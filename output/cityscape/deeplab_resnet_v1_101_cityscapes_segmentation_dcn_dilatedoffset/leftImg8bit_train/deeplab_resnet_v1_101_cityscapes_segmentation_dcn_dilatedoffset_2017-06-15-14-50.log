2017-06-15 14:50:31,800 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data01/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data01/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn_dilatedoffset'}

2017-06-15 14:51:06,809 Epoch[0] Batch [10]	Speed: 7.94 samples/sec	Train-FCNLogLoss=2.869633,	
2017-06-15 14:51:11,627 Epoch[0] Batch [20]	Speed: 8.30 samples/sec	Train-FCNLogLoss=2.728760,	
2017-06-15 14:51:16,647 Epoch[0] Batch [30]	Speed: 7.97 samples/sec	Train-FCNLogLoss=2.500670,	
2017-06-15 14:51:21,501 Epoch[0] Batch [40]	Speed: 8.24 samples/sec	Train-FCNLogLoss=2.260489,	
2017-06-15 14:51:26,462 Epoch[0] Batch [50]	Speed: 8.06 samples/sec	Train-FCNLogLoss=2.058872,	
2017-06-15 14:51:31,327 Epoch[0] Batch [60]	Speed: 8.22 samples/sec	Train-FCNLogLoss=1.901368,	
2017-06-15 14:51:36,458 Epoch[0] Batch [70]	Speed: 7.80 samples/sec	Train-FCNLogLoss=1.768904,	
2017-06-15 14:51:41,379 Epoch[0] Batch [80]	Speed: 8.13 samples/sec	Train-FCNLogLoss=1.656049,	
2017-06-15 14:51:46,418 Epoch[0] Batch [90]	Speed: 7.94 samples/sec	Train-FCNLogLoss=1.562262,	
2017-06-15 14:51:51,395 Epoch[0] Batch [100]	Speed: 8.04 samples/sec	Train-FCNLogLoss=1.495783,	
2017-06-15 14:51:56,435 Epoch[0] Batch [110]	Speed: 7.94 samples/sec	Train-FCNLogLoss=1.427824,	
2017-06-15 14:52:01,352 Epoch[0] Batch [120]	Speed: 8.14 samples/sec	Train-FCNLogLoss=1.357380,	
2017-06-15 14:52:06,677 Epoch[0] Batch [130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=1.295747,	
2017-06-15 14:52:11,549 Epoch[0] Batch [140]	Speed: 8.21 samples/sec	Train-FCNLogLoss=1.251267,	
2017-06-15 14:52:16,547 Epoch[0] Batch [150]	Speed: 8.00 samples/sec	Train-FCNLogLoss=1.208183,	
2017-06-15 14:52:21,532 Epoch[0] Batch [160]	Speed: 8.02 samples/sec	Train-FCNLogLoss=1.172055,	
2017-06-15 14:52:26,431 Epoch[0] Batch [170]	Speed: 8.17 samples/sec	Train-FCNLogLoss=1.136288,	
2017-06-15 14:52:31,407 Epoch[0] Batch [180]	Speed: 8.04 samples/sec	Train-FCNLogLoss=1.101130,	
2017-06-15 14:52:36,392 Epoch[0] Batch [190]	Speed: 8.03 samples/sec	Train-FCNLogLoss=1.071117,	
2017-06-15 14:52:41,353 Epoch[0] Batch [200]	Speed: 8.06 samples/sec	Train-FCNLogLoss=1.041014,	
2017-06-15 14:52:46,301 Epoch[0] Batch [210]	Speed: 8.08 samples/sec	Train-FCNLogLoss=1.016800,	
2017-06-15 14:52:51,486 Epoch[0] Batch [220]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.994710,	
2017-06-15 14:52:56,354 Epoch[0] Batch [230]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.972539,	
2017-06-15 14:53:01,408 Epoch[0] Batch [240]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.954997,	
2017-06-15 14:53:06,411 Epoch[0] Batch [250]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.933182,	
2017-06-15 14:53:11,430 Epoch[0] Batch [260]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.915387,	
2017-06-15 14:53:16,308 Epoch[0] Batch [270]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.897338,	
2017-06-15 14:53:21,349 Epoch[0] Batch [280]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.880634,	
2017-06-15 14:53:26,234 Epoch[0] Batch [290]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.867344,	
2017-06-15 14:53:31,144 Epoch[0] Batch [300]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.853942,	
2017-06-15 14:53:36,218 Epoch[0] Batch [310]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.841070,	
2017-06-15 14:53:41,248 Epoch[0] Batch [320]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.828510,	
2017-06-15 14:53:46,380 Epoch[0] Batch [330]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.814990,	
2017-06-15 14:53:51,184 Epoch[0] Batch [340]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.805048,	
2017-06-15 14:53:56,496 Epoch[0] Batch [350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.795287,	
2017-06-15 14:54:01,441 Epoch[0] Batch [360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.786292,	
2017-06-15 14:54:06,366 Epoch[0] Batch [370]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.775663,	
2017-06-15 14:54:11,357 Epoch[0] Batch [380]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.765329,	
2017-06-15 14:54:16,324 Epoch[0] Batch [390]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.755758,	
2017-06-15 14:54:21,375 Epoch[0] Batch [400]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.746312,	
2017-06-15 14:54:26,539 Epoch[0] Batch [410]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.736141,	
2017-06-15 14:54:31,589 Epoch[0] Batch [420]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.728351,	
2017-06-15 14:54:36,668 Epoch[0] Batch [430]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.720172,	
2017-06-15 14:54:41,703 Epoch[0] Batch [440]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.711740,	
2017-06-15 14:54:46,804 Epoch[0] Batch [450]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.704627,	
2017-06-15 14:54:51,843 Epoch[0] Batch [460]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.699861,	
2017-06-15 14:54:56,856 Epoch[0] Batch [470]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.692886,	
2017-06-15 14:55:01,912 Epoch[0] Batch [480]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.686190,	
2017-06-15 14:55:07,071 Epoch[0] Batch [490]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.680140,	
2017-06-15 14:55:12,220 Epoch[0] Batch [500]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.672585,	
2017-06-15 14:55:17,151 Epoch[0] Batch [510]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.667342,	
2017-06-15 14:55:22,067 Epoch[0] Batch [520]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.661564,	
2017-06-15 14:55:27,099 Epoch[0] Batch [530]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.656442,	
2017-06-15 14:55:32,419 Epoch[0] Batch [540]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.650622,	
2017-06-15 14:55:38,562 Epoch[0] Batch [550]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.644769,	
2017-06-15 14:55:50,696 Epoch[0] Batch [560]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.639736,	
2017-06-15 14:55:59,869 Epoch[0] Batch [570]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.636482,	
2017-06-15 14:56:09,791 Epoch[0] Batch [580]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.632941,	
2017-06-15 14:56:20,763 Epoch[0] Batch [590]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.629399,	
2017-06-15 14:56:32,545 Epoch[0] Batch [600]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.624291,	
2017-06-15 14:56:39,960 Epoch[0] Batch [610]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.619861,	
2017-06-15 14:56:45,080 Epoch[0] Batch [620]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.615821,	
2017-06-15 14:56:49,952 Epoch[0] Batch [630]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.612174,	
2017-06-15 14:56:54,894 Epoch[0] Batch [640]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.608736,	
2017-06-15 14:56:59,800 Epoch[0] Batch [650]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.605295,	
2017-06-15 14:57:04,803 Epoch[0] Batch [660]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.601196,	
2017-06-15 14:57:09,713 Epoch[0] Batch [670]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.597705,	
2017-06-15 14:57:14,716 Epoch[0] Batch [680]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.593519,	
2017-06-15 14:57:19,736 Epoch[0] Batch [690]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.589656,	
2017-06-15 14:57:24,817 Epoch[0] Batch [700]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.586147,	
2017-06-15 14:57:29,742 Epoch[0] Batch [710]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.582087,	
2017-06-15 14:57:34,921 Epoch[0] Batch [720]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.578872,	
2017-06-15 14:57:39,827 Epoch[0] Batch [730]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.575647,	
2017-06-15 14:57:44,837 Epoch[0] Batch [740]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.572121,	
2017-06-15 14:57:49,842 Epoch[0] Batch [750]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.569716,	
2017-06-15 14:57:54,900 Epoch[0] Batch [760]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.566615,	
2017-06-15 14:58:00,081 Epoch[0] Batch [770]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.563167,	
2017-06-15 14:58:05,801 Epoch[0] Batch [780]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.560242,	
2017-06-15 14:58:11,815 Epoch[0] Batch [790]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.557528,	
2017-06-15 14:58:20,177 Epoch[0] Batch [800]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.554305,	
2017-06-15 14:58:25,002 Epoch[0] Batch [810]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.551697,	
2017-06-15 14:58:29,888 Epoch[0] Batch [820]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.549381,	
2017-06-15 14:58:34,810 Epoch[0] Batch [830]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.546673,	
2017-06-15 14:58:39,773 Epoch[0] Batch [840]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.543825,	
2017-06-15 14:58:44,609 Epoch[0] Batch [850]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.541466,	
2017-06-15 14:58:49,540 Epoch[0] Batch [860]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.538908,	
2017-06-15 14:58:54,376 Epoch[0] Batch [870]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.536037,	
2017-06-15 14:58:59,323 Epoch[0] Batch [880]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.534408,	
2017-06-15 14:59:04,206 Epoch[0] Batch [890]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.532358,	
2017-06-15 14:59:09,175 Epoch[0] Batch [900]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.530265,	
2017-06-15 14:59:14,058 Epoch[0] Batch [910]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.528074,	
2017-06-15 14:59:19,005 Epoch[0] Batch [920]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.525906,	
2017-06-15 14:59:23,970 Epoch[0] Batch [930]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.524336,	
2017-06-15 14:59:28,818 Epoch[0] Batch [940]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.522360,	
2017-06-15 14:59:33,769 Epoch[0] Batch [950]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.520346,	
2017-06-15 14:59:38,695 Epoch[0] Batch [960]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.518088,	
2017-06-15 14:59:43,642 Epoch[0] Batch [970]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.516755,	
2017-06-15 14:59:48,614 Epoch[0] Batch [980]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.515962,	
2017-06-15 14:59:53,766 Epoch[0] Batch [990]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.513383,	
2017-06-15 15:00:02,799 Epoch[0] Batch [1000]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.511687,	
2017-06-15 15:00:12,081 Epoch[0] Batch [1010]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.510713,	
2017-06-15 15:00:19,615 Epoch[0] Batch [1020]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.509713,	
2017-06-15 15:00:24,491 Epoch[0] Batch [1030]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.509525,	
2017-06-15 15:00:29,337 Epoch[0] Batch [1040]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.509268,	
2017-06-15 15:00:34,168 Epoch[0] Batch [1050]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.508884,	
2017-06-15 15:00:39,080 Epoch[0] Batch [1060]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.508028,	
2017-06-15 15:00:44,007 Epoch[0] Batch [1070]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.508086,	
2017-06-15 15:00:48,939 Epoch[0] Batch [1080]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.508764,	
2017-06-15 15:00:53,862 Epoch[0] Batch [1090]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.509125,	
2017-06-15 15:00:58,778 Epoch[0] Batch [1100]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.508608,	
2017-06-15 15:01:03,650 Epoch[0] Batch [1110]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.507312,	
2017-06-15 15:01:08,548 Epoch[0] Batch [1120]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.506078,	
2017-06-15 15:01:13,519 Epoch[0] Batch [1130]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.504393,	
2017-06-15 15:01:18,418 Epoch[0] Batch [1140]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.503635,	
2017-06-15 15:01:23,286 Epoch[0] Batch [1150]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.502870,	
2017-06-15 15:01:28,120 Epoch[0] Batch [1160]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.501533,	
2017-06-15 15:01:32,978 Epoch[0] Batch [1170]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.500053,	
2017-06-15 15:01:37,915 Epoch[0] Batch [1180]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.498978,	
2017-06-15 15:01:42,827 Epoch[0] Batch [1190]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.497329,	
2017-06-15 15:01:47,680 Epoch[0] Batch [1200]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.495837,	
2017-06-15 15:01:52,613 Epoch[0] Batch [1210]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.495719,	
2017-06-15 15:01:57,472 Epoch[0] Batch [1220]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.495320,	
2017-06-15 15:02:02,358 Epoch[0] Batch [1230]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.495132,	
2017-06-15 15:02:07,158 Epoch[0] Batch [1240]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.494209,	
2017-06-15 15:02:12,043 Epoch[0] Batch [1250]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.492856,	
2017-06-15 15:02:16,951 Epoch[0] Batch [1260]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.491474,	
2017-06-15 15:02:21,889 Epoch[0] Batch [1270]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.490054,	
2017-06-15 15:02:26,795 Epoch[0] Batch [1280]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.488778,	
2017-06-15 15:02:32,134 Epoch[0] Batch [1290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.487601,	
2017-06-15 15:02:40,352 Epoch[0] Batch [1300]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.485835,	
2017-06-15 15:02:47,585 Epoch[0] Batch [1310]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.484218,	
2017-06-15 15:02:52,467 Epoch[0] Batch [1320]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.482859,	
2017-06-15 15:02:57,437 Epoch[0] Batch [1330]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.481341,	
2017-06-15 15:03:02,278 Epoch[0] Batch [1340]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.480657,	
2017-06-15 15:03:07,217 Epoch[0] Batch [1350]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.479184,	
2017-06-15 15:03:12,124 Epoch[0] Batch [1360]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.479180,	
2017-06-15 15:03:17,044 Epoch[0] Batch [1370]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.478391,	
2017-06-15 15:03:22,023 Epoch[0] Batch [1380]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.477525,	
2017-06-15 15:03:26,903 Epoch[0] Batch [1390]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.476369,	
2017-06-15 15:03:31,697 Epoch[0] Batch [1400]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.474883,	
2017-06-15 15:03:36,542 Epoch[0] Batch [1410]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.473706,	
2017-06-15 15:03:41,416 Epoch[0] Batch [1420]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.472506,	
2017-06-15 15:03:46,281 Epoch[0] Batch [1430]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.471653,	
2017-06-15 15:03:51,124 Epoch[0] Batch [1440]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.470261,	
2017-06-15 15:03:56,021 Epoch[0] Batch [1450]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.469108,	
2017-06-15 15:04:00,811 Epoch[0] Batch [1460]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.467710,	
2017-06-15 15:04:05,718 Epoch[0] Batch [1470]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.466357,	
2017-06-15 15:04:10,632 Epoch[0] Batch [1480]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.465442,	
2017-06-15 15:04:13,491 Epoch[0] Train-FCNLogLoss=0.465385
2017-06-15 15:04:13,492 Epoch[0] Time cost=796.435
2017-06-15 15:04:14,332 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0001.params"
2017-06-15 15:04:16,138 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0001.states"
2017-06-15 15:04:21,477 Epoch[1] Batch [10]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.403203,	
2017-06-15 15:04:26,000 Epoch[1] Batch [20]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.349078,	
2017-06-15 15:04:30,499 Epoch[1] Batch [30]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.325966,	
2017-06-15 15:04:35,153 Epoch[1] Batch [40]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.313718,	
2017-06-15 15:04:39,770 Epoch[1] Batch [50]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.304883,	
2017-06-15 15:04:44,392 Epoch[1] Batch [60]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.303536,	
2017-06-15 15:04:49,032 Epoch[1] Batch [70]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.306588,	
2017-06-15 15:04:53,536 Epoch[1] Batch [80]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.300078,	
2017-06-15 15:04:58,119 Epoch[1] Batch [90]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.297546,	
2017-06-15 15:05:02,685 Epoch[1] Batch [100]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.296719,	
2017-06-15 15:05:07,427 Epoch[1] Batch [110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.290887,	
2017-06-15 15:05:11,921 Epoch[1] Batch [120]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.293241,	
2017-06-15 15:05:16,527 Epoch[1] Batch [130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.289436,	
2017-06-15 15:05:21,157 Epoch[1] Batch [140]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.293455,	
2017-06-15 15:05:25,638 Epoch[1] Batch [150]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.291953,	
2017-06-15 15:05:30,184 Epoch[1] Batch [160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.292771,	
2017-06-15 15:05:34,792 Epoch[1] Batch [170]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.297346,	
2017-06-15 15:05:39,475 Epoch[1] Batch [180]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.297327,	
2017-06-15 15:05:46,239 Epoch[1] Batch [190]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.294626,	
2017-06-15 15:05:53,989 Epoch[1] Batch [200]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.291738,	
2017-06-15 15:06:01,312 Epoch[1] Batch [210]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.291985,	
2017-06-15 15:06:05,769 Epoch[1] Batch [220]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.289520,	
2017-06-15 15:06:10,318 Epoch[1] Batch [230]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.287757,	
2017-06-15 15:06:14,792 Epoch[1] Batch [240]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.288085,	
2017-06-15 15:06:19,425 Epoch[1] Batch [250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.287688,	
2017-06-15 15:06:23,993 Epoch[1] Batch [260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.287367,	
2017-06-15 15:06:28,561 Epoch[1] Batch [270]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.288455,	
2017-06-15 15:06:33,197 Epoch[1] Batch [280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.288632,	
2017-06-15 15:06:37,726 Epoch[1] Batch [290]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.287352,	
2017-06-15 15:06:42,353 Epoch[1] Batch [300]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.286577,	
2017-06-15 15:06:46,884 Epoch[1] Batch [310]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.285143,	
2017-06-15 15:06:51,411 Epoch[1] Batch [320]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.284780,	
2017-06-15 15:06:55,984 Epoch[1] Batch [330]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.283607,	
2017-06-15 15:07:00,642 Epoch[1] Batch [340]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.283106,	
2017-06-15 15:07:05,222 Epoch[1] Batch [350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.282847,	
2017-06-15 15:07:09,768 Epoch[1] Batch [360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.281398,	
2017-06-15 15:07:14,339 Epoch[1] Batch [370]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.281939,	
2017-06-15 15:07:18,857 Epoch[1] Batch [380]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.280902,	
2017-06-15 15:07:23,424 Epoch[1] Batch [390]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.279773,	
2017-06-15 15:07:27,934 Epoch[1] Batch [400]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.278997,	
2017-06-15 15:07:32,514 Epoch[1] Batch [410]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.278359,	
2017-06-15 15:07:37,129 Epoch[1] Batch [420]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.276828,	
2017-06-15 15:07:41,600 Epoch[1] Batch [430]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.277148,	
2017-06-15 15:07:46,240 Epoch[1] Batch [440]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.276761,	
2017-06-15 15:07:50,793 Epoch[1] Batch [450]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.276958,	
2017-06-15 15:07:55,420 Epoch[1] Batch [460]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.276067,	
2017-06-15 15:07:59,996 Epoch[1] Batch [470]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.274570,	
2017-06-15 15:08:04,547 Epoch[1] Batch [480]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.273778,	
2017-06-15 15:08:09,136 Epoch[1] Batch [490]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.272293,	
2017-06-15 15:08:13,706 Epoch[1] Batch [500]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.271333,	
2017-06-15 15:08:18,303 Epoch[1] Batch [510]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.270448,	
2017-06-15 15:08:22,826 Epoch[1] Batch [520]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.269641,	
2017-06-15 15:08:27,420 Epoch[1] Batch [530]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.269211,	
2017-06-15 15:08:32,012 Epoch[1] Batch [540]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.267826,	
2017-06-15 15:08:36,551 Epoch[1] Batch [550]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.268118,	
2017-06-15 15:08:41,063 Epoch[1] Batch [560]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.267028,	
2017-06-15 15:08:45,675 Epoch[1] Batch [570]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.266027,	
2017-06-15 15:08:50,210 Epoch[1] Batch [580]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.265629,	
2017-06-15 15:08:54,894 Epoch[1] Batch [590]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.265178,	
2017-06-15 15:08:59,550 Epoch[1] Batch [600]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.264717,	
2017-06-15 15:09:04,178 Epoch[1] Batch [610]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.264389,	
2017-06-15 15:09:08,662 Epoch[1] Batch [620]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.263517,	
2017-06-15 15:09:13,242 Epoch[1] Batch [630]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.263336,	
2017-06-15 15:09:17,753 Epoch[1] Batch [640]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.262824,	
2017-06-15 15:09:22,264 Epoch[1] Batch [650]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.264603,	
2017-06-15 15:09:26,805 Epoch[1] Batch [660]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.264614,	
2017-06-15 15:09:31,378 Epoch[1] Batch [670]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.264579,	
2017-06-15 15:09:35,981 Epoch[1] Batch [680]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.265398,	
2017-06-15 15:09:40,541 Epoch[1] Batch [690]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.265610,	
2017-06-15 15:09:45,113 Epoch[1] Batch [700]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.265597,	
2017-06-15 15:09:49,676 Epoch[1] Batch [710]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.266166,	
2017-06-15 15:09:54,256 Epoch[1] Batch [720]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.266069,	
2017-06-15 15:10:02,002 Epoch[1] Batch [730]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.265545,	
2017-06-15 15:10:10,375 Epoch[1] Batch [740]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.265256,	
2017-06-15 15:10:17,897 Epoch[1] Batch [750]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.265002,	
2017-06-15 15:10:26,953 Epoch[1] Batch [760]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.264403,	
2017-06-15 15:10:37,222 Epoch[1] Batch [770]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.264000,	
2017-06-15 15:10:42,667 Epoch[1] Batch [780]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.263183,	
2017-06-15 15:10:47,178 Epoch[1] Batch [790]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.262597,	
2017-06-15 15:10:51,709 Epoch[1] Batch [800]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.261904,	
2017-06-15 15:10:56,116 Epoch[1] Batch [810]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.261224,	
2017-06-15 15:11:00,664 Epoch[1] Batch [820]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.260480,	
2017-06-15 15:11:05,189 Epoch[1] Batch [830]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.260351,	
2017-06-15 15:11:09,705 Epoch[1] Batch [840]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.259582,	
2017-06-15 15:11:14,411 Epoch[1] Batch [850]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.259162,	
2017-06-15 15:11:18,962 Epoch[1] Batch [860]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.258742,	
2017-06-15 15:11:23,560 Epoch[1] Batch [870]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.258017,	
2017-06-15 15:11:28,160 Epoch[1] Batch [880]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.257956,	
2017-06-15 15:11:32,759 Epoch[1] Batch [890]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.257914,	
2017-06-15 15:11:37,398 Epoch[1] Batch [900]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.257209,	
2017-06-15 15:11:41,914 Epoch[1] Batch [910]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.257340,	
2017-06-15 15:11:46,514 Epoch[1] Batch [920]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.256956,	
2017-06-15 15:11:51,076 Epoch[1] Batch [930]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.256700,	
2017-06-15 15:11:55,651 Epoch[1] Batch [940]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.256169,	
2017-06-15 15:12:00,229 Epoch[1] Batch [950]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.255607,	
2017-06-15 15:12:04,857 Epoch[1] Batch [960]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.255258,	
2017-06-15 15:12:09,430 Epoch[1] Batch [970]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.254832,	
2017-06-15 15:12:14,009 Epoch[1] Batch [980]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.255049,	
2017-06-15 15:12:18,563 Epoch[1] Batch [990]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.254994,	
2017-06-15 15:12:23,208 Epoch[1] Batch [1000]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.254551,	
2017-06-15 15:12:27,782 Epoch[1] Batch [1010]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.254224,	
2017-06-15 15:12:32,448 Epoch[1] Batch [1020]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.253812,	
2017-06-15 15:12:37,137 Epoch[1] Batch [1030]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.253626,	
2017-06-15 15:12:41,765 Epoch[1] Batch [1040]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.253127,	
2017-06-15 15:12:46,384 Epoch[1] Batch [1050]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.253104,	
2017-06-15 15:12:50,909 Epoch[1] Batch [1060]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.252824,	
2017-06-15 15:12:55,533 Epoch[1] Batch [1070]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.252413,	
2017-06-15 15:13:00,122 Epoch[1] Batch [1080]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.252218,	
2017-06-15 15:13:04,715 Epoch[1] Batch [1090]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.251936,	
2017-06-15 15:13:09,260 Epoch[1] Batch [1100]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.251843,	
2017-06-15 15:13:13,876 Epoch[1] Batch [1110]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.251567,	
2017-06-15 15:13:18,453 Epoch[1] Batch [1120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.251307,	
2017-06-15 15:13:23,053 Epoch[1] Batch [1130]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.251517,	
2017-06-15 15:13:27,724 Epoch[1] Batch [1140]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.251962,	
2017-06-15 15:13:32,234 Epoch[1] Batch [1150]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.251733,	
2017-06-15 15:13:36,798 Epoch[1] Batch [1160]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.251515,	
2017-06-15 15:13:41,381 Epoch[1] Batch [1170]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.251220,	
2017-06-15 15:13:45,933 Epoch[1] Batch [1180]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.250816,	
2017-06-15 15:13:50,469 Epoch[1] Batch [1190]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.250621,	
2017-06-15 15:13:55,048 Epoch[1] Batch [1200]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.250233,	
2017-06-15 15:13:59,772 Epoch[1] Batch [1210]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.249903,	
2017-06-15 15:14:04,332 Epoch[1] Batch [1220]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.249423,	
2017-06-15 15:14:09,268 Epoch[1] Batch [1230]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.248913,	
2017-06-15 15:14:14,529 Epoch[1] Batch [1240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.248906,	
2017-06-15 15:14:21,736 Epoch[1] Batch [1250]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.248677,	
2017-06-15 15:14:28,486 Epoch[1] Batch [1260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.248474,	
2017-06-15 15:14:37,647 Epoch[1] Batch [1270]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.248349,	
2017-06-15 15:14:42,603 Epoch[1] Batch [1280]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.247908,	
2017-06-15 15:14:47,032 Epoch[1] Batch [1290]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.247597,	
2017-06-15 15:14:51,556 Epoch[1] Batch [1300]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.247189,	
2017-06-15 15:14:56,119 Epoch[1] Batch [1310]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.247049,	
2017-06-15 15:15:00,706 Epoch[1] Batch [1320]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.246793,	
2017-06-15 15:15:05,219 Epoch[1] Batch [1330]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.246387,	
2017-06-15 15:15:09,773 Epoch[1] Batch [1340]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.246035,	
2017-06-15 15:15:14,381 Epoch[1] Batch [1350]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.245845,	
2017-06-15 15:15:18,965 Epoch[1] Batch [1360]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.245974,	
2017-06-15 15:15:23,552 Epoch[1] Batch [1370]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.245743,	
2017-06-15 15:15:28,186 Epoch[1] Batch [1380]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.245754,	
2017-06-15 15:15:33,193 Epoch[1] Batch [1390]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.245606,	
2017-06-15 15:15:39,012 Epoch[1] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.245734,	
2017-06-15 15:15:46,461 Epoch[1] Batch [1410]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.245974,	
2017-06-15 15:15:53,230 Epoch[1] Batch [1420]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.246111,	
2017-06-15 15:15:58,563 Epoch[1] Batch [1430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.245920,	
2017-06-15 15:16:03,217 Epoch[1] Batch [1440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.245634,	
2017-06-15 15:16:07,763 Epoch[1] Batch [1450]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.245525,	
2017-06-15 15:16:12,310 Epoch[1] Batch [1460]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.245114,	
2017-06-15 15:16:16,868 Epoch[1] Batch [1470]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.244862,	
2017-06-15 15:16:21,484 Epoch[1] Batch [1480]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.244710,	
2017-06-15 15:16:24,181 Epoch[1] Train-FCNLogLoss=0.244419
2017-06-15 15:16:24,181 Epoch[1] Time cost=728.043
2017-06-15 15:16:24,903 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0002.params"
2017-06-15 15:16:26,607 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0002.states"
2017-06-15 15:16:31,875 Epoch[2] Batch [10]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.239706,	
2017-06-15 15:16:36,410 Epoch[2] Batch [20]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.238783,	
2017-06-15 15:16:40,981 Epoch[2] Batch [30]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.224102,	
2017-06-15 15:16:45,467 Epoch[2] Batch [40]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.219874,	
2017-06-15 15:16:50,071 Epoch[2] Batch [50]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.214622,	
2017-06-15 15:16:54,644 Epoch[2] Batch [60]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.208501,	
2017-06-15 15:16:59,325 Epoch[2] Batch [70]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.211296,	
2017-06-15 15:17:03,820 Epoch[2] Batch [80]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.211356,	
2017-06-15 15:17:08,366 Epoch[2] Batch [90]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.211395,	
2017-06-15 15:17:12,964 Epoch[2] Batch [100]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.208417,	
2017-06-15 15:17:17,538 Epoch[2] Batch [110]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.207876,	
2017-06-15 15:17:22,166 Epoch[2] Batch [120]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.205469,	
2017-06-15 15:17:26,846 Epoch[2] Batch [130]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.204281,	
2017-06-15 15:17:31,285 Epoch[2] Batch [140]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.201645,	
2017-06-15 15:17:35,761 Epoch[2] Batch [150]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.200566,	
2017-06-15 15:17:40,310 Epoch[2] Batch [160]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.199027,	
2017-06-15 15:17:44,829 Epoch[2] Batch [170]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.198304,	
2017-06-15 15:17:49,442 Epoch[2] Batch [180]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.198989,	
2017-06-15 15:17:54,009 Epoch[2] Batch [190]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.198623,	
2017-06-15 15:17:58,620 Epoch[2] Batch [200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.197728,	
2017-06-15 15:18:03,178 Epoch[2] Batch [210]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.198890,	
2017-06-15 15:18:07,719 Epoch[2] Batch [220]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.200399,	
2017-06-15 15:18:12,361 Epoch[2] Batch [230]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.200317,	
2017-06-15 15:18:17,228 Epoch[2] Batch [240]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.200015,	
2017-06-15 15:18:23,905 Epoch[2] Batch [250]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.199186,	
2017-06-15 15:18:31,330 Epoch[2] Batch [260]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.199158,	
2017-06-15 15:18:40,695 Epoch[2] Batch [270]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.199768,	
2017-06-15 15:18:45,174 Epoch[2] Batch [280]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.199608,	
2017-06-15 15:18:49,630 Epoch[2] Batch [290]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.200894,	
2017-06-15 15:18:54,047 Epoch[2] Batch [300]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.200709,	
2017-06-15 15:18:58,582 Epoch[2] Batch [310]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.201621,	
2017-06-15 15:19:03,282 Epoch[2] Batch [320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.202779,	
2017-06-15 15:19:07,944 Epoch[2] Batch [330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.203834,	
2017-06-15 15:19:12,473 Epoch[2] Batch [340]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.205303,	
2017-06-15 15:19:17,202 Epoch[2] Batch [350]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.207663,	
2017-06-15 15:19:21,669 Epoch[2] Batch [360]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.208750,	
2017-06-15 15:19:26,213 Epoch[2] Batch [370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.208622,	
2017-06-15 15:19:30,739 Epoch[2] Batch [380]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.208204,	
2017-06-15 15:19:35,261 Epoch[2] Batch [390]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.207796,	
2017-06-15 15:19:39,858 Epoch[2] Batch [400]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.207076,	
2017-06-15 15:19:44,402 Epoch[2] Batch [410]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.206507,	
2017-06-15 15:19:48,976 Epoch[2] Batch [420]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.207971,	
2017-06-15 15:19:53,490 Epoch[2] Batch [430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.209327,	
2017-06-15 15:19:58,149 Epoch[2] Batch [440]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.209823,	
2017-06-15 15:20:02,837 Epoch[2] Batch [450]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.209184,	
2017-06-15 15:20:07,528 Epoch[2] Batch [460]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.209793,	
2017-06-15 15:20:12,123 Epoch[2] Batch [470]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.210023,	
2017-06-15 15:20:16,740 Epoch[2] Batch [480]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.209413,	
2017-06-15 15:20:21,283 Epoch[2] Batch [490]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.208655,	
2017-06-15 15:20:25,840 Epoch[2] Batch [500]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.208376,	
2017-06-15 15:20:30,363 Epoch[2] Batch [510]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.208161,	
2017-06-15 15:20:34,895 Epoch[2] Batch [520]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.207669,	
2017-06-15 15:20:39,446 Epoch[2] Batch [530]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.207598,	
2017-06-15 15:20:43,993 Epoch[2] Batch [540]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.207599,	
2017-06-15 15:20:48,541 Epoch[2] Batch [550]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.207284,	
2017-06-15 15:20:53,083 Epoch[2] Batch [560]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.206956,	
2017-06-15 15:20:57,710 Epoch[2] Batch [570]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.207178,	
2017-06-15 15:21:02,257 Epoch[2] Batch [580]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.207434,	
2017-06-15 15:21:06,830 Epoch[2] Batch [590]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.206774,	
2017-06-15 15:21:11,348 Epoch[2] Batch [600]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.206184,	
2017-06-15 15:21:15,908 Epoch[2] Batch [610]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.205471,	
2017-06-15 15:21:20,588 Epoch[2] Batch [620]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.205132,	
2017-06-15 15:21:25,285 Epoch[2] Batch [630]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.208471,	
2017-06-15 15:21:29,925 Epoch[2] Batch [640]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.210379,	
2017-06-15 15:21:34,463 Epoch[2] Batch [650]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.211296,	
2017-06-15 15:21:39,033 Epoch[2] Batch [660]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.212242,	
2017-06-15 15:21:43,475 Epoch[2] Batch [670]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.212410,	
2017-06-15 15:21:48,136 Epoch[2] Batch [680]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.213055,	
2017-06-15 15:21:52,735 Epoch[2] Batch [690]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.213380,	
2017-06-15 15:21:57,328 Epoch[2] Batch [700]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.213695,	
2017-06-15 15:22:01,892 Epoch[2] Batch [710]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.214201,	
2017-06-15 15:22:06,460 Epoch[2] Batch [720]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.214069,	
2017-06-15 15:22:11,076 Epoch[2] Batch [730]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.214855,	
2017-06-15 15:22:15,593 Epoch[2] Batch [740]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.216177,	
2017-06-15 15:22:20,165 Epoch[2] Batch [750]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.216150,	
2017-06-15 15:22:24,749 Epoch[2] Batch [760]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.216191,	
2017-06-15 15:22:29,326 Epoch[2] Batch [770]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.216038,	
2017-06-15 15:22:33,958 Epoch[2] Batch [780]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.216018,	
2017-06-15 15:22:38,480 Epoch[2] Batch [790]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.215920,	
2017-06-15 15:22:43,071 Epoch[2] Batch [800]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.215394,	
2017-06-15 15:22:47,708 Epoch[2] Batch [810]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.215049,	
2017-06-15 15:22:52,330 Epoch[2] Batch [820]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.214608,	
2017-06-15 15:22:56,866 Epoch[2] Batch [830]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.214188,	
2017-06-15 15:23:01,492 Epoch[2] Batch [840]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.214210,	
2017-06-15 15:23:06,028 Epoch[2] Batch [850]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.213805,	
2017-06-15 15:23:10,700 Epoch[2] Batch [860]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.213835,	
2017-06-15 15:23:15,269 Epoch[2] Batch [870]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.213341,	
2017-06-15 15:23:19,885 Epoch[2] Batch [880]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.212818,	
2017-06-15 15:23:24,499 Epoch[2] Batch [890]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.213227,	
2017-06-15 15:23:29,084 Epoch[2] Batch [900]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.212973,	
2017-06-15 15:23:33,692 Epoch[2] Batch [910]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.212807,	
2017-06-15 15:23:38,238 Epoch[2] Batch [920]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.212354,	
2017-06-15 15:23:42,830 Epoch[2] Batch [930]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.211828,	
2017-06-15 15:23:47,462 Epoch[2] Batch [940]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.211460,	
2017-06-15 15:23:51,995 Epoch[2] Batch [950]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.211211,	
2017-06-15 15:23:56,587 Epoch[2] Batch [960]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.211119,	
2017-06-15 15:24:01,219 Epoch[2] Batch [970]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.211389,	
2017-06-15 15:24:05,786 Epoch[2] Batch [980]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.211389,	
2017-06-15 15:24:10,390 Epoch[2] Batch [990]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.211413,	
2017-06-15 15:24:14,966 Epoch[2] Batch [1000]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.210989,	
2017-06-15 15:24:19,811 Epoch[2] Batch [1010]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.210519,	
2017-06-15 15:24:24,381 Epoch[2] Batch [1020]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.210243,	
2017-06-15 15:24:29,034 Epoch[2] Batch [1030]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.210045,	
2017-06-15 15:24:33,696 Epoch[2] Batch [1040]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.209811,	
2017-06-15 15:24:38,417 Epoch[2] Batch [1050]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.209881,	
2017-06-15 15:24:43,143 Epoch[2] Batch [1060]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.209936,	
2017-06-15 15:24:47,994 Epoch[2] Batch [1070]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.209454,	
2017-06-15 15:24:52,893 Epoch[2] Batch [1080]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.209395,	
2017-06-15 15:24:57,687 Epoch[2] Batch [1090]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.209387,	
2017-06-15 15:25:02,272 Epoch[2] Batch [1100]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.208996,	
2017-06-15 15:25:07,086 Epoch[2] Batch [1110]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.209086,	
2017-06-15 15:25:11,745 Epoch[2] Batch [1120]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.209102,	
2017-06-15 15:25:16,314 Epoch[2] Batch [1130]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.208829,	
2017-06-15 15:25:21,019 Epoch[2] Batch [1140]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.208916,	
2017-06-15 15:25:25,860 Epoch[2] Batch [1150]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.208861,	
2017-06-15 15:25:30,659 Epoch[2] Batch [1160]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.208612,	
2017-06-15 15:25:35,274 Epoch[2] Batch [1170]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.208328,	
2017-06-15 15:25:39,948 Epoch[2] Batch [1180]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.208315,	
2017-06-15 15:25:44,585 Epoch[2] Batch [1190]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.208745,	
2017-06-15 15:25:49,095 Epoch[2] Batch [1200]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.208777,	
2017-06-15 15:25:53,642 Epoch[2] Batch [1210]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.208946,	
2017-06-15 15:25:58,348 Epoch[2] Batch [1220]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.208827,	
2017-06-15 15:26:02,935 Epoch[2] Batch [1230]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.208878,	
2017-06-15 15:26:08,025 Epoch[2] Batch [1240]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.208533,	
2017-06-15 15:26:12,812 Epoch[2] Batch [1250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.208421,	
2017-06-15 15:26:18,054 Epoch[2] Batch [1260]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.208414,	
2017-06-15 15:26:23,040 Epoch[2] Batch [1270]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.208505,	
2017-06-15 15:26:27,996 Epoch[2] Batch [1280]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.208391,	
2017-06-15 15:26:32,537 Epoch[2] Batch [1290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.208212,	
2017-06-15 15:26:37,483 Epoch[2] Batch [1300]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.208156,	
2017-06-15 15:26:42,286 Epoch[2] Batch [1310]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.208020,	
2017-06-15 15:26:46,824 Epoch[2] Batch [1320]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.207865,	
2017-06-15 15:26:51,467 Epoch[2] Batch [1330]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.207691,	
2017-06-15 15:26:56,308 Epoch[2] Batch [1340]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.207424,	
2017-06-15 15:27:01,331 Epoch[2] Batch [1350]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.207346,	
2017-06-15 15:27:05,967 Epoch[2] Batch [1360]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.207102,	
2017-06-15 15:27:10,526 Epoch[2] Batch [1370]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.206983,	
2017-06-15 15:27:15,196 Epoch[2] Batch [1380]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.207057,	
2017-06-15 15:27:20,154 Epoch[2] Batch [1390]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.206922,	
2017-06-15 15:27:25,094 Epoch[2] Batch [1400]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.206896,	
2017-06-15 15:27:30,310 Epoch[2] Batch [1410]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.206727,	
2017-06-15 15:27:35,492 Epoch[2] Batch [1420]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.206647,	
2017-06-15 15:27:40,216 Epoch[2] Batch [1430]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.206507,	
2017-06-15 15:27:45,672 Epoch[2] Batch [1440]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.206450,	
2017-06-15 15:27:50,496 Epoch[2] Batch [1450]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.206428,	
2017-06-15 15:27:55,319 Epoch[2] Batch [1460]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.206387,	
2017-06-15 15:28:00,190 Epoch[2] Batch [1470]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.206326,	
2017-06-15 15:28:04,856 Epoch[2] Batch [1480]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.206347,	
2017-06-15 15:28:08,030 Epoch[2] Train-FCNLogLoss=0.206149
2017-06-15 15:28:08,030 Epoch[2] Time cost=701.423
2017-06-15 15:28:08,798 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0003.params"
2017-06-15 15:28:10,619 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0003.states"
2017-06-15 15:28:16,141 Epoch[3] Batch [10]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.187272,	
2017-06-15 15:28:21,032 Epoch[3] Batch [20]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.175919,	
2017-06-15 15:28:25,842 Epoch[3] Batch [30]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.171097,	
2017-06-15 15:28:30,441 Epoch[3] Batch [40]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.172818,	
2017-06-15 15:28:35,352 Epoch[3] Batch [50]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.169871,	
2017-06-15 15:28:40,094 Epoch[3] Batch [60]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.167989,	
2017-06-15 15:28:44,849 Epoch[3] Batch [70]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.170228,	
2017-06-15 15:28:49,812 Epoch[3] Batch [80]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.176411,	
2017-06-15 15:28:54,516 Epoch[3] Batch [90]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.175929,	
2017-06-15 15:28:59,646 Epoch[3] Batch [100]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.174095,	
2017-06-15 15:29:04,239 Epoch[3] Batch [110]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.191481,	
2017-06-15 15:29:08,980 Epoch[3] Batch [120]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.226328,	
2017-06-15 15:29:13,961 Epoch[3] Batch [130]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.243330,	
2017-06-15 15:29:18,724 Epoch[3] Batch [140]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.248089,	
2017-06-15 15:29:23,662 Epoch[3] Batch [150]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.250749,	
2017-06-15 15:29:28,582 Epoch[3] Batch [160]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.251342,	
2017-06-15 15:29:33,105 Epoch[3] Batch [170]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.252191,	
2017-06-15 15:29:37,663 Epoch[3] Batch [180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.253737,	
2017-06-15 15:29:42,207 Epoch[3] Batch [190]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.251961,	
2017-06-15 15:29:46,846 Epoch[3] Batch [200]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.251833,	
2017-06-15 15:29:51,503 Epoch[3] Batch [210]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.250181,	
2017-06-15 15:29:56,004 Epoch[3] Batch [220]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.249759,	
2017-06-15 15:30:00,501 Epoch[3] Batch [230]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.246974,	
2017-06-15 15:30:05,072 Epoch[3] Batch [240]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.245894,	
2017-06-15 15:30:09,643 Epoch[3] Batch [250]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.245323,	
2017-06-15 15:30:14,216 Epoch[3] Batch [260]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.247939,	
2017-06-15 15:30:18,709 Epoch[3] Batch [270]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.247382,	
2017-06-15 15:30:23,229 Epoch[3] Batch [280]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.245027,	
2017-06-15 15:30:27,740 Epoch[3] Batch [290]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.244538,	
2017-06-15 15:30:32,347 Epoch[3] Batch [300]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.243020,	
2017-06-15 15:30:36,970 Epoch[3] Batch [310]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.241642,	
2017-06-15 15:30:41,487 Epoch[3] Batch [320]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.240565,	
2017-06-15 15:30:46,025 Epoch[3] Batch [330]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.240313,	
2017-06-15 15:30:50,522 Epoch[3] Batch [340]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.239813,	
2017-06-15 15:30:55,097 Epoch[3] Batch [350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.238705,	
2017-06-15 15:30:59,602 Epoch[3] Batch [360]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.237397,	
2017-06-15 15:31:04,357 Epoch[3] Batch [370]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.235913,	
2017-06-15 15:31:08,935 Epoch[3] Batch [380]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.234537,	
2017-06-15 15:31:13,492 Epoch[3] Batch [390]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.234711,	
2017-06-15 15:31:18,088 Epoch[3] Batch [400]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.233450,	
2017-06-15 15:31:22,662 Epoch[3] Batch [410]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.232737,	
2017-06-15 15:31:27,389 Epoch[3] Batch [420]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.231299,	
2017-06-15 15:31:31,906 Epoch[3] Batch [430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.229969,	
2017-06-15 15:31:36,535 Epoch[3] Batch [440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.228925,	
2017-06-15 15:31:41,226 Epoch[3] Batch [450]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.228863,	
2017-06-15 15:31:46,273 Epoch[3] Batch [460]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.228079,	
2017-06-15 15:31:53,865 Epoch[3] Batch [470]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.227704,	
2017-06-15 15:31:59,431 Epoch[3] Batch [480]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.227518,	
2017-06-15 15:32:05,723 Epoch[3] Batch [490]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.226457,	
2017-06-15 15:32:21,088 Epoch[3] Batch [500]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.225666,	
2017-06-15 15:32:28,795 Epoch[3] Batch [510]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.224456,	
2017-06-15 15:32:35,892 Epoch[3] Batch [520]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.223764,	
2017-06-15 15:32:42,775 Epoch[3] Batch [530]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.223685,	
2017-06-15 15:32:51,562 Epoch[3] Batch [540]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.223846,	
2017-06-15 15:33:01,158 Epoch[3] Batch [550]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.223765,	
2017-06-15 15:33:05,703 Epoch[3] Batch [560]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.223194,	
2017-06-15 15:33:10,169 Epoch[3] Batch [570]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.222145,	
2017-06-15 15:33:14,824 Epoch[3] Batch [580]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.221787,	
2017-06-15 15:33:19,327 Epoch[3] Batch [590]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.221553,	
2017-06-15 15:33:23,750 Epoch[3] Batch [600]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.221068,	
2017-06-15 15:33:28,281 Epoch[3] Batch [610]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.220635,	
2017-06-15 15:33:32,817 Epoch[3] Batch [620]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.219901,	
2017-06-15 15:33:37,482 Epoch[3] Batch [630]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.219547,	
2017-06-15 15:33:42,106 Epoch[3] Batch [640]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.218844,	
2017-06-15 15:33:46,737 Epoch[3] Batch [650]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.218509,	
2017-06-15 15:33:51,294 Epoch[3] Batch [660]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.218639,	
2017-06-15 15:33:55,935 Epoch[3] Batch [670]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.217846,	
2017-06-15 15:34:00,515 Epoch[3] Batch [680]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.217340,	
2017-06-15 15:34:05,143 Epoch[3] Batch [690]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.217102,	
2017-06-15 15:34:09,796 Epoch[3] Batch [700]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.216918,	
2017-06-15 15:34:14,475 Epoch[3] Batch [710]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.216135,	
2017-06-15 15:34:19,050 Epoch[3] Batch [720]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.215297,	
2017-06-15 15:34:23,648 Epoch[3] Batch [730]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.215547,	
2017-06-15 15:34:28,314 Epoch[3] Batch [740]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.215209,	
2017-06-15 15:34:32,861 Epoch[3] Batch [750]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.214761,	
2017-06-15 15:34:37,501 Epoch[3] Batch [760]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.214763,	
2017-06-15 15:34:42,058 Epoch[3] Batch [770]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.214411,	
2017-06-15 15:34:46,674 Epoch[3] Batch [780]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.213929,	
2017-06-15 15:34:51,183 Epoch[3] Batch [790]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.213458,	
2017-06-15 15:34:55,754 Epoch[3] Batch [800]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.212748,	
2017-06-15 15:35:00,464 Epoch[3] Batch [810]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.212551,	
2017-06-15 15:35:04,946 Epoch[3] Batch [820]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.212233,	
2017-06-15 15:35:09,567 Epoch[3] Batch [830]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.211752,	
2017-06-15 15:35:14,360 Epoch[3] Batch [840]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.211263,	
2017-06-15 15:35:18,977 Epoch[3] Batch [850]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.211229,	
2017-06-15 15:35:23,911 Epoch[3] Batch [860]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.210886,	
2017-06-15 15:35:28,462 Epoch[3] Batch [870]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.210418,	
2017-06-15 15:35:33,760 Epoch[3] Batch [880]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.210184,	
2017-06-15 15:35:40,212 Epoch[3] Batch [890]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.210411,	
2017-06-15 15:35:48,771 Epoch[3] Batch [900]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.210055,	
2017-06-15 15:35:57,661 Epoch[3] Batch [910]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.210024,	
2017-06-15 15:36:03,357 Epoch[3] Batch [920]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.209696,	
2017-06-15 15:36:07,846 Epoch[3] Batch [930]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.209354,	
2017-06-15 15:36:12,353 Epoch[3] Batch [940]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.209052,	
2017-06-15 15:36:16,929 Epoch[3] Batch [950]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.208647,	
2017-06-15 15:36:21,439 Epoch[3] Batch [960]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.208179,	
2017-06-15 15:36:26,061 Epoch[3] Batch [970]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.207896,	
2017-06-15 15:36:30,598 Epoch[3] Batch [980]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.208159,	
2017-06-15 15:36:35,236 Epoch[3] Batch [990]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.207751,	
2017-06-15 15:36:39,793 Epoch[3] Batch [1000]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.207434,	
2017-06-15 15:36:44,303 Epoch[3] Batch [1010]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.207117,	
2017-06-15 15:36:48,822 Epoch[3] Batch [1020]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.206676,	
2017-06-15 15:36:53,381 Epoch[3] Batch [1030]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.206646,	
2017-06-15 15:36:57,996 Epoch[3] Batch [1040]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.206358,	
2017-06-15 15:37:02,532 Epoch[3] Batch [1050]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.205949,	
2017-06-15 15:37:07,177 Epoch[3] Batch [1060]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.205521,	
2017-06-15 15:37:11,923 Epoch[3] Batch [1070]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.205198,	
2017-06-15 15:37:17,265 Epoch[3] Batch [1080]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.204966,	
2017-06-15 15:37:24,033 Epoch[3] Batch [1090]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.204551,	
2017-06-15 15:37:30,829 Epoch[3] Batch [1100]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.204326,	
2017-06-15 15:37:37,829 Epoch[3] Batch [1110]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.204168,	
2017-06-15 15:37:47,054 Epoch[3] Batch [1120]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.203771,	
2017-06-15 15:37:53,109 Epoch[3] Batch [1130]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.203675,	
2017-06-15 15:37:57,635 Epoch[3] Batch [1140]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.203243,	
2017-06-15 15:38:02,259 Epoch[3] Batch [1150]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.203214,	
2017-06-15 15:38:06,931 Epoch[3] Batch [1160]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.203064,	
2017-06-15 15:38:11,396 Epoch[3] Batch [1170]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.202656,	
2017-06-15 15:38:16,011 Epoch[3] Batch [1180]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.202311,	
2017-06-15 15:38:20,686 Epoch[3] Batch [1190]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.202240,	
2017-06-15 15:38:25,314 Epoch[3] Batch [1200]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.202145,	
2017-06-15 15:38:29,894 Epoch[3] Batch [1210]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.202281,	
2017-06-15 15:38:34,481 Epoch[3] Batch [1220]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.202136,	
2017-06-15 15:38:38,996 Epoch[3] Batch [1230]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.201926,	
2017-06-15 15:38:43,590 Epoch[3] Batch [1240]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.201952,	
2017-06-15 15:38:48,076 Epoch[3] Batch [1250]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.201794,	
2017-06-15 15:38:52,747 Epoch[3] Batch [1260]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.202075,	
2017-06-15 15:38:57,314 Epoch[3] Batch [1270]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.202130,	
2017-06-15 15:39:01,956 Epoch[3] Batch [1280]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.202223,	
2017-06-15 15:39:06,601 Epoch[3] Batch [1290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.202379,	
2017-06-15 15:39:11,135 Epoch[3] Batch [1300]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.202293,	
2017-06-15 15:39:15,727 Epoch[3] Batch [1310]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.202115,	
2017-06-15 15:39:20,286 Epoch[3] Batch [1320]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.201962,	
2017-06-15 15:39:24,956 Epoch[3] Batch [1330]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.201931,	
2017-06-15 15:39:29,539 Epoch[3] Batch [1340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.202055,	
2017-06-15 15:39:34,101 Epoch[3] Batch [1350]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.201791,	
2017-06-15 15:39:38,610 Epoch[3] Batch [1360]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.201657,	
2017-06-15 15:39:43,191 Epoch[3] Batch [1370]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.201477,	
2017-06-15 15:39:47,742 Epoch[3] Batch [1380]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.201217,	
2017-06-15 15:39:52,315 Epoch[3] Batch [1390]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.200968,	
2017-06-15 15:39:56,936 Epoch[3] Batch [1400]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.200669,	
2017-06-15 15:40:01,514 Epoch[3] Batch [1410]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.200623,	
2017-06-15 15:40:06,020 Epoch[3] Batch [1420]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.200448,	
2017-06-15 15:40:10,641 Epoch[3] Batch [1430]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.200127,	
2017-06-15 15:40:15,165 Epoch[3] Batch [1440]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.199892,	
2017-06-15 15:40:19,743 Epoch[3] Batch [1450]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.199698,	
2017-06-15 15:40:24,355 Epoch[3] Batch [1460]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.199624,	
2017-06-15 15:40:28,913 Epoch[3] Batch [1470]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.199379,	
2017-06-15 15:40:33,447 Epoch[3] Batch [1480]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.199253,	
2017-06-15 15:40:36,226 Epoch[3] Train-FCNLogLoss=0.199211
2017-06-15 15:40:36,226 Epoch[3] Time cost=745.607
2017-06-15 15:40:36,988 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0004.params"
2017-06-15 15:40:38,783 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0004.states"
2017-06-15 15:40:44,101 Epoch[4] Batch [10]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.164484,	
2017-06-15 15:40:48,581 Epoch[4] Batch [20]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.155187,	
2017-06-15 15:40:53,068 Epoch[4] Batch [30]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.164059,	
2017-06-15 15:40:57,652 Epoch[4] Batch [40]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.160131,	
2017-06-15 15:41:02,187 Epoch[4] Batch [50]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.161675,	
2017-06-15 15:41:06,817 Epoch[4] Batch [60]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.166344,	
2017-06-15 15:41:11,304 Epoch[4] Batch [70]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.165212,	
2017-06-15 15:41:15,855 Epoch[4] Batch [80]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.168757,	
2017-06-15 15:41:20,415 Epoch[4] Batch [90]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.171140,	
2017-06-15 15:41:25,001 Epoch[4] Batch [100]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.170464,	
2017-06-15 15:41:29,491 Epoch[4] Batch [110]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.169531,	
2017-06-15 15:41:34,141 Epoch[4] Batch [120]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.169235,	
2017-06-15 15:41:38,606 Epoch[4] Batch [130]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.169386,	
2017-06-15 15:41:43,154 Epoch[4] Batch [140]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.168765,	
2017-06-15 15:41:47,738 Epoch[4] Batch [150]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.167494,	
2017-06-15 15:41:52,334 Epoch[4] Batch [160]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.167313,	
2017-06-15 15:41:56,814 Epoch[4] Batch [170]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.166593,	
2017-06-15 15:42:01,400 Epoch[4] Batch [180]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.164954,	
2017-06-15 15:42:06,233 Epoch[4] Batch [190]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.164636,	
2017-06-15 15:42:10,889 Epoch[4] Batch [200]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.165453,	
2017-06-15 15:42:15,610 Epoch[4] Batch [210]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.166019,	
2017-06-15 15:42:20,173 Epoch[4] Batch [220]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.166457,	
2017-06-15 15:42:24,745 Epoch[4] Batch [230]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.167133,	
2017-06-15 15:42:29,378 Epoch[4] Batch [240]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.167155,	
2017-06-15 15:42:33,912 Epoch[4] Batch [250]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.167449,	
2017-06-15 15:42:38,488 Epoch[4] Batch [260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.167182,	
2017-06-15 15:42:43,037 Epoch[4] Batch [270]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.167269,	
2017-06-15 15:42:47,612 Epoch[4] Batch [280]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.167707,	
2017-06-15 15:42:52,304 Epoch[4] Batch [290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.167224,	
2017-06-15 15:42:56,880 Epoch[4] Batch [300]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.167827,	
2017-06-15 15:43:01,450 Epoch[4] Batch [310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.167516,	
2017-06-15 15:43:06,270 Epoch[4] Batch [320]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.167310,	
2017-06-15 15:43:10,962 Epoch[4] Batch [330]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.168817,	
2017-06-15 15:43:15,509 Epoch[4] Batch [340]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.170480,	
2017-06-15 15:43:20,056 Epoch[4] Batch [350]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.172483,	
2017-06-15 15:43:24,544 Epoch[4] Batch [360]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.173171,	
2017-06-15 15:43:29,188 Epoch[4] Batch [370]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.173245,	
2017-06-15 15:43:33,836 Epoch[4] Batch [380]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.173751,	
2017-06-15 15:43:38,360 Epoch[4] Batch [390]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.174275,	
2017-06-15 15:43:42,826 Epoch[4] Batch [400]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.176313,	
2017-06-15 15:43:47,400 Epoch[4] Batch [410]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.178731,	
2017-06-15 15:43:51,925 Epoch[4] Batch [420]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.179535,	
2017-06-15 15:43:56,559 Epoch[4] Batch [430]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.179506,	
2017-06-15 15:44:01,211 Epoch[4] Batch [440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.179328,	
2017-06-15 15:44:05,797 Epoch[4] Batch [450]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.180312,	
2017-06-15 15:44:10,643 Epoch[4] Batch [460]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.179586,	
2017-06-15 15:44:15,305 Epoch[4] Batch [470]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.180206,	
2017-06-15 15:44:20,104 Epoch[4] Batch [480]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.179715,	
2017-06-15 15:44:24,909 Epoch[4] Batch [490]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.179508,	
2017-06-15 15:44:30,121 Epoch[4] Batch [500]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.179290,	
2017-06-15 15:44:39,388 Epoch[4] Batch [510]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.178852,	
2017-06-15 15:44:46,429 Epoch[4] Batch [520]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.179397,	
2017-06-15 15:44:54,912 Epoch[4] Batch [530]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.179433,	
2017-06-15 15:45:04,654 Epoch[4] Batch [540]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.179825,	
2017-06-15 15:45:10,982 Epoch[4] Batch [550]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.179675,	
2017-06-15 15:45:15,529 Epoch[4] Batch [560]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.179455,	
2017-06-15 15:45:19,939 Epoch[4] Batch [570]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.179197,	
2017-06-15 15:45:24,503 Epoch[4] Batch [580]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.178918,	
2017-06-15 15:45:29,008 Epoch[4] Batch [590]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.178520,	
2017-06-15 15:45:33,670 Epoch[4] Batch [600]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.178308,	
2017-06-15 15:45:38,312 Epoch[4] Batch [610]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.178324,	
2017-06-15 15:45:43,054 Epoch[4] Batch [620]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.177835,	
2017-06-15 15:45:47,566 Epoch[4] Batch [630]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.177632,	
2017-06-15 15:45:52,300 Epoch[4] Batch [640]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.177474,	
2017-06-15 15:45:56,899 Epoch[4] Batch [650]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.177066,	
2017-06-15 15:46:01,414 Epoch[4] Batch [660]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.177285,	
2017-06-15 15:46:06,180 Epoch[4] Batch [670]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.177142,	
2017-06-15 15:46:10,763 Epoch[4] Batch [680]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.176843,	
2017-06-15 15:46:15,415 Epoch[4] Batch [690]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.176580,	
2017-06-15 15:46:20,125 Epoch[4] Batch [700]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.175852,	
2017-06-15 15:46:25,106 Epoch[4] Batch [710]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.175611,	
2017-06-15 15:46:30,446 Epoch[4] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.175524,	
2017-06-15 15:46:36,877 Epoch[4] Batch [730]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.175160,	
2017-06-15 15:46:43,959 Epoch[4] Batch [740]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.175503,	
2017-06-15 15:46:51,336 Epoch[4] Batch [750]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.175115,	
2017-06-15 15:46:56,039 Epoch[4] Batch [760]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.174815,	
2017-06-15 15:47:00,489 Epoch[4] Batch [770]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.175134,	
2017-06-15 15:47:05,053 Epoch[4] Batch [780]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.174807,	
2017-06-15 15:47:09,750 Epoch[4] Batch [790]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.174714,	
2017-06-15 15:47:14,319 Epoch[4] Batch [800]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.174462,	
2017-06-15 15:47:18,875 Epoch[4] Batch [810]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.174060,	
2017-06-15 15:47:23,403 Epoch[4] Batch [820]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.175212,	
2017-06-15 15:47:27,973 Epoch[4] Batch [830]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.175454,	
2017-06-15 15:47:32,550 Epoch[4] Batch [840]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.175924,	
2017-06-15 15:47:37,281 Epoch[4] Batch [850]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.175896,	
2017-06-15 15:47:41,953 Epoch[4] Batch [860]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.175672,	
2017-06-15 15:47:46,591 Epoch[4] Batch [870]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.175772,	
2017-06-15 15:47:51,207 Epoch[4] Batch [880]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.175834,	
2017-06-15 15:47:55,766 Epoch[4] Batch [890]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.175842,	
2017-06-15 15:48:00,372 Epoch[4] Batch [900]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.175654,	
2017-06-15 15:48:04,961 Epoch[4] Batch [910]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.175350,	
2017-06-15 15:48:09,566 Epoch[4] Batch [920]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.174898,	
2017-06-15 15:48:14,206 Epoch[4] Batch [930]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.174707,	
2017-06-15 15:48:18,820 Epoch[4] Batch [940]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.174794,	
2017-06-15 15:48:23,425 Epoch[4] Batch [950]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.174552,	
2017-06-15 15:48:27,964 Epoch[4] Batch [960]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.174518,	
2017-06-15 15:48:32,616 Epoch[4] Batch [970]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.174115,	
2017-06-15 15:48:37,247 Epoch[4] Batch [980]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.174076,	
2017-06-15 15:48:41,845 Epoch[4] Batch [990]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.174006,	
2017-06-15 15:48:46,469 Epoch[4] Batch [1000]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.174021,	
2017-06-15 15:48:51,086 Epoch[4] Batch [1010]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.173956,	
2017-06-15 15:48:55,730 Epoch[4] Batch [1020]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.173681,	
2017-06-15 15:49:00,427 Epoch[4] Batch [1030]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.173718,	
2017-06-15 15:49:05,032 Epoch[4] Batch [1040]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.173575,	
2017-06-15 15:49:09,716 Epoch[4] Batch [1050]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.173339,	
2017-06-15 15:49:14,308 Epoch[4] Batch [1060]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.173139,	
2017-06-15 15:49:19,092 Epoch[4] Batch [1070]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.173355,	
2017-06-15 15:49:23,536 Epoch[4] Batch [1080]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.173428,	
2017-06-15 15:49:28,158 Epoch[4] Batch [1090]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.173335,	
2017-06-15 15:49:32,763 Epoch[4] Batch [1100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.173454,	
2017-06-15 15:49:37,431 Epoch[4] Batch [1110]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.173361,	
2017-06-15 15:49:42,015 Epoch[4] Batch [1120]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.173194,	
2017-06-15 15:49:46,620 Epoch[4] Batch [1130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.173076,	
2017-06-15 15:49:51,281 Epoch[4] Batch [1140]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.172867,	
2017-06-15 15:49:55,792 Epoch[4] Batch [1150]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.172944,	
2017-06-15 15:50:00,496 Epoch[4] Batch [1160]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.172847,	
2017-06-15 15:50:05,162 Epoch[4] Batch [1170]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.173072,	
2017-06-15 15:50:09,785 Epoch[4] Batch [1180]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.173291,	
2017-06-15 15:50:14,234 Epoch[4] Batch [1190]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.173295,	
2017-06-15 15:50:18,781 Epoch[4] Batch [1200]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.173213,	
2017-06-15 15:50:23,346 Epoch[4] Batch [1210]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.173011,	
2017-06-15 15:50:27,902 Epoch[4] Batch [1220]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.172921,	
2017-06-15 15:50:32,522 Epoch[4] Batch [1230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.172528,	
2017-06-15 15:50:37,167 Epoch[4] Batch [1240]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.172516,	
2017-06-15 15:50:41,834 Epoch[4] Batch [1250]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.172316,	
2017-06-15 15:50:46,367 Epoch[4] Batch [1260]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.172403,	
2017-06-15 15:50:50,892 Epoch[4] Batch [1270]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.172448,	
2017-06-15 15:50:55,580 Epoch[4] Batch [1280]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.172426,	
2017-06-15 15:51:00,150 Epoch[4] Batch [1290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.172401,	
2017-06-15 15:51:05,063 Epoch[4] Batch [1300]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.172607,	
2017-06-15 15:51:09,640 Epoch[4] Batch [1310]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.172580,	
2017-06-15 15:51:14,221 Epoch[4] Batch [1320]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.172429,	
2017-06-15 15:51:18,833 Epoch[4] Batch [1330]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.172298,	
2017-06-15 15:51:23,394 Epoch[4] Batch [1340]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.172294,	
2017-06-15 15:51:28,025 Epoch[4] Batch [1350]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.172128,	
2017-06-15 15:51:32,598 Epoch[4] Batch [1360]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.172157,	
2017-06-15 15:51:37,226 Epoch[4] Batch [1370]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.172069,	
2017-06-15 15:51:41,858 Epoch[4] Batch [1380]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.171830,	
2017-06-15 15:51:46,648 Epoch[4] Batch [1390]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.171665,	
2017-06-15 15:51:51,360 Epoch[4] Batch [1400]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.171487,	
2017-06-15 15:51:56,097 Epoch[4] Batch [1410]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.171416,	
2017-06-15 15:52:00,665 Epoch[4] Batch [1420]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.171234,	
2017-06-15 15:52:05,670 Epoch[4] Batch [1430]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.171181,	
2017-06-15 15:52:10,128 Epoch[4] Batch [1440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.170914,	
2017-06-15 15:52:14,967 Epoch[4] Batch [1450]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.170832,	
2017-06-15 15:52:19,775 Epoch[4] Batch [1460]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.170806,	
2017-06-15 15:52:24,379 Epoch[4] Batch [1470]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.170728,	
2017-06-15 15:52:29,248 Epoch[4] Batch [1480]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.170741,	
2017-06-15 15:52:31,935 Epoch[4] Train-FCNLogLoss=0.170751
2017-06-15 15:52:31,935 Epoch[4] Time cost=713.151
2017-06-15 15:52:32,680 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0005.params"
2017-06-15 15:52:34,436 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0005.states"
2017-06-15 15:52:39,854 Epoch[5] Batch [10]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.158174,	
2017-06-15 15:52:44,594 Epoch[5] Batch [20]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.150454,	
2017-06-15 15:52:49,366 Epoch[5] Batch [30]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.152266,	
2017-06-15 15:52:54,628 Epoch[5] Batch [40]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.148662,	
2017-06-15 15:52:59,718 Epoch[5] Batch [50]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.153600,	
2017-06-15 15:53:04,453 Epoch[5] Batch [60]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.155741,	
2017-06-15 15:53:09,230 Epoch[5] Batch [70]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.154650,	
2017-06-15 15:53:13,892 Epoch[5] Batch [80]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.153742,	
2017-06-15 15:53:18,482 Epoch[5] Batch [90]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.151613,	
2017-06-15 15:53:23,158 Epoch[5] Batch [100]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.152435,	
2017-06-15 15:53:27,791 Epoch[5] Batch [110]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.151062,	
2017-06-15 15:53:32,440 Epoch[5] Batch [120]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.152005,	
2017-06-15 15:53:37,148 Epoch[5] Batch [130]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.150816,	
2017-06-15 15:53:41,739 Epoch[5] Batch [140]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.149292,	
2017-06-15 15:53:46,262 Epoch[5] Batch [150]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.150299,	
2017-06-15 15:53:50,950 Epoch[5] Batch [160]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.149505,	
2017-06-15 15:53:55,541 Epoch[5] Batch [170]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.148712,	
2017-06-15 15:54:00,122 Epoch[5] Batch [180]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.148911,	
2017-06-15 15:54:04,808 Epoch[5] Batch [190]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.148919,	
2017-06-15 15:54:09,608 Epoch[5] Batch [200]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.148368,	
2017-06-15 15:54:14,308 Epoch[5] Batch [210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.148472,	
2017-06-15 15:54:19,048 Epoch[5] Batch [220]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.147834,	
2017-06-15 15:54:23,714 Epoch[5] Batch [230]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.147741,	
2017-06-15 15:54:28,466 Epoch[5] Batch [240]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.147807,	
2017-06-15 15:54:33,158 Epoch[5] Batch [250]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.147487,	
2017-06-15 15:54:38,047 Epoch[5] Batch [260]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.147514,	
2017-06-15 15:54:43,348 Epoch[5] Batch [270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.147169,	
2017-06-15 15:54:48,303 Epoch[5] Batch [280]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.147385,	
2017-06-15 15:54:53,278 Epoch[5] Batch [290]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.147388,	
2017-06-15 15:54:57,991 Epoch[5] Batch [300]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.147562,	
2017-06-15 15:55:02,707 Epoch[5] Batch [310]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.147393,	
2017-06-15 15:55:07,526 Epoch[5] Batch [320]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.148053,	
2017-06-15 15:55:12,277 Epoch[5] Batch [330]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.149187,	
2017-06-15 15:55:16,944 Epoch[5] Batch [340]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.148958,	
2017-06-15 15:55:21,535 Epoch[5] Batch [350]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.149314,	
2017-06-15 15:55:26,222 Epoch[5] Batch [360]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.149177,	
2017-06-15 15:55:30,966 Epoch[5] Batch [370]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.149143,	
2017-06-15 15:55:35,606 Epoch[5] Batch [380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.149147,	
2017-06-15 15:55:40,408 Epoch[5] Batch [390]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.149444,	
2017-06-15 15:55:45,133 Epoch[5] Batch [400]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.149944,	
2017-06-15 15:55:50,329 Epoch[5] Batch [410]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.150061,	
2017-06-15 15:55:54,993 Epoch[5] Batch [420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.150555,	
2017-06-15 15:55:59,514 Epoch[5] Batch [430]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.150584,	
2017-06-15 15:56:04,509 Epoch[5] Batch [440]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.150681,	
2017-06-15 15:56:09,117 Epoch[5] Batch [450]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.150627,	
2017-06-15 15:56:13,783 Epoch[5] Batch [460]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.150698,	
2017-06-15 15:56:18,407 Epoch[5] Batch [470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.150286,	
2017-06-15 15:56:23,103 Epoch[5] Batch [480]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.150039,	
2017-06-15 15:56:27,962 Epoch[5] Batch [490]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.149740,	
2017-06-15 15:56:32,795 Epoch[5] Batch [500]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.149750,	
2017-06-15 15:56:37,502 Epoch[5] Batch [510]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.149410,	
2017-06-15 15:56:42,405 Epoch[5] Batch [520]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.149420,	
2017-06-15 15:56:47,507 Epoch[5] Batch [530]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.149530,	
2017-06-15 15:56:52,598 Epoch[5] Batch [540]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.149750,	
2017-06-15 15:56:57,172 Epoch[5] Batch [550]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.150213,	
2017-06-15 15:57:02,323 Epoch[5] Batch [560]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.150085,	
2017-06-15 15:57:06,988 Epoch[5] Batch [570]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.149985,	
2017-06-15 15:57:11,683 Epoch[5] Batch [580]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.149888,	
2017-06-15 15:57:16,607 Epoch[5] Batch [590]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.149775,	
2017-06-15 15:57:21,240 Epoch[5] Batch [600]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.149622,	
2017-06-15 15:57:26,047 Epoch[5] Batch [610]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.149689,	
2017-06-15 15:57:30,866 Epoch[5] Batch [620]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.149846,	
2017-06-15 15:57:35,460 Epoch[5] Batch [630]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.150271,	
2017-06-15 15:57:40,240 Epoch[5] Batch [640]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.150955,	
2017-06-15 15:57:44,846 Epoch[5] Batch [650]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.151397,	
2017-06-15 15:57:49,539 Epoch[5] Batch [660]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.151399,	
2017-06-15 15:57:54,234 Epoch[5] Batch [670]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.151983,	
2017-06-15 15:57:58,890 Epoch[5] Batch [680]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.152554,	
2017-06-15 15:58:04,162 Epoch[5] Batch [690]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.153184,	
2017-06-15 15:58:08,808 Epoch[5] Batch [700]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.153261,	
2017-06-15 15:58:13,443 Epoch[5] Batch [710]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.153519,	
2017-06-15 15:58:18,108 Epoch[5] Batch [720]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.154050,	
2017-06-15 15:58:22,741 Epoch[5] Batch [730]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.154027,	
2017-06-15 15:58:27,441 Epoch[5] Batch [740]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.154025,	
2017-06-15 15:58:32,141 Epoch[5] Batch [750]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.153989,	
2017-06-15 15:58:36,932 Epoch[5] Batch [760]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.153877,	
2017-06-15 15:58:41,550 Epoch[5] Batch [770]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.154047,	
2017-06-15 15:58:46,289 Epoch[5] Batch [780]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.154194,	
2017-06-15 15:58:50,822 Epoch[5] Batch [790]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.154082,	
2017-06-15 15:58:55,598 Epoch[5] Batch [800]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.153907,	
2017-06-15 15:59:00,173 Epoch[5] Batch [810]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.153917,	
2017-06-15 15:59:04,783 Epoch[5] Batch [820]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.154074,	
2017-06-15 15:59:09,583 Epoch[5] Batch [830]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.154293,	
2017-06-15 15:59:14,307 Epoch[5] Batch [840]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.154453,	
2017-06-15 15:59:18,933 Epoch[5] Batch [850]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.154689,	
2017-06-15 15:59:23,496 Epoch[5] Batch [860]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.154928,	
2017-06-15 15:59:28,017 Epoch[5] Batch [870]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.154942,	
2017-06-15 15:59:32,626 Epoch[5] Batch [880]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.154770,	
2017-06-15 15:59:37,281 Epoch[5] Batch [890]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.154700,	
2017-06-15 15:59:41,836 Epoch[5] Batch [900]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.154588,	
2017-06-15 15:59:46,501 Epoch[5] Batch [910]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.154564,	
2017-06-15 15:59:51,150 Epoch[5] Batch [920]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.154674,	
2017-06-15 15:59:55,708 Epoch[5] Batch [930]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.154642,	
2017-06-15 16:00:00,235 Epoch[5] Batch [940]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.154589,	
2017-06-15 16:00:04,780 Epoch[5] Batch [950]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.154644,	
2017-06-15 16:00:09,338 Epoch[5] Batch [960]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.154421,	
2017-06-15 16:00:14,045 Epoch[5] Batch [970]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.154367,	
2017-06-15 16:00:18,571 Epoch[5] Batch [980]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.154289,	
2017-06-15 16:00:23,208 Epoch[5] Batch [990]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.154118,	
2017-06-15 16:00:27,735 Epoch[5] Batch [1000]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.154009,	
2017-06-15 16:00:32,426 Epoch[5] Batch [1010]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.153895,	
2017-06-15 16:00:36,927 Epoch[5] Batch [1020]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.153913,	
2017-06-15 16:00:41,597 Epoch[5] Batch [1030]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.153751,	
2017-06-15 16:00:46,203 Epoch[5] Batch [1040]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.153846,	
2017-06-15 16:00:50,693 Epoch[5] Batch [1050]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.153740,	
2017-06-15 16:00:55,209 Epoch[5] Batch [1060]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.153749,	
2017-06-15 16:00:59,756 Epoch[5] Batch [1070]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.153702,	
2017-06-15 16:01:04,319 Epoch[5] Batch [1080]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.153698,	
2017-06-15 16:01:08,819 Epoch[5] Batch [1090]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.153655,	
2017-06-15 16:01:13,473 Epoch[5] Batch [1100]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.153578,	
2017-06-15 16:01:17,915 Epoch[5] Batch [1110]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.153945,	
2017-06-15 16:01:22,497 Epoch[5] Batch [1120]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.154228,	
2017-06-15 16:01:27,164 Epoch[5] Batch [1130]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.154086,	
2017-06-15 16:01:31,646 Epoch[5] Batch [1140]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.154036,	
2017-06-15 16:01:36,265 Epoch[5] Batch [1150]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.154468,	
2017-06-15 16:01:40,767 Epoch[5] Batch [1160]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.154391,	
2017-06-15 16:01:45,347 Epoch[5] Batch [1170]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.154372,	
2017-06-15 16:01:49,870 Epoch[5] Batch [1180]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.154475,	
2017-06-15 16:01:54,447 Epoch[5] Batch [1190]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.154443,	
2017-06-15 16:01:59,009 Epoch[5] Batch [1200]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.154461,	
2017-06-15 16:02:03,681 Epoch[5] Batch [1210]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.154560,	
2017-06-15 16:02:08,245 Epoch[5] Batch [1220]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.154520,	
2017-06-15 16:02:12,837 Epoch[5] Batch [1230]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.154385,	
2017-06-15 16:02:17,687 Epoch[5] Batch [1240]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.154345,	
2017-06-15 16:02:22,286 Epoch[5] Batch [1250]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.154594,	
2017-06-15 16:02:26,871 Epoch[5] Batch [1260]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.155410,	
2017-06-15 16:02:31,502 Epoch[5] Batch [1270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.155568,	
2017-06-15 16:02:36,045 Epoch[5] Batch [1280]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.155718,	
2017-06-15 16:02:40,747 Epoch[5] Batch [1290]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.155675,	
2017-06-15 16:02:45,343 Epoch[5] Batch [1300]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.155687,	
2017-06-15 16:02:50,221 Epoch[5] Batch [1310]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.155744,	
2017-06-15 16:02:55,038 Epoch[5] Batch [1320]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.155803,	
2017-06-15 16:02:59,823 Epoch[5] Batch [1330]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.155727,	
2017-06-15 16:03:04,412 Epoch[5] Batch [1340]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.155717,	
2017-06-15 16:03:08,987 Epoch[5] Batch [1350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.155656,	
2017-06-15 16:03:13,620 Epoch[5] Batch [1360]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.155884,	
2017-06-15 16:03:18,177 Epoch[5] Batch [1370]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.156188,	
2017-06-15 16:03:22,890 Epoch[5] Batch [1380]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.156353,	
2017-06-15 16:03:27,390 Epoch[5] Batch [1390]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.156626,	
2017-06-15 16:03:32,109 Epoch[5] Batch [1400]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.156886,	
2017-06-15 16:03:36,700 Epoch[5] Batch [1410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.156909,	
2017-06-15 16:03:41,218 Epoch[5] Batch [1420]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.156872,	
2017-06-15 16:03:45,809 Epoch[5] Batch [1430]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.156818,	
2017-06-15 16:03:50,341 Epoch[5] Batch [1440]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.156844,	
2017-06-15 16:03:55,069 Epoch[5] Batch [1450]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.156921,	
2017-06-15 16:03:59,572 Epoch[5] Batch [1460]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.156887,	
2017-06-15 16:04:04,171 Epoch[5] Batch [1470]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.156817,	
2017-06-15 16:04:08,776 Epoch[5] Batch [1480]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.156803,	
2017-06-15 16:04:11,504 Epoch[5] Train-FCNLogLoss=0.156746
2017-06-15 16:04:11,504 Epoch[5] Time cost=697.068
2017-06-15 16:04:12,271 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0006.params"
2017-06-15 16:04:14,154 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0006.states"
2017-06-15 16:04:19,553 Epoch[6] Batch [10]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.145396,	
2017-06-15 16:04:24,093 Epoch[6] Batch [20]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.144284,	
2017-06-15 16:04:28,480 Epoch[6] Batch [30]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.149535,	
2017-06-15 16:04:33,048 Epoch[6] Batch [40]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.153697,	
2017-06-15 16:04:37,709 Epoch[6] Batch [50]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.153470,	
2017-06-15 16:04:42,329 Epoch[6] Batch [60]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.156554,	
2017-06-15 16:04:46,926 Epoch[6] Batch [70]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.155222,	
2017-06-15 16:04:51,487 Epoch[6] Batch [80]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.152517,	
2017-06-15 16:04:56,122 Epoch[6] Batch [90]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.151481,	
2017-06-15 16:05:00,680 Epoch[6] Batch [100]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.149591,	
2017-06-15 16:05:05,225 Epoch[6] Batch [110]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.148053,	
2017-06-15 16:05:09,829 Epoch[6] Batch [120]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.148902,	
2017-06-15 16:05:14,339 Epoch[6] Batch [130]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.149280,	
2017-06-15 16:05:18,950 Epoch[6] Batch [140]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.148579,	
2017-06-15 16:05:23,461 Epoch[6] Batch [150]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.149528,	
2017-06-15 16:05:28,025 Epoch[6] Batch [160]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.148264,	
2017-06-15 16:05:32,601 Epoch[6] Batch [170]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.148808,	
2017-06-15 16:05:37,193 Epoch[6] Batch [180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.148472,	
2017-06-15 16:05:41,774 Epoch[6] Batch [190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.148816,	
2017-06-15 16:05:46,374 Epoch[6] Batch [200]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.148277,	
2017-06-15 16:05:50,917 Epoch[6] Batch [210]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.148557,	
2017-06-15 16:05:55,532 Epoch[6] Batch [220]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.148394,	
2017-06-15 16:06:00,077 Epoch[6] Batch [230]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.148776,	
2017-06-15 16:06:04,641 Epoch[6] Batch [240]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.149004,	
2017-06-15 16:06:09,526 Epoch[6] Batch [250]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.148982,	
2017-06-15 16:06:14,089 Epoch[6] Batch [260]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.148817,	
2017-06-15 16:06:18,759 Epoch[6] Batch [270]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.149557,	
2017-06-15 16:06:23,273 Epoch[6] Batch [280]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.149277,	
2017-06-15 16:06:27,775 Epoch[6] Batch [290]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.149014,	
2017-06-15 16:06:32,390 Epoch[6] Batch [300]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.148137,	
2017-06-15 16:06:36,961 Epoch[6] Batch [310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.147759,	
2017-06-15 16:06:41,567 Epoch[6] Batch [320]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.147886,	
2017-06-15 16:06:46,086 Epoch[6] Batch [330]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.148204,	
2017-06-15 16:06:50,676 Epoch[6] Batch [340]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.147937,	
2017-06-15 16:06:55,381 Epoch[6] Batch [350]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.148556,	
2017-06-15 16:07:00,010 Epoch[6] Batch [360]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.148802,	
2017-06-15 16:07:04,440 Epoch[6] Batch [370]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.148486,	
2017-06-15 16:07:09,122 Epoch[6] Batch [380]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.148548,	
2017-06-15 16:07:13,732 Epoch[6] Batch [390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.148494,	
2017-06-15 16:07:18,237 Epoch[6] Batch [400]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.148933,	
2017-06-15 16:07:22,988 Epoch[6] Batch [410]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.149588,	
2017-06-15 16:07:27,606 Epoch[6] Batch [420]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.149564,	
2017-06-15 16:07:32,309 Epoch[6] Batch [430]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.149323,	
2017-06-15 16:07:36,975 Epoch[6] Batch [440]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.149188,	
2017-06-15 16:07:42,102 Epoch[6] Batch [450]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.149201,	
2017-06-15 16:07:49,880 Epoch[6] Batch [460]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.149304,	
2017-06-15 16:07:58,047 Epoch[6] Batch [470]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.149497,	
2017-06-15 16:08:06,487 Epoch[6] Batch [480]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.149374,	
2017-06-15 16:08:15,982 Epoch[6] Batch [490]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.149198,	
2017-06-15 16:08:25,437 Epoch[6] Batch [500]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.149420,	
2017-06-15 16:08:31,733 Epoch[6] Batch [510]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.149510,	
2017-06-15 16:08:41,977 Epoch[6] Batch [520]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.149240,	
2017-06-15 16:08:51,880 Epoch[6] Batch [530]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.149252,	
2017-06-15 16:08:57,567 Epoch[6] Batch [540]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.149167,	
2017-06-15 16:09:01,963 Epoch[6] Batch [550]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.149008,	
2017-06-15 16:09:06,425 Epoch[6] Batch [560]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.149908,	
2017-06-15 16:09:10,998 Epoch[6] Batch [570]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.149992,	
2017-06-15 16:09:15,529 Epoch[6] Batch [580]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.150319,	
2017-06-15 16:09:20,020 Epoch[6] Batch [590]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.150732,	
2017-06-15 16:09:24,630 Epoch[6] Batch [600]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.150671,	
2017-06-15 16:09:29,233 Epoch[6] Batch [610]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.151227,	
2017-06-15 16:09:33,856 Epoch[6] Batch [620]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.151249,	
2017-06-15 16:09:38,483 Epoch[6] Batch [630]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.151417,	
2017-06-15 16:09:43,113 Epoch[6] Batch [640]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.151339,	
2017-06-15 16:09:47,805 Epoch[6] Batch [650]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.151284,	
2017-06-15 16:09:52,438 Epoch[6] Batch [660]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.151201,	
2017-06-15 16:09:57,118 Epoch[6] Batch [670]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.151023,	
2017-06-15 16:10:01,761 Epoch[6] Batch [680]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.150994,	
2017-06-15 16:10:06,364 Epoch[6] Batch [690]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.151227,	
2017-06-15 16:10:10,996 Epoch[6] Batch [700]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.151503,	
2017-06-15 16:10:15,687 Epoch[6] Batch [710]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.151946,	
2017-06-15 16:10:20,292 Epoch[6] Batch [720]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.152268,	
2017-06-15 16:10:24,915 Epoch[6] Batch [730]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.152253,	
2017-06-15 16:10:29,597 Epoch[6] Batch [740]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.152268,	
2017-06-15 16:10:34,253 Epoch[6] Batch [750]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.152224,	
2017-06-15 16:10:38,920 Epoch[6] Batch [760]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.152448,	
2017-06-15 16:10:43,560 Epoch[6] Batch [770]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.152223,	
2017-06-15 16:10:48,217 Epoch[6] Batch [780]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.152006,	
2017-06-15 16:10:52,857 Epoch[6] Batch [790]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.151924,	
2017-06-15 16:10:57,511 Epoch[6] Batch [800]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.152135,	
2017-06-15 16:11:02,278 Epoch[6] Batch [810]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.152443,	
2017-06-15 16:11:06,957 Epoch[6] Batch [820]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.152528,	
2017-06-15 16:11:11,669 Epoch[6] Batch [830]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.152620,	
2017-06-15 16:11:16,418 Epoch[6] Batch [840]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.152402,	
2017-06-15 16:11:21,060 Epoch[6] Batch [850]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.152285,	
2017-06-15 16:11:25,671 Epoch[6] Batch [860]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.152335,	
2017-06-15 16:11:30,320 Epoch[6] Batch [870]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.152300,	
2017-06-15 16:11:35,366 Epoch[6] Batch [880]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.152325,	
2017-06-15 16:11:41,677 Epoch[6] Batch [890]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.152079,	
2017-06-15 16:11:48,791 Epoch[6] Batch [900]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.152207,	
2017-06-15 16:11:55,549 Epoch[6] Batch [910]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.152052,	
2017-06-15 16:12:04,269 Epoch[6] Batch [920]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.151855,	
2017-06-15 16:12:08,986 Epoch[6] Batch [930]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.151551,	
2017-06-15 16:12:13,602 Epoch[6] Batch [940]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.151291,	
2017-06-15 16:12:18,231 Epoch[6] Batch [950]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.151277,	
2017-06-15 16:12:22,805 Epoch[6] Batch [960]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.151132,	
2017-06-15 16:12:27,436 Epoch[6] Batch [970]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.151009,	
2017-06-15 16:12:32,083 Epoch[6] Batch [980]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.150819,	
2017-06-15 16:12:36,719 Epoch[6] Batch [990]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.150867,	
2017-06-15 16:12:41,300 Epoch[6] Batch [1000]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.150841,	
2017-06-15 16:12:46,025 Epoch[6] Batch [1010]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.150900,	
2017-06-15 16:12:50,618 Epoch[6] Batch [1020]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.150935,	
2017-06-15 16:12:55,224 Epoch[6] Batch [1030]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.150822,	
2017-06-15 16:12:59,858 Epoch[6] Batch [1040]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.150766,	
2017-06-15 16:13:04,495 Epoch[6] Batch [1050]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.150898,	
2017-06-15 16:13:09,211 Epoch[6] Batch [1060]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.150870,	
2017-06-15 16:13:13,835 Epoch[6] Batch [1070]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.150757,	
2017-06-15 16:13:18,498 Epoch[6] Batch [1080]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.150636,	
2017-06-15 16:13:23,112 Epoch[6] Batch [1090]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.150467,	
2017-06-15 16:13:27,713 Epoch[6] Batch [1100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.150413,	
2017-06-15 16:13:32,382 Epoch[6] Batch [1110]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.150453,	
2017-06-15 16:13:36,995 Epoch[6] Batch [1120]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.150380,	
2017-06-15 16:13:41,691 Epoch[6] Batch [1130]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.150244,	
2017-06-15 16:13:46,382 Epoch[6] Batch [1140]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.150275,	
2017-06-15 16:13:51,003 Epoch[6] Batch [1150]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.150309,	
2017-06-15 16:13:55,597 Epoch[6] Batch [1160]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.150274,	
2017-06-15 16:14:00,204 Epoch[6] Batch [1170]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.150200,	
2017-06-15 16:14:04,844 Epoch[6] Batch [1180]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.150063,	
2017-06-15 16:14:09,522 Epoch[6] Batch [1190]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.149824,	
2017-06-15 16:14:14,134 Epoch[6] Batch [1200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.149781,	
2017-06-15 16:14:18,789 Epoch[6] Batch [1210]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.149674,	
2017-06-15 16:14:23,416 Epoch[6] Batch [1220]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.149656,	
2017-06-15 16:14:28,059 Epoch[6] Batch [1230]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.149611,	
2017-06-15 16:14:32,649 Epoch[6] Batch [1240]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.149627,	
2017-06-15 16:14:37,347 Epoch[6] Batch [1250]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.149556,	
2017-06-15 16:14:42,008 Epoch[6] Batch [1260]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.149413,	
2017-06-15 16:14:46,769 Epoch[6] Batch [1270]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.149282,	
2017-06-15 16:14:51,400 Epoch[6] Batch [1280]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.149081,	
2017-06-15 16:14:56,106 Epoch[6] Batch [1290]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.148899,	
2017-06-15 16:15:00,716 Epoch[6] Batch [1300]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.148793,	
2017-06-15 16:15:05,373 Epoch[6] Batch [1310]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.148534,	
2017-06-15 16:15:10,017 Epoch[6] Batch [1320]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.148524,	
2017-06-15 16:15:14,642 Epoch[6] Batch [1330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.148454,	
2017-06-15 16:15:19,273 Epoch[6] Batch [1340]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.148388,	
2017-06-15 16:15:23,932 Epoch[6] Batch [1350]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.148264,	
2017-06-15 16:15:28,620 Epoch[6] Batch [1360]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.148326,	
2017-06-15 16:15:33,220 Epoch[6] Batch [1370]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.148410,	
2017-06-15 16:15:37,811 Epoch[6] Batch [1380]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.148510,	
2017-06-15 16:15:42,412 Epoch[6] Batch [1390]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.148499,	
2017-06-15 16:15:47,043 Epoch[6] Batch [1400]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.148425,	
2017-06-15 16:15:51,670 Epoch[6] Batch [1410]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.148418,	
2017-06-15 16:15:56,264 Epoch[6] Batch [1420]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.148522,	
2017-06-15 16:16:00,945 Epoch[6] Batch [1430]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.148516,	
2017-06-15 16:16:05,550 Epoch[6] Batch [1440]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.148421,	
2017-06-15 16:16:10,212 Epoch[6] Batch [1450]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.148558,	
2017-06-15 16:16:14,820 Epoch[6] Batch [1460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.148645,	
2017-06-15 16:16:19,448 Epoch[6] Batch [1470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.148679,	
2017-06-15 16:16:24,096 Epoch[6] Batch [1480]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.148617,	
2017-06-15 16:16:26,777 Epoch[6] Train-FCNLogLoss=0.148627
2017-06-15 16:16:26,778 Epoch[6] Time cost=732.623
2017-06-15 16:16:27,737 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0007.params"
2017-06-15 16:16:29,632 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0007.states"
2017-06-15 16:16:34,900 Epoch[7] Batch [10]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.147838,	
2017-06-15 16:16:39,397 Epoch[7] Batch [20]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.142724,	
2017-06-15 16:16:43,918 Epoch[7] Batch [30]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.145629,	
2017-06-15 16:16:48,495 Epoch[7] Batch [40]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.146279,	
2017-06-15 16:16:53,099 Epoch[7] Batch [50]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.141402,	
2017-06-15 16:16:57,844 Epoch[7] Batch [60]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.144797,	
2017-06-15 16:17:02,398 Epoch[7] Batch [70]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.146137,	
2017-06-15 16:17:06,989 Epoch[7] Batch [80]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.147643,	
2017-06-15 16:17:11,633 Epoch[7] Batch [90]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.146149,	
2017-06-15 16:17:16,139 Epoch[7] Batch [100]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.145480,	
2017-06-15 16:17:20,871 Epoch[7] Batch [110]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.144438,	
2017-06-15 16:17:25,491 Epoch[7] Batch [120]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.142155,	
2017-06-15 16:17:30,087 Epoch[7] Batch [130]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.141744,	
2017-06-15 16:17:34,769 Epoch[7] Batch [140]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.142562,	
2017-06-15 16:17:39,361 Epoch[7] Batch [150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.142999,	
2017-06-15 16:17:43,982 Epoch[7] Batch [160]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.144780,	
2017-06-15 16:17:48,545 Epoch[7] Batch [170]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.144846,	
2017-06-15 16:17:53,229 Epoch[7] Batch [180]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.145337,	
2017-06-15 16:17:57,810 Epoch[7] Batch [190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.144535,	
2017-06-15 16:18:02,524 Epoch[7] Batch [200]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.145065,	
2017-06-15 16:18:07,183 Epoch[7] Batch [210]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.144597,	
2017-06-15 16:18:11,751 Epoch[7] Batch [220]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.145578,	
2017-06-15 16:18:16,371 Epoch[7] Batch [230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.146109,	
2017-06-15 16:18:20,919 Epoch[7] Batch [240]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.146182,	
2017-06-15 16:18:25,518 Epoch[7] Batch [250]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.146229,	
2017-06-15 16:18:30,100 Epoch[7] Batch [260]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.146392,	
2017-06-15 16:18:34,782 Epoch[7] Batch [270]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.145872,	
2017-06-15 16:18:39,568 Epoch[7] Batch [280]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.145337,	
2017-06-15 16:18:44,258 Epoch[7] Batch [290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.146029,	
2017-06-15 16:18:48,767 Epoch[7] Batch [300]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.145653,	
2017-06-15 16:18:53,457 Epoch[7] Batch [310]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.145136,	
2017-06-15 16:18:58,033 Epoch[7] Batch [320]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.144603,	
2017-06-15 16:19:02,626 Epoch[7] Batch [330]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.144078,	
2017-06-15 16:19:07,279 Epoch[7] Batch [340]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.144458,	
2017-06-15 16:19:11,917 Epoch[7] Batch [350]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.144721,	
2017-06-15 16:19:16,564 Epoch[7] Batch [360]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.144992,	
2017-06-15 16:19:21,123 Epoch[7] Batch [370]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.146474,	
2017-06-15 16:19:25,687 Epoch[7] Batch [380]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.146318,	
2017-06-15 16:19:30,365 Epoch[7] Batch [390]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.146278,	
2017-06-15 16:19:34,913 Epoch[7] Batch [400]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.146550,	
2017-06-15 16:19:39,621 Epoch[7] Batch [410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.146281,	
2017-06-15 16:19:44,156 Epoch[7] Batch [420]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.146377,	
2017-06-15 16:19:48,749 Epoch[7] Batch [430]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.146282,	
2017-06-15 16:19:53,412 Epoch[7] Batch [440]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.146498,	
2017-06-15 16:19:58,054 Epoch[7] Batch [450]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.146969,	
2017-06-15 16:20:02,653 Epoch[7] Batch [460]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.146836,	
2017-06-15 16:20:07,246 Epoch[7] Batch [470]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.146917,	
2017-06-15 16:20:11,887 Epoch[7] Batch [480]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.146533,	
2017-06-15 16:20:16,541 Epoch[7] Batch [490]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.146550,	
2017-06-15 16:20:21,102 Epoch[7] Batch [500]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.146951,	
2017-06-15 16:20:25,782 Epoch[7] Batch [510]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.147013,	
2017-06-15 16:20:30,296 Epoch[7] Batch [520]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.147669,	
2017-06-15 16:20:34,864 Epoch[7] Batch [530]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.147538,	
2017-06-15 16:20:39,468 Epoch[7] Batch [540]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.147963,	
2017-06-15 16:20:44,063 Epoch[7] Batch [550]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.147882,	
2017-06-15 16:20:48,610 Epoch[7] Batch [560]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.147876,	
2017-06-15 16:20:53,209 Epoch[7] Batch [570]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.148149,	
2017-06-15 16:20:57,964 Epoch[7] Batch [580]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.148074,	
2017-06-15 16:21:02,886 Epoch[7] Batch [590]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.148419,	
2017-06-15 16:21:07,686 Epoch[7] Batch [600]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.148009,	
2017-06-15 16:21:12,334 Epoch[7] Batch [610]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.147827,	
2017-06-15 16:21:16,943 Epoch[7] Batch [620]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.147774,	
2017-06-15 16:21:21,665 Epoch[7] Batch [630]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.147905,	
2017-06-15 16:21:26,875 Epoch[7] Batch [640]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.147975,	
2017-06-15 16:21:31,751 Epoch[7] Batch [650]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.148102,	
2017-06-15 16:21:36,484 Epoch[7] Batch [660]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.147999,	
2017-06-15 16:21:41,139 Epoch[7] Batch [670]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.147810,	
2017-06-15 16:21:45,719 Epoch[7] Batch [680]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.147490,	
2017-06-15 16:21:50,529 Epoch[7] Batch [690]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.147411,	
2017-06-15 16:21:55,182 Epoch[7] Batch [700]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.147172,	
2017-06-15 16:22:00,013 Epoch[7] Batch [710]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.146763,	
2017-06-15 16:22:04,687 Epoch[7] Batch [720]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.146717,	
2017-06-15 16:22:09,478 Epoch[7] Batch [730]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.146451,	
2017-06-15 16:22:14,375 Epoch[7] Batch [740]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.146621,	
2017-06-15 16:22:19,368 Epoch[7] Batch [750]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.146445,	
2017-06-15 16:22:24,000 Epoch[7] Batch [760]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.146519,	
2017-06-15 16:22:28,706 Epoch[7] Batch [770]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.146615,	
2017-06-15 16:22:33,362 Epoch[7] Batch [780]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.146465,	
2017-06-15 16:22:37,960 Epoch[7] Batch [790]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.146494,	
2017-06-15 16:22:42,640 Epoch[7] Batch [800]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.146447,	
2017-06-15 16:22:47,386 Epoch[7] Batch [810]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.146502,	
2017-06-15 16:22:52,037 Epoch[7] Batch [820]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.146298,	
2017-06-15 16:22:56,959 Epoch[7] Batch [830]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.146138,	
2017-06-15 16:23:01,870 Epoch[7] Batch [840]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.146120,	
2017-06-15 16:23:06,543 Epoch[7] Batch [850]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.145979,	
2017-06-15 16:23:11,259 Epoch[7] Batch [860]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.145856,	
2017-06-15 16:23:15,795 Epoch[7] Batch [870]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.145879,	
2017-06-15 16:23:20,369 Epoch[7] Batch [880]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.145766,	
2017-06-15 16:23:25,057 Epoch[7] Batch [890]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.145633,	
2017-06-15 16:23:29,802 Epoch[7] Batch [900]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.145542,	
2017-06-15 16:23:35,014 Epoch[7] Batch [910]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.145446,	
2017-06-15 16:23:39,899 Epoch[7] Batch [920]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.145178,	
2017-06-15 16:23:44,663 Epoch[7] Batch [930]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.144817,	
2017-06-15 16:23:49,292 Epoch[7] Batch [940]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.144547,	
2017-06-15 16:23:53,922 Epoch[7] Batch [950]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.144602,	
2017-06-15 16:23:58,620 Epoch[7] Batch [960]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.144800,	
2017-06-15 16:24:03,350 Epoch[7] Batch [970]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.144759,	
2017-06-15 16:24:08,129 Epoch[7] Batch [980]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.144671,	
2017-06-15 16:24:12,779 Epoch[7] Batch [990]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.144462,	
2017-06-15 16:24:17,440 Epoch[7] Batch [1000]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.144480,	
2017-06-15 16:24:22,386 Epoch[7] Batch [1010]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.144443,	
2017-06-15 16:24:27,411 Epoch[7] Batch [1020]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.144235,	
2017-06-15 16:24:32,069 Epoch[7] Batch [1030]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.144079,	
2017-06-15 16:24:36,877 Epoch[7] Batch [1040]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.144185,	
2017-06-15 16:24:41,622 Epoch[7] Batch [1050]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.144346,	
2017-06-15 16:24:46,603 Epoch[7] Batch [1060]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.144211,	
2017-06-15 16:24:51,390 Epoch[7] Batch [1070]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.144192,	
2017-06-15 16:24:56,079 Epoch[7] Batch [1080]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.144067,	
2017-06-15 16:25:01,016 Epoch[7] Batch [1090]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.143960,	
2017-06-15 16:25:05,578 Epoch[7] Batch [1100]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.143790,	
2017-06-15 16:25:10,193 Epoch[7] Batch [1110]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.143679,	
2017-06-15 16:25:15,022 Epoch[7] Batch [1120]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.143676,	
2017-06-15 16:25:19,695 Epoch[7] Batch [1130]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.143552,	
2017-06-15 16:25:24,610 Epoch[7] Batch [1140]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.143453,	
2017-06-15 16:25:29,454 Epoch[7] Batch [1150]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.143421,	
2017-06-15 16:25:34,048 Epoch[7] Batch [1160]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.143547,	
2017-06-15 16:25:38,754 Epoch[7] Batch [1170]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.143473,	
2017-06-15 16:25:43,637 Epoch[7] Batch [1180]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.143570,	
2017-06-15 16:25:48,332 Epoch[7] Batch [1190]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.143533,	
2017-06-15 16:25:52,980 Epoch[7] Batch [1200]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.143405,	
2017-06-15 16:25:57,710 Epoch[7] Batch [1210]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.143282,	
2017-06-15 16:26:02,377 Epoch[7] Batch [1220]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.143252,	
2017-06-15 16:26:07,589 Epoch[7] Batch [1230]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.143152,	
2017-06-15 16:26:12,439 Epoch[7] Batch [1240]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.143076,	
2017-06-15 16:26:17,426 Epoch[7] Batch [1250]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.142986,	
2017-06-15 16:26:21,993 Epoch[7] Batch [1260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.142958,	
2017-06-15 16:26:26,545 Epoch[7] Batch [1270]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.142917,	
2017-06-15 16:26:31,556 Epoch[7] Batch [1280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.142842,	
2017-06-15 16:26:36,270 Epoch[7] Batch [1290]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.142740,	
2017-06-15 16:26:41,153 Epoch[7] Batch [1300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.142716,	
2017-06-15 16:26:45,782 Epoch[7] Batch [1310]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.142576,	
2017-06-15 16:26:50,559 Epoch[7] Batch [1320]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.142555,	
2017-06-15 16:26:55,286 Epoch[7] Batch [1330]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.142385,	
2017-06-15 16:27:00,115 Epoch[7] Batch [1340]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.142372,	
2017-06-15 16:27:04,821 Epoch[7] Batch [1350]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.142156,	
2017-06-15 16:27:09,396 Epoch[7] Batch [1360]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.142340,	
2017-06-15 16:27:14,359 Epoch[7] Batch [1370]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.142299,	
2017-06-15 16:27:18,905 Epoch[7] Batch [1380]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.142686,	
2017-06-15 16:27:23,514 Epoch[7] Batch [1390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.142782,	
2017-06-15 16:27:28,224 Epoch[7] Batch [1400]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.142714,	
2017-06-15 16:27:32,939 Epoch[7] Batch [1410]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.142833,	
2017-06-15 16:27:37,826 Epoch[7] Batch [1420]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.142822,	
2017-06-15 16:27:42,735 Epoch[7] Batch [1430]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.142661,	
2017-06-15 16:27:47,463 Epoch[7] Batch [1440]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.142683,	
2017-06-15 16:27:52,101 Epoch[7] Batch [1450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.142602,	
2017-06-15 16:27:56,785 Epoch[7] Batch [1460]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.142505,	
2017-06-15 16:28:01,262 Epoch[7] Batch [1470]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.142637,	
2017-06-15 16:28:05,870 Epoch[7] Batch [1480]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.142677,	
2017-06-15 16:28:08,573 Epoch[7] Train-FCNLogLoss=0.142670
2017-06-15 16:28:08,574 Epoch[7] Time cost=698.941
2017-06-15 16:28:09,333 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0008.params"
2017-06-15 16:28:10,985 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0008.states"
2017-06-15 16:28:16,275 Epoch[8] Batch [10]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.135249,	
2017-06-15 16:28:20,857 Epoch[8] Batch [20]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.133047,	
2017-06-15 16:28:25,469 Epoch[8] Batch [30]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.129502,	
2017-06-15 16:28:30,029 Epoch[8] Batch [40]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.131658,	
2017-06-15 16:28:34,585 Epoch[8] Batch [50]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.133706,	
2017-06-15 16:28:39,098 Epoch[8] Batch [60]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.133230,	
2017-06-15 16:28:43,697 Epoch[8] Batch [70]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.132585,	
2017-06-15 16:28:48,355 Epoch[8] Batch [80]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.134851,	
2017-06-15 16:28:52,959 Epoch[8] Batch [90]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.133186,	
2017-06-15 16:28:57,436 Epoch[8] Batch [100]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.133956,	
2017-06-15 16:29:02,004 Epoch[8] Batch [110]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.133642,	
2017-06-15 16:29:06,631 Epoch[8] Batch [120]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.134040,	
2017-06-15 16:29:11,236 Epoch[8] Batch [130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.134534,	
2017-06-15 16:29:15,835 Epoch[8] Batch [140]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.134071,	
2017-06-15 16:29:20,519 Epoch[8] Batch [150]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.134967,	
2017-06-15 16:29:25,007 Epoch[8] Batch [160]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.136200,	
2017-06-15 16:29:29,623 Epoch[8] Batch [170]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.135714,	
2017-06-15 16:29:34,180 Epoch[8] Batch [180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.136189,	
2017-06-15 16:29:38,792 Epoch[8] Batch [190]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.135394,	
2017-06-15 16:29:43,352 Epoch[8] Batch [200]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.135250,	
2017-06-15 16:29:47,876 Epoch[8] Batch [210]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.135310,	
2017-06-15 16:29:52,501 Epoch[8] Batch [220]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.136811,	
2017-06-15 16:29:57,005 Epoch[8] Batch [230]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.137012,	
2017-06-15 16:30:01,653 Epoch[8] Batch [240]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.137852,	
2017-06-15 16:30:06,159 Epoch[8] Batch [250]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.138314,	
2017-06-15 16:30:10,781 Epoch[8] Batch [260]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.138254,	
2017-06-15 16:30:15,347 Epoch[8] Batch [270]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.138164,	
2017-06-15 16:30:19,879 Epoch[8] Batch [280]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.137971,	
2017-06-15 16:30:24,447 Epoch[8] Batch [290]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.137967,	
2017-06-15 16:30:28,987 Epoch[8] Batch [300]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.137536,	
2017-06-15 16:30:33,556 Epoch[8] Batch [310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.137088,	
2017-06-15 16:30:38,167 Epoch[8] Batch [320]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.136306,	
2017-06-15 16:30:42,804 Epoch[8] Batch [330]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.136381,	
2017-06-15 16:30:47,426 Epoch[8] Batch [340]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.135949,	
2017-06-15 16:30:52,094 Epoch[8] Batch [350]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.135901,	
2017-06-15 16:30:56,690 Epoch[8] Batch [360]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.136267,	
2017-06-15 16:31:01,256 Epoch[8] Batch [370]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.136182,	
2017-06-15 16:31:05,852 Epoch[8] Batch [380]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.135947,	
2017-06-15 16:31:10,364 Epoch[8] Batch [390]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.135446,	
2017-06-15 16:31:15,040 Epoch[8] Batch [400]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.135373,	
2017-06-15 16:31:19,892 Epoch[8] Batch [410]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.135473,	
2017-06-15 16:31:24,391 Epoch[8] Batch [420]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.135215,	
2017-06-15 16:31:29,003 Epoch[8] Batch [430]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.135393,	
2017-06-15 16:31:33,582 Epoch[8] Batch [440]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.135167,	
2017-06-15 16:31:38,093 Epoch[8] Batch [450]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.134848,	
2017-06-15 16:31:42,683 Epoch[8] Batch [460]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.135161,	
2017-06-15 16:31:47,231 Epoch[8] Batch [470]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.135346,	
2017-06-15 16:31:51,815 Epoch[8] Batch [480]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.135385,	
2017-06-15 16:31:56,397 Epoch[8] Batch [490]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.135706,	
2017-06-15 16:32:02,056 Epoch[8] Batch [500]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.135608,	
2017-06-15 16:32:06,789 Epoch[8] Batch [510]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.135834,	
2017-06-15 16:32:11,369 Epoch[8] Batch [520]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.135958,	
2017-06-15 16:32:15,996 Epoch[8] Batch [530]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.135818,	
2017-06-15 16:32:20,778 Epoch[8] Batch [540]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.135855,	
2017-06-15 16:32:25,872 Epoch[8] Batch [550]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.136702,	
2017-06-15 16:32:30,432 Epoch[8] Batch [560]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.136953,	
2017-06-15 16:32:35,455 Epoch[8] Batch [570]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.137054,	
2017-06-15 16:32:40,172 Epoch[8] Batch [580]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.137110,	
2017-06-15 16:32:44,897 Epoch[8] Batch [590]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.137249,	
2017-06-15 16:32:49,503 Epoch[8] Batch [600]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.136965,	
2017-06-15 16:32:54,074 Epoch[8] Batch [610]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.136711,	
2017-06-15 16:32:59,191 Epoch[8] Batch [620]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.136610,	
2017-06-15 16:33:03,905 Epoch[8] Batch [630]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.136517,	
2017-06-15 16:33:08,908 Epoch[8] Batch [640]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.136535,	
2017-06-15 16:33:13,732 Epoch[8] Batch [650]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.136732,	
2017-06-15 16:33:18,396 Epoch[8] Batch [660]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.136642,	
2017-06-15 16:33:22,927 Epoch[8] Batch [670]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.136787,	
2017-06-15 16:33:27,630 Epoch[8] Batch [680]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.136690,	
2017-06-15 16:33:32,374 Epoch[8] Batch [690]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.136987,	
2017-06-15 16:33:37,017 Epoch[8] Batch [700]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.137055,	
2017-06-15 16:33:41,940 Epoch[8] Batch [710]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.137082,	
2017-06-15 16:33:46,528 Epoch[8] Batch [720]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.137124,	
2017-06-15 16:33:51,368 Epoch[8] Batch [730]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.136900,	
2017-06-15 16:33:55,943 Epoch[8] Batch [740]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.136899,	
2017-06-15 16:34:01,581 Epoch[8] Batch [750]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.136692,	
2017-06-15 16:34:08,147 Epoch[8] Batch [760]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.136631,	
2017-06-15 16:34:15,166 Epoch[8] Batch [770]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.136583,	
2017-06-15 16:34:21,638 Epoch[8] Batch [780]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.136602,	
2017-06-15 16:34:29,502 Epoch[8] Batch [790]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.136855,	
2017-06-15 16:34:37,353 Epoch[8] Batch [800]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.136926,	
2017-06-15 16:34:45,647 Epoch[8] Batch [810]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.137168,	
2017-06-15 16:34:53,331 Epoch[8] Batch [820]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.137224,	
2017-06-15 16:35:03,491 Epoch[8] Batch [830]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.137090,	
2017-06-15 16:35:11,351 Epoch[8] Batch [840]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.136973,	
2017-06-15 16:35:19,201 Epoch[8] Batch [850]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.136805,	
2017-06-15 16:35:24,395 Epoch[8] Batch [860]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.136876,	
2017-06-15 16:35:28,918 Epoch[8] Batch [870]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.136958,	
2017-06-15 16:35:33,420 Epoch[8] Batch [880]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.137037,	
2017-06-15 16:35:38,449 Epoch[8] Batch [890]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.137107,	
2017-06-15 16:35:43,045 Epoch[8] Batch [900]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.137071,	
2017-06-15 16:35:48,242 Epoch[8] Batch [910]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.137156,	
2017-06-15 16:35:53,730 Epoch[8] Batch [920]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.137035,	
2017-06-15 16:35:59,335 Epoch[8] Batch [930]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.137062,	
2017-06-15 16:36:05,602 Epoch[8] Batch [940]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.136921,	
2017-06-15 16:36:12,849 Epoch[8] Batch [950]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.136881,	
2017-06-15 16:36:17,914 Epoch[8] Batch [960]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.137002,	
2017-06-15 16:36:22,569 Epoch[8] Batch [970]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.137013,	
2017-06-15 16:36:27,171 Epoch[8] Batch [980]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.137018,	
2017-06-15 16:36:31,887 Epoch[8] Batch [990]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.136937,	
2017-06-15 16:36:36,524 Epoch[8] Batch [1000]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.137056,	
2017-06-15 16:36:41,331 Epoch[8] Batch [1010]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.136912,	
2017-06-15 16:36:45,945 Epoch[8] Batch [1020]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.136914,	
2017-06-15 16:36:50,611 Epoch[8] Batch [1030]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.136809,	
2017-06-15 16:36:55,237 Epoch[8] Batch [1040]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.136734,	
2017-06-15 16:36:59,873 Epoch[8] Batch [1050]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.136714,	
2017-06-15 16:37:04,612 Epoch[8] Batch [1060]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.136658,	
2017-06-15 16:37:09,252 Epoch[8] Batch [1070]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.136553,	
2017-06-15 16:37:13,920 Epoch[8] Batch [1080]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.136546,	
2017-06-15 16:37:18,599 Epoch[8] Batch [1090]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.136453,	
2017-06-15 16:37:25,690 Epoch[8] Batch [1100]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.136396,	
2017-06-15 16:37:31,065 Epoch[8] Batch [1110]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.136293,	
2017-06-15 16:37:36,684 Epoch[8] Batch [1120]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.136277,	
2017-06-15 16:37:41,291 Epoch[8] Batch [1130]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.136269,	
2017-06-15 16:37:45,913 Epoch[8] Batch [1140]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.136412,	
2017-06-15 16:37:50,449 Epoch[8] Batch [1150]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.136392,	
2017-06-15 16:37:55,066 Epoch[8] Batch [1160]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.136525,	
2017-06-15 16:37:59,598 Epoch[8] Batch [1170]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.136534,	
2017-06-15 16:38:04,345 Epoch[8] Batch [1180]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.136656,	
2017-06-15 16:38:09,124 Epoch[8] Batch [1190]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.136577,	
2017-06-15 16:38:13,652 Epoch[8] Batch [1200]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.136868,	
2017-06-15 16:38:18,233 Epoch[8] Batch [1210]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.136859,	
2017-06-15 16:38:22,806 Epoch[8] Batch [1220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.136874,	
2017-06-15 16:38:27,447 Epoch[8] Batch [1230]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.137190,	
2017-06-15 16:38:32,192 Epoch[8] Batch [1240]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.137350,	
2017-06-15 16:38:36,974 Epoch[8] Batch [1250]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.137246,	
2017-06-15 16:38:41,677 Epoch[8] Batch [1260]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.137251,	
2017-06-15 16:38:46,390 Epoch[8] Batch [1270]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.137232,	
2017-06-15 16:38:51,117 Epoch[8] Batch [1280]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.137385,	
2017-06-15 16:38:55,823 Epoch[8] Batch [1290]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.137278,	
2017-06-15 16:39:00,566 Epoch[8] Batch [1300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.137390,	
2017-06-15 16:39:05,180 Epoch[8] Batch [1310]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.137363,	
2017-06-15 16:39:09,861 Epoch[8] Batch [1320]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.137232,	
2017-06-15 16:39:14,461 Epoch[8] Batch [1330]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.137178,	
2017-06-15 16:39:19,163 Epoch[8] Batch [1340]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.137188,	
2017-06-15 16:39:23,764 Epoch[8] Batch [1350]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.137059,	
2017-06-15 16:39:28,426 Epoch[8] Batch [1360]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.136969,	
2017-06-15 16:39:33,055 Epoch[8] Batch [1370]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.136878,	
2017-06-15 16:39:37,647 Epoch[8] Batch [1380]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.136863,	
2017-06-15 16:39:42,483 Epoch[8] Batch [1390]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.136859,	
2017-06-15 16:39:47,076 Epoch[8] Batch [1400]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.136781,	
2017-06-15 16:39:51,798 Epoch[8] Batch [1410]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.136864,	
2017-06-15 16:39:56,538 Epoch[8] Batch [1420]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.136844,	
2017-06-15 16:40:01,264 Epoch[8] Batch [1430]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.136894,	
2017-06-15 16:40:05,909 Epoch[8] Batch [1440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.136870,	
2017-06-15 16:40:10,480 Epoch[8] Batch [1450]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.136894,	
2017-06-15 16:40:15,017 Epoch[8] Batch [1460]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.136922,	
2017-06-15 16:40:19,727 Epoch[8] Batch [1470]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.136929,	
2017-06-15 16:40:24,431 Epoch[8] Batch [1480]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.136900,	
2017-06-15 16:40:27,184 Epoch[8] Train-FCNLogLoss=0.136902
2017-06-15 16:40:27,185 Epoch[8] Time cost=736.199
2017-06-15 16:40:28,221 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0009.params"
2017-06-15 16:40:30,105 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0009.states"
2017-06-15 16:40:35,476 Epoch[9] Batch [10]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.145747,	
2017-06-15 16:40:40,080 Epoch[9] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.150338,	
2017-06-15 16:40:44,708 Epoch[9] Batch [30]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.145303,	
2017-06-15 16:40:49,397 Epoch[9] Batch [40]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.139605,	
2017-06-15 16:40:54,070 Epoch[9] Batch [50]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.138288,	
2017-06-15 16:40:58,678 Epoch[9] Batch [60]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.138084,	
2017-06-15 16:41:03,372 Epoch[9] Batch [70]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.138769,	
2017-06-15 16:41:08,121 Epoch[9] Batch [80]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.136847,	
2017-06-15 16:41:12,770 Epoch[9] Batch [90]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.136533,	
2017-06-15 16:41:17,420 Epoch[9] Batch [100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.135479,	
2017-06-15 16:41:22,058 Epoch[9] Batch [110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.134352,	
2017-06-15 16:41:26,718 Epoch[9] Batch [120]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.135037,	
2017-06-15 16:41:31,330 Epoch[9] Batch [130]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.135878,	
2017-06-15 16:41:35,897 Epoch[9] Batch [140]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.135611,	
2017-06-15 16:41:40,609 Epoch[9] Batch [150]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.137933,	
2017-06-15 16:41:45,272 Epoch[9] Batch [160]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.137389,	
2017-06-15 16:41:50,007 Epoch[9] Batch [170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.136142,	
2017-06-15 16:41:54,655 Epoch[9] Batch [180]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.135586,	
2017-06-15 16:41:59,289 Epoch[9] Batch [190]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.135924,	
2017-06-15 16:42:03,915 Epoch[9] Batch [200]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.136328,	
2017-06-15 16:42:08,514 Epoch[9] Batch [210]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.136102,	
2017-06-15 16:42:13,143 Epoch[9] Batch [220]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.135764,	
2017-06-15 16:42:17,708 Epoch[9] Batch [230]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.136128,	
2017-06-15 16:42:22,317 Epoch[9] Batch [240]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.136105,	
2017-06-15 16:42:26,945 Epoch[9] Batch [250]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.136238,	
2017-06-15 16:42:31,587 Epoch[9] Batch [260]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.135784,	
2017-06-15 16:42:36,198 Epoch[9] Batch [270]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.135788,	
2017-06-15 16:42:40,736 Epoch[9] Batch [280]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.135534,	
2017-06-15 16:42:45,353 Epoch[9] Batch [290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.135262,	
2017-06-15 16:42:49,929 Epoch[9] Batch [300]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.135571,	
2017-06-15 16:42:54,555 Epoch[9] Batch [310]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.135202,	
2017-06-15 16:42:59,188 Epoch[9] Batch [320]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.134996,	
2017-06-15 16:43:03,828 Epoch[9] Batch [330]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.135659,	
2017-06-15 16:43:08,412 Epoch[9] Batch [340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.136070,	
2017-06-15 16:43:12,924 Epoch[9] Batch [350]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.138120,	
2017-06-15 16:43:17,524 Epoch[9] Batch [360]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.138963,	
2017-06-15 16:43:22,195 Epoch[9] Batch [370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.138638,	
2017-06-15 16:43:26,864 Epoch[9] Batch [380]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.139543,	
2017-06-15 16:43:31,541 Epoch[9] Batch [390]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.139906,	
2017-06-15 16:43:36,185 Epoch[9] Batch [400]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.140430,	
2017-06-15 16:43:40,694 Epoch[9] Batch [410]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.140564,	
2017-06-15 16:43:45,317 Epoch[9] Batch [420]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.140453,	
2017-06-15 16:43:49,893 Epoch[9] Batch [430]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.140027,	
2017-06-15 16:43:54,585 Epoch[9] Batch [440]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.140014,	
2017-06-15 16:43:59,370 Epoch[9] Batch [450]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.139525,	
2017-06-15 16:44:04,007 Epoch[9] Batch [460]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.139625,	
2017-06-15 16:44:08,755 Epoch[9] Batch [470]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.139487,	
2017-06-15 16:44:13,350 Epoch[9] Batch [480]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.139182,	
2017-06-15 16:44:17,921 Epoch[9] Batch [490]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.139130,	
2017-06-15 16:44:22,584 Epoch[9] Batch [500]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.139213,	
2017-06-15 16:44:27,269 Epoch[9] Batch [510]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.139626,	
2017-06-15 16:44:31,935 Epoch[9] Batch [520]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.139870,	
2017-06-15 16:44:36,639 Epoch[9] Batch [530]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.139670,	
2017-06-15 16:44:41,358 Epoch[9] Batch [540]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.139773,	
2017-06-15 16:44:45,985 Epoch[9] Batch [550]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.139747,	
2017-06-15 16:44:50,589 Epoch[9] Batch [560]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.139696,	
2017-06-15 16:44:55,204 Epoch[9] Batch [570]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.139539,	
2017-06-15 16:45:00,029 Epoch[9] Batch [580]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.139615,	
2017-06-15 16:45:04,745 Epoch[9] Batch [590]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.139444,	
2017-06-15 16:45:11,915 Epoch[9] Batch [600]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.139665,	
2017-06-15 16:45:18,264 Epoch[9] Batch [610]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.139690,	
2017-06-15 16:45:23,636 Epoch[9] Batch [620]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.139456,	
2017-06-15 16:45:28,203 Epoch[9] Batch [630]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.139194,	
2017-06-15 16:45:32,813 Epoch[9] Batch [640]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.138967,	
2017-06-15 16:45:37,499 Epoch[9] Batch [650]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.139080,	
2017-06-15 16:45:42,076 Epoch[9] Batch [660]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.139000,	
2017-06-15 16:45:46,744 Epoch[9] Batch [670]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.138964,	
2017-06-15 16:45:51,360 Epoch[9] Batch [680]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.138859,	
2017-06-15 16:45:56,176 Epoch[9] Batch [690]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.138661,	
2017-06-15 16:46:01,085 Epoch[9] Batch [700]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.138833,	
2017-06-15 16:46:05,802 Epoch[9] Batch [710]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.138468,	
2017-06-15 16:46:10,382 Epoch[9] Batch [720]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.138382,	
2017-06-15 16:46:15,052 Epoch[9] Batch [730]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.138675,	
2017-06-15 16:46:19,607 Epoch[9] Batch [740]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.138598,	
2017-06-15 16:46:24,162 Epoch[9] Batch [750]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.138442,	
2017-06-15 16:46:28,783 Epoch[9] Batch [760]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.138453,	
2017-06-15 16:46:33,457 Epoch[9] Batch [770]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.138362,	
2017-06-15 16:46:38,189 Epoch[9] Batch [780]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.138493,	
2017-06-15 16:46:42,899 Epoch[9] Batch [790]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.138200,	
2017-06-15 16:46:47,610 Epoch[9] Batch [800]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.137975,	
2017-06-15 16:46:52,217 Epoch[9] Batch [810]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.137878,	
2017-06-15 16:46:58,794 Epoch[9] Batch [820]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.137649,	
2017-06-15 16:47:07,104 Epoch[9] Batch [830]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.137791,	
2017-06-15 16:47:15,264 Epoch[9] Batch [840]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.138013,	
2017-06-15 16:47:24,185 Epoch[9] Batch [850]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.137908,	
2017-06-15 16:47:36,303 Epoch[9] Batch [860]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.137967,	
2017-06-15 16:47:50,034 Epoch[9] Batch [870]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.137873,	
2017-06-15 16:48:07,150 Epoch[9] Batch [880]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.137919,	
2017-06-15 16:48:23,870 Epoch[9] Batch [890]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.137737,	
2017-06-15 16:48:40,604 Epoch[9] Batch [900]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.137806,	
2017-06-15 16:48:53,002 Epoch[9] Batch [910]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.137915,	
2017-06-15 16:48:57,628 Epoch[9] Batch [920]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.137906,	
2017-06-15 16:49:02,066 Epoch[9] Batch [930]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.137776,	
2017-06-15 16:49:06,625 Epoch[9] Batch [940]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.137621,	
2017-06-15 16:49:11,149 Epoch[9] Batch [950]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.137631,	
2017-06-15 16:49:15,601 Epoch[9] Batch [960]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.137499,	
2017-06-15 16:49:20,057 Epoch[9] Batch [970]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.137528,	
2017-06-15 16:49:24,584 Epoch[9] Batch [980]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.137438,	
2017-06-15 16:49:29,194 Epoch[9] Batch [990]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.137233,	
2017-06-15 16:49:33,828 Epoch[9] Batch [1000]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.137146,	
2017-06-15 16:49:38,450 Epoch[9] Batch [1010]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.137080,	
2017-06-15 16:49:43,082 Epoch[9] Batch [1020]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.137042,	
2017-06-15 16:49:47,755 Epoch[9] Batch [1030]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.137144,	
2017-06-15 16:49:52,367 Epoch[9] Batch [1040]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.136938,	
2017-06-15 16:49:57,040 Epoch[9] Batch [1050]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.136970,	
2017-06-15 16:50:01,753 Epoch[9] Batch [1060]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.136906,	
2017-06-15 16:50:06,469 Epoch[9] Batch [1070]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.136776,	
2017-06-15 16:50:11,052 Epoch[9] Batch [1080]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.136696,	
2017-06-15 16:50:16,552 Epoch[9] Batch [1090]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.136796,	
2017-06-15 16:50:21,801 Epoch[9] Batch [1100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.136754,	
2017-06-15 16:50:28,567 Epoch[9] Batch [1110]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.136767,	
2017-06-15 16:50:42,413 Epoch[9] Batch [1120]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.136705,	
2017-06-15 16:50:52,461 Epoch[9] Batch [1130]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.136719,	
2017-06-15 16:51:06,632 Epoch[9] Batch [1140]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.136891,	
2017-06-15 16:51:20,268 Epoch[9] Batch [1150]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.136831,	
2017-06-15 16:51:34,019 Epoch[9] Batch [1160]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.136724,	
2017-06-15 16:51:47,071 Epoch[9] Batch [1170]	Speed: 3.06 samples/sec	Train-FCNLogLoss=0.136817,	
2017-06-15 16:52:00,712 Epoch[9] Batch [1180]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.136858,	
2017-06-15 16:52:15,217 Epoch[9] Batch [1190]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.136865,	
2017-06-15 16:52:29,771 Epoch[9] Batch [1200]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.136863,	
2017-06-15 16:52:45,125 Epoch[9] Batch [1210]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.136777,	
2017-06-15 16:53:01,501 Epoch[9] Batch [1220]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.136634,	
2017-06-15 16:53:13,063 Epoch[9] Batch [1230]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.136691,	
2017-06-15 16:53:29,286 Epoch[9] Batch [1240]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.136645,	
2017-06-15 16:53:43,767 Epoch[9] Batch [1250]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.136617,	
2017-06-15 16:53:56,894 Epoch[9] Batch [1260]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.136523,	
2017-06-15 16:54:09,429 Epoch[9] Batch [1270]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.136381,	
2017-06-15 16:54:14,347 Epoch[9] Batch [1280]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.136424,	
2017-06-15 16:54:18,830 Epoch[9] Batch [1290]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.136312,	
2017-06-15 16:54:23,559 Epoch[9] Batch [1300]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.136356,	
2017-06-15 16:54:28,470 Epoch[9] Batch [1310]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.136291,	
2017-06-15 16:54:33,597 Epoch[9] Batch [1320]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.136244,	
2017-06-15 16:54:40,393 Epoch[9] Batch [1330]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.136129,	
2017-06-15 16:54:46,411 Epoch[9] Batch [1340]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.136064,	
2017-06-15 16:54:51,127 Epoch[9] Batch [1350]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.136044,	
2017-06-15 16:54:55,834 Epoch[9] Batch [1360]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.135874,	
2017-06-15 16:55:00,474 Epoch[9] Batch [1370]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.135717,	
2017-06-15 16:55:05,291 Epoch[9] Batch [1380]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.135543,	
2017-06-15 16:55:09,928 Epoch[9] Batch [1390]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.135576,	
2017-06-15 16:55:14,531 Epoch[9] Batch [1400]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.135468,	
2017-06-15 16:55:19,261 Epoch[9] Batch [1410]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.135460,	
2017-06-15 16:55:24,018 Epoch[9] Batch [1420]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.135469,	
2017-06-15 16:55:28,863 Epoch[9] Batch [1430]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.135391,	
2017-06-15 16:55:33,654 Epoch[9] Batch [1440]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.135345,	
2017-06-15 16:55:38,510 Epoch[9] Batch [1450]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.135309,	
2017-06-15 16:55:45,225 Epoch[9] Batch [1460]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.135319,	
2017-06-15 16:55:56,564 Epoch[9] Batch [1470]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.135288,	
2017-06-15 16:56:11,703 Epoch[9] Batch [1480]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.135171,	
2017-06-15 16:56:20,981 Epoch[9] Train-FCNLogLoss=0.135239
2017-06-15 16:56:20,981 Epoch[9] Time cost=950.876
2017-06-15 16:56:22,106 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0010.params"
2017-06-15 16:56:29,270 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0010.states"
2017-06-15 16:56:44,551 Epoch[10] Batch [10]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.117038,	
2017-06-15 16:57:01,711 Epoch[10] Batch [20]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.113860,	
2017-06-15 16:57:16,765 Epoch[10] Batch [30]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.121390,	
2017-06-15 16:57:31,562 Epoch[10] Batch [40]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.127022,	
2017-06-15 16:57:49,033 Epoch[10] Batch [50]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.126057,	
2017-06-15 16:58:08,616 Epoch[10] Batch [60]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.124355,	
2017-06-15 16:58:27,972 Epoch[10] Batch [70]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.125375,	
2017-06-15 16:58:42,707 Epoch[10] Batch [80]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.124947,	
2017-06-15 16:58:54,272 Epoch[10] Batch [90]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.124934,	
2017-06-15 16:58:59,073 Epoch[10] Batch [100]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.124805,	
2017-06-15 16:59:03,661 Epoch[10] Batch [110]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.124887,	
2017-06-15 16:59:08,210 Epoch[10] Batch [120]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.125299,	
2017-06-15 16:59:12,806 Epoch[10] Batch [130]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.126411,	
2017-06-15 16:59:17,399 Epoch[10] Batch [140]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.129325,	
2017-06-15 16:59:21,930 Epoch[10] Batch [150]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.129775,	
2017-06-15 16:59:26,505 Epoch[10] Batch [160]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.129418,	
2017-06-15 16:59:31,008 Epoch[10] Batch [170]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.129287,	
2017-06-15 16:59:35,657 Epoch[10] Batch [180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.128988,	
2017-06-15 16:59:40,331 Epoch[10] Batch [190]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128740,	
2017-06-15 16:59:45,064 Epoch[10] Batch [200]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.128006,	
2017-06-15 16:59:49,775 Epoch[10] Batch [210]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.127660,	
2017-06-15 16:59:54,442 Epoch[10] Batch [220]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.126842,	
2017-06-15 16:59:59,091 Epoch[10] Batch [230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.127050,	
2017-06-15 17:00:03,801 Epoch[10] Batch [240]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.127073,	
2017-06-15 17:00:08,437 Epoch[10] Batch [250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.127574,	
2017-06-15 17:00:13,035 Epoch[10] Batch [260]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.127509,	
2017-06-15 17:00:17,792 Epoch[10] Batch [270]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.127583,	
2017-06-15 17:00:22,486 Epoch[10] Batch [280]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.128308,	
2017-06-15 17:00:27,174 Epoch[10] Batch [290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.130588,	
2017-06-15 17:00:31,821 Epoch[10] Batch [300]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.131961,	
2017-06-15 17:00:36,454 Epoch[10] Batch [310]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132498,	
2017-06-15 17:00:41,068 Epoch[10] Batch [320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.133494,	
2017-06-15 17:00:45,712 Epoch[10] Batch [330]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.134571,	
2017-06-15 17:00:50,325 Epoch[10] Batch [340]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.134914,	
2017-06-15 17:00:55,101 Epoch[10] Batch [350]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.134870,	
2017-06-15 17:00:59,686 Epoch[10] Batch [360]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.134647,	
2017-06-15 17:01:04,285 Epoch[10] Batch [370]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.134284,	
2017-06-15 17:01:08,916 Epoch[10] Batch [380]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.134093,	
2017-06-15 17:01:13,548 Epoch[10] Batch [390]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.134173,	
2017-06-15 17:01:18,099 Epoch[10] Batch [400]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.133941,	
2017-06-15 17:01:22,725 Epoch[10] Batch [410]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.133746,	
2017-06-15 17:01:27,311 Epoch[10] Batch [420]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.133821,	
2017-06-15 17:01:31,972 Epoch[10] Batch [430]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.133757,	
2017-06-15 17:01:36,616 Epoch[10] Batch [440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.133810,	
2017-06-15 17:01:41,201 Epoch[10] Batch [450]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.133834,	
2017-06-15 17:01:45,808 Epoch[10] Batch [460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.133682,	
2017-06-15 17:01:50,471 Epoch[10] Batch [470]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.133460,	
2017-06-15 17:01:55,068 Epoch[10] Batch [480]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.133403,	
2017-06-15 17:01:59,825 Epoch[10] Batch [490]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.133341,	
2017-06-15 17:02:04,622 Epoch[10] Batch [500]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.133264,	
2017-06-15 17:02:09,374 Epoch[10] Batch [510]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.132928,	
2017-06-15 17:02:14,025 Epoch[10] Batch [520]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.132829,	
2017-06-15 17:02:18,822 Epoch[10] Batch [530]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.132732,	
2017-06-15 17:02:23,461 Epoch[10] Batch [540]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132728,	
2017-06-15 17:02:28,101 Epoch[10] Batch [550]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132492,	
2017-06-15 17:02:32,758 Epoch[10] Batch [560]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.132361,	
2017-06-15 17:02:37,418 Epoch[10] Batch [570]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.132390,	
2017-06-15 17:02:41,939 Epoch[10] Batch [580]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.132169,	
2017-06-15 17:02:46,645 Epoch[10] Batch [590]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.132073,	
2017-06-15 17:02:51,233 Epoch[10] Batch [600]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.131941,	
2017-06-15 17:02:55,852 Epoch[10] Batch [610]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.131704,	
2017-06-15 17:03:00,354 Epoch[10] Batch [620]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.131393,	
2017-06-15 17:03:05,011 Epoch[10] Batch [630]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.131099,	
2017-06-15 17:03:09,582 Epoch[10] Batch [640]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.131283,	
2017-06-15 17:03:14,379 Epoch[10] Batch [650]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.131072,	
2017-06-15 17:03:18,958 Epoch[10] Batch [660]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.130949,	
2017-06-15 17:03:23,683 Epoch[10] Batch [670]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.130751,	
2017-06-15 17:03:28,362 Epoch[10] Batch [680]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.130712,	
2017-06-15 17:03:32,964 Epoch[10] Batch [690]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.130723,	
2017-06-15 17:03:37,725 Epoch[10] Batch [700]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.130512,	
2017-06-15 17:03:42,279 Epoch[10] Batch [710]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.130527,	
2017-06-15 17:03:46,934 Epoch[10] Batch [720]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.130673,	
2017-06-15 17:03:51,532 Epoch[10] Batch [730]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.130658,	
2017-06-15 17:03:56,108 Epoch[10] Batch [740]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.130755,	
2017-06-15 17:04:01,082 Epoch[10] Batch [750]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.130820,	
2017-06-15 17:04:06,008 Epoch[10] Batch [760]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.131308,	
2017-06-15 17:04:13,020 Epoch[10] Batch [770]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.131345,	
2017-06-15 17:04:24,466 Epoch[10] Batch [780]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.131355,	
2017-06-15 17:04:37,548 Epoch[10] Batch [790]	Speed: 3.06 samples/sec	Train-FCNLogLoss=0.131368,	
2017-06-15 17:04:55,803 Epoch[10] Batch [800]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.131592,	
2017-06-15 17:05:18,296 Epoch[10] Batch [810]	Speed: 1.78 samples/sec	Train-FCNLogLoss=0.131651,	
2017-06-15 17:05:33,454 Epoch[10] Batch [820]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.131866,	
2017-06-15 17:05:52,578 Epoch[10] Batch [830]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.132150,	
2017-06-15 17:05:58,637 Epoch[10] Batch [840]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.132154,	
2017-06-15 17:06:03,136 Epoch[10] Batch [850]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.132098,	
2017-06-15 17:06:07,899 Epoch[10] Batch [860]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.132112,	
2017-06-15 17:06:12,389 Epoch[10] Batch [870]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.132139,	
2017-06-15 17:06:16,979 Epoch[10] Batch [880]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.132123,	
2017-06-15 17:06:22,035 Epoch[10] Batch [890]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.132115,	
2017-06-15 17:06:27,695 Epoch[10] Batch [900]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.132074,	
2017-06-15 17:06:35,792 Epoch[10] Batch [910]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.132174,	
2017-06-15 17:06:44,051 Epoch[10] Batch [920]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.132278,	
2017-06-15 17:06:51,846 Epoch[10] Batch [930]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.132285,	
2017-06-15 17:07:00,557 Epoch[10] Batch [940]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.132112,	
2017-06-15 17:07:09,158 Epoch[10] Batch [950]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.131897,	
2017-06-15 17:07:17,353 Epoch[10] Batch [960]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.132031,	
2017-06-15 17:07:25,225 Epoch[10] Batch [970]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.132083,	
2017-06-15 17:07:33,554 Epoch[10] Batch [980]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.132008,	
2017-06-15 17:07:41,820 Epoch[10] Batch [990]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.132058,	
2017-06-15 17:07:49,621 Epoch[10] Batch [1000]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.132089,	
2017-06-15 17:07:57,506 Epoch[10] Batch [1010]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.132017,	
2017-06-15 17:08:05,426 Epoch[10] Batch [1020]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.132179,	
2017-06-15 17:08:14,145 Epoch[10] Batch [1030]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.132036,	
2017-06-15 17:08:22,286 Epoch[10] Batch [1040]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.132049,	
2017-06-15 17:08:30,099 Epoch[10] Batch [1050]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.132047,	
2017-06-15 17:08:38,109 Epoch[10] Batch [1060]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.132078,	
2017-06-15 17:08:46,160 Epoch[10] Batch [1070]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.132206,	
2017-06-15 17:08:54,100 Epoch[10] Batch [1080]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.132167,	
2017-06-15 17:09:02,531 Epoch[10] Batch [1090]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.132154,	
2017-06-15 17:09:09,468 Epoch[10] Batch [1100]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.132088,	
2017-06-15 17:09:14,080 Epoch[10] Batch [1110]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.132046,	
2017-06-15 17:09:18,641 Epoch[10] Batch [1120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.132266,	
2017-06-15 17:09:23,256 Epoch[10] Batch [1130]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.132456,	
2017-06-15 17:09:27,926 Epoch[10] Batch [1140]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.132408,	
2017-06-15 17:09:32,579 Epoch[10] Batch [1150]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.132496,	
2017-06-15 17:09:37,237 Epoch[10] Batch [1160]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.132863,	
2017-06-15 17:09:41,860 Epoch[10] Batch [1170]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.133664,	
2017-06-15 17:09:46,487 Epoch[10] Batch [1180]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.133988,	
2017-06-15 17:09:51,214 Epoch[10] Batch [1190]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.134557,	
2017-06-15 17:09:55,806 Epoch[10] Batch [1200]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.135572,	
2017-06-15 17:10:00,778 Epoch[10] Batch [1210]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.136285,	
2017-06-15 17:10:08,307 Epoch[10] Batch [1220]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.136542,	
2017-06-15 17:10:15,652 Epoch[10] Batch [1230]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.136919,	
2017-06-15 17:10:23,753 Epoch[10] Batch [1240]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.137127,	
2017-06-15 17:10:31,745 Epoch[10] Batch [1250]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.137120,	
2017-06-15 17:10:39,884 Epoch[10] Batch [1260]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.137174,	
2017-06-15 17:10:47,926 Epoch[10] Batch [1270]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.137193,	
2017-06-15 17:10:55,953 Epoch[10] Batch [1280]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.137261,	
2017-06-15 17:11:03,858 Epoch[10] Batch [1290]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.137683,	
2017-06-15 17:11:11,907 Epoch[10] Batch [1300]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.138158,	
2017-06-15 17:11:19,950 Epoch[10] Batch [1310]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.138317,	
2017-06-15 17:11:27,880 Epoch[10] Batch [1320]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.138347,	
2017-06-15 17:11:35,645 Epoch[10] Batch [1330]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.138360,	
2017-06-15 17:11:43,492 Epoch[10] Batch [1340]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.138325,	
2017-06-15 17:11:51,515 Epoch[10] Batch [1350]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.138392,	
2017-06-15 17:11:59,598 Epoch[10] Batch [1360]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.138640,	
2017-06-15 17:12:08,049 Epoch[10] Batch [1370]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.138701,	
2017-06-15 17:12:16,179 Epoch[10] Batch [1380]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.138652,	
2017-06-15 17:12:24,285 Epoch[10] Batch [1390]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.138644,	
2017-06-15 17:12:32,470 Epoch[10] Batch [1400]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.138739,	
2017-06-15 17:12:40,344 Epoch[10] Batch [1410]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.138984,	
2017-06-15 17:12:48,455 Epoch[10] Batch [1420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.138991,	
2017-06-15 17:12:56,600 Epoch[10] Batch [1430]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.138999,	
2017-06-15 17:13:04,518 Epoch[10] Batch [1440]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.139080,	
2017-06-15 17:13:09,322 Epoch[10] Batch [1450]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.139013,	
2017-06-15 17:13:13,714 Epoch[10] Batch [1460]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.139054,	
2017-06-15 17:13:18,259 Epoch[10] Batch [1470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.139083,	
2017-06-15 17:13:22,871 Epoch[10] Batch [1480]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.139105,	
2017-06-15 17:13:25,565 Epoch[10] Train-FCNLogLoss=0.139188
2017-06-15 17:13:25,565 Epoch[10] Time cost=1016.295
2017-06-15 17:13:26,359 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0011.params"
2017-06-15 17:13:27,854 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0011.states"
2017-06-15 17:13:33,250 Epoch[11] Batch [10]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115837,	
2017-06-15 17:13:37,782 Epoch[11] Batch [20]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.126126,	
2017-06-15 17:13:42,390 Epoch[11] Batch [30]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.125250,	
2017-06-15 17:13:46,921 Epoch[11] Batch [40]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.126242,	
2017-06-15 17:13:51,582 Epoch[11] Batch [50]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.130128,	
2017-06-15 17:13:56,196 Epoch[11] Batch [60]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.129075,	
2017-06-15 17:14:00,778 Epoch[11] Batch [70]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.129666,	
2017-06-15 17:14:05,388 Epoch[11] Batch [80]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.131917,	
2017-06-15 17:14:10,020 Epoch[11] Batch [90]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.132793,	
2017-06-15 17:14:14,634 Epoch[11] Batch [100]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.133765,	
2017-06-15 17:14:19,238 Epoch[11] Batch [110]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.134150,	
2017-06-15 17:14:23,817 Epoch[11] Batch [120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.134557,	
2017-06-15 17:14:28,518 Epoch[11] Batch [130]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.133299,	
2017-06-15 17:14:33,288 Epoch[11] Batch [140]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.132262,	
2017-06-15 17:14:37,957 Epoch[11] Batch [150]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.132445,	
2017-06-15 17:14:42,699 Epoch[11] Batch [160]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.132214,	
2017-06-15 17:14:47,516 Epoch[11] Batch [170]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.132186,	
2017-06-15 17:14:52,129 Epoch[11] Batch [180]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.132213,	
2017-06-15 17:14:56,657 Epoch[11] Batch [190]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.131870,	
2017-06-15 17:15:01,225 Epoch[11] Batch [200]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.131946,	
2017-06-15 17:15:05,825 Epoch[11] Batch [210]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.132278,	
2017-06-15 17:15:10,356 Epoch[11] Batch [220]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.132820,	
2017-06-15 17:15:15,071 Epoch[11] Batch [230]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.132432,	
2017-06-15 17:15:19,771 Epoch[11] Batch [240]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.132541,	
2017-06-15 17:15:24,446 Epoch[11] Batch [250]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.132655,	
2017-06-15 17:15:29,138 Epoch[11] Batch [260]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.132061,	
2017-06-15 17:15:33,805 Epoch[11] Batch [270]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.132145,	
2017-06-15 17:15:38,510 Epoch[11] Batch [280]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.132035,	
2017-06-15 17:15:43,040 Epoch[11] Batch [290]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.131175,	
2017-06-15 17:15:47,812 Epoch[11] Batch [300]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.131586,	
2017-06-15 17:15:52,455 Epoch[11] Batch [310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.131890,	
2017-06-15 17:15:57,158 Epoch[11] Batch [320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.131824,	
2017-06-15 17:16:01,770 Epoch[11] Batch [330]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.131955,	
2017-06-15 17:16:06,526 Epoch[11] Batch [340]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.131658,	
2017-06-15 17:16:11,032 Epoch[11] Batch [350]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.131577,	
2017-06-15 17:16:15,702 Epoch[11] Batch [360]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.131520,	
2017-06-15 17:16:20,430 Epoch[11] Batch [370]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.131346,	
2017-06-15 17:16:25,136 Epoch[11] Batch [380]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.131529,	
2017-06-15 17:16:29,800 Epoch[11] Batch [390]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.131121,	
2017-06-15 17:16:34,480 Epoch[11] Batch [400]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.131409,	
2017-06-15 17:16:39,133 Epoch[11] Batch [410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.131541,	
2017-06-15 17:16:43,666 Epoch[11] Batch [420]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.131633,	
2017-06-15 17:16:48,396 Epoch[11] Batch [430]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.131985,	
2017-06-15 17:16:53,018 Epoch[11] Batch [440]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.132031,	
2017-06-15 17:16:57,570 Epoch[11] Batch [450]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.131895,	
2017-06-15 17:17:02,125 Epoch[11] Batch [460]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.131477,	
2017-06-15 17:17:06,782 Epoch[11] Batch [470]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.131458,	
2017-06-15 17:17:11,418 Epoch[11] Batch [480]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.131557,	
2017-06-15 17:17:16,057 Epoch[11] Batch [490]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.131630,	
2017-06-15 17:17:20,678 Epoch[11] Batch [500]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.131653,	
2017-06-15 17:17:25,245 Epoch[11] Batch [510]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.131403,	
2017-06-15 17:17:30,016 Epoch[11] Batch [520]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.131266,	
2017-06-15 17:17:34,718 Epoch[11] Batch [530]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.131365,	
2017-06-15 17:17:39,416 Epoch[11] Batch [540]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.131368,	
2017-06-15 17:17:43,932 Epoch[11] Batch [550]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.131437,	
2017-06-15 17:17:48,780 Epoch[11] Batch [560]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.131576,	
2017-06-15 17:17:53,433 Epoch[11] Batch [570]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.131440,	
2017-06-15 17:17:58,107 Epoch[11] Batch [580]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.131123,	
2017-06-15 17:18:02,827 Epoch[11] Batch [590]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.131040,	
2017-06-15 17:18:07,373 Epoch[11] Batch [600]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.131169,	
2017-06-15 17:18:12,122 Epoch[11] Batch [610]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.130907,	
2017-06-15 17:18:16,638 Epoch[11] Batch [620]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.130651,	
2017-06-15 17:18:21,249 Epoch[11] Batch [630]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.130638,	
2017-06-15 17:18:26,004 Epoch[11] Batch [640]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.130871,	
2017-06-15 17:18:30,741 Epoch[11] Batch [650]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.130866,	
2017-06-15 17:18:35,354 Epoch[11] Batch [660]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.130817,	
2017-06-15 17:18:39,960 Epoch[11] Batch [670]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.130674,	
2017-06-15 17:18:44,661 Epoch[11] Batch [680]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.130647,	
2017-06-15 17:18:49,314 Epoch[11] Batch [690]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.130729,	
2017-06-15 17:18:54,047 Epoch[11] Batch [700]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.130654,	
2017-06-15 17:18:58,620 Epoch[11] Batch [710]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.130479,	
2017-06-15 17:19:03,283 Epoch[11] Batch [720]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.130392,	
2017-06-15 17:19:08,015 Epoch[11] Batch [730]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.130478,	
2017-06-15 17:19:12,697 Epoch[11] Batch [740]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.130256,	
2017-06-15 17:19:17,483 Epoch[11] Batch [750]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.129985,	
2017-06-15 17:19:22,021 Epoch[11] Batch [760]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.129766,	
2017-06-15 17:19:26,643 Epoch[11] Batch [770]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.129736,	
2017-06-15 17:19:31,231 Epoch[11] Batch [780]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.129893,	
2017-06-15 17:19:35,918 Epoch[11] Batch [790]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.129813,	
2017-06-15 17:19:40,542 Epoch[11] Batch [800]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.129608,	
2017-06-15 17:19:45,231 Epoch[11] Batch [810]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.129694,	
2017-06-15 17:19:50,023 Epoch[11] Batch [820]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.129965,	
2017-06-15 17:19:54,704 Epoch[11] Batch [830]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.130014,	
2017-06-15 17:19:59,342 Epoch[11] Batch [840]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.130122,	
2017-06-15 17:20:04,025 Epoch[11] Batch [850]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.130062,	
2017-06-15 17:20:08,786 Epoch[11] Batch [860]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.129897,	
2017-06-15 17:20:13,406 Epoch[11] Batch [870]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.130039,	
2017-06-15 17:20:18,159 Epoch[11] Batch [880]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.130007,	
2017-06-15 17:20:22,687 Epoch[11] Batch [890]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.129966,	
2017-06-15 17:20:27,217 Epoch[11] Batch [900]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.129747,	
2017-06-15 17:20:31,955 Epoch[11] Batch [910]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.129899,	
2017-06-15 17:20:36,548 Epoch[11] Batch [920]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.129806,	
2017-06-15 17:20:41,265 Epoch[11] Batch [930]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.129734,	
2017-06-15 17:20:45,942 Epoch[11] Batch [940]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.129600,	
2017-06-15 17:20:50,621 Epoch[11] Batch [950]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.129451,	
2017-06-15 17:20:55,321 Epoch[11] Batch [960]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.129403,	
2017-06-15 17:20:59,940 Epoch[11] Batch [970]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.129188,	
2017-06-15 17:21:04,547 Epoch[11] Batch [980]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.129041,	
2017-06-15 17:21:09,229 Epoch[11] Batch [990]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.128923,	
2017-06-15 17:21:14,007 Epoch[11] Batch [1000]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.128864,	
2017-06-15 17:21:18,780 Epoch[11] Batch [1010]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.128795,	
2017-06-15 17:21:23,335 Epoch[11] Batch [1020]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.128782,	
2017-06-15 17:21:27,968 Epoch[11] Batch [1030]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.128629,	
2017-06-15 17:21:32,894 Epoch[11] Batch [1040]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.128536,	
2017-06-15 17:21:37,536 Epoch[11] Batch [1050]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.128480,	
2017-06-15 17:21:42,207 Epoch[11] Batch [1060]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128318,	
2017-06-15 17:21:46,923 Epoch[11] Batch [1070]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.128447,	
2017-06-15 17:21:51,571 Epoch[11] Batch [1080]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.128501,	
2017-06-15 17:21:56,564 Epoch[11] Batch [1090]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.128407,	
2017-06-15 17:22:01,359 Epoch[11] Batch [1100]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.128250,	
2017-06-15 17:22:05,961 Epoch[11] Batch [1110]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.128240,	
2017-06-15 17:22:10,516 Epoch[11] Batch [1120]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.128342,	
2017-06-15 17:22:15,115 Epoch[11] Batch [1130]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.128277,	
2017-06-15 17:22:20,080 Epoch[11] Batch [1140]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.128463,	
2017-06-15 17:22:24,776 Epoch[11] Batch [1150]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.128554,	
2017-06-15 17:22:29,432 Epoch[11] Batch [1160]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.128510,	
2017-06-15 17:22:34,086 Epoch[11] Batch [1170]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.128478,	
2017-06-15 17:22:38,641 Epoch[11] Batch [1180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.128479,	
2017-06-15 17:22:43,308 Epoch[11] Batch [1190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.128413,	
2017-06-15 17:22:48,087 Epoch[11] Batch [1200]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.128441,	
2017-06-15 17:22:52,641 Epoch[11] Batch [1210]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.128330,	
2017-06-15 17:22:57,303 Epoch[11] Batch [1220]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.128334,	
2017-06-15 17:23:01,908 Epoch[11] Batch [1230]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.128534,	
2017-06-15 17:23:06,511 Epoch[11] Batch [1240]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.128486,	
2017-06-15 17:23:11,085 Epoch[11] Batch [1250]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.128501,	
2017-06-15 17:23:15,646 Epoch[11] Batch [1260]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.128471,	
2017-06-15 17:23:20,258 Epoch[11] Batch [1270]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.128530,	
2017-06-15 17:23:24,808 Epoch[11] Batch [1280]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.128486,	
2017-06-15 17:23:29,464 Epoch[11] Batch [1290]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.128382,	
2017-06-15 17:23:34,067 Epoch[11] Batch [1300]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.128351,	
2017-06-15 17:23:38,584 Epoch[11] Batch [1310]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.128305,	
2017-06-15 17:23:43,143 Epoch[11] Batch [1320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.128222,	
2017-06-15 17:23:47,824 Epoch[11] Batch [1330]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.128184,	
2017-06-15 17:23:52,455 Epoch[11] Batch [1340]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.128134,	
2017-06-15 17:23:57,127 Epoch[11] Batch [1350]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128010,	
2017-06-15 17:24:01,747 Epoch[11] Batch [1360]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.128029,	
2017-06-15 17:24:06,315 Epoch[11] Batch [1370]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.128009,	
2017-06-15 17:24:11,007 Epoch[11] Batch [1380]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128062,	
2017-06-15 17:24:15,654 Epoch[11] Batch [1390]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.127980,	
2017-06-15 17:24:20,238 Epoch[11] Batch [1400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.127940,	
2017-06-15 17:24:24,927 Epoch[11] Batch [1410]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.127954,	
2017-06-15 17:24:29,501 Epoch[11] Batch [1420]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.127913,	
2017-06-15 17:24:34,107 Epoch[11] Batch [1430]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.127803,	
2017-06-15 17:24:38,724 Epoch[11] Batch [1440]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.127959,	
2017-06-15 17:24:43,382 Epoch[11] Batch [1450]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.127990,	
2017-06-15 17:24:47,970 Epoch[11] Batch [1460]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.128113,	
2017-06-15 17:24:52,640 Epoch[11] Batch [1470]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.128141,	
2017-06-15 17:24:57,305 Epoch[11] Batch [1480]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.128131,	
2017-06-15 17:25:00,028 Epoch[11] Train-FCNLogLoss=0.128116
2017-06-15 17:25:00,028 Epoch[11] Time cost=692.173
2017-06-15 17:25:00,834 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0012.params"
2017-06-15 17:25:02,529 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0012.states"
2017-06-15 17:25:07,831 Epoch[12] Batch [10]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.107604,	
2017-06-15 17:25:12,407 Epoch[12] Batch [20]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.113348,	
2017-06-15 17:25:17,088 Epoch[12] Batch [30]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.115737,	
2017-06-15 17:25:21,780 Epoch[12] Batch [40]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.113155,	
2017-06-15 17:25:26,390 Epoch[12] Batch [50]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.112870,	
2017-06-15 17:25:31,111 Epoch[12] Batch [60]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.113219,	
2017-06-15 17:25:35,785 Epoch[12] Batch [70]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.114691,	
2017-06-15 17:25:40,621 Epoch[12] Batch [80]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.116817,	
2017-06-15 17:25:45,204 Epoch[12] Batch [90]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.118178,	
2017-06-15 17:25:49,847 Epoch[12] Batch [100]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.119599,	
2017-06-15 17:25:54,410 Epoch[12] Batch [110]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.120258,	
2017-06-15 17:25:59,151 Epoch[12] Batch [120]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.119102,	
2017-06-15 17:26:03,758 Epoch[12] Batch [130]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.119171,	
2017-06-15 17:26:08,353 Epoch[12] Batch [140]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.120247,	
2017-06-15 17:26:13,046 Epoch[12] Batch [150]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.120865,	
2017-06-15 17:26:17,617 Epoch[12] Batch [160]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.121171,	
2017-06-15 17:26:22,200 Epoch[12] Batch [170]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.121317,	
2017-06-15 17:26:26,734 Epoch[12] Batch [180]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.120501,	
2017-06-15 17:26:31,311 Epoch[12] Batch [190]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.120960,	
2017-06-15 17:26:35,845 Epoch[12] Batch [200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.120320,	
2017-06-15 17:26:40,572 Epoch[12] Batch [210]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.119381,	
2017-06-15 17:26:45,100 Epoch[12] Batch [220]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.119501,	
2017-06-15 17:26:50,118 Epoch[12] Batch [230]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.119989,	
2017-06-15 17:26:54,978 Epoch[12] Batch [240]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.119737,	
2017-06-15 17:26:59,637 Epoch[12] Batch [250]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.119611,	
2017-06-15 17:27:04,225 Epoch[12] Batch [260]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.119618,	
2017-06-15 17:27:08,957 Epoch[12] Batch [270]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.119917,	
2017-06-15 17:27:13,500 Epoch[12] Batch [280]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.120484,	
2017-06-15 17:27:18,218 Epoch[12] Batch [290]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.120156,	
2017-06-15 17:27:22,811 Epoch[12] Batch [300]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.121061,	
2017-06-15 17:27:27,629 Epoch[12] Batch [310]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.121150,	
2017-06-15 17:27:32,243 Epoch[12] Batch [320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.121038,	
2017-06-15 17:27:36,978 Epoch[12] Batch [330]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.120965,	
2017-06-15 17:27:41,569 Epoch[12] Batch [340]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.120749,	
2017-06-15 17:27:46,214 Epoch[12] Batch [350]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.121157,	
2017-06-15 17:27:50,917 Epoch[12] Batch [360]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.121021,	
2017-06-15 17:27:55,817 Epoch[12] Batch [370]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.120734,	
2017-06-15 17:28:00,443 Epoch[12] Batch [380]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.120665,	
2017-06-15 17:28:05,068 Epoch[12] Batch [390]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.121153,	
2017-06-15 17:28:09,823 Epoch[12] Batch [400]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.121340,	
2017-06-15 17:28:14,520 Epoch[12] Batch [410]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.123073,	
2017-06-15 17:28:19,314 Epoch[12] Batch [420]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.123432,	
2017-06-15 17:28:23,886 Epoch[12] Batch [430]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.123398,	
2017-06-15 17:28:28,544 Epoch[12] Batch [440]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.123427,	
2017-06-15 17:28:33,068 Epoch[12] Batch [450]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.123466,	
2017-06-15 17:28:37,615 Epoch[12] Batch [460]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.123589,	
2017-06-15 17:28:42,203 Epoch[12] Batch [470]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.123422,	
2017-06-15 17:28:46,695 Epoch[12] Batch [480]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.123348,	
2017-06-15 17:28:51,490 Epoch[12] Batch [490]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.123342,	
2017-06-15 17:28:56,060 Epoch[12] Batch [500]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.124000,	
2017-06-15 17:29:00,712 Epoch[12] Batch [510]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.124216,	
2017-06-15 17:29:05,380 Epoch[12] Batch [520]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.124377,	
2017-06-15 17:29:10,092 Epoch[12] Batch [530]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.124391,	
2017-06-15 17:29:14,792 Epoch[12] Batch [540]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.124297,	
2017-06-15 17:29:19,418 Epoch[12] Batch [550]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.124356,	
2017-06-15 17:29:23,986 Epoch[12] Batch [560]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.124380,	
2017-06-15 17:29:28,549 Epoch[12] Batch [570]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.124505,	
2017-06-15 17:29:33,073 Epoch[12] Batch [580]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.124473,	
2017-06-15 17:29:37,648 Epoch[12] Batch [590]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.124454,	
2017-06-15 17:29:42,290 Epoch[12] Batch [600]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.124357,	
2017-06-15 17:29:46,946 Epoch[12] Batch [610]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.124122,	
2017-06-15 17:29:51,469 Epoch[12] Batch [620]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.124149,	
2017-06-15 17:29:56,099 Epoch[12] Batch [630]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.124077,	
2017-06-15 17:30:00,740 Epoch[12] Batch [640]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.124073,	
2017-06-15 17:30:05,475 Epoch[12] Batch [650]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.124316,	
2017-06-15 17:30:10,023 Epoch[12] Batch [660]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.124180,	
2017-06-15 17:30:14,537 Epoch[12] Batch [670]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.124064,	
2017-06-15 17:30:19,191 Epoch[12] Batch [680]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.124286,	
2017-06-15 17:30:23,800 Epoch[12] Batch [690]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.124169,	
2017-06-15 17:30:28,417 Epoch[12] Batch [700]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.124004,	
2017-06-15 17:30:33,069 Epoch[12] Batch [710]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.123976,	
2017-06-15 17:30:37,621 Epoch[12] Batch [720]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.124225,	
2017-06-15 17:30:42,326 Epoch[12] Batch [730]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.124194,	
2017-06-15 17:30:46,996 Epoch[12] Batch [740]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124031,	
2017-06-15 17:30:51,535 Epoch[12] Batch [750]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.124103,	
2017-06-15 17:30:56,110 Epoch[12] Batch [760]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.124153,	
2017-06-15 17:31:00,905 Epoch[12] Batch [770]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.124216,	
2017-06-15 17:31:05,473 Epoch[12] Batch [780]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.124016,	
2017-06-15 17:31:10,233 Epoch[12] Batch [790]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.123981,	
2017-06-15 17:31:14,867 Epoch[12] Batch [800]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.123952,	
2017-06-15 17:31:19,549 Epoch[12] Batch [810]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.123996,	
2017-06-15 17:31:24,265 Epoch[12] Batch [820]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.123995,	
2017-06-15 17:31:29,026 Epoch[12] Batch [830]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.123893,	
2017-06-15 17:31:33,713 Epoch[12] Batch [840]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.123699,	
2017-06-15 17:31:38,373 Epoch[12] Batch [850]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.123639,	
2017-06-15 17:31:43,077 Epoch[12] Batch [860]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.123707,	
2017-06-15 17:31:47,820 Epoch[12] Batch [870]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.123768,	
2017-06-15 17:31:52,579 Epoch[12] Batch [880]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.123848,	
2017-06-15 17:31:57,330 Epoch[12] Batch [890]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.123689,	
2017-06-15 17:32:02,212 Epoch[12] Batch [900]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.123591,	
2017-06-15 17:32:06,976 Epoch[12] Batch [910]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.123600,	
2017-06-15 17:32:11,721 Epoch[12] Batch [920]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.123572,	
2017-06-15 17:32:16,538 Epoch[12] Batch [930]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.123595,	
2017-06-15 17:32:21,163 Epoch[12] Batch [940]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123315,	
2017-06-15 17:32:26,029 Epoch[12] Batch [950]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.123188,	
2017-06-15 17:32:30,753 Epoch[12] Batch [960]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.123233,	
2017-06-15 17:32:35,497 Epoch[12] Batch [970]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.123224,	
2017-06-15 17:32:40,162 Epoch[12] Batch [980]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.123204,	
2017-06-15 17:32:44,880 Epoch[12] Batch [990]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.123148,	
2017-06-15 17:32:49,780 Epoch[12] Batch [1000]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.123229,	
2017-06-15 17:32:54,338 Epoch[12] Batch [1010]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.123490,	
2017-06-15 17:32:58,950 Epoch[12] Batch [1020]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.123427,	
2017-06-15 17:33:03,604 Epoch[12] Batch [1030]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.123269,	
2017-06-15 17:33:08,518 Epoch[12] Batch [1040]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.123370,	
2017-06-15 17:33:13,276 Epoch[12] Batch [1050]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.123360,	
2017-06-15 17:33:18,011 Epoch[12] Batch [1060]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.123380,	
2017-06-15 17:33:22,765 Epoch[12] Batch [1070]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.123538,	
2017-06-15 17:33:27,537 Epoch[12] Batch [1080]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.123649,	
2017-06-15 17:33:32,394 Epoch[12] Batch [1090]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.123634,	
2017-06-15 17:33:37,401 Epoch[12] Batch [1100]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.123464,	
2017-06-15 17:33:42,036 Epoch[12] Batch [1110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.123465,	
2017-06-15 17:33:46,757 Epoch[12] Batch [1120]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.123552,	
2017-06-15 17:33:51,371 Epoch[12] Batch [1130]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.123587,	
2017-06-15 17:33:56,029 Epoch[12] Batch [1140]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.123710,	
2017-06-15 17:34:00,602 Epoch[12] Batch [1150]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.123694,	
2017-06-15 17:34:05,176 Epoch[12] Batch [1160]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.123867,	
2017-06-15 17:34:09,863 Epoch[12] Batch [1170]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.123786,	
2017-06-15 17:34:14,449 Epoch[12] Batch [1180]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.123776,	
2017-06-15 17:34:19,119 Epoch[12] Batch [1190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.123666,	
2017-06-15 17:34:23,725 Epoch[12] Batch [1200]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.123615,	
2017-06-15 17:34:28,382 Epoch[12] Batch [1210]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.123509,	
2017-06-15 17:34:32,934 Epoch[12] Batch [1220]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.123683,	
2017-06-15 17:34:37,502 Epoch[12] Batch [1230]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.123751,	
2017-06-15 17:34:42,197 Epoch[12] Batch [1240]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.123798,	
2017-06-15 17:34:46,832 Epoch[12] Batch [1250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.123729,	
2017-06-15 17:34:51,456 Epoch[12] Batch [1260]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123913,	
2017-06-15 17:34:56,442 Epoch[12] Batch [1270]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.123991,	
2017-06-15 17:35:01,113 Epoch[12] Batch [1280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.123935,	
2017-06-15 17:35:05,820 Epoch[12] Batch [1290]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.123927,	
2017-06-15 17:35:10,453 Epoch[12] Batch [1300]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.123840,	
2017-06-15 17:35:15,068 Epoch[12] Batch [1310]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.123829,	
2017-06-15 17:35:19,680 Epoch[12] Batch [1320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.123826,	
2017-06-15 17:35:24,316 Epoch[12] Batch [1330]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.123789,	
2017-06-15 17:35:29,106 Epoch[12] Batch [1340]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.123771,	
2017-06-15 17:35:33,766 Epoch[12] Batch [1350]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.123754,	
2017-06-15 17:35:38,393 Epoch[12] Batch [1360]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123986,	
2017-06-15 17:35:42,933 Epoch[12] Batch [1370]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.123983,	
2017-06-15 17:35:47,558 Epoch[12] Batch [1380]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123967,	
2017-06-15 17:35:52,302 Epoch[12] Batch [1390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.123990,	
2017-06-15 17:35:56,857 Epoch[12] Batch [1400]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.124053,	
2017-06-15 17:36:01,529 Epoch[12] Batch [1410]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124140,	
2017-06-15 17:36:06,198 Epoch[12] Batch [1420]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.124066,	
2017-06-15 17:36:10,823 Epoch[12] Batch [1430]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.124111,	
2017-06-15 17:36:15,508 Epoch[12] Batch [1440]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.124022,	
2017-06-15 17:36:20,079 Epoch[12] Batch [1450]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.124075,	
2017-06-15 17:36:24,662 Epoch[12] Batch [1460]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.124078,	
2017-06-15 17:36:29,288 Epoch[12] Batch [1470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.124002,	
2017-06-15 17:36:33,951 Epoch[12] Batch [1480]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.124004,	
2017-06-15 17:36:36,668 Epoch[12] Train-FCNLogLoss=0.124015
2017-06-15 17:36:36,669 Epoch[12] Time cost=694.140
2017-06-15 17:36:37,448 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0013.params"
2017-06-15 17:36:39,132 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0013.states"
2017-06-15 17:36:44,698 Epoch[13] Batch [10]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.117411,	
2017-06-15 17:36:49,307 Epoch[13] Batch [20]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.121589,	
2017-06-15 17:36:54,037 Epoch[13] Batch [30]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.124244,	
2017-06-15 17:36:58,702 Epoch[13] Batch [40]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.120398,	
2017-06-15 17:37:03,400 Epoch[13] Batch [50]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.119497,	
2017-06-15 17:37:08,107 Epoch[13] Batch [60]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.119708,	
2017-06-15 17:37:12,707 Epoch[13] Batch [70]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.123352,	
2017-06-15 17:37:17,308 Epoch[13] Batch [80]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.122663,	
2017-06-15 17:37:21,929 Epoch[13] Batch [90]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121353,	
2017-06-15 17:37:26,525 Epoch[13] Batch [100]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.122038,	
2017-06-15 17:37:31,048 Epoch[13] Batch [110]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.123060,	
2017-06-15 17:37:35,694 Epoch[13] Batch [120]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.123854,	
2017-06-15 17:37:40,209 Epoch[13] Batch [130]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.124394,	
2017-06-15 17:37:44,754 Epoch[13] Batch [140]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.124701,	
2017-06-15 17:37:49,517 Epoch[13] Batch [150]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.125632,	
2017-06-15 17:37:54,037 Epoch[13] Batch [160]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.126396,	
2017-06-15 17:37:58,768 Epoch[13] Batch [170]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.126783,	
2017-06-15 17:38:03,405 Epoch[13] Batch [180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.126282,	
2017-06-15 17:38:08,079 Epoch[13] Batch [190]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.125864,	
2017-06-15 17:38:12,938 Epoch[13] Batch [200]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.126452,	
2017-06-15 17:38:17,651 Epoch[13] Batch [210]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.125866,	
2017-06-15 17:38:22,242 Epoch[13] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.125623,	
2017-06-15 17:38:26,892 Epoch[13] Batch [230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.125229,	
2017-06-15 17:38:31,557 Epoch[13] Batch [240]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.124606,	
2017-06-15 17:38:36,108 Epoch[13] Batch [250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.124671,	
2017-06-15 17:38:40,653 Epoch[13] Batch [260]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.124748,	
2017-06-15 17:38:45,288 Epoch[13] Batch [270]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.124798,	
2017-06-15 17:38:49,954 Epoch[13] Batch [280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.124848,	
2017-06-15 17:38:54,582 Epoch[13] Batch [290]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.124769,	
2017-06-15 17:38:59,377 Epoch[13] Batch [300]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.124498,	
2017-06-15 17:39:04,377 Epoch[13] Batch [310]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.124288,	
2017-06-15 17:39:09,060 Epoch[13] Batch [320]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.124289,	
2017-06-15 17:39:13,807 Epoch[13] Batch [330]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.124649,	
2017-06-15 17:39:18,388 Epoch[13] Batch [340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.124054,	
2017-06-15 17:39:23,077 Epoch[13] Batch [350]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.124108,	
2017-06-15 17:39:27,743 Epoch[13] Batch [360]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.124191,	
2017-06-15 17:39:32,255 Epoch[13] Batch [370]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.124411,	
2017-06-15 17:39:36,905 Epoch[13] Batch [380]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.124276,	
2017-06-15 17:39:41,564 Epoch[13] Batch [390]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.124054,	
2017-06-15 17:39:46,263 Epoch[13] Batch [400]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.124499,	
2017-06-15 17:39:50,816 Epoch[13] Batch [410]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.124285,	
2017-06-15 17:39:55,497 Epoch[13] Batch [420]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.124213,	
2017-06-15 17:40:00,440 Epoch[13] Batch [430]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.124560,	
2017-06-15 17:40:05,022 Epoch[13] Batch [440]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.124065,	
2017-06-15 17:40:09,544 Epoch[13] Batch [450]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.124206,	
2017-06-15 17:40:14,145 Epoch[13] Batch [460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.123981,	
2017-06-15 17:40:18,747 Epoch[13] Batch [470]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.123883,	
2017-06-15 17:40:23,281 Epoch[13] Batch [480]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.123604,	
2017-06-15 17:40:27,833 Epoch[13] Batch [490]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.123341,	
2017-06-15 17:40:32,382 Epoch[13] Batch [500]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.122996,	
2017-06-15 17:40:37,094 Epoch[13] Batch [510]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.123147,	
2017-06-15 17:40:41,768 Epoch[13] Batch [520]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.122813,	
2017-06-15 17:40:46,523 Epoch[13] Batch [530]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.122812,	
2017-06-15 17:40:51,049 Epoch[13] Batch [540]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.122639,	
2017-06-15 17:40:55,563 Epoch[13] Batch [550]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.122635,	
2017-06-15 17:41:00,273 Epoch[13] Batch [560]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.122533,	
2017-06-15 17:41:04,962 Epoch[13] Batch [570]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.122425,	
2017-06-15 17:41:09,562 Epoch[13] Batch [580]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.122176,	
2017-06-15 17:41:14,169 Epoch[13] Batch [590]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.122251,	
2017-06-15 17:41:18,807 Epoch[13] Batch [600]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121756,	
2017-06-15 17:41:23,398 Epoch[13] Batch [610]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.121821,	
2017-06-15 17:41:28,007 Epoch[13] Batch [620]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.121776,	
2017-06-15 17:41:32,641 Epoch[13] Batch [630]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121853,	
2017-06-15 17:41:37,167 Epoch[13] Batch [640]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.121647,	
2017-06-15 17:41:41,868 Epoch[13] Batch [650]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.121400,	
2017-06-15 17:41:46,449 Epoch[13] Batch [660]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.121403,	
2017-06-15 17:41:51,038 Epoch[13] Batch [670]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.121301,	
2017-06-15 17:41:55,687 Epoch[13] Batch [680]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.121242,	
2017-06-15 17:42:00,383 Epoch[13] Batch [690]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.121095,	
2017-06-15 17:42:05,142 Epoch[13] Batch [700]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.121078,	
2017-06-15 17:42:09,717 Epoch[13] Batch [710]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.120941,	
2017-06-15 17:42:14,353 Epoch[13] Batch [720]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121024,	
2017-06-15 17:42:18,939 Epoch[13] Batch [730]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.120907,	
2017-06-15 17:42:23,847 Epoch[13] Batch [740]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.120829,	
2017-06-15 17:42:28,667 Epoch[13] Batch [750]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.120677,	
2017-06-15 17:42:33,306 Epoch[13] Batch [760]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.120779,	
2017-06-15 17:42:37,835 Epoch[13] Batch [770]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.120583,	
2017-06-15 17:42:42,413 Epoch[13] Batch [780]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.120523,	
2017-06-15 17:42:47,044 Epoch[13] Batch [790]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.120674,	
2017-06-15 17:42:51,701 Epoch[13] Batch [800]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.120698,	
2017-06-15 17:42:56,246 Epoch[13] Batch [810]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120678,	
2017-06-15 17:43:00,790 Epoch[13] Batch [820]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120584,	
2017-06-15 17:43:05,401 Epoch[13] Batch [830]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.120482,	
2017-06-15 17:43:09,968 Epoch[13] Batch [840]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.120537,	
2017-06-15 17:43:14,674 Epoch[13] Batch [850]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.120571,	
2017-06-15 17:43:19,246 Epoch[13] Batch [860]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.120414,	
2017-06-15 17:43:23,818 Epoch[13] Batch [870]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.120738,	
2017-06-15 17:43:28,476 Epoch[13] Batch [880]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.120788,	
2017-06-15 17:43:33,021 Epoch[13] Batch [890]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120982,	
2017-06-15 17:43:37,601 Epoch[13] Batch [900]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.121199,	
2017-06-15 17:43:42,204 Epoch[13] Batch [910]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121613,	
2017-06-15 17:43:46,780 Epoch[13] Batch [920]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.121757,	
2017-06-15 17:43:51,391 Epoch[13] Batch [930]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.121908,	
2017-06-15 17:43:55,980 Epoch[13] Batch [940]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.121963,	
2017-06-15 17:44:00,886 Epoch[13] Batch [950]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.122057,	
2017-06-15 17:44:05,454 Epoch[13] Batch [960]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.122007,	
2017-06-15 17:44:09,994 Epoch[13] Batch [970]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.121944,	
2017-06-15 17:44:14,680 Epoch[13] Batch [980]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121954,	
2017-06-15 17:44:19,230 Epoch[13] Batch [990]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121861,	
2017-06-15 17:44:23,929 Epoch[13] Batch [1000]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.121804,	
2017-06-15 17:44:28,502 Epoch[13] Batch [1010]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.122015,	
2017-06-15 17:44:33,070 Epoch[13] Batch [1020]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.121900,	
2017-06-15 17:44:37,715 Epoch[13] Batch [1030]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.121951,	
2017-06-15 17:44:42,442 Epoch[13] Batch [1040]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121863,	
2017-06-15 17:44:47,062 Epoch[13] Batch [1050]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121856,	
2017-06-15 17:44:51,605 Epoch[13] Batch [1060]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.121880,	
2017-06-15 17:44:56,209 Epoch[13] Batch [1070]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121964,	
2017-06-15 17:45:00,755 Epoch[13] Batch [1080]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.121888,	
2017-06-15 17:45:05,623 Epoch[13] Batch [1090]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.121895,	
2017-06-15 17:45:10,062 Epoch[13] Batch [1100]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.121924,	
2017-06-15 17:45:14,736 Epoch[13] Batch [1110]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121876,	
2017-06-15 17:45:19,267 Epoch[13] Batch [1120]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.121774,	
2017-06-15 17:45:23,952 Epoch[13] Batch [1130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121747,	
2017-06-15 17:45:28,590 Epoch[13] Batch [1140]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121684,	
2017-06-15 17:45:33,499 Epoch[13] Batch [1150]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.121737,	
2017-06-15 17:45:38,134 Epoch[13] Batch [1160]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121694,	
2017-06-15 17:45:42,713 Epoch[13] Batch [1170]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.121662,	
2017-06-15 17:45:47,379 Epoch[13] Batch [1180]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.121646,	
2017-06-15 17:45:52,010 Epoch[13] Batch [1190]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.121619,	
2017-06-15 17:45:56,612 Epoch[13] Batch [1200]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121670,	
2017-06-15 17:46:01,381 Epoch[13] Batch [1210]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.121469,	
2017-06-15 17:46:06,021 Epoch[13] Batch [1220]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.121470,	
2017-06-15 17:46:10,696 Epoch[13] Batch [1230]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121477,	
2017-06-15 17:46:15,314 Epoch[13] Batch [1240]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121403,	
2017-06-15 17:46:19,868 Epoch[13] Batch [1250]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.121482,	
2017-06-15 17:46:24,452 Epoch[13] Batch [1260]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.121406,	
2017-06-15 17:46:29,081 Epoch[13] Batch [1270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.121369,	
2017-06-15 17:46:33,582 Epoch[13] Batch [1280]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.121369,	
2017-06-15 17:46:38,192 Epoch[13] Batch [1290]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.121306,	
2017-06-15 17:46:42,868 Epoch[13] Batch [1300]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121233,	
2017-06-15 17:46:47,580 Epoch[13] Batch [1310]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.121134,	
2017-06-15 17:46:52,142 Epoch[13] Batch [1320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.121184,	
2017-06-15 17:46:56,688 Epoch[13] Batch [1330]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.121450,	
2017-06-15 17:47:01,327 Epoch[13] Batch [1340]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.121653,	
2017-06-15 17:47:06,205 Epoch[13] Batch [1350]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.121904,	
2017-06-15 17:47:10,765 Epoch[13] Batch [1360]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.122083,	
2017-06-15 17:47:15,462 Epoch[13] Batch [1370]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.122163,	
2017-06-15 17:47:20,139 Epoch[13] Batch [1380]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.122211,	
2017-06-15 17:47:24,853 Epoch[13] Batch [1390]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.122262,	
2017-06-15 17:47:29,440 Epoch[13] Batch [1400]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.122241,	
2017-06-15 17:47:34,184 Epoch[13] Batch [1410]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.122240,	
2017-06-15 17:47:39,053 Epoch[13] Batch [1420]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.122280,	
2017-06-15 17:47:43,828 Epoch[13] Batch [1430]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.122396,	
2017-06-15 17:47:48,705 Epoch[13] Batch [1440]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.122333,	
2017-06-15 17:47:53,445 Epoch[13] Batch [1450]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.122296,	
2017-06-15 17:47:57,979 Epoch[13] Batch [1460]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.122226,	
2017-06-15 17:48:02,622 Epoch[13] Batch [1470]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.122214,	
2017-06-15 17:48:07,210 Epoch[13] Batch [1480]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.122236,	
2017-06-15 17:48:09,826 Epoch[13] Train-FCNLogLoss=0.122263
2017-06-15 17:48:09,826 Epoch[13] Time cost=690.694
2017-06-15 17:48:10,523 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0014.params"
2017-06-15 17:48:12,218 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0014.states"
2017-06-15 17:48:17,880 Epoch[14] Batch [10]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.134861,	
2017-06-15 17:48:22,405 Epoch[14] Batch [20]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.134466,	
2017-06-15 17:48:27,017 Epoch[14] Batch [30]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.132379,	
2017-06-15 17:48:31,679 Epoch[14] Batch [40]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.130545,	
2017-06-15 17:48:36,273 Epoch[14] Batch [50]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.129675,	
2017-06-15 17:48:40,885 Epoch[14] Batch [60]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.129656,	
2017-06-15 17:48:45,515 Epoch[14] Batch [70]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.131031,	
2017-06-15 17:48:50,064 Epoch[14] Batch [80]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128036,	
2017-06-15 17:48:54,580 Epoch[14] Batch [90]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.126682,	
2017-06-15 17:48:59,216 Epoch[14] Batch [100]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.125789,	
2017-06-15 17:49:03,737 Epoch[14] Batch [110]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.125789,	
2017-06-15 17:49:08,364 Epoch[14] Batch [120]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.125394,	
2017-06-15 17:49:12,949 Epoch[14] Batch [130]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.125942,	
2017-06-15 17:49:17,514 Epoch[14] Batch [140]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.124984,	
2017-06-15 17:49:22,027 Epoch[14] Batch [150]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.124742,	
2017-06-15 17:49:26,643 Epoch[14] Batch [160]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.125805,	
2017-06-15 17:49:31,195 Epoch[14] Batch [170]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.126000,	
2017-06-15 17:49:35,737 Epoch[14] Batch [180]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.127540,	
2017-06-15 17:49:40,299 Epoch[14] Batch [190]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.128133,	
2017-06-15 17:49:44,873 Epoch[14] Batch [200]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.127538,	
2017-06-15 17:49:49,484 Epoch[14] Batch [210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.128107,	
2017-06-15 17:49:54,039 Epoch[14] Batch [220]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.127972,	
2017-06-15 17:49:58,525 Epoch[14] Batch [230]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.128595,	
2017-06-15 17:50:03,133 Epoch[14] Batch [240]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.128277,	
2017-06-15 17:50:07,857 Epoch[14] Batch [250]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.127658,	
2017-06-15 17:50:12,435 Epoch[14] Batch [260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.127734,	
2017-06-15 17:50:17,070 Epoch[14] Batch [270]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.127287,	
2017-06-15 17:50:21,689 Epoch[14] Batch [280]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.127423,	
2017-06-15 17:50:26,307 Epoch[14] Batch [290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.127474,	
2017-06-15 17:50:30,862 Epoch[14] Batch [300]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.126726,	
2017-06-15 17:50:35,498 Epoch[14] Batch [310]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.126442,	
2017-06-15 17:50:40,032 Epoch[14] Batch [320]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.125948,	
2017-06-15 17:50:44,821 Epoch[14] Batch [330]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.125755,	
2017-06-15 17:50:49,361 Epoch[14] Batch [340]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.125545,	
2017-06-15 17:50:53,991 Epoch[14] Batch [350]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.125715,	
2017-06-15 17:50:58,641 Epoch[14] Batch [360]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.124682,	
2017-06-15 17:51:03,187 Epoch[14] Batch [370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.124320,	
2017-06-15 17:51:07,782 Epoch[14] Batch [380]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.124368,	
2017-06-15 17:51:12,392 Epoch[14] Batch [390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.124658,	
2017-06-15 17:51:16,984 Epoch[14] Batch [400]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.124797,	
2017-06-15 17:51:21,708 Epoch[14] Batch [410]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.125158,	
2017-06-15 17:51:26,515 Epoch[14] Batch [420]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.125147,	
2017-06-15 17:51:31,158 Epoch[14] Batch [430]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.124897,	
2017-06-15 17:51:35,703 Epoch[14] Batch [440]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.125089,	
2017-06-15 17:51:40,444 Epoch[14] Batch [450]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.124907,	
2017-06-15 17:51:45,077 Epoch[14] Batch [460]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.124431,	
2017-06-15 17:51:49,715 Epoch[14] Batch [470]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.124225,	
2017-06-15 17:51:54,657 Epoch[14] Batch [480]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.124126,	
2017-06-15 17:51:59,568 Epoch[14] Batch [490]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.123977,	
2017-06-15 17:52:04,868 Epoch[14] Batch [500]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.123778,	
2017-06-15 17:52:09,980 Epoch[14] Batch [510]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.123628,	
2017-06-15 17:52:14,591 Epoch[14] Batch [520]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.123439,	
2017-06-15 17:52:19,311 Epoch[14] Batch [530]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.123636,	
2017-06-15 17:52:24,157 Epoch[14] Batch [540]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.123734,	
2017-06-15 17:52:28,886 Epoch[14] Batch [550]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.123397,	
2017-06-15 17:52:33,532 Epoch[14] Batch [560]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.123261,	
2017-06-15 17:52:38,057 Epoch[14] Batch [570]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.123135,	
2017-06-15 17:52:42,722 Epoch[14] Batch [580]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.122987,	
2017-06-15 17:52:47,440 Epoch[14] Batch [590]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.122832,	
2017-06-15 17:52:51,924 Epoch[14] Batch [600]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.122517,	
2017-06-15 17:52:56,502 Epoch[14] Batch [610]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.122275,	
2017-06-15 17:53:01,124 Epoch[14] Batch [620]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.122280,	
2017-06-15 17:53:06,238 Epoch[14] Batch [630]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.122414,	
2017-06-15 17:53:11,021 Epoch[14] Batch [640]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.122212,	
2017-06-15 17:53:16,127 Epoch[14] Batch [650]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.122009,	
2017-06-15 17:53:21,078 Epoch[14] Batch [660]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.121910,	
2017-06-15 17:53:25,940 Epoch[14] Batch [670]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.121987,	
2017-06-15 17:53:30,766 Epoch[14] Batch [680]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.122163,	
2017-06-15 17:53:35,602 Epoch[14] Batch [690]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.121781,	
2017-06-15 17:53:40,698 Epoch[14] Batch [700]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.121931,	
2017-06-15 17:53:45,698 Epoch[14] Batch [710]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.122142,	
2017-06-15 17:53:50,708 Epoch[14] Batch [720]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.122105,	
2017-06-15 17:53:55,546 Epoch[14] Batch [730]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.122121,	
2017-06-15 17:54:00,453 Epoch[14] Batch [740]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.122149,	
2017-06-15 17:54:05,414 Epoch[14] Batch [750]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.122184,	
2017-06-15 17:54:10,444 Epoch[14] Batch [760]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.121993,	
2017-06-15 17:54:15,648 Epoch[14] Batch [770]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.121896,	
2017-06-15 17:54:20,488 Epoch[14] Batch [780]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.122288,	
2017-06-15 17:54:25,224 Epoch[14] Batch [790]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.122181,	
2017-06-15 17:54:30,138 Epoch[14] Batch [800]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.122193,	
2017-06-15 17:54:34,917 Epoch[14] Batch [810]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.122184,	
2017-06-15 17:54:39,748 Epoch[14] Batch [820]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.121994,	
2017-06-15 17:54:44,770 Epoch[14] Batch [830]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.121786,	
2017-06-15 17:54:49,515 Epoch[14] Batch [840]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.121771,	
2017-06-15 17:54:54,505 Epoch[14] Batch [850]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.121724,	
2017-06-15 17:54:59,263 Epoch[14] Batch [860]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.121814,	
2017-06-15 17:55:04,406 Epoch[14] Batch [870]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.121870,	
2017-06-15 17:55:09,243 Epoch[14] Batch [880]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.121704,	
2017-06-15 17:55:14,598 Epoch[14] Batch [890]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121762,	
2017-06-15 17:55:20,192 Epoch[14] Batch [900]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.121795,	
2017-06-15 17:55:24,900 Epoch[14] Batch [910]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121788,	
2017-06-15 17:55:29,618 Epoch[14] Batch [920]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.121911,	
2017-06-15 17:55:34,276 Epoch[14] Batch [930]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.121802,	
2017-06-15 17:55:38,892 Epoch[14] Batch [940]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.121858,	
2017-06-15 17:55:43,598 Epoch[14] Batch [950]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121731,	
2017-06-15 17:55:48,516 Epoch[14] Batch [960]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.121776,	
2017-06-15 17:55:53,428 Epoch[14] Batch [970]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.121695,	
2017-06-15 17:55:58,335 Epoch[14] Batch [980]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.121583,	
2017-06-15 17:56:03,267 Epoch[14] Batch [990]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.121563,	
2017-06-15 17:56:08,042 Epoch[14] Batch [1000]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.121527,	
2017-06-15 17:56:12,748 Epoch[14] Batch [1010]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121481,	
2017-06-15 17:56:17,465 Epoch[14] Batch [1020]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.121481,	
2017-06-15 17:56:22,224 Epoch[14] Batch [1030]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.121441,	
2017-06-15 17:56:26,825 Epoch[14] Batch [1040]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121481,	
2017-06-15 17:56:31,697 Epoch[14] Batch [1050]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.121413,	
2017-06-15 17:56:36,279 Epoch[14] Batch [1060]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.121285,	
2017-06-15 17:56:40,989 Epoch[14] Batch [1070]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.121241,	
2017-06-15 17:56:46,067 Epoch[14] Batch [1080]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.121359,	
2017-06-15 17:56:51,029 Epoch[14] Batch [1090]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.121321,	
2017-06-15 17:56:55,914 Epoch[14] Batch [1100]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.121248,	
2017-06-15 17:57:00,597 Epoch[14] Batch [1110]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121202,	
2017-06-15 17:57:05,367 Epoch[14] Batch [1120]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.121253,	
2017-06-15 17:57:10,320 Epoch[14] Batch [1130]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.121224,	
2017-06-15 17:57:15,520 Epoch[14] Batch [1140]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.121464,	
2017-06-15 17:57:20,728 Epoch[14] Batch [1150]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.122483,	
2017-06-15 17:57:25,627 Epoch[14] Batch [1160]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.122947,	
2017-06-15 17:57:30,361 Epoch[14] Batch [1170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.122990,	
2017-06-15 17:57:35,523 Epoch[14] Batch [1180]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.123192,	
2017-06-15 17:57:40,154 Epoch[14] Batch [1190]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.123427,	
2017-06-15 17:57:44,814 Epoch[14] Batch [1200]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.123498,	
2017-06-15 17:57:49,561 Epoch[14] Batch [1210]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.123571,	
2017-06-15 17:57:54,649 Epoch[14] Batch [1220]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.123707,	
2017-06-15 17:57:59,746 Epoch[14] Batch [1230]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.123648,	
2017-06-15 17:58:04,515 Epoch[14] Batch [1240]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.123579,	
2017-06-15 17:58:09,243 Epoch[14] Batch [1250]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.123630,	
2017-06-15 17:58:13,891 Epoch[14] Batch [1260]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.123675,	
2017-06-15 17:58:18,517 Epoch[14] Batch [1270]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123649,	
2017-06-15 17:58:23,019 Epoch[14] Batch [1280]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.123668,	
2017-06-15 17:58:27,543 Epoch[14] Batch [1290]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.123737,	
2017-06-15 17:58:32,038 Epoch[14] Batch [1300]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.123574,	
2017-06-15 17:58:36,686 Epoch[14] Batch [1310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.123484,	
2017-06-15 17:58:41,258 Epoch[14] Batch [1320]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.123615,	
2017-06-15 17:58:45,765 Epoch[14] Batch [1330]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.123539,	
2017-06-15 17:58:50,386 Epoch[14] Batch [1340]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.123426,	
2017-06-15 17:58:54,962 Epoch[14] Batch [1350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.123413,	
2017-06-15 17:58:59,609 Epoch[14] Batch [1360]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.123419,	
2017-06-15 17:59:04,225 Epoch[14] Batch [1370]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.123431,	
2017-06-15 17:59:08,864 Epoch[14] Batch [1380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.123439,	
2017-06-15 17:59:13,473 Epoch[14] Batch [1390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.123492,	
2017-06-15 17:59:18,007 Epoch[14] Batch [1400]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.123478,	
2017-06-15 17:59:22,544 Epoch[14] Batch [1410]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.123512,	
2017-06-15 17:59:27,134 Epoch[14] Batch [1420]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.123434,	
2017-06-15 17:59:31,611 Epoch[14] Batch [1430]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.123400,	
2017-06-15 17:59:36,223 Epoch[14] Batch [1440]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.123299,	
2017-06-15 17:59:40,892 Epoch[14] Batch [1450]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.123223,	
2017-06-15 17:59:45,479 Epoch[14] Batch [1460]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.123054,	
2017-06-15 17:59:50,118 Epoch[14] Batch [1470]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.123075,	
2017-06-15 17:59:54,645 Epoch[14] Batch [1480]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.123140,	
2017-06-15 17:59:57,387 Epoch[14] Train-FCNLogLoss=0.123126
2017-06-15 17:59:57,387 Epoch[14] Time cost=705.169
2017-06-15 17:59:58,546 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0015.params"
2017-06-15 18:00:00,473 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0015.states"
2017-06-15 18:00:05,828 Epoch[15] Batch [10]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121397,	
2017-06-15 18:00:10,385 Epoch[15] Batch [20]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.118360,	
2017-06-15 18:00:14,997 Epoch[15] Batch [30]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.122047,	
2017-06-15 18:00:19,555 Epoch[15] Batch [40]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.120923,	
2017-06-15 18:00:24,186 Epoch[15] Batch [50]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.122593,	
2017-06-15 18:00:28,755 Epoch[15] Batch [60]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.121137,	
2017-06-15 18:00:33,411 Epoch[15] Batch [70]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.121208,	
2017-06-15 18:00:37,933 Epoch[15] Batch [80]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.120440,	
2017-06-15 18:00:42,578 Epoch[15] Batch [90]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.118689,	
2017-06-15 18:00:47,077 Epoch[15] Batch [100]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.119066,	
2017-06-15 18:00:51,604 Epoch[15] Batch [110]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.119490,	
2017-06-15 18:00:56,223 Epoch[15] Batch [120]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.119521,	
2017-06-15 18:01:00,804 Epoch[15] Batch [130]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.121426,	
2017-06-15 18:01:05,333 Epoch[15] Batch [140]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.120837,	
2017-06-15 18:01:09,978 Epoch[15] Batch [150]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.120586,	
2017-06-15 18:01:14,524 Epoch[15] Batch [160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120621,	
2017-06-15 18:01:19,071 Epoch[15] Batch [170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120211,	
2017-06-15 18:01:23,745 Epoch[15] Batch [180]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.119507,	
2017-06-15 18:01:28,530 Epoch[15] Batch [190]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.118765,	
2017-06-15 18:01:33,133 Epoch[15] Batch [200]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.118603,	
2017-06-15 18:01:37,789 Epoch[15] Batch [210]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.118658,	
2017-06-15 18:01:42,239 Epoch[15] Batch [220]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.118618,	
2017-06-15 18:01:46,790 Epoch[15] Batch [230]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.118352,	
2017-06-15 18:01:51,323 Epoch[15] Batch [240]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.118482,	
2017-06-15 18:01:56,038 Epoch[15] Batch [250]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.118303,	
2017-06-15 18:02:00,566 Epoch[15] Batch [260]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.118474,	
2017-06-15 18:02:05,212 Epoch[15] Batch [270]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.118142,	
2017-06-15 18:02:09,743 Epoch[15] Batch [280]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.118230,	
2017-06-15 18:02:14,281 Epoch[15] Batch [290]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.118651,	
2017-06-15 18:02:19,229 Epoch[15] Batch [300]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.118441,	
2017-06-15 18:02:23,850 Epoch[15] Batch [310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.118430,	
2017-06-15 18:02:28,343 Epoch[15] Batch [320]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.118547,	
2017-06-15 18:02:32,969 Epoch[15] Batch [330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.118496,	
2017-06-15 18:02:37,566 Epoch[15] Batch [340]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.118155,	
2017-06-15 18:02:42,078 Epoch[15] Batch [350]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.118075,	
2017-06-15 18:02:46,699 Epoch[15] Batch [360]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.118039,	
2017-06-15 18:02:51,304 Epoch[15] Batch [370]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.117850,	
2017-06-15 18:02:55,884 Epoch[15] Batch [380]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117937,	
2017-06-15 18:03:00,490 Epoch[15] Batch [390]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.117957,	
2017-06-15 18:03:04,941 Epoch[15] Batch [400]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.118016,	
2017-06-15 18:03:09,489 Epoch[15] Batch [410]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.118170,	
2017-06-15 18:03:13,976 Epoch[15] Batch [420]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.118275,	
2017-06-15 18:03:18,643 Epoch[15] Batch [430]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.118863,	
2017-06-15 18:03:23,272 Epoch[15] Batch [440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.118422,	
2017-06-15 18:03:27,821 Epoch[15] Batch [450]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.118454,	
2017-06-15 18:03:32,425 Epoch[15] Batch [460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.118564,	
2017-06-15 18:03:36,972 Epoch[15] Batch [470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.118286,	
2017-06-15 18:03:41,817 Epoch[15] Batch [480]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.118238,	
2017-06-15 18:03:46,427 Epoch[15] Batch [490]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.118090,	
2017-06-15 18:03:50,952 Epoch[15] Batch [500]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.117832,	
2017-06-15 18:03:55,575 Epoch[15] Batch [510]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.117804,	
2017-06-15 18:04:00,161 Epoch[15] Batch [520]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.117965,	
2017-06-15 18:04:04,768 Epoch[15] Batch [530]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.118037,	
2017-06-15 18:04:09,339 Epoch[15] Batch [540]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.117955,	
2017-06-15 18:04:13,895 Epoch[15] Batch [550]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.117690,	
2017-06-15 18:04:18,664 Epoch[15] Batch [560]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.117662,	
2017-06-15 18:04:23,313 Epoch[15] Batch [570]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.117677,	
2017-06-15 18:04:27,808 Epoch[15] Batch [580]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.117693,	
2017-06-15 18:04:32,367 Epoch[15] Batch [590]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.117672,	
2017-06-15 18:04:36,931 Epoch[15] Batch [600]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.117642,	
2017-06-15 18:04:41,560 Epoch[15] Batch [610]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.117835,	
2017-06-15 18:04:46,092 Epoch[15] Batch [620]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.117740,	
2017-06-15 18:04:50,715 Epoch[15] Batch [630]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.117766,	
2017-06-15 18:04:55,195 Epoch[15] Batch [640]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.117762,	
2017-06-15 18:04:59,763 Epoch[15] Batch [650]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.117562,	
2017-06-15 18:05:04,409 Epoch[15] Batch [660]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.117560,	
2017-06-15 18:05:08,950 Epoch[15] Batch [670]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.117600,	
2017-06-15 18:05:13,562 Epoch[15] Batch [680]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.117560,	
2017-06-15 18:05:18,165 Epoch[15] Batch [690]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.117484,	
2017-06-15 18:05:22,781 Epoch[15] Batch [700]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.117504,	
2017-06-15 18:05:27,277 Epoch[15] Batch [710]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.117438,	
2017-06-15 18:05:32,306 Epoch[15] Batch [720]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.117469,	
2017-06-15 18:05:37,157 Epoch[15] Batch [730]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.117377,	
2017-06-15 18:05:41,676 Epoch[15] Batch [740]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.117293,	
2017-06-15 18:05:46,248 Epoch[15] Batch [750]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.117301,	
2017-06-15 18:05:50,832 Epoch[15] Batch [760]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117412,	
2017-06-15 18:05:55,639 Epoch[15] Batch [770]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.117609,	
2017-06-15 18:06:00,411 Epoch[15] Batch [780]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.117790,	
2017-06-15 18:06:04,985 Epoch[15] Batch [790]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.118083,	
2017-06-15 18:06:09,615 Epoch[15] Batch [800]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.118045,	
2017-06-15 18:06:14,198 Epoch[15] Batch [810]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117963,	
2017-06-15 18:06:18,931 Epoch[15] Batch [820]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.117987,	
2017-06-15 18:06:23,512 Epoch[15] Batch [830]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117829,	
2017-06-15 18:06:28,034 Epoch[15] Batch [840]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.117824,	
2017-06-15 18:06:32,648 Epoch[15] Batch [850]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.117683,	
2017-06-15 18:06:37,126 Epoch[15] Batch [860]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.117629,	
2017-06-15 18:06:41,709 Epoch[15] Batch [870]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117522,	
2017-06-15 18:06:46,314 Epoch[15] Batch [880]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.117436,	
2017-06-15 18:06:51,000 Epoch[15] Batch [890]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.117338,	
2017-06-15 18:06:55,555 Epoch[15] Batch [900]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.117276,	
2017-06-15 18:07:00,112 Epoch[15] Batch [910]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.117426,	
2017-06-15 18:07:04,689 Epoch[15] Batch [920]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.117872,	
2017-06-15 18:07:09,361 Epoch[15] Batch [930]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.117890,	
2017-06-15 18:07:13,988 Epoch[15] Batch [940]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.117941,	
2017-06-15 18:07:18,824 Epoch[15] Batch [950]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.117963,	
2017-06-15 18:07:23,285 Epoch[15] Batch [960]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.118066,	
2017-06-15 18:07:27,872 Epoch[15] Batch [970]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.118227,	
2017-06-15 18:07:32,478 Epoch[15] Batch [980]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.118284,	
2017-06-15 18:07:37,005 Epoch[15] Batch [990]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.118359,	
2017-06-15 18:07:41,644 Epoch[15] Batch [1000]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.118392,	
2017-06-15 18:07:46,272 Epoch[15] Batch [1010]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.118602,	
2017-06-15 18:07:50,880 Epoch[15] Batch [1020]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.118625,	
2017-06-15 18:07:55,452 Epoch[15] Batch [1030]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.118505,	
2017-06-15 18:08:00,006 Epoch[15] Batch [1040]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.118410,	
2017-06-15 18:08:04,584 Epoch[15] Batch [1050]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.118472,	
2017-06-15 18:08:09,304 Epoch[15] Batch [1060]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.118588,	
2017-06-15 18:08:13,919 Epoch[15] Batch [1070]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.118505,	
2017-06-15 18:08:18,462 Epoch[15] Batch [1080]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.118609,	
2017-06-15 18:08:23,038 Epoch[15] Batch [1090]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.118690,	
2017-06-15 18:08:27,520 Epoch[15] Batch [1100]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.118644,	
2017-06-15 18:08:32,019 Epoch[15] Batch [1110]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.118595,	
2017-06-15 18:08:36,738 Epoch[15] Batch [1120]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.118478,	
2017-06-15 18:08:41,214 Epoch[15] Batch [1130]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.118591,	
2017-06-15 18:08:45,896 Epoch[15] Batch [1140]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.118560,	
2017-06-15 18:08:50,643 Epoch[15] Batch [1150]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.118609,	
2017-06-15 18:08:55,265 Epoch[15] Batch [1160]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.118483,	
2017-06-15 18:08:59,838 Epoch[15] Batch [1170]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.118411,	
2017-06-15 18:09:04,411 Epoch[15] Batch [1180]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.118348,	
2017-06-15 18:09:09,115 Epoch[15] Batch [1190]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.118325,	
2017-06-15 18:09:13,650 Epoch[15] Batch [1200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.118262,	
2017-06-15 18:09:18,278 Epoch[15] Batch [1210]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.118217,	
2017-06-15 18:09:22,993 Epoch[15] Batch [1220]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.118255,	
2017-06-15 18:09:27,726 Epoch[15] Batch [1230]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.118340,	
2017-06-15 18:09:32,212 Epoch[15] Batch [1240]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.118835,	
2017-06-15 18:09:36,740 Epoch[15] Batch [1250]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.118873,	
2017-06-15 18:09:41,415 Epoch[15] Batch [1260]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.118908,	
2017-06-15 18:09:45,982 Epoch[15] Batch [1270]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.118836,	
2017-06-15 18:09:50,562 Epoch[15] Batch [1280]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.118822,	
2017-06-15 18:09:54,976 Epoch[15] Batch [1290]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.118900,	
2017-06-15 18:09:59,565 Epoch[15] Batch [1300]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.118946,	
2017-06-15 18:10:04,165 Epoch[15] Batch [1310]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.118980,	
2017-06-15 18:10:08,873 Epoch[15] Batch [1320]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.118980,	
2017-06-15 18:10:13,433 Epoch[15] Batch [1330]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.118970,	
2017-06-15 18:10:18,021 Epoch[15] Batch [1340]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.119029,	
2017-06-15 18:10:22,578 Epoch[15] Batch [1350]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.118969,	
2017-06-15 18:10:27,182 Epoch[15] Batch [1360]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.118954,	
2017-06-15 18:10:32,043 Epoch[15] Batch [1370]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.118941,	
2017-06-15 18:10:36,561 Epoch[15] Batch [1380]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.118943,	
2017-06-15 18:10:41,250 Epoch[15] Batch [1390]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.118876,	
2017-06-15 18:10:45,772 Epoch[15] Batch [1400]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.118841,	
2017-06-15 18:10:50,260 Epoch[15] Batch [1410]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.118849,	
2017-06-15 18:10:54,869 Epoch[15] Batch [1420]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.118891,	
2017-06-15 18:10:59,492 Epoch[15] Batch [1430]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.118801,	
2017-06-15 18:11:04,058 Epoch[15] Batch [1440]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.118744,	
2017-06-15 18:11:08,608 Epoch[15] Batch [1450]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.118716,	
2017-06-15 18:11:13,181 Epoch[15] Batch [1460]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.118639,	
2017-06-15 18:11:17,750 Epoch[15] Batch [1470]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.118647,	
2017-06-15 18:11:22,238 Epoch[15] Batch [1480]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.118678,	
2017-06-15 18:11:24,890 Epoch[15] Train-FCNLogLoss=0.118636
2017-06-15 18:11:24,891 Epoch[15] Time cost=684.417
2017-06-15 18:11:25,558 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0016.params"
2017-06-15 18:11:27,223 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0016.states"
2017-06-15 18:11:32,558 Epoch[16] Batch [10]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.110145,	
2017-06-15 18:11:37,118 Epoch[16] Batch [20]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.111366,	
2017-06-15 18:11:41,619 Epoch[16] Batch [30]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.110742,	
2017-06-15 18:11:46,260 Epoch[16] Batch [40]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.112592,	
2017-06-15 18:11:50,885 Epoch[16] Batch [50]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112454,	
2017-06-15 18:11:55,449 Epoch[16] Batch [60]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.111467,	
2017-06-15 18:12:00,017 Epoch[16] Batch [70]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.113998,	
2017-06-15 18:12:04,725 Epoch[16] Batch [80]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.114768,	
2017-06-15 18:12:09,295 Epoch[16] Batch [90]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.115249,	
2017-06-15 18:12:13,909 Epoch[16] Batch [100]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.117238,	
2017-06-15 18:12:18,478 Epoch[16] Batch [110]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.116887,	
2017-06-15 18:12:23,041 Epoch[16] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.116224,	
2017-06-15 18:12:27,629 Epoch[16] Batch [130]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.115720,	
2017-06-15 18:12:32,230 Epoch[16] Batch [140]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.115900,	
2017-06-15 18:12:36,848 Epoch[16] Batch [150]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.115639,	
2017-06-15 18:12:41,522 Epoch[16] Batch [160]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.116030,	
2017-06-15 18:12:46,035 Epoch[16] Batch [170]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.117938,	
2017-06-15 18:12:50,699 Epoch[16] Batch [180]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.117359,	
2017-06-15 18:12:55,306 Epoch[16] Batch [190]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117128,	
2017-06-15 18:12:59,865 Epoch[16] Batch [200]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.117414,	
2017-06-15 18:13:04,491 Epoch[16] Batch [210]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.117260,	
2017-06-15 18:13:08,977 Epoch[16] Batch [220]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.117371,	
2017-06-15 18:13:13,541 Epoch[16] Batch [230]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.117535,	
2017-06-15 18:13:18,079 Epoch[16] Batch [240]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117480,	
2017-06-15 18:13:22,638 Epoch[16] Batch [250]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.117340,	
2017-06-15 18:13:27,330 Epoch[16] Batch [260]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.117097,	
2017-06-15 18:13:31,812 Epoch[16] Batch [270]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.116765,	
2017-06-15 18:13:36,518 Epoch[16] Batch [280]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.116825,	
2017-06-15 18:13:41,157 Epoch[16] Batch [290]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.116805,	
2017-06-15 18:13:45,696 Epoch[16] Batch [300]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.116985,	
2017-06-15 18:13:50,331 Epoch[16] Batch [310]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.117280,	
2017-06-15 18:13:54,891 Epoch[16] Batch [320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.117114,	
2017-06-15 18:13:59,489 Epoch[16] Batch [330]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.117290,	
2017-06-15 18:14:04,019 Epoch[16] Batch [340]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.117212,	
2017-06-15 18:14:08,510 Epoch[16] Batch [350]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.116926,	
2017-06-15 18:14:13,009 Epoch[16] Batch [360]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.117877,	
2017-06-15 18:14:17,748 Epoch[16] Batch [370]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.117829,	
2017-06-15 18:14:22,505 Epoch[16] Batch [380]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.117979,	
2017-06-15 18:14:27,047 Epoch[16] Batch [390]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.118217,	
2017-06-15 18:14:31,609 Epoch[16] Batch [400]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.118162,	
2017-06-15 18:14:36,118 Epoch[16] Batch [410]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.117850,	
2017-06-15 18:14:40,683 Epoch[16] Batch [420]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.117942,	
2017-06-15 18:14:45,230 Epoch[16] Batch [430]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.117721,	
2017-06-15 18:14:49,803 Epoch[16] Batch [440]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.117546,	
2017-06-15 18:14:54,424 Epoch[16] Batch [450]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.117004,	
2017-06-15 18:14:58,957 Epoch[16] Batch [460]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.116741,	
2017-06-15 18:15:03,614 Epoch[16] Batch [470]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.116582,	
2017-06-15 18:15:08,137 Epoch[16] Batch [480]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.116380,	
2017-06-15 18:15:12,723 Epoch[16] Batch [490]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.116114,	
2017-06-15 18:15:17,345 Epoch[16] Batch [500]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.116228,	
2017-06-15 18:15:21,880 Epoch[16] Batch [510]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.116557,	
2017-06-15 18:15:26,411 Epoch[16] Batch [520]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.116263,	
2017-06-15 18:15:31,060 Epoch[16] Batch [530]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.116070,	
2017-06-15 18:15:35,557 Epoch[16] Batch [540]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116002,	
2017-06-15 18:15:40,184 Epoch[16] Batch [550]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.116062,	
2017-06-15 18:15:44,727 Epoch[16] Batch [560]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.115858,	
2017-06-15 18:15:49,193 Epoch[16] Batch [570]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.115935,	
2017-06-15 18:15:53,787 Epoch[16] Batch [580]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.115952,	
2017-06-15 18:15:58,313 Epoch[16] Batch [590]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.115921,	
2017-06-15 18:16:02,885 Epoch[16] Batch [600]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.115883,	
2017-06-15 18:16:07,528 Epoch[16] Batch [610]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.115993,	
2017-06-15 18:16:12,101 Epoch[16] Batch [620]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.115893,	
2017-06-15 18:16:16,668 Epoch[16] Batch [630]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.115913,	
2017-06-15 18:16:21,284 Epoch[16] Batch [640]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.115811,	
2017-06-15 18:16:25,790 Epoch[16] Batch [650]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.115945,	
2017-06-15 18:16:30,285 Epoch[16] Batch [660]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116124,	
2017-06-15 18:16:34,816 Epoch[16] Batch [670]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.116189,	
2017-06-15 18:16:39,414 Epoch[16] Batch [680]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.116115,	
2017-06-15 18:16:43,971 Epoch[16] Batch [690]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.115900,	
2017-06-15 18:16:48,644 Epoch[16] Batch [700]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.115636,	
2017-06-15 18:16:53,178 Epoch[16] Batch [710]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.115634,	
2017-06-15 18:16:57,655 Epoch[16] Batch [720]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.115694,	
2017-06-15 18:17:02,160 Epoch[16] Batch [730]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.116196,	
2017-06-15 18:17:06,657 Epoch[16] Batch [740]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116289,	
2017-06-15 18:17:11,371 Epoch[16] Batch [750]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.116303,	
2017-06-15 18:17:15,968 Epoch[16] Batch [760]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.116513,	
2017-06-15 18:17:20,659 Epoch[16] Batch [770]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.116529,	
2017-06-15 18:17:25,297 Epoch[16] Batch [780]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.116677,	
2017-06-15 18:17:29,981 Epoch[16] Batch [790]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.116748,	
2017-06-15 18:17:34,469 Epoch[16] Batch [800]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.116698,	
2017-06-15 18:17:39,118 Epoch[16] Batch [810]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.116617,	
2017-06-15 18:17:43,668 Epoch[16] Batch [820]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.116605,	
2017-06-15 18:17:48,310 Epoch[16] Batch [830]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.116502,	
2017-06-15 18:17:52,830 Epoch[16] Batch [840]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.116438,	
2017-06-15 18:17:57,457 Epoch[16] Batch [850]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.116611,	
2017-06-15 18:18:02,066 Epoch[16] Batch [860]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.116431,	
2017-06-15 18:18:06,672 Epoch[16] Batch [870]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.116442,	
2017-06-15 18:18:11,224 Epoch[16] Batch [880]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.116849,	
2017-06-15 18:18:15,883 Epoch[16] Batch [890]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.117011,	
2017-06-15 18:18:20,361 Epoch[16] Batch [900]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.117294,	
2017-06-15 18:18:24,910 Epoch[16] Batch [910]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.117406,	
2017-06-15 18:18:29,535 Epoch[16] Batch [920]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.117329,	
2017-06-15 18:18:34,080 Epoch[16] Batch [930]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.117591,	
2017-06-15 18:18:38,641 Epoch[16] Batch [940]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.117598,	
2017-06-15 18:18:43,208 Epoch[16] Batch [950]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.117517,	
2017-06-15 18:18:47,761 Epoch[16] Batch [960]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.117528,	
2017-06-15 18:18:52,281 Epoch[16] Batch [970]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.117561,	
2017-06-15 18:18:56,944 Epoch[16] Batch [980]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.117613,	
2017-06-15 18:19:01,535 Epoch[16] Batch [990]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.117594,	
2017-06-15 18:19:06,114 Epoch[16] Batch [1000]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.117555,	
2017-06-15 18:19:10,660 Epoch[16] Batch [1010]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.117508,	
2017-06-15 18:19:15,296 Epoch[16] Batch [1020]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.117478,	
2017-06-15 18:19:19,908 Epoch[16] Batch [1030]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.117478,	
2017-06-15 18:19:24,475 Epoch[16] Batch [1040]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.117465,	
2017-06-15 18:19:29,089 Epoch[16] Batch [1050]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.117406,	
2017-06-15 18:19:33,736 Epoch[16] Batch [1060]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.117349,	
2017-06-15 18:19:38,378 Epoch[16] Batch [1070]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.117323,	
2017-06-15 18:19:42,965 Epoch[16] Batch [1080]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.117344,	
2017-06-15 18:19:47,657 Epoch[16] Batch [1090]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.117274,	
2017-06-15 18:19:52,401 Epoch[16] Batch [1100]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.117355,	
2017-06-15 18:19:57,036 Epoch[16] Batch [1110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.117449,	
2017-06-15 18:20:01,548 Epoch[16] Batch [1120]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.117466,	
2017-06-15 18:20:06,264 Epoch[16] Batch [1130]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.117658,	
2017-06-15 18:20:10,980 Epoch[16] Batch [1140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.117736,	
2017-06-15 18:20:16,172 Epoch[16] Batch [1150]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.117744,	
2017-06-15 18:20:20,867 Epoch[16] Batch [1160]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.117608,	
2017-06-15 18:20:25,752 Epoch[16] Batch [1170]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.117545,	
2017-06-15 18:20:30,719 Epoch[16] Batch [1180]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.117651,	
2017-06-15 18:20:35,321 Epoch[16] Batch [1190]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.117603,	
2017-06-15 18:20:39,996 Epoch[16] Batch [1200]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.117614,	
2017-06-15 18:20:44,861 Epoch[16] Batch [1210]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.117576,	
2017-06-15 18:20:49,481 Epoch[16] Batch [1220]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.117736,	
2017-06-15 18:20:54,195 Epoch[16] Batch [1230]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.117576,	
2017-06-15 18:20:58,823 Epoch[16] Batch [1240]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.117914,	
2017-06-15 18:21:03,615 Epoch[16] Batch [1250]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.117841,	
2017-06-15 18:21:08,402 Epoch[16] Batch [1260]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.117819,	
2017-06-15 18:21:13,148 Epoch[16] Batch [1270]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.117856,	
2017-06-15 18:21:17,914 Epoch[16] Batch [1280]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.117984,	
2017-06-15 18:21:22,465 Epoch[16] Batch [1290]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.117983,	
2017-06-15 18:21:27,202 Epoch[16] Batch [1300]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.118050,	
2017-06-15 18:21:31,903 Epoch[16] Batch [1310]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.118008,	
2017-06-15 18:21:36,741 Epoch[16] Batch [1320]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.118012,	
2017-06-15 18:21:41,349 Epoch[16] Batch [1330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117946,	
2017-06-15 18:21:45,956 Epoch[16] Batch [1340]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117848,	
2017-06-15 18:21:50,720 Epoch[16] Batch [1350]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.117849,	
2017-06-15 18:21:55,576 Epoch[16] Batch [1360]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.117831,	
2017-06-15 18:22:00,137 Epoch[16] Batch [1370]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.117790,	
2017-06-15 18:22:05,083 Epoch[16] Batch [1380]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.117721,	
2017-06-15 18:22:09,994 Epoch[16] Batch [1390]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.117563,	
2017-06-15 18:22:15,289 Epoch[16] Batch [1400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.117503,	
2017-06-15 18:22:20,013 Epoch[16] Batch [1410]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.117502,	
2017-06-15 18:22:24,792 Epoch[16] Batch [1420]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.117478,	
2017-06-15 18:22:29,537 Epoch[16] Batch [1430]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.117400,	
2017-06-15 18:22:34,313 Epoch[16] Batch [1440]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.117447,	
2017-06-15 18:22:39,052 Epoch[16] Batch [1450]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.117525,	
2017-06-15 18:22:43,784 Epoch[16] Batch [1460]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.117473,	
2017-06-15 18:22:48,717 Epoch[16] Batch [1470]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.117500,	
2017-06-15 18:22:53,737 Epoch[16] Batch [1480]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.117464,	
2017-06-15 18:22:56,493 Epoch[16] Train-FCNLogLoss=0.117419
2017-06-15 18:22:56,493 Epoch[16] Time cost=689.269
2017-06-15 18:22:57,773 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0017.params"
2017-06-15 18:22:59,909 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0017.states"
2017-06-15 18:23:05,475 Epoch[17] Batch [10]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.115855,	
2017-06-15 18:23:10,263 Epoch[17] Batch [20]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.113229,	
2017-06-15 18:23:15,198 Epoch[17] Batch [30]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.111305,	
2017-06-15 18:23:19,740 Epoch[17] Batch [40]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.115046,	
2017-06-15 18:23:24,329 Epoch[17] Batch [50]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.115840,	
2017-06-15 18:23:29,313 Epoch[17] Batch [60]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.114277,	
2017-06-15 18:23:33,960 Epoch[17] Batch [70]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.113779,	
2017-06-15 18:23:39,202 Epoch[17] Batch [80]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112915,	
2017-06-15 18:23:43,930 Epoch[17] Batch [90]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.113163,	
2017-06-15 18:23:48,490 Epoch[17] Batch [100]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112502,	
2017-06-15 18:23:53,390 Epoch[17] Batch [110]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.111586,	
2017-06-15 18:23:58,205 Epoch[17] Batch [120]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.111864,	
2017-06-15 18:24:02,903 Epoch[17] Batch [130]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.111932,	
2017-06-15 18:24:07,876 Epoch[17] Batch [140]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.112544,	
2017-06-15 18:24:12,594 Epoch[17] Batch [150]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.112332,	
2017-06-15 18:24:17,341 Epoch[17] Batch [160]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.112141,	
2017-06-15 18:24:22,382 Epoch[17] Batch [170]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.111856,	
2017-06-15 18:24:27,075 Epoch[17] Batch [180]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.111629,	
2017-06-15 18:24:31,584 Epoch[17] Batch [190]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111505,	
2017-06-15 18:24:36,247 Epoch[17] Batch [200]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.111322,	
2017-06-15 18:24:40,851 Epoch[17] Batch [210]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.110868,	
2017-06-15 18:24:46,064 Epoch[17] Batch [220]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.110980,	
2017-06-15 18:24:50,889 Epoch[17] Batch [230]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.110965,	
2017-06-15 18:24:55,507 Epoch[17] Batch [240]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.111155,	
2017-06-15 18:24:59,968 Epoch[17] Batch [250]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111124,	
2017-06-15 18:25:04,826 Epoch[17] Batch [260]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.110920,	
2017-06-15 18:25:09,377 Epoch[17] Batch [270]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.110248,	
2017-06-15 18:25:14,168 Epoch[17] Batch [280]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.110069,	
2017-06-15 18:25:19,361 Epoch[17] Batch [290]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.110384,	
2017-06-15 18:25:24,030 Epoch[17] Batch [300]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.110175,	
2017-06-15 18:25:28,720 Epoch[17] Batch [310]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.110261,	
2017-06-15 18:25:33,560 Epoch[17] Batch [320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.110348,	
2017-06-15 18:25:38,294 Epoch[17] Batch [330]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.110063,	
2017-06-15 18:25:43,041 Epoch[17] Batch [340]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.110425,	
2017-06-15 18:25:47,870 Epoch[17] Batch [350]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.110029,	
2017-06-15 18:25:53,036 Epoch[17] Batch [360]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.109845,	
2017-06-15 18:25:57,973 Epoch[17] Batch [370]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.109790,	
2017-06-15 18:26:02,681 Epoch[17] Batch [380]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.110100,	
2017-06-15 18:26:07,848 Epoch[17] Batch [390]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.109842,	
2017-06-15 18:26:12,413 Epoch[17] Batch [400]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109713,	
2017-06-15 18:26:17,248 Epoch[17] Batch [410]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.109899,	
2017-06-15 18:26:21,915 Epoch[17] Batch [420]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.110356,	
2017-06-15 18:26:26,614 Epoch[17] Batch [430]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.110392,	
2017-06-15 18:26:31,359 Epoch[17] Batch [440]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.110206,	
2017-06-15 18:26:36,063 Epoch[17] Batch [450]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.110152,	
2017-06-15 18:26:40,840 Epoch[17] Batch [460]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.110223,	
2017-06-15 18:26:45,553 Epoch[17] Batch [470]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.110216,	
2017-06-15 18:26:50,207 Epoch[17] Batch [480]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.110071,	
2017-06-15 18:26:54,816 Epoch[17] Batch [490]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110132,	
2017-06-15 18:26:59,630 Epoch[17] Batch [500]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.110158,	
2017-06-15 18:27:04,441 Epoch[17] Batch [510]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.110105,	
2017-06-15 18:27:09,088 Epoch[17] Batch [520]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.110077,	
2017-06-15 18:27:13,709 Epoch[17] Batch [530]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.110057,	
2017-06-15 18:27:18,620 Epoch[17] Batch [540]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.110121,	
2017-06-15 18:27:23,297 Epoch[17] Batch [550]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.110359,	
2017-06-15 18:27:28,346 Epoch[17] Batch [560]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.110236,	
2017-06-15 18:27:33,025 Epoch[17] Batch [570]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.110422,	
2017-06-15 18:27:38,127 Epoch[17] Batch [580]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.110492,	
2017-06-15 18:27:42,776 Epoch[17] Batch [590]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.110456,	
2017-06-15 18:27:47,632 Epoch[17] Batch [600]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.110456,	
2017-06-15 18:27:52,252 Epoch[17] Batch [610]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.110777,	
2017-06-15 18:27:56,937 Epoch[17] Batch [620]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.110905,	
2017-06-15 18:28:01,662 Epoch[17] Batch [630]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.111241,	
2017-06-15 18:28:06,203 Epoch[17] Batch [640]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.111531,	
2017-06-15 18:28:10,812 Epoch[17] Batch [650]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.111446,	
2017-06-15 18:28:15,410 Epoch[17] Batch [660]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.111617,	
2017-06-15 18:28:20,011 Epoch[17] Batch [670]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.111688,	
2017-06-15 18:28:24,585 Epoch[17] Batch [680]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.111648,	
2017-06-15 18:28:29,252 Epoch[17] Batch [690]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.111520,	
2017-06-15 18:28:33,702 Epoch[17] Batch [700]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.111337,	
2017-06-15 18:28:38,206 Epoch[17] Batch [710]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.111493,	
2017-06-15 18:28:42,823 Epoch[17] Batch [720]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.111624,	
2017-06-15 18:28:47,336 Epoch[17] Batch [730]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.111738,	
2017-06-15 18:28:51,855 Epoch[17] Batch [740]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.111865,	
2017-06-15 18:28:56,458 Epoch[17] Batch [750]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.112002,	
2017-06-15 18:29:01,189 Epoch[17] Batch [760]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.112107,	
2017-06-15 18:29:05,728 Epoch[17] Batch [770]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112086,	
2017-06-15 18:29:10,296 Epoch[17] Batch [780]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.112256,	
2017-06-15 18:29:14,788 Epoch[17] Batch [790]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.112212,	
2017-06-15 18:29:19,430 Epoch[17] Batch [800]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.112507,	
2017-06-15 18:29:23,985 Epoch[17] Batch [810]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.112523,	
2017-06-15 18:29:28,591 Epoch[17] Batch [820]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.112531,	
2017-06-15 18:29:33,375 Epoch[17] Batch [830]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.112376,	
2017-06-15 18:29:38,036 Epoch[17] Batch [840]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112383,	
2017-06-15 18:29:42,653 Epoch[17] Batch [850]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.112447,	
2017-06-15 18:29:47,213 Epoch[17] Batch [860]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112471,	
2017-06-15 18:29:51,985 Epoch[17] Batch [870]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.112445,	
2017-06-15 18:29:56,628 Epoch[17] Batch [880]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.112314,	
2017-06-15 18:30:01,209 Epoch[17] Batch [890]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.112253,	
2017-06-15 18:30:05,954 Epoch[17] Batch [900]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.112223,	
2017-06-15 18:30:10,791 Epoch[17] Batch [910]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.112208,	
2017-06-15 18:30:15,528 Epoch[17] Batch [920]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.112255,	
2017-06-15 18:30:20,135 Epoch[17] Batch [930]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.112209,	
2017-06-15 18:30:24,709 Epoch[17] Batch [940]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.112274,	
2017-06-15 18:30:29,212 Epoch[17] Batch [950]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.112323,	
2017-06-15 18:30:33,787 Epoch[17] Batch [960]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.112365,	
2017-06-15 18:30:38,308 Epoch[17] Batch [970]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.112298,	
2017-06-15 18:30:42,991 Epoch[17] Batch [980]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.112282,	
2017-06-15 18:30:47,533 Epoch[17] Batch [990]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112328,	
2017-06-15 18:30:52,207 Epoch[17] Batch [1000]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.112319,	
2017-06-15 18:30:56,749 Epoch[17] Batch [1010]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112337,	
2017-06-15 18:31:01,535 Epoch[17] Batch [1020]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.112355,	
2017-06-15 18:31:06,208 Epoch[17] Batch [1030]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.112300,	
2017-06-15 18:31:10,835 Epoch[17] Batch [1040]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112208,	
2017-06-15 18:31:15,394 Epoch[17] Batch [1050]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112296,	
2017-06-15 18:31:20,029 Epoch[17] Batch [1060]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.112193,	
2017-06-15 18:31:24,566 Epoch[17] Batch [1070]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.112135,	
2017-06-15 18:31:29,127 Epoch[17] Batch [1080]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112155,	
2017-06-15 18:31:33,712 Epoch[17] Batch [1090]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.112081,	
2017-06-15 18:31:38,309 Epoch[17] Batch [1100]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.112039,	
2017-06-15 18:31:43,129 Epoch[17] Batch [1110]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.112051,	
2017-06-15 18:31:47,913 Epoch[17] Batch [1120]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.112096,	
2017-06-15 18:31:52,538 Epoch[17] Batch [1130]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112102,	
2017-06-15 18:31:57,166 Epoch[17] Batch [1140]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.112093,	
2017-06-15 18:32:01,709 Epoch[17] Batch [1150]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112146,	
2017-06-15 18:32:06,334 Epoch[17] Batch [1160]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112025,	
2017-06-15 18:32:10,879 Epoch[17] Batch [1170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.111970,	
2017-06-15 18:32:15,434 Epoch[17] Batch [1180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.112009,	
2017-06-15 18:32:20,235 Epoch[17] Batch [1190]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.111983,	
2017-06-15 18:32:24,720 Epoch[17] Batch [1200]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.111987,	
2017-06-15 18:32:29,384 Epoch[17] Batch [1210]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112069,	
2017-06-15 18:32:33,909 Epoch[17] Batch [1220]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112009,	
2017-06-15 18:32:38,592 Epoch[17] Batch [1230]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.112322,	
2017-06-15 18:32:43,121 Epoch[17] Batch [1240]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.112339,	
2017-06-15 18:32:47,782 Epoch[17] Batch [1250]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112389,	
2017-06-15 18:32:52,472 Epoch[17] Batch [1260]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.112456,	
2017-06-15 18:32:57,074 Epoch[17] Batch [1270]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.112534,	
2017-06-15 18:33:01,718 Epoch[17] Batch [1280]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.112518,	
2017-06-15 18:33:06,265 Epoch[17] Batch [1290]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.112551,	
2017-06-15 18:33:10,930 Epoch[17] Batch [1300]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.112564,	
2017-06-15 18:33:15,581 Epoch[17] Batch [1310]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.112573,	
2017-06-15 18:33:20,171 Epoch[17] Batch [1320]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.112574,	
2017-06-15 18:33:24,694 Epoch[17] Batch [1330]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112579,	
2017-06-15 18:33:29,319 Epoch[17] Batch [1340]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112590,	
2017-06-15 18:33:34,010 Epoch[17] Batch [1350]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.112649,	
2017-06-15 18:33:38,664 Epoch[17] Batch [1360]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.112601,	
2017-06-15 18:33:43,208 Epoch[17] Batch [1370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.112644,	
2017-06-15 18:33:47,793 Epoch[17] Batch [1380]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.112610,	
2017-06-15 18:33:52,506 Epoch[17] Batch [1390]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.112595,	
2017-06-15 18:33:57,068 Epoch[17] Batch [1400]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112603,	
2017-06-15 18:34:01,594 Epoch[17] Batch [1410]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112638,	
2017-06-15 18:34:06,301 Epoch[17] Batch [1420]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.112622,	
2017-06-15 18:34:10,872 Epoch[17] Batch [1430]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.112721,	
2017-06-15 18:34:15,447 Epoch[17] Batch [1440]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.112679,	
2017-06-15 18:34:20,082 Epoch[17] Batch [1450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.112787,	
2017-06-15 18:34:24,582 Epoch[17] Batch [1460]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.112767,	
2017-06-15 18:34:29,214 Epoch[17] Batch [1470]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.112707,	
2017-06-15 18:34:33,789 Epoch[17] Batch [1480]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.112750,	
2017-06-15 18:34:36,507 Epoch[17] Train-FCNLogLoss=0.112704
2017-06-15 18:34:36,507 Epoch[17] Time cost=696.598
2017-06-15 18:34:37,730 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0018.params"
2017-06-15 18:34:39,394 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0018.states"
2017-06-15 18:34:44,625 Epoch[18] Batch [10]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.101455,	
2017-06-15 18:34:49,163 Epoch[18] Batch [20]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.111038,	
2017-06-15 18:34:53,788 Epoch[18] Batch [30]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.113123,	
2017-06-15 18:34:58,514 Epoch[18] Batch [40]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.114049,	
2017-06-15 18:35:03,186 Epoch[18] Batch [50]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.113269,	
2017-06-15 18:35:07,751 Epoch[18] Batch [60]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.114241,	
2017-06-15 18:35:12,384 Epoch[18] Batch [70]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.114389,	
2017-06-15 18:35:16,906 Epoch[18] Batch [80]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.111910,	
2017-06-15 18:35:21,521 Epoch[18] Batch [90]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.112538,	
2017-06-15 18:35:26,255 Epoch[18] Batch [100]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.112083,	
2017-06-15 18:35:30,908 Epoch[18] Batch [110]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.111527,	
2017-06-15 18:35:35,537 Epoch[18] Batch [120]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.112067,	
2017-06-15 18:35:40,146 Epoch[18] Batch [130]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.111568,	
2017-06-15 18:35:44,738 Epoch[18] Batch [140]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.111632,	
2017-06-15 18:35:49,406 Epoch[18] Batch [150]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.115673,	
2017-06-15 18:35:53,887 Epoch[18] Batch [160]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.117115,	
2017-06-15 18:35:58,463 Epoch[18] Batch [170]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.118368,	
2017-06-15 18:36:03,102 Epoch[18] Batch [180]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.119449,	
2017-06-15 18:36:07,671 Epoch[18] Batch [190]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.119866,	
2017-06-15 18:36:12,398 Epoch[18] Batch [200]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.119864,	
2017-06-15 18:36:17,004 Epoch[18] Batch [210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.120204,	
2017-06-15 18:36:21,613 Epoch[18] Batch [220]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.122336,	
2017-06-15 18:36:26,107 Epoch[18] Batch [230]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.126414,	
2017-06-15 18:36:30,713 Epoch[18] Batch [240]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.127799,	
2017-06-15 18:36:35,343 Epoch[18] Batch [250]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.128854,	
2017-06-15 18:36:39,871 Epoch[18] Batch [260]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.129304,	
2017-06-15 18:36:44,505 Epoch[18] Batch [270]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.129448,	
2017-06-15 18:36:49,118 Epoch[18] Batch [280]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.129761,	
2017-06-15 18:36:53,675 Epoch[18] Batch [290]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.129712,	
2017-06-15 18:36:58,288 Epoch[18] Batch [300]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.130233,	
2017-06-15 18:37:02,990 Epoch[18] Batch [310]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.129780,	
2017-06-15 18:37:07,645 Epoch[18] Batch [320]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.129944,	
2017-06-15 18:37:12,252 Epoch[18] Batch [330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.130454,	
2017-06-15 18:37:16,891 Epoch[18] Batch [340]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.131542,	
2017-06-15 18:37:21,414 Epoch[18] Batch [350]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.131794,	
2017-06-15 18:37:26,022 Epoch[18] Batch [360]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.131199,	
2017-06-15 18:37:30,597 Epoch[18] Batch [370]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.131227,	
2017-06-15 18:37:35,173 Epoch[18] Batch [380]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.130811,	
2017-06-15 18:37:39,788 Epoch[18] Batch [390]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.130381,	
2017-06-15 18:37:44,372 Epoch[18] Batch [400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.130940,	
2017-06-15 18:37:49,004 Epoch[18] Batch [410]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.130867,	
2017-06-15 18:37:53,586 Epoch[18] Batch [420]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.130586,	
2017-06-15 18:37:58,228 Epoch[18] Batch [430]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.130195,	
2017-06-15 18:38:02,767 Epoch[18] Batch [440]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.129670,	
2017-06-15 18:38:07,354 Epoch[18] Batch [450]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.129316,	
2017-06-15 18:38:12,055 Epoch[18] Batch [460]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.128856,	
2017-06-15 18:38:16,581 Epoch[18] Batch [470]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.128742,	
2017-06-15 18:38:21,261 Epoch[18] Batch [480]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.128774,	
2017-06-15 18:38:25,820 Epoch[18] Batch [490]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.128434,	
2017-06-15 18:38:30,483 Epoch[18] Batch [500]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.128041,	
2017-06-15 18:38:35,110 Epoch[18] Batch [510]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.127980,	
2017-06-15 18:38:39,713 Epoch[18] Batch [520]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.128047,	
2017-06-15 18:38:44,278 Epoch[18] Batch [530]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.128139,	
2017-06-15 18:38:48,812 Epoch[18] Batch [540]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.127836,	
2017-06-15 18:38:53,450 Epoch[18] Batch [550]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.127485,	
2017-06-15 18:38:58,158 Epoch[18] Batch [560]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.127416,	
2017-06-15 18:39:02,752 Epoch[18] Batch [570]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.127346,	
2017-06-15 18:39:07,259 Epoch[18] Batch [580]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.127063,	
2017-06-15 18:39:11,966 Epoch[18] Batch [590]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.126779,	
2017-06-15 18:39:16,543 Epoch[18] Batch [600]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.126411,	
2017-06-15 18:39:21,125 Epoch[18] Batch [610]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.126164,	
2017-06-15 18:39:25,914 Epoch[18] Batch [620]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.126000,	
2017-06-15 18:39:30,538 Epoch[18] Batch [630]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.126076,	
2017-06-15 18:39:35,094 Epoch[18] Batch [640]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.125812,	
2017-06-15 18:39:39,683 Epoch[18] Batch [650]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.125588,	
2017-06-15 18:39:44,296 Epoch[18] Batch [660]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.125453,	
2017-06-15 18:39:48,951 Epoch[18] Batch [670]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.125341,	
2017-06-15 18:39:53,514 Epoch[18] Batch [680]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.125297,	
2017-06-15 18:39:58,099 Epoch[18] Batch [690]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.125039,	
2017-06-15 18:40:02,743 Epoch[18] Batch [700]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.125116,	
2017-06-15 18:40:07,405 Epoch[18] Batch [710]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.124880,	
2017-06-15 18:40:11,943 Epoch[18] Batch [720]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.124681,	
2017-06-15 18:40:16,489 Epoch[18] Batch [730]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.124611,	
2017-06-15 18:40:21,083 Epoch[18] Batch [740]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.124441,	
2017-06-15 18:40:25,767 Epoch[18] Batch [750]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.124424,	
2017-06-15 18:40:30,416 Epoch[18] Batch [760]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.124367,	
2017-06-15 18:40:35,030 Epoch[18] Batch [770]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.124097,	
2017-06-15 18:40:39,526 Epoch[18] Batch [780]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.124360,	
2017-06-15 18:40:44,124 Epoch[18] Batch [790]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.124456,	
2017-06-15 18:40:48,590 Epoch[18] Batch [800]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.124421,	
2017-06-15 18:40:53,252 Epoch[18] Batch [810]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.124138,	
2017-06-15 18:40:57,905 Epoch[18] Batch [820]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.123953,	
2017-06-15 18:41:02,749 Epoch[18] Batch [830]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.123905,	
2017-06-15 18:41:07,278 Epoch[18] Batch [840]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.123892,	
2017-06-15 18:41:11,957 Epoch[18] Batch [850]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.123696,	
2017-06-15 18:41:16,554 Epoch[18] Batch [860]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.123523,	
2017-06-15 18:41:21,267 Epoch[18] Batch [870]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.123463,	
2017-06-15 18:41:25,890 Epoch[18] Batch [880]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123380,	
2017-06-15 18:41:30,475 Epoch[18] Batch [890]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.123308,	
2017-06-15 18:41:35,230 Epoch[18] Batch [900]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.123168,	
2017-06-15 18:41:39,835 Epoch[18] Batch [910]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.123084,	
2017-06-15 18:41:44,619 Epoch[18] Batch [920]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.122851,	
2017-06-15 18:41:49,239 Epoch[18] Batch [930]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.122738,	
2017-06-15 18:41:53,811 Epoch[18] Batch [940]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.122836,	
2017-06-15 18:41:58,321 Epoch[18] Batch [950]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.122638,	
2017-06-15 18:42:03,172 Epoch[18] Batch [960]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.122478,	
2017-06-15 18:42:07,875 Epoch[18] Batch [970]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.122485,	
2017-06-15 18:42:12,755 Epoch[18] Batch [980]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.122343,	
2017-06-15 18:42:17,425 Epoch[18] Batch [990]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.122334,	
2017-06-15 18:42:22,028 Epoch[18] Batch [1000]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.122252,	
2017-06-15 18:42:26,718 Epoch[18] Batch [1010]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.122037,	
2017-06-15 18:42:31,343 Epoch[18] Batch [1020]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.122024,	
2017-06-15 18:42:36,352 Epoch[18] Batch [1030]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.121982,	
2017-06-15 18:42:40,973 Epoch[18] Batch [1040]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121740,	
2017-06-15 18:42:45,627 Epoch[18] Batch [1050]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.121626,	
2017-06-15 18:42:50,313 Epoch[18] Batch [1060]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121546,	
2017-06-15 18:42:55,056 Epoch[18] Batch [1070]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.121646,	
2017-06-15 18:42:59,649 Epoch[18] Batch [1080]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.121612,	
2017-06-15 18:43:04,203 Epoch[18] Batch [1090]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.121565,	
2017-06-15 18:43:09,045 Epoch[18] Batch [1100]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.121536,	
2017-06-15 18:43:13,584 Epoch[18] Batch [1110]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.121556,	
2017-06-15 18:43:18,257 Epoch[18] Batch [1120]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121633,	
2017-06-15 18:43:22,759 Epoch[18] Batch [1130]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.121469,	
2017-06-15 18:43:27,574 Epoch[18] Batch [1140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.121395,	
2017-06-15 18:43:32,050 Epoch[18] Batch [1150]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.121356,	
2017-06-15 18:43:36,649 Epoch[18] Batch [1160]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.121179,	
2017-06-15 18:43:41,350 Epoch[18] Batch [1170]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.121020,	
2017-06-15 18:43:45,891 Epoch[18] Batch [1180]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.120932,	
2017-06-15 18:43:50,486 Epoch[18] Batch [1190]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.120833,	
2017-06-15 18:43:55,129 Epoch[18] Batch [1200]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.120716,	
2017-06-15 18:43:59,680 Epoch[18] Batch [1210]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.120702,	
2017-06-15 18:44:04,278 Epoch[18] Batch [1220]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.120558,	
2017-06-15 18:44:08,826 Epoch[18] Batch [1230]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120508,	
2017-06-15 18:44:13,473 Epoch[18] Batch [1240]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.120518,	
2017-06-15 18:44:18,050 Epoch[18] Batch [1250]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.120584,	
2017-06-15 18:44:22,668 Epoch[18] Batch [1260]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.120480,	
2017-06-15 18:44:27,175 Epoch[18] Batch [1270]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.120528,	
2017-06-15 18:44:31,788 Epoch[18] Batch [1280]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.120485,	
2017-06-15 18:44:36,408 Epoch[18] Batch [1290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.120523,	
2017-06-15 18:44:40,991 Epoch[18] Batch [1300]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.120390,	
2017-06-15 18:44:45,638 Epoch[18] Batch [1310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.120366,	
2017-06-15 18:44:50,308 Epoch[18] Batch [1320]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.120306,	
2017-06-15 18:44:54,776 Epoch[18] Batch [1330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.120220,	
2017-06-15 18:44:59,383 Epoch[18] Batch [1340]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.120124,	
2017-06-15 18:45:03,964 Epoch[18] Batch [1350]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.120046,	
2017-06-15 18:45:08,701 Epoch[18] Batch [1360]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.120034,	
2017-06-15 18:45:13,222 Epoch[18] Batch [1370]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.119910,	
2017-06-15 18:45:17,912 Epoch[18] Batch [1380]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.119799,	
2017-06-15 18:45:22,582 Epoch[18] Batch [1390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.119837,	
2017-06-15 18:45:27,410 Epoch[18] Batch [1400]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.119751,	
2017-06-15 18:45:32,007 Epoch[18] Batch [1410]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.119697,	
2017-06-15 18:45:36,519 Epoch[18] Batch [1420]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.119613,	
2017-06-15 18:45:41,505 Epoch[18] Batch [1430]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.119535,	
2017-06-15 18:45:46,074 Epoch[18] Batch [1440]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.119470,	
2017-06-15 18:45:50,556 Epoch[18] Batch [1450]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.119356,	
2017-06-15 18:45:55,156 Epoch[18] Batch [1460]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.119274,	
2017-06-15 18:45:59,672 Epoch[18] Batch [1470]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.119117,	
2017-06-15 18:46:04,305 Epoch[18] Batch [1480]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.119135,	
2017-06-15 18:46:07,046 Epoch[18] Train-FCNLogLoss=0.119128
2017-06-15 18:46:07,046 Epoch[18] Time cost=687.652
2017-06-15 18:46:07,912 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0019.params"
2017-06-15 18:46:09,574 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0019.states"
2017-06-15 18:46:14,960 Epoch[19] Batch [10]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.114966,	
2017-06-15 18:46:19,627 Epoch[19] Batch [20]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.118602,	
2017-06-15 18:46:24,253 Epoch[19] Batch [30]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.114310,	
2017-06-15 18:46:28,798 Epoch[19] Batch [40]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.115142,	
2017-06-15 18:46:33,329 Epoch[19] Batch [50]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.113971,	
2017-06-15 18:46:37,914 Epoch[19] Batch [60]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.109993,	
2017-06-15 18:46:42,565 Epoch[19] Batch [70]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.109783,	
2017-06-15 18:46:47,244 Epoch[19] Batch [80]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.111197,	
2017-06-15 18:46:51,800 Epoch[19] Batch [90]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.111532,	
2017-06-15 18:46:56,451 Epoch[19] Batch [100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.111693,	
2017-06-15 18:47:01,068 Epoch[19] Batch [110]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.110682,	
2017-06-15 18:47:05,667 Epoch[19] Batch [120]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109794,	
2017-06-15 18:47:10,326 Epoch[19] Batch [130]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.110155,	
2017-06-15 18:47:15,077 Epoch[19] Batch [140]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.110079,	
2017-06-15 18:47:19,630 Epoch[19] Batch [150]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.109924,	
2017-06-15 18:47:24,302 Epoch[19] Batch [160]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.110082,	
2017-06-15 18:47:29,159 Epoch[19] Batch [170]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.110039,	
2017-06-15 18:47:33,704 Epoch[19] Batch [180]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109558,	
2017-06-15 18:47:38,460 Epoch[19] Batch [190]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.109365,	
2017-06-15 18:47:43,021 Epoch[19] Batch [200]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109727,	
2017-06-15 18:47:47,887 Epoch[19] Batch [210]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.109966,	
2017-06-15 18:47:52,573 Epoch[19] Batch [220]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109760,	
2017-06-15 18:47:57,164 Epoch[19] Batch [230]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.109591,	
2017-06-15 18:48:01,720 Epoch[19] Batch [240]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.108957,	
2017-06-15 18:48:06,336 Epoch[19] Batch [250]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108791,	
2017-06-15 18:48:11,016 Epoch[19] Batch [260]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108971,	
2017-06-15 18:48:15,659 Epoch[19] Batch [270]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.108804,	
2017-06-15 18:48:20,155 Epoch[19] Batch [280]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.109182,	
2017-06-15 18:48:24,769 Epoch[19] Batch [290]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.109176,	
2017-06-15 18:48:29,373 Epoch[19] Batch [300]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108925,	
2017-06-15 18:48:34,051 Epoch[19] Batch [310]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.109087,	
2017-06-15 18:48:38,676 Epoch[19] Batch [320]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.109760,	
2017-06-15 18:48:43,305 Epoch[19] Batch [330]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109664,	
2017-06-15 18:48:47,954 Epoch[19] Batch [340]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.109426,	
2017-06-15 18:48:52,489 Epoch[19] Batch [350]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.109663,	
2017-06-15 18:48:57,080 Epoch[19] Batch [360]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.109594,	
2017-06-15 18:49:01,674 Epoch[19] Batch [370]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.109521,	
2017-06-15 18:49:06,253 Epoch[19] Batch [380]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.109169,	
2017-06-15 18:49:10,860 Epoch[19] Batch [390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109493,	
2017-06-15 18:49:15,597 Epoch[19] Batch [400]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.109519,	
2017-06-15 18:49:20,206 Epoch[19] Batch [410]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109434,	
2017-06-15 18:49:24,802 Epoch[19] Batch [420]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109535,	
2017-06-15 18:49:29,370 Epoch[19] Batch [430]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109359,	
2017-06-15 18:49:33,949 Epoch[19] Batch [440]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.109635,	
2017-06-15 18:49:38,454 Epoch[19] Batch [450]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.109811,	
2017-06-15 18:49:43,144 Epoch[19] Batch [460]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.109847,	
2017-06-15 18:49:47,712 Epoch[19] Batch [470]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109560,	
2017-06-15 18:49:52,329 Epoch[19] Batch [480]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.109424,	
2017-06-15 18:49:56,958 Epoch[19] Batch [490]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109417,	
2017-06-15 18:50:01,745 Epoch[19] Batch [500]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.109397,	
2017-06-15 18:50:06,417 Epoch[19] Batch [510]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.109536,	
2017-06-15 18:50:11,059 Epoch[19] Batch [520]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.109472,	
2017-06-15 18:50:15,825 Epoch[19] Batch [530]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.109208,	
2017-06-15 18:50:20,558 Epoch[19] Batch [540]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109190,	
2017-06-15 18:50:25,381 Epoch[19] Batch [550]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.109111,	
2017-06-15 18:50:30,121 Epoch[19] Batch [560]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.109405,	
2017-06-15 18:50:35,129 Epoch[19] Batch [570]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.109546,	
2017-06-15 18:50:40,079 Epoch[19] Batch [580]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.109740,	
2017-06-15 18:50:44,913 Epoch[19] Batch [590]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.109792,	
2017-06-15 18:50:49,691 Epoch[19] Batch [600]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.109761,	
2017-06-15 18:50:54,385 Epoch[19] Batch [610]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.109796,	
2017-06-15 18:50:58,984 Epoch[19] Batch [620]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109967,	
2017-06-15 18:51:03,580 Epoch[19] Batch [630]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.110091,	
2017-06-15 18:51:08,216 Epoch[19] Batch [640]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.110218,	
2017-06-15 18:51:12,934 Epoch[19] Batch [650]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.110243,	
2017-06-15 18:51:17,562 Epoch[19] Batch [660]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.110139,	
2017-06-15 18:51:22,048 Epoch[19] Batch [670]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.110022,	
2017-06-15 18:51:26,644 Epoch[19] Batch [680]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109922,	
2017-06-15 18:51:31,271 Epoch[19] Batch [690]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.109844,	
2017-06-15 18:51:35,956 Epoch[19] Batch [700]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109925,	
2017-06-15 18:51:40,682 Epoch[19] Batch [710]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.109886,	
2017-06-15 18:51:45,620 Epoch[19] Batch [720]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.109791,	
2017-06-15 18:51:50,366 Epoch[19] Batch [730]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.109988,	
2017-06-15 18:51:55,549 Epoch[19] Batch [740]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.110074,	
2017-06-15 18:52:00,407 Epoch[19] Batch [750]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.110070,	
2017-06-15 18:52:05,321 Epoch[19] Batch [760]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.110220,	
2017-06-15 18:52:09,925 Epoch[19] Batch [770]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.110298,	
2017-06-15 18:52:14,684 Epoch[19] Batch [780]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.110266,	
2017-06-15 18:52:19,502 Epoch[19] Batch [790]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.110384,	
2017-06-15 18:52:24,254 Epoch[19] Batch [800]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.110469,	
2017-06-15 18:52:29,039 Epoch[19] Batch [810]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.110592,	
2017-06-15 18:52:33,973 Epoch[19] Batch [820]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.110583,	
2017-06-15 18:52:38,627 Epoch[19] Batch [830]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.110560,	
2017-06-15 18:52:43,261 Epoch[19] Batch [840]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.110723,	
2017-06-15 18:52:47,974 Epoch[19] Batch [850]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.110646,	
2017-06-15 18:52:52,842 Epoch[19] Batch [860]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.110664,	
2017-06-15 18:52:57,524 Epoch[19] Batch [870]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.110610,	
2017-06-15 18:53:02,259 Epoch[19] Batch [880]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.110555,	
2017-06-15 18:53:07,244 Epoch[19] Batch [890]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.110530,	
2017-06-15 18:53:11,829 Epoch[19] Batch [900]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.110585,	
2017-06-15 18:53:16,551 Epoch[19] Batch [910]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.110579,	
2017-06-15 18:53:21,430 Epoch[19] Batch [920]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.110535,	
2017-06-15 18:53:26,239 Epoch[19] Batch [930]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.110438,	
2017-06-15 18:53:31,161 Epoch[19] Batch [940]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.110397,	
2017-06-15 18:53:35,838 Epoch[19] Batch [950]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.110337,	
2017-06-15 18:53:40,714 Epoch[19] Batch [960]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.110206,	
2017-06-15 18:53:45,525 Epoch[19] Batch [970]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.110250,	
2017-06-15 18:53:50,132 Epoch[19] Batch [980]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110278,	
2017-06-15 18:53:54,891 Epoch[19] Batch [990]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.110319,	
2017-06-15 18:53:59,824 Epoch[19] Batch [1000]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.110256,	
2017-06-15 18:54:04,856 Epoch[19] Batch [1010]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.110201,	
2017-06-15 18:54:09,473 Epoch[19] Batch [1020]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.110240,	
2017-06-15 18:54:14,654 Epoch[19] Batch [1030]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.110272,	
2017-06-15 18:54:19,352 Epoch[19] Batch [1040]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.110328,	
2017-06-15 18:54:24,021 Epoch[19] Batch [1050]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.110290,	
2017-06-15 18:54:28,657 Epoch[19] Batch [1060]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.110185,	
2017-06-15 18:54:33,412 Epoch[19] Batch [1070]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.110276,	
2017-06-15 18:54:38,141 Epoch[19] Batch [1080]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.110194,	
2017-06-15 18:54:42,818 Epoch[19] Batch [1090]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.110166,	
2017-06-15 18:54:47,573 Epoch[19] Batch [1100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.110162,	
2017-06-15 18:54:52,454 Epoch[19] Batch [1110]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.110059,	
2017-06-15 18:54:57,281 Epoch[19] Batch [1120]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.110092,	
2017-06-15 18:55:02,020 Epoch[19] Batch [1130]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.110108,	
2017-06-15 18:55:06,736 Epoch[19] Batch [1140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.110133,	
2017-06-15 18:55:11,979 Epoch[19] Batch [1150]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.110100,	
2017-06-15 18:55:17,174 Epoch[19] Batch [1160]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.110090,	
2017-06-15 18:55:22,073 Epoch[19] Batch [1170]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.109994,	
2017-06-15 18:55:26,862 Epoch[19] Batch [1180]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.109982,	
2017-06-15 18:55:31,458 Epoch[19] Batch [1190]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109943,	
2017-06-15 18:55:36,373 Epoch[19] Batch [1200]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.109962,	
2017-06-15 18:55:41,134 Epoch[19] Batch [1210]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.109902,	
2017-06-15 18:55:46,075 Epoch[19] Batch [1220]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.109778,	
2017-06-15 18:55:50,667 Epoch[19] Batch [1230]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.109659,	
2017-06-15 18:55:55,370 Epoch[19] Batch [1240]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.109586,	
2017-06-15 18:55:59,955 Epoch[19] Batch [1250]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.109629,	
2017-06-15 18:56:04,721 Epoch[19] Batch [1260]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.109674,	
2017-06-15 18:56:10,040 Epoch[19] Batch [1270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.109664,	
2017-06-15 18:56:14,624 Epoch[19] Batch [1280]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.109702,	
2017-06-15 18:56:19,260 Epoch[19] Batch [1290]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.109727,	
2017-06-15 18:56:24,195 Epoch[19] Batch [1300]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.109763,	
2017-06-15 18:56:28,842 Epoch[19] Batch [1310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.109734,	
2017-06-15 18:56:33,556 Epoch[19] Batch [1320]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.109776,	
2017-06-15 18:56:38,539 Epoch[19] Batch [1330]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.109840,	
2017-06-15 18:56:43,482 Epoch[19] Batch [1340]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.109903,	
2017-06-15 18:56:48,108 Epoch[19] Batch [1350]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.109819,	
2017-06-15 18:56:52,711 Epoch[19] Batch [1360]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.109739,	
2017-06-15 18:56:57,268 Epoch[19] Batch [1370]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109789,	
2017-06-15 18:57:01,890 Epoch[19] Batch [1380]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.109783,	
2017-06-15 18:57:06,581 Epoch[19] Batch [1390]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.109873,	
2017-06-15 18:57:11,394 Epoch[19] Batch [1400]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.109914,	
2017-06-15 18:57:15,942 Epoch[19] Batch [1410]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109956,	
2017-06-15 18:57:20,740 Epoch[19] Batch [1420]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.110041,	
2017-06-15 18:57:25,263 Epoch[19] Batch [1430]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.110036,	
2017-06-15 18:57:29,893 Epoch[19] Batch [1440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109982,	
2017-06-15 18:57:34,411 Epoch[19] Batch [1450]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.110004,	
2017-06-15 18:57:39,056 Epoch[19] Batch [1460]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.109968,	
2017-06-15 18:57:43,624 Epoch[19] Batch [1470]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109944,	
2017-06-15 18:57:48,329 Epoch[19] Batch [1480]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.109993,	
2017-06-15 18:57:51,062 Epoch[19] Train-FCNLogLoss=0.110014
2017-06-15 18:57:51,062 Epoch[19] Time cost=701.488
2017-06-15 18:57:51,846 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0020.params"
2017-06-15 18:57:53,772 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0020.states"
2017-06-15 18:57:59,112 Epoch[20] Batch [10]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104093,	
2017-06-15 18:58:03,851 Epoch[20] Batch [20]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.106623,	
2017-06-15 18:58:08,453 Epoch[20] Batch [30]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107252,	
2017-06-15 18:58:13,086 Epoch[20] Batch [40]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.105469,	
2017-06-15 18:58:17,690 Epoch[20] Batch [50]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.103038,	
2017-06-15 18:58:22,323 Epoch[20] Batch [60]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.103168,	
2017-06-15 18:58:27,037 Epoch[20] Batch [70]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104818,	
2017-06-15 18:58:31,589 Epoch[20] Batch [80]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.106639,	
2017-06-15 18:58:36,288 Epoch[20] Batch [90]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.105379,	
2017-06-15 18:58:40,889 Epoch[20] Batch [100]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.104488,	
2017-06-15 18:58:45,511 Epoch[20] Batch [110]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.105246,	
2017-06-15 18:58:50,095 Epoch[20] Batch [120]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106644,	
2017-06-15 18:58:54,565 Epoch[20] Batch [130]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.106726,	
2017-06-15 18:58:59,267 Epoch[20] Batch [140]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.105416,	
2017-06-15 18:59:03,858 Epoch[20] Batch [150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.105396,	
2017-06-15 18:59:08,615 Epoch[20] Batch [160]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.105323,	
2017-06-15 18:59:13,360 Epoch[20] Batch [170]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.105550,	
2017-06-15 18:59:18,083 Epoch[20] Batch [180]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.105734,	
2017-06-15 18:59:22,709 Epoch[20] Batch [190]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.105973,	
2017-06-15 18:59:27,403 Epoch[20] Batch [200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.106369,	
2017-06-15 18:59:32,064 Epoch[20] Batch [210]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.106469,	
2017-06-15 18:59:36,696 Epoch[20] Batch [220]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.106752,	
2017-06-15 18:59:41,449 Epoch[20] Batch [230]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.106098,	
2017-06-15 18:59:46,025 Epoch[20] Batch [240]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.106303,	
2017-06-15 18:59:50,679 Epoch[20] Batch [250]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.106709,	
2017-06-15 18:59:55,465 Epoch[20] Batch [260]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.106305,	
2017-06-15 19:00:00,074 Epoch[20] Batch [270]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.106684,	
2017-06-15 19:00:04,592 Epoch[20] Batch [280]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.106767,	
2017-06-15 19:00:09,208 Epoch[20] Batch [290]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.107116,	
2017-06-15 19:00:13,776 Epoch[20] Batch [300]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.107045,	
2017-06-15 19:00:18,329 Epoch[20] Batch [310]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.106948,	
2017-06-15 19:00:22,969 Epoch[20] Batch [320]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107127,	
2017-06-15 19:00:27,553 Epoch[20] Batch [330]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.107261,	
2017-06-15 19:00:32,182 Epoch[20] Batch [340]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.107208,	
2017-06-15 19:00:36,940 Epoch[20] Batch [350]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.107365,	
2017-06-15 19:00:41,506 Epoch[20] Batch [360]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.107234,	
2017-06-15 19:00:46,291 Epoch[20] Batch [370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.107028,	
2017-06-15 19:00:50,930 Epoch[20] Batch [380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107516,	
2017-06-15 19:00:55,674 Epoch[20] Batch [390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.108351,	
2017-06-15 19:01:00,373 Epoch[20] Batch [400]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.108742,	
2017-06-15 19:01:04,990 Epoch[20] Batch [410]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108897,	
2017-06-15 19:01:09,700 Epoch[20] Batch [420]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.108852,	
2017-06-15 19:01:14,346 Epoch[20] Batch [430]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.108919,	
2017-06-15 19:01:19,058 Epoch[20] Batch [440]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.108873,	
2017-06-15 19:01:23,706 Epoch[20] Batch [450]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.108603,	
2017-06-15 19:01:28,839 Epoch[20] Batch [460]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.108940,	
2017-06-15 19:01:33,436 Epoch[20] Batch [470]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108804,	
2017-06-15 19:01:38,033 Epoch[20] Batch [480]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109132,	
2017-06-15 19:01:42,764 Epoch[20] Batch [490]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109335,	
2017-06-15 19:01:47,312 Epoch[20] Batch [500]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109205,	
2017-06-15 19:01:51,851 Epoch[20] Batch [510]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.108889,	
2017-06-15 19:01:56,417 Epoch[20] Batch [520]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108709,	
2017-06-15 19:02:01,066 Epoch[20] Batch [530]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.108791,	
2017-06-15 19:02:05,736 Epoch[20] Batch [540]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.108814,	
2017-06-15 19:02:10,301 Epoch[20] Batch [550]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108958,	
2017-06-15 19:02:15,012 Epoch[20] Batch [560]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.108964,	
2017-06-15 19:02:19,550 Epoch[20] Batch [570]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.109013,	
2017-06-15 19:02:24,105 Epoch[20] Batch [580]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109055,	
2017-06-15 19:02:28,606 Epoch[20] Batch [590]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.108978,	
2017-06-15 19:02:33,345 Epoch[20] Batch [600]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.108909,	
2017-06-15 19:02:37,998 Epoch[20] Batch [610]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.109125,	
2017-06-15 19:02:42,772 Epoch[20] Batch [620]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.109007,	
2017-06-15 19:02:47,592 Epoch[20] Batch [630]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.108896,	
2017-06-15 19:02:52,151 Epoch[20] Batch [640]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.108688,	
2017-06-15 19:02:56,893 Epoch[20] Batch [650]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.108753,	
2017-06-15 19:03:01,526 Epoch[20] Batch [660]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.108664,	
2017-06-15 19:03:06,169 Epoch[20] Batch [670]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.108423,	
2017-06-15 19:03:10,908 Epoch[20] Batch [680]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.108364,	
2017-06-15 19:03:15,623 Epoch[20] Batch [690]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.108376,	
2017-06-15 19:03:20,303 Epoch[20] Batch [700]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108341,	
2017-06-15 19:03:25,143 Epoch[20] Batch [710]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.108314,	
2017-06-15 19:03:30,182 Epoch[20] Batch [720]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.108231,	
2017-06-15 19:03:34,724 Epoch[20] Batch [730]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.108297,	
2017-06-15 19:03:39,341 Epoch[20] Batch [740]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108323,	
2017-06-15 19:03:43,915 Epoch[20] Batch [750]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108213,	
2017-06-15 19:03:48,643 Epoch[20] Batch [760]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.108120,	
2017-06-15 19:03:53,206 Epoch[20] Batch [770]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108080,	
2017-06-15 19:03:57,844 Epoch[20] Batch [780]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.108108,	
2017-06-15 19:04:02,434 Epoch[20] Batch [790]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.108153,	
2017-06-15 19:04:07,092 Epoch[20] Batch [800]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.108162,	
2017-06-15 19:04:12,070 Epoch[20] Batch [810]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.108479,	
2017-06-15 19:04:16,681 Epoch[20] Batch [820]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.108820,	
2017-06-15 19:04:21,732 Epoch[20] Batch [830]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.108887,	
2017-06-15 19:04:26,389 Epoch[20] Batch [840]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.108860,	
2017-06-15 19:04:31,112 Epoch[20] Batch [850]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.108792,	
2017-06-15 19:04:35,691 Epoch[20] Batch [860]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.108595,	
2017-06-15 19:04:40,381 Epoch[20] Batch [870]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.108993,	
2017-06-15 19:04:44,922 Epoch[20] Batch [880]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109028,	
2017-06-15 19:04:49,532 Epoch[20] Batch [890]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109143,	
2017-06-15 19:04:54,319 Epoch[20] Batch [900]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.109064,	
2017-06-15 19:04:58,888 Epoch[20] Batch [910]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108946,	
2017-06-15 19:05:03,458 Epoch[20] Batch [920]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.109011,	
2017-06-15 19:05:08,165 Epoch[20] Batch [930]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.108974,	
2017-06-15 19:05:13,153 Epoch[20] Batch [940]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.108954,	
2017-06-15 19:05:17,651 Epoch[20] Batch [950]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.109034,	
2017-06-15 19:05:22,317 Epoch[20] Batch [960]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.109036,	
2017-06-15 19:05:27,011 Epoch[20] Batch [970]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.109145,	
2017-06-15 19:05:31,620 Epoch[20] Batch [980]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109213,	
2017-06-15 19:05:36,479 Epoch[20] Batch [990]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.109233,	
2017-06-15 19:05:41,091 Epoch[20] Batch [1000]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.109179,	
2017-06-15 19:05:45,681 Epoch[20] Batch [1010]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.109092,	
2017-06-15 19:05:50,355 Epoch[20] Batch [1020]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.109114,	
2017-06-15 19:05:54,955 Epoch[20] Batch [1030]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109046,	
2017-06-15 19:05:59,896 Epoch[20] Batch [1040]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.109022,	
2017-06-15 19:06:04,580 Epoch[20] Batch [1050]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109119,	
2017-06-15 19:06:09,504 Epoch[20] Batch [1060]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.108965,	
2017-06-15 19:06:13,992 Epoch[20] Batch [1070]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.108961,	
2017-06-15 19:06:18,906 Epoch[20] Batch [1080]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.108967,	
2017-06-15 19:06:23,664 Epoch[20] Batch [1090]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108980,	
2017-06-15 19:06:28,382 Epoch[20] Batch [1100]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.109086,	
2017-06-15 19:06:32,966 Epoch[20] Batch [1110]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.109149,	
2017-06-15 19:06:37,525 Epoch[20] Batch [1120]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109103,	
2017-06-15 19:06:42,242 Epoch[20] Batch [1130]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.109160,	
2017-06-15 19:06:46,949 Epoch[20] Batch [1140]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.109130,	
2017-06-15 19:06:51,641 Epoch[20] Batch [1150]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.109213,	
2017-06-15 19:06:56,228 Epoch[20] Batch [1160]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.109242,	
2017-06-15 19:07:00,905 Epoch[20] Batch [1170]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.109285,	
2017-06-15 19:07:05,415 Epoch[20] Batch [1180]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.109236,	
2017-06-15 19:07:10,054 Epoch[20] Batch [1190]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.109264,	
2017-06-15 19:07:14,676 Epoch[20] Batch [1200]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.109246,	
2017-06-15 19:07:19,240 Epoch[20] Batch [1210]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109234,	
2017-06-15 19:07:23,915 Epoch[20] Batch [1220]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.109183,	
2017-06-15 19:07:28,472 Epoch[20] Batch [1230]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109122,	
2017-06-15 19:07:33,234 Epoch[20] Batch [1240]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.109012,	
2017-06-15 19:07:37,838 Epoch[20] Batch [1250]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108938,	
2017-06-15 19:07:42,534 Epoch[20] Batch [1260]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.109182,	
2017-06-15 19:07:47,354 Epoch[20] Batch [1270]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.109248,	
2017-06-15 19:07:51,925 Epoch[20] Batch [1280]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.109207,	
2017-06-15 19:07:56,524 Epoch[20] Batch [1290]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109131,	
2017-06-15 19:08:01,149 Epoch[20] Batch [1300]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.109196,	
2017-06-15 19:08:05,940 Epoch[20] Batch [1310]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.109223,	
2017-06-15 19:08:10,396 Epoch[20] Batch [1320]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.109266,	
2017-06-15 19:08:15,097 Epoch[20] Batch [1330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.109256,	
2017-06-15 19:08:19,764 Epoch[20] Batch [1340]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.109196,	
2017-06-15 19:08:24,340 Epoch[20] Batch [1350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.109174,	
2017-06-15 19:08:29,044 Epoch[20] Batch [1360]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.109278,	
2017-06-15 19:08:33,567 Epoch[20] Batch [1370]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.109310,	
2017-06-15 19:08:38,476 Epoch[20] Batch [1380]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.109350,	
2017-06-15 19:08:43,031 Epoch[20] Batch [1390]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109289,	
2017-06-15 19:08:47,643 Epoch[20] Batch [1400]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.109208,	
2017-06-15 19:08:52,207 Epoch[20] Batch [1410]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109130,	
2017-06-15 19:08:56,716 Epoch[20] Batch [1420]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.109249,	
2017-06-15 19:09:01,318 Epoch[20] Batch [1430]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.109210,	
2017-06-15 19:09:05,912 Epoch[20] Batch [1440]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.109233,	
2017-06-15 19:09:10,773 Epoch[20] Batch [1450]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.109259,	
2017-06-15 19:09:15,383 Epoch[20] Batch [1460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109213,	
2017-06-15 19:09:20,000 Epoch[20] Batch [1470]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.109227,	
2017-06-15 19:09:24,609 Epoch[20] Batch [1480]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109184,	
2017-06-15 19:09:27,308 Epoch[20] Train-FCNLogLoss=0.109214
2017-06-15 19:09:27,308 Epoch[20] Time cost=693.535
2017-06-15 19:09:27,983 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0021.params"
2017-06-15 19:09:30,213 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0021.states"
2017-06-15 19:09:35,588 Epoch[21] Batch [10]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.100043,	
2017-06-15 19:09:40,503 Epoch[21] Batch [20]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.101311,	
2017-06-15 19:09:45,209 Epoch[21] Batch [30]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.104651,	
2017-06-15 19:09:49,731 Epoch[21] Batch [40]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.105313,	
2017-06-15 19:09:54,422 Epoch[21] Batch [50]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.104868,	
2017-06-15 19:09:59,050 Epoch[21] Batch [60]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.105726,	
2017-06-15 19:10:03,664 Epoch[21] Batch [70]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.107129,	
2017-06-15 19:10:08,347 Epoch[21] Batch [80]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.106599,	
2017-06-15 19:10:12,999 Epoch[21] Batch [90]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.105742,	
2017-06-15 19:10:17,603 Epoch[21] Batch [100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.106536,	
2017-06-15 19:10:22,208 Epoch[21] Batch [110]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.106826,	
2017-06-15 19:10:26,795 Epoch[21] Batch [120]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.106524,	
2017-06-15 19:10:31,464 Epoch[21] Batch [130]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.107336,	
2017-06-15 19:10:36,286 Epoch[21] Batch [140]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.107615,	
2017-06-15 19:10:40,843 Epoch[21] Batch [150]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.108632,	
2017-06-15 19:10:45,501 Epoch[21] Batch [160]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.108665,	
2017-06-15 19:10:50,133 Epoch[21] Batch [170]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109319,	
2017-06-15 19:10:55,082 Epoch[21] Batch [180]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.109290,	
2017-06-15 19:10:59,653 Epoch[21] Batch [190]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108822,	
2017-06-15 19:11:04,355 Epoch[21] Batch [200]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.108634,	
2017-06-15 19:11:09,334 Epoch[21] Batch [210]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.109124,	
2017-06-15 19:11:14,028 Epoch[21] Batch [220]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.108775,	
2017-06-15 19:11:18,730 Epoch[21] Batch [230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.108680,	
2017-06-15 19:11:23,328 Epoch[21] Batch [240]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108542,	
2017-06-15 19:11:28,681 Epoch[21] Batch [250]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.108749,	
2017-06-15 19:11:33,281 Epoch[21] Batch [260]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108895,	
2017-06-15 19:11:37,852 Epoch[21] Batch [270]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108650,	
2017-06-15 19:11:42,456 Epoch[21] Batch [280]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108248,	
2017-06-15 19:11:47,018 Epoch[21] Batch [290]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108103,	
2017-06-15 19:11:51,773 Epoch[21] Batch [300]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108242,	
2017-06-15 19:11:56,255 Epoch[21] Batch [310]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.108068,	
2017-06-15 19:12:01,242 Epoch[21] Batch [320]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.107604,	
2017-06-15 19:12:05,808 Epoch[21] Batch [330]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.107522,	
2017-06-15 19:12:10,554 Epoch[21] Batch [340]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.107676,	
2017-06-15 19:12:15,161 Epoch[21] Batch [350]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.107757,	
2017-06-15 19:12:20,488 Epoch[21] Batch [360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107634,	
2017-06-15 19:12:25,002 Epoch[21] Batch [370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.107379,	
2017-06-15 19:12:29,590 Epoch[21] Batch [380]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.107451,	
2017-06-15 19:12:34,254 Epoch[21] Batch [390]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.107692,	
2017-06-15 19:12:38,834 Epoch[21] Batch [400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.107452,	
2017-06-15 19:12:43,393 Epoch[21] Batch [410]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108031,	
2017-06-15 19:12:48,048 Epoch[21] Batch [420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.108111,	
2017-06-15 19:12:52,720 Epoch[21] Batch [430]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.108000,	
2017-06-15 19:12:57,335 Epoch[21] Batch [440]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.107960,	
2017-06-15 19:13:01,880 Epoch[21] Batch [450]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.108560,	
2017-06-15 19:13:06,715 Epoch[21] Batch [460]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.108473,	
2017-06-15 19:13:11,338 Epoch[21] Batch [470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.108274,	
2017-06-15 19:13:16,150 Epoch[21] Batch [480]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.108010,	
2017-06-15 19:13:20,852 Epoch[21] Batch [490]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.107943,	
2017-06-15 19:13:25,554 Epoch[21] Batch [500]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.108120,	
2017-06-15 19:13:30,103 Epoch[21] Batch [510]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107847,	
2017-06-15 19:13:34,854 Epoch[21] Batch [520]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.107934,	
2017-06-15 19:13:39,473 Epoch[21] Batch [530]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.107854,	
2017-06-15 19:13:44,214 Epoch[21] Batch [540]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.107856,	
2017-06-15 19:13:48,939 Epoch[21] Batch [550]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.107809,	
2017-06-15 19:13:53,481 Epoch[21] Batch [560]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.107731,	
2017-06-15 19:13:58,724 Epoch[21] Batch [570]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.107979,	
2017-06-15 19:14:03,480 Epoch[21] Batch [580]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108003,	
2017-06-15 19:14:08,377 Epoch[21] Batch [590]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.108096,	
2017-06-15 19:14:13,109 Epoch[21] Batch [600]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.108089,	
2017-06-15 19:14:17,955 Epoch[21] Batch [610]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.108113,	
2017-06-15 19:14:22,480 Epoch[21] Batch [620]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107988,	
2017-06-15 19:14:27,216 Epoch[21] Batch [630]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.108204,	
2017-06-15 19:14:32,155 Epoch[21] Batch [640]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.108243,	
2017-06-15 19:14:36,912 Epoch[21] Batch [650]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108408,	
2017-06-15 19:14:41,670 Epoch[21] Batch [660]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108457,	
2017-06-15 19:14:46,320 Epoch[21] Batch [670]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108464,	
2017-06-15 19:14:51,056 Epoch[21] Batch [680]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.108495,	
2017-06-15 19:14:55,678 Epoch[21] Batch [690]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.108674,	
2017-06-15 19:15:00,793 Epoch[21] Batch [700]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.108594,	
2017-06-15 19:15:05,399 Epoch[21] Batch [710]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108519,	
2017-06-15 19:15:10,100 Epoch[21] Batch [720]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.108472,	
2017-06-15 19:15:14,984 Epoch[21] Batch [730]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.108486,	
2017-06-15 19:15:19,592 Epoch[21] Batch [740]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.108323,	
2017-06-15 19:15:24,205 Epoch[21] Batch [750]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108108,	
2017-06-15 19:15:28,832 Epoch[21] Batch [760]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.108039,	
2017-06-15 19:15:33,645 Epoch[21] Batch [770]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.107944,	
2017-06-15 19:15:38,225 Epoch[21] Batch [780]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.107844,	
2017-06-15 19:15:42,790 Epoch[21] Batch [790]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108085,	
2017-06-15 19:15:47,380 Epoch[21] Batch [800]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.107922,	
2017-06-15 19:15:51,971 Epoch[21] Batch [810]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.107963,	
2017-06-15 19:15:56,836 Epoch[21] Batch [820]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.107948,	
2017-06-15 19:16:01,476 Epoch[21] Batch [830]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107999,	
2017-06-15 19:16:06,519 Epoch[21] Batch [840]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.108004,	
2017-06-15 19:16:10,933 Epoch[21] Batch [850]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.108024,	
2017-06-15 19:16:15,788 Epoch[21] Batch [860]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.108041,	
2017-06-15 19:16:20,340 Epoch[21] Batch [870]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.108071,	
2017-06-15 19:16:25,454 Epoch[21] Batch [880]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.108110,	
2017-06-15 19:16:30,028 Epoch[21] Batch [890]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108243,	
2017-06-15 19:16:34,909 Epoch[21] Batch [900]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.108183,	
2017-06-15 19:16:39,714 Epoch[21] Batch [910]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.108290,	
2017-06-15 19:16:44,396 Epoch[21] Batch [920]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.108225,	
2017-06-15 19:16:49,325 Epoch[21] Batch [930]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.108122,	
2017-06-15 19:16:53,851 Epoch[21] Batch [940]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108173,	
2017-06-15 19:16:58,876 Epoch[21] Batch [950]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.108123,	
2017-06-15 19:17:03,411 Epoch[21] Batch [960]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108124,	
2017-06-15 19:17:08,129 Epoch[21] Batch [970]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.108154,	
2017-06-15 19:17:12,660 Epoch[21] Batch [980]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.108143,	
2017-06-15 19:17:17,944 Epoch[21] Batch [990]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108132,	
2017-06-15 19:17:22,506 Epoch[21] Batch [1000]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108088,	
2017-06-15 19:17:27,070 Epoch[21] Batch [1010]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108050,	
2017-06-15 19:17:32,112 Epoch[21] Batch [1020]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.108237,	
2017-06-15 19:17:36,868 Epoch[21] Batch [1030]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108201,	
2017-06-15 19:17:42,211 Epoch[21] Batch [1040]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.108211,	
2017-06-15 19:17:46,779 Epoch[21] Batch [1050]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108197,	
2017-06-15 19:17:51,663 Epoch[21] Batch [1060]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.108206,	
2017-06-15 19:17:56,201 Epoch[21] Batch [1070]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108063,	
2017-06-15 19:18:01,437 Epoch[21] Batch [1080]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.107981,	
2017-06-15 19:18:06,027 Epoch[21] Batch [1090]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.108146,	
2017-06-15 19:18:10,881 Epoch[21] Batch [1100]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.108177,	
2017-06-15 19:18:15,617 Epoch[21] Batch [1110]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.108156,	
2017-06-15 19:18:20,255 Epoch[21] Batch [1120]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.108108,	
2017-06-15 19:18:25,392 Epoch[21] Batch [1130]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.108144,	
2017-06-15 19:18:30,014 Epoch[21] Batch [1140]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.108109,	
2017-06-15 19:18:34,854 Epoch[21] Batch [1150]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.108009,	
2017-06-15 19:18:39,501 Epoch[21] Batch [1160]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.107994,	
2017-06-15 19:18:44,044 Epoch[21] Batch [1170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107907,	
2017-06-15 19:18:48,748 Epoch[21] Batch [1180]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.107862,	
2017-06-15 19:18:53,645 Epoch[21] Batch [1190]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.107787,	
2017-06-15 19:18:58,559 Epoch[21] Batch [1200]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.107916,	
2017-06-15 19:19:03,603 Epoch[21] Batch [1210]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.107899,	
2017-06-15 19:19:08,244 Epoch[21] Batch [1220]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107912,	
2017-06-15 19:19:12,960 Epoch[21] Batch [1230]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.108163,	
2017-06-15 19:19:18,277 Epoch[21] Batch [1240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.108237,	
2017-06-15 19:19:23,070 Epoch[21] Batch [1250]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.108207,	
2017-06-15 19:19:27,790 Epoch[21] Batch [1260]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.108179,	
2017-06-15 19:19:33,167 Epoch[21] Batch [1270]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.108158,	
2017-06-15 19:19:38,335 Epoch[21] Batch [1280]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108150,	
2017-06-15 19:19:43,051 Epoch[21] Batch [1290]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.108060,	
2017-06-15 19:19:47,820 Epoch[21] Batch [1300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.108133,	
2017-06-15 19:19:52,456 Epoch[21] Batch [1310]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.108075,	
2017-06-15 19:19:57,391 Epoch[21] Batch [1320]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.108026,	
2017-06-15 19:20:02,073 Epoch[21] Batch [1330]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.108074,	
2017-06-15 19:20:06,900 Epoch[21] Batch [1340]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.108022,	
2017-06-15 19:20:11,497 Epoch[21] Batch [1350]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107978,	
2017-06-15 19:20:16,303 Epoch[21] Batch [1360]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.107901,	
2017-06-15 19:20:20,979 Epoch[21] Batch [1370]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.107886,	
2017-06-15 19:20:26,023 Epoch[21] Batch [1380]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.107930,	
2017-06-15 19:20:30,931 Epoch[21] Batch [1390]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.107918,	
2017-06-15 19:20:35,779 Epoch[21] Batch [1400]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.107883,	
2017-06-15 19:20:40,839 Epoch[21] Batch [1410]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.107786,	
2017-06-15 19:20:45,486 Epoch[21] Batch [1420]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.107766,	
2017-06-15 19:20:50,154 Epoch[21] Batch [1430]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.107717,	
2017-06-15 19:20:54,643 Epoch[21] Batch [1440]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.107732,	
2017-06-15 19:20:59,276 Epoch[21] Batch [1450]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.107820,	
2017-06-15 19:21:03,913 Epoch[21] Batch [1460]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107761,	
2017-06-15 19:21:08,877 Epoch[21] Batch [1470]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.107811,	
2017-06-15 19:21:13,561 Epoch[21] Batch [1480]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.107799,	
2017-06-15 19:21:16,369 Epoch[21] Train-FCNLogLoss=0.107831
2017-06-15 19:21:16,369 Epoch[21] Time cost=706.156
2017-06-15 19:21:17,048 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0022.params"
2017-06-15 19:21:18,822 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0022.states"
2017-06-15 19:21:24,371 Epoch[22] Batch [10]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094628,	
2017-06-15 19:21:29,410 Epoch[22] Batch [20]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.096163,	
2017-06-15 19:21:34,314 Epoch[22] Batch [30]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.095620,	
2017-06-15 19:21:39,319 Epoch[22] Batch [40]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.097645,	
2017-06-15 19:21:43,918 Epoch[22] Batch [50]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097060,	
2017-06-15 19:21:48,532 Epoch[22] Batch [60]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.098143,	
2017-06-15 19:21:53,152 Epoch[22] Batch [70]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.100151,	
2017-06-15 19:21:57,773 Epoch[22] Batch [80]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.100377,	
2017-06-15 19:22:02,780 Epoch[22] Batch [90]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.101659,	
2017-06-15 19:22:07,396 Epoch[22] Batch [100]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.101908,	
2017-06-15 19:22:12,180 Epoch[22] Batch [110]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.101981,	
2017-06-15 19:22:17,169 Epoch[22] Batch [120]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.103719,	
2017-06-15 19:22:22,160 Epoch[22] Batch [130]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.103902,	
2017-06-15 19:22:26,896 Epoch[22] Batch [140]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.104149,	
2017-06-15 19:22:32,019 Epoch[22] Batch [150]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.102976,	
2017-06-15 19:22:37,518 Epoch[22] Batch [160]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.102863,	
2017-06-15 19:22:42,593 Epoch[22] Batch [170]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.103526,	
2017-06-15 19:22:47,387 Epoch[22] Batch [180]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.103507,	
2017-06-15 19:22:52,685 Epoch[22] Batch [190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.103794,	
2017-06-15 19:22:57,379 Epoch[22] Batch [200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.103574,	
2017-06-15 19:23:02,231 Epoch[22] Batch [210]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.103850,	
2017-06-15 19:23:06,994 Epoch[22] Batch [220]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.103858,	
2017-06-15 19:23:12,220 Epoch[22] Batch [230]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.103541,	
2017-06-15 19:23:17,032 Epoch[22] Batch [240]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.104108,	
2017-06-15 19:23:21,760 Epoch[22] Batch [250]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.104590,	
2017-06-15 19:23:26,540 Epoch[22] Batch [260]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.105040,	
2017-06-15 19:23:31,168 Epoch[22] Batch [270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.105259,	
2017-06-15 19:23:35,804 Epoch[22] Batch [280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.105244,	
2017-06-15 19:23:40,719 Epoch[22] Batch [290]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.105345,	
2017-06-15 19:23:45,571 Epoch[22] Batch [300]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.105399,	
2017-06-15 19:23:50,787 Epoch[22] Batch [310]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.105862,	
2017-06-15 19:23:55,488 Epoch[22] Batch [320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.105815,	
2017-06-15 19:24:00,348 Epoch[22] Batch [330]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.105514,	
2017-06-15 19:24:05,156 Epoch[22] Batch [340]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.105552,	
2017-06-15 19:24:10,418 Epoch[22] Batch [350]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.105610,	
2017-06-15 19:24:15,130 Epoch[22] Batch [360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.105546,	
2017-06-15 19:24:19,904 Epoch[22] Batch [370]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.105846,	
2017-06-15 19:24:25,132 Epoch[22] Batch [380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.105607,	
2017-06-15 19:24:30,432 Epoch[22] Batch [390]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.105536,	
2017-06-15 19:24:35,423 Epoch[22] Batch [400]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.105353,	
2017-06-15 19:24:40,171 Epoch[22] Batch [410]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.105227,	
2017-06-15 19:24:45,194 Epoch[22] Batch [420]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.104941,	
2017-06-15 19:24:50,876 Epoch[22] Batch [430]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.104997,	
2017-06-15 19:24:56,404 Epoch[22] Batch [440]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.104822,	
2017-06-15 19:25:01,155 Epoch[22] Batch [450]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.104737,	
2017-06-15 19:25:05,910 Epoch[22] Batch [460]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.104967,	
2017-06-15 19:25:10,610 Epoch[22] Batch [470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.104931,	
2017-06-15 19:25:15,265 Epoch[22] Batch [480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.104937,	
2017-06-15 19:25:19,914 Epoch[22] Batch [490]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.105049,	
2017-06-15 19:25:24,512 Epoch[22] Batch [500]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.105039,	
2017-06-15 19:25:29,390 Epoch[22] Batch [510]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.105034,	
2017-06-15 19:25:34,537 Epoch[22] Batch [520]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.104888,	
2017-06-15 19:25:39,378 Epoch[22] Batch [530]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.104643,	
2017-06-15 19:25:44,141 Epoch[22] Batch [540]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.104643,	
2017-06-15 19:25:49,220 Epoch[22] Batch [550]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.104752,	
2017-06-15 19:25:53,969 Epoch[22] Batch [560]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.104856,	
2017-06-15 19:25:58,884 Epoch[22] Batch [570]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.104878,	
2017-06-15 19:26:03,728 Epoch[22] Batch [580]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.104906,	
2017-06-15 19:26:08,831 Epoch[22] Batch [590]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.104914,	
2017-06-15 19:26:14,195 Epoch[22] Batch [600]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104949,	
2017-06-15 19:26:19,017 Epoch[22] Batch [610]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.105012,	
2017-06-15 19:26:24,612 Epoch[22] Batch [620]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.105126,	
2017-06-15 19:26:29,237 Epoch[22] Batch [630]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.105002,	
2017-06-15 19:26:34,417 Epoch[22] Batch [640]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.104838,	
2017-06-15 19:26:38,932 Epoch[22] Batch [650]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.104834,	
2017-06-15 19:26:44,359 Epoch[22] Batch [660]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.104764,	
2017-06-15 19:26:49,115 Epoch[22] Batch [670]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.104548,	
2017-06-15 19:26:54,244 Epoch[22] Batch [680]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.104681,	
2017-06-15 19:26:58,838 Epoch[22] Batch [690]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.104593,	
2017-06-15 19:27:04,396 Epoch[22] Batch [700]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.104669,	
2017-06-15 19:27:09,093 Epoch[22] Batch [710]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.104727,	
2017-06-15 19:27:14,339 Epoch[22] Batch [720]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.104662,	
2017-06-15 19:27:18,859 Epoch[22] Batch [730]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104482,	
2017-06-15 19:27:24,637 Epoch[22] Batch [740]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104528,	
2017-06-15 19:27:29,225 Epoch[22] Batch [750]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.104480,	
2017-06-15 19:27:35,189 Epoch[22] Batch [760]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.104380,	
2017-06-15 19:27:40,820 Epoch[22] Batch [770]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.104561,	
2017-06-15 19:27:46,189 Epoch[22] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.104455,	
2017-06-15 19:27:50,841 Epoch[22] Batch [790]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.104358,	
2017-06-15 19:27:56,081 Epoch[22] Batch [800]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.104326,	
2017-06-15 19:28:00,924 Epoch[22] Batch [810]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.104449,	
2017-06-15 19:28:06,096 Epoch[22] Batch [820]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.104604,	
2017-06-15 19:28:11,486 Epoch[22] Batch [830]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.104537,	
2017-06-15 19:28:16,247 Epoch[22] Batch [840]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.104521,	
2017-06-15 19:28:21,483 Epoch[22] Batch [850]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.104477,	
2017-06-15 19:28:26,350 Epoch[22] Batch [860]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.104498,	
2017-06-15 19:28:31,539 Epoch[22] Batch [870]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.104394,	
2017-06-15 19:28:36,174 Epoch[22] Batch [880]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.104465,	
2017-06-15 19:28:41,930 Epoch[22] Batch [890]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.104331,	
2017-06-15 19:28:46,587 Epoch[22] Batch [900]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.104365,	
2017-06-15 19:28:52,338 Epoch[22] Batch [910]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.104655,	
2017-06-15 19:28:57,146 Epoch[22] Batch [920]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.104727,	
2017-06-15 19:29:02,764 Epoch[22] Batch [930]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.104844,	
2017-06-15 19:29:07,401 Epoch[22] Batch [940]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.104840,	
2017-06-15 19:29:12,995 Epoch[22] Batch [950]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.104627,	
2017-06-15 19:29:17,722 Epoch[22] Batch [960]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.104576,	
2017-06-15 19:29:23,438 Epoch[22] Batch [970]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.104746,	
2017-06-15 19:29:28,170 Epoch[22] Batch [980]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.104577,	
2017-06-15 19:29:34,274 Epoch[22] Batch [990]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104586,	
2017-06-15 19:29:38,817 Epoch[22] Batch [1000]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.104657,	
2017-06-15 19:29:44,151 Epoch[22] Batch [1010]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.104636,	
2017-06-15 19:29:48,722 Epoch[22] Batch [1020]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.104738,	
2017-06-15 19:29:54,115 Epoch[22] Batch [1030]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.104662,	
2017-06-15 19:29:59,233 Epoch[22] Batch [1040]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.104681,	
2017-06-15 19:30:04,594 Epoch[22] Batch [1050]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104647,	
2017-06-15 19:30:10,078 Epoch[22] Batch [1060]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.104779,	
2017-06-15 19:30:14,914 Epoch[22] Batch [1070]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.104830,	
2017-06-15 19:30:20,728 Epoch[22] Batch [1080]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104775,	
2017-06-15 19:30:25,535 Epoch[22] Batch [1090]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.104900,	
2017-06-15 19:30:30,676 Epoch[22] Batch [1100]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.104948,	
2017-06-15 19:30:35,544 Epoch[22] Batch [1110]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.104994,	
2017-06-15 19:30:41,066 Epoch[22] Batch [1120]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.104952,	
2017-06-15 19:30:45,861 Epoch[22] Batch [1130]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.105006,	
2017-06-15 19:30:51,263 Epoch[22] Batch [1140]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.104964,	
2017-06-15 19:30:55,872 Epoch[22] Batch [1150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.104898,	
2017-06-15 19:31:01,420 Epoch[22] Batch [1160]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.104876,	
2017-06-15 19:31:06,068 Epoch[22] Batch [1170]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.104786,	
2017-06-15 19:31:12,100 Epoch[22] Batch [1180]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.104805,	
2017-06-15 19:31:16,967 Epoch[22] Batch [1190]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.104731,	
2017-06-15 19:31:22,944 Epoch[22] Batch [1200]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104809,	
2017-06-15 19:31:27,577 Epoch[22] Batch [1210]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.104776,	
2017-06-15 19:31:33,804 Epoch[22] Batch [1220]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.104675,	
2017-06-15 19:31:38,608 Epoch[22] Batch [1230]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.104723,	
2017-06-15 19:31:44,130 Epoch[22] Batch [1240]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.104789,	
2017-06-15 19:31:48,839 Epoch[22] Batch [1250]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104902,	
2017-06-15 19:31:54,789 Epoch[22] Batch [1260]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104999,	
2017-06-15 19:31:59,365 Epoch[22] Batch [1270]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.105026,	
2017-06-15 19:32:05,478 Epoch[22] Batch [1280]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.105204,	
2017-06-15 19:32:10,035 Epoch[22] Batch [1290]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105354,	
2017-06-15 19:32:15,969 Epoch[22] Batch [1300]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105581,	
2017-06-15 19:32:20,718 Epoch[22] Batch [1310]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.105633,	
2017-06-15 19:32:26,514 Epoch[22] Batch [1320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105608,	
2017-06-15 19:32:31,012 Epoch[22] Batch [1330]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.105626,	
2017-06-15 19:32:36,707 Epoch[22] Batch [1340]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.105603,	
2017-06-15 19:32:41,211 Epoch[22] Batch [1350]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.105529,	
2017-06-15 19:32:46,652 Epoch[22] Batch [1360]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.105469,	
2017-06-15 19:32:51,549 Epoch[22] Batch [1370]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.105569,	
2017-06-15 19:32:57,165 Epoch[22] Batch [1380]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.105543,	
2017-06-15 19:33:01,602 Epoch[22] Batch [1390]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.105581,	
2017-06-15 19:33:07,894 Epoch[22] Batch [1400]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.105556,	
2017-06-15 19:33:12,746 Epoch[22] Batch [1410]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.105555,	
2017-06-15 19:33:18,461 Epoch[22] Batch [1420]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.105532,	
2017-06-15 19:33:23,753 Epoch[22] Batch [1430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.105527,	
2017-06-15 19:33:29,129 Epoch[22] Batch [1440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.105472,	
2017-06-15 19:33:34,073 Epoch[22] Batch [1450]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.105449,	
2017-06-15 19:33:39,627 Epoch[22] Batch [1460]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.105419,	
2017-06-15 19:33:44,482 Epoch[22] Batch [1470]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.105368,	
2017-06-15 19:33:50,112 Epoch[22] Batch [1480]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.105337,	
2017-06-15 19:33:53,053 Epoch[22] Train-FCNLogLoss=0.105351
2017-06-15 19:33:53,053 Epoch[22] Time cost=754.231
2017-06-15 19:33:53,937 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0023.params"
2017-06-15 19:33:56,201 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0023.states"
2017-06-15 19:34:02,617 Epoch[23] Batch [10]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.091651,	
2017-06-15 19:34:07,322 Epoch[23] Batch [20]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.099796,	
2017-06-15 19:34:13,570 Epoch[23] Batch [30]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.101043,	
2017-06-15 19:34:18,350 Epoch[23] Batch [40]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.103294,	
2017-06-15 19:34:23,824 Epoch[23] Batch [50]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.103120,	
2017-06-15 19:34:28,467 Epoch[23] Batch [60]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.102796,	
2017-06-15 19:34:34,081 Epoch[23] Batch [70]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102287,	
2017-06-15 19:34:38,924 Epoch[23] Batch [80]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.102360,	
2017-06-15 19:34:45,286 Epoch[23] Batch [90]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.102134,	
2017-06-15 19:34:49,919 Epoch[23] Batch [100]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.101748,	
2017-06-15 19:34:56,488 Epoch[23] Batch [110]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.101686,	
2017-06-15 19:35:01,306 Epoch[23] Batch [120]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.100860,	
2017-06-15 19:35:06,599 Epoch[23] Batch [130]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100700,	
2017-06-15 19:35:12,026 Epoch[23] Batch [140]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.101082,	
2017-06-15 19:35:17,880 Epoch[23] Batch [150]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.101237,	
2017-06-15 19:35:23,570 Epoch[23] Batch [160]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.101645,	
2017-06-15 19:35:29,545 Epoch[23] Batch [170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101736,	
2017-06-15 19:35:35,059 Epoch[23] Batch [180]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.101545,	
2017-06-15 19:35:40,674 Epoch[23] Batch [190]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101497,	
2017-06-15 19:35:46,473 Epoch[23] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101604,	
2017-06-15 19:35:51,179 Epoch[23] Batch [210]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.101794,	
2017-06-15 19:35:56,964 Epoch[23] Batch [220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101723,	
2017-06-15 19:36:02,542 Epoch[23] Batch [230]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.101627,	
2017-06-15 19:36:08,842 Epoch[23] Batch [240]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.101565,	
2017-06-15 19:36:14,046 Epoch[23] Batch [250]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.101644,	
2017-06-15 19:36:20,875 Epoch[23] Batch [260]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.101600,	
2017-06-15 19:36:26,617 Epoch[23] Batch [270]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.101615,	
2017-06-15 19:36:32,165 Epoch[23] Batch [280]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.101906,	
2017-06-15 19:36:37,145 Epoch[23] Batch [290]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.101839,	
2017-06-15 19:36:42,600 Epoch[23] Batch [300]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.102058,	
2017-06-15 19:36:47,862 Epoch[23] Batch [310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.102489,	
2017-06-15 19:36:53,791 Epoch[23] Batch [320]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.102784,	
2017-06-15 19:37:00,279 Epoch[23] Batch [330]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.103113,	
2017-06-15 19:37:05,404 Epoch[23] Batch [340]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.103897,	
2017-06-15 19:37:11,246 Epoch[23] Batch [350]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103936,	
2017-06-15 19:37:16,641 Epoch[23] Batch [360]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.104200,	
2017-06-15 19:37:23,243 Epoch[23] Batch [370]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.104340,	
2017-06-15 19:37:28,350 Epoch[23] Batch [380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.104475,	
2017-06-15 19:37:35,115 Epoch[23] Batch [390]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.104198,	
2017-06-15 19:37:41,555 Epoch[23] Batch [400]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.104102,	
2017-06-15 19:37:47,465 Epoch[23] Batch [410]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104091,	
2017-06-15 19:37:54,036 Epoch[23] Batch [420]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.104140,	
2017-06-15 19:37:59,011 Epoch[23] Batch [430]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.104268,	
2017-06-15 19:38:05,236 Epoch[23] Batch [440]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.104231,	
2017-06-15 19:38:10,054 Epoch[23] Batch [450]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.104227,	
2017-06-15 19:38:16,069 Epoch[23] Batch [460]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.104302,	
2017-06-15 19:38:21,367 Epoch[23] Batch [470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.104608,	
2017-06-15 19:38:27,680 Epoch[23] Batch [480]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.104654,	
2017-06-15 19:38:32,683 Epoch[23] Batch [490]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.104611,	
2017-06-15 19:38:38,974 Epoch[23] Batch [500]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.104715,	
2017-06-15 19:38:44,108 Epoch[23] Batch [510]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.105181,	
2017-06-15 19:38:51,091 Epoch[23] Batch [520]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.105332,	
2017-06-15 19:38:57,413 Epoch[23] Batch [530]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.105488,	
2017-06-15 19:39:02,423 Epoch[23] Batch [540]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.105361,	
2017-06-15 19:39:08,096 Epoch[23] Batch [550]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.105404,	
2017-06-15 19:39:12,994 Epoch[23] Batch [560]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.105339,	
2017-06-15 19:39:19,129 Epoch[23] Batch [570]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.105264,	
2017-06-15 19:39:24,380 Epoch[23] Batch [580]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.105373,	
2017-06-15 19:39:30,398 Epoch[23] Batch [590]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.105263,	
2017-06-15 19:39:35,328 Epoch[23] Batch [600]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.105175,	
2017-06-15 19:39:41,803 Epoch[23] Batch [610]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.105130,	
2017-06-15 19:39:46,821 Epoch[23] Batch [620]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.105231,	
2017-06-15 19:39:53,323 Epoch[23] Batch [630]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.105194,	
2017-06-15 19:39:58,348 Epoch[23] Batch [640]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.105272,	
2017-06-15 19:40:04,904 Epoch[23] Batch [650]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.105120,	
2017-06-15 19:40:10,298 Epoch[23] Batch [660]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.105201,	
2017-06-15 19:40:15,752 Epoch[23] Batch [670]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.105230,	
2017-06-15 19:40:21,459 Epoch[23] Batch [680]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.105145,	
2017-06-15 19:40:27,299 Epoch[23] Batch [690]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105279,	
2017-06-15 19:40:33,070 Epoch[23] Batch [700]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105304,	
2017-06-15 19:40:38,870 Epoch[23] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105317,	
2017-06-15 19:40:45,927 Epoch[23] Batch [720]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.105282,	
2017-06-15 19:40:50,578 Epoch[23] Batch [730]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.105519,	
2017-06-15 19:40:57,457 Epoch[23] Batch [740]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.105330,	
2017-06-15 19:41:02,760 Epoch[23] Batch [750]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.105450,	
2017-06-15 19:41:09,766 Epoch[23] Batch [760]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.105391,	
2017-06-15 19:41:16,244 Epoch[23] Batch [770]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.105323,	
2017-06-15 19:41:21,565 Epoch[23] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105357,	
2017-06-15 19:41:28,440 Epoch[23] Batch [790]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.105256,	
2017-06-15 19:41:33,794 Epoch[23] Batch [800]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105188,	
2017-06-15 19:41:39,818 Epoch[23] Batch [810]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.105100,	
2017-06-15 19:41:44,870 Epoch[23] Batch [820]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.105033,	
2017-06-15 19:41:50,523 Epoch[23] Batch [830]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.105020,	
2017-06-15 19:41:56,640 Epoch[23] Batch [840]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.104994,	
2017-06-15 19:42:02,218 Epoch[23] Batch [850]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.104933,	
2017-06-15 19:42:08,327 Epoch[23] Batch [860]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104926,	
2017-06-15 19:42:13,263 Epoch[23] Batch [870]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.104948,	
2017-06-15 19:42:19,469 Epoch[23] Batch [880]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.104902,	
2017-06-15 19:42:24,343 Epoch[23] Batch [890]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.104975,	
2017-06-15 19:42:31,145 Epoch[23] Batch [900]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.104966,	
2017-06-15 19:42:36,353 Epoch[23] Batch [910]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105002,	
2017-06-15 19:42:42,457 Epoch[23] Batch [920]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.105073,	
2017-06-15 19:42:47,527 Epoch[23] Batch [930]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.105132,	
2017-06-15 19:42:54,167 Epoch[23] Batch [940]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.105193,	
2017-06-15 19:43:00,666 Epoch[23] Batch [950]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.105143,	
2017-06-15 19:43:07,249 Epoch[23] Batch [960]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.105127,	
2017-06-15 19:43:14,294 Epoch[23] Batch [970]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.105110,	
2017-06-15 19:43:19,287 Epoch[23] Batch [980]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.105065,	
2017-06-15 19:43:25,157 Epoch[23] Batch [990]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104994,	
2017-06-15 19:43:30,541 Epoch[23] Batch [1000]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.104958,	
2017-06-15 19:43:37,027 Epoch[23] Batch [1010]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.104958,	
2017-06-15 19:43:43,362 Epoch[23] Batch [1020]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.104967,	
2017-06-15 19:43:51,088 Epoch[23] Batch [1030]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.105028,	
2017-06-15 19:43:58,046 Epoch[23] Batch [1040]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.104970,	
2017-06-15 19:44:05,447 Epoch[23] Batch [1050]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.104966,	
2017-06-15 19:44:13,496 Epoch[23] Batch [1060]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.104898,	
2017-06-15 19:44:21,126 Epoch[23] Batch [1070]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.104842,	
2017-06-15 19:44:27,373 Epoch[23] Batch [1080]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.104944,	
2017-06-15 19:44:34,195 Epoch[23] Batch [1090]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.104868,	
2017-06-15 19:44:40,722 Epoch[23] Batch [1100]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.104903,	
2017-06-15 19:44:47,043 Epoch[23] Batch [1110]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.105008,	
2017-06-15 19:44:54,298 Epoch[23] Batch [1120]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.104902,	
2017-06-15 19:45:01,661 Epoch[23] Batch [1130]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.104812,	
2017-06-15 19:45:08,946 Epoch[23] Batch [1140]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.104808,	
2017-06-15 19:45:13,983 Epoch[23] Batch [1150]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.104840,	
2017-06-15 19:45:21,491 Epoch[23] Batch [1160]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.104760,	
2017-06-15 19:45:28,845 Epoch[23] Batch [1170]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.104602,	
2017-06-15 19:45:34,211 Epoch[23] Batch [1180]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.104537,	
2017-06-15 19:45:41,038 Epoch[23] Batch [1190]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.104444,	
2017-06-15 19:45:46,488 Epoch[23] Batch [1200]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.104393,	
2017-06-15 19:45:53,666 Epoch[23] Batch [1210]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.104408,	
2017-06-15 19:45:59,126 Epoch[23] Batch [1220]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.104357,	
2017-06-15 19:46:04,984 Epoch[23] Batch [1230]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.104395,	
2017-06-15 19:46:12,089 Epoch[23] Batch [1240]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.104330,	
2017-06-15 19:46:19,432 Epoch[23] Batch [1250]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.104379,	
2017-06-15 19:46:26,232 Epoch[23] Batch [1260]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.104501,	
2017-06-15 19:46:32,950 Epoch[23] Batch [1270]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.104500,	
2017-06-15 19:46:37,808 Epoch[23] Batch [1280]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.104502,	
2017-06-15 19:46:44,688 Epoch[23] Batch [1290]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.104517,	
2017-06-15 19:46:50,096 Epoch[23] Batch [1300]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.104524,	
2017-06-15 19:46:56,906 Epoch[23] Batch [1310]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.104509,	
2017-06-15 19:47:02,635 Epoch[23] Batch [1320]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.104444,	
2017-06-15 19:47:08,991 Epoch[23] Batch [1330]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.104392,	
2017-06-15 19:47:15,324 Epoch[23] Batch [1340]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.104353,	
2017-06-15 19:47:21,163 Epoch[23] Batch [1350]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.104321,	
2017-06-15 19:47:27,743 Epoch[23] Batch [1360]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.104272,	
2017-06-15 19:47:33,045 Epoch[23] Batch [1370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.104309,	
2017-06-15 19:47:39,867 Epoch[23] Batch [1380]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.104315,	
2017-06-15 19:47:46,513 Epoch[23] Batch [1390]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.104256,	
2017-06-15 19:47:53,320 Epoch[23] Batch [1400]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.104224,	
2017-06-15 19:48:00,021 Epoch[23] Batch [1410]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.104265,	
2017-06-15 19:48:05,412 Epoch[23] Batch [1420]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.104338,	
2017-06-15 19:48:12,037 Epoch[23] Batch [1430]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.104267,	
2017-06-15 19:48:17,101 Epoch[23] Batch [1440]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.104297,	
2017-06-15 19:48:22,384 Epoch[23] Batch [1450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.104302,	
2017-06-15 19:48:28,341 Epoch[23] Batch [1460]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104314,	
2017-06-15 19:48:35,029 Epoch[23] Batch [1470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.104360,	
2017-06-15 19:48:41,591 Epoch[23] Batch [1480]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.104297,	
2017-06-15 19:48:45,122 Epoch[23] Train-FCNLogLoss=0.104309
2017-06-15 19:48:45,122 Epoch[23] Time cost=888.921
2017-06-15 19:48:45,752 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0024.params"
2017-06-15 19:48:48,567 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0024.states"
2017-06-15 19:48:56,087 Epoch[24] Batch [10]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.095976,	
2017-06-15 19:49:02,278 Epoch[24] Batch [20]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.105790,	
2017-06-15 19:49:08,151 Epoch[24] Batch [30]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.105364,	
2017-06-15 19:49:14,730 Epoch[24] Batch [40]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.104661,	
2017-06-15 19:49:20,863 Epoch[24] Batch [50]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.103497,	
2017-06-15 19:49:27,390 Epoch[24] Batch [60]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.107435,	
2017-06-15 19:49:33,720 Epoch[24] Batch [70]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.109587,	
2017-06-15 19:49:39,769 Epoch[24] Batch [80]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109687,	
2017-06-15 19:49:46,211 Epoch[24] Batch [90]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.108557,	
2017-06-15 19:49:53,436 Epoch[24] Batch [100]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.107963,	
2017-06-15 19:50:00,710 Epoch[24] Batch [110]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.108509,	
2017-06-15 19:50:07,558 Epoch[24] Batch [120]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.108622,	
2017-06-15 19:50:14,771 Epoch[24] Batch [130]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.108231,	
2017-06-15 19:50:21,012 Epoch[24] Batch [140]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.108092,	
2017-06-15 19:50:28,244 Epoch[24] Batch [150]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.107566,	
2017-06-15 19:50:34,755 Epoch[24] Batch [160]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.107805,	
2017-06-15 19:50:41,284 Epoch[24] Batch [170]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.106933,	
2017-06-15 19:50:48,181 Epoch[24] Batch [180]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.106400,	
2017-06-15 19:50:55,347 Epoch[24] Batch [190]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.106709,	
2017-06-15 19:51:02,388 Epoch[24] Batch [200]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.106311,	
2017-06-15 19:51:09,550 Epoch[24] Batch [210]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.105679,	
2017-06-15 19:51:16,479 Epoch[24] Batch [220]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.105946,	
2017-06-15 19:51:23,247 Epoch[24] Batch [230]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.105652,	
2017-06-15 19:51:31,042 Epoch[24] Batch [240]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.105570,	
2017-06-15 19:51:38,188 Epoch[24] Batch [250]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.105123,	
2017-06-15 19:51:44,707 Epoch[24] Batch [260]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.105330,	
2017-06-15 19:51:51,645 Epoch[24] Batch [270]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.105167,	
2017-06-15 19:51:58,559 Epoch[24] Batch [280]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.105019,	
2017-06-15 19:52:06,907 Epoch[24] Batch [290]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.104608,	
2017-06-15 19:52:15,001 Epoch[24] Batch [300]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.104166,	
2017-06-15 19:52:22,062 Epoch[24] Batch [310]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.104028,	
2017-06-15 19:52:30,012 Epoch[24] Batch [320]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.104083,	
2017-06-15 19:52:37,227 Epoch[24] Batch [330]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.104226,	
2017-06-15 19:52:44,155 Epoch[24] Batch [340]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.104322,	
2017-06-15 19:52:51,793 Epoch[24] Batch [350]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.104579,	
2017-06-15 19:52:59,588 Epoch[24] Batch [360]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.104695,	
2017-06-15 19:53:07,214 Epoch[24] Batch [370]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.104519,	
2017-06-15 19:53:15,280 Epoch[24] Batch [380]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.104470,	
2017-06-15 19:53:22,910 Epoch[24] Batch [390]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.104204,	
2017-06-15 19:53:30,697 Epoch[24] Batch [400]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.103899,	
2017-06-15 19:53:38,557 Epoch[24] Batch [410]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.103813,	
2017-06-15 19:53:45,552 Epoch[24] Batch [420]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.104029,	
2017-06-15 19:53:53,152 Epoch[24] Batch [430]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.103931,	
2017-06-15 19:54:00,765 Epoch[24] Batch [440]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.103902,	
2017-06-15 19:54:07,960 Epoch[24] Batch [450]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.103860,	
2017-06-15 19:54:15,095 Epoch[24] Batch [460]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.103907,	
2017-06-15 19:54:22,551 Epoch[24] Batch [470]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.103859,	
2017-06-15 19:54:29,907 Epoch[24] Batch [480]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.103630,	
2017-06-15 19:54:37,597 Epoch[24] Batch [490]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.103551,	
2017-06-15 19:54:44,961 Epoch[24] Batch [500]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.103783,	
2017-06-15 19:54:52,379 Epoch[24] Batch [510]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.103937,	
2017-06-15 19:54:59,315 Epoch[24] Batch [520]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.104048,	
2017-06-15 19:55:07,043 Epoch[24] Batch [530]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.103857,	
2017-06-15 19:55:14,437 Epoch[24] Batch [540]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.103904,	
2017-06-15 19:55:22,129 Epoch[24] Batch [550]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.103955,	
2017-06-15 19:55:29,468 Epoch[24] Batch [560]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.104123,	
2017-06-15 19:55:36,505 Epoch[24] Batch [570]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.103749,	
2017-06-15 19:55:44,396 Epoch[24] Batch [580]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.103625,	
2017-06-15 19:55:51,347 Epoch[24] Batch [590]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.103571,	
2017-06-15 19:55:58,721 Epoch[24] Batch [600]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.103729,	
2017-06-15 19:56:06,101 Epoch[24] Batch [610]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.103490,	
2017-06-15 19:56:12,919 Epoch[24] Batch [620]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.103309,	
2017-06-15 19:56:17,776 Epoch[24] Batch [630]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.103317,	
2017-06-15 19:56:25,259 Epoch[24] Batch [640]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.103504,	
2017-06-15 19:56:32,486 Epoch[24] Batch [650]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.103496,	
2017-06-15 19:56:39,459 Epoch[24] Batch [660]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.103567,	
2017-06-15 19:56:47,099 Epoch[24] Batch [670]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.103505,	
2017-06-15 19:56:54,141 Epoch[24] Batch [680]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.103668,	
2017-06-15 19:57:01,925 Epoch[24] Batch [690]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.103778,	
2017-06-15 19:57:08,908 Epoch[24] Batch [700]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.103683,	
2017-06-15 19:57:16,957 Epoch[24] Batch [710]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.103709,	
2017-06-15 19:57:24,388 Epoch[24] Batch [720]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.103565,	
2017-06-15 19:57:32,385 Epoch[24] Batch [730]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.103420,	
2017-06-15 19:57:39,903 Epoch[24] Batch [740]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.103237,	
2017-06-15 19:57:47,277 Epoch[24] Batch [750]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.103250,	
2017-06-15 19:57:53,851 Epoch[24] Batch [760]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.103253,	
2017-06-15 19:58:02,037 Epoch[24] Batch [770]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.103284,	
2017-06-15 19:58:09,465 Epoch[24] Batch [780]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.103238,	
2017-06-15 19:58:16,436 Epoch[24] Batch [790]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.103222,	
2017-06-15 19:58:23,388 Epoch[24] Batch [800]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.103257,	
2017-06-15 19:58:31,247 Epoch[24] Batch [810]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.103234,	
2017-06-15 19:58:38,102 Epoch[24] Batch [820]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.103131,	
2017-06-15 19:58:45,080 Epoch[24] Batch [830]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.103146,	
2017-06-15 19:58:52,571 Epoch[24] Batch [840]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.103064,	
2017-06-15 19:58:59,505 Epoch[24] Batch [850]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.103082,	
2017-06-15 19:59:07,330 Epoch[24] Batch [860]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.103155,	
2017-06-15 19:59:14,862 Epoch[24] Batch [870]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.103249,	
2017-06-15 19:59:22,089 Epoch[24] Batch [880]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.103316,	
2017-06-15 19:59:29,097 Epoch[24] Batch [890]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.103331,	
2017-06-15 19:59:36,949 Epoch[24] Batch [900]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.103234,	
2017-06-15 19:59:44,127 Epoch[24] Batch [910]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.103217,	
2017-06-15 19:59:50,990 Epoch[24] Batch [920]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.103223,	
2017-06-15 19:59:57,656 Epoch[24] Batch [930]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.103222,	
2017-06-15 20:00:04,827 Epoch[24] Batch [940]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.103353,	
2017-06-15 20:00:12,623 Epoch[24] Batch [950]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.103332,	
2017-06-15 20:00:19,847 Epoch[24] Batch [960]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.103738,	
2017-06-15 20:00:28,082 Epoch[24] Batch [970]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.103767,	
2017-06-15 20:00:34,912 Epoch[24] Batch [980]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.103818,	
2017-06-15 20:00:41,979 Epoch[24] Batch [990]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.103804,	
2017-06-15 20:00:49,300 Epoch[24] Batch [1000]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.103943,	
2017-06-15 20:00:57,663 Epoch[24] Batch [1010]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.103865,	
2017-06-15 20:01:05,440 Epoch[24] Batch [1020]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.103772,	
2017-06-15 20:01:11,908 Epoch[24] Batch [1030]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.103706,	
2017-06-15 20:01:18,704 Epoch[24] Batch [1040]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.103763,	
2017-06-15 20:01:25,076 Epoch[24] Batch [1050]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.103820,	
2017-06-15 20:01:32,945 Epoch[24] Batch [1060]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.103855,	
2017-06-15 20:01:40,616 Epoch[24] Batch [1070]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.103955,	
2017-06-15 20:01:48,221 Epoch[24] Batch [1080]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.103828,	
2017-06-15 20:01:54,985 Epoch[24] Batch [1090]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.103844,	
2017-06-15 20:02:02,597 Epoch[24] Batch [1100]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.103818,	
2017-06-15 20:02:09,346 Epoch[24] Batch [1110]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.103792,	
2017-06-15 20:02:17,168 Epoch[24] Batch [1120]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.103843,	
2017-06-15 20:02:25,235 Epoch[24] Batch [1130]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.103853,	
2017-06-15 20:02:33,904 Epoch[24] Batch [1140]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.103761,	
2017-06-15 20:02:43,634 Epoch[24] Batch [1150]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.103816,	
2017-06-15 20:02:50,967 Epoch[24] Batch [1160]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.103875,	
2017-06-15 20:02:58,940 Epoch[24] Batch [1170]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.103881,	
2017-06-15 20:03:05,928 Epoch[24] Batch [1180]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.103832,	
2017-06-15 20:03:13,753 Epoch[24] Batch [1190]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.103740,	
2017-06-15 20:03:21,460 Epoch[24] Batch [1200]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.103715,	
2017-06-15 20:03:28,790 Epoch[24] Batch [1210]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.103647,	
2017-06-15 20:03:36,584 Epoch[24] Batch [1220]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.103621,	
2017-06-15 20:03:44,016 Epoch[24] Batch [1230]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.103629,	
2017-06-15 20:03:52,513 Epoch[24] Batch [1240]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.103624,	
2017-06-15 20:04:01,069 Epoch[24] Batch [1250]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.103620,	
2017-06-15 20:04:08,566 Epoch[24] Batch [1260]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.103755,	
2017-06-15 20:04:15,723 Epoch[24] Batch [1270]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.103711,	
2017-06-15 20:04:23,546 Epoch[24] Batch [1280]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.103756,	
2017-06-15 20:04:30,919 Epoch[24] Batch [1290]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.103720,	
2017-06-15 20:04:39,518 Epoch[24] Batch [1300]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.103662,	
2017-06-15 20:04:47,021 Epoch[24] Batch [1310]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.103809,	
2017-06-15 20:04:55,134 Epoch[24] Batch [1320]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.103855,	
2017-06-15 20:05:03,031 Epoch[24] Batch [1330]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.103861,	
2017-06-15 20:05:10,601 Epoch[24] Batch [1340]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.103837,	
2017-06-15 20:05:18,543 Epoch[24] Batch [1350]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.103704,	
2017-06-15 20:05:26,363 Epoch[24] Batch [1360]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.103649,	
2017-06-15 20:05:33,516 Epoch[24] Batch [1370]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.103601,	
2017-06-15 20:05:41,317 Epoch[24] Batch [1380]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.103698,	
2017-06-15 20:05:48,574 Epoch[24] Batch [1390]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.103656,	
2017-06-15 20:05:55,756 Epoch[24] Batch [1400]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.103700,	
2017-06-15 20:06:02,781 Epoch[24] Batch [1410]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.103627,	
2017-06-15 20:06:09,762 Epoch[24] Batch [1420]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.103602,	
2017-06-15 20:06:18,126 Epoch[24] Batch [1430]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.103621,	
2017-06-15 20:06:25,235 Epoch[24] Batch [1440]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.103658,	
2017-06-15 20:06:31,773 Epoch[24] Batch [1450]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.103640,	
2017-06-15 20:06:39,336 Epoch[24] Batch [1460]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.103576,	
2017-06-15 20:06:46,752 Epoch[24] Batch [1470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.103543,	
2017-06-15 20:06:53,608 Epoch[24] Batch [1480]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.103566,	
2017-06-15 20:06:58,376 Epoch[24] Train-FCNLogLoss=0.103577
2017-06-15 20:06:58,376 Epoch[24] Time cost=1089.809
2017-06-15 20:06:59,631 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0025.params"
2017-06-15 20:07:02,346 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0025.states"
2017-06-15 20:07:09,629 Epoch[25] Batch [10]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.100525,	
2017-06-15 20:07:16,402 Epoch[25] Batch [20]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.095984,	
2017-06-15 20:07:22,581 Epoch[25] Batch [30]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.097850,	
2017-06-15 20:07:29,046 Epoch[25] Batch [40]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.098641,	
2017-06-15 20:07:35,534 Epoch[25] Batch [50]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.101242,	
2017-06-15 20:07:42,674 Epoch[25] Batch [60]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.101556,	
2017-06-15 20:07:51,105 Epoch[25] Batch [70]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.102849,	
2017-06-15 20:07:59,097 Epoch[25] Batch [80]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.103520,	
2017-06-15 20:08:05,987 Epoch[25] Batch [90]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.102460,	
2017-06-15 20:08:12,108 Epoch[25] Batch [100]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102251,	
2017-06-15 20:08:20,086 Epoch[25] Batch [110]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.102277,	
2017-06-15 20:08:25,975 Epoch[25] Batch [120]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.103016,	
2017-06-15 20:08:33,411 Epoch[25] Batch [130]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.102626,	
2017-06-15 20:08:40,884 Epoch[25] Batch [140]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.102972,	
2017-06-15 20:08:48,763 Epoch[25] Batch [150]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.102716,	
2017-06-15 20:08:55,487 Epoch[25] Batch [160]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.103238,	
2017-06-15 20:09:05,715 Epoch[25] Batch [170]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.102229,	
2017-06-15 20:09:14,350 Epoch[25] Batch [180]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.102077,	
2017-06-15 20:09:22,269 Epoch[25] Batch [190]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.101614,	
2017-06-15 20:09:30,149 Epoch[25] Batch [200]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.101215,	
2017-06-15 20:09:37,809 Epoch[25] Batch [210]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.101040,	
2017-06-15 20:09:44,759 Epoch[25] Batch [220]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.100997,	
2017-06-15 20:09:52,443 Epoch[25] Batch [230]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.101595,	
2017-06-15 20:09:59,671 Epoch[25] Batch [240]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.101435,	
2017-06-15 20:10:06,774 Epoch[25] Batch [250]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.101391,	
2017-06-15 20:10:14,212 Epoch[25] Batch [260]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.101303,	
2017-06-15 20:10:22,470 Epoch[25] Batch [270]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.101323,	
2017-06-15 20:10:30,502 Epoch[25] Batch [280]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.101438,	
2017-06-15 20:10:38,506 Epoch[25] Batch [290]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.101224,	
2017-06-15 20:10:46,045 Epoch[25] Batch [300]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.100939,	
2017-06-15 20:10:54,315 Epoch[25] Batch [310]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.100781,	
2017-06-15 20:11:03,500 Epoch[25] Batch [320]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.100781,	
2017-06-15 20:11:11,405 Epoch[25] Batch [330]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.100960,	
2017-06-15 20:11:18,623 Epoch[25] Batch [340]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.101160,	
2017-06-15 20:11:25,835 Epoch[25] Batch [350]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.101255,	
2017-06-15 20:11:32,936 Epoch[25] Batch [360]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.101289,	
2017-06-15 20:11:38,817 Epoch[25] Batch [370]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.101242,	
2017-06-15 20:11:46,047 Epoch[25] Batch [380]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.101657,	
2017-06-15 20:11:53,272 Epoch[25] Batch [390]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.101585,	
2017-06-15 20:12:00,525 Epoch[25] Batch [400]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.101427,	
2017-06-15 20:12:06,815 Epoch[25] Batch [410]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.101558,	
2017-06-15 20:12:14,012 Epoch[25] Batch [420]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.101626,	
2017-06-15 20:12:21,432 Epoch[25] Batch [430]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.101644,	
2017-06-15 20:12:29,735 Epoch[25] Batch [440]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.101861,	
2017-06-15 20:12:37,301 Epoch[25] Batch [450]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.102844,	
2017-06-15 20:12:45,027 Epoch[25] Batch [460]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.103038,	
2017-06-15 20:12:51,717 Epoch[25] Batch [470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.103440,	
2017-06-15 20:12:59,947 Epoch[25] Batch [480]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.103508,	
2017-06-15 20:13:06,989 Epoch[25] Batch [490]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.103746,	
2017-06-15 20:13:13,460 Epoch[25] Batch [500]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.103657,	
2017-06-15 20:13:21,421 Epoch[25] Batch [510]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.103697,	
2017-06-15 20:13:28,197 Epoch[25] Batch [520]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.103797,	
2017-06-15 20:13:35,151 Epoch[25] Batch [530]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.103884,	
2017-06-15 20:13:42,545 Epoch[25] Batch [540]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.103776,	
2017-06-15 20:13:50,692 Epoch[25] Batch [550]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.103579,	
2017-06-15 20:13:58,491 Epoch[25] Batch [560]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.103660,	
2017-06-15 20:14:06,029 Epoch[25] Batch [570]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.103562,	
2017-06-15 20:14:13,304 Epoch[25] Batch [580]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.103488,	
2017-06-15 20:14:20,901 Epoch[25] Batch [590]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.103311,	
2017-06-15 20:14:30,712 Epoch[25] Batch [600]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.103181,	
2017-06-15 20:14:37,900 Epoch[25] Batch [610]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.103454,	
2017-06-15 20:14:44,813 Epoch[25] Batch [620]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.103506,	
2017-06-15 20:14:51,966 Epoch[25] Batch [630]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.103618,	
2017-06-15 20:14:58,198 Epoch[25] Batch [640]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.103635,	
2017-06-15 20:15:05,325 Epoch[25] Batch [650]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.103655,	
2017-06-15 20:15:12,413 Epoch[25] Batch [660]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.103730,	
2017-06-15 20:15:19,477 Epoch[25] Batch [670]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.103732,	
2017-06-15 20:15:26,453 Epoch[25] Batch [680]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.103661,	
2017-06-15 20:15:33,331 Epoch[25] Batch [690]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.103637,	
2017-06-15 20:15:41,529 Epoch[25] Batch [700]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.103608,	
2017-06-15 20:15:49,493 Epoch[25] Batch [710]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.103546,	
2017-06-15 20:15:55,949 Epoch[25] Batch [720]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.103433,	
2017-06-15 20:16:02,498 Epoch[25] Batch [730]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.103498,	
2017-06-15 20:16:09,568 Epoch[25] Batch [740]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.103561,	
2017-06-15 20:16:17,197 Epoch[25] Batch [750]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.103515,	
2017-06-15 20:16:24,301 Epoch[25] Batch [760]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.103407,	
2017-06-15 20:16:32,102 Epoch[25] Batch [770]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.103435,	
2017-06-15 20:16:39,748 Epoch[25] Batch [780]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.103228,	
2017-06-15 20:16:46,671 Epoch[25] Batch [790]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.103135,	
2017-06-15 20:16:53,913 Epoch[25] Batch [800]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.103182,	
2017-06-15 20:17:00,891 Epoch[25] Batch [810]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.103274,	
2017-06-15 20:17:07,802 Epoch[25] Batch [820]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.103242,	
2017-06-15 20:17:15,514 Epoch[25] Batch [830]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.103142,	
2017-06-15 20:17:23,450 Epoch[25] Batch [840]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.103115,	
2017-06-15 20:17:30,276 Epoch[25] Batch [850]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.102968,	
2017-06-15 20:17:38,044 Epoch[25] Batch [860]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.102943,	
2017-06-15 20:17:45,444 Epoch[25] Batch [870]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.102870,	
2017-06-15 20:17:53,127 Epoch[25] Batch [880]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.102954,	
2017-06-15 20:18:01,592 Epoch[25] Batch [890]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.103035,	
2017-06-15 20:18:08,838 Epoch[25] Batch [900]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.102977,	
2017-06-15 20:18:16,193 Epoch[25] Batch [910]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.102833,	
2017-06-15 20:18:24,487 Epoch[25] Batch [920]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.102763,	
2017-06-15 20:18:32,004 Epoch[25] Batch [930]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.102671,	
2017-06-15 20:18:40,108 Epoch[25] Batch [940]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.102609,	
2017-06-15 20:18:47,271 Epoch[25] Batch [950]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.102678,	
2017-06-15 20:18:55,277 Epoch[25] Batch [960]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.102591,	
2017-06-15 20:19:02,909 Epoch[25] Batch [970]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.102617,	
2017-06-15 20:19:10,797 Epoch[25] Batch [980]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.102648,	
2017-06-15 20:19:17,830 Epoch[25] Batch [990]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.102514,	
2017-06-15 20:19:25,398 Epoch[25] Batch [1000]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.102582,	
2017-06-15 20:19:32,982 Epoch[25] Batch [1010]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.102591,	
2017-06-15 20:19:39,774 Epoch[25] Batch [1020]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.102702,	
2017-06-15 20:19:47,340 Epoch[25] Batch [1030]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.102699,	
2017-06-15 20:19:54,627 Epoch[25] Batch [1040]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.102688,	
2017-06-15 20:20:02,765 Epoch[25] Batch [1050]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.102715,	
2017-06-15 20:20:10,282 Epoch[25] Batch [1060]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.102740,	
2017-06-15 20:20:17,560 Epoch[25] Batch [1070]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.102871,	
2017-06-15 20:20:26,240 Epoch[25] Batch [1080]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.102924,	
2017-06-15 20:20:33,865 Epoch[25] Batch [1090]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.102858,	
2017-06-15 20:20:40,814 Epoch[25] Batch [1100]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102845,	
2017-06-15 20:20:48,473 Epoch[25] Batch [1110]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.102833,	
2017-06-15 20:20:56,403 Epoch[25] Batch [1120]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.102954,	
2017-06-15 20:21:03,966 Epoch[25] Batch [1130]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.102924,	
2017-06-15 20:21:11,673 Epoch[25] Batch [1140]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.102944,	
2017-06-15 20:21:18,636 Epoch[25] Batch [1150]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.102944,	
2017-06-15 20:21:26,592 Epoch[25] Batch [1160]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.102936,	
2017-06-15 20:21:34,604 Epoch[25] Batch [1170]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.102914,	
2017-06-15 20:21:42,136 Epoch[25] Batch [1180]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.102888,	
2017-06-15 20:21:50,452 Epoch[25] Batch [1190]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.102810,	
2017-06-15 20:21:57,263 Epoch[25] Batch [1200]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.102768,	
2017-06-15 20:22:05,392 Epoch[25] Batch [1210]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.102812,	
2017-06-15 20:22:13,294 Epoch[25] Batch [1220]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.102714,	
2017-06-15 20:22:21,483 Epoch[25] Batch [1230]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.102716,	
2017-06-15 20:22:29,172 Epoch[25] Batch [1240]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.102648,	
2017-06-15 20:22:36,249 Epoch[25] Batch [1250]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.102633,	
2017-06-15 20:22:43,531 Epoch[25] Batch [1260]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.102580,	
2017-06-15 20:22:51,770 Epoch[25] Batch [1270]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.102592,	
2017-06-15 20:22:58,612 Epoch[25] Batch [1280]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.102515,	
2017-06-15 20:23:05,490 Epoch[25] Batch [1290]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.102569,	
2017-06-15 20:23:13,768 Epoch[25] Batch [1300]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.102591,	
2017-06-15 20:23:21,913 Epoch[25] Batch [1310]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.102551,	
2017-06-15 20:23:30,013 Epoch[25] Batch [1320]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.102542,	
2017-06-15 20:23:38,896 Epoch[25] Batch [1330]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.102543,	
2017-06-15 20:23:46,783 Epoch[25] Batch [1340]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.102462,	
2017-06-15 20:23:54,003 Epoch[25] Batch [1350]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.102479,	
2017-06-15 20:24:02,241 Epoch[25] Batch [1360]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.102431,	
2017-06-15 20:24:10,111 Epoch[25] Batch [1370]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.102426,	
2017-06-15 20:24:18,520 Epoch[25] Batch [1380]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.102468,	
2017-06-15 20:24:27,020 Epoch[25] Batch [1390]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.102479,	
2017-06-15 20:24:35,463 Epoch[25] Batch [1400]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.102432,	
2017-06-15 20:24:43,408 Epoch[25] Batch [1410]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.102420,	
2017-06-15 20:24:51,302 Epoch[25] Batch [1420]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.102362,	
2017-06-15 20:24:59,274 Epoch[25] Batch [1430]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.102292,	
2017-06-15 20:25:06,970 Epoch[25] Batch [1440]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.102272,	
2017-06-15 20:25:15,307 Epoch[25] Batch [1450]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.102304,	
2017-06-15 20:25:23,288 Epoch[25] Batch [1460]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.102248,	
2017-06-15 20:25:31,067 Epoch[25] Batch [1470]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.102211,	
2017-06-15 20:25:39,334 Epoch[25] Batch [1480]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.102221,	
2017-06-15 20:25:43,325 Epoch[25] Train-FCNLogLoss=0.102279
2017-06-15 20:25:43,325 Epoch[25] Time cost=1120.979
2017-06-15 20:25:44,399 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0026.params"
2017-06-15 20:25:47,681 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0026.states"
2017-06-15 20:25:57,544 Epoch[26] Batch [10]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.113962,	
2017-06-15 20:26:05,804 Epoch[26] Batch [20]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.113126,	
2017-06-15 20:26:13,378 Epoch[26] Batch [30]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.112595,	
2017-06-15 20:26:21,574 Epoch[26] Batch [40]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.112146,	
2017-06-15 20:26:28,954 Epoch[26] Batch [50]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.110479,	
2017-06-15 20:26:37,027 Epoch[26] Batch [60]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.109574,	
2017-06-15 20:26:43,587 Epoch[26] Batch [70]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.108916,	
2017-06-15 20:26:51,639 Epoch[26] Batch [80]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.109000,	
2017-06-15 20:27:00,145 Epoch[26] Batch [90]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.109188,	
2017-06-15 20:27:09,279 Epoch[26] Batch [100]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.110093,	
2017-06-15 20:27:17,379 Epoch[26] Batch [110]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.109667,	
2017-06-15 20:27:25,595 Epoch[26] Batch [120]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.109035,	
2017-06-15 20:27:32,452 Epoch[26] Batch [130]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.108732,	
2017-06-15 20:27:41,181 Epoch[26] Batch [140]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.108199,	
2017-06-15 20:27:47,428 Epoch[26] Batch [150]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.107855,	
2017-06-15 20:27:54,850 Epoch[26] Batch [160]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.107035,	
2017-06-15 20:28:03,172 Epoch[26] Batch [170]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.106309,	
2017-06-15 20:28:10,580 Epoch[26] Batch [180]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.106501,	
2017-06-15 20:28:17,175 Epoch[26] Batch [190]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.106224,	
2017-06-15 20:28:24,967 Epoch[26] Batch [200]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.105766,	
2017-06-15 20:28:32,499 Epoch[26] Batch [210]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.105257,	
2017-06-15 20:28:42,024 Epoch[26] Batch [220]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.104859,	
2017-06-15 20:28:49,885 Epoch[26] Batch [230]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.105043,	
2017-06-15 20:28:59,835 Epoch[26] Batch [240]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.104999,	
2017-06-15 20:29:07,624 Epoch[26] Batch [250]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.104873,	
2017-06-15 20:29:15,914 Epoch[26] Batch [260]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.104739,	
2017-06-15 20:29:22,763 Epoch[26] Batch [270]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.104319,	
2017-06-15 20:29:29,894 Epoch[26] Batch [280]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.104567,	
2017-06-15 20:29:36,923 Epoch[26] Batch [290]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.104659,	
2017-06-15 20:29:44,774 Epoch[26] Batch [300]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.104814,	
2017-06-15 20:29:53,652 Epoch[26] Batch [310]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.104731,	
2017-06-15 20:30:01,244 Epoch[26] Batch [320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.104931,	
2017-06-15 20:30:08,977 Epoch[26] Batch [330]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.104725,	
2017-06-15 20:30:16,387 Epoch[26] Batch [340]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.104739,	
2017-06-15 20:30:23,935 Epoch[26] Batch [350]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.104758,	
2017-06-15 20:30:31,764 Epoch[26] Batch [360]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.104628,	
2017-06-15 20:30:38,591 Epoch[26] Batch [370]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.104823,	
2017-06-15 20:30:45,891 Epoch[26] Batch [380]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.105036,	
2017-06-15 20:30:52,870 Epoch[26] Batch [390]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.104945,	
2017-06-15 20:31:00,351 Epoch[26] Batch [400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.104687,	
2017-06-15 20:31:08,874 Epoch[26] Batch [410]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.104756,	
2017-06-15 20:31:16,230 Epoch[26] Batch [420]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.104747,	
2017-06-15 20:31:23,684 Epoch[26] Batch [430]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.104626,	
2017-06-15 20:31:32,737 Epoch[26] Batch [440]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.104524,	
2017-06-15 20:31:40,779 Epoch[26] Batch [450]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.104481,	
2017-06-15 20:31:47,387 Epoch[26] Batch [460]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.104127,	
2017-06-15 20:31:54,802 Epoch[26] Batch [470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.103954,	
2017-06-15 20:32:01,632 Epoch[26] Batch [480]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.103832,	
2017-06-15 20:32:09,447 Epoch[26] Batch [490]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.103663,	
2017-06-15 20:32:15,749 Epoch[26] Batch [500]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.103760,	
2017-06-15 20:32:23,401 Epoch[26] Batch [510]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.103600,	
2017-06-15 20:32:30,746 Epoch[26] Batch [520]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.103568,	
2017-06-15 20:32:37,488 Epoch[26] Batch [530]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.103534,	
2017-06-15 20:32:45,408 Epoch[26] Batch [540]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.103384,	
2017-06-15 20:32:52,782 Epoch[26] Batch [550]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.103334,	
2017-06-15 20:33:00,132 Epoch[26] Batch [560]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.103092,	
2017-06-15 20:33:07,719 Epoch[26] Batch [570]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.103025,	
2017-06-15 20:33:15,107 Epoch[26] Batch [580]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.102899,	
2017-06-15 20:33:23,372 Epoch[26] Batch [590]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.102773,	
2017-06-15 20:33:30,027 Epoch[26] Batch [600]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.102583,	
2017-06-15 20:33:37,938 Epoch[26] Batch [610]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.102636,	
2017-06-15 20:33:45,385 Epoch[26] Batch [620]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.103001,	
2017-06-15 20:33:52,273 Epoch[26] Batch [630]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.103042,	
2017-06-15 20:34:00,338 Epoch[26] Batch [640]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.103191,	
2017-06-15 20:34:07,414 Epoch[26] Batch [650]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.103133,	
2017-06-15 20:34:14,525 Epoch[26] Batch [660]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.103055,	
2017-06-15 20:34:21,680 Epoch[26] Batch [670]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.102957,	
2017-06-15 20:34:29,639 Epoch[26] Batch [680]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.102896,	
2017-06-15 20:34:36,537 Epoch[26] Batch [690]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.102779,	
2017-06-15 20:34:43,637 Epoch[26] Batch [700]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.102761,	
2017-06-15 20:34:50,821 Epoch[26] Batch [710]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.102757,	
2017-06-15 20:34:57,288 Epoch[26] Batch [720]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.102811,	
2017-06-15 20:35:04,232 Epoch[26] Batch [730]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102656,	
2017-06-15 20:35:11,728 Epoch[26] Batch [740]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.102717,	
2017-06-15 20:35:19,711 Epoch[26] Batch [750]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.102708,	
2017-06-15 20:35:27,035 Epoch[26] Batch [760]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.102717,	
2017-06-15 20:35:34,998 Epoch[26] Batch [770]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.102858,	
2017-06-15 20:35:42,758 Epoch[26] Batch [780]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.102826,	
2017-06-15 20:35:50,505 Epoch[26] Batch [790]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.102667,	
2017-06-15 20:35:58,134 Epoch[26] Batch [800]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.102587,	
2017-06-15 20:36:05,715 Epoch[26] Batch [810]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.102520,	
2017-06-15 20:36:14,369 Epoch[26] Batch [820]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.102715,	
2017-06-15 20:36:22,327 Epoch[26] Batch [830]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.102699,	
2017-06-15 20:36:28,682 Epoch[26] Batch [840]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.102662,	
2017-06-15 20:36:36,428 Epoch[26] Batch [850]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.102630,	
2017-06-15 20:36:43,046 Epoch[26] Batch [860]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.102572,	
2017-06-15 20:36:50,604 Epoch[26] Batch [870]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.102503,	
2017-06-15 20:36:59,342 Epoch[26] Batch [880]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.102447,	
2017-06-15 20:37:07,249 Epoch[26] Batch [890]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.102294,	
2017-06-15 20:37:15,008 Epoch[26] Batch [900]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.102343,	
2017-06-15 20:37:22,584 Epoch[26] Batch [910]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.102279,	
2017-06-15 20:37:29,306 Epoch[26] Batch [920]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.102295,	
2017-06-15 20:37:36,369 Epoch[26] Batch [930]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.102419,	
2017-06-15 20:37:43,999 Epoch[26] Batch [940]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.102443,	
2017-06-15 20:37:50,320 Epoch[26] Batch [950]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.102504,	
2017-06-15 20:37:57,111 Epoch[26] Batch [960]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.102610,	
2017-06-15 20:38:04,460 Epoch[26] Batch [970]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.102705,	
2017-06-15 20:38:11,770 Epoch[26] Batch [980]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.102665,	
2017-06-15 20:38:19,022 Epoch[26] Batch [990]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.102657,	
2017-06-15 20:38:25,178 Epoch[26] Batch [1000]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.102585,	
2017-06-15 20:38:32,774 Epoch[26] Batch [1010]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.102513,	
2017-06-15 20:38:40,427 Epoch[26] Batch [1020]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.102531,	
2017-06-15 20:38:47,453 Epoch[26] Batch [1030]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.102507,	
2017-06-15 20:38:53,361 Epoch[26] Batch [1040]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.102669,	
2017-06-15 20:39:00,399 Epoch[26] Batch [1050]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.102687,	
2017-06-15 20:39:07,424 Epoch[26] Batch [1060]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.102654,	
2017-06-15 20:39:13,734 Epoch[26] Batch [1070]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.102626,	
2017-06-15 20:39:20,962 Epoch[26] Batch [1080]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.102666,	
2017-06-15 20:39:29,713 Epoch[26] Batch [1090]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.102784,	
2017-06-15 20:39:36,803 Epoch[26] Batch [1100]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.102835,	
2017-06-15 20:39:44,007 Epoch[26] Batch [1110]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.102970,	
2017-06-15 20:39:52,156 Epoch[26] Batch [1120]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.103114,	
2017-06-15 20:39:59,855 Epoch[26] Batch [1130]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.103094,	
2017-06-15 20:40:06,763 Epoch[26] Batch [1140]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.103012,	
2017-06-15 20:40:14,333 Epoch[26] Batch [1150]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.103016,	
2017-06-15 20:40:20,771 Epoch[26] Batch [1160]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.102976,	
2017-06-15 20:40:27,860 Epoch[26] Batch [1170]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.102983,	
2017-06-15 20:40:34,464 Epoch[26] Batch [1180]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.103041,	
2017-06-15 20:40:41,006 Epoch[26] Batch [1190]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.102947,	
2017-06-15 20:40:48,579 Epoch[26] Batch [1200]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.102849,	
2017-06-15 20:40:55,857 Epoch[26] Batch [1210]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.102751,	
2017-06-15 20:41:03,822 Epoch[26] Batch [1220]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.102735,	
2017-06-15 20:41:11,658 Epoch[26] Batch [1230]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.102812,	
2017-06-15 20:41:19,165 Epoch[26] Batch [1240]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.102812,	
2017-06-15 20:41:26,716 Epoch[26] Batch [1250]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.102879,	
2017-06-15 20:41:34,288 Epoch[26] Batch [1260]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.102854,	
2017-06-15 20:41:40,857 Epoch[26] Batch [1270]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.102799,	
2017-06-15 20:41:48,677 Epoch[26] Batch [1280]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.102784,	
2017-06-15 20:41:56,630 Epoch[26] Batch [1290]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.102653,	
2017-06-15 20:42:03,941 Epoch[26] Batch [1300]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.102663,	
2017-06-15 20:42:10,034 Epoch[26] Batch [1310]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102641,	
2017-06-15 20:42:17,931 Epoch[26] Batch [1320]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.102619,	
2017-06-15 20:42:25,203 Epoch[26] Batch [1330]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.102567,	
2017-06-15 20:42:33,695 Epoch[26] Batch [1340]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.102598,	
2017-06-15 20:42:40,937 Epoch[26] Batch [1350]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.102676,	
2017-06-15 20:42:47,759 Epoch[26] Batch [1360]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.102637,	
2017-06-15 20:42:55,567 Epoch[26] Batch [1370]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.102650,	
2017-06-15 20:43:03,463 Epoch[26] Batch [1380]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.102735,	
2017-06-15 20:43:10,660 Epoch[26] Batch [1390]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.102786,	
2017-06-15 20:43:17,383 Epoch[26] Batch [1400]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.102773,	
2017-06-15 20:43:24,298 Epoch[26] Batch [1410]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.102819,	
2017-06-15 20:43:31,340 Epoch[26] Batch [1420]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.102785,	
2017-06-15 20:43:38,009 Epoch[26] Batch [1430]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.102785,	
2017-06-15 20:43:46,646 Epoch[26] Batch [1440]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.102736,	
2017-06-15 20:43:55,271 Epoch[26] Batch [1450]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.102722,	
2017-06-15 20:44:02,608 Epoch[26] Batch [1460]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.102689,	
2017-06-15 20:44:10,119 Epoch[26] Batch [1470]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.102688,	
2017-06-15 20:44:16,654 Epoch[26] Batch [1480]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.102664,	
2017-06-15 20:44:21,658 Epoch[26] Train-FCNLogLoss=0.102660
2017-06-15 20:44:21,658 Epoch[26] Time cost=1113.977
2017-06-15 20:44:22,581 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0027.params"
2017-06-15 20:44:25,012 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0027.states"
2017-06-15 20:44:33,109 Epoch[27] Batch [10]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.100779,	
2017-06-15 20:44:40,374 Epoch[27] Batch [20]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.099501,	
2017-06-15 20:44:47,306 Epoch[27] Batch [30]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.099892,	
2017-06-15 20:44:53,175 Epoch[27] Batch [40]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.100171,	
2017-06-15 20:45:00,674 Epoch[27] Batch [50]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.098116,	
2017-06-15 20:45:08,467 Epoch[27] Batch [60]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.100015,	
2017-06-15 20:45:16,114 Epoch[27] Batch [70]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098979,	
2017-06-15 20:45:23,882 Epoch[27] Batch [80]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.097734,	
2017-06-15 20:45:31,525 Epoch[27] Batch [90]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098736,	
2017-06-15 20:45:39,036 Epoch[27] Batch [100]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099553,	
2017-06-15 20:45:46,027 Epoch[27] Batch [110]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.098367,	
2017-06-15 20:45:53,906 Epoch[27] Batch [120]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.098616,	
2017-06-15 20:46:01,398 Epoch[27] Batch [130]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098255,	
2017-06-15 20:46:09,410 Epoch[27] Batch [140]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.098278,	
2017-06-15 20:46:17,235 Epoch[27] Batch [150]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.098566,	
2017-06-15 20:46:24,111 Epoch[27] Batch [160]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.098554,	
2017-06-15 20:46:32,202 Epoch[27] Batch [170]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.098344,	
2017-06-15 20:46:40,021 Epoch[27] Batch [180]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.098189,	
2017-06-15 20:46:48,047 Epoch[27] Batch [190]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.098305,	
2017-06-15 20:46:55,475 Epoch[27] Batch [200]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098302,	
2017-06-15 20:47:02,907 Epoch[27] Batch [210]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.098802,	
2017-06-15 20:47:10,192 Epoch[27] Batch [220]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.099288,	
2017-06-15 20:47:18,124 Epoch[27] Batch [230]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.099254,	
2017-06-15 20:47:25,279 Epoch[27] Batch [240]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.099441,	
2017-06-15 20:47:32,005 Epoch[27] Batch [250]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.099208,	
2017-06-15 20:47:39,894 Epoch[27] Batch [260]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.099071,	
2017-06-15 20:47:48,090 Epoch[27] Batch [270]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.098868,	
2017-06-15 20:47:56,332 Epoch[27] Batch [280]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.098838,	
2017-06-15 20:48:03,758 Epoch[27] Batch [290]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098560,	
2017-06-15 20:48:10,665 Epoch[27] Batch [300]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.098394,	
2017-06-15 20:48:16,168 Epoch[27] Batch [310]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.098575,	
2017-06-15 20:48:22,020 Epoch[27] Batch [320]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098498,	
2017-06-15 20:48:29,477 Epoch[27] Batch [330]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.098616,	
2017-06-15 20:48:36,780 Epoch[27] Batch [340]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.098568,	
2017-06-15 20:48:44,640 Epoch[27] Batch [350]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098651,	
2017-06-15 20:48:52,515 Epoch[27] Batch [360]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.098348,	
2017-06-15 20:48:59,736 Epoch[27] Batch [370]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.098403,	
2017-06-15 20:49:06,372 Epoch[27] Batch [380]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.098474,	
2017-06-15 20:49:13,902 Epoch[27] Batch [390]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098729,	
2017-06-15 20:49:22,073 Epoch[27] Batch [400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.098602,	
2017-06-15 20:49:29,489 Epoch[27] Batch [410]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098836,	
2017-06-15 20:49:36,923 Epoch[27] Batch [420]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.098861,	
2017-06-15 20:49:44,891 Epoch[27] Batch [430]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.098692,	
2017-06-15 20:49:51,417 Epoch[27] Batch [440]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.098465,	
2017-06-15 20:49:59,465 Epoch[27] Batch [450]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.098356,	
2017-06-15 20:50:06,289 Epoch[27] Batch [460]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.098596,	
2017-06-15 20:50:13,675 Epoch[27] Batch [470]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098703,	
2017-06-15 20:50:20,822 Epoch[27] Batch [480]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.098680,	
2017-06-15 20:50:28,400 Epoch[27] Batch [490]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098579,	
2017-06-15 20:50:36,442 Epoch[27] Batch [500]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.098458,	
2017-06-15 20:50:44,028 Epoch[27] Batch [510]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098330,	
2017-06-15 20:50:51,433 Epoch[27] Batch [520]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.098049,	
2017-06-15 20:50:58,739 Epoch[27] Batch [530]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.097961,	
2017-06-15 20:51:06,067 Epoch[27] Batch [540]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.097951,	
2017-06-15 20:51:13,943 Epoch[27] Batch [550]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.098116,	
2017-06-15 20:51:21,187 Epoch[27] Batch [560]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.097952,	
2017-06-15 20:51:28,329 Epoch[27] Batch [570]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.098053,	
2017-06-15 20:51:35,905 Epoch[27] Batch [580]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098104,	
2017-06-15 20:51:43,223 Epoch[27] Batch [590]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.098252,	
2017-06-15 20:51:51,254 Epoch[27] Batch [600]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.098251,	
2017-06-15 20:51:59,319 Epoch[27] Batch [610]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.098357,	
2017-06-15 20:52:06,783 Epoch[27] Batch [620]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.098176,	
2017-06-15 20:52:15,008 Epoch[27] Batch [630]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.098069,	
2017-06-15 20:52:22,541 Epoch[27] Batch [640]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098169,	
2017-06-15 20:52:29,682 Epoch[27] Batch [650]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.098369,	
2017-06-15 20:52:37,262 Epoch[27] Batch [660]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098512,	
2017-06-15 20:52:44,593 Epoch[27] Batch [670]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.098779,	
2017-06-15 20:52:51,734 Epoch[27] Batch [680]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.099401,	
2017-06-15 20:52:59,859 Epoch[27] Batch [690]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.099185,	
2017-06-15 20:53:07,250 Epoch[27] Batch [700]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.099261,	
2017-06-15 20:53:15,201 Epoch[27] Batch [710]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.099301,	
2017-06-15 20:53:23,706 Epoch[27] Batch [720]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.099369,	
2017-06-15 20:53:31,101 Epoch[27] Batch [730]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.099218,	
2017-06-15 20:53:38,000 Epoch[27] Batch [740]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.099171,	
2017-06-15 20:53:45,542 Epoch[27] Batch [750]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.099200,	
2017-06-15 20:53:53,443 Epoch[27] Batch [760]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.099226,	
2017-06-15 20:54:02,102 Epoch[27] Batch [770]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.099224,	
2017-06-15 20:54:10,192 Epoch[27] Batch [780]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.099119,	
2017-06-15 20:54:17,020 Epoch[27] Batch [790]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.099144,	
2017-06-15 20:54:25,245 Epoch[27] Batch [800]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.098988,	
2017-06-15 20:54:33,298 Epoch[27] Batch [810]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.099065,	
2017-06-15 20:54:40,221 Epoch[27] Batch [820]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.099144,	
2017-06-15 20:54:47,678 Epoch[27] Batch [830]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099142,	
2017-06-15 20:54:56,597 Epoch[27] Batch [840]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.099168,	
2017-06-15 20:55:03,955 Epoch[27] Batch [850]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.099172,	
2017-06-15 20:55:11,711 Epoch[27] Batch [860]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.099193,	
2017-06-15 20:55:19,253 Epoch[27] Batch [870]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.099306,	
2017-06-15 20:55:26,777 Epoch[27] Batch [880]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.099485,	
2017-06-15 20:55:35,183 Epoch[27] Batch [890]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.099980,	
2017-06-15 20:55:42,353 Epoch[27] Batch [900]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.100457,	
2017-06-15 20:55:49,942 Epoch[27] Batch [910]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.101190,	
2017-06-15 20:55:56,613 Epoch[27] Batch [920]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.101821,	
2017-06-15 20:56:03,815 Epoch[27] Batch [930]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.102127,	
2017-06-15 20:56:11,078 Epoch[27] Batch [940]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.102349,	
2017-06-15 20:56:18,365 Epoch[27] Batch [950]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.102428,	
2017-06-15 20:56:26,178 Epoch[27] Batch [960]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.102498,	
2017-06-15 20:56:34,121 Epoch[27] Batch [970]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.102510,	
2017-06-15 20:56:42,296 Epoch[27] Batch [980]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.102551,	
2017-06-15 20:56:49,261 Epoch[27] Batch [990]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.102536,	
2017-06-15 20:56:56,869 Epoch[27] Batch [1000]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.102669,	
2017-06-15 20:57:04,110 Epoch[27] Batch [1010]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.102668,	
2017-06-15 20:57:11,846 Epoch[27] Batch [1020]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.103100,	
2017-06-15 20:57:19,972 Epoch[27] Batch [1030]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.103184,	
2017-06-15 20:57:27,680 Epoch[27] Batch [1040]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.103402,	
2017-06-15 20:57:34,125 Epoch[27] Batch [1050]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.103441,	
2017-06-15 20:57:41,734 Epoch[27] Batch [1060]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.103514,	
2017-06-15 20:57:48,363 Epoch[27] Batch [1070]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.103886,	
2017-06-15 20:57:55,663 Epoch[27] Batch [1080]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.104173,	
2017-06-15 20:58:03,394 Epoch[27] Batch [1090]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.104238,	
2017-06-15 20:58:10,893 Epoch[27] Batch [1100]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.104259,	
2017-06-15 20:58:18,437 Epoch[27] Batch [1110]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.104241,	
2017-06-15 20:58:25,746 Epoch[27] Batch [1120]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.104181,	
2017-06-15 20:58:33,327 Epoch[27] Batch [1130]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.104173,	
2017-06-15 20:58:40,546 Epoch[27] Batch [1140]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.104219,	
2017-06-15 20:58:48,052 Epoch[27] Batch [1150]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.104186,	
2017-06-15 20:58:56,317 Epoch[27] Batch [1160]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.104216,	
2017-06-15 20:59:03,440 Epoch[27] Batch [1170]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.104257,	
2017-06-15 20:59:10,238 Epoch[27] Batch [1180]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.104174,	
2017-06-15 20:59:18,183 Epoch[27] Batch [1190]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.104125,	
2017-06-15 20:59:25,502 Epoch[27] Batch [1200]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.104023,	
2017-06-15 20:59:32,420 Epoch[27] Batch [1210]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.103953,	
2017-06-15 20:59:39,511 Epoch[27] Batch [1220]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.103952,	
2017-06-15 20:59:47,095 Epoch[27] Batch [1230]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.103961,	
2017-06-15 20:59:54,662 Epoch[27] Batch [1240]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.104018,	
2017-06-15 21:00:02,548 Epoch[27] Batch [1250]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.104051,	
2017-06-15 21:00:09,805 Epoch[27] Batch [1260]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.104006,	
2017-06-15 21:00:17,703 Epoch[27] Batch [1270]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.103985,	
2017-06-15 21:00:25,237 Epoch[27] Batch [1280]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.103952,	
2017-06-15 21:00:32,644 Epoch[27] Batch [1290]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.103893,	
2017-06-15 21:00:40,214 Epoch[27] Batch [1300]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.103877,	
2017-06-15 21:00:46,973 Epoch[27] Batch [1310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.103880,	
2017-06-15 21:00:54,566 Epoch[27] Batch [1320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.103888,	
2017-06-15 21:01:02,342 Epoch[27] Batch [1330]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.103884,	
2017-06-15 21:01:09,593 Epoch[27] Batch [1340]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.103921,	
2017-06-15 21:01:16,748 Epoch[27] Batch [1350]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.103864,	
2017-06-15 21:01:24,532 Epoch[27] Batch [1360]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.103875,	
2017-06-15 21:01:32,077 Epoch[27] Batch [1370]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.103838,	
2017-06-15 21:01:38,610 Epoch[27] Batch [1380]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.103818,	
2017-06-15 21:01:46,147 Epoch[27] Batch [1390]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.103888,	
2017-06-15 21:01:54,387 Epoch[27] Batch [1400]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.103916,	
2017-06-15 21:02:01,154 Epoch[27] Batch [1410]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.103826,	
2017-06-15 21:02:10,091 Epoch[27] Batch [1420]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.103789,	
2017-06-15 21:02:17,879 Epoch[27] Batch [1430]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.103753,	
2017-06-15 21:02:25,624 Epoch[27] Batch [1440]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.103802,	
2017-06-15 21:02:33,633 Epoch[27] Batch [1450]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.103848,	
2017-06-15 21:02:40,343 Epoch[27] Batch [1460]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.103893,	
2017-06-15 21:02:49,198 Epoch[27] Batch [1470]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.104056,	
2017-06-15 21:02:57,254 Epoch[27] Batch [1480]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.104110,	
2017-06-15 21:03:01,787 Epoch[27] Train-FCNLogLoss=0.104111
2017-06-15 21:03:01,787 Epoch[27] Time cost=1116.775
2017-06-15 21:03:02,502 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0028.params"
2017-06-15 21:03:04,808 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0028.states"
2017-06-15 21:03:13,278 Epoch[28] Batch [10]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.093889,	
2017-06-15 21:03:19,997 Epoch[28] Batch [20]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.096567,	
2017-06-15 21:03:27,698 Epoch[28] Batch [30]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.100700,	
2017-06-15 21:03:35,278 Epoch[28] Batch [40]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098167,	
2017-06-15 21:03:41,865 Epoch[28] Batch [50]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.095796,	
2017-06-15 21:03:47,597 Epoch[28] Batch [60]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.096055,	
2017-06-15 21:03:54,769 Epoch[28] Batch [70]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.096215,	
2017-06-15 21:04:02,205 Epoch[28] Batch [80]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095953,	
2017-06-15 21:04:09,211 Epoch[28] Batch [90]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.096548,	
2017-06-15 21:04:16,336 Epoch[28] Batch [100]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.097544,	
2017-06-15 21:04:22,854 Epoch[28] Batch [110]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.097210,	
2017-06-15 21:04:28,364 Epoch[28] Batch [120]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.096836,	
2017-06-15 21:04:34,786 Epoch[28] Batch [130]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.096936,	
2017-06-15 21:04:42,207 Epoch[28] Batch [140]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.096268,	
2017-06-15 21:04:50,240 Epoch[28] Batch [150]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.096614,	
2017-06-15 21:04:57,737 Epoch[28] Batch [160]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.096341,	
2017-06-15 21:05:04,183 Epoch[28] Batch [170]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.096731,	
2017-06-15 21:05:11,936 Epoch[28] Batch [180]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.096316,	
2017-06-15 21:05:20,195 Epoch[28] Batch [190]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.096373,	
2017-06-15 21:05:27,681 Epoch[28] Batch [200]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.095976,	
2017-06-15 21:05:33,889 Epoch[28] Batch [210]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.095502,	
2017-06-15 21:05:40,934 Epoch[28] Batch [220]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.095584,	
2017-06-15 21:05:47,840 Epoch[28] Batch [230]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.095877,	
2017-06-15 21:05:54,919 Epoch[28] Batch [240]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.096072,	
2017-06-15 21:06:02,697 Epoch[28] Batch [250]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.096136,	
2017-06-15 21:06:10,272 Epoch[28] Batch [260]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.096703,	
2017-06-15 21:06:17,837 Epoch[28] Batch [270]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096551,	
2017-06-15 21:06:26,474 Epoch[28] Batch [280]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.096729,	
2017-06-15 21:06:34,362 Epoch[28] Batch [290]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.096643,	
2017-06-15 21:06:42,119 Epoch[28] Batch [300]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.096979,	
2017-06-15 21:06:50,059 Epoch[28] Batch [310]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.096854,	
2017-06-15 21:06:57,900 Epoch[28] Batch [320]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.096867,	
2017-06-15 21:07:05,152 Epoch[28] Batch [330]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.096675,	
2017-06-15 21:07:13,020 Epoch[28] Batch [340]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096784,	
2017-06-15 21:07:21,547 Epoch[28] Batch [350]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.096618,	
2017-06-15 21:07:28,948 Epoch[28] Batch [360]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.096487,	
2017-06-15 21:07:37,305 Epoch[28] Batch [370]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.096438,	
2017-06-15 21:07:45,144 Epoch[28] Batch [380]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.096473,	
2017-06-15 21:07:51,689 Epoch[28] Batch [390]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.096730,	
2017-06-15 21:07:59,667 Epoch[28] Batch [400]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.096631,	
2017-06-15 21:08:06,997 Epoch[28] Batch [410]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.096780,	
2017-06-15 21:08:14,963 Epoch[28] Batch [420]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.097174,	
2017-06-15 21:08:23,116 Epoch[28] Batch [430]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.097337,	
2017-06-15 21:08:30,366 Epoch[28] Batch [440]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.097410,	
2017-06-15 21:08:37,464 Epoch[28] Batch [450]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.097471,	
2017-06-15 21:08:45,866 Epoch[28] Batch [460]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.097411,	
2017-06-15 21:08:53,715 Epoch[28] Batch [470]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.097537,	
2017-06-15 21:09:01,776 Epoch[28] Batch [480]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.097493,	
2017-06-15 21:09:08,995 Epoch[28] Batch [490]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.097281,	
2017-06-15 21:09:16,480 Epoch[28] Batch [500]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.097335,	
2017-06-15 21:09:23,883 Epoch[28] Batch [510]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.097621,	
2017-06-15 21:09:30,985 Epoch[28] Batch [520]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.097715,	
2017-06-15 21:09:38,706 Epoch[28] Batch [530]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.097803,	
2017-06-15 21:09:47,042 Epoch[28] Batch [540]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.097944,	
2017-06-15 21:09:53,343 Epoch[28] Batch [550]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.098202,	
2017-06-15 21:10:01,031 Epoch[28] Batch [560]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098108,	
2017-06-15 21:10:07,955 Epoch[28] Batch [570]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.098192,	
2017-06-15 21:10:14,308 Epoch[28] Batch [580]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.098076,	
2017-06-15 21:10:21,364 Epoch[28] Batch [590]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.098085,	
2017-06-15 21:10:28,160 Epoch[28] Batch [600]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.098055,	
2017-06-15 21:10:35,541 Epoch[28] Batch [610]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098012,	
2017-06-15 21:10:43,421 Epoch[28] Batch [620]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.097936,	
2017-06-15 21:10:51,008 Epoch[28] Batch [630]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.097783,	
2017-06-15 21:10:59,803 Epoch[28] Batch [640]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.097796,	
2017-06-15 21:11:06,979 Epoch[28] Batch [650]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.097906,	
2017-06-15 21:11:14,156 Epoch[28] Batch [660]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.097847,	
2017-06-15 21:11:23,071 Epoch[28] Batch [670]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.097654,	
2017-06-15 21:11:29,371 Epoch[28] Batch [680]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.097628,	
2017-06-15 21:11:37,078 Epoch[28] Batch [690]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.097593,	
2017-06-15 21:11:44,233 Epoch[28] Batch [700]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.097543,	
2017-06-15 21:11:53,243 Epoch[28] Batch [710]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.097520,	
2017-06-15 21:12:01,167 Epoch[28] Batch [720]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.097375,	
2017-06-15 21:12:10,457 Epoch[28] Batch [730]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.097486,	
2017-06-15 21:12:18,306 Epoch[28] Batch [740]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.097411,	
2017-06-15 21:12:25,804 Epoch[28] Batch [750]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.097349,	
2017-06-15 21:12:34,787 Epoch[28] Batch [760]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.097299,	
2017-06-15 21:12:42,222 Epoch[28] Batch [770]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.097342,	
2017-06-15 21:12:50,415 Epoch[28] Batch [780]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.097571,	
2017-06-15 21:12:58,020 Epoch[28] Batch [790]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.097731,	
2017-06-15 21:13:05,949 Epoch[28] Batch [800]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.097679,	
2017-06-15 21:13:14,104 Epoch[28] Batch [810]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.097746,	
2017-06-15 21:13:21,415 Epoch[28] Batch [820]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.097815,	
2017-06-15 21:13:28,821 Epoch[28] Batch [830]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.097775,	
2017-06-15 21:13:36,021 Epoch[28] Batch [840]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.097749,	
2017-06-15 21:13:42,609 Epoch[28] Batch [850]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.097810,	
2017-06-15 21:13:50,872 Epoch[28] Batch [860]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.097782,	
2017-06-15 21:13:58,520 Epoch[28] Batch [870]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.097757,	
2017-06-15 21:14:06,894 Epoch[28] Batch [880]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.097761,	
2017-06-15 21:14:13,294 Epoch[28] Batch [890]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.097878,	
2017-06-15 21:14:19,773 Epoch[28] Batch [900]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.097912,	
2017-06-15 21:14:25,305 Epoch[28] Batch [910]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098136,	
2017-06-15 21:14:32,725 Epoch[28] Batch [920]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098286,	
2017-06-15 21:14:40,023 Epoch[28] Batch [930]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.098754,	
2017-06-15 21:14:46,558 Epoch[28] Batch [940]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.098991,	
2017-06-15 21:14:54,425 Epoch[28] Batch [950]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.099082,	
2017-06-15 21:15:01,819 Epoch[28] Batch [960]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.099321,	
2017-06-15 21:15:09,053 Epoch[28] Batch [970]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.099441,	
2017-06-15 21:15:16,824 Epoch[28] Batch [980]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.099473,	
2017-06-15 21:15:24,117 Epoch[28] Batch [990]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.099482,	
2017-06-15 21:15:32,016 Epoch[28] Batch [1000]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.099530,	
2017-06-15 21:15:39,541 Epoch[28] Batch [1010]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.099507,	
2017-06-15 21:15:47,048 Epoch[28] Batch [1020]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099437,	
2017-06-15 21:15:55,382 Epoch[28] Batch [1030]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.099458,	
2017-06-15 21:16:02,889 Epoch[28] Batch [1040]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099526,	
2017-06-15 21:16:10,895 Epoch[28] Batch [1050]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.099537,	
2017-06-15 21:16:18,619 Epoch[28] Batch [1060]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.099489,	
2017-06-15 21:16:25,458 Epoch[28] Batch [1070]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.099433,	
2017-06-15 21:16:34,521 Epoch[28] Batch [1080]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.099407,	
2017-06-15 21:16:42,317 Epoch[28] Batch [1090]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.099571,	
2017-06-15 21:16:49,741 Epoch[28] Batch [1100]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.099532,	
2017-06-15 21:16:57,195 Epoch[28] Batch [1110]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.099544,	
2017-06-15 21:17:05,137 Epoch[28] Batch [1120]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.099564,	
2017-06-15 21:17:12,685 Epoch[28] Batch [1130]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.099572,	
2017-06-15 21:17:19,804 Epoch[28] Batch [1140]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099510,	
2017-06-15 21:17:27,470 Epoch[28] Batch [1150]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.099480,	
2017-06-15 21:17:34,945 Epoch[28] Batch [1160]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.099545,	
2017-06-15 21:17:42,219 Epoch[28] Batch [1170]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.099483,	
2017-06-15 21:17:49,397 Epoch[28] Batch [1180]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.099483,	
2017-06-15 21:17:57,248 Epoch[28] Batch [1190]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.099537,	
2017-06-15 21:18:05,569 Epoch[28] Batch [1200]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.099460,	
2017-06-15 21:18:13,095 Epoch[28] Batch [1210]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.099590,	
2017-06-15 21:18:22,365 Epoch[28] Batch [1220]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.099569,	
2017-06-15 21:18:30,247 Epoch[28] Batch [1230]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.099581,	
2017-06-15 21:18:38,326 Epoch[28] Batch [1240]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.099551,	
2017-06-15 21:18:45,896 Epoch[28] Batch [1250]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.099554,	
2017-06-15 21:18:53,454 Epoch[28] Batch [1260]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.099528,	
2017-06-15 21:19:00,979 Epoch[28] Batch [1270]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.099486,	
2017-06-15 21:19:08,539 Epoch[28] Batch [1280]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.099457,	
2017-06-15 21:19:15,831 Epoch[28] Batch [1290]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.099477,	
2017-06-15 21:19:23,756 Epoch[28] Batch [1300]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.099556,	
2017-06-15 21:19:31,465 Epoch[28] Batch [1310]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.099548,	
2017-06-15 21:19:38,745 Epoch[28] Batch [1320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.099535,	
2017-06-15 21:19:46,148 Epoch[28] Batch [1330]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.099674,	
2017-06-15 21:19:53,523 Epoch[28] Batch [1340]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.099707,	
2017-06-15 21:20:01,329 Epoch[28] Batch [1350]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.099836,	
2017-06-15 21:20:08,844 Epoch[28] Batch [1360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.099827,	
2017-06-15 21:20:16,952 Epoch[28] Batch [1370]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.099845,	
2017-06-15 21:20:25,699 Epoch[28] Batch [1380]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.099823,	
2017-06-15 21:20:33,781 Epoch[28] Batch [1390]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.099892,	
2017-06-15 21:20:41,338 Epoch[28] Batch [1400]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-15 21:20:49,484 Epoch[28] Batch [1410]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.099874,	
2017-06-15 21:20:56,638 Epoch[28] Batch [1420]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.099830,	
2017-06-15 21:21:04,301 Epoch[28] Batch [1430]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.099879,	
2017-06-15 21:21:12,662 Epoch[28] Batch [1440]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.099794,	
2017-06-15 21:21:19,850 Epoch[28] Batch [1450]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.099789,	
2017-06-15 21:21:27,018 Epoch[28] Batch [1460]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.099728,	
2017-06-15 21:21:34,361 Epoch[28] Batch [1470]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.099708,	
2017-06-15 21:21:41,559 Epoch[28] Batch [1480]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.099739,	
2017-06-15 21:21:46,428 Epoch[28] Train-FCNLogLoss=0.099701
2017-06-15 21:21:46,428 Epoch[28] Time cost=1121.620
2017-06-15 21:21:47,114 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0029.params"
2017-06-15 21:21:49,337 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0029.states"
2017-06-15 21:21:56,986 Epoch[29] Batch [10]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.098058,	
2017-06-15 21:22:03,372 Epoch[29] Batch [20]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.095825,	
2017-06-15 21:22:10,182 Epoch[29] Batch [30]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.097195,	
2017-06-15 21:22:17,112 Epoch[29] Batch [40]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.098002,	
2017-06-15 21:22:23,751 Epoch[29] Batch [50]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.099455,	
2017-06-15 21:22:31,274 Epoch[29] Batch [60]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.100302,	
2017-06-15 21:22:37,682 Epoch[29] Batch [70]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.100024,	
2017-06-15 21:22:45,024 Epoch[29] Batch [80]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.099695,	
2017-06-15 21:22:52,589 Epoch[29] Batch [90]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.100785,	
2017-06-15 21:22:59,606 Epoch[29] Batch [100]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.099820,	
2017-06-15 21:23:06,663 Epoch[29] Batch [110]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.100389,	
2017-06-15 21:23:13,774 Epoch[29] Batch [120]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.099688,	
2017-06-15 21:23:20,679 Epoch[29] Batch [130]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.099157,	
2017-06-15 21:23:27,542 Epoch[29] Batch [140]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.098796,	
2017-06-15 21:23:34,455 Epoch[29] Batch [150]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.097927,	
2017-06-15 21:23:41,688 Epoch[29] Batch [160]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.097354,	
2017-06-15 21:23:48,433 Epoch[29] Batch [170]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.097086,	
2017-06-15 21:23:55,876 Epoch[29] Batch [180]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.096557,	
2017-06-15 21:24:03,465 Epoch[29] Batch [190]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096338,	
2017-06-15 21:24:11,049 Epoch[29] Batch [200]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.095820,	
2017-06-15 21:24:19,737 Epoch[29] Batch [210]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.096276,	
2017-06-15 21:24:26,775 Epoch[29] Batch [220]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.096372,	
2017-06-15 21:24:34,044 Epoch[29] Batch [230]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.096511,	
2017-06-15 21:24:41,359 Epoch[29] Batch [240]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.096131,	
2017-06-15 21:24:49,343 Epoch[29] Batch [250]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.096379,	
2017-06-15 21:24:56,511 Epoch[29] Batch [260]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.096239,	
2017-06-15 21:25:03,761 Epoch[29] Batch [270]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.096491,	
2017-06-15 21:25:11,255 Epoch[29] Batch [280]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.096755,	
2017-06-15 21:25:18,727 Epoch[29] Batch [290]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096534,	
2017-06-15 21:25:26,525 Epoch[29] Batch [300]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096282,	
2017-06-15 21:25:34,327 Epoch[29] Batch [310]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096063,	
2017-06-15 21:25:42,147 Epoch[29] Batch [320]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095972,	
2017-06-15 21:25:49,946 Epoch[29] Batch [330]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095880,	
2017-06-15 21:25:57,885 Epoch[29] Batch [340]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.095984,	
2017-06-15 21:26:04,783 Epoch[29] Batch [350]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.095845,	
2017-06-15 21:26:12,632 Epoch[29] Batch [360]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.096192,	
2017-06-15 21:26:20,430 Epoch[29] Batch [370]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096273,	
2017-06-15 21:26:27,788 Epoch[29] Batch [380]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.096357,	
2017-06-15 21:26:34,844 Epoch[29] Batch [390]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.096338,	
2017-06-15 21:26:41,811 Epoch[29] Batch [400]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.096163,	
2017-06-15 21:26:48,673 Epoch[29] Batch [410]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.096092,	
2017-06-15 21:26:55,846 Epoch[29] Batch [420]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.096234,	
2017-06-15 21:27:02,963 Epoch[29] Batch [430]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.096440,	
2017-06-15 21:27:10,418 Epoch[29] Batch [440]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.096905,	
2017-06-15 21:27:17,358 Epoch[29] Batch [450]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.097040,	
2017-06-15 21:27:24,179 Epoch[29] Batch [460]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.097197,	
2017-06-15 21:27:30,535 Epoch[29] Batch [470]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.097295,	
2017-06-15 21:27:37,817 Epoch[29] Batch [480]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.097454,	
2017-06-15 21:27:44,816 Epoch[29] Batch [490]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.097474,	
2017-06-15 21:27:51,734 Epoch[29] Batch [500]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.097426,	
2017-06-15 21:27:59,345 Epoch[29] Batch [510]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.097459,	
2017-06-15 21:28:06,457 Epoch[29] Batch [520]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.097300,	
2017-06-15 21:28:13,422 Epoch[29] Batch [530]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.097658,	
2017-06-15 21:28:20,775 Epoch[29] Batch [540]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.097726,	
2017-06-15 21:28:28,634 Epoch[29] Batch [550]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.097662,	
2017-06-15 21:28:36,832 Epoch[29] Batch [560]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.097639,	
2017-06-15 21:28:44,054 Epoch[29] Batch [570]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.097608,	
2017-06-15 21:28:51,278 Epoch[29] Batch [580]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.097566,	
2017-06-15 21:28:58,329 Epoch[29] Batch [590]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.097469,	
2017-06-15 21:29:05,612 Epoch[29] Batch [600]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.097414,	
2017-06-15 21:29:12,924 Epoch[29] Batch [610]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.097214,	
2017-06-15 21:29:20,058 Epoch[29] Batch [620]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.097102,	
2017-06-15 21:29:27,732 Epoch[29] Batch [630]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.097158,	
2017-06-15 21:29:35,596 Epoch[29] Batch [640]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.097036,	
2017-06-15 21:29:43,467 Epoch[29] Batch [650]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.097172,	
2017-06-15 21:29:51,290 Epoch[29] Batch [660]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.097016,	
2017-06-15 21:29:59,199 Epoch[29] Batch [670]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.097100,	
2017-06-15 21:30:06,976 Epoch[29] Batch [680]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.097177,	
2017-06-15 21:30:14,419 Epoch[29] Batch [690]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.097177,	
2017-06-15 21:30:21,735 Epoch[29] Batch [700]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.097229,	
2017-06-15 21:30:29,140 Epoch[29] Batch [710]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.097245,	
2017-06-15 21:30:37,082 Epoch[29] Batch [720]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.097262,	
2017-06-15 21:30:44,234 Epoch[29] Batch [730]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.097418,	
2017-06-15 21:30:52,194 Epoch[29] Batch [740]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.097336,	
2017-06-15 21:30:59,235 Epoch[29] Batch [750]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.097590,	
2017-06-15 21:31:07,588 Epoch[29] Batch [760]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.097705,	
2017-06-15 21:31:15,476 Epoch[29] Batch [770]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.098099,	
2017-06-15 21:31:22,754 Epoch[29] Batch [780]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.098246,	
2017-06-15 21:31:30,012 Epoch[29] Batch [790]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.098312,	
2017-06-15 21:31:38,077 Epoch[29] Batch [800]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.098454,	
2017-06-15 21:31:45,387 Epoch[29] Batch [810]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.098556,	
2017-06-15 21:31:52,676 Epoch[29] Batch [820]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.098561,	
2017-06-15 21:32:00,417 Epoch[29] Batch [830]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098602,	
2017-06-15 21:32:07,656 Epoch[29] Batch [840]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.098647,	
2017-06-15 21:32:15,059 Epoch[29] Batch [850]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.098713,	
2017-06-15 21:32:22,741 Epoch[29] Batch [860]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.098714,	
2017-06-15 21:32:30,373 Epoch[29] Batch [870]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098668,	
2017-06-15 21:32:39,242 Epoch[29] Batch [880]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.098792,	
2017-06-15 21:32:47,005 Epoch[29] Batch [890]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.098860,	
2017-06-15 21:32:55,093 Epoch[29] Batch [900]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.098786,	
2017-06-15 21:33:02,459 Epoch[29] Batch [910]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.098728,	
2017-06-15 21:33:10,447 Epoch[29] Batch [920]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.098764,	
2017-06-15 21:33:17,748 Epoch[29] Batch [930]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.098777,	
2017-06-15 21:33:25,251 Epoch[29] Batch [940]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.098779,	
2017-06-15 21:33:33,207 Epoch[29] Batch [950]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.098824,	
2017-06-15 21:33:41,059 Epoch[29] Batch [960]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098790,	
2017-06-15 21:33:49,085 Epoch[29] Batch [970]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.098826,	
2017-06-15 21:33:56,333 Epoch[29] Batch [980]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.098829,	
2017-06-15 21:34:03,678 Epoch[29] Batch [990]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098695,	
2017-06-15 21:34:11,171 Epoch[29] Batch [1000]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098673,	
2017-06-15 21:34:19,035 Epoch[29] Batch [1010]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098697,	
2017-06-15 21:34:26,112 Epoch[29] Batch [1020]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.098595,	
2017-06-15 21:34:34,828 Epoch[29] Batch [1030]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.098602,	
2017-06-15 21:34:42,874 Epoch[29] Batch [1040]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.098570,	
2017-06-15 21:34:50,571 Epoch[29] Batch [1050]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098585,	
2017-06-15 21:34:57,139 Epoch[29] Batch [1060]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.098690,	
2017-06-15 21:35:04,484 Epoch[29] Batch [1070]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098664,	
2017-06-15 21:35:12,656 Epoch[29] Batch [1080]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.098671,	
2017-06-15 21:35:20,224 Epoch[29] Batch [1090]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098629,	
2017-06-15 21:35:28,542 Epoch[29] Batch [1100]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.098646,	
2017-06-15 21:35:35,141 Epoch[29] Batch [1110]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.098649,	
2017-06-15 21:35:42,621 Epoch[29] Batch [1120]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.098695,	
2017-06-15 21:35:50,188 Epoch[29] Batch [1130]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098733,	
2017-06-15 21:35:57,248 Epoch[29] Batch [1140]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.098899,	
2017-06-15 21:36:05,724 Epoch[29] Batch [1150]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.098882,	
2017-06-15 21:36:13,115 Epoch[29] Batch [1160]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.098903,	
2017-06-15 21:36:22,171 Epoch[29] Batch [1170]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.098884,	
2017-06-15 21:36:29,393 Epoch[29] Batch [1180]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.098900,	
2017-06-15 21:36:36,171 Epoch[29] Batch [1190]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.098920,	
2017-06-15 21:36:43,017 Epoch[29] Batch [1200]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.098844,	
2017-06-15 21:36:49,908 Epoch[29] Batch [1210]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.098870,	
2017-06-15 21:36:56,944 Epoch[29] Batch [1220]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.098908,	
2017-06-15 21:37:03,212 Epoch[29] Batch [1230]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.098874,	
2017-06-15 21:37:10,457 Epoch[29] Batch [1240]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.098991,	
2017-06-15 21:37:17,874 Epoch[29] Batch [1250]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098944,	
2017-06-15 21:37:24,619 Epoch[29] Batch [1260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.098821,	
2017-06-15 21:37:33,642 Epoch[29] Batch [1270]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.098751,	
2017-06-15 21:37:40,884 Epoch[29] Batch [1280]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.098772,	
2017-06-15 21:37:47,867 Epoch[29] Batch [1290]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.098726,	
2017-06-15 21:37:54,419 Epoch[29] Batch [1300]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.098637,	
2017-06-15 21:38:02,059 Epoch[29] Batch [1310]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098625,	
2017-06-15 21:38:10,226 Epoch[29] Batch [1320]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.098551,	
2017-06-15 21:38:18,324 Epoch[29] Batch [1330]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.098475,	
2017-06-15 21:38:25,290 Epoch[29] Batch [1340]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.098482,	
2017-06-15 21:38:32,987 Epoch[29] Batch [1350]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098534,	
2017-06-15 21:38:40,118 Epoch[29] Batch [1360]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.098526,	
2017-06-15 21:38:47,570 Epoch[29] Batch [1370]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.098679,	
2017-06-15 21:38:55,309 Epoch[29] Batch [1380]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098904,	
2017-06-15 21:39:02,739 Epoch[29] Batch [1390]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.099273,	
2017-06-15 21:39:10,933 Epoch[29] Batch [1400]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.099755,	
2017-06-15 21:39:18,817 Epoch[29] Batch [1410]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.100015,	
2017-06-15 21:39:25,851 Epoch[29] Batch [1420]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100139,	
2017-06-15 21:39:34,534 Epoch[29] Batch [1430]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.100165,	
2017-06-15 21:39:41,925 Epoch[29] Batch [1440]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.100192,	
2017-06-15 21:39:48,730 Epoch[29] Batch [1450]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.100181,	
2017-06-15 21:39:57,229 Epoch[29] Batch [1460]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.100182,	
2017-06-15 21:40:04,540 Epoch[29] Batch [1470]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.100203,	
2017-06-15 21:40:12,123 Epoch[29] Batch [1480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.100202,	
2017-06-15 21:40:16,553 Epoch[29] Train-FCNLogLoss=0.100193
2017-06-15 21:40:16,553 Epoch[29] Time cost=1107.216
2017-06-15 21:40:17,228 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0030.params"
2017-06-15 21:40:19,808 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0030.states"
2017-06-15 21:40:28,049 Epoch[30] Batch [10]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.121046,	
2017-06-15 21:40:36,779 Epoch[30] Batch [20]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.121568,	
2017-06-15 21:40:44,418 Epoch[30] Batch [30]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.124512,	
2017-06-15 21:40:53,165 Epoch[30] Batch [40]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.120931,	
2017-06-15 21:40:59,950 Epoch[30] Batch [50]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.118676,	
2017-06-15 21:41:07,048 Epoch[30] Batch [60]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.117812,	
2017-06-15 21:41:13,635 Epoch[30] Batch [70]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.114398,	
2017-06-15 21:41:21,984 Epoch[30] Batch [80]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.112517,	
2017-06-15 21:41:31,229 Epoch[30] Batch [90]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.111204,	
2017-06-15 21:41:38,981 Epoch[30] Batch [100]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.109922,	
2017-06-15 21:41:46,974 Epoch[30] Batch [110]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.109817,	
2017-06-15 21:41:54,509 Epoch[30] Batch [120]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.108882,	
2017-06-15 21:42:01,872 Epoch[30] Batch [130]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.108399,	
2017-06-15 21:42:09,907 Epoch[30] Batch [140]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.107812,	
2017-06-15 21:42:16,841 Epoch[30] Batch [150]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.107464,	
2017-06-15 21:42:24,632 Epoch[30] Batch [160]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.106752,	
2017-06-15 21:42:31,723 Epoch[30] Batch [170]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.106348,	
2017-06-15 21:42:38,578 Epoch[30] Batch [180]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.106106,	
2017-06-15 21:42:45,530 Epoch[30] Batch [190]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.105171,	
2017-06-15 21:42:52,024 Epoch[30] Batch [200]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.104886,	
2017-06-15 21:42:58,809 Epoch[30] Batch [210]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.104986,	
2017-06-15 21:43:06,104 Epoch[30] Batch [220]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.105209,	
2017-06-15 21:43:12,801 Epoch[30] Batch [230]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.105104,	
2017-06-15 21:43:19,905 Epoch[30] Batch [240]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.105144,	
2017-06-15 21:43:28,583 Epoch[30] Batch [250]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.105262,	
2017-06-15 21:43:35,645 Epoch[30] Batch [260]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.105395,	
2017-06-15 21:43:44,068 Epoch[30] Batch [270]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.105186,	
2017-06-15 21:43:50,451 Epoch[30] Batch [280]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.104694,	
2017-06-15 21:43:57,015 Epoch[30] Batch [290]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.104416,	
2017-06-15 21:44:04,426 Epoch[30] Batch [300]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.104105,	
2017-06-15 21:44:11,834 Epoch[30] Batch [310]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.103496,	
2017-06-15 21:44:18,363 Epoch[30] Batch [320]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.103329,	
2017-06-15 21:44:25,311 Epoch[30] Batch [330]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.103218,	
2017-06-15 21:44:32,039 Epoch[30] Batch [340]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.103334,	
2017-06-15 21:44:39,892 Epoch[30] Batch [350]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.103299,	
2017-06-15 21:44:46,744 Epoch[30] Batch [360]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.103130,	
2017-06-15 21:44:53,786 Epoch[30] Batch [370]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.103200,	
2017-06-15 21:45:01,498 Epoch[30] Batch [380]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.102950,	
2017-06-15 21:45:09,844 Epoch[30] Batch [390]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.102946,	
2017-06-15 21:45:17,458 Epoch[30] Batch [400]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.102861,	
2017-06-15 21:45:25,167 Epoch[30] Batch [410]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.102993,	
2017-06-15 21:45:32,779 Epoch[30] Batch [420]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.102587,	
2017-06-15 21:45:40,121 Epoch[30] Batch [430]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.102288,	
2017-06-15 21:45:47,492 Epoch[30] Batch [440]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.102399,	
2017-06-15 21:45:55,649 Epoch[30] Batch [450]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.102362,	
2017-06-15 21:46:02,940 Epoch[30] Batch [460]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.102369,	
2017-06-15 21:46:11,018 Epoch[30] Batch [470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.102356,	
2017-06-15 21:46:18,347 Epoch[30] Batch [480]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.102251,	
2017-06-15 21:46:25,443 Epoch[30] Batch [490]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.102309,	
2017-06-15 21:46:32,983 Epoch[30] Batch [500]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.102113,	
2017-06-15 21:46:40,429 Epoch[30] Batch [510]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.102104,	
2017-06-15 21:46:47,512 Epoch[30] Batch [520]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.101920,	
2017-06-15 21:46:54,912 Epoch[30] Batch [530]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.101710,	
2017-06-15 21:47:03,131 Epoch[30] Batch [540]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.101689,	
2017-06-15 21:47:10,611 Epoch[30] Batch [550]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.101589,	
2017-06-15 21:47:18,586 Epoch[30] Batch [560]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.101846,	
2017-06-15 21:47:25,096 Epoch[30] Batch [570]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.101698,	
2017-06-15 21:47:32,232 Epoch[30] Batch [580]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.101601,	
2017-06-15 21:47:39,051 Epoch[30] Batch [590]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.101511,	
2017-06-15 21:47:45,960 Epoch[30] Batch [600]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.101509,	
2017-06-15 21:47:52,794 Epoch[30] Batch [610]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.101354,	
2017-06-15 21:48:01,283 Epoch[30] Batch [620]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.101270,	
2017-06-15 21:48:08,546 Epoch[30] Batch [630]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.101365,	
2017-06-15 21:48:16,256 Epoch[30] Batch [640]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-15 21:48:24,503 Epoch[30] Batch [650]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.101414,	
2017-06-15 21:48:32,283 Epoch[30] Batch [660]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.101463,	
2017-06-15 21:48:38,718 Epoch[30] Batch [670]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.101578,	
2017-06-15 21:48:46,679 Epoch[30] Batch [680]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.101438,	
2017-06-15 21:48:54,689 Epoch[30] Batch [690]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.101413,	
2017-06-15 21:49:01,802 Epoch[30] Batch [700]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.101242,	
2017-06-15 21:49:09,746 Epoch[30] Batch [710]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.101218,	
2017-06-15 21:49:17,642 Epoch[30] Batch [720]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.101088,	
2017-06-15 21:49:25,230 Epoch[30] Batch [730]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.101276,	
2017-06-15 21:49:33,613 Epoch[30] Batch [740]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.101233,	
2017-06-15 21:49:40,897 Epoch[30] Batch [750]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.101115,	
2017-06-15 21:49:48,543 Epoch[30] Batch [760]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.100997,	
2017-06-15 21:49:56,655 Epoch[30] Batch [770]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.100921,	
2017-06-15 21:50:03,618 Epoch[30] Batch [780]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.100870,	
2017-06-15 21:50:11,115 Epoch[30] Batch [790]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.100646,	
2017-06-15 21:50:19,033 Epoch[30] Batch [800]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.100679,	
2017-06-15 21:50:27,073 Epoch[30] Batch [810]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.100497,	
2017-06-15 21:50:35,515 Epoch[30] Batch [820]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.100421,	
2017-06-15 21:50:43,344 Epoch[30] Batch [830]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.100430,	
2017-06-15 21:50:50,121 Epoch[30] Batch [840]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.100314,	
2017-06-15 21:50:57,148 Epoch[30] Batch [850]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100192,	
2017-06-15 21:51:04,448 Epoch[30] Batch [860]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.100164,	
2017-06-15 21:51:11,944 Epoch[30] Batch [870]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.100144,	
2017-06-15 21:51:19,335 Epoch[30] Batch [880]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.100052,	
2017-06-15 21:51:26,714 Epoch[30] Batch [890]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.100197,	
2017-06-15 21:51:34,026 Epoch[30] Batch [900]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.100267,	
2017-06-15 21:51:41,727 Epoch[30] Batch [910]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.100252,	
2017-06-15 21:51:50,019 Epoch[30] Batch [920]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.100175,	
2017-06-15 21:51:57,030 Epoch[30] Batch [930]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.100150,	
2017-06-15 21:52:05,213 Epoch[30] Batch [940]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.100060,	
2017-06-15 21:52:12,903 Epoch[30] Batch [950]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.100167,	
2017-06-15 21:52:20,468 Epoch[30] Batch [960]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.100048,	
2017-06-15 21:52:27,808 Epoch[30] Batch [970]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.099951,	
2017-06-15 21:52:35,372 Epoch[30] Batch [980]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.099826,	
2017-06-15 21:52:42,127 Epoch[30] Batch [990]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.099798,	
2017-06-15 21:52:49,846 Epoch[30] Batch [1000]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.099787,	
2017-06-15 21:52:57,015 Epoch[30] Batch [1010]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.099785,	
2017-06-15 21:53:04,129 Epoch[30] Batch [1020]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099796,	
2017-06-15 21:53:11,820 Epoch[30] Batch [1030]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.099773,	
2017-06-15 21:53:19,648 Epoch[30] Batch [1040]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.099626,	
2017-06-15 21:53:28,008 Epoch[30] Batch [1050]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.099546,	
2017-06-15 21:53:35,312 Epoch[30] Batch [1060]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.099524,	
2017-06-15 21:53:43,532 Epoch[30] Batch [1070]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.099579,	
2017-06-15 21:53:51,033 Epoch[30] Batch [1080]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099614,	
2017-06-15 21:53:58,432 Epoch[30] Batch [1090]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.099587,	
2017-06-15 21:54:06,915 Epoch[30] Batch [1100]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.099610,	
2017-06-15 21:54:14,840 Epoch[30] Batch [1110]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.099512,	
2017-06-15 21:54:22,397 Epoch[30] Batch [1120]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.099560,	
2017-06-15 21:54:30,051 Epoch[30] Batch [1130]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.099584,	
2017-06-15 21:54:39,004 Epoch[30] Batch [1140]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.099593,	
2017-06-15 21:54:47,605 Epoch[30] Batch [1150]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.099483,	
2017-06-15 21:54:54,658 Epoch[30] Batch [1160]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.099559,	
2017-06-15 21:55:02,029 Epoch[30] Batch [1170]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.099553,	
2017-06-15 21:55:10,223 Epoch[30] Batch [1180]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.099556,	
2017-06-15 21:55:16,923 Epoch[30] Batch [1190]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.099513,	
2017-06-15 21:55:23,838 Epoch[30] Batch [1200]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.099512,	
2017-06-15 21:55:31,869 Epoch[30] Batch [1210]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.099480,	
2017-06-15 21:55:39,663 Epoch[30] Batch [1220]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.099442,	
2017-06-15 21:55:47,560 Epoch[30] Batch [1230]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.099445,	
2017-06-15 21:55:54,630 Epoch[30] Batch [1240]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.099444,	
2017-06-15 21:56:01,718 Epoch[30] Batch [1250]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.099457,	
2017-06-15 21:56:10,090 Epoch[30] Batch [1260]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.099400,	
2017-06-15 21:56:17,529 Epoch[30] Batch [1270]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.099375,	
2017-06-15 21:56:25,470 Epoch[30] Batch [1280]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.099371,	
2017-06-15 21:56:32,854 Epoch[30] Batch [1290]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.099303,	
2017-06-15 21:56:39,943 Epoch[30] Batch [1300]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.099179,	
2017-06-15 21:56:47,408 Epoch[30] Batch [1310]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099167,	
2017-06-15 21:56:54,548 Epoch[30] Batch [1320]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-15 21:57:01,458 Epoch[30] Batch [1330]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.099264,	
2017-06-15 21:57:09,013 Epoch[30] Batch [1340]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.099175,	
2017-06-15 21:57:16,444 Epoch[30] Batch [1350]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.099164,	
2017-06-15 21:57:24,414 Epoch[30] Batch [1360]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.099163,	
2017-06-15 21:57:32,438 Epoch[30] Batch [1370]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.099145,	
2017-06-15 21:57:40,419 Epoch[30] Batch [1380]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.099173,	
2017-06-15 21:57:46,830 Epoch[30] Batch [1390]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.099163,	
2017-06-15 21:57:55,036 Epoch[30] Batch [1400]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.099210,	
2017-06-15 21:58:02,321 Epoch[30] Batch [1410]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.099237,	
2017-06-15 21:58:10,065 Epoch[30] Batch [1420]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.099162,	
2017-06-15 21:58:18,137 Epoch[30] Batch [1430]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.099204,	
2017-06-15 21:58:26,414 Epoch[30] Batch [1440]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.099155,	
2017-06-15 21:58:33,538 Epoch[30] Batch [1450]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099189,	
2017-06-15 21:58:40,984 Epoch[30] Batch [1460]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.099148,	
2017-06-15 21:58:47,870 Epoch[30] Batch [1470]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.099084,	
2017-06-15 21:58:55,556 Epoch[30] Batch [1480]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.099109,	
2017-06-15 21:59:00,037 Epoch[30] Train-FCNLogLoss=0.099132
2017-06-15 21:59:00,037 Epoch[30] Time cost=1120.229
2017-06-15 21:59:01,180 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0031.params"
2017-06-15 21:59:03,223 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0031.states"
2017-06-15 21:59:11,907 Epoch[31] Batch [10]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.107776,	
2017-06-15 21:59:19,004 Epoch[31] Batch [20]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.102960,	
2017-06-15 21:59:26,890 Epoch[31] Batch [30]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.103444,	
2017-06-15 21:59:33,846 Epoch[31] Batch [40]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.101432,	
2017-06-15 21:59:42,470 Epoch[31] Batch [50]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.099730,	
2017-06-15 21:59:48,918 Epoch[31] Batch [60]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.098503,	
2017-06-15 21:59:55,487 Epoch[31] Batch [70]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.096981,	
2017-06-15 22:00:02,885 Epoch[31] Batch [80]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.098692,	
2017-06-15 22:00:10,687 Epoch[31] Batch [90]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.098240,	
2017-06-15 22:00:17,267 Epoch[31] Batch [100]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.098220,	
2017-06-15 22:00:24,277 Epoch[31] Batch [110]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.096991,	
2017-06-15 22:00:31,236 Epoch[31] Batch [120]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.097170,	
2017-06-15 22:00:38,336 Epoch[31] Batch [130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.097569,	
2017-06-15 22:00:45,528 Epoch[31] Batch [140]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.098065,	
2017-06-15 22:00:52,895 Epoch[31] Batch [150]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.098056,	
2017-06-15 22:01:00,388 Epoch[31] Batch [160]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.097880,	
2017-06-15 22:01:07,459 Epoch[31] Batch [170]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.097701,	
2017-06-15 22:01:14,933 Epoch[31] Batch [180]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.097455,	
2017-06-15 22:01:22,596 Epoch[31] Batch [190]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.097046,	
2017-06-15 22:01:29,870 Epoch[31] Batch [200]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.096973,	
2017-06-15 22:01:37,184 Epoch[31] Batch [210]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.096735,	
2017-06-15 22:01:43,742 Epoch[31] Batch [220]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.096662,	
2017-06-15 22:01:50,811 Epoch[31] Batch [230]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.096835,	
2017-06-15 22:01:57,766 Epoch[31] Batch [240]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.096137,	
2017-06-15 22:02:04,655 Epoch[31] Batch [250]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.096136,	
2017-06-15 22:02:11,031 Epoch[31] Batch [260]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.095940,	
2017-06-15 22:02:17,400 Epoch[31] Batch [270]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.096005,	
2017-06-15 22:02:23,825 Epoch[31] Batch [280]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.096026,	
2017-06-15 22:02:31,666 Epoch[31] Batch [290]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.095642,	
2017-06-15 22:02:39,377 Epoch[31] Batch [300]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.095411,	
2017-06-15 22:02:46,472 Epoch[31] Batch [310]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.095242,	
2017-06-15 22:02:52,882 Epoch[31] Batch [320]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.095196,	
2017-06-15 22:02:58,850 Epoch[31] Batch [330]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.094996,	
2017-06-15 22:03:04,522 Epoch[31] Batch [340]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.094988,	
2017-06-15 22:03:11,441 Epoch[31] Batch [350]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.095352,	
2017-06-15 22:03:19,324 Epoch[31] Batch [360]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.095586,	
2017-06-15 22:03:26,496 Epoch[31] Batch [370]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.095880,	
2017-06-15 22:03:34,278 Epoch[31] Batch [380]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.095636,	
2017-06-15 22:03:41,293 Epoch[31] Batch [390]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.095861,	
2017-06-15 22:03:48,742 Epoch[31] Batch [400]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.096098,	
2017-06-15 22:03:55,717 Epoch[31] Batch [410]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.096239,	
2017-06-15 22:04:02,507 Epoch[31] Batch [420]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.096071,	
2017-06-15 22:04:09,037 Epoch[31] Batch [430]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.096235,	
2017-06-15 22:04:16,063 Epoch[31] Batch [440]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.096451,	
2017-06-15 22:04:23,482 Epoch[31] Batch [450]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.096376,	
2017-06-15 22:04:31,249 Epoch[31] Batch [460]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.096401,	
2017-06-15 22:04:38,196 Epoch[31] Batch [470]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.096430,	
2017-06-15 22:04:45,062 Epoch[31] Batch [480]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.096245,	
2017-06-15 22:04:51,737 Epoch[31] Batch [490]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096290,	
2017-06-15 22:04:59,488 Epoch[31] Batch [500]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.096336,	
2017-06-15 22:05:07,094 Epoch[31] Batch [510]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.096198,	
2017-06-15 22:05:14,104 Epoch[31] Batch [520]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.096209,	
2017-06-15 22:05:21,307 Epoch[31] Batch [530]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.096295,	
2017-06-15 22:05:29,369 Epoch[31] Batch [540]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.096292,	
2017-06-15 22:05:37,814 Epoch[31] Batch [550]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.096212,	
2017-06-15 22:05:45,148 Epoch[31] Batch [560]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.096244,	
2017-06-15 22:05:51,407 Epoch[31] Batch [570]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.096426,	
2017-06-15 22:05:59,352 Epoch[31] Batch [580]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.096653,	
2017-06-15 22:06:06,778 Epoch[31] Batch [590]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.096823,	
2017-06-15 22:06:13,398 Epoch[31] Batch [600]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.096832,	
2017-06-15 22:06:21,319 Epoch[31] Batch [610]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.096809,	
2017-06-15 22:06:28,264 Epoch[31] Batch [620]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.096847,	
2017-06-15 22:06:35,214 Epoch[31] Batch [630]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.096723,	
2017-06-15 22:06:42,137 Epoch[31] Batch [640]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.096586,	
2017-06-15 22:06:50,180 Epoch[31] Batch [650]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.096580,	
2017-06-15 22:06:57,400 Epoch[31] Batch [660]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.096591,	
2017-06-15 22:07:04,962 Epoch[31] Batch [670]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096329,	
2017-06-15 22:07:11,759 Epoch[31] Batch [680]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.096459,	
2017-06-15 22:07:17,790 Epoch[31] Batch [690]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.096446,	
2017-06-15 22:07:24,259 Epoch[31] Batch [700]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.096530,	
2017-06-15 22:07:30,405 Epoch[31] Batch [710]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.096373,	
2017-06-15 22:07:35,857 Epoch[31] Batch [720]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.096449,	
2017-06-15 22:07:44,343 Epoch[31] Batch [730]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.096473,	
2017-06-15 22:07:52,538 Epoch[31] Batch [740]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.096481,	
2017-06-15 22:07:59,439 Epoch[31] Batch [750]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.096453,	
2017-06-15 22:08:07,816 Epoch[31] Batch [760]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.096363,	
2017-06-15 22:08:15,802 Epoch[31] Batch [770]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.096369,	
2017-06-15 22:08:22,752 Epoch[31] Batch [780]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.096396,	
2017-06-15 22:08:32,707 Epoch[31] Batch [790]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.096258,	
2017-06-15 22:08:39,798 Epoch[31] Batch [800]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.096220,	
2017-06-15 22:08:47,672 Epoch[31] Batch [810]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096266,	
2017-06-15 22:08:54,786 Epoch[31] Batch [820]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.096362,	
2017-06-15 22:09:02,480 Epoch[31] Batch [830]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.096491,	
2017-06-15 22:09:09,154 Epoch[31] Batch [840]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096576,	
2017-06-15 22:09:16,590 Epoch[31] Batch [850]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.096607,	
2017-06-15 22:09:23,893 Epoch[31] Batch [860]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.096587,	
2017-06-15 22:09:31,724 Epoch[31] Batch [870]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.096466,	
2017-06-15 22:09:37,943 Epoch[31] Batch [880]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.096725,	
2017-06-15 22:09:44,824 Epoch[31] Batch [890]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.096689,	
2017-06-15 22:09:51,965 Epoch[31] Batch [900]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.096745,	
2017-06-15 22:10:00,373 Epoch[31] Batch [910]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.096800,	
2017-06-15 22:10:07,810 Epoch[31] Batch [920]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.096788,	
2017-06-15 22:10:16,013 Epoch[31] Batch [930]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.096705,	
2017-06-15 22:10:24,515 Epoch[31] Batch [940]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.096683,	
2017-06-15 22:10:32,188 Epoch[31] Batch [950]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.096610,	
2017-06-15 22:10:40,255 Epoch[31] Batch [960]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.096564,	
2017-06-15 22:10:48,788 Epoch[31] Batch [970]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.096538,	
2017-06-15 22:10:56,008 Epoch[31] Batch [980]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.096475,	
2017-06-15 22:11:03,965 Epoch[31] Batch [990]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.096569,	
2017-06-15 22:11:11,682 Epoch[31] Batch [1000]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.096480,	
2017-06-15 22:11:19,284 Epoch[31] Batch [1010]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.096417,	
2017-06-15 22:11:26,938 Epoch[31] Batch [1020]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.096351,	
2017-06-15 22:11:34,755 Epoch[31] Batch [1030]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.096294,	
2017-06-15 22:11:42,423 Epoch[31] Batch [1040]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.096302,	
2017-06-15 22:11:50,304 Epoch[31] Batch [1050]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096270,	
2017-06-15 22:11:57,208 Epoch[31] Batch [1060]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.096120,	
2017-06-15 22:12:04,578 Epoch[31] Batch [1070]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.096131,	
2017-06-15 22:12:13,734 Epoch[31] Batch [1080]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.096167,	
2017-06-15 22:12:21,820 Epoch[31] Batch [1090]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.096182,	
2017-06-15 22:12:29,405 Epoch[31] Batch [1100]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096248,	
2017-06-15 22:12:37,455 Epoch[31] Batch [1110]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.096156,	
2017-06-15 22:12:44,596 Epoch[31] Batch [1120]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.096153,	
2017-06-15 22:12:51,784 Epoch[31] Batch [1130]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.096095,	
2017-06-15 22:12:58,952 Epoch[31] Batch [1140]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.096003,	
2017-06-15 22:13:04,958 Epoch[31] Batch [1150]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.095999,	
2017-06-15 22:13:12,308 Epoch[31] Batch [1160]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.096071,	
2017-06-15 22:13:18,394 Epoch[31] Batch [1170]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.096097,	
2017-06-15 22:13:25,907 Epoch[31] Batch [1180]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.096083,	
2017-06-15 22:13:34,057 Epoch[31] Batch [1190]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.096059,	
2017-06-15 22:13:41,152 Epoch[31] Batch [1200]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.096024,	
2017-06-15 22:13:47,861 Epoch[31] Batch [1210]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.096051,	
2017-06-15 22:13:55,094 Epoch[31] Batch [1220]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.096188,	
2017-06-15 22:14:01,594 Epoch[31] Batch [1230]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.096182,	
2017-06-15 22:14:09,183 Epoch[31] Batch [1240]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096079,	
2017-06-15 22:14:17,244 Epoch[31] Batch [1250]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.096058,	
2017-06-15 22:14:24,540 Epoch[31] Batch [1260]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.096063,	
2017-06-15 22:14:33,119 Epoch[31] Batch [1270]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.096002,	
2017-06-15 22:14:40,881 Epoch[31] Batch [1280]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.095982,	
2017-06-15 22:14:50,149 Epoch[31] Batch [1290]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.096040,	
2017-06-15 22:14:57,628 Epoch[31] Batch [1300]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096070,	
2017-06-15 22:15:05,289 Epoch[31] Batch [1310]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.096108,	
2017-06-15 22:15:13,090 Epoch[31] Batch [1320]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096117,	
2017-06-15 22:15:22,737 Epoch[31] Batch [1330]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.096045,	
2017-06-15 22:15:30,328 Epoch[31] Batch [1340]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096024,	
2017-06-15 22:15:38,854 Epoch[31] Batch [1350]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.096015,	
2017-06-15 22:15:48,077 Epoch[31] Batch [1360]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.096010,	
2017-06-15 22:15:55,971 Epoch[31] Batch [1370]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.096115,	
2017-06-15 22:16:04,093 Epoch[31] Batch [1380]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.096285,	
2017-06-15 22:16:12,609 Epoch[31] Batch [1390]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.096366,	
2017-06-15 22:16:20,246 Epoch[31] Batch [1400]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.096366,	
2017-06-15 22:16:27,084 Epoch[31] Batch [1410]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.096398,	
2017-06-15 22:16:34,871 Epoch[31] Batch [1420]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.096433,	
2017-06-15 22:16:42,526 Epoch[31] Batch [1430]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.096441,	
2017-06-15 22:16:49,373 Epoch[31] Batch [1440]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.096396,	
2017-06-15 22:16:57,009 Epoch[31] Batch [1450]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.096424,	
2017-06-15 22:17:05,396 Epoch[31] Batch [1460]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.096403,	
2017-06-15 22:17:13,331 Epoch[31] Batch [1470]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.096446,	
2017-06-15 22:17:19,893 Epoch[31] Batch [1480]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.096399,	
2017-06-15 22:17:24,512 Epoch[31] Train-FCNLogLoss=0.096387
2017-06-15 22:17:24,512 Epoch[31] Time cost=1101.289
2017-06-15 22:17:25,241 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0032.params"
2017-06-15 22:17:27,164 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0032.states"
2017-06-15 22:17:35,396 Epoch[32] Batch [10]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.099498,	
2017-06-15 22:17:41,127 Epoch[32] Batch [20]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.104343,	
2017-06-15 22:17:46,964 Epoch[32] Batch [30]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101489,	
2017-06-15 22:17:55,225 Epoch[32] Batch [40]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.100532,	
2017-06-15 22:18:02,265 Epoch[32] Batch [50]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.096660,	
2017-06-15 22:18:08,273 Epoch[32] Batch [60]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.096658,	
2017-06-15 22:18:15,297 Epoch[32] Batch [70]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.097262,	
2017-06-15 22:18:22,920 Epoch[32] Batch [80]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.098893,	
2017-06-15 22:18:30,097 Epoch[32] Batch [90]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.099708,	
2017-06-15 22:18:36,435 Epoch[32] Batch [100]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.100698,	
2017-06-15 22:18:42,126 Epoch[32] Batch [110]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.100798,	
2017-06-15 22:18:49,312 Epoch[32] Batch [120]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.100310,	
2017-06-15 22:18:57,315 Epoch[32] Batch [130]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.100501,	
2017-06-15 22:19:04,127 Epoch[32] Batch [140]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.099787,	
2017-06-15 22:19:11,551 Epoch[32] Batch [150]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.100015,	
2017-06-15 22:19:17,858 Epoch[32] Batch [160]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.099598,	
2017-06-15 22:19:25,449 Epoch[32] Batch [170]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.099265,	
2017-06-15 22:19:33,099 Epoch[32] Batch [180]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.099447,	
2017-06-15 22:19:41,501 Epoch[32] Batch [190]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.099054,	
2017-06-15 22:19:48,705 Epoch[32] Batch [200]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.099298,	
2017-06-15 22:19:57,946 Epoch[32] Batch [210]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.099013,	
2017-06-15 22:20:05,015 Epoch[32] Batch [220]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.099387,	
2017-06-15 22:20:12,572 Epoch[32] Batch [230]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.099201,	
2017-06-15 22:20:19,716 Epoch[32] Batch [240]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.098926,	
2017-06-15 22:20:26,726 Epoch[32] Batch [250]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.098969,	
2017-06-15 22:20:33,626 Epoch[32] Batch [260]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.098521,	
2017-06-15 22:20:40,510 Epoch[32] Batch [270]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098312,	
2017-06-15 22:20:48,086 Epoch[32] Batch [280]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098204,	
2017-06-15 22:20:56,498 Epoch[32] Batch [290]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.098093,	
2017-06-15 22:21:03,426 Epoch[32] Batch [300]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.098051,	
2017-06-15 22:21:10,283 Epoch[32] Batch [310]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.098033,	
2017-06-15 22:21:17,461 Epoch[32] Batch [320]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.098185,	
2017-06-15 22:21:24,618 Epoch[32] Batch [330]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098110,	
2017-06-15 22:21:32,074 Epoch[32] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.098182,	
2017-06-15 22:21:38,959 Epoch[32] Batch [350]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098084,	
2017-06-15 22:21:46,504 Epoch[32] Batch [360]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.098134,	
2017-06-15 22:21:53,507 Epoch[32] Batch [370]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.097876,	
2017-06-15 22:22:01,460 Epoch[32] Batch [380]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.097869,	
2017-06-15 22:22:07,263 Epoch[32] Batch [390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097819,	
2017-06-15 22:22:14,876 Epoch[32] Batch [400]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.097772,	
2017-06-15 22:22:22,167 Epoch[32] Batch [410]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.097976,	
2017-06-15 22:22:29,226 Epoch[32] Batch [420]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.097985,	
2017-06-15 22:22:36,607 Epoch[32] Batch [430]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.097768,	
2017-06-15 22:22:44,163 Epoch[32] Batch [440]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.097865,	
2017-06-15 22:22:50,128 Epoch[32] Batch [450]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.097866,	
2017-06-15 22:22:57,870 Epoch[32] Batch [460]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098014,	
2017-06-15 22:23:04,027 Epoch[32] Batch [470]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.097830,	
2017-06-15 22:23:11,786 Epoch[32] Batch [480]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.097624,	
2017-06-15 22:23:19,615 Epoch[32] Batch [490]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.097640,	
2017-06-15 22:23:28,073 Epoch[32] Batch [500]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.097645,	
2017-06-15 22:23:36,588 Epoch[32] Batch [510]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.097704,	
2017-06-15 22:23:44,284 Epoch[32] Batch [520]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.097658,	
2017-06-15 22:23:51,582 Epoch[32] Batch [530]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097535,	
2017-06-15 22:23:59,412 Epoch[32] Batch [540]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.097567,	
2017-06-15 22:24:08,321 Epoch[32] Batch [550]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.097583,	
2017-06-15 22:24:18,224 Epoch[32] Batch [560]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.097727,	
2017-06-15 22:24:26,227 Epoch[32] Batch [570]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.097710,	
2017-06-15 22:24:34,159 Epoch[32] Batch [580]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.097634,	
2017-06-15 22:24:42,437 Epoch[32] Batch [590]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.097454,	
2017-06-15 22:24:50,059 Epoch[32] Batch [600]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.097425,	
2017-06-15 22:24:56,308 Epoch[32] Batch [610]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.097442,	
2017-06-15 22:25:01,920 Epoch[32] Batch [620]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.097454,	
2017-06-15 22:25:07,262 Epoch[32] Batch [630]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097211,	
2017-06-15 22:25:12,492 Epoch[32] Batch [640]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097252,	
2017-06-15 22:25:17,862 Epoch[32] Batch [650]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097267,	
2017-06-15 22:25:23,724 Epoch[32] Batch [660]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.097156,	
2017-06-15 22:25:29,319 Epoch[32] Batch [670]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.097180,	
2017-06-15 22:25:35,981 Epoch[32] Batch [680]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.097216,	
2017-06-15 22:25:41,221 Epoch[32] Batch [690]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097155,	
2017-06-15 22:25:47,750 Epoch[32] Batch [700]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.097030,	
2017-06-15 22:25:52,982 Epoch[32] Batch [710]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097041,	
2017-06-15 22:25:58,228 Epoch[32] Batch [720]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096951,	
2017-06-15 22:26:03,601 Epoch[32] Batch [730]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096885,	
2017-06-15 22:26:09,328 Epoch[32] Batch [740]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.096906,	
2017-06-15 22:26:15,257 Epoch[32] Batch [750]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.097026,	
2017-06-15 22:26:20,703 Epoch[32] Batch [760]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.097036,	
2017-06-15 22:26:26,138 Epoch[32] Batch [770]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.097018,	
2017-06-15 22:26:31,600 Epoch[32] Batch [780]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.096977,	
2017-06-15 22:26:36,979 Epoch[32] Batch [790]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096991,	
2017-06-15 22:26:42,757 Epoch[32] Batch [800]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097108,	
2017-06-15 22:26:48,312 Epoch[32] Batch [810]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097378,	
2017-06-15 22:26:54,129 Epoch[32] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097565,	
2017-06-15 22:26:59,762 Epoch[32] Batch [830]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.097846,	
2017-06-15 22:27:05,451 Epoch[32] Batch [840]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.098022,	
2017-06-15 22:27:10,628 Epoch[32] Batch [850]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.097999,	
2017-06-15 22:27:16,178 Epoch[32] Batch [860]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.098028,	
2017-06-15 22:27:21,358 Epoch[32] Batch [870]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098029,	
2017-06-15 22:27:26,600 Epoch[32] Batch [880]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097981,	
2017-06-15 22:27:32,112 Epoch[32] Batch [890]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.098009,	
2017-06-15 22:27:37,559 Epoch[32] Batch [900]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098113,	
2017-06-15 22:27:44,155 Epoch[32] Batch [910]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.098044,	
2017-06-15 22:27:49,603 Epoch[32] Batch [920]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098035,	
2017-06-15 22:27:54,723 Epoch[32] Batch [930]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.098106,	
2017-06-15 22:27:59,861 Epoch[32] Batch [940]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.098103,	
2017-06-15 22:28:05,607 Epoch[32] Batch [950]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098241,	
2017-06-15 22:28:10,968 Epoch[32] Batch [960]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098303,	
2017-06-15 22:28:16,181 Epoch[32] Batch [970]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.098179,	
2017-06-15 22:28:21,611 Epoch[32] Batch [980]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098205,	
2017-06-15 22:28:27,223 Epoch[32] Batch [990]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098131,	
2017-06-15 22:28:32,824 Epoch[32] Batch [1000]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098082,	
2017-06-15 22:28:38,471 Epoch[32] Batch [1010]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.097949,	
2017-06-15 22:28:44,322 Epoch[32] Batch [1020]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.097925,	
2017-06-15 22:28:49,621 Epoch[32] Batch [1030]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097850,	
2017-06-15 22:28:55,666 Epoch[32] Batch [1040]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097838,	
2017-06-15 22:29:00,920 Epoch[32] Batch [1050]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097827,	
2017-06-15 22:29:07,546 Epoch[32] Batch [1060]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.097802,	
2017-06-15 22:29:15,004 Epoch[32] Batch [1070]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.097720,	
2017-06-15 22:29:20,778 Epoch[32] Batch [1080]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097691,	
2017-06-15 22:29:28,102 Epoch[32] Batch [1090]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.097664,	
2017-06-15 22:29:35,035 Epoch[32] Batch [1100]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.097697,	
2017-06-15 22:29:41,704 Epoch[32] Batch [1110]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.097726,	
2017-06-15 22:29:48,300 Epoch[32] Batch [1120]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.097722,	
2017-06-15 22:29:54,195 Epoch[32] Batch [1130]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.097689,	
2017-06-15 22:30:00,311 Epoch[32] Batch [1140]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.097639,	
2017-06-15 22:30:05,786 Epoch[32] Batch [1150]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.097572,	
2017-06-15 22:30:12,412 Epoch[32] Batch [1160]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.097567,	
2017-06-15 22:30:18,856 Epoch[32] Batch [1170]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.097625,	
2017-06-15 22:30:24,096 Epoch[32] Batch [1180]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097603,	
2017-06-15 22:30:30,460 Epoch[32] Batch [1190]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.097591,	
2017-06-15 22:30:36,020 Epoch[32] Batch [1200]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.097559,	
2017-06-15 22:30:42,493 Epoch[32] Batch [1210]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.097529,	
2017-06-15 22:30:48,215 Epoch[32] Batch [1220]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.097498,	
2017-06-15 22:30:54,772 Epoch[32] Batch [1230]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.097467,	
2017-06-15 22:30:59,919 Epoch[32] Batch [1240]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.097504,	
2017-06-15 22:31:06,605 Epoch[32] Batch [1250]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.097469,	
2017-06-15 22:31:11,730 Epoch[32] Batch [1260]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.097456,	
2017-06-15 22:31:18,422 Epoch[32] Batch [1270]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.097397,	
2017-06-15 22:31:24,163 Epoch[32] Batch [1280]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.097450,	
2017-06-15 22:31:31,174 Epoch[32] Batch [1290]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.097478,	
2017-06-15 22:31:37,945 Epoch[32] Batch [1300]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.097434,	
2017-06-15 22:31:43,477 Epoch[32] Batch [1310]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.097398,	
2017-06-15 22:31:50,901 Epoch[32] Batch [1320]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.097408,	
2017-06-15 22:31:55,953 Epoch[32] Batch [1330]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.097312,	
2017-06-15 22:32:02,559 Epoch[32] Batch [1340]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.097394,	
2017-06-15 22:32:07,763 Epoch[32] Batch [1350]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.097364,	
2017-06-15 22:32:14,184 Epoch[32] Batch [1360]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.097412,	
2017-06-15 22:32:19,997 Epoch[32] Batch [1370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097328,	
2017-06-15 22:32:26,300 Epoch[32] Batch [1380]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.097380,	
2017-06-15 22:32:32,560 Epoch[32] Batch [1390]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.097595,	
2017-06-15 22:32:38,783 Epoch[32] Batch [1400]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.097835,	
2017-06-15 22:32:46,663 Epoch[32] Batch [1410]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.098121,	
2017-06-15 22:32:51,894 Epoch[32] Batch [1420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098387,	
2017-06-15 22:32:58,254 Epoch[32] Batch [1430]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.098470,	
2017-06-15 22:33:03,930 Epoch[32] Batch [1440]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.098594,	
2017-06-15 22:33:10,748 Epoch[32] Batch [1450]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.098699,	
2017-06-15 22:33:17,570 Epoch[32] Batch [1460]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.098711,	
2017-06-15 22:33:23,176 Epoch[32] Batch [1470]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098751,	
2017-06-15 22:33:29,745 Epoch[32] Batch [1480]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.098757,	
2017-06-15 22:33:33,170 Epoch[32] Train-FCNLogLoss=0.098760
2017-06-15 22:33:33,171 Epoch[32] Time cost=966.006
2017-06-15 22:33:34,126 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0033.params"
2017-06-15 22:33:36,394 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0033.states"
2017-06-15 22:33:45,561 Epoch[33] Batch [10]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.082795,	
2017-06-15 22:33:52,954 Epoch[33] Batch [20]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.089882,	
2017-06-15 22:33:58,715 Epoch[33] Batch [30]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.090555,	
2017-06-15 22:34:05,292 Epoch[33] Batch [40]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.092392,	
2017-06-15 22:34:10,945 Epoch[33] Batch [50]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.091388,	
2017-06-15 22:34:17,058 Epoch[33] Batch [60]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.090391,	
2017-06-15 22:34:23,552 Epoch[33] Batch [70]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.090926,	
2017-06-15 22:34:29,179 Epoch[33] Batch [80]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.090209,	
2017-06-15 22:34:36,110 Epoch[33] Batch [90]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.090724,	
2017-06-15 22:34:42,286 Epoch[33] Batch [100]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.091637,	
2017-06-15 22:34:49,305 Epoch[33] Batch [110]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.091801,	
2017-06-15 22:34:55,064 Epoch[33] Batch [120]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.091206,	
2017-06-15 22:35:01,546 Epoch[33] Batch [130]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.090793,	
2017-06-15 22:35:07,973 Epoch[33] Batch [140]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.091933,	
2017-06-15 22:35:14,306 Epoch[33] Batch [150]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.092076,	
2017-06-15 22:35:21,286 Epoch[33] Batch [160]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.092081,	
2017-06-15 22:35:26,733 Epoch[33] Batch [170]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092383,	
2017-06-15 22:35:34,346 Epoch[33] Batch [180]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.092693,	
2017-06-15 22:35:40,563 Epoch[33] Batch [190]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.092964,	
2017-06-15 22:35:46,800 Epoch[33] Batch [200]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093419,	
2017-06-15 22:35:53,881 Epoch[33] Batch [210]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.093430,	
2017-06-15 22:35:59,717 Epoch[33] Batch [220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.093479,	
2017-06-15 22:36:06,143 Epoch[33] Batch [230]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093626,	
2017-06-15 22:36:13,170 Epoch[33] Batch [240]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.093777,	
2017-06-15 22:36:20,009 Epoch[33] Batch [250]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.094017,	
2017-06-15 22:36:26,826 Epoch[33] Batch [260]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.094390,	
2017-06-15 22:36:33,937 Epoch[33] Batch [270]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094260,	
2017-06-15 22:36:42,729 Epoch[33] Batch [280]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.094172,	
2017-06-15 22:36:49,756 Epoch[33] Batch [290]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.094023,	
2017-06-15 22:36:55,383 Epoch[33] Batch [300]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.094112,	
2017-06-15 22:37:02,221 Epoch[33] Batch [310]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.094119,	
2017-06-15 22:37:08,483 Epoch[33] Batch [320]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.094150,	
2017-06-15 22:37:15,507 Epoch[33] Batch [330]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.094632,	
2017-06-15 22:37:22,814 Epoch[33] Batch [340]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.095466,	
2017-06-15 22:37:28,547 Epoch[33] Batch [350]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.095871,	
2017-06-15 22:37:34,622 Epoch[33] Batch [360]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.096196,	
2017-06-15 22:37:40,879 Epoch[33] Batch [370]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.096119,	
2017-06-15 22:37:48,750 Epoch[33] Batch [380]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096468,	
2017-06-15 22:37:55,485 Epoch[33] Batch [390]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.096745,	
2017-06-15 22:38:01,878 Epoch[33] Batch [400]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.096788,	
2017-06-15 22:38:09,064 Epoch[33] Batch [410]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.096708,	
2017-06-15 22:38:15,659 Epoch[33] Batch [420]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.096480,	
2017-06-15 22:38:21,217 Epoch[33] Batch [430]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.096353,	
2017-06-15 22:38:28,126 Epoch[33] Batch [440]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.096724,	
2017-06-15 22:38:34,230 Epoch[33] Batch [450]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.096680,	
2017-06-15 22:38:40,935 Epoch[33] Batch [460]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.096625,	
2017-06-15 22:38:47,420 Epoch[33] Batch [470]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.096515,	
2017-06-15 22:38:54,999 Epoch[33] Batch [480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.096290,	
2017-06-15 22:39:01,958 Epoch[33] Batch [490]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.096092,	
2017-06-15 22:39:09,625 Epoch[33] Batch [500]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.095967,	
2017-06-15 22:39:17,230 Epoch[33] Batch [510]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.095763,	
2017-06-15 22:39:24,054 Epoch[33] Batch [520]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.095682,	
2017-06-15 22:39:30,248 Epoch[33] Batch [530]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.095589,	
2017-06-15 22:39:38,012 Epoch[33] Batch [540]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.095618,	
2017-06-15 22:39:46,116 Epoch[33] Batch [550]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.095556,	
2017-06-15 22:39:53,143 Epoch[33] Batch [560]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.095403,	
2017-06-15 22:39:59,312 Epoch[33] Batch [570]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.095557,	
2017-06-15 22:40:06,600 Epoch[33] Batch [580]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.095716,	
2017-06-15 22:40:14,117 Epoch[33] Batch [590]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095737,	
2017-06-15 22:40:20,326 Epoch[33] Batch [600]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.095669,	
2017-06-15 22:40:27,543 Epoch[33] Batch [610]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.095770,	
2017-06-15 22:40:33,570 Epoch[33] Batch [620]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.096473,	
2017-06-15 22:40:41,037 Epoch[33] Batch [630]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.096624,	
2017-06-15 22:40:47,983 Epoch[33] Batch [640]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.096549,	
2017-06-15 22:40:55,591 Epoch[33] Batch [650]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.096612,	
2017-06-15 22:41:02,822 Epoch[33] Batch [660]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.096496,	
2017-06-15 22:41:09,389 Epoch[33] Batch [670]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.096504,	
2017-06-15 22:41:15,194 Epoch[33] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096552,	
2017-06-15 22:41:22,665 Epoch[33] Batch [690]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096614,	
2017-06-15 22:41:29,245 Epoch[33] Batch [700]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.096553,	
2017-06-15 22:41:36,504 Epoch[33] Batch [710]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.096641,	
2017-06-15 22:41:43,394 Epoch[33] Batch [720]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.096790,	
2017-06-15 22:41:49,259 Epoch[33] Batch [730]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.096678,	
2017-06-15 22:41:56,669 Epoch[33] Batch [740]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.096637,	
2017-06-15 22:42:03,543 Epoch[33] Batch [750]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.096618,	
2017-06-15 22:42:11,001 Epoch[33] Batch [760]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.096469,	
2017-06-15 22:42:17,836 Epoch[33] Batch [770]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.096521,	
2017-06-15 22:42:25,080 Epoch[33] Batch [780]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.096600,	
2017-06-15 22:42:33,022 Epoch[33] Batch [790]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.096834,	
2017-06-15 22:42:39,766 Epoch[33] Batch [800]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.096750,	
2017-06-15 22:42:46,806 Epoch[33] Batch [810]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.096655,	
2017-06-15 22:42:54,568 Epoch[33] Batch [820]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.096494,	
2017-06-15 22:43:03,233 Epoch[33] Batch [830]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.096556,	
2017-06-15 22:43:10,434 Epoch[33] Batch [840]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.096431,	
2017-06-15 22:43:18,055 Epoch[33] Batch [850]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.096523,	
2017-06-15 22:43:26,112 Epoch[33] Batch [860]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.096517,	
2017-06-15 22:43:34,376 Epoch[33] Batch [870]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.096508,	
2017-06-15 22:43:43,449 Epoch[33] Batch [880]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.096488,	
2017-06-15 22:43:50,815 Epoch[33] Batch [890]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.096468,	
2017-06-15 22:43:58,043 Epoch[33] Batch [900]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.096379,	
2017-06-15 22:44:06,153 Epoch[33] Batch [910]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.096362,	
2017-06-15 22:44:13,370 Epoch[33] Batch [920]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.096355,	
2017-06-15 22:44:20,623 Epoch[33] Batch [930]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.096414,	
2017-06-15 22:44:26,332 Epoch[33] Batch [940]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.096352,	
2017-06-15 22:44:33,395 Epoch[33] Batch [950]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.096265,	
2017-06-15 22:44:39,760 Epoch[33] Batch [960]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.096172,	
2017-06-15 22:44:44,841 Epoch[33] Batch [970]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.096139,	
2017-06-15 22:44:51,818 Epoch[33] Batch [980]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.096118,	
2017-06-15 22:44:57,151 Epoch[33] Batch [990]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096064,	
2017-06-15 22:45:05,512 Epoch[33] Batch [1000]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.095980,	
2017-06-15 22:45:12,491 Epoch[33] Batch [1010]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.095919,	
2017-06-15 22:45:20,009 Epoch[33] Batch [1020]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095871,	
2017-06-15 22:45:27,036 Epoch[33] Batch [1030]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.095936,	
2017-06-15 22:45:33,295 Epoch[33] Batch [1040]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.095950,	
2017-06-15 22:45:38,984 Epoch[33] Batch [1050]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.095825,	
2017-06-15 22:45:45,440 Epoch[33] Batch [1060]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.095746,	
2017-06-15 22:45:50,660 Epoch[33] Batch [1070]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.095741,	
2017-06-15 22:45:57,322 Epoch[33] Batch [1080]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.095787,	
2017-06-15 22:46:03,677 Epoch[33] Batch [1090]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.095776,	
2017-06-15 22:46:11,267 Epoch[33] Batch [1100]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.095759,	
2017-06-15 22:46:18,657 Epoch[33] Batch [1110]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.095722,	
2017-06-15 22:46:24,038 Epoch[33] Batch [1120]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095712,	
2017-06-15 22:46:31,510 Epoch[33] Batch [1130]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095808,	
2017-06-15 22:46:36,956 Epoch[33] Batch [1140]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.095908,	
2017-06-15 22:46:44,154 Epoch[33] Batch [1150]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.095998,	
2017-06-15 22:46:51,070 Epoch[33] Batch [1160]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.096017,	
2017-06-15 22:46:57,956 Epoch[33] Batch [1170]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.096004,	
2017-06-15 22:47:04,717 Epoch[33] Batch [1180]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.096069,	
2017-06-15 22:47:11,450 Epoch[33] Batch [1190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.096054,	
2017-06-15 22:47:19,142 Epoch[33] Batch [1200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.096036,	
2017-06-15 22:47:26,430 Epoch[33] Batch [1210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.095981,	
2017-06-15 22:47:32,054 Epoch[33] Batch [1220]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.096035,	
2017-06-15 22:47:38,771 Epoch[33] Batch [1230]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.096139,	
2017-06-15 22:47:44,368 Epoch[33] Batch [1240]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.096154,	
2017-06-15 22:47:50,007 Epoch[33] Batch [1250]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.096134,	
2017-06-15 22:47:55,977 Epoch[33] Batch [1260]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.096164,	
2017-06-15 22:48:03,960 Epoch[33] Batch [1270]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.096186,	
2017-06-15 22:48:10,562 Epoch[33] Batch [1280]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.096162,	
2017-06-15 22:48:16,100 Epoch[33] Batch [1290]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.096185,	
2017-06-15 22:48:22,498 Epoch[33] Batch [1300]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.096101,	
2017-06-15 22:48:29,188 Epoch[33] Batch [1310]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.096063,	
2017-06-15 22:48:34,335 Epoch[33] Batch [1320]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.096098,	
2017-06-15 22:48:41,389 Epoch[33] Batch [1330]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.096044,	
2017-06-15 22:48:46,856 Epoch[33] Batch [1340]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.096086,	
2017-06-15 22:48:54,471 Epoch[33] Batch [1350]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.096102,	
2017-06-15 22:49:00,515 Epoch[33] Batch [1360]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.096116,	
2017-06-15 22:49:08,110 Epoch[33] Batch [1370]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096098,	
2017-06-15 22:49:15,129 Epoch[33] Batch [1380]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.096136,	
2017-06-15 22:49:21,803 Epoch[33] Batch [1390]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096206,	
2017-06-15 22:49:29,346 Epoch[33] Batch [1400]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.096196,	
2017-06-15 22:49:36,451 Epoch[33] Batch [1410]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.096188,	
2017-06-15 22:49:43,395 Epoch[33] Batch [1420]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.096253,	
2017-06-15 22:49:50,982 Epoch[33] Batch [1430]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096140,	
2017-06-15 22:49:58,045 Epoch[33] Batch [1440]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.096140,	
2017-06-15 22:50:03,449 Epoch[33] Batch [1450]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.096124,	
2017-06-15 22:50:09,829 Epoch[33] Batch [1460]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.096111,	
2017-06-15 22:50:14,766 Epoch[33] Batch [1470]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.096159,	
2017-06-15 22:50:22,207 Epoch[33] Batch [1480]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.096135,	
2017-06-15 22:50:25,171 Epoch[33] Train-FCNLogLoss=0.096098
2017-06-15 22:50:25,171 Epoch[33] Time cost=1008.777
2017-06-15 22:50:26,017 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0034.params"
2017-06-15 22:50:28,613 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0034.states"
2017-06-15 22:50:36,377 Epoch[34] Batch [10]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.100708,	
2017-06-15 22:50:43,770 Epoch[34] Batch [20]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.095918,	
2017-06-15 22:50:48,959 Epoch[34] Batch [30]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089911,	
2017-06-15 22:50:54,950 Epoch[34] Batch [40]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.090549,	
2017-06-15 22:51:00,756 Epoch[34] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.091735,	
2017-06-15 22:51:09,469 Epoch[34] Batch [60]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.091670,	
2017-06-15 22:51:15,563 Epoch[34] Batch [70]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.091011,	
2017-06-15 22:51:22,513 Epoch[34] Batch [80]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.092346,	
2017-06-15 22:51:30,093 Epoch[34] Batch [90]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.092121,	
2017-06-15 22:51:36,982 Epoch[34] Batch [100]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.093046,	
2017-06-15 22:51:42,966 Epoch[34] Batch [110]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.092019,	
2017-06-15 22:51:48,024 Epoch[34] Batch [120]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092482,	
2017-06-15 22:51:53,710 Epoch[34] Batch [130]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.092550,	
2017-06-15 22:51:59,858 Epoch[34] Batch [140]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.093021,	
2017-06-15 22:52:05,531 Epoch[34] Batch [150]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.093221,	
2017-06-15 22:52:11,478 Epoch[34] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093245,	
2017-06-15 22:52:17,202 Epoch[34] Batch [170]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.093475,	
2017-06-15 22:52:23,121 Epoch[34] Batch [180]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.093930,	
2017-06-15 22:52:29,333 Epoch[34] Batch [190]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.094406,	
2017-06-15 22:52:34,515 Epoch[34] Batch [200]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094518,	
2017-06-15 22:52:40,223 Epoch[34] Batch [210]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.094169,	
2017-06-15 22:52:46,173 Epoch[34] Batch [220]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094361,	
2017-06-15 22:52:52,199 Epoch[34] Batch [230]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.094284,	
2017-06-15 22:52:58,539 Epoch[34] Batch [240]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.094558,	
2017-06-15 22:53:04,495 Epoch[34] Batch [250]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094798,	
2017-06-15 22:53:10,514 Epoch[34] Batch [260]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.095309,	
2017-06-15 22:53:17,343 Epoch[34] Batch [270]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.094947,	
2017-06-15 22:53:23,294 Epoch[34] Batch [280]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094562,	
2017-06-15 22:53:28,918 Epoch[34] Batch [290]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.094407,	
2017-06-15 22:53:35,125 Epoch[34] Batch [300]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.094484,	
2017-06-15 22:53:40,984 Epoch[34] Batch [310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.094437,	
2017-06-15 22:53:47,610 Epoch[34] Batch [320]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.094148,	
2017-06-15 22:53:54,136 Epoch[34] Batch [330]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.093901,	
2017-06-15 22:54:00,223 Epoch[34] Batch [340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.094187,	
2017-06-15 22:54:06,279 Epoch[34] Batch [350]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.094122,	
2017-06-15 22:54:12,275 Epoch[34] Batch [360]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.094058,	
2017-06-15 22:54:18,007 Epoch[34] Batch [370]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.094110,	
2017-06-15 22:54:24,140 Epoch[34] Batch [380]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093883,	
2017-06-15 22:54:30,342 Epoch[34] Batch [390]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.093928,	
2017-06-15 22:54:36,752 Epoch[34] Batch [400]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093906,	
2017-06-15 22:54:42,864 Epoch[34] Batch [410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.093909,	
2017-06-15 22:54:49,201 Epoch[34] Batch [420]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.093881,	
2017-06-15 22:54:54,980 Epoch[34] Batch [430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093900,	
2017-06-15 22:55:01,514 Epoch[34] Batch [440]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.093830,	
2017-06-15 22:55:08,001 Epoch[34] Batch [450]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.094033,	
2017-06-15 22:55:13,845 Epoch[34] Batch [460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.094117,	
2017-06-15 22:55:20,306 Epoch[34] Batch [470]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.094139,	
2017-06-15 22:55:26,341 Epoch[34] Batch [480]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.094058,	
2017-06-15 22:55:32,529 Epoch[34] Batch [490]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.094258,	
2017-06-15 22:55:39,142 Epoch[34] Batch [500]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.094283,	
2017-06-15 22:55:46,269 Epoch[34] Batch [510]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.094342,	
2017-06-15 22:55:53,723 Epoch[34] Batch [520]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094133,	
2017-06-15 22:56:00,489 Epoch[34] Batch [530]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.094243,	
2017-06-15 22:56:06,924 Epoch[34] Batch [540]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.094229,	
2017-06-15 22:56:14,149 Epoch[34] Batch [550]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.094269,	
2017-06-15 22:56:20,657 Epoch[34] Batch [560]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.094144,	
2017-06-15 22:56:28,202 Epoch[34] Batch [570]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.094016,	
2017-06-15 22:56:35,631 Epoch[34] Batch [580]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.094086,	
2017-06-15 22:56:41,780 Epoch[34] Batch [590]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.094099,	
2017-06-15 22:56:47,767 Epoch[34] Batch [600]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094131,	
2017-06-15 22:56:54,786 Epoch[34] Batch [610]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.094120,	
2017-06-15 22:57:01,937 Epoch[34] Batch [620]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.094288,	
2017-06-15 22:57:09,390 Epoch[34] Batch [630]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094404,	
2017-06-15 22:57:15,834 Epoch[34] Batch [640]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094283,	
2017-06-15 22:57:23,529 Epoch[34] Batch [650]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.094438,	
2017-06-15 22:57:30,226 Epoch[34] Batch [660]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.094377,	
2017-06-15 22:57:36,908 Epoch[34] Batch [670]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094253,	
2017-06-15 22:57:44,597 Epoch[34] Batch [680]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.094127,	
2017-06-15 22:57:51,872 Epoch[34] Batch [690]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.094003,	
2017-06-15 22:57:59,404 Epoch[34] Batch [700]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.093996,	
2017-06-15 22:58:05,910 Epoch[34] Batch [710]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.094237,	
2017-06-15 22:58:12,545 Epoch[34] Batch [720]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.094192,	
2017-06-15 22:58:19,560 Epoch[34] Batch [730]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.094261,	
2017-06-15 22:58:26,775 Epoch[34] Batch [740]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.094312,	
2017-06-15 22:58:33,349 Epoch[34] Batch [750]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.094393,	
2017-06-15 22:58:40,364 Epoch[34] Batch [760]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.094314,	
2017-06-15 22:58:47,096 Epoch[34] Batch [770]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.094351,	
2017-06-15 22:58:54,367 Epoch[34] Batch [780]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.094444,	
2017-06-15 22:59:00,820 Epoch[34] Batch [790]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.094456,	
2017-06-15 22:59:07,505 Epoch[34] Batch [800]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.094392,	
2017-06-15 22:59:14,621 Epoch[34] Batch [810]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.094413,	
2017-06-15 22:59:22,721 Epoch[34] Batch [820]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.094349,	
2017-06-15 22:59:29,070 Epoch[34] Batch [830]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.094425,	
2017-06-15 22:59:35,893 Epoch[34] Batch [840]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.094359,	
2017-06-15 22:59:43,032 Epoch[34] Batch [850]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.094410,	
2017-06-15 22:59:50,113 Epoch[34] Batch [860]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.094356,	
2017-06-15 22:59:56,944 Epoch[34] Batch [870]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.094246,	
2017-06-15 23:00:05,358 Epoch[34] Batch [880]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.094218,	
2017-06-15 23:00:12,572 Epoch[34] Batch [890]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.094214,	
2017-06-15 23:00:20,991 Epoch[34] Batch [900]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.094126,	
2017-06-15 23:00:27,703 Epoch[34] Batch [910]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.094154,	
2017-06-15 23:00:35,362 Epoch[34] Batch [920]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.094127,	
2017-06-15 23:00:41,834 Epoch[34] Batch [930]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.094107,	
2017-06-15 23:00:48,859 Epoch[34] Batch [940]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.094127,	
2017-06-15 23:00:57,446 Epoch[34] Batch [950]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.094174,	
2017-06-15 23:01:05,584 Epoch[34] Batch [960]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.094114,	
2017-06-15 23:01:13,375 Epoch[34] Batch [970]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.094136,	
2017-06-15 23:01:19,598 Epoch[34] Batch [980]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.094168,	
2017-06-15 23:01:27,090 Epoch[34] Batch [990]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.094158,	
2017-06-15 23:01:34,841 Epoch[34] Batch [1000]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.094114,	
2017-06-15 23:01:42,134 Epoch[34] Batch [1010]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.094156,	
2017-06-15 23:01:49,227 Epoch[34] Batch [1020]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.094161,	
2017-06-15 23:01:56,098 Epoch[34] Batch [1030]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.094190,	
2017-06-15 23:02:03,325 Epoch[34] Batch [1040]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.094260,	
2017-06-15 23:02:10,118 Epoch[34] Batch [1050]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.094304,	
2017-06-15 23:02:18,490 Epoch[34] Batch [1060]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.094313,	
2017-06-15 23:02:25,404 Epoch[34] Batch [1070]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.094385,	
2017-06-15 23:02:32,437 Epoch[34] Batch [1080]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.094413,	
2017-06-15 23:02:39,365 Epoch[34] Batch [1090]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.094384,	
2017-06-15 23:02:46,405 Epoch[34] Batch [1100]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.094341,	
2017-06-15 23:02:53,966 Epoch[34] Batch [1110]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.094281,	
2017-06-15 23:03:03,722 Epoch[34] Batch [1120]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.094162,	
2017-06-15 23:03:12,519 Epoch[34] Batch [1130]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.094138,	
2017-06-15 23:03:20,055 Epoch[34] Batch [1140]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.094168,	
2017-06-15 23:03:27,830 Epoch[34] Batch [1150]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.094234,	
2017-06-15 23:03:34,501 Epoch[34] Batch [1160]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.094261,	
2017-06-15 23:03:42,303 Epoch[34] Batch [1170]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.094270,	
2017-06-15 23:03:49,591 Epoch[34] Batch [1180]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.094182,	
2017-06-15 23:03:57,021 Epoch[34] Batch [1190]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.094083,	
2017-06-15 23:04:04,470 Epoch[34] Batch [1200]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094057,	
2017-06-15 23:04:11,501 Epoch[34] Batch [1210]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.094025,	
2017-06-15 23:04:18,604 Epoch[34] Batch [1220]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094044,	
2017-06-15 23:04:25,911 Epoch[34] Batch [1230]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.094058,	
2017-06-15 23:04:33,477 Epoch[34] Batch [1240]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.094058,	
2017-06-15 23:04:40,958 Epoch[34] Batch [1250]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.094093,	
2017-06-15 23:04:48,935 Epoch[34] Batch [1260]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.094098,	
2017-06-15 23:04:56,824 Epoch[34] Batch [1270]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.094093,	
2017-06-15 23:05:03,459 Epoch[34] Batch [1280]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.094092,	
2017-06-15 23:05:12,124 Epoch[34] Batch [1290]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.094144,	
2017-06-15 23:05:18,822 Epoch[34] Batch [1300]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.094175,	
2017-06-15 23:05:27,170 Epoch[34] Batch [1310]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.094141,	
2017-06-15 23:05:34,418 Epoch[34] Batch [1320]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.094155,	
2017-06-15 23:05:42,234 Epoch[34] Batch [1330]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094189,	
2017-06-15 23:05:50,344 Epoch[34] Batch [1340]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.094113,	
2017-06-15 23:05:57,911 Epoch[34] Batch [1350]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.094127,	
2017-06-15 23:06:05,049 Epoch[34] Batch [1360]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.094112,	
2017-06-15 23:06:12,710 Epoch[34] Batch [1370]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.094083,	
2017-06-15 23:06:21,010 Epoch[34] Batch [1380]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.094041,	
2017-06-15 23:06:28,292 Epoch[34] Batch [1390]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.094017,	
2017-06-15 23:06:34,970 Epoch[34] Batch [1400]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094007,	
2017-06-15 23:06:43,238 Epoch[34] Batch [1410]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.094019,	
2017-06-15 23:06:51,436 Epoch[34] Batch [1420]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.094068,	
2017-06-15 23:06:57,980 Epoch[34] Batch [1430]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.094091,	
2017-06-15 23:07:06,590 Epoch[34] Batch [1440]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.094044,	
2017-06-15 23:07:14,780 Epoch[34] Batch [1450]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.094056,	
2017-06-15 23:07:22,972 Epoch[34] Batch [1460]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.094033,	
2017-06-15 23:07:30,095 Epoch[34] Batch [1470]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.094102,	
2017-06-15 23:07:37,333 Epoch[34] Batch [1480]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.094062,	
2017-06-15 23:07:41,721 Epoch[34] Train-FCNLogLoss=0.094107
2017-06-15 23:07:41,722 Epoch[34] Time cost=1033.108
2017-06-15 23:07:42,619 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0035.params"
2017-06-15 23:07:45,405 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0035.states"
2017-06-15 23:07:55,252 Epoch[35] Batch [10]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.095707,	
2017-06-15 23:08:02,566 Epoch[35] Batch [20]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.095190,	
2017-06-15 23:08:10,046 Epoch[35] Batch [30]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.097100,	
2017-06-15 23:08:18,685 Epoch[35] Batch [40]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.095959,	
2017-06-15 23:08:26,146 Epoch[35] Batch [50]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094581,	
2017-06-15 23:08:33,423 Epoch[35] Batch [60]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.094046,	
2017-06-15 23:08:42,885 Epoch[35] Batch [70]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.092998,	
2017-06-15 23:08:49,752 Epoch[35] Batch [80]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.095123,	
2017-06-15 23:08:56,855 Epoch[35] Batch [90]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094136,	
2017-06-15 23:09:05,849 Epoch[35] Batch [100]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.094219,	
2017-06-15 23:09:13,179 Epoch[35] Batch [110]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.094084,	
2017-06-15 23:09:19,887 Epoch[35] Batch [120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.093763,	
2017-06-15 23:09:28,585 Epoch[35] Batch [130]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.093179,	
2017-06-15 23:09:36,156 Epoch[35] Batch [140]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.093070,	
2017-06-15 23:09:43,814 Epoch[35] Batch [150]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.092501,	
2017-06-15 23:09:52,063 Epoch[35] Batch [160]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.092883,	
2017-06-15 23:10:00,457 Epoch[35] Batch [170]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.092955,	
2017-06-15 23:10:08,969 Epoch[35] Batch [180]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.092593,	
2017-06-15 23:10:15,476 Epoch[35] Batch [190]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.092344,	
2017-06-15 23:10:23,461 Epoch[35] Batch [200]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.092279,	
2017-06-15 23:10:31,180 Epoch[35] Batch [210]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.092550,	
2017-06-15 23:10:38,610 Epoch[35] Batch [220]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.092463,	
2017-06-15 23:10:46,345 Epoch[35] Batch [230]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.092026,	
2017-06-15 23:10:53,880 Epoch[35] Batch [240]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.091769,	
2017-06-15 23:11:01,241 Epoch[35] Batch [250]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.091935,	
2017-06-15 23:11:08,503 Epoch[35] Batch [260]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.092006,	
2017-06-15 23:11:15,856 Epoch[35] Batch [270]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.091797,	
2017-06-15 23:11:23,000 Epoch[35] Batch [280]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.091432,	
2017-06-15 23:11:30,543 Epoch[35] Batch [290]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.091240,	
2017-06-15 23:11:38,082 Epoch[35] Batch [300]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.091414,	
2017-06-15 23:11:45,755 Epoch[35] Batch [310]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.091175,	
2017-06-15 23:11:53,970 Epoch[35] Batch [320]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.091398,	
2017-06-15 23:12:01,564 Epoch[35] Batch [330]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.091470,	
2017-06-15 23:12:08,894 Epoch[35] Batch [340]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.091316,	
2017-06-15 23:12:15,912 Epoch[35] Batch [350]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.091693,	
2017-06-15 23:12:23,860 Epoch[35] Batch [360]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.091592,	
2017-06-15 23:12:31,694 Epoch[35] Batch [370]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.091549,	
2017-06-15 23:12:39,000 Epoch[35] Batch [380]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.091692,	
2017-06-15 23:12:46,893 Epoch[35] Batch [390]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.091697,	
2017-06-15 23:12:53,899 Epoch[35] Batch [400]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.091943,	
2017-06-15 23:13:01,122 Epoch[35] Batch [410]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.092021,	
2017-06-15 23:13:09,171 Epoch[35] Batch [420]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.092160,	
2017-06-15 23:13:16,641 Epoch[35] Batch [430]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.092361,	
2017-06-15 23:13:23,702 Epoch[35] Batch [440]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.092276,	
2017-06-15 23:13:31,384 Epoch[35] Batch [450]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.092126,	
2017-06-15 23:13:39,261 Epoch[35] Batch [460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.092144,	
2017-06-15 23:13:47,864 Epoch[35] Batch [470]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.092229,	
2017-06-15 23:13:54,785 Epoch[35] Batch [480]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.092180,	
2017-06-15 23:14:02,082 Epoch[35] Batch [490]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.092113,	
2017-06-15 23:14:09,285 Epoch[35] Batch [500]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.092252,	
2017-06-15 23:14:16,416 Epoch[35] Batch [510]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.092218,	
2017-06-15 23:14:24,362 Epoch[35] Batch [520]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.092133,	
2017-06-15 23:14:31,967 Epoch[35] Batch [530]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.092063,	
2017-06-15 23:14:39,583 Epoch[35] Batch [540]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.091985,	
2017-06-15 23:14:47,648 Epoch[35] Batch [550]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.092054,	
2017-06-15 23:14:55,103 Epoch[35] Batch [560]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092030,	
2017-06-15 23:15:02,391 Epoch[35] Batch [570]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.092077,	
2017-06-15 23:15:09,834 Epoch[35] Batch [580]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092203,	
2017-06-15 23:15:17,913 Epoch[35] Batch [590]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.092086,	
2017-06-15 23:15:25,912 Epoch[35] Batch [600]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.092046,	
2017-06-15 23:15:33,680 Epoch[35] Batch [610]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.091979,	
2017-06-15 23:15:40,952 Epoch[35] Batch [620]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.091926,	
2017-06-15 23:15:48,776 Epoch[35] Batch [630]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.091995,	
2017-06-15 23:15:56,707 Epoch[35] Batch [640]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.092006,	
2017-06-15 23:16:04,988 Epoch[35] Batch [650]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.091971,	
2017-06-15 23:16:13,887 Epoch[35] Batch [660]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.091905,	
2017-06-15 23:16:22,629 Epoch[35] Batch [670]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.091801,	
2017-06-15 23:16:29,967 Epoch[35] Batch [680]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.091931,	
2017-06-15 23:16:37,216 Epoch[35] Batch [690]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.091907,	
2017-06-15 23:16:45,271 Epoch[35] Batch [700]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.091923,	
2017-06-15 23:16:52,614 Epoch[35] Batch [710]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.091866,	
2017-06-15 23:17:00,944 Epoch[35] Batch [720]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.091935,	
2017-06-15 23:17:08,834 Epoch[35] Batch [730]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.091801,	
2017-06-15 23:17:17,474 Epoch[35] Batch [740]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.091756,	
2017-06-15 23:17:23,815 Epoch[35] Batch [750]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.091756,	
2017-06-15 23:17:31,999 Epoch[35] Batch [760]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.091756,	
2017-06-15 23:17:38,763 Epoch[35] Batch [770]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.091754,	
2017-06-15 23:17:45,777 Epoch[35] Batch [780]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.091782,	
2017-06-15 23:17:54,342 Epoch[35] Batch [790]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.091845,	
2017-06-15 23:18:02,596 Epoch[35] Batch [800]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.091751,	
2017-06-15 23:18:10,543 Epoch[35] Batch [810]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.091704,	
2017-06-15 23:18:18,781 Epoch[35] Batch [820]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.091830,	
2017-06-15 23:18:27,502 Epoch[35] Batch [830]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.091854,	
2017-06-15 23:18:35,766 Epoch[35] Batch [840]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.091994,	
2017-06-15 23:18:43,798 Epoch[35] Batch [850]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.091960,	
2017-06-15 23:18:52,256 Epoch[35] Batch [860]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.091893,	
2017-06-15 23:19:00,264 Epoch[35] Batch [870]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.091857,	
2017-06-15 23:19:08,262 Epoch[35] Batch [880]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.091783,	
2017-06-15 23:19:15,958 Epoch[35] Batch [890]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.091744,	
2017-06-15 23:19:24,071 Epoch[35] Batch [900]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.091677,	
2017-06-15 23:19:31,682 Epoch[35] Batch [910]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.091689,	
2017-06-15 23:19:40,925 Epoch[35] Batch [920]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.091669,	
2017-06-15 23:19:49,618 Epoch[35] Batch [930]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.091767,	
2017-06-15 23:19:56,764 Epoch[35] Batch [940]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.091816,	
2017-06-15 23:20:04,743 Epoch[35] Batch [950]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.091777,	
2017-06-15 23:20:12,401 Epoch[35] Batch [960]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.091707,	
2017-06-15 23:20:20,108 Epoch[35] Batch [970]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.091653,	
2017-06-15 23:20:28,415 Epoch[35] Batch [980]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.091601,	
2017-06-15 23:20:36,634 Epoch[35] Batch [990]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.091662,	
2017-06-15 23:20:44,754 Epoch[35] Batch [1000]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.091611,	
2017-06-15 23:20:51,580 Epoch[35] Batch [1010]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.091509,	
2017-06-15 23:20:59,335 Epoch[35] Batch [1020]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.091530,	
2017-06-15 23:21:07,422 Epoch[35] Batch [1030]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.091648,	
2017-06-15 23:21:15,341 Epoch[35] Batch [1040]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.091754,	
2017-06-15 23:21:23,407 Epoch[35] Batch [1050]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.091858,	
2017-06-15 23:21:31,584 Epoch[35] Batch [1060]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.091854,	
2017-06-15 23:21:39,544 Epoch[35] Batch [1070]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.091839,	
2017-06-15 23:21:47,027 Epoch[35] Batch [1080]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.091888,	
2017-06-15 23:21:55,090 Epoch[35] Batch [1090]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.091891,	
2017-06-15 23:22:02,245 Epoch[35] Batch [1100]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.091857,	
2017-06-15 23:22:09,298 Epoch[35] Batch [1110]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.091807,	
2017-06-15 23:22:16,785 Epoch[35] Batch [1120]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.091770,	
2017-06-15 23:22:24,876 Epoch[35] Batch [1130]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.091733,	
2017-06-15 23:22:33,336 Epoch[35] Batch [1140]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.091693,	
2017-06-15 23:22:41,477 Epoch[35] Batch [1150]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.091766,	
2017-06-15 23:22:49,320 Epoch[35] Batch [1160]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.091750,	
2017-06-15 23:22:56,504 Epoch[35] Batch [1170]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.091747,	
2017-06-15 23:23:04,541 Epoch[35] Batch [1180]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.091726,	
2017-06-15 23:23:11,822 Epoch[35] Batch [1190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.091743,	
2017-06-15 23:23:19,409 Epoch[35] Batch [1200]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.091820,	
2017-06-15 23:23:28,354 Epoch[35] Batch [1210]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.091881,	
2017-06-15 23:23:36,734 Epoch[35] Batch [1220]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.091888,	
2017-06-15 23:23:45,336 Epoch[35] Batch [1230]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.091879,	
2017-06-15 23:23:52,630 Epoch[35] Batch [1240]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.091932,	
2017-06-15 23:23:59,961 Epoch[35] Batch [1250]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.092048,	
2017-06-15 23:24:08,160 Epoch[35] Batch [1260]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.092037,	
2017-06-15 23:24:16,292 Epoch[35] Batch [1270]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.091980,	
2017-06-15 23:24:23,992 Epoch[35] Batch [1280]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.091948,	
2017-06-15 23:24:31,819 Epoch[35] Batch [1290]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.091962,	
2017-06-15 23:24:39,911 Epoch[35] Batch [1300]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.091980,	
2017-06-15 23:24:47,677 Epoch[35] Batch [1310]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.091959,	
2017-06-15 23:24:55,267 Epoch[35] Batch [1320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.092070,	
2017-06-15 23:25:02,862 Epoch[35] Batch [1330]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.092071,	
2017-06-15 23:25:11,465 Epoch[35] Batch [1340]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.092119,	
2017-06-15 23:25:19,172 Epoch[35] Batch [1350]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.092184,	
2017-06-15 23:25:27,698 Epoch[35] Batch [1360]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.092202,	
2017-06-15 23:25:36,866 Epoch[35] Batch [1370]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.092288,	
2017-06-15 23:25:44,800 Epoch[35] Batch [1380]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.092348,	
2017-06-15 23:25:53,431 Epoch[35] Batch [1390]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.092302,	
2017-06-15 23:26:01,576 Epoch[35] Batch [1400]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.092355,	
2017-06-15 23:26:09,885 Epoch[35] Batch [1410]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.092353,	
2017-06-15 23:26:18,677 Epoch[35] Batch [1420]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.092416,	
2017-06-15 23:26:26,278 Epoch[35] Batch [1430]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.092631,	
2017-06-15 23:26:34,415 Epoch[35] Batch [1440]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.093270,	
2017-06-15 23:26:42,376 Epoch[35] Batch [1450]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.093626,	
2017-06-15 23:26:50,690 Epoch[35] Batch [1460]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.094016,	
2017-06-15 23:26:58,348 Epoch[35] Batch [1470]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.094168,	
2017-06-15 23:27:06,225 Epoch[35] Batch [1480]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.094384,	
2017-06-15 23:27:12,043 Epoch[35] Train-FCNLogLoss=0.094573
2017-06-15 23:27:12,043 Epoch[35] Time cost=1166.637
2017-06-15 23:27:12,781 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0036.params"
2017-06-15 23:27:15,143 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0036.states"
2017-06-15 23:27:24,077 Epoch[36] Batch [10]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.112385,	
2017-06-15 23:27:31,687 Epoch[36] Batch [20]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.100607,	
2017-06-15 23:27:38,451 Epoch[36] Batch [30]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.101069,	
2017-06-15 23:27:46,227 Epoch[36] Batch [40]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.096438,	
2017-06-15 23:27:54,136 Epoch[36] Batch [50]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.094707,	
2017-06-15 23:28:01,639 Epoch[36] Batch [60]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.095880,	
2017-06-15 23:28:08,724 Epoch[36] Batch [70]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.095749,	
2017-06-15 23:28:15,964 Epoch[36] Batch [80]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.095818,	
2017-06-15 23:28:23,581 Epoch[36] Batch [90]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.096680,	
2017-06-15 23:28:32,123 Epoch[36] Batch [100]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.096432,	
2017-06-15 23:28:40,677 Epoch[36] Batch [110]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.096408,	
2017-06-15 23:28:48,327 Epoch[36] Batch [120]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.096310,	
2017-06-15 23:28:55,155 Epoch[36] Batch [130]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.095575,	
2017-06-15 23:29:02,129 Epoch[36] Batch [140]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.096017,	
2017-06-15 23:29:09,356 Epoch[36] Batch [150]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.096044,	
2017-06-15 23:29:17,387 Epoch[36] Batch [160]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.096635,	
2017-06-15 23:29:25,335 Epoch[36] Batch [170]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.098051,	
2017-06-15 23:29:31,932 Epoch[36] Batch [180]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.098888,	
2017-06-15 23:29:39,830 Epoch[36] Batch [190]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.099873,	
2017-06-15 23:29:46,611 Epoch[36] Batch [200]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.099693,	
2017-06-15 23:29:54,644 Epoch[36] Batch [210]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.099358,	
2017-06-15 23:30:02,682 Epoch[36] Batch [220]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.099089,	
2017-06-15 23:30:09,607 Epoch[36] Batch [230]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.099614,	
2017-06-15 23:30:16,882 Epoch[36] Batch [240]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.099408,	
2017-06-15 23:30:24,341 Epoch[36] Batch [250]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099424,	
2017-06-15 23:30:32,200 Epoch[36] Batch [260]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098907,	
2017-06-15 23:30:40,308 Epoch[36] Batch [270]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.098510,	
2017-06-15 23:30:48,015 Epoch[36] Batch [280]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.098897,	
2017-06-15 23:30:56,270 Epoch[36] Batch [290]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.098958,	
2017-06-15 23:31:04,074 Epoch[36] Batch [300]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.099270,	
2017-06-15 23:31:11,825 Epoch[36] Batch [310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.099110,	
2017-06-15 23:31:18,390 Epoch[36] Batch [320]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.098914,	
2017-06-15 23:31:26,897 Epoch[36] Batch [330]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.099395,	
2017-06-15 23:31:33,880 Epoch[36] Batch [340]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.099344,	
2017-06-15 23:31:41,119 Epoch[36] Batch [350]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.099261,	
2017-06-15 23:31:50,730 Epoch[36] Batch [360]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.099360,	
2017-06-15 23:31:57,757 Epoch[36] Batch [370]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.098983,	
2017-06-15 23:32:03,918 Epoch[36] Batch [380]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.098731,	
2017-06-15 23:32:11,528 Epoch[36] Batch [390]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.098686,	
2017-06-15 23:32:18,914 Epoch[36] Batch [400]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098651,	
2017-06-15 23:32:26,607 Epoch[36] Batch [410]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098687,	
2017-06-15 23:32:33,294 Epoch[36] Batch [420]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.098698,	
2017-06-15 23:32:40,721 Epoch[36] Batch [430]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098621,	
2017-06-15 23:32:49,050 Epoch[36] Batch [440]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.098513,	
2017-06-15 23:32:56,583 Epoch[36] Batch [450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098337,	
2017-06-15 23:33:05,281 Epoch[36] Batch [460]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.098496,	
2017-06-15 23:33:12,449 Epoch[36] Batch [470]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.098203,	
2017-06-15 23:33:19,791 Epoch[36] Batch [480]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097892,	
2017-06-15 23:33:26,731 Epoch[36] Batch [490]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.097759,	
2017-06-15 23:33:33,614 Epoch[36] Batch [500]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.097561,	
2017-06-15 23:33:41,092 Epoch[36] Batch [510]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.097586,	
2017-06-15 23:33:48,159 Epoch[36] Batch [520]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.097620,	
2017-06-15 23:33:55,440 Epoch[36] Batch [530]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.097491,	
2017-06-15 23:34:03,104 Epoch[36] Batch [540]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.097470,	
2017-06-15 23:34:10,329 Epoch[36] Batch [550]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.097434,	
2017-06-15 23:34:17,703 Epoch[36] Batch [560]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.097396,	
2017-06-15 23:34:24,393 Epoch[36] Batch [570]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.097245,	
2017-06-15 23:34:33,036 Epoch[36] Batch [580]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.097124,	
2017-06-15 23:34:39,612 Epoch[36] Batch [590]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.098101,	
2017-06-15 23:34:46,906 Epoch[36] Batch [600]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.099608,	
2017-06-15 23:34:53,844 Epoch[36] Batch [610]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.100328,	
2017-06-15 23:35:01,343 Epoch[36] Batch [620]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.101478,	
2017-06-15 23:35:08,190 Epoch[36] Batch [630]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.105867,	
2017-06-15 23:35:14,706 Epoch[36] Batch [640]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.107485,	
2017-06-15 23:35:21,545 Epoch[36] Batch [650]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.109206,	
2017-06-15 23:35:30,808 Epoch[36] Batch [660]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.110855,	
2017-06-15 23:35:38,770 Epoch[36] Batch [670]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.112356,	
2017-06-15 23:35:45,786 Epoch[36] Batch [680]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.112879,	
2017-06-15 23:35:53,401 Epoch[36] Batch [690]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.113449,	
2017-06-15 23:36:01,177 Epoch[36] Batch [700]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.114206,	
2017-06-15 23:36:08,473 Epoch[36] Batch [710]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.114733,	
2017-06-15 23:36:15,945 Epoch[36] Batch [720]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.115324,	
2017-06-15 23:36:24,405 Epoch[36] Batch [730]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115774,	
2017-06-15 23:36:31,821 Epoch[36] Batch [740]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.116031,	
2017-06-15 23:36:38,977 Epoch[36] Batch [750]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.116391,	
2017-06-15 23:36:45,836 Epoch[36] Batch [760]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.116315,	
2017-06-15 23:36:53,495 Epoch[36] Batch [770]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.116238,	
2017-06-15 23:37:01,147 Epoch[36] Batch [780]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.116296,	
2017-06-15 23:37:10,110 Epoch[36] Batch [790]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.116350,	
2017-06-15 23:37:17,159 Epoch[36] Batch [800]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.116405,	
2017-06-15 23:37:25,476 Epoch[36] Batch [810]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.116271,	
2017-06-15 23:37:33,400 Epoch[36] Batch [820]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.116049,	
2017-06-15 23:37:40,515 Epoch[36] Batch [830]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.116407,	
2017-06-15 23:37:47,434 Epoch[36] Batch [840]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.116581,	
2017-06-15 23:37:54,136 Epoch[36] Batch [850]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.116519,	
2017-06-15 23:38:01,400 Epoch[36] Batch [860]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.116273,	
2017-06-15 23:38:10,186 Epoch[36] Batch [870]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.116144,	
2017-06-15 23:38:17,290 Epoch[36] Batch [880]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.116053,	
2017-06-15 23:38:25,949 Epoch[36] Batch [890]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.116036,	
2017-06-15 23:38:33,214 Epoch[36] Batch [900]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.115902,	
2017-06-15 23:38:41,107 Epoch[36] Batch [910]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.115845,	
2017-06-15 23:38:48,506 Epoch[36] Batch [920]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.115764,	
2017-06-15 23:38:57,015 Epoch[36] Batch [930]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.115724,	
2017-06-15 23:39:04,070 Epoch[36] Batch [940]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.115631,	
2017-06-15 23:39:11,368 Epoch[36] Batch [950]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.115470,	
2017-06-15 23:39:18,779 Epoch[36] Batch [960]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.115416,	
2017-06-15 23:39:25,432 Epoch[36] Batch [970]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.115243,	
2017-06-15 23:39:33,408 Epoch[36] Batch [980]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.115148,	
2017-06-15 23:39:41,395 Epoch[36] Batch [990]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.115184,	
2017-06-15 23:39:49,334 Epoch[36] Batch [1000]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.115153,	
2017-06-15 23:39:57,278 Epoch[36] Batch [1010]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.115181,	
2017-06-15 23:40:04,099 Epoch[36] Batch [1020]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.115238,	
2017-06-15 23:40:11,742 Epoch[36] Batch [1030]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.115253,	
2017-06-15 23:40:20,114 Epoch[36] Batch [1040]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.115120,	
2017-06-15 23:40:27,355 Epoch[36] Batch [1050]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.114941,	
2017-06-15 23:40:35,620 Epoch[36] Batch [1060]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.115074,	
2017-06-15 23:40:43,750 Epoch[36] Batch [1070]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.115097,	
2017-06-15 23:40:51,153 Epoch[36] Batch [1080]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.115048,	
2017-06-15 23:40:58,739 Epoch[36] Batch [1090]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.114893,	
2017-06-15 23:41:05,363 Epoch[36] Batch [1100]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.114728,	
2017-06-15 23:41:12,711 Epoch[36] Batch [1110]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.114495,	
2017-06-15 23:41:20,404 Epoch[36] Batch [1120]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.114519,	
2017-06-15 23:41:28,524 Epoch[36] Batch [1130]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.114492,	
2017-06-15 23:41:36,208 Epoch[36] Batch [1140]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.114555,	
2017-06-15 23:41:43,511 Epoch[36] Batch [1150]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.114499,	
2017-06-15 23:41:50,226 Epoch[36] Batch [1160]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.114813,	
2017-06-15 23:41:57,380 Epoch[36] Batch [1170]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.115242,	
2017-06-15 23:42:04,053 Epoch[36] Batch [1180]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.115326,	
2017-06-15 23:42:10,406 Epoch[36] Batch [1190]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.115546,	
2017-06-15 23:42:17,985 Epoch[36] Batch [1200]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.115604,	
2017-06-15 23:42:25,510 Epoch[36] Batch [1210]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.115670,	
2017-06-15 23:42:31,021 Epoch[36] Batch [1220]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.115615,	
2017-06-15 23:42:38,976 Epoch[36] Batch [1230]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.115473,	
2017-06-15 23:42:46,630 Epoch[36] Batch [1240]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.115473,	
2017-06-15 23:42:53,753 Epoch[36] Batch [1250]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.115396,	
2017-06-15 23:43:01,193 Epoch[36] Batch [1260]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.115278,	
2017-06-15 23:43:07,710 Epoch[36] Batch [1270]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.115210,	
2017-06-15 23:43:14,772 Epoch[36] Batch [1280]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.115086,	
2017-06-15 23:43:22,946 Epoch[36] Batch [1290]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.115038,	
2017-06-15 23:43:29,953 Epoch[36] Batch [1300]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.114954,	
2017-06-15 23:43:37,231 Epoch[36] Batch [1310]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.114813,	
2017-06-15 23:43:44,324 Epoch[36] Batch [1320]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.114591,	
2017-06-15 23:43:52,239 Epoch[36] Batch [1330]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.114543,	
2017-06-15 23:43:59,577 Epoch[36] Batch [1340]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.114477,	
2017-06-15 23:44:07,105 Epoch[36] Batch [1350]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.114453,	
2017-06-15 23:44:14,525 Epoch[36] Batch [1360]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.114366,	
2017-06-15 23:44:21,846 Epoch[36] Batch [1370]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.114291,	
2017-06-15 23:44:28,720 Epoch[36] Batch [1380]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.114246,	
2017-06-15 23:44:35,982 Epoch[36] Batch [1390]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.114110,	
2017-06-15 23:44:43,596 Epoch[36] Batch [1400]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.113985,	
2017-06-15 23:44:50,297 Epoch[36] Batch [1410]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.113914,	
2017-06-15 23:44:58,148 Epoch[36] Batch [1420]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.113772,	
2017-06-15 23:45:05,354 Epoch[36] Batch [1430]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.113616,	
2017-06-15 23:45:12,309 Epoch[36] Batch [1440]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.113568,	
2017-06-15 23:45:19,150 Epoch[36] Batch [1450]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.113482,	
2017-06-15 23:45:27,141 Epoch[36] Batch [1460]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.113501,	
2017-06-15 23:45:34,361 Epoch[36] Batch [1470]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.113404,	
2017-06-15 23:45:41,962 Epoch[36] Batch [1480]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.113317,	
2017-06-15 23:45:46,996 Epoch[36] Train-FCNLogLoss=0.113241
2017-06-15 23:45:46,996 Epoch[36] Time cost=1111.852
2017-06-15 23:45:47,733 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0037.params"
2017-06-15 23:45:49,808 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0037.states"
2017-06-15 23:45:57,488 Epoch[37] Batch [10]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.410573,	
2017-06-15 23:46:04,851 Epoch[37] Batch [20]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.348857,	
2017-06-15 23:46:12,256 Epoch[37] Batch [30]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.320518,	
2017-06-15 23:46:20,008 Epoch[37] Batch [40]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.286060,	
2017-06-15 23:46:26,419 Epoch[37] Batch [50]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.258078,	
2017-06-15 23:46:33,548 Epoch[37] Batch [60]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.238509,	
2017-06-15 23:46:39,949 Epoch[37] Batch [70]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.226371,	
2017-06-15 23:46:46,650 Epoch[37] Batch [80]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.216603,	
2017-06-15 23:46:53,938 Epoch[37] Batch [90]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.209924,	
2017-06-15 23:47:00,944 Epoch[37] Batch [100]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.206675,	
2017-06-15 23:47:07,606 Epoch[37] Batch [110]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.200554,	
2017-06-15 23:47:13,378 Epoch[37] Batch [120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.195734,	
2017-06-15 23:47:20,177 Epoch[37] Batch [130]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.192691,	
2017-06-15 23:47:26,883 Epoch[37] Batch [140]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.189297,	
2017-06-15 23:47:33,260 Epoch[37] Batch [150]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.183670,	
2017-06-15 23:47:40,514 Epoch[37] Batch [160]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.183187,	
2017-06-15 23:47:47,976 Epoch[37] Batch [170]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.179575,	
2017-06-15 23:47:56,150 Epoch[37] Batch [180]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.177555,	
2017-06-15 23:48:02,967 Epoch[37] Batch [190]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.174634,	
2017-06-15 23:48:09,511 Epoch[37] Batch [200]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.171126,	
2017-06-15 23:48:16,791 Epoch[37] Batch [210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.168547,	
2017-06-15 23:48:25,274 Epoch[37] Batch [220]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.166796,	
2017-06-15 23:48:32,124 Epoch[37] Batch [230]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.164269,	
2017-06-15 23:48:39,309 Epoch[37] Batch [240]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.162035,	
2017-06-15 23:48:45,928 Epoch[37] Batch [250]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.159941,	
2017-06-15 23:48:51,847 Epoch[37] Batch [260]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.158057,	
2017-06-15 23:48:59,257 Epoch[37] Batch [270]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.155933,	
2017-06-15 23:49:06,336 Epoch[37] Batch [280]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.154441,	
2017-06-15 23:49:14,188 Epoch[37] Batch [290]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.152772,	
2017-06-15 23:49:21,901 Epoch[37] Batch [300]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.151316,	
2017-06-15 23:49:29,654 Epoch[37] Batch [310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.149556,	
2017-06-15 23:49:38,475 Epoch[37] Batch [320]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.148119,	
2017-06-15 23:49:45,687 Epoch[37] Batch [330]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.146521,	
2017-06-15 23:49:52,393 Epoch[37] Batch [340]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.145721,	
2017-06-15 23:49:58,472 Epoch[37] Batch [350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.144917,	
2017-06-15 23:50:06,376 Epoch[37] Batch [360]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.143705,	
2017-06-15 23:50:14,346 Epoch[37] Batch [370]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.142448,	
2017-06-15 23:50:20,925 Epoch[37] Batch [380]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.141518,	
2017-06-15 23:50:27,425 Epoch[37] Batch [390]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.140369,	
2017-06-15 23:50:34,520 Epoch[37] Batch [400]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.139826,	
2017-06-15 23:50:41,690 Epoch[37] Batch [410]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.139437,	
2017-06-15 23:50:48,808 Epoch[37] Batch [420]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.138695,	
2017-06-15 23:50:56,814 Epoch[37] Batch [430]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.137704,	
2017-06-15 23:51:03,823 Epoch[37] Batch [440]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.137045,	
2017-06-15 23:51:09,886 Epoch[37] Batch [450]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.136605,	
2017-06-15 23:51:18,308 Epoch[37] Batch [460]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.136019,	
2017-06-15 23:51:25,300 Epoch[37] Batch [470]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.135422,	
2017-06-15 23:51:32,492 Epoch[37] Batch [480]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.134709,	
2017-06-15 23:51:38,895 Epoch[37] Batch [490]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.134173,	
2017-06-15 23:51:46,439 Epoch[37] Batch [500]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.133581,	
2017-06-15 23:51:53,994 Epoch[37] Batch [510]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.133198,	
2017-06-15 23:52:01,088 Epoch[37] Batch [520]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.132707,	
2017-06-15 23:52:08,611 Epoch[37] Batch [530]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.132215,	
2017-06-15 23:52:15,493 Epoch[37] Batch [540]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.131610,	
2017-06-15 23:52:22,435 Epoch[37] Batch [550]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.131203,	
2017-06-15 23:52:29,297 Epoch[37] Batch [560]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.130588,	
2017-06-15 23:52:37,170 Epoch[37] Batch [570]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.130803,	
2017-06-15 23:52:44,287 Epoch[37] Batch [580]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.131102,	
2017-06-15 23:52:52,985 Epoch[37] Batch [590]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.131242,	
2017-06-15 23:53:00,579 Epoch[37] Batch [600]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.131368,	
2017-06-15 23:53:07,888 Epoch[37] Batch [610]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.131146,	
2017-06-15 23:53:14,851 Epoch[37] Batch [620]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.131057,	
2017-06-15 23:53:25,429 Epoch[37] Batch [630]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.134213,	
2017-06-15 23:53:32,998 Epoch[37] Batch [640]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.135713,	
2017-06-15 23:53:40,329 Epoch[37] Batch [650]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.136672,	
2017-06-15 23:53:47,776 Epoch[37] Batch [660]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.137251,	
2017-06-15 23:53:55,559 Epoch[37] Batch [670]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.138614,	
2017-06-15 23:54:04,600 Epoch[37] Batch [680]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.138356,	
2017-06-15 23:54:11,656 Epoch[37] Batch [690]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.138170,	
2017-06-15 23:54:18,939 Epoch[37] Batch [700]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.138465,	
2017-06-15 23:54:27,164 Epoch[37] Batch [710]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.138514,	
2017-06-15 23:54:34,237 Epoch[37] Batch [720]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.140123,	
2017-06-15 23:54:41,918 Epoch[37] Batch [730]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.140502,	
2017-06-15 23:54:50,476 Epoch[37] Batch [740]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.140686,	
2017-06-15 23:54:58,274 Epoch[37] Batch [750]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.140906,	
2017-06-15 23:55:06,394 Epoch[37] Batch [760]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.141009,	
2017-06-15 23:55:13,050 Epoch[37] Batch [770]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.141655,	
2017-06-15 23:55:20,644 Epoch[37] Batch [780]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.142019,	
2017-06-15 23:55:28,462 Epoch[37] Batch [790]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.141945,	
2017-06-15 23:55:36,452 Epoch[37] Batch [800]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.141998,	
2017-06-15 23:55:43,419 Epoch[37] Batch [810]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.141754,	
2017-06-15 23:55:50,894 Epoch[37] Batch [820]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.141963,	
2017-06-15 23:55:58,405 Epoch[37] Batch [830]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.141721,	
2017-06-15 23:56:06,142 Epoch[37] Batch [840]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.141670,	
2017-06-15 23:56:13,554 Epoch[37] Batch [850]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.141653,	
2017-06-15 23:56:21,303 Epoch[37] Batch [860]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.141620,	
2017-06-15 23:56:29,162 Epoch[37] Batch [870]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.141345,	
2017-06-15 23:56:37,160 Epoch[37] Batch [880]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.141159,	
2017-06-15 23:56:44,933 Epoch[37] Batch [890]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.140815,	
2017-06-15 23:56:53,707 Epoch[37] Batch [900]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.140600,	
2017-06-15 23:57:01,504 Epoch[37] Batch [910]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.140221,	
2017-06-15 23:57:09,475 Epoch[37] Batch [920]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.139965,	
2017-06-15 23:57:18,296 Epoch[37] Batch [930]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.139534,	
2017-06-15 23:57:26,149 Epoch[37] Batch [940]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.139250,	
2017-06-15 23:57:33,903 Epoch[37] Batch [950]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.139072,	
2017-06-15 23:57:41,384 Epoch[37] Batch [960]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.138723,	
2017-06-15 23:57:49,486 Epoch[37] Batch [970]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.138413,	
2017-06-15 23:57:57,448 Epoch[37] Batch [980]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.138181,	
2017-06-15 23:58:05,008 Epoch[37] Batch [990]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.137940,	
2017-06-15 23:58:12,186 Epoch[37] Batch [1000]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.137727,	
2017-06-15 23:58:19,383 Epoch[37] Batch [1010]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.137479,	
2017-06-15 23:58:26,621 Epoch[37] Batch [1020]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.137104,	
2017-06-15 23:58:34,086 Epoch[37] Batch [1030]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.136821,	
2017-06-15 23:58:42,029 Epoch[37] Batch [1040]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.136592,	
2017-06-15 23:58:50,298 Epoch[37] Batch [1050]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.136320,	
2017-06-15 23:58:56,854 Epoch[37] Batch [1060]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.136028,	
2017-06-15 23:59:04,960 Epoch[37] Batch [1070]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.135741,	
2017-06-15 23:59:12,327 Epoch[37] Batch [1080]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.135418,	
2017-06-15 23:59:19,966 Epoch[37] Batch [1090]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.135175,	
2017-06-15 23:59:28,551 Epoch[37] Batch [1100]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.134982,	
2017-06-15 23:59:36,044 Epoch[37] Batch [1110]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.134805,	
2017-06-15 23:59:43,548 Epoch[37] Batch [1120]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.134491,	
2017-06-15 23:59:51,378 Epoch[37] Batch [1130]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.134368,	
2017-06-15 23:59:58,645 Epoch[37] Batch [1140]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.134027,	
2017-06-16 00:00:06,344 Epoch[37] Batch [1150]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.133793,	
2017-06-16 00:00:14,575 Epoch[37] Batch [1160]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.133463,	
2017-06-16 00:00:23,031 Epoch[37] Batch [1170]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.133261,	
2017-06-16 00:00:30,197 Epoch[37] Batch [1180]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.133080,	
2017-06-16 00:00:37,615 Epoch[37] Batch [1190]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.132881,	
2017-06-16 00:00:45,140 Epoch[37] Batch [1200]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.132664,	
2017-06-16 00:00:52,799 Epoch[37] Batch [1210]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.132353,	
2017-06-16 00:00:59,275 Epoch[37] Batch [1220]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.132022,	
2017-06-16 00:01:06,663 Epoch[37] Batch [1230]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.131738,	
2017-06-16 00:01:14,747 Epoch[37] Batch [1240]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.131473,	
2017-06-16 00:01:22,050 Epoch[37] Batch [1250]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.131236,	
2017-06-16 00:01:29,873 Epoch[37] Batch [1260]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.131010,	
2017-06-16 00:01:37,172 Epoch[37] Batch [1270]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.130778,	
2017-06-16 00:01:45,056 Epoch[37] Batch [1280]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.130518,	
2017-06-16 00:01:51,755 Epoch[37] Batch [1290]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.130293,	
2017-06-16 00:01:58,959 Epoch[37] Batch [1300]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.130039,	
2017-06-16 00:02:05,837 Epoch[37] Batch [1310]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.129773,	
2017-06-16 00:02:12,376 Epoch[37] Batch [1320]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.129509,	
2017-06-16 00:02:20,526 Epoch[37] Batch [1330]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.129291,	
2017-06-16 00:02:28,207 Epoch[37] Batch [1340]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.129160,	
2017-06-16 00:02:35,493 Epoch[37] Batch [1350]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.128945,	
2017-06-16 00:02:42,569 Epoch[37] Batch [1360]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.128708,	
2017-06-16 00:02:49,446 Epoch[37] Batch [1370]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.128430,	
2017-06-16 00:02:56,412 Epoch[37] Batch [1380]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.128311,	
2017-06-16 00:03:04,310 Epoch[37] Batch [1390]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.128019,	
2017-06-16 00:03:12,048 Epoch[37] Batch [1400]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.127874,	
2017-06-16 00:03:18,736 Epoch[37] Batch [1410]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.127712,	
2017-06-16 00:03:26,230 Epoch[37] Batch [1420]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.127538,	
2017-06-16 00:03:33,922 Epoch[37] Batch [1430]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.127407,	
2017-06-16 00:03:41,954 Epoch[37] Batch [1440]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.127239,	
2017-06-16 00:03:49,202 Epoch[37] Batch [1450]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.127094,	
2017-06-16 00:03:57,154 Epoch[37] Batch [1460]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.126907,	
2017-06-16 00:04:03,807 Epoch[37] Batch [1470]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.126770,	
2017-06-16 00:04:11,265 Epoch[37] Batch [1480]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.126570,	
2017-06-16 00:04:16,143 Epoch[37] Train-FCNLogLoss=0.126483
2017-06-16 00:04:16,143 Epoch[37] Time cost=1106.334
2017-06-16 00:04:16,907 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0038.params"
2017-06-16 00:04:20,630 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0038.states"
2017-06-16 00:04:28,496 Epoch[38] Batch [10]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.102780,	
2017-06-16 00:04:35,180 Epoch[38] Batch [20]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.101639,	
2017-06-16 00:04:42,748 Epoch[38] Batch [30]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.102977,	
2017-06-16 00:04:49,413 Epoch[38] Batch [40]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.108331,	
2017-06-16 00:04:56,172 Epoch[38] Batch [50]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.109437,	
2017-06-16 00:05:03,310 Epoch[38] Batch [60]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.111658,	
2017-06-16 00:05:09,252 Epoch[38] Batch [70]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.110879,	
2017-06-16 00:05:16,084 Epoch[38] Batch [80]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.111256,	
2017-06-16 00:05:23,260 Epoch[38] Batch [90]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.111288,	
2017-06-16 00:05:30,329 Epoch[38] Batch [100]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.110781,	
2017-06-16 00:05:37,385 Epoch[38] Batch [110]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.110513,	
2017-06-16 00:05:44,441 Epoch[38] Batch [120]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.109904,	
2017-06-16 00:05:51,926 Epoch[38] Batch [130]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.109023,	
2017-06-16 00:05:59,418 Epoch[38] Batch [140]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.109333,	
2017-06-16 00:06:07,181 Epoch[38] Batch [150]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.107570,	
2017-06-16 00:06:14,266 Epoch[38] Batch [160]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.106538,	
2017-06-16 00:06:21,238 Epoch[38] Batch [170]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.106793,	
2017-06-16 00:06:27,479 Epoch[38] Batch [180]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106733,	
2017-06-16 00:06:34,640 Epoch[38] Batch [190]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.106269,	
2017-06-16 00:06:41,601 Epoch[38] Batch [200]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.106318,	
2017-06-16 00:06:48,238 Epoch[38] Batch [210]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.105891,	
2017-06-16 00:06:55,541 Epoch[38] Batch [220]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.105626,	
2017-06-16 00:07:02,681 Epoch[38] Batch [230]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.106037,	
2017-06-16 00:07:10,066 Epoch[38] Batch [240]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.107881,	
2017-06-16 00:07:17,095 Epoch[38] Batch [250]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.108598,	
2017-06-16 00:07:22,746 Epoch[38] Batch [260]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.109033,	
2017-06-16 00:07:29,087 Epoch[38] Batch [270]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.109602,	
2017-06-16 00:07:35,820 Epoch[38] Batch [280]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.109527,	
2017-06-16 00:07:42,931 Epoch[38] Batch [290]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109620,	
2017-06-16 00:07:48,545 Epoch[38] Batch [300]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.109406,	
2017-06-16 00:07:56,059 Epoch[38] Batch [310]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.109332,	
2017-06-16 00:08:02,389 Epoch[38] Batch [320]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.109458,	
2017-06-16 00:08:09,444 Epoch[38] Batch [330]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.109503,	
2017-06-16 00:08:16,888 Epoch[38] Batch [340]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.109439,	
2017-06-16 00:08:23,769 Epoch[38] Batch [350]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.109203,	
2017-06-16 00:08:30,244 Epoch[38] Batch [360]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.109240,	
2017-06-16 00:08:37,640 Epoch[38] Batch [370]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.109190,	
2017-06-16 00:08:44,774 Epoch[38] Batch [380]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.108805,	
2017-06-16 00:08:51,637 Epoch[38] Batch [390]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.108894,	
2017-06-16 00:08:58,428 Epoch[38] Batch [400]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.108813,	
2017-06-16 00:09:05,264 Epoch[38] Batch [410]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.108696,	
2017-06-16 00:09:11,180 Epoch[38] Batch [420]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.108519,	
2017-06-16 00:09:18,669 Epoch[38] Batch [430]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.108046,	
2017-06-16 00:09:24,607 Epoch[38] Batch [440]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107950,	
2017-06-16 00:09:32,072 Epoch[38] Batch [450]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.107930,	
2017-06-16 00:09:39,316 Epoch[38] Batch [460]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.107525,	
2017-06-16 00:09:46,061 Epoch[38] Batch [470]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.107329,	
2017-06-16 00:09:53,407 Epoch[38] Batch [480]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.107348,	
2017-06-16 00:09:59,216 Epoch[38] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107109,	
2017-06-16 00:10:05,855 Epoch[38] Batch [500]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.106999,	
2017-06-16 00:10:12,792 Epoch[38] Batch [510]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.106819,	
2017-06-16 00:10:20,086 Epoch[38] Batch [520]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.106584,	
2017-06-16 00:10:27,062 Epoch[38] Batch [530]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.106360,	
2017-06-16 00:10:35,344 Epoch[38] Batch [540]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.106123,	
2017-06-16 00:10:42,189 Epoch[38] Batch [550]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.105794,	
2017-06-16 00:10:48,738 Epoch[38] Batch [560]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.105646,	
2017-06-16 00:10:55,922 Epoch[38] Batch [570]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.105538,	
2017-06-16 00:11:03,409 Epoch[38] Batch [580]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.105361,	
2017-06-16 00:11:10,398 Epoch[38] Batch [590]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.105245,	
2017-06-16 00:11:18,183 Epoch[38] Batch [600]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.104939,	
2017-06-16 00:11:24,399 Epoch[38] Batch [610]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.104820,	
2017-06-16 00:11:31,129 Epoch[38] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.104546,	
2017-06-16 00:11:38,700 Epoch[38] Batch [630]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.104518,	
2017-06-16 00:11:45,467 Epoch[38] Batch [640]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.104485,	
2017-06-16 00:11:52,974 Epoch[38] Batch [650]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.104466,	
2017-06-16 00:11:59,213 Epoch[38] Batch [660]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.104462,	
2017-06-16 00:12:07,451 Epoch[38] Batch [670]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.104369,	
2017-06-16 00:12:14,993 Epoch[38] Batch [680]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.104270,	
2017-06-16 00:12:22,883 Epoch[38] Batch [690]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.104093,	
2017-06-16 00:12:29,749 Epoch[38] Batch [700]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.104126,	
2017-06-16 00:12:36,430 Epoch[38] Batch [710]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.104034,	
2017-06-16 00:12:42,300 Epoch[38] Batch [720]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104151,	
2017-06-16 00:12:50,818 Epoch[38] Batch [730]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.104055,	
2017-06-16 00:12:57,766 Epoch[38] Batch [740]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.104047,	
2017-06-16 00:13:05,362 Epoch[38] Batch [750]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.104087,	
2017-06-16 00:13:13,639 Epoch[38] Batch [760]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.104130,	
2017-06-16 00:13:21,148 Epoch[38] Batch [770]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.104095,	
2017-06-16 00:13:28,621 Epoch[38] Batch [780]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.104068,	
2017-06-16 00:13:36,340 Epoch[38] Batch [790]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.104142,	
2017-06-16 00:13:43,526 Epoch[38] Batch [800]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.104164,	
2017-06-16 00:13:49,736 Epoch[38] Batch [810]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.104145,	
2017-06-16 00:13:57,219 Epoch[38] Batch [820]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.104123,	
2017-06-16 00:14:02,980 Epoch[38] Batch [830]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.104159,	
2017-06-16 00:14:08,744 Epoch[38] Batch [840]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.104282,	
2017-06-16 00:14:16,137 Epoch[38] Batch [850]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.104675,	
2017-06-16 00:14:23,277 Epoch[38] Batch [860]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.104764,	
2017-06-16 00:14:30,241 Epoch[38] Batch [870]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.104819,	
2017-06-16 00:14:38,670 Epoch[38] Batch [880]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.104771,	
2017-06-16 00:14:48,066 Epoch[38] Batch [890]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.104793,	
2017-06-16 00:14:54,578 Epoch[38] Batch [900]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.104796,	
2017-06-16 00:15:01,974 Epoch[38] Batch [910]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.104718,	
2017-06-16 00:15:08,933 Epoch[38] Batch [920]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.104653,	
2017-06-16 00:15:17,372 Epoch[38] Batch [930]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.104509,	
2017-06-16 00:15:24,741 Epoch[38] Batch [940]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.104484,	
2017-06-16 00:15:34,001 Epoch[38] Batch [950]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.104464,	
2017-06-16 00:15:41,922 Epoch[38] Batch [960]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.104356,	
2017-06-16 00:15:50,259 Epoch[38] Batch [970]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.104337,	
2017-06-16 00:15:57,742 Epoch[38] Batch [980]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.104267,	
2017-06-16 00:16:04,834 Epoch[38] Batch [990]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.104309,	
2017-06-16 00:16:12,223 Epoch[38] Batch [1000]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.104316,	
2017-06-16 00:16:19,422 Epoch[38] Batch [1010]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.104299,	
2017-06-16 00:16:26,985 Epoch[38] Batch [1020]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.104316,	
2017-06-16 00:16:34,024 Epoch[38] Batch [1030]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.104239,	
2017-06-16 00:16:40,586 Epoch[38] Batch [1040]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.104081,	
2017-06-16 00:16:48,272 Epoch[38] Batch [1050]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.104031,	
2017-06-16 00:16:55,994 Epoch[38] Batch [1060]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.104006,	
2017-06-16 00:17:03,372 Epoch[38] Batch [1070]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.103880,	
2017-06-16 00:17:11,223 Epoch[38] Batch [1080]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.103777,	
2017-06-16 00:17:18,717 Epoch[38] Batch [1090]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.103728,	
2017-06-16 00:17:27,182 Epoch[38] Batch [1100]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.103707,	
2017-06-16 00:17:33,932 Epoch[38] Batch [1110]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.103678,	
2017-06-16 00:17:41,341 Epoch[38] Batch [1120]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.103606,	
2017-06-16 00:17:49,118 Epoch[38] Batch [1130]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.103605,	
2017-06-16 00:17:57,105 Epoch[38] Batch [1140]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.103464,	
2017-06-16 00:18:03,214 Epoch[38] Batch [1150]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103436,	
2017-06-16 00:18:10,404 Epoch[38] Batch [1160]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.103397,	
2017-06-16 00:18:17,057 Epoch[38] Batch [1170]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.103340,	
2017-06-16 00:18:23,276 Epoch[38] Batch [1180]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.103236,	
2017-06-16 00:18:30,635 Epoch[38] Batch [1190]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.103286,	
2017-06-16 00:18:39,078 Epoch[38] Batch [1200]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.103316,	
2017-06-16 00:18:46,912 Epoch[38] Batch [1210]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.103149,	
2017-06-16 00:18:53,724 Epoch[38] Batch [1220]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.103050,	
2017-06-16 00:19:00,996 Epoch[38] Batch [1230]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.103012,	
2017-06-16 00:19:08,774 Epoch[38] Batch [1240]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.102974,	
2017-06-16 00:19:17,379 Epoch[38] Batch [1250]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.102949,	
2017-06-16 00:19:24,636 Epoch[38] Batch [1260]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.102994,	
2017-06-16 00:19:33,255 Epoch[38] Batch [1270]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.102969,	
2017-06-16 00:19:42,269 Epoch[38] Batch [1280]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.102957,	
2017-06-16 00:19:49,996 Epoch[38] Batch [1290]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.102950,	
2017-06-16 00:19:57,488 Epoch[38] Batch [1300]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.102870,	
2017-06-16 00:20:04,500 Epoch[38] Batch [1310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.102774,	
2017-06-16 00:20:12,137 Epoch[38] Batch [1320]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.102658,	
2017-06-16 00:20:19,670 Epoch[38] Batch [1330]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.102567,	
2017-06-16 00:20:27,953 Epoch[38] Batch [1340]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.102473,	
2017-06-16 00:20:35,682 Epoch[38] Batch [1350]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.102409,	
2017-06-16 00:20:43,864 Epoch[38] Batch [1360]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.102365,	
2017-06-16 00:20:51,045 Epoch[38] Batch [1370]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.102277,	
2017-06-16 00:20:58,781 Epoch[38] Batch [1380]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.102321,	
2017-06-16 00:21:06,391 Epoch[38] Batch [1390]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.102250,	
2017-06-16 00:21:13,743 Epoch[38] Batch [1400]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.102195,	
2017-06-16 00:21:21,338 Epoch[38] Batch [1410]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.102178,	
2017-06-16 00:21:28,192 Epoch[38] Batch [1420]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.102193,	
2017-06-16 00:21:35,333 Epoch[38] Batch [1430]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.102141,	
2017-06-16 00:21:43,335 Epoch[38] Batch [1440]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.102042,	
2017-06-16 00:21:50,467 Epoch[38] Batch [1450]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.102123,	
2017-06-16 00:21:57,743 Epoch[38] Batch [1460]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.102060,	
2017-06-16 00:22:05,301 Epoch[38] Batch [1470]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.102016,	
2017-06-16 00:22:12,873 Epoch[38] Batch [1480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.101909,	
2017-06-16 00:22:17,211 Epoch[38] Train-FCNLogLoss=0.101893
2017-06-16 00:22:17,211 Epoch[38] Time cost=1076.581
2017-06-16 00:22:18,020 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0039.params"
2017-06-16 00:22:19,994 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0039.states"
2017-06-16 00:22:27,219 Epoch[39] Batch [10]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.110761,	
2017-06-16 00:22:34,169 Epoch[39] Batch [20]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102925,	
2017-06-16 00:22:42,763 Epoch[39] Batch [30]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.100570,	
2017-06-16 00:22:49,832 Epoch[39] Batch [40]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.101887,	
2017-06-16 00:22:57,579 Epoch[39] Batch [50]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.101442,	
2017-06-16 00:23:04,969 Epoch[39] Batch [60]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.099205,	
2017-06-16 00:23:11,888 Epoch[39] Batch [70]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.098703,	
2017-06-16 00:23:19,816 Epoch[39] Batch [80]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.098072,	
2017-06-16 00:23:26,682 Epoch[39] Batch [90]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.097948,	
2017-06-16 00:23:33,840 Epoch[39] Batch [100]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098452,	
2017-06-16 00:23:41,065 Epoch[39] Batch [110]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.098052,	
2017-06-16 00:23:49,509 Epoch[39] Batch [120]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.097000,	
2017-06-16 00:23:57,023 Epoch[39] Batch [130]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.096226,	
2017-06-16 00:24:04,674 Epoch[39] Batch [140]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.095977,	
2017-06-16 00:24:12,700 Epoch[39] Batch [150]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.096701,	
2017-06-16 00:24:20,620 Epoch[39] Batch [160]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.096406,	
2017-06-16 00:24:29,058 Epoch[39] Batch [170]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.096685,	
2017-06-16 00:24:36,779 Epoch[39] Batch [180]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.097087,	
2017-06-16 00:24:42,785 Epoch[39] Batch [190]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.096832,	
2017-06-16 00:24:50,090 Epoch[39] Batch [200]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.096688,	
2017-06-16 00:24:57,107 Epoch[39] Batch [210]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.096678,	
2017-06-16 00:25:04,583 Epoch[39] Batch [220]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096681,	
2017-06-16 00:25:12,680 Epoch[39] Batch [230]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.096976,	
2017-06-16 00:25:20,430 Epoch[39] Batch [240]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.097053,	
2017-06-16 00:25:28,404 Epoch[39] Batch [250]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.096999,	
2017-06-16 00:25:36,755 Epoch[39] Batch [260]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.097121,	
2017-06-16 00:25:43,869 Epoch[39] Batch [270]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.097130,	
2017-06-16 00:25:50,478 Epoch[39] Batch [280]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.096732,	
2017-06-16 00:25:57,948 Epoch[39] Batch [290]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.096862,	
2017-06-16 00:26:05,190 Epoch[39] Batch [300]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.096944,	
2017-06-16 00:26:12,405 Epoch[39] Batch [310]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.096912,	
2017-06-16 00:26:20,174 Epoch[39] Batch [320]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.096929,	
2017-06-16 00:26:27,741 Epoch[39] Batch [330]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096758,	
2017-06-16 00:26:35,092 Epoch[39] Batch [340]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.096532,	
2017-06-16 00:26:42,949 Epoch[39] Batch [350]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.096408,	
2017-06-16 00:26:49,961 Epoch[39] Batch [360]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.096375,	
2017-06-16 00:26:57,553 Epoch[39] Batch [370]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096290,	
2017-06-16 00:27:05,370 Epoch[39] Batch [380]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.096316,	
2017-06-16 00:27:12,045 Epoch[39] Batch [390]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096156,	
2017-06-16 00:27:20,130 Epoch[39] Batch [400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.096044,	
2017-06-16 00:27:27,530 Epoch[39] Batch [410]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.095806,	
2017-06-16 00:27:35,673 Epoch[39] Batch [420]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095767,	
2017-06-16 00:27:43,236 Epoch[39] Batch [430]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.095782,	
2017-06-16 00:27:50,716 Epoch[39] Batch [440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095719,	
2017-06-16 00:27:57,749 Epoch[39] Batch [450]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.095573,	
2017-06-16 00:28:04,704 Epoch[39] Batch [460]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.095680,	
2017-06-16 00:28:11,914 Epoch[39] Batch [470]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.095936,	
2017-06-16 00:28:19,789 Epoch[39] Batch [480]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096030,	
2017-06-16 00:28:27,309 Epoch[39] Batch [490]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.096068,	
2017-06-16 00:28:34,626 Epoch[39] Batch [500]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.095936,	
2017-06-16 00:28:41,792 Epoch[39] Batch [510]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.096018,	
2017-06-16 00:28:48,523 Epoch[39] Batch [520]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.096185,	
2017-06-16 00:28:57,038 Epoch[39] Batch [530]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.096108,	
2017-06-16 00:29:04,599 Epoch[39] Batch [540]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.095949,	
2017-06-16 00:29:11,421 Epoch[39] Batch [550]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.095901,	
2017-06-16 00:29:18,958 Epoch[39] Batch [560]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095778,	
2017-06-16 00:29:26,527 Epoch[39] Batch [570]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.095722,	
2017-06-16 00:29:33,962 Epoch[39] Batch [580]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095507,	
2017-06-16 00:29:42,091 Epoch[39] Batch [590]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.095352,	
2017-06-16 00:29:49,546 Epoch[39] Batch [600]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.095271,	
2017-06-16 00:29:57,070 Epoch[39] Batch [610]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095270,	
2017-06-16 00:30:03,801 Epoch[39] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.095150,	
2017-06-16 00:30:10,473 Epoch[39] Batch [630]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094957,	
2017-06-16 00:30:18,285 Epoch[39] Batch [640]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094995,	
2017-06-16 00:30:25,744 Epoch[39] Batch [650]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094797,	
2017-06-16 00:30:33,014 Epoch[39] Batch [660]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.094638,	
2017-06-16 00:30:40,863 Epoch[39] Batch [670]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.094628,	
2017-06-16 00:30:48,451 Epoch[39] Batch [680]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.094623,	
2017-06-16 00:30:55,616 Epoch[39] Batch [690]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.094495,	
2017-06-16 00:31:03,429 Epoch[39] Batch [700]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094457,	
2017-06-16 00:31:10,797 Epoch[39] Batch [710]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.094321,	
2017-06-16 00:31:19,127 Epoch[39] Batch [720]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.094131,	
2017-06-16 00:31:26,813 Epoch[39] Batch [730]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.094076,	
2017-06-16 00:31:34,263 Epoch[39] Batch [740]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094076,	
2017-06-16 00:31:42,302 Epoch[39] Batch [750]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.094138,	
2017-06-16 00:31:49,216 Epoch[39] Batch [760]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.094104,	
2017-06-16 00:31:56,680 Epoch[39] Batch [770]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094006,	
2017-06-16 00:32:03,359 Epoch[39] Batch [780]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.093996,	
2017-06-16 00:32:11,355 Epoch[39] Batch [790]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.093864,	
2017-06-16 00:32:18,727 Epoch[39] Batch [800]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.094005,	
2017-06-16 00:32:25,502 Epoch[39] Batch [810]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.093953,	
2017-06-16 00:32:32,964 Epoch[39] Batch [820]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.093879,	
2017-06-16 00:32:40,276 Epoch[39] Batch [830]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.094044,	
2017-06-16 00:32:47,487 Epoch[39] Batch [840]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.093997,	
2017-06-16 00:32:54,660 Epoch[39] Batch [850]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.094161,	
2017-06-16 00:33:01,697 Epoch[39] Batch [860]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.094261,	
2017-06-16 00:33:09,795 Epoch[39] Batch [870]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.094304,	
2017-06-16 00:33:17,662 Epoch[39] Batch [880]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.094452,	
2017-06-16 00:33:25,924 Epoch[39] Batch [890]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.094388,	
2017-06-16 00:33:33,133 Epoch[39] Batch [900]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.094449,	
2017-06-16 00:33:40,729 Epoch[39] Batch [910]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.094348,	
2017-06-16 00:33:48,661 Epoch[39] Batch [920]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.094302,	
2017-06-16 00:33:56,662 Epoch[39] Batch [930]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.094317,	
2017-06-16 00:34:04,398 Epoch[39] Batch [940]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.094401,	
2017-06-16 00:34:12,403 Epoch[39] Batch [950]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.094410,	
2017-06-16 00:34:20,903 Epoch[39] Batch [960]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.094280,	
2017-06-16 00:34:28,257 Epoch[39] Batch [970]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.094273,	
2017-06-16 00:34:34,992 Epoch[39] Batch [980]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.094425,	
2017-06-16 00:34:43,375 Epoch[39] Batch [990]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.094349,	
2017-06-16 00:34:51,443 Epoch[39] Batch [1000]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.094312,	
2017-06-16 00:34:59,323 Epoch[39] Batch [1010]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.094292,	
2017-06-16 00:35:07,275 Epoch[39] Batch [1020]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.094385,	
2017-06-16 00:35:14,547 Epoch[39] Batch [1030]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.094362,	
2017-06-16 00:35:22,578 Epoch[39] Batch [1040]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.094388,	
2017-06-16 00:35:30,396 Epoch[39] Batch [1050]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094321,	
2017-06-16 00:35:37,625 Epoch[39] Batch [1060]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.094301,	
2017-06-16 00:35:45,004 Epoch[39] Batch [1070]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.094279,	
2017-06-16 00:35:52,636 Epoch[39] Batch [1080]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.094199,	
2017-06-16 00:36:00,837 Epoch[39] Batch [1090]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.094192,	
2017-06-16 00:36:07,638 Epoch[39] Batch [1100]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.094151,	
2017-06-16 00:36:14,842 Epoch[39] Batch [1110]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.094110,	
2017-06-16 00:36:22,831 Epoch[39] Batch [1120]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.094017,	
2017-06-16 00:36:29,738 Epoch[39] Batch [1130]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.093978,	
2017-06-16 00:36:37,891 Epoch[39] Batch [1140]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.093973,	
2017-06-16 00:36:45,211 Epoch[39] Batch [1150]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.094032,	
2017-06-16 00:36:51,805 Epoch[39] Batch [1160]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.094140,	
2017-06-16 00:37:00,626 Epoch[39] Batch [1170]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.094185,	
2017-06-16 00:37:08,423 Epoch[39] Batch [1180]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.094181,	
2017-06-16 00:37:16,068 Epoch[39] Batch [1190]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.094200,	
2017-06-16 00:37:23,981 Epoch[39] Batch [1200]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.094273,	
2017-06-16 00:37:32,354 Epoch[39] Batch [1210]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.094296,	
2017-06-16 00:37:40,417 Epoch[39] Batch [1220]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.094332,	
2017-06-16 00:37:47,163 Epoch[39] Batch [1230]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.094399,	
2017-06-16 00:37:55,098 Epoch[39] Batch [1240]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.094323,	
2017-06-16 00:38:02,763 Epoch[39] Batch [1250]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.094323,	
2017-06-16 00:38:10,262 Epoch[39] Batch [1260]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.094325,	
2017-06-16 00:38:17,170 Epoch[39] Batch [1270]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.094325,	
2017-06-16 00:38:24,771 Epoch[39] Batch [1280]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.094338,	
2017-06-16 00:38:32,935 Epoch[39] Batch [1290]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.094307,	
2017-06-16 00:38:39,838 Epoch[39] Batch [1300]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.094322,	
2017-06-16 00:38:47,095 Epoch[39] Batch [1310]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.094366,	
2017-06-16 00:38:54,598 Epoch[39] Batch [1320]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.094354,	
2017-06-16 00:39:02,510 Epoch[39] Batch [1330]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.094347,	
2017-06-16 00:39:10,415 Epoch[39] Batch [1340]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.094295,	
2017-06-16 00:39:18,076 Epoch[39] Batch [1350]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.094265,	
2017-06-16 00:39:24,851 Epoch[39] Batch [1360]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.094177,	
2017-06-16 00:39:32,246 Epoch[39] Batch [1370]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.094234,	
2017-06-16 00:39:40,680 Epoch[39] Batch [1380]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.094296,	
2017-06-16 00:39:47,650 Epoch[39] Batch [1390]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.094277,	
2017-06-16 00:39:55,960 Epoch[39] Batch [1400]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.094294,	
2017-06-16 00:40:02,637 Epoch[39] Batch [1410]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094274,	
2017-06-16 00:40:09,916 Epoch[39] Batch [1420]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.094237,	
2017-06-16 00:40:17,659 Epoch[39] Batch [1430]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.094156,	
2017-06-16 00:40:24,712 Epoch[39] Batch [1440]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.094457,	
2017-06-16 00:40:31,599 Epoch[39] Batch [1450]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.094463,	
2017-06-16 00:40:38,983 Epoch[39] Batch [1460]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.094605,	
2017-06-16 00:40:46,937 Epoch[39] Batch [1470]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.094656,	
2017-06-16 00:40:55,168 Epoch[39] Batch [1480]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.094670,	
2017-06-16 00:40:58,833 Epoch[39] Train-FCNLogLoss=0.094670
2017-06-16 00:40:58,833 Epoch[39] Time cost=1118.838
2017-06-16 00:40:59,720 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0040.params"
2017-06-16 00:41:02,282 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0040.states"
2017-06-16 00:41:11,530 Epoch[40] Batch [10]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.112147,	
2017-06-16 00:41:19,509 Epoch[40] Batch [20]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.106855,	
2017-06-16 00:41:27,645 Epoch[40] Batch [30]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.102215,	
2017-06-16 00:41:35,034 Epoch[40] Batch [40]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.099502,	
2017-06-16 00:41:42,355 Epoch[40] Batch [50]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.099048,	
2017-06-16 00:41:49,380 Epoch[40] Batch [60]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.097940,	
2017-06-16 00:41:56,723 Epoch[40] Batch [70]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097800,	
2017-06-16 00:42:03,754 Epoch[40] Batch [80]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.097534,	
2017-06-16 00:42:09,335 Epoch[40] Batch [90]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.096476,	
2017-06-16 00:42:17,521 Epoch[40] Batch [100]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.095168,	
2017-06-16 00:42:24,565 Epoch[40] Batch [110]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.094992,	
2017-06-16 00:42:32,028 Epoch[40] Batch [120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094687,	
2017-06-16 00:42:41,108 Epoch[40] Batch [130]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.093716,	
2017-06-16 00:42:47,397 Epoch[40] Batch [140]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.093810,	
2017-06-16 00:42:54,795 Epoch[40] Batch [150]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.093892,	
2017-06-16 00:43:02,092 Epoch[40] Batch [160]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.094803,	
2017-06-16 00:43:08,446 Epoch[40] Batch [170]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.095084,	
2017-06-16 00:43:16,346 Epoch[40] Batch [180]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.094786,	
2017-06-16 00:43:23,684 Epoch[40] Batch [190]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.094306,	
2017-06-16 00:43:31,290 Epoch[40] Batch [200]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.094261,	
2017-06-16 00:43:38,394 Epoch[40] Batch [210]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094214,	
2017-06-16 00:43:46,579 Epoch[40] Batch [220]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.094665,	
2017-06-16 00:43:54,068 Epoch[40] Batch [230]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.094672,	
2017-06-16 00:44:00,379 Epoch[40] Batch [240]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.094620,	
2017-06-16 00:44:06,781 Epoch[40] Batch [250]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.094422,	
2017-06-16 00:44:14,033 Epoch[40] Batch [260]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.094098,	
2017-06-16 00:44:21,843 Epoch[40] Batch [270]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094245,	
2017-06-16 00:44:30,917 Epoch[40] Batch [280]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.094227,	
2017-06-16 00:44:39,512 Epoch[40] Batch [290]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.093967,	
2017-06-16 00:44:47,028 Epoch[40] Batch [300]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.093512,	
2017-06-16 00:44:53,932 Epoch[40] Batch [310]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.093439,	
2017-06-16 00:45:01,117 Epoch[40] Batch [320]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.093408,	
2017-06-16 00:45:08,876 Epoch[40] Batch [330]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.093104,	
2017-06-16 00:45:16,735 Epoch[40] Batch [340]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.093074,	
2017-06-16 00:45:23,809 Epoch[40] Batch [350]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.093013,	
2017-06-16 00:45:31,288 Epoch[40] Batch [360]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.093222,	
2017-06-16 00:45:39,479 Epoch[40] Batch [370]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.092859,	
2017-06-16 00:45:46,285 Epoch[40] Batch [380]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.093174,	
2017-06-16 00:45:54,352 Epoch[40] Batch [390]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.093079,	
2017-06-16 00:46:02,236 Epoch[40] Batch [400]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.093392,	
2017-06-16 00:46:09,087 Epoch[40] Batch [410]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.093439,	
2017-06-16 00:46:16,008 Epoch[40] Batch [420]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.093438,	
2017-06-16 00:46:23,380 Epoch[40] Batch [430]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.093401,	
2017-06-16 00:46:30,351 Epoch[40] Batch [440]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.093253,	
2017-06-16 00:46:39,059 Epoch[40] Batch [450]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.093323,	
2017-06-16 00:46:47,002 Epoch[40] Batch [460]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.093534,	
2017-06-16 00:46:54,462 Epoch[40] Batch [470]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.093648,	
2017-06-16 00:47:02,187 Epoch[40] Batch [480]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.093620,	
2017-06-16 00:47:09,625 Epoch[40] Batch [490]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.093622,	
2017-06-16 00:47:17,832 Epoch[40] Batch [500]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.093515,	
2017-06-16 00:47:24,772 Epoch[40] Batch [510]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.093511,	
2017-06-16 00:47:31,451 Update[60000]: Change learning rate to 5.00000e-05
2017-06-16 00:47:32,547 Epoch[40] Batch [520]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.093619,	
2017-06-16 00:47:39,461 Epoch[40] Batch [530]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.093705,	
2017-06-16 00:47:46,305 Epoch[40] Batch [540]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.093571,	
2017-06-16 00:47:53,347 Epoch[40] Batch [550]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.093609,	
2017-06-16 00:48:01,447 Epoch[40] Batch [560]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.093602,	
2017-06-16 00:48:08,908 Epoch[40] Batch [570]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.093535,	
2017-06-16 00:48:15,811 Epoch[40] Batch [580]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.093488,	
2017-06-16 00:48:23,380 Epoch[40] Batch [590]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.093417,	
2017-06-16 00:48:30,657 Epoch[40] Batch [600]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.093332,	
2017-06-16 00:48:39,476 Epoch[40] Batch [610]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.093260,	
2017-06-16 00:48:47,358 Epoch[40] Batch [620]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.093339,	
2017-06-16 00:48:55,395 Epoch[40] Batch [630]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.093339,	
2017-06-16 00:49:02,161 Epoch[40] Batch [640]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.093307,	
2017-06-16 00:49:10,801 Epoch[40] Batch [650]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.093162,	
2017-06-16 00:49:18,589 Epoch[40] Batch [660]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.093157,	
2017-06-16 00:49:25,816 Epoch[40] Batch [670]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.093176,	
2017-06-16 00:49:33,110 Epoch[40] Batch [680]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.092968,	
2017-06-16 00:49:40,962 Epoch[40] Batch [690]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.092917,	
2017-06-16 00:49:47,414 Epoch[40] Batch [700]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.092824,	
2017-06-16 00:49:54,660 Epoch[40] Batch [710]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.092753,	
2017-06-16 00:50:02,731 Epoch[40] Batch [720]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.092618,	
2017-06-16 00:50:10,371 Epoch[40] Batch [730]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.092640,	
2017-06-16 00:50:17,239 Epoch[40] Batch [740]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.092658,	
2017-06-16 00:50:24,607 Epoch[40] Batch [750]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.092601,	
2017-06-16 00:50:32,327 Epoch[40] Batch [760]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.092508,	
2017-06-16 00:50:40,058 Epoch[40] Batch [770]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.092447,	
2017-06-16 00:50:48,095 Epoch[40] Batch [780]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.092494,	
2017-06-16 00:50:55,502 Epoch[40] Batch [790]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.092445,	
2017-06-16 00:51:03,694 Epoch[40] Batch [800]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.092451,	
2017-06-16 00:51:11,364 Epoch[40] Batch [810]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.092288,	
2017-06-16 00:51:19,095 Epoch[40] Batch [820]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.092317,	
2017-06-16 00:51:26,440 Epoch[40] Batch [830]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.092294,	
2017-06-16 00:51:34,578 Epoch[40] Batch [840]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.092220,	
2017-06-16 00:51:41,890 Epoch[40] Batch [850]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.092057,	
2017-06-16 00:51:48,617 Epoch[40] Batch [860]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.092032,	
2017-06-16 00:51:55,155 Epoch[40] Batch [870]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.091944,	
2017-06-16 00:52:01,575 Epoch[40] Batch [880]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.091907,	
2017-06-16 00:52:09,658 Epoch[40] Batch [890]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.091973,	
2017-06-16 00:52:17,716 Epoch[40] Batch [900]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.092061,	
2017-06-16 00:52:24,425 Epoch[40] Batch [910]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.092006,	
2017-06-16 00:52:31,335 Epoch[40] Batch [920]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.092046,	
2017-06-16 00:52:38,328 Epoch[40] Batch [930]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.092074,	
2017-06-16 00:52:45,369 Epoch[40] Batch [940]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.092098,	
2017-06-16 00:52:52,952 Epoch[40] Batch [950]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.091992,	
2017-06-16 00:53:01,180 Epoch[40] Batch [960]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.092004,	
2017-06-16 00:53:08,661 Epoch[40] Batch [970]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.091890,	
2017-06-16 00:53:16,123 Epoch[40] Batch [980]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.091841,	
2017-06-16 00:53:23,434 Epoch[40] Batch [990]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.091814,	
2017-06-16 00:53:30,340 Epoch[40] Batch [1000]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.091735,	
2017-06-16 00:53:38,121 Epoch[40] Batch [1010]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.091616,	
2017-06-16 00:53:44,990 Epoch[40] Batch [1020]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.091547,	
2017-06-16 00:53:53,248 Epoch[40] Batch [1030]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.091538,	
2017-06-16 00:54:01,425 Epoch[40] Batch [1040]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.091461,	
2017-06-16 00:54:08,563 Epoch[40] Batch [1050]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.091423,	
2017-06-16 00:54:17,175 Epoch[40] Batch [1060]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.091460,	
2017-06-16 00:54:23,867 Epoch[40] Batch [1070]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.091347,	
2017-06-16 00:54:30,632 Epoch[40] Batch [1080]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.091292,	
2017-06-16 00:54:38,988 Epoch[40] Batch [1090]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.091284,	
2017-06-16 00:54:47,244 Epoch[40] Batch [1100]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.091284,	
2017-06-16 00:54:54,901 Epoch[40] Batch [1110]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.091319,	
2017-06-16 00:55:02,209 Epoch[40] Batch [1120]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.091285,	
2017-06-16 00:55:09,655 Epoch[40] Batch [1130]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-16 00:55:17,607 Epoch[40] Batch [1140]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.091277,	
2017-06-16 00:55:25,637 Epoch[40] Batch [1150]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.091335,	
2017-06-16 00:55:33,755 Epoch[40] Batch [1160]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.091297,	
2017-06-16 00:55:40,690 Epoch[40] Batch [1170]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.091336,	
2017-06-16 00:55:48,357 Epoch[40] Batch [1180]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.091349,	
2017-06-16 00:55:56,234 Epoch[40] Batch [1190]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.091304,	
2017-06-16 00:56:03,593 Epoch[40] Batch [1200]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.091387,	
2017-06-16 00:56:11,043 Epoch[40] Batch [1210]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.091357,	
2017-06-16 00:56:17,806 Epoch[40] Batch [1220]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.091338,	
2017-06-16 00:56:25,239 Epoch[40] Batch [1230]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.091296,	
2017-06-16 00:56:32,863 Epoch[40] Batch [1240]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.091170,	
2017-06-16 00:56:40,721 Epoch[40] Batch [1250]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.091187,	
2017-06-16 00:56:49,623 Epoch[40] Batch [1260]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.091193,	
2017-06-16 00:56:57,263 Epoch[40] Batch [1270]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.091261,	
2017-06-16 00:57:04,990 Epoch[40] Batch [1280]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.091291,	
2017-06-16 00:57:13,518 Epoch[40] Batch [1290]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.091225,	
2017-06-16 00:57:21,870 Epoch[40] Batch [1300]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.091238,	
2017-06-16 00:57:28,833 Epoch[40] Batch [1310]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.091179,	
2017-06-16 00:57:36,302 Epoch[40] Batch [1320]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.091177,	
2017-06-16 00:57:43,786 Epoch[40] Batch [1330]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.091148,	
2017-06-16 00:57:50,723 Epoch[40] Batch [1340]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.091134,	
2017-06-16 00:57:57,638 Epoch[40] Batch [1350]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.091065,	
2017-06-16 00:58:05,427 Epoch[40] Batch [1360]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.091094,	
2017-06-16 00:58:13,138 Epoch[40] Batch [1370]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.091018,	
2017-06-16 00:58:21,218 Epoch[40] Batch [1380]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.090990,	
2017-06-16 00:58:28,887 Epoch[40] Batch [1390]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.090985,	
2017-06-16 00:58:36,475 Epoch[40] Batch [1400]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.091033,	
2017-06-16 00:58:44,272 Epoch[40] Batch [1410]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.091049,	
2017-06-16 00:58:51,799 Epoch[40] Batch [1420]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.091099,	
2017-06-16 00:59:00,568 Epoch[40] Batch [1430]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.091136,	
2017-06-16 00:59:08,101 Epoch[40] Batch [1440]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.091130,	
2017-06-16 00:59:16,430 Epoch[40] Batch [1450]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.091103,	
2017-06-16 00:59:23,800 Epoch[40] Batch [1460]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.091106,	
2017-06-16 00:59:31,520 Epoch[40] Batch [1470]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.091061,	
2017-06-16 00:59:39,199 Epoch[40] Batch [1480]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.090983,	
2017-06-16 00:59:43,481 Epoch[40] Train-FCNLogLoss=0.090956
2017-06-16 00:59:43,481 Epoch[40] Time cost=1121.199
2017-06-16 00:59:44,279 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0041.params"
2017-06-16 00:59:46,650 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0041.states"
2017-06-16 00:59:54,051 Epoch[41] Batch [10]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.081188,	
2017-06-16 01:00:01,578 Epoch[41] Batch [20]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086159,	
2017-06-16 01:00:08,903 Epoch[41] Batch [30]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.084428,	
2017-06-16 01:00:16,050 Epoch[41] Batch [40]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.085062,	
2017-06-16 01:00:22,855 Epoch[41] Batch [50]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086947,	
2017-06-16 01:00:31,148 Epoch[41] Batch [60]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.085920,	
2017-06-16 01:00:37,872 Epoch[41] Batch [70]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.084640,	
2017-06-16 01:00:44,219 Epoch[41] Batch [80]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.084770,	
2017-06-16 01:00:50,727 Epoch[41] Batch [90]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.085654,	
2017-06-16 01:00:57,496 Epoch[41] Batch [100]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.084997,	
2017-06-16 01:01:03,975 Epoch[41] Batch [110]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.085017,	
2017-06-16 01:01:11,951 Epoch[41] Batch [120]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.085062,	
2017-06-16 01:01:19,431 Epoch[41] Batch [130]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.085072,	
2017-06-16 01:01:25,970 Epoch[41] Batch [140]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.085358,	
2017-06-16 01:01:34,122 Epoch[41] Batch [150]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.085892,	
2017-06-16 01:01:41,478 Epoch[41] Batch [160]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.086181,	
2017-06-16 01:01:48,370 Epoch[41] Batch [170]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086485,	
2017-06-16 01:01:55,311 Epoch[41] Batch [180]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.086542,	
2017-06-16 01:02:02,124 Epoch[41] Batch [190]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087076,	
2017-06-16 01:02:10,078 Epoch[41] Batch [200]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087125,	
2017-06-16 01:02:17,172 Epoch[41] Batch [210]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087271,	
2017-06-16 01:02:23,580 Epoch[41] Batch [220]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.086928,	
2017-06-16 01:02:30,860 Epoch[41] Batch [230]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086920,	
2017-06-16 01:02:39,365 Epoch[41] Batch [240]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.087391,	
2017-06-16 01:02:46,926 Epoch[41] Batch [250]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.087523,	
2017-06-16 01:02:54,516 Epoch[41] Batch [260]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.087640,	
2017-06-16 01:03:01,580 Epoch[41] Batch [270]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087730,	
2017-06-16 01:03:08,129 Epoch[41] Batch [280]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-16 01:03:16,067 Epoch[41] Batch [290]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.088153,	
2017-06-16 01:03:23,398 Epoch[41] Batch [300]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.088452,	
2017-06-16 01:03:31,004 Epoch[41] Batch [310]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-16 01:03:38,094 Epoch[41] Batch [320]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088428,	
2017-06-16 01:03:44,746 Epoch[41] Batch [330]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088279,	
2017-06-16 01:03:51,039 Epoch[41] Batch [340]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.088215,	
2017-06-16 01:03:58,179 Epoch[41] Batch [350]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088338,	
2017-06-16 01:04:04,454 Epoch[41] Batch [360]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.088327,	
2017-06-16 01:04:12,056 Epoch[41] Batch [370]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-16 01:04:18,385 Epoch[41] Batch [380]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088384,	
2017-06-16 01:04:24,510 Epoch[41] Batch [390]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-16 01:04:31,127 Epoch[41] Batch [400]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088682,	
2017-06-16 01:04:37,635 Epoch[41] Batch [410]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.088581,	
2017-06-16 01:04:45,749 Epoch[41] Batch [420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088547,	
2017-06-16 01:04:52,735 Epoch[41] Batch [430]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.088459,	
2017-06-16 01:04:59,759 Epoch[41] Batch [440]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088888,	
2017-06-16 01:05:06,458 Epoch[41] Batch [450]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.089033,	
2017-06-16 01:05:13,308 Epoch[41] Batch [460]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.089113,	
2017-06-16 01:05:19,595 Epoch[41] Batch [470]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.089144,	
2017-06-16 01:05:26,359 Epoch[41] Batch [480]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.089287,	
2017-06-16 01:05:33,756 Epoch[41] Batch [490]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.089252,	
2017-06-16 01:05:41,352 Epoch[41] Batch [500]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.089043,	
2017-06-16 01:05:48,048 Epoch[41] Batch [510]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.089091,	
2017-06-16 01:05:54,936 Epoch[41] Batch [520]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.089343,	
2017-06-16 01:06:01,926 Epoch[41] Batch [530]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.089327,	
2017-06-16 01:06:09,443 Epoch[41] Batch [540]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.089381,	
2017-06-16 01:06:16,445 Epoch[41] Batch [550]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.089329,	
2017-06-16 01:06:24,925 Epoch[41] Batch [560]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.089278,	
2017-06-16 01:06:32,063 Epoch[41] Batch [570]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.089468,	
2017-06-16 01:06:39,307 Epoch[41] Batch [580]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.089525,	
2017-06-16 01:06:46,410 Epoch[41] Batch [590]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.089511,	
2017-06-16 01:06:53,028 Epoch[41] Batch [600]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-16 01:07:02,440 Epoch[41] Batch [610]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.089477,	
2017-06-16 01:07:10,072 Epoch[41] Batch [620]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.089443,	
2017-06-16 01:07:17,593 Epoch[41] Batch [630]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.089379,	
2017-06-16 01:07:24,869 Epoch[41] Batch [640]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.089372,	
2017-06-16 01:07:32,086 Epoch[41] Batch [650]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.089415,	
2017-06-16 01:07:39,668 Epoch[41] Batch [660]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.089572,	
2017-06-16 01:07:46,978 Epoch[41] Batch [670]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.089385,	
2017-06-16 01:07:55,457 Epoch[41] Batch [680]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-16 01:08:02,095 Epoch[41] Batch [690]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.089596,	
2017-06-16 01:08:09,007 Epoch[41] Batch [700]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.089569,	
2017-06-16 01:08:15,773 Epoch[41] Batch [710]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.089601,	
2017-06-16 01:08:24,514 Epoch[41] Batch [720]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.089558,	
2017-06-16 01:08:31,429 Epoch[41] Batch [730]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.089625,	
2017-06-16 01:08:38,800 Epoch[41] Batch [740]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.089642,	
2017-06-16 01:08:45,846 Epoch[41] Batch [750]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.089730,	
2017-06-16 01:08:52,355 Epoch[41] Batch [760]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.089704,	
2017-06-16 01:08:59,502 Epoch[41] Batch [770]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-16 01:09:06,304 Epoch[41] Batch [780]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.089721,	
2017-06-16 01:09:14,003 Epoch[41] Batch [790]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089679,	
2017-06-16 01:09:21,356 Epoch[41] Batch [800]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.089522,	
2017-06-16 01:09:28,946 Epoch[41] Batch [810]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.089401,	
2017-06-16 01:09:36,808 Epoch[41] Batch [820]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.089404,	
2017-06-16 01:09:44,116 Epoch[41] Batch [830]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.089314,	
2017-06-16 01:09:52,036 Epoch[41] Batch [840]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.089298,	
2017-06-16 01:09:59,204 Epoch[41] Batch [850]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.089363,	
2017-06-16 01:10:07,201 Epoch[41] Batch [860]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089451,	
2017-06-16 01:10:15,154 Epoch[41] Batch [870]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.089389,	
2017-06-16 01:10:22,684 Epoch[41] Batch [880]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.089405,	
2017-06-16 01:10:31,528 Epoch[41] Batch [890]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.089431,	
2017-06-16 01:10:38,294 Epoch[41] Batch [900]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.089336,	
2017-06-16 01:10:44,726 Epoch[41] Batch [910]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.089335,	
2017-06-16 01:10:52,430 Epoch[41] Batch [920]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089371,	
2017-06-16 01:10:59,215 Epoch[41] Batch [930]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.089419,	
2017-06-16 01:11:06,964 Epoch[41] Batch [940]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089482,	
2017-06-16 01:11:13,941 Epoch[41] Batch [950]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.089351,	
2017-06-16 01:11:20,741 Epoch[41] Batch [960]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-16 01:11:28,439 Epoch[41] Batch [970]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089506,	
2017-06-16 01:11:36,724 Epoch[41] Batch [980]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.089446,	
2017-06-16 01:11:44,687 Epoch[41] Batch [990]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089516,	
2017-06-16 01:11:52,271 Epoch[41] Batch [1000]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.089409,	
2017-06-16 01:11:59,432 Epoch[41] Batch [1010]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.089381,	
2017-06-16 01:12:06,533 Epoch[41] Batch [1020]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.089336,	
2017-06-16 01:12:15,926 Epoch[41] Batch [1030]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.089239,	
2017-06-16 01:12:22,955 Epoch[41] Batch [1040]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.089232,	
2017-06-16 01:12:30,360 Epoch[41] Batch [1050]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.089147,	
2017-06-16 01:12:37,563 Epoch[41] Batch [1060]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.089075,	
2017-06-16 01:12:45,653 Epoch[41] Batch [1070]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.089106,	
2017-06-16 01:12:52,958 Epoch[41] Batch [1080]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.089105,	
2017-06-16 01:12:58,960 Epoch[41] Batch [1090]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.089088,	
2017-06-16 01:13:06,979 Epoch[41] Batch [1100]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.089067,	
2017-06-16 01:13:14,315 Epoch[41] Batch [1110]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.089143,	
2017-06-16 01:13:21,448 Epoch[41] Batch [1120]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.089151,	
2017-06-16 01:13:29,319 Epoch[41] Batch [1130]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.089102,	
2017-06-16 01:13:36,912 Epoch[41] Batch [1140]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.089110,	
2017-06-16 01:13:45,596 Epoch[41] Batch [1150]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.089169,	
2017-06-16 01:13:52,982 Epoch[41] Batch [1160]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.089227,	
2017-06-16 01:14:00,176 Epoch[41] Batch [1170]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089257,	
2017-06-16 01:14:07,967 Epoch[41] Batch [1180]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089251,	
2017-06-16 01:14:15,533 Epoch[41] Batch [1190]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.089246,	
2017-06-16 01:14:23,359 Epoch[41] Batch [1200]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089240,	
2017-06-16 01:14:31,632 Epoch[41] Batch [1210]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.089185,	
2017-06-16 01:14:38,748 Epoch[41] Batch [1220]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.089206,	
2017-06-16 01:14:46,396 Epoch[41] Batch [1230]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.089181,	
2017-06-16 01:14:53,718 Epoch[41] Batch [1240]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.089219,	
2017-06-16 01:15:01,148 Epoch[41] Batch [1250]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.089173,	
2017-06-16 01:15:08,243 Epoch[41] Batch [1260]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.089138,	
2017-06-16 01:15:17,212 Epoch[41] Batch [1270]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.089126,	
2017-06-16 01:15:24,758 Epoch[41] Batch [1280]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.089129,	
2017-06-16 01:15:31,904 Epoch[41] Batch [1290]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.089085,	
2017-06-16 01:15:38,774 Epoch[41] Batch [1300]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.089107,	
2017-06-16 01:15:47,808 Epoch[41] Batch [1310]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.089088,	
2017-06-16 01:15:54,759 Epoch[41] Batch [1320]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.089045,	
2017-06-16 01:16:02,775 Epoch[41] Batch [1330]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.089075,	
2017-06-16 01:16:10,995 Epoch[41] Batch [1340]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.089023,	
2017-06-16 01:16:19,767 Epoch[41] Batch [1350]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.089058,	
2017-06-16 01:16:27,210 Epoch[41] Batch [1360]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.089093,	
2017-06-16 01:16:34,948 Epoch[41] Batch [1370]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.089115,	
2017-06-16 01:16:42,568 Epoch[41] Batch [1380]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.089135,	
2017-06-16 01:16:49,862 Epoch[41] Batch [1390]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.089089,	
2017-06-16 01:16:56,791 Epoch[41] Batch [1400]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.089066,	
2017-06-16 01:17:04,261 Epoch[41] Batch [1410]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.089021,	
2017-06-16 01:17:12,926 Epoch[41] Batch [1420]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.089140,	
2017-06-16 01:17:20,754 Epoch[41] Batch [1430]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089210,	
2017-06-16 01:17:28,007 Epoch[41] Batch [1440]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.089227,	
2017-06-16 01:17:35,806 Epoch[41] Batch [1450]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089260,	
2017-06-16 01:17:43,718 Epoch[41] Batch [1460]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.089252,	
2017-06-16 01:17:52,578 Epoch[41] Batch [1470]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.089263,	
2017-06-16 01:18:00,214 Epoch[41] Batch [1480]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.089277,	
2017-06-16 01:18:05,334 Epoch[41] Train-FCNLogLoss=0.089256
2017-06-16 01:18:05,334 Epoch[41] Time cost=1098.684
2017-06-16 01:18:06,052 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0042.params"
2017-06-16 01:18:08,528 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0042.states"
2017-06-16 01:18:14,801 Epoch[42] Batch [10]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090764,	
2017-06-16 01:18:21,722 Epoch[42] Batch [20]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.090208,	
2017-06-16 01:18:27,491 Epoch[42] Batch [30]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.089648,	
2017-06-16 01:18:36,036 Epoch[42] Batch [40]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.088193,	
2017-06-16 01:18:42,320 Epoch[42] Batch [50]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.091082,	
2017-06-16 01:18:49,461 Epoch[42] Batch [60]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.090252,	
2017-06-16 01:18:56,636 Epoch[42] Batch [70]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.089402,	
2017-06-16 01:19:03,502 Epoch[42] Batch [80]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.089140,	
2017-06-16 01:19:10,605 Epoch[42] Batch [90]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.089237,	
2017-06-16 01:19:17,771 Epoch[42] Batch [100]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.089103,	
2017-06-16 01:19:25,886 Epoch[42] Batch [110]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089269,	
2017-06-16 01:19:33,342 Epoch[42] Batch [120]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.089784,	
2017-06-16 01:19:40,551 Epoch[42] Batch [130]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.089222,	
2017-06-16 01:19:48,550 Epoch[42] Batch [140]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089126,	
2017-06-16 01:19:55,577 Epoch[42] Batch [150]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.089451,	
2017-06-16 01:20:02,509 Epoch[42] Batch [160]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.089312,	
2017-06-16 01:20:10,452 Epoch[42] Batch [170]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.089351,	
2017-06-16 01:20:17,030 Epoch[42] Batch [180]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.089709,	
2017-06-16 01:20:25,460 Epoch[42] Batch [190]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.089442,	
2017-06-16 01:20:33,018 Epoch[42] Batch [200]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.091154,	
2017-06-16 01:20:40,143 Epoch[42] Batch [210]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.091396,	
2017-06-16 01:20:46,983 Epoch[42] Batch [220]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.091599,	
2017-06-16 01:20:54,797 Epoch[42] Batch [230]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.091312,	
2017-06-16 01:21:02,260 Epoch[42] Batch [240]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.091227,	
2017-06-16 01:21:09,273 Epoch[42] Batch [250]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.091300,	
2017-06-16 01:21:16,604 Epoch[42] Batch [260]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.091215,	
2017-06-16 01:21:24,172 Epoch[42] Batch [270]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.090924,	
2017-06-16 01:21:31,607 Epoch[42] Batch [280]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.090735,	
2017-06-16 01:21:38,933 Epoch[42] Batch [290]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.090679,	
2017-06-16 01:21:45,975 Epoch[42] Batch [300]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.090245,	
2017-06-16 01:21:52,871 Epoch[42] Batch [310]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.090237,	
2017-06-16 01:22:00,571 Epoch[42] Batch [320]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.090338,	
2017-06-16 01:22:07,514 Epoch[42] Batch [330]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.090366,	
2017-06-16 01:22:14,693 Epoch[42] Batch [340]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.090444,	
2017-06-16 01:22:23,210 Epoch[42] Batch [350]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.090337,	
2017-06-16 01:22:31,395 Epoch[42] Batch [360]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.090305,	
2017-06-16 01:22:38,557 Epoch[42] Batch [370]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.090363,	
2017-06-16 01:22:45,570 Epoch[42] Batch [380]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.090363,	
2017-06-16 01:22:53,266 Epoch[42] Batch [390]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.090187,	
2017-06-16 01:23:00,220 Epoch[42] Batch [400]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.089891,	
2017-06-16 01:23:08,361 Epoch[42] Batch [410]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.089798,	
2017-06-16 01:23:15,499 Epoch[42] Batch [420]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.089633,	
2017-06-16 01:23:22,852 Epoch[42] Batch [430]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.089573,	
2017-06-16 01:23:30,146 Epoch[42] Batch [440]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.089510,	
2017-06-16 01:23:36,707 Epoch[42] Batch [450]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.089523,	
2017-06-16 01:23:44,963 Epoch[42] Batch [460]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.089526,	
2017-06-16 01:23:51,360 Epoch[42] Batch [470]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.089405,	
2017-06-16 01:23:58,746 Epoch[42] Batch [480]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.089554,	
2017-06-16 01:24:06,857 Epoch[42] Batch [490]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089451,	
2017-06-16 01:24:14,402 Epoch[42] Batch [500]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.089444,	
2017-06-16 01:24:22,742 Epoch[42] Batch [510]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.089451,	
2017-06-16 01:24:30,749 Epoch[42] Batch [520]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089379,	
2017-06-16 01:24:38,420 Epoch[42] Batch [530]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.089225,	
2017-06-16 01:24:45,927 Epoch[42] Batch [540]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.089021,	
2017-06-16 01:24:53,634 Epoch[42] Batch [550]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089169,	
2017-06-16 01:25:00,953 Epoch[42] Batch [560]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.089098,	
2017-06-16 01:25:07,992 Epoch[42] Batch [570]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.089022,	
2017-06-16 01:25:14,643 Epoch[42] Batch [580]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088991,	
2017-06-16 01:25:22,923 Epoch[42] Batch [590]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.088957,	
2017-06-16 01:25:30,102 Epoch[42] Batch [600]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088895,	
2017-06-16 01:25:37,218 Epoch[42] Batch [610]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088981,	
2017-06-16 01:25:44,827 Epoch[42] Batch [620]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.089075,	
2017-06-16 01:25:51,854 Epoch[42] Batch [630]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088908,	
2017-06-16 01:25:59,504 Epoch[42] Batch [640]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088774,	
2017-06-16 01:26:06,654 Epoch[42] Batch [650]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088832,	
2017-06-16 01:26:13,951 Epoch[42] Batch [660]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088896,	
2017-06-16 01:26:21,963 Epoch[42] Batch [670]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.088813,	
2017-06-16 01:26:29,872 Epoch[42] Batch [680]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.088813,	
2017-06-16 01:26:37,050 Epoch[42] Batch [690]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088880,	
2017-06-16 01:26:45,288 Epoch[42] Batch [700]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088751,	
2017-06-16 01:26:52,648 Epoch[42] Batch [710]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.088722,	
2017-06-16 01:27:01,186 Epoch[42] Batch [720]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.088711,	
2017-06-16 01:27:07,644 Epoch[42] Batch [730]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088656,	
2017-06-16 01:27:15,784 Epoch[42] Batch [740]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.088615,	
2017-06-16 01:27:23,317 Epoch[42] Batch [750]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.088517,	
2017-06-16 01:27:30,957 Epoch[42] Batch [760]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.088587,	
2017-06-16 01:27:38,683 Epoch[42] Batch [770]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.088628,	
2017-06-16 01:27:46,292 Epoch[42] Batch [780]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.088638,	
2017-06-16 01:27:53,846 Epoch[42] Batch [790]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.088470,	
2017-06-16 01:28:00,630 Epoch[42] Batch [800]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.088413,	
2017-06-16 01:28:07,210 Epoch[42] Batch [810]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088429,	
2017-06-16 01:28:14,507 Epoch[42] Batch [820]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-16 01:28:22,050 Epoch[42] Batch [830]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.088430,	
2017-06-16 01:28:28,787 Epoch[42] Batch [840]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.088524,	
2017-06-16 01:28:36,571 Epoch[42] Batch [850]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.088665,	
2017-06-16 01:28:43,792 Epoch[42] Batch [860]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.088581,	
2017-06-16 01:28:51,468 Epoch[42] Batch [870]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.088495,	
2017-06-16 01:28:58,887 Epoch[42] Batch [880]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.088528,	
2017-06-16 01:29:06,533 Epoch[42] Batch [890]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088559,	
2017-06-16 01:29:14,260 Epoch[42] Batch [900]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.088588,	
2017-06-16 01:29:21,556 Epoch[42] Batch [910]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088567,	
2017-06-16 01:29:28,559 Epoch[42] Batch [920]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-16 01:29:36,946 Epoch[42] Batch [930]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.088505,	
2017-06-16 01:29:44,554 Epoch[42] Batch [940]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.088557,	
2017-06-16 01:29:52,121 Epoch[42] Batch [950]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088684,	
2017-06-16 01:30:00,282 Epoch[42] Batch [960]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.088629,	
2017-06-16 01:30:07,226 Epoch[42] Batch [970]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.088592,	
2017-06-16 01:30:14,603 Epoch[42] Batch [980]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.088568,	
2017-06-16 01:30:21,443 Epoch[42] Batch [990]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088565,	
2017-06-16 01:30:29,534 Epoch[42] Batch [1000]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.088559,	
2017-06-16 01:30:38,109 Epoch[42] Batch [1010]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.088549,	
2017-06-16 01:30:46,701 Epoch[42] Batch [1020]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.088538,	
2017-06-16 01:30:54,148 Epoch[42] Batch [1030]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088557,	
2017-06-16 01:31:01,573 Epoch[42] Batch [1040]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.088516,	
2017-06-16 01:31:08,409 Epoch[42] Batch [1050]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088502,	
2017-06-16 01:31:16,053 Epoch[42] Batch [1060]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088484,	
2017-06-16 01:31:23,739 Epoch[42] Batch [1070]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088455,	
2017-06-16 01:31:30,553 Epoch[42] Batch [1080]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.088478,	
2017-06-16 01:31:38,350 Epoch[42] Batch [1090]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-16 01:31:46,349 Epoch[42] Batch [1100]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.088489,	
2017-06-16 01:31:54,048 Epoch[42] Batch [1110]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-16 01:32:02,332 Epoch[42] Batch [1120]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.088512,	
2017-06-16 01:32:09,196 Epoch[42] Batch [1130]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088526,	
2017-06-16 01:32:16,253 Epoch[42] Batch [1140]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.088516,	
2017-06-16 01:32:25,300 Epoch[42] Batch [1150]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.088429,	
2017-06-16 01:32:33,183 Epoch[42] Batch [1160]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.088482,	
2017-06-16 01:32:41,306 Epoch[42] Batch [1170]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-16 01:32:48,816 Epoch[42] Batch [1180]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088490,	
2017-06-16 01:32:56,797 Epoch[42] Batch [1190]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-16 01:33:04,423 Epoch[42] Batch [1200]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-16 01:33:11,710 Epoch[42] Batch [1210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.088486,	
2017-06-16 01:33:19,611 Epoch[42] Batch [1220]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.088485,	
2017-06-16 01:33:27,977 Epoch[42] Batch [1230]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.088501,	
2017-06-16 01:33:35,732 Epoch[42] Batch [1240]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088484,	
2017-06-16 01:33:44,286 Epoch[42] Batch [1250]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-16 01:33:51,833 Epoch[42] Batch [1260]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-16 01:33:59,423 Epoch[42] Batch [1270]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.088595,	
2017-06-16 01:34:06,879 Epoch[42] Batch [1280]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088544,	
2017-06-16 01:34:14,844 Epoch[42] Batch [1290]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.088566,	
2017-06-16 01:34:22,261 Epoch[42] Batch [1300]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-16 01:34:29,834 Epoch[42] Batch [1310]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-16 01:34:37,366 Epoch[42] Batch [1320]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.088641,	
2017-06-16 01:34:44,276 Epoch[42] Batch [1330]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088622,	
2017-06-16 01:34:50,786 Epoch[42] Batch [1340]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.088536,	
2017-06-16 01:34:58,145 Epoch[42] Batch [1350]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-16 01:35:06,016 Epoch[42] Batch [1360]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.088558,	
2017-06-16 01:35:13,202 Epoch[42] Batch [1370]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088505,	
2017-06-16 01:35:19,682 Epoch[42] Batch [1380]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088469,	
2017-06-16 01:35:27,434 Epoch[42] Batch [1390]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088426,	
2017-06-16 01:35:34,690 Epoch[42] Batch [1400]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.088407,	
2017-06-16 01:35:42,371 Epoch[42] Batch [1410]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.088445,	
2017-06-16 01:35:49,717 Epoch[42] Batch [1420]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.088427,	
2017-06-16 01:35:57,023 Epoch[42] Batch [1430]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-16 01:36:03,240 Epoch[42] Batch [1440]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.088447,	
2017-06-16 01:36:10,971 Epoch[42] Batch [1450]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.088495,	
2017-06-16 01:36:17,854 Epoch[42] Batch [1460]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.088490,	
2017-06-16 01:36:25,558 Epoch[42] Batch [1470]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.088431,	
2017-06-16 01:36:33,027 Epoch[42] Batch [1480]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.088427,	
2017-06-16 01:36:38,042 Epoch[42] Train-FCNLogLoss=0.088369
2017-06-16 01:36:38,042 Epoch[42] Time cost=1109.513
2017-06-16 01:36:38,779 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0043.params"
2017-06-16 01:36:40,941 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0043.states"
2017-06-16 01:36:49,559 Epoch[43] Batch [10]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.087265,	
2017-06-16 01:36:56,985 Epoch[43] Batch [20]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087822,	
2017-06-16 01:37:04,296 Epoch[43] Batch [30]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.087996,	
2017-06-16 01:37:11,033 Epoch[43] Batch [40]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.085172,	
2017-06-16 01:37:18,224 Epoch[43] Batch [50]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087228,	
2017-06-16 01:37:25,452 Epoch[43] Batch [60]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086582,	
2017-06-16 01:37:32,077 Epoch[43] Batch [70]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-16 01:37:39,067 Epoch[43] Batch [80]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087445,	
2017-06-16 01:37:46,488 Epoch[43] Batch [90]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087262,	
2017-06-16 01:37:54,312 Epoch[43] Batch [100]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.087076,	
2017-06-16 01:38:01,409 Epoch[43] Batch [110]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086553,	
2017-06-16 01:38:08,404 Epoch[43] Batch [120]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087085,	
2017-06-16 01:38:16,214 Epoch[43] Batch [130]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.086659,	
2017-06-16 01:38:24,317 Epoch[43] Batch [140]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.086846,	
2017-06-16 01:38:31,191 Epoch[43] Batch [150]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.086962,	
2017-06-16 01:38:37,989 Epoch[43] Batch [160]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087197,	
2017-06-16 01:38:45,054 Epoch[43] Batch [170]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087741,	
2017-06-16 01:38:51,591 Epoch[43] Batch [180]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087715,	
2017-06-16 01:38:58,507 Epoch[43] Batch [190]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087631,	
2017-06-16 01:39:06,406 Epoch[43] Batch [200]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087811,	
2017-06-16 01:39:13,325 Epoch[43] Batch [210]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087408,	
2017-06-16 01:39:20,446 Epoch[43] Batch [220]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-16 01:39:27,628 Epoch[43] Batch [230]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.087381,	
2017-06-16 01:39:34,696 Epoch[43] Batch [240]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-16 01:39:42,108 Epoch[43] Batch [250]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087357,	
2017-06-16 01:39:49,134 Epoch[43] Batch [260]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.087189,	
2017-06-16 01:39:56,317 Epoch[43] Batch [270]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.087164,	
2017-06-16 01:40:03,509 Epoch[43] Batch [280]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087035,	
2017-06-16 01:40:11,614 Epoch[43] Batch [290]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.087269,	
2017-06-16 01:40:18,469 Epoch[43] Batch [300]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.087293,	
2017-06-16 01:40:25,741 Epoch[43] Batch [310]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.087457,	
2017-06-16 01:40:33,601 Epoch[43] Batch [320]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-16 01:40:40,894 Epoch[43] Batch [330]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087576,	
2017-06-16 01:40:48,330 Epoch[43] Batch [340]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.087547,	
2017-06-16 01:40:55,586 Epoch[43] Batch [350]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087647,	
2017-06-16 01:41:02,830 Epoch[43] Batch [360]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087555,	
2017-06-16 01:41:10,140 Epoch[43] Batch [370]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.087985,	
2017-06-16 01:41:17,131 Epoch[43] Batch [380]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.088165,	
2017-06-16 01:41:24,279 Epoch[43] Batch [390]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088254,	
2017-06-16 01:41:31,465 Epoch[43] Batch [400]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088056,	
2017-06-16 01:41:39,114 Epoch[43] Batch [410]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087941,	
2017-06-16 01:41:46,845 Epoch[43] Batch [420]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087946,	
2017-06-16 01:41:54,793 Epoch[43] Batch [430]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.088140,	
2017-06-16 01:42:02,096 Epoch[43] Batch [440]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088098,	
2017-06-16 01:42:08,864 Epoch[43] Batch [450]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088289,	
2017-06-16 01:42:15,136 Epoch[43] Batch [460]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-16 01:42:21,931 Epoch[43] Batch [470]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.088058,	
2017-06-16 01:42:28,787 Epoch[43] Batch [480]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-16 01:42:36,136 Epoch[43] Batch [490]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.088033,	
2017-06-16 01:42:44,089 Epoch[43] Batch [500]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.088220,	
2017-06-16 01:42:50,697 Epoch[43] Batch [510]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088133,	
2017-06-16 01:42:57,926 Epoch[43] Batch [520]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.088037,	
2017-06-16 01:43:06,535 Epoch[43] Batch [530]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.087949,	
2017-06-16 01:43:13,900 Epoch[43] Batch [540]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088057,	
2017-06-16 01:43:22,032 Epoch[43] Batch [550]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.087961,	
2017-06-16 01:43:29,650 Epoch[43] Batch [560]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087972,	
2017-06-16 01:43:36,126 Epoch[43] Batch [570]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.087926,	
2017-06-16 01:43:42,908 Epoch[43] Batch [580]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087859,	
2017-06-16 01:43:50,256 Epoch[43] Batch [590]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.087874,	
2017-06-16 01:43:58,365 Epoch[43] Batch [600]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087892,	
2017-06-16 01:44:06,783 Epoch[43] Batch [610]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.087859,	
2017-06-16 01:44:15,247 Epoch[43] Batch [620]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.088024,	
2017-06-16 01:44:22,421 Epoch[43] Batch [630]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.087904,	
2017-06-16 01:44:29,444 Epoch[43] Batch [640]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087824,	
2017-06-16 01:44:37,579 Epoch[43] Batch [650]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.087737,	
2017-06-16 01:44:44,719 Epoch[43] Batch [660]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087627,	
2017-06-16 01:44:52,672 Epoch[43] Batch [670]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087608,	
2017-06-16 01:45:00,379 Epoch[43] Batch [680]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.087694,	
2017-06-16 01:45:07,386 Epoch[43] Batch [690]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.087807,	
2017-06-16 01:45:15,989 Epoch[43] Batch [700]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.087753,	
2017-06-16 01:45:23,244 Epoch[43] Batch [710]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087632,	
2017-06-16 01:45:30,711 Epoch[43] Batch [720]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.087566,	
2017-06-16 01:45:39,168 Epoch[43] Batch [730]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.087635,	
2017-06-16 01:45:47,341 Epoch[43] Batch [740]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.087655,	
2017-06-16 01:45:55,265 Epoch[43] Batch [750]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.087576,	
2017-06-16 01:46:03,381 Epoch[43] Batch [760]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087649,	
2017-06-16 01:46:11,017 Epoch[43] Batch [770]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.087628,	
2017-06-16 01:46:18,114 Epoch[43] Batch [780]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087708,	
2017-06-16 01:46:25,860 Epoch[43] Batch [790]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-16 01:46:32,682 Epoch[43] Batch [800]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.087718,	
2017-06-16 01:46:41,074 Epoch[43] Batch [810]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.087688,	
2017-06-16 01:46:50,095 Epoch[43] Batch [820]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.087663,	
2017-06-16 01:46:57,538 Epoch[43] Batch [830]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-16 01:47:05,575 Epoch[43] Batch [840]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.087817,	
2017-06-16 01:47:12,532 Epoch[43] Batch [850]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087845,	
2017-06-16 01:47:20,832 Epoch[43] Batch [860]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.087847,	
2017-06-16 01:47:28,944 Epoch[43] Batch [870]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087848,	
2017-06-16 01:47:35,172 Epoch[43] Batch [880]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087798,	
2017-06-16 01:47:42,821 Epoch[43] Batch [890]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087820,	
2017-06-16 01:47:50,405 Epoch[43] Batch [900]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.087851,	
2017-06-16 01:47:56,936 Epoch[43] Batch [910]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.087849,	
2017-06-16 01:48:03,451 Epoch[43] Batch [920]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.087924,	
2017-06-16 01:48:10,952 Epoch[43] Batch [930]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087875,	
2017-06-16 01:48:18,292 Epoch[43] Batch [940]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.087927,	
2017-06-16 01:48:26,148 Epoch[43] Batch [950]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087930,	
2017-06-16 01:48:33,993 Epoch[43] Batch [960]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087964,	
2017-06-16 01:48:41,645 Epoch[43] Batch [970]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088046,	
2017-06-16 01:48:49,135 Epoch[43] Batch [980]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.088016,	
2017-06-16 01:48:56,652 Epoch[43] Batch [990]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.088009,	
2017-06-16 01:49:04,251 Epoch[43] Batch [1000]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.088060,	
2017-06-16 01:49:12,855 Epoch[43] Batch [1010]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.088010,	
2017-06-16 01:49:20,342 Epoch[43] Batch [1020]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087950,	
2017-06-16 01:49:27,955 Epoch[43] Batch [1030]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087956,	
2017-06-16 01:49:35,827 Epoch[43] Batch [1040]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-16 01:49:43,122 Epoch[43] Batch [1050]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087931,	
2017-06-16 01:49:50,205 Epoch[43] Batch [1060]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087987,	
2017-06-16 01:49:57,719 Epoch[43] Batch [1070]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.088075,	
2017-06-16 01:50:05,694 Epoch[43] Batch [1080]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.088091,	
2017-06-16 01:50:12,192 Epoch[43] Batch [1090]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088116,	
2017-06-16 01:50:19,178 Epoch[43] Batch [1100]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.088094,	
2017-06-16 01:50:26,870 Epoch[43] Batch [1110]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088130,	
2017-06-16 01:50:34,331 Epoch[43] Batch [1120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-16 01:50:42,923 Epoch[43] Batch [1130]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.088172,	
2017-06-16 01:50:49,996 Epoch[43] Batch [1140]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088176,	
2017-06-16 01:50:56,980 Epoch[43] Batch [1150]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-16 01:51:04,045 Epoch[43] Batch [1160]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-16 01:51:11,533 Epoch[43] Batch [1170]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.088151,	
2017-06-16 01:51:20,111 Epoch[43] Batch [1180]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.088131,	
2017-06-16 01:51:26,802 Epoch[43] Batch [1190]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-16 01:51:34,497 Epoch[43] Batch [1200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088139,	
2017-06-16 01:51:41,781 Epoch[43] Batch [1210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-16 01:51:49,621 Epoch[43] Batch [1220]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087994,	
2017-06-16 01:51:57,083 Epoch[43] Batch [1230]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.087961,	
2017-06-16 01:52:05,551 Epoch[43] Batch [1240]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.087956,	
2017-06-16 01:52:12,617 Epoch[43] Batch [1250]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088034,	
2017-06-16 01:52:21,771 Epoch[43] Batch [1260]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.088068,	
2017-06-16 01:52:29,247 Epoch[43] Batch [1270]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-16 01:52:36,902 Epoch[43] Batch [1280]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088059,	
2017-06-16 01:52:44,008 Epoch[43] Batch [1290]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.088109,	
2017-06-16 01:52:53,136 Epoch[43] Batch [1300]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.088106,	
2017-06-16 01:53:00,494 Epoch[43] Batch [1310]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-16 01:53:08,757 Epoch[43] Batch [1320]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-16 01:53:14,765 Epoch[43] Batch [1330]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.088153,	
2017-06-16 01:53:21,393 Epoch[43] Batch [1340]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088181,	
2017-06-16 01:53:29,163 Epoch[43] Batch [1350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-16 01:53:36,335 Epoch[43] Batch [1360]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.088189,	
2017-06-16 01:53:44,888 Epoch[43] Batch [1370]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.088080,	
2017-06-16 01:53:52,372 Epoch[43] Batch [1380]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.088056,	
2017-06-16 01:53:59,493 Epoch[43] Batch [1390]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088038,	
2017-06-16 01:54:07,676 Epoch[43] Batch [1400]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.088038,	
2017-06-16 01:54:14,655 Epoch[43] Batch [1410]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.088145,	
2017-06-16 01:54:22,194 Epoch[43] Batch [1420]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.088112,	
2017-06-16 01:54:29,053 Epoch[43] Batch [1430]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088106,	
2017-06-16 01:54:36,526 Epoch[43] Batch [1440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-16 01:54:43,900 Epoch[43] Batch [1450]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.088143,	
2017-06-16 01:54:51,123 Epoch[43] Batch [1460]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.088170,	
2017-06-16 01:54:58,493 Epoch[43] Batch [1470]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088119,	
2017-06-16 01:55:04,902 Epoch[43] Batch [1480]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088085,	
2017-06-16 01:55:09,733 Epoch[43] Train-FCNLogLoss=0.088147
2017-06-16 01:55:09,733 Epoch[43] Time cost=1108.792
2017-06-16 01:55:10,838 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0044.params"
2017-06-16 01:55:13,195 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0044.states"
2017-06-16 01:55:20,704 Epoch[44] Batch [10]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.077350,	
2017-06-16 01:55:27,244 Epoch[44] Batch [20]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.080617,	
2017-06-16 01:55:33,479 Epoch[44] Batch [30]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.081966,	
2017-06-16 01:55:39,665 Epoch[44] Batch [40]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085057,	
2017-06-16 01:55:45,615 Epoch[44] Batch [50]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.085945,	
2017-06-16 01:55:53,180 Epoch[44] Batch [60]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.086508,	
2017-06-16 01:56:00,407 Epoch[44] Batch [70]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087293,	
2017-06-16 01:56:07,389 Epoch[44] Batch [80]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.087245,	
2017-06-16 01:56:13,960 Epoch[44] Batch [90]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.087935,	
2017-06-16 01:56:19,775 Epoch[44] Batch [100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087282,	
2017-06-16 01:56:27,230 Epoch[44] Batch [110]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087372,	
2017-06-16 01:56:32,857 Epoch[44] Batch [120]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-16 01:56:40,169 Epoch[44] Batch [130]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.089612,	
2017-06-16 01:56:47,830 Epoch[44] Batch [140]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.089501,	
2017-06-16 01:56:55,242 Epoch[44] Batch [150]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.089383,	
2017-06-16 01:57:02,788 Epoch[44] Batch [160]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.089616,	
2017-06-16 01:57:09,893 Epoch[44] Batch [170]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.089510,	
2017-06-16 01:57:17,693 Epoch[44] Batch [180]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.090024,	
2017-06-16 01:57:23,871 Epoch[44] Batch [190]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.090211,	
2017-06-16 01:57:30,893 Epoch[44] Batch [200]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.089740,	
2017-06-16 01:57:36,587 Epoch[44] Batch [210]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.089769,	
2017-06-16 01:57:43,561 Epoch[44] Batch [220]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.089901,	
2017-06-16 01:57:50,754 Epoch[44] Batch [230]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089844,	
2017-06-16 01:57:58,332 Epoch[44] Batch [240]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.089917,	
2017-06-16 01:58:05,406 Epoch[44] Batch [250]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.090350,	
2017-06-16 01:58:11,557 Epoch[44] Batch [260]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.090590,	
2017-06-16 01:58:19,320 Epoch[44] Batch [270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.090400,	
2017-06-16 01:58:26,670 Epoch[44] Batch [280]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.089898,	
2017-06-16 01:58:33,984 Epoch[44] Batch [290]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-16 01:58:40,380 Epoch[44] Batch [300]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.089386,	
2017-06-16 01:58:47,182 Epoch[44] Batch [310]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.089504,	
2017-06-16 01:58:54,016 Epoch[44] Batch [320]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.089448,	
2017-06-16 01:59:00,436 Epoch[44] Batch [330]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.089133,	
2017-06-16 01:59:08,307 Epoch[44] Batch [340]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.088881,	
2017-06-16 01:59:14,756 Epoch[44] Batch [350]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.089001,	
2017-06-16 01:59:22,455 Epoch[44] Batch [360]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088638,	
2017-06-16 01:59:28,068 Epoch[44] Batch [370]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.088443,	
2017-06-16 01:59:36,309 Epoch[44] Batch [380]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.088516,	
2017-06-16 01:59:42,524 Epoch[44] Batch [390]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088757,	
2017-06-16 01:59:49,698 Epoch[44] Batch [400]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.088790,	
2017-06-16 01:59:55,653 Epoch[44] Batch [410]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088811,	
2017-06-16 02:00:02,310 Epoch[44] Batch [420]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088697,	
2017-06-16 02:00:09,284 Epoch[44] Batch [430]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.088903,	
2017-06-16 02:00:15,397 Epoch[44] Batch [440]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088833,	
2017-06-16 02:00:21,995 Epoch[44] Batch [450]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088964,	
2017-06-16 02:00:29,896 Epoch[44] Batch [460]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.088973,	
2017-06-16 02:00:37,398 Epoch[44] Batch [470]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088846,	
2017-06-16 02:00:44,790 Epoch[44] Batch [480]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.088883,	
2017-06-16 02:00:52,203 Epoch[44] Batch [490]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.088747,	
2017-06-16 02:00:59,191 Epoch[44] Batch [500]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.088628,	
2017-06-16 02:01:06,951 Epoch[44] Batch [510]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-16 02:01:13,700 Epoch[44] Batch [520]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.088849,	
2017-06-16 02:01:19,930 Epoch[44] Batch [530]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.089167,	
2017-06-16 02:01:26,651 Epoch[44] Batch [540]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.089289,	
2017-06-16 02:01:33,510 Epoch[44] Batch [550]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.089200,	
2017-06-16 02:01:40,671 Epoch[44] Batch [560]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.089163,	
2017-06-16 02:01:48,940 Epoch[44] Batch [570]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.089017,	
2017-06-16 02:01:56,800 Epoch[44] Batch [580]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.088981,	
2017-06-16 02:02:03,772 Epoch[44] Batch [590]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.089008,	
2017-06-16 02:02:11,628 Epoch[44] Batch [600]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.088928,	
2017-06-16 02:02:18,807 Epoch[44] Batch [610]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088886,	
2017-06-16 02:02:26,119 Epoch[44] Batch [620]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.088904,	
2017-06-16 02:02:33,666 Epoch[44] Batch [630]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.088762,	
2017-06-16 02:02:40,061 Epoch[44] Batch [640]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-16 02:02:47,066 Epoch[44] Batch [650]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.088523,	
2017-06-16 02:02:53,991 Epoch[44] Batch [660]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088610,	
2017-06-16 02:03:01,174 Epoch[44] Batch [670]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088753,	
2017-06-16 02:03:07,773 Epoch[44] Batch [680]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088903,	
2017-06-16 02:03:13,848 Epoch[44] Batch [690]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.088989,	
2017-06-16 02:03:21,262 Epoch[44] Batch [700]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.088945,	
2017-06-16 02:03:27,950 Epoch[44] Batch [710]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088824,	
2017-06-16 02:03:35,176 Epoch[44] Batch [720]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.088829,	
2017-06-16 02:03:41,028 Epoch[44] Batch [730]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.088766,	
2017-06-16 02:03:48,739 Epoch[44] Batch [740]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.088731,	
2017-06-16 02:03:56,067 Epoch[44] Batch [750]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.088738,	
2017-06-16 02:04:03,217 Epoch[44] Batch [760]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088845,	
2017-06-16 02:04:10,634 Epoch[44] Batch [770]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.088719,	
2017-06-16 02:04:17,402 Epoch[44] Batch [780]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088879,	
2017-06-16 02:04:24,592 Epoch[44] Batch [790]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088899,	
2017-06-16 02:04:31,539 Epoch[44] Batch [800]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.088898,	
2017-06-16 02:04:38,661 Epoch[44] Batch [810]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088865,	
2017-06-16 02:04:45,121 Epoch[44] Batch [820]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088898,	
2017-06-16 02:04:52,755 Epoch[44] Batch [830]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.088821,	
2017-06-16 02:05:00,830 Epoch[44] Batch [840]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-16 02:05:08,288 Epoch[44] Batch [850]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-16 02:05:15,766 Epoch[44] Batch [860]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.088758,	
2017-06-16 02:05:22,215 Epoch[44] Batch [870]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088762,	
2017-06-16 02:05:29,389 Epoch[44] Batch [880]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.088757,	
2017-06-16 02:05:36,021 Epoch[44] Batch [890]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-16 02:05:43,522 Epoch[44] Batch [900]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088711,	
2017-06-16 02:05:51,380 Epoch[44] Batch [910]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.088741,	
2017-06-16 02:05:59,475 Epoch[44] Batch [920]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-16 02:06:06,973 Epoch[44] Batch [930]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.088674,	
2017-06-16 02:06:14,003 Epoch[44] Batch [940]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-16 02:06:21,507 Epoch[44] Batch [950]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088582,	
2017-06-16 02:06:29,100 Epoch[44] Batch [960]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.088625,	
2017-06-16 02:06:36,465 Epoch[44] Batch [970]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088671,	
2017-06-16 02:06:44,092 Epoch[44] Batch [980]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.088685,	
2017-06-16 02:06:51,844 Epoch[44] Batch [990]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-16 02:06:59,194 Epoch[44] Batch [1000]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.088707,	
2017-06-16 02:07:04,087 Epoch[44] Batch [1010]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088734,	
2017-06-16 02:07:12,079 Epoch[44] Batch [1020]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-16 02:07:19,468 Epoch[44] Batch [1030]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.088794,	
2017-06-16 02:07:26,582 Epoch[44] Batch [1040]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088759,	
2017-06-16 02:07:33,315 Epoch[44] Batch [1050]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.088653,	
2017-06-16 02:07:40,943 Epoch[44] Batch [1060]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.088714,	
2017-06-16 02:07:48,456 Epoch[44] Batch [1070]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.088751,	
2017-06-16 02:07:56,253 Epoch[44] Batch [1080]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.088652,	
2017-06-16 02:08:03,569 Epoch[44] Batch [1090]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.088726,	
2017-06-16 02:08:09,993 Epoch[44] Batch [1100]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088717,	
2017-06-16 02:08:17,206 Epoch[44] Batch [1110]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.088705,	
2017-06-16 02:08:24,342 Epoch[44] Batch [1120]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.088719,	
2017-06-16 02:08:32,455 Epoch[44] Batch [1130]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088649,	
2017-06-16 02:08:39,349 Epoch[44] Batch [1140]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-16 02:08:46,704 Epoch[44] Batch [1150]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.088632,	
2017-06-16 02:08:54,147 Epoch[44] Batch [1160]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088704,	
2017-06-16 02:09:01,453 Epoch[44] Batch [1170]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088677,	
2017-06-16 02:09:08,781 Epoch[44] Batch [1180]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.088697,	
2017-06-16 02:09:15,857 Epoch[44] Batch [1190]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.088660,	
2017-06-16 02:09:22,962 Epoch[44] Batch [1200]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.088684,	
2017-06-16 02:09:29,659 Epoch[44] Batch [1210]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088621,	
2017-06-16 02:09:36,302 Epoch[44] Batch [1220]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088581,	
2017-06-16 02:09:44,093 Epoch[44] Batch [1230]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.088561,	
2017-06-16 02:09:51,861 Epoch[44] Batch [1240]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088556,	
2017-06-16 02:09:58,351 Epoch[44] Batch [1250]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088601,	
2017-06-16 02:10:06,468 Epoch[44] Batch [1260]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-16 02:10:14,414 Epoch[44] Batch [1270]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.088583,	
2017-06-16 02:10:22,599 Epoch[44] Batch [1280]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.088555,	
2017-06-16 02:10:29,894 Epoch[44] Batch [1290]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-16 02:10:37,177 Epoch[44] Batch [1300]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.088575,	
2017-06-16 02:10:45,017 Epoch[44] Batch [1310]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.088585,	
2017-06-16 02:10:52,087 Epoch[44] Batch [1320]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088526,	
2017-06-16 02:10:59,684 Epoch[44] Batch [1330]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.088516,	
2017-06-16 02:11:07,337 Epoch[44] Batch [1340]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088577,	
2017-06-16 02:11:14,786 Epoch[44] Batch [1350]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088531,	
2017-06-16 02:11:22,751 Epoch[44] Batch [1360]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.088578,	
2017-06-16 02:11:29,225 Epoch[44] Batch [1370]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088561,	
2017-06-16 02:11:36,058 Epoch[44] Batch [1380]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-16 02:11:43,470 Epoch[44] Batch [1390]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.088463,	
2017-06-16 02:11:50,130 Epoch[44] Batch [1400]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088457,	
2017-06-16 02:11:57,226 Epoch[44] Batch [1410]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-16 02:12:04,398 Epoch[44] Batch [1420]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.088395,	
2017-06-16 02:12:11,821 Epoch[44] Batch [1430]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.088373,	
2017-06-16 02:12:20,232 Epoch[44] Batch [1440]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.088278,	
2017-06-16 02:12:27,800 Epoch[44] Batch [1450]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088279,	
2017-06-16 02:12:34,889 Epoch[44] Batch [1460]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088280,	
2017-06-16 02:12:41,929 Epoch[44] Batch [1470]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.088245,	
2017-06-16 02:12:49,154 Epoch[44] Batch [1480]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.088191,	
2017-06-16 02:12:53,280 Epoch[44] Train-FCNLogLoss=0.088163
2017-06-16 02:12:53,280 Epoch[44] Time cost=1060.084
2017-06-16 02:12:54,170 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0045.params"
2017-06-16 02:12:56,208 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0045.states"
2017-06-16 02:13:04,044 Epoch[45] Batch [10]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.083427,	
2017-06-16 02:13:10,754 Epoch[45] Batch [20]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.082835,	
2017-06-16 02:13:17,354 Epoch[45] Batch [30]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.083890,	
2017-06-16 02:13:24,502 Epoch[45] Batch [40]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086917,	
2017-06-16 02:13:31,334 Epoch[45] Batch [50]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.086157,	
2017-06-16 02:13:40,735 Epoch[45] Batch [60]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.087862,	
2017-06-16 02:13:47,938 Epoch[45] Batch [70]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086682,	
2017-06-16 02:13:56,902 Epoch[45] Batch [80]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.086698,	
2017-06-16 02:14:03,901 Epoch[45] Batch [90]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086279,	
2017-06-16 02:14:10,498 Epoch[45] Batch [100]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.086904,	
2017-06-16 02:14:17,731 Epoch[45] Batch [110]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087593,	
2017-06-16 02:14:25,558 Epoch[45] Batch [120]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.088216,	
2017-06-16 02:14:34,570 Epoch[45] Batch [130]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.088058,	
2017-06-16 02:14:41,559 Epoch[45] Batch [140]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-16 02:14:49,729 Epoch[45] Batch [150]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.088377,	
2017-06-16 02:14:57,588 Epoch[45] Batch [160]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.088812,	
2017-06-16 02:15:04,303 Epoch[45] Batch [170]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.088503,	
2017-06-16 02:15:11,823 Epoch[45] Batch [180]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.088408,	
2017-06-16 02:15:19,971 Epoch[45] Batch [190]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.088335,	
2017-06-16 02:15:27,421 Epoch[45] Batch [200]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-16 02:15:34,580 Epoch[45] Batch [210]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.088082,	
2017-06-16 02:15:42,716 Epoch[45] Batch [220]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.088366,	
2017-06-16 02:15:49,386 Epoch[45] Batch [230]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.087945,	
2017-06-16 02:15:56,453 Epoch[45] Batch [240]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088110,	
2017-06-16 02:16:04,868 Epoch[45] Batch [250]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.087918,	
2017-06-16 02:16:11,292 Epoch[45] Batch [260]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087773,	
2017-06-16 02:16:18,218 Epoch[45] Batch [270]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087869,	
2017-06-16 02:16:25,104 Epoch[45] Batch [280]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.088061,	
2017-06-16 02:16:32,963 Epoch[45] Batch [290]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087751,	
2017-06-16 02:16:40,575 Epoch[45] Batch [300]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.087859,	
2017-06-16 02:16:48,682 Epoch[45] Batch [310]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087684,	
2017-06-16 02:16:56,413 Epoch[45] Batch [320]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087984,	
2017-06-16 02:17:02,671 Epoch[45] Batch [330]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088062,	
2017-06-16 02:17:09,883 Epoch[45] Batch [340]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087962,	
2017-06-16 02:17:15,724 Epoch[45] Batch [350]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087997,	
2017-06-16 02:17:22,300 Epoch[45] Batch [360]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-16 02:17:29,881 Epoch[45] Batch [370]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.088342,	
2017-06-16 02:17:37,152 Epoch[45] Batch [380]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.088201,	
2017-06-16 02:17:44,081 Epoch[45] Batch [390]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.088094,	
2017-06-16 02:17:51,957 Epoch[45] Batch [400]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.087983,	
2017-06-16 02:17:59,195 Epoch[45] Batch [410]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.088080,	
2017-06-16 02:18:07,103 Epoch[45] Batch [420]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.088040,	
2017-06-16 02:18:14,253 Epoch[45] Batch [430]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087933,	
2017-06-16 02:18:21,846 Epoch[45] Batch [440]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.087737,	
2017-06-16 02:18:28,566 Epoch[45] Batch [450]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.087655,	
2017-06-16 02:18:37,424 Epoch[45] Batch [460]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.087652,	
2017-06-16 02:18:44,158 Epoch[45] Batch [470]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087648,	
2017-06-16 02:18:50,623 Epoch[45] Batch [480]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087614,	
2017-06-16 02:18:57,683 Epoch[45] Batch [490]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.087599,	
2017-06-16 02:19:04,232 Epoch[45] Batch [500]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-16 02:19:12,869 Epoch[45] Batch [510]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.087581,	
2017-06-16 02:19:20,097 Epoch[45] Batch [520]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-16 02:19:27,220 Epoch[45] Batch [530]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087569,	
2017-06-16 02:19:34,113 Epoch[45] Batch [540]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087492,	
2017-06-16 02:19:41,555 Epoch[45] Batch [550]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.087476,	
2017-06-16 02:19:48,276 Epoch[45] Batch [560]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.087429,	
2017-06-16 02:19:55,995 Epoch[45] Batch [570]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087288,	
2017-06-16 02:20:05,111 Epoch[45] Batch [580]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-16 02:20:12,831 Epoch[45] Batch [590]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087485,	
2017-06-16 02:20:19,620 Epoch[45] Batch [600]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.087607,	
2017-06-16 02:20:26,513 Epoch[45] Batch [610]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087724,	
2017-06-16 02:20:34,669 Epoch[45] Batch [620]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.087744,	
2017-06-16 02:20:42,056 Epoch[45] Batch [630]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.087769,	
2017-06-16 02:20:49,176 Epoch[45] Batch [640]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087727,	
2017-06-16 02:20:56,431 Epoch[45] Batch [650]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087938,	
2017-06-16 02:21:03,491 Epoch[45] Batch [660]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.087994,	
2017-06-16 02:21:10,488 Epoch[45] Batch [670]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087839,	
2017-06-16 02:21:16,871 Epoch[45] Batch [680]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.087938,	
2017-06-16 02:21:24,634 Epoch[45] Batch [690]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088075,	
2017-06-16 02:21:31,879 Epoch[45] Batch [700]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.088050,	
2017-06-16 02:21:39,526 Epoch[45] Batch [710]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088085,	
2017-06-16 02:21:47,277 Epoch[45] Batch [720]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088200,	
2017-06-16 02:21:54,487 Epoch[45] Batch [730]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.088212,	
2017-06-16 02:22:01,361 Epoch[45] Batch [740]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088158,	
2017-06-16 02:22:09,101 Epoch[45] Batch [750]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.088074,	
2017-06-16 02:22:16,379 Epoch[45] Batch [760]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.088046,	
2017-06-16 02:22:23,499 Epoch[45] Batch [770]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088061,	
2017-06-16 02:22:31,018 Epoch[45] Batch [780]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.088004,	
2017-06-16 02:22:38,580 Epoch[45] Batch [790]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088056,	
2017-06-16 02:22:45,722 Epoch[45] Batch [800]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088082,	
2017-06-16 02:22:52,849 Epoch[45] Batch [810]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.088084,	
2017-06-16 02:23:00,961 Epoch[45] Batch [820]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088008,	
2017-06-16 02:23:07,875 Epoch[45] Batch [830]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.087875,	
2017-06-16 02:23:14,767 Epoch[45] Batch [840]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087954,	
2017-06-16 02:23:22,460 Epoch[45] Batch [850]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087914,	
2017-06-16 02:23:29,680 Epoch[45] Batch [860]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087948,	
2017-06-16 02:23:35,378 Epoch[45] Batch [870]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.087886,	
2017-06-16 02:23:42,515 Epoch[45] Batch [880]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087933,	
2017-06-16 02:23:49,671 Epoch[45] Batch [890]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087942,	
2017-06-16 02:23:56,334 Epoch[45] Batch [900]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.087810,	
2017-06-16 02:24:03,407 Epoch[45] Batch [910]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087884,	
2017-06-16 02:24:12,225 Epoch[45] Batch [920]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.087770,	
2017-06-16 02:24:20,128 Epoch[45] Batch [930]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087773,	
2017-06-16 02:24:27,028 Epoch[45] Batch [940]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087747,	
2017-06-16 02:24:35,009 Epoch[45] Batch [950]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.087801,	
2017-06-16 02:24:42,275 Epoch[45] Batch [960]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087758,	
2017-06-16 02:24:49,941 Epoch[45] Batch [970]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087846,	
2017-06-16 02:24:57,364 Epoch[45] Batch [980]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087752,	
2017-06-16 02:25:05,044 Epoch[45] Batch [990]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087691,	
2017-06-16 02:25:13,225 Epoch[45] Batch [1000]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.087579,	
2017-06-16 02:25:20,330 Epoch[45] Batch [1010]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.087584,	
2017-06-16 02:25:27,363 Epoch[45] Batch [1020]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.087574,	
2017-06-16 02:25:34,980 Epoch[45] Batch [1030]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087532,	
2017-06-16 02:25:41,979 Epoch[45] Batch [1040]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087535,	
2017-06-16 02:25:50,181 Epoch[45] Batch [1050]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.087605,	
2017-06-16 02:25:58,153 Epoch[45] Batch [1060]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.087644,	
2017-06-16 02:26:05,395 Epoch[45] Batch [1070]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087692,	
2017-06-16 02:26:13,469 Epoch[45] Batch [1080]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-16 02:26:21,299 Epoch[45] Batch [1090]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.087621,	
2017-06-16 02:26:28,705 Epoch[45] Batch [1100]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087663,	
2017-06-16 02:26:36,360 Epoch[45] Batch [1110]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087662,	
2017-06-16 02:26:44,170 Epoch[45] Batch [1120]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-16 02:26:52,071 Epoch[45] Batch [1130]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087712,	
2017-06-16 02:27:00,005 Epoch[45] Batch [1140]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.087750,	
2017-06-16 02:27:07,590 Epoch[45] Batch [1150]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.087762,	
2017-06-16 02:27:15,270 Epoch[45] Batch [1160]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087743,	
2017-06-16 02:27:22,116 Epoch[45] Batch [1170]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.087702,	
2017-06-16 02:27:29,479 Epoch[45] Batch [1180]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.087664,	
2017-06-16 02:27:37,966 Epoch[45] Batch [1190]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.087668,	
2017-06-16 02:27:45,970 Epoch[45] Batch [1200]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087641,	
2017-06-16 02:27:53,128 Epoch[45] Batch [1210]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087633,	
2017-06-16 02:27:59,844 Epoch[45] Batch [1220]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087624,	
2017-06-16 02:28:08,261 Epoch[45] Batch [1230]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.087576,	
2017-06-16 02:28:15,308 Epoch[45] Batch [1240]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087651,	
2017-06-16 02:28:22,816 Epoch[45] Batch [1250]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-16 02:28:30,623 Epoch[45] Batch [1260]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-16 02:28:37,766 Epoch[45] Batch [1270]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087726,	
2017-06-16 02:28:45,609 Epoch[45] Batch [1280]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087725,	
2017-06-16 02:28:53,978 Epoch[45] Batch [1290]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.087693,	
2017-06-16 02:29:02,593 Epoch[45] Batch [1300]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.087687,	
2017-06-16 02:29:10,628 Epoch[45] Batch [1310]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-16 02:29:18,443 Epoch[45] Batch [1320]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.087706,	
2017-06-16 02:29:26,016 Epoch[45] Batch [1330]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.087701,	
2017-06-16 02:29:33,772 Epoch[45] Batch [1340]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087688,	
2017-06-16 02:29:42,064 Epoch[45] Batch [1350]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.087768,	
2017-06-16 02:29:49,769 Epoch[45] Batch [1360]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.087758,	
2017-06-16 02:29:58,038 Epoch[45] Batch [1370]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.087837,	
2017-06-16 02:30:05,931 Epoch[45] Batch [1380]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087834,	
2017-06-16 02:30:14,513 Epoch[45] Batch [1390]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.087799,	
2017-06-16 02:30:22,589 Epoch[45] Batch [1400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.087813,	
2017-06-16 02:30:29,434 Epoch[45] Batch [1410]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.087788,	
2017-06-16 02:30:37,421 Epoch[45] Batch [1420]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.087797,	
2017-06-16 02:30:45,361 Epoch[45] Batch [1430]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-16 02:30:52,663 Epoch[45] Batch [1440]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087773,	
2017-06-16 02:30:59,860 Epoch[45] Batch [1450]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087786,	
2017-06-16 02:31:07,664 Epoch[45] Batch [1460]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087836,	
2017-06-16 02:31:14,368 Epoch[45] Batch [1470]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.087815,	
2017-06-16 02:31:22,511 Epoch[45] Batch [1480]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.087861,	
2017-06-16 02:31:28,068 Epoch[45] Train-FCNLogLoss=0.087948
2017-06-16 02:31:28,068 Epoch[45] Time cost=1111.859
2017-06-16 02:31:29,018 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0046.params"
2017-06-16 02:31:31,296 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0046.states"
2017-06-16 02:31:38,956 Epoch[46] Batch [10]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.094086,	
2017-06-16 02:31:45,290 Epoch[46] Batch [20]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.096006,	
2017-06-16 02:31:52,284 Epoch[46] Batch [30]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.093865,	
2017-06-16 02:31:59,426 Epoch[46] Batch [40]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.090675,	
2017-06-16 02:32:06,752 Epoch[46] Batch [50]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.088725,	
2017-06-16 02:32:13,949 Epoch[46] Batch [60]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089708,	
2017-06-16 02:32:21,701 Epoch[46] Batch [70]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.090054,	
2017-06-16 02:32:28,616 Epoch[46] Batch [80]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.089948,	
2017-06-16 02:32:36,009 Epoch[46] Batch [90]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.090365,	
2017-06-16 02:32:43,611 Epoch[46] Batch [100]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.090075,	
2017-06-16 02:32:51,665 Epoch[46] Batch [110]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.090061,	
2017-06-16 02:32:58,456 Epoch[46] Batch [120]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.089818,	
2017-06-16 02:33:05,858 Epoch[46] Batch [130]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.089231,	
2017-06-16 02:33:12,917 Epoch[46] Batch [140]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.088233,	
2017-06-16 02:33:20,860 Epoch[46] Batch [150]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.088013,	
2017-06-16 02:33:28,801 Epoch[46] Batch [160]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.087837,	
2017-06-16 02:33:36,588 Epoch[46] Batch [170]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.087989,	
2017-06-16 02:33:42,723 Epoch[46] Batch [180]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088445,	
2017-06-16 02:33:49,644 Epoch[46] Batch [190]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088235,	
2017-06-16 02:33:56,756 Epoch[46] Batch [200]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088415,	
2017-06-16 02:34:03,929 Epoch[46] Batch [210]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.088757,	
2017-06-16 02:34:10,165 Epoch[46] Batch [220]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.089245,	
2017-06-16 02:34:17,355 Epoch[46] Batch [230]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088992,	
2017-06-16 02:34:24,272 Epoch[46] Batch [240]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.089631,	
2017-06-16 02:34:32,324 Epoch[46] Batch [250]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.089757,	
2017-06-16 02:34:39,443 Epoch[46] Batch [260]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.089622,	
2017-06-16 02:34:46,731 Epoch[46] Batch [270]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.089748,	
2017-06-16 02:34:54,052 Epoch[46] Batch [280]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.089583,	
2017-06-16 02:35:00,934 Epoch[46] Batch [290]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-16 02:35:08,436 Epoch[46] Batch [300]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.089478,	
2017-06-16 02:35:14,553 Epoch[46] Batch [310]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.089743,	
2017-06-16 02:35:21,285 Epoch[46] Batch [320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.089720,	
2017-06-16 02:35:28,482 Epoch[46] Batch [330]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089868,	
2017-06-16 02:35:35,789 Epoch[46] Batch [340]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.090058,	
2017-06-16 02:35:42,222 Epoch[46] Batch [350]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.089878,	
2017-06-16 02:35:49,138 Epoch[46] Batch [360]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.089788,	
2017-06-16 02:35:56,250 Epoch[46] Batch [370]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.089487,	
2017-06-16 02:36:02,653 Epoch[46] Batch [380]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.089330,	
2017-06-16 02:36:09,856 Epoch[46] Batch [390]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.089406,	
2017-06-16 02:36:16,694 Epoch[46] Batch [400]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.089348,	
2017-06-16 02:36:24,750 Epoch[46] Batch [410]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-16 02:36:32,036 Epoch[46] Batch [420]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.088844,	
2017-06-16 02:36:39,831 Epoch[46] Batch [430]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.088656,	
2017-06-16 02:36:46,434 Epoch[46] Batch [440]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088665,	
2017-06-16 02:36:53,933 Epoch[46] Batch [450]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-16 02:37:00,482 Epoch[46] Batch [460]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088492,	
2017-06-16 02:37:07,513 Epoch[46] Batch [470]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088443,	
2017-06-16 02:37:15,318 Epoch[46] Batch [480]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.088296,	
2017-06-16 02:37:22,469 Epoch[46] Batch [490]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.088338,	
2017-06-16 02:37:29,727 Epoch[46] Batch [500]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.088307,	
2017-06-16 02:37:37,356 Epoch[46] Batch [510]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.088203,	
2017-06-16 02:37:44,756 Epoch[46] Batch [520]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.088209,	
2017-06-16 02:37:52,233 Epoch[46] Batch [530]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.088103,	
2017-06-16 02:37:59,497 Epoch[46] Batch [540]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.088147,	
2017-06-16 02:38:06,235 Epoch[46] Batch [550]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087967,	
2017-06-16 02:38:13,931 Epoch[46] Batch [560]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088071,	
2017-06-16 02:38:21,589 Epoch[46] Batch [570]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.088218,	
2017-06-16 02:38:28,959 Epoch[46] Batch [580]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088264,	
2017-06-16 02:38:36,977 Epoch[46] Batch [590]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.088259,	
2017-06-16 02:38:45,298 Epoch[46] Batch [600]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.088178,	
2017-06-16 02:38:52,364 Epoch[46] Batch [610]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088089,	
2017-06-16 02:38:59,099 Epoch[46] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087919,	
2017-06-16 02:39:06,240 Epoch[46] Batch [630]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087955,	
2017-06-16 02:39:13,457 Epoch[46] Batch [640]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087920,	
2017-06-16 02:39:21,227 Epoch[46] Batch [650]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.087986,	
2017-06-16 02:39:29,945 Epoch[46] Batch [660]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-16 02:39:37,438 Epoch[46] Batch [670]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087798,	
2017-06-16 02:39:44,735 Epoch[46] Batch [680]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087805,	
2017-06-16 02:39:53,651 Epoch[46] Batch [690]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.087867,	
2017-06-16 02:40:00,542 Epoch[46] Batch [700]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.087969,	
2017-06-16 02:40:08,081 Epoch[46] Batch [710]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087923,	
2017-06-16 02:40:15,536 Epoch[46] Batch [720]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087872,	
2017-06-16 02:40:22,418 Epoch[46] Batch [730]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.088056,	
2017-06-16 02:40:30,359 Epoch[46] Batch [740]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.088083,	
2017-06-16 02:40:38,153 Epoch[46] Batch [750]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.088055,	
2017-06-16 02:40:45,521 Epoch[46] Batch [760]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.087964,	
2017-06-16 02:40:53,220 Epoch[46] Batch [770]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087957,	
2017-06-16 02:41:00,612 Epoch[46] Batch [780]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.088068,	
2017-06-16 02:41:07,461 Epoch[46] Batch [790]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.088083,	
2017-06-16 02:41:15,640 Epoch[46] Batch [800]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.088003,	
2017-06-16 02:41:23,307 Epoch[46] Batch [810]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.088056,	
2017-06-16 02:41:31,115 Epoch[46] Batch [820]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.088146,	
2017-06-16 02:41:39,043 Epoch[46] Batch [830]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.088083,	
2017-06-16 02:41:46,474 Epoch[46] Batch [840]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.088134,	
2017-06-16 02:41:53,912 Epoch[46] Batch [850]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.088137,	
2017-06-16 02:42:01,459 Epoch[46] Batch [860]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.088164,	
2017-06-16 02:42:09,739 Epoch[46] Batch [870]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.088182,	
2017-06-16 02:42:17,514 Epoch[46] Batch [880]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.088253,	
2017-06-16 02:42:25,099 Epoch[46] Batch [890]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.088207,	
2017-06-16 02:42:33,070 Epoch[46] Batch [900]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-16 02:42:40,934 Epoch[46] Batch [910]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.088424,	
2017-06-16 02:42:48,816 Epoch[46] Batch [920]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.088355,	
2017-06-16 02:42:56,262 Epoch[46] Batch [930]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088411,	
2017-06-16 02:43:05,048 Epoch[46] Batch [940]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.088350,	
2017-06-16 02:43:11,925 Epoch[46] Batch [950]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-16 02:43:19,022 Epoch[46] Batch [960]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088205,	
2017-06-16 02:43:26,865 Epoch[46] Batch [970]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-16 02:43:34,901 Epoch[46] Batch [980]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.088249,	
2017-06-16 02:43:42,456 Epoch[46] Batch [990]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088204,	
2017-06-16 02:43:49,949 Epoch[46] Batch [1000]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.088267,	
2017-06-16 02:43:57,087 Epoch[46] Batch [1010]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088241,	
2017-06-16 02:44:04,432 Epoch[46] Batch [1020]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.088281,	
2017-06-16 02:44:11,687 Epoch[46] Batch [1030]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.088333,	
2017-06-16 02:44:19,133 Epoch[46] Batch [1040]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-16 02:44:27,001 Epoch[46] Batch [1050]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.088418,	
2017-06-16 02:44:34,750 Epoch[46] Batch [1060]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088353,	
2017-06-16 02:44:43,103 Epoch[46] Batch [1070]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.088289,	
2017-06-16 02:44:51,331 Epoch[46] Batch [1080]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088249,	
2017-06-16 02:44:59,477 Epoch[46] Batch [1090]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-16 02:45:07,587 Epoch[46] Batch [1100]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088170,	
2017-06-16 02:45:15,523 Epoch[46] Batch [1110]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.088188,	
2017-06-16 02:45:23,275 Epoch[46] Batch [1120]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-16 02:45:30,541 Epoch[46] Batch [1130]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.088190,	
2017-06-16 02:45:38,248 Epoch[46] Batch [1140]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.088113,	
2017-06-16 02:45:46,743 Epoch[46] Batch [1150]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.088087,	
2017-06-16 02:45:54,643 Epoch[46] Batch [1160]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.088019,	
2017-06-16 02:46:02,015 Epoch[46] Batch [1170]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.087901,	
2017-06-16 02:46:09,564 Epoch[46] Batch [1180]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.087928,	
2017-06-16 02:46:17,782 Epoch[46] Batch [1190]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.087903,	
2017-06-16 02:46:25,095 Epoch[46] Batch [1200]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.087848,	
2017-06-16 02:46:31,907 Epoch[46] Batch [1210]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-16 02:46:41,385 Epoch[46] Batch [1220]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.087837,	
2017-06-16 02:46:49,454 Epoch[46] Batch [1230]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.087830,	
2017-06-16 02:46:57,279 Epoch[46] Batch [1240]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.087822,	
2017-06-16 02:47:04,640 Epoch[46] Batch [1250]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.087724,	
2017-06-16 02:47:13,356 Epoch[46] Batch [1260]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.087735,	
2017-06-16 02:47:22,181 Epoch[46] Batch [1270]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.087722,	
2017-06-16 02:47:29,858 Epoch[46] Batch [1280]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087738,	
2017-06-16 02:47:37,531 Epoch[46] Batch [1290]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087724,	
2017-06-16 02:47:45,038 Epoch[46] Batch [1300]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087748,	
2017-06-16 02:47:53,196 Epoch[46] Batch [1310]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.087717,	
2017-06-16 02:48:01,436 Epoch[46] Batch [1320]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.087702,	
2017-06-16 02:48:08,409 Epoch[46] Batch [1330]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.087675,	
2017-06-16 02:48:17,074 Epoch[46] Batch [1340]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.087713,	
2017-06-16 02:48:24,500 Epoch[46] Batch [1350]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087718,	
2017-06-16 02:48:32,456 Epoch[46] Batch [1360]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087734,	
2017-06-16 02:48:39,315 Epoch[46] Batch [1370]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-16 02:48:47,633 Epoch[46] Batch [1380]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.087707,	
2017-06-16 02:48:55,702 Epoch[46] Batch [1390]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-16 02:49:03,358 Epoch[46] Batch [1400]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087773,	
2017-06-16 02:49:11,241 Epoch[46] Batch [1410]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087755,	
2017-06-16 02:49:18,547 Epoch[46] Batch [1420]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087726,	
2017-06-16 02:49:26,069 Epoch[46] Batch [1430]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-16 02:49:33,981 Epoch[46] Batch [1440]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087723,	
2017-06-16 02:49:42,505 Epoch[46] Batch [1450]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.087785,	
2017-06-16 02:49:50,503 Epoch[46] Batch [1460]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087842,	
2017-06-16 02:49:58,195 Epoch[46] Batch [1470]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087825,	
2017-06-16 02:50:07,053 Epoch[46] Batch [1480]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-16 02:50:12,109 Epoch[46] Train-FCNLogLoss=0.087753
2017-06-16 02:50:12,109 Epoch[46] Time cost=1120.812
2017-06-16 02:50:12,865 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0047.params"
2017-06-16 02:50:15,379 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0047.states"
2017-06-16 02:50:23,664 Epoch[47] Batch [10]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.082995,	
2017-06-16 02:50:30,184 Epoch[47] Batch [20]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.089768,	
2017-06-16 02:50:37,251 Epoch[47] Batch [30]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.091652,	
2017-06-16 02:50:43,736 Epoch[47] Batch [40]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.089764,	
2017-06-16 02:50:50,088 Epoch[47] Batch [50]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.091905,	
2017-06-16 02:50:57,678 Epoch[47] Batch [60]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.091890,	
2017-06-16 02:51:04,194 Epoch[47] Batch [70]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.091604,	
2017-06-16 02:51:10,409 Epoch[47] Batch [80]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.089873,	
2017-06-16 02:51:17,687 Epoch[47] Batch [90]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.088846,	
2017-06-16 02:51:24,872 Epoch[47] Batch [100]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.089215,	
2017-06-16 02:51:31,550 Epoch[47] Batch [110]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.089406,	
2017-06-16 02:51:38,427 Epoch[47] Batch [120]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088878,	
2017-06-16 02:51:44,867 Epoch[47] Batch [130]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088628,	
2017-06-16 02:51:51,766 Epoch[47] Batch [140]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087794,	
2017-06-16 02:51:58,832 Epoch[47] Batch [150]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087510,	
2017-06-16 02:52:05,743 Epoch[47] Batch [160]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088035,	
2017-06-16 02:52:11,653 Epoch[47] Batch [170]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.088167,	
2017-06-16 02:52:18,814 Epoch[47] Batch [180]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087972,	
2017-06-16 02:52:26,268 Epoch[47] Batch [190]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087957,	
2017-06-16 02:52:33,185 Epoch[47] Batch [200]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087987,	
2017-06-16 02:52:41,134 Epoch[47] Batch [210]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087762,	
2017-06-16 02:52:49,123 Epoch[47] Batch [220]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088320,	
2017-06-16 02:52:54,770 Epoch[47] Batch [230]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.088090,	
2017-06-16 02:53:02,625 Epoch[47] Batch [240]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087995,	
2017-06-16 02:53:10,364 Epoch[47] Batch [250]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087943,	
2017-06-16 02:53:18,884 Epoch[47] Batch [260]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.088657,	
2017-06-16 02:53:26,234 Epoch[47] Batch [270]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-16 02:53:32,570 Epoch[47] Batch [280]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088278,	
2017-06-16 02:53:40,925 Epoch[47] Batch [290]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.088551,	
2017-06-16 02:53:47,799 Epoch[47] Batch [300]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088524,	
2017-06-16 02:53:56,548 Epoch[47] Batch [310]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.088578,	
2017-06-16 02:54:03,277 Epoch[47] Batch [320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.089245,	
2017-06-16 02:54:10,094 Epoch[47] Batch [330]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.089066,	
2017-06-16 02:54:16,322 Epoch[47] Batch [340]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.089019,	
2017-06-16 02:54:22,883 Epoch[47] Batch [350]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.089006,	
2017-06-16 02:54:29,903 Epoch[47] Batch [360]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088841,	
2017-06-16 02:54:36,631 Epoch[47] Batch [370]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.088799,	
2017-06-16 02:54:44,318 Epoch[47] Batch [380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088879,	
2017-06-16 02:54:52,185 Epoch[47] Batch [390]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.088910,	
2017-06-16 02:55:00,350 Epoch[47] Batch [400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.088954,	
2017-06-16 02:55:08,806 Epoch[47] Batch [410]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.088917,	
2017-06-16 02:55:15,685 Epoch[47] Batch [420]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088810,	
2017-06-16 02:55:22,552 Epoch[47] Batch [430]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088664,	
2017-06-16 02:55:28,653 Epoch[47] Batch [440]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.088358,	
2017-06-16 02:55:34,450 Epoch[47] Batch [450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.088256,	
2017-06-16 02:55:40,487 Epoch[47] Batch [460]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088257,	
2017-06-16 02:55:47,121 Epoch[47] Batch [470]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.088076,	
2017-06-16 02:55:54,085 Epoch[47] Batch [480]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.088084,	
2017-06-16 02:56:02,304 Epoch[47] Batch [490]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.088164,	
2017-06-16 02:56:09,363 Epoch[47] Batch [500]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.088310,	
2017-06-16 02:56:16,479 Epoch[47] Batch [510]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088294,	
2017-06-16 02:56:22,888 Epoch[47] Batch [520]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088361,	
2017-06-16 02:56:29,919 Epoch[47] Batch [530]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088436,	
2017-06-16 02:56:37,102 Epoch[47] Batch [540]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-16 02:56:44,684 Epoch[47] Batch [550]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.088567,	
2017-06-16 02:56:52,811 Epoch[47] Batch [560]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.088479,	
2017-06-16 02:57:00,105 Epoch[47] Batch [570]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088617,	
2017-06-16 02:57:08,109 Epoch[47] Batch [580]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.088600,	
2017-06-16 02:57:15,844 Epoch[47] Batch [590]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.088458,	
2017-06-16 02:57:23,206 Epoch[47] Batch [600]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088282,	
2017-06-16 02:57:30,966 Epoch[47] Batch [610]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088551,	
2017-06-16 02:57:38,127 Epoch[47] Batch [620]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.088432,	
2017-06-16 02:57:45,890 Epoch[47] Batch [630]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088458,	
2017-06-16 02:57:53,522 Epoch[47] Batch [640]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.088330,	
2017-06-16 02:58:00,466 Epoch[47] Batch [650]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.088293,	
2017-06-16 02:58:07,673 Epoch[47] Batch [660]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.088092,	
2017-06-16 02:58:15,001 Epoch[47] Batch [670]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.088196,	
2017-06-16 02:58:22,499 Epoch[47] Batch [680]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088007,	
2017-06-16 02:58:29,860 Epoch[47] Batch [690]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088026,	
2017-06-16 02:58:37,424 Epoch[47] Batch [700]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088097,	
2017-06-16 02:58:45,956 Epoch[47] Batch [710]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.088017,	
2017-06-16 02:58:53,625 Epoch[47] Batch [720]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.088108,	
2017-06-16 02:59:00,970 Epoch[47] Batch [730]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.088029,	
2017-06-16 02:59:09,346 Epoch[47] Batch [740]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.087988,	
2017-06-16 02:59:16,558 Epoch[47] Batch [750]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087939,	
2017-06-16 02:59:24,040 Epoch[47] Batch [760]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087899,	
2017-06-16 02:59:31,939 Epoch[47] Batch [770]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087866,	
2017-06-16 02:59:38,908 Epoch[47] Batch [780]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.087816,	
2017-06-16 02:59:45,932 Epoch[47] Batch [790]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087784,	
2017-06-16 02:59:53,101 Epoch[47] Batch [800]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.087754,	
2017-06-16 03:00:01,143 Epoch[47] Batch [810]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-16 03:00:08,773 Epoch[47] Batch [820]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.087644,	
2017-06-16 03:00:16,191 Epoch[47] Batch [830]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087565,	
2017-06-16 03:00:23,400 Epoch[47] Batch [840]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087586,	
2017-06-16 03:00:30,309 Epoch[47] Batch [850]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.087570,	
2017-06-16 03:00:37,725 Epoch[47] Batch [860]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087511,	
2017-06-16 03:00:44,209 Epoch[47] Batch [870]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.087587,	
2017-06-16 03:00:51,828 Epoch[47] Batch [880]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087606,	
2017-06-16 03:00:59,367 Epoch[47] Batch [890]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-16 03:01:06,409 Epoch[47] Batch [900]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087501,	
2017-06-16 03:01:14,610 Epoch[47] Batch [910]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-16 03:01:21,625 Epoch[47] Batch [920]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087503,	
2017-06-16 03:01:29,217 Epoch[47] Batch [930]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.087589,	
2017-06-16 03:01:36,946 Epoch[47] Batch [940]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087588,	
2017-06-16 03:01:44,057 Epoch[47] Batch [950]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.087557,	
2017-06-16 03:01:51,752 Epoch[47] Batch [960]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087614,	
2017-06-16 03:01:59,798 Epoch[47] Batch [970]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.087514,	
2017-06-16 03:02:07,041 Epoch[47] Batch [980]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087430,	
2017-06-16 03:02:13,314 Epoch[47] Batch [990]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.087425,	
2017-06-16 03:02:20,102 Epoch[47] Batch [1000]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.087441,	
2017-06-16 03:02:27,589 Epoch[47] Batch [1010]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087416,	
2017-06-16 03:02:34,394 Epoch[47] Batch [1020]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-16 03:02:43,813 Epoch[47] Batch [1030]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.087330,	
2017-06-16 03:02:51,064 Epoch[47] Batch [1040]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087364,	
2017-06-16 03:02:58,466 Epoch[47] Batch [1050]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087373,	
2017-06-16 03:03:05,552 Epoch[47] Batch [1060]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087435,	
2017-06-16 03:03:12,996 Epoch[47] Batch [1070]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087495,	
2017-06-16 03:03:19,965 Epoch[47] Batch [1080]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.087423,	
2017-06-16 03:03:28,417 Epoch[47] Batch [1090]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.087326,	
2017-06-16 03:03:34,859 Epoch[47] Batch [1100]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087264,	
2017-06-16 03:03:42,661 Epoch[47] Batch [1110]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087236,	
2017-06-16 03:03:49,759 Epoch[47] Batch [1120]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-16 03:03:56,709 Epoch[47] Batch [1130]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.087305,	
2017-06-16 03:04:04,897 Epoch[47] Batch [1140]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-16 03:04:12,849 Epoch[47] Batch [1150]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087209,	
2017-06-16 03:04:19,998 Epoch[47] Batch [1160]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087247,	
2017-06-16 03:04:26,746 Epoch[47] Batch [1170]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087265,	
2017-06-16 03:04:33,830 Epoch[47] Batch [1180]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087279,	
2017-06-16 03:04:41,245 Epoch[47] Batch [1190]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087247,	
2017-06-16 03:04:48,651 Epoch[47] Batch [1200]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087249,	
2017-06-16 03:04:55,843 Epoch[47] Batch [1210]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087229,	
2017-06-16 03:05:02,341 Epoch[47] Batch [1220]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.087218,	
2017-06-16 03:05:10,448 Epoch[47] Batch [1230]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087141,	
2017-06-16 03:05:18,293 Epoch[47] Batch [1240]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087125,	
2017-06-16 03:05:24,718 Epoch[47] Batch [1250]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087100,	
2017-06-16 03:05:31,679 Epoch[47] Batch [1260]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087074,	
2017-06-16 03:05:39,146 Epoch[47] Batch [1270]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.087002,	
2017-06-16 03:05:45,719 Epoch[47] Batch [1280]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.087106,	
2017-06-16 03:05:53,468 Epoch[47] Batch [1290]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087378,	
2017-06-16 03:06:00,655 Epoch[47] Batch [1300]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.087357,	
2017-06-16 03:06:08,583 Epoch[47] Batch [1310]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.087342,	
2017-06-16 03:06:15,899 Epoch[47] Batch [1320]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.087317,	
2017-06-16 03:06:22,992 Epoch[47] Batch [1330]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087349,	
2017-06-16 03:06:30,729 Epoch[47] Batch [1340]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-16 03:06:39,508 Epoch[47] Batch [1350]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.087364,	
2017-06-16 03:06:46,271 Epoch[47] Batch [1360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-16 03:06:53,605 Epoch[47] Batch [1370]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.087375,	
2017-06-16 03:07:01,445 Epoch[47] Batch [1380]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087383,	
2017-06-16 03:07:09,558 Epoch[47] Batch [1390]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087319,	
2017-06-16 03:07:16,788 Epoch[47] Batch [1400]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087341,	
2017-06-16 03:07:23,524 Epoch[47] Batch [1410]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087324,	
2017-06-16 03:07:31,364 Epoch[47] Batch [1420]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087361,	
2017-06-16 03:07:38,819 Epoch[47] Batch [1430]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087378,	
2017-06-16 03:07:46,303 Epoch[47] Batch [1440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087411,	
2017-06-16 03:07:53,744 Epoch[47] Batch [1450]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.087398,	
2017-06-16 03:08:01,690 Epoch[47] Batch [1460]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087404,	
2017-06-16 03:08:09,585 Epoch[47] Batch [1470]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087385,	
2017-06-16 03:08:15,981 Epoch[47] Batch [1480]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087408,	
2017-06-16 03:08:19,900 Epoch[47] Train-FCNLogLoss=0.087372
2017-06-16 03:08:19,900 Epoch[47] Time cost=1084.521
2017-06-16 03:08:20,614 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0048.params"
2017-06-16 03:08:23,731 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0048.states"
2017-06-16 03:08:31,657 Epoch[48] Batch [10]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.085967,	
2017-06-16 03:08:38,358 Epoch[48] Batch [20]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.091872,	
2017-06-16 03:08:45,589 Epoch[48] Batch [30]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.091011,	
2017-06-16 03:08:52,275 Epoch[48] Batch [40]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.090390,	
2017-06-16 03:08:59,464 Epoch[48] Batch [50]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089397,	
2017-06-16 03:09:06,482 Epoch[48] Batch [60]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.089455,	
2017-06-16 03:09:13,236 Epoch[48] Batch [70]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.090181,	
2017-06-16 03:09:19,815 Epoch[48] Batch [80]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.089348,	
2017-06-16 03:09:26,882 Epoch[48] Batch [90]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088335,	
2017-06-16 03:09:33,786 Epoch[48] Batch [100]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.087531,	
2017-06-16 03:09:41,906 Epoch[48] Batch [110]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087717,	
2017-06-16 03:09:49,504 Epoch[48] Batch [120]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.087555,	
2017-06-16 03:09:56,688 Epoch[48] Batch [130]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088071,	
2017-06-16 03:10:04,730 Epoch[48] Batch [140]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.088599,	
2017-06-16 03:10:12,968 Epoch[48] Batch [150]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088856,	
2017-06-16 03:10:20,559 Epoch[48] Batch [160]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.088686,	
2017-06-16 03:10:27,827 Epoch[48] Batch [170]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.088308,	
2017-06-16 03:10:35,013 Epoch[48] Batch [180]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-16 03:10:42,316 Epoch[48] Batch [190]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.088830,	
2017-06-16 03:10:50,276 Epoch[48] Batch [200]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.088904,	
2017-06-16 03:10:57,298 Epoch[48] Batch [210]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-16 03:11:04,487 Epoch[48] Batch [220]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089234,	
2017-06-16 03:11:12,148 Epoch[48] Batch [230]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.089102,	
2017-06-16 03:11:18,831 Epoch[48] Batch [240]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-16 03:11:27,249 Epoch[48] Batch [250]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.088314,	
2017-06-16 03:11:34,589 Epoch[48] Batch [260]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.088442,	
2017-06-16 03:11:43,189 Epoch[48] Batch [270]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.088297,	
2017-06-16 03:11:49,565 Epoch[48] Batch [280]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088402,	
2017-06-16 03:11:56,533 Epoch[48] Batch [290]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.088318,	
2017-06-16 03:12:05,356 Epoch[48] Batch [300]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.087999,	
2017-06-16 03:12:12,313 Epoch[48] Batch [310]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087866,	
2017-06-16 03:12:20,520 Epoch[48] Batch [320]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.087965,	
2017-06-16 03:12:26,835 Epoch[48] Batch [330]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087874,	
2017-06-16 03:12:34,243 Epoch[48] Batch [340]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087929,	
2017-06-16 03:12:41,310 Epoch[48] Batch [350]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087914,	
2017-06-16 03:12:49,011 Epoch[48] Batch [360]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.087818,	
2017-06-16 03:12:56,722 Epoch[48] Batch [370]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-16 03:13:04,385 Epoch[48] Batch [380]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087803,	
2017-06-16 03:13:11,276 Epoch[48] Batch [390]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.088015,	
2017-06-16 03:13:17,880 Epoch[48] Batch [400]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088002,	
2017-06-16 03:13:26,188 Epoch[48] Batch [410]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.088045,	
2017-06-16 03:13:32,878 Epoch[48] Batch [420]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087889,	
2017-06-16 03:13:39,210 Epoch[48] Batch [430]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087829,	
2017-06-16 03:13:45,885 Epoch[48] Batch [440]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.087934,	
2017-06-16 03:13:52,898 Epoch[48] Batch [450]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087999,	
2017-06-16 03:14:00,383 Epoch[48] Batch [460]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.088002,	
2017-06-16 03:14:07,582 Epoch[48] Batch [470]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088177,	
2017-06-16 03:14:15,029 Epoch[48] Batch [480]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.088253,	
2017-06-16 03:14:22,634 Epoch[48] Batch [490]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.088257,	
2017-06-16 03:14:30,008 Epoch[48] Batch [500]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.088337,	
2017-06-16 03:14:37,096 Epoch[48] Batch [510]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088433,	
2017-06-16 03:14:44,347 Epoch[48] Batch [520]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.088373,	
2017-06-16 03:14:51,351 Epoch[48] Batch [530]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.088293,	
2017-06-16 03:14:58,006 Epoch[48] Batch [540]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088121,	
2017-06-16 03:15:05,672 Epoch[48] Batch [550]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.088151,	
2017-06-16 03:15:13,237 Epoch[48] Batch [560]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088172,	
2017-06-16 03:15:20,253 Epoch[48] Batch [570]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088186,	
2017-06-16 03:15:27,394 Epoch[48] Batch [580]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-16 03:15:33,949 Epoch[48] Batch [590]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.088335,	
2017-06-16 03:15:39,465 Epoch[48] Batch [600]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088265,	
2017-06-16 03:15:48,158 Epoch[48] Batch [610]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.087997,	
2017-06-16 03:15:53,853 Epoch[48] Batch [620]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.087885,	
2017-06-16 03:16:00,401 Epoch[48] Batch [630]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087914,	
2017-06-16 03:16:07,065 Epoch[48] Batch [640]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-16 03:16:15,422 Epoch[48] Batch [650]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.087989,	
2017-06-16 03:16:22,808 Epoch[48] Batch [660]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.087846,	
2017-06-16 03:16:30,819 Epoch[48] Batch [670]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087846,	
2017-06-16 03:16:38,218 Epoch[48] Batch [680]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087863,	
2017-06-16 03:16:45,846 Epoch[48] Batch [690]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.087839,	
2017-06-16 03:16:53,535 Epoch[48] Batch [700]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087850,	
2017-06-16 03:17:00,871 Epoch[48] Batch [710]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.087861,	
2017-06-16 03:17:08,417 Epoch[48] Batch [720]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-16 03:17:16,068 Epoch[48] Batch [730]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-16 03:17:23,151 Epoch[48] Batch [740]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087785,	
2017-06-16 03:17:29,577 Epoch[48] Batch [750]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087786,	
2017-06-16 03:17:37,864 Epoch[48] Batch [760]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.087813,	
2017-06-16 03:17:45,369 Epoch[48] Batch [770]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087821,	
2017-06-16 03:17:54,206 Epoch[48] Batch [780]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.087722,	
2017-06-16 03:18:02,743 Epoch[48] Batch [790]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.087718,	
2017-06-16 03:18:10,142 Epoch[48] Batch [800]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087734,	
2017-06-16 03:18:17,186 Epoch[48] Batch [810]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087706,	
2017-06-16 03:18:24,104 Epoch[48] Batch [820]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087637,	
2017-06-16 03:18:32,091 Epoch[48] Batch [830]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.087609,	
2017-06-16 03:18:39,272 Epoch[48] Batch [840]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-16 03:18:46,057 Epoch[48] Batch [850]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087624,	
2017-06-16 03:18:53,592 Epoch[48] Batch [860]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087739,	
2017-06-16 03:19:00,139 Epoch[48] Batch [870]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087635,	
2017-06-16 03:19:07,464 Epoch[48] Batch [880]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087550,	
2017-06-16 03:19:15,365 Epoch[48] Batch [890]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087493,	
2017-06-16 03:19:22,299 Epoch[48] Batch [900]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.087521,	
2017-06-16 03:19:29,575 Epoch[48] Batch [910]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.087506,	
2017-06-16 03:19:37,146 Epoch[48] Batch [920]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.087419,	
2017-06-16 03:19:44,523 Epoch[48] Batch [930]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.087382,	
2017-06-16 03:19:52,161 Epoch[48] Batch [940]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-16 03:19:59,456 Epoch[48] Batch [950]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087476,	
2017-06-16 03:20:07,295 Epoch[48] Batch [960]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-16 03:20:15,811 Epoch[48] Batch [970]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-16 03:20:22,690 Epoch[48] Batch [980]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.087444,	
2017-06-16 03:20:31,051 Epoch[48] Batch [990]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.087472,	
2017-06-16 03:20:38,449 Epoch[48] Batch [1000]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087408,	
2017-06-16 03:20:45,858 Epoch[48] Batch [1010]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087405,	
2017-06-16 03:20:53,185 Epoch[48] Batch [1020]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087533,	
2017-06-16 03:21:00,478 Epoch[48] Batch [1030]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.087521,	
2017-06-16 03:21:08,487 Epoch[48] Batch [1040]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087620,	
2017-06-16 03:21:15,874 Epoch[48] Batch [1050]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.087585,	
2017-06-16 03:21:23,279 Epoch[48] Batch [1060]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087651,	
2017-06-16 03:21:29,902 Epoch[48] Batch [1070]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087577,	
2017-06-16 03:21:37,787 Epoch[48] Batch [1080]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087614,	
2017-06-16 03:21:45,134 Epoch[48] Batch [1090]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.087564,	
2017-06-16 03:21:53,463 Epoch[48] Batch [1100]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.087636,	
2017-06-16 03:21:59,475 Epoch[48] Batch [1110]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.087664,	
2017-06-16 03:22:06,916 Epoch[48] Batch [1120]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.087690,	
2017-06-16 03:22:14,153 Epoch[48] Batch [1130]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-16 03:22:20,829 Epoch[48] Batch [1140]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.087664,	
2017-06-16 03:22:27,695 Epoch[48] Batch [1150]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087644,	
2017-06-16 03:22:34,525 Epoch[48] Batch [1160]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.087658,	
2017-06-16 03:22:42,027 Epoch[48] Batch [1170]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087640,	
2017-06-16 03:22:50,425 Epoch[48] Batch [1180]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.087681,	
2017-06-16 03:22:58,203 Epoch[48] Batch [1190]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.087700,	
2017-06-16 03:23:05,059 Epoch[48] Batch [1200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-16 03:23:12,443 Epoch[48] Batch [1210]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.087710,	
2017-06-16 03:23:19,948 Epoch[48] Batch [1220]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087747,	
2017-06-16 03:23:27,127 Epoch[48] Batch [1230]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.087664,	
2017-06-16 03:23:33,907 Epoch[48] Batch [1240]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087709,	
2017-06-16 03:23:40,479 Epoch[48] Batch [1250]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-16 03:23:48,679 Epoch[48] Batch [1260]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.087697,	
2017-06-16 03:23:56,349 Epoch[48] Batch [1270]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087711,	
2017-06-16 03:24:03,835 Epoch[48] Batch [1280]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087714,	
2017-06-16 03:24:10,424 Epoch[48] Batch [1290]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.087690,	
2017-06-16 03:24:17,486 Epoch[48] Batch [1300]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087710,	
2017-06-16 03:24:24,490 Epoch[48] Batch [1310]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.087778,	
2017-06-16 03:24:31,603 Epoch[48] Batch [1320]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087834,	
2017-06-16 03:24:39,374 Epoch[48] Batch [1330]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.087833,	
2017-06-16 03:24:47,203 Epoch[48] Batch [1340]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-16 03:24:53,432 Epoch[48] Batch [1350]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087843,	
2017-06-16 03:25:00,459 Epoch[48] Batch [1360]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.087826,	
2017-06-16 03:25:06,371 Epoch[48] Batch [1370]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087841,	
2017-06-16 03:25:13,774 Epoch[48] Batch [1380]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-16 03:25:21,070 Epoch[48] Batch [1390]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087837,	
2017-06-16 03:25:28,290 Epoch[48] Batch [1400]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087875,	
2017-06-16 03:25:36,289 Epoch[48] Batch [1410]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-16 03:25:44,255 Epoch[48] Batch [1420]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.087890,	
2017-06-16 03:25:51,095 Epoch[48] Batch [1430]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.087840,	
2017-06-16 03:25:58,809 Epoch[48] Batch [1440]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.087839,	
2017-06-16 03:26:06,286 Epoch[48] Batch [1450]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087845,	
2017-06-16 03:26:12,834 Epoch[48] Batch [1460]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087805,	
2017-06-16 03:26:20,579 Epoch[48] Batch [1470]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087793,	
2017-06-16 03:26:28,762 Epoch[48] Batch [1480]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.087882,	
2017-06-16 03:26:33,590 Epoch[48] Train-FCNLogLoss=0.087835
2017-06-16 03:26:33,590 Epoch[48] Time cost=1089.859
2017-06-16 03:26:34,372 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0049.params"
2017-06-16 03:26:36,619 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0049.states"
2017-06-16 03:26:45,453 Epoch[49] Batch [10]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.090988,	
2017-06-16 03:26:52,814 Epoch[49] Batch [20]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.090019,	
2017-06-16 03:27:01,186 Epoch[49] Batch [30]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.086981,	
2017-06-16 03:27:08,532 Epoch[49] Batch [40]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.085931,	
2017-06-16 03:27:16,707 Epoch[49] Batch [50]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.085275,	
2017-06-16 03:27:23,685 Epoch[49] Batch [60]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.084872,	
2017-06-16 03:27:31,529 Epoch[49] Batch [70]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.085316,	
2017-06-16 03:27:38,528 Epoch[49] Batch [80]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.085317,	
2017-06-16 03:27:45,339 Epoch[49] Batch [90]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087615,	
2017-06-16 03:27:53,173 Epoch[49] Batch [100]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.088041,	
2017-06-16 03:28:01,374 Epoch[49] Batch [110]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.088086,	
2017-06-16 03:28:09,060 Epoch[49] Batch [120]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088701,	
2017-06-16 03:28:17,153 Epoch[49] Batch [130]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-16 03:28:24,728 Epoch[49] Batch [140]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.088700,	
2017-06-16 03:28:32,458 Epoch[49] Batch [150]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.088694,	
2017-06-16 03:28:39,301 Epoch[49] Batch [160]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088889,	
2017-06-16 03:28:45,958 Epoch[49] Batch [170]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088933,	
2017-06-16 03:28:54,178 Epoch[49] Batch [180]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.088370,	
2017-06-16 03:29:01,739 Epoch[49] Batch [190]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088107,	
2017-06-16 03:29:09,044 Epoch[49] Batch [200]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087451,	
2017-06-16 03:29:17,060 Epoch[49] Batch [210]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087474,	
2017-06-16 03:29:24,089 Epoch[49] Batch [220]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-16 03:29:30,768 Epoch[49] Batch [230]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.087338,	
2017-06-16 03:29:39,290 Epoch[49] Batch [240]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.087631,	
2017-06-16 03:29:46,548 Epoch[49] Batch [250]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087789,	
2017-06-16 03:29:53,515 Epoch[49] Batch [260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.087190,	
2017-06-16 03:30:00,260 Epoch[49] Batch [270]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087179,	
2017-06-16 03:30:07,857 Epoch[49] Batch [280]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.087204,	
2017-06-16 03:30:15,289 Epoch[49] Batch [290]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-16 03:30:22,587 Epoch[49] Batch [300]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087330,	
2017-06-16 03:30:29,977 Epoch[49] Batch [310]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087297,	
2017-06-16 03:30:36,902 Epoch[49] Batch [320]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087479,	
2017-06-16 03:30:43,973 Epoch[49] Batch [330]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087238,	
2017-06-16 03:30:51,143 Epoch[49] Batch [340]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.087229,	
2017-06-16 03:30:59,133 Epoch[49] Batch [350]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.086919,	
2017-06-16 03:31:05,908 Epoch[49] Batch [360]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086897,	
2017-06-16 03:31:12,674 Epoch[49] Batch [370]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.086964,	
2017-06-16 03:31:19,650 Epoch[49] Batch [380]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.087008,	
2017-06-16 03:31:27,708 Epoch[49] Batch [390]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.087090,	
2017-06-16 03:31:35,268 Epoch[49] Batch [400]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.087136,	
2017-06-16 03:31:42,777 Epoch[49] Batch [410]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087310,	
2017-06-16 03:31:49,382 Epoch[49] Batch [420]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087480,	
2017-06-16 03:31:56,777 Epoch[49] Batch [430]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087673,	
2017-06-16 03:32:05,373 Epoch[49] Batch [440]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.087674,	
2017-06-16 03:32:13,246 Epoch[49] Batch [450]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-16 03:32:20,022 Epoch[49] Batch [460]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087730,	
2017-06-16 03:32:27,743 Epoch[49] Batch [470]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087709,	
2017-06-16 03:32:35,363 Epoch[49] Batch [480]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087937,	
2017-06-16 03:32:43,029 Epoch[49] Batch [490]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087896,	
2017-06-16 03:32:50,258 Epoch[49] Batch [500]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087882,	
2017-06-16 03:32:57,876 Epoch[49] Batch [510]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087929,	
2017-06-16 03:33:06,109 Epoch[49] Batch [520]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.087783,	
2017-06-16 03:33:14,113 Epoch[49] Batch [530]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087723,	
2017-06-16 03:33:21,355 Epoch[49] Batch [540]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087700,	
2017-06-16 03:33:28,804 Epoch[49] Batch [550]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087745,	
2017-06-16 03:33:35,889 Epoch[49] Batch [560]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087607,	
2017-06-16 03:33:43,605 Epoch[49] Batch [570]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087578,	
2017-06-16 03:33:49,880 Epoch[49] Batch [580]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.087691,	
2017-06-16 03:33:57,431 Epoch[49] Batch [590]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.087723,	
2017-06-16 03:34:04,823 Epoch[49] Batch [600]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087678,	
2017-06-16 03:34:12,315 Epoch[49] Batch [610]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087625,	
2017-06-16 03:34:19,616 Epoch[49] Batch [620]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087570,	
2017-06-16 03:34:27,766 Epoch[49] Batch [630]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.087522,	
2017-06-16 03:34:35,274 Epoch[49] Batch [640]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087441,	
2017-06-16 03:34:43,917 Epoch[49] Batch [650]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.087446,	
2017-06-16 03:34:50,331 Epoch[49] Batch [660]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.087397,	
2017-06-16 03:34:58,410 Epoch[49] Batch [670]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.087447,	
2017-06-16 03:35:06,619 Epoch[49] Batch [680]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.087354,	
2017-06-16 03:35:14,314 Epoch[49] Batch [690]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087358,	
2017-06-16 03:35:22,593 Epoch[49] Batch [700]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.087437,	
2017-06-16 03:35:30,328 Epoch[49] Batch [710]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087424,	
2017-06-16 03:35:37,398 Epoch[49] Batch [720]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-16 03:35:43,960 Epoch[49] Batch [730]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087415,	
2017-06-16 03:35:50,881 Epoch[49] Batch [740]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087309,	
2017-06-16 03:35:57,972 Epoch[49] Batch [750]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087320,	
2017-06-16 03:36:05,464 Epoch[49] Batch [760]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087329,	
2017-06-16 03:36:12,279 Epoch[49] Batch [770]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087313,	
2017-06-16 03:36:19,939 Epoch[49] Batch [780]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087286,	
2017-06-16 03:36:27,777 Epoch[49] Batch [790]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087241,	
2017-06-16 03:36:34,557 Epoch[49] Batch [800]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087215,	
2017-06-16 03:36:41,106 Epoch[49] Batch [810]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087232,	
2017-06-16 03:36:48,732 Epoch[49] Batch [820]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087237,	
2017-06-16 03:36:56,147 Epoch[49] Batch [830]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087225,	
2017-06-16 03:37:03,579 Epoch[49] Batch [840]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.087260,	
2017-06-16 03:37:11,392 Epoch[49] Batch [850]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.087223,	
2017-06-16 03:37:19,237 Epoch[49] Batch [860]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087194,	
2017-06-16 03:37:27,024 Epoch[49] Batch [870]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.087246,	
2017-06-16 03:37:33,116 Epoch[49] Batch [880]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087211,	
2017-06-16 03:37:40,200 Epoch[49] Batch [890]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087197,	
2017-06-16 03:37:46,356 Epoch[49] Batch [900]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087293,	
2017-06-16 03:37:54,345 Epoch[49] Batch [910]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.087259,	
2017-06-16 03:38:01,491 Epoch[49] Batch [920]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087286,	
2017-06-16 03:38:08,626 Epoch[49] Batch [930]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087396,	
2017-06-16 03:38:15,958 Epoch[49] Batch [940]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087430,	
2017-06-16 03:38:23,091 Epoch[49] Batch [950]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-16 03:38:31,540 Epoch[49] Batch [960]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.087374,	
2017-06-16 03:38:38,645 Epoch[49] Batch [970]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.087323,	
2017-06-16 03:38:44,771 Epoch[49] Batch [980]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.087396,	
2017-06-16 03:38:51,316 Epoch[49] Batch [990]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087399,	
2017-06-16 03:39:00,734 Epoch[49] Batch [1000]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.087490,	
2017-06-16 03:39:08,535 Epoch[49] Batch [1010]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087533,	
2017-06-16 03:39:15,952 Epoch[49] Batch [1020]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087550,	
2017-06-16 03:39:23,604 Epoch[49] Batch [1030]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087559,	
2017-06-16 03:39:32,030 Epoch[49] Batch [1040]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.087514,	
2017-06-16 03:39:39,598 Epoch[49] Batch [1050]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.087518,	
2017-06-16 03:39:46,478 Epoch[49] Batch [1060]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.087581,	
2017-06-16 03:39:54,001 Epoch[49] Batch [1070]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-16 03:40:02,295 Epoch[49] Batch [1080]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.087500,	
2017-06-16 03:40:09,769 Epoch[49] Batch [1090]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087486,	
2017-06-16 03:40:17,048 Epoch[49] Batch [1100]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.087465,	
2017-06-16 03:40:24,332 Epoch[49] Batch [1110]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.087478,	
2017-06-16 03:40:31,500 Epoch[49] Batch [1120]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.087440,	
2017-06-16 03:40:39,448 Epoch[49] Batch [1130]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087409,	
2017-06-16 03:40:47,211 Epoch[49] Batch [1140]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.087362,	
2017-06-16 03:40:54,835 Epoch[49] Batch [1150]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087340,	
2017-06-16 03:41:03,122 Epoch[49] Batch [1160]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.087249,	
2017-06-16 03:41:10,347 Epoch[49] Batch [1170]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087305,	
2017-06-16 03:41:17,365 Epoch[49] Batch [1180]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087306,	
2017-06-16 03:41:25,660 Epoch[49] Batch [1190]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.087323,	
2017-06-16 03:41:32,713 Epoch[49] Batch [1200]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.087307,	
2017-06-16 03:41:39,841 Epoch[49] Batch [1210]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087276,	
2017-06-16 03:41:47,590 Epoch[49] Batch [1220]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087199,	
2017-06-16 03:41:54,613 Epoch[49] Batch [1230]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087134,	
2017-06-16 03:42:02,007 Epoch[49] Batch [1240]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087155,	
2017-06-16 03:42:09,766 Epoch[49] Batch [1250]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087084,	
2017-06-16 03:42:16,918 Epoch[49] Batch [1260]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087094,	
2017-06-16 03:42:24,890 Epoch[49] Batch [1270]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.087043,	
2017-06-16 03:42:32,244 Epoch[49] Batch [1280]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.087112,	
2017-06-16 03:42:40,047 Epoch[49] Batch [1290]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087110,	
2017-06-16 03:42:47,141 Epoch[49] Batch [1300]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087161,	
2017-06-16 03:42:54,822 Epoch[49] Batch [1310]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087183,	
2017-06-16 03:43:01,538 Epoch[49] Batch [1320]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087159,	
2017-06-16 03:43:08,224 Epoch[49] Batch [1330]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087153,	
2017-06-16 03:43:14,180 Epoch[49] Batch [1340]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087158,	
2017-06-16 03:43:21,582 Epoch[49] Batch [1350]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087160,	
2017-06-16 03:43:29,106 Epoch[49] Batch [1360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.087093,	
2017-06-16 03:43:35,672 Epoch[49] Batch [1370]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.087113,	
2017-06-16 03:43:41,984 Epoch[49] Batch [1380]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.087045,	
2017-06-16 03:43:49,140 Epoch[49] Batch [1390]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087037,	
2017-06-16 03:43:56,408 Epoch[49] Batch [1400]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.087070,	
2017-06-16 03:44:03,606 Epoch[49] Batch [1410]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087029,	
2017-06-16 03:44:10,521 Epoch[49] Batch [1420]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087020,	
2017-06-16 03:44:17,655 Epoch[49] Batch [1430]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-16 03:44:25,156 Epoch[49] Batch [1440]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087046,	
2017-06-16 03:44:32,997 Epoch[49] Batch [1450]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087028,	
2017-06-16 03:44:41,354 Epoch[49] Batch [1460]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.086977,	
2017-06-16 03:44:48,506 Epoch[49] Batch [1470]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086979,	
2017-06-16 03:44:55,600 Epoch[49] Batch [1480]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086949,	
2017-06-16 03:44:59,872 Epoch[49] Train-FCNLogLoss=0.086921
2017-06-16 03:44:59,872 Epoch[49] Time cost=1103.253
2017-06-16 03:45:00,555 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0050.params"
2017-06-16 03:45:02,722 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0050.states"
2017-06-16 03:45:10,716 Epoch[50] Batch [10]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.089383,	
2017-06-16 03:45:18,273 Epoch[50] Batch [20]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.091889,	
2017-06-16 03:45:24,528 Epoch[50] Batch [30]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.089640,	
2017-06-16 03:45:32,498 Epoch[50] Batch [40]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-16 03:45:39,767 Epoch[50] Batch [50]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.089083,	
2017-06-16 03:45:46,342 Epoch[50] Batch [60]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.090080,	
2017-06-16 03:45:53,456 Epoch[50] Batch [70]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.089181,	
2017-06-16 03:46:01,124 Epoch[50] Batch [80]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087995,	
2017-06-16 03:46:07,242 Epoch[50] Batch [90]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087993,	
2017-06-16 03:46:14,059 Epoch[50] Batch [100]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.088296,	
2017-06-16 03:46:20,713 Epoch[50] Batch [110]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087934,	
2017-06-16 03:46:28,322 Epoch[50] Batch [120]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.087976,	
2017-06-16 03:46:35,514 Epoch[50] Batch [130]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087372,	
2017-06-16 03:46:42,507 Epoch[50] Batch [140]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087457,	
2017-06-16 03:46:49,592 Epoch[50] Batch [150]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-16 03:46:56,894 Epoch[50] Batch [160]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086952,	
2017-06-16 03:47:04,190 Epoch[50] Batch [170]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086999,	
2017-06-16 03:47:12,076 Epoch[50] Batch [180]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087326,	
2017-06-16 03:47:19,359 Epoch[50] Batch [190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.087316,	
2017-06-16 03:47:26,606 Epoch[50] Batch [200]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087041,	
2017-06-16 03:47:34,267 Epoch[50] Batch [210]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087129,	
2017-06-16 03:47:40,874 Epoch[50] Batch [220]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.087058,	
2017-06-16 03:47:48,455 Epoch[50] Batch [230]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.087107,	
2017-06-16 03:47:55,662 Epoch[50] Batch [240]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086838,	
2017-06-16 03:48:02,444 Epoch[50] Batch [250]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086547,	
2017-06-16 03:48:09,606 Epoch[50] Batch [260]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086647,	
2017-06-16 03:48:17,487 Epoch[50] Batch [270]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.086845,	
2017-06-16 03:48:23,511 Epoch[50] Batch [280]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.086618,	
2017-06-16 03:48:29,697 Epoch[50] Batch [290]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.086479,	
2017-06-16 03:48:36,940 Epoch[50] Batch [300]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086429,	
2017-06-16 03:48:44,044 Epoch[50] Batch [310]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086717,	
2017-06-16 03:48:52,681 Epoch[50] Batch [320]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.086298,	
2017-06-16 03:48:59,914 Epoch[50] Batch [330]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086341,	
2017-06-16 03:49:07,498 Epoch[50] Batch [340]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.086460,	
2017-06-16 03:49:14,785 Epoch[50] Batch [350]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086500,	
2017-06-16 03:49:22,887 Epoch[50] Batch [360]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.086529,	
2017-06-16 03:49:31,101 Epoch[50] Batch [370]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.086609,	
2017-06-16 03:49:38,186 Epoch[50] Batch [380]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086714,	
2017-06-16 03:49:45,052 Epoch[50] Batch [390]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086800,	
2017-06-16 03:49:51,749 Epoch[50] Batch [400]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086852,	
2017-06-16 03:49:58,679 Epoch[50] Batch [410]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.086949,	
2017-06-16 03:50:06,950 Epoch[50] Batch [420]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.086961,	
2017-06-16 03:50:14,155 Epoch[50] Batch [430]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086922,	
2017-06-16 03:50:22,061 Epoch[50] Batch [440]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.086951,	
2017-06-16 03:50:29,452 Epoch[50] Batch [450]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087008,	
2017-06-16 03:50:35,813 Epoch[50] Batch [460]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.086888,	
2017-06-16 03:50:42,357 Epoch[50] Batch [470]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.086838,	
2017-06-16 03:50:48,856 Epoch[50] Batch [480]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.086820,	
2017-06-16 03:50:56,161 Epoch[50] Batch [490]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086793,	
2017-06-16 03:51:04,342 Epoch[50] Batch [500]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.086836,	
2017-06-16 03:51:11,518 Epoch[50] Batch [510]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086868,	
2017-06-16 03:51:18,778 Epoch[50] Batch [520]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087074,	
2017-06-16 03:51:26,579 Epoch[50] Batch [530]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087090,	
2017-06-16 03:51:33,423 Epoch[50] Batch [540]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.087125,	
2017-06-16 03:51:41,322 Epoch[50] Batch [550]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087153,	
2017-06-16 03:51:49,273 Epoch[50] Batch [560]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.087110,	
2017-06-16 03:51:55,967 Epoch[50] Batch [570]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.086975,	
2017-06-16 03:52:02,608 Epoch[50] Batch [580]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087100,	
2017-06-16 03:52:10,777 Epoch[50] Batch [590]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.087067,	
2017-06-16 03:52:17,605 Epoch[50] Batch [600]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.087265,	
2017-06-16 03:52:24,726 Epoch[50] Batch [610]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087150,	
2017-06-16 03:52:32,697 Epoch[50] Batch [620]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.087190,	
2017-06-16 03:52:41,356 Epoch[50] Batch [630]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.086964,	
2017-06-16 03:52:50,542 Epoch[50] Batch [640]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.087070,	
2017-06-16 03:52:57,095 Epoch[50] Batch [650]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087075,	
2017-06-16 03:53:03,996 Epoch[50] Batch [660]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086925,	
2017-06-16 03:53:11,371 Epoch[50] Batch [670]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.086897,	
2017-06-16 03:53:18,586 Epoch[50] Batch [680]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086890,	
2017-06-16 03:53:25,560 Epoch[50] Batch [690]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.087044,	
2017-06-16 03:53:32,140 Epoch[50] Batch [700]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087088,	
2017-06-16 03:53:39,786 Epoch[50] Batch [710]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087070,	
2017-06-16 03:53:47,506 Epoch[50] Batch [720]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087088,	
2017-06-16 03:53:55,086 Epoch[50] Batch [730]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.087029,	
2017-06-16 03:54:01,947 Epoch[50] Batch [740]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087157,	
2017-06-16 03:54:10,387 Epoch[50] Batch [750]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.087162,	
2017-06-16 03:54:18,240 Epoch[50] Batch [760]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087139,	
2017-06-16 03:54:27,034 Epoch[50] Batch [770]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.087013,	
2017-06-16 03:54:34,748 Epoch[50] Batch [780]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.086971,	
2017-06-16 03:54:41,974 Epoch[50] Batch [790]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086978,	
2017-06-16 03:54:49,103 Epoch[50] Batch [800]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086898,	
2017-06-16 03:54:56,580 Epoch[50] Batch [810]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086822,	
2017-06-16 03:55:04,437 Epoch[50] Batch [820]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.086813,	
2017-06-16 03:55:12,686 Epoch[50] Batch [830]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.086801,	
2017-06-16 03:55:19,740 Epoch[50] Batch [840]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086848,	
2017-06-16 03:55:27,321 Epoch[50] Batch [850]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.086750,	
2017-06-16 03:55:34,861 Epoch[50] Batch [860]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086755,	
2017-06-16 03:55:44,169 Epoch[50] Batch [870]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.086891,	
2017-06-16 03:55:52,407 Epoch[50] Batch [880]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.086825,	
2017-06-16 03:56:00,069 Epoch[50] Batch [890]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.086841,	
2017-06-16 03:56:06,766 Epoch[50] Batch [900]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086824,	
2017-06-16 03:56:13,674 Epoch[50] Batch [910]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086723,	
2017-06-16 03:56:21,524 Epoch[50] Batch [920]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086622,	
2017-06-16 03:56:29,595 Epoch[50] Batch [930]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.086658,	
2017-06-16 03:56:37,227 Epoch[50] Batch [940]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.086574,	
2017-06-16 03:56:45,163 Epoch[50] Batch [950]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.086536,	
2017-06-16 03:56:51,805 Epoch[50] Batch [960]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.086639,	
2017-06-16 03:56:58,259 Epoch[50] Batch [970]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.086659,	
2017-06-16 03:57:06,454 Epoch[50] Batch [980]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.086652,	
2017-06-16 03:57:13,599 Epoch[50] Batch [990]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086652,	
2017-06-16 03:57:21,333 Epoch[50] Batch [1000]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.086726,	
2017-06-16 03:57:29,133 Epoch[50] Batch [1010]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.086699,	
2017-06-16 03:57:36,650 Epoch[50] Batch [1020]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.086735,	
2017-06-16 03:57:45,424 Epoch[50] Batch [1030]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.086791,	
2017-06-16 03:57:53,167 Epoch[50] Batch [1040]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.086839,	
2017-06-16 03:58:01,028 Epoch[50] Batch [1050]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.086755,	
2017-06-16 03:58:08,356 Epoch[50] Batch [1060]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.086763,	
2017-06-16 03:58:16,418 Epoch[50] Batch [1070]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.086699,	
2017-06-16 03:58:23,598 Epoch[50] Batch [1080]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086696,	
2017-06-16 03:58:30,530 Epoch[50] Batch [1090]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.086651,	
2017-06-16 03:58:38,825 Epoch[50] Batch [1100]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.086611,	
2017-06-16 03:58:46,658 Epoch[50] Batch [1110]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.086591,	
2017-06-16 03:58:54,127 Epoch[50] Batch [1120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086596,	
2017-06-16 03:59:02,105 Epoch[50] Batch [1130]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.086638,	
2017-06-16 03:59:09,551 Epoch[50] Batch [1140]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086622,	
2017-06-16 03:59:18,085 Epoch[50] Batch [1150]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.086656,	
2017-06-16 03:59:25,879 Epoch[50] Batch [1160]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.086657,	
2017-06-16 03:59:33,175 Epoch[50] Batch [1170]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086650,	
2017-06-16 03:59:41,467 Epoch[50] Batch [1180]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.086593,	
2017-06-16 03:59:48,485 Epoch[50] Batch [1190]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086611,	
2017-06-16 03:59:56,832 Epoch[50] Batch [1200]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.086661,	
2017-06-16 04:00:03,923 Epoch[50] Batch [1210]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086662,	
2017-06-16 04:00:11,331 Epoch[50] Batch [1220]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.086672,	
2017-06-16 04:00:18,856 Epoch[50] Batch [1230]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.086724,	
2017-06-16 04:00:26,480 Epoch[50] Batch [1240]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.086775,	
2017-06-16 04:00:33,716 Epoch[50] Batch [1250]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086911,	
2017-06-16 04:00:40,628 Epoch[50] Batch [1260]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086976,	
2017-06-16 04:00:49,242 Epoch[50] Batch [1270]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.087005,	
2017-06-16 04:00:56,385 Epoch[50] Batch [1280]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086977,	
2017-06-16 04:01:04,494 Epoch[50] Batch [1290]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.086972,	
2017-06-16 04:01:11,049 Epoch[50] Batch [1300]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.086913,	
2017-06-16 04:01:19,012 Epoch[50] Batch [1310]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.086908,	
2017-06-16 04:01:26,214 Epoch[50] Batch [1320]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086900,	
2017-06-16 04:01:33,937 Epoch[50] Batch [1330]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.086877,	
2017-06-16 04:01:40,768 Epoch[50] Batch [1340]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.086884,	
2017-06-16 04:01:48,450 Epoch[50] Batch [1350]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.086889,	
2017-06-16 04:01:56,400 Epoch[50] Batch [1360]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.086869,	
2017-06-16 04:02:04,993 Epoch[50] Batch [1370]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.086845,	
2017-06-16 04:02:13,172 Epoch[50] Batch [1380]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.086835,	
2017-06-16 04:02:21,718 Epoch[50] Batch [1390]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.086827,	
2017-06-16 04:02:29,561 Epoch[50] Batch [1400]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086776,	
2017-06-16 04:02:37,064 Epoch[50] Batch [1410]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.086780,	
2017-06-16 04:02:44,850 Epoch[50] Batch [1420]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.086715,	
2017-06-16 04:02:52,459 Epoch[50] Batch [1430]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.086750,	
2017-06-16 04:03:00,251 Epoch[50] Batch [1440]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.086711,	
2017-06-16 04:03:08,424 Epoch[50] Batch [1450]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.086655,	
2017-06-16 04:03:15,138 Epoch[50] Batch [1460]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.086675,	
2017-06-16 04:03:22,133 Epoch[50] Batch [1470]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086696,	
2017-06-16 04:03:29,532 Epoch[50] Batch [1480]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.086713,	
2017-06-16 04:03:33,830 Epoch[50] Train-FCNLogLoss=0.086734
2017-06-16 04:03:33,830 Epoch[50] Time cost=1111.108
2017-06-16 04:03:34,634 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0051.params"
2017-06-16 04:03:36,924 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0051.states"
2017-06-16 04:03:45,206 Epoch[51] Batch [10]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.079521,	
2017-06-16 04:03:52,248 Epoch[51] Batch [20]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.078379,	
2017-06-16 04:03:59,156 Epoch[51] Batch [30]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.075635,	
2017-06-16 04:04:06,935 Epoch[51] Batch [40]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.077457,	
2017-06-16 04:04:14,309 Epoch[51] Batch [50]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.078573,	
2017-06-16 04:04:21,177 Epoch[51] Batch [60]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.080154,	
2017-06-16 04:04:27,841 Epoch[51] Batch [70]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.081986,	
2017-06-16 04:04:34,212 Epoch[51] Batch [80]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.081782,	
2017-06-16 04:04:40,683 Epoch[51] Batch [90]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.083422,	
2017-06-16 04:04:48,282 Epoch[51] Batch [100]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.083358,	
2017-06-16 04:04:54,674 Epoch[51] Batch [110]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.084323,	
2017-06-16 04:05:01,456 Epoch[51] Batch [120]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.085136,	
2017-06-16 04:05:09,149 Epoch[51] Batch [130]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.086659,	
2017-06-16 04:05:16,267 Epoch[51] Batch [140]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087313,	
2017-06-16 04:05:23,375 Epoch[51] Batch [150]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.087075,	
2017-06-16 04:05:29,352 Epoch[51] Batch [160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087928,	
2017-06-16 04:05:37,068 Epoch[51] Batch [170]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087801,	
2017-06-16 04:05:44,643 Epoch[51] Batch [180]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.088108,	
2017-06-16 04:05:51,299 Epoch[51] Batch [190]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087485,	
2017-06-16 04:05:58,773 Epoch[51] Batch [200]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087316,	
2017-06-16 04:06:04,752 Epoch[51] Batch [210]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087284,	
2017-06-16 04:06:12,097 Epoch[51] Batch [220]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.086876,	
2017-06-16 04:06:18,423 Epoch[51] Batch [230]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086904,	
2017-06-16 04:06:26,844 Epoch[51] Batch [240]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.086962,	
2017-06-16 04:06:34,127 Epoch[51] Batch [250]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-16 04:06:41,034 Epoch[51] Batch [260]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.087207,	
2017-06-16 04:06:48,798 Epoch[51] Batch [270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.086932,	
2017-06-16 04:06:55,411 Epoch[51] Batch [280]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.086630,	
2017-06-16 04:07:01,985 Epoch[51] Batch [290]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087073,	
2017-06-16 04:07:08,998 Epoch[51] Batch [300]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086980,	
2017-06-16 04:07:15,267 Epoch[51] Batch [310]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.086776,	
2017-06-16 04:07:21,352 Epoch[51] Batch [320]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.086940,	
2017-06-16 04:07:28,045 Epoch[51] Batch [330]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.086842,	
2017-06-16 04:07:34,271 Epoch[51] Batch [340]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.086996,	
2017-06-16 04:07:40,760 Epoch[51] Batch [350]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086590,	
2017-06-16 04:07:48,363 Epoch[51] Batch [360]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.086693,	
2017-06-16 04:07:55,484 Epoch[51] Batch [370]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.086788,	
2017-06-16 04:08:02,924 Epoch[51] Batch [380]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.086727,	
2017-06-16 04:08:09,482 Epoch[51] Batch [390]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.086844,	
2017-06-16 04:08:15,830 Epoch[51] Batch [400]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086660,	
2017-06-16 04:08:23,081 Epoch[51] Batch [410]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086532,	
2017-06-16 04:08:29,715 Epoch[51] Batch [420]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.086678,	
2017-06-16 04:08:36,202 Epoch[51] Batch [430]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086762,	
2017-06-16 04:08:42,871 Epoch[51] Batch [440]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086505,	
2017-06-16 04:08:49,955 Epoch[51] Batch [450]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086522,	
2017-06-16 04:08:57,243 Epoch[51] Batch [460]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086514,	
2017-06-16 04:09:03,969 Epoch[51] Batch [470]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086745,	
2017-06-16 04:09:10,767 Epoch[51] Batch [480]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086696,	
2017-06-16 04:09:17,460 Epoch[51] Batch [490]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.086760,	
2017-06-16 04:09:25,371 Epoch[51] Batch [500]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.086868,	
2017-06-16 04:09:32,589 Epoch[51] Batch [510]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086843,	
2017-06-16 04:09:40,347 Epoch[51] Batch [520]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.086766,	
2017-06-16 04:09:48,123 Epoch[51] Batch [530]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.086603,	
2017-06-16 04:09:55,422 Epoch[51] Batch [540]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086578,	
2017-06-16 04:10:02,276 Epoch[51] Batch [550]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086493,	
2017-06-16 04:10:09,407 Epoch[51] Batch [560]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086259,	
2017-06-16 04:10:16,622 Epoch[51] Batch [570]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086127,	
2017-06-16 04:10:23,953 Epoch[51] Batch [580]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.086362,	
2017-06-16 04:10:32,422 Epoch[51] Batch [590]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.086465,	
2017-06-16 04:10:39,617 Epoch[51] Batch [600]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086540,	
2017-06-16 04:10:47,575 Epoch[51] Batch [610]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.086614,	
2017-06-16 04:10:54,368 Epoch[51] Batch [620]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086678,	
2017-06-16 04:11:00,619 Epoch[51] Batch [630]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086671,	
2017-06-16 04:11:08,720 Epoch[51] Batch [640]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.086712,	
2017-06-16 04:11:18,124 Epoch[51] Batch [650]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.086726,	
2017-06-16 04:11:23,974 Epoch[51] Batch [660]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086675,	
2017-06-16 04:11:31,511 Epoch[51] Batch [670]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086888,	
2017-06-16 04:11:39,715 Epoch[51] Batch [680]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.086913,	
2017-06-16 04:11:47,864 Epoch[51] Batch [690]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.087046,	
2017-06-16 04:11:56,778 Epoch[51] Batch [700]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.087020,	
2017-06-16 04:12:04,120 Epoch[51] Batch [710]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.087149,	
2017-06-16 04:12:11,329 Epoch[51] Batch [720]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087140,	
2017-06-16 04:12:18,562 Epoch[51] Batch [730]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087239,	
2017-06-16 04:12:25,772 Epoch[51] Batch [740]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087297,	
2017-06-16 04:12:32,364 Epoch[51] Batch [750]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.087307,	
2017-06-16 04:12:39,184 Epoch[51] Batch [760]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087176,	
2017-06-16 04:12:46,577 Epoch[51] Batch [770]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087065,	
2017-06-16 04:12:54,198 Epoch[51] Batch [780]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.086992,	
2017-06-16 04:13:00,588 Epoch[51] Batch [790]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.087119,	
2017-06-16 04:13:07,025 Epoch[51] Batch [800]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087103,	
2017-06-16 04:13:14,688 Epoch[51] Batch [810]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087008,	
2017-06-16 04:13:23,419 Epoch[51] Batch [820]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.087009,	
2017-06-16 04:13:30,157 Epoch[51] Batch [830]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.086925,	
2017-06-16 04:13:37,217 Epoch[51] Batch [840]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086977,	
2017-06-16 04:13:44,421 Epoch[51] Batch [850]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086824,	
2017-06-16 04:13:51,563 Epoch[51] Batch [860]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086743,	
2017-06-16 04:13:59,139 Epoch[51] Batch [870]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.086688,	
2017-06-16 04:14:06,073 Epoch[51] Batch [880]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.086726,	
2017-06-16 04:14:14,192 Epoch[51] Batch [890]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.086763,	
2017-06-16 04:14:21,362 Epoch[51] Batch [900]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086730,	
2017-06-16 04:14:28,338 Epoch[51] Batch [910]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086697,	
2017-06-16 04:14:34,595 Epoch[51] Batch [920]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.086642,	
2017-06-16 04:14:43,052 Epoch[51] Batch [930]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.086541,	
2017-06-16 04:14:50,607 Epoch[51] Batch [940]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.086593,	
2017-06-16 04:14:58,376 Epoch[51] Batch [950]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.086674,	
2017-06-16 04:15:05,198 Epoch[51] Batch [960]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.086717,	
2017-06-16 04:15:13,121 Epoch[51] Batch [970]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086714,	
2017-06-16 04:15:20,144 Epoch[51] Batch [980]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086736,	
2017-06-16 04:15:28,303 Epoch[51] Batch [990]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.086755,	
2017-06-16 04:15:34,826 Epoch[51] Batch [1000]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.086718,	
2017-06-16 04:15:42,439 Epoch[51] Batch [1010]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.086671,	
2017-06-16 04:15:48,935 Epoch[51] Batch [1020]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.086667,	
2017-06-16 04:15:56,430 Epoch[51] Batch [1030]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.086648,	
2017-06-16 04:16:04,602 Epoch[51] Batch [1040]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.086618,	
2017-06-16 04:16:12,154 Epoch[51] Batch [1050]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.086605,	
2017-06-16 04:16:19,624 Epoch[51] Batch [1060]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086590,	
2017-06-16 04:16:26,917 Epoch[51] Batch [1070]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086575,	
2017-06-16 04:16:34,229 Epoch[51] Batch [1080]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.086546,	
2017-06-16 04:16:41,692 Epoch[51] Batch [1090]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086489,	
2017-06-16 04:16:48,456 Epoch[51] Batch [1100]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.086498,	
2017-06-16 04:16:56,561 Epoch[51] Batch [1110]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.086643,	
2017-06-16 04:17:03,123 Epoch[51] Batch [1120]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.086627,	
2017-06-16 04:17:09,660 Epoch[51] Batch [1130]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.086589,	
2017-06-16 04:17:17,433 Epoch[51] Batch [1140]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.086580,	
2017-06-16 04:17:24,660 Epoch[51] Batch [1150]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086553,	
2017-06-16 04:17:31,962 Epoch[51] Batch [1160]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086584,	
2017-06-16 04:17:39,388 Epoch[51] Batch [1170]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.086575,	
2017-06-16 04:17:46,581 Epoch[51] Batch [1180]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086502,	
2017-06-16 04:17:53,485 Epoch[51] Batch [1190]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086599,	
2017-06-16 04:18:00,350 Epoch[51] Batch [1200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086642,	
2017-06-16 04:18:08,359 Epoch[51] Batch [1210]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.086640,	
2017-06-16 04:18:15,321 Epoch[51] Batch [1220]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086620,	
2017-06-16 04:18:21,419 Epoch[51] Batch [1230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086581,	
2017-06-16 04:18:30,154 Epoch[51] Batch [1240]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.086600,	
2017-06-16 04:18:37,623 Epoch[51] Batch [1250]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086578,	
2017-06-16 04:18:44,653 Epoch[51] Batch [1260]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086659,	
2017-06-16 04:18:51,874 Epoch[51] Batch [1270]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086678,	
2017-06-16 04:18:59,417 Epoch[51] Batch [1280]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.086730,	
2017-06-16 04:19:06,627 Epoch[51] Batch [1290]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086681,	
2017-06-16 04:19:14,090 Epoch[51] Batch [1300]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086748,	
2017-06-16 04:19:20,811 Epoch[51] Batch [1310]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086748,	
2017-06-16 04:19:28,657 Epoch[51] Batch [1320]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086753,	
2017-06-16 04:19:36,468 Epoch[51] Batch [1330]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.086754,	
2017-06-16 04:19:43,560 Epoch[51] Batch [1340]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086798,	
2017-06-16 04:19:51,964 Epoch[51] Batch [1350]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.086865,	
2017-06-16 04:19:59,459 Epoch[51] Batch [1360]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.086890,	
2017-06-16 04:20:06,876 Epoch[51] Batch [1370]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.086831,	
2017-06-16 04:20:13,672 Epoch[51] Batch [1380]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.086829,	
2017-06-16 04:20:22,963 Epoch[51] Batch [1390]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.086800,	
2017-06-16 04:20:30,848 Epoch[51] Batch [1400]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.086794,	
2017-06-16 04:20:37,668 Epoch[51] Batch [1410]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.086815,	
2017-06-16 04:20:45,892 Epoch[51] Batch [1420]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.086825,	
2017-06-16 04:20:54,861 Epoch[51] Batch [1430]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.086837,	
2017-06-16 04:21:02,694 Epoch[51] Batch [1440]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.086821,	
2017-06-16 04:21:09,450 Epoch[51] Batch [1450]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086788,	
2017-06-16 04:21:16,981 Epoch[51] Batch [1460]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086737,	
2017-06-16 04:21:24,653 Epoch[51] Batch [1470]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.086794,	
2017-06-16 04:21:31,221 Epoch[51] Batch [1480]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.086818,	
2017-06-16 04:21:36,243 Epoch[51] Train-FCNLogLoss=0.086774
2017-06-16 04:21:36,243 Epoch[51] Time cost=1079.318
2017-06-16 04:21:37,320 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0052.params"
2017-06-16 04:21:40,089 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0052.states"
2017-06-16 04:21:48,547 Epoch[52] Batch [10]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.081751,	
2017-06-16 04:21:56,152 Epoch[52] Batch [20]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.085849,	
2017-06-16 04:22:04,035 Epoch[52] Batch [30]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.085994,	
2017-06-16 04:22:12,142 Epoch[52] Batch [40]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.083499,	
2017-06-16 04:22:19,761 Epoch[52] Batch [50]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.085010,	
2017-06-16 04:22:26,778 Epoch[52] Batch [60]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.084411,	
2017-06-16 04:22:33,891 Epoch[52] Batch [70]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.084089,	
2017-06-16 04:22:40,885 Epoch[52] Batch [80]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.083934,	
2017-06-16 04:22:48,388 Epoch[52] Batch [90]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.085391,	
2017-06-16 04:22:56,498 Epoch[52] Batch [100]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.086035,	
2017-06-16 04:23:03,272 Epoch[52] Batch [110]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.085795,	
2017-06-16 04:23:10,969 Epoch[52] Batch [120]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.086043,	
2017-06-16 04:23:18,073 Epoch[52] Batch [130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.085303,	
2017-06-16 04:23:27,057 Epoch[52] Batch [140]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.085608,	
2017-06-16 04:23:33,656 Epoch[52] Batch [150]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.085750,	
2017-06-16 04:23:40,659 Epoch[52] Batch [160]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086085,	
2017-06-16 04:23:49,444 Epoch[52] Batch [170]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.085988,	
2017-06-16 04:23:56,354 Epoch[52] Batch [180]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.085780,	
2017-06-16 04:24:03,977 Epoch[52] Batch [190]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.085843,	
2017-06-16 04:24:11,117 Epoch[52] Batch [200]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.085731,	
2017-06-16 04:24:17,445 Epoch[52] Batch [210]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.085482,	
2017-06-16 04:24:26,286 Epoch[52] Batch [220]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.085561,	
2017-06-16 04:24:33,556 Epoch[52] Batch [230]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.085461,	
2017-06-16 04:24:41,594 Epoch[52] Batch [240]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.085326,	
2017-06-16 04:24:48,910 Epoch[52] Batch [250]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.085247,	
2017-06-16 04:24:56,324 Epoch[52] Batch [260]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.085504,	
2017-06-16 04:25:04,389 Epoch[52] Batch [270]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.085677,	
2017-06-16 04:25:11,384 Epoch[52] Batch [280]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.085703,	
2017-06-16 04:25:19,840 Epoch[52] Batch [290]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.086223,	
2017-06-16 04:25:26,850 Epoch[52] Batch [300]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086195,	
2017-06-16 04:25:35,431 Epoch[52] Batch [310]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.086467,	
2017-06-16 04:25:43,433 Epoch[52] Batch [320]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.086668,	
2017-06-16 04:25:50,400 Epoch[52] Batch [330]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.086953,	
2017-06-16 04:25:57,418 Epoch[52] Batch [340]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087051,	
2017-06-16 04:26:04,904 Epoch[52] Batch [350]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.086923,	
2017-06-16 04:26:12,928 Epoch[52] Batch [360]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087085,	
2017-06-16 04:26:19,967 Epoch[52] Batch [370]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087024,	
2017-06-16 04:26:27,858 Epoch[52] Batch [380]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.086849,	
2017-06-16 04:26:35,218 Epoch[52] Batch [390]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-16 04:26:42,110 Epoch[52] Batch [400]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086971,	
2017-06-16 04:26:49,384 Epoch[52] Batch [410]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.087043,	
2017-06-16 04:26:58,093 Epoch[52] Batch [420]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.087167,	
2017-06-16 04:27:06,133 Epoch[52] Batch [430]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.087229,	
2017-06-16 04:27:13,850 Epoch[52] Batch [440]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087097,	
2017-06-16 04:27:21,911 Epoch[52] Batch [450]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.087044,	
2017-06-16 04:27:28,225 Epoch[52] Batch [460]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087228,	
2017-06-16 04:27:35,322 Epoch[52] Batch [470]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087103,	
2017-06-16 04:27:41,338 Epoch[52] Batch [480]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.087021,	
2017-06-16 04:27:49,141 Epoch[52] Batch [490]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087137,	
2017-06-16 04:27:55,891 Epoch[52] Batch [500]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087113,	
2017-06-16 04:28:05,190 Epoch[52] Batch [510]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.087081,	
2017-06-16 04:28:13,033 Epoch[52] Batch [520]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087059,	
2017-06-16 04:28:20,892 Epoch[52] Batch [530]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087051,	
2017-06-16 04:28:29,331 Epoch[52] Batch [540]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.087127,	
2017-06-16 04:28:38,020 Epoch[52] Batch [550]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.087082,	
2017-06-16 04:28:45,134 Epoch[52] Batch [560]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.086970,	
2017-06-16 04:28:53,920 Epoch[52] Batch [570]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.086832,	
2017-06-16 04:29:01,889 Epoch[52] Batch [580]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.086955,	
2017-06-16 04:29:10,359 Epoch[52] Batch [590]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.087304,	
2017-06-16 04:29:18,851 Epoch[52] Batch [600]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.087092,	
2017-06-16 04:29:26,326 Epoch[52] Batch [610]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087107,	
2017-06-16 04:29:34,060 Epoch[52] Batch [620]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087001,	
2017-06-16 04:29:41,752 Epoch[52] Batch [630]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.086948,	
2017-06-16 04:29:49,311 Epoch[52] Batch [640]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.087043,	
2017-06-16 04:29:56,995 Epoch[52] Batch [650]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087142,	
2017-06-16 04:30:04,439 Epoch[52] Batch [660]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087158,	
2017-06-16 04:30:12,687 Epoch[52] Batch [670]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.087120,	
2017-06-16 04:30:20,818 Epoch[52] Batch [680]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.087094,	
2017-06-16 04:30:28,558 Epoch[52] Batch [690]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-16 04:30:36,160 Epoch[52] Batch [700]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.087014,	
2017-06-16 04:30:43,118 Epoch[52] Batch [710]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087101,	
2017-06-16 04:30:51,841 Epoch[52] Batch [720]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.086989,	
2017-06-16 04:30:59,616 Epoch[52] Batch [730]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.086895,	
2017-06-16 04:31:07,230 Epoch[52] Batch [740]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.086740,	
2017-06-16 04:31:15,168 Epoch[52] Batch [750]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.086768,	
2017-06-16 04:31:22,515 Epoch[52] Batch [760]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.086755,	
2017-06-16 04:31:29,497 Epoch[52] Batch [770]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086777,	
2017-06-16 04:31:37,542 Epoch[52] Batch [780]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.086758,	
2017-06-16 04:31:45,887 Epoch[52] Batch [790]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.086749,	
2017-06-16 04:31:54,052 Epoch[52] Batch [800]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.086867,	
2017-06-16 04:32:02,188 Epoch[52] Batch [810]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.086908,	
2017-06-16 04:32:09,864 Epoch[52] Batch [820]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.086872,	
2017-06-16 04:32:17,516 Epoch[52] Batch [830]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.086746,	
2017-06-16 04:32:25,344 Epoch[52] Batch [840]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.086720,	
2017-06-16 04:32:33,734 Epoch[52] Batch [850]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.086829,	
2017-06-16 04:32:41,648 Epoch[52] Batch [860]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086833,	
2017-06-16 04:32:49,482 Epoch[52] Batch [870]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.086809,	
2017-06-16 04:32:56,465 Epoch[52] Batch [880]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086739,	
2017-06-16 04:33:04,382 Epoch[52] Batch [890]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086822,	
2017-06-16 04:33:11,949 Epoch[52] Batch [900]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.086796,	
2017-06-16 04:33:20,236 Epoch[52] Batch [910]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.086797,	
2017-06-16 04:33:28,386 Epoch[52] Batch [920]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.086765,	
2017-06-16 04:33:35,255 Epoch[52] Batch [930]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.086756,	
2017-06-16 04:33:43,759 Epoch[52] Batch [940]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.086851,	
2017-06-16 04:33:51,905 Epoch[52] Batch [950]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.086870,	
2017-06-16 04:33:59,843 Epoch[52] Batch [960]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.086750,	
2017-06-16 04:34:07,956 Epoch[52] Batch [970]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.086829,	
2017-06-16 04:34:16,037 Epoch[52] Batch [980]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.086873,	
2017-06-16 04:34:24,418 Epoch[52] Batch [990]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.086851,	
2017-06-16 04:34:32,414 Epoch[52] Batch [1000]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.086807,	
2017-06-16 04:34:39,929 Epoch[52] Batch [1010]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.086769,	
2017-06-16 04:34:47,493 Epoch[52] Batch [1020]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.086723,	
2017-06-16 04:34:55,510 Epoch[52] Batch [1030]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.086757,	
2017-06-16 04:35:04,425 Epoch[52] Batch [1040]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.086762,	
2017-06-16 04:35:11,600 Epoch[52] Batch [1050]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086720,	
2017-06-16 04:35:18,905 Epoch[52] Batch [1060]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086646,	
2017-06-16 04:35:27,065 Epoch[52] Batch [1070]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.086690,	
2017-06-16 04:35:34,766 Epoch[52] Batch [1080]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.086670,	
2017-06-16 04:35:42,015 Epoch[52] Batch [1090]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086718,	
2017-06-16 04:35:49,885 Epoch[52] Batch [1100]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.086843,	
2017-06-16 04:35:58,056 Epoch[52] Batch [1110]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.086799,	
2017-06-16 04:36:05,629 Epoch[52] Batch [1120]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.086931,	
2017-06-16 04:36:12,882 Epoch[52] Batch [1130]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.086893,	
2017-06-16 04:36:19,728 Epoch[52] Batch [1140]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086896,	
2017-06-16 04:36:27,883 Epoch[52] Batch [1150]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.086873,	
2017-06-16 04:36:35,190 Epoch[52] Batch [1160]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.086818,	
2017-06-16 04:36:42,597 Epoch[52] Batch [1170]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.086791,	
2017-06-16 04:36:49,043 Epoch[52] Batch [1180]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086811,	
2017-06-16 04:36:56,406 Epoch[52] Batch [1190]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.086826,	
2017-06-16 04:37:03,770 Epoch[52] Batch [1200]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.086729,	
2017-06-16 04:37:11,087 Epoch[52] Batch [1210]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.086752,	
2017-06-16 04:37:19,396 Epoch[52] Batch [1220]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.086714,	
2017-06-16 04:37:26,277 Epoch[52] Batch [1230]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.086676,	
2017-06-16 04:37:33,739 Epoch[52] Batch [1240]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086710,	
2017-06-16 04:37:42,286 Epoch[52] Batch [1250]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.086723,	
2017-06-16 04:37:49,835 Epoch[52] Batch [1260]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.086756,	
2017-06-16 04:37:58,042 Epoch[52] Batch [1270]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.086728,	
2017-06-16 04:38:05,782 Epoch[52] Batch [1280]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.086743,	
2017-06-16 04:38:13,157 Epoch[52] Batch [1290]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.086721,	
2017-06-16 04:38:20,490 Epoch[52] Batch [1300]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.086736,	
2017-06-16 04:38:29,486 Epoch[52] Batch [1310]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.086712,	
2017-06-16 04:38:37,250 Epoch[52] Batch [1320]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.086742,	
2017-06-16 04:38:44,750 Epoch[52] Batch [1330]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.086703,	
2017-06-16 04:38:52,592 Epoch[52] Batch [1340]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086662,	
2017-06-16 04:39:00,616 Epoch[52] Batch [1350]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.086643,	
2017-06-16 04:39:08,437 Epoch[52] Batch [1360]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.086627,	
2017-06-16 04:39:15,580 Epoch[52] Batch [1370]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086580,	
2017-06-16 04:39:24,008 Epoch[52] Batch [1380]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.086573,	
2017-06-16 04:39:34,051 Epoch[52] Batch [1390]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.086580,	
2017-06-16 04:39:40,370 Epoch[52] Batch [1400]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.086629,	
2017-06-16 04:39:48,418 Epoch[52] Batch [1410]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.086629,	
2017-06-16 04:39:55,896 Epoch[52] Batch [1420]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086623,	
2017-06-16 04:40:03,435 Epoch[52] Batch [1430]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086653,	
2017-06-16 04:40:10,675 Epoch[52] Batch [1440]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086713,	
2017-06-16 04:40:19,303 Epoch[52] Batch [1450]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.086749,	
2017-06-16 04:40:27,302 Epoch[52] Batch [1460]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.086786,	
2017-06-16 04:40:35,633 Epoch[52] Batch [1470]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.086708,	
2017-06-16 04:40:43,428 Epoch[52] Batch [1480]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.086695,	
2017-06-16 04:40:49,562 Epoch[52] Train-FCNLogLoss=0.086699
2017-06-16 04:40:49,563 Epoch[52] Time cost=1149.473
2017-06-16 04:40:50,624 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0053.params"
2017-06-16 04:40:53,217 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset-0053.states"
2017-06-16 04:40:53,234 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data01/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data01/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn_dilatedoffset'}

2017-06-16 04:41:33,898 testing 4/500 data 0.8633s net 0.4961s post 0.0105s
2017-06-16 04:41:34,830 testing 8/500 data 0.7021s net 0.4388s post 0.0100s
2017-06-16 04:41:35,738 testing 12/500 data 0.6401s net 0.4198s post 0.0100s
2017-06-16 04:41:36,818 testing 16/500 data 0.6528s net 0.4097s post 0.0099s
2017-06-16 04:41:37,600 testing 20/500 data 0.6005s net 0.4036s post 0.0102s
2017-06-16 04:41:38,478 testing 24/500 data 0.5815s net 0.3998s post 0.0103s
2017-06-16 04:41:39,214 testing 28/500 data 0.5478s net 0.3973s post 0.0099s
2017-06-16 04:41:40,948 testing 32/500 data 0.6477s net 0.3952s post 0.0097s
2017-06-16 04:41:41,849 testing 36/500 data 0.6329s net 0.3934s post 0.0094s
2017-06-16 04:41:42,952 testing 40/500 data 0.6408s net 0.3921s post 0.0095s
2017-06-16 04:41:43,874 testing 44/500 data 0.6310s net 0.3910s post 0.0094s
2017-06-16 04:41:44,605 testing 48/500 data 0.6065s net 0.3903s post 0.0096s
2017-06-16 04:41:45,561 testing 52/500 data 0.6030s net 0.3897s post 0.0098s
2017-06-16 04:41:46,279 testing 56/500 data 0.5831s net 0.3892s post 0.0100s
2017-06-16 04:41:47,185 testing 60/500 data 0.5782s net 0.3888s post 0.0101s
2017-06-16 04:41:48,103 testing 64/500 data 0.5748s net 0.3885s post 0.0101s
2017-06-16 04:41:49,138 testing 68/500 data 0.5789s net 0.3881s post 0.0101s
2017-06-16 04:41:49,978 testing 72/500 data 0.5714s net 0.3880s post 0.0101s
2017-06-16 04:41:50,992 testing 76/500 data 0.5741s net 0.3877s post 0.0100s
2017-06-16 04:41:52,094 testing 80/500 data 0.5810s net 0.3874s post 0.0099s
2017-06-16 04:41:52,980 testing 84/500 data 0.5767s net 0.3872s post 0.0100s
2017-06-16 04:41:53,902 testing 88/500 data 0.5746s net 0.3871s post 0.0099s
2017-06-16 04:41:54,735 testing 92/500 data 0.5685s net 0.3871s post 0.0099s
2017-06-16 04:41:55,636 testing 96/500 data 0.5660s net 0.3869s post 0.0098s
2017-06-16 04:41:56,369 testing 100/500 data 0.5570s net 0.3867s post 0.0099s
2017-06-16 04:41:57,096 testing 104/500 data 0.5485s net 0.3866s post 0.0098s
2017-06-16 04:41:57,835 testing 108/500 data 0.5411s net 0.3864s post 0.0098s
2017-06-16 04:41:58,602 testing 112/500 data 0.5351s net 0.3863s post 0.0098s
2017-06-16 04:41:59,486 testing 116/500 data 0.5336s net 0.3862s post 0.0098s
2017-06-16 04:42:00,569 testing 120/500 data 0.5388s net 0.3861s post 0.0098s
2017-06-16 04:42:01,602 testing 124/500 data 0.5423s net 0.3859s post 0.0097s
2017-06-16 04:42:02,308 testing 128/500 data 0.5352s net 0.3858s post 0.0096s
2017-06-16 04:42:03,218 testing 132/500 data 0.5347s net 0.3857s post 0.0096s
2017-06-16 04:42:04,106 testing 136/500 data 0.5335s net 0.3856s post 0.0096s
2017-06-16 04:42:05,134 testing 140/500 data 0.5365s net 0.3855s post 0.0096s
2017-06-16 04:42:05,990 testing 144/500 data 0.5344s net 0.3855s post 0.0096s
2017-06-16 04:42:06,795 testing 148/500 data 0.5312s net 0.3853s post 0.0096s
2017-06-16 04:42:07,710 testing 152/500 data 0.5309s net 0.3853s post 0.0096s
2017-06-16 04:42:08,676 testing 156/500 data 0.5320s net 0.3852s post 0.0096s
2017-06-16 04:42:09,448 testing 160/500 data 0.5282s net 0.3851s post 0.0096s
2017-06-16 04:42:10,561 testing 164/500 data 0.5329s net 0.3851s post 0.0097s
2017-06-16 04:42:11,331 testing 168/500 data 0.5292s net 0.3850s post 0.0097s
2017-06-16 04:42:12,691 testing 172/500 data 0.5393s net 0.3850s post 0.0097s
2017-06-16 04:42:13,447 testing 176/500 data 0.5354s net 0.3850s post 0.0096s
2017-06-16 04:42:14,366 testing 180/500 data 0.5352s net 0.3849s post 0.0097s
2017-06-16 04:42:15,266 testing 184/500 data 0.5346s net 0.3849s post 0.0096s
2017-06-16 04:42:16,225 testing 188/500 data 0.5353s net 0.3848s post 0.0097s
2017-06-16 04:42:16,951 testing 192/500 data 0.5311s net 0.3847s post 0.0097s
2017-06-16 04:42:17,668 testing 196/500 data 0.5269s net 0.3847s post 0.0096s
2017-06-16 04:42:18,377 testing 200/500 data 0.5228s net 0.3846s post 0.0096s
2017-06-16 04:42:19,130 testing 204/500 data 0.5196s net 0.3846s post 0.0096s
2017-06-16 04:42:19,841 testing 208/500 data 0.5159s net 0.3845s post 0.0095s
2017-06-16 04:42:20,828 testing 212/500 data 0.5174s net 0.3844s post 0.0095s
2017-06-16 04:42:21,726 testing 216/500 data 0.5170s net 0.3844s post 0.0096s
2017-06-16 04:42:22,647 testing 220/500 data 0.5173s net 0.3843s post 0.0096s
2017-06-16 04:42:23,493 testing 224/500 data 0.5162s net 0.3844s post 0.0095s
2017-06-16 04:42:24,555 testing 228/500 data 0.5189s net 0.3843s post 0.0095s
2017-06-16 04:42:25,486 testing 232/500 data 0.5193s net 0.3843s post 0.0095s
2017-06-16 04:42:26,901 testing 236/500 data 0.5279s net 0.3842s post 0.0094s
2017-06-16 04:42:28,162 testing 240/500 data 0.5337s net 0.3842s post 0.0094s
2017-06-16 04:42:29,711 testing 244/500 data 0.5440s net 0.3841s post 0.0093s
2017-06-16 04:42:30,781 testing 248/500 data 0.5462s net 0.3841s post 0.0093s
2017-06-16 04:42:31,635 testing 252/500 data 0.5449s net 0.3840s post 0.0092s
2017-06-16 04:42:32,450 testing 256/500 data 0.5431s net 0.3840s post 0.0092s
2017-06-16 04:42:33,715 testing 260/500 data 0.5480s net 0.3840s post 0.0093s
2017-06-16 04:42:35,174 testing 264/500 data 0.5559s net 0.3840s post 0.0093s
2017-06-16 04:42:36,292 testing 268/500 data 0.5584s net 0.3840s post 0.0093s
2017-06-16 04:42:37,215 testing 272/500 data 0.5580s net 0.3839s post 0.0094s
2017-06-16 04:42:38,206 testing 276/500 data 0.5586s net 0.3839s post 0.0094s
2017-06-16 04:42:38,946 testing 280/500 data 0.5556s net 0.3838s post 0.0094s
2017-06-16 04:42:39,928 testing 284/500 data 0.5562s net 0.3838s post 0.0093s
2017-06-16 04:42:40,825 testing 288/500 data 0.5555s net 0.3837s post 0.0094s
2017-06-16 04:42:41,565 testing 292/500 data 0.5526s net 0.3837s post 0.0094s
2017-06-16 04:42:42,845 testing 296/500 data 0.5572s net 0.3837s post 0.0093s
2017-06-16 04:42:43,717 testing 300/500 data 0.5563s net 0.3836s post 0.0093s
2017-06-16 04:42:44,610 testing 304/500 data 0.5556s net 0.3836s post 0.0093s
2017-06-16 04:42:45,590 testing 308/500 data 0.5560s net 0.3836s post 0.0093s
2017-06-16 04:42:46,619 testing 312/500 data 0.5570s net 0.3835s post 0.0093s
2017-06-16 04:42:47,808 testing 316/500 data 0.5601s net 0.3835s post 0.0094s
2017-06-16 04:42:48,826 testing 320/500 data 0.5609s net 0.3834s post 0.0094s
2017-06-16 04:42:49,735 testing 324/500 data 0.5604s net 0.3834s post 0.0094s
2017-06-16 04:42:50,823 testing 328/500 data 0.5621s net 0.3833s post 0.0094s
2017-06-16 04:42:51,722 testing 332/500 data 0.5614s net 0.3833s post 0.0094s
2017-06-16 04:42:52,740 testing 336/500 data 0.5622s net 0.3833s post 0.0094s
2017-06-16 04:42:53,718 testing 340/500 data 0.5626s net 0.3832s post 0.0094s
2017-06-16 04:42:54,809 testing 344/500 data 0.5642s net 0.3832s post 0.0094s
2017-06-16 04:42:55,669 testing 348/500 data 0.5631s net 0.3832s post 0.0094s
2017-06-16 04:42:56,657 testing 352/500 data 0.5634s net 0.3832s post 0.0094s
2017-06-16 04:42:57,691 testing 356/500 data 0.5643s net 0.3831s post 0.0094s
2017-06-16 04:42:58,674 testing 360/500 data 0.5647s net 0.3831s post 0.0094s
2017-06-16 04:42:59,877 testing 364/500 data 0.5674s net 0.3831s post 0.0094s
2017-06-16 04:43:00,844 testing 368/500 data 0.5675s net 0.3830s post 0.0094s
2017-06-16 04:43:01,822 testing 372/500 data 0.5678s net 0.3830s post 0.0093s
2017-06-16 04:43:02,774 testing 376/500 data 0.5677s net 0.3830s post 0.0094s
2017-06-16 04:43:03,784 testing 380/500 data 0.5682s net 0.3831s post 0.0093s
2017-06-16 04:43:04,833 testing 384/500 data 0.5692s net 0.3830s post 0.0093s
2017-06-16 04:43:05,640 testing 388/500 data 0.5676s net 0.3830s post 0.0093s
2017-06-16 04:43:06,711 testing 392/500 data 0.5687s net 0.3830s post 0.0093s
2017-06-16 04:43:08,090 testing 396/500 data 0.5730s net 0.3830s post 0.0092s
2017-06-16 04:43:09,178 testing 400/500 data 0.5742s net 0.3830s post 0.0092s
2017-06-16 04:43:10,090 testing 404/500 data 0.5737s net 0.3830s post 0.0092s
2017-06-16 04:43:11,054 testing 408/500 data 0.5737s net 0.3830s post 0.0092s
2017-06-16 04:43:11,815 testing 412/500 data 0.5717s net 0.3830s post 0.0092s
2017-06-16 04:43:12,747 testing 416/500 data 0.5714s net 0.3830s post 0.0092s
2017-06-16 04:43:13,574 testing 420/500 data 0.5702s net 0.3830s post 0.0092s
2017-06-16 04:43:14,472 testing 424/500 data 0.5695s net 0.3830s post 0.0092s
2017-06-16 04:43:15,512 testing 428/500 data 0.5703s net 0.3830s post 0.0092s
2017-06-16 04:43:16,449 testing 432/500 data 0.5700s net 0.3830s post 0.0092s
2017-06-16 04:43:17,400 testing 436/500 data 0.5699s net 0.3830s post 0.0092s
2017-06-16 04:43:18,202 testing 440/500 data 0.5685s net 0.3830s post 0.0092s
2017-06-16 04:43:19,258 testing 444/500 data 0.5693s net 0.3830s post 0.0092s
2017-06-16 04:43:19,956 testing 448/500 data 0.5671s net 0.3830s post 0.0091s
2017-06-16 04:43:20,677 testing 452/500 data 0.5650s net 0.3830s post 0.0091s
2017-06-16 04:43:21,723 testing 456/500 data 0.5658s net 0.3830s post 0.0091s
2017-06-16 04:43:22,418 testing 460/500 data 0.5635s net 0.3830s post 0.0091s
2017-06-16 04:43:23,381 testing 464/500 data 0.5636s net 0.3829s post 0.0091s
2017-06-16 04:43:24,146 testing 468/500 data 0.5620s net 0.3829s post 0.0091s
2017-06-16 04:43:25,143 testing 472/500 data 0.5623s net 0.3829s post 0.0091s
2017-06-16 04:43:25,956 testing 476/500 data 0.5611s net 0.3829s post 0.0091s
2017-06-16 04:43:26,938 testing 480/500 data 0.5613s net 0.3829s post 0.0091s
2017-06-16 04:43:27,892 testing 484/500 data 0.5614s net 0.3829s post 0.0091s
2017-06-16 04:43:28,838 testing 488/500 data 0.5613s net 0.3829s post 0.0091s
2017-06-16 04:43:29,922 testing 492/500 data 0.5624s net 0.3829s post 0.0091s
2017-06-16 04:43:31,082 testing 496/500 data 0.5640s net 0.3829s post 0.0092s
2017-06-16 04:43:31,863 testing 500/500 data 0.5626s net 0.3829s post 0.0091s
2017-06-16 04:45:06,939 evaluate segmentation: 

2017-06-16 04:45:06,939 IU_array:

2017-06-16 04:45:06,940 0.98054
2017-06-16 04:45:06,940 0.84091
2017-06-16 04:45:06,940 0.91640
2017-06-16 04:45:06,940 0.56775
2017-06-16 04:45:06,940 0.57554
2017-06-16 04:45:06,940 0.54486
2017-06-16 04:45:06,940 0.64342
2017-06-16 04:45:06,940 0.74129
2017-06-16 04:45:06,940 0.91527
2017-06-16 04:45:06,940 0.62916
2017-06-16 04:45:06,940 0.93760
2017-06-16 04:45:06,941 0.78659
2017-06-16 04:45:06,941 0.60210
2017-06-16 04:45:06,941 0.93800
2017-06-16 04:45:06,941 0.67518
2017-06-16 04:45:06,941 0.83765
2017-06-16 04:45:06,941 0.67365
2017-06-16 04:45:06,941 0.64390
2017-06-16 04:45:06,941 0.74598
2017-06-16 04:45:06,941 meanIU:0.74715

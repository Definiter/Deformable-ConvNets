2017-06-27 10:31:40,080 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate6x6'}

2017-06-27 10:32:31,666 Epoch[0] Batch [10]	Speed: 7.51 samples/sec	Train-FCNLogLoss=2.882257,	
2017-06-27 10:32:36,126 Epoch[0] Batch [20]	Speed: 8.97 samples/sec	Train-FCNLogLoss=2.749678,	
2017-06-27 10:32:40,444 Epoch[0] Batch [30]	Speed: 9.27 samples/sec	Train-FCNLogLoss=2.475806,	
2017-06-27 10:32:44,876 Epoch[0] Batch [40]	Speed: 9.03 samples/sec	Train-FCNLogLoss=2.223036,	
2017-06-27 10:32:49,587 Epoch[0] Batch [50]	Speed: 8.49 samples/sec	Train-FCNLogLoss=1.992441,	
2017-06-27 10:32:53,907 Epoch[0] Batch [60]	Speed: 9.26 samples/sec	Train-FCNLogLoss=1.835813,	
2017-06-27 10:32:58,574 Epoch[0] Batch [70]	Speed: 8.57 samples/sec	Train-FCNLogLoss=1.698435,	
2017-06-27 10:33:02,932 Epoch[0] Batch [80]	Speed: 9.18 samples/sec	Train-FCNLogLoss=1.590158,	
2017-06-27 10:33:07,078 Epoch[0] Batch [90]	Speed: 9.65 samples/sec	Train-FCNLogLoss=1.494239,	
2017-06-27 10:33:11,555 Epoch[0] Batch [100]	Speed: 8.94 samples/sec	Train-FCNLogLoss=1.422731,	
2017-06-27 10:33:16,335 Epoch[0] Batch [110]	Speed: 8.37 samples/sec	Train-FCNLogLoss=1.352368,	
2017-06-27 10:33:20,481 Epoch[0] Batch [120]	Speed: 9.65 samples/sec	Train-FCNLogLoss=1.295305,	
2017-06-27 10:33:24,503 Epoch[0] Batch [130]	Speed: 9.95 samples/sec	Train-FCNLogLoss=1.245579,	
2017-06-27 10:33:28,451 Epoch[0] Batch [140]	Speed: 10.13 samples/sec	Train-FCNLogLoss=1.194514,	
2017-06-27 10:33:32,701 Epoch[0] Batch [150]	Speed: 9.41 samples/sec	Train-FCNLogLoss=1.149263,	
2017-06-27 10:33:37,089 Epoch[0] Batch [160]	Speed: 9.12 samples/sec	Train-FCNLogLoss=1.111053,	
2017-06-27 10:33:41,416 Epoch[0] Batch [170]	Speed: 9.25 samples/sec	Train-FCNLogLoss=1.085008,	
2017-06-27 10:33:45,699 Epoch[0] Batch [180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=1.052922,	
2017-06-27 10:33:50,111 Epoch[0] Batch [190]	Speed: 9.07 samples/sec	Train-FCNLogLoss=1.021507,	
2017-06-27 10:33:54,246 Epoch[0] Batch [200]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.995329,	
2017-06-27 10:33:58,705 Epoch[0] Batch [210]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.971425,	
2017-06-27 10:34:03,111 Epoch[0] Batch [220]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.950329,	
2017-06-27 10:34:07,318 Epoch[0] Batch [230]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.925701,	
2017-06-27 10:34:11,708 Epoch[0] Batch [240]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.910338,	
2017-06-27 10:34:16,158 Epoch[0] Batch [250]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.893542,	
2017-06-27 10:34:20,299 Epoch[0] Batch [260]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.876364,	
2017-06-27 10:34:24,739 Epoch[0] Batch [270]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.866207,	
2017-06-27 10:34:28,919 Epoch[0] Batch [280]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.854832,	
2017-06-27 10:34:33,311 Epoch[0] Batch [290]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.842794,	
2017-06-27 10:34:37,471 Epoch[0] Batch [300]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.831907,	
2017-06-27 10:34:41,805 Epoch[0] Batch [310]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.817581,	
2017-06-27 10:34:45,956 Epoch[0] Batch [320]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.804565,	
2017-06-27 10:34:50,664 Epoch[0] Batch [330]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.793673,	
2017-06-27 10:34:54,878 Epoch[0] Batch [340]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.783544,	
2017-06-27 10:34:58,958 Epoch[0] Batch [350]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.772261,	
2017-06-27 10:35:03,070 Epoch[0] Batch [360]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.762088,	
2017-06-27 10:35:07,605 Epoch[0] Batch [370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.753134,	
2017-06-27 10:35:11,927 Epoch[0] Batch [380]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.744591,	
2017-06-27 10:35:16,303 Epoch[0] Batch [390]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.736640,	
2017-06-27 10:35:20,561 Epoch[0] Batch [400]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.727932,	
2017-06-27 10:35:24,824 Epoch[0] Batch [410]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.719679,	
2017-06-27 10:35:29,213 Epoch[0] Batch [420]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.711707,	
2017-06-27 10:35:33,455 Epoch[0] Batch [430]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.704794,	
2017-06-27 10:35:38,239 Epoch[0] Batch [440]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.698188,	
2017-06-27 10:35:42,382 Epoch[0] Batch [450]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.691163,	
2017-06-27 10:35:46,815 Epoch[0] Batch [460]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.685215,	
2017-06-27 10:35:51,059 Epoch[0] Batch [470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.678747,	
2017-06-27 10:35:55,188 Epoch[0] Batch [480]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.672688,	
2017-06-27 10:35:59,640 Epoch[0] Batch [490]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.667108,	
2017-06-27 10:36:04,270 Epoch[0] Batch [500]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.660948,	
2017-06-27 10:36:09,369 Epoch[0] Batch [510]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.655619,	
2017-06-27 10:36:14,350 Epoch[0] Batch [520]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.649890,	
2017-06-27 10:36:19,229 Epoch[0] Batch [530]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.644149,	
2017-06-27 10:36:24,064 Epoch[0] Batch [540]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.640142,	
2017-06-27 10:36:28,919 Epoch[0] Batch [550]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.636417,	
2017-06-27 10:36:33,580 Epoch[0] Batch [560]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.631471,	
2017-06-27 10:36:38,049 Epoch[0] Batch [570]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.626437,	
2017-06-27 10:36:42,362 Epoch[0] Batch [580]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.621975,	
2017-06-27 10:36:47,132 Epoch[0] Batch [590]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.617260,	
2017-06-27 10:36:51,583 Epoch[0] Batch [600]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.613503,	
2017-06-27 10:36:55,994 Epoch[0] Batch [610]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.610048,	
2017-06-27 10:37:00,454 Epoch[0] Batch [620]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.605913,	
2017-06-27 10:37:04,879 Epoch[0] Batch [630]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.602353,	
2017-06-27 10:37:09,220 Epoch[0] Batch [640]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.598699,	
2017-06-27 10:37:13,545 Epoch[0] Batch [650]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.594945,	
2017-06-27 10:37:17,917 Epoch[0] Batch [660]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.590502,	
2017-06-27 10:37:22,211 Epoch[0] Batch [670]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.587328,	
2017-06-27 10:37:26,828 Epoch[0] Batch [680]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.583423,	
2017-06-27 10:37:31,313 Epoch[0] Batch [690]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.579830,	
2017-06-27 10:37:35,755 Epoch[0] Batch [700]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.575626,	
2017-06-27 10:37:40,031 Epoch[0] Batch [710]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.572891,	
2017-06-27 10:37:44,515 Epoch[0] Batch [720]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.569553,	
2017-06-27 10:37:48,778 Epoch[0] Batch [730]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.565922,	
2017-06-27 10:37:53,088 Epoch[0] Batch [740]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.562409,	
2017-06-27 10:37:57,481 Epoch[0] Batch [750]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.560432,	
2017-06-27 10:38:01,863 Epoch[0] Batch [760]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.556968,	
2017-06-27 10:38:06,184 Epoch[0] Batch [770]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.554411,	
2017-06-27 10:38:10,581 Epoch[0] Batch [780]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.551388,	
2017-06-27 10:38:14,741 Epoch[0] Batch [790]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.548805,	
2017-06-27 10:38:19,238 Epoch[0] Batch [800]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.546286,	
2017-06-27 10:38:23,393 Epoch[0] Batch [810]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.544092,	
2017-06-27 10:38:27,657 Epoch[0] Batch [820]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.542432,	
2017-06-27 10:38:31,847 Epoch[0] Batch [830]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.539944,	
2017-06-27 10:38:36,432 Epoch[0] Batch [840]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.537324,	
2017-06-27 10:38:40,753 Epoch[0] Batch [850]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.535003,	
2017-06-27 10:38:45,142 Epoch[0] Batch [860]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.532959,	
2017-06-27 10:38:49,700 Epoch[0] Batch [870]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.530547,	
2017-06-27 10:38:54,091 Epoch[0] Batch [880]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.528550,	
2017-06-27 10:38:58,510 Epoch[0] Batch [890]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.526173,	
2017-06-27 10:39:02,969 Epoch[0] Batch [900]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.523860,	
2017-06-27 10:39:07,499 Epoch[0] Batch [910]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.521811,	
2017-06-27 10:39:11,927 Epoch[0] Batch [920]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.519144,	
2017-06-27 10:39:16,151 Epoch[0] Batch [930]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.517632,	
2017-06-27 10:39:20,516 Epoch[0] Batch [940]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.515362,	
2017-06-27 10:39:24,847 Epoch[0] Batch [950]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.513125,	
2017-06-27 10:39:29,094 Epoch[0] Batch [960]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.510991,	
2017-06-27 10:39:33,339 Epoch[0] Batch [970]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.509028,	
2017-06-27 10:39:37,521 Epoch[0] Batch [980]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.507221,	
2017-06-27 10:39:42,089 Epoch[0] Batch [990]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.505230,	
2017-06-27 10:39:46,417 Epoch[0] Batch [1000]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.503433,	
2017-06-27 10:39:51,118 Epoch[0] Batch [1010]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.502398,	
2017-06-27 10:39:55,566 Epoch[0] Batch [1020]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.501548,	
2017-06-27 10:40:00,106 Epoch[0] Batch [1030]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.500397,	
2017-06-27 10:40:04,813 Epoch[0] Batch [1040]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.499285,	
2017-06-27 10:40:09,087 Epoch[0] Batch [1050]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.497812,	
2017-06-27 10:40:13,597 Epoch[0] Batch [1060]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.497543,	
2017-06-27 10:40:18,066 Epoch[0] Batch [1070]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.496360,	
2017-06-27 10:40:22,214 Epoch[0] Batch [1080]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.496846,	
2017-06-27 10:40:26,562 Epoch[0] Batch [1090]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.495718,	
2017-06-27 10:40:30,758 Epoch[0] Batch [1100]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.494903,	
2017-06-27 10:40:35,004 Epoch[0] Batch [1110]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.493936,	
2017-06-27 10:40:39,338 Epoch[0] Batch [1120]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.492940,	
2017-06-27 10:40:43,682 Epoch[0] Batch [1130]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.492225,	
2017-06-27 10:40:47,951 Epoch[0] Batch [1140]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.491000,	
2017-06-27 10:40:52,408 Epoch[0] Batch [1150]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.493606,	
2017-06-27 10:40:58,659 Epoch[0] Batch [1160]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.494107,	
2017-06-27 10:41:03,041 Epoch[0] Batch [1170]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.493784,	
2017-06-27 10:41:07,360 Epoch[0] Batch [1180]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.492873,	
2017-06-27 10:41:11,804 Epoch[0] Batch [1190]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.492696,	
2017-06-27 10:41:16,396 Epoch[0] Batch [1200]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.491637,	
2017-06-27 10:41:20,724 Epoch[0] Batch [1210]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.490524,	
2017-06-27 10:41:24,968 Epoch[0] Batch [1220]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.489710,	
2017-06-27 10:41:29,698 Epoch[0] Batch [1230]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.488873,	
2017-06-27 10:41:34,472 Epoch[0] Batch [1240]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.488114,	
2017-06-27 10:41:38,742 Epoch[0] Batch [1250]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.487470,	
2017-06-27 10:41:43,011 Epoch[0] Batch [1260]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.486751,	
2017-06-27 10:41:47,463 Epoch[0] Batch [1270]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.485204,	
2017-06-27 10:41:51,678 Epoch[0] Batch [1280]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.484680,	
2017-06-27 10:41:55,823 Epoch[0] Batch [1290]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.483489,	
2017-06-27 10:42:00,231 Epoch[0] Batch [1300]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.481946,	
2017-06-27 10:42:04,759 Epoch[0] Batch [1310]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.480957,	
2017-06-27 10:42:09,674 Epoch[0] Batch [1320]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.480085,	
2017-06-27 10:42:13,941 Epoch[0] Batch [1330]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.479075,	
2017-06-27 10:42:18,255 Epoch[0] Batch [1340]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.478170,	
2017-06-27 10:42:22,690 Epoch[0] Batch [1350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.476548,	
2017-06-27 10:42:27,138 Epoch[0] Batch [1360]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.475703,	
2017-06-27 10:42:31,684 Epoch[0] Batch [1370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.474816,	
2017-06-27 10:42:36,067 Epoch[0] Batch [1380]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.473249,	
2017-06-27 10:42:40,492 Epoch[0] Batch [1390]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.472496,	
2017-06-27 10:42:44,836 Epoch[0] Batch [1400]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.471648,	
2017-06-27 10:42:49,131 Epoch[0] Batch [1410]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.471261,	
2017-06-27 10:42:53,263 Epoch[0] Batch [1420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.470149,	
2017-06-27 10:42:57,739 Epoch[0] Batch [1430]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.468970,	
2017-06-27 10:43:02,292 Epoch[0] Batch [1440]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.467601,	
2017-06-27 10:43:06,557 Epoch[0] Batch [1450]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.466109,	
2017-06-27 10:43:11,015 Epoch[0] Batch [1460]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.465434,	
2017-06-27 10:43:15,566 Epoch[0] Batch [1470]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.464533,	
2017-06-27 10:43:19,961 Epoch[0] Batch [1480]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.463297,	
2017-06-27 10:43:22,445 Epoch[0] Train-FCNLogLoss=0.462721
2017-06-27 10:43:22,446 Epoch[0] Time cost=662.139
2017-06-27 10:43:23,498 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0001.params"
2017-06-27 10:43:25,133 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0001.states"
2017-06-27 10:43:29,775 Epoch[1] Batch [10]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.278523,	
2017-06-27 10:43:33,945 Epoch[1] Batch [20]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.288122,	
2017-06-27 10:43:37,891 Epoch[1] Batch [30]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.279050,	
2017-06-27 10:43:41,756 Epoch[1] Batch [40]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.281039,	
2017-06-27 10:43:45,925 Epoch[1] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.274750,	
2017-06-27 10:43:49,960 Epoch[1] Batch [60]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.277025,	
2017-06-27 10:43:53,753 Epoch[1] Batch [70]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.280260,	
2017-06-27 10:43:57,920 Epoch[1] Batch [80]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.273672,	
2017-06-27 10:44:01,814 Epoch[1] Batch [90]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.275293,	
2017-06-27 10:44:05,967 Epoch[1] Batch [100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.276794,	
2017-06-27 10:44:10,289 Epoch[1] Batch [110]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.273170,	
2017-06-27 10:44:14,204 Epoch[1] Batch [120]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.272370,	
2017-06-27 10:44:18,457 Epoch[1] Batch [130]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.272962,	
2017-06-27 10:44:22,453 Epoch[1] Batch [140]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.271654,	
2017-06-27 10:44:26,360 Epoch[1] Batch [150]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.268599,	
2017-06-27 10:44:30,569 Epoch[1] Batch [160]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.265837,	
2017-06-27 10:44:34,548 Epoch[1] Batch [170]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.263069,	
2017-06-27 10:44:38,336 Epoch[1] Batch [180]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.263425,	
2017-06-27 10:44:42,451 Epoch[1] Batch [190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.262020,	
2017-06-27 10:44:46,297 Epoch[1] Batch [200]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.259337,	
2017-06-27 10:44:50,275 Epoch[1] Batch [210]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.262320,	
2017-06-27 10:44:54,364 Epoch[1] Batch [220]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.263790,	
2017-06-27 10:44:58,299 Epoch[1] Batch [230]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.265260,	
2017-06-27 10:45:02,265 Epoch[1] Batch [240]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.266383,	
2017-06-27 10:45:06,078 Epoch[1] Batch [250]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.266655,	
2017-06-27 10:45:10,265 Epoch[1] Batch [260]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.267284,	
2017-06-27 10:45:14,119 Epoch[1] Batch [270]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.268017,	
2017-06-27 10:45:18,273 Epoch[1] Batch [280]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.266560,	
2017-06-27 10:45:22,081 Epoch[1] Batch [290]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.265596,	
2017-06-27 10:45:25,996 Epoch[1] Batch [300]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.265158,	
2017-06-27 10:45:30,000 Epoch[1] Batch [310]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.265889,	
2017-06-27 10:45:33,811 Epoch[1] Batch [320]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.266302,	
2017-06-27 10:45:37,829 Epoch[1] Batch [330]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.266305,	
2017-06-27 10:45:41,632 Epoch[1] Batch [340]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.266677,	
2017-06-27 10:45:45,449 Epoch[1] Batch [350]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.265105,	
2017-06-27 10:45:49,423 Epoch[1] Batch [360]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.265726,	
2017-06-27 10:45:53,515 Epoch[1] Batch [370]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.266748,	
2017-06-27 10:45:57,450 Epoch[1] Batch [380]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.266636,	
2017-06-27 10:46:01,508 Epoch[1] Batch [390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.266410,	
2017-06-27 10:46:05,491 Epoch[1] Batch [400]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.268525,	
2017-06-27 10:46:09,493 Epoch[1] Batch [410]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.269030,	
2017-06-27 10:46:13,710 Epoch[1] Batch [420]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.269488,	
2017-06-27 10:46:17,849 Epoch[1] Batch [430]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.268556,	
2017-06-27 10:46:21,781 Epoch[1] Batch [440]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.267667,	
2017-06-27 10:46:25,709 Epoch[1] Batch [450]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.267632,	
2017-06-27 10:46:29,690 Epoch[1] Batch [460]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.266874,	
2017-06-27 10:46:33,624 Epoch[1] Batch [470]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.265558,	
2017-06-27 10:46:37,720 Epoch[1] Batch [480]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.264856,	
2017-06-27 10:46:41,985 Epoch[1] Batch [490]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.264181,	
2017-06-27 10:46:45,923 Epoch[1] Batch [500]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.264347,	
2017-06-27 10:46:49,913 Epoch[1] Batch [510]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.264035,	
2017-06-27 10:46:53,952 Epoch[1] Batch [520]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.263942,	
2017-06-27 10:46:57,854 Epoch[1] Batch [530]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.263181,	
2017-06-27 10:47:01,822 Epoch[1] Batch [540]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.262747,	
2017-06-27 10:47:06,169 Epoch[1] Batch [550]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.263018,	
2017-06-27 10:47:10,474 Epoch[1] Batch [560]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.263877,	
2017-06-27 10:47:14,467 Epoch[1] Batch [570]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.263637,	
2017-06-27 10:47:18,411 Epoch[1] Batch [580]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.263222,	
2017-06-27 10:47:22,319 Epoch[1] Batch [590]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.263099,	
2017-06-27 10:47:26,270 Epoch[1] Batch [600]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.262433,	
2017-06-27 10:47:30,228 Epoch[1] Batch [610]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.262933,	
2017-06-27 10:47:34,151 Epoch[1] Batch [620]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.263606,	
2017-06-27 10:47:38,125 Epoch[1] Batch [630]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.263267,	
2017-06-27 10:47:42,042 Epoch[1] Batch [640]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.262385,	
2017-06-27 10:47:45,996 Epoch[1] Batch [650]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.261800,	
2017-06-27 10:47:50,024 Epoch[1] Batch [660]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.261361,	
2017-06-27 10:47:53,832 Epoch[1] Batch [670]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.261058,	
2017-06-27 10:47:57,802 Epoch[1] Batch [680]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.260534,	
2017-06-27 10:48:01,653 Epoch[1] Batch [690]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.259920,	
2017-06-27 10:48:05,511 Epoch[1] Batch [700]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.259231,	
2017-06-27 10:48:09,476 Epoch[1] Batch [710]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.258937,	
2017-06-27 10:48:13,263 Epoch[1] Batch [720]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.258470,	
2017-06-27 10:48:17,091 Epoch[1] Batch [730]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.258986,	
2017-06-27 10:48:21,154 Epoch[1] Batch [740]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.258502,	
2017-06-27 10:48:25,428 Epoch[1] Batch [750]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.258760,	
2017-06-27 10:48:29,579 Epoch[1] Batch [760]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.258797,	
2017-06-27 10:48:33,491 Epoch[1] Batch [770]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.258597,	
2017-06-27 10:48:37,371 Epoch[1] Batch [780]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.258022,	
2017-06-27 10:48:41,297 Epoch[1] Batch [790]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.257697,	
2017-06-27 10:48:45,589 Epoch[1] Batch [800]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.257345,	
2017-06-27 10:48:49,711 Epoch[1] Batch [810]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.257378,	
2017-06-27 10:48:53,601 Epoch[1] Batch [820]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.257049,	
2017-06-27 10:48:57,862 Epoch[1] Batch [830]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.256843,	
2017-06-27 10:49:01,623 Epoch[1] Batch [840]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.256485,	
2017-06-27 10:49:05,578 Epoch[1] Batch [850]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.256709,	
2017-06-27 10:49:09,536 Epoch[1] Batch [860]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.257180,	
2017-06-27 10:49:13,610 Epoch[1] Batch [870]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.257506,	
2017-06-27 10:49:17,500 Epoch[1] Batch [880]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.257316,	
2017-06-27 10:49:21,561 Epoch[1] Batch [890]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.257435,	
2017-06-27 10:49:25,414 Epoch[1] Batch [900]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.257395,	
2017-06-27 10:49:29,503 Epoch[1] Batch [910]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.256919,	
2017-06-27 10:49:33,552 Epoch[1] Batch [920]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.257079,	
2017-06-27 10:49:37,585 Epoch[1] Batch [930]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.256688,	
2017-06-27 10:49:41,615 Epoch[1] Batch [940]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.256589,	
2017-06-27 10:49:45,576 Epoch[1] Batch [950]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.256353,	
2017-06-27 10:49:49,584 Epoch[1] Batch [960]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.255905,	
2017-06-27 10:49:53,540 Epoch[1] Batch [970]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.255735,	
2017-06-27 10:49:57,479 Epoch[1] Batch [980]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.256282,	
2017-06-27 10:50:01,588 Epoch[1] Batch [990]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.256035,	
2017-06-27 10:50:05,678 Epoch[1] Batch [1000]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.256288,	
2017-06-27 10:50:09,830 Epoch[1] Batch [1010]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.256264,	
2017-06-27 10:50:13,709 Epoch[1] Batch [1020]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.256671,	
2017-06-27 10:50:17,714 Epoch[1] Batch [1030]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.256528,	
2017-06-27 10:50:22,030 Epoch[1] Batch [1040]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.256422,	
2017-06-27 10:50:25,974 Epoch[1] Batch [1050]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.255780,	
2017-06-27 10:50:29,957 Epoch[1] Batch [1060]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.255488,	
2017-06-27 10:50:33,915 Epoch[1] Batch [1070]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.255091,	
2017-06-27 10:50:38,102 Epoch[1] Batch [1080]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.254832,	
2017-06-27 10:50:42,267 Epoch[1] Batch [1090]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.254546,	
2017-06-27 10:50:46,144 Epoch[1] Batch [1100]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.254241,	
2017-06-27 10:50:49,949 Epoch[1] Batch [1110]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.253944,	
2017-06-27 10:50:53,887 Epoch[1] Batch [1120]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.254058,	
2017-06-27 10:50:57,924 Epoch[1] Batch [1130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.253898,	
2017-06-27 10:51:01,837 Epoch[1] Batch [1140]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.253635,	
2017-06-27 10:51:05,926 Epoch[1] Batch [1150]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.253420,	
2017-06-27 10:51:10,012 Epoch[1] Batch [1160]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.253225,	
2017-06-27 10:51:14,001 Epoch[1] Batch [1170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.253223,	
2017-06-27 10:51:17,933 Epoch[1] Batch [1180]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.252844,	
2017-06-27 10:51:21,754 Epoch[1] Batch [1190]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.252951,	
2017-06-27 10:51:25,591 Epoch[1] Batch [1200]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.253001,	
2017-06-27 10:51:29,678 Epoch[1] Batch [1210]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.252858,	
2017-06-27 10:51:33,631 Epoch[1] Batch [1220]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.252786,	
2017-06-27 10:51:37,753 Epoch[1] Batch [1230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.252661,	
2017-06-27 10:51:41,768 Epoch[1] Batch [1240]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.252496,	
2017-06-27 10:51:45,785 Epoch[1] Batch [1250]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.252412,	
2017-06-27 10:51:49,630 Epoch[1] Batch [1260]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.252620,	
2017-06-27 10:51:53,511 Epoch[1] Batch [1270]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.252566,	
2017-06-27 10:51:57,346 Epoch[1] Batch [1280]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.252303,	
2017-06-27 10:52:01,296 Epoch[1] Batch [1290]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.252103,	
2017-06-27 10:52:05,085 Epoch[1] Batch [1300]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.251923,	
2017-06-27 10:52:09,102 Epoch[1] Batch [1310]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.251951,	
2017-06-27 10:52:13,109 Epoch[1] Batch [1320]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.252019,	
2017-06-27 10:52:17,162 Epoch[1] Batch [1330]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.251639,	
2017-06-27 10:52:21,318 Epoch[1] Batch [1340]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.251511,	
2017-06-27 10:52:25,270 Epoch[1] Batch [1350]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.251205,	
2017-06-27 10:52:29,164 Epoch[1] Batch [1360]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.250852,	
2017-06-27 10:52:33,345 Epoch[1] Batch [1370]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.250415,	
2017-06-27 10:52:37,320 Epoch[1] Batch [1380]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.250211,	
2017-06-27 10:52:41,650 Epoch[1] Batch [1390]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.250440,	
2017-06-27 10:52:45,850 Epoch[1] Batch [1400]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.250319,	
2017-06-27 10:52:50,073 Epoch[1] Batch [1410]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.250316,	
2017-06-27 10:52:53,791 Epoch[1] Batch [1420]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.250126,	
2017-06-27 10:52:57,711 Epoch[1] Batch [1430]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.249668,	
2017-06-27 10:53:01,823 Epoch[1] Batch [1440]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.249580,	
2017-06-27 10:53:05,797 Epoch[1] Batch [1450]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.249159,	
2017-06-27 10:53:09,538 Epoch[1] Batch [1460]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.249005,	
2017-06-27 10:53:13,686 Epoch[1] Batch [1470]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.248469,	
2017-06-27 10:53:17,719 Epoch[1] Batch [1480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.248296,	
2017-06-27 10:53:20,242 Epoch[1] Train-FCNLogLoss=0.248176
2017-06-27 10:53:20,243 Epoch[1] Time cost=595.109
2017-06-27 10:53:21,018 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0002.params"
2017-06-27 10:53:22,625 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0002.states"
2017-06-27 10:53:27,265 Epoch[2] Batch [10]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.200584,	
2017-06-27 10:53:31,272 Epoch[2] Batch [20]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.199791,	
2017-06-27 10:53:35,249 Epoch[2] Batch [30]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.196265,	
2017-06-27 10:53:39,175 Epoch[2] Batch [40]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.202158,	
2017-06-27 10:53:43,039 Epoch[2] Batch [50]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.197804,	
2017-06-27 10:53:46,961 Epoch[2] Batch [60]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.196998,	
2017-06-27 10:53:50,983 Epoch[2] Batch [70]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.199043,	
2017-06-27 10:53:54,956 Epoch[2] Batch [80]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.199525,	
2017-06-27 10:53:58,931 Epoch[2] Batch [90]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.196528,	
2017-06-27 10:54:02,849 Epoch[2] Batch [100]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.196578,	
2017-06-27 10:54:06,837 Epoch[2] Batch [110]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.198961,	
2017-06-27 10:54:10,661 Epoch[2] Batch [120]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.205804,	
2017-06-27 10:54:14,677 Epoch[2] Batch [130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.207046,	
2017-06-27 10:54:18,661 Epoch[2] Batch [140]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.208605,	
2017-06-27 10:54:22,658 Epoch[2] Batch [150]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.209428,	
2017-06-27 10:54:26,846 Epoch[2] Batch [160]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.210687,	
2017-06-27 10:54:30,848 Epoch[2] Batch [170]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.211789,	
2017-06-27 10:54:34,899 Epoch[2] Batch [180]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.211728,	
2017-06-27 10:54:38,864 Epoch[2] Batch [190]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.210137,	
2017-06-27 10:54:42,738 Epoch[2] Batch [200]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.212708,	
2017-06-27 10:54:46,794 Epoch[2] Batch [210]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.213345,	
2017-06-27 10:54:50,822 Epoch[2] Batch [220]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.214193,	
2017-06-27 10:54:54,712 Epoch[2] Batch [230]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.214515,	
2017-06-27 10:54:58,910 Epoch[2] Batch [240]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.214203,	
2017-06-27 10:55:02,955 Epoch[2] Batch [250]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.214374,	
2017-06-27 10:55:07,073 Epoch[2] Batch [260]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.215086,	
2017-06-27 10:55:10,980 Epoch[2] Batch [270]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.214506,	
2017-06-27 10:55:15,039 Epoch[2] Batch [280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.214209,	
2017-06-27 10:55:19,012 Epoch[2] Batch [290]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.213079,	
2017-06-27 10:55:22,948 Epoch[2] Batch [300]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.213201,	
2017-06-27 10:55:26,944 Epoch[2] Batch [310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.212678,	
2017-06-27 10:55:30,886 Epoch[2] Batch [320]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.213718,	
2017-06-27 10:55:34,753 Epoch[2] Batch [330]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.212722,	
2017-06-27 10:55:38,790 Epoch[2] Batch [340]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.212489,	
2017-06-27 10:55:42,763 Epoch[2] Batch [350]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.212617,	
2017-06-27 10:55:46,732 Epoch[2] Batch [360]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.212028,	
2017-06-27 10:55:50,787 Epoch[2] Batch [370]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.212549,	
2017-06-27 10:55:54,830 Epoch[2] Batch [380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.211847,	
2017-06-27 10:55:58,797 Epoch[2] Batch [390]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.211609,	
2017-06-27 10:56:02,864 Epoch[2] Batch [400]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.211921,	
2017-06-27 10:56:06,890 Epoch[2] Batch [410]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.211400,	
2017-06-27 10:56:10,996 Epoch[2] Batch [420]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.211989,	
2017-06-27 10:56:15,324 Epoch[2] Batch [430]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.211588,	
2017-06-27 10:56:19,244 Epoch[2] Batch [440]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.211938,	
2017-06-27 10:56:23,382 Epoch[2] Batch [450]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.210768,	
2017-06-27 10:56:27,172 Epoch[2] Batch [460]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.210372,	
2017-06-27 10:56:31,102 Epoch[2] Batch [470]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.209945,	
2017-06-27 10:56:35,201 Epoch[2] Batch [480]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.209323,	
2017-06-27 10:56:39,362 Epoch[2] Batch [490]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.209073,	
2017-06-27 10:56:43,332 Epoch[2] Batch [500]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.209641,	
2017-06-27 10:56:47,255 Epoch[2] Batch [510]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.209332,	
2017-06-27 10:56:51,248 Epoch[2] Batch [520]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.209653,	
2017-06-27 10:56:54,986 Epoch[2] Batch [530]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.208812,	
2017-06-27 10:56:59,004 Epoch[2] Batch [540]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.208450,	
2017-06-27 10:57:02,958 Epoch[2] Batch [550]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.208333,	
2017-06-27 10:57:06,941 Epoch[2] Batch [560]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.209520,	
2017-06-27 10:57:11,121 Epoch[2] Batch [570]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.209435,	
2017-06-27 10:57:15,058 Epoch[2] Batch [580]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.210207,	
2017-06-27 10:57:19,041 Epoch[2] Batch [590]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.209985,	
2017-06-27 10:57:22,979 Epoch[2] Batch [600]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.209781,	
2017-06-27 10:57:27,034 Epoch[2] Batch [610]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.209382,	
2017-06-27 10:57:30,868 Epoch[2] Batch [620]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.209479,	
2017-06-27 10:57:34,826 Epoch[2] Batch [630]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.209513,	
2017-06-27 10:57:38,904 Epoch[2] Batch [640]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.209567,	
2017-06-27 10:57:42,972 Epoch[2] Batch [650]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.210347,	
2017-06-27 10:57:47,015 Epoch[2] Batch [660]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.210964,	
2017-06-27 10:57:51,179 Epoch[2] Batch [670]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.211526,	
2017-06-27 10:57:55,126 Epoch[2] Batch [680]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.211548,	
2017-06-27 10:57:59,184 Epoch[2] Batch [690]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.211414,	
2017-06-27 10:58:03,220 Epoch[2] Batch [700]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.212102,	
2017-06-27 10:58:07,304 Epoch[2] Batch [710]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.211829,	
2017-06-27 10:58:11,364 Epoch[2] Batch [720]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.212144,	
2017-06-27 10:58:15,554 Epoch[2] Batch [730]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.211782,	
2017-06-27 10:58:19,674 Epoch[2] Batch [740]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.211985,	
2017-06-27 10:58:23,629 Epoch[2] Batch [750]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.212421,	
2017-06-27 10:58:27,605 Epoch[2] Batch [760]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.212690,	
2017-06-27 10:58:31,683 Epoch[2] Batch [770]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.212351,	
2017-06-27 10:58:36,385 Epoch[2] Batch [780]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.212383,	
2017-06-27 10:58:41,598 Epoch[2] Batch [790]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.211974,	
2017-06-27 10:58:46,833 Epoch[2] Batch [800]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.211632,	
2017-06-27 10:58:52,052 Epoch[2] Batch [810]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211644,	
2017-06-27 10:58:57,327 Epoch[2] Batch [820]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.211273,	
2017-06-27 10:59:02,600 Epoch[2] Batch [830]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.211364,	
2017-06-27 10:59:07,881 Epoch[2] Batch [840]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.211291,	
2017-06-27 10:59:13,119 Epoch[2] Batch [850]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.211084,	
2017-06-27 10:59:18,360 Epoch[2] Batch [860]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.211146,	
2017-06-27 10:59:23,642 Epoch[2] Batch [870]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.211213,	
2017-06-27 10:59:28,888 Epoch[2] Batch [880]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.211134,	
2017-06-27 10:59:34,130 Epoch[2] Batch [890]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.211077,	
2017-06-27 10:59:39,373 Epoch[2] Batch [900]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.210965,	
2017-06-27 10:59:44,624 Epoch[2] Batch [910]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.210949,	
2017-06-27 10:59:49,910 Epoch[2] Batch [920]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.210638,	
2017-06-27 10:59:55,204 Epoch[2] Batch [930]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.210423,	
2017-06-27 11:00:00,410 Epoch[2] Batch [940]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.210200,	
2017-06-27 11:00:05,696 Epoch[2] Batch [950]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.210026,	
2017-06-27 11:00:10,921 Epoch[2] Batch [960]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.209903,	
2017-06-27 11:00:16,224 Epoch[2] Batch [970]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.209669,	
2017-06-27 11:00:21,421 Epoch[2] Batch [980]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.209209,	
2017-06-27 11:00:26,622 Epoch[2] Batch [990]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.208974,	
2017-06-27 11:00:31,905 Epoch[2] Batch [1000]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.209084,	
2017-06-27 11:00:37,167 Epoch[2] Batch [1010]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.209187,	
2017-06-27 11:00:42,441 Epoch[2] Batch [1020]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.209088,	
2017-06-27 11:00:47,694 Epoch[2] Batch [1030]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.209117,	
2017-06-27 11:00:52,967 Epoch[2] Batch [1040]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.208895,	
2017-06-27 11:00:58,206 Epoch[2] Batch [1050]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.208628,	
2017-06-27 11:01:03,472 Epoch[2] Batch [1060]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.208421,	
2017-06-27 11:01:08,704 Epoch[2] Batch [1070]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.208128,	
2017-06-27 11:01:13,985 Epoch[2] Batch [1080]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.208273,	
2017-06-27 11:01:19,234 Epoch[2] Batch [1090]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.208065,	
2017-06-27 11:01:24,490 Epoch[2] Batch [1100]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.207899,	
2017-06-27 11:01:29,766 Epoch[2] Batch [1110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.208057,	
2017-06-27 11:01:35,018 Epoch[2] Batch [1120]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.208380,	
2017-06-27 11:01:40,297 Epoch[2] Batch [1130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.208382,	
2017-06-27 11:01:45,586 Epoch[2] Batch [1140]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.208277,	
2017-06-27 11:01:50,877 Epoch[2] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.208126,	
2017-06-27 11:01:56,115 Epoch[2] Batch [1160]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.207933,	
2017-06-27 11:02:01,383 Epoch[2] Batch [1170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.207776,	
2017-06-27 11:02:06,655 Epoch[2] Batch [1180]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.207732,	
2017-06-27 11:02:11,926 Epoch[2] Batch [1190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.207763,	
2017-06-27 11:02:17,216 Epoch[2] Batch [1200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.207925,	
2017-06-27 11:02:22,445 Epoch[2] Batch [1210]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.208080,	
2017-06-27 11:02:27,706 Epoch[2] Batch [1220]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.207924,	
2017-06-27 11:02:32,919 Epoch[2] Batch [1230]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.207965,	
2017-06-27 11:02:38,201 Epoch[2] Batch [1240]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.208061,	
2017-06-27 11:02:43,530 Epoch[2] Batch [1250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.207920,	
2017-06-27 11:02:48,717 Epoch[2] Batch [1260]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.207785,	
2017-06-27 11:02:53,985 Epoch[2] Batch [1270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.207972,	
2017-06-27 11:02:59,259 Epoch[2] Batch [1280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.207886,	
2017-06-27 11:03:04,506 Epoch[2] Batch [1290]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.207823,	
2017-06-27 11:03:09,762 Epoch[2] Batch [1300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.207921,	
2017-06-27 11:03:15,032 Epoch[2] Batch [1310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.207983,	
2017-06-27 11:03:20,306 Epoch[2] Batch [1320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.207590,	
2017-06-27 11:03:25,568 Epoch[2] Batch [1330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.207311,	
2017-06-27 11:03:30,852 Epoch[2] Batch [1340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.207470,	
2017-06-27 11:03:36,086 Epoch[2] Batch [1350]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.207216,	
2017-06-27 11:03:41,360 Epoch[2] Batch [1360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.207117,	
2017-06-27 11:03:46,604 Epoch[2] Batch [1370]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.206976,	
2017-06-27 11:03:51,885 Epoch[2] Batch [1380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.206759,	
2017-06-27 11:03:57,116 Epoch[2] Batch [1390]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.206702,	
2017-06-27 11:04:02,370 Epoch[2] Batch [1400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.206472,	
2017-06-27 11:04:07,637 Epoch[2] Batch [1410]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.206378,	
2017-06-27 11:04:12,907 Epoch[2] Batch [1420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.206167,	
2017-06-27 11:04:18,139 Epoch[2] Batch [1430]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.206151,	
2017-06-27 11:04:23,467 Epoch[2] Batch [1440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.206009,	
2017-06-27 11:04:28,673 Epoch[2] Batch [1450]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.206000,	
2017-06-27 11:04:33,937 Epoch[2] Batch [1460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.205935,	
2017-06-27 11:04:39,206 Epoch[2] Batch [1470]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.205712,	
2017-06-27 11:04:44,456 Epoch[2] Batch [1480]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.205429,	
2017-06-27 11:04:47,597 Epoch[2] Train-FCNLogLoss=0.205588
2017-06-27 11:04:47,597 Epoch[2] Time cost=684.971
2017-06-27 11:04:48,392 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0003.params"
2017-06-27 11:04:49,969 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0003.states"
2017-06-27 11:04:55,945 Epoch[3] Batch [10]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.160506,	
2017-06-27 11:05:01,201 Epoch[3] Batch [20]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.170481,	
2017-06-27 11:05:06,461 Epoch[3] Batch [30]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.178172,	
2017-06-27 11:05:11,699 Epoch[3] Batch [40]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.175229,	
2017-06-27 11:05:16,965 Epoch[3] Batch [50]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.178224,	
2017-06-27 11:05:21,730 Epoch[3] Batch [60]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.179141,	
2017-06-27 11:05:26,408 Epoch[3] Batch [70]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.178450,	
2017-06-27 11:05:31,176 Epoch[3] Batch [80]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.180865,	
2017-06-27 11:05:35,211 Epoch[3] Batch [90]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.180547,	
2017-06-27 11:05:39,098 Epoch[3] Batch [100]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.178052,	
2017-06-27 11:05:42,890 Epoch[3] Batch [110]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.179948,	
2017-06-27 11:05:46,758 Epoch[3] Batch [120]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.179083,	
2017-06-27 11:05:50,724 Epoch[3] Batch [130]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.183373,	
2017-06-27 11:05:55,558 Epoch[3] Batch [140]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.182921,	
2017-06-27 11:06:00,190 Epoch[3] Batch [150]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.183606,	
2017-06-27 11:06:04,781 Epoch[3] Batch [160]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.184001,	
2017-06-27 11:06:09,732 Epoch[3] Batch [170]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.184095,	
2017-06-27 11:06:13,599 Epoch[3] Batch [180]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.186113,	
2017-06-27 11:06:17,571 Epoch[3] Batch [190]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.186142,	
2017-06-27 11:06:22,752 Epoch[3] Batch [200]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.184593,	
2017-06-27 11:06:28,030 Epoch[3] Batch [210]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.185118,	
2017-06-27 11:06:32,803 Epoch[3] Batch [220]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.184951,	
2017-06-27 11:06:37,757 Epoch[3] Batch [230]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.184683,	
2017-06-27 11:06:42,568 Epoch[3] Batch [240]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.183813,	
2017-06-27 11:06:47,350 Epoch[3] Batch [250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.182242,	
2017-06-27 11:06:52,128 Epoch[3] Batch [260]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.182723,	
2017-06-27 11:06:57,120 Epoch[3] Batch [270]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.182748,	
2017-06-27 11:07:02,131 Epoch[3] Batch [280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.184114,	
2017-06-27 11:07:07,064 Epoch[3] Batch [290]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.184395,	
2017-06-27 11:07:12,115 Epoch[3] Batch [300]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.184988,	
2017-06-27 11:07:17,363 Epoch[3] Batch [310]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.185054,	
2017-06-27 11:07:22,430 Epoch[3] Batch [320]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.185809,	
2017-06-27 11:07:27,252 Epoch[3] Batch [330]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.186855,	
2017-06-27 11:07:31,702 Epoch[3] Batch [340]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.186508,	
2017-06-27 11:07:36,443 Epoch[3] Batch [350]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.186289,	
2017-06-27 11:07:41,313 Epoch[3] Batch [360]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.186777,	
2017-06-27 11:07:45,670 Epoch[3] Batch [370]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.187032,	
2017-06-27 11:07:50,821 Epoch[3] Batch [380]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.186844,	
2017-06-27 11:07:56,070 Epoch[3] Batch [390]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.186331,	
2017-06-27 11:08:00,951 Epoch[3] Batch [400]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.185812,	
2017-06-27 11:08:05,953 Epoch[3] Batch [410]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.185186,	
2017-06-27 11:08:10,657 Epoch[3] Batch [420]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.186903,	
2017-06-27 11:08:15,764 Epoch[3] Batch [430]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.187066,	
2017-06-27 11:08:20,672 Epoch[3] Batch [440]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.187253,	
2017-06-27 11:08:25,269 Epoch[3] Batch [450]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.187091,	
2017-06-27 11:08:30,058 Epoch[3] Batch [460]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.187397,	
2017-06-27 11:08:34,651 Epoch[3] Batch [470]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.187078,	
2017-06-27 11:08:39,606 Epoch[3] Batch [480]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.187133,	
2017-06-27 11:08:44,508 Epoch[3] Batch [490]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.186922,	
2017-06-27 11:08:49,559 Epoch[3] Batch [500]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.186524,	
2017-06-27 11:08:53,687 Epoch[3] Batch [510]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.186854,	
2017-06-27 11:08:58,183 Epoch[3] Batch [520]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.186263,	
2017-06-27 11:09:01,959 Epoch[3] Batch [530]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.186020,	
2017-06-27 11:09:05,827 Epoch[3] Batch [540]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.185505,	
2017-06-27 11:09:10,703 Epoch[3] Batch [550]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.185480,	
2017-06-27 11:09:15,510 Epoch[3] Batch [560]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.185079,	
2017-06-27 11:09:20,185 Epoch[3] Batch [570]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.184738,	
2017-06-27 11:09:24,719 Epoch[3] Batch [580]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.184785,	
2017-06-27 11:09:29,208 Epoch[3] Batch [590]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.184691,	
2017-06-27 11:09:33,242 Epoch[3] Batch [600]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.185003,	
2017-06-27 11:09:37,069 Epoch[3] Batch [610]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.185153,	
2017-06-27 11:09:42,243 Epoch[3] Batch [620]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.184944,	
2017-06-27 11:09:46,153 Epoch[3] Batch [630]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.185039,	
2017-06-27 11:09:50,308 Epoch[3] Batch [640]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.185238,	
2017-06-27 11:09:54,226 Epoch[3] Batch [650]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.185352,	
2017-06-27 11:09:59,938 Epoch[3] Batch [660]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.185472,	
2017-06-27 11:10:04,077 Epoch[3] Batch [670]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.185262,	
2017-06-27 11:10:08,289 Epoch[3] Batch [680]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.185045,	
2017-06-27 11:10:12,687 Epoch[3] Batch [690]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.184535,	
2017-06-27 11:10:16,643 Epoch[3] Batch [700]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.184217,	
2017-06-27 11:10:20,950 Epoch[3] Batch [710]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.184064,	
2017-06-27 11:10:25,678 Epoch[3] Batch [720]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.184080,	
2017-06-27 11:10:30,163 Epoch[3] Batch [730]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.183775,	
2017-06-27 11:10:34,109 Epoch[3] Batch [740]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.183807,	
2017-06-27 11:10:37,914 Epoch[3] Batch [750]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.183636,	
2017-06-27 11:10:42,497 Epoch[3] Batch [760]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.183624,	
2017-06-27 11:10:47,444 Epoch[3] Batch [770]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.183875,	
2017-06-27 11:10:52,676 Epoch[3] Batch [780]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.183751,	
2017-06-27 11:10:56,709 Epoch[3] Batch [790]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.183650,	
2017-06-27 11:11:00,616 Epoch[3] Batch [800]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.183873,	
2017-06-27 11:11:05,045 Epoch[3] Batch [810]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.184314,	
2017-06-27 11:11:09,451 Epoch[3] Batch [820]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.184190,	
2017-06-27 11:11:13,630 Epoch[3] Batch [830]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.184046,	
2017-06-27 11:11:17,351 Epoch[3] Batch [840]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.183920,	
2017-06-27 11:11:23,717 Epoch[3] Batch [850]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.183838,	
2017-06-27 11:11:27,707 Epoch[3] Batch [860]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.183456,	
2017-06-27 11:11:32,355 Epoch[3] Batch [870]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.183277,	
2017-06-27 11:11:37,233 Epoch[3] Batch [880]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.183674,	
2017-06-27 11:11:41,676 Epoch[3] Batch [890]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.184096,	
2017-06-27 11:11:46,211 Epoch[3] Batch [900]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.184181,	
2017-06-27 11:11:50,099 Epoch[3] Batch [910]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.184293,	
2017-06-27 11:11:54,046 Epoch[3] Batch [920]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.184329,	
2017-06-27 11:11:57,929 Epoch[3] Batch [930]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.184465,	
2017-06-27 11:12:01,645 Epoch[3] Batch [940]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.184595,	
2017-06-27 11:12:07,559 Epoch[3] Batch [950]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.184432,	
2017-06-27 11:12:12,708 Epoch[3] Batch [960]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.184411,	
2017-06-27 11:12:18,077 Epoch[3] Batch [970]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.184531,	
2017-06-27 11:12:21,893 Epoch[3] Batch [980]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.184303,	
2017-06-27 11:12:27,037 Epoch[3] Batch [990]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.184214,	
2017-06-27 11:12:31,007 Epoch[3] Batch [1000]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.184027,	
2017-06-27 11:12:35,352 Epoch[3] Batch [1010]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.183924,	
2017-06-27 11:12:39,783 Epoch[3] Batch [1020]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.184081,	
2017-06-27 11:12:43,816 Epoch[3] Batch [1030]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.183871,	
2017-06-27 11:12:48,397 Epoch[3] Batch [1040]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.183670,	
2017-06-27 11:12:52,228 Epoch[3] Batch [1050]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.183636,	
2017-06-27 11:12:57,144 Epoch[3] Batch [1060]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.183511,	
2017-06-27 11:13:01,043 Epoch[3] Batch [1070]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.183907,	
2017-06-27 11:13:05,528 Epoch[3] Batch [1080]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.183936,	
2017-06-27 11:13:10,368 Epoch[3] Batch [1090]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.183811,	
2017-06-27 11:13:16,170 Epoch[3] Batch [1100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.183529,	
2017-06-27 11:13:20,158 Epoch[3] Batch [1110]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.183314,	
2017-06-27 11:13:25,177 Epoch[3] Batch [1120]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.183165,	
2017-06-27 11:13:29,241 Epoch[3] Batch [1130]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.182971,	
2017-06-27 11:13:33,141 Epoch[3] Batch [1140]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.182859,	
2017-06-27 11:13:37,010 Epoch[3] Batch [1150]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.182750,	
2017-06-27 11:13:40,890 Epoch[3] Batch [1160]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.182929,	
2017-06-27 11:13:45,073 Epoch[3] Batch [1170]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.182648,	
2017-06-27 11:13:50,275 Epoch[3] Batch [1180]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.182518,	
2017-06-27 11:13:55,300 Epoch[3] Batch [1190]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.182223,	
2017-06-27 11:14:00,447 Epoch[3] Batch [1200]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.182221,	
2017-06-27 11:14:05,709 Epoch[3] Batch [1210]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.182102,	
2017-06-27 11:14:10,926 Epoch[3] Batch [1220]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.182000,	
2017-06-27 11:14:16,174 Epoch[3] Batch [1230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.182403,	
2017-06-27 11:14:21,411 Epoch[3] Batch [1240]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.182261,	
2017-06-27 11:14:26,673 Epoch[3] Batch [1250]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.182137,	
2017-06-27 11:14:31,906 Epoch[3] Batch [1260]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.182323,	
2017-06-27 11:14:37,140 Epoch[3] Batch [1270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.182453,	
2017-06-27 11:14:42,368 Epoch[3] Batch [1280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.182274,	
2017-06-27 11:14:47,615 Epoch[3] Batch [1290]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.182057,	
2017-06-27 11:14:52,891 Epoch[3] Batch [1300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.182130,	
2017-06-27 11:14:58,105 Epoch[3] Batch [1310]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.182072,	
2017-06-27 11:15:03,383 Epoch[3] Batch [1320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.182249,	
2017-06-27 11:15:08,671 Epoch[3] Batch [1330]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.182136,	
2017-06-27 11:15:13,896 Epoch[3] Batch [1340]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.182141,	
2017-06-27 11:15:19,140 Epoch[3] Batch [1350]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.182123,	
2017-06-27 11:15:24,405 Epoch[3] Batch [1360]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.181976,	
2017-06-27 11:15:29,645 Epoch[3] Batch [1370]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.181847,	
2017-06-27 11:15:34,885 Epoch[3] Batch [1380]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.181638,	
2017-06-27 11:15:40,124 Epoch[3] Batch [1390]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.181455,	
2017-06-27 11:15:45,357 Epoch[3] Batch [1400]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.181426,	
2017-06-27 11:15:50,657 Epoch[3] Batch [1410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.181421,	
2017-06-27 11:15:55,848 Epoch[3] Batch [1420]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.181256,	
2017-06-27 11:16:01,031 Epoch[3] Batch [1430]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.181221,	
2017-06-27 11:16:04,987 Epoch[3] Batch [1440]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.181402,	
2017-06-27 11:16:09,064 Epoch[3] Batch [1450]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.181424,	
2017-06-27 11:16:14,009 Epoch[3] Batch [1460]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.181374,	
2017-06-27 11:16:19,283 Epoch[3] Batch [1470]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.181342,	
2017-06-27 11:16:24,509 Epoch[3] Batch [1480]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.181278,	
2017-06-27 11:16:27,670 Epoch[3] Train-FCNLogLoss=0.181162
2017-06-27 11:16:27,671 Epoch[3] Time cost=697.701
2017-06-27 11:16:28,484 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0004.params"
2017-06-27 11:16:30,220 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0004.states"
2017-06-27 11:16:36,098 Epoch[4] Batch [10]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.184072,	
2017-06-27 11:16:41,330 Epoch[4] Batch [20]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.191012,	
2017-06-27 11:16:46,590 Epoch[4] Batch [30]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.196837,	
2017-06-27 11:16:51,843 Epoch[4] Batch [40]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.192075,	
2017-06-27 11:16:57,128 Epoch[4] Batch [50]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.188578,	
2017-06-27 11:17:02,334 Epoch[4] Batch [60]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.187753,	
2017-06-27 11:17:07,598 Epoch[4] Batch [70]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.188638,	
2017-06-27 11:17:12,847 Epoch[4] Batch [80]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.190522,	
2017-06-27 11:17:18,108 Epoch[4] Batch [90]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.192220,	
2017-06-27 11:17:23,357 Epoch[4] Batch [100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.190284,	
2017-06-27 11:17:28,607 Epoch[4] Batch [110]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.191591,	
2017-06-27 11:17:33,757 Epoch[4] Batch [120]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.189826,	
2017-06-27 11:17:39,064 Epoch[4] Batch [130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.189228,	
2017-06-27 11:17:44,359 Epoch[4] Batch [140]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.187066,	
2017-06-27 11:17:49,594 Epoch[4] Batch [150]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.185054,	
2017-06-27 11:17:54,875 Epoch[4] Batch [160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.183438,	
2017-06-27 11:18:00,112 Epoch[4] Batch [170]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.182713,	
2017-06-27 11:18:05,358 Epoch[4] Batch [180]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.181490,	
2017-06-27 11:18:10,599 Epoch[4] Batch [190]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.180371,	
2017-06-27 11:18:15,852 Epoch[4] Batch [200]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.179948,	
2017-06-27 11:18:21,102 Epoch[4] Batch [210]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.180180,	
2017-06-27 11:18:26,384 Epoch[4] Batch [220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.180201,	
2017-06-27 11:18:31,652 Epoch[4] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.179957,	
2017-06-27 11:18:36,930 Epoch[4] Batch [240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.180979,	
2017-06-27 11:18:42,172 Epoch[4] Batch [250]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.180288,	
2017-06-27 11:18:47,461 Epoch[4] Batch [260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.179467,	
2017-06-27 11:18:52,675 Epoch[4] Batch [270]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.180404,	
2017-06-27 11:18:57,936 Epoch[4] Batch [280]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.179900,	
2017-06-27 11:19:03,198 Epoch[4] Batch [290]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.179758,	
2017-06-27 11:19:08,486 Epoch[4] Batch [300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.178315,	
2017-06-27 11:19:13,710 Epoch[4] Batch [310]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.178314,	
2017-06-27 11:19:18,989 Epoch[4] Batch [320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.178078,	
2017-06-27 11:19:24,232 Epoch[4] Batch [330]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.177408,	
2017-06-27 11:19:29,502 Epoch[4] Batch [340]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.177091,	
2017-06-27 11:19:34,721 Epoch[4] Batch [350]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.176716,	
2017-06-27 11:19:40,028 Epoch[4] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.175584,	
2017-06-27 11:19:45,288 Epoch[4] Batch [370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.176133,	
2017-06-27 11:19:50,538 Epoch[4] Batch [380]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.175912,	
2017-06-27 11:19:55,821 Epoch[4] Batch [390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.175518,	
2017-06-27 11:20:01,098 Epoch[4] Batch [400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.176238,	
2017-06-27 11:20:06,332 Epoch[4] Batch [410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.175584,	
2017-06-27 11:20:11,467 Epoch[4] Batch [420]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.175808,	
2017-06-27 11:20:16,724 Epoch[4] Batch [430]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.175665,	
2017-06-27 11:20:21,953 Epoch[4] Batch [440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.175339,	
2017-06-27 11:20:27,225 Epoch[4] Batch [450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.175119,	
2017-06-27 11:20:32,493 Epoch[4] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.174513,	
2017-06-27 11:20:37,758 Epoch[4] Batch [470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.174200,	
2017-06-27 11:20:43,027 Epoch[4] Batch [480]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.173855,	
2017-06-27 11:20:48,291 Epoch[4] Batch [490]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.173266,	
2017-06-27 11:20:53,535 Epoch[4] Batch [500]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.172580,	
2017-06-27 11:20:58,802 Epoch[4] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.173142,	
2017-06-27 11:21:04,032 Epoch[4] Batch [520]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.173098,	
2017-06-27 11:21:09,320 Epoch[4] Batch [530]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.173276,	
2017-06-27 11:21:14,600 Epoch[4] Batch [540]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.172977,	
2017-06-27 11:21:19,855 Epoch[4] Batch [550]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.172809,	
2017-06-27 11:21:25,117 Epoch[4] Batch [560]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.172925,	
2017-06-27 11:21:30,381 Epoch[4] Batch [570]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.172952,	
2017-06-27 11:21:35,633 Epoch[4] Batch [580]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.173040,	
2017-06-27 11:21:40,893 Epoch[4] Batch [590]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.173264,	
2017-06-27 11:21:46,189 Epoch[4] Batch [600]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.173135,	
2017-06-27 11:21:51,416 Epoch[4] Batch [610]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.173035,	
2017-06-27 11:21:56,710 Epoch[4] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.172886,	
2017-06-27 11:22:01,956 Epoch[4] Batch [630]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.172753,	
2017-06-27 11:22:07,211 Epoch[4] Batch [640]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.172770,	
2017-06-27 11:22:12,530 Epoch[4] Batch [650]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.172788,	
2017-06-27 11:22:17,726 Epoch[4] Batch [660]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.172683,	
2017-06-27 11:22:22,998 Epoch[4] Batch [670]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.172605,	
2017-06-27 11:22:28,270 Epoch[4] Batch [680]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.172488,	
2017-06-27 11:22:33,515 Epoch[4] Batch [690]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.172111,	
2017-06-27 11:22:38,767 Epoch[4] Batch [700]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.172080,	
2017-06-27 11:22:43,941 Epoch[4] Batch [710]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.171858,	
2017-06-27 11:22:48,789 Epoch[4] Batch [720]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.171821,	
2017-06-27 11:22:54,066 Epoch[4] Batch [730]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.171784,	
2017-06-27 11:22:59,290 Epoch[4] Batch [740]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.171681,	
2017-06-27 11:23:04,515 Epoch[4] Batch [750]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.171869,	
2017-06-27 11:23:09,766 Epoch[4] Batch [760]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.171627,	
2017-06-27 11:23:15,037 Epoch[4] Batch [770]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171465,	
2017-06-27 11:23:20,305 Epoch[4] Batch [780]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171482,	
2017-06-27 11:23:25,592 Epoch[4] Batch [790]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.171444,	
2017-06-27 11:23:30,808 Epoch[4] Batch [800]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.171202,	
2017-06-27 11:23:36,078 Epoch[4] Batch [810]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171206,	
2017-06-27 11:23:41,332 Epoch[4] Batch [820]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.171197,	
2017-06-27 11:23:46,572 Epoch[4] Batch [830]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.171650,	
2017-06-27 11:23:51,795 Epoch[4] Batch [840]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.171562,	
2017-06-27 11:23:57,051 Epoch[4] Batch [850]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.172202,	
2017-06-27 11:24:02,300 Epoch[4] Batch [860]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.172081,	
2017-06-27 11:24:07,579 Epoch[4] Batch [870]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.172324,	
2017-06-27 11:24:12,825 Epoch[4] Batch [880]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.172017,	
2017-06-27 11:24:18,077 Epoch[4] Batch [890]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.172181,	
2017-06-27 11:24:23,291 Epoch[4] Batch [900]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.171987,	
2017-06-27 11:24:28,580 Epoch[4] Batch [910]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.171775,	
2017-06-27 11:24:33,801 Epoch[4] Batch [920]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.171682,	
2017-06-27 11:24:39,087 Epoch[4] Batch [930]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.171604,	
2017-06-27 11:24:44,310 Epoch[4] Batch [940]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.171574,	
2017-06-27 11:24:49,589 Epoch[4] Batch [950]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.171430,	
2017-06-27 11:24:54,894 Epoch[4] Batch [960]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.171333,	
2017-06-27 11:25:00,168 Epoch[4] Batch [970]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171122,	
2017-06-27 11:25:05,400 Epoch[4] Batch [980]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.171242,	
2017-06-27 11:25:10,619 Epoch[4] Batch [990]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.171197,	
2017-06-27 11:25:15,370 Epoch[4] Batch [1000]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.171411,	
2017-06-27 11:25:19,673 Epoch[4] Batch [1010]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.171367,	
2017-06-27 11:25:23,545 Epoch[4] Batch [1020]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.171325,	
2017-06-27 11:25:27,752 Epoch[4] Batch [1030]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.171633,	
2017-06-27 11:25:31,796 Epoch[4] Batch [1040]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.171583,	
2017-06-27 11:25:36,056 Epoch[4] Batch [1050]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.171660,	
2017-06-27 11:25:40,225 Epoch[4] Batch [1060]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.171444,	
2017-06-27 11:25:45,428 Epoch[4] Batch [1070]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.171470,	
2017-06-27 11:25:49,975 Epoch[4] Batch [1080]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.171529,	
2017-06-27 11:25:54,977 Epoch[4] Batch [1090]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.171516,	
2017-06-27 11:25:58,862 Epoch[4] Batch [1100]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.171438,	
2017-06-27 11:26:03,439 Epoch[4] Batch [1110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.171649,	
2017-06-27 11:26:08,750 Epoch[4] Batch [1120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.172123,	
2017-06-27 11:26:12,695 Epoch[4] Batch [1130]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.172349,	
2017-06-27 11:26:18,811 Epoch[4] Batch [1140]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.172609,	
2017-06-27 11:26:23,388 Epoch[4] Batch [1150]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.172661,	
2017-06-27 11:26:27,585 Epoch[4] Batch [1160]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.172635,	
2017-06-27 11:26:32,249 Epoch[4] Batch [1170]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.172446,	
2017-06-27 11:26:36,919 Epoch[4] Batch [1180]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.172406,	
2017-06-27 11:26:44,501 Epoch[4] Batch [1190]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.172367,	
2017-06-27 11:26:49,517 Epoch[4] Batch [1200]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.172298,	
2017-06-27 11:26:53,292 Epoch[4] Batch [1210]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.172285,	
2017-06-27 11:26:57,577 Epoch[4] Batch [1220]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.172088,	
2017-06-27 11:27:02,860 Epoch[4] Batch [1230]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.171899,	
2017-06-27 11:27:06,658 Epoch[4] Batch [1240]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.171986,	
2017-06-27 11:27:11,204 Epoch[4] Batch [1250]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.171988,	
2017-06-27 11:27:16,222 Epoch[4] Batch [1260]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.171778,	
2017-06-27 11:27:21,457 Epoch[4] Batch [1270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.171755,	
2017-06-27 11:27:26,702 Epoch[4] Batch [1280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.171524,	
2017-06-27 11:27:31,929 Epoch[4] Batch [1290]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.171396,	
2017-06-27 11:27:37,141 Epoch[4] Batch [1300]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.171176,	
2017-06-27 11:27:42,380 Epoch[4] Batch [1310]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.170941,	
2017-06-27 11:27:47,619 Epoch[4] Batch [1320]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.170790,	
2017-06-27 11:27:52,897 Epoch[4] Batch [1330]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.170914,	
2017-06-27 11:27:58,121 Epoch[4] Batch [1340]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.171257,	
2017-06-27 11:28:03,355 Epoch[4] Batch [1350]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.171236,	
2017-06-27 11:28:08,642 Epoch[4] Batch [1360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.171377,	
2017-06-27 11:28:13,913 Epoch[4] Batch [1370]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171451,	
2017-06-27 11:28:19,147 Epoch[4] Batch [1380]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.171508,	
2017-06-27 11:28:24,388 Epoch[4] Batch [1390]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.171637,	
2017-06-27 11:28:29,677 Epoch[4] Batch [1400]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.171596,	
2017-06-27 11:28:34,891 Epoch[4] Batch [1410]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.171332,	
2017-06-27 11:28:40,164 Epoch[4] Batch [1420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171321,	
2017-06-27 11:28:45,403 Epoch[4] Batch [1430]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.171704,	
2017-06-27 11:28:50,675 Epoch[4] Batch [1440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171790,	
2017-06-27 11:28:55,946 Epoch[4] Batch [1450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.171785,	
2017-06-27 11:29:01,208 Epoch[4] Batch [1460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.171715,	
2017-06-27 11:29:06,471 Epoch[4] Batch [1470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.171613,	
2017-06-27 11:29:11,724 Epoch[4] Batch [1480]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.171577,	
2017-06-27 11:29:14,905 Epoch[4] Train-FCNLogLoss=0.171534
2017-06-27 11:29:14,906 Epoch[4] Time cost=764.685
2017-06-27 11:29:15,706 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0005.params"
2017-06-27 11:29:17,300 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0005.states"
2017-06-27 11:29:23,121 Epoch[5] Batch [10]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.145693,	
2017-06-27 11:29:28,335 Epoch[5] Batch [20]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.149171,	
2017-06-27 11:29:33,592 Epoch[5] Batch [30]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.155733,	
2017-06-27 11:29:38,843 Epoch[5] Batch [40]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.154893,	
2017-06-27 11:29:44,116 Epoch[5] Batch [50]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.154724,	
2017-06-27 11:29:49,364 Epoch[5] Batch [60]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.155159,	
2017-06-27 11:29:54,636 Epoch[5] Batch [70]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.158378,	
2017-06-27 11:29:59,868 Epoch[5] Batch [80]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.159224,	
2017-06-27 11:30:05,117 Epoch[5] Batch [90]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.157823,	
2017-06-27 11:30:10,369 Epoch[5] Batch [100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.159190,	
2017-06-27 11:30:15,635 Epoch[5] Batch [110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.158112,	
2017-06-27 11:30:20,865 Epoch[5] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.158744,	
2017-06-27 11:30:25,904 Epoch[5] Batch [130]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.160016,	
2017-06-27 11:30:31,164 Epoch[5] Batch [140]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.158955,	
2017-06-27 11:30:35,628 Epoch[5] Batch [150]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.158551,	
2017-06-27 11:30:39,915 Epoch[5] Batch [160]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.158728,	
2017-06-27 11:30:45,103 Epoch[5] Batch [170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.157583,	
2017-06-27 11:30:50,330 Epoch[5] Batch [180]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.158083,	
2017-06-27 11:30:55,598 Epoch[5] Batch [190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.160402,	
2017-06-27 11:31:00,843 Epoch[5] Batch [200]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.162015,	
2017-06-27 11:31:06,131 Epoch[5] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.162557,	
2017-06-27 11:31:11,390 Epoch[5] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.162224,	
2017-06-27 11:31:16,620 Epoch[5] Batch [230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.161810,	
2017-06-27 11:31:21,900 Epoch[5] Batch [240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.161287,	
2017-06-27 11:31:27,156 Epoch[5] Batch [250]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.162415,	
2017-06-27 11:31:32,404 Epoch[5] Batch [260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.161673,	
2017-06-27 11:31:37,693 Epoch[5] Batch [270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.161682,	
2017-06-27 11:31:42,906 Epoch[5] Batch [280]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.162015,	
2017-06-27 11:31:48,187 Epoch[5] Batch [290]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.162058,	
2017-06-27 11:31:53,427 Epoch[5] Batch [300]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.161692,	
2017-06-27 11:31:58,695 Epoch[5] Batch [310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.161012,	
2017-06-27 11:32:03,924 Epoch[5] Batch [320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.161430,	
2017-06-27 11:32:09,226 Epoch[5] Batch [330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.161392,	
2017-06-27 11:32:14,548 Epoch[5] Batch [340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.161027,	
2017-06-27 11:32:19,722 Epoch[5] Batch [350]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.160429,	
2017-06-27 11:32:25,024 Epoch[5] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.160151,	
2017-06-27 11:32:30,230 Epoch[5] Batch [370]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.160067,	
2017-06-27 11:32:35,457 Epoch[5] Batch [380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.159922,	
2017-06-27 11:32:40,762 Epoch[5] Batch [390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.159570,	
2017-06-27 11:32:46,029 Epoch[5] Batch [400]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.159381,	
2017-06-27 11:32:51,258 Epoch[5] Batch [410]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.159294,	
2017-06-27 11:32:56,532 Epoch[5] Batch [420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.159447,	
2017-06-27 11:33:01,772 Epoch[5] Batch [430]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.159429,	
2017-06-27 11:33:07,010 Epoch[5] Batch [440]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.159084,	
2017-06-27 11:33:12,292 Epoch[5] Batch [450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.158896,	
2017-06-27 11:33:17,548 Epoch[5] Batch [460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.158727,	
2017-06-27 11:33:22,810 Epoch[5] Batch [470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.159870,	
2017-06-27 11:33:27,473 Epoch[5] Batch [480]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.159989,	
2017-06-27 11:33:31,608 Epoch[5] Batch [490]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.160208,	
2017-06-27 11:33:35,822 Epoch[5] Batch [500]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.160009,	
2017-06-27 11:33:40,245 Epoch[5] Batch [510]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.160071,	
2017-06-27 11:33:45,044 Epoch[5] Batch [520]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.159936,	
2017-06-27 11:33:49,279 Epoch[5] Batch [530]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.160368,	
2017-06-27 11:33:54,083 Epoch[5] Batch [540]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.160565,	
2017-06-27 11:33:58,500 Epoch[5] Batch [550]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.160197,	
2017-06-27 11:34:03,220 Epoch[5] Batch [560]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.160499,	
2017-06-27 11:34:07,846 Epoch[5] Batch [570]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.160262,	
2017-06-27 11:34:12,323 Epoch[5] Batch [580]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.160440,	
2017-06-27 11:34:17,163 Epoch[5] Batch [590]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.160417,	
2017-06-27 11:34:21,267 Epoch[5] Batch [600]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.160360,	
2017-06-27 11:34:25,222 Epoch[5] Batch [610]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.160584,	
2017-06-27 11:34:29,511 Epoch[5] Batch [620]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.160791,	
2017-06-27 11:34:33,545 Epoch[5] Batch [630]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.160713,	
2017-06-27 11:34:37,628 Epoch[5] Batch [640]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.160605,	
2017-06-27 11:34:42,857 Epoch[5] Batch [650]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.160472,	
2017-06-27 11:34:47,291 Epoch[5] Batch [660]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.160436,	
2017-06-27 11:34:51,799 Epoch[5] Batch [670]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.160475,	
2017-06-27 11:34:57,000 Epoch[5] Batch [680]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.160325,	
2017-06-27 11:35:01,204 Epoch[5] Batch [690]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.160272,	
2017-06-27 11:35:06,031 Epoch[5] Batch [700]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.160384,	
2017-06-27 11:35:10,403 Epoch[5] Batch [710]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.160435,	
2017-06-27 11:35:14,887 Epoch[5] Batch [720]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.160486,	
2017-06-27 11:35:19,161 Epoch[5] Batch [730]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.160836,	
2017-06-27 11:35:23,484 Epoch[5] Batch [740]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.160811,	
2017-06-27 11:35:27,244 Epoch[5] Batch [750]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.160882,	
2017-06-27 11:35:33,009 Epoch[5] Batch [760]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.161171,	
2017-06-27 11:35:37,788 Epoch[5] Batch [770]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.161259,	
2017-06-27 11:35:42,386 Epoch[5] Batch [780]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.161334,	
2017-06-27 11:35:46,242 Epoch[5] Batch [790]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.161183,	
2017-06-27 11:35:50,145 Epoch[5] Batch [800]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.161051,	
2017-06-27 11:35:54,992 Epoch[5] Batch [810]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.161085,	
2017-06-27 11:35:58,841 Epoch[5] Batch [820]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.161224,	
2017-06-27 11:36:03,760 Epoch[5] Batch [830]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.161580,	
2017-06-27 11:36:07,907 Epoch[5] Batch [840]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.161913,	
2017-06-27 11:36:12,100 Epoch[5] Batch [850]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.161670,	
2017-06-27 11:36:15,960 Epoch[5] Batch [860]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.161622,	
2017-06-27 11:36:22,309 Epoch[5] Batch [870]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.162102,	
2017-06-27 11:36:27,345 Epoch[5] Batch [880]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.162201,	
2017-06-27 11:36:32,067 Epoch[5] Batch [890]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.162112,	
2017-06-27 11:36:36,046 Epoch[5] Batch [900]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.162144,	
2017-06-27 11:36:39,949 Epoch[5] Batch [910]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.162044,	
2017-06-27 11:36:44,489 Epoch[5] Batch [920]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.161931,	
2017-06-27 11:36:48,334 Epoch[5] Batch [930]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.161703,	
2017-06-27 11:36:53,174 Epoch[5] Batch [940]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.161589,	
2017-06-27 11:36:57,083 Epoch[5] Batch [950]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.161575,	
2017-06-27 11:37:00,959 Epoch[5] Batch [960]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.161613,	
2017-06-27 11:37:04,850 Epoch[5] Batch [970]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.161523,	
2017-06-27 11:37:09,044 Epoch[5] Batch [980]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.161427,	
2017-06-27 11:37:12,855 Epoch[5] Batch [990]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.161642,	
2017-06-27 11:37:17,302 Epoch[5] Batch [1000]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.161365,	
2017-06-27 11:37:21,236 Epoch[5] Batch [1010]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.161336,	
2017-06-27 11:37:25,546 Epoch[5] Batch [1020]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.161304,	
2017-06-27 11:37:29,381 Epoch[5] Batch [1030]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.161253,	
2017-06-27 11:37:33,268 Epoch[5] Batch [1040]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.161231,	
2017-06-27 11:37:38,529 Epoch[5] Batch [1050]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.161382,	
2017-06-27 11:37:43,854 Epoch[5] Batch [1060]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.161601,	
2017-06-27 11:37:48,252 Epoch[5] Batch [1070]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.161564,	
2017-06-27 11:37:52,510 Epoch[5] Batch [1080]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.161670,	
2017-06-27 11:37:56,310 Epoch[5] Batch [1090]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.161619,	
2017-06-27 11:38:00,894 Epoch[5] Batch [1100]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.161490,	
2017-06-27 11:38:05,702 Epoch[5] Batch [1110]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.161427,	
2017-06-27 11:38:10,900 Epoch[5] Batch [1120]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.161337,	
2017-06-27 11:38:14,862 Epoch[5] Batch [1130]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.161539,	
2017-06-27 11:38:21,675 Epoch[5] Batch [1140]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.161611,	
2017-06-27 11:38:26,203 Epoch[5] Batch [1150]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.161552,	
2017-06-27 11:38:30,538 Epoch[5] Batch [1160]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.161713,	
2017-06-27 11:38:35,909 Epoch[5] Batch [1170]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.161764,	
2017-06-27 11:38:39,705 Epoch[5] Batch [1180]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.162072,	
2017-06-27 11:38:44,262 Epoch[5] Batch [1190]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.161888,	
2017-06-27 11:38:48,719 Epoch[5] Batch [1200]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.162025,	
2017-06-27 11:38:53,680 Epoch[5] Batch [1210]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.161844,	
2017-06-27 11:38:58,053 Epoch[5] Batch [1220]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.161678,	
2017-06-27 11:39:03,207 Epoch[5] Batch [1230]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.161691,	
2017-06-27 11:39:09,736 Epoch[5] Batch [1240]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.161707,	
2017-06-27 11:39:14,343 Epoch[5] Batch [1250]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.161833,	
2017-06-27 11:39:18,294 Epoch[5] Batch [1260]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.161801,	
2017-06-27 11:39:24,452 Epoch[5] Batch [1270]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.161810,	
2017-06-27 11:39:29,163 Epoch[5] Batch [1280]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.161786,	
2017-06-27 11:39:34,198 Epoch[5] Batch [1290]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.161731,	
2017-06-27 11:39:39,460 Epoch[5] Batch [1300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.161719,	
2017-06-27 11:39:43,838 Epoch[5] Batch [1310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.162023,	
2017-06-27 11:39:47,788 Epoch[5] Batch [1320]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.161973,	
2017-06-27 11:39:51,719 Epoch[5] Batch [1330]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.161904,	
2017-06-27 11:39:56,333 Epoch[5] Batch [1340]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.161979,	
2017-06-27 11:40:00,867 Epoch[5] Batch [1350]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.161823,	
2017-06-27 11:40:07,964 Epoch[5] Batch [1360]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.161699,	
2017-06-27 11:40:12,935 Epoch[5] Batch [1370]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.161688,	
2017-06-27 11:40:17,438 Epoch[5] Batch [1380]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.161661,	
2017-06-27 11:40:23,358 Epoch[5] Batch [1390]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.161666,	
2017-06-27 11:40:27,164 Epoch[5] Batch [1400]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.161661,	
2017-06-27 11:40:31,670 Epoch[5] Batch [1410]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.161714,	
2017-06-27 11:40:35,676 Epoch[5] Batch [1420]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.161701,	
2017-06-27 11:40:40,223 Epoch[5] Batch [1430]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.161636,	
2017-06-27 11:40:44,626 Epoch[5] Batch [1440]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.161624,	
2017-06-27 11:40:48,548 Epoch[5] Batch [1450]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.161635,	
2017-06-27 11:40:52,775 Epoch[5] Batch [1460]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.161467,	
2017-06-27 11:40:56,890 Epoch[5] Batch [1470]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.161387,	
2017-06-27 11:41:01,237 Epoch[5] Batch [1480]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.161472,	
2017-06-27 11:41:03,695 Epoch[5] Train-FCNLogLoss=0.161510
2017-06-27 11:41:03,695 Epoch[5] Time cost=706.395
2017-06-27 11:41:04,500 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0006.params"
2017-06-27 11:41:06,141 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0006.states"
2017-06-27 11:41:10,677 Epoch[6] Batch [10]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.163327,	
2017-06-27 11:41:14,676 Epoch[6] Batch [20]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.153356,	
2017-06-27 11:41:18,949 Epoch[6] Batch [30]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.157937,	
2017-06-27 11:41:23,399 Epoch[6] Batch [40]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.159088,	
2017-06-27 11:41:28,736 Epoch[6] Batch [50]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.159548,	
2017-06-27 11:41:33,319 Epoch[6] Batch [60]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.157878,	
2017-06-27 11:41:38,466 Epoch[6] Batch [70]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.156208,	
2017-06-27 11:41:42,925 Epoch[6] Batch [80]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.157085,	
2017-06-27 11:41:47,436 Epoch[6] Batch [90]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.156739,	
2017-06-27 11:41:52,303 Epoch[6] Batch [100]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.156270,	
2017-06-27 11:41:56,188 Epoch[6] Batch [110]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.156241,	
2017-06-27 11:42:00,686 Epoch[6] Batch [120]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.156337,	
2017-06-27 11:42:04,474 Epoch[6] Batch [130]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.156071,	
2017-06-27 11:42:09,021 Epoch[6] Batch [140]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.155934,	
2017-06-27 11:42:13,036 Epoch[6] Batch [150]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.156294,	
2017-06-27 11:42:18,690 Epoch[6] Batch [160]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.155921,	
2017-06-27 11:42:23,067 Epoch[6] Batch [170]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.156065,	
2017-06-27 11:42:29,055 Epoch[6] Batch [180]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.155333,	
2017-06-27 11:42:33,235 Epoch[6] Batch [190]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.154601,	
2017-06-27 11:42:38,197 Epoch[6] Batch [200]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.154068,	
2017-06-27 11:42:42,343 Epoch[6] Batch [210]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.154410,	
2017-06-27 11:42:46,647 Epoch[6] Batch [220]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.154367,	
2017-06-27 11:42:50,534 Epoch[6] Batch [230]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.154745,	
2017-06-27 11:42:54,245 Epoch[6] Batch [240]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.153070,	
2017-06-27 11:42:58,130 Epoch[6] Batch [250]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.152478,	
2017-06-27 11:43:04,213 Epoch[6] Batch [260]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.152360,	
2017-06-27 11:43:10,659 Epoch[6] Batch [270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.152006,	
2017-06-27 11:43:14,535 Epoch[6] Batch [280]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.151766,	
2017-06-27 11:43:18,814 Epoch[6] Batch [290]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.151600,	
2017-06-27 11:43:23,890 Epoch[6] Batch [300]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.151600,	
2017-06-27 11:43:27,694 Epoch[6] Batch [310]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.151521,	
2017-06-27 11:43:31,989 Epoch[6] Batch [320]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.151551,	
2017-06-27 11:43:38,267 Epoch[6] Batch [330]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.151969,	
2017-06-27 11:43:43,456 Epoch[6] Batch [340]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.152072,	
2017-06-27 11:43:47,877 Epoch[6] Batch [350]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.152188,	
2017-06-27 11:43:52,132 Epoch[6] Batch [360]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.152333,	
2017-06-27 11:43:56,985 Epoch[6] Batch [370]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.152627,	
2017-06-27 11:44:04,442 Epoch[6] Batch [380]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.153183,	
2017-06-27 11:44:09,007 Epoch[6] Batch [390]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.154116,	
2017-06-27 11:44:14,743 Epoch[6] Batch [400]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.153729,	
2017-06-27 11:44:19,058 Epoch[6] Batch [410]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.153674,	
2017-06-27 11:44:22,895 Epoch[6] Batch [420]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.155297,	
2017-06-27 11:44:27,439 Epoch[6] Batch [430]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.155691,	
2017-06-27 11:44:31,748 Epoch[6] Batch [440]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.155950,	
2017-06-27 11:44:35,863 Epoch[6] Batch [450]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.156069,	
2017-06-27 11:44:41,118 Epoch[6] Batch [460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.156041,	
2017-06-27 11:44:47,962 Epoch[6] Batch [470]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.156024,	
2017-06-27 11:44:52,393 Epoch[6] Batch [480]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.156224,	
2017-06-27 11:44:56,242 Epoch[6] Batch [490]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.156303,	
2017-06-27 11:45:00,383 Epoch[6] Batch [500]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.156571,	
2017-06-27 11:45:04,663 Epoch[6] Batch [510]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.156380,	
2017-06-27 11:45:09,278 Epoch[6] Batch [520]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.156111,	
2017-06-27 11:45:13,962 Epoch[6] Batch [530]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.155972,	
2017-06-27 11:45:18,092 Epoch[6] Batch [540]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.156291,	
2017-06-27 11:45:21,933 Epoch[6] Batch [550]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.156245,	
2017-06-27 11:45:27,036 Epoch[6] Batch [560]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.155850,	
2017-06-27 11:45:30,931 Epoch[6] Batch [570]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.155740,	
2017-06-27 11:45:37,911 Epoch[6] Batch [580]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.155950,	
2017-06-27 11:45:42,763 Epoch[6] Batch [590]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.156019,	
2017-06-27 11:45:46,620 Epoch[6] Batch [600]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.156303,	
2017-06-27 11:45:50,479 Epoch[6] Batch [610]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.156491,	
2017-06-27 11:45:55,845 Epoch[6] Batch [620]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.156318,	
2017-06-27 11:46:02,393 Epoch[6] Batch [630]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.155952,	
2017-06-27 11:46:07,070 Epoch[6] Batch [640]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.155639,	
2017-06-27 11:46:10,979 Epoch[6] Batch [650]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.155739,	
2017-06-27 11:46:14,954 Epoch[6] Batch [660]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.155682,	
2017-06-27 11:46:18,929 Epoch[6] Batch [670]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.155376,	
2017-06-27 11:46:23,006 Epoch[6] Batch [680]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.155516,	
2017-06-27 11:46:27,737 Epoch[6] Batch [690]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.155726,	
2017-06-27 11:46:32,086 Epoch[6] Batch [700]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.155550,	
2017-06-27 11:46:37,051 Epoch[6] Batch [710]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.155661,	
2017-06-27 11:46:41,776 Epoch[6] Batch [720]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.155670,	
2017-06-27 11:46:46,598 Epoch[6] Batch [730]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.155639,	
2017-06-27 11:46:51,430 Epoch[6] Batch [740]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.155684,	
2017-06-27 11:46:57,591 Epoch[6] Batch [750]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.155594,	
2017-06-27 11:47:02,466 Epoch[6] Batch [760]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.155240,	
2017-06-27 11:47:06,799 Epoch[6] Batch [770]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.155164,	
2017-06-27 11:47:11,912 Epoch[6] Batch [780]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.155403,	
2017-06-27 11:47:17,238 Epoch[6] Batch [790]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.155462,	
2017-06-27 11:47:22,189 Epoch[6] Batch [800]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.155442,	
2017-06-27 11:47:28,881 Epoch[6] Batch [810]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.155172,	
2017-06-27 11:47:32,860 Epoch[6] Batch [820]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.155370,	
2017-06-27 11:47:37,749 Epoch[6] Batch [830]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.155694,	
2017-06-27 11:47:41,639 Epoch[6] Batch [840]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.155612,	
2017-06-27 11:47:45,631 Epoch[6] Batch [850]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.156001,	
2017-06-27 11:47:49,922 Epoch[6] Batch [860]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.156011,	
2017-06-27 11:47:54,161 Epoch[6] Batch [870]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.155992,	
2017-06-27 11:47:58,137 Epoch[6] Batch [880]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.156013,	
2017-06-27 11:48:04,111 Epoch[6] Batch [890]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.156036,	
2017-06-27 11:48:08,461 Epoch[6] Batch [900]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.156061,	
2017-06-27 11:48:12,398 Epoch[6] Batch [910]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.155850,	
2017-06-27 11:48:16,242 Epoch[6] Batch [920]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.155874,	
2017-06-27 11:48:20,887 Epoch[6] Batch [930]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.156024,	
2017-06-27 11:48:24,874 Epoch[6] Batch [940]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.155952,	
2017-06-27 11:48:29,590 Epoch[6] Batch [950]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.155850,	
2017-06-27 11:48:33,761 Epoch[6] Batch [960]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.155702,	
2017-06-27 11:48:39,921 Epoch[6] Batch [970]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.155610,	
2017-06-27 11:48:44,607 Epoch[6] Batch [980]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.155500,	
2017-06-27 11:48:48,655 Epoch[6] Batch [990]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.155756,	
2017-06-27 11:48:53,250 Epoch[6] Batch [1000]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.155600,	
2017-06-27 11:48:58,084 Epoch[6] Batch [1010]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.155461,	
2017-06-27 11:49:03,829 Epoch[6] Batch [1020]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.155548,	
2017-06-27 11:49:09,842 Epoch[6] Batch [1030]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.155482,	
2017-06-27 11:49:14,878 Epoch[6] Batch [1040]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.155377,	
2017-06-27 11:49:19,365 Epoch[6] Batch [1050]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.155418,	
2017-06-27 11:49:24,576 Epoch[6] Batch [1060]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.155490,	
2017-06-27 11:49:28,695 Epoch[6] Batch [1070]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.155380,	
2017-06-27 11:49:33,827 Epoch[6] Batch [1080]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.155322,	
2017-06-27 11:49:38,448 Epoch[6] Batch [1090]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.155373,	
2017-06-27 11:49:43,594 Epoch[6] Batch [1100]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.155286,	
2017-06-27 11:49:48,890 Epoch[6] Batch [1110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.155252,	
2017-06-27 11:49:54,197 Epoch[6] Batch [1120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.155331,	
2017-06-27 11:49:59,428 Epoch[6] Batch [1130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.155321,	
2017-06-27 11:50:04,691 Epoch[6] Batch [1140]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.155214,	
2017-06-27 11:50:09,903 Epoch[6] Batch [1150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.155178,	
2017-06-27 11:50:15,150 Epoch[6] Batch [1160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.155164,	
2017-06-27 11:50:20,423 Epoch[6] Batch [1170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.154998,	
2017-06-27 11:50:25,653 Epoch[6] Batch [1180]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.154867,	
2017-06-27 11:50:30,908 Epoch[6] Batch [1190]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.154815,	
2017-06-27 11:50:36,148 Epoch[6] Batch [1200]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.154785,	
2017-06-27 11:50:41,476 Epoch[6] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.155190,	
2017-06-27 11:50:46,647 Epoch[6] Batch [1220]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.155344,	
2017-06-27 11:50:51,901 Epoch[6] Batch [1230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.155317,	
2017-06-27 11:50:57,161 Epoch[6] Batch [1240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.155346,	
2017-06-27 11:51:02,379 Epoch[6] Batch [1250]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.155553,	
2017-06-27 11:51:07,643 Epoch[6] Batch [1260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.155416,	
2017-06-27 11:51:12,909 Epoch[6] Batch [1270]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.155460,	
2017-06-27 11:51:18,156 Epoch[6] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.155574,	
2017-06-27 11:51:23,398 Epoch[6] Batch [1290]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.155375,	
2017-06-27 11:51:28,662 Epoch[6] Batch [1300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.155542,	
2017-06-27 11:51:33,933 Epoch[6] Batch [1310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.155455,	
2017-06-27 11:51:39,168 Epoch[6] Batch [1320]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.155493,	
2017-06-27 11:51:44,135 Epoch[6] Batch [1330]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.155536,	
2017-06-27 11:51:49,384 Epoch[6] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.155458,	
2017-06-27 11:51:54,669 Epoch[6] Batch [1350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.155320,	
2017-06-27 11:51:59,966 Epoch[6] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.155281,	
2017-06-27 11:52:05,238 Epoch[6] Batch [1370]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.155239,	
2017-06-27 11:52:10,499 Epoch[6] Batch [1380]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.155197,	
2017-06-27 11:52:15,778 Epoch[6] Batch [1390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.155162,	
2017-06-27 11:52:21,004 Epoch[6] Batch [1400]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.155133,	
2017-06-27 11:52:26,173 Epoch[6] Batch [1410]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.155419,	
2017-06-27 11:52:31,463 Epoch[6] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.155806,	
2017-06-27 11:52:36,728 Epoch[6] Batch [1430]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.155987,	
2017-06-27 11:52:41,983 Epoch[6] Batch [1440]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.156075,	
2017-06-27 11:52:47,224 Epoch[6] Batch [1450]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.156159,	
2017-06-27 11:52:52,415 Epoch[6] Batch [1460]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.156021,	
2017-06-27 11:52:57,525 Epoch[6] Batch [1470]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.156245,	
2017-06-27 11:53:02,811 Epoch[6] Batch [1480]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.156222,	
2017-06-27 11:53:05,947 Epoch[6] Train-FCNLogLoss=0.156214
2017-06-27 11:53:05,947 Epoch[6] Time cost=719.806
2017-06-27 11:53:06,753 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0007.params"
2017-06-27 11:53:08,372 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0007.states"
2017-06-27 11:53:14,028 Epoch[7] Batch [10]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.182212,	
2017-06-27 11:53:19,107 Epoch[7] Batch [20]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.162766,	
2017-06-27 11:53:24,301 Epoch[7] Batch [30]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.160490,	
2017-06-27 11:53:29,517 Epoch[7] Batch [40]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.155597,	
2017-06-27 11:53:34,777 Epoch[7] Batch [50]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.154263,	
2017-06-27 11:53:40,048 Epoch[7] Batch [60]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.151759,	
2017-06-27 11:53:45,337 Epoch[7] Batch [70]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.153670,	
2017-06-27 11:53:50,617 Epoch[7] Batch [80]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.150696,	
2017-06-27 11:53:55,846 Epoch[7] Batch [90]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.149192,	
2017-06-27 11:54:01,085 Epoch[7] Batch [100]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.149250,	
2017-06-27 11:54:06,389 Epoch[7] Batch [110]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.147707,	
2017-06-27 11:54:11,618 Epoch[7] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.146897,	
2017-06-27 11:54:16,890 Epoch[7] Batch [130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.146284,	
2017-06-27 11:54:22,161 Epoch[7] Batch [140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.147691,	
2017-06-27 11:54:27,444 Epoch[7] Batch [150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.148774,	
2017-06-27 11:54:32,704 Epoch[7] Batch [160]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.148727,	
2017-06-27 11:54:37,997 Epoch[7] Batch [170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.148207,	
2017-06-27 11:54:43,232 Epoch[7] Batch [180]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.148893,	
2017-06-27 11:54:48,452 Epoch[7] Batch [190]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.148189,	
2017-06-27 11:54:53,722 Epoch[7] Batch [200]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.148100,	
2017-06-27 11:54:58,994 Epoch[7] Batch [210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.147680,	
2017-06-27 11:55:04,308 Epoch[7] Batch [220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.148336,	
2017-06-27 11:55:09,545 Epoch[7] Batch [230]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.147822,	
2017-06-27 11:55:14,806 Epoch[7] Batch [240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.147982,	
2017-06-27 11:55:20,131 Epoch[7] Batch [250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.148439,	
2017-06-27 11:55:25,389 Epoch[7] Batch [260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.148658,	
2017-06-27 11:55:29,221 Epoch[7] Batch [270]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.149041,	
2017-06-27 11:55:33,934 Epoch[7] Batch [280]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.148815,	
2017-06-27 11:55:39,165 Epoch[7] Batch [290]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.149177,	
2017-06-27 11:55:44,514 Epoch[7] Batch [300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.149067,	
2017-06-27 11:55:49,771 Epoch[7] Batch [310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.149129,	
2017-06-27 11:55:55,027 Epoch[7] Batch [320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.148701,	
2017-06-27 11:56:00,273 Epoch[7] Batch [330]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.148107,	
2017-06-27 11:56:05,532 Epoch[7] Batch [340]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.148306,	
2017-06-27 11:56:10,816 Epoch[7] Batch [350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.148700,	
2017-06-27 11:56:16,090 Epoch[7] Batch [360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.148805,	
2017-06-27 11:56:21,367 Epoch[7] Batch [370]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.148964,	
2017-06-27 11:56:26,693 Epoch[7] Batch [380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.149555,	
2017-06-27 11:56:31,887 Epoch[7] Batch [390]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.149552,	
2017-06-27 11:56:37,232 Epoch[7] Batch [400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.149531,	
2017-06-27 11:56:42,559 Epoch[7] Batch [410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.149410,	
2017-06-27 11:56:47,854 Epoch[7] Batch [420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.149340,	
2017-06-27 11:56:53,119 Epoch[7] Batch [430]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.148896,	
2017-06-27 11:56:58,378 Epoch[7] Batch [440]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.149919,	
2017-06-27 11:57:03,646 Epoch[7] Batch [450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.150392,	
2017-06-27 11:57:08,903 Epoch[7] Batch [460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.151224,	
2017-06-27 11:57:14,175 Epoch[7] Batch [470]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.152096,	
2017-06-27 11:57:19,402 Epoch[7] Batch [480]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.151812,	
2017-06-27 11:57:24,668 Epoch[7] Batch [490]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.151817,	
2017-06-27 11:57:29,940 Epoch[7] Batch [500]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.151695,	
2017-06-27 11:57:35,198 Epoch[7] Batch [510]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.151505,	
2017-06-27 11:57:40,485 Epoch[7] Batch [520]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.151268,	
2017-06-27 11:57:45,488 Epoch[7] Batch [530]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.151291,	
2017-06-27 11:57:50,713 Epoch[7] Batch [540]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.151435,	
2017-06-27 11:57:55,980 Epoch[7] Batch [550]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.151408,	
2017-06-27 11:58:01,247 Epoch[7] Batch [560]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.151028,	
2017-06-27 11:58:06,512 Epoch[7] Batch [570]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.151036,	
2017-06-27 11:58:11,746 Epoch[7] Batch [580]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150818,	
2017-06-27 11:58:17,021 Epoch[7] Batch [590]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.150731,	
2017-06-27 11:58:22,283 Epoch[7] Batch [600]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150720,	
2017-06-27 11:58:27,525 Epoch[7] Batch [610]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.150475,	
2017-06-27 11:58:32,769 Epoch[7] Batch [620]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.150518,	
2017-06-27 11:58:38,033 Epoch[7] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150258,	
2017-06-27 11:58:43,285 Epoch[7] Batch [640]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.150455,	
2017-06-27 11:58:48,549 Epoch[7] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150588,	
2017-06-27 11:58:53,803 Epoch[7] Batch [660]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.150476,	
2017-06-27 11:58:59,018 Epoch[7] Batch [670]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.150182,	
2017-06-27 11:59:04,224 Epoch[7] Batch [680]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.150026,	
2017-06-27 11:59:09,280 Epoch[7] Batch [690]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.149866,	
2017-06-27 11:59:14,411 Epoch[7] Batch [700]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.150289,	
2017-06-27 11:59:19,411 Epoch[7] Batch [710]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.150147,	
2017-06-27 11:59:24,473 Epoch[7] Batch [720]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.150059,	
2017-06-27 11:59:29,454 Epoch[7] Batch [730]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.150067,	
2017-06-27 11:59:34,723 Epoch[7] Batch [740]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.150860,	
2017-06-27 11:59:40,006 Epoch[7] Batch [750]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.150836,	
2017-06-27 11:59:45,250 Epoch[7] Batch [760]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.150862,	
2017-06-27 11:59:50,493 Epoch[7] Batch [770]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.150745,	
2017-06-27 11:59:55,737 Epoch[7] Batch [780]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.150630,	
2017-06-27 12:00:00,979 Epoch[7] Batch [790]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.150810,	
2017-06-27 12:00:06,278 Epoch[7] Batch [800]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.150744,	
2017-06-27 12:00:11,514 Epoch[7] Batch [810]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150640,	
2017-06-27 12:00:16,779 Epoch[7] Batch [820]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150626,	
2017-06-27 12:00:22,083 Epoch[7] Batch [830]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.150737,	
2017-06-27 12:00:27,322 Epoch[7] Batch [840]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150563,	
2017-06-27 12:00:32,627 Epoch[7] Batch [850]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.150363,	
2017-06-27 12:00:37,839 Epoch[7] Batch [860]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.150416,	
2017-06-27 12:00:43,092 Epoch[7] Batch [870]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.150373,	
2017-06-27 12:00:48,343 Epoch[7] Batch [880]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.150342,	
2017-06-27 12:00:53,639 Epoch[7] Batch [890]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.150403,	
2017-06-27 12:00:58,885 Epoch[7] Batch [900]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.150439,	
2017-06-27 12:01:04,133 Epoch[7] Batch [910]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.150347,	
2017-06-27 12:01:09,283 Epoch[7] Batch [920]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.150710,	
2017-06-27 12:01:14,487 Epoch[7] Batch [930]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.150810,	
2017-06-27 12:01:19,831 Epoch[7] Batch [940]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.150707,	
2017-06-27 12:01:24,846 Epoch[7] Batch [950]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.150713,	
2017-06-27 12:01:29,103 Epoch[7] Batch [960]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.150657,	
2017-06-27 12:01:33,787 Epoch[7] Batch [970]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.150578,	
2017-06-27 12:01:38,849 Epoch[7] Batch [980]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.150712,	
2017-06-27 12:01:44,115 Epoch[7] Batch [990]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150477,	
2017-06-27 12:01:49,330 Epoch[7] Batch [1000]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.150417,	
2017-06-27 12:01:54,565 Epoch[7] Batch [1010]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150534,	
2017-06-27 12:01:59,833 Epoch[7] Batch [1020]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.150591,	
2017-06-27 12:02:05,080 Epoch[7] Batch [1030]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.150512,	
2017-06-27 12:02:10,342 Epoch[7] Batch [1040]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150315,	
2017-06-27 12:02:15,637 Epoch[7] Batch [1050]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.150152,	
2017-06-27 12:02:20,852 Epoch[7] Batch [1060]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.150183,	
2017-06-27 12:02:26,114 Epoch[7] Batch [1070]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150270,	
2017-06-27 12:02:31,380 Epoch[7] Batch [1080]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150299,	
2017-06-27 12:02:36,655 Epoch[7] Batch [1090]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.150452,	
2017-06-27 12:02:41,888 Epoch[7] Batch [1100]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150871,	
2017-06-27 12:02:47,149 Epoch[7] Batch [1110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150968,	
2017-06-27 12:02:52,406 Epoch[7] Batch [1120]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.151017,	
2017-06-27 12:02:57,675 Epoch[7] Batch [1130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.150787,	
2017-06-27 12:03:02,902 Epoch[7] Batch [1140]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.150796,	
2017-06-27 12:03:08,166 Epoch[7] Batch [1150]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150622,	
2017-06-27 12:03:13,414 Epoch[7] Batch [1160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.150683,	
2017-06-27 12:03:18,689 Epoch[7] Batch [1170]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.150770,	
2017-06-27 12:03:23,908 Epoch[7] Batch [1180]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.150718,	
2017-06-27 12:03:29,141 Epoch[7] Batch [1190]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150698,	
2017-06-27 12:03:34,402 Epoch[7] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150658,	
2017-06-27 12:03:39,779 Epoch[7] Batch [1210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.150711,	
2017-06-27 12:03:44,953 Epoch[7] Batch [1220]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.150844,	
2017-06-27 12:03:50,230 Epoch[7] Batch [1230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.150687,	
2017-06-27 12:03:55,469 Epoch[7] Batch [1240]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150482,	
2017-06-27 12:04:00,768 Epoch[7] Batch [1250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.150286,	
2017-06-27 12:04:05,982 Epoch[7] Batch [1260]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.150328,	
2017-06-27 12:04:11,292 Epoch[7] Batch [1270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.150402,	
2017-06-27 12:04:16,532 Epoch[7] Batch [1280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.150375,	
2017-06-27 12:04:21,769 Epoch[7] Batch [1290]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.150193,	
2017-06-27 12:04:27,031 Epoch[7] Batch [1300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.150062,	
2017-06-27 12:04:32,276 Epoch[7] Batch [1310]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.149985,	
2017-06-27 12:04:37,569 Epoch[7] Batch [1320]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.149804,	
2017-06-27 12:04:42,783 Epoch[7] Batch [1330]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.149598,	
2017-06-27 12:04:48,036 Epoch[7] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.149738,	
2017-06-27 12:04:53,317 Epoch[7] Batch [1350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.149763,	
2017-06-27 12:04:58,614 Epoch[7] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.149781,	
2017-06-27 12:05:03,869 Epoch[7] Batch [1370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.149851,	
2017-06-27 12:05:09,167 Epoch[7] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.149875,	
2017-06-27 12:05:14,391 Epoch[7] Batch [1390]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.149948,	
2017-06-27 12:05:19,691 Epoch[7] Batch [1400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.149959,	
2017-06-27 12:05:24,951 Epoch[7] Batch [1410]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.149909,	
2017-06-27 12:05:30,223 Epoch[7] Batch [1420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.149903,	
2017-06-27 12:05:35,503 Epoch[7] Batch [1430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.149787,	
2017-06-27 12:05:40,401 Epoch[7] Batch [1440]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.149794,	
2017-06-27 12:05:45,678 Epoch[7] Batch [1450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.149707,	
2017-06-27 12:05:50,911 Epoch[7] Batch [1460]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.149548,	
2017-06-27 12:05:56,204 Epoch[7] Batch [1470]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.149540,	
2017-06-27 12:06:01,480 Epoch[7] Batch [1480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.149443,	
2017-06-27 12:06:04,623 Epoch[7] Train-FCNLogLoss=0.149412
2017-06-27 12:06:04,623 Epoch[7] Time cost=776.251
2017-06-27 12:06:05,389 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0008.params"
2017-06-27 12:06:07,062 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0008.states"
2017-06-27 12:06:12,948 Epoch[8] Batch [10]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.154323,	
2017-06-27 12:06:18,218 Epoch[8] Batch [20]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.148413,	
2017-06-27 12:06:23,492 Epoch[8] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.146465,	
2017-06-27 12:06:28,764 Epoch[8] Batch [40]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.154139,	
2017-06-27 12:06:34,028 Epoch[8] Batch [50]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.149544,	
2017-06-27 12:06:39,323 Epoch[8] Batch [60]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.148816,	
2017-06-27 12:06:44,578 Epoch[8] Batch [70]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.146757,	
2017-06-27 12:06:49,877 Epoch[8] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.145881,	
2017-06-27 12:06:55,108 Epoch[8] Batch [90]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.143749,	
2017-06-27 12:07:00,403 Epoch[8] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.144849,	
2017-06-27 12:07:05,660 Epoch[8] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.144209,	
2017-06-27 12:07:10,914 Epoch[8] Batch [120]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.143971,	
2017-06-27 12:07:16,145 Epoch[8] Batch [130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.143933,	
2017-06-27 12:07:21,444 Epoch[8] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.142899,	
2017-06-27 12:07:26,741 Epoch[8] Batch [150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.141395,	
2017-06-27 12:07:31,964 Epoch[8] Batch [160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142450,	
2017-06-27 12:07:37,188 Epoch[8] Batch [170]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.141498,	
2017-06-27 12:07:42,215 Epoch[8] Batch [180]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.141974,	
2017-06-27 12:07:47,228 Epoch[8] Batch [190]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.141542,	
2017-06-27 12:07:52,306 Epoch[8] Batch [200]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.141173,	
2017-06-27 12:07:57,587 Epoch[8] Batch [210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.140080,	
2017-06-27 12:08:02,841 Epoch[8] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.140741,	
2017-06-27 12:08:08,098 Epoch[8] Batch [230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.141019,	
2017-06-27 12:08:13,376 Epoch[8] Batch [240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.140677,	
2017-06-27 12:08:18,356 Epoch[8] Batch [250]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.140496,	
2017-06-27 12:08:23,564 Epoch[8] Batch [260]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.139878,	
2017-06-27 12:08:28,821 Epoch[8] Batch [270]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.140271,	
2017-06-27 12:08:34,078 Epoch[8] Batch [280]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.140300,	
2017-06-27 12:08:39,412 Epoch[8] Batch [290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.142385,	
2017-06-27 12:08:43,587 Epoch[8] Batch [300]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.142948,	
2017-06-27 12:08:48,536 Epoch[8] Batch [310]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.142451,	
2017-06-27 12:08:53,760 Epoch[8] Batch [320]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142386,	
2017-06-27 12:08:59,061 Epoch[8] Batch [330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.141648,	
2017-06-27 12:09:04,254 Epoch[8] Batch [340]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.141948,	
2017-06-27 12:09:09,516 Epoch[8] Batch [350]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.141632,	
2017-06-27 12:09:14,572 Epoch[8] Batch [360]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.141406,	
2017-06-27 12:09:19,834 Epoch[8] Batch [370]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.141625,	
2017-06-27 12:09:25,111 Epoch[8] Batch [380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.141540,	
2017-06-27 12:09:30,283 Epoch[8] Batch [390]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.141961,	
2017-06-27 12:09:35,552 Epoch[8] Batch [400]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.141702,	
2017-06-27 12:09:40,740 Epoch[8] Batch [410]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.141498,	
2017-06-27 12:09:46,034 Epoch[8] Batch [420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.141565,	
2017-06-27 12:09:51,268 Epoch[8] Batch [430]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142075,	
2017-06-27 12:09:56,549 Epoch[8] Batch [440]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.142681,	
2017-06-27 12:10:01,735 Epoch[8] Batch [450]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.142775,	
2017-06-27 12:10:06,817 Epoch[8] Batch [460]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.142891,	
2017-06-27 12:10:12,054 Epoch[8] Batch [470]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142919,	
2017-06-27 12:10:17,314 Epoch[8] Batch [480]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.142603,	
2017-06-27 12:10:22,553 Epoch[8] Batch [490]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142205,	
2017-06-27 12:10:27,786 Epoch[8] Batch [500]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142357,	
2017-06-27 12:10:33,020 Epoch[8] Batch [510]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142513,	
2017-06-27 12:10:38,266 Epoch[8] Batch [520]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.142632,	
2017-06-27 12:10:43,532 Epoch[8] Batch [530]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.142745,	
2017-06-27 12:10:48,587 Epoch[8] Batch [540]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.143432,	
2017-06-27 12:10:53,607 Epoch[8] Batch [550]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.143196,	
2017-06-27 12:10:58,822 Epoch[8] Batch [560]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.143442,	
2017-06-27 12:11:04,070 Epoch[8] Batch [570]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.143350,	
2017-06-27 12:11:09,322 Epoch[8] Batch [580]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.143618,	
2017-06-27 12:11:14,582 Epoch[8] Batch [590]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.143681,	
2017-06-27 12:11:19,781 Epoch[8] Batch [600]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.143643,	
2017-06-27 12:11:25,066 Epoch[8] Batch [610]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.143255,	
2017-06-27 12:11:30,280 Epoch[8] Batch [620]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.142863,	
2017-06-27 12:11:35,547 Epoch[8] Batch [630]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.142694,	
2017-06-27 12:11:40,833 Epoch[8] Batch [640]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.142493,	
2017-06-27 12:11:46,043 Epoch[8] Batch [650]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.142323,	
2017-06-27 12:11:51,298 Epoch[8] Batch [660]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.142181,	
2017-06-27 12:11:56,089 Epoch[8] Batch [670]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.142384,	
2017-06-27 12:12:01,335 Epoch[8] Batch [680]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.142582,	
2017-06-27 12:12:06,579 Epoch[8] Batch [690]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.142580,	
2017-06-27 12:12:11,824 Epoch[8] Batch [700]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.142479,	
2017-06-27 12:12:17,064 Epoch[8] Batch [710]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.142262,	
2017-06-27 12:12:22,342 Epoch[8] Batch [720]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.142096,	
2017-06-27 12:12:27,565 Epoch[8] Batch [730]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142093,	
2017-06-27 12:12:32,827 Epoch[8] Batch [740]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.141887,	
2017-06-27 12:12:38,083 Epoch[8] Batch [750]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.141871,	
2017-06-27 12:12:43,376 Epoch[8] Batch [760]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.142134,	
2017-06-27 12:12:48,474 Epoch[8] Batch [770]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.142207,	
2017-06-27 12:12:53,480 Epoch[8] Batch [780]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.142592,	
2017-06-27 12:12:58,638 Epoch[8] Batch [790]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.142560,	
2017-06-27 12:13:03,960 Epoch[8] Batch [800]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.142419,	
2017-06-27 12:13:09,202 Epoch[8] Batch [810]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.142339,	
2017-06-27 12:13:14,451 Epoch[8] Batch [820]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.142311,	
2017-06-27 12:13:19,719 Epoch[8] Batch [830]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.142415,	
2017-06-27 12:13:24,987 Epoch[8] Batch [840]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.142499,	
2017-06-27 12:13:30,237 Epoch[8] Batch [850]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.142340,	
2017-06-27 12:13:35,463 Epoch[8] Batch [860]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.142402,	
2017-06-27 12:13:40,761 Epoch[8] Batch [870]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.142432,	
2017-06-27 12:13:45,192 Epoch[8] Batch [880]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.142490,	
2017-06-27 12:13:49,934 Epoch[8] Batch [890]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.142427,	
2017-06-27 12:13:54,705 Epoch[8] Batch [900]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.142500,	
2017-06-27 12:13:59,428 Epoch[8] Batch [910]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.142413,	
2017-06-27 12:14:04,747 Epoch[8] Batch [920]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.142320,	
2017-06-27 12:14:09,798 Epoch[8] Batch [930]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.142403,	
2017-06-27 12:14:14,800 Epoch[8] Batch [940]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.142318,	
2017-06-27 12:14:19,607 Epoch[8] Batch [950]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.142289,	
2017-06-27 12:14:24,668 Epoch[8] Batch [960]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.142636,	
2017-06-27 12:14:29,394 Epoch[8] Batch [970]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.142841,	
2017-06-27 12:14:34,639 Epoch[8] Batch [980]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.142634,	
2017-06-27 12:14:39,876 Epoch[8] Batch [990]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142444,	
2017-06-27 12:14:44,444 Epoch[8] Batch [1000]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.142339,	
2017-06-27 12:14:49,040 Epoch[8] Batch [1010]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.142690,	
2017-06-27 12:14:53,613 Epoch[8] Batch [1020]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.142797,	
2017-06-27 12:14:58,145 Epoch[8] Batch [1030]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.142847,	
2017-06-27 12:15:03,122 Epoch[8] Batch [1040]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.142873,	
2017-06-27 12:15:08,358 Epoch[8] Batch [1050]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142870,	
2017-06-27 12:15:13,392 Epoch[8] Batch [1060]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.142863,	
2017-06-27 12:15:18,508 Epoch[8] Batch [1070]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.142872,	
2017-06-27 12:15:23,653 Epoch[8] Batch [1080]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.143057,	
2017-06-27 12:15:28,500 Epoch[8] Batch [1090]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.142994,	
2017-06-27 12:15:33,533 Epoch[8] Batch [1100]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.143146,	
2017-06-27 12:15:38,576 Epoch[8] Batch [1110]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.143311,	
2017-06-27 12:15:43,760 Epoch[8] Batch [1120]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.143229,	
2017-06-27 12:15:49,078 Epoch[8] Batch [1130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.143337,	
2017-06-27 12:15:54,381 Epoch[8] Batch [1140]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.143338,	
2017-06-27 12:15:59,619 Epoch[8] Batch [1150]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.143385,	
2017-06-27 12:16:04,600 Epoch[8] Batch [1160]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.143365,	
2017-06-27 12:16:09,395 Epoch[8] Batch [1170]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.143408,	
2017-06-27 12:16:14,409 Epoch[8] Batch [1180]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.143432,	
2017-06-27 12:16:19,597 Epoch[8] Batch [1190]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.143408,	
2017-06-27 12:16:24,684 Epoch[8] Batch [1200]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.143586,	
2017-06-27 12:16:29,739 Epoch[8] Batch [1210]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.143689,	
2017-06-27 12:16:34,926 Epoch[8] Batch [1220]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.143634,	
2017-06-27 12:16:39,995 Epoch[8] Batch [1230]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.143742,	
2017-06-27 12:16:44,914 Epoch[8] Batch [1240]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.143743,	
2017-06-27 12:16:49,528 Epoch[8] Batch [1250]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.143799,	
2017-06-27 12:16:54,311 Epoch[8] Batch [1260]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.143820,	
2017-06-27 12:16:59,066 Epoch[8] Batch [1270]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.143778,	
2017-06-27 12:17:04,077 Epoch[8] Batch [1280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.143723,	
2017-06-27 12:17:08,946 Epoch[8] Batch [1290]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.143740,	
2017-06-27 12:17:13,959 Epoch[8] Batch [1300]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.143618,	
2017-06-27 12:17:19,242 Epoch[8] Batch [1310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.143678,	
2017-06-27 12:17:24,462 Epoch[8] Batch [1320]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.143682,	
2017-06-27 12:17:29,445 Epoch[8] Batch [1330]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.143674,	
2017-06-27 12:17:34,207 Epoch[8] Batch [1340]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.143577,	
2017-06-27 12:17:38,884 Epoch[8] Batch [1350]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.143521,	
2017-06-27 12:17:43,706 Epoch[8] Batch [1360]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.143394,	
2017-06-27 12:17:48,277 Epoch[8] Batch [1370]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.143598,	
2017-06-27 12:17:52,685 Epoch[8] Batch [1380]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.143512,	
2017-06-27 12:17:57,484 Epoch[8] Batch [1390]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.143447,	
2017-06-27 12:18:02,333 Epoch[8] Batch [1400]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.143432,	
2017-06-27 12:18:06,819 Epoch[8] Batch [1410]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.143675,	
2017-06-27 12:18:12,018 Epoch[8] Batch [1420]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.143698,	
2017-06-27 12:18:17,092 Epoch[8] Batch [1430]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.143774,	
2017-06-27 12:18:22,046 Epoch[8] Batch [1440]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.143872,	
2017-06-27 12:18:26,685 Epoch[8] Batch [1450]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.143822,	
2017-06-27 12:18:31,214 Epoch[8] Batch [1460]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.143846,	
2017-06-27 12:18:35,748 Epoch[8] Batch [1470]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.143790,	
2017-06-27 12:18:40,796 Epoch[8] Batch [1480]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.143688,	
2017-06-27 12:18:43,904 Epoch[8] Train-FCNLogLoss=0.143745
2017-06-27 12:18:43,904 Epoch[8] Time cost=756.842
2017-06-27 12:18:44,749 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0009.params"
2017-06-27 12:18:46,510 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0009.states"
2017-06-27 12:18:52,067 Epoch[9] Batch [10]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.154355,	
2017-06-27 12:18:57,071 Epoch[9] Batch [20]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.150656,	
2017-06-27 12:19:02,323 Epoch[9] Batch [30]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.147760,	
2017-06-27 12:19:07,608 Epoch[9] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.146960,	
2017-06-27 12:19:12,726 Epoch[9] Batch [50]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.145116,	
2017-06-27 12:19:17,681 Epoch[9] Batch [60]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.145388,	
2017-06-27 12:19:22,270 Epoch[9] Batch [70]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.142907,	
2017-06-27 12:19:27,240 Epoch[9] Batch [80]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.143048,	
2017-06-27 12:19:32,042 Epoch[9] Batch [90]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.144136,	
2017-06-27 12:19:36,530 Epoch[9] Batch [100]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.142582,	
2017-06-27 12:19:41,475 Epoch[9] Batch [110]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.141825,	
2017-06-27 12:19:46,525 Epoch[9] Batch [120]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.140574,	
2017-06-27 12:19:51,588 Epoch[9] Batch [130]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.140903,	
2017-06-27 12:19:56,784 Epoch[9] Batch [140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.140339,	
2017-06-27 12:20:01,811 Epoch[9] Batch [150]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.141577,	
2017-06-27 12:20:06,851 Epoch[9] Batch [160]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.142053,	
2017-06-27 12:20:11,703 Epoch[9] Batch [170]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.142645,	
2017-06-27 12:20:16,688 Epoch[9] Batch [180]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.141815,	
2017-06-27 12:20:21,938 Epoch[9] Batch [190]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.141572,	
2017-06-27 12:20:26,988 Epoch[9] Batch [200]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.140984,	
2017-06-27 12:20:31,969 Epoch[9] Batch [210]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.140381,	
2017-06-27 12:20:37,212 Epoch[9] Batch [220]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.141481,	
2017-06-27 12:20:42,480 Epoch[9] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.142182,	
2017-06-27 12:20:47,734 Epoch[9] Batch [240]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.142985,	
2017-06-27 12:20:52,969 Epoch[9] Batch [250]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.142461,	
2017-06-27 12:20:58,233 Epoch[9] Batch [260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.142593,	
2017-06-27 12:21:03,497 Epoch[9] Batch [270]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.142231,	
2017-06-27 12:21:08,745 Epoch[9] Batch [280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.142258,	
2017-06-27 12:21:13,958 Epoch[9] Batch [290]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.141911,	
2017-06-27 12:21:19,182 Epoch[9] Batch [300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142403,	
2017-06-27 12:21:24,301 Epoch[9] Batch [310]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.142818,	
2017-06-27 12:21:28,761 Epoch[9] Batch [320]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.142533,	
2017-06-27 12:21:33,826 Epoch[9] Batch [330]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.142579,	
2017-06-27 12:21:39,048 Epoch[9] Batch [340]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142636,	
2017-06-27 12:21:43,860 Epoch[9] Batch [350]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.142360,	
2017-06-27 12:21:48,660 Epoch[9] Batch [360]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.142358,	
2017-06-27 12:21:53,420 Epoch[9] Batch [370]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.142052,	
2017-06-27 12:21:58,239 Epoch[9] Batch [380]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.142013,	
2017-06-27 12:22:03,435 Epoch[9] Batch [390]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.141957,	
2017-06-27 12:22:08,273 Epoch[9] Batch [400]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.141729,	
2017-06-27 12:22:13,449 Epoch[9] Batch [410]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.141451,	
2017-06-27 12:22:18,300 Epoch[9] Batch [420]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.141078,	
2017-06-27 12:22:23,267 Epoch[9] Batch [430]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.140956,	
2017-06-27 12:22:27,738 Epoch[9] Batch [440]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.140422,	
2017-06-27 12:22:31,669 Epoch[9] Batch [450]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.140552,	
2017-06-27 12:22:36,320 Epoch[9] Batch [460]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.140690,	
2017-06-27 12:22:41,283 Epoch[9] Batch [470]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.141090,	
2017-06-27 12:22:46,165 Epoch[9] Batch [480]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.141516,	
2017-06-27 12:22:51,326 Epoch[9] Batch [490]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.141379,	
2017-06-27 12:22:56,058 Epoch[9] Batch [500]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.141641,	
2017-06-27 12:23:00,477 Epoch[9] Batch [510]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.142112,	
2017-06-27 12:23:05,480 Epoch[9] Batch [520]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.141870,	
2017-06-27 12:23:10,512 Epoch[9] Batch [530]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.141895,	
2017-06-27 12:23:15,078 Epoch[9] Batch [540]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.141856,	
2017-06-27 12:23:20,230 Epoch[9] Batch [550]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.141986,	
2017-06-27 12:23:25,324 Epoch[9] Batch [560]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.141806,	
2017-06-27 12:23:30,568 Epoch[9] Batch [570]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.141746,	
2017-06-27 12:23:35,583 Epoch[9] Batch [580]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.141933,	
2017-06-27 12:23:40,424 Epoch[9] Batch [590]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.141784,	
2017-06-27 12:23:45,623 Epoch[9] Batch [600]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.141695,	
2017-06-27 12:23:50,716 Epoch[9] Batch [610]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.141924,	
2017-06-27 12:23:55,659 Epoch[9] Batch [620]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.141909,	
2017-06-27 12:24:00,690 Epoch[9] Batch [630]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.141503,	
2017-06-27 12:24:05,725 Epoch[9] Batch [640]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.141467,	
2017-06-27 12:24:10,963 Epoch[9] Batch [650]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.141445,	
2017-06-27 12:24:16,206 Epoch[9] Batch [660]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.141169,	
2017-06-27 12:24:21,287 Epoch[9] Batch [670]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.141229,	
2017-06-27 12:24:26,524 Epoch[9] Batch [680]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.140996,	
2017-06-27 12:24:30,907 Epoch[9] Batch [690]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.140867,	
2017-06-27 12:24:35,875 Epoch[9] Batch [700]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.140787,	
2017-06-27 12:24:40,915 Epoch[9] Batch [710]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.140772,	
2017-06-27 12:24:45,905 Epoch[9] Batch [720]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.140749,	
2017-06-27 12:24:50,772 Epoch[9] Batch [730]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.140919,	
2017-06-27 12:24:55,725 Epoch[9] Batch [740]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.141029,	
2017-06-27 12:25:00,282 Epoch[9] Batch [750]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.140841,	
2017-06-27 12:25:05,324 Epoch[9] Batch [760]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.140835,	
2017-06-27 12:25:10,509 Epoch[9] Batch [770]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.140779,	
2017-06-27 12:25:15,420 Epoch[9] Batch [780]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.140799,	
2017-06-27 12:25:20,658 Epoch[9] Batch [790]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.140721,	
2017-06-27 12:25:25,946 Epoch[9] Batch [800]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.140578,	
2017-06-27 12:25:31,189 Epoch[9] Batch [810]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.140488,	
2017-06-27 12:25:36,399 Epoch[9] Batch [820]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.140505,	
2017-06-27 12:25:41,180 Epoch[9] Batch [830]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.140232,	
2017-06-27 12:25:45,769 Epoch[9] Batch [840]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.140234,	
2017-06-27 12:25:50,289 Epoch[9] Batch [850]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.140265,	
2017-06-27 12:25:54,879 Epoch[9] Batch [860]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.140017,	
2017-06-27 12:25:59,342 Epoch[9] Batch [870]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.139982,	
2017-06-27 12:26:04,113 Epoch[9] Batch [880]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.139931,	
2017-06-27 12:26:08,958 Epoch[9] Batch [890]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.139843,	
2017-06-27 12:26:14,145 Epoch[9] Batch [900]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.139709,	
2017-06-27 12:26:19,346 Epoch[9] Batch [910]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.139708,	
2017-06-27 12:26:24,455 Epoch[9] Batch [920]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.139772,	
2017-06-27 12:26:29,658 Epoch[9] Batch [930]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.139852,	
2017-06-27 12:26:34,449 Epoch[9] Batch [940]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.140095,	
2017-06-27 12:26:39,683 Epoch[9] Batch [950]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.140166,	
2017-06-27 12:26:44,898 Epoch[9] Batch [960]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.140345,	
2017-06-27 12:26:49,990 Epoch[9] Batch [970]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.140281,	
2017-06-27 12:26:54,724 Epoch[9] Batch [980]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.140464,	
2017-06-27 12:26:59,242 Epoch[9] Batch [990]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.140781,	
2017-06-27 12:27:03,962 Epoch[9] Batch [1000]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.141078,	
2017-06-27 12:27:08,383 Epoch[9] Batch [1010]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.141292,	
2017-06-27 12:27:13,041 Epoch[9] Batch [1020]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.141685,	
2017-06-27 12:27:17,963 Epoch[9] Batch [1030]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.141748,	
2017-06-27 12:27:23,092 Epoch[9] Batch [1040]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.141773,	
2017-06-27 12:27:28,110 Epoch[9] Batch [1050]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.141929,	
2017-06-27 12:27:33,129 Epoch[9] Batch [1060]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.141790,	
2017-06-27 12:27:37,962 Epoch[9] Batch [1070]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.141793,	
2017-06-27 12:27:42,728 Epoch[9] Batch [1080]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.141714,	
2017-06-27 12:27:47,770 Epoch[9] Batch [1090]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.141676,	
2017-06-27 12:27:52,806 Epoch[9] Batch [1100]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.141909,	
2017-06-27 12:27:58,017 Epoch[9] Batch [1110]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.141989,	
2017-06-27 12:28:02,981 Epoch[9] Batch [1120]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.141948,	
2017-06-27 12:28:07,826 Epoch[9] Batch [1130]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.141908,	
2017-06-27 12:28:12,960 Epoch[9] Batch [1140]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.142134,	
2017-06-27 12:28:17,437 Epoch[9] Batch [1150]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.142231,	
2017-06-27 12:28:22,668 Epoch[9] Batch [1160]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.142252,	
2017-06-27 12:28:27,803 Epoch[9] Batch [1170]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.142292,	
2017-06-27 12:28:33,031 Epoch[9] Batch [1180]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.142146,	
2017-06-27 12:28:38,039 Epoch[9] Batch [1190]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.142230,	
2017-06-27 12:28:42,997 Epoch[9] Batch [1200]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.142215,	
2017-06-27 12:28:47,746 Epoch[9] Batch [1210]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.142359,	
2017-06-27 12:28:52,838 Epoch[9] Batch [1220]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.142410,	
2017-06-27 12:28:57,914 Epoch[9] Batch [1230]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.142427,	
2017-06-27 12:29:02,916 Epoch[9] Batch [1240]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.142336,	
2017-06-27 12:29:07,898 Epoch[9] Batch [1250]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.142221,	
2017-06-27 12:29:12,420 Epoch[9] Batch [1260]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.142348,	
2017-06-27 12:29:17,245 Epoch[9] Batch [1270]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.142356,	
2017-06-27 12:29:22,501 Epoch[9] Batch [1280]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.142392,	
2017-06-27 12:29:27,712 Epoch[9] Batch [1290]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.142373,	
2017-06-27 12:29:32,938 Epoch[9] Batch [1300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142286,	
2017-06-27 12:29:38,182 Epoch[9] Batch [1310]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.142205,	
2017-06-27 12:29:43,005 Epoch[9] Batch [1320]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.142202,	
2017-06-27 12:29:47,992 Epoch[9] Batch [1330]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.142222,	
2017-06-27 12:29:52,728 Epoch[9] Batch [1340]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.142164,	
2017-06-27 12:29:57,450 Epoch[9] Batch [1350]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.142208,	
2017-06-27 12:30:02,117 Epoch[9] Batch [1360]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.142206,	
2017-06-27 12:30:07,084 Epoch[9] Batch [1370]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.142120,	
2017-06-27 12:30:11,598 Epoch[9] Batch [1380]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.142075,	
2017-06-27 12:30:16,394 Epoch[9] Batch [1390]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.141884,	
2017-06-27 12:30:20,719 Epoch[9] Batch [1400]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.141853,	
2017-06-27 12:30:25,258 Epoch[9] Batch [1410]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.141804,	
2017-06-27 12:30:29,558 Epoch[9] Batch [1420]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.141772,	
2017-06-27 12:30:34,147 Epoch[9] Batch [1430]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.141639,	
2017-06-27 12:30:38,554 Epoch[9] Batch [1440]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.141554,	
2017-06-27 12:30:42,925 Epoch[9] Batch [1450]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.141589,	
2017-06-27 12:30:47,470 Epoch[9] Batch [1460]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.141497,	
2017-06-27 12:30:52,211 Epoch[9] Batch [1470]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.141520,	
2017-06-27 12:30:57,021 Epoch[9] Batch [1480]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.141439,	
2017-06-27 12:30:59,682 Epoch[9] Train-FCNLogLoss=0.141354
2017-06-27 12:30:59,682 Epoch[9] Time cost=733.171
2017-06-27 12:31:00,488 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0010.params"
2017-06-27 12:31:02,115 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0010.states"
2017-06-27 12:31:07,906 Epoch[10] Batch [10]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.123996,	
2017-06-27 12:31:12,981 Epoch[10] Batch [20]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.129076,	
2017-06-27 12:31:18,216 Epoch[10] Batch [30]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.130808,	
2017-06-27 12:31:22,996 Epoch[10] Batch [40]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.133442,	
2017-06-27 12:31:27,559 Epoch[10] Batch [50]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.135794,	
2017-06-27 12:31:31,851 Epoch[10] Batch [60]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.137014,	
2017-06-27 12:31:36,825 Epoch[10] Batch [70]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.138185,	
2017-06-27 12:31:41,469 Epoch[10] Batch [80]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.151502,	
2017-06-27 12:31:45,741 Epoch[10] Batch [90]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.154189,	
2017-06-27 12:31:50,412 Epoch[10] Batch [100]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.155320,	
2017-06-27 12:31:55,432 Epoch[10] Batch [110]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.154723,	
2017-06-27 12:32:00,535 Epoch[10] Batch [120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.153254,	
2017-06-27 12:32:05,669 Epoch[10] Batch [130]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.153247,	
2017-06-27 12:32:10,908 Epoch[10] Batch [140]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.152569,	
2017-06-27 12:32:16,013 Epoch[10] Batch [150]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.151523,	
2017-06-27 12:32:20,954 Epoch[10] Batch [160]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.150541,	
2017-06-27 12:32:25,991 Epoch[10] Batch [170]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.150240,	
2017-06-27 12:32:31,220 Epoch[10] Batch [180]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.151755,	
2017-06-27 12:32:36,580 Epoch[10] Batch [190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.151628,	
2017-06-27 12:32:41,770 Epoch[10] Batch [200]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.150789,	
2017-06-27 12:32:46,839 Epoch[10] Batch [210]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.149428,	
2017-06-27 12:32:51,471 Epoch[10] Batch [220]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.148899,	
2017-06-27 12:32:55,795 Epoch[10] Batch [230]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.148742,	
2017-06-27 12:33:00,414 Epoch[10] Batch [240]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.147694,	
2017-06-27 12:33:04,936 Epoch[10] Batch [250]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.146609,	
2017-06-27 12:33:09,713 Epoch[10] Batch [260]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.146877,	
2017-06-27 12:33:14,828 Epoch[10] Batch [270]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.146420,	
2017-06-27 12:33:19,862 Epoch[10] Batch [280]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.145963,	
2017-06-27 12:33:25,033 Epoch[10] Batch [290]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.145770,	
2017-06-27 12:33:29,766 Epoch[10] Batch [300]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.145351,	
2017-06-27 12:33:34,130 Epoch[10] Batch [310]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.144770,	
2017-06-27 12:33:39,080 Epoch[10] Batch [320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.144755,	
2017-06-27 12:33:44,304 Epoch[10] Batch [330]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.144913,	
2017-06-27 12:33:49,153 Epoch[10] Batch [340]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.144602,	
2017-06-27 12:33:54,149 Epoch[10] Batch [350]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.145076,	
2017-06-27 12:33:59,372 Epoch[10] Batch [360]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.144406,	
2017-06-27 12:34:04,444 Epoch[10] Batch [370]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.144054,	
2017-06-27 12:34:09,238 Epoch[10] Batch [380]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.144010,	
2017-06-27 12:34:14,232 Epoch[10] Batch [390]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.143658,	
2017-06-27 12:34:19,013 Epoch[10] Batch [400]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.143382,	
2017-06-27 12:34:23,930 Epoch[10] Batch [410]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.143333,	
2017-06-27 12:34:28,570 Epoch[10] Batch [420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.142820,	
2017-06-27 12:34:33,405 Epoch[10] Batch [430]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.142249,	
2017-06-27 12:34:38,110 Epoch[10] Batch [440]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.142337,	
2017-06-27 12:34:42,858 Epoch[10] Batch [450]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.142119,	
2017-06-27 12:34:47,913 Epoch[10] Batch [460]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.141711,	
2017-06-27 12:34:52,432 Epoch[10] Batch [470]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.141915,	
2017-06-27 12:34:56,893 Epoch[10] Batch [480]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.141771,	
2017-06-27 12:35:01,521 Epoch[10] Batch [490]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.141316,	
2017-06-27 12:35:06,776 Epoch[10] Batch [500]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.141169,	
2017-06-27 12:35:12,005 Epoch[10] Batch [510]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.141094,	
2017-06-27 12:35:17,286 Epoch[10] Batch [520]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.141208,	
2017-06-27 12:35:22,487 Epoch[10] Batch [530]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.140930,	
2017-06-27 12:35:27,317 Epoch[10] Batch [540]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.140546,	
2017-06-27 12:35:32,312 Epoch[10] Batch [550]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.140404,	
2017-06-27 12:35:37,357 Epoch[10] Batch [560]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.140082,	
2017-06-27 12:35:42,529 Epoch[10] Batch [570]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.140280,	
2017-06-27 12:35:47,829 Epoch[10] Batch [580]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.140405,	
2017-06-27 12:35:53,071 Epoch[10] Batch [590]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.140227,	
2017-06-27 12:35:58,129 Epoch[10] Batch [600]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.140530,	
2017-06-27 12:36:02,459 Epoch[10] Batch [610]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.140766,	
2017-06-27 12:36:07,189 Epoch[10] Batch [620]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.140416,	
2017-06-27 12:36:12,187 Epoch[10] Batch [630]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.140313,	
2017-06-27 12:36:17,081 Epoch[10] Batch [640]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.140090,	
2017-06-27 12:36:22,266 Epoch[10] Batch [650]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.140015,	
2017-06-27 12:36:27,273 Epoch[10] Batch [660]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.139704,	
2017-06-27 12:36:32,471 Epoch[10] Batch [670]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.139475,	
2017-06-27 12:36:37,692 Epoch[10] Batch [680]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.139270,	
2017-06-27 12:36:42,805 Epoch[10] Batch [690]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.139251,	
2017-06-27 12:36:47,537 Epoch[10] Batch [700]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.139032,	
2017-06-27 12:36:51,738 Epoch[10] Batch [710]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.138947,	
2017-06-27 12:36:56,162 Epoch[10] Batch [720]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.138612,	
2017-06-27 12:37:00,922 Epoch[10] Batch [730]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.138376,	
2017-06-27 12:37:06,138 Epoch[10] Batch [740]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.138227,	
2017-06-27 12:37:10,710 Epoch[10] Batch [750]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.137982,	
2017-06-27 12:37:15,268 Epoch[10] Batch [760]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.138146,	
2017-06-27 12:37:20,270 Epoch[10] Batch [770]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.138455,	
2017-06-27 12:37:25,532 Epoch[10] Batch [780]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.138588,	
2017-06-27 12:37:30,704 Epoch[10] Batch [790]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.139461,	
2017-06-27 12:37:35,803 Epoch[10] Batch [800]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.139741,	
2017-06-27 12:37:41,011 Epoch[10] Batch [810]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.140087,	
2017-06-27 12:37:45,752 Epoch[10] Batch [820]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.140118,	
2017-06-27 12:37:50,607 Epoch[10] Batch [830]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.140292,	
2017-06-27 12:37:55,353 Epoch[10] Batch [840]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.140516,	
2017-06-27 12:37:59,893 Epoch[10] Batch [850]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.140581,	
2017-06-27 12:38:04,842 Epoch[10] Batch [860]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.140504,	
2017-06-27 12:38:09,873 Epoch[10] Batch [870]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.140507,	
2017-06-27 12:38:15,133 Epoch[10] Batch [880]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.140429,	
2017-06-27 12:38:19,754 Epoch[10] Batch [890]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.140252,	
2017-06-27 12:38:24,758 Epoch[10] Batch [900]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.140400,	
2017-06-27 12:38:29,436 Epoch[10] Batch [910]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.140377,	
2017-06-27 12:38:34,021 Epoch[10] Batch [920]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.140163,	
2017-06-27 12:38:38,827 Epoch[10] Batch [930]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.140233,	
2017-06-27 12:38:43,835 Epoch[10] Batch [940]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.140205,	
2017-06-27 12:38:48,386 Epoch[10] Batch [950]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.140156,	
2017-06-27 12:38:53,337 Epoch[10] Batch [960]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.140089,	
2017-06-27 12:38:58,145 Epoch[10] Batch [970]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.140011,	
2017-06-27 12:39:03,164 Epoch[10] Batch [980]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.139981,	
2017-06-27 12:39:08,792 Epoch[10] Batch [990]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.139803,	
2017-06-27 12:39:13,036 Epoch[10] Batch [1000]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.139706,	
2017-06-27 12:39:18,447 Epoch[10] Batch [1010]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.139526,	
2017-06-27 12:39:22,698 Epoch[10] Batch [1020]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.139418,	
2017-06-27 12:39:27,931 Epoch[10] Batch [1030]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.139259,	
2017-06-27 12:39:31,752 Epoch[10] Batch [1040]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.139132,	
2017-06-27 12:39:36,038 Epoch[10] Batch [1050]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.139158,	
2017-06-27 12:39:40,419 Epoch[10] Batch [1060]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.139128,	
2017-06-27 12:39:44,729 Epoch[10] Batch [1070]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.138934,	
2017-06-27 12:39:49,553 Epoch[10] Batch [1080]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.138818,	
2017-06-27 12:39:55,924 Epoch[10] Batch [1090]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.139012,	
2017-06-27 12:40:01,198 Epoch[10] Batch [1100]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.139002,	
2017-06-27 12:40:06,854 Epoch[10] Batch [1110]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.138841,	
2017-06-27 12:40:11,707 Epoch[10] Batch [1120]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.139066,	
2017-06-27 12:40:17,352 Epoch[10] Batch [1130]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.139175,	
2017-06-27 12:40:21,285 Epoch[10] Batch [1140]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.139263,	
2017-06-27 12:40:26,131 Epoch[10] Batch [1150]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.139284,	
2017-06-27 12:40:30,590 Epoch[10] Batch [1160]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.139245,	
2017-06-27 12:40:35,357 Epoch[10] Batch [1170]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.139070,	
2017-06-27 12:40:39,908 Epoch[10] Batch [1180]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.138983,	
2017-06-27 12:40:44,848 Epoch[10] Batch [1190]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.138943,	
2017-06-27 12:40:49,364 Epoch[10] Batch [1200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.138945,	
2017-06-27 12:40:53,905 Epoch[10] Batch [1210]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.138903,	
2017-06-27 12:40:58,932 Epoch[10] Batch [1220]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.138903,	
2017-06-27 12:41:04,182 Epoch[10] Batch [1230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.138858,	
2017-06-27 12:41:09,260 Epoch[10] Batch [1240]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.138789,	
2017-06-27 12:41:14,454 Epoch[10] Batch [1250]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.138714,	
2017-06-27 12:41:19,297 Epoch[10] Batch [1260]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.138647,	
2017-06-27 12:41:24,549 Epoch[10] Batch [1270]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.138446,	
2017-06-27 12:41:29,828 Epoch[10] Batch [1280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.138360,	
2017-06-27 12:41:35,128 Epoch[10] Batch [1290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.138401,	
2017-06-27 12:41:40,300 Epoch[10] Batch [1300]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.138438,	
2017-06-27 12:41:45,555 Epoch[10] Batch [1310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.138350,	
2017-06-27 12:41:50,384 Epoch[10] Batch [1320]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.138384,	
2017-06-27 12:41:55,648 Epoch[10] Batch [1330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.138371,	
2017-06-27 12:42:00,633 Epoch[10] Batch [1340]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.138398,	
2017-06-27 12:42:05,381 Epoch[10] Batch [1350]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.138342,	
2017-06-27 12:42:10,662 Epoch[10] Batch [1360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.138294,	
2017-06-27 12:42:15,943 Epoch[10] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.138284,	
2017-06-27 12:42:20,937 Epoch[10] Batch [1380]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.138145,	
2017-06-27 12:42:26,142 Epoch[10] Batch [1390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.138105,	
2017-06-27 12:42:31,386 Epoch[10] Batch [1400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.138092,	
2017-06-27 12:42:36,659 Epoch[10] Batch [1410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.138081,	
2017-06-27 12:42:41,896 Epoch[10] Batch [1420]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.138090,	
2017-06-27 12:42:47,157 Epoch[10] Batch [1430]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.138158,	
2017-06-27 12:42:52,416 Epoch[10] Batch [1440]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.138183,	
2017-06-27 12:42:57,663 Epoch[10] Batch [1450]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.138088,	
2017-06-27 12:43:02,952 Epoch[10] Batch [1460]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.137939,	
2017-06-27 12:43:08,205 Epoch[10] Batch [1470]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.137908,	
2017-06-27 12:43:13,454 Epoch[10] Batch [1480]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.137920,	
2017-06-27 12:43:16,590 Epoch[10] Train-FCNLogLoss=0.137888
2017-06-27 12:43:16,590 Epoch[10] Time cost=734.475
2017-06-27 12:43:17,377 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0011.params"
2017-06-27 12:43:18,923 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0011.states"
2017-06-27 12:43:24,885 Epoch[11] Batch [10]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.134754,	
2017-06-27 12:43:30,111 Epoch[11] Batch [20]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.139380,	
2017-06-27 12:43:35,402 Epoch[11] Batch [30]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.139882,	
2017-06-27 12:43:40,614 Epoch[11] Batch [40]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.136195,	
2017-06-27 12:43:45,651 Epoch[11] Batch [50]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.138299,	
2017-06-27 12:43:50,179 Epoch[11] Batch [60]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.138772,	
2017-06-27 12:43:55,183 Epoch[11] Batch [70]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.138660,	
2017-06-27 12:44:00,483 Epoch[11] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.136663,	
2017-06-27 12:44:05,679 Epoch[11] Batch [90]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.138026,	
2017-06-27 12:44:10,974 Epoch[11] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.136804,	
2017-06-27 12:44:16,208 Epoch[11] Batch [110]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.138306,	
2017-06-27 12:44:21,479 Epoch[11] Batch [120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.139591,	
2017-06-27 12:44:26,730 Epoch[11] Batch [130]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.140058,	
2017-06-27 12:44:31,962 Epoch[11] Batch [140]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.139995,	
2017-06-27 12:44:37,215 Epoch[11] Batch [150]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.139139,	
2017-06-27 12:44:42,467 Epoch[11] Batch [160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.138393,	
2017-06-27 12:44:47,734 Epoch[11] Batch [170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.139812,	
2017-06-27 12:44:52,996 Epoch[11] Batch [180]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.140239,	
2017-06-27 12:44:58,248 Epoch[11] Batch [190]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.140116,	
2017-06-27 12:45:03,497 Epoch[11] Batch [200]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.139544,	
2017-06-27 12:45:08,788 Epoch[11] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.139347,	
2017-06-27 12:45:14,014 Epoch[11] Batch [220]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.138311,	
2017-06-27 12:45:19,273 Epoch[11] Batch [230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.137895,	
2017-06-27 12:45:24,521 Epoch[11] Batch [240]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.137886,	
2017-06-27 12:45:29,780 Epoch[11] Batch [250]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.137567,	
2017-06-27 12:45:35,045 Epoch[11] Batch [260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.137636,	
2017-06-27 12:45:40,292 Epoch[11] Batch [270]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.137230,	
2017-06-27 12:45:45,560 Epoch[11] Batch [280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.137353,	
2017-06-27 12:45:50,804 Epoch[11] Batch [290]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.137097,	
2017-06-27 12:45:56,072 Epoch[11] Batch [300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.137756,	
2017-06-27 12:46:01,335 Epoch[11] Batch [310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.137915,	
2017-06-27 12:46:06,573 Epoch[11] Batch [320]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.137600,	
2017-06-27 12:46:11,823 Epoch[11] Batch [330]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.137897,	
2017-06-27 12:46:17,089 Epoch[11] Batch [340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.138225,	
2017-06-27 12:46:22,340 Epoch[11] Batch [350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.138549,	
2017-06-27 12:46:27,585 Epoch[11] Batch [360]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.139498,	
2017-06-27 12:46:32,860 Epoch[11] Batch [370]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.140037,	
2017-06-27 12:46:38,086 Epoch[11] Batch [380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.139730,	
2017-06-27 12:46:43,152 Epoch[11] Batch [390]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.140056,	
2017-06-27 12:46:48,279 Epoch[11] Batch [400]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.139724,	
2017-06-27 12:46:53,504 Epoch[11] Batch [410]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.139116,	
2017-06-27 12:46:58,309 Epoch[11] Batch [420]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.139253,	
2017-06-27 12:47:03,551 Epoch[11] Batch [430]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.138917,	
2017-06-27 12:47:08,644 Epoch[11] Batch [440]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.138534,	
2017-06-27 12:47:12,773 Epoch[11] Batch [450]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.138455,	
2017-06-27 12:47:16,695 Epoch[11] Batch [460]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.138560,	
2017-06-27 12:47:20,708 Epoch[11] Batch [470]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.138207,	
2017-06-27 12:47:25,439 Epoch[11] Batch [480]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.137962,	
2017-06-27 12:47:29,466 Epoch[11] Batch [490]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.137787,	
2017-06-27 12:47:34,909 Epoch[11] Batch [500]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.137553,	
2017-06-27 12:47:39,306 Epoch[11] Batch [510]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.137015,	
2017-06-27 12:47:45,370 Epoch[11] Batch [520]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.136714,	
2017-06-27 12:47:51,105 Epoch[11] Batch [530]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.136436,	
2017-06-27 12:47:55,274 Epoch[11] Batch [540]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.136350,	
2017-06-27 12:47:59,456 Epoch[11] Batch [550]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.136266,	
2017-06-27 12:48:04,772 Epoch[11] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.136002,	
2017-06-27 12:48:09,189 Epoch[11] Batch [570]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.135914,	
2017-06-27 12:48:13,470 Epoch[11] Batch [580]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.135548,	
2017-06-27 12:48:18,821 Epoch[11] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135390,	
2017-06-27 12:48:23,380 Epoch[11] Batch [600]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.135154,	
2017-06-27 12:48:28,374 Epoch[11] Batch [610]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.135005,	
2017-06-27 12:48:32,143 Epoch[11] Batch [620]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.134856,	
2017-06-27 12:48:36,562 Epoch[11] Batch [630]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.134770,	
2017-06-27 12:48:41,348 Epoch[11] Batch [640]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.134583,	
2017-06-27 12:48:46,471 Epoch[11] Batch [650]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.134566,	
2017-06-27 12:48:50,409 Epoch[11] Batch [660]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.134542,	
2017-06-27 12:48:54,644 Epoch[11] Batch [670]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.134350,	
2017-06-27 12:48:59,269 Epoch[11] Batch [680]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.134363,	
2017-06-27 12:49:03,123 Epoch[11] Batch [690]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.134385,	
2017-06-27 12:49:07,001 Epoch[11] Batch [700]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.134343,	
2017-06-27 12:49:12,214 Epoch[11] Batch [710]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.134243,	
2017-06-27 12:49:17,147 Epoch[11] Batch [720]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.134371,	
2017-06-27 12:49:22,616 Epoch[11] Batch [730]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.134287,	
2017-06-27 12:49:27,425 Epoch[11] Batch [740]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.134142,	
2017-06-27 12:49:31,894 Epoch[11] Batch [750]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.134128,	
2017-06-27 12:49:37,201 Epoch[11] Batch [760]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.133998,	
2017-06-27 12:49:41,574 Epoch[11] Batch [770]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.133891,	
2017-06-27 12:49:45,452 Epoch[11] Batch [780]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.133820,	
2017-06-27 12:49:49,786 Epoch[11] Batch [790]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.133809,	
2017-06-27 12:49:53,670 Epoch[11] Batch [800]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.133614,	
2017-06-27 12:50:00,253 Epoch[11] Batch [810]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.133672,	
2017-06-27 12:50:05,525 Epoch[11] Batch [820]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.133523,	
2017-06-27 12:50:10,788 Epoch[11] Batch [830]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.133576,	
2017-06-27 12:50:15,561 Epoch[11] Batch [840]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.133473,	
2017-06-27 12:50:20,811 Epoch[11] Batch [850]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.133617,	
2017-06-27 12:50:25,516 Epoch[11] Batch [860]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.133494,	
2017-06-27 12:50:29,886 Epoch[11] Batch [870]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.133407,	
2017-06-27 12:50:36,008 Epoch[11] Batch [880]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.133256,	
2017-06-27 12:50:41,122 Epoch[11] Batch [890]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.133200,	
2017-06-27 12:50:46,687 Epoch[11] Batch [900]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.132955,	
2017-06-27 12:50:50,661 Epoch[11] Batch [910]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.132845,	
2017-06-27 12:50:55,689 Epoch[11] Batch [920]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.132572,	
2017-06-27 12:50:59,684 Epoch[11] Batch [930]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.132429,	
2017-06-27 12:51:06,061 Epoch[11] Batch [940]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.132764,	
2017-06-27 12:51:13,509 Epoch[11] Batch [950]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.132721,	
2017-06-27 12:51:18,527 Epoch[11] Batch [960]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.132807,	
2017-06-27 12:51:24,556 Epoch[11] Batch [970]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.132904,	
2017-06-27 12:51:28,452 Epoch[11] Batch [980]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.132964,	
2017-06-27 12:51:32,398 Epoch[11] Batch [990]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.133008,	
2017-06-27 12:51:36,353 Epoch[11] Batch [1000]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.132825,	
2017-06-27 12:51:40,765 Epoch[11] Batch [1010]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.132849,	
2017-06-27 12:51:45,259 Epoch[11] Batch [1020]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.132658,	
2017-06-27 12:51:50,352 Epoch[11] Batch [1030]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.132662,	
2017-06-27 12:51:54,460 Epoch[11] Batch [1040]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.132659,	
2017-06-27 12:51:59,662 Epoch[11] Batch [1050]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.132735,	
2017-06-27 12:52:04,185 Epoch[11] Batch [1060]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.132814,	
2017-06-27 12:52:08,099 Epoch[11] Batch [1070]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.132983,	
2017-06-27 12:52:12,043 Epoch[11] Batch [1080]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.132903,	
2017-06-27 12:52:18,037 Epoch[11] Batch [1090]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.132857,	
2017-06-27 12:52:25,516 Epoch[11] Batch [1100]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.132784,	
2017-06-27 12:52:29,923 Epoch[11] Batch [1110]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.132744,	
2017-06-27 12:52:34,068 Epoch[11] Batch [1120]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.132620,	
2017-06-27 12:52:38,308 Epoch[11] Batch [1130]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.132636,	
2017-06-27 12:52:44,703 Epoch[11] Batch [1140]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.132701,	
2017-06-27 12:52:49,809 Epoch[11] Batch [1150]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.132643,	
2017-06-27 12:52:53,615 Epoch[11] Batch [1160]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.132513,	
2017-06-27 12:52:58,453 Epoch[11] Batch [1170]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.132705,	
2017-06-27 12:53:05,635 Epoch[11] Batch [1180]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.132699,	
2017-06-27 12:53:10,795 Epoch[11] Batch [1190]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.132709,	
2017-06-27 12:53:15,833 Epoch[11] Batch [1200]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.132638,	
2017-06-27 12:53:20,089 Epoch[11] Batch [1210]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.132556,	
2017-06-27 12:53:25,368 Epoch[11] Batch [1220]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.132588,	
2017-06-27 12:53:29,630 Epoch[11] Batch [1230]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.132576,	
2017-06-27 12:53:34,196 Epoch[11] Batch [1240]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.132533,	
2017-06-27 12:53:38,233 Epoch[11] Batch [1250]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.132585,	
2017-06-27 12:53:42,918 Epoch[11] Batch [1260]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.132517,	
2017-06-27 12:53:46,896 Epoch[11] Batch [1270]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.132475,	
2017-06-27 12:53:53,455 Epoch[11] Batch [1280]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.132431,	
2017-06-27 12:53:57,378 Epoch[11] Batch [1290]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.132556,	
2017-06-27 12:54:02,476 Epoch[11] Batch [1300]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.132547,	
2017-06-27 12:54:07,886 Epoch[11] Batch [1310]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.132546,	
2017-06-27 12:54:12,614 Epoch[11] Batch [1320]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.132467,	
2017-06-27 12:54:17,996 Epoch[11] Batch [1330]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.132569,	
2017-06-27 12:54:22,645 Epoch[11] Batch [1340]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.132523,	
2017-06-27 12:54:26,549 Epoch[11] Batch [1350]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.132596,	
2017-06-27 12:54:32,954 Epoch[11] Batch [1360]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.132646,	
2017-06-27 12:54:38,176 Epoch[11] Batch [1370]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.132644,	
2017-06-27 12:54:42,172 Epoch[11] Batch [1380]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.132566,	
2017-06-27 12:54:46,058 Epoch[11] Batch [1390]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.132401,	
2017-06-27 12:54:51,314 Epoch[11] Batch [1400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.132559,	
2017-06-27 12:54:56,604 Epoch[11] Batch [1410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.132673,	
2017-06-27 12:55:01,830 Epoch[11] Batch [1420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.132663,	
2017-06-27 12:55:07,040 Epoch[11] Batch [1430]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.132546,	
2017-06-27 12:55:12,321 Epoch[11] Batch [1440]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.132630,	
2017-06-27 12:55:17,478 Epoch[11] Batch [1450]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.132520,	
2017-06-27 12:55:22,728 Epoch[11] Batch [1460]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.132742,	
2017-06-27 12:55:27,952 Epoch[11] Batch [1470]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.132740,	
2017-06-27 12:55:33,204 Epoch[11] Batch [1480]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.132725,	
2017-06-27 12:55:36,383 Epoch[11] Train-FCNLogLoss=0.132725
2017-06-27 12:55:36,383 Epoch[11] Time cost=737.460
2017-06-27 12:55:37,201 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0012.params"
2017-06-27 12:55:38,724 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0012.states"
2017-06-27 12:55:44,583 Epoch[12] Batch [10]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.130691,	
2017-06-27 12:55:49,840 Epoch[12] Batch [20]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.124777,	
2017-06-27 12:55:55,110 Epoch[12] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.120820,	
2017-06-27 12:56:00,367 Epoch[12] Batch [40]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.127467,	
2017-06-27 12:56:05,604 Epoch[12] Batch [50]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.128520,	
2017-06-27 12:56:10,785 Epoch[12] Batch [60]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.131184,	
2017-06-27 12:56:16,021 Epoch[12] Batch [70]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.132073,	
2017-06-27 12:56:21,323 Epoch[12] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.132511,	
2017-06-27 12:56:26,393 Epoch[12] Batch [90]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.132630,	
2017-06-27 12:56:31,655 Epoch[12] Batch [100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.130242,	
2017-06-27 12:56:36,896 Epoch[12] Batch [110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.130053,	
2017-06-27 12:56:42,161 Epoch[12] Batch [120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.129411,	
2017-06-27 12:56:47,380 Epoch[12] Batch [130]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.129327,	
2017-06-27 12:56:52,653 Epoch[12] Batch [140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.130180,	
2017-06-27 12:56:57,110 Epoch[12] Batch [150]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.129365,	
2017-06-27 12:57:01,749 Epoch[12] Batch [160]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.129309,	
2017-06-27 12:57:06,783 Epoch[12] Batch [170]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.130268,	
2017-06-27 12:57:12,139 Epoch[12] Batch [180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131315,	
2017-06-27 12:57:17,304 Epoch[12] Batch [190]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.132042,	
2017-06-27 12:57:22,569 Epoch[12] Batch [200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.131829,	
2017-06-27 12:57:27,816 Epoch[12] Batch [210]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.131956,	
2017-06-27 12:57:33,069 Epoch[12] Batch [220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.131629,	
2017-06-27 12:57:38,334 Epoch[12] Batch [230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.132172,	
2017-06-27 12:57:43,579 Epoch[12] Batch [240]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.131662,	
2017-06-27 12:57:48,771 Epoch[12] Batch [250]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.131526,	
2017-06-27 12:57:53,914 Epoch[12] Batch [260]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.131466,	
2017-06-27 12:57:59,231 Epoch[12] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131354,	
2017-06-27 12:58:04,451 Epoch[12] Batch [280]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.131736,	
2017-06-27 12:58:09,406 Epoch[12] Batch [290]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.131490,	
2017-06-27 12:58:14,771 Epoch[12] Batch [300]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131032,	
2017-06-27 12:58:19,808 Epoch[12] Batch [310]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.130342,	
2017-06-27 12:58:25,062 Epoch[12] Batch [320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.129797,	
2017-06-27 12:58:30,342 Epoch[12] Batch [330]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.129345,	
2017-06-27 12:58:35,586 Epoch[12] Batch [340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.129129,	
2017-06-27 12:58:40,833 Epoch[12] Batch [350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.128954,	
2017-06-27 12:58:46,120 Epoch[12] Batch [360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.128977,	
2017-06-27 12:58:51,166 Epoch[12] Batch [370]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.129344,	
2017-06-27 12:58:54,970 Epoch[12] Batch [380]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.129518,	
2017-06-27 12:58:59,178 Epoch[12] Batch [390]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.129792,	
2017-06-27 12:59:05,478 Epoch[12] Batch [400]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.129393,	
2017-06-27 12:59:10,249 Epoch[12] Batch [410]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.129310,	
2017-06-27 12:59:16,386 Epoch[12] Batch [420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.129386,	
2017-06-27 12:59:20,953 Epoch[12] Batch [430]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.129995,	
2017-06-27 12:59:26,098 Epoch[12] Batch [440]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.130254,	
2017-06-27 12:59:31,279 Epoch[12] Batch [450]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.130224,	
2017-06-27 12:59:36,522 Epoch[12] Batch [460]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.130046,	
2017-06-27 12:59:41,823 Epoch[12] Batch [470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.131014,	
2017-06-27 12:59:46,747 Epoch[12] Batch [480]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.131077,	
2017-06-27 12:59:51,867 Epoch[12] Batch [490]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.131127,	
2017-06-27 12:59:57,051 Epoch[12] Batch [500]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.131016,	
2017-06-27 13:00:02,347 Epoch[12] Batch [510]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.131301,	
2017-06-27 13:00:07,605 Epoch[12] Batch [520]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.131235,	
2017-06-27 13:00:12,896 Epoch[12] Batch [530]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131198,	
2017-06-27 13:00:18,129 Epoch[12] Batch [540]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.130958,	
2017-06-27 13:00:23,173 Epoch[12] Batch [550]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.130870,	
2017-06-27 13:00:28,371 Epoch[12] Batch [560]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.130762,	
2017-06-27 13:00:33,662 Epoch[12] Batch [570]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.130538,	
2017-06-27 13:00:38,881 Epoch[12] Batch [580]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.130525,	
2017-06-27 13:00:44,142 Epoch[12] Batch [590]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.130365,	
2017-06-27 13:00:49,420 Epoch[12] Batch [600]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130533,	
2017-06-27 13:00:54,642 Epoch[12] Batch [610]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.130467,	
2017-06-27 13:00:59,950 Epoch[12] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130266,	
2017-06-27 13:01:05,181 Epoch[12] Batch [630]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.130105,	
2017-06-27 13:01:10,453 Epoch[12] Batch [640]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.129945,	
2017-06-27 13:01:15,726 Epoch[12] Batch [650]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.129773,	
2017-06-27 13:01:20,982 Epoch[12] Batch [660]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.129999,	
2017-06-27 13:01:26,245 Epoch[12] Batch [670]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.129859,	
2017-06-27 13:01:31,452 Epoch[12] Batch [680]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.129785,	
2017-06-27 13:01:36,791 Epoch[12] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130057,	
2017-06-27 13:01:41,973 Epoch[12] Batch [700]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.129946,	
2017-06-27 13:01:46,937 Epoch[12] Batch [710]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.129702,	
2017-06-27 13:01:52,127 Epoch[12] Batch [720]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.129469,	
2017-06-27 13:01:56,841 Epoch[12] Batch [730]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.129388,	
2017-06-27 13:02:01,940 Epoch[12] Batch [740]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.129301,	
2017-06-27 13:02:07,184 Epoch[12] Batch [750]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.129283,	
2017-06-27 13:02:12,364 Epoch[12] Batch [760]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.129251,	
2017-06-27 13:02:17,433 Epoch[12] Batch [770]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.129185,	
2017-06-27 13:02:22,699 Epoch[12] Batch [780]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.129569,	
2017-06-27 13:02:27,196 Epoch[12] Batch [790]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.129692,	
2017-06-27 13:02:33,326 Epoch[12] Batch [800]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.129656,	
2017-06-27 13:02:38,183 Epoch[12] Batch [810]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.129694,	
2017-06-27 13:02:42,750 Epoch[12] Batch [820]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.129595,	
2017-06-27 13:02:46,949 Epoch[12] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.129497,	
2017-06-27 13:02:52,046 Epoch[12] Batch [840]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.129356,	
2017-06-27 13:02:57,183 Epoch[12] Batch [850]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.129295,	
2017-06-27 13:03:02,090 Epoch[12] Batch [860]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.128999,	
2017-06-27 13:03:06,970 Epoch[12] Batch [870]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.128906,	
2017-06-27 13:03:11,998 Epoch[12] Batch [880]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.128830,	
2017-06-27 13:03:16,589 Epoch[12] Batch [890]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.128862,	
2017-06-27 13:03:21,235 Epoch[12] Batch [900]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.128736,	
2017-06-27 13:03:25,472 Epoch[12] Batch [910]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.128790,	
2017-06-27 13:03:30,365 Epoch[12] Batch [920]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.128987,	
2017-06-27 13:03:35,639 Epoch[12] Batch [930]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.128943,	
2017-06-27 13:03:41,246 Epoch[12] Batch [940]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.128970,	
2017-06-27 13:03:46,624 Epoch[12] Batch [950]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.129086,	
2017-06-27 13:03:51,311 Epoch[12] Batch [960]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.129034,	
2017-06-27 13:03:56,434 Epoch[12] Batch [970]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.129205,	
2017-06-27 13:04:00,284 Epoch[12] Batch [980]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.129230,	
2017-06-27 13:04:04,313 Epoch[12] Batch [990]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.129238,	
2017-06-27 13:04:10,774 Epoch[12] Batch [1000]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.129177,	
2017-06-27 13:04:15,818 Epoch[12] Batch [1010]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.128976,	
2017-06-27 13:04:21,008 Epoch[12] Batch [1020]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.128883,	
2017-06-27 13:04:25,756 Epoch[12] Batch [1030]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.128903,	
2017-06-27 13:04:29,909 Epoch[12] Batch [1040]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.128860,	
2017-06-27 13:04:34,161 Epoch[12] Batch [1050]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.128879,	
2017-06-27 13:04:38,697 Epoch[12] Batch [1060]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.128862,	
2017-06-27 13:04:43,463 Epoch[12] Batch [1070]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.128805,	
2017-06-27 13:04:47,745 Epoch[12] Batch [1080]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.129054,	
2017-06-27 13:04:51,851 Epoch[12] Batch [1090]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129192,	
2017-06-27 13:04:57,850 Epoch[12] Batch [1100]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.129328,	
2017-06-27 13:05:02,623 Epoch[12] Batch [1110]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.129440,	
2017-06-27 13:05:06,803 Epoch[12] Batch [1120]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.129539,	
2017-06-27 13:05:10,966 Epoch[12] Batch [1130]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.129487,	
2017-06-27 13:05:14,896 Epoch[12] Batch [1140]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.129560,	
2017-06-27 13:05:21,697 Epoch[12] Batch [1150]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.129682,	
2017-06-27 13:05:28,404 Epoch[12] Batch [1160]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.129655,	
2017-06-27 13:05:33,328 Epoch[12] Batch [1170]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.129721,	
2017-06-27 13:05:38,792 Epoch[12] Batch [1180]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.129855,	
2017-06-27 13:05:42,685 Epoch[12] Batch [1190]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.129651,	
2017-06-27 13:05:47,585 Epoch[12] Batch [1200]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.129551,	
2017-06-27 13:05:52,596 Epoch[12] Batch [1210]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.129670,	
2017-06-27 13:05:58,418 Epoch[12] Batch [1220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.129723,	
2017-06-27 13:06:03,651 Epoch[12] Batch [1230]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.129710,	
2017-06-27 13:06:08,274 Epoch[12] Batch [1240]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.129705,	
2017-06-27 13:06:13,335 Epoch[12] Batch [1250]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.129663,	
2017-06-27 13:06:17,897 Epoch[12] Batch [1260]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.129682,	
2017-06-27 13:06:22,600 Epoch[12] Batch [1270]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.129677,	
2017-06-27 13:06:27,237 Epoch[12] Batch [1280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.129707,	
2017-06-27 13:06:32,256 Epoch[12] Batch [1290]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.129745,	
2017-06-27 13:06:37,130 Epoch[12] Batch [1300]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.129699,	
2017-06-27 13:06:41,682 Epoch[12] Batch [1310]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.129623,	
2017-06-27 13:06:46,739 Epoch[12] Batch [1320]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.129610,	
2017-06-27 13:06:51,450 Epoch[12] Batch [1330]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.129444,	
2017-06-27 13:06:56,439 Epoch[12] Batch [1340]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.129511,	
2017-06-27 13:07:01,415 Epoch[12] Batch [1350]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.129526,	
2017-06-27 13:07:06,424 Epoch[12] Batch [1360]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.129480,	
2017-06-27 13:07:11,207 Epoch[12] Batch [1370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.129437,	
2017-06-27 13:07:16,447 Epoch[12] Batch [1380]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.129453,	
2017-06-27 13:07:21,689 Epoch[12] Batch [1390]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.129501,	
2017-06-27 13:07:26,487 Epoch[12] Batch [1400]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.129568,	
2017-06-27 13:07:31,320 Epoch[12] Batch [1410]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.129651,	
2017-06-27 13:07:35,978 Epoch[12] Batch [1420]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.129606,	
2017-06-27 13:07:40,774 Epoch[12] Batch [1430]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.129561,	
2017-06-27 13:07:45,787 Epoch[12] Batch [1440]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.129645,	
2017-06-27 13:07:50,753 Epoch[12] Batch [1450]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.129652,	
2017-06-27 13:07:55,769 Epoch[12] Batch [1460]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.129610,	
2017-06-27 13:08:00,241 Epoch[12] Batch [1470]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.129630,	
2017-06-27 13:08:04,986 Epoch[12] Batch [1480]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.129552,	
2017-06-27 13:08:08,079 Epoch[12] Train-FCNLogLoss=0.129591
2017-06-27 13:08:08,079 Epoch[12] Time cost=749.355
2017-06-27 13:08:08,891 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0013.params"
2017-06-27 13:08:10,640 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0013.states"
2017-06-27 13:08:15,731 Epoch[13] Batch [10]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.125858,	
2017-06-27 13:08:20,587 Epoch[13] Batch [20]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.116434,	
2017-06-27 13:08:25,217 Epoch[13] Batch [30]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.119406,	
2017-06-27 13:08:29,762 Epoch[13] Batch [40]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.121515,	
2017-06-27 13:08:34,026 Epoch[13] Batch [50]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.121842,	
2017-06-27 13:08:38,764 Epoch[13] Batch [60]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.124361,	
2017-06-27 13:08:43,569 Epoch[13] Batch [70]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.123876,	
2017-06-27 13:08:48,669 Epoch[13] Batch [80]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.121934,	
2017-06-27 13:08:53,410 Epoch[13] Batch [90]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.122552,	
2017-06-27 13:08:58,427 Epoch[13] Batch [100]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.121545,	
2017-06-27 13:09:03,124 Epoch[13] Batch [110]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.122823,	
2017-06-27 13:09:07,978 Epoch[13] Batch [120]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.124122,	
2017-06-27 13:09:12,802 Epoch[13] Batch [130]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.124478,	
2017-06-27 13:09:17,549 Epoch[13] Batch [140]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.124750,	
2017-06-27 13:09:22,530 Epoch[13] Batch [150]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.125134,	
2017-06-27 13:09:27,401 Epoch[13] Batch [160]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.126227,	
2017-06-27 13:09:32,448 Epoch[13] Batch [170]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.126871,	
2017-06-27 13:09:37,487 Epoch[13] Batch [180]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.126784,	
2017-06-27 13:09:42,420 Epoch[13] Batch [190]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.126667,	
2017-06-27 13:09:47,068 Epoch[13] Batch [200]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.126753,	
2017-06-27 13:09:52,045 Epoch[13] Batch [210]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.126029,	
2017-06-27 13:09:57,269 Epoch[13] Batch [220]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.126011,	
2017-06-27 13:10:02,526 Epoch[13] Batch [230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.126596,	
2017-06-27 13:10:07,661 Epoch[13] Batch [240]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.126068,	
2017-06-27 13:10:12,395 Epoch[13] Batch [250]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.126182,	
2017-06-27 13:10:17,156 Epoch[13] Batch [260]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.126365,	
2017-06-27 13:10:22,265 Epoch[13] Batch [270]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.125670,	
2017-06-27 13:10:27,498 Epoch[13] Batch [280]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125323,	
2017-06-27 13:10:32,575 Epoch[13] Batch [290]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.124653,	
2017-06-27 13:10:37,856 Epoch[13] Batch [300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124479,	
2017-06-27 13:10:42,666 Epoch[13] Batch [310]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.124494,	
2017-06-27 13:10:47,488 Epoch[13] Batch [320]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.124553,	
2017-06-27 13:10:52,164 Epoch[13] Batch [330]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124075,	
2017-06-27 13:10:57,374 Epoch[13] Batch [340]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.124684,	
2017-06-27 13:11:02,155 Epoch[13] Batch [350]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.124320,	
2017-06-27 13:11:06,727 Epoch[13] Batch [360]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.125348,	
2017-06-27 13:11:11,272 Epoch[13] Batch [370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.125631,	
2017-06-27 13:11:15,713 Epoch[13] Batch [380]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.126301,	
2017-06-27 13:11:20,396 Epoch[13] Batch [390]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.126261,	
2017-06-27 13:11:25,216 Epoch[13] Batch [400]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.127045,	
2017-06-27 13:11:30,032 Epoch[13] Batch [410]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.126688,	
2017-06-27 13:11:34,829 Epoch[13] Batch [420]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.126571,	
2017-06-27 13:11:39,985 Epoch[13] Batch [430]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.126675,	
2017-06-27 13:11:45,074 Epoch[13] Batch [440]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.126327,	
2017-06-27 13:11:49,872 Epoch[13] Batch [450]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.126191,	
2017-06-27 13:11:54,868 Epoch[13] Batch [460]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.126518,	
2017-06-27 13:11:59,948 Epoch[13] Batch [470]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.126237,	
2017-06-27 13:12:04,755 Epoch[13] Batch [480]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.126626,	
2017-06-27 13:12:09,752 Epoch[13] Batch [490]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.126658,	
2017-06-27 13:12:14,578 Epoch[13] Batch [500]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.126900,	
2017-06-27 13:12:19,508 Epoch[13] Batch [510]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.127429,	
2017-06-27 13:12:24,270 Epoch[13] Batch [520]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.127716,	
2017-06-27 13:12:28,865 Epoch[13] Batch [530]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.127880,	
2017-06-27 13:12:33,627 Epoch[13] Batch [540]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.127803,	
2017-06-27 13:12:38,771 Epoch[13] Batch [550]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.127529,	
2017-06-27 13:12:43,730 Epoch[13] Batch [560]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.127347,	
2017-06-27 13:12:48,765 Epoch[13] Batch [570]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.127169,	
2017-06-27 13:12:53,954 Epoch[13] Batch [580]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.127042,	
2017-06-27 13:12:58,824 Epoch[13] Batch [590]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.127091,	
2017-06-27 13:13:03,580 Epoch[13] Batch [600]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.126947,	
2017-06-27 13:13:08,762 Epoch[13] Batch [610]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.126831,	
2017-06-27 13:13:13,588 Epoch[13] Batch [620]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.126913,	
2017-06-27 13:13:18,622 Epoch[13] Batch [630]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.127399,	
2017-06-27 13:13:23,416 Epoch[13] Batch [640]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.127414,	
2017-06-27 13:13:28,235 Epoch[13] Batch [650]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.127267,	
2017-06-27 13:13:32,992 Epoch[13] Batch [660]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.127067,	
2017-06-27 13:13:37,741 Epoch[13] Batch [670]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.126834,	
2017-06-27 13:13:42,482 Epoch[13] Batch [680]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.126897,	
2017-06-27 13:13:47,274 Epoch[13] Batch [690]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.126617,	
2017-06-27 13:13:50,976 Epoch[13] Batch [700]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.126730,	
2017-06-27 13:13:55,074 Epoch[13] Batch [710]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.126626,	
2017-06-27 13:14:00,063 Epoch[13] Batch [720]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.126573,	
2017-06-27 13:14:05,087 Epoch[13] Batch [730]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.126563,	
2017-06-27 13:14:10,024 Epoch[13] Batch [740]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.126634,	
2017-06-27 13:14:15,035 Epoch[13] Batch [750]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.126758,	
2017-06-27 13:14:19,961 Epoch[13] Batch [760]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.126753,	
2017-06-27 13:14:24,602 Epoch[13] Batch [770]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.126924,	
2017-06-27 13:14:29,605 Epoch[13] Batch [780]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.126917,	
2017-06-27 13:14:34,605 Epoch[13] Batch [790]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.126936,	
2017-06-27 13:14:38,793 Epoch[13] Batch [800]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.126945,	
2017-06-27 13:14:42,933 Epoch[13] Batch [810]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.126812,	
2017-06-27 13:14:47,523 Epoch[13] Batch [820]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.126677,	
2017-06-27 13:14:52,032 Epoch[13] Batch [830]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.126786,	
2017-06-27 13:14:56,543 Epoch[13] Batch [840]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.126778,	
2017-06-27 13:15:01,748 Epoch[13] Batch [850]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126719,	
2017-06-27 13:15:06,603 Epoch[13] Batch [860]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.126804,	
2017-06-27 13:15:11,396 Epoch[13] Batch [870]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.126963,	
2017-06-27 13:15:16,455 Epoch[13] Batch [880]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.126878,	
2017-06-27 13:15:21,384 Epoch[13] Batch [890]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.126919,	
2017-06-27 13:15:26,411 Epoch[13] Batch [900]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.127102,	
2017-06-27 13:15:31,281 Epoch[13] Batch [910]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.127052,	
2017-06-27 13:15:36,396 Epoch[13] Batch [920]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.126926,	
2017-06-27 13:15:41,690 Epoch[13] Batch [930]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126908,	
2017-06-27 13:15:46,773 Epoch[13] Batch [940]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.126849,	
2017-06-27 13:15:51,904 Epoch[13] Batch [950]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.127111,	
2017-06-27 13:15:56,861 Epoch[13] Batch [960]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.127011,	
2017-06-27 13:16:01,617 Epoch[13] Batch [970]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.127053,	
2017-06-27 13:16:06,675 Epoch[13] Batch [980]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.126917,	
2017-06-27 13:16:11,685 Epoch[13] Batch [990]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.126731,	
2017-06-27 13:16:16,716 Epoch[13] Batch [1000]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.126765,	
2017-06-27 13:16:21,775 Epoch[13] Batch [1010]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.126612,	
2017-06-27 13:16:26,237 Epoch[13] Batch [1020]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.126813,	
2017-06-27 13:16:31,110 Epoch[13] Batch [1030]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.126844,	
2017-06-27 13:16:36,085 Epoch[13] Batch [1040]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.126764,	
2017-06-27 13:16:40,433 Epoch[13] Batch [1050]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.126817,	
2017-06-27 13:16:44,760 Epoch[13] Batch [1060]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.126664,	
2017-06-27 13:16:49,626 Epoch[13] Batch [1070]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.126578,	
2017-06-27 13:16:54,822 Epoch[13] Batch [1080]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.126683,	
2017-06-27 13:17:00,078 Epoch[13] Batch [1090]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.126735,	
2017-06-27 13:17:04,921 Epoch[13] Batch [1100]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.126733,	
2017-06-27 13:17:09,782 Epoch[13] Batch [1110]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.126696,	
2017-06-27 13:17:14,867 Epoch[13] Batch [1120]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.126673,	
2017-06-27 13:17:19,870 Epoch[13] Batch [1130]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.126732,	
2017-06-27 13:17:24,761 Epoch[13] Batch [1140]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.126764,	
2017-06-27 13:17:29,963 Epoch[13] Batch [1150]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126866,	
2017-06-27 13:17:34,631 Epoch[13] Batch [1160]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.127094,	
2017-06-27 13:17:39,767 Epoch[13] Batch [1170]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.127114,	
2017-06-27 13:17:44,875 Epoch[13] Batch [1180]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.127112,	
2017-06-27 13:17:49,219 Epoch[13] Batch [1190]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.127138,	
2017-06-27 13:17:53,506 Epoch[13] Batch [1200]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.127077,	
2017-06-27 13:17:58,301 Epoch[13] Batch [1210]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.127145,	
2017-06-27 13:18:03,273 Epoch[13] Batch [1220]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.127243,	
2017-06-27 13:18:08,230 Epoch[13] Batch [1230]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.127268,	
2017-06-27 13:18:13,574 Epoch[13] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.127238,	
2017-06-27 13:18:18,597 Epoch[13] Batch [1250]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.127103,	
2017-06-27 13:18:23,670 Epoch[13] Batch [1260]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.127061,	
2017-06-27 13:18:28,730 Epoch[13] Batch [1270]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.127175,	
2017-06-27 13:18:33,950 Epoch[13] Batch [1280]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.127129,	
2017-06-27 13:18:39,205 Epoch[13] Batch [1290]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.127210,	
2017-06-27 13:18:44,205 Epoch[13] Batch [1300]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.127034,	
2017-06-27 13:18:49,503 Epoch[13] Batch [1310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.126971,	
2017-06-27 13:18:54,494 Epoch[13] Batch [1320]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.126919,	
2017-06-27 13:18:59,310 Epoch[13] Batch [1330]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.126926,	
2017-06-27 13:19:04,214 Epoch[13] Batch [1340]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.126810,	
2017-06-27 13:19:09,091 Epoch[13] Batch [1350]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.126771,	
2017-06-27 13:19:14,098 Epoch[13] Batch [1360]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.126814,	
2017-06-27 13:19:18,856 Epoch[13] Batch [1370]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.126831,	
2017-06-27 13:19:24,123 Epoch[13] Batch [1380]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.126749,	
2017-06-27 13:19:29,359 Epoch[13] Batch [1390]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126639,	
2017-06-27 13:19:34,526 Epoch[13] Batch [1400]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.126551,	
2017-06-27 13:19:39,392 Epoch[13] Batch [1410]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.126617,	
2017-06-27 13:19:44,652 Epoch[13] Batch [1420]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.126682,	
2017-06-27 13:19:49,841 Epoch[13] Batch [1430]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.126618,	
2017-06-27 13:19:55,081 Epoch[13] Batch [1440]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.126612,	
2017-06-27 13:20:00,148 Epoch[13] Batch [1450]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.126668,	
2017-06-27 13:20:05,114 Epoch[13] Batch [1460]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.126634,	
2017-06-27 13:20:10,184 Epoch[13] Batch [1470]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.126644,	
2017-06-27 13:20:15,367 Epoch[13] Batch [1480]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.126476,	
2017-06-27 13:20:18,583 Epoch[13] Train-FCNLogLoss=0.126367
2017-06-27 13:20:18,583 Epoch[13] Time cost=727.943
2017-06-27 13:20:19,528 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0014.params"
2017-06-27 13:20:21,306 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0014.states"
2017-06-27 13:20:26,979 Epoch[14] Batch [10]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.116101,	
2017-06-27 13:20:32,214 Epoch[14] Batch [20]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.114157,	
2017-06-27 13:20:37,487 Epoch[14] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.117869,	
2017-06-27 13:20:42,767 Epoch[14] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.113417,	
2017-06-27 13:20:47,883 Epoch[14] Batch [50]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.112884,	
2017-06-27 13:20:52,972 Epoch[14] Batch [60]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.116283,	
2017-06-27 13:20:58,056 Epoch[14] Batch [70]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.116318,	
2017-06-27 13:21:03,219 Epoch[14] Batch [80]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.115927,	
2017-06-27 13:21:08,499 Epoch[14] Batch [90]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.116753,	
2017-06-27 13:21:13,829 Epoch[14] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.115829,	
2017-06-27 13:21:18,826 Epoch[14] Batch [110]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.115995,	
2017-06-27 13:21:24,109 Epoch[14] Batch [120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116323,	
2017-06-27 13:21:29,357 Epoch[14] Batch [130]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.117122,	
2017-06-27 13:21:34,624 Epoch[14] Batch [140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.117659,	
2017-06-27 13:21:39,881 Epoch[14] Batch [150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.117865,	
2017-06-27 13:21:45,130 Epoch[14] Batch [160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.119643,	
2017-06-27 13:21:49,811 Epoch[14] Batch [170]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.119076,	
2017-06-27 13:21:54,487 Epoch[14] Batch [180]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.120201,	
2017-06-27 13:21:59,271 Epoch[14] Batch [190]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.120944,	
2017-06-27 13:22:04,061 Epoch[14] Batch [200]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.121143,	
2017-06-27 13:22:09,063 Epoch[14] Batch [210]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.121559,	
2017-06-27 13:22:13,791 Epoch[14] Batch [220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121372,	
2017-06-27 13:22:18,384 Epoch[14] Batch [230]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.121265,	
2017-06-27 13:22:22,900 Epoch[14] Batch [240]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.121063,	
2017-06-27 13:22:27,454 Epoch[14] Batch [250]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.121170,	
2017-06-27 13:22:32,034 Epoch[14] Batch [260]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.121608,	
2017-06-27 13:22:37,036 Epoch[14] Batch [270]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.121666,	
2017-06-27 13:22:42,021 Epoch[14] Batch [280]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.122440,	
2017-06-27 13:22:47,061 Epoch[14] Batch [290]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.122281,	
2017-06-27 13:22:52,027 Epoch[14] Batch [300]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.122190,	
2017-06-27 13:22:56,729 Epoch[14] Batch [310]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.124651,	
2017-06-27 13:23:01,678 Epoch[14] Batch [320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.125981,	
2017-06-27 13:23:06,840 Epoch[14] Batch [330]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.126602,	
2017-06-27 13:23:11,217 Epoch[14] Batch [340]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.128103,	
2017-06-27 13:23:15,762 Epoch[14] Batch [350]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128324,	
2017-06-27 13:23:20,310 Epoch[14] Batch [360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128169,	
2017-06-27 13:23:25,084 Epoch[14] Batch [370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.128222,	
2017-06-27 13:23:29,418 Epoch[14] Batch [380]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.128119,	
2017-06-27 13:23:33,694 Epoch[14] Batch [390]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.128103,	
2017-06-27 13:23:38,203 Epoch[14] Batch [400]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.128123,	
2017-06-27 13:23:43,033 Epoch[14] Batch [410]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.127929,	
2017-06-27 13:23:47,776 Epoch[14] Batch [420]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.128056,	
2017-06-27 13:23:52,645 Epoch[14] Batch [430]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.127930,	
2017-06-27 13:23:57,378 Epoch[14] Batch [440]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.127569,	
2017-06-27 13:24:01,997 Epoch[14] Batch [450]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.127389,	
2017-06-27 13:24:06,464 Epoch[14] Batch [460]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.127646,	
2017-06-27 13:24:10,932 Epoch[14] Batch [470]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.127285,	
2017-06-27 13:24:16,100 Epoch[14] Batch [480]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.127248,	
2017-06-27 13:24:21,268 Epoch[14] Batch [490]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.127316,	
2017-06-27 13:24:26,348 Epoch[14] Batch [500]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.127480,	
2017-06-27 13:24:31,197 Epoch[14] Batch [510]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.127264,	
2017-06-27 13:24:36,394 Epoch[14] Batch [520]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.127416,	
2017-06-27 13:24:41,449 Epoch[14] Batch [530]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.127371,	
2017-06-27 13:24:46,724 Epoch[14] Batch [540]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.127077,	
2017-06-27 13:24:52,039 Epoch[14] Batch [550]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.127093,	
2017-06-27 13:24:57,078 Epoch[14] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.127017,	
2017-06-27 13:25:01,817 Epoch[14] Batch [570]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.127103,	
2017-06-27 13:25:06,684 Epoch[14] Batch [580]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.127061,	
2017-06-27 13:25:11,398 Epoch[14] Batch [590]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.127024,	
2017-06-27 13:25:15,988 Epoch[14] Batch [600]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.126842,	
2017-06-27 13:25:20,782 Epoch[14] Batch [610]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.126750,	
2017-06-27 13:25:26,011 Epoch[14] Batch [620]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.126669,	
2017-06-27 13:25:31,242 Epoch[14] Batch [630]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.126495,	
2017-06-27 13:25:36,148 Epoch[14] Batch [640]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.126439,	
2017-06-27 13:25:40,845 Epoch[14] Batch [650]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.126395,	
2017-06-27 13:25:46,190 Epoch[14] Batch [660]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.126393,	
2017-06-27 13:25:51,424 Epoch[14] Batch [670]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126293,	
2017-06-27 13:25:56,699 Epoch[14] Batch [680]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125950,	
2017-06-27 13:26:01,990 Epoch[14] Batch [690]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125721,	
2017-06-27 13:26:07,320 Epoch[14] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125412,	
2017-06-27 13:26:12,571 Epoch[14] Batch [710]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125278,	
2017-06-27 13:26:17,858 Epoch[14] Batch [720]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125282,	
2017-06-27 13:26:23,102 Epoch[14] Batch [730]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125120,	
2017-06-27 13:26:28,359 Epoch[14] Batch [740]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125045,	
2017-06-27 13:26:33,625 Epoch[14] Batch [750]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124781,	
2017-06-27 13:26:38,908 Epoch[14] Batch [760]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124636,	
2017-06-27 13:26:44,183 Epoch[14] Batch [770]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.124620,	
2017-06-27 13:26:49,448 Epoch[14] Batch [780]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124660,	
2017-06-27 13:26:54,672 Epoch[14] Batch [790]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.124733,	
2017-06-27 13:26:59,942 Epoch[14] Batch [800]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.124841,	
2017-06-27 13:27:05,212 Epoch[14] Batch [810]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.124823,	
2017-06-27 13:27:10,488 Epoch[14] Batch [820]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.124838,	
2017-06-27 13:27:15,786 Epoch[14] Batch [830]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124925,	
2017-06-27 13:27:21,021 Epoch[14] Batch [840]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125021,	
2017-06-27 13:27:26,288 Epoch[14] Batch [850]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.124897,	
2017-06-27 13:27:31,550 Epoch[14] Batch [860]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124641,	
2017-06-27 13:27:36,724 Epoch[14] Batch [870]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.124690,	
2017-06-27 13:27:42,050 Epoch[14] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124650,	
2017-06-27 13:27:47,337 Epoch[14] Batch [890]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124488,	
2017-06-27 13:27:52,599 Epoch[14] Batch [900]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124445,	
2017-06-27 13:27:56,892 Epoch[14] Batch [910]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.124484,	
2017-06-27 13:28:01,467 Epoch[14] Batch [920]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.124492,	
2017-06-27 13:28:06,686 Epoch[14] Batch [930]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.124606,	
2017-06-27 13:28:11,984 Epoch[14] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124638,	
2017-06-27 13:28:17,204 Epoch[14] Batch [950]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.124804,	
2017-06-27 13:28:22,486 Epoch[14] Batch [960]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124938,	
2017-06-27 13:28:27,736 Epoch[14] Batch [970]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125077,	
2017-06-27 13:28:32,982 Epoch[14] Batch [980]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125369,	
2017-06-27 13:28:38,225 Epoch[14] Batch [990]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125447,	
2017-06-27 13:28:43,524 Epoch[14] Batch [1000]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125464,	
2017-06-27 13:28:48,774 Epoch[14] Batch [1010]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125587,	
2017-06-27 13:28:54,014 Epoch[14] Batch [1020]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125427,	
2017-06-27 13:28:59,291 Epoch[14] Batch [1030]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125406,	
2017-06-27 13:29:04,532 Epoch[14] Batch [1040]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125433,	
2017-06-27 13:29:09,789 Epoch[14] Batch [1050]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125377,	
2017-06-27 13:29:15,047 Epoch[14] Batch [1060]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125441,	
2017-06-27 13:29:20,301 Epoch[14] Batch [1070]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125490,	
2017-06-27 13:29:25,525 Epoch[14] Batch [1080]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.125372,	
2017-06-27 13:29:30,765 Epoch[14] Batch [1090]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125380,	
2017-06-27 13:29:36,057 Epoch[14] Batch [1100]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125386,	
2017-06-27 13:29:41,305 Epoch[14] Batch [1110]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125494,	
2017-06-27 13:29:46,583 Epoch[14] Batch [1120]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125429,	
2017-06-27 13:29:51,839 Epoch[14] Batch [1130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125445,	
2017-06-27 13:29:57,077 Epoch[14] Batch [1140]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125468,	
2017-06-27 13:30:02,332 Epoch[14] Batch [1150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125469,	
2017-06-27 13:30:07,596 Epoch[14] Batch [1160]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125335,	
2017-06-27 13:30:12,894 Epoch[14] Batch [1170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125265,	
2017-06-27 13:30:18,062 Epoch[14] Batch [1180]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.125335,	
2017-06-27 13:30:23,359 Epoch[14] Batch [1190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125287,	
2017-06-27 13:30:28,617 Epoch[14] Batch [1200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125122,	
2017-06-27 13:30:33,899 Epoch[14] Batch [1210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125019,	
2017-06-27 13:30:39,135 Epoch[14] Batch [1220]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125131,	
2017-06-27 13:30:44,390 Epoch[14] Batch [1230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125068,	
2017-06-27 13:30:49,643 Epoch[14] Batch [1240]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125133,	
2017-06-27 13:30:54,925 Epoch[14] Batch [1250]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125161,	
2017-06-27 13:31:00,187 Epoch[14] Batch [1260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125080,	
2017-06-27 13:31:05,413 Epoch[14] Batch [1270]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.125003,	
2017-06-27 13:31:10,663 Epoch[14] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.124972,	
2017-06-27 13:31:15,849 Epoch[14] Batch [1290]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.124892,	
2017-06-27 13:31:21,074 Epoch[14] Batch [1300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.124985,	
2017-06-27 13:31:26,356 Epoch[14] Batch [1310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124968,	
2017-06-27 13:31:31,602 Epoch[14] Batch [1320]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125022,	
2017-06-27 13:31:36,800 Epoch[14] Batch [1330]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.125059,	
2017-06-27 13:31:42,055 Epoch[14] Batch [1340]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125168,	
2017-06-27 13:31:47,148 Epoch[14] Batch [1350]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.125295,	
2017-06-27 13:31:52,179 Epoch[14] Batch [1360]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.125205,	
2017-06-27 13:31:57,421 Epoch[14] Batch [1370]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125151,	
2017-06-27 13:32:02,663 Epoch[14] Batch [1380]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125216,	
2017-06-27 13:32:07,913 Epoch[14] Batch [1390]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125188,	
2017-06-27 13:32:13,189 Epoch[14] Batch [1400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125228,	
2017-06-27 13:32:18,442 Epoch[14] Batch [1410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125157,	
2017-06-27 13:32:23,688 Epoch[14] Batch [1420]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125186,	
2017-06-27 13:32:28,605 Epoch[14] Batch [1430]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.125170,	
2017-06-27 13:32:33,705 Epoch[14] Batch [1440]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.125109,	
2017-06-27 13:32:38,958 Epoch[14] Batch [1450]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125106,	
2017-06-27 13:32:44,176 Epoch[14] Batch [1460]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.125136,	
2017-06-27 13:32:49,441 Epoch[14] Batch [1470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125127,	
2017-06-27 13:32:54,663 Epoch[14] Batch [1480]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.125071,	
2017-06-27 13:32:57,560 Epoch[14] Train-FCNLogLoss=0.125048
2017-06-27 13:32:57,561 Epoch[14] Time cost=756.254
2017-06-27 13:32:58,347 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0015.params"
2017-06-27 13:32:59,992 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0015.states"
2017-06-27 13:33:05,714 Epoch[15] Batch [10]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.119061,	
2017-06-27 13:33:11,036 Epoch[15] Batch [20]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.113489,	
2017-06-27 13:33:16,219 Epoch[15] Batch [30]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.116300,	
2017-06-27 13:33:21,458 Epoch[15] Batch [40]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.115104,	
2017-06-27 13:33:26,740 Epoch[15] Batch [50]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.115485,	
2017-06-27 13:33:32,004 Epoch[15] Batch [60]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.115317,	
2017-06-27 13:33:37,283 Epoch[15] Batch [70]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.116826,	
2017-06-27 13:33:42,524 Epoch[15] Batch [80]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.115362,	
2017-06-27 13:33:47,558 Epoch[15] Batch [90]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.117149,	
2017-06-27 13:33:52,804 Epoch[15] Batch [100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.116942,	
2017-06-27 13:33:58,045 Epoch[15] Batch [110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.116320,	
2017-06-27 13:34:03,301 Epoch[15] Batch [120]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.117369,	
2017-06-27 13:34:08,579 Epoch[15] Batch [130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.117172,	
2017-06-27 13:34:13,827 Epoch[15] Batch [140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.117559,	
2017-06-27 13:34:19,101 Epoch[15] Batch [150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.117956,	
2017-06-27 13:34:24,358 Epoch[15] Batch [160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.119341,	
2017-06-27 13:34:29,589 Epoch[15] Batch [170]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.118860,	
2017-06-27 13:34:34,880 Epoch[15] Batch [180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118928,	
2017-06-27 13:34:40,143 Epoch[15] Batch [190]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.119037,	
2017-06-27 13:34:45,401 Epoch[15] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.119308,	
2017-06-27 13:34:50,611 Epoch[15] Batch [210]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119888,	
2017-06-27 13:34:55,901 Epoch[15] Batch [220]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.120050,	
2017-06-27 13:35:01,171 Epoch[15] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119681,	
2017-06-27 13:35:06,432 Epoch[15] Batch [240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.119536,	
2017-06-27 13:35:11,678 Epoch[15] Batch [250]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120034,	
2017-06-27 13:35:16,970 Epoch[15] Batch [260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.120097,	
2017-06-27 13:35:22,205 Epoch[15] Batch [270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.120918,	
2017-06-27 13:35:27,481 Epoch[15] Batch [280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121183,	
2017-06-27 13:35:32,665 Epoch[15] Batch [290]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.121080,	
2017-06-27 13:35:37,650 Epoch[15] Batch [300]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.121257,	
2017-06-27 13:35:42,784 Epoch[15] Batch [310]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.120752,	
2017-06-27 13:35:48,053 Epoch[15] Batch [320]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121028,	
2017-06-27 13:35:53,318 Epoch[15] Batch [330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121133,	
2017-06-27 13:35:58,631 Epoch[15] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121549,	
2017-06-27 13:36:03,913 Epoch[15] Batch [350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122168,	
2017-06-27 13:36:09,164 Epoch[15] Batch [360]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.122584,	
2017-06-27 13:36:14,424 Epoch[15] Batch [370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123001,	
2017-06-27 13:36:19,675 Epoch[15] Batch [380]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123451,	
2017-06-27 13:36:24,934 Epoch[15] Batch [390]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123313,	
2017-06-27 13:36:30,233 Epoch[15] Batch [400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.122910,	
2017-06-27 13:36:35,506 Epoch[15] Batch [410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.122799,	
2017-06-27 13:36:40,786 Epoch[15] Batch [420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122638,	
2017-06-27 13:36:46,015 Epoch[15] Batch [430]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.122380,	
2017-06-27 13:36:50,587 Epoch[15] Batch [440]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.122344,	
2017-06-27 13:36:55,397 Epoch[15] Batch [450]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.122359,	
2017-06-27 13:37:00,438 Epoch[15] Batch [460]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.122686,	
2017-06-27 13:37:05,671 Epoch[15] Batch [470]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122614,	
2017-06-27 13:37:10,901 Epoch[15] Batch [480]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.122639,	
2017-06-27 13:37:15,810 Epoch[15] Batch [490]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.123087,	
2017-06-27 13:37:20,963 Epoch[15] Batch [500]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.122941,	
2017-06-27 13:37:25,582 Epoch[15] Batch [510]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.123048,	
2017-06-27 13:37:30,113 Epoch[15] Batch [520]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.122825,	
2017-06-27 13:37:35,290 Epoch[15] Batch [530]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.122758,	
2017-06-27 13:37:40,331 Epoch[15] Batch [540]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.122645,	
2017-06-27 13:37:45,362 Epoch[15] Batch [550]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.122775,	
2017-06-27 13:37:50,032 Epoch[15] Batch [560]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.122386,	
2017-06-27 13:37:55,163 Epoch[15] Batch [570]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.122172,	
2017-06-27 13:37:59,748 Epoch[15] Batch [580]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.122066,	
2017-06-27 13:38:04,358 Epoch[15] Batch [590]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.121969,	
2017-06-27 13:38:09,589 Epoch[15] Batch [600]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121884,	
2017-06-27 13:38:14,874 Epoch[15] Batch [610]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121664,	
2017-06-27 13:38:19,842 Epoch[15] Batch [620]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.121682,	
2017-06-27 13:38:24,552 Epoch[15] Batch [630]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.121852,	
2017-06-27 13:38:29,632 Epoch[15] Batch [640]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.121913,	
2017-06-27 13:38:34,869 Epoch[15] Batch [650]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.121811,	
2017-06-27 13:38:40,120 Epoch[15] Batch [660]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.122257,	
2017-06-27 13:38:45,465 Epoch[15] Batch [670]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122561,	
2017-06-27 13:38:50,686 Epoch[15] Batch [680]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.122666,	
2017-06-27 13:38:55,923 Epoch[15] Batch [690]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122668,	
2017-06-27 13:39:01,226 Epoch[15] Batch [700]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.122709,	
2017-06-27 13:39:06,446 Epoch[15] Batch [710]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.122565,	
2017-06-27 13:39:11,752 Epoch[15] Batch [720]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.122483,	
2017-06-27 13:39:16,979 Epoch[15] Batch [730]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.122403,	
2017-06-27 13:39:22,252 Epoch[15] Batch [740]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.122376,	
2017-06-27 13:39:27,527 Epoch[15] Batch [750]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122338,	
2017-06-27 13:39:32,760 Epoch[15] Batch [760]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122349,	
2017-06-27 13:39:38,075 Epoch[15] Batch [770]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.122354,	
2017-06-27 13:39:43,308 Epoch[15] Batch [780]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122503,	
2017-06-27 13:39:48,566 Epoch[15] Batch [790]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.122366,	
2017-06-27 13:39:53,659 Epoch[15] Batch [800]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.122367,	
2017-06-27 13:39:58,698 Epoch[15] Batch [810]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.122198,	
2017-06-27 13:40:03,972 Epoch[15] Batch [820]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122204,	
2017-06-27 13:40:09,188 Epoch[15] Batch [830]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.122083,	
2017-06-27 13:40:14,464 Epoch[15] Batch [840]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122078,	
2017-06-27 13:40:19,711 Epoch[15] Batch [850]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121976,	
2017-06-27 13:40:24,952 Epoch[15] Batch [860]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.122088,	
2017-06-27 13:40:30,246 Epoch[15] Batch [870]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.121925,	
2017-06-27 13:40:35,471 Epoch[15] Batch [880]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121781,	
2017-06-27 13:40:40,534 Epoch[15] Batch [890]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.121706,	
2017-06-27 13:40:45,793 Epoch[15] Batch [900]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121734,	
2017-06-27 13:40:51,059 Epoch[15] Batch [910]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121782,	
2017-06-27 13:40:56,261 Epoch[15] Batch [920]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.121660,	
2017-06-27 13:41:01,541 Epoch[15] Batch [930]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121641,	
2017-06-27 13:41:06,787 Epoch[15] Batch [940]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.121619,	
2017-06-27 13:41:12,060 Epoch[15] Batch [950]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121569,	
2017-06-27 13:41:16,521 Epoch[15] Batch [960]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.121398,	
2017-06-27 13:41:20,979 Epoch[15] Batch [970]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.121408,	
2017-06-27 13:41:26,480 Epoch[15] Batch [980]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.121534,	
2017-06-27 13:41:31,536 Epoch[15] Batch [990]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.121621,	
2017-06-27 13:41:36,802 Epoch[15] Batch [1000]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121681,	
2017-06-27 13:41:42,081 Epoch[15] Batch [1010]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121651,	
2017-06-27 13:41:47,310 Epoch[15] Batch [1020]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121786,	
2017-06-27 13:41:52,567 Epoch[15] Batch [1030]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121624,	
2017-06-27 13:41:57,843 Epoch[15] Batch [1040]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121701,	
2017-06-27 13:42:03,111 Epoch[15] Batch [1050]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121619,	
2017-06-27 13:42:08,337 Epoch[15] Batch [1060]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121626,	
2017-06-27 13:42:13,624 Epoch[15] Batch [1070]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121567,	
2017-06-27 13:42:18,903 Epoch[15] Batch [1080]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121422,	
2017-06-27 13:42:24,100 Epoch[15] Batch [1090]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.121394,	
2017-06-27 13:42:28,670 Epoch[15] Batch [1100]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.121317,	
2017-06-27 13:42:33,923 Epoch[15] Batch [1110]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121214,	
2017-06-27 13:42:39,166 Epoch[15] Batch [1120]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.121216,	
2017-06-27 13:42:44,439 Epoch[15] Batch [1130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121122,	
2017-06-27 13:42:49,661 Epoch[15] Batch [1140]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.121257,	
2017-06-27 13:42:54,948 Epoch[15] Batch [1150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121301,	
2017-06-27 13:43:00,183 Epoch[15] Batch [1160]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.121359,	
2017-06-27 13:43:05,461 Epoch[15] Batch [1170]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121372,	
2017-06-27 13:43:10,736 Epoch[15] Batch [1180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121428,	
2017-06-27 13:43:16,001 Epoch[15] Batch [1190]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121745,	
2017-06-27 13:43:21,226 Epoch[15] Batch [1200]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.121764,	
2017-06-27 13:43:26,458 Epoch[15] Batch [1210]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121830,	
2017-06-27 13:43:31,743 Epoch[15] Batch [1220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121747,	
2017-06-27 13:43:36,592 Epoch[15] Batch [1230]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.121765,	
2017-06-27 13:43:41,793 Epoch[15] Batch [1240]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.121904,	
2017-06-27 13:43:47,062 Epoch[15] Batch [1250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.122228,	
2017-06-27 13:43:52,372 Epoch[15] Batch [1260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.122282,	
2017-06-27 13:43:57,664 Epoch[15] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122595,	
2017-06-27 13:44:02,993 Epoch[15] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122659,	
2017-06-27 13:44:08,021 Epoch[15] Batch [1290]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.122827,	
2017-06-27 13:44:12,816 Epoch[15] Batch [1300]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.122849,	
2017-06-27 13:44:17,839 Epoch[15] Batch [1310]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.122940,	
2017-06-27 13:44:22,630 Epoch[15] Batch [1320]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.122969,	
2017-06-27 13:44:27,912 Epoch[15] Batch [1330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122936,	
2017-06-27 13:44:33,172 Epoch[15] Batch [1340]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123077,	
2017-06-27 13:44:38,199 Epoch[15] Batch [1350]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.123159,	
2017-06-27 13:44:43,187 Epoch[15] Batch [1360]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.123126,	
2017-06-27 13:44:48,259 Epoch[15] Batch [1370]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.123171,	
2017-06-27 13:44:53,508 Epoch[15] Batch [1380]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123254,	
2017-06-27 13:44:58,679 Epoch[15] Batch [1390]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.123296,	
2017-06-27 13:45:03,570 Epoch[15] Batch [1400]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.123218,	
2017-06-27 13:45:08,758 Epoch[15] Batch [1410]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.123196,	
2017-06-27 13:45:14,048 Epoch[15] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.123270,	
2017-06-27 13:45:19,305 Epoch[15] Batch [1430]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123260,	
2017-06-27 13:45:24,570 Epoch[15] Batch [1440]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.123180,	
2017-06-27 13:45:29,828 Epoch[15] Batch [1450]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123170,	
2017-06-27 13:45:35,067 Epoch[15] Batch [1460]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.123211,	
2017-06-27 13:45:40,343 Epoch[15] Batch [1470]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.123118,	
2017-06-27 13:45:45,629 Epoch[15] Batch [1480]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.123164,	
2017-06-27 13:45:48,785 Epoch[15] Train-FCNLogLoss=0.123153
2017-06-27 13:45:48,785 Epoch[15] Time cost=768.793
2017-06-27 13:45:49,594 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0016.params"
2017-06-27 13:45:51,333 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0016.states"
2017-06-27 13:45:56,967 Epoch[16] Batch [10]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.120376,	
2017-06-27 13:46:02,227 Epoch[16] Batch [20]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.126434,	
2017-06-27 13:46:07,491 Epoch[16] Batch [30]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121761,	
2017-06-27 13:46:12,751 Epoch[16] Batch [40]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121565,	
2017-06-27 13:46:18,011 Epoch[16] Batch [50]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.123025,	
2017-06-27 13:46:23,261 Epoch[16] Batch [60]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.126911,	
2017-06-27 13:46:28,536 Epoch[16] Batch [70]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.128720,	
2017-06-27 13:46:33,770 Epoch[16] Batch [80]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.130662,	
2017-06-27 13:46:39,046 Epoch[16] Batch [90]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.133384,	
2017-06-27 13:46:44,310 Epoch[16] Batch [100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.134937,	
2017-06-27 13:46:49,594 Epoch[16] Batch [110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.135051,	
2017-06-27 13:46:54,844 Epoch[16] Batch [120]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.134598,	
2017-06-27 13:47:00,122 Epoch[16] Batch [130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.136479,	
2017-06-27 13:47:05,400 Epoch[16] Batch [140]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.135021,	
2017-06-27 13:47:10,629 Epoch[16] Batch [150]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.134157,	
2017-06-27 13:47:15,907 Epoch[16] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.134013,	
2017-06-27 13:47:21,180 Epoch[16] Batch [170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.133689,	
2017-06-27 13:47:26,457 Epoch[16] Batch [180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.132096,	
2017-06-27 13:47:31,731 Epoch[16] Batch [190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130991,	
2017-06-27 13:47:36,979 Epoch[16] Batch [200]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.130215,	
2017-06-27 13:47:42,261 Epoch[16] Batch [210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130495,	
2017-06-27 13:47:47,492 Epoch[16] Batch [220]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.130533,	
2017-06-27 13:47:52,768 Epoch[16] Batch [230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.129753,	
2017-06-27 13:47:58,048 Epoch[16] Batch [240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130124,	
2017-06-27 13:48:03,311 Epoch[16] Batch [250]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.129757,	
2017-06-27 13:48:08,594 Epoch[16] Batch [260]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.129320,	
2017-06-27 13:48:13,826 Epoch[16] Batch [270]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.128279,	
2017-06-27 13:48:19,095 Epoch[16] Batch [280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.127793,	
2017-06-27 13:48:24,367 Epoch[16] Batch [290]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.127225,	
2017-06-27 13:48:29,633 Epoch[16] Batch [300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.126626,	
2017-06-27 13:48:34,903 Epoch[16] Batch [310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.126441,	
2017-06-27 13:48:40,140 Epoch[16] Batch [320]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126015,	
2017-06-27 13:48:45,401 Epoch[16] Batch [330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125755,	
2017-06-27 13:48:50,646 Epoch[16] Batch [340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.125602,	
2017-06-27 13:48:55,925 Epoch[16] Batch [350]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125532,	
2017-06-27 13:49:01,198 Epoch[16] Batch [360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.125475,	
2017-06-27 13:49:06,437 Epoch[16] Batch [370]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125470,	
2017-06-27 13:49:11,706 Epoch[16] Batch [380]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.125504,	
2017-06-27 13:49:16,994 Epoch[16] Batch [390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125662,	
2017-06-27 13:49:22,227 Epoch[16] Batch [400]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126078,	
2017-06-27 13:49:27,383 Epoch[16] Batch [410]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.125866,	
2017-06-27 13:49:32,675 Epoch[16] Batch [420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125859,	
2017-06-27 13:49:37,923 Epoch[16] Batch [430]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125899,	
2017-06-27 13:49:43,194 Epoch[16] Batch [440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.126348,	
2017-06-27 13:49:48,441 Epoch[16] Batch [450]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.126177,	
2017-06-27 13:49:53,709 Epoch[16] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.125975,	
2017-06-27 13:49:58,937 Epoch[16] Batch [470]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.125799,	
2017-06-27 13:50:04,234 Epoch[16] Batch [480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125786,	
2017-06-27 13:50:09,503 Epoch[16] Batch [490]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.125809,	
2017-06-27 13:50:14,697 Epoch[16] Batch [500]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.125612,	
2017-06-27 13:50:20,018 Epoch[16] Batch [510]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125344,	
2017-06-27 13:50:25,228 Epoch[16] Batch [520]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.125070,	
2017-06-27 13:50:30,510 Epoch[16] Batch [530]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124789,	
2017-06-27 13:50:35,819 Epoch[16] Batch [540]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124481,	
2017-06-27 13:50:41,071 Epoch[16] Batch [550]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.124684,	
2017-06-27 13:50:46,325 Epoch[16] Batch [560]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.124430,	
2017-06-27 13:50:51,588 Epoch[16] Batch [570]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124232,	
2017-06-27 13:50:56,885 Epoch[16] Batch [580]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124059,	
2017-06-27 13:51:02,136 Epoch[16] Batch [590]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.124096,	
2017-06-27 13:51:07,404 Epoch[16] Batch [600]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.123967,	
2017-06-27 13:51:12,672 Epoch[16] Batch [610]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.123982,	
2017-06-27 13:51:17,935 Epoch[16] Batch [620]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.123777,	
2017-06-27 13:51:23,180 Epoch[16] Batch [630]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.123768,	
2017-06-27 13:51:28,461 Epoch[16] Batch [640]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.123578,	
2017-06-27 13:51:33,737 Epoch[16] Batch [650]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.123444,	
2017-06-27 13:51:39,027 Epoch[16] Batch [660]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.123387,	
2017-06-27 13:51:44,280 Epoch[16] Batch [670]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123181,	
2017-06-27 13:51:49,557 Epoch[16] Batch [680]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.123079,	
2017-06-27 13:51:54,803 Epoch[16] Batch [690]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123003,	
2017-06-27 13:52:00,093 Epoch[16] Batch [700]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122988,	
2017-06-27 13:52:05,367 Epoch[16] Batch [710]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122847,	
2017-06-27 13:52:10,635 Epoch[16] Batch [720]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.122769,	
2017-06-27 13:52:15,887 Epoch[16] Batch [730]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.122702,	
2017-06-27 13:52:21,177 Epoch[16] Batch [740]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122792,	
2017-06-27 13:52:26,451 Epoch[16] Batch [750]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122689,	
2017-06-27 13:52:31,738 Epoch[16] Batch [760]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122475,	
2017-06-27 13:52:36,997 Epoch[16] Batch [770]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.122471,	
2017-06-27 13:52:42,268 Epoch[16] Batch [780]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.122569,	
2017-06-27 13:52:47,550 Epoch[16] Batch [790]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122581,	
2017-06-27 13:52:52,814 Epoch[16] Batch [800]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.122569,	
2017-06-27 13:52:58,106 Epoch[16] Batch [810]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122583,	
2017-06-27 13:53:03,366 Epoch[16] Batch [820]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.122681,	
2017-06-27 13:53:08,632 Epoch[16] Batch [830]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.122626,	
2017-06-27 13:53:13,944 Epoch[16] Batch [840]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.122713,	
2017-06-27 13:53:19,271 Epoch[16] Batch [850]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122625,	
2017-06-27 13:53:24,466 Epoch[16] Batch [860]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.122450,	
2017-06-27 13:53:29,765 Epoch[16] Batch [870]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.122566,	
2017-06-27 13:53:35,059 Epoch[16] Batch [880]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122651,	
2017-06-27 13:53:40,291 Epoch[16] Batch [890]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.122499,	
2017-06-27 13:53:45,598 Epoch[16] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.122465,	
2017-06-27 13:53:50,878 Epoch[16] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122309,	
2017-06-27 13:53:56,167 Epoch[16] Batch [920]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122269,	
2017-06-27 13:54:01,444 Epoch[16] Batch [930]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122242,	
2017-06-27 13:54:06,709 Epoch[16] Batch [940]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.122157,	
2017-06-27 13:54:11,965 Epoch[16] Batch [950]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.122187,	
2017-06-27 13:54:17,253 Epoch[16] Batch [960]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122032,	
2017-06-27 13:54:22,510 Epoch[16] Batch [970]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121903,	
2017-06-27 13:54:27,778 Epoch[16] Batch [980]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121901,	
2017-06-27 13:54:31,743 Epoch[16] Batch [990]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.121921,	
2017-06-27 13:54:36,899 Epoch[16] Batch [1000]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.121773,	
2017-06-27 13:54:42,196 Epoch[16] Batch [1010]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121590,	
2017-06-27 13:54:47,467 Epoch[16] Batch [1020]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121549,	
2017-06-27 13:54:52,720 Epoch[16] Batch [1030]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121456,	
2017-06-27 13:54:57,988 Epoch[16] Batch [1040]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121464,	
2017-06-27 13:55:03,024 Epoch[16] Batch [1050]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.121387,	
2017-06-27 13:55:08,285 Epoch[16] Batch [1060]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121318,	
2017-06-27 13:55:13,540 Epoch[16] Batch [1070]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121400,	
2017-06-27 13:55:18,800 Epoch[16] Batch [1080]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121473,	
2017-06-27 13:55:24,108 Epoch[16] Batch [1090]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121543,	
2017-06-27 13:55:29,368 Epoch[16] Batch [1100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121549,	
2017-06-27 13:55:34,634 Epoch[16] Batch [1110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121355,	
2017-06-27 13:55:39,914 Epoch[16] Batch [1120]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121340,	
2017-06-27 13:55:45,182 Epoch[16] Batch [1130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121339,	
2017-06-27 13:55:50,496 Epoch[16] Batch [1140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121253,	
2017-06-27 13:55:55,743 Epoch[16] Batch [1150]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121253,	
2017-06-27 13:56:00,973 Epoch[16] Batch [1160]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121152,	
2017-06-27 13:56:06,403 Epoch[16] Batch [1170]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.121233,	
2017-06-27 13:56:12,404 Epoch[16] Batch [1180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.121122,	
2017-06-27 13:56:18,122 Epoch[16] Batch [1190]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.121135,	
2017-06-27 13:56:24,223 Epoch[16] Batch [1200]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.121088,	
2017-06-27 13:56:30,166 Epoch[16] Batch [1210]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.121022,	
2017-06-27 13:56:36,418 Epoch[16] Batch [1220]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.121021,	
2017-06-27 13:56:42,340 Epoch[16] Batch [1230]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.120976,	
2017-06-27 13:56:47,983 Epoch[16] Batch [1240]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.120961,	
2017-06-27 13:56:53,752 Epoch[16] Batch [1250]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120861,	
2017-06-27 13:56:59,949 Epoch[16] Batch [1260]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.120816,	
2017-06-27 13:57:07,177 Epoch[16] Batch [1270]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.120759,	
2017-06-27 13:57:13,659 Epoch[16] Batch [1280]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.120713,	
2017-06-27 13:57:19,965 Epoch[16] Batch [1290]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.120788,	
2017-06-27 13:57:25,943 Epoch[16] Batch [1300]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.120759,	
2017-06-27 13:57:31,653 Epoch[16] Batch [1310]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.120790,	
2017-06-27 13:57:37,470 Epoch[16] Batch [1320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120917,	
2017-06-27 13:57:43,655 Epoch[16] Batch [1330]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.120916,	
2017-06-27 13:57:49,401 Epoch[16] Batch [1340]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.120738,	
2017-06-27 13:57:55,269 Epoch[16] Batch [1350]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.120724,	
2017-06-27 13:58:00,861 Epoch[16] Batch [1360]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.120695,	
2017-06-27 13:58:06,721 Epoch[16] Batch [1370]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.120750,	
2017-06-27 13:58:12,809 Epoch[16] Batch [1380]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.120781,	
2017-06-27 13:58:19,537 Epoch[16] Batch [1390]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.120883,	
2017-06-27 13:58:25,522 Epoch[16] Batch [1400]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.121174,	
2017-06-27 13:58:31,821 Epoch[16] Batch [1410]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.121197,	
2017-06-27 13:58:38,950 Epoch[16] Batch [1420]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.121288,	
2017-06-27 13:58:44,605 Epoch[16] Batch [1430]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.121329,	
2017-06-27 13:58:51,044 Epoch[16] Batch [1440]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.121402,	
2017-06-27 13:58:57,334 Epoch[16] Batch [1450]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.121412,	
2017-06-27 13:59:03,604 Epoch[16] Batch [1460]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.121419,	
2017-06-27 13:59:10,080 Epoch[16] Batch [1470]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.121749,	
2017-06-27 13:59:15,956 Epoch[16] Batch [1480]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.121976,	
2017-06-27 13:59:19,919 Epoch[16] Train-FCNLogLoss=0.122488
2017-06-27 13:59:19,919 Epoch[16] Time cost=808.582
2017-06-27 13:59:21,254 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0017.params"
2017-06-27 13:59:25,230 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0017.states"
2017-06-27 13:59:31,851 Epoch[17] Batch [10]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.193531,	
2017-06-27 13:59:37,707 Epoch[17] Batch [20]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.178109,	
2017-06-27 13:59:43,511 Epoch[17] Batch [30]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164004,	
2017-06-27 13:59:49,335 Epoch[17] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.165632,	
2017-06-27 13:59:55,217 Epoch[17] Batch [50]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.160814,	
2017-06-27 14:00:01,118 Epoch[17] Batch [60]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.160052,	
2017-06-27 14:00:07,707 Epoch[17] Batch [70]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.155364,	
2017-06-27 14:00:14,445 Epoch[17] Batch [80]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.151513,	
2017-06-27 14:00:20,546 Epoch[17] Batch [90]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.148578,	
2017-06-27 14:00:27,161 Epoch[17] Batch [100]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.146110,	
2017-06-27 14:00:33,638 Epoch[17] Batch [110]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.145184,	
2017-06-27 14:00:39,784 Epoch[17] Batch [120]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.143366,	
2017-06-27 14:00:46,766 Epoch[17] Batch [130]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.145991,	
2017-06-27 14:00:52,955 Epoch[17] Batch [140]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.145822,	
2017-06-27 14:00:59,679 Epoch[17] Batch [150]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.143354,	
2017-06-27 14:01:06,319 Epoch[17] Batch [160]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.141613,	
2017-06-27 14:01:12,681 Epoch[17] Batch [170]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.140572,	
2017-06-27 14:01:18,972 Epoch[17] Batch [180]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.138873,	
2017-06-27 14:01:24,992 Epoch[17] Batch [190]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.138076,	
2017-06-27 14:01:30,963 Epoch[17] Batch [200]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.137504,	
2017-06-27 14:01:37,404 Epoch[17] Batch [210]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.136900,	
2017-06-27 14:01:44,344 Epoch[17] Batch [220]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.135827,	
2017-06-27 14:01:50,506 Epoch[17] Batch [230]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.135256,	
2017-06-27 14:01:57,195 Epoch[17] Batch [240]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.134959,	
2017-06-27 14:02:03,748 Epoch[17] Batch [250]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.134711,	
2017-06-27 14:02:10,647 Epoch[17] Batch [260]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.133690,	
2017-06-27 14:02:17,472 Epoch[17] Batch [270]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.133120,	
2017-06-27 14:02:23,837 Epoch[17] Batch [280]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.132351,	
2017-06-27 14:02:30,255 Epoch[17] Batch [290]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.132194,	
2017-06-27 14:02:37,323 Epoch[17] Batch [300]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.131372,	
2017-06-27 14:02:45,656 Epoch[17] Batch [310]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.130905,	
2017-06-27 14:02:53,701 Epoch[17] Batch [320]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.130212,	
2017-06-27 14:03:01,488 Epoch[17] Batch [330]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.129839,	
2017-06-27 14:03:09,259 Epoch[17] Batch [340]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.129358,	
2017-06-27 14:03:18,279 Epoch[17] Batch [350]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.128988,	
2017-06-27 14:03:25,339 Epoch[17] Batch [360]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.128618,	
2017-06-27 14:03:32,638 Epoch[17] Batch [370]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.128159,	
2017-06-27 14:03:39,405 Epoch[17] Batch [380]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.127627,	
2017-06-27 14:03:46,643 Epoch[17] Batch [390]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.127565,	
2017-06-27 14:03:53,381 Epoch[17] Batch [400]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.127138,	
2017-06-27 14:04:01,111 Epoch[17] Batch [410]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.126546,	
2017-06-27 14:04:08,476 Epoch[17] Batch [420]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.126385,	
2017-06-27 14:04:15,756 Epoch[17] Batch [430]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.126153,	
2017-06-27 14:04:22,655 Epoch[17] Batch [440]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.126078,	
2017-06-27 14:04:29,372 Epoch[17] Batch [450]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.125733,	
2017-06-27 14:04:36,587 Epoch[17] Batch [460]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.126012,	
2017-06-27 14:04:43,469 Epoch[17] Batch [470]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.125626,	
2017-06-27 14:04:50,631 Epoch[17] Batch [480]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.125552,	
2017-06-27 14:04:57,981 Epoch[17] Batch [490]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.125235,	
2017-06-27 14:05:05,450 Epoch[17] Batch [500]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.125097,	
2017-06-27 14:05:13,378 Epoch[17] Batch [510]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.125029,	
2017-06-27 14:05:20,802 Epoch[17] Batch [520]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.124813,	
2017-06-27 14:05:28,714 Epoch[17] Batch [530]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.125093,	
2017-06-27 14:05:36,717 Epoch[17] Batch [540]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.124673,	
2017-06-27 14:05:44,268 Epoch[17] Batch [550]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.124520,	
2017-06-27 14:05:52,271 Epoch[17] Batch [560]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.124508,	
2017-06-27 14:06:00,305 Epoch[17] Batch [570]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.124269,	
2017-06-27 14:06:07,321 Epoch[17] Batch [580]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.124271,	
2017-06-27 14:06:14,939 Epoch[17] Batch [590]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.124265,	
2017-06-27 14:06:22,000 Epoch[17] Batch [600]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.123934,	
2017-06-27 14:06:32,015 Epoch[17] Batch [610]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.123672,	
2017-06-27 14:06:41,753 Epoch[17] Batch [620]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.123537,	
2017-06-27 14:06:49,792 Epoch[17] Batch [630]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.123291,	
2017-06-27 14:06:57,070 Epoch[17] Batch [640]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.123099,	
2017-06-27 14:07:04,005 Epoch[17] Batch [650]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.122978,	
2017-06-27 14:07:12,382 Epoch[17] Batch [660]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.122779,	
2017-06-27 14:07:20,798 Epoch[17] Batch [670]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.122724,	
2017-06-27 14:07:29,093 Epoch[17] Batch [680]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.122599,	
2017-06-27 14:07:36,726 Epoch[17] Batch [690]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.122452,	
2017-06-27 14:07:45,807 Epoch[17] Batch [700]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.122533,	
2017-06-27 14:07:53,991 Epoch[17] Batch [710]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.122449,	
2017-06-27 14:08:04,900 Epoch[17] Batch [720]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.122451,	
2017-06-27 14:08:18,936 Epoch[17] Batch [730]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.122319,	
2017-06-27 14:08:30,340 Epoch[17] Batch [740]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.122061,	
2017-06-27 14:08:39,928 Epoch[17] Batch [750]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.122070,	
2017-06-27 14:08:46,815 Epoch[17] Batch [760]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.121976,	
2017-06-27 14:08:53,994 Epoch[17] Batch [770]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.121832,	
2017-06-27 14:09:02,307 Epoch[17] Batch [780]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.121574,	
2017-06-27 14:09:09,697 Epoch[17] Batch [790]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.121290,	
2017-06-27 14:09:16,834 Epoch[17] Batch [800]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.121145,	
2017-06-27 14:09:23,477 Epoch[17] Batch [810]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.121022,	
2017-06-27 14:09:30,853 Epoch[17] Batch [820]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.121014,	
2017-06-27 14:09:37,455 Epoch[17] Batch [830]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.120891,	
2017-06-27 14:09:44,702 Epoch[17] Batch [840]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.120902,	
2017-06-27 14:09:51,718 Epoch[17] Batch [850]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.120903,	
2017-06-27 14:09:58,253 Epoch[17] Batch [860]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.120888,	
2017-06-27 14:10:04,503 Epoch[17] Batch [870]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.120789,	
2017-06-27 14:10:11,303 Epoch[17] Batch [880]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.120748,	
2017-06-27 14:10:18,293 Epoch[17] Batch [890]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.120572,	
2017-06-27 14:10:25,276 Epoch[17] Batch [900]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.120418,	
2017-06-27 14:10:32,701 Epoch[17] Batch [910]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.120490,	
2017-06-27 14:10:40,097 Epoch[17] Batch [920]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.120495,	
2017-06-27 14:10:47,587 Epoch[17] Batch [930]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.120419,	
2017-06-27 14:10:54,922 Epoch[17] Batch [940]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.120290,	
2017-06-27 14:11:02,201 Epoch[17] Batch [950]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.120159,	
2017-06-27 14:11:08,581 Epoch[17] Batch [960]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.120266,	
2017-06-27 14:11:13,922 Epoch[17] Batch [970]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.120266,	
2017-06-27 14:11:19,184 Epoch[17] Batch [980]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.120362,	
2017-06-27 14:11:24,844 Epoch[17] Batch [990]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.120431,	
2017-06-27 14:11:30,882 Epoch[17] Batch [1000]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.120298,	
2017-06-27 14:11:36,915 Epoch[17] Batch [1010]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.120273,	
2017-06-27 14:11:42,939 Epoch[17] Batch [1020]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.120167,	
2017-06-27 14:11:48,990 Epoch[17] Batch [1030]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.120090,	
2017-06-27 14:11:54,982 Epoch[17] Batch [1040]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.120023,	
2017-06-27 14:12:01,028 Epoch[17] Batch [1050]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.120016,	
2017-06-27 14:12:07,109 Epoch[17] Batch [1060]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.120032,	
2017-06-27 14:12:13,104 Epoch[17] Batch [1070]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.120047,	
2017-06-27 14:12:19,076 Epoch[17] Batch [1080]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.119896,	
2017-06-27 14:12:25,166 Epoch[17] Batch [1090]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.119843,	
2017-06-27 14:12:31,251 Epoch[17] Batch [1100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.119793,	
2017-06-27 14:12:37,324 Epoch[17] Batch [1110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.119768,	
2017-06-27 14:12:43,428 Epoch[17] Batch [1120]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.119701,	
2017-06-27 14:12:49,300 Epoch[17] Batch [1130]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.119690,	
2017-06-27 14:12:53,677 Epoch[17] Batch [1140]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.119778,	
2017-06-27 14:12:59,643 Epoch[17] Batch [1150]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.119830,	
2017-06-27 14:13:05,680 Epoch[17] Batch [1160]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.119801,	
2017-06-27 14:13:11,647 Epoch[17] Batch [1170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.119792,	
2017-06-27 14:13:17,408 Epoch[17] Batch [1180]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.119926,	
2017-06-27 14:13:22,788 Epoch[17] Batch [1190]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119962,	
2017-06-27 14:13:28,198 Epoch[17] Batch [1200]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.120059,	
2017-06-27 14:13:33,451 Epoch[17] Batch [1210]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.120065,	
2017-06-27 14:13:38,779 Epoch[17] Batch [1220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120052,	
2017-06-27 14:13:44,044 Epoch[17] Batch [1230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.120020,	
2017-06-27 14:13:49,395 Epoch[17] Batch [1240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.120035,	
2017-06-27 14:13:54,669 Epoch[17] Batch [1250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119971,	
2017-06-27 14:13:59,977 Epoch[17] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119939,	
2017-06-27 14:14:05,189 Epoch[17] Batch [1270]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119866,	
2017-06-27 14:14:10,505 Epoch[17] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119897,	
2017-06-27 14:14:15,812 Epoch[17] Batch [1290]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119993,	
2017-06-27 14:14:21,114 Epoch[17] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.120047,	
2017-06-27 14:14:26,329 Epoch[17] Batch [1310]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.120073,	
2017-06-27 14:14:31,657 Epoch[17] Batch [1320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120072,	
2017-06-27 14:14:36,913 Epoch[17] Batch [1330]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.119930,	
2017-06-27 14:14:42,226 Epoch[17] Batch [1340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.120027,	
2017-06-27 14:14:47,538 Epoch[17] Batch [1350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119972,	
2017-06-27 14:14:52,804 Epoch[17] Batch [1360]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.119910,	
2017-06-27 14:14:58,096 Epoch[17] Batch [1370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.119891,	
2017-06-27 14:15:03,476 Epoch[17] Batch [1380]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.120126,	
2017-06-27 14:15:08,759 Epoch[17] Batch [1390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.120346,	
2017-06-27 14:15:14,295 Epoch[17] Batch [1400]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.120338,	
2017-06-27 14:15:19,502 Epoch[17] Batch [1410]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.120352,	
2017-06-27 14:15:25,051 Epoch[17] Batch [1420]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.120287,	
2017-06-27 14:15:30,369 Epoch[17] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.120254,	
2017-06-27 14:15:36,439 Epoch[17] Batch [1440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.120202,	
2017-06-27 14:15:41,777 Epoch[17] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.120215,	
2017-06-27 14:15:47,130 Epoch[17] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.120207,	
2017-06-27 14:15:52,748 Epoch[17] Batch [1470]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.120102,	
2017-06-27 14:15:57,931 Epoch[17] Batch [1480]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120133,	
2017-06-27 14:16:01,076 Epoch[17] Train-FCNLogLoss=0.120119
2017-06-27 14:16:01,076 Epoch[17] Time cost=995.846
2017-06-27 14:16:02,033 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0018.params"
2017-06-27 14:16:03,892 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0018.states"
2017-06-27 14:16:09,731 Epoch[18] Batch [10]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.115721,	
2017-06-27 14:16:15,107 Epoch[18] Batch [20]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.126523,	
2017-06-27 14:16:20,172 Epoch[18] Batch [30]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.119508,	
2017-06-27 14:16:25,315 Epoch[18] Batch [40]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.120165,	
2017-06-27 14:16:30,695 Epoch[18] Batch [50]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.119946,	
2017-06-27 14:16:36,127 Epoch[18] Batch [60]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.118681,	
2017-06-27 14:16:41,517 Epoch[18] Batch [70]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.118009,	
2017-06-27 14:16:46,878 Epoch[18] Batch [80]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116976,	
2017-06-27 14:16:52,234 Epoch[18] Batch [90]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117316,	
2017-06-27 14:16:57,830 Epoch[18] Batch [100]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.117146,	
2017-06-27 14:17:03,213 Epoch[18] Batch [110]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.116884,	
2017-06-27 14:17:08,572 Epoch[18] Batch [120]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116579,	
2017-06-27 14:17:13,750 Epoch[18] Batch [130]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.117015,	
2017-06-27 14:17:19,141 Epoch[18] Batch [140]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.116315,	
2017-06-27 14:17:24,424 Epoch[18] Batch [150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116050,	
2017-06-27 14:17:29,601 Epoch[18] Batch [160]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.115302,	
2017-06-27 14:17:34,711 Epoch[18] Batch [170]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.114616,	
2017-06-27 14:17:39,706 Epoch[18] Batch [180]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.114687,	
2017-06-27 14:17:45,112 Epoch[18] Batch [190]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.114773,	
2017-06-27 14:17:50,364 Epoch[18] Batch [200]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.114646,	
2017-06-27 14:17:55,543 Epoch[18] Batch [210]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.114460,	
2017-06-27 14:18:00,955 Epoch[18] Batch [220]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.114374,	
2017-06-27 14:18:06,399 Epoch[18] Batch [230]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.114029,	
2017-06-27 14:18:11,560 Epoch[18] Batch [240]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.113754,	
2017-06-27 14:18:16,705 Epoch[18] Batch [250]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.113863,	
2017-06-27 14:18:22,015 Epoch[18] Batch [260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113829,	
2017-06-27 14:18:27,436 Epoch[18] Batch [270]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.113587,	
2017-06-27 14:18:32,689 Epoch[18] Batch [280]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.113953,	
2017-06-27 14:18:37,737 Epoch[18] Batch [290]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.114050,	
2017-06-27 14:18:42,882 Epoch[18] Batch [300]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.114371,	
2017-06-27 14:18:48,207 Epoch[18] Batch [310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114113,	
2017-06-27 14:18:53,270 Epoch[18] Batch [320]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.114345,	
2017-06-27 14:18:57,987 Epoch[18] Batch [330]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.114929,	
2017-06-27 14:19:03,022 Epoch[18] Batch [340]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.116332,	
2017-06-27 14:19:08,227 Epoch[18] Batch [350]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.117684,	
2017-06-27 14:19:13,636 Epoch[18] Batch [360]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.118027,	
2017-06-27 14:19:18,969 Epoch[18] Batch [370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117820,	
2017-06-27 14:19:24,465 Epoch[18] Batch [380]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.117903,	
2017-06-27 14:19:29,743 Epoch[18] Batch [390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.118109,	
2017-06-27 14:19:35,091 Epoch[18] Batch [400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118058,	
2017-06-27 14:19:40,425 Epoch[18] Batch [410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118434,	
2017-06-27 14:19:45,594 Epoch[18] Batch [420]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.118324,	
2017-06-27 14:19:50,916 Epoch[18] Batch [430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118419,	
2017-06-27 14:19:56,122 Epoch[18] Batch [440]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.118285,	
2017-06-27 14:20:01,299 Epoch[18] Batch [450]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.118148,	
2017-06-27 14:20:06,573 Epoch[18] Batch [460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.118076,	
2017-06-27 14:20:11,717 Epoch[18] Batch [470]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.118164,	
2017-06-27 14:20:16,867 Epoch[18] Batch [480]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.117969,	
2017-06-27 14:20:22,030 Epoch[18] Batch [490]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.117912,	
2017-06-27 14:20:27,166 Epoch[18] Batch [500]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.117715,	
2017-06-27 14:20:32,336 Epoch[18] Batch [510]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.117512,	
2017-06-27 14:20:38,087 Epoch[18] Batch [520]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.117491,	
2017-06-27 14:20:43,363 Epoch[18] Batch [530]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.117589,	
2017-06-27 14:20:48,726 Epoch[18] Batch [540]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117609,	
2017-06-27 14:20:53,878 Epoch[18] Batch [550]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.117773,	
2017-06-27 14:20:58,774 Epoch[18] Batch [560]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.117723,	
2017-06-27 14:21:03,865 Epoch[18] Batch [570]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.117832,	
2017-06-27 14:21:09,181 Epoch[18] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117520,	
2017-06-27 14:21:14,607 Epoch[18] Batch [590]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.117484,	
2017-06-27 14:21:19,973 Epoch[18] Batch [600]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117726,	
2017-06-27 14:21:25,567 Epoch[18] Batch [610]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.117933,	
2017-06-27 14:21:30,969 Epoch[18] Batch [620]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.117781,	
2017-06-27 14:21:36,102 Epoch[18] Batch [630]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.117554,	
2017-06-27 14:21:41,482 Epoch[18] Batch [640]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117549,	
2017-06-27 14:21:46,838 Epoch[18] Batch [650]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117647,	
2017-06-27 14:21:52,189 Epoch[18] Batch [660]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117721,	
2017-06-27 14:21:57,567 Epoch[18] Batch [670]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117478,	
2017-06-27 14:22:02,941 Epoch[18] Batch [680]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117597,	
2017-06-27 14:22:08,320 Epoch[18] Batch [690]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117585,	
2017-06-27 14:22:13,635 Epoch[18] Batch [700]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117561,	
2017-06-27 14:22:18,999 Epoch[18] Batch [710]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117323,	
2017-06-27 14:22:24,354 Epoch[18] Batch [720]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117214,	
2017-06-27 14:22:29,334 Epoch[18] Batch [730]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.117226,	
2017-06-27 14:22:34,559 Epoch[18] Batch [740]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.117148,	
2017-06-27 14:22:39,896 Epoch[18] Batch [750]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117068,	
2017-06-27 14:22:44,926 Epoch[18] Batch [760]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.117059,	
2017-06-27 14:22:50,234 Epoch[18] Batch [770]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117055,	
2017-06-27 14:22:55,470 Epoch[18] Batch [780]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.117003,	
2017-06-27 14:23:00,835 Epoch[18] Batch [790]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117097,	
2017-06-27 14:23:06,084 Epoch[18] Batch [800]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.116996,	
2017-06-27 14:23:11,455 Epoch[18] Batch [810]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116936,	
2017-06-27 14:23:16,865 Epoch[18] Batch [820]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.116966,	
2017-06-27 14:23:22,276 Epoch[18] Batch [830]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.116814,	
2017-06-27 14:23:27,666 Epoch[18] Batch [840]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.116800,	
2017-06-27 14:23:33,051 Epoch[18] Batch [850]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.116771,	
2017-06-27 14:23:38,380 Epoch[18] Batch [860]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116927,	
2017-06-27 14:23:43,767 Epoch[18] Batch [870]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.116941,	
2017-06-27 14:23:49,128 Epoch[18] Batch [880]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117033,	
2017-06-27 14:23:54,558 Epoch[18] Batch [890]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.116948,	
2017-06-27 14:23:59,945 Epoch[18] Batch [900]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.116848,	
2017-06-27 14:24:05,336 Epoch[18] Batch [910]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.116941,	
2017-06-27 14:24:10,772 Epoch[18] Batch [920]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.116956,	
2017-06-27 14:24:16,155 Epoch[18] Batch [930]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.116987,	
2017-06-27 14:24:21,624 Epoch[18] Batch [940]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.117124,	
2017-06-27 14:24:26,993 Epoch[18] Batch [950]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117156,	
2017-06-27 14:24:32,352 Epoch[18] Batch [960]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117298,	
2017-06-27 14:24:37,787 Epoch[18] Batch [970]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.117482,	
2017-06-27 14:24:43,187 Epoch[18] Batch [980]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.117522,	
2017-06-27 14:24:48,576 Epoch[18] Batch [990]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117419,	
2017-06-27 14:24:53,950 Epoch[18] Batch [1000]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117319,	
2017-06-27 14:24:59,317 Epoch[18] Batch [1010]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117287,	
2017-06-27 14:25:04,732 Epoch[18] Batch [1020]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.117164,	
2017-06-27 14:25:10,139 Epoch[18] Batch [1030]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.117188,	
2017-06-27 14:25:15,493 Epoch[18] Batch [1040]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117286,	
2017-06-27 14:25:20,939 Epoch[18] Batch [1050]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.117264,	
2017-06-27 14:25:26,364 Epoch[18] Batch [1060]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.117229,	
2017-06-27 14:25:31,737 Epoch[18] Batch [1070]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117074,	
2017-06-27 14:25:37,105 Epoch[18] Batch [1080]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117091,	
2017-06-27 14:25:42,494 Epoch[18] Batch [1090]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117061,	
2017-06-27 14:25:47,868 Epoch[18] Batch [1100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117049,	
2017-06-27 14:25:53,238 Epoch[18] Batch [1110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117060,	
2017-06-27 14:25:58,650 Epoch[18] Batch [1120]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.117002,	
2017-06-27 14:26:03,974 Epoch[18] Batch [1130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116915,	
2017-06-27 14:26:09,367 Epoch[18] Batch [1140]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117173,	
2017-06-27 14:26:14,768 Epoch[18] Batch [1150]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.117267,	
2017-06-27 14:26:20,126 Epoch[18] Batch [1160]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117240,	
2017-06-27 14:26:24,783 Epoch[18] Batch [1170]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.117184,	
2017-06-27 14:26:29,304 Epoch[18] Batch [1180]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.117187,	
2017-06-27 14:26:34,638 Epoch[18] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117176,	
2017-06-27 14:26:39,974 Epoch[18] Batch [1200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117251,	
2017-06-27 14:26:45,338 Epoch[18] Batch [1210]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117377,	
2017-06-27 14:26:50,679 Epoch[18] Batch [1220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117509,	
2017-06-27 14:26:56,072 Epoch[18] Batch [1230]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117660,	
2017-06-27 14:27:01,502 Epoch[18] Batch [1240]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.117835,	
2017-06-27 14:27:06,774 Epoch[18] Batch [1250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.117924,	
2017-06-27 14:27:12,171 Epoch[18] Batch [1260]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.118035,	
2017-06-27 14:27:17,529 Epoch[18] Batch [1270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118131,	
2017-06-27 14:27:22,864 Epoch[18] Batch [1280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118260,	
2017-06-27 14:27:28,194 Epoch[18] Batch [1290]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118238,	
2017-06-27 14:27:33,548 Epoch[18] Batch [1300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118201,	
2017-06-27 14:27:38,919 Epoch[18] Batch [1310]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118205,	
2017-06-27 14:27:44,238 Epoch[18] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118173,	
2017-06-27 14:27:49,592 Epoch[18] Batch [1330]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118030,	
2017-06-27 14:27:54,967 Epoch[18] Batch [1340]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118008,	
2017-06-27 14:28:00,317 Epoch[18] Batch [1350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118073,	
2017-06-27 14:28:05,652 Epoch[18] Batch [1360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118161,	
2017-06-27 14:28:10,987 Epoch[18] Batch [1370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118191,	
2017-06-27 14:28:16,181 Epoch[18] Batch [1380]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.118231,	
2017-06-27 14:28:21,524 Epoch[18] Batch [1390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118183,	
2017-06-27 14:28:26,795 Epoch[18] Batch [1400]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118112,	
2017-06-27 14:28:32,255 Epoch[18] Batch [1410]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.118179,	
2017-06-27 14:28:37,786 Epoch[18] Batch [1420]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.118156,	
2017-06-27 14:28:43,100 Epoch[18] Batch [1430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118055,	
2017-06-27 14:28:48,619 Epoch[18] Batch [1440]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.118059,	
2017-06-27 14:28:54,704 Epoch[18] Batch [1450]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.118097,	
2017-06-27 14:29:00,331 Epoch[18] Batch [1460]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.118002,	
2017-06-27 14:29:05,723 Epoch[18] Batch [1470]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117899,	
2017-06-27 14:29:11,097 Epoch[18] Batch [1480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117873,	
2017-06-27 14:29:14,488 Epoch[18] Train-FCNLogLoss=0.117856
2017-06-27 14:29:14,488 Epoch[18] Time cost=790.596
2017-06-27 14:29:15,332 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0019.params"
2017-06-27 14:29:17,043 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0019.states"
2017-06-27 14:29:23,127 Epoch[19] Batch [10]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.111939,	
2017-06-27 14:29:28,656 Epoch[19] Batch [20]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.106733,	
2017-06-27 14:29:34,658 Epoch[19] Batch [30]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.104445,	
2017-06-27 14:29:40,461 Epoch[19] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107482,	
2017-06-27 14:29:46,056 Epoch[19] Batch [50]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.105584,	
2017-06-27 14:29:51,619 Epoch[19] Batch [60]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.106244,	
2017-06-27 14:29:57,029 Epoch[19] Batch [70]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.108768,	
2017-06-27 14:30:02,707 Epoch[19] Batch [80]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.110687,	
2017-06-27 14:30:08,381 Epoch[19] Batch [90]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.112020,	
2017-06-27 14:30:13,984 Epoch[19] Batch [100]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.114305,	
2017-06-27 14:30:19,602 Epoch[19] Batch [110]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.114054,	
2017-06-27 14:30:25,259 Epoch[19] Batch [120]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.114611,	
2017-06-27 14:30:30,707 Epoch[19] Batch [130]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.115264,	
2017-06-27 14:30:36,238 Epoch[19] Batch [140]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.115976,	
2017-06-27 14:30:41,888 Epoch[19] Batch [150]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.115855,	
2017-06-27 14:30:47,928 Epoch[19] Batch [160]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.115716,	
2017-06-27 14:30:53,656 Epoch[19] Batch [170]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.115283,	
2017-06-27 14:30:59,309 Epoch[19] Batch [180]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.115680,	
2017-06-27 14:31:05,139 Epoch[19] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116062,	
2017-06-27 14:31:10,649 Epoch[19] Batch [200]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.115729,	
2017-06-27 14:31:16,504 Epoch[19] Batch [210]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.115534,	
2017-06-27 14:31:22,257 Epoch[19] Batch [220]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116033,	
2017-06-27 14:31:28,132 Epoch[19] Batch [230]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.116079,	
2017-06-27 14:31:33,845 Epoch[19] Batch [240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.115625,	
2017-06-27 14:31:39,822 Epoch[19] Batch [250]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.115262,	
2017-06-27 14:31:45,533 Epoch[19] Batch [260]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.115261,	
2017-06-27 14:31:51,451 Epoch[19] Batch [270]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.115165,	
2017-06-27 14:31:57,573 Epoch[19] Batch [280]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.115374,	
2017-06-27 14:32:03,126 Epoch[19] Batch [290]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.114962,	
2017-06-27 14:32:08,848 Epoch[19] Batch [300]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.114773,	
2017-06-27 14:32:14,294 Epoch[19] Batch [310]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.114609,	
2017-06-27 14:32:20,002 Epoch[19] Batch [320]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.114041,	
2017-06-27 14:32:26,223 Epoch[19] Batch [330]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.113753,	
2017-06-27 14:32:31,781 Epoch[19] Batch [340]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.113478,	
2017-06-27 14:32:37,084 Epoch[19] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113289,	
2017-06-27 14:32:43,089 Epoch[19] Batch [360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.113334,	
2017-06-27 14:32:48,963 Epoch[19] Batch [370]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.112727,	
2017-06-27 14:32:54,743 Epoch[19] Batch [380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112534,	
2017-06-27 14:33:00,625 Epoch[19] Batch [390]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.112600,	
2017-06-27 14:33:06,494 Epoch[19] Batch [400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.112768,	
2017-06-27 14:33:12,335 Epoch[19] Batch [410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.112660,	
2017-06-27 14:33:18,047 Epoch[19] Batch [420]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.112517,	
2017-06-27 14:33:23,904 Epoch[19] Batch [430]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.112176,	
2017-06-27 14:33:29,590 Epoch[19] Batch [440]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.112203,	
2017-06-27 14:33:35,518 Epoch[19] Batch [450]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.112022,	
2017-06-27 14:33:41,207 Epoch[19] Batch [460]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.112404,	
2017-06-27 14:33:46,987 Epoch[19] Batch [470]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112399,	
2017-06-27 14:33:52,996 Epoch[19] Batch [480]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.112483,	
2017-06-27 14:33:58,754 Epoch[19] Batch [490]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.112154,	
2017-06-27 14:34:04,636 Epoch[19] Batch [500]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.112744,	
2017-06-27 14:34:10,562 Epoch[19] Batch [510]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.113157,	
2017-06-27 14:34:16,278 Epoch[19] Batch [520]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.113162,	
2017-06-27 14:34:21,746 Epoch[19] Batch [530]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.113119,	
2017-06-27 14:34:27,735 Epoch[19] Batch [540]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113158,	
2017-06-27 14:34:33,653 Epoch[19] Batch [550]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.113139,	
2017-06-27 14:34:39,483 Epoch[19] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113195,	
2017-06-27 14:34:45,204 Epoch[19] Batch [570]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.113277,	
2017-06-27 14:34:50,693 Epoch[19] Batch [580]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.113172,	
2017-06-27 14:34:56,653 Epoch[19] Batch [590]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.113300,	
2017-06-27 14:35:02,220 Epoch[19] Batch [600]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.113514,	
2017-06-27 14:35:07,714 Epoch[19] Batch [610]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.113346,	
2017-06-27 14:35:13,510 Epoch[19] Batch [620]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113547,	
2017-06-27 14:35:19,487 Epoch[19] Batch [630]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.113433,	
2017-06-27 14:35:25,089 Epoch[19] Batch [640]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.113451,	
2017-06-27 14:35:30,951 Epoch[19] Batch [650]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113524,	
2017-06-27 14:35:36,665 Epoch[19] Batch [660]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.113853,	
2017-06-27 14:35:42,205 Epoch[19] Batch [670]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.113742,	
2017-06-27 14:35:47,832 Epoch[19] Batch [680]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.113739,	
2017-06-27 14:35:53,538 Epoch[19] Batch [690]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.113589,	
2017-06-27 14:35:59,318 Epoch[19] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113664,	
2017-06-27 14:36:04,953 Epoch[19] Batch [710]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.113710,	
2017-06-27 14:36:11,069 Epoch[19] Batch [720]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.113573,	
2017-06-27 14:36:17,055 Epoch[19] Batch [730]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113558,	
2017-06-27 14:36:22,780 Epoch[19] Batch [740]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.113857,	
2017-06-27 14:36:28,404 Epoch[19] Batch [750]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.113919,	
2017-06-27 14:36:34,063 Epoch[19] Batch [760]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.113988,	
2017-06-27 14:36:39,803 Epoch[19] Batch [770]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.113800,	
2017-06-27 14:36:45,564 Epoch[19] Batch [780]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113845,	
2017-06-27 14:36:51,551 Epoch[19] Batch [790]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113801,	
2017-06-27 14:36:57,131 Epoch[19] Batch [800]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.113832,	
2017-06-27 14:37:02,661 Epoch[19] Batch [810]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.113829,	
2017-06-27 14:37:08,167 Epoch[19] Batch [820]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.113857,	
2017-06-27 14:37:14,339 Epoch[19] Batch [830]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.113902,	
2017-06-27 14:37:20,459 Epoch[19] Batch [840]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.115132,	
2017-06-27 14:37:26,651 Epoch[19] Batch [850]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.116956,	
2017-06-27 14:37:32,271 Epoch[19] Batch [860]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.117653,	
2017-06-27 14:37:40,957 Epoch[19] Batch [870]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.118190,	
2017-06-27 14:37:48,785 Epoch[19] Batch [880]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.118553,	
2017-06-27 14:38:00,039 Epoch[19] Batch [890]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.118826,	
2017-06-27 14:38:11,115 Epoch[19] Batch [900]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.119020,	
2017-06-27 14:38:22,655 Epoch[19] Batch [910]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.119212,	
2017-06-27 14:38:32,949 Epoch[19] Batch [920]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.119521,	
2017-06-27 14:38:42,635 Epoch[19] Batch [930]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.119651,	
2017-06-27 14:38:54,852 Epoch[19] Batch [940]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.119841,	
2017-06-27 14:39:07,385 Epoch[19] Batch [950]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.119901,	
2017-06-27 14:39:18,492 Epoch[19] Batch [960]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.120063,	
2017-06-27 14:39:28,957 Epoch[19] Batch [970]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.120218,	
2017-06-27 14:39:34,594 Epoch[19] Batch [980]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.120152,	
2017-06-27 14:39:40,104 Epoch[19] Batch [990]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.120322,	
2017-06-27 14:39:45,750 Epoch[19] Batch [1000]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.120464,	
2017-06-27 14:39:51,415 Epoch[19] Batch [1010]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.120799,	
2017-06-27 14:39:56,960 Epoch[19] Batch [1020]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.120829,	
2017-06-27 14:40:02,781 Epoch[19] Batch [1030]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121095,	
2017-06-27 14:40:08,331 Epoch[19] Batch [1040]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.121213,	
2017-06-27 14:40:14,016 Epoch[19] Batch [1050]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.121347,	
2017-06-27 14:40:19,580 Epoch[19] Batch [1060]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.121237,	
2017-06-27 14:40:25,672 Epoch[19] Batch [1070]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.121331,	
2017-06-27 14:40:31,543 Epoch[19] Batch [1080]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.121308,	
2017-06-27 14:40:37,432 Epoch[19] Batch [1090]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.121321,	
2017-06-27 14:40:42,882 Epoch[19] Batch [1100]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.121384,	
2017-06-27 14:40:48,823 Epoch[19] Batch [1110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.121363,	
2017-06-27 14:40:54,556 Epoch[19] Batch [1120]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.121456,	
2017-06-27 14:41:00,229 Epoch[19] Batch [1130]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.121598,	
2017-06-27 14:41:06,062 Epoch[19] Batch [1140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121589,	
2017-06-27 14:41:11,784 Epoch[19] Batch [1150]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.121637,	
2017-06-27 14:41:17,660 Epoch[19] Batch [1160]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.121624,	
2017-06-27 14:41:23,317 Epoch[19] Batch [1170]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.121572,	
2017-06-27 14:41:29,244 Epoch[19] Batch [1180]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.121474,	
2017-06-27 14:41:34,930 Epoch[19] Batch [1190]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.121553,	
2017-06-27 14:41:40,671 Epoch[19] Batch [1200]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.121672,	
2017-06-27 14:41:46,325 Epoch[19] Batch [1210]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.122029,	
2017-06-27 14:41:52,044 Epoch[19] Batch [1220]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.122187,	
2017-06-27 14:41:57,742 Epoch[19] Batch [1230]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.122279,	
2017-06-27 14:42:03,526 Epoch[19] Batch [1240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.122253,	
2017-06-27 14:42:09,173 Epoch[19] Batch [1250]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.122241,	
2017-06-27 14:42:14,984 Epoch[19] Batch [1260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122407,	
2017-06-27 14:42:20,447 Epoch[19] Batch [1270]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.122468,	
2017-06-27 14:42:26,453 Epoch[19] Batch [1280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.122358,	
2017-06-27 14:42:31,852 Epoch[19] Batch [1290]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.122253,	
2017-06-27 14:42:37,545 Epoch[19] Batch [1300]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.122251,	
2017-06-27 14:42:43,551 Epoch[19] Batch [1310]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.122167,	
2017-06-27 14:42:49,055 Epoch[19] Batch [1320]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.122061,	
2017-06-27 14:42:54,519 Epoch[19] Batch [1330]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.122018,	
2017-06-27 14:43:00,344 Epoch[19] Batch [1340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121978,	
2017-06-27 14:43:06,189 Epoch[19] Batch [1350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.121930,	
2017-06-27 14:43:11,860 Epoch[19] Batch [1360]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.121965,	
2017-06-27 14:43:18,066 Epoch[19] Batch [1370]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.121961,	
2017-06-27 14:43:23,837 Epoch[19] Batch [1380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121960,	
2017-06-27 14:43:29,722 Epoch[19] Batch [1390]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.121843,	
2017-06-27 14:43:35,532 Epoch[19] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121843,	
2017-06-27 14:43:41,150 Epoch[19] Batch [1410]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.121780,	
2017-06-27 14:43:46,728 Epoch[19] Batch [1420]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.121775,	
2017-06-27 14:43:52,383 Epoch[19] Batch [1430]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.121669,	
2017-06-27 14:43:58,093 Epoch[19] Batch [1440]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.121649,	
2017-06-27 14:44:03,692 Epoch[19] Batch [1450]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.121669,	
2017-06-27 14:44:09,551 Epoch[19] Batch [1460]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121588,	
2017-06-27 14:44:15,093 Epoch[19] Batch [1470]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.121526,	
2017-06-27 14:44:20,834 Epoch[19] Batch [1480]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.121501,	
2017-06-27 14:44:24,222 Epoch[19] Train-FCNLogLoss=0.121473
2017-06-27 14:44:24,222 Epoch[19] Time cost=907.178
2017-06-27 14:44:25,094 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0020.params"
2017-06-27 14:44:26,971 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0020.states"
2017-06-27 14:44:33,638 Epoch[20] Batch [10]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124361,	
2017-06-27 14:44:39,368 Epoch[20] Batch [20]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.115595,	
2017-06-27 14:44:45,038 Epoch[20] Batch [30]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.112973,	
2017-06-27 14:44:50,724 Epoch[20] Batch [40]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.114526,	
2017-06-27 14:44:56,473 Epoch[20] Batch [50]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.113444,	
2017-06-27 14:45:02,095 Epoch[20] Batch [60]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.111548,	
2017-06-27 14:45:07,513 Epoch[20] Batch [70]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.111653,	
2017-06-27 14:45:12,978 Epoch[20] Batch [80]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.111706,	
2017-06-27 14:45:18,692 Epoch[20] Batch [90]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.110779,	
2017-06-27 14:45:24,277 Epoch[20] Batch [100]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.111674,	
2017-06-27 14:45:29,732 Epoch[20] Batch [110]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.111144,	
2017-06-27 14:45:35,262 Epoch[20] Batch [120]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.110857,	
2017-06-27 14:45:40,642 Epoch[20] Batch [130]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.111007,	
2017-06-27 14:45:46,077 Epoch[20] Batch [140]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.110783,	
2017-06-27 14:45:52,099 Epoch[20] Batch [150]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.110550,	
2017-06-27 14:45:57,721 Epoch[20] Batch [160]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.112016,	
2017-06-27 14:46:03,298 Epoch[20] Batch [170]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.112554,	
2017-06-27 14:46:08,878 Epoch[20] Batch [180]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.113560,	
2017-06-27 14:46:14,468 Epoch[20] Batch [190]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.114468,	
2017-06-27 14:46:20,274 Epoch[20] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114944,	
2017-06-27 14:46:25,950 Epoch[20] Batch [210]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.114831,	
2017-06-27 14:46:31,531 Epoch[20] Batch [220]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.115085,	
2017-06-27 14:46:37,242 Epoch[20] Batch [230]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.115797,	
2017-06-27 14:46:43,461 Epoch[20] Batch [240]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.116880,	
2017-06-27 14:46:49,196 Epoch[20] Batch [250]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.117725,	
2017-06-27 14:46:54,887 Epoch[20] Batch [260]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.117406,	
2017-06-27 14:47:00,667 Epoch[20] Batch [270]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118098,	
2017-06-27 14:47:06,513 Epoch[20] Batch [280]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.118398,	
2017-06-27 14:47:12,245 Epoch[20] Batch [290]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.118667,	
2017-06-27 14:47:18,043 Epoch[20] Batch [300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119232,	
2017-06-27 14:47:23,841 Epoch[20] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119162,	
2017-06-27 14:47:30,079 Epoch[20] Batch [320]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.119446,	
2017-06-27 14:47:36,024 Epoch[20] Batch [330]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.119195,	
2017-06-27 14:47:41,987 Epoch[20] Batch [340]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.119255,	
2017-06-27 14:47:54,815 Epoch[20] Batch [350]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.119717,	
2017-06-27 14:48:05,820 Epoch[20] Batch [360]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.119524,	
2017-06-27 14:48:11,718 Epoch[20] Batch [370]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.119870,	
2017-06-27 14:48:17,493 Epoch[20] Batch [380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119397,	
2017-06-27 14:48:23,251 Epoch[20] Batch [390]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.119149,	
2017-06-27 14:48:29,346 Epoch[20] Batch [400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.119401,	
2017-06-27 14:48:34,884 Epoch[20] Batch [410]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.119128,	
2017-06-27 14:48:40,667 Epoch[20] Batch [420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.119493,	
2017-06-27 14:48:46,423 Epoch[20] Batch [430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.119601,	
2017-06-27 14:48:52,036 Epoch[20] Batch [440]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.119427,	
2017-06-27 14:48:57,677 Epoch[20] Batch [450]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.119460,	
2017-06-27 14:49:03,356 Epoch[20] Batch [460]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.119265,	
2017-06-27 14:49:09,391 Epoch[20] Batch [470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.119611,	
2017-06-27 14:49:15,035 Epoch[20] Batch [480]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.119439,	
2017-06-27 14:49:20,698 Epoch[20] Batch [490]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.119445,	
2017-06-27 14:49:27,024 Epoch[20] Batch [500]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.119475,	
2017-06-27 14:49:33,445 Epoch[20] Batch [510]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.119579,	
2017-06-27 14:49:39,107 Epoch[20] Batch [520]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.119636,	
2017-06-27 14:49:44,799 Epoch[20] Batch [530]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.119760,	
2017-06-27 14:49:50,815 Epoch[20] Batch [540]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.119606,	
2017-06-27 14:49:56,727 Epoch[20] Batch [550]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.119525,	
2017-06-27 14:50:02,277 Epoch[20] Batch [560]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.119257,	
2017-06-27 14:50:08,208 Epoch[20] Batch [570]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.119401,	
2017-06-27 14:50:14,065 Epoch[20] Batch [580]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.119195,	
2017-06-27 14:50:19,679 Epoch[20] Batch [590]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.118936,	
2017-06-27 14:50:25,343 Epoch[20] Batch [600]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.118918,	
2017-06-27 14:50:31,128 Epoch[20] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118775,	
2017-06-27 14:50:37,343 Epoch[20] Batch [620]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.118692,	
2017-06-27 14:50:43,061 Epoch[20] Batch [630]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.118282,	
2017-06-27 14:50:51,558 Epoch[20] Batch [640]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.118297,	
2017-06-27 14:51:08,337 Epoch[20] Batch [650]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.118229,	
2017-06-27 14:51:14,475 Epoch[20] Batch [660]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.118064,	
2017-06-27 14:51:20,244 Epoch[20] Batch [670]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117822,	
2017-06-27 14:51:25,827 Epoch[20] Batch [680]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.117570,	
2017-06-27 14:51:31,899 Epoch[20] Batch [690]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.117438,	
2017-06-27 14:51:37,611 Epoch[20] Batch [700]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.117674,	
2017-06-27 14:51:42,936 Epoch[20] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117830,	
2017-06-27 14:51:48,182 Epoch[20] Batch [720]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.117699,	
2017-06-27 14:51:53,414 Epoch[20] Batch [730]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.117601,	
2017-06-27 14:51:58,644 Epoch[20] Batch [740]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.117388,	
2017-06-27 14:52:03,914 Epoch[20] Batch [750]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.117275,	
2017-06-27 14:52:09,121 Epoch[20] Batch [760]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.117300,	
2017-06-27 14:52:15,124 Epoch[20] Batch [770]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.117270,	
2017-06-27 14:52:20,324 Epoch[20] Batch [780]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.117030,	
2017-06-27 14:52:25,609 Epoch[20] Batch [790]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.117056,	
2017-06-27 14:52:30,926 Epoch[20] Batch [800]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.117026,	
2017-06-27 14:52:36,081 Epoch[20] Batch [810]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.117801,	
2017-06-27 14:52:41,330 Epoch[20] Batch [820]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.118574,	
2017-06-27 14:52:46,598 Epoch[20] Batch [830]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119112,	
2017-06-27 14:52:51,892 Epoch[20] Batch [840]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.119810,	
2017-06-27 14:52:57,118 Epoch[20] Batch [850]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.119861,	
2017-06-27 14:53:02,363 Epoch[20] Batch [860]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120019,	
2017-06-27 14:53:07,599 Epoch[20] Batch [870]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.120078,	
2017-06-27 14:53:12,857 Epoch[20] Batch [880]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.120116,	
2017-06-27 14:53:18,097 Epoch[20] Batch [890]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120210,	
2017-06-27 14:53:23,338 Epoch[20] Batch [900]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120200,	
2017-06-27 14:53:28,662 Epoch[20] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120148,	
2017-06-27 14:53:33,876 Epoch[20] Batch [920]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.120175,	
2017-06-27 14:53:38,313 Epoch[20] Batch [930]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.120176,	
2017-06-27 14:53:43,528 Epoch[20] Batch [940]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.120239,	
2017-06-27 14:53:48,790 Epoch[20] Batch [950]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.120300,	
2017-06-27 14:53:54,087 Epoch[20] Batch [960]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.120365,	
2017-06-27 14:53:59,259 Epoch[20] Batch [970]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.120263,	
2017-06-27 14:54:04,491 Epoch[20] Batch [980]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.120084,	
2017-06-27 14:54:09,739 Epoch[20] Batch [990]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.119975,	
2017-06-27 14:54:15,026 Epoch[20] Batch [1000]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.119821,	
2017-06-27 14:54:20,296 Epoch[20] Batch [1010]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119643,	
2017-06-27 14:54:25,573 Epoch[20] Batch [1020]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119486,	
2017-06-27 14:54:30,842 Epoch[20] Batch [1030]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119515,	
2017-06-27 14:54:36,083 Epoch[20] Batch [1040]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.119699,	
2017-06-27 14:54:41,357 Epoch[20] Batch [1050]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119767,	
2017-06-27 14:54:46,595 Epoch[20] Batch [1060]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.119862,	
2017-06-27 14:54:51,857 Epoch[20] Batch [1070]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.119821,	
2017-06-27 14:54:57,123 Epoch[20] Batch [1080]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.119787,	
2017-06-27 14:55:02,521 Epoch[20] Batch [1090]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.119756,	
2017-06-27 14:55:07,769 Epoch[20] Batch [1100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.119693,	
2017-06-27 14:55:13,305 Epoch[20] Batch [1110]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.119666,	
2017-06-27 14:55:18,600 Epoch[20] Batch [1120]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.119598,	
2017-06-27 14:55:23,615 Epoch[20] Batch [1130]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.119566,	
2017-06-27 14:55:29,007 Epoch[20] Batch [1140]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119513,	
2017-06-27 14:55:34,382 Epoch[20] Batch [1150]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119417,	
2017-06-27 14:55:39,697 Epoch[20] Batch [1160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119477,	
2017-06-27 14:55:44,862 Epoch[20] Batch [1170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.119386,	
2017-06-27 14:55:50,458 Epoch[20] Batch [1180]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.119382,	
2017-06-27 14:55:55,571 Epoch[20] Batch [1190]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.119316,	
2017-06-27 14:56:00,809 Epoch[20] Batch [1200]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.119326,	
2017-06-27 14:56:06,153 Epoch[20] Batch [1210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119222,	
2017-06-27 14:56:11,454 Epoch[20] Batch [1220]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.119056,	
2017-06-27 14:56:16,746 Epoch[20] Batch [1230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.119034,	
2017-06-27 14:56:22,019 Epoch[20] Batch [1240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119030,	
2017-06-27 14:56:27,265 Epoch[20] Batch [1250]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.118992,	
2017-06-27 14:56:32,540 Epoch[20] Batch [1260]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119053,	
2017-06-27 14:56:37,813 Epoch[20] Batch [1270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118958,	
2017-06-27 14:56:43,049 Epoch[20] Batch [1280]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.118879,	
2017-06-27 14:56:48,316 Epoch[20] Batch [1290]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.118890,	
2017-06-27 14:56:53,578 Epoch[20] Batch [1300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.118859,	
2017-06-27 14:56:58,865 Epoch[20] Batch [1310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118797,	
2017-06-27 14:57:04,119 Epoch[20] Batch [1320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118787,	
2017-06-27 14:57:09,376 Epoch[20] Batch [1330]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118684,	
2017-06-27 14:57:14,630 Epoch[20] Batch [1340]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118812,	
2017-06-27 14:57:19,877 Epoch[20] Batch [1350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.118814,	
2017-06-27 14:57:25,146 Epoch[20] Batch [1360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118867,	
2017-06-27 14:57:30,415 Epoch[20] Batch [1370]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118937,	
2017-06-27 14:57:35,714 Epoch[20] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118834,	
2017-06-27 14:57:40,924 Epoch[20] Batch [1390]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.118740,	
2017-06-27 14:57:46,197 Epoch[20] Batch [1400]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118752,	
2017-06-27 14:57:51,431 Epoch[20] Batch [1410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.118698,	
2017-06-27 14:57:56,764 Epoch[20] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118620,	
2017-06-27 14:58:01,987 Epoch[20] Batch [1430]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.118594,	
2017-06-27 14:58:07,243 Epoch[20] Batch [1440]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118556,	
2017-06-27 14:58:12,493 Epoch[20] Batch [1450]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.118521,	
2017-06-27 14:58:17,749 Epoch[20] Batch [1460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118519,	
2017-06-27 14:58:23,019 Epoch[20] Batch [1470]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118436,	
2017-06-27 14:58:28,257 Epoch[20] Batch [1480]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.118262,	
2017-06-27 14:58:31,456 Epoch[20] Train-FCNLogLoss=0.118185
2017-06-27 14:58:31,457 Epoch[20] Time cost=844.485
2017-06-27 14:58:32,402 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0021.params"
2017-06-27 14:58:34,227 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0021.states"
2017-06-27 14:58:40,223 Epoch[21] Batch [10]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.114563,	
2017-06-27 14:58:45,486 Epoch[21] Batch [20]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112241,	
2017-06-27 14:58:50,754 Epoch[21] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.109408,	
2017-06-27 14:58:55,989 Epoch[21] Batch [40]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.113273,	
2017-06-27 14:59:01,246 Epoch[21] Batch [50]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112242,	
2017-06-27 14:59:06,487 Epoch[21] Batch [60]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111595,	
2017-06-27 14:59:11,732 Epoch[21] Batch [70]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111957,	
2017-06-27 14:59:16,996 Epoch[21] Batch [80]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111712,	
2017-06-27 14:59:22,232 Epoch[21] Batch [90]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112456,	
2017-06-27 14:59:30,205 Epoch[21] Batch [100]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.113533,	
2017-06-27 14:59:35,480 Epoch[21] Batch [110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.113332,	
2017-06-27 14:59:40,732 Epoch[21] Batch [120]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112745,	
2017-06-27 14:59:45,988 Epoch[21] Batch [130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112589,	
2017-06-27 14:59:51,221 Epoch[21] Batch [140]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112563,	
2017-06-27 14:59:56,518 Epoch[21] Batch [150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.112318,	
2017-06-27 15:00:01,727 Epoch[21] Batch [160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.113628,	
2017-06-27 15:00:06,999 Epoch[21] Batch [170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113697,	
2017-06-27 15:00:12,223 Epoch[21] Batch [180]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.113021,	
2017-06-27 15:00:17,444 Epoch[21] Batch [190]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112560,	
2017-06-27 15:00:22,733 Epoch[21] Batch [200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.112572,	
2017-06-27 15:00:27,990 Epoch[21] Batch [210]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112266,	
2017-06-27 15:00:33,225 Epoch[21] Batch [220]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112610,	
2017-06-27 15:00:38,463 Epoch[21] Batch [230]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112563,	
2017-06-27 15:00:43,716 Epoch[21] Batch [240]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112437,	
2017-06-27 15:00:48,976 Epoch[21] Batch [250]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112777,	
2017-06-27 15:00:54,227 Epoch[21] Batch [260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112578,	
2017-06-27 15:00:59,498 Epoch[21] Batch [270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113282,	
2017-06-27 15:01:04,727 Epoch[21] Batch [280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.113041,	
2017-06-27 15:01:10,001 Epoch[21] Batch [290]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.113004,	
2017-06-27 15:01:15,226 Epoch[21] Batch [300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.113119,	
2017-06-27 15:01:20,494 Epoch[21] Batch [310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112966,	
2017-06-27 15:01:25,764 Epoch[21] Batch [320]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112664,	
2017-06-27 15:01:31,007 Epoch[21] Batch [330]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112471,	
2017-06-27 15:01:36,259 Epoch[21] Batch [340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112745,	
2017-06-27 15:01:41,482 Epoch[21] Batch [350]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112737,	
2017-06-27 15:01:49,109 Epoch[21] Batch [360]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.113242,	
2017-06-27 15:01:57,620 Epoch[21] Batch [370]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.113576,	
2017-06-27 15:02:02,877 Epoch[21] Batch [380]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.113878,	
2017-06-27 15:02:08,140 Epoch[21] Batch [390]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.114073,	
2017-06-27 15:02:13,365 Epoch[21] Batch [400]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.114155,	
2017-06-27 15:02:20,735 Epoch[21] Batch [410]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.114102,	
2017-06-27 15:02:36,378 Epoch[21] Batch [420]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.114111,	
2017-06-27 15:02:45,886 Epoch[21] Batch [430]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.113886,	
2017-06-27 15:02:52,929 Epoch[21] Batch [440]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.114144,	
2017-06-27 15:02:58,107 Epoch[21] Batch [450]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.113750,	
2017-06-27 15:03:03,297 Epoch[21] Batch [460]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.113666,	
2017-06-27 15:03:08,537 Epoch[21] Batch [470]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.113627,	
2017-06-27 15:03:13,795 Epoch[21] Batch [480]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.113531,	
2017-06-27 15:03:18,996 Epoch[21] Batch [490]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.113464,	
2017-06-27 15:03:24,216 Epoch[21] Batch [500]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.113430,	
2017-06-27 15:03:29,473 Epoch[21] Batch [510]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.113202,	
2017-06-27 15:03:34,670 Epoch[21] Batch [520]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.113424,	
2017-06-27 15:03:39,912 Epoch[21] Batch [530]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.113573,	
2017-06-27 15:03:45,135 Epoch[21] Batch [540]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.113600,	
2017-06-27 15:03:50,402 Epoch[21] Batch [550]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.113655,	
2017-06-27 15:03:55,638 Epoch[21] Batch [560]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.113634,	
2017-06-27 15:04:00,903 Epoch[21] Batch [570]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.113450,	
2017-06-27 15:04:06,156 Epoch[21] Batch [580]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.113401,	
2017-06-27 15:04:11,426 Epoch[21] Batch [590]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113541,	
2017-06-27 15:04:16,667 Epoch[21] Batch [600]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.113449,	
2017-06-27 15:04:21,908 Epoch[21] Batch [610]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.113310,	
2017-06-27 15:04:27,145 Epoch[21] Batch [620]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.113233,	
2017-06-27 15:04:32,417 Epoch[21] Batch [630]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113265,	
2017-06-27 15:04:37,651 Epoch[21] Batch [640]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.113025,	
2017-06-27 15:04:42,903 Epoch[21] Batch [650]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112942,	
2017-06-27 15:04:48,153 Epoch[21] Batch [660]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112969,	
2017-06-27 15:04:53,438 Epoch[21] Batch [670]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.112901,	
2017-06-27 15:04:58,662 Epoch[21] Batch [680]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112785,	
2017-06-27 15:05:03,917 Epoch[21] Batch [690]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.113004,	
2017-06-27 15:05:09,214 Epoch[21] Batch [700]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.112854,	
2017-06-27 15:05:14,457 Epoch[21] Batch [710]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112929,	
2017-06-27 15:05:19,688 Epoch[21] Batch [720]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112722,	
2017-06-27 15:05:24,978 Epoch[21] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.112502,	
2017-06-27 15:05:30,209 Epoch[21] Batch [740]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112539,	
2017-06-27 15:05:35,480 Epoch[21] Batch [750]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112625,	
2017-06-27 15:05:40,762 Epoch[21] Batch [760]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.112621,	
2017-06-27 15:05:46,027 Epoch[21] Batch [770]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112645,	
2017-06-27 15:05:51,255 Epoch[21] Batch [780]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112506,	
2017-06-27 15:05:56,519 Epoch[21] Batch [790]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112424,	
2017-06-27 15:06:09,733 Epoch[21] Batch [800]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.112369,	
2017-06-27 15:06:21,901 Epoch[21] Batch [810]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.112406,	
2017-06-27 15:06:30,411 Epoch[21] Batch [820]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.112534,	
2017-06-27 15:06:36,561 Epoch[21] Batch [830]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.112480,	
2017-06-27 15:06:41,830 Epoch[21] Batch [840]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112329,	
2017-06-27 15:06:47,016 Epoch[21] Batch [850]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112406,	
2017-06-27 15:06:52,287 Epoch[21] Batch [860]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112458,	
2017-06-27 15:06:57,515 Epoch[21] Batch [870]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112342,	
2017-06-27 15:07:02,718 Epoch[21] Batch [880]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112249,	
2017-06-27 15:07:07,963 Epoch[21] Batch [890]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112320,	
2017-06-27 15:07:13,209 Epoch[21] Batch [900]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112201,	
2017-06-27 15:07:18,440 Epoch[21] Batch [910]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112238,	
2017-06-27 15:07:23,701 Epoch[21] Batch [920]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112170,	
2017-06-27 15:07:28,230 Epoch[21] Batch [930]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.112136,	
2017-06-27 15:07:33,201 Epoch[21] Batch [940]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.112193,	
2017-06-27 15:07:38,421 Epoch[21] Batch [950]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112251,	
2017-06-27 15:07:43,685 Epoch[21] Batch [960]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112101,	
2017-06-27 15:07:48,903 Epoch[21] Batch [970]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111914,	
2017-06-27 15:07:54,202 Epoch[21] Batch [980]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111956,	
2017-06-27 15:07:59,424 Epoch[21] Batch [990]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111951,	
2017-06-27 15:08:04,655 Epoch[21] Batch [1000]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111956,	
2017-06-27 15:08:09,900 Epoch[21] Batch [1010]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111940,	
2017-06-27 15:08:15,228 Epoch[21] Batch [1020]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.111856,	
2017-06-27 15:08:20,474 Epoch[21] Batch [1030]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111834,	
2017-06-27 15:08:25,677 Epoch[21] Batch [1040]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.111810,	
2017-06-27 15:08:30,959 Epoch[21] Batch [1050]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111773,	
2017-06-27 15:08:36,195 Epoch[21] Batch [1060]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111807,	
2017-06-27 15:08:41,453 Epoch[21] Batch [1070]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111810,	
2017-06-27 15:08:46,735 Epoch[21] Batch [1080]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111821,	
2017-06-27 15:08:51,951 Epoch[21] Batch [1090]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111804,	
2017-06-27 15:08:57,210 Epoch[21] Batch [1100]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111824,	
2017-06-27 15:09:02,464 Epoch[21] Batch [1110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111902,	
2017-06-27 15:09:07,730 Epoch[21] Batch [1120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111949,	
2017-06-27 15:09:13,009 Epoch[21] Batch [1130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111926,	
2017-06-27 15:09:18,269 Epoch[21] Batch [1140]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111914,	
2017-06-27 15:09:23,487 Epoch[21] Batch [1150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111843,	
2017-06-27 15:09:28,779 Epoch[21] Batch [1160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.111796,	
2017-06-27 15:09:34,005 Epoch[21] Batch [1170]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111743,	
2017-06-27 15:09:39,307 Epoch[21] Batch [1180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111651,	
2017-06-27 15:09:44,544 Epoch[21] Batch [1190]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111759,	
2017-06-27 15:09:49,809 Epoch[21] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111857,	
2017-06-27 15:09:55,029 Epoch[21] Batch [1210]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111897,	
2017-06-27 15:10:00,298 Epoch[21] Batch [1220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111825,	
2017-06-27 15:10:05,556 Epoch[21] Batch [1230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111829,	
2017-06-27 15:10:10,787 Epoch[21] Batch [1240]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111772,	
2017-06-27 15:10:16,082 Epoch[21] Batch [1250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111849,	
2017-06-27 15:10:21,304 Epoch[21] Batch [1260]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111804,	
2017-06-27 15:10:26,596 Epoch[21] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.111718,	
2017-06-27 15:10:31,839 Epoch[21] Batch [1280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111720,	
2017-06-27 15:10:37,082 Epoch[21] Batch [1290]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111670,	
2017-06-27 15:10:42,340 Epoch[21] Batch [1300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111633,	
2017-06-27 15:10:47,617 Epoch[21] Batch [1310]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111605,	
2017-06-27 15:10:52,812 Epoch[21] Batch [1320]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.111658,	
2017-06-27 15:10:58,158 Epoch[21] Batch [1330]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.111573,	
2017-06-27 15:11:03,370 Epoch[21] Batch [1340]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111587,	
2017-06-27 15:11:08,630 Epoch[21] Batch [1350]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111516,	
2017-06-27 15:11:13,928 Epoch[21] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111546,	
2017-06-27 15:11:19,156 Epoch[21] Batch [1370]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111583,	
2017-06-27 15:11:24,384 Epoch[21] Batch [1380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111525,	
2017-06-27 15:11:29,679 Epoch[21] Batch [1390]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111468,	
2017-06-27 15:11:34,920 Epoch[21] Batch [1400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111438,	
2017-06-27 15:11:40,197 Epoch[21] Batch [1410]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111493,	
2017-06-27 15:11:45,453 Epoch[21] Batch [1420]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111423,	
2017-06-27 15:11:50,721 Epoch[21] Batch [1430]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111448,	
2017-06-27 15:11:56,509 Epoch[21] Batch [1440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111462,	
2017-06-27 15:12:01,768 Epoch[21] Batch [1450]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111501,	
2017-06-27 15:12:09,557 Epoch[21] Batch [1460]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.111494,	
2017-06-27 15:12:16,526 Epoch[21] Batch [1470]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.111441,	
2017-06-27 15:12:21,792 Epoch[21] Batch [1480]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111474,	
2017-06-27 15:12:24,914 Epoch[21] Train-FCNLogLoss=0.111502
2017-06-27 15:12:24,914 Epoch[21] Time cost=830.686
2017-06-27 15:12:25,634 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0022.params"
2017-06-27 15:12:27,176 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0022.states"
2017-06-27 15:12:33,067 Epoch[22] Batch [10]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.120094,	
2017-06-27 15:12:38,295 Epoch[22] Batch [20]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.115631,	
2017-06-27 15:12:43,576 Epoch[22] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.115101,	
2017-06-27 15:12:48,871 Epoch[22] Batch [40]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.112966,	
2017-06-27 15:12:54,706 Epoch[22] Batch [50]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.109169,	
2017-06-27 15:13:01,557 Epoch[22] Batch [60]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.109154,	
2017-06-27 15:13:08,389 Epoch[22] Batch [70]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.108088,	
2017-06-27 15:13:15,237 Epoch[22] Batch [80]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.108907,	
2017-06-27 15:13:21,242 Epoch[22] Batch [90]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.107880,	
2017-06-27 15:13:27,043 Epoch[22] Batch [100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107773,	
2017-06-27 15:13:32,281 Epoch[22] Batch [110]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108529,	
2017-06-27 15:13:37,507 Epoch[22] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.108637,	
2017-06-27 15:13:42,773 Epoch[22] Batch [130]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.109158,	
2017-06-27 15:13:48,001 Epoch[22] Batch [140]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.109158,	
2017-06-27 15:13:53,216 Epoch[22] Batch [150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.109306,	
2017-06-27 15:13:58,497 Epoch[22] Batch [160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.110204,	
2017-06-27 15:14:03,723 Epoch[22] Batch [170]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.110826,	
2017-06-27 15:14:09,023 Epoch[22] Batch [180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.110282,	
2017-06-27 15:14:14,226 Epoch[22] Batch [190]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.110183,	
2017-06-27 15:14:19,499 Epoch[22] Batch [200]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.110342,	
2017-06-27 15:14:24,729 Epoch[22] Batch [210]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111100,	
2017-06-27 15:14:30,001 Epoch[22] Batch [220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111375,	
2017-06-27 15:14:35,266 Epoch[22] Batch [230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111291,	
2017-06-27 15:14:40,533 Epoch[22] Batch [240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111133,	
2017-06-27 15:14:45,770 Epoch[22] Batch [250]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111700,	
2017-06-27 15:14:51,012 Epoch[22] Batch [260]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112011,	
2017-06-27 15:14:56,257 Epoch[22] Batch [270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112004,	
2017-06-27 15:15:01,507 Epoch[22] Batch [280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112073,	
2017-06-27 15:15:06,777 Epoch[22] Batch [290]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112058,	
2017-06-27 15:15:12,001 Epoch[22] Batch [300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112582,	
2017-06-27 15:15:17,300 Epoch[22] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.112458,	
2017-06-27 15:15:22,595 Epoch[22] Batch [320]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.112288,	
2017-06-27 15:15:27,778 Epoch[22] Batch [330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111949,	
2017-06-27 15:15:33,081 Epoch[22] Batch [340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.111698,	
2017-06-27 15:15:38,314 Epoch[22] Batch [350]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111597,	
2017-06-27 15:15:43,614 Epoch[22] Batch [360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111701,	
2017-06-27 15:15:48,871 Epoch[22] Batch [370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111803,	
2017-06-27 15:15:54,091 Epoch[22] Batch [380]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111763,	
2017-06-27 15:15:59,352 Epoch[22] Batch [390]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111974,	
2017-06-27 15:16:04,592 Epoch[22] Batch [400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112052,	
2017-06-27 15:16:09,897 Epoch[22] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.112114,	
2017-06-27 15:16:15,127 Epoch[22] Batch [420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111686,	
2017-06-27 15:16:20,411 Epoch[22] Batch [430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111796,	
2017-06-27 15:16:25,620 Epoch[22] Batch [440]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111705,	
2017-06-27 15:16:30,897 Epoch[22] Batch [450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111387,	
2017-06-27 15:16:36,137 Epoch[22] Batch [460]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112085,	
2017-06-27 15:16:41,351 Epoch[22] Batch [470]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112373,	
2017-06-27 15:16:46,655 Epoch[22] Batch [480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.112597,	
2017-06-27 15:16:51,925 Epoch[22] Batch [490]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112552,	
2017-06-27 15:16:57,157 Epoch[22] Batch [500]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112966,	
2017-06-27 15:17:02,421 Epoch[22] Batch [510]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112864,	
2017-06-27 15:17:07,645 Epoch[22] Batch [520]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.113078,	
2017-06-27 15:17:12,916 Epoch[22] Batch [530]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113195,	
2017-06-27 15:17:18,187 Epoch[22] Batch [540]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113208,	
2017-06-27 15:17:23,418 Epoch[22] Batch [550]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.113145,	
2017-06-27 15:17:28,663 Epoch[22] Batch [560]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112857,	
2017-06-27 15:17:33,922 Epoch[22] Batch [570]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112799,	
2017-06-27 15:17:39,175 Epoch[22] Batch [580]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112628,	
2017-06-27 15:17:44,427 Epoch[22] Batch [590]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112646,	
2017-06-27 15:17:49,689 Epoch[22] Batch [600]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112657,	
2017-06-27 15:17:54,917 Epoch[22] Batch [610]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112525,	
2017-06-27 15:18:00,154 Epoch[22] Batch [620]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112266,	
2017-06-27 15:18:05,467 Epoch[22] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.112034,	
2017-06-27 15:18:10,687 Epoch[22] Batch [640]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111867,	
2017-06-27 15:18:15,989 Epoch[22] Batch [650]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111878,	
2017-06-27 15:18:21,221 Epoch[22] Batch [660]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111937,	
2017-06-27 15:18:26,467 Epoch[22] Batch [670]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111839,	
2017-06-27 15:18:31,737 Epoch[22] Batch [680]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111892,	
2017-06-27 15:18:36,952 Epoch[22] Batch [690]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112031,	
2017-06-27 15:18:42,233 Epoch[22] Batch [700]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.112009,	
2017-06-27 15:18:47,448 Epoch[22] Batch [710]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112117,	
2017-06-27 15:18:52,731 Epoch[22] Batch [720]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.112248,	
2017-06-27 15:18:57,956 Epoch[22] Batch [730]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112344,	
2017-06-27 15:19:03,227 Epoch[22] Batch [740]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112364,	
2017-06-27 15:19:08,505 Epoch[22] Batch [750]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.112246,	
2017-06-27 15:19:13,759 Epoch[22] Batch [760]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112072,	
2017-06-27 15:19:19,037 Epoch[22] Batch [770]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.112007,	
2017-06-27 15:19:24,242 Epoch[22] Batch [780]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111946,	
2017-06-27 15:19:29,493 Epoch[22] Batch [790]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111905,	
2017-06-27 15:19:34,727 Epoch[22] Batch [800]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111907,	
2017-06-27 15:19:39,993 Epoch[22] Batch [810]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111796,	
2017-06-27 15:19:45,205 Epoch[22] Batch [820]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111871,	
2017-06-27 15:19:50,472 Epoch[22] Batch [830]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111748,	
2017-06-27 15:19:55,709 Epoch[22] Batch [840]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111897,	
2017-06-27 15:20:00,955 Epoch[22] Batch [850]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112021,	
2017-06-27 15:20:06,168 Epoch[22] Batch [860]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112066,	
2017-06-27 15:20:11,427 Epoch[22] Batch [870]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112190,	
2017-06-27 15:20:16,694 Epoch[22] Batch [880]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112222,	
2017-06-27 15:20:21,991 Epoch[22] Batch [890]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.112191,	
2017-06-27 15:20:27,188 Epoch[22] Batch [900]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112276,	
2017-06-27 15:20:32,406 Epoch[22] Batch [910]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112327,	
2017-06-27 15:20:37,651 Epoch[22] Batch [920]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.112076,	
2017-06-27 15:20:42,274 Epoch[22] Batch [930]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.111971,	
2017-06-27 15:20:46,893 Epoch[22] Batch [940]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.112023,	
2017-06-27 15:20:52,077 Epoch[22] Batch [950]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111946,	
2017-06-27 15:20:57,352 Epoch[22] Batch [960]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111922,	
2017-06-27 15:21:02,588 Epoch[22] Batch [970]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111819,	
2017-06-27 15:21:07,851 Epoch[22] Batch [980]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111844,	
2017-06-27 15:21:13,104 Epoch[22] Batch [990]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111834,	
2017-06-27 15:21:18,367 Epoch[22] Batch [1000]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111843,	
2017-06-27 15:21:23,621 Epoch[22] Batch [1010]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111942,	
2017-06-27 15:21:28,855 Epoch[22] Batch [1020]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111829,	
2017-06-27 15:21:34,164 Epoch[22] Batch [1030]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.111849,	
2017-06-27 15:21:39,350 Epoch[22] Batch [1040]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.111853,	
2017-06-27 15:21:44,655 Epoch[22] Batch [1050]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.111933,	
2017-06-27 15:21:49,907 Epoch[22] Batch [1060]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111980,	
2017-06-27 15:21:55,153 Epoch[22] Batch [1070]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111889,	
2017-06-27 15:22:00,445 Epoch[22] Batch [1080]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.111880,	
2017-06-27 15:22:05,722 Epoch[22] Batch [1090]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111816,	
2017-06-27 15:22:10,978 Epoch[22] Batch [1100]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111831,	
2017-06-27 15:22:16,263 Epoch[22] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111771,	
2017-06-27 15:22:21,530 Epoch[22] Batch [1120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111890,	
2017-06-27 15:22:26,758 Epoch[22] Batch [1130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111855,	
2017-06-27 15:22:32,056 Epoch[22] Batch [1140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111821,	
2017-06-27 15:22:37,371 Epoch[22] Batch [1150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.111871,	
2017-06-27 15:22:42,657 Epoch[22] Batch [1160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111890,	
2017-06-27 15:22:47,893 Epoch[22] Batch [1170]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111991,	
2017-06-27 15:22:53,159 Epoch[22] Batch [1180]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112011,	
2017-06-27 15:22:58,433 Epoch[22] Batch [1190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112103,	
2017-06-27 15:23:03,691 Epoch[22] Batch [1200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112057,	
2017-06-27 15:23:09,011 Epoch[22] Batch [1210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.112086,	
2017-06-27 15:23:14,272 Epoch[22] Batch [1220]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111940,	
2017-06-27 15:23:19,522 Epoch[22] Batch [1230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111792,	
2017-06-27 15:23:24,793 Epoch[22] Batch [1240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111753,	
2017-06-27 15:23:30,078 Epoch[22] Batch [1250]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111567,	
2017-06-27 15:23:35,363 Epoch[22] Batch [1260]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111561,	
2017-06-27 15:23:40,670 Epoch[22] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.111622,	
2017-06-27 15:23:45,942 Epoch[22] Batch [1280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111535,	
2017-06-27 15:23:51,214 Epoch[22] Batch [1290]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111440,	
2017-06-27 15:23:56,596 Epoch[22] Batch [1300]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.111408,	
2017-06-27 15:24:01,862 Epoch[22] Batch [1310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111355,	
2017-06-27 15:24:07,158 Epoch[22] Batch [1320]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111389,	
2017-06-27 15:24:12,460 Epoch[22] Batch [1330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.111373,	
2017-06-27 15:24:17,753 Epoch[22] Batch [1340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.111308,	
2017-06-27 15:24:23,023 Epoch[22] Batch [1350]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111351,	
2017-06-27 15:24:28,234 Epoch[22] Batch [1360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111274,	
2017-06-27 15:24:33,585 Epoch[22] Batch [1370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.111236,	
2017-06-27 15:24:38,886 Epoch[22] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111206,	
2017-06-27 15:24:44,289 Epoch[22] Batch [1390]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.111218,	
2017-06-27 15:24:49,537 Epoch[22] Batch [1400]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111146,	
2017-06-27 15:24:54,898 Epoch[22] Batch [1410]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.111185,	
2017-06-27 15:25:00,226 Epoch[22] Batch [1420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.111191,	
2017-06-27 15:25:05,585 Epoch[22] Batch [1430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.111243,	
2017-06-27 15:25:11,004 Epoch[22] Batch [1440]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.111279,	
2017-06-27 15:25:16,305 Epoch[22] Batch [1450]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111185,	
2017-06-27 15:25:21,646 Epoch[22] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.111160,	
2017-06-27 15:25:27,004 Epoch[22] Batch [1470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.111164,	
2017-06-27 15:25:32,342 Epoch[22] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.111123,	
2017-06-27 15:25:35,515 Epoch[22] Train-FCNLogLoss=0.111115
2017-06-27 15:25:35,516 Epoch[22] Time cost=788.339
2017-06-27 15:25:36,220 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0023.params"
2017-06-27 15:25:37,914 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0023.states"
2017-06-27 15:25:43,762 Epoch[23] Batch [10]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.104462,	
2017-06-27 15:25:49,157 Epoch[23] Batch [20]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.112086,	
2017-06-27 15:25:54,460 Epoch[23] Batch [30]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114274,	
2017-06-27 15:25:59,831 Epoch[23] Batch [40]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114341,	
2017-06-27 15:26:05,143 Epoch[23] Batch [50]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.111935,	
2017-06-27 15:26:10,487 Epoch[23] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114094,	
2017-06-27 15:26:15,840 Epoch[23] Batch [70]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.112503,	
2017-06-27 15:26:21,155 Epoch[23] Batch [80]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.111949,	
2017-06-27 15:26:26,513 Epoch[23] Batch [90]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.110559,	
2017-06-27 15:26:31,828 Epoch[23] Batch [100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.112791,	
2017-06-27 15:26:37,170 Epoch[23] Batch [110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.112020,	
2017-06-27 15:26:42,516 Epoch[23] Batch [120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.111231,	
2017-06-27 15:26:47,833 Epoch[23] Batch [130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.112292,	
2017-06-27 15:26:53,188 Epoch[23] Batch [140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.112556,	
2017-06-27 15:26:58,504 Epoch[23] Batch [150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.111663,	
2017-06-27 15:27:03,887 Epoch[23] Batch [160]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.111317,	
2017-06-27 15:27:09,177 Epoch[23] Batch [170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.110511,	
2017-06-27 15:27:14,555 Epoch[23] Batch [180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.111203,	
2017-06-27 15:27:19,862 Epoch[23] Batch [190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.111223,	
2017-06-27 15:27:25,205 Epoch[23] Batch [200]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.111455,	
2017-06-27 15:27:30,573 Epoch[23] Batch [210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.111061,	
2017-06-27 15:27:35,880 Epoch[23] Batch [220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.110693,	
2017-06-27 15:27:41,183 Epoch[23] Batch [230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.111442,	
2017-06-27 15:27:46,523 Epoch[23] Batch [240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.111503,	
2017-06-27 15:27:51,844 Epoch[23] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.111381,	
2017-06-27 15:27:57,196 Epoch[23] Batch [260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.110888,	
2017-06-27 15:28:02,442 Epoch[23] Batch [270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.110718,	
2017-06-27 15:28:07,819 Epoch[23] Batch [280]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.110981,	
2017-06-27 15:28:13,135 Epoch[23] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.110870,	
2017-06-27 15:28:18,478 Epoch[23] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.110730,	
2017-06-27 15:28:23,780 Epoch[23] Batch [310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.110589,	
2017-06-27 15:28:29,157 Epoch[23] Batch [320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.110470,	
2017-06-27 15:28:34,450 Epoch[23] Batch [330]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.110218,	
2017-06-27 15:28:39,770 Epoch[23] Batch [340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.110260,	
2017-06-27 15:28:45,056 Epoch[23] Batch [350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.110119,	
2017-06-27 15:28:50,355 Epoch[23] Batch [360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.109697,	
2017-06-27 15:28:55,688 Epoch[23] Batch [370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.109822,	
2017-06-27 15:29:00,996 Epoch[23] Batch [380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.109659,	
2017-06-27 15:29:06,355 Epoch[23] Batch [390]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.109507,	
2017-06-27 15:29:11,687 Epoch[23] Batch [400]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.109925,	
2017-06-27 15:29:16,988 Epoch[23] Batch [410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.110038,	
2017-06-27 15:29:22,345 Epoch[23] Batch [420]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.110312,	
2017-06-27 15:29:27,674 Epoch[23] Batch [430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.110439,	
2017-06-27 15:29:33,020 Epoch[23] Batch [440]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.111196,	
2017-06-27 15:29:38,336 Epoch[23] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.111361,	
2017-06-27 15:29:43,634 Epoch[23] Batch [460]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111501,	
2017-06-27 15:29:48,933 Epoch[23] Batch [470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111483,	
2017-06-27 15:29:54,256 Epoch[23] Batch [480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.111204,	
2017-06-27 15:29:59,543 Epoch[23] Batch [490]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111054,	
2017-06-27 15:30:04,859 Epoch[23] Batch [500]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.110942,	
2017-06-27 15:30:10,116 Epoch[23] Batch [510]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.110514,	
2017-06-27 15:30:15,492 Epoch[23] Batch [520]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.110263,	
2017-06-27 15:30:20,863 Epoch[23] Batch [530]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.109893,	
2017-06-27 15:30:26,158 Epoch[23] Batch [540]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.109899,	
2017-06-27 15:30:31,504 Epoch[23] Batch [550]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.110006,	
2017-06-27 15:30:36,830 Epoch[23] Batch [560]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.110038,	
2017-06-27 15:30:42,216 Epoch[23] Batch [570]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.109850,	
2017-06-27 15:30:47,559 Epoch[23] Batch [580]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.109664,	
2017-06-27 15:30:52,849 Epoch[23] Batch [590]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.109742,	
2017-06-27 15:30:58,220 Epoch[23] Batch [600]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.109635,	
2017-06-27 15:31:03,564 Epoch[23] Batch [610]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.109607,	
2017-06-27 15:31:08,912 Epoch[23] Batch [620]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.109368,	
2017-06-27 15:31:14,173 Epoch[23] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.109364,	
2017-06-27 15:31:19,515 Epoch[23] Batch [640]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.109357,	
2017-06-27 15:31:24,864 Epoch[23] Batch [650]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.109181,	
2017-06-27 15:31:30,171 Epoch[23] Batch [660]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108995,	
2017-06-27 15:31:35,555 Epoch[23] Batch [670]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.109029,	
2017-06-27 15:31:40,884 Epoch[23] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.108969,	
2017-06-27 15:31:46,197 Epoch[23] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108870,	
2017-06-27 15:31:51,455 Epoch[23] Batch [700]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.108819,	
2017-06-27 15:31:56,781 Epoch[23] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.108898,	
2017-06-27 15:32:02,087 Epoch[23] Batch [720]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108825,	
2017-06-27 15:32:07,324 Epoch[23] Batch [730]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108803,	
2017-06-27 15:32:12,667 Epoch[23] Batch [740]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.108587,	
2017-06-27 15:32:17,966 Epoch[23] Batch [750]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108536,	
2017-06-27 15:32:23,353 Epoch[23] Batch [760]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.108504,	
2017-06-27 15:32:28,637 Epoch[23] Batch [770]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108365,	
2017-06-27 15:32:33,982 Epoch[23] Batch [780]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108315,	
2017-06-27 15:32:39,280 Epoch[23] Batch [790]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108377,	
2017-06-27 15:32:44,647 Epoch[23] Batch [800]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.108420,	
2017-06-27 15:32:50,003 Epoch[23] Batch [810]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.108528,	
2017-06-27 15:32:55,290 Epoch[23] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108576,	
2017-06-27 15:33:00,585 Epoch[23] Batch [830]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.108595,	
2017-06-27 15:33:05,940 Epoch[23] Batch [840]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.108409,	
2017-06-27 15:33:11,254 Epoch[23] Batch [850]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108483,	
2017-06-27 15:33:16,570 Epoch[23] Batch [860]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.108568,	
2017-06-27 15:33:21,922 Epoch[23] Batch [870]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.108416,	
2017-06-27 15:33:27,270 Epoch[23] Batch [880]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108410,	
2017-06-27 15:33:32,560 Epoch[23] Batch [890]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.108485,	
2017-06-27 15:33:37,946 Epoch[23] Batch [900]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.108644,	
2017-06-27 15:33:43,271 Epoch[23] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.108658,	
2017-06-27 15:33:48,606 Epoch[23] Batch [920]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.108608,	
2017-06-27 15:33:53,906 Epoch[23] Batch [930]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108609,	
2017-06-27 15:33:58,110 Epoch[23] Batch [940]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.108643,	
2017-06-27 15:34:03,379 Epoch[23] Batch [950]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.108810,	
2017-06-27 15:34:08,709 Epoch[23] Batch [960]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.108879,	
2017-06-27 15:34:14,039 Epoch[23] Batch [970]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.108941,	
2017-06-27 15:34:19,408 Epoch[23] Batch [980]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.108947,	
2017-06-27 15:34:24,709 Epoch[23] Batch [990]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108975,	
2017-06-27 15:34:30,014 Epoch[23] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108968,	
2017-06-27 15:34:35,359 Epoch[23] Batch [1010]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108889,	
2017-06-27 15:34:40,669 Epoch[23] Batch [1020]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108782,	
2017-06-27 15:34:45,998 Epoch[23] Batch [1030]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.108682,	
2017-06-27 15:34:51,356 Epoch[23] Batch [1040]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.108542,	
2017-06-27 15:34:56,665 Epoch[23] Batch [1050]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108541,	
2017-06-27 15:35:01,961 Epoch[23] Batch [1060]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108483,	
2017-06-27 15:35:07,234 Epoch[23] Batch [1070]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.108542,	
2017-06-27 15:35:12,484 Epoch[23] Batch [1080]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.108402,	
2017-06-27 15:35:17,796 Epoch[23] Batch [1090]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108459,	
2017-06-27 15:35:23,095 Epoch[23] Batch [1100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108456,	
2017-06-27 15:35:28,395 Epoch[23] Batch [1110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108464,	
2017-06-27 15:35:33,699 Epoch[23] Batch [1120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108452,	
2017-06-27 15:35:39,011 Epoch[23] Batch [1130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108437,	
2017-06-27 15:35:44,250 Epoch[23] Batch [1140]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108384,	
2017-06-27 15:35:49,544 Epoch[23] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.108292,	
2017-06-27 15:35:54,767 Epoch[23] Batch [1160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.108181,	
2017-06-27 15:36:00,116 Epoch[23] Batch [1170]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108240,	
2017-06-27 15:36:05,441 Epoch[23] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.108282,	
2017-06-27 15:36:10,808 Epoch[23] Batch [1190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.108317,	
2017-06-27 15:36:16,117 Epoch[23] Batch [1200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108303,	
2017-06-27 15:36:21,429 Epoch[23] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108204,	
2017-06-27 15:36:26,803 Epoch[23] Batch [1220]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.108099,	
2017-06-27 15:36:32,053 Epoch[23] Batch [1230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.108118,	
2017-06-27 15:36:37,357 Epoch[23] Batch [1240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108057,	
2017-06-27 15:36:42,658 Epoch[23] Batch [1250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108059,	
2017-06-27 15:36:47,963 Epoch[23] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108011,	
2017-06-27 15:36:53,297 Epoch[23] Batch [1270]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.107972,	
2017-06-27 15:36:58,618 Epoch[23] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.107907,	
2017-06-27 15:37:03,919 Epoch[23] Batch [1290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.107945,	
2017-06-27 15:37:09,219 Epoch[23] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108083,	
2017-06-27 15:37:14,549 Epoch[23] Batch [1310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.108384,	
2017-06-27 15:37:19,886 Epoch[23] Batch [1320]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.108714,	
2017-06-27 15:37:25,224 Epoch[23] Batch [1330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.108793,	
2017-06-27 15:37:30,503 Epoch[23] Batch [1340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.108805,	
2017-06-27 15:37:35,848 Epoch[23] Batch [1350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108857,	
2017-06-27 15:37:41,124 Epoch[23] Batch [1360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.108808,	
2017-06-27 15:37:46,441 Epoch[23] Batch [1370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.108790,	
2017-06-27 15:37:51,724 Epoch[23] Batch [1380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108790,	
2017-06-27 15:37:57,026 Epoch[23] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108749,	
2017-06-27 15:38:02,333 Epoch[23] Batch [1400]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108669,	
2017-06-27 15:38:07,644 Epoch[23] Batch [1410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108668,	
2017-06-27 15:38:12,938 Epoch[23] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.108578,	
2017-06-27 15:38:18,246 Epoch[23] Batch [1430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108583,	
2017-06-27 15:38:23,527 Epoch[23] Batch [1440]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108566,	
2017-06-27 15:38:28,882 Epoch[23] Batch [1450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.108625,	
2017-06-27 15:38:34,168 Epoch[23] Batch [1460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108730,	
2017-06-27 15:38:39,418 Epoch[23] Batch [1470]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.108730,	
2017-06-27 15:38:44,700 Epoch[23] Batch [1480]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108849,	
2017-06-27 15:38:47,911 Epoch[23] Train-FCNLogLoss=0.108933
2017-06-27 15:38:47,912 Epoch[23] Time cost=789.997
2017-06-27 15:38:48,749 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0024.params"
2017-06-27 15:38:50,432 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0024.states"
2017-06-27 15:38:56,530 Epoch[24] Batch [10]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.109786,	
2017-06-27 15:39:01,896 Epoch[24] Batch [20]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114175,	
2017-06-27 15:39:07,152 Epoch[24] Batch [30]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112270,	
2017-06-27 15:39:12,494 Epoch[24] Batch [40]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.112932,	
2017-06-27 15:39:17,708 Epoch[24] Batch [50]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112540,	
2017-06-27 15:39:23,008 Epoch[24] Batch [60]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.114462,	
2017-06-27 15:39:28,338 Epoch[24] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113994,	
2017-06-27 15:39:33,687 Epoch[24] Batch [80]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.115141,	
2017-06-27 15:39:39,045 Epoch[24] Batch [90]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117727,	
2017-06-27 15:39:44,274 Epoch[24] Batch [100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.117019,	
2017-06-27 15:39:49,559 Epoch[24] Batch [110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116303,	
2017-06-27 15:39:54,846 Epoch[24] Batch [120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.115562,	
2017-06-27 15:40:00,188 Epoch[24] Batch [130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114406,	
2017-06-27 15:40:05,487 Epoch[24] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.113507,	
2017-06-27 15:40:10,818 Epoch[24] Batch [150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.112575,	
2017-06-27 15:40:16,129 Epoch[24] Batch [160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.112407,	
2017-06-27 15:40:21,459 Epoch[24] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.112956,	
2017-06-27 15:40:26,787 Epoch[24] Batch [180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.112811,	
2017-06-27 15:40:32,153 Epoch[24] Batch [190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.113035,	
2017-06-27 15:40:37,477 Epoch[24] Batch [200]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.112234,	
2017-06-27 15:40:42,761 Epoch[24] Batch [210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111593,	
2017-06-27 15:40:48,059 Epoch[24] Batch [220]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.110924,	
2017-06-27 15:40:53,403 Epoch[24] Batch [230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.110449,	
2017-06-27 15:40:58,733 Epoch[24] Batch [240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.110345,	
2017-06-27 15:41:04,064 Epoch[24] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.109934,	
2017-06-27 15:41:09,369 Epoch[24] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.109705,	
2017-06-27 15:41:14,690 Epoch[24] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.109701,	
2017-06-27 15:41:20,051 Epoch[24] Batch [280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.110219,	
2017-06-27 15:41:25,304 Epoch[24] Batch [290]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111663,	
2017-06-27 15:41:30,671 Epoch[24] Batch [300]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.120042,	
2017-06-27 15:41:36,049 Epoch[24] Batch [310]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.127975,	
2017-06-27 15:41:41,375 Epoch[24] Batch [320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131017,	
2017-06-27 15:41:46,694 Epoch[24] Batch [330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134390,	
2017-06-27 15:41:51,963 Epoch[24] Batch [340]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.135130,	
2017-06-27 15:41:57,315 Epoch[24] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136273,	
2017-06-27 15:42:02,680 Epoch[24] Batch [360]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.136835,	
2017-06-27 15:42:08,019 Epoch[24] Batch [370]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.136857,	
2017-06-27 15:42:13,316 Epoch[24] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.138069,	
2017-06-27 15:42:18,654 Epoch[24] Batch [390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.138823,	
2017-06-27 15:42:23,935 Epoch[24] Batch [400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.140128,	
2017-06-27 15:42:29,242 Epoch[24] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.140469,	
2017-06-27 15:42:34,545 Epoch[24] Batch [420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.140157,	
2017-06-27 15:42:39,912 Epoch[24] Batch [430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.139893,	
2017-06-27 15:42:45,269 Epoch[24] Batch [440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.139709,	
2017-06-27 15:42:50,586 Epoch[24] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.139497,	
2017-06-27 15:42:55,911 Epoch[24] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.139622,	
2017-06-27 15:43:01,252 Epoch[24] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.139458,	
2017-06-27 15:43:06,556 Epoch[24] Batch [480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.139078,	
2017-06-27 15:43:11,866 Epoch[24] Batch [490]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.138758,	
2017-06-27 15:43:17,217 Epoch[24] Batch [500]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.138356,	
2017-06-27 15:43:22,566 Epoch[24] Batch [510]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.138147,	
2017-06-27 15:43:27,865 Epoch[24] Batch [520]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.137682,	
2017-06-27 15:43:33,216 Epoch[24] Batch [530]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.137299,	
2017-06-27 15:43:38,505 Epoch[24] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.137110,	
2017-06-27 15:43:43,860 Epoch[24] Batch [550]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.136772,	
2017-06-27 15:43:49,133 Epoch[24] Batch [560]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.136447,	
2017-06-27 15:43:54,504 Epoch[24] Batch [570]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.136051,	
2017-06-27 15:43:59,840 Epoch[24] Batch [580]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.135783,	
2017-06-27 15:44:05,164 Epoch[24] Batch [590]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135296,	
2017-06-27 15:44:10,468 Epoch[24] Batch [600]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.135094,	
2017-06-27 15:44:15,772 Epoch[24] Batch [610]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.135021,	
2017-06-27 15:44:21,112 Epoch[24] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134919,	
2017-06-27 15:44:26,379 Epoch[24] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.134666,	
2017-06-27 15:44:31,706 Epoch[24] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134564,	
2017-06-27 15:44:36,986 Epoch[24] Batch [650]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.134174,	
2017-06-27 15:44:42,280 Epoch[24] Batch [660]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.134030,	
2017-06-27 15:44:47,601 Epoch[24] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133744,	
2017-06-27 15:44:52,879 Epoch[24] Batch [680]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.133468,	
2017-06-27 15:44:58,160 Epoch[24] Batch [690]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.132952,	
2017-06-27 15:45:03,530 Epoch[24] Batch [700]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.132794,	
2017-06-27 15:45:08,806 Epoch[24] Batch [710]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.132687,	
2017-06-27 15:45:14,049 Epoch[24] Batch [720]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.132407,	
2017-06-27 15:45:19,393 Epoch[24] Batch [730]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.132295,	
2017-06-27 15:45:24,698 Epoch[24] Batch [740]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.132083,	
2017-06-27 15:45:30,007 Epoch[24] Batch [750]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131919,	
2017-06-27 15:45:35,275 Epoch[24] Batch [760]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.131678,	
2017-06-27 15:45:40,562 Epoch[24] Batch [770]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.131376,	
2017-06-27 15:45:45,865 Epoch[24] Batch [780]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131270,	
2017-06-27 15:45:51,142 Epoch[24] Batch [790]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.131332,	
2017-06-27 15:45:56,387 Epoch[24] Batch [800]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.131104,	
2017-06-27 15:46:01,644 Epoch[24] Batch [810]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.131009,	
2017-06-27 15:46:06,924 Epoch[24] Batch [820]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130772,	
2017-06-27 15:46:12,249 Epoch[24] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130651,	
2017-06-27 15:46:17,519 Epoch[24] Batch [840]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.130455,	
2017-06-27 15:46:22,869 Epoch[24] Batch [850]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130275,	
2017-06-27 15:46:28,130 Epoch[24] Batch [860]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.129935,	
2017-06-27 15:46:33,445 Epoch[24] Batch [870]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129806,	
2017-06-27 15:46:38,793 Epoch[24] Batch [880]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.129581,	
2017-06-27 15:46:44,070 Epoch[24] Batch [890]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.129277,	
2017-06-27 15:46:49,373 Epoch[24] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.129133,	
2017-06-27 15:46:54,660 Epoch[24] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.128989,	
2017-06-27 15:46:59,984 Epoch[24] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.128816,	
2017-06-27 15:47:05,307 Epoch[24] Batch [930]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.128467,	
2017-06-27 15:47:09,361 Epoch[24] Batch [940]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.128355,	
2017-06-27 15:47:14,597 Epoch[24] Batch [950]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.128257,	
2017-06-27 15:47:19,886 Epoch[24] Batch [960]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.128058,	
2017-06-27 15:47:25,204 Epoch[24] Batch [970]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.127779,	
2017-06-27 15:47:30,583 Epoch[24] Batch [980]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.127768,	
2017-06-27 15:47:35,858 Epoch[24] Batch [990]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.127566,	
2017-06-27 15:47:41,096 Epoch[24] Batch [1000]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.127403,	
2017-06-27 15:47:46,422 Epoch[24] Batch [1010]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.127341,	
2017-06-27 15:47:51,712 Epoch[24] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.127273,	
2017-06-27 15:47:57,096 Epoch[24] Batch [1030]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.127084,	
2017-06-27 15:48:02,442 Epoch[24] Batch [1040]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.127092,	
2017-06-27 15:48:07,782 Epoch[24] Batch [1050]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.127163,	
2017-06-27 15:48:13,073 Epoch[24] Batch [1060]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126783,	
2017-06-27 15:48:18,367 Epoch[24] Batch [1070]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126557,	
2017-06-27 15:48:23,626 Epoch[24] Batch [1080]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.126471,	
2017-06-27 15:48:28,954 Epoch[24] Batch [1090]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.126269,	
2017-06-27 15:48:34,200 Epoch[24] Batch [1100]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.126134,	
2017-06-27 15:48:39,520 Epoch[24] Batch [1110]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125962,	
2017-06-27 15:48:44,831 Epoch[24] Batch [1120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125961,	
2017-06-27 15:48:50,133 Epoch[24] Batch [1130]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125805,	
2017-06-27 15:48:55,520 Epoch[24] Batch [1140]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125635,	
2017-06-27 15:49:00,827 Epoch[24] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125523,	
2017-06-27 15:49:06,214 Epoch[24] Batch [1160]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125371,	
2017-06-27 15:49:11,475 Epoch[24] Batch [1170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125237,	
2017-06-27 15:49:16,844 Epoch[24] Batch [1180]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125167,	
2017-06-27 15:49:22,124 Epoch[24] Batch [1190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125062,	
2017-06-27 15:49:27,444 Epoch[24] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.124959,	
2017-06-27 15:49:32,745 Epoch[24] Batch [1210]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124750,	
2017-06-27 15:49:38,048 Epoch[24] Batch [1220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124570,	
2017-06-27 15:49:43,378 Epoch[24] Batch [1230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124476,	
2017-06-27 15:49:48,653 Epoch[24] Batch [1240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.124434,	
2017-06-27 15:49:53,966 Epoch[24] Batch [1250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124353,	
2017-06-27 15:49:59,231 Epoch[24] Batch [1260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124260,	
2017-06-27 15:50:04,527 Epoch[24] Batch [1270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124178,	
2017-06-27 15:50:09,850 Epoch[24] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124054,	
2017-06-27 15:50:15,153 Epoch[24] Batch [1290]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124003,	
2017-06-27 15:50:20,435 Epoch[24] Batch [1300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.123849,	
2017-06-27 15:50:25,743 Epoch[24] Batch [1310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.123756,	
2017-06-27 15:50:31,063 Epoch[24] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.123673,	
2017-06-27 15:50:36,301 Epoch[24] Batch [1330]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.123637,	
2017-06-27 15:50:41,592 Epoch[24] Batch [1340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.123562,	
2017-06-27 15:50:48,612 Epoch[24] Batch [1350]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.123374,	
2017-06-27 15:50:56,837 Epoch[24] Batch [1360]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.123334,	
2017-06-27 15:51:06,070 Epoch[24] Batch [1370]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.123265,	
2017-06-27 15:51:14,121 Epoch[24] Batch [1380]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.123145,	
2017-06-27 15:51:22,622 Epoch[24] Batch [1390]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.122992,	
2017-06-27 15:51:31,967 Epoch[24] Batch [1400]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.122947,	
2017-06-27 15:51:40,094 Epoch[24] Batch [1410]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.122911,	
2017-06-27 15:51:48,360 Epoch[24] Batch [1420]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.122796,	
2017-06-27 15:51:56,045 Epoch[24] Batch [1430]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.122746,	
2017-06-27 15:52:04,076 Epoch[24] Batch [1440]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.122663,	
2017-06-27 15:52:12,405 Epoch[24] Batch [1450]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.122683,	
2017-06-27 15:52:20,799 Epoch[24] Batch [1460]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.122628,	
2017-06-27 15:52:28,828 Epoch[24] Batch [1470]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.122560,	
2017-06-27 15:52:36,900 Epoch[24] Batch [1480]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.122497,	
2017-06-27 15:52:41,585 Epoch[24] Train-FCNLogLoss=0.122532
2017-06-27 15:52:41,595 Epoch[24] Time cost=831.163
2017-06-27 15:52:43,242 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0025.params"
2017-06-27 15:52:46,617 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0025.states"
2017-06-27 15:52:56,172 Epoch[25] Batch [10]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.109021,	
2017-06-27 15:53:04,141 Epoch[25] Batch [20]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.125893,	
2017-06-27 15:53:12,479 Epoch[25] Batch [30]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.129011,	
2017-06-27 15:53:20,823 Epoch[25] Batch [40]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.127720,	
2017-06-27 15:53:29,374 Epoch[25] Batch [50]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.128443,	
2017-06-27 15:53:37,973 Epoch[25] Batch [60]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.129624,	
2017-06-27 15:53:45,992 Epoch[25] Batch [70]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.128832,	
2017-06-27 15:53:53,944 Epoch[25] Batch [80]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.128398,	
2017-06-27 15:54:01,829 Epoch[25] Batch [90]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.125877,	
2017-06-27 15:54:10,172 Epoch[25] Batch [100]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.125652,	
2017-06-27 15:54:18,567 Epoch[25] Batch [110]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.124018,	
2017-06-27 15:54:26,315 Epoch[25] Batch [120]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.123372,	
2017-06-27 15:54:34,208 Epoch[25] Batch [130]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.121767,	
2017-06-27 15:54:42,518 Epoch[25] Batch [140]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.121518,	
2017-06-27 15:54:50,501 Epoch[25] Batch [150]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.121422,	
2017-06-27 15:54:58,362 Epoch[25] Batch [160]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.121755,	
2017-06-27 15:55:06,328 Epoch[25] Batch [170]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.121398,	
2017-06-27 15:55:13,785 Epoch[25] Batch [180]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.121152,	
2017-06-27 15:55:20,853 Epoch[25] Batch [190]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.120280,	
2017-06-27 15:55:27,578 Epoch[25] Batch [200]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.120400,	
2017-06-27 15:55:33,998 Epoch[25] Batch [210]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.120421,	
2017-06-27 15:55:40,220 Epoch[25] Batch [220]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.121261,	
2017-06-27 15:55:45,996 Epoch[25] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121156,	
2017-06-27 15:55:51,419 Epoch[25] Batch [240]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.121013,	
2017-06-27 15:55:56,922 Epoch[25] Batch [250]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.120834,	
2017-06-27 15:56:02,293 Epoch[25] Batch [260]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.120388,	
2017-06-27 15:56:07,613 Epoch[25] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.120225,	
2017-06-27 15:56:12,937 Epoch[25] Batch [280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120200,	
2017-06-27 15:56:18,380 Epoch[25] Batch [290]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.119904,	
2017-06-27 15:56:23,749 Epoch[25] Batch [300]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118941,	
2017-06-27 15:56:29,017 Epoch[25] Batch [310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118657,	
2017-06-27 15:56:34,373 Epoch[25] Batch [320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118185,	
2017-06-27 15:56:39,870 Epoch[25] Batch [330]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.117921,	
2017-06-27 15:56:45,220 Epoch[25] Batch [340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117331,	
2017-06-27 15:56:50,577 Epoch[25] Batch [350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117236,	
2017-06-27 15:56:55,836 Epoch[25] Batch [360]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.117216,	
2017-06-27 15:57:01,116 Epoch[25] Batch [370]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.116898,	
2017-06-27 15:57:06,478 Epoch[25] Batch [380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116604,	
2017-06-27 15:57:11,747 Epoch[25] Batch [390]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.116323,	
2017-06-27 15:57:17,051 Epoch[25] Batch [400]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116256,	
2017-06-27 15:57:22,349 Epoch[25] Batch [410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116026,	
2017-06-27 15:57:27,735 Epoch[25] Batch [420]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.115891,	
2017-06-27 15:57:33,061 Epoch[25] Batch [430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.115618,	
2017-06-27 15:57:38,343 Epoch[25] Batch [440]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.115385,	
2017-06-27 15:57:43,662 Epoch[25] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.115332,	
2017-06-27 15:57:48,934 Epoch[25] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.115168,	
2017-06-27 15:57:54,271 Epoch[25] Batch [470]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.115035,	
2017-06-27 15:57:59,642 Epoch[25] Batch [480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.115045,	
2017-06-27 15:58:04,855 Epoch[25] Batch [490]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.114941,	
2017-06-27 15:58:10,207 Epoch[25] Batch [500]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.114763,	
2017-06-27 15:58:15,489 Epoch[25] Batch [510]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.114697,	
2017-06-27 15:58:20,844 Epoch[25] Batch [520]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.114362,	
2017-06-27 15:58:26,161 Epoch[25] Batch [530]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114336,	
2017-06-27 15:58:31,492 Epoch[25] Batch [540]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.114270,	
2017-06-27 15:58:36,795 Epoch[25] Batch [550]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114330,	
2017-06-27 15:58:42,103 Epoch[25] Batch [560]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114354,	
2017-06-27 15:58:47,529 Epoch[25] Batch [570]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.114501,	
2017-06-27 15:58:52,764 Epoch[25] Batch [580]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.114207,	
2017-06-27 15:58:58,076 Epoch[25] Batch [590]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.114158,	
2017-06-27 15:59:03,256 Epoch[25] Batch [600]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.113891,	
2017-06-27 15:59:08,652 Epoch[25] Batch [610]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.113849,	
2017-06-27 15:59:13,987 Epoch[25] Batch [620]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113632,	
2017-06-27 15:59:19,298 Epoch[25] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113391,	
2017-06-27 15:59:24,534 Epoch[25] Batch [640]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.113453,	
2017-06-27 15:59:29,794 Epoch[25] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.113376,	
2017-06-27 15:59:35,121 Epoch[25] Batch [660]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113482,	
2017-06-27 15:59:40,474 Epoch[25] Batch [670]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113472,	
2017-06-27 15:59:45,834 Epoch[25] Batch [680]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113306,	
2017-06-27 15:59:51,063 Epoch[25] Batch [690]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.113290,	
2017-06-27 15:59:56,439 Epoch[25] Batch [700]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.113271,	
2017-06-27 16:00:01,909 Epoch[25] Batch [710]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.113351,	
2017-06-27 16:00:07,213 Epoch[25] Batch [720]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113730,	
2017-06-27 16:00:12,551 Epoch[25] Batch [730]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113882,	
2017-06-27 16:00:17,824 Epoch[25] Batch [740]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113935,	
2017-06-27 16:00:23,147 Epoch[25] Batch [750]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113941,	
2017-06-27 16:00:28,367 Epoch[25] Batch [760]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.114005,	
2017-06-27 16:00:33,694 Epoch[25] Batch [770]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113844,	
2017-06-27 16:00:39,003 Epoch[25] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113815,	
2017-06-27 16:00:44,387 Epoch[25] Batch [790]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.113853,	
2017-06-27 16:00:49,635 Epoch[25] Batch [800]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.113932,	
2017-06-27 16:00:54,898 Epoch[25] Batch [810]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.113806,	
2017-06-27 16:01:00,166 Epoch[25] Batch [820]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113784,	
2017-06-27 16:01:05,370 Epoch[25] Batch [830]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.113806,	
2017-06-27 16:01:10,714 Epoch[25] Batch [840]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114067,	
2017-06-27 16:01:15,965 Epoch[25] Batch [850]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.114054,	
2017-06-27 16:01:21,327 Epoch[25] Batch [860]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113913,	
2017-06-27 16:01:26,628 Epoch[25] Batch [870]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.113750,	
2017-06-27 16:01:31,990 Epoch[25] Batch [880]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113598,	
2017-06-27 16:01:37,352 Epoch[25] Batch [890]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113598,	
2017-06-27 16:01:42,590 Epoch[25] Batch [900]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.113482,	
2017-06-27 16:01:47,893 Epoch[25] Batch [910]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113268,	
2017-06-27 16:01:53,232 Epoch[25] Batch [920]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113161,	
2017-06-27 16:01:58,621 Epoch[25] Batch [930]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.113115,	
2017-06-27 16:02:03,928 Epoch[25] Batch [940]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113146,	
2017-06-27 16:02:08,692 Epoch[25] Batch [950]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.113030,	
2017-06-27 16:02:13,995 Epoch[25] Batch [960]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113085,	
2017-06-27 16:02:19,226 Epoch[25] Batch [970]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.113033,	
2017-06-27 16:02:24,624 Epoch[25] Batch [980]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.112977,	
2017-06-27 16:02:29,669 Epoch[25] Batch [990]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.112799,	
2017-06-27 16:02:35,330 Epoch[25] Batch [1000]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.112818,	
2017-06-27 16:02:41,126 Epoch[25] Batch [1010]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112740,	
2017-06-27 16:02:46,835 Epoch[25] Batch [1020]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.112802,	
2017-06-27 16:02:52,287 Epoch[25] Batch [1030]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.112855,	
2017-06-27 16:02:57,940 Epoch[25] Batch [1040]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.112904,	
2017-06-27 16:03:03,545 Epoch[25] Batch [1050]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.112811,	
2017-06-27 16:03:09,054 Epoch[25] Batch [1060]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.112724,	
2017-06-27 16:03:14,681 Epoch[25] Batch [1070]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.112728,	
2017-06-27 16:03:20,182 Epoch[25] Batch [1080]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.112656,	
2017-06-27 16:03:26,076 Epoch[25] Batch [1090]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.113117,	
2017-06-27 16:03:31,790 Epoch[25] Batch [1100]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.113230,	
2017-06-27 16:03:37,051 Epoch[25] Batch [1110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.113950,	
2017-06-27 16:03:42,796 Epoch[25] Batch [1120]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.114341,	
2017-06-27 16:03:48,548 Epoch[25] Batch [1130]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.114779,	
2017-06-27 16:03:54,351 Epoch[25] Batch [1140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114876,	
2017-06-27 16:04:00,410 Epoch[25] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.114907,	
2017-06-27 16:04:06,219 Epoch[25] Batch [1160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114904,	
2017-06-27 16:04:12,101 Epoch[25] Batch [1170]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.114892,	
2017-06-27 16:04:18,046 Epoch[25] Batch [1180]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.114882,	
2017-06-27 16:04:23,659 Epoch[25] Batch [1190]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.114834,	
2017-06-27 16:04:29,564 Epoch[25] Batch [1200]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.114811,	
2017-06-27 16:04:35,452 Epoch[25] Batch [1210]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.114761,	
2017-06-27 16:04:41,025 Epoch[25] Batch [1220]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.114672,	
2017-06-27 16:04:46,396 Epoch[25] Batch [1230]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114647,	
2017-06-27 16:04:52,008 Epoch[25] Batch [1240]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.114638,	
2017-06-27 16:04:57,782 Epoch[25] Batch [1250]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.114620,	
2017-06-27 16:05:03,267 Epoch[25] Batch [1260]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.114527,	
2017-06-27 16:05:08,960 Epoch[25] Batch [1270]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.114556,	
2017-06-27 16:05:14,690 Epoch[25] Batch [1280]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.114547,	
2017-06-27 16:05:20,355 Epoch[25] Batch [1290]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.114609,	
2017-06-27 16:05:25,761 Epoch[25] Batch [1300]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.114604,	
2017-06-27 16:05:31,994 Epoch[25] Batch [1310]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.114518,	
2017-06-27 16:05:37,981 Epoch[25] Batch [1320]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.114478,	
2017-06-27 16:05:43,458 Epoch[25] Batch [1330]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.114376,	
2017-06-27 16:05:48,982 Epoch[25] Batch [1340]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.114242,	
2017-06-27 16:05:54,498 Epoch[25] Batch [1350]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.114210,	
2017-06-27 16:06:00,502 Epoch[25] Batch [1360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.114093,	
2017-06-27 16:06:06,324 Epoch[25] Batch [1370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114144,	
2017-06-27 16:06:12,231 Epoch[25] Batch [1380]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.114249,	
2017-06-27 16:06:17,869 Epoch[25] Batch [1390]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.114212,	
2017-06-27 16:06:23,820 Epoch[25] Batch [1400]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.114215,	
2017-06-27 16:06:29,965 Epoch[25] Batch [1410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.114179,	
2017-06-27 16:06:36,217 Epoch[25] Batch [1420]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.114092,	
2017-06-27 16:06:42,361 Epoch[25] Batch [1430]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.114036,	
2017-06-27 16:06:49,230 Epoch[25] Batch [1440]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.113981,	
2017-06-27 16:06:55,823 Epoch[25] Batch [1450]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.113960,	
2017-06-27 16:07:02,420 Epoch[25] Batch [1460]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.113857,	
2017-06-27 16:07:08,195 Epoch[25] Batch [1470]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113818,	
2017-06-27 16:07:14,062 Epoch[25] Batch [1480]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113697,	
2017-06-27 16:07:17,553 Epoch[25] Train-FCNLogLoss=0.113669
2017-06-27 16:07:17,553 Epoch[25] Time cost=870.935
2017-06-27 16:07:18,732 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0026.params"
2017-06-27 16:07:22,515 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0026.states"
2017-06-27 16:07:28,976 Epoch[26] Batch [10]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.108478,	
2017-06-27 16:07:35,141 Epoch[26] Batch [20]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.107543,	
2017-06-27 16:07:40,906 Epoch[26] Batch [30]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106791,	
2017-06-27 16:07:46,549 Epoch[26] Batch [40]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.107940,	
2017-06-27 16:07:53,085 Epoch[26] Batch [50]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.107362,	
2017-06-27 16:07:59,388 Epoch[26] Batch [60]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.106785,	
2017-06-27 16:08:05,995 Epoch[26] Batch [70]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.104538,	
2017-06-27 16:08:12,998 Epoch[26] Batch [80]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.105288,	
2017-06-27 16:08:19,569 Epoch[26] Batch [90]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.106250,	
2017-06-27 16:08:25,728 Epoch[26] Batch [100]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.105965,	
2017-06-27 16:08:32,980 Epoch[26] Batch [110]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.105413,	
2017-06-27 16:08:40,287 Epoch[26] Batch [120]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.105067,	
2017-06-27 16:08:47,212 Epoch[26] Batch [130]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.105405,	
2017-06-27 16:08:54,646 Epoch[26] Batch [140]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.105363,	
2017-06-27 16:09:01,614 Epoch[26] Batch [150]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.105920,	
2017-06-27 16:09:08,846 Epoch[26] Batch [160]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.106022,	
2017-06-27 16:09:16,305 Epoch[26] Batch [170]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.105742,	
2017-06-27 16:09:24,030 Epoch[26] Batch [180]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.106747,	
2017-06-27 16:09:31,637 Epoch[26] Batch [190]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.107072,	
2017-06-27 16:09:39,489 Epoch[26] Batch [200]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.106880,	
2017-06-27 16:09:47,038 Epoch[26] Batch [210]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.107507,	
2017-06-27 16:09:54,773 Epoch[26] Batch [220]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.107929,	
2017-06-27 16:10:02,814 Epoch[26] Batch [230]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.107522,	
2017-06-27 16:10:10,723 Epoch[26] Batch [240]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.107378,	
2017-06-27 16:10:18,624 Epoch[26] Batch [250]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.107207,	
2017-06-27 16:10:26,603 Epoch[26] Batch [260]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.106887,	
2017-06-27 16:10:34,375 Epoch[26] Batch [270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.106772,	
2017-06-27 16:10:42,159 Epoch[26] Batch [280]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.106444,	
2017-06-27 16:10:50,022 Epoch[26] Batch [290]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.106622,	
2017-06-27 16:10:57,998 Epoch[26] Batch [300]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.106325,	
2017-06-27 16:11:05,786 Epoch[26] Batch [310]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.106302,	
2017-06-27 16:11:13,820 Epoch[26] Batch [320]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.106033,	
2017-06-27 16:11:21,867 Epoch[26] Batch [330]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.105808,	
2017-06-27 16:11:29,976 Epoch[26] Batch [340]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.105808,	
2017-06-27 16:11:37,954 Epoch[26] Batch [350]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.106134,	
2017-06-27 16:11:46,238 Epoch[26] Batch [360]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.106671,	
2017-06-27 16:11:54,228 Epoch[26] Batch [370]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.106710,	
2017-06-27 16:12:02,093 Epoch[26] Batch [380]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.106810,	
2017-06-27 16:12:10,579 Epoch[26] Batch [390]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.106837,	
2017-06-27 16:12:18,801 Epoch[26] Batch [400]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.106772,	
2017-06-27 16:12:27,025 Epoch[26] Batch [410]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.106723,	
2017-06-27 16:12:35,467 Epoch[26] Batch [420]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.106528,	
2017-06-27 16:12:44,220 Epoch[26] Batch [430]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.106415,	
2017-06-27 16:12:52,604 Epoch[26] Batch [440]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.106438,	
2017-06-27 16:13:01,386 Epoch[26] Batch [450]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.106184,	
2017-06-27 16:13:09,730 Epoch[26] Batch [460]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.106278,	
2017-06-27 16:13:18,272 Epoch[26] Batch [470]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.106151,	
2017-06-27 16:13:26,847 Epoch[26] Batch [480]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.106159,	
2017-06-27 16:13:34,788 Epoch[26] Batch [490]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.106322,	
2017-06-27 16:13:43,230 Epoch[26] Batch [500]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.106290,	
2017-06-27 16:13:50,792 Epoch[26] Batch [510]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.105990,	
2017-06-27 16:13:58,893 Epoch[26] Batch [520]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.106130,	
2017-06-27 16:14:06,937 Epoch[26] Batch [530]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.106174,	
2017-06-27 16:14:15,023 Epoch[26] Batch [540]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.106180,	
2017-06-27 16:14:23,199 Epoch[26] Batch [550]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.106401,	
2017-06-27 16:14:31,226 Epoch[26] Batch [560]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.106570,	
2017-06-27 16:14:39,353 Epoch[26] Batch [570]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.106434,	
2017-06-27 16:14:47,488 Epoch[26] Batch [580]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.106496,	
2017-06-27 16:14:55,923 Epoch[26] Batch [590]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.106414,	
2017-06-27 16:15:03,945 Epoch[26] Batch [600]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.106305,	
2017-06-27 16:15:12,179 Epoch[26] Batch [610]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.106488,	
2017-06-27 16:15:20,936 Epoch[26] Batch [620]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.106651,	
2017-06-27 16:15:30,558 Epoch[26] Batch [630]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.106525,	
2017-06-27 16:15:39,832 Epoch[26] Batch [640]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.106607,	
2017-06-27 16:15:49,428 Epoch[26] Batch [650]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.106652,	
2017-06-27 16:15:58,761 Epoch[26] Batch [660]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.106483,	
2017-06-27 16:16:08,722 Epoch[26] Batch [670]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.106512,	
2017-06-27 16:16:18,353 Epoch[26] Batch [680]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.106521,	
2017-06-27 16:16:27,511 Epoch[26] Batch [690]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.106655,	
2017-06-27 16:16:36,660 Epoch[26] Batch [700]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.106750,	
2017-06-27 16:16:45,989 Epoch[26] Batch [710]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.106632,	
2017-06-27 16:16:55,184 Epoch[26] Batch [720]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.106465,	
2017-06-27 16:17:04,192 Epoch[26] Batch [730]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.106317,	
2017-06-27 16:17:12,751 Epoch[26] Batch [740]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.106278,	
2017-06-27 16:17:21,381 Epoch[26] Batch [750]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.106319,	
2017-06-27 16:17:30,576 Epoch[26] Batch [760]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.106288,	
2017-06-27 16:17:39,896 Epoch[26] Batch [770]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.106078,	
2017-06-27 16:17:48,935 Epoch[26] Batch [780]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.106100,	
2017-06-27 16:17:57,334 Epoch[26] Batch [790]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.106086,	
2017-06-27 16:18:06,167 Epoch[26] Batch [800]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.106026,	
2017-06-27 16:18:15,278 Epoch[26] Batch [810]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.106021,	
2017-06-27 16:18:23,981 Epoch[26] Batch [820]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.106099,	
2017-06-27 16:18:32,303 Epoch[26] Batch [830]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.106028,	
2017-06-27 16:18:40,760 Epoch[26] Batch [840]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.105906,	
2017-06-27 16:18:49,009 Epoch[26] Batch [850]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.105961,	
2017-06-27 16:18:57,100 Epoch[26] Batch [860]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.105947,	
2017-06-27 16:19:05,485 Epoch[26] Batch [870]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.106039,	
2017-06-27 16:19:14,549 Epoch[26] Batch [880]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.105858,	
2017-06-27 16:19:23,504 Epoch[26] Batch [890]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.105924,	
2017-06-27 16:19:32,279 Epoch[26] Batch [900]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.105862,	
2017-06-27 16:19:41,412 Epoch[26] Batch [910]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.106049,	
2017-06-27 16:19:49,369 Epoch[26] Batch [920]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.106026,	
2017-06-27 16:19:57,617 Epoch[26] Batch [930]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.106077,	
2017-06-27 16:20:05,846 Epoch[26] Batch [940]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.106061,	
2017-06-27 16:20:13,532 Epoch[26] Batch [950]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.106040,	
2017-06-27 16:20:20,418 Epoch[26] Batch [960]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106050,	
2017-06-27 16:20:26,290 Epoch[26] Batch [970]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.105998,	
2017-06-27 16:20:32,317 Epoch[26] Batch [980]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.105977,	
2017-06-27 16:20:38,186 Epoch[26] Batch [990]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106006,	
2017-06-27 16:20:44,149 Epoch[26] Batch [1000]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105974,	
2017-06-27 16:20:50,335 Epoch[26] Batch [1010]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106056,	
2017-06-27 16:20:57,225 Epoch[26] Batch [1020]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106022,	
2017-06-27 16:21:02,999 Epoch[26] Batch [1030]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105995,	
2017-06-27 16:21:09,256 Epoch[26] Batch [1040]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.105939,	
2017-06-27 16:21:15,402 Epoch[26] Batch [1050]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.106034,	
2017-06-27 16:21:21,509 Epoch[26] Batch [1060]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106032,	
2017-06-27 16:21:27,498 Epoch[26] Batch [1070]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106157,	
2017-06-27 16:21:33,741 Epoch[26] Batch [1080]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106079,	
2017-06-27 16:21:39,298 Epoch[26] Batch [1090]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.106129,	
2017-06-27 16:21:45,431 Epoch[26] Batch [1100]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.106101,	
2017-06-27 16:21:51,650 Epoch[26] Batch [1110]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.106093,	
2017-06-27 16:21:57,960 Epoch[26] Batch [1120]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.106251,	
2017-06-27 16:22:03,678 Epoch[26] Batch [1130]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.106258,	
2017-06-27 16:22:09,961 Epoch[26] Batch [1140]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.106274,	
2017-06-27 16:22:15,512 Epoch[26] Batch [1150]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.106400,	
2017-06-27 16:22:21,290 Epoch[26] Batch [1160]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106537,	
2017-06-27 16:22:26,690 Epoch[26] Batch [1170]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.106560,	
2017-06-27 16:22:32,217 Epoch[26] Batch [1180]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.106525,	
2017-06-27 16:22:37,983 Epoch[26] Batch [1190]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106463,	
2017-06-27 16:22:43,713 Epoch[26] Batch [1200]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106455,	
2017-06-27 16:22:49,267 Epoch[26] Batch [1210]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.106449,	
2017-06-27 16:22:54,674 Epoch[26] Batch [1220]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.106445,	
2017-06-27 16:23:00,335 Epoch[26] Batch [1230]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.106462,	
2017-06-27 16:23:06,713 Epoch[26] Batch [1240]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.106422,	
2017-06-27 16:23:12,769 Epoch[26] Batch [1250]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106376,	
2017-06-27 16:23:19,222 Epoch[26] Batch [1260]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.106326,	
2017-06-27 16:23:25,902 Epoch[26] Batch [1270]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.106285,	
2017-06-27 16:23:32,990 Epoch[26] Batch [1280]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.106296,	
2017-06-27 16:23:40,117 Epoch[26] Batch [1290]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.106318,	
2017-06-27 16:23:47,331 Epoch[26] Batch [1300]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.106287,	
2017-06-27 16:23:55,046 Epoch[26] Batch [1310]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.106240,	
2017-06-27 16:24:03,221 Epoch[26] Batch [1320]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.106207,	
2017-06-27 16:24:10,825 Epoch[26] Batch [1330]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.106181,	
2017-06-27 16:24:18,461 Epoch[26] Batch [1340]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.106283,	
2017-06-27 16:24:26,357 Epoch[26] Batch [1350]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.106200,	
2017-06-27 16:24:34,623 Epoch[26] Batch [1360]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.106199,	
2017-06-27 16:24:42,833 Epoch[26] Batch [1370]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.106214,	
2017-06-27 16:24:51,108 Epoch[26] Batch [1380]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.106162,	
2017-06-27 16:24:59,005 Epoch[26] Batch [1390]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.106221,	
2017-06-27 16:25:06,363 Epoch[26] Batch [1400]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.106161,	
2017-06-27 16:25:14,125 Epoch[26] Batch [1410]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.106134,	
2017-06-27 16:25:21,937 Epoch[26] Batch [1420]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.106100,	
2017-06-27 16:25:29,578 Epoch[26] Batch [1430]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.106139,	
2017-06-27 16:25:37,167 Epoch[26] Batch [1440]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.106094,	
2017-06-27 16:25:44,760 Epoch[26] Batch [1450]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.106144,	
2017-06-27 16:25:52,656 Epoch[26] Batch [1460]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.106182,	
2017-06-27 16:26:00,385 Epoch[26] Batch [1470]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.106234,	
2017-06-27 16:26:08,196 Epoch[26] Batch [1480]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.106338,	
2017-06-27 16:26:13,066 Epoch[26] Train-FCNLogLoss=0.106311
2017-06-27 16:26:13,066 Epoch[26] Time cost=1130.551
2017-06-27 16:26:14,147 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0027.params"
2017-06-27 16:26:17,850 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0027.states"
2017-06-27 16:26:26,246 Epoch[27] Batch [10]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.101957,	
2017-06-27 16:26:33,986 Epoch[27] Batch [20]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.101287,	
2017-06-27 16:26:41,884 Epoch[27] Batch [30]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.100665,	
2017-06-27 16:26:49,636 Epoch[27] Batch [40]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.098861,	
2017-06-27 16:26:57,292 Epoch[27] Batch [50]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.100184,	
2017-06-27 16:27:05,146 Epoch[27] Batch [60]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.100268,	
2017-06-27 16:27:13,134 Epoch[27] Batch [70]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.104029,	
2017-06-27 16:27:21,222 Epoch[27] Batch [80]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.104120,	
2017-06-27 16:27:29,336 Epoch[27] Batch [90]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.104931,	
2017-06-27 16:27:36,969 Epoch[27] Batch [100]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.107067,	
2017-06-27 16:27:44,682 Epoch[27] Batch [110]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.107880,	
2017-06-27 16:27:52,573 Epoch[27] Batch [120]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.107908,	
2017-06-27 16:28:00,522 Epoch[27] Batch [130]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.106905,	
2017-06-27 16:28:08,818 Epoch[27] Batch [140]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.106848,	
2017-06-27 16:28:16,882 Epoch[27] Batch [150]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.107320,	
2017-06-27 16:28:24,955 Epoch[27] Batch [160]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.107443,	
2017-06-27 16:28:32,866 Epoch[27] Batch [170]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.107106,	
2017-06-27 16:28:40,998 Epoch[27] Batch [180]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.107295,	
2017-06-27 16:28:49,194 Epoch[27] Batch [190]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.107048,	
2017-06-27 16:28:56,946 Epoch[27] Batch [200]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.107048,	
2017-06-27 16:29:05,313 Epoch[27] Batch [210]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.106837,	
2017-06-27 16:29:13,470 Epoch[27] Batch [220]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.106743,	
2017-06-27 16:29:21,531 Epoch[27] Batch [230]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.106634,	
2017-06-27 16:29:29,521 Epoch[27] Batch [240]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.106870,	
2017-06-27 16:29:37,588 Epoch[27] Batch [250]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.107033,	
2017-06-27 16:29:45,700 Epoch[27] Batch [260]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.107270,	
2017-06-27 16:29:53,860 Epoch[27] Batch [270]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.107408,	
2017-06-27 16:30:02,233 Epoch[27] Batch [280]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.107463,	
2017-06-27 16:30:10,238 Epoch[27] Batch [290]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.107455,	
2017-06-27 16:30:18,430 Epoch[27] Batch [300]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.107066,	
2017-06-27 16:30:26,499 Epoch[27] Batch [310]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.106730,	
2017-06-27 16:30:34,389 Epoch[27] Batch [320]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.106383,	
2017-06-27 16:30:42,362 Epoch[27] Batch [330]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.106143,	
2017-06-27 16:30:50,337 Epoch[27] Batch [340]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.105970,	
2017-06-27 16:30:58,441 Epoch[27] Batch [350]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.105726,	
2017-06-27 16:31:06,905 Epoch[27] Batch [360]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.106083,	
2017-06-27 16:31:14,934 Epoch[27] Batch [370]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.105846,	
2017-06-27 16:31:23,132 Epoch[27] Batch [380]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.105803,	
2017-06-27 16:31:31,338 Epoch[27] Batch [390]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.105658,	
2017-06-27 16:31:39,865 Epoch[27] Batch [400]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.105608,	
2017-06-27 16:31:47,907 Epoch[27] Batch [410]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.105320,	
2017-06-27 16:31:56,322 Epoch[27] Batch [420]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.105387,	
2017-06-27 16:32:05,021 Epoch[27] Batch [430]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.105631,	
2017-06-27 16:32:13,723 Epoch[27] Batch [440]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.105829,	
2017-06-27 16:32:22,039 Epoch[27] Batch [450]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.106021,	
2017-06-27 16:32:30,315 Epoch[27] Batch [460]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.106422,	
2017-06-27 16:32:38,777 Epoch[27] Batch [470]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.106442,	
2017-06-27 16:32:47,062 Epoch[27] Batch [480]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.106457,	
2017-06-27 16:32:55,439 Epoch[27] Batch [490]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.106444,	
2017-06-27 16:33:03,344 Epoch[27] Batch [500]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.106372,	
2017-06-27 16:33:11,350 Epoch[27] Batch [510]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.106435,	
2017-06-27 16:33:19,307 Epoch[27] Batch [520]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.106103,	
2017-06-27 16:33:27,662 Epoch[27] Batch [530]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.105905,	
2017-06-27 16:33:35,807 Epoch[27] Batch [540]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.105854,	
2017-06-27 16:33:44,329 Epoch[27] Batch [550]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.106039,	
2017-06-27 16:33:50,799 Epoch[27] Batch [560]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.105967,	
2017-06-27 16:33:56,954 Epoch[27] Batch [570]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.105925,	
2017-06-27 16:34:03,198 Epoch[27] Batch [580]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106058,	
2017-06-27 16:34:09,303 Epoch[27] Batch [590]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106090,	
2017-06-27 16:34:15,365 Epoch[27] Batch [600]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106023,	
2017-06-27 16:34:20,967 Epoch[27] Batch [610]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.106204,	
2017-06-27 16:34:26,845 Epoch[27] Batch [620]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106141,	
2017-06-27 16:34:33,092 Epoch[27] Batch [630]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.106293,	
2017-06-27 16:34:38,982 Epoch[27] Batch [640]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106145,	
2017-06-27 16:34:45,296 Epoch[27] Batch [650]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.106428,	
2017-06-27 16:34:52,087 Epoch[27] Batch [660]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.106629,	
2017-06-27 16:34:58,916 Epoch[27] Batch [670]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.106540,	
2017-06-27 16:35:05,299 Epoch[27] Batch [680]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.106324,	
2017-06-27 16:35:12,016 Epoch[27] Batch [690]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.106102,	
2017-06-27 16:35:18,452 Epoch[27] Batch [700]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106194,	
2017-06-27 16:35:25,407 Epoch[27] Batch [710]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.106108,	
2017-06-27 16:35:31,891 Epoch[27] Batch [720]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.106086,	
2017-06-27 16:35:38,600 Epoch[27] Batch [730]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.105963,	
2017-06-27 16:35:44,733 Epoch[27] Batch [740]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.106063,	
2017-06-27 16:35:51,103 Epoch[27] Batch [750]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.106138,	
2017-06-27 16:35:57,537 Epoch[27] Batch [760]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106121,	
2017-06-27 16:36:04,355 Epoch[27] Batch [770]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.106018,	
2017-06-27 16:36:10,238 Epoch[27] Batch [780]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.106015,	
2017-06-27 16:36:16,667 Epoch[27] Batch [790]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106063,	
2017-06-27 16:36:24,205 Epoch[27] Batch [800]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.105989,	
2017-06-27 16:36:30,525 Epoch[27] Batch [810]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.106073,	
2017-06-27 16:36:37,561 Epoch[27] Batch [820]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.106167,	
2017-06-27 16:36:44,710 Epoch[27] Batch [830]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.106123,	
2017-06-27 16:36:51,159 Epoch[27] Batch [840]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.106083,	
2017-06-27 16:36:57,441 Epoch[27] Batch [850]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.106151,	
2017-06-27 16:37:04,021 Epoch[27] Batch [860]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.106192,	
2017-06-27 16:37:10,715 Epoch[27] Batch [870]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.106205,	
2017-06-27 16:37:17,279 Epoch[27] Batch [880]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.106188,	
2017-06-27 16:37:23,523 Epoch[27] Batch [890]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106270,	
2017-06-27 16:37:29,631 Epoch[27] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106537,	
2017-06-27 16:37:35,650 Epoch[27] Batch [910]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.106516,	
2017-06-27 16:37:41,905 Epoch[27] Batch [920]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.106532,	
2017-06-27 16:37:48,033 Epoch[27] Batch [930]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106508,	
2017-06-27 16:37:54,607 Epoch[27] Batch [940]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.107417,	
2017-06-27 16:38:00,737 Epoch[27] Batch [950]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.108075,	
2017-06-27 16:38:06,451 Epoch[27] Batch [960]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.108427,	
2017-06-27 16:38:12,705 Epoch[27] Batch [970]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.108787,	
2017-06-27 16:38:18,941 Epoch[27] Batch [980]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.108949,	
2017-06-27 16:38:25,151 Epoch[27] Batch [990]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.109027,	
2017-06-27 16:38:32,014 Epoch[27] Batch [1000]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.109113,	
2017-06-27 16:38:38,606 Epoch[27] Batch [1010]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.109125,	
2017-06-27 16:38:44,753 Epoch[27] Batch [1020]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.109165,	
2017-06-27 16:38:50,778 Epoch[27] Batch [1030]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.109198,	
2017-06-27 16:38:56,936 Epoch[27] Batch [1040]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.109156,	
2017-06-27 16:39:02,704 Epoch[27] Batch [1050]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.109152,	
2017-06-27 16:39:08,696 Epoch[27] Batch [1060]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.109094,	
2017-06-27 16:39:14,856 Epoch[27] Batch [1070]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.109143,	
2017-06-27 16:39:20,252 Epoch[27] Batch [1080]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.109163,	
2017-06-27 16:39:25,613 Epoch[27] Batch [1090]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.109198,	
2017-06-27 16:39:31,026 Epoch[27] Batch [1100]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.109123,	
2017-06-27 16:39:35,819 Epoch[27] Batch [1110]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.109278,	
2017-06-27 16:39:41,432 Epoch[27] Batch [1120]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.109258,	
2017-06-27 16:39:47,133 Epoch[27] Batch [1130]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.109283,	
2017-06-27 16:39:52,756 Epoch[27] Batch [1140]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.109199,	
2017-06-27 16:39:58,594 Epoch[27] Batch [1150]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.109159,	
2017-06-27 16:40:03,849 Epoch[27] Batch [1160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.109168,	
2017-06-27 16:40:09,381 Epoch[27] Batch [1170]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.109111,	
2017-06-27 16:40:14,605 Epoch[27] Batch [1180]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.109255,	
2017-06-27 16:40:20,329 Epoch[27] Batch [1190]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.109342,	
2017-06-27 16:40:26,235 Epoch[27] Batch [1200]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.109319,	
2017-06-27 16:40:32,676 Epoch[27] Batch [1210]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.109323,	
2017-06-27 16:40:39,588 Epoch[27] Batch [1220]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.109315,	
2017-06-27 16:40:46,525 Epoch[27] Batch [1230]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.109325,	
2017-06-27 16:40:54,012 Epoch[27] Batch [1240]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.109231,	
2017-06-27 16:41:01,719 Epoch[27] Batch [1250]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.109248,	
2017-06-27 16:41:09,782 Epoch[27] Batch [1260]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.109241,	
2017-06-27 16:41:18,087 Epoch[27] Batch [1270]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.109208,	
2017-06-27 16:41:26,847 Epoch[27] Batch [1280]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.109167,	
2017-06-27 16:41:35,652 Epoch[27] Batch [1290]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.109102,	
2017-06-27 16:41:44,528 Epoch[27] Batch [1300]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.109119,	
2017-06-27 16:41:53,007 Epoch[27] Batch [1310]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.108991,	
2017-06-27 16:42:02,067 Epoch[27] Batch [1320]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.108965,	
2017-06-27 16:42:11,093 Epoch[27] Batch [1330]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.108893,	
2017-06-27 16:42:19,876 Epoch[27] Batch [1340]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.108816,	
2017-06-27 16:42:28,694 Epoch[27] Batch [1350]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.108738,	
2017-06-27 16:42:38,000 Epoch[27] Batch [1360]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.108689,	
2017-06-27 16:42:47,313 Epoch[27] Batch [1370]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.108674,	
2017-06-27 16:42:56,912 Epoch[27] Batch [1380]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.108617,	
2017-06-27 16:43:06,019 Epoch[27] Batch [1390]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.108521,	
2017-06-27 16:43:14,562 Epoch[27] Batch [1400]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.108503,	
2017-06-27 16:43:22,403 Epoch[27] Batch [1410]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.108490,	
2017-06-27 16:43:30,524 Epoch[27] Batch [1420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.108475,	
2017-06-27 16:43:38,486 Epoch[27] Batch [1430]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.108396,	
2017-06-27 16:43:46,604 Epoch[27] Batch [1440]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.108375,	
2017-06-27 16:43:54,857 Epoch[27] Batch [1450]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.108419,	
2017-06-27 16:44:03,014 Epoch[27] Batch [1460]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.108402,	
2017-06-27 16:44:11,213 Epoch[27] Batch [1470]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.108379,	
2017-06-27 16:44:19,351 Epoch[27] Batch [1480]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.108419,	
2017-06-27 16:44:24,978 Epoch[27] Train-FCNLogLoss=0.108426
2017-06-27 16:44:24,979 Epoch[27] Time cost=1087.128
2017-06-27 16:44:26,019 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0028.params"
2017-06-27 16:44:29,632 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0028.states"
2017-06-27 16:44:38,836 Epoch[28] Batch [10]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.109014,	
2017-06-27 16:44:46,956 Epoch[28] Batch [20]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.105229,	
2017-06-27 16:44:55,386 Epoch[28] Batch [30]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.102798,	
2017-06-27 16:45:04,085 Epoch[28] Batch [40]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.102049,	
2017-06-27 16:45:12,089 Epoch[28] Batch [50]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.102791,	
2017-06-27 16:45:20,156 Epoch[28] Batch [60]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.102507,	
2017-06-27 16:45:28,391 Epoch[28] Batch [70]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.101717,	
2017-06-27 16:45:36,406 Epoch[28] Batch [80]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.103226,	
2017-06-27 16:45:44,237 Epoch[28] Batch [90]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.104011,	
2017-06-27 16:45:52,317 Epoch[28] Batch [100]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.103296,	
2017-06-27 16:46:00,241 Epoch[28] Batch [110]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.103074,	
2017-06-27 16:46:09,056 Epoch[28] Batch [120]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.103150,	
2017-06-27 16:46:17,270 Epoch[28] Batch [130]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.102776,	
2017-06-27 16:46:25,486 Epoch[28] Batch [140]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.102170,	
2017-06-27 16:46:33,508 Epoch[28] Batch [150]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.102576,	
2017-06-27 16:46:41,799 Epoch[28] Batch [160]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.102074,	
2017-06-27 16:46:50,209 Epoch[28] Batch [170]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.101835,	
2017-06-27 16:46:58,726 Epoch[28] Batch [180]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.101555,	
2017-06-27 16:47:07,863 Epoch[28] Batch [190]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.101724,	
2017-06-27 16:47:16,990 Epoch[28] Batch [200]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.102067,	
2017-06-27 16:47:25,835 Epoch[28] Batch [210]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.103114,	
2017-06-27 16:47:34,477 Epoch[28] Batch [220]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.102732,	
2017-06-27 16:47:43,063 Epoch[28] Batch [230]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.102201,	
2017-06-27 16:47:51,165 Epoch[28] Batch [240]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.101825,	
2017-06-27 16:47:59,123 Epoch[28] Batch [250]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.101916,	
2017-06-27 16:48:07,293 Epoch[28] Batch [260]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.102092,	
2017-06-27 16:48:15,790 Epoch[28] Batch [270]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.102771,	
2017-06-27 16:48:23,741 Epoch[28] Batch [280]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.103097,	
2017-06-27 16:48:32,764 Epoch[28] Batch [290]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.103358,	
2017-06-27 16:48:41,056 Epoch[28] Batch [300]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.103162,	
2017-06-27 16:48:49,319 Epoch[28] Batch [310]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.103509,	
2017-06-27 16:48:58,077 Epoch[28] Batch [320]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.103724,	
2017-06-27 16:49:07,014 Epoch[28] Batch [330]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.103713,	
2017-06-27 16:49:16,218 Epoch[28] Batch [340]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.103775,	
2017-06-27 16:49:25,002 Epoch[28] Batch [350]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.103905,	
2017-06-27 16:49:33,976 Epoch[28] Batch [360]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.104108,	
2017-06-27 16:49:42,569 Epoch[28] Batch [370]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.103852,	
2017-06-27 16:49:51,462 Epoch[28] Batch [380]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.103963,	
2017-06-27 16:50:00,260 Epoch[28] Batch [390]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.104215,	
2017-06-27 16:50:09,264 Epoch[28] Batch [400]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.104527,	
2017-06-27 16:50:17,860 Epoch[28] Batch [410]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.104473,	
2017-06-27 16:50:26,563 Epoch[28] Batch [420]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.104451,	
2017-06-27 16:50:35,144 Epoch[28] Batch [430]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.104411,	
2017-06-27 16:50:43,927 Epoch[28] Batch [440]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.104446,	
2017-06-27 16:50:52,799 Epoch[28] Batch [450]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.104408,	
2017-06-27 16:51:01,492 Epoch[28] Batch [460]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.104285,	
2017-06-27 16:51:10,210 Epoch[28] Batch [470]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.104429,	
2017-06-27 16:51:18,890 Epoch[28] Batch [480]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.104145,	
2017-06-27 16:51:28,008 Epoch[28] Batch [490]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.104267,	
2017-06-27 16:51:36,751 Epoch[28] Batch [500]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.104116,	
2017-06-27 16:51:46,076 Epoch[28] Batch [510]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.104015,	
2017-06-27 16:51:55,059 Epoch[28] Batch [520]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.104270,	
2017-06-27 16:52:03,871 Epoch[28] Batch [530]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.104277,	
2017-06-27 16:52:13,136 Epoch[28] Batch [540]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.104124,	
2017-06-27 16:52:21,833 Epoch[28] Batch [550]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.104465,	
2017-06-27 16:52:30,477 Epoch[28] Batch [560]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.104506,	
2017-06-27 16:52:39,494 Epoch[28] Batch [570]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.104461,	
2017-06-27 16:52:48,458 Epoch[28] Batch [580]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.104433,	
2017-06-27 16:52:57,273 Epoch[28] Batch [590]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.104541,	
2017-06-27 16:53:06,007 Epoch[28] Batch [600]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.104455,	
2017-06-27 16:53:14,999 Epoch[28] Batch [610]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.104429,	
2017-06-27 16:53:23,942 Epoch[28] Batch [620]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.104321,	
2017-06-27 16:53:32,268 Epoch[28] Batch [630]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.104410,	
2017-06-27 16:53:40,246 Epoch[28] Batch [640]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.104429,	
2017-06-27 16:53:48,648 Epoch[28] Batch [650]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.104583,	
2017-06-27 16:53:57,197 Epoch[28] Batch [660]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.104666,	
2017-06-27 16:54:05,420 Epoch[28] Batch [670]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.104823,	
2017-06-27 16:54:13,796 Epoch[28] Batch [680]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.104641,	
2017-06-27 16:54:22,210 Epoch[28] Batch [690]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.104610,	
2017-06-27 16:54:30,589 Epoch[28] Batch [700]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.104530,	
2017-06-27 16:54:38,912 Epoch[28] Batch [710]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.104500,	
2017-06-27 16:54:46,975 Epoch[28] Batch [720]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.104550,	
2017-06-27 16:54:55,675 Epoch[28] Batch [730]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.104406,	
2017-06-27 16:55:04,252 Epoch[28] Batch [740]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.104377,	
2017-06-27 16:55:12,546 Epoch[28] Batch [750]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.104355,	
2017-06-27 16:55:20,506 Epoch[28] Batch [760]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.104411,	
2017-06-27 16:55:28,700 Epoch[28] Batch [770]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.104414,	
2017-06-27 16:55:37,071 Epoch[28] Batch [780]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.104375,	
2017-06-27 16:55:45,355 Epoch[28] Batch [790]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.104525,	
2017-06-27 16:55:53,826 Epoch[28] Batch [800]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.104576,	
2017-06-27 16:56:02,381 Epoch[28] Batch [810]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.104563,	
2017-06-27 16:56:11,429 Epoch[28] Batch [820]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.104639,	
2017-06-27 16:56:21,038 Epoch[28] Batch [830]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.104632,	
2017-06-27 16:56:30,198 Epoch[28] Batch [840]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.104765,	
2017-06-27 16:56:39,563 Epoch[28] Batch [850]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.104804,	
2017-06-27 16:56:49,084 Epoch[28] Batch [860]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.104811,	
2017-06-27 16:56:58,953 Epoch[28] Batch [870]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.104721,	
2017-06-27 16:57:09,065 Epoch[28] Batch [880]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.104776,	
2017-06-27 16:57:18,395 Epoch[28] Batch [890]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.104698,	
2017-06-27 16:57:26,537 Epoch[28] Batch [900]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.104559,	
2017-06-27 16:57:34,608 Epoch[28] Batch [910]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.104536,	
2017-06-27 16:57:42,926 Epoch[28] Batch [920]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.104418,	
2017-06-27 16:57:51,485 Epoch[28] Batch [930]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.104564,	
2017-06-27 16:57:59,733 Epoch[28] Batch [940]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.104614,	
2017-06-27 16:58:07,751 Epoch[28] Batch [950]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.104506,	
2017-06-27 16:58:16,395 Epoch[28] Batch [960]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.104435,	
2017-06-27 16:58:24,827 Epoch[28] Batch [970]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.104547,	
2017-06-27 16:58:33,397 Epoch[28] Batch [980]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.104504,	
2017-06-27 16:58:43,269 Epoch[28] Batch [990]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.104472,	
2017-06-27 16:58:52,559 Epoch[28] Batch [1000]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.104469,	
2017-06-27 16:59:02,724 Epoch[28] Batch [1010]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.104449,	
2017-06-27 16:59:12,088 Epoch[28] Batch [1020]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.104447,	
2017-06-27 16:59:21,681 Epoch[28] Batch [1030]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.104529,	
2017-06-27 16:59:31,702 Epoch[28] Batch [1040]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.104477,	
2017-06-27 16:59:41,008 Epoch[28] Batch [1050]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.104405,	
2017-06-27 16:59:51,428 Epoch[28] Batch [1060]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.104497,	
2017-06-27 17:00:02,816 Epoch[28] Batch [1070]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.104401,	
2017-06-27 17:00:13,965 Epoch[28] Batch [1080]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.104372,	
2017-06-27 17:00:25,483 Epoch[28] Batch [1090]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.104388,	
2017-06-27 17:00:36,248 Epoch[28] Batch [1100]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.104427,	
2017-06-27 17:00:48,605 Epoch[28] Batch [1110]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.104356,	
2017-06-27 17:01:00,464 Epoch[28] Batch [1120]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.104315,	
2017-06-27 17:01:10,383 Epoch[28] Batch [1130]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.104259,	
2017-06-27 17:01:19,521 Epoch[28] Batch [1140]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.104209,	
2017-06-27 17:01:30,230 Epoch[28] Batch [1150]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.104346,	
2017-06-27 17:01:40,265 Epoch[28] Batch [1160]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.104230,	
2017-06-27 17:01:51,035 Epoch[28] Batch [1170]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.104217,	
2017-06-27 17:02:00,799 Epoch[28] Batch [1180]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.104212,	
2017-06-27 17:02:10,171 Epoch[28] Batch [1190]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.104254,	
2017-06-27 17:02:19,812 Epoch[28] Batch [1200]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.104231,	
2017-06-27 17:02:29,818 Epoch[28] Batch [1210]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.104226,	
2017-06-27 17:02:39,992 Epoch[28] Batch [1220]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.104169,	
2017-06-27 17:02:50,132 Epoch[28] Batch [1230]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.104079,	
2017-06-27 17:03:00,900 Epoch[28] Batch [1240]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.104172,	
2017-06-27 17:03:09,974 Epoch[28] Batch [1250]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.104112,	
2017-06-27 17:03:19,510 Epoch[28] Batch [1260]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.104009,	
2017-06-27 17:03:29,340 Epoch[28] Batch [1270]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.104007,	
2017-06-27 17:03:39,042 Epoch[28] Batch [1280]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.103976,	
2017-06-27 17:03:50,004 Epoch[28] Batch [1290]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.103980,	
2017-06-27 17:04:00,344 Epoch[28] Batch [1300]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.103931,	
2017-06-27 17:04:10,228 Epoch[28] Batch [1310]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.103850,	
2017-06-27 17:04:20,489 Epoch[28] Batch [1320]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.103806,	
2017-06-27 17:04:30,434 Epoch[28] Batch [1330]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.103836,	
2017-06-27 17:04:40,441 Epoch[28] Batch [1340]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.103849,	
2017-06-27 17:04:50,572 Epoch[28] Batch [1350]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.103810,	
2017-06-27 17:05:00,671 Epoch[28] Batch [1360]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.103780,	
2017-06-27 17:05:11,238 Epoch[28] Batch [1370]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.103686,	
2017-06-27 17:05:21,345 Epoch[28] Batch [1380]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.103675,	
2017-06-27 17:05:31,341 Epoch[28] Batch [1390]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.103652,	
2017-06-27 17:05:41,808 Epoch[28] Batch [1400]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.103600,	
2017-06-27 17:05:52,898 Epoch[28] Batch [1410]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.103569,	
2017-06-27 17:06:04,035 Epoch[28] Batch [1420]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.103501,	
2017-06-27 17:06:14,539 Epoch[28] Batch [1430]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.103508,	
2017-06-27 17:06:26,037 Epoch[28] Batch [1440]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.103504,	
2017-06-27 17:06:37,191 Epoch[28] Batch [1450]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.103457,	
2017-06-27 17:06:47,445 Epoch[28] Batch [1460]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.103472,	
2017-06-27 17:06:59,500 Epoch[28] Batch [1470]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.103602,	
2017-06-27 17:07:10,306 Epoch[28] Batch [1480]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.103570,	
2017-06-27 17:07:16,230 Epoch[28] Train-FCNLogLoss=0.103554
2017-06-27 17:07:16,230 Epoch[28] Time cost=1366.597
2017-06-27 17:07:20,783 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0029.params"
2017-06-27 17:07:26,517 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0029.states"
2017-06-27 17:07:38,081 Epoch[29] Batch [10]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.099097,	
2017-06-27 17:07:49,399 Epoch[29] Batch [20]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.102767,	
2017-06-27 17:07:59,999 Epoch[29] Batch [30]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.097004,	
2017-06-27 17:08:10,976 Epoch[29] Batch [40]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.102085,	
2017-06-27 17:08:22,070 Epoch[29] Batch [50]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.100986,	
2017-06-27 17:08:34,107 Epoch[29] Batch [60]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.101291,	
2017-06-27 17:08:45,226 Epoch[29] Batch [70]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.100831,	
2017-06-27 17:08:56,617 Epoch[29] Batch [80]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101394,	
2017-06-27 17:09:07,517 Epoch[29] Batch [90]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.101451,	
2017-06-27 17:09:19,255 Epoch[29] Batch [100]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.101172,	
2017-06-27 17:09:30,232 Epoch[29] Batch [110]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101940,	
2017-06-27 17:09:40,646 Epoch[29] Batch [120]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.103283,	
2017-06-27 17:09:51,529 Epoch[29] Batch [130]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.103131,	
2017-06-27 17:10:02,434 Epoch[29] Batch [140]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.103265,	
2017-06-27 17:10:14,012 Epoch[29] Batch [150]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.103081,	
2017-06-27 17:10:25,345 Epoch[29] Batch [160]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.102884,	
2017-06-27 17:10:35,983 Epoch[29] Batch [170]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.102935,	
2017-06-27 17:10:47,447 Epoch[29] Batch [180]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.103054,	
2017-06-27 17:10:58,355 Epoch[29] Batch [190]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.102481,	
2017-06-27 17:11:09,751 Epoch[29] Batch [200]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.102236,	
2017-06-27 17:11:20,274 Epoch[29] Batch [210]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.101751,	
2017-06-27 17:11:32,017 Epoch[29] Batch [220]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.101758,	
2017-06-27 17:11:43,312 Epoch[29] Batch [230]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.101350,	
2017-06-27 17:11:54,807 Epoch[29] Batch [240]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.101255,	
2017-06-27 17:12:05,516 Epoch[29] Batch [250]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.100941,	
2017-06-27 17:12:16,945 Epoch[29] Batch [260]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.101284,	
2017-06-27 17:12:28,113 Epoch[29] Batch [270]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.101453,	
2017-06-27 17:12:39,496 Epoch[29] Batch [280]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101389,	
2017-06-27 17:12:50,740 Epoch[29] Batch [290]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.101466,	
2017-06-27 17:13:01,677 Epoch[29] Batch [300]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.101812,	
2017-06-27 17:13:12,903 Epoch[29] Batch [310]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.101414,	
2017-06-27 17:13:24,072 Epoch[29] Batch [320]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.101700,	
2017-06-27 17:13:35,194 Epoch[29] Batch [330]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.101515,	
2017-06-27 17:13:45,730 Epoch[29] Batch [340]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.101454,	
2017-06-27 17:13:56,274 Epoch[29] Batch [350]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.101757,	
2017-06-27 17:14:07,024 Epoch[29] Batch [360]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.101730,	
2017-06-27 17:14:17,718 Epoch[29] Batch [370]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101724,	
2017-06-27 17:14:29,168 Epoch[29] Batch [380]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.101734,	
2017-06-27 17:14:40,081 Epoch[29] Batch [390]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.101835,	
2017-06-27 17:14:50,378 Epoch[29] Batch [400]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101953,	
2017-06-27 17:15:01,643 Epoch[29] Batch [410]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.101885,	
2017-06-27 17:15:12,641 Epoch[29] Batch [420]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101871,	
2017-06-27 17:15:22,482 Epoch[29] Batch [430]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.101643,	
2017-06-27 17:15:33,781 Epoch[29] Batch [440]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.101621,	
2017-06-27 17:15:43,883 Epoch[29] Batch [450]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.101510,	
2017-06-27 17:15:54,121 Epoch[29] Batch [460]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.101478,	
2017-06-27 17:16:04,957 Epoch[29] Batch [470]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.101588,	
2017-06-27 17:16:16,415 Epoch[29] Batch [480]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.101581,	
2017-06-27 17:16:27,090 Epoch[29] Batch [490]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.101573,	
2017-06-27 17:16:38,406 Epoch[29] Batch [500]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101629,	
2017-06-27 17:16:49,510 Epoch[29] Batch [510]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.101419,	
2017-06-27 17:17:00,876 Epoch[29] Batch [520]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.101404,	
2017-06-27 17:17:12,203 Epoch[29] Batch [530]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101474,	
2017-06-27 17:17:23,015 Epoch[29] Batch [540]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.101430,	
2017-06-27 17:17:34,451 Epoch[29] Batch [550]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.101226,	
2017-06-27 17:17:44,607 Epoch[29] Batch [560]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.101295,	
2017-06-27 17:17:55,593 Epoch[29] Batch [570]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101154,	
2017-06-27 17:18:06,331 Epoch[29] Batch [580]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.101316,	
2017-06-27 17:18:17,509 Epoch[29] Batch [590]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.101407,	
2017-06-27 17:18:27,077 Epoch[29] Batch [600]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.101540,	
2017-06-27 17:18:38,223 Epoch[29] Batch [610]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.101521,	
2017-06-27 17:18:48,460 Epoch[29] Batch [620]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.101323,	
2017-06-27 17:18:58,373 Epoch[29] Batch [630]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.101487,	
2017-06-27 17:19:08,689 Epoch[29] Batch [640]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101498,	
2017-06-27 17:19:19,543 Epoch[29] Batch [650]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.101552,	
2017-06-27 17:19:31,145 Epoch[29] Batch [660]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.101763,	
2017-06-27 17:19:42,251 Epoch[29] Batch [670]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.101718,	
2017-06-27 17:19:52,573 Epoch[29] Batch [680]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101768,	
2017-06-27 17:20:03,561 Epoch[29] Batch [690]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101606,	
2017-06-27 17:20:15,275 Epoch[29] Batch [700]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.101597,	
2017-06-27 17:20:26,143 Epoch[29] Batch [710]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101476,	
2017-06-27 17:20:36,492 Epoch[29] Batch [720]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.101463,	
2017-06-27 17:20:47,196 Epoch[29] Batch [730]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101495,	
2017-06-27 17:20:57,790 Epoch[29] Batch [740]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.101396,	
2017-06-27 17:21:08,680 Epoch[29] Batch [750]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.101472,	
2017-06-27 17:21:19,908 Epoch[29] Batch [760]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.101489,	
2017-06-27 17:21:30,650 Epoch[29] Batch [770]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.101424,	
2017-06-27 17:21:41,341 Epoch[29] Batch [780]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101370,	
2017-06-27 17:21:51,507 Epoch[29] Batch [790]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.101441,	
2017-06-27 17:22:01,529 Epoch[29] Batch [800]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.101455,	
2017-06-27 17:22:12,482 Epoch[29] Batch [810]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.101460,	
2017-06-27 17:22:22,637 Epoch[29] Batch [820]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.101633,	
2017-06-27 17:22:33,360 Epoch[29] Batch [830]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.101549,	
2017-06-27 17:22:42,964 Epoch[29] Batch [840]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.101638,	
2017-06-27 17:22:53,368 Epoch[29] Batch [850]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.101760,	
2017-06-27 17:23:04,406 Epoch[29] Batch [860]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.101783,	
2017-06-27 17:23:15,746 Epoch[29] Batch [870]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101764,	
2017-06-27 17:23:26,612 Epoch[29] Batch [880]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101685,	
2017-06-27 17:23:36,833 Epoch[29] Batch [890]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.101739,	
2017-06-27 17:23:47,473 Epoch[29] Batch [900]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.101744,	
2017-06-27 17:23:58,352 Epoch[29] Batch [910]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101829,	
2017-06-27 17:24:09,980 Epoch[29] Batch [920]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.101898,	
2017-06-27 17:24:20,407 Epoch[29] Batch [930]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.101913,	
2017-06-27 17:24:31,373 Epoch[29] Batch [940]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.101852,	
2017-06-27 17:24:42,591 Epoch[29] Batch [950]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.101700,	
2017-06-27 17:24:54,066 Epoch[29] Batch [960]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.101695,	
2017-06-27 17:25:05,050 Epoch[29] Batch [970]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101718,	
2017-06-27 17:25:16,433 Epoch[29] Batch [980]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101798,	
2017-06-27 17:25:27,880 Epoch[29] Batch [990]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.101723,	
2017-06-27 17:25:39,365 Epoch[29] Batch [1000]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.101673,	
2017-06-27 17:25:50,682 Epoch[29] Batch [1010]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101684,	
2017-06-27 17:26:02,153 Epoch[29] Batch [1020]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.101604,	
2017-06-27 17:26:12,489 Epoch[29] Batch [1030]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.101580,	
2017-06-27 17:26:24,517 Epoch[29] Batch [1040]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.101578,	
2017-06-27 17:26:34,953 Epoch[29] Batch [1050]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.101530,	
2017-06-27 17:26:45,425 Epoch[29] Batch [1060]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.101497,	
2017-06-27 17:26:56,795 Epoch[29] Batch [1070]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.101545,	
2017-06-27 17:27:07,196 Epoch[29] Batch [1080]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.101440,	
2017-06-27 17:27:18,190 Epoch[29] Batch [1090]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101441,	
2017-06-27 17:27:28,900 Epoch[29] Batch [1100]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.101514,	
2017-06-27 17:27:40,168 Epoch[29] Batch [1110]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.101505,	
2017-06-27 17:27:50,311 Epoch[29] Batch [1120]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.101518,	
2017-06-27 17:28:01,257 Epoch[29] Batch [1130]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101594,	
2017-06-27 17:28:11,778 Epoch[29] Batch [1140]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.101646,	
2017-06-27 17:28:22,760 Epoch[29] Batch [1150]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.101672,	
2017-06-27 17:28:34,266 Epoch[29] Batch [1160]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.101674,	
2017-06-27 17:28:45,376 Epoch[29] Batch [1170]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.101645,	
2017-06-27 17:28:55,365 Epoch[29] Batch [1180]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.101602,	
2017-06-27 17:29:07,738 Epoch[29] Batch [1190]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.101592,	
2017-06-27 17:29:20,476 Epoch[29] Batch [1200]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.101699,	
2017-06-27 17:29:32,419 Epoch[29] Batch [1210]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.101715,	
2017-06-27 17:29:44,738 Epoch[29] Batch [1220]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.101799,	
2017-06-27 17:29:56,041 Epoch[29] Batch [1230]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.101811,	
2017-06-27 17:30:07,323 Epoch[29] Batch [1240]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.101870,	
2017-06-27 17:30:18,505 Epoch[29] Batch [1250]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.101989,	
2017-06-27 17:30:29,624 Epoch[29] Batch [1260]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.101952,	
2017-06-27 17:30:41,033 Epoch[29] Batch [1270]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101896,	
2017-06-27 17:30:51,907 Epoch[29] Batch [1280]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101818,	
2017-06-27 17:31:03,349 Epoch[29] Batch [1290]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.101802,	
2017-06-27 17:31:16,039 Epoch[29] Batch [1300]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.101875,	
2017-06-27 17:31:26,544 Epoch[29] Batch [1310]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.101884,	
2017-06-27 17:31:37,129 Epoch[29] Batch [1320]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.101823,	
2017-06-27 17:31:49,240 Epoch[29] Batch [1330]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.101749,	
2017-06-27 17:31:59,832 Epoch[29] Batch [1340]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.101737,	
2017-06-27 17:32:10,981 Epoch[29] Batch [1350]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.101713,	
2017-06-27 17:32:22,890 Epoch[29] Batch [1360]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.101711,	
2017-06-27 17:32:33,786 Epoch[29] Batch [1370]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.101694,	
2017-06-27 17:32:45,198 Epoch[29] Batch [1380]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101652,	
2017-06-27 17:32:56,891 Epoch[29] Batch [1390]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.101690,	
2017-06-27 17:33:07,741 Epoch[29] Batch [1400]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.101706,	
2017-06-27 17:33:18,432 Epoch[29] Batch [1410]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101742,	
2017-06-27 17:33:29,316 Epoch[29] Batch [1420]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.101722,	
2017-06-27 17:33:39,878 Epoch[29] Batch [1430]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.102014,	
2017-06-27 17:33:51,412 Epoch[29] Batch [1440]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.102012,	
2017-06-27 17:34:02,420 Epoch[29] Batch [1450]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.102093,	
2017-06-27 17:34:14,276 Epoch[29] Batch [1460]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.102064,	
2017-06-27 17:34:25,514 Epoch[29] Batch [1470]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.102076,	
2017-06-27 17:34:37,054 Epoch[29] Batch [1480]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.102112,	
2017-06-27 17:34:43,944 Epoch[29] Train-FCNLogLoss=0.102118
2017-06-27 17:34:43,945 Epoch[29] Time cost=1637.111
2017-06-27 17:34:48,283 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0030.params"
2017-06-27 17:34:53,501 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0030.states"
2017-06-27 17:35:06,953 Epoch[30] Batch [10]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.115555,	
2017-06-27 17:35:17,295 Epoch[30] Batch [20]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.111681,	
2017-06-27 17:35:29,249 Epoch[30] Batch [30]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.109202,	
2017-06-27 17:35:40,997 Epoch[30] Batch [40]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.108514,	
2017-06-27 17:35:52,643 Epoch[30] Batch [50]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.107032,	
2017-06-27 17:36:03,080 Epoch[30] Batch [60]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.106125,	
2017-06-27 17:36:14,237 Epoch[30] Batch [70]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.105255,	
2017-06-27 17:36:25,063 Epoch[30] Batch [80]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.103642,	
2017-06-27 17:36:36,002 Epoch[30] Batch [90]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.102907,	
2017-06-27 17:36:47,194 Epoch[30] Batch [100]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.101331,	
2017-06-27 17:36:58,911 Epoch[30] Batch [110]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.101219,	
2017-06-27 17:37:09,671 Epoch[30] Batch [120]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.101258,	
2017-06-27 17:37:20,563 Epoch[30] Batch [130]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.102353,	
2017-06-27 17:37:30,892 Epoch[30] Batch [140]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.102571,	
2017-06-27 17:37:42,545 Epoch[30] Batch [150]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.103926,	
2017-06-27 17:37:53,957 Epoch[30] Batch [160]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.103611,	
2017-06-27 17:38:05,421 Epoch[30] Batch [170]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.103013,	
2017-06-27 17:38:17,013 Epoch[30] Batch [180]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.103454,	
2017-06-27 17:38:28,171 Epoch[30] Batch [190]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.103322,	
2017-06-27 17:38:39,063 Epoch[30] Batch [200]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.102958,	
2017-06-27 17:38:49,952 Epoch[30] Batch [210]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.103004,	
2017-06-27 17:39:00,904 Epoch[30] Batch [220]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.103174,	
2017-06-27 17:39:12,557 Epoch[30] Batch [230]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.102814,	
2017-06-27 17:39:24,200 Epoch[30] Batch [240]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.102659,	
2017-06-27 17:39:36,852 Epoch[30] Batch [250]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.102849,	
2017-06-27 17:39:48,439 Epoch[30] Batch [260]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.102518,	
2017-06-27 17:39:59,170 Epoch[30] Batch [270]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.102542,	
2017-06-27 17:40:09,507 Epoch[30] Batch [280]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.102711,	
2017-06-27 17:40:20,338 Epoch[30] Batch [290]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.102702,	
2017-06-27 17:40:31,161 Epoch[30] Batch [300]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.102743,	
2017-06-27 17:40:42,988 Epoch[30] Batch [310]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.102475,	
2017-06-27 17:40:54,642 Epoch[30] Batch [320]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.102738,	
2017-06-27 17:41:06,609 Epoch[30] Batch [330]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.102640,	
2017-06-27 17:41:17,441 Epoch[30] Batch [340]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.102536,	
2017-06-27 17:41:27,855 Epoch[30] Batch [350]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.102303,	
2017-06-27 17:41:38,983 Epoch[30] Batch [360]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.102274,	
2017-06-27 17:41:49,314 Epoch[30] Batch [370]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.102085,	
2017-06-27 17:41:59,922 Epoch[30] Batch [380]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.101949,	
2017-06-27 17:42:10,241 Epoch[30] Batch [390]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101796,	
2017-06-27 17:42:21,573 Epoch[30] Batch [400]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101498,	
2017-06-27 17:42:32,017 Epoch[30] Batch [410]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.101449,	
2017-06-27 17:42:42,217 Epoch[30] Batch [420]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.101605,	
2017-06-27 17:42:54,263 Epoch[30] Batch [430]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.101730,	
2017-06-27 17:43:06,151 Epoch[30] Batch [440]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.101544,	
2017-06-27 17:43:16,755 Epoch[30] Batch [450]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.101784,	
2017-06-27 17:43:29,075 Epoch[30] Batch [460]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.101647,	
2017-06-27 17:43:39,838 Epoch[30] Batch [470]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.101642,	
2017-06-27 17:43:51,354 Epoch[30] Batch [480]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.101640,	
2017-06-27 17:44:02,820 Epoch[30] Batch [490]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.101778,	
2017-06-27 17:44:13,977 Epoch[30] Batch [500]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.101764,	
2017-06-27 17:44:24,977 Epoch[30] Batch [510]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101705,	
2017-06-27 17:44:35,335 Epoch[30] Batch [520]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.101620,	
2017-06-27 17:44:46,333 Epoch[30] Batch [530]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101659,	
2017-06-27 17:44:58,481 Epoch[30] Batch [540]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.101750,	
2017-06-27 17:45:10,964 Epoch[30] Batch [550]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.101519,	
2017-06-27 17:45:22,295 Epoch[30] Batch [560]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101662,	
2017-06-27 17:45:34,563 Epoch[30] Batch [570]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.101779,	
2017-06-27 17:45:47,661 Epoch[30] Batch [580]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.101818,	
2017-06-27 17:45:59,774 Epoch[30] Batch [590]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.101694,	
2017-06-27 17:46:11,031 Epoch[30] Batch [600]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.101662,	
2017-06-27 17:46:23,126 Epoch[30] Batch [610]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.102038,	
2017-06-27 17:46:34,899 Epoch[30] Batch [620]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.101908,	
2017-06-27 17:46:46,435 Epoch[30] Batch [630]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.102017,	
2017-06-27 17:46:58,331 Epoch[30] Batch [640]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.102024,	
2017-06-27 17:47:10,474 Epoch[30] Batch [650]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.101945,	
2017-06-27 17:47:22,364 Epoch[30] Batch [660]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.102119,	
2017-06-27 17:47:33,330 Epoch[30] Batch [670]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.102222,	
2017-06-27 17:47:44,476 Epoch[30] Batch [680]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.102170,	
2017-06-27 17:47:54,942 Epoch[30] Batch [690]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.102257,	
2017-06-27 17:48:06,431 Epoch[30] Batch [700]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.102093,	
2017-06-27 17:48:17,565 Epoch[30] Batch [710]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.102138,	
2017-06-27 17:48:28,784 Epoch[30] Batch [720]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.102147,	
2017-06-27 17:48:40,438 Epoch[30] Batch [730]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.102273,	
2017-06-27 17:48:51,680 Epoch[30] Batch [740]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.102275,	
2017-06-27 17:49:02,951 Epoch[30] Batch [750]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.102237,	
2017-06-27 17:49:14,571 Epoch[30] Batch [760]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.102338,	
2017-06-27 17:49:25,006 Epoch[30] Batch [770]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.102352,	
2017-06-27 17:49:36,755 Epoch[30] Batch [780]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.102360,	
2017-06-27 17:49:47,704 Epoch[30] Batch [790]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.102289,	
2017-06-27 17:49:57,776 Epoch[30] Batch [800]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.102235,	
2017-06-27 17:50:08,502 Epoch[30] Batch [810]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.102213,	
2017-06-27 17:50:19,133 Epoch[30] Batch [820]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.102117,	
2017-06-27 17:50:29,954 Epoch[30] Batch [830]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.101966,	
2017-06-27 17:50:40,836 Epoch[30] Batch [840]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101822,	
2017-06-27 17:50:50,895 Epoch[30] Batch [850]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.101818,	
2017-06-27 17:51:02,221 Epoch[30] Batch [860]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101817,	
2017-06-27 17:51:12,543 Epoch[30] Batch [870]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101809,	
2017-06-27 17:51:23,468 Epoch[30] Batch [880]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101719,	
2017-06-27 17:51:34,252 Epoch[30] Batch [890]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.101732,	
2017-06-27 17:51:44,815 Epoch[30] Batch [900]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.101684,	
2017-06-27 17:51:55,425 Epoch[30] Batch [910]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.101780,	
2017-06-27 17:52:05,993 Epoch[30] Batch [920]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.101747,	
2017-06-27 17:52:17,378 Epoch[30] Batch [930]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101700,	
2017-06-27 17:52:29,223 Epoch[30] Batch [940]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.101582,	
2017-06-27 17:52:39,908 Epoch[30] Batch [950]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101701,	
2017-06-27 17:52:49,932 Epoch[30] Batch [960]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.101694,	
2017-06-27 17:53:00,598 Epoch[30] Batch [970]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.101800,	
2017-06-27 17:53:11,205 Epoch[30] Batch [980]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.101691,	
2017-06-27 17:53:21,224 Epoch[30] Batch [990]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.101697,	
2017-06-27 17:53:31,879 Epoch[30] Batch [1000]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.101663,	
2017-06-27 17:53:42,130 Epoch[30] Batch [1010]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.101574,	
2017-06-27 17:53:53,215 Epoch[30] Batch [1020]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.101746,	
2017-06-27 17:54:03,538 Epoch[30] Batch [1030]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101768,	
2017-06-27 17:54:13,723 Epoch[30] Batch [1040]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.101795,	
2017-06-27 17:54:23,694 Epoch[30] Batch [1050]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.101597,	
2017-06-27 17:54:34,767 Epoch[30] Batch [1060]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.101602,	
2017-06-27 17:54:45,149 Epoch[30] Batch [1070]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.101676,	
2017-06-27 17:54:54,955 Epoch[30] Batch [1080]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.101697,	
2017-06-27 17:55:05,108 Epoch[30] Batch [1090]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.101714,	
2017-06-27 17:55:15,532 Epoch[30] Batch [1100]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.101654,	
2017-06-27 17:55:25,670 Epoch[30] Batch [1110]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.101711,	
2017-06-27 17:55:35,982 Epoch[30] Batch [1120]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101797,	
2017-06-27 17:55:46,513 Epoch[30] Batch [1130]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.101741,	
2017-06-27 17:55:57,167 Epoch[30] Batch [1140]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.101732,	
2017-06-27 17:56:07,480 Epoch[30] Batch [1150]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101641,	
2017-06-27 17:56:17,694 Epoch[30] Batch [1160]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.101703,	
2017-06-27 17:56:29,065 Epoch[30] Batch [1170]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.101687,	
2017-06-27 17:56:39,097 Epoch[30] Batch [1180]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.101621,	
2017-06-27 17:56:49,855 Epoch[30] Batch [1190]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.101596,	
2017-06-27 17:57:00,596 Epoch[30] Batch [1200]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.101497,	
2017-06-27 17:57:10,641 Epoch[30] Batch [1210]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.101514,	
2017-06-27 17:57:22,887 Epoch[30] Batch [1220]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.101531,	
2017-06-27 17:57:33,769 Epoch[30] Batch [1230]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101492,	
2017-06-27 17:57:43,796 Epoch[30] Batch [1240]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.101466,	
2017-06-27 17:57:54,960 Epoch[30] Batch [1250]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.101450,	
2017-06-27 17:58:05,795 Epoch[30] Batch [1260]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.101557,	
2017-06-27 17:58:16,291 Epoch[30] Batch [1270]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.101529,	
2017-06-27 17:58:28,043 Epoch[30] Batch [1280]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.101587,	
2017-06-27 17:58:40,159 Epoch[30] Batch [1290]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.101504,	
2017-06-27 17:58:51,568 Epoch[30] Batch [1300]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101476,	
2017-06-27 17:59:02,411 Epoch[30] Batch [1310]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.101419,	
2017-06-27 17:59:13,397 Epoch[30] Batch [1320]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101532,	
2017-06-27 17:59:24,826 Epoch[30] Batch [1330]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.101524,	
2017-06-27 17:59:35,144 Epoch[30] Batch [1340]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.101502,	
2017-06-27 17:59:46,169 Epoch[30] Batch [1350]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.101462,	
2017-06-27 17:59:57,730 Epoch[30] Batch [1360]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.101380,	
2017-06-27 18:00:09,441 Epoch[30] Batch [1370]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.101406,	
2017-06-27 18:00:20,119 Epoch[30] Batch [1380]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.101404,	
2017-06-27 18:00:30,964 Epoch[30] Batch [1390]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.101510,	
2017-06-27 18:00:42,442 Epoch[30] Batch [1400]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.101500,	
2017-06-27 18:00:54,712 Epoch[30] Batch [1410]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.101420,	
2017-06-27 18:01:06,635 Epoch[30] Batch [1420]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.101382,	
2017-06-27 18:01:18,387 Epoch[30] Batch [1430]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.101342,	
2017-06-27 18:01:29,891 Epoch[30] Batch [1440]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.101249,	
2017-06-27 18:01:40,443 Epoch[30] Batch [1450]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.101207,	
2017-06-27 18:01:52,104 Epoch[30] Batch [1460]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.101211,	
2017-06-27 18:02:04,649 Epoch[30] Batch [1470]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.101230,	
2017-06-27 18:02:16,600 Epoch[30] Batch [1480]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.101259,	
2017-06-27 18:02:23,745 Epoch[30] Train-FCNLogLoss=0.101209
2017-06-27 18:02:23,746 Epoch[30] Time cost=1649.991
2017-06-27 18:02:35,863 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0031.params"
2017-06-27 18:02:46,507 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0031.states"
2017-06-27 18:02:58,976 Epoch[31] Batch [10]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.099067,	
2017-06-27 18:03:10,343 Epoch[31] Batch [20]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.096747,	
2017-06-27 18:03:21,157 Epoch[31] Batch [30]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.095800,	
2017-06-27 18:03:31,987 Epoch[31] Batch [40]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.095679,	
2017-06-27 18:03:43,461 Epoch[31] Batch [50]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.095636,	
2017-06-27 18:03:55,307 Epoch[31] Batch [60]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.099608,	
2017-06-27 18:04:06,416 Epoch[31] Batch [70]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.098939,	
2017-06-27 18:04:17,874 Epoch[31] Batch [80]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.099694,	
2017-06-27 18:04:29,259 Epoch[31] Batch [90]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.100232,	
2017-06-27 18:04:41,656 Epoch[31] Batch [100]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.099460,	
2017-06-27 18:04:52,326 Epoch[31] Batch [110]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.099698,	
2017-06-27 18:05:03,665 Epoch[31] Batch [120]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.101039,	
2017-06-27 18:05:14,836 Epoch[31] Batch [130]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.101697,	
2017-06-27 18:05:26,542 Epoch[31] Batch [140]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.101466,	
2017-06-27 18:05:37,676 Epoch[31] Batch [150]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.101328,	
2017-06-27 18:05:50,568 Epoch[31] Batch [160]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.100681,	
2017-06-27 18:06:02,944 Epoch[31] Batch [170]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.100743,	
2017-06-27 18:06:13,987 Epoch[31] Batch [180]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.101092,	
2017-06-27 18:06:25,386 Epoch[31] Batch [190]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.101128,	
2017-06-27 18:06:36,814 Epoch[31] Batch [200]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.100998,	
2017-06-27 18:06:47,530 Epoch[31] Batch [210]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.100647,	
2017-06-27 18:06:59,531 Epoch[31] Batch [220]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.100016,	
2017-06-27 18:07:11,425 Epoch[31] Batch [230]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.100157,	
2017-06-27 18:07:21,841 Epoch[31] Batch [240]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.100378,	
2017-06-27 18:07:32,266 Epoch[31] Batch [250]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.100375,	
2017-06-27 18:07:43,062 Epoch[31] Batch [260]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.100710,	
2017-06-27 18:07:54,089 Epoch[31] Batch [270]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.100498,	
2017-06-27 18:08:04,589 Epoch[31] Batch [280]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.100849,	
2017-06-27 18:08:14,826 Epoch[31] Batch [290]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.100582,	
2017-06-27 18:08:25,897 Epoch[31] Batch [300]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.100522,	
2017-06-27 18:08:35,840 Epoch[31] Batch [310]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.100446,	
2017-06-27 18:08:46,233 Epoch[31] Batch [320]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.100726,	
2017-06-27 18:08:56,593 Epoch[31] Batch [330]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.100674,	
2017-06-27 18:09:07,593 Epoch[31] Batch [340]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101096,	
2017-06-27 18:09:17,814 Epoch[31] Batch [350]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.101019,	
2017-06-27 18:09:28,758 Epoch[31] Batch [360]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.100749,	
2017-06-27 18:09:39,826 Epoch[31] Batch [370]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.100873,	
2017-06-27 18:09:50,777 Epoch[31] Batch [380]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.101034,	
2017-06-27 18:10:00,726 Epoch[31] Batch [390]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.100991,	
2017-06-27 18:10:11,597 Epoch[31] Batch [400]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101104,	
2017-06-27 18:10:22,512 Epoch[31] Batch [410]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.100836,	
2017-06-27 18:10:32,832 Epoch[31] Batch [420]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.100709,	
2017-06-27 18:10:42,892 Epoch[31] Batch [430]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.100801,	
2017-06-27 18:10:53,843 Epoch[31] Batch [440]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.100826,	
2017-06-27 18:11:04,711 Epoch[31] Batch [450]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.101018,	
2017-06-27 18:11:15,100 Epoch[31] Batch [460]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.101174,	
2017-06-27 18:11:26,148 Epoch[31] Batch [470]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.101378,	
2017-06-27 18:11:36,132 Epoch[31] Batch [480]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.101562,	
2017-06-27 18:11:46,933 Epoch[31] Batch [490]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.101555,	
2017-06-27 18:11:57,624 Epoch[31] Batch [500]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101529,	
2017-06-27 18:12:07,265 Epoch[31] Batch [510]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.101438,	
2017-06-27 18:12:17,133 Epoch[31] Batch [520]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.101157,	
2017-06-27 18:12:27,914 Epoch[31] Batch [530]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.101164,	
2017-06-27 18:12:38,241 Epoch[31] Batch [540]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.101037,	
2017-06-27 18:12:49,244 Epoch[31] Batch [550]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.100922,	
2017-06-27 18:12:59,777 Epoch[31] Batch [560]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.100789,	
2017-06-27 18:13:10,771 Epoch[31] Batch [570]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.100881,	
2017-06-27 18:13:22,908 Epoch[31] Batch [580]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.100823,	
2017-06-27 18:13:33,724 Epoch[31] Batch [590]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.100845,	
2017-06-27 18:13:44,950 Epoch[31] Batch [600]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.100788,	
2017-06-27 18:13:55,211 Epoch[31] Batch [610]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.100608,	
2017-06-27 18:14:06,099 Epoch[31] Batch [620]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.100637,	
2017-06-27 18:14:17,036 Epoch[31] Batch [630]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.100667,	
2017-06-27 18:14:27,527 Epoch[31] Batch [640]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.100731,	
2017-06-27 18:14:37,406 Epoch[31] Batch [650]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.100659,	
2017-06-27 18:14:48,555 Epoch[31] Batch [660]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.100553,	
2017-06-27 18:14:58,945 Epoch[31] Batch [670]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.100397,	
2017-06-27 18:15:08,923 Epoch[31] Batch [680]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.100221,	
2017-06-27 18:15:19,436 Epoch[31] Batch [690]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.100255,	
2017-06-27 18:15:29,066 Epoch[31] Batch [700]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.100197,	
2017-06-27 18:15:40,060 Epoch[31] Batch [710]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.100095,	
2017-06-27 18:15:50,697 Epoch[31] Batch [720]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.100144,	
2017-06-27 18:16:01,490 Epoch[31] Batch [730]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.100092,	
2017-06-27 18:16:11,505 Epoch[31] Batch [740]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.100099,	
2017-06-27 18:16:21,787 Epoch[31] Batch [750]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.100281,	
2017-06-27 18:16:31,506 Epoch[31] Batch [760]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.100221,	
2017-06-27 18:16:41,701 Epoch[31] Batch [770]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.100178,	
2017-06-27 18:16:52,055 Epoch[31] Batch [780]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.100121,	
2017-06-27 18:17:03,171 Epoch[31] Batch [790]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.100037,	
2017-06-27 18:17:13,815 Epoch[31] Batch [800]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.100127,	
2017-06-27 18:17:24,284 Epoch[31] Batch [810]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.100092,	
2017-06-27 18:17:35,422 Epoch[31] Batch [820]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.100161,	
2017-06-27 18:17:46,137 Epoch[31] Batch [830]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.100273,	
2017-06-27 18:17:57,338 Epoch[31] Batch [840]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.100197,	
2017-06-27 18:18:08,230 Epoch[31] Batch [850]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.100079,	
2017-06-27 18:18:19,758 Epoch[31] Batch [860]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.100122,	
2017-06-27 18:18:30,360 Epoch[31] Batch [870]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.100131,	
2017-06-27 18:18:41,273 Epoch[31] Batch [880]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.100020,	
2017-06-27 18:18:51,269 Epoch[31] Batch [890]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.099979,	
2017-06-27 18:19:01,333 Epoch[31] Batch [900]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.099858,	
2017-06-27 18:19:11,543 Epoch[31] Batch [910]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.099851,	
2017-06-27 18:19:21,513 Epoch[31] Batch [920]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.099806,	
2017-06-27 18:19:32,327 Epoch[31] Batch [930]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.099852,	
2017-06-27 18:19:42,687 Epoch[31] Batch [940]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.099787,	
2017-06-27 18:19:53,020 Epoch[31] Batch [950]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.099712,	
2017-06-27 18:20:02,802 Epoch[31] Batch [960]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.099645,	
2017-06-27 18:20:13,554 Epoch[31] Batch [970]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.099570,	
2017-06-27 18:20:24,100 Epoch[31] Batch [980]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.099567,	
2017-06-27 18:20:35,614 Epoch[31] Batch [990]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.099619,	
2017-06-27 18:20:47,047 Epoch[31] Batch [1000]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.099574,	
2017-06-27 18:20:58,606 Epoch[31] Batch [1010]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.099535,	
2017-06-27 18:21:09,348 Epoch[31] Batch [1020]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.099554,	
2017-06-27 18:21:19,669 Epoch[31] Batch [1030]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.099546,	
2017-06-27 18:21:29,934 Epoch[31] Batch [1040]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.099708,	
2017-06-27 18:21:42,050 Epoch[31] Batch [1050]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.099795,	
2017-06-27 18:21:53,027 Epoch[31] Batch [1060]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.099720,	
2017-06-27 18:22:04,764 Epoch[31] Batch [1070]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.099703,	
2017-06-27 18:22:15,858 Epoch[31] Batch [1080]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.099791,	
2017-06-27 18:22:26,547 Epoch[31] Batch [1090]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.099829,	
2017-06-27 18:22:37,353 Epoch[31] Batch [1100]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.099819,	
2017-06-27 18:22:48,179 Epoch[31] Batch [1110]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.099888,	
2017-06-27 18:22:59,744 Epoch[31] Batch [1120]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.099847,	
2017-06-27 18:23:11,574 Epoch[31] Batch [1130]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.099782,	
2017-06-27 18:23:22,777 Epoch[31] Batch [1140]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.099732,	
2017-06-27 18:23:34,537 Epoch[31] Batch [1150]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.099722,	
2017-06-27 18:23:45,883 Epoch[31] Batch [1160]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.099763,	
2017-06-27 18:23:56,131 Epoch[31] Batch [1170]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.099802,	
2017-06-27 18:24:06,719 Epoch[31] Batch [1180]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.099748,	
2017-06-27 18:24:17,821 Epoch[31] Batch [1190]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.099765,	
2017-06-27 18:24:29,132 Epoch[31] Batch [1200]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.099775,	
2017-06-27 18:24:40,475 Epoch[31] Batch [1210]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.099871,	
2017-06-27 18:24:51,673 Epoch[31] Batch [1220]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.099855,	
2017-06-27 18:25:02,594 Epoch[31] Batch [1230]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.099810,	
2017-06-27 18:25:13,072 Epoch[31] Batch [1240]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.099913,	
2017-06-27 18:25:23,973 Epoch[31] Batch [1250]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-27 18:25:34,425 Epoch[31] Batch [1260]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.099995,	
2017-06-27 18:25:45,459 Epoch[31] Batch [1270]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.099990,	
2017-06-27 18:25:55,488 Epoch[31] Batch [1280]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.099972,	
2017-06-27 18:26:06,431 Epoch[31] Batch [1290]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.099994,	
2017-06-27 18:26:17,691 Epoch[31] Batch [1300]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.099945,	
2017-06-27 18:26:28,685 Epoch[31] Batch [1310]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.099896,	
2017-06-27 18:26:40,397 Epoch[31] Batch [1320]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.099965,	
2017-06-27 18:26:51,445 Epoch[31] Batch [1330]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.100016,	
2017-06-27 18:27:03,567 Epoch[31] Batch [1340]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.100026,	
2017-06-27 18:27:14,129 Epoch[31] Batch [1350]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.100011,	
2017-06-27 18:27:25,845 Epoch[31] Batch [1360]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.099982,	
2017-06-27 18:27:36,980 Epoch[31] Batch [1370]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.099980,	
2017-06-27 18:27:47,830 Epoch[31] Batch [1380]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.099949,	
2017-06-27 18:27:59,241 Epoch[31] Batch [1390]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.099908,	
2017-06-27 18:28:10,171 Epoch[31] Batch [1400]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.099846,	
2017-06-27 18:28:21,159 Epoch[31] Batch [1410]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.099921,	
2017-06-27 18:28:32,575 Epoch[31] Batch [1420]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-27 18:28:43,440 Epoch[31] Batch [1430]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.099875,	
2017-06-27 18:28:55,436 Epoch[31] Batch [1440]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.099851,	
2017-06-27 18:29:07,757 Epoch[31] Batch [1450]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.099862,	
2017-06-27 18:29:20,193 Epoch[31] Batch [1460]	Speed: 3.22 samples/sec	Train-FCNLogLoss=0.099919,	
2017-06-27 18:29:30,515 Epoch[31] Batch [1470]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.099842,	
2017-06-27 18:29:41,913 Epoch[31] Batch [1480]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.099882,	
2017-06-27 18:29:48,433 Epoch[31] Train-FCNLogLoss=0.099854
2017-06-27 18:29:48,434 Epoch[31] Time cost=1621.783
2017-06-27 18:29:57,049 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0032.params"
2017-06-27 18:30:04,328 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0032.states"
2017-06-27 18:30:17,345 Epoch[32] Batch [10]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.094996,	
2017-06-27 18:30:28,679 Epoch[32] Batch [20]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.104741,	
2017-06-27 18:30:41,670 Epoch[32] Batch [30]	Speed: 3.08 samples/sec	Train-FCNLogLoss=0.103080,	
2017-06-27 18:30:54,438 Epoch[32] Batch [40]	Speed: 3.13 samples/sec	Train-FCNLogLoss=0.099874,	
2017-06-27 18:31:05,951 Epoch[32] Batch [50]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.099358,	
2017-06-27 18:31:17,964 Epoch[32] Batch [60]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.101928,	
2017-06-27 18:31:29,176 Epoch[32] Batch [70]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.102866,	
2017-06-27 18:31:41,370 Epoch[32] Batch [80]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.101848,	
2017-06-27 18:31:53,653 Epoch[32] Batch [90]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.101764,	
2017-06-27 18:32:04,848 Epoch[32] Batch [100]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.101159,	
2017-06-27 18:32:15,823 Epoch[32] Batch [110]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101510,	
2017-06-27 18:32:27,614 Epoch[32] Batch [120]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.105401,	
2017-06-27 18:32:39,047 Epoch[32] Batch [130]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.108236,	
2017-06-27 18:32:50,699 Epoch[32] Batch [140]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.110206,	
2017-06-27 18:33:01,711 Epoch[32] Batch [150]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.111752,	
2017-06-27 18:33:12,845 Epoch[32] Batch [160]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.112598,	
2017-06-27 18:33:23,827 Epoch[32] Batch [170]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.112453,	
2017-06-27 18:33:38,611 Epoch[32] Batch [180]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.112788,	
2017-06-27 18:33:51,004 Epoch[32] Batch [190]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.112483,	
2017-06-27 18:34:02,593 Epoch[32] Batch [200]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.111806,	
2017-06-27 18:34:13,466 Epoch[32] Batch [210]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.111636,	
2017-06-27 18:34:25,582 Epoch[32] Batch [220]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.111614,	
2017-06-27 18:34:37,938 Epoch[32] Batch [230]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.111253,	
2017-06-27 18:34:49,446 Epoch[32] Batch [240]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.111249,	
2017-06-27 18:35:01,255 Epoch[32] Batch [250]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.111443,	
2017-06-27 18:35:12,622 Epoch[32] Batch [260]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.110979,	
2017-06-27 18:35:23,755 Epoch[32] Batch [270]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.110819,	
2017-06-27 18:35:35,535 Epoch[32] Batch [280]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.109805,	
2017-06-27 18:35:48,089 Epoch[32] Batch [290]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.109596,	
2017-06-27 18:35:59,860 Epoch[32] Batch [300]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.109246,	
2017-06-27 18:36:13,386 Epoch[32] Batch [310]	Speed: 2.98 samples/sec	Train-FCNLogLoss=0.109064,	
2017-06-27 18:36:24,905 Epoch[32] Batch [320]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.108631,	
2017-06-27 18:36:36,463 Epoch[32] Batch [330]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.108222,	
2017-06-27 18:36:47,849 Epoch[32] Batch [340]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.108119,	
2017-06-27 18:37:01,554 Epoch[32] Batch [350]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.107679,	
2017-06-27 18:37:12,387 Epoch[32] Batch [360]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.107797,	
2017-06-27 18:37:22,941 Epoch[32] Batch [370]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.107470,	
2017-06-27 18:37:34,850 Epoch[32] Batch [380]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.107175,	
2017-06-27 18:37:45,643 Epoch[32] Batch [390]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.107099,	
2017-06-27 18:37:56,952 Epoch[32] Batch [400]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.106767,	
2017-06-27 18:38:09,425 Epoch[32] Batch [410]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.106574,	
2017-06-27 18:38:21,753 Epoch[32] Batch [420]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.106296,	
2017-06-27 18:38:36,430 Epoch[32] Batch [430]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.106117,	
2017-06-27 18:38:51,102 Epoch[32] Batch [440]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.105842,	
2017-06-27 18:39:05,065 Epoch[32] Batch [450]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.105551,	
2017-06-27 18:39:17,272 Epoch[32] Batch [460]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.105302,	
2017-06-27 18:39:28,161 Epoch[32] Batch [470]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.104952,	
2017-06-27 18:39:41,132 Epoch[32] Batch [480]	Speed: 3.08 samples/sec	Train-FCNLogLoss=0.104669,	
2017-06-27 18:39:55,321 Epoch[32] Batch [490]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.104751,	
2017-06-27 18:40:06,221 Epoch[32] Batch [500]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.104839,	
2017-06-27 18:40:17,787 Epoch[32] Batch [510]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.104622,	
2017-06-27 18:40:30,100 Epoch[32] Batch [520]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.104351,	
2017-06-27 18:40:42,066 Epoch[32] Batch [530]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.104437,	
2017-06-27 18:40:53,689 Epoch[32] Batch [540]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.104321,	
2017-06-27 18:41:05,338 Epoch[32] Batch [550]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.104168,	
2017-06-27 18:41:16,878 Epoch[32] Batch [560]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.103899,	
2017-06-27 18:41:28,508 Epoch[32] Batch [570]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.103813,	
2017-06-27 18:41:40,277 Epoch[32] Batch [580]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.103701,	
2017-06-27 18:41:52,360 Epoch[32] Batch [590]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.103635,	
2017-06-27 18:42:03,874 Epoch[32] Batch [600]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.103735,	
2017-06-27 18:42:15,201 Epoch[32] Batch [610]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.103589,	
2017-06-27 18:42:27,344 Epoch[32] Batch [620]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.103669,	
2017-06-27 18:42:39,061 Epoch[32] Batch [630]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.103734,	
2017-06-27 18:42:49,443 Epoch[32] Batch [640]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.103756,	
2017-06-27 18:43:00,779 Epoch[32] Batch [650]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.103748,	
2017-06-27 18:43:13,688 Epoch[32] Batch [660]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.103645,	
2017-06-27 18:43:25,322 Epoch[32] Batch [670]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.103695,	
2017-06-27 18:43:37,347 Epoch[32] Batch [680]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.103727,	
2017-06-27 18:43:48,962 Epoch[32] Batch [690]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.103520,	
2017-06-27 18:44:01,593 Epoch[32] Batch [700]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.103468,	
2017-06-27 18:44:13,423 Epoch[32] Batch [710]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.103416,	
2017-06-27 18:44:25,157 Epoch[32] Batch [720]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.103402,	
2017-06-27 18:44:37,645 Epoch[32] Batch [730]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.103204,	
2017-06-27 18:44:49,436 Epoch[32] Batch [740]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.103036,	
2017-06-27 18:45:01,152 Epoch[32] Batch [750]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.103071,	
2017-06-27 18:45:12,081 Epoch[32] Batch [760]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.102844,	
2017-06-27 18:45:26,072 Epoch[32] Batch [770]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.102728,	
2017-06-27 18:45:36,381 Epoch[32] Batch [780]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.102652,	
2017-06-27 18:45:47,243 Epoch[32] Batch [790]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.102515,	
2017-06-27 18:45:57,538 Epoch[32] Batch [800]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.102346,	
2017-06-27 18:46:09,375 Epoch[32] Batch [810]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.102403,	
2017-06-27 18:46:19,998 Epoch[32] Batch [820]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.102554,	
2017-06-27 18:46:32,367 Epoch[32] Batch [830]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.102635,	
2017-06-27 18:46:43,428 Epoch[32] Batch [840]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.102648,	
2017-06-27 18:46:54,398 Epoch[32] Batch [850]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.102574,	
2017-06-27 18:47:05,644 Epoch[32] Batch [860]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.102572,	
2017-06-27 18:47:16,359 Epoch[32] Batch [870]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.102519,	
2017-06-27 18:47:28,267 Epoch[32] Batch [880]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.102375,	
2017-06-27 18:47:39,043 Epoch[32] Batch [890]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.102274,	
2017-06-27 18:47:49,876 Epoch[32] Batch [900]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.102083,	
2017-06-27 18:47:59,961 Epoch[32] Batch [910]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.102055,	
2017-06-27 18:48:12,127 Epoch[32] Batch [920]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.102021,	
2017-06-27 18:48:23,605 Epoch[32] Batch [930]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.101953,	
2017-06-27 18:48:35,232 Epoch[32] Batch [940]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.101920,	
2017-06-27 18:48:47,072 Epoch[32] Batch [950]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.102023,	
2017-06-27 18:48:58,358 Epoch[32] Batch [960]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.102049,	
2017-06-27 18:49:10,065 Epoch[32] Batch [970]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.101982,	
2017-06-27 18:49:21,708 Epoch[32] Batch [980]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.101949,	
2017-06-27 18:49:37,257 Epoch[32] Batch [990]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.101999,	
2017-06-27 18:49:46,835 Epoch[32] Batch [1000]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.102016,	
2017-06-27 18:49:57,035 Epoch[32] Batch [1010]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.102093,	
2017-06-27 18:50:07,833 Epoch[32] Batch [1020]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.102033,	
2017-06-27 18:50:19,106 Epoch[32] Batch [1030]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.102097,	
2017-06-27 18:50:32,060 Epoch[32] Batch [1040]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.102056,	
2017-06-27 18:50:42,682 Epoch[32] Batch [1050]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.102029,	
2017-06-27 18:50:53,741 Epoch[32] Batch [1060]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.101942,	
2017-06-27 18:51:06,069 Epoch[32] Batch [1070]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.101892,	
2017-06-27 18:51:17,363 Epoch[32] Batch [1080]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.101856,	
2017-06-27 18:51:28,806 Epoch[32] Batch [1090]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.101799,	
2017-06-27 18:51:40,060 Epoch[32] Batch [1100]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.101789,	
2017-06-27 18:51:50,742 Epoch[32] Batch [1110]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101857,	
2017-06-27 18:52:01,824 Epoch[32] Batch [1120]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.101802,	
2017-06-27 18:52:12,664 Epoch[32] Batch [1130]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.101740,	
2017-06-27 18:52:23,375 Epoch[32] Batch [1140]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.101711,	
2017-06-27 18:52:39,781 Epoch[32] Batch [1150]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.101703,	
2017-06-27 18:52:49,807 Epoch[32] Batch [1160]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.101730,	
2017-06-27 18:52:59,780 Epoch[32] Batch [1170]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.101643,	
2017-06-27 18:53:08,527 Epoch[32] Batch [1180]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.101601,	
2017-06-27 18:53:17,465 Epoch[32] Batch [1190]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.101555,	
2017-06-27 18:53:27,717 Epoch[32] Batch [1200]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.101580,	
2017-06-27 18:53:39,453 Epoch[32] Batch [1210]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.101447,	
2017-06-27 18:53:50,363 Epoch[32] Batch [1220]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.101467,	
2017-06-27 18:54:01,055 Epoch[32] Batch [1230]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101370,	
2017-06-27 18:54:11,822 Epoch[32] Batch [1240]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.101419,	
2017-06-27 18:54:23,475 Epoch[32] Batch [1250]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.101525,	
2017-06-27 18:54:33,864 Epoch[32] Batch [1260]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.101538,	
2017-06-27 18:54:44,537 Epoch[32] Batch [1270]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.101588,	
2017-06-27 18:54:55,244 Epoch[32] Batch [1280]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101434,	
2017-06-27 18:55:05,709 Epoch[32] Batch [1290]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.101424,	
2017-06-27 18:55:16,939 Epoch[32] Batch [1300]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.101452,	
2017-06-27 18:55:27,713 Epoch[32] Batch [1310]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.101464,	
2017-06-27 18:55:41,352 Epoch[32] Batch [1320]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.101355,	
2017-06-27 18:55:51,935 Epoch[32] Batch [1330]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.101347,	
2017-06-27 18:56:03,564 Epoch[32] Batch [1340]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.101336,	
2017-06-27 18:56:14,381 Epoch[32] Batch [1350]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.101319,	
2017-06-27 18:56:30,573 Epoch[32] Batch [1360]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.101290,	
2017-06-27 18:56:41,566 Epoch[32] Batch [1370]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.101249,	
2017-06-27 18:56:51,212 Epoch[32] Batch [1380]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.101156,	
2017-06-27 18:57:01,282 Epoch[32] Batch [1390]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.101152,	
2017-06-27 18:57:13,148 Epoch[32] Batch [1400]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.101130,	
2017-06-27 18:57:23,831 Epoch[32] Batch [1410]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.101098,	
2017-06-27 18:57:34,342 Epoch[32] Batch [1420]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.101094,	
2017-06-27 18:57:44,107 Epoch[32] Batch [1430]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.101169,	
2017-06-27 18:57:54,241 Epoch[32] Batch [1440]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.101141,	
2017-06-27 18:58:04,417 Epoch[32] Batch [1450]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.101060,	
2017-06-27 18:58:15,623 Epoch[32] Batch [1460]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.100990,	
2017-06-27 18:58:26,994 Epoch[32] Batch [1470]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.100943,	
2017-06-27 18:58:38,716 Epoch[32] Batch [1480]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.100860,	
2017-06-27 18:58:45,689 Epoch[32] Train-FCNLogLoss=0.100815
2017-06-27 18:58:45,690 Epoch[32] Time cost=1720.924
2017-06-27 18:59:09,190 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0033.params"
2017-06-27 18:59:17,320 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0033.states"
2017-06-27 18:59:29,457 Epoch[33] Batch [10]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.101147,	
2017-06-27 18:59:39,869 Epoch[33] Batch [20]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.098193,	
2017-06-27 18:59:50,023 Epoch[33] Batch [30]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.097798,	
2017-06-27 19:00:00,810 Epoch[33] Batch [40]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.098011,	
2017-06-27 19:00:14,689 Epoch[33] Batch [50]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.098985,	
2017-06-27 19:00:25,550 Epoch[33] Batch [60]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.098869,	
2017-06-27 19:00:37,051 Epoch[33] Batch [70]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.099058,	
2017-06-27 19:00:48,032 Epoch[33] Batch [80]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.099092,	
2017-06-27 19:00:58,881 Epoch[33] Batch [90]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.097985,	
2017-06-27 19:01:09,121 Epoch[33] Batch [100]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.098030,	
2017-06-27 19:01:20,095 Epoch[33] Batch [110]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.097571,	
2017-06-27 19:01:30,697 Epoch[33] Batch [120]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.098226,	
2017-06-27 19:01:42,873 Epoch[33] Batch [130]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.098596,	
2017-06-27 19:01:53,126 Epoch[33] Batch [140]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.099122,	
2017-06-27 19:02:03,910 Epoch[33] Batch [150]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.099083,	
2017-06-27 19:02:16,452 Epoch[33] Batch [160]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.099502,	
2017-06-27 19:02:27,560 Epoch[33] Batch [170]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.100212,	
2017-06-27 19:02:39,449 Epoch[33] Batch [180]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.100148,	
2017-06-27 19:02:50,109 Epoch[33] Batch [190]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.100880,	
2017-06-27 19:03:00,834 Epoch[33] Batch [200]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.101105,	
2017-06-27 19:03:11,855 Epoch[33] Batch [210]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.101089,	
2017-06-27 19:03:23,299 Epoch[33] Batch [220]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.101234,	
2017-06-27 19:03:34,188 Epoch[33] Batch [230]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.101343,	
2017-06-27 19:03:44,101 Epoch[33] Batch [240]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.101196,	
2017-06-27 19:03:55,600 Epoch[33] Batch [250]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.101071,	
2017-06-27 19:04:09,443 Epoch[33] Batch [260]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.100566,	
2017-06-27 19:04:19,972 Epoch[33] Batch [270]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.100163,	
2017-06-27 19:04:31,217 Epoch[33] Batch [280]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.099967,	
2017-06-27 19:04:42,391 Epoch[33] Batch [290]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.099714,	
2017-06-27 19:04:54,188 Epoch[33] Batch [300]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.099622,	
2017-06-27 19:05:05,724 Epoch[33] Batch [310]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.099837,	
2017-06-27 19:05:17,128 Epoch[33] Batch [320]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.099494,	
2017-06-27 19:05:28,531 Epoch[33] Batch [330]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.099548,	
2017-06-27 19:05:38,216 Epoch[33] Batch [340]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.099377,	
2017-06-27 19:05:48,431 Epoch[33] Batch [350]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.099056,	
2017-06-27 19:05:59,998 Epoch[33] Batch [360]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.099141,	
2017-06-27 19:06:11,210 Epoch[33] Batch [370]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.099454,	
2017-06-27 19:06:22,328 Epoch[33] Batch [380]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.099480,	
2017-06-27 19:06:32,986 Epoch[33] Batch [390]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.099519,	
2017-06-27 19:06:44,355 Epoch[33] Batch [400]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.099264,	
2017-06-27 19:06:55,965 Epoch[33] Batch [410]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.099285,	
2017-06-27 19:07:06,351 Epoch[33] Batch [420]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.099132,	
2017-06-27 19:07:18,643 Epoch[33] Batch [430]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.099137,	
2017-06-27 19:07:29,063 Epoch[33] Batch [440]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.099144,	
2017-06-27 19:07:39,943 Epoch[33] Batch [450]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.098823,	
2017-06-27 19:07:51,345 Epoch[33] Batch [460]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.098785,	
2017-06-27 19:08:02,415 Epoch[33] Batch [470]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.098687,	
2017-06-27 19:08:13,884 Epoch[33] Batch [480]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.098680,	
2017-06-27 19:08:25,189 Epoch[33] Batch [490]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.098554,	
2017-06-27 19:08:36,509 Epoch[33] Batch [500]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.098473,	
2017-06-27 19:08:48,208 Epoch[33] Batch [510]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.098479,	
2017-06-27 19:09:00,676 Epoch[33] Batch [520]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.098392,	
2017-06-27 19:09:11,468 Epoch[33] Batch [530]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.098513,	
2017-06-27 19:09:22,486 Epoch[33] Batch [540]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.098645,	
2017-06-27 19:09:33,290 Epoch[33] Batch [550]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.098575,	
2017-06-27 19:09:47,149 Epoch[33] Batch [560]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.098637,	
2017-06-27 19:09:58,319 Epoch[33] Batch [570]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.098565,	
2017-06-27 19:10:08,213 Epoch[33] Batch [580]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.098523,	
2017-06-27 19:10:18,836 Epoch[33] Batch [590]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.098552,	
2017-06-27 19:10:28,911 Epoch[33] Batch [600]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.098364,	
2017-06-27 19:10:39,775 Epoch[33] Batch [610]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.098292,	
2017-06-27 19:10:49,674 Epoch[33] Batch [620]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.098222,	
2017-06-27 19:11:00,664 Epoch[33] Batch [630]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.098179,	
2017-06-27 19:11:11,105 Epoch[33] Batch [640]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.097934,	
2017-06-27 19:11:26,126 Epoch[33] Batch [650]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.097841,	
2017-06-27 19:11:37,492 Epoch[33] Batch [660]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.097890,	
2017-06-27 19:11:47,686 Epoch[33] Batch [670]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.097826,	
2017-06-27 19:11:58,372 Epoch[33] Batch [680]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.097774,	
2017-06-27 19:12:09,920 Epoch[33] Batch [690]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.097668,	
2017-06-27 19:12:20,940 Epoch[33] Batch [700]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.097824,	
2017-06-27 19:12:32,380 Epoch[33] Batch [710]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.097939,	
2017-06-27 19:12:46,854 Epoch[33] Batch [720]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.098000,	
2017-06-27 19:12:57,189 Epoch[33] Batch [730]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.097981,	
2017-06-27 19:13:07,570 Epoch[33] Batch [740]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.097950,	
2017-06-27 19:13:19,102 Epoch[33] Batch [750]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.097879,	
2017-06-27 19:13:30,208 Epoch[33] Batch [760]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.097859,	
2017-06-27 19:13:42,459 Epoch[33] Batch [770]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.097896,	
2017-06-27 19:13:54,218 Epoch[33] Batch [780]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.097855,	
2017-06-27 19:14:05,231 Epoch[33] Batch [790]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.097844,	
2017-06-27 19:14:16,080 Epoch[33] Batch [800]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.097761,	
2017-06-27 19:14:27,395 Epoch[33] Batch [810]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.097816,	
2017-06-27 19:14:39,083 Epoch[33] Batch [820]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.097756,	
2017-06-27 19:14:48,767 Epoch[33] Batch [830]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.097696,	
2017-06-27 19:15:00,236 Epoch[33] Batch [840]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.097641,	
2017-06-27 19:15:10,929 Epoch[33] Batch [850]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.097567,	
2017-06-27 19:15:21,914 Epoch[33] Batch [860]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.097746,	
2017-06-27 19:15:32,428 Epoch[33] Batch [870]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.097808,	
2017-06-27 19:15:42,562 Epoch[33] Batch [880]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.097858,	
2017-06-27 19:15:54,042 Epoch[33] Batch [890]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.097985,	
2017-06-27 19:16:05,649 Epoch[33] Batch [900]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.097979,	
2017-06-27 19:16:16,912 Epoch[33] Batch [910]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.098047,	
2017-06-27 19:16:28,510 Epoch[33] Batch [920]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.098089,	
2017-06-27 19:16:39,991 Epoch[33] Batch [930]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.098084,	
2017-06-27 19:16:51,920 Epoch[33] Batch [940]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.098035,	
2017-06-27 19:17:03,788 Epoch[33] Batch [950]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.098105,	
2017-06-27 19:17:14,475 Epoch[33] Batch [960]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.098105,	
2017-06-27 19:17:25,270 Epoch[33] Batch [970]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.098018,	
2017-06-27 19:17:36,742 Epoch[33] Batch [980]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.097964,	
2017-06-27 19:17:47,631 Epoch[33] Batch [990]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.097943,	
2017-06-27 19:17:59,192 Epoch[33] Batch [1000]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.098055,	
2017-06-27 19:18:09,699 Epoch[33] Batch [1010]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.098076,	
2017-06-27 19:18:20,118 Epoch[33] Batch [1020]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.098213,	
2017-06-27 19:18:31,261 Epoch[33] Batch [1030]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.098207,	
2017-06-27 19:18:42,433 Epoch[33] Batch [1040]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.098140,	
2017-06-27 19:18:53,323 Epoch[33] Batch [1050]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.098151,	
2017-06-27 19:19:04,992 Epoch[33] Batch [1060]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.098172,	
2017-06-27 19:19:16,521 Epoch[33] Batch [1070]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.098194,	
2017-06-27 19:19:26,340 Epoch[33] Batch [1080]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.098230,	
2017-06-27 19:19:38,742 Epoch[33] Batch [1090]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.098316,	
2017-06-27 19:19:49,763 Epoch[33] Batch [1100]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.098221,	
2017-06-27 19:20:00,183 Epoch[33] Batch [1110]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.098256,	
2017-06-27 19:20:11,396 Epoch[33] Batch [1120]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.098205,	
2017-06-27 19:20:22,450 Epoch[33] Batch [1130]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.098259,	
2017-06-27 19:20:34,627 Epoch[33] Batch [1140]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.098223,	
2017-06-27 19:20:44,449 Epoch[33] Batch [1150]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.098202,	
2017-06-27 19:20:54,830 Epoch[33] Batch [1160]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.098175,	
2017-06-27 19:21:05,022 Epoch[33] Batch [1170]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.098117,	
2017-06-27 19:21:16,361 Epoch[33] Batch [1180]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.098258,	
2017-06-27 19:21:27,770 Epoch[33] Batch [1190]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.098270,	
2017-06-27 19:21:40,057 Epoch[33] Batch [1200]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.098253,	
2017-06-27 19:21:53,679 Epoch[33] Batch [1210]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.098225,	
2017-06-27 19:22:05,352 Epoch[33] Batch [1220]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.098234,	
2017-06-27 19:22:14,796 Epoch[33] Batch [1230]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.098231,	
2017-06-27 19:22:25,279 Epoch[33] Batch [1240]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.098232,	
2017-06-27 19:22:35,642 Epoch[33] Batch [1250]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.098179,	
2017-06-27 19:22:46,411 Epoch[33] Batch [1260]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.098197,	
2017-06-27 19:22:57,708 Epoch[33] Batch [1270]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.098233,	
2017-06-27 19:23:08,481 Epoch[33] Batch [1280]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.098178,	
2017-06-27 19:23:20,158 Epoch[33] Batch [1290]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.098103,	
2017-06-27 19:23:30,891 Epoch[33] Batch [1300]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.098064,	
2017-06-27 19:23:40,802 Epoch[33] Batch [1310]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.098061,	
2017-06-27 19:23:51,625 Epoch[33] Batch [1320]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.098006,	
2017-06-27 19:24:02,928 Epoch[33] Batch [1330]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.098041,	
2017-06-27 19:24:13,734 Epoch[33] Batch [1340]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.098040,	
2017-06-27 19:24:24,719 Epoch[33] Batch [1350]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.098070,	
2017-06-27 19:24:36,374 Epoch[33] Batch [1360]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.098024,	
2017-06-27 19:24:47,440 Epoch[33] Batch [1370]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.097964,	
2017-06-27 19:24:58,692 Epoch[33] Batch [1380]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.097905,	
2017-06-27 19:25:08,874 Epoch[33] Batch [1390]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.097911,	
2017-06-27 19:25:19,855 Epoch[33] Batch [1400]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.097840,	
2017-06-27 19:25:31,566 Epoch[33] Batch [1410]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.097804,	
2017-06-27 19:25:42,933 Epoch[33] Batch [1420]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.097748,	
2017-06-27 19:25:53,542 Epoch[33] Batch [1430]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.097741,	
2017-06-27 19:26:05,301 Epoch[33] Batch [1440]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.097702,	
2017-06-27 19:26:16,673 Epoch[33] Batch [1450]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.097730,	
2017-06-27 19:26:27,175 Epoch[33] Batch [1460]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.097716,	
2017-06-27 19:26:38,643 Epoch[33] Batch [1470]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.097707,	
2017-06-27 19:26:50,060 Epoch[33] Batch [1480]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.097658,	
2017-06-27 19:26:56,715 Epoch[33] Train-FCNLogLoss=0.097684
2017-06-27 19:26:56,715 Epoch[33] Time cost=1659.048
2017-06-27 19:27:02,605 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0034.params"
2017-06-27 19:27:15,705 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0034.states"
2017-06-27 19:27:27,353 Epoch[34] Batch [10]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.098993,	
2017-06-27 19:27:38,193 Epoch[34] Batch [20]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.095588,	
2017-06-27 19:27:48,414 Epoch[34] Batch [30]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.097766,	
2017-06-27 19:27:58,565 Epoch[34] Batch [40]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.096539,	
2017-06-27 19:28:10,037 Epoch[34] Batch [50]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.097915,	
2017-06-27 19:28:20,651 Epoch[34] Batch [60]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.096188,	
2017-06-27 19:28:32,016 Epoch[34] Batch [70]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.096379,	
2017-06-27 19:28:43,340 Epoch[34] Batch [80]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.095656,	
2017-06-27 19:28:55,702 Epoch[34] Batch [90]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.096924,	
2017-06-27 19:29:07,287 Epoch[34] Batch [100]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.097016,	
2017-06-27 19:29:18,575 Epoch[34] Batch [110]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.097172,	
2017-06-27 19:29:29,710 Epoch[34] Batch [120]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.096505,	
2017-06-27 19:29:41,862 Epoch[34] Batch [130]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.096861,	
2017-06-27 19:29:53,745 Epoch[34] Batch [140]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.095764,	
2017-06-27 19:30:04,468 Epoch[34] Batch [150]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.095403,	
2017-06-27 19:30:15,833 Epoch[34] Batch [160]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.094757,	
2017-06-27 19:30:28,735 Epoch[34] Batch [170]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.094771,	
2017-06-27 19:30:39,863 Epoch[34] Batch [180]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.095204,	
2017-06-27 19:30:50,664 Epoch[34] Batch [190]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.095539,	
2017-06-27 19:31:01,523 Epoch[34] Batch [200]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.095529,	
2017-06-27 19:31:12,217 Epoch[34] Batch [210]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.095249,	
2017-06-27 19:31:22,187 Epoch[34] Batch [220]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.095371,	
2017-06-27 19:31:33,786 Epoch[34] Batch [230]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.095825,	
2017-06-27 19:31:44,436 Epoch[34] Batch [240]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.096494,	
2017-06-27 19:31:56,276 Epoch[34] Batch [250]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.096909,	
2017-06-27 19:32:08,342 Epoch[34] Batch [260]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.097680,	
2017-06-27 19:32:18,970 Epoch[34] Batch [270]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-27 19:32:29,499 Epoch[34] Batch [280]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.098436,	
2017-06-27 19:32:40,737 Epoch[34] Batch [290]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.098961,	
2017-06-27 19:32:51,571 Epoch[34] Batch [300]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.099126,	
2017-06-27 19:33:02,445 Epoch[34] Batch [310]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.098937,	
2017-06-27 19:33:13,610 Epoch[34] Batch [320]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.098792,	
2017-06-27 19:33:23,321 Epoch[34] Batch [330]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.098913,	
2017-06-27 19:33:33,166 Epoch[34] Batch [340]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.098975,	
2017-06-27 19:33:42,646 Epoch[34] Batch [350]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.098904,	
2017-06-27 19:33:52,234 Epoch[34] Batch [360]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.098754,	
2017-06-27 19:34:02,273 Epoch[34] Batch [370]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.099056,	
2017-06-27 19:34:13,526 Epoch[34] Batch [380]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.099259,	
2017-06-27 19:34:23,733 Epoch[34] Batch [390]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.099104,	
2017-06-27 19:34:35,171 Epoch[34] Batch [400]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.099144,	
2017-06-27 19:34:45,294 Epoch[34] Batch [410]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.099350,	
2017-06-27 19:34:56,904 Epoch[34] Batch [420]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.099505,	
2017-06-27 19:35:07,322 Epoch[34] Batch [430]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.099281,	
2017-06-27 19:35:17,046 Epoch[34] Batch [440]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.099185,	
2017-06-27 19:35:28,299 Epoch[34] Batch [450]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.099040,	
2017-06-27 19:35:39,512 Epoch[34] Batch [460]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.099166,	
2017-06-27 19:35:51,063 Epoch[34] Batch [470]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.098930,	
2017-06-27 19:36:03,433 Epoch[34] Batch [480]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.099048,	
2017-06-27 19:36:13,923 Epoch[34] Batch [490]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.098886,	
2017-06-27 19:36:24,683 Epoch[34] Batch [500]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.098793,	
2017-06-27 19:36:34,975 Epoch[34] Batch [510]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.098854,	
2017-06-27 19:36:46,817 Epoch[34] Batch [520]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.098572,	
2017-06-27 19:36:56,978 Epoch[34] Batch [530]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.098870,	
2017-06-27 19:37:08,037 Epoch[34] Batch [540]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.098817,	
2017-06-27 19:37:18,912 Epoch[34] Batch [550]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.098909,	
2017-06-27 19:37:30,216 Epoch[34] Batch [560]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.098847,	
2017-06-27 19:37:41,716 Epoch[34] Batch [570]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.098703,	
2017-06-27 19:37:52,768 Epoch[34] Batch [580]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.098741,	
2017-06-27 19:38:03,050 Epoch[34] Batch [590]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.098661,	
2017-06-27 19:38:15,353 Epoch[34] Batch [600]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.098624,	
2017-06-27 19:38:26,905 Epoch[34] Batch [610]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.098438,	
2017-06-27 19:38:37,738 Epoch[34] Batch [620]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.098458,	
2017-06-27 19:38:48,283 Epoch[34] Batch [630]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.098398,	
2017-06-27 19:38:59,036 Epoch[34] Batch [640]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.098362,	
2017-06-27 19:39:09,491 Epoch[34] Batch [650]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.098325,	
2017-06-27 19:39:21,692 Epoch[34] Batch [660]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.098326,	
2017-06-27 19:39:31,845 Epoch[34] Batch [670]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.098348,	
2017-06-27 19:39:42,769 Epoch[34] Batch [680]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.098436,	
2017-06-27 19:39:54,174 Epoch[34] Batch [690]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.098337,	
2017-06-27 19:40:06,210 Epoch[34] Batch [700]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.098259,	
2017-06-27 19:40:16,592 Epoch[34] Batch [710]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.098191,	
2017-06-27 19:40:28,133 Epoch[34] Batch [720]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.098423,	
2017-06-27 19:40:39,123 Epoch[34] Batch [730]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.098446,	
2017-06-27 19:40:50,671 Epoch[34] Batch [740]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.098491,	
2017-06-27 19:41:01,503 Epoch[34] Batch [750]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.098588,	
2017-06-27 19:41:13,061 Epoch[34] Batch [760]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.098466,	
2017-06-27 19:41:24,378 Epoch[34] Batch [770]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.098440,	
2017-06-27 19:41:35,346 Epoch[34] Batch [780]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.098554,	
2017-06-27 19:41:47,084 Epoch[34] Batch [790]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.098622,	
2017-06-27 19:41:58,632 Epoch[34] Batch [800]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.098611,	
2017-06-27 19:42:09,989 Epoch[34] Batch [810]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.098672,	
2017-06-27 19:42:21,496 Epoch[34] Batch [820]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.098632,	
2017-06-27 19:42:32,085 Epoch[34] Batch [830]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.098728,	
2017-06-27 19:42:43,412 Epoch[34] Batch [840]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.098772,	
2017-06-27 19:42:54,112 Epoch[34] Batch [850]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.098667,	
2017-06-27 19:43:05,421 Epoch[34] Batch [860]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.098645,	
2017-06-27 19:43:16,653 Epoch[34] Batch [870]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.098618,	
2017-06-27 19:43:27,437 Epoch[34] Batch [880]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.098530,	
2017-06-27 19:43:39,636 Epoch[34] Batch [890]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.098393,	
2017-06-27 19:43:50,735 Epoch[34] Batch [900]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.098482,	
2017-06-27 19:44:01,343 Epoch[34] Batch [910]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.098422,	
2017-06-27 19:44:12,723 Epoch[34] Batch [920]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.098419,	
2017-06-27 19:44:24,059 Epoch[34] Batch [930]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.098356,	
2017-06-27 19:44:34,339 Epoch[34] Batch [940]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.098220,	
2017-06-27 19:44:45,262 Epoch[34] Batch [950]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.098279,	
2017-06-27 19:44:56,792 Epoch[34] Batch [960]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.098227,	
2017-06-27 19:45:08,089 Epoch[34] Batch [970]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.098140,	
2017-06-27 19:45:18,494 Epoch[34] Batch [980]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.098065,	
2017-06-27 19:45:30,761 Epoch[34] Batch [990]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.098123,	
2017-06-27 19:45:41,662 Epoch[34] Batch [1000]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.098071,	
2017-06-27 19:45:54,186 Epoch[34] Batch [1010]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.098122,	
2017-06-27 19:46:05,657 Epoch[34] Batch [1020]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.098070,	
2017-06-27 19:46:17,852 Epoch[34] Batch [1030]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.098111,	
2017-06-27 19:46:29,090 Epoch[34] Batch [1040]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.098041,	
2017-06-27 19:46:40,722 Epoch[34] Batch [1050]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.097994,	
2017-06-27 19:46:52,450 Epoch[34] Batch [1060]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.098005,	
2017-06-27 19:47:02,141 Epoch[34] Batch [1070]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.098000,	
2017-06-27 19:47:13,571 Epoch[34] Batch [1080]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.097950,	
2017-06-27 19:47:25,276 Epoch[34] Batch [1090]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.097974,	
2017-06-27 19:47:36,048 Epoch[34] Batch [1100]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.097867,	
2017-06-27 19:47:48,040 Epoch[34] Batch [1110]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.097797,	
2017-06-27 19:47:58,430 Epoch[34] Batch [1120]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.097829,	
2017-06-27 19:48:09,758 Epoch[34] Batch [1130]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.097872,	
2017-06-27 19:48:20,902 Epoch[34] Batch [1140]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.097820,	
2017-06-27 19:48:32,889 Epoch[34] Batch [1150]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.097758,	
2017-06-27 19:48:44,897 Epoch[34] Batch [1160]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.097801,	
2017-06-27 19:48:56,077 Epoch[34] Batch [1170]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.097781,	
2017-06-27 19:49:06,784 Epoch[34] Batch [1180]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.097769,	
2017-06-27 19:49:18,531 Epoch[34] Batch [1190]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.097792,	
2017-06-27 19:49:29,523 Epoch[34] Batch [1200]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.097839,	
2017-06-27 19:49:40,953 Epoch[34] Batch [1210]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.097895,	
2017-06-27 19:49:51,843 Epoch[34] Batch [1220]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.097844,	
2017-06-27 19:50:03,241 Epoch[34] Batch [1230]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.097906,	
2017-06-27 19:50:13,645 Epoch[34] Batch [1240]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.097909,	
2017-06-27 19:50:23,409 Epoch[34] Batch [1250]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.097857,	
2017-06-27 19:50:35,166 Epoch[34] Batch [1260]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.097865,	
2017-06-27 19:50:45,470 Epoch[34] Batch [1270]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.097796,	
2017-06-27 19:50:57,139 Epoch[34] Batch [1280]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.097773,	
2017-06-27 19:51:08,572 Epoch[34] Batch [1290]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.097813,	
2017-06-27 19:51:18,997 Epoch[34] Batch [1300]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.097817,	
2017-06-27 19:51:28,875 Epoch[34] Batch [1310]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.097808,	
2017-06-27 19:51:39,673 Epoch[34] Batch [1320]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.097792,	
2017-06-27 19:51:52,139 Epoch[34] Batch [1330]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.097737,	
2017-06-27 19:52:02,485 Epoch[34] Batch [1340]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.097695,	
2017-06-27 19:52:13,158 Epoch[34] Batch [1350]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.097676,	
2017-06-27 19:52:24,707 Epoch[34] Batch [1360]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.097687,	
2017-06-27 19:52:34,852 Epoch[34] Batch [1370]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.097648,	
2017-06-27 19:52:45,492 Epoch[34] Batch [1380]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.097605,	
2017-06-27 19:52:55,908 Epoch[34] Batch [1390]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.097658,	
2017-06-27 19:53:07,018 Epoch[34] Batch [1400]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.097634,	
2017-06-27 19:53:17,840 Epoch[34] Batch [1410]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.097616,	
2017-06-27 19:53:29,011 Epoch[34] Batch [1420]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.097606,	
2017-06-27 19:53:39,476 Epoch[34] Batch [1430]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.097550,	
2017-06-27 19:53:50,724 Epoch[34] Batch [1440]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.097578,	
2017-06-27 19:54:01,622 Epoch[34] Batch [1450]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.097551,	
2017-06-27 19:54:12,043 Epoch[34] Batch [1460]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.097571,	
2017-06-27 19:54:23,577 Epoch[34] Batch [1470]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.097524,	
2017-06-27 19:54:35,721 Epoch[34] Batch [1480]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.097507,	
2017-06-27 19:54:41,426 Epoch[34] Train-FCNLogLoss=0.097496
2017-06-27 19:54:41,426 Epoch[34] Time cost=1645.302
2017-06-27 19:54:44,788 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0035.params"
2017-06-27 19:54:53,183 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0035.states"
2017-06-27 19:55:04,746 Epoch[35] Batch [10]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.089231,	
2017-06-27 19:55:14,502 Epoch[35] Batch [20]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.095423,	
2017-06-27 19:55:24,419 Epoch[35] Batch [30]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.098114,	
2017-06-27 19:55:34,576 Epoch[35] Batch [40]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.097627,	
2017-06-27 19:55:44,552 Epoch[35] Batch [50]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.095321,	
2017-06-27 19:55:54,987 Epoch[35] Batch [60]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.095037,	
2017-06-27 19:56:05,734 Epoch[35] Batch [70]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.096517,	
2017-06-27 19:56:16,688 Epoch[35] Batch [80]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.096679,	
2017-06-27 19:56:27,779 Epoch[35] Batch [90]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.097410,	
2017-06-27 19:56:38,715 Epoch[35] Batch [100]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.096966,	
2017-06-27 19:56:49,457 Epoch[35] Batch [110]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.096880,	
2017-06-27 19:57:01,699 Epoch[35] Batch [120]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.096933,	
2017-06-27 19:57:13,010 Epoch[35] Batch [130]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.097287,	
2017-06-27 19:57:23,637 Epoch[35] Batch [140]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.098127,	
2017-06-27 19:57:35,021 Epoch[35] Batch [150]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.098084,	
2017-06-27 19:57:45,565 Epoch[35] Batch [160]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.098156,	
2017-06-27 19:57:56,277 Epoch[35] Batch [170]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.098299,	
2017-06-27 19:58:07,363 Epoch[35] Batch [180]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.098011,	
2017-06-27 19:58:18,586 Epoch[35] Batch [190]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.098309,	
2017-06-27 19:58:28,888 Epoch[35] Batch [200]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.098812,	
2017-06-27 19:58:41,127 Epoch[35] Batch [210]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.099732,	
2017-06-27 19:58:52,917 Epoch[35] Batch [220]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.100397,	
2017-06-27 19:59:03,007 Epoch[35] Batch [230]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.100210,	
2017-06-27 19:59:13,300 Epoch[35] Batch [240]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.100216,	
2017-06-27 19:59:23,759 Epoch[35] Batch [250]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.100043,	
2017-06-27 19:59:35,413 Epoch[35] Batch [260]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.099855,	
2017-06-27 19:59:48,295 Epoch[35] Batch [270]	Speed: 3.11 samples/sec	Train-FCNLogLoss=0.099668,	
2017-06-27 20:00:00,362 Epoch[35] Batch [280]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.099605,	
2017-06-27 20:00:10,756 Epoch[35] Batch [290]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.099299,	
2017-06-27 20:00:20,450 Epoch[35] Batch [300]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.099291,	
2017-06-27 20:00:31,498 Epoch[35] Batch [310]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.099200,	
2017-06-27 20:00:41,834 Epoch[35] Batch [320]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.098957,	
2017-06-27 20:00:51,877 Epoch[35] Batch [330]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.099116,	
2017-06-27 20:01:01,768 Epoch[35] Batch [340]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.098931,	
2017-06-27 20:01:12,685 Epoch[35] Batch [350]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.098964,	
2017-06-27 20:01:23,265 Epoch[35] Batch [360]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.099028,	
2017-06-27 20:01:34,146 Epoch[35] Batch [370]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.099070,	
2017-06-27 20:01:44,414 Epoch[35] Batch [380]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.099224,	
2017-06-27 20:01:55,492 Epoch[35] Batch [390]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.099225,	
2017-06-27 20:02:07,321 Epoch[35] Batch [400]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.099142,	
2017-06-27 20:02:17,791 Epoch[35] Batch [410]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.099065,	
2017-06-27 20:02:29,165 Epoch[35] Batch [420]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.098907,	
2017-06-27 20:02:39,591 Epoch[35] Batch [430]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.098622,	
2017-06-27 20:02:50,109 Epoch[35] Batch [440]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.098262,	
2017-06-27 20:03:00,494 Epoch[35] Batch [450]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.098379,	
2017-06-27 20:03:12,442 Epoch[35] Batch [460]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.098350,	
2017-06-27 20:03:22,987 Epoch[35] Batch [470]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.098251,	
2017-06-27 20:03:33,438 Epoch[35] Batch [480]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.098151,	
2017-06-27 20:03:44,992 Epoch[35] Batch [490]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.098352,	
2017-06-27 20:03:55,126 Epoch[35] Batch [500]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.098669,	
2017-06-27 20:04:04,950 Epoch[35] Batch [510]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.098718,	
2017-06-27 20:04:17,861 Epoch[35] Batch [520]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.098741,	
2017-06-27 20:04:28,677 Epoch[35] Batch [530]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.098741,	
2017-06-27 20:04:40,110 Epoch[35] Batch [540]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.098732,	
2017-06-27 20:04:51,327 Epoch[35] Batch [550]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.098494,	
2017-06-27 20:05:02,947 Epoch[35] Batch [560]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.098492,	
2017-06-27 20:05:14,219 Epoch[35] Batch [570]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.098319,	
2017-06-27 20:05:24,879 Epoch[35] Batch [580]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.098300,	
2017-06-27 20:05:35,288 Epoch[35] Batch [590]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.098212,	
2017-06-27 20:05:46,772 Epoch[35] Batch [600]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.098296,	
2017-06-27 20:05:57,914 Epoch[35] Batch [610]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.098226,	
2017-06-27 20:06:07,910 Epoch[35] Batch [620]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.098155,	
2017-06-27 20:06:18,629 Epoch[35] Batch [630]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.098371,	
2017-06-27 20:06:28,931 Epoch[35] Batch [640]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.098250,	
2017-06-27 20:06:40,422 Epoch[35] Batch [650]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.098240,	
2017-06-27 20:06:50,887 Epoch[35] Batch [660]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.098288,	
2017-06-27 20:07:02,608 Epoch[35] Batch [670]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.098329,	
2017-06-27 20:07:14,390 Epoch[35] Batch [680]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.098166,	
2017-06-27 20:07:27,085 Epoch[35] Batch [690]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.098215,	
2017-06-27 20:07:39,144 Epoch[35] Batch [700]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.098080,	
2017-06-27 20:07:50,499 Epoch[35] Batch [710]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.097930,	
2017-06-27 20:08:00,898 Epoch[35] Batch [720]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.097714,	
2017-06-27 20:08:13,031 Epoch[35] Batch [730]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.097585,	
2017-06-27 20:08:24,562 Epoch[35] Batch [740]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.097520,	
2017-06-27 20:08:34,996 Epoch[35] Batch [750]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.097557,	
2017-06-27 20:08:45,600 Epoch[35] Batch [760]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.097412,	
2017-06-27 20:08:55,548 Epoch[35] Batch [770]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.097379,	
2017-06-27 20:09:05,768 Epoch[35] Batch [780]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.097261,	
2017-06-27 20:09:16,768 Epoch[35] Batch [790]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.097257,	
2017-06-27 20:09:27,748 Epoch[35] Batch [800]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.097236,	
2017-06-27 20:09:39,250 Epoch[35] Batch [810]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.097326,	
2017-06-27 20:09:49,338 Epoch[35] Batch [820]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.097254,	
2017-06-27 20:10:00,574 Epoch[35] Batch [830]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.097219,	
2017-06-27 20:10:11,322 Epoch[35] Batch [840]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.097298,	
2017-06-27 20:10:22,584 Epoch[35] Batch [850]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.097280,	
2017-06-27 20:10:32,824 Epoch[35] Batch [860]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.097279,	
2017-06-27 20:10:43,402 Epoch[35] Batch [870]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.097210,	
2017-06-27 20:10:54,906 Epoch[35] Batch [880]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.097138,	
2017-06-27 20:11:05,781 Epoch[35] Batch [890]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.097132,	
2017-06-27 20:11:16,997 Epoch[35] Batch [900]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.097123,	
2017-06-27 20:11:27,550 Epoch[35] Batch [910]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.097194,	
2017-06-27 20:11:37,895 Epoch[35] Batch [920]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.097275,	
2017-06-27 20:11:49,760 Epoch[35] Batch [930]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.097145,	
2017-06-27 20:11:59,439 Epoch[35] Batch [940]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.097090,	
2017-06-27 20:12:09,915 Epoch[35] Batch [950]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.097091,	
2017-06-27 20:12:21,352 Epoch[35] Batch [960]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.097030,	
2017-06-27 20:12:33,454 Epoch[35] Batch [970]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.097009,	
2017-06-27 20:12:45,027 Epoch[35] Batch [980]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.097035,	
2017-06-27 20:12:57,299 Epoch[35] Batch [990]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.096930,	
2017-06-27 20:13:08,486 Epoch[35] Batch [1000]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.096897,	
2017-06-27 20:13:20,177 Epoch[35] Batch [1010]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.096967,	
2017-06-27 20:13:31,791 Epoch[35] Batch [1020]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.096974,	
2017-06-27 20:13:41,917 Epoch[35] Batch [1030]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.097008,	
2017-06-27 20:13:53,594 Epoch[35] Batch [1040]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.096979,	
2017-06-27 20:14:04,308 Epoch[35] Batch [1050]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.096892,	
2017-06-27 20:14:14,871 Epoch[35] Batch [1060]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.096895,	
2017-06-27 20:14:27,713 Epoch[35] Batch [1070]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.096844,	
2017-06-27 20:14:39,668 Epoch[35] Batch [1080]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.096799,	
2017-06-27 20:14:50,296 Epoch[35] Batch [1090]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.096782,	
2017-06-27 20:15:01,808 Epoch[35] Batch [1100]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.096776,	
2017-06-27 20:15:13,697 Epoch[35] Batch [1110]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.096860,	
2017-06-27 20:15:25,652 Epoch[35] Batch [1120]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.096973,	
2017-06-27 20:15:37,514 Epoch[35] Batch [1130]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.096885,	
2017-06-27 20:15:48,317 Epoch[35] Batch [1140]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.096860,	
2017-06-27 20:15:58,723 Epoch[35] Batch [1150]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.096835,	
2017-06-27 20:16:10,515 Epoch[35] Batch [1160]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.096817,	
2017-06-27 20:16:21,713 Epoch[35] Batch [1170]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.096770,	
2017-06-27 20:16:32,725 Epoch[35] Batch [1180]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.096753,	
2017-06-27 20:16:43,558 Epoch[35] Batch [1190]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.096783,	
2017-06-27 20:16:54,231 Epoch[35] Batch [1200]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.096740,	
2017-06-27 20:17:05,466 Epoch[35] Batch [1210]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.096716,	
2017-06-27 20:17:16,417 Epoch[35] Batch [1220]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.096645,	
2017-06-27 20:17:27,980 Epoch[35] Batch [1230]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.096576,	
2017-06-27 20:17:41,513 Epoch[35] Batch [1240]	Speed: 2.96 samples/sec	Train-FCNLogLoss=0.096572,	
2017-06-27 20:17:49,529 Epoch[35] Batch [1250]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.096555,	
2017-06-27 20:17:58,153 Epoch[35] Batch [1260]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.096502,	
2017-06-27 20:18:07,154 Epoch[35] Batch [1270]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.096414,	
2017-06-27 20:18:15,721 Epoch[35] Batch [1280]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.096394,	
2017-06-27 20:18:24,175 Epoch[35] Batch [1290]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.096364,	
2017-06-27 20:18:32,989 Epoch[35] Batch [1300]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.096342,	
2017-06-27 20:18:42,166 Epoch[35] Batch [1310]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.096217,	
2017-06-27 20:18:50,635 Epoch[35] Batch [1320]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.096175,	
2017-06-27 20:18:58,823 Epoch[35] Batch [1330]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.096173,	
2017-06-27 20:19:07,104 Epoch[35] Batch [1340]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.096125,	
2017-06-27 20:19:14,892 Epoch[35] Batch [1350]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.096043,	
2017-06-27 20:19:22,222 Epoch[35] Batch [1360]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.096091,	
2017-06-27 20:19:30,042 Epoch[35] Batch [1370]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.096045,	
2017-06-27 20:19:37,007 Epoch[35] Batch [1380]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.096079,	
2017-06-27 20:19:45,256 Epoch[35] Batch [1390]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.096173,	
2017-06-27 20:19:51,586 Epoch[35] Batch [1400]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.096174,	
2017-06-27 20:19:59,079 Epoch[35] Batch [1410]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.096299,	
2017-06-27 20:20:06,329 Epoch[35] Batch [1420]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.096376,	
2017-06-27 20:20:13,462 Epoch[35] Batch [1430]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.096424,	
2017-06-27 20:20:20,989 Epoch[35] Batch [1440]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.096478,	
2017-06-27 20:20:28,018 Epoch[35] Batch [1450]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.096426,	
2017-06-27 20:20:34,696 Epoch[35] Batch [1460]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096430,	
2017-06-27 20:20:41,378 Epoch[35] Batch [1470]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096440,	
2017-06-27 20:20:47,903 Epoch[35] Batch [1480]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.096441,	
2017-06-27 20:20:51,567 Epoch[35] Train-FCNLogLoss=0.096440
2017-06-27 20:20:51,567 Epoch[35] Time cost=1558.204
2017-06-27 20:20:52,457 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0036.params"
2017-06-27 20:20:54,250 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0036.states"
2017-06-27 20:21:01,026 Epoch[36] Batch [10]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.093308,	
2017-06-27 20:21:07,039 Epoch[36] Batch [20]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.096995,	
2017-06-27 20:21:13,186 Epoch[36] Batch [30]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.093635,	
2017-06-27 20:21:19,331 Epoch[36] Batch [40]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.092668,	
2017-06-27 20:21:25,520 Epoch[36] Batch [50]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.091906,	
2017-06-27 20:21:31,778 Epoch[36] Batch [60]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.093244,	
2017-06-27 20:21:37,778 Epoch[36] Batch [70]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.093064,	
2017-06-27 20:21:44,308 Epoch[36] Batch [80]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.093584,	
2017-06-27 20:21:49,890 Epoch[36] Batch [90]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.094187,	
2017-06-27 20:21:54,964 Epoch[36] Batch [100]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.093899,	
2017-06-27 20:22:00,398 Epoch[36] Batch [110]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094274,	
2017-06-27 20:22:06,139 Epoch[36] Batch [120]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.094159,	
2017-06-27 20:22:11,518 Epoch[36] Batch [130]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093533,	
2017-06-27 20:22:17,015 Epoch[36] Batch [140]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093255,	
2017-06-27 20:22:22,739 Epoch[36] Batch [150]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.092877,	
2017-06-27 20:22:28,294 Epoch[36] Batch [160]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093346,	
2017-06-27 20:22:33,855 Epoch[36] Batch [170]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093828,	
2017-06-27 20:22:39,764 Epoch[36] Batch [180]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.093724,	
2017-06-27 20:22:45,063 Epoch[36] Batch [190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093858,	
2017-06-27 20:22:50,754 Epoch[36] Batch [200]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.093497,	
2017-06-27 20:22:55,991 Epoch[36] Batch [210]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093496,	
2017-06-27 20:23:02,443 Epoch[36] Batch [220]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.093563,	
2017-06-27 20:23:08,221 Epoch[36] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093517,	
2017-06-27 20:23:13,563 Epoch[36] Batch [240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093316,	
2017-06-27 20:23:18,632 Epoch[36] Batch [250]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093413,	
2017-06-27 20:23:23,913 Epoch[36] Batch [260]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093525,	
2017-06-27 20:23:29,250 Epoch[36] Batch [270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093560,	
2017-06-27 20:23:34,555 Epoch[36] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093970,	
2017-06-27 20:23:39,840 Epoch[36] Batch [290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093995,	
2017-06-27 20:23:45,140 Epoch[36] Batch [300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094228,	
2017-06-27 20:23:50,440 Epoch[36] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094142,	
2017-06-27 20:23:55,668 Epoch[36] Batch [320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094458,	
2017-06-27 20:24:00,936 Epoch[36] Batch [330]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094675,	
2017-06-27 20:24:06,247 Epoch[36] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095051,	
2017-06-27 20:24:11,618 Epoch[36] Batch [350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095275,	
2017-06-27 20:24:16,914 Epoch[36] Batch [360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095593,	
2017-06-27 20:24:22,187 Epoch[36] Batch [370]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095525,	
2017-06-27 20:24:27,488 Epoch[36] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095697,	
2017-06-27 20:24:32,795 Epoch[36] Batch [390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095878,	
2017-06-27 20:24:38,046 Epoch[36] Batch [400]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096436,	
2017-06-27 20:24:43,331 Epoch[36] Batch [410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096536,	
2017-06-27 20:24:48,591 Epoch[36] Batch [420]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096516,	
2017-06-27 20:24:53,884 Epoch[36] Batch [430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096612,	
2017-06-27 20:24:59,156 Epoch[36] Batch [440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096707,	
2017-06-27 20:25:04,478 Epoch[36] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096703,	
2017-06-27 20:25:09,770 Epoch[36] Batch [460]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096795,	
2017-06-27 20:25:15,082 Epoch[36] Batch [470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096835,	
2017-06-27 20:25:20,389 Epoch[36] Batch [480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096850,	
2017-06-27 20:25:25,668 Epoch[36] Batch [490]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096681,	
2017-06-27 20:25:30,992 Epoch[36] Batch [500]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096568,	
2017-06-27 20:25:36,301 Epoch[36] Batch [510]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096650,	
2017-06-27 20:25:41,553 Epoch[36] Batch [520]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096607,	
2017-06-27 20:25:46,807 Epoch[36] Batch [530]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096770,	
2017-06-27 20:25:52,093 Epoch[36] Batch [540]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096900,	
2017-06-27 20:25:57,447 Epoch[36] Batch [550]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096885,	
2017-06-27 20:26:02,761 Epoch[36] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096811,	
2017-06-27 20:26:08,061 Epoch[36] Batch [570]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097094,	
2017-06-27 20:26:13,374 Epoch[36] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097022,	
2017-06-27 20:26:18,690 Epoch[36] Batch [590]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096848,	
2017-06-27 20:26:24,055 Epoch[36] Batch [600]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096805,	
2017-06-27 20:26:29,356 Epoch[36] Batch [610]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096664,	
2017-06-27 20:26:34,635 Epoch[36] Batch [620]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096817,	
2017-06-27 20:26:39,973 Epoch[36] Batch [630]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096798,	
2017-06-27 20:26:45,281 Epoch[36] Batch [640]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096905,	
2017-06-27 20:26:50,568 Epoch[36] Batch [650]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096887,	
2017-06-27 20:26:55,911 Epoch[36] Batch [660]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096861,	
2017-06-27 20:27:01,245 Epoch[36] Batch [670]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096866,	
2017-06-27 20:27:06,547 Epoch[36] Batch [680]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097023,	
2017-06-27 20:27:11,829 Epoch[36] Batch [690]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097282,	
2017-06-27 20:27:17,092 Epoch[36] Batch [700]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.097430,	
2017-06-27 20:27:22,401 Epoch[36] Batch [710]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097536,	
2017-06-27 20:27:27,687 Epoch[36] Batch [720]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097500,	
2017-06-27 20:27:32,958 Epoch[36] Batch [730]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097541,	
2017-06-27 20:27:38,222 Epoch[36] Batch [740]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.097508,	
2017-06-27 20:27:43,538 Epoch[36] Batch [750]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097483,	
2017-06-27 20:27:48,815 Epoch[36] Batch [760]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097454,	
2017-06-27 20:27:54,034 Epoch[36] Batch [770]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.097502,	
2017-06-27 20:27:59,378 Epoch[36] Batch [780]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097513,	
2017-06-27 20:28:04,758 Epoch[36] Batch [790]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097376,	
2017-06-27 20:28:10,028 Epoch[36] Batch [800]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097396,	
2017-06-27 20:28:15,338 Epoch[36] Batch [810]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097323,	
2017-06-27 20:28:20,577 Epoch[36] Batch [820]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097347,	
2017-06-27 20:28:25,873 Epoch[36] Batch [830]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097366,	
2017-06-27 20:28:31,190 Epoch[36] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097267,	
2017-06-27 20:28:36,459 Epoch[36] Batch [850]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097233,	
2017-06-27 20:28:41,758 Epoch[36] Batch [860]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097176,	
2017-06-27 20:28:47,092 Epoch[36] Batch [870]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097128,	
2017-06-27 20:28:52,379 Epoch[36] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097165,	
2017-06-27 20:28:57,636 Epoch[36] Batch [890]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097232,	
2017-06-27 20:29:02,954 Epoch[36] Batch [900]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097204,	
2017-06-27 20:29:08,228 Epoch[36] Batch [910]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097201,	
2017-06-27 20:29:13,524 Epoch[36] Batch [920]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097122,	
2017-06-27 20:29:18,866 Epoch[36] Batch [930]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097122,	
2017-06-27 20:29:24,108 Epoch[36] Batch [940]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097095,	
2017-06-27 20:29:29,426 Epoch[36] Batch [950]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097134,	
2017-06-27 20:29:34,706 Epoch[36] Batch [960]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097034,	
2017-06-27 20:29:40,022 Epoch[36] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096909,	
2017-06-27 20:29:45,300 Epoch[36] Batch [980]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096925,	
2017-06-27 20:29:50,601 Epoch[36] Batch [990]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097056,	
2017-06-27 20:29:55,883 Epoch[36] Batch [1000]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097032,	
2017-06-27 20:30:01,155 Epoch[36] Batch [1010]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096993,	
2017-06-27 20:30:06,487 Epoch[36] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097053,	
2017-06-27 20:30:11,807 Epoch[36] Batch [1030]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097025,	
2017-06-27 20:30:17,066 Epoch[36] Batch [1040]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096954,	
2017-06-27 20:30:22,400 Epoch[36] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096923,	
2017-06-27 20:30:27,674 Epoch[36] Batch [1060]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096866,	
2017-06-27 20:30:32,975 Epoch[36] Batch [1070]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096780,	
2017-06-27 20:30:38,274 Epoch[36] Batch [1080]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096674,	
2017-06-27 20:30:43,549 Epoch[36] Batch [1090]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096710,	
2017-06-27 20:30:48,848 Epoch[36] Batch [1100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096671,	
2017-06-27 20:30:54,127 Epoch[36] Batch [1110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096563,	
2017-06-27 20:30:59,479 Epoch[36] Batch [1120]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096475,	
2017-06-27 20:31:04,716 Epoch[36] Batch [1130]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.096464,	
2017-06-27 20:31:10,042 Epoch[36] Batch [1140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096461,	
2017-06-27 20:31:15,238 Epoch[36] Batch [1150]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.096480,	
2017-06-27 20:31:20,569 Epoch[36] Batch [1160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096395,	
2017-06-27 20:31:25,866 Epoch[36] Batch [1170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096389,	
2017-06-27 20:31:31,198 Epoch[36] Batch [1180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096389,	
2017-06-27 20:31:36,529 Epoch[36] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096399,	
2017-06-27 20:31:41,842 Epoch[36] Batch [1200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096381,	
2017-06-27 20:31:47,155 Epoch[36] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096451,	
2017-06-27 20:31:52,530 Epoch[36] Batch [1220]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096437,	
2017-06-27 20:31:57,819 Epoch[36] Batch [1230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096499,	
2017-06-27 20:32:02,857 Epoch[36] Batch [1240]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.096592,	
2017-06-27 20:32:07,222 Epoch[36] Batch [1250]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.096509,	
2017-06-27 20:32:12,471 Epoch[36] Batch [1260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096542,	
2017-06-27 20:32:17,820 Epoch[36] Batch [1270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096455,	
2017-06-27 20:32:23,099 Epoch[36] Batch [1280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096468,	
2017-06-27 20:32:28,410 Epoch[36] Batch [1290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096513,	
2017-06-27 20:32:33,731 Epoch[36] Batch [1300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096436,	
2017-06-27 20:32:39,024 Epoch[36] Batch [1310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096440,	
2017-06-27 20:32:44,357 Epoch[36] Batch [1320]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096541,	
2017-06-27 20:32:49,667 Epoch[36] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096491,	
2017-06-27 20:32:54,915 Epoch[36] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096500,	
2017-06-27 20:33:00,192 Epoch[36] Batch [1350]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096454,	
2017-06-27 20:33:05,529 Epoch[36] Batch [1360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096378,	
2017-06-27 20:33:10,829 Epoch[36] Batch [1370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096289,	
2017-06-27 20:33:16,173 Epoch[36] Batch [1380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096215,	
2017-06-27 20:33:21,476 Epoch[36] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096205,	
2017-06-27 20:33:26,800 Epoch[36] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096193,	
2017-06-27 20:33:32,138 Epoch[36] Batch [1410]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096237,	
2017-06-27 20:33:37,383 Epoch[36] Batch [1420]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.096263,	
2017-06-27 20:33:42,694 Epoch[36] Batch [1430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096245,	
2017-06-27 20:33:48,003 Epoch[36] Batch [1440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096210,	
2017-06-27 20:33:53,331 Epoch[36] Batch [1450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096291,	
2017-06-27 20:33:58,632 Epoch[36] Batch [1460]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096254,	
2017-06-27 20:34:03,953 Epoch[36] Batch [1470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096255,	
2017-06-27 20:34:09,264 Epoch[36] Batch [1480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096288,	
2017-06-27 20:34:12,454 Epoch[36] Train-FCNLogLoss=0.096286
2017-06-27 20:34:12,454 Epoch[36] Time cost=798.203
2017-06-27 20:34:13,305 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0037.params"
2017-06-27 20:34:15,038 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0037.states"
2017-06-27 20:34:21,024 Epoch[37] Batch [10]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.101338,	
2017-06-27 20:34:26,293 Epoch[37] Batch [20]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094275,	
2017-06-27 20:34:31,614 Epoch[37] Batch [30]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092619,	
2017-06-27 20:34:36,889 Epoch[37] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093549,	
2017-06-27 20:34:42,176 Epoch[37] Batch [50]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093744,	
2017-06-27 20:34:47,442 Epoch[37] Batch [60]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093699,	
2017-06-27 20:34:52,786 Epoch[37] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093568,	
2017-06-27 20:34:58,070 Epoch[37] Batch [80]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093629,	
2017-06-27 20:35:03,381 Epoch[37] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092875,	
2017-06-27 20:35:08,655 Epoch[37] Batch [100]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096748,	
2017-06-27 20:35:13,909 Epoch[37] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097268,	
2017-06-27 20:35:19,256 Epoch[37] Batch [120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096721,	
2017-06-27 20:35:24,527 Epoch[37] Batch [130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096380,	
2017-06-27 20:35:29,832 Epoch[37] Batch [140]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096589,	
2017-06-27 20:35:35,152 Epoch[37] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096265,	
2017-06-27 20:35:40,454 Epoch[37] Batch [160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096208,	
2017-06-27 20:35:45,759 Epoch[37] Batch [170]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095866,	
2017-06-27 20:35:51,067 Epoch[37] Batch [180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096207,	
2017-06-27 20:35:56,341 Epoch[37] Batch [190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097169,	
2017-06-27 20:36:01,612 Epoch[37] Batch [200]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097690,	
2017-06-27 20:36:06,926 Epoch[37] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097622,	
2017-06-27 20:36:12,180 Epoch[37] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097620,	
2017-06-27 20:36:17,424 Epoch[37] Batch [230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097805,	
2017-06-27 20:36:22,718 Epoch[37] Batch [240]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098111,	
2017-06-27 20:36:28,017 Epoch[37] Batch [250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097903,	
2017-06-27 20:36:33,291 Epoch[37] Batch [260]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098036,	
2017-06-27 20:36:38,570 Epoch[37] Batch [270]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097882,	
2017-06-27 20:36:43,829 Epoch[37] Batch [280]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097646,	
2017-06-27 20:36:49,103 Epoch[37] Batch [290]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097502,	
2017-06-27 20:36:54,413 Epoch[37] Batch [300]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097761,	
2017-06-27 20:36:59,711 Epoch[37] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097923,	
2017-06-27 20:37:04,987 Epoch[37] Batch [320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097897,	
2017-06-27 20:37:10,295 Epoch[37] Batch [330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097729,	
2017-06-27 20:37:15,542 Epoch[37] Batch [340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097694,	
2017-06-27 20:37:20,847 Epoch[37] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097552,	
2017-06-27 20:37:26,156 Epoch[37] Batch [360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097533,	
2017-06-27 20:37:31,389 Epoch[37] Batch [370]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097317,	
2017-06-27 20:37:36,708 Epoch[37] Batch [380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097144,	
2017-06-27 20:37:41,991 Epoch[37] Batch [390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097165,	
2017-06-27 20:37:47,292 Epoch[37] Batch [400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097128,	
2017-06-27 20:37:52,579 Epoch[37] Batch [410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096908,	
2017-06-27 20:37:57,867 Epoch[37] Batch [420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096659,	
2017-06-27 20:38:03,151 Epoch[37] Batch [430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096663,	
2017-06-27 20:38:08,398 Epoch[37] Batch [440]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096770,	
2017-06-27 20:38:13,735 Epoch[37] Batch [450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096917,	
2017-06-27 20:38:18,975 Epoch[37] Batch [460]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.096758,	
2017-06-27 20:38:24,270 Epoch[37] Batch [470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096582,	
2017-06-27 20:38:29,559 Epoch[37] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096595,	
2017-06-27 20:38:34,832 Epoch[37] Batch [490]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096335,	
2017-06-27 20:38:40,134 Epoch[37] Batch [500]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096042,	
2017-06-27 20:38:45,411 Epoch[37] Batch [510]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096048,	
2017-06-27 20:38:50,698 Epoch[37] Batch [520]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096038,	
2017-06-27 20:38:55,995 Epoch[37] Batch [530]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096051,	
2017-06-27 20:39:01,280 Epoch[37] Batch [540]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096534,	
2017-06-27 20:39:06,609 Epoch[37] Batch [550]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096607,	
2017-06-27 20:39:11,888 Epoch[37] Batch [560]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096609,	
2017-06-27 20:39:17,173 Epoch[37] Batch [570]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096645,	
2017-06-27 20:39:22,456 Epoch[37] Batch [580]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097189,	
2017-06-27 20:39:27,760 Epoch[37] Batch [590]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097195,	
2017-06-27 20:39:33,071 Epoch[37] Batch [600]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097842,	
2017-06-27 20:39:38,335 Epoch[37] Batch [610]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.098396,	
2017-06-27 20:39:43,639 Epoch[37] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098656,	
2017-06-27 20:39:48,925 Epoch[37] Batch [630]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098828,	
2017-06-27 20:39:54,230 Epoch[37] Batch [640]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098809,	
2017-06-27 20:39:59,547 Epoch[37] Batch [650]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098851,	
2017-06-27 20:40:04,809 Epoch[37] Batch [660]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.098658,	
2017-06-27 20:40:10,098 Epoch[37] Batch [670]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098808,	
2017-06-27 20:40:15,418 Epoch[37] Batch [680]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098936,	
2017-06-27 20:40:20,672 Epoch[37] Batch [690]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099178,	
2017-06-27 20:40:25,942 Epoch[37] Batch [700]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099294,	
2017-06-27 20:40:31,251 Epoch[37] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099357,	
2017-06-27 20:40:36,520 Epoch[37] Batch [720]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099271,	
2017-06-27 20:40:41,848 Epoch[37] Batch [730]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099327,	
2017-06-27 20:40:47,138 Epoch[37] Batch [740]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099188,	
2017-06-27 20:40:52,432 Epoch[37] Batch [750]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099293,	
2017-06-27 20:40:57,743 Epoch[37] Batch [760]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099163,	
2017-06-27 20:41:03,062 Epoch[37] Batch [770]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099190,	
2017-06-27 20:41:08,316 Epoch[37] Batch [780]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099131,	
2017-06-27 20:41:13,609 Epoch[37] Batch [790]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099240,	
2017-06-27 20:41:18,890 Epoch[37] Batch [800]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099301,	
2017-06-27 20:41:24,178 Epoch[37] Batch [810]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099252,	
2017-06-27 20:41:29,478 Epoch[37] Batch [820]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.099227,	
2017-06-27 20:41:34,723 Epoch[37] Batch [830]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.099183,	
2017-06-27 20:41:40,024 Epoch[37] Batch [840]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.099137,	
2017-06-27 20:41:45,334 Epoch[37] Batch [850]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098999,	
2017-06-27 20:41:50,657 Epoch[37] Batch [860]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099093,	
2017-06-27 20:41:55,970 Epoch[37] Batch [870]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099131,	
2017-06-27 20:42:01,291 Epoch[37] Batch [880]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099051,	
2017-06-27 20:42:06,612 Epoch[37] Batch [890]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099155,	
2017-06-27 20:42:11,924 Epoch[37] Batch [900]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099320,	
2017-06-27 20:42:17,222 Epoch[37] Batch [910]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.099263,	
2017-06-27 20:42:22,507 Epoch[37] Batch [920]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099372,	
2017-06-27 20:42:27,798 Epoch[37] Batch [930]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099431,	
2017-06-27 20:42:33,074 Epoch[37] Batch [940]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099642,	
2017-06-27 20:42:38,378 Epoch[37] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099686,	
2017-06-27 20:42:43,703 Epoch[37] Batch [960]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099697,	
2017-06-27 20:42:48,967 Epoch[37] Batch [970]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099512,	
2017-06-27 20:42:54,253 Epoch[37] Batch [980]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099543,	
2017-06-27 20:42:59,566 Epoch[37] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099474,	
2017-06-27 20:43:04,834 Epoch[37] Batch [1000]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099500,	
2017-06-27 20:43:10,130 Epoch[37] Batch [1010]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.099364,	
2017-06-27 20:43:15,405 Epoch[37] Batch [1020]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099296,	
2017-06-27 20:43:20,686 Epoch[37] Batch [1030]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099307,	
2017-06-27 20:43:25,989 Epoch[37] Batch [1040]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099336,	
2017-06-27 20:43:31,271 Epoch[37] Batch [1050]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099234,	
2017-06-27 20:43:36,566 Epoch[37] Batch [1060]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099161,	
2017-06-27 20:43:41,850 Epoch[37] Batch [1070]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099129,	
2017-06-27 20:43:47,127 Epoch[37] Batch [1080]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099012,	
2017-06-27 20:43:52,415 Epoch[37] Batch [1090]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099029,	
2017-06-27 20:43:57,688 Epoch[37] Batch [1100]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.098977,	
2017-06-27 20:44:03,020 Epoch[37] Batch [1110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099044,	
2017-06-27 20:44:08,271 Epoch[37] Batch [1120]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098938,	
2017-06-27 20:44:13,571 Epoch[37] Batch [1130]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098971,	
2017-06-27 20:44:18,924 Epoch[37] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098949,	
2017-06-27 20:44:24,189 Epoch[37] Batch [1150]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099079,	
2017-06-27 20:44:29,427 Epoch[37] Batch [1160]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099121,	
2017-06-27 20:44:34,719 Epoch[37] Batch [1170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099125,	
2017-06-27 20:44:40,024 Epoch[37] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099507,	
2017-06-27 20:44:45,312 Epoch[37] Batch [1190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099625,	
2017-06-27 20:44:50,546 Epoch[37] Batch [1200]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099694,	
2017-06-27 20:44:55,813 Epoch[37] Batch [1210]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099753,	
2017-06-27 20:45:01,139 Epoch[37] Batch [1220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099776,	
2017-06-27 20:45:06,409 Epoch[37] Batch [1230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099851,	
2017-06-27 20:45:11,678 Epoch[37] Batch [1240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099970,	
2017-06-27 20:45:15,749 Epoch[37] Batch [1250]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100019,	
2017-06-27 20:45:20,983 Epoch[37] Batch [1260]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.100079,	
2017-06-27 20:45:26,274 Epoch[37] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100108,	
2017-06-27 20:45:31,573 Epoch[37] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100067,	
2017-06-27 20:45:36,920 Epoch[37] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100074,	
2017-06-27 20:45:42,165 Epoch[37] Batch [1300]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.100081,	
2017-06-27 20:45:47,484 Epoch[37] Batch [1310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100168,	
2017-06-27 20:45:52,764 Epoch[37] Batch [1320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.100248,	
2017-06-27 20:45:58,054 Epoch[37] Batch [1330]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100286,	
2017-06-27 20:46:03,328 Epoch[37] Batch [1340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.100223,	
2017-06-27 20:46:08,656 Epoch[37] Batch [1350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100167,	
2017-06-27 20:46:13,977 Epoch[37] Batch [1360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100164,	
2017-06-27 20:46:19,271 Epoch[37] Batch [1370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100085,	
2017-06-27 20:46:24,545 Epoch[37] Batch [1380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.100012,	
2017-06-27 20:46:29,876 Epoch[37] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099991,	
2017-06-27 20:46:35,161 Epoch[37] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099981,	
2017-06-27 20:46:40,485 Epoch[37] Batch [1410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099998,	
2017-06-27 20:46:45,816 Epoch[37] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100205,	
2017-06-27 20:46:51,085 Epoch[37] Batch [1430]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100284,	
2017-06-27 20:46:56,396 Epoch[37] Batch [1440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100393,	
2017-06-27 20:47:01,685 Epoch[37] Batch [1450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100378,	
2017-06-27 20:47:07,026 Epoch[37] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100405,	
2017-06-27 20:47:12,258 Epoch[37] Batch [1470]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.100497,	
2017-06-27 20:47:17,610 Epoch[37] Batch [1480]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100603,	
2017-06-27 20:47:20,717 Epoch[37] Train-FCNLogLoss=0.100702
2017-06-27 20:47:20,717 Epoch[37] Time cost=785.679
2017-06-27 20:47:21,635 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0038.params"
2017-06-27 20:47:23,376 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0038.states"
2017-06-27 20:47:29,411 Epoch[38] Batch [10]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.100802,	
2017-06-27 20:47:34,694 Epoch[38] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.103830,	
2017-06-27 20:47:39,964 Epoch[38] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.105155,	
2017-06-27 20:47:45,273 Epoch[38] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.104285,	
2017-06-27 20:47:50,573 Epoch[38] Batch [50]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.104803,	
2017-06-27 20:47:55,866 Epoch[38] Batch [60]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.101520,	
2017-06-27 20:48:01,168 Epoch[38] Batch [70]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.100964,	
2017-06-27 20:48:06,487 Epoch[38] Batch [80]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100037,	
2017-06-27 20:48:11,771 Epoch[38] Batch [90]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.100162,	
2017-06-27 20:48:17,074 Epoch[38] Batch [100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.100190,	
2017-06-27 20:48:22,336 Epoch[38] Batch [110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099491,	
2017-06-27 20:48:27,626 Epoch[38] Batch [120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099857,	
2017-06-27 20:48:32,904 Epoch[38] Batch [130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098991,	
2017-06-27 20:48:38,239 Epoch[38] Batch [140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099076,	
2017-06-27 20:48:43,485 Epoch[38] Batch [150]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.098906,	
2017-06-27 20:48:48,803 Epoch[38] Batch [160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099334,	
2017-06-27 20:48:54,098 Epoch[38] Batch [170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099786,	
2017-06-27 20:48:59,392 Epoch[38] Batch [180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100059,	
2017-06-27 20:49:04,713 Epoch[38] Batch [190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099825,	
2017-06-27 20:49:10,015 Epoch[38] Batch [200]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099680,	
2017-06-27 20:49:15,262 Epoch[38] Batch [210]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.099677,	
2017-06-27 20:49:20,578 Epoch[38] Batch [220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099813,	
2017-06-27 20:49:25,847 Epoch[38] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099478,	
2017-06-27 20:49:31,152 Epoch[38] Batch [240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099353,	
2017-06-27 20:49:36,427 Epoch[38] Batch [250]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099121,	
2017-06-27 20:49:41,695 Epoch[38] Batch [260]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099210,	
2017-06-27 20:49:46,974 Epoch[38] Batch [270]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099231,	
2017-06-27 20:49:52,215 Epoch[38] Batch [280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.099129,	
2017-06-27 20:49:57,573 Epoch[38] Batch [290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098996,	
2017-06-27 20:50:02,884 Epoch[38] Batch [300]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098501,	
2017-06-27 20:50:08,199 Epoch[38] Batch [310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098536,	
2017-06-27 20:50:13,473 Epoch[38] Batch [320]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.098753,	
2017-06-27 20:50:18,796 Epoch[38] Batch [330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098499,	
2017-06-27 20:50:24,138 Epoch[38] Batch [340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098199,	
2017-06-27 20:50:29,462 Epoch[38] Batch [350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098169,	
2017-06-27 20:50:34,775 Epoch[38] Batch [360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098035,	
2017-06-27 20:50:40,024 Epoch[38] Batch [370]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098106,	
2017-06-27 20:50:45,308 Epoch[38] Batch [380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097935,	
2017-06-27 20:50:50,646 Epoch[38] Batch [390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097923,	
2017-06-27 20:50:55,927 Epoch[38] Batch [400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097782,	
2017-06-27 20:51:01,233 Epoch[38] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097855,	
2017-06-27 20:51:06,537 Epoch[38] Batch [420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097896,	
2017-06-27 20:51:11,830 Epoch[38] Batch [430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098187,	
2017-06-27 20:51:17,126 Epoch[38] Batch [440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098085,	
2017-06-27 20:51:22,485 Epoch[38] Batch [450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098234,	
2017-06-27 20:51:27,765 Epoch[38] Batch [460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098597,	
2017-06-27 20:51:33,031 Epoch[38] Batch [470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.098629,	
2017-06-27 20:51:38,374 Epoch[38] Batch [480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098391,	
2017-06-27 20:51:43,632 Epoch[38] Batch [490]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.098410,	
2017-06-27 20:51:48,962 Epoch[38] Batch [500]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098368,	
2017-06-27 20:51:54,249 Epoch[38] Batch [510]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098454,	
2017-06-27 20:51:59,573 Epoch[38] Batch [520]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098486,	
2017-06-27 20:52:04,901 Epoch[38] Batch [530]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098182,	
2017-06-27 20:52:10,160 Epoch[38] Batch [540]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.098191,	
2017-06-27 20:52:15,488 Epoch[38] Batch [550]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098118,	
2017-06-27 20:52:20,794 Epoch[38] Batch [560]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098129,	
2017-06-27 20:52:26,061 Epoch[38] Batch [570]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.098156,	
2017-06-27 20:52:31,372 Epoch[38] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098077,	
2017-06-27 20:52:36,662 Epoch[38] Batch [590]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097960,	
2017-06-27 20:52:41,950 Epoch[38] Batch [600]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098011,	
2017-06-27 20:52:47,249 Epoch[38] Batch [610]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098111,	
2017-06-27 20:52:52,513 Epoch[38] Batch [620]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.098127,	
2017-06-27 20:52:57,835 Epoch[38] Batch [630]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098043,	
2017-06-27 20:53:03,122 Epoch[38] Batch [640]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097842,	
2017-06-27 20:53:08,393 Epoch[38] Batch [650]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097819,	
2017-06-27 20:53:13,738 Epoch[38] Batch [660]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097809,	
2017-06-27 20:53:19,056 Epoch[38] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097803,	
2017-06-27 20:53:24,368 Epoch[38] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097743,	
2017-06-27 20:53:29,635 Epoch[38] Batch [690]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097680,	
2017-06-27 20:53:34,940 Epoch[38] Batch [700]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097692,	
2017-06-27 20:53:40,218 Epoch[38] Batch [710]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097677,	
2017-06-27 20:53:45,532 Epoch[38] Batch [720]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097674,	
2017-06-27 20:53:50,808 Epoch[38] Batch [730]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097660,	
2017-06-27 20:53:56,128 Epoch[38] Batch [740]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097614,	
2017-06-27 20:54:01,412 Epoch[38] Batch [750]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097594,	
2017-06-27 20:54:06,708 Epoch[38] Batch [760]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097470,	
2017-06-27 20:54:11,979 Epoch[38] Batch [770]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097359,	
2017-06-27 20:54:17,212 Epoch[38] Batch [780]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097398,	
2017-06-27 20:54:22,564 Epoch[38] Batch [790]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097294,	
2017-06-27 20:54:27,810 Epoch[38] Batch [800]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097213,	
2017-06-27 20:54:33,117 Epoch[38] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097134,	
2017-06-27 20:54:38,470 Epoch[38] Batch [820]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097245,	
2017-06-27 20:54:43,771 Epoch[38] Batch [830]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097145,	
2017-06-27 20:54:49,030 Epoch[38] Batch [840]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097140,	
2017-06-27 20:54:54,360 Epoch[38] Batch [850]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097124,	
2017-06-27 20:54:59,692 Epoch[38] Batch [860]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096994,	
2017-06-27 20:55:04,987 Epoch[38] Batch [870]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096885,	
2017-06-27 20:55:10,296 Epoch[38] Batch [880]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096789,	
2017-06-27 20:55:15,576 Epoch[38] Batch [890]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096919,	
2017-06-27 20:55:20,868 Epoch[38] Batch [900]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097053,	
2017-06-27 20:55:26,166 Epoch[38] Batch [910]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097107,	
2017-06-27 20:55:31,464 Epoch[38] Batch [920]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097146,	
2017-06-27 20:55:36,745 Epoch[38] Batch [930]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097078,	
2017-06-27 20:55:42,044 Epoch[38] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097047,	
2017-06-27 20:55:47,364 Epoch[38] Batch [950]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096888,	
2017-06-27 20:55:52,697 Epoch[38] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096841,	
2017-06-27 20:55:58,011 Epoch[38] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096742,	
2017-06-27 20:56:03,326 Epoch[38] Batch [980]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096731,	
2017-06-27 20:56:08,635 Epoch[38] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096595,	
2017-06-27 20:56:13,936 Epoch[38] Batch [1000]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096506,	
2017-06-27 20:56:19,258 Epoch[38] Batch [1010]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096408,	
2017-06-27 20:56:24,555 Epoch[38] Batch [1020]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096353,	
2017-06-27 20:56:29,854 Epoch[38] Batch [1030]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096277,	
2017-06-27 20:56:35,142 Epoch[38] Batch [1040]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096335,	
2017-06-27 20:56:40,510 Epoch[38] Batch [1050]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096370,	
2017-06-27 20:56:45,762 Epoch[38] Batch [1060]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096462,	
2017-06-27 20:56:51,101 Epoch[38] Batch [1070]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096409,	
2017-06-27 20:56:56,403 Epoch[38] Batch [1080]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096459,	
2017-06-27 20:57:01,692 Epoch[38] Batch [1090]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096597,	
2017-06-27 20:57:06,995 Epoch[38] Batch [1100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096572,	
2017-06-27 20:57:12,335 Epoch[38] Batch [1110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096544,	
2017-06-27 20:57:17,618 Epoch[38] Batch [1120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096570,	
2017-06-27 20:57:22,981 Epoch[38] Batch [1130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096515,	
2017-06-27 20:57:28,249 Epoch[38] Batch [1140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096473,	
2017-06-27 20:57:33,573 Epoch[38] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096450,	
2017-06-27 20:57:38,890 Epoch[38] Batch [1160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096385,	
2017-06-27 20:57:44,205 Epoch[38] Batch [1170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096422,	
2017-06-27 20:57:49,522 Epoch[38] Batch [1180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096392,	
2017-06-27 20:57:54,797 Epoch[38] Batch [1190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096412,	
2017-06-27 20:58:00,159 Epoch[38] Batch [1200]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096494,	
2017-06-27 20:58:05,411 Epoch[38] Batch [1210]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096545,	
2017-06-27 20:58:10,756 Epoch[38] Batch [1220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096578,	
2017-06-27 20:58:16,062 Epoch[38] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096574,	
2017-06-27 20:58:21,344 Epoch[38] Batch [1240]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096510,	
2017-06-27 20:58:25,571 Epoch[38] Batch [1250]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.096514,	
2017-06-27 20:58:30,825 Epoch[38] Batch [1260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096526,	
2017-06-27 20:58:36,115 Epoch[38] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096444,	
2017-06-27 20:58:41,403 Epoch[38] Batch [1280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096444,	
2017-06-27 20:58:46,686 Epoch[38] Batch [1290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096429,	
2017-06-27 20:58:51,986 Epoch[38] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096394,	
2017-06-27 20:58:57,271 Epoch[38] Batch [1310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096403,	
2017-06-27 20:59:02,548 Epoch[38] Batch [1320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096399,	
2017-06-27 20:59:07,878 Epoch[38] Batch [1330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096398,	
2017-06-27 20:59:13,149 Epoch[38] Batch [1340]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096398,	
2017-06-27 20:59:18,465 Epoch[38] Batch [1350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096378,	
2017-06-27 20:59:23,677 Epoch[38] Batch [1360]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096378,	
2017-06-27 20:59:28,977 Epoch[38] Batch [1370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096460,	
2017-06-27 20:59:34,292 Epoch[38] Batch [1380]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096474,	
2017-06-27 20:59:39,571 Epoch[38] Batch [1390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096460,	
2017-06-27 20:59:44,893 Epoch[38] Batch [1400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096461,	
2017-06-27 20:59:50,189 Epoch[38] Batch [1410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096405,	
2017-06-27 20:59:55,525 Epoch[38] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096454,	
2017-06-27 21:00:00,807 Epoch[38] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096467,	
2017-06-27 21:00:06,124 Epoch[38] Batch [1440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096528,	
2017-06-27 21:00:11,452 Epoch[38] Batch [1450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096633,	
2017-06-27 21:00:16,717 Epoch[38] Batch [1460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096615,	
2017-06-27 21:00:22,008 Epoch[38] Batch [1470]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096630,	
2017-06-27 21:00:27,337 Epoch[38] Batch [1480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096664,	
2017-06-27 21:00:30,545 Epoch[38] Train-FCNLogLoss=0.096657
2017-06-27 21:00:30,545 Epoch[38] Time cost=787.169
2017-06-27 21:00:31,398 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0039.params"
2017-06-27 21:00:33,034 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0039.states"
2017-06-27 21:00:38,953 Epoch[39] Batch [10]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097283,	
2017-06-27 21:00:44,272 Epoch[39] Batch [20]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098614,	
2017-06-27 21:00:49,566 Epoch[39] Batch [30]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100946,	
2017-06-27 21:00:54,842 Epoch[39] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097704,	
2017-06-27 21:01:00,129 Epoch[39] Batch [50]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097687,	
2017-06-27 21:01:05,444 Epoch[39] Batch [60]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095836,	
2017-06-27 21:01:10,721 Epoch[39] Batch [70]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095818,	
2017-06-27 21:01:16,012 Epoch[39] Batch [80]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095785,	
2017-06-27 21:01:21,290 Epoch[39] Batch [90]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096026,	
2017-06-27 21:01:26,559 Epoch[39] Batch [100]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096166,	
2017-06-27 21:01:31,814 Epoch[39] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.095739,	
2017-06-27 21:01:37,122 Epoch[39] Batch [120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095658,	
2017-06-27 21:01:42,401 Epoch[39] Batch [130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096511,	
2017-06-27 21:01:47,684 Epoch[39] Batch [140]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095944,	
2017-06-27 21:01:52,961 Epoch[39] Batch [150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096103,	
2017-06-27 21:01:58,237 Epoch[39] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095159,	
2017-06-27 21:02:03,504 Epoch[39] Batch [170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094253,	
2017-06-27 21:02:08,824 Epoch[39] Batch [180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094081,	
2017-06-27 21:02:14,094 Epoch[39] Batch [190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094075,	
2017-06-27 21:02:19,348 Epoch[39] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093287,	
2017-06-27 21:02:24,614 Epoch[39] Batch [210]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092967,	
2017-06-27 21:02:29,885 Epoch[39] Batch [220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092978,	
2017-06-27 21:02:35,218 Epoch[39] Batch [230]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093149,	
2017-06-27 21:02:40,568 Epoch[39] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092942,	
2017-06-27 21:02:45,847 Epoch[39] Batch [250]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093282,	
2017-06-27 21:02:51,145 Epoch[39] Batch [260]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093231,	
2017-06-27 21:02:56,455 Epoch[39] Batch [270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093376,	
2017-06-27 21:03:01,746 Epoch[39] Batch [280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093096,	
2017-06-27 21:03:07,056 Epoch[39] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093025,	
2017-06-27 21:03:12,353 Epoch[39] Batch [300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093139,	
2017-06-27 21:03:17,615 Epoch[39] Batch [310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092937,	
2017-06-27 21:03:22,928 Epoch[39] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092770,	
2017-06-27 21:03:28,218 Epoch[39] Batch [330]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092682,	
2017-06-27 21:03:33,527 Epoch[39] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092801,	
2017-06-27 21:03:38,843 Epoch[39] Batch [350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092767,	
2017-06-27 21:03:44,148 Epoch[39] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092874,	
2017-06-27 21:03:49,398 Epoch[39] Batch [370]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092896,	
2017-06-27 21:03:54,736 Epoch[39] Batch [380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093040,	
2017-06-27 21:04:00,027 Epoch[39] Batch [390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093315,	
2017-06-27 21:04:05,357 Epoch[39] Batch [400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093288,	
2017-06-27 21:04:10,672 Epoch[39] Batch [410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093440,	
2017-06-27 21:04:15,987 Epoch[39] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093507,	
2017-06-27 21:04:21,223 Epoch[39] Batch [430]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093576,	
2017-06-27 21:04:26,510 Epoch[39] Batch [440]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093455,	
2017-06-27 21:04:31,782 Epoch[39] Batch [450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093485,	
2017-06-27 21:04:37,100 Epoch[39] Batch [460]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093401,	
2017-06-27 21:04:42,403 Epoch[39] Batch [470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093558,	
2017-06-27 21:04:47,717 Epoch[39] Batch [480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093523,	
2017-06-27 21:04:53,010 Epoch[39] Batch [490]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094241,	
2017-06-27 21:04:58,276 Epoch[39] Batch [500]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094514,	
2017-06-27 21:05:03,629 Epoch[39] Batch [510]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094833,	
2017-06-27 21:05:08,932 Epoch[39] Batch [520]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095101,	
2017-06-27 21:05:14,234 Epoch[39] Batch [530]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095200,	
2017-06-27 21:05:19,552 Epoch[39] Batch [540]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095256,	
2017-06-27 21:05:24,906 Epoch[39] Batch [550]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095168,	
2017-06-27 21:05:30,152 Epoch[39] Batch [560]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095130,	
2017-06-27 21:05:35,474 Epoch[39] Batch [570]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095161,	
2017-06-27 21:05:40,739 Epoch[39] Batch [580]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095141,	
2017-06-27 21:05:46,010 Epoch[39] Batch [590]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095219,	
2017-06-27 21:05:51,345 Epoch[39] Batch [600]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095337,	
2017-06-27 21:05:56,616 Epoch[39] Batch [610]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095277,	
2017-06-27 21:06:01,950 Epoch[39] Batch [620]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095251,	
2017-06-27 21:06:07,225 Epoch[39] Batch [630]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095281,	
2017-06-27 21:06:12,499 Epoch[39] Batch [640]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095393,	
2017-06-27 21:06:17,822 Epoch[39] Batch [650]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095370,	
2017-06-27 21:06:23,096 Epoch[39] Batch [660]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095283,	
2017-06-27 21:06:28,371 Epoch[39] Batch [670]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095204,	
2017-06-27 21:06:33,690 Epoch[39] Batch [680]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095162,	
2017-06-27 21:06:38,957 Epoch[39] Batch [690]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095121,	
2017-06-27 21:06:44,241 Epoch[39] Batch [700]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094924,	
2017-06-27 21:06:49,531 Epoch[39] Batch [710]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094982,	
2017-06-27 21:06:54,843 Epoch[39] Batch [720]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094994,	
2017-06-27 21:07:00,130 Epoch[39] Batch [730]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095148,	
2017-06-27 21:07:05,424 Epoch[39] Batch [740]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095127,	
2017-06-27 21:07:10,701 Epoch[39] Batch [750]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095252,	
2017-06-27 21:07:16,020 Epoch[39] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095627,	
2017-06-27 21:07:21,334 Epoch[39] Batch [770]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095790,	
2017-06-27 21:07:26,629 Epoch[39] Batch [780]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095790,	
2017-06-27 21:07:31,902 Epoch[39] Batch [790]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095842,	
2017-06-27 21:07:37,168 Epoch[39] Batch [800]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095798,	
2017-06-27 21:07:42,490 Epoch[39] Batch [810]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095818,	
2017-06-27 21:07:47,773 Epoch[39] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095694,	
2017-06-27 21:07:53,058 Epoch[39] Batch [830]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095653,	
2017-06-27 21:07:58,363 Epoch[39] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095715,	
2017-06-27 21:08:03,656 Epoch[39] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095707,	
2017-06-27 21:08:08,964 Epoch[39] Batch [860]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095699,	
2017-06-27 21:08:14,213 Epoch[39] Batch [870]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.095578,	
2017-06-27 21:08:19,513 Epoch[39] Batch [880]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095635,	
2017-06-27 21:08:24,817 Epoch[39] Batch [890]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095607,	
2017-06-27 21:08:30,137 Epoch[39] Batch [900]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095564,	
2017-06-27 21:08:35,414 Epoch[39] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095427,	
2017-06-27 21:08:40,728 Epoch[39] Batch [920]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095464,	
2017-06-27 21:08:46,005 Epoch[39] Batch [930]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095466,	
2017-06-27 21:08:51,274 Epoch[39] Batch [940]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095454,	
2017-06-27 21:08:56,574 Epoch[39] Batch [950]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095525,	
2017-06-27 21:09:01,866 Epoch[39] Batch [960]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095641,	
2017-06-27 21:09:07,169 Epoch[39] Batch [970]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095678,	
2017-06-27 21:09:12,452 Epoch[39] Batch [980]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095727,	
2017-06-27 21:09:17,720 Epoch[39] Batch [990]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095641,	
2017-06-27 21:09:23,012 Epoch[39] Batch [1000]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095582,	
2017-06-27 21:09:28,308 Epoch[39] Batch [1010]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095603,	
2017-06-27 21:09:33,598 Epoch[39] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095675,	
2017-06-27 21:09:38,892 Epoch[39] Batch [1030]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095689,	
2017-06-27 21:09:44,184 Epoch[39] Batch [1040]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095668,	
2017-06-27 21:09:49,399 Epoch[39] Batch [1050]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095661,	
2017-06-27 21:09:54,707 Epoch[39] Batch [1060]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095607,	
2017-06-27 21:10:00,087 Epoch[39] Batch [1070]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095546,	
2017-06-27 21:10:05,407 Epoch[39] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095675,	
2017-06-27 21:10:10,711 Epoch[39] Batch [1090]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095942,	
2017-06-27 21:10:16,002 Epoch[39] Batch [1100]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096051,	
2017-06-27 21:10:21,286 Epoch[39] Batch [1110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096059,	
2017-06-27 21:10:26,488 Epoch[39] Batch [1120]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.096025,	
2017-06-27 21:10:31,845 Epoch[39] Batch [1130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096026,	
2017-06-27 21:10:37,120 Epoch[39] Batch [1140]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096062,	
2017-06-27 21:10:42,417 Epoch[39] Batch [1150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096116,	
2017-06-27 21:10:47,719 Epoch[39] Batch [1160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096077,	
2017-06-27 21:10:53,038 Epoch[39] Batch [1170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096045,	
2017-06-27 21:10:58,339 Epoch[39] Batch [1180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096079,	
2017-06-27 21:11:03,630 Epoch[39] Batch [1190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096083,	
2017-06-27 21:11:08,989 Epoch[39] Batch [1200]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096032,	
2017-06-27 21:11:14,261 Epoch[39] Batch [1210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096033,	
2017-06-27 21:11:19,583 Epoch[39] Batch [1220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096057,	
2017-06-27 21:11:24,839 Epoch[39] Batch [1230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096008,	
2017-06-27 21:11:30,104 Epoch[39] Batch [1240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096056,	
2017-06-27 21:11:34,356 Epoch[39] Batch [1250]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.096135,	
2017-06-27 21:11:39,530 Epoch[39] Batch [1260]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096148,	
2017-06-27 21:11:44,782 Epoch[39] Batch [1270]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096114,	
2017-06-27 21:11:50,066 Epoch[39] Batch [1280]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096103,	
2017-06-27 21:11:55,349 Epoch[39] Batch [1290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096096,	
2017-06-27 21:12:00,644 Epoch[39] Batch [1300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096072,	
2017-06-27 21:12:05,937 Epoch[39] Batch [1310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096133,	
2017-06-27 21:12:11,155 Epoch[39] Batch [1320]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096151,	
2017-06-27 21:12:16,465 Epoch[39] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096219,	
2017-06-27 21:12:21,703 Epoch[39] Batch [1340]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.096258,	
2017-06-27 21:12:27,001 Epoch[39] Batch [1350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096232,	
2017-06-27 21:12:32,295 Epoch[39] Batch [1360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096244,	
2017-06-27 21:12:37,496 Epoch[39] Batch [1370]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.096232,	
2017-06-27 21:12:42,769 Epoch[39] Batch [1380]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096255,	
2017-06-27 21:12:48,064 Epoch[39] Batch [1390]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096312,	
2017-06-27 21:12:53,379 Epoch[39] Batch [1400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096295,	
2017-06-27 21:12:58,676 Epoch[39] Batch [1410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096291,	
2017-06-27 21:13:03,984 Epoch[39] Batch [1420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096245,	
2017-06-27 21:13:09,311 Epoch[39] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096220,	
2017-06-27 21:13:14,576 Epoch[39] Batch [1440]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096196,	
2017-06-27 21:13:19,938 Epoch[39] Batch [1450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096168,	
2017-06-27 21:13:25,217 Epoch[39] Batch [1460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096196,	
2017-06-27 21:13:30,516 Epoch[39] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096227,	
2017-06-27 21:13:35,778 Epoch[39] Batch [1480]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096269,	
2017-06-27 21:13:38,925 Epoch[39] Train-FCNLogLoss=0.096260
2017-06-27 21:13:38,925 Epoch[39] Time cost=785.891
2017-06-27 21:13:39,823 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0040.params"
2017-06-27 21:13:41,628 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0040.states"
2017-06-27 21:13:47,627 Epoch[40] Batch [10]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100042,	
2017-06-27 21:13:52,907 Epoch[40] Batch [20]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098250,	
2017-06-27 21:13:58,190 Epoch[40] Batch [30]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095011,	
2017-06-27 21:14:03,505 Epoch[40] Batch [40]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093139,	
2017-06-27 21:14:08,764 Epoch[40] Batch [50]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093815,	
2017-06-27 21:14:14,042 Epoch[40] Batch [60]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093349,	
2017-06-27 21:14:19,330 Epoch[40] Batch [70]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092259,	
2017-06-27 21:14:24,631 Epoch[40] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093058,	
2017-06-27 21:14:29,914 Epoch[40] Batch [90]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093846,	
2017-06-27 21:14:35,224 Epoch[40] Batch [100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094289,	
2017-06-27 21:14:40,411 Epoch[40] Batch [110]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094432,	
2017-06-27 21:14:45,727 Epoch[40] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093805,	
2017-06-27 21:14:51,036 Epoch[40] Batch [130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094019,	
2017-06-27 21:14:56,347 Epoch[40] Batch [140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095052,	
2017-06-27 21:15:01,694 Epoch[40] Batch [150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094854,	
2017-06-27 21:15:06,964 Epoch[40] Batch [160]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095021,	
2017-06-27 21:15:12,287 Epoch[40] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094332,	
2017-06-27 21:15:17,587 Epoch[40] Batch [180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094905,	
2017-06-27 21:15:22,886 Epoch[40] Batch [190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094312,	
2017-06-27 21:15:28,201 Epoch[40] Batch [200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094484,	
2017-06-27 21:15:33,489 Epoch[40] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094502,	
2017-06-27 21:15:38,779 Epoch[40] Batch [220]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094125,	
2017-06-27 21:15:44,082 Epoch[40] Batch [230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093784,	
2017-06-27 21:15:49,385 Epoch[40] Batch [240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093626,	
2017-06-27 21:15:54,712 Epoch[40] Batch [250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094090,	
2017-06-27 21:16:00,041 Epoch[40] Batch [260]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094466,	
2017-06-27 21:16:05,368 Epoch[40] Batch [270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094240,	
2017-06-27 21:16:10,638 Epoch[40] Batch [280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094181,	
2017-06-27 21:16:15,959 Epoch[40] Batch [290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093937,	
2017-06-27 21:16:21,291 Epoch[40] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093749,	
2017-06-27 21:16:26,598 Epoch[40] Batch [310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093710,	
2017-06-27 21:16:31,876 Epoch[40] Batch [320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093736,	
2017-06-27 21:16:37,261 Epoch[40] Batch [330]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093660,	
2017-06-27 21:16:42,539 Epoch[40] Batch [340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093476,	
2017-06-27 21:16:47,821 Epoch[40] Batch [350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093355,	
2017-06-27 21:16:53,165 Epoch[40] Batch [360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093345,	
2017-06-27 21:16:58,425 Epoch[40] Batch [370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093460,	
2017-06-27 21:17:03,786 Epoch[40] Batch [380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093270,	
2017-06-27 21:17:09,064 Epoch[40] Batch [390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093313,	
2017-06-27 21:17:14,383 Epoch[40] Batch [400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092960,	
2017-06-27 21:17:19,666 Epoch[40] Batch [410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092796,	
2017-06-27 21:17:24,953 Epoch[40] Batch [420]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092808,	
2017-06-27 21:17:30,249 Epoch[40] Batch [430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092806,	
2017-06-27 21:17:35,568 Epoch[40] Batch [440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092756,	
2017-06-27 21:17:40,931 Epoch[40] Batch [450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092893,	
2017-06-27 21:17:46,246 Epoch[40] Batch [460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092947,	
2017-06-27 21:17:51,536 Epoch[40] Batch [470]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093164,	
2017-06-27 21:17:56,825 Epoch[40] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093278,	
2017-06-27 21:18:02,136 Epoch[40] Batch [490]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093299,	
2017-06-27 21:18:07,411 Epoch[40] Batch [500]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093319,	
2017-06-27 21:18:12,715 Epoch[40] Batch [510]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093308,	
2017-06-27 21:18:16,944 Update[60000]: Change learning rate to 5.00000e-05
2017-06-27 21:18:18,010 Epoch[40] Batch [520]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093141,	
2017-06-27 21:18:23,288 Epoch[40] Batch [530]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093076,	
2017-06-27 21:18:28,574 Epoch[40] Batch [540]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093026,	
2017-06-27 21:18:33,866 Epoch[40] Batch [550]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092923,	
2017-06-27 21:18:39,127 Epoch[40] Batch [560]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092833,	
2017-06-27 21:18:44,390 Epoch[40] Batch [570]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092819,	
2017-06-27 21:18:49,704 Epoch[40] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092833,	
2017-06-27 21:18:55,026 Epoch[40] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092756,	
2017-06-27 21:19:00,324 Epoch[40] Batch [600]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092774,	
2017-06-27 21:19:05,659 Epoch[40] Batch [610]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092752,	
2017-06-27 21:19:10,947 Epoch[40] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092678,	
2017-06-27 21:19:16,212 Epoch[40] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092570,	
2017-06-27 21:19:21,542 Epoch[40] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092638,	
2017-06-27 21:19:26,854 Epoch[40] Batch [650]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092550,	
2017-06-27 21:19:32,161 Epoch[40] Batch [660]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092373,	
2017-06-27 21:19:37,492 Epoch[40] Batch [670]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092330,	
2017-06-27 21:19:42,816 Epoch[40] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092342,	
2017-06-27 21:19:48,067 Epoch[40] Batch [690]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092061,	
2017-06-27 21:19:53,405 Epoch[40] Batch [700]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092108,	
2017-06-27 21:19:58,708 Epoch[40] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092135,	
2017-06-27 21:20:03,993 Epoch[40] Batch [720]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092204,	
2017-06-27 21:20:09,282 Epoch[40] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092083,	
2017-06-27 21:20:14,572 Epoch[40] Batch [740]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092105,	
2017-06-27 21:20:19,932 Epoch[40] Batch [750]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092168,	
2017-06-27 21:20:25,161 Epoch[40] Batch [760]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.092222,	
2017-06-27 21:20:30,455 Epoch[40] Batch [770]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092192,	
2017-06-27 21:20:35,804 Epoch[40] Batch [780]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092208,	
2017-06-27 21:20:41,051 Epoch[40] Batch [790]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092163,	
2017-06-27 21:20:46,339 Epoch[40] Batch [800]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092184,	
2017-06-27 21:20:51,644 Epoch[40] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092107,	
2017-06-27 21:20:56,933 Epoch[40] Batch [820]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092081,	
2017-06-27 21:21:02,259 Epoch[40] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092057,	
2017-06-27 21:21:07,562 Epoch[40] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092042,	
2017-06-27 21:21:12,853 Epoch[40] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091967,	
2017-06-27 21:21:18,174 Epoch[40] Batch [860]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091959,	
2017-06-27 21:21:23,460 Epoch[40] Batch [870]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091928,	
2017-06-27 21:21:28,741 Epoch[40] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091829,	
2017-06-27 21:21:34,063 Epoch[40] Batch [890]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091877,	
2017-06-27 21:21:39,366 Epoch[40] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091790,	
2017-06-27 21:21:44,650 Epoch[40] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091772,	
2017-06-27 21:21:49,954 Epoch[40] Batch [920]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091770,	
2017-06-27 21:21:55,266 Epoch[40] Batch [930]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091827,	
2017-06-27 21:22:00,573 Epoch[40] Batch [940]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091818,	
2017-06-27 21:22:05,854 Epoch[40] Batch [950]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091777,	
2017-06-27 21:22:11,189 Epoch[40] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091772,	
2017-06-27 21:22:16,493 Epoch[40] Batch [970]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091728,	
2017-06-27 21:22:21,801 Epoch[40] Batch [980]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091745,	
2017-06-27 21:22:27,071 Epoch[40] Batch [990]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091722,	
2017-06-27 21:22:32,422 Epoch[40] Batch [1000]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091741,	
2017-06-27 21:22:37,731 Epoch[40] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091723,	
2017-06-27 21:22:43,022 Epoch[40] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091673,	
2017-06-27 21:22:48,283 Epoch[40] Batch [1030]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091716,	
2017-06-27 21:22:53,601 Epoch[40] Batch [1040]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091674,	
2017-06-27 21:22:58,941 Epoch[40] Batch [1050]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091721,	
2017-06-27 21:23:04,207 Epoch[40] Batch [1060]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091724,	
2017-06-27 21:23:09,541 Epoch[40] Batch [1070]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091740,	
2017-06-27 21:23:14,813 Epoch[40] Batch [1080]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091723,	
2017-06-27 21:23:20,140 Epoch[40] Batch [1090]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091727,	
2017-06-27 21:23:25,447 Epoch[40] Batch [1100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091689,	
2017-06-27 21:23:30,768 Epoch[40] Batch [1110]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091547,	
2017-06-27 21:23:36,033 Epoch[40] Batch [1120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091499,	
2017-06-27 21:23:41,365 Epoch[40] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091388,	
2017-06-27 21:23:46,641 Epoch[40] Batch [1140]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091398,	
2017-06-27 21:23:51,950 Epoch[40] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091280,	
2017-06-27 21:23:57,249 Epoch[40] Batch [1160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091250,	
2017-06-27 21:24:02,576 Epoch[40] Batch [1170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091257,	
2017-06-27 21:24:07,932 Epoch[40] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091243,	
2017-06-27 21:24:13,205 Epoch[40] Batch [1190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091277,	
2017-06-27 21:24:18,525 Epoch[40] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091335,	
2017-06-27 21:24:23,705 Epoch[40] Batch [1210]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.091369,	
2017-06-27 21:24:29,023 Epoch[40] Batch [1220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091330,	
2017-06-27 21:24:34,343 Epoch[40] Batch [1230]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091372,	
2017-06-27 21:24:39,647 Epoch[40] Batch [1240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091414,	
2017-06-27 21:24:43,876 Epoch[40] Batch [1250]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.091404,	
2017-06-27 21:24:48,987 Epoch[40] Batch [1260]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.091338,	
2017-06-27 21:24:54,275 Epoch[40] Batch [1270]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091321,	
2017-06-27 21:24:59,583 Epoch[40] Batch [1280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091228,	
2017-06-27 21:25:04,937 Epoch[40] Batch [1290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091298,	
2017-06-27 21:25:10,221 Epoch[40] Batch [1300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091312,	
2017-06-27 21:25:15,516 Epoch[40] Batch [1310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091312,	
2017-06-27 21:25:20,846 Epoch[40] Batch [1320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091352,	
2017-06-27 21:25:26,141 Epoch[40] Batch [1330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091319,	
2017-06-27 21:25:31,468 Epoch[40] Batch [1340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091328,	
2017-06-27 21:25:36,730 Epoch[40] Batch [1350]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091244,	
2017-06-27 21:25:42,081 Epoch[40] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091319,	
2017-06-27 21:25:47,395 Epoch[40] Batch [1370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091310,	
2017-06-27 21:25:52,682 Epoch[40] Batch [1380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091344,	
2017-06-27 21:25:57,972 Epoch[40] Batch [1390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091325,	
2017-06-27 21:26:03,307 Epoch[40] Batch [1400]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091351,	
2017-06-27 21:26:08,577 Epoch[40] Batch [1410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091319,	
2017-06-27 21:26:13,944 Epoch[40] Batch [1420]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091284,	
2017-06-27 21:26:19,224 Epoch[40] Batch [1430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091322,	
2017-06-27 21:26:24,531 Epoch[40] Batch [1440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091269,	
2017-06-27 21:26:29,858 Epoch[40] Batch [1450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091367,	
2017-06-27 21:26:35,156 Epoch[40] Batch [1460]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091360,	
2017-06-27 21:26:40,457 Epoch[40] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091359,	
2017-06-27 21:26:45,736 Epoch[40] Batch [1480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091423,	
2017-06-27 21:26:48,940 Epoch[40] Train-FCNLogLoss=0.091454
2017-06-27 21:26:48,940 Epoch[40] Time cost=787.311
2017-06-27 21:26:49,792 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0041.params"
2017-06-27 21:26:51,487 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0041.states"
2017-06-27 21:26:57,524 Epoch[41] Batch [10]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097161,	
2017-06-27 21:27:02,791 Epoch[41] Batch [20]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093001,	
2017-06-27 21:27:08,080 Epoch[41] Batch [30]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089396,	
2017-06-27 21:27:13,368 Epoch[41] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089285,	
2017-06-27 21:27:18,705 Epoch[41] Batch [50]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087448,	
2017-06-27 21:27:24,019 Epoch[41] Batch [60]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087096,	
2017-06-27 21:27:29,296 Epoch[41] Batch [70]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-27 21:27:34,625 Epoch[41] Batch [80]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087353,	
2017-06-27 21:27:39,916 Epoch[41] Batch [90]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088134,	
2017-06-27 21:27:45,198 Epoch[41] Batch [100]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089513,	
2017-06-27 21:27:50,546 Epoch[41] Batch [110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089594,	
2017-06-27 21:27:55,806 Epoch[41] Batch [120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089034,	
2017-06-27 21:28:01,127 Epoch[41] Batch [130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089724,	
2017-06-27 21:28:06,427 Epoch[41] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089574,	
2017-06-27 21:28:11,764 Epoch[41] Batch [150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089093,	
2017-06-27 21:28:17,054 Epoch[41] Batch [160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088988,	
2017-06-27 21:28:22,391 Epoch[41] Batch [170]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088534,	
2017-06-27 21:28:27,703 Epoch[41] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088594,	
2017-06-27 21:28:32,989 Epoch[41] Batch [190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089870,	
2017-06-27 21:28:38,284 Epoch[41] Batch [200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089474,	
2017-06-27 21:28:43,596 Epoch[41] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089220,	
2017-06-27 21:28:48,856 Epoch[41] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089130,	
2017-06-27 21:28:54,159 Epoch[41] Batch [230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088869,	
2017-06-27 21:28:59,473 Epoch[41] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-27 21:29:04,721 Epoch[41] Batch [250]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089079,	
2017-06-27 21:29:10,081 Epoch[41] Batch [260]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088818,	
2017-06-27 21:29:15,388 Epoch[41] Batch [270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088970,	
2017-06-27 21:29:20,701 Epoch[41] Batch [280]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089178,	
2017-06-27 21:29:26,041 Epoch[41] Batch [290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089220,	
2017-06-27 21:29:31,330 Epoch[41] Batch [300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089151,	
2017-06-27 21:29:36,644 Epoch[41] Batch [310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088987,	
2017-06-27 21:29:41,889 Epoch[41] Batch [320]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089252,	
2017-06-27 21:29:47,187 Epoch[41] Batch [330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089564,	
2017-06-27 21:29:52,492 Epoch[41] Batch [340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089693,	
2017-06-27 21:29:57,803 Epoch[41] Batch [350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089960,	
2017-06-27 21:30:03,118 Epoch[41] Batch [360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090093,	
2017-06-27 21:30:08,419 Epoch[41] Batch [370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090014,	
2017-06-27 21:30:13,662 Epoch[41] Batch [380]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090137,	
2017-06-27 21:30:18,991 Epoch[41] Batch [390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090204,	
2017-06-27 21:30:24,317 Epoch[41] Batch [400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090407,	
2017-06-27 21:30:29,626 Epoch[41] Batch [410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090501,	
2017-06-27 21:30:34,964 Epoch[41] Batch [420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090449,	
2017-06-27 21:30:40,252 Epoch[41] Batch [430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090563,	
2017-06-27 21:30:45,524 Epoch[41] Batch [440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090826,	
2017-06-27 21:30:50,842 Epoch[41] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090881,	
2017-06-27 21:30:56,144 Epoch[41] Batch [460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090973,	
2017-06-27 21:31:01,434 Epoch[41] Batch [470]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090991,	
2017-06-27 21:31:06,733 Epoch[41] Batch [480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091109,	
2017-06-27 21:31:12,021 Epoch[41] Batch [490]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090956,	
2017-06-27 21:31:17,322 Epoch[41] Batch [500]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090866,	
2017-06-27 21:31:22,613 Epoch[41] Batch [510]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090754,	
2017-06-27 21:31:27,911 Epoch[41] Batch [520]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090713,	
2017-06-27 21:31:33,216 Epoch[41] Batch [530]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090618,	
2017-06-27 21:31:38,507 Epoch[41] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090644,	
2017-06-27 21:31:43,841 Epoch[41] Batch [550]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090574,	
2017-06-27 21:31:49,153 Epoch[41] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090644,	
2017-06-27 21:31:54,467 Epoch[41] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090543,	
2017-06-27 21:31:59,737 Epoch[41] Batch [580]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090596,	
2017-06-27 21:32:05,085 Epoch[41] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090772,	
2017-06-27 21:32:10,366 Epoch[41] Batch [600]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090856,	
2017-06-27 21:32:15,725 Epoch[41] Batch [610]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090770,	
2017-06-27 21:32:21,006 Epoch[41] Batch [620]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091005,	
2017-06-27 21:32:26,280 Epoch[41] Batch [630]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090995,	
2017-06-27 21:32:31,608 Epoch[41] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090916,	
2017-06-27 21:32:36,876 Epoch[41] Batch [650]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090809,	
2017-06-27 21:32:42,174 Epoch[41] Batch [660]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090738,	
2017-06-27 21:32:47,519 Epoch[41] Batch [670]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090741,	
2017-06-27 21:32:52,791 Epoch[41] Batch [680]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090608,	
2017-06-27 21:32:58,116 Epoch[41] Batch [690]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090695,	
2017-06-27 21:33:03,429 Epoch[41] Batch [700]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090779,	
2017-06-27 21:33:08,719 Epoch[41] Batch [710]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090713,	
2017-06-27 21:33:14,009 Epoch[41] Batch [720]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090537,	
2017-06-27 21:33:19,392 Epoch[41] Batch [730]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090635,	
2017-06-27 21:33:24,671 Epoch[41] Batch [740]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090667,	
2017-06-27 21:33:29,928 Epoch[41] Batch [750]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090573,	
2017-06-27 21:33:35,245 Epoch[41] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090532,	
2017-06-27 21:33:40,519 Epoch[41] Batch [770]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090495,	
2017-06-27 21:33:45,841 Epoch[41] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090474,	
2017-06-27 21:33:51,179 Epoch[41] Batch [790]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090538,	
2017-06-27 21:33:56,468 Epoch[41] Batch [800]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-27 21:34:01,741 Epoch[41] Batch [810]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090401,	
2017-06-27 21:34:07,066 Epoch[41] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090379,	
2017-06-27 21:34:12,370 Epoch[41] Batch [830]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090326,	
2017-06-27 21:34:17,693 Epoch[41] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090428,	
2017-06-27 21:34:22,998 Epoch[41] Batch [850]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090415,	
2017-06-27 21:34:28,318 Epoch[41] Batch [860]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090463,	
2017-06-27 21:34:33,598 Epoch[41] Batch [870]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090449,	
2017-06-27 21:34:38,883 Epoch[41] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090378,	
2017-06-27 21:34:44,204 Epoch[41] Batch [890]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090308,	
2017-06-27 21:34:49,527 Epoch[41] Batch [900]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090305,	
2017-06-27 21:34:54,842 Epoch[41] Batch [910]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090406,	
2017-06-27 21:35:00,106 Epoch[41] Batch [920]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090280,	
2017-06-27 21:35:05,448 Epoch[41] Batch [930]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090259,	
2017-06-27 21:35:10,740 Epoch[41] Batch [940]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090223,	
2017-06-27 21:35:16,061 Epoch[41] Batch [950]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090141,	
2017-06-27 21:35:21,371 Epoch[41] Batch [960]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090100,	
2017-06-27 21:35:26,654 Epoch[41] Batch [970]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090103,	
2017-06-27 21:35:31,936 Epoch[41] Batch [980]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090135,	
2017-06-27 21:35:37,255 Epoch[41] Batch [990]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090200,	
2017-06-27 21:35:42,600 Epoch[41] Batch [1000]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090244,	
2017-06-27 21:35:47,903 Epoch[41] Batch [1010]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090118,	
2017-06-27 21:35:53,186 Epoch[41] Batch [1020]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090092,	
2017-06-27 21:35:58,499 Epoch[41] Batch [1030]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090056,	
2017-06-27 21:36:03,829 Epoch[41] Batch [1040]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090054,	
2017-06-27 21:36:09,123 Epoch[41] Batch [1050]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089989,	
2017-06-27 21:36:14,416 Epoch[41] Batch [1060]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090000,	
2017-06-27 21:36:19,739 Epoch[41] Batch [1070]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089918,	
2017-06-27 21:36:25,043 Epoch[41] Batch [1080]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089890,	
2017-06-27 21:36:30,351 Epoch[41] Batch [1090]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089933,	
2017-06-27 21:36:35,664 Epoch[41] Batch [1100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089844,	
2017-06-27 21:36:40,979 Epoch[41] Batch [1110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089850,	
2017-06-27 21:36:46,329 Epoch[41] Batch [1120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089808,	
2017-06-27 21:36:51,633 Epoch[41] Batch [1130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089827,	
2017-06-27 21:36:56,914 Epoch[41] Batch [1140]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089852,	
2017-06-27 21:37:02,206 Epoch[41] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089788,	
2017-06-27 21:37:07,513 Epoch[41] Batch [1160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089720,	
2017-06-27 21:37:12,867 Epoch[41] Batch [1170]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089754,	
2017-06-27 21:37:18,155 Epoch[41] Batch [1180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089741,	
2017-06-27 21:37:23,495 Epoch[41] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089719,	
2017-06-27 21:37:28,775 Epoch[41] Batch [1200]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089695,	
2017-06-27 21:37:34,060 Epoch[41] Batch [1210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089690,	
2017-06-27 21:37:39,382 Epoch[41] Batch [1220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089691,	
2017-06-27 21:37:44,632 Epoch[41] Batch [1230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089695,	
2017-06-27 21:37:49,957 Epoch[41] Batch [1240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089619,	
2017-06-27 21:37:54,347 Epoch[41] Batch [1250]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.089544,	
2017-06-27 21:37:59,598 Epoch[41] Batch [1260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089530,	
2017-06-27 21:38:04,901 Epoch[41] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089544,	
2017-06-27 21:38:10,185 Epoch[41] Batch [1280]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089593,	
2017-06-27 21:38:15,517 Epoch[41] Batch [1290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089512,	
2017-06-27 21:38:20,810 Epoch[41] Batch [1300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089575,	
2017-06-27 21:38:26,074 Epoch[41] Batch [1310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089657,	
2017-06-27 21:38:31,437 Epoch[41] Batch [1320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089635,	
2017-06-27 21:38:36,750 Epoch[41] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089560,	
2017-06-27 21:38:42,044 Epoch[41] Batch [1340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089658,	
2017-06-27 21:38:47,371 Epoch[41] Batch [1350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089633,	
2017-06-27 21:38:52,681 Epoch[41] Batch [1360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089585,	
2017-06-27 21:38:57,967 Epoch[41] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089589,	
2017-06-27 21:39:03,255 Epoch[41] Batch [1380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089556,	
2017-06-27 21:39:08,544 Epoch[41] Batch [1390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089504,	
2017-06-27 21:39:13,804 Epoch[41] Batch [1400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089508,	
2017-06-27 21:39:19,114 Epoch[41] Batch [1410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089451,	
2017-06-27 21:39:24,378 Epoch[41] Batch [1420]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089478,	
2017-06-27 21:39:29,674 Epoch[41] Batch [1430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089494,	
2017-06-27 21:39:34,972 Epoch[41] Batch [1440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089510,	
2017-06-27 21:39:40,269 Epoch[41] Batch [1450]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089498,	
2017-06-27 21:39:45,527 Epoch[41] Batch [1460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089419,	
2017-06-27 21:39:50,810 Epoch[41] Batch [1470]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-27 21:39:56,085 Epoch[41] Batch [1480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089504,	
2017-06-27 21:39:59,267 Epoch[41] Train-FCNLogLoss=0.089513
2017-06-27 21:39:59,267 Epoch[41] Time cost=787.779
2017-06-27 21:40:00,163 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0042.params"
2017-06-27 21:40:01,921 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0042.states"
2017-06-27 21:40:08,127 Epoch[42] Batch [10]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-27 21:40:13,372 Epoch[42] Batch [20]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089226,	
2017-06-27 21:40:18,654 Epoch[42] Batch [30]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088471,	
2017-06-27 21:40:23,981 Epoch[42] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088400,	
2017-06-27 21:40:29,247 Epoch[42] Batch [50]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087566,	
2017-06-27 21:40:34,500 Epoch[42] Batch [60]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086816,	
2017-06-27 21:40:39,805 Epoch[42] Batch [70]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.085798,	
2017-06-27 21:40:45,064 Epoch[42] Batch [80]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.085830,	
2017-06-27 21:40:50,336 Epoch[42] Batch [90]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087485,	
2017-06-27 21:40:55,647 Epoch[42] Batch [100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087840,	
2017-06-27 21:41:00,915 Epoch[42] Batch [110]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087781,	
2017-06-27 21:41:06,224 Epoch[42] Batch [120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087918,	
2017-06-27 21:41:11,498 Epoch[42] Batch [130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087343,	
2017-06-27 21:41:16,791 Epoch[42] Batch [140]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087247,	
2017-06-27 21:41:22,101 Epoch[42] Batch [150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087274,	
2017-06-27 21:41:27,397 Epoch[42] Batch [160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087743,	
2017-06-27 21:41:32,693 Epoch[42] Batch [170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087558,	
2017-06-27 21:41:37,981 Epoch[42] Batch [180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087579,	
2017-06-27 21:41:43,264 Epoch[42] Batch [190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087539,	
2017-06-27 21:41:48,558 Epoch[42] Batch [200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087580,	
2017-06-27 21:41:53,869 Epoch[42] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087831,	
2017-06-27 21:41:59,147 Epoch[42] Batch [220]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088383,	
2017-06-27 21:42:04,414 Epoch[42] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088073,	
2017-06-27 21:42:09,704 Epoch[42] Batch [240]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088145,	
2017-06-27 21:42:15,022 Epoch[42] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088004,	
2017-06-27 21:42:20,331 Epoch[42] Batch [260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088306,	
2017-06-27 21:42:25,622 Epoch[42] Batch [270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088132,	
2017-06-27 21:42:30,939 Epoch[42] Batch [280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088069,	
2017-06-27 21:42:36,224 Epoch[42] Batch [290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088425,	
2017-06-27 21:42:41,547 Epoch[42] Batch [300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-27 21:42:46,810 Epoch[42] Batch [310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088691,	
2017-06-27 21:42:52,102 Epoch[42] Batch [320]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088664,	
2017-06-27 21:42:57,403 Epoch[42] Batch [330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088438,	
2017-06-27 21:43:02,696 Epoch[42] Batch [340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088471,	
2017-06-27 21:43:07,989 Epoch[42] Batch [350]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088333,	
2017-06-27 21:43:13,298 Epoch[42] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088531,	
2017-06-27 21:43:18,588 Epoch[42] Batch [370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088563,	
2017-06-27 21:43:23,890 Epoch[42] Batch [380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-27 21:43:29,172 Epoch[42] Batch [390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088270,	
2017-06-27 21:43:34,476 Epoch[42] Batch [400]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088215,	
2017-06-27 21:43:39,777 Epoch[42] Batch [410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088281,	
2017-06-27 21:43:45,052 Epoch[42] Batch [420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088340,	
2017-06-27 21:43:50,353 Epoch[42] Batch [430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088542,	
2017-06-27 21:43:55,659 Epoch[42] Batch [440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088599,	
2017-06-27 21:44:00,956 Epoch[42] Batch [450]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088615,	
2017-06-27 21:44:06,288 Epoch[42] Batch [460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088809,	
2017-06-27 21:44:11,573 Epoch[42] Batch [470]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088832,	
2017-06-27 21:44:16,853 Epoch[42] Batch [480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088689,	
2017-06-27 21:44:22,169 Epoch[42] Batch [490]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088892,	
2017-06-27 21:44:27,448 Epoch[42] Batch [500]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088910,	
2017-06-27 21:44:32,723 Epoch[42] Batch [510]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089179,	
2017-06-27 21:44:38,007 Epoch[42] Batch [520]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089147,	
2017-06-27 21:44:43,317 Epoch[42] Batch [530]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089159,	
2017-06-27 21:44:48,610 Epoch[42] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089022,	
2017-06-27 21:44:53,891 Epoch[42] Batch [550]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088958,	
2017-06-27 21:44:59,176 Epoch[42] Batch [560]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088889,	
2017-06-27 21:45:04,442 Epoch[42] Batch [570]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088842,	
2017-06-27 21:45:09,718 Epoch[42] Batch [580]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088832,	
2017-06-27 21:45:15,017 Epoch[42] Batch [590]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-27 21:45:20,345 Epoch[42] Batch [600]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088565,	
2017-06-27 21:45:25,609 Epoch[42] Batch [610]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088397,	
2017-06-27 21:45:30,902 Epoch[42] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088499,	
2017-06-27 21:45:36,175 Epoch[42] Batch [630]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088493,	
2017-06-27 21:45:41,467 Epoch[42] Batch [640]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088509,	
2017-06-27 21:45:46,769 Epoch[42] Batch [650]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088418,	
2017-06-27 21:45:52,082 Epoch[42] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088393,	
2017-06-27 21:45:57,347 Epoch[42] Batch [670]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088534,	
2017-06-27 21:46:02,575 Epoch[42] Batch [680]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088451,	
2017-06-27 21:46:07,904 Epoch[42] Batch [690]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088490,	
2017-06-27 21:46:13,139 Epoch[42] Batch [700]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-27 21:46:18,509 Epoch[42] Batch [710]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088429,	
2017-06-27 21:46:23,781 Epoch[42] Batch [720]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088316,	
2017-06-27 21:46:29,066 Epoch[42] Batch [730]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088382,	
2017-06-27 21:46:34,389 Epoch[42] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088389,	
2017-06-27 21:46:39,708 Epoch[42] Batch [750]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088356,	
2017-06-27 21:46:45,006 Epoch[42] Batch [760]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088435,	
2017-06-27 21:46:50,339 Epoch[42] Batch [770]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088569,	
2017-06-27 21:46:55,604 Epoch[42] Batch [780]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-27 21:47:00,901 Epoch[42] Batch [790]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-27 21:47:06,207 Epoch[42] Batch [800]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088487,	
2017-06-27 21:47:11,509 Epoch[42] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088545,	
2017-06-27 21:47:16,735 Epoch[42] Batch [820]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088546,	
2017-06-27 21:47:22,064 Epoch[42] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088575,	
2017-06-27 21:47:27,404 Epoch[42] Batch [840]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088641,	
2017-06-27 21:47:32,691 Epoch[42] Batch [850]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088587,	
2017-06-27 21:47:37,949 Epoch[42] Batch [860]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088670,	
2017-06-27 21:47:43,237 Epoch[42] Batch [870]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088689,	
2017-06-27 21:47:48,568 Epoch[42] Batch [880]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088770,	
2017-06-27 21:47:53,822 Epoch[42] Batch [890]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088673,	
2017-06-27 21:47:59,079 Epoch[42] Batch [900]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088690,	
2017-06-27 21:48:04,408 Epoch[42] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-27 21:48:09,713 Epoch[42] Batch [920]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088676,	
2017-06-27 21:48:15,021 Epoch[42] Batch [930]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088683,	
2017-06-27 21:48:20,307 Epoch[42] Batch [940]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088745,	
2017-06-27 21:48:25,641 Epoch[42] Batch [950]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088700,	
2017-06-27 21:48:30,962 Epoch[42] Batch [960]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088648,	
2017-06-27 21:48:36,213 Epoch[42] Batch [970]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088608,	
2017-06-27 21:48:41,528 Epoch[42] Batch [980]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088673,	
2017-06-27 21:48:46,832 Epoch[42] Batch [990]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088656,	
2017-06-27 21:48:52,136 Epoch[42] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-27 21:48:57,424 Epoch[42] Batch [1010]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-27 21:49:02,727 Epoch[42] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088783,	
2017-06-27 21:49:08,024 Epoch[42] Batch [1030]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-27 21:49:13,320 Epoch[42] Batch [1040]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088741,	
2017-06-27 21:49:18,630 Epoch[42] Batch [1050]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088766,	
2017-06-27 21:49:23,954 Epoch[42] Batch [1060]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088755,	
2017-06-27 21:49:29,249 Epoch[42] Batch [1070]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088733,	
2017-06-27 21:49:34,524 Epoch[42] Batch [1080]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088762,	
2017-06-27 21:49:39,814 Epoch[42] Batch [1090]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-27 21:49:45,154 Epoch[42] Batch [1100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088706,	
2017-06-27 21:49:50,414 Epoch[42] Batch [1110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088768,	
2017-06-27 21:49:55,721 Epoch[42] Batch [1120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-27 21:50:01,047 Epoch[42] Batch [1130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088979,	
2017-06-27 21:50:06,343 Epoch[42] Batch [1140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089011,	
2017-06-27 21:50:11,681 Epoch[42] Batch [1150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089037,	
2017-06-27 21:50:16,977 Epoch[42] Batch [1160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089066,	
2017-06-27 21:50:22,252 Epoch[42] Batch [1170]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089095,	
2017-06-27 21:50:27,562 Epoch[42] Batch [1180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089167,	
2017-06-27 21:50:32,850 Epoch[42] Batch [1190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089196,	
2017-06-27 21:50:38,166 Epoch[42] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089247,	
2017-06-27 21:50:43,479 Epoch[42] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089194,	
2017-06-27 21:50:48,754 Epoch[42] Batch [1220]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089218,	
2017-06-27 21:50:54,043 Epoch[42] Batch [1230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-27 21:50:59,362 Epoch[42] Batch [1240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089105,	
2017-06-27 21:51:03,644 Epoch[42] Batch [1250]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.089119,	
2017-06-27 21:51:08,763 Epoch[42] Batch [1260]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.089085,	
2017-06-27 21:51:14,050 Epoch[42] Batch [1270]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089108,	
2017-06-27 21:51:19,318 Epoch[42] Batch [1280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089145,	
2017-06-27 21:51:24,633 Epoch[42] Batch [1290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089116,	
2017-06-27 21:51:29,933 Epoch[42] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089148,	
2017-06-27 21:51:35,237 Epoch[42] Batch [1310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089096,	
2017-06-27 21:51:40,527 Epoch[42] Batch [1320]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089076,	
2017-06-27 21:51:45,812 Epoch[42] Batch [1330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089067,	
2017-06-27 21:51:51,128 Epoch[42] Batch [1340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089052,	
2017-06-27 21:51:56,411 Epoch[42] Batch [1350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089018,	
2017-06-27 21:52:01,729 Epoch[42] Batch [1360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088974,	
2017-06-27 21:52:06,984 Epoch[42] Batch [1370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088994,	
2017-06-27 21:52:12,274 Epoch[42] Batch [1380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089018,	
2017-06-27 21:52:17,566 Epoch[42] Batch [1390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088971,	
2017-06-27 21:52:22,861 Epoch[42] Batch [1400]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089010,	
2017-06-27 21:52:28,162 Epoch[42] Batch [1410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088931,	
2017-06-27 21:52:33,436 Epoch[42] Batch [1420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088929,	
2017-06-27 21:52:38,675 Epoch[42] Batch [1430]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088924,	
2017-06-27 21:52:43,995 Epoch[42] Batch [1440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088968,	
2017-06-27 21:52:49,272 Epoch[42] Batch [1450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088979,	
2017-06-27 21:52:54,575 Epoch[42] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088990,	
2017-06-27 21:52:59,914 Epoch[42] Batch [1470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089026,	
2017-06-27 21:53:05,214 Epoch[42] Batch [1480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089106,	
2017-06-27 21:53:08,415 Epoch[42] Train-FCNLogLoss=0.089120
2017-06-27 21:53:08,416 Epoch[42] Time cost=786.494
2017-06-27 21:53:09,307 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0043.params"
2017-06-27 21:53:11,068 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0043.states"
2017-06-27 21:53:17,054 Epoch[43] Batch [10]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.080331,	
2017-06-27 21:53:22,331 Epoch[43] Batch [20]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.083509,	
2017-06-27 21:53:27,672 Epoch[43] Batch [30]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086438,	
2017-06-27 21:53:32,987 Epoch[43] Batch [40]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087553,	
2017-06-27 21:53:38,292 Epoch[43] Batch [50]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086472,	
2017-06-27 21:53:43,578 Epoch[43] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087986,	
2017-06-27 21:53:48,899 Epoch[43] Batch [70]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088231,	
2017-06-27 21:53:54,189 Epoch[43] Batch [80]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087239,	
2017-06-27 21:53:59,489 Epoch[43] Batch [90]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086687,	
2017-06-27 21:54:04,827 Epoch[43] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086424,	
2017-06-27 21:54:10,108 Epoch[43] Batch [110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.085753,	
2017-06-27 21:54:15,421 Epoch[43] Batch [120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086421,	
2017-06-27 21:54:20,738 Epoch[43] Batch [130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087908,	
2017-06-27 21:54:26,036 Epoch[43] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-27 21:54:31,366 Epoch[43] Batch [150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087510,	
2017-06-27 21:54:36,680 Epoch[43] Batch [160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087365,	
2017-06-27 21:54:42,009 Epoch[43] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087660,	
2017-06-27 21:54:47,284 Epoch[43] Batch [180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087906,	
2017-06-27 21:54:52,575 Epoch[43] Batch [190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088007,	
2017-06-27 21:54:57,856 Epoch[43] Batch [200]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088221,	
2017-06-27 21:55:03,192 Epoch[43] Batch [210]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-27 21:55:08,445 Epoch[43] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088476,	
2017-06-27 21:55:13,748 Epoch[43] Batch [230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088525,	
2017-06-27 21:55:19,070 Epoch[43] Batch [240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088707,	
2017-06-27 21:55:24,351 Epoch[43] Batch [250]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088740,	
2017-06-27 21:55:29,659 Epoch[43] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088576,	
2017-06-27 21:55:34,959 Epoch[43] Batch [270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088336,	
2017-06-27 21:55:40,267 Epoch[43] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088038,	
2017-06-27 21:55:45,538 Epoch[43] Batch [290]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-27 21:55:50,862 Epoch[43] Batch [300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088611,	
2017-06-27 21:55:56,176 Epoch[43] Batch [310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088748,	
2017-06-27 21:56:01,491 Epoch[43] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088588,	
2017-06-27 21:56:06,792 Epoch[43] Batch [330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088378,	
2017-06-27 21:56:12,055 Epoch[43] Batch [340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088440,	
2017-06-27 21:56:17,378 Epoch[43] Batch [350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088660,	
2017-06-27 21:56:22,678 Epoch[43] Batch [360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-27 21:56:27,979 Epoch[43] Batch [370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088660,	
2017-06-27 21:56:33,280 Epoch[43] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088620,	
2017-06-27 21:56:38,591 Epoch[43] Batch [390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088596,	
2017-06-27 21:56:43,846 Epoch[43] Batch [400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-27 21:56:49,149 Epoch[43] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088882,	
2017-06-27 21:56:54,440 Epoch[43] Batch [420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089323,	
2017-06-27 21:56:59,764 Epoch[43] Batch [430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089375,	
2017-06-27 21:57:05,091 Epoch[43] Batch [440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089310,	
2017-06-27 21:57:10,383 Epoch[43] Batch [450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089442,	
2017-06-27 21:57:15,707 Epoch[43] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089503,	
2017-06-27 21:57:21,000 Epoch[43] Batch [470]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089308,	
2017-06-27 21:57:26,281 Epoch[43] Batch [480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089260,	
2017-06-27 21:57:31,556 Epoch[43] Batch [490]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089128,	
2017-06-27 21:57:36,863 Epoch[43] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089086,	
2017-06-27 21:57:42,189 Epoch[43] Batch [510]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089099,	
2017-06-27 21:57:47,464 Epoch[43] Batch [520]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088875,	
2017-06-27 21:57:52,780 Epoch[43] Batch [530]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089129,	
2017-06-27 21:57:58,072 Epoch[43] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089150,	
2017-06-27 21:58:03,434 Epoch[43] Batch [550]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089050,	
2017-06-27 21:58:08,744 Epoch[43] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089061,	
2017-06-27 21:58:14,026 Epoch[43] Batch [570]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089036,	
2017-06-27 21:58:19,296 Epoch[43] Batch [580]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088916,	
2017-06-27 21:58:24,580 Epoch[43] Batch [590]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089115,	
2017-06-27 21:58:29,850 Epoch[43] Batch [600]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089102,	
2017-06-27 21:58:35,180 Epoch[43] Batch [610]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089080,	
2017-06-27 21:58:40,477 Epoch[43] Batch [620]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089077,	
2017-06-27 21:58:45,766 Epoch[43] Batch [630]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089058,	
2017-06-27 21:58:51,028 Epoch[43] Batch [640]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-27 21:58:56,316 Epoch[43] Batch [650]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088969,	
2017-06-27 21:59:01,579 Epoch[43] Batch [660]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088996,	
2017-06-27 21:59:06,885 Epoch[43] Batch [670]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089004,	
2017-06-27 21:59:12,187 Epoch[43] Batch [680]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088953,	
2017-06-27 21:59:17,473 Epoch[43] Batch [690]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088916,	
2017-06-27 21:59:22,757 Epoch[43] Batch [700]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088843,	
2017-06-27 21:59:28,052 Epoch[43] Batch [710]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088900,	
2017-06-27 21:59:33,323 Epoch[43] Batch [720]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088814,	
2017-06-27 21:59:38,626 Epoch[43] Batch [730]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088861,	
2017-06-27 21:59:43,924 Epoch[43] Batch [740]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088804,	
2017-06-27 21:59:49,237 Epoch[43] Batch [750]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088825,	
2017-06-27 21:59:54,529 Epoch[43] Batch [760]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088791,	
2017-06-27 21:59:59,834 Epoch[43] Batch [770]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-27 22:00:05,102 Epoch[43] Batch [780]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088584,	
2017-06-27 22:00:10,385 Epoch[43] Batch [790]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088658,	
2017-06-27 22:00:15,685 Epoch[43] Batch [800]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088674,	
2017-06-27 22:00:20,956 Epoch[43] Batch [810]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088603,	
2017-06-27 22:00:26,287 Epoch[43] Batch [820]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088605,	
2017-06-27 22:00:31,562 Epoch[43] Batch [830]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088480,	
2017-06-27 22:00:36,864 Epoch[43] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088408,	
2017-06-27 22:00:42,156 Epoch[43] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088387,	
2017-06-27 22:00:47,459 Epoch[43] Batch [860]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088430,	
2017-06-27 22:00:52,742 Epoch[43] Batch [870]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088409,	
2017-06-27 22:00:58,072 Epoch[43] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088536,	
2017-06-27 22:01:03,366 Epoch[43] Batch [890]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088549,	
2017-06-27 22:01:08,663 Epoch[43] Batch [900]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088524,	
2017-06-27 22:01:13,947 Epoch[43] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088486,	
2017-06-27 22:01:19,278 Epoch[43] Batch [920]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088442,	
2017-06-27 22:01:24,552 Epoch[43] Batch [930]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088531,	
2017-06-27 22:01:29,902 Epoch[43] Batch [940]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088513,	
2017-06-27 22:01:35,205 Epoch[43] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088460,	
2017-06-27 22:01:40,473 Epoch[43] Batch [960]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088458,	
2017-06-27 22:01:45,788 Epoch[43] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088551,	
2017-06-27 22:01:51,051 Epoch[43] Batch [980]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088428,	
2017-06-27 22:01:56,374 Epoch[43] Batch [990]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088454,	
2017-06-27 22:02:01,663 Epoch[43] Batch [1000]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-27 22:02:07,004 Epoch[43] Batch [1010]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-27 22:02:12,282 Epoch[43] Batch [1020]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088651,	
2017-06-27 22:02:17,543 Epoch[43] Batch [1030]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088641,	
2017-06-27 22:02:22,855 Epoch[43] Batch [1040]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-27 22:02:28,114 Epoch[43] Batch [1050]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-27 22:02:33,432 Epoch[43] Batch [1060]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088678,	
2017-06-27 22:02:38,685 Epoch[43] Batch [1070]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088692,	
2017-06-27 22:02:44,010 Epoch[43] Batch [1080]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088717,	
2017-06-27 22:02:49,282 Epoch[43] Batch [1090]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088726,	
2017-06-27 22:02:54,598 Epoch[43] Batch [1100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088807,	
2017-06-27 22:02:59,880 Epoch[43] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088731,	
2017-06-27 22:03:05,180 Epoch[43] Batch [1120]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088775,	
2017-06-27 22:03:10,462 Epoch[43] Batch [1130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088811,	
2017-06-27 22:03:15,783 Epoch[43] Batch [1140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088766,	
2017-06-27 22:03:21,052 Epoch[43] Batch [1150]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-27 22:03:26,425 Epoch[43] Batch [1160]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088727,	
2017-06-27 22:03:31,693 Epoch[43] Batch [1170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-27 22:03:36,968 Epoch[43] Batch [1180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088816,	
2017-06-27 22:03:42,258 Epoch[43] Batch [1190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-27 22:03:47,558 Epoch[43] Batch [1200]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088855,	
2017-06-27 22:03:52,829 Epoch[43] Batch [1210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088774,	
2017-06-27 22:03:58,142 Epoch[43] Batch [1220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088736,	
2017-06-27 22:04:03,483 Epoch[43] Batch [1230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088753,	
2017-06-27 22:04:08,723 Epoch[43] Batch [1240]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088764,	
2017-06-27 22:04:13,018 Epoch[43] Batch [1250]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088772,	
2017-06-27 22:04:18,059 Epoch[43] Batch [1260]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088746,	
2017-06-27 22:04:23,387 Epoch[43] Batch [1270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088750,	
2017-06-27 22:04:28,650 Epoch[43] Batch [1280]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088735,	
2017-06-27 22:04:33,958 Epoch[43] Batch [1290]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088731,	
2017-06-27 22:04:39,226 Epoch[43] Batch [1300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-27 22:04:44,530 Epoch[43] Batch [1310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088757,	
2017-06-27 22:04:49,798 Epoch[43] Batch [1320]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088733,	
2017-06-27 22:04:55,104 Epoch[43] Batch [1330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088657,	
2017-06-27 22:05:00,412 Epoch[43] Batch [1340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088652,	
2017-06-27 22:05:05,643 Epoch[43] Batch [1350]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-27 22:05:10,912 Epoch[43] Batch [1360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088610,	
2017-06-27 22:05:16,196 Epoch[43] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088648,	
2017-06-27 22:05:21,459 Epoch[43] Batch [1380]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088754,	
2017-06-27 22:05:26,739 Epoch[43] Batch [1390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-27 22:05:32,022 Epoch[43] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088794,	
2017-06-27 22:05:37,340 Epoch[43] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088775,	
2017-06-27 22:05:42,583 Epoch[43] Batch [1420]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088725,	
2017-06-27 22:05:47,868 Epoch[43] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088751,	
2017-06-27 22:05:53,166 Epoch[43] Batch [1440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088813,	
2017-06-27 22:05:58,465 Epoch[43] Batch [1450]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088800,	
2017-06-27 22:06:03,743 Epoch[43] Batch [1460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088729,	
2017-06-27 22:06:08,986 Epoch[43] Batch [1470]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088722,	
2017-06-27 22:06:14,256 Epoch[43] Batch [1480]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088664,	
2017-06-27 22:06:17,427 Epoch[43] Train-FCNLogLoss=0.088668
2017-06-27 22:06:17,427 Epoch[43] Time cost=786.359
2017-06-27 22:06:18,324 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0044.params"
2017-06-27 22:06:19,989 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0044.states"
2017-06-27 22:06:26,099 Epoch[44] Batch [10]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097717,	
2017-06-27 22:06:31,360 Epoch[44] Batch [20]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093320,	
2017-06-27 22:06:36,652 Epoch[44] Batch [30]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093547,	
2017-06-27 22:06:41,957 Epoch[44] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092204,	
2017-06-27 22:06:47,217 Epoch[44] Batch [50]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092197,	
2017-06-27 22:06:52,539 Epoch[44] Batch [60]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092506,	
2017-06-27 22:06:57,821 Epoch[44] Batch [70]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091001,	
2017-06-27 22:07:03,091 Epoch[44] Batch [80]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091436,	
2017-06-27 22:07:08,350 Epoch[44] Batch [90]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092247,	
2017-06-27 22:07:13,653 Epoch[44] Batch [100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092166,	
2017-06-27 22:07:18,945 Epoch[44] Batch [110]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092348,	
2017-06-27 22:07:24,187 Epoch[44] Batch [120]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092091,	
2017-06-27 22:07:29,503 Epoch[44] Batch [130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090947,	
2017-06-27 22:07:34,770 Epoch[44] Batch [140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091113,	
2017-06-27 22:07:40,085 Epoch[44] Batch [150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090804,	
2017-06-27 22:07:45,367 Epoch[44] Batch [160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090749,	
2017-06-27 22:07:50,664 Epoch[44] Batch [170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090472,	
2017-06-27 22:07:55,954 Epoch[44] Batch [180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090039,	
2017-06-27 22:08:01,268 Epoch[44] Batch [190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090131,	
2017-06-27 22:08:06,571 Epoch[44] Batch [200]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090180,	
2017-06-27 22:08:11,866 Epoch[44] Batch [210]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089539,	
2017-06-27 22:08:17,161 Epoch[44] Batch [220]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089537,	
2017-06-27 22:08:22,491 Epoch[44] Batch [230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089573,	
2017-06-27 22:08:27,760 Epoch[44] Batch [240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089054,	
2017-06-27 22:08:33,079 Epoch[44] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088827,	
2017-06-27 22:08:38,384 Epoch[44] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088505,	
2017-06-27 22:08:43,679 Epoch[44] Batch [270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088605,	
2017-06-27 22:08:49,003 Epoch[44] Batch [280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088346,	
2017-06-27 22:08:54,278 Epoch[44] Batch [290]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088477,	
2017-06-27 22:08:59,622 Epoch[44] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088576,	
2017-06-27 22:09:04,911 Epoch[44] Batch [310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088382,	
2017-06-27 22:09:10,239 Epoch[44] Batch [320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088296,	
2017-06-27 22:09:15,506 Epoch[44] Batch [330]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088422,	
2017-06-27 22:09:20,838 Epoch[44] Batch [340]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088533,	
2017-06-27 22:09:26,142 Epoch[44] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088601,	
2017-06-27 22:09:31,489 Epoch[44] Batch [360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088648,	
2017-06-27 22:09:36,813 Epoch[44] Batch [370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088321,	
2017-06-27 22:09:42,130 Epoch[44] Batch [380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088226,	
2017-06-27 22:09:47,464 Epoch[44] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088294,	
2017-06-27 22:09:52,723 Epoch[44] Batch [400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088303,	
2017-06-27 22:09:58,007 Epoch[44] Batch [410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088473,	
2017-06-27 22:10:03,319 Epoch[44] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-27 22:10:08,623 Epoch[44] Batch [430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-27 22:10:13,928 Epoch[44] Batch [440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088507,	
2017-06-27 22:10:19,266 Epoch[44] Batch [450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088489,	
2017-06-27 22:10:24,551 Epoch[44] Batch [460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088490,	
2017-06-27 22:10:29,892 Epoch[44] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088707,	
2017-06-27 22:10:35,213 Epoch[44] Batch [480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088794,	
2017-06-27 22:10:40,509 Epoch[44] Batch [490]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088801,	
2017-06-27 22:10:45,793 Epoch[44] Batch [500]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088584,	
2017-06-27 22:10:51,108 Epoch[44] Batch [510]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088574,	
2017-06-27 22:10:56,443 Epoch[44] Batch [520]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088602,	
2017-06-27 22:11:01,744 Epoch[44] Batch [530]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088642,	
2017-06-27 22:11:07,069 Epoch[44] Batch [540]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-27 22:11:12,403 Epoch[44] Batch [550]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088505,	
2017-06-27 22:11:17,745 Epoch[44] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088653,	
2017-06-27 22:11:23,082 Epoch[44] Batch [570]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088600,	
2017-06-27 22:11:28,334 Epoch[44] Batch [580]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088487,	
2017-06-27 22:11:33,651 Epoch[44] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088552,	
2017-06-27 22:11:38,937 Epoch[44] Batch [600]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088568,	
2017-06-27 22:11:44,208 Epoch[44] Batch [610]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088615,	
2017-06-27 22:11:49,498 Epoch[44] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-27 22:11:54,825 Epoch[44] Batch [630]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-27 22:12:00,112 Epoch[44] Batch [640]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088654,	
2017-06-27 22:12:05,398 Epoch[44] Batch [650]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088523,	
2017-06-27 22:12:10,694 Epoch[44] Batch [660]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088411,	
2017-06-27 22:12:15,975 Epoch[44] Batch [670]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-27 22:12:21,303 Epoch[44] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088375,	
2017-06-27 22:12:26,582 Epoch[44] Batch [690]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088285,	
2017-06-27 22:12:31,852 Epoch[44] Batch [700]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088346,	
2017-06-27 22:12:37,138 Epoch[44] Batch [710]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088364,	
2017-06-27 22:12:42,426 Epoch[44] Batch [720]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088352,	
2017-06-27 22:12:47,754 Epoch[44] Batch [730]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088386,	
2017-06-27 22:12:53,031 Epoch[44] Batch [740]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088438,	
2017-06-27 22:12:58,336 Epoch[44] Batch [750]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088464,	
2017-06-27 22:13:03,654 Epoch[44] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-27 22:13:08,881 Epoch[44] Batch [770]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-27 22:13:14,188 Epoch[44] Batch [780]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088480,	
2017-06-27 22:13:19,478 Epoch[44] Batch [790]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-27 22:13:24,765 Epoch[44] Batch [800]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088340,	
2017-06-27 22:13:30,086 Epoch[44] Batch [810]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088433,	
2017-06-27 22:13:35,370 Epoch[44] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-27 22:13:40,664 Epoch[44] Batch [830]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088513,	
2017-06-27 22:13:45,971 Epoch[44] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088555,	
2017-06-27 22:13:51,258 Epoch[44] Batch [850]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-27 22:13:56,535 Epoch[44] Batch [860]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088416,	
2017-06-27 22:14:01,863 Epoch[44] Batch [870]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088387,	
2017-06-27 22:14:07,105 Epoch[44] Batch [880]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-27 22:14:12,381 Epoch[44] Batch [890]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088303,	
2017-06-27 22:14:17,693 Epoch[44] Batch [900]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088273,	
2017-06-27 22:14:22,975 Epoch[44] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-27 22:14:28,270 Epoch[44] Batch [920]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088367,	
2017-06-27 22:14:33,589 Epoch[44] Batch [930]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088431,	
2017-06-27 22:14:38,834 Epoch[44] Batch [940]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088375,	
2017-06-27 22:14:44,136 Epoch[44] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088383,	
2017-06-27 22:14:49,405 Epoch[44] Batch [960]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088449,	
2017-06-27 22:14:54,718 Epoch[44] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088583,	
2017-06-27 22:14:59,998 Epoch[44] Batch [980]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-27 22:15:05,271 Epoch[44] Batch [990]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088650,	
2017-06-27 22:15:10,548 Epoch[44] Batch [1000]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088671,	
2017-06-27 22:15:15,813 Epoch[44] Batch [1010]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088615,	
2017-06-27 22:15:21,094 Epoch[44] Batch [1020]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-27 22:15:26,419 Epoch[44] Batch [1030]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-27 22:15:31,703 Epoch[44] Batch [1040]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-27 22:15:36,992 Epoch[44] Batch [1050]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-27 22:15:42,273 Epoch[44] Batch [1060]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088778,	
2017-06-27 22:15:47,551 Epoch[44] Batch [1070]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-27 22:15:52,807 Epoch[44] Batch [1080]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088781,	
2017-06-27 22:15:58,098 Epoch[44] Batch [1090]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088717,	
2017-06-27 22:16:03,396 Epoch[44] Batch [1100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088620,	
2017-06-27 22:16:08,675 Epoch[44] Batch [1110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-27 22:16:14,005 Epoch[44] Batch [1120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088596,	
2017-06-27 22:16:19,263 Epoch[44] Batch [1130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-27 22:16:24,525 Epoch[44] Batch [1140]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-27 22:16:29,802 Epoch[44] Batch [1150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088679,	
2017-06-27 22:16:35,127 Epoch[44] Batch [1160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-27 22:16:40,426 Epoch[44] Batch [1170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088687,	
2017-06-27 22:16:45,695 Epoch[44] Batch [1180]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088626,	
2017-06-27 22:16:50,998 Epoch[44] Batch [1190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088621,	
2017-06-27 22:16:56,259 Epoch[44] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088660,	
2017-06-27 22:17:01,585 Epoch[44] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088729,	
2017-06-27 22:17:06,870 Epoch[44] Batch [1220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088749,	
2017-06-27 22:17:12,106 Epoch[44] Batch [1230]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-27 22:17:17,440 Epoch[44] Batch [1240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088740,	
2017-06-27 22:17:21,974 Epoch[44] Batch [1250]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088746,	
2017-06-27 22:17:26,921 Epoch[44] Batch [1260]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088732,	
2017-06-27 22:17:32,207 Epoch[44] Batch [1270]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088693,	
2017-06-27 22:17:37,613 Epoch[44] Batch [1280]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088742,	
2017-06-27 22:17:42,898 Epoch[44] Batch [1290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088711,	
2017-06-27 22:17:48,186 Epoch[44] Batch [1300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088633,	
2017-06-27 22:17:53,474 Epoch[44] Batch [1310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088593,	
2017-06-27 22:17:58,831 Epoch[44] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-27 22:18:04,109 Epoch[44] Batch [1330]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-27 22:18:09,422 Epoch[44] Batch [1340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088543,	
2017-06-27 22:18:14,710 Epoch[44] Batch [1350]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-27 22:18:20,019 Epoch[44] Batch [1360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088438,	
2017-06-27 22:18:25,304 Epoch[44] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-27 22:18:30,588 Epoch[44] Batch [1380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-27 22:18:35,917 Epoch[44] Batch [1390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088445,	
2017-06-27 22:18:41,191 Epoch[44] Batch [1400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088464,	
2017-06-27 22:18:46,480 Epoch[44] Batch [1410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088450,	
2017-06-27 22:18:51,775 Epoch[44] Batch [1420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088369,	
2017-06-27 22:18:57,067 Epoch[44] Batch [1430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088334,	
2017-06-27 22:19:02,397 Epoch[44] Batch [1440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088265,	
2017-06-27 22:19:07,667 Epoch[44] Batch [1450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088307,	
2017-06-27 22:19:13,000 Epoch[44] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088361,	
2017-06-27 22:19:18,270 Epoch[44] Batch [1470]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-27 22:19:23,580 Epoch[44] Batch [1480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088292,	
2017-06-27 22:19:26,782 Epoch[44] Train-FCNLogLoss=0.088280
2017-06-27 22:19:26,782 Epoch[44] Time cost=786.793
2017-06-27 22:19:27,664 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0045.params"
2017-06-27 22:19:29,352 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0045.states"
2017-06-27 22:19:35,398 Epoch[45] Batch [10]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.090809,	
2017-06-27 22:19:40,731 Epoch[45] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091074,	
2017-06-27 22:19:46,026 Epoch[45] Batch [30]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090130,	
2017-06-27 22:19:51,352 Epoch[45] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-27 22:19:56,718 Epoch[45] Batch [50]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087984,	
2017-06-27 22:20:02,021 Epoch[45] Batch [60]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087908,	
2017-06-27 22:20:07,321 Epoch[45] Batch [70]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087675,	
2017-06-27 22:20:12,626 Epoch[45] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086913,	
2017-06-27 22:20:17,959 Epoch[45] Batch [90]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087241,	
2017-06-27 22:20:23,254 Epoch[45] Batch [100]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087439,	
2017-06-27 22:20:28,526 Epoch[45] Batch [110]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-27 22:20:33,853 Epoch[45] Batch [120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088231,	
2017-06-27 22:20:39,172 Epoch[45] Batch [130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088262,	
2017-06-27 22:20:44,478 Epoch[45] Batch [140]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088625,	
2017-06-27 22:20:49,799 Epoch[45] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088990,	
2017-06-27 22:20:55,122 Epoch[45] Batch [160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089043,	
2017-06-27 22:21:00,407 Epoch[45] Batch [170]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089274,	
2017-06-27 22:21:05,737 Epoch[45] Batch [180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089603,	
2017-06-27 22:21:11,021 Epoch[45] Batch [190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-27 22:21:16,283 Epoch[45] Batch [200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089517,	
2017-06-27 22:21:21,661 Epoch[45] Batch [210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089384,	
2017-06-27 22:21:26,929 Epoch[45] Batch [220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089197,	
2017-06-27 22:21:32,216 Epoch[45] Batch [230]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089140,	
2017-06-27 22:21:37,565 Epoch[45] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089289,	
2017-06-27 22:21:42,892 Epoch[45] Batch [250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089616,	
2017-06-27 22:21:48,176 Epoch[45] Batch [260]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089549,	
2017-06-27 22:21:53,527 Epoch[45] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089229,	
2017-06-27 22:21:58,823 Epoch[45] Batch [280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089476,	
2017-06-27 22:22:04,162 Epoch[45] Batch [290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089202,	
2017-06-27 22:22:09,452 Epoch[45] Batch [300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089164,	
2017-06-27 22:22:14,750 Epoch[45] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089305,	
2017-06-27 22:22:20,142 Epoch[45] Batch [320]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089479,	
2017-06-27 22:22:25,398 Epoch[45] Batch [330]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089347,	
2017-06-27 22:22:30,694 Epoch[45] Batch [340]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089018,	
2017-06-27 22:22:35,995 Epoch[45] Batch [350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089109,	
2017-06-27 22:22:41,256 Epoch[45] Batch [360]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-27 22:22:46,569 Epoch[45] Batch [370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089083,	
2017-06-27 22:22:51,871 Epoch[45] Batch [380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088948,	
2017-06-27 22:22:57,147 Epoch[45] Batch [390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088864,	
2017-06-27 22:23:02,344 Epoch[45] Batch [400]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088714,	
2017-06-27 22:23:07,661 Epoch[45] Batch [410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088692,	
2017-06-27 22:23:12,975 Epoch[45] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088448,	
2017-06-27 22:23:18,232 Epoch[45] Batch [430]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088476,	
2017-06-27 22:23:23,544 Epoch[45] Batch [440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088587,	
2017-06-27 22:23:28,898 Epoch[45] Batch [450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088644,	
2017-06-27 22:23:34,167 Epoch[45] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088778,	
2017-06-27 22:23:39,484 Epoch[45] Batch [470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-27 22:23:44,773 Epoch[45] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088704,	
2017-06-27 22:23:50,138 Epoch[45] Batch [490]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088681,	
2017-06-27 22:23:55,398 Epoch[45] Batch [500]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088657,	
2017-06-27 22:24:00,671 Epoch[45] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-27 22:24:05,980 Epoch[45] Batch [520]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088494,	
2017-06-27 22:24:11,273 Epoch[45] Batch [530]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088594,	
2017-06-27 22:24:16,567 Epoch[45] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-27 22:24:21,860 Epoch[45] Batch [550]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-27 22:24:27,159 Epoch[45] Batch [560]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088621,	
2017-06-27 22:24:32,459 Epoch[45] Batch [570]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088715,	
2017-06-27 22:24:37,783 Epoch[45] Batch [580]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088865,	
2017-06-27 22:24:43,052 Epoch[45] Batch [590]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-27 22:24:48,342 Epoch[45] Batch [600]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-27 22:24:53,688 Epoch[45] Batch [610]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088640,	
2017-06-27 22:24:58,989 Epoch[45] Batch [620]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088582,	
2017-06-27 22:25:04,252 Epoch[45] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088395,	
2017-06-27 22:25:09,565 Epoch[45] Batch [640]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088267,	
2017-06-27 22:25:14,856 Epoch[45] Batch [650]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088266,	
2017-06-27 22:25:20,142 Epoch[45] Batch [660]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088192,	
2017-06-27 22:25:25,430 Epoch[45] Batch [670]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088167,	
2017-06-27 22:25:30,736 Epoch[45] Batch [680]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088214,	
2017-06-27 22:25:36,056 Epoch[45] Batch [690]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088219,	
2017-06-27 22:25:41,302 Epoch[45] Batch [700]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088261,	
2017-06-27 22:25:46,617 Epoch[45] Batch [710]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088240,	
2017-06-27 22:25:51,918 Epoch[45] Batch [720]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088077,	
2017-06-27 22:25:57,207 Epoch[45] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087996,	
2017-06-27 22:26:02,494 Epoch[45] Batch [740]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087921,	
2017-06-27 22:26:07,819 Epoch[45] Batch [750]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087890,	
2017-06-27 22:26:13,076 Epoch[45] Batch [760]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087889,	
2017-06-27 22:26:18,403 Epoch[45] Batch [770]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087881,	
2017-06-27 22:26:23,689 Epoch[45] Batch [780]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087848,	
2017-06-27 22:26:29,000 Epoch[45] Batch [790]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087821,	
2017-06-27 22:26:34,326 Epoch[45] Batch [800]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-27 22:26:39,640 Epoch[45] Batch [810]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087684,	
2017-06-27 22:26:44,881 Epoch[45] Batch [820]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087597,	
2017-06-27 22:26:50,229 Epoch[45] Batch [830]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087792,	
2017-06-27 22:26:55,541 Epoch[45] Batch [840]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087793,	
2017-06-27 22:27:00,818 Epoch[45] Batch [850]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087937,	
2017-06-27 22:27:06,179 Epoch[45] Batch [860]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087844,	
2017-06-27 22:27:11,427 Epoch[45] Batch [870]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-27 22:27:16,814 Epoch[45] Batch [880]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087868,	
2017-06-27 22:27:22,059 Epoch[45] Batch [890]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088019,	
2017-06-27 22:27:27,388 Epoch[45] Batch [900]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088064,	
2017-06-27 22:27:32,675 Epoch[45] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088041,	
2017-06-27 22:27:37,975 Epoch[45] Batch [920]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-27 22:27:43,277 Epoch[45] Batch [930]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088236,	
2017-06-27 22:27:48,591 Epoch[45] Batch [940]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088279,	
2017-06-27 22:27:53,871 Epoch[45] Batch [950]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088334,	
2017-06-27 22:27:59,208 Epoch[45] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088374,	
2017-06-27 22:28:04,545 Epoch[45] Batch [970]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088378,	
2017-06-27 22:28:09,856 Epoch[45] Batch [980]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088384,	
2017-06-27 22:28:15,188 Epoch[45] Batch [990]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088422,	
2017-06-27 22:28:20,429 Epoch[45] Batch [1000]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088429,	
2017-06-27 22:28:25,731 Epoch[45] Batch [1010]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088322,	
2017-06-27 22:28:31,082 Epoch[45] Batch [1020]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088268,	
2017-06-27 22:28:36,360 Epoch[45] Batch [1030]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088252,	
2017-06-27 22:28:41,672 Epoch[45] Batch [1040]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088218,	
2017-06-27 22:28:46,992 Epoch[45] Batch [1050]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088191,	
2017-06-27 22:28:52,279 Epoch[45] Batch [1060]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-27 22:28:57,623 Epoch[45] Batch [1070]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088131,	
2017-06-27 22:29:02,947 Epoch[45] Batch [1080]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088149,	
2017-06-27 22:29:08,247 Epoch[45] Batch [1090]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088091,	
2017-06-27 22:29:13,589 Epoch[45] Batch [1100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088094,	
2017-06-27 22:29:18,871 Epoch[45] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088178,	
2017-06-27 22:29:24,214 Epoch[45] Batch [1120]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088220,	
2017-06-27 22:29:29,506 Epoch[45] Batch [1130]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088182,	
2017-06-27 22:29:34,802 Epoch[45] Batch [1140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088283,	
2017-06-27 22:29:40,110 Epoch[45] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088246,	
2017-06-27 22:29:45,451 Epoch[45] Batch [1160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088218,	
2017-06-27 22:29:50,745 Epoch[45] Batch [1170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088263,	
2017-06-27 22:29:56,080 Epoch[45] Batch [1180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-27 22:30:01,403 Epoch[45] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088249,	
2017-06-27 22:30:06,694 Epoch[45] Batch [1200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088206,	
2017-06-27 22:30:11,979 Epoch[45] Batch [1210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088191,	
2017-06-27 22:30:17,293 Epoch[45] Batch [1220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088250,	
2017-06-27 22:30:22,586 Epoch[45] Batch [1230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088201,	
2017-06-27 22:30:27,926 Epoch[45] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088164,	
2017-06-27 22:30:32,306 Epoch[45] Batch [1250]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088140,	
2017-06-27 22:30:37,615 Epoch[45] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088178,	
2017-06-27 22:30:42,890 Epoch[45] Batch [1270]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088209,	
2017-06-27 22:30:48,272 Epoch[45] Batch [1280]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088184,	
2017-06-27 22:30:53,557 Epoch[45] Batch [1290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088197,	
2017-06-27 22:30:58,851 Epoch[45] Batch [1300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088200,	
2017-06-27 22:31:04,154 Epoch[45] Batch [1310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088218,	
2017-06-27 22:31:09,452 Epoch[45] Batch [1320]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088221,	
2017-06-27 22:31:14,739 Epoch[45] Batch [1330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088216,	
2017-06-27 22:31:20,013 Epoch[45] Batch [1340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088227,	
2017-06-27 22:31:25,301 Epoch[45] Batch [1350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088271,	
2017-06-27 22:31:30,588 Epoch[45] Batch [1360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088221,	
2017-06-27 22:31:35,896 Epoch[45] Batch [1370]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088245,	
2017-06-27 22:31:41,184 Epoch[45] Batch [1380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088219,	
2017-06-27 22:31:46,463 Epoch[45] Batch [1390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088221,	
2017-06-27 22:31:51,774 Epoch[45] Batch [1400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088215,	
2017-06-27 22:31:57,046 Epoch[45] Batch [1410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088281,	
2017-06-27 22:32:02,317 Epoch[45] Batch [1420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088240,	
2017-06-27 22:32:07,638 Epoch[45] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088276,	
2017-06-27 22:32:12,886 Epoch[45] Batch [1440]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088252,	
2017-06-27 22:32:18,218 Epoch[45] Batch [1450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088187,	
2017-06-27 22:32:23,491 Epoch[45] Batch [1460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088236,	
2017-06-27 22:32:28,766 Epoch[45] Batch [1470]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088212,	
2017-06-27 22:32:34,074 Epoch[45] Batch [1480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088155,	
2017-06-27 22:32:37,233 Epoch[45] Train-FCNLogLoss=0.088155
2017-06-27 22:32:37,233 Epoch[45] Time cost=787.881
2017-06-27 22:32:38,118 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0046.params"
2017-06-27 22:32:39,762 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0046.states"
2017-06-27 22:32:45,752 Epoch[46] Batch [10]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-27 22:32:51,039 Epoch[46] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091463,	
2017-06-27 22:32:56,319 Epoch[46] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087974,	
2017-06-27 22:33:01,602 Epoch[46] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086526,	
2017-06-27 22:33:06,894 Epoch[46] Batch [50]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086102,	
2017-06-27 22:33:12,206 Epoch[46] Batch [60]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.085830,	
2017-06-27 22:33:17,476 Epoch[46] Batch [70]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.085566,	
2017-06-27 22:33:22,753 Epoch[46] Batch [80]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.085511,	
2017-06-27 22:33:28,022 Epoch[46] Batch [90]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.085838,	
2017-06-27 22:33:33,268 Epoch[46] Batch [100]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086594,	
2017-06-27 22:33:38,559 Epoch[46] Batch [110]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086842,	
2017-06-27 22:33:43,845 Epoch[46] Batch [120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086971,	
2017-06-27 22:33:49,129 Epoch[46] Batch [130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086563,	
2017-06-27 22:33:54,446 Epoch[46] Batch [140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087647,	
2017-06-27 22:33:59,726 Epoch[46] Batch [150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086986,	
2017-06-27 22:34:05,027 Epoch[46] Batch [160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087038,	
2017-06-27 22:34:10,288 Epoch[46] Batch [170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087327,	
2017-06-27 22:34:15,570 Epoch[46] Batch [180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087673,	
2017-06-27 22:34:20,888 Epoch[46] Batch [190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087760,	
2017-06-27 22:34:26,154 Epoch[46] Batch [200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-27 22:34:31,448 Epoch[46] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087857,	
2017-06-27 22:34:36,751 Epoch[46] Batch [220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087888,	
2017-06-27 22:34:42,021 Epoch[46] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087609,	
2017-06-27 22:34:47,323 Epoch[46] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087260,	
2017-06-27 22:34:52,569 Epoch[46] Batch [250]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087095,	
2017-06-27 22:34:57,805 Epoch[46] Batch [260]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087144,	
2017-06-27 22:35:03,127 Epoch[46] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087117,	
2017-06-27 22:35:08,477 Epoch[46] Batch [280]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087204,	
2017-06-27 22:35:13,802 Epoch[46] Batch [290]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087309,	
2017-06-27 22:35:19,058 Epoch[46] Batch [300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087544,	
2017-06-27 22:35:24,386 Epoch[46] Batch [310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087426,	
2017-06-27 22:35:29,693 Epoch[46] Batch [320]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087324,	
2017-06-27 22:35:34,955 Epoch[46] Batch [330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087474,	
2017-06-27 22:35:40,250 Epoch[46] Batch [340]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087198,	
2017-06-27 22:35:45,539 Epoch[46] Batch [350]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087250,	
2017-06-27 22:35:50,808 Epoch[46] Batch [360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086963,	
2017-06-27 22:35:56,140 Epoch[46] Batch [370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087019,	
2017-06-27 22:36:01,416 Epoch[46] Batch [380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087096,	
2017-06-27 22:36:06,707 Epoch[46] Batch [390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087067,	
2017-06-27 22:36:11,990 Epoch[46] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086984,	
2017-06-27 22:36:17,276 Epoch[46] Batch [410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087158,	
2017-06-27 22:36:22,577 Epoch[46] Batch [420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087218,	
2017-06-27 22:36:27,854 Epoch[46] Batch [430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087260,	
2017-06-27 22:36:33,169 Epoch[46] Batch [440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087266,	
2017-06-27 22:36:38,483 Epoch[46] Batch [450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087219,	
2017-06-27 22:36:43,763 Epoch[46] Batch [460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-27 22:36:49,071 Epoch[46] Batch [470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087268,	
2017-06-27 22:36:54,373 Epoch[46] Batch [480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087158,	
2017-06-27 22:36:59,672 Epoch[46] Batch [490]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087127,	
2017-06-27 22:37:04,983 Epoch[46] Batch [500]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087295,	
2017-06-27 22:37:10,267 Epoch[46] Batch [510]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-27 22:37:15,514 Epoch[46] Batch [520]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087106,	
2017-06-27 22:37:20,836 Epoch[46] Batch [530]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087295,	
2017-06-27 22:37:26,123 Epoch[46] Batch [540]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087322,	
2017-06-27 22:37:31,416 Epoch[46] Batch [550]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087247,	
2017-06-27 22:37:36,717 Epoch[46] Batch [560]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087097,	
2017-06-27 22:37:42,002 Epoch[46] Batch [570]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087052,	
2017-06-27 22:37:47,288 Epoch[46] Batch [580]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086957,	
2017-06-27 22:37:52,586 Epoch[46] Batch [590]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086801,	
2017-06-27 22:37:57,911 Epoch[46] Batch [600]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086856,	
2017-06-27 22:38:03,208 Epoch[46] Batch [610]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086908,	
2017-06-27 22:38:08,467 Epoch[46] Batch [620]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086905,	
2017-06-27 22:38:13,732 Epoch[46] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087152,	
2017-06-27 22:38:19,059 Epoch[46] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087243,	
2017-06-27 22:38:24,361 Epoch[46] Batch [650]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087372,	
2017-06-27 22:38:29,652 Epoch[46] Batch [660]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087329,	
2017-06-27 22:38:34,964 Epoch[46] Batch [670]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087434,	
2017-06-27 22:38:40,275 Epoch[46] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087435,	
2017-06-27 22:38:45,551 Epoch[46] Batch [690]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087413,	
2017-06-27 22:38:50,874 Epoch[46] Batch [700]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087308,	
2017-06-27 22:38:56,112 Epoch[46] Batch [710]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087324,	
2017-06-27 22:39:01,429 Epoch[46] Batch [720]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087512,	
2017-06-27 22:39:06,687 Epoch[46] Batch [730]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087627,	
2017-06-27 22:39:11,984 Epoch[46] Batch [740]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087796,	
2017-06-27 22:39:17,316 Epoch[46] Batch [750]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087857,	
2017-06-27 22:39:22,650 Epoch[46] Batch [760]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087793,	
2017-06-27 22:39:27,928 Epoch[46] Batch [770]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087789,	
2017-06-27 22:39:33,242 Epoch[46] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087808,	
2017-06-27 22:39:38,562 Epoch[46] Batch [790]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087863,	
2017-06-27 22:39:43,870 Epoch[46] Batch [800]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087789,	
2017-06-27 22:39:49,158 Epoch[46] Batch [810]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087784,	
2017-06-27 22:39:54,487 Epoch[46] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087782,	
2017-06-27 22:39:59,807 Epoch[46] Batch [830]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087883,	
2017-06-27 22:40:05,093 Epoch[46] Batch [840]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087879,	
2017-06-27 22:40:10,435 Epoch[46] Batch [850]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087889,	
2017-06-27 22:40:15,756 Epoch[46] Batch [860]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087889,	
2017-06-27 22:40:21,042 Epoch[46] Batch [870]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087839,	
2017-06-27 22:40:26,378 Epoch[46] Batch [880]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087842,	
2017-06-27 22:40:31,711 Epoch[46] Batch [890]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087788,	
2017-06-27 22:40:36,968 Epoch[46] Batch [900]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087675,	
2017-06-27 22:40:42,286 Epoch[46] Batch [910]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087607,	
2017-06-27 22:40:47,619 Epoch[46] Batch [920]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087544,	
2017-06-27 22:40:52,892 Epoch[46] Batch [930]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087454,	
2017-06-27 22:40:58,238 Epoch[46] Batch [940]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-27 22:41:03,533 Epoch[46] Batch [950]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087514,	
2017-06-27 22:41:08,855 Epoch[46] Batch [960]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087450,	
2017-06-27 22:41:14,116 Epoch[46] Batch [970]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087423,	
2017-06-27 22:41:19,396 Epoch[46] Batch [980]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087400,	
2017-06-27 22:41:24,709 Epoch[46] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087405,	
2017-06-27 22:41:30,018 Epoch[46] Batch [1000]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087415,	
2017-06-27 22:41:35,259 Epoch[46] Batch [1010]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087438,	
2017-06-27 22:41:40,533 Epoch[46] Batch [1020]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087428,	
2017-06-27 22:41:45,846 Epoch[46] Batch [1030]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087469,	
2017-06-27 22:41:51,123 Epoch[46] Batch [1040]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087639,	
2017-06-27 22:41:56,442 Epoch[46] Batch [1050]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-27 22:42:01,759 Epoch[46] Batch [1060]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087707,	
2017-06-27 22:42:07,002 Epoch[46] Batch [1070]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087769,	
2017-06-27 22:42:12,303 Epoch[46] Batch [1080]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087722,	
2017-06-27 22:42:17,621 Epoch[46] Batch [1090]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087826,	
2017-06-27 22:42:22,864 Epoch[46] Batch [1100]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087915,	
2017-06-27 22:42:28,187 Epoch[46] Batch [1110]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087964,	
2017-06-27 22:42:33,517 Epoch[46] Batch [1120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087903,	
2017-06-27 22:42:38,802 Epoch[46] Batch [1130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087908,	
2017-06-27 22:42:44,085 Epoch[46] Batch [1140]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087984,	
2017-06-27 22:42:49,401 Epoch[46] Batch [1150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087984,	
2017-06-27 22:42:54,675 Epoch[46] Batch [1160]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088005,	
2017-06-27 22:42:59,971 Epoch[46] Batch [1170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087983,	
2017-06-27 22:43:05,287 Epoch[46] Batch [1180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087973,	
2017-06-27 22:43:10,558 Epoch[46] Batch [1190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088028,	
2017-06-27 22:43:15,911 Epoch[46] Batch [1200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088007,	
2017-06-27 22:43:21,265 Epoch[46] Batch [1210]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087939,	
2017-06-27 22:43:26,539 Epoch[46] Batch [1220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087905,	
2017-06-27 22:43:31,817 Epoch[46] Batch [1230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087860,	
2017-06-27 22:43:37,130 Epoch[46] Batch [1240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087866,	
2017-06-27 22:43:41,462 Epoch[46] Batch [1250]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087918,	
2017-06-27 22:43:46,521 Epoch[46] Batch [1260]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087890,	
2017-06-27 22:43:51,825 Epoch[46] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087849,	
2017-06-27 22:43:57,085 Epoch[46] Batch [1280]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087805,	
2017-06-27 22:44:02,417 Epoch[46] Batch [1290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087791,	
2017-06-27 22:44:07,705 Epoch[46] Batch [1300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-27 22:44:12,964 Epoch[46] Batch [1310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087878,	
2017-06-27 22:44:18,261 Epoch[46] Batch [1320]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087890,	
2017-06-27 22:44:23,534 Epoch[46] Batch [1330]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087907,	
2017-06-27 22:44:28,781 Epoch[46] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087848,	
2017-06-27 22:44:34,084 Epoch[46] Batch [1350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087854,	
2017-06-27 22:44:39,378 Epoch[46] Batch [1360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087875,	
2017-06-27 22:44:44,664 Epoch[46] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087897,	
2017-06-27 22:44:49,959 Epoch[46] Batch [1380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087882,	
2017-06-27 22:44:55,252 Epoch[46] Batch [1390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087854,	
2017-06-27 22:45:00,545 Epoch[46] Batch [1400]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087855,	
2017-06-27 22:45:05,865 Epoch[46] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087896,	
2017-06-27 22:45:11,207 Epoch[46] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087941,	
2017-06-27 22:45:16,471 Epoch[46] Batch [1430]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087951,	
2017-06-27 22:45:21,772 Epoch[46] Batch [1440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087910,	
2017-06-27 22:45:27,083 Epoch[46] Batch [1450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087906,	
2017-06-27 22:45:32,455 Epoch[46] Batch [1460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087873,	
2017-06-27 22:45:37,769 Epoch[46] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087926,	
2017-06-27 22:45:43,054 Epoch[46] Batch [1480]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087908,	
2017-06-27 22:45:46,239 Epoch[46] Train-FCNLogLoss=0.087875
2017-06-27 22:45:46,239 Epoch[46] Time cost=786.477
2017-06-27 22:45:47,098 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0047.params"
2017-06-27 22:45:48,803 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0047.states"
2017-06-27 22:45:54,692 Epoch[47] Batch [10]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.089716,	
2017-06-27 22:45:59,958 Epoch[47] Batch [20]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086109,	
2017-06-27 22:46:05,277 Epoch[47] Batch [30]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087677,	
2017-06-27 22:46:10,548 Epoch[47] Batch [40]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086870,	
2017-06-27 22:46:15,873 Epoch[47] Batch [50]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086219,	
2017-06-27 22:46:21,151 Epoch[47] Batch [60]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086098,	
2017-06-27 22:46:26,500 Epoch[47] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.086273,	
2017-06-27 22:46:31,781 Epoch[47] Batch [80]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087253,	
2017-06-27 22:46:37,075 Epoch[47] Batch [90]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086742,	
2017-06-27 22:46:42,317 Epoch[47] Batch [100]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088597,	
2017-06-27 22:46:47,619 Epoch[47] Batch [110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089185,	
2017-06-27 22:46:52,947 Epoch[47] Batch [120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-27 22:46:58,188 Epoch[47] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088203,	
2017-06-27 22:47:03,481 Epoch[47] Batch [140]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088030,	
2017-06-27 22:47:08,801 Epoch[47] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087989,	
2017-06-27 22:47:14,074 Epoch[47] Batch [160]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088519,	
2017-06-27 22:47:19,380 Epoch[47] Batch [170]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089268,	
2017-06-27 22:47:24,682 Epoch[47] Batch [180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089301,	
2017-06-27 22:47:29,960 Epoch[47] Batch [190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089323,	
2017-06-27 22:47:35,218 Epoch[47] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089039,	
2017-06-27 22:47:40,568 Epoch[47] Batch [210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088950,	
2017-06-27 22:47:45,870 Epoch[47] Batch [220]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088862,	
2017-06-27 22:47:51,179 Epoch[47] Batch [230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089061,	
2017-06-27 22:47:56,491 Epoch[47] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-27 22:48:01,812 Epoch[47] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088576,	
2017-06-27 22:48:07,114 Epoch[47] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088546,	
2017-06-27 22:48:12,432 Epoch[47] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088397,	
2017-06-27 22:48:17,735 Epoch[47] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088124,	
2017-06-27 22:48:23,031 Epoch[47] Batch [290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088437,	
2017-06-27 22:48:28,356 Epoch[47] Batch [300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088469,	
2017-06-27 22:48:33,694 Epoch[47] Batch [310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088148,	
2017-06-27 22:48:38,974 Epoch[47] Batch [320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087940,	
2017-06-27 22:48:44,283 Epoch[47] Batch [330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087726,	
2017-06-27 22:48:49,568 Epoch[47] Batch [340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088075,	
2017-06-27 22:48:54,915 Epoch[47] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-27 22:49:00,259 Epoch[47] Batch [360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087908,	
2017-06-27 22:49:05,523 Epoch[47] Batch [370]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088131,	
2017-06-27 22:49:10,820 Epoch[47] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088049,	
2017-06-27 22:49:16,152 Epoch[47] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088173,	
2017-06-27 22:49:21,451 Epoch[47] Batch [400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088086,	
2017-06-27 22:49:26,725 Epoch[47] Batch [410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087921,	
2017-06-27 22:49:32,045 Epoch[47] Batch [420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088076,	
2017-06-27 22:49:37,355 Epoch[47] Batch [430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088021,	
2017-06-27 22:49:42,673 Epoch[47] Batch [440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087892,	
2017-06-27 22:49:47,976 Epoch[47] Batch [450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087755,	
2017-06-27 22:49:53,296 Epoch[47] Batch [460]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087715,	
2017-06-27 22:49:58,560 Epoch[47] Batch [470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087770,	
2017-06-27 22:50:03,915 Epoch[47] Batch [480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087735,	
2017-06-27 22:50:09,238 Epoch[47] Batch [490]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087797,	
2017-06-27 22:50:14,510 Epoch[47] Batch [500]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087819,	
2017-06-27 22:50:19,827 Epoch[47] Batch [510]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087770,	
2017-06-27 22:50:25,129 Epoch[47] Batch [520]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087736,	
2017-06-27 22:50:30,413 Epoch[47] Batch [530]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-27 22:50:35,728 Epoch[47] Batch [540]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087872,	
2017-06-27 22:50:41,052 Epoch[47] Batch [550]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087909,	
2017-06-27 22:50:46,352 Epoch[47] Batch [560]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088062,	
2017-06-27 22:50:51,680 Epoch[47] Batch [570]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088064,	
2017-06-27 22:50:56,949 Epoch[47] Batch [580]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088032,	
2017-06-27 22:51:02,250 Epoch[47] Batch [590]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088003,	
2017-06-27 22:51:07,552 Epoch[47] Batch [600]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088046,	
2017-06-27 22:51:12,950 Epoch[47] Batch [610]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088011,	
2017-06-27 22:51:18,225 Epoch[47] Batch [620]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088027,	
2017-06-27 22:51:23,497 Epoch[47] Batch [630]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088030,	
2017-06-27 22:51:28,773 Epoch[47] Batch [640]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-27 22:51:34,074 Epoch[47] Batch [650]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088165,	
2017-06-27 22:51:39,338 Epoch[47] Batch [660]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088048,	
2017-06-27 22:51:44,618 Epoch[47] Batch [670]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088084,	
2017-06-27 22:51:49,934 Epoch[47] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088121,	
2017-06-27 22:51:55,226 Epoch[47] Batch [690]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088099,	
2017-06-27 22:52:00,469 Epoch[47] Batch [700]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088014,	
2017-06-27 22:52:05,714 Epoch[47] Batch [710]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088068,	
2017-06-27 22:52:11,051 Epoch[47] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088035,	
2017-06-27 22:52:16,321 Epoch[47] Batch [730]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088186,	
2017-06-27 22:52:21,629 Epoch[47] Batch [740]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088157,	
2017-06-27 22:52:26,952 Epoch[47] Batch [750]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088139,	
2017-06-27 22:52:32,286 Epoch[47] Batch [760]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088118,	
2017-06-27 22:52:37,603 Epoch[47] Batch [770]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088041,	
2017-06-27 22:52:42,932 Epoch[47] Batch [780]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-27 22:52:48,200 Epoch[47] Batch [790]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087903,	
2017-06-27 22:52:53,474 Epoch[47] Batch [800]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087831,	
2017-06-27 22:52:58,779 Epoch[47] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087852,	
2017-06-27 22:53:04,066 Epoch[47] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087752,	
2017-06-27 22:53:09,377 Epoch[47] Batch [830]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087875,	
2017-06-27 22:53:14,588 Epoch[47] Batch [840]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087822,	
2017-06-27 22:53:19,868 Epoch[47] Batch [850]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087804,	
2017-06-27 22:53:25,197 Epoch[47] Batch [860]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087827,	
2017-06-27 22:53:30,492 Epoch[47] Batch [870]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087811,	
2017-06-27 22:53:35,807 Epoch[47] Batch [880]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087856,	
2017-06-27 22:53:41,115 Epoch[47] Batch [890]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087816,	
2017-06-27 22:53:46,419 Epoch[47] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087755,	
2017-06-27 22:53:51,695 Epoch[47] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087831,	
2017-06-27 22:53:57,049 Epoch[47] Batch [920]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087776,	
2017-06-27 22:54:02,295 Epoch[47] Batch [930]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087843,	
2017-06-27 22:54:07,665 Epoch[47] Batch [940]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087786,	
2017-06-27 22:54:12,973 Epoch[47] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087748,	
2017-06-27 22:54:18,293 Epoch[47] Batch [960]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087731,	
2017-06-27 22:54:23,576 Epoch[47] Batch [970]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087776,	
2017-06-27 22:54:28,887 Epoch[47] Batch [980]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087819,	
2017-06-27 22:54:34,237 Epoch[47] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087804,	
2017-06-27 22:54:39,478 Epoch[47] Batch [1000]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087749,	
2017-06-27 22:54:44,797 Epoch[47] Batch [1010]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087754,	
2017-06-27 22:54:50,075 Epoch[47] Batch [1020]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087693,	
2017-06-27 22:54:55,414 Epoch[47] Batch [1030]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087718,	
2017-06-27 22:55:00,738 Epoch[47] Batch [1040]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087763,	
2017-06-27 22:55:06,050 Epoch[47] Batch [1050]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-27 22:55:11,375 Epoch[47] Batch [1060]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087726,	
2017-06-27 22:55:16,666 Epoch[47] Batch [1070]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087666,	
2017-06-27 22:55:21,964 Epoch[47] Batch [1080]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087690,	
2017-06-27 22:55:27,287 Epoch[47] Batch [1090]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087732,	
2017-06-27 22:55:32,586 Epoch[47] Batch [1100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087737,	
2017-06-27 22:55:37,959 Epoch[47] Batch [1110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-27 22:55:43,303 Epoch[47] Batch [1120]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087826,	
2017-06-27 22:55:48,574 Epoch[47] Batch [1130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087889,	
2017-06-27 22:55:53,896 Epoch[47] Batch [1140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087867,	
2017-06-27 22:55:59,183 Epoch[47] Batch [1150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087866,	
2017-06-27 22:56:04,510 Epoch[47] Batch [1160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087832,	
2017-06-27 22:56:09,776 Epoch[47] Batch [1170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087748,	
2017-06-27 22:56:15,098 Epoch[47] Batch [1180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087736,	
2017-06-27 22:56:20,416 Epoch[47] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087819,	
2017-06-27 22:56:25,710 Epoch[47] Batch [1200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087784,	
2017-06-27 22:56:31,036 Epoch[47] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087773,	
2017-06-27 22:56:36,317 Epoch[47] Batch [1220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-27 22:56:41,632 Epoch[47] Batch [1230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087784,	
2017-06-27 22:56:46,933 Epoch[47] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087814,	
2017-06-27 22:56:51,479 Epoch[47] Batch [1250]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087854,	
2017-06-27 22:56:56,451 Epoch[47] Batch [1260]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087858,	
2017-06-27 22:57:01,766 Epoch[47] Batch [1270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087861,	
2017-06-27 22:57:07,065 Epoch[47] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087864,	
2017-06-27 22:57:12,365 Epoch[47] Batch [1290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087768,	
2017-06-27 22:57:17,641 Epoch[47] Batch [1300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087810,	
2017-06-27 22:57:22,956 Epoch[47] Batch [1310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087756,	
2017-06-27 22:57:28,208 Epoch[47] Batch [1320]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-27 22:57:33,501 Epoch[47] Batch [1330]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087756,	
2017-06-27 22:57:38,780 Epoch[47] Batch [1340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087770,	
2017-06-27 22:57:44,088 Epoch[47] Batch [1350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087846,	
2017-06-27 22:57:49,393 Epoch[47] Batch [1360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087824,	
2017-06-27 22:57:54,718 Epoch[47] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087848,	
2017-06-27 22:57:59,993 Epoch[47] Batch [1380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087811,	
2017-06-27 22:58:05,188 Epoch[47] Batch [1390]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087793,	
2017-06-27 22:58:10,489 Epoch[47] Batch [1400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087783,	
2017-06-27 22:58:15,821 Epoch[47] Batch [1410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087816,	
2017-06-27 22:58:21,098 Epoch[47] Batch [1420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087781,	
2017-06-27 22:58:26,422 Epoch[47] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087837,	
2017-06-27 22:58:31,723 Epoch[47] Batch [1440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087777,	
2017-06-27 22:58:37,028 Epoch[47] Batch [1450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087791,	
2017-06-27 22:58:42,310 Epoch[47] Batch [1460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087749,	
2017-06-27 22:58:47,605 Epoch[47] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087777,	
2017-06-27 22:58:52,925 Epoch[47] Batch [1480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087776,	
2017-06-27 22:58:56,127 Epoch[47] Train-FCNLogLoss=0.087766
2017-06-27 22:58:56,127 Epoch[47] Time cost=787.324
2017-06-27 22:58:56,888 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0048.params"
2017-06-27 22:58:58,780 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0048.states"
2017-06-27 22:59:04,726 Epoch[48] Batch [10]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087198,	
2017-06-27 22:59:10,011 Epoch[48] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088118,	
2017-06-27 22:59:15,297 Epoch[48] Batch [30]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088056,	
2017-06-27 22:59:20,589 Epoch[48] Batch [40]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089456,	
2017-06-27 22:59:25,840 Epoch[48] Batch [50]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089444,	
2017-06-27 22:59:31,130 Epoch[48] Batch [60]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088348,	
2017-06-27 22:59:36,303 Epoch[48] Batch [70]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089160,	
2017-06-27 22:59:41,598 Epoch[48] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089079,	
2017-06-27 22:59:46,908 Epoch[48] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089083,	
2017-06-27 22:59:52,173 Epoch[48] Batch [100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088003,	
2017-06-27 22:59:57,443 Epoch[48] Batch [110]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087286,	
2017-06-27 23:00:02,751 Epoch[48] Batch [120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087174,	
2017-06-27 23:00:08,034 Epoch[48] Batch [130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087004,	
2017-06-27 23:00:13,329 Epoch[48] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086530,	
2017-06-27 23:00:18,633 Epoch[48] Batch [150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086698,	
2017-06-27 23:00:23,932 Epoch[48] Batch [160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086513,	
2017-06-27 23:00:29,242 Epoch[48] Batch [170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086911,	
2017-06-27 23:00:34,534 Epoch[48] Batch [180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087106,	
2017-06-27 23:00:39,806 Epoch[48] Batch [190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087245,	
2017-06-27 23:00:45,072 Epoch[48] Batch [200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087745,	
2017-06-27 23:00:50,362 Epoch[48] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087680,	
2017-06-27 23:00:55,640 Epoch[48] Batch [220]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087999,	
2017-06-27 23:01:00,887 Epoch[48] Batch [230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087903,	
2017-06-27 23:01:06,227 Epoch[48] Batch [240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087693,	
2017-06-27 23:01:11,497 Epoch[48] Batch [250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087998,	
2017-06-27 23:01:16,765 Epoch[48] Batch [260]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087823,	
2017-06-27 23:01:22,055 Epoch[48] Batch [270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087485,	
2017-06-27 23:01:27,340 Epoch[48] Batch [280]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087522,	
2017-06-27 23:01:32,645 Epoch[48] Batch [290]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-27 23:01:37,906 Epoch[48] Batch [300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087426,	
2017-06-27 23:01:43,227 Epoch[48] Batch [310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087374,	
2017-06-27 23:01:48,515 Epoch[48] Batch [320]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087193,	
2017-06-27 23:01:53,794 Epoch[48] Batch [330]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087014,	
2017-06-27 23:01:59,079 Epoch[48] Batch [340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086863,	
2017-06-27 23:02:04,367 Epoch[48] Batch [350]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086726,	
2017-06-27 23:02:09,652 Epoch[48] Batch [360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086520,	
2017-06-27 23:02:14,939 Epoch[48] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086539,	
2017-06-27 23:02:20,228 Epoch[48] Batch [380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086578,	
2017-06-27 23:02:25,525 Epoch[48] Batch [390]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086530,	
2017-06-27 23:02:30,835 Epoch[48] Batch [400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086722,	
2017-06-27 23:02:36,112 Epoch[48] Batch [410]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086731,	
2017-06-27 23:02:41,381 Epoch[48] Batch [420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086565,	
2017-06-27 23:02:46,657 Epoch[48] Batch [430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086530,	
2017-06-27 23:02:51,973 Epoch[48] Batch [440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086539,	
2017-06-27 23:02:57,261 Epoch[48] Batch [450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-27 23:03:02,557 Epoch[48] Batch [460]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086580,	
2017-06-27 23:03:07,867 Epoch[48] Batch [470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086920,	
2017-06-27 23:03:13,152 Epoch[48] Batch [480]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086890,	
2017-06-27 23:03:18,425 Epoch[48] Batch [490]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086966,	
2017-06-27 23:03:23,701 Epoch[48] Batch [500]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087122,	
2017-06-27 23:03:29,023 Epoch[48] Batch [510]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087071,	
2017-06-27 23:03:34,303 Epoch[48] Batch [520]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087122,	
2017-06-27 23:03:39,624 Epoch[48] Batch [530]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087159,	
2017-06-27 23:03:44,929 Epoch[48] Batch [540]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087088,	
2017-06-27 23:03:50,200 Epoch[48] Batch [550]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087220,	
2017-06-27 23:03:55,445 Epoch[48] Batch [560]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087219,	
2017-06-27 23:04:00,730 Epoch[48] Batch [570]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087225,	
2017-06-27 23:04:06,035 Epoch[48] Batch [580]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087334,	
2017-06-27 23:04:11,353 Epoch[48] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087318,	
2017-06-27 23:04:16,704 Epoch[48] Batch [600]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087529,	
2017-06-27 23:04:21,982 Epoch[48] Batch [610]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087482,	
2017-06-27 23:04:27,311 Epoch[48] Batch [620]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-27 23:04:32,594 Epoch[48] Batch [630]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087711,	
2017-06-27 23:04:37,858 Epoch[48] Batch [640]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087656,	
2017-06-27 23:04:43,200 Epoch[48] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087712,	
2017-06-27 23:04:48,516 Epoch[48] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087615,	
2017-06-27 23:04:53,803 Epoch[48] Batch [670]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087515,	
2017-06-27 23:04:59,073 Epoch[48] Batch [680]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087570,	
2017-06-27 23:05:04,375 Epoch[48] Batch [690]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087647,	
2017-06-27 23:05:09,714 Epoch[48] Batch [700]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087649,	
2017-06-27 23:05:14,958 Epoch[48] Batch [710]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087716,	
2017-06-27 23:05:20,291 Epoch[48] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087747,	
2017-06-27 23:05:25,600 Epoch[48] Batch [730]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087611,	
2017-06-27 23:05:30,878 Epoch[48] Batch [740]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087473,	
2017-06-27 23:05:36,203 Epoch[48] Batch [750]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087411,	
2017-06-27 23:05:41,453 Epoch[48] Batch [760]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087473,	
2017-06-27 23:05:46,760 Epoch[48] Batch [770]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087353,	
2017-06-27 23:05:52,069 Epoch[48] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087415,	
2017-06-27 23:05:57,367 Epoch[48] Batch [790]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087433,	
2017-06-27 23:06:02,676 Epoch[48] Batch [800]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087317,	
2017-06-27 23:06:07,929 Epoch[48] Batch [810]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087331,	
2017-06-27 23:06:13,243 Epoch[48] Batch [820]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087396,	
2017-06-27 23:06:18,540 Epoch[48] Batch [830]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087432,	
2017-06-27 23:06:23,823 Epoch[48] Batch [840]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087464,	
2017-06-27 23:06:29,120 Epoch[48] Batch [850]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087460,	
2017-06-27 23:06:34,363 Epoch[48] Batch [860]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087570,	
2017-06-27 23:06:39,696 Epoch[48] Batch [870]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087547,	
2017-06-27 23:06:44,973 Epoch[48] Batch [880]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087613,	
2017-06-27 23:06:50,283 Epoch[48] Batch [890]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087669,	
2017-06-27 23:06:55,560 Epoch[48] Batch [900]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-27 23:07:00,847 Epoch[48] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-27 23:07:06,157 Epoch[48] Batch [920]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087479,	
2017-06-27 23:07:11,405 Epoch[48] Batch [930]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-27 23:07:16,730 Epoch[48] Batch [940]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087363,	
2017-06-27 23:07:22,016 Epoch[48] Batch [950]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087392,	
2017-06-27 23:07:27,316 Epoch[48] Batch [960]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087361,	
2017-06-27 23:07:32,583 Epoch[48] Batch [970]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-27 23:07:37,858 Epoch[48] Batch [980]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087497,	
2017-06-27 23:07:43,170 Epoch[48] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087456,	
2017-06-27 23:07:48,441 Epoch[48] Batch [1000]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-27 23:07:53,764 Epoch[48] Batch [1010]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087395,	
2017-06-27 23:07:59,068 Epoch[48] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-27 23:08:04,374 Epoch[48] Batch [1030]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087504,	
2017-06-27 23:08:09,631 Epoch[48] Batch [1040]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087467,	
2017-06-27 23:08:14,933 Epoch[48] Batch [1050]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087440,	
2017-06-27 23:08:20,213 Epoch[48] Batch [1060]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087412,	
2017-06-27 23:08:25,500 Epoch[48] Batch [1070]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-27 23:08:30,745 Epoch[48] Batch [1080]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087445,	
2017-06-27 23:08:36,064 Epoch[48] Batch [1090]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087440,	
2017-06-27 23:08:41,353 Epoch[48] Batch [1100]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087420,	
2017-06-27 23:08:46,655 Epoch[48] Batch [1110]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087382,	
2017-06-27 23:08:51,893 Epoch[48] Batch [1120]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-27 23:08:57,203 Epoch[48] Batch [1130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-27 23:09:02,468 Epoch[48] Batch [1140]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087511,	
2017-06-27 23:09:07,753 Epoch[48] Batch [1150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087546,	
2017-06-27 23:09:13,024 Epoch[48] Batch [1160]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087613,	
2017-06-27 23:09:18,290 Epoch[48] Batch [1170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087601,	
2017-06-27 23:09:23,574 Epoch[48] Batch [1180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087656,	
2017-06-27 23:09:28,854 Epoch[48] Batch [1190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-27 23:09:34,181 Epoch[48] Batch [1200]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087969,	
2017-06-27 23:09:39,457 Epoch[48] Batch [1210]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-27 23:09:44,750 Epoch[48] Batch [1220]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087986,	
2017-06-27 23:09:50,034 Epoch[48] Batch [1230]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087917,	
2017-06-27 23:09:55,312 Epoch[48] Batch [1240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087870,	
2017-06-27 23:10:00,095 Epoch[48] Batch [1250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087811,	
2017-06-27 23:10:04,935 Epoch[48] Batch [1260]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087833,	
2017-06-27 23:10:10,207 Epoch[48] Batch [1270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087892,	
2017-06-27 23:10:15,496 Epoch[48] Batch [1280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087879,	
2017-06-27 23:10:20,787 Epoch[48] Batch [1290]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087867,	
2017-06-27 23:10:26,070 Epoch[48] Batch [1300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087824,	
2017-06-27 23:10:31,347 Epoch[48] Batch [1310]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087854,	
2017-06-27 23:10:36,636 Epoch[48] Batch [1320]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087818,	
2017-06-27 23:10:41,933 Epoch[48] Batch [1330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087826,	
2017-06-27 23:10:47,202 Epoch[48] Batch [1340]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087832,	
2017-06-27 23:10:52,444 Epoch[48] Batch [1350]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087888,	
2017-06-27 23:10:57,694 Epoch[48] Batch [1360]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087892,	
2017-06-27 23:11:03,021 Epoch[48] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087896,	
2017-06-27 23:11:08,318 Epoch[48] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087840,	
2017-06-27 23:11:13,622 Epoch[48] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087842,	
2017-06-27 23:11:18,928 Epoch[48] Batch [1400]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087824,	
2017-06-27 23:11:24,236 Epoch[48] Batch [1410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087771,	
2017-06-27 23:11:29,530 Epoch[48] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087702,	
2017-06-27 23:11:34,814 Epoch[48] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087752,	
2017-06-27 23:11:40,129 Epoch[48] Batch [1440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087712,	
2017-06-27 23:11:45,414 Epoch[48] Batch [1450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087701,	
2017-06-27 23:11:50,747 Epoch[48] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087699,	
2017-06-27 23:11:56,021 Epoch[48] Batch [1470]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087627,	
2017-06-27 23:12:01,324 Epoch[48] Batch [1480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087587,	
2017-06-27 23:12:04,513 Epoch[48] Train-FCNLogLoss=0.087626
2017-06-27 23:12:04,513 Epoch[48] Time cost=785.732
2017-06-27 23:12:05,300 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0049.params"
2017-06-27 23:12:07,017 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0049.states"
2017-06-27 23:12:13,107 Epoch[49] Batch [10]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.083998,	
2017-06-27 23:12:18,391 Epoch[49] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.084920,	
2017-06-27 23:12:23,664 Epoch[49] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086898,	
2017-06-27 23:12:28,950 Epoch[49] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089270,	
2017-06-27 23:12:34,255 Epoch[49] Batch [50]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088309,	
2017-06-27 23:12:39,557 Epoch[49] Batch [60]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089459,	
2017-06-27 23:12:44,836 Epoch[49] Batch [70]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088687,	
2017-06-27 23:12:50,073 Epoch[49] Batch [80]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088363,	
2017-06-27 23:12:55,309 Epoch[49] Batch [90]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-27 23:13:00,672 Epoch[49] Batch [100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088232,	
2017-06-27 23:13:05,981 Epoch[49] Batch [110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087831,	
2017-06-27 23:13:11,272 Epoch[49] Batch [120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087751,	
2017-06-27 23:13:16,584 Epoch[49] Batch [130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-27 23:13:21,924 Epoch[49] Batch [140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087687,	
2017-06-27 23:13:27,241 Epoch[49] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087537,	
2017-06-27 23:13:32,564 Epoch[49] Batch [160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087927,	
2017-06-27 23:13:37,862 Epoch[49] Batch [170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087677,	
2017-06-27 23:13:43,242 Epoch[49] Batch [180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087750,	
2017-06-27 23:13:48,530 Epoch[49] Batch [190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087506,	
2017-06-27 23:13:53,850 Epoch[49] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087519,	
2017-06-27 23:13:59,171 Epoch[49] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087745,	
2017-06-27 23:14:04,424 Epoch[49] Batch [220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087251,	
2017-06-27 23:14:09,738 Epoch[49] Batch [230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087206,	
2017-06-27 23:14:15,032 Epoch[49] Batch [240]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087154,	
2017-06-27 23:14:20,354 Epoch[49] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087030,	
2017-06-27 23:14:25,616 Epoch[49] Batch [260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086885,	
2017-06-27 23:14:30,905 Epoch[49] Batch [270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087137,	
2017-06-27 23:14:36,205 Epoch[49] Batch [280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087094,	
2017-06-27 23:14:41,495 Epoch[49] Batch [290]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087246,	
2017-06-27 23:14:46,752 Epoch[49] Batch [300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087039,	
2017-06-27 23:14:52,059 Epoch[49] Batch [310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087189,	
2017-06-27 23:14:57,402 Epoch[49] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087275,	
2017-06-27 23:15:02,648 Epoch[49] Batch [330]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087701,	
2017-06-27 23:15:07,981 Epoch[49] Batch [340]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-27 23:15:13,241 Epoch[49] Batch [350]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087465,	
2017-06-27 23:15:18,534 Epoch[49] Batch [360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087390,	
2017-06-27 23:15:23,829 Epoch[49] Batch [370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087352,	
2017-06-27 23:15:29,112 Epoch[49] Batch [380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087414,	
2017-06-27 23:15:34,406 Epoch[49] Batch [390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087571,	
2017-06-27 23:15:39,721 Epoch[49] Batch [400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087612,	
2017-06-27 23:15:45,010 Epoch[49] Batch [410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087721,	
2017-06-27 23:15:50,332 Epoch[49] Batch [420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087688,	
2017-06-27 23:15:55,606 Epoch[49] Batch [430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087824,	
2017-06-27 23:16:00,914 Epoch[49] Batch [440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087694,	
2017-06-27 23:16:06,179 Epoch[49] Batch [450]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087945,	
2017-06-27 23:16:11,484 Epoch[49] Batch [460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087734,	
2017-06-27 23:16:16,750 Epoch[49] Batch [470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-27 23:16:22,082 Epoch[49] Batch [480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087724,	
2017-06-27 23:16:27,360 Epoch[49] Batch [490]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087759,	
2017-06-27 23:16:32,649 Epoch[49] Batch [500]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087757,	
2017-06-27 23:16:37,920 Epoch[49] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087715,	
2017-06-27 23:16:43,182 Epoch[49] Batch [520]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087674,	
2017-06-27 23:16:48,455 Epoch[49] Batch [530]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-27 23:16:53,759 Epoch[49] Batch [540]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087791,	
2017-06-27 23:16:59,074 Epoch[49] Batch [550]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087902,	
2017-06-27 23:17:04,369 Epoch[49] Batch [560]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087816,	
2017-06-27 23:17:09,642 Epoch[49] Batch [570]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087886,	
2017-06-27 23:17:14,920 Epoch[49] Batch [580]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-27 23:17:20,238 Epoch[49] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087883,	
2017-06-27 23:17:25,536 Epoch[49] Batch [600]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087770,	
2017-06-27 23:17:30,795 Epoch[49] Batch [610]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-27 23:17:36,073 Epoch[49] Batch [620]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087725,	
2017-06-27 23:17:41,364 Epoch[49] Batch [630]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087669,	
2017-06-27 23:17:46,633 Epoch[49] Batch [640]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087642,	
2017-06-27 23:17:51,933 Epoch[49] Batch [650]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087568,	
2017-06-27 23:17:57,233 Epoch[49] Batch [660]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087489,	
2017-06-27 23:18:02,524 Epoch[49] Batch [670]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087499,	
2017-06-27 23:18:07,800 Epoch[49] Batch [680]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-27 23:18:13,071 Epoch[49] Batch [690]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087619,	
2017-06-27 23:18:18,343 Epoch[49] Batch [700]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087658,	
2017-06-27 23:18:23,639 Epoch[49] Batch [710]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087651,	
2017-06-27 23:18:28,943 Epoch[49] Batch [720]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087714,	
2017-06-27 23:18:34,245 Epoch[49] Batch [730]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087771,	
2017-06-27 23:18:39,515 Epoch[49] Batch [740]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-27 23:18:44,795 Epoch[49] Batch [750]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087624,	
2017-06-27 23:18:50,077 Epoch[49] Batch [760]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087651,	
2017-06-27 23:18:55,377 Epoch[49] Batch [770]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087503,	
2017-06-27 23:19:00,666 Epoch[49] Batch [780]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087644,	
2017-06-27 23:19:05,951 Epoch[49] Batch [790]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087540,	
2017-06-27 23:19:11,217 Epoch[49] Batch [800]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087515,	
2017-06-27 23:19:16,547 Epoch[49] Batch [810]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087548,	
2017-06-27 23:19:21,798 Epoch[49] Batch [820]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087610,	
2017-06-27 23:19:27,153 Epoch[49] Batch [830]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087717,	
2017-06-27 23:19:32,426 Epoch[49] Batch [840]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087807,	
2017-06-27 23:19:37,725 Epoch[49] Batch [850]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087839,	
2017-06-27 23:19:43,024 Epoch[49] Batch [860]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087925,	
2017-06-27 23:19:48,298 Epoch[49] Batch [870]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087817,	
2017-06-27 23:19:53,571 Epoch[49] Batch [880]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087808,	
2017-06-27 23:19:58,859 Epoch[49] Batch [890]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087868,	
2017-06-27 23:20:04,161 Epoch[49] Batch [900]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087844,	
2017-06-27 23:20:09,430 Epoch[49] Batch [910]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087824,	
2017-06-27 23:20:14,740 Epoch[49] Batch [920]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087772,	
2017-06-27 23:20:20,012 Epoch[49] Batch [930]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087697,	
2017-06-27 23:20:25,280 Epoch[49] Batch [940]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087664,	
2017-06-27 23:20:30,583 Epoch[49] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087593,	
2017-06-27 23:20:35,864 Epoch[49] Batch [960]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087658,	
2017-06-27 23:20:41,193 Epoch[49] Batch [970]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087695,	
2017-06-27 23:20:46,476 Epoch[49] Batch [980]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087740,	
2017-06-27 23:20:51,760 Epoch[49] Batch [990]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087707,	
2017-06-27 23:20:57,025 Epoch[49] Batch [1000]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087751,	
2017-06-27 23:21:02,323 Epoch[49] Batch [1010]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087830,	
2017-06-27 23:21:07,616 Epoch[49] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-27 23:21:12,903 Epoch[49] Batch [1030]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087753,	
2017-06-27 23:21:18,199 Epoch[49] Batch [1040]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087809,	
2017-06-27 23:21:23,508 Epoch[49] Batch [1050]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087746,	
2017-06-27 23:21:28,707 Epoch[49] Batch [1060]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087771,	
2017-06-27 23:21:34,085 Epoch[49] Batch [1070]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087798,	
2017-06-27 23:21:39,380 Epoch[49] Batch [1080]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087774,	
2017-06-27 23:21:44,659 Epoch[49] Batch [1090]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087842,	
2017-06-27 23:21:49,980 Epoch[49] Batch [1100]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087843,	
2017-06-27 23:21:55,270 Epoch[49] Batch [1110]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087957,	
2017-06-27 23:22:00,580 Epoch[49] Batch [1120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088051,	
2017-06-27 23:22:05,912 Epoch[49] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087983,	
2017-06-27 23:22:11,209 Epoch[49] Batch [1140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087937,	
2017-06-27 23:22:16,513 Epoch[49] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088007,	
2017-06-27 23:22:21,815 Epoch[49] Batch [1160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087900,	
2017-06-27 23:22:27,078 Epoch[49] Batch [1170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087950,	
2017-06-27 23:22:32,412 Epoch[49] Batch [1180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087963,	
2017-06-27 23:22:37,729 Epoch[49] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087910,	
2017-06-27 23:22:43,095 Epoch[49] Batch [1200]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087897,	
2017-06-27 23:22:48,389 Epoch[49] Batch [1210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087886,	
2017-06-27 23:22:53,697 Epoch[49] Batch [1220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087896,	
2017-06-27 23:22:59,009 Epoch[49] Batch [1230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087848,	
2017-06-27 23:23:04,310 Epoch[49] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087905,	
2017-06-27 23:23:09,063 Epoch[49] Batch [1250]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087932,	
2017-06-27 23:23:13,882 Epoch[49] Batch [1260]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087978,	
2017-06-27 23:23:19,163 Epoch[49] Batch [1270]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088001,	
2017-06-27 23:23:24,493 Epoch[49] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-27 23:23:29,804 Epoch[49] Batch [1290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087958,	
2017-06-27 23:23:35,079 Epoch[49] Batch [1300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087918,	
2017-06-27 23:23:40,357 Epoch[49] Batch [1310]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087941,	
2017-06-27 23:23:45,661 Epoch[49] Batch [1320]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087917,	
2017-06-27 23:23:50,966 Epoch[49] Batch [1330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-27 23:23:56,272 Epoch[49] Batch [1340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087845,	
2017-06-27 23:24:01,549 Epoch[49] Batch [1350]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087795,	
2017-06-27 23:24:06,837 Epoch[49] Batch [1360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087763,	
2017-06-27 23:24:12,135 Epoch[49] Batch [1370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087823,	
2017-06-27 23:24:17,443 Epoch[49] Batch [1380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087786,	
2017-06-27 23:24:22,743 Epoch[49] Batch [1390]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087787,	
2017-06-27 23:24:28,049 Epoch[49] Batch [1400]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087740,	
2017-06-27 23:24:33,330 Epoch[49] Batch [1410]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087751,	
2017-06-27 23:24:38,619 Epoch[49] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087737,	
2017-06-27 23:24:43,830 Epoch[49] Batch [1430]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087695,	
2017-06-27 23:24:49,101 Epoch[49] Batch [1440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087696,	
2017-06-27 23:24:54,374 Epoch[49] Batch [1450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-27 23:24:59,665 Epoch[49] Batch [1460]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087634,	
2017-06-27 23:25:04,969 Epoch[49] Batch [1470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087597,	
2017-06-27 23:25:10,268 Epoch[49] Batch [1480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087634,	
2017-06-27 23:25:13,424 Epoch[49] Train-FCNLogLoss=0.087625
2017-06-27 23:25:13,424 Epoch[49] Time cost=786.406
2017-06-27 23:25:14,186 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0050.params"
2017-06-27 23:25:15,925 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0050.states"
2017-06-27 23:25:22,063 Epoch[50] Batch [10]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.092421,	
2017-06-27 23:25:27,319 Epoch[50] Batch [20]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094447,	
2017-06-27 23:25:32,655 Epoch[50] Batch [30]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091782,	
2017-06-27 23:25:37,952 Epoch[50] Batch [40]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089823,	
2017-06-27 23:25:43,270 Epoch[50] Batch [50]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-27 23:25:48,585 Epoch[50] Batch [60]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089282,	
2017-06-27 23:25:53,867 Epoch[50] Batch [70]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088549,	
2017-06-27 23:25:59,163 Epoch[50] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087941,	
2017-06-27 23:26:04,480 Epoch[50] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088541,	
2017-06-27 23:26:09,766 Epoch[50] Batch [100]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-27 23:26:15,066 Epoch[50] Batch [110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088289,	
2017-06-27 23:26:20,336 Epoch[50] Batch [120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088294,	
2017-06-27 23:26:25,641 Epoch[50] Batch [130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088582,	
2017-06-27 23:26:30,940 Epoch[50] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088625,	
2017-06-27 23:26:36,214 Epoch[50] Batch [150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087771,	
2017-06-27 23:26:41,541 Epoch[50] Batch [160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087690,	
2017-06-27 23:26:46,836 Epoch[50] Batch [170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087924,	
2017-06-27 23:26:52,138 Epoch[50] Batch [180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087283,	
2017-06-27 23:26:57,441 Epoch[50] Batch [190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087539,	
2017-06-27 23:27:02,758 Epoch[50] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087828,	
2017-06-27 23:27:08,047 Epoch[50] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087929,	
2017-06-27 23:27:13,359 Epoch[50] Batch [220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087727,	
2017-06-27 23:27:18,647 Epoch[50] Batch [230]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087833,	
2017-06-27 23:27:23,945 Epoch[50] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087509,	
2017-06-27 23:27:29,269 Epoch[50] Batch [250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087514,	
2017-06-27 23:27:34,532 Epoch[50] Batch [260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087371,	
2017-06-27 23:27:39,852 Epoch[50] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087090,	
2017-06-27 23:27:45,131 Epoch[50] Batch [280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086734,	
2017-06-27 23:27:50,465 Epoch[50] Batch [290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086703,	
2017-06-27 23:27:55,775 Epoch[50] Batch [300]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086910,	
2017-06-27 23:28:01,063 Epoch[50] Batch [310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086863,	
2017-06-27 23:28:06,377 Epoch[50] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086796,	
2017-06-27 23:28:11,709 Epoch[50] Batch [330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086561,	
2017-06-27 23:28:17,016 Epoch[50] Batch [340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086651,	
2017-06-27 23:28:22,336 Epoch[50] Batch [350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086667,	
2017-06-27 23:28:27,624 Epoch[50] Batch [360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086787,	
2017-06-27 23:28:32,888 Epoch[50] Batch [370]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086791,	
2017-06-27 23:28:38,154 Epoch[50] Batch [380]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086731,	
2017-06-27 23:28:43,443 Epoch[50] Batch [390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086960,	
2017-06-27 23:28:48,728 Epoch[50] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087043,	
2017-06-27 23:28:54,035 Epoch[50] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-27 23:28:59,326 Epoch[50] Batch [420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086973,	
2017-06-27 23:29:04,632 Epoch[50] Batch [430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086983,	
2017-06-27 23:29:09,894 Epoch[50] Batch [440]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086966,	
2017-06-27 23:29:15,174 Epoch[50] Batch [450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086964,	
2017-06-27 23:29:20,460 Epoch[50] Batch [460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086941,	
2017-06-27 23:29:25,762 Epoch[50] Batch [470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086895,	
2017-06-27 23:29:31,061 Epoch[50] Batch [480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086882,	
2017-06-27 23:29:36,332 Epoch[50] Batch [490]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086910,	
2017-06-27 23:29:41,625 Epoch[50] Batch [500]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086880,	
2017-06-27 23:29:46,882 Epoch[50] Batch [510]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086870,	
2017-06-27 23:29:52,178 Epoch[50] Batch [520]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086894,	
2017-06-27 23:29:57,464 Epoch[50] Batch [530]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087046,	
2017-06-27 23:30:02,765 Epoch[50] Batch [540]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087137,	
2017-06-27 23:30:08,061 Epoch[50] Batch [550]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087140,	
2017-06-27 23:30:13,377 Epoch[50] Batch [560]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087150,	
2017-06-27 23:30:18,652 Epoch[50] Batch [570]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087368,	
2017-06-27 23:30:23,926 Epoch[50] Batch [580]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087388,	
2017-06-27 23:30:29,213 Epoch[50] Batch [590]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087429,	
2017-06-27 23:30:34,533 Epoch[50] Batch [600]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087487,	
2017-06-27 23:30:39,824 Epoch[50] Batch [610]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087581,	
2017-06-27 23:30:45,127 Epoch[50] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087584,	
2017-06-27 23:30:50,436 Epoch[50] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087638,	
2017-06-27 23:30:55,755 Epoch[50] Batch [640]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087665,	
2017-06-27 23:31:01,033 Epoch[50] Batch [650]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087592,	
2017-06-27 23:31:06,300 Epoch[50] Batch [660]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087612,	
2017-06-27 23:31:11,639 Epoch[50] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087671,	
2017-06-27 23:31:16,947 Epoch[50] Batch [680]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087631,	
2017-06-27 23:31:22,195 Epoch[50] Batch [690]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087634,	
2017-06-27 23:31:27,535 Epoch[50] Batch [700]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087606,	
2017-06-27 23:31:32,791 Epoch[50] Batch [710]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087692,	
2017-06-27 23:31:38,052 Epoch[50] Batch [720]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087589,	
2017-06-27 23:31:43,398 Epoch[50] Batch [730]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087478,	
2017-06-27 23:31:48,693 Epoch[50] Batch [740]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087366,	
2017-06-27 23:31:53,990 Epoch[50] Batch [750]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087413,	
2017-06-27 23:31:59,247 Epoch[50] Batch [760]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087411,	
2017-06-27 23:32:04,568 Epoch[50] Batch [770]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087494,	
2017-06-27 23:32:09,853 Epoch[50] Batch [780]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087379,	
2017-06-27 23:32:15,141 Epoch[50] Batch [790]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087283,	
2017-06-27 23:32:20,462 Epoch[50] Batch [800]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087364,	
2017-06-27 23:32:25,801 Epoch[50] Batch [810]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087248,	
2017-06-27 23:32:31,085 Epoch[50] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087363,	
2017-06-27 23:32:36,372 Epoch[50] Batch [830]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087369,	
2017-06-27 23:32:41,658 Epoch[50] Batch [840]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087361,	
2017-06-27 23:32:46,977 Epoch[50] Batch [850]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087340,	
2017-06-27 23:32:52,283 Epoch[50] Batch [860]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087205,	
2017-06-27 23:32:57,532 Epoch[50] Batch [870]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087181,	
2017-06-27 23:33:02,838 Epoch[50] Batch [880]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087064,	
2017-06-27 23:33:08,143 Epoch[50] Batch [890]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087158,	
2017-06-27 23:33:13,434 Epoch[50] Batch [900]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087243,	
2017-06-27 23:33:18,710 Epoch[50] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087201,	
2017-06-27 23:33:23,976 Epoch[50] Batch [920]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087190,	
2017-06-27 23:33:29,269 Epoch[50] Batch [930]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087205,	
2017-06-27 23:33:34,563 Epoch[50] Batch [940]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087154,	
2017-06-27 23:33:39,892 Epoch[50] Batch [950]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087213,	
2017-06-27 23:33:45,152 Epoch[50] Batch [960]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087205,	
2017-06-27 23:33:50,464 Epoch[50] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087282,	
2017-06-27 23:33:55,736 Epoch[50] Batch [980]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087341,	
2017-06-27 23:34:01,022 Epoch[50] Batch [990]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087312,	
2017-06-27 23:34:06,328 Epoch[50] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087353,	
2017-06-27 23:34:11,520 Epoch[50] Batch [1010]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087457,	
2017-06-27 23:34:16,861 Epoch[50] Batch [1020]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087500,	
2017-06-27 23:34:22,143 Epoch[50] Batch [1030]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087416,	
2017-06-27 23:34:27,457 Epoch[50] Batch [1040]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087375,	
2017-06-27 23:34:32,789 Epoch[50] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-27 23:34:38,094 Epoch[50] Batch [1060]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087509,	
2017-06-27 23:34:43,326 Epoch[50] Batch [1070]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-27 23:34:48,709 Epoch[50] Batch [1080]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-27 23:34:53,998 Epoch[50] Batch [1090]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087381,	
2017-06-27 23:34:59,294 Epoch[50] Batch [1100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087308,	
2017-06-27 23:35:04,630 Epoch[50] Batch [1110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-27 23:35:09,926 Epoch[50] Batch [1120]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087306,	
2017-06-27 23:35:15,196 Epoch[50] Batch [1130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087412,	
2017-06-27 23:35:20,538 Epoch[50] Batch [1140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-27 23:35:25,835 Epoch[50] Batch [1150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087337,	
2017-06-27 23:35:31,142 Epoch[50] Batch [1160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087332,	
2017-06-27 23:35:36,461 Epoch[50] Batch [1170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087352,	
2017-06-27 23:35:41,740 Epoch[50] Batch [1180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087390,	
2017-06-27 23:35:47,059 Epoch[50] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087403,	
2017-06-27 23:35:52,320 Epoch[50] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087473,	
2017-06-27 23:35:57,625 Epoch[50] Batch [1210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087445,	
2017-06-27 23:36:02,874 Epoch[50] Batch [1220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087479,	
2017-06-27 23:36:08,168 Epoch[50] Batch [1230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087519,	
2017-06-27 23:36:13,489 Epoch[50] Batch [1240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087619,	
2017-06-27 23:36:18,265 Epoch[50] Batch [1250]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087618,	
2017-06-27 23:36:23,004 Epoch[50] Batch [1260]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087593,	
2017-06-27 23:36:28,312 Epoch[50] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-27 23:36:33,625 Epoch[50] Batch [1280]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087590,	
2017-06-27 23:36:38,901 Epoch[50] Batch [1290]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-27 23:36:44,165 Epoch[50] Batch [1300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087509,	
2017-06-27 23:36:49,505 Epoch[50] Batch [1310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087532,	
2017-06-27 23:36:54,782 Epoch[50] Batch [1320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087554,	
2017-06-27 23:37:00,053 Epoch[50] Batch [1330]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087522,	
2017-06-27 23:37:05,371 Epoch[50] Batch [1340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087526,	
2017-06-27 23:37:10,689 Epoch[50] Batch [1350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087466,	
2017-06-27 23:37:15,987 Epoch[50] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-27 23:37:21,216 Epoch[50] Batch [1370]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087430,	
2017-06-27 23:37:26,532 Epoch[50] Batch [1380]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087433,	
2017-06-27 23:37:31,858 Epoch[50] Batch [1390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-27 23:37:37,146 Epoch[50] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087365,	
2017-06-27 23:37:42,463 Epoch[50] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-27 23:37:47,753 Epoch[50] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087377,	
2017-06-27 23:37:53,028 Epoch[50] Batch [1430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087413,	
2017-06-27 23:37:58,336 Epoch[50] Batch [1440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087370,	
2017-06-27 23:38:03,575 Epoch[50] Batch [1450]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087362,	
2017-06-27 23:38:08,885 Epoch[50] Batch [1460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-27 23:38:14,212 Epoch[50] Batch [1470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087278,	
2017-06-27 23:38:19,483 Epoch[50] Batch [1480]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087255,	
2017-06-27 23:38:22,706 Epoch[50] Train-FCNLogLoss=0.087245
2017-06-27 23:38:22,706 Epoch[50] Time cost=786.780
2017-06-27 23:38:23,453 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0051.params"
2017-06-27 23:38:25,153 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0051.states"
2017-06-27 23:38:31,161 Epoch[51] Batch [10]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089752,	
2017-06-27 23:38:36,399 Epoch[51] Batch [20]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093351,	
2017-06-27 23:38:41,723 Epoch[51] Batch [30]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090513,	
2017-06-27 23:38:47,026 Epoch[51] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090052,	
2017-06-27 23:38:52,365 Epoch[51] Batch [50]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089999,	
2017-06-27 23:38:57,669 Epoch[51] Batch [60]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089102,	
2017-06-27 23:39:02,985 Epoch[51] Batch [70]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088667,	
2017-06-27 23:39:08,319 Epoch[51] Batch [80]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088538,	
2017-06-27 23:39:13,565 Epoch[51] Batch [90]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088107,	
2017-06-27 23:39:18,861 Epoch[51] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-27 23:39:24,118 Epoch[51] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088700,	
2017-06-27 23:39:29,436 Epoch[51] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088963,	
2017-06-27 23:39:34,720 Epoch[51] Batch [130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089259,	
2017-06-27 23:39:40,041 Epoch[51] Batch [140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088719,	
2017-06-27 23:39:45,305 Epoch[51] Batch [150]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088311,	
2017-06-27 23:39:50,599 Epoch[51] Batch [160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087798,	
2017-06-27 23:39:55,897 Epoch[51] Batch [170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087440,	
2017-06-27 23:40:01,178 Epoch[51] Batch [180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087628,	
2017-06-27 23:40:06,491 Epoch[51] Batch [190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-27 23:40:11,691 Epoch[51] Batch [200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087906,	
2017-06-27 23:40:17,013 Epoch[51] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087695,	
2017-06-27 23:40:22,350 Epoch[51] Batch [220]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087582,	
2017-06-27 23:40:27,671 Epoch[51] Batch [230]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086706,	
2017-06-27 23:40:32,919 Epoch[51] Batch [240]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086790,	
2017-06-27 23:40:38,250 Epoch[51] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086738,	
2017-06-27 23:40:43,535 Epoch[51] Batch [260]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086821,	
2017-06-27 23:40:48,860 Epoch[51] Batch [270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086754,	
2017-06-27 23:40:54,137 Epoch[51] Batch [280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086863,	
2017-06-27 23:40:59,525 Epoch[51] Batch [290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087014,	
2017-06-27 23:41:04,803 Epoch[51] Batch [300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086749,	
2017-06-27 23:41:10,107 Epoch[51] Batch [310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086705,	
2017-06-27 23:41:15,438 Epoch[51] Batch [320]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086648,	
2017-06-27 23:41:20,772 Epoch[51] Batch [330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086326,	
2017-06-27 23:41:26,048 Epoch[51] Batch [340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086266,	
2017-06-27 23:41:31,380 Epoch[51] Batch [350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086325,	
2017-06-27 23:41:36,681 Epoch[51] Batch [360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086345,	
2017-06-27 23:41:41,998 Epoch[51] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086401,	
2017-06-27 23:41:47,292 Epoch[51] Batch [380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086619,	
2017-06-27 23:41:52,624 Epoch[51] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086600,	
2017-06-27 23:41:57,965 Epoch[51] Batch [400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086871,	
2017-06-27 23:42:03,265 Epoch[51] Batch [410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086916,	
2017-06-27 23:42:08,605 Epoch[51] Batch [420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086993,	
2017-06-27 23:42:13,870 Epoch[51] Batch [430]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087002,	
2017-06-27 23:42:19,200 Epoch[51] Batch [440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086901,	
2017-06-27 23:42:24,477 Epoch[51] Batch [450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086931,	
2017-06-27 23:42:29,782 Epoch[51] Batch [460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086818,	
2017-06-27 23:42:35,098 Epoch[51] Batch [470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086718,	
2017-06-27 23:42:40,421 Epoch[51] Batch [480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086659,	
2017-06-27 23:42:45,709 Epoch[51] Batch [490]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086842,	
2017-06-27 23:42:51,030 Epoch[51] Batch [500]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086819,	
2017-06-27 23:42:56,345 Epoch[51] Batch [510]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086763,	
2017-06-27 23:43:01,669 Epoch[51] Batch [520]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086838,	
2017-06-27 23:43:06,992 Epoch[51] Batch [530]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086756,	
2017-06-27 23:43:12,281 Epoch[51] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086794,	
2017-06-27 23:43:17,571 Epoch[51] Batch [550]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086935,	
2017-06-27 23:43:22,898 Epoch[51] Batch [560]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086831,	
2017-06-27 23:43:28,189 Epoch[51] Batch [570]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086843,	
2017-06-27 23:43:33,482 Epoch[51] Batch [580]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086896,	
2017-06-27 23:43:38,809 Epoch[51] Batch [590]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086917,	
2017-06-27 23:43:44,096 Epoch[51] Batch [600]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086901,	
2017-06-27 23:43:49,430 Epoch[51] Batch [610]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086821,	
2017-06-27 23:43:54,715 Epoch[51] Batch [620]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086858,	
2017-06-27 23:44:00,015 Epoch[51] Batch [630]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086972,	
2017-06-27 23:44:05,316 Epoch[51] Batch [640]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086985,	
2017-06-27 23:44:10,599 Epoch[51] Batch [650]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086990,	
2017-06-27 23:44:15,944 Epoch[51] Batch [660]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.086894,	
2017-06-27 23:44:21,205 Epoch[51] Batch [670]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086871,	
2017-06-27 23:44:26,512 Epoch[51] Batch [680]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086732,	
2017-06-27 23:44:31,837 Epoch[51] Batch [690]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086719,	
2017-06-27 23:44:37,133 Epoch[51] Batch [700]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086707,	
2017-06-27 23:44:42,449 Epoch[51] Batch [710]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086744,	
2017-06-27 23:44:47,756 Epoch[51] Batch [720]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086714,	
2017-06-27 23:44:53,059 Epoch[51] Batch [730]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086643,	
2017-06-27 23:44:58,336 Epoch[51] Batch [740]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086629,	
2017-06-27 23:45:03,600 Epoch[51] Batch [750]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086629,	
2017-06-27 23:45:08,932 Epoch[51] Batch [760]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086577,	
2017-06-27 23:45:14,218 Epoch[51] Batch [770]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086553,	
2017-06-27 23:45:19,510 Epoch[51] Batch [780]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086518,	
2017-06-27 23:45:24,811 Epoch[51] Batch [790]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086422,	
2017-06-27 23:45:30,124 Epoch[51] Batch [800]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086363,	
2017-06-27 23:45:35,456 Epoch[51] Batch [810]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086348,	
2017-06-27 23:45:40,747 Epoch[51] Batch [820]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086288,	
2017-06-27 23:45:46,050 Epoch[51] Batch [830]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086277,	
2017-06-27 23:45:51,354 Epoch[51] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086443,	
2017-06-27 23:45:56,642 Epoch[51] Batch [850]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086444,	
2017-06-27 23:46:01,938 Epoch[51] Batch [860]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086475,	
2017-06-27 23:46:07,287 Epoch[51] Batch [870]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.086450,	
2017-06-27 23:46:12,529 Epoch[51] Batch [880]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086547,	
2017-06-27 23:46:17,898 Epoch[51] Batch [890]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.086529,	
2017-06-27 23:46:23,192 Epoch[51] Batch [900]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086610,	
2017-06-27 23:46:28,482 Epoch[51] Batch [910]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086515,	
2017-06-27 23:46:33,784 Epoch[51] Batch [920]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086498,	
2017-06-27 23:46:39,062 Epoch[51] Batch [930]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086459,	
2017-06-27 23:46:44,357 Epoch[51] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086544,	
2017-06-27 23:46:49,682 Epoch[51] Batch [950]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086587,	
2017-06-27 23:46:55,014 Epoch[51] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086677,	
2017-06-27 23:47:00,287 Epoch[51] Batch [970]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086648,	
2017-06-27 23:47:05,625 Epoch[51] Batch [980]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086728,	
2017-06-27 23:47:10,918 Epoch[51] Batch [990]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086744,	
2017-06-27 23:47:16,241 Epoch[51] Batch [1000]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086724,	
2017-06-27 23:47:21,563 Epoch[51] Batch [1010]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086741,	
2017-06-27 23:47:26,907 Epoch[51] Batch [1020]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086693,	
2017-06-27 23:47:32,199 Epoch[51] Batch [1030]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086687,	
2017-06-27 23:47:37,510 Epoch[51] Batch [1040]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086668,	
2017-06-27 23:47:42,799 Epoch[51] Batch [1050]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086767,	
2017-06-27 23:47:48,101 Epoch[51] Batch [1060]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086779,	
2017-06-27 23:47:53,402 Epoch[51] Batch [1070]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086707,	
2017-06-27 23:47:58,734 Epoch[51] Batch [1080]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086710,	
2017-06-27 23:48:04,020 Epoch[51] Batch [1090]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086680,	
2017-06-27 23:48:09,330 Epoch[51] Batch [1100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086698,	
2017-06-27 23:48:14,688 Epoch[51] Batch [1110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086788,	
2017-06-27 23:48:19,959 Epoch[51] Batch [1120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086759,	
2017-06-27 23:48:25,268 Epoch[51] Batch [1130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086765,	
2017-06-27 23:48:30,566 Epoch[51] Batch [1140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086747,	
2017-06-27 23:48:35,842 Epoch[51] Batch [1150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086758,	
2017-06-27 23:48:41,115 Epoch[51] Batch [1160]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086693,	
2017-06-27 23:48:46,457 Epoch[51] Batch [1170]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086677,	
2017-06-27 23:48:51,765 Epoch[51] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086707,	
2017-06-27 23:48:57,064 Epoch[51] Batch [1190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086718,	
2017-06-27 23:49:02,357 Epoch[51] Batch [1200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086746,	
2017-06-27 23:49:07,667 Epoch[51] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086853,	
2017-06-27 23:49:12,994 Epoch[51] Batch [1220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086808,	
2017-06-27 23:49:18,301 Epoch[51] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086820,	
2017-06-27 23:49:23,586 Epoch[51] Batch [1240]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086862,	
2017-06-27 23:49:28,373 Epoch[51] Batch [1250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086972,	
2017-06-27 23:49:33,051 Epoch[51] Batch [1260]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.086956,	
2017-06-27 23:49:38,359 Epoch[51] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086959,	
2017-06-27 23:49:43,654 Epoch[51] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086978,	
2017-06-27 23:49:48,974 Epoch[51] Batch [1290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086985,	
2017-06-27 23:49:54,235 Epoch[51] Batch [1300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087025,	
2017-06-27 23:49:59,519 Epoch[51] Batch [1310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087037,	
2017-06-27 23:50:04,815 Epoch[51] Batch [1320]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087132,	
2017-06-27 23:50:10,154 Epoch[51] Batch [1330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087101,	
2017-06-27 23:50:15,446 Epoch[51] Batch [1340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087131,	
2017-06-27 23:50:20,719 Epoch[51] Batch [1350]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087199,	
2017-06-27 23:50:26,011 Epoch[51] Batch [1360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087141,	
2017-06-27 23:50:31,301 Epoch[51] Batch [1370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087133,	
2017-06-27 23:50:36,608 Epoch[51] Batch [1380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087143,	
2017-06-27 23:50:41,894 Epoch[51] Batch [1390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087113,	
2017-06-27 23:50:47,197 Epoch[51] Batch [1400]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087127,	
2017-06-27 23:50:52,401 Epoch[51] Batch [1410]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087142,	
2017-06-27 23:50:57,706 Epoch[51] Batch [1420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087183,	
2017-06-27 23:51:02,991 Epoch[51] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087221,	
2017-06-27 23:51:08,310 Epoch[51] Batch [1440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087158,	
2017-06-27 23:51:13,625 Epoch[51] Batch [1450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087210,	
2017-06-27 23:51:18,968 Epoch[51] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087248,	
2017-06-27 23:51:24,264 Epoch[51] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087210,	
2017-06-27 23:51:29,569 Epoch[51] Batch [1480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087200,	
2017-06-27 23:51:32,769 Epoch[51] Train-FCNLogLoss=0.087190
2017-06-27 23:51:32,769 Epoch[51] Time cost=787.615
2017-06-27 23:51:33,513 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0052.params"
2017-06-27 23:51:35,236 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0052.states"
2017-06-27 23:51:41,369 Epoch[52] Batch [10]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089973,	
2017-06-27 23:51:46,650 Epoch[52] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089650,	
2017-06-27 23:51:51,958 Epoch[52] Batch [30]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-27 23:51:57,239 Epoch[52] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089296,	
2017-06-27 23:52:02,572 Epoch[52] Batch [50]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089248,	
2017-06-27 23:52:07,846 Epoch[52] Batch [60]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087811,	
2017-06-27 23:52:13,184 Epoch[52] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088676,	
2017-06-27 23:52:18,522 Epoch[52] Batch [80]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088484,	
2017-06-27 23:52:23,799 Epoch[52] Batch [90]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087635,	
2017-06-27 23:52:29,130 Epoch[52] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086631,	
2017-06-27 23:52:34,386 Epoch[52] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086362,	
2017-06-27 23:52:39,705 Epoch[52] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086517,	
2017-06-27 23:52:45,030 Epoch[52] Batch [130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086364,	
2017-06-27 23:52:50,393 Epoch[52] Batch [140]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086685,	
2017-06-27 23:52:55,655 Epoch[52] Batch [150]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086889,	
2017-06-27 23:53:00,939 Epoch[52] Batch [160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087206,	
2017-06-27 23:53:06,230 Epoch[52] Batch [170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087581,	
2017-06-27 23:53:11,506 Epoch[52] Batch [180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087616,	
2017-06-27 23:53:16,792 Epoch[52] Batch [190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087112,	
2017-06-27 23:53:22,099 Epoch[52] Batch [200]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087272,	
2017-06-27 23:53:27,356 Epoch[52] Batch [210]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087200,	
2017-06-27 23:53:32,672 Epoch[52] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086925,	
2017-06-27 23:53:37,901 Epoch[52] Batch [230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087327,	
2017-06-27 23:53:43,201 Epoch[52] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087314,	
2017-06-27 23:53:48,479 Epoch[52] Batch [250]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-27 23:53:53,801 Epoch[52] Batch [260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087106,	
2017-06-27 23:53:59,104 Epoch[52] Batch [270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087179,	
2017-06-27 23:54:04,355 Epoch[52] Batch [280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087267,	
2017-06-27 23:54:09,667 Epoch[52] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087620,	
2017-06-27 23:54:14,944 Epoch[52] Batch [300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087624,	
2017-06-27 23:54:20,249 Epoch[52] Batch [310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087576,	
2017-06-27 23:54:25,493 Epoch[52] Batch [320]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087348,	
2017-06-27 23:54:30,796 Epoch[52] Batch [330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087510,	
2017-06-27 23:54:36,066 Epoch[52] Batch [340]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087662,	
2017-06-27 23:54:41,356 Epoch[52] Batch [350]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087754,	
2017-06-27 23:54:46,616 Epoch[52] Batch [360]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-27 23:54:51,901 Epoch[52] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087683,	
2017-06-27 23:54:57,224 Epoch[52] Batch [380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087548,	
2017-06-27 23:55:02,479 Epoch[52] Batch [390]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087570,	
2017-06-27 23:55:07,777 Epoch[52] Batch [400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087504,	
2017-06-27 23:55:13,042 Epoch[52] Batch [410]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087684,	
2017-06-27 23:55:18,353 Epoch[52] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087831,	
2017-06-27 23:55:23,628 Epoch[52] Batch [430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087679,	
2017-06-27 23:55:28,901 Epoch[52] Batch [440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087803,	
2017-06-27 23:55:34,183 Epoch[52] Batch [450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087593,	
2017-06-27 23:55:39,463 Epoch[52] Batch [460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-27 23:55:44,754 Epoch[52] Batch [470]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087255,	
2017-06-27 23:55:50,066 Epoch[52] Batch [480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087239,	
2017-06-27 23:55:55,359 Epoch[52] Batch [490]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087362,	
2017-06-27 23:56:00,625 Epoch[52] Batch [500]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087483,	
2017-06-27 23:56:05,928 Epoch[52] Batch [510]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087283,	
2017-06-27 23:56:11,219 Epoch[52] Batch [520]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087289,	
2017-06-27 23:56:16,489 Epoch[52] Batch [530]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087179,	
2017-06-27 23:56:21,757 Epoch[52] Batch [540]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-27 23:56:27,076 Epoch[52] Batch [550]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087243,	
2017-06-27 23:56:32,355 Epoch[52] Batch [560]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087212,	
2017-06-27 23:56:37,607 Epoch[52] Batch [570]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087296,	
2017-06-27 23:56:42,870 Epoch[52] Batch [580]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087362,	
2017-06-27 23:56:48,176 Epoch[52] Batch [590]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-27 23:56:53,467 Epoch[52] Batch [600]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087152,	
2017-06-27 23:56:58,748 Epoch[52] Batch [610]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087072,	
2017-06-27 23:57:04,040 Epoch[52] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087196,	
2017-06-27 23:57:09,318 Epoch[52] Batch [630]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087271,	
2017-06-27 23:57:14,618 Epoch[52] Batch [640]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087393,	
2017-06-27 23:57:19,905 Epoch[52] Batch [650]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087410,	
2017-06-27 23:57:25,219 Epoch[52] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-27 23:57:30,532 Epoch[52] Batch [670]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087454,	
2017-06-27 23:57:35,834 Epoch[52] Batch [680]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087442,	
2017-06-27 23:57:41,117 Epoch[52] Batch [690]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087314,	
2017-06-27 23:57:46,439 Epoch[52] Batch [700]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087271,	
2017-06-27 23:57:51,732 Epoch[52] Batch [710]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087295,	
2017-06-27 23:57:56,989 Epoch[52] Batch [720]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087339,	
2017-06-27 23:58:02,275 Epoch[52] Batch [730]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087409,	
2017-06-27 23:58:07,551 Epoch[52] Batch [740]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087382,	
2017-06-27 23:58:12,847 Epoch[52] Batch [750]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087328,	
2017-06-27 23:58:18,150 Epoch[52] Batch [760]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-27 23:58:23,456 Epoch[52] Batch [770]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087349,	
2017-06-27 23:58:28,726 Epoch[52] Batch [780]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-27 23:58:34,044 Epoch[52] Batch [790]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-27 23:58:39,269 Epoch[52] Batch [800]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087491,	
2017-06-27 23:58:44,562 Epoch[52] Batch [810]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-27 23:58:49,846 Epoch[52] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087573,	
2017-06-27 23:58:55,175 Epoch[52] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-27 23:59:00,510 Epoch[52] Batch [840]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087633,	
2017-06-27 23:59:05,861 Epoch[52] Batch [850]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087696,	
2017-06-27 23:59:11,149 Epoch[52] Batch [860]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087693,	
2017-06-27 23:59:16,467 Epoch[52] Batch [870]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087603,	
2017-06-27 23:59:21,771 Epoch[52] Batch [880]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087575,	
2017-06-27 23:59:27,115 Epoch[52] Batch [890]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087679,	
2017-06-27 23:59:32,383 Epoch[52] Batch [900]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087656,	
2017-06-27 23:59:37,705 Epoch[52] Batch [910]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-27 23:59:42,995 Epoch[52] Batch [920]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087608,	
2017-06-27 23:59:48,330 Epoch[52] Batch [930]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087617,	
2017-06-27 23:59:53,632 Epoch[52] Batch [940]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087633,	
2017-06-27 23:59:58,945 Epoch[52] Batch [950]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087612,	
2017-06-28 00:00:04,217 Epoch[52] Batch [960]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087621,	
2017-06-28 00:00:09,543 Epoch[52] Batch [970]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-28 00:00:14,864 Epoch[52] Batch [980]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087783,	
2017-06-28 00:00:20,183 Epoch[52] Batch [990]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087779,	
2017-06-28 00:00:25,462 Epoch[52] Batch [1000]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087751,	
2017-06-28 00:00:30,798 Epoch[52] Batch [1010]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087661,	
2017-06-28 00:00:36,104 Epoch[52] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087637,	
2017-06-28 00:00:41,366 Epoch[52] Batch [1030]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087628,	
2017-06-28 00:00:46,744 Epoch[52] Batch [1040]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-28 00:00:52,033 Epoch[52] Batch [1050]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087676,	
2017-06-28 00:00:57,333 Epoch[52] Batch [1060]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-28 00:01:02,643 Epoch[52] Batch [1070]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087715,	
2017-06-28 00:01:07,946 Epoch[52] Batch [1080]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087675,	
2017-06-28 00:01:13,219 Epoch[52] Batch [1090]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-28 00:01:18,546 Epoch[52] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087707,	
2017-06-28 00:01:23,847 Epoch[52] Batch [1110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087652,	
2017-06-28 00:01:29,107 Epoch[52] Batch [1120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087631,	
2017-06-28 00:01:34,473 Epoch[52] Batch [1130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-28 00:01:39,739 Epoch[52] Batch [1140]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087566,	
2017-06-28 00:01:45,035 Epoch[52] Batch [1150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087614,	
2017-06-28 00:01:50,330 Epoch[52] Batch [1160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087608,	
2017-06-28 00:01:55,645 Epoch[52] Batch [1170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-28 00:02:00,911 Epoch[52] Batch [1180]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087616,	
2017-06-28 00:02:06,233 Epoch[52] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087601,	
2017-06-28 00:02:11,547 Epoch[52] Batch [1200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087569,	
2017-06-28 00:02:16,829 Epoch[52] Batch [1210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087527,	
2017-06-28 00:02:22,141 Epoch[52] Batch [1220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087490,	
2017-06-28 00:02:27,402 Epoch[52] Batch [1230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087459,	
2017-06-28 00:02:32,766 Epoch[52] Batch [1240]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087380,	
2017-06-28 00:02:37,652 Epoch[52] Batch [1250]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.087446,	
2017-06-28 00:02:42,379 Epoch[52] Batch [1260]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087405,	
2017-06-28 00:02:47,671 Epoch[52] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087392,	
2017-06-28 00:02:52,952 Epoch[52] Batch [1280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087398,	
2017-06-28 00:02:58,244 Epoch[52] Batch [1290]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087426,	
2017-06-28 00:03:03,546 Epoch[52] Batch [1300]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087377,	
2017-06-28 00:03:08,767 Epoch[52] Batch [1310]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087338,	
2017-06-28 00:03:14,106 Epoch[52] Batch [1320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087310,	
2017-06-28 00:03:19,393 Epoch[52] Batch [1330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087307,	
2017-06-28 00:03:24,667 Epoch[52] Batch [1340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-28 00:03:29,943 Epoch[52] Batch [1350]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087352,	
2017-06-28 00:03:35,226 Epoch[52] Batch [1360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087330,	
2017-06-28 00:03:40,549 Epoch[52] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087307,	
2017-06-28 00:03:45,828 Epoch[52] Batch [1380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087343,	
2017-06-28 00:03:51,115 Epoch[52] Batch [1390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-28 00:03:56,361 Epoch[52] Batch [1400]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087245,	
2017-06-28 00:04:01,652 Epoch[52] Batch [1410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087302,	
2017-06-28 00:04:06,933 Epoch[52] Batch [1420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087386,	
2017-06-28 00:04:12,255 Epoch[52] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087386,	
2017-06-28 00:04:17,514 Epoch[52] Batch [1440]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087374,	
2017-06-28 00:04:22,804 Epoch[52] Batch [1450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-28 00:04:28,089 Epoch[52] Batch [1460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087418,	
2017-06-28 00:04:33,388 Epoch[52] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087421,	
2017-06-28 00:04:38,683 Epoch[52] Batch [1480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087394,	
2017-06-28 00:04:41,855 Epoch[52] Train-FCNLogLoss=0.087371
2017-06-28 00:04:41,856 Epoch[52] Time cost=786.619
2017-06-28 00:04:42,562 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0053.params"
2017-06-28 00:04:44,284 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6-0053.states"
2017-06-28 00:04:44,345 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate6x6'}

2017-06-28 00:05:00,196 testing 4/500 data 0.6753s net 0.3937s post 0.0063s
2017-06-28 00:05:00,882 testing 8/500 data 0.5336s net 0.3407s post 0.0063s
2017-06-28 00:05:01,685 testing 12/500 data 0.5102s net 0.3381s post 0.0065s
2017-06-28 00:05:02,533 testing 16/500 data 0.4988s net 0.3469s post 0.0073s
2017-06-28 00:05:03,331 testing 20/500 data 0.4790s net 0.3559s post 0.0071s
2017-06-28 00:05:03,983 testing 24/500 data 0.4575s net 0.3451s post 0.0078s
2017-06-28 00:05:04,769 testing 28/500 data 0.4575s net 0.3418s post 0.0075s
2017-06-28 00:05:05,544 testing 32/500 data 0.4492s net 0.3465s post 0.0072s
2017-06-28 00:05:06,264 testing 36/500 data 0.4470s net 0.3395s post 0.0071s
2017-06-28 00:05:07,071 testing 40/500 data 0.4497s net 0.3382s post 0.0071s
2017-06-28 00:05:07,814 testing 44/500 data 0.4453s net 0.3379s post 0.0071s
2017-06-28 00:05:08,634 testing 48/500 data 0.4483s net 0.3373s post 0.0071s
2017-06-28 00:05:09,370 testing 52/500 data 0.4424s net 0.3387s post 0.0073s
2017-06-28 00:05:10,101 testing 56/500 data 0.4420s net 0.3350s post 0.0074s
2017-06-28 00:05:10,834 testing 60/500 data 0.4392s net 0.3344s post 0.0073s
2017-06-28 00:05:11,629 testing 64/500 data 0.4375s net 0.3370s post 0.0073s
2017-06-28 00:05:12,280 testing 68/500 data 0.4329s net 0.3340s post 0.0072s
2017-06-28 00:05:13,035 testing 72/500 data 0.4320s net 0.3338s post 0.0072s
2017-06-28 00:05:13,675 testing 76/500 data 0.4276s net 0.3312s post 0.0072s
2017-06-28 00:05:14,454 testing 80/500 data 0.4284s net 0.3311s post 0.0072s
2017-06-28 00:05:15,308 testing 84/500 data 0.4350s net 0.3287s post 0.0071s
2017-06-28 00:05:16,120 testing 88/500 data 0.4373s net 0.3279s post 0.0074s
2017-06-28 00:05:16,862 testing 92/500 data 0.4358s net 0.3282s post 0.0073s
2017-06-28 00:05:17,558 testing 96/500 data 0.4328s net 0.3266s post 0.0089s
2017-06-28 00:05:18,275 testing 100/500 data 0.4307s net 0.3266s post 0.0089s
2017-06-28 00:05:19,015 testing 104/500 data 0.4270s net 0.3291s post 0.0090s
2017-06-28 00:05:19,714 testing 108/500 data 0.4253s net 0.3284s post 0.0090s
2017-06-28 00:05:20,450 testing 112/500 data 0.4260s net 0.3269s post 0.0089s
2017-06-28 00:05:21,197 testing 116/500 data 0.4247s net 0.3277s post 0.0089s
2017-06-28 00:05:22,020 testing 120/500 data 0.4254s net 0.3291s post 0.0088s
2017-06-28 00:05:22,672 testing 124/500 data 0.4232s net 0.3278s post 0.0087s
2017-06-28 00:05:23,419 testing 128/500 data 0.4227s net 0.3279s post 0.0087s
2017-06-28 00:05:24,213 testing 132/500 data 0.4234s net 0.3282s post 0.0088s
2017-06-28 00:05:25,012 testing 136/500 data 0.4233s net 0.3294s post 0.0087s
2017-06-28 00:05:25,824 testing 140/500 data 0.4232s net 0.3310s post 0.0087s
2017-06-28 00:05:26,482 testing 144/500 data 0.4216s net 0.3298s post 0.0086s
2017-06-28 00:05:27,261 testing 148/500 data 0.4222s net 0.3296s post 0.0087s
2017-06-28 00:05:28,054 testing 152/500 data 0.4234s net 0.3293s post 0.0087s
2017-06-28 00:05:28,854 testing 156/500 data 0.4228s net 0.3310s post 0.0086s
2017-06-28 00:05:29,493 testing 160/500 data 0.4204s net 0.3303s post 0.0087s
2017-06-28 00:05:30,244 testing 164/500 data 0.4203s net 0.3302s post 0.0086s
2017-06-28 00:05:31,009 testing 168/500 data 0.4201s net 0.3305s post 0.0086s
2017-06-28 00:05:31,662 testing 172/500 data 0.4187s net 0.3296s post 0.0085s
2017-06-28 00:05:32,465 testing 176/500 data 0.4201s net 0.3292s post 0.0085s
2017-06-28 00:05:33,199 testing 180/500 data 0.4194s net 0.3295s post 0.0084s
2017-06-28 00:05:33,804 testing 184/500 data 0.4172s net 0.3284s post 0.0084s
2017-06-28 00:05:34,562 testing 188/500 data 0.4175s net 0.3282s post 0.0083s
2017-06-28 00:05:35,266 testing 192/500 data 0.4169s net 0.3278s post 0.0083s
2017-06-28 00:05:36,010 testing 196/500 data 0.4167s net 0.3278s post 0.0083s
2017-06-28 00:05:36,752 testing 200/500 data 0.4159s net 0.3284s post 0.0083s
2017-06-28 00:05:37,545 testing 204/500 data 0.4154s net 0.3298s post 0.0082s
2017-06-28 00:05:38,181 testing 208/500 data 0.4134s net 0.3296s post 0.0082s
2017-06-28 00:05:38,981 testing 212/500 data 0.4144s net 0.3295s post 0.0082s
2017-06-28 00:05:39,759 testing 216/500 data 0.4151s net 0.3293s post 0.0081s
2017-06-28 00:05:40,539 testing 220/500 data 0.4147s net 0.3303s post 0.0081s
2017-06-28 00:05:41,296 testing 224/500 data 0.4152s net 0.3299s post 0.0081s
2017-06-28 00:05:42,036 testing 228/500 data 0.4151s net 0.3298s post 0.0081s
2017-06-28 00:05:42,801 testing 232/500 data 0.4144s net 0.3307s post 0.0080s
2017-06-28 00:05:43,451 testing 236/500 data 0.4133s net 0.3300s post 0.0080s
2017-06-28 00:05:44,260 testing 240/500 data 0.4144s net 0.3299s post 0.0080s
2017-06-28 00:05:45,006 testing 244/500 data 0.4145s net 0.3297s post 0.0080s
2017-06-28 00:05:45,819 testing 248/500 data 0.4145s net 0.3307s post 0.0080s
2017-06-28 00:05:46,447 testing 252/500 data 0.4128s net 0.3305s post 0.0079s
2017-06-28 00:05:47,192 testing 256/500 data 0.4125s net 0.3307s post 0.0079s
2017-06-28 00:05:47,828 testing 260/500 data 0.4114s net 0.3301s post 0.0079s
2017-06-28 00:05:48,575 testing 264/500 data 0.4112s net 0.3302s post 0.0079s
2017-06-28 00:05:49,355 testing 268/500 data 0.4108s net 0.3311s post 0.0079s
2017-06-28 00:05:49,987 testing 272/500 data 0.4095s net 0.3306s post 0.0079s
2017-06-28 00:05:50,712 testing 276/500 data 0.4088s net 0.3309s post 0.0080s
2017-06-28 00:05:51,405 testing 280/500 data 0.4077s net 0.3312s post 0.0079s
2017-06-28 00:05:52,064 testing 284/500 data 0.4066s net 0.3312s post 0.0079s
2017-06-28 00:05:52,759 testing 288/500 data 0.4055s net 0.3316s post 0.0079s
2017-06-28 00:05:53,424 testing 292/500 data 0.4045s net 0.3315s post 0.0079s
2017-06-28 00:05:54,201 testing 296/500 data 0.4050s net 0.3314s post 0.0079s
2017-06-28 00:05:54,954 testing 300/500 data 0.4047s net 0.3319s post 0.0079s
2017-06-28 00:05:55,565 testing 304/500 data 0.4033s net 0.3315s post 0.0079s
2017-06-28 00:05:56,303 testing 308/500 data 0.4033s net 0.3314s post 0.0079s
2017-06-28 00:05:57,059 testing 312/500 data 0.4027s net 0.3322s post 0.0079s
2017-06-28 00:05:57,676 testing 316/500 data 0.4014s net 0.3319s post 0.0079s
2017-06-28 00:05:58,389 testing 320/500 data 0.4008s net 0.3322s post 0.0079s
2017-06-28 00:05:59,078 testing 324/500 data 0.4001s net 0.3322s post 0.0078s
2017-06-28 00:05:59,805 testing 328/500 data 0.4001s net 0.3321s post 0.0078s
2017-06-28 00:06:00,542 testing 332/500 data 0.3997s net 0.3325s post 0.0078s
2017-06-28 00:06:01,206 testing 336/500 data 0.3994s net 0.3320s post 0.0078s
2017-06-28 00:06:01,946 testing 340/500 data 0.3994s net 0.3319s post 0.0078s
2017-06-28 00:06:02,722 testing 344/500 data 0.3998s net 0.3320s post 0.0078s
2017-06-28 00:06:03,534 testing 348/500 data 0.4005s net 0.3321s post 0.0077s
2017-06-28 00:06:04,184 testing 352/500 data 0.3999s net 0.3317s post 0.0077s
2017-06-28 00:06:04,967 testing 356/500 data 0.4005s net 0.3316s post 0.0077s
2017-06-28 00:06:05,741 testing 360/500 data 0.4006s net 0.3318s post 0.0078s
2017-06-28 00:06:06,540 testing 364/500 data 0.4006s net 0.3325s post 0.0078s
2017-06-28 00:06:07,150 testing 368/500 data 0.3993s net 0.3324s post 0.0078s
2017-06-28 00:06:07,912 testing 372/500 data 0.3996s net 0.3323s post 0.0077s
2017-06-28 00:06:08,668 testing 376/500 data 0.3991s net 0.3330s post 0.0077s
2017-06-28 00:06:09,476 testing 380/500 data 0.3992s net 0.3337s post 0.0077s
2017-06-28 00:06:10,330 testing 384/500 data 0.3998s net 0.3343s post 0.0077s
2017-06-28 00:06:10,973 testing 388/500 data 0.3992s net 0.3339s post 0.0077s
2017-06-28 00:06:11,696 testing 392/500 data 0.3990s net 0.3338s post 0.0077s
2017-06-28 00:06:12,460 testing 396/500 data 0.3987s net 0.3344s post 0.0077s
2017-06-28 00:06:13,146 testing 400/500 data 0.3985s net 0.3340s post 0.0077s
2017-06-28 00:06:13,967 testing 404/500 data 0.3995s net 0.3338s post 0.0077s
2017-06-28 00:06:14,684 testing 408/500 data 0.3992s net 0.3339s post 0.0077s
2017-06-28 00:06:15,472 testing 412/500 data 0.3991s net 0.3344s post 0.0077s
2017-06-28 00:06:16,121 testing 416/500 data 0.3987s net 0.3340s post 0.0077s
2017-06-28 00:06:16,863 testing 420/500 data 0.3988s net 0.3339s post 0.0077s
2017-06-28 00:06:17,585 testing 424/500 data 0.3981s net 0.3345s post 0.0077s
2017-06-28 00:06:18,223 testing 428/500 data 0.3973s net 0.3344s post 0.0076s
2017-06-28 00:06:18,944 testing 432/500 data 0.3970s net 0.3345s post 0.0076s
2017-06-28 00:06:19,573 testing 436/500 data 0.3964s net 0.3341s post 0.0076s
2017-06-28 00:06:20,344 testing 440/500 data 0.3968s net 0.3340s post 0.0076s
2017-06-28 00:06:21,114 testing 444/500 data 0.3965s net 0.3346s post 0.0076s
2017-06-28 00:06:21,738 testing 448/500 data 0.3956s net 0.3344s post 0.0076s
2017-06-28 00:06:22,472 testing 452/500 data 0.3956s net 0.3344s post 0.0076s
2017-06-28 00:06:23,187 testing 456/500 data 0.3950s net 0.3348s post 0.0076s
2017-06-28 00:06:23,846 testing 460/500 data 0.3944s net 0.3347s post 0.0076s
2017-06-28 00:06:24,613 testing 464/500 data 0.3945s net 0.3348s post 0.0076s
2017-06-28 00:06:25,403 testing 468/500 data 0.3944s net 0.3354s post 0.0077s
2017-06-28 00:06:26,026 testing 472/500 data 0.3936s net 0.3352s post 0.0076s
2017-06-28 00:06:26,753 testing 476/500 data 0.3931s net 0.3357s post 0.0076s
2017-06-28 00:06:27,398 testing 480/500 data 0.3927s net 0.3353s post 0.0076s
2017-06-28 00:06:28,141 testing 484/500 data 0.3928s net 0.3353s post 0.0076s
2017-06-28 00:06:28,916 testing 488/500 data 0.3926s net 0.3358s post 0.0076s
2017-06-28 00:06:29,561 testing 492/500 data 0.3923s net 0.3354s post 0.0076s
2017-06-28 00:06:30,350 testing 496/500 data 0.3927s net 0.3354s post 0.0076s
2017-06-28 00:06:31,063 testing 500/500 data 0.3923s net 0.3356s post 0.0076s
2017-06-28 00:08:30,258 evaluate segmentation: 

2017-06-28 00:08:30,259 IU_array:

2017-06-28 00:08:30,259 0.97825
2017-06-28 00:08:30,259 0.82730
2017-06-28 00:08:30,259 0.91295
2017-06-28 00:08:30,259 0.51015
2017-06-28 00:08:30,259 0.53245
2017-06-28 00:08:30,259 0.53813
2017-06-28 00:08:30,259 0.63403
2017-06-28 00:08:30,259 0.72392
2017-06-28 00:08:30,259 0.91351
2017-06-28 00:08:30,259 0.61283
2017-06-28 00:08:30,259 0.93698
2017-06-28 00:08:30,259 0.77736
2017-06-28 00:08:30,259 0.57230
2017-06-28 00:08:30,259 0.93724
2017-06-28 00:08:30,259 0.63874
2017-06-28 00:08:30,259 0.81106
2017-06-28 00:08:30,260 0.65746
2017-06-28 00:08:30,260 0.59448
2017-06-28 00:08:30,260 0.73839
2017-06-28 00:08:30,260 meanIU:0.72882

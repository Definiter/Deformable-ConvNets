2017-06-26 10:26:42,083 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate6x6',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate6x6'}

2017-06-26 10:27:31,656 Epoch[0] Batch [10]	Speed: 9.20 samples/sec	Train-FCNLogLoss=2.878527,	
2017-06-26 10:27:36,107 Epoch[0] Batch [20]	Speed: 8.99 samples/sec	Train-FCNLogLoss=2.731075,	
2017-06-26 10:27:40,524 Epoch[0] Batch [30]	Speed: 9.06 samples/sec	Train-FCNLogLoss=2.508042,	
2017-06-26 10:27:44,799 Epoch[0] Batch [40]	Speed: 9.36 samples/sec	Train-FCNLogLoss=2.287144,	
2017-06-26 10:27:49,020 Epoch[0] Batch [50]	Speed: 9.48 samples/sec	Train-FCNLogLoss=2.069331,	
2017-06-26 10:27:53,320 Epoch[0] Batch [60]	Speed: 9.30 samples/sec	Train-FCNLogLoss=1.917257,	
2017-06-26 10:27:57,852 Epoch[0] Batch [70]	Speed: 8.83 samples/sec	Train-FCNLogLoss=1.776780,	
2017-06-26 10:28:02,434 Epoch[0] Batch [80]	Speed: 8.73 samples/sec	Train-FCNLogLoss=1.660238,	
2017-06-26 10:28:07,053 Epoch[0] Batch [90]	Speed: 8.66 samples/sec	Train-FCNLogLoss=1.548841,	
2017-06-26 10:28:11,161 Epoch[0] Batch [100]	Speed: 9.74 samples/sec	Train-FCNLogLoss=1.461579,	
2017-06-26 10:28:15,380 Epoch[0] Batch [110]	Speed: 9.48 samples/sec	Train-FCNLogLoss=1.383838,	
2017-06-26 10:28:19,509 Epoch[0] Batch [120]	Speed: 9.69 samples/sec	Train-FCNLogLoss=1.329038,	
2017-06-26 10:28:23,969 Epoch[0] Batch [130]	Speed: 8.97 samples/sec	Train-FCNLogLoss=1.273668,	
2017-06-26 10:28:28,625 Epoch[0] Batch [140]	Speed: 8.59 samples/sec	Train-FCNLogLoss=1.226004,	
2017-06-26 10:28:33,195 Epoch[0] Batch [150]	Speed: 8.75 samples/sec	Train-FCNLogLoss=1.181515,	
2017-06-26 10:28:37,769 Epoch[0] Batch [160]	Speed: 8.75 samples/sec	Train-FCNLogLoss=1.138237,	
2017-06-26 10:28:42,321 Epoch[0] Batch [170]	Speed: 8.79 samples/sec	Train-FCNLogLoss=1.100032,	
2017-06-26 10:28:46,853 Epoch[0] Batch [180]	Speed: 8.83 samples/sec	Train-FCNLogLoss=1.067738,	
2017-06-26 10:28:51,321 Epoch[0] Batch [190]	Speed: 8.95 samples/sec	Train-FCNLogLoss=1.040159,	
2017-06-26 10:28:55,834 Epoch[0] Batch [200]	Speed: 8.87 samples/sec	Train-FCNLogLoss=1.011561,	
2017-06-26 10:29:00,257 Epoch[0] Batch [210]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.984962,	
2017-06-26 10:29:04,901 Epoch[0] Batch [220]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.963895,	
2017-06-26 10:29:09,476 Epoch[0] Batch [230]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.942285,	
2017-06-26 10:29:13,843 Epoch[0] Batch [240]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.923126,	
2017-06-26 10:29:18,319 Epoch[0] Batch [250]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.904267,	
2017-06-26 10:29:22,551 Epoch[0] Batch [260]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.885111,	
2017-06-26 10:29:26,721 Epoch[0] Batch [270]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.873374,	
2017-06-26 10:29:30,855 Epoch[0] Batch [280]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.856787,	
2017-06-26 10:29:34,915 Epoch[0] Batch [290]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.841537,	
2017-06-26 10:29:39,124 Epoch[0] Batch [300]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.831803,	
2017-06-26 10:29:43,217 Epoch[0] Batch [310]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.821483,	
2017-06-26 10:29:47,327 Epoch[0] Batch [320]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.809312,	
2017-06-26 10:29:51,446 Epoch[0] Batch [330]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.798759,	
2017-06-26 10:29:55,610 Epoch[0] Batch [340]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.790707,	
2017-06-26 10:29:59,890 Epoch[0] Batch [350]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.780694,	
2017-06-26 10:30:04,069 Epoch[0] Batch [360]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.771000,	
2017-06-26 10:30:08,304 Epoch[0] Batch [370]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.759915,	
2017-06-26 10:30:12,568 Epoch[0] Batch [380]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.750113,	
2017-06-26 10:30:17,788 Epoch[0] Batch [390]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.741590,	
2017-06-26 10:30:23,204 Epoch[0] Batch [400]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.734281,	
2017-06-26 10:30:29,440 Epoch[0] Batch [410]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.725825,	
2017-06-26 10:30:35,896 Epoch[0] Batch [420]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.716838,	
2017-06-26 10:30:43,402 Epoch[0] Batch [430]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.709816,	
2017-06-26 10:30:51,960 Epoch[0] Batch [440]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.702202,	
2017-06-26 10:31:01,247 Epoch[0] Batch [450]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.695549,	
2017-06-26 10:31:09,762 Epoch[0] Batch [460]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.688445,	
2017-06-26 10:31:16,730 Epoch[0] Batch [470]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.682303,	
2017-06-26 10:31:24,275 Epoch[0] Batch [480]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.676103,	
2017-06-26 10:31:33,221 Epoch[0] Batch [490]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.670175,	
2017-06-26 10:31:43,063 Epoch[0] Batch [500]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.664531,	
2017-06-26 10:31:53,211 Epoch[0] Batch [510]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.658551,	
2017-06-26 10:32:00,521 Epoch[0] Batch [520]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.651927,	
2017-06-26 10:32:07,239 Epoch[0] Batch [530]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.648914,	
2017-06-26 10:32:16,608 Epoch[0] Batch [540]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.644159,	
2017-06-26 10:32:24,048 Epoch[0] Batch [550]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.639255,	
2017-06-26 10:32:30,549 Epoch[0] Batch [560]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.633902,	
2017-06-26 10:32:36,370 Epoch[0] Batch [570]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.628815,	
2017-06-26 10:32:41,598 Epoch[0] Batch [580]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.624260,	
2017-06-26 10:32:49,467 Epoch[0] Batch [590]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.619400,	
2017-06-26 10:32:55,124 Epoch[0] Batch [600]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.614932,	
2017-06-26 10:33:32,706 Epoch[0] Batch [610]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.610480,	
2017-06-26 10:33:47,425 Epoch[0] Batch [620]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.607397,	
2017-06-26 10:33:53,029 Epoch[0] Batch [630]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.603576,	
2017-06-26 10:33:58,346 Epoch[0] Batch [640]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.599920,	
2017-06-26 10:34:03,568 Epoch[0] Batch [650]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.596021,	
2017-06-26 10:34:08,726 Epoch[0] Batch [660]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.592323,	
2017-06-26 10:34:13,255 Epoch[0] Batch [670]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.589091,	
2017-06-26 10:34:18,239 Epoch[0] Batch [680]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.586054,	
2017-06-26 10:34:22,903 Epoch[0] Batch [690]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.582580,	
2017-06-26 10:34:27,925 Epoch[0] Batch [700]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.579922,	
2017-06-26 10:34:32,525 Epoch[0] Batch [710]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.576381,	
2017-06-26 10:34:37,667 Epoch[0] Batch [720]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.572750,	
2017-06-26 10:34:42,891 Epoch[0] Batch [730]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.569366,	
2017-06-26 10:34:47,853 Epoch[0] Batch [740]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.566393,	
2017-06-26 10:34:52,594 Epoch[0] Batch [750]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.563227,	
2017-06-26 10:34:57,390 Epoch[0] Batch [760]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.559928,	
2017-06-26 10:35:03,409 Epoch[0] Batch [770]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.557352,	
2017-06-26 10:35:09,416 Epoch[0] Batch [780]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.554160,	
2017-06-26 10:35:15,521 Epoch[0] Batch [790]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.551567,	
2017-06-26 10:35:22,097 Epoch[0] Batch [800]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.548402,	
2017-06-26 10:35:29,459 Epoch[0] Batch [810]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.545449,	
2017-06-26 10:35:37,368 Epoch[0] Batch [820]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.543082,	
2017-06-26 10:35:45,494 Epoch[0] Batch [830]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.540040,	
2017-06-26 10:35:54,619 Epoch[0] Batch [840]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.537288,	
2017-06-26 10:36:03,176 Epoch[0] Batch [850]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.534718,	
2017-06-26 10:36:13,235 Epoch[0] Batch [860]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.532012,	
2017-06-26 10:36:23,195 Epoch[0] Batch [870]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.529763,	
2017-06-26 10:36:33,096 Epoch[0] Batch [880]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.527249,	
2017-06-26 10:36:43,026 Epoch[0] Batch [890]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.524981,	
2017-06-26 10:36:52,520 Epoch[0] Batch [900]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.523126,	
2017-06-26 10:37:01,733 Epoch[0] Batch [910]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.521746,	
2017-06-26 10:37:10,418 Epoch[0] Batch [920]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.519653,	
2017-06-26 10:37:17,209 Epoch[0] Batch [930]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.517549,	
2017-06-26 10:37:28,809 Epoch[0] Batch [940]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.515213,	
2017-06-26 10:37:35,293 Epoch[0] Batch [950]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.513356,	
2017-06-26 10:37:41,715 Epoch[0] Batch [960]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.511824,	
2017-06-26 10:37:48,408 Epoch[0] Batch [970]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.509503,	
2017-06-26 10:37:54,409 Epoch[0] Batch [980]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.507557,	
2017-06-26 10:38:00,246 Epoch[0] Batch [990]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.505561,	
2017-06-26 10:38:05,657 Epoch[0] Batch [1000]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.503409,	
2017-06-26 10:38:11,489 Epoch[0] Batch [1010]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.502360,	
2017-06-26 10:38:16,939 Epoch[0] Batch [1020]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.502289,	
2017-06-26 10:38:22,138 Epoch[0] Batch [1030]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.501423,	
2017-06-26 10:38:28,141 Epoch[0] Batch [1040]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.500280,	
2017-06-26 10:38:33,876 Epoch[0] Batch [1050]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.500375,	
2017-06-26 10:38:39,480 Epoch[0] Batch [1060]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.501435,	
2017-06-26 10:38:45,512 Epoch[0] Batch [1070]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.500573,	
2017-06-26 10:38:51,133 Epoch[0] Batch [1080]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.499936,	
2017-06-26 10:39:09,924 Epoch[0] Batch [1090]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.498720,	
2017-06-26 10:39:15,711 Epoch[0] Batch [1100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.499032,	
2017-06-26 10:39:21,721 Epoch[0] Batch [1110]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.498938,	
2017-06-26 10:39:27,237 Epoch[0] Batch [1120]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.498386,	
2017-06-26 10:39:34,713 Epoch[0] Batch [1130]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.497495,	
2017-06-26 10:39:44,042 Epoch[0] Batch [1140]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.496538,	
2017-06-26 10:39:52,838 Epoch[0] Batch [1150]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.495055,	
2017-06-26 10:40:01,404 Epoch[0] Batch [1160]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.494221,	
2017-06-26 10:40:09,606 Epoch[0] Batch [1170]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.493419,	
2017-06-26 10:40:17,382 Epoch[0] Batch [1180]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.492998,	
2017-06-26 10:40:24,243 Epoch[0] Batch [1190]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.492160,	
2017-06-26 10:40:32,838 Epoch[0] Batch [1200]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.491173,	
2017-06-26 10:40:42,507 Epoch[0] Batch [1210]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.490756,	
2017-06-26 10:40:52,251 Epoch[0] Batch [1220]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.489761,	

2017-07-18 14:45:58,025 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-18 14:48:47,666 Epoch[0] Batch [10]	Speed: 3.83 samples/sec	Train-FCNLogLoss=2.887816,	
2017-07-18 14:48:58,211 Epoch[0] Batch [20]	Speed: 3.79 samples/sec	Train-FCNLogLoss=2.742349,	
2017-07-18 14:49:08,615 Epoch[0] Batch [30]	Speed: 3.84 samples/sec	Train-FCNLogLoss=2.506257,	
2017-07-18 14:49:18,888 Epoch[0] Batch [40]	Speed: 3.89 samples/sec	Train-FCNLogLoss=2.259488,	
2017-07-18 14:49:29,241 Epoch[0] Batch [50]	Speed: 3.86 samples/sec	Train-FCNLogLoss=2.052647,	
2017-07-18 14:49:39,535 Epoch[0] Batch [60]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.866134,	
2017-07-18 14:49:49,755 Epoch[0] Batch [70]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.754616,	
2017-07-18 14:50:00,016 Epoch[0] Batch [80]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.641358,	
2017-07-18 14:50:10,407 Epoch[0] Batch [90]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.555172,	
2017-07-18 14:50:20,559 Epoch[0] Batch [100]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.468123,	
2017-07-18 14:50:30,620 Epoch[0] Batch [110]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.392386,	
2017-07-18 14:50:41,025 Epoch[0] Batch [120]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.332114,	
2017-07-18 14:50:51,262 Epoch[0] Batch [130]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.281606,	
2017-07-18 14:51:01,450 Epoch[0] Batch [140]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.229475,	
2017-07-18 14:51:11,820 Epoch[0] Batch [150]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.192344,	
2017-07-18 14:51:22,048 Epoch[0] Batch [160]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.147516,	
2017-07-18 14:51:32,443 Epoch[0] Batch [170]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.105714,	
2017-07-18 14:51:42,916 Epoch[0] Batch [180]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.070056,	
2017-07-18 14:51:52,779 Epoch[0] Batch [190]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.038540,	
2017-07-18 14:52:02,847 Epoch[0] Batch [200]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.009418,	
2017-07-18 14:52:13,099 Epoch[0] Batch [210]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.984173,	
2017-07-18 14:52:23,326 Epoch[0] Batch [220]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.959558,	
2017-07-18 14:52:33,657 Epoch[0] Batch [230]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.941865,	
2017-07-18 14:52:43,595 Epoch[0] Batch [240]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.923188,	
2017-07-18 14:52:53,381 Epoch[0] Batch [250]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.907371,	
2017-07-18 14:53:03,220 Epoch[0] Batch [260]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.890992,	
2017-07-18 14:53:13,276 Epoch[0] Batch [270]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.874167,	
2017-07-18 14:53:22,985 Epoch[0] Batch [280]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.858162,	
2017-07-18 14:53:32,940 Epoch[0] Batch [290]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.843690,	
2017-07-18 14:53:43,133 Epoch[0] Batch [300]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.831057,	
2017-07-18 14:53:53,372 Epoch[0] Batch [310]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.815835,	
2017-07-18 14:54:03,169 Epoch[0] Batch [320]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.807046,	
2017-07-18 14:54:13,252 Epoch[0] Batch [330]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.796559,	
2017-07-18 14:54:22,816 Epoch[0] Batch [340]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.786435,	
2017-07-18 14:54:33,059 Epoch[0] Batch [350]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.778318,	
2017-07-18 14:54:42,876 Epoch[0] Batch [360]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.769307,	
2017-07-18 14:54:52,712 Epoch[0] Batch [370]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.758827,	
2017-07-18 14:55:02,465 Epoch[0] Batch [380]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.748857,	
2017-07-18 14:55:11,810 Epoch[0] Batch [390]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.738790,	
2017-07-18 14:55:21,242 Epoch[0] Batch [400]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.729317,	
2017-07-18 14:55:30,711 Epoch[0] Batch [410]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.722948,	
2017-07-18 14:55:40,405 Epoch[0] Batch [420]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.714836,	
2017-07-18 14:55:50,047 Epoch[0] Batch [430]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.708892,	
2017-07-18 14:55:59,374 Epoch[0] Batch [440]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.701881,	
2017-07-18 14:56:08,846 Epoch[0] Batch [450]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.694002,	
2017-07-18 14:56:18,196 Epoch[0] Batch [460]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.685884,	
2017-07-18 14:56:27,197 Epoch[0] Batch [470]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.678687,	
2017-07-18 14:56:35,800 Epoch[0] Batch [480]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.673201,	
2017-07-18 14:56:44,404 Epoch[0] Batch [490]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.666640,	
2017-07-18 14:56:53,330 Epoch[0] Batch [500]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.661682,	
2017-07-18 14:57:01,821 Epoch[0] Batch [510]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.656927,	
2017-07-18 14:57:10,210 Epoch[0] Batch [520]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.651632,	
2017-07-18 14:57:19,450 Epoch[0] Batch [530]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.645338,	
2017-07-18 14:57:28,436 Epoch[0] Batch [540]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.640221,	
2017-07-18 14:57:37,834 Epoch[0] Batch [550]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.635207,	
2017-07-18 14:57:47,448 Epoch[0] Batch [560]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.630418,	
2017-07-18 14:57:57,341 Epoch[0] Batch [570]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.626912,	
2017-07-18 14:58:06,662 Epoch[0] Batch [580]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.622349,	
2017-07-18 14:58:15,832 Epoch[0] Batch [590]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.617622,	
2017-07-18 14:58:24,829 Epoch[0] Batch [600]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.613142,	
2017-07-18 14:58:34,142 Epoch[0] Batch [610]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.610172,	
2017-07-18 14:58:43,008 Epoch[0] Batch [620]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.605738,	
2017-07-18 14:58:52,853 Epoch[0] Batch [630]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.603328,	
2017-07-18 14:59:02,310 Epoch[0] Batch [640]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.599622,	
2017-07-18 14:59:11,514 Epoch[0] Batch [650]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.596355,	
2017-07-18 14:59:21,079 Epoch[0] Batch [660]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.593383,	
2017-07-18 14:59:30,683 Epoch[0] Batch [670]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.590416,	
2017-07-18 14:59:40,058 Epoch[0] Batch [680]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.588051,	
2017-07-18 14:59:49,645 Epoch[0] Batch [690]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.584676,	
2017-07-18 14:59:59,301 Epoch[0] Batch [700]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.581108,	
2017-07-18 15:00:08,978 Epoch[0] Batch [710]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.577958,	
2017-07-18 15:00:18,544 Epoch[0] Batch [720]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.575100,	
2017-07-18 15:00:28,247 Epoch[0] Batch [730]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.572016,	
2017-07-18 15:00:38,011 Epoch[0] Batch [740]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.568838,	
2017-07-18 15:00:47,421 Epoch[0] Batch [750]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.565540,	
2017-07-18 15:00:57,029 Epoch[0] Batch [760]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.563037,	
2017-07-18 15:01:06,876 Epoch[0] Batch [770]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.560305,	
2017-07-18 15:01:16,564 Epoch[0] Batch [780]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.559749,	
2017-07-18 15:01:26,124 Epoch[0] Batch [790]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.556637,	
2017-07-18 15:01:35,514 Epoch[0] Batch [800]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.553699,	
2017-07-18 15:01:44,633 Epoch[0] Batch [810]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.550976,	
2017-07-18 15:01:53,793 Epoch[0] Batch [820]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.548169,	
2017-07-18 15:02:03,162 Epoch[0] Batch [830]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.545524,	
2017-07-18 15:02:12,162 Epoch[0] Batch [840]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.544039,	
2017-07-18 15:02:20,870 Epoch[0] Batch [850]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.541397,	
2017-07-18 15:02:29,993 Epoch[0] Batch [860]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.539152,	
2017-07-18 15:02:39,643 Epoch[0] Batch [870]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.537019,	
2017-07-18 15:02:49,307 Epoch[0] Batch [880]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.534915,	
2017-07-18 15:02:58,912 Epoch[0] Batch [890]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.532831,	
2017-07-18 15:03:08,950 Epoch[0] Batch [900]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.530636,	
2017-07-18 15:03:19,100 Epoch[0] Batch [910]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.528642,	
2017-07-18 15:03:28,719 Epoch[0] Batch [920]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.526528,	
2017-07-18 15:03:38,626 Epoch[0] Batch [930]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.524798,	
2017-07-18 15:03:48,257 Epoch[0] Batch [940]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.522068,	
2017-07-18 15:03:57,916 Epoch[0] Batch [950]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.519958,	
2017-07-18 15:04:07,889 Epoch[0] Batch [960]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.517940,	
2017-07-18 15:04:17,705 Epoch[0] Batch [970]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.515933,	
2017-07-18 15:04:27,306 Epoch[0] Batch [980]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.514164,	
2017-07-18 15:04:36,412 Epoch[0] Batch [990]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.512673,	
2017-07-18 15:04:45,744 Epoch[0] Batch [1000]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.511527,	
2017-07-18 15:04:54,826 Epoch[0] Batch [1010]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.510869,	
2017-07-18 15:05:03,536 Epoch[0] Batch [1020]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.510760,	
2017-07-18 15:05:12,699 Epoch[0] Batch [1030]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.511542,	
2017-07-18 15:05:22,161 Epoch[0] Batch [1040]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.512314,	
2017-07-18 15:05:31,843 Epoch[0] Batch [1050]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.512251,	
2017-07-18 15:05:41,034 Epoch[0] Batch [1060]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.512384,	
2017-07-18 15:05:50,483 Epoch[0] Batch [1070]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.511923,	
2017-07-18 15:05:59,614 Epoch[0] Batch [1080]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.511444,	
2017-07-18 15:06:08,358 Epoch[0] Batch [1090]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.510243,	
2017-07-18 15:06:17,394 Epoch[0] Batch [1100]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.509495,	
2017-07-18 15:06:26,353 Epoch[0] Batch [1110]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.508227,	
2017-07-18 15:06:35,379 Epoch[0] Batch [1120]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.507534,	
2017-07-18 15:06:44,075 Epoch[0] Batch [1130]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.505903,	
2017-07-18 15:06:52,836 Epoch[0] Batch [1140]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.504739,	
2017-07-18 15:07:01,155 Epoch[0] Batch [1150]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.503440,	
2017-07-18 15:07:10,079 Epoch[0] Batch [1160]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.502309,	
2017-07-18 15:07:18,252 Epoch[0] Batch [1170]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.501278,	
2017-07-18 15:07:26,609 Epoch[0] Batch [1180]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.500248,	
2017-07-18 15:07:34,773 Epoch[0] Batch [1190]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.498724,	
2017-07-18 15:07:43,255 Epoch[0] Batch [1200]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.497239,	
2017-07-18 15:07:51,850 Epoch[0] Batch [1210]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.495656,	
2017-07-18 15:08:01,003 Epoch[0] Batch [1220]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.494792,	
2017-07-18 15:08:09,702 Epoch[0] Batch [1230]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.494332,	
2017-07-18 15:08:17,847 Epoch[0] Batch [1240]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.493730,	
2017-07-18 15:08:26,449 Epoch[0] Batch [1250]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.493240,	
2017-07-18 15:08:35,251 Epoch[0] Batch [1260]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.493212,	
2017-07-18 15:08:43,613 Epoch[0] Batch [1270]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.492797,	
2017-07-18 15:08:52,536 Epoch[0] Batch [1280]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.491645,	
2017-07-18 15:09:00,961 Epoch[0] Batch [1290]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.490506,	
2017-07-18 15:09:09,186 Epoch[0] Batch [1300]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.488979,	
2017-07-18 15:09:17,720 Epoch[0] Batch [1310]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.487988,	
2017-07-18 15:09:26,134 Epoch[0] Batch [1320]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.486862,	
2017-07-18 15:09:34,449 Epoch[0] Batch [1330]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.485707,	
2017-07-18 15:09:42,673 Epoch[0] Batch [1340]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.484600,	
2017-07-18 15:09:51,130 Epoch[0] Batch [1350]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.483365,	
2017-07-18 15:09:59,882 Epoch[0] Batch [1360]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.482547,	
2017-07-18 15:10:08,371 Epoch[0] Batch [1370]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.481743,	
2017-07-18 15:10:17,017 Epoch[0] Batch [1380]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.481244,	
2017-07-18 15:10:26,080 Epoch[0] Batch [1390]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.481186,	
2017-07-18 15:10:34,893 Epoch[0] Batch [1400]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.480575,	
2017-07-18 15:10:44,060 Epoch[0] Batch [1410]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.479504,	
2017-07-18 15:10:52,695 Epoch[0] Batch [1420]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.478350,	
2017-07-18 15:11:01,102 Epoch[0] Batch [1430]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.477104,	
2017-07-18 15:11:10,084 Epoch[0] Batch [1440]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.476068,	
2017-07-18 15:11:19,326 Epoch[0] Batch [1450]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.474974,	
2017-07-18 15:11:28,862 Epoch[0] Batch [1460]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.473825,	
2017-07-18 15:11:38,308 Epoch[0] Batch [1470]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.472766,	
2017-07-18 15:11:48,050 Epoch[0] Batch [1480]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.471686,	
2017-07-18 15:11:54,021 Epoch[0] Train-FCNLogLoss=0.470886
2017-07-18 15:11:54,022 Epoch[0] Time cost=1406.369
2017-07-18 15:11:55,685 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-18 15:12:01,280 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-18 15:12:10,366 Epoch[1] Batch [10]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.324037,	
2017-07-18 15:12:17,929 Epoch[1] Batch [20]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.309235,	
2017-07-18 15:12:25,800 Epoch[1] Batch [30]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.322867,	
2017-07-18 15:12:33,603 Epoch[1] Batch [40]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.313794,	
2017-07-18 15:12:41,685 Epoch[1] Batch [50]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.306618,	
2017-07-18 15:12:49,780 Epoch[1] Batch [60]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.305651,	
2017-07-18 15:12:57,717 Epoch[1] Batch [70]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.306855,	
2017-07-18 15:13:06,220 Epoch[1] Batch [80]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.302613,	
2017-07-18 15:13:14,205 Epoch[1] Batch [90]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.297050,	
2017-07-18 15:13:22,242 Epoch[1] Batch [100]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.293325,	
2017-07-18 15:13:30,034 Epoch[1] Batch [110]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.293920,	
2017-07-18 15:13:37,905 Epoch[1] Batch [120]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.295335,	
2017-07-18 15:13:46,006 Epoch[1] Batch [130]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.297236,	
2017-07-18 15:13:53,932 Epoch[1] Batch [140]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.296151,	
2017-07-18 15:14:01,988 Epoch[1] Batch [150]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.298381,	
2017-07-18 15:14:09,703 Epoch[1] Batch [160]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.297907,	
2017-07-18 15:14:17,828 Epoch[1] Batch [170]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.294804,	
2017-07-18 15:14:25,562 Epoch[1] Batch [180]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.293103,	
2017-07-18 15:14:33,212 Epoch[1] Batch [190]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.289605,	
2017-07-18 15:14:41,367 Epoch[1] Batch [200]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.290546,	
2017-07-18 15:14:48,955 Epoch[1] Batch [210]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.293368,	

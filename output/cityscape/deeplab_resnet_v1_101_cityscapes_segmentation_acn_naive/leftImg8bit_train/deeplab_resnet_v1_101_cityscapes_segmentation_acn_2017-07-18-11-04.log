2017-07-18 11:04:20,784 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-18 11:07:15,098 Epoch[0] Batch [10]	Speed: 3.76 samples/sec	Train-FCNLogLoss=2.824473,	
2017-07-18 11:07:25,751 Epoch[0] Batch [20]	Speed: 3.75 samples/sec	Train-FCNLogLoss=2.513037,	
2017-07-18 11:07:36,481 Epoch[0] Batch [30]	Speed: 3.73 samples/sec	Train-FCNLogLoss=2.303386,	
2017-07-18 11:07:46,902 Epoch[0] Batch [40]	Speed: 3.84 samples/sec	Train-FCNLogLoss=2.182040,	
2017-07-18 11:07:57,695 Epoch[0] Batch [50]	Speed: 3.71 samples/sec	Train-FCNLogLoss=2.086761,	
2017-07-18 11:08:08,318 Epoch[0] Batch [60]	Speed: 3.77 samples/sec	Train-FCNLogLoss=2.011328,	
2017-07-18 11:08:19,210 Epoch[0] Batch [70]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.958967,	
2017-07-18 11:08:29,688 Epoch[0] Batch [80]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.893851,	
2017-07-18 11:08:40,338 Epoch[0] Batch [90]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.833253,	
2017-07-18 11:08:50,902 Epoch[0] Batch [100]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.788782,	
2017-07-18 11:09:01,202 Epoch[0] Batch [110]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.753937,	
2017-07-18 11:09:11,543 Epoch[0] Batch [120]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.717286,	
2017-07-18 11:09:21,913 Epoch[0] Batch [130]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.692056,	
2017-07-18 11:09:32,175 Epoch[0] Batch [140]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.660402,	
2017-07-18 11:09:42,455 Epoch[0] Batch [150]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.635985,	
2017-07-18 11:09:52,790 Epoch[0] Batch [160]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.617347,	
2017-07-18 11:10:03,494 Epoch[0] Batch [170]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.598188,	
2017-07-18 11:10:13,920 Epoch[0] Batch [180]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.582885,	
2017-07-18 11:10:24,575 Epoch[0] Batch [190]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.567018,	
2017-07-18 11:10:35,169 Epoch[0] Batch [200]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.557761,	
2017-07-18 11:10:45,832 Epoch[0] Batch [210]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.546894,	
2017-07-18 11:10:56,162 Epoch[0] Batch [220]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.533069,	
2017-07-18 11:11:06,763 Epoch[0] Batch [230]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.521367,	
2017-07-18 11:11:17,149 Epoch[0] Batch [240]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.513639,	
2017-07-18 11:11:27,844 Epoch[0] Batch [250]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.507306,	
2017-07-18 11:11:38,425 Epoch[0] Batch [260]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.498142,	
2017-07-18 11:11:48,992 Epoch[0] Batch [270]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.486906,	
2017-07-18 11:11:59,449 Epoch[0] Batch [280]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.482807,	
2017-07-18 11:12:09,916 Epoch[0] Batch [290]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.477226,	
2017-07-18 11:12:20,481 Epoch[0] Batch [300]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.467736,	
2017-07-18 11:12:30,748 Epoch[0] Batch [310]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.459717,	
2017-07-18 11:12:41,174 Epoch[0] Batch [320]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.455814,	
2017-07-18 11:12:51,835 Epoch[0] Batch [330]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.449072,	
2017-07-18 11:13:02,309 Epoch[0] Batch [340]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.444930,	
2017-07-18 11:13:12,672 Epoch[0] Batch [350]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.443342,	
2017-07-18 11:13:22,953 Epoch[0] Batch [360]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.441029,	
2017-07-18 11:13:33,469 Epoch[0] Batch [370]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.439350,	
2017-07-18 11:13:44,112 Epoch[0] Batch [380]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.434720,	
2017-07-18 11:13:54,857 Epoch[0] Batch [390]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.430419,	
2017-07-18 11:14:05,437 Epoch[0] Batch [400]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.428446,	
2017-07-18 11:14:15,901 Epoch[0] Batch [410]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.426165,	
2017-07-18 11:14:26,732 Epoch[0] Batch [420]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.421165,	
2017-07-18 11:14:37,216 Epoch[0] Batch [430]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.417529,	
2017-07-18 11:14:47,873 Epoch[0] Batch [440]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.412944,	
2017-07-18 11:14:58,366 Epoch[0] Batch [450]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.408064,	
2017-07-18 11:15:09,043 Epoch[0] Batch [460]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.405211,	
2017-07-18 11:15:19,416 Epoch[0] Batch [470]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.401830,	
2017-07-18 11:15:29,814 Epoch[0] Batch [480]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.400420,	
2017-07-18 11:15:39,735 Epoch[0] Batch [490]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.396268,	
2017-07-18 11:15:49,125 Epoch[0] Batch [500]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.394865,	
2017-07-18 11:15:58,285 Epoch[0] Batch [510]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.392501,	
2017-07-18 11:16:06,752 Epoch[0] Batch [520]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.389369,	
2017-07-18 11:16:14,821 Epoch[0] Batch [530]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.390026,	
2017-07-18 11:16:23,026 Epoch[0] Batch [540]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.388928,	
2017-07-18 11:16:30,983 Epoch[0] Batch [550]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.384274,	
2017-07-18 11:16:38,531 Epoch[0] Batch [560]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.381844,	
2017-07-18 11:16:46,844 Epoch[0] Batch [570]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.380622,	
2017-07-18 11:16:55,271 Epoch[0] Batch [580]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.381431,	
2017-07-18 11:17:02,856 Epoch[0] Batch [590]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.378398,	
2017-07-18 11:17:10,434 Epoch[0] Batch [600]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.377098,	
2017-07-18 11:17:17,976 Epoch[0] Batch [610]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.375894,	
2017-07-18 11:17:25,632 Epoch[0] Batch [620]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.375242,	
2017-07-18 11:17:33,285 Epoch[0] Batch [630]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.372140,	
2017-07-18 11:17:41,581 Epoch[0] Batch [640]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.370255,	
2017-07-18 11:17:49,367 Epoch[0] Batch [650]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.368906,	
2017-07-18 11:17:56,690 Epoch[0] Batch [660]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.366685,	
2017-07-18 11:18:04,114 Epoch[0] Batch [670]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.364531,	
2017-07-18 11:18:11,960 Epoch[0] Batch [680]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.363006,	
2017-07-18 11:18:19,590 Epoch[0] Batch [690]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.360291,	
2017-07-18 11:18:26,775 Epoch[0] Batch [700]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.358408,	
2017-07-18 11:18:33,856 Epoch[0] Batch [710]	Speed: 5.65 samples/sec	Train-FCNLogLoss=1.356557,	
2017-07-18 11:18:41,006 Epoch[0] Batch [720]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.355112,	
2017-07-18 11:18:48,406 Epoch[0] Batch [730]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.353065,	
2017-07-18 11:18:56,152 Epoch[0] Batch [740]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.351711,	
2017-07-18 11:19:03,663 Epoch[0] Batch [750]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.350777,	
2017-07-18 11:19:11,056 Epoch[0] Batch [760]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.349439,	
2017-07-18 11:19:18,684 Epoch[0] Batch [770]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.348603,	
2017-07-18 11:19:26,227 Epoch[0] Batch [780]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.348442,	
2017-07-18 11:19:33,247 Epoch[0] Batch [790]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.347985,	
2017-07-18 11:19:40,545 Epoch[0] Batch [800]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.346324,	
2017-07-18 11:19:47,742 Epoch[0] Batch [810]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.345918,	
2017-07-18 11:19:55,162 Epoch[0] Batch [820]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.345073,	
2017-07-18 11:20:02,174 Epoch[0] Batch [830]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.343821,	
2017-07-18 11:20:09,284 Epoch[0] Batch [840]	Speed: 5.63 samples/sec	Train-FCNLogLoss=1.343191,	
2017-07-18 11:20:16,504 Epoch[0] Batch [850]	Speed: 5.54 samples/sec	Train-FCNLogLoss=1.342883,	
2017-07-18 11:20:23,744 Epoch[0] Batch [860]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.340905,	
2017-07-18 11:20:31,370 Epoch[0] Batch [870]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.338153,	
2017-07-18 11:20:39,141 Epoch[0] Batch [880]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.337408,	
2017-07-18 11:20:46,788 Epoch[0] Batch [890]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.336425,	
2017-07-18 11:20:54,610 Epoch[0] Batch [900]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.336622,	
2017-07-18 11:21:02,509 Epoch[0] Batch [910]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.335526,	
2017-07-18 11:21:10,304 Epoch[0] Batch [920]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.335469,	
2017-07-18 11:21:17,938 Epoch[0] Batch [930]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.334602,	
2017-07-18 11:21:25,871 Epoch[0] Batch [940]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.333323,	
2017-07-18 11:21:33,970 Epoch[0] Batch [950]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.333027,	
2017-07-18 11:21:48,315 Epoch[0] Batch [960]	Speed: 2.79 samples/sec	Train-FCNLogLoss=1.332282,	
2017-07-18 11:21:55,847 Epoch[0] Batch [970]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.330815,	
2017-07-18 11:22:03,478 Epoch[0] Batch [980]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.330786,	
2017-07-18 11:22:11,096 Epoch[0] Batch [990]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.330811,	
2017-07-18 11:22:19,046 Epoch[0] Batch [1000]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.329493,	
2017-07-18 11:22:27,559 Epoch[0] Batch [1010]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.330246,	
2017-07-18 11:22:36,068 Epoch[0] Batch [1020]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.331984,	
2017-07-18 11:22:44,251 Epoch[0] Batch [1030]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.336712,	
2017-07-18 11:22:52,906 Epoch[0] Batch [1040]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.343106,	
2017-07-18 11:23:01,457 Epoch[0] Batch [1050]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.349449,	
2017-07-18 11:23:09,602 Epoch[0] Batch [1060]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.354989,	
2017-07-18 11:23:17,375 Epoch[0] Batch [1070]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.359807,	
2017-07-18 11:23:25,426 Epoch[0] Batch [1080]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.363738,	
2017-07-18 11:23:33,937 Epoch[0] Batch [1090]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.367211,	
2017-07-18 11:23:42,477 Epoch[0] Batch [1100]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.377051,	
2017-07-18 11:23:50,447 Epoch[0] Batch [1110]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.382109,	
2017-07-18 11:23:58,585 Epoch[0] Batch [1120]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.386318,	
2017-07-18 11:24:07,923 Epoch[0] Batch [1130]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.392165,	
2017-07-18 11:24:17,114 Epoch[0] Batch [1140]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.396289,	
2017-07-18 11:24:26,224 Epoch[0] Batch [1150]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.398332,	
2017-07-18 11:24:35,641 Epoch[0] Batch [1160]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.401567,	
2017-07-18 11:24:44,117 Epoch[0] Batch [1170]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.404407,	
2017-07-18 11:24:53,163 Epoch[0] Batch [1180]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.407436,	
2017-07-18 11:25:01,921 Epoch[0] Batch [1190]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.409110,	
2017-07-18 11:25:10,525 Epoch[0] Batch [1200]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.410716,	
2017-07-18 11:25:20,002 Epoch[0] Batch [1210]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.412464,	
2017-07-18 11:25:29,334 Epoch[0] Batch [1220]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.417287,	
2017-07-18 11:25:38,694 Epoch[0] Batch [1230]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.422598,	
2017-07-18 11:25:48,081 Epoch[0] Batch [1240]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.426596,	
2017-07-18 11:25:57,377 Epoch[0] Batch [1250]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.429563,	
2017-07-18 11:26:06,108 Epoch[0] Batch [1260]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.431261,	
2017-07-18 11:26:15,210 Epoch[0] Batch [1270]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.432852,	
2017-07-18 11:26:24,255 Epoch[0] Batch [1280]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.431904,	
2017-07-18 11:26:32,789 Epoch[0] Batch [1290]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.433178,	
2017-07-18 11:26:41,289 Epoch[0] Batch [1300]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.438242,	
2017-07-18 11:26:49,827 Epoch[0] Batch [1310]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.440994,	
2017-07-18 11:26:58,251 Epoch[0] Batch [1320]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.443341,	
2017-07-18 11:27:06,067 Epoch[0] Batch [1330]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.445619,	
2017-07-18 11:27:13,386 Epoch[0] Batch [1340]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.446582,	
2017-07-18 11:27:20,878 Epoch[0] Batch [1350]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.446129,	
2017-07-18 11:27:28,346 Epoch[0] Batch [1360]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.446381,	
2017-07-18 11:27:35,264 Epoch[0] Batch [1370]	Speed: 5.78 samples/sec	Train-FCNLogLoss=1.445725,	
2017-07-18 11:27:42,457 Epoch[0] Batch [1380]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.445237,	
2017-07-18 11:27:49,579 Epoch[0] Batch [1390]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.444926,	
2017-07-18 11:27:57,790 Epoch[0] Batch [1400]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.444293,	
2017-07-18 11:28:04,939 Epoch[0] Batch [1410]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.444165,	
2017-07-18 11:28:12,078 Epoch[0] Batch [1420]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.443428,	
2017-07-18 11:28:19,414 Epoch[0] Batch [1430]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.442420,	
2017-07-18 11:28:27,241 Epoch[0] Batch [1440]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.440801,	
2017-07-18 11:28:34,398 Epoch[0] Batch [1450]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.439946,	
2017-07-18 11:28:41,804 Epoch[0] Batch [1460]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.438992,	
2017-07-18 11:28:49,363 Epoch[0] Batch [1470]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.437378,	
2017-07-18 11:28:57,274 Epoch[0] Batch [1480]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.435513,	
2017-07-18 11:29:01,756 Epoch[0] Train-FCNLogLoss=1.434744
2017-07-18 11:29:01,756 Epoch[0] Time cost=1326.655
2017-07-18 11:29:03,472 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-18 11:29:10,760 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-18 11:29:19,306 Epoch[1] Batch [10]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.320801,	
2017-07-18 11:29:26,586 Epoch[1] Batch [20]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.329829,	
2017-07-18 11:29:33,634 Epoch[1] Batch [30]	Speed: 5.68 samples/sec	Train-FCNLogLoss=1.339458,	
2017-07-18 11:29:41,484 Epoch[1] Batch [40]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.306695,	
2017-07-18 11:29:48,977 Epoch[1] Batch [50]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.301738,	
2017-07-18 11:29:56,623 Epoch[1] Batch [60]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.295862,	
2017-07-18 11:30:02,959 Epoch[1] Batch [70]	Speed: 6.31 samples/sec	Train-FCNLogLoss=1.280775,	
2017-07-18 11:30:10,348 Epoch[1] Batch [80]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.288122,	
2017-07-18 11:30:17,882 Epoch[1] Batch [90]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.283906,	
2017-07-18 11:30:25,089 Epoch[1] Batch [100]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.275505,	
2017-07-18 11:30:33,613 Epoch[1] Batch [110]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.276126,	
2017-07-18 11:30:42,225 Epoch[1] Batch [120]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.270504,	
2017-07-18 11:30:50,915 Epoch[1] Batch [130]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.269906,	
2017-07-18 11:31:00,334 Epoch[1] Batch [140]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.270976,	
2017-07-18 11:31:09,786 Epoch[1] Batch [150]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.273467,	
2017-07-18 11:31:19,000 Epoch[1] Batch [160]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.282274,	
2017-07-18 11:31:28,805 Epoch[1] Batch [170]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.285492,	
2017-07-18 11:31:38,115 Epoch[1] Batch [180]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.280668,	
2017-07-18 11:31:47,281 Epoch[1] Batch [190]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.285157,	
2017-07-18 11:31:53,862 Epoch[1] Batch [200]	Speed: 6.08 samples/sec	Train-FCNLogLoss=1.284139,	
2017-07-18 11:32:00,271 Epoch[1] Batch [210]	Speed: 6.24 samples/sec	Train-FCNLogLoss=1.288715,	
2017-07-18 11:32:06,455 Epoch[1] Batch [220]	Speed: 6.47 samples/sec	Train-FCNLogLoss=1.292199,	
2017-07-18 11:32:12,791 Epoch[1] Batch [230]	Speed: 6.31 samples/sec	Train-FCNLogLoss=1.290435,	
2017-07-18 11:32:19,348 Epoch[1] Batch [240]	Speed: 6.10 samples/sec	Train-FCNLogLoss=1.290043,	
2017-07-18 11:32:25,953 Epoch[1] Batch [250]	Speed: 6.06 samples/sec	Train-FCNLogLoss=1.292142,	
2017-07-18 11:32:32,856 Epoch[1] Batch [260]	Speed: 5.80 samples/sec	Train-FCNLogLoss=1.294214,	
2017-07-18 11:32:40,666 Epoch[1] Batch [270]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.293806,	
2017-07-18 11:32:47,205 Epoch[1] Batch [280]	Speed: 6.12 samples/sec	Train-FCNLogLoss=1.291492,	
2017-07-18 11:32:53,695 Epoch[1] Batch [290]	Speed: 6.16 samples/sec	Train-FCNLogLoss=1.288700,	
2017-07-18 11:33:00,175 Epoch[1] Batch [300]	Speed: 6.17 samples/sec	Train-FCNLogLoss=1.286217,	
2017-07-18 11:33:06,573 Epoch[1] Batch [310]	Speed: 6.25 samples/sec	Train-FCNLogLoss=1.287650,	
2017-07-18 11:33:13,418 Epoch[1] Batch [320]	Speed: 5.84 samples/sec	Train-FCNLogLoss=1.287901,	
2017-07-18 11:33:19,861 Epoch[1] Batch [330]	Speed: 6.21 samples/sec	Train-FCNLogLoss=1.290483,	
2017-07-18 11:33:26,949 Epoch[1] Batch [340]	Speed: 5.64 samples/sec	Train-FCNLogLoss=1.289015,	
2017-07-18 11:33:33,629 Epoch[1] Batch [350]	Speed: 5.99 samples/sec	Train-FCNLogLoss=1.290684,	
2017-07-18 11:33:40,447 Epoch[1] Batch [360]	Speed: 5.87 samples/sec	Train-FCNLogLoss=1.291083,	
2017-07-18 11:33:47,376 Epoch[1] Batch [370]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.290699,	
2017-07-18 11:33:54,019 Epoch[1] Batch [380]	Speed: 6.02 samples/sec	Train-FCNLogLoss=1.291098,	
2017-07-18 11:34:00,549 Epoch[1] Batch [390]	Speed: 6.13 samples/sec	Train-FCNLogLoss=1.290267,	
2017-07-18 11:34:07,174 Epoch[1] Batch [400]	Speed: 6.04 samples/sec	Train-FCNLogLoss=1.290183,	
2017-07-18 11:34:13,708 Epoch[1] Batch [410]	Speed: 6.12 samples/sec	Train-FCNLogLoss=1.288673,	
2017-07-18 11:34:19,984 Epoch[1] Batch [420]	Speed: 6.37 samples/sec	Train-FCNLogLoss=1.287628,	
2017-07-18 11:34:26,178 Epoch[1] Batch [430]	Speed: 6.46 samples/sec	Train-FCNLogLoss=1.289002,	
2017-07-18 11:34:32,637 Epoch[1] Batch [440]	Speed: 6.19 samples/sec	Train-FCNLogLoss=1.286125,	
2017-07-18 11:34:38,956 Epoch[1] Batch [450]	Speed: 6.33 samples/sec	Train-FCNLogLoss=1.287395,	
2017-07-18 11:34:45,239 Epoch[1] Batch [460]	Speed: 6.37 samples/sec	Train-FCNLogLoss=1.285786,	
2017-07-18 11:34:51,048 Epoch[1] Batch [470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=1.288205,	
2017-07-18 11:34:57,193 Epoch[1] Batch [480]	Speed: 6.51 samples/sec	Train-FCNLogLoss=1.290400,	
2017-07-18 11:35:03,800 Epoch[1] Batch [490]	Speed: 6.06 samples/sec	Train-FCNLogLoss=1.289570,	
2017-07-18 11:35:10,575 Epoch[1] Batch [500]	Speed: 5.90 samples/sec	Train-FCNLogLoss=1.289317,	
2017-07-18 11:35:17,439 Epoch[1] Batch [510]	Speed: 5.83 samples/sec	Train-FCNLogLoss=1.288428,	
2017-07-18 11:35:25,618 Epoch[1] Batch [520]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.287493,	
2017-07-18 11:35:33,698 Epoch[1] Batch [530]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.286253,	
2017-07-18 11:35:40,180 Epoch[1] Batch [540]	Speed: 6.17 samples/sec	Train-FCNLogLoss=1.285065,	
2017-07-18 11:35:47,072 Epoch[1] Batch [550]	Speed: 5.80 samples/sec	Train-FCNLogLoss=1.284001,	
2017-07-18 11:35:53,920 Epoch[1] Batch [560]	Speed: 5.84 samples/sec	Train-FCNLogLoss=1.283641,	
2017-07-18 11:36:00,879 Epoch[1] Batch [570]	Speed: 5.75 samples/sec	Train-FCNLogLoss=1.282244,	
2017-07-18 11:36:07,815 Epoch[1] Batch [580]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.282219,	
2017-07-18 11:36:14,893 Epoch[1] Batch [590]	Speed: 5.65 samples/sec	Train-FCNLogLoss=1.281054,	
2017-07-18 11:36:21,938 Epoch[1] Batch [600]	Speed: 5.68 samples/sec	Train-FCNLogLoss=1.281332,	
2017-07-18 11:36:28,567 Epoch[1] Batch [610]	Speed: 6.03 samples/sec	Train-FCNLogLoss=1.283746,	
2017-07-18 11:36:36,095 Epoch[1] Batch [620]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.282111,	
2017-07-18 11:36:43,409 Epoch[1] Batch [630]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.279645,	
2017-07-18 11:36:51,280 Epoch[1] Batch [640]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.278901,	
2017-07-18 11:36:58,408 Epoch[1] Batch [650]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.278730,	
2017-07-18 11:37:05,732 Epoch[1] Batch [660]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.279477,	
2017-07-18 11:37:12,735 Epoch[1] Batch [670]	Speed: 5.71 samples/sec	Train-FCNLogLoss=1.279319,	
2017-07-18 11:37:19,867 Epoch[1] Batch [680]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.280304,	
2017-07-18 11:37:26,880 Epoch[1] Batch [690]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.279499,	
2017-07-18 11:37:33,351 Epoch[1] Batch [700]	Speed: 6.18 samples/sec	Train-FCNLogLoss=1.278334,	
2017-07-18 11:37:40,140 Epoch[1] Batch [710]	Speed: 5.89 samples/sec	Train-FCNLogLoss=1.278146,	
2017-07-18 11:37:47,284 Epoch[1] Batch [720]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.277731,	
2017-07-18 11:37:54,252 Epoch[1] Batch [730]	Speed: 5.74 samples/sec	Train-FCNLogLoss=1.277862,	
2017-07-18 11:38:01,803 Epoch[1] Batch [740]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.276473,	
2017-07-18 11:38:10,451 Epoch[1] Batch [750]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.274910,	
2017-07-18 11:38:19,599 Epoch[1] Batch [760]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.275684,	
2017-07-18 11:38:27,249 Epoch[1] Batch [770]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.275492,	
2017-07-18 11:38:35,112 Epoch[1] Batch [780]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.274078,	
2017-07-18 11:38:42,261 Epoch[1] Batch [790]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.273843,	
2017-07-18 11:38:49,846 Epoch[1] Batch [800]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.273436,	
2017-07-18 11:38:57,384 Epoch[1] Batch [810]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.274509,	
2017-07-18 11:39:04,964 Epoch[1] Batch [820]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.274327,	
2017-07-18 11:39:12,731 Epoch[1] Batch [830]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.273419,	
2017-07-18 11:39:20,538 Epoch[1] Batch [840]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.273832,	
2017-07-18 11:39:27,738 Epoch[1] Batch [850]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.273566,	
2017-07-18 11:39:35,408 Epoch[1] Batch [860]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.274058,	
2017-07-18 11:39:43,060 Epoch[1] Batch [870]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.274050,	
2017-07-18 11:39:51,631 Epoch[1] Batch [880]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.273910,	
2017-07-18 11:40:00,329 Epoch[1] Batch [890]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.274470,	
2017-07-18 11:40:09,553 Epoch[1] Batch [900]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.274310,	
2017-07-18 11:40:17,491 Epoch[1] Batch [910]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.276480,	
2017-07-18 11:40:25,025 Epoch[1] Batch [920]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.276261,	
2017-07-18 11:40:33,154 Epoch[1] Batch [930]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.276365,	
2017-07-18 11:40:40,780 Epoch[1] Batch [940]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.275267,	
2017-07-18 11:40:48,346 Epoch[1] Batch [950]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.274752,	
2017-07-18 11:40:56,112 Epoch[1] Batch [960]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.275531,	
2017-07-18 11:41:04,095 Epoch[1] Batch [970]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.274968,	
2017-07-18 11:41:11,712 Epoch[1] Batch [980]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.276308,	
2017-07-18 11:41:18,899 Epoch[1] Batch [990]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.274680,	
2017-07-18 11:41:27,075 Epoch[1] Batch [1000]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.273711,	
2017-07-18 11:41:34,681 Epoch[1] Batch [1010]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.272459,	
2017-07-18 11:41:41,701 Epoch[1] Batch [1020]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.272765,	
2017-07-18 11:41:49,377 Epoch[1] Batch [1030]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.272938,	
2017-07-18 11:41:57,340 Epoch[1] Batch [1040]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.272941,	
2017-07-18 11:42:05,119 Epoch[1] Batch [1050]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.271964,	
2017-07-18 11:42:12,684 Epoch[1] Batch [1060]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.272084,	
2017-07-18 11:42:20,394 Epoch[1] Batch [1070]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.272052,	
2017-07-18 11:42:28,116 Epoch[1] Batch [1080]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.271616,	
2017-07-18 11:42:35,809 Epoch[1] Batch [1090]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.271696,	
2017-07-18 11:42:43,232 Epoch[1] Batch [1100]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.271317,	
2017-07-18 11:42:50,689 Epoch[1] Batch [1110]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.270734,	
2017-07-18 11:42:58,463 Epoch[1] Batch [1120]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.270973,	
2017-07-18 11:43:06,246 Epoch[1] Batch [1130]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.270155,	
2017-07-18 11:43:13,694 Epoch[1] Batch [1140]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.269593,	
2017-07-18 11:43:21,488 Epoch[1] Batch [1150]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.269858,	
2017-07-18 11:43:29,412 Epoch[1] Batch [1160]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.269886,	
2017-07-18 11:43:37,564 Epoch[1] Batch [1170]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.270012,	
2017-07-18 11:43:45,623 Epoch[1] Batch [1180]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.269325,	
2017-07-18 11:43:53,292 Epoch[1] Batch [1190]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.268744,	
2017-07-18 11:44:01,117 Epoch[1] Batch [1200]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.268902,	
2017-07-18 11:44:08,719 Epoch[1] Batch [1210]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.268923,	
2017-07-18 11:44:16,222 Epoch[1] Batch [1220]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.268426,	
2017-07-18 11:44:23,600 Epoch[1] Batch [1230]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.267783,	
2017-07-18 11:44:31,298 Epoch[1] Batch [1240]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.267254,	
2017-07-18 11:44:38,889 Epoch[1] Batch [1250]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.266811,	
2017-07-18 11:44:46,618 Epoch[1] Batch [1260]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.266960,	
2017-07-18 11:44:54,184 Epoch[1] Batch [1270]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.268078,	
2017-07-18 11:45:01,998 Epoch[1] Batch [1280]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.267804,	
2017-07-18 11:45:09,397 Epoch[1] Batch [1290]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.267980,	
2017-07-18 11:45:17,024 Epoch[1] Batch [1300]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.268047,	
2017-07-18 11:45:24,751 Epoch[1] Batch [1310]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.267949,	
2017-07-18 11:45:32,249 Epoch[1] Batch [1320]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.267626,	
2017-07-18 11:45:39,734 Epoch[1] Batch [1330]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.267584,	
2017-07-18 11:45:47,422 Epoch[1] Batch [1340]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.267221,	
2017-07-18 11:45:55,167 Epoch[1] Batch [1350]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.266772,	
2017-07-18 11:46:03,351 Epoch[1] Batch [1360]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.266457,	
2017-07-18 11:46:11,369 Epoch[1] Batch [1370]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.265484,	
2017-07-18 11:46:19,510 Epoch[1] Batch [1380]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.265093,	
2017-07-18 11:46:27,464 Epoch[1] Batch [1390]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.265004,	
2017-07-18 11:46:35,401 Epoch[1] Batch [1400]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.265414,	
2017-07-18 11:46:43,517 Epoch[1] Batch [1410]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.265091,	
2017-07-18 11:46:51,904 Epoch[1] Batch [1420]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.264616,	
2017-07-18 11:47:00,489 Epoch[1] Batch [1430]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.264436,	
2017-07-18 11:47:09,098 Epoch[1] Batch [1440]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.264453,	
2017-07-18 11:47:17,223 Epoch[1] Batch [1450]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.265043,	
2017-07-18 11:47:25,720 Epoch[1] Batch [1460]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.265064,	
2017-07-18 11:47:34,057 Epoch[1] Batch [1470]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.265299,	
2017-07-18 11:47:42,679 Epoch[1] Batch [1480]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.265443,	
2017-07-18 11:47:47,846 Epoch[1] Train-FCNLogLoss=1.265070
2017-07-18 11:47:47,846 Epoch[1] Time cost=1117.085
2017-07-18 11:47:49,349 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-18 11:47:53,757 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-18 11:48:02,649 Epoch[2] Batch [10]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.231651,	
2017-07-18 11:48:10,403 Epoch[2] Batch [20]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.247177,	
2017-07-18 11:48:17,772 Epoch[2] Batch [30]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.234265,	
2017-07-18 11:48:25,200 Epoch[2] Batch [40]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.249336,	
2017-07-18 11:48:32,106 Epoch[2] Batch [50]	Speed: 5.79 samples/sec	Train-FCNLogLoss=1.253062,	
2017-07-18 11:48:39,179 Epoch[2] Batch [60]	Speed: 5.66 samples/sec	Train-FCNLogLoss=1.235249,	
2017-07-18 11:48:46,645 Epoch[2] Batch [70]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.245897,	
2017-07-18 11:48:53,923 Epoch[2] Batch [80]	Speed: 5.50 samples/sec	Train-FCNLogLoss=1.242940,	
2017-07-18 11:49:01,146 Epoch[2] Batch [90]	Speed: 5.54 samples/sec	Train-FCNLogLoss=1.238148,	
2017-07-18 11:49:08,206 Epoch[2] Batch [100]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.239736,	
2017-07-18 11:49:15,911 Epoch[2] Batch [110]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.233221,	
2017-07-18 11:49:23,777 Epoch[2] Batch [120]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.231514,	
2017-07-18 11:49:31,021 Epoch[2] Batch [130]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.240777,	
2017-07-18 11:49:38,345 Epoch[2] Batch [140]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.243399,	
2017-07-18 11:49:45,866 Epoch[2] Batch [150]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.242402,	
2017-07-18 11:49:53,166 Epoch[2] Batch [160]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.244327,	
2017-07-18 11:50:01,465 Epoch[2] Batch [170]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.244537,	
2017-07-18 11:50:09,417 Epoch[2] Batch [180]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.242773,	
2017-07-18 11:50:16,349 Epoch[2] Batch [190]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.243142,	
2017-07-18 11:50:24,378 Epoch[2] Batch [200]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.241576,	
2017-07-18 11:50:31,688 Epoch[2] Batch [210]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.246641,	
2017-07-18 11:50:38,468 Epoch[2] Batch [220]	Speed: 5.90 samples/sec	Train-FCNLogLoss=1.249325,	
2017-07-18 11:50:44,522 Epoch[2] Batch [230]	Speed: 6.61 samples/sec	Train-FCNLogLoss=1.252261,	
2017-07-18 11:50:51,251 Epoch[2] Batch [240]	Speed: 5.94 samples/sec	Train-FCNLogLoss=1.248406,	
2017-07-18 11:50:57,581 Epoch[2] Batch [250]	Speed: 6.32 samples/sec	Train-FCNLogLoss=1.247560,	
2017-07-18 11:51:04,061 Epoch[2] Batch [260]	Speed: 6.17 samples/sec	Train-FCNLogLoss=1.248125,	
2017-07-18 11:51:10,350 Epoch[2] Batch [270]	Speed: 6.36 samples/sec	Train-FCNLogLoss=1.250526,	
2017-07-18 11:51:16,944 Epoch[2] Batch [280]	Speed: 6.07 samples/sec	Train-FCNLogLoss=1.253572,	
2017-07-18 11:51:23,389 Epoch[2] Batch [290]	Speed: 6.21 samples/sec	Train-FCNLogLoss=1.253904,	
2017-07-18 11:51:31,438 Epoch[2] Batch [300]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.251856,	
2017-07-18 11:51:38,727 Epoch[2] Batch [310]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.250200,	
2017-07-18 11:51:46,226 Epoch[2] Batch [320]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.250198,	
2017-07-18 11:51:53,765 Epoch[2] Batch [330]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.252141,	
2017-07-18 11:52:01,113 Epoch[2] Batch [340]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.256840,	
2017-07-18 11:52:08,794 Epoch[2] Batch [350]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.259268,	
2017-07-18 11:52:16,601 Epoch[2] Batch [360]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.258211,	
2017-07-18 11:52:23,936 Epoch[2] Batch [370]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.256002,	
2017-07-18 11:52:31,306 Epoch[2] Batch [380]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.257996,	
2017-07-18 11:52:38,661 Epoch[2] Batch [390]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.256870,	
2017-07-18 11:52:46,646 Epoch[2] Batch [400]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.256910,	
2017-07-18 11:52:54,881 Epoch[2] Batch [410]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.255244,	
2017-07-18 11:53:02,760 Epoch[2] Batch [420]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.254666,	
2017-07-18 11:53:10,456 Epoch[2] Batch [430]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.252151,	
2017-07-18 11:53:18,428 Epoch[2] Batch [440]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.251731,	
2017-07-18 11:53:26,285 Epoch[2] Batch [450]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.252742,	
2017-07-18 11:53:33,840 Epoch[2] Batch [460]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.251827,	
2017-07-18 11:53:41,256 Epoch[2] Batch [470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.250413,	
2017-07-18 11:53:48,832 Epoch[2] Batch [480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.251993,	
2017-07-18 11:53:56,715 Epoch[2] Batch [490]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.252894,	
2017-07-18 11:54:05,008 Epoch[2] Batch [500]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.253718,	
2017-07-18 11:54:13,157 Epoch[2] Batch [510]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.253730,	
2017-07-18 11:54:20,960 Epoch[2] Batch [520]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.252107,	
2017-07-18 11:54:28,549 Epoch[2] Batch [530]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.251318,	
2017-07-18 11:54:36,327 Epoch[2] Batch [540]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.251093,	
2017-07-18 11:54:44,102 Epoch[2] Batch [550]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.249229,	
2017-07-18 11:54:51,456 Epoch[2] Batch [560]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.248232,	
2017-07-18 11:54:58,694 Epoch[2] Batch [570]	Speed: 5.53 samples/sec	Train-FCNLogLoss=1.247752,	
2017-07-18 11:55:06,274 Epoch[2] Batch [580]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.246402,	
2017-07-18 11:55:13,481 Epoch[2] Batch [590]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.247169,	
2017-07-18 11:55:20,919 Epoch[2] Batch [600]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.247278,	
2017-07-18 11:55:28,258 Epoch[2] Batch [610]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.247439,	
2017-07-18 11:55:35,824 Epoch[2] Batch [620]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.247934,	
2017-07-18 11:55:43,315 Epoch[2] Batch [630]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.247225,	
2017-07-18 11:55:50,479 Epoch[2] Batch [640]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.246026,	
2017-07-18 11:55:57,908 Epoch[2] Batch [650]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.246171,	
2017-07-18 11:56:05,368 Epoch[2] Batch [660]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.246547,	
2017-07-18 11:56:12,732 Epoch[2] Batch [670]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.247478,	
2017-07-18 11:56:20,272 Epoch[2] Batch [680]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.248681,	
2017-07-18 11:56:27,440 Epoch[2] Batch [690]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.248757,	
2017-07-18 11:56:34,455 Epoch[2] Batch [700]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.248908,	
2017-07-18 11:56:42,072 Epoch[2] Batch [710]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.248671,	
2017-07-18 11:56:49,215 Epoch[2] Batch [720]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.248910,	
2017-07-18 11:56:57,073 Epoch[2] Batch [730]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.248447,	
2017-07-18 11:57:04,428 Epoch[2] Batch [740]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.250416,	
2017-07-18 11:57:11,987 Epoch[2] Batch [750]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.251060,	
2017-07-18 11:57:19,498 Epoch[2] Batch [760]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.251042,	
2017-07-18 11:57:26,799 Epoch[2] Batch [770]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.250338,	
2017-07-18 11:57:34,176 Epoch[2] Batch [780]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.250262,	
2017-07-18 11:57:42,049 Epoch[2] Batch [790]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.249186,	
2017-07-18 11:57:49,627 Epoch[2] Batch [800]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.248663,	
2017-07-18 11:57:57,153 Epoch[2] Batch [810]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.249099,	
2017-07-18 11:58:04,670 Epoch[2] Batch [820]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.249373,	
2017-07-18 11:58:12,065 Epoch[2] Batch [830]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.248808,	
2017-07-18 11:58:19,241 Epoch[2] Batch [840]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.248817,	
2017-07-18 11:58:26,905 Epoch[2] Batch [850]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.251056,	
2017-07-18 11:58:34,509 Epoch[2] Batch [860]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.251763,	
2017-07-18 11:58:42,322 Epoch[2] Batch [870]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.251419,	
2017-07-18 11:58:49,643 Epoch[2] Batch [880]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.251743,	
2017-07-18 11:58:57,316 Epoch[2] Batch [890]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.252540,	
2017-07-18 11:59:04,689 Epoch[2] Batch [900]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.252104,	
2017-07-18 11:59:12,365 Epoch[2] Batch [910]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.252353,	
2017-07-18 11:59:19,938 Epoch[2] Batch [920]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.252691,	
2017-07-18 11:59:27,504 Epoch[2] Batch [930]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.251664,	
2017-07-18 11:59:35,830 Epoch[2] Batch [940]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.250915,	
2017-07-18 11:59:44,026 Epoch[2] Batch [950]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.250472,	
2017-07-18 11:59:52,863 Epoch[2] Batch [960]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.249158,	
2017-07-18 12:00:01,464 Epoch[2] Batch [970]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.248981,	
2017-07-18 12:00:10,116 Epoch[2] Batch [980]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.249553,	
2017-07-18 12:00:18,554 Epoch[2] Batch [990]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.248662,	
2017-07-18 12:00:27,439 Epoch[2] Batch [1000]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.249232,	
2017-07-18 12:00:36,845 Epoch[2] Batch [1010]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.249931,	
2017-07-18 12:00:45,875 Epoch[2] Batch [1020]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.249477,	
2017-07-18 12:00:55,298 Epoch[2] Batch [1030]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.249323,	
2017-07-18 12:01:04,316 Epoch[2] Batch [1040]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.248910,	
2017-07-18 12:01:13,615 Epoch[2] Batch [1050]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.248425,	
2017-07-18 12:01:22,681 Epoch[2] Batch [1060]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.250113,	
2017-07-18 12:01:32,168 Epoch[2] Batch [1070]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.250297,	
2017-07-18 12:01:41,475 Epoch[2] Batch [1080]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.250257,	
2017-07-18 12:01:50,973 Epoch[2] Batch [1090]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.249689,	
2017-07-18 12:01:59,882 Epoch[2] Batch [1100]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.249385,	
2017-07-18 12:02:09,126 Epoch[2] Batch [1110]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.250017,	
2017-07-18 12:02:18,036 Epoch[2] Batch [1120]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.249348,	
2017-07-18 12:02:27,008 Epoch[2] Batch [1130]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.248168,	
2017-07-18 12:02:36,171 Epoch[2] Batch [1140]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.247728,	
2017-07-18 12:02:45,241 Epoch[2] Batch [1150]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.247634,	
2017-07-18 12:02:54,035 Epoch[2] Batch [1160]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.248607,	
2017-07-18 12:03:03,456 Epoch[2] Batch [1170]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.249761,	
2017-07-18 12:03:21,586 Epoch[2] Batch [1180]	Speed: 2.21 samples/sec	Train-FCNLogLoss=1.250466,	
2017-07-18 12:03:34,568 Epoch[2] Batch [1190]	Speed: 3.08 samples/sec	Train-FCNLogLoss=1.250477,	
2017-07-18 12:03:50,492 Epoch[2] Batch [1200]	Speed: 2.51 samples/sec	Train-FCNLogLoss=1.251198,	
2017-07-18 12:04:03,450 Epoch[2] Batch [1210]	Speed: 3.09 samples/sec	Train-FCNLogLoss=1.251576,	
2017-07-18 12:04:16,432 Epoch[2] Batch [1220]	Speed: 3.08 samples/sec	Train-FCNLogLoss=1.251218,	
2017-07-18 12:04:29,087 Epoch[2] Batch [1230]	Speed: 3.16 samples/sec	Train-FCNLogLoss=1.251801,	
2017-07-18 12:04:41,983 Epoch[2] Batch [1240]	Speed: 3.10 samples/sec	Train-FCNLogLoss=1.251551,	
2017-07-18 12:04:55,739 Epoch[2] Batch [1250]	Speed: 2.91 samples/sec	Train-FCNLogLoss=1.250503,	
2017-07-18 12:05:09,767 Epoch[2] Batch [1260]	Speed: 2.85 samples/sec	Train-FCNLogLoss=1.249910,	
2017-07-18 12:05:22,931 Epoch[2] Batch [1270]	Speed: 3.04 samples/sec	Train-FCNLogLoss=1.249876,	
2017-07-18 12:05:36,474 Epoch[2] Batch [1280]	Speed: 2.95 samples/sec	Train-FCNLogLoss=1.249970,	
2017-07-18 12:05:49,814 Epoch[2] Batch [1290]	Speed: 3.00 samples/sec	Train-FCNLogLoss=1.250845,	
2017-07-18 12:06:02,764 Epoch[2] Batch [1300]	Speed: 3.09 samples/sec	Train-FCNLogLoss=1.251011,	
2017-07-18 12:06:13,022 Epoch[2] Batch [1310]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.250291,	
2017-07-18 12:06:23,083 Epoch[2] Batch [1320]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.250459,	
2017-07-18 12:06:32,015 Epoch[2] Batch [1330]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.250336,	
2017-07-18 12:06:40,732 Epoch[2] Batch [1340]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.250436,	
2017-07-18 12:06:49,408 Epoch[2] Batch [1350]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.250337,	
2017-07-18 12:06:58,214 Epoch[2] Batch [1360]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.250182,	
2017-07-18 12:07:07,928 Epoch[2] Batch [1370]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.250650,	
2017-07-18 12:07:17,321 Epoch[2] Batch [1380]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.250868,	
2017-07-18 12:07:25,891 Epoch[2] Batch [1390]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.250697,	
2017-07-18 12:07:33,948 Epoch[2] Batch [1400]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.250577,	
2017-07-18 12:07:42,608 Epoch[2] Batch [1410]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.250095,	
2017-07-18 12:07:50,831 Epoch[2] Batch [1420]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.249790,	
2017-07-18 12:07:59,068 Epoch[2] Batch [1430]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.249845,	
2017-07-18 12:08:07,369 Epoch[2] Batch [1440]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.249467,	
2017-07-18 12:08:15,771 Epoch[2] Batch [1450]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.250002,	
2017-07-18 12:08:24,710 Epoch[2] Batch [1460]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.249417,	
2017-07-18 12:08:32,690 Epoch[2] Batch [1470]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.249683,	
2017-07-18 12:08:41,101 Epoch[2] Batch [1480]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.249707,	
2017-07-18 12:08:45,920 Epoch[2] Train-FCNLogLoss=1.249699
2017-07-18 12:08:45,920 Epoch[2] Time cost=1252.163
2017-07-18 12:08:47,095 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-18 12:08:52,206 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-18 12:09:00,524 Epoch[3] Batch [10]	Speed: 5.66 samples/sec	Train-FCNLogLoss=1.235363,	
2017-07-18 12:09:08,360 Epoch[3] Batch [20]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.200713,	
2017-07-18 12:09:15,343 Epoch[3] Batch [30]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.216730,	
2017-07-18 12:09:22,336 Epoch[3] Batch [40]	Speed: 5.72 samples/sec	Train-FCNLogLoss=1.209138,	
2017-07-18 12:09:29,105 Epoch[3] Batch [50]	Speed: 5.91 samples/sec	Train-FCNLogLoss=1.244001,	

2017-07-18 12:09:42,594 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-18 12:12:30,085 Epoch[0] Batch [10]	Speed: 3.16 samples/sec	Train-FCNLogLoss=2.801278,	
2017-07-18 12:12:42,777 Epoch[0] Batch [20]	Speed: 3.15 samples/sec	Train-FCNLogLoss=2.501928,	
2017-07-18 12:12:55,476 Epoch[0] Batch [30]	Speed: 3.15 samples/sec	Train-FCNLogLoss=2.280196,	
2017-07-18 12:13:07,859 Epoch[0] Batch [40]	Speed: 3.23 samples/sec	Train-FCNLogLoss=2.144646,	
2017-07-18 12:13:20,677 Epoch[0] Batch [50]	Speed: 3.12 samples/sec	Train-FCNLogLoss=2.064335,	
2017-07-18 12:13:33,385 Epoch[0] Batch [60]	Speed: 3.15 samples/sec	Train-FCNLogLoss=2.007317,	
2017-07-18 12:13:45,733 Epoch[0] Batch [70]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.942075,	
2017-07-18 12:13:58,475 Epoch[0] Batch [80]	Speed: 3.14 samples/sec	Train-FCNLogLoss=1.913916,	
2017-07-18 12:14:11,061 Epoch[0] Batch [90]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.863857,	
2017-07-18 12:14:23,425 Epoch[0] Batch [100]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.829791,	
2017-07-18 12:14:35,909 Epoch[0] Batch [110]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.804256,	
2017-07-18 12:14:48,353 Epoch[0] Batch [120]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.772348,	
2017-07-18 12:15:00,797 Epoch[0] Batch [130]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.737344,	
2017-07-18 12:15:13,115 Epoch[0] Batch [140]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.706918,	
2017-07-18 12:15:25,392 Epoch[0] Batch [150]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.676244,	
2017-07-18 12:15:37,574 Epoch[0] Batch [160]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.654435,	
2017-07-18 12:15:50,139 Epoch[0] Batch [170]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.633271,	
2017-07-18 12:16:02,717 Epoch[0] Batch [180]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.611486,	
2017-07-18 12:16:14,787 Epoch[0] Batch [190]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.593619,	
2017-07-18 12:16:27,259 Epoch[0] Batch [200]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.580343,	
2017-07-18 12:16:39,606 Epoch[0] Batch [210]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.568329,	
2017-07-18 12:16:51,842 Epoch[0] Batch [220]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.553798,	
2017-07-18 12:17:04,335 Epoch[0] Batch [230]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.542008,	
2017-07-18 12:17:16,550 Epoch[0] Batch [240]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.529876,	
2017-07-18 12:17:28,942 Epoch[0] Batch [250]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.518500,	
2017-07-18 12:17:41,386 Epoch[0] Batch [260]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.507213,	
2017-07-18 12:17:53,814 Epoch[0] Batch [270]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.496395,	
2017-07-18 12:18:06,060 Epoch[0] Batch [280]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.488735,	
2017-07-18 12:18:18,411 Epoch[0] Batch [290]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.479206,	
2017-07-18 12:18:30,702 Epoch[0] Batch [300]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.470253,	
2017-07-18 12:18:43,282 Epoch[0] Batch [310]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.464047,	
2017-07-18 12:18:55,611 Epoch[0] Batch [320]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.460258,	
2017-07-18 12:19:08,102 Epoch[0] Batch [330]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.454443,	
2017-07-18 12:19:20,577 Epoch[0] Batch [340]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.447272,	
2017-07-18 12:19:32,995 Epoch[0] Batch [350]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.439526,	
2017-07-18 12:19:45,111 Epoch[0] Batch [360]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.432778,	
2017-07-18 12:19:57,573 Epoch[0] Batch [370]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.429407,	
2017-07-18 12:20:10,256 Epoch[0] Batch [380]	Speed: 3.15 samples/sec	Train-FCNLogLoss=1.424697,	
2017-07-18 12:20:22,923 Epoch[0] Batch [390]	Speed: 3.16 samples/sec	Train-FCNLogLoss=1.422778,	
2017-07-18 12:20:35,369 Epoch[0] Batch [400]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.420438,	
2017-07-18 12:20:47,912 Epoch[0] Batch [410]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.417835,	
2017-07-18 12:21:00,384 Epoch[0] Batch [420]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.414577,	
2017-07-18 12:21:12,787 Epoch[0] Batch [430]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.411003,	
2017-07-18 12:21:25,107 Epoch[0] Batch [440]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.405941,	
2017-07-18 12:21:37,336 Epoch[0] Batch [450]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.402005,	
2017-07-18 12:21:49,211 Epoch[0] Batch [460]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.399198,	
2017-07-18 12:22:00,834 Epoch[0] Batch [470]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.396589,	
2017-07-18 12:22:13,108 Epoch[0] Batch [480]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.391400,	
2017-07-18 12:22:24,941 Epoch[0] Batch [490]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.388948,	
2017-07-18 12:22:36,676 Epoch[0] Batch [500]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.388088,	
2017-07-18 12:22:48,295 Epoch[0] Batch [510]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.385895,	
2017-07-18 12:23:00,048 Epoch[0] Batch [520]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.382135,	
2017-07-18 12:23:12,133 Epoch[0] Batch [530]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.380272,	
2017-07-18 12:23:24,518 Epoch[0] Batch [540]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.377112,	
2017-07-18 12:23:36,635 Epoch[0] Batch [550]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.374481,	
2017-07-18 12:23:48,793 Epoch[0] Batch [560]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.371159,	
2017-07-18 12:24:00,487 Epoch[0] Batch [570]	Speed: 3.42 samples/sec	Train-FCNLogLoss=1.370149,	
2017-07-18 12:24:11,910 Epoch[0] Batch [580]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.367703,	
2017-07-18 12:24:23,459 Epoch[0] Batch [590]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.367818,	
2017-07-18 12:24:35,060 Epoch[0] Batch [600]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.365245,	
2017-07-18 12:24:46,854 Epoch[0] Batch [610]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.364311,	
2017-07-18 12:24:58,733 Epoch[0] Batch [620]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.362988,	
2017-07-18 12:25:10,813 Epoch[0] Batch [630]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.361886,	
2017-07-18 12:25:22,747 Epoch[0] Batch [640]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.360293,	
2017-07-18 12:25:34,652 Epoch[0] Batch [650]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.358439,	
2017-07-18 12:25:46,577 Epoch[0] Batch [660]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.354084,	
2017-07-18 12:25:58,147 Epoch[0] Batch [670]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.352104,	
2017-07-18 12:26:09,918 Epoch[0] Batch [680]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.350074,	
2017-07-18 12:26:21,965 Epoch[0] Batch [690]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.349792,	
2017-07-18 12:26:33,895 Epoch[0] Batch [700]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.348976,	
2017-07-18 12:26:45,258 Epoch[0] Batch [710]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.347884,	
2017-07-18 12:26:56,873 Epoch[0] Batch [720]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.347243,	
2017-07-18 12:27:08,546 Epoch[0] Batch [730]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.346233,	
2017-07-18 12:27:20,119 Epoch[0] Batch [740]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.344916,	
2017-07-18 12:27:32,052 Epoch[0] Batch [750]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.344324,	
2017-07-18 12:27:43,551 Epoch[0] Batch [760]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.342391,	
2017-07-18 12:27:55,630 Epoch[0] Batch [770]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.340707,	
2017-07-18 12:28:07,474 Epoch[0] Batch [780]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.340178,	
2017-07-18 12:28:18,837 Epoch[0] Batch [790]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.339472,	
2017-07-18 12:28:30,479 Epoch[0] Batch [800]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.338892,	
2017-07-18 12:28:42,305 Epoch[0] Batch [810]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.336966,	
2017-07-18 12:28:54,322 Epoch[0] Batch [820]	Speed: 3.33 samples/sec	Train-FCNLogLoss=1.336622,	
2017-07-18 12:29:05,994 Epoch[0] Batch [830]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.336285,	
2017-07-18 12:29:18,324 Epoch[0] Batch [840]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.335244,	
2017-07-18 12:29:30,581 Epoch[0] Batch [850]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.333902,	
2017-07-18 12:29:42,769 Epoch[0] Batch [860]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.334509,	
2017-07-18 12:29:54,919 Epoch[0] Batch [870]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.334196,	
2017-07-18 12:30:07,237 Epoch[0] Batch [880]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.333704,	
2017-07-18 12:30:19,520 Epoch[0] Batch [890]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.332921,	
2017-07-18 12:30:32,089 Epoch[0] Batch [900]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.332583,	
2017-07-18 12:30:44,542 Epoch[0] Batch [910]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.330834,	
2017-07-18 12:30:57,022 Epoch[0] Batch [920]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.330582,	
2017-07-18 12:31:09,459 Epoch[0] Batch [930]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.330642,	
2017-07-18 12:31:21,836 Epoch[0] Batch [940]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.330887,	
2017-07-18 12:31:34,571 Epoch[0] Batch [950]	Speed: 3.14 samples/sec	Train-FCNLogLoss=1.329997,	
2017-07-18 12:31:47,129 Epoch[0] Batch [960]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.329120,	
2017-07-18 12:31:59,670 Epoch[0] Batch [970]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.328375,	
2017-07-18 12:32:12,389 Epoch[0] Batch [980]	Speed: 3.15 samples/sec	Train-FCNLogLoss=1.327536,	
2017-07-18 12:32:25,187 Epoch[0] Batch [990]	Speed: 3.13 samples/sec	Train-FCNLogLoss=1.327423,	
2017-07-18 12:32:37,906 Epoch[0] Batch [1000]	Speed: 3.15 samples/sec	Train-FCNLogLoss=1.326963,	
2017-07-18 12:32:50,415 Epoch[0] Batch [1010]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.327431,	
2017-07-18 12:33:02,224 Epoch[0] Batch [1020]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.331765,	
2017-07-18 12:33:14,145 Epoch[0] Batch [1030]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.335355,	
2017-07-18 12:33:26,083 Epoch[0] Batch [1040]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.337252,	
2017-07-18 12:33:38,471 Epoch[0] Batch [1050]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.336880,	
2017-07-18 12:33:50,503 Epoch[0] Batch [1060]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.338772,	
2017-07-18 12:34:02,826 Epoch[0] Batch [1070]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.340864,	
2017-07-18 12:34:14,803 Epoch[0] Batch [1080]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.341739,	
2017-07-18 12:34:27,005 Epoch[0] Batch [1090]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.342813,	
2017-07-18 12:34:39,513 Epoch[0] Batch [1100]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.343507,	
2017-07-18 12:34:51,795 Epoch[0] Batch [1110]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.343654,	
2017-07-18 12:35:03,969 Epoch[0] Batch [1120]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.343851,	
2017-07-18 12:35:15,946 Epoch[0] Batch [1130]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.343168,	
2017-07-18 12:35:27,780 Epoch[0] Batch [1140]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.342711,	
2017-07-18 12:35:40,119 Epoch[0] Batch [1150]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.342465,	
2017-07-18 12:35:52,233 Epoch[0] Batch [1160]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.341751,	
2017-07-18 12:36:04,766 Epoch[0] Batch [1170]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.341540,	
2017-07-18 12:36:16,762 Epoch[0] Batch [1180]	Speed: 3.33 samples/sec	Train-FCNLogLoss=1.341657,	
2017-07-18 12:36:28,990 Epoch[0] Batch [1190]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.340707,	
2017-07-18 12:36:41,034 Epoch[0] Batch [1200]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.341218,	
2017-07-18 12:36:53,160 Epoch[0] Batch [1210]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.341144,	
2017-07-18 12:37:05,552 Epoch[0] Batch [1220]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.341428,	
2017-07-18 12:37:17,714 Epoch[0] Batch [1230]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.341791,	
2017-07-18 12:37:30,038 Epoch[0] Batch [1240]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.340882,	
2017-07-18 12:37:42,490 Epoch[0] Batch [1250]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.340439,	
2017-07-18 12:37:54,810 Epoch[0] Batch [1260]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.339169,	
2017-07-18 12:38:07,049 Epoch[0] Batch [1270]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.338804,	
2017-07-18 12:38:19,198 Epoch[0] Batch [1280]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.337745,	
2017-07-18 12:38:31,420 Epoch[0] Batch [1290]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.337930,	
2017-07-18 12:38:43,990 Epoch[0] Batch [1300]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.338170,	
2017-07-18 12:38:56,112 Epoch[0] Batch [1310]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.337940,	
2017-07-18 12:39:08,336 Epoch[0] Batch [1320]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.337127,	
2017-07-18 12:39:20,530 Epoch[0] Batch [1330]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.335882,	
2017-07-18 12:39:32,995 Epoch[0] Batch [1340]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.336514,	
2017-07-18 12:39:45,454 Epoch[0] Batch [1350]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.336419,	
2017-07-18 12:39:57,855 Epoch[0] Batch [1360]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.336107,	
2017-07-18 12:40:10,697 Epoch[0] Batch [1370]	Speed: 3.11 samples/sec	Train-FCNLogLoss=1.335897,	
2017-07-18 12:40:23,277 Epoch[0] Batch [1380]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.336034,	
2017-07-18 12:40:36,027 Epoch[0] Batch [1390]	Speed: 3.14 samples/sec	Train-FCNLogLoss=1.335866,	
2017-07-18 12:40:51,753 Epoch[0] Batch [1400]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.335267,	
2017-07-18 12:41:01,785 Epoch[0] Batch [1410]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.334831,	
2017-07-18 12:41:11,105 Epoch[0] Batch [1420]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.334398,	
2017-07-18 12:41:21,218 Epoch[0] Batch [1430]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.333731,	
2017-07-18 12:41:31,061 Epoch[0] Batch [1440]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.333875,	
2017-07-18 12:41:41,043 Epoch[0] Batch [1450]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.333588,	
2017-07-18 12:41:51,025 Epoch[0] Batch [1460]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.333341,	
2017-07-18 12:42:02,247 Epoch[0] Batch [1470]	Speed: 3.56 samples/sec	Train-FCNLogLoss=1.333097,	
2017-07-18 12:42:14,506 Epoch[0] Batch [1480]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.332620,	
2017-07-18 12:42:21,697 Epoch[0] Train-FCNLogLoss=1.332368
2017-07-18 12:42:21,697 Epoch[0] Time cost=1814.386
2017-07-18 12:42:23,861 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-18 12:42:30,736 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-18 12:42:40,912 Epoch[1] Batch [10]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.288320,	
2017-07-18 12:42:49,977 Epoch[1] Batch [20]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.253172,	
2017-07-18 12:42:59,224 Epoch[1] Batch [30]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.235645,	
2017-07-18 12:43:08,601 Epoch[1] Batch [40]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.221257,	
2017-07-18 12:43:18,350 Epoch[1] Batch [50]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.222055,	
2017-07-18 12:43:27,778 Epoch[1] Batch [60]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.249513,	
2017-07-18 12:43:37,320 Epoch[1] Batch [70]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.253927,	
2017-07-18 12:43:46,755 Epoch[1] Batch [80]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.255523,	
2017-07-18 12:43:56,539 Epoch[1] Batch [90]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.260485,	
2017-07-18 12:44:05,674 Epoch[1] Batch [100]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.258812,	
2017-07-18 12:44:14,960 Epoch[1] Batch [110]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.259152,	
2017-07-18 12:44:25,118 Epoch[1] Batch [120]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.256169,	
2017-07-18 12:44:34,604 Epoch[1] Batch [130]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.259142,	
2017-07-18 12:44:44,262 Epoch[1] Batch [140]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.258775,	
2017-07-18 12:44:53,669 Epoch[1] Batch [150]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.256083,	
2017-07-18 12:45:02,993 Epoch[1] Batch [160]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.257764,	
2017-07-18 12:45:12,759 Epoch[1] Batch [170]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.268145,	
2017-07-18 12:45:22,435 Epoch[1] Batch [180]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.266374,	
2017-07-18 12:45:32,114 Epoch[1] Batch [190]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.270813,	
2017-07-18 12:45:41,774 Epoch[1] Batch [200]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.269699,	
2017-07-18 12:45:51,450 Epoch[1] Batch [210]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.269973,	
2017-07-18 12:46:01,687 Epoch[1] Batch [220]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.270016,	
2017-07-18 12:46:11,639 Epoch[1] Batch [230]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.268410,	
2017-07-18 12:46:21,412 Epoch[1] Batch [240]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.266616,	
2017-07-18 12:46:31,550 Epoch[1] Batch [250]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.266967,	
2017-07-18 12:46:40,903 Epoch[1] Batch [260]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.265915,	
2017-07-18 12:46:50,315 Epoch[1] Batch [270]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.266716,	
2017-07-18 12:47:00,190 Epoch[1] Batch [280]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.266007,	
2017-07-18 12:47:09,240 Epoch[1] Batch [290]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.266162,	
2017-07-18 12:47:18,763 Epoch[1] Batch [300]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.267726,	
2017-07-18 12:47:27,857 Epoch[1] Batch [310]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.267695,	
2017-07-18 12:47:37,738 Epoch[1] Batch [320]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.272228,	
2017-07-18 12:47:47,348 Epoch[1] Batch [330]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.270722,	
2017-07-18 12:47:56,997 Epoch[1] Batch [340]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.270528,	
2017-07-18 12:48:06,859 Epoch[1] Batch [350]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.268541,	
2017-07-18 12:48:16,663 Epoch[1] Batch [360]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.269443,	
2017-07-18 12:48:26,110 Epoch[1] Batch [370]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.267703,	
2017-07-18 12:48:35,923 Epoch[1] Batch [380]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.268828,	
2017-07-18 12:48:45,182 Epoch[1] Batch [390]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.269320,	
2017-07-18 12:48:54,838 Epoch[1] Batch [400]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.269798,	
2017-07-18 12:49:04,336 Epoch[1] Batch [410]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.269863,	
2017-07-18 12:49:14,242 Epoch[1] Batch [420]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.271485,	
2017-07-18 12:49:24,035 Epoch[1] Batch [430]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.274103,	
2017-07-18 12:49:33,940 Epoch[1] Batch [440]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.272474,	
2017-07-18 12:49:43,790 Epoch[1] Batch [450]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.272613,	
2017-07-18 12:49:54,138 Epoch[1] Batch [460]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.273009,	
2017-07-18 12:50:04,075 Epoch[1] Batch [470]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.271176,	
2017-07-18 12:50:13,952 Epoch[1] Batch [480]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.271305,	
2017-07-18 12:50:24,086 Epoch[1] Batch [490]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.273207,	
2017-07-18 12:50:34,310 Epoch[1] Batch [500]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.273207,	
2017-07-18 12:50:44,298 Epoch[1] Batch [510]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.271709,	
2017-07-18 12:50:54,259 Epoch[1] Batch [520]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.271109,	
2017-07-18 12:51:04,287 Epoch[1] Batch [530]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.270491,	
2017-07-18 12:51:14,552 Epoch[1] Batch [540]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.267319,	
2017-07-18 12:51:24,811 Epoch[1] Batch [550]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.267628,	
2017-07-18 12:51:34,488 Epoch[1] Batch [560]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.266659,	
2017-07-18 12:51:44,543 Epoch[1] Batch [570]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.265210,	
2017-07-18 12:51:54,734 Epoch[1] Batch [580]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.266741,	
2017-07-18 12:52:04,735 Epoch[1] Batch [590]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.269360,	
2017-07-18 12:52:15,346 Epoch[1] Batch [600]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.269551,	
2017-07-18 12:52:25,633 Epoch[1] Batch [610]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.270562,	
2017-07-18 12:52:36,087 Epoch[1] Batch [620]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.268619,	
2017-07-18 12:52:46,259 Epoch[1] Batch [630]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.267896,	
2017-07-18 12:52:56,864 Epoch[1] Batch [640]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.267973,	
2017-07-18 12:53:07,256 Epoch[1] Batch [650]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.267813,	
2017-07-18 12:53:17,608 Epoch[1] Batch [660]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.267638,	
2017-07-18 12:53:28,061 Epoch[1] Batch [670]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.266364,	
2017-07-18 12:53:38,667 Epoch[1] Batch [680]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.266381,	
2017-07-18 12:53:48,843 Epoch[1] Batch [690]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.266009,	
2017-07-18 12:53:58,909 Epoch[1] Batch [700]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.265607,	
2017-07-18 12:54:09,265 Epoch[1] Batch [710]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.265421,	
2017-07-18 12:54:19,723 Epoch[1] Batch [720]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.266208,	
2017-07-18 12:54:29,837 Epoch[1] Batch [730]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.266155,	
2017-07-18 12:54:39,922 Epoch[1] Batch [740]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.266087,	
2017-07-18 12:54:49,783 Epoch[1] Batch [750]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.265137,	
2017-07-18 12:55:00,289 Epoch[1] Batch [760]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.265519,	
2017-07-18 12:55:10,854 Epoch[1] Batch [770]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.265490,	
2017-07-18 12:55:21,722 Epoch[1] Batch [780]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.266118,	
2017-07-18 12:55:32,792 Epoch[1] Batch [790]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.266521,	
2017-07-18 12:55:43,301 Epoch[1] Batch [800]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.266834,	
2017-07-18 12:55:54,058 Epoch[1] Batch [810]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.267968,	
2017-07-18 12:56:04,828 Epoch[1] Batch [820]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.268298,	
2017-07-18 12:56:15,724 Epoch[1] Batch [830]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.268835,	
2017-07-18 12:56:26,427 Epoch[1] Batch [840]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.268155,	
2017-07-18 12:56:37,309 Epoch[1] Batch [850]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.268125,	
2017-07-18 12:56:48,249 Epoch[1] Batch [860]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.267197,	
2017-07-18 12:56:59,206 Epoch[1] Batch [870]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.267685,	
2017-07-18 12:57:10,306 Epoch[1] Batch [880]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.267955,	
2017-07-18 12:57:21,206 Epoch[1] Batch [890]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.268810,	
2017-07-18 12:57:32,112 Epoch[1] Batch [900]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.268998,	
2017-07-18 12:57:43,140 Epoch[1] Batch [910]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.268787,	
2017-07-18 12:57:54,491 Epoch[1] Batch [920]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.269022,	
2017-07-18 12:58:05,752 Epoch[1] Batch [930]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.269632,	
2017-07-18 12:58:16,713 Epoch[1] Batch [940]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.269985,	
2017-07-18 12:58:27,649 Epoch[1] Batch [950]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.269730,	
2017-07-18 12:58:38,884 Epoch[1] Batch [960]	Speed: 3.56 samples/sec	Train-FCNLogLoss=1.269217,	
2017-07-18 12:58:49,886 Epoch[1] Batch [970]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.268860,	
2017-07-18 12:59:00,744 Epoch[1] Batch [980]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.268458,	
2017-07-18 12:59:11,309 Epoch[1] Batch [990]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.268876,	
2017-07-18 12:59:21,654 Epoch[1] Batch [1000]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.269192,	
2017-07-18 12:59:32,141 Epoch[1] Batch [1010]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.269163,	
2017-07-18 12:59:42,934 Epoch[1] Batch [1020]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.268520,	
2017-07-18 12:59:53,361 Epoch[1] Batch [1030]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.269415,	
2017-07-18 13:00:04,371 Epoch[1] Batch [1040]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.269793,	
2017-07-18 13:00:14,986 Epoch[1] Batch [1050]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.269158,	
2017-07-18 13:00:25,523 Epoch[1] Batch [1060]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.268145,	
2017-07-18 13:00:36,143 Epoch[1] Batch [1070]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.268333,	
2017-07-18 13:00:46,446 Epoch[1] Batch [1080]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.267349,	
2017-07-18 13:00:57,513 Epoch[1] Batch [1090]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.266533,	
2017-07-18 13:01:07,911 Epoch[1] Batch [1100]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.265808,	
2017-07-18 13:01:18,224 Epoch[1] Batch [1110]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.264954,	
2017-07-18 13:01:28,788 Epoch[1] Batch [1120]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.264568,	
2017-07-18 13:01:39,330 Epoch[1] Batch [1130]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.264319,	
2017-07-18 13:01:49,596 Epoch[1] Batch [1140]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.263525,	
2017-07-18 13:01:59,553 Epoch[1] Batch [1150]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.263345,	
2017-07-18 13:02:10,132 Epoch[1] Batch [1160]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.263130,	
2017-07-18 13:02:20,784 Epoch[1] Batch [1170]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.263056,	
2017-07-18 13:02:31,269 Epoch[1] Batch [1180]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.262545,	
2017-07-18 13:02:41,797 Epoch[1] Batch [1190]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.261441,	
2017-07-18 13:02:52,303 Epoch[1] Batch [1200]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.261337,	
2017-07-18 13:03:02,729 Epoch[1] Batch [1210]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.262093,	
2017-07-18 13:03:13,124 Epoch[1] Batch [1220]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.261712,	
2017-07-18 13:03:23,709 Epoch[1] Batch [1230]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.261251,	
2017-07-18 13:03:34,620 Epoch[1] Batch [1240]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.260632,	
2017-07-18 13:03:45,147 Epoch[1] Batch [1250]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.260651,	
2017-07-18 13:03:56,039 Epoch[1] Batch [1260]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.261718,	
2017-07-18 13:04:06,000 Epoch[1] Batch [1270]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.260998,	
2017-07-18 13:04:15,998 Epoch[1] Batch [1280]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.260534,	
2017-07-18 13:04:26,183 Epoch[1] Batch [1290]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.260003,	
2017-07-18 13:04:36,020 Epoch[1] Batch [1300]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.259513,	
2017-07-18 13:04:45,878 Epoch[1] Batch [1310]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.259167,	
2017-07-18 13:04:55,321 Epoch[1] Batch [1320]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.258478,	
2017-07-18 13:05:05,645 Epoch[1] Batch [1330]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.258000,	
2017-07-18 13:05:16,265 Epoch[1] Batch [1340]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.257505,	
2017-07-18 13:05:26,937 Epoch[1] Batch [1350]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.257936,	
2017-07-18 13:05:37,282 Epoch[1] Batch [1360]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.258814,	
2017-07-18 13:05:48,354 Epoch[1] Batch [1370]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.258618,	
2017-07-18 13:05:58,703 Epoch[1] Batch [1380]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.258486,	
2017-07-18 13:06:09,077 Epoch[1] Batch [1390]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.258072,	
2017-07-18 13:06:19,204 Epoch[1] Batch [1400]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.258190,	
2017-07-18 13:06:29,016 Epoch[1] Batch [1410]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.258495,	
2017-07-18 13:06:39,237 Epoch[1] Batch [1420]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.257535,	
2017-07-18 13:06:49,783 Epoch[1] Batch [1430]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.257356,	
2017-07-18 13:07:00,009 Epoch[1] Batch [1440]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.257245,	
2017-07-18 13:07:10,041 Epoch[1] Batch [1450]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.257548,	
2017-07-18 13:07:19,931 Epoch[1] Batch [1460]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.256994,	
2017-07-18 13:07:29,816 Epoch[1] Batch [1470]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.256113,	
2017-07-18 13:07:39,396 Epoch[1] Batch [1480]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.256190,	
2017-07-18 13:07:45,190 Epoch[1] Train-FCNLogLoss=1.256519
2017-07-18 13:07:45,191 Epoch[1] Time cost=1514.455
2017-07-18 13:07:46,885 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-18 13:07:52,255 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-18 13:08:02,591 Epoch[2] Batch [10]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.246702,	
2017-07-18 13:08:11,470 Epoch[2] Batch [20]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.227217,	
2017-07-18 13:08:20,371 Epoch[2] Batch [30]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.213838,	
2017-07-18 13:08:29,519 Epoch[2] Batch [40]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.231635,	
2017-07-18 13:08:38,651 Epoch[2] Batch [50]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.251842,	
2017-07-18 13:08:47,673 Epoch[2] Batch [60]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.240890,	
2017-07-18 13:08:56,866 Epoch[2] Batch [70]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.238314,	
2017-07-18 13:09:06,033 Epoch[2] Batch [80]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.245638,	
2017-07-18 13:09:15,222 Epoch[2] Batch [90]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.244424,	
2017-07-18 13:09:24,304 Epoch[2] Batch [100]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.237009,	
2017-07-18 13:09:33,816 Epoch[2] Batch [110]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.236140,	
2017-07-18 13:09:43,176 Epoch[2] Batch [120]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.233003,	
2017-07-18 13:09:52,603 Epoch[2] Batch [130]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.226599,	
2017-07-18 13:10:01,579 Epoch[2] Batch [140]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.220167,	
2017-07-18 13:10:10,762 Epoch[2] Batch [150]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.224105,	
2017-07-18 13:10:19,896 Epoch[2] Batch [160]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.220284,	
2017-07-18 13:10:29,057 Epoch[2] Batch [170]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.220687,	
2017-07-18 13:10:38,326 Epoch[2] Batch [180]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.222688,	
2017-07-18 13:10:47,360 Epoch[2] Batch [190]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.222324,	
2017-07-18 13:10:54,491 Epoch[2] Batch [200]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.222198,	
2017-07-18 13:11:01,407 Epoch[2] Batch [210]	Speed: 5.78 samples/sec	Train-FCNLogLoss=1.221900,	
2017-07-18 13:11:08,336 Epoch[2] Batch [220]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.225448,	
2017-07-18 13:11:15,476 Epoch[2] Batch [230]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.226920,	
2017-07-18 13:11:22,619 Epoch[2] Batch [240]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.227901,	
2017-07-18 13:11:29,780 Epoch[2] Batch [250]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.229687,	
2017-07-18 13:11:36,986 Epoch[2] Batch [260]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.229155,	
2017-07-18 13:11:44,174 Epoch[2] Batch [270]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.229534,	
2017-07-18 13:11:50,874 Epoch[2] Batch [280]	Speed: 5.97 samples/sec	Train-FCNLogLoss=1.228651,	
2017-07-18 13:11:58,201 Epoch[2] Batch [290]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.231069,	
2017-07-18 13:12:05,141 Epoch[2] Batch [300]	Speed: 5.76 samples/sec	Train-FCNLogLoss=1.230768,	
2017-07-18 13:12:12,458 Epoch[2] Batch [310]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.232999,	
2017-07-18 13:12:19,732 Epoch[2] Batch [320]	Speed: 5.50 samples/sec	Train-FCNLogLoss=1.231252,	
2017-07-18 13:12:26,712 Epoch[2] Batch [330]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.236625,	
2017-07-18 13:12:33,836 Epoch[2] Batch [340]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.235772,	
2017-07-18 13:12:41,203 Epoch[2] Batch [350]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.240110,	
2017-07-18 13:12:47,974 Epoch[2] Batch [360]	Speed: 5.91 samples/sec	Train-FCNLogLoss=1.241156,	
2017-07-18 13:12:54,974 Epoch[2] Batch [370]	Speed: 5.72 samples/sec	Train-FCNLogLoss=1.243171,	
2017-07-18 13:13:01,809 Epoch[2] Batch [380]	Speed: 5.85 samples/sec	Train-FCNLogLoss=1.245079,	
2017-07-18 13:13:08,930 Epoch[2] Batch [390]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.246677,	
2017-07-18 13:13:15,796 Epoch[2] Batch [400]	Speed: 5.83 samples/sec	Train-FCNLogLoss=1.247269,	
2017-07-18 13:13:22,771 Epoch[2] Batch [410]	Speed: 5.74 samples/sec	Train-FCNLogLoss=1.248854,	
2017-07-18 13:13:30,202 Epoch[2] Batch [420]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.247694,	
2017-07-18 13:13:37,920 Epoch[2] Batch [430]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.250109,	
2017-07-18 13:13:45,567 Epoch[2] Batch [440]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.251471,	
2017-07-18 13:13:53,414 Epoch[2] Batch [450]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.251941,	
2017-07-18 13:14:00,894 Epoch[2] Batch [460]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.249184,	
2017-07-18 13:14:08,617 Epoch[2] Batch [470]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.250007,	
2017-07-18 13:14:15,624 Epoch[2] Batch [480]	Speed: 5.71 samples/sec	Train-FCNLogLoss=1.250466,	
2017-07-18 13:14:23,177 Epoch[2] Batch [490]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.250121,	
2017-07-18 13:14:31,242 Epoch[2] Batch [500]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.251889,	
2017-07-18 13:14:38,870 Epoch[2] Batch [510]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.252653,	
2017-07-18 13:14:46,894 Epoch[2] Batch [520]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.253159,	
2017-07-18 13:14:55,047 Epoch[2] Batch [530]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.255037,	
2017-07-18 13:15:02,907 Epoch[2] Batch [540]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.256069,	
2017-07-18 13:15:10,450 Epoch[2] Batch [550]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.255620,	
2017-07-18 13:15:18,288 Epoch[2] Batch [560]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.254759,	
2017-07-18 13:15:26,279 Epoch[2] Batch [570]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.256572,	
2017-07-18 13:15:33,485 Epoch[2] Batch [580]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.256831,	
2017-07-18 13:15:41,380 Epoch[2] Batch [590]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.256409,	
2017-07-18 13:15:49,322 Epoch[2] Batch [600]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.257785,	
2017-07-18 13:15:56,865 Epoch[2] Batch [610]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.257661,	
2017-07-18 13:16:04,360 Epoch[2] Batch [620]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.256838,	
2017-07-18 13:16:11,625 Epoch[2] Batch [630]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.257528,	
2017-07-18 13:16:19,407 Epoch[2] Batch [640]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.258949,	
2017-07-18 13:16:26,965 Epoch[2] Batch [650]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.259548,	
2017-07-18 13:16:34,952 Epoch[2] Batch [660]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.260895,	
2017-07-18 13:16:43,403 Epoch[2] Batch [670]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.261098,	
2017-07-18 13:16:50,948 Epoch[2] Batch [680]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.261302,	
2017-07-18 13:16:59,090 Epoch[2] Batch [690]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.262099,	
2017-07-18 13:17:06,751 Epoch[2] Batch [700]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.261917,	
2017-07-18 13:17:14,629 Epoch[2] Batch [710]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.262708,	
2017-07-18 13:17:22,453 Epoch[2] Batch [720]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.262455,	
2017-07-18 13:17:30,187 Epoch[2] Batch [730]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.264178,	
2017-07-18 13:17:38,228 Epoch[2] Batch [740]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.264194,	
2017-07-18 13:17:46,863 Epoch[2] Batch [750]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.264772,	
2017-07-18 13:17:54,950 Epoch[2] Batch [760]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.264862,	
2017-07-18 13:18:02,857 Epoch[2] Batch [770]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.265321,	
2017-07-18 13:18:11,362 Epoch[2] Batch [780]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.266260,	
2017-07-18 13:18:20,426 Epoch[2] Batch [790]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.266701,	
2017-07-18 13:18:29,224 Epoch[2] Batch [800]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.265930,	
2017-07-18 13:18:37,845 Epoch[2] Batch [810]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.264601,	
2017-07-18 13:18:46,224 Epoch[2] Batch [820]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.264541,	
2017-07-18 13:18:54,767 Epoch[2] Batch [830]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.264238,	
2017-07-18 13:19:02,692 Epoch[2] Batch [840]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.263818,	
2017-07-18 13:19:10,995 Epoch[2] Batch [850]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.263959,	
2017-07-18 13:19:19,546 Epoch[2] Batch [860]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.263259,	
2017-07-18 13:19:27,690 Epoch[2] Batch [870]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.264028,	
2017-07-18 13:19:35,996 Epoch[2] Batch [880]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.263784,	
2017-07-18 13:19:45,029 Epoch[2] Batch [890]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.263857,	
2017-07-18 13:19:53,873 Epoch[2] Batch [900]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.265253,	
2017-07-18 13:20:02,945 Epoch[2] Batch [910]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.265041,	
2017-07-18 13:20:11,431 Epoch[2] Batch [920]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.265311,	
2017-07-18 13:20:19,904 Epoch[2] Batch [930]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.264897,	
2017-07-18 13:20:28,877 Epoch[2] Batch [940]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.264465,	
2017-07-18 13:20:37,627 Epoch[2] Batch [950]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.264665,	
2017-07-18 13:20:46,435 Epoch[2] Batch [960]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.265398,	
2017-07-18 13:20:55,022 Epoch[2] Batch [970]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.265376,	
2017-07-18 13:21:03,411 Epoch[2] Batch [980]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.265247,	
2017-07-18 13:21:12,514 Epoch[2] Batch [990]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.264873,	
2017-07-18 13:21:21,450 Epoch[2] Batch [1000]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.264615,	
2017-07-18 13:21:30,356 Epoch[2] Batch [1010]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.264694,	
2017-07-18 13:21:39,089 Epoch[2] Batch [1020]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.263827,	
2017-07-18 13:21:47,707 Epoch[2] Batch [1030]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.263174,	
2017-07-18 13:21:56,453 Epoch[2] Batch [1040]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.263268,	
2017-07-18 13:22:05,387 Epoch[2] Batch [1050]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.262713,	
2017-07-18 13:22:14,478 Epoch[2] Batch [1060]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.262319,	
2017-07-18 13:22:23,866 Epoch[2] Batch [1070]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.262350,	
2017-07-18 13:22:33,140 Epoch[2] Batch [1080]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.261326,	
2017-07-18 13:22:42,529 Epoch[2] Batch [1090]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.261218,	
2017-07-18 13:22:51,763 Epoch[2] Batch [1100]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.260213,	
2017-07-18 13:23:01,184 Epoch[2] Batch [1110]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.260666,	
2017-07-18 13:23:10,643 Epoch[2] Batch [1120]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.260815,	
2017-07-18 13:23:20,010 Epoch[2] Batch [1130]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.260987,	
2017-07-18 13:23:28,900 Epoch[2] Batch [1140]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.260212,	
2017-07-18 13:23:38,232 Epoch[2] Batch [1150]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.260629,	
2017-07-18 13:23:47,758 Epoch[2] Batch [1160]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.260048,	
2017-07-18 13:23:57,203 Epoch[2] Batch [1170]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.260941,	
2017-07-18 13:24:06,391 Epoch[2] Batch [1180]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.260661,	
2017-07-18 13:24:15,291 Epoch[2] Batch [1190]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.260857,	
2017-07-18 13:24:24,830 Epoch[2] Batch [1200]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.260609,	
2017-07-18 13:24:34,148 Epoch[2] Batch [1210]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.259802,	
2017-07-18 13:24:43,682 Epoch[2] Batch [1220]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.259222,	
2017-07-18 13:24:53,020 Epoch[2] Batch [1230]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.259178,	
2017-07-18 13:25:02,139 Epoch[2] Batch [1240]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.258562,	
2017-07-18 13:25:11,466 Epoch[2] Batch [1250]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.258441,	
2017-07-18 13:25:21,145 Epoch[2] Batch [1260]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.258019,	
2017-07-18 13:25:30,910 Epoch[2] Batch [1270]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.258762,	
2017-07-18 13:25:40,236 Epoch[2] Batch [1280]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.257921,	
2017-07-18 13:25:49,674 Epoch[2] Batch [1290]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.258007,	
2017-07-18 13:25:59,162 Epoch[2] Batch [1300]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.257990,	
2017-07-18 13:26:08,471 Epoch[2] Batch [1310]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.257883,	
2017-07-18 13:26:18,000 Epoch[2] Batch [1320]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.257788,	
2017-07-18 13:26:27,703 Epoch[2] Batch [1330]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.256920,	
2017-07-18 13:26:37,350 Epoch[2] Batch [1340]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.256349,	
2017-07-18 13:26:46,645 Epoch[2] Batch [1350]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.256462,	
2017-07-18 13:26:56,399 Epoch[2] Batch [1360]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.256101,	
2017-07-18 13:27:05,977 Epoch[2] Batch [1370]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.255722,	
2017-07-18 13:27:16,156 Epoch[2] Batch [1380]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.255914,	
2017-07-18 13:27:29,016 Epoch[2] Batch [1390]	Speed: 3.11 samples/sec	Train-FCNLogLoss=1.255471,	
2017-07-18 13:27:42,312 Epoch[2] Batch [1400]	Speed: 3.01 samples/sec	Train-FCNLogLoss=1.255492,	
2017-07-18 13:27:52,078 Epoch[2] Batch [1410]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.255344,	
2017-07-18 13:28:01,998 Epoch[2] Batch [1420]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.254904,	
2017-07-18 13:28:11,808 Epoch[2] Batch [1430]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.254476,	
2017-07-18 13:28:21,569 Epoch[2] Batch [1440]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.254833,	
2017-07-18 13:28:31,031 Epoch[2] Batch [1450]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.254363,	
2017-07-18 13:28:41,196 Epoch[2] Batch [1460]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.253759,	
2017-07-18 13:28:51,058 Epoch[2] Batch [1470]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.253469,	
2017-07-18 13:29:01,048 Epoch[2] Batch [1480]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.253486,	
2017-07-18 13:29:07,038 Epoch[2] Train-FCNLogLoss=1.253157
2017-07-18 13:29:07,038 Epoch[2] Time cost=1274.783
2017-07-18 13:29:08,663 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-18 13:29:12,895 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-18 13:29:21,563 Epoch[3] Batch [10]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.355576,	
2017-07-18 13:29:29,126 Epoch[3] Batch [20]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.285466,	
2017-07-18 13:29:36,759 Epoch[3] Batch [30]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.283846,	
2017-07-18 13:29:44,664 Epoch[3] Batch [40]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.271304,	
2017-07-18 13:29:52,279 Epoch[3] Batch [50]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.262101,	
2017-07-18 13:30:00,000 Epoch[3] Batch [60]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.252334,	
2017-07-18 13:30:10,210 Epoch[3] Batch [70]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.257575,	
2017-07-18 13:30:27,472 Epoch[3] Batch [80]	Speed: 2.32 samples/sec	Train-FCNLogLoss=1.274755,	
2017-07-18 13:30:44,441 Epoch[3] Batch [90]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.268406,	
2017-07-18 13:31:00,931 Epoch[3] Batch [100]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.272644,	
2017-07-18 13:31:18,335 Epoch[3] Batch [110]	Speed: 2.30 samples/sec	Train-FCNLogLoss=1.275455,	
2017-07-18 13:31:35,672 Epoch[3] Batch [120]	Speed: 2.31 samples/sec	Train-FCNLogLoss=1.274493,	
2017-07-18 13:31:53,800 Epoch[3] Batch [130]	Speed: 2.21 samples/sec	Train-FCNLogLoss=1.274656,	
2017-07-18 13:32:08,555 Epoch[3] Batch [140]	Speed: 2.71 samples/sec	Train-FCNLogLoss=1.270422,	
2017-07-18 13:32:25,542 Epoch[3] Batch [150]	Speed: 2.35 samples/sec	Train-FCNLogLoss=1.268922,	
2017-07-18 13:32:42,002 Epoch[3] Batch [160]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.272006,	
2017-07-18 13:32:56,256 Epoch[3] Batch [170]	Speed: 2.81 samples/sec	Train-FCNLogLoss=1.263880,	
2017-07-18 13:33:04,595 Epoch[3] Batch [180]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.265851,	
2017-07-18 13:33:12,475 Epoch[3] Batch [190]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.268431,	
2017-07-18 13:33:20,553 Epoch[3] Batch [200]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.271750,	
2017-07-18 13:33:28,454 Epoch[3] Batch [210]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.266514,	
2017-07-18 13:33:36,740 Epoch[3] Batch [220]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.265219,	
2017-07-18 13:33:44,936 Epoch[3] Batch [230]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.264812,	
2017-07-18 13:33:53,307 Epoch[3] Batch [240]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.262483,	
2017-07-18 13:34:01,267 Epoch[3] Batch [250]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.258946,	
2017-07-18 13:34:09,899 Epoch[3] Batch [260]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.253476,	
2017-07-18 13:34:18,524 Epoch[3] Batch [270]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.254251,	
2017-07-18 13:34:27,706 Epoch[3] Batch [280]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.256393,	
2017-07-18 13:34:36,684 Epoch[3] Batch [290]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.257057,	
2017-07-18 13:34:45,331 Epoch[3] Batch [300]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.259769,	
2017-07-18 13:34:53,538 Epoch[3] Batch [310]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.262140,	
2017-07-18 13:35:01,474 Epoch[3] Batch [320]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.260444,	
2017-07-18 13:35:10,168 Epoch[3] Batch [330]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.261909,	
2017-07-18 13:35:18,421 Epoch[3] Batch [340]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.261814,	
2017-07-18 13:35:26,479 Epoch[3] Batch [350]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.260564,	
2017-07-18 13:35:34,960 Epoch[3] Batch [360]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.259224,	
2017-07-18 13:35:43,668 Epoch[3] Batch [370]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.261761,	
2017-07-18 13:35:51,807 Epoch[3] Batch [380]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.259701,	
2017-07-18 13:36:00,008 Epoch[3] Batch [390]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.260723,	
2017-07-18 13:36:08,110 Epoch[3] Batch [400]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.259129,	
2017-07-18 13:36:16,358 Epoch[3] Batch [410]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.257435,	
2017-07-18 13:36:24,906 Epoch[3] Batch [420]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.258988,	
2017-07-18 13:36:39,777 Epoch[3] Batch [430]	Speed: 2.69 samples/sec	Train-FCNLogLoss=1.256294,	
2017-07-18 13:36:55,089 Epoch[3] Batch [440]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.256951,	
2017-07-18 13:37:12,068 Epoch[3] Batch [450]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.256477,	
2017-07-18 13:37:27,683 Epoch[3] Batch [460]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.255421,	
2017-07-18 13:37:42,800 Epoch[3] Batch [470]	Speed: 2.65 samples/sec	Train-FCNLogLoss=1.256710,	
2017-07-18 13:37:58,161 Epoch[3] Batch [480]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.258022,	
2017-07-18 13:38:13,028 Epoch[3] Batch [490]	Speed: 2.69 samples/sec	Train-FCNLogLoss=1.259226,	
2017-07-18 13:38:29,120 Epoch[3] Batch [500]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.258951,	
2017-07-18 13:38:45,278 Epoch[3] Batch [510]	Speed: 2.48 samples/sec	Train-FCNLogLoss=1.260816,	
2017-07-18 13:39:00,618 Epoch[3] Batch [520]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.260010,	
2017-07-18 13:39:16,239 Epoch[3] Batch [530]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.259520,	
2017-07-18 13:39:31,769 Epoch[3] Batch [540]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.259128,	
2017-07-18 13:39:47,552 Epoch[3] Batch [550]	Speed: 2.53 samples/sec	Train-FCNLogLoss=1.259581,	
2017-07-18 13:39:57,640 Epoch[3] Batch [560]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.259413,	
2017-07-18 13:40:06,094 Epoch[3] Batch [570]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.258669,	
2017-07-18 13:40:14,174 Epoch[3] Batch [580]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.257115,	
2017-07-18 13:40:23,281 Epoch[3] Batch [590]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.257007,	
2017-07-18 13:40:32,031 Epoch[3] Batch [600]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.256381,	
2017-07-18 13:40:40,699 Epoch[3] Batch [610]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.256292,	
2017-07-18 13:40:49,423 Epoch[3] Batch [620]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.255799,	
2017-07-18 13:40:57,768 Epoch[3] Batch [630]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.254870,	
2017-07-18 13:41:06,238 Epoch[3] Batch [640]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.254746,	
2017-07-18 13:41:15,211 Epoch[3] Batch [650]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.256384,	
2017-07-18 13:41:23,916 Epoch[3] Batch [660]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.257094,	
2017-07-18 13:41:32,587 Epoch[3] Batch [670]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.256638,	
2017-07-18 13:41:41,836 Epoch[3] Batch [680]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.257021,	
2017-07-18 13:41:51,677 Epoch[3] Batch [690]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.256284,	
2017-07-18 13:42:01,053 Epoch[3] Batch [700]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.256149,	
2017-07-18 13:42:11,090 Epoch[3] Batch [710]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.256314,	
2017-07-18 13:42:21,010 Epoch[3] Batch [720]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.258490,	
2017-07-18 13:42:30,967 Epoch[3] Batch [730]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.258288,	
2017-07-18 13:42:40,918 Epoch[3] Batch [740]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.258225,	
2017-07-18 13:42:50,642 Epoch[3] Batch [750]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.258662,	
2017-07-18 13:43:00,937 Epoch[3] Batch [760]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.258468,	
2017-07-18 13:43:11,335 Epoch[3] Batch [770]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.260112,	
2017-07-18 13:43:21,022 Epoch[3] Batch [780]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.259149,	
2017-07-18 13:43:30,455 Epoch[3] Batch [790]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.259012,	
2017-07-18 13:43:40,164 Epoch[3] Batch [800]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.260052,	
2017-07-18 13:43:49,920 Epoch[3] Batch [810]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.260336,	
2017-07-18 13:43:59,755 Epoch[3] Batch [820]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.260501,	
2017-07-18 13:44:08,791 Epoch[3] Batch [830]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.261829,	
2017-07-18 13:44:17,868 Epoch[3] Batch [840]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.261391,	
2017-07-18 13:44:26,954 Epoch[3] Batch [850]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.260988,	
2017-07-18 13:44:35,659 Epoch[3] Batch [860]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.260890,	
2017-07-18 13:44:44,208 Epoch[3] Batch [870]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.261006,	
2017-07-18 13:44:53,525 Epoch[3] Batch [880]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.259512,	
2017-07-18 13:45:03,306 Epoch[3] Batch [890]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.260849,	
2017-07-18 13:45:13,190 Epoch[3] Batch [900]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.259637,	
2017-07-18 13:45:22,552 Epoch[3] Batch [910]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.258350,	
2017-07-18 13:45:31,526 Epoch[3] Batch [920]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.257993,	
2017-07-18 13:45:40,895 Epoch[3] Batch [930]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.257868,	
2017-07-18 13:45:49,994 Epoch[3] Batch [940]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.257271,	
2017-07-18 13:45:59,291 Epoch[3] Batch [950]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.256521,	
2017-07-18 13:46:09,316 Epoch[3] Batch [960]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.256399,	
2017-07-18 13:46:19,173 Epoch[3] Batch [970]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.256712,	
2017-07-18 13:46:28,875 Epoch[3] Batch [980]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.256079,	
2017-07-18 13:46:38,893 Epoch[3] Batch [990]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.255469,	
2017-07-18 13:46:48,256 Epoch[3] Batch [1000]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.255053,	
2017-07-18 13:46:58,540 Epoch[3] Batch [1010]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.255362,	
2017-07-18 13:47:08,495 Epoch[3] Batch [1020]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.255499,	
2017-07-18 13:47:18,881 Epoch[3] Batch [1030]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.255753,	
2017-07-18 13:47:28,725 Epoch[3] Batch [1040]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.255772,	
2017-07-18 13:47:38,542 Epoch[3] Batch [1050]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.255058,	
2017-07-18 13:47:47,913 Epoch[3] Batch [1060]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.254390,	
2017-07-18 13:47:57,615 Epoch[3] Batch [1070]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.253602,	
2017-07-18 13:48:07,178 Epoch[3] Batch [1080]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.253172,	
2017-07-18 13:48:17,016 Epoch[3] Batch [1090]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.253208,	
2017-07-18 13:48:26,746 Epoch[3] Batch [1100]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.253144,	
2017-07-18 13:48:36,837 Epoch[3] Batch [1110]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.253340,	
2017-07-18 13:48:46,988 Epoch[3] Batch [1120]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.253463,	
2017-07-18 13:48:57,123 Epoch[3] Batch [1130]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.252487,	
2017-07-18 13:49:06,894 Epoch[3] Batch [1140]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.253677,	
2017-07-18 13:49:16,499 Epoch[3] Batch [1150]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.253404,	
2017-07-18 13:49:26,723 Epoch[3] Batch [1160]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.253732,	
2017-07-18 13:49:42,465 Epoch[3] Batch [1170]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.254309,	
2017-07-18 13:50:01,996 Epoch[3] Batch [1180]	Speed: 2.05 samples/sec	Train-FCNLogLoss=1.254176,	
2017-07-18 13:50:19,943 Epoch[3] Batch [1190]	Speed: 2.23 samples/sec	Train-FCNLogLoss=1.252826,	
2017-07-18 13:50:36,653 Epoch[3] Batch [1200]	Speed: 2.39 samples/sec	Train-FCNLogLoss=1.254213,	
2017-07-18 13:50:56,071 Epoch[3] Batch [1210]	Speed: 2.06 samples/sec	Train-FCNLogLoss=1.254261,	
2017-07-18 13:51:12,966 Epoch[3] Batch [1220]	Speed: 2.37 samples/sec	Train-FCNLogLoss=1.254180,	
2017-07-18 13:51:30,436 Epoch[3] Batch [1230]	Speed: 2.29 samples/sec	Train-FCNLogLoss=1.254696,	
2017-07-18 13:51:48,235 Epoch[3] Batch [1240]	Speed: 2.25 samples/sec	Train-FCNLogLoss=1.254374,	
2017-07-18 13:52:06,796 Epoch[3] Batch [1250]	Speed: 2.16 samples/sec	Train-FCNLogLoss=1.254071,	
2017-07-18 13:52:25,580 Epoch[3] Batch [1260]	Speed: 2.13 samples/sec	Train-FCNLogLoss=1.253974,	
2017-07-18 13:52:42,166 Epoch[3] Batch [1270]	Speed: 2.41 samples/sec	Train-FCNLogLoss=1.253404,	
2017-07-18 13:53:01,119 Epoch[3] Batch [1280]	Speed: 2.11 samples/sec	Train-FCNLogLoss=1.252791,	
2017-07-18 13:53:20,167 Epoch[3] Batch [1290]	Speed: 2.10 samples/sec	Train-FCNLogLoss=1.251877,	
2017-07-18 13:53:38,372 Epoch[3] Batch [1300]	Speed: 2.20 samples/sec	Train-FCNLogLoss=1.251688,	
2017-07-18 13:53:55,694 Epoch[3] Batch [1310]	Speed: 2.31 samples/sec	Train-FCNLogLoss=1.251918,	
2017-07-18 13:54:13,676 Epoch[3] Batch [1320]	Speed: 2.22 samples/sec	Train-FCNLogLoss=1.251752,	
2017-07-18 13:54:31,955 Epoch[3] Batch [1330]	Speed: 2.19 samples/sec	Train-FCNLogLoss=1.250695,	
2017-07-18 13:54:50,032 Epoch[3] Batch [1340]	Speed: 2.21 samples/sec	Train-FCNLogLoss=1.250174,	
2017-07-18 13:55:06,913 Epoch[3] Batch [1350]	Speed: 2.37 samples/sec	Train-FCNLogLoss=1.249819,	
2017-07-18 13:55:26,822 Epoch[3] Batch [1360]	Speed: 2.01 samples/sec	Train-FCNLogLoss=1.249533,	
2017-07-18 13:55:45,663 Epoch[3] Batch [1370]	Speed: 2.12 samples/sec	Train-FCNLogLoss=1.249266,	
2017-07-18 13:56:05,769 Epoch[3] Batch [1380]	Speed: 1.99 samples/sec	Train-FCNLogLoss=1.249309,	
2017-07-18 13:56:23,391 Epoch[3] Batch [1390]	Speed: 2.27 samples/sec	Train-FCNLogLoss=1.249903,	
2017-07-18 13:56:41,400 Epoch[3] Batch [1400]	Speed: 2.22 samples/sec	Train-FCNLogLoss=1.249476,	
2017-07-18 13:56:59,951 Epoch[3] Batch [1410]	Speed: 2.16 samples/sec	Train-FCNLogLoss=1.250091,	
2017-07-18 13:57:18,045 Epoch[3] Batch [1420]	Speed: 2.21 samples/sec	Train-FCNLogLoss=1.250296,	
2017-07-18 13:57:35,880 Epoch[3] Batch [1430]	Speed: 2.24 samples/sec	Train-FCNLogLoss=1.249731,	
2017-07-18 13:57:52,945 Epoch[3] Batch [1440]	Speed: 2.34 samples/sec	Train-FCNLogLoss=1.249516,	
2017-07-18 13:58:10,764 Epoch[3] Batch [1450]	Speed: 2.24 samples/sec	Train-FCNLogLoss=1.248900,	
2017-07-18 13:58:29,484 Epoch[3] Batch [1460]	Speed: 2.14 samples/sec	Train-FCNLogLoss=1.249313,	
2017-07-18 13:58:47,560 Epoch[3] Batch [1470]	Speed: 2.21 samples/sec	Train-FCNLogLoss=1.249010,	
2017-07-18 13:59:05,592 Epoch[3] Batch [1480]	Speed: 2.22 samples/sec	Train-FCNLogLoss=1.249266,	
2017-07-18 13:59:15,165 Epoch[3] Train-FCNLogLoss=1.249009
2017-07-18 13:59:15,165 Epoch[3] Time cost=1802.270
2017-07-18 13:59:16,765 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.params"
2017-07-18 13:59:22,167 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.states"
2017-07-18 13:59:38,824 Epoch[4] Batch [10]	Speed: 2.57 samples/sec	Train-FCNLogLoss=1.256669,	
2017-07-18 13:59:52,820 Epoch[4] Batch [20]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.311647,	
2017-07-18 14:00:10,050 Epoch[4] Batch [30]	Speed: 2.32 samples/sec	Train-FCNLogLoss=1.276345,	
2017-07-18 14:00:26,878 Epoch[4] Batch [40]	Speed: 2.38 samples/sec	Train-FCNLogLoss=1.270496,	
2017-07-18 14:00:45,951 Epoch[4] Batch [50]	Speed: 2.10 samples/sec	Train-FCNLogLoss=1.257175,	
2017-07-18 14:01:02,015 Epoch[4] Batch [60]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.259051,	
2017-07-18 14:01:18,063 Epoch[4] Batch [70]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.257122,	
2017-07-18 14:01:34,786 Epoch[4] Batch [80]	Speed: 2.39 samples/sec	Train-FCNLogLoss=1.260358,	
2017-07-18 14:01:53,379 Epoch[4] Batch [90]	Speed: 2.15 samples/sec	Train-FCNLogLoss=1.255977,	
2017-07-18 14:02:09,826 Epoch[4] Batch [100]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.256956,	
2017-07-18 14:02:27,000 Epoch[4] Batch [110]	Speed: 2.33 samples/sec	Train-FCNLogLoss=1.257919,	
2017-07-18 14:02:44,137 Epoch[4] Batch [120]	Speed: 2.33 samples/sec	Train-FCNLogLoss=1.265502,	
2017-07-18 14:03:02,177 Epoch[4] Batch [130]	Speed: 2.22 samples/sec	Train-FCNLogLoss=1.259901,	
2017-07-18 14:03:20,293 Epoch[4] Batch [140]	Speed: 2.21 samples/sec	Train-FCNLogLoss=1.254651,	
2017-07-18 14:03:35,092 Epoch[4] Batch [150]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.250145,	
2017-07-18 14:03:53,120 Epoch[4] Batch [160]	Speed: 2.22 samples/sec	Train-FCNLogLoss=1.252958,	
2017-07-18 14:04:09,812 Epoch[4] Batch [170]	Speed: 2.40 samples/sec	Train-FCNLogLoss=1.253440,	
2017-07-18 14:04:25,571 Epoch[4] Batch [180]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.251785,	
2017-07-18 14:04:42,275 Epoch[4] Batch [190]	Speed: 2.39 samples/sec	Train-FCNLogLoss=1.254015,	
2017-07-18 14:05:00,015 Epoch[4] Batch [200]	Speed: 2.25 samples/sec	Train-FCNLogLoss=1.252723,	
2017-07-18 14:05:17,219 Epoch[4] Batch [210]	Speed: 2.33 samples/sec	Train-FCNLogLoss=1.251886,	
2017-07-18 14:05:35,108 Epoch[4] Batch [220]	Speed: 2.24 samples/sec	Train-FCNLogLoss=1.251052,	
2017-07-18 14:05:50,119 Epoch[4] Batch [230]	Speed: 2.66 samples/sec	Train-FCNLogLoss=1.253139,	
2017-07-18 14:06:07,044 Epoch[4] Batch [240]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.252505,	
2017-07-18 14:06:21,723 Epoch[4] Batch [250]	Speed: 2.73 samples/sec	Train-FCNLogLoss=1.255110,	
2017-07-18 14:06:30,670 Epoch[4] Batch [260]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.254219,	
2017-07-18 14:06:39,532 Epoch[4] Batch [270]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.256000,	
2017-07-18 14:06:48,389 Epoch[4] Batch [280]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.254657,	
2017-07-18 14:06:57,008 Epoch[4] Batch [290]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.253380,	
2017-07-18 14:07:05,501 Epoch[4] Batch [300]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.251195,	
2017-07-18 14:07:14,023 Epoch[4] Batch [310]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.249715,	
2017-07-18 14:07:22,549 Epoch[4] Batch [320]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.249787,	
2017-07-18 14:07:30,704 Epoch[4] Batch [330]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.252454,	
2017-07-18 14:07:39,122 Epoch[4] Batch [340]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.253554,	
2017-07-18 14:07:47,672 Epoch[4] Batch [350]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.252785,	
2017-07-18 14:07:56,242 Epoch[4] Batch [360]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.252705,	
2017-07-18 14:08:04,372 Epoch[4] Batch [370]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.252936,	
2017-07-18 14:08:12,659 Epoch[4] Batch [380]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.251376,	
2017-07-18 14:08:20,964 Epoch[4] Batch [390]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.248360,	
2017-07-18 14:08:29,245 Epoch[4] Batch [400]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.250650,	
2017-07-18 14:08:37,807 Epoch[4] Batch [410]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.248946,	
2017-07-18 14:08:46,662 Epoch[4] Batch [420]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.247513,	
2017-07-18 14:08:55,267 Epoch[4] Batch [430]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.249202,	
2017-07-18 14:09:03,932 Epoch[4] Batch [440]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.250815,	
2017-07-18 14:09:12,492 Epoch[4] Batch [450]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.251878,	
2017-07-18 14:09:22,271 Epoch[4] Batch [460]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.251512,	
2017-07-18 14:09:31,701 Epoch[4] Batch [470]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.255574,	
2017-07-18 14:09:41,634 Epoch[4] Batch [480]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.257031,	
2017-07-18 14:09:51,192 Epoch[4] Batch [490]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.256797,	
2017-07-18 14:10:01,262 Epoch[4] Batch [500]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.254831,	
2017-07-18 14:10:11,015 Epoch[4] Batch [510]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.255803,	
2017-07-18 14:10:21,047 Epoch[4] Batch [520]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.254461,	
2017-07-18 14:10:30,863 Epoch[4] Batch [530]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.255110,	
2017-07-18 14:10:40,190 Epoch[4] Batch [540]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.256175,	
2017-07-18 14:10:49,301 Epoch[4] Batch [550]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.257594,	
2017-07-18 14:10:58,994 Epoch[4] Batch [560]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.257264,	
2017-07-18 14:11:08,166 Epoch[4] Batch [570]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.258995,	
2017-07-18 14:11:17,959 Epoch[4] Batch [580]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.259360,	
2017-07-18 14:11:27,883 Epoch[4] Batch [590]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.258980,	
2017-07-18 14:11:36,962 Epoch[4] Batch [600]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.259046,	
2017-07-18 14:11:46,808 Epoch[4] Batch [610]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.259378,	
2017-07-18 14:11:56,313 Epoch[4] Batch [620]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.258170,	
2017-07-18 14:12:06,289 Epoch[4] Batch [630]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.257209,	
2017-07-18 14:12:15,321 Epoch[4] Batch [640]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.256830,	
2017-07-18 14:12:24,897 Epoch[4] Batch [650]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.256819,	
2017-07-18 14:12:35,134 Epoch[4] Batch [660]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.256228,	
2017-07-18 14:12:45,285 Epoch[4] Batch [670]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.256661,	
2017-07-18 14:12:55,405 Epoch[4] Batch [680]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.255435,	
2017-07-18 14:13:04,804 Epoch[4] Batch [690]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.256393,	
2017-07-18 14:13:14,407 Epoch[4] Batch [700]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.257845,	
2017-07-18 14:13:23,994 Epoch[4] Batch [710]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.257671,	
2017-07-18 14:13:33,566 Epoch[4] Batch [720]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.258369,	
2017-07-18 14:13:43,225 Epoch[4] Batch [730]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.258691,	
2017-07-18 14:13:52,529 Epoch[4] Batch [740]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.257418,	
2017-07-18 14:14:02,749 Epoch[4] Batch [750]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.258399,	
2017-07-18 14:14:12,556 Epoch[4] Batch [760]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.258256,	
2017-07-18 14:14:22,126 Epoch[4] Batch [770]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.257589,	
2017-07-18 14:14:31,370 Epoch[4] Batch [780]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.256970,	
2017-07-18 14:14:40,700 Epoch[4] Batch [790]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.257284,	
2017-07-18 14:14:49,996 Epoch[4] Batch [800]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.257597,	
2017-07-18 14:14:59,287 Epoch[4] Batch [810]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.257729,	
2017-07-18 14:15:08,503 Epoch[4] Batch [820]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.257432,	
2017-07-18 14:15:18,222 Epoch[4] Batch [830]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.257823,	
2017-07-18 14:15:27,459 Epoch[4] Batch [840]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.256658,	
2017-07-18 14:15:36,599 Epoch[4] Batch [850]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.256151,	
2017-07-18 14:15:45,563 Epoch[4] Batch [860]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.256972,	
2017-07-18 14:15:54,906 Epoch[4] Batch [870]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.256207,	
2017-07-18 14:16:04,131 Epoch[4] Batch [880]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.255727,	
2017-07-18 14:16:13,387 Epoch[4] Batch [890]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.255214,	
2017-07-18 14:16:22,357 Epoch[4] Batch [900]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.254962,	
2017-07-18 14:16:31,620 Epoch[4] Batch [910]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.254501,	
2017-07-18 14:16:40,910 Epoch[4] Batch [920]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.254442,	
2017-07-18 14:16:50,189 Epoch[4] Batch [930]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.254046,	
2017-07-18 14:16:59,341 Epoch[4] Batch [940]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.252356,	
2017-07-18 14:17:08,837 Epoch[4] Batch [950]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.251346,	
2017-07-18 14:17:18,293 Epoch[4] Batch [960]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.250336,	
2017-07-18 14:17:27,485 Epoch[4] Batch [970]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.250376,	
2017-07-18 14:17:37,119 Epoch[4] Batch [980]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.250309,	
2017-07-18 14:17:46,197 Epoch[4] Batch [990]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.250999,	
2017-07-18 14:17:55,680 Epoch[4] Batch [1000]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.251010,	
2017-07-18 14:18:05,319 Epoch[4] Batch [1010]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.251070,	
2017-07-18 14:18:14,666 Epoch[4] Batch [1020]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.251010,	
2017-07-18 14:18:23,903 Epoch[4] Batch [1030]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.251166,	
2017-07-18 14:18:33,083 Epoch[4] Batch [1040]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.251265,	
2017-07-18 14:18:42,353 Epoch[4] Batch [1050]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.251605,	
2017-07-18 14:18:51,600 Epoch[4] Batch [1060]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.251189,	
2017-07-18 14:19:00,952 Epoch[4] Batch [1070]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.250318,	
2017-07-18 14:19:10,482 Epoch[4] Batch [1080]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.249521,	
2017-07-18 14:19:19,974 Epoch[4] Batch [1090]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.249039,	
2017-07-18 14:19:29,900 Epoch[4] Batch [1100]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.249188,	
2017-07-18 14:19:39,597 Epoch[4] Batch [1110]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.249666,	
2017-07-18 14:19:49,300 Epoch[4] Batch [1120]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.249239,	
2017-07-18 14:19:59,354 Epoch[4] Batch [1130]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.248399,	
2017-07-18 14:20:08,958 Epoch[4] Batch [1140]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.248153,	
2017-07-18 14:20:18,816 Epoch[4] Batch [1150]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.248615,	
2017-07-18 14:20:28,791 Epoch[4] Batch [1160]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.248715,	
2017-07-18 14:20:38,848 Epoch[4] Batch [1170]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.248932,	
2017-07-18 14:20:48,652 Epoch[4] Batch [1180]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.248550,	
2017-07-18 14:20:58,667 Epoch[4] Batch [1190]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.248477,	
2017-07-18 14:21:08,490 Epoch[4] Batch [1200]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.248620,	
2017-07-18 14:21:18,513 Epoch[4] Batch [1210]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.247807,	
2017-07-18 14:21:28,293 Epoch[4] Batch [1220]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.247539,	
2017-07-18 14:21:38,006 Epoch[4] Batch [1230]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.247720,	
2017-07-18 14:21:47,634 Epoch[4] Batch [1240]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.246856,	
2017-07-18 14:21:57,423 Epoch[4] Batch [1250]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.246761,	
2017-07-18 14:22:07,388 Epoch[4] Batch [1260]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.247233,	
2017-07-18 14:22:16,778 Epoch[4] Batch [1270]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.247551,	
2017-07-18 14:22:25,772 Epoch[4] Batch [1280]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.248106,	
2017-07-18 14:22:35,359 Epoch[4] Batch [1290]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.248611,	
2017-07-18 14:22:44,796 Epoch[4] Batch [1300]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.247985,	
2017-07-18 14:22:52,776 Epoch[4] Batch [1310]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.247165,	
2017-07-18 14:23:00,839 Epoch[4] Batch [1320]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.246656,	
2017-07-18 14:23:08,880 Epoch[4] Batch [1330]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.247456,	
2017-07-18 14:23:16,734 Epoch[4] Batch [1340]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.247435,	
2017-07-18 14:23:25,083 Epoch[4] Batch [1350]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.247302,	
2017-07-18 14:23:33,757 Epoch[4] Batch [1360]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.247704,	
2017-07-18 14:23:41,715 Epoch[4] Batch [1370]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.247948,	
2017-07-18 14:23:49,672 Epoch[4] Batch [1380]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.247963,	
2017-07-18 14:23:58,351 Epoch[4] Batch [1390]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.247795,	
2017-07-18 14:24:07,136 Epoch[4] Batch [1400]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.247617,	
2017-07-18 14:24:15,861 Epoch[4] Batch [1410]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.247665,	
2017-07-18 14:24:24,329 Epoch[4] Batch [1420]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.247226,	
2017-07-18 14:24:33,016 Epoch[4] Batch [1430]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.247077,	
2017-07-18 14:24:41,796 Epoch[4] Batch [1440]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.246965,	
2017-07-18 14:24:50,645 Epoch[4] Batch [1450]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.245975,	
2017-07-18 14:24:59,292 Epoch[4] Batch [1460]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.245604,	
2017-07-18 14:25:08,129 Epoch[4] Batch [1470]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.245192,	
2017-07-18 14:25:16,891 Epoch[4] Batch [1480]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.245665,	
2017-07-18 14:25:21,952 Epoch[4] Train-FCNLogLoss=1.246092
2017-07-18 14:25:21,953 Epoch[4] Time cost=1559.785
2017-07-18 14:25:23,752 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.params"
2017-07-18 14:25:28,915 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.states"
2017-07-18 14:25:37,495 Epoch[5] Batch [10]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.267277,	
2017-07-18 14:25:44,929 Epoch[5] Batch [20]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.273158,	
2017-07-18 14:25:52,002 Epoch[5] Batch [30]	Speed: 5.66 samples/sec	Train-FCNLogLoss=1.281466,	
2017-07-18 14:25:59,165 Epoch[5] Batch [40]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.262410,	
2017-07-18 14:26:06,376 Epoch[5] Batch [50]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.241474,	
2017-07-18 14:26:13,666 Epoch[5] Batch [60]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.257236,	
2017-07-18 14:26:20,903 Epoch[5] Batch [70]	Speed: 5.53 samples/sec	Train-FCNLogLoss=1.265828,	
2017-07-18 14:26:28,285 Epoch[5] Batch [80]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.257182,	
2017-07-18 14:26:35,401 Epoch[5] Batch [90]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.245444,	
2017-07-18 14:26:43,076 Epoch[5] Batch [100]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.246705,	
2017-07-18 14:26:50,330 Epoch[5] Batch [110]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.244334,	
2017-07-18 14:26:58,048 Epoch[5] Batch [120]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.248022,	
2017-07-18 14:27:05,743 Epoch[5] Batch [130]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.243867,	
2017-07-18 14:27:13,609 Epoch[5] Batch [140]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.241157,	
2017-07-18 14:27:21,613 Epoch[5] Batch [150]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.244583,	
2017-07-18 14:27:29,751 Epoch[5] Batch [160]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.242365,	
2017-07-18 14:27:37,266 Epoch[5] Batch [170]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.236106,	
2017-07-18 14:27:45,178 Epoch[5] Batch [180]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.240169,	
2017-07-18 14:27:52,835 Epoch[5] Batch [190]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.241491,	
2017-07-18 14:28:00,719 Epoch[5] Batch [200]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.241555,	
2017-07-18 14:28:08,131 Epoch[5] Batch [210]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.243711,	
2017-07-18 14:28:16,321 Epoch[5] Batch [220]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.245687,	
2017-07-18 14:28:24,258 Epoch[5] Batch [230]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.243174,	
2017-07-18 14:28:32,640 Epoch[5] Batch [240]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.250499,	
2017-07-18 14:28:40,612 Epoch[5] Batch [250]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.248860,	
2017-07-18 14:28:48,849 Epoch[5] Batch [260]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.252005,	
2017-07-18 14:28:56,976 Epoch[5] Batch [270]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.255275,	
2017-07-18 14:29:04,836 Epoch[5] Batch [280]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.254657,	
2017-07-18 14:29:12,929 Epoch[5] Batch [290]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.252264,	
2017-07-18 14:29:21,119 Epoch[5] Batch [300]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.253903,	
2017-07-18 14:29:29,256 Epoch[5] Batch [310]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.253245,	
2017-07-18 14:29:37,084 Epoch[5] Batch [320]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.251739,	
2017-07-18 14:29:45,088 Epoch[5] Batch [330]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.249709,	
2017-07-18 14:29:52,605 Epoch[5] Batch [340]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.247200,	
2017-07-18 14:30:00,374 Epoch[5] Batch [350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.248074,	
2017-07-18 14:30:08,224 Epoch[5] Batch [360]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.247394,	
2017-07-18 14:30:16,635 Epoch[5] Batch [370]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.247001,	
2017-07-18 14:30:24,115 Epoch[5] Batch [380]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.246635,	
2017-07-18 14:30:31,402 Epoch[5] Batch [390]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.244918,	
2017-07-18 14:30:38,875 Epoch[5] Batch [400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.242200,	
2017-07-18 14:30:46,530 Epoch[5] Batch [410]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.245177,	
2017-07-18 14:30:54,452 Epoch[5] Batch [420]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.243262,	
2017-07-18 14:31:02,360 Epoch[5] Batch [430]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.242291,	
2017-07-18 14:31:09,990 Epoch[5] Batch [440]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.241816,	
2017-07-18 14:31:18,035 Epoch[5] Batch [450]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.242707,	
2017-07-18 14:31:26,948 Epoch[5] Batch [460]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.241532,	
2017-07-18 14:31:34,877 Epoch[5] Batch [470]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.240072,	
2017-07-18 14:31:43,040 Epoch[5] Batch [480]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.239781,	
2017-07-18 14:31:51,990 Epoch[5] Batch [490]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.239949,	
2017-07-18 14:32:01,942 Epoch[5] Batch [500]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.241393,	
2017-07-18 14:32:12,355 Epoch[5] Batch [510]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.240563,	
2017-07-18 14:32:22,029 Epoch[5] Batch [520]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.241442,	
2017-07-18 14:32:31,799 Epoch[5] Batch [530]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.240598,	
2017-07-18 14:32:41,516 Epoch[5] Batch [540]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.242120,	
2017-07-18 14:32:51,580 Epoch[5] Batch [550]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.241523,	
2017-07-18 14:33:01,516 Epoch[5] Batch [560]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.240160,	
2017-07-18 14:33:10,901 Epoch[5] Batch [570]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.239650,	
2017-07-18 14:33:20,721 Epoch[5] Batch [580]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.240520,	
2017-07-18 14:33:30,738 Epoch[5] Batch [590]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.241735,	
2017-07-18 14:33:40,618 Epoch[5] Batch [600]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.242648,	
2017-07-18 14:33:50,812 Epoch[5] Batch [610]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.243621,	
2017-07-18 14:34:00,841 Epoch[5] Batch [620]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.241737,	
2017-07-18 14:34:10,986 Epoch[5] Batch [630]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.242396,	
2017-07-18 14:34:21,494 Epoch[5] Batch [640]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.242577,	
2017-07-18 14:34:31,560 Epoch[5] Batch [650]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.242780,	
2017-07-18 14:34:41,862 Epoch[5] Batch [660]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.241667,	
2017-07-18 14:34:52,316 Epoch[5] Batch [670]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.242571,	
2017-07-18 14:35:02,667 Epoch[5] Batch [680]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.244858,	
2017-07-18 14:35:13,478 Epoch[5] Batch [690]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.244895,	
2017-07-18 14:35:23,874 Epoch[5] Batch [700]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.245507,	
2017-07-18 14:35:34,512 Epoch[5] Batch [710]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.245321,	
2017-07-18 14:35:45,028 Epoch[5] Batch [720]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.247000,	
2017-07-18 14:35:55,221 Epoch[5] Batch [730]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.247066,	
2017-07-18 14:36:05,469 Epoch[5] Batch [740]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.247039,	
2017-07-18 14:36:16,006 Epoch[5] Batch [750]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.247922,	
2017-07-18 14:36:26,894 Epoch[5] Batch [760]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.247964,	
2017-07-18 14:36:37,349 Epoch[5] Batch [770]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.248302,	
2017-07-18 14:36:48,098 Epoch[5] Batch [780]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.247955,	
2017-07-18 14:36:58,368 Epoch[5] Batch [790]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.246102,	
2017-07-18 14:37:08,681 Epoch[5] Batch [800]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.244562,	
2017-07-18 14:37:18,789 Epoch[5] Batch [810]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.243502,	
2017-07-18 14:37:29,298 Epoch[5] Batch [820]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.242079,	
2017-07-18 14:37:40,030 Epoch[5] Batch [830]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.241654,	
2017-07-18 14:37:50,943 Epoch[5] Batch [840]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.242038,	

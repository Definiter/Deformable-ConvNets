2017-07-13 10:44:30,156 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-13 10:45:25,550 Epoch[0] Batch [10]	Speed: 4.05 samples/sec	Train-FCNLogLoss=2.747120,	
2017-07-13 10:45:35,016 Epoch[0] Batch [20]	Speed: 4.23 samples/sec	Train-FCNLogLoss=2.424087,	
2017-07-13 10:45:44,398 Epoch[0] Batch [30]	Speed: 4.26 samples/sec	Train-FCNLogLoss=2.214278,	
2017-07-13 10:45:53,620 Epoch[0] Batch [40]	Speed: 4.34 samples/sec	Train-FCNLogLoss=2.079780,	
2017-07-13 10:46:03,136 Epoch[0] Batch [50]	Speed: 4.20 samples/sec	Train-FCNLogLoss=2.006200,	
2017-07-13 10:46:12,849 Epoch[0] Batch [60]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.943303,	
2017-07-13 10:46:22,403 Epoch[0] Batch [70]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.891518,	
2017-07-13 10:46:31,889 Epoch[0] Batch [80]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.850380,	
2017-07-13 10:46:41,408 Epoch[0] Batch [90]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.807173,	
2017-07-13 10:46:51,167 Epoch[0] Batch [100]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.756675,	
2017-07-13 10:47:01,307 Epoch[0] Batch [110]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.718780,	
2017-07-13 10:47:10,032 Epoch[0] Batch [120]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.687798,	
2017-07-13 10:47:19,245 Epoch[0] Batch [130]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.671948,	
2017-07-13 10:47:28,265 Epoch[0] Batch [140]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.651845,	
2017-07-13 10:47:38,051 Epoch[0] Batch [150]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.628672,	
2017-07-13 10:47:47,484 Epoch[0] Batch [160]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.608595,	
2017-07-13 10:47:56,507 Epoch[0] Batch [170]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.584729,	
2017-07-13 10:48:05,363 Epoch[0] Batch [180]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.566812,	
2017-07-13 10:48:14,709 Epoch[0] Batch [190]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.554073,	
2017-07-13 10:48:23,732 Epoch[0] Batch [200]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.538302,	
2017-07-13 10:48:32,787 Epoch[0] Batch [210]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.525213,	
2017-07-13 10:48:42,034 Epoch[0] Batch [220]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.513047,	
2017-07-13 10:48:51,283 Epoch[0] Batch [230]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.506593,	
2017-07-13 10:49:00,201 Epoch[0] Batch [240]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.502143,	
2017-07-13 10:49:09,731 Epoch[0] Batch [250]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.492809,	
2017-07-13 10:49:18,864 Epoch[0] Batch [260]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.489362,	
2017-07-13 10:49:28,140 Epoch[0] Batch [270]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.480693,	
2017-07-13 10:49:37,318 Epoch[0] Batch [280]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.477336,	
2017-07-13 10:49:46,655 Epoch[0] Batch [290]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.470820,	
2017-07-13 10:49:55,674 Epoch[0] Batch [300]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.467121,	
2017-07-13 10:50:05,167 Epoch[0] Batch [310]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.461153,	
2017-07-13 10:50:14,738 Epoch[0] Batch [320]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.454857,	
2017-07-13 10:50:23,756 Epoch[0] Batch [330]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.450319,	
2017-07-13 10:50:32,681 Epoch[0] Batch [340]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.442322,	
2017-07-13 10:50:41,720 Epoch[0] Batch [350]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.438786,	
2017-07-13 10:50:50,721 Epoch[0] Batch [360]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.432999,	
2017-07-13 10:50:59,901 Epoch[0] Batch [370]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.428493,	
2017-07-13 10:51:09,085 Epoch[0] Batch [380]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.421812,	
2017-07-13 10:51:18,468 Epoch[0] Batch [390]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.417146,	
2017-07-13 10:51:27,716 Epoch[0] Batch [400]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.413451,	
2017-07-13 10:51:36,946 Epoch[0] Batch [410]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.408764,	
2017-07-13 10:51:46,180 Epoch[0] Batch [420]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.408490,	
2017-07-13 10:51:55,456 Epoch[0] Batch [430]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.404588,	
2017-07-13 10:52:05,083 Epoch[0] Batch [440]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.401501,	
2017-07-13 10:52:14,385 Epoch[0] Batch [450]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.398872,	
2017-07-13 10:52:23,860 Epoch[0] Batch [460]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.394279,	
2017-07-13 10:52:33,512 Epoch[0] Batch [470]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.391923,	
2017-07-13 10:52:42,884 Epoch[0] Batch [480]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.390770,	
2017-07-13 10:52:52,361 Epoch[0] Batch [490]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.389917,	
2017-07-13 10:53:01,649 Epoch[0] Batch [500]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.386762,	
2017-07-13 10:53:11,149 Epoch[0] Batch [510]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.384500,	
2017-07-13 10:53:20,121 Epoch[0] Batch [520]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.382838,	
2017-07-13 10:53:29,675 Epoch[0] Batch [530]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.380421,	
2017-07-13 10:53:39,103 Epoch[0] Batch [540]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.378279,	
2017-07-13 10:53:48,551 Epoch[0] Batch [550]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.375428,	
2017-07-13 10:53:58,165 Epoch[0] Batch [560]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.374793,	
2017-07-13 10:54:07,569 Epoch[0] Batch [570]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.372220,	
2017-07-13 10:54:17,054 Epoch[0] Batch [580]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.370403,	
2017-07-13 10:54:26,668 Epoch[0] Batch [590]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.369058,	
2017-07-13 10:54:36,078 Epoch[0] Batch [600]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.368564,	
2017-07-13 10:54:45,598 Epoch[0] Batch [610]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.367098,	
2017-07-13 10:54:55,194 Epoch[0] Batch [620]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.366116,	
2017-07-13 10:55:04,924 Epoch[0] Batch [630]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.363777,	
2017-07-13 10:55:14,156 Epoch[0] Batch [640]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.362146,	
2017-07-13 10:55:23,092 Epoch[0] Batch [650]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.360905,	
2017-07-13 10:55:32,514 Epoch[0] Batch [660]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.357692,	
2017-07-13 10:55:42,024 Epoch[0] Batch [670]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.354509,	
2017-07-13 10:55:51,674 Epoch[0] Batch [680]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.353359,	
2017-07-13 10:56:00,916 Epoch[0] Batch [690]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.351652,	
2017-07-13 10:56:10,334 Epoch[0] Batch [700]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.351266,	
2017-07-13 10:56:19,784 Epoch[0] Batch [710]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.350998,	
2017-07-13 10:56:29,464 Epoch[0] Batch [720]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.351271,	
2017-07-13 10:56:38,949 Epoch[0] Batch [730]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.350108,	
2017-07-13 10:56:48,278 Epoch[0] Batch [740]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.348816,	
2017-07-13 10:56:57,662 Epoch[0] Batch [750]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.349411,	
2017-07-13 10:57:06,930 Epoch[0] Batch [760]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.347691,	
2017-07-13 10:57:16,422 Epoch[0] Batch [770]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.346835,	
2017-07-13 10:57:25,923 Epoch[0] Batch [780]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.345615,	
2017-07-13 10:57:35,031 Epoch[0] Batch [790]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.343901,	
2017-07-13 10:57:44,258 Epoch[0] Batch [800]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.343337,	
2017-07-13 10:57:53,366 Epoch[0] Batch [810]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.341078,	
2017-07-13 10:58:02,362 Epoch[0] Batch [820]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.339987,	
2017-07-13 10:58:11,210 Epoch[0] Batch [830]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.337979,	
2017-07-13 10:58:20,455 Epoch[0] Batch [840]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.337039,	
2017-07-13 10:58:29,716 Epoch[0] Batch [850]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.335140,	
2017-07-13 10:58:39,206 Epoch[0] Batch [860]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.334392,	
2017-07-13 10:58:48,415 Epoch[0] Batch [870]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.334579,	
2017-07-13 10:58:57,526 Epoch[0] Batch [880]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.332381,	
2017-07-13 10:59:07,130 Epoch[0] Batch [890]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.331455,	
2017-07-13 10:59:16,404 Epoch[0] Batch [900]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.332037,	
2017-07-13 10:59:25,439 Epoch[0] Batch [910]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.332373,	
2017-07-13 10:59:35,062 Epoch[0] Batch [920]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.331086,	
2017-07-13 10:59:44,624 Epoch[0] Batch [930]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.330362,	
2017-07-13 10:59:53,877 Epoch[0] Batch [940]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.330631,	
2017-07-13 11:00:03,508 Epoch[0] Batch [950]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.330352,	
2017-07-13 11:00:12,860 Epoch[0] Batch [960]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.328872,	
2017-07-13 11:00:21,938 Epoch[0] Batch [970]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.328397,	
2017-07-13 11:00:31,373 Epoch[0] Batch [980]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.327398,	
2017-07-13 11:00:40,934 Epoch[0] Batch [990]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.325717,	
2017-07-13 11:00:49,831 Epoch[0] Batch [1000]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.324521,	
2017-07-13 11:00:59,273 Epoch[0] Batch [1010]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.330395,	
2017-07-13 11:01:08,464 Epoch[0] Batch [1020]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.334370,	
2017-07-13 11:01:17,626 Epoch[0] Batch [1030]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.340651,	
2017-07-13 11:01:26,792 Epoch[0] Batch [1040]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.346579,	
2017-07-13 11:01:36,336 Epoch[0] Batch [1050]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.354416,	
2017-07-13 11:01:45,622 Epoch[0] Batch [1060]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.357988,	
2017-07-13 11:01:55,272 Epoch[0] Batch [1070]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.362162,	
2017-07-13 11:02:04,856 Epoch[0] Batch [1080]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.366675,	
2017-07-13 11:02:14,314 Epoch[0] Batch [1090]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.370317,	
2017-07-13 11:02:23,903 Epoch[0] Batch [1100]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.374517,	
2017-07-13 11:02:33,556 Epoch[0] Batch [1110]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.377794,	
2017-07-13 11:02:43,183 Epoch[0] Batch [1120]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.381016,	
2017-07-13 11:02:52,534 Epoch[0] Batch [1130]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.384862,	
2017-07-13 11:03:02,037 Epoch[0] Batch [1140]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.388447,	
2017-07-13 11:03:11,415 Epoch[0] Batch [1150]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.390471,	
2017-07-13 11:03:21,047 Epoch[0] Batch [1160]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.393417,	
2017-07-13 11:03:30,664 Epoch[0] Batch [1170]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.396425,	
2017-07-13 11:03:40,667 Epoch[0] Batch [1180]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.398313,	
2017-07-13 11:03:50,353 Epoch[0] Batch [1190]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.400215,	
2017-07-13 11:04:00,034 Epoch[0] Batch [1200]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.402858,	
2017-07-13 11:04:09,373 Epoch[0] Batch [1210]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.404919,	
2017-07-13 11:04:18,726 Epoch[0] Batch [1220]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.408042,	
2017-07-13 11:04:28,099 Epoch[0] Batch [1230]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.409102,	
2017-07-13 11:04:37,567 Epoch[0] Batch [1240]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.410024,	
2017-07-13 11:04:47,282 Epoch[0] Batch [1250]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.410550,	
2017-07-13 11:04:56,959 Epoch[0] Batch [1260]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.410775,	
2017-07-13 11:05:06,441 Epoch[0] Batch [1270]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.410693,	
2017-07-13 11:05:16,173 Epoch[0] Batch [1280]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.410767,	
2017-07-13 11:05:25,801 Epoch[0] Batch [1290]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.409392,	
2017-07-13 11:05:35,438 Epoch[0] Batch [1300]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.409776,	
2017-07-13 11:05:44,975 Epoch[0] Batch [1310]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.411007,	
2017-07-13 11:05:54,557 Epoch[0] Batch [1320]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.411398,	
2017-07-13 11:06:04,174 Epoch[0] Batch [1330]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.410253,	
2017-07-13 11:06:13,680 Epoch[0] Batch [1340]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.409669,	
2017-07-13 11:06:23,231 Epoch[0] Batch [1350]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.409569,	
2017-07-13 11:06:32,824 Epoch[0] Batch [1360]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.409244,	
2017-07-13 11:06:42,311 Epoch[0] Batch [1370]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.409417,	
2017-07-13 11:06:51,620 Epoch[0] Batch [1380]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.408814,	
2017-07-13 11:07:01,337 Epoch[0] Batch [1390]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.408179,	
2017-07-13 11:07:11,105 Epoch[0] Batch [1400]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.407166,	
2017-07-13 11:07:20,854 Epoch[0] Batch [1410]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.406882,	
2017-07-13 11:07:30,508 Epoch[0] Batch [1420]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.405287,	
2017-07-13 11:07:40,227 Epoch[0] Batch [1430]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.404427,	
2017-07-13 11:07:50,451 Epoch[0] Batch [1440]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.403498,	
2017-07-13 11:08:00,037 Epoch[0] Batch [1450]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.403717,	
2017-07-13 11:08:09,471 Epoch[0] Batch [1460]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.403053,	
2017-07-13 11:08:18,944 Epoch[0] Batch [1470]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.402591,	
2017-07-13 11:08:28,556 Epoch[0] Batch [1480]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.402093,	
2017-07-13 11:08:34,167 Epoch[0] Train-FCNLogLoss=1.401223
2017-07-13 11:08:34,167 Epoch[0] Time cost=1408.821
2017-07-13 11:08:35,519 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-13 11:08:40,197 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-13 11:08:48,959 Epoch[1] Batch [10]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.314251,	
2017-07-13 11:08:56,919 Epoch[1] Batch [20]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.297626,	
2017-07-13 11:09:04,874 Epoch[1] Batch [30]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.301749,	
2017-07-13 11:09:12,807 Epoch[1] Batch [40]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.293985,	
2017-07-13 11:09:20,591 Epoch[1] Batch [50]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.291870,	
2017-07-13 11:09:28,594 Epoch[1] Batch [60]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.302203,	
2017-07-13 11:09:36,419 Epoch[1] Batch [70]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.293724,	
2017-07-13 11:09:44,438 Epoch[1] Batch [80]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.305963,	
2017-07-13 11:09:52,290 Epoch[1] Batch [90]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.318776,	
2017-07-13 11:10:00,236 Epoch[1] Batch [100]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.318526,	
2017-07-13 11:10:08,289 Epoch[1] Batch [110]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.311902,	
2017-07-13 11:10:16,210 Epoch[1] Batch [120]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.304084,	
2017-07-13 11:10:24,026 Epoch[1] Batch [130]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.300384,	
2017-07-13 11:10:32,089 Epoch[1] Batch [140]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.299734,	
2017-07-13 11:10:40,097 Epoch[1] Batch [150]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.297847,	
2017-07-13 11:10:47,958 Epoch[1] Batch [160]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.298961,	
2017-07-13 11:10:55,908 Epoch[1] Batch [170]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.293799,	
2017-07-13 11:11:03,842 Epoch[1] Batch [180]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.297090,	
2017-07-13 11:11:11,888 Epoch[1] Batch [190]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.297858,	
2017-07-13 11:11:19,952 Epoch[1] Batch [200]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.295324,	
2017-07-13 11:11:27,886 Epoch[1] Batch [210]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.301506,	
2017-07-13 11:11:35,888 Epoch[1] Batch [220]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.300237,	
2017-07-13 11:11:43,878 Epoch[1] Batch [230]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.296312,	
2017-07-13 11:11:51,959 Epoch[1] Batch [240]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.295250,	
2017-07-13 11:11:59,894 Epoch[1] Batch [250]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.292831,	
2017-07-13 11:12:07,963 Epoch[1] Batch [260]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.295362,	
2017-07-13 11:12:16,047 Epoch[1] Batch [270]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.297250,	
2017-07-13 11:12:23,655 Epoch[1] Batch [280]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.292607,	
2017-07-13 11:12:31,430 Epoch[1] Batch [290]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.285900,	
2017-07-13 11:12:39,347 Epoch[1] Batch [300]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.284118,	
2017-07-13 11:12:47,268 Epoch[1] Batch [310]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.283430,	
2017-07-13 11:12:55,141 Epoch[1] Batch [320]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.283861,	
2017-07-13 11:13:02,879 Epoch[1] Batch [330]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.281799,	
2017-07-13 11:13:10,541 Epoch[1] Batch [340]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.279131,	
2017-07-13 11:13:18,178 Epoch[1] Batch [350]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.279622,	
2017-07-13 11:13:25,876 Epoch[1] Batch [360]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.277960,	
2017-07-13 11:13:33,592 Epoch[1] Batch [370]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.277818,	
2017-07-13 11:13:41,179 Epoch[1] Batch [380]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.279320,	
2017-07-13 11:13:48,775 Epoch[1] Batch [390]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.278652,	
2017-07-13 11:13:56,359 Epoch[1] Batch [400]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.280395,	
2017-07-13 11:14:04,128 Epoch[1] Batch [410]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.278814,	
2017-07-13 11:14:11,870 Epoch[1] Batch [420]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.277780,	
2017-07-13 11:14:19,369 Epoch[1] Batch [430]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.276907,	
2017-07-13 11:14:26,994 Epoch[1] Batch [440]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.276936,	
2017-07-13 11:14:34,895 Epoch[1] Batch [450]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.277266,	
2017-07-13 11:14:42,650 Epoch[1] Batch [460]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.281075,	
2017-07-13 11:14:50,483 Epoch[1] Batch [470]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.278040,	
2017-07-13 11:14:58,534 Epoch[1] Batch [480]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.279766,	
2017-07-13 11:15:06,003 Epoch[1] Batch [490]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.279819,	
2017-07-13 11:15:13,861 Epoch[1] Batch [500]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.279643,	
2017-07-13 11:15:21,347 Epoch[1] Batch [510]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.281661,	
2017-07-13 11:15:28,984 Epoch[1] Batch [520]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.281387,	
2017-07-13 11:15:36,685 Epoch[1] Batch [530]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.279961,	
2017-07-13 11:15:44,651 Epoch[1] Batch [540]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.279107,	
2017-07-13 11:15:52,058 Epoch[1] Batch [550]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.277447,	
2017-07-13 11:15:59,749 Epoch[1] Batch [560]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.277767,	
2017-07-13 11:16:07,336 Epoch[1] Batch [570]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.277255,	
2017-07-13 11:16:15,013 Epoch[1] Batch [580]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.276765,	
2017-07-13 11:16:22,632 Epoch[1] Batch [590]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.274500,	
2017-07-13 11:16:30,560 Epoch[1] Batch [600]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.273581,	
2017-07-13 11:16:44,220 Epoch[1] Batch [610]	Speed: 2.93 samples/sec	Train-FCNLogLoss=1.272135,	
2017-07-13 11:17:03,348 Epoch[1] Batch [620]	Speed: 2.09 samples/sec	Train-FCNLogLoss=1.272200,	
2017-07-13 11:17:17,318 Epoch[1] Batch [630]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.272502,	
2017-07-13 11:17:31,258 Epoch[1] Batch [640]	Speed: 2.87 samples/sec	Train-FCNLogLoss=1.272066,	
2017-07-13 11:17:49,709 Epoch[1] Batch [650]	Speed: 2.17 samples/sec	Train-FCNLogLoss=1.271454,	
2017-07-13 11:18:09,002 Epoch[1] Batch [660]	Speed: 2.07 samples/sec	Train-FCNLogLoss=1.272019,	
2017-07-13 11:18:30,498 Epoch[1] Batch [670]	Speed: 1.86 samples/sec	Train-FCNLogLoss=1.272522,	
2017-07-13 11:18:49,704 Epoch[1] Batch [680]	Speed: 2.08 samples/sec	Train-FCNLogLoss=1.271698,	
2017-07-13 11:19:09,570 Epoch[1] Batch [690]	Speed: 2.01 samples/sec	Train-FCNLogLoss=1.272910,	
2017-07-13 11:19:26,845 Epoch[1] Batch [700]	Speed: 2.32 samples/sec	Train-FCNLogLoss=1.274423,	
2017-07-13 11:19:46,598 Epoch[1] Batch [710]	Speed: 2.03 samples/sec	Train-FCNLogLoss=1.272586,	
2017-07-13 11:20:06,228 Epoch[1] Batch [720]	Speed: 2.04 samples/sec	Train-FCNLogLoss=1.271635,	
2017-07-13 11:20:24,495 Epoch[1] Batch [730]	Speed: 2.19 samples/sec	Train-FCNLogLoss=1.271299,	
2017-07-13 11:20:41,982 Epoch[1] Batch [740]	Speed: 2.29 samples/sec	Train-FCNLogLoss=1.269777,	
2017-07-13 11:20:53,844 Epoch[1] Batch [750]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.268963,	
2017-07-13 11:21:06,791 Epoch[1] Batch [760]	Speed: 3.09 samples/sec	Train-FCNLogLoss=1.269173,	
2017-07-13 11:21:19,794 Epoch[1] Batch [770]	Speed: 3.08 samples/sec	Train-FCNLogLoss=1.268713,	
2017-07-13 11:21:37,094 Epoch[1] Batch [780]	Speed: 2.31 samples/sec	Train-FCNLogLoss=1.268635,	
2017-07-13 11:21:52,755 Epoch[1] Batch [790]	Speed: 2.55 samples/sec	Train-FCNLogLoss=1.269037,	
2017-07-13 11:22:07,258 Epoch[1] Batch [800]	Speed: 2.76 samples/sec	Train-FCNLogLoss=1.267492,	
2017-07-13 11:22:21,759 Epoch[1] Batch [810]	Speed: 2.76 samples/sec	Train-FCNLogLoss=1.267101,	
2017-07-13 11:22:36,326 Epoch[1] Batch [820]	Speed: 2.75 samples/sec	Train-FCNLogLoss=1.267977,	
2017-07-13 11:22:50,367 Epoch[1] Batch [830]	Speed: 2.85 samples/sec	Train-FCNLogLoss=1.267756,	
2017-07-13 11:23:04,932 Epoch[1] Batch [840]	Speed: 2.75 samples/sec	Train-FCNLogLoss=1.267555,	
2017-07-13 11:23:19,770 Epoch[1] Batch [850]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.267679,	
2017-07-13 11:23:32,610 Epoch[1] Batch [860]	Speed: 3.12 samples/sec	Train-FCNLogLoss=1.268163,	
2017-07-13 11:23:45,769 Epoch[1] Batch [870]	Speed: 3.04 samples/sec	Train-FCNLogLoss=1.268077,	
2017-07-13 11:23:57,967 Epoch[1] Batch [880]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.268839,	
2017-07-13 11:24:11,816 Epoch[1] Batch [890]	Speed: 2.89 samples/sec	Train-FCNLogLoss=1.268523,	
2017-07-13 11:24:26,515 Epoch[1] Batch [900]	Speed: 2.72 samples/sec	Train-FCNLogLoss=1.267454,	
2017-07-13 11:24:41,233 Epoch[1] Batch [910]	Speed: 2.72 samples/sec	Train-FCNLogLoss=1.266329,	
2017-07-13 11:24:55,835 Epoch[1] Batch [920]	Speed: 2.74 samples/sec	Train-FCNLogLoss=1.265815,	
2017-07-13 11:25:11,465 Epoch[1] Batch [930]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.266655,	
2017-07-13 11:25:25,851 Epoch[1] Batch [940]	Speed: 2.78 samples/sec	Train-FCNLogLoss=1.266490,	
2017-07-13 11:25:42,933 Epoch[1] Batch [950]	Speed: 2.34 samples/sec	Train-FCNLogLoss=1.267001,	
2017-07-13 11:25:59,333 Epoch[1] Batch [960]	Speed: 2.44 samples/sec	Train-FCNLogLoss=1.267251,	
2017-07-13 11:26:13,396 Epoch[1] Batch [970]	Speed: 2.84 samples/sec	Train-FCNLogLoss=1.266790,	
2017-07-13 11:26:29,440 Epoch[1] Batch [980]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.266402,	
2017-07-13 11:26:43,869 Epoch[1] Batch [990]	Speed: 2.77 samples/sec	Train-FCNLogLoss=1.266078,	
2017-07-13 11:26:57,215 Epoch[1] Batch [1000]	Speed: 3.00 samples/sec	Train-FCNLogLoss=1.265958,	
2017-07-13 11:27:13,540 Epoch[1] Batch [1010]	Speed: 2.45 samples/sec	Train-FCNLogLoss=1.266538,	
2017-07-13 11:27:28,618 Epoch[1] Batch [1020]	Speed: 2.65 samples/sec	Train-FCNLogLoss=1.265966,	
2017-07-13 11:27:43,012 Epoch[1] Batch [1030]	Speed: 2.78 samples/sec	Train-FCNLogLoss=1.266102,	
2017-07-13 11:27:56,988 Epoch[1] Batch [1040]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.266300,	
2017-07-13 11:28:09,628 Epoch[1] Batch [1050]	Speed: 3.16 samples/sec	Train-FCNLogLoss=1.267159,	
2017-07-13 11:28:22,456 Epoch[1] Batch [1060]	Speed: 3.12 samples/sec	Train-FCNLogLoss=1.267764,	
2017-07-13 11:28:36,158 Epoch[1] Batch [1070]	Speed: 2.92 samples/sec	Train-FCNLogLoss=1.268510,	
2017-07-13 11:28:50,562 Epoch[1] Batch [1080]	Speed: 2.78 samples/sec	Train-FCNLogLoss=1.268724,	
2017-07-13 11:29:03,823 Epoch[1] Batch [1090]	Speed: 3.02 samples/sec	Train-FCNLogLoss=1.268197,	
2017-07-13 11:29:18,236 Epoch[1] Batch [1100]	Speed: 2.78 samples/sec	Train-FCNLogLoss=1.267983,	
2017-07-13 11:29:32,893 Epoch[1] Batch [1110]	Speed: 2.73 samples/sec	Train-FCNLogLoss=1.267197,	
2017-07-13 11:29:48,724 Epoch[1] Batch [1120]	Speed: 2.53 samples/sec	Train-FCNLogLoss=1.267350,	
2017-07-13 11:30:02,980 Epoch[1] Batch [1130]	Speed: 2.81 samples/sec	Train-FCNLogLoss=1.267339,	
2017-07-13 11:30:20,282 Epoch[1] Batch [1140]	Speed: 2.31 samples/sec	Train-FCNLogLoss=1.267679,	
2017-07-13 11:30:36,394 Epoch[1] Batch [1150]	Speed: 2.48 samples/sec	Train-FCNLogLoss=1.268066,	
2017-07-13 11:30:51,926 Epoch[1] Batch [1160]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.268294,	
2017-07-13 11:31:08,298 Epoch[1] Batch [1170]	Speed: 2.44 samples/sec	Train-FCNLogLoss=1.267662,	
2017-07-13 11:31:23,228 Epoch[1] Batch [1180]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.267421,	
2017-07-13 11:31:39,200 Epoch[1] Batch [1190]	Speed: 2.50 samples/sec	Train-FCNLogLoss=1.266559,	
2017-07-13 11:31:53,338 Epoch[1] Batch [1200]	Speed: 2.83 samples/sec	Train-FCNLogLoss=1.266462,	
2017-07-13 11:32:06,174 Epoch[1] Batch [1210]	Speed: 3.12 samples/sec	Train-FCNLogLoss=1.266143,	
2017-07-13 11:32:22,705 Epoch[1] Batch [1220]	Speed: 2.42 samples/sec	Train-FCNLogLoss=1.265324,	
2017-07-13 11:32:38,287 Epoch[1] Batch [1230]	Speed: 2.57 samples/sec	Train-FCNLogLoss=1.266223,	
2017-07-13 11:32:52,040 Epoch[1] Batch [1240]	Speed: 2.91 samples/sec	Train-FCNLogLoss=1.266913,	
2017-07-13 11:33:05,304 Epoch[1] Batch [1250]	Speed: 3.02 samples/sec	Train-FCNLogLoss=1.267127,	
2017-07-13 11:33:20,228 Epoch[1] Batch [1260]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.267912,	
2017-07-13 11:33:36,625 Epoch[1] Batch [1270]	Speed: 2.44 samples/sec	Train-FCNLogLoss=1.267819,	
2017-07-13 11:33:52,796 Epoch[1] Batch [1280]	Speed: 2.47 samples/sec	Train-FCNLogLoss=1.267944,	
2017-07-13 11:34:05,758 Epoch[1] Batch [1290]	Speed: 3.09 samples/sec	Train-FCNLogLoss=1.267538,	
2017-07-13 11:34:21,162 Epoch[1] Batch [1300]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.267092,	
2017-07-13 11:34:33,748 Epoch[1] Batch [1310]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.267169,	
2017-07-13 11:34:46,178 Epoch[1] Batch [1320]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.267512,	
2017-07-13 11:34:58,481 Epoch[1] Batch [1330]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.267110,	
2017-07-13 11:35:12,286 Epoch[1] Batch [1340]	Speed: 2.90 samples/sec	Train-FCNLogLoss=1.267139,	
2017-07-13 11:35:27,010 Epoch[1] Batch [1350]	Speed: 2.72 samples/sec	Train-FCNLogLoss=1.266631,	
2017-07-13 11:35:41,844 Epoch[1] Batch [1360]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.266590,	
2017-07-13 11:35:56,106 Epoch[1] Batch [1370]	Speed: 2.80 samples/sec	Train-FCNLogLoss=1.266633,	
2017-07-13 11:36:08,911 Epoch[1] Batch [1380]	Speed: 3.12 samples/sec	Train-FCNLogLoss=1.266341,	
2017-07-13 11:36:22,996 Epoch[1] Batch [1390]	Speed: 2.84 samples/sec	Train-FCNLogLoss=1.265747,	
2017-07-13 11:36:37,931 Epoch[1] Batch [1400]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.265832,	
2017-07-13 11:36:53,269 Epoch[1] Batch [1410]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.265841,	
2017-07-13 11:37:08,252 Epoch[1] Batch [1420]	Speed: 2.67 samples/sec	Train-FCNLogLoss=1.265151,	
2017-07-13 11:37:21,501 Epoch[1] Batch [1430]	Speed: 3.02 samples/sec	Train-FCNLogLoss=1.265193,	
2017-07-13 11:37:35,289 Epoch[1] Batch [1440]	Speed: 2.90 samples/sec	Train-FCNLogLoss=1.265157,	
2017-07-13 11:37:51,336 Epoch[1] Batch [1450]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.264579,	
2017-07-13 11:38:07,537 Epoch[1] Batch [1460]	Speed: 2.47 samples/sec	Train-FCNLogLoss=1.264798,	
2017-07-13 11:38:22,370 Epoch[1] Batch [1470]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.264870,	
2017-07-13 11:38:39,414 Epoch[1] Batch [1480]	Speed: 2.35 samples/sec	Train-FCNLogLoss=1.264585,	
2017-07-13 11:38:46,643 Epoch[1] Train-FCNLogLoss=1.264801
2017-07-13 11:38:46,643 Epoch[1] Time cost=1806.445
2017-07-13 11:38:49,439 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-13 11:38:59,680 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-13 11:39:16,369 Epoch[2] Batch [10]	Speed: 2.78 samples/sec	Train-FCNLogLoss=1.108448,	
2017-07-13 11:39:31,370 Epoch[2] Batch [20]	Speed: 2.67 samples/sec	Train-FCNLogLoss=1.195979,	
2017-07-13 11:39:45,591 Epoch[2] Batch [30]	Speed: 2.81 samples/sec	Train-FCNLogLoss=1.221415,	
2017-07-13 11:40:01,849 Epoch[2] Batch [40]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.232625,	
2017-07-13 11:40:18,148 Epoch[2] Batch [50]	Speed: 2.45 samples/sec	Train-FCNLogLoss=1.219143,	
2017-07-13 11:40:31,942 Epoch[2] Batch [60]	Speed: 2.90 samples/sec	Train-FCNLogLoss=1.224068,	
2017-07-13 11:40:45,013 Epoch[2] Batch [70]	Speed: 3.06 samples/sec	Train-FCNLogLoss=1.230441,	
2017-07-13 11:40:59,027 Epoch[2] Batch [80]	Speed: 2.85 samples/sec	Train-FCNLogLoss=1.238373,	
2017-07-13 11:41:12,146 Epoch[2] Batch [90]	Speed: 3.05 samples/sec	Train-FCNLogLoss=1.258054,	
2017-07-13 11:41:27,763 Epoch[2] Batch [100]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.254252,	
2017-07-13 11:41:44,139 Epoch[2] Batch [110]	Speed: 2.44 samples/sec	Train-FCNLogLoss=1.241759,	
2017-07-13 11:41:58,288 Epoch[2] Batch [120]	Speed: 2.83 samples/sec	Train-FCNLogLoss=1.245546,	
2017-07-13 11:42:12,379 Epoch[2] Batch [130]	Speed: 2.84 samples/sec	Train-FCNLogLoss=1.245005,	
2017-07-13 11:42:25,145 Epoch[2] Batch [140]	Speed: 3.13 samples/sec	Train-FCNLogLoss=1.243049,	
2017-07-13 11:42:39,775 Epoch[2] Batch [150]	Speed: 2.73 samples/sec	Train-FCNLogLoss=1.249349,	
2017-07-13 11:42:53,890 Epoch[2] Batch [160]	Speed: 2.83 samples/sec	Train-FCNLogLoss=1.249391,	
2017-07-13 11:43:10,175 Epoch[2] Batch [170]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.252467,	
2017-07-13 11:43:23,931 Epoch[2] Batch [180]	Speed: 2.91 samples/sec	Train-FCNLogLoss=1.248943,	
2017-07-13 11:43:36,868 Epoch[2] Batch [190]	Speed: 3.09 samples/sec	Train-FCNLogLoss=1.243638,	
2017-07-13 11:43:51,728 Epoch[2] Batch [200]	Speed: 2.69 samples/sec	Train-FCNLogLoss=1.245973,	
2017-07-13 11:44:06,948 Epoch[2] Batch [210]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.244957,	
2017-07-13 11:44:22,532 Epoch[2] Batch [220]	Speed: 2.57 samples/sec	Train-FCNLogLoss=1.246356,	
2017-07-13 11:44:36,501 Epoch[2] Batch [230]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.251049,	
2017-07-13 11:44:51,831 Epoch[2] Batch [240]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.250356,	
2017-07-13 11:45:08,756 Epoch[2] Batch [250]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.250643,	
2017-07-13 11:45:22,875 Epoch[2] Batch [260]	Speed: 2.83 samples/sec	Train-FCNLogLoss=1.248611,	
2017-07-13 11:45:36,672 Epoch[2] Batch [270]	Speed: 2.90 samples/sec	Train-FCNLogLoss=1.253374,	
2017-07-13 11:45:50,081 Epoch[2] Batch [280]	Speed: 2.98 samples/sec	Train-FCNLogLoss=1.251970,	
2017-07-13 11:46:05,457 Epoch[2] Batch [290]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.251493,	
2017-07-13 11:46:19,776 Epoch[2] Batch [300]	Speed: 2.79 samples/sec	Train-FCNLogLoss=1.250904,	
2017-07-13 11:46:34,432 Epoch[2] Batch [310]	Speed: 2.73 samples/sec	Train-FCNLogLoss=1.249752,	
2017-07-13 11:46:48,282 Epoch[2] Batch [320]	Speed: 2.89 samples/sec	Train-FCNLogLoss=1.247564,	
2017-07-13 11:47:03,085 Epoch[2] Batch [330]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.247243,	
2017-07-13 11:47:17,782 Epoch[2] Batch [340]	Speed: 2.72 samples/sec	Train-FCNLogLoss=1.246646,	
2017-07-13 11:47:32,796 Epoch[2] Batch [350]	Speed: 2.66 samples/sec	Train-FCNLogLoss=1.250083,	
2017-07-13 11:47:49,772 Epoch[2] Batch [360]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.248860,	
2017-07-13 11:48:05,554 Epoch[2] Batch [370]	Speed: 2.53 samples/sec	Train-FCNLogLoss=1.247712,	
2017-07-13 11:48:21,074 Epoch[2] Batch [380]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.246650,	
2017-07-13 11:48:34,707 Epoch[2] Batch [390]	Speed: 2.93 samples/sec	Train-FCNLogLoss=1.244417,	
2017-07-13 11:48:51,017 Epoch[2] Batch [400]	Speed: 2.45 samples/sec	Train-FCNLogLoss=1.244830,	
2017-07-13 11:49:05,942 Epoch[2] Batch [410]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.243142,	
2017-07-13 11:49:19,212 Epoch[2] Batch [420]	Speed: 3.01 samples/sec	Train-FCNLogLoss=1.243692,	
2017-07-13 11:49:33,498 Epoch[2] Batch [430]	Speed: 2.80 samples/sec	Train-FCNLogLoss=1.244890,	
2017-07-13 11:49:49,296 Epoch[2] Batch [440]	Speed: 2.53 samples/sec	Train-FCNLogLoss=1.243556,	
2017-07-13 11:50:03,663 Epoch[2] Batch [450]	Speed: 2.78 samples/sec	Train-FCNLogLoss=1.246000,	
2017-07-13 11:50:17,483 Epoch[2] Batch [460]	Speed: 2.89 samples/sec	Train-FCNLogLoss=1.245229,	
2017-07-13 11:50:33,776 Epoch[2] Batch [470]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.245088,	
2017-07-13 11:50:49,728 Epoch[2] Batch [480]	Speed: 2.51 samples/sec	Train-FCNLogLoss=1.244867,	
2017-07-13 11:51:05,449 Epoch[2] Batch [490]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.247971,	
2017-07-13 11:51:19,930 Epoch[2] Batch [500]	Speed: 2.76 samples/sec	Train-FCNLogLoss=1.248327,	
2017-07-13 11:51:35,483 Epoch[2] Batch [510]	Speed: 2.57 samples/sec	Train-FCNLogLoss=1.248844,	
2017-07-13 11:51:50,753 Epoch[2] Batch [520]	Speed: 2.62 samples/sec	Train-FCNLogLoss=1.248383,	
2017-07-13 11:52:08,954 Epoch[2] Batch [530]	Speed: 2.20 samples/sec	Train-FCNLogLoss=1.248912,	
2017-07-13 11:52:25,957 Epoch[2] Batch [540]	Speed: 2.35 samples/sec	Train-FCNLogLoss=1.250170,	
2017-07-13 11:52:44,143 Epoch[2] Batch [550]	Speed: 2.20 samples/sec	Train-FCNLogLoss=1.250595,	
2017-07-13 11:53:00,736 Epoch[2] Batch [560]	Speed: 2.41 samples/sec	Train-FCNLogLoss=1.250216,	
2017-07-13 11:53:21,299 Epoch[2] Batch [570]	Speed: 1.95 samples/sec	Train-FCNLogLoss=1.250645,	
2017-07-13 11:53:36,409 Epoch[2] Batch [580]	Speed: 2.65 samples/sec	Train-FCNLogLoss=1.249711,	
2017-07-13 11:53:50,685 Epoch[2] Batch [590]	Speed: 2.80 samples/sec	Train-FCNLogLoss=1.248953,	
2017-07-13 11:54:04,100 Epoch[2] Batch [600]	Speed: 2.98 samples/sec	Train-FCNLogLoss=1.246190,	
2017-07-13 11:54:20,217 Epoch[2] Batch [610]	Speed: 2.48 samples/sec	Train-FCNLogLoss=1.247225,	
2017-07-13 11:54:34,989 Epoch[2] Batch [620]	Speed: 2.71 samples/sec	Train-FCNLogLoss=1.247161,	
2017-07-13 11:54:49,544 Epoch[2] Batch [630]	Speed: 2.75 samples/sec	Train-FCNLogLoss=1.247242,	
2017-07-13 11:55:06,801 Epoch[2] Batch [640]	Speed: 2.32 samples/sec	Train-FCNLogLoss=1.246771,	
2017-07-13 11:55:23,902 Epoch[2] Batch [650]	Speed: 2.34 samples/sec	Train-FCNLogLoss=1.246336,	
2017-07-13 11:55:40,354 Epoch[2] Batch [660]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.243748,	
2017-07-13 11:55:55,868 Epoch[2] Batch [670]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.244820,	
2017-07-13 11:56:11,975 Epoch[2] Batch [680]	Speed: 2.48 samples/sec	Train-FCNLogLoss=1.246322,	
2017-07-13 11:56:28,329 Epoch[2] Batch [690]	Speed: 2.45 samples/sec	Train-FCNLogLoss=1.246114,	
2017-07-13 11:56:43,378 Epoch[2] Batch [700]	Speed: 2.66 samples/sec	Train-FCNLogLoss=1.246094,	
2017-07-13 11:57:00,728 Epoch[2] Batch [710]	Speed: 2.31 samples/sec	Train-FCNLogLoss=1.247446,	
2017-07-13 11:57:19,365 Epoch[2] Batch [720]	Speed: 2.15 samples/sec	Train-FCNLogLoss=1.248037,	
2017-07-13 11:57:36,284 Epoch[2] Batch [730]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.248919,	
2017-07-13 11:57:51,107 Epoch[2] Batch [740]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.248106,	
2017-07-13 11:58:07,491 Epoch[2] Batch [750]	Speed: 2.44 samples/sec	Train-FCNLogLoss=1.248011,	
2017-07-13 11:58:24,683 Epoch[2] Batch [760]	Speed: 2.33 samples/sec	Train-FCNLogLoss=1.248731,	
2017-07-13 11:58:41,978 Epoch[2] Batch [770]	Speed: 2.31 samples/sec	Train-FCNLogLoss=1.249188,	
2017-07-13 11:58:57,390 Epoch[2] Batch [780]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.249389,	
2017-07-13 11:59:12,330 Epoch[2] Batch [790]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.248427,	
2017-07-13 11:59:28,466 Epoch[2] Batch [800]	Speed: 2.48 samples/sec	Train-FCNLogLoss=1.248342,	
2017-07-13 11:59:45,696 Epoch[2] Batch [810]	Speed: 2.32 samples/sec	Train-FCNLogLoss=1.248163,	
2017-07-13 12:00:01,791 Epoch[2] Batch [820]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.247827,	
2017-07-13 12:00:16,916 Epoch[2] Batch [830]	Speed: 2.64 samples/sec	Train-FCNLogLoss=1.248777,	
2017-07-13 12:00:34,289 Epoch[2] Batch [840]	Speed: 2.30 samples/sec	Train-FCNLogLoss=1.249156,	
2017-07-13 12:00:52,130 Epoch[2] Batch [850]	Speed: 2.24 samples/sec	Train-FCNLogLoss=1.250711,	
2017-07-13 12:01:07,605 Epoch[2] Batch [860]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.250610,	
2017-07-13 12:01:25,233 Epoch[2] Batch [870]	Speed: 2.27 samples/sec	Train-FCNLogLoss=1.250918,	
2017-07-13 12:01:42,540 Epoch[2] Batch [880]	Speed: 2.31 samples/sec	Train-FCNLogLoss=1.251237,	
2017-07-13 12:02:00,947 Epoch[2] Batch [890]	Speed: 2.17 samples/sec	Train-FCNLogLoss=1.251671,	
2017-07-13 12:02:17,966 Epoch[2] Batch [900]	Speed: 2.35 samples/sec	Train-FCNLogLoss=1.251900,	
2017-07-13 12:02:33,585 Epoch[2] Batch [910]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.251760,	
2017-07-13 12:02:49,639 Epoch[2] Batch [920]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.251993,	
2017-07-13 12:03:05,223 Epoch[2] Batch [930]	Speed: 2.57 samples/sec	Train-FCNLogLoss=1.251882,	
2017-07-13 12:03:22,112 Epoch[2] Batch [940]	Speed: 2.37 samples/sec	Train-FCNLogLoss=1.251589,	
2017-07-13 12:03:39,313 Epoch[2] Batch [950]	Speed: 2.33 samples/sec	Train-FCNLogLoss=1.251507,	
2017-07-13 12:03:54,951 Epoch[2] Batch [960]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.251104,	
2017-07-13 12:04:11,254 Epoch[2] Batch [970]	Speed: 2.45 samples/sec	Train-FCNLogLoss=1.251644,	
2017-07-13 12:04:26,814 Epoch[2] Batch [980]	Speed: 2.57 samples/sec	Train-FCNLogLoss=1.252603,	
2017-07-13 12:04:43,251 Epoch[2] Batch [990]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.252495,	
2017-07-13 12:04:58,996 Epoch[2] Batch [1000]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.252905,	
2017-07-13 12:05:15,540 Epoch[2] Batch [1010]	Speed: 2.42 samples/sec	Train-FCNLogLoss=1.252050,	
2017-07-13 12:05:30,354 Epoch[2] Batch [1020]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.252631,	
2017-07-13 12:05:43,817 Epoch[2] Batch [1030]	Speed: 2.97 samples/sec	Train-FCNLogLoss=1.251573,	
2017-07-13 12:05:57,939 Epoch[2] Batch [1040]	Speed: 2.83 samples/sec	Train-FCNLogLoss=1.251459,	
2017-07-13 12:06:12,846 Epoch[2] Batch [1050]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.250794,	
2017-07-13 12:06:29,592 Epoch[2] Batch [1060]	Speed: 2.39 samples/sec	Train-FCNLogLoss=1.250879,	
2017-07-13 12:06:43,149 Epoch[2] Batch [1070]	Speed: 2.95 samples/sec	Train-FCNLogLoss=1.250384,	
2017-07-13 12:07:00,777 Epoch[2] Batch [1080]	Speed: 2.27 samples/sec	Train-FCNLogLoss=1.249970,	
2017-07-13 12:07:19,466 Epoch[2] Batch [1090]	Speed: 2.14 samples/sec	Train-FCNLogLoss=1.250465,	
2017-07-13 12:07:37,023 Epoch[2] Batch [1100]	Speed: 2.28 samples/sec	Train-FCNLogLoss=1.250352,	
2017-07-13 12:07:56,181 Epoch[2] Batch [1110]	Speed: 2.09 samples/sec	Train-FCNLogLoss=1.250345,	
2017-07-13 12:08:13,899 Epoch[2] Batch [1120]	Speed: 2.26 samples/sec	Train-FCNLogLoss=1.251554,	
2017-07-13 12:08:27,843 Epoch[2] Batch [1130]	Speed: 2.87 samples/sec	Train-FCNLogLoss=1.252095,	
2017-07-13 12:08:44,376 Epoch[2] Batch [1140]	Speed: 2.42 samples/sec	Train-FCNLogLoss=1.251844,	
2017-07-13 12:08:59,671 Epoch[2] Batch [1150]	Speed: 2.62 samples/sec	Train-FCNLogLoss=1.251616,	
2017-07-13 12:09:13,645 Epoch[2] Batch [1160]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.251887,	
2017-07-13 12:09:29,370 Epoch[2] Batch [1170]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.251942,	
2017-07-13 12:09:44,007 Epoch[2] Batch [1180]	Speed: 2.73 samples/sec	Train-FCNLogLoss=1.251377,	
2017-07-13 12:09:57,922 Epoch[2] Batch [1190]	Speed: 2.87 samples/sec	Train-FCNLogLoss=1.252084,	
2017-07-13 12:10:11,178 Epoch[2] Batch [1200]	Speed: 3.02 samples/sec	Train-FCNLogLoss=1.251803,	
2017-07-13 12:10:25,318 Epoch[2] Batch [1210]	Speed: 2.83 samples/sec	Train-FCNLogLoss=1.251117,	
2017-07-13 12:10:40,220 Epoch[2] Batch [1220]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.250572,	
2017-07-13 12:10:54,515 Epoch[2] Batch [1230]	Speed: 2.80 samples/sec	Train-FCNLogLoss=1.250736,	
2017-07-13 12:11:13,366 Epoch[2] Batch [1240]	Speed: 2.12 samples/sec	Train-FCNLogLoss=1.251641,	
2017-07-13 12:11:28,120 Epoch[2] Batch [1250]	Speed: 2.71 samples/sec	Train-FCNLogLoss=1.251681,	
2017-07-13 12:11:42,803 Epoch[2] Batch [1260]	Speed: 2.72 samples/sec	Train-FCNLogLoss=1.251676,	
2017-07-13 12:11:58,510 Epoch[2] Batch [1270]	Speed: 2.55 samples/sec	Train-FCNLogLoss=1.251323,	
2017-07-13 12:12:13,626 Epoch[2] Batch [1280]	Speed: 2.65 samples/sec	Train-FCNLogLoss=1.250575,	
2017-07-13 12:12:28,976 Epoch[2] Batch [1290]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.250604,	
2017-07-13 12:12:43,448 Epoch[2] Batch [1300]	Speed: 2.76 samples/sec	Train-FCNLogLoss=1.250472,	
2017-07-13 12:12:58,660 Epoch[2] Batch [1310]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.250132,	
2017-07-13 12:13:12,949 Epoch[2] Batch [1320]	Speed: 2.80 samples/sec	Train-FCNLogLoss=1.249701,	
2017-07-13 12:13:27,900 Epoch[2] Batch [1330]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.249852,	
2017-07-13 12:13:45,255 Epoch[2] Batch [1340]	Speed: 2.30 samples/sec	Train-FCNLogLoss=1.249872,	
2017-07-13 12:13:59,286 Epoch[2] Batch [1350]	Speed: 2.85 samples/sec	Train-FCNLogLoss=1.249854,	
2017-07-13 12:14:14,078 Epoch[2] Batch [1360]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.249870,	
2017-07-13 12:14:31,073 Epoch[2] Batch [1370]	Speed: 2.35 samples/sec	Train-FCNLogLoss=1.249668,	
2017-07-13 12:14:45,948 Epoch[2] Batch [1380]	Speed: 2.69 samples/sec	Train-FCNLogLoss=1.249706,	
2017-07-13 12:15:02,196 Epoch[2] Batch [1390]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.249410,	
2017-07-13 12:15:16,921 Epoch[2] Batch [1400]	Speed: 2.72 samples/sec	Train-FCNLogLoss=1.249328,	
2017-07-13 12:15:33,370 Epoch[2] Batch [1410]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.250274,	
2017-07-13 12:15:49,376 Epoch[2] Batch [1420]	Speed: 2.50 samples/sec	Train-FCNLogLoss=1.250107,	
2017-07-13 12:16:03,994 Epoch[2] Batch [1430]	Speed: 2.74 samples/sec	Train-FCNLogLoss=1.249545,	
2017-07-13 12:16:19,173 Epoch[2] Batch [1440]	Speed: 2.64 samples/sec	Train-FCNLogLoss=1.249783,	
2017-07-13 12:16:35,149 Epoch[2] Batch [1450]	Speed: 2.50 samples/sec	Train-FCNLogLoss=1.249498,	
2017-07-13 12:16:51,199 Epoch[2] Batch [1460]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.249291,	
2017-07-13 12:17:06,140 Epoch[2] Batch [1470]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.249499,	
2017-07-13 12:17:18,745 Epoch[2] Batch [1480]	Speed: 3.17 samples/sec	Train-FCNLogLoss=1.249723,	
2017-07-13 12:17:26,774 Epoch[2] Train-FCNLogLoss=1.249203
2017-07-13 12:17:26,775 Epoch[2] Time cost=2307.094
2017-07-13 12:17:28,824 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-13 12:17:44,363 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-13 12:18:00,834 Epoch[3] Batch [10]	Speed: 2.73 samples/sec	Train-FCNLogLoss=1.161467,	
2017-07-13 12:18:16,063 Epoch[3] Batch [20]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.176224,	
2017-07-13 12:18:31,786 Epoch[3] Batch [30]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.178082,	
2017-07-13 12:18:46,645 Epoch[3] Batch [40]	Speed: 2.69 samples/sec	Train-FCNLogLoss=1.213459,	
2017-07-13 12:19:02,150 Epoch[3] Batch [50]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.244554,	
2017-07-13 12:19:17,782 Epoch[3] Batch [60]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.260545,	
2017-07-13 12:19:33,401 Epoch[3] Batch [70]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.259998,	
2017-07-13 12:19:49,649 Epoch[3] Batch [80]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.252428,	
2017-07-13 12:20:06,666 Epoch[3] Batch [90]	Speed: 2.35 samples/sec	Train-FCNLogLoss=1.239739,	
2017-07-13 12:20:22,102 Epoch[3] Batch [100]	Speed: 2.59 samples/sec	Train-FCNLogLoss=1.251689,	
2017-07-13 12:20:37,604 Epoch[3] Batch [110]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.254063,	
2017-07-13 12:20:53,496 Epoch[3] Batch [120]	Speed: 2.52 samples/sec	Train-FCNLogLoss=1.250203,	
2017-07-13 12:21:09,360 Epoch[3] Batch [130]	Speed: 2.52 samples/sec	Train-FCNLogLoss=1.248075,	
2017-07-13 12:21:24,674 Epoch[3] Batch [140]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.255075,	
2017-07-13 12:21:41,326 Epoch[3] Batch [150]	Speed: 2.40 samples/sec	Train-FCNLogLoss=1.255418,	
2017-07-13 12:21:56,026 Epoch[3] Batch [160]	Speed: 2.72 samples/sec	Train-FCNLogLoss=1.248829,	
2017-07-13 12:22:11,047 Epoch[3] Batch [170]	Speed: 2.66 samples/sec	Train-FCNLogLoss=1.252468,	
2017-07-13 12:22:25,802 Epoch[3] Batch [180]	Speed: 2.71 samples/sec	Train-FCNLogLoss=1.252421,	
2017-07-13 12:22:40,281 Epoch[3] Batch [190]	Speed: 2.76 samples/sec	Train-FCNLogLoss=1.251928,	
2017-07-13 12:22:54,063 Epoch[3] Batch [200]	Speed: 2.90 samples/sec	Train-FCNLogLoss=1.249787,	
2017-07-13 12:23:09,582 Epoch[3] Batch [210]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.246135,	
2017-07-13 12:23:26,033 Epoch[3] Batch [220]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.251602,	
2017-07-13 12:23:43,011 Epoch[3] Batch [230]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.249430,	
2017-07-13 12:23:57,824 Epoch[3] Batch [240]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.247529,	
2017-07-13 12:24:13,992 Epoch[3] Batch [250]	Speed: 2.47 samples/sec	Train-FCNLogLoss=1.253256,	
2017-07-13 12:24:29,644 Epoch[3] Batch [260]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.255479,	
2017-07-13 12:24:43,523 Epoch[3] Batch [270]	Speed: 2.88 samples/sec	Train-FCNLogLoss=1.255413,	
2017-07-13 12:24:59,187 Epoch[3] Batch [280]	Speed: 2.55 samples/sec	Train-FCNLogLoss=1.254236,	
2017-07-13 12:25:14,290 Epoch[3] Batch [290]	Speed: 2.65 samples/sec	Train-FCNLogLoss=1.257073,	
2017-07-13 12:25:30,473 Epoch[3] Batch [300]	Speed: 2.47 samples/sec	Train-FCNLogLoss=1.254744,	
2017-07-13 12:25:45,979 Epoch[3] Batch [310]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.255585,	
2017-07-13 12:26:02,958 Epoch[3] Batch [320]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.254849,	
2017-07-13 12:26:19,764 Epoch[3] Batch [330]	Speed: 2.38 samples/sec	Train-FCNLogLoss=1.253647,	
2017-07-13 12:26:35,914 Epoch[3] Batch [340]	Speed: 2.48 samples/sec	Train-FCNLogLoss=1.255460,	
2017-07-13 12:26:50,978 Epoch[3] Batch [350]	Speed: 2.66 samples/sec	Train-FCNLogLoss=1.255776,	
2017-07-13 12:27:06,481 Epoch[3] Batch [360]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.254996,	
2017-07-13 12:27:19,998 Epoch[3] Batch [370]	Speed: 2.96 samples/sec	Train-FCNLogLoss=1.255412,	
2017-07-13 12:27:37,644 Epoch[3] Batch [380]	Speed: 2.27 samples/sec	Train-FCNLogLoss=1.254485,	
2017-07-13 12:27:53,927 Epoch[3] Batch [390]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.254378,	
2017-07-13 12:28:07,624 Epoch[3] Batch [400]	Speed: 2.92 samples/sec	Train-FCNLogLoss=1.252437,	
2017-07-13 12:28:22,522 Epoch[3] Batch [410]	Speed: 2.68 samples/sec	Train-FCNLogLoss=1.250307,	
2017-07-13 12:28:40,941 Epoch[3] Batch [420]	Speed: 2.17 samples/sec	Train-FCNLogLoss=1.250961,	
2017-07-13 12:29:02,046 Epoch[3] Batch [430]	Speed: 1.90 samples/sec	Train-FCNLogLoss=1.250457,	
2017-07-13 12:29:24,834 Epoch[3] Batch [440]	Speed: 1.76 samples/sec	Train-FCNLogLoss=1.249799,	
2017-07-13 12:29:44,129 Epoch[3] Batch [450]	Speed: 2.07 samples/sec	Train-FCNLogLoss=1.249984,	
2017-07-13 12:30:04,312 Epoch[3] Batch [460]	Speed: 1.98 samples/sec	Train-FCNLogLoss=1.248818,	
2017-07-13 12:30:23,953 Epoch[3] Batch [470]	Speed: 2.04 samples/sec	Train-FCNLogLoss=1.249927,	
2017-07-13 12:30:44,503 Epoch[3] Batch [480]	Speed: 1.95 samples/sec	Train-FCNLogLoss=1.250044,	
2017-07-13 12:31:06,416 Epoch[3] Batch [490]	Speed: 1.83 samples/sec	Train-FCNLogLoss=1.248756,	
2017-07-13 12:31:26,656 Epoch[3] Batch [500]	Speed: 1.98 samples/sec	Train-FCNLogLoss=1.249381,	
2017-07-13 12:31:44,900 Epoch[3] Batch [510]	Speed: 2.19 samples/sec	Train-FCNLogLoss=1.248085,	
2017-07-13 12:32:05,523 Epoch[3] Batch [520]	Speed: 1.94 samples/sec	Train-FCNLogLoss=1.248762,	
2017-07-13 12:32:24,825 Epoch[3] Batch [530]	Speed: 2.07 samples/sec	Train-FCNLogLoss=1.249644,	
2017-07-13 12:32:44,900 Epoch[3] Batch [540]	Speed: 1.99 samples/sec	Train-FCNLogLoss=1.249413,	
2017-07-13 12:33:01,155 Epoch[3] Batch [550]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.248889,	
2017-07-13 12:33:15,624 Epoch[3] Batch [560]	Speed: 2.76 samples/sec	Train-FCNLogLoss=1.247540,	

2017-07-13 17:06:58,360 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-13 17:08:14,882 Epoch[0] Batch [10]	Speed: 3.37 samples/sec	Train-FCNLogLoss=2.741282,	
2017-07-13 17:08:26,600 Epoch[0] Batch [20]	Speed: 3.41 samples/sec	Train-FCNLogLoss=2.440832,	
2017-07-13 17:08:38,504 Epoch[0] Batch [30]	Speed: 3.36 samples/sec	Train-FCNLogLoss=2.220591,	
2017-07-13 17:08:50,783 Epoch[0] Batch [40]	Speed: 3.26 samples/sec	Train-FCNLogLoss=2.095298,	
2017-07-13 17:09:02,374 Epoch[0] Batch [50]	Speed: 3.45 samples/sec	Train-FCNLogLoss=2.004400,	
2017-07-13 17:09:14,297 Epoch[0] Batch [60]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.937054,	
2017-07-13 17:09:25,864 Epoch[0] Batch [70]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.866957,	
2017-07-13 17:09:37,890 Epoch[0] Batch [80]	Speed: 3.33 samples/sec	Train-FCNLogLoss=1.805771,	
2017-07-13 17:09:49,740 Epoch[0] Batch [90]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.775077,	
2017-07-13 17:10:01,750 Epoch[0] Batch [100]	Speed: 3.33 samples/sec	Train-FCNLogLoss=1.739312,	
2017-07-13 17:10:13,308 Epoch[0] Batch [110]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.713655,	
2017-07-13 17:10:25,031 Epoch[0] Batch [120]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.676981,	
2017-07-13 17:10:36,795 Epoch[0] Batch [130]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.656394,	
2017-07-13 17:10:48,504 Epoch[0] Batch [140]	Speed: 3.42 samples/sec	Train-FCNLogLoss=1.623724,	
2017-07-13 17:11:00,379 Epoch[0] Batch [150]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.607905,	
2017-07-13 17:11:11,854 Epoch[0] Batch [160]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.584296,	
2017-07-13 17:11:23,585 Epoch[0] Batch [170]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.565775,	
2017-07-13 17:11:35,538 Epoch[0] Batch [180]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.548041,	
2017-07-13 17:11:46,959 Epoch[0] Batch [190]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.540686,	
2017-07-13 17:11:58,753 Epoch[0] Batch [200]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.528037,	
2017-07-13 17:12:10,680 Epoch[0] Batch [210]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.517774,	
2017-07-13 17:12:22,398 Epoch[0] Batch [220]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.504193,	
2017-07-13 17:12:34,151 Epoch[0] Batch [230]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.493855,	
2017-07-13 17:12:45,873 Epoch[0] Batch [240]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.483836,	
2017-07-13 17:12:57,666 Epoch[0] Batch [250]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.473792,	
2017-07-13 17:13:09,640 Epoch[0] Batch [260]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.465585,	
2017-07-13 17:13:21,510 Epoch[0] Batch [270]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.460225,	
2017-07-13 17:13:33,502 Epoch[0] Batch [280]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.455335,	
2017-07-13 17:13:45,303 Epoch[0] Batch [290]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.447129,	
2017-07-13 17:13:57,129 Epoch[0] Batch [300]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.441218,	
2017-07-13 17:14:09,175 Epoch[0] Batch [310]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.436895,	
2017-07-13 17:14:20,978 Epoch[0] Batch [320]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.435542,	
2017-07-13 17:14:33,145 Epoch[0] Batch [330]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.429622,	
2017-07-13 17:14:44,613 Epoch[0] Batch [340]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.424376,	
2017-07-13 17:14:55,724 Epoch[0] Batch [350]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.419387,	
2017-07-13 17:15:07,775 Epoch[0] Batch [360]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.417002,	
2017-07-13 17:15:19,809 Epoch[0] Batch [370]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.411539,	
2017-07-13 17:15:31,849 Epoch[0] Batch [380]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.410142,	
2017-07-13 17:15:43,975 Epoch[0] Batch [390]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.406555,	
2017-07-13 17:15:55,964 Epoch[0] Batch [400]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.407311,	
2017-07-13 17:16:07,951 Epoch[0] Batch [410]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.403368,	
2017-07-13 17:16:20,019 Epoch[0] Batch [420]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.396799,	
2017-07-13 17:16:31,895 Epoch[0] Batch [430]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.392375,	
2017-07-13 17:16:44,072 Epoch[0] Batch [440]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.390014,	
2017-07-13 17:16:55,664 Epoch[0] Batch [450]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.385419,	
2017-07-13 17:17:07,625 Epoch[0] Batch [460]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.382819,	
2017-07-13 17:17:19,479 Epoch[0] Batch [470]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.382094,	
2017-07-13 17:17:31,370 Epoch[0] Batch [480]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.382433,	
2017-07-13 17:17:43,314 Epoch[0] Batch [490]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.381046,	
2017-07-13 17:17:55,236 Epoch[0] Batch [500]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.380036,	
2017-07-13 17:18:07,323 Epoch[0] Batch [510]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.379521,	
2017-07-13 17:18:27,498 Epoch[0] Batch [520]	Speed: 1.98 samples/sec	Train-FCNLogLoss=1.377949,	
2017-07-13 17:18:48,912 Epoch[0] Batch [530]	Speed: 1.87 samples/sec	Train-FCNLogLoss=1.374695,	
2017-07-13 17:19:11,605 Epoch[0] Batch [540]	Speed: 1.76 samples/sec	Train-FCNLogLoss=1.372540,	
2017-07-13 17:19:34,184 Epoch[0] Batch [550]	Speed: 1.77 samples/sec	Train-FCNLogLoss=1.369737,	
2017-07-13 17:19:57,936 Epoch[0] Batch [560]	Speed: 1.68 samples/sec	Train-FCNLogLoss=1.367621,	
2017-07-13 17:20:19,462 Epoch[0] Batch [570]	Speed: 1.86 samples/sec	Train-FCNLogLoss=1.367740,	
2017-07-13 17:20:40,417 Epoch[0] Batch [580]	Speed: 1.91 samples/sec	Train-FCNLogLoss=1.367215,	
2017-07-13 17:21:02,473 Epoch[0] Batch [590]	Speed: 1.81 samples/sec	Train-FCNLogLoss=1.366536,	
2017-07-13 17:21:24,829 Epoch[0] Batch [600]	Speed: 1.79 samples/sec	Train-FCNLogLoss=1.364840,	
2017-07-13 17:21:47,179 Epoch[0] Batch [610]	Speed: 1.79 samples/sec	Train-FCNLogLoss=1.363558,	
2017-07-13 17:22:09,796 Epoch[0] Batch [620]	Speed: 1.77 samples/sec	Train-FCNLogLoss=1.361890,	
2017-07-13 17:22:33,301 Epoch[0] Batch [630]	Speed: 1.70 samples/sec	Train-FCNLogLoss=1.361818,	
2017-07-13 17:22:55,045 Epoch[0] Batch [640]	Speed: 1.84 samples/sec	Train-FCNLogLoss=1.359387,	
2017-07-13 17:23:17,527 Epoch[0] Batch [650]	Speed: 1.78 samples/sec	Train-FCNLogLoss=1.358827,	
2017-07-13 17:23:39,939 Epoch[0] Batch [660]	Speed: 1.78 samples/sec	Train-FCNLogLoss=1.357373,	
2017-07-13 17:24:02,217 Epoch[0] Batch [670]	Speed: 1.80 samples/sec	Train-FCNLogLoss=1.356598,	
2017-07-13 17:24:25,288 Epoch[0] Batch [680]	Speed: 1.73 samples/sec	Train-FCNLogLoss=1.354914,	
2017-07-13 17:24:48,006 Epoch[0] Batch [690]	Speed: 1.76 samples/sec	Train-FCNLogLoss=1.354950,	
2017-07-13 17:25:11,027 Epoch[0] Batch [700]	Speed: 1.74 samples/sec	Train-FCNLogLoss=1.354041,	
2017-07-13 17:25:32,591 Epoch[0] Batch [710]	Speed: 1.85 samples/sec	Train-FCNLogLoss=1.352455,	
2017-07-13 17:25:54,779 Epoch[0] Batch [720]	Speed: 1.80 samples/sec	Train-FCNLogLoss=1.352028,	
2017-07-13 17:26:17,515 Epoch[0] Batch [730]	Speed: 1.76 samples/sec	Train-FCNLogLoss=1.350379,	
2017-07-13 17:26:39,467 Epoch[0] Batch [740]	Speed: 1.82 samples/sec	Train-FCNLogLoss=1.347312,	
2017-07-13 17:27:01,251 Epoch[0] Batch [750]	Speed: 1.84 samples/sec	Train-FCNLogLoss=1.346692,	
2017-07-13 17:27:23,000 Epoch[0] Batch [760]	Speed: 1.84 samples/sec	Train-FCNLogLoss=1.345338,	
2017-07-13 17:27:45,290 Epoch[0] Batch [770]	Speed: 1.79 samples/sec	Train-FCNLogLoss=1.342993,	
2017-07-13 17:28:09,147 Epoch[0] Batch [780]	Speed: 1.68 samples/sec	Train-FCNLogLoss=1.340789,	
2017-07-13 17:28:32,615 Epoch[0] Batch [790]	Speed: 1.70 samples/sec	Train-FCNLogLoss=1.339212,	
2017-07-13 17:28:52,279 Epoch[0] Batch [800]	Speed: 2.03 samples/sec	Train-FCNLogLoss=1.339465,	
2017-07-13 17:29:11,805 Epoch[0] Batch [810]	Speed: 2.05 samples/sec	Train-FCNLogLoss=1.338216,	
2017-07-13 17:29:33,931 Epoch[0] Batch [820]	Speed: 1.81 samples/sec	Train-FCNLogLoss=1.337040,	
2017-07-13 17:29:55,412 Epoch[0] Batch [830]	Speed: 1.86 samples/sec	Train-FCNLogLoss=1.335505,	
2017-07-13 17:30:15,180 Epoch[0] Batch [840]	Speed: 2.02 samples/sec	Train-FCNLogLoss=1.336067,	
2017-07-13 17:30:34,996 Epoch[0] Batch [850]	Speed: 2.02 samples/sec	Train-FCNLogLoss=1.336299,	
2017-07-13 17:30:56,822 Epoch[0] Batch [860]	Speed: 1.83 samples/sec	Train-FCNLogLoss=1.333634,	
2017-07-13 17:31:19,454 Epoch[0] Batch [870]	Speed: 1.77 samples/sec	Train-FCNLogLoss=1.333746,	
2017-07-13 17:31:40,198 Epoch[0] Batch [880]	Speed: 1.93 samples/sec	Train-FCNLogLoss=1.333636,	
2017-07-13 17:32:00,045 Epoch[0] Batch [890]	Speed: 2.02 samples/sec	Train-FCNLogLoss=1.332723,	
2017-07-13 17:32:22,554 Epoch[0] Batch [900]	Speed: 1.78 samples/sec	Train-FCNLogLoss=1.332444,	
2017-07-13 17:32:45,223 Epoch[0] Batch [910]	Speed: 1.76 samples/sec	Train-FCNLogLoss=1.330771,	
2017-07-13 17:33:07,238 Epoch[0] Batch [920]	Speed: 1.82 samples/sec	Train-FCNLogLoss=1.331031,	
2017-07-13 17:33:26,964 Epoch[0] Batch [930]	Speed: 2.03 samples/sec	Train-FCNLogLoss=1.331088,	
2017-07-13 17:33:48,327 Epoch[0] Batch [940]	Speed: 1.87 samples/sec	Train-FCNLogLoss=1.330132,	
2017-07-13 17:34:09,346 Epoch[0] Batch [950]	Speed: 1.90 samples/sec	Train-FCNLogLoss=1.329294,	
2017-07-13 17:34:30,239 Epoch[0] Batch [960]	Speed: 1.91 samples/sec	Train-FCNLogLoss=1.327916,	
2017-07-13 17:34:50,765 Epoch[0] Batch [970]	Speed: 1.95 samples/sec	Train-FCNLogLoss=1.326955,	
2017-07-13 17:35:11,530 Epoch[0] Batch [980]	Speed: 1.93 samples/sec	Train-FCNLogLoss=1.327172,	
2017-07-13 17:35:33,293 Epoch[0] Batch [990]	Speed: 1.84 samples/sec	Train-FCNLogLoss=1.326857,	
2017-07-13 17:35:55,689 Epoch[0] Batch [1000]	Speed: 1.79 samples/sec	Train-FCNLogLoss=1.327023,	
2017-07-13 17:36:18,171 Epoch[0] Batch [1010]	Speed: 1.78 samples/sec	Train-FCNLogLoss=1.328054,	
2017-07-13 17:36:39,536 Epoch[0] Batch [1020]	Speed: 1.87 samples/sec	Train-FCNLogLoss=1.333621,	
2017-07-13 17:37:01,654 Epoch[0] Batch [1030]	Speed: 1.81 samples/sec	Train-FCNLogLoss=1.341081,	
2017-07-13 17:37:24,399 Epoch[0] Batch [1040]	Speed: 1.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:37:47,564 Epoch[0] Batch [1050]	Speed: 1.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:38:09,818 Epoch[0] Batch [1060]	Speed: 1.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:38:32,169 Epoch[0] Batch [1070]	Speed: 1.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:38:55,841 Epoch[0] Batch [1080]	Speed: 1.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:39:18,572 Epoch[0] Batch [1090]	Speed: 1.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:39:41,325 Epoch[0] Batch [1100]	Speed: 1.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:40:02,894 Epoch[0] Batch [1110]	Speed: 1.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:40:24,981 Epoch[0] Batch [1120]	Speed: 1.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:40:48,281 Epoch[0] Batch [1130]	Speed: 1.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:41:09,543 Epoch[0] Batch [1140]	Speed: 1.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:41:29,632 Epoch[0] Batch [1150]	Speed: 1.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:41:52,524 Epoch[0] Batch [1160]	Speed: 1.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:42:15,512 Epoch[0] Batch [1170]	Speed: 1.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:42:37,130 Epoch[0] Batch [1180]	Speed: 1.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:42:59,785 Epoch[0] Batch [1190]	Speed: 1.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:43:22,300 Epoch[0] Batch [1200]	Speed: 1.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:43:45,228 Epoch[0] Batch [1210]	Speed: 1.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:44:07,569 Epoch[0] Batch [1220]	Speed: 1.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:44:29,520 Epoch[0] Batch [1230]	Speed: 1.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:44:53,161 Epoch[0] Batch [1240]	Speed: 1.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:45:14,183 Epoch[0] Batch [1250]	Speed: 1.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:45:36,974 Epoch[0] Batch [1260]	Speed: 1.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:45:58,498 Epoch[0] Batch [1270]	Speed: 1.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:46:21,367 Epoch[0] Batch [1280]	Speed: 1.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:46:45,536 Epoch[0] Batch [1290]	Speed: 1.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:47:05,984 Epoch[0] Batch [1300]	Speed: 1.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:47:28,979 Epoch[0] Batch [1310]	Speed: 1.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:47:52,652 Epoch[0] Batch [1320]	Speed: 1.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:48:16,687 Epoch[0] Batch [1330]	Speed: 1.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:48:34,750 Epoch[0] Batch [1340]	Speed: 2.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:48:52,128 Epoch[0] Batch [1350]	Speed: 2.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:49:12,104 Epoch[0] Batch [1360]	Speed: 2.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:49:34,349 Epoch[0] Batch [1370]	Speed: 1.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:50:00,729 Epoch[0] Batch [1380]	Speed: 1.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:50:29,537 Epoch[0] Batch [1390]	Speed: 1.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:50:55,999 Epoch[0] Batch [1400]	Speed: 1.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:51:22,367 Epoch[0] Batch [1410]	Speed: 1.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:51:49,271 Epoch[0] Batch [1420]	Speed: 1.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:52:14,644 Epoch[0] Batch [1430]	Speed: 1.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:52:40,973 Epoch[0] Batch [1440]	Speed: 1.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:53:06,948 Epoch[0] Batch [1450]	Speed: 1.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:53:34,510 Epoch[0] Batch [1460]	Speed: 1.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:53:58,003 Epoch[0] Batch [1470]	Speed: 1.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:54:23,563 Epoch[0] Batch [1480]	Speed: 1.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:54:39,795 Epoch[0] Train-FCNLogLoss=nan
2017-07-13 17:54:39,795 Epoch[0] Time cost=2810.022
2017-07-13 17:54:43,588 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-13 17:55:06,859 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-13 17:55:26,670 Epoch[1] Batch [10]	Speed: 2.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:55:43,198 Epoch[1] Batch [20]	Speed: 2.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:56:00,256 Epoch[1] Batch [30]	Speed: 2.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:56:17,620 Epoch[1] Batch [40]	Speed: 2.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:56:33,646 Epoch[1] Batch [50]	Speed: 2.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:56:50,264 Epoch[1] Batch [60]	Speed: 2.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:57:07,465 Epoch[1] Batch [70]	Speed: 2.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:57:22,740 Epoch[1] Batch [80]	Speed: 2.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:57:39,231 Epoch[1] Batch [90]	Speed: 2.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:57:55,190 Epoch[1] Batch [100]	Speed: 2.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:58:11,620 Epoch[1] Batch [110]	Speed: 2.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:58:27,840 Epoch[1] Batch [120]	Speed: 2.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:58:44,440 Epoch[1] Batch [130]	Speed: 2.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:59:00,630 Epoch[1] Batch [140]	Speed: 2.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:59:17,447 Epoch[1] Batch [150]	Speed: 2.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:59:32,298 Epoch[1] Batch [160]	Speed: 2.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 17:59:49,419 Epoch[1] Batch [170]	Speed: 2.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:00:06,403 Epoch[1] Batch [180]	Speed: 2.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:00:23,908 Epoch[1] Batch [190]	Speed: 2.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:00:39,912 Epoch[1] Batch [200]	Speed: 2.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:00:57,413 Epoch[1] Batch [210]	Speed: 2.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:01:14,342 Epoch[1] Batch [220]	Speed: 2.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:01:30,714 Epoch[1] Batch [230]	Speed: 2.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:01:46,536 Epoch[1] Batch [240]	Speed: 2.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:02:01,818 Epoch[1] Batch [250]	Speed: 2.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:02:17,531 Epoch[1] Batch [260]	Speed: 2.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:02:34,310 Epoch[1] Batch [270]	Speed: 2.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:02:50,257 Epoch[1] Batch [280]	Speed: 2.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:03:06,432 Epoch[1] Batch [290]	Speed: 2.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:03:23,703 Epoch[1] Batch [300]	Speed: 2.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:03:39,913 Epoch[1] Batch [310]	Speed: 2.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:03:57,122 Epoch[1] Batch [320]	Speed: 2.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:04:14,489 Epoch[1] Batch [330]	Speed: 2.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:04:28,702 Epoch[1] Batch [340]	Speed: 2.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:04:37,146 Epoch[1] Batch [350]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:04:45,339 Epoch[1] Batch [360]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:04:53,207 Epoch[1] Batch [370]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:01,080 Epoch[1] Batch [380]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:08,864 Epoch[1] Batch [390]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:17,076 Epoch[1] Batch [400]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:25,149 Epoch[1] Batch [410]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:33,020 Epoch[1] Batch [420]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:40,934 Epoch[1] Batch [430]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:48,907 Epoch[1] Batch [440]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:05:57,032 Epoch[1] Batch [450]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:06:05,306 Epoch[1] Batch [460]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:06:13,538 Epoch[1] Batch [470]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:06:21,617 Epoch[1] Batch [480]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:06:29,440 Epoch[1] Batch [490]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:06:37,376 Epoch[1] Batch [500]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:06:45,393 Epoch[1] Batch [510]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:06:53,254 Epoch[1] Batch [520]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:07:01,419 Epoch[1] Batch [530]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:07:09,578 Epoch[1] Batch [540]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:07:18,369 Epoch[1] Batch [550]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:07:27,094 Epoch[1] Batch [560]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:07:35,691 Epoch[1] Batch [570]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:07:44,608 Epoch[1] Batch [580]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:07:54,385 Epoch[1] Batch [590]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:08:09,282 Epoch[1] Batch [600]	Speed: 2.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:08:23,608 Epoch[1] Batch [610]	Speed: 2.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:08:38,313 Epoch[1] Batch [620]	Speed: 2.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:08:56,432 Epoch[1] Batch [630]	Speed: 2.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:09:11,735 Epoch[1] Batch [640]	Speed: 2.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:09:27,233 Epoch[1] Batch [650]	Speed: 2.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:09:41,944 Epoch[1] Batch [660]	Speed: 2.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:09:57,671 Epoch[1] Batch [670]	Speed: 2.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:10:12,959 Epoch[1] Batch [680]	Speed: 2.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:10:27,789 Epoch[1] Batch [690]	Speed: 2.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:10:42,196 Epoch[1] Batch [700]	Speed: 2.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:10:56,931 Epoch[1] Batch [710]	Speed: 2.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:11:12,772 Epoch[1] Batch [720]	Speed: 2.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:11:29,114 Epoch[1] Batch [730]	Speed: 2.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:11:46,513 Epoch[1] Batch [740]	Speed: 2.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:12:01,710 Epoch[1] Batch [750]	Speed: 2.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:12:17,814 Epoch[1] Batch [760]	Speed: 2.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:12:34,746 Epoch[1] Batch [770]	Speed: 2.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:12:51,939 Epoch[1] Batch [780]	Speed: 2.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:13:04,609 Epoch[1] Batch [790]	Speed: 3.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:13:13,542 Epoch[1] Batch [800]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:13:22,913 Epoch[1] Batch [810]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:13:32,661 Epoch[1] Batch [820]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:13:42,008 Epoch[1] Batch [830]	Speed: 4.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:13:50,435 Epoch[1] Batch [840]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:13:59,395 Epoch[1] Batch [850]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:14:08,480 Epoch[1] Batch [860]	Speed: 4.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:14:17,638 Epoch[1] Batch [870]	Speed: 4.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:14:26,594 Epoch[1] Batch [880]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:14:34,660 Epoch[1] Batch [890]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:14:43,418 Epoch[1] Batch [900]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:14:51,909 Epoch[1] Batch [910]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:15:00,212 Epoch[1] Batch [920]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:15:09,138 Epoch[1] Batch [930]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:15:17,927 Epoch[1] Batch [940]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:15:26,936 Epoch[1] Batch [950]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:15:35,916 Epoch[1] Batch [960]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:15:45,284 Epoch[1] Batch [970]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:15:54,685 Epoch[1] Batch [980]	Speed: 4.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:16:04,266 Epoch[1] Batch [990]	Speed: 4.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:16:13,828 Epoch[1] Batch [1000]	Speed: 4.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:16:23,399 Epoch[1] Batch [1010]	Speed: 4.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:16:32,181 Epoch[1] Batch [1020]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:16:41,306 Epoch[1] Batch [1030]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:16:50,231 Epoch[1] Batch [1040]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:16:58,618 Epoch[1] Batch [1050]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:17:07,396 Epoch[1] Batch [1060]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:17:16,114 Epoch[1] Batch [1070]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:17:25,029 Epoch[1] Batch [1080]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:17:33,998 Epoch[1] Batch [1090]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:17:43,007 Epoch[1] Batch [1100]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:17:52,083 Epoch[1] Batch [1110]	Speed: 4.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:18:01,194 Epoch[1] Batch [1120]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:18:10,146 Epoch[1] Batch [1130]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:18:19,082 Epoch[1] Batch [1140]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:18:28,367 Epoch[1] Batch [1150]	Speed: 4.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:18:37,363 Epoch[1] Batch [1160]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:18:46,606 Epoch[1] Batch [1170]	Speed: 4.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:18:55,495 Epoch[1] Batch [1180]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:19:04,548 Epoch[1] Batch [1190]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:19:13,716 Epoch[1] Batch [1200]	Speed: 4.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:19:22,656 Epoch[1] Batch [1210]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:19:32,315 Epoch[1] Batch [1220]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:19:41,593 Epoch[1] Batch [1230]	Speed: 4.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:19:50,447 Epoch[1] Batch [1240]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:19:59,554 Epoch[1] Batch [1250]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:20:08,626 Epoch[1] Batch [1260]	Speed: 4.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:20:17,779 Epoch[1] Batch [1270]	Speed: 4.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:20:26,882 Epoch[1] Batch [1280]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:20:35,672 Epoch[1] Batch [1290]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:20:45,423 Epoch[1] Batch [1300]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:20:57,833 Epoch[1] Batch [1310]	Speed: 3.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:21:06,939 Epoch[1] Batch [1320]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:21:15,803 Epoch[1] Batch [1330]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:21:25,004 Epoch[1] Batch [1340]	Speed: 4.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:21:34,808 Epoch[1] Batch [1350]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:21:44,846 Epoch[1] Batch [1360]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:21:55,183 Epoch[1] Batch [1370]	Speed: 3.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:22:05,211 Epoch[1] Batch [1380]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:22:14,072 Epoch[1] Batch [1390]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:22:23,076 Epoch[1] Batch [1400]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:22:32,066 Epoch[1] Batch [1410]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:22:40,985 Epoch[1] Batch [1420]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:22:50,006 Epoch[1] Batch [1430]	Speed: 4.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:22:59,030 Epoch[1] Batch [1440]	Speed: 4.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:23:08,275 Epoch[1] Batch [1450]	Speed: 4.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:23:16,991 Epoch[1] Batch [1460]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:23:24,637 Epoch[1] Batch [1470]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:23:31,344 Epoch[1] Batch [1480]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:23:35,388 Epoch[1] Train-FCNLogLoss=nan
2017-07-13 18:23:35,388 Epoch[1] Time cost=1708.529
2017-07-13 18:23:36,577 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-13 18:23:40,490 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-13 18:23:47,921 Epoch[2] Batch [10]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:23:54,596 Epoch[2] Batch [20]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:01,219 Epoch[2] Batch [30]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:07,901 Epoch[2] Batch [40]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:14,481 Epoch[2] Batch [50]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:21,117 Epoch[2] Batch [60]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:27,833 Epoch[2] Batch [70]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:34,548 Epoch[2] Batch [80]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:41,321 Epoch[2] Batch [90]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:48,047 Epoch[2] Batch [100]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:24:54,785 Epoch[2] Batch [110]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:01,491 Epoch[2] Batch [120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:08,239 Epoch[2] Batch [130]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:14,935 Epoch[2] Batch [140]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:21,688 Epoch[2] Batch [150]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:28,347 Epoch[2] Batch [160]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:35,117 Epoch[2] Batch [170]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:41,859 Epoch[2] Batch [180]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:48,599 Epoch[2] Batch [190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:25:55,357 Epoch[2] Batch [200]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:02,086 Epoch[2] Batch [210]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:08,817 Epoch[2] Batch [220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:15,614 Epoch[2] Batch [230]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:22,323 Epoch[2] Batch [240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:29,082 Epoch[2] Batch [250]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:35,778 Epoch[2] Batch [260]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:42,497 Epoch[2] Batch [270]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:49,224 Epoch[2] Batch [280]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:26:56,003 Epoch[2] Batch [290]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:02,689 Epoch[2] Batch [300]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:09,390 Epoch[2] Batch [310]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:16,141 Epoch[2] Batch [320]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:22,859 Epoch[2] Batch [330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:29,633 Epoch[2] Batch [340]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:36,540 Epoch[2] Batch [350]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:43,327 Epoch[2] Batch [360]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:50,039 Epoch[2] Batch [370]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:27:56,745 Epoch[2] Batch [380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:03,546 Epoch[2] Batch [390]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:10,276 Epoch[2] Batch [400]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:17,001 Epoch[2] Batch [410]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:23,717 Epoch[2] Batch [420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:30,468 Epoch[2] Batch [430]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:37,034 Epoch[2] Batch [440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:43,748 Epoch[2] Batch [450]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:50,469 Epoch[2] Batch [460]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:28:57,216 Epoch[2] Batch [470]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:03,960 Epoch[2] Batch [480]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:10,673 Epoch[2] Batch [490]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:17,438 Epoch[2] Batch [500]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:24,181 Epoch[2] Batch [510]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:30,911 Epoch[2] Batch [520]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:37,633 Epoch[2] Batch [530]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:44,396 Epoch[2] Batch [540]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:51,141 Epoch[2] Batch [550]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:29:57,868 Epoch[2] Batch [560]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:04,591 Epoch[2] Batch [570]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:11,401 Epoch[2] Batch [580]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:18,105 Epoch[2] Batch [590]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:24,825 Epoch[2] Batch [600]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:31,561 Epoch[2] Batch [610]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:38,261 Epoch[2] Batch [620]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:45,009 Epoch[2] Batch [630]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:51,752 Epoch[2] Batch [640]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:30:58,451 Epoch[2] Batch [650]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:05,172 Epoch[2] Batch [660]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:11,876 Epoch[2] Batch [670]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:18,626 Epoch[2] Batch [680]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:25,371 Epoch[2] Batch [690]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:32,099 Epoch[2] Batch [700]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:38,839 Epoch[2] Batch [710]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:45,555 Epoch[2] Batch [720]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:52,278 Epoch[2] Batch [730]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:31:59,035 Epoch[2] Batch [740]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:05,715 Epoch[2] Batch [750]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:12,431 Epoch[2] Batch [760]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:19,190 Epoch[2] Batch [770]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:26,113 Epoch[2] Batch [780]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:32,729 Epoch[2] Batch [790]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:39,550 Epoch[2] Batch [800]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:46,410 Epoch[2] Batch [810]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:53,183 Epoch[2] Batch [820]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:32:59,879 Epoch[2] Batch [830]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:06,597 Epoch[2] Batch [840]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:13,255 Epoch[2] Batch [850]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:20,000 Epoch[2] Batch [860]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:26,731 Epoch[2] Batch [870]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:33,449 Epoch[2] Batch [880]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:40,113 Epoch[2] Batch [890]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:46,872 Epoch[2] Batch [900]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:33:53,546 Epoch[2] Batch [910]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:00,227 Epoch[2] Batch [920]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:06,977 Epoch[2] Batch [930]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:13,677 Epoch[2] Batch [940]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:20,435 Epoch[2] Batch [950]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:27,102 Epoch[2] Batch [960]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:33,871 Epoch[2] Batch [970]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:40,626 Epoch[2] Batch [980]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:47,334 Epoch[2] Batch [990]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:34:54,096 Epoch[2] Batch [1000]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:00,805 Epoch[2] Batch [1010]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:07,581 Epoch[2] Batch [1020]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:14,321 Epoch[2] Batch [1030]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:21,071 Epoch[2] Batch [1040]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:27,766 Epoch[2] Batch [1050]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:34,465 Epoch[2] Batch [1060]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:41,158 Epoch[2] Batch [1070]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:47,943 Epoch[2] Batch [1080]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:35:54,716 Epoch[2] Batch [1090]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:01,431 Epoch[2] Batch [1100]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:08,201 Epoch[2] Batch [1110]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:14,851 Epoch[2] Batch [1120]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:21,527 Epoch[2] Batch [1130]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:28,305 Epoch[2] Batch [1140]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:35,036 Epoch[2] Batch [1150]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:41,762 Epoch[2] Batch [1160]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:48,486 Epoch[2] Batch [1170]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:36:55,197 Epoch[2] Batch [1180]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:01,884 Epoch[2] Batch [1190]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:08,617 Epoch[2] Batch [1200]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:15,371 Epoch[2] Batch [1210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:21,938 Epoch[2] Batch [1220]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:28,704 Epoch[2] Batch [1230]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:35,404 Epoch[2] Batch [1240]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:42,153 Epoch[2] Batch [1250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:48,898 Epoch[2] Batch [1260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:37:55,642 Epoch[2] Batch [1270]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:02,426 Epoch[2] Batch [1280]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:09,164 Epoch[2] Batch [1290]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:15,876 Epoch[2] Batch [1300]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:22,646 Epoch[2] Batch [1310]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:29,389 Epoch[2] Batch [1320]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:36,134 Epoch[2] Batch [1330]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:42,867 Epoch[2] Batch [1340]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:49,446 Epoch[2] Batch [1350]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:38:56,104 Epoch[2] Batch [1360]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:02,869 Epoch[2] Batch [1370]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:09,437 Epoch[2] Batch [1380]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:16,215 Epoch[2] Batch [1390]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:22,987 Epoch[2] Batch [1400]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:29,713 Epoch[2] Batch [1410]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:36,355 Epoch[2] Batch [1420]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:43,024 Epoch[2] Batch [1430]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:49,749 Epoch[2] Batch [1440]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:39:56,506 Epoch[2] Batch [1450]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:40:03,283 Epoch[2] Batch [1460]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:40:09,946 Epoch[2] Batch [1470]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:40:16,688 Epoch[2] Batch [1480]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:40:20,730 Epoch[2] Train-FCNLogLoss=nan
2017-07-13 18:40:20,730 Epoch[2] Time cost=1000.240
2017-07-13 18:40:21,907 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-13 18:40:26,122 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-13 18:40:33,676 Epoch[3] Batch [10]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:40:40,407 Epoch[3] Batch [20]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:40:47,117 Epoch[3] Batch [30]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:40:53,880 Epoch[3] Batch [40]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:00,594 Epoch[3] Batch [50]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:07,349 Epoch[3] Batch [60]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:14,082 Epoch[3] Batch [70]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:20,820 Epoch[3] Batch [80]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:27,565 Epoch[3] Batch [90]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:34,285 Epoch[3] Batch [100]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:41,063 Epoch[3] Batch [110]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:47,811 Epoch[3] Batch [120]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:41:54,520 Epoch[3] Batch [130]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:01,262 Epoch[3] Batch [140]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:07,992 Epoch[3] Batch [150]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:14,756 Epoch[3] Batch [160]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:21,486 Epoch[3] Batch [170]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:28,272 Epoch[3] Batch [180]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:35,043 Epoch[3] Batch [190]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:41,761 Epoch[3] Batch [200]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:48,489 Epoch[3] Batch [210]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:42:55,219 Epoch[3] Batch [220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:02,092 Epoch[3] Batch [230]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:09,266 Epoch[3] Batch [240]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:15,859 Epoch[3] Batch [250]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:22,607 Epoch[3] Batch [260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:29,343 Epoch[3] Batch [270]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:36,153 Epoch[3] Batch [280]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:42,834 Epoch[3] Batch [290]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:49,604 Epoch[3] Batch [300]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:43:56,319 Epoch[3] Batch [310]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:03,039 Epoch[3] Batch [320]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:09,790 Epoch[3] Batch [330]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:16,560 Epoch[3] Batch [340]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:23,336 Epoch[3] Batch [350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:30,138 Epoch[3] Batch [360]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:36,949 Epoch[3] Batch [370]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:43,700 Epoch[3] Batch [380]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:50,404 Epoch[3] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:44:57,116 Epoch[3] Batch [400]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:03,849 Epoch[3] Batch [410]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:10,575 Epoch[3] Batch [420]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:17,306 Epoch[3] Batch [430]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:24,128 Epoch[3] Batch [440]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:30,871 Epoch[3] Batch [450]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:37,604 Epoch[3] Batch [460]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:44,313 Epoch[3] Batch [470]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:51,039 Epoch[3] Batch [480]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:45:57,774 Epoch[3] Batch [490]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:04,494 Epoch[3] Batch [500]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:11,268 Epoch[3] Batch [510]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:18,003 Epoch[3] Batch [520]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:24,765 Epoch[3] Batch [530]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:31,530 Epoch[3] Batch [540]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:38,277 Epoch[3] Batch [550]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:44,982 Epoch[3] Batch [560]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:51,708 Epoch[3] Batch [570]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:46:58,434 Epoch[3] Batch [580]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:05,199 Epoch[3] Batch [590]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:11,922 Epoch[3] Batch [600]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:18,630 Epoch[3] Batch [610]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:25,365 Epoch[3] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:32,146 Epoch[3] Batch [630]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:38,920 Epoch[3] Batch [640]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:45,625 Epoch[3] Batch [650]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:52,398 Epoch[3] Batch [660]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:47:59,134 Epoch[3] Batch [670]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:05,870 Epoch[3] Batch [680]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:12,625 Epoch[3] Batch [690]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:19,382 Epoch[3] Batch [700]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:26,088 Epoch[3] Batch [710]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:32,920 Epoch[3] Batch [720]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:39,506 Epoch[3] Batch [730]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:46,261 Epoch[3] Batch [740]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:53,180 Epoch[3] Batch [750]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:48:59,987 Epoch[3] Batch [760]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:06,753 Epoch[3] Batch [770]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:13,523 Epoch[3] Batch [780]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:20,255 Epoch[3] Batch [790]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:26,922 Epoch[3] Batch [800]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:33,632 Epoch[3] Batch [810]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:40,444 Epoch[3] Batch [820]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:47,231 Epoch[3] Batch [830]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:49:54,190 Epoch[3] Batch [840]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:00,906 Epoch[3] Batch [850]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:07,728 Epoch[3] Batch [860]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:14,406 Epoch[3] Batch [870]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:21,134 Epoch[3] Batch [880]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:27,778 Epoch[3] Batch [890]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:34,476 Epoch[3] Batch [900]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:41,234 Epoch[3] Batch [910]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:47,975 Epoch[3] Batch [920]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:50:54,711 Epoch[3] Batch [930]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:01,494 Epoch[3] Batch [940]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:08,250 Epoch[3] Batch [950]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:14,930 Epoch[3] Batch [960]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:21,699 Epoch[3] Batch [970]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:28,365 Epoch[3] Batch [980]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:35,129 Epoch[3] Batch [990]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:41,916 Epoch[3] Batch [1000]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:48,652 Epoch[3] Batch [1010]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:51:55,347 Epoch[3] Batch [1020]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:02,113 Epoch[3] Batch [1030]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:08,813 Epoch[3] Batch [1040]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:15,545 Epoch[3] Batch [1050]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:22,282 Epoch[3] Batch [1060]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:29,005 Epoch[3] Batch [1070]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:35,802 Epoch[3] Batch [1080]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:42,493 Epoch[3] Batch [1090]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:49,302 Epoch[3] Batch [1100]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:52:55,979 Epoch[3] Batch [1110]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:02,790 Epoch[3] Batch [1120]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:09,769 Epoch[3] Batch [1130]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:16,461 Epoch[3] Batch [1140]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:23,211 Epoch[3] Batch [1150]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:29,897 Epoch[3] Batch [1160]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:36,659 Epoch[3] Batch [1170]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:43,457 Epoch[3] Batch [1180]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:50,178 Epoch[3] Batch [1190]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:53:56,938 Epoch[3] Batch [1200]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:03,733 Epoch[3] Batch [1210]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:10,466 Epoch[3] Batch [1220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:17,247 Epoch[3] Batch [1230]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:23,976 Epoch[3] Batch [1240]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:30,713 Epoch[3] Batch [1250]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:37,513 Epoch[3] Batch [1260]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:44,220 Epoch[3] Batch [1270]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:50,845 Epoch[3] Batch [1280]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:54:57,615 Epoch[3] Batch [1290]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:04,401 Epoch[3] Batch [1300]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:11,164 Epoch[3] Batch [1310]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:17,905 Epoch[3] Batch [1320]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:24,362 Epoch[3] Batch [1330]	Speed: 6.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:31,077 Epoch[3] Batch [1340]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:37,780 Epoch[3] Batch [1350]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:44,533 Epoch[3] Batch [1360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:51,311 Epoch[3] Batch [1370]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:55:58,043 Epoch[3] Batch [1380]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:04,768 Epoch[3] Batch [1390]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:11,513 Epoch[3] Batch [1400]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:18,206 Epoch[3] Batch [1410]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:24,916 Epoch[3] Batch [1420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:31,626 Epoch[3] Batch [1430]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:38,391 Epoch[3] Batch [1440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:45,107 Epoch[3] Batch [1450]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:51,840 Epoch[3] Batch [1460]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:56:58,557 Epoch[3] Batch [1470]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:57:05,285 Epoch[3] Batch [1480]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:57:09,354 Epoch[3] Train-FCNLogLoss=nan
2017-07-13 18:57:09,354 Epoch[3] Time cost=1003.231
2017-07-13 18:57:10,406 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.params"
2017-07-13 18:57:15,066 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.states"
2017-07-13 18:57:22,812 Epoch[4] Batch [10]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:57:29,634 Epoch[4] Batch [20]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:57:36,317 Epoch[4] Batch [30]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:57:43,084 Epoch[4] Batch [40]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:57:49,850 Epoch[4] Batch [50]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:57:56,675 Epoch[4] Batch [60]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:03,269 Epoch[4] Batch [70]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:10,145 Epoch[4] Batch [80]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:16,853 Epoch[4] Batch [90]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:23,542 Epoch[4] Batch [100]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:30,337 Epoch[4] Batch [110]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:36,999 Epoch[4] Batch [120]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:43,769 Epoch[4] Batch [130]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:50,486 Epoch[4] Batch [140]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:58:57,210 Epoch[4] Batch [150]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:04,352 Epoch[4] Batch [160]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:11,240 Epoch[4] Batch [170]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:17,950 Epoch[4] Batch [180]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:24,695 Epoch[4] Batch [190]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:31,453 Epoch[4] Batch [200]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:38,172 Epoch[4] Batch [210]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:44,923 Epoch[4] Batch [220]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:51,650 Epoch[4] Batch [230]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 18:59:58,377 Epoch[4] Batch [240]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:05,116 Epoch[4] Batch [250]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:11,840 Epoch[4] Batch [260]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:18,596 Epoch[4] Batch [270]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:25,411 Epoch[4] Batch [280]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:32,045 Epoch[4] Batch [290]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:38,782 Epoch[4] Batch [300]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:45,510 Epoch[4] Batch [310]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:52,268 Epoch[4] Batch [320]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:00:59,010 Epoch[4] Batch [330]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:05,750 Epoch[4] Batch [340]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:12,487 Epoch[4] Batch [350]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:19,259 Epoch[4] Batch [360]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:25,988 Epoch[4] Batch [370]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:32,687 Epoch[4] Batch [380]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:39,477 Epoch[4] Batch [390]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:46,102 Epoch[4] Batch [400]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:53,242 Epoch[4] Batch [410]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:01:59,885 Epoch[4] Batch [420]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:06,630 Epoch[4] Batch [430]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:13,334 Epoch[4] Batch [440]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:20,086 Epoch[4] Batch [450]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:26,807 Epoch[4] Batch [460]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:33,498 Epoch[4] Batch [470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:40,231 Epoch[4] Batch [480]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:47,094 Epoch[4] Batch [490]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:02:53,889 Epoch[4] Batch [500]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:00,598 Epoch[4] Batch [510]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:07,309 Epoch[4] Batch [520]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:13,969 Epoch[4] Batch [530]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:20,678 Epoch[4] Batch [540]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:27,094 Epoch[4] Batch [550]	Speed: 6.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:33,640 Epoch[4] Batch [560]	Speed: 6.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:40,310 Epoch[4] Batch [570]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:46,990 Epoch[4] Batch [580]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:03:53,420 Epoch[4] Batch [590]	Speed: 6.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:00,103 Epoch[4] Batch [600]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:06,748 Epoch[4] Batch [610]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:13,224 Epoch[4] Batch [620]	Speed: 6.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:20,099 Epoch[4] Batch [630]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:26,802 Epoch[4] Batch [640]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:33,409 Epoch[4] Batch [650]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:40,092 Epoch[4] Batch [660]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:46,750 Epoch[4] Batch [670]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:04:53,624 Epoch[4] Batch [680]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:00,391 Epoch[4] Batch [690]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:07,093 Epoch[4] Batch [700]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:13,854 Epoch[4] Batch [710]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:20,500 Epoch[4] Batch [720]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:27,182 Epoch[4] Batch [730]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:33,906 Epoch[4] Batch [740]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:40,655 Epoch[4] Batch [750]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:47,239 Epoch[4] Batch [760]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:05:54,176 Epoch[4] Batch [770]	Speed: 5.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:00,852 Epoch[4] Batch [780]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:07,553 Epoch[4] Batch [790]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:14,375 Epoch[4] Batch [800]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:21,136 Epoch[4] Batch [810]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:27,819 Epoch[4] Batch [820]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:34,584 Epoch[4] Batch [830]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:41,296 Epoch[4] Batch [840]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:47,885 Epoch[4] Batch [850]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:06:54,552 Epoch[4] Batch [860]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:00,886 Epoch[4] Batch [870]	Speed: 6.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:07,613 Epoch[4] Batch [880]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:14,119 Epoch[4] Batch [890]	Speed: 6.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:20,781 Epoch[4] Batch [900]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:27,517 Epoch[4] Batch [910]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:34,107 Epoch[4] Batch [920]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:40,900 Epoch[4] Batch [930]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:47,554 Epoch[4] Batch [940]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:07:54,213 Epoch[4] Batch [950]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:00,913 Epoch[4] Batch [960]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:07,565 Epoch[4] Batch [970]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:14,413 Epoch[4] Batch [980]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:21,201 Epoch[4] Batch [990]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:27,699 Epoch[4] Batch [1000]	Speed: 6.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:35,002 Epoch[4] Batch [1010]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:41,957 Epoch[4] Batch [1020]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:48,973 Epoch[4] Batch [1030]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:08:56,514 Epoch[4] Batch [1040]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:03,851 Epoch[4] Batch [1050]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:11,391 Epoch[4] Batch [1060]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:18,812 Epoch[4] Batch [1070]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:25,907 Epoch[4] Batch [1080]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:33,360 Epoch[4] Batch [1090]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:40,500 Epoch[4] Batch [1100]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:47,572 Epoch[4] Batch [1110]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:09:54,767 Epoch[4] Batch [1120]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:02,201 Epoch[4] Batch [1130]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:09,752 Epoch[4] Batch [1140]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:16,814 Epoch[4] Batch [1150]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:23,983 Epoch[4] Batch [1160]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:31,104 Epoch[4] Batch [1170]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:38,815 Epoch[4] Batch [1180]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:45,175 Epoch[4] Batch [1190]	Speed: 6.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:52,370 Epoch[4] Batch [1200]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:10:59,616 Epoch[4] Batch [1210]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:06,819 Epoch[4] Batch [1220]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:13,408 Epoch[4] Batch [1230]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:20,640 Epoch[4] Batch [1240]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:27,787 Epoch[4] Batch [1250]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:35,008 Epoch[4] Batch [1260]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:42,488 Epoch[4] Batch [1270]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:49,858 Epoch[4] Batch [1280]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:11:57,140 Epoch[4] Batch [1290]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:04,413 Epoch[4] Batch [1300]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:11,959 Epoch[4] Batch [1310]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:19,048 Epoch[4] Batch [1320]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:26,606 Epoch[4] Batch [1330]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:34,187 Epoch[4] Batch [1340]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:41,442 Epoch[4] Batch [1350]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:48,713 Epoch[4] Batch [1360]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:12:56,021 Epoch[4] Batch [1370]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:03,245 Epoch[4] Batch [1380]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:10,551 Epoch[4] Batch [1390]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:17,656 Epoch[4] Batch [1400]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:24,167 Epoch[4] Batch [1410]	Speed: 6.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:30,760 Epoch[4] Batch [1420]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:37,406 Epoch[4] Batch [1430]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:43,977 Epoch[4] Batch [1440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:50,386 Epoch[4] Batch [1450]	Speed: 6.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:13:56,885 Epoch[4] Batch [1460]	Speed: 6.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:14:03,576 Epoch[4] Batch [1470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:14:10,264 Epoch[4] Batch [1480]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:14:14,303 Epoch[4] Train-FCNLogLoss=nan
2017-07-13 19:14:14,303 Epoch[4] Time cost=1019.236
2017-07-13 19:14:15,494 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.params"
2017-07-13 19:14:19,474 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.states"
2017-07-13 19:14:27,150 Epoch[5] Batch [10]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:14:33,886 Epoch[5] Batch [20]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:14:40,508 Epoch[5] Batch [30]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:14:47,302 Epoch[5] Batch [40]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:14:53,951 Epoch[5] Batch [50]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:00,466 Epoch[5] Batch [60]	Speed: 6.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:07,165 Epoch[5] Batch [70]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:13,940 Epoch[5] Batch [80]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:20,546 Epoch[5] Batch [90]	Speed: 6.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:27,219 Epoch[5] Batch [100]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:34,105 Epoch[5] Batch [110]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:40,789 Epoch[5] Batch [120]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:47,346 Epoch[5] Batch [130]	Speed: 6.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:15:54,286 Epoch[5] Batch [140]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:01,040 Epoch[5] Batch [150]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:07,801 Epoch[5] Batch [160]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:14,534 Epoch[5] Batch [170]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:21,287 Epoch[5] Batch [180]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:28,135 Epoch[5] Batch [190]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:34,780 Epoch[5] Batch [200]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:41,546 Epoch[5] Batch [210]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:48,409 Epoch[5] Batch [220]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:16:55,028 Epoch[5] Batch [230]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:01,778 Epoch[5] Batch [240]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:08,628 Epoch[5] Batch [250]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:15,263 Epoch[5] Batch [260]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:22,033 Epoch[5] Batch [270]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:28,743 Epoch[5] Batch [280]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:35,524 Epoch[5] Batch [290]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:42,303 Epoch[5] Batch [300]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:49,014 Epoch[5] Batch [310]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:17:55,713 Epoch[5] Batch [320]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:02,467 Epoch[5] Batch [330]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:09,177 Epoch[5] Batch [340]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:15,890 Epoch[5] Batch [350]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:22,692 Epoch[5] Batch [360]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:29,380 Epoch[5] Batch [370]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:36,084 Epoch[5] Batch [380]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:42,782 Epoch[5] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:49,577 Epoch[5] Batch [400]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:18:56,307 Epoch[5] Batch [410]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:03,104 Epoch[5] Batch [420]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:09,731 Epoch[5] Batch [430]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:16,466 Epoch[5] Batch [440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:23,156 Epoch[5] Batch [450]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:29,914 Epoch[5] Batch [460]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:36,691 Epoch[5] Batch [470]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:43,434 Epoch[5] Batch [480]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:50,165 Epoch[5] Batch [490]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:19:56,860 Epoch[5] Batch [500]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:03,428 Epoch[5] Batch [510]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:10,171 Epoch[5] Batch [520]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:16,882 Epoch[5] Batch [530]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:23,625 Epoch[5] Batch [540]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:30,340 Epoch[5] Batch [550]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:37,076 Epoch[5] Batch [560]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:43,764 Epoch[5] Batch [570]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:50,483 Epoch[5] Batch [580]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:20:57,233 Epoch[5] Batch [590]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:04,152 Epoch[5] Batch [600]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:10,788 Epoch[5] Batch [610]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:17,505 Epoch[5] Batch [620]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:24,319 Epoch[5] Batch [630]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:30,976 Epoch[5] Batch [640]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:37,676 Epoch[5] Batch [650]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:44,388 Epoch[5] Batch [660]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:51,111 Epoch[5] Batch [670]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:21:57,840 Epoch[5] Batch [680]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:04,586 Epoch[5] Batch [690]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:11,327 Epoch[5] Batch [700]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:18,047 Epoch[5] Batch [710]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:24,812 Epoch[5] Batch [720]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:31,423 Epoch[5] Batch [730]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:38,168 Epoch[5] Batch [740]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:44,989 Epoch[5] Batch [750]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:51,648 Epoch[5] Batch [760]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:22:58,351 Epoch[5] Batch [770]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:05,035 Epoch[5] Batch [780]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:11,734 Epoch[5] Batch [790]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:18,465 Epoch[5] Batch [800]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:25,275 Epoch[5] Batch [810]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:31,960 Epoch[5] Batch [820]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:38,609 Epoch[5] Batch [830]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:45,351 Epoch[5] Batch [840]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:52,101 Epoch[5] Batch [850]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:23:58,810 Epoch[5] Batch [860]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:05,529 Epoch[5] Batch [870]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:12,270 Epoch[5] Batch [880]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:19,001 Epoch[5] Batch [890]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:25,652 Epoch[5] Batch [900]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:32,367 Epoch[5] Batch [910]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:39,089 Epoch[5] Batch [920]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:45,879 Epoch[5] Batch [930]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:52,490 Epoch[5] Batch [940]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:24:59,270 Epoch[5] Batch [950]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:06,039 Epoch[5] Batch [960]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:12,717 Epoch[5] Batch [970]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:19,518 Epoch[5] Batch [980]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:26,286 Epoch[5] Batch [990]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:33,027 Epoch[5] Batch [1000]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:39,816 Epoch[5] Batch [1010]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:46,715 Epoch[5] Batch [1020]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:25:53,402 Epoch[5] Batch [1030]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:00,125 Epoch[5] Batch [1040]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:06,983 Epoch[5] Batch [1050]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:13,530 Epoch[5] Batch [1060]	Speed: 6.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:20,380 Epoch[5] Batch [1070]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:27,034 Epoch[5] Batch [1080]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:33,787 Epoch[5] Batch [1090]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:40,452 Epoch[5] Batch [1100]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:47,188 Epoch[5] Batch [1110]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:26:53,861 Epoch[5] Batch [1120]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:00,572 Epoch[5] Batch [1130]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:07,340 Epoch[5] Batch [1140]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:14,161 Epoch[5] Batch [1150]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:20,719 Epoch[5] Batch [1160]	Speed: 6.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:27,449 Epoch[5] Batch [1170]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:34,255 Epoch[5] Batch [1180]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:40,993 Epoch[5] Batch [1190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:47,753 Epoch[5] Batch [1200]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:27:54,469 Epoch[5] Batch [1210]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:01,199 Epoch[5] Batch [1220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:07,910 Epoch[5] Batch [1230]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:14,611 Epoch[5] Batch [1240]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:21,330 Epoch[5] Batch [1250]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:28,124 Epoch[5] Batch [1260]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:34,763 Epoch[5] Batch [1270]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:41,502 Epoch[5] Batch [1280]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:48,310 Epoch[5] Batch [1290]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:28:54,938 Epoch[5] Batch [1300]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:01,714 Epoch[5] Batch [1310]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:08,389 Epoch[5] Batch [1320]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:15,115 Epoch[5] Batch [1330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:21,828 Epoch[5] Batch [1340]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:28,530 Epoch[5] Batch [1350]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:35,471 Epoch[5] Batch [1360]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:42,220 Epoch[5] Batch [1370]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:48,956 Epoch[5] Batch [1380]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:29:55,673 Epoch[5] Batch [1390]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:01,752 Epoch[5] Batch [1400]	Speed: 6.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:08,596 Epoch[5] Batch [1410]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:15,322 Epoch[5] Batch [1420]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:22,014 Epoch[5] Batch [1430]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:28,743 Epoch[5] Batch [1440]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:35,462 Epoch[5] Batch [1450]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:42,142 Epoch[5] Batch [1460]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:48,848 Epoch[5] Batch [1470]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:55,573 Epoch[5] Batch [1480]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:30:59,543 Epoch[5] Train-FCNLogLoss=nan
2017-07-13 19:30:59,544 Epoch[5] Time cost=1000.069
2017-07-13 19:31:00,510 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.params"
2017-07-13 19:31:04,494 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.states"
2017-07-13 19:31:12,248 Epoch[6] Batch [10]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:31:19,022 Epoch[6] Batch [20]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:31:25,678 Epoch[6] Batch [30]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:31:32,471 Epoch[6] Batch [40]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:31:39,107 Epoch[6] Batch [50]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:31:45,955 Epoch[6] Batch [60]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:31:52,653 Epoch[6] Batch [70]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:31:59,377 Epoch[6] Batch [80]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:06,033 Epoch[6] Batch [90]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:12,793 Epoch[6] Batch [100]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:19,496 Epoch[6] Batch [110]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:26,234 Epoch[6] Batch [120]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:32,923 Epoch[6] Batch [130]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:39,670 Epoch[6] Batch [140]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:46,358 Epoch[6] Batch [150]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:53,073 Epoch[6] Batch [160]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:32:59,823 Epoch[6] Batch [170]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:06,534 Epoch[6] Batch [180]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:13,259 Epoch[6] Batch [190]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:19,992 Epoch[6] Batch [200]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:26,666 Epoch[6] Batch [210]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:33,512 Epoch[6] Batch [220]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:40,103 Epoch[6] Batch [230]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:47,135 Epoch[6] Batch [240]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:33:53,763 Epoch[6] Batch [250]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:00,472 Epoch[6] Batch [260]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:07,192 Epoch[6] Batch [270]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:13,909 Epoch[6] Batch [280]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:20,684 Epoch[6] Batch [290]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:27,374 Epoch[6] Batch [300]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:33,999 Epoch[6] Batch [310]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:40,792 Epoch[6] Batch [320]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:47,519 Epoch[6] Batch [330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:34:54,298 Epoch[6] Batch [340]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:01,095 Epoch[6] Batch [350]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:07,896 Epoch[6] Batch [360]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:14,753 Epoch[6] Batch [370]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:21,389 Epoch[6] Batch [380]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:28,277 Epoch[6] Batch [390]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:35,246 Epoch[6] Batch [400]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:42,021 Epoch[6] Batch [410]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:48,933 Epoch[6] Batch [420]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:35:55,560 Epoch[6] Batch [430]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:02,275 Epoch[6] Batch [440]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:09,091 Epoch[6] Batch [450]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:15,855 Epoch[6] Batch [460]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:22,756 Epoch[6] Batch [470]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:29,475 Epoch[6] Batch [480]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:36,083 Epoch[6] Batch [490]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:42,802 Epoch[6] Batch [500]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:49,536 Epoch[6] Batch [510]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:36:56,258 Epoch[6] Batch [520]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:03,042 Epoch[6] Batch [530]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:09,739 Epoch[6] Batch [540]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:16,428 Epoch[6] Batch [550]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:23,111 Epoch[6] Batch [560]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:29,888 Epoch[6] Batch [570]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:36,523 Epoch[6] Batch [580]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:43,271 Epoch[6] Batch [590]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:49,960 Epoch[6] Batch [600]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:37:56,786 Epoch[6] Batch [610]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:03,479 Epoch[6] Batch [620]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:10,212 Epoch[6] Batch [630]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:16,902 Epoch[6] Batch [640]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:23,688 Epoch[6] Batch [650]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:30,350 Epoch[6] Batch [660]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:37,080 Epoch[6] Batch [670]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:43,796 Epoch[6] Batch [680]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:50,520 Epoch[6] Batch [690]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:38:57,285 Epoch[6] Batch [700]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:04,062 Epoch[6] Batch [710]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:10,750 Epoch[6] Batch [720]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:17,486 Epoch[6] Batch [730]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:24,195 Epoch[6] Batch [740]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:30,967 Epoch[6] Batch [750]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:37,716 Epoch[6] Batch [760]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:44,588 Epoch[6] Batch [770]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:51,200 Epoch[6] Batch [780]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:39:57,886 Epoch[6] Batch [790]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:04,613 Epoch[6] Batch [800]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:11,312 Epoch[6] Batch [810]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:18,086 Epoch[6] Batch [820]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:24,742 Epoch[6] Batch [830]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:31,857 Epoch[6] Batch [840]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:39,583 Epoch[6] Batch [850]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:46,492 Epoch[6] Batch [860]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:40:53,478 Epoch[6] Batch [870]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:00,308 Epoch[6] Batch [880]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:07,337 Epoch[6] Batch [890]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:14,473 Epoch[6] Batch [900]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:21,457 Epoch[6] Batch [910]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:28,583 Epoch[6] Batch [920]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:35,584 Epoch[6] Batch [930]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:42,746 Epoch[6] Batch [940]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:50,055 Epoch[6] Batch [950]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:41:56,732 Epoch[6] Batch [960]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:03,489 Epoch[6] Batch [970]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:10,195 Epoch[6] Batch [980]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:16,865 Epoch[6] Batch [990]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:23,737 Epoch[6] Batch [1000]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:30,669 Epoch[6] Batch [1010]	Speed: 5.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:37,585 Epoch[6] Batch [1020]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:44,760 Epoch[6] Batch [1030]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:51,478 Epoch[6] Batch [1040]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:42:58,159 Epoch[6] Batch [1050]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:04,896 Epoch[6] Batch [1060]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:11,591 Epoch[6] Batch [1070]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:18,097 Epoch[6] Batch [1080]	Speed: 6.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:25,100 Epoch[6] Batch [1090]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:32,263 Epoch[6] Batch [1100]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:39,514 Epoch[6] Batch [1110]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:46,312 Epoch[6] Batch [1120]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:43:53,419 Epoch[6] Batch [1130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:00,159 Epoch[6] Batch [1140]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:06,824 Epoch[6] Batch [1150]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:13,743 Epoch[6] Batch [1160]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:20,358 Epoch[6] Batch [1170]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:27,419 Epoch[6] Batch [1180]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:34,631 Epoch[6] Batch [1190]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:41,816 Epoch[6] Batch [1200]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:48,911 Epoch[6] Batch [1210]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:44:56,001 Epoch[6] Batch [1220]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:02,712 Epoch[6] Batch [1230]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:09,519 Epoch[6] Batch [1240]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:16,198 Epoch[6] Batch [1250]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:23,219 Epoch[6] Batch [1260]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:30,464 Epoch[6] Batch [1270]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:37,549 Epoch[6] Batch [1280]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:44,439 Epoch[6] Batch [1290]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:51,181 Epoch[6] Batch [1300]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:45:57,948 Epoch[6] Batch [1310]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:04,526 Epoch[6] Batch [1320]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:11,750 Epoch[6] Batch [1330]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:18,691 Epoch[6] Batch [1340]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:25,967 Epoch[6] Batch [1350]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:32,678 Epoch[6] Batch [1360]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:39,139 Epoch[6] Batch [1370]	Speed: 6.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:45,268 Epoch[6] Batch [1380]	Speed: 6.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:51,917 Epoch[6] Batch [1390]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:46:58,596 Epoch[6] Batch [1400]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:05,150 Epoch[6] Batch [1410]	Speed: 6.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:11,780 Epoch[6] Batch [1420]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:18,599 Epoch[6] Batch [1430]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:25,676 Epoch[6] Batch [1440]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:32,727 Epoch[6] Batch [1450]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:39,615 Epoch[6] Batch [1460]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:46,313 Epoch[6] Batch [1470]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:53,011 Epoch[6] Batch [1480]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:47:57,035 Epoch[6] Train-FCNLogLoss=nan
2017-07-13 19:47:57,036 Epoch[6] Time cost=1012.541
2017-07-13 19:47:58,231 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.params"
2017-07-13 19:48:02,154 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.states"
2017-07-13 19:48:09,943 Epoch[7] Batch [10]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:48:16,639 Epoch[7] Batch [20]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:48:23,310 Epoch[7] Batch [30]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:48:30,024 Epoch[7] Batch [40]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:48:36,635 Epoch[7] Batch [50]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:48:43,366 Epoch[7] Batch [60]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:48:50,130 Epoch[7] Batch [70]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:48:56,792 Epoch[7] Batch [80]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:03,597 Epoch[7] Batch [90]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:10,249 Epoch[7] Batch [100]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:16,816 Epoch[7] Batch [110]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:23,951 Epoch[7] Batch [120]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:31,082 Epoch[7] Batch [130]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:38,429 Epoch[7] Batch [140]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:45,432 Epoch[7] Batch [150]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:52,230 Epoch[7] Batch [160]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:49:59,388 Epoch[7] Batch [170]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:06,556 Epoch[7] Batch [180]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:13,625 Epoch[7] Batch [190]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:20,406 Epoch[7] Batch [200]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:27,315 Epoch[7] Batch [210]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:34,370 Epoch[7] Batch [220]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:41,767 Epoch[7] Batch [230]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:48,602 Epoch[7] Batch [240]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:50:55,356 Epoch[7] Batch [250]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:02,416 Epoch[7] Batch [260]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:09,851 Epoch[7] Batch [270]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:16,815 Epoch[7] Batch [280]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:23,898 Epoch[7] Batch [290]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:31,140 Epoch[7] Batch [300]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:38,140 Epoch[7] Batch [310]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:44,777 Epoch[7] Batch [320]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:51,997 Epoch[7] Batch [330]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:51:58,823 Epoch[7] Batch [340]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:05,683 Epoch[7] Batch [350]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:12,765 Epoch[7] Batch [360]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:19,759 Epoch[7] Batch [370]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:26,862 Epoch[7] Batch [380]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:33,989 Epoch[7] Batch [390]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:41,067 Epoch[7] Batch [400]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:48,399 Epoch[7] Batch [410]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:52:55,725 Epoch[7] Batch [420]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:02,855 Epoch[7] Batch [430]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:09,930 Epoch[7] Batch [440]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:17,345 Epoch[7] Batch [450]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:24,613 Epoch[7] Batch [460]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:31,795 Epoch[7] Batch [470]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:38,981 Epoch[7] Batch [480]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:46,262 Epoch[7] Batch [490]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:53:53,139 Epoch[7] Batch [500]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:00,222 Epoch[7] Batch [510]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:07,964 Epoch[7] Batch [520]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:15,388 Epoch[7] Batch [530]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:22,928 Epoch[7] Batch [540]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:30,596 Epoch[7] Batch [550]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:37,878 Epoch[7] Batch [560]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:45,508 Epoch[7] Batch [570]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:52,505 Epoch[7] Batch [580]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:54:59,925 Epoch[7] Batch [590]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:07,314 Epoch[7] Batch [600]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:14,136 Epoch[7] Batch [610]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:21,528 Epoch[7] Batch [620]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:28,708 Epoch[7] Batch [630]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:36,121 Epoch[7] Batch [640]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:43,351 Epoch[7] Batch [650]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:50,360 Epoch[7] Batch [660]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:55:57,511 Epoch[7] Batch [670]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:04,709 Epoch[7] Batch [680]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:12,262 Epoch[7] Batch [690]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:19,276 Epoch[7] Batch [700]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:26,553 Epoch[7] Batch [710]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:34,008 Epoch[7] Batch [720]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:41,460 Epoch[7] Batch [730]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:48,266 Epoch[7] Batch [740]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:56:55,209 Epoch[7] Batch [750]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:02,359 Epoch[7] Batch [760]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:09,396 Epoch[7] Batch [770]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:16,894 Epoch[7] Batch [780]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:23,663 Epoch[7] Batch [790]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:30,385 Epoch[7] Batch [800]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:37,144 Epoch[7] Batch [810]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:43,835 Epoch[7] Batch [820]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:50,833 Epoch[7] Batch [830]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:57:57,755 Epoch[7] Batch [840]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:04,653 Epoch[7] Batch [850]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:11,894 Epoch[7] Batch [860]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:18,831 Epoch[7] Batch [870]	Speed: 5.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:26,020 Epoch[7] Batch [880]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:32,948 Epoch[7] Batch [890]	Speed: 5.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:40,004 Epoch[7] Batch [900]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:47,141 Epoch[7] Batch [910]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:58:54,469 Epoch[7] Batch [920]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:01,156 Epoch[7] Batch [930]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:08,269 Epoch[7] Batch [940]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:15,059 Epoch[7] Batch [950]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:22,185 Epoch[7] Batch [960]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:29,201 Epoch[7] Batch [970]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:36,319 Epoch[7] Batch [980]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:43,586 Epoch[7] Batch [990]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:51,017 Epoch[7] Batch [1000]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 19:59:58,318 Epoch[7] Batch [1010]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:05,409 Epoch[7] Batch [1020]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:12,649 Epoch[7] Batch [1030]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:19,903 Epoch[7] Batch [1040]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:26,931 Epoch[7] Batch [1050]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:33,881 Epoch[7] Batch [1060]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:40,894 Epoch[7] Batch [1070]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:47,939 Epoch[7] Batch [1080]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:00:54,866 Epoch[7] Batch [1090]	Speed: 5.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:02,512 Epoch[7] Batch [1100]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:09,843 Epoch[7] Batch [1110]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:16,720 Epoch[7] Batch [1120]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:23,225 Epoch[7] Batch [1130]	Speed: 6.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:30,585 Epoch[7] Batch [1140]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:37,791 Epoch[7] Batch [1150]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:44,434 Epoch[7] Batch [1160]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:51,469 Epoch[7] Batch [1170]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:01:58,018 Epoch[7] Batch [1180]	Speed: 6.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:04,863 Epoch[7] Batch [1190]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:11,854 Epoch[7] Batch [1200]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:19,210 Epoch[7] Batch [1210]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:26,670 Epoch[7] Batch [1220]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:34,211 Epoch[7] Batch [1230]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:41,538 Epoch[7] Batch [1240]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:49,149 Epoch[7] Batch [1250]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:02:56,469 Epoch[7] Batch [1260]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:03,456 Epoch[7] Batch [1270]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:10,648 Epoch[7] Batch [1280]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:17,757 Epoch[7] Batch [1290]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:24,865 Epoch[7] Batch [1300]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:32,036 Epoch[7] Batch [1310]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:39,249 Epoch[7] Batch [1320]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:46,653 Epoch[7] Batch [1330]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:03:53,840 Epoch[7] Batch [1340]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:01,036 Epoch[7] Batch [1350]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:07,998 Epoch[7] Batch [1360]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:15,196 Epoch[7] Batch [1370]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:22,228 Epoch[7] Batch [1380]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:29,223 Epoch[7] Batch [1390]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:36,605 Epoch[7] Batch [1400]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:44,021 Epoch[7] Batch [1410]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:50,884 Epoch[7] Batch [1420]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:04:57,987 Epoch[7] Batch [1430]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:05:04,559 Epoch[7] Batch [1440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:05:11,257 Epoch[7] Batch [1450]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:05:18,112 Epoch[7] Batch [1460]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:05:25,550 Epoch[7] Batch [1470]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:05:32,269 Epoch[7] Batch [1480]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:05:36,423 Epoch[7] Train-FCNLogLoss=nan
2017-07-13 20:05:36,423 Epoch[7] Time cost=1054.269
2017-07-13 20:05:37,645 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.params"
2017-07-13 20:05:41,544 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.states"
2017-07-13 20:05:49,216 Epoch[8] Batch [10]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:05:55,856 Epoch[8] Batch [20]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:02,404 Epoch[8] Batch [30]	Speed: 6.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:08,976 Epoch[8] Batch [40]	Speed: 6.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:15,752 Epoch[8] Batch [50]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:22,226 Epoch[8] Batch [60]	Speed: 6.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:29,067 Epoch[8] Batch [70]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:35,757 Epoch[8] Batch [80]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:42,402 Epoch[8] Batch [90]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:49,292 Epoch[8] Batch [100]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:06:56,109 Epoch[8] Batch [110]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:02,957 Epoch[8] Batch [120]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:09,741 Epoch[8] Batch [130]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:16,877 Epoch[8] Batch [140]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:23,610 Epoch[8] Batch [150]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:30,345 Epoch[8] Batch [160]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:37,050 Epoch[8] Batch [170]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:43,816 Epoch[8] Batch [180]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:50,551 Epoch[8] Batch [190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:07:57,267 Epoch[8] Batch [200]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:03,988 Epoch[8] Batch [210]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:10,711 Epoch[8] Batch [220]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:17,661 Epoch[8] Batch [230]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:24,370 Epoch[8] Batch [240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:31,080 Epoch[8] Batch [250]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:37,857 Epoch[8] Batch [260]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:44,529 Epoch[8] Batch [270]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:51,596 Epoch[8] Batch [280]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:08:58,127 Epoch[8] Batch [290]	Speed: 6.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:05,305 Epoch[8] Batch [300]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:12,330 Epoch[8] Batch [310]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:19,622 Epoch[8] Batch [320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:26,820 Epoch[8] Batch [330]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:33,814 Epoch[8] Batch [340]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:41,577 Epoch[8] Batch [350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:49,267 Epoch[8] Batch [360]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:09:56,716 Epoch[8] Batch [370]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:04,057 Epoch[8] Batch [380]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:11,176 Epoch[8] Batch [390]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:18,632 Epoch[8] Batch [400]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:26,073 Epoch[8] Batch [410]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:33,021 Epoch[8] Batch [420]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:39,764 Epoch[8] Batch [430]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:46,585 Epoch[8] Batch [440]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:53,331 Epoch[8] Batch [450]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:10:59,975 Epoch[8] Batch [460]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:07,321 Epoch[8] Batch [470]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:14,436 Epoch[8] Batch [480]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:21,153 Epoch[8] Batch [490]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:28,482 Epoch[8] Batch [500]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:35,830 Epoch[8] Batch [510]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:43,068 Epoch[8] Batch [520]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:49,907 Epoch[8] Batch [530]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:11:56,962 Epoch[8] Batch [540]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:03,771 Epoch[8] Batch [550]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:10,501 Epoch[8] Batch [560]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:17,559 Epoch[8] Batch [570]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:24,337 Epoch[8] Batch [580]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:31,055 Epoch[8] Batch [590]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:37,742 Epoch[8] Batch [600]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:44,544 Epoch[8] Batch [610]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:51,458 Epoch[8] Batch [620]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:12:58,283 Epoch[8] Batch [630]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:05,419 Epoch[8] Batch [640]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:12,628 Epoch[8] Batch [650]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:19,457 Epoch[8] Batch [660]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:26,508 Epoch[8] Batch [670]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:33,599 Epoch[8] Batch [680]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:40,826 Epoch[8] Batch [690]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:48,196 Epoch[8] Batch [700]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:13:55,363 Epoch[8] Batch [710]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:02,462 Epoch[8] Batch [720]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:09,540 Epoch[8] Batch [730]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:16,701 Epoch[8] Batch [740]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:23,588 Epoch[8] Batch [750]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:30,791 Epoch[8] Batch [760]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:38,173 Epoch[8] Batch [770]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:45,300 Epoch[8] Batch [780]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:52,576 Epoch[8] Batch [790]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:14:59,962 Epoch[8] Batch [800]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:07,369 Epoch[8] Batch [810]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:14,360 Epoch[8] Batch [820]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:21,551 Epoch[8] Batch [830]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:28,413 Epoch[8] Batch [840]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:35,642 Epoch[8] Batch [850]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:42,856 Epoch[8] Batch [860]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:49,974 Epoch[8] Batch [870]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:15:57,354 Epoch[8] Batch [880]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:04,778 Epoch[8] Batch [890]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:12,146 Epoch[8] Batch [900]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:19,686 Epoch[8] Batch [910]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:26,912 Epoch[8] Batch [920]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:34,413 Epoch[8] Batch [930]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:42,062 Epoch[8] Batch [940]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:49,043 Epoch[8] Batch [950]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:16:56,862 Epoch[8] Batch [960]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:03,957 Epoch[8] Batch [970]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:11,455 Epoch[8] Batch [980]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:18,737 Epoch[8] Batch [990]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:26,213 Epoch[8] Batch [1000]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:33,459 Epoch[8] Batch [1010]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:40,507 Epoch[8] Batch [1020]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:47,989 Epoch[8] Batch [1030]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:17:55,397 Epoch[8] Batch [1040]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:02,789 Epoch[8] Batch [1050]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:10,087 Epoch[8] Batch [1060]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:16,613 Epoch[8] Batch [1070]	Speed: 6.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:23,338 Epoch[8] Batch [1080]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:30,080 Epoch[8] Batch [1090]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:37,093 Epoch[8] Batch [1100]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:43,858 Epoch[8] Batch [1110]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:50,564 Epoch[8] Batch [1120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:18:57,236 Epoch[8] Batch [1130]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:04,051 Epoch[8] Batch [1140]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:10,716 Epoch[8] Batch [1150]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:17,413 Epoch[8] Batch [1160]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:24,173 Epoch[8] Batch [1170]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:30,790 Epoch[8] Batch [1180]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:37,648 Epoch[8] Batch [1190]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:44,353 Epoch[8] Batch [1200]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:50,995 Epoch[8] Batch [1210]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:19:57,757 Epoch[8] Batch [1220]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:04,435 Epoch[8] Batch [1230]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:11,189 Epoch[8] Batch [1240]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:17,894 Epoch[8] Batch [1250]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:24,516 Epoch[8] Batch [1260]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:31,573 Epoch[8] Batch [1270]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:38,491 Epoch[8] Batch [1280]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:45,382 Epoch[8] Batch [1290]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:52,389 Epoch[8] Batch [1300]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:20:59,018 Epoch[8] Batch [1310]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:05,778 Epoch[8] Batch [1320]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:12,521 Epoch[8] Batch [1330]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:19,215 Epoch[8] Batch [1340]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:25,910 Epoch[8] Batch [1350]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:32,602 Epoch[8] Batch [1360]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:39,218 Epoch[8] Batch [1370]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:45,926 Epoch[8] Batch [1380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:52,774 Epoch[8] Batch [1390]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:21:59,437 Epoch[8] Batch [1400]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:06,233 Epoch[8] Batch [1410]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:12,942 Epoch[8] Batch [1420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:19,720 Epoch[8] Batch [1430]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:26,487 Epoch[8] Batch [1440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:33,147 Epoch[8] Batch [1450]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:39,819 Epoch[8] Batch [1460]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:46,556 Epoch[8] Batch [1470]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:53,311 Epoch[8] Batch [1480]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:22:57,207 Epoch[8] Train-FCNLogLoss=nan
2017-07-13 20:22:57,207 Epoch[8] Time cost=1035.662
2017-07-13 20:22:58,209 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.params"
2017-07-13 20:23:02,075 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.states"
2017-07-13 20:23:09,698 Epoch[9] Batch [10]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:23:16,320 Epoch[9] Batch [20]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:23:23,066 Epoch[9] Batch [30]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:23:29,863 Epoch[9] Batch [40]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:23:36,592 Epoch[9] Batch [50]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:23:43,329 Epoch[9] Batch [60]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:23:50,016 Epoch[9] Batch [70]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:23:56,810 Epoch[9] Batch [80]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:03,364 Epoch[9] Batch [90]	Speed: 6.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:10,158 Epoch[9] Batch [100]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:16,928 Epoch[9] Batch [110]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:23,660 Epoch[9] Batch [120]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:30,349 Epoch[9] Batch [130]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:36,957 Epoch[9] Batch [140]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:43,619 Epoch[9] Batch [150]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:50,381 Epoch[9] Batch [160]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:24:57,022 Epoch[9] Batch [170]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:03,744 Epoch[9] Batch [180]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:10,409 Epoch[9] Batch [190]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:17,288 Epoch[9] Batch [200]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:23,887 Epoch[9] Batch [210]	Speed: 6.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:30,775 Epoch[9] Batch [220]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:37,354 Epoch[9] Batch [230]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:44,055 Epoch[9] Batch [240]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:50,754 Epoch[9] Batch [250]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:25:57,558 Epoch[9] Batch [260]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:04,316 Epoch[9] Batch [270]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:11,030 Epoch[9] Batch [280]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:17,659 Epoch[9] Batch [290]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:24,472 Epoch[9] Batch [300]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:31,229 Epoch[9] Batch [310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:38,141 Epoch[9] Batch [320]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:44,955 Epoch[9] Batch [330]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:51,586 Epoch[9] Batch [340]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:26:58,431 Epoch[9] Batch [350]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:05,971 Epoch[9] Batch [360]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:13,344 Epoch[9] Batch [370]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:20,508 Epoch[9] Batch [380]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:27,578 Epoch[9] Batch [390]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:34,698 Epoch[9] Batch [400]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:41,617 Epoch[9] Batch [410]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:49,116 Epoch[9] Batch [420]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:27:56,623 Epoch[9] Batch [430]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:04,706 Epoch[9] Batch [440]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:12,447 Epoch[9] Batch [450]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:20,129 Epoch[9] Batch [460]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:27,584 Epoch[9] Batch [470]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:34,893 Epoch[9] Batch [480]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:42,912 Epoch[9] Batch [490]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:50,489 Epoch[9] Batch [500]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:28:58,124 Epoch[9] Batch [510]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:05,822 Epoch[9] Batch [520]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:13,965 Epoch[9] Batch [530]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:21,862 Epoch[9] Batch [540]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:29,306 Epoch[9] Batch [550]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:37,212 Epoch[9] Batch [560]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:44,432 Epoch[9] Batch [570]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:51,835 Epoch[9] Batch [580]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:29:59,148 Epoch[9] Batch [590]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:06,540 Epoch[9] Batch [600]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:13,616 Epoch[9] Batch [610]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:20,806 Epoch[9] Batch [620]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:27,634 Epoch[9] Batch [630]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:34,321 Epoch[9] Batch [640]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:41,363 Epoch[9] Batch [650]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:48,119 Epoch[9] Batch [660]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:30:55,545 Epoch[9] Batch [670]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:03,561 Epoch[9] Batch [680]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:10,951 Epoch[9] Batch [690]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:18,613 Epoch[9] Batch [700]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:26,871 Epoch[9] Batch [710]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:34,421 Epoch[9] Batch [720]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:42,322 Epoch[9] Batch [730]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:49,968 Epoch[9] Batch [740]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:31:57,419 Epoch[9] Batch [750]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:04,788 Epoch[9] Batch [760]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:12,267 Epoch[9] Batch [770]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:19,638 Epoch[9] Batch [780]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:26,891 Epoch[9] Batch [790]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:33,661 Epoch[9] Batch [800]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:40,908 Epoch[9] Batch [810]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:47,949 Epoch[9] Batch [820]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:32:55,435 Epoch[9] Batch [830]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:02,545 Epoch[9] Batch [840]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:09,498 Epoch[9] Batch [850]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:16,745 Epoch[9] Batch [860]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:24,479 Epoch[9] Batch [870]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:31,849 Epoch[9] Batch [880]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:39,508 Epoch[9] Batch [890]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:47,093 Epoch[9] Batch [900]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:33:54,800 Epoch[9] Batch [910]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:02,400 Epoch[9] Batch [920]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:09,419 Epoch[9] Batch [930]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:16,832 Epoch[9] Batch [940]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:24,733 Epoch[9] Batch [950]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:31,789 Epoch[9] Batch [960]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:38,952 Epoch[9] Batch [970]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:46,130 Epoch[9] Batch [980]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:34:53,820 Epoch[9] Batch [990]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:00,676 Epoch[9] Batch [1000]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:07,765 Epoch[9] Batch [1010]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:14,885 Epoch[9] Batch [1020]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:21,980 Epoch[9] Batch [1030]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:29,689 Epoch[9] Batch [1040]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:37,188 Epoch[9] Batch [1050]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:44,488 Epoch[9] Batch [1060]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:51,814 Epoch[9] Batch [1070]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:35:59,148 Epoch[9] Batch [1080]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:06,591 Epoch[9] Batch [1090]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:14,388 Epoch[9] Batch [1100]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:22,054 Epoch[9] Batch [1110]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:29,915 Epoch[9] Batch [1120]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:37,864 Epoch[9] Batch [1130]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:45,039 Epoch[9] Batch [1140]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:52,532 Epoch[9] Batch [1150]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:36:59,138 Epoch[9] Batch [1160]	Speed: 6.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:06,926 Epoch[9] Batch [1170]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:13,822 Epoch[9] Batch [1180]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:20,642 Epoch[9] Batch [1190]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:27,614 Epoch[9] Batch [1200]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:34,897 Epoch[9] Batch [1210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:42,308 Epoch[9] Batch [1220]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:49,622 Epoch[9] Batch [1230]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:37:56,617 Epoch[9] Batch [1240]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:03,517 Epoch[9] Batch [1250]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:10,610 Epoch[9] Batch [1260]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:17,365 Epoch[9] Batch [1270]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:23,986 Epoch[9] Batch [1280]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:30,737 Epoch[9] Batch [1290]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:37,557 Epoch[9] Batch [1300]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:44,305 Epoch[9] Batch [1310]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:51,287 Epoch[9] Batch [1320]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:38:58,081 Epoch[9] Batch [1330]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:05,020 Epoch[9] Batch [1340]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:11,851 Epoch[9] Batch [1350]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:18,555 Epoch[9] Batch [1360]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:25,318 Epoch[9] Batch [1370]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:31,976 Epoch[9] Batch [1380]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:39,043 Epoch[9] Batch [1390]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:45,748 Epoch[9] Batch [1400]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:52,446 Epoch[9] Batch [1410]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:39:59,054 Epoch[9] Batch [1420]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:40:05,889 Epoch[9] Batch [1430]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:40:12,658 Epoch[9] Batch [1440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:40:19,517 Epoch[9] Batch [1450]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:40:26,133 Epoch[9] Batch [1460]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:40:32,927 Epoch[9] Batch [1470]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:40:39,546 Epoch[9] Batch [1480]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:40:43,528 Epoch[9] Train-FCNLogLoss=nan
2017-07-13 20:40:43,528 Epoch[9] Time cost=1061.453
2017-07-13 20:40:44,764 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.params"
2017-07-13 20:40:48,616 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.states"
2017-07-13 20:40:56,317 Epoch[10] Batch [10]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:03,158 Epoch[10] Batch [20]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:09,656 Epoch[10] Batch [30]	Speed: 6.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:16,307 Epoch[10] Batch [40]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:23,094 Epoch[10] Batch [50]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:29,792 Epoch[10] Batch [60]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:36,500 Epoch[10] Batch [70]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:43,161 Epoch[10] Batch [80]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:49,874 Epoch[10] Batch [90]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:41:56,609 Epoch[10] Batch [100]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:03,343 Epoch[10] Batch [110]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:10,033 Epoch[10] Batch [120]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:16,761 Epoch[10] Batch [130]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:23,553 Epoch[10] Batch [140]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:30,370 Epoch[10] Batch [150]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:37,700 Epoch[10] Batch [160]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:44,761 Epoch[10] Batch [170]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:51,518 Epoch[10] Batch [180]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:42:58,214 Epoch[10] Batch [190]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:04,930 Epoch[10] Batch [200]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:11,692 Epoch[10] Batch [210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:18,462 Epoch[10] Batch [220]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:25,104 Epoch[10] Batch [230]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:31,840 Epoch[10] Batch [240]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:38,589 Epoch[10] Batch [250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:45,326 Epoch[10] Batch [260]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:52,000 Epoch[10] Batch [270]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:43:58,738 Epoch[10] Batch [280]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:05,465 Epoch[10] Batch [290]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:12,189 Epoch[10] Batch [300]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:18,948 Epoch[10] Batch [310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:25,674 Epoch[10] Batch [320]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:32,436 Epoch[10] Batch [330]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:39,153 Epoch[10] Batch [340]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:45,934 Epoch[10] Batch [350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:52,637 Epoch[10] Batch [360]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:44:59,427 Epoch[10] Batch [370]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:06,117 Epoch[10] Batch [380]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:12,893 Epoch[10] Batch [390]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:19,639 Epoch[10] Batch [400]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:26,300 Epoch[10] Batch [410]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:33,099 Epoch[10] Batch [420]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:39,828 Epoch[10] Batch [430]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:46,408 Epoch[10] Batch [440]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:53,106 Epoch[10] Batch [450]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:45:59,843 Epoch[10] Batch [460]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:06,522 Epoch[10] Batch [470]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:13,225 Epoch[10] Batch [480]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:19,979 Epoch[10] Batch [490]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:26,625 Epoch[10] Batch [500]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:33,326 Epoch[10] Batch [510]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:40,010 Epoch[10] Batch [520]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:46,757 Epoch[10] Batch [530]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:46:53,528 Epoch[10] Batch [540]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:00,220 Epoch[10] Batch [550]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:06,972 Epoch[10] Batch [560]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:13,716 Epoch[10] Batch [570]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:20,496 Epoch[10] Batch [580]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:27,150 Epoch[10] Batch [590]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:33,983 Epoch[10] Batch [600]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:40,689 Epoch[10] Batch [610]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:47,506 Epoch[10] Batch [620]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:47:54,101 Epoch[10] Batch [630]	Speed: 6.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:00,809 Epoch[10] Batch [640]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:07,571 Epoch[10] Batch [650]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:14,331 Epoch[10] Batch [660]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:21,108 Epoch[10] Batch [670]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:27,762 Epoch[10] Batch [680]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:34,469 Epoch[10] Batch [690]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:41,158 Epoch[10] Batch [700]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:47,887 Epoch[10] Batch [710]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:48:54,701 Epoch[10] Batch [720]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:01,337 Epoch[10] Batch [730]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:08,116 Epoch[10] Batch [740]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:14,825 Epoch[10] Batch [750]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:21,544 Epoch[10] Batch [760]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:28,328 Epoch[10] Batch [770]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:35,000 Epoch[10] Batch [780]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:41,762 Epoch[10] Batch [790]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:48,431 Epoch[10] Batch [800]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:49:55,156 Epoch[10] Batch [810]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:01,887 Epoch[10] Batch [820]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:08,668 Epoch[10] Batch [830]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:15,320 Epoch[10] Batch [840]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:22,039 Epoch[10] Batch [850]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:28,790 Epoch[10] Batch [860]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:35,483 Epoch[10] Batch [870]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:42,162 Epoch[10] Batch [880]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:48,890 Epoch[10] Batch [890]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:50:55,578 Epoch[10] Batch [900]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:02,297 Epoch[10] Batch [910]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:09,020 Epoch[10] Batch [920]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:15,788 Epoch[10] Batch [930]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:22,664 Epoch[10] Batch [940]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:29,583 Epoch[10] Batch [950]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:36,244 Epoch[10] Batch [960]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:42,983 Epoch[10] Batch [970]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:49,672 Epoch[10] Batch [980]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:51:56,495 Epoch[10] Batch [990]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:03,182 Epoch[10] Batch [1000]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:09,933 Epoch[10] Batch [1010]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:17,211 Epoch[10] Batch [1020]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:23,790 Epoch[10] Batch [1030]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:30,571 Epoch[10] Batch [1040]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:37,203 Epoch[10] Batch [1050]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:43,943 Epoch[10] Batch [1060]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:50,734 Epoch[10] Batch [1070]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:52:57,349 Epoch[10] Batch [1080]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:04,107 Epoch[10] Batch [1090]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:10,897 Epoch[10] Batch [1100]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:17,599 Epoch[10] Batch [1110]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:24,342 Epoch[10] Batch [1120]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:31,007 Epoch[10] Batch [1130]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:37,752 Epoch[10] Batch [1140]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:44,361 Epoch[10] Batch [1150]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:51,336 Epoch[10] Batch [1160]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:53:58,616 Epoch[10] Batch [1170]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:05,473 Epoch[10] Batch [1180]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:12,602 Epoch[10] Batch [1190]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:19,529 Epoch[10] Batch [1200]	Speed: 5.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:26,484 Epoch[10] Batch [1210]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:33,733 Epoch[10] Batch [1220]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:40,505 Epoch[10] Batch [1230]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:48,058 Epoch[10] Batch [1240]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:54:54,889 Epoch[10] Batch [1250]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:02,298 Epoch[10] Batch [1260]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:09,188 Epoch[10] Batch [1270]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:16,137 Epoch[10] Batch [1280]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:23,162 Epoch[10] Batch [1290]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:30,220 Epoch[10] Batch [1300]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:37,327 Epoch[10] Batch [1310]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:44,199 Epoch[10] Batch [1320]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:51,221 Epoch[10] Batch [1330]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:55:58,085 Epoch[10] Batch [1340]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:05,075 Epoch[10] Batch [1350]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:12,229 Epoch[10] Batch [1360]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:19,419 Epoch[10] Batch [1370]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:26,554 Epoch[10] Batch [1380]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:33,461 Epoch[10] Batch [1390]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:40,547 Epoch[10] Batch [1400]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:47,589 Epoch[10] Batch [1410]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:56:54,598 Epoch[10] Batch [1420]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:57:01,980 Epoch[10] Batch [1430]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:57:09,721 Epoch[10] Batch [1440]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:57:17,094 Epoch[10] Batch [1450]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:57:24,041 Epoch[10] Batch [1460]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:57:31,017 Epoch[10] Batch [1470]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:57:38,059 Epoch[10] Batch [1480]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:57:42,381 Epoch[10] Train-FCNLogLoss=nan
2017-07-13 20:57:42,381 Epoch[10] Time cost=1013.764
2017-07-13 20:57:43,476 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.params"
2017-07-13 20:57:47,433 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.states"
2017-07-13 20:57:55,669 Epoch[11] Batch [10]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:02,593 Epoch[11] Batch [20]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:09,770 Epoch[11] Batch [30]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:16,775 Epoch[11] Batch [40]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:23,681 Epoch[11] Batch [50]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:30,908 Epoch[11] Batch [60]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:38,214 Epoch[11] Batch [70]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:45,210 Epoch[11] Batch [80]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:49,206 Epoch[11] Batch [90]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:53,437 Epoch[11] Batch [100]	Speed: 9.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:58:57,478 Epoch[11] Batch [110]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:01,503 Epoch[11] Batch [120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:05,505 Epoch[11] Batch [130]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:09,572 Epoch[11] Batch [140]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:13,601 Epoch[11] Batch [150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:17,616 Epoch[11] Batch [160]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:21,692 Epoch[11] Batch [170]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:25,683 Epoch[11] Batch [180]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:29,710 Epoch[11] Batch [190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:33,741 Epoch[11] Batch [200]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:37,765 Epoch[11] Batch [210]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:41,781 Epoch[11] Batch [220]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:45,814 Epoch[11] Batch [230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:49,859 Epoch[11] Batch [240]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:53,878 Epoch[11] Batch [250]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 20:59:57,890 Epoch[11] Batch [260]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:01,938 Epoch[11] Batch [270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:05,993 Epoch[11] Batch [280]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:10,019 Epoch[11] Batch [290]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:14,042 Epoch[11] Batch [300]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:18,091 Epoch[11] Batch [310]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:22,079 Epoch[11] Batch [320]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:26,138 Epoch[11] Batch [330]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:30,163 Epoch[11] Batch [340]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:34,169 Epoch[11] Batch [350]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:38,203 Epoch[11] Batch [360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:42,241 Epoch[11] Batch [370]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:46,285 Epoch[11] Batch [380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:50,318 Epoch[11] Batch [390]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:54,353 Epoch[11] Batch [400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:00:58,386 Epoch[11] Batch [410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:02,402 Epoch[11] Batch [420]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:06,402 Epoch[11] Batch [430]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:10,443 Epoch[11] Batch [440]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:14,485 Epoch[11] Batch [450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:18,514 Epoch[11] Batch [460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:22,550 Epoch[11] Batch [470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:26,543 Epoch[11] Batch [480]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:30,552 Epoch[11] Batch [490]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:34,570 Epoch[11] Batch [500]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:38,638 Epoch[11] Batch [510]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:42,642 Epoch[11] Batch [520]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:46,662 Epoch[11] Batch [530]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:50,697 Epoch[11] Batch [540]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:54,691 Epoch[11] Batch [550]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:01:58,742 Epoch[11] Batch [560]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:02,737 Epoch[11] Batch [570]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:06,762 Epoch[11] Batch [580]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:10,773 Epoch[11] Batch [590]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:14,836 Epoch[11] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:18,879 Epoch[11] Batch [610]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:22,875 Epoch[11] Batch [620]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:26,870 Epoch[11] Batch [630]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:30,904 Epoch[11] Batch [640]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:34,930 Epoch[11] Batch [650]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:38,975 Epoch[11] Batch [660]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:43,032 Epoch[11] Batch [670]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:47,079 Epoch[11] Batch [680]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:51,075 Epoch[11] Batch [690]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:55,082 Epoch[11] Batch [700]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:02:59,118 Epoch[11] Batch [710]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:03,164 Epoch[11] Batch [720]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:07,211 Epoch[11] Batch [730]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:11,225 Epoch[11] Batch [740]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:15,272 Epoch[11] Batch [750]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:19,289 Epoch[11] Batch [760]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:23,278 Epoch[11] Batch [770]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:27,326 Epoch[11] Batch [780]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:31,347 Epoch[11] Batch [790]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:35,372 Epoch[11] Batch [800]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:39,429 Epoch[11] Batch [810]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:43,438 Epoch[11] Batch [820]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:47,459 Epoch[11] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:51,464 Epoch[11] Batch [840]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:55,498 Epoch[11] Batch [850]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:03:59,532 Epoch[11] Batch [860]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:03,501 Epoch[11] Batch [870]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:07,486 Epoch[11] Batch [880]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:11,509 Epoch[11] Batch [890]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:15,576 Epoch[11] Batch [900]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:19,586 Epoch[11] Batch [910]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:23,590 Epoch[11] Batch [920]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:27,628 Epoch[11] Batch [930]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:31,612 Epoch[11] Batch [940]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:35,614 Epoch[11] Batch [950]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:39,682 Epoch[11] Batch [960]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:43,645 Epoch[11] Batch [970]	Speed: 10.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:47,691 Epoch[11] Batch [980]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:51,705 Epoch[11] Batch [990]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:55,729 Epoch[11] Batch [1000]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:04:59,761 Epoch[11] Batch [1010]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:03,786 Epoch[11] Batch [1020]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:07,807 Epoch[11] Batch [1030]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:11,857 Epoch[11] Batch [1040]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:15,872 Epoch[11] Batch [1050]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:19,947 Epoch[11] Batch [1060]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:23,954 Epoch[11] Batch [1070]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:27,964 Epoch[11] Batch [1080]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:31,982 Epoch[11] Batch [1090]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:36,026 Epoch[11] Batch [1100]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:40,019 Epoch[11] Batch [1110]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:44,041 Epoch[11] Batch [1120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:48,039 Epoch[11] Batch [1130]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:52,072 Epoch[11] Batch [1140]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:05:56,100 Epoch[11] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:00,108 Epoch[11] Batch [1160]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:04,120 Epoch[11] Batch [1170]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:08,099 Epoch[11] Batch [1180]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:12,145 Epoch[11] Batch [1190]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:16,150 Epoch[11] Batch [1200]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:20,187 Epoch[11] Batch [1210]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:24,208 Epoch[11] Batch [1220]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:28,214 Epoch[11] Batch [1230]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:32,274 Epoch[11] Batch [1240]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:36,277 Epoch[11] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:40,260 Epoch[11] Batch [1260]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:44,305 Epoch[11] Batch [1270]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:48,347 Epoch[11] Batch [1280]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:52,359 Epoch[11] Batch [1290]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:06:56,421 Epoch[11] Batch [1300]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:00,428 Epoch[11] Batch [1310]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:04,428 Epoch[11] Batch [1320]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:08,485 Epoch[11] Batch [1330]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:12,499 Epoch[11] Batch [1340]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:16,488 Epoch[11] Batch [1350]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:20,515 Epoch[11] Batch [1360]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:24,538 Epoch[11] Batch [1370]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:28,553 Epoch[11] Batch [1380]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:32,571 Epoch[11] Batch [1390]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:36,579 Epoch[11] Batch [1400]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:40,591 Epoch[11] Batch [1410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:44,649 Epoch[11] Batch [1420]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:48,618 Epoch[11] Batch [1430]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:52,720 Epoch[11] Batch [1440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:07:56,723 Epoch[11] Batch [1450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:00,755 Epoch[11] Batch [1460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:04,791 Epoch[11] Batch [1470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:08,863 Epoch[11] Batch [1480]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:11,245 Epoch[11] Train-FCNLogLoss=nan
2017-07-13 21:08:11,245 Epoch[11] Time cost=623.812
2017-07-13 21:08:12,105 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.params"
2017-07-13 21:08:13,728 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.states"
2017-07-13 21:08:18,408 Epoch[12] Batch [10]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:22,446 Epoch[12] Batch [20]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:26,473 Epoch[12] Batch [30]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:30,506 Epoch[12] Batch [40]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:34,538 Epoch[12] Batch [50]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:38,538 Epoch[12] Batch [60]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:42,561 Epoch[12] Batch [70]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:46,647 Epoch[12] Batch [80]	Speed: 9.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:50,633 Epoch[12] Batch [90]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:54,668 Epoch[12] Batch [100]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:08:58,719 Epoch[12] Batch [110]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:02,753 Epoch[12] Batch [120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:06,786 Epoch[12] Batch [130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:10,777 Epoch[12] Batch [140]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:14,772 Epoch[12] Batch [150]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:18,814 Epoch[12] Batch [160]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:22,811 Epoch[12] Batch [170]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:26,855 Epoch[12] Batch [180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:30,831 Epoch[12] Batch [190]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:34,877 Epoch[12] Batch [200]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:38,879 Epoch[12] Batch [210]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:42,932 Epoch[12] Batch [220]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:46,924 Epoch[12] Batch [230]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:50,957 Epoch[12] Batch [240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:55,030 Epoch[12] Batch [250]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:09:59,051 Epoch[12] Batch [260]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:03,091 Epoch[12] Batch [270]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:07,110 Epoch[12] Batch [280]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:11,193 Epoch[12] Batch [290]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:15,163 Epoch[12] Batch [300]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:19,246 Epoch[12] Batch [310]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:23,267 Epoch[12] Batch [320]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:27,311 Epoch[12] Batch [330]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:31,320 Epoch[12] Batch [340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:35,371 Epoch[12] Batch [350]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:39,377 Epoch[12] Batch [360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:43,343 Epoch[12] Batch [370]	Speed: 10.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:47,387 Epoch[12] Batch [380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:51,377 Epoch[12] Batch [390]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:55,399 Epoch[12] Batch [400]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:10:59,444 Epoch[12] Batch [410]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:03,488 Epoch[12] Batch [420]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:07,507 Epoch[12] Batch [430]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:11,519 Epoch[12] Batch [440]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:15,532 Epoch[12] Batch [450]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:19,525 Epoch[12] Batch [460]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:23,587 Epoch[12] Batch [470]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:27,594 Epoch[12] Batch [480]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:31,628 Epoch[12] Batch [490]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:35,675 Epoch[12] Batch [500]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:39,715 Epoch[12] Batch [510]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:43,708 Epoch[12] Batch [520]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:47,720 Epoch[12] Batch [530]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:51,770 Epoch[12] Batch [540]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:55,765 Epoch[12] Batch [550]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:11:59,770 Epoch[12] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:03,780 Epoch[12] Batch [570]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:07,826 Epoch[12] Batch [580]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:11,858 Epoch[12] Batch [590]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:15,891 Epoch[12] Batch [600]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:19,901 Epoch[12] Batch [610]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:23,938 Epoch[12] Batch [620]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:27,942 Epoch[12] Batch [630]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:31,987 Epoch[12] Batch [640]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:36,005 Epoch[12] Batch [650]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:40,063 Epoch[12] Batch [660]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:44,110 Epoch[12] Batch [670]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:48,079 Epoch[12] Batch [680]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:52,142 Epoch[12] Batch [690]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:12:56,152 Epoch[12] Batch [700]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:00,190 Epoch[12] Batch [710]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:04,265 Epoch[12] Batch [720]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:08,251 Epoch[12] Batch [730]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:12,224 Epoch[12] Batch [740]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:16,227 Epoch[12] Batch [750]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:20,237 Epoch[12] Batch [760]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:24,251 Epoch[12] Batch [770]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:28,277 Epoch[12] Batch [780]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:32,267 Epoch[12] Batch [790]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:36,325 Epoch[12] Batch [800]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:40,371 Epoch[12] Batch [810]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:44,365 Epoch[12] Batch [820]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:48,393 Epoch[12] Batch [830]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:52,393 Epoch[12] Batch [840]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:13:56,430 Epoch[12] Batch [850]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:00,452 Epoch[12] Batch [860]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:04,465 Epoch[12] Batch [870]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:08,467 Epoch[12] Batch [880]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:12,479 Epoch[12] Batch [890]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:16,512 Epoch[12] Batch [900]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:20,559 Epoch[12] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:24,560 Epoch[12] Batch [920]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:28,599 Epoch[12] Batch [930]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:32,672 Epoch[12] Batch [940]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:36,663 Epoch[12] Batch [950]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:40,720 Epoch[12] Batch [960]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:44,737 Epoch[12] Batch [970]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:48,779 Epoch[12] Batch [980]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:52,811 Epoch[12] Batch [990]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:14:56,797 Epoch[12] Batch [1000]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:00,868 Epoch[12] Batch [1010]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:04,901 Epoch[12] Batch [1020]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:08,903 Epoch[12] Batch [1030]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:12,904 Epoch[12] Batch [1040]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:16,922 Epoch[12] Batch [1050]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:20,949 Epoch[12] Batch [1060]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:24,972 Epoch[12] Batch [1070]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:28,989 Epoch[12] Batch [1080]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:33,004 Epoch[12] Batch [1090]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:37,011 Epoch[12] Batch [1100]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:41,037 Epoch[12] Batch [1110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:45,048 Epoch[12] Batch [1120]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:49,074 Epoch[12] Batch [1130]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:53,069 Epoch[12] Batch [1140]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:15:57,119 Epoch[12] Batch [1150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:01,142 Epoch[12] Batch [1160]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:05,157 Epoch[12] Batch [1170]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:09,148 Epoch[12] Batch [1180]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:13,161 Epoch[12] Batch [1190]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:17,181 Epoch[12] Batch [1200]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:21,205 Epoch[12] Batch [1210]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:25,209 Epoch[12] Batch [1220]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:29,271 Epoch[12] Batch [1230]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:33,278 Epoch[12] Batch [1240]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:37,346 Epoch[12] Batch [1250]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:41,380 Epoch[12] Batch [1260]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:45,391 Epoch[12] Batch [1270]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:49,382 Epoch[12] Batch [1280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:53,392 Epoch[12] Batch [1290]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:16:57,422 Epoch[12] Batch [1300]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:01,399 Epoch[12] Batch [1310]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:05,461 Epoch[12] Batch [1320]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:09,462 Epoch[12] Batch [1330]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:13,516 Epoch[12] Batch [1340]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:17,563 Epoch[12] Batch [1350]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:21,608 Epoch[12] Batch [1360]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:25,609 Epoch[12] Batch [1370]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:29,633 Epoch[12] Batch [1380]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:33,677 Epoch[12] Batch [1390]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:37,717 Epoch[12] Batch [1400]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:41,707 Epoch[12] Batch [1410]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:45,690 Epoch[12] Batch [1420]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:49,718 Epoch[12] Batch [1430]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:53,718 Epoch[12] Batch [1440]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:17:57,726 Epoch[12] Batch [1450]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:01,770 Epoch[12] Batch [1460]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:05,785 Epoch[12] Batch [1470]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:09,802 Epoch[12] Batch [1480]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:12,183 Epoch[12] Train-FCNLogLoss=nan
2017-07-13 21:18:12,183 Epoch[12] Time cost=598.455
2017-07-13 21:18:13,018 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.params"
2017-07-13 21:18:14,615 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.states"
2017-07-13 21:18:19,283 Epoch[13] Batch [10]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:23,320 Epoch[13] Batch [20]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:27,356 Epoch[13] Batch [30]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:31,347 Epoch[13] Batch [40]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:35,392 Epoch[13] Batch [50]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:39,377 Epoch[13] Batch [60]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:43,417 Epoch[13] Batch [70]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:47,464 Epoch[13] Batch [80]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:51,442 Epoch[13] Batch [90]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:55,457 Epoch[13] Batch [100]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:18:59,485 Epoch[13] Batch [110]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:03,476 Epoch[13] Batch [120]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:07,493 Epoch[13] Batch [130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:11,516 Epoch[13] Batch [140]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:15,502 Epoch[13] Batch [150]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:19,534 Epoch[13] Batch [160]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:23,514 Epoch[13] Batch [170]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:27,535 Epoch[13] Batch [180]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:31,540 Epoch[13] Batch [190]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:35,570 Epoch[13] Batch [200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:39,580 Epoch[13] Batch [210]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:43,570 Epoch[13] Batch [220]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:47,559 Epoch[13] Batch [230]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:51,586 Epoch[13] Batch [240]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:55,625 Epoch[13] Batch [250]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:19:59,636 Epoch[13] Batch [260]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:03,683 Epoch[13] Batch [270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:07,704 Epoch[13] Batch [280]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:11,781 Epoch[13] Batch [290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:15,827 Epoch[13] Batch [300]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:19,840 Epoch[13] Batch [310]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:23,872 Epoch[13] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:27,868 Epoch[13] Batch [330]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:31,914 Epoch[13] Batch [340]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:35,886 Epoch[13] Batch [350]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:39,891 Epoch[13] Batch [360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:43,939 Epoch[13] Batch [370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:47,922 Epoch[13] Batch [380]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:51,945 Epoch[13] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:55,963 Epoch[13] Batch [400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:20:59,970 Epoch[13] Batch [410]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:04,018 Epoch[13] Batch [420]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:08,036 Epoch[13] Batch [430]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:12,084 Epoch[13] Batch [440]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:16,131 Epoch[13] Batch [450]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:20,108 Epoch[13] Batch [460]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:24,152 Epoch[13] Batch [470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:28,162 Epoch[13] Batch [480]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:32,169 Epoch[13] Batch [490]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:36,176 Epoch[13] Batch [500]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:40,191 Epoch[13] Batch [510]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:44,212 Epoch[13] Batch [520]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:48,206 Epoch[13] Batch [530]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:52,220 Epoch[13] Batch [540]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:21:56,271 Epoch[13] Batch [550]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:00,238 Epoch[13] Batch [560]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:04,298 Epoch[13] Batch [570]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:08,339 Epoch[13] Batch [580]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:12,407 Epoch[13] Batch [590]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:16,458 Epoch[13] Batch [600]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:20,457 Epoch[13] Batch [610]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:24,482 Epoch[13] Batch [620]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:28,518 Epoch[13] Batch [630]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:32,541 Epoch[13] Batch [640]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:36,619 Epoch[13] Batch [650]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:40,622 Epoch[13] Batch [660]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:44,625 Epoch[13] Batch [670]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:48,665 Epoch[13] Batch [680]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:52,682 Epoch[13] Batch [690]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:22:56,702 Epoch[13] Batch [700]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:00,715 Epoch[13] Batch [710]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:04,713 Epoch[13] Batch [720]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:08,739 Epoch[13] Batch [730]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:12,783 Epoch[13] Batch [740]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:16,799 Epoch[13] Batch [750]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:20,809 Epoch[13] Batch [760]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:24,857 Epoch[13] Batch [770]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:28,888 Epoch[13] Batch [780]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:32,892 Epoch[13] Batch [790]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:36,918 Epoch[13] Batch [800]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:40,927 Epoch[13] Batch [810]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:45,000 Epoch[13] Batch [820]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:49,012 Epoch[13] Batch [830]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:53,039 Epoch[13] Batch [840]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:23:57,042 Epoch[13] Batch [850]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:01,038 Epoch[13] Batch [860]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:05,035 Epoch[13] Batch [870]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:09,103 Epoch[13] Batch [880]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:13,140 Epoch[13] Batch [890]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:17,159 Epoch[13] Batch [900]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:21,203 Epoch[13] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:25,224 Epoch[13] Batch [920]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:29,273 Epoch[13] Batch [930]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:33,325 Epoch[13] Batch [940]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:37,344 Epoch[13] Batch [950]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:41,356 Epoch[13] Batch [960]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:45,365 Epoch[13] Batch [970]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:49,373 Epoch[13] Batch [980]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:53,385 Epoch[13] Batch [990]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:24:57,386 Epoch[13] Batch [1000]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:01,395 Epoch[13] Batch [1010]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:05,422 Epoch[13] Batch [1020]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:09,423 Epoch[13] Batch [1030]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:13,460 Epoch[13] Batch [1040]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:17,507 Epoch[13] Batch [1050]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:21,538 Epoch[13] Batch [1060]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:25,557 Epoch[13] Batch [1070]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:29,628 Epoch[13] Batch [1080]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:33,687 Epoch[13] Batch [1090]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:37,595 Epoch[13] Batch [1100]	Speed: 10.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:41,724 Epoch[13] Batch [1110]	Speed: 9.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:45,815 Epoch[13] Batch [1120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:49,635 Epoch[13] Batch [1130]	Speed: 10.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:53,661 Epoch[13] Batch [1140]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:25:57,684 Epoch[13] Batch [1150]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:01,696 Epoch[13] Batch [1160]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:05,735 Epoch[13] Batch [1170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:09,741 Epoch[13] Batch [1180]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:13,798 Epoch[13] Batch [1190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:17,815 Epoch[13] Batch [1200]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:21,837 Epoch[13] Batch [1210]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:25,849 Epoch[13] Batch [1220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:29,884 Epoch[13] Batch [1230]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:33,864 Epoch[13] Batch [1240]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:37,886 Epoch[13] Batch [1250]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:41,935 Epoch[13] Batch [1260]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:45,935 Epoch[13] Batch [1270]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:50,009 Epoch[13] Batch [1280]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:54,041 Epoch[13] Batch [1290]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:26:58,088 Epoch[13] Batch [1300]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:02,074 Epoch[13] Batch [1310]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:06,092 Epoch[13] Batch [1320]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:10,135 Epoch[13] Batch [1330]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:14,164 Epoch[13] Batch [1340]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:18,167 Epoch[13] Batch [1350]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:22,130 Epoch[13] Batch [1360]	Speed: 10.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:26,154 Epoch[13] Batch [1370]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:30,217 Epoch[13] Batch [1380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:34,239 Epoch[13] Batch [1390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:38,252 Epoch[13] Batch [1400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:42,285 Epoch[13] Batch [1410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:46,261 Epoch[13] Batch [1420]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:50,273 Epoch[13] Batch [1430]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:54,339 Epoch[13] Batch [1440]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:27:58,345 Epoch[13] Batch [1450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:02,350 Epoch[13] Batch [1460]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:06,331 Epoch[13] Batch [1470]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:10,362 Epoch[13] Batch [1480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:12,726 Epoch[13] Train-FCNLogLoss=nan
2017-07-13 21:28:12,726 Epoch[13] Time cost=598.111
2017-07-13 21:28:13,547 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.params"
2017-07-13 21:28:15,268 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.states"
2017-07-13 21:28:20,116 Epoch[14] Batch [10]	Speed: 9.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:24,109 Epoch[14] Batch [20]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:28,113 Epoch[14] Batch [30]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:32,122 Epoch[14] Batch [40]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:36,223 Epoch[14] Batch [50]	Speed: 9.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:40,217 Epoch[14] Batch [60]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:44,283 Epoch[14] Batch [70]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:48,296 Epoch[14] Batch [80]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:52,366 Epoch[14] Batch [90]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:28:56,425 Epoch[14] Batch [100]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:00,448 Epoch[14] Batch [110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:04,452 Epoch[14] Batch [120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:08,466 Epoch[14] Batch [130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:12,484 Epoch[14] Batch [140]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:16,525 Epoch[14] Batch [150]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:20,486 Epoch[14] Batch [160]	Speed: 10.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:24,550 Epoch[14] Batch [170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:28,599 Epoch[14] Batch [180]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:32,648 Epoch[14] Batch [190]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:36,646 Epoch[14] Batch [200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:40,677 Epoch[14] Batch [210]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:44,722 Epoch[14] Batch [220]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:48,754 Epoch[14] Batch [230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:52,802 Epoch[14] Batch [240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:29:56,777 Epoch[14] Batch [250]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:00,830 Epoch[14] Batch [260]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:04,892 Epoch[14] Batch [270]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:08,901 Epoch[14] Batch [280]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:12,920 Epoch[14] Batch [290]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:16,913 Epoch[14] Batch [300]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:20,948 Epoch[14] Batch [310]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:24,963 Epoch[14] Batch [320]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:28,996 Epoch[14] Batch [330]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:33,054 Epoch[14] Batch [340]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:37,069 Epoch[14] Batch [350]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:41,094 Epoch[14] Batch [360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:45,070 Epoch[14] Batch [370]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:49,079 Epoch[14] Batch [380]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:53,112 Epoch[14] Batch [390]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:30:57,133 Epoch[14] Batch [400]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:01,173 Epoch[14] Batch [410]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:05,184 Epoch[14] Batch [420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:09,221 Epoch[14] Batch [430]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:13,216 Epoch[14] Batch [440]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:17,276 Epoch[14] Batch [450]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:21,305 Epoch[14] Batch [460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:25,315 Epoch[14] Batch [470]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:29,290 Epoch[14] Batch [480]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:33,349 Epoch[14] Batch [490]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:37,354 Epoch[14] Batch [500]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:41,358 Epoch[14] Batch [510]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:45,395 Epoch[14] Batch [520]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:49,401 Epoch[14] Batch [530]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:53,397 Epoch[14] Batch [540]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:31:57,382 Epoch[14] Batch [550]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:01,401 Epoch[14] Batch [560]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:05,404 Epoch[14] Batch [570]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:09,381 Epoch[14] Batch [580]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:13,388 Epoch[14] Batch [590]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:17,421 Epoch[14] Batch [600]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:21,408 Epoch[14] Batch [610]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:25,453 Epoch[14] Batch [620]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:29,486 Epoch[14] Batch [630]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:33,531 Epoch[14] Batch [640]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:37,540 Epoch[14] Batch [650]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:41,627 Epoch[14] Batch [660]	Speed: 9.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:45,630 Epoch[14] Batch [670]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:49,660 Epoch[14] Batch [680]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:53,656 Epoch[14] Batch [690]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:32:57,695 Epoch[14] Batch [700]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:01,705 Epoch[14] Batch [710]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:05,776 Epoch[14] Batch [720]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:09,796 Epoch[14] Batch [730]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:13,847 Epoch[14] Batch [740]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:17,906 Epoch[14] Batch [750]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:21,915 Epoch[14] Batch [760]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:25,970 Epoch[14] Batch [770]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:29,983 Epoch[14] Batch [780]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:33,998 Epoch[14] Batch [790]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:38,030 Epoch[14] Batch [800]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:42,059 Epoch[14] Batch [810]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:46,104 Epoch[14] Batch [820]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:50,094 Epoch[14] Batch [830]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:54,141 Epoch[14] Batch [840]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:33:58,171 Epoch[14] Batch [850]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:02,178 Epoch[14] Batch [860]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:06,220 Epoch[14] Batch [870]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:10,235 Epoch[14] Batch [880]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:14,240 Epoch[14] Batch [890]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:18,223 Epoch[14] Batch [900]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:22,262 Epoch[14] Batch [910]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:26,328 Epoch[14] Batch [920]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:30,334 Epoch[14] Batch [930]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:34,326 Epoch[14] Batch [940]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:38,400 Epoch[14] Batch [950]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:42,405 Epoch[14] Batch [960]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:46,434 Epoch[14] Batch [970]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:50,427 Epoch[14] Batch [980]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:54,444 Epoch[14] Batch [990]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:34:58,503 Epoch[14] Batch [1000]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:02,512 Epoch[14] Batch [1010]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:06,520 Epoch[14] Batch [1020]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:10,547 Epoch[14] Batch [1030]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:14,558 Epoch[14] Batch [1040]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:18,538 Epoch[14] Batch [1050]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:22,554 Epoch[14] Batch [1060]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:26,566 Epoch[14] Batch [1070]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:30,534 Epoch[14] Batch [1080]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:34,555 Epoch[14] Batch [1090]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:38,580 Epoch[14] Batch [1100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:42,662 Epoch[14] Batch [1110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:46,677 Epoch[14] Batch [1120]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:50,667 Epoch[14] Batch [1130]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:54,711 Epoch[14] Batch [1140]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:35:58,726 Epoch[14] Batch [1150]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:02,758 Epoch[14] Batch [1160]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:06,764 Epoch[14] Batch [1170]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:10,797 Epoch[14] Batch [1180]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:14,817 Epoch[14] Batch [1190]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:18,854 Epoch[14] Batch [1200]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:22,843 Epoch[14] Batch [1210]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:26,863 Epoch[14] Batch [1220]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:30,905 Epoch[14] Batch [1230]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:34,984 Epoch[14] Batch [1240]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:39,019 Epoch[14] Batch [1250]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:43,061 Epoch[14] Batch [1260]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:47,084 Epoch[14] Batch [1270]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:51,122 Epoch[14] Batch [1280]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:55,154 Epoch[14] Batch [1290]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:36:59,104 Epoch[14] Batch [1300]	Speed: 10.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:03,150 Epoch[14] Batch [1310]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:07,161 Epoch[14] Batch [1320]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:11,128 Epoch[14] Batch [1330]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:15,137 Epoch[14] Batch [1340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:19,182 Epoch[14] Batch [1350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:23,234 Epoch[14] Batch [1360]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:27,299 Epoch[14] Batch [1370]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:31,385 Epoch[14] Batch [1380]	Speed: 9.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:35,400 Epoch[14] Batch [1390]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:39,457 Epoch[14] Batch [1400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:43,480 Epoch[14] Batch [1410]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:47,509 Epoch[14] Batch [1420]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:51,568 Epoch[14] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:55,571 Epoch[14] Batch [1440]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:37:59,605 Epoch[14] Batch [1450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:03,612 Epoch[14] Batch [1460]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:07,636 Epoch[14] Batch [1470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:11,678 Epoch[14] Batch [1480]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:14,041 Epoch[14] Train-FCNLogLoss=nan
2017-07-13 21:38:14,041 Epoch[14] Time cost=598.773
2017-07-13 21:38:14,920 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.params"
2017-07-13 21:38:16,521 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.states"
2017-07-13 21:38:21,199 Epoch[15] Batch [10]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:25,231 Epoch[15] Batch [20]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:29,277 Epoch[15] Batch [30]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:33,337 Epoch[15] Batch [40]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:37,355 Epoch[15] Batch [50]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:41,399 Epoch[15] Batch [60]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:45,426 Epoch[15] Batch [70]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:49,443 Epoch[15] Batch [80]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:53,455 Epoch[15] Batch [90]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:38:57,479 Epoch[15] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:01,528 Epoch[15] Batch [110]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:05,566 Epoch[15] Batch [120]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:09,608 Epoch[15] Batch [130]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:13,617 Epoch[15] Batch [140]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:17,654 Epoch[15] Batch [150]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:21,659 Epoch[15] Batch [160]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:25,681 Epoch[15] Batch [170]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:29,725 Epoch[15] Batch [180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:33,720 Epoch[15] Batch [190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:37,767 Epoch[15] Batch [200]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:41,800 Epoch[15] Batch [210]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:45,844 Epoch[15] Batch [220]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:49,873 Epoch[15] Batch [230]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:53,875 Epoch[15] Batch [240]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:39:57,899 Epoch[15] Batch [250]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:01,969 Epoch[15] Batch [260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:05,979 Epoch[15] Batch [270]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:10,007 Epoch[15] Batch [280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:14,062 Epoch[15] Batch [290]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:18,076 Epoch[15] Batch [300]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:22,085 Epoch[15] Batch [310]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:26,095 Epoch[15] Batch [320]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:30,117 Epoch[15] Batch [330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:34,130 Epoch[15] Batch [340]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:38,162 Epoch[15] Batch [350]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:42,182 Epoch[15] Batch [360]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:46,195 Epoch[15] Batch [370]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:50,226 Epoch[15] Batch [380]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:54,284 Epoch[15] Batch [390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:40:58,367 Epoch[15] Batch [400]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:02,418 Epoch[15] Batch [410]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:06,449 Epoch[15] Batch [420]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:10,451 Epoch[15] Batch [430]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:14,473 Epoch[15] Batch [440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:18,476 Epoch[15] Batch [450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:22,494 Epoch[15] Batch [460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:26,550 Epoch[15] Batch [470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:30,527 Epoch[15] Batch [480]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:34,621 Epoch[15] Batch [490]	Speed: 9.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:38,678 Epoch[15] Batch [500]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:42,692 Epoch[15] Batch [510]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:46,724 Epoch[15] Batch [520]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:50,759 Epoch[15] Batch [530]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:54,762 Epoch[15] Batch [540]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:41:58,793 Epoch[15] Batch [550]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:02,835 Epoch[15] Batch [560]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:06,820 Epoch[15] Batch [570]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:10,836 Epoch[15] Batch [580]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:14,892 Epoch[15] Batch [590]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:18,919 Epoch[15] Batch [600]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:22,984 Epoch[15] Batch [610]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:27,019 Epoch[15] Batch [620]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:31,030 Epoch[15] Batch [630]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:35,038 Epoch[15] Batch [640]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:39,065 Epoch[15] Batch [650]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:43,077 Epoch[15] Batch [660]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:47,130 Epoch[15] Batch [670]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:51,137 Epoch[15] Batch [680]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:55,174 Epoch[15] Batch [690]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:42:59,192 Epoch[15] Batch [700]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:03,226 Epoch[15] Batch [710]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:07,247 Epoch[15] Batch [720]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:11,266 Epoch[15] Batch [730]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:15,318 Epoch[15] Batch [740]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:19,331 Epoch[15] Batch [750]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:23,391 Epoch[15] Batch [760]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:27,393 Epoch[15] Batch [770]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:31,444 Epoch[15] Batch [780]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:35,506 Epoch[15] Batch [790]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:39,570 Epoch[15] Batch [800]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:43,619 Epoch[15] Batch [810]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:47,640 Epoch[15] Batch [820]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:51,686 Epoch[15] Batch [830]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:55,701 Epoch[15] Batch [840]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:43:59,734 Epoch[15] Batch [850]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:03,769 Epoch[15] Batch [860]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:07,785 Epoch[15] Batch [870]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:11,801 Epoch[15] Batch [880]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:15,832 Epoch[15] Batch [890]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:19,862 Epoch[15] Batch [900]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:23,886 Epoch[15] Batch [910]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:27,898 Epoch[15] Batch [920]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:31,965 Epoch[15] Batch [930]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:35,982 Epoch[15] Batch [940]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:40,012 Epoch[15] Batch [950]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:44,037 Epoch[15] Batch [960]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:48,067 Epoch[15] Batch [970]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:52,073 Epoch[15] Batch [980]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:44:56,129 Epoch[15] Batch [990]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:00,160 Epoch[15] Batch [1000]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:04,150 Epoch[15] Batch [1010]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:08,188 Epoch[15] Batch [1020]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:12,177 Epoch[15] Batch [1030]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:16,202 Epoch[15] Batch [1040]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:20,223 Epoch[15] Batch [1050]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:24,221 Epoch[15] Batch [1060]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:28,276 Epoch[15] Batch [1070]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:32,294 Epoch[15] Batch [1080]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:36,307 Epoch[15] Batch [1090]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:40,370 Epoch[15] Batch [1100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:44,376 Epoch[15] Batch [1110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:48,424 Epoch[15] Batch [1120]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:52,432 Epoch[15] Batch [1130]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:45:56,474 Epoch[15] Batch [1140]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:00,497 Epoch[15] Batch [1150]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:04,525 Epoch[15] Batch [1160]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:08,512 Epoch[15] Batch [1170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:12,525 Epoch[15] Batch [1180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:16,536 Epoch[15] Batch [1190]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:20,535 Epoch[15] Batch [1200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:24,561 Epoch[15] Batch [1210]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:28,614 Epoch[15] Batch [1220]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:32,675 Epoch[15] Batch [1230]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:36,701 Epoch[15] Batch [1240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:40,713 Epoch[15] Batch [1250]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:44,743 Epoch[15] Batch [1260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:48,724 Epoch[15] Batch [1270]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:52,748 Epoch[15] Batch [1280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:46:56,736 Epoch[15] Batch [1290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:00,758 Epoch[15] Batch [1300]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:04,708 Epoch[15] Batch [1310]	Speed: 10.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:08,758 Epoch[15] Batch [1320]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:12,775 Epoch[15] Batch [1330]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:16,770 Epoch[15] Batch [1340]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:20,784 Epoch[15] Batch [1350]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:24,818 Epoch[15] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:28,855 Epoch[15] Batch [1370]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:32,898 Epoch[15] Batch [1380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:36,990 Epoch[15] Batch [1390]	Speed: 9.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:41,025 Epoch[15] Batch [1400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:45,050 Epoch[15] Batch [1410]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:49,027 Epoch[15] Batch [1420]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:53,091 Epoch[15] Batch [1430]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:47:57,146 Epoch[15] Batch [1440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:01,167 Epoch[15] Batch [1450]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:05,171 Epoch[15] Batch [1460]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:09,212 Epoch[15] Batch [1470]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:13,227 Epoch[15] Batch [1480]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:15,621 Epoch[15] Train-FCNLogLoss=nan
2017-07-13 21:48:15,622 Epoch[15] Time cost=599.100
2017-07-13 21:48:16,454 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.params"
2017-07-13 21:48:18,040 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.states"
2017-07-13 21:48:22,736 Epoch[16] Batch [10]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:26,770 Epoch[16] Batch [20]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:30,794 Epoch[16] Batch [30]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:34,832 Epoch[16] Batch [40]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:38,846 Epoch[16] Batch [50]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:42,871 Epoch[16] Batch [60]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:46,967 Epoch[16] Batch [70]	Speed: 9.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:50,944 Epoch[16] Batch [80]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:54,961 Epoch[16] Batch [90]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:48:58,993 Epoch[16] Batch [100]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:03,029 Epoch[16] Batch [110]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:07,010 Epoch[16] Batch [120]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:11,043 Epoch[16] Batch [130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:15,023 Epoch[16] Batch [140]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:19,033 Epoch[16] Batch [150]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:23,029 Epoch[16] Batch [160]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:27,035 Epoch[16] Batch [170]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:31,073 Epoch[16] Batch [180]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:35,062 Epoch[16] Batch [190]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:39,079 Epoch[16] Batch [200]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:43,109 Epoch[16] Batch [210]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:47,138 Epoch[16] Batch [220]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:51,159 Epoch[16] Batch [230]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:55,184 Epoch[16] Batch [240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:49:59,217 Epoch[16] Batch [250]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:03,239 Epoch[16] Batch [260]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:07,237 Epoch[16] Batch [270]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:11,252 Epoch[16] Batch [280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:15,313 Epoch[16] Batch [290]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:19,316 Epoch[16] Batch [300]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:23,319 Epoch[16] Batch [310]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:27,350 Epoch[16] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:31,338 Epoch[16] Batch [330]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:35,346 Epoch[16] Batch [340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:39,359 Epoch[16] Batch [350]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:43,360 Epoch[16] Batch [360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:47,389 Epoch[16] Batch [370]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:51,425 Epoch[16] Batch [380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:55,491 Epoch[16] Batch [390]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:50:59,516 Epoch[16] Batch [400]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:03,507 Epoch[16] Batch [410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:07,531 Epoch[16] Batch [420]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:11,602 Epoch[16] Batch [430]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:15,619 Epoch[16] Batch [440]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:19,624 Epoch[16] Batch [450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:23,650 Epoch[16] Batch [460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:27,648 Epoch[16] Batch [470]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:31,633 Epoch[16] Batch [480]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:35,659 Epoch[16] Batch [490]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:39,706 Epoch[16] Batch [500]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:43,756 Epoch[16] Batch [510]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:47,754 Epoch[16] Batch [520]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:51,769 Epoch[16] Batch [530]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:55,812 Epoch[16] Batch [540]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:51:59,886 Epoch[16] Batch [550]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:03,864 Epoch[16] Batch [560]	Speed: 10.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:07,940 Epoch[16] Batch [570]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:11,909 Epoch[16] Batch [580]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:15,937 Epoch[16] Batch [590]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:19,933 Epoch[16] Batch [600]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:23,957 Epoch[16] Batch [610]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:27,987 Epoch[16] Batch [620]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:32,034 Epoch[16] Batch [630]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:36,063 Epoch[16] Batch [640]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:40,094 Epoch[16] Batch [650]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:44,111 Epoch[16] Batch [660]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:48,144 Epoch[16] Batch [670]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:52,189 Epoch[16] Batch [680]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:52:56,204 Epoch[16] Batch [690]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:00,282 Epoch[16] Batch [700]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:04,321 Epoch[16] Batch [710]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:08,322 Epoch[16] Batch [720]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:12,366 Epoch[16] Batch [730]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:16,337 Epoch[16] Batch [740]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:20,370 Epoch[16] Batch [750]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:24,373 Epoch[16] Batch [760]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:28,432 Epoch[16] Batch [770]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:32,441 Epoch[16] Batch [780]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:36,484 Epoch[16] Batch [790]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:40,510 Epoch[16] Batch [800]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:44,534 Epoch[16] Batch [810]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:48,536 Epoch[16] Batch [820]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:52,511 Epoch[16] Batch [830]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:53:56,581 Epoch[16] Batch [840]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:00,609 Epoch[16] Batch [850]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:04,601 Epoch[16] Batch [860]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:08,619 Epoch[16] Batch [870]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:12,645 Epoch[16] Batch [880]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:16,646 Epoch[16] Batch [890]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:20,642 Epoch[16] Batch [900]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:24,688 Epoch[16] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:28,753 Epoch[16] Batch [920]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:32,778 Epoch[16] Batch [930]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:36,828 Epoch[16] Batch [940]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:40,807 Epoch[16] Batch [950]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:44,857 Epoch[16] Batch [960]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:48,919 Epoch[16] Batch [970]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:52,939 Epoch[16] Batch [980]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:54:56,940 Epoch[16] Batch [990]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:00,996 Epoch[16] Batch [1000]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:05,057 Epoch[16] Batch [1010]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:09,102 Epoch[16] Batch [1020]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:13,110 Epoch[16] Batch [1030]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:17,143 Epoch[16] Batch [1040]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:21,232 Epoch[16] Batch [1050]	Speed: 9.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:25,230 Epoch[16] Batch [1060]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:29,223 Epoch[16] Batch [1070]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:33,291 Epoch[16] Batch [1080]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:37,318 Epoch[16] Batch [1090]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:41,360 Epoch[16] Batch [1100]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:45,409 Epoch[16] Batch [1110]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:49,425 Epoch[16] Batch [1120]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:53,440 Epoch[16] Batch [1130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:55:57,497 Epoch[16] Batch [1140]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:01,529 Epoch[16] Batch [1150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:05,630 Epoch[16] Batch [1160]	Speed: 9.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:09,636 Epoch[16] Batch [1170]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:13,676 Epoch[16] Batch [1180]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:17,734 Epoch[16] Batch [1190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:21,756 Epoch[16] Batch [1200]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:25,780 Epoch[16] Batch [1210]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:29,799 Epoch[16] Batch [1220]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:33,851 Epoch[16] Batch [1230]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:37,851 Epoch[16] Batch [1240]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:41,869 Epoch[16] Batch [1250]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:45,938 Epoch[16] Batch [1260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:49,952 Epoch[16] Batch [1270]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:53,969 Epoch[16] Batch [1280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:56:57,996 Epoch[16] Batch [1290]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:01,990 Epoch[16] Batch [1300]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:06,037 Epoch[16] Batch [1310]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:10,043 Epoch[16] Batch [1320]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:14,060 Epoch[16] Batch [1330]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:18,073 Epoch[16] Batch [1340]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:22,100 Epoch[16] Batch [1350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:26,128 Epoch[16] Batch [1360]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:30,169 Epoch[16] Batch [1370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:34,209 Epoch[16] Batch [1380]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:38,263 Epoch[16] Batch [1390]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:42,260 Epoch[16] Batch [1400]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:46,253 Epoch[16] Batch [1410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:50,312 Epoch[16] Batch [1420]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:54,363 Epoch[16] Batch [1430]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:57:58,351 Epoch[16] Batch [1440]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:02,435 Epoch[16] Batch [1450]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:06,456 Epoch[16] Batch [1460]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:10,500 Epoch[16] Batch [1470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:14,529 Epoch[16] Batch [1480]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:16,928 Epoch[16] Train-FCNLogLoss=nan
2017-07-13 21:58:16,928 Epoch[16] Time cost=598.888
2017-07-13 21:58:17,838 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.params"
2017-07-13 21:58:19,478 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.states"
2017-07-13 21:58:24,182 Epoch[17] Batch [10]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:28,185 Epoch[17] Batch [20]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:32,190 Epoch[17] Batch [30]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:36,196 Epoch[17] Batch [40]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:40,230 Epoch[17] Batch [50]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:44,254 Epoch[17] Batch [60]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:48,288 Epoch[17] Batch [70]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:52,321 Epoch[17] Batch [80]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:58:56,353 Epoch[17] Batch [90]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:00,379 Epoch[17] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:04,400 Epoch[17] Batch [110]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:08,403 Epoch[17] Batch [120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:12,489 Epoch[17] Batch [130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:16,538 Epoch[17] Batch [140]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:20,551 Epoch[17] Batch [150]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:24,578 Epoch[17] Batch [160]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:28,565 Epoch[17] Batch [170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:32,612 Epoch[17] Batch [180]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:36,614 Epoch[17] Batch [190]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:40,658 Epoch[17] Batch [200]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:44,721 Epoch[17] Batch [210]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:48,683 Epoch[17] Batch [220]	Speed: 10.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:52,756 Epoch[17] Batch [230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 21:59:56,776 Epoch[17] Batch [240]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:00,820 Epoch[17] Batch [250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:04,838 Epoch[17] Batch [260]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:08,877 Epoch[17] Batch [270]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:12,936 Epoch[17] Batch [280]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:16,979 Epoch[17] Batch [290]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:20,978 Epoch[17] Batch [300]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:25,012 Epoch[17] Batch [310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:29,012 Epoch[17] Batch [320]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:33,089 Epoch[17] Batch [330]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:37,061 Epoch[17] Batch [340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:41,097 Epoch[17] Batch [350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:45,107 Epoch[17] Batch [360]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:49,176 Epoch[17] Batch [370]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:53,179 Epoch[17] Batch [380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:00:57,197 Epoch[17] Batch [390]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:01,138 Epoch[17] Batch [400]	Speed: 10.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:05,118 Epoch[17] Batch [410]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:09,269 Epoch[17] Batch [420]	Speed: 9.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:13,163 Epoch[17] Batch [430]	Speed: 10.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:17,163 Epoch[17] Batch [440]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:21,204 Epoch[17] Batch [450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:25,260 Epoch[17] Batch [460]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:29,285 Epoch[17] Batch [470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:33,278 Epoch[17] Batch [480]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:37,347 Epoch[17] Batch [490]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:41,370 Epoch[17] Batch [500]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:45,343 Epoch[17] Batch [510]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:49,371 Epoch[17] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:53,435 Epoch[17] Batch [530]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:01:57,482 Epoch[17] Batch [540]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:01,523 Epoch[17] Batch [550]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:05,540 Epoch[17] Batch [560]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:09,544 Epoch[17] Batch [570]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:13,546 Epoch[17] Batch [580]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:17,588 Epoch[17] Batch [590]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:21,633 Epoch[17] Batch [600]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:25,677 Epoch[17] Batch [610]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:29,671 Epoch[17] Batch [620]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:33,707 Epoch[17] Batch [630]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:37,774 Epoch[17] Batch [640]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:41,819 Epoch[17] Batch [650]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:45,855 Epoch[17] Batch [660]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:49,903 Epoch[17] Batch [670]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:53,903 Epoch[17] Batch [680]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:02:57,946 Epoch[17] Batch [690]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:01,950 Epoch[17] Batch [700]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:05,947 Epoch[17] Batch [710]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:09,978 Epoch[17] Batch [720]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:14,011 Epoch[17] Batch [730]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:18,037 Epoch[17] Batch [740]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:22,065 Epoch[17] Batch [750]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:26,072 Epoch[17] Batch [760]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:30,096 Epoch[17] Batch [770]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:34,119 Epoch[17] Batch [780]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:38,174 Epoch[17] Batch [790]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:42,223 Epoch[17] Batch [800]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:46,262 Epoch[17] Batch [810]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:50,307 Epoch[17] Batch [820]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:03:54,375 Epoch[17] Batch [830]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:00,175 Epoch[17] Batch [840]	Speed: 6.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:08,215 Epoch[17] Batch [850]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:15,802 Epoch[17] Batch [860]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:23,952 Epoch[17] Batch [870]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:32,453 Epoch[17] Batch [880]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:40,399 Epoch[17] Batch [890]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:48,417 Epoch[17] Batch [900]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:04:56,399 Epoch[17] Batch [910]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:03,580 Epoch[17] Batch [920]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:11,138 Epoch[17] Batch [930]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:18,875 Epoch[17] Batch [940]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:26,784 Epoch[17] Batch [950]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:34,796 Epoch[17] Batch [960]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:42,646 Epoch[17] Batch [970]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:50,235 Epoch[17] Batch [980]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:05:58,190 Epoch[17] Batch [990]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:05,770 Epoch[17] Batch [1000]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:13,478 Epoch[17] Batch [1010]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:20,952 Epoch[17] Batch [1020]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:28,088 Epoch[17] Batch [1030]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:35,847 Epoch[17] Batch [1040]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:43,370 Epoch[17] Batch [1050]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:50,870 Epoch[17] Batch [1060]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:06:58,735 Epoch[17] Batch [1070]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:06,425 Epoch[17] Batch [1080]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:13,988 Epoch[17] Batch [1090]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:22,178 Epoch[17] Batch [1100]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:29,886 Epoch[17] Batch [1110]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:37,286 Epoch[17] Batch [1120]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:44,612 Epoch[17] Batch [1130]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:52,053 Epoch[17] Batch [1140]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:07:59,438 Epoch[17] Batch [1150]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:06,477 Epoch[17] Batch [1160]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:13,247 Epoch[17] Batch [1170]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:19,901 Epoch[17] Batch [1180]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:26,207 Epoch[17] Batch [1190]	Speed: 6.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:31,844 Epoch[17] Batch [1200]	Speed: 7.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:37,390 Epoch[17] Batch [1210]	Speed: 7.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:42,311 Epoch[17] Batch [1220]	Speed: 8.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:47,150 Epoch[17] Batch [1230]	Speed: 8.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:51,987 Epoch[17] Batch [1240]	Speed: 8.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:08:56,479 Epoch[17] Batch [1250]	Speed: 8.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:00,972 Epoch[17] Batch [1260]	Speed: 8.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:05,440 Epoch[17] Batch [1270]	Speed: 8.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:09,751 Epoch[17] Batch [1280]	Speed: 9.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:14,123 Epoch[17] Batch [1290]	Speed: 9.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:18,291 Epoch[17] Batch [1300]	Speed: 9.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:22,531 Epoch[17] Batch [1310]	Speed: 9.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:26,741 Epoch[17] Batch [1320]	Speed: 9.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:30,977 Epoch[17] Batch [1330]	Speed: 9.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:35,106 Epoch[17] Batch [1340]	Speed: 9.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:39,389 Epoch[17] Batch [1350]	Speed: 9.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:43,536 Epoch[17] Batch [1360]	Speed: 9.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:47,587 Epoch[17] Batch [1370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:51,590 Epoch[17] Batch [1380]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:55,641 Epoch[17] Batch [1390]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:09:59,634 Epoch[17] Batch [1400]	Speed: 10.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:03,668 Epoch[17] Batch [1410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:07,788 Epoch[17] Batch [1420]	Speed: 9.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:11,849 Epoch[17] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:15,933 Epoch[17] Batch [1440]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:20,021 Epoch[17] Batch [1450]	Speed: 9.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:24,101 Epoch[17] Batch [1460]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:28,229 Epoch[17] Batch [1470]	Speed: 9.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:32,248 Epoch[17] Batch [1480]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:34,664 Epoch[17] Train-FCNLogLoss=nan
2017-07-13 22:10:34,665 Epoch[17] Time cost=735.187
2017-07-13 22:10:35,512 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.params"
2017-07-13 22:10:37,220 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.states"
2017-07-13 22:10:41,952 Epoch[18] Batch [10]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:46,043 Epoch[18] Batch [20]	Speed: 9.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:50,092 Epoch[18] Batch [30]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:54,143 Epoch[18] Batch [40]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:10:58,145 Epoch[18] Batch [50]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:02,158 Epoch[18] Batch [60]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:06,162 Epoch[18] Batch [70]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:10,279 Epoch[18] Batch [80]	Speed: 9.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:14,361 Epoch[18] Batch [90]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:18,391 Epoch[18] Batch [100]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:22,400 Epoch[18] Batch [110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:26,468 Epoch[18] Batch [120]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:30,495 Epoch[18] Batch [130]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:34,516 Epoch[18] Batch [140]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:38,529 Epoch[18] Batch [150]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:42,599 Epoch[18] Batch [160]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:46,649 Epoch[18] Batch [170]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:50,627 Epoch[18] Batch [180]	Speed: 10.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:54,627 Epoch[18] Batch [190]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:11:58,629 Epoch[18] Batch [200]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:02,651 Epoch[18] Batch [210]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:06,663 Epoch[18] Batch [220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:10,650 Epoch[18] Batch [230]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:14,621 Epoch[18] Batch [240]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:18,636 Epoch[18] Batch [250]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:22,705 Epoch[18] Batch [260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:26,714 Epoch[18] Batch [270]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:30,753 Epoch[18] Batch [280]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:34,790 Epoch[18] Batch [290]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:38,850 Epoch[18] Batch [300]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:42,848 Epoch[18] Batch [310]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:46,882 Epoch[18] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:50,898 Epoch[18] Batch [330]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:54,961 Epoch[18] Batch [340]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:12:58,994 Epoch[18] Batch [350]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:02,996 Epoch[18] Batch [360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:07,042 Epoch[18] Batch [370]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:11,100 Epoch[18] Batch [380]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:15,109 Epoch[18] Batch [390]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:19,148 Epoch[18] Batch [400]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:23,169 Epoch[18] Batch [410]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:27,166 Epoch[18] Batch [420]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:31,216 Epoch[18] Batch [430]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:35,242 Epoch[18] Batch [440]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:39,297 Epoch[18] Batch [450]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:43,301 Epoch[18] Batch [460]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:47,301 Epoch[18] Batch [470]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:51,375 Epoch[18] Batch [480]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:55,403 Epoch[18] Batch [490]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:13:59,474 Epoch[18] Batch [500]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:03,507 Epoch[18] Batch [510]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:07,547 Epoch[18] Batch [520]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:11,564 Epoch[18] Batch [530]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:15,580 Epoch[18] Batch [540]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:19,608 Epoch[18] Batch [550]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:23,634 Epoch[18] Batch [560]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:27,706 Epoch[18] Batch [570]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:31,759 Epoch[18] Batch [580]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:35,806 Epoch[18] Batch [590]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:39,869 Epoch[18] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:43,882 Epoch[18] Batch [610]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:47,961 Epoch[18] Batch [620]	Speed: 9.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:51,982 Epoch[18] Batch [630]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:14:56,017 Epoch[18] Batch [640]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:00,056 Epoch[18] Batch [650]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:04,119 Epoch[18] Batch [660]	Speed: 9.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:08,150 Epoch[18] Batch [670]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:12,201 Epoch[18] Batch [680]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:16,295 Epoch[18] Batch [690]	Speed: 9.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:20,316 Epoch[18] Batch [700]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:24,346 Epoch[18] Batch [710]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:28,339 Epoch[18] Batch [720]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:32,372 Epoch[18] Batch [730]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:36,446 Epoch[18] Batch [740]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:40,460 Epoch[18] Batch [750]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:44,483 Epoch[18] Batch [760]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:48,522 Epoch[18] Batch [770]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:52,551 Epoch[18] Batch [780]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:15:56,562 Epoch[18] Batch [790]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:00,550 Epoch[18] Batch [800]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:04,580 Epoch[18] Batch [810]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:08,589 Epoch[18] Batch [820]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:12,624 Epoch[18] Batch [830]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:16,692 Epoch[18] Batch [840]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:20,733 Epoch[18] Batch [850]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:24,760 Epoch[18] Batch [860]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:28,806 Epoch[18] Batch [870]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:32,843 Epoch[18] Batch [880]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:36,874 Epoch[18] Batch [890]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:40,876 Epoch[18] Batch [900]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:44,947 Epoch[18] Batch [910]	Speed: 9.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:48,983 Epoch[18] Batch [920]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:52,955 Epoch[18] Batch [930]	Speed: 10.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:16:57,001 Epoch[18] Batch [940]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:01,054 Epoch[18] Batch [950]	Speed: 9.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:05,080 Epoch[18] Batch [960]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:09,114 Epoch[18] Batch [970]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:13,127 Epoch[18] Batch [980]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:17,131 Epoch[18] Batch [990]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:21,150 Epoch[18] Batch [1000]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:25,216 Epoch[18] Batch [1010]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:29,264 Epoch[18] Batch [1020]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:33,265 Epoch[18] Batch [1030]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:37,316 Epoch[18] Batch [1040]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:41,344 Epoch[18] Batch [1050]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:45,331 Epoch[18] Batch [1060]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:49,377 Epoch[18] Batch [1070]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:53,383 Epoch[18] Batch [1080]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:17:57,401 Epoch[18] Batch [1090]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:01,390 Epoch[18] Batch [1100]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:05,422 Epoch[18] Batch [1110]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:09,455 Epoch[18] Batch [1120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:13,467 Epoch[18] Batch [1130]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:17,534 Epoch[18] Batch [1140]	Speed: 9.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:21,547 Epoch[18] Batch [1150]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:25,550 Epoch[18] Batch [1160]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:29,539 Epoch[18] Batch [1170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:33,588 Epoch[18] Batch [1180]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:37,630 Epoch[18] Batch [1190]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:41,625 Epoch[18] Batch [1200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:45,639 Epoch[18] Batch [1210]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:49,646 Epoch[18] Batch [1220]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:53,642 Epoch[18] Batch [1230]	Speed: 10.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:18:57,667 Epoch[18] Batch [1240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:01,673 Epoch[18] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:05,695 Epoch[18] Batch [1260]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:09,742 Epoch[18] Batch [1270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:13,767 Epoch[18] Batch [1280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:17,803 Epoch[18] Batch [1290]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:21,816 Epoch[18] Batch [1300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:25,829 Epoch[18] Batch [1310]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:29,860 Epoch[18] Batch [1320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:33,865 Epoch[18] Batch [1330]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:37,902 Epoch[18] Batch [1340]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:41,916 Epoch[18] Batch [1350]	Speed: 9.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:45,950 Epoch[18] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:49,971 Epoch[18] Batch [1370]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:53,976 Epoch[18] Batch [1380]	Speed: 9.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:19:57,995 Epoch[18] Batch [1390]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:02,035 Epoch[18] Batch [1400]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:06,063 Epoch[18] Batch [1410]	Speed: 9.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:10,079 Epoch[18] Batch [1420]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:14,073 Epoch[18] Batch [1430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:18,074 Epoch[18] Batch [1440]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:22,080 Epoch[18] Batch [1450]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:26,137 Epoch[18] Batch [1460]	Speed: 9.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:30,137 Epoch[18] Batch [1470]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:34,156 Epoch[18] Batch [1480]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:36,524 Epoch[18] Train-FCNLogLoss=nan
2017-07-13 22:20:36,524 Epoch[18] Time cost=599.304
2017-07-13 22:20:37,334 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.params"
2017-07-13 22:20:38,944 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.states"
2017-07-13 22:20:43,642 Epoch[19] Batch [10]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:47,664 Epoch[19] Batch [20]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:51,675 Epoch[19] Batch [30]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:55,691 Epoch[19] Batch [40]	Speed: 9.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:20:59,699 Epoch[19] Batch [50]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:03,687 Epoch[19] Batch [60]	Speed: 10.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:07,708 Epoch[19] Batch [70]	Speed: 9.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:11,745 Epoch[19] Batch [80]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:15,770 Epoch[19] Batch [90]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:19,769 Epoch[19] Batch [100]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:23,804 Epoch[19] Batch [110]	Speed: 9.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:27,837 Epoch[19] Batch [120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:31,845 Epoch[19] Batch [130]	Speed: 9.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:35,814 Epoch[19] Batch [140]	Speed: 10.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:39,888 Epoch[19] Batch [150]	Speed: 9.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:43,929 Epoch[19] Batch [160]	Speed: 9.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:47,929 Epoch[19] Batch [170]	Speed: 10.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:52,053 Epoch[19] Batch [180]	Speed: 9.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:21:56,101 Epoch[19] Batch [190]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:00,146 Epoch[19] Batch [200]	Speed: 9.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:04,273 Epoch[19] Batch [210]	Speed: 9.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:08,296 Epoch[19] Batch [220]	Speed: 9.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:12,379 Epoch[19] Batch [230]	Speed: 9.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:16,427 Epoch[19] Batch [240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:20,653 Epoch[19] Batch [250]	Speed: 9.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:25,007 Epoch[19] Batch [260]	Speed: 9.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:29,467 Epoch[19] Batch [270]	Speed: 8.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:33,615 Epoch[19] Batch [280]	Speed: 9.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:38,176 Epoch[19] Batch [290]	Speed: 8.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:43,081 Epoch[19] Batch [300]	Speed: 8.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:48,882 Epoch[19] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:22:54,478 Epoch[19] Batch [320]	Speed: 7.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:00,097 Epoch[19] Batch [330]	Speed: 7.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:06,750 Epoch[19] Batch [340]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:13,641 Epoch[19] Batch [350]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:21,486 Epoch[19] Batch [360]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:29,160 Epoch[19] Batch [370]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:36,698 Epoch[19] Batch [380]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:43,835 Epoch[19] Batch [390]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:51,209 Epoch[19] Batch [400]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:23:58,474 Epoch[19] Batch [410]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:05,999 Epoch[19] Batch [420]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:13,536 Epoch[19] Batch [430]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:20,920 Epoch[19] Batch [440]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:28,183 Epoch[19] Batch [450]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:35,264 Epoch[19] Batch [460]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:42,589 Epoch[19] Batch [470]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:50,727 Epoch[19] Batch [480]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:24:58,728 Epoch[19] Batch [490]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:06,997 Epoch[19] Batch [500]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:14,770 Epoch[19] Batch [510]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:22,255 Epoch[19] Batch [520]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:29,660 Epoch[19] Batch [530]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:36,941 Epoch[19] Batch [540]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:44,541 Epoch[19] Batch [550]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:51,937 Epoch[19] Batch [560]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:25:59,278 Epoch[19] Batch [570]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:06,465 Epoch[19] Batch [580]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:13,857 Epoch[19] Batch [590]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:21,011 Epoch[19] Batch [600]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:28,431 Epoch[19] Batch [610]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:35,894 Epoch[19] Batch [620]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:43,291 Epoch[19] Batch [630]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:50,484 Epoch[19] Batch [640]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:26:58,033 Epoch[19] Batch [650]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:05,579 Epoch[19] Batch [660]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:13,032 Epoch[19] Batch [670]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:20,594 Epoch[19] Batch [680]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:27,889 Epoch[19] Batch [690]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:35,423 Epoch[19] Batch [700]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:42,872 Epoch[19] Batch [710]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:50,429 Epoch[19] Batch [720]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:27:57,927 Epoch[19] Batch [730]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:05,550 Epoch[19] Batch [740]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:12,989 Epoch[19] Batch [750]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:20,557 Epoch[19] Batch [760]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:28,368 Epoch[19] Batch [770]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:35,890 Epoch[19] Batch [780]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:43,185 Epoch[19] Batch [790]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:50,719 Epoch[19] Batch [800]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:28:58,216 Epoch[19] Batch [810]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:29:05,587 Epoch[19] Batch [820]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:29:13,048 Epoch[19] Batch [830]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:29:20,322 Epoch[19] Batch [840]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:29:28,327 Epoch[19] Batch [850]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:29:36,354 Epoch[19] Batch [860]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:29:44,596 Epoch[19] Batch [870]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:29:52,849 Epoch[19] Batch [880]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:01,040 Epoch[19] Batch [890]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:09,378 Epoch[19] Batch [900]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:17,515 Epoch[19] Batch [910]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:25,701 Epoch[19] Batch [920]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:33,757 Epoch[19] Batch [930]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:41,819 Epoch[19] Batch [940]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:49,460 Epoch[19] Batch [950]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:30:57,401 Epoch[19] Batch [960]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:31:05,458 Epoch[19] Batch [970]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:31:13,906 Epoch[19] Batch [980]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:31:21,797 Epoch[19] Batch [990]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:31:29,219 Epoch[19] Batch [1000]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:31:36,565 Epoch[19] Batch [1010]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:31:44,024 Epoch[19] Batch [1020]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:31:51,353 Epoch[19] Batch [1030]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:32:00,091 Epoch[19] Batch [1040]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:32:08,693 Epoch[19] Batch [1050]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:32:17,748 Epoch[19] Batch [1060]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:32:26,620 Epoch[19] Batch [1070]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:32:35,243 Epoch[19] Batch [1080]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:32:44,165 Epoch[19] Batch [1090]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:32:52,890 Epoch[19] Batch [1100]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:33:01,757 Epoch[19] Batch [1110]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:33:10,776 Epoch[19] Batch [1120]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:33:19,694 Epoch[19] Batch [1130]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:33:28,375 Epoch[19] Batch [1140]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:33:37,077 Epoch[19] Batch [1150]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:33:45,825 Epoch[19] Batch [1160]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:33:54,669 Epoch[19] Batch [1170]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:02,574 Epoch[19] Batch [1180]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:10,244 Epoch[19] Batch [1190]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:17,853 Epoch[19] Batch [1200]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:25,462 Epoch[19] Batch [1210]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:33,306 Epoch[19] Batch [1220]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:41,759 Epoch[19] Batch [1230]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:49,825 Epoch[19] Batch [1240]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:34:58,065 Epoch[19] Batch [1250]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:35:06,288 Epoch[19] Batch [1260]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:35:14,511 Epoch[19] Batch [1270]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:35:22,530 Epoch[19] Batch [1280]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:35:30,623 Epoch[19] Batch [1290]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:35:38,695 Epoch[19] Batch [1300]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:35:46,983 Epoch[19] Batch [1310]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:35:55,525 Epoch[19] Batch [1320]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:36:03,712 Epoch[19] Batch [1330]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:36:12,016 Epoch[19] Batch [1340]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:36:19,996 Epoch[19] Batch [1350]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:36:28,261 Epoch[19] Batch [1360]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:36:36,370 Epoch[19] Batch [1370]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:36:44,645 Epoch[19] Batch [1380]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:36:52,911 Epoch[19] Batch [1390]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:37:00,842 Epoch[19] Batch [1400]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:37:09,847 Epoch[19] Batch [1410]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:37:18,664 Epoch[19] Batch [1420]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:37:27,002 Epoch[19] Batch [1430]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:37:35,448 Epoch[19] Batch [1440]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:37:43,670 Epoch[19] Batch [1450]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:37:51,873 Epoch[19] Batch [1460]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:38:00,086 Epoch[19] Batch [1470]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:38:08,199 Epoch[19] Batch [1480]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:38:13,024 Epoch[19] Train-FCNLogLoss=nan
2017-07-13 22:38:13,024 Epoch[19] Time cost=1054.079
2017-07-13 22:38:14,140 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.params"
2017-07-13 22:38:18,012 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.states"
2017-07-13 22:38:27,300 Epoch[20] Batch [10]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:38:35,211 Epoch[20] Batch [20]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:38:43,211 Epoch[20] Batch [30]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:38:51,370 Epoch[20] Batch [40]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:38:59,561 Epoch[20] Batch [50]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:39:07,366 Epoch[20] Batch [60]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:39:15,257 Epoch[20] Batch [70]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:39:23,324 Epoch[20] Batch [80]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:39:31,564 Epoch[20] Batch [90]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:39:39,452 Epoch[20] Batch [100]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:39:47,481 Epoch[20] Batch [110]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:39:55,882 Epoch[20] Batch [120]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:40:03,784 Epoch[20] Batch [130]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:40:11,971 Epoch[20] Batch [140]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:40:19,810 Epoch[20] Batch [150]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:40:27,984 Epoch[20] Batch [160]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:40:36,194 Epoch[20] Batch [170]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:40:44,265 Epoch[20] Batch [180]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:40:52,280 Epoch[20] Batch [190]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:00,908 Epoch[20] Batch [200]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:09,458 Epoch[20] Batch [210]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:18,004 Epoch[20] Batch [220]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:26,443 Epoch[20] Batch [230]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:35,099 Epoch[20] Batch [240]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:43,474 Epoch[20] Batch [250]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:51,703 Epoch[20] Batch [260]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:41:59,744 Epoch[20] Batch [270]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:42:07,630 Epoch[20] Batch [280]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:42:16,014 Epoch[20] Batch [290]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:42:23,788 Epoch[20] Batch [300]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:42:31,847 Epoch[20] Batch [310]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:42:39,954 Epoch[20] Batch [320]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:42:48,203 Epoch[20] Batch [330]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:42:56,487 Epoch[20] Batch [340]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:43:04,760 Epoch[20] Batch [350]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:43:12,917 Epoch[20] Batch [360]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:43:21,032 Epoch[20] Batch [370]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:43:29,095 Epoch[20] Batch [380]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:43:37,426 Epoch[20] Batch [390]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:43:45,591 Epoch[20] Batch [400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:43:53,643 Epoch[20] Batch [410]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:44:01,772 Epoch[20] Batch [420]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:44:10,002 Epoch[20] Batch [430]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:44:18,825 Epoch[20] Batch [440]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:44:27,494 Epoch[20] Batch [450]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:44:36,070 Epoch[20] Batch [460]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:44:44,553 Epoch[20] Batch [470]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:44:52,759 Epoch[20] Batch [480]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:45:01,295 Epoch[20] Batch [490]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:45:10,411 Epoch[20] Batch [500]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:45:19,404 Epoch[20] Batch [510]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:45:28,042 Epoch[20] Batch [520]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:45:36,443 Epoch[20] Batch [530]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:45:45,319 Epoch[20] Batch [540]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:45:53,751 Epoch[20] Batch [550]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:46:02,144 Epoch[20] Batch [560]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:46:10,394 Epoch[20] Batch [570]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:46:19,540 Epoch[20] Batch [580]	Speed: 4.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:46:28,142 Epoch[20] Batch [590]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:46:36,599 Epoch[20] Batch [600]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:46:44,820 Epoch[20] Batch [610]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:46:53,401 Epoch[20] Batch [620]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:47:02,186 Epoch[20] Batch [630]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:47:10,950 Epoch[20] Batch [640]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:47:19,711 Epoch[20] Batch [650]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:47:28,212 Epoch[20] Batch [660]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:47:36,606 Epoch[20] Batch [670]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:47:45,203 Epoch[20] Batch [680]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:47:53,429 Epoch[20] Batch [690]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:48:02,235 Epoch[20] Batch [700]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:48:10,870 Epoch[20] Batch [710]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:48:19,658 Epoch[20] Batch [720]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:48:27,959 Epoch[20] Batch [730]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:48:36,986 Epoch[20] Batch [740]	Speed: 4.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:48:45,596 Epoch[20] Batch [750]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:48:54,001 Epoch[20] Batch [760]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:49:02,500 Epoch[20] Batch [770]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:49:11,302 Epoch[20] Batch [780]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:49:20,167 Epoch[20] Batch [790]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:49:28,811 Epoch[20] Batch [800]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:49:37,470 Epoch[20] Batch [810]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:49:46,293 Epoch[20] Batch [820]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:49:54,963 Epoch[20] Batch [830]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:50:04,423 Epoch[20] Batch [840]	Speed: 4.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:50:12,592 Epoch[20] Batch [850]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:50:20,939 Epoch[20] Batch [860]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:50:29,610 Epoch[20] Batch [870]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:50:38,356 Epoch[20] Batch [880]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:50:47,026 Epoch[20] Batch [890]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:50:55,612 Epoch[20] Batch [900]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:51:04,077 Epoch[20] Batch [910]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:51:12,751 Epoch[20] Batch [920]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:51:21,493 Epoch[20] Batch [930]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:51:30,188 Epoch[20] Batch [940]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:51:38,581 Epoch[20] Batch [950]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:51:47,598 Epoch[20] Batch [960]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:51:56,440 Epoch[20] Batch [970]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:52:05,795 Epoch[20] Batch [980]	Speed: 4.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:52:15,553 Epoch[20] Batch [990]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:52:25,430 Epoch[20] Batch [1000]	Speed: 4.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:52:35,522 Epoch[20] Batch [1010]	Speed: 3.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:52:44,881 Epoch[20] Batch [1020]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:52:54,618 Epoch[20] Batch [1030]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:53:04,544 Epoch[20] Batch [1040]	Speed: 4.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:53:14,009 Epoch[20] Batch [1050]	Speed: 4.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:53:23,629 Epoch[20] Batch [1060]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:53:33,112 Epoch[20] Batch [1070]	Speed: 4.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:53:43,126 Epoch[20] Batch [1080]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:53:52,663 Epoch[20] Batch [1090]	Speed: 4.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:54:02,328 Epoch[20] Batch [1100]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:54:12,051 Epoch[20] Batch [1110]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:54:21,503 Epoch[20] Batch [1120]	Speed: 4.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:54:31,653 Epoch[20] Batch [1130]	Speed: 3.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:54:41,249 Epoch[20] Batch [1140]	Speed: 4.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:54:51,267 Epoch[20] Batch [1150]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:55:01,068 Epoch[20] Batch [1160]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:55:10,760 Epoch[20] Batch [1170]	Speed: 4.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:55:20,604 Epoch[20] Batch [1180]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:55:30,501 Epoch[20] Batch [1190]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:55:40,115 Epoch[20] Batch [1200]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:55:50,112 Epoch[20] Batch [1210]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:56:00,132 Epoch[20] Batch [1220]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:56:09,684 Epoch[20] Batch [1230]	Speed: 4.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:56:20,192 Epoch[20] Batch [1240]	Speed: 3.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:56:30,145 Epoch[20] Batch [1250]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:56:40,028 Epoch[20] Batch [1260]	Speed: 4.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:56:49,922 Epoch[20] Batch [1270]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:57:00,532 Epoch[20] Batch [1280]	Speed: 3.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:57:10,687 Epoch[20] Batch [1290]	Speed: 3.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:57:20,791 Epoch[20] Batch [1300]	Speed: 3.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:57:31,310 Epoch[20] Batch [1310]	Speed: 3.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:57:41,704 Epoch[20] Batch [1320]	Speed: 3.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:57:51,996 Epoch[20] Batch [1330]	Speed: 3.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:58:02,198 Epoch[20] Batch [1340]	Speed: 3.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:58:12,473 Epoch[20] Batch [1350]	Speed: 3.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:58:22,879 Epoch[20] Batch [1360]	Speed: 3.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:58:33,458 Epoch[20] Batch [1370]	Speed: 3.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:58:44,391 Epoch[20] Batch [1380]	Speed: 3.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:58:55,015 Epoch[20] Batch [1390]	Speed: 3.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:59:05,360 Epoch[20] Batch [1400]	Speed: 3.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:59:15,992 Epoch[20] Batch [1410]	Speed: 3.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:59:26,569 Epoch[20] Batch [1420]	Speed: 3.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:59:36,656 Epoch[20] Batch [1430]	Speed: 3.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:59:47,325 Epoch[20] Batch [1440]	Speed: 3.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 22:59:58,091 Epoch[20] Batch [1450]	Speed: 3.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:00:08,535 Epoch[20] Batch [1460]	Speed: 3.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:00:18,881 Epoch[20] Batch [1470]	Speed: 3.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:00:29,305 Epoch[20] Batch [1480]	Speed: 3.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:00:35,395 Epoch[20] Train-FCNLogLoss=nan
2017-07-13 23:00:35,395 Epoch[20] Time cost=1337.382
2017-07-13 23:00:36,703 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.params"
2017-07-13 23:00:41,368 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.states"
2017-07-13 23:00:52,427 Epoch[21] Batch [10]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:01:02,470 Epoch[21] Batch [20]	Speed: 3.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:01:12,443 Epoch[21] Batch [30]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:01:22,428 Epoch[21] Batch [40]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:01:32,313 Epoch[21] Batch [50]	Speed: 4.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:01:41,990 Epoch[21] Batch [60]	Speed: 4.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:01:52,000 Epoch[21] Batch [70]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:02:02,065 Epoch[21] Batch [80]	Speed: 3.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:02:12,125 Epoch[21] Batch [90]	Speed: 3.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:02:22,066 Epoch[21] Batch [100]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:02:31,824 Epoch[21] Batch [110]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:02:41,083 Epoch[21] Batch [120]	Speed: 4.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:02:50,469 Epoch[21] Batch [130]	Speed: 4.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:02:59,828 Epoch[21] Batch [140]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:03:09,103 Epoch[21] Batch [150]	Speed: 4.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:03:18,490 Epoch[21] Batch [160]	Speed: 4.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:03:27,668 Epoch[21] Batch [170]	Speed: 4.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:03:36,810 Epoch[21] Batch [180]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:03:46,165 Epoch[21] Batch [190]	Speed: 4.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:03:54,340 Epoch[21] Batch [200]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:02,376 Epoch[21] Batch [210]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:10,428 Epoch[21] Batch [220]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:18,468 Epoch[21] Batch [230]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:26,508 Epoch[21] Batch [240]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:34,696 Epoch[21] Batch [250]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:42,578 Epoch[21] Batch [260]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:50,741 Epoch[21] Batch [270]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:04:58,997 Epoch[21] Batch [280]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:05:07,184 Epoch[21] Batch [290]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:05:15,311 Epoch[21] Batch [300]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:05:23,415 Epoch[21] Batch [310]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:05:31,530 Epoch[21] Batch [320]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:05:39,935 Epoch[21] Batch [330]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:05:48,268 Epoch[21] Batch [340]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:05:56,699 Epoch[21] Batch [350]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:06:05,019 Epoch[21] Batch [360]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:06:13,289 Epoch[21] Batch [370]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:06:21,796 Epoch[21] Batch [380]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:06:30,134 Epoch[21] Batch [390]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:06:38,360 Epoch[21] Batch [400]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:06:46,929 Epoch[21] Batch [410]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:06:55,015 Epoch[21] Batch [420]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:02,624 Epoch[21] Batch [430]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:10,006 Epoch[21] Batch [440]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:17,384 Epoch[21] Batch [450]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:24,871 Epoch[21] Batch [460]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:32,286 Epoch[21] Batch [470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:39,810 Epoch[21] Batch [480]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:47,188 Epoch[21] Batch [490]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:07:54,719 Epoch[21] Batch [500]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:02,258 Epoch[21] Batch [510]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:09,627 Epoch[21] Batch [520]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:16,891 Epoch[21] Batch [530]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:24,231 Epoch[21] Batch [540]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:31,707 Epoch[21] Batch [550]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:39,183 Epoch[21] Batch [560]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:46,532 Epoch[21] Batch [570]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:08:53,901 Epoch[21] Batch [580]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:01,340 Epoch[21] Batch [590]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:08,682 Epoch[21] Batch [600]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:16,074 Epoch[21] Batch [610]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:23,588 Epoch[21] Batch [620]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:31,007 Epoch[21] Batch [630]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:38,553 Epoch[21] Batch [640]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:45,928 Epoch[21] Batch [650]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:09:53,467 Epoch[21] Batch [660]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:00,852 Epoch[21] Batch [670]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:08,265 Epoch[21] Batch [680]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:15,862 Epoch[21] Batch [690]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:23,309 Epoch[21] Batch [700]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:30,896 Epoch[21] Batch [710]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:38,669 Epoch[21] Batch [720]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:46,125 Epoch[21] Batch [730]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:10:53,850 Epoch[21] Batch [740]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:01,519 Epoch[21] Batch [750]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:08,875 Epoch[21] Batch [760]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:16,275 Epoch[21] Batch [770]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:23,699 Epoch[21] Batch [780]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:31,315 Epoch[21] Batch [790]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:39,264 Epoch[21] Batch [800]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:46,639 Epoch[21] Batch [810]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:11:54,258 Epoch[21] Batch [820]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:02,135 Epoch[21] Batch [830]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:09,935 Epoch[21] Batch [840]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:17,908 Epoch[21] Batch [850]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:25,662 Epoch[21] Batch [860]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:33,356 Epoch[21] Batch [870]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:41,186 Epoch[21] Batch [880]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:48,657 Epoch[21] Batch [890]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:12:56,248 Epoch[21] Batch [900]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:13:03,682 Epoch[21] Batch [910]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:13:11,986 Epoch[21] Batch [920]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:13:19,965 Epoch[21] Batch [930]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:13:28,151 Epoch[21] Batch [940]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:13:36,442 Epoch[21] Batch [950]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:13:44,621 Epoch[21] Batch [960]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:13:52,406 Epoch[21] Batch [970]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:00,853 Epoch[21] Batch [980]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:09,251 Epoch[21] Batch [990]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:17,921 Epoch[21] Batch [1000]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:26,380 Epoch[21] Batch [1010]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:34,673 Epoch[21] Batch [1020]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:42,395 Epoch[21] Batch [1030]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:50,479 Epoch[21] Batch [1040]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:14:57,975 Epoch[21] Batch [1050]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:15:06,029 Epoch[21] Batch [1060]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:15:14,604 Epoch[21] Batch [1070]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:15:22,889 Epoch[21] Batch [1080]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:15:30,977 Epoch[21] Batch [1090]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:15:39,695 Epoch[21] Batch [1100]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:15:48,545 Epoch[21] Batch [1110]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:15:57,439 Epoch[21] Batch [1120]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:05,660 Epoch[21] Batch [1130]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:13,792 Epoch[21] Batch [1140]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:21,605 Epoch[21] Batch [1150]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:29,118 Epoch[21] Batch [1160]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:36,831 Epoch[21] Batch [1170]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:44,301 Epoch[21] Batch [1180]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:51,891 Epoch[21] Batch [1190]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:16:59,625 Epoch[21] Batch [1200]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:17:07,300 Epoch[21] Batch [1210]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:17:15,027 Epoch[21] Batch [1220]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:17:22,524 Epoch[21] Batch [1230]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:17:30,261 Epoch[21] Batch [1240]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:17:37,731 Epoch[21] Batch [1250]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:17:45,340 Epoch[21] Batch [1260]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:17:53,287 Epoch[21] Batch [1270]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:01,417 Epoch[21] Batch [1280]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:09,720 Epoch[21] Batch [1290]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:17,208 Epoch[21] Batch [1300]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:25,304 Epoch[21] Batch [1310]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:33,312 Epoch[21] Batch [1320]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:41,107 Epoch[21] Batch [1330]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:48,684 Epoch[21] Batch [1340]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:18:56,459 Epoch[21] Batch [1350]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:04,201 Epoch[21] Batch [1360]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:11,778 Epoch[21] Batch [1370]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:19,321 Epoch[21] Batch [1380]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:27,218 Epoch[21] Batch [1390]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:34,839 Epoch[21] Batch [1400]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:42,842 Epoch[21] Batch [1410]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:50,612 Epoch[21] Batch [1420]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:19:58,815 Epoch[21] Batch [1430]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:20:07,053 Epoch[21] Batch [1440]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:20:15,864 Epoch[21] Batch [1450]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:20:24,764 Epoch[21] Batch [1460]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:20:33,574 Epoch[21] Batch [1470]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:20:42,545 Epoch[21] Batch [1480]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:20:47,829 Epoch[21] Train-FCNLogLoss=nan
2017-07-13 23:20:47,829 Epoch[21] Time cost=1206.461
2017-07-13 23:20:49,049 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.params"
2017-07-13 23:20:52,917 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.states"
2017-07-13 23:21:02,945 Epoch[22] Batch [10]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:21:11,045 Epoch[22] Batch [20]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:21:19,150 Epoch[22] Batch [30]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:21:27,629 Epoch[22] Batch [40]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:21:35,883 Epoch[22] Batch [50]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:21:44,256 Epoch[22] Batch [60]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:21:52,504 Epoch[22] Batch [70]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:00,704 Epoch[22] Batch [80]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:08,849 Epoch[22] Batch [90]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:16,927 Epoch[22] Batch [100]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:25,167 Epoch[22] Batch [110]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:33,336 Epoch[22] Batch [120]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:41,552 Epoch[22] Batch [130]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:49,696 Epoch[22] Batch [140]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:22:57,583 Epoch[22] Batch [150]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:23:05,502 Epoch[22] Batch [160]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:23:13,709 Epoch[22] Batch [170]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:23:21,642 Epoch[22] Batch [180]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:23:29,497 Epoch[22] Batch [190]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:23:37,267 Epoch[22] Batch [200]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:23:45,814 Epoch[22] Batch [210]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:23:54,384 Epoch[22] Batch [220]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:02,966 Epoch[22] Batch [230]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:11,408 Epoch[22] Batch [240]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:19,251 Epoch[22] Batch [250]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:26,638 Epoch[22] Batch [260]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:34,254 Epoch[22] Batch [270]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:42,447 Epoch[22] Batch [280]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:50,323 Epoch[22] Batch [290]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:24:57,718 Epoch[22] Batch [300]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:05,212 Epoch[22] Batch [310]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:12,526 Epoch[22] Batch [320]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:19,818 Epoch[22] Batch [330]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:27,195 Epoch[22] Batch [340]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:34,393 Epoch[22] Batch [350]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:41,941 Epoch[22] Batch [360]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:49,402 Epoch[22] Batch [370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:25:56,730 Epoch[22] Batch [380]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:04,115 Epoch[22] Batch [390]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:11,612 Epoch[22] Batch [400]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:19,070 Epoch[22] Batch [410]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:26,527 Epoch[22] Batch [420]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:33,858 Epoch[22] Batch [430]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:41,066 Epoch[22] Batch [440]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:48,466 Epoch[22] Batch [450]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:26:55,981 Epoch[22] Batch [460]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:03,427 Epoch[22] Batch [470]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:10,943 Epoch[22] Batch [480]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:18,427 Epoch[22] Batch [490]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:25,990 Epoch[22] Batch [500]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:33,675 Epoch[22] Batch [510]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:41,148 Epoch[22] Batch [520]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:48,575 Epoch[22] Batch [530]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:27:56,012 Epoch[22] Batch [540]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:03,419 Epoch[22] Batch [550]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:10,882 Epoch[22] Batch [560]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:18,331 Epoch[22] Batch [570]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:25,782 Epoch[22] Batch [580]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:33,275 Epoch[22] Batch [590]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:40,641 Epoch[22] Batch [600]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:47,922 Epoch[22] Batch [610]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:28:55,396 Epoch[22] Batch [620]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:02,931 Epoch[22] Batch [630]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:10,513 Epoch[22] Batch [640]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:17,921 Epoch[22] Batch [650]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:25,362 Epoch[22] Batch [660]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:32,869 Epoch[22] Batch [670]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:40,182 Epoch[22] Batch [680]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:47,493 Epoch[22] Batch [690]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:29:55,036 Epoch[22] Batch [700]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:02,410 Epoch[22] Batch [710]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:09,940 Epoch[22] Batch [720]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:17,394 Epoch[22] Batch [730]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:24,893 Epoch[22] Batch [740]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:32,525 Epoch[22] Batch [750]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:39,861 Epoch[22] Batch [760]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:47,499 Epoch[22] Batch [770]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:30:55,161 Epoch[22] Batch [780]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:02,755 Epoch[22] Batch [790]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:09,859 Epoch[22] Batch [800]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:17,313 Epoch[22] Batch [810]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:24,736 Epoch[22] Batch [820]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:32,065 Epoch[22] Batch [830]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:39,494 Epoch[22] Batch [840]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:47,182 Epoch[22] Batch [850]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:31:54,847 Epoch[22] Batch [860]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:02,146 Epoch[22] Batch [870]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:09,483 Epoch[22] Batch [880]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:17,011 Epoch[22] Batch [890]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:24,583 Epoch[22] Batch [900]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:32,152 Epoch[22] Batch [910]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:39,702 Epoch[22] Batch [920]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:47,180 Epoch[22] Batch [930]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:32:54,546 Epoch[22] Batch [940]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:01,710 Epoch[22] Batch [950]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:09,184 Epoch[22] Batch [960]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:16,751 Epoch[22] Batch [970]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:24,290 Epoch[22] Batch [980]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:31,343 Epoch[22] Batch [990]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:38,759 Epoch[22] Batch [1000]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:46,291 Epoch[22] Batch [1010]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:33:53,716 Epoch[22] Batch [1020]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:01,264 Epoch[22] Batch [1030]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:08,709 Epoch[22] Batch [1040]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:16,095 Epoch[22] Batch [1050]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:23,838 Epoch[22] Batch [1060]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:31,600 Epoch[22] Batch [1070]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:39,211 Epoch[22] Batch [1080]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:46,522 Epoch[22] Batch [1090]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:34:54,221 Epoch[22] Batch [1100]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:01,824 Epoch[22] Batch [1110]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:09,671 Epoch[22] Batch [1120]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:16,939 Epoch[22] Batch [1130]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:24,438 Epoch[22] Batch [1140]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:31,885 Epoch[22] Batch [1150]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:39,201 Epoch[22] Batch [1160]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:46,499 Epoch[22] Batch [1170]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:35:53,848 Epoch[22] Batch [1180]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:01,193 Epoch[22] Batch [1190]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:08,703 Epoch[22] Batch [1200]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:16,012 Epoch[22] Batch [1210]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:23,616 Epoch[22] Batch [1220]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:31,040 Epoch[22] Batch [1230]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:38,376 Epoch[22] Batch [1240]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:45,839 Epoch[22] Batch [1250]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:36:53,087 Epoch[22] Batch [1260]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:00,333 Epoch[22] Batch [1270]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:07,993 Epoch[22] Batch [1280]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:15,171 Epoch[22] Batch [1290]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:22,649 Epoch[22] Batch [1300]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:30,286 Epoch[22] Batch [1310]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:37,811 Epoch[22] Batch [1320]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:45,505 Epoch[22] Batch [1330]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:37:53,224 Epoch[22] Batch [1340]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:00,615 Epoch[22] Batch [1350]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:08,130 Epoch[22] Batch [1360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:15,727 Epoch[22] Batch [1370]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:23,036 Epoch[22] Batch [1380]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:30,771 Epoch[22] Batch [1390]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:38,245 Epoch[22] Batch [1400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:46,472 Epoch[22] Batch [1410]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:38:54,986 Epoch[22] Batch [1420]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:39:03,459 Epoch[22] Batch [1430]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:39:11,875 Epoch[22] Batch [1440]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:39:20,203 Epoch[22] Batch [1450]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:39:28,538 Epoch[22] Batch [1460]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:39:37,132 Epoch[22] Batch [1470]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:39:45,080 Epoch[22] Batch [1480]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:39:50,012 Epoch[22] Train-FCNLogLoss=nan
2017-07-13 23:39:50,012 Epoch[22] Time cost=1137.095
2017-07-13 23:39:51,112 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.params"
2017-07-13 23:39:54,986 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.states"
2017-07-13 23:40:04,386 Epoch[23] Batch [10]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:40:12,265 Epoch[23] Batch [20]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:40:20,026 Epoch[23] Batch [30]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:40:27,894 Epoch[23] Batch [40]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:40:35,156 Epoch[23] Batch [50]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:40:43,291 Epoch[23] Batch [60]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:40:50,815 Epoch[23] Batch [70]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:40:58,301 Epoch[23] Batch [80]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:06,059 Epoch[23] Batch [90]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:13,484 Epoch[23] Batch [100]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:21,235 Epoch[23] Batch [110]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:28,577 Epoch[23] Batch [120]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:35,987 Epoch[23] Batch [130]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:43,177 Epoch[23] Batch [140]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:50,343 Epoch[23] Batch [150]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:41:57,545 Epoch[23] Batch [160]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:42:05,262 Epoch[23] Batch [170]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:42:13,049 Epoch[23] Batch [180]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:42:21,279 Epoch[23] Batch [190]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:42:29,707 Epoch[23] Batch [200]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:42:37,504 Epoch[23] Batch [210]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:42:45,005 Epoch[23] Batch [220]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:42:52,524 Epoch[23] Batch [230]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:00,176 Epoch[23] Batch [240]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:07,672 Epoch[23] Batch [250]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:15,546 Epoch[23] Batch [260]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:23,436 Epoch[23] Batch [270]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:31,287 Epoch[23] Batch [280]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:39,399 Epoch[23] Batch [290]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:46,971 Epoch[23] Batch [300]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:43:54,451 Epoch[23] Batch [310]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:01,208 Epoch[23] Batch [320]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:07,704 Epoch[23] Batch [330]	Speed: 6.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:14,287 Epoch[23] Batch [340]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:20,822 Epoch[23] Batch [350]	Speed: 6.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:28,155 Epoch[23] Batch [360]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:35,456 Epoch[23] Batch [370]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:42,336 Epoch[23] Batch [380]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:49,234 Epoch[23] Batch [390]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:44:56,181 Epoch[23] Batch [400]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:03,309 Epoch[23] Batch [410]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:10,058 Epoch[23] Batch [420]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:16,768 Epoch[23] Batch [430]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:23,658 Epoch[23] Batch [440]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:30,826 Epoch[23] Batch [450]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:37,656 Epoch[23] Batch [460]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:44,561 Epoch[23] Batch [470]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:51,085 Epoch[23] Batch [480]	Speed: 6.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:45:57,951 Epoch[23] Batch [490]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:04,907 Epoch[23] Batch [500]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:11,929 Epoch[23] Batch [510]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:18,829 Epoch[23] Batch [520]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:25,430 Epoch[23] Batch [530]	Speed: 6.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:32,399 Epoch[23] Batch [540]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:39,098 Epoch[23] Batch [550]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:45,728 Epoch[23] Batch [560]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:52,493 Epoch[23] Batch [570]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:46:59,090 Epoch[23] Batch [580]	Speed: 6.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:05,903 Epoch[23] Batch [590]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:12,735 Epoch[23] Batch [600]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:19,315 Epoch[23] Batch [610]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:26,118 Epoch[23] Batch [620]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:32,789 Epoch[23] Batch [630]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:39,348 Epoch[23] Batch [640]	Speed: 6.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:45,932 Epoch[23] Batch [650]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:52,839 Epoch[23] Batch [660]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:47:59,573 Epoch[23] Batch [670]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:06,451 Epoch[23] Batch [680]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:13,309 Epoch[23] Batch [690]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:20,225 Epoch[23] Batch [700]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:27,047 Epoch[23] Batch [710]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:33,860 Epoch[23] Batch [720]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:40,778 Epoch[23] Batch [730]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:47,589 Epoch[23] Batch [740]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:48:54,069 Epoch[23] Batch [750]	Speed: 6.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:01,845 Epoch[23] Batch [760]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:09,456 Epoch[23] Batch [770]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:16,927 Epoch[23] Batch [780]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:24,651 Epoch[23] Batch [790]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:32,305 Epoch[23] Batch [800]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:39,911 Epoch[23] Batch [810]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:47,759 Epoch[23] Batch [820]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:49:55,306 Epoch[23] Batch [830]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:02,904 Epoch[23] Batch [840]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:10,298 Epoch[23] Batch [850]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:18,307 Epoch[23] Batch [860]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:26,070 Epoch[23] Batch [870]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:33,616 Epoch[23] Batch [880]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:41,240 Epoch[23] Batch [890]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:48,478 Epoch[23] Batch [900]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:50:56,205 Epoch[23] Batch [910]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:04,264 Epoch[23] Batch [920]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:11,987 Epoch[23] Batch [930]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:19,374 Epoch[23] Batch [940]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:27,206 Epoch[23] Batch [950]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:34,809 Epoch[23] Batch [960]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:42,258 Epoch[23] Batch [970]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:49,911 Epoch[23] Batch [980]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:51:57,409 Epoch[23] Batch [990]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:05,287 Epoch[23] Batch [1000]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:12,693 Epoch[23] Batch [1010]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:20,253 Epoch[23] Batch [1020]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:28,055 Epoch[23] Batch [1030]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:35,987 Epoch[23] Batch [1040]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:43,769 Epoch[23] Batch [1050]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:51,973 Epoch[23] Batch [1060]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:52:59,989 Epoch[23] Batch [1070]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:53:07,865 Epoch[23] Batch [1080]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:53:15,701 Epoch[23] Batch [1090]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:53:23,581 Epoch[23] Batch [1100]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:53:31,277 Epoch[23] Batch [1110]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:53:39,231 Epoch[23] Batch [1120]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:53:47,374 Epoch[23] Batch [1130]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:53:55,262 Epoch[23] Batch [1140]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:03,041 Epoch[23] Batch [1150]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:10,912 Epoch[23] Batch [1160]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:18,987 Epoch[23] Batch [1170]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:26,941 Epoch[23] Batch [1180]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:34,952 Epoch[23] Batch [1190]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:43,006 Epoch[23] Batch [1200]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:51,106 Epoch[23] Batch [1210]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:54:58,806 Epoch[23] Batch [1220]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:55:06,470 Epoch[23] Batch [1230]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:55:14,493 Epoch[23] Batch [1240]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:55:22,502 Epoch[23] Batch [1250]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:55:30,291 Epoch[23] Batch [1260]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:55:38,251 Epoch[23] Batch [1270]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:55:45,932 Epoch[23] Batch [1280]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:55:53,575 Epoch[23] Batch [1290]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:01,717 Epoch[23] Batch [1300]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:09,941 Epoch[23] Batch [1310]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:17,880 Epoch[23] Batch [1320]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:26,026 Epoch[23] Batch [1330]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:34,107 Epoch[23] Batch [1340]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:42,062 Epoch[23] Batch [1350]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:49,741 Epoch[23] Batch [1360]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:56:57,741 Epoch[23] Batch [1370]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:57:05,525 Epoch[23] Batch [1380]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:57:13,482 Epoch[23] Batch [1390]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:57:21,568 Epoch[23] Batch [1400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:57:29,494 Epoch[23] Batch [1410]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:57:37,435 Epoch[23] Batch [1420]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:57:45,319 Epoch[23] Batch [1430]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:57:53,391 Epoch[23] Batch [1440]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:58:01,471 Epoch[23] Batch [1450]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:58:09,563 Epoch[23] Batch [1460]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:58:17,551 Epoch[23] Batch [1470]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:58:25,576 Epoch[23] Batch [1480]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:58:30,419 Epoch[23] Train-FCNLogLoss=nan
2017-07-13 23:58:30,420 Epoch[23] Time cost=1115.433
2017-07-13 23:58:31,514 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.params"
2017-07-13 23:58:35,377 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.states"
2017-07-13 23:58:44,474 Epoch[24] Batch [10]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:58:52,410 Epoch[24] Batch [20]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:00,023 Epoch[24] Batch [30]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:07,211 Epoch[24] Batch [40]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:14,288 Epoch[24] Batch [50]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:20,990 Epoch[24] Batch [60]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:28,045 Epoch[24] Batch [70]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:35,097 Epoch[24] Batch [80]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:42,350 Epoch[24] Batch [90]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:49,382 Epoch[24] Batch [100]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-13 23:59:56,765 Epoch[24] Batch [110]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:04,052 Epoch[24] Batch [120]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:11,407 Epoch[24] Batch [130]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:18,599 Epoch[24] Batch [140]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:26,118 Epoch[24] Batch [150]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:33,670 Epoch[24] Batch [160]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:41,076 Epoch[24] Batch [170]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:47,437 Epoch[24] Batch [180]	Speed: 6.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:00:54,543 Epoch[24] Batch [190]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:01,486 Epoch[24] Batch [200]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:08,631 Epoch[24] Batch [210]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:15,695 Epoch[24] Batch [220]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:22,760 Epoch[24] Batch [230]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:29,676 Epoch[24] Batch [240]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:36,473 Epoch[24] Batch [250]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:43,375 Epoch[24] Batch [260]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:50,407 Epoch[24] Batch [270]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:01:57,592 Epoch[24] Batch [280]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:04,657 Epoch[24] Batch [290]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:11,991 Epoch[24] Batch [300]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:19,507 Epoch[24] Batch [310]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:26,908 Epoch[24] Batch [320]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:34,150 Epoch[24] Batch [330]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:41,386 Epoch[24] Batch [340]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:48,548 Epoch[24] Batch [350]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:02:55,835 Epoch[24] Batch [360]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:03,229 Epoch[24] Batch [370]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:10,401 Epoch[24] Batch [380]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:17,571 Epoch[24] Batch [390]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:24,882 Epoch[24] Batch [400]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:32,096 Epoch[24] Batch [410]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:38,953 Epoch[24] Batch [420]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:46,140 Epoch[24] Batch [430]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:03:53,517 Epoch[24] Batch [440]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:00,691 Epoch[24] Batch [450]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:08,066 Epoch[24] Batch [460]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:15,838 Epoch[24] Batch [470]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:23,878 Epoch[24] Batch [480]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:31,967 Epoch[24] Batch [490]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:40,154 Epoch[24] Batch [500]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:48,367 Epoch[24] Batch [510]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:04:56,043 Epoch[24] Batch [520]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:03,616 Epoch[24] Batch [530]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:11,291 Epoch[24] Batch [540]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:18,930 Epoch[24] Batch [550]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:26,643 Epoch[24] Batch [560]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:34,014 Epoch[24] Batch [570]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:42,110 Epoch[24] Batch [580]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:50,640 Epoch[24] Batch [590]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:05:59,206 Epoch[24] Batch [600]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:06:07,453 Epoch[24] Batch [610]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:06:15,868 Epoch[24] Batch [620]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:06:24,500 Epoch[24] Batch [630]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:06:32,820 Epoch[24] Batch [640]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:06:41,051 Epoch[24] Batch [650]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:06:49,033 Epoch[24] Batch [660]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:06:56,541 Epoch[24] Batch [670]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:04,109 Epoch[24] Batch [680]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:11,776 Epoch[24] Batch [690]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:19,360 Epoch[24] Batch [700]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:26,961 Epoch[24] Batch [710]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:34,409 Epoch[24] Batch [720]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:41,844 Epoch[24] Batch [730]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:49,173 Epoch[24] Batch [740]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:07:56,811 Epoch[24] Batch [750]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:04,625 Epoch[24] Batch [760]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:12,448 Epoch[24] Batch [770]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:19,933 Epoch[24] Batch [780]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:27,608 Epoch[24] Batch [790]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:34,984 Epoch[24] Batch [800]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:43,184 Epoch[24] Batch [810]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:51,277 Epoch[24] Batch [820]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:08:59,164 Epoch[24] Batch [830]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:09:07,037 Epoch[24] Batch [840]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:09:15,028 Epoch[24] Batch [850]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:09:23,057 Epoch[24] Batch [860]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:09:31,218 Epoch[24] Batch [870]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:09:39,257 Epoch[24] Batch [880]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:09:47,215 Epoch[24] Batch [890]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:09:55,408 Epoch[24] Batch [900]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:10:03,416 Epoch[24] Batch [910]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:10:11,657 Epoch[24] Batch [920]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:10:19,832 Epoch[24] Batch [930]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:10:28,048 Epoch[24] Batch [940]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:10:36,219 Epoch[24] Batch [950]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:10:44,339 Epoch[24] Batch [960]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:10:52,455 Epoch[24] Batch [970]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:00,390 Epoch[24] Batch [980]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:08,364 Epoch[24] Batch [990]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:16,374 Epoch[24] Batch [1000]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:24,275 Epoch[24] Batch [1010]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:32,122 Epoch[24] Batch [1020]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:39,933 Epoch[24] Batch [1030]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:47,748 Epoch[24] Batch [1040]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:11:55,842 Epoch[24] Batch [1050]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:12:03,562 Epoch[24] Batch [1060]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:12:11,641 Epoch[24] Batch [1070]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:12:19,612 Epoch[24] Batch [1080]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:12:27,720 Epoch[24] Batch [1090]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:12:35,702 Epoch[24] Batch [1100]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:12:43,928 Epoch[24] Batch [1110]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:12:51,926 Epoch[24] Batch [1120]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:00,034 Epoch[24] Batch [1130]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:07,779 Epoch[24] Batch [1140]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:15,726 Epoch[24] Batch [1150]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:23,704 Epoch[24] Batch [1160]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:31,797 Epoch[24] Batch [1170]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:39,900 Epoch[24] Batch [1180]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:48,134 Epoch[24] Batch [1190]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:13:56,232 Epoch[24] Batch [1200]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:03,104 Epoch[24] Batch [1210]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:10,481 Epoch[24] Batch [1220]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:17,953 Epoch[24] Batch [1230]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:25,351 Epoch[24] Batch [1240]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:32,889 Epoch[24] Batch [1250]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:40,633 Epoch[24] Batch [1260]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:48,133 Epoch[24] Batch [1270]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:14:55,347 Epoch[24] Batch [1280]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:02,902 Epoch[24] Batch [1290]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:10,173 Epoch[24] Batch [1300]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:17,696 Epoch[24] Batch [1310]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:25,194 Epoch[24] Batch [1320]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:32,824 Epoch[24] Batch [1330]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:40,498 Epoch[24] Batch [1340]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:47,967 Epoch[24] Batch [1350]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:15:55,535 Epoch[24] Batch [1360]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:03,065 Epoch[24] Batch [1370]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:10,501 Epoch[24] Batch [1380]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:17,765 Epoch[24] Batch [1390]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:25,257 Epoch[24] Batch [1400]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:32,556 Epoch[24] Batch [1410]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:40,251 Epoch[24] Batch [1420]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:47,779 Epoch[24] Batch [1430]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:16:55,116 Epoch[24] Batch [1440]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:17:02,649 Epoch[24] Batch [1450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:17:10,084 Epoch[24] Batch [1460]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:17:17,358 Epoch[24] Batch [1470]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:17:24,947 Epoch[24] Batch [1480]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:17:29,431 Epoch[24] Train-FCNLogLoss=nan
2017-07-14 00:17:29,431 Epoch[24] Time cost=1134.054
2017-07-14 00:17:30,588 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.params"
2017-07-14 00:17:34,372 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.states"
2017-07-14 00:17:42,812 Epoch[25] Batch [10]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:17:50,392 Epoch[25] Batch [20]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:17:57,996 Epoch[25] Batch [30]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:05,595 Epoch[25] Batch [40]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:13,459 Epoch[25] Batch [50]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:21,146 Epoch[25] Batch [60]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:28,634 Epoch[25] Batch [70]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:36,269 Epoch[25] Batch [80]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:43,757 Epoch[25] Batch [90]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:51,714 Epoch[25] Batch [100]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:18:59,383 Epoch[25] Batch [110]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:07,009 Epoch[25] Batch [120]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:14,537 Epoch[25] Batch [130]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:21,908 Epoch[25] Batch [140]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:29,104 Epoch[25] Batch [150]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:36,778 Epoch[25] Batch [160]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:44,108 Epoch[25] Batch [170]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:51,555 Epoch[25] Batch [180]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:19:58,771 Epoch[25] Batch [190]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:20:06,315 Epoch[25] Batch [200]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:20:13,981 Epoch[25] Batch [210]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:20:21,516 Epoch[25] Batch [220]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:20:29,102 Epoch[25] Batch [230]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:20:36,633 Epoch[25] Batch [240]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:20:44,473 Epoch[25] Batch [250]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:20:52,716 Epoch[25] Batch [260]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:01,205 Epoch[25] Batch [270]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:09,699 Epoch[25] Batch [280]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:18,200 Epoch[25] Batch [290]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:26,459 Epoch[25] Batch [300]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:34,396 Epoch[25] Batch [310]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:42,394 Epoch[25] Batch [320]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:50,500 Epoch[25] Batch [330]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:21:58,490 Epoch[25] Batch [340]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:22:06,575 Epoch[25] Batch [350]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:22:14,516 Epoch[25] Batch [360]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:22:22,484 Epoch[25] Batch [370]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:22:30,706 Epoch[25] Batch [380]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:22:38,811 Epoch[25] Batch [390]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:22:46,885 Epoch[25] Batch [400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:22:55,343 Epoch[25] Batch [410]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:03,566 Epoch[25] Batch [420]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:11,389 Epoch[25] Batch [430]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:19,275 Epoch[25] Batch [440]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:27,563 Epoch[25] Batch [450]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:35,585 Epoch[25] Batch [460]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:43,406 Epoch[25] Batch [470]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:51,674 Epoch[25] Batch [480]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:23:59,849 Epoch[25] Batch [490]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:24:08,020 Epoch[25] Batch [500]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:24:16,367 Epoch[25] Batch [510]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:24:24,348 Epoch[25] Batch [520]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:24:32,441 Epoch[25] Batch [530]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:24:40,317 Epoch[25] Batch [540]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:24:48,303 Epoch[25] Batch [550]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:24:56,359 Epoch[25] Batch [560]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:25:04,324 Epoch[25] Batch [570]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:25:12,600 Epoch[25] Batch [580]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:25:20,585 Epoch[25] Batch [590]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:25:29,138 Epoch[25] Batch [600]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:25:37,427 Epoch[25] Batch [610]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:25:45,710 Epoch[25] Batch [620]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:25:53,847 Epoch[25] Batch [630]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:01,962 Epoch[25] Batch [640]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:10,099 Epoch[25] Batch [650]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:18,144 Epoch[25] Batch [660]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:26,200 Epoch[25] Batch [670]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:34,196 Epoch[25] Batch [680]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:42,127 Epoch[25] Batch [690]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:50,366 Epoch[25] Batch [700]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:26:58,394 Epoch[25] Batch [710]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:27:06,362 Epoch[25] Batch [720]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:27:14,439 Epoch[25] Batch [730]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:27:22,614 Epoch[25] Batch [740]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:27:30,631 Epoch[25] Batch [750]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:27:39,041 Epoch[25] Batch [760]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:27:46,961 Epoch[25] Batch [770]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:27:55,248 Epoch[25] Batch [780]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:03,193 Epoch[25] Batch [790]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:11,491 Epoch[25] Batch [800]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:19,461 Epoch[25] Batch [810]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:27,452 Epoch[25] Batch [820]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:35,494 Epoch[25] Batch [830]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:43,421 Epoch[25] Batch [840]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:51,618 Epoch[25] Batch [850]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:28:59,791 Epoch[25] Batch [860]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:29:07,672 Epoch[25] Batch [870]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:29:15,925 Epoch[25] Batch [880]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:29:23,946 Epoch[25] Batch [890]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:29:32,004 Epoch[25] Batch [900]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:29:39,741 Epoch[25] Batch [910]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:29:47,394 Epoch[25] Batch [920]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:29:54,682 Epoch[25] Batch [930]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:02,263 Epoch[25] Batch [940]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:10,019 Epoch[25] Batch [950]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:18,023 Epoch[25] Batch [960]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:26,208 Epoch[25] Batch [970]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:34,199 Epoch[25] Batch [980]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:42,423 Epoch[25] Batch [990]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:50,245 Epoch[25] Batch [1000]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:30:58,512 Epoch[25] Batch [1010]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:31:06,434 Epoch[25] Batch [1020]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:31:14,773 Epoch[25] Batch [1030]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:31:23,025 Epoch[25] Batch [1040]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:31:31,164 Epoch[25] Batch [1050]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:31:39,392 Epoch[25] Batch [1060]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:31:47,559 Epoch[25] Batch [1070]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:31:55,630 Epoch[25] Batch [1080]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:32:03,590 Epoch[25] Batch [1090]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:32:12,051 Epoch[25] Batch [1100]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:32:20,377 Epoch[25] Batch [1110]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:32:28,854 Epoch[25] Batch [1120]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:32:37,051 Epoch[25] Batch [1130]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:32:45,521 Epoch[25] Batch [1140]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:32:53,538 Epoch[25] Batch [1150]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:01,854 Epoch[25] Batch [1160]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:10,230 Epoch[25] Batch [1170]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:18,481 Epoch[25] Batch [1180]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:26,585 Epoch[25] Batch [1190]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:34,854 Epoch[25] Batch [1200]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:43,086 Epoch[25] Batch [1210]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:51,331 Epoch[25] Batch [1220]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:33:59,220 Epoch[25] Batch [1230]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:34:07,148 Epoch[25] Batch [1240]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:34:15,148 Epoch[25] Batch [1250]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:34:23,286 Epoch[25] Batch [1260]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:34:31,393 Epoch[25] Batch [1270]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:34:39,687 Epoch[25] Batch [1280]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:34:48,003 Epoch[25] Batch [1290]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:34:56,222 Epoch[25] Batch [1300]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:35:04,633 Epoch[25] Batch [1310]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:35:12,660 Epoch[25] Batch [1320]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:35:20,969 Epoch[25] Batch [1330]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:35:29,095 Epoch[25] Batch [1340]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:35:37,432 Epoch[25] Batch [1350]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:35:45,796 Epoch[25] Batch [1360]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:35:53,974 Epoch[25] Batch [1370]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:02,296 Epoch[25] Batch [1380]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:10,729 Epoch[25] Batch [1390]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:18,682 Epoch[25] Batch [1400]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:26,646 Epoch[25] Batch [1410]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:34,330 Epoch[25] Batch [1420]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:42,191 Epoch[25] Batch [1430]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:49,627 Epoch[25] Batch [1440]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:36:57,140 Epoch[25] Batch [1450]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:37:04,459 Epoch[25] Batch [1460]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:37:12,510 Epoch[25] Batch [1470]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:37:20,565 Epoch[25] Batch [1480]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:37:25,578 Epoch[25] Train-FCNLogLoss=nan
2017-07-14 00:37:25,578 Epoch[25] Time cost=1191.206
2017-07-14 00:37:26,622 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.params"
2017-07-14 00:37:30,554 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.states"
2017-07-14 00:37:39,722 Epoch[26] Batch [10]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:37:47,710 Epoch[26] Batch [20]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:37:55,819 Epoch[26] Batch [30]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:38:03,688 Epoch[26] Batch [40]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:38:11,818 Epoch[26] Batch [50]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:38:20,234 Epoch[26] Batch [60]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:38:28,441 Epoch[26] Batch [70]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:38:36,582 Epoch[26] Batch [80]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:38:44,594 Epoch[26] Batch [90]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:38:52,591 Epoch[26] Batch [100]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:00,731 Epoch[26] Batch [110]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:08,737 Epoch[26] Batch [120]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:16,732 Epoch[26] Batch [130]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:24,933 Epoch[26] Batch [140]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:33,122 Epoch[26] Batch [150]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:41,026 Epoch[26] Batch [160]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:48,925 Epoch[26] Batch [170]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:39:57,135 Epoch[26] Batch [180]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:40:05,271 Epoch[26] Batch [190]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:40:13,447 Epoch[26] Batch [200]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:40:21,581 Epoch[26] Batch [210]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:40:29,687 Epoch[26] Batch [220]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:40:37,884 Epoch[26] Batch [230]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:40:46,357 Epoch[26] Batch [240]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:40:54,579 Epoch[26] Batch [250]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:02,620 Epoch[26] Batch [260]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:09,920 Epoch[26] Batch [270]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:17,345 Epoch[26] Batch [280]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:24,718 Epoch[26] Batch [290]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:32,074 Epoch[26] Batch [300]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:39,544 Epoch[26] Batch [310]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:46,990 Epoch[26] Batch [320]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:41:54,506 Epoch[26] Batch [330]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:01,898 Epoch[26] Batch [340]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:09,212 Epoch[26] Batch [350]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:16,555 Epoch[26] Batch [360]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:24,069 Epoch[26] Batch [370]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:31,455 Epoch[26] Batch [380]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:38,698 Epoch[26] Batch [390]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:46,145 Epoch[26] Batch [400]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:42:53,654 Epoch[26] Batch [410]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:01,128 Epoch[26] Batch [420]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:08,723 Epoch[26] Batch [430]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:16,197 Epoch[26] Batch [440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:23,616 Epoch[26] Batch [450]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:31,045 Epoch[26] Batch [460]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:38,481 Epoch[26] Batch [470]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:45,923 Epoch[26] Batch [480]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:43:53,540 Epoch[26] Batch [490]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:01,096 Epoch[26] Batch [500]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:08,445 Epoch[26] Batch [510]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:15,774 Epoch[26] Batch [520]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:23,048 Epoch[26] Batch [530]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:30,619 Epoch[26] Batch [540]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:38,038 Epoch[26] Batch [550]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:45,406 Epoch[26] Batch [560]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:44:52,672 Epoch[26] Batch [570]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:00,848 Epoch[26] Batch [580]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:08,157 Epoch[26] Batch [590]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:15,535 Epoch[26] Batch [600]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:22,931 Epoch[26] Batch [610]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:30,268 Epoch[26] Batch [620]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:37,647 Epoch[26] Batch [630]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:45,276 Epoch[26] Batch [640]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:52,587 Epoch[26] Batch [650]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:45:59,978 Epoch[26] Batch [660]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:46:07,365 Epoch[26] Batch [670]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:46:14,790 Epoch[26] Batch [680]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:46:22,304 Epoch[26] Batch [690]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:46:30,599 Epoch[26] Batch [700]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:46:38,748 Epoch[26] Batch [710]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:46:46,580 Epoch[26] Batch [720]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:46:54,345 Epoch[26] Batch [730]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:47:03,121 Epoch[26] Batch [740]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:47:11,945 Epoch[26] Batch [750]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:47:20,058 Epoch[26] Batch [760]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:47:28,156 Epoch[26] Batch [770]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:47:36,314 Epoch[26] Batch [780]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:47:44,413 Epoch[26] Batch [790]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:47:52,613 Epoch[26] Batch [800]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:00,605 Epoch[26] Batch [810]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:08,585 Epoch[26] Batch [820]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:16,698 Epoch[26] Batch [830]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:24,685 Epoch[26] Batch [840]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:32,820 Epoch[26] Batch [850]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:40,669 Epoch[26] Batch [860]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:48,719 Epoch[26] Batch [870]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:48:56,790 Epoch[26] Batch [880]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:49:04,874 Epoch[26] Batch [890]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:49:12,657 Epoch[26] Batch [900]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:49:20,024 Epoch[26] Batch [910]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:49:28,338 Epoch[26] Batch [920]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:49:37,118 Epoch[26] Batch [930]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:49:45,958 Epoch[26] Batch [940]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:49:54,794 Epoch[26] Batch [950]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:50:03,205 Epoch[26] Batch [960]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:50:12,098 Epoch[26] Batch [970]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:50:21,014 Epoch[26] Batch [980]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:50:29,690 Epoch[26] Batch [990]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:50:38,513 Epoch[26] Batch [1000]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:50:45,984 Epoch[26] Batch [1010]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:50:53,794 Epoch[26] Batch [1020]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:01,311 Epoch[26] Batch [1030]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:08,766 Epoch[26] Batch [1040]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:16,354 Epoch[26] Batch [1050]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:23,868 Epoch[26] Batch [1060]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:31,614 Epoch[26] Batch [1070]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:39,866 Epoch[26] Batch [1080]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:47,673 Epoch[26] Batch [1090]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:51:55,490 Epoch[26] Batch [1100]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:03,621 Epoch[26] Batch [1110]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:12,187 Epoch[26] Batch [1120]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:20,775 Epoch[26] Batch [1130]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:28,874 Epoch[26] Batch [1140]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:36,270 Epoch[26] Batch [1150]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:43,556 Epoch[26] Batch [1160]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:51,205 Epoch[26] Batch [1170]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:52:58,782 Epoch[26] Batch [1180]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:06,265 Epoch[26] Batch [1190]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:13,745 Epoch[26] Batch [1200]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:21,230 Epoch[26] Batch [1210]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:28,696 Epoch[26] Batch [1220]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:36,658 Epoch[26] Batch [1230]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:44,269 Epoch[26] Batch [1240]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:51,821 Epoch[26] Batch [1250]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:53:59,439 Epoch[26] Batch [1260]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:54:07,286 Epoch[26] Batch [1270]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:54:14,971 Epoch[26] Batch [1280]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:54:22,678 Epoch[26] Batch [1290]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:54:30,541 Epoch[26] Batch [1300]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:54:38,250 Epoch[26] Batch [1310]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:54:45,840 Epoch[26] Batch [1320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:54:53,299 Epoch[26] Batch [1330]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:00,987 Epoch[26] Batch [1340]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:08,391 Epoch[26] Batch [1350]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:16,210 Epoch[26] Batch [1360]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:23,989 Epoch[26] Batch [1370]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:32,175 Epoch[26] Batch [1380]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:40,555 Epoch[26] Batch [1390]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:49,039 Epoch[26] Batch [1400]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:55:57,094 Epoch[26] Batch [1410]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:05,121 Epoch[26] Batch [1420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:13,224 Epoch[26] Batch [1430]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:21,112 Epoch[26] Batch [1440]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:29,124 Epoch[26] Batch [1450]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:37,480 Epoch[26] Batch [1460]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:45,489 Epoch[26] Batch [1470]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:53,735 Epoch[26] Batch [1480]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:56:58,635 Epoch[26] Train-FCNLogLoss=nan
2017-07-14 00:56:58,635 Epoch[26] Time cost=1168.081
2017-07-14 00:56:59,970 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.params"
2017-07-14 00:57:03,861 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.states"
2017-07-14 00:57:12,406 Epoch[27] Batch [10]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:57:20,375 Epoch[27] Batch [20]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:57:28,470 Epoch[27] Batch [30]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:57:36,279 Epoch[27] Batch [40]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:57:44,247 Epoch[27] Batch [50]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:57:52,161 Epoch[27] Batch [60]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:00,101 Epoch[27] Batch [70]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:08,123 Epoch[27] Batch [80]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:16,399 Epoch[27] Batch [90]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:24,476 Epoch[27] Batch [100]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:32,691 Epoch[27] Batch [110]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:40,576 Epoch[27] Batch [120]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:48,840 Epoch[27] Batch [130]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:58:56,941 Epoch[27] Batch [140]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:59:05,135 Epoch[27] Batch [150]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:59:13,410 Epoch[27] Batch [160]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:59:21,901 Epoch[27] Batch [170]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:59:30,118 Epoch[27] Batch [180]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:59:38,236 Epoch[27] Batch [190]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:59:46,017 Epoch[27] Batch [200]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 00:59:53,768 Epoch[27] Batch [210]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:01,733 Epoch[27] Batch [220]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:09,507 Epoch[27] Batch [230]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:17,424 Epoch[27] Batch [240]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:25,543 Epoch[27] Batch [250]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:33,461 Epoch[27] Batch [260]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:41,510 Epoch[27] Batch [270]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:49,466 Epoch[27] Batch [280]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:00:57,162 Epoch[27] Batch [290]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:04,695 Epoch[27] Batch [300]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:12,181 Epoch[27] Batch [310]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:19,467 Epoch[27] Batch [320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:26,743 Epoch[27] Batch [330]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:34,160 Epoch[27] Batch [340]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:41,540 Epoch[27] Batch [350]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:49,653 Epoch[27] Batch [360]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:01:57,880 Epoch[27] Batch [370]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:02:05,752 Epoch[27] Batch [380]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:02:13,568 Epoch[27] Batch [390]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:02:21,427 Epoch[27] Batch [400]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:02:29,772 Epoch[27] Batch [410]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:02:37,869 Epoch[27] Batch [420]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:02:46,044 Epoch[27] Batch [430]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:02:54,379 Epoch[27] Batch [440]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:02,224 Epoch[27] Batch [450]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:10,210 Epoch[27] Batch [460]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:18,064 Epoch[27] Batch [470]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:26,301 Epoch[27] Batch [480]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:34,360 Epoch[27] Batch [490]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:42,334 Epoch[27] Batch [500]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:50,363 Epoch[27] Batch [510]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:03:58,469 Epoch[27] Batch [520]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:04:06,676 Epoch[27] Batch [530]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:04:15,022 Epoch[27] Batch [540]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:04:23,583 Epoch[27] Batch [550]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:04:31,780 Epoch[27] Batch [560]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:04:39,908 Epoch[27] Batch [570]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:04:47,890 Epoch[27] Batch [580]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:04:56,143 Epoch[27] Batch [590]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:05:04,147 Epoch[27] Batch [600]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:05:12,318 Epoch[27] Batch [610]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:05:20,547 Epoch[27] Batch [620]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:05:28,651 Epoch[27] Batch [630]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:05:36,792 Epoch[27] Batch [640]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:05:44,937 Epoch[27] Batch [650]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:05:53,083 Epoch[27] Batch [660]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:01,197 Epoch[27] Batch [670]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:09,462 Epoch[27] Batch [680]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:17,549 Epoch[27] Batch [690]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:25,671 Epoch[27] Batch [700]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:33,803 Epoch[27] Batch [710]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:41,706 Epoch[27] Batch [720]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:49,652 Epoch[27] Batch [730]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:06:57,443 Epoch[27] Batch [740]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:07:05,520 Epoch[27] Batch [750]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:07:13,663 Epoch[27] Batch [760]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:07:21,882 Epoch[27] Batch [770]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:07:29,764 Epoch[27] Batch [780]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:07:37,887 Epoch[27] Batch [790]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:07:46,005 Epoch[27] Batch [800]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:07:53,959 Epoch[27] Batch [810]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:02,020 Epoch[27] Batch [820]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:10,000 Epoch[27] Batch [830]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:18,151 Epoch[27] Batch [840]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:26,362 Epoch[27] Batch [850]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:34,428 Epoch[27] Batch [860]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:42,431 Epoch[27] Batch [870]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:50,528 Epoch[27] Batch [880]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:08:58,460 Epoch[27] Batch [890]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:09:06,545 Epoch[27] Batch [900]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:09:14,794 Epoch[27] Batch [910]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:09:23,108 Epoch[27] Batch [920]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:09:31,018 Epoch[27] Batch [930]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:09:39,107 Epoch[27] Batch [940]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:09:46,957 Epoch[27] Batch [950]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:09:55,267 Epoch[27] Batch [960]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:10:03,170 Epoch[27] Batch [970]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:10:11,331 Epoch[27] Batch [980]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:10:19,399 Epoch[27] Batch [990]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:10:27,605 Epoch[27] Batch [1000]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:10:35,736 Epoch[27] Batch [1010]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:10:44,175 Epoch[27] Batch [1020]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:10:52,472 Epoch[27] Batch [1030]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:00,785 Epoch[27] Batch [1040]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:08,631 Epoch[27] Batch [1050]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:16,141 Epoch[27] Batch [1060]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:24,608 Epoch[27] Batch [1070]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:32,766 Epoch[27] Batch [1080]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:40,332 Epoch[27] Batch [1090]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:48,624 Epoch[27] Batch [1100]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:11:56,903 Epoch[27] Batch [1110]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:04,820 Epoch[27] Batch [1120]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:12,116 Epoch[27] Batch [1130]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:19,605 Epoch[27] Batch [1140]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:26,985 Epoch[27] Batch [1150]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:34,996 Epoch[27] Batch [1160]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:43,286 Epoch[27] Batch [1170]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:51,652 Epoch[27] Batch [1180]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:12:59,785 Epoch[27] Batch [1190]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:13:08,006 Epoch[27] Batch [1200]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:13:15,887 Epoch[27] Batch [1210]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:13:24,039 Epoch[27] Batch [1220]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:13:32,327 Epoch[27] Batch [1230]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:13:40,283 Epoch[27] Batch [1240]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:13:48,444 Epoch[27] Batch [1250]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:13:56,405 Epoch[27] Batch [1260]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:14:04,138 Epoch[27] Batch [1270]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:14:12,248 Epoch[27] Batch [1280]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:14:20,609 Epoch[27] Batch [1290]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:14:28,546 Epoch[27] Batch [1300]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:14:36,442 Epoch[27] Batch [1310]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:14:44,611 Epoch[27] Batch [1320]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:14:52,560 Epoch[27] Batch [1330]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:00,344 Epoch[27] Batch [1340]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:08,390 Epoch[27] Batch [1350]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:16,573 Epoch[27] Batch [1360]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:24,459 Epoch[27] Batch [1370]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:31,903 Epoch[27] Batch [1380]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:39,571 Epoch[27] Batch [1390]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:47,008 Epoch[27] Batch [1400]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:15:54,559 Epoch[27] Batch [1410]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:02,088 Epoch[27] Batch [1420]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:09,447 Epoch[27] Batch [1430]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:16,935 Epoch[27] Batch [1440]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:24,471 Epoch[27] Batch [1450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:32,271 Epoch[27] Batch [1460]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:39,741 Epoch[27] Batch [1470]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:47,094 Epoch[27] Batch [1480]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:16:51,684 Epoch[27] Train-FCNLogLoss=nan
2017-07-14 01:16:51,684 Epoch[27] Time cost=1187.823
2017-07-14 01:16:52,783 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.params"
2017-07-14 01:16:56,697 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.states"
2017-07-14 01:17:05,499 Epoch[28] Batch [10]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:17:13,504 Epoch[28] Batch [20]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:17:21,536 Epoch[28] Batch [30]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:17:29,219 Epoch[28] Batch [40]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:17:36,614 Epoch[28] Batch [50]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:17:44,864 Epoch[28] Batch [60]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:17:52,451 Epoch[28] Batch [70]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:00,062 Epoch[28] Batch [80]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:07,519 Epoch[28] Batch [90]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:14,922 Epoch[28] Batch [100]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:22,327 Epoch[28] Batch [110]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:29,405 Epoch[28] Batch [120]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:36,676 Epoch[28] Batch [130]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:44,307 Epoch[28] Batch [140]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:52,018 Epoch[28] Batch [150]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:18:59,341 Epoch[28] Batch [160]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:06,920 Epoch[28] Batch [170]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:14,535 Epoch[28] Batch [180]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:22,132 Epoch[28] Batch [190]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:29,900 Epoch[28] Batch [200]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:37,532 Epoch[28] Batch [210]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:44,960 Epoch[28] Batch [220]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:52,326 Epoch[28] Batch [230]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:19:59,798 Epoch[28] Batch [240]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:07,283 Epoch[28] Batch [250]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:14,852 Epoch[28] Batch [260]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:22,357 Epoch[28] Batch [270]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:29,797 Epoch[28] Batch [280]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:37,195 Epoch[28] Batch [290]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:44,762 Epoch[28] Batch [300]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:52,192 Epoch[28] Batch [310]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:20:59,778 Epoch[28] Batch [320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:07,150 Epoch[28] Batch [330]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:14,593 Epoch[28] Batch [340]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:22,190 Epoch[28] Batch [350]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:29,622 Epoch[28] Batch [360]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:37,172 Epoch[28] Batch [370]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:44,657 Epoch[28] Batch [380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:51,906 Epoch[28] Batch [390]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:21:59,327 Epoch[28] Batch [400]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:06,579 Epoch[28] Batch [410]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:14,013 Epoch[28] Batch [420]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:21,451 Epoch[28] Batch [430]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:28,975 Epoch[28] Batch [440]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:36,514 Epoch[28] Batch [450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:44,098 Epoch[28] Batch [460]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:51,405 Epoch[28] Batch [470]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:22:58,948 Epoch[28] Batch [480]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:06,491 Epoch[28] Batch [490]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:14,001 Epoch[28] Batch [500]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:21,493 Epoch[28] Batch [510]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:29,031 Epoch[28] Batch [520]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:36,575 Epoch[28] Batch [530]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:44,161 Epoch[28] Batch [540]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:51,715 Epoch[28] Batch [550]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:23:59,003 Epoch[28] Batch [560]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:24:06,940 Epoch[28] Batch [570]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:24:14,745 Epoch[28] Batch [580]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:24:22,530 Epoch[28] Batch [590]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:24:30,584 Epoch[28] Batch [600]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:24:38,163 Epoch[28] Batch [610]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:24:45,627 Epoch[28] Batch [620]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:24:53,168 Epoch[28] Batch [630]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:00,514 Epoch[28] Batch [640]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:08,131 Epoch[28] Batch [650]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:15,518 Epoch[28] Batch [660]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:22,861 Epoch[28] Batch [670]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:30,231 Epoch[28] Batch [680]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:37,678 Epoch[28] Batch [690]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:45,056 Epoch[28] Batch [700]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:25:52,659 Epoch[28] Batch [710]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:00,073 Epoch[28] Batch [720]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:07,579 Epoch[28] Batch [730]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:15,645 Epoch[28] Batch [740]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:23,754 Epoch[28] Batch [750]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:31,939 Epoch[28] Batch [760]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:40,019 Epoch[28] Batch [770]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:47,439 Epoch[28] Batch [780]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:26:54,902 Epoch[28] Batch [790]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:02,151 Epoch[28] Batch [800]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:09,570 Epoch[28] Batch [810]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:17,008 Epoch[28] Batch [820]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:24,336 Epoch[28] Batch [830]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:31,637 Epoch[28] Batch [840]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:38,920 Epoch[28] Batch [850]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:46,474 Epoch[28] Batch [860]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:27:53,601 Epoch[28] Batch [870]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:00,978 Epoch[28] Batch [880]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:08,615 Epoch[28] Batch [890]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:16,026 Epoch[28] Batch [900]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:23,547 Epoch[28] Batch [910]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:31,125 Epoch[28] Batch [920]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:38,554 Epoch[28] Batch [930]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:45,882 Epoch[28] Batch [940]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:28:53,363 Epoch[28] Batch [950]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:00,570 Epoch[28] Batch [960]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:07,924 Epoch[28] Batch [970]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:15,612 Epoch[28] Batch [980]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:23,234 Epoch[28] Batch [990]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:30,837 Epoch[28] Batch [1000]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:38,152 Epoch[28] Batch [1010]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:45,598 Epoch[28] Batch [1020]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:29:53,048 Epoch[28] Batch [1030]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:00,298 Epoch[28] Batch [1040]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:07,696 Epoch[28] Batch [1050]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:15,163 Epoch[28] Batch [1060]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:22,848 Epoch[28] Batch [1070]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:30,341 Epoch[28] Batch [1080]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:37,768 Epoch[28] Batch [1090]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:45,144 Epoch[28] Batch [1100]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:30:52,647 Epoch[28] Batch [1110]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:00,058 Epoch[28] Batch [1120]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:07,883 Epoch[28] Batch [1130]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:15,377 Epoch[28] Batch [1140]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:22,797 Epoch[28] Batch [1150]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:30,428 Epoch[28] Batch [1160]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:37,990 Epoch[28] Batch [1170]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:46,208 Epoch[28] Batch [1180]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:31:54,444 Epoch[28] Batch [1190]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:01,752 Epoch[28] Batch [1200]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:09,884 Epoch[28] Batch [1210]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:17,639 Epoch[28] Batch [1220]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:25,849 Epoch[28] Batch [1230]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:33,943 Epoch[28] Batch [1240]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:42,098 Epoch[28] Batch [1250]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:50,259 Epoch[28] Batch [1260]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:32:58,437 Epoch[28] Batch [1270]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:33:05,890 Epoch[28] Batch [1280]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:33:14,149 Epoch[28] Batch [1290]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:33:22,320 Epoch[28] Batch [1300]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:33:30,675 Epoch[28] Batch [1310]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:33:38,924 Epoch[28] Batch [1320]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:33:46,840 Epoch[28] Batch [1330]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:33:54,784 Epoch[28] Batch [1340]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:02,385 Epoch[28] Batch [1350]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:10,043 Epoch[28] Batch [1360]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:17,594 Epoch[28] Batch [1370]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:25,154 Epoch[28] Batch [1380]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:32,396 Epoch[28] Batch [1390]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:40,659 Epoch[28] Batch [1400]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:47,920 Epoch[28] Batch [1410]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:34:55,414 Epoch[28] Batch [1420]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:35:02,848 Epoch[28] Batch [1430]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:35:10,409 Epoch[28] Batch [1440]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:35:18,054 Epoch[28] Batch [1450]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:35:25,510 Epoch[28] Batch [1460]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:35:32,799 Epoch[28] Batch [1470]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:35:40,376 Epoch[28] Batch [1480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:35:44,933 Epoch[28] Train-FCNLogLoss=nan
2017-07-14 01:35:44,934 Epoch[28] Time cost=1128.236
2017-07-14 01:35:46,106 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.params"
2017-07-14 01:35:50,017 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.states"
2017-07-14 01:35:58,696 Epoch[29] Batch [10]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:06,256 Epoch[29] Batch [20]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:13,792 Epoch[29] Batch [30]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:21,373 Epoch[29] Batch [40]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:28,985 Epoch[29] Batch [50]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:36,456 Epoch[29] Batch [60]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:43,954 Epoch[29] Batch [70]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:51,649 Epoch[29] Batch [80]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:36:59,171 Epoch[29] Batch [90]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:37:06,578 Epoch[29] Batch [100]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:37:13,825 Epoch[29] Batch [110]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:37:21,294 Epoch[29] Batch [120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:37:29,328 Epoch[29] Batch [130]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:37:37,328 Epoch[29] Batch [140]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:37:45,490 Epoch[29] Batch [150]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:37:53,457 Epoch[29] Batch [160]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:01,436 Epoch[29] Batch [170]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:09,047 Epoch[29] Batch [180]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:16,477 Epoch[29] Batch [190]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:24,172 Epoch[29] Batch [200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:31,800 Epoch[29] Batch [210]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:39,287 Epoch[29] Batch [220]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:46,835 Epoch[29] Batch [230]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:38:54,413 Epoch[29] Batch [240]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:01,972 Epoch[29] Batch [250]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:09,398 Epoch[29] Batch [260]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:17,051 Epoch[29] Batch [270]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:24,248 Epoch[29] Batch [280]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:31,936 Epoch[29] Batch [290]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:39,316 Epoch[29] Batch [300]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:46,826 Epoch[29] Batch [310]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:39:54,209 Epoch[29] Batch [320]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:01,604 Epoch[29] Batch [330]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:08,812 Epoch[29] Batch [340]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:16,513 Epoch[29] Batch [350]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:24,063 Epoch[29] Batch [360]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:31,620 Epoch[29] Batch [370]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:38,931 Epoch[29] Batch [380]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:46,338 Epoch[29] Batch [390]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:40:53,921 Epoch[29] Batch [400]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:01,570 Epoch[29] Batch [410]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:08,982 Epoch[29] Batch [420]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:16,617 Epoch[29] Batch [430]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:24,599 Epoch[29] Batch [440]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:32,625 Epoch[29] Batch [450]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:40,642 Epoch[29] Batch [460]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:48,541 Epoch[29] Batch [470]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:41:56,127 Epoch[29] Batch [480]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:42:03,587 Epoch[29] Batch [490]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:42:10,929 Epoch[29] Batch [500]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:42:19,142 Epoch[29] Batch [510]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:42:27,363 Epoch[29] Batch [520]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:42:35,384 Epoch[29] Batch [530]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:42:43,822 Epoch[29] Batch [540]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:42:52,431 Epoch[29] Batch [550]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:00,758 Epoch[29] Batch [560]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:08,738 Epoch[29] Batch [570]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:16,981 Epoch[29] Batch [580]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:25,767 Epoch[29] Batch [590]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:33,844 Epoch[29] Batch [600]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:42,047 Epoch[29] Batch [610]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:50,114 Epoch[29] Batch [620]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:43:57,898 Epoch[29] Batch [630]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:05,969 Epoch[29] Batch [640]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:13,928 Epoch[29] Batch [650]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:21,759 Epoch[29] Batch [660]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:29,591 Epoch[29] Batch [670]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:37,432 Epoch[29] Batch [680]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:44,948 Epoch[29] Batch [690]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:52,357 Epoch[29] Batch [700]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:44:59,856 Epoch[29] Batch [710]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:45:07,764 Epoch[29] Batch [720]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:45:15,861 Epoch[29] Batch [730]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:45:23,312 Epoch[29] Batch [740]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:45:30,712 Epoch[29] Batch [750]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:45:38,026 Epoch[29] Batch [760]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:45:45,518 Epoch[29] Batch [770]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:45:52,836 Epoch[29] Batch [780]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:46:00,894 Epoch[29] Batch [790]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:46:09,861 Epoch[29] Batch [800]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:46:18,904 Epoch[29] Batch [810]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:46:27,819 Epoch[29] Batch [820]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:46:36,750 Epoch[29] Batch [830]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:46:45,681 Epoch[29] Batch [840]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:46:54,168 Epoch[29] Batch [850]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:02,434 Epoch[29] Batch [860]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:10,454 Epoch[29] Batch [870]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:18,711 Epoch[29] Batch [880]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:26,632 Epoch[29] Batch [890]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:34,886 Epoch[29] Batch [900]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:43,099 Epoch[29] Batch [910]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:51,072 Epoch[29] Batch [920]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:47:59,141 Epoch[29] Batch [930]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:48:07,365 Epoch[29] Batch [940]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:48:15,366 Epoch[29] Batch [950]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:48:23,394 Epoch[29] Batch [960]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:48:31,663 Epoch[29] Batch [970]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:48:39,558 Epoch[29] Batch [980]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:48:47,809 Epoch[29] Batch [990]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:48:55,894 Epoch[29] Batch [1000]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:49:04,059 Epoch[29] Batch [1010]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:49:12,421 Epoch[29] Batch [1020]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:49:20,931 Epoch[29] Batch [1030]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:49:29,597 Epoch[29] Batch [1040]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:49:37,876 Epoch[29] Batch [1050]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:49:46,652 Epoch[29] Batch [1060]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:49:55,341 Epoch[29] Batch [1070]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:50:03,746 Epoch[29] Batch [1080]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:50:12,191 Epoch[29] Batch [1090]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:50:20,675 Epoch[29] Batch [1100]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:50:29,445 Epoch[29] Batch [1110]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:50:37,221 Epoch[29] Batch [1120]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:50:44,892 Epoch[29] Batch [1130]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:50:53,062 Epoch[29] Batch [1140]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:01,429 Epoch[29] Batch [1150]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:09,987 Epoch[29] Batch [1160]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:18,231 Epoch[29] Batch [1170]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:26,317 Epoch[29] Batch [1180]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:34,654 Epoch[29] Batch [1190]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:42,713 Epoch[29] Batch [1200]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:51,101 Epoch[29] Batch [1210]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:51:59,189 Epoch[29] Batch [1220]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:52:07,538 Epoch[29] Batch [1230]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:52:15,503 Epoch[29] Batch [1240]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:52:23,422 Epoch[29] Batch [1250]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:52:31,415 Epoch[29] Batch [1260]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:52:39,625 Epoch[29] Batch [1270]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:52:47,902 Epoch[29] Batch [1280]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:52:55,838 Epoch[29] Batch [1290]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:04,252 Epoch[29] Batch [1300]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:12,700 Epoch[29] Batch [1310]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:20,414 Epoch[29] Batch [1320]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:28,069 Epoch[29] Batch [1330]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:35,542 Epoch[29] Batch [1340]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:43,419 Epoch[29] Batch [1350]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:51,087 Epoch[29] Batch [1360]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:53:58,754 Epoch[29] Batch [1370]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:54:06,420 Epoch[29] Batch [1380]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:54:13,944 Epoch[29] Batch [1390]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:54:21,446 Epoch[29] Batch [1400]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:54:29,392 Epoch[29] Batch [1410]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:54:38,409 Epoch[29] Batch [1420]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:54:47,002 Epoch[29] Batch [1430]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:54:55,839 Epoch[29] Batch [1440]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:55:04,601 Epoch[29] Batch [1450]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:55:13,509 Epoch[29] Batch [1460]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:55:22,470 Epoch[29] Batch [1470]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:55:31,330 Epoch[29] Batch [1480]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:55:35,840 Epoch[29] Train-FCNLogLoss=nan
2017-07-14 01:55:35,840 Epoch[29] Time cost=1185.822
2017-07-14 01:55:36,952 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.params"
2017-07-14 01:55:40,828 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.states"
2017-07-14 01:55:49,486 Epoch[30] Batch [10]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:55:57,554 Epoch[30] Batch [20]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:56:05,292 Epoch[30] Batch [30]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:56:13,451 Epoch[30] Batch [40]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:56:21,710 Epoch[30] Batch [50]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:56:29,680 Epoch[30] Batch [60]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:56:37,629 Epoch[30] Batch [70]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:56:45,530 Epoch[30] Batch [80]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:56:53,304 Epoch[30] Batch [90]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:01,717 Epoch[30] Batch [100]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:10,097 Epoch[30] Batch [110]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:18,336 Epoch[30] Batch [120]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:26,740 Epoch[30] Batch [130]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:34,936 Epoch[30] Batch [140]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:43,067 Epoch[30] Batch [150]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:51,277 Epoch[30] Batch [160]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:57:59,440 Epoch[30] Batch [170]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:58:07,134 Epoch[30] Batch [180]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:58:15,283 Epoch[30] Batch [190]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:58:22,425 Epoch[30] Batch [200]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:58:29,950 Epoch[30] Batch [210]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:58:37,417 Epoch[30] Batch [220]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:58:45,254 Epoch[30] Batch [230]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:58:52,912 Epoch[30] Batch [240]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:00,575 Epoch[30] Batch [250]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:08,208 Epoch[30] Batch [260]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:15,969 Epoch[30] Batch [270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:23,664 Epoch[30] Batch [280]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:31,368 Epoch[30] Batch [290]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:38,943 Epoch[30] Batch [300]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:46,094 Epoch[30] Batch [310]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 01:59:53,625 Epoch[30] Batch [320]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:01,159 Epoch[30] Batch [330]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:07,750 Epoch[30] Batch [340]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:14,733 Epoch[30] Batch [350]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:21,728 Epoch[30] Batch [360]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:28,919 Epoch[30] Batch [370]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:36,343 Epoch[30] Batch [380]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:43,496 Epoch[30] Batch [390]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:50,729 Epoch[30] Batch [400]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:00:57,762 Epoch[30] Batch [410]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:04,525 Epoch[30] Batch [420]	Speed: 5.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:11,319 Epoch[30] Batch [430]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:18,212 Epoch[30] Batch [440]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:25,216 Epoch[30] Batch [450]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:31,793 Epoch[30] Batch [460]	Speed: 6.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:38,661 Epoch[30] Batch [470]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:45,547 Epoch[30] Batch [480]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:52,772 Epoch[30] Batch [490]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:01:59,476 Epoch[30] Batch [500]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:06,487 Epoch[30] Batch [510]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:13,531 Epoch[30] Batch [520]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:20,552 Epoch[30] Batch [530]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:27,853 Epoch[30] Batch [540]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:35,319 Epoch[30] Batch [550]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:42,665 Epoch[30] Batch [560]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:49,940 Epoch[30] Batch [570]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:02:57,165 Epoch[30] Batch [580]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:04,459 Epoch[30] Batch [590]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:11,613 Epoch[30] Batch [600]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:18,892 Epoch[30] Batch [610]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:26,119 Epoch[30] Batch [620]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:33,337 Epoch[30] Batch [630]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:40,765 Epoch[30] Batch [640]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:47,831 Epoch[30] Batch [650]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:03:55,060 Epoch[30] Batch [660]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:01,941 Epoch[30] Batch [670]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:08,645 Epoch[30] Batch [680]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:15,267 Epoch[30] Batch [690]	Speed: 6.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:22,144 Epoch[30] Batch [700]	Speed: 5.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:29,329 Epoch[30] Batch [710]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:36,597 Epoch[30] Batch [720]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:43,355 Epoch[30] Batch [730]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:50,189 Epoch[30] Batch [740]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:04:57,007 Epoch[30] Batch [750]	Speed: 5.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:04,149 Epoch[30] Batch [760]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:10,693 Epoch[30] Batch [770]	Speed: 6.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:17,698 Epoch[30] Batch [780]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:25,036 Epoch[30] Batch [790]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:32,296 Epoch[30] Batch [800]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:39,463 Epoch[30] Batch [810]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:46,381 Epoch[30] Batch [820]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:05:53,384 Epoch[30] Batch [830]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:00,375 Epoch[30] Batch [840]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:06,970 Epoch[30] Batch [850]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:13,873 Epoch[30] Batch [860]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:20,768 Epoch[30] Batch [870]	Speed: 5.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:27,736 Epoch[30] Batch [880]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:34,846 Epoch[30] Batch [890]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:41,973 Epoch[30] Batch [900]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:49,195 Epoch[30] Batch [910]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:06:56,243 Epoch[30] Batch [920]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:03,438 Epoch[30] Batch [930]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:10,649 Epoch[30] Batch [940]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:17,435 Epoch[30] Batch [950]	Speed: 5.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:24,418 Epoch[30] Batch [960]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:31,068 Epoch[30] Batch [970]	Speed: 6.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:38,070 Epoch[30] Batch [980]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:45,077 Epoch[30] Batch [990]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:52,275 Epoch[30] Batch [1000]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:07:59,435 Epoch[30] Batch [1010]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:06,756 Epoch[30] Batch [1020]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:13,966 Epoch[30] Batch [1030]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:21,186 Epoch[30] Batch [1040]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:28,699 Epoch[30] Batch [1050]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:36,252 Epoch[30] Batch [1060]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:43,638 Epoch[30] Batch [1070]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:51,280 Epoch[30] Batch [1080]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:08:58,681 Epoch[30] Batch [1090]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:06,201 Epoch[30] Batch [1100]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:13,537 Epoch[30] Batch [1110]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:20,782 Epoch[30] Batch [1120]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:28,186 Epoch[30] Batch [1130]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:35,512 Epoch[30] Batch [1140]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:42,925 Epoch[30] Batch [1150]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:50,185 Epoch[30] Batch [1160]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:09:57,728 Epoch[30] Batch [1170]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:04,857 Epoch[30] Batch [1180]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:11,604 Epoch[30] Batch [1190]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:18,991 Epoch[30] Batch [1200]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:26,285 Epoch[30] Batch [1210]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:33,803 Epoch[30] Batch [1220]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:41,104 Epoch[30] Batch [1230]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:48,509 Epoch[30] Batch [1240]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:10:56,711 Epoch[30] Batch [1250]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:04,886 Epoch[30] Batch [1260]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:12,890 Epoch[30] Batch [1270]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:20,949 Epoch[30] Batch [1280]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:28,775 Epoch[30] Batch [1290]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:36,288 Epoch[30] Batch [1300]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:44,572 Epoch[30] Batch [1310]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:52,176 Epoch[30] Batch [1320]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:11:59,507 Epoch[30] Batch [1330]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:12:07,324 Epoch[30] Batch [1340]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:12:15,496 Epoch[30] Batch [1350]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:12:23,646 Epoch[30] Batch [1360]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:12:31,890 Epoch[30] Batch [1370]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:12:39,936 Epoch[30] Batch [1380]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:12:48,508 Epoch[30] Batch [1390]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:12:57,340 Epoch[30] Batch [1400]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:13:04,981 Epoch[30] Batch [1410]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:13:12,852 Epoch[30] Batch [1420]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:13:20,933 Epoch[30] Batch [1430]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:13:28,974 Epoch[30] Batch [1440]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:13:36,382 Epoch[30] Batch [1450]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:13:44,257 Epoch[30] Batch [1460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:13:52,252 Epoch[30] Batch [1470]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:14:00,498 Epoch[30] Batch [1480]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:14:05,385 Epoch[30] Train-FCNLogLoss=nan
2017-07-14 02:14:05,385 Epoch[30] Time cost=1104.557
2017-07-14 02:14:06,430 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.params"
2017-07-14 02:14:10,418 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.states"
2017-07-14 02:14:19,538 Epoch[31] Batch [10]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:14:27,632 Epoch[31] Batch [20]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:14:36,149 Epoch[31] Batch [30]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:14:44,644 Epoch[31] Batch [40]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:14:53,299 Epoch[31] Batch [50]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:02,075 Epoch[31] Batch [60]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:10,724 Epoch[31] Batch [70]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:18,768 Epoch[31] Batch [80]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:26,250 Epoch[31] Batch [90]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:33,878 Epoch[31] Batch [100]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:41,731 Epoch[31] Batch [110]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:49,427 Epoch[31] Batch [120]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:15:57,323 Epoch[31] Batch [130]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:16:05,168 Epoch[31] Batch [140]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:16:12,896 Epoch[31] Batch [150]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:16:20,622 Epoch[31] Batch [160]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:16:28,074 Epoch[31] Batch [170]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:16:35,639 Epoch[31] Batch [180]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:16:43,367 Epoch[31] Batch [190]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:16:51,787 Epoch[31] Batch [200]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:00,375 Epoch[31] Batch [210]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:08,251 Epoch[31] Batch [220]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:16,268 Epoch[31] Batch [230]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:24,504 Epoch[31] Batch [240]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:32,750 Epoch[31] Batch [250]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:40,847 Epoch[31] Batch [260]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:48,769 Epoch[31] Batch [270]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:17:56,841 Epoch[31] Batch [280]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:18:05,162 Epoch[31] Batch [290]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:18:13,332 Epoch[31] Batch [300]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:18:21,513 Epoch[31] Batch [310]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:18:29,752 Epoch[31] Batch [320]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:18:38,041 Epoch[31] Batch [330]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:18:46,081 Epoch[31] Batch [340]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:18:54,208 Epoch[31] Batch [350]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:02,285 Epoch[31] Batch [360]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:10,432 Epoch[31] Batch [370]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:18,779 Epoch[31] Batch [380]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:26,934 Epoch[31] Batch [390]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:34,386 Epoch[31] Batch [400]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:42,340 Epoch[31] Batch [410]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:50,074 Epoch[31] Batch [420]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:19:57,978 Epoch[31] Batch [430]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:20:05,867 Epoch[31] Batch [440]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:20:13,895 Epoch[31] Batch [450]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:20:21,969 Epoch[31] Batch [460]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:20:30,046 Epoch[31] Batch [470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:20:38,106 Epoch[31] Batch [480]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:20:46,101 Epoch[31] Batch [490]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:20:54,274 Epoch[31] Batch [500]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:02,172 Epoch[31] Batch [510]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:10,014 Epoch[31] Batch [520]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:17,837 Epoch[31] Batch [530]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:25,708 Epoch[31] Batch [540]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:33,607 Epoch[31] Batch [550]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:41,362 Epoch[31] Batch [560]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:49,263 Epoch[31] Batch [570]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:21:57,123 Epoch[31] Batch [580]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:22:04,901 Epoch[31] Batch [590]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:22:12,798 Epoch[31] Batch [600]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:22:20,355 Epoch[31] Batch [610]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:22:28,463 Epoch[31] Batch [620]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:22:36,387 Epoch[31] Batch [630]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:22:44,338 Epoch[31] Batch [640]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:22:52,077 Epoch[31] Batch [650]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:00,173 Epoch[31] Batch [660]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:08,172 Epoch[31] Batch [670]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:16,218 Epoch[31] Batch [680]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:24,273 Epoch[31] Batch [690]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:32,130 Epoch[31] Batch [700]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:39,931 Epoch[31] Batch [710]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:47,934 Epoch[31] Batch [720]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:23:55,959 Epoch[31] Batch [730]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:03,606 Epoch[31] Batch [740]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:11,647 Epoch[31] Batch [750]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:19,581 Epoch[31] Batch [760]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:27,619 Epoch[31] Batch [770]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:35,854 Epoch[31] Batch [780]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:43,953 Epoch[31] Batch [790]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:51,806 Epoch[31] Batch [800]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:24:59,504 Epoch[31] Batch [810]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:07,159 Epoch[31] Batch [820]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:14,741 Epoch[31] Batch [830]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:22,174 Epoch[31] Batch [840]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:29,523 Epoch[31] Batch [850]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:36,867 Epoch[31] Batch [860]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:44,151 Epoch[31] Batch [870]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:51,683 Epoch[31] Batch [880]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:25:59,047 Epoch[31] Batch [890]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:26:06,432 Epoch[31] Batch [900]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:26:13,983 Epoch[31] Batch [910]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:26:21,914 Epoch[31] Batch [920]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:26:29,685 Epoch[31] Batch [930]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:26:37,960 Epoch[31] Batch [940]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:26:46,240 Epoch[31] Batch [950]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:26:54,237 Epoch[31] Batch [960]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:02,659 Epoch[31] Batch [970]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:10,648 Epoch[31] Batch [980]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:18,244 Epoch[31] Batch [990]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:26,092 Epoch[31] Batch [1000]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:33,809 Epoch[31] Batch [1010]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:42,193 Epoch[31] Batch [1020]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:49,832 Epoch[31] Batch [1030]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:27:57,591 Epoch[31] Batch [1040]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:28:05,392 Epoch[31] Batch [1050]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:28:13,788 Epoch[31] Batch [1060]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:28:22,215 Epoch[31] Batch [1070]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:28:29,821 Epoch[31] Batch [1080]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:28:37,145 Epoch[31] Batch [1090]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:28:45,773 Epoch[31] Batch [1100]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:28:54,653 Epoch[31] Batch [1110]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:02,373 Epoch[31] Batch [1120]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:10,735 Epoch[31] Batch [1130]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:18,325 Epoch[31] Batch [1140]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:25,794 Epoch[31] Batch [1150]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:33,586 Epoch[31] Batch [1160]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:41,561 Epoch[31] Batch [1170]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:49,723 Epoch[31] Batch [1180]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:29:57,925 Epoch[31] Batch [1190]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:05,890 Epoch[31] Batch [1200]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:13,589 Epoch[31] Batch [1210]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:20,937 Epoch[31] Batch [1220]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:28,450 Epoch[31] Batch [1230]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:35,814 Epoch[31] Batch [1240]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:43,397 Epoch[31] Batch [1250]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:50,860 Epoch[31] Batch [1260]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:30:59,040 Epoch[31] Batch [1270]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:31:06,904 Epoch[31] Batch [1280]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:31:14,609 Epoch[31] Batch [1290]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:31:22,708 Epoch[31] Batch [1300]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:31:30,968 Epoch[31] Batch [1310]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:31:39,036 Epoch[31] Batch [1320]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:31:47,125 Epoch[31] Batch [1330]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:31:55,030 Epoch[31] Batch [1340]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:32:03,171 Epoch[31] Batch [1350]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:32:11,409 Epoch[31] Batch [1360]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:32:19,641 Epoch[31] Batch [1370]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:32:27,730 Epoch[31] Batch [1380]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:32:35,742 Epoch[31] Batch [1390]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:32:43,828 Epoch[31] Batch [1400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:32:51,932 Epoch[31] Batch [1410]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:00,051 Epoch[31] Batch [1420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:08,201 Epoch[31] Batch [1430]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:16,287 Epoch[31] Batch [1440]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:24,395 Epoch[31] Batch [1450]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:32,122 Epoch[31] Batch [1460]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:39,622 Epoch[31] Batch [1470]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:47,080 Epoch[31] Batch [1480]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:33:51,757 Epoch[31] Train-FCNLogLoss=nan
2017-07-14 02:33:51,758 Epoch[31] Time cost=1181.340
2017-07-14 02:33:52,944 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.params"
2017-07-14 02:33:56,895 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.states"
2017-07-14 02:34:05,480 Epoch[32] Batch [10]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:34:12,922 Epoch[32] Batch [20]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:34:20,514 Epoch[32] Batch [30]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:34:27,771 Epoch[32] Batch [40]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:34:35,172 Epoch[32] Batch [50]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:34:42,556 Epoch[32] Batch [60]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:34:50,029 Epoch[32] Batch [70]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:34:57,570 Epoch[32] Batch [80]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:05,236 Epoch[32] Batch [90]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:12,587 Epoch[32] Batch [100]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:20,185 Epoch[32] Batch [110]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:27,566 Epoch[32] Batch [120]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:34,653 Epoch[32] Batch [130]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:42,127 Epoch[32] Batch [140]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:49,506 Epoch[32] Batch [150]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:35:56,940 Epoch[32] Batch [160]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:04,600 Epoch[32] Batch [170]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:12,084 Epoch[32] Batch [180]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:19,652 Epoch[32] Batch [190]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:27,164 Epoch[32] Batch [200]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:34,360 Epoch[32] Batch [210]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:41,760 Epoch[32] Batch [220]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:49,139 Epoch[32] Batch [230]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:36:56,445 Epoch[32] Batch [240]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:04,081 Epoch[32] Batch [250]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:11,540 Epoch[32] Batch [260]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:18,955 Epoch[32] Batch [270]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:26,329 Epoch[32] Batch [280]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:33,913 Epoch[32] Batch [290]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:41,493 Epoch[32] Batch [300]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:49,044 Epoch[32] Batch [310]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:37:56,607 Epoch[32] Batch [320]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:04,038 Epoch[32] Batch [330]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:11,789 Epoch[32] Batch [340]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:19,582 Epoch[32] Batch [350]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:27,035 Epoch[32] Batch [360]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:34,502 Epoch[32] Batch [370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:41,925 Epoch[32] Batch [380]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:49,358 Epoch[32] Batch [390]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:38:57,683 Epoch[32] Batch [400]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:39:06,008 Epoch[32] Batch [410]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:39:13,573 Epoch[32] Batch [420]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:39:21,185 Epoch[32] Batch [430]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:39:29,221 Epoch[32] Batch [440]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:39:37,290 Epoch[32] Batch [450]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:39:45,184 Epoch[32] Batch [460]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:39:53,667 Epoch[32] Batch [470]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:02,453 Epoch[32] Batch [480]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:11,179 Epoch[32] Batch [490]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:19,920 Epoch[32] Batch [500]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:28,497 Epoch[32] Batch [510]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:36,426 Epoch[32] Batch [520]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:44,051 Epoch[32] Batch [530]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:51,486 Epoch[32] Batch [540]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:40:59,043 Epoch[32] Batch [550]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:41:06,813 Epoch[32] Batch [560]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:41:14,792 Epoch[32] Batch [570]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:41:22,918 Epoch[32] Batch [580]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:41:31,040 Epoch[32] Batch [590]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:41:39,023 Epoch[32] Batch [600]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:41:46,823 Epoch[32] Batch [610]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:41:54,859 Epoch[32] Batch [620]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:02,909 Epoch[32] Batch [630]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:10,771 Epoch[32] Batch [640]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:19,131 Epoch[32] Batch [650]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:27,207 Epoch[32] Batch [660]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:35,534 Epoch[32] Batch [670]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:43,428 Epoch[32] Batch [680]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:51,530 Epoch[32] Batch [690]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:42:59,630 Epoch[32] Batch [700]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:43:07,762 Epoch[32] Batch [710]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:43:15,838 Epoch[32] Batch [720]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:43:23,579 Epoch[32] Batch [730]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:43:31,680 Epoch[32] Batch [740]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:43:39,716 Epoch[32] Batch [750]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:43:47,981 Epoch[32] Batch [760]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:43:56,376 Epoch[32] Batch [770]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:44:04,709 Epoch[32] Batch [780]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:44:13,025 Epoch[32] Batch [790]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:44:21,288 Epoch[32] Batch [800]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:44:29,850 Epoch[32] Batch [810]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:44:38,333 Epoch[32] Batch [820]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:44:46,725 Epoch[32] Batch [830]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:44:55,011 Epoch[32] Batch [840]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:03,027 Epoch[32] Batch [850]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:11,190 Epoch[32] Batch [860]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:19,045 Epoch[32] Batch [870]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:27,220 Epoch[32] Batch [880]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:34,927 Epoch[32] Batch [890]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:43,427 Epoch[32] Batch [900]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:51,605 Epoch[32] Batch [910]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:45:59,531 Epoch[32] Batch [920]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:46:08,264 Epoch[32] Batch [930]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:46:16,920 Epoch[32] Batch [940]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:46:24,452 Epoch[32] Batch [950]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:46:31,800 Epoch[32] Batch [960]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:46:39,171 Epoch[32] Batch [970]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:46:46,173 Epoch[32] Batch [980]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:46:53,701 Epoch[32] Batch [990]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:00,694 Epoch[32] Batch [1000]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:08,283 Epoch[32] Batch [1010]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:15,723 Epoch[32] Batch [1020]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:23,079 Epoch[32] Batch [1030]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:30,673 Epoch[32] Batch [1040]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:38,099 Epoch[32] Batch [1050]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:45,502 Epoch[32] Batch [1060]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:47:52,666 Epoch[32] Batch [1070]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:00,254 Epoch[32] Batch [1080]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:07,396 Epoch[32] Batch [1090]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:15,036 Epoch[32] Batch [1100]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:22,516 Epoch[32] Batch [1110]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:29,887 Epoch[32] Batch [1120]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:37,152 Epoch[32] Batch [1130]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:44,703 Epoch[32] Batch [1140]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:52,104 Epoch[32] Batch [1150]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:48:59,850 Epoch[32] Batch [1160]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:49:07,568 Epoch[32] Batch [1170]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:49:15,136 Epoch[32] Batch [1180]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:49:22,717 Epoch[32] Batch [1190]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:49:30,239 Epoch[32] Batch [1200]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:49:37,684 Epoch[32] Batch [1210]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:49:45,209 Epoch[32] Batch [1220]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:49:52,703 Epoch[32] Batch [1230]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:00,165 Epoch[32] Batch [1240]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:07,475 Epoch[32] Batch [1250]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:14,969 Epoch[32] Batch [1260]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:22,657 Epoch[32] Batch [1270]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:30,112 Epoch[32] Batch [1280]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:37,573 Epoch[32] Batch [1290]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:45,039 Epoch[32] Batch [1300]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:50:52,503 Epoch[32] Batch [1310]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:00,076 Epoch[32] Batch [1320]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:07,262 Epoch[32] Batch [1330]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:14,776 Epoch[32] Batch [1340]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:23,279 Epoch[32] Batch [1350]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:31,530 Epoch[32] Batch [1360]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:39,625 Epoch[32] Batch [1370]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:47,946 Epoch[32] Batch [1380]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:51:55,953 Epoch[32] Batch [1390]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:52:04,763 Epoch[32] Batch [1400]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:52:13,471 Epoch[32] Batch [1410]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:52:22,281 Epoch[32] Batch [1420]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:52:31,064 Epoch[32] Batch [1430]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:52:40,026 Epoch[32] Batch [1440]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:52:48,835 Epoch[32] Batch [1450]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:52:56,985 Epoch[32] Batch [1460]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:53:05,000 Epoch[32] Batch [1470]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:53:12,831 Epoch[32] Batch [1480]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:53:17,652 Epoch[32] Train-FCNLogLoss=nan
2017-07-14 02:53:17,652 Epoch[32] Time cost=1160.757
2017-07-14 02:53:18,802 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.params"
2017-07-14 02:53:22,723 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.states"
2017-07-14 02:53:32,271 Epoch[33] Batch [10]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:53:40,687 Epoch[33] Batch [20]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:53:48,488 Epoch[33] Batch [30]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:53:56,934 Epoch[33] Batch [40]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:05,046 Epoch[33] Batch [50]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:12,954 Epoch[33] Batch [60]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:20,676 Epoch[33] Batch [70]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:27,870 Epoch[33] Batch [80]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:35,225 Epoch[33] Batch [90]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:42,614 Epoch[33] Batch [100]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:50,412 Epoch[33] Batch [110]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:54:57,946 Epoch[33] Batch [120]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:05,779 Epoch[33] Batch [130]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:13,719 Epoch[33] Batch [140]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:21,587 Epoch[33] Batch [150]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:29,500 Epoch[33] Batch [160]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:37,188 Epoch[33] Batch [170]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:45,188 Epoch[33] Batch [180]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:52,639 Epoch[33] Batch [190]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:55:59,864 Epoch[33] Batch [200]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:56:06,985 Epoch[33] Batch [210]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:56:14,703 Epoch[33] Batch [220]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:56:21,904 Epoch[33] Batch [230]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:56:29,263 Epoch[33] Batch [240]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:56:36,614 Epoch[33] Batch [250]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:56:44,299 Epoch[33] Batch [260]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:56:52,233 Epoch[33] Batch [270]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:00,177 Epoch[33] Batch [280]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:08,177 Epoch[33] Batch [290]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:16,267 Epoch[33] Batch [300]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:24,257 Epoch[33] Batch [310]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:32,274 Epoch[33] Batch [320]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:40,683 Epoch[33] Batch [330]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:48,929 Epoch[33] Batch [340]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:57:56,566 Epoch[33] Batch [350]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:58:04,687 Epoch[33] Batch [360]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:58:12,768 Epoch[33] Batch [370]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:58:20,974 Epoch[33] Batch [380]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:58:29,116 Epoch[33] Batch [390]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:58:37,139 Epoch[33] Batch [400]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:58:45,230 Epoch[33] Batch [410]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:58:53,177 Epoch[33] Batch [420]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:01,074 Epoch[33] Batch [430]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:09,083 Epoch[33] Batch [440]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:17,050 Epoch[33] Batch [450]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:25,032 Epoch[33] Batch [460]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:32,980 Epoch[33] Batch [470]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:40,947 Epoch[33] Batch [480]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:49,213 Epoch[33] Batch [490]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 02:59:57,390 Epoch[33] Batch [500]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:00:05,635 Epoch[33] Batch [510]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:00:13,839 Epoch[33] Batch [520]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:00:21,867 Epoch[33] Batch [530]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:00:29,868 Epoch[33] Batch [540]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:00:38,035 Epoch[33] Batch [550]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:00:45,914 Epoch[33] Batch [560]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:00:53,834 Epoch[33] Batch [570]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:01,946 Epoch[33] Batch [580]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:09,894 Epoch[33] Batch [590]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:17,982 Epoch[33] Batch [600]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:25,731 Epoch[33] Batch [610]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:33,099 Epoch[33] Batch [620]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:40,455 Epoch[33] Batch [630]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:47,939 Epoch[33] Batch [640]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:01:55,293 Epoch[33] Batch [650]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:02,659 Epoch[33] Batch [660]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:10,170 Epoch[33] Batch [670]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:17,691 Epoch[33] Batch [680]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:24,955 Epoch[33] Batch [690]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:32,507 Epoch[33] Batch [700]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:39,801 Epoch[33] Batch [710]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:47,299 Epoch[33] Batch [720]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:02:54,843 Epoch[33] Batch [730]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:02,998 Epoch[33] Batch [740]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:11,099 Epoch[33] Batch [750]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:19,216 Epoch[33] Batch [760]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:27,341 Epoch[33] Batch [770]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:35,305 Epoch[33] Batch [780]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:43,285 Epoch[33] Batch [790]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:51,473 Epoch[33] Batch [800]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:03:59,603 Epoch[33] Batch [810]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:04:07,756 Epoch[33] Batch [820]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:04:15,723 Epoch[33] Batch [830]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:04:23,852 Epoch[33] Batch [840]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:04:32,023 Epoch[33] Batch [850]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:04:39,885 Epoch[33] Batch [860]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:04:47,897 Epoch[33] Batch [870]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:04:55,968 Epoch[33] Batch [880]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:04,004 Epoch[33] Batch [890]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:11,670 Epoch[33] Batch [900]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:19,606 Epoch[33] Batch [910]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:27,593 Epoch[33] Batch [920]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:35,486 Epoch[33] Batch [930]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:43,530 Epoch[33] Batch [940]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:51,735 Epoch[33] Batch [950]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:05:59,386 Epoch[33] Batch [960]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:06:07,339 Epoch[33] Batch [970]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:06:15,446 Epoch[33] Batch [980]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:06:23,565 Epoch[33] Batch [990]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:06:31,712 Epoch[33] Batch [1000]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:06:39,616 Epoch[33] Batch [1010]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:06:47,533 Epoch[33] Batch [1020]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:06:55,795 Epoch[33] Batch [1030]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:07:03,900 Epoch[33] Batch [1040]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:07:12,156 Epoch[33] Batch [1050]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:07:20,512 Epoch[33] Batch [1060]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:07:28,759 Epoch[33] Batch [1070]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:07:37,060 Epoch[33] Batch [1080]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:07:45,148 Epoch[33] Batch [1090]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:07:53,059 Epoch[33] Batch [1100]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:00,954 Epoch[33] Batch [1110]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:09,182 Epoch[33] Batch [1120]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:17,310 Epoch[33] Batch [1130]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:25,167 Epoch[33] Batch [1140]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:33,064 Epoch[33] Batch [1150]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:40,887 Epoch[33] Batch [1160]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:48,595 Epoch[33] Batch [1170]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:08:56,545 Epoch[33] Batch [1180]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:09:04,272 Epoch[33] Batch [1190]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:09:12,483 Epoch[33] Batch [1200]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:09:20,752 Epoch[33] Batch [1210]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:09:29,018 Epoch[33] Batch [1220]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:09:37,362 Epoch[33] Batch [1230]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:09:45,567 Epoch[33] Batch [1240]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:09:54,161 Epoch[33] Batch [1250]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:02,112 Epoch[33] Batch [1260]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:09,674 Epoch[33] Batch [1270]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:17,278 Epoch[33] Batch [1280]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:25,017 Epoch[33] Batch [1290]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:33,133 Epoch[33] Batch [1300]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:40,735 Epoch[33] Batch [1310]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:49,016 Epoch[33] Batch [1320]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:10:57,011 Epoch[33] Batch [1330]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:11:05,006 Epoch[33] Batch [1340]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:11:13,056 Epoch[33] Batch [1350]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:11:21,029 Epoch[33] Batch [1360]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:11:29,098 Epoch[33] Batch [1370]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:11:36,793 Epoch[33] Batch [1380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:11:44,972 Epoch[33] Batch [1390]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:11:53,045 Epoch[33] Batch [1400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:01,191 Epoch[33] Batch [1410]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:09,303 Epoch[33] Batch [1420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:17,241 Epoch[33] Batch [1430]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:25,198 Epoch[33] Batch [1440]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:33,326 Epoch[33] Batch [1450]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:41,223 Epoch[33] Batch [1460]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:48,951 Epoch[33] Batch [1470]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:12:57,193 Epoch[33] Batch [1480]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:13:02,062 Epoch[33] Train-FCNLogLoss=nan
2017-07-14 03:13:02,062 Epoch[33] Time cost=1179.338
2017-07-14 03:13:03,122 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.params"
2017-07-14 03:13:07,129 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.states"
2017-07-14 03:13:15,654 Epoch[34] Batch [10]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:13:23,177 Epoch[34] Batch [20]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:13:30,424 Epoch[34] Batch [30]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:13:38,046 Epoch[34] Batch [40]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:13:45,447 Epoch[34] Batch [50]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:13:52,920 Epoch[34] Batch [60]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:00,193 Epoch[34] Batch [70]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:07,546 Epoch[34] Batch [80]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:15,140 Epoch[34] Batch [90]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:22,385 Epoch[34] Batch [100]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:29,509 Epoch[34] Batch [110]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:36,790 Epoch[34] Batch [120]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:44,433 Epoch[34] Batch [130]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:51,814 Epoch[34] Batch [140]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:14:58,979 Epoch[34] Batch [150]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:06,429 Epoch[34] Batch [160]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:13,956 Epoch[34] Batch [170]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:21,530 Epoch[34] Batch [180]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:28,926 Epoch[34] Batch [190]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:36,478 Epoch[34] Batch [200]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:43,911 Epoch[34] Batch [210]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:51,242 Epoch[34] Batch [220]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:15:58,638 Epoch[34] Batch [230]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:06,122 Epoch[34] Batch [240]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:13,218 Epoch[34] Batch [250]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:20,532 Epoch[34] Batch [260]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:28,160 Epoch[34] Batch [270]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:35,226 Epoch[34] Batch [280]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:42,825 Epoch[34] Batch [290]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:50,082 Epoch[34] Batch [300]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:16:57,748 Epoch[34] Batch [310]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:17:05,134 Epoch[34] Batch [320]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:17:12,727 Epoch[34] Batch [330]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:17:20,581 Epoch[34] Batch [340]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:17:28,622 Epoch[34] Batch [350]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:17:36,875 Epoch[34] Batch [360]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:17:45,202 Epoch[34] Batch [370]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:17:54,024 Epoch[34] Batch [380]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:02,439 Epoch[34] Batch [390]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:11,202 Epoch[34] Batch [400]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:19,955 Epoch[34] Batch [410]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:28,142 Epoch[34] Batch [420]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:36,306 Epoch[34] Batch [430]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:44,056 Epoch[34] Batch [440]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:51,391 Epoch[34] Batch [450]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:18:59,619 Epoch[34] Batch [460]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:19:08,030 Epoch[34] Batch [470]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:19:16,306 Epoch[34] Batch [480]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:19:24,327 Epoch[34] Batch [490]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:19:32,373 Epoch[34] Batch [500]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:19:40,055 Epoch[34] Batch [510]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:19:47,597 Epoch[34] Batch [520]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:19:54,881 Epoch[34] Batch [530]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:02,175 Epoch[34] Batch [540]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:09,646 Epoch[34] Batch [550]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:17,179 Epoch[34] Batch [560]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:24,587 Epoch[34] Batch [570]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:32,030 Epoch[34] Batch [580]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:39,336 Epoch[34] Batch [590]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:47,183 Epoch[34] Batch [600]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:20:54,808 Epoch[34] Batch [610]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:02,309 Epoch[34] Batch [620]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:09,987 Epoch[34] Batch [630]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:17,481 Epoch[34] Batch [640]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:24,775 Epoch[34] Batch [650]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:32,304 Epoch[34] Batch [660]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:39,894 Epoch[34] Batch [670]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:47,413 Epoch[34] Batch [680]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:21:55,185 Epoch[34] Batch [690]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:22:02,542 Epoch[34] Batch [700]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:22:10,487 Epoch[34] Batch [710]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:22:18,050 Epoch[34] Batch [720]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:22:26,408 Epoch[34] Batch [730]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:22:35,228 Epoch[34] Batch [740]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:22:43,835 Epoch[34] Batch [750]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:22:52,518 Epoch[34] Batch [760]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:23:01,040 Epoch[34] Batch [770]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:23:09,606 Epoch[34] Batch [780]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:23:18,109 Epoch[34] Batch [790]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:23:26,882 Epoch[34] Batch [800]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:23:35,388 Epoch[34] Batch [810]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:23:44,026 Epoch[34] Batch [820]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:23:53,007 Epoch[34] Batch [830]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:01,099 Epoch[34] Batch [840]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:09,037 Epoch[34] Batch [850]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:17,160 Epoch[34] Batch [860]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:24,905 Epoch[34] Batch [870]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:32,297 Epoch[34] Batch [880]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:39,507 Epoch[34] Batch [890]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:46,846 Epoch[34] Batch [900]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:24:54,467 Epoch[34] Batch [910]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:01,640 Epoch[34] Batch [920]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:09,080 Epoch[34] Batch [930]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:16,514 Epoch[34] Batch [940]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:23,829 Epoch[34] Batch [950]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:31,162 Epoch[34] Batch [960]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:38,441 Epoch[34] Batch [970]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:45,899 Epoch[34] Batch [980]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:25:53,370 Epoch[34] Batch [990]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:00,697 Epoch[34] Batch [1000]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:08,134 Epoch[34] Batch [1010]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:15,493 Epoch[34] Batch [1020]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:22,926 Epoch[34] Batch [1030]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:30,326 Epoch[34] Batch [1040]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:37,603 Epoch[34] Batch [1050]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:44,855 Epoch[34] Batch [1060]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:52,396 Epoch[34] Batch [1070]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:26:59,897 Epoch[34] Batch [1080]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:27:07,306 Epoch[34] Batch [1090]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:27:14,818 Epoch[34] Batch [1100]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:27:22,104 Epoch[34] Batch [1110]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:27:29,645 Epoch[34] Batch [1120]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:27:37,525 Epoch[34] Batch [1130]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:27:45,904 Epoch[34] Batch [1140]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:27:53,664 Epoch[34] Batch [1150]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:01,062 Epoch[34] Batch [1160]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:08,632 Epoch[34] Batch [1170]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:16,759 Epoch[34] Batch [1180]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:25,003 Epoch[34] Batch [1190]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:32,897 Epoch[34] Batch [1200]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:41,127 Epoch[34] Batch [1210]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:49,357 Epoch[34] Batch [1220]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:28:57,188 Epoch[34] Batch [1230]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:29:05,499 Epoch[34] Batch [1240]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:29:13,377 Epoch[34] Batch [1250]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:29:21,694 Epoch[34] Batch [1260]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:29:29,656 Epoch[34] Batch [1270]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:29:38,047 Epoch[34] Batch [1280]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:29:46,166 Epoch[34] Batch [1290]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:29:53,987 Epoch[34] Batch [1300]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:01,739 Epoch[34] Batch [1310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:09,767 Epoch[34] Batch [1320]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:18,109 Epoch[34] Batch [1330]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:26,251 Epoch[34] Batch [1340]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:34,098 Epoch[34] Batch [1350]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:42,289 Epoch[34] Batch [1360]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:50,071 Epoch[34] Batch [1370]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:30:57,973 Epoch[34] Batch [1380]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:31:06,170 Epoch[34] Batch [1390]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:31:14,013 Epoch[34] Batch [1400]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:31:22,279 Epoch[34] Batch [1410]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:31:30,391 Epoch[34] Batch [1420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:31:38,233 Epoch[34] Batch [1430]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:31:46,409 Epoch[34] Batch [1440]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:31:54,647 Epoch[34] Batch [1450]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:32:02,740 Epoch[34] Batch [1460]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:32:10,664 Epoch[34] Batch [1470]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:32:18,730 Epoch[34] Batch [1480]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:32:23,240 Epoch[34] Train-FCNLogLoss=nan
2017-07-14 03:32:23,240 Epoch[34] Time cost=1156.110
2017-07-14 03:32:24,273 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.params"
2017-07-14 03:32:28,154 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.states"
2017-07-14 03:32:37,186 Epoch[35] Batch [10]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:32:45,560 Epoch[35] Batch [20]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:32:53,694 Epoch[35] Batch [30]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:01,887 Epoch[35] Batch [40]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:09,876 Epoch[35] Batch [50]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:18,007 Epoch[35] Batch [60]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:26,040 Epoch[35] Batch [70]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:34,017 Epoch[35] Batch [80]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:42,334 Epoch[35] Batch [90]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:50,682 Epoch[35] Batch [100]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:33:58,289 Epoch[35] Batch [110]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:05,572 Epoch[35] Batch [120]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:12,802 Epoch[35] Batch [130]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:19,994 Epoch[35] Batch [140]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:27,579 Epoch[35] Batch [150]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:34,971 Epoch[35] Batch [160]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:42,568 Epoch[35] Batch [170]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:50,048 Epoch[35] Batch [180]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:34:57,559 Epoch[35] Batch [190]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:04,968 Epoch[35] Batch [200]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:12,265 Epoch[35] Batch [210]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:19,736 Epoch[35] Batch [220]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:27,144 Epoch[35] Batch [230]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:34,718 Epoch[35] Batch [240]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:42,369 Epoch[35] Batch [250]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:49,872 Epoch[35] Batch [260]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:35:57,481 Epoch[35] Batch [270]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:05,060 Epoch[35] Batch [280]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:12,307 Epoch[35] Batch [290]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:19,764 Epoch[35] Batch [300]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:27,129 Epoch[35] Batch [310]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:34,601 Epoch[35] Batch [320]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:41,838 Epoch[35] Batch [330]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:49,358 Epoch[35] Batch [340]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:36:57,031 Epoch[35] Batch [350]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:04,636 Epoch[35] Batch [360]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:11,902 Epoch[35] Batch [370]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:19,219 Epoch[35] Batch [380]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:26,839 Epoch[35] Batch [390]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:34,331 Epoch[35] Batch [400]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:41,817 Epoch[35] Batch [410]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:49,295 Epoch[35] Batch [420]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:37:56,460 Epoch[35] Batch [430]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:03,943 Epoch[35] Batch [440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:11,219 Epoch[35] Batch [450]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:18,629 Epoch[35] Batch [460]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:26,047 Epoch[35] Batch [470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:33,564 Epoch[35] Batch [480]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:41,198 Epoch[35] Batch [490]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:48,767 Epoch[35] Batch [500]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:38:56,094 Epoch[35] Batch [510]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:03,507 Epoch[35] Batch [520]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:10,747 Epoch[35] Batch [530]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:18,223 Epoch[35] Batch [540]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:25,743 Epoch[35] Batch [550]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:33,058 Epoch[35] Batch [560]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:40,483 Epoch[35] Batch [570]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:47,718 Epoch[35] Batch [580]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:39:55,231 Epoch[35] Batch [590]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:02,610 Epoch[35] Batch [600]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:10,118 Epoch[35] Batch [610]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:17,479 Epoch[35] Batch [620]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:24,815 Epoch[35] Batch [630]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:32,393 Epoch[35] Batch [640]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:40,005 Epoch[35] Batch [650]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:47,554 Epoch[35] Batch [660]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:40:54,982 Epoch[35] Batch [670]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:02,385 Epoch[35] Batch [680]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:09,456 Epoch[35] Batch [690]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:16,839 Epoch[35] Batch [700]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:24,320 Epoch[35] Batch [710]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:31,604 Epoch[35] Batch [720]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:38,969 Epoch[35] Batch [730]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:46,407 Epoch[35] Batch [740]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:41:53,862 Epoch[35] Batch [750]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:01,355 Epoch[35] Batch [760]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:08,655 Epoch[35] Batch [770]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:15,923 Epoch[35] Batch [780]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:23,456 Epoch[35] Batch [790]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:30,859 Epoch[35] Batch [800]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:37,978 Epoch[35] Batch [810]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:45,526 Epoch[35] Batch [820]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:42:53,506 Epoch[35] Batch [830]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:01,497 Epoch[35] Batch [840]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:09,357 Epoch[35] Batch [850]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:17,441 Epoch[35] Batch [860]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:25,793 Epoch[35] Batch [870]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:34,078 Epoch[35] Batch [880]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:41,931 Epoch[35] Batch [890]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:49,666 Epoch[35] Batch [900]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:43:57,891 Epoch[35] Batch [910]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:44:05,567 Epoch[35] Batch [920]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:44:13,199 Epoch[35] Batch [930]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:44:20,459 Epoch[35] Batch [940]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:44:28,818 Epoch[35] Batch [950]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:44:36,871 Epoch[35] Batch [960]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:44:44,993 Epoch[35] Batch [970]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:44:53,066 Epoch[35] Batch [980]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:00,935 Epoch[35] Batch [990]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:09,049 Epoch[35] Batch [1000]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:17,245 Epoch[35] Batch [1010]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:25,062 Epoch[35] Batch [1020]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:32,676 Epoch[35] Batch [1030]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:40,181 Epoch[35] Batch [1040]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:47,738 Epoch[35] Batch [1050]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:45:55,938 Epoch[35] Batch [1060]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:04,300 Epoch[35] Batch [1070]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:12,065 Epoch[35] Batch [1080]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:19,295 Epoch[35] Batch [1090]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:27,613 Epoch[35] Batch [1100]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:35,645 Epoch[35] Batch [1110]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:43,256 Epoch[35] Batch [1120]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:50,715 Epoch[35] Batch [1130]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:46:58,131 Epoch[35] Batch [1140]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:47:05,564 Epoch[35] Batch [1150]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:47:12,999 Epoch[35] Batch [1160]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:47:20,170 Epoch[35] Batch [1170]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:47:27,559 Epoch[35] Batch [1180]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:47:35,176 Epoch[35] Batch [1190]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:47:43,824 Epoch[35] Batch [1200]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:47:52,340 Epoch[35] Batch [1210]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:00,439 Epoch[35] Batch [1220]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:08,788 Epoch[35] Batch [1230]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:17,167 Epoch[35] Batch [1240]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:25,371 Epoch[35] Batch [1250]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:33,755 Epoch[35] Batch [1260]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:41,507 Epoch[35] Batch [1270]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:48,988 Epoch[35] Batch [1280]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:48:57,161 Epoch[35] Batch [1290]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:04,848 Epoch[35] Batch [1300]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:12,251 Epoch[35] Batch [1310]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:19,553 Epoch[35] Batch [1320]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:26,830 Epoch[35] Batch [1330]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:34,235 Epoch[35] Batch [1340]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:41,691 Epoch[35] Batch [1350]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:49,217 Epoch[35] Batch [1360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:49:57,087 Epoch[35] Batch [1370]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:05,313 Epoch[35] Batch [1380]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:12,850 Epoch[35] Batch [1390]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:20,704 Epoch[35] Batch [1400]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:27,895 Epoch[35] Batch [1410]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:35,830 Epoch[35] Batch [1420]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:43,472 Epoch[35] Batch [1430]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:51,449 Epoch[35] Batch [1440]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:50:59,533 Epoch[35] Batch [1450]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:51:07,578 Epoch[35] Batch [1460]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:51:15,833 Epoch[35] Batch [1470]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:51:23,521 Epoch[35] Batch [1480]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:51:28,947 Epoch[35] Train-FCNLogLoss=nan
2017-07-14 03:51:28,947 Epoch[35] Time cost=1140.792
2017-07-14 03:51:29,992 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.params"
2017-07-14 03:51:34,040 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.states"
2017-07-14 03:51:42,911 Epoch[36] Batch [10]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:51:50,759 Epoch[36] Batch [20]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:51:58,897 Epoch[36] Batch [30]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:52:07,040 Epoch[36] Batch [40]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:52:15,177 Epoch[36] Batch [50]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:52:23,343 Epoch[36] Batch [60]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:52:31,186 Epoch[36] Batch [70]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:52:39,328 Epoch[36] Batch [80]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:52:47,769 Epoch[36] Batch [90]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:52:55,911 Epoch[36] Batch [100]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:03,807 Epoch[36] Batch [110]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:11,621 Epoch[36] Batch [120]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:19,452 Epoch[36] Batch [130]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:28,023 Epoch[36] Batch [140]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:35,907 Epoch[36] Batch [150]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:43,912 Epoch[36] Batch [160]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:51,868 Epoch[36] Batch [170]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:53:59,989 Epoch[36] Batch [180]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:54:07,664 Epoch[36] Batch [190]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:54:15,793 Epoch[36] Batch [200]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:54:23,959 Epoch[36] Batch [210]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:54:32,188 Epoch[36] Batch [220]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:54:40,572 Epoch[36] Batch [230]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:54:48,739 Epoch[36] Batch [240]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:54:56,823 Epoch[36] Batch [250]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:55:05,164 Epoch[36] Batch [260]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:55:13,178 Epoch[36] Batch [270]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:55:21,404 Epoch[36] Batch [280]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:55:29,723 Epoch[36] Batch [290]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:55:37,946 Epoch[36] Batch [300]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:55:46,126 Epoch[36] Batch [310]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:55:54,048 Epoch[36] Batch [320]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:56:02,310 Epoch[36] Batch [330]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:56:10,758 Epoch[36] Batch [340]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:56:19,266 Epoch[36] Batch [350]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:56:28,062 Epoch[36] Batch [360]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:56:36,016 Epoch[36] Batch [370]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:56:44,047 Epoch[36] Batch [380]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:56:52,240 Epoch[36] Batch [390]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:00,476 Epoch[36] Batch [400]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:08,540 Epoch[36] Batch [410]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:16,595 Epoch[36] Batch [420]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:24,672 Epoch[36] Batch [430]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:32,764 Epoch[36] Batch [440]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:40,838 Epoch[36] Batch [450]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:48,988 Epoch[36] Batch [460]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:57:57,313 Epoch[36] Batch [470]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:58:05,228 Epoch[36] Batch [480]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:58:13,114 Epoch[36] Batch [490]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:58:20,973 Epoch[36] Batch [500]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:58:29,174 Epoch[36] Batch [510]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:58:37,159 Epoch[36] Batch [520]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:58:45,153 Epoch[36] Batch [530]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:58:53,238 Epoch[36] Batch [540]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:01,245 Epoch[36] Batch [550]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:08,908 Epoch[36] Batch [560]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:17,007 Epoch[36] Batch [570]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:25,118 Epoch[36] Batch [580]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:32,972 Epoch[36] Batch [590]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:41,104 Epoch[36] Batch [600]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:49,085 Epoch[36] Batch [610]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 03:59:57,092 Epoch[36] Batch [620]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:00:05,066 Epoch[36] Batch [630]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:00:13,018 Epoch[36] Batch [640]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:00:21,077 Epoch[36] Batch [650]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:00:29,209 Epoch[36] Batch [660]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:00:37,259 Epoch[36] Batch [670]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:00:45,445 Epoch[36] Batch [680]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:00:53,377 Epoch[36] Batch [690]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:01,458 Epoch[36] Batch [700]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:09,651 Epoch[36] Batch [710]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:17,564 Epoch[36] Batch [720]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:25,272 Epoch[36] Batch [730]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:32,527 Epoch[36] Batch [740]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:39,733 Epoch[36] Batch [750]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:47,044 Epoch[36] Batch [760]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:01:54,537 Epoch[36] Batch [770]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:01,873 Epoch[36] Batch [780]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:09,043 Epoch[36] Batch [790]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:16,564 Epoch[36] Batch [800]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:24,099 Epoch[36] Batch [810]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:31,630 Epoch[36] Batch [820]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:39,066 Epoch[36] Batch [830]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:46,530 Epoch[36] Batch [840]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:02:53,721 Epoch[36] Batch [850]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:01,219 Epoch[36] Batch [860]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:08,754 Epoch[36] Batch [870]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:16,597 Epoch[36] Batch [880]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:24,555 Epoch[36] Batch [890]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:32,898 Epoch[36] Batch [900]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:41,153 Epoch[36] Batch [910]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:49,189 Epoch[36] Batch [920]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:03:57,154 Epoch[36] Batch [930]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:04:05,324 Epoch[36] Batch [940]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:04:13,271 Epoch[36] Batch [950]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:04:21,374 Epoch[36] Batch [960]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:04:29,544 Epoch[36] Batch [970]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:04:37,563 Epoch[36] Batch [980]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:04:45,543 Epoch[36] Batch [990]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:04:53,632 Epoch[36] Batch [1000]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:01,807 Epoch[36] Batch [1010]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:09,854 Epoch[36] Batch [1020]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:17,699 Epoch[36] Batch [1030]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:25,847 Epoch[36] Batch [1040]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:33,838 Epoch[36] Batch [1050]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:41,771 Epoch[36] Batch [1060]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:49,769 Epoch[36] Batch [1070]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:05:57,637 Epoch[36] Batch [1080]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:06:05,789 Epoch[36] Batch [1090]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:06:13,509 Epoch[36] Batch [1100]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:06:21,166 Epoch[36] Batch [1110]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:06:28,591 Epoch[36] Batch [1120]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:06:36,029 Epoch[36] Batch [1130]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:06:43,467 Epoch[36] Batch [1140]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:06:52,022 Epoch[36] Batch [1150]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:00,815 Epoch[36] Batch [1160]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:09,712 Epoch[36] Batch [1170]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:18,493 Epoch[36] Batch [1180]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:26,749 Epoch[36] Batch [1190]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:34,858 Epoch[36] Batch [1200]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:43,116 Epoch[36] Batch [1210]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:51,191 Epoch[36] Batch [1220]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:07:59,038 Epoch[36] Batch [1230]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:08:07,121 Epoch[36] Batch [1240]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:08:15,345 Epoch[36] Batch [1250]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:08:23,553 Epoch[36] Batch [1260]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:08:31,678 Epoch[36] Batch [1270]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:08:39,702 Epoch[36] Batch [1280]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:08:47,805 Epoch[36] Batch [1290]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:08:56,144 Epoch[36] Batch [1300]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:09:04,364 Epoch[36] Batch [1310]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:09:12,883 Epoch[36] Batch [1320]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:09:21,548 Epoch[36] Batch [1330]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:09:30,450 Epoch[36] Batch [1340]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:09:39,229 Epoch[36] Batch [1350]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:09:47,681 Epoch[36] Batch [1360]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:09:55,759 Epoch[36] Batch [1370]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:10:03,921 Epoch[36] Batch [1380]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:10:11,849 Epoch[36] Batch [1390]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:10:20,056 Epoch[36] Batch [1400]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:10:28,642 Epoch[36] Batch [1410]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:10:37,028 Epoch[36] Batch [1420]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:10:45,946 Epoch[36] Batch [1430]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:10:54,626 Epoch[36] Batch [1440]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:11:02,788 Epoch[36] Batch [1450]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:11:10,013 Epoch[36] Batch [1460]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:11:17,446 Epoch[36] Batch [1470]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:11:24,631 Epoch[36] Batch [1480]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:11:29,192 Epoch[36] Train-FCNLogLoss=nan
2017-07-14 04:11:29,193 Epoch[36] Time cost=1195.152
2017-07-14 04:11:30,299 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.params"
2017-07-14 04:11:34,377 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.states"
2017-07-14 04:11:43,031 Epoch[37] Batch [10]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:11:50,994 Epoch[37] Batch [20]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:11:59,099 Epoch[37] Batch [30]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:12:07,373 Epoch[37] Batch [40]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:12:15,383 Epoch[37] Batch [50]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:12:23,747 Epoch[37] Batch [60]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:12:32,065 Epoch[37] Batch [70]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:12:40,313 Epoch[37] Batch [80]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:12:48,703 Epoch[37] Batch [90]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:12:56,596 Epoch[37] Batch [100]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:13:04,956 Epoch[37] Batch [110]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:13:13,179 Epoch[37] Batch [120]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:13:21,287 Epoch[37] Batch [130]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:13:29,509 Epoch[37] Batch [140]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:13:37,687 Epoch[37] Batch [150]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:13:46,054 Epoch[37] Batch [160]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:13:54,344 Epoch[37] Batch [170]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:14:02,716 Epoch[37] Batch [180]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:14:11,204 Epoch[37] Batch [190]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:14:19,663 Epoch[37] Batch [200]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:14:27,966 Epoch[37] Batch [210]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:14:36,171 Epoch[37] Batch [220]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:14:44,459 Epoch[37] Batch [230]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:14:52,708 Epoch[37] Batch [240]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:01,004 Epoch[37] Batch [250]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:08,705 Epoch[37] Batch [260]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:16,253 Epoch[37] Batch [270]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:23,661 Epoch[37] Batch [280]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:31,177 Epoch[37] Batch [290]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:38,614 Epoch[37] Batch [300]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:46,277 Epoch[37] Batch [310]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:15:53,785 Epoch[37] Batch [320]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:01,285 Epoch[37] Batch [330]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:08,735 Epoch[37] Batch [340]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:16,314 Epoch[37] Batch [350]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:23,887 Epoch[37] Batch [360]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:31,563 Epoch[37] Batch [370]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:39,203 Epoch[37] Batch [380]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:46,820 Epoch[37] Batch [390]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:16:54,213 Epoch[37] Batch [400]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:01,969 Epoch[37] Batch [410]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:09,580 Epoch[37] Batch [420]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:16,872 Epoch[37] Batch [430]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:24,299 Epoch[37] Batch [440]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:31,834 Epoch[37] Batch [450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:39,200 Epoch[37] Batch [460]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:46,632 Epoch[37] Batch [470]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:17:54,023 Epoch[37] Batch [480]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:01,489 Epoch[37] Batch [490]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:09,038 Epoch[37] Batch [500]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:16,319 Epoch[37] Batch [510]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:23,847 Epoch[37] Batch [520]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:31,467 Epoch[37] Batch [530]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:39,009 Epoch[37] Batch [540]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:46,435 Epoch[37] Batch [550]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:18:53,814 Epoch[37] Batch [560]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:01,067 Epoch[37] Batch [570]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:08,236 Epoch[37] Batch [580]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:15,410 Epoch[37] Batch [590]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:22,715 Epoch[37] Batch [600]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:30,073 Epoch[37] Batch [610]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:37,662 Epoch[37] Batch [620]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:45,249 Epoch[37] Batch [630]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:19:52,554 Epoch[37] Batch [640]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:00,100 Epoch[37] Batch [650]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:07,725 Epoch[37] Batch [660]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:15,126 Epoch[37] Batch [670]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:22,679 Epoch[37] Batch [680]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:30,141 Epoch[37] Batch [690]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:37,638 Epoch[37] Batch [700]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:43,959 Epoch[37] Batch [710]	Speed: 6.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:50,454 Epoch[37] Batch [720]	Speed: 6.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:20:56,816 Epoch[37] Batch [730]	Speed: 6.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:02,687 Epoch[37] Batch [740]	Speed: 6.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:09,084 Epoch[37] Batch [750]	Speed: 6.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:15,694 Epoch[37] Batch [760]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:22,253 Epoch[37] Batch [770]	Speed: 6.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:28,777 Epoch[37] Batch [780]	Speed: 6.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:35,279 Epoch[37] Batch [790]	Speed: 6.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:42,194 Epoch[37] Batch [800]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:48,804 Epoch[37] Batch [810]	Speed: 6.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:21:55,663 Epoch[37] Batch [820]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:02,737 Epoch[37] Batch [830]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:09,927 Epoch[37] Batch [840]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:16,735 Epoch[37] Batch [850]	Speed: 5.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:23,414 Epoch[37] Batch [860]	Speed: 5.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:30,146 Epoch[37] Batch [870]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:37,156 Epoch[37] Batch [880]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:44,037 Epoch[37] Batch [890]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:50,772 Epoch[37] Batch [900]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:22:57,517 Epoch[37] Batch [910]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:04,346 Epoch[37] Batch [920]	Speed: 5.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:11,371 Epoch[37] Batch [930]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:18,112 Epoch[37] Batch [940]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:25,068 Epoch[37] Batch [950]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:31,786 Epoch[37] Batch [960]	Speed: 5.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:38,642 Epoch[37] Batch [970]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:45,797 Epoch[37] Batch [980]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:52,664 Epoch[37] Batch [990]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:23:59,851 Epoch[37] Batch [1000]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:07,017 Epoch[37] Batch [1010]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:13,622 Epoch[37] Batch [1020]	Speed: 6.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:20,456 Epoch[37] Batch [1030]	Speed: 5.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:27,095 Epoch[37] Batch [1040]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:33,465 Epoch[37] Batch [1050]	Speed: 6.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:40,323 Epoch[37] Batch [1060]	Speed: 5.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:47,074 Epoch[37] Batch [1070]	Speed: 5.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:24:53,779 Epoch[37] Batch [1080]	Speed: 5.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:00,799 Epoch[37] Batch [1090]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:07,645 Epoch[37] Batch [1100]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:14,667 Epoch[37] Batch [1110]	Speed: 5.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:21,302 Epoch[37] Batch [1120]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:28,309 Epoch[37] Batch [1130]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:35,286 Epoch[37] Batch [1140]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:41,951 Epoch[37] Batch [1150]	Speed: 6.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:48,806 Epoch[37] Batch [1160]	Speed: 5.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:25:55,537 Epoch[37] Batch [1170]	Speed: 5.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:02,320 Epoch[37] Batch [1180]	Speed: 5.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:08,872 Epoch[37] Batch [1190]	Speed: 6.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:15,506 Epoch[37] Batch [1200]	Speed: 6.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:22,162 Epoch[37] Batch [1210]	Speed: 6.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:28,871 Epoch[37] Batch [1220]	Speed: 5.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:35,340 Epoch[37] Batch [1230]	Speed: 6.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:41,926 Epoch[37] Batch [1240]	Speed: 6.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:49,636 Epoch[37] Batch [1250]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:26:56,605 Epoch[37] Batch [1260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:04,124 Epoch[37] Batch [1270]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:11,199 Epoch[37] Batch [1280]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:18,079 Epoch[37] Batch [1290]	Speed: 5.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:25,272 Epoch[37] Batch [1300]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:33,172 Epoch[37] Batch [1310]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:41,070 Epoch[37] Batch [1320]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:49,150 Epoch[37] Batch [1330]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:27:56,822 Epoch[37] Batch [1340]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:04,579 Epoch[37] Batch [1350]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:12,727 Epoch[37] Batch [1360]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:20,693 Epoch[37] Batch [1370]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:28,784 Epoch[37] Batch [1380]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:36,654 Epoch[37] Batch [1390]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:44,269 Epoch[37] Batch [1400]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:51,746 Epoch[37] Batch [1410]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:28:59,590 Epoch[37] Batch [1420]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:29:07,682 Epoch[37] Batch [1430]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:29:15,510 Epoch[37] Batch [1440]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:29:23,778 Epoch[37] Batch [1450]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:29:32,299 Epoch[37] Batch [1460]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:29:40,533 Epoch[37] Batch [1470]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:29:48,225 Epoch[37] Batch [1480]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:29:52,379 Epoch[37] Train-FCNLogLoss=nan
2017-07-14 04:29:52,379 Epoch[37] Time cost=1098.001
2017-07-14 04:29:53,573 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.params"
2017-07-14 04:29:58,342 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.states"
2017-07-14 04:30:07,519 Epoch[38] Batch [10]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:30:16,155 Epoch[38] Batch [20]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:30:24,143 Epoch[38] Batch [30]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:30:32,876 Epoch[38] Batch [40]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:30:40,678 Epoch[38] Batch [50]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:30:49,309 Epoch[38] Batch [60]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:30:57,078 Epoch[38] Batch [70]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:31:05,805 Epoch[38] Batch [80]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:31:14,390 Epoch[38] Batch [90]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:31:22,572 Epoch[38] Batch [100]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:31:31,010 Epoch[38] Batch [110]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:31:39,363 Epoch[38] Batch [120]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:31:47,673 Epoch[38] Batch [130]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:31:57,517 Epoch[38] Batch [140]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:32:07,003 Epoch[38] Batch [150]	Speed: 4.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:32:16,614 Epoch[38] Batch [160]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:32:26,223 Epoch[38] Batch [170]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:32:35,416 Epoch[38] Batch [180]	Speed: 4.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:32:45,656 Epoch[38] Batch [190]	Speed: 3.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:32:54,865 Epoch[38] Batch [200]	Speed: 4.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:33:03,912 Epoch[38] Batch [210]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:33:12,716 Epoch[38] Batch [220]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:33:21,235 Epoch[38] Batch [230]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:33:30,362 Epoch[38] Batch [240]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:33:39,354 Epoch[38] Batch [250]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:33:47,932 Epoch[38] Batch [260]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:33:56,725 Epoch[38] Batch [270]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:34:05,470 Epoch[38] Batch [280]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:34:14,350 Epoch[38] Batch [290]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:34:23,170 Epoch[38] Batch [300]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:34:32,339 Epoch[38] Batch [310]	Speed: 4.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:34:42,370 Epoch[38] Batch [320]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:34:52,393 Epoch[38] Batch [330]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:35:02,132 Epoch[38] Batch [340]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:35:11,530 Epoch[38] Batch [350]	Speed: 4.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:35:21,145 Epoch[38] Batch [360]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:35:30,695 Epoch[38] Batch [370]	Speed: 4.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:35:40,498 Epoch[38] Batch [380]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:35:50,304 Epoch[38] Batch [390]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:36:00,030 Epoch[38] Batch [400]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:36:09,838 Epoch[38] Batch [410]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:36:19,633 Epoch[38] Batch [420]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:36:29,399 Epoch[38] Batch [430]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:36:39,125 Epoch[38] Batch [440]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:36:48,304 Epoch[38] Batch [450]	Speed: 4.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:36:57,886 Epoch[38] Batch [460]	Speed: 4.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:37:07,731 Epoch[38] Batch [470]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:37:16,730 Epoch[38] Batch [480]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:37:26,361 Epoch[38] Batch [490]	Speed: 4.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:37:35,869 Epoch[38] Batch [500]	Speed: 4.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:37:46,149 Epoch[38] Batch [510]	Speed: 3.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:37:56,601 Epoch[38] Batch [520]	Speed: 3.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:38:07,022 Epoch[38] Batch [530]	Speed: 3.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:38:17,991 Epoch[38] Batch [540]	Speed: 3.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:38:27,672 Epoch[38] Batch [550]	Speed: 4.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:38:36,367 Epoch[38] Batch [560]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:38:45,218 Epoch[38] Batch [570]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:38:54,254 Epoch[38] Batch [580]	Speed: 4.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:39:03,271 Epoch[38] Batch [590]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:39:12,348 Epoch[38] Batch [600]	Speed: 4.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:39:21,401 Epoch[38] Batch [610]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:39:30,306 Epoch[38] Batch [620]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:39:39,157 Epoch[38] Batch [630]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:39:47,355 Epoch[38] Batch [640]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:39:55,925 Epoch[38] Batch [650]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:40:04,763 Epoch[38] Batch [660]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:40:13,732 Epoch[38] Batch [670]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:40:22,713 Epoch[38] Batch [680]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:40:31,818 Epoch[38] Batch [690]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:40:40,569 Epoch[38] Batch [700]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:40:49,583 Epoch[38] Batch [710]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:40:58,337 Epoch[38] Batch [720]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:41:07,301 Epoch[38] Batch [730]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:41:16,123 Epoch[38] Batch [740]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:41:24,943 Epoch[38] Batch [750]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:41:33,796 Epoch[38] Batch [760]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:41:42,758 Epoch[38] Batch [770]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:41:51,715 Epoch[38] Batch [780]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:42:00,848 Epoch[38] Batch [790]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:42:09,694 Epoch[38] Batch [800]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:42:18,815 Epoch[38] Batch [810]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:42:27,367 Epoch[38] Batch [820]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:42:36,097 Epoch[38] Batch [830]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:42:44,941 Epoch[38] Batch [840]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:42:53,854 Epoch[38] Batch [850]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:43:02,848 Epoch[38] Batch [860]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:43:11,821 Epoch[38] Batch [870]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:43:20,717 Epoch[38] Batch [880]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:43:29,628 Epoch[38] Batch [890]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:43:38,446 Epoch[38] Batch [900]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:43:47,500 Epoch[38] Batch [910]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:43:56,420 Epoch[38] Batch [920]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:44:05,249 Epoch[38] Batch [930]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:44:14,312 Epoch[38] Batch [940]	Speed: 4.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:44:23,184 Epoch[38] Batch [950]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:44:32,319 Epoch[38] Batch [960]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:44:41,158 Epoch[38] Batch [970]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:44:50,022 Epoch[38] Batch [980]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:44:58,833 Epoch[38] Batch [990]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:45:07,878 Epoch[38] Batch [1000]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:45:16,688 Epoch[38] Batch [1010]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:45:25,184 Epoch[38] Batch [1020]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:45:34,144 Epoch[38] Batch [1030]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:45:43,159 Epoch[38] Batch [1040]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:45:51,981 Epoch[38] Batch [1050]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:46:00,679 Epoch[38] Batch [1060]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:46:09,627 Epoch[38] Batch [1070]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:46:18,756 Epoch[38] Batch [1080]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:46:27,510 Epoch[38] Batch [1090]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:46:36,321 Epoch[38] Batch [1100]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:46:45,399 Epoch[38] Batch [1110]	Speed: 4.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:46:54,272 Epoch[38] Batch [1120]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:47:03,178 Epoch[38] Batch [1130]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:47:12,015 Epoch[38] Batch [1140]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:47:20,974 Epoch[38] Batch [1150]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:47:29,803 Epoch[38] Batch [1160]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:47:38,555 Epoch[38] Batch [1170]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:47:47,493 Epoch[38] Batch [1180]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:47:56,448 Epoch[38] Batch [1190]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:48:05,095 Epoch[38] Batch [1200]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:48:13,902 Epoch[38] Batch [1210]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:48:22,537 Epoch[38] Batch [1220]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:48:31,314 Epoch[38] Batch [1230]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:48:40,121 Epoch[38] Batch [1240]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:48:49,151 Epoch[38] Batch [1250]	Speed: 4.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:48:57,802 Epoch[38] Batch [1260]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:49:06,541 Epoch[38] Batch [1270]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:49:15,154 Epoch[38] Batch [1280]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:49:24,019 Epoch[38] Batch [1290]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:49:32,878 Epoch[38] Batch [1300]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:49:42,330 Epoch[38] Batch [1310]	Speed: 4.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:49:52,158 Epoch[38] Batch [1320]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:50:02,082 Epoch[38] Batch [1330]	Speed: 4.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:50:11,823 Epoch[38] Batch [1340]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:50:22,060 Epoch[38] Batch [1350]	Speed: 3.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:50:31,929 Epoch[38] Batch [1360]	Speed: 4.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:50:42,405 Epoch[38] Batch [1370]	Speed: 3.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:50:52,207 Epoch[38] Batch [1380]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:51:02,244 Epoch[38] Batch [1390]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:51:12,254 Epoch[38] Batch [1400]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:51:22,146 Epoch[38] Batch [1410]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:51:32,049 Epoch[38] Batch [1420]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:51:41,829 Epoch[38] Batch [1430]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:51:51,600 Epoch[38] Batch [1440]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:52:01,561 Epoch[38] Batch [1450]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:52:11,376 Epoch[38] Batch [1460]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:52:20,989 Epoch[38] Batch [1470]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:52:30,811 Epoch[38] Batch [1480]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:52:36,571 Epoch[38] Train-FCNLogLoss=nan
2017-07-14 04:52:36,571 Epoch[38] Time cost=1358.228
2017-07-14 04:52:37,661 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.params"
2017-07-14 04:52:42,504 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.states"
2017-07-14 04:52:53,281 Epoch[39] Batch [10]	Speed: 4.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:53:02,981 Epoch[39] Batch [20]	Speed: 4.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:53:12,514 Epoch[39] Batch [30]	Speed: 4.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:53:22,137 Epoch[39] Batch [40]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:53:31,938 Epoch[39] Batch [50]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:53:41,747 Epoch[39] Batch [60]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:53:51,382 Epoch[39] Batch [70]	Speed: 4.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:54:01,236 Epoch[39] Batch [80]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:54:11,039 Epoch[39] Batch [90]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:54:20,534 Epoch[39] Batch [100]	Speed: 4.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:54:30,229 Epoch[39] Batch [110]	Speed: 4.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:54:40,170 Epoch[39] Batch [120]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:54:49,937 Epoch[39] Batch [130]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:54:58,783 Epoch[39] Batch [140]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:55:08,927 Epoch[39] Batch [150]	Speed: 3.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:55:19,098 Epoch[39] Batch [160]	Speed: 3.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:55:29,366 Epoch[39] Batch [170]	Speed: 3.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:55:38,186 Epoch[39] Batch [180]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:55:46,618 Epoch[39] Batch [190]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:55:55,379 Epoch[39] Batch [200]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:56:04,208 Epoch[39] Batch [210]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:56:13,203 Epoch[39] Batch [220]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:56:21,957 Epoch[39] Batch [230]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:56:31,280 Epoch[39] Batch [240]	Speed: 4.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:56:40,897 Epoch[39] Batch [250]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:56:50,600 Epoch[39] Batch [260]	Speed: 4.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:57:00,631 Epoch[39] Batch [270]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:57:11,238 Epoch[39] Batch [280]	Speed: 3.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:57:21,270 Epoch[39] Batch [290]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:57:30,429 Epoch[39] Batch [300]	Speed: 4.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:57:39,571 Epoch[39] Batch [310]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:57:49,723 Epoch[39] Batch [320]	Speed: 3.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:57:58,597 Epoch[39] Batch [330]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:58:07,444 Epoch[39] Batch [340]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:58:16,157 Epoch[39] Batch [350]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:58:25,370 Epoch[39] Batch [360]	Speed: 4.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:58:35,763 Epoch[39] Batch [370]	Speed: 3.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:58:45,917 Epoch[39] Batch [380]	Speed: 3.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:58:54,737 Epoch[39] Batch [390]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:59:04,302 Epoch[39] Batch [400]	Speed: 4.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:59:14,013 Epoch[39] Batch [410]	Speed: 4.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:59:23,795 Epoch[39] Batch [420]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:59:33,612 Epoch[39] Batch [430]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:59:43,533 Epoch[39] Batch [440]	Speed: 4.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 04:59:53,326 Epoch[39] Batch [450]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:00:03,668 Epoch[39] Batch [460]	Speed: 3.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:00:14,124 Epoch[39] Batch [470]	Speed: 3.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:00:24,560 Epoch[39] Batch [480]	Speed: 3.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:00:35,027 Epoch[39] Batch [490]	Speed: 3.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:00:45,077 Epoch[39] Batch [500]	Speed: 3.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:00:54,700 Epoch[39] Batch [510]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:01:04,700 Epoch[39] Batch [520]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:01:14,486 Epoch[39] Batch [530]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:01:24,351 Epoch[39] Batch [540]	Speed: 4.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:01:34,107 Epoch[39] Batch [550]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:01:44,159 Epoch[39] Batch [560]	Speed: 3.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:01:53,928 Epoch[39] Batch [570]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:02:03,824 Epoch[39] Batch [580]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:02:13,834 Epoch[39] Batch [590]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:02:23,577 Epoch[39] Batch [600]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:02:33,158 Epoch[39] Batch [610]	Speed: 4.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:02:42,973 Epoch[39] Batch [620]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:02:52,947 Epoch[39] Batch [630]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:03:02,452 Epoch[39] Batch [640]	Speed: 4.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:03:11,934 Epoch[39] Batch [650]	Speed: 4.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:03:21,606 Epoch[39] Batch [660]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:03:31,634 Epoch[39] Batch [670]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:03:41,618 Epoch[39] Batch [680]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:03:51,273 Epoch[39] Batch [690]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:04:00,861 Epoch[39] Batch [700]	Speed: 4.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:04:10,377 Epoch[39] Batch [710]	Speed: 4.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:04:20,360 Epoch[39] Batch [720]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:04:30,211 Epoch[39] Batch [730]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:04:40,106 Epoch[39] Batch [740]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:04:49,498 Epoch[39] Batch [750]	Speed: 4.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:04:59,466 Epoch[39] Batch [760]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:05:09,133 Epoch[39] Batch [770]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:05:18,856 Epoch[39] Batch [780]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:05:28,667 Epoch[39] Batch [790]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:05:38,437 Epoch[39] Batch [800]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:05:48,289 Epoch[39] Batch [810]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:05:57,956 Epoch[39] Batch [820]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:06:07,320 Epoch[39] Batch [830]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:06:17,229 Epoch[39] Batch [840]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:06:26,953 Epoch[39] Batch [850]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:06:36,785 Epoch[39] Batch [860]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:06:46,612 Epoch[39] Batch [870]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:06:56,633 Epoch[39] Batch [880]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:07:06,010 Epoch[39] Batch [890]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:07:14,871 Epoch[39] Batch [900]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:07:23,874 Epoch[39] Batch [910]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:07:32,782 Epoch[39] Batch [920]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:07:41,658 Epoch[39] Batch [930]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:07:50,523 Epoch[39] Batch [940]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:07:59,433 Epoch[39] Batch [950]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:08:08,434 Epoch[39] Batch [960]	Speed: 4.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:08:17,547 Epoch[39] Batch [970]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:08:26,332 Epoch[39] Batch [980]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:08:35,183 Epoch[39] Batch [990]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:08:43,894 Epoch[39] Batch [1000]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:08:53,088 Epoch[39] Batch [1010]	Speed: 4.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:09:02,992 Epoch[39] Batch [1020]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:09:12,600 Epoch[39] Batch [1030]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:09:22,545 Epoch[39] Batch [1040]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:09:32,283 Epoch[39] Batch [1050]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:09:41,525 Epoch[39] Batch [1060]	Speed: 4.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:09:50,372 Epoch[39] Batch [1070]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:09:59,314 Epoch[39] Batch [1080]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:10:08,067 Epoch[39] Batch [1090]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:10:17,039 Epoch[39] Batch [1100]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:10:25,933 Epoch[39] Batch [1110]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:10:34,739 Epoch[39] Batch [1120]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:10:43,854 Epoch[39] Batch [1130]	Speed: 4.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:10:52,661 Epoch[39] Batch [1140]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:11:01,967 Epoch[39] Batch [1150]	Speed: 4.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:11:11,816 Epoch[39] Batch [1160]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:11:21,828 Epoch[39] Batch [1170]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:11:32,272 Epoch[39] Batch [1180]	Speed: 3.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:11:42,802 Epoch[39] Batch [1190]	Speed: 3.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:11:53,338 Epoch[39] Batch [1200]	Speed: 3.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:12:03,590 Epoch[39] Batch [1210]	Speed: 3.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:12:13,429 Epoch[39] Batch [1220]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:12:23,199 Epoch[39] Batch [1230]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:12:32,923 Epoch[39] Batch [1240]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:12:43,572 Epoch[39] Batch [1250]	Speed: 3.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:12:53,916 Epoch[39] Batch [1260]	Speed: 3.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:13:03,772 Epoch[39] Batch [1270]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:13:13,391 Epoch[39] Batch [1280]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:13:22,973 Epoch[39] Batch [1290]	Speed: 4.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:13:32,632 Epoch[39] Batch [1300]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:13:42,280 Epoch[39] Batch [1310]	Speed: 4.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:13:51,840 Epoch[39] Batch [1320]	Speed: 4.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:14:00,867 Epoch[39] Batch [1330]	Speed: 4.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:14:10,352 Epoch[39] Batch [1340]	Speed: 4.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:14:20,126 Epoch[39] Batch [1350]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:14:29,914 Epoch[39] Batch [1360]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:14:39,456 Epoch[39] Batch [1370]	Speed: 4.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:14:48,801 Epoch[39] Batch [1380]	Speed: 4.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:14:57,853 Epoch[39] Batch [1390]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:15:07,315 Epoch[39] Batch [1400]	Speed: 4.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:15:16,215 Epoch[39] Batch [1410]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:15:25,600 Epoch[39] Batch [1420]	Speed: 4.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:15:34,830 Epoch[39] Batch [1430]	Speed: 4.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:15:44,145 Epoch[39] Batch [1440]	Speed: 4.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:15:53,614 Epoch[39] Batch [1450]	Speed: 4.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:16:04,596 Epoch[39] Batch [1460]	Speed: 3.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:16:15,473 Epoch[39] Batch [1470]	Speed: 3.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:16:25,470 Epoch[39] Batch [1480]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:16:31,386 Epoch[39] Train-FCNLogLoss=nan
2017-07-14 05:16:31,386 Epoch[39] Time cost=1428.881
2017-07-14 05:16:32,623 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.params"
2017-07-14 05:16:37,515 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.states"
2017-07-14 05:16:48,625 Epoch[40] Batch [10]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:16:58,249 Epoch[40] Batch [20]	Speed: 4.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:17:08,002 Epoch[40] Batch [30]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:17:18,537 Epoch[40] Batch [40]	Speed: 3.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:17:28,601 Epoch[40] Batch [50]	Speed: 3.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:17:38,106 Epoch[40] Batch [60]	Speed: 4.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:17:46,871 Epoch[40] Batch [70]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:17:55,836 Epoch[40] Batch [80]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:18:04,662 Epoch[40] Batch [90]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:18:13,707 Epoch[40] Batch [100]	Speed: 4.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:18:22,675 Epoch[40] Batch [110]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:18:31,306 Epoch[40] Batch [120]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:18:40,232 Epoch[40] Batch [130]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:18:49,142 Epoch[40] Batch [140]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:18:58,138 Epoch[40] Batch [150]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:19:06,997 Epoch[40] Batch [160]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:19:15,783 Epoch[40] Batch [170]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:19:24,751 Epoch[40] Batch [180]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:19:33,624 Epoch[40] Batch [190]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:19:42,482 Epoch[40] Batch [200]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:19:51,352 Epoch[40] Batch [210]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:20:00,493 Epoch[40] Batch [220]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:20:09,385 Epoch[40] Batch [230]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:20:17,748 Epoch[40] Batch [240]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:20:26,847 Epoch[40] Batch [250]	Speed: 4.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:20:36,136 Epoch[40] Batch [260]	Speed: 4.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:20:46,028 Epoch[40] Batch [270]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:20:56,070 Epoch[40] Batch [280]	Speed: 3.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:21:06,347 Epoch[40] Batch [290]	Speed: 3.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:21:16,852 Epoch[40] Batch [300]	Speed: 3.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:21:27,253 Epoch[40] Batch [310]	Speed: 3.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:21:37,212 Epoch[40] Batch [320]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:21:47,321 Epoch[40] Batch [330]	Speed: 3.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:21:58,156 Epoch[40] Batch [340]	Speed: 3.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:22:07,624 Epoch[40] Batch [350]	Speed: 4.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:22:16,920 Epoch[40] Batch [360]	Speed: 4.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:22:26,914 Epoch[40] Batch [370]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:22:36,581 Epoch[40] Batch [380]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:22:46,234 Epoch[40] Batch [390]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:22:56,148 Epoch[40] Batch [400]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:23:06,156 Epoch[40] Batch [410]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:23:15,979 Epoch[40] Batch [420]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:23:25,685 Epoch[40] Batch [430]	Speed: 4.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:23:35,399 Epoch[40] Batch [440]	Speed: 4.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:23:44,901 Epoch[40] Batch [450]	Speed: 4.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:23:54,809 Epoch[40] Batch [460]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:24:04,771 Epoch[40] Batch [470]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:24:14,649 Epoch[40] Batch [480]	Speed: 4.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:24:24,400 Epoch[40] Batch [490]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:24:34,236 Epoch[40] Batch [500]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:24:43,746 Epoch[40] Batch [510]	Speed: 4.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:24:52,204 Update[60000]: Change learning rate to 5.00000e-05
2017-07-14 05:24:53,485 Epoch[40] Batch [520]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:25:03,496 Epoch[40] Batch [530]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:25:13,663 Epoch[40] Batch [540]	Speed: 3.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:25:23,736 Epoch[40] Batch [550]	Speed: 3.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:25:33,388 Epoch[40] Batch [560]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:25:43,156 Epoch[40] Batch [570]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:25:53,012 Epoch[40] Batch [580]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:26:03,551 Epoch[40] Batch [590]	Speed: 3.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:26:12,851 Epoch[40] Batch [600]	Speed: 4.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:26:22,500 Epoch[40] Batch [610]	Speed: 4.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:26:32,046 Epoch[40] Batch [620]	Speed: 4.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:26:42,665 Epoch[40] Batch [630]	Speed: 3.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:26:53,193 Epoch[40] Batch [640]	Speed: 3.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:27:03,620 Epoch[40] Batch [650]	Speed: 3.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:27:14,366 Epoch[40] Batch [660]	Speed: 3.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:27:24,336 Epoch[40] Batch [670]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:27:35,037 Epoch[40] Batch [680]	Speed: 3.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:27:45,727 Epoch[40] Batch [690]	Speed: 3.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:27:56,751 Epoch[40] Batch [700]	Speed: 3.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:28:07,552 Epoch[40] Batch [710]	Speed: 3.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:28:17,618 Epoch[40] Batch [720]	Speed: 3.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:28:27,279 Epoch[40] Batch [730]	Speed: 4.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:28:37,142 Epoch[40] Batch [740]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:28:46,913 Epoch[40] Batch [750]	Speed: 4.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:28:56,912 Epoch[40] Batch [760]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:29:06,632 Epoch[40] Batch [770]	Speed: 4.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:29:16,631 Epoch[40] Batch [780]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:29:26,396 Epoch[40] Batch [790]	Speed: 4.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:29:35,841 Epoch[40] Batch [800]	Speed: 4.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:29:45,671 Epoch[40] Batch [810]	Speed: 4.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:29:55,320 Epoch[40] Batch [820]	Speed: 4.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:30:04,751 Epoch[40] Batch [830]	Speed: 4.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:30:14,679 Epoch[40] Batch [840]	Speed: 4.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:30:24,316 Epoch[40] Batch [850]	Speed: 4.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:30:34,004 Epoch[40] Batch [860]	Speed: 4.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:30:43,559 Epoch[40] Batch [870]	Speed: 4.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:30:53,862 Epoch[40] Batch [880]	Speed: 3.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:31:04,524 Epoch[40] Batch [890]	Speed: 3.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:31:14,990 Epoch[40] Batch [900]	Speed: 3.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:31:25,547 Epoch[40] Batch [910]	Speed: 3.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:31:35,751 Epoch[40] Batch [920]	Speed: 3.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:31:46,031 Epoch[40] Batch [930]	Speed: 3.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:31:56,041 Epoch[40] Batch [940]	Speed: 4.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:32:06,204 Epoch[40] Batch [950]	Speed: 3.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:32:16,267 Epoch[40] Batch [960]	Speed: 3.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:32:25,964 Epoch[40] Batch [970]	Speed: 4.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:32:36,070 Epoch[40] Batch [980]	Speed: 3.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:32:46,285 Epoch[40] Batch [990]	Speed: 3.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:32:56,310 Epoch[40] Batch [1000]	Speed: 3.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:33:06,041 Epoch[40] Batch [1010]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:33:15,937 Epoch[40] Batch [1020]	Speed: 4.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:33:26,309 Epoch[40] Batch [1030]	Speed: 3.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:33:36,404 Epoch[40] Batch [1040]	Speed: 3.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:33:45,751 Epoch[40] Batch [1050]	Speed: 4.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:33:54,400 Epoch[40] Batch [1060]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:34:03,207 Epoch[40] Batch [1070]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:34:12,160 Epoch[40] Batch [1080]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:34:21,077 Epoch[40] Batch [1090]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:34:30,064 Epoch[40] Batch [1100]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:34:39,222 Epoch[40] Batch [1110]	Speed: 4.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:34:48,000 Epoch[40] Batch [1120]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:34:56,798 Epoch[40] Batch [1130]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:35:05,481 Epoch[40] Batch [1140]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:35:14,386 Epoch[40] Batch [1150]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:35:23,309 Epoch[40] Batch [1160]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:35:32,371 Epoch[40] Batch [1170]	Speed: 4.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:35:39,824 Epoch[40] Batch [1180]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:35:47,198 Epoch[40] Batch [1190]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:35:54,537 Epoch[40] Batch [1200]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:01,620 Epoch[40] Batch [1210]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:08,958 Epoch[40] Batch [1220]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:16,227 Epoch[40] Batch [1230]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:23,639 Epoch[40] Batch [1240]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:30,966 Epoch[40] Batch [1250]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:38,263 Epoch[40] Batch [1260]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:45,587 Epoch[40] Batch [1270]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:36:52,763 Epoch[40] Batch [1280]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:00,153 Epoch[40] Batch [1290]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:07,313 Epoch[40] Batch [1300]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:14,668 Epoch[40] Batch [1310]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:22,009 Epoch[40] Batch [1320]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:29,202 Epoch[40] Batch [1330]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:36,545 Epoch[40] Batch [1340]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:43,960 Epoch[40] Batch [1350]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:37:51,964 Epoch[40] Batch [1360]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:00,613 Epoch[40] Batch [1370]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:07,788 Epoch[40] Batch [1380]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:15,929 Epoch[40] Batch [1390]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:23,491 Epoch[40] Batch [1400]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:31,560 Epoch[40] Batch [1410]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:39,750 Epoch[40] Batch [1420]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:47,896 Epoch[40] Batch [1430]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:38:55,785 Epoch[40] Batch [1440]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:39:04,012 Epoch[40] Batch [1450]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:39:12,322 Epoch[40] Batch [1460]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:39:20,490 Epoch[40] Batch [1470]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:39:28,657 Epoch[40] Batch [1480]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:39:33,150 Epoch[40] Train-FCNLogLoss=nan
2017-07-14 05:39:33,150 Epoch[40] Time cost=1375.635
2017-07-14 05:39:34,363 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.params"
2017-07-14 05:39:38,328 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.states"
2017-07-14 05:39:46,555 Epoch[41] Batch [10]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:39:54,006 Epoch[41] Batch [20]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:02,063 Epoch[41] Batch [30]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:10,057 Epoch[41] Batch [40]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:18,225 Epoch[41] Batch [50]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:26,537 Epoch[41] Batch [60]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:34,741 Epoch[41] Batch [70]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:42,733 Epoch[41] Batch [80]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:51,029 Epoch[41] Batch [90]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:40:59,024 Epoch[41] Batch [100]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:41:07,009 Epoch[41] Batch [110]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:41:15,212 Epoch[41] Batch [120]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:41:23,192 Epoch[41] Batch [130]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:41:31,495 Epoch[41] Batch [140]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:41:39,701 Epoch[41] Batch [150]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:41:47,673 Epoch[41] Batch [160]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:41:55,868 Epoch[41] Batch [170]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:42:04,130 Epoch[41] Batch [180]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:42:12,100 Epoch[41] Batch [190]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:42:19,820 Epoch[41] Batch [200]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:42:27,817 Epoch[41] Batch [210]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:42:36,117 Epoch[41] Batch [220]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:42:44,098 Epoch[41] Batch [230]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:42:52,160 Epoch[41] Batch [240]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:00,238 Epoch[41] Batch [250]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:08,451 Epoch[41] Batch [260]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:16,562 Epoch[41] Batch [270]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:24,596 Epoch[41] Batch [280]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:32,840 Epoch[41] Batch [290]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:40,998 Epoch[41] Batch [300]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:49,267 Epoch[41] Batch [310]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:43:57,778 Epoch[41] Batch [320]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:44:06,000 Epoch[41] Batch [330]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:44:14,271 Epoch[41] Batch [340]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:44:22,457 Epoch[41] Batch [350]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:44:30,464 Epoch[41] Batch [360]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:44:38,479 Epoch[41] Batch [370]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:44:46,754 Epoch[41] Batch [380]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:44:55,458 Epoch[41] Batch [390]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:45:03,534 Epoch[41] Batch [400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:45:11,715 Epoch[41] Batch [410]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:45:19,886 Epoch[41] Batch [420]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:45:28,683 Epoch[41] Batch [430]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:45:36,940 Epoch[41] Batch [440]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:45:45,387 Epoch[41] Batch [450]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:45:54,249 Epoch[41] Batch [460]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:46:03,784 Epoch[41] Batch [470]	Speed: 4.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:46:12,470 Epoch[41] Batch [480]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:46:20,908 Epoch[41] Batch [490]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:46:29,542 Epoch[41] Batch [500]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:46:37,418 Epoch[41] Batch [510]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:46:46,070 Epoch[41] Batch [520]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:46:55,002 Epoch[41] Batch [530]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:47:04,076 Epoch[41] Batch [540]	Speed: 4.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:47:12,228 Epoch[41] Batch [550]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:47:19,923 Epoch[41] Batch [560]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:47:28,356 Epoch[41] Batch [570]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:47:37,078 Epoch[41] Batch [580]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:47:45,145 Epoch[41] Batch [590]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:47:53,230 Epoch[41] Batch [600]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:01,640 Epoch[41] Batch [610]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:09,934 Epoch[41] Batch [620]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:18,186 Epoch[41] Batch [630]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:26,326 Epoch[41] Batch [640]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:34,637 Epoch[41] Batch [650]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:42,688 Epoch[41] Batch [660]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:50,714 Epoch[41] Batch [670]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:48:58,961 Epoch[41] Batch [680]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:49:07,007 Epoch[41] Batch [690]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:49:15,125 Epoch[41] Batch [700]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:49:23,396 Epoch[41] Batch [710]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:49:31,483 Epoch[41] Batch [720]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:49:39,792 Epoch[41] Batch [730]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:49:47,712 Epoch[41] Batch [740]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:49:55,741 Epoch[41] Batch [750]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:03,814 Epoch[41] Batch [760]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:11,417 Epoch[41] Batch [770]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:19,468 Epoch[41] Batch [780]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:27,541 Epoch[41] Batch [790]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:35,722 Epoch[41] Batch [800]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:43,619 Epoch[41] Batch [810]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:51,483 Epoch[41] Batch [820]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:50:59,555 Epoch[41] Batch [830]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:51:07,410 Epoch[41] Batch [840]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:51:15,459 Epoch[41] Batch [850]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:51:23,632 Epoch[41] Batch [860]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:51:31,581 Epoch[41] Batch [870]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:51:39,725 Epoch[41] Batch [880]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:51:47,951 Epoch[41] Batch [890]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:51:55,971 Epoch[41] Batch [900]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:52:04,008 Epoch[41] Batch [910]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:52:12,155 Epoch[41] Batch [920]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:52:20,289 Epoch[41] Batch [930]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:52:28,241 Epoch[41] Batch [940]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:52:36,233 Epoch[41] Batch [950]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:52:44,506 Epoch[41] Batch [960]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:52:52,661 Epoch[41] Batch [970]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:00,722 Epoch[41] Batch [980]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:08,909 Epoch[41] Batch [990]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:17,229 Epoch[41] Batch [1000]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:25,278 Epoch[41] Batch [1010]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:33,925 Epoch[41] Batch [1020]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:42,259 Epoch[41] Batch [1030]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:49,894 Epoch[41] Batch [1040]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:53:57,580 Epoch[41] Batch [1050]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:54:06,192 Epoch[41] Batch [1060]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:54:14,682 Epoch[41] Batch [1070]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:54:22,969 Epoch[41] Batch [1080]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:54:31,153 Epoch[41] Batch [1090]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:54:39,399 Epoch[41] Batch [1100]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:54:47,231 Epoch[41] Batch [1110]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:54:54,769 Epoch[41] Batch [1120]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:02,504 Epoch[41] Batch [1130]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:09,966 Epoch[41] Batch [1140]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:17,874 Epoch[41] Batch [1150]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:25,346 Epoch[41] Batch [1160]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:32,840 Epoch[41] Batch [1170]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:40,042 Epoch[41] Batch [1180]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:47,281 Epoch[41] Batch [1190]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:55:54,261 Epoch[41] Batch [1200]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:01,302 Epoch[41] Batch [1210]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:08,527 Epoch[41] Batch [1220]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:15,880 Epoch[41] Batch [1230]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:23,727 Epoch[41] Batch [1240]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:31,482 Epoch[41] Batch [1250]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:38,864 Epoch[41] Batch [1260]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:45,849 Epoch[41] Batch [1270]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:56:53,095 Epoch[41] Batch [1280]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:01,041 Epoch[41] Batch [1290]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:08,766 Epoch[41] Batch [1300]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:16,769 Epoch[41] Batch [1310]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:24,859 Epoch[41] Batch [1320]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:32,647 Epoch[41] Batch [1330]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:40,690 Epoch[41] Batch [1340]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:48,367 Epoch[41] Batch [1350]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:57:55,815 Epoch[41] Batch [1360]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:04,296 Epoch[41] Batch [1370]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:12,660 Epoch[41] Batch [1380]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:21,445 Epoch[41] Batch [1390]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:29,682 Epoch[41] Batch [1400]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:37,100 Epoch[41] Batch [1410]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:44,241 Epoch[41] Batch [1420]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:51,518 Epoch[41] Batch [1430]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:58:58,743 Epoch[41] Batch [1440]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:59:06,443 Epoch[41] Batch [1450]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:59:14,606 Epoch[41] Batch [1460]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:59:22,526 Epoch[41] Batch [1470]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:59:30,404 Epoch[41] Batch [1480]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:59:35,470 Epoch[41] Train-FCNLogLoss=nan
2017-07-14 05:59:35,471 Epoch[41] Time cost=1197.142
2017-07-14 05:59:36,697 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.params"
2017-07-14 05:59:40,624 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.states"
2017-07-14 05:59:50,504 Epoch[42] Batch [10]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 05:59:59,228 Epoch[42] Batch [20]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:00:06,661 Epoch[42] Batch [30]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:00:14,662 Epoch[42] Batch [40]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:00:22,790 Epoch[42] Batch [50]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:00:31,079 Epoch[42] Batch [60]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:00:38,409 Epoch[42] Batch [70]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:00:45,735 Epoch[42] Batch [80]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:00:53,001 Epoch[42] Batch [90]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:00,324 Epoch[42] Batch [100]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:07,840 Epoch[42] Batch [110]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:15,373 Epoch[42] Batch [120]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:22,813 Epoch[42] Batch [130]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:30,197 Epoch[42] Batch [140]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:37,760 Epoch[42] Batch [150]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:45,026 Epoch[42] Batch [160]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:01:52,701 Epoch[42] Batch [170]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:00,385 Epoch[42] Batch [180]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:08,130 Epoch[42] Batch [190]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:16,096 Epoch[42] Batch [200]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:24,049 Epoch[42] Batch [210]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:31,728 Epoch[42] Batch [220]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:39,594 Epoch[42] Batch [230]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:47,063 Epoch[42] Batch [240]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:02:55,029 Epoch[42] Batch [250]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:02,793 Epoch[42] Batch [260]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:10,561 Epoch[42] Batch [270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:18,676 Epoch[42] Batch [280]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:26,468 Epoch[42] Batch [290]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:34,531 Epoch[42] Batch [300]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:41,944 Epoch[42] Batch [310]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:50,048 Epoch[42] Batch [320]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:03:58,278 Epoch[42] Batch [330]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:04:06,277 Epoch[42] Batch [340]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:04:14,319 Epoch[42] Batch [350]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:04:22,306 Epoch[42] Batch [360]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:04:30,320 Epoch[42] Batch [370]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:04:38,308 Epoch[42] Batch [380]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:04:46,336 Epoch[42] Batch [390]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:04:54,287 Epoch[42] Batch [400]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:02,148 Epoch[42] Batch [410]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:10,356 Epoch[42] Batch [420]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:18,395 Epoch[42] Batch [430]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:26,157 Epoch[42] Batch [440]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:33,944 Epoch[42] Batch [450]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:41,734 Epoch[42] Batch [460]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:50,012 Epoch[42] Batch [470]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:05:57,812 Epoch[42] Batch [480]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:06:05,921 Epoch[42] Batch [490]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:06:13,911 Epoch[42] Batch [500]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:06:22,015 Epoch[42] Batch [510]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:06:30,008 Epoch[42] Batch [520]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:06:38,069 Epoch[42] Batch [530]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:06:45,621 Epoch[42] Batch [540]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:06:53,466 Epoch[42] Batch [550]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:01,611 Epoch[42] Batch [560]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:08,995 Epoch[42] Batch [570]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:17,191 Epoch[42] Batch [580]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:25,191 Epoch[42] Batch [590]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:33,576 Epoch[42] Batch [600]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:41,654 Epoch[42] Batch [610]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:49,512 Epoch[42] Batch [620]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:07:56,793 Epoch[42] Batch [630]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:04,393 Epoch[42] Batch [640]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:11,860 Epoch[42] Batch [650]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:19,173 Epoch[42] Batch [660]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:26,476 Epoch[42] Batch [670]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:33,436 Epoch[42] Batch [680]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:40,661 Epoch[42] Batch [690]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:47,959 Epoch[42] Batch [700]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:08:56,023 Epoch[42] Batch [710]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:04,042 Epoch[42] Batch [720]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:12,059 Epoch[42] Batch [730]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:19,463 Epoch[42] Batch [740]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:26,948 Epoch[42] Batch [750]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:34,318 Epoch[42] Batch [760]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:41,713 Epoch[42] Batch [770]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:49,092 Epoch[42] Batch [780]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:09:56,279 Epoch[42] Batch [790]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:03,925 Epoch[42] Batch [800]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:11,146 Epoch[42] Batch [810]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:18,239 Epoch[42] Batch [820]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:25,266 Epoch[42] Batch [830]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:32,734 Epoch[42] Batch [840]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:39,936 Epoch[42] Batch [850]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:46,976 Epoch[42] Batch [860]	Speed: 5.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:10:54,658 Epoch[42] Batch [870]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:01,729 Epoch[42] Batch [880]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:08,893 Epoch[42] Batch [890]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:16,268 Epoch[42] Batch [900]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:23,736 Epoch[42] Batch [910]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:30,968 Epoch[42] Batch [920]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:38,489 Epoch[42] Batch [930]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:45,948 Epoch[42] Batch [940]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:11:53,385 Epoch[42] Batch [950]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:00,663 Epoch[42] Batch [960]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:07,996 Epoch[42] Batch [970]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:15,314 Epoch[42] Batch [980]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:22,750 Epoch[42] Batch [990]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:30,236 Epoch[42] Batch [1000]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:37,232 Epoch[42] Batch [1010]	Speed: 5.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:44,507 Epoch[42] Batch [1020]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:51,751 Epoch[42] Batch [1030]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:12:59,210 Epoch[42] Batch [1040]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:13:07,449 Epoch[42] Batch [1050]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:13:15,333 Epoch[42] Batch [1060]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:13:23,276 Epoch[42] Batch [1070]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:13:31,339 Epoch[42] Batch [1080]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:13:39,157 Epoch[42] Batch [1090]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:13:47,418 Epoch[42] Batch [1100]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:13:55,573 Epoch[42] Batch [1110]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:03,704 Epoch[42] Batch [1120]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:11,524 Epoch[42] Batch [1130]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:19,644 Epoch[42] Batch [1140]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:27,808 Epoch[42] Batch [1150]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:35,813 Epoch[42] Batch [1160]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:43,779 Epoch[42] Batch [1170]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:51,865 Epoch[42] Batch [1180]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:14:59,918 Epoch[42] Batch [1190]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:15:07,995 Epoch[42] Batch [1200]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:15:15,486 Epoch[42] Batch [1210]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:15:22,819 Epoch[42] Batch [1220]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:15:30,081 Epoch[42] Batch [1230]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:15:37,307 Epoch[42] Batch [1240]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:15:44,571 Epoch[42] Batch [1250]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:15:52,100 Epoch[42] Batch [1260]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:00,345 Epoch[42] Batch [1270]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:07,711 Epoch[42] Batch [1280]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:15,672 Epoch[42] Batch [1290]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:23,269 Epoch[42] Batch [1300]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:30,491 Epoch[42] Batch [1310]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:37,831 Epoch[42] Batch [1320]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:45,145 Epoch[42] Batch [1330]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:16:52,698 Epoch[42] Batch [1340]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:00,245 Epoch[42] Batch [1350]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:07,698 Epoch[42] Batch [1360]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:14,970 Epoch[42] Batch [1370]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:22,454 Epoch[42] Batch [1380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:30,668 Epoch[42] Batch [1390]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:38,151 Epoch[42] Batch [1400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:45,781 Epoch[42] Batch [1410]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:17:53,896 Epoch[42] Batch [1420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:18:01,725 Epoch[42] Batch [1430]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:18:09,264 Epoch[42] Batch [1440]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:18:16,462 Epoch[42] Batch [1450]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:18:23,649 Epoch[42] Batch [1460]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:18:31,180 Epoch[42] Batch [1470]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:18:38,593 Epoch[42] Batch [1480]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:18:42,934 Epoch[42] Train-FCNLogLoss=nan
2017-07-14 06:18:42,935 Epoch[42] Time cost=1142.310
2017-07-14 06:18:44,282 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.params"
2017-07-14 06:18:48,310 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.states"
2017-07-14 06:18:56,684 Epoch[43] Batch [10]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:03,793 Epoch[43] Batch [20]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:11,142 Epoch[43] Batch [30]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:18,279 Epoch[43] Batch [40]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:25,689 Epoch[43] Batch [50]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:32,854 Epoch[43] Batch [60]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:39,801 Epoch[43] Batch [70]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:47,045 Epoch[43] Batch [80]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:19:54,536 Epoch[43] Batch [90]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:01,886 Epoch[43] Batch [100]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:09,430 Epoch[43] Batch [110]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:17,014 Epoch[43] Batch [120]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:24,326 Epoch[43] Batch [130]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:31,582 Epoch[43] Batch [140]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:38,827 Epoch[43] Batch [150]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:45,768 Epoch[43] Batch [160]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:20:53,182 Epoch[43] Batch [170]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:00,514 Epoch[43] Batch [180]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:07,728 Epoch[43] Batch [190]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:15,514 Epoch[43] Batch [200]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:23,236 Epoch[43] Batch [210]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:30,929 Epoch[43] Batch [220]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:39,037 Epoch[43] Batch [230]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:46,475 Epoch[43] Batch [240]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:21:53,860 Epoch[43] Batch [250]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:01,785 Epoch[43] Batch [260]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:09,639 Epoch[43] Batch [270]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:17,681 Epoch[43] Batch [280]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:25,403 Epoch[43] Batch [290]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:33,361 Epoch[43] Batch [300]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:41,416 Epoch[43] Batch [310]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:48,338 Epoch[43] Batch [320]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:22:55,262 Epoch[43] Batch [330]	Speed: 5.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:02,510 Epoch[43] Batch [340]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:10,283 Epoch[43] Batch [350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:18,228 Epoch[43] Batch [360]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:25,954 Epoch[43] Batch [370]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:33,508 Epoch[43] Batch [380]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:41,367 Epoch[43] Batch [390]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:49,734 Epoch[43] Batch [400]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:23:57,880 Epoch[43] Batch [410]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:24:05,782 Epoch[43] Batch [420]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:24:14,119 Epoch[43] Batch [430]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:24:22,882 Epoch[43] Batch [440]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:24:31,510 Epoch[43] Batch [450]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:24:40,079 Epoch[43] Batch [460]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:24:48,319 Epoch[43] Batch [470]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:24:56,719 Epoch[43] Batch [480]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:04,803 Epoch[43] Batch [490]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:12,410 Epoch[43] Batch [500]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:20,284 Epoch[43] Batch [510]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:28,125 Epoch[43] Batch [520]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:35,940 Epoch[43] Batch [530]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:43,436 Epoch[43] Batch [540]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:51,334 Epoch[43] Batch [550]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:25:59,211 Epoch[43] Batch [560]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:26:06,511 Epoch[43] Batch [570]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:26:14,453 Epoch[43] Batch [580]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:26:22,139 Epoch[43] Batch [590]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:26:30,272 Epoch[43] Batch [600]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:26:38,028 Epoch[43] Batch [610]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:26:45,770 Epoch[43] Batch [620]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:26:53,530 Epoch[43] Batch [630]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:01,005 Epoch[43] Batch [640]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:08,441 Epoch[43] Batch [650]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:16,036 Epoch[43] Batch [660]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:23,441 Epoch[43] Batch [670]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:30,352 Epoch[43] Batch [680]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:38,420 Epoch[43] Batch [690]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:46,064 Epoch[43] Batch [700]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:27:54,194 Epoch[43] Batch [710]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:01,686 Epoch[43] Batch [720]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:09,573 Epoch[43] Batch [730]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:17,665 Epoch[43] Batch [740]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:26,120 Epoch[43] Batch [750]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:34,380 Epoch[43] Batch [760]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:42,754 Epoch[43] Batch [770]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:51,211 Epoch[43] Batch [780]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:28:59,578 Epoch[43] Batch [790]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:29:07,745 Epoch[43] Batch [800]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:29:15,846 Epoch[43] Batch [810]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:29:23,997 Epoch[43] Batch [820]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:29:32,628 Epoch[43] Batch [830]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:29:40,972 Epoch[43] Batch [840]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:29:49,712 Epoch[43] Batch [850]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:29:58,038 Epoch[43] Batch [860]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:30:06,658 Epoch[43] Batch [870]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:30:14,771 Epoch[43] Batch [880]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:30:22,667 Epoch[43] Batch [890]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:30:31,014 Epoch[43] Batch [900]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:30:38,753 Epoch[43] Batch [910]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:30:46,085 Epoch[43] Batch [920]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:30:53,409 Epoch[43] Batch [930]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:00,686 Epoch[43] Batch [940]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:08,426 Epoch[43] Batch [950]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:16,403 Epoch[43] Batch [960]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:24,465 Epoch[43] Batch [970]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:32,465 Epoch[43] Batch [980]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:39,670 Epoch[43] Batch [990]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:46,747 Epoch[43] Batch [1000]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:31:54,068 Epoch[43] Batch [1010]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:01,132 Epoch[43] Batch [1020]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:08,286 Epoch[43] Batch [1030]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:16,019 Epoch[43] Batch [1040]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:24,030 Epoch[43] Batch [1050]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:32,263 Epoch[43] Batch [1060]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:40,151 Epoch[43] Batch [1070]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:48,030 Epoch[43] Batch [1080]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:32:55,883 Epoch[43] Batch [1090]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:33:03,628 Epoch[43] Batch [1100]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:33:11,962 Epoch[43] Batch [1110]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:33:20,359 Epoch[43] Batch [1120]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:33:28,714 Epoch[43] Batch [1130]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:33:36,927 Epoch[43] Batch [1140]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:33:44,776 Epoch[43] Batch [1150]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:33:52,421 Epoch[43] Batch [1160]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:00,211 Epoch[43] Batch [1170]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:07,631 Epoch[43] Batch [1180]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:15,274 Epoch[43] Batch [1190]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:23,093 Epoch[43] Batch [1200]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:31,024 Epoch[43] Batch [1210]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:38,761 Epoch[43] Batch [1220]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:46,163 Epoch[43] Batch [1230]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:34:53,322 Epoch[43] Batch [1240]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:00,590 Epoch[43] Batch [1250]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:07,595 Epoch[43] Batch [1260]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:15,035 Epoch[43] Batch [1270]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:22,507 Epoch[43] Batch [1280]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:30,094 Epoch[43] Batch [1290]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:37,695 Epoch[43] Batch [1300]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:45,265 Epoch[43] Batch [1310]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:35:52,670 Epoch[43] Batch [1320]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:00,353 Epoch[43] Batch [1330]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:07,886 Epoch[43] Batch [1340]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:15,842 Epoch[43] Batch [1350]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:23,654 Epoch[43] Batch [1360]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:30,988 Epoch[43] Batch [1370]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:38,751 Epoch[43] Batch [1380]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:45,904 Epoch[43] Batch [1390]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:52,595 Epoch[43] Batch [1400]	Speed: 5.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:36:59,937 Epoch[43] Batch [1410]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:07,382 Epoch[43] Batch [1420]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:14,646 Epoch[43] Batch [1430]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:22,105 Epoch[43] Batch [1440]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:29,877 Epoch[43] Batch [1450]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:37,624 Epoch[43] Batch [1460]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:44,768 Epoch[43] Batch [1470]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:52,345 Epoch[43] Batch [1480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:37:57,046 Epoch[43] Train-FCNLogLoss=nan
2017-07-14 06:37:57,046 Epoch[43] Time cost=1148.736
2017-07-14 06:37:58,067 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.params"
2017-07-14 06:38:01,974 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.states"
2017-07-14 06:38:10,563 Epoch[44] Batch [10]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:38:18,133 Epoch[44] Batch [20]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:38:25,702 Epoch[44] Batch [30]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:38:33,027 Epoch[44] Batch [40]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:38:41,117 Epoch[44] Batch [50]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:38:49,399 Epoch[44] Batch [60]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:38:57,819 Epoch[44] Batch [70]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:05,426 Epoch[44] Batch [80]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:12,835 Epoch[44] Batch [90]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:20,231 Epoch[44] Batch [100]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:27,826 Epoch[44] Batch [110]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:35,319 Epoch[44] Batch [120]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:42,970 Epoch[44] Batch [130]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:50,331 Epoch[44] Batch [140]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:39:57,619 Epoch[44] Batch [150]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:05,006 Epoch[44] Batch [160]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:12,587 Epoch[44] Batch [170]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:20,290 Epoch[44] Batch [180]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:28,118 Epoch[44] Batch [190]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:35,672 Epoch[44] Batch [200]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:43,295 Epoch[44] Batch [210]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:50,978 Epoch[44] Batch [220]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:40:58,851 Epoch[44] Batch [230]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:41:06,407 Epoch[44] Batch [240]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:41:14,186 Epoch[44] Batch [250]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:41:21,486 Epoch[44] Batch [260]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:41:29,149 Epoch[44] Batch [270]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:41:37,330 Epoch[44] Batch [280]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:41:45,166 Epoch[44] Batch [290]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:41:52,757 Epoch[44] Batch [300]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:00,793 Epoch[44] Batch [310]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:08,690 Epoch[44] Batch [320]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:16,827 Epoch[44] Batch [330]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:24,739 Epoch[44] Batch [340]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:32,664 Epoch[44] Batch [350]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:40,562 Epoch[44] Batch [360]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:48,740 Epoch[44] Batch [370]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:42:56,430 Epoch[44] Batch [380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:43:04,637 Epoch[44] Batch [390]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:43:12,581 Epoch[44] Batch [400]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:43:20,617 Epoch[44] Batch [410]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:43:28,566 Epoch[44] Batch [420]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:43:36,579 Epoch[44] Batch [430]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:43:44,808 Epoch[44] Batch [440]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:43:52,926 Epoch[44] Batch [450]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:01,121 Epoch[44] Batch [460]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:09,196 Epoch[44] Batch [470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:17,397 Epoch[44] Batch [480]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:25,362 Epoch[44] Batch [490]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:33,222 Epoch[44] Batch [500]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:41,480 Epoch[44] Batch [510]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:49,615 Epoch[44] Batch [520]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:44:57,738 Epoch[44] Batch [530]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:45:06,045 Epoch[44] Batch [540]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:45:14,111 Epoch[44] Batch [550]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:45:22,057 Epoch[44] Batch [560]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:45:30,114 Epoch[44] Batch [570]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:45:38,004 Epoch[44] Batch [580]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:45:46,037 Epoch[44] Batch [590]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:45:54,256 Epoch[44] Batch [600]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:02,405 Epoch[44] Batch [610]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:10,507 Epoch[44] Batch [620]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:18,778 Epoch[44] Batch [630]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:27,466 Epoch[44] Batch [640]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:35,101 Epoch[44] Batch [650]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:42,500 Epoch[44] Batch [660]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:50,076 Epoch[44] Batch [670]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:46:57,446 Epoch[44] Batch [680]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:04,963 Epoch[44] Batch [690]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:12,511 Epoch[44] Batch [700]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:20,164 Epoch[44] Batch [710]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:27,902 Epoch[44] Batch [720]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:35,129 Epoch[44] Batch [730]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:42,481 Epoch[44] Batch [740]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:49,696 Epoch[44] Batch [750]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:47:57,072 Epoch[44] Batch [760]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:04,597 Epoch[44] Batch [770]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:12,405 Epoch[44] Batch [780]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:19,842 Epoch[44] Batch [790]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:27,133 Epoch[44] Batch [800]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:34,530 Epoch[44] Batch [810]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:42,032 Epoch[44] Batch [820]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:49,441 Epoch[44] Batch [830]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:48:56,949 Epoch[44] Batch [840]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:04,375 Epoch[44] Batch [850]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:11,892 Epoch[44] Batch [860]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:19,569 Epoch[44] Batch [870]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:26,932 Epoch[44] Batch [880]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:34,504 Epoch[44] Batch [890]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:41,819 Epoch[44] Batch [900]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:49,402 Epoch[44] Batch [910]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:49:56,546 Epoch[44] Batch [920]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:03,962 Epoch[44] Batch [930]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:11,391 Epoch[44] Batch [940]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:18,837 Epoch[44] Batch [950]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:26,390 Epoch[44] Batch [960]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:33,827 Epoch[44] Batch [970]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:41,398 Epoch[44] Batch [980]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:48,721 Epoch[44] Batch [990]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:50:56,110 Epoch[44] Batch [1000]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:03,567 Epoch[44] Batch [1010]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:11,039 Epoch[44] Batch [1020]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:18,508 Epoch[44] Batch [1030]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:25,970 Epoch[44] Batch [1040]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:33,449 Epoch[44] Batch [1050]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:40,821 Epoch[44] Batch [1060]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:48,148 Epoch[44] Batch [1070]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:51:55,604 Epoch[44] Batch [1080]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:02,979 Epoch[44] Batch [1090]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:11,049 Epoch[44] Batch [1100]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:19,095 Epoch[44] Batch [1110]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:27,071 Epoch[44] Batch [1120]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:35,161 Epoch[44] Batch [1130]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:43,264 Epoch[44] Batch [1140]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:51,525 Epoch[44] Batch [1150]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:52:59,753 Epoch[44] Batch [1160]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:53:07,749 Epoch[44] Batch [1170]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:53:15,563 Epoch[44] Batch [1180]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:53:22,786 Epoch[44] Batch [1190]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:53:30,283 Epoch[44] Batch [1200]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:53:37,848 Epoch[44] Batch [1210]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:53:45,470 Epoch[44] Batch [1220]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:53:52,958 Epoch[44] Batch [1230]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:00,413 Epoch[44] Batch [1240]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:07,617 Epoch[44] Batch [1250]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:15,093 Epoch[44] Batch [1260]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:22,288 Epoch[44] Batch [1270]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:29,821 Epoch[44] Batch [1280]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:37,350 Epoch[44] Batch [1290]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:44,686 Epoch[44] Batch [1300]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:51,990 Epoch[44] Batch [1310]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:54:59,453 Epoch[44] Batch [1320]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:06,659 Epoch[44] Batch [1330]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:14,076 Epoch[44] Batch [1340]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:21,542 Epoch[44] Batch [1350]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:29,119 Epoch[44] Batch [1360]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:36,471 Epoch[44] Batch [1370]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:43,766 Epoch[44] Batch [1380]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:51,278 Epoch[44] Batch [1390]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:55:58,659 Epoch[44] Batch [1400]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:06,126 Epoch[44] Batch [1410]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:13,536 Epoch[44] Batch [1420]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:21,115 Epoch[44] Batch [1430]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:28,494 Epoch[44] Batch [1440]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:35,886 Epoch[44] Batch [1450]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:43,450 Epoch[44] Batch [1460]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:50,767 Epoch[44] Batch [1470]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:56:58,660 Epoch[44] Batch [1480]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:57:03,460 Epoch[44] Train-FCNLogLoss=nan
2017-07-14 06:57:03,460 Epoch[44] Time cost=1141.485
2017-07-14 06:57:04,629 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.params"
2017-07-14 06:57:08,488 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.states"
2017-07-14 06:57:16,608 Epoch[45] Batch [10]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:57:23,950 Epoch[45] Batch [20]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:57:31,317 Epoch[45] Batch [30]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:57:38,536 Epoch[45] Batch [40]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:57:46,249 Epoch[45] Batch [50]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:57:53,662 Epoch[45] Batch [60]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:01,088 Epoch[45] Batch [70]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:08,722 Epoch[45] Batch [80]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:16,065 Epoch[45] Batch [90]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:23,702 Epoch[45] Batch [100]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:31,458 Epoch[45] Batch [110]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:38,882 Epoch[45] Batch [120]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:46,514 Epoch[45] Batch [130]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:58:54,119 Epoch[45] Batch [140]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:01,740 Epoch[45] Batch [150]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:09,318 Epoch[45] Batch [160]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:16,759 Epoch[45] Batch [170]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:24,501 Epoch[45] Batch [180]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:31,960 Epoch[45] Batch [190]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:39,588 Epoch[45] Batch [200]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:46,985 Epoch[45] Batch [210]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 06:59:54,385 Epoch[45] Batch [220]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:01,761 Epoch[45] Batch [230]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:09,133 Epoch[45] Batch [240]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:16,586 Epoch[45] Batch [250]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:23,673 Epoch[45] Batch [260]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:31,160 Epoch[45] Batch [270]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:38,679 Epoch[45] Batch [280]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:46,121 Epoch[45] Batch [290]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:00:53,672 Epoch[45] Batch [300]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:00,900 Epoch[45] Batch [310]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:08,063 Epoch[45] Batch [320]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:15,954 Epoch[45] Batch [330]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:23,356 Epoch[45] Batch [340]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:30,714 Epoch[45] Batch [350]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:38,380 Epoch[45] Batch [360]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:45,631 Epoch[45] Batch [370]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:01:53,234 Epoch[45] Batch [380]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:00,830 Epoch[45] Batch [390]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:08,324 Epoch[45] Batch [400]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:15,919 Epoch[45] Batch [410]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:23,747 Epoch[45] Batch [420]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:31,177 Epoch[45] Batch [430]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:40,030 Epoch[45] Batch [440]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:49,018 Epoch[45] Batch [450]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:02:57,489 Epoch[45] Batch [460]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:05,970 Epoch[45] Batch [470]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:13,935 Epoch[45] Batch [480]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:21,580 Epoch[45] Batch [490]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:29,033 Epoch[45] Batch [500]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:36,708 Epoch[45] Batch [510]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:44,112 Epoch[45] Batch [520]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:51,576 Epoch[45] Batch [530]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:03:58,892 Epoch[45] Batch [540]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:06,585 Epoch[45] Batch [550]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:14,019 Epoch[45] Batch [560]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:21,703 Epoch[45] Batch [570]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:29,270 Epoch[45] Batch [580]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:36,767 Epoch[45] Batch [590]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:44,429 Epoch[45] Batch [600]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:51,991 Epoch[45] Batch [610]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:04:59,256 Epoch[45] Batch [620]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:06,745 Epoch[45] Batch [630]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:14,203 Epoch[45] Batch [640]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:21,837 Epoch[45] Batch [650]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:29,360 Epoch[45] Batch [660]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:36,949 Epoch[45] Batch [670]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:44,546 Epoch[45] Batch [680]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:52,133 Epoch[45] Batch [690]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:05:59,578 Epoch[45] Batch [700]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:06:07,269 Epoch[45] Batch [710]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:06:14,874 Epoch[45] Batch [720]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:06:22,495 Epoch[45] Batch [730]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:06:30,004 Epoch[45] Batch [740]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:06:37,638 Epoch[45] Batch [750]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:06:45,290 Epoch[45] Batch [760]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:06:52,762 Epoch[45] Batch [770]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:00,994 Epoch[45] Batch [780]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:09,406 Epoch[45] Batch [790]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:17,509 Epoch[45] Batch [800]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:25,826 Epoch[45] Batch [810]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:33,918 Epoch[45] Batch [820]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:42,257 Epoch[45] Batch [830]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:50,424 Epoch[45] Batch [840]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:07:58,589 Epoch[45] Batch [850]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:08:06,680 Epoch[45] Batch [860]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:08:14,993 Epoch[45] Batch [870]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:08:23,211 Epoch[45] Batch [880]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:08:31,382 Epoch[45] Batch [890]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:08:39,516 Epoch[45] Batch [900]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:08:47,739 Epoch[45] Batch [910]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:08:55,913 Epoch[45] Batch [920]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:09:04,200 Epoch[45] Batch [930]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:09:12,398 Epoch[45] Batch [940]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:09:20,317 Epoch[45] Batch [950]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:09:28,457 Epoch[45] Batch [960]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:09:36,556 Epoch[45] Batch [970]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:09:44,757 Epoch[45] Batch [980]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:09:52,858 Epoch[45] Batch [990]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:01,021 Epoch[45] Batch [1000]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:09,011 Epoch[45] Batch [1010]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:17,180 Epoch[45] Batch [1020]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:25,243 Epoch[45] Batch [1030]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:33,356 Epoch[45] Batch [1040]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:41,666 Epoch[45] Batch [1050]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:49,519 Epoch[45] Batch [1060]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:10:57,698 Epoch[45] Batch [1070]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:11:05,914 Epoch[45] Batch [1080]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:11:13,982 Epoch[45] Batch [1090]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:11:21,964 Epoch[45] Batch [1100]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:11:30,183 Epoch[45] Batch [1110]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:11:38,506 Epoch[45] Batch [1120]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:11:46,619 Epoch[45] Batch [1130]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:11:54,283 Epoch[45] Batch [1140]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:01,922 Epoch[45] Batch [1150]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:09,623 Epoch[45] Batch [1160]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:17,147 Epoch[45] Batch [1170]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:25,118 Epoch[45] Batch [1180]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:32,951 Epoch[45] Batch [1190]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:41,021 Epoch[45] Batch [1200]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:48,785 Epoch[45] Batch [1210]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:12:56,907 Epoch[45] Batch [1220]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:13:04,970 Epoch[45] Batch [1230]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:13:13,012 Epoch[45] Batch [1240]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:13:21,169 Epoch[45] Batch [1250]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:13:29,063 Epoch[45] Batch [1260]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:13:37,014 Epoch[45] Batch [1270]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:13:44,988 Epoch[45] Batch [1280]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:13:53,201 Epoch[45] Batch [1290]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:01,252 Epoch[45] Batch [1300]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:09,385 Epoch[45] Batch [1310]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:16,981 Epoch[45] Batch [1320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:24,809 Epoch[45] Batch [1330]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:32,677 Epoch[45] Batch [1340]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:40,639 Epoch[45] Batch [1350]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:48,504 Epoch[45] Batch [1360]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:14:56,724 Epoch[45] Batch [1370]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:15:05,422 Epoch[45] Batch [1380]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:15:13,559 Epoch[45] Batch [1390]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:15:21,616 Epoch[45] Batch [1400]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:15:29,587 Epoch[45] Batch [1410]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:15:37,566 Epoch[45] Batch [1420]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:15:45,487 Epoch[45] Batch [1430]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:15:52,822 Epoch[45] Batch [1440]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:16:00,043 Epoch[45] Batch [1450]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:16:07,426 Epoch[45] Batch [1460]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:16:14,593 Epoch[45] Batch [1470]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:16:21,985 Epoch[45] Batch [1480]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:16:26,457 Epoch[45] Train-FCNLogLoss=nan
2017-07-14 07:16:26,457 Epoch[45] Time cost=1157.969
2017-07-14 07:16:27,548 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.params"
2017-07-14 07:16:31,444 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.states"
2017-07-14 07:16:39,943 Epoch[46] Batch [10]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:16:47,071 Epoch[46] Batch [20]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:16:54,653 Epoch[46] Batch [30]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:02,199 Epoch[46] Batch [40]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:09,360 Epoch[46] Batch [50]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:16,637 Epoch[46] Batch [60]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:24,106 Epoch[46] Batch [70]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:31,544 Epoch[46] Batch [80]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:38,977 Epoch[46] Batch [90]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:46,381 Epoch[46] Batch [100]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:17:53,826 Epoch[46] Batch [110]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:01,403 Epoch[46] Batch [120]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:09,047 Epoch[46] Batch [130]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:16,609 Epoch[46] Batch [140]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:23,720 Epoch[46] Batch [150]	Speed: 5.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:31,340 Epoch[46] Batch [160]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:38,972 Epoch[46] Batch [170]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:46,924 Epoch[46] Batch [180]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:18:54,908 Epoch[46] Batch [190]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:02,541 Epoch[46] Batch [200]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:11,053 Epoch[46] Batch [210]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:19,552 Epoch[46] Batch [220]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:27,635 Epoch[46] Batch [230]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:34,983 Epoch[46] Batch [240]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:42,302 Epoch[46] Batch [250]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:50,358 Epoch[46] Batch [260]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:19:58,417 Epoch[46] Batch [270]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:20:06,889 Epoch[46] Batch [280]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:20:15,428 Epoch[46] Batch [290]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:20:23,548 Epoch[46] Batch [300]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:20:32,035 Epoch[46] Batch [310]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:20:40,115 Epoch[46] Batch [320]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:20:48,175 Epoch[46] Batch [330]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:20:56,268 Epoch[46] Batch [340]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:21:04,499 Epoch[46] Batch [350]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:21:13,376 Epoch[46] Batch [360]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:21:22,177 Epoch[46] Batch [370]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:21:30,325 Epoch[46] Batch [380]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:21:37,891 Epoch[46] Batch [390]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:21:46,510 Epoch[46] Batch [400]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:21:55,383 Epoch[46] Batch [410]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:22:03,859 Epoch[46] Batch [420]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:22:11,959 Epoch[46] Batch [430]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:22:20,222 Epoch[46] Batch [440]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:22:28,463 Epoch[46] Batch [450]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:22:36,327 Epoch[46] Batch [460]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:22:44,420 Epoch[46] Batch [470]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:22:52,779 Epoch[46] Batch [480]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:01,058 Epoch[46] Batch [490]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:09,176 Epoch[46] Batch [500]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:17,267 Epoch[46] Batch [510]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:25,412 Epoch[46] Batch [520]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:33,312 Epoch[46] Batch [530]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:41,263 Epoch[46] Batch [540]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:49,639 Epoch[46] Batch [550]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:23:57,894 Epoch[46] Batch [560]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:24:06,221 Epoch[46] Batch [570]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:24:14,403 Epoch[46] Batch [580]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:24:22,555 Epoch[46] Batch [590]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:24:30,638 Epoch[46] Batch [600]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:24:38,941 Epoch[46] Batch [610]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:24:47,146 Epoch[46] Batch [620]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:24:55,090 Epoch[46] Batch [630]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:03,226 Epoch[46] Batch [640]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:11,247 Epoch[46] Batch [650]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:19,507 Epoch[46] Batch [660]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:27,226 Epoch[46] Batch [670]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:35,459 Epoch[46] Batch [680]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:43,724 Epoch[46] Batch [690]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:51,873 Epoch[46] Batch [700]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:25:59,868 Epoch[46] Batch [710]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:26:07,898 Epoch[46] Batch [720]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:26:16,044 Epoch[46] Batch [730]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:26:24,131 Epoch[46] Batch [740]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:26:32,447 Epoch[46] Batch [750]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:26:40,768 Epoch[46] Batch [760]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:26:49,022 Epoch[46] Batch [770]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:26:57,274 Epoch[46] Batch [780]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:27:05,474 Epoch[46] Batch [790]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:27:13,617 Epoch[46] Batch [800]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:27:21,784 Epoch[46] Batch [810]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:27:30,042 Epoch[46] Batch [820]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:27:38,186 Epoch[46] Batch [830]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:27:46,399 Epoch[46] Batch [840]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:27:54,363 Epoch[46] Batch [850]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:02,297 Epoch[46] Batch [860]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:10,573 Epoch[46] Batch [870]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:18,524 Epoch[46] Batch [880]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:26,634 Epoch[46] Batch [890]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:34,635 Epoch[46] Batch [900]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:42,794 Epoch[46] Batch [910]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:51,043 Epoch[46] Batch [920]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:28:59,144 Epoch[46] Batch [930]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:29:07,355 Epoch[46] Batch [940]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:29:15,448 Epoch[46] Batch [950]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:29:23,534 Epoch[46] Batch [960]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:29:31,609 Epoch[46] Batch [970]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:29:39,697 Epoch[46] Batch [980]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:29:47,866 Epoch[46] Batch [990]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:29:56,155 Epoch[46] Batch [1000]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:30:04,034 Epoch[46] Batch [1010]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:30:12,211 Epoch[46] Batch [1020]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:30:20,389 Epoch[46] Batch [1030]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:30:28,567 Epoch[46] Batch [1040]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:30:36,689 Epoch[46] Batch [1050]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:30:44,816 Epoch[46] Batch [1060]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:30:52,893 Epoch[46] Batch [1070]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:01,112 Epoch[46] Batch [1080]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:09,344 Epoch[46] Batch [1090]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:17,457 Epoch[46] Batch [1100]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:25,529 Epoch[46] Batch [1110]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:33,500 Epoch[46] Batch [1120]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:41,510 Epoch[46] Batch [1130]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:49,313 Epoch[46] Batch [1140]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:31:57,479 Epoch[46] Batch [1150]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:32:05,498 Epoch[46] Batch [1160]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:32:13,638 Epoch[46] Batch [1170]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:32:21,538 Epoch[46] Batch [1180]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:32:29,580 Epoch[46] Batch [1190]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:32:37,710 Epoch[46] Batch [1200]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:32:46,187 Epoch[46] Batch [1210]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:32:54,404 Epoch[46] Batch [1220]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:33:02,625 Epoch[46] Batch [1230]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:33:10,726 Epoch[46] Batch [1240]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:33:18,815 Epoch[46] Batch [1250]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:33:26,992 Epoch[46] Batch [1260]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:33:34,993 Epoch[46] Batch [1270]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:33:43,294 Epoch[46] Batch [1280]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:33:51,755 Epoch[46] Batch [1290]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:00,028 Epoch[46] Batch [1300]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:08,271 Epoch[46] Batch [1310]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:16,140 Epoch[46] Batch [1320]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:24,344 Epoch[46] Batch [1330]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:32,448 Epoch[46] Batch [1340]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:40,497 Epoch[46] Batch [1350]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:48,653 Epoch[46] Batch [1360]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:34:56,683 Epoch[46] Batch [1370]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:35:04,997 Epoch[46] Batch [1380]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:35:13,391 Epoch[46] Batch [1390]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:35:21,525 Epoch[46] Batch [1400]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:35:29,608 Epoch[46] Batch [1410]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:35:37,836 Epoch[46] Batch [1420]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:35:45,947 Epoch[46] Batch [1430]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:35:54,047 Epoch[46] Batch [1440]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:36:02,149 Epoch[46] Batch [1450]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:36:10,788 Epoch[46] Batch [1460]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:36:19,161 Epoch[46] Batch [1470]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:36:26,807 Epoch[46] Batch [1480]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:36:31,245 Epoch[46] Train-FCNLogLoss=nan
2017-07-14 07:36:31,246 Epoch[46] Time cost=1199.801
2017-07-14 07:36:32,342 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.params"
2017-07-14 07:36:36,406 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.states"
2017-07-14 07:36:44,923 Epoch[47] Batch [10]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:36:52,258 Epoch[47] Batch [20]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:00,185 Epoch[47] Batch [30]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:07,887 Epoch[47] Batch [40]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:16,176 Epoch[47] Batch [50]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:24,488 Epoch[47] Batch [60]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:32,541 Epoch[47] Batch [70]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:40,589 Epoch[47] Batch [80]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:48,425 Epoch[47] Batch [90]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:37:56,792 Epoch[47] Batch [100]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:04,995 Epoch[47] Batch [110]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:13,245 Epoch[47] Batch [120]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:21,286 Epoch[47] Batch [130]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:29,046 Epoch[47] Batch [140]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:36,646 Epoch[47] Batch [150]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:43,951 Epoch[47] Batch [160]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:51,507 Epoch[47] Batch [170]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:38:58,937 Epoch[47] Batch [180]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:06,855 Epoch[47] Batch [190]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:14,546 Epoch[47] Batch [200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:22,727 Epoch[47] Batch [210]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:29,841 Epoch[47] Batch [220]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:37,412 Epoch[47] Batch [230]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:44,628 Epoch[47] Batch [240]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:51,857 Epoch[47] Batch [250]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:39:59,566 Epoch[47] Batch [260]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:40:07,040 Epoch[47] Batch [270]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:40:14,190 Epoch[47] Batch [280]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:40:21,775 Epoch[47] Batch [290]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:40:29,262 Epoch[47] Batch [300]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:40:36,682 Epoch[47] Batch [310]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:40:44,892 Epoch[47] Batch [320]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:40:52,903 Epoch[47] Batch [330]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:00,670 Epoch[47] Batch [340]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:08,043 Epoch[47] Batch [350]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:15,469 Epoch[47] Batch [360]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:23,032 Epoch[47] Batch [370]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:30,571 Epoch[47] Batch [380]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:38,188 Epoch[47] Batch [390]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:46,093 Epoch[47] Batch [400]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:41:53,278 Epoch[47] Batch [410]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:00,945 Epoch[47] Batch [420]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:08,625 Epoch[47] Batch [430]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:16,647 Epoch[47] Batch [440]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:25,881 Epoch[47] Batch [450]	Speed: 4.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:34,552 Epoch[47] Batch [460]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:41,856 Epoch[47] Batch [470]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:49,427 Epoch[47] Batch [480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:42:57,012 Epoch[47] Batch [490]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:04,970 Epoch[47] Batch [500]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:12,463 Epoch[47] Batch [510]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:20,215 Epoch[47] Batch [520]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:27,879 Epoch[47] Batch [530]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:35,126 Epoch[47] Batch [540]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:42,698 Epoch[47] Batch [550]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:50,037 Epoch[47] Batch [560]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:43:57,189 Epoch[47] Batch [570]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:04,973 Epoch[47] Batch [580]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:12,666 Epoch[47] Batch [590]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:20,322 Epoch[47] Batch [600]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:27,959 Epoch[47] Batch [610]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:35,420 Epoch[47] Batch [620]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:43,223 Epoch[47] Batch [630]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:50,697 Epoch[47] Batch [640]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:44:58,138 Epoch[47] Batch [650]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:05,940 Epoch[47] Batch [660]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:13,603 Epoch[47] Batch [670]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:21,184 Epoch[47] Batch [680]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:28,856 Epoch[47] Batch [690]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:36,284 Epoch[47] Batch [700]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:44,237 Epoch[47] Batch [710]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:51,892 Epoch[47] Batch [720]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:45:58,942 Epoch[47] Batch [730]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:05,997 Epoch[47] Batch [740]	Speed: 5.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:12,911 Epoch[47] Batch [750]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:20,100 Epoch[47] Batch [760]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:27,442 Epoch[47] Batch [770]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:34,383 Epoch[47] Batch [780]	Speed: 5.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:41,559 Epoch[47] Batch [790]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:48,517 Epoch[47] Batch [800]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:46:55,924 Epoch[47] Batch [810]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:02,953 Epoch[47] Batch [820]	Speed: 5.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:10,099 Epoch[47] Batch [830]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:17,254 Epoch[47] Batch [840]	Speed: 5.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:24,852 Epoch[47] Batch [850]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:32,505 Epoch[47] Batch [860]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:39,901 Epoch[47] Batch [870]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:47,443 Epoch[47] Batch [880]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:47:54,818 Epoch[47] Batch [890]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:02,361 Epoch[47] Batch [900]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:09,875 Epoch[47] Batch [910]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:16,879 Epoch[47] Batch [920]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:24,291 Epoch[47] Batch [930]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:31,199 Epoch[47] Batch [940]	Speed: 5.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:38,402 Epoch[47] Batch [950]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:45,384 Epoch[47] Batch [960]	Speed: 5.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:52,551 Epoch[47] Batch [970]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:48:59,553 Epoch[47] Batch [980]	Speed: 5.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:06,919 Epoch[47] Batch [990]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:14,127 Epoch[47] Batch [1000]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:21,209 Epoch[47] Batch [1010]	Speed: 5.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:28,474 Epoch[47] Batch [1020]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:35,686 Epoch[47] Batch [1030]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:42,660 Epoch[47] Batch [1040]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:49,913 Epoch[47] Batch [1050]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:49:56,976 Epoch[47] Batch [1060]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:04,388 Epoch[47] Batch [1070]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:11,721 Epoch[47] Batch [1080]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:18,888 Epoch[47] Batch [1090]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:25,647 Epoch[47] Batch [1100]	Speed: 5.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:32,936 Epoch[47] Batch [1110]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:40,182 Epoch[47] Batch [1120]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:47,563 Epoch[47] Batch [1130]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:50:54,810 Epoch[47] Batch [1140]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:02,387 Epoch[47] Batch [1150]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:09,796 Epoch[47] Batch [1160]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:17,924 Epoch[47] Batch [1170]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:25,291 Epoch[47] Batch [1180]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:32,602 Epoch[47] Batch [1190]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:39,936 Epoch[47] Batch [1200]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:46,906 Epoch[47] Batch [1210]	Speed: 5.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:51:54,120 Epoch[47] Batch [1220]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:01,303 Epoch[47] Batch [1230]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:08,571 Epoch[47] Batch [1240]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:15,941 Epoch[47] Batch [1250]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:23,459 Epoch[47] Batch [1260]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:30,827 Epoch[47] Batch [1270]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:38,131 Epoch[47] Batch [1280]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:45,511 Epoch[47] Batch [1290]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:52:52,762 Epoch[47] Batch [1300]	Speed: 5.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:00,158 Epoch[47] Batch [1310]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:07,588 Epoch[47] Batch [1320]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:14,875 Epoch[47] Batch [1330]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:22,306 Epoch[47] Batch [1340]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:29,724 Epoch[47] Batch [1350]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:37,127 Epoch[47] Batch [1360]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:44,662 Epoch[47] Batch [1370]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:52,168 Epoch[47] Batch [1380]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:53:59,755 Epoch[47] Batch [1390]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:54:07,342 Epoch[47] Batch [1400]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:54:14,982 Epoch[47] Batch [1410]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:54:22,670 Epoch[47] Batch [1420]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:54:30,035 Epoch[47] Batch [1430]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:54:37,996 Epoch[47] Batch [1440]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:54:46,294 Epoch[47] Batch [1450]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:54:54,399 Epoch[47] Batch [1460]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:55:02,324 Epoch[47] Batch [1470]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:55:10,399 Epoch[47] Batch [1480]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:55:15,169 Epoch[47] Train-FCNLogLoss=nan
2017-07-14 07:55:15,169 Epoch[47] Time cost=1118.762
2017-07-14 07:55:16,250 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.params"
2017-07-14 07:55:20,150 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.states"
2017-07-14 07:55:28,475 Epoch[48] Batch [10]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:55:35,788 Epoch[48] Batch [20]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:55:43,257 Epoch[48] Batch [30]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:55:50,665 Epoch[48] Batch [40]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:55:58,099 Epoch[48] Batch [50]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:05,622 Epoch[48] Batch [60]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:12,881 Epoch[48] Batch [70]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:20,393 Epoch[48] Batch [80]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:27,959 Epoch[48] Batch [90]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:35,232 Epoch[48] Batch [100]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:42,548 Epoch[48] Batch [110]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:49,961 Epoch[48] Batch [120]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:56:57,196 Epoch[48] Batch [130]	Speed: 5.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:04,751 Epoch[48] Batch [140]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:12,156 Epoch[48] Batch [150]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:19,478 Epoch[48] Batch [160]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:26,991 Epoch[48] Batch [170]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:34,505 Epoch[48] Batch [180]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:41,848 Epoch[48] Batch [190]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:49,216 Epoch[48] Batch [200]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:57:56,661 Epoch[48] Batch [210]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:04,171 Epoch[48] Batch [220]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:11,549 Epoch[48] Batch [230]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:18,923 Epoch[48] Batch [240]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:26,216 Epoch[48] Batch [250]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:33,613 Epoch[48] Batch [260]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:41,169 Epoch[48] Batch [270]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:48,682 Epoch[48] Batch [280]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:58:56,230 Epoch[48] Batch [290]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:03,802 Epoch[48] Batch [300]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:11,025 Epoch[48] Batch [310]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:18,699 Epoch[48] Batch [320]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:26,227 Epoch[48] Batch [330]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:33,704 Epoch[48] Batch [340]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:41,062 Epoch[48] Batch [350]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:48,247 Epoch[48] Batch [360]	Speed: 5.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 07:59:55,896 Epoch[48] Batch [370]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:03,346 Epoch[48] Batch [380]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:11,034 Epoch[48] Batch [390]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:18,199 Epoch[48] Batch [400]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:25,704 Epoch[48] Batch [410]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:33,325 Epoch[48] Batch [420]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:41,214 Epoch[48] Batch [430]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:48,808 Epoch[48] Batch [440]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:00:56,287 Epoch[48] Batch [450]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:03,926 Epoch[48] Batch [460]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:11,607 Epoch[48] Batch [470]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:19,122 Epoch[48] Batch [480]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:26,883 Epoch[48] Batch [490]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:34,449 Epoch[48] Batch [500]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:42,262 Epoch[48] Batch [510]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:49,637 Epoch[48] Batch [520]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:01:57,634 Epoch[48] Batch [530]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:02:05,575 Epoch[48] Batch [540]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:02:13,601 Epoch[48] Batch [550]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:02:21,301 Epoch[48] Batch [560]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:02:29,253 Epoch[48] Batch [570]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:02:37,154 Epoch[48] Batch [580]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:02:45,313 Epoch[48] Batch [590]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:02:53,503 Epoch[48] Batch [600]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:01,671 Epoch[48] Batch [610]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:09,626 Epoch[48] Batch [620]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:17,884 Epoch[48] Batch [630]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:26,134 Epoch[48] Batch [640]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:34,111 Epoch[48] Batch [650]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:42,077 Epoch[48] Batch [660]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:50,054 Epoch[48] Batch [670]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:03:58,453 Epoch[48] Batch [680]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:04:06,403 Epoch[48] Batch [690]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:04:14,335 Epoch[48] Batch [700]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:04:22,002 Epoch[48] Batch [710]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:04:29,739 Epoch[48] Batch [720]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:04:37,736 Epoch[48] Batch [730]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:04:45,923 Epoch[48] Batch [740]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:04:54,804 Epoch[48] Batch [750]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:05:03,351 Epoch[48] Batch [760]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:05:11,900 Epoch[48] Batch [770]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:05:20,143 Epoch[48] Batch [780]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:05:28,894 Epoch[48] Batch [790]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:05:37,643 Epoch[48] Batch [800]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:05:46,200 Epoch[48] Batch [810]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:05:54,043 Epoch[48] Batch [820]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:01,919 Epoch[48] Batch [830]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:10,389 Epoch[48] Batch [840]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:18,946 Epoch[48] Batch [850]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:26,744 Epoch[48] Batch [860]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:34,604 Epoch[48] Batch [870]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:42,558 Epoch[48] Batch [880]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:50,454 Epoch[48] Batch [890]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:06:58,351 Epoch[48] Batch [900]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:07:05,898 Epoch[48] Batch [910]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:07:13,601 Epoch[48] Batch [920]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:07:21,672 Epoch[48] Batch [930]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:07:29,637 Epoch[48] Batch [940]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:07:38,163 Epoch[48] Batch [950]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:07:46,766 Epoch[48] Batch [960]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:07:55,469 Epoch[48] Batch [970]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:03,621 Epoch[48] Batch [980]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:11,965 Epoch[48] Batch [990]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:19,732 Epoch[48] Batch [1000]	Speed: 5.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:28,204 Epoch[48] Batch [1010]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:36,498 Epoch[48] Batch [1020]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:44,304 Epoch[48] Batch [1030]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:51,947 Epoch[48] Batch [1040]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:08:59,542 Epoch[48] Batch [1050]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:09:07,124 Epoch[48] Batch [1060]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:09:14,799 Epoch[48] Batch [1070]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:09:21,865 Epoch[48] Batch [1080]	Speed: 5.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:09:29,295 Epoch[48] Batch [1090]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:09:37,197 Epoch[48] Batch [1100]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:09:45,152 Epoch[48] Batch [1110]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:09:53,300 Epoch[48] Batch [1120]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:01,316 Epoch[48] Batch [1130]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:09,049 Epoch[48] Batch [1140]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:16,160 Epoch[48] Batch [1150]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:24,320 Epoch[48] Batch [1160]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:32,682 Epoch[48] Batch [1170]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:40,432 Epoch[48] Batch [1180]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:47,967 Epoch[48] Batch [1190]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:10:55,658 Epoch[48] Batch [1200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:11:03,812 Epoch[48] Batch [1210]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:11:11,866 Epoch[48] Batch [1220]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:11:19,887 Epoch[48] Batch [1230]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:11:27,886 Epoch[48] Batch [1240]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:11:35,893 Epoch[48] Batch [1250]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:11:43,863 Epoch[48] Batch [1260]	Speed: 5.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:11:51,818 Epoch[48] Batch [1270]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:00,138 Epoch[48] Batch [1280]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:08,396 Epoch[48] Batch [1290]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:16,408 Epoch[48] Batch [1300]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:24,633 Epoch[48] Batch [1310]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:32,922 Epoch[48] Batch [1320]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:40,975 Epoch[48] Batch [1330]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:49,178 Epoch[48] Batch [1340]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:12:57,401 Epoch[48] Batch [1350]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:13:05,964 Epoch[48] Batch [1360]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:13:14,464 Epoch[48] Batch [1370]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:13:23,391 Epoch[48] Batch [1380]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:13:32,082 Epoch[48] Batch [1390]	Speed: 4.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:13:40,703 Epoch[48] Batch [1400]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:13:49,497 Epoch[48] Batch [1410]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:13:58,635 Epoch[48] Batch [1420]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:14:07,626 Epoch[48] Batch [1430]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:14:16,455 Epoch[48] Batch [1440]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:14:25,309 Epoch[48] Batch [1450]	Speed: 4.52 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:14:35,267 Epoch[48] Batch [1460]	Speed: 4.02 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:14:43,869 Epoch[48] Batch [1470]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:14:52,361 Epoch[48] Batch [1480]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:14:57,584 Epoch[48] Train-FCNLogLoss=nan
2017-07-14 08:14:57,584 Epoch[48] Time cost=1177.434
2017-07-14 08:14:58,674 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.params"
2017-07-14 08:15:02,675 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.states"
2017-07-14 08:15:12,090 Epoch[49] Batch [10]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:15:20,306 Epoch[49] Batch [20]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:15:28,253 Epoch[49] Batch [30]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:15:36,531 Epoch[49] Batch [40]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:15:44,543 Epoch[49] Batch [50]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:15:52,665 Epoch[49] Batch [60]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:00,646 Epoch[49] Batch [70]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:08,829 Epoch[49] Batch [80]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:17,032 Epoch[49] Batch [90]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:25,341 Epoch[49] Batch [100]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:33,430 Epoch[49] Batch [110]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:41,693 Epoch[49] Batch [120]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:49,897 Epoch[49] Batch [130]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:16:58,017 Epoch[49] Batch [140]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:17:06,312 Epoch[49] Batch [150]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:17:14,388 Epoch[49] Batch [160]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:17:22,532 Epoch[49] Batch [170]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:17:30,825 Epoch[49] Batch [180]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:17:38,933 Epoch[49] Batch [190]	Speed: 4.93 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:17:47,230 Epoch[49] Batch [200]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:17:55,507 Epoch[49] Batch [210]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:18:03,688 Epoch[49] Batch [220]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:18:12,145 Epoch[49] Batch [230]	Speed: 4.73 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:18:20,932 Epoch[49] Batch [240]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:18:29,768 Epoch[49] Batch [250]	Speed: 4.53 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:18:38,488 Epoch[49] Batch [260]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:18:47,099 Epoch[49] Batch [270]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:18:55,986 Epoch[49] Batch [280]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:19:04,758 Epoch[49] Batch [290]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:19:13,115 Epoch[49] Batch [300]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:19:21,400 Epoch[49] Batch [310]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:19:29,504 Epoch[49] Batch [320]	Speed: 4.94 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:19:37,426 Epoch[49] Batch [330]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:19:45,735 Epoch[49] Batch [340]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:19:54,066 Epoch[49] Batch [350]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:20:02,463 Epoch[49] Batch [360]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:20:10,761 Epoch[49] Batch [370]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:20:19,119 Epoch[49] Batch [380]	Speed: 4.79 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:20:27,268 Epoch[49] Batch [390]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:20:35,432 Epoch[49] Batch [400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:20:43,473 Epoch[49] Batch [410]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:20:51,788 Epoch[49] Batch [420]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:00,098 Epoch[49] Batch [430]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:08,351 Epoch[49] Batch [440]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:16,357 Epoch[49] Batch [450]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:25,043 Epoch[49] Batch [460]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:33,421 Epoch[49] Batch [470]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:41,968 Epoch[49] Batch [480]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:50,026 Epoch[49] Batch [490]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:21:57,758 Epoch[49] Batch [500]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:05,583 Epoch[49] Batch [510]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:13,294 Epoch[49] Batch [520]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:20,722 Epoch[49] Batch [530]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:28,093 Epoch[49] Batch [540]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:35,877 Epoch[49] Batch [550]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:43,322 Epoch[49] Batch [560]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:50,596 Epoch[49] Batch [570]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:22:58,169 Epoch[49] Batch [580]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:05,828 Epoch[49] Batch [590]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:13,418 Epoch[49] Batch [600]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:20,757 Epoch[49] Batch [610]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:28,382 Epoch[49] Batch [620]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:36,076 Epoch[49] Batch [630]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:43,889 Epoch[49] Batch [640]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:51,389 Epoch[49] Batch [650]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:23:59,140 Epoch[49] Batch [660]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:06,730 Epoch[49] Batch [670]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:14,394 Epoch[49] Batch [680]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:21,818 Epoch[49] Batch [690]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:29,310 Epoch[49] Batch [700]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:36,858 Epoch[49] Batch [710]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:44,321 Epoch[49] Batch [720]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:51,838 Epoch[49] Batch [730]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:24:59,494 Epoch[49] Batch [740]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:25:07,121 Epoch[49] Batch [750]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:25:14,967 Epoch[49] Batch [760]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:25:23,153 Epoch[49] Batch [770]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:25:31,664 Epoch[49] Batch [780]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:25:40,160 Epoch[49] Batch [790]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:25:48,239 Epoch[49] Batch [800]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:25:56,406 Epoch[49] Batch [810]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:26:04,915 Epoch[49] Batch [820]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:26:13,463 Epoch[49] Batch [830]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:26:21,851 Epoch[49] Batch [840]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:26:30,463 Epoch[49] Batch [850]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:26:38,839 Epoch[49] Batch [860]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:26:47,468 Epoch[49] Batch [870]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:26:56,148 Epoch[49] Batch [880]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:04,469 Epoch[49] Batch [890]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:12,038 Epoch[49] Batch [900]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:19,743 Epoch[49] Batch [910]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:27,045 Epoch[49] Batch [920]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:34,507 Epoch[49] Batch [930]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:41,892 Epoch[49] Batch [940]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:49,390 Epoch[49] Batch [950]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:27:56,921 Epoch[49] Batch [960]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:04,523 Epoch[49] Batch [970]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:12,191 Epoch[49] Batch [980]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:19,994 Epoch[49] Batch [990]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:27,495 Epoch[49] Batch [1000]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:35,165 Epoch[49] Batch [1010]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:42,719 Epoch[49] Batch [1020]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:50,588 Epoch[49] Batch [1030]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:28:57,936 Epoch[49] Batch [1040]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:05,368 Epoch[49] Batch [1050]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:12,764 Epoch[49] Batch [1060]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:20,361 Epoch[49] Batch [1070]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:27,659 Epoch[49] Batch [1080]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:35,091 Epoch[49] Batch [1090]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:42,209 Epoch[49] Batch [1100]	Speed: 5.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:49,585 Epoch[49] Batch [1110]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:29:57,053 Epoch[49] Batch [1120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:04,525 Epoch[49] Batch [1130]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:12,187 Epoch[49] Batch [1140]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:20,103 Epoch[49] Batch [1150]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:27,601 Epoch[49] Batch [1160]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:35,140 Epoch[49] Batch [1170]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:42,587 Epoch[49] Batch [1180]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:50,218 Epoch[49] Batch [1190]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:30:57,576 Epoch[49] Batch [1200]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:05,148 Epoch[49] Batch [1210]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:12,716 Epoch[49] Batch [1220]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:20,454 Epoch[49] Batch [1230]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:28,279 Epoch[49] Batch [1240]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:35,957 Epoch[49] Batch [1250]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:43,698 Epoch[49] Batch [1260]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:51,534 Epoch[49] Batch [1270]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:31:58,724 Epoch[49] Batch [1280]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:32:06,099 Epoch[49] Batch [1290]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:32:14,077 Epoch[49] Batch [1300]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:32:21,958 Epoch[49] Batch [1310]	Speed: 5.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:32:29,513 Epoch[49] Batch [1320]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:32:37,244 Epoch[49] Batch [1330]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:32:44,917 Epoch[49] Batch [1340]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:32:52,703 Epoch[49] Batch [1350]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:00,015 Epoch[49] Batch [1360]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:07,666 Epoch[49] Batch [1370]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:15,229 Epoch[49] Batch [1380]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:23,068 Epoch[49] Batch [1390]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:30,912 Epoch[49] Batch [1400]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:38,523 Epoch[49] Batch [1410]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:46,056 Epoch[49] Batch [1420]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:33:53,681 Epoch[49] Batch [1430]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:34:01,695 Epoch[49] Batch [1440]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:34:10,244 Epoch[49] Batch [1450]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:34:18,471 Epoch[49] Batch [1460]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:34:26,713 Epoch[49] Batch [1470]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:34:34,796 Epoch[49] Batch [1480]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:34:39,608 Epoch[49] Train-FCNLogLoss=nan
2017-07-14 08:34:39,608 Epoch[49] Time cost=1176.932
2017-07-14 08:34:40,717 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.params"
2017-07-14 08:34:44,599 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.states"
2017-07-14 08:34:53,353 Epoch[50] Batch [10]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:00,723 Epoch[50] Batch [20]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:08,105 Epoch[50] Batch [30]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:15,512 Epoch[50] Batch [40]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:23,050 Epoch[50] Batch [50]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:30,644 Epoch[50] Batch [60]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:38,032 Epoch[50] Batch [70]	Speed: 5.42 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:45,483 Epoch[50] Batch [80]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:35:53,058 Epoch[50] Batch [90]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:00,385 Epoch[50] Batch [100]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:07,835 Epoch[50] Batch [110]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:15,181 Epoch[50] Batch [120]	Speed: 5.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:22,613 Epoch[50] Batch [130]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:30,119 Epoch[50] Batch [140]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:37,522 Epoch[50] Batch [150]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:44,876 Epoch[50] Batch [160]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:52,354 Epoch[50] Batch [170]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:36:59,763 Epoch[50] Batch [180]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:37:07,169 Epoch[50] Batch [190]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:37:14,799 Epoch[50] Batch [200]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:37:22,440 Epoch[50] Batch [210]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:37:29,995 Epoch[50] Batch [220]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:37:37,443 Epoch[50] Batch [230]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:37:45,099 Epoch[50] Batch [240]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:37:52,427 Epoch[50] Batch [250]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:00,065 Epoch[50] Batch [260]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:07,674 Epoch[50] Batch [270]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:15,210 Epoch[50] Batch [280]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:22,722 Epoch[50] Batch [290]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:30,110 Epoch[50] Batch [300]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:37,608 Epoch[50] Batch [310]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:44,958 Epoch[50] Batch [320]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:38:52,590 Epoch[50] Batch [330]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:39:00,047 Epoch[50] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:39:07,369 Epoch[50] Batch [350]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:39:14,951 Epoch[50] Batch [360]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:39:22,606 Epoch[50] Batch [370]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:39:30,044 Epoch[50] Batch [380]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:39:42,914 Epoch[50] Batch [390]	Speed: 3.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:39:53,310 Epoch[50] Batch [400]	Speed: 3.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:01,379 Epoch[50] Batch [410]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:08,815 Epoch[50] Batch [420]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:16,208 Epoch[50] Batch [430]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:23,620 Epoch[50] Batch [440]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:31,072 Epoch[50] Batch [450]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:38,354 Epoch[50] Batch [460]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:45,482 Epoch[50] Batch [470]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:52,810 Epoch[50] Batch [480]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:40:59,764 Epoch[50] Batch [490]	Speed: 5.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:06,861 Epoch[50] Batch [500]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:14,299 Epoch[50] Batch [510]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:21,646 Epoch[50] Batch [520]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:29,070 Epoch[50] Batch [530]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:36,552 Epoch[50] Batch [540]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:43,755 Epoch[50] Batch [550]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:51,306 Epoch[50] Batch [560]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:41:58,780 Epoch[50] Batch [570]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:06,051 Epoch[50] Batch [580]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:13,707 Epoch[50] Batch [590]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:20,831 Epoch[50] Batch [600]	Speed: 5.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:28,273 Epoch[50] Batch [610]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:35,590 Epoch[50] Batch [620]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:42,783 Epoch[50] Batch [630]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:50,322 Epoch[50] Batch [640]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:42:57,888 Epoch[50] Batch [650]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:05,254 Epoch[50] Batch [660]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:12,795 Epoch[50] Batch [670]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:20,414 Epoch[50] Batch [680]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:27,926 Epoch[50] Batch [690]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:35,226 Epoch[50] Batch [700]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:42,646 Epoch[50] Batch [710]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:50,150 Epoch[50] Batch [720]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:43:57,676 Epoch[50] Batch [730]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:05,115 Epoch[50] Batch [740]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:12,608 Epoch[50] Batch [750]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:20,054 Epoch[50] Batch [760]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:27,323 Epoch[50] Batch [770]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:34,710 Epoch[50] Batch [780]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:42,106 Epoch[50] Batch [790]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:49,821 Epoch[50] Batch [800]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:44:57,272 Epoch[50] Batch [810]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:04,492 Epoch[50] Batch [820]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:12,102 Epoch[50] Batch [830]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:19,467 Epoch[50] Batch [840]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:26,888 Epoch[50] Batch [850]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:34,169 Epoch[50] Batch [860]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:41,626 Epoch[50] Batch [870]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:49,160 Epoch[50] Batch [880]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:45:56,690 Epoch[50] Batch [890]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:04,109 Epoch[50] Batch [900]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:11,597 Epoch[50] Batch [910]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:19,154 Epoch[50] Batch [920]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:26,787 Epoch[50] Batch [930]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:34,135 Epoch[50] Batch [940]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:41,583 Epoch[50] Batch [950]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:49,035 Epoch[50] Batch [960]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:46:56,255 Epoch[50] Batch [970]	Speed: 5.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:03,901 Epoch[50] Batch [980]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:11,409 Epoch[50] Batch [990]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:19,020 Epoch[50] Batch [1000]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:26,585 Epoch[50] Batch [1010]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:34,248 Epoch[50] Batch [1020]	Speed: 5.22 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:41,773 Epoch[50] Batch [1030]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:49,060 Epoch[50] Batch [1040]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:47:56,549 Epoch[50] Batch [1050]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:03,751 Epoch[50] Batch [1060]	Speed: 5.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:11,158 Epoch[50] Batch [1070]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:18,672 Epoch[50] Batch [1080]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:26,204 Epoch[50] Batch [1090]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:33,555 Epoch[50] Batch [1100]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:41,108 Epoch[50] Batch [1110]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:48,682 Epoch[50] Batch [1120]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:48:56,273 Epoch[50] Batch [1130]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:03,894 Epoch[50] Batch [1140]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:11,348 Epoch[50] Batch [1150]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:18,936 Epoch[50] Batch [1160]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:26,469 Epoch[50] Batch [1170]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:34,005 Epoch[50] Batch [1180]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:41,688 Epoch[50] Batch [1190]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:49,251 Epoch[50] Batch [1200]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:49:56,690 Epoch[50] Batch [1210]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:04,191 Epoch[50] Batch [1220]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:11,699 Epoch[50] Batch [1230]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:19,301 Epoch[50] Batch [1240]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:26,774 Epoch[50] Batch [1250]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:34,049 Epoch[50] Batch [1260]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:41,625 Epoch[50] Batch [1270]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:49,124 Epoch[50] Batch [1280]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:50:56,214 Epoch[50] Batch [1290]	Speed: 5.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:51:03,744 Epoch[50] Batch [1300]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:51:11,420 Epoch[50] Batch [1310]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:51:21,682 Epoch[50] Batch [1320]	Speed: 3.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:51:30,781 Epoch[50] Batch [1330]	Speed: 4.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:51:39,730 Epoch[50] Batch [1340]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:51:48,902 Epoch[50] Batch [1350]	Speed: 4.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:51:57,697 Epoch[50] Batch [1360]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:05,478 Epoch[50] Batch [1370]	Speed: 5.14 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:13,105 Epoch[50] Batch [1380]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:20,781 Epoch[50] Batch [1390]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:28,369 Epoch[50] Batch [1400]	Speed: 5.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:36,233 Epoch[50] Batch [1410]	Speed: 5.09 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:43,667 Epoch[50] Batch [1420]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:51,460 Epoch[50] Batch [1430]	Speed: 5.13 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:52:59,103 Epoch[50] Batch [1440]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:53:06,936 Epoch[50] Batch [1450]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:53:14,684 Epoch[50] Batch [1460]	Speed: 5.16 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:53:22,533 Epoch[50] Batch [1470]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:53:30,079 Epoch[50] Batch [1480]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:53:34,952 Epoch[50] Train-FCNLogLoss=nan
2017-07-14 08:53:34,952 Epoch[50] Time cost=1130.353
2017-07-14 08:53:36,209 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.params"
2017-07-14 08:53:40,391 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.states"
2017-07-14 08:53:49,098 Epoch[51] Batch [10]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:53:56,796 Epoch[51] Batch [20]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:04,163 Epoch[51] Batch [30]	Speed: 5.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:11,510 Epoch[51] Batch [40]	Speed: 5.44 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:19,041 Epoch[51] Batch [50]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:26,453 Epoch[51] Batch [60]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:33,920 Epoch[51] Batch [70]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:41,463 Epoch[51] Batch [80]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:49,301 Epoch[51] Batch [90]	Speed: 5.10 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:54:57,244 Epoch[51] Batch [100]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:55:05,721 Epoch[51] Batch [110]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:55:13,737 Epoch[51] Batch [120]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:55:22,057 Epoch[51] Batch [130]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:55:30,580 Epoch[51] Batch [140]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:55:38,975 Epoch[51] Batch [150]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:55:47,350 Epoch[51] Batch [160]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:55:55,487 Epoch[51] Batch [170]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:56:03,138 Epoch[51] Batch [180]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:56:11,164 Epoch[51] Batch [190]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:56:19,505 Epoch[51] Batch [200]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:56:27,558 Epoch[51] Batch [210]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:56:35,870 Epoch[51] Batch [220]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:56:44,614 Epoch[51] Batch [230]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:56:53,133 Epoch[51] Batch [240]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:57:01,677 Epoch[51] Batch [250]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:57:10,088 Epoch[51] Batch [260]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:57:18,556 Epoch[51] Batch [270]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:57:26,956 Epoch[51] Batch [280]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:57:35,675 Epoch[51] Batch [290]	Speed: 4.59 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:57:44,153 Epoch[51] Batch [300]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:57:52,753 Epoch[51] Batch [310]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:58:01,538 Epoch[51] Batch [320]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:58:10,172 Epoch[51] Batch [330]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:58:18,658 Epoch[51] Batch [340]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:58:27,275 Epoch[51] Batch [350]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:58:35,597 Epoch[51] Batch [360]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:58:44,032 Epoch[51] Batch [370]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:58:52,370 Epoch[51] Batch [380]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:00,254 Epoch[51] Batch [390]	Speed: 5.07 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:08,650 Epoch[51] Batch [400]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:16,595 Epoch[51] Batch [410]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:24,984 Epoch[51] Batch [420]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:33,317 Epoch[51] Batch [430]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:41,630 Epoch[51] Batch [440]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:49,682 Epoch[51] Batch [450]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 08:59:57,849 Epoch[51] Batch [460]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:00:06,102 Epoch[51] Batch [470]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:00:14,121 Epoch[51] Batch [480]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:00:22,411 Epoch[51] Batch [490]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:00:30,428 Epoch[51] Batch [500]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:00:38,830 Epoch[51] Batch [510]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:00:46,659 Epoch[51] Batch [520]	Speed: 5.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:00:54,379 Epoch[51] Batch [530]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:01,642 Epoch[51] Batch [540]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:08,909 Epoch[51] Batch [550]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:16,206 Epoch[51] Batch [560]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:23,727 Epoch[51] Batch [570]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:31,228 Epoch[51] Batch [580]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:38,846 Epoch[51] Batch [590]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:46,421 Epoch[51] Batch [600]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:01:53,813 Epoch[51] Batch [610]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:01,430 Epoch[51] Batch [620]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:08,984 Epoch[51] Batch [630]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:16,305 Epoch[51] Batch [640]	Speed: 5.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:23,955 Epoch[51] Batch [650]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:31,259 Epoch[51] Batch [660]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:39,447 Epoch[51] Batch [670]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:48,373 Epoch[51] Batch [680]	Speed: 4.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:02:55,795 Epoch[51] Batch [690]	Speed: 5.39 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:03,201 Epoch[51] Batch [700]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:10,595 Epoch[51] Batch [710]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:17,999 Epoch[51] Batch [720]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:25,146 Epoch[51] Batch [730]	Speed: 5.60 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:32,881 Epoch[51] Batch [740]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:40,322 Epoch[51] Batch [750]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:47,903 Epoch[51] Batch [760]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:03:55,303 Epoch[51] Batch [770]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:02,793 Epoch[51] Batch [780]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:10,055 Epoch[51] Batch [790]	Speed: 5.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:17,603 Epoch[51] Batch [800]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:25,070 Epoch[51] Batch [810]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:32,577 Epoch[51] Batch [820]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:39,865 Epoch[51] Batch [830]	Speed: 5.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:47,359 Epoch[51] Batch [840]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:04:55,551 Epoch[51] Batch [850]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:05:03,790 Epoch[51] Batch [860]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:05:11,931 Epoch[51] Batch [870]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:05:20,151 Epoch[51] Batch [880]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:05:28,536 Epoch[51] Batch [890]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:05:36,980 Epoch[51] Batch [900]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:05:45,779 Epoch[51] Batch [910]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:05:54,296 Epoch[51] Batch [920]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:06:02,292 Epoch[51] Batch [930]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:06:10,721 Epoch[51] Batch [940]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:06:19,108 Epoch[51] Batch [950]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:06:27,502 Epoch[51] Batch [960]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:06:36,403 Epoch[51] Batch [970]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:06:44,951 Epoch[51] Batch [980]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:06:53,429 Epoch[51] Batch [990]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:01,972 Epoch[51] Batch [1000]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:10,293 Epoch[51] Batch [1010]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:18,697 Epoch[51] Batch [1020]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:26,960 Epoch[51] Batch [1030]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:35,026 Epoch[51] Batch [1040]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:43,073 Epoch[51] Batch [1050]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:51,243 Epoch[51] Batch [1060]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:07:59,795 Epoch[51] Batch [1070]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:08:08,202 Epoch[51] Batch [1080]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:08:16,420 Epoch[51] Batch [1090]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:08:24,492 Epoch[51] Batch [1100]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:08:32,787 Epoch[51] Batch [1110]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:08:40,852 Epoch[51] Batch [1120]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:08:49,509 Epoch[51] Batch [1130]	Speed: 4.62 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:08:58,056 Epoch[51] Batch [1140]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:09:06,199 Epoch[51] Batch [1150]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:09:13,919 Epoch[51] Batch [1160]	Speed: 5.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:09:22,005 Epoch[51] Batch [1170]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:09:30,155 Epoch[51] Batch [1180]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:09:38,281 Epoch[51] Batch [1190]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:09:46,606 Epoch[51] Batch [1200]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:09:54,862 Epoch[51] Batch [1210]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:10:03,338 Epoch[51] Batch [1220]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:10:11,593 Epoch[51] Batch [1230]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:10:19,765 Epoch[51] Batch [1240]	Speed: 4.90 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:10:28,058 Epoch[51] Batch [1250]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:10:35,987 Epoch[51] Batch [1260]	Speed: 5.04 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:10:44,411 Epoch[51] Batch [1270]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:10:52,785 Epoch[51] Batch [1280]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:00,741 Epoch[51] Batch [1290]	Speed: 5.03 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:08,927 Epoch[51] Batch [1300]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:17,056 Epoch[51] Batch [1310]	Speed: 4.92 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:24,961 Epoch[51] Batch [1320]	Speed: 5.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:33,027 Epoch[51] Batch [1330]	Speed: 4.96 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:41,390 Epoch[51] Batch [1340]	Speed: 4.78 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:49,806 Epoch[51] Batch [1350]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:11:59,016 Epoch[51] Batch [1360]	Speed: 4.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:12:08,371 Epoch[51] Batch [1370]	Speed: 4.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:12:18,182 Epoch[51] Batch [1380]	Speed: 4.08 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:12:27,544 Epoch[51] Batch [1390]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:12:36,795 Epoch[51] Batch [1400]	Speed: 4.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:12:47,220 Epoch[51] Batch [1410]	Speed: 3.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:12:56,817 Epoch[51] Batch [1420]	Speed: 4.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:13:07,304 Epoch[51] Batch [1430]	Speed: 3.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:13:17,275 Epoch[51] Batch [1440]	Speed: 4.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:13:27,141 Epoch[51] Batch [1450]	Speed: 4.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:13:36,880 Epoch[51] Batch [1460]	Speed: 4.11 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:13:46,248 Epoch[51] Batch [1470]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:13:55,878 Epoch[51] Batch [1480]	Speed: 4.15 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:14:01,675 Epoch[51] Train-FCNLogLoss=nan
2017-07-14 09:14:01,675 Epoch[51] Time cost=1221.283
2017-07-14 09:14:02,907 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.params"
2017-07-14 09:14:07,696 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.states"
2017-07-14 09:14:17,833 Epoch[52] Batch [10]	Speed: 4.45 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:14:26,609 Epoch[52] Batch [20]	Speed: 4.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:14:35,516 Epoch[52] Batch [30]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:14:44,484 Epoch[52] Batch [40]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:14:53,109 Epoch[52] Batch [50]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:15:01,870 Epoch[52] Batch [60]	Speed: 4.57 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:15:10,809 Epoch[52] Batch [70]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:15:19,890 Epoch[52] Batch [80]	Speed: 4.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:15:28,804 Epoch[52] Batch [90]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:15:37,746 Epoch[52] Batch [100]	Speed: 4.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:15:46,633 Epoch[52] Batch [110]	Speed: 4.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:15:55,533 Epoch[52] Batch [120]	Speed: 4.49 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:03,134 Epoch[52] Batch [130]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:10,704 Epoch[52] Batch [140]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:18,230 Epoch[52] Batch [150]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:25,750 Epoch[52] Batch [160]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:33,257 Epoch[52] Batch [170]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:40,750 Epoch[52] Batch [180]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:48,251 Epoch[52] Batch [190]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:16:55,868 Epoch[52] Batch [200]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:03,414 Epoch[52] Batch [210]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:10,845 Epoch[52] Batch [220]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:18,276 Epoch[52] Batch [230]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:25,709 Epoch[52] Batch [240]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:33,244 Epoch[52] Batch [250]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:40,799 Epoch[52] Batch [260]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:48,077 Epoch[52] Batch [270]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:17:55,590 Epoch[52] Batch [280]	Speed: 5.32 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:18:03,063 Epoch[52] Batch [290]	Speed: 5.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:18:10,370 Epoch[52] Batch [300]	Speed: 5.48 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:18:23,761 Epoch[52] Batch [310]	Speed: 2.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:18:33,317 Epoch[52] Batch [320]	Speed: 4.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:18:41,055 Epoch[52] Batch [330]	Speed: 5.17 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:18:48,769 Epoch[52] Batch [340]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:18:56,259 Epoch[52] Batch [350]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:03,794 Epoch[52] Batch [360]	Speed: 5.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:11,251 Epoch[52] Batch [370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:19,231 Epoch[52] Batch [380]	Speed: 5.01 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:26,874 Epoch[52] Batch [390]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:34,509 Epoch[52] Batch [400]	Speed: 5.24 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:41,940 Epoch[52] Batch [410]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:49,588 Epoch[52] Batch [420]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:19:56,753 Epoch[52] Batch [430]	Speed: 5.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:04,299 Epoch[52] Batch [440]	Speed: 5.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:11,702 Epoch[52] Batch [450]	Speed: 5.40 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:18,898 Epoch[52] Batch [460]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:26,515 Epoch[52] Batch [470]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:33,959 Epoch[52] Batch [480]	Speed: 5.37 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:41,559 Epoch[52] Batch [490]	Speed: 5.26 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:49,122 Epoch[52] Batch [500]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:20:56,586 Epoch[52] Batch [510]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:03,977 Epoch[52] Batch [520]	Speed: 5.41 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:11,599 Epoch[52] Batch [530]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:19,057 Epoch[52] Batch [540]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:26,615 Epoch[52] Batch [550]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:34,309 Epoch[52] Batch [560]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:41,957 Epoch[52] Batch [570]	Speed: 5.23 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:49,444 Epoch[52] Batch [580]	Speed: 5.34 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:21:56,761 Epoch[52] Batch [590]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:04,385 Epoch[52] Batch [600]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:12,003 Epoch[52] Batch [610]	Speed: 5.25 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:19,509 Epoch[52] Batch [620]	Speed: 5.33 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:26,974 Epoch[52] Batch [630]	Speed: 5.36 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:34,251 Epoch[52] Batch [640]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:41,689 Epoch[52] Batch [650]	Speed: 5.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:49,250 Epoch[52] Batch [660]	Speed: 5.29 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:22:57,064 Epoch[52] Batch [670]	Speed: 5.12 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:04,750 Epoch[52] Batch [680]	Speed: 5.20 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:12,421 Epoch[52] Batch [690]	Speed: 5.21 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:19,691 Epoch[52] Batch [700]	Speed: 5.50 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:27,008 Epoch[52] Batch [710]	Speed: 5.47 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:34,578 Epoch[52] Batch [720]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:42,148 Epoch[52] Batch [730]	Speed: 5.28 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:49,342 Epoch[52] Batch [740]	Speed: 5.56 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:23:57,054 Epoch[52] Batch [750]	Speed: 5.19 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:24:05,261 Epoch[52] Batch [760]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:24:13,571 Epoch[52] Batch [770]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:24:21,717 Epoch[52] Batch [780]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:24:30,106 Epoch[52] Batch [790]	Speed: 4.77 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:24:38,287 Epoch[52] Batch [800]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:24:46,376 Epoch[52] Batch [810]	Speed: 4.95 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:24:54,415 Epoch[52] Batch [820]	Speed: 4.98 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:25:02,958 Epoch[52] Batch [830]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:25:11,362 Epoch[52] Batch [840]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:25:19,377 Epoch[52] Batch [850]	Speed: 4.99 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:25:27,671 Epoch[52] Batch [860]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:25:35,940 Epoch[52] Batch [870]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:25:44,448 Epoch[52] Batch [880]	Speed: 4.70 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:25:52,701 Epoch[52] Batch [890]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:01,020 Epoch[52] Batch [900]	Speed: 4.81 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:09,262 Epoch[52] Batch [910]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:17,270 Epoch[52] Batch [920]	Speed: 5.00 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:25,495 Epoch[52] Batch [930]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:33,770 Epoch[52] Batch [940]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:41,993 Epoch[52] Batch [950]	Speed: 4.86 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:50,264 Epoch[52] Batch [960]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:26:58,406 Epoch[52] Batch [970]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:27:06,458 Epoch[52] Batch [980]	Speed: 4.97 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:27:14,753 Epoch[52] Batch [990]	Speed: 4.82 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:27:22,676 Epoch[52] Batch [1000]	Speed: 5.05 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:27:31,002 Epoch[52] Batch [1010]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:27:39,638 Epoch[52] Batch [1020]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:27:47,928 Epoch[52] Batch [1030]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:27:56,801 Epoch[52] Batch [1040]	Speed: 4.51 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:28:05,277 Epoch[52] Batch [1050]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:28:14,240 Epoch[52] Batch [1060]	Speed: 4.46 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:28:22,676 Epoch[52] Batch [1070]	Speed: 4.74 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:28:31,297 Epoch[52] Batch [1080]	Speed: 4.64 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:28:39,624 Epoch[52] Batch [1090]	Speed: 4.80 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:28:48,163 Epoch[52] Batch [1100]	Speed: 4.68 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:28:56,961 Epoch[52] Batch [1110]	Speed: 4.55 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:29:05,369 Epoch[52] Batch [1120]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:29:14,112 Epoch[52] Batch [1130]	Speed: 4.58 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:29:22,916 Epoch[52] Batch [1140]	Speed: 4.54 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:29:31,551 Epoch[52] Batch [1150]	Speed: 4.63 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:29:39,981 Epoch[52] Batch [1160]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:29:48,464 Epoch[52] Batch [1170]	Speed: 4.72 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:29:56,728 Epoch[52] Batch [1180]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:30:05,010 Epoch[52] Batch [1190]	Speed: 4.83 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:30:14,136 Epoch[52] Batch [1200]	Speed: 4.38 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:30:22,712 Epoch[52] Batch [1210]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:30:30,916 Epoch[52] Batch [1220]	Speed: 4.88 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:30:39,410 Epoch[52] Batch [1230]	Speed: 4.71 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:30:48,017 Epoch[52] Batch [1240]	Speed: 4.65 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:30:56,234 Epoch[52] Batch [1250]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:31:04,908 Epoch[52] Batch [1260]	Speed: 4.61 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:31:13,085 Epoch[52] Batch [1270]	Speed: 4.89 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:31:21,512 Epoch[52] Batch [1280]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:31:29,909 Epoch[52] Batch [1290]	Speed: 4.76 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:31:38,162 Epoch[52] Batch [1300]	Speed: 4.85 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:31:46,698 Epoch[52] Batch [1310]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:31:55,119 Epoch[52] Batch [1320]	Speed: 4.75 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:32:03,260 Epoch[52] Batch [1330]	Speed: 4.91 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:32:11,520 Epoch[52] Batch [1340]	Speed: 4.84 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:32:20,098 Epoch[52] Batch [1350]	Speed: 4.66 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:32:28,670 Epoch[52] Batch [1360]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:32:37,194 Epoch[52] Batch [1370]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:32:45,401 Epoch[52] Batch [1380]	Speed: 4.87 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:32:53,924 Epoch[52] Batch [1390]	Speed: 4.69 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:33:02,956 Epoch[52] Batch [1400]	Speed: 4.43 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:33:11,515 Epoch[52] Batch [1410]	Speed: 4.67 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:33:21,079 Epoch[52] Batch [1420]	Speed: 4.18 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:33:30,265 Epoch[52] Batch [1430]	Speed: 4.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:33:39,572 Epoch[52] Batch [1440]	Speed: 4.30 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:33:49,421 Epoch[52] Batch [1450]	Speed: 4.06 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:33:58,787 Epoch[52] Batch [1460]	Speed: 4.27 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:34:08,068 Epoch[52] Batch [1470]	Speed: 4.31 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:34:17,262 Epoch[52] Batch [1480]	Speed: 4.35 samples/sec	Train-FCNLogLoss=nan,	
2017-07-14 09:34:23,161 Epoch[52] Train-FCNLogLoss=nan
2017-07-14 09:34:23,162 Epoch[52] Time cost=1215.465
2017-07-14 09:34:24,272 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.params"
2017-07-14 09:34:28,176 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.states"
2017-07-14 09:34:28,196 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-14 09:34:36,606 testing 4/500 data 1.3451s net 0.3531s post 0.0070s
2017-07-14 09:34:37,944 testing 8/500 data 1.1814s net 0.3334s post 0.0070s
2017-07-14 09:34:39,339 testing 12/500 data 1.1488s net 0.3234s post 0.0072s
2017-07-14 09:34:40,702 testing 16/500 data 1.1250s net 0.3179s post 0.0075s
2017-07-14 09:34:42,062 testing 20/500 data 1.1086s net 0.3165s post 0.0073s
2017-07-14 09:34:43,394 testing 24/500 data 1.0950s net 0.3132s post 0.0074s
2017-07-14 09:34:44,779 testing 28/500 data 1.0926s net 0.3113s post 0.0073s
2017-07-14 09:34:46,100 testing 32/500 data 1.0814s net 0.3113s post 0.0072s
2017-07-14 09:34:47,489 testing 36/500 data 1.0804s net 0.3111s post 0.0072s
2017-07-14 09:34:48,838 testing 40/500 data 1.0769s net 0.3096s post 0.0072s
2017-07-14 09:34:50,143 testing 44/500 data 1.0701s net 0.3083s post 0.0072s
2017-07-14 09:34:51,520 testing 48/500 data 1.0697s net 0.3080s post 0.0072s
2017-07-14 09:34:52,872 testing 52/500 data 1.0678s net 0.3072s post 0.0074s
2017-07-14 09:34:54,214 testing 56/500 data 1.0657s net 0.3064s post 0.0074s
2017-07-14 09:34:55,558 testing 60/500 data 1.0638s net 0.3059s post 0.0074s
2017-07-14 09:34:56,902 testing 64/500 data 1.0617s net 0.3057s post 0.0077s
2017-07-14 09:34:58,286 testing 68/500 data 1.0623s net 0.3056s post 0.0077s
2017-07-14 09:34:59,624 testing 72/500 data 1.0604s net 0.3053s post 0.0077s
2017-07-14 09:35:00,904 testing 76/500 data 1.0562s net 0.3047s post 0.0077s
2017-07-14 09:35:02,292 testing 80/500 data 1.0570s net 0.3049s post 0.0077s
2017-07-14 09:35:03,684 testing 84/500 data 1.0578s net 0.3052s post 0.0076s
2017-07-14 09:35:04,957 testing 88/500 data 1.0537s net 0.3048s post 0.0076s
2017-07-14 09:35:06,275 testing 92/500 data 1.0518s net 0.3047s post 0.0076s
2017-07-14 09:35:07,638 testing 96/500 data 1.0522s net 0.3043s post 0.0076s
2017-07-14 09:35:09,023 testing 100/500 data 1.0528s net 0.3043s post 0.0078s
2017-07-14 09:35:10,444 testing 104/500 data 1.0548s net 0.3045s post 0.0078s
2017-07-14 09:35:11,819 testing 108/500 data 1.0548s net 0.3048s post 0.0077s
2017-07-14 09:35:13,176 testing 112/500 data 1.0549s net 0.3043s post 0.0077s
2017-07-14 09:35:14,478 testing 116/500 data 1.0529s net 0.3042s post 0.0076s
2017-07-14 09:35:15,867 testing 120/500 data 1.0540s net 0.3039s post 0.0076s
2017-07-14 09:35:17,216 testing 124/500 data 1.0535s net 0.3038s post 0.0077s
2017-07-14 09:35:18,567 testing 128/500 data 1.0534s net 0.3035s post 0.0077s
2017-07-14 09:35:19,952 testing 132/500 data 1.0539s net 0.3036s post 0.0076s
2017-07-14 09:35:21,312 testing 136/500 data 1.0539s net 0.3035s post 0.0076s
2017-07-14 09:35:22,614 testing 140/500 data 1.0523s net 0.3033s post 0.0076s
2017-07-14 09:35:23,966 testing 144/500 data 1.0522s net 0.3031s post 0.0076s
2017-07-14 09:35:25,311 testing 148/500 data 1.0516s net 0.3032s post 0.0076s
2017-07-14 09:35:26,659 testing 152/500 data 1.0514s net 0.3031s post 0.0076s
2017-07-14 09:35:27,983 testing 156/500 data 1.0506s net 0.3030s post 0.0076s
2017-07-14 09:35:29,357 testing 160/500 data 1.0511s net 0.3028s post 0.0075s
2017-07-14 09:35:30,725 testing 164/500 data 1.0511s net 0.3030s post 0.0075s
2017-07-14 09:35:32,062 testing 168/500 data 1.0508s net 0.3027s post 0.0075s
2017-07-14 09:35:33,368 testing 172/500 data 1.0494s net 0.3027s post 0.0075s
2017-07-14 09:35:34,710 testing 176/500 data 1.0492s net 0.3026s post 0.0075s
2017-07-14 09:35:36,047 testing 180/500 data 1.0485s net 0.3028s post 0.0075s
2017-07-14 09:35:37,391 testing 184/500 data 1.0483s net 0.3028s post 0.0075s
2017-07-14 09:35:38,829 testing 188/500 data 1.0499s net 0.3028s post 0.0074s
2017-07-14 09:35:40,175 testing 192/500 data 1.0497s net 0.3027s post 0.0074s
2017-07-14 09:35:41,535 testing 196/500 data 1.0499s net 0.3025s post 0.0074s
2017-07-14 09:35:42,929 testing 200/500 data 1.0507s net 0.3025s post 0.0074s
2017-07-14 09:35:44,268 testing 204/500 data 1.0505s net 0.3023s post 0.0074s
2017-07-14 09:35:45,594 testing 208/500 data 1.0499s net 0.3022s post 0.0074s
2017-07-14 09:35:47,000 testing 212/500 data 1.0509s net 0.3021s post 0.0074s
2017-07-14 09:35:48,364 testing 216/500 data 1.0510s net 0.3021s post 0.0073s
2017-07-14 09:35:49,721 testing 220/500 data 1.0508s net 0.3022s post 0.0073s
2017-07-14 09:35:51,081 testing 224/500 data 1.0509s net 0.3022s post 0.0073s
2017-07-14 09:35:52,398 testing 228/500 data 1.0501s net 0.3022s post 0.0073s
2017-07-14 09:35:53,741 testing 232/500 data 1.0499s net 0.3021s post 0.0073s
2017-07-14 09:35:55,091 testing 236/500 data 1.0496s net 0.3022s post 0.0073s
2017-07-14 09:35:56,446 testing 240/500 data 1.0496s net 0.3022s post 0.0073s
2017-07-14 09:35:57,836 testing 244/500 data 1.0499s net 0.3023s post 0.0074s
2017-07-14 09:35:59,152 testing 248/500 data 1.0493s net 0.3023s post 0.0073s
2017-07-14 09:36:00,530 testing 252/500 data 1.0495s net 0.3023s post 0.0073s
2017-07-14 09:36:01,836 testing 256/500 data 1.0488s net 0.3023s post 0.0073s
2017-07-14 09:36:03,178 testing 260/500 data 1.0486s net 0.3023s post 0.0073s
2017-07-14 09:36:04,524 testing 264/500 data 1.0484s net 0.3023s post 0.0073s
2017-07-14 09:36:05,864 testing 268/500 data 1.0482s net 0.3022s post 0.0073s
2017-07-14 09:36:07,228 testing 272/500 data 1.0481s net 0.3024s post 0.0073s
2017-07-14 09:36:08,584 testing 276/500 data 1.0481s net 0.3024s post 0.0072s
2017-07-14 09:36:09,884 testing 280/500 data 1.0472s net 0.3024s post 0.0072s
2017-07-14 09:36:11,207 testing 284/500 data 1.0468s net 0.3024s post 0.0072s
2017-07-14 09:36:12,585 testing 288/500 data 1.0472s net 0.3023s post 0.0072s
2017-07-14 09:36:13,880 testing 292/500 data 1.0463s net 0.3024s post 0.0072s
2017-07-14 09:36:15,237 testing 296/500 data 1.0464s net 0.3023s post 0.0072s
2017-07-14 09:36:16,552 testing 300/500 data 1.0460s net 0.3022s post 0.0072s
2017-07-14 09:36:17,916 testing 304/500 data 1.0462s net 0.3021s post 0.0072s
2017-07-14 09:36:19,289 testing 308/500 data 1.0464s net 0.3020s post 0.0072s
2017-07-14 09:36:20,703 testing 312/500 data 1.0472s net 0.3020s post 0.0072s
2017-07-14 09:36:22,026 testing 316/500 data 1.0468s net 0.3020s post 0.0072s
2017-07-14 09:36:23,489 testing 320/500 data 1.0482s net 0.3020s post 0.0072s
2017-07-14 09:36:24,801 testing 324/500 data 1.0478s net 0.3019s post 0.0072s
2017-07-14 09:36:26,293 testing 328/500 data 1.0495s net 0.3018s post 0.0072s
2017-07-14 09:36:27,613 testing 332/500 data 1.0490s net 0.3018s post 0.0071s
2017-07-14 09:36:29,175 testing 336/500 data 1.0514s net 0.3019s post 0.0072s
2017-07-14 09:36:30,534 testing 340/500 data 1.0515s net 0.3017s post 0.0072s
2017-07-14 09:36:31,886 testing 344/500 data 1.0515s net 0.3016s post 0.0072s
2017-07-14 09:36:33,345 testing 348/500 data 1.0526s net 0.3017s post 0.0072s
2017-07-14 09:36:34,668 testing 352/500 data 1.0521s net 0.3017s post 0.0071s
2017-07-14 09:36:36,178 testing 356/500 data 1.0538s net 0.3017s post 0.0071s
2017-07-14 09:36:37,539 testing 360/500 data 1.0537s net 0.3018s post 0.0071s
2017-07-14 09:36:39,003 testing 364/500 data 1.0548s net 0.3018s post 0.0071s
2017-07-14 09:36:40,380 testing 368/500 data 1.0549s net 0.3019s post 0.0071s
2017-07-14 09:36:41,749 testing 372/500 data 1.0550s net 0.3018s post 0.0071s
2017-07-14 09:36:43,176 testing 376/500 data 1.0555s net 0.3020s post 0.0071s
2017-07-14 09:36:44,464 testing 380/500 data 1.0548s net 0.3019s post 0.0071s
2017-07-14 09:36:45,943 testing 384/500 data 1.0559s net 0.3020s post 0.0071s
2017-07-14 09:36:47,408 testing 388/500 data 1.0570s net 0.3019s post 0.0071s
2017-07-14 09:36:48,827 testing 392/500 data 1.0575s net 0.3019s post 0.0071s
2017-07-14 09:36:50,206 testing 396/500 data 1.0577s net 0.3019s post 0.0071s
2017-07-14 09:36:51,655 testing 400/500 data 1.0586s net 0.3019s post 0.0071s
2017-07-14 09:36:52,846 testing 404/500 data 1.0568s net 0.3018s post 0.0071s
2017-07-14 09:36:54,173 testing 408/500 data 1.0565s net 0.3018s post 0.0071s
2017-07-14 09:36:55,617 testing 412/500 data 1.0572s net 0.3019s post 0.0071s
2017-07-14 09:36:56,969 testing 416/500 data 1.0571s net 0.3018s post 0.0071s
2017-07-14 09:36:58,266 testing 420/500 data 1.0565s net 0.3019s post 0.0071s
2017-07-14 09:36:59,650 testing 424/500 data 1.0567s net 0.3018s post 0.0071s
2017-07-14 09:37:01,020 testing 428/500 data 1.0567s net 0.3019s post 0.0071s
2017-07-14 09:37:02,382 testing 432/500 data 1.0567s net 0.3018s post 0.0071s
2017-07-14 09:37:03,715 testing 436/500 data 1.0563s net 0.3019s post 0.0071s
2017-07-14 09:37:05,148 testing 440/500 data 1.0570s net 0.3018s post 0.0071s
2017-07-14 09:37:06,589 testing 444/500 data 1.0576s net 0.3019s post 0.0070s
2017-07-14 09:37:07,923 testing 448/500 data 1.0573s net 0.3019s post 0.0070s
2017-07-14 09:37:09,476 testing 452/500 data 1.0589s net 0.3019s post 0.0071s
2017-07-14 09:37:10,826 testing 456/500 data 1.0588s net 0.3019s post 0.0071s
2017-07-14 09:37:12,085 testing 460/500 data 1.0579s net 0.3019s post 0.0070s
2017-07-14 09:37:13,563 testing 464/500 data 1.0589s net 0.3019s post 0.0070s
2017-07-14 09:37:14,950 testing 468/500 data 1.0590s net 0.3019s post 0.0070s
2017-07-14 09:37:16,312 testing 472/500 data 1.0588s net 0.3020s post 0.0070s
2017-07-14 09:37:17,667 testing 476/500 data 1.0586s net 0.3021s post 0.0070s
2017-07-14 09:37:19,075 testing 480/500 data 1.0590s net 0.3021s post 0.0070s
2017-07-14 09:37:20,434 testing 484/500 data 1.0589s net 0.3021s post 0.0070s
2017-07-14 09:37:21,723 testing 488/500 data 1.0583s net 0.3021s post 0.0070s
2017-07-14 09:37:23,173 testing 492/500 data 1.0588s net 0.3022s post 0.0070s
2017-07-14 09:37:24,567 testing 496/500 data 1.0591s net 0.3022s post 0.0070s
2017-07-14 09:37:25,881 testing 500/500 data 1.0587s net 0.3021s post 0.0070s
2017-07-14 09:39:24,010 evaluate segmentation: 

2017-07-14 09:39:24,010 IU_array:

2017-07-14 09:39:24,010 0.37651
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,010 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 0.00000
2017-07-14 09:39:24,011 meanIU:0.01982

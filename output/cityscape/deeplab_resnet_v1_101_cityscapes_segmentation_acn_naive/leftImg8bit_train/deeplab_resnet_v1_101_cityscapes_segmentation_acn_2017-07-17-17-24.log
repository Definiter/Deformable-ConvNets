2017-07-17 17:24:54,425 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-17 17:26:18,169 Epoch[0] Batch [10]	Speed: 3.58 samples/sec	Train-FCNLogLoss=2.811651,	
2017-07-17 17:26:29,928 Epoch[0] Batch [20]	Speed: 3.40 samples/sec	Train-FCNLogLoss=2.454363,	
2017-07-17 17:26:43,950 Epoch[0] Batch [30]	Speed: 2.85 samples/sec	Train-FCNLogLoss=2.221890,	
2017-07-17 17:26:58,602 Epoch[0] Batch [40]	Speed: 2.73 samples/sec	Train-FCNLogLoss=2.115144,	
2017-07-17 17:27:08,743 Epoch[0] Batch [50]	Speed: 3.95 samples/sec	Train-FCNLogLoss=2.024555,	
2017-07-17 17:27:18,517 Epoch[0] Batch [60]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.948067,	
2017-07-17 17:27:28,800 Epoch[0] Batch [70]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.886931,	
2017-07-17 17:27:39,019 Epoch[0] Batch [80]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.855217,	
2017-07-17 17:27:49,261 Epoch[0] Batch [90]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.801131,	
2017-07-17 17:28:00,012 Epoch[0] Batch [100]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.756649,	
2017-07-17 17:28:10,803 Epoch[0] Batch [110]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.714643,	
2017-07-17 17:28:21,671 Epoch[0] Batch [120]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.677318,	
2017-07-17 17:28:31,921 Epoch[0] Batch [130]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.647775,	
2017-07-17 17:28:42,152 Epoch[0] Batch [140]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.630204,	
2017-07-17 17:28:52,182 Epoch[0] Batch [150]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.608984,	
2017-07-17 17:29:02,467 Epoch[0] Batch [160]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.589709,	
2017-07-17 17:29:12,231 Epoch[0] Batch [170]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.572856,	
2017-07-17 17:29:22,455 Epoch[0] Batch [180]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.554305,	
2017-07-17 17:29:32,949 Epoch[0] Batch [190]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.541678,	
2017-07-17 17:29:43,395 Epoch[0] Batch [200]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.531588,	
2017-07-17 17:29:53,949 Epoch[0] Batch [210]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.524094,	
2017-07-17 17:30:04,497 Epoch[0] Batch [220]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.516231,	
2017-07-17 17:30:14,997 Epoch[0] Batch [230]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.504586,	
2017-07-17 17:30:25,738 Epoch[0] Batch [240]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.490069,	
2017-07-17 17:30:36,702 Epoch[0] Batch [250]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.481934,	
2017-07-17 17:30:49,027 Epoch[0] Batch [260]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.472979,	
2017-07-17 17:31:03,371 Epoch[0] Batch [270]	Speed: 2.79 samples/sec	Train-FCNLogLoss=1.459082,	
2017-07-17 17:31:15,779 Epoch[0] Batch [280]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.455293,	
2017-07-17 17:31:29,767 Epoch[0] Batch [290]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.452386,	
2017-07-17 17:31:43,300 Epoch[0] Batch [300]	Speed: 2.96 samples/sec	Train-FCNLogLoss=1.450915,	
2017-07-17 17:31:55,525 Epoch[0] Batch [310]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.443933,	
2017-07-17 17:32:08,435 Epoch[0] Batch [320]	Speed: 3.10 samples/sec	Train-FCNLogLoss=1.442005,	
2017-07-17 17:32:18,310 Epoch[0] Batch [330]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.434744,	
2017-07-17 17:32:28,563 Epoch[0] Batch [340]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.430236,	
2017-07-17 17:32:38,554 Epoch[0] Batch [350]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.423268,	
2017-07-17 17:32:48,347 Epoch[0] Batch [360]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.421227,	
2017-07-17 17:32:58,107 Epoch[0] Batch [370]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.419917,	
2017-07-17 17:33:07,650 Epoch[0] Batch [380]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.414966,	
2017-07-17 17:33:17,554 Epoch[0] Batch [390]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.409110,	
2017-07-17 17:33:27,442 Epoch[0] Batch [400]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.406497,	
2017-07-17 17:33:36,838 Epoch[0] Batch [410]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.402926,	
2017-07-17 17:33:46,819 Epoch[0] Batch [420]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.399913,	
2017-07-17 17:33:56,454 Epoch[0] Batch [430]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.396634,	
2017-07-17 17:34:06,048 Epoch[0] Batch [440]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.395870,	
2017-07-17 17:34:15,600 Epoch[0] Batch [450]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.392149,	
2017-07-17 17:34:25,028 Epoch[0] Batch [460]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.389358,	
2017-07-17 17:34:35,423 Epoch[0] Batch [470]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.385734,	
2017-07-17 17:34:45,257 Epoch[0] Batch [480]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.384542,	
2017-07-17 17:34:54,937 Epoch[0] Batch [490]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.384029,	
2017-07-17 17:35:04,626 Epoch[0] Batch [500]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.382752,	
2017-07-17 17:35:14,697 Epoch[0] Batch [510]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.379642,	
2017-07-17 17:35:25,023 Epoch[0] Batch [520]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.376450,	
2017-07-17 17:35:35,088 Epoch[0] Batch [530]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.373943,	
2017-07-17 17:35:44,727 Epoch[0] Batch [540]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.371862,	
2017-07-17 17:35:54,474 Epoch[0] Batch [550]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.371187,	
2017-07-17 17:36:04,402 Epoch[0] Batch [560]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.368240,	
2017-07-17 17:36:13,805 Epoch[0] Batch [570]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.367003,	
2017-07-17 17:36:23,818 Epoch[0] Batch [580]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.366279,	
2017-07-17 17:36:33,696 Epoch[0] Batch [590]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.364440,	
2017-07-17 17:36:43,520 Epoch[0] Batch [600]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.364167,	
2017-07-17 17:36:53,721 Epoch[0] Batch [610]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.362345,	
2017-07-17 17:37:03,801 Epoch[0] Batch [620]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.359410,	
2017-07-17 17:37:13,517 Epoch[0] Batch [630]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.358548,	
2017-07-17 17:37:23,549 Epoch[0] Batch [640]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.355300,	
2017-07-17 17:37:33,401 Epoch[0] Batch [650]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.353549,	
2017-07-17 17:37:43,027 Epoch[0] Batch [660]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.351400,	
2017-07-17 17:37:52,787 Epoch[0] Batch [670]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.348874,	
2017-07-17 17:38:02,501 Epoch[0] Batch [680]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.346955,	
2017-07-17 17:38:11,976 Epoch[0] Batch [690]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.344944,	
2017-07-17 17:38:21,894 Epoch[0] Batch [700]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.343648,	
2017-07-17 17:38:31,683 Epoch[0] Batch [710]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.342990,	
2017-07-17 17:38:41,751 Epoch[0] Batch [720]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.341872,	
2017-07-17 17:38:51,619 Epoch[0] Batch [730]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.340773,	
2017-07-17 17:39:01,747 Epoch[0] Batch [740]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.340303,	
2017-07-17 17:39:11,768 Epoch[0] Batch [750]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.338343,	
2017-07-17 17:39:21,278 Epoch[0] Batch [760]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.336602,	
2017-07-17 17:39:30,950 Epoch[0] Batch [770]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.333920,	
2017-07-17 17:39:40,902 Epoch[0] Batch [780]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.333728,	
2017-07-17 17:39:50,467 Epoch[0] Batch [790]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.333383,	
2017-07-17 17:39:59,999 Epoch[0] Batch [800]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.332201,	
2017-07-17 17:40:09,447 Epoch[0] Batch [810]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.332426,	
2017-07-17 17:40:19,073 Epoch[0] Batch [820]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.331417,	
2017-07-17 17:40:28,691 Epoch[0] Batch [830]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.331017,	
2017-07-17 17:40:38,041 Epoch[0] Batch [840]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.328839,	
2017-07-17 17:40:47,765 Epoch[0] Batch [850]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.328849,	
2017-07-17 17:40:57,490 Epoch[0] Batch [860]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.328072,	
2017-07-17 17:41:06,986 Epoch[0] Batch [870]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.326734,	
2017-07-17 17:41:16,551 Epoch[0] Batch [880]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.325181,	
2017-07-17 17:41:26,166 Epoch[0] Batch [890]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.326411,	
2017-07-17 17:41:36,292 Epoch[0] Batch [900]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.325898,	
2017-07-17 17:41:46,184 Epoch[0] Batch [910]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.324822,	
2017-07-17 17:41:56,105 Epoch[0] Batch [920]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.324213,	
2017-07-17 17:42:06,151 Epoch[0] Batch [930]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.322538,	
2017-07-17 17:42:16,200 Epoch[0] Batch [940]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.322221,	
2017-07-17 17:42:26,010 Epoch[0] Batch [950]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.321085,	
2017-07-17 17:42:35,999 Epoch[0] Batch [960]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.322140,	
2017-07-17 17:42:45,980 Epoch[0] Batch [970]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.321773,	
2017-07-17 17:43:05,839 Epoch[0] Batch [980]	Speed: 2.01 samples/sec	Train-FCNLogLoss=1.321093,	
2017-07-17 17:43:15,708 Epoch[0] Batch [990]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.319668,	
2017-07-17 17:43:25,671 Epoch[0] Batch [1000]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.319142,	
2017-07-17 17:43:36,000 Epoch[0] Batch [1010]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.319946,	
2017-07-17 17:43:46,404 Epoch[0] Batch [1020]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.322359,	
2017-07-17 17:43:56,991 Epoch[0] Batch [1030]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.327073,	
2017-07-17 17:44:07,636 Epoch[0] Batch [1040]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.332821,	
2017-07-17 17:44:17,742 Epoch[0] Batch [1050]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.336498,	
2017-07-17 17:44:27,810 Epoch[0] Batch [1060]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.339848,	
2017-07-17 17:44:37,612 Epoch[0] Batch [1070]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.342237,	
2017-07-17 17:44:47,179 Epoch[0] Batch [1080]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.343548,	
2017-07-17 17:44:57,263 Epoch[0] Batch [1090]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.344039,	
2017-07-17 17:45:07,367 Epoch[0] Batch [1100]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.344293,	
2017-07-17 17:45:17,328 Epoch[0] Batch [1110]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.345440,	
2017-07-17 17:45:27,290 Epoch[0] Batch [1120]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.344606,	
2017-07-17 17:45:37,133 Epoch[0] Batch [1130]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.345325,	
2017-07-17 17:45:47,451 Epoch[0] Batch [1140]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.345724,	
2017-07-17 17:45:57,572 Epoch[0] Batch [1150]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.346159,	
2017-07-17 17:46:06,749 Epoch[0] Batch [1160]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.346086,	
2017-07-17 17:46:16,316 Epoch[0] Batch [1170]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.346650,	
2017-07-17 17:46:25,938 Epoch[0] Batch [1180]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.346586,	
2017-07-17 17:46:35,424 Epoch[0] Batch [1190]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.346876,	
2017-07-17 17:46:45,057 Epoch[0] Batch [1200]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.346308,	
2017-07-17 17:46:54,544 Epoch[0] Batch [1210]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.345653,	
2017-07-17 17:47:04,475 Epoch[0] Batch [1220]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.345689,	
2017-07-17 17:47:14,315 Epoch[0] Batch [1230]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.345231,	
2017-07-17 17:47:24,472 Epoch[0] Batch [1240]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.345053,	
2017-07-17 17:47:34,307 Epoch[0] Batch [1250]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.344413,	
2017-07-17 17:47:44,047 Epoch[0] Batch [1260]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.344803,	
2017-07-17 17:47:53,761 Epoch[0] Batch [1270]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.344100,	
2017-07-17 17:48:04,069 Epoch[0] Batch [1280]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.343936,	
2017-07-17 17:48:13,885 Epoch[0] Batch [1290]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.343806,	
2017-07-17 17:48:23,916 Epoch[0] Batch [1300]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.343135,	
2017-07-17 17:48:34,074 Epoch[0] Batch [1310]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.342756,	
2017-07-17 17:48:44,165 Epoch[0] Batch [1320]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.341922,	
2017-07-17 17:48:53,866 Epoch[0] Batch [1330]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.341116,	
2017-07-17 17:49:03,629 Epoch[0] Batch [1340]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.339993,	
2017-07-17 17:49:14,176 Epoch[0] Batch [1350]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.339163,	
2017-07-17 17:49:24,829 Epoch[0] Batch [1360]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.338074,	
2017-07-17 17:49:34,782 Epoch[0] Batch [1370]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.337541,	
2017-07-17 17:49:44,720 Epoch[0] Batch [1380]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.337784,	
2017-07-17 17:49:54,748 Epoch[0] Batch [1390]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.337514,	
2017-07-17 17:50:04,336 Epoch[0] Batch [1400]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.336888,	
2017-07-17 17:50:14,019 Epoch[0] Batch [1410]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.336015,	
2017-07-17 17:50:23,751 Epoch[0] Batch [1420]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.335645,	
2017-07-17 17:50:33,403 Epoch[0] Batch [1430]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.335130,	
2017-07-17 17:50:43,254 Epoch[0] Batch [1440]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.334203,	
2017-07-17 17:50:53,112 Epoch[0] Batch [1450]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.335294,	
2017-07-17 17:51:03,370 Epoch[0] Batch [1460]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.335116,	
2017-07-17 17:51:13,224 Epoch[0] Batch [1470]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.334948,	
2017-07-17 17:51:22,936 Epoch[0] Batch [1480]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.334609,	
2017-07-17 17:51:28,656 Epoch[0] Train-FCNLogLoss=1.334416
2017-07-17 17:51:28,656 Epoch[0] Time cost=1533.622
2017-07-17 17:51:30,466 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-17 17:51:34,696 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-17 17:51:45,423 Epoch[1] Batch [10]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.294816,	
2017-07-17 17:51:54,668 Epoch[1] Batch [20]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.267931,	
2017-07-17 17:52:03,928 Epoch[1] Batch [30]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.277707,	
2017-07-17 17:52:13,217 Epoch[1] Batch [40]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.275992,	
2017-07-17 17:52:23,191 Epoch[1] Batch [50]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.275733,	
2017-07-17 17:52:33,107 Epoch[1] Batch [60]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.274901,	
2017-07-17 17:52:43,515 Epoch[1] Batch [70]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.281012,	
2017-07-17 17:52:53,325 Epoch[1] Batch [80]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.277260,	
2017-07-17 17:53:03,879 Epoch[1] Batch [90]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.272016,	
2017-07-17 17:53:14,198 Epoch[1] Batch [100]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.264732,	
2017-07-17 17:53:24,418 Epoch[1] Batch [110]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.264011,	
2017-07-17 17:53:34,005 Epoch[1] Batch [120]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.256858,	
2017-07-17 17:53:44,252 Epoch[1] Batch [130]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.260858,	
2017-07-17 17:53:53,966 Epoch[1] Batch [140]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.263478,	
2017-07-17 17:54:04,168 Epoch[1] Batch [150]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.265344,	
2017-07-17 17:54:13,893 Epoch[1] Batch [160]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.265760,	
2017-07-17 17:54:24,021 Epoch[1] Batch [170]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.266109,	
2017-07-17 17:54:34,462 Epoch[1] Batch [180]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.266094,	
2017-07-17 17:54:44,638 Epoch[1] Batch [190]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.261191,	
2017-07-17 17:55:04,304 Epoch[1] Batch [200]	Speed: 2.03 samples/sec	Train-FCNLogLoss=1.261925,	
2017-07-17 17:55:15,184 Epoch[1] Batch [210]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.265073,	
2017-07-17 17:55:25,167 Epoch[1] Batch [220]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.262664,	
2017-07-17 17:55:34,979 Epoch[1] Batch [230]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.259369,	
2017-07-17 17:55:44,603 Epoch[1] Batch [240]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.258442,	
2017-07-17 17:55:54,073 Epoch[1] Batch [250]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.263690,	
2017-07-17 17:56:04,320 Epoch[1] Batch [260]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.268802,	
2017-07-17 17:56:13,992 Epoch[1] Batch [270]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.273415,	
2017-07-17 17:56:23,676 Epoch[1] Batch [280]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.272908,	
2017-07-17 17:56:33,109 Epoch[1] Batch [290]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.276559,	
2017-07-17 17:56:42,820 Epoch[1] Batch [300]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.273109,	
2017-07-17 17:56:52,515 Epoch[1] Batch [310]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.272005,	
2017-07-17 17:57:02,112 Epoch[1] Batch [320]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.269623,	
2017-07-17 17:57:11,627 Epoch[1] Batch [330]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.271633,	
2017-07-17 17:57:21,581 Epoch[1] Batch [340]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.270886,	
2017-07-17 17:57:30,677 Epoch[1] Batch [350]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.270300,	
2017-07-17 17:57:40,147 Epoch[1] Batch [360]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.274363,	
2017-07-17 17:57:49,953 Epoch[1] Batch [370]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.272817,	
2017-07-17 17:57:59,411 Epoch[1] Batch [380]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.273269,	
2017-07-17 17:58:08,813 Epoch[1] Batch [390]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.271193,	
2017-07-17 17:58:18,930 Epoch[1] Batch [400]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.273705,	
2017-07-17 17:58:28,488 Epoch[1] Batch [410]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.275067,	
2017-07-17 17:58:37,712 Epoch[1] Batch [420]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.274765,	
2017-07-17 17:58:47,238 Epoch[1] Batch [430]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.272432,	
2017-07-17 17:58:56,798 Epoch[1] Batch [440]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.272510,	
2017-07-17 17:59:06,663 Epoch[1] Batch [450]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.270365,	
2017-07-17 17:59:16,523 Epoch[1] Batch [460]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.270397,	
2017-07-17 17:59:26,873 Epoch[1] Batch [470]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.271383,	
2017-07-17 17:59:36,757 Epoch[1] Batch [480]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.271362,	
2017-07-17 17:59:46,378 Epoch[1] Batch [490]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.270721,	
2017-07-17 17:59:56,413 Epoch[1] Batch [500]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.273744,	
2017-07-17 18:00:06,636 Epoch[1] Batch [510]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.273841,	
2017-07-17 18:00:16,815 Epoch[1] Batch [520]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.273889,	
2017-07-17 18:00:26,624 Epoch[1] Batch [530]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.271953,	
2017-07-17 18:00:35,596 Epoch[1] Batch [540]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.272115,	
2017-07-17 18:00:44,798 Epoch[1] Batch [550]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.270489,	
2017-07-17 18:00:54,201 Epoch[1] Batch [560]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.269409,	
2017-07-17 18:01:03,309 Epoch[1] Batch [570]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.269151,	
2017-07-17 18:01:12,223 Epoch[1] Batch [580]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.269133,	
2017-07-17 18:01:21,386 Epoch[1] Batch [590]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.271442,	
2017-07-17 18:01:30,734 Epoch[1] Batch [600]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.272084,	
2017-07-17 18:01:39,292 Epoch[1] Batch [610]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.271238,	
2017-07-17 18:01:48,547 Epoch[1] Batch [620]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.270871,	
2017-07-17 18:01:57,685 Epoch[1] Batch [630]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.270211,	
2017-07-17 18:02:07,035 Epoch[1] Batch [640]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.270217,	
2017-07-17 18:02:15,993 Epoch[1] Batch [650]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.270139,	
2017-07-17 18:02:24,562 Epoch[1] Batch [660]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.270819,	
2017-07-17 18:02:32,920 Epoch[1] Batch [670]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.270310,	
2017-07-17 18:02:41,841 Epoch[1] Batch [680]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.270267,	
2017-07-17 18:02:50,610 Epoch[1] Batch [690]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.269295,	
2017-07-17 18:02:59,260 Epoch[1] Batch [700]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.267186,	
2017-07-17 18:03:08,068 Epoch[1] Batch [710]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.266960,	
2017-07-17 18:03:16,961 Epoch[1] Batch [720]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.266659,	
2017-07-17 18:03:26,025 Epoch[1] Batch [730]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.265003,	
2017-07-17 18:03:34,685 Epoch[1] Batch [740]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.266319,	
2017-07-17 18:03:43,027 Epoch[1] Batch [750]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.267471,	
2017-07-17 18:03:51,984 Epoch[1] Batch [760]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.268228,	
2017-07-17 18:04:00,810 Epoch[1] Batch [770]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.267297,	
2017-07-17 18:04:09,515 Epoch[1] Batch [780]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.267322,	
2017-07-17 18:04:18,573 Epoch[1] Batch [790]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.266621,	
2017-07-17 18:04:27,224 Epoch[1] Batch [800]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.267875,	
2017-07-17 18:04:36,036 Epoch[1] Batch [810]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.268135,	
2017-07-17 18:04:44,843 Epoch[1] Batch [820]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.268659,	
2017-07-17 18:04:53,547 Epoch[1] Batch [830]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.267828,	
2017-07-17 18:05:02,365 Epoch[1] Batch [840]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.267199,	
2017-07-17 18:05:10,660 Epoch[1] Batch [850]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.268538,	
2017-07-17 18:05:18,879 Epoch[1] Batch [860]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.267496,	
2017-07-17 18:05:26,770 Epoch[1] Batch [870]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.267130,	
2017-07-17 18:05:34,999 Epoch[1] Batch [880]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.266473,	
2017-07-17 18:05:43,973 Epoch[1] Batch [890]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.266246,	
2017-07-17 18:05:52,111 Epoch[1] Batch [900]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.265205,	
2017-07-17 18:05:59,901 Epoch[1] Batch [910]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.265790,	
2017-07-17 18:06:07,967 Epoch[1] Batch [920]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.265461,	
2017-07-17 18:06:16,216 Epoch[1] Batch [930]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.264405,	
2017-07-17 18:06:24,358 Epoch[1] Batch [940]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.264949,	
2017-07-17 18:06:33,097 Epoch[1] Batch [950]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.264986,	
2017-07-17 18:06:41,477 Epoch[1] Batch [960]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.264426,	
2017-07-17 18:06:49,625 Epoch[1] Batch [970]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.262971,	
2017-07-17 18:06:58,011 Epoch[1] Batch [980]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.262698,	
2017-07-17 18:07:06,457 Epoch[1] Batch [990]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.263693,	
2017-07-17 18:07:14,665 Epoch[1] Batch [1000]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.264049,	
2017-07-17 18:07:22,834 Epoch[1] Batch [1010]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.263711,	
2017-07-17 18:07:31,443 Epoch[1] Batch [1020]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.262019,	
2017-07-17 18:07:39,927 Epoch[1] Batch [1030]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.261862,	
2017-07-17 18:07:48,473 Epoch[1] Batch [1040]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.261485,	
2017-07-17 18:07:57,175 Epoch[1] Batch [1050]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.261689,	
2017-07-17 18:08:05,668 Epoch[1] Batch [1060]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.261948,	
2017-07-17 18:08:14,192 Epoch[1] Batch [1070]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.262102,	
2017-07-17 18:08:22,475 Epoch[1] Batch [1080]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.261771,	
2017-07-17 18:08:30,810 Epoch[1] Batch [1090]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.262576,	
2017-07-17 18:08:39,308 Epoch[1] Batch [1100]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.262361,	
2017-07-17 18:08:47,667 Epoch[1] Batch [1110]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.262177,	
2017-07-17 18:08:56,583 Epoch[1] Batch [1120]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.261998,	
2017-07-17 18:09:04,570 Epoch[1] Batch [1130]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.261009,	
2017-07-17 18:09:12,614 Epoch[1] Batch [1140]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.261667,	
2017-07-17 18:09:21,038 Epoch[1] Batch [1150]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.261363,	
2017-07-17 18:09:29,000 Epoch[1] Batch [1160]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.262341,	
2017-07-17 18:09:37,616 Epoch[1] Batch [1170]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.262078,	
2017-07-17 18:09:46,483 Epoch[1] Batch [1180]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.261682,	
2017-07-17 18:09:54,833 Epoch[1] Batch [1190]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.261300,	
2017-07-17 18:10:03,407 Epoch[1] Batch [1200]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.261876,	
2017-07-17 18:10:11,744 Epoch[1] Batch [1210]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.262510,	
2017-07-17 18:10:20,252 Epoch[1] Batch [1220]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.262663,	
2017-07-17 18:10:29,115 Epoch[1] Batch [1230]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.263270,	
2017-07-17 18:10:37,838 Epoch[1] Batch [1240]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.263461,	
2017-07-17 18:10:46,146 Epoch[1] Batch [1250]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.264244,	
2017-07-17 18:10:54,282 Epoch[1] Batch [1260]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.263990,	
2017-07-17 18:11:03,154 Epoch[1] Batch [1270]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.263362,	
2017-07-17 18:11:12,327 Epoch[1] Batch [1280]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.263238,	
2017-07-17 18:11:20,587 Epoch[1] Batch [1290]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.263175,	
2017-07-17 18:11:29,419 Epoch[1] Batch [1300]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.263095,	
2017-07-17 18:11:37,947 Epoch[1] Batch [1310]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.262574,	
2017-07-17 18:11:47,082 Epoch[1] Batch [1320]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.262986,	
2017-07-17 18:11:55,204 Epoch[1] Batch [1330]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.263423,	
2017-07-17 18:12:03,409 Epoch[1] Batch [1340]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.262839,	
2017-07-17 18:12:11,128 Epoch[1] Batch [1350]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.263802,	
2017-07-17 18:12:19,612 Epoch[1] Batch [1360]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.263384,	
2017-07-17 18:12:28,050 Epoch[1] Batch [1370]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.263087,	
2017-07-17 18:12:36,649 Epoch[1] Batch [1380]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.263593,	
2017-07-17 18:12:45,421 Epoch[1] Batch [1390]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.263716,	
2017-07-17 18:12:54,095 Epoch[1] Batch [1400]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.263586,	
2017-07-17 18:13:02,723 Epoch[1] Batch [1410]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.263076,	
2017-07-17 18:13:11,019 Epoch[1] Batch [1420]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.263040,	
2017-07-17 18:13:19,854 Epoch[1] Batch [1430]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.262591,	
2017-07-17 18:13:28,636 Epoch[1] Batch [1440]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.262536,	
2017-07-17 18:13:37,298 Epoch[1] Batch [1450]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.261786,	
2017-07-17 18:13:46,190 Epoch[1] Batch [1460]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.262218,	
2017-07-17 18:13:54,526 Epoch[1] Batch [1470]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.262089,	
2017-07-17 18:14:03,281 Epoch[1] Batch [1480]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.262050,	
2017-07-17 18:14:08,213 Epoch[1] Train-FCNLogLoss=1.261863
2017-07-17 18:14:08,213 Epoch[1] Time cost=1353.444
2017-07-17 18:14:09,544 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-17 18:14:12,421 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-17 18:14:21,822 Epoch[2] Batch [10]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.222566,	
2017-07-17 18:14:37,171 Epoch[2] Batch [20]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.188400,	
2017-07-17 18:14:44,755 Epoch[2] Batch [30]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.199247,	
2017-07-17 18:14:52,341 Epoch[2] Batch [40]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.230087,	
2017-07-17 18:15:00,632 Epoch[2] Batch [50]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.260644,	
2017-07-17 18:15:09,013 Epoch[2] Batch [60]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.260747,	
2017-07-17 18:15:17,293 Epoch[2] Batch [70]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.253444,	
2017-07-17 18:15:25,192 Epoch[2] Batch [80]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.258290,	
2017-07-17 18:15:33,515 Epoch[2] Batch [90]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.264961,	
2017-07-17 18:15:42,188 Epoch[2] Batch [100]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.257608,	
2017-07-17 18:15:50,306 Epoch[2] Batch [110]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.255722,	
2017-07-17 18:15:58,047 Epoch[2] Batch [120]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.256795,	
2017-07-17 18:16:06,150 Epoch[2] Batch [130]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.258465,	
2017-07-17 18:16:14,360 Epoch[2] Batch [140]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.260162,	
2017-07-17 18:16:22,466 Epoch[2] Batch [150]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.259674,	
2017-07-17 18:16:30,700 Epoch[2] Batch [160]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.251889,	
2017-07-17 18:16:38,970 Epoch[2] Batch [170]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.262794,	
2017-07-17 18:16:47,269 Epoch[2] Batch [180]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.269852,	
2017-07-17 18:16:55,261 Epoch[2] Batch [190]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.270362,	
2017-07-17 18:17:03,304 Epoch[2] Batch [200]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.270778,	
2017-07-17 18:17:11,736 Epoch[2] Batch [210]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.266686,	
2017-07-17 18:17:20,027 Epoch[2] Batch [220]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.268067,	
2017-07-17 18:17:28,309 Epoch[2] Batch [230]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.270464,	
2017-07-17 18:17:36,718 Epoch[2] Batch [240]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.269825,	
2017-07-17 18:17:44,793 Epoch[2] Batch [250]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.274934,	
2017-07-17 18:17:52,566 Epoch[2] Batch [260]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.276399,	
2017-07-17 18:18:00,916 Epoch[2] Batch [270]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.278604,	
2017-07-17 18:18:09,804 Epoch[2] Batch [280]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.276126,	
2017-07-17 18:18:18,231 Epoch[2] Batch [290]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.275765,	
2017-07-17 18:18:26,178 Epoch[2] Batch [300]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.272318,	
2017-07-17 18:18:34,092 Epoch[2] Batch [310]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.272130,	
2017-07-17 18:18:42,095 Epoch[2] Batch [320]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.270170,	
2017-07-17 18:18:50,212 Epoch[2] Batch [330]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.267739,	
2017-07-17 18:18:57,743 Epoch[2] Batch [340]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.264261,	
2017-07-17 18:19:05,661 Epoch[2] Batch [350]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.266656,	
2017-07-17 18:19:13,226 Epoch[2] Batch [360]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.270038,	
2017-07-17 18:19:21,482 Epoch[2] Batch [370]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.267737,	
2017-07-17 18:19:28,950 Epoch[2] Batch [380]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.268661,	
2017-07-17 18:19:36,562 Epoch[2] Batch [390]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.265576,	
2017-07-17 18:19:44,775 Epoch[2] Batch [400]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.265536,	
2017-07-17 18:19:52,733 Epoch[2] Batch [410]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.263699,	
2017-07-17 18:20:00,773 Epoch[2] Batch [420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.263908,	
2017-07-17 18:20:08,784 Epoch[2] Batch [430]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.262018,	
2017-07-17 18:20:16,862 Epoch[2] Batch [440]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.262392,	
2017-07-17 18:20:24,968 Epoch[2] Batch [450]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.265169,	
2017-07-17 18:20:33,217 Epoch[2] Batch [460]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.265873,	
2017-07-17 18:20:41,274 Epoch[2] Batch [470]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.265791,	
2017-07-17 18:20:49,721 Epoch[2] Batch [480]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.264337,	
2017-07-17 18:20:57,933 Epoch[2] Batch [490]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.263723,	
2017-07-17 18:21:05,848 Epoch[2] Batch [500]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.265192,	
2017-07-17 18:21:13,446 Epoch[2] Batch [510]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.265333,	
2017-07-17 18:21:21,871 Epoch[2] Batch [520]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.267124,	
2017-07-17 18:21:30,166 Epoch[2] Batch [530]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.267348,	
2017-07-17 18:21:37,947 Epoch[2] Batch [540]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.265376,	
2017-07-17 18:21:46,303 Epoch[2] Batch [550]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.263495,	
2017-07-17 18:21:54,699 Epoch[2] Batch [560]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.263321,	
2017-07-17 18:22:03,086 Epoch[2] Batch [570]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.264322,	
2017-07-17 18:22:11,291 Epoch[2] Batch [580]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.265014,	
2017-07-17 18:22:20,025 Epoch[2] Batch [590]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.263301,	
2017-07-17 18:22:28,217 Epoch[2] Batch [600]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.259786,	
2017-07-17 18:22:36,248 Epoch[2] Batch [610]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.258362,	
2017-07-17 18:22:44,496 Epoch[2] Batch [620]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.258730,	
2017-07-17 18:22:52,689 Epoch[2] Batch [630]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.258676,	
2017-07-17 18:23:00,413 Epoch[2] Batch [640]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.257891,	
2017-07-17 18:23:08,502 Epoch[2] Batch [650]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.257283,	
2017-07-17 18:23:16,712 Epoch[2] Batch [660]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.256608,	
2017-07-17 18:23:24,832 Epoch[2] Batch [670]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.257629,	
2017-07-17 18:23:33,122 Epoch[2] Batch [680]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.257446,	
2017-07-17 18:23:41,708 Epoch[2] Batch [690]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.257977,	
2017-07-17 18:23:50,304 Epoch[2] Batch [700]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.258348,	
2017-07-17 18:23:59,272 Epoch[2] Batch [710]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.258493,	
2017-07-17 18:24:07,707 Epoch[2] Batch [720]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.256944,	
2017-07-17 18:24:15,943 Epoch[2] Batch [730]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.256893,	
2017-07-17 18:24:24,346 Epoch[2] Batch [740]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.255508,	
2017-07-17 18:24:32,341 Epoch[2] Batch [750]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.254593,	
2017-07-17 18:24:40,607 Epoch[2] Batch [760]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.256267,	
2017-07-17 18:24:49,156 Epoch[2] Batch [770]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.256639,	
2017-07-17 18:24:57,060 Epoch[2] Batch [780]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.256380,	
2017-07-17 18:25:05,282 Epoch[2] Batch [790]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.256719,	
2017-07-17 18:25:13,440 Epoch[2] Batch [800]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.255714,	
2017-07-17 18:25:22,364 Epoch[2] Batch [810]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.254950,	
2017-07-17 18:25:30,481 Epoch[2] Batch [820]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.254377,	
2017-07-17 18:25:39,289 Epoch[2] Batch [830]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.254843,	
2017-07-17 18:25:47,560 Epoch[2] Batch [840]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.254838,	
2017-07-17 18:25:55,569 Epoch[2] Batch [850]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.255220,	
2017-07-17 18:26:03,773 Epoch[2] Batch [860]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.255405,	
2017-07-17 18:26:12,086 Epoch[2] Batch [870]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.255210,	
2017-07-17 18:26:20,601 Epoch[2] Batch [880]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.254659,	
2017-07-17 18:26:28,895 Epoch[2] Batch [890]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.254340,	
2017-07-17 18:26:37,633 Epoch[2] Batch [900]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.255020,	
2017-07-17 18:26:46,453 Epoch[2] Batch [910]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.255258,	
2017-07-17 18:26:55,000 Epoch[2] Batch [920]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.255585,	
2017-07-17 18:27:03,552 Epoch[2] Batch [930]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.255771,	
2017-07-17 18:27:11,670 Epoch[2] Batch [940]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.255339,	
2017-07-17 18:27:20,012 Epoch[2] Batch [950]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.255304,	
2017-07-17 18:27:28,519 Epoch[2] Batch [960]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.256396,	
2017-07-17 18:27:36,377 Epoch[2] Batch [970]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.256767,	
2017-07-17 18:27:44,594 Epoch[2] Batch [980]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.256370,	
2017-07-17 18:27:52,546 Epoch[2] Batch [990]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.256082,	
2017-07-17 18:28:00,412 Epoch[2] Batch [1000]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.256016,	
2017-07-17 18:28:09,013 Epoch[2] Batch [1010]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.255702,	
2017-07-17 18:28:17,172 Epoch[2] Batch [1020]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.255391,	
2017-07-17 18:28:26,020 Epoch[2] Batch [1030]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.255367,	
2017-07-17 18:28:34,786 Epoch[2] Batch [1040]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.253851,	
2017-07-17 18:28:44,652 Epoch[2] Batch [1050]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.253999,	
2017-07-17 18:28:53,473 Epoch[2] Batch [1060]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.253729,	
2017-07-17 18:29:02,557 Epoch[2] Batch [1070]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.253732,	
2017-07-17 18:29:11,753 Epoch[2] Batch [1080]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.254026,	
2017-07-17 18:29:20,443 Epoch[2] Batch [1090]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.253570,	
2017-07-17 18:29:28,415 Epoch[2] Batch [1100]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.253366,	
2017-07-17 18:29:37,094 Epoch[2] Batch [1110]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.252990,	
2017-07-17 18:29:45,533 Epoch[2] Batch [1120]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.253541,	
2017-07-17 18:29:54,826 Epoch[2] Batch [1130]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.254460,	
2017-07-17 18:30:03,444 Epoch[2] Batch [1140]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.254522,	
2017-07-17 18:30:12,311 Epoch[2] Batch [1150]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.254821,	
2017-07-17 18:30:21,686 Epoch[2] Batch [1160]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.255408,	
2017-07-17 18:30:29,780 Epoch[2] Batch [1170]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.255318,	
2017-07-17 18:30:39,228 Epoch[2] Batch [1180]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.254974,	
2017-07-17 18:30:48,510 Epoch[2] Batch [1190]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.254741,	
2017-07-17 18:30:57,979 Epoch[2] Batch [1200]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.254903,	
2017-07-17 18:31:07,015 Epoch[2] Batch [1210]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.254642,	
2017-07-17 18:31:16,117 Epoch[2] Batch [1220]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.255006,	
2017-07-17 18:31:25,151 Epoch[2] Batch [1230]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.255150,	
2017-07-17 18:31:33,974 Epoch[2] Batch [1240]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.254946,	
2017-07-17 18:31:42,371 Epoch[2] Batch [1250]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.255426,	
2017-07-17 18:31:51,621 Epoch[2] Batch [1260]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.255917,	
2017-07-17 18:32:00,109 Epoch[2] Batch [1270]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.255376,	
2017-07-17 18:32:09,407 Epoch[2] Batch [1280]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.254974,	
2017-07-17 18:32:18,019 Epoch[2] Batch [1290]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.254615,	
2017-07-17 18:32:27,193 Epoch[2] Batch [1300]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.254677,	
2017-07-17 18:32:36,096 Epoch[2] Batch [1310]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.254454,	
2017-07-17 18:32:45,649 Epoch[2] Batch [1320]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.254476,	
2017-07-17 18:32:55,024 Epoch[2] Batch [1330]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.253829,	
2017-07-17 18:33:04,327 Epoch[2] Batch [1340]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.253501,	
2017-07-17 18:33:12,355 Epoch[2] Batch [1350]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.252995,	
2017-07-17 18:33:22,054 Epoch[2] Batch [1360]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.252187,	
2017-07-17 18:33:31,291 Epoch[2] Batch [1370]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.251630,	
2017-07-17 18:33:40,107 Epoch[2] Batch [1380]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.252096,	
2017-07-17 18:33:49,050 Epoch[2] Batch [1390]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.251724,	
2017-07-17 18:33:58,635 Epoch[2] Batch [1400]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.251460,	
2017-07-17 18:34:07,297 Epoch[2] Batch [1410]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.251759,	
2017-07-17 18:34:15,573 Epoch[2] Batch [1420]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.251897,	
2017-07-17 18:34:23,600 Epoch[2] Batch [1430]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.251971,	
2017-07-17 18:34:31,452 Epoch[2] Batch [1440]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.252173,	
2017-07-17 18:34:41,034 Epoch[2] Batch [1450]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.252583,	
2017-07-17 18:34:49,494 Epoch[2] Batch [1460]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.252888,	
2017-07-17 18:34:57,717 Epoch[2] Batch [1470]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.253033,	
2017-07-17 18:35:06,255 Epoch[2] Batch [1480]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.253660,	
2017-07-17 18:35:11,208 Epoch[2] Train-FCNLogLoss=1.253582
2017-07-17 18:35:11,208 Epoch[2] Time cost=1258.527
2017-07-17 18:35:12,396 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-17 18:35:15,296 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-17 18:35:24,454 Epoch[3] Batch [10]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.258150,	
2017-07-17 18:35:32,651 Epoch[3] Batch [20]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.251073,	
2017-07-17 18:35:40,429 Epoch[3] Batch [30]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.255185,	
2017-07-17 18:35:49,419 Epoch[3] Batch [40]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.268125,	
2017-07-17 18:35:57,638 Epoch[3] Batch [50]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.285121,	
2017-07-17 18:36:07,191 Epoch[3] Batch [60]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.284738,	
2017-07-17 18:36:16,753 Epoch[3] Batch [70]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.277539,	
2017-07-17 18:36:25,577 Epoch[3] Batch [80]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.269541,	
2017-07-17 18:36:34,695 Epoch[3] Batch [90]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.277520,	
2017-07-17 18:36:43,441 Epoch[3] Batch [100]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.288963,	
2017-07-17 18:36:52,617 Epoch[3] Batch [110]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.279329,	
2017-07-17 18:37:02,230 Epoch[3] Batch [120]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.281052,	
2017-07-17 18:37:19,441 Epoch[3] Batch [130]	Speed: 2.32 samples/sec	Train-FCNLogLoss=1.288226,	
2017-07-17 18:37:27,884 Epoch[3] Batch [140]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.287342,	
2017-07-17 18:37:36,438 Epoch[3] Batch [150]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.279231,	
2017-07-17 18:37:45,100 Epoch[3] Batch [160]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.277818,	
2017-07-17 18:37:53,591 Epoch[3] Batch [170]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.273618,	
2017-07-17 18:38:02,524 Epoch[3] Batch [180]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.273279,	
2017-07-17 18:38:11,098 Epoch[3] Batch [190]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.274701,	
2017-07-17 18:38:19,930 Epoch[3] Batch [200]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.276006,	
2017-07-17 18:38:28,115 Epoch[3] Batch [210]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.269986,	
2017-07-17 18:38:36,046 Epoch[3] Batch [220]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.270329,	
2017-07-17 18:38:44,946 Epoch[3] Batch [230]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.267401,	
2017-07-17 18:38:53,278 Epoch[3] Batch [240]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.266556,	
2017-07-17 18:39:01,228 Epoch[3] Batch [250]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.268580,	
2017-07-17 18:39:09,207 Epoch[3] Batch [260]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.273384,	
2017-07-17 18:39:18,478 Epoch[3] Batch [270]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.269965,	
2017-07-17 18:39:27,007 Epoch[3] Batch [280]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.268715,	
2017-07-17 18:39:35,591 Epoch[3] Batch [290]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.268748,	
2017-07-17 18:39:44,315 Epoch[3] Batch [300]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.264174,	
2017-07-17 18:39:53,432 Epoch[3] Batch [310]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.260929,	
2017-07-17 18:40:01,429 Epoch[3] Batch [320]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.261600,	
2017-07-17 18:40:09,717 Epoch[3] Batch [330]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.261075,	
2017-07-17 18:40:17,918 Epoch[3] Batch [340]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.260030,	
2017-07-17 18:40:25,892 Epoch[3] Batch [350]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.261862,	
2017-07-17 18:40:34,161 Epoch[3] Batch [360]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.260583,	
2017-07-17 18:40:42,351 Epoch[3] Batch [370]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.259759,	
2017-07-17 18:40:51,250 Epoch[3] Batch [380]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.261232,	
2017-07-17 18:41:00,347 Epoch[3] Batch [390]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.262986,	
2017-07-17 18:41:08,636 Epoch[3] Batch [400]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.264015,	
2017-07-17 18:41:17,521 Epoch[3] Batch [410]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.262641,	
2017-07-17 18:41:25,510 Epoch[3] Batch [420]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.262933,	
2017-07-17 18:41:33,645 Epoch[3] Batch [430]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.259597,	
2017-07-17 18:41:43,001 Epoch[3] Batch [440]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.260467,	
2017-07-17 18:41:51,732 Epoch[3] Batch [450]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.260610,	
2017-07-17 18:42:00,397 Epoch[3] Batch [460]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.261418,	
2017-07-17 18:42:08,540 Epoch[3] Batch [470]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.263886,	
2017-07-17 18:42:17,235 Epoch[3] Batch [480]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.263285,	
2017-07-17 18:42:25,414 Epoch[3] Batch [490]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.262963,	
2017-07-17 18:42:33,729 Epoch[3] Batch [500]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.260686,	
2017-07-17 18:42:41,974 Epoch[3] Batch [510]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.261966,	
2017-07-17 18:42:50,335 Epoch[3] Batch [520]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.260198,	
2017-07-17 18:42:59,498 Epoch[3] Batch [530]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.258428,	
2017-07-17 18:43:07,975 Epoch[3] Batch [540]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.259235,	
2017-07-17 18:43:16,179 Epoch[3] Batch [550]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.260125,	
2017-07-17 18:43:24,104 Epoch[3] Batch [560]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.260106,	
2017-07-17 18:43:31,977 Epoch[3] Batch [570]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.260308,	
2017-07-17 18:43:40,685 Epoch[3] Batch [580]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.258761,	
2017-07-17 18:43:49,206 Epoch[3] Batch [590]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.258631,	
2017-07-17 18:43:57,971 Epoch[3] Batch [600]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.258455,	
2017-07-17 18:44:06,790 Epoch[3] Batch [610]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.259688,	
2017-07-17 18:44:15,188 Epoch[3] Batch [620]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.259105,	
2017-07-17 18:44:23,418 Epoch[3] Batch [630]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.260027,	
2017-07-17 18:44:32,357 Epoch[3] Batch [640]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.259731,	
2017-07-17 18:44:40,790 Epoch[3] Batch [650]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.258593,	
2017-07-17 18:44:49,515 Epoch[3] Batch [660]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.257950,	
2017-07-17 18:44:57,785 Epoch[3] Batch [670]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.256596,	
2017-07-17 18:45:06,385 Epoch[3] Batch [680]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.256747,	
2017-07-17 18:45:15,521 Epoch[3] Batch [690]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.256820,	
2017-07-17 18:45:23,666 Epoch[3] Batch [700]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.256324,	
2017-07-17 18:45:31,762 Epoch[3] Batch [710]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.255042,	
2017-07-17 18:45:40,470 Epoch[3] Batch [720]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.254371,	
2017-07-17 18:45:49,997 Epoch[3] Batch [730]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.255611,	
2017-07-17 18:45:58,570 Epoch[3] Batch [740]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.254410,	
2017-07-17 18:46:07,094 Epoch[3] Batch [750]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.254996,	
2017-07-17 18:46:15,838 Epoch[3] Batch [760]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.255531,	
2017-07-17 18:46:25,231 Epoch[3] Batch [770]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.254583,	
2017-07-17 18:46:33,598 Epoch[3] Batch [780]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.254987,	
2017-07-17 18:46:42,128 Epoch[3] Batch [790]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.255158,	
2017-07-17 18:46:50,781 Epoch[3] Batch [800]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.255539,	
2017-07-17 18:46:58,747 Epoch[3] Batch [810]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.256503,	
2017-07-17 18:47:07,624 Epoch[3] Batch [820]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.256872,	
2017-07-17 18:47:16,090 Epoch[3] Batch [830]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.256344,	
2017-07-17 18:47:24,428 Epoch[3] Batch [840]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.255220,	
2017-07-17 18:47:32,727 Epoch[3] Batch [850]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.255981,	
2017-07-17 18:47:41,701 Epoch[3] Batch [860]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.256121,	
2017-07-17 18:47:50,015 Epoch[3] Batch [870]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.255221,	
2017-07-17 18:47:59,295 Epoch[3] Batch [880]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.254703,	
2017-07-17 18:48:07,799 Epoch[3] Batch [890]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.254525,	
2017-07-17 18:48:16,539 Epoch[3] Batch [900]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.254048,	
2017-07-17 18:48:24,862 Epoch[3] Batch [910]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.255010,	
2017-07-17 18:48:33,028 Epoch[3] Batch [920]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.255087,	
2017-07-17 18:48:41,496 Epoch[3] Batch [930]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.255553,	
2017-07-17 18:48:51,028 Epoch[3] Batch [940]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.255964,	
2017-07-17 18:49:00,125 Epoch[3] Batch [950]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.256737,	
2017-07-17 18:49:08,550 Epoch[3] Batch [960]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.257061,	
2017-07-17 18:49:17,154 Epoch[3] Batch [970]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.257833,	
2017-07-17 18:49:25,310 Epoch[3] Batch [980]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.257431,	
2017-07-17 18:49:33,624 Epoch[3] Batch [990]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.257644,	
2017-07-17 18:49:42,000 Epoch[3] Batch [1000]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.256838,	
2017-07-17 18:49:50,230 Epoch[3] Batch [1010]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.256015,	
2017-07-17 18:49:58,637 Epoch[3] Batch [1020]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.254466,	
2017-07-17 18:50:06,803 Epoch[3] Batch [1030]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.254299,	
2017-07-17 18:50:14,984 Epoch[3] Batch [1040]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.255253,	
2017-07-17 18:50:24,053 Epoch[3] Batch [1050]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.255090,	
2017-07-17 18:50:32,421 Epoch[3] Batch [1060]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.254587,	
2017-07-17 18:50:41,550 Epoch[3] Batch [1070]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.254925,	
2017-07-17 18:50:50,156 Epoch[3] Batch [1080]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.255594,	
2017-07-17 18:50:58,939 Epoch[3] Batch [1090]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.255580,	
2017-07-17 18:51:07,302 Epoch[3] Batch [1100]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.254789,	
2017-07-17 18:51:15,960 Epoch[3] Batch [1110]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.255551,	
2017-07-17 18:51:24,808 Epoch[3] Batch [1120]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.255007,	
2017-07-17 18:51:34,319 Epoch[3] Batch [1130]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.254717,	
2017-07-17 18:51:43,462 Epoch[3] Batch [1140]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.255015,	
2017-07-17 18:51:51,414 Epoch[3] Batch [1150]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.255361,	
2017-07-17 18:52:00,195 Epoch[3] Batch [1160]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.255544,	
2017-07-17 18:52:09,027 Epoch[3] Batch [1170]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.254825,	
2017-07-17 18:52:18,749 Epoch[3] Batch [1180]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.254649,	
2017-07-17 18:52:27,134 Epoch[3] Batch [1190]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.255998,	
2017-07-17 18:52:35,745 Epoch[3] Batch [1200]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.255649,	
2017-07-17 18:52:44,317 Epoch[3] Batch [1210]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.255000,	
2017-07-17 18:52:53,960 Epoch[3] Batch [1220]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.255273,	
2017-07-17 18:53:02,876 Epoch[3] Batch [1230]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.255188,	
2017-07-17 18:53:11,510 Epoch[3] Batch [1240]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.254626,	
2017-07-17 18:53:20,327 Epoch[3] Batch [1250]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.254407,	
2017-07-17 18:53:30,028 Epoch[3] Batch [1260]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.254874,	
2017-07-17 18:53:38,288 Epoch[3] Batch [1270]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.255241,	
2017-07-17 18:53:46,697 Epoch[3] Batch [1280]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.254527,	
2017-07-17 18:53:55,437 Epoch[3] Batch [1290]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.254476,	
2017-07-17 18:54:04,578 Epoch[3] Batch [1300]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.254524,	
2017-07-17 18:54:13,216 Epoch[3] Batch [1310]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.254185,	
2017-07-17 18:54:21,784 Epoch[3] Batch [1320]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.253974,	
2017-07-17 18:54:31,334 Epoch[3] Batch [1330]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.254095,	
2017-07-17 18:54:40,917 Epoch[3] Batch [1340]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.254273,	
2017-07-17 18:54:50,488 Epoch[3] Batch [1350]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.253482,	
2017-07-17 18:54:59,350 Epoch[3] Batch [1360]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.253901,	
2017-07-17 18:55:07,980 Epoch[3] Batch [1370]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.253982,	
2017-07-17 18:55:16,572 Epoch[3] Batch [1380]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.254136,	
2017-07-17 18:55:25,334 Epoch[3] Batch [1390]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.253833,	
2017-07-17 18:55:34,541 Epoch[3] Batch [1400]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.254449,	
2017-07-17 18:55:43,055 Epoch[3] Batch [1410]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.254310,	
2017-07-17 18:55:52,546 Epoch[3] Batch [1420]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.253856,	
2017-07-17 18:56:01,307 Epoch[3] Batch [1430]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.253374,	
2017-07-17 18:56:10,110 Epoch[3] Batch [1440]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.252874,	
2017-07-17 18:56:19,439 Epoch[3] Batch [1450]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.252777,	
2017-07-17 18:56:28,062 Epoch[3] Batch [1460]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.252457,	
2017-07-17 18:56:37,669 Epoch[3] Batch [1470]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.253265,	
2017-07-17 18:56:46,484 Epoch[3] Batch [1480]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.253394,	
2017-07-17 18:56:51,838 Epoch[3] Train-FCNLogLoss=1.253939
2017-07-17 18:56:51,839 Epoch[3] Time cost=1296.353
2017-07-17 18:56:53,386 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.params"
2017-07-17 18:56:56,421 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.states"
2017-07-17 18:57:06,580 Epoch[4] Batch [10]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.199924,	
2017-07-17 18:57:15,772 Epoch[4] Batch [20]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.251224,	
2017-07-17 18:57:25,619 Epoch[4] Batch [30]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.293734,	
2017-07-17 18:57:35,798 Epoch[4] Batch [40]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.284655,	
2017-07-17 18:57:45,335 Epoch[4] Batch [50]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.269516,	
2017-07-17 18:57:55,096 Epoch[4] Batch [60]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.284154,	
2017-07-17 18:58:04,041 Epoch[4] Batch [70]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.275867,	
2017-07-17 18:58:13,104 Epoch[4] Batch [80]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.270635,	
2017-07-17 18:58:22,777 Epoch[4] Batch [90]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.270186,	
2017-07-17 18:58:31,679 Epoch[4] Batch [100]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.272444,	
2017-07-17 18:58:41,006 Epoch[4] Batch [110]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.269691,	
2017-07-17 18:58:50,989 Epoch[4] Batch [120]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.270717,	
2017-07-17 18:59:00,649 Epoch[4] Batch [130]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.257585,	
2017-07-17 18:59:10,698 Epoch[4] Batch [140]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.256623,	
2017-07-17 18:59:19,705 Epoch[4] Batch [150]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.255844,	
2017-07-17 18:59:28,315 Epoch[4] Batch [160]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.259210,	
2017-07-17 18:59:37,860 Epoch[4] Batch [170]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.264131,	
2017-07-17 18:59:46,780 Epoch[4] Batch [180]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.262251,	
2017-07-17 18:59:56,177 Epoch[4] Batch [190]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.265724,	
2017-07-17 19:00:04,938 Epoch[4] Batch [200]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.261416,	
2017-07-17 19:00:13,568 Epoch[4] Batch [210]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.262965,	
2017-07-17 19:00:23,197 Epoch[4] Batch [220]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.260018,	
2017-07-17 19:00:31,722 Epoch[4] Batch [230]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.256217,	
2017-07-17 19:00:39,993 Epoch[4] Batch [240]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.259335,	
2017-07-17 19:00:48,992 Epoch[4] Batch [250]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.258986,	
2017-07-17 19:00:57,607 Epoch[4] Batch [260]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.258278,	
2017-07-17 19:01:07,322 Epoch[4] Batch [270]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.260261,	
2017-07-17 19:01:16,319 Epoch[4] Batch [280]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.258815,	
2017-07-17 19:01:26,931 Epoch[4] Batch [290]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.258962,	
2017-07-17 19:01:35,755 Epoch[4] Batch [300]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.258102,	
2017-07-17 19:01:46,194 Epoch[4] Batch [310]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.256793,	
2017-07-17 19:01:55,853 Epoch[4] Batch [320]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.256398,	
2017-07-17 19:02:04,242 Epoch[4] Batch [330]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.255779,	
2017-07-17 19:02:12,924 Epoch[4] Batch [340]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.256461,	
2017-07-17 19:02:22,313 Epoch[4] Batch [350]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.257742,	
2017-07-17 19:02:31,279 Epoch[4] Batch [360]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.255819,	
2017-07-17 19:02:40,279 Epoch[4] Batch [370]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.258404,	
2017-07-17 19:02:50,667 Epoch[4] Batch [380]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.259271,	
2017-07-17 19:03:00,338 Epoch[4] Batch [390]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.259006,	
2017-07-17 19:03:09,675 Epoch[4] Batch [400]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.259658,	
2017-07-17 19:03:18,163 Epoch[4] Batch [410]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.257762,	
2017-07-17 19:03:26,800 Epoch[4] Batch [420]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.256867,	
2017-07-17 19:03:36,376 Epoch[4] Batch [430]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.257421,	
2017-07-17 19:03:45,318 Epoch[4] Batch [440]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.257522,	
2017-07-17 19:03:54,757 Epoch[4] Batch [450]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.256843,	
2017-07-17 19:04:03,863 Epoch[4] Batch [460]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.258093,	
2017-07-17 19:04:13,109 Epoch[4] Batch [470]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.257005,	
2017-07-17 19:04:21,878 Epoch[4] Batch [480]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.256450,	
2017-07-17 19:04:30,604 Epoch[4] Batch [490]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.254110,	
2017-07-17 19:04:39,587 Epoch[4] Batch [500]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.253564,	
2017-07-17 19:04:48,666 Epoch[4] Batch [510]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.251843,	
2017-07-17 19:04:57,150 Epoch[4] Batch [520]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.252362,	
2017-07-17 19:05:06,233 Epoch[4] Batch [530]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.253610,	
2017-07-17 19:05:14,549 Epoch[4] Batch [540]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.252971,	
2017-07-17 19:05:23,181 Epoch[4] Batch [550]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.255609,	
2017-07-17 19:05:31,640 Epoch[4] Batch [560]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.256007,	
2017-07-17 19:05:40,560 Epoch[4] Batch [570]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.257615,	
2017-07-17 19:05:49,940 Epoch[4] Batch [580]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.255598,	
2017-07-17 19:05:58,729 Epoch[4] Batch [590]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.254266,	
2017-07-17 19:06:07,803 Epoch[4] Batch [600]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.254178,	
2017-07-17 19:06:16,578 Epoch[4] Batch [610]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.253190,	
2017-07-17 19:06:25,299 Epoch[4] Batch [620]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.252861,	
2017-07-17 19:06:34,303 Epoch[4] Batch [630]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.252918,	
2017-07-17 19:06:42,750 Epoch[4] Batch [640]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.252047,	
2017-07-17 19:06:52,198 Epoch[4] Batch [650]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.251311,	
2017-07-17 19:07:01,463 Epoch[4] Batch [660]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.250898,	
2017-07-17 19:07:10,377 Epoch[4] Batch [670]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.249766,	
2017-07-17 19:07:19,161 Epoch[4] Batch [680]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.249615,	
2017-07-17 19:07:28,299 Epoch[4] Batch [690]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.249422,	
2017-07-17 19:07:37,602 Epoch[4] Batch [700]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.248494,	
2017-07-17 19:07:46,735 Epoch[4] Batch [710]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.249170,	
2017-07-17 19:07:56,159 Epoch[4] Batch [720]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.248212,	
2017-07-17 19:08:05,288 Epoch[4] Batch [730]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.248010,	
2017-07-17 19:08:15,378 Epoch[4] Batch [740]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.248064,	
2017-07-17 19:08:24,255 Epoch[4] Batch [750]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.248221,	
2017-07-17 19:08:34,456 Epoch[4] Batch [760]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.247573,	
2017-07-17 19:08:43,460 Epoch[4] Batch [770]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.248826,	
2017-07-17 19:08:52,444 Epoch[4] Batch [780]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.249322,	
2017-07-17 19:09:01,327 Epoch[4] Batch [790]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.248386,	
2017-07-17 19:09:10,936 Epoch[4] Batch [800]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.247352,	
2017-07-17 19:09:20,092 Epoch[4] Batch [810]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.247316,	
2017-07-17 19:09:29,127 Epoch[4] Batch [820]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.247256,	
2017-07-17 19:09:37,834 Epoch[4] Batch [830]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.247141,	
2017-07-17 19:09:46,770 Epoch[4] Batch [840]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.247924,	
2017-07-17 19:09:55,604 Epoch[4] Batch [850]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.246598,	
2017-07-17 19:10:04,423 Epoch[4] Batch [860]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.245673,	
2017-07-17 19:10:13,670 Epoch[4] Batch [870]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.246635,	
2017-07-17 19:10:22,235 Epoch[4] Batch [880]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.247485,	
2017-07-17 19:10:31,755 Epoch[4] Batch [890]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.247424,	
2017-07-17 19:10:40,297 Epoch[4] Batch [900]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.247970,	
2017-07-17 19:10:49,379 Epoch[4] Batch [910]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.248164,	
2017-07-17 19:10:58,306 Epoch[4] Batch [920]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.248724,	
2017-07-17 19:11:07,435 Epoch[4] Batch [930]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.248973,	
2017-07-17 19:11:15,924 Epoch[4] Batch [940]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.249817,	
2017-07-17 19:11:24,923 Epoch[4] Batch [950]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.249847,	
2017-07-17 19:11:33,561 Epoch[4] Batch [960]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.249626,	
2017-07-17 19:11:42,417 Epoch[4] Batch [970]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.249879,	
2017-07-17 19:11:51,212 Epoch[4] Batch [980]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.249747,	
2017-07-17 19:12:00,600 Epoch[4] Batch [990]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.249502,	
2017-07-17 19:12:25,044 Epoch[4] Batch [1000]	Speed: 1.64 samples/sec	Train-FCNLogLoss=1.248567,	
2017-07-17 19:12:33,423 Epoch[4] Batch [1010]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.250180,	
2017-07-17 19:12:41,902 Epoch[4] Batch [1020]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.249974,	
2017-07-17 19:12:50,694 Epoch[4] Batch [1030]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.250320,	
2017-07-17 19:13:01,167 Epoch[4] Batch [1040]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.250773,	
2017-07-17 19:13:10,161 Epoch[4] Batch [1050]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.250616,	
2017-07-17 19:13:19,026 Epoch[4] Batch [1060]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.250523,	
2017-07-17 19:13:28,474 Epoch[4] Batch [1070]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.249367,	
2017-07-17 19:13:37,265 Epoch[4] Batch [1080]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.248479,	
2017-07-17 19:13:45,882 Epoch[4] Batch [1090]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.248937,	
2017-07-17 19:13:54,538 Epoch[4] Batch [1100]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.248535,	
2017-07-17 19:14:03,687 Epoch[4] Batch [1110]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.247874,	
2017-07-17 19:14:13,246 Epoch[4] Batch [1120]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.247395,	
2017-07-17 19:14:22,457 Epoch[4] Batch [1130]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.247685,	
2017-07-17 19:14:31,211 Epoch[4] Batch [1140]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.247969,	
2017-07-17 19:14:39,809 Epoch[4] Batch [1150]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.247589,	
2017-07-17 19:14:48,602 Epoch[4] Batch [1160]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.247480,	
2017-07-17 19:14:57,578 Epoch[4] Batch [1170]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.247616,	
2017-07-17 19:15:06,942 Epoch[4] Batch [1180]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.247262,	
2017-07-17 19:15:15,465 Epoch[4] Batch [1190]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.247910,	
2017-07-17 19:15:24,381 Epoch[4] Batch [1200]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.248419,	
2017-07-17 19:15:33,201 Epoch[4] Batch [1210]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.249140,	
2017-07-17 19:15:42,214 Epoch[4] Batch [1220]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.248466,	
2017-07-17 19:15:50,852 Epoch[4] Batch [1230]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.247738,	
2017-07-17 19:15:59,699 Epoch[4] Batch [1240]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.247347,	
2017-07-17 19:16:08,936 Epoch[4] Batch [1250]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.247211,	
2017-07-17 19:16:17,701 Epoch[4] Batch [1260]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.247177,	
2017-07-17 19:16:27,684 Epoch[4] Batch [1270]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.246724,	
2017-07-17 19:16:36,330 Epoch[4] Batch [1280]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.247427,	
2017-07-17 19:16:45,358 Epoch[4] Batch [1290]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.247531,	
2017-07-17 19:16:54,332 Epoch[4] Batch [1300]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.247566,	
2017-07-17 19:17:02,880 Epoch[4] Batch [1310]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.247383,	
2017-07-17 19:17:11,389 Epoch[4] Batch [1320]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.247740,	
2017-07-17 19:17:20,720 Epoch[4] Batch [1330]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.247492,	
2017-07-17 19:17:30,130 Epoch[4] Batch [1340]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.247170,	
2017-07-17 19:17:38,315 Epoch[4] Batch [1350]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.248241,	
2017-07-17 19:17:46,557 Epoch[4] Batch [1360]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.248850,	
2017-07-17 19:17:55,036 Epoch[4] Batch [1370]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.249071,	
2017-07-17 19:18:03,627 Epoch[4] Batch [1380]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.249735,	
2017-07-17 19:18:12,621 Epoch[4] Batch [1390]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.249464,	
2017-07-17 19:18:22,078 Epoch[4] Batch [1400]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.249266,	
2017-07-17 19:18:31,065 Epoch[4] Batch [1410]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.250215,	
2017-07-17 19:18:40,443 Epoch[4] Batch [1420]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.249892,	
2017-07-17 19:18:49,343 Epoch[4] Batch [1430]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.250719,	
2017-07-17 19:18:58,913 Epoch[4] Batch [1440]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.250671,	
2017-07-17 19:19:07,271 Epoch[4] Batch [1450]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.250386,	
2017-07-17 19:19:16,132 Epoch[4] Batch [1460]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.249769,	
2017-07-17 19:19:24,802 Epoch[4] Batch [1470]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.250006,	
2017-07-17 19:19:34,542 Epoch[4] Batch [1480]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.249709,	
2017-07-17 19:19:39,510 Epoch[4] Train-FCNLogLoss=1.250328
2017-07-17 19:19:39,510 Epoch[4] Time cost=1362.840
2017-07-17 19:19:41,268 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.params"
2017-07-17 19:19:44,880 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.states"
2017-07-17 19:19:54,863 Epoch[5] Batch [10]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.295440,	
2017-07-17 19:20:02,869 Epoch[5] Batch [20]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.278105,	
2017-07-17 19:20:10,139 Epoch[5] Batch [30]	Speed: 5.50 samples/sec	Train-FCNLogLoss=1.276107,	
2017-07-17 19:20:18,112 Epoch[5] Batch [40]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.268033,	
2017-07-17 19:20:25,601 Epoch[5] Batch [50]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.263274,	
2017-07-17 19:20:33,284 Epoch[5] Batch [60]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.257668,	
2017-07-17 19:20:41,167 Epoch[5] Batch [70]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.258320,	
2017-07-17 19:20:48,713 Epoch[5] Batch [80]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.269978,	
2017-07-17 19:20:56,323 Epoch[5] Batch [90]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.275693,	
2017-07-17 19:21:05,011 Epoch[5] Batch [100]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.261711,	
2017-07-17 19:21:12,807 Epoch[5] Batch [110]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.262854,	
2017-07-17 19:21:21,036 Epoch[5] Batch [120]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.266321,	
2017-07-17 19:21:30,318 Epoch[5] Batch [130]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.258788,	
2017-07-17 19:21:39,608 Epoch[5] Batch [140]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.254939,	
2017-07-17 19:21:47,852 Epoch[5] Batch [150]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.264950,	
2017-07-17 19:21:55,303 Epoch[5] Batch [160]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.260954,	
2017-07-17 19:22:03,110 Epoch[5] Batch [170]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.256149,	
2017-07-17 19:22:11,064 Epoch[5] Batch [180]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.257046,	
2017-07-17 19:22:19,335 Epoch[5] Batch [190]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.255721,	
2017-07-17 19:22:27,289 Epoch[5] Batch [200]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.257993,	
2017-07-17 19:22:35,990 Epoch[5] Batch [210]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.260669,	
2017-07-17 19:22:43,882 Epoch[5] Batch [220]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.262031,	
2017-07-17 19:22:51,893 Epoch[5] Batch [230]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.263301,	
2017-07-17 19:22:59,584 Epoch[5] Batch [240]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.266499,	
2017-07-17 19:23:07,318 Epoch[5] Batch [250]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.265867,	
2017-07-17 19:23:15,772 Epoch[5] Batch [260]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.268088,	
2017-07-17 19:23:23,814 Epoch[5] Batch [270]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.262649,	
2017-07-17 19:23:31,526 Epoch[5] Batch [280]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.262498,	
2017-07-17 19:23:39,127 Epoch[5] Batch [290]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.261601,	
2017-07-17 19:23:47,821 Epoch[5] Batch [300]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.264120,	
2017-07-17 19:23:55,897 Epoch[5] Batch [310]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.264619,	
2017-07-17 19:24:03,572 Epoch[5] Batch [320]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.264700,	
2017-07-17 19:24:11,933 Epoch[5] Batch [330]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.265894,	
2017-07-17 19:24:19,499 Epoch[5] Batch [340]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.265699,	
2017-07-17 19:24:26,965 Epoch[5] Batch [350]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.267249,	
2017-07-17 19:24:35,335 Epoch[5] Batch [360]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.267762,	
2017-07-17 19:24:43,216 Epoch[5] Batch [370]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.268942,	
2017-07-17 19:24:51,904 Epoch[5] Batch [380]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.271083,	
2017-07-17 19:25:00,033 Epoch[5] Batch [390]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.269354,	
2017-07-17 19:25:09,206 Epoch[5] Batch [400]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.270419,	
2017-07-17 19:25:17,822 Epoch[5] Batch [410]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.270850,	
2017-07-17 19:25:25,362 Epoch[5] Batch [420]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.271189,	
2017-07-17 19:25:34,468 Epoch[5] Batch [430]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.269060,	
2017-07-17 19:25:41,752 Epoch[5] Batch [440]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.266279,	
2017-07-17 19:25:50,023 Epoch[5] Batch [450]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.268553,	
2017-07-17 19:25:58,274 Epoch[5] Batch [460]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.267558,	
2017-07-17 19:26:06,117 Epoch[5] Batch [470]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.266777,	
2017-07-17 19:26:14,239 Epoch[5] Batch [480]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.267514,	
2017-07-17 19:26:22,573 Epoch[5] Batch [490]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.265874,	
2017-07-17 19:26:30,314 Epoch[5] Batch [500]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.265989,	
2017-07-17 19:26:38,937 Epoch[5] Batch [510]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.266118,	
2017-07-17 19:26:46,383 Epoch[5] Batch [520]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.264907,	
2017-07-17 19:26:54,691 Epoch[5] Batch [530]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.263806,	
2017-07-17 19:27:03,143 Epoch[5] Batch [540]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.263377,	
2017-07-17 19:27:10,940 Epoch[5] Batch [550]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.264824,	
2017-07-17 19:27:19,579 Epoch[5] Batch [560]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.263733,	
2017-07-17 19:27:27,873 Epoch[5] Batch [570]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.264619,	
2017-07-17 19:27:36,104 Epoch[5] Batch [580]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.264271,	
2017-07-17 19:27:44,350 Epoch[5] Batch [590]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.262993,	
2017-07-17 19:27:52,065 Epoch[5] Batch [600]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.263235,	
2017-07-17 19:28:00,357 Epoch[5] Batch [610]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.263239,	
2017-07-17 19:28:08,479 Epoch[5] Batch [620]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.261526,	
2017-07-17 19:28:17,115 Epoch[5] Batch [630]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.261795,	
2017-07-17 19:28:25,269 Epoch[5] Batch [640]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.260877,	
2017-07-17 19:28:33,637 Epoch[5] Batch [650]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.260916,	
2017-07-17 19:28:42,254 Epoch[5] Batch [660]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.260913,	
2017-07-17 19:28:50,583 Epoch[5] Batch [670]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.260717,	
2017-07-17 19:28:58,916 Epoch[5] Batch [680]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.259803,	
2017-07-17 19:29:07,291 Epoch[5] Batch [690]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.257783,	
2017-07-17 19:29:15,140 Epoch[5] Batch [700]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.257089,	
2017-07-17 19:29:23,315 Epoch[5] Batch [710]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.255732,	
2017-07-17 19:29:31,132 Epoch[5] Batch [720]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.255715,	
2017-07-17 19:29:38,938 Epoch[5] Batch [730]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.257246,	
2017-07-17 19:29:46,883 Epoch[5] Batch [740]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.257570,	
2017-07-17 19:29:54,995 Epoch[5] Batch [750]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.258364,	
2017-07-17 19:30:03,122 Epoch[5] Batch [760]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.257533,	
2017-07-17 19:30:10,981 Epoch[5] Batch [770]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.258312,	
2017-07-17 19:30:18,957 Epoch[5] Batch [780]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.257006,	
2017-07-17 19:30:27,443 Epoch[5] Batch [790]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.258662,	
2017-07-17 19:30:35,082 Epoch[5] Batch [800]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.259547,	
2017-07-17 19:30:43,089 Epoch[5] Batch [810]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.260443,	
2017-07-17 19:30:51,072 Epoch[5] Batch [820]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.258386,	
2017-07-17 19:30:58,972 Epoch[5] Batch [830]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.259111,	
2017-07-17 19:31:07,205 Epoch[5] Batch [840]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.258054,	
2017-07-17 19:31:15,309 Epoch[5] Batch [850]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.257989,	
2017-07-17 19:31:23,072 Epoch[5] Batch [860]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.258796,	
2017-07-17 19:31:31,151 Epoch[5] Batch [870]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.257665,	
2017-07-17 19:31:38,815 Epoch[5] Batch [880]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.258178,	
2017-07-17 19:31:46,307 Epoch[5] Batch [890]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.257927,	
2017-07-17 19:31:53,938 Epoch[5] Batch [900]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.257154,	
2017-07-17 19:32:01,701 Epoch[5] Batch [910]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.257183,	
2017-07-17 19:32:09,216 Epoch[5] Batch [920]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.256440,	
2017-07-17 19:32:17,296 Epoch[5] Batch [930]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.256612,	
2017-07-17 19:32:25,164 Epoch[5] Batch [940]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.257209,	
2017-07-17 19:32:32,954 Epoch[5] Batch [950]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.257174,	
2017-07-17 19:32:40,768 Epoch[5] Batch [960]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.257432,	
2017-07-17 19:32:48,474 Epoch[5] Batch [970]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.256869,	
2017-07-17 19:32:56,855 Epoch[5] Batch [980]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.256544,	
2017-07-17 19:33:04,638 Epoch[5] Batch [990]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.256393,	
2017-07-17 19:33:12,850 Epoch[5] Batch [1000]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.256830,	
2017-07-17 19:33:20,626 Epoch[5] Batch [1010]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.257277,	
2017-07-17 19:33:28,576 Epoch[5] Batch [1020]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.258172,	
2017-07-17 19:33:36,718 Epoch[5] Batch [1030]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.257632,	
2017-07-17 19:33:44,759 Epoch[5] Batch [1040]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.256368,	
2017-07-17 19:33:52,335 Epoch[5] Batch [1050]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.255900,	
2017-07-17 19:33:59,746 Epoch[5] Batch [1060]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.255824,	
2017-07-17 19:34:07,483 Epoch[5] Batch [1070]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.255293,	
2017-07-17 19:34:15,456 Epoch[5] Batch [1080]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.256525,	
2017-07-17 19:34:22,901 Epoch[5] Batch [1090]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.255850,	
2017-07-17 19:34:30,608 Epoch[5] Batch [1100]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.254986,	
2017-07-17 19:34:38,434 Epoch[5] Batch [1110]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.255581,	
2017-07-17 19:34:45,832 Epoch[5] Batch [1120]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.255657,	
2017-07-17 19:34:53,292 Epoch[5] Batch [1130]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.255730,	
2017-07-17 19:35:01,343 Epoch[5] Batch [1140]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.255699,	
2017-07-17 19:35:09,119 Epoch[5] Batch [1150]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.255708,	
2017-07-17 19:35:17,237 Epoch[5] Batch [1160]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.255483,	
2017-07-17 19:35:24,982 Epoch[5] Batch [1170]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.254573,	
2017-07-17 19:35:32,772 Epoch[5] Batch [1180]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.254127,	
2017-07-17 19:35:40,257 Epoch[5] Batch [1190]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.254109,	
2017-07-17 19:35:48,700 Epoch[5] Batch [1200]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.253850,	
2017-07-17 19:35:56,989 Epoch[5] Batch [1210]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.254098,	
2017-07-17 19:36:04,348 Epoch[5] Batch [1220]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.253349,	
2017-07-17 19:36:11,819 Epoch[5] Batch [1230]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.253276,	
2017-07-17 19:36:19,047 Epoch[5] Batch [1240]	Speed: 5.53 samples/sec	Train-FCNLogLoss=1.254036,	
2017-07-17 19:36:27,029 Epoch[5] Batch [1250]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.254092,	
2017-07-17 19:36:34,627 Epoch[5] Batch [1260]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.254585,	
2017-07-17 19:36:51,010 Epoch[5] Batch [1270]	Speed: 2.44 samples/sec	Train-FCNLogLoss=1.254434,	
2017-07-17 19:36:59,001 Epoch[5] Batch [1280]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.254127,	
2017-07-17 19:37:06,223 Epoch[5] Batch [1290]	Speed: 5.54 samples/sec	Train-FCNLogLoss=1.254300,	
2017-07-17 19:37:14,098 Epoch[5] Batch [1300]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.254820,	
2017-07-17 19:37:22,234 Epoch[5] Batch [1310]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.255227,	
2017-07-17 19:37:30,393 Epoch[5] Batch [1320]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.254537,	
2017-07-17 19:37:38,282 Epoch[5] Batch [1330]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.254216,	
2017-07-17 19:37:46,064 Epoch[5] Batch [1340]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.253993,	
2017-07-17 19:37:53,480 Epoch[5] Batch [1350]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.253728,	
2017-07-17 19:38:01,397 Epoch[5] Batch [1360]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.253048,	
2017-07-17 19:38:09,385 Epoch[5] Batch [1370]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.254147,	
2017-07-17 19:38:17,015 Epoch[5] Batch [1380]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.254360,	
2017-07-17 19:38:25,203 Epoch[5] Batch [1390]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.253979,	
2017-07-17 19:38:32,942 Epoch[5] Batch [1400]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.253516,	
2017-07-17 19:38:41,424 Epoch[5] Batch [1410]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.253097,	
2017-07-17 19:38:49,766 Epoch[5] Batch [1420]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.252866,	
2017-07-17 19:38:57,973 Epoch[5] Batch [1430]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.252661,	
2017-07-17 19:39:05,967 Epoch[5] Batch [1440]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.252036,	
2017-07-17 19:39:14,323 Epoch[5] Batch [1450]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.252673,	
2017-07-17 19:39:22,331 Epoch[5] Batch [1460]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.253020,	
2017-07-17 19:39:30,135 Epoch[5] Batch [1470]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.252603,	
2017-07-17 19:39:38,033 Epoch[5] Batch [1480]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.252417,	
2017-07-17 19:39:42,961 Epoch[5] Train-FCNLogLoss=1.252596
2017-07-17 19:39:42,961 Epoch[5] Time cost=1197.872
2017-07-17 19:39:44,036 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.params"
2017-07-17 19:39:47,087 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.states"
2017-07-17 19:39:56,973 Epoch[6] Batch [10]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.189400,	
2017-07-17 19:40:05,008 Epoch[6] Batch [20]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.202581,	
2017-07-17 19:40:12,444 Epoch[6] Batch [30]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.224237,	
2017-07-17 19:40:21,639 Epoch[6] Batch [40]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.244319,	
2017-07-17 19:40:29,958 Epoch[6] Batch [50]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.228888,	
2017-07-17 19:40:38,811 Epoch[6] Batch [60]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.219600,	
2017-07-17 19:40:48,539 Epoch[6] Batch [70]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.217778,	
2017-07-17 19:40:58,079 Epoch[6] Batch [80]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.234059,	
2017-07-17 19:41:07,711 Epoch[6] Batch [90]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.235405,	
2017-07-17 19:41:17,712 Epoch[6] Batch [100]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.230308,	
2017-07-17 19:41:27,570 Epoch[6] Batch [110]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.228502,	
2017-07-17 19:41:37,541 Epoch[6] Batch [120]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.225533,	
2017-07-17 19:41:47,244 Epoch[6] Batch [130]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.231188,	
2017-07-17 19:41:56,996 Epoch[6] Batch [140]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.227959,	
2017-07-17 19:42:06,682 Epoch[6] Batch [150]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.234542,	
2017-07-17 19:42:16,562 Epoch[6] Batch [160]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.235298,	
2017-07-17 19:42:25,743 Epoch[6] Batch [170]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.235066,	
2017-07-17 19:42:34,944 Epoch[6] Batch [180]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.235466,	
2017-07-17 19:42:44,227 Epoch[6] Batch [190]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.230878,	
2017-07-17 19:42:53,299 Epoch[6] Batch [200]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.232457,	
2017-07-17 19:43:03,016 Epoch[6] Batch [210]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.236840,	
2017-07-17 19:43:12,570 Epoch[6] Batch [220]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.234409,	
2017-07-17 19:43:22,298 Epoch[6] Batch [230]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.239632,	
2017-07-17 19:43:32,723 Epoch[6] Batch [240]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.236819,	
2017-07-17 19:43:42,799 Epoch[6] Batch [250]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.239100,	
2017-07-17 19:43:53,412 Epoch[6] Batch [260]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.242359,	
2017-07-17 19:44:03,656 Epoch[6] Batch [270]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.243672,	
2017-07-17 19:44:13,729 Epoch[6] Batch [280]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.239616,	
2017-07-17 19:44:24,286 Epoch[6] Batch [290]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.239316,	
2017-07-17 19:44:35,013 Epoch[6] Batch [300]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.240378,	
2017-07-17 19:44:45,107 Epoch[6] Batch [310]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.239991,	
2017-07-17 19:44:55,281 Epoch[6] Batch [320]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.239514,	
2017-07-17 19:45:05,413 Epoch[6] Batch [330]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.242760,	
2017-07-17 19:45:15,796 Epoch[6] Batch [340]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.240419,	
2017-07-17 19:45:25,895 Epoch[6] Batch [350]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.238274,	
2017-07-17 19:45:35,935 Epoch[6] Batch [360]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.238548,	
2017-07-17 19:45:46,401 Epoch[6] Batch [370]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.238743,	
2017-07-17 19:45:56,680 Epoch[6] Batch [380]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.241347,	
2017-07-17 19:46:07,116 Epoch[6] Batch [390]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.239726,	
2017-07-17 19:46:17,208 Epoch[6] Batch [400]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.241106,	
2017-07-17 19:46:27,343 Epoch[6] Batch [410]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.240864,	
2017-07-17 19:46:37,277 Epoch[6] Batch [420]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.240436,	
2017-07-17 19:46:47,677 Epoch[6] Batch [430]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.239879,	
2017-07-17 19:46:58,125 Epoch[6] Batch [440]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.241728,	
2017-07-17 19:47:08,104 Epoch[6] Batch [450]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.240916,	
2017-07-17 19:47:18,030 Epoch[6] Batch [460]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.239939,	
2017-07-17 19:47:28,145 Epoch[6] Batch [470]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.239824,	
2017-07-17 19:47:38,229 Epoch[6] Batch [480]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.241754,	
2017-07-17 19:47:48,192 Epoch[6] Batch [490]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.241931,	
2017-07-17 19:47:58,290 Epoch[6] Batch [500]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.244047,	
2017-07-17 19:48:08,209 Epoch[6] Batch [510]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.244589,	
2017-07-17 19:48:18,464 Epoch[6] Batch [520]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.244365,	
2017-07-17 19:48:28,423 Epoch[6] Batch [530]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.244191,	
2017-07-17 19:48:38,334 Epoch[6] Batch [540]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.243576,	
2017-07-17 19:48:48,394 Epoch[6] Batch [550]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.242751,	
2017-07-17 19:48:58,590 Epoch[6] Batch [560]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.239878,	
2017-07-17 19:49:08,731 Epoch[6] Batch [570]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.239771,	
2017-07-17 19:49:18,882 Epoch[6] Batch [580]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.241547,	
2017-07-17 19:49:29,484 Epoch[6] Batch [590]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.241969,	
2017-07-17 19:49:39,577 Epoch[6] Batch [600]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.242518,	
2017-07-17 19:49:49,689 Epoch[6] Batch [610]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.242453,	
2017-07-17 19:49:59,934 Epoch[6] Batch [620]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.242203,	
2017-07-17 19:50:10,215 Epoch[6] Batch [630]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.241491,	
2017-07-17 19:50:20,265 Epoch[6] Batch [640]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.239930,	
2017-07-17 19:50:30,388 Epoch[6] Batch [650]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.239668,	
2017-07-17 19:50:40,482 Epoch[6] Batch [660]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.240452,	
2017-07-17 19:50:50,876 Epoch[6] Batch [670]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.241379,	
2017-07-17 19:51:00,975 Epoch[6] Batch [680]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.242184,	
2017-07-17 19:51:11,411 Epoch[6] Batch [690]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.242661,	
2017-07-17 19:51:21,565 Epoch[6] Batch [700]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.242501,	
2017-07-17 19:51:31,750 Epoch[6] Batch [710]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.241880,	
2017-07-17 19:51:42,001 Epoch[6] Batch [720]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.243056,	
2017-07-17 19:51:52,288 Epoch[6] Batch [730]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.242432,	
2017-07-17 19:52:02,595 Epoch[6] Batch [740]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.240309,	
2017-07-17 19:52:12,793 Epoch[6] Batch [750]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.241140,	
2017-07-17 19:52:22,996 Epoch[6] Batch [760]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.240015,	
2017-07-17 19:52:33,197 Epoch[6] Batch [770]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.239566,	
2017-07-17 19:52:55,056 Epoch[6] Batch [780]	Speed: 1.83 samples/sec	Train-FCNLogLoss=1.240541,	
2017-07-17 19:53:05,374 Epoch[6] Batch [790]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.239330,	
2017-07-17 19:53:15,451 Epoch[6] Batch [800]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.238858,	
2017-07-17 19:53:25,865 Epoch[6] Batch [810]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.238894,	
2017-07-17 19:53:36,278 Epoch[6] Batch [820]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.239633,	
2017-07-17 19:53:46,663 Epoch[6] Batch [830]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.240295,	
2017-07-17 19:53:57,360 Epoch[6] Batch [840]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.240273,	
2017-07-17 19:54:07,888 Epoch[6] Batch [850]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.238667,	
2017-07-17 19:54:18,329 Epoch[6] Batch [860]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.238671,	
2017-07-17 19:54:28,765 Epoch[6] Batch [870]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.238726,	
2017-07-17 19:54:39,831 Epoch[6] Batch [880]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.239324,	
2017-07-17 19:54:50,828 Epoch[6] Batch [890]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.239078,	
2017-07-17 19:55:01,485 Epoch[6] Batch [900]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.238981,	
2017-07-17 19:55:12,447 Epoch[6] Batch [910]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.239557,	
2017-07-17 19:55:23,512 Epoch[6] Batch [920]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.238518,	
2017-07-17 19:55:33,943 Epoch[6] Batch [930]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.238485,	
2017-07-17 19:55:44,587 Epoch[6] Batch [940]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.238107,	
2017-07-17 19:55:55,233 Epoch[6] Batch [950]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.238823,	
2017-07-17 19:56:06,577 Epoch[6] Batch [960]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.238703,	
2017-07-17 19:56:17,211 Epoch[6] Batch [970]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.238800,	
2017-07-17 19:56:27,763 Epoch[6] Batch [980]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.238273,	
2017-07-17 19:56:38,710 Epoch[6] Batch [990]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.238479,	
2017-07-17 19:56:49,436 Epoch[6] Batch [1000]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.238365,	
2017-07-17 19:56:59,834 Epoch[6] Batch [1010]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.238618,	
2017-07-17 19:57:10,430 Epoch[6] Batch [1020]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.238305,	
2017-07-17 19:57:21,032 Epoch[6] Batch [1030]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.237755,	
2017-07-17 19:57:32,185 Epoch[6] Batch [1040]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.237301,	
2017-07-17 19:57:42,804 Epoch[6] Batch [1050]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.237248,	
2017-07-17 19:57:53,749 Epoch[6] Batch [1060]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.238703,	
2017-07-17 19:58:04,283 Epoch[6] Batch [1070]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.239112,	
2017-07-17 19:58:14,875 Epoch[6] Batch [1080]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.239248,	
2017-07-17 19:58:25,338 Epoch[6] Batch [1090]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.238729,	
2017-07-17 19:58:35,820 Epoch[6] Batch [1100]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.239315,	
2017-07-17 19:58:46,426 Epoch[6] Batch [1110]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.239882,	
2017-07-17 19:58:56,918 Epoch[6] Batch [1120]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.239674,	
2017-07-17 19:59:07,806 Epoch[6] Batch [1130]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.240355,	
2017-07-17 19:59:18,134 Epoch[6] Batch [1140]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.241195,	
2017-07-17 19:59:28,449 Epoch[6] Batch [1150]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.241249,	
2017-07-17 19:59:38,902 Epoch[6] Batch [1160]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.242118,	
2017-07-17 19:59:49,466 Epoch[6] Batch [1170]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.242053,	
2017-07-17 19:59:59,609 Epoch[6] Batch [1180]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.242048,	
2017-07-17 20:00:10,056 Epoch[6] Batch [1190]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.242139,	
2017-07-17 20:00:20,624 Epoch[6] Batch [1200]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.242110,	
2017-07-17 20:00:31,086 Epoch[6] Batch [1210]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.241926,	
2017-07-17 20:00:41,476 Epoch[6] Batch [1220]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.241733,	
2017-07-17 20:00:51,896 Epoch[6] Batch [1230]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.242341,	
2017-07-17 20:01:02,308 Epoch[6] Batch [1240]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.241770,	
2017-07-17 20:01:12,850 Epoch[6] Batch [1250]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.241101,	
2017-07-17 20:01:23,418 Epoch[6] Batch [1260]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.240605,	
2017-07-17 20:01:33,740 Epoch[6] Batch [1270]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.240314,	
2017-07-17 20:01:44,201 Epoch[6] Batch [1280]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.239532,	
2017-07-17 20:01:54,565 Epoch[6] Batch [1290]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.239927,	
2017-07-17 20:02:05,228 Epoch[6] Batch [1300]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.239928,	
2017-07-17 20:02:15,616 Epoch[6] Batch [1310]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.240366,	
2017-07-17 20:02:25,950 Epoch[6] Batch [1320]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.240347,	
2017-07-17 20:02:36,382 Epoch[6] Batch [1330]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.240157,	
2017-07-17 20:02:46,664 Epoch[6] Batch [1340]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.240475,	
2017-07-17 20:02:57,243 Epoch[6] Batch [1350]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.240486,	
2017-07-17 20:03:07,838 Epoch[6] Batch [1360]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.240918,	
2017-07-17 20:03:18,390 Epoch[6] Batch [1370]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.241505,	
2017-07-17 20:03:28,665 Epoch[6] Batch [1380]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.241327,	
2017-07-17 20:03:38,836 Epoch[6] Batch [1390]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.241580,	
2017-07-17 20:03:49,079 Epoch[6] Batch [1400]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.241372,	
2017-07-17 20:03:59,343 Epoch[6] Batch [1410]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.240787,	
2017-07-17 20:04:09,768 Epoch[6] Batch [1420]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.240979,	
2017-07-17 20:04:20,243 Epoch[6] Batch [1430]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.241657,	
2017-07-17 20:04:30,639 Epoch[6] Batch [1440]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.240960,	
2017-07-17 20:04:41,474 Epoch[6] Batch [1450]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.240539,	
2017-07-17 20:04:51,809 Epoch[6] Batch [1460]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.240936,	
2017-07-17 20:05:02,638 Epoch[6] Batch [1470]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.241053,	
2017-07-17 20:05:13,215 Epoch[6] Batch [1480]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.241539,	
2017-07-17 20:05:19,701 Epoch[6] Train-FCNLogLoss=1.242323
2017-07-17 20:05:19,701 Epoch[6] Time cost=1532.548
2017-07-17 20:05:21,223 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.params"
2017-07-17 20:05:24,947 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.states"
2017-07-17 20:05:37,088 Epoch[7] Batch [10]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.151136,	
2017-07-17 20:05:47,674 Epoch[7] Batch [20]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.190446,	
2017-07-17 20:05:58,319 Epoch[7] Batch [30]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.188535,	
2017-07-17 20:06:08,885 Epoch[7] Batch [40]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.207350,	
2017-07-17 20:06:19,368 Epoch[7] Batch [50]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.228798,	
2017-07-17 20:06:29,831 Epoch[7] Batch [60]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.230488,	
2017-07-17 20:06:40,189 Epoch[7] Batch [70]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.232406,	
2017-07-17 20:06:50,417 Epoch[7] Batch [80]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.226706,	
2017-07-17 20:07:01,128 Epoch[7] Batch [90]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.223057,	
2017-07-17 20:07:11,567 Epoch[7] Batch [100]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.231345,	
2017-07-17 20:07:21,870 Epoch[7] Batch [110]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.226622,	
2017-07-17 20:07:32,078 Epoch[7] Batch [120]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.224245,	
2017-07-17 20:07:42,505 Epoch[7] Batch [130]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.216090,	
2017-07-17 20:07:52,784 Epoch[7] Batch [140]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.222659,	
2017-07-17 20:08:03,844 Epoch[7] Batch [150]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.221096,	
2017-07-17 20:08:14,688 Epoch[7] Batch [160]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.216461,	
2017-07-17 20:08:25,210 Epoch[7] Batch [170]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.216939,	
2017-07-17 20:08:35,624 Epoch[7] Batch [180]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.218915,	
2017-07-17 20:08:46,149 Epoch[7] Batch [190]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.222789,	
2017-07-17 20:08:56,744 Epoch[7] Batch [200]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.225986,	
2017-07-17 20:09:06,991 Epoch[7] Batch [210]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.224483,	
2017-07-17 20:09:17,214 Epoch[7] Batch [220]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.227703,	
2017-07-17 20:09:27,716 Epoch[7] Batch [230]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.225234,	
2017-07-17 20:09:38,073 Epoch[7] Batch [240]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.227693,	
2017-07-17 20:09:48,794 Epoch[7] Batch [250]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.224974,	
2017-07-17 20:09:59,601 Epoch[7] Batch [260]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.227915,	
2017-07-17 20:10:10,093 Epoch[7] Batch [270]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.228334,	
2017-07-17 20:10:20,635 Epoch[7] Batch [280]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.230295,	
2017-07-17 20:10:31,259 Epoch[7] Batch [290]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.227351,	
2017-07-17 20:10:42,008 Epoch[7] Batch [300]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.226250,	
2017-07-17 20:10:52,914 Epoch[7] Batch [310]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.227652,	
2017-07-17 20:11:03,555 Epoch[7] Batch [320]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.230122,	
2017-07-17 20:11:14,349 Epoch[7] Batch [330]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.232262,	
2017-07-17 20:11:25,096 Epoch[7] Batch [340]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.237570,	
2017-07-17 20:11:35,728 Epoch[7] Batch [350]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.238958,	
2017-07-17 20:11:46,180 Epoch[7] Batch [360]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.240289,	
2017-07-17 20:11:56,705 Epoch[7] Batch [370]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.240397,	
2017-07-17 20:12:07,251 Epoch[7] Batch [380]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.241056,	
2017-07-17 20:12:17,825 Epoch[7] Batch [390]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.243027,	
2017-07-17 20:12:28,164 Epoch[7] Batch [400]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.244905,	
2017-07-17 20:12:39,073 Epoch[7] Batch [410]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.243729,	
2017-07-17 20:12:49,206 Epoch[7] Batch [420]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.241270,	
2017-07-17 20:13:00,009 Epoch[7] Batch [430]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.241284,	
2017-07-17 20:13:10,674 Epoch[7] Batch [440]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.242077,	
2017-07-17 20:13:21,038 Epoch[7] Batch [450]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.243277,	
2017-07-17 20:13:31,295 Epoch[7] Batch [460]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.241971,	
2017-07-17 20:13:41,475 Epoch[7] Batch [470]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.243299,	
2017-07-17 20:13:51,651 Epoch[7] Batch [480]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.243430,	
2017-07-17 20:14:01,752 Epoch[7] Batch [490]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.242943,	
2017-07-17 20:14:12,082 Epoch[7] Batch [500]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.244329,	
2017-07-17 20:14:22,114 Epoch[7] Batch [510]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.244982,	
2017-07-17 20:14:32,909 Epoch[7] Batch [520]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.244443,	
2017-07-17 20:14:43,420 Epoch[7] Batch [530]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.242478,	
2017-07-17 20:14:53,870 Epoch[7] Batch [540]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.243977,	
2017-07-17 20:15:04,414 Epoch[7] Batch [550]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.246481,	
2017-07-17 20:15:14,930 Epoch[7] Batch [560]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.247169,	
2017-07-17 20:15:24,991 Epoch[7] Batch [570]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.246605,	
2017-07-17 20:15:35,326 Epoch[7] Batch [580]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.245812,	
2017-07-17 20:15:45,366 Epoch[7] Batch [590]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.245362,	
2017-07-17 20:15:55,529 Epoch[7] Batch [600]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.245517,	
2017-07-17 20:16:05,801 Epoch[7] Batch [610]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.244437,	
2017-07-17 20:16:15,872 Epoch[7] Batch [620]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.245447,	
2017-07-17 20:16:26,430 Epoch[7] Batch [630]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.244639,	
2017-07-17 20:16:36,364 Epoch[7] Batch [640]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.244869,	
2017-07-17 20:16:46,644 Epoch[7] Batch [650]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.243676,	
2017-07-17 20:16:56,969 Epoch[7] Batch [660]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.243983,	
2017-07-17 20:17:07,353 Epoch[7] Batch [670]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.244856,	
2017-07-17 20:17:17,912 Epoch[7] Batch [680]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.244257,	
2017-07-17 20:17:28,493 Epoch[7] Batch [690]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.246328,	
2017-07-17 20:17:38,873 Epoch[7] Batch [700]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.245184,	
2017-07-17 20:17:49,353 Epoch[7] Batch [710]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.245194,	
2017-07-17 20:17:59,975 Epoch[7] Batch [720]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.245881,	
2017-07-17 20:18:10,622 Epoch[7] Batch [730]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.247211,	
2017-07-17 20:18:20,828 Epoch[7] Batch [740]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.247517,	
2017-07-17 20:18:31,291 Epoch[7] Batch [750]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.247258,	
2017-07-17 20:18:41,718 Epoch[7] Batch [760]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.245286,	
2017-07-17 20:18:52,116 Epoch[7] Batch [770]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.244558,	
2017-07-17 20:19:02,725 Epoch[7] Batch [780]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.244855,	
2017-07-17 20:19:13,372 Epoch[7] Batch [790]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.245266,	
2017-07-17 20:19:23,964 Epoch[7] Batch [800]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.245215,	
2017-07-17 20:19:34,609 Epoch[7] Batch [810]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.245182,	
2017-07-17 20:19:45,197 Epoch[7] Batch [820]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.245477,	
2017-07-17 20:19:55,924 Epoch[7] Batch [830]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.244981,	
2017-07-17 20:20:06,368 Epoch[7] Batch [840]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.244039,	
2017-07-17 20:20:16,774 Epoch[7] Batch [850]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.243877,	
2017-07-17 20:20:27,073 Epoch[7] Batch [860]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.243848,	
2017-07-17 20:20:37,541 Epoch[7] Batch [870]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.243520,	
2017-07-17 20:20:47,971 Epoch[7] Batch [880]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.243514,	
2017-07-17 20:20:58,539 Epoch[7] Batch [890]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.244640,	
2017-07-17 20:21:09,055 Epoch[7] Batch [900]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.243542,	
2017-07-17 20:21:28,706 Epoch[7] Batch [910]	Speed: 2.04 samples/sec	Train-FCNLogLoss=1.242566,	
2017-07-17 20:21:39,337 Epoch[7] Batch [920]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.242329,	
2017-07-17 20:21:49,988 Epoch[7] Batch [930]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.242088,	
2017-07-17 20:22:00,735 Epoch[7] Batch [940]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.241563,	
2017-07-17 20:22:11,608 Epoch[7] Batch [950]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.242757,	
2017-07-17 20:22:22,113 Epoch[7] Batch [960]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.242288,	
2017-07-17 20:22:32,866 Epoch[7] Batch [970]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.242844,	
2017-07-17 20:22:43,151 Epoch[7] Batch [980]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.242053,	
2017-07-17 20:22:53,766 Epoch[7] Batch [990]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.241681,	
2017-07-17 20:23:04,365 Epoch[7] Batch [1000]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.242086,	
2017-07-17 20:23:14,689 Epoch[7] Batch [1010]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.241832,	
2017-07-17 20:23:25,247 Epoch[7] Batch [1020]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.242703,	
2017-07-17 20:23:35,164 Epoch[7] Batch [1030]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.242981,	
2017-07-17 20:23:45,179 Epoch[7] Batch [1040]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.242357,	
2017-07-17 20:23:55,600 Epoch[7] Batch [1050]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.242935,	
2017-07-17 20:24:05,968 Epoch[7] Batch [1060]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.243032,	
2017-07-17 20:24:16,272 Epoch[7] Batch [1070]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.242518,	
2017-07-17 20:24:26,598 Epoch[7] Batch [1080]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.242081,	
2017-07-17 20:24:37,309 Epoch[7] Batch [1090]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.242083,	
2017-07-17 20:24:47,478 Epoch[7] Batch [1100]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.241372,	
2017-07-17 20:24:58,104 Epoch[7] Batch [1110]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.241385,	
2017-07-17 20:25:08,315 Epoch[7] Batch [1120]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.241044,	
2017-07-17 20:25:18,829 Epoch[7] Batch [1130]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.240225,	
2017-07-17 20:25:29,273 Epoch[7] Batch [1140]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.239973,	
2017-07-17 20:25:40,079 Epoch[7] Batch [1150]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.240173,	
2017-07-17 20:25:50,781 Epoch[7] Batch [1160]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.240400,	
2017-07-17 20:26:01,151 Epoch[7] Batch [1170]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.240272,	
2017-07-17 20:26:11,645 Epoch[7] Batch [1180]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.240869,	
2017-07-17 20:26:22,118 Epoch[7] Batch [1190]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.241442,	
2017-07-17 20:26:32,741 Epoch[7] Batch [1200]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.240958,	
2017-07-17 20:26:43,625 Epoch[7] Batch [1210]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.241582,	
2017-07-17 20:26:54,605 Epoch[7] Batch [1220]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.241796,	
2017-07-17 20:27:04,088 Epoch[7] Batch [1230]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.241660,	
2017-07-17 20:27:13,439 Epoch[7] Batch [1240]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.241541,	
2017-07-17 20:27:22,723 Epoch[7] Batch [1250]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.240794,	
2017-07-17 20:27:32,234 Epoch[7] Batch [1260]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.240417,	
2017-07-17 20:27:41,634 Epoch[7] Batch [1270]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.240564,	
2017-07-17 20:27:51,189 Epoch[7] Batch [1280]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.241009,	
2017-07-17 20:28:01,144 Epoch[7] Batch [1290]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.241051,	
2017-07-17 20:28:10,668 Epoch[7] Batch [1300]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.241078,	
2017-07-17 20:28:20,181 Epoch[7] Batch [1310]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.240896,	
2017-07-17 20:28:30,130 Epoch[7] Batch [1320]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.240816,	
2017-07-17 20:28:39,625 Epoch[7] Batch [1330]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.240618,	
2017-07-17 20:28:49,382 Epoch[7] Batch [1340]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.240629,	
2017-07-17 20:28:58,873 Epoch[7] Batch [1350]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.240985,	
2017-07-17 20:29:08,442 Epoch[7] Batch [1360]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.242407,	
2017-07-17 20:29:18,380 Epoch[7] Batch [1370]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.242190,	
2017-07-17 20:29:28,423 Epoch[7] Batch [1380]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.242748,	
2017-07-17 20:29:37,387 Epoch[7] Batch [1390]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.242600,	
2017-07-17 20:29:46,996 Epoch[7] Batch [1400]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.242438,	
2017-07-17 20:29:56,589 Epoch[7] Batch [1410]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.241733,	
2017-07-17 20:30:06,438 Epoch[7] Batch [1420]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.241298,	
2017-07-17 20:30:15,932 Epoch[7] Batch [1430]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.241703,	
2017-07-17 20:30:25,431 Epoch[7] Batch [1440]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.241727,	
2017-07-17 20:30:34,951 Epoch[7] Batch [1450]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.241854,	
2017-07-17 20:30:44,366 Epoch[7] Batch [1460]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.241470,	
2017-07-17 20:30:53,959 Epoch[7] Batch [1470]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.241638,	
2017-07-17 20:31:03,318 Epoch[7] Batch [1480]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.241369,	
2017-07-17 20:31:09,134 Epoch[7] Train-FCNLogLoss=1.241349
2017-07-17 20:31:09,134 Epoch[7] Time cost=1543.925
2017-07-17 20:31:10,554 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.params"
2017-07-17 20:31:14,150 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.states"
2017-07-17 20:31:23,738 Epoch[8] Batch [10]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.236018,	
2017-07-17 20:31:32,566 Epoch[8] Batch [20]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.229262,	
2017-07-17 20:31:41,645 Epoch[8] Batch [30]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.208754,	
2017-07-17 20:31:50,618 Epoch[8] Batch [40]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.226481,	
2017-07-17 20:31:59,245 Epoch[8] Batch [50]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.231276,	
2017-07-17 20:32:09,269 Epoch[8] Batch [60]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.237944,	
2017-07-17 20:32:19,197 Epoch[8] Batch [70]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.236526,	
2017-07-17 20:32:28,789 Epoch[8] Batch [80]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.224219,	
2017-07-17 20:32:38,737 Epoch[8] Batch [90]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.236486,	
2017-07-17 20:32:48,339 Epoch[8] Batch [100]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.242825,	
2017-07-17 20:32:57,577 Epoch[8] Batch [110]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.245299,	
2017-07-17 20:33:06,789 Epoch[8] Batch [120]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.244733,	
2017-07-17 20:33:15,784 Epoch[8] Batch [130]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.246905,	
2017-07-17 20:33:24,854 Epoch[8] Batch [140]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.247289,	
2017-07-17 20:33:34,297 Epoch[8] Batch [150]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.249356,	
2017-07-17 20:33:43,884 Epoch[8] Batch [160]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.250141,	
2017-07-17 20:33:53,230 Epoch[8] Batch [170]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.250510,	
2017-07-17 20:34:02,900 Epoch[8] Batch [180]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.248551,	
2017-07-17 20:34:12,749 Epoch[8] Batch [190]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.247430,	
2017-07-17 20:34:23,115 Epoch[8] Batch [200]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.242393,	
2017-07-17 20:34:33,499 Epoch[8] Batch [210]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.246252,	
2017-07-17 20:34:43,543 Epoch[8] Batch [220]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.247407,	
2017-07-17 20:34:53,800 Epoch[8] Batch [230]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.245289,	
2017-07-17 20:35:03,723 Epoch[8] Batch [240]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.242490,	
2017-07-17 20:35:13,752 Epoch[8] Batch [250]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.243920,	
2017-07-17 20:35:23,978 Epoch[8] Batch [260]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.246719,	
2017-07-17 20:35:34,215 Epoch[8] Batch [270]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.243218,	
2017-07-17 20:35:44,091 Epoch[8] Batch [280]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.242950,	
2017-07-17 20:35:54,083 Epoch[8] Batch [290]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.245716,	
2017-07-17 20:36:03,811 Epoch[8] Batch [300]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.245227,	
2017-07-17 20:36:13,996 Epoch[8] Batch [310]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.242944,	
2017-07-17 20:36:24,356 Epoch[8] Batch [320]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.240830,	
2017-07-17 20:36:34,048 Epoch[8] Batch [330]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.241038,	
2017-07-17 20:36:43,292 Epoch[8] Batch [340]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.244296,	
2017-07-17 20:36:52,693 Epoch[8] Batch [350]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.246649,	
2017-07-17 20:37:02,301 Epoch[8] Batch [360]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.246060,	
2017-07-17 20:37:11,585 Epoch[8] Batch [370]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.248605,	
2017-07-17 20:37:21,002 Epoch[8] Batch [380]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.246375,	
2017-07-17 20:37:29,805 Epoch[8] Batch [390]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.247535,	
2017-07-17 20:37:38,802 Epoch[8] Batch [400]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.246473,	
2017-07-17 20:37:47,974 Epoch[8] Batch [410]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.244107,	
2017-07-17 20:37:57,086 Epoch[8] Batch [420]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.245039,	
2017-07-17 20:38:06,740 Epoch[8] Batch [430]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.242742,	
2017-07-17 20:38:16,055 Epoch[8] Batch [440]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.243612,	
2017-07-17 20:38:25,325 Epoch[8] Batch [450]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.244589,	
2017-07-17 20:38:34,344 Epoch[8] Batch [460]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.245885,	
2017-07-17 20:38:43,576 Epoch[8] Batch [470]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.244910,	
2017-07-17 20:38:53,220 Epoch[8] Batch [480]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.244461,	
2017-07-17 20:39:02,562 Epoch[8] Batch [490]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.242133,	
2017-07-17 20:39:11,811 Epoch[8] Batch [500]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.241361,	
2017-07-17 20:39:21,023 Epoch[8] Batch [510]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.241996,	
2017-07-17 20:39:30,411 Epoch[8] Batch [520]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.241346,	
2017-07-17 20:39:39,852 Epoch[8] Batch [530]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.241725,	
2017-07-17 20:39:49,110 Epoch[8] Batch [540]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.240365,	
2017-07-17 20:39:58,599 Epoch[8] Batch [550]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.238561,	
2017-07-17 20:40:09,765 Epoch[8] Batch [560]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.239187,	
2017-07-17 20:40:20,463 Epoch[8] Batch [570]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.239804,	
2017-07-17 20:40:29,966 Epoch[8] Batch [580]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.240617,	
2017-07-17 20:40:39,395 Epoch[8] Batch [590]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.240589,	
2017-07-17 20:40:48,871 Epoch[8] Batch [600]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.243083,	
2017-07-17 20:40:58,552 Epoch[8] Batch [610]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.243644,	
2017-07-17 20:41:08,151 Epoch[8] Batch [620]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.242685,	
2017-07-17 20:41:17,725 Epoch[8] Batch [630]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.243016,	
2017-07-17 20:41:27,371 Epoch[8] Batch [640]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.242181,	
2017-07-17 20:41:36,680 Epoch[8] Batch [650]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.241349,	
2017-07-17 20:41:45,605 Epoch[8] Batch [660]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.241072,	
2017-07-17 20:41:55,123 Epoch[8] Batch [670]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.240493,	
2017-07-17 20:42:04,410 Epoch[8] Batch [680]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.238894,	
2017-07-17 20:42:13,353 Epoch[8] Batch [690]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.239474,	
2017-07-17 20:42:22,873 Epoch[8] Batch [700]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.240357,	
2017-07-17 20:42:32,113 Epoch[8] Batch [710]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.239183,	
2017-07-17 20:42:41,393 Epoch[8] Batch [720]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.238620,	
2017-07-17 20:42:50,807 Epoch[8] Batch [730]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.238827,	
2017-07-17 20:43:00,550 Epoch[8] Batch [740]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.239210,	
2017-07-17 20:43:10,123 Epoch[8] Batch [750]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.240249,	
2017-07-17 20:43:19,657 Epoch[8] Batch [760]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.239221,	
2017-07-17 20:43:29,212 Epoch[8] Batch [770]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.238151,	
2017-07-17 20:43:38,587 Epoch[8] Batch [780]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.238925,	
2017-07-17 20:43:47,645 Epoch[8] Batch [790]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.238555,	
2017-07-17 20:43:55,060 Epoch[8] Batch [800]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.238009,	
2017-07-17 20:44:03,025 Epoch[8] Batch [810]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.237883,	
2017-07-17 20:44:11,389 Epoch[8] Batch [820]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.238254,	
2017-07-17 20:44:21,253 Epoch[8] Batch [830]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.237605,	
2017-07-17 20:44:31,433 Epoch[8] Batch [840]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.237141,	
2017-07-17 20:44:41,219 Epoch[8] Batch [850]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.237142,	
2017-07-17 20:44:51,672 Epoch[8] Batch [860]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.236122,	
2017-07-17 20:45:02,063 Epoch[8] Batch [870]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.236462,	
2017-07-17 20:45:12,550 Epoch[8] Batch [880]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.237104,	
2017-07-17 20:45:23,051 Epoch[8] Batch [890]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.236343,	
2017-07-17 20:45:33,506 Epoch[8] Batch [900]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.236892,	
2017-07-17 20:45:44,106 Epoch[8] Batch [910]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.237047,	
2017-07-17 20:45:54,579 Epoch[8] Batch [920]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.236659,	
2017-07-17 20:46:05,111 Epoch[8] Batch [930]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.237039,	
2017-07-17 20:46:15,628 Epoch[8] Batch [940]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.237344,	
2017-07-17 20:46:25,885 Epoch[8] Batch [950]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.237248,	
2017-07-17 20:46:36,373 Epoch[8] Batch [960]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.237388,	
2017-07-17 20:46:46,757 Epoch[8] Batch [970]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.238860,	
2017-07-17 20:46:57,253 Epoch[8] Batch [980]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.238968,	
2017-07-17 20:47:07,464 Epoch[8] Batch [990]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.239961,	
2017-07-17 20:47:17,667 Epoch[8] Batch [1000]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.240772,	
2017-07-17 20:47:28,055 Epoch[8] Batch [1010]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.240667,	
2017-07-17 20:47:38,393 Epoch[8] Batch [1020]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.240026,	
2017-07-17 20:47:49,015 Epoch[8] Batch [1030]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.240830,	
2017-07-17 20:47:59,540 Epoch[8] Batch [1040]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.241658,	
2017-07-17 20:48:09,943 Epoch[8] Batch [1050]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.241317,	
2017-07-17 20:48:20,256 Epoch[8] Batch [1060]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.241098,	
2017-07-17 20:48:30,377 Epoch[8] Batch [1070]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.240592,	
2017-07-17 20:48:40,756 Epoch[8] Batch [1080]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.240980,	
2017-07-17 20:48:50,798 Epoch[8] Batch [1090]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.241148,	
2017-07-17 20:49:01,213 Epoch[8] Batch [1100]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.240740,	
2017-07-17 20:49:11,773 Epoch[8] Batch [1110]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.240925,	
2017-07-17 20:49:22,342 Epoch[8] Batch [1120]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.240570,	
2017-07-17 20:49:32,804 Epoch[8] Batch [1130]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.241598,	
2017-07-17 20:49:43,256 Epoch[8] Batch [1140]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.242466,	
2017-07-17 20:49:53,696 Epoch[8] Batch [1150]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.243312,	
2017-07-17 20:50:04,246 Epoch[8] Batch [1160]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.243278,	
2017-07-17 20:50:15,023 Epoch[8] Batch [1170]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.243028,	
2017-07-17 20:50:25,754 Epoch[8] Batch [1180]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.242651,	
2017-07-17 20:50:36,667 Epoch[8] Batch [1190]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.242346,	
2017-07-17 20:50:47,389 Epoch[8] Batch [1200]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.242438,	
2017-07-17 20:50:58,344 Epoch[8] Batch [1210]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.242266,	
2017-07-17 20:51:09,015 Epoch[8] Batch [1220]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.242472,	
2017-07-17 20:51:19,929 Epoch[8] Batch [1230]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.241621,	
2017-07-17 20:51:30,739 Epoch[8] Batch [1240]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.241691,	
2017-07-17 20:51:41,451 Epoch[8] Batch [1250]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.241114,	
2017-07-17 20:51:51,749 Epoch[8] Batch [1260]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.241290,	
2017-07-17 20:52:02,586 Epoch[8] Batch [1270]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.242244,	
2017-07-17 20:52:13,143 Epoch[8] Batch [1280]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.242630,	
2017-07-17 20:52:23,803 Epoch[8] Batch [1290]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.242936,	
2017-07-17 20:52:34,388 Epoch[8] Batch [1300]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.242088,	
2017-07-17 20:52:45,077 Epoch[8] Batch [1310]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.241641,	
2017-07-17 20:52:55,841 Epoch[8] Batch [1320]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.242186,	
2017-07-17 20:53:06,496 Epoch[8] Batch [1330]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.242193,	
2017-07-17 20:53:17,320 Epoch[8] Batch [1340]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.242635,	
2017-07-17 20:53:27,743 Epoch[8] Batch [1350]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.242475,	
2017-07-17 20:53:38,482 Epoch[8] Batch [1360]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.241744,	
2017-07-17 20:53:49,013 Epoch[8] Batch [1370]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.241531,	
2017-07-17 20:53:59,718 Epoch[8] Batch [1380]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.241074,	
2017-07-17 20:54:10,162 Epoch[8] Batch [1390]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.241060,	
2017-07-17 20:54:20,685 Epoch[8] Batch [1400]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.241692,	
2017-07-17 20:54:31,351 Epoch[8] Batch [1410]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.241772,	
2017-07-17 20:54:42,029 Epoch[8] Batch [1420]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.241723,	
2017-07-17 20:54:52,818 Epoch[8] Batch [1430]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.241098,	
2017-07-17 20:55:03,373 Epoch[8] Batch [1440]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.240881,	
2017-07-17 20:55:14,055 Epoch[8] Batch [1450]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.240760,	
2017-07-17 20:55:24,450 Epoch[8] Batch [1460]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.240741,	
2017-07-17 20:55:34,690 Epoch[8] Batch [1470]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.241587,	
2017-07-17 20:55:45,394 Epoch[8] Batch [1480]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.241616,	
2017-07-17 20:55:51,677 Epoch[8] Train-FCNLogLoss=1.241336
2017-07-17 20:55:51,678 Epoch[8] Time cost=1477.452
2017-07-17 20:55:52,791 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.params"
2017-07-17 20:55:55,662 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.states"
2017-07-17 20:56:06,128 Epoch[9] Batch [10]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.231971,	
2017-07-17 20:56:15,342 Epoch[9] Batch [20]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.288117,	
2017-07-17 20:56:24,599 Epoch[9] Batch [30]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.288455,	
2017-07-17 20:56:34,059 Epoch[9] Batch [40]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.275569,	
2017-07-17 20:56:43,146 Epoch[9] Batch [50]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.267204,	
2017-07-17 20:56:52,058 Epoch[9] Batch [60]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.259703,	
2017-07-17 20:57:00,899 Epoch[9] Batch [70]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.263006,	
2017-07-17 20:57:10,322 Epoch[9] Batch [80]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.261690,	
2017-07-17 20:57:19,466 Epoch[9] Batch [90]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.268176,	
2017-07-17 20:57:28,486 Epoch[9] Batch [100]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.261041,	
2017-07-17 20:57:37,521 Epoch[9] Batch [110]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.255377,	
2017-07-17 20:57:46,987 Epoch[9] Batch [120]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.255027,	
2017-07-17 20:57:56,151 Epoch[9] Batch [130]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.256158,	
2017-07-17 20:58:05,201 Epoch[9] Batch [140]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.256038,	
2017-07-17 20:58:14,294 Epoch[9] Batch [150]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.263578,	
2017-07-17 20:58:23,586 Epoch[9] Batch [160]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.259085,	
2017-07-17 20:58:32,517 Epoch[9] Batch [170]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.258997,	
2017-07-17 20:58:41,591 Epoch[9] Batch [180]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.254731,	
2017-07-17 20:58:50,808 Epoch[9] Batch [190]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.253560,	
2017-07-17 20:59:00,084 Epoch[9] Batch [200]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.247928,	
2017-07-17 20:59:09,293 Epoch[9] Batch [210]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.244933,	
2017-07-17 20:59:18,610 Epoch[9] Batch [220]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.248637,	
2017-07-17 20:59:27,878 Epoch[9] Batch [230]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.245365,	
2017-07-17 20:59:36,845 Epoch[9] Batch [240]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.246793,	
2017-07-17 20:59:46,050 Epoch[9] Batch [250]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.248272,	
2017-07-17 20:59:55,278 Epoch[9] Batch [260]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.249291,	
2017-07-17 21:00:04,283 Epoch[9] Batch [270]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.249534,	
2017-07-17 21:00:13,466 Epoch[9] Batch [280]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.249653,	
2017-07-17 21:00:22,430 Epoch[9] Batch [290]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.250712,	
2017-07-17 21:00:31,596 Epoch[9] Batch [300]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.248563,	
2017-07-17 21:00:42,022 Epoch[9] Batch [310]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.249794,	
2017-07-17 21:00:52,541 Epoch[9] Batch [320]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.250832,	
2017-07-17 21:01:02,985 Epoch[9] Batch [330]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.250930,	
2017-07-17 21:01:13,636 Epoch[9] Batch [340]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.251187,	
2017-07-17 21:01:24,028 Epoch[9] Batch [350]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.252432,	
2017-07-17 21:01:34,194 Epoch[9] Batch [360]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.253216,	
2017-07-17 21:01:44,792 Epoch[9] Batch [370]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.253873,	
2017-07-17 21:01:55,102 Epoch[9] Batch [380]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.254581,	
2017-07-17 21:02:05,627 Epoch[9] Batch [390]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.253108,	
2017-07-17 21:02:15,960 Epoch[9] Batch [400]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.250819,	
2017-07-17 21:02:26,682 Epoch[9] Batch [410]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.252450,	
2017-07-17 21:02:37,351 Epoch[9] Batch [420]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.253091,	
2017-07-17 21:02:47,759 Epoch[9] Batch [430]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.252369,	
2017-07-17 21:02:58,387 Epoch[9] Batch [440]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.253383,	
2017-07-17 21:03:08,938 Epoch[9] Batch [450]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.256102,	
2017-07-17 21:03:19,415 Epoch[9] Batch [460]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.256375,	
2017-07-17 21:03:29,845 Epoch[9] Batch [470]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.255293,	
2017-07-17 21:03:40,571 Epoch[9] Batch [480]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.256256,	
2017-07-17 21:03:51,012 Epoch[9] Batch [490]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.254987,	
2017-07-17 21:04:01,688 Epoch[9] Batch [500]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.256420,	
2017-07-17 21:04:11,808 Epoch[9] Batch [510]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.258290,	
2017-07-17 21:04:22,435 Epoch[9] Batch [520]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.258531,	
2017-07-17 21:04:33,106 Epoch[9] Batch [530]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.258031,	
2017-07-17 21:04:43,644 Epoch[9] Batch [540]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.257378,	
2017-07-17 21:04:53,933 Epoch[9] Batch [550]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.256608,	
2017-07-17 21:05:04,300 Epoch[9] Batch [560]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.258192,	
2017-07-17 21:05:14,450 Epoch[9] Batch [570]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.255758,	
2017-07-17 21:05:24,837 Epoch[9] Batch [580]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.256793,	
2017-07-17 21:05:35,316 Epoch[9] Batch [590]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.257374,	
2017-07-17 21:05:45,735 Epoch[9] Batch [600]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.257198,	
2017-07-17 21:05:56,183 Epoch[9] Batch [610]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.256683,	
2017-07-17 21:06:06,311 Epoch[9] Batch [620]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.255887,	
2017-07-17 21:06:16,986 Epoch[9] Batch [630]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.256041,	
2017-07-17 21:06:27,631 Epoch[9] Batch [640]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.255572,	
2017-07-17 21:06:38,197 Epoch[9] Batch [650]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.255897,	
2017-07-17 21:06:48,925 Epoch[9] Batch [660]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.254292,	
2017-07-17 21:06:59,259 Epoch[9] Batch [670]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.254292,	
2017-07-17 21:07:09,772 Epoch[9] Batch [680]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.252904,	
2017-07-17 21:07:20,441 Epoch[9] Batch [690]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.251160,	
2017-07-17 21:07:31,135 Epoch[9] Batch [700]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.251643,	
2017-07-17 21:07:41,886 Epoch[9] Batch [710]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.250936,	
2017-07-17 21:07:52,600 Epoch[9] Batch [720]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.251404,	
2017-07-17 21:08:03,343 Epoch[9] Batch [730]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.252623,	
2017-07-17 21:08:13,753 Epoch[9] Batch [740]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.252856,	
2017-07-17 21:08:24,363 Epoch[9] Batch [750]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.251842,	
2017-07-17 21:08:34,824 Epoch[9] Batch [760]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.251846,	
2017-07-17 21:08:45,234 Epoch[9] Batch [770]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.250397,	
2017-07-17 21:08:55,708 Epoch[9] Batch [780]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.249890,	
2017-07-17 21:09:06,569 Epoch[9] Batch [790]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.249255,	
2017-07-17 21:09:17,277 Epoch[9] Batch [800]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.248759,	
2017-07-17 21:09:27,685 Epoch[9] Batch [810]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.249321,	
2017-07-17 21:09:38,218 Epoch[9] Batch [820]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.248613,	
2017-07-17 21:09:48,446 Epoch[9] Batch [830]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.248023,	
2017-07-17 21:09:58,824 Epoch[9] Batch [840]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.247435,	
2017-07-17 21:10:09,545 Epoch[9] Batch [850]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.248401,	
2017-07-17 21:10:19,801 Epoch[9] Batch [860]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.248131,	
2017-07-17 21:10:29,998 Epoch[9] Batch [870]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.247723,	
2017-07-17 21:10:40,401 Epoch[9] Batch [880]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.247963,	
2017-07-17 21:10:50,533 Epoch[9] Batch [890]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.248349,	
2017-07-17 21:11:01,135 Epoch[9] Batch [900]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.247923,	
2017-07-17 21:11:11,131 Epoch[9] Batch [910]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.247375,	
2017-07-17 21:11:21,828 Epoch[9] Batch [920]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.247548,	
2017-07-17 21:11:32,371 Epoch[9] Batch [930]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.246336,	
2017-07-17 21:11:42,581 Epoch[9] Batch [940]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.246629,	
2017-07-17 21:11:52,993 Epoch[9] Batch [950]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.245952,	
2017-07-17 21:12:03,332 Epoch[9] Batch [960]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.245485,	
2017-07-17 21:12:13,681 Epoch[9] Batch [970]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.245936,	
2017-07-17 21:12:24,031 Epoch[9] Batch [980]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.247307,	
2017-07-17 21:12:34,355 Epoch[9] Batch [990]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.247313,	
2017-07-17 21:12:44,962 Epoch[9] Batch [1000]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.247367,	
2017-07-17 21:12:55,477 Epoch[9] Batch [1010]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.247165,	
2017-07-17 21:13:05,938 Epoch[9] Batch [1020]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.246732,	
2017-07-17 21:13:16,336 Epoch[9] Batch [1030]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.247456,	
2017-07-17 21:13:27,028 Epoch[9] Batch [1040]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.246630,	
2017-07-17 21:13:37,500 Epoch[9] Batch [1050]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.246389,	
2017-07-17 21:13:48,176 Epoch[9] Batch [1060]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.246228,	
2017-07-17 21:13:58,745 Epoch[9] Batch [1070]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.246532,	
2017-07-17 21:14:09,370 Epoch[9] Batch [1080]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.246739,	
2017-07-17 21:14:19,986 Epoch[9] Batch [1090]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.246756,	
2017-07-17 21:14:30,458 Epoch[9] Batch [1100]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.246604,	
2017-07-17 21:14:40,744 Epoch[9] Batch [1110]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.247101,	
2017-07-17 21:14:50,967 Epoch[9] Batch [1120]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.246801,	
2017-07-17 21:15:01,581 Epoch[9] Batch [1130]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.246832,	
2017-07-17 21:15:11,768 Epoch[9] Batch [1140]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.246225,	
2017-07-17 21:15:22,394 Epoch[9] Batch [1150]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.245582,	
2017-07-17 21:15:33,083 Epoch[9] Batch [1160]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.245776,	
2017-07-17 21:15:44,020 Epoch[9] Batch [1170]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.245333,	
2017-07-17 21:15:54,602 Epoch[9] Batch [1180]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.244717,	
2017-07-17 21:16:05,326 Epoch[9] Batch [1190]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.244491,	
2017-07-17 21:16:15,810 Epoch[9] Batch [1200]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.244319,	
2017-07-17 21:16:26,628 Epoch[9] Batch [1210]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.244611,	
2017-07-17 21:16:37,147 Epoch[9] Batch [1220]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.245151,	
2017-07-17 21:16:47,309 Epoch[9] Batch [1230]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.245267,	
2017-07-17 21:16:57,618 Epoch[9] Batch [1240]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.245321,	
2017-07-17 21:17:07,952 Epoch[9] Batch [1250]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.245607,	
2017-07-17 21:17:18,248 Epoch[9] Batch [1260]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.246087,	
2017-07-17 21:17:28,778 Epoch[9] Batch [1270]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.246206,	
2017-07-17 21:17:38,953 Epoch[9] Batch [1280]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.246173,	
2017-07-17 21:17:49,425 Epoch[9] Batch [1290]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.246058,	
2017-07-17 21:17:59,693 Epoch[9] Batch [1300]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.245902,	
2017-07-17 21:18:10,136 Epoch[9] Batch [1310]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.245687,	
2017-07-17 21:18:20,585 Epoch[9] Batch [1320]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.245748,	
2017-07-17 21:18:31,505 Epoch[9] Batch [1330]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.245661,	
2017-07-17 21:18:42,040 Epoch[9] Batch [1340]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.245602,	
2017-07-17 21:18:52,508 Epoch[9] Batch [1350]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.245981,	
2017-07-17 21:19:03,061 Epoch[9] Batch [1360]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.245504,	
2017-07-17 21:19:13,615 Epoch[9] Batch [1370]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.245256,	
2017-07-17 21:19:24,736 Epoch[9] Batch [1380]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.245274,	
2017-07-17 21:19:35,248 Epoch[9] Batch [1390]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.245262,	
2017-07-17 21:19:45,820 Epoch[9] Batch [1400]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.245581,	
2017-07-17 21:19:56,481 Epoch[9] Batch [1410]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.245018,	
2017-07-17 21:20:06,704 Epoch[9] Batch [1420]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.245140,	
2017-07-17 21:20:17,073 Epoch[9] Batch [1430]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.244452,	
2017-07-17 21:20:27,371 Epoch[9] Batch [1440]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.244109,	
2017-07-17 21:20:37,714 Epoch[9] Batch [1450]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.243775,	
2017-07-17 21:20:47,714 Epoch[9] Batch [1460]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.243716,	
2017-07-17 21:20:58,093 Epoch[9] Batch [1470]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.244097,	
2017-07-17 21:21:08,589 Epoch[9] Batch [1480]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.244017,	
2017-07-17 21:21:14,686 Epoch[9] Train-FCNLogLoss=1.243591
2017-07-17 21:21:14,686 Epoch[9] Time cost=1519.024
2017-07-17 21:21:16,143 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.params"
2017-07-17 21:21:18,942 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.states"
2017-07-17 21:21:30,877 Epoch[10] Batch [10]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.287546,	
2017-07-17 21:21:41,772 Epoch[10] Batch [20]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.304129,	
2017-07-17 21:21:52,760 Epoch[10] Batch [30]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.275333,	
2017-07-17 21:22:03,310 Epoch[10] Batch [40]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.281652,	
2017-07-17 21:22:13,724 Epoch[10] Batch [50]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.271870,	
2017-07-17 21:22:24,396 Epoch[10] Batch [60]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.276025,	
2017-07-17 21:22:34,613 Epoch[10] Batch [70]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.257804,	
2017-07-17 21:22:45,231 Epoch[10] Batch [80]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.256674,	
2017-07-17 21:22:55,715 Epoch[10] Batch [90]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.247773,	
2017-07-17 21:23:06,415 Epoch[10] Batch [100]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.259518,	
2017-07-17 21:23:17,260 Epoch[10] Batch [110]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.255022,	
2017-07-17 21:23:27,689 Epoch[10] Batch [120]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.256398,	
2017-07-17 21:23:38,161 Epoch[10] Batch [130]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.254726,	
2017-07-17 21:23:48,720 Epoch[10] Batch [140]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.262613,	
2017-07-17 21:23:59,507 Epoch[10] Batch [150]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.260589,	
2017-07-17 21:24:09,824 Epoch[10] Batch [160]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.262836,	
2017-07-17 21:24:20,320 Epoch[10] Batch [170]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.263818,	
2017-07-17 21:24:30,827 Epoch[10] Batch [180]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.265691,	
2017-07-17 21:24:41,517 Epoch[10] Batch [190]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.260698,	
2017-07-17 21:24:52,123 Epoch[10] Batch [200]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.258706,	
2017-07-17 21:25:02,915 Epoch[10] Batch [210]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.260057,	
2017-07-17 21:25:13,557 Epoch[10] Batch [220]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.255446,	
2017-07-17 21:25:23,710 Epoch[10] Batch [230]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.257505,	
2017-07-17 21:25:34,464 Epoch[10] Batch [240]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.256869,	
2017-07-17 21:25:44,101 Epoch[10] Batch [250]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.257593,	
2017-07-17 21:25:53,044 Epoch[10] Batch [260]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.257070,	
2017-07-17 21:26:02,461 Epoch[10] Batch [270]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.255033,	
2017-07-17 21:26:12,152 Epoch[10] Batch [280]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.257930,	
2017-07-17 21:26:21,563 Epoch[10] Batch [290]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.262683,	
2017-07-17 21:26:31,424 Epoch[10] Batch [300]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.262796,	
2017-07-17 21:26:41,380 Epoch[10] Batch [310]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.258637,	
2017-07-17 21:26:50,538 Epoch[10] Batch [320]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.256749,	
2017-07-17 21:26:58,867 Epoch[10] Batch [330]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.255041,	
2017-07-17 21:27:07,586 Epoch[10] Batch [340]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.255435,	
2017-07-17 21:27:17,107 Epoch[10] Batch [350]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.254022,	
2017-07-17 21:27:26,235 Epoch[10] Batch [360]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.253944,	
2017-07-17 21:27:35,361 Epoch[10] Batch [370]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.254564,	
2017-07-17 21:27:44,125 Epoch[10] Batch [380]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.252232,	
2017-07-17 21:27:53,312 Epoch[10] Batch [390]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.252801,	
2017-07-17 21:28:02,545 Epoch[10] Batch [400]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.251076,	
2017-07-17 21:28:11,665 Epoch[10] Batch [410]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.249164,	
2017-07-17 21:28:21,223 Epoch[10] Batch [420]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.251497,	
2017-07-17 21:28:30,219 Epoch[10] Batch [430]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.250474,	
2017-07-17 21:28:39,309 Epoch[10] Batch [440]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.250102,	
2017-07-17 21:28:48,862 Epoch[10] Batch [450]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.249452,	
2017-07-17 21:28:58,128 Epoch[10] Batch [460]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.247232,	
2017-07-17 21:29:07,772 Epoch[10] Batch [470]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.246541,	
2017-07-17 21:29:16,900 Epoch[10] Batch [480]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.247124,	
2017-07-17 21:29:25,892 Epoch[10] Batch [490]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.245563,	
2017-07-17 21:29:35,230 Epoch[10] Batch [500]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.248254,	
2017-07-17 21:29:44,455 Epoch[10] Batch [510]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.247947,	
2017-07-17 21:29:53,667 Epoch[10] Batch [520]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.247813,	
2017-07-17 21:30:02,664 Epoch[10] Batch [530]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.247787,	
2017-07-17 21:30:11,951 Epoch[10] Batch [540]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.247936,	
2017-07-17 21:30:21,422 Epoch[10] Batch [550]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.248366,	
2017-07-17 21:30:31,038 Epoch[10] Batch [560]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.249858,	
2017-07-17 21:30:40,658 Epoch[10] Batch [570]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.249532,	
2017-07-17 21:30:49,634 Epoch[10] Batch [580]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.249312,	
2017-07-17 21:30:59,157 Epoch[10] Batch [590]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.251464,	
2017-07-17 21:31:08,482 Epoch[10] Batch [600]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.252447,	
2017-07-17 21:31:17,984 Epoch[10] Batch [610]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.252825,	
2017-07-17 21:31:27,329 Epoch[10] Batch [620]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.254144,	
2017-07-17 21:31:36,686 Epoch[10] Batch [630]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.254200,	
2017-07-17 21:31:46,187 Epoch[10] Batch [640]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.254398,	
2017-07-17 21:31:55,030 Epoch[10] Batch [650]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.253129,	
2017-07-17 21:32:04,544 Epoch[10] Batch [660]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.255348,	
2017-07-17 21:32:13,947 Epoch[10] Batch [670]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.256793,	
2017-07-17 21:32:23,396 Epoch[10] Batch [680]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.256829,	
2017-07-17 21:32:32,739 Epoch[10] Batch [690]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.254296,	
2017-07-17 21:32:42,022 Epoch[10] Batch [700]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.255350,	
2017-07-17 21:32:51,464 Epoch[10] Batch [710]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.255806,	
2017-07-17 21:33:00,854 Epoch[10] Batch [720]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.256744,	
2017-07-17 21:33:10,308 Epoch[10] Batch [730]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.256168,	
2017-07-17 21:33:19,775 Epoch[10] Batch [740]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.257522,	
2017-07-17 21:33:29,263 Epoch[10] Batch [750]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.257329,	
2017-07-17 21:33:38,719 Epoch[10] Batch [760]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.256183,	
2017-07-17 21:33:47,969 Epoch[10] Batch [770]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.257172,	
2017-07-17 21:33:57,179 Epoch[10] Batch [780]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.256903,	
2017-07-17 21:34:06,539 Epoch[10] Batch [790]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.255318,	
2017-07-17 21:34:16,220 Epoch[10] Batch [800]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.254601,	
2017-07-17 21:34:25,631 Epoch[10] Batch [810]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.254432,	
2017-07-17 21:34:35,124 Epoch[10] Batch [820]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.254501,	
2017-07-17 21:34:43,964 Epoch[10] Batch [830]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.254584,	
2017-07-17 21:34:53,250 Epoch[10] Batch [840]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.255214,	
2017-07-17 21:35:02,442 Epoch[10] Batch [850]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.255746,	
2017-07-17 21:35:11,942 Epoch[10] Batch [860]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.256059,	
2017-07-17 21:35:21,221 Epoch[10] Batch [870]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.256357,	
2017-07-17 21:35:30,339 Epoch[10] Batch [880]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.255780,	
2017-07-17 21:35:40,006 Epoch[10] Batch [890]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.255236,	
2017-07-17 21:35:49,516 Epoch[10] Batch [900]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.255066,	
2017-07-17 21:35:58,687 Epoch[10] Batch [910]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.255151,	
2017-07-17 21:36:07,835 Epoch[10] Batch [920]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.255126,	
2017-07-17 21:36:17,478 Epoch[10] Batch [930]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.253907,	
2017-07-17 21:36:26,931 Epoch[10] Batch [940]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.253169,	
2017-07-17 21:36:36,341 Epoch[10] Batch [950]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.253482,	
2017-07-17 21:36:45,880 Epoch[10] Batch [960]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.253052,	
2017-07-17 21:36:55,270 Epoch[10] Batch [970]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.253147,	
2017-07-17 21:37:05,046 Epoch[10] Batch [980]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.252472,	
2017-07-17 21:37:14,579 Epoch[10] Batch [990]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.252216,	
2017-07-17 21:37:24,111 Epoch[10] Batch [1000]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.251721,	
2017-07-17 21:37:33,505 Epoch[10] Batch [1010]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.251298,	
2017-07-17 21:37:42,908 Epoch[10] Batch [1020]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.252669,	
2017-07-17 21:37:52,323 Epoch[10] Batch [1030]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.251933,	
2017-07-17 21:38:01,619 Epoch[10] Batch [1040]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.251913,	
2017-07-17 21:38:11,022 Epoch[10] Batch [1050]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.251046,	
2017-07-17 21:38:20,411 Epoch[10] Batch [1060]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.250984,	
2017-07-17 21:38:29,724 Epoch[10] Batch [1070]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.251524,	
2017-07-17 21:38:38,969 Epoch[10] Batch [1080]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.251597,	
2017-07-17 21:38:48,577 Epoch[10] Batch [1090]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.252116,	
2017-07-17 21:38:57,711 Epoch[10] Batch [1100]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.252080,	
2017-07-17 21:39:07,057 Epoch[10] Batch [1110]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.251870,	
2017-07-17 21:39:16,414 Epoch[10] Batch [1120]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.251634,	
2017-07-17 21:39:25,651 Epoch[10] Batch [1130]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.250652,	
2017-07-17 21:39:35,136 Epoch[10] Batch [1140]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.251033,	
2017-07-17 21:39:44,366 Epoch[10] Batch [1150]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.252119,	
2017-07-17 21:39:53,754 Epoch[10] Batch [1160]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.251820,	
2017-07-17 21:40:03,242 Epoch[10] Batch [1170]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.252901,	
2017-07-17 21:40:12,875 Epoch[10] Batch [1180]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.253370,	
2017-07-17 21:40:22,093 Epoch[10] Batch [1190]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.253070,	
2017-07-17 21:40:31,278 Epoch[10] Batch [1200]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.252385,	
2017-07-17 21:40:40,656 Epoch[10] Batch [1210]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.251613,	
2017-07-17 21:40:49,993 Epoch[10] Batch [1220]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.251814,	
2017-07-17 21:40:59,411 Epoch[10] Batch [1230]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.252169,	
2017-07-17 21:41:08,681 Epoch[10] Batch [1240]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.251846,	
2017-07-17 21:41:18,204 Epoch[10] Batch [1250]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.251445,	
2017-07-17 21:41:27,253 Epoch[10] Batch [1260]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.251052,	
2017-07-17 21:41:36,538 Epoch[10] Batch [1270]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.250833,	
2017-07-17 21:41:45,812 Epoch[10] Batch [1280]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.251133,	
2017-07-17 21:41:55,166 Epoch[10] Batch [1290]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.251082,	
2017-07-17 21:42:04,454 Epoch[10] Batch [1300]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.252221,	
2017-07-17 21:42:14,027 Epoch[10] Batch [1310]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.251183,	
2017-07-17 21:42:23,459 Epoch[10] Batch [1320]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.250828,	
2017-07-17 21:42:32,598 Epoch[10] Batch [1330]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.250905,	
2017-07-17 21:42:42,014 Epoch[10] Batch [1340]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.250407,	
2017-07-17 21:42:51,315 Epoch[10] Batch [1350]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.250381,	
2017-07-17 21:43:00,793 Epoch[10] Batch [1360]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.251406,	
2017-07-17 21:43:09,796 Epoch[10] Batch [1370]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.250950,	
2017-07-17 21:43:19,255 Epoch[10] Batch [1380]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.251221,	
2017-07-17 21:43:28,815 Epoch[10] Batch [1390]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.251288,	
2017-07-17 21:43:37,905 Epoch[10] Batch [1400]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.250370,	
2017-07-17 21:43:46,971 Epoch[10] Batch [1410]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.250697,	
2017-07-17 21:43:56,217 Epoch[10] Batch [1420]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.250436,	
2017-07-17 21:44:05,155 Epoch[10] Batch [1430]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.250266,	
2017-07-17 21:44:14,276 Epoch[10] Batch [1440]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.250182,	
2017-07-17 21:44:22,757 Epoch[10] Batch [1450]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.249921,	
2017-07-17 21:44:31,935 Epoch[10] Batch [1460]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.249436,	
2017-07-17 21:44:40,982 Epoch[10] Batch [1470]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.250465,	
2017-07-17 21:44:50,401 Epoch[10] Batch [1480]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.249809,	
2017-07-17 21:44:56,049 Epoch[10] Train-FCNLogLoss=1.249884
2017-07-17 21:44:56,049 Epoch[10] Time cost=1417.106
2017-07-17 21:44:57,318 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.params"
2017-07-17 21:45:00,576 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.states"
2017-07-17 21:45:11,657 Epoch[11] Batch [10]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.306230,	
2017-07-17 21:45:20,941 Epoch[11] Batch [20]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.256281,	
2017-07-17 21:45:30,198 Epoch[11] Batch [30]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.247763,	
2017-07-17 21:45:39,710 Epoch[11] Batch [40]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.226832,	
2017-07-17 21:45:49,332 Epoch[11] Batch [50]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.254039,	
2017-07-17 21:45:58,801 Epoch[11] Batch [60]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.258294,	
2017-07-17 21:46:08,050 Epoch[11] Batch [70]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.253042,	
2017-07-17 21:46:17,250 Epoch[11] Batch [80]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.256901,	
2017-07-17 21:46:26,063 Epoch[11] Batch [90]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.252611,	
2017-07-17 21:46:35,591 Epoch[11] Batch [100]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.243988,	
2017-07-17 21:46:44,928 Epoch[11] Batch [110]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.242110,	
2017-07-17 21:46:54,060 Epoch[11] Batch [120]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.236191,	
2017-07-17 21:47:03,283 Epoch[11] Batch [130]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.241501,	
2017-07-17 21:47:12,467 Epoch[11] Batch [140]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.233121,	
2017-07-17 21:47:21,801 Epoch[11] Batch [150]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237292,	
2017-07-17 21:47:31,272 Epoch[11] Batch [160]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.233884,	
2017-07-17 21:47:40,534 Epoch[11] Batch [170]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.233033,	
2017-07-17 21:47:49,669 Epoch[11] Batch [180]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.227679,	
2017-07-17 21:47:58,818 Epoch[11] Batch [190]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.236565,	
2017-07-17 21:48:07,676 Epoch[11] Batch [200]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.238426,	
2017-07-17 21:48:17,126 Epoch[11] Batch [210]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.241408,	
2017-07-17 21:48:26,568 Epoch[11] Batch [220]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.241189,	
2017-07-17 21:48:36,026 Epoch[11] Batch [230]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.239975,	
2017-07-17 21:48:45,293 Epoch[11] Batch [240]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.241121,	
2017-07-17 21:48:54,670 Epoch[11] Batch [250]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.242559,	
2017-07-17 21:49:04,234 Epoch[11] Batch [260]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.246940,	
2017-07-17 21:49:13,707 Epoch[11] Batch [270]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.249363,	
2017-07-17 21:49:22,998 Epoch[11] Batch [280]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.246306,	
2017-07-17 21:49:32,703 Epoch[11] Batch [290]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.243843,	
2017-07-17 21:49:41,949 Epoch[11] Batch [300]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.244619,	
2017-07-17 21:49:51,239 Epoch[11] Batch [310]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.244891,	
2017-07-17 21:50:00,305 Epoch[11] Batch [320]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.242263,	
2017-07-17 21:50:09,878 Epoch[11] Batch [330]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.239506,	
2017-07-17 21:50:19,375 Epoch[11] Batch [340]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.237992,	
2017-07-17 21:50:29,001 Epoch[11] Batch [350]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.235907,	
2017-07-17 21:50:38,447 Epoch[11] Batch [360]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.237201,	
2017-07-17 21:50:47,406 Epoch[11] Batch [370]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.236946,	
2017-07-17 21:50:56,617 Epoch[11] Batch [380]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.239572,	
2017-07-17 21:51:05,822 Epoch[11] Batch [390]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.238343,	
2017-07-17 21:51:15,172 Epoch[11] Batch [400]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.237080,	
2017-07-17 21:51:24,652 Epoch[11] Batch [410]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.236267,	
2017-07-17 21:51:34,089 Epoch[11] Batch [420]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.235892,	
2017-07-17 21:51:43,590 Epoch[11] Batch [430]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.235207,	
2017-07-17 21:51:52,871 Epoch[11] Batch [440]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.237641,	
2017-07-17 21:52:02,269 Epoch[11] Batch [450]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.240470,	
2017-07-17 21:52:10,900 Epoch[11] Batch [460]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.243164,	
2017-07-17 21:52:20,161 Epoch[11] Batch [470]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.242467,	
2017-07-17 21:52:29,416 Epoch[11] Batch [480]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.244548,	
2017-07-17 21:52:39,176 Epoch[11] Batch [490]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.245366,	
2017-07-17 21:52:48,437 Epoch[11] Batch [500]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.244287,	
2017-07-17 21:52:57,512 Epoch[11] Batch [510]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.242988,	
2017-07-17 21:53:06,690 Epoch[11] Batch [520]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.241644,	
2017-07-17 21:53:15,729 Epoch[11] Batch [530]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242754,	
2017-07-17 21:53:25,117 Epoch[11] Batch [540]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.243544,	
2017-07-17 21:53:34,585 Epoch[11] Batch [550]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.243830,	
2017-07-17 21:53:43,950 Epoch[11] Batch [560]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.244243,	
2017-07-17 21:53:53,442 Epoch[11] Batch [570]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.244675,	
2017-07-17 21:54:03,193 Epoch[11] Batch [580]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.244265,	
2017-07-17 21:54:12,456 Epoch[11] Batch [590]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.243933,	
2017-07-17 21:54:21,931 Epoch[11] Batch [600]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.242266,	
2017-07-17 21:54:31,147 Epoch[11] Batch [610]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.243303,	
2017-07-17 21:54:39,647 Epoch[11] Batch [620]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.243277,	
2017-07-17 21:54:48,581 Epoch[11] Batch [630]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.242834,	
2017-07-17 21:54:58,010 Epoch[11] Batch [640]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.241722,	
2017-07-17 21:55:07,589 Epoch[11] Batch [650]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.242148,	
2017-07-17 21:55:16,860 Epoch[11] Batch [660]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.242863,	
2017-07-17 21:55:26,414 Epoch[11] Batch [670]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.242171,	
2017-07-17 21:55:35,841 Epoch[11] Batch [680]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.242818,	
2017-07-17 21:55:45,136 Epoch[11] Batch [690]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.242564,	
2017-07-17 21:55:54,736 Epoch[11] Batch [700]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.242053,	
2017-07-17 21:56:04,256 Epoch[11] Batch [710]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.242536,	
2017-07-17 21:56:13,704 Epoch[11] Batch [720]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.243795,	
2017-07-17 21:56:23,180 Epoch[11] Batch [730]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.244002,	
2017-07-17 21:56:31,893 Epoch[11] Batch [740]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.244436,	
2017-07-17 21:56:41,003 Epoch[11] Batch [750]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.243944,	
2017-07-17 21:56:50,259 Epoch[11] Batch [760]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.243246,	
2017-07-17 21:56:59,676 Epoch[11] Batch [770]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.243773,	
2017-07-17 21:57:09,006 Epoch[11] Batch [780]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.243955,	
2017-07-17 21:57:18,486 Epoch[11] Batch [790]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.242688,	
2017-07-17 21:57:27,944 Epoch[11] Batch [800]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.242829,	
2017-07-17 21:57:37,144 Epoch[11] Batch [810]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.242127,	
2017-07-17 21:57:46,348 Epoch[11] Batch [820]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.242006,	
2017-07-17 21:57:55,730 Epoch[11] Batch [830]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.242541,	
2017-07-17 21:58:04,763 Epoch[11] Batch [840]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242379,	
2017-07-17 21:58:12,850 Epoch[11] Batch [850]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.241465,	
2017-07-17 21:58:20,627 Epoch[11] Batch [860]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.241547,	
2017-07-17 21:58:28,587 Epoch[11] Batch [870]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.240669,	
2017-07-17 21:58:36,711 Epoch[11] Batch [880]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.240775,	
2017-07-17 21:58:44,659 Epoch[11] Batch [890]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.241026,	
2017-07-17 21:58:52,713 Epoch[11] Batch [900]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.240956,	
2017-07-17 21:59:00,918 Epoch[11] Batch [910]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.240531,	
2017-07-17 21:59:09,213 Epoch[11] Batch [920]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.240879,	
2017-07-17 21:59:17,517 Epoch[11] Batch [930]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.240679,	
2017-07-17 21:59:26,286 Epoch[11] Batch [940]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.241233,	
2017-07-17 21:59:35,074 Epoch[11] Batch [950]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241227,	
2017-07-17 21:59:43,532 Epoch[11] Batch [960]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.241507,	
2017-07-17 21:59:52,394 Epoch[11] Batch [970]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.241575,	
2017-07-17 22:00:01,367 Epoch[11] Batch [980]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.241527,	
2017-07-17 22:00:10,193 Epoch[11] Batch [990]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.241711,	
2017-07-17 22:00:18,305 Epoch[11] Batch [1000]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.242692,	
2017-07-17 22:00:26,438 Epoch[11] Batch [1010]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.242381,	
2017-07-17 22:00:34,591 Epoch[11] Batch [1020]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.242995,	
2017-07-17 22:00:42,949 Epoch[11] Batch [1030]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.242770,	
2017-07-17 22:00:50,870 Epoch[11] Batch [1040]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.242030,	
2017-07-17 22:00:58,901 Epoch[11] Batch [1050]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.242399,	
2017-07-17 22:01:06,905 Epoch[11] Batch [1060]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.243171,	
2017-07-17 22:01:15,440 Epoch[11] Batch [1070]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.243464,	
2017-07-17 22:01:23,539 Epoch[11] Batch [1080]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.243110,	
2017-07-17 22:01:32,075 Epoch[11] Batch [1090]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.243550,	
2017-07-17 22:01:40,072 Epoch[11] Batch [1100]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.244555,	
2017-07-17 22:01:48,674 Epoch[11] Batch [1110]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.245141,	
2017-07-17 22:01:56,975 Epoch[11] Batch [1120]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.244653,	
2017-07-17 22:02:05,050 Epoch[11] Batch [1130]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.244699,	
2017-07-17 22:02:13,463 Epoch[11] Batch [1140]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.245571,	
2017-07-17 22:02:21,586 Epoch[11] Batch [1150]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.245919,	
2017-07-17 22:02:29,699 Epoch[11] Batch [1160]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.245859,	
2017-07-17 22:02:38,432 Epoch[11] Batch [1170]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.245362,	
2017-07-17 22:02:46,983 Epoch[11] Batch [1180]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.245291,	
2017-07-17 22:02:55,416 Epoch[11] Batch [1190]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.245857,	
2017-07-17 22:03:03,296 Epoch[11] Batch [1200]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.245532,	
2017-07-17 22:03:11,557 Epoch[11] Batch [1210]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.246365,	
2017-07-17 22:03:19,732 Epoch[11] Batch [1220]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.246059,	
2017-07-17 22:03:28,105 Epoch[11] Batch [1230]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.247239,	
2017-07-17 22:03:36,582 Epoch[11] Batch [1240]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.247286,	
2017-07-17 22:03:44,751 Epoch[11] Batch [1250]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.247575,	
2017-07-17 22:03:52,982 Epoch[11] Batch [1260]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.248468,	
2017-07-17 22:04:01,304 Epoch[11] Batch [1270]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.248569,	
2017-07-17 22:04:09,721 Epoch[11] Batch [1280]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.248371,	
2017-07-17 22:04:17,980 Epoch[11] Batch [1290]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.248690,	
2017-07-17 22:04:25,964 Epoch[11] Batch [1300]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.248639,	
2017-07-17 22:04:34,326 Epoch[11] Batch [1310]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.248482,	
2017-07-17 22:04:42,746 Epoch[11] Batch [1320]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.247931,	
2017-07-17 22:04:50,912 Epoch[11] Batch [1330]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.247546,	
2017-07-17 22:04:59,116 Epoch[11] Batch [1340]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.247076,	
2017-07-17 22:05:07,236 Epoch[11] Batch [1350]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.246184,	
2017-07-17 22:05:15,663 Epoch[11] Batch [1360]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.246604,	
2017-07-17 22:05:23,906 Epoch[11] Batch [1370]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.246494,	
2017-07-17 22:05:32,147 Epoch[11] Batch [1380]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.246339,	
2017-07-17 22:05:40,519 Epoch[11] Batch [1390]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.246012,	
2017-07-17 22:05:48,433 Epoch[11] Batch [1400]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.246424,	
2017-07-17 22:05:56,959 Epoch[11] Batch [1410]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.246158,	
2017-07-17 22:06:05,587 Epoch[11] Batch [1420]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.245801,	
2017-07-17 22:06:13,848 Epoch[11] Batch [1430]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.245370,	
2017-07-17 22:06:22,314 Epoch[11] Batch [1440]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.245626,	
2017-07-17 22:06:30,793 Epoch[11] Batch [1450]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.245477,	
2017-07-17 22:06:38,881 Epoch[11] Batch [1460]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.245784,	
2017-07-17 22:06:47,309 Epoch[11] Batch [1470]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.245547,	
2017-07-17 22:06:55,475 Epoch[11] Batch [1480]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.245235,	
2017-07-17 22:07:00,225 Epoch[11] Train-FCNLogLoss=1.245436
2017-07-17 22:07:00,225 Epoch[11] Time cost=1319.322
2017-07-17 22:07:01,301 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.params"
2017-07-17 22:07:05,277 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.states"
2017-07-17 22:07:14,615 Epoch[12] Batch [10]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.229856,	
2017-07-17 22:07:22,963 Epoch[12] Batch [20]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.258856,	
2017-07-17 22:07:31,329 Epoch[12] Batch [30]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.252490,	
2017-07-17 22:07:39,665 Epoch[12] Batch [40]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.234654,	
2017-07-17 22:07:47,989 Epoch[12] Batch [50]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.266021,	
2017-07-17 22:07:56,003 Epoch[12] Batch [60]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.263060,	
2017-07-17 22:08:04,430 Epoch[12] Batch [70]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.276195,	
2017-07-17 22:08:12,687 Epoch[12] Batch [80]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.269607,	
2017-07-17 22:08:21,002 Epoch[12] Batch [90]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.258035,	
2017-07-17 22:08:29,489 Epoch[12] Batch [100]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.255275,	
2017-07-17 22:08:37,568 Epoch[12] Batch [110]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.249894,	
2017-07-17 22:08:45,926 Epoch[12] Batch [120]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.247308,	
2017-07-17 22:08:54,144 Epoch[12] Batch [130]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.247017,	
2017-07-17 22:09:02,141 Epoch[12] Batch [140]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.252273,	
2017-07-17 22:09:10,692 Epoch[12] Batch [150]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.252750,	
2017-07-17 22:09:19,241 Epoch[12] Batch [160]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.252469,	
2017-07-17 22:09:27,473 Epoch[12] Batch [170]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.256560,	
2017-07-17 22:09:35,297 Epoch[12] Batch [180]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.255321,	
2017-07-17 22:09:43,330 Epoch[12] Batch [190]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.257419,	
2017-07-17 22:09:51,384 Epoch[12] Batch [200]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.253489,	
2017-07-17 22:09:59,503 Epoch[12] Batch [210]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.247539,	
2017-07-17 22:10:08,273 Epoch[12] Batch [220]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.250291,	
2017-07-17 22:10:16,955 Epoch[12] Batch [230]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.248349,	
2017-07-17 22:10:24,930 Epoch[12] Batch [240]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.250467,	
2017-07-17 22:10:33,054 Epoch[12] Batch [250]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.250029,	
2017-07-17 22:10:41,888 Epoch[12] Batch [260]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.247536,	
2017-07-17 22:10:50,242 Epoch[12] Batch [270]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.253415,	
2017-07-17 22:10:58,044 Epoch[12] Batch [280]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.255161,	
2017-07-17 22:11:06,227 Epoch[12] Batch [290]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.255391,	
2017-07-17 22:11:14,541 Epoch[12] Batch [300]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.254385,	
2017-07-17 22:11:22,860 Epoch[12] Batch [310]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.257113,	
2017-07-17 22:11:31,101 Epoch[12] Batch [320]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.258555,	
2017-07-17 22:11:39,402 Epoch[12] Batch [330]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.259037,	
2017-07-17 22:11:47,671 Epoch[12] Batch [340]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.261192,	
2017-07-17 22:11:56,187 Epoch[12] Batch [350]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.257821,	
2017-07-17 22:12:04,566 Epoch[12] Batch [360]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.256716,	
2017-07-17 22:12:13,122 Epoch[12] Batch [370]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.256765,	
2017-07-17 22:12:21,668 Epoch[12] Batch [380]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.257087,	
2017-07-17 22:12:30,103 Epoch[12] Batch [390]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.259169,	
2017-07-17 22:12:38,356 Epoch[12] Batch [400]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.256485,	
2017-07-17 22:12:46,436 Epoch[12] Batch [410]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.254350,	
2017-07-17 22:12:54,178 Epoch[12] Batch [420]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.258387,	
2017-07-17 22:13:02,319 Epoch[12] Batch [430]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.258793,	
2017-07-17 22:13:10,659 Epoch[12] Batch [440]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.259129,	
2017-07-17 22:13:19,302 Epoch[12] Batch [450]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.257118,	
2017-07-17 22:13:27,743 Epoch[12] Batch [460]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.258634,	
2017-07-17 22:13:35,942 Epoch[12] Batch [470]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.259806,	
2017-07-17 22:13:44,215 Epoch[12] Batch [480]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.259396,	
2017-07-17 22:13:52,815 Epoch[12] Batch [490]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.261244,	
2017-07-17 22:14:01,636 Epoch[12] Batch [500]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.259603,	
2017-07-17 22:14:10,213 Epoch[12] Batch [510]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.259948,	
2017-07-17 22:14:18,625 Epoch[12] Batch [520]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.260989,	
2017-07-17 22:14:26,923 Epoch[12] Batch [530]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.260165,	
2017-07-17 22:14:34,976 Epoch[12] Batch [540]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.259963,	
2017-07-17 22:14:43,382 Epoch[12] Batch [550]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.258506,	
2017-07-17 22:14:51,514 Epoch[12] Batch [560]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.257494,	
2017-07-17 22:14:59,805 Epoch[12] Batch [570]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.255328,	
2017-07-17 22:15:08,145 Epoch[12] Batch [580]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.254793,	
2017-07-17 22:15:16,745 Epoch[12] Batch [590]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.254525,	
2017-07-17 22:15:24,794 Epoch[12] Batch [600]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.252908,	
2017-07-17 22:15:33,339 Epoch[12] Batch [610]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.251123,	
2017-07-17 22:15:41,800 Epoch[12] Batch [620]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.253056,	
2017-07-17 22:15:49,801 Epoch[12] Batch [630]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.252510,	
2017-07-17 22:15:57,681 Epoch[12] Batch [640]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.250886,	
2017-07-17 22:16:05,891 Epoch[12] Batch [650]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.250314,	
2017-07-17 22:16:14,467 Epoch[12] Batch [660]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.249876,	
2017-07-17 22:16:22,389 Epoch[12] Batch [670]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.250093,	
2017-07-17 22:16:30,730 Epoch[12] Batch [680]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.249144,	
2017-07-17 22:16:39,397 Epoch[12] Batch [690]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.248642,	
2017-07-17 22:16:47,868 Epoch[12] Batch [700]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.247439,	
2017-07-17 22:16:56,084 Epoch[12] Batch [710]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.247648,	
2017-07-17 22:17:03,981 Epoch[12] Batch [720]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.247610,	
2017-07-17 22:17:11,925 Epoch[12] Batch [730]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.247395,	
2017-07-17 22:17:20,304 Epoch[12] Batch [740]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.247764,	
2017-07-17 22:17:29,018 Epoch[12] Batch [750]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.247741,	
2017-07-17 22:17:37,319 Epoch[12] Batch [760]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.247376,	
2017-07-17 22:17:45,426 Epoch[12] Batch [770]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.246838,	
2017-07-17 22:17:53,484 Epoch[12] Batch [780]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.246019,	
2017-07-17 22:18:01,835 Epoch[12] Batch [790]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.245352,	
2017-07-17 22:18:10,009 Epoch[12] Batch [800]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.244416,	
2017-07-17 22:18:18,517 Epoch[12] Batch [810]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.244846,	
2017-07-17 22:18:27,030 Epoch[12] Batch [820]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.244587,	
2017-07-17 22:18:35,326 Epoch[12] Batch [830]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.244115,	
2017-07-17 22:18:43,717 Epoch[12] Batch [840]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.243613,	
2017-07-17 22:18:52,086 Epoch[12] Batch [850]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.243215,	
2017-07-17 22:19:00,224 Epoch[12] Batch [860]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.242794,	
2017-07-17 22:19:08,716 Epoch[12] Batch [870]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.242392,	
2017-07-17 22:19:17,140 Epoch[12] Batch [880]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.243044,	
2017-07-17 22:19:25,302 Epoch[12] Batch [890]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.242977,	
2017-07-17 22:19:34,105 Epoch[12] Batch [900]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.243132,	
2017-07-17 22:19:42,970 Epoch[12] Batch [910]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.243152,	
2017-07-17 22:19:51,942 Epoch[12] Batch [920]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.244617,	
2017-07-17 22:20:00,689 Epoch[12] Batch [930]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.245066,	
2017-07-17 22:20:09,685 Epoch[12] Batch [940]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.245052,	
2017-07-17 22:20:18,559 Epoch[12] Batch [950]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.244279,	
2017-07-17 22:20:27,726 Epoch[12] Batch [960]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.243471,	
2017-07-17 22:20:36,484 Epoch[12] Batch [970]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.243352,	
2017-07-17 22:20:45,195 Epoch[12] Batch [980]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.244006,	
2017-07-17 22:20:53,620 Epoch[12] Batch [990]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.243998,	
2017-07-17 22:21:02,595 Epoch[12] Batch [1000]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.244390,	
2017-07-17 22:21:11,558 Epoch[12] Batch [1010]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.245164,	
2017-07-17 22:21:20,475 Epoch[12] Batch [1020]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.244490,	
2017-07-17 22:21:29,282 Epoch[12] Batch [1030]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.245420,	
2017-07-17 22:21:37,703 Epoch[12] Batch [1040]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.244877,	
2017-07-17 22:21:46,424 Epoch[12] Batch [1050]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.246214,	
2017-07-17 22:21:55,340 Epoch[12] Batch [1060]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.244819,	
2017-07-17 22:22:04,331 Epoch[12] Batch [1070]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.245073,	
2017-07-17 22:22:13,327 Epoch[12] Batch [1080]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.244946,	
2017-07-17 22:22:22,348 Epoch[12] Batch [1090]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.245871,	
2017-07-17 22:22:31,402 Epoch[12] Batch [1100]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.245946,	
2017-07-17 22:22:40,339 Epoch[12] Batch [1110]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.245533,	
2017-07-17 22:22:49,248 Epoch[12] Batch [1120]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.244419,	
2017-07-17 22:22:57,966 Epoch[12] Batch [1130]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.244654,	
2017-07-17 22:23:06,742 Epoch[12] Batch [1140]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.245065,	
2017-07-17 22:23:15,753 Epoch[12] Batch [1150]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.245302,	
2017-07-17 22:23:24,865 Epoch[12] Batch [1160]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.246085,	
2017-07-17 22:23:34,252 Epoch[12] Batch [1170]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.245568,	
2017-07-17 22:23:43,655 Epoch[12] Batch [1180]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.245093,	
2017-07-17 22:23:52,801 Epoch[12] Batch [1190]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.244918,	
2017-07-17 22:24:01,739 Epoch[12] Batch [1200]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.245385,	
2017-07-17 22:24:10,903 Epoch[12] Batch [1210]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.245662,	
2017-07-17 22:24:20,162 Epoch[12] Batch [1220]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.245034,	
2017-07-17 22:24:29,026 Epoch[12] Batch [1230]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.244482,	
2017-07-17 22:24:38,111 Epoch[12] Batch [1240]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.244308,	
2017-07-17 22:24:47,278 Epoch[12] Batch [1250]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.245023,	
2017-07-17 22:24:56,623 Epoch[12] Batch [1260]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.245361,	
2017-07-17 22:25:05,549 Epoch[12] Batch [1270]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.244821,	
2017-07-17 22:25:14,509 Epoch[12] Batch [1280]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.245897,	
2017-07-17 22:25:23,755 Epoch[12] Batch [1290]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.246006,	
2017-07-17 22:25:32,789 Epoch[12] Batch [1300]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.245870,	
2017-07-17 22:25:41,493 Epoch[12] Batch [1310]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.245666,	
2017-07-17 22:25:50,392 Epoch[12] Batch [1320]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.245685,	
2017-07-17 22:25:59,171 Epoch[12] Batch [1330]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.246270,	
2017-07-17 22:26:07,854 Epoch[12] Batch [1340]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.245934,	
2017-07-17 22:26:16,690 Epoch[12] Batch [1350]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.246006,	
2017-07-17 22:26:25,827 Epoch[12] Batch [1360]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.246402,	
2017-07-17 22:26:35,285 Epoch[12] Batch [1370]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.246932,	
2017-07-17 22:26:44,635 Epoch[12] Batch [1380]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.246539,	
2017-07-17 22:26:53,724 Epoch[12] Batch [1390]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.246556,	
2017-07-17 22:27:03,197 Epoch[12] Batch [1400]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.247062,	
2017-07-17 22:27:12,324 Epoch[12] Batch [1410]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.246655,	
2017-07-17 22:27:21,275 Epoch[12] Batch [1420]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.247637,	
2017-07-17 22:27:30,481 Epoch[12] Batch [1430]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.247690,	
2017-07-17 22:27:39,373 Epoch[12] Batch [1440]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.247266,	
2017-07-17 22:27:48,357 Epoch[12] Batch [1450]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.247415,	
2017-07-17 22:27:57,199 Epoch[12] Batch [1460]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.246950,	
2017-07-17 22:28:06,233 Epoch[12] Batch [1470]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.246678,	
2017-07-17 22:28:15,006 Epoch[12] Batch [1480]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.247161,	
2017-07-17 22:28:20,365 Epoch[12] Train-FCNLogLoss=1.246852
2017-07-17 22:28:20,365 Epoch[12] Time cost=1275.051
2017-07-17 22:28:21,601 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.params"
2017-07-17 22:28:25,335 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.states"
2017-07-17 22:28:36,436 Epoch[13] Batch [10]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.214747,	
2017-07-17 22:28:46,704 Epoch[13] Batch [20]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.207472,	
2017-07-17 22:28:56,829 Epoch[13] Batch [30]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.221221,	
2017-07-17 22:29:07,156 Epoch[13] Batch [40]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.227217,	
2017-07-17 22:29:17,011 Epoch[13] Batch [50]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.239931,	
2017-07-17 22:29:27,395 Epoch[13] Batch [60]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.222899,	
2017-07-17 22:29:37,332 Epoch[13] Batch [70]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.217928,	
2017-07-17 22:29:47,418 Epoch[13] Batch [80]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.224164,	
2017-07-17 22:29:57,245 Epoch[13] Batch [90]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.226223,	
2017-07-17 22:30:07,565 Epoch[13] Batch [100]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.224006,	
2017-07-17 22:30:17,510 Epoch[13] Batch [110]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.227303,	
2017-07-17 22:30:27,282 Epoch[13] Batch [120]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.221864,	
2017-07-17 22:30:37,489 Epoch[13] Batch [130]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.231602,	
2017-07-17 22:30:47,830 Epoch[13] Batch [140]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.225552,	
2017-07-17 22:30:58,078 Epoch[13] Batch [150]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.224003,	
2017-07-17 22:31:08,247 Epoch[13] Batch [160]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.223037,	
2017-07-17 22:31:18,661 Epoch[13] Batch [170]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.217980,	
2017-07-17 22:31:28,933 Epoch[13] Batch [180]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.218682,	
2017-07-17 22:31:39,116 Epoch[13] Batch [190]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.222021,	
2017-07-17 22:31:49,097 Epoch[13] Batch [200]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.219297,	
2017-07-17 22:31:59,053 Epoch[13] Batch [210]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.221453,	
2017-07-17 22:32:09,086 Epoch[13] Batch [220]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.224344,	
2017-07-17 22:32:18,067 Epoch[13] Batch [230]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.225309,	
2017-07-17 22:32:26,865 Epoch[13] Batch [240]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.226105,	
2017-07-17 22:32:35,780 Epoch[13] Batch [250]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.229806,	
2017-07-17 22:32:44,797 Epoch[13] Batch [260]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.231642,	
2017-07-17 22:32:53,569 Epoch[13] Batch [270]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.231182,	
2017-07-17 22:33:02,384 Epoch[13] Batch [280]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.229440,	
2017-07-17 22:33:11,064 Epoch[13] Batch [290]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.230943,	
2017-07-17 22:33:19,877 Epoch[13] Batch [300]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.230552,	
2017-07-17 22:33:28,875 Epoch[13] Batch [310]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.229913,	
2017-07-17 22:33:37,725 Epoch[13] Batch [320]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.229723,	
2017-07-17 22:33:46,962 Epoch[13] Batch [330]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.228225,	
2017-07-17 22:33:56,189 Epoch[13] Batch [340]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.228960,	
2017-07-17 22:34:05,340 Epoch[13] Batch [350]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.232531,	
2017-07-17 22:34:14,053 Epoch[13] Batch [360]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.233233,	
2017-07-17 22:34:23,186 Epoch[13] Batch [370]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.233777,	
2017-07-17 22:34:32,193 Epoch[13] Batch [380]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.234050,	
2017-07-17 22:34:41,244 Epoch[13] Batch [390]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.233517,	
2017-07-17 22:34:50,434 Epoch[13] Batch [400]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.232494,	
2017-07-17 22:34:59,084 Epoch[13] Batch [410]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.231826,	
2017-07-17 22:35:08,137 Epoch[13] Batch [420]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.232011,	
2017-07-17 22:35:17,232 Epoch[13] Batch [430]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.234017,	
2017-07-17 22:35:26,330 Epoch[13] Batch [440]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.236202,	
2017-07-17 22:35:35,059 Epoch[13] Batch [450]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236657,	
2017-07-17 22:35:43,994 Epoch[13] Batch [460]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.236969,	
2017-07-17 22:35:53,088 Epoch[13] Batch [470]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.236370,	
2017-07-17 22:36:02,125 Epoch[13] Batch [480]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.236810,	
2017-07-17 22:36:11,224 Epoch[13] Batch [490]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.235809,	
2017-07-17 22:36:20,068 Epoch[13] Batch [500]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.234720,	
2017-07-17 22:36:28,937 Epoch[13] Batch [510]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.232445,	
2017-07-17 22:36:38,319 Epoch[13] Batch [520]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.233390,	
2017-07-17 22:36:47,275 Epoch[13] Batch [530]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.233458,	
2017-07-17 22:36:56,197 Epoch[13] Batch [540]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.230727,	
2017-07-17 22:37:04,740 Epoch[13] Batch [550]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.230773,	
2017-07-17 22:37:13,570 Epoch[13] Batch [560]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.233475,	
2017-07-17 22:37:22,402 Epoch[13] Batch [570]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.233205,	
2017-07-17 22:37:31,162 Epoch[13] Batch [580]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.233730,	
2017-07-17 22:37:39,821 Epoch[13] Batch [590]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.233804,	
2017-07-17 22:37:48,814 Epoch[13] Batch [600]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.234704,	
2017-07-17 22:37:57,954 Epoch[13] Batch [610]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.234319,	
2017-07-17 22:38:07,040 Epoch[13] Batch [620]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.233578,	
2017-07-17 22:38:16,169 Epoch[13] Batch [630]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.234790,	
2017-07-17 22:38:24,835 Epoch[13] Batch [640]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.235857,	
2017-07-17 22:38:34,107 Epoch[13] Batch [650]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.235359,	
2017-07-17 22:38:43,163 Epoch[13] Batch [660]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.235184,	
2017-07-17 22:38:52,499 Epoch[13] Batch [670]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.234837,	
2017-07-17 22:39:01,742 Epoch[13] Batch [680]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.235541,	
2017-07-17 22:39:10,675 Epoch[13] Batch [690]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.235813,	
2017-07-17 22:39:19,733 Epoch[13] Batch [700]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.236289,	
2017-07-17 22:39:28,481 Epoch[13] Batch [710]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.235248,	
2017-07-17 22:39:37,551 Epoch[13] Batch [720]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.235578,	
2017-07-17 22:39:46,524 Epoch[13] Batch [730]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.233530,	
2017-07-17 22:39:55,715 Epoch[13] Batch [740]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.234302,	
2017-07-17 22:40:04,718 Epoch[13] Batch [750]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.234805,	
2017-07-17 22:40:14,179 Epoch[13] Batch [760]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.234661,	
2017-07-17 22:40:23,318 Epoch[13] Batch [770]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.232975,	
2017-07-17 22:40:32,232 Epoch[13] Batch [780]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.233760,	
2017-07-17 22:40:41,240 Epoch[13] Batch [790]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.234275,	
2017-07-17 22:40:50,282 Epoch[13] Batch [800]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.235558,	
2017-07-17 22:40:59,257 Epoch[13] Batch [810]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.235238,	
2017-07-17 22:41:08,204 Epoch[13] Batch [820]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.234381,	
2017-07-17 22:41:17,407 Epoch[13] Batch [830]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.234902,	
2017-07-17 22:41:26,608 Epoch[13] Batch [840]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.235709,	
2017-07-17 22:41:35,741 Epoch[13] Batch [850]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.236063,	
2017-07-17 22:41:44,467 Epoch[13] Batch [860]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236205,	
2017-07-17 22:41:53,403 Epoch[13] Batch [870]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.236486,	
2017-07-17 22:42:02,535 Epoch[13] Batch [880]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.235602,	
2017-07-17 22:42:11,652 Epoch[13] Batch [890]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.235673,	
2017-07-17 22:42:20,754 Epoch[13] Batch [900]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.234719,	
2017-07-17 22:42:30,028 Epoch[13] Batch [910]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.234523,	
2017-07-17 22:42:38,694 Epoch[13] Batch [920]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.234143,	
2017-07-17 22:42:47,614 Epoch[13] Batch [930]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.235011,	
2017-07-17 22:42:56,656 Epoch[13] Batch [940]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.234333,	
2017-07-17 22:43:06,041 Epoch[13] Batch [950]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.234560,	
2017-07-17 22:43:15,315 Epoch[13] Batch [960]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.233836,	
2017-07-17 22:43:24,465 Epoch[13] Batch [970]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.232863,	
2017-07-17 22:43:33,618 Epoch[13] Batch [980]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.232787,	
2017-07-17 22:43:42,861 Epoch[13] Batch [990]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.232790,	
2017-07-17 22:43:52,196 Epoch[13] Batch [1000]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.232910,	
2017-07-17 22:44:01,396 Epoch[13] Batch [1010]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.233406,	
2017-07-17 22:44:10,646 Epoch[13] Batch [1020]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.233776,	
2017-07-17 22:44:19,890 Epoch[13] Batch [1030]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.234482,	
2017-07-17 22:44:29,107 Epoch[13] Batch [1040]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.234919,	
2017-07-17 22:44:38,089 Epoch[13] Batch [1050]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.235823,	
2017-07-17 22:44:47,240 Epoch[13] Batch [1060]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.235408,	
2017-07-17 22:44:56,632 Epoch[13] Batch [1070]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.235092,	
2017-07-17 22:45:05,600 Epoch[13] Batch [1080]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.235780,	
2017-07-17 22:45:15,015 Epoch[13] Batch [1090]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.234851,	
2017-07-17 22:45:24,122 Epoch[13] Batch [1100]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.234751,	
2017-07-17 22:45:33,219 Epoch[13] Batch [1110]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.235635,	
2017-07-17 22:45:42,233 Epoch[13] Batch [1120]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.236447,	
2017-07-17 22:45:51,286 Epoch[13] Batch [1130]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.237317,	
2017-07-17 22:46:00,221 Epoch[13] Batch [1140]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.236896,	
2017-07-17 22:46:08,782 Epoch[13] Batch [1150]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.237620,	
2017-07-17 22:46:17,805 Epoch[13] Batch [1160]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.237981,	
2017-07-17 22:46:26,828 Epoch[13] Batch [1170]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.238374,	
2017-07-17 22:46:35,956 Epoch[13] Batch [1180]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.238550,	
2017-07-17 22:46:44,556 Epoch[13] Batch [1190]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.238701,	
2017-07-17 22:46:53,680 Epoch[13] Batch [1200]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.238650,	
2017-07-17 22:47:02,896 Epoch[13] Batch [1210]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.238518,	
2017-07-17 22:47:11,636 Epoch[13] Batch [1220]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.239097,	
2017-07-17 22:47:20,531 Epoch[13] Batch [1230]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.237987,	
2017-07-17 22:47:29,259 Epoch[13] Batch [1240]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236862,	
2017-07-17 22:47:38,017 Epoch[13] Batch [1250]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238010,	
2017-07-17 22:47:47,059 Epoch[13] Batch [1260]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.237778,	
2017-07-17 22:47:56,240 Epoch[13] Batch [1270]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.238233,	
2017-07-17 22:48:05,144 Epoch[13] Batch [1280]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.237954,	
2017-07-17 22:48:14,006 Epoch[13] Batch [1290]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.238547,	
2017-07-17 22:48:22,908 Epoch[13] Batch [1300]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.238542,	
2017-07-17 22:48:30,597 Epoch[13] Batch [1310]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.239323,	
2017-07-17 22:48:38,300 Epoch[13] Batch [1320]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.238750,	
2017-07-17 22:48:46,034 Epoch[13] Batch [1330]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.239391,	
2017-07-17 22:48:53,770 Epoch[13] Batch [1340]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.239736,	
2017-07-17 22:49:01,531 Epoch[13] Batch [1350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.239689,	
2017-07-17 22:49:09,131 Epoch[13] Batch [1360]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.240570,	
2017-07-17 22:49:17,776 Epoch[13] Batch [1370]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.241254,	
2017-07-17 22:49:26,931 Epoch[13] Batch [1380]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.240303,	
2017-07-17 22:49:36,013 Epoch[13] Batch [1390]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.239814,	
2017-07-17 22:49:45,326 Epoch[13] Batch [1400]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.239814,	
2017-07-17 22:49:54,338 Epoch[13] Batch [1410]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.239968,	
2017-07-17 22:50:02,732 Epoch[13] Batch [1420]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.239832,	
2017-07-17 22:50:11,460 Epoch[13] Batch [1430]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.238981,	
2017-07-17 22:50:20,154 Epoch[13] Batch [1440]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.239059,	
2017-07-17 22:50:29,314 Epoch[13] Batch [1450]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.239280,	
2017-07-17 22:50:38,360 Epoch[13] Batch [1460]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.239451,	
2017-07-17 22:50:47,004 Epoch[13] Batch [1470]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.239454,	
2017-07-17 22:50:56,388 Epoch[13] Batch [1480]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.239092,	
2017-07-17 22:51:01,815 Epoch[13] Train-FCNLogLoss=1.239397
2017-07-17 22:51:01,815 Epoch[13] Time cost=1356.480
2017-07-17 22:51:03,063 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.params"
2017-07-17 22:51:06,331 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.states"
2017-07-17 22:51:14,945 Epoch[14] Batch [10]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.276159,	
2017-07-17 22:51:22,496 Epoch[14] Batch [20]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.247508,	
2017-07-17 22:51:29,394 Epoch[14] Batch [30]	Speed: 5.80 samples/sec	Train-FCNLogLoss=1.229153,	
2017-07-17 22:51:36,370 Epoch[14] Batch [40]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.242416,	
2017-07-17 22:51:43,372 Epoch[14] Batch [50]	Speed: 5.71 samples/sec	Train-FCNLogLoss=1.239581,	
2017-07-17 22:51:50,503 Epoch[14] Batch [60]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.244436,	
2017-07-17 22:51:57,603 Epoch[14] Batch [70]	Speed: 5.63 samples/sec	Train-FCNLogLoss=1.243489,	
2017-07-17 22:52:05,073 Epoch[14] Batch [80]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.239887,	
2017-07-17 22:52:11,835 Epoch[14] Batch [90]	Speed: 5.92 samples/sec	Train-FCNLogLoss=1.236346,	
2017-07-17 22:52:18,548 Epoch[14] Batch [100]	Speed: 5.96 samples/sec	Train-FCNLogLoss=1.241370,	
2017-07-17 22:52:25,792 Epoch[14] Batch [110]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.245268,	
2017-07-17 22:52:33,000 Epoch[14] Batch [120]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.241533,	
2017-07-17 22:52:39,986 Epoch[14] Batch [130]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.244251,	
2017-07-17 22:52:47,004 Epoch[14] Batch [140]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.249345,	
2017-07-17 22:52:54,065 Epoch[14] Batch [150]	Speed: 5.66 samples/sec	Train-FCNLogLoss=1.246680,	
2017-07-17 22:53:00,950 Epoch[14] Batch [160]	Speed: 5.81 samples/sec	Train-FCNLogLoss=1.246839,	
2017-07-17 22:53:08,463 Epoch[14] Batch [170]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.247783,	
2017-07-17 22:53:15,546 Epoch[14] Batch [180]	Speed: 5.65 samples/sec	Train-FCNLogLoss=1.243827,	
2017-07-17 22:53:22,826 Epoch[14] Batch [190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.242261,	
2017-07-17 22:53:29,666 Epoch[14] Batch [200]	Speed: 5.85 samples/sec	Train-FCNLogLoss=1.240799,	
2017-07-17 22:53:37,486 Epoch[14] Batch [210]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.242844,	
2017-07-17 22:53:44,953 Epoch[14] Batch [220]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.243226,	
2017-07-17 22:53:52,011 Epoch[14] Batch [230]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.244949,	
2017-07-17 22:53:58,906 Epoch[14] Batch [240]	Speed: 5.80 samples/sec	Train-FCNLogLoss=1.248630,	
2017-07-17 22:54:06,096 Epoch[14] Batch [250]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.246331,	
2017-07-17 22:54:13,119 Epoch[14] Batch [260]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.247530,	
2017-07-17 22:54:20,092 Epoch[14] Batch [270]	Speed: 5.74 samples/sec	Train-FCNLogLoss=1.250653,	
2017-07-17 22:54:27,233 Epoch[14] Batch [280]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.251022,	
2017-07-17 22:54:34,442 Epoch[14] Batch [290]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.252951,	
2017-07-17 22:54:41,429 Epoch[14] Batch [300]	Speed: 5.72 samples/sec	Train-FCNLogLoss=1.256703,	
2017-07-17 22:54:48,781 Epoch[14] Batch [310]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.254855,	
2017-07-17 22:54:56,019 Epoch[14] Batch [320]	Speed: 5.53 samples/sec	Train-FCNLogLoss=1.253928,	
2017-07-17 22:55:02,723 Epoch[14] Batch [330]	Speed: 5.97 samples/sec	Train-FCNLogLoss=1.257233,	
2017-07-17 22:55:10,314 Epoch[14] Batch [340]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.256913,	
2017-07-17 22:55:17,337 Epoch[14] Batch [350]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.255819,	
2017-07-17 22:55:24,570 Epoch[14] Batch [360]	Speed: 5.53 samples/sec	Train-FCNLogLoss=1.254644,	
2017-07-17 22:55:31,898 Epoch[14] Batch [370]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.254487,	
2017-07-17 22:55:38,807 Epoch[14] Batch [380]	Speed: 5.79 samples/sec	Train-FCNLogLoss=1.254204,	
2017-07-17 22:55:45,973 Epoch[14] Batch [390]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.254970,	
2017-07-17 22:55:53,192 Epoch[14] Batch [400]	Speed: 5.54 samples/sec	Train-FCNLogLoss=1.253149,	
2017-07-17 22:56:00,346 Epoch[14] Batch [410]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.251229,	
2017-07-17 22:56:07,740 Epoch[14] Batch [420]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.249676,	
2017-07-17 22:56:14,884 Epoch[14] Batch [430]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.248040,	
2017-07-17 22:56:21,849 Epoch[14] Batch [440]	Speed: 5.74 samples/sec	Train-FCNLogLoss=1.250518,	
2017-07-17 22:56:28,770 Epoch[14] Batch [450]	Speed: 5.78 samples/sec	Train-FCNLogLoss=1.248909,	
2017-07-17 22:56:35,416 Epoch[14] Batch [460]	Speed: 6.02 samples/sec	Train-FCNLogLoss=1.247116,	
2017-07-17 22:56:42,586 Epoch[14] Batch [470]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.245816,	
2017-07-17 22:56:49,578 Epoch[14] Batch [480]	Speed: 5.72 samples/sec	Train-FCNLogLoss=1.244621,	
2017-07-17 22:56:56,631 Epoch[14] Batch [490]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.243458,	
2017-07-17 22:57:03,982 Epoch[14] Batch [500]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.243744,	
2017-07-17 22:57:11,116 Epoch[14] Batch [510]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.242950,	
2017-07-17 22:57:18,407 Epoch[14] Batch [520]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.242503,	
2017-07-17 22:57:25,730 Epoch[14] Batch [530]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.241921,	
2017-07-17 22:57:32,949 Epoch[14] Batch [540]	Speed: 5.54 samples/sec	Train-FCNLogLoss=1.239848,	
2017-07-17 22:57:40,192 Epoch[14] Batch [550]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.241444,	
2017-07-17 22:57:47,602 Epoch[14] Batch [560]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.241273,	
2017-07-17 22:57:54,750 Epoch[14] Batch [570]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.241348,	
2017-07-17 22:58:01,689 Epoch[14] Batch [580]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.242922,	
2017-07-17 22:58:08,871 Epoch[14] Batch [590]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.242939,	
2017-07-17 22:58:15,748 Epoch[14] Batch [600]	Speed: 5.82 samples/sec	Train-FCNLogLoss=1.242007,	
2017-07-17 22:58:23,079 Epoch[14] Batch [610]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.242147,	
2017-07-17 22:58:29,700 Epoch[14] Batch [620]	Speed: 6.04 samples/sec	Train-FCNLogLoss=1.242145,	
2017-07-17 22:58:36,899 Epoch[14] Batch [630]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.240835,	
2017-07-17 22:58:44,067 Epoch[14] Batch [640]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.239819,	
2017-07-17 22:58:50,971 Epoch[14] Batch [650]	Speed: 5.79 samples/sec	Train-FCNLogLoss=1.238572,	
2017-07-17 22:58:58,222 Epoch[14] Batch [660]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.237230,	
2017-07-17 22:59:05,332 Epoch[14] Batch [670]	Speed: 5.63 samples/sec	Train-FCNLogLoss=1.237663,	
2017-07-17 22:59:12,323 Epoch[14] Batch [680]	Speed: 5.72 samples/sec	Train-FCNLogLoss=1.238893,	
2017-07-17 22:59:19,799 Epoch[14] Batch [690]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.239744,	
2017-07-17 22:59:27,130 Epoch[14] Batch [700]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.240556,	
2017-07-17 22:59:34,039 Epoch[14] Batch [710]	Speed: 5.79 samples/sec	Train-FCNLogLoss=1.240908,	
2017-07-17 22:59:41,356 Epoch[14] Batch [720]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.239976,	
2017-07-17 22:59:48,524 Epoch[14] Batch [730]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.239361,	
2017-07-17 22:59:55,875 Epoch[14] Batch [740]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.239928,	
2017-07-17 23:00:02,846 Epoch[14] Batch [750]	Speed: 5.74 samples/sec	Train-FCNLogLoss=1.238689,	
2017-07-17 23:00:09,827 Epoch[14] Batch [760]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.239531,	
2017-07-17 23:00:16,805 Epoch[14] Batch [770]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.238058,	
2017-07-17 23:00:24,004 Epoch[14] Batch [780]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.238226,	
2017-07-17 23:00:31,587 Epoch[14] Batch [790]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.237379,	
2017-07-17 23:00:38,869 Epoch[14] Batch [800]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.237520,	
2017-07-17 23:00:46,300 Epoch[14] Batch [810]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.237959,	
2017-07-17 23:00:53,723 Epoch[14] Batch [820]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.237867,	
2017-07-17 23:01:01,079 Epoch[14] Batch [830]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.237997,	
2017-07-17 23:01:07,652 Epoch[14] Batch [840]	Speed: 6.09 samples/sec	Train-FCNLogLoss=1.238380,	
2017-07-17 23:01:14,764 Epoch[14] Batch [850]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.238747,	
2017-07-17 23:01:22,444 Epoch[14] Batch [860]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.238454,	
2017-07-17 23:01:29,777 Epoch[14] Batch [870]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.237343,	
2017-07-17 23:01:37,117 Epoch[14] Batch [880]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.237225,	
2017-07-17 23:01:44,047 Epoch[14] Batch [890]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.236928,	
2017-07-17 23:01:51,135 Epoch[14] Batch [900]	Speed: 5.64 samples/sec	Train-FCNLogLoss=1.237153,	
2017-07-17 23:01:58,467 Epoch[14] Batch [910]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.237092,	
2017-07-17 23:02:05,410 Epoch[14] Batch [920]	Speed: 5.76 samples/sec	Train-FCNLogLoss=1.236926,	
2017-07-17 23:02:12,822 Epoch[14] Batch [930]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.237300,	
2017-07-17 23:02:19,856 Epoch[14] Batch [940]	Speed: 5.69 samples/sec	Train-FCNLogLoss=1.237716,	
2017-07-17 23:02:27,267 Epoch[14] Batch [950]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.237748,	
2017-07-17 23:02:34,467 Epoch[14] Batch [960]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.239214,	
2017-07-17 23:02:40,900 Epoch[14] Batch [970]	Speed: 6.22 samples/sec	Train-FCNLogLoss=1.238620,	
2017-07-17 23:02:48,182 Epoch[14] Batch [980]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.238426,	
2017-07-17 23:02:54,894 Epoch[14] Batch [990]	Speed: 5.96 samples/sec	Train-FCNLogLoss=1.237943,	
2017-07-17 23:03:01,928 Epoch[14] Batch [1000]	Speed: 5.69 samples/sec	Train-FCNLogLoss=1.237853,	
2017-07-17 23:03:08,999 Epoch[14] Batch [1010]	Speed: 5.66 samples/sec	Train-FCNLogLoss=1.237436,	
2017-07-17 23:03:15,930 Epoch[14] Batch [1020]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.237737,	
2017-07-17 23:03:22,912 Epoch[14] Batch [1030]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.237884,	
2017-07-17 23:03:30,015 Epoch[14] Batch [1040]	Speed: 5.63 samples/sec	Train-FCNLogLoss=1.238070,	
2017-07-17 23:03:36,937 Epoch[14] Batch [1050]	Speed: 5.78 samples/sec	Train-FCNLogLoss=1.238146,	
2017-07-17 23:03:43,764 Epoch[14] Batch [1060]	Speed: 5.86 samples/sec	Train-FCNLogLoss=1.237707,	
2017-07-17 23:03:51,313 Epoch[14] Batch [1070]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.238149,	
2017-07-17 23:03:58,459 Epoch[14] Batch [1080]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.238555,	
2017-07-17 23:04:05,474 Epoch[14] Batch [1090]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.239300,	
2017-07-17 23:04:12,270 Epoch[14] Batch [1100]	Speed: 5.89 samples/sec	Train-FCNLogLoss=1.238654,	
2017-07-17 23:04:19,478 Epoch[14] Batch [1110]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.239214,	
2017-07-17 23:04:26,854 Epoch[14] Batch [1120]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.239332,	
2017-07-17 23:04:33,844 Epoch[14] Batch [1130]	Speed: 5.72 samples/sec	Train-FCNLogLoss=1.240068,	
2017-07-17 23:04:40,619 Epoch[14] Batch [1140]	Speed: 5.90 samples/sec	Train-FCNLogLoss=1.239553,	
2017-07-17 23:04:48,356 Epoch[14] Batch [1150]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.240986,	
2017-07-17 23:04:55,187 Epoch[14] Batch [1160]	Speed: 5.86 samples/sec	Train-FCNLogLoss=1.240726,	
2017-07-17 23:05:02,324 Epoch[14] Batch [1170]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.239656,	
2017-07-17 23:05:09,287 Epoch[14] Batch [1180]	Speed: 5.74 samples/sec	Train-FCNLogLoss=1.239814,	
2017-07-17 23:05:16,344 Epoch[14] Batch [1190]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.239119,	
2017-07-17 23:05:23,293 Epoch[14] Batch [1200]	Speed: 5.76 samples/sec	Train-FCNLogLoss=1.239389,	
2017-07-17 23:05:30,582 Epoch[14] Batch [1210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.240029,	
2017-07-17 23:05:38,463 Epoch[14] Batch [1220]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.239847,	
2017-07-17 23:05:45,780 Epoch[14] Batch [1230]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.239394,	
2017-07-17 23:05:53,570 Epoch[14] Batch [1240]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.238829,	
2017-07-17 23:06:00,816 Epoch[14] Batch [1250]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.239068,	
2017-07-17 23:06:08,119 Epoch[14] Batch [1260]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.239382,	
2017-07-17 23:06:15,491 Epoch[14] Batch [1270]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.239720,	
2017-07-17 23:06:22,697 Epoch[14] Batch [1280]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.240221,	
2017-07-17 23:06:29,522 Epoch[14] Batch [1290]	Speed: 5.86 samples/sec	Train-FCNLogLoss=1.239950,	
2017-07-17 23:06:36,502 Epoch[14] Batch [1300]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.240626,	
2017-07-17 23:06:43,862 Epoch[14] Batch [1310]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.239786,	
2017-07-17 23:06:51,701 Epoch[14] Batch [1320]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.240269,	
2017-07-17 23:06:58,738 Epoch[14] Batch [1330]	Speed: 5.68 samples/sec	Train-FCNLogLoss=1.240097,	
2017-07-17 23:07:05,988 Epoch[14] Batch [1340]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.240264,	
2017-07-17 23:07:13,096 Epoch[14] Batch [1350]	Speed: 5.63 samples/sec	Train-FCNLogLoss=1.239866,	
2017-07-17 23:07:20,679 Epoch[14] Batch [1360]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.240304,	
2017-07-17 23:07:28,126 Epoch[14] Batch [1370]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.240495,	
2017-07-17 23:07:35,294 Epoch[14] Batch [1380]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.240311,	
2017-07-17 23:07:42,346 Epoch[14] Batch [1390]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.239803,	
2017-07-17 23:07:49,788 Epoch[14] Batch [1400]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.239917,	
2017-07-17 23:07:57,349 Epoch[14] Batch [1410]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.240560,	
2017-07-17 23:08:04,834 Epoch[14] Batch [1420]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.240699,	
2017-07-17 23:08:12,308 Epoch[14] Batch [1430]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.241019,	
2017-07-17 23:08:20,271 Epoch[14] Batch [1440]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.241073,	
2017-07-17 23:08:27,808 Epoch[14] Batch [1450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.241662,	
2017-07-17 23:08:35,325 Epoch[14] Batch [1460]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.242105,	
2017-07-17 23:08:42,669 Epoch[14] Batch [1470]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.242385,	
2017-07-17 23:08:49,655 Epoch[14] Batch [1480]	Speed: 5.73 samples/sec	Train-FCNLogLoss=1.242501,	
2017-07-17 23:08:53,787 Epoch[14] Train-FCNLogLoss=1.242567
2017-07-17 23:08:53,788 Epoch[14] Time cost=1067.457
2017-07-17 23:08:55,169 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.params"
2017-07-17 23:08:58,341 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.states"
2017-07-17 23:09:06,153 Epoch[15] Batch [10]	Speed: 5.93 samples/sec	Train-FCNLogLoss=1.120782,	
2017-07-17 23:09:14,152 Epoch[15] Batch [20]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.217366,	
2017-07-17 23:09:21,114 Epoch[15] Batch [30]	Speed: 5.75 samples/sec	Train-FCNLogLoss=1.220652,	
2017-07-17 23:09:28,591 Epoch[15] Batch [40]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.208649,	
2017-07-17 23:09:35,653 Epoch[15] Batch [50]	Speed: 5.66 samples/sec	Train-FCNLogLoss=1.223486,	
2017-07-17 23:09:43,149 Epoch[15] Batch [60]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.214746,	
2017-07-17 23:09:50,591 Epoch[15] Batch [70]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.211028,	
2017-07-17 23:09:57,228 Epoch[15] Batch [80]	Speed: 6.03 samples/sec	Train-FCNLogLoss=1.207896,	
2017-07-17 23:10:04,429 Epoch[15] Batch [90]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.209653,	
2017-07-17 23:10:11,563 Epoch[15] Batch [100]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.218011,	
2017-07-17 23:10:19,518 Epoch[15] Batch [110]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.224290,	
2017-07-17 23:10:27,080 Epoch[15] Batch [120]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.231353,	
2017-07-17 23:10:34,355 Epoch[15] Batch [130]	Speed: 5.50 samples/sec	Train-FCNLogLoss=1.237696,	
2017-07-17 23:10:41,409 Epoch[15] Batch [140]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.240682,	
2017-07-17 23:10:48,589 Epoch[15] Batch [150]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.233423,	
2017-07-17 23:10:56,148 Epoch[15] Batch [160]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.235036,	
2017-07-17 23:11:03,414 Epoch[15] Batch [170]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.234738,	
2017-07-17 23:11:10,652 Epoch[15] Batch [180]	Speed: 5.53 samples/sec	Train-FCNLogLoss=1.232640,	
2017-07-17 23:11:17,557 Epoch[15] Batch [190]	Speed: 5.79 samples/sec	Train-FCNLogLoss=1.229419,	
2017-07-17 23:11:24,851 Epoch[15] Batch [200]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.229345,	
2017-07-17 23:11:32,057 Epoch[15] Batch [210]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.225397,	
2017-07-17 23:11:39,778 Epoch[15] Batch [220]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.223706,	
2017-07-17 23:11:47,302 Epoch[15] Batch [230]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.227859,	
2017-07-17 23:11:54,463 Epoch[15] Batch [240]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.230815,	
2017-07-17 23:12:01,827 Epoch[15] Batch [250]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.228673,	
2017-07-17 23:12:08,681 Epoch[15] Batch [260]	Speed: 5.84 samples/sec	Train-FCNLogLoss=1.228024,	
2017-07-17 23:12:16,180 Epoch[15] Batch [270]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.225127,	
2017-07-17 23:12:23,846 Epoch[15] Batch [280]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.222808,	
2017-07-17 23:12:30,655 Epoch[15] Batch [290]	Speed: 5.88 samples/sec	Train-FCNLogLoss=1.225446,	
2017-07-17 23:12:37,697 Epoch[15] Batch [300]	Speed: 5.68 samples/sec	Train-FCNLogLoss=1.227869,	
2017-07-17 23:12:44,946 Epoch[15] Batch [310]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.226840,	
2017-07-17 23:12:52,384 Epoch[15] Batch [320]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.229528,	
2017-07-17 23:12:59,406 Epoch[15] Batch [330]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.228584,	
2017-07-17 23:13:06,938 Epoch[15] Batch [340]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.228925,	
2017-07-17 23:13:14,440 Epoch[15] Batch [350]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.229766,	
2017-07-17 23:13:21,933 Epoch[15] Batch [360]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.232385,	
2017-07-17 23:13:29,488 Epoch[15] Batch [370]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.233696,	
2017-07-17 23:13:36,954 Epoch[15] Batch [380]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.236777,	
2017-07-17 23:13:44,112 Epoch[15] Batch [390]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.235326,	
2017-07-17 23:13:51,165 Epoch[15] Batch [400]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.236201,	
2017-07-17 23:13:58,540 Epoch[15] Batch [410]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.236433,	
2017-07-17 23:14:05,825 Epoch[15] Batch [420]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.239768,	
2017-07-17 23:14:13,016 Epoch[15] Batch [430]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.239351,	
2017-07-17 23:14:20,068 Epoch[15] Batch [440]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.238478,	
2017-07-17 23:14:27,414 Epoch[15] Batch [450]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.238602,	
2017-07-17 23:14:34,801 Epoch[15] Batch [460]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.237769,	
2017-07-17 23:14:42,371 Epoch[15] Batch [470]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.238562,	
2017-07-17 23:14:49,631 Epoch[15] Batch [480]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.238710,	
2017-07-17 23:14:57,094 Epoch[15] Batch [490]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.238632,	
2017-07-17 23:15:04,853 Epoch[15] Batch [500]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.239406,	
2017-07-17 23:15:12,412 Epoch[15] Batch [510]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.239509,	
2017-07-17 23:15:19,988 Epoch[15] Batch [520]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.238392,	
2017-07-17 23:15:27,603 Epoch[15] Batch [530]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.239262,	
2017-07-17 23:15:34,988 Epoch[15] Batch [540]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.238054,	
2017-07-17 23:15:41,919 Epoch[15] Batch [550]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.237383,	
2017-07-17 23:15:49,174 Epoch[15] Batch [560]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.235466,	
2017-07-17 23:15:56,516 Epoch[15] Batch [570]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.235783,	
2017-07-17 23:16:03,662 Epoch[15] Batch [580]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.234828,	
2017-07-17 23:16:10,675 Epoch[15] Batch [590]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.234879,	
2017-07-17 23:16:18,261 Epoch[15] Batch [600]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.233679,	
2017-07-17 23:16:25,546 Epoch[15] Batch [610]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.232553,	
2017-07-17 23:16:33,238 Epoch[15] Batch [620]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.232562,	
2017-07-17 23:16:40,384 Epoch[15] Batch [630]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.233670,	
2017-07-17 23:16:47,768 Epoch[15] Batch [640]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.234674,	
2017-07-17 23:16:55,557 Epoch[15] Batch [650]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.234151,	
2017-07-17 23:17:03,120 Epoch[15] Batch [660]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.232853,	
2017-07-17 23:17:10,951 Epoch[15] Batch [670]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.231389,	
2017-07-17 23:17:18,440 Epoch[15] Batch [680]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.232002,	
2017-07-17 23:17:25,555 Epoch[15] Batch [690]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.234603,	
2017-07-17 23:17:32,762 Epoch[15] Batch [700]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.233832,	
2017-07-17 23:17:40,150 Epoch[15] Batch [710]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.234237,	
2017-07-17 23:17:47,762 Epoch[15] Batch [720]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.235526,	
2017-07-17 23:17:55,292 Epoch[15] Batch [730]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.235797,	
2017-07-17 23:18:02,310 Epoch[15] Batch [740]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.236091,	
2017-07-17 23:18:09,552 Epoch[15] Batch [750]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.236862,	
2017-07-17 23:18:16,595 Epoch[15] Batch [760]	Speed: 5.68 samples/sec	Train-FCNLogLoss=1.236503,	
2017-07-17 23:18:23,635 Epoch[15] Batch [770]	Speed: 5.68 samples/sec	Train-FCNLogLoss=1.235944,	
2017-07-17 23:18:30,938 Epoch[15] Batch [780]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.236243,	
2017-07-17 23:18:38,335 Epoch[15] Batch [790]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.237070,	
2017-07-17 23:18:45,213 Epoch[15] Batch [800]	Speed: 5.82 samples/sec	Train-FCNLogLoss=1.236674,	
2017-07-17 23:18:53,200 Epoch[15] Batch [810]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.237981,	
2017-07-17 23:19:00,540 Epoch[15] Batch [820]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.238941,	
2017-07-17 23:19:08,645 Epoch[15] Batch [830]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.238320,	
2017-07-17 23:19:16,845 Epoch[15] Batch [840]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.240301,	
2017-07-17 23:19:24,285 Epoch[15] Batch [850]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.239651,	
2017-07-17 23:19:33,082 Epoch[15] Batch [860]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.239540,	
2017-07-17 23:19:40,947 Epoch[15] Batch [870]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.238970,	
2017-07-17 23:19:48,661 Epoch[15] Batch [880]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.238907,	
2017-07-17 23:19:56,351 Epoch[15] Batch [890]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.239951,	
2017-07-17 23:20:04,172 Epoch[15] Batch [900]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.240808,	
2017-07-17 23:20:11,353 Epoch[15] Batch [910]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.240867,	
2017-07-17 23:20:19,313 Epoch[15] Batch [920]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.241685,	
2017-07-17 23:20:27,114 Epoch[15] Batch [930]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.241859,	
2017-07-17 23:20:34,356 Epoch[15] Batch [940]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.242595,	
2017-07-17 23:20:41,852 Epoch[15] Batch [950]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.242751,	
2017-07-17 23:20:49,166 Epoch[15] Batch [960]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.243283,	
2017-07-17 23:20:56,732 Epoch[15] Batch [970]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.244009,	
2017-07-17 23:21:04,474 Epoch[15] Batch [980]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.243647,	
2017-07-17 23:21:12,388 Epoch[15] Batch [990]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.242956,	
2017-07-17 23:21:19,591 Epoch[15] Batch [1000]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.243471,	
2017-07-17 23:21:27,421 Epoch[15] Batch [1010]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.243030,	
2017-07-17 23:21:34,968 Epoch[15] Batch [1020]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.242883,	
2017-07-17 23:21:42,609 Epoch[15] Batch [1030]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.243003,	
2017-07-17 23:21:50,321 Epoch[15] Batch [1040]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.242521,	
2017-07-17 23:21:57,634 Epoch[15] Batch [1050]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.242526,	
2017-07-17 23:22:04,999 Epoch[15] Batch [1060]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.242207,	
2017-07-17 23:22:12,337 Epoch[15] Batch [1070]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.241020,	
2017-07-17 23:22:20,147 Epoch[15] Batch [1080]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.241474,	
2017-07-17 23:22:27,275 Epoch[15] Batch [1090]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.241256,	
2017-07-17 23:22:34,852 Epoch[15] Batch [1100]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.240945,	
2017-07-17 23:22:42,355 Epoch[15] Batch [1110]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.240637,	
2017-07-17 23:22:49,618 Epoch[15] Batch [1120]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.241388,	
2017-07-17 23:22:57,043 Epoch[15] Batch [1130]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.241431,	
2017-07-17 23:23:04,600 Epoch[15] Batch [1140]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.241152,	
2017-07-17 23:23:12,049 Epoch[15] Batch [1150]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.241302,	
2017-07-17 23:23:19,181 Epoch[15] Batch [1160]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.241529,	
2017-07-17 23:23:27,656 Epoch[15] Batch [1170]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.243288,	
2017-07-17 23:23:35,305 Epoch[15] Batch [1180]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.243279,	
2017-07-17 23:23:42,502 Epoch[15] Batch [1190]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.243584,	
2017-07-17 23:23:49,802 Epoch[15] Batch [1200]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.243821,	
2017-07-17 23:23:57,446 Epoch[15] Batch [1210]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.243188,	
2017-07-17 23:24:04,985 Epoch[15] Batch [1220]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.242536,	
2017-07-17 23:24:12,336 Epoch[15] Batch [1230]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.241884,	
2017-07-17 23:24:20,069 Epoch[15] Batch [1240]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.242157,	
2017-07-17 23:24:28,205 Epoch[15] Batch [1250]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.241393,	
2017-07-17 23:24:36,365 Epoch[15] Batch [1260]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.241546,	
2017-07-17 23:24:44,349 Epoch[15] Batch [1270]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.242719,	
2017-07-17 23:24:52,436 Epoch[15] Batch [1280]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.242450,	
2017-07-17 23:25:00,756 Epoch[15] Batch [1290]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.243118,	
2017-07-17 23:25:08,356 Epoch[15] Batch [1300]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.243251,	
2017-07-17 23:25:15,872 Epoch[15] Batch [1310]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.243378,	
2017-07-17 23:25:23,300 Epoch[15] Batch [1320]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.243126,	
2017-07-17 23:25:30,626 Epoch[15] Batch [1330]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.243521,	
2017-07-17 23:25:38,018 Epoch[15] Batch [1340]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.243414,	
2017-07-17 23:25:45,429 Epoch[15] Batch [1350]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.242907,	
2017-07-17 23:25:52,950 Epoch[15] Batch [1360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.243383,	
2017-07-17 23:26:00,081 Epoch[15] Batch [1370]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.243688,	
2017-07-17 23:26:07,883 Epoch[15] Batch [1380]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.243184,	
2017-07-17 23:26:16,162 Epoch[15] Batch [1390]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.243318,	
2017-07-17 23:26:23,668 Epoch[15] Batch [1400]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.243449,	
2017-07-17 23:26:31,299 Epoch[15] Batch [1410]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.243358,	
2017-07-17 23:26:39,143 Epoch[15] Batch [1420]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.242931,	
2017-07-17 23:26:46,690 Epoch[15] Batch [1430]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.242580,	
2017-07-17 23:26:54,137 Epoch[15] Batch [1440]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.242491,	
2017-07-17 23:27:01,812 Epoch[15] Batch [1450]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.241827,	
2017-07-17 23:27:09,211 Epoch[15] Batch [1460]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.241898,	
2017-07-17 23:27:16,786 Epoch[15] Batch [1470]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.242352,	
2017-07-17 23:27:24,188 Epoch[15] Batch [1480]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.241725,	
2017-07-17 23:27:28,305 Epoch[15] Train-FCNLogLoss=1.241336
2017-07-17 23:27:28,305 Epoch[15] Time cost=1109.964
2017-07-17 23:27:29,566 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.params"
2017-07-17 23:27:32,546 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.states"
2017-07-17 23:27:41,620 Epoch[16] Batch [10]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.240242,	
2017-07-17 23:27:49,511 Epoch[16] Batch [20]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.252598,	
2017-07-17 23:27:57,874 Epoch[16] Batch [30]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.216586,	
2017-07-17 23:28:05,255 Epoch[16] Batch [40]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.197072,	
2017-07-17 23:28:13,087 Epoch[16] Batch [50]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.233543,	
2017-07-17 23:28:20,635 Epoch[16] Batch [60]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.224545,	
2017-07-17 23:28:28,390 Epoch[16] Batch [70]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.226834,	
2017-07-17 23:28:36,167 Epoch[16] Batch [80]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.236494,	
2017-07-17 23:28:44,075 Epoch[16] Batch [90]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.232357,	
2017-07-17 23:28:52,291 Epoch[16] Batch [100]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.226380,	
2017-07-17 23:29:00,482 Epoch[16] Batch [110]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.233622,	
2017-07-17 23:29:08,141 Epoch[16] Batch [120]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.236938,	
2017-07-17 23:29:16,117 Epoch[16] Batch [130]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.237028,	
2017-07-17 23:29:24,008 Epoch[16] Batch [140]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.230028,	
2017-07-17 23:29:32,096 Epoch[16] Batch [150]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.229901,	
2017-07-17 23:29:39,878 Epoch[16] Batch [160]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.231619,	
2017-07-17 23:29:47,693 Epoch[16] Batch [170]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.232214,	
2017-07-17 23:29:55,411 Epoch[16] Batch [180]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.234824,	
2017-07-17 23:30:03,542 Epoch[16] Batch [190]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.231222,	
2017-07-17 23:30:11,689 Epoch[16] Batch [200]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.232026,	
2017-07-17 23:30:19,407 Epoch[16] Batch [210]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.230230,	
2017-07-17 23:30:27,072 Epoch[16] Batch [220]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.227527,	
2017-07-17 23:30:34,612 Epoch[16] Batch [230]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.224957,	
2017-07-17 23:30:42,759 Epoch[16] Batch [240]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.224558,	
2017-07-17 23:30:50,663 Epoch[16] Batch [250]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.224643,	
2017-07-17 23:30:58,777 Epoch[16] Batch [260]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.222405,	
2017-07-17 23:31:06,788 Epoch[16] Batch [270]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.223825,	
2017-07-17 23:31:15,014 Epoch[16] Batch [280]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.224752,	
2017-07-17 23:31:22,846 Epoch[16] Batch [290]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.224769,	
2017-07-17 23:31:30,444 Epoch[16] Batch [300]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.224173,	
2017-07-17 23:31:38,056 Epoch[16] Batch [310]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.222716,	
2017-07-17 23:31:45,677 Epoch[16] Batch [320]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.221407,	
2017-07-17 23:31:52,827 Epoch[16] Batch [330]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.221749,	
2017-07-17 23:32:00,414 Epoch[16] Batch [340]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.220097,	
2017-07-17 23:32:08,088 Epoch[16] Batch [350]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.223634,	
2017-07-17 23:32:15,571 Epoch[16] Batch [360]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.222303,	
2017-07-17 23:32:23,328 Epoch[16] Batch [370]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.222475,	
2017-07-17 23:32:30,856 Epoch[16] Batch [380]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.220620,	
2017-07-17 23:32:38,282 Epoch[16] Batch [390]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.222038,	
2017-07-17 23:32:45,743 Epoch[16] Batch [400]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.222851,	
2017-07-17 23:32:53,913 Epoch[16] Batch [410]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.221971,	
2017-07-17 23:33:01,314 Epoch[16] Batch [420]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.222698,	
2017-07-17 23:33:08,967 Epoch[16] Batch [430]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.223722,	
2017-07-17 23:33:16,691 Epoch[16] Batch [440]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.224647,	
2017-07-17 23:33:24,192 Epoch[16] Batch [450]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.225019,	
2017-07-17 23:33:31,873 Epoch[16] Batch [460]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.226776,	
2017-07-17 23:33:39,204 Epoch[16] Batch [470]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.225992,	
2017-07-17 23:33:46,651 Epoch[16] Batch [480]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.226141,	
2017-07-17 23:33:54,387 Epoch[16] Batch [490]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.226714,	
2017-07-17 23:34:01,751 Epoch[16] Batch [500]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.227279,	
2017-07-17 23:34:09,681 Epoch[16] Batch [510]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.225723,	
2017-07-17 23:34:17,390 Epoch[16] Batch [520]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.226145,	
2017-07-17 23:34:25,289 Epoch[16] Batch [530]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.226966,	
2017-07-17 23:34:33,468 Epoch[16] Batch [540]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.224756,	
2017-07-17 23:34:42,241 Epoch[16] Batch [550]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.225423,	
2017-07-17 23:34:50,583 Epoch[16] Batch [560]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.227006,	
2017-07-17 23:34:58,441 Epoch[16] Batch [570]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.228742,	
2017-07-17 23:35:06,519 Epoch[16] Batch [580]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.229317,	
2017-07-17 23:35:14,381 Epoch[16] Batch [590]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.229844,	
2017-07-17 23:35:22,653 Epoch[16] Batch [600]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.230128,	
2017-07-17 23:35:30,261 Epoch[16] Batch [610]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.232673,	
2017-07-17 23:35:38,634 Epoch[16] Batch [620]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.231515,	
2017-07-17 23:35:46,642 Epoch[16] Batch [630]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.233905,	
2017-07-17 23:35:55,073 Epoch[16] Batch [640]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.235950,	
2017-07-17 23:36:03,185 Epoch[16] Batch [650]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.237210,	
2017-07-17 23:36:11,123 Epoch[16] Batch [660]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.236754,	
2017-07-17 23:36:19,361 Epoch[16] Batch [670]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.236445,	
2017-07-17 23:36:27,542 Epoch[16] Batch [680]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.237769,	
2017-07-17 23:36:36,139 Epoch[16] Batch [690]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.237737,	
2017-07-17 23:36:44,738 Epoch[16] Batch [700]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.237398,	
2017-07-17 23:36:52,842 Epoch[16] Batch [710]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.238281,	
2017-07-17 23:37:00,891 Epoch[16] Batch [720]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.238500,	
2017-07-17 23:37:09,144 Epoch[16] Batch [730]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.237480,	
2017-07-17 23:37:17,125 Epoch[16] Batch [740]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.237317,	
2017-07-17 23:37:25,154 Epoch[16] Batch [750]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.239077,	
2017-07-17 23:37:33,308 Epoch[16] Batch [760]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.240033,	
2017-07-17 23:37:41,743 Epoch[16] Batch [770]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.240897,	
2017-07-17 23:37:49,901 Epoch[16] Batch [780]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.242240,	
2017-07-17 23:37:58,384 Epoch[16] Batch [790]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.243225,	
2017-07-17 23:38:06,603 Epoch[16] Batch [800]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.244599,	
2017-07-17 23:38:14,739 Epoch[16] Batch [810]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.244378,	
2017-07-17 23:38:22,958 Epoch[16] Batch [820]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.244870,	
2017-07-17 23:38:31,575 Epoch[16] Batch [830]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.245469,	
2017-07-17 23:38:39,993 Epoch[16] Batch [840]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.245200,	
2017-07-17 23:38:48,032 Epoch[16] Batch [850]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.244761,	
2017-07-17 23:38:56,441 Epoch[16] Batch [860]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.244318,	
2017-07-17 23:39:04,975 Epoch[16] Batch [870]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.243397,	
2017-07-17 23:39:13,371 Epoch[16] Batch [880]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.243295,	
2017-07-17 23:39:21,394 Epoch[16] Batch [890]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.242119,	
2017-07-17 23:39:28,979 Epoch[16] Batch [900]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.242430,	
2017-07-17 23:39:36,815 Epoch[16] Batch [910]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.241364,	
2017-07-17 23:39:44,774 Epoch[16] Batch [920]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.242531,	
2017-07-17 23:39:53,157 Epoch[16] Batch [930]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.243049,	
2017-07-17 23:40:01,295 Epoch[16] Batch [940]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.242645,	
2017-07-17 23:40:09,451 Epoch[16] Batch [950]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.241974,	
2017-07-17 23:40:17,792 Epoch[16] Batch [960]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.242219,	
2017-07-17 23:40:25,944 Epoch[16] Batch [970]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.241783,	
2017-07-17 23:40:34,821 Epoch[16] Batch [980]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.242077,	
2017-07-17 23:40:43,256 Epoch[16] Batch [990]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.242289,	
2017-07-17 23:40:51,471 Epoch[16] Batch [1000]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.242648,	
2017-07-17 23:40:59,978 Epoch[16] Batch [1010]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.243728,	
2017-07-17 23:41:08,448 Epoch[16] Batch [1020]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.242759,	
2017-07-17 23:41:16,253 Epoch[16] Batch [1030]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.242131,	
2017-07-17 23:41:24,104 Epoch[16] Batch [1040]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.242404,	
2017-07-17 23:41:32,172 Epoch[16] Batch [1050]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.242732,	
2017-07-17 23:41:39,885 Epoch[16] Batch [1060]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.243373,	
2017-07-17 23:41:48,196 Epoch[16] Batch [1070]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.242818,	
2017-07-17 23:41:56,078 Epoch[16] Batch [1080]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.243154,	
2017-07-17 23:42:04,224 Epoch[16] Batch [1090]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.243734,	
2017-07-17 23:42:12,638 Epoch[16] Batch [1100]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.243719,	
2017-07-17 23:42:21,008 Epoch[16] Batch [1110]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.244091,	
2017-07-17 23:42:29,250 Epoch[16] Batch [1120]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.243252,	
2017-07-17 23:42:37,274 Epoch[16] Batch [1130]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.242848,	
2017-07-17 23:42:45,215 Epoch[16] Batch [1140]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.242791,	
2017-07-17 23:42:53,385 Epoch[16] Batch [1150]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.243086,	
2017-07-17 23:43:01,627 Epoch[16] Batch [1160]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.242804,	
2017-07-17 23:43:09,677 Epoch[16] Batch [1170]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.242382,	
2017-07-17 23:43:17,622 Epoch[16] Batch [1180]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.241732,	
2017-07-17 23:43:25,858 Epoch[16] Batch [1190]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.241555,	
2017-07-17 23:43:33,761 Epoch[16] Batch [1200]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.242352,	
2017-07-17 23:43:41,779 Epoch[16] Batch [1210]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.242435,	
2017-07-17 23:43:50,310 Epoch[16] Batch [1220]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.242777,	
2017-07-17 23:43:58,757 Epoch[16] Batch [1230]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.243611,	
2017-07-17 23:44:07,027 Epoch[16] Batch [1240]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.242773,	
2017-07-17 23:44:15,006 Epoch[16] Batch [1250]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.242853,	
2017-07-17 23:44:23,171 Epoch[16] Batch [1260]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.243609,	
2017-07-17 23:44:30,891 Epoch[16] Batch [1270]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.242944,	
2017-07-17 23:44:39,154 Epoch[16] Batch [1280]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.242834,	
2017-07-17 23:44:47,131 Epoch[16] Batch [1290]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.242421,	
2017-07-17 23:44:55,333 Epoch[16] Batch [1300]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.242271,	
2017-07-17 23:45:03,156 Epoch[16] Batch [1310]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.242390,	
2017-07-17 23:45:11,832 Epoch[16] Batch [1320]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.242700,	
2017-07-17 23:45:19,727 Epoch[16] Batch [1330]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.242676,	
2017-07-17 23:45:28,014 Epoch[16] Batch [1340]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.243187,	
2017-07-17 23:45:36,302 Epoch[16] Batch [1350]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.242892,	
2017-07-17 23:45:44,996 Epoch[16] Batch [1360]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.242677,	
2017-07-17 23:45:53,421 Epoch[16] Batch [1370]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.242877,	
2017-07-17 23:46:01,693 Epoch[16] Batch [1380]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.242712,	
2017-07-17 23:46:10,061 Epoch[16] Batch [1390]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.242612,	
2017-07-17 23:46:18,188 Epoch[16] Batch [1400]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.242219,	
2017-07-17 23:46:26,251 Epoch[16] Batch [1410]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.241914,	
2017-07-17 23:46:34,275 Epoch[16] Batch [1420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.242050,	
2017-07-17 23:46:42,459 Epoch[16] Batch [1430]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.242605,	
2017-07-17 23:46:50,789 Epoch[16] Batch [1440]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.242299,	
2017-07-17 23:46:58,740 Epoch[16] Batch [1450]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.242272,	
2017-07-17 23:47:06,707 Epoch[16] Batch [1460]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.242831,	
2017-07-17 23:47:15,114 Epoch[16] Batch [1470]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.242345,	
2017-07-17 23:47:23,101 Epoch[16] Batch [1480]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.241910,	
2017-07-17 23:47:27,908 Epoch[16] Train-FCNLogLoss=1.242028
2017-07-17 23:47:27,908 Epoch[16] Time cost=1195.092
2017-07-17 23:47:28,941 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.params"
2017-07-17 23:47:31,496 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.states"
2017-07-17 23:47:40,666 Epoch[17] Batch [10]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.188966,	
2017-07-17 23:47:48,533 Epoch[17] Batch [20]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.233917,	
2017-07-17 23:47:55,796 Epoch[17] Batch [30]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.221281,	
2017-07-17 23:48:03,319 Epoch[17] Batch [40]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.211841,	
2017-07-17 23:48:10,820 Epoch[17] Batch [50]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.213608,	
2017-07-17 23:48:18,467 Epoch[17] Batch [60]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.211222,	
2017-07-17 23:48:25,979 Epoch[17] Batch [70]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.216509,	
2017-07-17 23:48:33,667 Epoch[17] Batch [80]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.218958,	
2017-07-17 23:48:41,060 Epoch[17] Batch [90]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.223624,	
2017-07-17 23:48:48,200 Epoch[17] Batch [100]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.218103,	
2017-07-17 23:48:55,502 Epoch[17] Batch [110]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.229962,	
2017-07-17 23:49:02,989 Epoch[17] Batch [120]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.228297,	
2017-07-17 23:49:10,632 Epoch[17] Batch [130]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.227491,	
2017-07-17 23:49:18,068 Epoch[17] Batch [140]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.230901,	
2017-07-17 23:49:25,451 Epoch[17] Batch [150]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.229653,	
2017-07-17 23:49:33,134 Epoch[17] Batch [160]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.233729,	
2017-07-17 23:49:40,732 Epoch[17] Batch [170]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.233598,	
2017-07-17 23:49:48,653 Epoch[17] Batch [180]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.232123,	
2017-07-17 23:49:56,477 Epoch[17] Batch [190]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.230050,	
2017-07-17 23:50:03,954 Epoch[17] Batch [200]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.234219,	
2017-07-17 23:50:11,311 Epoch[17] Batch [210]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.232934,	
2017-07-17 23:50:18,885 Epoch[17] Batch [220]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.236173,	
2017-07-17 23:50:26,553 Epoch[17] Batch [230]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.236905,	
2017-07-17 23:50:33,772 Epoch[17] Batch [240]	Speed: 5.54 samples/sec	Train-FCNLogLoss=1.235615,	
2017-07-17 23:50:41,145 Epoch[17] Batch [250]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.232447,	
2017-07-17 23:50:48,744 Epoch[17] Batch [260]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.237658,	
2017-07-17 23:50:56,341 Epoch[17] Batch [270]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.236703,	
2017-07-17 23:51:03,681 Epoch[17] Batch [280]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.236557,	
2017-07-17 23:51:11,632 Epoch[17] Batch [290]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.240764,	
2017-07-17 23:51:19,158 Epoch[17] Batch [300]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.239272,	
2017-07-17 23:51:26,839 Epoch[17] Batch [310]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.240306,	
2017-07-17 23:51:34,676 Epoch[17] Batch [320]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.240273,	
2017-07-17 23:51:42,146 Epoch[17] Batch [330]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.240915,	
2017-07-17 23:51:49,745 Epoch[17] Batch [340]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.242086,	
2017-07-17 23:51:57,430 Epoch[17] Batch [350]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.242116,	
2017-07-17 23:52:04,976 Epoch[17] Batch [360]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.241502,	
2017-07-17 23:52:12,349 Epoch[17] Batch [370]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.241296,	
2017-07-17 23:52:19,901 Epoch[17] Batch [380]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.240493,	
2017-07-17 23:52:27,950 Epoch[17] Batch [390]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.237422,	
2017-07-17 23:52:35,516 Epoch[17] Batch [400]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.237802,	
2017-07-17 23:52:43,855 Epoch[17] Batch [410]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.238797,	
2017-07-17 23:52:52,014 Epoch[17] Batch [420]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.238207,	
2017-07-17 23:53:00,067 Epoch[17] Batch [430]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.237637,	
2017-07-17 23:53:07,553 Epoch[17] Batch [440]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.238771,	
2017-07-17 23:53:14,505 Epoch[17] Batch [450]	Speed: 5.75 samples/sec	Train-FCNLogLoss=1.236691,	
2017-07-17 23:53:21,780 Epoch[17] Batch [460]	Speed: 5.50 samples/sec	Train-FCNLogLoss=1.238872,	
2017-07-17 23:53:29,410 Epoch[17] Batch [470]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.238069,	
2017-07-17 23:53:36,706 Epoch[17] Batch [480]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.237201,	
2017-07-17 23:53:43,925 Epoch[17] Batch [490]	Speed: 5.54 samples/sec	Train-FCNLogLoss=1.238106,	
2017-07-17 23:53:50,931 Epoch[17] Batch [500]	Speed: 5.71 samples/sec	Train-FCNLogLoss=1.236647,	
2017-07-17 23:53:58,590 Epoch[17] Batch [510]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.237111,	
2017-07-17 23:54:06,046 Epoch[17] Batch [520]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.236095,	
2017-07-17 23:54:13,288 Epoch[17] Batch [530]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.235197,	
2017-07-17 23:54:21,329 Epoch[17] Batch [540]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.234972,	
2017-07-17 23:54:29,172 Epoch[17] Batch [550]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.234465,	
2017-07-17 23:54:36,079 Epoch[17] Batch [560]	Speed: 5.79 samples/sec	Train-FCNLogLoss=1.234941,	
2017-07-17 23:54:43,609 Epoch[17] Batch [570]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.234771,	
2017-07-17 23:54:50,816 Epoch[17] Batch [580]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.234923,	
2017-07-17 23:54:58,113 Epoch[17] Batch [590]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.235376,	
2017-07-17 23:55:05,615 Epoch[17] Batch [600]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.234755,	
2017-07-17 23:55:12,809 Epoch[17] Batch [610]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.235172,	
2017-07-17 23:55:20,125 Epoch[17] Batch [620]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.236606,	
2017-07-17 23:55:27,685 Epoch[17] Batch [630]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.236814,	
2017-07-17 23:55:35,178 Epoch[17] Batch [640]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.236236,	
2017-07-17 23:55:42,593 Epoch[17] Batch [650]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.235914,	
2017-07-17 23:55:49,981 Epoch[17] Batch [660]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.237391,	
2017-07-17 23:55:57,172 Epoch[17] Batch [670]	Speed: 5.56 samples/sec	Train-FCNLogLoss=1.235584,	
2017-07-17 23:56:04,555 Epoch[17] Batch [680]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.235454,	
2017-07-17 23:56:11,860 Epoch[17] Batch [690]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.235477,	
2017-07-17 23:56:19,386 Epoch[17] Batch [700]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.238080,	
2017-07-17 23:56:27,180 Epoch[17] Batch [710]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.238126,	
2017-07-17 23:56:34,647 Epoch[17] Batch [720]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.238240,	
2017-07-17 23:56:42,143 Epoch[17] Batch [730]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.237740,	
2017-07-17 23:56:49,404 Epoch[17] Batch [740]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.236152,	
2017-07-17 23:56:57,158 Epoch[17] Batch [750]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.236319,	
2017-07-17 23:57:04,663 Epoch[17] Batch [760]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.236843,	
2017-07-17 23:57:12,497 Epoch[17] Batch [770]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.238118,	
2017-07-17 23:57:19,875 Epoch[17] Batch [780]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.238335,	
2017-07-17 23:57:27,486 Epoch[17] Batch [790]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.238948,	
2017-07-17 23:57:34,844 Epoch[17] Batch [800]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.238463,	
2017-07-17 23:57:42,389 Epoch[17] Batch [810]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.237870,	
2017-07-17 23:57:49,880 Epoch[17] Batch [820]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.237904,	
2017-07-17 23:57:57,669 Epoch[17] Batch [830]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.237813,	
2017-07-17 23:58:05,031 Epoch[17] Batch [840]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.237449,	
2017-07-17 23:58:12,599 Epoch[17] Batch [850]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.237722,	
2017-07-17 23:58:20,050 Epoch[17] Batch [860]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.239304,	
2017-07-17 23:58:27,655 Epoch[17] Batch [870]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.240962,	
2017-07-17 23:58:35,270 Epoch[17] Batch [880]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.241276,	
2017-07-17 23:58:42,810 Epoch[17] Batch [890]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.241361,	
2017-07-17 23:58:50,635 Epoch[17] Batch [900]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.240614,	
2017-07-17 23:58:58,041 Epoch[17] Batch [910]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.240635,	
2017-07-17 23:59:05,657 Epoch[17] Batch [920]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.239786,	
2017-07-17 23:59:13,434 Epoch[17] Batch [930]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.240458,	
2017-07-17 23:59:21,276 Epoch[17] Batch [940]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.239794,	
2017-07-17 23:59:28,794 Epoch[17] Batch [950]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.241911,	
2017-07-17 23:59:36,109 Epoch[17] Batch [960]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.241853,	
2017-07-17 23:59:43,529 Epoch[17] Batch [970]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.241306,	
2017-07-17 23:59:51,057 Epoch[17] Batch [980]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.242066,	
2017-07-17 23:59:58,355 Epoch[17] Batch [990]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.242762,	
2017-07-18 00:00:05,910 Epoch[17] Batch [1000]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.243105,	
2017-07-18 00:00:13,611 Epoch[17] Batch [1010]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.242102,	
2017-07-18 00:00:21,090 Epoch[17] Batch [1020]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.242999,	
2017-07-18 00:00:28,644 Epoch[17] Batch [1030]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.242927,	
2017-07-18 00:00:36,362 Epoch[17] Batch [1040]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.243486,	
2017-07-18 00:00:44,208 Epoch[17] Batch [1050]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.243324,	
2017-07-18 00:00:51,310 Epoch[17] Batch [1060]	Speed: 5.63 samples/sec	Train-FCNLogLoss=1.243085,	
2017-07-18 00:00:58,693 Epoch[17] Batch [1070]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.243060,	
2017-07-18 00:01:06,086 Epoch[17] Batch [1080]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.242725,	
2017-07-18 00:01:13,858 Epoch[17] Batch [1090]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.242275,	
2017-07-18 00:01:21,284 Epoch[17] Batch [1100]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.242612,	
2017-07-18 00:01:28,763 Epoch[17] Batch [1110]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.241985,	
2017-07-18 00:01:36,616 Epoch[17] Batch [1120]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.242004,	
2017-07-18 00:01:44,236 Epoch[17] Batch [1130]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.242007,	
2017-07-18 00:01:52,029 Epoch[17] Batch [1140]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.241800,	
2017-07-18 00:01:59,235 Epoch[17] Batch [1150]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.241633,	
2017-07-18 00:02:06,580 Epoch[17] Batch [1160]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.242325,	
2017-07-18 00:02:13,941 Epoch[17] Batch [1170]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.242214,	
2017-07-18 00:02:21,634 Epoch[17] Batch [1180]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.242366,	
2017-07-18 00:02:29,575 Epoch[17] Batch [1190]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.243240,	
2017-07-18 00:02:37,646 Epoch[17] Batch [1200]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.243311,	
2017-07-18 00:02:45,688 Epoch[17] Batch [1210]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.243615,	
2017-07-18 00:02:53,971 Epoch[17] Batch [1220]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.243649,	
2017-07-18 00:03:01,595 Epoch[17] Batch [1230]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.243237,	
2017-07-18 00:03:10,113 Epoch[17] Batch [1240]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.243370,	
2017-07-18 00:03:18,758 Epoch[17] Batch [1250]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.243447,	
2017-07-18 00:03:27,053 Epoch[17] Batch [1260]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.243822,	
2017-07-18 00:03:35,352 Epoch[17] Batch [1270]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.243792,	
2017-07-18 00:03:43,706 Epoch[17] Batch [1280]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.243522,	
2017-07-18 00:03:51,826 Epoch[17] Batch [1290]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.243538,	
2017-07-18 00:03:59,858 Epoch[17] Batch [1300]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.243717,	
2017-07-18 00:04:08,271 Epoch[17] Batch [1310]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.243423,	
2017-07-18 00:04:16,373 Epoch[17] Batch [1320]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.242803,	
2017-07-18 00:04:24,805 Epoch[17] Batch [1330]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.243410,	
2017-07-18 00:04:33,080 Epoch[17] Batch [1340]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.243693,	
2017-07-18 00:04:41,329 Epoch[17] Batch [1350]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.243570,	
2017-07-18 00:04:49,319 Epoch[17] Batch [1360]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.242888,	
2017-07-18 00:04:57,181 Epoch[17] Batch [1370]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.242984,	
2017-07-18 00:05:05,541 Epoch[17] Batch [1380]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.243022,	
2017-07-18 00:05:13,494 Epoch[17] Batch [1390]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.242553,	
2017-07-18 00:05:21,490 Epoch[17] Batch [1400]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.241815,	
2017-07-18 00:05:29,792 Epoch[17] Batch [1410]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.241973,	
2017-07-18 00:05:38,072 Epoch[17] Batch [1420]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.241338,	
2017-07-18 00:05:46,266 Epoch[17] Batch [1430]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.241827,	
2017-07-18 00:05:54,087 Epoch[17] Batch [1440]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.241301,	
2017-07-18 00:06:02,271 Epoch[17] Batch [1450]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.241484,	
2017-07-18 00:06:10,719 Epoch[17] Batch [1460]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.240945,	
2017-07-18 00:06:18,802 Epoch[17] Batch [1470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.240703,	
2017-07-18 00:06:26,948 Epoch[17] Batch [1480]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.240594,	
2017-07-18 00:06:31,630 Epoch[17] Train-FCNLogLoss=1.240410
2017-07-18 00:06:31,631 Epoch[17] Time cost=1139.933
2017-07-18 00:06:33,066 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.params"
2017-07-18 00:06:36,363 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.states"
2017-07-18 00:06:45,295 Epoch[18] Batch [10]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.183346,	
2017-07-18 00:06:52,863 Epoch[18] Batch [20]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.186600,	
2017-07-18 00:07:00,683 Epoch[18] Batch [30]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.211384,	
2017-07-18 00:07:08,181 Epoch[18] Batch [40]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.223820,	
2017-07-18 00:07:15,825 Epoch[18] Batch [50]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.237296,	
2017-07-18 00:07:23,675 Epoch[18] Batch [60]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.240003,	
2017-07-18 00:07:31,821 Epoch[18] Batch [70]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.240933,	
2017-07-18 00:07:39,378 Epoch[18] Batch [80]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.236811,	
2017-07-18 00:07:47,155 Epoch[18] Batch [90]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.249212,	
2017-07-18 00:07:54,730 Epoch[18] Batch [100]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.248741,	
2017-07-18 00:08:02,156 Epoch[18] Batch [110]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.252426,	
2017-07-18 00:08:09,920 Epoch[18] Batch [120]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.259539,	
2017-07-18 00:08:17,884 Epoch[18] Batch [130]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.258700,	
2017-07-18 00:08:25,201 Epoch[18] Batch [140]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.262404,	
2017-07-18 00:08:32,699 Epoch[18] Batch [150]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.267064,	
2017-07-18 00:08:40,372 Epoch[18] Batch [160]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.266125,	
2017-07-18 00:08:48,315 Epoch[18] Batch [170]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.259130,	
2017-07-18 00:08:55,689 Epoch[18] Batch [180]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.259773,	
2017-07-18 00:09:03,471 Epoch[18] Batch [190]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.261540,	
2017-07-18 00:09:11,178 Epoch[18] Batch [200]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.260224,	
2017-07-18 00:09:18,678 Epoch[18] Batch [210]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.260253,	
2017-07-18 00:09:26,645 Epoch[18] Batch [220]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.261359,	
2017-07-18 00:09:34,144 Epoch[18] Batch [230]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.257362,	
2017-07-18 00:09:41,522 Epoch[18] Batch [240]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.259180,	
2017-07-18 00:09:49,819 Epoch[18] Batch [250]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.255759,	
2017-07-18 00:09:57,679 Epoch[18] Batch [260]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.255205,	
2017-07-18 00:10:05,689 Epoch[18] Batch [270]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.254957,	
2017-07-18 00:10:13,445 Epoch[18] Batch [280]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.255908,	
2017-07-18 00:10:21,479 Epoch[18] Batch [290]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.253724,	
2017-07-18 00:10:29,159 Epoch[18] Batch [300]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.253396,	
2017-07-18 00:10:36,914 Epoch[18] Batch [310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.254076,	
2017-07-18 00:10:45,099 Epoch[18] Batch [320]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.253269,	
2017-07-18 00:10:53,090 Epoch[18] Batch [330]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.255427,	
2017-07-18 00:11:01,025 Epoch[18] Batch [340]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.252027,	
2017-07-18 00:11:08,915 Epoch[18] Batch [350]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.253878,	
2017-07-18 00:11:17,009 Epoch[18] Batch [360]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.253663,	
2017-07-18 00:11:24,887 Epoch[18] Batch [370]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.252383,	
2017-07-18 00:11:32,823 Epoch[18] Batch [380]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.250396,	
2017-07-18 00:11:41,692 Epoch[18] Batch [390]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.249185,	
2017-07-18 00:11:50,510 Epoch[18] Batch [400]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.249331,	
2017-07-18 00:11:58,425 Epoch[18] Batch [410]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.248586,	
2017-07-18 00:12:06,958 Epoch[18] Batch [420]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.248581,	
2017-07-18 00:12:15,460 Epoch[18] Batch [430]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.249345,	
2017-07-18 00:12:24,126 Epoch[18] Batch [440]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.250857,	
2017-07-18 00:12:32,371 Epoch[18] Batch [450]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.250147,	
2017-07-18 00:12:41,038 Epoch[18] Batch [460]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.250813,	
2017-07-18 00:12:49,735 Epoch[18] Batch [470]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.253361,	
2017-07-18 00:12:57,795 Epoch[18] Batch [480]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.252052,	
2017-07-18 00:13:05,750 Epoch[18] Batch [490]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.253498,	
2017-07-18 00:13:14,276 Epoch[18] Batch [500]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.252504,	
2017-07-18 00:13:22,288 Epoch[18] Batch [510]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.251986,	
2017-07-18 00:13:30,410 Epoch[18] Batch [520]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.252275,	
2017-07-18 00:13:38,712 Epoch[18] Batch [530]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.252070,	
2017-07-18 00:13:47,596 Epoch[18] Batch [540]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.250980,	
2017-07-18 00:13:56,244 Epoch[18] Batch [550]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.251344,	
2017-07-18 00:14:05,063 Epoch[18] Batch [560]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.250801,	
2017-07-18 00:14:13,453 Epoch[18] Batch [570]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.249488,	
2017-07-18 00:14:21,988 Epoch[18] Batch [580]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.248685,	
2017-07-18 00:14:30,327 Epoch[18] Batch [590]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.249142,	
2017-07-18 00:14:38,890 Epoch[18] Batch [600]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.248468,	
2017-07-18 00:14:47,121 Epoch[18] Batch [610]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.248800,	
2017-07-18 00:14:55,991 Epoch[18] Batch [620]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.247226,	
2017-07-18 00:15:04,984 Epoch[18] Batch [630]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.246210,	
2017-07-18 00:15:13,496 Epoch[18] Batch [640]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.246007,	
2017-07-18 00:15:22,265 Epoch[18] Batch [650]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.246570,	
2017-07-18 00:15:30,415 Epoch[18] Batch [660]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.246583,	
2017-07-18 00:15:38,983 Epoch[18] Batch [670]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.244668,	
2017-07-18 00:15:47,279 Epoch[18] Batch [680]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.245593,	
2017-07-18 00:15:55,620 Epoch[18] Batch [690]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.243773,	
2017-07-18 00:16:03,922 Epoch[18] Batch [700]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.243771,	
2017-07-18 00:16:12,563 Epoch[18] Batch [710]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.243918,	
2017-07-18 00:16:20,607 Epoch[18] Batch [720]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.243720,	
2017-07-18 00:16:28,649 Epoch[18] Batch [730]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.243817,	
2017-07-18 00:16:36,887 Epoch[18] Batch [740]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.242556,	
2017-07-18 00:16:45,321 Epoch[18] Batch [750]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.243336,	
2017-07-18 00:16:53,794 Epoch[18] Batch [760]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.243685,	
2017-07-18 00:17:01,997 Epoch[18] Batch [770]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.243917,	
2017-07-18 00:17:10,376 Epoch[18] Batch [780]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.245412,	
2017-07-18 00:17:19,118 Epoch[18] Batch [790]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.246643,	
2017-07-18 00:17:27,417 Epoch[18] Batch [800]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.247096,	
2017-07-18 00:17:36,006 Epoch[18] Batch [810]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.246984,	
2017-07-18 00:17:44,146 Epoch[18] Batch [820]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.247249,	
2017-07-18 00:17:52,586 Epoch[18] Batch [830]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.245987,	
2017-07-18 00:18:01,106 Epoch[18] Batch [840]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.246822,	
2017-07-18 00:18:09,739 Epoch[18] Batch [850]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.247451,	
2017-07-18 00:18:18,622 Epoch[18] Batch [860]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.246989,	
2017-07-18 00:18:27,092 Epoch[18] Batch [870]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.246102,	
2017-07-18 00:18:35,743 Epoch[18] Batch [880]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.245439,	
2017-07-18 00:18:44,775 Epoch[18] Batch [890]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.244122,	
2017-07-18 00:18:53,128 Epoch[18] Batch [900]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.244490,	
2017-07-18 00:19:02,404 Epoch[18] Batch [910]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.244114,	
2017-07-18 00:19:10,962 Epoch[18] Batch [920]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.243519,	
2017-07-18 00:19:19,611 Epoch[18] Batch [930]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.242206,	
2017-07-18 00:19:28,006 Epoch[18] Batch [940]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.242528,	
2017-07-18 00:19:36,226 Epoch[18] Batch [950]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.241904,	
2017-07-18 00:19:44,652 Epoch[18] Batch [960]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.241897,	
2017-07-18 00:19:53,075 Epoch[18] Batch [970]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.241459,	
2017-07-18 00:20:02,215 Epoch[18] Batch [980]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.241100,	
2017-07-18 00:20:10,708 Epoch[18] Batch [990]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.241430,	
2017-07-18 00:20:19,027 Epoch[18] Batch [1000]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.241073,	
2017-07-18 00:20:27,250 Epoch[18] Batch [1010]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.241129,	
2017-07-18 00:20:35,655 Epoch[18] Batch [1020]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.241811,	
2017-07-18 00:20:44,129 Epoch[18] Batch [1030]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.241565,	
2017-07-18 00:20:52,598 Epoch[18] Batch [1040]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.242655,	
2017-07-18 00:21:00,734 Epoch[18] Batch [1050]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.242496,	
2017-07-18 00:21:09,220 Epoch[18] Batch [1060]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.242635,	
2017-07-18 00:21:17,935 Epoch[18] Batch [1070]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.241856,	
2017-07-18 00:21:26,645 Epoch[18] Batch [1080]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.241340,	
2017-07-18 00:21:35,412 Epoch[18] Batch [1090]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.241382,	
2017-07-18 00:21:43,839 Epoch[18] Batch [1100]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.241272,	
2017-07-18 00:21:52,169 Epoch[18] Batch [1110]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.240862,	
2017-07-18 00:22:00,685 Epoch[18] Batch [1120]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.240726,	
2017-07-18 00:22:09,471 Epoch[18] Batch [1130]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.240729,	
2017-07-18 00:22:18,080 Epoch[18] Batch [1140]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.239961,	
2017-07-18 00:22:26,564 Epoch[18] Batch [1150]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.240202,	
2017-07-18 00:22:35,129 Epoch[18] Batch [1160]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.240563,	
2017-07-18 00:22:43,530 Epoch[18] Batch [1170]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.240108,	
2017-07-18 00:22:52,143 Epoch[18] Batch [1180]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.240268,	
2017-07-18 00:23:00,604 Epoch[18] Batch [1190]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.239772,	
2017-07-18 00:23:09,147 Epoch[18] Batch [1200]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.239966,	
2017-07-18 00:23:18,132 Epoch[18] Batch [1210]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.240171,	
2017-07-18 00:23:26,411 Epoch[18] Batch [1220]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.240638,	
2017-07-18 00:23:35,115 Epoch[18] Batch [1230]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.240887,	
2017-07-18 00:23:43,657 Epoch[18] Batch [1240]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.241483,	
2017-07-18 00:23:51,922 Epoch[18] Batch [1250]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.241444,	
2017-07-18 00:24:00,434 Epoch[18] Batch [1260]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.241871,	
2017-07-18 00:24:09,287 Epoch[18] Batch [1270]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.240704,	
2017-07-18 00:24:18,074 Epoch[18] Batch [1280]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.240422,	
2017-07-18 00:24:26,549 Epoch[18] Batch [1290]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.241172,	
2017-07-18 00:24:34,834 Epoch[18] Batch [1300]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.241505,	
2017-07-18 00:24:43,087 Epoch[18] Batch [1310]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.241190,	
2017-07-18 00:24:51,767 Epoch[18] Batch [1320]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.241376,	
2017-07-18 00:24:59,968 Epoch[18] Batch [1330]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.241077,	
2017-07-18 00:25:08,331 Epoch[18] Batch [1340]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.241244,	
2017-07-18 00:25:17,189 Epoch[18] Batch [1350]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.241618,	
2017-07-18 00:25:25,799 Epoch[18] Batch [1360]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.241591,	
2017-07-18 00:25:34,291 Epoch[18] Batch [1370]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.242132,	
2017-07-18 00:25:42,638 Epoch[18] Batch [1380]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.243494,	
2017-07-18 00:25:51,158 Epoch[18] Batch [1390]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.243185,	
2017-07-18 00:25:59,579 Epoch[18] Batch [1400]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.243187,	
2017-07-18 00:26:08,048 Epoch[18] Batch [1410]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.242467,	
2017-07-18 00:26:16,301 Epoch[18] Batch [1420]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.241983,	
2017-07-18 00:26:24,841 Epoch[18] Batch [1430]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.241627,	
2017-07-18 00:26:33,144 Epoch[18] Batch [1440]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.241785,	
2017-07-18 00:26:41,623 Epoch[18] Batch [1450]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.242115,	
2017-07-18 00:26:50,183 Epoch[18] Batch [1460]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.241988,	
2017-07-18 00:26:58,989 Epoch[18] Batch [1470]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.242292,	
2017-07-18 00:27:07,798 Epoch[18] Batch [1480]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.242132,	
2017-07-18 00:27:13,347 Epoch[18] Train-FCNLogLoss=1.241639
2017-07-18 00:27:13,348 Epoch[18] Time cost=1236.877
2017-07-18 00:27:14,390 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.params"
2017-07-18 00:27:17,353 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.states"
2017-07-18 00:27:27,170 Epoch[19] Batch [10]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.234363,	
2017-07-18 00:27:35,250 Epoch[19] Batch [20]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.220658,	
2017-07-18 00:27:43,144 Epoch[19] Batch [30]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.211677,	
2017-07-18 00:27:51,272 Epoch[19] Batch [40]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.225162,	
2017-07-18 00:27:59,492 Epoch[19] Batch [50]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.248298,	
2017-07-18 00:28:07,790 Epoch[19] Batch [60]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.259411,	
2017-07-18 00:28:15,952 Epoch[19] Batch [70]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.251603,	
2017-07-18 00:28:24,476 Epoch[19] Batch [80]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.248017,	
2017-07-18 00:28:32,405 Epoch[19] Batch [90]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.227293,	
2017-07-18 00:28:40,804 Epoch[19] Batch [100]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.229849,	
2017-07-18 00:28:48,983 Epoch[19] Batch [110]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.233956,	
2017-07-18 00:28:57,614 Epoch[19] Batch [120]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.233507,	
2017-07-18 00:29:06,002 Epoch[19] Batch [130]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.236539,	
2017-07-18 00:29:14,004 Epoch[19] Batch [140]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.230340,	
2017-07-18 00:29:22,030 Epoch[19] Batch [150]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.225072,	
2017-07-18 00:29:30,656 Epoch[19] Batch [160]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.230323,	
2017-07-18 00:29:39,249 Epoch[19] Batch [170]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.232122,	
2017-07-18 00:29:47,395 Epoch[19] Batch [180]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.228305,	
2017-07-18 00:29:56,308 Epoch[19] Batch [190]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.230840,	
2017-07-18 00:30:04,681 Epoch[19] Batch [200]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.231993,	
2017-07-18 00:30:12,681 Epoch[19] Batch [210]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.227911,	
2017-07-18 00:30:21,111 Epoch[19] Batch [220]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.227159,	
2017-07-18 00:30:29,285 Epoch[19] Batch [230]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.226023,	
2017-07-18 00:30:37,660 Epoch[19] Batch [240]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.222412,	
2017-07-18 00:30:45,927 Epoch[19] Batch [250]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.223040,	
2017-07-18 00:30:54,350 Epoch[19] Batch [260]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.225582,	
2017-07-18 00:31:03,176 Epoch[19] Batch [270]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.227408,	
2017-07-18 00:31:11,267 Epoch[19] Batch [280]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.231473,	
2017-07-18 00:31:19,584 Epoch[19] Batch [290]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.229543,	
2017-07-18 00:31:28,106 Epoch[19] Batch [300]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.230505,	
2017-07-18 00:31:36,811 Epoch[19] Batch [310]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.230248,	
2017-07-18 00:31:44,922 Epoch[19] Batch [320]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.231942,	
2017-07-18 00:31:53,303 Epoch[19] Batch [330]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.229266,	
2017-07-18 00:32:01,499 Epoch[19] Batch [340]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.232397,	
2017-07-18 00:32:09,763 Epoch[19] Batch [350]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.238003,	
2017-07-18 00:32:18,127 Epoch[19] Batch [360]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.238494,	
2017-07-18 00:32:26,572 Epoch[19] Batch [370]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.238678,	
2017-07-18 00:32:35,001 Epoch[19] Batch [380]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.239125,	
2017-07-18 00:32:43,739 Epoch[19] Batch [390]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.240483,	
2017-07-18 00:32:51,865 Epoch[19] Batch [400]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.238258,	
2017-07-18 00:33:00,193 Epoch[19] Batch [410]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.234343,	
2017-07-18 00:33:08,193 Epoch[19] Batch [420]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.232082,	
2017-07-18 00:33:16,312 Epoch[19] Batch [430]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.230958,	
2017-07-18 00:33:24,828 Epoch[19] Batch [440]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.230792,	
2017-07-18 00:33:33,111 Epoch[19] Batch [450]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.232899,	
2017-07-18 00:33:41,843 Epoch[19] Batch [460]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.234801,	
2017-07-18 00:33:50,911 Epoch[19] Batch [470]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.233270,	
2017-07-18 00:33:59,484 Epoch[19] Batch [480]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.234020,	
2017-07-18 00:34:08,026 Epoch[19] Batch [490]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.234994,	
2017-07-18 00:34:16,552 Epoch[19] Batch [500]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.234457,	
2017-07-18 00:34:25,300 Epoch[19] Batch [510]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.236030,	
2017-07-18 00:34:34,180 Epoch[19] Batch [520]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.237550,	
2017-07-18 00:34:42,485 Epoch[19] Batch [530]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.237320,	
2017-07-18 00:34:51,206 Epoch[19] Batch [540]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.237019,	
2017-07-18 00:35:00,167 Epoch[19] Batch [550]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.237579,	
2017-07-18 00:35:08,679 Epoch[19] Batch [560]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.238956,	
2017-07-18 00:35:17,759 Epoch[19] Batch [570]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.237772,	
2017-07-18 00:35:26,436 Epoch[19] Batch [580]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.240847,	
2017-07-18 00:35:35,520 Epoch[19] Batch [590]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.239241,	
2017-07-18 00:35:44,053 Epoch[19] Batch [600]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.241831,	
2017-07-18 00:35:52,546 Epoch[19] Batch [610]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.242355,	
2017-07-18 00:36:01,280 Epoch[19] Batch [620]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.240225,	
2017-07-18 00:36:09,946 Epoch[19] Batch [630]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239895,	
2017-07-18 00:36:18,443 Epoch[19] Batch [640]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.238916,	
2017-07-18 00:36:26,987 Epoch[19] Batch [650]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.239117,	
2017-07-18 00:36:35,651 Epoch[19] Batch [660]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239580,	
2017-07-18 00:36:44,805 Epoch[19] Batch [670]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.240428,	
2017-07-18 00:36:53,792 Epoch[19] Batch [680]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.240472,	
2017-07-18 00:37:02,326 Epoch[19] Batch [690]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.240266,	
2017-07-18 00:37:10,925 Epoch[19] Batch [700]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.241700,	
2017-07-18 00:37:19,790 Epoch[19] Batch [710]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.240228,	
2017-07-18 00:37:28,587 Epoch[19] Batch [720]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241418,	
2017-07-18 00:37:37,598 Epoch[19] Batch [730]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.240784,	
2017-07-18 00:37:46,384 Epoch[19] Batch [740]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.240031,	
2017-07-18 00:37:55,526 Epoch[19] Batch [750]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.239025,	
2017-07-18 00:38:04,256 Epoch[19] Batch [760]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.240386,	
2017-07-18 00:38:12,777 Epoch[19] Batch [770]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.240773,	
2017-07-18 00:38:21,392 Epoch[19] Batch [780]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.240671,	
2017-07-18 00:38:30,078 Epoch[19] Batch [790]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.241421,	
2017-07-18 00:38:38,533 Epoch[19] Batch [800]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.241598,	
2017-07-18 00:38:47,269 Epoch[19] Batch [810]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.241445,	
2017-07-18 00:38:55,619 Epoch[19] Batch [820]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.241517,	
2017-07-18 00:39:03,926 Epoch[19] Batch [830]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.241843,	
2017-07-18 00:39:12,720 Epoch[19] Batch [840]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241115,	
2017-07-18 00:39:21,571 Epoch[19] Batch [850]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.240529,	
2017-07-18 00:39:30,412 Epoch[19] Batch [860]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.241596,	
2017-07-18 00:39:39,496 Epoch[19] Batch [870]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.240750,	
2017-07-18 00:39:48,098 Epoch[19] Batch [880]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.241449,	
2017-07-18 00:39:57,126 Epoch[19] Batch [890]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.240619,	
2017-07-18 00:40:06,027 Epoch[19] Batch [900]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.240810,	
2017-07-18 00:40:14,704 Epoch[19] Batch [910]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.240387,	
2017-07-18 00:40:23,499 Epoch[19] Batch [920]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241164,	
2017-07-18 00:40:32,241 Epoch[19] Batch [930]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.241581,	
2017-07-18 00:40:40,930 Epoch[19] Batch [940]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.241630,	
2017-07-18 00:40:49,747 Epoch[19] Batch [950]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.241979,	
2017-07-18 00:40:58,779 Epoch[19] Batch [960]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242347,	
2017-07-18 00:41:07,784 Epoch[19] Batch [970]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242206,	
2017-07-18 00:41:16,755 Epoch[19] Batch [980]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.242002,	
2017-07-18 00:41:25,214 Epoch[19] Batch [990]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.241656,	
2017-07-18 00:41:34,185 Epoch[19] Batch [1000]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.241649,	
2017-07-18 00:41:42,972 Epoch[19] Batch [1010]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241896,	
2017-07-18 00:41:51,859 Epoch[19] Batch [1020]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.242039,	
2017-07-18 00:42:00,494 Epoch[19] Batch [1030]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.242292,	
2017-07-18 00:42:09,329 Epoch[19] Batch [1040]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.242825,	
2017-07-18 00:42:18,219 Epoch[19] Batch [1050]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.242126,	
2017-07-18 00:42:27,120 Epoch[19] Batch [1060]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.242054,	
2017-07-18 00:42:35,837 Epoch[19] Batch [1070]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.241454,	
2017-07-18 00:42:44,957 Epoch[19] Batch [1080]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.242393,	
2017-07-18 00:42:53,879 Epoch[19] Batch [1090]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.242108,	
2017-07-18 00:43:02,714 Epoch[19] Batch [1100]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.242198,	
2017-07-18 00:43:11,528 Epoch[19] Batch [1110]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.241428,	
2017-07-18 00:43:20,074 Epoch[19] Batch [1120]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.241756,	
2017-07-18 00:43:28,886 Epoch[19] Batch [1130]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.242346,	
2017-07-18 00:43:37,555 Epoch[19] Batch [1140]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.241951,	
2017-07-18 00:43:46,526 Epoch[19] Batch [1150]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.242711,	
2017-07-18 00:43:54,998 Epoch[19] Batch [1160]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.243506,	
2017-07-18 00:44:03,713 Epoch[19] Batch [1170]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.243432,	
2017-07-18 00:44:12,479 Epoch[19] Batch [1180]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.242986,	
2017-07-18 00:44:21,335 Epoch[19] Batch [1190]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.242421,	
2017-07-18 00:44:30,200 Epoch[19] Batch [1200]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.243189,	
2017-07-18 00:44:39,173 Epoch[19] Batch [1210]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.243435,	
2017-07-18 00:44:47,927 Epoch[19] Batch [1220]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.243740,	
2017-07-18 00:44:56,497 Epoch[19] Batch [1230]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.243866,	
2017-07-18 00:45:04,962 Epoch[19] Batch [1240]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.243958,	
2017-07-18 00:45:13,181 Epoch[19] Batch [1250]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.243951,	
2017-07-18 00:45:21,904 Epoch[19] Batch [1260]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.245021,	
2017-07-18 00:45:30,737 Epoch[19] Batch [1270]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.244621,	
2017-07-18 00:45:39,410 Epoch[19] Batch [1280]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.244715,	
2017-07-18 00:45:48,061 Epoch[19] Batch [1290]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.244851,	
2017-07-18 00:45:56,905 Epoch[19] Batch [1300]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.244750,	
2017-07-18 00:46:05,368 Epoch[19] Batch [1310]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.244654,	
2017-07-18 00:46:14,191 Epoch[19] Batch [1320]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.244689,	
2017-07-18 00:46:23,247 Epoch[19] Batch [1330]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.243946,	
2017-07-18 00:46:31,973 Epoch[19] Batch [1340]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.243287,	
2017-07-18 00:46:41,023 Epoch[19] Batch [1350]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.244375,	
2017-07-18 00:46:50,046 Epoch[19] Batch [1360]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.244559,	
2017-07-18 00:46:58,838 Epoch[19] Batch [1370]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.244683,	
2017-07-18 00:47:08,767 Epoch[19] Batch [1380]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.244151,	
2017-07-18 00:47:17,956 Epoch[19] Batch [1390]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.243068,	
2017-07-18 00:47:27,134 Epoch[19] Batch [1400]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.243229,	
2017-07-18 00:47:36,108 Epoch[19] Batch [1410]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.242958,	
2017-07-18 00:47:44,908 Epoch[19] Batch [1420]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.243058,	
2017-07-18 00:47:53,914 Epoch[19] Batch [1430]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242661,	
2017-07-18 00:48:02,637 Epoch[19] Batch [1440]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.242307,	
2017-07-18 00:48:11,927 Epoch[19] Batch [1450]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.242735,	
2017-07-18 00:48:20,672 Epoch[19] Batch [1460]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.243225,	
2017-07-18 00:48:29,584 Epoch[19] Batch [1470]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.243182,	
2017-07-18 00:48:38,344 Epoch[19] Batch [1480]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.242683,	
2017-07-18 00:48:43,690 Epoch[19] Train-FCNLogLoss=1.243109
2017-07-18 00:48:43,690 Epoch[19] Time cost=1286.143
2017-07-18 00:48:44,691 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.params"
2017-07-18 00:48:47,310 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.states"
2017-07-18 00:48:57,007 Epoch[20] Batch [10]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.300039,	
2017-07-18 00:49:05,010 Epoch[20] Batch [20]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.227698,	
2017-07-18 00:49:13,085 Epoch[20] Batch [30]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.243302,	
2017-07-18 00:49:21,427 Epoch[20] Batch [40]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.247952,	
2017-07-18 00:49:29,538 Epoch[20] Batch [50]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.254331,	
2017-07-18 00:49:37,987 Epoch[20] Batch [60]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.249035,	
2017-07-18 00:49:46,491 Epoch[20] Batch [70]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.256976,	
2017-07-18 00:49:54,697 Epoch[20] Batch [80]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.266706,	
2017-07-18 00:50:02,961 Epoch[20] Batch [90]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.262147,	
2017-07-18 00:50:11,189 Epoch[20] Batch [100]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.255798,	
2017-07-18 00:50:19,330 Epoch[20] Batch [110]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.248567,	
2017-07-18 00:50:27,519 Epoch[20] Batch [120]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.246005,	
2017-07-18 00:50:35,874 Epoch[20] Batch [130]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.253776,	
2017-07-18 00:50:43,943 Epoch[20] Batch [140]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.256491,	
2017-07-18 00:50:52,466 Epoch[20] Batch [150]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.254924,	
2017-07-18 00:51:01,160 Epoch[20] Batch [160]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.254274,	
2017-07-18 00:51:09,151 Epoch[20] Batch [170]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.261281,	
2017-07-18 00:51:17,035 Epoch[20] Batch [180]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.254809,	
2017-07-18 00:51:24,902 Epoch[20] Batch [190]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.253429,	
2017-07-18 00:51:33,321 Epoch[20] Batch [200]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.248756,	
2017-07-18 00:51:41,487 Epoch[20] Batch [210]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.249204,	
2017-07-18 00:51:50,126 Epoch[20] Batch [220]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.249963,	
2017-07-18 00:51:58,095 Epoch[20] Batch [230]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.254750,	
2017-07-18 00:52:06,689 Epoch[20] Batch [240]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.252905,	
2017-07-18 00:52:14,886 Epoch[20] Batch [250]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.251990,	
2017-07-18 00:52:23,168 Epoch[20] Batch [260]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.253242,	
2017-07-18 00:52:31,363 Epoch[20] Batch [270]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.253034,	
2017-07-18 00:52:39,276 Epoch[20] Batch [280]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.248596,	
2017-07-18 00:52:47,551 Epoch[20] Batch [290]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.249257,	
2017-07-18 00:52:55,699 Epoch[20] Batch [300]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.246569,	
2017-07-18 00:53:03,918 Epoch[20] Batch [310]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.245249,	
2017-07-18 00:53:12,401 Epoch[20] Batch [320]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.243290,	
2017-07-18 00:53:20,746 Epoch[20] Batch [330]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.247988,	
2017-07-18 00:53:29,212 Epoch[20] Batch [340]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.247035,	
2017-07-18 00:53:38,095 Epoch[20] Batch [350]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.245818,	
2017-07-18 00:53:46,591 Epoch[20] Batch [360]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.242935,	
2017-07-18 00:53:55,148 Epoch[20] Batch [370]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.242199,	
2017-07-18 00:54:03,680 Epoch[20] Batch [380]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.246516,	
2017-07-18 00:54:12,538 Epoch[20] Batch [390]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.247647,	
2017-07-18 00:54:21,101 Epoch[20] Batch [400]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.247656,	
2017-07-18 00:54:29,440 Epoch[20] Batch [410]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.246755,	
2017-07-18 00:54:37,676 Epoch[20] Batch [420]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.246957,	
2017-07-18 00:54:46,126 Epoch[20] Batch [430]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.244770,	
2017-07-18 00:54:54,484 Epoch[20] Batch [440]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.246853,	
2017-07-18 00:55:02,765 Epoch[20] Batch [450]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.248093,	
2017-07-18 00:55:11,421 Epoch[20] Batch [460]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.247789,	
2017-07-18 00:55:19,926 Epoch[20] Batch [470]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.245205,	
2017-07-18 00:55:28,445 Epoch[20] Batch [480]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.244291,	
2017-07-18 00:55:36,681 Epoch[20] Batch [490]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.243955,	
2017-07-18 00:55:45,046 Epoch[20] Batch [500]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.243071,	
2017-07-18 00:55:53,315 Epoch[20] Batch [510]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.242057,	
2017-07-18 00:56:01,884 Epoch[20] Batch [520]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.240740,	
2017-07-18 00:56:10,401 Epoch[20] Batch [530]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.240593,	
2017-07-18 00:56:18,577 Epoch[20] Batch [540]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.239910,	
2017-07-18 00:56:27,388 Epoch[20] Batch [550]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.239453,	
2017-07-18 00:56:35,997 Epoch[20] Batch [560]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.238512,	
2017-07-18 00:56:44,708 Epoch[20] Batch [570]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.238634,	
2017-07-18 00:56:53,013 Epoch[20] Batch [580]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.239708,	
2017-07-18 00:57:01,422 Epoch[20] Batch [590]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.238518,	
2017-07-18 00:57:10,454 Epoch[20] Batch [600]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.238253,	
2017-07-18 00:57:19,001 Epoch[20] Batch [610]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.237622,	
2017-07-18 00:57:27,571 Epoch[20] Batch [620]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.238431,	
2017-07-18 00:57:36,316 Epoch[20] Batch [630]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238614,	
2017-07-18 00:57:44,806 Epoch[20] Batch [640]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.238390,	
2017-07-18 00:57:53,566 Epoch[20] Batch [650]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238583,	
2017-07-18 00:58:02,207 Epoch[20] Batch [660]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237616,	
2017-07-18 00:58:10,985 Epoch[20] Batch [670]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.239523,	
2017-07-18 00:58:19,623 Epoch[20] Batch [680]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.241010,	
2017-07-18 00:58:28,381 Epoch[20] Batch [690]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.242081,	
2017-07-18 00:58:37,263 Epoch[20] Batch [700]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.241595,	
2017-07-18 00:58:45,693 Epoch[20] Batch [710]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.240955,	
2017-07-18 00:58:54,604 Epoch[20] Batch [720]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.240224,	
2017-07-18 00:59:03,142 Epoch[20] Batch [730]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.240058,	
2017-07-18 00:59:12,134 Epoch[20] Batch [740]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.240027,	
2017-07-18 00:59:20,956 Epoch[20] Batch [750]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.239562,	
2017-07-18 00:59:29,751 Epoch[20] Batch [760]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.240132,	
2017-07-18 00:59:38,569 Epoch[20] Batch [770]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.240718,	
2017-07-18 00:59:47,520 Epoch[20] Batch [780]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.240088,	
2017-07-18 00:59:56,386 Epoch[20] Batch [790]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.240255,	
2017-07-18 01:00:05,086 Epoch[20] Batch [800]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.240173,	
2017-07-18 01:00:13,958 Epoch[20] Batch [810]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.239289,	
2017-07-18 01:00:22,616 Epoch[20] Batch [820]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239478,	
2017-07-18 01:00:31,083 Epoch[20] Batch [830]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.239887,	
2017-07-18 01:00:40,339 Epoch[20] Batch [840]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.240872,	
2017-07-18 01:00:49,051 Epoch[20] Batch [850]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.242171,	
2017-07-18 01:00:57,846 Epoch[20] Batch [860]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241346,	
2017-07-18 01:01:06,708 Epoch[20] Batch [870]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.241925,	
2017-07-18 01:01:15,322 Epoch[20] Batch [880]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.241583,	
2017-07-18 01:01:24,076 Epoch[20] Batch [890]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.241029,	
2017-07-18 01:01:32,491 Epoch[20] Batch [900]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.241265,	
2017-07-18 01:01:40,955 Epoch[20] Batch [910]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.240424,	
2017-07-18 01:01:49,405 Epoch[20] Batch [920]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.240423,	
2017-07-18 01:01:58,173 Epoch[20] Batch [930]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.240426,	
2017-07-18 01:02:06,879 Epoch[20] Batch [940]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.240768,	
2017-07-18 01:02:15,735 Epoch[20] Batch [950]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.239707,	
2017-07-18 01:02:24,726 Epoch[20] Batch [960]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.239680,	
2017-07-18 01:02:33,445 Epoch[20] Batch [970]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.238900,	
2017-07-18 01:02:42,375 Epoch[20] Batch [980]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.239806,	
2017-07-18 01:02:50,986 Epoch[20] Batch [990]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.240633,	
2017-07-18 01:02:59,906 Epoch[20] Batch [1000]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.240734,	
2017-07-18 01:03:08,917 Epoch[20] Batch [1010]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.241250,	
2017-07-18 01:03:17,639 Epoch[20] Batch [1020]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.242514,	
2017-07-18 01:03:26,237 Epoch[20] Batch [1030]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.242608,	
2017-07-18 01:03:35,316 Epoch[20] Batch [1040]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.242101,	
2017-07-18 01:03:43,983 Epoch[20] Batch [1050]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.241831,	
2017-07-18 01:03:52,769 Epoch[20] Batch [1060]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241810,	
2017-07-18 01:04:01,342 Epoch[20] Batch [1070]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.241527,	
2017-07-18 01:04:09,875 Epoch[20] Batch [1080]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.241728,	
2017-07-18 01:04:18,706 Epoch[20] Batch [1090]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.241709,	
2017-07-18 01:04:27,198 Epoch[20] Batch [1100]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.241409,	
2017-07-18 01:04:35,907 Epoch[20] Batch [1110]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.241131,	
2017-07-18 01:04:44,387 Epoch[20] Batch [1120]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.241951,	
2017-07-18 01:04:53,153 Epoch[20] Batch [1130]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.242163,	
2017-07-18 01:05:02,236 Epoch[20] Batch [1140]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.242365,	
2017-07-18 01:05:10,401 Epoch[20] Batch [1150]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.242663,	
2017-07-18 01:05:19,201 Epoch[20] Batch [1160]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.242619,	
2017-07-18 01:05:28,000 Epoch[20] Batch [1170]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.242290,	
2017-07-18 01:05:37,038 Epoch[20] Batch [1180]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242368,	
2017-07-18 01:05:45,376 Epoch[20] Batch [1190]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.242429,	
2017-07-18 01:05:53,908 Epoch[20] Batch [1200]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.242522,	
2017-07-18 01:06:02,787 Epoch[20] Batch [1210]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.242153,	
2017-07-18 01:06:11,562 Epoch[20] Batch [1220]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.242619,	
2017-07-18 01:06:20,072 Epoch[20] Batch [1230]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.242241,	
2017-07-18 01:06:28,620 Epoch[20] Batch [1240]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.242121,	
2017-07-18 01:06:37,474 Epoch[20] Batch [1250]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.241568,	
2017-07-18 01:06:46,287 Epoch[20] Batch [1260]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.242697,	
2017-07-18 01:06:55,318 Epoch[20] Batch [1270]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242058,	
2017-07-18 01:07:04,187 Epoch[20] Batch [1280]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.241609,	
2017-07-18 01:07:12,834 Epoch[20] Batch [1290]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.240852,	
2017-07-18 01:07:22,318 Epoch[20] Batch [1300]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.241331,	
2017-07-18 01:07:31,848 Epoch[20] Batch [1310]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.240880,	
2017-07-18 01:07:41,649 Epoch[20] Batch [1320]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.241043,	
2017-07-18 01:07:50,149 Epoch[20] Batch [1330]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.240635,	
2017-07-18 01:07:58,766 Epoch[20] Batch [1340]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.240989,	
2017-07-18 01:08:07,475 Epoch[20] Batch [1350]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.240670,	
2017-07-18 01:08:15,900 Epoch[20] Batch [1360]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.240658,	
2017-07-18 01:08:24,265 Epoch[20] Batch [1370]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.240018,	
2017-07-18 01:08:33,234 Epoch[20] Batch [1380]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.239976,	
2017-07-18 01:08:41,838 Epoch[20] Batch [1390]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.239408,	
2017-07-18 01:08:50,559 Epoch[20] Batch [1400]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.239379,	
2017-07-18 01:08:58,894 Epoch[20] Batch [1410]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.239509,	
2017-07-18 01:09:07,550 Epoch[20] Batch [1420]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239317,	
2017-07-18 01:09:16,312 Epoch[20] Batch [1430]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.239742,	
2017-07-18 01:09:25,077 Epoch[20] Batch [1440]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.239771,	
2017-07-18 01:09:34,177 Epoch[20] Batch [1450]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.239583,	
2017-07-18 01:09:42,340 Epoch[20] Batch [1460]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.239236,	
2017-07-18 01:09:51,121 Epoch[20] Batch [1470]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.239041,	
2017-07-18 01:09:59,635 Epoch[20] Batch [1480]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.238740,	
2017-07-18 01:10:04,797 Epoch[20] Train-FCNLogLoss=1.238291
2017-07-18 01:10:04,798 Epoch[20] Time cost=1277.294
2017-07-18 01:10:06,026 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.params"
2017-07-18 01:10:09,174 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.states"
2017-07-18 01:10:19,710 Epoch[21] Batch [10]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.277729,	
2017-07-18 01:10:27,778 Epoch[21] Batch [20]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.227304,	
2017-07-18 01:10:36,358 Epoch[21] Batch [30]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.195871,	
2017-07-18 01:10:44,759 Epoch[21] Batch [40]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.196328,	
2017-07-18 01:10:52,857 Epoch[21] Batch [50]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.213772,	
2017-07-18 01:11:01,628 Epoch[21] Batch [60]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.228718,	
2017-07-18 01:11:09,688 Epoch[21] Batch [70]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.221636,	
2017-07-18 01:11:17,991 Epoch[21] Batch [80]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.219335,	
2017-07-18 01:11:26,176 Epoch[21] Batch [90]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.217847,	
2017-07-18 01:11:34,784 Epoch[21] Batch [100]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.225830,	
2017-07-18 01:11:43,242 Epoch[21] Batch [110]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.227831,	
2017-07-18 01:11:51,073 Epoch[21] Batch [120]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.222688,	
2017-07-18 01:11:59,795 Epoch[21] Batch [130]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.235056,	
2017-07-18 01:12:07,777 Epoch[21] Batch [140]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.238404,	
2017-07-18 01:12:16,581 Epoch[21] Batch [150]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.235285,	
2017-07-18 01:12:25,011 Epoch[21] Batch [160]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.236191,	
2017-07-18 01:12:33,241 Epoch[21] Batch [170]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.234678,	
2017-07-18 01:12:41,408 Epoch[21] Batch [180]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.230577,	
2017-07-18 01:12:49,902 Epoch[21] Batch [190]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.235561,	
2017-07-18 01:12:58,642 Epoch[21] Batch [200]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236382,	
2017-07-18 01:13:06,592 Epoch[21] Batch [210]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.235909,	
2017-07-18 01:13:14,914 Epoch[21] Batch [220]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.240197,	
2017-07-18 01:13:23,359 Epoch[21] Batch [230]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.237735,	
2017-07-18 01:13:31,568 Epoch[21] Batch [240]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.238688,	
2017-07-18 01:13:39,924 Epoch[21] Batch [250]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.242624,	
2017-07-18 01:13:48,217 Epoch[21] Batch [260]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.242923,	
2017-07-18 01:13:56,478 Epoch[21] Batch [270]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.241888,	
2017-07-18 01:14:04,694 Epoch[21] Batch [280]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.239689,	
2017-07-18 01:14:13,284 Epoch[21] Batch [290]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.238691,	
2017-07-18 01:14:22,011 Epoch[21] Batch [300]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.238874,	
2017-07-18 01:14:30,836 Epoch[21] Batch [310]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.237001,	
2017-07-18 01:14:39,283 Epoch[21] Batch [320]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.238199,	
2017-07-18 01:14:47,988 Epoch[21] Batch [330]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.235726,	
2017-07-18 01:14:56,534 Epoch[21] Batch [340]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.236404,	
2017-07-18 01:15:05,160 Epoch[21] Batch [350]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.235367,	
2017-07-18 01:15:13,870 Epoch[21] Batch [360]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.237004,	
2017-07-18 01:15:22,309 Epoch[21] Batch [370]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.233793,	
2017-07-18 01:15:30,986 Epoch[21] Batch [380]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.234388,	
2017-07-18 01:15:39,959 Epoch[21] Batch [390]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.235138,	
2017-07-18 01:15:48,438 Epoch[21] Batch [400]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.235195,	
2017-07-18 01:15:57,121 Epoch[21] Batch [410]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.235337,	
2017-07-18 01:16:05,703 Epoch[21] Batch [420]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.233447,	
2017-07-18 01:16:14,754 Epoch[21] Batch [430]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.235614,	
2017-07-18 01:16:23,513 Epoch[21] Batch [440]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.237049,	
2017-07-18 01:16:32,501 Epoch[21] Batch [450]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.237518,	
2017-07-18 01:16:41,341 Epoch[21] Batch [460]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.237395,	
2017-07-18 01:16:50,136 Epoch[21] Batch [470]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.237320,	
2017-07-18 01:16:58,937 Epoch[21] Batch [480]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.235625,	
2017-07-18 01:17:07,153 Epoch[21] Batch [490]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.235602,	
2017-07-18 01:17:15,534 Epoch[21] Batch [500]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.235315,	
2017-07-18 01:17:24,137 Epoch[21] Batch [510]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.236271,	
2017-07-18 01:17:32,600 Epoch[21] Batch [520]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.235628,	
2017-07-18 01:17:41,204 Epoch[21] Batch [530]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.237109,	
2017-07-18 01:17:49,152 Epoch[21] Batch [540]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.237668,	
2017-07-18 01:17:57,533 Epoch[21] Batch [550]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.238217,	
2017-07-18 01:18:05,605 Epoch[21] Batch [560]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.237018,	
2017-07-18 01:18:13,767 Epoch[21] Batch [570]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.239167,	
2017-07-18 01:18:21,894 Epoch[21] Batch [580]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.237429,	
2017-07-18 01:18:30,228 Epoch[21] Batch [590]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.238741,	
2017-07-18 01:18:38,569 Epoch[21] Batch [600]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.239792,	
2017-07-18 01:18:47,301 Epoch[21] Batch [610]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.241832,	
2017-07-18 01:18:55,490 Epoch[21] Batch [620]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.241288,	
2017-07-18 01:19:03,785 Epoch[21] Batch [630]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.240988,	
2017-07-18 01:19:12,524 Epoch[21] Batch [640]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.240261,	
2017-07-18 01:19:21,278 Epoch[21] Batch [650]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238975,	
2017-07-18 01:19:29,845 Epoch[21] Batch [660]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.237776,	
2017-07-18 01:19:38,452 Epoch[21] Batch [670]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.238048,	
2017-07-18 01:19:46,836 Epoch[21] Batch [680]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.238309,	
2017-07-18 01:19:55,337 Epoch[21] Batch [690]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.236869,	
2017-07-18 01:20:03,763 Epoch[21] Batch [700]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.236924,	
2017-07-18 01:20:12,276 Epoch[21] Batch [710]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.235707,	
2017-07-18 01:20:20,793 Epoch[21] Batch [720]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.234301,	
2017-07-18 01:20:29,597 Epoch[21] Batch [730]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.235136,	
2017-07-18 01:20:38,014 Epoch[21] Batch [740]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.236026,	
2017-07-18 01:20:46,442 Epoch[21] Batch [750]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.236677,	
2017-07-18 01:20:54,904 Epoch[21] Batch [760]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.237001,	
2017-07-18 01:21:06,084 Epoch[21] Batch [770]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.237725,	
2017-07-18 01:21:14,830 Epoch[21] Batch [780]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.237289,	
2017-07-18 01:21:23,197 Epoch[21] Batch [790]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.236265,	
2017-07-18 01:21:31,676 Epoch[21] Batch [800]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.237696,	
2017-07-18 01:21:40,116 Epoch[21] Batch [810]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.237668,	
2017-07-18 01:21:48,758 Epoch[21] Batch [820]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237367,	
2017-07-18 01:21:57,546 Epoch[21] Batch [830]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.238259,	
2017-07-18 01:22:06,473 Epoch[21] Batch [840]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.240628,	
2017-07-18 01:22:14,985 Epoch[21] Batch [850]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.239410,	
2017-07-18 01:22:23,478 Epoch[21] Batch [860]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.239592,	
2017-07-18 01:22:31,715 Epoch[21] Batch [870]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.239559,	
2017-07-18 01:22:40,457 Epoch[21] Batch [880]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.239825,	
2017-07-18 01:22:49,314 Epoch[21] Batch [890]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.240737,	
2017-07-18 01:22:58,115 Epoch[21] Batch [900]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.240511,	
2017-07-18 01:23:06,628 Epoch[21] Batch [910]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.241730,	
2017-07-18 01:23:15,131 Epoch[21] Batch [920]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.240841,	
2017-07-18 01:23:24,115 Epoch[21] Batch [930]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.240474,	
2017-07-18 01:23:32,630 Epoch[21] Batch [940]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.240579,	
2017-07-18 01:23:40,740 Epoch[21] Batch [950]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.240298,	
2017-07-18 01:23:49,424 Epoch[21] Batch [960]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.240462,	
2017-07-18 01:23:58,025 Epoch[21] Batch [970]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.240193,	
2017-07-18 01:24:06,222 Epoch[21] Batch [980]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.240232,	
2017-07-18 01:24:14,812 Epoch[21] Batch [990]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.240122,	
2017-07-18 01:24:23,407 Epoch[21] Batch [1000]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.240257,	
2017-07-18 01:24:32,060 Epoch[21] Batch [1010]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239305,	
2017-07-18 01:24:41,013 Epoch[21] Batch [1020]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.239035,	
2017-07-18 01:24:49,362 Epoch[21] Batch [1030]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.238813,	
2017-07-18 01:24:58,239 Epoch[21] Batch [1040]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.238932,	
2017-07-18 01:25:06,902 Epoch[21] Batch [1050]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.238172,	
2017-07-18 01:25:15,310 Epoch[21] Batch [1060]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.238072,	
2017-07-18 01:25:23,549 Epoch[21] Batch [1070]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.238263,	
2017-07-18 01:25:32,059 Epoch[21] Batch [1080]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.237399,	
2017-07-18 01:25:41,157 Epoch[21] Batch [1090]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.237575,	
2017-07-18 01:25:49,870 Epoch[21] Batch [1100]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.238096,	
2017-07-18 01:25:58,657 Epoch[21] Batch [1110]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.237963,	
2017-07-18 01:26:07,692 Epoch[21] Batch [1120]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.237756,	
2017-07-18 01:26:16,638 Epoch[21] Batch [1130]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.237412,	
2017-07-18 01:26:25,310 Epoch[21] Batch [1140]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.237612,	
2017-07-18 01:26:34,343 Epoch[21] Batch [1150]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.237574,	
2017-07-18 01:26:43,407 Epoch[21] Batch [1160]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.236796,	
2017-07-18 01:26:51,923 Epoch[21] Batch [1170]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.236698,	
2017-07-18 01:27:00,661 Epoch[21] Batch [1180]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236598,	
2017-07-18 01:27:09,584 Epoch[21] Batch [1190]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.237386,	
2017-07-18 01:27:18,788 Epoch[21] Batch [1200]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.236602,	
2017-07-18 01:27:27,434 Epoch[21] Batch [1210]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.236946,	
2017-07-18 01:27:36,258 Epoch[21] Batch [1220]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.237418,	
2017-07-18 01:27:44,837 Epoch[21] Batch [1230]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.236639,	
2017-07-18 01:27:53,365 Epoch[21] Batch [1240]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.236358,	
2017-07-18 01:28:02,145 Epoch[21] Batch [1250]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.236100,	
2017-07-18 01:28:10,604 Epoch[21] Batch [1260]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.236060,	
2017-07-18 01:28:19,688 Epoch[21] Batch [1270]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.236621,	
2017-07-18 01:28:28,163 Epoch[21] Batch [1280]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.237016,	
2017-07-18 01:28:36,840 Epoch[21] Batch [1290]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.237432,	
2017-07-18 01:28:45,535 Epoch[21] Batch [1300]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.237534,	
2017-07-18 01:28:54,089 Epoch[21] Batch [1310]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.237821,	
2017-07-18 01:29:02,732 Epoch[21] Batch [1320]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.238699,	
2017-07-18 01:29:11,552 Epoch[21] Batch [1330]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.238973,	
2017-07-18 01:29:20,084 Epoch[21] Batch [1340]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.238950,	
2017-07-18 01:29:28,902 Epoch[21] Batch [1350]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.238618,	
2017-07-18 01:29:37,809 Epoch[21] Batch [1360]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.238541,	
2017-07-18 01:29:46,446 Epoch[21] Batch [1370]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237852,	
2017-07-18 01:29:55,433 Epoch[21] Batch [1380]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.238779,	
2017-07-18 01:30:03,855 Epoch[21] Batch [1390]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.238582,	
2017-07-18 01:30:13,081 Epoch[21] Batch [1400]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.238251,	
2017-07-18 01:30:22,079 Epoch[21] Batch [1410]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.238639,	
2017-07-18 01:30:30,744 Epoch[21] Batch [1420]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239021,	
2017-07-18 01:30:39,391 Epoch[21] Batch [1430]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.239889,	
2017-07-18 01:30:48,367 Epoch[21] Batch [1440]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.239651,	
2017-07-18 01:30:57,417 Epoch[21] Batch [1450]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.240082,	
2017-07-18 01:31:06,143 Epoch[21] Batch [1460]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.240143,	
2017-07-18 01:31:14,858 Epoch[21] Batch [1470]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.240140,	
2017-07-18 01:31:23,811 Epoch[21] Batch [1480]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.240955,	
2017-07-18 01:31:29,230 Epoch[21] Train-FCNLogLoss=1.240283
2017-07-18 01:31:29,231 Epoch[21] Time cost=1279.852
2017-07-18 01:31:30,197 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.params"
2017-07-18 01:31:33,356 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.states"
2017-07-18 01:31:43,945 Epoch[22] Batch [10]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.256882,	
2017-07-18 01:31:52,292 Epoch[22] Batch [20]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.257360,	
2017-07-18 01:32:00,935 Epoch[22] Batch [30]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.260394,	
2017-07-18 01:32:09,201 Epoch[22] Batch [40]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.247540,	
2017-07-18 01:32:17,615 Epoch[22] Batch [50]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.245090,	
2017-07-18 01:32:25,876 Epoch[22] Batch [60]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.258950,	
2017-07-18 01:32:34,155 Epoch[22] Batch [70]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.249368,	
2017-07-18 01:32:42,462 Epoch[22] Batch [80]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.241253,	
2017-07-18 01:32:51,329 Epoch[22] Batch [90]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.251729,	
2017-07-18 01:32:59,548 Epoch[22] Batch [100]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.254639,	
2017-07-18 01:33:07,458 Epoch[22] Batch [110]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.244868,	
2017-07-18 01:33:15,534 Epoch[22] Batch [120]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.248674,	
2017-07-18 01:33:23,974 Epoch[22] Batch [130]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.241208,	
2017-07-18 01:33:32,426 Epoch[22] Batch [140]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.242584,	
2017-07-18 01:33:40,325 Epoch[22] Batch [150]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.236760,	
2017-07-18 01:33:48,395 Epoch[22] Batch [160]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.234894,	
2017-07-18 01:33:56,813 Epoch[22] Batch [170]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.232043,	
2017-07-18 01:34:05,443 Epoch[22] Batch [180]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.227952,	
2017-07-18 01:34:14,294 Epoch[22] Batch [190]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.227239,	
2017-07-18 01:34:22,427 Epoch[22] Batch [200]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.224468,	
2017-07-18 01:34:31,129 Epoch[22] Batch [210]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.225813,	
2017-07-18 01:34:39,642 Epoch[22] Batch [220]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.224321,	
2017-07-18 01:34:47,950 Epoch[22] Batch [230]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.223263,	
2017-07-18 01:34:56,195 Epoch[22] Batch [240]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.224393,	
2017-07-18 01:35:04,454 Epoch[22] Batch [250]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.227457,	
2017-07-18 01:35:12,745 Epoch[22] Batch [260]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.227928,	
2017-07-18 01:35:20,982 Epoch[22] Batch [270]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.225807,	
2017-07-18 01:35:29,334 Epoch[22] Batch [280]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.222794,	
2017-07-18 01:35:37,677 Epoch[22] Batch [290]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.222879,	
2017-07-18 01:35:46,121 Epoch[22] Batch [300]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.222982,	
2017-07-18 01:35:54,632 Epoch[22] Batch [310]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.221661,	
2017-07-18 01:36:03,049 Epoch[22] Batch [320]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.224419,	
2017-07-18 01:36:11,796 Epoch[22] Batch [330]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.226540,	
2017-07-18 01:36:20,129 Epoch[22] Batch [340]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.229825,	
2017-07-18 01:36:28,636 Epoch[22] Batch [350]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.230820,	
2017-07-18 01:36:37,277 Epoch[22] Batch [360]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.233880,	
2017-07-18 01:36:45,747 Epoch[22] Batch [370]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.234039,	
2017-07-18 01:36:54,190 Epoch[22] Batch [380]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.233149,	
2017-07-18 01:37:02,758 Epoch[22] Batch [390]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.231448,	
2017-07-18 01:37:10,975 Epoch[22] Batch [400]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.231891,	
2017-07-18 01:37:19,425 Epoch[22] Batch [410]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.232796,	
2017-07-18 01:37:27,906 Epoch[22] Batch [420]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.231156,	
2017-07-18 01:37:36,086 Epoch[22] Batch [430]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.231177,	
2017-07-18 01:37:44,852 Epoch[22] Batch [440]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.230244,	
2017-07-18 01:37:53,610 Epoch[22] Batch [450]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.229768,	
2017-07-18 01:38:02,090 Epoch[22] Batch [460]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.228623,	
2017-07-18 01:38:10,755 Epoch[22] Batch [470]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.227996,	
2017-07-18 01:38:19,655 Epoch[22] Batch [480]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.227215,	
2017-07-18 01:38:28,302 Epoch[22] Batch [490]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.227044,	
2017-07-18 01:38:37,076 Epoch[22] Batch [500]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.227863,	
2017-07-18 01:38:45,299 Epoch[22] Batch [510]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.230365,	
2017-07-18 01:38:53,856 Epoch[22] Batch [520]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.231929,	
2017-07-18 01:39:02,257 Epoch[22] Batch [530]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.232566,	
2017-07-18 01:39:11,195 Epoch[22] Batch [540]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.232708,	
2017-07-18 01:39:20,074 Epoch[22] Batch [550]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.233377,	
2017-07-18 01:39:28,826 Epoch[22] Batch [560]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.234104,	
2017-07-18 01:39:37,582 Epoch[22] Batch [570]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.234013,	
2017-07-18 01:39:46,141 Epoch[22] Batch [580]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.235060,	
2017-07-18 01:39:55,220 Epoch[22] Batch [590]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.235185,	
2017-07-18 01:40:03,659 Epoch[22] Batch [600]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.234599,	
2017-07-18 01:40:12,268 Epoch[22] Batch [610]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.234496,	
2017-07-18 01:40:20,813 Epoch[22] Batch [620]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.234122,	
2017-07-18 01:40:29,510 Epoch[22] Batch [630]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.233767,	
2017-07-18 01:40:38,103 Epoch[22] Batch [640]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.232548,	
2017-07-18 01:40:46,815 Epoch[22] Batch [650]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.232666,	
2017-07-18 01:40:55,562 Epoch[22] Batch [660]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.232857,	
2017-07-18 01:41:04,432 Epoch[22] Batch [670]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.231246,	
2017-07-18 01:41:13,058 Epoch[22] Batch [680]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.229751,	
2017-07-18 01:41:21,473 Epoch[22] Batch [690]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.229832,	
2017-07-18 01:41:29,512 Epoch[22] Batch [700]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.229375,	
2017-07-18 01:41:37,161 Epoch[22] Batch [710]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.228329,	
2017-07-18 01:41:45,065 Epoch[22] Batch [720]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.229746,	
2017-07-18 01:41:52,923 Epoch[22] Batch [730]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.228915,	
2017-07-18 01:42:00,434 Epoch[22] Batch [740]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.228700,	
2017-07-18 01:42:08,098 Epoch[22] Batch [750]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.228492,	
2017-07-18 01:42:16,211 Epoch[22] Batch [760]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.229349,	
2017-07-18 01:42:24,301 Epoch[22] Batch [770]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.228284,	
2017-07-18 01:42:32,593 Epoch[22] Batch [780]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.228159,	
2017-07-18 01:42:40,739 Epoch[22] Batch [790]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.228096,	
2017-07-18 01:42:49,264 Epoch[22] Batch [800]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.228162,	
2017-07-18 01:42:57,585 Epoch[22] Batch [810]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.227795,	
2017-07-18 01:43:06,226 Epoch[22] Batch [820]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.228393,	
2017-07-18 01:43:14,705 Epoch[22] Batch [830]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.228139,	
2017-07-18 01:43:22,668 Epoch[22] Batch [840]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.229431,	
2017-07-18 01:43:31,077 Epoch[22] Batch [850]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.229288,	
2017-07-18 01:43:39,379 Epoch[22] Batch [860]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.230178,	
2017-07-18 01:43:47,416 Epoch[22] Batch [870]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.230408,	
2017-07-18 01:43:55,438 Epoch[22] Batch [880]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.230770,	
2017-07-18 01:44:03,573 Epoch[22] Batch [890]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.231504,	
2017-07-18 01:44:11,740 Epoch[22] Batch [900]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.230938,	
2017-07-18 01:44:19,865 Epoch[22] Batch [910]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.231552,	
2017-07-18 01:44:27,793 Epoch[22] Batch [920]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.231047,	
2017-07-18 01:44:35,888 Epoch[22] Batch [930]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.231113,	
2017-07-18 01:44:43,944 Epoch[22] Batch [940]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.231001,	
2017-07-18 01:44:51,872 Epoch[22] Batch [950]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.231773,	
2017-07-18 01:45:00,097 Epoch[22] Batch [960]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.232307,	
2017-07-18 01:45:07,916 Epoch[22] Batch [970]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.233039,	
2017-07-18 01:45:16,079 Epoch[22] Batch [980]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.232834,	
2017-07-18 01:45:24,131 Epoch[22] Batch [990]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.232768,	
2017-07-18 01:45:32,322 Epoch[22] Batch [1000]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.232992,	
2017-07-18 01:45:40,748 Epoch[22] Batch [1010]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.232798,	
2017-07-18 01:45:48,737 Epoch[22] Batch [1020]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.233262,	
2017-07-18 01:45:56,981 Epoch[22] Batch [1030]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.233616,	
2017-07-18 01:46:04,490 Epoch[22] Batch [1040]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.233522,	
2017-07-18 01:46:12,194 Epoch[22] Batch [1050]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.233668,	
2017-07-18 01:46:20,556 Epoch[22] Batch [1060]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.234042,	
2017-07-18 01:46:28,365 Epoch[22] Batch [1070]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.233421,	
2017-07-18 01:46:36,822 Epoch[22] Batch [1080]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.233681,	
2017-07-18 01:46:44,860 Epoch[22] Batch [1090]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.234394,	
2017-07-18 01:46:53,130 Epoch[22] Batch [1100]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.233679,	
2017-07-18 01:47:01,190 Epoch[22] Batch [1110]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.232370,	
2017-07-18 01:47:09,371 Epoch[22] Batch [1120]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.231826,	
2017-07-18 01:47:17,310 Epoch[22] Batch [1130]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.232403,	
2017-07-18 01:47:25,450 Epoch[22] Batch [1140]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.232584,	
2017-07-18 01:47:34,021 Epoch[22] Batch [1150]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.233151,	
2017-07-18 01:47:42,177 Epoch[22] Batch [1160]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.234084,	
2017-07-18 01:47:50,400 Epoch[22] Batch [1170]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.233919,	
2017-07-18 01:47:58,651 Epoch[22] Batch [1180]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.234635,	
2017-07-18 01:48:06,634 Epoch[22] Batch [1190]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.234807,	
2017-07-18 01:48:14,637 Epoch[22] Batch [1200]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.234567,	
2017-07-18 01:48:22,431 Epoch[22] Batch [1210]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.235351,	
2017-07-18 01:48:30,163 Epoch[22] Batch [1220]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.235335,	
2017-07-18 01:48:38,132 Epoch[22] Batch [1230]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.235105,	
2017-07-18 01:48:46,153 Epoch[22] Batch [1240]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.235612,	
2017-07-18 01:48:54,108 Epoch[22] Batch [1250]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.235252,	
2017-07-18 01:49:02,211 Epoch[22] Batch [1260]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.235885,	
2017-07-18 01:49:10,317 Epoch[22] Batch [1270]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.236167,	
2017-07-18 01:49:18,449 Epoch[22] Batch [1280]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.236258,	
2017-07-18 01:49:26,509 Epoch[22] Batch [1290]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.236363,	
2017-07-18 01:49:34,655 Epoch[22] Batch [1300]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.236494,	
2017-07-18 01:49:42,419 Epoch[22] Batch [1310]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.236946,	
2017-07-18 01:49:50,538 Epoch[22] Batch [1320]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.236923,	
2017-07-18 01:49:58,747 Epoch[22] Batch [1330]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.236726,	
2017-07-18 01:50:06,871 Epoch[22] Batch [1340]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.237612,	
2017-07-18 01:50:15,152 Epoch[22] Batch [1350]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.237716,	
2017-07-18 01:50:23,059 Epoch[22] Batch [1360]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.237707,	
2017-07-18 01:50:31,311 Epoch[22] Batch [1370]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.238373,	
2017-07-18 01:50:39,614 Epoch[22] Batch [1380]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.238173,	
2017-07-18 01:50:47,639 Epoch[22] Batch [1390]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.238556,	
2017-07-18 01:50:55,790 Epoch[22] Batch [1400]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.238261,	
2017-07-18 01:51:03,805 Epoch[22] Batch [1410]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.237582,	
2017-07-18 01:51:12,210 Epoch[22] Batch [1420]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.237422,	
2017-07-18 01:51:20,722 Epoch[22] Batch [1430]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.237626,	
2017-07-18 01:51:28,662 Epoch[22] Batch [1440]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.237968,	
2017-07-18 01:51:36,577 Epoch[22] Batch [1450]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.238280,	
2017-07-18 01:51:44,593 Epoch[22] Batch [1460]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.237671,	
2017-07-18 01:51:52,376 Epoch[22] Batch [1470]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.238824,	
2017-07-18 01:52:00,342 Epoch[22] Batch [1480]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.238406,	
2017-07-18 01:52:05,329 Epoch[22] Train-FCNLogLoss=1.238347
2017-07-18 01:52:05,330 Epoch[22] Time cost=1231.633
2017-07-18 01:52:06,590 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.params"
2017-07-18 01:52:10,517 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.states"
2017-07-18 01:52:19,864 Epoch[23] Batch [10]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.206508,	
2017-07-18 01:52:28,281 Epoch[23] Batch [20]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.218942,	
2017-07-18 01:52:36,715 Epoch[23] Batch [30]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.229721,	
2017-07-18 01:52:45,249 Epoch[23] Batch [40]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.222812,	
2017-07-18 01:52:53,493 Epoch[23] Batch [50]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.225710,	
2017-07-18 01:53:01,471 Epoch[23] Batch [60]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.235171,	
2017-07-18 01:53:09,843 Epoch[23] Batch [70]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.246683,	
2017-07-18 01:53:18,133 Epoch[23] Batch [80]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.233925,	
2017-07-18 01:53:26,474 Epoch[23] Batch [90]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.230567,	
2017-07-18 01:53:34,765 Epoch[23] Batch [100]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.240315,	
2017-07-18 01:53:43,321 Epoch[23] Batch [110]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.243165,	
2017-07-18 01:53:51,649 Epoch[23] Batch [120]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.236480,	
2017-07-18 01:54:00,584 Epoch[23] Batch [130]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.230147,	
2017-07-18 01:54:08,898 Epoch[23] Batch [140]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.233957,	
2017-07-18 01:54:17,183 Epoch[23] Batch [150]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.231363,	
2017-07-18 01:54:25,548 Epoch[23] Batch [160]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.242523,	
2017-07-18 01:54:34,323 Epoch[23] Batch [170]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.240820,	
2017-07-18 01:54:42,892 Epoch[23] Batch [180]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.232961,	
2017-07-18 01:54:51,300 Epoch[23] Batch [190]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.235834,	
2017-07-18 01:54:59,695 Epoch[23] Batch [200]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.234317,	
2017-07-18 01:55:08,161 Epoch[23] Batch [210]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.229246,	
2017-07-18 01:55:16,421 Epoch[23] Batch [220]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.224672,	
2017-07-18 01:55:24,520 Epoch[23] Batch [230]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.228184,	
2017-07-18 01:55:33,057 Epoch[23] Batch [240]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.228698,	
2017-07-18 01:55:41,440 Epoch[23] Batch [250]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.231486,	
2017-07-18 01:55:49,694 Epoch[23] Batch [260]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.231840,	
2017-07-18 01:55:57,933 Epoch[23] Batch [270]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.231736,	
2017-07-18 01:56:06,056 Epoch[23] Batch [280]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.231052,	
2017-07-18 01:56:14,452 Epoch[23] Batch [290]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.226940,	
2017-07-18 01:56:22,711 Epoch[23] Batch [300]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.228447,	
2017-07-18 01:56:31,243 Epoch[23] Batch [310]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.229011,	
2017-07-18 01:56:39,899 Epoch[23] Batch [320]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.229244,	
2017-07-18 01:56:48,171 Epoch[23] Batch [330]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.228169,	
2017-07-18 01:56:56,646 Epoch[23] Batch [340]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.228385,	
2017-07-18 01:57:05,322 Epoch[23] Batch [350]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.231532,	
2017-07-18 01:57:13,705 Epoch[23] Batch [360]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.230733,	
2017-07-18 01:57:21,819 Epoch[23] Batch [370]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.229991,	
2017-07-18 01:57:30,142 Epoch[23] Batch [380]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.230435,	
2017-07-18 01:57:38,552 Epoch[23] Batch [390]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.228391,	
2017-07-18 01:57:47,038 Epoch[23] Batch [400]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.227626,	
2017-07-18 01:57:55,408 Epoch[23] Batch [410]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.232699,	
2017-07-18 01:58:03,649 Epoch[23] Batch [420]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.232999,	
2017-07-18 01:58:11,894 Epoch[23] Batch [430]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.232270,	
2017-07-18 01:58:19,938 Epoch[23] Batch [440]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.233975,	
2017-07-18 01:58:28,280 Epoch[23] Batch [450]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.236099,	
2017-07-18 01:58:36,716 Epoch[23] Batch [460]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.237648,	
2017-07-18 01:58:45,502 Epoch[23] Batch [470]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.238405,	
2017-07-18 01:58:53,705 Epoch[23] Batch [480]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.240129,	
2017-07-18 01:59:02,151 Epoch[23] Batch [490]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.239609,	
2017-07-18 01:59:10,671 Epoch[23] Batch [500]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.240645,	
2017-07-18 01:59:19,184 Epoch[23] Batch [510]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.240800,	
2017-07-18 01:59:27,211 Epoch[23] Batch [520]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.239686,	
2017-07-18 01:59:35,985 Epoch[23] Batch [530]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.241545,	
2017-07-18 01:59:44,685 Epoch[23] Batch [540]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.240246,	
2017-07-18 01:59:53,382 Epoch[23] Batch [550]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.240200,	
2017-07-18 02:00:01,819 Epoch[23] Batch [560]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.240781,	
2017-07-18 02:00:10,716 Epoch[23] Batch [570]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.240288,	
2017-07-18 02:00:19,160 Epoch[23] Batch [580]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.242207,	
2017-07-18 02:00:27,545 Epoch[23] Batch [590]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.240408,	
2017-07-18 02:00:36,324 Epoch[23] Batch [600]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.238795,	
2017-07-18 02:00:45,180 Epoch[23] Batch [610]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.239825,	
2017-07-18 02:00:53,882 Epoch[23] Batch [620]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.240234,	
2017-07-18 02:01:02,496 Epoch[23] Batch [630]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.238717,	
2017-07-18 02:01:10,753 Epoch[23] Batch [640]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.237899,	
2017-07-18 02:01:19,206 Epoch[23] Batch [650]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.237400,	
2017-07-18 02:01:27,315 Epoch[23] Batch [660]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.237173,	
2017-07-18 02:01:35,751 Epoch[23] Batch [670]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.236074,	
2017-07-18 02:01:44,243 Epoch[23] Batch [680]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.236839,	
2017-07-18 02:01:52,262 Epoch[23] Batch [690]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.236508,	
2017-07-18 02:02:00,606 Epoch[23] Batch [700]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.236226,	
2017-07-18 02:02:09,137 Epoch[23] Batch [710]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.236731,	
2017-07-18 02:02:17,560 Epoch[23] Batch [720]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.236645,	
2017-07-18 02:02:25,960 Epoch[23] Batch [730]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.236854,	
2017-07-18 02:02:34,623 Epoch[23] Batch [740]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.236946,	
2017-07-18 02:02:42,935 Epoch[23] Batch [750]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.237784,	
2017-07-18 02:02:51,644 Epoch[23] Batch [760]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.238178,	
2017-07-18 02:03:00,498 Epoch[23] Batch [770]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.237304,	
2017-07-18 02:03:09,127 Epoch[23] Batch [780]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.238144,	
2017-07-18 02:03:17,976 Epoch[23] Batch [790]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.239168,	
2017-07-18 02:03:26,391 Epoch[23] Batch [800]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.239121,	
2017-07-18 02:03:34,709 Epoch[23] Batch [810]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.239798,	
2017-07-18 02:03:42,903 Epoch[23] Batch [820]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.238943,	
2017-07-18 02:03:51,611 Epoch[23] Batch [830]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.239337,	
2017-07-18 02:03:59,837 Epoch[23] Batch [840]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.239279,	
2017-07-18 02:04:08,539 Epoch[23] Batch [850]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.240908,	
2017-07-18 02:04:17,217 Epoch[23] Batch [860]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.240786,	
2017-07-18 02:04:25,894 Epoch[23] Batch [870]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.240253,	
2017-07-18 02:04:34,527 Epoch[23] Batch [880]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.241801,	
2017-07-18 02:04:43,354 Epoch[23] Batch [890]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.241400,	
2017-07-18 02:04:52,143 Epoch[23] Batch [900]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.240950,	
2017-07-18 02:05:00,930 Epoch[23] Batch [910]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241342,	
2017-07-18 02:05:09,705 Epoch[23] Batch [920]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.241194,	
2017-07-18 02:05:18,354 Epoch[23] Batch [930]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.241646,	
2017-07-18 02:05:26,988 Epoch[23] Batch [940]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.241192,	
2017-07-18 02:05:35,833 Epoch[23] Batch [950]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.242054,	
2017-07-18 02:05:44,203 Epoch[23] Batch [960]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.241700,	
2017-07-18 02:05:52,920 Epoch[23] Batch [970]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.241753,	
2017-07-18 02:06:01,518 Epoch[23] Batch [980]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.241905,	
2017-07-18 02:06:10,267 Epoch[23] Batch [990]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.242232,	
2017-07-18 02:06:18,965 Epoch[23] Batch [1000]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.242248,	
2017-07-18 02:06:27,545 Epoch[23] Batch [1010]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.241904,	
2017-07-18 02:06:36,206 Epoch[23] Batch [1020]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.242339,	
2017-07-18 02:06:45,171 Epoch[23] Batch [1030]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.243271,	
2017-07-18 02:06:53,830 Epoch[23] Batch [1040]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.243457,	
2017-07-18 02:07:02,781 Epoch[23] Batch [1050]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.242299,	
2017-07-18 02:07:11,505 Epoch[23] Batch [1060]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.242062,	
2017-07-18 02:07:20,221 Epoch[23] Batch [1070]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.242784,	
2017-07-18 02:07:29,147 Epoch[23] Batch [1080]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.244329,	
2017-07-18 02:07:38,037 Epoch[23] Batch [1090]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.245097,	
2017-07-18 02:07:47,229 Epoch[23] Batch [1100]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.245542,	
2017-07-18 02:07:56,289 Epoch[23] Batch [1110]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.246395,	
2017-07-18 02:08:05,391 Epoch[23] Batch [1120]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.245878,	
2017-07-18 02:08:14,396 Epoch[23] Batch [1130]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.246086,	
2017-07-18 02:08:23,531 Epoch[23] Batch [1140]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.246464,	
2017-07-18 02:08:32,260 Epoch[23] Batch [1150]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.246335,	
2017-07-18 02:08:40,634 Epoch[23] Batch [1160]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.245963,	
2017-07-18 02:08:49,470 Epoch[23] Batch [1170]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.246379,	
2017-07-18 02:08:58,540 Epoch[23] Batch [1180]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.245383,	
2017-07-18 02:09:07,663 Epoch[23] Batch [1190]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.245717,	
2017-07-18 02:09:16,541 Epoch[23] Batch [1200]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.245191,	
2017-07-18 02:09:25,275 Epoch[23] Batch [1210]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.245325,	
2017-07-18 02:09:34,228 Epoch[23] Batch [1220]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.244854,	
2017-07-18 02:09:43,076 Epoch[23] Batch [1230]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.244975,	
2017-07-18 02:09:51,647 Epoch[23] Batch [1240]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.245513,	
2017-07-18 02:10:00,383 Epoch[23] Batch [1250]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.245579,	
2017-07-18 02:10:09,218 Epoch[23] Batch [1260]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.245366,	
2017-07-18 02:10:18,513 Epoch[23] Batch [1270]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.245268,	
2017-07-18 02:10:27,610 Epoch[23] Batch [1280]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.245003,	
2017-07-18 02:10:36,535 Epoch[23] Batch [1290]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.245289,	
2017-07-18 02:10:45,590 Epoch[23] Batch [1300]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.244873,	
2017-07-18 02:10:54,685 Epoch[23] Batch [1310]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.244418,	
2017-07-18 02:11:03,720 Epoch[23] Batch [1320]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.244872,	
2017-07-18 02:11:12,825 Epoch[23] Batch [1330]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.244841,	
2017-07-18 02:11:21,943 Epoch[23] Batch [1340]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.244882,	
2017-07-18 02:11:30,861 Epoch[23] Batch [1350]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.245189,	
2017-07-18 02:11:40,115 Epoch[23] Batch [1360]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.245002,	
2017-07-18 02:11:49,006 Epoch[23] Batch [1370]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.244880,	
2017-07-18 02:11:58,109 Epoch[23] Batch [1380]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.245195,	
2017-07-18 02:12:07,342 Epoch[23] Batch [1390]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.245733,	
2017-07-18 02:12:16,816 Epoch[23] Batch [1400]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.245722,	
2017-07-18 02:12:26,108 Epoch[23] Batch [1410]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.244981,	
2017-07-18 02:12:35,180 Epoch[23] Batch [1420]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.244357,	
2017-07-18 02:12:44,345 Epoch[23] Batch [1430]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.244339,	
2017-07-18 02:12:53,196 Epoch[23] Batch [1440]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.244443,	
2017-07-18 02:13:02,551 Epoch[23] Batch [1450]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.244795,	
2017-07-18 02:13:11,438 Epoch[23] Batch [1460]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.244897,	
2017-07-18 02:13:20,325 Epoch[23] Batch [1470]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.244453,	
2017-07-18 02:13:29,548 Epoch[23] Batch [1480]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.243852,	
2017-07-18 02:13:35,292 Epoch[23] Train-FCNLogLoss=1.243508
2017-07-18 02:13:35,292 Epoch[23] Time cost=1284.690
2017-07-18 02:13:36,477 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.params"
2017-07-18 02:13:39,352 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.states"
2017-07-18 02:13:49,913 Epoch[24] Batch [10]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.214672,	
2017-07-18 02:13:58,493 Epoch[24] Batch [20]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.276326,	
2017-07-18 02:14:07,127 Epoch[24] Batch [30]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.243355,	
2017-07-18 02:14:15,675 Epoch[24] Batch [40]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.257270,	
2017-07-18 02:14:24,321 Epoch[24] Batch [50]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.276068,	
2017-07-18 02:14:32,772 Epoch[24] Batch [60]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.283193,	
2017-07-18 02:14:41,259 Epoch[24] Batch [70]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.263521,	
2017-07-18 02:14:49,974 Epoch[24] Batch [80]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.264410,	
2017-07-18 02:14:58,481 Epoch[24] Batch [90]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.264338,	
2017-07-18 02:15:07,121 Epoch[24] Batch [100]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.255751,	
2017-07-18 02:15:15,531 Epoch[24] Batch [110]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.248017,	
2017-07-18 02:15:23,837 Epoch[24] Batch [120]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.244835,	
2017-07-18 02:15:32,175 Epoch[24] Batch [130]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.241517,	
2017-07-18 02:15:40,733 Epoch[24] Batch [140]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.244006,	
2017-07-18 02:15:49,272 Epoch[24] Batch [150]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.252996,	
2017-07-18 02:15:58,166 Epoch[24] Batch [160]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.249517,	
2017-07-18 02:16:06,797 Epoch[24] Batch [170]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.250050,	
2017-07-18 02:16:15,605 Epoch[24] Batch [180]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.242953,	
2017-07-18 02:16:23,975 Epoch[24] Batch [190]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.243639,	
2017-07-18 02:16:32,513 Epoch[24] Batch [200]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.238785,	
2017-07-18 02:16:41,289 Epoch[24] Batch [210]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.239898,	
2017-07-18 02:16:49,532 Epoch[24] Batch [220]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.238660,	
2017-07-18 02:16:57,944 Epoch[24] Batch [230]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.235587,	
2017-07-18 02:17:06,267 Epoch[24] Batch [240]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.234526,	
2017-07-18 02:17:14,883 Epoch[24] Batch [250]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.238318,	
2017-07-18 02:17:23,304 Epoch[24] Batch [260]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.239203,	
2017-07-18 02:17:31,780 Epoch[24] Batch [270]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.238770,	
2017-07-18 02:17:40,234 Epoch[24] Batch [280]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.238300,	
2017-07-18 02:17:48,717 Epoch[24] Batch [290]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.238022,	
2017-07-18 02:17:57,236 Epoch[24] Batch [300]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.236139,	
2017-07-18 02:18:05,759 Epoch[24] Batch [310]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.234480,	
2017-07-18 02:18:14,174 Epoch[24] Batch [320]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.234384,	
2017-07-18 02:18:22,751 Epoch[24] Batch [330]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.234288,	
2017-07-18 02:18:31,164 Epoch[24] Batch [340]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.232903,	
2017-07-18 02:18:39,893 Epoch[24] Batch [350]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.229855,	
2017-07-18 02:18:48,699 Epoch[24] Batch [360]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.229996,	
2017-07-18 02:18:57,670 Epoch[24] Batch [370]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.232044,	
2017-07-18 02:19:06,271 Epoch[24] Batch [380]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.229511,	
2017-07-18 02:19:15,168 Epoch[24] Batch [390]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.230284,	
2017-07-18 02:19:23,743 Epoch[24] Batch [400]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.228952,	
2017-07-18 02:19:32,441 Epoch[24] Batch [410]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.227997,	
2017-07-18 02:19:41,200 Epoch[24] Batch [420]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.227715,	
2017-07-18 02:19:49,792 Epoch[24] Batch [430]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.227808,	
2017-07-18 02:19:58,535 Epoch[24] Batch [440]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.227701,	
2017-07-18 02:20:07,370 Epoch[24] Batch [450]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.227920,	
2017-07-18 02:20:16,159 Epoch[24] Batch [460]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.228654,	
2017-07-18 02:20:24,729 Epoch[24] Batch [470]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.227629,	
2017-07-18 02:20:33,288 Epoch[24] Batch [480]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.227820,	
2017-07-18 02:20:43,231 Epoch[24] Batch [490]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.231382,	
2017-07-18 02:20:51,522 Epoch[24] Batch [500]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.230493,	
2017-07-18 02:21:00,568 Epoch[24] Batch [510]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.229854,	
2017-07-18 02:21:08,828 Epoch[24] Batch [520]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.231809,	
2017-07-18 02:21:17,453 Epoch[24] Batch [530]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.229564,	
2017-07-18 02:21:26,444 Epoch[24] Batch [540]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.230381,	
2017-07-18 02:21:35,050 Epoch[24] Batch [550]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.230985,	
2017-07-18 02:21:43,532 Epoch[24] Batch [560]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.231036,	
2017-07-18 02:21:52,729 Epoch[24] Batch [570]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.231388,	
2017-07-18 02:22:01,208 Epoch[24] Batch [580]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.229671,	
2017-07-18 02:22:10,198 Epoch[24] Batch [590]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.231387,	
2017-07-18 02:22:18,581 Epoch[24] Batch [600]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.230894,	
2017-07-18 02:22:27,342 Epoch[24] Batch [610]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.232862,	
2017-07-18 02:22:36,080 Epoch[24] Batch [620]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.232860,	
2017-07-18 02:22:44,567 Epoch[24] Batch [630]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.232969,	
2017-07-18 02:22:53,119 Epoch[24] Batch [640]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.232643,	
2017-07-18 02:23:01,660 Epoch[24] Batch [650]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.232335,	
2017-07-18 02:23:10,161 Epoch[24] Batch [660]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.234051,	
2017-07-18 02:23:19,081 Epoch[24] Batch [670]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.234731,	
2017-07-18 02:23:27,886 Epoch[24] Batch [680]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.235003,	
2017-07-18 02:23:36,413 Epoch[24] Batch [690]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.235133,	
2017-07-18 02:23:45,508 Epoch[24] Batch [700]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.234454,	
2017-07-18 02:23:54,362 Epoch[24] Batch [710]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.235472,	
2017-07-18 02:24:02,870 Epoch[24] Batch [720]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.235881,	
2017-07-18 02:24:11,422 Epoch[24] Batch [730]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.236488,	
2017-07-18 02:24:19,954 Epoch[24] Batch [740]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.236075,	
2017-07-18 02:24:28,515 Epoch[24] Batch [750]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.234937,	
2017-07-18 02:24:37,305 Epoch[24] Batch [760]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.235360,	
2017-07-18 02:24:46,033 Epoch[24] Batch [770]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.235375,	
2017-07-18 02:24:54,541 Epoch[24] Batch [780]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.235243,	
2017-07-18 02:25:02,922 Epoch[24] Batch [790]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.234624,	
2017-07-18 02:25:11,548 Epoch[24] Batch [800]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.234125,	
2017-07-18 02:25:20,348 Epoch[24] Batch [810]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.233892,	
2017-07-18 02:25:28,963 Epoch[24] Batch [820]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.234129,	
2017-07-18 02:25:37,606 Epoch[24] Batch [830]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.233058,	
2017-07-18 02:25:45,916 Epoch[24] Batch [840]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.234028,	
2017-07-18 02:25:54,756 Epoch[24] Batch [850]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.234075,	
2017-07-18 02:26:03,660 Epoch[24] Batch [860]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.234099,	
2017-07-18 02:26:12,454 Epoch[24] Batch [870]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.233894,	
2017-07-18 02:26:21,561 Epoch[24] Batch [880]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.233464,	
2017-07-18 02:26:30,285 Epoch[24] Batch [890]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.234374,	
2017-07-18 02:26:38,990 Epoch[24] Batch [900]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.234034,	
2017-07-18 02:26:47,632 Epoch[24] Batch [910]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.234271,	
2017-07-18 02:26:56,235 Epoch[24] Batch [920]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.233967,	
2017-07-18 02:27:05,314 Epoch[24] Batch [930]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.234320,	
2017-07-18 02:27:14,160 Epoch[24] Batch [940]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.233822,	
2017-07-18 02:27:22,818 Epoch[24] Batch [950]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.233329,	
2017-07-18 02:27:31,368 Epoch[24] Batch [960]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.234252,	
2017-07-18 02:27:40,056 Epoch[24] Batch [970]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.235085,	
2017-07-18 02:27:48,618 Epoch[24] Batch [980]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.235900,	
2017-07-18 02:27:57,221 Epoch[24] Batch [990]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.236338,	
2017-07-18 02:28:06,165 Epoch[24] Batch [1000]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.236425,	
2017-07-18 02:28:14,659 Epoch[24] Batch [1010]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.237415,	
2017-07-18 02:28:23,149 Epoch[24] Batch [1020]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.237328,	
2017-07-18 02:28:31,873 Epoch[24] Batch [1030]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.237358,	
2017-07-18 02:28:40,541 Epoch[24] Batch [1040]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.237406,	
2017-07-18 02:28:49,217 Epoch[24] Batch [1050]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.236330,	
2017-07-18 02:28:57,503 Epoch[24] Batch [1060]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.237392,	
2017-07-18 02:29:05,924 Epoch[24] Batch [1070]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.237180,	
2017-07-18 02:29:14,676 Epoch[24] Batch [1080]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.236410,	
2017-07-18 02:29:23,109 Epoch[24] Batch [1090]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.236487,	
2017-07-18 02:29:31,421 Epoch[24] Batch [1100]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.237098,	
2017-07-18 02:29:40,049 Epoch[24] Batch [1110]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.237259,	
2017-07-18 02:29:48,532 Epoch[24] Batch [1120]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.236883,	
2017-07-18 02:29:57,154 Epoch[24] Batch [1130]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.236958,	
2017-07-18 02:30:05,943 Epoch[24] Batch [1140]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.236882,	
2017-07-18 02:30:14,782 Epoch[24] Batch [1150]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.236916,	
2017-07-18 02:30:23,829 Epoch[24] Batch [1160]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.236744,	
2017-07-18 02:30:32,404 Epoch[24] Batch [1170]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.237277,	
2017-07-18 02:30:40,992 Epoch[24] Batch [1180]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.237465,	
2017-07-18 02:30:49,721 Epoch[24] Batch [1190]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.237158,	
2017-07-18 02:30:58,483 Epoch[24] Batch [1200]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.236569,	
2017-07-18 02:31:06,832 Epoch[24] Batch [1210]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.235861,	
2017-07-18 02:31:15,173 Epoch[24] Batch [1220]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.236320,	
2017-07-18 02:31:23,663 Epoch[24] Batch [1230]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.236939,	
2017-07-18 02:31:31,989 Epoch[24] Batch [1240]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.237104,	
2017-07-18 02:31:40,628 Epoch[24] Batch [1250]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237466,	
2017-07-18 02:31:49,115 Epoch[24] Batch [1260]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.237225,	
2017-07-18 02:31:57,744 Epoch[24] Batch [1270]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.237547,	
2017-07-18 02:32:06,249 Epoch[24] Batch [1280]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.237253,	
2017-07-18 02:32:14,739 Epoch[24] Batch [1290]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.237499,	
2017-07-18 02:32:23,276 Epoch[24] Batch [1300]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.238106,	
2017-07-18 02:32:31,883 Epoch[24] Batch [1310]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.238274,	
2017-07-18 02:32:40,002 Epoch[24] Batch [1320]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.237271,	
2017-07-18 02:32:48,678 Epoch[24] Batch [1330]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.237812,	
2017-07-18 02:32:57,060 Epoch[24] Batch [1340]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.237513,	
2017-07-18 02:33:05,404 Epoch[24] Batch [1350]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.237484,	
2017-07-18 02:33:14,087 Epoch[24] Batch [1360]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.237866,	
2017-07-18 02:33:22,853 Epoch[24] Batch [1370]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.237058,	
2017-07-18 02:33:31,121 Epoch[24] Batch [1380]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.236914,	
2017-07-18 02:33:39,470 Epoch[24] Batch [1390]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.237224,	
2017-07-18 02:33:47,746 Epoch[24] Batch [1400]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.237137,	
2017-07-18 02:33:56,502 Epoch[24] Batch [1410]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.237210,	
2017-07-18 02:34:05,393 Epoch[24] Batch [1420]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.237346,	
2017-07-18 02:34:13,949 Epoch[24] Batch [1430]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.238102,	
2017-07-18 02:34:22,013 Epoch[24] Batch [1440]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.237853,	
2017-07-18 02:34:30,473 Epoch[24] Batch [1450]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.238172,	
2017-07-18 02:34:38,869 Epoch[24] Batch [1460]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.238527,	
2017-07-18 02:34:47,585 Epoch[24] Batch [1470]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.238554,	
2017-07-18 02:34:55,949 Epoch[24] Batch [1480]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.237970,	
2017-07-18 02:35:01,051 Epoch[24] Train-FCNLogLoss=1.237627
2017-07-18 02:35:01,052 Epoch[24] Time cost=1281.486
2017-07-18 02:35:02,376 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.params"
2017-07-18 02:35:05,839 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.states"
2017-07-18 02:35:15,680 Epoch[25] Batch [10]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.312126,	
2017-07-18 02:35:24,214 Epoch[25] Batch [20]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.264305,	
2017-07-18 02:35:32,867 Epoch[25] Batch [30]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.257297,	
2017-07-18 02:35:42,003 Epoch[25] Batch [40]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.266866,	
2017-07-18 02:35:50,628 Epoch[25] Batch [50]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.269205,	
2017-07-18 02:35:59,313 Epoch[25] Batch [60]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.269120,	
2017-07-18 02:36:08,102 Epoch[25] Batch [70]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.267400,	
2017-07-18 02:36:17,174 Epoch[25] Batch [80]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.276573,	
2017-07-18 02:36:25,682 Epoch[25] Batch [90]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.267333,	
2017-07-18 02:36:34,249 Epoch[25] Batch [100]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.261157,	
2017-07-18 02:36:43,246 Epoch[25] Batch [110]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.261233,	
2017-07-18 02:36:51,825 Epoch[25] Batch [120]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.255132,	
2017-07-18 02:37:00,265 Epoch[25] Batch [130]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.255100,	
2017-07-18 02:37:08,681 Epoch[25] Batch [140]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.250938,	
2017-07-18 02:37:17,439 Epoch[25] Batch [150]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.250219,	
2017-07-18 02:37:26,241 Epoch[25] Batch [160]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.251181,	
2017-07-18 02:37:34,732 Epoch[25] Batch [170]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.251637,	
2017-07-18 02:37:43,643 Epoch[25] Batch [180]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.252136,	
2017-07-18 02:37:52,226 Epoch[25] Batch [190]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.254314,	
2017-07-18 02:38:00,817 Epoch[25] Batch [200]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.260439,	
2017-07-18 02:38:09,536 Epoch[25] Batch [210]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.261079,	
2017-07-18 02:38:18,041 Epoch[25] Batch [220]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.260776,	
2017-07-18 02:38:26,873 Epoch[25] Batch [230]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.260637,	
2017-07-18 02:38:35,617 Epoch[25] Batch [240]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.258078,	
2017-07-18 02:38:44,443 Epoch[25] Batch [250]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.255317,	
2017-07-18 02:38:53,095 Epoch[25] Batch [260]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.255765,	
2017-07-18 02:39:01,511 Epoch[25] Batch [270]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.256708,	
2017-07-18 02:39:10,407 Epoch[25] Batch [280]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.255391,	
2017-07-18 02:39:19,180 Epoch[25] Batch [290]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.256303,	
2017-07-18 02:39:27,898 Epoch[25] Batch [300]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.257351,	
2017-07-18 02:39:36,738 Epoch[25] Batch [310]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.254652,	
2017-07-18 02:39:45,581 Epoch[25] Batch [320]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.254933,	
2017-07-18 02:39:54,431 Epoch[25] Batch [330]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.253207,	
2017-07-18 02:40:03,040 Epoch[25] Batch [340]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.254439,	
2017-07-18 02:40:11,834 Epoch[25] Batch [350]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.252930,	
2017-07-18 02:40:22,142 Epoch[25] Batch [360]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.253311,	
2017-07-18 02:40:31,949 Epoch[25] Batch [370]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.254469,	
2017-07-18 02:40:40,546 Epoch[25] Batch [380]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.252845,	
2017-07-18 02:40:49,662 Epoch[25] Batch [390]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.253747,	
2017-07-18 02:40:58,992 Epoch[25] Batch [400]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.249953,	
2017-07-18 02:41:08,200 Epoch[25] Batch [410]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.247860,	
2017-07-18 02:41:17,118 Epoch[25] Batch [420]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.248233,	
2017-07-18 02:41:25,985 Epoch[25] Batch [430]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.248343,	
2017-07-18 02:41:34,990 Epoch[25] Batch [440]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.247741,	
2017-07-18 02:41:43,776 Epoch[25] Batch [450]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.247535,	
2017-07-18 02:41:52,488 Epoch[25] Batch [460]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.248196,	
2017-07-18 02:42:01,752 Epoch[25] Batch [470]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.248058,	
2017-07-18 02:42:10,556 Epoch[25] Batch [480]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.248461,	
2017-07-18 02:42:19,417 Epoch[25] Batch [490]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.246180,	
2017-07-18 02:42:28,786 Epoch[25] Batch [500]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.245490,	
2017-07-18 02:42:38,166 Epoch[25] Batch [510]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.246679,	
2017-07-18 02:42:46,986 Epoch[25] Batch [520]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.246257,	
2017-07-18 02:42:55,978 Epoch[25] Batch [530]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.246224,	
2017-07-18 02:43:05,103 Epoch[25] Batch [540]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.248990,	
2017-07-18 02:43:13,990 Epoch[25] Batch [550]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.248973,	
2017-07-18 02:43:23,006 Epoch[25] Batch [560]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.249455,	
2017-07-18 02:43:31,889 Epoch[25] Batch [570]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.248327,	
2017-07-18 02:43:40,826 Epoch[25] Batch [580]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.248342,	
2017-07-18 02:43:49,589 Epoch[25] Batch [590]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.247894,	
2017-07-18 02:43:58,833 Epoch[25] Batch [600]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.246375,	
2017-07-18 02:44:07,603 Epoch[25] Batch [610]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.247026,	
2017-07-18 02:44:16,637 Epoch[25] Batch [620]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.245913,	
2017-07-18 02:44:25,489 Epoch[25] Batch [630]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.244910,	
2017-07-18 02:44:34,381 Epoch[25] Batch [640]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.244180,	
2017-07-18 02:44:42,957 Epoch[25] Batch [650]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.242685,	
2017-07-18 02:44:51,738 Epoch[25] Batch [660]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.243183,	
2017-07-18 02:45:00,845 Epoch[25] Batch [670]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.243571,	
2017-07-18 02:45:09,329 Epoch[25] Batch [680]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.243473,	
2017-07-18 02:45:18,221 Epoch[25] Batch [690]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.242915,	
2017-07-18 02:45:26,956 Epoch[25] Batch [700]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.243413,	
2017-07-18 02:45:35,706 Epoch[25] Batch [710]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.243203,	
2017-07-18 02:45:44,736 Epoch[25] Batch [720]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.243415,	
2017-07-18 02:45:53,824 Epoch[25] Batch [730]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.242817,	
2017-07-18 02:46:02,674 Epoch[25] Batch [740]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.241629,	
2017-07-18 02:46:11,739 Epoch[25] Batch [750]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.241375,	
2017-07-18 02:46:21,044 Epoch[25] Batch [760]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.240824,	
2017-07-18 02:46:29,707 Epoch[25] Batch [770]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.242020,	
2017-07-18 02:46:38,382 Epoch[25] Batch [780]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.242681,	
2017-07-18 02:46:47,077 Epoch[25] Batch [790]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.242108,	
2017-07-18 02:46:56,008 Epoch[25] Batch [800]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.244219,	
2017-07-18 02:47:04,974 Epoch[25] Batch [810]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.244329,	
2017-07-18 02:47:14,060 Epoch[25] Batch [820]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.243317,	
2017-07-18 02:47:23,183 Epoch[25] Batch [830]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.242310,	
2017-07-18 02:47:31,944 Epoch[25] Batch [840]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.242104,	
2017-07-18 02:47:40,986 Epoch[25] Batch [850]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.241886,	
2017-07-18 02:47:49,831 Epoch[25] Batch [860]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.242148,	
2017-07-18 02:47:58,896 Epoch[25] Batch [870]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.243314,	
2017-07-18 02:48:07,913 Epoch[25] Batch [880]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.243520,	
2017-07-18 02:48:16,944 Epoch[25] Batch [890]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242836,	
2017-07-18 02:48:25,952 Epoch[25] Batch [900]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242998,	
2017-07-18 02:48:35,213 Epoch[25] Batch [910]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.243331,	
2017-07-18 02:48:44,205 Epoch[25] Batch [920]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.242993,	
2017-07-18 02:48:53,008 Epoch[25] Batch [930]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.243156,	
2017-07-18 02:49:02,525 Epoch[25] Batch [940]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.243581,	
2017-07-18 02:49:11,838 Epoch[25] Batch [950]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.243574,	
2017-07-18 02:49:20,170 Epoch[25] Batch [960]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.244098,	
2017-07-18 02:49:28,992 Epoch[25] Batch [970]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.243544,	
2017-07-18 02:49:37,499 Epoch[25] Batch [980]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.242195,	
2017-07-18 02:49:46,690 Epoch[25] Batch [990]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.241804,	
2017-07-18 02:49:55,823 Epoch[25] Batch [1000]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.241018,	
2017-07-18 02:50:05,110 Epoch[25] Batch [1010]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.241921,	
2017-07-18 02:50:14,488 Epoch[25] Batch [1020]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.242259,	
2017-07-18 02:50:23,576 Epoch[25] Batch [1030]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.242322,	
2017-07-18 02:50:32,337 Epoch[25] Batch [1040]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.241809,	
2017-07-18 02:50:40,935 Epoch[25] Batch [1050]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.242574,	
2017-07-18 02:50:49,788 Epoch[25] Batch [1060]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.241217,	
2017-07-18 02:50:58,703 Epoch[25] Batch [1070]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.241426,	
2017-07-18 02:51:07,734 Epoch[25] Batch [1080]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.241133,	
2017-07-18 02:51:16,734 Epoch[25] Batch [1090]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.240194,	
2017-07-18 02:51:25,639 Epoch[25] Batch [1100]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.239492,	
2017-07-18 02:51:34,283 Epoch[25] Batch [1110]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.239184,	
2017-07-18 02:51:43,421 Epoch[25] Batch [1120]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.239210,	
2017-07-18 02:51:52,678 Epoch[25] Batch [1130]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.238474,	
2017-07-18 02:52:01,778 Epoch[25] Batch [1140]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.239808,	
2017-07-18 02:52:10,952 Epoch[25] Batch [1150]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.240476,	
2017-07-18 02:52:19,835 Epoch[25] Batch [1160]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.240446,	
2017-07-18 02:52:28,883 Epoch[25] Batch [1170]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.240009,	
2017-07-18 02:52:37,943 Epoch[25] Batch [1180]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.240620,	
2017-07-18 02:52:47,125 Epoch[25] Batch [1190]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.239884,	
2017-07-18 02:52:56,177 Epoch[25] Batch [1200]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.240090,	
2017-07-18 02:53:05,314 Epoch[25] Batch [1210]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.239510,	
2017-07-18 02:53:14,334 Epoch[25] Batch [1220]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.239132,	
2017-07-18 02:53:23,567 Epoch[25] Batch [1230]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.238673,	
2017-07-18 02:53:32,611 Epoch[25] Batch [1240]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.238626,	
2017-07-18 02:53:41,789 Epoch[25] Batch [1250]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.237569,	
2017-07-18 02:53:51,197 Epoch[25] Batch [1260]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.236863,	
2017-07-18 02:54:00,429 Epoch[25] Batch [1270]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.236615,	
2017-07-18 02:54:09,330 Epoch[25] Batch [1280]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.236332,	
2017-07-18 02:54:18,709 Epoch[25] Batch [1290]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.237085,	
2017-07-18 02:54:28,055 Epoch[25] Batch [1300]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.236891,	
2017-07-18 02:54:42,509 Epoch[25] Batch [1310]	Speed: 2.77 samples/sec	Train-FCNLogLoss=1.236370,	
2017-07-18 02:54:51,623 Epoch[25] Batch [1320]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.237286,	
2017-07-18 02:55:00,893 Epoch[25] Batch [1330]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.237300,	
2017-07-18 02:55:10,286 Epoch[25] Batch [1340]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.238337,	
2017-07-18 02:55:19,620 Epoch[25] Batch [1350]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.238728,	
2017-07-18 02:55:28,902 Epoch[25] Batch [1360]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.238161,	
2017-07-18 02:55:38,283 Epoch[25] Batch [1370]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.238094,	
2017-07-18 02:55:47,853 Epoch[25] Batch [1380]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.238005,	
2017-07-18 02:55:57,178 Epoch[25] Batch [1390]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237816,	
2017-07-18 02:56:06,445 Epoch[25] Batch [1400]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.238309,	
2017-07-18 02:56:15,744 Epoch[25] Batch [1410]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.237581,	
2017-07-18 02:56:24,987 Epoch[25] Batch [1420]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.237698,	
2017-07-18 02:56:34,221 Epoch[25] Batch [1430]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.238311,	
2017-07-18 02:56:43,301 Epoch[25] Batch [1440]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.238660,	
2017-07-18 02:56:52,546 Epoch[25] Batch [1450]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.238546,	
2017-07-18 02:57:01,623 Epoch[25] Batch [1460]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.239169,	
2017-07-18 02:57:10,884 Epoch[25] Batch [1470]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.239241,	
2017-07-18 02:57:20,130 Epoch[25] Batch [1480]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.238952,	
2017-07-18 02:57:25,610 Epoch[25] Train-FCNLogLoss=1.238497
2017-07-18 02:57:25,610 Epoch[25] Time cost=1339.593
2017-07-18 02:57:27,053 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.params"
2017-07-18 02:57:30,827 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.states"
2017-07-18 02:57:41,657 Epoch[26] Batch [10]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.240359,	
2017-07-18 02:57:50,737 Epoch[26] Batch [20]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.228933,	
2017-07-18 02:57:59,621 Epoch[26] Batch [30]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.194662,	
2017-07-18 02:58:08,830 Epoch[26] Batch [40]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.193101,	
2017-07-18 02:58:17,642 Epoch[26] Batch [50]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.205526,	
2017-07-18 02:58:26,703 Epoch[26] Batch [60]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.217493,	
2017-07-18 02:58:36,044 Epoch[26] Batch [70]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.218825,	
2017-07-18 02:58:45,032 Epoch[26] Batch [80]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.209898,	
2017-07-18 02:58:54,108 Epoch[26] Batch [90]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.219615,	
2017-07-18 02:59:03,434 Epoch[26] Batch [100]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.232085,	
2017-07-18 02:59:12,151 Epoch[26] Batch [110]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.227996,	
2017-07-18 02:59:21,412 Epoch[26] Batch [120]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.239811,	
2017-07-18 02:59:30,497 Epoch[26] Batch [130]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.236155,	
2017-07-18 02:59:39,680 Epoch[26] Batch [140]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.235943,	
2017-07-18 02:59:48,738 Epoch[26] Batch [150]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.234078,	
2017-07-18 02:59:57,670 Epoch[26] Batch [160]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.233964,	
2017-07-18 03:00:06,574 Epoch[26] Batch [170]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.231038,	
2017-07-18 03:00:15,921 Epoch[26] Batch [180]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.231733,	
2017-07-18 03:00:25,395 Epoch[26] Batch [190]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.234843,	
2017-07-18 03:00:34,413 Epoch[26] Batch [200]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.235275,	
2017-07-18 03:00:43,563 Epoch[26] Batch [210]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.235801,	
2017-07-18 03:00:52,754 Epoch[26] Batch [220]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.231349,	
2017-07-18 03:01:01,834 Epoch[26] Batch [230]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.235211,	
2017-07-18 03:01:11,141 Epoch[26] Batch [240]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.236114,	
2017-07-18 03:01:19,975 Epoch[26] Batch [250]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.235200,	
2017-07-18 03:01:29,309 Epoch[26] Batch [260]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.235212,	
2017-07-18 03:01:38,233 Epoch[26] Batch [270]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.237868,	
2017-07-18 03:01:47,330 Epoch[26] Batch [280]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.236371,	
2017-07-18 03:01:56,673 Epoch[26] Batch [290]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.234827,	
2017-07-18 03:02:05,399 Epoch[26] Batch [300]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.235655,	
2017-07-18 03:02:14,392 Epoch[26] Batch [310]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.239528,	
2017-07-18 03:02:23,682 Epoch[26] Batch [320]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.240544,	
2017-07-18 03:02:32,470 Epoch[26] Batch [330]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.242975,	
2017-07-18 03:02:41,170 Epoch[26] Batch [340]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.245102,	
2017-07-18 03:02:50,315 Epoch[26] Batch [350]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.246249,	
2017-07-18 03:02:59,437 Epoch[26] Batch [360]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.245773,	
2017-07-18 03:03:08,420 Epoch[26] Batch [370]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.246263,	
2017-07-18 03:03:17,275 Epoch[26] Batch [380]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.243002,	
2017-07-18 03:03:26,345 Epoch[26] Batch [390]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.242068,	
2017-07-18 03:03:35,550 Epoch[26] Batch [400]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.240644,	
2017-07-18 03:03:44,913 Epoch[26] Batch [410]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.241414,	
2017-07-18 03:03:53,872 Epoch[26] Batch [420]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.238508,	
2017-07-18 03:04:02,630 Epoch[26] Batch [430]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.235950,	
2017-07-18 03:04:11,792 Epoch[26] Batch [440]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.235852,	
2017-07-18 03:04:20,609 Epoch[26] Batch [450]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.235699,	
2017-07-18 03:04:29,090 Epoch[26] Batch [460]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.235104,	
2017-07-18 03:04:37,960 Epoch[26] Batch [470]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.235522,	
2017-07-18 03:04:47,066 Epoch[26] Batch [480]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.238233,	
2017-07-18 03:04:56,208 Epoch[26] Batch [490]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.239333,	
2017-07-18 03:05:05,078 Epoch[26] Batch [500]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.239522,	
2017-07-18 03:05:13,918 Epoch[26] Batch [510]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.240342,	
2017-07-18 03:05:23,072 Epoch[26] Batch [520]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.240156,	
2017-07-18 03:05:32,076 Epoch[26] Batch [530]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.241315,	
2017-07-18 03:05:41,256 Epoch[26] Batch [540]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.240847,	
2017-07-18 03:05:50,369 Epoch[26] Batch [550]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.242174,	
2017-07-18 03:05:59,461 Epoch[26] Batch [560]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.242751,	
2017-07-18 03:06:08,354 Epoch[26] Batch [570]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.243627,	
2017-07-18 03:06:17,293 Epoch[26] Batch [580]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.244808,	
2017-07-18 03:06:26,239 Epoch[26] Batch [590]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.243356,	
2017-07-18 03:06:35,589 Epoch[26] Batch [600]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.242896,	
2017-07-18 03:06:44,776 Epoch[26] Batch [610]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.243745,	
2017-07-18 03:06:54,108 Epoch[26] Batch [620]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.243615,	
2017-07-18 03:07:03,428 Epoch[26] Batch [630]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.244610,	
2017-07-18 03:07:12,939 Epoch[26] Batch [640]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.242437,	
2017-07-18 03:07:21,885 Epoch[26] Batch [650]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.241929,	
2017-07-18 03:07:30,877 Epoch[26] Batch [660]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.242405,	
2017-07-18 03:07:40,364 Epoch[26] Batch [670]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.241330,	
2017-07-18 03:07:49,406 Epoch[26] Batch [680]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.240632,	
2017-07-18 03:07:58,568 Epoch[26] Batch [690]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.238545,	
2017-07-18 03:08:07,747 Epoch[26] Batch [700]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.239320,	
2017-07-18 03:08:16,970 Epoch[26] Batch [710]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.238818,	
2017-07-18 03:08:26,170 Epoch[26] Batch [720]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.239572,	
2017-07-18 03:08:35,489 Epoch[26] Batch [730]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.240179,	
2017-07-18 03:08:44,815 Epoch[26] Batch [740]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.240786,	
2017-07-18 03:08:53,766 Epoch[26] Batch [750]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.242879,	
2017-07-18 03:09:03,042 Epoch[26] Batch [760]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.241679,	
2017-07-18 03:09:12,356 Epoch[26] Batch [770]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.241412,	
2017-07-18 03:09:21,672 Epoch[26] Batch [780]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.242324,	
2017-07-18 03:09:30,932 Epoch[26] Batch [790]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.241831,	
2017-07-18 03:09:40,139 Epoch[26] Batch [800]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.242532,	
2017-07-18 03:09:49,423 Epoch[26] Batch [810]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.241451,	
2017-07-18 03:09:58,700 Epoch[26] Batch [820]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.240753,	
2017-07-18 03:10:08,202 Epoch[26] Batch [830]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.241376,	
2017-07-18 03:10:17,606 Epoch[26] Batch [840]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.241447,	
2017-07-18 03:10:26,838 Epoch[26] Batch [850]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.240762,	
2017-07-18 03:10:36,103 Epoch[26] Batch [860]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.242262,	
2017-07-18 03:10:45,161 Epoch[26] Batch [870]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.242798,	
2017-07-18 03:10:56,878 Epoch[26] Batch [880]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.242265,	
2017-07-18 03:11:06,132 Epoch[26] Batch [890]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.242197,	
2017-07-18 03:11:15,327 Epoch[26] Batch [900]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.242777,	
2017-07-18 03:11:24,594 Epoch[26] Batch [910]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.242441,	
2017-07-18 03:11:33,918 Epoch[26] Batch [920]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.243856,	
2017-07-18 03:11:42,786 Epoch[26] Batch [930]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.242666,	
2017-07-18 03:11:52,326 Epoch[26] Batch [940]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.242241,	
2017-07-18 03:12:01,615 Epoch[26] Batch [950]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.242483,	
2017-07-18 03:12:10,639 Epoch[26] Batch [960]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242371,	
2017-07-18 03:12:19,891 Epoch[26] Batch [970]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.242268,	
2017-07-18 03:12:29,272 Epoch[26] Batch [980]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.241184,	
2017-07-18 03:12:38,553 Epoch[26] Batch [990]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.240788,	
2017-07-18 03:12:47,571 Epoch[26] Batch [1000]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.240312,	
2017-07-18 03:12:56,830 Epoch[26] Batch [1010]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.240692,	
2017-07-18 03:13:06,029 Epoch[26] Batch [1020]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.240127,	
2017-07-18 03:13:15,097 Epoch[26] Batch [1030]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.240434,	
2017-07-18 03:13:24,601 Epoch[26] Batch [1040]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.240817,	
2017-07-18 03:13:33,867 Epoch[26] Batch [1050]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.241758,	
2017-07-18 03:13:43,333 Epoch[26] Batch [1060]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.241661,	
2017-07-18 03:13:52,781 Epoch[26] Batch [1070]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.241351,	
2017-07-18 03:14:02,087 Epoch[26] Batch [1080]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.240903,	
2017-07-18 03:14:11,510 Epoch[26] Batch [1090]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.241244,	
2017-07-18 03:14:21,129 Epoch[26] Batch [1100]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.241532,	
2017-07-18 03:14:30,230 Epoch[26] Batch [1110]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.242363,	
2017-07-18 03:14:39,440 Epoch[26] Batch [1120]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.242843,	
2017-07-18 03:14:48,717 Epoch[26] Batch [1130]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.242084,	
2017-07-18 03:14:57,877 Epoch[26] Batch [1140]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.242331,	
2017-07-18 03:15:07,044 Epoch[26] Batch [1150]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.241974,	
2017-07-18 03:15:15,983 Epoch[26] Batch [1160]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.242173,	
2017-07-18 03:15:25,460 Epoch[26] Batch [1170]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.242508,	
2017-07-18 03:15:34,752 Epoch[26] Batch [1180]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.243742,	
2017-07-18 03:15:44,046 Epoch[26] Batch [1190]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.243895,	
2017-07-18 03:15:53,432 Epoch[26] Batch [1200]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.243361,	
2017-07-18 03:16:02,708 Epoch[26] Batch [1210]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.242109,	
2017-07-18 03:16:11,804 Epoch[26] Batch [1220]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.242164,	
2017-07-18 03:16:21,042 Epoch[26] Batch [1230]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.241566,	
2017-07-18 03:16:30,306 Epoch[26] Batch [1240]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.241798,	
2017-07-18 03:16:39,458 Epoch[26] Batch [1250]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.242163,	
2017-07-18 03:16:48,754 Epoch[26] Batch [1260]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.241704,	
2017-07-18 03:16:58,025 Epoch[26] Batch [1270]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.242012,	
2017-07-18 03:17:06,944 Epoch[26] Batch [1280]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.242159,	
2017-07-18 03:17:16,368 Epoch[26] Batch [1290]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.242188,	
2017-07-18 03:17:25,798 Epoch[26] Batch [1300]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.242529,	
2017-07-18 03:17:34,811 Epoch[26] Batch [1310]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242831,	
2017-07-18 03:17:44,258 Epoch[26] Batch [1320]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.243182,	
2017-07-18 03:17:55,475 Epoch[26] Batch [1330]	Speed: 3.57 samples/sec	Train-FCNLogLoss=1.243352,	
2017-07-18 03:18:05,053 Epoch[26] Batch [1340]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.243493,	
2017-07-18 03:18:14,337 Epoch[26] Batch [1350]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.243103,	
2017-07-18 03:18:23,768 Epoch[26] Batch [1360]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.243524,	
2017-07-18 03:18:33,507 Epoch[26] Batch [1370]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.243254,	
2017-07-18 03:18:42,584 Epoch[26] Batch [1380]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.242545,	
2017-07-18 03:18:51,828 Epoch[26] Batch [1390]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.243850,	
2017-07-18 03:19:01,265 Epoch[26] Batch [1400]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.243235,	
2017-07-18 03:19:10,336 Epoch[26] Batch [1410]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.242758,	
2017-07-18 03:19:19,918 Epoch[26] Batch [1420]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.243411,	
2017-07-18 03:19:29,273 Epoch[26] Batch [1430]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.243157,	
2017-07-18 03:19:38,381 Epoch[26] Batch [1440]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.242759,	
2017-07-18 03:19:47,311 Epoch[26] Batch [1450]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.242898,	
2017-07-18 03:19:56,896 Epoch[26] Batch [1460]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.243281,	
2017-07-18 03:20:06,315 Epoch[26] Batch [1470]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.243057,	
2017-07-18 03:20:15,895 Epoch[26] Batch [1480]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.243112,	
2017-07-18 03:20:21,686 Epoch[26] Train-FCNLogLoss=1.243455
2017-07-18 03:20:21,687 Epoch[26] Time cost=1370.588
2017-07-18 03:20:22,922 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.params"
2017-07-18 03:20:26,093 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.states"
2017-07-18 03:20:36,477 Epoch[27] Batch [10]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.233164,	
2017-07-18 03:20:46,170 Epoch[27] Batch [20]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.249106,	
2017-07-18 03:20:55,839 Epoch[27] Batch [30]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.249905,	
2017-07-18 03:21:05,124 Epoch[27] Batch [40]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.247639,	
2017-07-18 03:21:14,496 Epoch[27] Batch [50]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.246633,	
2017-07-18 03:21:23,894 Epoch[27] Batch [60]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.269239,	
2017-07-18 03:21:33,475 Epoch[27] Batch [70]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.253389,	
2017-07-18 03:21:42,814 Epoch[27] Batch [80]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.252594,	
2017-07-18 03:21:51,963 Epoch[27] Batch [90]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.256112,	
2017-07-18 03:22:01,034 Epoch[27] Batch [100]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.253738,	
2017-07-18 03:22:10,645 Epoch[27] Batch [110]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.250655,	
2017-07-18 03:22:19,981 Epoch[27] Batch [120]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.246871,	
2017-07-18 03:22:29,518 Epoch[27] Batch [130]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.254356,	
2017-07-18 03:22:39,278 Epoch[27] Batch [140]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.258693,	
2017-07-18 03:22:48,609 Epoch[27] Batch [150]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.263374,	
2017-07-18 03:22:58,228 Epoch[27] Batch [160]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.261616,	
2017-07-18 03:23:07,628 Epoch[27] Batch [170]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.261428,	
2017-07-18 03:23:17,001 Epoch[27] Batch [180]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.262016,	
2017-07-18 03:23:26,420 Epoch[27] Batch [190]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.260296,	
2017-07-18 03:23:35,526 Epoch[27] Batch [200]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.251969,	
2017-07-18 03:23:44,960 Epoch[27] Batch [210]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.255088,	
2017-07-18 03:23:53,896 Epoch[27] Batch [220]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.258410,	
2017-07-18 03:24:03,386 Epoch[27] Batch [230]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.256978,	
2017-07-18 03:24:12,619 Epoch[27] Batch [240]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.255269,	
2017-07-18 03:24:21,988 Epoch[27] Batch [250]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.256576,	
2017-07-18 03:24:31,437 Epoch[27] Batch [260]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.256698,	
2017-07-18 03:24:40,883 Epoch[27] Batch [270]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.251026,	
2017-07-18 03:24:49,924 Epoch[27] Batch [280]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.248982,	
2017-07-18 03:24:59,465 Epoch[27] Batch [290]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.248282,	
2017-07-18 03:25:08,782 Epoch[27] Batch [300]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.248304,	
2017-07-18 03:25:17,988 Epoch[27] Batch [310]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.245198,	
2017-07-18 03:25:27,604 Epoch[27] Batch [320]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.246913,	
2017-07-18 03:25:36,785 Epoch[27] Batch [330]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.246287,	
2017-07-18 03:25:45,960 Epoch[27] Batch [340]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.246309,	
2017-07-18 03:25:55,203 Epoch[27] Batch [350]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.245244,	
2017-07-18 03:26:04,375 Epoch[27] Batch [360]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.245695,	
2017-07-18 03:26:13,761 Epoch[27] Batch [370]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.243770,	
2017-07-18 03:26:23,024 Epoch[27] Batch [380]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.244390,	
2017-07-18 03:26:32,632 Epoch[27] Batch [390]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.244340,	
2017-07-18 03:26:42,093 Epoch[27] Batch [400]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.244705,	
2017-07-18 03:26:51,393 Epoch[27] Batch [410]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.244845,	
2017-07-18 03:27:00,631 Epoch[27] Batch [420]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.245449,	
2017-07-18 03:27:10,040 Epoch[27] Batch [430]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.245769,	
2017-07-18 03:27:19,542 Epoch[27] Batch [440]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.245583,	
2017-07-18 03:27:29,339 Epoch[27] Batch [450]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.244924,	
2017-07-18 03:27:38,738 Epoch[27] Batch [460]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.244612,	
2017-07-18 03:27:47,967 Epoch[27] Batch [470]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.245941,	
2017-07-18 03:27:57,374 Epoch[27] Batch [480]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.246583,	
2017-07-18 03:28:06,883 Epoch[27] Batch [490]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.246605,	
2017-07-18 03:28:16,145 Epoch[27] Batch [500]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.249769,	
2017-07-18 03:28:25,412 Epoch[27] Batch [510]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.250127,	
2017-07-18 03:28:34,450 Epoch[27] Batch [520]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.250710,	
2017-07-18 03:28:43,659 Epoch[27] Batch [530]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.252658,	
2017-07-18 03:28:52,630 Epoch[27] Batch [540]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.252614,	
2017-07-18 03:29:02,037 Epoch[27] Batch [550]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.251758,	
2017-07-18 03:29:11,224 Epoch[27] Batch [560]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.252976,	
2017-07-18 03:29:20,703 Epoch[27] Batch [570]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.252160,	
2017-07-18 03:29:30,188 Epoch[27] Batch [580]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.252445,	
2017-07-18 03:29:38,924 Epoch[27] Batch [590]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.251233,	
2017-07-18 03:29:48,237 Epoch[27] Batch [600]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.249659,	
2017-07-18 03:29:57,732 Epoch[27] Batch [610]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.248018,	
2017-07-18 03:30:07,037 Epoch[27] Batch [620]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.248365,	
2017-07-18 03:30:16,117 Epoch[27] Batch [630]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.248600,	
2017-07-18 03:30:25,605 Epoch[27] Batch [640]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.249861,	
2017-07-18 03:30:35,058 Epoch[27] Batch [650]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.250865,	
2017-07-18 03:30:44,161 Epoch[27] Batch [660]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.251372,	
2017-07-18 03:30:53,460 Epoch[27] Batch [670]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.250349,	
2017-07-18 03:31:02,788 Epoch[27] Batch [680]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.250486,	
2017-07-18 03:31:12,344 Epoch[27] Batch [690]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.249946,	
2017-07-18 03:31:21,869 Epoch[27] Batch [700]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.249316,	
2017-07-18 03:31:31,072 Epoch[27] Batch [710]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.248868,	
2017-07-18 03:31:40,398 Epoch[27] Batch [720]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.249396,	
2017-07-18 03:31:50,230 Epoch[27] Batch [730]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.249796,	
2017-07-18 03:31:59,891 Epoch[27] Batch [740]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.250498,	
2017-07-18 03:32:09,307 Epoch[27] Batch [750]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.250539,	
2017-07-18 03:32:18,589 Epoch[27] Batch [760]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.251166,	
2017-07-18 03:32:28,377 Epoch[27] Batch [770]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.251146,	
2017-07-18 03:32:37,988 Epoch[27] Batch [780]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.250039,	
2017-07-18 03:32:47,522 Epoch[27] Batch [790]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.250265,	
2017-07-18 03:32:57,290 Epoch[27] Batch [800]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.249672,	
2017-07-18 03:33:06,692 Epoch[27] Batch [810]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.248753,	
2017-07-18 03:33:15,983 Epoch[27] Batch [820]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.249898,	
2017-07-18 03:33:25,629 Epoch[27] Batch [830]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.250162,	
2017-07-18 03:33:35,052 Epoch[27] Batch [840]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.249660,	
2017-07-18 03:33:44,393 Epoch[27] Batch [850]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.248457,	
2017-07-18 03:33:53,775 Epoch[27] Batch [860]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.248208,	
2017-07-18 03:34:02,865 Epoch[27] Batch [870]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.247045,	
2017-07-18 03:34:12,426 Epoch[27] Batch [880]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.247481,	
2017-07-18 03:34:21,767 Epoch[27] Batch [890]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.247226,	
2017-07-18 03:34:31,228 Epoch[27] Batch [900]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.247252,	
2017-07-18 03:34:40,570 Epoch[27] Batch [910]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.248612,	
2017-07-18 03:34:50,028 Epoch[27] Batch [920]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.247794,	
2017-07-18 03:34:59,456 Epoch[27] Batch [930]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.248686,	
2017-07-18 03:35:08,749 Epoch[27] Batch [940]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.249553,	
2017-07-18 03:35:18,211 Epoch[27] Batch [950]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.248780,	
2017-07-18 03:35:27,692 Epoch[27] Batch [960]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.248740,	
2017-07-18 03:35:37,278 Epoch[27] Batch [970]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.248437,	
2017-07-18 03:35:46,633 Epoch[27] Batch [980]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.248642,	
2017-07-18 03:35:56,238 Epoch[27] Batch [990]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.248470,	
2017-07-18 03:36:05,705 Epoch[27] Batch [1000]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.248017,	
2017-07-18 03:36:14,989 Epoch[27] Batch [1010]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.247532,	
2017-07-18 03:36:24,277 Epoch[27] Batch [1020]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.247138,	
2017-07-18 03:36:33,810 Epoch[27] Batch [1030]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.246419,	
2017-07-18 03:36:43,685 Epoch[27] Batch [1040]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.247522,	
2017-07-18 03:36:52,952 Epoch[27] Batch [1050]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.247768,	
2017-07-18 03:37:02,313 Epoch[27] Batch [1060]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.247772,	
2017-07-18 03:37:11,705 Epoch[27] Batch [1070]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.247932,	
2017-07-18 03:37:21,314 Epoch[27] Batch [1080]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.247423,	
2017-07-18 03:37:30,730 Epoch[27] Batch [1090]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.245990,	
2017-07-18 03:37:40,286 Epoch[27] Batch [1100]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.246292,	
2017-07-18 03:37:49,759 Epoch[27] Batch [1110]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.246541,	
2017-07-18 03:37:59,100 Epoch[27] Batch [1120]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.246771,	
2017-07-18 03:38:08,675 Epoch[27] Batch [1130]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.246229,	
2017-07-18 03:38:17,960 Epoch[27] Batch [1140]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.246026,	
2017-07-18 03:38:27,096 Epoch[27] Batch [1150]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.246496,	
2017-07-18 03:38:36,321 Epoch[27] Batch [1160]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.246176,	
2017-07-18 03:38:45,681 Epoch[27] Batch [1170]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.245839,	
2017-07-18 03:38:55,185 Epoch[27] Batch [1180]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.245302,	
2017-07-18 03:39:04,698 Epoch[27] Batch [1190]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.244844,	
2017-07-18 03:39:14,073 Epoch[27] Batch [1200]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.244491,	
2017-07-18 03:39:23,414 Epoch[27] Batch [1210]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.243946,	
2017-07-18 03:39:32,848 Epoch[27] Batch [1220]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.244168,	
2017-07-18 03:39:42,225 Epoch[27] Batch [1230]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.244243,	
2017-07-18 03:39:51,458 Epoch[27] Batch [1240]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.244096,	
2017-07-18 03:40:00,664 Epoch[27] Batch [1250]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.245538,	
2017-07-18 03:40:10,635 Epoch[27] Batch [1260]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.244949,	
2017-07-18 03:40:20,153 Epoch[27] Batch [1270]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.245020,	
2017-07-18 03:40:29,874 Epoch[27] Batch [1280]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.244740,	
2017-07-18 03:40:39,461 Epoch[27] Batch [1290]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.244071,	
2017-07-18 03:40:49,113 Epoch[27] Batch [1300]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.244149,	
2017-07-18 03:40:58,464 Epoch[27] Batch [1310]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.244313,	
2017-07-18 03:41:07,833 Epoch[27] Batch [1320]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.243704,	
2017-07-18 03:41:17,266 Epoch[27] Batch [1330]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.244210,	
2017-07-18 03:41:26,870 Epoch[27] Batch [1340]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.245080,	
2017-07-18 03:41:36,331 Epoch[27] Batch [1350]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.245441,	
2017-07-18 03:41:45,901 Epoch[27] Batch [1360]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.245526,	
2017-07-18 03:41:55,296 Epoch[27] Batch [1370]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.246059,	
2017-07-18 03:42:04,759 Epoch[27] Batch [1380]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.245318,	
2017-07-18 03:42:14,433 Epoch[27] Batch [1390]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.245040,	
2017-07-18 03:42:23,755 Epoch[27] Batch [1400]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.244835,	
2017-07-18 03:42:33,369 Epoch[27] Batch [1410]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.244980,	
2017-07-18 03:42:43,011 Epoch[27] Batch [1420]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.245023,	
2017-07-18 03:42:52,665 Epoch[27] Batch [1430]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.245401,	
2017-07-18 03:43:02,121 Epoch[27] Batch [1440]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.245102,	
2017-07-18 03:43:11,673 Epoch[27] Batch [1450]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.244712,	
2017-07-18 03:43:21,202 Epoch[27] Batch [1460]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.244097,	
2017-07-18 03:43:30,936 Epoch[27] Batch [1470]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.244219,	
2017-07-18 03:43:40,352 Epoch[27] Batch [1480]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.244376,	
2017-07-18 03:43:46,022 Epoch[27] Train-FCNLogLoss=1.244690
2017-07-18 03:43:46,022 Epoch[27] Time cost=1399.731
2017-07-18 03:43:47,138 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.params"
2017-07-18 03:43:51,556 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.states"
2017-07-18 03:44:01,620 Epoch[28] Batch [10]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.375449,	
2017-07-18 03:44:10,126 Epoch[28] Batch [20]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.288022,	
2017-07-18 03:44:18,876 Epoch[28] Batch [30]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.287983,	
2017-07-18 03:44:27,577 Epoch[28] Batch [40]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.300249,	
2017-07-18 03:44:36,586 Epoch[28] Batch [50]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.271566,	
2017-07-18 03:44:45,670 Epoch[28] Batch [60]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.277360,	
2017-07-18 03:44:54,087 Epoch[28] Batch [70]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.267807,	
2017-07-18 03:45:02,755 Epoch[28] Batch [80]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.253152,	
2017-07-18 03:45:11,531 Epoch[28] Batch [90]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.251984,	
2017-07-18 03:45:20,445 Epoch[28] Batch [100]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.244965,	
2017-07-18 03:45:29,405 Epoch[28] Batch [110]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.235072,	
2017-07-18 03:45:38,310 Epoch[28] Batch [120]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.238867,	
2017-07-18 03:45:47,108 Epoch[28] Batch [130]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.244356,	
2017-07-18 03:45:55,734 Epoch[28] Batch [140]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.243552,	
2017-07-18 03:46:04,142 Epoch[28] Batch [150]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.246065,	
2017-07-18 03:46:13,170 Epoch[28] Batch [160]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.240996,	
2017-07-18 03:46:21,810 Epoch[28] Batch [170]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.246731,	
2017-07-18 03:46:30,407 Epoch[28] Batch [180]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.243504,	
2017-07-18 03:46:39,155 Epoch[28] Batch [190]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.237772,	
2017-07-18 03:46:47,992 Epoch[28] Batch [200]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.233712,	
2017-07-18 03:46:56,927 Epoch[28] Batch [210]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.229122,	
2017-07-18 03:47:05,772 Epoch[28] Batch [220]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.230595,	
2017-07-18 03:47:14,672 Epoch[28] Batch [230]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.229616,	
2017-07-18 03:47:23,196 Epoch[28] Batch [240]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.235299,	
2017-07-18 03:47:32,186 Epoch[28] Batch [250]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.237712,	
2017-07-18 03:47:40,926 Epoch[28] Batch [260]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236384,	
2017-07-18 03:47:50,035 Epoch[28] Batch [270]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.235951,	
2017-07-18 03:47:58,670 Epoch[28] Batch [280]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.240264,	
2017-07-18 03:48:07,302 Epoch[28] Batch [290]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237629,	
2017-07-18 03:48:15,910 Epoch[28] Batch [300]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.235928,	
2017-07-18 03:48:24,809 Epoch[28] Batch [310]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.237036,	
2017-07-18 03:48:33,930 Epoch[28] Batch [320]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.236588,	
2017-07-18 03:48:42,250 Epoch[28] Batch [330]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.233827,	
2017-07-18 03:48:51,399 Epoch[28] Batch [340]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.236966,	
2017-07-18 03:49:00,259 Epoch[28] Batch [350]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.236028,	
2017-07-18 03:49:08,624 Epoch[28] Batch [360]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.235694,	
2017-07-18 03:49:17,114 Epoch[28] Batch [370]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.234454,	
2017-07-18 03:49:25,813 Epoch[28] Batch [380]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.234903,	
2017-07-18 03:49:34,616 Epoch[28] Batch [390]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.235320,	
2017-07-18 03:49:43,625 Epoch[28] Batch [400]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.236622,	
2017-07-18 03:49:52,038 Epoch[28] Batch [410]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.233739,	
2017-07-18 03:50:00,473 Epoch[28] Batch [420]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.234564,	
2017-07-18 03:50:08,877 Epoch[28] Batch [430]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.235417,	
2017-07-18 03:50:17,096 Epoch[28] Batch [440]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.235853,	
2017-07-18 03:50:25,730 Epoch[28] Batch [450]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.236861,	
2017-07-18 03:50:34,544 Epoch[28] Batch [460]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.235625,	
2017-07-18 03:50:43,496 Epoch[28] Batch [470]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.235400,	
2017-07-18 03:50:52,515 Epoch[28] Batch [480]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.234303,	
2017-07-18 03:51:01,301 Epoch[28] Batch [490]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.236319,	
2017-07-18 03:51:10,061 Epoch[28] Batch [500]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.235690,	
2017-07-18 03:51:18,897 Epoch[28] Batch [510]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.234303,	
2017-07-18 03:51:27,975 Epoch[28] Batch [520]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.234417,	
2017-07-18 03:51:36,819 Epoch[28] Batch [530]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.236024,	
2017-07-18 03:51:45,522 Epoch[28] Batch [540]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.235100,	
2017-07-18 03:51:54,396 Epoch[28] Batch [550]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.233809,	
2017-07-18 03:52:03,472 Epoch[28] Batch [560]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.236140,	
2017-07-18 03:52:12,343 Epoch[28] Batch [570]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.234531,	
2017-07-18 03:52:21,377 Epoch[28] Batch [580]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.233942,	
2017-07-18 03:52:30,624 Epoch[28] Batch [590]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.234262,	
2017-07-18 03:52:39,723 Epoch[28] Batch [600]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.235437,	
2017-07-18 03:52:48,892 Epoch[28] Batch [610]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.234688,	
2017-07-18 03:52:57,798 Epoch[28] Batch [620]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.232658,	
2017-07-18 03:53:06,695 Epoch[28] Batch [630]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.233999,	
2017-07-18 03:53:15,690 Epoch[28] Batch [640]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.233135,	
2017-07-18 03:53:24,635 Epoch[28] Batch [650]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.234030,	
2017-07-18 03:53:33,542 Epoch[28] Batch [660]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.233525,	
2017-07-18 03:53:42,728 Epoch[28] Batch [670]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.234623,	
2017-07-18 03:53:51,566 Epoch[28] Batch [680]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.234238,	
2017-07-18 03:54:00,672 Epoch[28] Batch [690]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.235221,	
2017-07-18 03:54:09,189 Epoch[28] Batch [700]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.236187,	
2017-07-18 03:54:18,049 Epoch[28] Batch [710]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.236562,	
2017-07-18 03:54:27,032 Epoch[28] Batch [720]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.236192,	
2017-07-18 03:54:36,444 Epoch[28] Batch [730]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.236131,	
2017-07-18 03:54:45,760 Epoch[28] Batch [740]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.236750,	
2017-07-18 03:54:55,042 Epoch[28] Batch [750]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.235958,	
2017-07-18 03:55:04,134 Epoch[28] Batch [760]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.234594,	
2017-07-18 03:55:12,817 Epoch[28] Batch [770]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.234400,	
2017-07-18 03:55:21,778 Epoch[28] Batch [780]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.235286,	
2017-07-18 03:55:31,252 Epoch[28] Batch [790]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.234308,	
2017-07-18 03:55:40,331 Epoch[28] Batch [800]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.233114,	
2017-07-18 03:55:49,460 Epoch[28] Batch [810]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.234306,	
2017-07-18 03:55:58,432 Epoch[28] Batch [820]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.234375,	
2017-07-18 03:56:07,440 Epoch[28] Batch [830]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.235407,	
2017-07-18 03:56:16,595 Epoch[28] Batch [840]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.237044,	
2017-07-18 03:56:25,849 Epoch[28] Batch [850]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.236575,	
2017-07-18 03:56:34,899 Epoch[28] Batch [860]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.235123,	
2017-07-18 03:56:44,101 Epoch[28] Batch [870]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.234475,	
2017-07-18 03:56:53,341 Epoch[28] Batch [880]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.234741,	
2017-07-18 03:57:02,643 Epoch[28] Batch [890]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.234913,	
2017-07-18 03:57:12,134 Epoch[28] Batch [900]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.234210,	
2017-07-18 03:57:21,229 Epoch[28] Batch [910]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.233211,	
2017-07-18 03:57:30,834 Epoch[28] Batch [920]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.233308,	
2017-07-18 03:57:40,289 Epoch[28] Batch [930]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.233640,	
2017-07-18 03:57:49,820 Epoch[28] Batch [940]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.234562,	
2017-07-18 03:57:59,350 Epoch[28] Batch [950]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.234721,	
2017-07-18 03:58:08,747 Epoch[28] Batch [960]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.235346,	
2017-07-18 03:58:17,725 Epoch[28] Batch [970]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.235076,	
2017-07-18 03:58:27,081 Epoch[28] Batch [980]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.234758,	
2017-07-18 03:58:36,555 Epoch[28] Batch [990]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.233980,	
2017-07-18 03:58:45,769 Epoch[28] Batch [1000]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.234559,	
2017-07-18 03:58:54,997 Epoch[28] Batch [1010]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.234752,	
2017-07-18 03:59:04,074 Epoch[28] Batch [1020]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.235705,	
2017-07-18 03:59:13,527 Epoch[28] Batch [1030]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.236168,	
2017-07-18 03:59:22,481 Epoch[28] Batch [1040]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.237165,	
2017-07-18 03:59:31,388 Epoch[28] Batch [1050]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.237767,	
2017-07-18 03:59:40,483 Epoch[28] Batch [1060]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.237436,	
2017-07-18 03:59:49,750 Epoch[28] Batch [1070]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.236606,	
2017-07-18 03:59:59,050 Epoch[28] Batch [1080]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.236193,	
2017-07-18 04:00:07,944 Epoch[28] Batch [1090]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.236173,	
2017-07-18 04:00:16,853 Epoch[28] Batch [1100]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.236838,	
2017-07-18 04:00:26,266 Epoch[28] Batch [1110]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.237511,	
2017-07-18 04:00:35,238 Epoch[28] Batch [1120]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.238169,	
2017-07-18 04:00:44,569 Epoch[28] Batch [1130]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237484,	
2017-07-18 04:00:53,516 Epoch[28] Batch [1140]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.237187,	
2017-07-18 04:01:02,695 Epoch[28] Batch [1150]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.237973,	
2017-07-18 04:01:12,018 Epoch[28] Batch [1160]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.238036,	
2017-07-18 04:01:20,828 Epoch[28] Batch [1170]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.237962,	
2017-07-18 04:01:29,784 Epoch[28] Batch [1180]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.237978,	
2017-07-18 04:01:38,456 Epoch[28] Batch [1190]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.237726,	
2017-07-18 04:01:47,686 Epoch[28] Batch [1200]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.238486,	
2017-07-18 04:01:56,798 Epoch[28] Batch [1210]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.238836,	
2017-07-18 04:02:05,852 Epoch[28] Batch [1220]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.239601,	
2017-07-18 04:02:16,772 Epoch[28] Batch [1230]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.239522,	
2017-07-18 04:02:26,232 Epoch[28] Batch [1240]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.239780,	
2017-07-18 04:02:35,741 Epoch[28] Batch [1250]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.239804,	
2017-07-18 04:02:44,986 Epoch[28] Batch [1260]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.240449,	
2017-07-18 04:02:54,405 Epoch[28] Batch [1270]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.240040,	
2017-07-18 04:03:03,862 Epoch[28] Batch [1280]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.240306,	
2017-07-18 04:03:13,455 Epoch[28] Batch [1290]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.239750,	
2017-07-18 04:03:22,763 Epoch[28] Batch [1300]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.239512,	
2017-07-18 04:03:32,525 Epoch[28] Batch [1310]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.239263,	
2017-07-18 04:03:41,996 Epoch[28] Batch [1320]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.239146,	
2017-07-18 04:03:51,667 Epoch[28] Batch [1330]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.239130,	
2017-07-18 04:04:01,154 Epoch[28] Batch [1340]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.239870,	
2017-07-18 04:04:10,566 Epoch[28] Batch [1350]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.239617,	
2017-07-18 04:04:19,909 Epoch[28] Batch [1360]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.239723,	
2017-07-18 04:04:28,947 Epoch[28] Batch [1370]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.238572,	
2017-07-18 04:04:38,122 Epoch[28] Batch [1380]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.237556,	
2017-07-18 04:04:47,303 Epoch[28] Batch [1390]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.236987,	
2017-07-18 04:04:56,594 Epoch[28] Batch [1400]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.236862,	
2017-07-18 04:05:05,707 Epoch[28] Batch [1410]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.236525,	
2017-07-18 04:05:15,047 Epoch[28] Batch [1420]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.236699,	
2017-07-18 04:05:24,004 Epoch[28] Batch [1430]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.236363,	
2017-07-18 04:05:33,263 Epoch[28] Batch [1440]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.236936,	
2017-07-18 04:05:42,429 Epoch[28] Batch [1450]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.236996,	
2017-07-18 04:05:51,869 Epoch[28] Batch [1460]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.237592,	
2017-07-18 04:06:01,346 Epoch[28] Batch [1470]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.238366,	
2017-07-18 04:06:10,574 Epoch[28] Batch [1480]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.238716,	
2017-07-18 04:06:16,139 Epoch[28] Train-FCNLogLoss=1.238966
2017-07-18 04:06:16,139 Epoch[28] Time cost=1344.358
2017-07-18 04:06:17,423 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.params"
2017-07-18 04:06:20,585 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.states"
2017-07-18 04:06:31,829 Epoch[29] Batch [10]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.183107,	
2017-07-18 04:06:40,651 Epoch[29] Batch [20]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.163193,	
2017-07-18 04:06:50,038 Epoch[29] Batch [30]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.207672,	
2017-07-18 04:06:59,314 Epoch[29] Batch [40]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.224529,	
2017-07-18 04:07:08,190 Epoch[29] Batch [50]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.242753,	
2017-07-18 04:07:17,266 Epoch[29] Batch [60]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.249275,	
2017-07-18 04:07:26,263 Epoch[29] Batch [70]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.252323,	
2017-07-18 04:07:35,230 Epoch[29] Batch [80]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.242970,	
2017-07-18 04:07:44,134 Epoch[29] Batch [90]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.244921,	
2017-07-18 04:07:52,937 Epoch[29] Batch [100]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.248776,	
2017-07-18 04:08:01,975 Epoch[29] Batch [110]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.255635,	
2017-07-18 04:08:11,171 Epoch[29] Batch [120]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.251837,	
2017-07-18 04:08:19,990 Epoch[29] Batch [130]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.253629,	
2017-07-18 04:08:29,006 Epoch[29] Batch [140]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.258959,	
2017-07-18 04:08:37,703 Epoch[29] Batch [150]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.261746,	
2017-07-18 04:08:46,244 Epoch[29] Batch [160]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.260129,	
2017-07-18 04:08:54,952 Epoch[29] Batch [170]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.257351,	
2017-07-18 04:09:03,496 Epoch[29] Batch [180]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.260802,	
2017-07-18 04:09:11,812 Epoch[29] Batch [190]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.257649,	
2017-07-18 04:09:20,480 Epoch[29] Batch [200]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.256239,	
2017-07-18 04:09:29,369 Epoch[29] Batch [210]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.259808,	
2017-07-18 04:09:38,522 Epoch[29] Batch [220]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.260315,	
2017-07-18 04:09:47,361 Epoch[29] Batch [230]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.258111,	
2017-07-18 04:09:56,129 Epoch[29] Batch [240]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.257862,	
2017-07-18 04:10:04,876 Epoch[29] Batch [250]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.257827,	
2017-07-18 04:10:13,679 Epoch[29] Batch [260]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.261201,	
2017-07-18 04:10:22,608 Epoch[29] Batch [270]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.261049,	
2017-07-18 04:10:31,358 Epoch[29] Batch [280]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.259909,	
2017-07-18 04:10:40,137 Epoch[29] Batch [290]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.256038,	
2017-07-18 04:10:49,013 Epoch[29] Batch [300]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.250464,	
2017-07-18 04:10:57,390 Epoch[29] Batch [310]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.250148,	
2017-07-18 04:11:06,152 Epoch[29] Batch [320]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.249558,	
2017-07-18 04:11:15,143 Epoch[29] Batch [330]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.250548,	
2017-07-18 04:11:23,986 Epoch[29] Batch [340]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.248130,	
2017-07-18 04:11:32,941 Epoch[29] Batch [350]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.246653,	
2017-07-18 04:11:41,868 Epoch[29] Batch [360]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.247006,	
2017-07-18 04:11:50,747 Epoch[29] Batch [370]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.246851,	
2017-07-18 04:11:59,492 Epoch[29] Batch [380]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.245241,	
2017-07-18 04:12:08,179 Epoch[29] Batch [390]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.247598,	
2017-07-18 04:12:17,170 Epoch[29] Batch [400]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.247365,	
2017-07-18 04:12:26,290 Epoch[29] Batch [410]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.246776,	
2017-07-18 04:12:35,217 Epoch[29] Batch [420]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.245261,	
2017-07-18 04:12:45,464 Epoch[29] Batch [430]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.244165,	
2017-07-18 04:12:55,294 Epoch[29] Batch [440]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.244694,	
2017-07-18 04:13:04,245 Epoch[29] Batch [450]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.245121,	
2017-07-18 04:13:13,132 Epoch[29] Batch [460]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.246800,	
2017-07-18 04:13:22,101 Epoch[29] Batch [470]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.247418,	
2017-07-18 04:13:30,905 Epoch[29] Batch [480]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.249955,	
2017-07-18 04:13:39,668 Epoch[29] Batch [490]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.248347,	
2017-07-18 04:13:48,698 Epoch[29] Batch [500]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.246935,	
2017-07-18 04:13:57,924 Epoch[29] Batch [510]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.247256,	
2017-07-18 04:14:07,097 Epoch[29] Batch [520]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.244687,	
2017-07-18 04:14:15,997 Epoch[29] Batch [530]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.246424,	
2017-07-18 04:14:24,759 Epoch[29] Batch [540]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.246546,	
2017-07-18 04:14:33,960 Epoch[29] Batch [550]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.245461,	
2017-07-18 04:14:42,904 Epoch[29] Batch [560]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.245232,	
2017-07-18 04:14:51,691 Epoch[29] Batch [570]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.244703,	
2017-07-18 04:15:00,600 Epoch[29] Batch [580]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.244567,	
2017-07-18 04:15:09,403 Epoch[29] Batch [590]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.244040,	
2017-07-18 04:15:18,350 Epoch[29] Batch [600]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.243725,	
2017-07-18 04:15:27,567 Epoch[29] Batch [610]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.243345,	
2017-07-18 04:15:36,760 Epoch[29] Batch [620]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.242083,	
2017-07-18 04:15:45,870 Epoch[29] Batch [630]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.242759,	
2017-07-18 04:15:54,899 Epoch[29] Batch [640]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.243005,	
2017-07-18 04:16:03,614 Epoch[29] Batch [650]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.244871,	
2017-07-18 04:16:12,296 Epoch[29] Batch [660]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.244820,	
2017-07-18 04:16:21,721 Epoch[29] Batch [670]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.243880,	
2017-07-18 04:16:30,779 Epoch[29] Batch [680]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.242436,	
2017-07-18 04:16:39,996 Epoch[29] Batch [690]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.243288,	
2017-07-18 04:16:49,146 Epoch[29] Batch [700]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.243378,	
2017-07-18 04:16:58,073 Epoch[29] Batch [710]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.242124,	
2017-07-18 04:17:07,094 Epoch[29] Batch [720]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242161,	
2017-07-18 04:17:16,300 Epoch[29] Batch [730]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.241488,	
2017-07-18 04:17:25,708 Epoch[29] Batch [740]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.242163,	
2017-07-18 04:17:34,762 Epoch[29] Batch [750]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.241800,	
2017-07-18 04:17:44,308 Epoch[29] Batch [760]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.242065,	
2017-07-18 04:17:53,393 Epoch[29] Batch [770]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.241242,	
2017-07-18 04:18:02,196 Epoch[29] Batch [780]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.242229,	
2017-07-18 04:18:11,015 Epoch[29] Batch [790]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.241781,	
2017-07-18 04:18:19,974 Epoch[29] Batch [800]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.241987,	
2017-07-18 04:18:29,421 Epoch[29] Batch [810]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.243813,	
2017-07-18 04:18:38,895 Epoch[29] Batch [820]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.244018,	
2017-07-18 04:18:47,871 Epoch[29] Batch [830]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.243459,	
2017-07-18 04:18:57,204 Epoch[29] Batch [840]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.243711,	
2017-07-18 04:19:06,217 Epoch[29] Batch [850]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242910,	
2017-07-18 04:19:15,380 Epoch[29] Batch [860]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.244037,	
2017-07-18 04:19:24,550 Epoch[29] Batch [870]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.243385,	
2017-07-18 04:19:34,301 Epoch[29] Batch [880]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.244615,	
2017-07-18 04:19:43,331 Epoch[29] Batch [890]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.244497,	
2017-07-18 04:19:52,801 Epoch[29] Batch [900]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.245079,	
2017-07-18 04:20:01,679 Epoch[29] Batch [910]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.244459,	
2017-07-18 04:20:10,960 Epoch[29] Batch [920]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.244891,	
2017-07-18 04:20:19,994 Epoch[29] Batch [930]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.246030,	
2017-07-18 04:20:28,732 Epoch[29] Batch [940]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.245693,	
2017-07-18 04:20:38,092 Epoch[29] Batch [950]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.245226,	
2017-07-18 04:20:47,191 Epoch[29] Batch [960]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.245082,	
2017-07-18 04:20:56,306 Epoch[29] Batch [970]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.245084,	
2017-07-18 04:21:05,244 Epoch[29] Batch [980]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.245256,	
2017-07-18 04:21:14,148 Epoch[29] Batch [990]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.245134,	
2017-07-18 04:21:22,957 Epoch[29] Batch [1000]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.246185,	
2017-07-18 04:21:31,853 Epoch[29] Batch [1010]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.245420,	
2017-07-18 04:21:41,296 Epoch[29] Batch [1020]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.245112,	
2017-07-18 04:21:50,615 Epoch[29] Batch [1030]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.245552,	
2017-07-18 04:22:00,178 Epoch[29] Batch [1040]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.245169,	
2017-07-18 04:22:09,458 Epoch[29] Batch [1050]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.244552,	
2017-07-18 04:22:18,859 Epoch[29] Batch [1060]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.243548,	
2017-07-18 04:22:28,065 Epoch[29] Batch [1070]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.243582,	
2017-07-18 04:22:37,299 Epoch[29] Batch [1080]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.243205,	
2017-07-18 04:22:46,593 Epoch[29] Batch [1090]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.243420,	
2017-07-18 04:22:55,571 Epoch[29] Batch [1100]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.242850,	
2017-07-18 04:23:04,647 Epoch[29] Batch [1110]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.243028,	
2017-07-18 04:23:14,042 Epoch[29] Batch [1120]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.242412,	
2017-07-18 04:23:23,059 Epoch[29] Batch [1130]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242789,	
2017-07-18 04:23:32,323 Epoch[29] Batch [1140]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.242905,	
2017-07-18 04:23:41,415 Epoch[29] Batch [1150]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.244351,	
2017-07-18 04:23:50,589 Epoch[29] Batch [1160]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.243814,	
2017-07-18 04:23:59,848 Epoch[29] Batch [1170]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.244507,	
2017-07-18 04:24:09,063 Epoch[29] Batch [1180]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.243690,	
2017-07-18 04:24:18,006 Epoch[29] Batch [1190]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.244130,	
2017-07-18 04:24:27,286 Epoch[29] Batch [1200]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.245117,	
2017-07-18 04:24:36,772 Epoch[29] Batch [1210]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.244844,	
2017-07-18 04:24:45,948 Epoch[29] Batch [1220]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.245039,	
2017-07-18 04:24:55,150 Epoch[29] Batch [1230]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.245271,	
2017-07-18 04:25:04,339 Epoch[29] Batch [1240]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.245170,	
2017-07-18 04:25:13,568 Epoch[29] Batch [1250]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.244883,	
2017-07-18 04:25:22,744 Epoch[29] Batch [1260]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.244249,	
2017-07-18 04:25:31,950 Epoch[29] Batch [1270]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.243667,	
2017-07-18 04:25:41,175 Epoch[29] Batch [1280]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.243900,	
2017-07-18 04:25:50,634 Epoch[29] Batch [1290]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.243961,	
2017-07-18 04:25:59,743 Epoch[29] Batch [1300]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.244025,	
2017-07-18 04:26:08,335 Epoch[29] Batch [1310]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.244029,	
2017-07-18 04:26:16,607 Epoch[29] Batch [1320]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.243558,	
2017-07-18 04:26:25,405 Epoch[29] Batch [1330]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.243820,	
2017-07-18 04:26:34,088 Epoch[29] Batch [1340]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.243696,	
2017-07-18 04:26:42,487 Epoch[29] Batch [1350]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.243455,	
2017-07-18 04:26:51,244 Epoch[29] Batch [1360]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.243033,	
2017-07-18 04:27:00,046 Epoch[29] Batch [1370]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.243158,	
2017-07-18 04:27:08,672 Epoch[29] Batch [1380]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.243463,	
2017-07-18 04:27:17,951 Epoch[29] Batch [1390]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.244085,	
2017-07-18 04:27:27,227 Epoch[29] Batch [1400]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.243478,	
2017-07-18 04:27:36,134 Epoch[29] Batch [1410]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.243236,	
2017-07-18 04:27:45,274 Epoch[29] Batch [1420]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.242769,	
2017-07-18 04:27:54,595 Epoch[29] Batch [1430]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.243297,	
2017-07-18 04:28:03,735 Epoch[29] Batch [1440]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.243246,	
2017-07-18 04:28:13,046 Epoch[29] Batch [1450]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.244276,	
2017-07-18 04:28:22,117 Epoch[29] Batch [1460]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.244026,	
2017-07-18 04:28:31,346 Epoch[29] Batch [1470]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.244387,	
2017-07-18 04:28:40,638 Epoch[29] Batch [1480]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.244908,	
2017-07-18 04:28:46,267 Epoch[29] Train-FCNLogLoss=1.245692
2017-07-18 04:28:46,267 Epoch[29] Time cost=1345.527
2017-07-18 04:28:47,849 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.params"
2017-07-18 04:28:51,503 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.states"
2017-07-18 04:29:01,716 Epoch[30] Batch [10]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.257918,	
2017-07-18 04:29:10,042 Epoch[30] Batch [20]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.271141,	
2017-07-18 04:29:18,195 Epoch[30] Batch [30]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.250365,	
2017-07-18 04:29:26,687 Epoch[30] Batch [40]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.252277,	
2017-07-18 04:29:35,186 Epoch[30] Batch [50]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.248785,	
2017-07-18 04:29:43,224 Epoch[30] Batch [60]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.251534,	
2017-07-18 04:29:51,323 Epoch[30] Batch [70]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.246743,	
2017-07-18 04:29:59,280 Epoch[30] Batch [80]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.244050,	
2017-07-18 04:30:08,058 Epoch[30] Batch [90]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.257458,	
2017-07-18 04:30:16,353 Epoch[30] Batch [100]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.266636,	
2017-07-18 04:30:24,956 Epoch[30] Batch [110]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.259334,	
2017-07-18 04:30:33,166 Epoch[30] Batch [120]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.251066,	
2017-07-18 04:30:41,379 Epoch[30] Batch [130]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.256777,	
2017-07-18 04:30:49,252 Epoch[30] Batch [140]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.256126,	
2017-07-18 04:30:57,719 Epoch[30] Batch [150]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.253456,	
2017-07-18 04:31:06,161 Epoch[30] Batch [160]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.252866,	
2017-07-18 04:31:14,265 Epoch[30] Batch [170]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.246089,	
2017-07-18 04:31:22,493 Epoch[30] Batch [180]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.244516,	
2017-07-18 04:31:30,761 Epoch[30] Batch [190]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.241908,	
2017-07-18 04:31:39,040 Epoch[30] Batch [200]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.240436,	
2017-07-18 04:31:46,978 Epoch[30] Batch [210]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.235718,	
2017-07-18 04:31:55,286 Epoch[30] Batch [220]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.236035,	
2017-07-18 04:32:03,675 Epoch[30] Batch [230]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.233617,	
2017-07-18 04:32:11,648 Epoch[30] Batch [240]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.231412,	
2017-07-18 04:32:19,913 Epoch[30] Batch [250]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.231015,	
2017-07-18 04:32:28,479 Epoch[30] Batch [260]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.230548,	
2017-07-18 04:32:36,891 Epoch[30] Batch [270]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.235178,	
2017-07-18 04:32:45,310 Epoch[30] Batch [280]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.234074,	
2017-07-18 04:32:53,871 Epoch[30] Batch [290]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.234277,	
2017-07-18 04:33:02,321 Epoch[30] Batch [300]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.234607,	
2017-07-18 04:33:10,716 Epoch[30] Batch [310]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.234933,	
2017-07-18 04:33:18,820 Epoch[30] Batch [320]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.231867,	
2017-07-18 04:33:27,426 Epoch[30] Batch [330]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.229818,	
2017-07-18 04:33:35,122 Epoch[30] Batch [340]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.229678,	
2017-07-18 04:33:43,565 Epoch[30] Batch [350]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.228084,	
2017-07-18 04:33:51,665 Epoch[30] Batch [360]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.228069,	
2017-07-18 04:34:00,469 Epoch[30] Batch [370]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.230052,	
2017-07-18 04:34:08,899 Epoch[30] Batch [380]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.231479,	
2017-07-18 04:34:17,291 Epoch[30] Batch [390]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.233887,	
2017-07-18 04:34:25,485 Epoch[30] Batch [400]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.235970,	
2017-07-18 04:34:34,223 Epoch[30] Batch [410]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236866,	
2017-07-18 04:34:42,454 Epoch[30] Batch [420]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.236943,	
2017-07-18 04:34:50,710 Epoch[30] Batch [430]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.236154,	
2017-07-18 04:34:59,353 Epoch[30] Batch [440]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.236089,	
2017-07-18 04:35:07,791 Epoch[30] Batch [450]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.235758,	
2017-07-18 04:35:16,544 Epoch[30] Batch [460]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.234743,	
2017-07-18 04:35:25,203 Epoch[30] Batch [470]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.235203,	
2017-07-18 04:35:33,617 Epoch[30] Batch [480]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.234839,	
2017-07-18 04:35:42,330 Epoch[30] Batch [490]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.235797,	
2017-07-18 04:35:50,832 Epoch[30] Batch [500]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.234737,	
2017-07-18 04:35:59,328 Epoch[30] Batch [510]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.235819,	
2017-07-18 04:36:07,687 Epoch[30] Batch [520]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.234641,	
2017-07-18 04:36:15,831 Epoch[30] Batch [530]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.234831,	
2017-07-18 04:36:24,718 Epoch[30] Batch [540]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.234097,	
2017-07-18 04:36:33,159 Epoch[30] Batch [550]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.235579,	
2017-07-18 04:36:41,330 Epoch[30] Batch [560]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.233925,	
2017-07-18 04:36:49,779 Epoch[30] Batch [570]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.234493,	
2017-07-18 04:36:58,256 Epoch[30] Batch [580]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.234941,	
2017-07-18 04:37:06,882 Epoch[30] Batch [590]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.235002,	
2017-07-18 04:37:15,048 Epoch[30] Batch [600]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.235576,	
2017-07-18 04:37:23,406 Epoch[30] Batch [610]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.236267,	
2017-07-18 04:37:31,921 Epoch[30] Batch [620]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.235416,	
2017-07-18 04:37:40,155 Epoch[30] Batch [630]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.235659,	
2017-07-18 04:37:48,611 Epoch[30] Batch [640]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.236561,	
2017-07-18 04:37:57,298 Epoch[30] Batch [650]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.236179,	
2017-07-18 04:38:05,612 Epoch[30] Batch [660]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.236578,	
2017-07-18 04:38:14,181 Epoch[30] Batch [670]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.236700,	
2017-07-18 04:38:23,594 Epoch[30] Batch [680]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.236230,	
2017-07-18 04:38:33,538 Epoch[30] Batch [690]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.235739,	
2017-07-18 04:38:42,820 Epoch[30] Batch [700]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.236765,	
2017-07-18 04:38:52,217 Epoch[30] Batch [710]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.237288,	
2017-07-18 04:39:01,596 Epoch[30] Batch [720]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.237143,	
2017-07-18 04:39:11,962 Epoch[30] Batch [730]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.236633,	
2017-07-18 04:39:23,041 Epoch[30] Batch [740]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.236366,	
2017-07-18 04:39:33,799 Epoch[30] Batch [750]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.236787,	
2017-07-18 04:39:44,166 Epoch[30] Batch [760]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.237682,	
2017-07-18 04:39:53,718 Epoch[30] Batch [770]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.237458,	
2017-07-18 04:40:04,283 Epoch[30] Batch [780]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.237742,	
2017-07-18 04:40:13,860 Epoch[30] Batch [790]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.238317,	
2017-07-18 04:40:23,610 Epoch[30] Batch [800]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.237697,	
2017-07-18 04:40:34,563 Epoch[30] Batch [810]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.238469,	
2017-07-18 04:40:45,691 Epoch[30] Batch [820]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.239314,	
2017-07-18 04:40:57,823 Epoch[30] Batch [830]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.238242,	
2017-07-18 04:41:07,137 Epoch[30] Batch [840]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.239785,	
2017-07-18 04:41:17,680 Epoch[30] Batch [850]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.240939,	
2017-07-18 04:41:27,989 Epoch[30] Batch [860]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.240017,	
2017-07-18 04:41:39,475 Epoch[30] Batch [870]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.239377,	
2017-07-18 04:41:53,121 Epoch[30] Batch [880]	Speed: 2.93 samples/sec	Train-FCNLogLoss=1.238907,	
2017-07-18 04:42:01,812 Epoch[30] Batch [890]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.239144,	
2017-07-18 04:42:11,886 Epoch[30] Batch [900]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.239076,	
2017-07-18 04:42:22,784 Epoch[30] Batch [910]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.238139,	
2017-07-18 04:42:32,146 Epoch[30] Batch [920]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.237899,	
2017-07-18 04:42:42,388 Epoch[30] Batch [930]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.237142,	
2017-07-18 04:42:51,705 Epoch[30] Batch [940]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.238566,	
2017-07-18 04:43:04,529 Epoch[30] Batch [950]	Speed: 3.12 samples/sec	Train-FCNLogLoss=1.238279,	
2017-07-18 04:43:14,841 Epoch[30] Batch [960]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.239440,	
2017-07-18 04:43:26,265 Epoch[30] Batch [970]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.239335,	
2017-07-18 04:43:38,399 Epoch[30] Batch [980]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.239594,	
2017-07-18 04:43:48,770 Epoch[30] Batch [990]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.239197,	
2017-07-18 04:43:58,254 Epoch[30] Batch [1000]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.239240,	
2017-07-18 04:44:08,892 Epoch[30] Batch [1010]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.239904,	
2017-07-18 04:44:21,133 Epoch[30] Batch [1020]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.240051,	
2017-07-18 04:44:30,876 Epoch[30] Batch [1030]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.241037,	
2017-07-18 04:44:41,818 Epoch[30] Batch [1040]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.241095,	
2017-07-18 04:44:52,239 Epoch[30] Batch [1050]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.241112,	
2017-07-18 04:45:01,602 Epoch[30] Batch [1060]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.241182,	
2017-07-18 04:45:12,365 Epoch[30] Batch [1070]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.240561,	
2017-07-18 04:45:22,596 Epoch[30] Batch [1080]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.240518,	
2017-07-18 04:45:34,184 Epoch[30] Batch [1090]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.241007,	
2017-07-18 04:45:43,722 Epoch[30] Batch [1100]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.241345,	
2017-07-18 04:45:54,073 Epoch[30] Batch [1110]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.241670,	
2017-07-18 04:46:06,302 Epoch[30] Batch [1120]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.241662,	
2017-07-18 04:46:17,904 Epoch[30] Batch [1130]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.241189,	
2017-07-18 04:46:28,895 Epoch[30] Batch [1140]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.240781,	
2017-07-18 04:46:39,897 Epoch[30] Batch [1150]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.240643,	
2017-07-18 04:46:50,775 Epoch[30] Batch [1160]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.240598,	
2017-07-18 04:47:01,296 Epoch[30] Batch [1170]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.240147,	
2017-07-18 04:47:12,019 Epoch[30] Batch [1180]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.240480,	
2017-07-18 04:47:22,477 Epoch[30] Batch [1190]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.240646,	
2017-07-18 04:47:33,259 Epoch[30] Batch [1200]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.240775,	
2017-07-18 04:47:43,484 Epoch[30] Batch [1210]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.240797,	
2017-07-18 04:47:54,530 Epoch[30] Batch [1220]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.240855,	
2017-07-18 04:48:05,340 Epoch[30] Batch [1230]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.241251,	
2017-07-18 04:48:16,208 Epoch[30] Batch [1240]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.241458,	
2017-07-18 04:48:26,730 Epoch[30] Batch [1250]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.240975,	
2017-07-18 04:48:37,276 Epoch[30] Batch [1260]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.240918,	
2017-07-18 04:48:47,601 Epoch[30] Batch [1270]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.240454,	
2017-07-18 04:48:57,731 Epoch[30] Batch [1280]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.240158,	
2017-07-18 04:49:08,830 Epoch[30] Batch [1290]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.239767,	
2017-07-18 04:49:20,474 Epoch[30] Batch [1300]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.239776,	
2017-07-18 04:49:32,216 Epoch[30] Batch [1310]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.240272,	
2017-07-18 04:49:42,391 Epoch[30] Batch [1320]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.240336,	
2017-07-18 04:49:52,940 Epoch[30] Batch [1330]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.239351,	
2017-07-18 04:50:03,491 Epoch[30] Batch [1340]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.239313,	
2017-07-18 04:50:13,107 Epoch[30] Batch [1350]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.240037,	
2017-07-18 04:50:22,764 Epoch[30] Batch [1360]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.239735,	
2017-07-18 04:50:34,104 Epoch[30] Batch [1370]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.239578,	
2017-07-18 04:50:44,238 Epoch[30] Batch [1380]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.239160,	
2017-07-18 04:50:54,289 Epoch[30] Batch [1390]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.239592,	
2017-07-18 04:51:03,901 Epoch[30] Batch [1400]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.239498,	
2017-07-18 04:51:16,851 Epoch[30] Batch [1410]	Speed: 3.09 samples/sec	Train-FCNLogLoss=1.239059,	
2017-07-18 04:51:28,831 Epoch[30] Batch [1420]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.238819,	
2017-07-18 04:51:39,488 Epoch[30] Batch [1430]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.238913,	
2017-07-18 04:51:50,438 Epoch[30] Batch [1440]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.238383,	
2017-07-18 04:52:02,117 Epoch[30] Batch [1450]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.238970,	
2017-07-18 04:52:12,484 Epoch[30] Batch [1460]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.238722,	
2017-07-18 04:52:23,966 Epoch[30] Batch [1470]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.238756,	
2017-07-18 04:52:36,282 Epoch[30] Batch [1480]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.238948,	
2017-07-18 04:52:43,723 Epoch[30] Train-FCNLogLoss=1.238871
2017-07-18 04:52:43,723 Epoch[30] Time cost=1432.071
2017-07-18 04:52:45,118 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.params"
2017-07-18 04:52:48,507 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.states"
2017-07-18 04:53:01,508 Epoch[31] Batch [10]	Speed: 3.42 samples/sec	Train-FCNLogLoss=1.258273,	
2017-07-18 04:53:12,502 Epoch[31] Batch [20]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.264753,	
2017-07-18 04:53:21,169 Epoch[31] Batch [30]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239733,	
2017-07-18 04:53:30,772 Epoch[31] Batch [40]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.217778,	
2017-07-18 04:53:40,198 Epoch[31] Batch [50]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.235297,	
2017-07-18 04:53:51,102 Epoch[31] Batch [60]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.230821,	
2017-07-18 04:54:02,618 Epoch[31] Batch [70]	Speed: 3.47 samples/sec	Train-FCNLogLoss=1.241739,	
2017-07-18 04:54:15,143 Epoch[31] Batch [80]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.248322,	
2017-07-18 04:54:24,267 Epoch[31] Batch [90]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.238210,	
2017-07-18 04:54:34,306 Epoch[31] Batch [100]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.229789,	
2017-07-18 04:54:44,913 Epoch[31] Batch [110]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.222569,	
2017-07-18 04:54:55,269 Epoch[31] Batch [120]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.229895,	
2017-07-18 04:55:06,012 Epoch[31] Batch [130]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.232295,	
2017-07-18 04:55:15,205 Epoch[31] Batch [140]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.240787,	
2017-07-18 04:55:25,211 Epoch[31] Batch [150]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.238243,	
2017-07-18 04:55:35,387 Epoch[31] Batch [160]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.231178,	
2017-07-18 04:55:46,380 Epoch[31] Batch [170]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.234002,	
2017-07-18 04:55:56,957 Epoch[31] Batch [180]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.235116,	
2017-07-18 04:56:07,760 Epoch[31] Batch [190]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.236596,	
2017-07-18 04:56:20,191 Epoch[31] Batch [200]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.238336,	
2017-07-18 04:56:29,773 Epoch[31] Batch [210]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.235563,	
2017-07-18 04:56:39,668 Epoch[31] Batch [220]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.239817,	
2017-07-18 04:56:52,196 Epoch[31] Batch [230]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.236956,	
2017-07-18 04:57:02,171 Epoch[31] Batch [240]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.240378,	
2017-07-18 04:57:11,352 Epoch[31] Batch [250]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.238052,	
2017-07-18 04:57:23,508 Epoch[31] Batch [260]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.236615,	
2017-07-18 04:57:34,716 Epoch[31] Batch [270]	Speed: 3.57 samples/sec	Train-FCNLogLoss=1.236730,	
2017-07-18 04:57:46,423 Epoch[31] Batch [280]	Speed: 3.42 samples/sec	Train-FCNLogLoss=1.237163,	
2017-07-18 04:57:57,238 Epoch[31] Batch [290]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.239624,	
2017-07-18 04:58:07,836 Epoch[31] Batch [300]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.237167,	
2017-07-18 04:58:18,928 Epoch[31] Batch [310]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.235790,	
2017-07-18 04:58:30,282 Epoch[31] Batch [320]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.232981,	
2017-07-18 04:58:41,763 Epoch[31] Batch [330]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.234606,	
2017-07-18 04:58:55,218 Epoch[31] Batch [340]	Speed: 2.97 samples/sec	Train-FCNLogLoss=1.234455,	
2017-07-18 04:59:06,698 Epoch[31] Batch [350]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.233757,	
2017-07-18 04:59:16,308 Epoch[31] Batch [360]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.233285,	
2017-07-18 04:59:27,056 Epoch[31] Batch [370]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.230404,	
2017-07-18 04:59:37,468 Epoch[31] Batch [380]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.233110,	
2017-07-18 04:59:47,942 Epoch[31] Batch [390]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.232532,	
2017-07-18 04:59:58,378 Epoch[31] Batch [400]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.235199,	
2017-07-18 05:00:09,146 Epoch[31] Batch [410]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.234806,	
2017-07-18 05:00:20,345 Epoch[31] Batch [420]	Speed: 3.57 samples/sec	Train-FCNLogLoss=1.235209,	
2017-07-18 05:00:30,488 Epoch[31] Batch [430]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.235829,	
2017-07-18 05:00:41,501 Epoch[31] Batch [440]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.235788,	
2017-07-18 05:00:52,086 Epoch[31] Batch [450]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.234285,	
2017-07-18 05:01:03,578 Epoch[31] Batch [460]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.235386,	
2017-07-18 05:01:12,171 Epoch[31] Batch [470]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.235744,	
2017-07-18 05:01:20,789 Epoch[31] Batch [480]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.235254,	
2017-07-18 05:01:29,585 Epoch[31] Batch [490]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.234553,	
2017-07-18 05:01:37,782 Epoch[31] Batch [500]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.232399,	
2017-07-18 05:01:46,423 Epoch[31] Batch [510]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.230370,	
2017-07-18 05:01:54,950 Epoch[31] Batch [520]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.230182,	
2017-07-18 05:02:03,699 Epoch[31] Batch [530]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.232654,	
2017-07-18 05:02:12,316 Epoch[31] Batch [540]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.232135,	
2017-07-18 05:02:21,181 Epoch[31] Batch [550]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.233430,	
2017-07-18 05:02:29,766 Epoch[31] Batch [560]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.233147,	
2017-07-18 05:02:38,487 Epoch[31] Batch [570]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.232022,	
2017-07-18 05:02:47,292 Epoch[31] Batch [580]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.232112,	
2017-07-18 05:02:55,861 Epoch[31] Batch [590]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.229694,	
2017-07-18 05:03:04,698 Epoch[31] Batch [600]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.230226,	
2017-07-18 05:03:13,113 Epoch[31] Batch [610]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.229732,	
2017-07-18 05:03:21,675 Epoch[31] Batch [620]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.229504,	
2017-07-18 05:03:30,296 Epoch[31] Batch [630]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.230564,	
2017-07-18 05:03:39,010 Epoch[31] Batch [640]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.232449,	
2017-07-18 05:03:47,714 Epoch[31] Batch [650]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.232302,	
2017-07-18 05:03:56,203 Epoch[31] Batch [660]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.232194,	
2017-07-18 05:04:04,782 Epoch[31] Batch [670]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.230924,	
2017-07-18 05:04:16,553 Epoch[31] Batch [680]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.232235,	
2017-07-18 05:04:25,402 Epoch[31] Batch [690]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.232230,	
2017-07-18 05:04:33,862 Epoch[31] Batch [700]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.232628,	
2017-07-18 05:04:42,444 Epoch[31] Batch [710]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.232455,	
2017-07-18 05:04:51,448 Epoch[31] Batch [720]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.234883,	
2017-07-18 05:04:59,996 Epoch[31] Batch [730]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.235463,	
2017-07-18 05:05:08,680 Epoch[31] Batch [740]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.235894,	
2017-07-18 05:05:17,170 Epoch[31] Batch [750]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.234528,	
2017-07-18 05:05:25,809 Epoch[31] Batch [760]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.234799,	
2017-07-18 05:05:34,449 Epoch[31] Batch [770]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.233479,	
2017-07-18 05:05:42,936 Epoch[31] Batch [780]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.233177,	
2017-07-18 05:05:51,320 Epoch[31] Batch [790]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.232888,	
2017-07-18 05:05:59,745 Epoch[31] Batch [800]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.232599,	
2017-07-18 05:06:08,372 Epoch[31] Batch [810]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.234388,	
2017-07-18 05:06:16,777 Epoch[31] Batch [820]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.234639,	
2017-07-18 05:06:24,904 Epoch[31] Batch [830]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.235471,	
2017-07-18 05:06:33,029 Epoch[31] Batch [840]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.235957,	
2017-07-18 05:06:41,542 Epoch[31] Batch [850]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.235529,	
2017-07-18 05:06:49,645 Epoch[31] Batch [860]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.234324,	
2017-07-18 05:06:57,660 Epoch[31] Batch [870]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.237021,	
2017-07-18 05:07:05,816 Epoch[31] Batch [880]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.236803,	
2017-07-18 05:07:14,138 Epoch[31] Batch [890]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.237062,	
2017-07-18 05:07:22,642 Epoch[31] Batch [900]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.236098,	
2017-07-18 05:07:30,791 Epoch[31] Batch [910]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.235100,	
2017-07-18 05:07:39,272 Epoch[31] Batch [920]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.234053,	
2017-07-18 05:07:47,791 Epoch[31] Batch [930]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.233180,	
2017-07-18 05:07:55,855 Epoch[31] Batch [940]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.232675,	
2017-07-18 05:08:04,088 Epoch[31] Batch [950]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.232676,	
2017-07-18 05:08:12,056 Epoch[31] Batch [960]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.233233,	
2017-07-18 05:08:20,132 Epoch[31] Batch [970]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.233542,	
2017-07-18 05:08:28,097 Epoch[31] Batch [980]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.233453,	
2017-07-18 05:08:36,266 Epoch[31] Batch [990]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.235286,	
2017-07-18 05:08:44,324 Epoch[31] Batch [1000]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.235065,	
2017-07-18 05:08:52,906 Epoch[31] Batch [1010]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.236152,	
2017-07-18 05:09:01,207 Epoch[31] Batch [1020]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.235538,	
2017-07-18 05:09:09,270 Epoch[31] Batch [1030]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.234975,	
2017-07-18 05:09:17,451 Epoch[31] Batch [1040]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.235281,	
2017-07-18 05:09:26,045 Epoch[31] Batch [1050]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.234461,	
2017-07-18 05:09:34,335 Epoch[31] Batch [1060]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.234004,	
2017-07-18 05:09:42,778 Epoch[31] Batch [1070]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.233395,	
2017-07-18 05:09:50,754 Epoch[31] Batch [1080]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.233358,	
2017-07-18 05:10:00,167 Epoch[31] Batch [1090]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.232696,	
2017-07-18 05:10:12,048 Epoch[31] Batch [1100]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.233351,	
2017-07-18 05:10:22,905 Epoch[31] Batch [1110]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.232946,	
2017-07-18 05:10:32,754 Epoch[31] Batch [1120]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.232027,	
2017-07-18 05:10:44,015 Epoch[31] Batch [1130]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.231208,	
2017-07-18 05:10:55,326 Epoch[31] Batch [1140]	Speed: 3.54 samples/sec	Train-FCNLogLoss=1.232273,	
2017-07-18 05:11:05,927 Epoch[31] Batch [1150]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.232165,	
2017-07-18 05:11:15,771 Epoch[31] Batch [1160]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.231886,	
2017-07-18 05:11:27,375 Epoch[31] Batch [1170]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.232657,	
2017-07-18 05:11:38,315 Epoch[31] Batch [1180]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.233848,	
2017-07-18 05:11:48,533 Epoch[31] Batch [1190]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.233920,	
2017-07-18 05:11:58,560 Epoch[31] Batch [1200]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.234170,	
2017-07-18 05:12:07,674 Epoch[31] Batch [1210]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.234377,	
2017-07-18 05:12:17,214 Epoch[31] Batch [1220]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.233640,	
2017-07-18 05:12:27,053 Epoch[31] Batch [1230]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.234263,	
2017-07-18 05:12:37,228 Epoch[31] Batch [1240]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.233725,	
2017-07-18 05:12:47,562 Epoch[31] Batch [1250]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.233348,	
2017-07-18 05:12:58,472 Epoch[31] Batch [1260]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.234031,	
2017-07-18 05:13:09,128 Epoch[31] Batch [1270]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.234206,	
2017-07-18 05:13:20,453 Epoch[31] Batch [1280]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.234436,	
2017-07-18 05:13:31,836 Epoch[31] Batch [1290]	Speed: 3.51 samples/sec	Train-FCNLogLoss=1.234665,	
2017-07-18 05:13:41,033 Epoch[31] Batch [1300]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.235195,	
2017-07-18 05:13:54,879 Epoch[31] Batch [1310]	Speed: 2.89 samples/sec	Train-FCNLogLoss=1.236160,	
2017-07-18 05:14:04,352 Epoch[31] Batch [1320]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.236626,	
2017-07-18 05:14:15,194 Epoch[31] Batch [1330]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.236861,	
2017-07-18 05:14:26,730 Epoch[31] Batch [1340]	Speed: 3.47 samples/sec	Train-FCNLogLoss=1.236925,	
2017-07-18 05:14:37,066 Epoch[31] Batch [1350]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.236962,	
2017-07-18 05:14:48,102 Epoch[31] Batch [1360]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.236659,	
2017-07-18 05:14:57,762 Epoch[31] Batch [1370]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.236504,	
2017-07-18 05:15:09,513 Epoch[31] Batch [1380]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.236339,	
2017-07-18 05:15:20,228 Epoch[31] Batch [1390]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.235831,	
2017-07-18 05:15:30,338 Epoch[31] Batch [1400]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.236218,	
2017-07-18 05:15:40,560 Epoch[31] Batch [1410]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.236047,	
2017-07-18 05:15:49,820 Epoch[31] Batch [1420]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.236192,	
2017-07-18 05:16:00,090 Epoch[31] Batch [1430]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.236746,	
2017-07-18 05:16:12,935 Epoch[31] Batch [1440]	Speed: 3.11 samples/sec	Train-FCNLogLoss=1.237682,	
2017-07-18 05:16:25,177 Epoch[31] Batch [1450]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.237686,	
2017-07-18 05:16:34,806 Epoch[31] Batch [1460]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.237687,	
2017-07-18 05:16:45,828 Epoch[31] Batch [1470]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.237705,	
2017-07-18 05:16:55,733 Epoch[31] Batch [1480]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.237690,	
2017-07-18 05:17:01,744 Epoch[31] Train-FCNLogLoss=1.237250
2017-07-18 05:17:01,745 Epoch[31] Time cost=1453.085
2017-07-18 05:17:02,952 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.params"
2017-07-18 05:17:05,322 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.states"
2017-07-18 05:17:16,951 Epoch[32] Batch [10]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.235871,	
2017-07-18 05:17:28,279 Epoch[32] Batch [20]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.234328,	
2017-07-18 05:17:38,569 Epoch[32] Batch [30]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.246711,	
2017-07-18 05:17:49,712 Epoch[32] Batch [40]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.224982,	
2017-07-18 05:17:59,295 Epoch[32] Batch [50]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.255116,	
2017-07-18 05:18:07,582 Epoch[32] Batch [60]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.245445,	
2017-07-18 05:18:16,975 Epoch[32] Batch [70]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.247620,	
2017-07-18 05:18:27,718 Epoch[32] Batch [80]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.237756,	
2017-07-18 05:18:38,145 Epoch[32] Batch [90]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.241293,	
2017-07-18 05:18:49,270 Epoch[32] Batch [100]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.238604,	
2017-07-18 05:18:58,869 Epoch[32] Batch [110]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.236685,	
2017-07-18 05:19:09,058 Epoch[32] Batch [120]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.229947,	
2017-07-18 05:19:18,939 Epoch[32] Batch [130]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.233706,	
2017-07-18 05:19:29,656 Epoch[32] Batch [140]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.242869,	
2017-07-18 05:19:39,799 Epoch[32] Batch [150]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.240779,	
2017-07-18 05:19:50,187 Epoch[32] Batch [160]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.239478,	
2017-07-18 05:20:01,485 Epoch[32] Batch [170]	Speed: 3.54 samples/sec	Train-FCNLogLoss=1.239481,	
2017-07-18 05:20:11,320 Epoch[32] Batch [180]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.237343,	
2017-07-18 05:20:22,992 Epoch[32] Batch [190]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.229997,	
2017-07-18 05:20:33,819 Epoch[32] Batch [200]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.229080,	
2017-07-18 05:20:44,996 Epoch[32] Batch [210]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.227922,	
2017-07-18 05:20:54,695 Epoch[32] Batch [220]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.228377,	
2017-07-18 05:21:03,609 Epoch[32] Batch [230]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.229593,	
2017-07-18 05:21:13,621 Epoch[32] Batch [240]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.225635,	
2017-07-18 05:21:24,830 Epoch[32] Batch [250]	Speed: 3.57 samples/sec	Train-FCNLogLoss=1.225837,	
2017-07-18 05:21:35,557 Epoch[32] Batch [260]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.227384,	
2017-07-18 05:21:44,610 Epoch[32] Batch [270]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.231302,	
2017-07-18 05:21:53,669 Epoch[32] Batch [280]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.228129,	
2017-07-18 05:22:04,992 Epoch[32] Batch [290]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.225158,	
2017-07-18 05:22:16,541 Epoch[32] Batch [300]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.224503,	
2017-07-18 05:22:26,635 Epoch[32] Batch [310]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.224244,	
2017-07-18 05:22:36,847 Epoch[32] Batch [320]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.223746,	
2017-07-18 05:22:47,075 Epoch[32] Batch [330]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.223215,	
2017-07-18 05:22:56,473 Epoch[32] Batch [340]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.225145,	
2017-07-18 05:23:06,354 Epoch[32] Batch [350]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.230104,	
2017-07-18 05:23:17,428 Epoch[32] Batch [360]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.231773,	
2017-07-18 05:23:27,476 Epoch[32] Batch [370]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.232547,	
2017-07-18 05:23:39,139 Epoch[32] Batch [380]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.233819,	
2017-07-18 05:23:48,575 Epoch[32] Batch [390]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.235080,	
2017-07-18 05:23:58,869 Epoch[32] Batch [400]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.236049,	
2017-07-18 05:24:09,791 Epoch[32] Batch [410]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.234617,	
2017-07-18 05:24:20,157 Epoch[32] Batch [420]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.234907,	
2017-07-18 05:24:30,362 Epoch[32] Batch [430]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.233870,	
2017-07-18 05:24:40,253 Epoch[32] Batch [440]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.234266,	
2017-07-18 05:24:52,539 Epoch[32] Batch [450]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.235942,	
2017-07-18 05:25:01,153 Epoch[32] Batch [460]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.234791,	
2017-07-18 05:25:09,703 Epoch[32] Batch [470]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.234996,	
2017-07-18 05:25:17,885 Epoch[32] Batch [480]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.233846,	
2017-07-18 05:25:26,058 Epoch[32] Batch [490]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.233802,	
2017-07-18 05:25:34,151 Epoch[32] Batch [500]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.233742,	
2017-07-18 05:25:42,316 Epoch[32] Batch [510]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.235483,	
2017-07-18 05:25:50,353 Epoch[32] Batch [520]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.235872,	
2017-07-18 05:25:59,380 Epoch[32] Batch [530]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.237776,	
2017-07-18 05:26:07,104 Epoch[32] Batch [540]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.238987,	
2017-07-18 05:26:15,580 Epoch[32] Batch [550]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.238940,	
2017-07-18 05:26:23,612 Epoch[32] Batch [560]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.239700,	
2017-07-18 05:26:31,511 Epoch[32] Batch [570]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.238181,	
2017-07-18 05:26:39,909 Epoch[32] Batch [580]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.239780,	
2017-07-18 05:26:48,435 Epoch[32] Batch [590]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.239864,	
2017-07-18 05:26:56,927 Epoch[32] Batch [600]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.239152,	
2017-07-18 05:27:04,984 Epoch[32] Batch [610]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.239375,	
2017-07-18 05:27:12,971 Epoch[32] Batch [620]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.237740,	
2017-07-18 05:27:21,138 Epoch[32] Batch [630]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.236966,	
2017-07-18 05:27:29,640 Epoch[32] Batch [640]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.236966,	
2017-07-18 05:27:37,974 Epoch[32] Batch [650]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.235261,	
2017-07-18 05:27:46,045 Epoch[32] Batch [660]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.237000,	
2017-07-18 05:27:54,196 Epoch[32] Batch [670]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.238187,	
2017-07-18 05:28:02,514 Epoch[32] Batch [680]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.238318,	
2017-07-18 05:28:10,805 Epoch[32] Batch [690]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.239292,	
2017-07-18 05:28:19,327 Epoch[32] Batch [700]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.238676,	
2017-07-18 05:28:27,548 Epoch[32] Batch [710]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.237589,	
2017-07-18 05:28:35,826 Epoch[32] Batch [720]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.239104,	
2017-07-18 05:28:44,019 Epoch[32] Batch [730]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.239683,	
2017-07-18 05:28:52,061 Epoch[32] Batch [740]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.239577,	
2017-07-18 05:28:59,888 Epoch[32] Batch [750]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.239173,	
2017-07-18 05:29:07,958 Epoch[32] Batch [760]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.239462,	
2017-07-18 05:29:16,239 Epoch[32] Batch [770]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.240265,	
2017-07-18 05:29:24,476 Epoch[32] Batch [780]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.240747,	
2017-07-18 05:29:32,881 Epoch[32] Batch [790]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.240661,	
2017-07-18 05:29:40,979 Epoch[32] Batch [800]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.239786,	
2017-07-18 05:29:49,188 Epoch[32] Batch [810]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.240498,	
2017-07-18 05:29:57,094 Epoch[32] Batch [820]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.241234,	
2017-07-18 05:30:04,574 Epoch[32] Batch [830]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.240940,	
2017-07-18 05:30:12,594 Epoch[32] Batch [840]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.241447,	
2017-07-18 05:30:20,769 Epoch[32] Batch [850]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.240976,	
2017-07-18 05:30:28,931 Epoch[32] Batch [860]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.239144,	
2017-07-18 05:30:37,306 Epoch[32] Batch [870]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.238798,	
2017-07-18 05:30:45,136 Epoch[32] Batch [880]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.238528,	
2017-07-18 05:30:53,323 Epoch[32] Batch [890]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.239580,	
2017-07-18 05:31:01,644 Epoch[32] Batch [900]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.239200,	
2017-07-18 05:31:09,591 Epoch[32] Batch [910]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.239508,	
2017-07-18 05:31:17,641 Epoch[32] Batch [920]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.239305,	
2017-07-18 05:31:25,990 Epoch[32] Batch [930]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.239693,	
2017-07-18 05:31:33,973 Epoch[32] Batch [940]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.239108,	
2017-07-18 05:31:42,377 Epoch[32] Batch [950]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.239702,	
2017-07-18 05:31:50,477 Epoch[32] Batch [960]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.238943,	
2017-07-18 05:31:58,523 Epoch[32] Batch [970]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.238890,	
2017-07-18 05:32:06,921 Epoch[32] Batch [980]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.238390,	
2017-07-18 05:32:14,873 Epoch[32] Batch [990]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.238863,	
2017-07-18 05:32:22,996 Epoch[32] Batch [1000]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.238383,	
2017-07-18 05:32:31,199 Epoch[32] Batch [1010]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.237536,	
2017-07-18 05:32:39,669 Epoch[32] Batch [1020]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.236740,	
2017-07-18 05:32:48,248 Epoch[32] Batch [1030]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.236746,	
2017-07-18 05:32:56,586 Epoch[32] Batch [1040]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.237258,	
2017-07-18 05:33:05,333 Epoch[32] Batch [1050]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238629,	
2017-07-18 05:33:13,461 Epoch[32] Batch [1060]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.238551,	
2017-07-18 05:33:24,392 Epoch[32] Batch [1070]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.239285,	
2017-07-18 05:33:34,353 Epoch[32] Batch [1080]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.238820,	
2017-07-18 05:33:47,190 Epoch[32] Batch [1090]	Speed: 3.12 samples/sec	Train-FCNLogLoss=1.237589,	
2017-07-18 05:33:59,071 Epoch[32] Batch [1100]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.237771,	
2017-07-18 05:34:09,569 Epoch[32] Batch [1110]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.237421,	
2017-07-18 05:34:20,986 Epoch[32] Batch [1120]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.236800,	
2017-07-18 05:34:33,344 Epoch[32] Batch [1130]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.237492,	
2017-07-18 05:34:44,323 Epoch[32] Batch [1140]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.237124,	
2017-07-18 05:34:54,969 Epoch[32] Batch [1150]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.237516,	
2017-07-18 05:35:06,106 Epoch[32] Batch [1160]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.237861,	
2017-07-18 05:35:17,770 Epoch[32] Batch [1170]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.237641,	
2017-07-18 05:35:27,556 Epoch[32] Batch [1180]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.237054,	
2017-07-18 05:35:38,002 Epoch[32] Batch [1190]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.237658,	
2017-07-18 05:35:47,745 Epoch[32] Batch [1200]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.237465,	
2017-07-18 05:35:57,079 Epoch[32] Batch [1210]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237289,	
2017-07-18 05:36:06,261 Epoch[32] Batch [1220]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.236571,	
2017-07-18 05:36:17,677 Epoch[32] Batch [1230]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.237086,	
2017-07-18 05:36:27,270 Epoch[32] Batch [1240]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.235928,	
2017-07-18 05:36:37,969 Epoch[32] Batch [1250]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.236560,	
2017-07-18 05:36:46,932 Epoch[32] Batch [1260]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.235767,	
2017-07-18 05:36:58,299 Epoch[32] Batch [1270]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.235926,	
2017-07-18 05:37:09,728 Epoch[32] Batch [1280]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.236784,	
2017-07-18 05:37:18,303 Epoch[32] Batch [1290]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.237255,	
2017-07-18 05:37:26,801 Epoch[32] Batch [1300]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.237238,	
2017-07-18 05:37:34,729 Epoch[32] Batch [1310]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.237302,	
2017-07-18 05:37:43,077 Epoch[32] Batch [1320]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.236009,	
2017-07-18 05:37:51,663 Epoch[32] Batch [1330]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.236244,	
2017-07-18 05:38:00,017 Epoch[32] Batch [1340]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.236525,	
2017-07-18 05:38:08,135 Epoch[32] Batch [1350]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.236728,	
2017-07-18 05:38:16,806 Epoch[32] Batch [1360]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.236829,	
2017-07-18 05:38:25,645 Epoch[32] Batch [1370]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.236932,	
2017-07-18 05:38:33,515 Epoch[32] Batch [1380]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.236808,	
2017-07-18 05:38:42,098 Epoch[32] Batch [1390]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.236769,	
2017-07-18 05:38:50,535 Epoch[32] Batch [1400]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.236744,	
2017-07-18 05:38:59,068 Epoch[32] Batch [1410]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.236502,	
2017-07-18 05:39:07,748 Epoch[32] Batch [1420]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.236553,	
2017-07-18 05:39:16,504 Epoch[32] Batch [1430]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.236749,	
2017-07-18 05:39:24,961 Epoch[32] Batch [1440]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.237041,	
2017-07-18 05:39:33,618 Epoch[32] Batch [1450]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.236703,	
2017-07-18 05:39:42,253 Epoch[32] Batch [1460]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.236547,	
2017-07-18 05:39:50,993 Epoch[32] Batch [1470]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236624,	
2017-07-18 05:39:59,385 Epoch[32] Batch [1480]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.235640,	
2017-07-18 05:40:04,282 Epoch[32] Train-FCNLogLoss=1.235731
2017-07-18 05:40:04,283 Epoch[32] Time cost=1378.715
2017-07-18 05:40:05,323 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.params"
2017-07-18 05:40:08,342 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.states"
2017-07-18 05:40:18,615 Epoch[33] Batch [10]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.248465,	
2017-07-18 05:40:27,003 Epoch[33] Batch [20]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.206575,	
2017-07-18 05:40:35,755 Epoch[33] Batch [30]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.209002,	
2017-07-18 05:40:44,499 Epoch[33] Batch [40]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238494,	
2017-07-18 05:40:52,873 Epoch[33] Batch [50]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.234162,	
2017-07-18 05:41:01,294 Epoch[33] Batch [60]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.245945,	
2017-07-18 05:41:09,702 Epoch[33] Batch [70]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.246793,	
2017-07-18 05:41:18,212 Epoch[33] Batch [80]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.242853,	
2017-07-18 05:41:26,757 Epoch[33] Batch [90]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.239785,	
2017-07-18 05:41:37,114 Epoch[33] Batch [100]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.248078,	
2017-07-18 05:41:45,656 Epoch[33] Batch [110]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.242041,	
2017-07-18 05:41:53,934 Epoch[33] Batch [120]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.249553,	
2017-07-18 05:42:02,152 Epoch[33] Batch [130]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.249615,	
2017-07-18 05:42:10,547 Epoch[33] Batch [140]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.251469,	
2017-07-18 05:42:18,856 Epoch[33] Batch [150]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.250908,	
2017-07-18 05:42:27,478 Epoch[33] Batch [160]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.250030,	
2017-07-18 05:42:35,785 Epoch[33] Batch [170]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.248677,	
2017-07-18 05:42:44,311 Epoch[33] Batch [180]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.243619,	
2017-07-18 05:42:52,824 Epoch[33] Batch [190]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.251848,	
2017-07-18 05:43:01,379 Epoch[33] Batch [200]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.255923,	
2017-07-18 05:43:09,959 Epoch[33] Batch [210]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.255907,	
2017-07-18 05:43:18,476 Epoch[33] Batch [220]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.251556,	
2017-07-18 05:43:26,913 Epoch[33] Batch [230]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.255919,	
2017-07-18 05:43:35,529 Epoch[33] Batch [240]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.254657,	
2017-07-18 05:43:44,116 Epoch[33] Batch [250]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.255488,	
2017-07-18 05:43:52,658 Epoch[33] Batch [260]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.255392,	
2017-07-18 05:44:01,231 Epoch[33] Batch [270]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.259261,	
2017-07-18 05:44:09,660 Epoch[33] Batch [280]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.260362,	
2017-07-18 05:44:18,173 Epoch[33] Batch [290]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.258229,	
2017-07-18 05:44:26,633 Epoch[33] Batch [300]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.255242,	
2017-07-18 05:44:35,264 Epoch[33] Batch [310]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.254949,	
2017-07-18 05:44:43,543 Epoch[33] Batch [320]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.254645,	
2017-07-18 05:44:51,982 Epoch[33] Batch [330]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.253760,	
2017-07-18 05:44:59,997 Epoch[33] Batch [340]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.251398,	
2017-07-18 05:45:08,401 Epoch[33] Batch [350]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.256389,	
2017-07-18 05:45:16,827 Epoch[33] Batch [360]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.256068,	
2017-07-18 05:45:25,587 Epoch[33] Batch [370]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.254534,	
2017-07-18 05:45:34,245 Epoch[33] Batch [380]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.251743,	
2017-07-18 05:45:42,692 Epoch[33] Batch [390]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.252557,	
2017-07-18 05:45:51,308 Epoch[33] Batch [400]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.251428,	
2017-07-18 05:45:59,972 Epoch[33] Batch [410]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.250630,	
2017-07-18 05:46:08,620 Epoch[33] Batch [420]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.252251,	
2017-07-18 05:46:16,856 Epoch[33] Batch [430]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.253105,	
2017-07-18 05:46:25,132 Epoch[33] Batch [440]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.252348,	
2017-07-18 05:46:33,763 Epoch[33] Batch [450]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.250505,	
2017-07-18 05:46:42,182 Epoch[33] Batch [460]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.248294,	
2017-07-18 05:46:50,720 Epoch[33] Batch [470]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.248439,	
2017-07-18 05:46:59,414 Epoch[33] Batch [480]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.247149,	
2017-07-18 05:47:07,909 Epoch[33] Batch [490]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.245913,	
2017-07-18 05:47:16,077 Epoch[33] Batch [500]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.243852,	
2017-07-18 05:47:24,548 Epoch[33] Batch [510]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.244884,	
2017-07-18 05:47:32,986 Epoch[33] Batch [520]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.244571,	
2017-07-18 05:47:41,653 Epoch[33] Batch [530]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.243895,	
2017-07-18 05:47:49,917 Epoch[33] Batch [540]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.244477,	
2017-07-18 05:47:58,012 Epoch[33] Batch [550]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.242220,	
2017-07-18 05:48:06,401 Epoch[33] Batch [560]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.243310,	
2017-07-18 05:48:14,730 Epoch[33] Batch [570]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.242845,	
2017-07-18 05:48:23,324 Epoch[33] Batch [580]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.241922,	
2017-07-18 05:48:31,360 Epoch[33] Batch [590]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.242075,	
2017-07-18 05:48:39,429 Epoch[33] Batch [600]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.243230,	
2017-07-18 05:48:48,133 Epoch[33] Batch [610]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.242625,	
2017-07-18 05:48:56,482 Epoch[33] Batch [620]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.242512,	
2017-07-18 05:49:05,447 Epoch[33] Batch [630]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.243570,	
2017-07-18 05:49:13,579 Epoch[33] Batch [640]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.244755,	
2017-07-18 05:49:21,840 Epoch[33] Batch [650]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.243648,	
2017-07-18 05:49:30,388 Epoch[33] Batch [660]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.243028,	
2017-07-18 05:49:38,996 Epoch[33] Batch [670]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.243044,	
2017-07-18 05:49:47,431 Epoch[33] Batch [680]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.242162,	
2017-07-18 05:49:56,062 Epoch[33] Batch [690]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.241847,	
2017-07-18 05:50:04,570 Epoch[33] Batch [700]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.241240,	
2017-07-18 05:50:12,529 Epoch[33] Batch [710]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.241172,	
2017-07-18 05:50:21,253 Epoch[33] Batch [720]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.241735,	
2017-07-18 05:50:29,466 Epoch[33] Batch [730]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.241273,	
2017-07-18 05:50:38,139 Epoch[33] Batch [740]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.240348,	
2017-07-18 05:50:46,436 Epoch[33] Batch [750]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.240423,	
2017-07-18 05:50:54,784 Epoch[33] Batch [760]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.240449,	
2017-07-18 05:51:03,202 Epoch[33] Batch [770]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.240631,	
2017-07-18 05:51:11,435 Epoch[33] Batch [780]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.240359,	
2017-07-18 05:51:19,539 Epoch[33] Batch [790]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.239880,	
2017-07-18 05:51:28,123 Epoch[33] Batch [800]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.238726,	
2017-07-18 05:51:36,442 Epoch[33] Batch [810]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.238491,	
2017-07-18 05:51:45,025 Epoch[33] Batch [820]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.237839,	
2017-07-18 05:51:53,460 Epoch[33] Batch [830]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.238422,	
2017-07-18 05:52:01,821 Epoch[33] Batch [840]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.238723,	
2017-07-18 05:52:10,474 Epoch[33] Batch [850]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.238279,	
2017-07-18 05:52:19,258 Epoch[33] Batch [860]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.237525,	
2017-07-18 05:52:27,720 Epoch[33] Batch [870]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.237787,	
2017-07-18 05:52:35,996 Epoch[33] Batch [880]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.236648,	
2017-07-18 05:52:44,598 Epoch[33] Batch [890]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.235744,	
2017-07-18 05:52:53,292 Epoch[33] Batch [900]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.236485,	
2017-07-18 05:53:01,932 Epoch[33] Batch [910]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.235772,	
2017-07-18 05:53:10,420 Epoch[33] Batch [920]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.235342,	
2017-07-18 05:53:18,996 Epoch[33] Batch [930]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.235664,	
2017-07-18 05:53:27,397 Epoch[33] Batch [940]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.234497,	
2017-07-18 05:53:36,114 Epoch[33] Batch [950]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.234539,	
2017-07-18 05:53:44,980 Epoch[33] Batch [960]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.235405,	
2017-07-18 05:53:53,531 Epoch[33] Batch [970]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.235167,	
2017-07-18 05:54:01,733 Epoch[33] Batch [980]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.235080,	
2017-07-18 05:54:09,910 Epoch[33] Batch [990]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.234195,	
2017-07-18 05:54:18,555 Epoch[33] Batch [1000]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.234277,	
2017-07-18 05:54:27,087 Epoch[33] Batch [1010]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.234342,	
2017-07-18 05:54:36,019 Epoch[33] Batch [1020]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.233678,	
2017-07-18 05:54:44,389 Epoch[33] Batch [1030]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.232977,	
2017-07-18 05:54:52,681 Epoch[33] Batch [1040]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.233536,	
2017-07-18 05:55:01,232 Epoch[33] Batch [1050]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.233936,	
2017-07-18 05:55:09,490 Epoch[33] Batch [1060]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.233598,	
2017-07-18 05:55:18,159 Epoch[33] Batch [1070]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.233673,	
2017-07-18 05:55:26,655 Epoch[33] Batch [1080]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.233280,	
2017-07-18 05:55:35,155 Epoch[33] Batch [1090]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.233213,	
2017-07-18 05:55:43,647 Epoch[33] Batch [1100]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.233098,	
2017-07-18 05:55:52,442 Epoch[33] Batch [1110]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.234460,	
2017-07-18 05:56:00,926 Epoch[33] Batch [1120]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.234146,	
2017-07-18 05:56:09,340 Epoch[33] Batch [1130]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.234215,	
2017-07-18 05:56:17,910 Epoch[33] Batch [1140]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.234693,	
2017-07-18 05:56:26,404 Epoch[33] Batch [1150]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.234985,	
2017-07-18 05:56:34,798 Epoch[33] Batch [1160]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.235204,	
2017-07-18 05:56:43,044 Epoch[33] Batch [1170]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.235359,	
2017-07-18 05:56:51,837 Epoch[33] Batch [1180]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.235415,	
2017-07-18 05:56:59,959 Epoch[33] Batch [1190]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.234865,	
2017-07-18 05:57:08,113 Epoch[33] Batch [1200]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.235737,	
2017-07-18 05:57:17,059 Epoch[33] Batch [1210]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.235553,	
2017-07-18 05:57:25,758 Epoch[33] Batch [1220]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.234866,	
2017-07-18 05:57:34,328 Epoch[33] Batch [1230]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.235256,	
2017-07-18 05:57:42,700 Epoch[33] Batch [1240]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.235118,	
2017-07-18 05:57:51,452 Epoch[33] Batch [1250]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.235269,	
2017-07-18 05:58:00,058 Epoch[33] Batch [1260]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.236500,	
2017-07-18 05:58:08,511 Epoch[33] Batch [1270]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.236882,	
2017-07-18 05:58:17,156 Epoch[33] Batch [1280]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237304,	
2017-07-18 05:58:25,606 Epoch[33] Batch [1290]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.237158,	
2017-07-18 05:58:34,004 Epoch[33] Batch [1300]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.236870,	
2017-07-18 05:58:42,562 Epoch[33] Batch [1310]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.236715,	
2017-07-18 05:58:51,359 Epoch[33] Batch [1320]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.236682,	
2017-07-18 05:58:59,873 Epoch[33] Batch [1330]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.236593,	
2017-07-18 05:59:08,175 Epoch[33] Batch [1340]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.237371,	
2017-07-18 05:59:16,819 Epoch[33] Batch [1350]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237163,	
2017-07-18 05:59:25,719 Epoch[33] Batch [1360]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.237289,	
2017-07-18 05:59:34,645 Epoch[33] Batch [1370]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.237020,	
2017-07-18 05:59:43,377 Epoch[33] Batch [1380]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.236143,	
2017-07-18 05:59:51,886 Epoch[33] Batch [1390]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.235758,	
2017-07-18 06:00:00,307 Epoch[33] Batch [1400]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.235575,	
2017-07-18 06:00:08,999 Epoch[33] Batch [1410]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.235436,	
2017-07-18 06:00:17,219 Epoch[33] Batch [1420]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.235555,	
2017-07-18 06:00:25,888 Epoch[33] Batch [1430]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.235730,	
2017-07-18 06:00:34,552 Epoch[33] Batch [1440]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.236254,	
2017-07-18 06:00:42,956 Epoch[33] Batch [1450]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.236035,	
2017-07-18 06:00:51,367 Epoch[33] Batch [1460]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.236297,	
2017-07-18 06:00:59,884 Epoch[33] Batch [1470]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.235485,	
2017-07-18 06:01:08,259 Epoch[33] Batch [1480]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.235800,	
2017-07-18 06:01:13,341 Epoch[33] Train-FCNLogLoss=1.235776
2017-07-18 06:01:13,341 Epoch[33] Time cost=1264.809
2017-07-18 06:01:14,269 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.params"
2017-07-18 06:01:17,406 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.states"
2017-07-18 06:01:28,057 Epoch[34] Batch [10]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.296293,	
2017-07-18 06:01:36,888 Epoch[34] Batch [20]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.211996,	
2017-07-18 06:01:45,579 Epoch[34] Batch [30]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.207255,	
2017-07-18 06:01:54,818 Epoch[34] Batch [40]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.221688,	
2017-07-18 06:02:03,969 Epoch[34] Batch [50]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.219368,	
2017-07-18 06:02:13,104 Epoch[34] Batch [60]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.226610,	
2017-07-18 06:02:22,275 Epoch[34] Batch [70]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.236780,	
2017-07-18 06:02:32,455 Epoch[34] Batch [80]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.243465,	
2017-07-18 06:02:42,857 Epoch[34] Batch [90]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.235655,	
2017-07-18 06:02:54,313 Epoch[34] Batch [100]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.241445,	
2017-07-18 06:03:06,105 Epoch[34] Batch [110]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.258965,	
2017-07-18 06:03:15,627 Epoch[34] Batch [120]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.258406,	
2017-07-18 06:03:26,263 Epoch[34] Batch [130]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.259816,	
2017-07-18 06:03:36,676 Epoch[34] Batch [140]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.261082,	
2017-07-18 06:03:48,785 Epoch[34] Batch [150]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.264101,	
2017-07-18 06:04:00,453 Epoch[34] Batch [160]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.266769,	
2017-07-18 06:04:13,560 Epoch[34] Batch [170]	Speed: 3.05 samples/sec	Train-FCNLogLoss=1.266472,	
2017-07-18 06:04:25,340 Epoch[34] Batch [180]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.261606,	
2017-07-18 06:04:36,131 Epoch[34] Batch [190]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.261056,	
2017-07-18 06:04:47,691 Epoch[34] Batch [200]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.258723,	
2017-07-18 06:04:58,026 Epoch[34] Batch [210]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.256703,	
2017-07-18 06:05:09,456 Epoch[34] Batch [220]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.255736,	
2017-07-18 06:05:19,567 Epoch[34] Batch [230]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.252055,	
2017-07-18 06:05:31,302 Epoch[34] Batch [240]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.248412,	
2017-07-18 06:05:45,322 Epoch[34] Batch [250]	Speed: 2.85 samples/sec	Train-FCNLogLoss=1.246473,	
2017-07-18 06:05:55,991 Epoch[34] Batch [260]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.250832,	
2017-07-18 06:06:06,341 Epoch[34] Batch [270]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.253229,	
2017-07-18 06:06:16,078 Epoch[34] Batch [280]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.254152,	
2017-07-18 06:06:27,212 Epoch[34] Batch [290]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.250953,	
2017-07-18 06:06:38,078 Epoch[34] Batch [300]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.248532,	
2017-07-18 06:06:48,960 Epoch[34] Batch [310]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.248228,	
2017-07-18 06:06:59,346 Epoch[34] Batch [320]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.248355,	
2017-07-18 06:07:10,067 Epoch[34] Batch [330]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.250392,	
2017-07-18 06:07:21,595 Epoch[34] Batch [340]	Speed: 3.47 samples/sec	Train-FCNLogLoss=1.248103,	
2017-07-18 06:07:31,617 Epoch[34] Batch [350]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.250193,	
2017-07-18 06:07:42,283 Epoch[34] Batch [360]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.250282,	
2017-07-18 06:07:51,918 Epoch[34] Batch [370]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.249022,	
2017-07-18 06:08:04,118 Epoch[34] Batch [380]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.249357,	
2017-07-18 06:08:13,862 Epoch[34] Batch [390]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.249163,	
2017-07-18 06:08:25,422 Epoch[34] Batch [400]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.247974,	
2017-07-18 06:08:36,560 Epoch[34] Batch [410]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.246410,	
2017-07-18 06:08:47,396 Epoch[34] Batch [420]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.248741,	
2017-07-18 06:08:57,810 Epoch[34] Batch [430]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.249384,	
2017-07-18 06:09:07,548 Epoch[34] Batch [440]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.246469,	
2017-07-18 06:09:17,531 Epoch[34] Batch [450]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.244016,	
2017-07-18 06:09:28,503 Epoch[34] Batch [460]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.241133,	
2017-07-18 06:09:38,129 Epoch[34] Batch [470]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.240940,	
2017-07-18 06:09:49,268 Epoch[34] Batch [480]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.239177,	
2017-07-18 06:09:59,215 Epoch[34] Batch [490]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.241588,	
2017-07-18 06:10:11,871 Epoch[34] Batch [500]	Speed: 3.16 samples/sec	Train-FCNLogLoss=1.241100,	
2017-07-18 06:10:22,992 Epoch[34] Batch [510]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.240075,	
2017-07-18 06:10:33,927 Epoch[34] Batch [520]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.239759,	
2017-07-18 06:10:44,314 Epoch[34] Batch [530]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.238725,	
2017-07-18 06:10:54,753 Epoch[34] Batch [540]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.237481,	
2017-07-18 06:11:07,806 Epoch[34] Batch [550]	Speed: 3.06 samples/sec	Train-FCNLogLoss=1.236727,	
2017-07-18 06:11:18,630 Epoch[34] Batch [560]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.236304,	
2017-07-18 06:11:31,228 Epoch[34] Batch [570]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.237141,	
2017-07-18 06:11:42,262 Epoch[34] Batch [580]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.238143,	
2017-07-18 06:11:55,168 Epoch[34] Batch [590]	Speed: 3.10 samples/sec	Train-FCNLogLoss=1.237942,	
2017-07-18 06:12:07,728 Epoch[34] Batch [600]	Speed: 3.18 samples/sec	Train-FCNLogLoss=1.237824,	
2017-07-18 06:12:19,014 Epoch[34] Batch [610]	Speed: 3.54 samples/sec	Train-FCNLogLoss=1.238203,	
2017-07-18 06:12:29,336 Epoch[34] Batch [620]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.237994,	
2017-07-18 06:12:38,675 Epoch[34] Batch [630]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.238866,	
2017-07-18 06:12:49,383 Epoch[34] Batch [640]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.237868,	
2017-07-18 06:13:03,066 Epoch[34] Batch [650]	Speed: 2.92 samples/sec	Train-FCNLogLoss=1.237741,	
2017-07-18 06:13:14,233 Epoch[34] Batch [660]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.237621,	
2017-07-18 06:13:25,120 Epoch[34] Batch [670]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.236702,	
2017-07-18 06:13:35,953 Epoch[34] Batch [680]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.236889,	
2017-07-18 06:13:46,478 Epoch[34] Batch [690]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.236665,	
2017-07-18 06:13:57,149 Epoch[34] Batch [700]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.235531,	
2017-07-18 06:14:07,941 Epoch[34] Batch [710]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.236111,	
2017-07-18 06:14:18,076 Epoch[34] Batch [720]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.236381,	
2017-07-18 06:14:27,960 Epoch[34] Batch [730]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.237207,	
2017-07-18 06:14:39,301 Epoch[34] Batch [740]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.237140,	
2017-07-18 06:14:53,674 Epoch[34] Batch [750]	Speed: 2.78 samples/sec	Train-FCNLogLoss=1.236262,	
2017-07-18 06:15:03,865 Epoch[34] Batch [760]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.234872,	
2017-07-18 06:15:14,947 Epoch[34] Batch [770]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.236138,	
2017-07-18 06:15:26,874 Epoch[34] Batch [780]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.237540,	
2017-07-18 06:15:37,332 Epoch[34] Batch [790]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.237924,	
2017-07-18 06:15:48,651 Epoch[34] Batch [800]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.237987,	
2017-07-18 06:15:58,868 Epoch[34] Batch [810]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.239642,	
2017-07-18 06:16:10,427 Epoch[34] Batch [820]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.238568,	
2017-07-18 06:16:21,692 Epoch[34] Batch [830]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.238461,	
2017-07-18 06:16:31,279 Epoch[34] Batch [840]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.239089,	
2017-07-18 06:16:41,879 Epoch[34] Batch [850]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.239106,	
2017-07-18 06:16:52,478 Epoch[34] Batch [860]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.238788,	
2017-07-18 06:17:04,348 Epoch[34] Batch [870]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.238618,	
2017-07-18 06:17:15,746 Epoch[34] Batch [880]	Speed: 3.51 samples/sec	Train-FCNLogLoss=1.237637,	
2017-07-18 06:17:27,800 Epoch[34] Batch [890]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.237743,	
2017-07-18 06:17:40,172 Epoch[34] Batch [900]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.237348,	
2017-07-18 06:17:50,117 Epoch[34] Batch [910]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.235977,	
2017-07-18 06:17:59,686 Epoch[34] Batch [920]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.235873,	
2017-07-18 06:18:11,034 Epoch[34] Batch [930]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.235103,	
2017-07-18 06:18:21,167 Epoch[34] Batch [940]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.237354,	
2017-07-18 06:18:30,448 Epoch[34] Batch [950]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.237420,	
2017-07-18 06:18:39,417 Epoch[34] Batch [960]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.238563,	
2017-07-18 06:18:48,267 Epoch[34] Batch [970]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.237406,	
2017-07-18 06:18:57,079 Epoch[34] Batch [980]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.237907,	
2017-07-18 06:19:05,905 Epoch[34] Batch [990]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.237421,	
2017-07-18 06:19:14,738 Epoch[34] Batch [1000]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.237292,	
2017-07-18 06:19:23,432 Epoch[34] Batch [1010]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.237602,	
2017-07-18 06:19:31,991 Epoch[34] Batch [1020]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.238392,	
2017-07-18 06:19:41,232 Epoch[34] Batch [1030]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.237951,	
2017-07-18 06:19:50,196 Epoch[34] Batch [1040]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.237629,	
2017-07-18 06:19:58,985 Epoch[34] Batch [1050]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.239148,	
2017-07-18 06:20:07,929 Epoch[34] Batch [1060]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.239370,	
2017-07-18 06:20:16,857 Epoch[34] Batch [1070]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.239840,	
2017-07-18 06:20:26,180 Epoch[34] Batch [1080]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.241027,	
2017-07-18 06:20:35,467 Epoch[34] Batch [1090]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.241046,	
2017-07-18 06:20:44,464 Epoch[34] Batch [1100]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.240264,	
2017-07-18 06:20:53,391 Epoch[34] Batch [1110]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.241045,	
2017-07-18 06:21:02,721 Epoch[34] Batch [1120]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.240438,	
2017-07-18 06:21:11,665 Epoch[34] Batch [1130]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.239990,	
2017-07-18 06:21:20,643 Epoch[34] Batch [1140]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.240047,	
2017-07-18 06:21:29,814 Epoch[34] Batch [1150]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.239037,	
2017-07-18 06:21:39,264 Epoch[34] Batch [1160]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.238675,	
2017-07-18 06:21:48,473 Epoch[34] Batch [1170]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.238838,	
2017-07-18 06:21:57,677 Epoch[34] Batch [1180]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.239419,	
2017-07-18 06:22:06,276 Epoch[34] Batch [1190]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.239668,	
2017-07-18 06:22:15,293 Epoch[34] Batch [1200]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.239350,	
2017-07-18 06:22:24,352 Epoch[34] Batch [1210]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.240043,	
2017-07-18 06:22:36,827 Epoch[34] Batch [1220]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.240822,	
2017-07-18 06:22:46,782 Epoch[34] Batch [1230]	Speed: 4.02 samples/sec	Train-FCNLogLoss=1.240380,	
2017-07-18 06:22:57,644 Epoch[34] Batch [1240]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.240120,	
2017-07-18 06:23:08,571 Epoch[34] Batch [1250]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.240058,	
2017-07-18 06:23:20,021 Epoch[34] Batch [1260]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.239310,	
2017-07-18 06:23:30,466 Epoch[34] Batch [1270]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.238166,	
2017-07-18 06:23:42,028 Epoch[34] Batch [1280]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.238313,	
2017-07-18 06:23:51,758 Epoch[34] Batch [1290]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.238729,	
2017-07-18 06:24:03,200 Epoch[34] Batch [1300]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.239322,	
2017-07-18 06:24:13,994 Epoch[34] Batch [1310]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.238185,	
2017-07-18 06:24:24,497 Epoch[34] Batch [1320]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.238339,	
2017-07-18 06:24:34,891 Epoch[34] Batch [1330]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.238244,	
2017-07-18 06:24:44,450 Epoch[34] Batch [1340]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.238602,	
2017-07-18 06:24:53,747 Epoch[34] Batch [1350]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.240023,	
2017-07-18 06:25:03,769 Epoch[34] Batch [1360]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.239982,	
2017-07-18 06:25:15,426 Epoch[34] Batch [1370]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.240156,	
2017-07-18 06:25:25,939 Epoch[34] Batch [1380]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.240195,	
2017-07-18 06:25:37,595 Epoch[34] Batch [1390]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.240676,	
2017-07-18 06:25:48,087 Epoch[34] Batch [1400]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.240906,	
2017-07-18 06:25:58,871 Epoch[34] Batch [1410]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.240917,	
2017-07-18 06:26:09,754 Epoch[34] Batch [1420]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.240688,	
2017-07-18 06:26:20,931 Epoch[34] Batch [1430]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.239905,	
2017-07-18 06:26:32,033 Epoch[34] Batch [1440]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.239763,	
2017-07-18 06:26:42,071 Epoch[34] Batch [1450]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.239713,	
2017-07-18 06:26:53,024 Epoch[34] Batch [1460]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.239916,	
2017-07-18 06:27:03,612 Epoch[34] Batch [1470]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.240125,	
2017-07-18 06:27:13,259 Epoch[34] Batch [1480]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.239854,	
2017-07-18 06:27:20,658 Epoch[34] Train-FCNLogLoss=1.239656
2017-07-18 06:27:20,658 Epoch[34] Time cost=1563.028
2017-07-18 06:27:21,608 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.params"
2017-07-18 06:27:24,396 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.states"
2017-07-18 06:27:35,123 Epoch[35] Batch [10]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.280165,	
2017-07-18 06:27:44,210 Epoch[35] Batch [20]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.286532,	
2017-07-18 06:27:53,222 Epoch[35] Batch [30]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.250924,	
2017-07-18 06:28:02,094 Epoch[35] Batch [40]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.242631,	
2017-07-18 06:28:11,213 Epoch[35] Batch [50]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.241650,	
2017-07-18 06:28:20,120 Epoch[35] Batch [60]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.261015,	
2017-07-18 06:28:29,010 Epoch[35] Batch [70]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.263065,	
2017-07-18 06:28:38,135 Epoch[35] Batch [80]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.253931,	
2017-07-18 06:28:47,123 Epoch[35] Batch [90]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.240448,	
2017-07-18 06:28:55,902 Epoch[35] Batch [100]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.230397,	
2017-07-18 06:29:04,780 Epoch[35] Batch [110]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.236816,	
2017-07-18 06:29:13,728 Epoch[35] Batch [120]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.242010,	
2017-07-18 06:29:22,668 Epoch[35] Batch [130]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.238918,	
2017-07-18 06:29:31,734 Epoch[35] Batch [140]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.244710,	
2017-07-18 06:29:41,047 Epoch[35] Batch [150]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.240194,	
2017-07-18 06:29:49,979 Epoch[35] Batch [160]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.240021,	
2017-07-18 06:29:58,762 Epoch[35] Batch [170]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.243990,	
2017-07-18 06:30:07,993 Epoch[35] Batch [180]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.247006,	
2017-07-18 06:30:16,744 Epoch[35] Batch [190]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.251075,	
2017-07-18 06:30:25,290 Epoch[35] Batch [200]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.249124,	
2017-07-18 06:30:34,477 Epoch[35] Batch [210]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.244022,	
2017-07-18 06:30:44,117 Epoch[35] Batch [220]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.242808,	
2017-07-18 06:30:53,162 Epoch[35] Batch [230]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.239874,	
2017-07-18 06:31:02,623 Epoch[35] Batch [240]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.234599,	
2017-07-18 06:31:11,671 Epoch[35] Batch [250]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.233798,	
2017-07-18 06:31:21,032 Epoch[35] Batch [260]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.231922,	
2017-07-18 06:31:30,078 Epoch[35] Batch [270]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.233793,	
2017-07-18 06:31:39,271 Epoch[35] Batch [280]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.232640,	
2017-07-18 06:31:48,286 Epoch[35] Batch [290]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.232970,	
2017-07-18 06:31:57,154 Epoch[35] Batch [300]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.234574,	
2017-07-18 06:32:06,260 Epoch[35] Batch [310]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.231908,	
2017-07-18 06:32:15,596 Epoch[35] Batch [320]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.234380,	
2017-07-18 06:32:24,603 Epoch[35] Batch [330]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.231706,	
2017-07-18 06:32:33,807 Epoch[35] Batch [340]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.230603,	
2017-07-18 06:32:43,080 Epoch[35] Batch [350]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.231079,	
2017-07-18 06:32:52,339 Epoch[35] Batch [360]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.230099,	
2017-07-18 06:33:01,530 Epoch[35] Batch [370]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.229649,	
2017-07-18 06:33:11,025 Epoch[35] Batch [380]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.228735,	
2017-07-18 06:33:20,037 Epoch[35] Batch [390]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.230278,	
2017-07-18 06:33:29,077 Epoch[35] Batch [400]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.231185,	
2017-07-18 06:33:38,361 Epoch[35] Batch [410]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.229777,	
2017-07-18 06:33:47,383 Epoch[35] Batch [420]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.231404,	
2017-07-18 06:33:56,646 Epoch[35] Batch [430]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.232015,	
2017-07-18 06:34:05,936 Epoch[35] Batch [440]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.232746,	
2017-07-18 06:34:15,433 Epoch[35] Batch [450]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.234898,	
2017-07-18 06:34:24,734 Epoch[35] Batch [460]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.236367,	
2017-07-18 06:34:34,147 Epoch[35] Batch [470]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.235965,	
2017-07-18 06:34:43,767 Epoch[35] Batch [480]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.237667,	
2017-07-18 06:34:52,834 Epoch[35] Batch [490]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.237204,	
2017-07-18 06:35:01,944 Epoch[35] Batch [500]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.236915,	
2017-07-18 06:35:11,312 Epoch[35] Batch [510]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.235077,	
2017-07-18 06:35:20,109 Epoch[35] Batch [520]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.235606,	
2017-07-18 06:35:29,306 Epoch[35] Batch [530]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.237777,	
2017-07-18 06:35:38,435 Epoch[35] Batch [540]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.237250,	
2017-07-18 06:35:47,775 Epoch[35] Batch [550]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.235901,	
2017-07-18 06:35:57,389 Epoch[35] Batch [560]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.238377,	
2017-07-18 06:36:07,021 Epoch[35] Batch [570]	Speed: 4.15 samples/sec	Train-FCNLogLoss=1.237020,	
2017-07-18 06:36:16,785 Epoch[35] Batch [580]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.236515,	
2017-07-18 06:36:25,978 Epoch[35] Batch [590]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.235309,	
2017-07-18 06:36:35,184 Epoch[35] Batch [600]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.237197,	
2017-07-18 06:36:44,376 Epoch[35] Batch [610]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.237110,	
2017-07-18 06:36:53,766 Epoch[35] Batch [620]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.237825,	
2017-07-18 06:37:02,752 Epoch[35] Batch [630]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.235820,	
2017-07-18 06:37:12,245 Epoch[35] Batch [640]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.235502,	
2017-07-18 06:37:21,951 Epoch[35] Batch [650]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.237163,	
2017-07-18 06:37:31,231 Epoch[35] Batch [660]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.237851,	
2017-07-18 06:37:40,673 Epoch[35] Batch [670]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.237117,	
2017-07-18 06:37:49,857 Epoch[35] Batch [680]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.237983,	
2017-07-18 06:37:59,091 Epoch[35] Batch [690]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.237774,	
2017-07-18 06:38:08,415 Epoch[35] Batch [700]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237373,	
2017-07-18 06:38:18,012 Epoch[35] Batch [710]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.236662,	
2017-07-18 06:38:27,444 Epoch[35] Batch [720]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.237246,	
2017-07-18 06:38:36,726 Epoch[35] Batch [730]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.237408,	
2017-07-18 06:38:45,852 Epoch[35] Batch [740]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.237561,	
2017-07-18 06:38:54,922 Epoch[35] Batch [750]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.235844,	
2017-07-18 06:39:04,332 Epoch[35] Batch [760]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.235652,	
2017-07-18 06:39:13,498 Epoch[35] Batch [770]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.235574,	
2017-07-18 06:39:22,957 Epoch[35] Batch [780]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.234469,	
2017-07-18 06:39:32,439 Epoch[35] Batch [790]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.233982,	
2017-07-18 06:39:41,530 Epoch[35] Batch [800]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.233355,	
2017-07-18 06:39:50,570 Epoch[35] Batch [810]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.233758,	
2017-07-18 06:39:59,614 Epoch[35] Batch [820]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.233321,	
2017-07-18 06:40:09,280 Epoch[35] Batch [830]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.232667,	
2017-07-18 06:40:18,363 Epoch[35] Batch [840]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.233733,	
2017-07-18 06:40:27,587 Epoch[35] Batch [850]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.232958,	
2017-07-18 06:40:36,875 Epoch[35] Batch [860]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.232294,	
2017-07-18 06:40:46,142 Epoch[35] Batch [870]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.233286,	
2017-07-18 06:40:55,383 Epoch[35] Batch [880]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.232759,	
2017-07-18 06:41:04,734 Epoch[35] Batch [890]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.233181,	
2017-07-18 06:41:14,239 Epoch[35] Batch [900]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.232348,	
2017-07-18 06:41:23,665 Epoch[35] Batch [910]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.232723,	
2017-07-18 06:41:33,087 Epoch[35] Batch [920]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.232450,	
2017-07-18 06:41:42,774 Epoch[35] Batch [930]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.231836,	
2017-07-18 06:41:52,444 Epoch[35] Batch [940]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.231659,	
2017-07-18 06:42:01,804 Epoch[35] Batch [950]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.231630,	
2017-07-18 06:42:11,121 Epoch[35] Batch [960]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.231791,	
2017-07-18 06:42:20,401 Epoch[35] Batch [970]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.232371,	
2017-07-18 06:42:29,983 Epoch[35] Batch [980]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.231999,	
2017-07-18 06:42:39,608 Epoch[35] Batch [990]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.233251,	
2017-07-18 06:42:49,291 Epoch[35] Batch [1000]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.234569,	
2017-07-18 06:42:58,361 Epoch[35] Batch [1010]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.234175,	
2017-07-18 06:43:07,723 Epoch[35] Batch [1020]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.233656,	
2017-07-18 06:43:17,174 Epoch[35] Batch [1030]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.234891,	
2017-07-18 06:43:26,685 Epoch[35] Batch [1040]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.235269,	
2017-07-18 06:43:35,680 Epoch[35] Batch [1050]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.234178,	
2017-07-18 06:43:45,134 Epoch[35] Batch [1060]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.234101,	
2017-07-18 06:43:54,466 Epoch[35] Batch [1070]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.234294,	
2017-07-18 06:44:03,588 Epoch[35] Batch [1080]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.235451,	
2017-07-18 06:44:13,075 Epoch[35] Batch [1090]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.235052,	
2017-07-18 06:44:22,504 Epoch[35] Batch [1100]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.234479,	
2017-07-18 06:44:31,951 Epoch[35] Batch [1110]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.234124,	
2017-07-18 06:44:41,467 Epoch[35] Batch [1120]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.234376,	
2017-07-18 06:44:51,050 Epoch[35] Batch [1130]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.234738,	
2017-07-18 06:45:00,350 Epoch[35] Batch [1140]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.234028,	
2017-07-18 06:45:09,858 Epoch[35] Batch [1150]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.234272,	
2017-07-18 06:45:19,089 Epoch[35] Batch [1160]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.234743,	
2017-07-18 06:45:28,627 Epoch[35] Batch [1170]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.234086,	
2017-07-18 06:45:38,147 Epoch[35] Batch [1180]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.234030,	
2017-07-18 06:45:47,803 Epoch[35] Batch [1190]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.233736,	
2017-07-18 06:45:57,259 Epoch[35] Batch [1200]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.233731,	
2017-07-18 06:46:06,510 Epoch[35] Batch [1210]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.233673,	
2017-07-18 06:46:15,458 Epoch[35] Batch [1220]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.233797,	
2017-07-18 06:46:24,699 Epoch[35] Batch [1230]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.233871,	
2017-07-18 06:46:34,236 Epoch[35] Batch [1240]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.233953,	
2017-07-18 06:46:43,533 Epoch[35] Batch [1250]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.233336,	
2017-07-18 06:46:53,421 Epoch[35] Batch [1260]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.234207,	
2017-07-18 06:47:04,006 Epoch[35] Batch [1270]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.234734,	
2017-07-18 06:47:14,050 Epoch[35] Batch [1280]	Speed: 3.98 samples/sec	Train-FCNLogLoss=1.235199,	
2017-07-18 06:47:25,464 Epoch[35] Batch [1290]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.234856,	
2017-07-18 06:47:37,345 Epoch[35] Batch [1300]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.233747,	
2017-07-18 06:47:47,663 Epoch[35] Batch [1310]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.234199,	
2017-07-18 06:47:58,676 Epoch[35] Batch [1320]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.234557,	
2017-07-18 06:48:10,510 Epoch[35] Batch [1330]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.234868,	
2017-07-18 06:48:21,620 Epoch[35] Batch [1340]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.234533,	
2017-07-18 06:48:33,050 Epoch[35] Batch [1350]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.235124,	
2017-07-18 06:48:43,147 Epoch[35] Batch [1360]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.236051,	
2017-07-18 06:48:53,488 Epoch[35] Batch [1370]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.236024,	
2017-07-18 06:49:05,229 Epoch[35] Batch [1380]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.235466,	
2017-07-18 06:49:15,573 Epoch[35] Batch [1390]	Speed: 3.87 samples/sec	Train-FCNLogLoss=1.235175,	
2017-07-18 06:49:29,044 Epoch[35] Batch [1400]	Speed: 2.97 samples/sec	Train-FCNLogLoss=1.235840,	
2017-07-18 06:49:39,195 Epoch[35] Batch [1410]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.235641,	
2017-07-18 06:49:51,537 Epoch[35] Batch [1420]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.235097,	
2017-07-18 06:50:04,312 Epoch[35] Batch [1430]	Speed: 3.13 samples/sec	Train-FCNLogLoss=1.235875,	
2017-07-18 06:50:15,766 Epoch[35] Batch [1440]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.236840,	
2017-07-18 06:50:27,455 Epoch[35] Batch [1450]	Speed: 3.42 samples/sec	Train-FCNLogLoss=1.236563,	
2017-07-18 06:50:38,702 Epoch[35] Batch [1460]	Speed: 3.56 samples/sec	Train-FCNLogLoss=1.236139,	
2017-07-18 06:50:52,086 Epoch[35] Batch [1470]	Speed: 2.99 samples/sec	Train-FCNLogLoss=1.236012,	
2017-07-18 06:51:05,213 Epoch[35] Batch [1480]	Speed: 3.05 samples/sec	Train-FCNLogLoss=1.235493,	
2017-07-18 06:51:12,469 Epoch[35] Train-FCNLogLoss=1.235747
2017-07-18 06:51:12,469 Epoch[35] Time cost=1428.017
2017-07-18 06:51:13,565 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.params"
2017-07-18 06:51:16,483 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.states"
2017-07-18 06:51:26,750 Epoch[36] Batch [10]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.225097,	
2017-07-18 06:51:36,726 Epoch[36] Batch [20]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.215235,	
2017-07-18 06:51:47,043 Epoch[36] Batch [30]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.240854,	
2017-07-18 06:51:56,768 Epoch[36] Batch [40]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.224539,	
2017-07-18 06:52:06,272 Epoch[36] Batch [50]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.237861,	
2017-07-18 06:52:16,007 Epoch[36] Batch [60]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.247098,	
2017-07-18 06:52:24,005 Epoch[36] Batch [70]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.239802,	
2017-07-18 06:52:31,396 Epoch[36] Batch [80]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.234923,	
2017-07-18 06:52:38,450 Epoch[36] Batch [90]	Speed: 5.67 samples/sec	Train-FCNLogLoss=1.222330,	
2017-07-18 06:52:45,989 Epoch[36] Batch [100]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.223431,	
2017-07-18 06:52:53,171 Epoch[36] Batch [110]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.229501,	
2017-07-18 06:53:01,034 Epoch[36] Batch [120]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.228990,	
2017-07-18 06:53:08,057 Epoch[36] Batch [130]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.238919,	
2017-07-18 06:53:15,297 Epoch[36] Batch [140]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.245537,	
2017-07-18 06:53:22,956 Epoch[36] Batch [150]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.246148,	
2017-07-18 06:53:30,479 Epoch[36] Batch [160]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.244921,	
2017-07-18 06:53:38,271 Epoch[36] Batch [170]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.249952,	
2017-07-18 06:53:45,869 Epoch[36] Batch [180]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.256692,	
2017-07-18 06:53:53,661 Epoch[36] Batch [190]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.256492,	
2017-07-18 06:54:01,208 Epoch[36] Batch [200]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.256377,	
2017-07-18 06:54:08,672 Epoch[36] Batch [210]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.255011,	
2017-07-18 06:54:16,163 Epoch[36] Batch [220]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.247151,	
2017-07-18 06:54:23,312 Epoch[36] Batch [230]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.244477,	
2017-07-18 06:54:30,244 Epoch[36] Batch [240]	Speed: 5.77 samples/sec	Train-FCNLogLoss=1.248677,	
2017-07-18 06:54:37,830 Epoch[36] Batch [250]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.246338,	
2017-07-18 06:54:45,161 Epoch[36] Batch [260]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.248424,	
2017-07-18 06:54:52,783 Epoch[36] Batch [270]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.244986,	
2017-07-18 06:55:00,437 Epoch[36] Batch [280]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.243565,	
2017-07-18 06:55:08,050 Epoch[36] Batch [290]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.244188,	
2017-07-18 06:55:15,347 Epoch[36] Batch [300]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.244885,	
2017-07-18 06:55:22,895 Epoch[36] Batch [310]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.242623,	
2017-07-18 06:55:30,083 Epoch[36] Batch [320]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.243341,	
2017-07-18 06:55:37,614 Epoch[36] Batch [330]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.240388,	
2017-07-18 06:55:44,924 Epoch[36] Batch [340]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.238940,	
2017-07-18 06:55:52,431 Epoch[36] Batch [350]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.235655,	
2017-07-18 06:55:59,305 Epoch[36] Batch [360]	Speed: 5.82 samples/sec	Train-FCNLogLoss=1.233621,	
2017-07-18 06:56:06,780 Epoch[36] Batch [370]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.232442,	
2017-07-18 06:56:14,707 Epoch[36] Batch [380]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.235761,	
2017-07-18 06:56:22,429 Epoch[36] Batch [390]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.239348,	
2017-07-18 06:56:30,380 Epoch[36] Batch [400]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.239730,	
2017-07-18 06:56:37,717 Epoch[36] Batch [410]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.244299,	
2017-07-18 06:56:45,556 Epoch[36] Batch [420]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.244531,	
2017-07-18 06:56:52,994 Epoch[36] Batch [430]	Speed: 5.38 samples/sec	Train-FCNLogLoss=1.244292,	
2017-07-18 06:57:00,513 Epoch[36] Batch [440]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.244334,	
2017-07-18 06:57:08,187 Epoch[36] Batch [450]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.242915,	
2017-07-18 06:57:15,348 Epoch[36] Batch [460]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.242147,	
2017-07-18 06:57:22,648 Epoch[36] Batch [470]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.243658,	
2017-07-18 06:57:30,199 Epoch[36] Batch [480]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.240891,	
2017-07-18 06:57:37,557 Epoch[36] Batch [490]	Speed: 5.44 samples/sec	Train-FCNLogLoss=1.239651,	
2017-07-18 06:57:44,901 Epoch[36] Batch [500]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.238484,	
2017-07-18 06:57:52,066 Epoch[36] Batch [510]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.238538,	
2017-07-18 06:57:59,656 Epoch[36] Batch [520]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.237161,	
2017-07-18 06:58:07,502 Epoch[36] Batch [530]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.236035,	
2017-07-18 06:58:15,312 Epoch[36] Batch [540]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.238621,	
2017-07-18 06:58:22,451 Epoch[36] Batch [550]	Speed: 5.60 samples/sec	Train-FCNLogLoss=1.236705,	
2017-07-18 06:58:29,816 Epoch[36] Batch [560]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.237014,	
2017-07-18 06:58:36,932 Epoch[36] Batch [570]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.236742,	
2017-07-18 06:58:44,415 Epoch[36] Batch [580]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.236537,	
2017-07-18 06:58:52,167 Epoch[36] Batch [590]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.235472,	
2017-07-18 06:58:59,918 Epoch[36] Batch [600]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.236277,	
2017-07-18 06:59:07,581 Epoch[36] Batch [610]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.236977,	
2017-07-18 06:59:15,112 Epoch[36] Batch [620]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.236540,	
2017-07-18 06:59:22,676 Epoch[36] Batch [630]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.236335,	
2017-07-18 06:59:29,740 Epoch[36] Batch [640]	Speed: 5.66 samples/sec	Train-FCNLogLoss=1.235446,	
2017-07-18 06:59:36,859 Epoch[36] Batch [650]	Speed: 5.62 samples/sec	Train-FCNLogLoss=1.236751,	
2017-07-18 06:59:44,685 Epoch[36] Batch [660]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.237821,	
2017-07-18 06:59:51,817 Epoch[36] Batch [670]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.238256,	
2017-07-18 06:59:59,782 Epoch[36] Batch [680]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.237739,	
2017-07-18 07:00:07,191 Epoch[36] Batch [690]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.237778,	
2017-07-18 07:00:15,571 Epoch[36] Batch [700]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.236289,	
2017-07-18 07:00:23,175 Epoch[36] Batch [710]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.236327,	
2017-07-18 07:00:31,028 Epoch[36] Batch [720]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.236233,	
2017-07-18 07:00:39,163 Epoch[36] Batch [730]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.235487,	
2017-07-18 07:00:47,102 Epoch[36] Batch [740]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.234347,	
2017-07-18 07:00:55,055 Epoch[36] Batch [750]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.233590,	
2017-07-18 07:01:02,773 Epoch[36] Batch [760]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.231753,	
2017-07-18 07:01:11,082 Epoch[36] Batch [770]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.231481,	
2017-07-18 07:01:19,042 Epoch[36] Batch [780]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.231346,	
2017-07-18 07:01:27,097 Epoch[36] Batch [790]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.231765,	
2017-07-18 07:01:35,548 Epoch[36] Batch [800]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.230804,	
2017-07-18 07:01:43,612 Epoch[36] Batch [810]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.232490,	
2017-07-18 07:01:51,846 Epoch[36] Batch [820]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.232489,	
2017-07-18 07:02:00,164 Epoch[36] Batch [830]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.233393,	
2017-07-18 07:02:07,743 Epoch[36] Batch [840]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.232876,	
2017-07-18 07:02:15,619 Epoch[36] Batch [850]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.232423,	
2017-07-18 07:02:23,575 Epoch[36] Batch [860]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.231326,	
2017-07-18 07:02:31,631 Epoch[36] Batch [870]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.231480,	
2017-07-18 07:02:39,685 Epoch[36] Batch [880]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.232543,	
2017-07-18 07:02:47,867 Epoch[36] Batch [890]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.231627,	
2017-07-18 07:02:56,000 Epoch[36] Batch [900]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.231067,	
2017-07-18 07:03:03,555 Epoch[36] Batch [910]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.230854,	
2017-07-18 07:03:11,254 Epoch[36] Batch [920]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.230408,	
2017-07-18 07:03:19,710 Epoch[36] Batch [930]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.230373,	
2017-07-18 07:03:27,438 Epoch[36] Batch [940]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.231332,	
2017-07-18 07:03:35,584 Epoch[36] Batch [950]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.231671,	
2017-07-18 07:03:43,552 Epoch[36] Batch [960]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.232388,	
2017-07-18 07:03:51,709 Epoch[36] Batch [970]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.232570,	
2017-07-18 07:03:59,199 Epoch[36] Batch [980]	Speed: 5.34 samples/sec	Train-FCNLogLoss=1.232797,	
2017-07-18 07:04:06,606 Epoch[36] Batch [990]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.232421,	
2017-07-18 07:04:13,884 Epoch[36] Batch [1000]	Speed: 5.50 samples/sec	Train-FCNLogLoss=1.232552,	
2017-07-18 07:04:21,432 Epoch[36] Batch [1010]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.231808,	
2017-07-18 07:04:28,978 Epoch[36] Batch [1020]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.232523,	
2017-07-18 07:04:37,164 Epoch[36] Batch [1030]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.231788,	
2017-07-18 07:04:45,534 Epoch[36] Batch [1040]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.232422,	
2017-07-18 07:04:53,057 Epoch[36] Batch [1050]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.232337,	
2017-07-18 07:05:00,987 Epoch[36] Batch [1060]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.232271,	
2017-07-18 07:05:09,401 Epoch[36] Batch [1070]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.232716,	
2017-07-18 07:05:17,696 Epoch[36] Batch [1080]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.232646,	
2017-07-18 07:05:25,673 Epoch[36] Batch [1090]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.232551,	
2017-07-18 07:05:33,799 Epoch[36] Batch [1100]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.233218,	
2017-07-18 07:05:41,713 Epoch[36] Batch [1110]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.233265,	
2017-07-18 07:05:49,351 Epoch[36] Batch [1120]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.233558,	
2017-07-18 07:05:57,115 Epoch[36] Batch [1130]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.233794,	
2017-07-18 07:06:04,896 Epoch[36] Batch [1140]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.233660,	
2017-07-18 07:06:23,625 Epoch[36] Batch [1150]	Speed: 2.14 samples/sec	Train-FCNLogLoss=1.234224,	
2017-07-18 07:06:31,323 Epoch[36] Batch [1160]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.234150,	
2017-07-18 07:06:38,976 Epoch[36] Batch [1170]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.234177,	
2017-07-18 07:06:46,594 Epoch[36] Batch [1180]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.234017,	
2017-07-18 07:06:54,416 Epoch[36] Batch [1190]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.233932,	
2017-07-18 07:07:01,715 Epoch[36] Batch [1200]	Speed: 5.48 samples/sec	Train-FCNLogLoss=1.234175,	
2017-07-18 07:07:09,336 Epoch[36] Batch [1210]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.233768,	
2017-07-18 07:07:16,988 Epoch[36] Batch [1220]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.233748,	
2017-07-18 07:07:25,041 Epoch[36] Batch [1230]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.232724,	
2017-07-18 07:07:32,806 Epoch[36] Batch [1240]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.232965,	
2017-07-18 07:07:40,841 Epoch[36] Batch [1250]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.232133,	
2017-07-18 07:07:48,774 Epoch[36] Batch [1260]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.232010,	
2017-07-18 07:07:56,163 Epoch[36] Batch [1270]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.231645,	
2017-07-18 07:08:03,993 Epoch[36] Batch [1280]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.232324,	
2017-07-18 07:08:11,784 Epoch[36] Batch [1290]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.232137,	
2017-07-18 07:08:19,311 Epoch[36] Batch [1300]	Speed: 5.31 samples/sec	Train-FCNLogLoss=1.232364,	
2017-07-18 07:08:27,374 Epoch[36] Batch [1310]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.232194,	
2017-07-18 07:08:35,511 Epoch[36] Batch [1320]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.231877,	
2017-07-18 07:08:43,228 Epoch[36] Batch [1330]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.232465,	
2017-07-18 07:08:50,968 Epoch[36] Batch [1340]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.232608,	
2017-07-18 07:08:58,378 Epoch[36] Batch [1350]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.232617,	
2017-07-18 07:09:05,893 Epoch[36] Batch [1360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=1.232533,	
2017-07-18 07:09:13,848 Epoch[36] Batch [1370]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.232236,	
2017-07-18 07:09:21,546 Epoch[36] Batch [1380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.232689,	
2017-07-18 07:09:28,681 Epoch[36] Batch [1390]	Speed: 5.61 samples/sec	Train-FCNLogLoss=1.233272,	
2017-07-18 07:09:36,123 Epoch[36] Batch [1400]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.233465,	
2017-07-18 07:09:44,065 Epoch[36] Batch [1410]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.233703,	
2017-07-18 07:09:51,307 Epoch[36] Batch [1420]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.233428,	
2017-07-18 07:09:58,918 Epoch[36] Batch [1430]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.232743,	
2017-07-18 07:10:06,653 Epoch[36] Batch [1440]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.232861,	
2017-07-18 07:10:14,287 Epoch[36] Batch [1450]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.233776,	
2017-07-18 07:10:22,163 Epoch[36] Batch [1460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.234155,	
2017-07-18 07:10:30,396 Epoch[36] Batch [1470]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.234278,	
2017-07-18 07:10:38,121 Epoch[36] Batch [1480]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.235432,	
2017-07-18 07:10:42,505 Epoch[36] Train-FCNLogLoss=1.235479
2017-07-18 07:10:42,506 Epoch[36] Time cost=1165.833
2017-07-18 07:10:43,482 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.params"
2017-07-18 07:10:46,633 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.states"
2017-07-18 07:10:55,697 Epoch[37] Batch [10]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.137363,	
2017-07-18 07:11:03,140 Epoch[37] Batch [20]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.155698,	
2017-07-18 07:11:11,034 Epoch[37] Batch [30]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.139869,	
2017-07-18 07:11:18,722 Epoch[37] Batch [40]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.164711,	
2017-07-18 07:11:25,877 Epoch[37] Batch [50]	Speed: 5.59 samples/sec	Train-FCNLogLoss=1.190430,	
2017-07-18 07:11:33,454 Epoch[37] Batch [60]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.200669,	
2017-07-18 07:11:40,663 Epoch[37] Batch [70]	Speed: 5.55 samples/sec	Train-FCNLogLoss=1.191639,	
2017-07-18 07:11:48,472 Epoch[37] Batch [80]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.186535,	
2017-07-18 07:11:56,095 Epoch[37] Batch [90]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.189790,	
2017-07-18 07:12:03,652 Epoch[37] Batch [100]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.187561,	
2017-07-18 07:12:11,132 Epoch[37] Batch [110]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.186830,	
2017-07-18 07:12:18,445 Epoch[37] Batch [120]	Speed: 5.47 samples/sec	Train-FCNLogLoss=1.186421,	
2017-07-18 07:12:26,078 Epoch[37] Batch [130]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.191629,	
2017-07-18 07:12:34,005 Epoch[37] Batch [140]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.193443,	
2017-07-18 07:12:41,910 Epoch[37] Batch [150]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.190065,	
2017-07-18 07:12:49,978 Epoch[37] Batch [160]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.194069,	
2017-07-18 07:12:57,640 Epoch[37] Batch [170]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.205732,	
2017-07-18 07:13:05,219 Epoch[37] Batch [180]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.204137,	
2017-07-18 07:13:12,542 Epoch[37] Batch [190]	Speed: 5.46 samples/sec	Train-FCNLogLoss=1.204037,	
2017-07-18 07:13:20,181 Epoch[37] Batch [200]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.203630,	
2017-07-18 07:13:27,637 Epoch[37] Batch [210]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.206998,	
2017-07-18 07:13:35,526 Epoch[37] Batch [220]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.207524,	
2017-07-18 07:13:43,070 Epoch[37] Batch [230]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.210080,	
2017-07-18 07:13:51,127 Epoch[37] Batch [240]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.210454,	
2017-07-18 07:13:58,879 Epoch[37] Batch [250]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.210088,	
2017-07-18 07:14:06,878 Epoch[37] Batch [260]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.210142,	
2017-07-18 07:14:14,575 Epoch[37] Batch [270]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.213293,	
2017-07-18 07:14:22,136 Epoch[37] Batch [280]	Speed: 5.29 samples/sec	Train-FCNLogLoss=1.213081,	
2017-07-18 07:14:29,619 Epoch[37] Batch [290]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.210800,	
2017-07-18 07:14:37,313 Epoch[37] Batch [300]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.217317,	
2017-07-18 07:14:44,691 Epoch[37] Batch [310]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.219958,	
2017-07-18 07:14:52,027 Epoch[37] Batch [320]	Speed: 5.45 samples/sec	Train-FCNLogLoss=1.220956,	
2017-07-18 07:15:09,584 Epoch[37] Batch [330]	Speed: 2.28 samples/sec	Train-FCNLogLoss=1.222449,	
2017-07-18 07:15:18,255 Epoch[37] Batch [340]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.223123,	
2017-07-18 07:15:29,913 Epoch[37] Batch [350]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.225919,	
2017-07-18 07:15:39,584 Epoch[37] Batch [360]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.223986,	
2017-07-18 07:15:50,355 Epoch[37] Batch [370]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.224851,	
2017-07-18 07:16:01,612 Epoch[37] Batch [380]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.225814,	
2017-07-18 07:16:11,481 Epoch[37] Batch [390]	Speed: 4.05 samples/sec	Train-FCNLogLoss=1.225963,	
2017-07-18 07:16:21,744 Epoch[37] Batch [400]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.225692,	
2017-07-18 07:16:30,463 Epoch[37] Batch [410]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.227443,	
2017-07-18 07:16:41,587 Epoch[37] Batch [420]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.226086,	
2017-07-18 07:16:52,736 Epoch[37] Batch [430]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.226064,	
2017-07-18 07:17:05,004 Epoch[37] Batch [440]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.229024,	
2017-07-18 07:17:14,835 Epoch[37] Batch [450]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.229826,	
2017-07-18 07:17:26,975 Epoch[37] Batch [460]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.230804,	
2017-07-18 07:17:37,808 Epoch[37] Batch [470]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.230342,	
2017-07-18 07:17:48,391 Epoch[37] Batch [480]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.229970,	
2017-07-18 07:18:00,840 Epoch[37] Batch [490]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.230136,	
2017-07-18 07:18:09,635 Epoch[37] Batch [500]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.232884,	
2017-07-18 07:18:19,905 Epoch[37] Batch [510]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.233554,	
2017-07-18 07:18:31,179 Epoch[37] Batch [520]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.234632,	
2017-07-18 07:18:42,720 Epoch[37] Batch [530]	Speed: 3.47 samples/sec	Train-FCNLogLoss=1.232990,	
2017-07-18 07:18:51,598 Epoch[37] Batch [540]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.232938,	
2017-07-18 07:19:00,893 Epoch[37] Batch [550]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.233590,	
2017-07-18 07:19:10,795 Epoch[37] Batch [560]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.232903,	
2017-07-18 07:19:19,730 Epoch[37] Batch [570]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.231934,	
2017-07-18 07:19:32,035 Epoch[37] Batch [580]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.233519,	
2017-07-18 07:19:43,277 Epoch[37] Batch [590]	Speed: 3.56 samples/sec	Train-FCNLogLoss=1.233768,	
2017-07-18 07:19:53,647 Epoch[37] Batch [600]	Speed: 3.86 samples/sec	Train-FCNLogLoss=1.235706,	
2017-07-18 07:20:04,302 Epoch[37] Batch [610]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.233757,	
2017-07-18 07:20:12,858 Epoch[37] Batch [620]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.234202,	
2017-07-18 07:20:22,940 Epoch[37] Batch [630]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.233585,	
2017-07-18 07:20:32,014 Epoch[37] Batch [640]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.234654,	
2017-07-18 07:20:42,255 Epoch[37] Batch [650]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.234170,	
2017-07-18 07:20:51,257 Epoch[37] Batch [660]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.234436,	
2017-07-18 07:21:01,158 Epoch[37] Batch [670]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.234179,	
2017-07-18 07:21:09,988 Epoch[37] Batch [680]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.234174,	
2017-07-18 07:21:19,565 Epoch[37] Batch [690]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.234491,	
2017-07-18 07:21:27,994 Epoch[37] Batch [700]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.234785,	
2017-07-18 07:21:37,960 Epoch[37] Batch [710]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.234850,	
2017-07-18 07:21:46,373 Epoch[37] Batch [720]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.235467,	
2017-07-18 07:21:55,609 Epoch[37] Batch [730]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.235003,	
2017-07-18 07:22:04,643 Epoch[37] Batch [740]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.235003,	
2017-07-18 07:22:14,187 Epoch[37] Batch [750]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.234823,	
2017-07-18 07:22:23,839 Epoch[37] Batch [760]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.235391,	
2017-07-18 07:22:34,454 Epoch[37] Batch [770]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.235228,	
2017-07-18 07:22:44,933 Epoch[37] Batch [780]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.234874,	
2017-07-18 07:22:56,317 Epoch[37] Batch [790]	Speed: 3.51 samples/sec	Train-FCNLogLoss=1.233370,	
2017-07-18 07:23:06,746 Epoch[37] Batch [800]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.235374,	
2017-07-18 07:23:16,189 Epoch[37] Batch [810]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.236237,	
2017-07-18 07:23:24,609 Epoch[37] Batch [820]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.235856,	
2017-07-18 07:23:32,311 Epoch[37] Batch [830]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.236342,	
2017-07-18 07:23:42,099 Epoch[37] Batch [840]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.237482,	
2017-07-18 07:23:51,713 Epoch[37] Batch [850]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.237777,	
2017-07-18 07:24:02,498 Epoch[37] Batch [860]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.237915,	
2017-07-18 07:24:13,296 Epoch[37] Batch [870]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.237203,	
2017-07-18 07:24:23,054 Epoch[37] Batch [880]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.236375,	
2017-07-18 07:24:32,670 Epoch[37] Batch [890]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.237236,	
2017-07-18 07:24:44,224 Epoch[37] Batch [900]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.237564,	
2017-07-18 07:24:54,076 Epoch[37] Batch [910]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.237148,	
2017-07-18 07:25:06,006 Epoch[37] Batch [920]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.237643,	
2017-07-18 07:25:17,225 Epoch[37] Batch [930]	Speed: 3.57 samples/sec	Train-FCNLogLoss=1.237023,	
2017-07-18 07:25:27,862 Epoch[37] Batch [940]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.236197,	
2017-07-18 07:25:38,573 Epoch[37] Batch [950]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.236917,	
2017-07-18 07:25:48,968 Epoch[37] Batch [960]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.237904,	
2017-07-18 07:25:57,966 Epoch[37] Batch [970]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.237774,	
2017-07-18 07:26:10,710 Epoch[37] Batch [980]	Speed: 3.14 samples/sec	Train-FCNLogLoss=1.237397,	
2017-07-18 07:26:20,303 Epoch[37] Batch [990]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.237269,	
2017-07-18 07:26:30,070 Epoch[37] Batch [1000]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.237917,	
2017-07-18 07:26:37,972 Epoch[37] Batch [1010]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.237625,	
2017-07-18 07:26:47,061 Epoch[37] Batch [1020]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.237266,	
2017-07-18 07:26:57,208 Epoch[37] Batch [1030]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.236979,	
2017-07-18 07:27:07,762 Epoch[37] Batch [1040]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.238013,	
2017-07-18 07:27:17,185 Epoch[37] Batch [1050]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.239445,	
2017-07-18 07:27:26,438 Epoch[37] Batch [1060]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.239005,	
2017-07-18 07:27:35,109 Epoch[37] Batch [1070]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.238454,	
2017-07-18 07:27:46,292 Epoch[37] Batch [1080]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.238271,	
2017-07-18 07:27:56,833 Epoch[37] Batch [1090]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.237942,	
2017-07-18 07:28:10,824 Epoch[37] Batch [1100]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.238144,	
2017-07-18 07:28:25,053 Epoch[37] Batch [1110]	Speed: 2.81 samples/sec	Train-FCNLogLoss=1.238128,	
2017-07-18 07:28:36,119 Epoch[37] Batch [1120]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.237600,	
2017-07-18 07:28:47,921 Epoch[37] Batch [1130]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.237644,	
2017-07-18 07:28:57,887 Epoch[37] Batch [1140]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.238707,	
2017-07-18 07:29:09,769 Epoch[37] Batch [1150]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.238853,	
2017-07-18 07:29:20,198 Epoch[37] Batch [1160]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.239372,	
2017-07-18 07:29:30,841 Epoch[37] Batch [1170]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.239256,	
2017-07-18 07:29:42,912 Epoch[37] Batch [1180]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.238881,	
2017-07-18 07:29:52,136 Epoch[37] Batch [1190]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.239646,	
2017-07-18 07:30:02,334 Epoch[37] Batch [1200]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.239801,	
2017-07-18 07:30:13,954 Epoch[37] Batch [1210]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.239912,	
2017-07-18 07:30:22,865 Epoch[37] Batch [1220]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.241581,	
2017-07-18 07:30:31,660 Epoch[37] Batch [1230]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.241383,	
2017-07-18 07:30:41,550 Epoch[37] Batch [1240]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.241138,	
2017-07-18 07:30:53,148 Epoch[37] Batch [1250]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.240476,	
2017-07-18 07:31:02,139 Epoch[37] Batch [1260]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.239892,	
2017-07-18 07:31:13,929 Epoch[37] Batch [1270]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.239750,	
2017-07-18 07:31:24,774 Epoch[37] Batch [1280]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.240162,	
2017-07-18 07:31:34,483 Epoch[37] Batch [1290]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.240078,	
2017-07-18 07:31:45,163 Epoch[37] Batch [1300]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.240419,	
2017-07-18 07:31:56,610 Epoch[37] Batch [1310]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.241004,	
2017-07-18 07:32:09,351 Epoch[37] Batch [1320]	Speed: 3.14 samples/sec	Train-FCNLogLoss=1.241580,	
2017-07-18 07:32:20,285 Epoch[37] Batch [1330]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.241939,	
2017-07-18 07:32:29,769 Epoch[37] Batch [1340]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.241817,	
2017-07-18 07:32:40,932 Epoch[37] Batch [1350]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.242680,	
2017-07-18 07:32:50,683 Epoch[37] Batch [1360]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.242557,	
2017-07-18 07:33:01,426 Epoch[37] Batch [1370]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.241979,	
2017-07-18 07:33:10,620 Epoch[37] Batch [1380]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.241826,	
2017-07-18 07:33:21,298 Epoch[37] Batch [1390]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.241160,	
2017-07-18 07:33:30,982 Epoch[37] Batch [1400]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.241363,	
2017-07-18 07:33:42,567 Epoch[37] Batch [1410]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.241958,	
2017-07-18 07:33:56,282 Epoch[37] Batch [1420]	Speed: 2.92 samples/sec	Train-FCNLogLoss=1.242227,	
2017-07-18 07:34:08,344 Epoch[37] Batch [1430]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.242308,	
2017-07-18 07:34:17,704 Epoch[37] Batch [1440]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.242903,	
2017-07-18 07:34:28,192 Epoch[37] Batch [1450]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.242666,	
2017-07-18 07:34:37,248 Epoch[37] Batch [1460]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.242178,	
2017-07-18 07:34:49,478 Epoch[37] Batch [1470]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.242223,	
2017-07-18 07:35:00,496 Epoch[37] Batch [1480]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.241803,	
2017-07-18 07:35:07,183 Epoch[37] Train-FCNLogLoss=1.242118
2017-07-18 07:35:07,183 Epoch[37] Time cost=1460.266
2017-07-18 07:35:08,239 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.params"
2017-07-18 07:35:11,130 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.states"
2017-07-18 07:35:23,805 Epoch[38] Batch [10]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.128986,	
2017-07-18 07:35:35,660 Epoch[38] Batch [20]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.195739,	
2017-07-18 07:35:47,239 Epoch[38] Batch [30]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.212310,	
2017-07-18 07:35:57,925 Epoch[38] Batch [40]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.211315,	
2017-07-18 07:36:09,665 Epoch[38] Batch [50]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.199794,	
2017-07-18 07:36:18,288 Epoch[38] Batch [60]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.190549,	
2017-07-18 07:36:31,330 Epoch[38] Batch [70]	Speed: 3.07 samples/sec	Train-FCNLogLoss=1.208791,	
2017-07-18 07:36:41,525 Epoch[38] Batch [80]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.215419,	
2017-07-18 07:36:52,164 Epoch[38] Batch [90]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.213753,	
2017-07-18 07:37:02,017 Epoch[38] Batch [100]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.217126,	
2017-07-18 07:37:14,102 Epoch[38] Batch [110]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.220182,	
2017-07-18 07:37:23,274 Epoch[38] Batch [120]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.215457,	
2017-07-18 07:37:33,453 Epoch[38] Batch [130]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.218662,	
2017-07-18 07:37:44,528 Epoch[38] Batch [140]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.218917,	
2017-07-18 07:37:55,298 Epoch[38] Batch [150]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.217642,	
2017-07-18 07:38:04,617 Epoch[38] Batch [160]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.226162,	
2017-07-18 07:38:14,607 Epoch[38] Batch [170]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.228781,	
2017-07-18 07:38:25,152 Epoch[38] Batch [180]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.228407,	
2017-07-18 07:38:35,440 Epoch[38] Batch [190]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.226828,	
2017-07-18 07:38:45,549 Epoch[38] Batch [200]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.232443,	
2017-07-18 07:38:57,183 Epoch[38] Batch [210]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.228786,	
2017-07-18 07:39:06,178 Epoch[38] Batch [220]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.229560,	
2017-07-18 07:39:16,254 Epoch[38] Batch [230]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.228007,	
2017-07-18 07:39:27,084 Epoch[38] Batch [240]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.226960,	
2017-07-18 07:39:38,117 Epoch[38] Batch [250]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.231160,	
2017-07-18 07:39:49,139 Epoch[38] Batch [260]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.229029,	
2017-07-18 07:39:58,652 Epoch[38] Batch [270]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.230724,	
2017-07-18 07:40:09,910 Epoch[38] Batch [280]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.228474,	
2017-07-18 07:40:21,956 Epoch[38] Batch [290]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.231396,	
2017-07-18 07:40:31,863 Epoch[38] Batch [300]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.227036,	
2017-07-18 07:40:41,613 Epoch[38] Batch [310]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.226609,	
2017-07-18 07:40:53,956 Epoch[38] Batch [320]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.225932,	
2017-07-18 07:41:04,527 Epoch[38] Batch [330]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.224364,	
2017-07-18 07:41:13,988 Epoch[38] Batch [340]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.222442,	
2017-07-18 07:41:21,852 Epoch[38] Batch [350]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.219649,	
2017-07-18 07:41:29,679 Epoch[38] Batch [360]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.220441,	
2017-07-18 07:41:37,141 Epoch[38] Batch [370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=1.218151,	
2017-07-18 07:41:45,184 Epoch[38] Batch [380]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.217232,	
2017-07-18 07:41:53,628 Epoch[38] Batch [390]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.217923,	
2017-07-18 07:42:01,793 Epoch[38] Batch [400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.218351,	
2017-07-18 07:42:09,511 Epoch[38] Batch [410]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.221989,	
2017-07-18 07:42:18,128 Epoch[38] Batch [420]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.221978,	
2017-07-18 07:42:26,191 Epoch[38] Batch [430]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.223378,	
2017-07-18 07:42:34,089 Epoch[38] Batch [440]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.223545,	
2017-07-18 07:42:42,354 Epoch[38] Batch [450]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.223182,	
2017-07-18 07:42:50,237 Epoch[38] Batch [460]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.223790,	
2017-07-18 07:42:57,918 Epoch[38] Batch [470]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.223221,	
2017-07-18 07:43:05,884 Epoch[38] Batch [480]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.223508,	
2017-07-18 07:43:13,494 Epoch[38] Batch [490]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.225072,	
2017-07-18 07:43:21,443 Epoch[38] Batch [500]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.225748,	
2017-07-18 07:43:29,331 Epoch[38] Batch [510]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.226041,	
2017-07-18 07:43:37,170 Epoch[38] Batch [520]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.225420,	
2017-07-18 07:43:44,880 Epoch[38] Batch [530]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.225929,	
2017-07-18 07:43:53,121 Epoch[38] Batch [540]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.226967,	
2017-07-18 07:44:00,867 Epoch[38] Batch [550]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.229605,	
2017-07-18 07:44:09,026 Epoch[38] Batch [560]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.231165,	
2017-07-18 07:44:17,287 Epoch[38] Batch [570]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.229728,	
2017-07-18 07:44:25,230 Epoch[38] Batch [580]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.229102,	
2017-07-18 07:44:33,768 Epoch[38] Batch [590]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.229156,	
2017-07-18 07:44:41,555 Epoch[38] Batch [600]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.230059,	
2017-07-18 07:44:49,671 Epoch[38] Batch [610]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.231219,	
2017-07-18 07:44:57,664 Epoch[38] Batch [620]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.231157,	
2017-07-18 07:45:05,426 Epoch[38] Batch [630]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.233332,	
2017-07-18 07:45:13,373 Epoch[38] Batch [640]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.234362,	
2017-07-18 07:45:20,964 Epoch[38] Batch [650]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.233970,	
2017-07-18 07:45:28,463 Epoch[38] Batch [660]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.233485,	
2017-07-18 07:45:36,288 Epoch[38] Batch [670]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.231986,	
2017-07-18 07:45:44,075 Epoch[38] Batch [680]	Speed: 5.14 samples/sec	Train-FCNLogLoss=1.232759,	
2017-07-18 07:45:51,552 Epoch[38] Batch [690]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.232082,	
2017-07-18 07:45:59,512 Epoch[38] Batch [700]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.232692,	
2017-07-18 07:46:07,234 Epoch[38] Batch [710]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.232922,	
2017-07-18 07:46:15,281 Epoch[38] Batch [720]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.232155,	
2017-07-18 07:46:23,279 Epoch[38] Batch [730]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.232579,	
2017-07-18 07:46:31,010 Epoch[38] Batch [740]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.232300,	
2017-07-18 07:46:38,841 Epoch[38] Batch [750]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.231399,	
2017-07-18 07:46:46,644 Epoch[38] Batch [760]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.231230,	
2017-07-18 07:46:54,532 Epoch[38] Batch [770]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.231466,	
2017-07-18 07:47:01,954 Epoch[38] Batch [780]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.231844,	
2017-07-18 07:47:09,729 Epoch[38] Batch [790]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.231858,	
2017-07-18 07:47:17,374 Epoch[38] Batch [800]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.231809,	
2017-07-18 07:47:25,226 Epoch[38] Batch [810]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.231132,	
2017-07-18 07:47:33,032 Epoch[38] Batch [820]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.231788,	
2017-07-18 07:47:40,273 Epoch[38] Batch [830]	Speed: 5.52 samples/sec	Train-FCNLogLoss=1.231963,	
2017-07-18 07:47:51,424 Epoch[38] Batch [840]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.231835,	
2017-07-18 07:48:01,658 Epoch[38] Batch [850]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.231559,	
2017-07-18 07:48:12,243 Epoch[38] Batch [860]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.230183,	
2017-07-18 07:48:21,330 Epoch[38] Batch [870]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.229853,	
2017-07-18 07:48:29,730 Epoch[38] Batch [880]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.230825,	
2017-07-18 07:48:41,525 Epoch[38] Batch [890]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.231810,	
2017-07-18 07:48:51,966 Epoch[38] Batch [900]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.231269,	
2017-07-18 07:49:03,380 Epoch[38] Batch [910]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.232576,	
2017-07-18 07:49:12,561 Epoch[38] Batch [920]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.231874,	
2017-07-18 07:49:22,878 Epoch[38] Batch [930]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.232641,	
2017-07-18 07:49:32,200 Epoch[38] Batch [940]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.232239,	
2017-07-18 07:49:40,165 Epoch[38] Batch [950]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.232928,	
2017-07-18 07:49:47,875 Epoch[38] Batch [960]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.233834,	
2017-07-18 07:49:55,639 Epoch[38] Batch [970]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.233341,	
2017-07-18 07:50:03,571 Epoch[38] Batch [980]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.233857,	
2017-07-18 07:50:10,861 Epoch[38] Batch [990]	Speed: 5.49 samples/sec	Train-FCNLogLoss=1.233420,	
2017-07-18 07:50:18,961 Epoch[38] Batch [1000]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.234497,	
2017-07-18 07:50:26,963 Epoch[38] Batch [1010]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.234254,	
2017-07-18 07:50:34,865 Epoch[38] Batch [1020]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.234766,	
2017-07-18 07:50:42,436 Epoch[38] Batch [1030]	Speed: 5.28 samples/sec	Train-FCNLogLoss=1.235077,	
2017-07-18 07:50:50,065 Epoch[38] Batch [1040]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.237003,	
2017-07-18 07:50:57,870 Epoch[38] Batch [1050]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.237103,	
2017-07-18 07:51:05,725 Epoch[38] Batch [1060]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.236964,	
2017-07-18 07:51:13,432 Epoch[38] Batch [1070]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.236331,	
2017-07-18 07:51:21,570 Epoch[38] Batch [1080]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.236000,	
2017-07-18 07:51:29,743 Epoch[38] Batch [1090]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.236847,	
2017-07-18 07:51:37,635 Epoch[38] Batch [1100]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.236894,	
2017-07-18 07:51:45,525 Epoch[38] Batch [1110]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.236748,	
2017-07-18 07:51:53,384 Epoch[38] Batch [1120]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.236691,	
2017-07-18 07:52:01,337 Epoch[38] Batch [1130]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.236256,	
2017-07-18 07:52:09,350 Epoch[38] Batch [1140]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.236495,	
2017-07-18 07:52:17,192 Epoch[38] Batch [1150]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.236219,	
2017-07-18 07:52:24,949 Epoch[38] Batch [1160]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.236366,	
2017-07-18 07:52:32,740 Epoch[38] Batch [1170]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.236696,	
2017-07-18 07:52:40,605 Epoch[38] Batch [1180]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.237339,	
2017-07-18 07:52:48,531 Epoch[38] Batch [1190]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.237724,	
2017-07-18 07:52:56,614 Epoch[38] Batch [1200]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.238941,	
2017-07-18 07:53:04,294 Epoch[38] Batch [1210]	Speed: 5.21 samples/sec	Train-FCNLogLoss=1.239816,	
2017-07-18 07:53:11,703 Epoch[38] Batch [1220]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.239403,	
2017-07-18 07:53:19,365 Epoch[38] Batch [1230]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.239732,	
2017-07-18 07:53:27,598 Epoch[38] Batch [1240]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.239596,	
2017-07-18 07:53:35,466 Epoch[38] Batch [1250]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.240206,	
2017-07-18 07:53:43,229 Epoch[38] Batch [1260]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.240306,	
2017-07-18 07:53:51,423 Epoch[38] Batch [1270]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.240592,	
2017-07-18 07:53:59,233 Epoch[38] Batch [1280]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.240892,	
2017-07-18 07:54:07,170 Epoch[38] Batch [1290]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.241641,	
2017-07-18 07:54:15,197 Epoch[38] Batch [1300]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.241645,	
2017-07-18 07:54:23,029 Epoch[38] Batch [1310]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.241299,	
2017-07-18 07:54:31,219 Epoch[38] Batch [1320]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.241752,	
2017-07-18 07:54:39,308 Epoch[38] Batch [1330]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.241996,	
2017-07-18 07:54:47,421 Epoch[38] Batch [1340]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.242216,	
2017-07-18 07:54:55,131 Epoch[38] Batch [1350]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.242630,	
2017-07-18 07:55:02,983 Epoch[38] Batch [1360]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.242770,	
2017-07-18 07:55:10,789 Epoch[38] Batch [1370]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.242707,	
2017-07-18 07:55:18,778 Epoch[38] Batch [1380]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.242649,	
2017-07-18 07:55:26,964 Epoch[38] Batch [1390]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.242529,	
2017-07-18 07:55:34,563 Epoch[38] Batch [1400]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.242734,	
2017-07-18 07:55:42,839 Epoch[38] Batch [1410]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.242612,	
2017-07-18 07:55:50,900 Epoch[38] Batch [1420]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.243293,	
2017-07-18 07:55:58,885 Epoch[38] Batch [1430]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.242522,	
2017-07-18 07:56:06,689 Epoch[38] Batch [1440]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.242800,	
2017-07-18 07:56:14,381 Epoch[38] Batch [1450]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.242696,	
2017-07-18 07:56:22,258 Epoch[38] Batch [1460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.242778,	
2017-07-18 07:56:30,259 Epoch[38] Batch [1470]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.242021,	
2017-07-18 07:56:38,297 Epoch[38] Batch [1480]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.242113,	
2017-07-18 07:56:43,001 Epoch[38] Train-FCNLogLoss=1.242154
2017-07-18 07:56:43,001 Epoch[38] Time cost=1291.764
2017-07-18 07:56:44,471 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.params"
2017-07-18 07:56:47,178 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.states"
2017-07-18 07:56:57,034 Epoch[39] Batch [10]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.286795,	
2017-07-18 07:57:05,374 Epoch[39] Batch [20]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.277415,	
2017-07-18 07:57:13,384 Epoch[39] Batch [30]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.274343,	
2017-07-18 07:57:21,436 Epoch[39] Batch [40]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.262197,	
2017-07-18 07:57:29,815 Epoch[39] Batch [50]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.249141,	
2017-07-18 07:57:37,852 Epoch[39] Batch [60]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.236637,	
2017-07-18 07:57:46,125 Epoch[39] Batch [70]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.229404,	
2017-07-18 07:57:54,576 Epoch[39] Batch [80]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.223486,	
2017-07-18 07:58:02,651 Epoch[39] Batch [90]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.222053,	
2017-07-18 07:58:10,673 Epoch[39] Batch [100]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.229980,	
2017-07-18 07:58:18,501 Epoch[39] Batch [110]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.229559,	
2017-07-18 07:58:26,918 Epoch[39] Batch [120]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.232354,	
2017-07-18 07:58:35,093 Epoch[39] Batch [130]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.231717,	
2017-07-18 07:58:43,145 Epoch[39] Batch [140]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.227728,	
2017-07-18 07:58:51,246 Epoch[39] Batch [150]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.225758,	
2017-07-18 07:58:59,390 Epoch[39] Batch [160]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.228938,	
2017-07-18 07:59:07,642 Epoch[39] Batch [170]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.230909,	
2017-07-18 07:59:16,000 Epoch[39] Batch [180]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.231465,	
2017-07-18 07:59:23,861 Epoch[39] Batch [190]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.227261,	
2017-07-18 07:59:32,134 Epoch[39] Batch [200]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.227737,	
2017-07-18 07:59:40,510 Epoch[39] Batch [210]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.227975,	
2017-07-18 07:59:48,311 Epoch[39] Batch [220]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.231120,	
2017-07-18 07:59:56,490 Epoch[39] Batch [230]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.229819,	
2017-07-18 08:00:04,455 Epoch[39] Batch [240]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.228268,	
2017-07-18 08:00:12,389 Epoch[39] Batch [250]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.226583,	
2017-07-18 08:00:20,593 Epoch[39] Batch [260]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.224054,	
2017-07-18 08:00:28,451 Epoch[39] Batch [270]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.225605,	
2017-07-18 08:00:36,398 Epoch[39] Batch [280]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.224956,	
2017-07-18 08:00:44,309 Epoch[39] Batch [290]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.227133,	
2017-07-18 08:00:52,267 Epoch[39] Batch [300]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.227020,	
2017-07-18 08:01:00,024 Epoch[39] Batch [310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.227304,	
2017-07-18 08:01:08,409 Epoch[39] Batch [320]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.228444,	
2017-07-18 08:01:16,490 Epoch[39] Batch [330]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.226824,	
2017-07-18 08:01:24,496 Epoch[39] Batch [340]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.227536,	
2017-07-18 08:01:32,491 Epoch[39] Batch [350]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.227169,	
2017-07-18 08:01:40,663 Epoch[39] Batch [360]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.225892,	
2017-07-18 08:01:49,030 Epoch[39] Batch [370]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.227643,	
2017-07-18 08:01:56,788 Epoch[39] Batch [380]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.227483,	
2017-07-18 08:02:04,741 Epoch[39] Batch [390]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.227705,	
2017-07-18 08:02:12,779 Epoch[39] Batch [400]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.227374,	
2017-07-18 08:02:20,960 Epoch[39] Batch [410]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.228517,	
2017-07-18 08:02:29,098 Epoch[39] Batch [420]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.226391,	
2017-07-18 08:02:37,221 Epoch[39] Batch [430]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.226276,	
2017-07-18 08:02:45,582 Epoch[39] Batch [440]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.225634,	
2017-07-18 08:02:53,570 Epoch[39] Batch [450]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.225076,	
2017-07-18 08:03:01,410 Epoch[39] Batch [460]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.224639,	
2017-07-18 08:03:09,686 Epoch[39] Batch [470]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.225348,	
2017-07-18 08:03:18,312 Epoch[39] Batch [480]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.225319,	
2017-07-18 08:03:26,368 Epoch[39] Batch [490]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.226194,	
2017-07-18 08:03:34,575 Epoch[39] Batch [500]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.226594,	
2017-07-18 08:03:42,651 Epoch[39] Batch [510]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.224211,	
2017-07-18 08:03:50,456 Epoch[39] Batch [520]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.225339,	
2017-07-18 08:03:58,549 Epoch[39] Batch [530]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.228324,	
2017-07-18 08:04:06,593 Epoch[39] Batch [540]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.229622,	
2017-07-18 08:04:14,610 Epoch[39] Batch [550]	Speed: 4.99 samples/sec	Train-FCNLogLoss=1.229983,	
2017-07-18 08:04:22,699 Epoch[39] Batch [560]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.232158,	
2017-07-18 08:04:30,928 Epoch[39] Batch [570]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.233926,	
2017-07-18 08:04:39,206 Epoch[39] Batch [580]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.235609,	
2017-07-18 08:04:47,436 Epoch[39] Batch [590]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.235093,	
2017-07-18 08:04:55,518 Epoch[39] Batch [600]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.236489,	
2017-07-18 08:05:03,313 Epoch[39] Batch [610]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.238202,	
2017-07-18 08:05:11,210 Epoch[39] Batch [620]	Speed: 5.07 samples/sec	Train-FCNLogLoss=1.236916,	
2017-07-18 08:05:19,503 Epoch[39] Batch [630]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.238827,	
2017-07-18 08:05:27,402 Epoch[39] Batch [640]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.238795,	
2017-07-18 08:05:35,601 Epoch[39] Batch [650]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.237647,	
2017-07-18 08:05:43,653 Epoch[39] Batch [660]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.237424,	
2017-07-18 08:05:51,688 Epoch[39] Batch [670]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.237359,	
2017-07-18 08:06:00,036 Epoch[39] Batch [680]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.237868,	
2017-07-18 08:06:07,897 Epoch[39] Batch [690]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.237568,	
2017-07-18 08:06:15,994 Epoch[39] Batch [700]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.236952,	
2017-07-18 08:06:24,020 Epoch[39] Batch [710]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.236493,	
2017-07-18 08:06:32,323 Epoch[39] Batch [720]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.235817,	
2017-07-18 08:06:39,868 Epoch[39] Batch [730]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.234500,	
2017-07-18 08:06:48,183 Epoch[39] Batch [740]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.233552,	
2017-07-18 08:06:56,585 Epoch[39] Batch [750]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.232569,	
2017-07-18 08:07:05,290 Epoch[39] Batch [760]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.232451,	
2017-07-18 08:07:13,791 Epoch[39] Batch [770]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.232234,	
2017-07-18 08:07:22,119 Epoch[39] Batch [780]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.232380,	
2017-07-18 08:07:30,642 Epoch[39] Batch [790]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.231767,	
2017-07-18 08:07:38,290 Epoch[39] Batch [800]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.230992,	
2017-07-18 08:07:46,585 Epoch[39] Batch [810]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.232343,	
2017-07-18 08:07:54,697 Epoch[39] Batch [820]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.231567,	
2017-07-18 08:08:03,145 Epoch[39] Batch [830]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.231582,	
2017-07-18 08:08:11,531 Epoch[39] Batch [840]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.231736,	
2017-07-18 08:08:19,748 Epoch[39] Batch [850]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.231610,	
2017-07-18 08:08:28,073 Epoch[39] Batch [860]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.231466,	
2017-07-18 08:08:36,693 Epoch[39] Batch [870]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.229911,	
2017-07-18 08:08:44,898 Epoch[39] Batch [880]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.229138,	
2017-07-18 08:08:53,518 Epoch[39] Batch [890]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.227928,	
2017-07-18 08:09:01,879 Epoch[39] Batch [900]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.227980,	
2017-07-18 08:09:10,158 Epoch[39] Batch [910]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.227490,	
2017-07-18 08:09:18,552 Epoch[39] Batch [920]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.227373,	
2017-07-18 08:09:26,482 Epoch[39] Batch [930]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.227647,	
2017-07-18 08:09:34,692 Epoch[39] Batch [940]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.228811,	
2017-07-18 08:09:42,969 Epoch[39] Batch [950]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.229115,	
2017-07-18 08:09:51,420 Epoch[39] Batch [960]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.229342,	
2017-07-18 08:09:59,516 Epoch[39] Batch [970]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.228644,	
2017-07-18 08:10:07,831 Epoch[39] Batch [980]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.228185,	
2017-07-18 08:10:16,263 Epoch[39] Batch [990]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.227178,	
2017-07-18 08:10:24,981 Epoch[39] Batch [1000]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.226669,	
2017-07-18 08:10:32,977 Epoch[39] Batch [1010]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.227460,	
2017-07-18 08:10:41,412 Epoch[39] Batch [1020]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.226634,	
2017-07-18 08:10:49,636 Epoch[39] Batch [1030]	Speed: 4.86 samples/sec	Train-FCNLogLoss=1.226072,	
2017-07-18 08:10:58,100 Epoch[39] Batch [1040]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.226439,	
2017-07-18 08:11:06,793 Epoch[39] Batch [1050]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.226700,	
2017-07-18 08:11:15,146 Epoch[39] Batch [1060]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.227452,	
2017-07-18 08:11:24,018 Epoch[39] Batch [1070]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.226660,	
2017-07-18 08:11:32,323 Epoch[39] Batch [1080]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.227946,	
2017-07-18 08:11:40,527 Epoch[39] Batch [1090]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.229501,	
2017-07-18 08:11:49,116 Epoch[39] Batch [1100]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.229402,	
2017-07-18 08:11:57,296 Epoch[39] Batch [1110]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.228395,	
2017-07-18 08:12:06,025 Epoch[39] Batch [1120]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.228220,	
2017-07-18 08:12:14,812 Epoch[39] Batch [1130]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.227596,	
2017-07-18 08:12:23,449 Epoch[39] Batch [1140]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.228601,	
2017-07-18 08:12:31,926 Epoch[39] Batch [1150]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.228054,	
2017-07-18 08:12:40,198 Epoch[39] Batch [1160]	Speed: 4.84 samples/sec	Train-FCNLogLoss=1.230398,	
2017-07-18 08:12:48,882 Epoch[39] Batch [1170]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.230070,	
2017-07-18 08:12:57,172 Epoch[39] Batch [1180]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.230238,	
2017-07-18 08:13:06,004 Epoch[39] Batch [1190]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.230529,	
2017-07-18 08:13:14,284 Epoch[39] Batch [1200]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.230697,	
2017-07-18 08:13:22,710 Epoch[39] Batch [1210]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.231006,	
2017-07-18 08:13:30,703 Epoch[39] Batch [1220]	Speed: 5.00 samples/sec	Train-FCNLogLoss=1.230691,	
2017-07-18 08:13:39,312 Epoch[39] Batch [1230]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.231244,	
2017-07-18 08:13:48,267 Epoch[39] Batch [1240]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.230872,	
2017-07-18 08:13:56,646 Epoch[39] Batch [1250]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.231495,	
2017-07-18 08:14:05,055 Epoch[39] Batch [1260]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.231172,	
2017-07-18 08:14:14,173 Epoch[39] Batch [1270]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.232159,	
2017-07-18 08:14:22,560 Epoch[39] Batch [1280]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.232312,	
2017-07-18 08:14:30,778 Epoch[39] Batch [1290]	Speed: 4.87 samples/sec	Train-FCNLogLoss=1.232746,	
2017-07-18 08:14:39,167 Epoch[39] Batch [1300]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.232931,	
2017-07-18 08:14:48,015 Epoch[39] Batch [1310]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.232329,	
2017-07-18 08:14:56,426 Epoch[39] Batch [1320]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.232942,	
2017-07-18 08:15:04,721 Epoch[39] Batch [1330]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.232550,	
2017-07-18 08:15:13,524 Epoch[39] Batch [1340]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.232685,	
2017-07-18 08:15:22,713 Epoch[39] Batch [1350]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.232836,	
2017-07-18 08:15:31,556 Epoch[39] Batch [1360]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.232526,	
2017-07-18 08:15:39,633 Epoch[39] Batch [1370]	Speed: 4.95 samples/sec	Train-FCNLogLoss=1.232443,	
2017-07-18 08:15:48,285 Epoch[39] Batch [1380]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.232251,	
2017-07-18 08:15:56,954 Epoch[39] Batch [1390]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.232164,	
2017-07-18 08:16:05,444 Epoch[39] Batch [1400]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.231841,	
2017-07-18 08:16:13,817 Epoch[39] Batch [1410]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.232366,	
2017-07-18 08:16:22,466 Epoch[39] Batch [1420]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.231709,	
2017-07-18 08:16:31,296 Epoch[39] Batch [1430]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.231334,	
2017-07-18 08:16:39,579 Epoch[39] Batch [1440]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.231187,	
2017-07-18 08:16:47,982 Epoch[39] Batch [1450]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.231977,	
2017-07-18 08:16:56,720 Epoch[39] Batch [1460]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.232061,	
2017-07-18 08:17:05,298 Epoch[39] Batch [1470]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.231960,	
2017-07-18 08:17:14,103 Epoch[39] Batch [1480]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.231514,	
2017-07-18 08:17:19,276 Epoch[39] Train-FCNLogLoss=1.232093
2017-07-18 08:17:19,276 Epoch[39] Time cost=1231.919
2017-07-18 08:17:20,252 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.params"
2017-07-18 08:17:23,006 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.states"
2017-07-18 08:17:32,893 Epoch[40] Batch [10]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.243729,	
2017-07-18 08:17:41,553 Epoch[40] Batch [20]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.262820,	
2017-07-18 08:17:49,535 Epoch[40] Batch [30]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.268556,	
2017-07-18 08:17:57,636 Epoch[40] Batch [40]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.249767,	
2017-07-18 08:18:05,621 Epoch[40] Batch [50]	Speed: 5.01 samples/sec	Train-FCNLogLoss=1.269318,	
2017-07-18 08:18:14,069 Epoch[40] Batch [60]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.258644,	
2017-07-18 08:18:22,108 Epoch[40] Batch [70]	Speed: 4.98 samples/sec	Train-FCNLogLoss=1.240720,	
2017-07-18 08:18:30,414 Epoch[40] Batch [80]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.238858,	
2017-07-18 08:18:38,852 Epoch[40] Batch [90]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.245487,	
2017-07-18 08:18:46,761 Epoch[40] Batch [100]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.253409,	
2017-07-18 08:18:55,238 Epoch[40] Batch [110]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.246923,	
2017-07-18 08:19:03,436 Epoch[40] Batch [120]	Speed: 4.88 samples/sec	Train-FCNLogLoss=1.243628,	
2017-07-18 08:19:12,206 Epoch[40] Batch [130]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.240188,	
2017-07-18 08:19:20,277 Epoch[40] Batch [140]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.244270,	
2017-07-18 08:19:28,982 Epoch[40] Batch [150]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.241219,	
2017-07-18 08:19:37,910 Epoch[40] Batch [160]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.240185,	
2017-07-18 08:19:46,220 Epoch[40] Batch [170]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.243628,	
2017-07-18 08:19:54,981 Epoch[40] Batch [180]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.246224,	
2017-07-18 08:20:03,424 Epoch[40] Batch [190]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.246769,	
2017-07-18 08:20:11,992 Epoch[40] Batch [200]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.251910,	
2017-07-18 08:20:20,416 Epoch[40] Batch [210]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.255978,	
2017-07-18 08:20:28,699 Epoch[40] Batch [220]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.254846,	
2017-07-18 08:20:37,437 Epoch[40] Batch [230]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.257520,	
2017-07-18 08:20:45,806 Epoch[40] Batch [240]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.255848,	
2017-07-18 08:20:54,098 Epoch[40] Batch [250]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.254077,	
2017-07-18 08:21:02,930 Epoch[40] Batch [260]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.254394,	
2017-07-18 08:21:11,633 Epoch[40] Batch [270]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.251288,	
2017-07-18 08:21:20,091 Epoch[40] Batch [280]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.249523,	
2017-07-18 08:21:28,713 Epoch[40] Batch [290]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.248459,	
2017-07-18 08:21:36,953 Epoch[40] Batch [300]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.245894,	
2017-07-18 08:21:45,699 Epoch[40] Batch [310]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.246688,	
2017-07-18 08:21:54,163 Epoch[40] Batch [320]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.248680,	
2017-07-18 08:22:02,319 Epoch[40] Batch [330]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.247243,	
2017-07-18 08:22:11,090 Epoch[40] Batch [340]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.247413,	
2017-07-18 08:22:19,647 Epoch[40] Batch [350]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.247629,	
2017-07-18 08:22:27,992 Epoch[40] Batch [360]	Speed: 4.79 samples/sec	Train-FCNLogLoss=1.244753,	
2017-07-18 08:22:36,730 Epoch[40] Batch [370]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.244461,	
2017-07-18 08:22:45,614 Epoch[40] Batch [380]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.244175,	
2017-07-18 08:22:54,341 Epoch[40] Batch [390]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.243381,	
2017-07-18 08:23:02,637 Epoch[40] Batch [400]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.243311,	
2017-07-18 08:23:11,133 Epoch[40] Batch [410]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.240686,	
2017-07-18 08:23:20,211 Epoch[40] Batch [420]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.240317,	
2017-07-18 08:23:28,621 Epoch[40] Batch [430]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.240340,	
2017-07-18 08:23:37,378 Epoch[40] Batch [440]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238161,	
2017-07-18 08:23:46,047 Epoch[40] Batch [450]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.239198,	
2017-07-18 08:23:54,669 Epoch[40] Batch [460]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.239955,	
2017-07-18 08:24:03,173 Epoch[40] Batch [470]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.240855,	
2017-07-18 08:24:11,549 Epoch[40] Batch [480]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.240161,	
2017-07-18 08:24:20,306 Epoch[40] Batch [490]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.240026,	
2017-07-18 08:24:28,985 Epoch[40] Batch [500]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.238447,	
2017-07-18 08:24:37,648 Epoch[40] Batch [510]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.239911,	
2017-07-18 08:24:44,889 Update[60000]: Change learning rate to 5.00000e-05
2017-07-18 08:24:46,134 Epoch[40] Batch [520]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.239813,	
2017-07-18 08:24:54,897 Epoch[40] Batch [530]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.238033,	
2017-07-18 08:25:03,452 Epoch[40] Batch [540]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.238352,	
2017-07-18 08:25:12,215 Epoch[40] Batch [550]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238339,	
2017-07-18 08:25:21,046 Epoch[40] Batch [560]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.236742,	
2017-07-18 08:25:29,555 Epoch[40] Batch [570]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.238110,	
2017-07-18 08:25:38,187 Epoch[40] Batch [580]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237707,	
2017-07-18 08:25:46,906 Epoch[40] Batch [590]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.236808,	
2017-07-18 08:25:55,833 Epoch[40] Batch [600]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.235701,	
2017-07-18 08:26:04,588 Epoch[40] Batch [610]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.234147,	
2017-07-18 08:26:13,006 Epoch[40] Batch [620]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.232178,	
2017-07-18 08:26:21,370 Epoch[40] Batch [630]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.232307,	
2017-07-18 08:26:30,135 Epoch[40] Batch [640]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.233160,	
2017-07-18 08:26:38,681 Epoch[40] Batch [650]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.231814,	
2017-07-18 08:26:47,437 Epoch[40] Batch [660]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.232270,	
2017-07-18 08:26:56,608 Epoch[40] Batch [670]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.231251,	
2017-07-18 08:27:05,406 Epoch[40] Batch [680]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.231895,	
2017-07-18 08:27:14,055 Epoch[40] Batch [690]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.233470,	
2017-07-18 08:27:22,375 Epoch[40] Batch [700]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.233829,	
2017-07-18 08:27:31,327 Epoch[40] Batch [710]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.233111,	
2017-07-18 08:27:39,770 Epoch[40] Batch [720]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.234320,	
2017-07-18 08:27:48,553 Epoch[40] Batch [730]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.233886,	
2017-07-18 08:27:57,235 Epoch[40] Batch [740]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.233474,	
2017-07-18 08:28:05,900 Epoch[40] Batch [750]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.233827,	
2017-07-18 08:28:14,882 Epoch[40] Batch [760]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.232788,	
2017-07-18 08:28:23,437 Epoch[40] Batch [770]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.232458,	
2017-07-18 08:28:32,000 Epoch[40] Batch [780]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.232286,	
2017-07-18 08:28:44,376 Epoch[40] Batch [790]	Speed: 3.23 samples/sec	Train-FCNLogLoss=1.232861,	
2017-07-18 08:28:56,787 Epoch[40] Batch [800]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.232150,	
2017-07-18 08:29:06,937 Epoch[40] Batch [810]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.231935,	
2017-07-18 08:29:18,501 Epoch[40] Batch [820]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.231343,	
2017-07-18 08:29:29,743 Epoch[40] Batch [830]	Speed: 3.56 samples/sec	Train-FCNLogLoss=1.231541,	
2017-07-18 08:29:40,892 Epoch[40] Batch [840]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.231446,	
2017-07-18 08:29:53,588 Epoch[40] Batch [850]	Speed: 3.15 samples/sec	Train-FCNLogLoss=1.233575,	
2017-07-18 08:30:04,698 Epoch[40] Batch [860]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.234043,	
2017-07-18 08:30:16,387 Epoch[40] Batch [870]	Speed: 3.42 samples/sec	Train-FCNLogLoss=1.233681,	
2017-07-18 08:30:28,296 Epoch[40] Batch [880]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.235200,	
2017-07-18 08:30:39,329 Epoch[40] Batch [890]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.235943,	
2017-07-18 08:30:51,003 Epoch[40] Batch [900]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.234696,	
2017-07-18 08:31:00,981 Epoch[40] Batch [910]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.235524,	
2017-07-18 08:31:10,876 Epoch[40] Batch [920]	Speed: 4.04 samples/sec	Train-FCNLogLoss=1.236160,	
2017-07-18 08:31:23,225 Epoch[40] Batch [930]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.236664,	
2017-07-18 08:31:33,032 Epoch[40] Batch [940]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.236440,	
2017-07-18 08:31:44,631 Epoch[40] Batch [950]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.236691,	
2017-07-18 08:31:55,188 Epoch[40] Batch [960]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.237608,	
2017-07-18 08:32:05,764 Epoch[40] Batch [970]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.236972,	
2017-07-18 08:32:15,339 Epoch[40] Batch [980]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.236095,	
2017-07-18 08:32:26,754 Epoch[40] Batch [990]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.236319,	
2017-07-18 08:32:37,356 Epoch[40] Batch [1000]	Speed: 3.77 samples/sec	Train-FCNLogLoss=1.236514,	
2017-07-18 08:32:47,476 Epoch[40] Batch [1010]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.236343,	
2017-07-18 08:32:56,620 Epoch[40] Batch [1020]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.236304,	
2017-07-18 08:33:07,940 Epoch[40] Batch [1030]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.237850,	
2017-07-18 08:33:18,839 Epoch[40] Batch [1040]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.236555,	
2017-07-18 08:33:30,092 Epoch[40] Batch [1050]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.236729,	
2017-07-18 08:33:39,939 Epoch[40] Batch [1060]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.237138,	
2017-07-18 08:33:50,207 Epoch[40] Batch [1070]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.237985,	
2017-07-18 08:34:00,137 Epoch[40] Batch [1080]	Speed: 4.03 samples/sec	Train-FCNLogLoss=1.237529,	
2017-07-18 08:34:10,315 Epoch[40] Batch [1090]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.237957,	
2017-07-18 08:34:22,169 Epoch[40] Batch [1100]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.237250,	
2017-07-18 08:34:32,029 Epoch[40] Batch [1110]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.236947,	
2017-07-18 08:34:42,709 Epoch[40] Batch [1120]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.238173,	
2017-07-18 08:34:53,337 Epoch[40] Batch [1130]	Speed: 3.76 samples/sec	Train-FCNLogLoss=1.237410,	
2017-07-18 08:35:03,752 Epoch[40] Batch [1140]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.237807,	
2017-07-18 08:35:15,514 Epoch[40] Batch [1150]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.236824,	
2017-07-18 08:35:26,554 Epoch[40] Batch [1160]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.236537,	
2017-07-18 08:35:37,622 Epoch[40] Batch [1170]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.236663,	
2017-07-18 08:35:50,071 Epoch[40] Batch [1180]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.236790,	
2017-07-18 08:35:59,578 Epoch[40] Batch [1190]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.237433,	
2017-07-18 08:36:12,062 Epoch[40] Batch [1200]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.237518,	
2017-07-18 08:36:23,433 Epoch[40] Batch [1210]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.237256,	
2017-07-18 08:36:32,730 Epoch[40] Batch [1220]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.236544,	
2017-07-18 08:36:43,717 Epoch[40] Batch [1230]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.236641,	
2017-07-18 08:36:52,981 Epoch[40] Batch [1240]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.236834,	
2017-07-18 08:37:04,733 Epoch[40] Batch [1250]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.236414,	
2017-07-18 08:37:14,807 Epoch[40] Batch [1260]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.236250,	
2017-07-18 08:37:26,134 Epoch[40] Batch [1270]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.236471,	
2017-07-18 08:37:36,306 Epoch[40] Batch [1280]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.236443,	
2017-07-18 08:37:46,517 Epoch[40] Batch [1290]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.237100,	
2017-07-18 08:37:58,113 Epoch[40] Batch [1300]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.237424,	
2017-07-18 08:38:08,081 Epoch[40] Batch [1310]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.238552,	
2017-07-18 08:38:18,837 Epoch[40] Batch [1320]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.238794,	
2017-07-18 08:38:29,886 Epoch[40] Batch [1330]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.238611,	
2017-07-18 08:38:40,742 Epoch[40] Batch [1340]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.238401,	
2017-07-18 08:38:49,388 Epoch[40] Batch [1350]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.238511,	
2017-07-18 08:38:58,284 Epoch[40] Batch [1360]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.238314,	
2017-07-18 08:39:07,262 Epoch[40] Batch [1370]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.238462,	
2017-07-18 08:39:16,141 Epoch[40] Batch [1380]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.237732,	
2017-07-18 08:39:25,120 Epoch[40] Batch [1390]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.238102,	
2017-07-18 08:39:33,880 Epoch[40] Batch [1400]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.238010,	
2017-07-18 08:39:42,483 Epoch[40] Batch [1410]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.237818,	
2017-07-18 08:39:51,097 Epoch[40] Batch [1420]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.237827,	
2017-07-18 08:39:59,747 Epoch[40] Batch [1430]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.237743,	
2017-07-18 08:40:08,089 Epoch[40] Batch [1440]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.237925,	
2017-07-18 08:40:16,555 Epoch[40] Batch [1450]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.237996,	
2017-07-18 08:40:25,359 Epoch[40] Batch [1460]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.237686,	
2017-07-18 08:40:33,996 Epoch[40] Batch [1470]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.237037,	
2017-07-18 08:40:43,092 Epoch[40] Batch [1480]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.237347,	
2017-07-18 08:40:48,341 Epoch[40] Train-FCNLogLoss=1.237429
2017-07-18 08:40:48,342 Epoch[40] Time cost=1405.135
2017-07-18 08:40:49,767 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.params"
2017-07-18 08:40:52,626 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.states"
2017-07-18 08:41:02,762 Epoch[41] Batch [10]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.123827,	
2017-07-18 08:41:11,369 Epoch[41] Batch [20]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.178607,	
2017-07-18 08:41:19,997 Epoch[41] Batch [30]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.221162,	
2017-07-18 08:41:28,858 Epoch[41] Batch [40]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.191710,	
2017-07-18 08:41:37,343 Epoch[41] Batch [50]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.194017,	
2017-07-18 08:41:46,284 Epoch[41] Batch [60]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.191484,	
2017-07-18 08:41:55,130 Epoch[41] Batch [70]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.215566,	
2017-07-18 08:42:03,723 Epoch[41] Batch [80]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.217062,	
2017-07-18 08:42:12,416 Epoch[41] Batch [90]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.223003,	
2017-07-18 08:42:21,247 Epoch[41] Batch [100]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.224092,	
2017-07-18 08:42:30,371 Epoch[41] Batch [110]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.218242,	
2017-07-18 08:42:39,012 Epoch[41] Batch [120]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.217622,	
2017-07-18 08:42:47,641 Epoch[41] Batch [130]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.217273,	
2017-07-18 08:42:56,526 Epoch[41] Batch [140]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.220134,	
2017-07-18 08:43:05,321 Epoch[41] Batch [150]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.224479,	
2017-07-18 08:43:13,772 Epoch[41] Batch [160]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.224453,	
2017-07-18 08:43:22,636 Epoch[41] Batch [170]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.219969,	
2017-07-18 08:43:31,543 Epoch[41] Batch [180]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.220512,	
2017-07-18 08:43:40,292 Epoch[41] Batch [190]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.215870,	
2017-07-18 08:43:49,116 Epoch[41] Batch [200]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.213463,	
2017-07-18 08:43:57,594 Epoch[41] Batch [210]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.213604,	
2017-07-18 08:44:06,291 Epoch[41] Batch [220]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.215237,	
2017-07-18 08:44:15,209 Epoch[41] Batch [230]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.218041,	
2017-07-18 08:44:23,976 Epoch[41] Batch [240]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.219369,	
2017-07-18 08:44:32,942 Epoch[41] Batch [250]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.220667,	
2017-07-18 08:44:41,927 Epoch[41] Batch [260]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.225010,	
2017-07-18 08:44:50,847 Epoch[41] Batch [270]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.225277,	
2017-07-18 08:44:59,733 Epoch[41] Batch [280]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.225705,	
2017-07-18 08:45:08,627 Epoch[41] Batch [290]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.227575,	
2017-07-18 08:45:17,298 Epoch[41] Batch [300]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.227513,	
2017-07-18 08:45:26,142 Epoch[41] Batch [310]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.225843,	
2017-07-18 08:45:34,626 Epoch[41] Batch [320]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.225331,	
2017-07-18 08:45:43,373 Epoch[41] Batch [330]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.228446,	
2017-07-18 08:45:52,031 Epoch[41] Batch [340]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.226180,	
2017-07-18 08:46:00,847 Epoch[41] Batch [350]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.228448,	
2017-07-18 08:46:10,052 Epoch[41] Batch [360]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.228370,	
2017-07-18 08:46:18,703 Epoch[41] Batch [370]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.226733,	
2017-07-18 08:46:27,474 Epoch[41] Batch [380]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.228695,	
2017-07-18 08:46:36,106 Epoch[41] Batch [390]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.229354,	
2017-07-18 08:46:44,865 Epoch[41] Batch [400]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.230200,	
2017-07-18 08:46:53,418 Epoch[41] Batch [410]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.228672,	
2017-07-18 08:47:02,088 Epoch[41] Batch [420]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.227033,	
2017-07-18 08:47:11,075 Epoch[41] Batch [430]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.227072,	
2017-07-18 08:47:21,582 Epoch[41] Batch [440]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.228523,	
2017-07-18 08:47:32,006 Epoch[41] Batch [450]	Speed: 3.84 samples/sec	Train-FCNLogLoss=1.229277,	
2017-07-18 08:47:41,826 Epoch[41] Batch [460]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.227869,	
2017-07-18 08:47:53,504 Epoch[41] Batch [470]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.226992,	
2017-07-18 08:48:05,025 Epoch[41] Batch [480]	Speed: 3.47 samples/sec	Train-FCNLogLoss=1.225163,	
2017-07-18 08:48:15,501 Epoch[41] Batch [490]	Speed: 3.82 samples/sec	Train-FCNLogLoss=1.227170,	
2017-07-18 08:48:26,339 Epoch[41] Batch [500]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.226430,	
2017-07-18 08:48:38,021 Epoch[41] Batch [510]	Speed: 3.42 samples/sec	Train-FCNLogLoss=1.224583,	
2017-07-18 08:48:50,350 Epoch[41] Batch [520]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.224751,	
2017-07-18 08:49:01,341 Epoch[41] Batch [530]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.225491,	
2017-07-18 08:49:11,440 Epoch[41] Batch [540]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.227612,	
2017-07-18 08:49:22,905 Epoch[41] Batch [550]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.229631,	
2017-07-18 08:49:32,766 Epoch[41] Batch [560]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.229840,	
2017-07-18 08:49:45,428 Epoch[41] Batch [570]	Speed: 3.16 samples/sec	Train-FCNLogLoss=1.230238,	
2017-07-18 08:49:55,166 Epoch[41] Batch [580]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.230025,	
2017-07-18 08:50:07,073 Epoch[41] Batch [590]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.230539,	
2017-07-18 08:50:17,800 Epoch[41] Batch [600]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.229538,	
2017-07-18 08:50:28,763 Epoch[41] Batch [610]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.230293,	
2017-07-18 08:50:40,744 Epoch[41] Batch [620]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.231726,	
2017-07-18 08:50:51,605 Epoch[41] Batch [630]	Speed: 3.68 samples/sec	Train-FCNLogLoss=1.232627,	
2017-07-18 08:51:02,965 Epoch[41] Batch [640]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.233732,	
2017-07-18 08:51:13,508 Epoch[41] Batch [650]	Speed: 3.79 samples/sec	Train-FCNLogLoss=1.233501,	
2017-07-18 08:51:25,539 Epoch[41] Batch [660]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.233753,	
2017-07-18 08:51:36,598 Epoch[41] Batch [670]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.234697,	
2017-07-18 08:51:48,674 Epoch[41] Batch [680]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.235793,	
2017-07-18 08:52:00,044 Epoch[41] Batch [690]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.235517,	
2017-07-18 08:52:09,323 Epoch[41] Batch [700]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.235826,	
2017-07-18 08:52:21,476 Epoch[41] Batch [710]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.235570,	
2017-07-18 08:52:32,953 Epoch[41] Batch [720]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.235341,	
2017-07-18 08:52:46,923 Epoch[41] Batch [730]	Speed: 2.86 samples/sec	Train-FCNLogLoss=1.234883,	
2017-07-18 08:52:57,325 Epoch[41] Batch [740]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.236047,	
2017-07-18 08:53:07,584 Epoch[41] Batch [750]	Speed: 3.90 samples/sec	Train-FCNLogLoss=1.237131,	
2017-07-18 08:53:18,439 Epoch[41] Batch [760]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.237443,	
2017-07-18 08:53:30,202 Epoch[41] Batch [770]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.236473,	
2017-07-18 08:53:41,330 Epoch[41] Batch [780]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.236725,	
2017-07-18 08:53:53,512 Epoch[41] Batch [790]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.234425,	
2017-07-18 08:54:04,214 Epoch[41] Batch [800]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.234072,	
2017-07-18 08:54:15,460 Epoch[41] Batch [810]	Speed: 3.56 samples/sec	Train-FCNLogLoss=1.234214,	
2017-07-18 08:54:26,429 Epoch[41] Batch [820]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.232769,	
2017-07-18 08:54:37,593 Epoch[41] Batch [830]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.232351,	
2017-07-18 08:54:49,424 Epoch[41] Batch [840]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.233182,	
2017-07-18 08:55:02,065 Epoch[41] Batch [850]	Speed: 3.16 samples/sec	Train-FCNLogLoss=1.233647,	
2017-07-18 08:55:14,066 Epoch[41] Batch [860]	Speed: 3.33 samples/sec	Train-FCNLogLoss=1.232399,	
2017-07-18 08:55:24,804 Epoch[41] Batch [870]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.231907,	
2017-07-18 08:55:35,550 Epoch[41] Batch [880]	Speed: 3.72 samples/sec	Train-FCNLogLoss=1.231886,	
2017-07-18 08:55:48,330 Epoch[41] Batch [890]	Speed: 3.13 samples/sec	Train-FCNLogLoss=1.232475,	
2017-07-18 08:56:00,753 Epoch[41] Batch [900]	Speed: 3.22 samples/sec	Train-FCNLogLoss=1.231836,	
2017-07-18 08:56:10,894 Epoch[41] Batch [910]	Speed: 3.94 samples/sec	Train-FCNLogLoss=1.232408,	
2017-07-18 08:56:23,416 Epoch[41] Batch [920]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.232620,	
2017-07-18 08:56:33,620 Epoch[41] Batch [930]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.231872,	
2017-07-18 08:56:46,249 Epoch[41] Batch [940]	Speed: 3.17 samples/sec	Train-FCNLogLoss=1.231596,	
2017-07-18 08:56:58,079 Epoch[41] Batch [950]	Speed: 3.38 samples/sec	Train-FCNLogLoss=1.233267,	
2017-07-18 08:57:09,617 Epoch[41] Batch [960]	Speed: 3.47 samples/sec	Train-FCNLogLoss=1.232156,	
2017-07-18 08:57:20,774 Epoch[41] Batch [970]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.232871,	
2017-07-18 08:57:31,826 Epoch[41] Batch [980]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.233123,	
2017-07-18 08:57:44,001 Epoch[41] Batch [990]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.233426,	
2017-07-18 08:57:54,510 Epoch[41] Batch [1000]	Speed: 3.81 samples/sec	Train-FCNLogLoss=1.233629,	
2017-07-18 08:58:05,785 Epoch[41] Batch [1010]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.233649,	
2017-07-18 08:58:17,522 Epoch[41] Batch [1020]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.233707,	
2017-07-18 08:58:29,573 Epoch[41] Batch [1030]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.234101,	
2017-07-18 08:58:41,625 Epoch[41] Batch [1040]	Speed: 3.32 samples/sec	Train-FCNLogLoss=1.232953,	
2017-07-18 08:58:51,691 Epoch[41] Batch [1050]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.233374,	
2017-07-18 08:59:03,975 Epoch[41] Batch [1060]	Speed: 3.26 samples/sec	Train-FCNLogLoss=1.233420,	
2017-07-18 08:59:15,570 Epoch[41] Batch [1070]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.232418,	
2017-07-18 08:59:25,751 Epoch[41] Batch [1080]	Speed: 3.93 samples/sec	Train-FCNLogLoss=1.232792,	
2017-07-18 08:59:37,522 Epoch[41] Batch [1090]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.232195,	
2017-07-18 08:59:46,236 Epoch[41] Batch [1100]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.231123,	
2017-07-18 08:59:55,207 Epoch[41] Batch [1110]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.230455,	
2017-07-18 09:00:04,070 Epoch[41] Batch [1120]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.230001,	
2017-07-18 09:00:13,016 Epoch[41] Batch [1130]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.229669,	
2017-07-18 09:00:22,164 Epoch[41] Batch [1140]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.229231,	
2017-07-18 09:00:30,727 Epoch[41] Batch [1150]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.228765,	
2017-07-18 09:00:39,464 Epoch[41] Batch [1160]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.228743,	
2017-07-18 09:00:48,243 Epoch[41] Batch [1170]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.228694,	
2017-07-18 09:00:56,979 Epoch[41] Batch [1180]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.228473,	
2017-07-18 09:01:05,947 Epoch[41] Batch [1190]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.228735,	
2017-07-18 09:01:15,053 Epoch[41] Batch [1200]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.228550,	
2017-07-18 09:01:24,032 Epoch[41] Batch [1210]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.228416,	
2017-07-18 09:01:32,912 Epoch[41] Batch [1220]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.229114,	
2017-07-18 09:01:41,947 Epoch[41] Batch [1230]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.229581,	
2017-07-18 09:01:50,504 Epoch[41] Batch [1240]	Speed: 4.68 samples/sec	Train-FCNLogLoss=1.229367,	
2017-07-18 09:01:59,344 Epoch[41] Batch [1250]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.229559,	
2017-07-18 09:02:08,428 Epoch[41] Batch [1260]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.229463,	
2017-07-18 09:02:17,303 Epoch[41] Batch [1270]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.230026,	
2017-07-18 09:02:26,485 Epoch[41] Batch [1280]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.230491,	
2017-07-18 09:02:35,892 Epoch[41] Batch [1290]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.231221,	
2017-07-18 09:02:44,712 Epoch[41] Batch [1300]	Speed: 4.54 samples/sec	Train-FCNLogLoss=1.231031,	
2017-07-18 09:02:53,801 Epoch[41] Batch [1310]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.230670,	
2017-07-18 09:03:03,072 Epoch[41] Batch [1320]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.231134,	
2017-07-18 09:03:12,052 Epoch[41] Batch [1330]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.231902,	
2017-07-18 09:03:21,212 Epoch[41] Batch [1340]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.231533,	
2017-07-18 09:03:30,228 Epoch[41] Batch [1350]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.230702,	
2017-07-18 09:03:38,909 Epoch[41] Batch [1360]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.230450,	
2017-07-18 09:03:48,193 Epoch[41] Batch [1370]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.230378,	
2017-07-18 09:03:57,395 Epoch[41] Batch [1380]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.229978,	
2017-07-18 09:04:06,403 Epoch[41] Batch [1390]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.229630,	
2017-07-18 09:04:15,314 Epoch[41] Batch [1400]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.229831,	
2017-07-18 09:04:24,585 Epoch[41] Batch [1410]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.230135,	
2017-07-18 09:04:34,238 Epoch[41] Batch [1420]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.231622,	
2017-07-18 09:04:43,477 Epoch[41] Batch [1430]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.231469,	
2017-07-18 09:04:52,644 Epoch[41] Batch [1440]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.231335,	
2017-07-18 09:05:01,514 Epoch[41] Batch [1450]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.231884,	
2017-07-18 09:05:10,455 Epoch[41] Batch [1460]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.232240,	
2017-07-18 09:05:19,629 Epoch[41] Batch [1470]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.231705,	
2017-07-18 09:05:28,569 Epoch[41] Batch [1480]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.230873,	
2017-07-18 09:05:34,225 Epoch[41] Train-FCNLogLoss=1.231273
2017-07-18 09:05:34,225 Epoch[41] Time cost=1481.337
2017-07-18 09:05:35,188 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.params"
2017-07-18 09:05:37,606 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.states"
2017-07-18 09:05:49,053 Epoch[42] Batch [10]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.246746,	
2017-07-18 09:05:58,839 Epoch[42] Batch [20]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.228796,	
2017-07-18 09:06:07,930 Epoch[42] Batch [30]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.235990,	
2017-07-18 09:06:16,240 Epoch[42] Batch [40]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.228890,	
2017-07-18 09:06:24,806 Epoch[42] Batch [50]	Speed: 4.67 samples/sec	Train-FCNLogLoss=1.242094,	
2017-07-18 09:06:33,138 Epoch[42] Batch [60]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.259020,	
2017-07-18 09:06:41,745 Epoch[42] Batch [70]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.252723,	
2017-07-18 09:06:50,570 Epoch[42] Batch [80]	Speed: 4.53 samples/sec	Train-FCNLogLoss=1.254332,	
2017-07-18 09:06:58,932 Epoch[42] Batch [90]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.256290,	
2017-07-18 09:07:07,551 Epoch[42] Batch [100]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.249483,	
2017-07-18 09:07:16,047 Epoch[42] Batch [110]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.249297,	
2017-07-18 09:07:24,921 Epoch[42] Batch [120]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.255855,	
2017-07-18 09:07:34,205 Epoch[42] Batch [130]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.252825,	
2017-07-18 09:07:42,915 Epoch[42] Batch [140]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.253926,	
2017-07-18 09:07:51,301 Epoch[42] Batch [150]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.250278,	
2017-07-18 09:08:00,395 Epoch[42] Batch [160]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.250767,	
2017-07-18 09:08:09,164 Epoch[42] Batch [170]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.250186,	
2017-07-18 09:08:18,041 Epoch[42] Batch [180]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.247100,	
2017-07-18 09:08:26,798 Epoch[42] Batch [190]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.249149,	
2017-07-18 09:08:35,766 Epoch[42] Batch [200]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.244953,	
2017-07-18 09:08:44,694 Epoch[42] Batch [210]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.250870,	
2017-07-18 09:08:53,395 Epoch[42] Batch [220]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.251440,	
2017-07-18 09:09:02,191 Epoch[42] Batch [230]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.255481,	
2017-07-18 09:09:10,982 Epoch[42] Batch [240]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.255054,	
2017-07-18 09:09:19,861 Epoch[42] Batch [250]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.252736,	
2017-07-18 09:09:28,968 Epoch[42] Batch [260]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.253854,	
2017-07-18 09:09:38,079 Epoch[42] Batch [270]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.254977,	
2017-07-18 09:09:46,933 Epoch[42] Batch [280]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.250840,	
2017-07-18 09:09:55,970 Epoch[42] Batch [290]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.251139,	
2017-07-18 09:10:04,913 Epoch[42] Batch [300]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.252836,	
2017-07-18 09:10:13,825 Epoch[42] Batch [310]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.250490,	
2017-07-18 09:10:22,321 Epoch[42] Batch [320]	Speed: 4.71 samples/sec	Train-FCNLogLoss=1.252136,	
2017-07-18 09:10:31,209 Epoch[42] Batch [330]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.252298,	
2017-07-18 09:10:39,940 Epoch[42] Batch [340]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.251668,	
2017-07-18 09:10:48,534 Epoch[42] Batch [350]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.249417,	
2017-07-18 09:10:57,334 Epoch[42] Batch [360]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.246333,	
2017-07-18 09:11:06,042 Epoch[42] Batch [370]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.246613,	
2017-07-18 09:11:15,202 Epoch[42] Batch [380]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.245064,	
2017-07-18 09:11:24,249 Epoch[42] Batch [390]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.242923,	
2017-07-18 09:11:33,158 Epoch[42] Batch [400]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.243810,	
2017-07-18 09:11:41,629 Epoch[42] Batch [410]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.244129,	
2017-07-18 09:11:50,244 Epoch[42] Batch [420]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.244409,	
2017-07-18 09:11:58,913 Epoch[42] Batch [430]	Speed: 4.61 samples/sec	Train-FCNLogLoss=1.246794,	
2017-07-18 09:12:07,432 Epoch[42] Batch [440]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.246896,	
2017-07-18 09:12:16,226 Epoch[42] Batch [450]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.248538,	
2017-07-18 09:12:24,625 Epoch[42] Batch [460]	Speed: 4.76 samples/sec	Train-FCNLogLoss=1.247266,	
2017-07-18 09:12:33,470 Epoch[42] Batch [470]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.245566,	
2017-07-18 09:12:42,170 Epoch[42] Batch [480]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.245960,	
2017-07-18 09:12:50,970 Epoch[42] Batch [490]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.246157,	
2017-07-18 09:13:00,165 Epoch[42] Batch [500]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.246055,	
2017-07-18 09:13:09,217 Epoch[42] Batch [510]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.246937,	
2017-07-18 09:13:18,251 Epoch[42] Batch [520]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.246175,	
2017-07-18 09:13:27,316 Epoch[42] Batch [530]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.245471,	
2017-07-18 09:13:36,312 Epoch[42] Batch [540]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.242799,	
2017-07-18 09:13:45,502 Epoch[42] Batch [550]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.244994,	
2017-07-18 09:13:54,159 Epoch[42] Batch [560]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.244805,	
2017-07-18 09:14:02,876 Epoch[42] Batch [570]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.243918,	
2017-07-18 09:14:11,799 Epoch[42] Batch [580]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.244050,	
2017-07-18 09:14:20,670 Epoch[42] Batch [590]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.243330,	
2017-07-18 09:14:29,658 Epoch[42] Batch [600]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.244116,	
2017-07-18 09:14:38,861 Epoch[42] Batch [610]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.242971,	
2017-07-18 09:14:47,643 Epoch[42] Batch [620]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.243668,	
2017-07-18 09:14:56,498 Epoch[42] Batch [630]	Speed: 4.52 samples/sec	Train-FCNLogLoss=1.244466,	
2017-07-18 09:15:05,282 Epoch[42] Batch [640]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.243912,	
2017-07-18 09:15:14,191 Epoch[42] Batch [650]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.243213,	
2017-07-18 09:15:23,384 Epoch[42] Batch [660]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.241740,	
2017-07-18 09:15:32,388 Epoch[42] Batch [670]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.243311,	
2017-07-18 09:15:40,998 Epoch[42] Batch [680]	Speed: 4.65 samples/sec	Train-FCNLogLoss=1.243042,	
2017-07-18 09:15:49,645 Epoch[42] Batch [690]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.242983,	
2017-07-18 09:15:58,664 Epoch[42] Batch [700]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242705,	
2017-07-18 09:16:07,541 Epoch[42] Batch [710]	Speed: 4.51 samples/sec	Train-FCNLogLoss=1.244008,	
2017-07-18 09:16:16,651 Epoch[42] Batch [720]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.243100,	
2017-07-18 09:16:25,551 Epoch[42] Batch [730]	Speed: 4.49 samples/sec	Train-FCNLogLoss=1.244273,	
2017-07-18 09:16:34,482 Epoch[42] Batch [740]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.243712,	
2017-07-18 09:16:43,518 Epoch[42] Batch [750]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.244246,	
2017-07-18 09:16:52,468 Epoch[42] Batch [760]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.243629,	
2017-07-18 09:17:01,390 Epoch[42] Batch [770]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.243370,	
2017-07-18 09:17:10,038 Epoch[42] Batch [780]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.243273,	
2017-07-18 09:17:19,019 Epoch[42] Batch [790]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.244165,	
2017-07-18 09:17:27,661 Epoch[42] Batch [800]	Speed: 4.63 samples/sec	Train-FCNLogLoss=1.245163,	
2017-07-18 09:17:36,697 Epoch[42] Batch [810]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.244495,	
2017-07-18 09:17:46,444 Epoch[42] Batch [820]	Speed: 4.10 samples/sec	Train-FCNLogLoss=1.244925,	
2017-07-18 09:17:55,105 Epoch[42] Batch [830]	Speed: 4.62 samples/sec	Train-FCNLogLoss=1.245096,	
2017-07-18 09:18:04,040 Epoch[42] Batch [840]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.245145,	
2017-07-18 09:18:12,931 Epoch[42] Batch [850]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.246136,	
2017-07-18 09:18:21,941 Epoch[42] Batch [860]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.246606,	
2017-07-18 09:18:31,273 Epoch[42] Batch [870]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.246500,	
2017-07-18 09:18:40,420 Epoch[42] Batch [880]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.246005,	
2017-07-18 09:18:49,201 Epoch[42] Batch [890]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.244633,	
2017-07-18 09:18:58,614 Epoch[42] Batch [900]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.244556,	
2017-07-18 09:19:07,933 Epoch[42] Batch [910]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.244220,	
2017-07-18 09:19:16,906 Epoch[42] Batch [920]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.243159,	
2017-07-18 09:19:25,678 Epoch[42] Batch [930]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.243175,	
2017-07-18 09:19:34,477 Epoch[42] Batch [940]	Speed: 4.55 samples/sec	Train-FCNLogLoss=1.243442,	
2017-07-18 09:19:43,252 Epoch[42] Batch [950]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.242633,	
2017-07-18 09:19:51,766 Epoch[42] Batch [960]	Speed: 4.70 samples/sec	Train-FCNLogLoss=1.243170,	
2017-07-18 09:20:00,293 Epoch[42] Batch [970]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.242624,	
2017-07-18 09:20:08,991 Epoch[42] Batch [980]	Speed: 4.60 samples/sec	Train-FCNLogLoss=1.242915,	
2017-07-18 09:20:16,961 Epoch[42] Batch [990]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.243231,	
2017-07-18 09:20:25,720 Epoch[42] Batch [1000]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.244407,	
2017-07-18 09:20:34,251 Epoch[42] Batch [1010]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.244671,	
2017-07-18 09:20:42,834 Epoch[42] Batch [1020]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.244183,	
2017-07-18 09:20:51,416 Epoch[42] Batch [1030]	Speed: 4.66 samples/sec	Train-FCNLogLoss=1.243306,	
2017-07-18 09:20:59,848 Epoch[42] Batch [1040]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.242079,	
2017-07-18 09:21:08,940 Epoch[42] Batch [1050]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.242223,	
2017-07-18 09:21:18,493 Epoch[42] Batch [1060]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.242106,	
2017-07-18 09:21:27,636 Epoch[42] Batch [1070]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.242189,	
2017-07-18 09:21:36,664 Epoch[42] Batch [1080]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.242273,	
2017-07-18 09:21:45,894 Epoch[42] Batch [1090]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.242778,	
2017-07-18 09:21:54,789 Epoch[42] Batch [1100]	Speed: 4.50 samples/sec	Train-FCNLogLoss=1.243407,	
2017-07-18 09:22:03,868 Epoch[42] Batch [1110]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.242559,	
2017-07-18 09:22:12,894 Epoch[42] Batch [1120]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.241512,	
2017-07-18 09:22:22,143 Epoch[42] Batch [1130]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.241265,	
2017-07-18 09:22:31,322 Epoch[42] Batch [1140]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.242109,	
2017-07-18 09:22:40,322 Epoch[42] Batch [1150]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.242247,	
2017-07-18 09:22:49,491 Epoch[42] Batch [1160]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.242322,	
2017-07-18 09:22:58,655 Epoch[42] Batch [1170]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.241929,	
2017-07-18 09:23:07,926 Epoch[42] Batch [1180]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.241421,	
2017-07-18 09:23:17,373 Epoch[42] Batch [1190]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.241167,	
2017-07-18 09:23:26,307 Epoch[42] Batch [1200]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.240242,	
2017-07-18 09:23:35,308 Epoch[42] Batch [1210]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.240215,	
2017-07-18 09:23:44,573 Epoch[42] Batch [1220]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.240260,	
2017-07-18 09:23:53,926 Epoch[42] Batch [1230]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.241104,	
2017-07-18 09:24:02,949 Epoch[42] Batch [1240]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.240908,	
2017-07-18 09:24:11,910 Epoch[42] Batch [1250]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.241417,	
2017-07-18 09:24:21,196 Epoch[42] Batch [1260]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.241671,	
2017-07-18 09:24:30,424 Epoch[42] Batch [1270]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.241565,	
2017-07-18 09:24:39,933 Epoch[42] Batch [1280]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.241063,	
2017-07-18 09:24:49,424 Epoch[42] Batch [1290]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.240293,	
2017-07-18 09:24:59,092 Epoch[42] Batch [1300]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.240105,	
2017-07-18 09:25:08,438 Epoch[42] Batch [1310]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.239564,	
2017-07-18 09:25:17,437 Epoch[42] Batch [1320]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.238580,	
2017-07-18 09:25:26,959 Epoch[42] Batch [1330]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.237543,	
2017-07-18 09:25:36,528 Epoch[42] Batch [1340]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.237532,	
2017-07-18 09:25:45,849 Epoch[42] Batch [1350]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237400,	
2017-07-18 09:25:55,035 Epoch[42] Batch [1360]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.237378,	
2017-07-18 09:26:04,279 Epoch[42] Batch [1370]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.237629,	
2017-07-18 09:26:13,610 Epoch[42] Batch [1380]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237755,	
2017-07-18 09:26:22,811 Epoch[42] Batch [1390]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.238093,	
2017-07-18 09:26:31,810 Epoch[42] Batch [1400]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.237841,	
2017-07-18 09:26:41,055 Epoch[42] Batch [1410]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.237921,	
2017-07-18 09:26:50,235 Epoch[42] Batch [1420]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.237598,	
2017-07-18 09:26:59,547 Epoch[42] Batch [1430]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.237698,	
2017-07-18 09:27:08,536 Epoch[42] Batch [1440]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.237740,	
2017-07-18 09:27:17,655 Epoch[42] Batch [1450]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.237325,	
2017-07-18 09:27:27,008 Epoch[42] Batch [1460]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.237258,	
2017-07-18 09:27:36,354 Epoch[42] Batch [1470]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.237133,	
2017-07-18 09:27:46,015 Epoch[42] Batch [1480]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.237644,	
2017-07-18 09:27:51,434 Epoch[42] Train-FCNLogLoss=1.237173
2017-07-18 09:27:51,434 Epoch[42] Time cost=1333.600
2017-07-18 09:27:52,640 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.params"
2017-07-18 09:27:55,641 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.states"
2017-07-18 09:28:06,572 Epoch[43] Batch [10]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.233633,	
2017-07-18 09:28:16,020 Epoch[43] Batch [20]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.235711,	
2017-07-18 09:28:25,323 Epoch[43] Batch [30]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.220605,	
2017-07-18 09:28:34,793 Epoch[43] Batch [40]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.210817,	
2017-07-18 09:28:44,084 Epoch[43] Batch [50]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.196248,	
2017-07-18 09:28:53,655 Epoch[43] Batch [60]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.198378,	
2017-07-18 09:29:02,584 Epoch[43] Batch [70]	Speed: 4.48 samples/sec	Train-FCNLogLoss=1.210808,	
2017-07-18 09:29:11,841 Epoch[43] Batch [80]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.214856,	
2017-07-18 09:29:21,138 Epoch[43] Batch [90]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.211588,	
2017-07-18 09:29:30,550 Epoch[43] Batch [100]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.213066,	
2017-07-18 09:29:40,162 Epoch[43] Batch [110]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.212520,	
2017-07-18 09:29:49,349 Epoch[43] Batch [120]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.221611,	
2017-07-18 09:29:59,131 Epoch[43] Batch [130]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.228626,	
2017-07-18 09:30:08,434 Epoch[43] Batch [140]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.228020,	
2017-07-18 09:30:18,039 Epoch[43] Batch [150]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.226102,	
2017-07-18 09:30:27,657 Epoch[43] Batch [160]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.231650,	
2017-07-18 09:30:37,037 Epoch[43] Batch [170]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.228100,	
2017-07-18 09:30:46,260 Epoch[43] Batch [180]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.233243,	
2017-07-18 09:30:55,585 Epoch[43] Batch [190]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237330,	
2017-07-18 09:31:04,829 Epoch[43] Batch [200]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.238919,	
2017-07-18 09:31:14,259 Epoch[43] Batch [210]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.240281,	
2017-07-18 09:31:23,867 Epoch[43] Batch [220]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.239479,	
2017-07-18 09:31:33,336 Epoch[43] Batch [230]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.242679,	
2017-07-18 09:31:42,570 Epoch[43] Batch [240]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.244520,	
2017-07-18 09:31:51,961 Epoch[43] Batch [250]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.238821,	
2017-07-18 09:32:01,661 Epoch[43] Batch [260]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.237696,	
2017-07-18 09:32:11,166 Epoch[43] Batch [270]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.241171,	
2017-07-18 09:32:20,330 Epoch[43] Batch [280]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.239950,	
2017-07-18 09:32:30,064 Epoch[43] Batch [290]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.239315,	
2017-07-18 09:32:39,751 Epoch[43] Batch [300]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.240460,	
2017-07-18 09:32:49,058 Epoch[43] Batch [310]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.241058,	
2017-07-18 09:32:58,418 Epoch[43] Batch [320]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.241347,	
2017-07-18 09:33:07,786 Epoch[43] Batch [330]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.240849,	
2017-07-18 09:33:17,136 Epoch[43] Batch [340]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.241066,	
2017-07-18 09:33:26,664 Epoch[43] Batch [350]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.242440,	
2017-07-18 09:33:36,136 Epoch[43] Batch [360]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.241304,	
2017-07-18 09:33:45,362 Epoch[43] Batch [370]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.239519,	
2017-07-18 09:33:54,484 Epoch[43] Batch [380]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.236633,	
2017-07-18 09:34:03,639 Epoch[43] Batch [390]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.234657,	
2017-07-18 09:34:13,089 Epoch[43] Batch [400]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.234153,	
2017-07-18 09:34:22,191 Epoch[43] Batch [410]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.233663,	
2017-07-18 09:34:31,574 Epoch[43] Batch [420]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.231656,	
2017-07-18 09:34:41,163 Epoch[43] Batch [430]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.231223,	
2017-07-18 09:34:50,339 Epoch[43] Batch [440]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.230497,	
2017-07-18 09:34:59,471 Epoch[43] Batch [450]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.230533,	
2017-07-18 09:35:08,822 Epoch[43] Batch [460]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.230696,	
2017-07-18 09:35:18,213 Epoch[43] Batch [470]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.232550,	
2017-07-18 09:35:27,520 Epoch[43] Batch [480]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.232209,	
2017-07-18 09:35:36,802 Epoch[43] Batch [490]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.236011,	
2017-07-18 09:35:46,058 Epoch[43] Batch [500]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.236113,	
2017-07-18 09:35:55,482 Epoch[43] Batch [510]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.235782,	
2017-07-18 09:36:04,709 Epoch[43] Batch [520]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.238812,	
2017-07-18 09:36:13,898 Epoch[43] Batch [530]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.239355,	
2017-07-18 09:36:23,202 Epoch[43] Batch [540]	Speed: 4.30 samples/sec	Train-FCNLogLoss=1.239175,	
2017-07-18 09:36:32,380 Epoch[43] Batch [550]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.237459,	
2017-07-18 09:36:41,723 Epoch[43] Batch [560]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.237386,	
2017-07-18 09:36:51,230 Epoch[43] Batch [570]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.235300,	
2017-07-18 09:37:00,424 Epoch[43] Batch [580]	Speed: 4.35 samples/sec	Train-FCNLogLoss=1.237170,	
2017-07-18 09:37:09,685 Epoch[43] Batch [590]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.236649,	
2017-07-18 09:37:19,165 Epoch[43] Batch [600]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.237125,	
2017-07-18 09:37:28,322 Epoch[43] Batch [610]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.239791,	
2017-07-18 09:37:37,410 Epoch[43] Batch [620]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.238190,	
2017-07-18 09:37:47,009 Epoch[43] Batch [630]	Speed: 4.17 samples/sec	Train-FCNLogLoss=1.238181,	
2017-07-18 09:37:56,336 Epoch[43] Batch [640]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.237774,	
2017-07-18 09:38:05,728 Epoch[43] Batch [650]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.237001,	
2017-07-18 09:38:15,135 Epoch[43] Batch [660]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.237129,	
2017-07-18 09:38:24,398 Epoch[43] Batch [670]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.238172,	
2017-07-18 09:38:33,643 Epoch[43] Batch [680]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.237309,	
2017-07-18 09:38:42,674 Epoch[43] Batch [690]	Speed: 4.43 samples/sec	Train-FCNLogLoss=1.237061,	
2017-07-18 09:38:51,884 Epoch[43] Batch [700]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.235972,	
2017-07-18 09:39:00,993 Epoch[43] Batch [710]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.234613,	
2017-07-18 09:39:10,277 Epoch[43] Batch [720]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.234672,	
2017-07-18 09:39:19,487 Epoch[43] Batch [730]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.234660,	
2017-07-18 09:39:28,747 Epoch[43] Batch [740]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.234333,	
2017-07-18 09:39:37,990 Epoch[43] Batch [750]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.233822,	
2017-07-18 09:39:47,205 Epoch[43] Batch [760]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.234499,	
2017-07-18 09:39:56,273 Epoch[43] Batch [770]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.232587,	
2017-07-18 09:40:05,739 Epoch[43] Batch [780]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.233096,	
2017-07-18 09:40:14,982 Epoch[43] Batch [790]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.232692,	
2017-07-18 09:40:24,768 Epoch[43] Batch [800]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.232315,	
2017-07-18 09:40:34,374 Epoch[43] Batch [810]	Speed: 4.16 samples/sec	Train-FCNLogLoss=1.233229,	
2017-07-18 09:40:43,721 Epoch[43] Batch [820]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.233511,	
2017-07-18 09:40:53,140 Epoch[43] Batch [830]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.233316,	
2017-07-18 09:41:02,254 Epoch[43] Batch [840]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.232193,	
2017-07-18 09:41:11,831 Epoch[43] Batch [850]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.234155,	
2017-07-18 09:41:21,301 Epoch[43] Batch [860]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.235183,	
2017-07-18 09:41:30,551 Epoch[43] Batch [870]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.234643,	
2017-07-18 09:41:39,780 Epoch[43] Batch [880]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.233315,	
2017-07-18 09:41:49,265 Epoch[43] Batch [890]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.231854,	
2017-07-18 09:41:58,501 Epoch[43] Batch [900]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.232693,	
2017-07-18 09:42:07,901 Epoch[43] Batch [910]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.231932,	
2017-07-18 09:42:17,259 Epoch[43] Batch [920]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.232236,	
2017-07-18 09:42:26,937 Epoch[43] Batch [930]	Speed: 4.13 samples/sec	Train-FCNLogLoss=1.232927,	
2017-07-18 09:42:36,307 Epoch[43] Batch [940]	Speed: 4.27 samples/sec	Train-FCNLogLoss=1.232662,	
2017-07-18 09:42:45,776 Epoch[43] Batch [950]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.232288,	
2017-07-18 09:42:55,020 Epoch[43] Batch [960]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.231366,	
2017-07-18 09:43:04,838 Epoch[43] Batch [970]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.231715,	
2017-07-18 09:43:14,272 Epoch[43] Batch [980]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.231970,	
2017-07-18 09:43:23,796 Epoch[43] Batch [990]	Speed: 4.20 samples/sec	Train-FCNLogLoss=1.231825,	
2017-07-18 09:43:33,299 Epoch[43] Batch [1000]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.232664,	
2017-07-18 09:43:42,701 Epoch[43] Batch [1010]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.232808,	
2017-07-18 09:43:52,091 Epoch[43] Batch [1020]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.232719,	
2017-07-18 09:44:01,892 Epoch[43] Batch [1030]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.231910,	
2017-07-18 09:44:11,170 Epoch[43] Batch [1040]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.232627,	
2017-07-18 09:44:20,217 Epoch[43] Batch [1050]	Speed: 4.42 samples/sec	Train-FCNLogLoss=1.233373,	
2017-07-18 09:44:29,481 Epoch[43] Batch [1060]	Speed: 4.32 samples/sec	Train-FCNLogLoss=1.234577,	
2017-07-18 09:44:38,834 Epoch[43] Batch [1070]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.234072,	
2017-07-18 09:44:48,121 Epoch[43] Batch [1080]	Speed: 4.31 samples/sec	Train-FCNLogLoss=1.234742,	
2017-07-18 09:44:57,470 Epoch[43] Batch [1090]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.234280,	
2017-07-18 09:45:06,817 Epoch[43] Batch [1100]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.234723,	
2017-07-18 09:45:16,064 Epoch[43] Batch [1110]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.234117,	
2017-07-18 09:45:25,245 Epoch[43] Batch [1120]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.234743,	
2017-07-18 09:45:34,635 Epoch[43] Batch [1130]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.234921,	
2017-07-18 09:45:44,049 Epoch[43] Batch [1140]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.234241,	
2017-07-18 09:45:53,839 Epoch[43] Batch [1150]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.234431,	
2017-07-18 09:46:03,396 Epoch[43] Batch [1160]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.234180,	
2017-07-18 09:46:13,237 Epoch[43] Batch [1170]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.234091,	
2017-07-18 09:46:22,684 Epoch[43] Batch [1180]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.233142,	
2017-07-18 09:46:32,241 Epoch[43] Batch [1190]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.233142,	
2017-07-18 09:46:41,395 Epoch[43] Batch [1200]	Speed: 4.37 samples/sec	Train-FCNLogLoss=1.232383,	
2017-07-18 09:46:50,814 Epoch[43] Batch [1210]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.232352,	
2017-07-18 09:47:00,558 Epoch[43] Batch [1220]	Speed: 4.11 samples/sec	Train-FCNLogLoss=1.232630,	
2017-07-18 09:47:09,892 Epoch[43] Batch [1230]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.232639,	
2017-07-18 09:47:21,807 Epoch[43] Batch [1240]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.232142,	
2017-07-18 09:47:31,820 Epoch[43] Batch [1250]	Speed: 3.99 samples/sec	Train-FCNLogLoss=1.232306,	
2017-07-18 09:47:44,376 Epoch[43] Batch [1260]	Speed: 3.19 samples/sec	Train-FCNLogLoss=1.232653,	
2017-07-18 09:47:57,041 Epoch[43] Batch [1270]	Speed: 3.16 samples/sec	Train-FCNLogLoss=1.232944,	
2017-07-18 09:48:07,254 Epoch[43] Batch [1280]	Speed: 3.92 samples/sec	Train-FCNLogLoss=1.232673,	
2017-07-18 09:48:17,850 Epoch[43] Batch [1290]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.232471,	
2017-07-18 09:48:29,417 Epoch[43] Batch [1300]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.232583,	
2017-07-18 09:48:40,227 Epoch[43] Batch [1310]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.233492,	
2017-07-18 09:48:51,203 Epoch[43] Batch [1320]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.233541,	
2017-07-18 09:49:02,197 Epoch[43] Batch [1330]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.233190,	
2017-07-18 09:49:13,315 Epoch[43] Batch [1340]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.233045,	
2017-07-18 09:49:24,942 Epoch[43] Batch [1350]	Speed: 3.44 samples/sec	Train-FCNLogLoss=1.232961,	
2017-07-18 09:49:35,182 Epoch[43] Batch [1360]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.232546,	
2017-07-18 09:49:44,681 Epoch[43] Batch [1370]	Speed: 4.21 samples/sec	Train-FCNLogLoss=1.231927,	
2017-07-18 09:49:54,764 Epoch[43] Batch [1380]	Speed: 3.97 samples/sec	Train-FCNLogLoss=1.232239,	
2017-07-18 09:50:05,343 Epoch[43] Batch [1390]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.232013,	
2017-07-18 09:50:16,330 Epoch[43] Batch [1400]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.232197,	
2017-07-18 09:50:27,588 Epoch[43] Batch [1410]	Speed: 3.55 samples/sec	Train-FCNLogLoss=1.232038,	
2017-07-18 09:50:39,921 Epoch[43] Batch [1420]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.232110,	
2017-07-18 09:50:51,036 Epoch[43] Batch [1430]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.232163,	
2017-07-18 09:51:02,792 Epoch[43] Batch [1440]	Speed: 3.40 samples/sec	Train-FCNLogLoss=1.232690,	
2017-07-18 09:51:16,326 Epoch[43] Batch [1450]	Speed: 2.96 samples/sec	Train-FCNLogLoss=1.233226,	
2017-07-18 09:51:26,631 Epoch[43] Batch [1460]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.233638,	
2017-07-18 09:51:39,546 Epoch[43] Batch [1470]	Speed: 3.10 samples/sec	Train-FCNLogLoss=1.233990,	
2017-07-18 09:51:50,278 Epoch[43] Batch [1480]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.234439,	
2017-07-18 09:51:56,232 Epoch[43] Train-FCNLogLoss=1.234359
2017-07-18 09:51:56,232 Epoch[43] Time cost=1440.453
2017-07-18 09:51:57,594 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.params"
2017-07-18 09:52:01,040 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.states"
2017-07-18 09:52:13,455 Epoch[44] Batch [10]	Speed: 3.67 samples/sec	Train-FCNLogLoss=1.206723,	
2017-07-18 09:52:24,462 Epoch[44] Batch [20]	Speed: 3.63 samples/sec	Train-FCNLogLoss=1.224148,	
2017-07-18 09:52:36,342 Epoch[44] Batch [30]	Speed: 3.37 samples/sec	Train-FCNLogLoss=1.279190,	
2017-07-18 09:52:48,061 Epoch[44] Batch [40]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.259047,	
2017-07-18 09:52:59,621 Epoch[44] Batch [50]	Speed: 3.46 samples/sec	Train-FCNLogLoss=1.245146,	
2017-07-18 09:53:12,101 Epoch[44] Batch [60]	Speed: 3.21 samples/sec	Train-FCNLogLoss=1.251669,	
2017-07-18 09:53:24,036 Epoch[44] Batch [70]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.258821,	
2017-07-18 09:53:35,400 Epoch[44] Batch [80]	Speed: 3.52 samples/sec	Train-FCNLogLoss=1.255291,	
2017-07-18 09:53:48,267 Epoch[44] Batch [90]	Speed: 3.11 samples/sec	Train-FCNLogLoss=1.253692,	
2017-07-18 09:54:00,762 Epoch[44] Batch [100]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.242196,	
2017-07-18 09:54:14,065 Epoch[44] Batch [110]	Speed: 3.01 samples/sec	Train-FCNLogLoss=1.238923,	
2017-07-18 09:54:25,671 Epoch[44] Batch [120]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.238028,	
2017-07-18 09:54:38,818 Epoch[44] Batch [130]	Speed: 3.04 samples/sec	Train-FCNLogLoss=1.241870,	
2017-07-18 09:54:50,738 Epoch[44] Batch [140]	Speed: 3.36 samples/sec	Train-FCNLogLoss=1.231413,	
2017-07-18 09:55:03,930 Epoch[44] Batch [150]	Speed: 3.03 samples/sec	Train-FCNLogLoss=1.229339,	
2017-07-18 09:55:16,226 Epoch[44] Batch [160]	Speed: 3.25 samples/sec	Train-FCNLogLoss=1.235035,	
2017-07-18 09:55:28,040 Epoch[44] Batch [170]	Speed: 3.39 samples/sec	Train-FCNLogLoss=1.231141,	
2017-07-18 09:55:40,645 Epoch[44] Batch [180]	Speed: 3.17 samples/sec	Train-FCNLogLoss=1.232060,	
2017-07-18 09:55:51,457 Epoch[44] Batch [190]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.231478,	
2017-07-18 09:56:02,913 Epoch[44] Batch [200]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.229647,	
2017-07-18 09:56:15,713 Epoch[44] Batch [210]	Speed: 3.13 samples/sec	Train-FCNLogLoss=1.232268,	
2017-07-18 09:56:28,816 Epoch[44] Batch [220]	Speed: 3.05 samples/sec	Train-FCNLogLoss=1.237577,	
2017-07-18 09:56:39,099 Epoch[44] Batch [230]	Speed: 3.89 samples/sec	Train-FCNLogLoss=1.238947,	
2017-07-18 09:56:51,441 Epoch[44] Batch [240]	Speed: 3.24 samples/sec	Train-FCNLogLoss=1.239888,	
2017-07-18 09:57:03,020 Epoch[44] Batch [250]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.237699,	
2017-07-18 09:57:16,171 Epoch[44] Batch [260]	Speed: 3.04 samples/sec	Train-FCNLogLoss=1.238797,	
2017-07-18 09:57:28,291 Epoch[44] Batch [270]	Speed: 3.30 samples/sec	Train-FCNLogLoss=1.240141,	
2017-07-18 09:57:41,468 Epoch[44] Batch [280]	Speed: 3.04 samples/sec	Train-FCNLogLoss=1.239416,	
2017-07-18 09:57:53,408 Epoch[44] Batch [290]	Speed: 3.35 samples/sec	Train-FCNLogLoss=1.239019,	
2017-07-18 09:58:04,732 Epoch[44] Batch [300]	Speed: 3.53 samples/sec	Train-FCNLogLoss=1.235420,	
2017-07-18 09:58:16,973 Epoch[44] Batch [310]	Speed: 3.27 samples/sec	Train-FCNLogLoss=1.236229,	
2017-07-18 09:58:27,365 Epoch[44] Batch [320]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.237726,	
2017-07-18 09:58:36,790 Epoch[44] Batch [330]	Speed: 4.24 samples/sec	Train-FCNLogLoss=1.237157,	
2017-07-18 09:58:45,890 Epoch[44] Batch [340]	Speed: 4.40 samples/sec	Train-FCNLogLoss=1.237788,	
2017-07-18 09:58:57,362 Epoch[44] Batch [350]	Speed: 3.49 samples/sec	Train-FCNLogLoss=1.234774,	
2017-07-18 09:59:07,762 Epoch[44] Batch [360]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.236586,	
2017-07-18 09:59:18,215 Epoch[44] Batch [370]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.236562,	
2017-07-18 09:59:28,889 Epoch[44] Batch [380]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.237114,	
2017-07-18 09:59:38,310 Epoch[44] Batch [390]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.235670,	
2017-07-18 09:59:50,810 Epoch[44] Batch [400]	Speed: 3.20 samples/sec	Train-FCNLogLoss=1.235890,	
2017-07-18 10:00:01,878 Epoch[44] Batch [410]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.235211,	
2017-07-18 10:00:12,580 Epoch[44] Batch [420]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.235203,	
2017-07-18 10:00:23,025 Epoch[44] Batch [430]	Speed: 3.83 samples/sec	Train-FCNLogLoss=1.233572,	
2017-07-18 10:00:33,805 Epoch[44] Batch [440]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.233570,	
2017-07-18 10:00:44,949 Epoch[44] Batch [450]	Speed: 3.59 samples/sec	Train-FCNLogLoss=1.233916,	
2017-07-18 10:00:56,063 Epoch[44] Batch [460]	Speed: 3.60 samples/sec	Train-FCNLogLoss=1.232156,	
2017-07-18 10:01:06,597 Epoch[44] Batch [470]	Speed: 3.80 samples/sec	Train-FCNLogLoss=1.231496,	
2017-07-18 10:01:18,078 Epoch[44] Batch [480]	Speed: 3.48 samples/sec	Train-FCNLogLoss=1.233527,	
2017-07-18 10:01:28,784 Epoch[44] Batch [490]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.233470,	
2017-07-18 10:01:39,003 Epoch[44] Batch [500]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.234136,	
2017-07-18 10:01:48,558 Epoch[44] Batch [510]	Speed: 4.19 samples/sec	Train-FCNLogLoss=1.233792,	
2017-07-18 10:01:59,290 Epoch[44] Batch [520]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.234067,	
2017-07-18 10:02:10,709 Epoch[44] Batch [530]	Speed: 3.50 samples/sec	Train-FCNLogLoss=1.234135,	
2017-07-18 10:02:20,552 Epoch[44] Batch [540]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.233956,	
2017-07-18 10:02:31,343 Epoch[44] Batch [550]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.231731,	
2017-07-18 10:03:05,853 Epoch[44] Batch [560]	Speed: 1.16 samples/sec	Train-FCNLogLoss=1.232408,	
2017-07-18 10:03:41,268 Epoch[44] Batch [570]	Speed: 1.13 samples/sec	Train-FCNLogLoss=1.232388,	
2017-07-18 10:04:18,348 Epoch[44] Batch [580]	Speed: 1.08 samples/sec	Train-FCNLogLoss=1.231819,	
2017-07-18 10:04:54,563 Epoch[44] Batch [590]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.231703,	
2017-07-18 10:05:30,844 Epoch[44] Batch [600]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.231495,	
2017-07-18 10:06:06,573 Epoch[44] Batch [610]	Speed: 1.12 samples/sec	Train-FCNLogLoss=1.230795,	
2017-07-18 10:06:42,323 Epoch[44] Batch [620]	Speed: 1.12 samples/sec	Train-FCNLogLoss=1.231768,	
2017-07-18 10:07:20,641 Epoch[44] Batch [630]	Speed: 1.04 samples/sec	Train-FCNLogLoss=1.232393,	
2017-07-18 10:07:57,029 Epoch[44] Batch [640]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.233837,	
2017-07-18 10:08:33,337 Epoch[44] Batch [650]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.234215,	
2017-07-18 10:09:08,068 Epoch[44] Batch [660]	Speed: 1.15 samples/sec	Train-FCNLogLoss=1.234768,	
2017-07-18 10:09:43,342 Epoch[44] Batch [670]	Speed: 1.13 samples/sec	Train-FCNLogLoss=1.235324,	
2017-07-18 10:10:20,272 Epoch[44] Batch [680]	Speed: 1.08 samples/sec	Train-FCNLogLoss=1.234888,	
2017-07-18 10:10:59,262 Epoch[44] Batch [690]	Speed: 1.03 samples/sec	Train-FCNLogLoss=1.234600,	
2017-07-18 10:11:37,897 Epoch[44] Batch [700]	Speed: 1.04 samples/sec	Train-FCNLogLoss=1.234961,	
2017-07-18 10:12:14,565 Epoch[44] Batch [710]	Speed: 1.09 samples/sec	Train-FCNLogLoss=1.234757,	
2017-07-18 10:12:52,068 Epoch[44] Batch [720]	Speed: 1.07 samples/sec	Train-FCNLogLoss=1.234083,	
2017-07-18 10:13:29,174 Epoch[44] Batch [730]	Speed: 1.08 samples/sec	Train-FCNLogLoss=1.233979,	
2017-07-18 10:14:05,818 Epoch[44] Batch [740]	Speed: 1.09 samples/sec	Train-FCNLogLoss=1.234244,	
2017-07-18 10:14:40,755 Epoch[44] Batch [750]	Speed: 1.14 samples/sec	Train-FCNLogLoss=1.233765,	
2017-07-18 10:15:17,657 Epoch[44] Batch [760]	Speed: 1.08 samples/sec	Train-FCNLogLoss=1.233313,	
2017-07-18 10:15:53,978 Epoch[44] Batch [770]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.234252,	
2017-07-18 10:16:30,010 Epoch[44] Batch [780]	Speed: 1.11 samples/sec	Train-FCNLogLoss=1.235517,	
2017-07-18 10:17:07,949 Epoch[44] Batch [790]	Speed: 1.05 samples/sec	Train-FCNLogLoss=1.236209,	
2017-07-18 10:17:45,545 Epoch[44] Batch [800]	Speed: 1.06 samples/sec	Train-FCNLogLoss=1.234679,	
2017-07-18 10:18:22,816 Epoch[44] Batch [810]	Speed: 1.07 samples/sec	Train-FCNLogLoss=1.234676,	
2017-07-18 10:18:58,478 Epoch[44] Batch [820]	Speed: 1.12 samples/sec	Train-FCNLogLoss=1.234403,	
2017-07-18 10:19:33,373 Epoch[44] Batch [830]	Speed: 1.15 samples/sec	Train-FCNLogLoss=1.234298,	
2017-07-18 10:20:12,585 Epoch[44] Batch [840]	Speed: 1.02 samples/sec	Train-FCNLogLoss=1.234273,	
2017-07-18 10:20:49,846 Epoch[44] Batch [850]	Speed: 1.07 samples/sec	Train-FCNLogLoss=1.235037,	
2017-07-18 10:21:27,635 Epoch[44] Batch [860]	Speed: 1.06 samples/sec	Train-FCNLogLoss=1.234095,	
2017-07-18 10:22:05,701 Epoch[44] Batch [870]	Speed: 1.05 samples/sec	Train-FCNLogLoss=1.233526,	
2017-07-18 10:22:42,403 Epoch[44] Batch [880]	Speed: 1.09 samples/sec	Train-FCNLogLoss=1.233203,	
2017-07-18 10:23:18,441 Epoch[44] Batch [890]	Speed: 1.11 samples/sec	Train-FCNLogLoss=1.233489,	
2017-07-18 10:23:54,431 Epoch[44] Batch [900]	Speed: 1.11 samples/sec	Train-FCNLogLoss=1.233145,	
2017-07-18 10:24:30,738 Epoch[44] Batch [910]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.234067,	
2017-07-18 10:25:08,301 Epoch[44] Batch [920]	Speed: 1.06 samples/sec	Train-FCNLogLoss=1.232733,	
2017-07-18 10:25:42,442 Epoch[44] Batch [930]	Speed: 1.17 samples/sec	Train-FCNLogLoss=1.232591,	
2017-07-18 10:26:18,410 Epoch[44] Batch [940]	Speed: 1.11 samples/sec	Train-FCNLogLoss=1.232248,	
2017-07-18 10:26:54,219 Epoch[44] Batch [950]	Speed: 1.12 samples/sec	Train-FCNLogLoss=1.232238,	
2017-07-18 10:27:31,420 Epoch[44] Batch [960]	Speed: 1.08 samples/sec	Train-FCNLogLoss=1.232201,	
2017-07-18 10:28:07,709 Epoch[44] Batch [970]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.231925,	
2017-07-18 10:28:43,445 Epoch[44] Batch [980]	Speed: 1.12 samples/sec	Train-FCNLogLoss=1.232289,	
2017-07-18 10:29:18,729 Epoch[44] Batch [990]	Speed: 1.13 samples/sec	Train-FCNLogLoss=1.232960,	
2017-07-18 10:29:52,673 Epoch[44] Batch [1000]	Speed: 1.18 samples/sec	Train-FCNLogLoss=1.232791,	
2017-07-18 10:30:28,022 Epoch[44] Batch [1010]	Speed: 1.13 samples/sec	Train-FCNLogLoss=1.233008,	
2017-07-18 10:31:04,300 Epoch[44] Batch [1020]	Speed: 1.10 samples/sec	Train-FCNLogLoss=1.233574,	
2017-07-18 10:31:39,987 Epoch[44] Batch [1030]	Speed: 1.12 samples/sec	Train-FCNLogLoss=1.233701,	
2017-07-18 10:32:15,257 Epoch[44] Batch [1040]	Speed: 1.13 samples/sec	Train-FCNLogLoss=1.234236,	
2017-07-18 10:32:49,751 Epoch[44] Batch [1050]	Speed: 1.16 samples/sec	Train-FCNLogLoss=1.233488,	
2017-07-18 10:33:25,303 Epoch[44] Batch [1060]	Speed: 1.13 samples/sec	Train-FCNLogLoss=1.234692,	
2017-07-18 10:33:58,080 Epoch[44] Batch [1070]	Speed: 1.22 samples/sec	Train-FCNLogLoss=1.235456,	

2017-07-20 10:27:54,357 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 100},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 100,
           'lr': 0.0005,
           'lr_step': '60',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn'}

2017-07-20 10:30:13,111 Epoch[0] Batch [10]	Speed: 9.75 samples/sec	Train-FCNLogLoss=2.879171,	
2017-07-20 10:30:17,308 Epoch[0] Batch [20]	Speed: 9.53 samples/sec	Train-FCNLogLoss=2.745026,	
2017-07-20 10:30:21,492 Epoch[0] Batch [30]	Speed: 9.56 samples/sec	Train-FCNLogLoss=2.506129,	
2017-07-20 10:30:25,404 Epoch[0] Batch [40]	Speed: 10.22 samples/sec	Train-FCNLogLoss=2.289520,	
2017-07-20 10:30:29,457 Epoch[0] Batch [50]	Speed: 9.87 samples/sec	Train-FCNLogLoss=2.090344,	
2017-07-20 10:30:33,503 Epoch[0] Batch [60]	Speed: 9.89 samples/sec	Train-FCNLogLoss=1.903434,	
2017-07-20 10:30:37,449 Epoch[0] Batch [70]	Speed: 10.14 samples/sec	Train-FCNLogLoss=1.759710,	
2017-07-20 10:30:41,434 Epoch[0] Batch [80]	Speed: 10.04 samples/sec	Train-FCNLogLoss=1.646800,	
2017-07-20 10:30:45,463 Epoch[0] Batch [90]	Speed: 9.93 samples/sec	Train-FCNLogLoss=1.560525,	
2017-07-20 10:30:49,372 Epoch[0] Batch [100]	Speed: 10.23 samples/sec	Train-FCNLogLoss=1.493459,	
2017-07-20 10:30:53,356 Epoch[0] Batch [110]	Speed: 10.04 samples/sec	Train-FCNLogLoss=1.413969,	
2017-07-20 10:30:57,351 Epoch[0] Batch [120]	Speed: 10.01 samples/sec	Train-FCNLogLoss=1.355874,	
2017-07-20 10:31:01,337 Epoch[0] Batch [130]	Speed: 10.04 samples/sec	Train-FCNLogLoss=1.303230,	
2017-07-20 10:31:05,372 Epoch[0] Batch [140]	Speed: 9.91 samples/sec	Train-FCNLogLoss=1.253975,	
2017-07-20 10:31:09,355 Epoch[0] Batch [150]	Speed: 10.04 samples/sec	Train-FCNLogLoss=1.206815,	
2017-07-20 10:31:13,378 Epoch[0] Batch [160]	Speed: 9.94 samples/sec	Train-FCNLogLoss=1.163222,	
2017-07-20 10:31:17,175 Epoch[0] Batch [170]	Speed: 10.53 samples/sec	Train-FCNLogLoss=1.123554,	
2017-07-20 10:31:21,241 Epoch[0] Batch [180]	Speed: 9.84 samples/sec	Train-FCNLogLoss=1.092247,	
2017-07-20 10:31:25,165 Epoch[0] Batch [190]	Speed: 10.19 samples/sec	Train-FCNLogLoss=1.058055,	
2017-07-20 10:31:29,104 Epoch[0] Batch [200]	Speed: 10.16 samples/sec	Train-FCNLogLoss=1.031515,	
2017-07-20 10:31:33,102 Epoch[0] Batch [210]	Speed: 10.00 samples/sec	Train-FCNLogLoss=1.004117,	
2017-07-20 10:31:37,196 Epoch[0] Batch [220]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.981264,	
2017-07-20 10:31:41,107 Epoch[0] Batch [230]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.961617,	
2017-07-20 10:31:45,066 Epoch[0] Batch [240]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.939581,	
2017-07-20 10:31:48,941 Epoch[0] Batch [250]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.924594,	
2017-07-20 10:31:53,003 Epoch[0] Batch [260]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.905755,	
2017-07-20 10:31:56,999 Epoch[0] Batch [270]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.890304,	
2017-07-20 10:32:00,990 Epoch[0] Batch [280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.872218,	
2017-07-20 10:32:05,096 Epoch[0] Batch [290]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.859166,	
2017-07-20 10:32:09,131 Epoch[0] Batch [300]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.847998,	
2017-07-20 10:32:13,141 Epoch[0] Batch [310]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.835443,	
2017-07-20 10:32:17,038 Epoch[0] Batch [320]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.824728,	
2017-07-20 10:32:21,016 Epoch[0] Batch [330]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.813003,	
2017-07-20 10:32:24,970 Epoch[0] Batch [340]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.802140,	
2017-07-20 10:32:28,817 Epoch[0] Batch [350]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.793378,	
2017-07-20 10:32:32,875 Epoch[0] Batch [360]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.782726,	
2017-07-20 10:32:36,820 Epoch[0] Batch [370]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.771481,	
2017-07-20 10:32:40,841 Epoch[0] Batch [380]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.760730,	
2017-07-20 10:32:44,935 Epoch[0] Batch [390]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.751267,	
2017-07-20 10:32:49,012 Epoch[0] Batch [400]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.743112,	
2017-07-20 10:32:53,170 Epoch[0] Batch [410]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.735081,	
2017-07-20 10:32:57,110 Epoch[0] Batch [420]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.728072,	
2017-07-20 10:33:01,059 Epoch[0] Batch [430]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.719227,	
2017-07-20 10:33:05,028 Epoch[0] Batch [440]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.713169,	
2017-07-20 10:33:09,142 Epoch[0] Batch [450]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.704997,	
2017-07-20 10:33:13,314 Epoch[0] Batch [460]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.697518,	
2017-07-20 10:33:17,199 Epoch[0] Batch [470]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.691026,	
2017-07-20 10:33:21,700 Epoch[0] Batch [480]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.685010,	
2017-07-20 10:33:26,050 Epoch[0] Batch [490]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.680057,	
2017-07-20 10:33:30,565 Epoch[0] Batch [500]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.674123,	
2017-07-20 10:33:34,830 Epoch[0] Batch [510]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.668777,	
2017-07-20 10:33:38,871 Epoch[0] Batch [520]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.662901,	
2017-07-20 10:33:42,935 Epoch[0] Batch [530]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.655944,	
2017-07-20 10:33:46,769 Epoch[0] Batch [540]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.651412,	
2017-07-20 10:33:51,389 Epoch[0] Batch [550]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.645813,	
2017-07-20 10:33:55,600 Epoch[0] Batch [560]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.640450,	
2017-07-20 10:34:00,178 Epoch[0] Batch [570]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.635675,	
2017-07-20 10:34:04,359 Epoch[0] Batch [580]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.630831,	
2017-07-20 10:34:08,499 Epoch[0] Batch [590]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.625954,	
2017-07-20 10:34:12,879 Epoch[0] Batch [600]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.621880,	
2017-07-20 10:34:16,928 Epoch[0] Batch [610]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.617716,	
2017-07-20 10:34:21,182 Epoch[0] Batch [620]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.614428,	
2017-07-20 10:34:25,788 Epoch[0] Batch [630]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.610604,	
2017-07-20 10:34:29,866 Epoch[0] Batch [640]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.607353,	
2017-07-20 10:34:33,882 Epoch[0] Batch [650]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.603619,	
2017-07-20 10:34:38,472 Epoch[0] Batch [660]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.602009,	
2017-07-20 10:34:42,748 Epoch[0] Batch [670]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.598556,	
2017-07-20 10:34:47,409 Epoch[0] Batch [680]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.594943,	
2017-07-20 10:34:51,795 Epoch[0] Batch [690]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.592176,	
2017-07-20 10:34:56,244 Epoch[0] Batch [700]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.588275,	
2017-07-20 10:35:00,333 Epoch[0] Batch [710]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.584425,	
2017-07-20 10:35:04,499 Epoch[0] Batch [720]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.581389,	
2017-07-20 10:35:08,893 Epoch[0] Batch [730]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.578405,	
2017-07-20 10:35:13,205 Epoch[0] Batch [740]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.575004,	
2017-07-20 10:35:17,923 Epoch[0] Batch [750]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.572191,	
2017-07-20 10:35:22,094 Epoch[0] Batch [760]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.569270,	
2017-07-20 10:35:26,153 Epoch[0] Batch [770]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.566567,	
2017-07-20 10:35:30,282 Epoch[0] Batch [780]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.563287,	
2017-07-20 10:35:34,508 Epoch[0] Batch [790]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.560620,	
2017-07-20 10:35:39,089 Epoch[0] Batch [800]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.558557,	
2017-07-20 10:35:43,502 Epoch[0] Batch [810]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.556196,	
2017-07-20 10:35:47,664 Epoch[0] Batch [820]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.554132,	
2017-07-20 10:35:52,112 Epoch[0] Batch [830]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.551851,	
2017-07-20 10:35:56,254 Epoch[0] Batch [840]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.549127,	
2017-07-20 10:36:00,429 Epoch[0] Batch [850]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.546671,	
2017-07-20 10:36:04,437 Epoch[0] Batch [860]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.544028,	
2017-07-20 10:36:09,017 Epoch[0] Batch [870]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.541826,	
2017-07-20 10:36:13,505 Epoch[0] Batch [880]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.539144,	
2017-07-20 10:36:17,532 Epoch[0] Batch [890]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.536356,	
2017-07-20 10:36:21,677 Epoch[0] Batch [900]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.533375,	
2017-07-20 10:36:25,809 Epoch[0] Batch [910]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.531024,	
2017-07-20 10:36:30,146 Epoch[0] Batch [920]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.529352,	
2017-07-20 10:36:34,804 Epoch[0] Batch [930]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.527362,	
2017-07-20 10:36:38,923 Epoch[0] Batch [940]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.525277,	
2017-07-20 10:36:43,393 Epoch[0] Batch [950]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.522948,	
2017-07-20 10:36:47,928 Epoch[0] Batch [960]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.520148,	
2017-07-20 10:36:52,373 Epoch[0] Batch [970]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.517501,	
2017-07-20 10:36:56,420 Epoch[0] Batch [980]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.515473,	
2017-07-20 10:37:00,484 Epoch[0] Batch [990]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.513900,	
2017-07-20 10:37:04,750 Epoch[0] Batch [1000]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.511364,	
2017-07-20 10:37:09,005 Epoch[0] Batch [1010]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.510033,	
2017-07-20 10:37:13,149 Epoch[0] Batch [1020]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.508529,	
2017-07-20 10:37:17,691 Epoch[0] Batch [1030]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.511164,	
2017-07-20 10:37:21,911 Epoch[0] Batch [1040]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.511893,	
2017-07-20 10:37:26,465 Epoch[0] Batch [1050]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.512551,	
2017-07-20 10:37:30,708 Epoch[0] Batch [1060]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.512642,	
2017-07-20 10:37:34,883 Epoch[0] Batch [1070]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.513983,	
2017-07-20 10:37:39,144 Epoch[0] Batch [1080]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.514211,	
2017-07-20 10:37:43,399 Epoch[0] Batch [1090]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.513803,	
2017-07-20 10:37:47,882 Epoch[0] Batch [1100]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.512753,	
2017-07-20 10:37:52,095 Epoch[0] Batch [1110]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.511907,	
2017-07-20 10:37:56,655 Epoch[0] Batch [1120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.510336,	
2017-07-20 10:38:01,075 Epoch[0] Batch [1130]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.509567,	
2017-07-20 10:38:05,056 Epoch[0] Batch [1140]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.508475,	
2017-07-20 10:38:09,434 Epoch[0] Batch [1150]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.507543,	
2017-07-20 10:38:13,793 Epoch[0] Batch [1160]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.507633,	
2017-07-20 10:38:17,976 Epoch[0] Batch [1170]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.506691,	
2017-07-20 10:38:22,293 Epoch[0] Batch [1180]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.505239,	
2017-07-20 10:38:26,161 Epoch[0] Batch [1190]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.503674,	
2017-07-20 10:38:30,816 Epoch[0] Batch [1200]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.502865,	
2017-07-20 10:38:35,605 Epoch[0] Batch [1210]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.501958,	
2017-07-20 10:38:40,156 Epoch[0] Batch [1220]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.501010,	
2017-07-20 10:38:44,310 Epoch[0] Batch [1230]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.499962,	
2017-07-20 10:38:48,346 Epoch[0] Batch [1240]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.498972,	
2017-07-20 10:38:53,069 Epoch[0] Batch [1250]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.497810,	
2017-07-20 10:38:57,096 Epoch[0] Batch [1260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.496206,	
2017-07-20 10:39:01,261 Epoch[0] Batch [1270]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.494542,	
2017-07-20 10:39:05,589 Epoch[0] Batch [1280]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.493914,	
2017-07-20 10:39:09,763 Epoch[0] Batch [1290]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.492499,	
2017-07-20 10:39:13,992 Epoch[0] Batch [1300]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.491387,	
2017-07-20 10:39:18,424 Epoch[0] Batch [1310]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.489682,	
2017-07-20 10:39:23,070 Epoch[0] Batch [1320]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.488089,	
2017-07-20 10:39:27,690 Epoch[0] Batch [1330]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.486460,	
2017-07-20 10:39:31,857 Epoch[0] Batch [1340]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.484978,	
2017-07-20 10:39:36,339 Epoch[0] Batch [1350]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.483414,	
2017-07-20 10:39:41,172 Epoch[0] Batch [1360]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.482129,	
2017-07-20 10:39:45,476 Epoch[0] Batch [1370]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.480684,	
2017-07-20 10:39:49,821 Epoch[0] Batch [1380]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.479295,	
2017-07-20 10:39:54,512 Epoch[0] Batch [1390]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.477996,	
2017-07-20 10:39:58,929 Epoch[0] Batch [1400]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.476523,	
2017-07-20 10:40:03,527 Epoch[0] Batch [1410]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.474956,	
2017-07-20 10:40:08,200 Epoch[0] Batch [1420]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.473751,	
2017-07-20 10:40:12,410 Epoch[0] Batch [1430]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.472514,	
2017-07-20 10:40:16,897 Epoch[0] Batch [1440]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.471021,	
2017-07-20 10:40:21,049 Epoch[0] Batch [1450]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.469895,	
2017-07-20 10:40:25,449 Epoch[0] Batch [1460]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.468431,	
2017-07-20 10:40:30,332 Epoch[0] Batch [1470]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.466989,	
2017-07-20 10:40:34,766 Epoch[0] Batch [1480]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.465517,	
2017-07-20 10:40:37,268 Epoch[0] Train-FCNLogLoss=0.464804
2017-07-20 10:40:37,268 Epoch[0] Time cost=634.170
2017-07-20 10:40:38,146 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0001.params"
2017-07-20 10:40:39,723 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0001.states"
2017-07-20 10:40:44,516 Epoch[1] Batch [10]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.283433,	
2017-07-20 10:40:48,357 Epoch[1] Batch [20]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.308212,	
2017-07-20 10:40:52,265 Epoch[1] Batch [30]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.307769,	
2017-07-20 10:40:56,318 Epoch[1] Batch [40]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.318597,	
2017-07-20 10:41:00,309 Epoch[1] Batch [50]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.308145,	
2017-07-20 10:41:04,631 Epoch[1] Batch [60]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.306931,	
2017-07-20 10:41:08,474 Epoch[1] Batch [70]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.306972,	
2017-07-20 10:41:12,625 Epoch[1] Batch [80]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.315602,	
2017-07-20 10:41:16,801 Epoch[1] Batch [90]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.317439,	
2017-07-20 10:41:20,598 Epoch[1] Batch [100]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.312731,	
2017-07-20 10:41:24,779 Epoch[1] Batch [110]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.307034,	
2017-07-20 10:41:28,782 Epoch[1] Batch [120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.302173,	
2017-07-20 10:41:33,028 Epoch[1] Batch [130]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.296245,	
2017-07-20 10:41:36,938 Epoch[1] Batch [140]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.292861,	
2017-07-20 10:41:41,033 Epoch[1] Batch [150]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.289700,	
2017-07-20 10:41:44,827 Epoch[1] Batch [160]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.290466,	
2017-07-20 10:41:49,263 Epoch[1] Batch [170]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.287634,	
2017-07-20 10:41:53,647 Epoch[1] Batch [180]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.287264,	
2017-07-20 10:41:57,970 Epoch[1] Batch [190]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.289370,	
2017-07-20 10:42:02,027 Epoch[1] Batch [200]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.288707,	
2017-07-20 10:42:06,105 Epoch[1] Batch [210]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.287562,	
2017-07-20 10:42:10,326 Epoch[1] Batch [220]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.286071,	
2017-07-20 10:42:14,430 Epoch[1] Batch [230]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.285829,	
2017-07-20 10:42:18,279 Epoch[1] Batch [240]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.285946,	
2017-07-20 10:42:22,423 Epoch[1] Batch [250]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.284923,	
2017-07-20 10:42:26,753 Epoch[1] Batch [260]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.283852,	
2017-07-20 10:42:30,839 Epoch[1] Batch [270]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.282115,	
2017-07-20 10:42:34,808 Epoch[1] Batch [280]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.280865,	
2017-07-20 10:42:38,934 Epoch[1] Batch [290]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.279387,	
2017-07-20 10:42:43,209 Epoch[1] Batch [300]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.277927,	
2017-07-20 10:42:47,242 Epoch[1] Batch [310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.276584,	
2017-07-20 10:42:51,470 Epoch[1] Batch [320]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.276896,	
2017-07-20 10:42:55,794 Epoch[1] Batch [330]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.276134,	
2017-07-20 10:42:59,895 Epoch[1] Batch [340]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.275351,	
2017-07-20 10:43:04,001 Epoch[1] Batch [350]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.275117,	
2017-07-20 10:43:07,943 Epoch[1] Batch [360]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.275670,	
2017-07-20 10:43:12,044 Epoch[1] Batch [370]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.276096,	
2017-07-20 10:43:16,357 Epoch[1] Batch [380]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.275488,	
2017-07-20 10:43:20,290 Epoch[1] Batch [390]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.274857,	
2017-07-20 10:43:24,532 Epoch[1] Batch [400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.274472,	
2017-07-20 10:43:28,429 Epoch[1] Batch [410]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.276787,	
2017-07-20 10:43:32,358 Epoch[1] Batch [420]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.276720,	
2017-07-20 10:43:36,212 Epoch[1] Batch [430]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.277713,	
2017-07-20 10:43:40,135 Epoch[1] Batch [440]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.277648,	
2017-07-20 10:43:44,008 Epoch[1] Batch [450]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.278672,	
2017-07-20 10:43:48,020 Epoch[1] Batch [460]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.278569,	
2017-07-20 10:43:52,505 Epoch[1] Batch [470]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.278241,	
2017-07-20 10:43:56,404 Epoch[1] Batch [480]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.279531,	
2017-07-20 10:44:00,670 Epoch[1] Batch [490]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.278872,	
2017-07-20 10:44:04,985 Epoch[1] Batch [500]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.277965,	
2017-07-20 10:44:09,235 Epoch[1] Batch [510]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.278356,	
2017-07-20 10:44:13,199 Epoch[1] Batch [520]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.277662,	
2017-07-20 10:44:17,493 Epoch[1] Batch [530]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.277237,	
2017-07-20 10:44:21,434 Epoch[1] Batch [540]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.277487,	
2017-07-20 10:44:25,937 Epoch[1] Batch [550]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.276467,	
2017-07-20 10:44:29,895 Epoch[1] Batch [560]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.275826,	
2017-07-20 10:44:33,911 Epoch[1] Batch [570]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.275769,	
2017-07-20 10:44:38,019 Epoch[1] Batch [580]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.275812,	
2017-07-20 10:44:42,006 Epoch[1] Batch [590]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.275491,	
2017-07-20 10:44:46,071 Epoch[1] Batch [600]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.274303,	
2017-07-20 10:44:50,392 Epoch[1] Batch [610]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.273926,	
2017-07-20 10:44:54,728 Epoch[1] Batch [620]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.273316,	
2017-07-20 10:44:59,122 Epoch[1] Batch [630]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.272715,	
2017-07-20 10:45:03,284 Epoch[1] Batch [640]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.271469,	
2017-07-20 10:45:07,267 Epoch[1] Batch [650]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.270467,	
2017-07-20 10:45:11,047 Epoch[1] Batch [660]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.269344,	
2017-07-20 10:45:15,035 Epoch[1] Batch [670]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.268146,	
2017-07-20 10:45:19,034 Epoch[1] Batch [680]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.267959,	
2017-07-20 10:45:23,025 Epoch[1] Batch [690]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.266744,	
2017-07-20 10:45:27,072 Epoch[1] Batch [700]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.266383,	
2017-07-20 10:45:31,109 Epoch[1] Batch [710]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.266042,	
2017-07-20 10:45:35,231 Epoch[1] Batch [720]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.266204,	
2017-07-20 10:45:39,333 Epoch[1] Batch [730]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.266469,	
2017-07-20 10:45:43,408 Epoch[1] Batch [740]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.266338,	
2017-07-20 10:45:47,458 Epoch[1] Batch [750]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.265777,	
2017-07-20 10:45:51,705 Epoch[1] Batch [760]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.265694,	
2017-07-20 10:45:55,694 Epoch[1] Batch [770]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.266104,	
2017-07-20 10:45:59,861 Epoch[1] Batch [780]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.265990,	
2017-07-20 10:46:04,733 Epoch[1] Batch [790]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.266107,	
2017-07-20 10:46:08,957 Epoch[1] Batch [800]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.265618,	
2017-07-20 10:46:13,041 Epoch[1] Batch [810]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.265335,	
2017-07-20 10:46:17,105 Epoch[1] Batch [820]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.265856,	
2017-07-20 10:46:21,257 Epoch[1] Batch [830]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.266131,	
2017-07-20 10:46:25,211 Epoch[1] Batch [840]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.266295,	
2017-07-20 10:46:29,114 Epoch[1] Batch [850]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.266264,	
2017-07-20 10:46:33,096 Epoch[1] Batch [860]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.265582,	
2017-07-20 10:46:37,378 Epoch[1] Batch [870]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.265603,	
2017-07-20 10:46:41,506 Epoch[1] Batch [880]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.265208,	
2017-07-20 10:46:45,585 Epoch[1] Batch [890]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.264896,	
2017-07-20 10:46:49,745 Epoch[1] Batch [900]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.264455,	
2017-07-20 10:46:53,748 Epoch[1] Batch [910]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.264521,	
2017-07-20 10:46:57,578 Epoch[1] Batch [920]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.264541,	
2017-07-20 10:47:01,644 Epoch[1] Batch [930]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.264309,	
2017-07-20 10:47:05,680 Epoch[1] Batch [940]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.264106,	
2017-07-20 10:47:09,652 Epoch[1] Batch [950]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.263848,	
2017-07-20 10:47:13,702 Epoch[1] Batch [960]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.263432,	
2017-07-20 10:47:17,630 Epoch[1] Batch [970]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.262950,	
2017-07-20 10:47:21,842 Epoch[1] Batch [980]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.262352,	
2017-07-20 10:47:25,773 Epoch[1] Batch [990]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.262069,	
2017-07-20 10:47:29,961 Epoch[1] Batch [1000]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.262084,	
2017-07-20 10:47:34,073 Epoch[1] Batch [1010]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.262298,	
2017-07-20 10:47:38,068 Epoch[1] Batch [1020]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.263859,	
2017-07-20 10:47:42,245 Epoch[1] Batch [1030]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.263895,	
2017-07-20 10:47:46,337 Epoch[1] Batch [1040]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.263646,	
2017-07-20 10:47:50,266 Epoch[1] Batch [1050]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.264091,	
2017-07-20 10:47:54,171 Epoch[1] Batch [1060]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.263903,	
2017-07-20 10:47:57,981 Epoch[1] Batch [1070]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.263631,	
2017-07-20 10:48:01,931 Epoch[1] Batch [1080]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.263514,	
2017-07-20 10:48:05,956 Epoch[1] Batch [1090]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.263815,	
2017-07-20 10:48:10,082 Epoch[1] Batch [1100]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.263734,	
2017-07-20 10:48:14,096 Epoch[1] Batch [1110]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.263262,	
2017-07-20 10:48:17,984 Epoch[1] Batch [1120]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.263149,	
2017-07-20 10:48:21,879 Epoch[1] Batch [1130]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.262676,	
2017-07-20 10:48:25,687 Epoch[1] Batch [1140]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.262117,	
2017-07-20 10:48:29,678 Epoch[1] Batch [1150]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.261648,	
2017-07-20 10:48:33,448 Epoch[1] Batch [1160]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.261422,	
2017-07-20 10:48:37,815 Epoch[1] Batch [1170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.261138,	
2017-07-20 10:48:41,693 Epoch[1] Batch [1180]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.261094,	
2017-07-20 10:48:45,542 Epoch[1] Batch [1190]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.260917,	
2017-07-20 10:48:49,349 Epoch[1] Batch [1200]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.260381,	
2017-07-20 10:48:53,294 Epoch[1] Batch [1210]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.260114,	
2017-07-20 10:48:57,288 Epoch[1] Batch [1220]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.259547,	
2017-07-20 10:49:01,114 Epoch[1] Batch [1230]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.259334,	
2017-07-20 10:49:05,009 Epoch[1] Batch [1240]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.258827,	
2017-07-20 10:49:09,089 Epoch[1] Batch [1250]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.258768,	
2017-07-20 10:49:12,983 Epoch[1] Batch [1260]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.258632,	
2017-07-20 10:49:17,067 Epoch[1] Batch [1270]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.258205,	
2017-07-20 10:49:21,042 Epoch[1] Batch [1280]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.258076,	
2017-07-20 10:49:25,363 Epoch[1] Batch [1290]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.257571,	
2017-07-20 10:49:29,198 Epoch[1] Batch [1300]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.257099,	
2017-07-20 10:49:33,218 Epoch[1] Batch [1310]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.256534,	
2017-07-20 10:49:37,135 Epoch[1] Batch [1320]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.256189,	
2017-07-20 10:49:40,977 Epoch[1] Batch [1330]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.255815,	
2017-07-20 10:49:44,983 Epoch[1] Batch [1340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.255640,	
2017-07-20 10:49:49,010 Epoch[1] Batch [1350]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.255087,	
2017-07-20 10:49:53,092 Epoch[1] Batch [1360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.254843,	
2017-07-20 10:49:57,326 Epoch[1] Batch [1370]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.254338,	
2017-07-20 10:50:01,348 Epoch[1] Batch [1380]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.254128,	
2017-07-20 10:50:05,285 Epoch[1] Batch [1390]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.253884,	
2017-07-20 10:50:09,268 Epoch[1] Batch [1400]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.253552,	
2017-07-20 10:50:13,210 Epoch[1] Batch [1410]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.253082,	
2017-07-20 10:50:17,133 Epoch[1] Batch [1420]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.252767,	
2017-07-20 10:50:21,177 Epoch[1] Batch [1430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.252498,	
2017-07-20 10:50:25,270 Epoch[1] Batch [1440]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.252446,	
2017-07-20 10:50:29,242 Epoch[1] Batch [1450]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.252316,	
2017-07-20 10:50:33,310 Epoch[1] Batch [1460]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.251962,	
2017-07-20 10:50:37,183 Epoch[1] Batch [1470]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.251731,	
2017-07-20 10:50:41,382 Epoch[1] Batch [1480]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.251704,	
2017-07-20 10:50:43,647 Epoch[1] Train-FCNLogLoss=0.251390
2017-07-20 10:50:43,647 Epoch[1] Time cost=603.923
2017-07-20 10:50:44,454 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0002.params"
2017-07-20 10:50:45,947 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0002.states"
2017-07-20 10:50:50,620 Epoch[2] Batch [10]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.214229,	
2017-07-20 10:50:54,622 Epoch[2] Batch [20]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.209384,	
2017-07-20 10:50:58,542 Epoch[2] Batch [30]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.207808,	
2017-07-20 10:51:02,548 Epoch[2] Batch [40]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.208087,	
2017-07-20 10:51:06,474 Epoch[2] Batch [50]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.202264,	
2017-07-20 10:51:10,578 Epoch[2] Batch [60]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.202046,	
2017-07-20 10:51:14,608 Epoch[2] Batch [70]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.199110,	
2017-07-20 10:51:19,120 Epoch[2] Batch [80]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.198339,	
2017-07-20 10:51:23,153 Epoch[2] Batch [90]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.197470,	
2017-07-20 10:51:27,261 Epoch[2] Batch [100]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.198128,	
2017-07-20 10:51:31,640 Epoch[2] Batch [110]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.199205,	
2017-07-20 10:51:36,039 Epoch[2] Batch [120]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.199882,	
2017-07-20 10:51:39,977 Epoch[2] Batch [130]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.200450,	
2017-07-20 10:51:44,160 Epoch[2] Batch [140]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.200614,	
2017-07-20 10:51:48,111 Epoch[2] Batch [150]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.199750,	
2017-07-20 10:51:52,125 Epoch[2] Batch [160]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.202929,	
2017-07-20 10:51:56,137 Epoch[2] Batch [170]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.205764,	
2017-07-20 10:52:00,098 Epoch[2] Batch [180]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.206580,	
2017-07-20 10:52:03,974 Epoch[2] Batch [190]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.206669,	
2017-07-20 10:52:07,985 Epoch[2] Batch [200]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.205852,	
2017-07-20 10:52:12,006 Epoch[2] Batch [210]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.204835,	
2017-07-20 10:52:16,000 Epoch[2] Batch [220]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.204983,	
2017-07-20 10:52:20,024 Epoch[2] Batch [230]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.205349,	
2017-07-20 10:52:23,896 Epoch[2] Batch [240]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.204508,	
2017-07-20 10:52:28,159 Epoch[2] Batch [250]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.204060,	
2017-07-20 10:52:32,270 Epoch[2] Batch [260]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.203364,	
2017-07-20 10:52:36,321 Epoch[2] Batch [270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.203875,	
2017-07-20 10:52:40,439 Epoch[2] Batch [280]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.204546,	
2017-07-20 10:52:44,612 Epoch[2] Batch [290]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.204396,	
2017-07-20 10:52:48,583 Epoch[2] Batch [300]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.203625,	
2017-07-20 10:52:52,566 Epoch[2] Batch [310]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.203479,	
2017-07-20 10:52:56,487 Epoch[2] Batch [320]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.202752,	
2017-07-20 10:53:00,503 Epoch[2] Batch [330]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.202386,	
2017-07-20 10:53:04,499 Epoch[2] Batch [340]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.202419,	
2017-07-20 10:53:08,632 Epoch[2] Batch [350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.201984,	
2017-07-20 10:53:12,713 Epoch[2] Batch [360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.202842,	
2017-07-20 10:53:16,747 Epoch[2] Batch [370]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.203003,	
2017-07-20 10:53:20,693 Epoch[2] Batch [380]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.202876,	
2017-07-20 10:53:25,002 Epoch[2] Batch [390]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.203873,	
2017-07-20 10:53:29,145 Epoch[2] Batch [400]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.204855,	
2017-07-20 10:53:33,420 Epoch[2] Batch [410]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.204602,	
2017-07-20 10:53:37,632 Epoch[2] Batch [420]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.204568,	
2017-07-20 10:53:41,470 Epoch[2] Batch [430]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.204399,	
2017-07-20 10:53:45,405 Epoch[2] Batch [440]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.203794,	
2017-07-20 10:53:49,469 Epoch[2] Batch [450]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.203348,	
2017-07-20 10:53:53,581 Epoch[2] Batch [460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.202604,	
2017-07-20 10:53:57,765 Epoch[2] Batch [470]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.202244,	
2017-07-20 10:54:02,233 Epoch[2] Batch [480]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.201916,	
2017-07-20 10:54:06,271 Epoch[2] Batch [490]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.201463,	
2017-07-20 10:54:10,260 Epoch[2] Batch [500]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.201485,	
2017-07-20 10:54:14,266 Epoch[2] Batch [510]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.201054,	
2017-07-20 10:54:18,175 Epoch[2] Batch [520]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.200528,	
2017-07-20 10:54:22,165 Epoch[2] Batch [530]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.200292,	
2017-07-20 10:54:26,155 Epoch[2] Batch [540]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.200895,	
2017-07-20 10:54:30,136 Epoch[2] Batch [550]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.201707,	
2017-07-20 10:54:34,099 Epoch[2] Batch [560]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.201936,	
2017-07-20 10:54:38,309 Epoch[2] Batch [570]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.201966,	
2017-07-20 10:54:42,110 Epoch[2] Batch [580]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.201684,	
2017-07-20 10:54:46,205 Epoch[2] Batch [590]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.202429,	
2017-07-20 10:54:50,256 Epoch[2] Batch [600]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.202370,	
2017-07-20 10:54:54,428 Epoch[2] Batch [610]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.202347,	
2017-07-20 10:54:58,518 Epoch[2] Batch [620]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.202407,	
2017-07-20 10:55:02,518 Epoch[2] Batch [630]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.202200,	
2017-07-20 10:55:06,668 Epoch[2] Batch [640]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.201824,	
2017-07-20 10:55:10,654 Epoch[2] Batch [650]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.201616,	
2017-07-20 10:55:14,470 Epoch[2] Batch [660]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.201725,	
2017-07-20 10:55:19,065 Epoch[2] Batch [670]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.201267,	
2017-07-20 10:55:23,173 Epoch[2] Batch [680]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.201520,	
2017-07-20 10:55:27,399 Epoch[2] Batch [690]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.201370,	
2017-07-20 10:55:31,497 Epoch[2] Batch [700]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.201576,	
2017-07-20 10:55:35,584 Epoch[2] Batch [710]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.201321,	
2017-07-20 10:55:39,721 Epoch[2] Batch [720]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.201355,	
2017-07-20 10:55:43,606 Epoch[2] Batch [730]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.201463,	
2017-07-20 10:55:47,900 Epoch[2] Batch [740]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.201481,	
2017-07-20 10:55:51,938 Epoch[2] Batch [750]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.201299,	
2017-07-20 10:55:56,018 Epoch[2] Batch [760]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.201134,	
2017-07-20 10:55:59,872 Epoch[2] Batch [770]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.200928,	
2017-07-20 10:56:03,864 Epoch[2] Batch [780]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.203256,	
2017-07-20 10:56:07,966 Epoch[2] Batch [790]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.204391,	
2017-07-20 10:56:12,009 Epoch[2] Batch [800]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.204574,	
2017-07-20 10:56:15,999 Epoch[2] Batch [810]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.204774,	
2017-07-20 10:56:20,195 Epoch[2] Batch [820]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.204955,	
2017-07-20 10:56:24,161 Epoch[2] Batch [830]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.204750,	
2017-07-20 10:56:28,195 Epoch[2] Batch [840]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.204385,	
2017-07-20 10:56:32,129 Epoch[2] Batch [850]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.204219,	
2017-07-20 10:56:36,232 Epoch[2] Batch [860]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.203829,	
2017-07-20 10:56:40,203 Epoch[2] Batch [870]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.203710,	
2017-07-20 10:56:44,235 Epoch[2] Batch [880]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.204293,	
2017-07-20 10:56:48,268 Epoch[2] Batch [890]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.204918,	
2017-07-20 10:56:52,224 Epoch[2] Batch [900]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.204920,	
2017-07-20 10:56:56,586 Epoch[2] Batch [910]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.204654,	
2017-07-20 10:57:00,537 Epoch[2] Batch [920]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.204490,	
2017-07-20 10:57:04,354 Epoch[2] Batch [930]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.204235,	
2017-07-20 10:57:08,334 Epoch[2] Batch [940]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.204153,	
2017-07-20 10:57:12,346 Epoch[2] Batch [950]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.203948,	
2017-07-20 10:57:16,317 Epoch[2] Batch [960]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.204050,	
2017-07-20 10:57:20,205 Epoch[2] Batch [970]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.203942,	
2017-07-20 10:57:24,149 Epoch[2] Batch [980]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.203950,	
2017-07-20 10:57:28,247 Epoch[2] Batch [990]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.203985,	
2017-07-20 10:57:32,168 Epoch[2] Batch [1000]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.203731,	
2017-07-20 10:57:36,346 Epoch[2] Batch [1010]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.203529,	
2017-07-20 10:57:40,483 Epoch[2] Batch [1020]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.203210,	
2017-07-20 10:57:44,807 Epoch[2] Batch [1030]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.203336,	
2017-07-20 10:57:49,001 Epoch[2] Batch [1040]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.203304,	
2017-07-20 10:57:52,987 Epoch[2] Batch [1050]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.203186,	
2017-07-20 10:57:57,040 Epoch[2] Batch [1060]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.203585,	
2017-07-20 10:58:01,369 Epoch[2] Batch [1070]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.203327,	
2017-07-20 10:58:05,520 Epoch[2] Batch [1080]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.203661,	
2017-07-20 10:58:09,551 Epoch[2] Batch [1090]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.203493,	
2017-07-20 10:58:13,916 Epoch[2] Batch [1100]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.203418,	
2017-07-20 10:58:18,126 Epoch[2] Batch [1110]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.203183,	
2017-07-20 10:58:22,207 Epoch[2] Batch [1120]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.202971,	
2017-07-20 10:58:26,159 Epoch[2] Batch [1130]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.202810,	
2017-07-20 10:58:30,331 Epoch[2] Batch [1140]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.202665,	
2017-07-20 10:58:34,200 Epoch[2] Batch [1150]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.202214,	
2017-07-20 10:58:38,272 Epoch[2] Batch [1160]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.201986,	
2017-07-20 10:58:42,549 Epoch[2] Batch [1170]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.201682,	
2017-07-20 10:58:46,918 Epoch[2] Batch [1180]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.201590,	
2017-07-20 10:58:50,870 Epoch[2] Batch [1190]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.201466,	
2017-07-20 10:58:55,233 Epoch[2] Batch [1200]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.201757,	
2017-07-20 10:58:59,680 Epoch[2] Batch [1210]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.201719,	
2017-07-20 10:59:03,768 Epoch[2] Batch [1220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.201679,	
2017-07-20 10:59:08,029 Epoch[2] Batch [1230]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.201401,	
2017-07-20 10:59:11,985 Epoch[2] Batch [1240]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.201230,	
2017-07-20 10:59:16,437 Epoch[2] Batch [1250]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.201031,	
2017-07-20 10:59:20,845 Epoch[2] Batch [1260]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.200881,	
2017-07-20 10:59:25,080 Epoch[2] Batch [1270]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.201326,	
2017-07-20 10:59:29,070 Epoch[2] Batch [1280]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.201226,	
2017-07-20 10:59:33,302 Epoch[2] Batch [1290]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.201315,	
2017-07-20 10:59:38,014 Epoch[2] Batch [1300]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.201247,	
2017-07-20 10:59:42,196 Epoch[2] Batch [1310]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.201158,	
2017-07-20 10:59:46,577 Epoch[2] Batch [1320]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.200871,	
2017-07-20 10:59:51,023 Epoch[2] Batch [1330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.200586,	
2017-07-20 10:59:55,155 Epoch[2] Batch [1340]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.200295,	
2017-07-20 10:59:59,367 Epoch[2] Batch [1350]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.199992,	
2017-07-20 11:00:03,304 Epoch[2] Batch [1360]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.199933,	
2017-07-20 11:00:07,313 Epoch[2] Batch [1370]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.199804,	
2017-07-20 11:00:11,385 Epoch[2] Batch [1380]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.199652,	
2017-07-20 11:00:15,550 Epoch[2] Batch [1390]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.199494,	
2017-07-20 11:00:19,557 Epoch[2] Batch [1400]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.199386,	
2017-07-20 11:00:24,093 Epoch[2] Batch [1410]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.199401,	
2017-07-20 11:00:28,315 Epoch[2] Batch [1420]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.199813,	
2017-07-20 11:00:32,371 Epoch[2] Batch [1430]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.199855,	
2017-07-20 11:00:36,520 Epoch[2] Batch [1440]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.199595,	
2017-07-20 11:00:41,083 Epoch[2] Batch [1450]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.199511,	
2017-07-20 11:00:45,196 Epoch[2] Batch [1460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.199450,	
2017-07-20 11:00:49,494 Epoch[2] Batch [1470]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.199760,	
2017-07-20 11:00:53,979 Epoch[2] Batch [1480]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.199761,	
2017-07-20 11:00:56,700 Epoch[2] Train-FCNLogLoss=0.199926
2017-07-20 11:00:56,700 Epoch[2] Time cost=610.753
2017-07-20 11:00:57,484 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0003.params"
2017-07-20 11:00:59,248 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0003.states"
2017-07-20 11:01:04,150 Epoch[3] Batch [10]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.192787,	
2017-07-20 11:01:08,356 Epoch[3] Batch [20]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.182639,	
2017-07-20 11:01:12,715 Epoch[3] Batch [30]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.182433,	
2017-07-20 11:01:16,925 Epoch[3] Batch [40]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.185278,	
2017-07-20 11:01:21,326 Epoch[3] Batch [50]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.184604,	
2017-07-20 11:01:25,770 Epoch[3] Batch [60]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.182587,	
2017-07-20 11:01:30,117 Epoch[3] Batch [70]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.185367,	
2017-07-20 11:01:34,195 Epoch[3] Batch [80]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.187165,	
2017-07-20 11:01:38,604 Epoch[3] Batch [90]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.190130,	
2017-07-20 11:01:42,657 Epoch[3] Batch [100]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.190324,	
2017-07-20 11:01:46,836 Epoch[3] Batch [110]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.188904,	
2017-07-20 11:01:51,248 Epoch[3] Batch [120]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.188883,	
2017-07-20 11:01:55,379 Epoch[3] Batch [130]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.187755,	
2017-07-20 11:01:59,809 Epoch[3] Batch [140]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.191117,	
2017-07-20 11:02:03,851 Epoch[3] Batch [150]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.189832,	
2017-07-20 11:02:07,994 Epoch[3] Batch [160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.190145,	
2017-07-20 11:02:12,148 Epoch[3] Batch [170]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.190824,	
2017-07-20 11:02:16,232 Epoch[3] Batch [180]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.188848,	
2017-07-20 11:02:20,877 Epoch[3] Batch [190]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.187027,	
2017-07-20 11:02:24,951 Epoch[3] Batch [200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.187628,	
2017-07-20 11:02:29,356 Epoch[3] Batch [210]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.188133,	
2017-07-20 11:02:33,483 Epoch[3] Batch [220]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.188289,	
2017-07-20 11:02:37,806 Epoch[3] Batch [230]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.188032,	
2017-07-20 11:02:41,891 Epoch[3] Batch [240]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.186541,	
2017-07-20 11:02:46,200 Epoch[3] Batch [250]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.186220,	
2017-07-20 11:02:50,298 Epoch[3] Batch [260]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.186812,	
2017-07-20 11:02:54,786 Epoch[3] Batch [270]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.186762,	
2017-07-20 11:02:59,106 Epoch[3] Batch [280]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.186690,	
2017-07-20 11:03:03,267 Epoch[3] Batch [290]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.186384,	
2017-07-20 11:03:07,533 Epoch[3] Batch [300]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.185520,	
2017-07-20 11:03:11,753 Epoch[3] Batch [310]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.185130,	
2017-07-20 11:03:15,750 Epoch[3] Batch [320]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.186028,	
2017-07-20 11:03:20,333 Epoch[3] Batch [330]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.185645,	
2017-07-20 11:03:24,544 Epoch[3] Batch [340]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.185484,	
2017-07-20 11:03:29,117 Epoch[3] Batch [350]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.184999,	
2017-07-20 11:03:33,081 Epoch[3] Batch [360]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.184854,	
2017-07-20 11:03:37,191 Epoch[3] Batch [370]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.186075,	
2017-07-20 11:03:41,457 Epoch[3] Batch [380]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.185357,	
2017-07-20 11:03:45,880 Epoch[3] Batch [390]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.184566,	
2017-07-20 11:03:50,130 Epoch[3] Batch [400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.184105,	
2017-07-20 11:03:54,345 Epoch[3] Batch [410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.186092,	
2017-07-20 11:03:58,487 Epoch[3] Batch [420]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.188649,	
2017-07-20 11:04:02,822 Epoch[3] Batch [430]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.190339,	
2017-07-20 11:04:07,455 Epoch[3] Batch [440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.191523,	
2017-07-20 11:04:11,555 Epoch[3] Batch [450]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.191365,	
2017-07-20 11:04:15,678 Epoch[3] Batch [460]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.191716,	
2017-07-20 11:04:20,294 Epoch[3] Batch [470]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.192376,	
2017-07-20 11:04:24,284 Epoch[3] Batch [480]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.192836,	
2017-07-20 11:04:28,100 Epoch[3] Batch [490]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.192460,	
2017-07-20 11:04:31,947 Epoch[3] Batch [500]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.192544,	
2017-07-20 11:04:36,426 Epoch[3] Batch [510]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.192603,	
2017-07-20 11:04:40,682 Epoch[3] Batch [520]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.192157,	
2017-07-20 11:04:44,804 Epoch[3] Batch [530]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.192203,	
2017-07-20 11:04:48,899 Epoch[3] Batch [540]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.192108,	
2017-07-20 11:04:53,020 Epoch[3] Batch [550]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.192168,	
2017-07-20 11:04:57,305 Epoch[3] Batch [560]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.191572,	
2017-07-20 11:05:01,384 Epoch[3] Batch [570]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.191122,	
2017-07-20 11:05:05,670 Epoch[3] Batch [580]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.191078,	
2017-07-20 11:05:09,600 Epoch[3] Batch [590]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.190976,	
2017-07-20 11:05:13,477 Epoch[3] Batch [600]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.191170,	
2017-07-20 11:05:17,973 Epoch[3] Batch [610]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.191265,	
2017-07-20 11:05:22,733 Epoch[3] Batch [620]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.191313,	
2017-07-20 11:05:26,656 Epoch[3] Batch [630]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.191019,	
2017-07-20 11:05:30,841 Epoch[3] Batch [640]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.190668,	
2017-07-20 11:05:35,116 Epoch[3] Batch [650]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.190331,	
2017-07-20 11:05:38,917 Epoch[3] Batch [660]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.190183,	
2017-07-20 11:05:43,287 Epoch[3] Batch [670]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.190132,	
2017-07-20 11:05:47,470 Epoch[3] Batch [680]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.190108,	
2017-07-20 11:05:51,802 Epoch[3] Batch [690]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.190251,	
2017-07-20 11:05:56,008 Epoch[3] Batch [700]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.189776,	
2017-07-20 11:06:00,022 Epoch[3] Batch [710]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.189859,	
2017-07-20 11:06:03,995 Epoch[3] Batch [720]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.189901,	
2017-07-20 11:06:08,143 Epoch[3] Batch [730]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.189579,	
2017-07-20 11:06:12,089 Epoch[3] Batch [740]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.189307,	
2017-07-20 11:06:16,142 Epoch[3] Batch [750]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.188908,	
2017-07-20 11:06:19,950 Epoch[3] Batch [760]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.188662,	
2017-07-20 11:06:24,021 Epoch[3] Batch [770]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.188391,	
2017-07-20 11:06:28,080 Epoch[3] Batch [780]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.188306,	
2017-07-20 11:06:32,031 Epoch[3] Batch [790]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.188008,	
2017-07-20 11:06:36,306 Epoch[3] Batch [800]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.187955,	
2017-07-20 11:06:40,273 Epoch[3] Batch [810]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.187667,	
2017-07-20 11:06:44,004 Epoch[3] Batch [820]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.187613,	
2017-07-20 11:06:47,842 Epoch[3] Batch [830]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.187361,	
2017-07-20 11:06:52,122 Epoch[3] Batch [840]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.187048,	
2017-07-20 11:06:55,904 Epoch[3] Batch [850]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.186718,	
2017-07-20 11:06:59,924 Epoch[3] Batch [860]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.186370,	
2017-07-20 11:07:03,751 Epoch[3] Batch [870]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.186039,	
2017-07-20 11:07:07,598 Epoch[3] Batch [880]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.186629,	
2017-07-20 11:07:11,614 Epoch[3] Batch [890]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.186505,	
2017-07-20 11:07:15,529 Epoch[3] Batch [900]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.186730,	
2017-07-20 11:07:19,589 Epoch[3] Batch [910]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.186563,	
2017-07-20 11:07:23,453 Epoch[3] Batch [920]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.186277,	
2017-07-20 11:07:27,723 Epoch[3] Batch [930]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.186308,	
2017-07-20 11:07:31,544 Epoch[3] Batch [940]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.186420,	
2017-07-20 11:07:35,456 Epoch[3] Batch [950]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.186433,	
2017-07-20 11:07:39,699 Epoch[3] Batch [960]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.186301,	
2017-07-20 11:07:43,521 Epoch[3] Batch [970]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.186169,	
2017-07-20 11:07:47,435 Epoch[3] Batch [980]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.186049,	
2017-07-20 11:07:51,391 Epoch[3] Batch [990]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.185854,	
2017-07-20 11:07:55,607 Epoch[3] Batch [1000]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.185556,	
2017-07-20 11:07:59,721 Epoch[3] Batch [1010]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.185611,	
2017-07-20 11:08:03,725 Epoch[3] Batch [1020]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.185284,	
2017-07-20 11:08:07,971 Epoch[3] Batch [1030]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.185275,	
2017-07-20 11:08:11,849 Epoch[3] Batch [1040]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.185382,	
2017-07-20 11:08:15,807 Epoch[3] Batch [1050]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.185370,	
2017-07-20 11:08:19,744 Epoch[3] Batch [1060]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.185267,	
2017-07-20 11:08:23,699 Epoch[3] Batch [1070]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.184991,	
2017-07-20 11:08:27,840 Epoch[3] Batch [1080]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.184842,	
2017-07-20 11:08:31,779 Epoch[3] Batch [1090]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.184444,	
2017-07-20 11:08:35,666 Epoch[3] Batch [1100]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.184348,	
2017-07-20 11:08:39,685 Epoch[3] Batch [1110]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.184251,	
2017-07-20 11:08:43,552 Epoch[3] Batch [1120]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.184202,	
2017-07-20 11:08:47,525 Epoch[3] Batch [1130]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.184169,	
2017-07-20 11:08:51,507 Epoch[3] Batch [1140]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.184088,	
2017-07-20 11:08:55,704 Epoch[3] Batch [1150]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.183930,	
2017-07-20 11:08:59,663 Epoch[3] Batch [1160]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.183862,	
2017-07-20 11:09:03,580 Epoch[3] Batch [1170]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.183621,	
2017-07-20 11:09:07,450 Epoch[3] Batch [1180]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.183388,	
2017-07-20 11:09:11,304 Epoch[3] Batch [1190]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.183130,	
2017-07-20 11:09:15,463 Epoch[3] Batch [1200]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.182967,	
2017-07-20 11:09:19,463 Epoch[3] Batch [1210]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.182953,	
2017-07-20 11:09:23,413 Epoch[3] Batch [1220]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.182941,	
2017-07-20 11:09:27,482 Epoch[3] Batch [1230]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.182743,	
2017-07-20 11:09:31,414 Epoch[3] Batch [1240]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.182684,	
2017-07-20 11:09:35,295 Epoch[3] Batch [1250]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.182514,	
2017-07-20 11:09:39,200 Epoch[3] Batch [1260]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.182638,	
2017-07-20 11:09:43,380 Epoch[3] Batch [1270]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.182440,	
2017-07-20 11:09:47,244 Epoch[3] Batch [1280]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.182265,	
2017-07-20 11:09:51,042 Epoch[3] Batch [1290]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.182348,	
2017-07-20 11:09:54,900 Epoch[3] Batch [1300]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.182147,	
2017-07-20 11:09:58,961 Epoch[3] Batch [1310]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.182099,	
2017-07-20 11:10:02,814 Epoch[3] Batch [1320]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.181842,	
2017-07-20 11:10:06,766 Epoch[3] Batch [1330]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.181609,	
2017-07-20 11:10:10,794 Epoch[3] Batch [1340]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.181501,	
2017-07-20 11:10:14,908 Epoch[3] Batch [1350]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.181255,	
2017-07-20 11:10:18,948 Epoch[3] Batch [1360]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.181299,	
2017-07-20 11:10:22,775 Epoch[3] Batch [1370]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.181201,	
2017-07-20 11:10:26,854 Epoch[3] Batch [1380]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.181079,	
2017-07-20 11:10:30,921 Epoch[3] Batch [1390]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.181345,	
2017-07-20 11:10:34,891 Epoch[3] Batch [1400]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.181208,	
2017-07-20 11:10:38,920 Epoch[3] Batch [1410]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.181252,	
2017-07-20 11:10:42,837 Epoch[3] Batch [1420]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.181346,	
2017-07-20 11:10:46,936 Epoch[3] Batch [1430]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.181295,	
2017-07-20 11:10:51,077 Epoch[3] Batch [1440]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.181345,	
2017-07-20 11:10:55,076 Epoch[3] Batch [1450]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.181181,	
2017-07-20 11:10:59,365 Epoch[3] Batch [1460]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.181103,	
2017-07-20 11:11:04,124 Epoch[3] Batch [1470]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.181009,	
2017-07-20 11:11:08,481 Epoch[3] Batch [1480]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.180804,	
2017-07-20 11:11:10,780 Epoch[3] Train-FCNLogLoss=0.180701
2017-07-20 11:11:10,780 Epoch[3] Time cost=611.531
2017-07-20 11:11:11,514 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0004.params"
2017-07-20 11:11:13,042 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0004.states"
2017-07-20 11:11:17,599 Epoch[4] Batch [10]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.237209,	
2017-07-20 11:11:21,433 Epoch[4] Batch [20]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.208630,	
2017-07-20 11:11:25,366 Epoch[4] Batch [30]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.194818,	
2017-07-20 11:11:29,185 Epoch[4] Batch [40]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.188864,	
2017-07-20 11:11:33,133 Epoch[4] Batch [50]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.186552,	
2017-07-20 11:11:36,881 Epoch[4] Batch [60]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.177205,	
2017-07-20 11:11:40,699 Epoch[4] Batch [70]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.171138,	
2017-07-20 11:11:44,777 Epoch[4] Batch [80]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.170270,	
2017-07-20 11:11:48,768 Epoch[4] Batch [90]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.168124,	
2017-07-20 11:11:52,610 Epoch[4] Batch [100]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.165589,	
2017-07-20 11:11:56,514 Epoch[4] Batch [110]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.164854,	
2017-07-20 11:12:00,494 Epoch[4] Batch [120]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.162905,	
2017-07-20 11:12:04,443 Epoch[4] Batch [130]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.163678,	
2017-07-20 11:12:08,637 Epoch[4] Batch [140]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.163060,	
2017-07-20 11:12:12,758 Epoch[4] Batch [150]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.163416,	
2017-07-20 11:12:16,766 Epoch[4] Batch [160]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.162487,	
2017-07-20 11:12:20,640 Epoch[4] Batch [170]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.162901,	
2017-07-20 11:12:24,724 Epoch[4] Batch [180]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.162682,	
2017-07-20 11:12:28,604 Epoch[4] Batch [190]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.162034,	
2017-07-20 11:12:32,321 Epoch[4] Batch [200]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.161798,	
2017-07-20 11:12:36,417 Epoch[4] Batch [210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.161738,	
2017-07-20 11:12:40,354 Epoch[4] Batch [220]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.164839,	
2017-07-20 11:12:44,164 Epoch[4] Batch [230]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.164335,	
2017-07-20 11:12:48,129 Epoch[4] Batch [240]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.164539,	
2017-07-20 11:12:52,059 Epoch[4] Batch [250]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.163965,	
2017-07-20 11:12:55,922 Epoch[4] Batch [260]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.163896,	
2017-07-20 11:13:00,051 Epoch[4] Batch [270]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.163789,	
2017-07-20 11:13:03,964 Epoch[4] Batch [280]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.163447,	
2017-07-20 11:13:08,145 Epoch[4] Batch [290]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.164377,	
2017-07-20 11:13:12,271 Epoch[4] Batch [300]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.164271,	
2017-07-20 11:13:16,277 Epoch[4] Batch [310]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.164302,	
2017-07-20 11:13:20,163 Epoch[4] Batch [320]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.163800,	
2017-07-20 11:13:24,163 Epoch[4] Batch [330]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.163303,	
2017-07-20 11:13:28,002 Epoch[4] Batch [340]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.162939,	
2017-07-20 11:13:31,899 Epoch[4] Batch [350]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.162845,	
2017-07-20 11:13:35,819 Epoch[4] Batch [360]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.163427,	
2017-07-20 11:13:39,732 Epoch[4] Batch [370]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.163743,	
2017-07-20 11:13:43,588 Epoch[4] Batch [380]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.163682,	
2017-07-20 11:13:47,411 Epoch[4] Batch [390]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.163502,	
2017-07-20 11:13:51,480 Epoch[4] Batch [400]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.163622,	
2017-07-20 11:13:55,824 Epoch[4] Batch [410]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.163601,	
2017-07-20 11:13:59,989 Epoch[4] Batch [420]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.163493,	
2017-07-20 11:14:03,958 Epoch[4] Batch [430]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.162833,	
2017-07-20 11:14:07,877 Epoch[4] Batch [440]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.162693,	
2017-07-20 11:14:11,922 Epoch[4] Batch [450]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.162989,	
2017-07-20 11:14:15,804 Epoch[4] Batch [460]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.162916,	
2017-07-20 11:14:19,636 Epoch[4] Batch [470]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.162413,	
2017-07-20 11:14:23,496 Epoch[4] Batch [480]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.162875,	
2017-07-20 11:14:27,322 Epoch[4] Batch [490]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.162951,	
2017-07-20 11:14:31,371 Epoch[4] Batch [500]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.163300,	
2017-07-20 11:14:35,502 Epoch[4] Batch [510]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.163627,	
2017-07-20 11:14:39,397 Epoch[4] Batch [520]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.163625,	
2017-07-20 11:14:43,429 Epoch[4] Batch [530]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.163445,	
2017-07-20 11:14:47,365 Epoch[4] Batch [540]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.163028,	
2017-07-20 11:14:51,195 Epoch[4] Batch [550]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.162716,	
2017-07-20 11:14:55,210 Epoch[4] Batch [560]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.163336,	
2017-07-20 11:14:59,046 Epoch[4] Batch [570]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.164149,	
2017-07-20 11:15:02,859 Epoch[4] Batch [580]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.164233,	
2017-07-20 11:15:06,699 Epoch[4] Batch [590]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.164208,	
2017-07-20 11:15:10,872 Epoch[4] Batch [600]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.164006,	
2017-07-20 11:15:14,923 Epoch[4] Batch [610]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.164055,	
2017-07-20 11:15:18,870 Epoch[4] Batch [620]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.163835,	
2017-07-20 11:15:22,858 Epoch[4] Batch [630]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.163498,	
2017-07-20 11:15:26,853 Epoch[4] Batch [640]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.163261,	
2017-07-20 11:15:30,785 Epoch[4] Batch [650]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.163341,	
2017-07-20 11:15:34,810 Epoch[4] Batch [660]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.163513,	
2017-07-20 11:15:38,875 Epoch[4] Batch [670]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.163217,	
2017-07-20 11:15:43,068 Epoch[4] Batch [680]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.163016,	
2017-07-20 11:15:46,954 Epoch[4] Batch [690]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.162809,	
2017-07-20 11:15:51,034 Epoch[4] Batch [700]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.162638,	
2017-07-20 11:15:55,059 Epoch[4] Batch [710]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.162514,	
2017-07-20 11:15:59,071 Epoch[4] Batch [720]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.162714,	
2017-07-20 11:16:03,279 Epoch[4] Batch [730]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.162640,	
2017-07-20 11:16:07,104 Epoch[4] Batch [740]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.162987,	
2017-07-20 11:16:11,132 Epoch[4] Batch [750]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.162767,	
2017-07-20 11:16:15,105 Epoch[4] Batch [760]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.162784,	
2017-07-20 11:16:19,059 Epoch[4] Batch [770]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.162720,	
2017-07-20 11:16:23,705 Epoch[4] Batch [780]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.162707,	
2017-07-20 11:16:27,839 Epoch[4] Batch [790]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.162406,	
2017-07-20 11:16:31,993 Epoch[4] Batch [800]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.162627,	
2017-07-20 11:16:36,216 Epoch[4] Batch [810]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.162419,	
2017-07-20 11:16:40,386 Epoch[4] Batch [820]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.162231,	
2017-07-20 11:16:44,535 Epoch[4] Batch [830]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.162377,	
2017-07-20 11:16:48,648 Epoch[4] Batch [840]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.162099,	
2017-07-20 11:16:52,594 Epoch[4] Batch [850]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.162061,	
2017-07-20 11:16:56,545 Epoch[4] Batch [860]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.162080,	
2017-07-20 11:17:00,718 Epoch[4] Batch [870]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.161875,	
2017-07-20 11:17:05,081 Epoch[4] Batch [880]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.161790,	
2017-07-20 11:17:09,223 Epoch[4] Batch [890]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.161930,	
2017-07-20 11:17:13,383 Epoch[4] Batch [900]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.161971,	
2017-07-20 11:17:17,656 Epoch[4] Batch [910]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.161854,	
2017-07-20 11:17:22,155 Epoch[4] Batch [920]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.161925,	
2017-07-20 11:17:26,508 Epoch[4] Batch [930]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.161990,	
2017-07-20 11:17:30,702 Epoch[4] Batch [940]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.161841,	
2017-07-20 11:17:34,823 Epoch[4] Batch [950]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.161843,	
2017-07-20 11:17:40,002 Epoch[4] Batch [960]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.161806,	
2017-07-20 11:17:44,257 Epoch[4] Batch [970]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.161732,	
2017-07-20 11:17:48,539 Epoch[4] Batch [980]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.161929,	
2017-07-20 11:17:52,954 Epoch[4] Batch [990]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.161777,	
2017-07-20 11:17:57,382 Epoch[4] Batch [1000]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.161722,	
2017-07-20 11:18:01,827 Epoch[4] Batch [1010]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.161576,	
2017-07-20 11:18:05,867 Epoch[4] Batch [1020]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.161645,	
2017-07-20 11:18:09,936 Epoch[4] Batch [1030]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.161513,	
2017-07-20 11:18:13,937 Epoch[4] Batch [1040]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.161488,	
2017-07-20 11:18:18,105 Epoch[4] Batch [1050]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.161759,	
2017-07-20 11:18:22,170 Epoch[4] Batch [1060]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.161799,	
2017-07-20 11:18:26,349 Epoch[4] Batch [1070]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.161559,	
2017-07-20 11:18:30,360 Epoch[4] Batch [1080]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.161529,	
2017-07-20 11:18:34,449 Epoch[4] Batch [1090]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.161676,	
2017-07-20 11:18:38,474 Epoch[4] Batch [1100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.162355,	
2017-07-20 11:18:42,497 Epoch[4] Batch [1110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.162408,	
2017-07-20 11:18:46,745 Epoch[4] Batch [1120]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.162529,	
2017-07-20 11:18:50,938 Epoch[4] Batch [1130]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.162407,	
2017-07-20 11:18:54,966 Epoch[4] Batch [1140]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.162446,	
2017-07-20 11:18:59,476 Epoch[4] Batch [1150]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.162348,	
2017-07-20 11:19:03,376 Epoch[4] Batch [1160]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.162279,	
2017-07-20 11:19:07,539 Epoch[4] Batch [1170]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.162226,	
2017-07-20 11:19:11,785 Epoch[4] Batch [1180]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.162132,	
2017-07-20 11:19:15,871 Epoch[4] Batch [1190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.162064,	
2017-07-20 11:19:20,079 Epoch[4] Batch [1200]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.161902,	
2017-07-20 11:19:24,108 Epoch[4] Batch [1210]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.161965,	
2017-07-20 11:19:28,477 Epoch[4] Batch [1220]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.161836,	
2017-07-20 11:19:32,833 Epoch[4] Batch [1230]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.161757,	
2017-07-20 11:19:37,137 Epoch[4] Batch [1240]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.161754,	
2017-07-20 11:19:41,178 Epoch[4] Batch [1250]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.161594,	
2017-07-20 11:19:45,426 Epoch[4] Batch [1260]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.161518,	
2017-07-20 11:19:49,499 Epoch[4] Batch [1270]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.161791,	
2017-07-20 11:19:53,622 Epoch[4] Batch [1280]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.162225,	
2017-07-20 11:19:57,873 Epoch[4] Batch [1290]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.162417,	
2017-07-20 11:20:02,081 Epoch[4] Batch [1300]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.162377,	
2017-07-20 11:20:06,782 Epoch[4] Batch [1310]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.162389,	
2017-07-20 11:20:11,395 Epoch[4] Batch [1320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.162529,	
2017-07-20 11:20:15,604 Epoch[4] Batch [1330]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.162430,	
2017-07-20 11:20:19,684 Epoch[4] Batch [1340]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.162367,	
2017-07-20 11:20:23,919 Epoch[4] Batch [1350]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.162346,	
2017-07-20 11:20:28,038 Epoch[4] Batch [1360]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.162289,	
2017-07-20 11:20:32,000 Epoch[4] Batch [1370]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.162229,	
2017-07-20 11:20:36,255 Epoch[4] Batch [1380]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.162056,	
2017-07-20 11:20:40,296 Epoch[4] Batch [1390]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.161951,	
2017-07-20 11:20:44,354 Epoch[4] Batch [1400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.161970,	
2017-07-20 11:20:48,533 Epoch[4] Batch [1410]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.162299,	
2017-07-20 11:20:52,987 Epoch[4] Batch [1420]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.162151,	
2017-07-20 11:20:56,791 Epoch[4] Batch [1430]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.162252,	
2017-07-20 11:21:00,823 Epoch[4] Batch [1440]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.162341,	
2017-07-20 11:21:05,061 Epoch[4] Batch [1450]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.162559,	
2017-07-20 11:21:09,115 Epoch[4] Batch [1460]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.162525,	
2017-07-20 11:21:13,170 Epoch[4] Batch [1470]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.162546,	
2017-07-20 11:21:17,423 Epoch[4] Batch [1480]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.162744,	
2017-07-20 11:21:19,854 Epoch[4] Train-FCNLogLoss=0.162744
2017-07-20 11:21:19,855 Epoch[4] Time cost=606.812
2017-07-20 11:21:20,620 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0005.params"
2017-07-20 11:21:22,238 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0005.states"
2017-07-20 11:21:26,905 Epoch[5] Batch [10]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.139067,	
2017-07-20 11:21:30,823 Epoch[5] Batch [20]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.139353,	
2017-07-20 11:21:34,999 Epoch[5] Batch [30]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.148017,	
2017-07-20 11:21:39,054 Epoch[5] Batch [40]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.152523,	
2017-07-20 11:21:43,180 Epoch[5] Batch [50]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.164762,	
2017-07-20 11:21:47,420 Epoch[5] Batch [60]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.164272,	
2017-07-20 11:21:51,833 Epoch[5] Batch [70]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.169268,	
2017-07-20 11:21:55,933 Epoch[5] Batch [80]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.167193,	
2017-07-20 11:21:59,996 Epoch[5] Batch [90]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.164728,	
2017-07-20 11:22:03,965 Epoch[5] Batch [100]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.165026,	
2017-07-20 11:22:08,087 Epoch[5] Batch [110]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.165920,	
2017-07-20 11:22:12,481 Epoch[5] Batch [120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.164635,	
2017-07-20 11:22:16,881 Epoch[5] Batch [130]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.163292,	
2017-07-20 11:22:20,775 Epoch[5] Batch [140]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.163389,	
2017-07-20 11:22:24,735 Epoch[5] Batch [150]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.162328,	
2017-07-20 11:22:28,852 Epoch[5] Batch [160]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.162172,	
2017-07-20 11:22:33,339 Epoch[5] Batch [170]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.161122,	
2017-07-20 11:22:37,569 Epoch[5] Batch [180]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.160843,	
2017-07-20 11:22:41,510 Epoch[5] Batch [190]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.161461,	
2017-07-20 11:22:45,467 Epoch[5] Batch [200]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.160665,	
2017-07-20 11:22:49,455 Epoch[5] Batch [210]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.160075,	
2017-07-20 11:22:53,764 Epoch[5] Batch [220]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.159792,	
2017-07-20 11:22:58,115 Epoch[5] Batch [230]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.159279,	
2017-07-20 11:23:02,777 Epoch[5] Batch [240]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.159263,	
2017-07-20 11:23:07,034 Epoch[5] Batch [250]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.159782,	
2017-07-20 11:23:11,230 Epoch[5] Batch [260]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.158709,	
2017-07-20 11:23:15,131 Epoch[5] Batch [270]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.158550,	
2017-07-20 11:23:19,567 Epoch[5] Batch [280]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.157919,	
2017-07-20 11:23:23,830 Epoch[5] Batch [290]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.157512,	
2017-07-20 11:23:27,792 Epoch[5] Batch [300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.157079,	
2017-07-20 11:23:31,728 Epoch[5] Batch [310]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.156805,	
2017-07-20 11:23:35,838 Epoch[5] Batch [320]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.156435,	
2017-07-20 11:23:40,204 Epoch[5] Batch [330]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.155644,	
2017-07-20 11:23:44,488 Epoch[5] Batch [340]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.155604,	
2017-07-20 11:23:48,608 Epoch[5] Batch [350]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.155490,	
2017-07-20 11:23:52,462 Epoch[5] Batch [360]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.155148,	
2017-07-20 11:23:56,410 Epoch[5] Batch [370]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.155442,	
2017-07-20 11:24:00,452 Epoch[5] Batch [380]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.155581,	
2017-07-20 11:24:04,505 Epoch[5] Batch [390]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.155462,	
2017-07-20 11:24:08,380 Epoch[5] Batch [400]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.156172,	
2017-07-20 11:24:12,433 Epoch[5] Batch [410]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.156029,	
2017-07-20 11:24:16,256 Epoch[5] Batch [420]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.156206,	
2017-07-20 11:24:20,231 Epoch[5] Batch [430]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.156035,	
2017-07-20 11:24:24,691 Epoch[5] Batch [440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.156125,	
2017-07-20 11:24:28,616 Epoch[5] Batch [450]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.155826,	
2017-07-20 11:24:32,501 Epoch[5] Batch [460]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.155663,	
2017-07-20 11:24:36,464 Epoch[5] Batch [470]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.155065,	
2017-07-20 11:24:40,565 Epoch[5] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.155127,	
2017-07-20 11:24:44,480 Epoch[5] Batch [490]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.155670,	
2017-07-20 11:24:48,359 Epoch[5] Batch [500]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.156475,	
2017-07-20 11:24:52,168 Epoch[5] Batch [510]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.156345,	
2017-07-20 11:24:56,058 Epoch[5] Batch [520]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.156627,	
2017-07-20 11:25:00,072 Epoch[5] Batch [530]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.156572,	
2017-07-20 11:25:03,848 Epoch[5] Batch [540]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.156569,	
2017-07-20 11:25:08,020 Epoch[5] Batch [550]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.156595,	
2017-07-20 11:25:12,184 Epoch[5] Batch [560]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.156624,	
2017-07-20 11:25:16,259 Epoch[5] Batch [570]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.156634,	
2017-07-20 11:25:20,354 Epoch[5] Batch [580]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.156311,	
2017-07-20 11:25:24,177 Epoch[5] Batch [590]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.156067,	
2017-07-20 11:25:28,277 Epoch[5] Batch [600]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.155981,	
2017-07-20 11:25:32,009 Epoch[5] Batch [610]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.156040,	
2017-07-20 11:25:36,016 Epoch[5] Batch [620]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.156121,	
2017-07-20 11:25:40,028 Epoch[5] Batch [630]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.156186,	
2017-07-20 11:25:44,161 Epoch[5] Batch [640]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.156095,	
2017-07-20 11:25:48,067 Epoch[5] Batch [650]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.156437,	
2017-07-20 11:25:51,961 Epoch[5] Batch [660]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.156586,	
2017-07-20 11:25:56,097 Epoch[5] Batch [670]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.156441,	
2017-07-20 11:25:59,948 Epoch[5] Batch [680]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.156458,	
2017-07-20 11:26:03,955 Epoch[5] Batch [690]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.156373,	
2017-07-20 11:26:07,886 Epoch[5] Batch [700]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.156720,	
2017-07-20 11:26:11,848 Epoch[5] Batch [710]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.157039,	
2017-07-20 11:26:15,964 Epoch[5] Batch [720]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.157483,	
2017-07-20 11:26:19,768 Epoch[5] Batch [730]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.157846,	
2017-07-20 11:26:23,951 Epoch[5] Batch [740]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.157918,	
2017-07-20 11:26:27,847 Epoch[5] Batch [750]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.157935,	
2017-07-20 11:26:32,034 Epoch[5] Batch [760]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.157822,	
2017-07-20 11:26:36,172 Epoch[5] Batch [770]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.157793,	
2017-07-20 11:26:40,206 Epoch[5] Batch [780]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.157446,	
2017-07-20 11:26:44,083 Epoch[5] Batch [790]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.157299,	
2017-07-20 11:26:47,901 Epoch[5] Batch [800]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.157192,	
2017-07-20 11:26:51,943 Epoch[5] Batch [810]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.157154,	
2017-07-20 11:26:55,766 Epoch[5] Batch [820]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.156865,	
2017-07-20 11:26:59,616 Epoch[5] Batch [830]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.156677,	
2017-07-20 11:27:03,708 Epoch[5] Batch [840]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.156583,	
2017-07-20 11:27:07,650 Epoch[5] Batch [850]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.156916,	
2017-07-20 11:27:11,540 Epoch[5] Batch [860]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.157202,	
2017-07-20 11:27:15,422 Epoch[5] Batch [870]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.157437,	
2017-07-20 11:27:19,444 Epoch[5] Batch [880]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.157550,	
2017-07-20 11:27:23,285 Epoch[5] Batch [890]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.157696,	
2017-07-20 11:27:27,308 Epoch[5] Batch [900]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.157838,	
2017-07-20 11:27:31,238 Epoch[5] Batch [910]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.157694,	
2017-07-20 11:27:35,059 Epoch[5] Batch [920]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.157676,	
2017-07-20 11:27:38,996 Epoch[5] Batch [930]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.157532,	
2017-07-20 11:27:42,778 Epoch[5] Batch [940]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.157507,	
2017-07-20 11:27:46,687 Epoch[5] Batch [950]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.157480,	
2017-07-20 11:27:50,436 Epoch[5] Batch [960]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.157279,	
2017-07-20 11:27:54,418 Epoch[5] Batch [970]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.157102,	
2017-07-20 11:27:58,443 Epoch[5] Batch [980]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.157042,	
2017-07-20 11:28:02,456 Epoch[5] Batch [990]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.157100,	
2017-07-20 11:28:06,710 Epoch[5] Batch [1000]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.157284,	
2017-07-20 11:28:10,950 Epoch[5] Batch [1010]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.157355,	
2017-07-20 11:28:14,963 Epoch[5] Batch [1020]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.157241,	
2017-07-20 11:28:19,111 Epoch[5] Batch [1030]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.157147,	
2017-07-20 11:28:23,010 Epoch[5] Batch [1040]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.157182,	
2017-07-20 11:28:26,993 Epoch[5] Batch [1050]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.157192,	
2017-07-20 11:28:30,885 Epoch[5] Batch [1060]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.157007,	
2017-07-20 11:28:34,683 Epoch[5] Batch [1070]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.156733,	
2017-07-20 11:28:38,768 Epoch[5] Batch [1080]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.156836,	
2017-07-20 11:28:42,602 Epoch[5] Batch [1090]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.156662,	
2017-07-20 11:28:46,400 Epoch[5] Batch [1100]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.156580,	
2017-07-20 11:28:50,288 Epoch[5] Batch [1110]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.156344,	
2017-07-20 11:28:54,352 Epoch[5] Batch [1120]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.156404,	
2017-07-20 11:28:58,312 Epoch[5] Batch [1130]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.156591,	
2017-07-20 11:29:02,228 Epoch[5] Batch [1140]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.157129,	
2017-07-20 11:29:06,156 Epoch[5] Batch [1150]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.157299,	
2017-07-20 11:29:10,084 Epoch[5] Batch [1160]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.157673,	
2017-07-20 11:29:13,897 Epoch[5] Batch [1170]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.157837,	
2017-07-20 11:29:17,881 Epoch[5] Batch [1180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.158058,	
2017-07-20 11:29:22,198 Epoch[5] Batch [1190]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.158085,	
2017-07-20 11:29:26,149 Epoch[5] Batch [1200]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.158184,	
2017-07-20 11:29:30,266 Epoch[5] Batch [1210]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.158154,	
2017-07-20 11:29:34,214 Epoch[5] Batch [1220]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.158196,	
2017-07-20 11:29:38,208 Epoch[5] Batch [1230]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.158575,	
2017-07-20 11:29:42,521 Epoch[5] Batch [1240]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.158748,	
2017-07-20 11:29:46,673 Epoch[5] Batch [1250]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.158802,	
2017-07-20 11:29:50,679 Epoch[5] Batch [1260]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.158710,	
2017-07-20 11:29:54,414 Epoch[5] Batch [1270]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.159000,	
2017-07-20 11:29:58,389 Epoch[5] Batch [1280]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.158960,	
2017-07-20 11:30:02,354 Epoch[5] Batch [1290]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.158872,	
2017-07-20 11:30:06,266 Epoch[5] Batch [1300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.158838,	
2017-07-20 11:30:10,417 Epoch[5] Batch [1310]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.158726,	
2017-07-20 11:30:14,365 Epoch[5] Batch [1320]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.158939,	
2017-07-20 11:30:18,113 Epoch[5] Batch [1330]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.159050,	
2017-07-20 11:30:22,243 Epoch[5] Batch [1340]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.159069,	
2017-07-20 11:30:26,222 Epoch[5] Batch [1350]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.159192,	
2017-07-20 11:30:30,059 Epoch[5] Batch [1360]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.159076,	
2017-07-20 11:30:33,982 Epoch[5] Batch [1370]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.159109,	
2017-07-20 11:30:37,827 Epoch[5] Batch [1380]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.158970,	
2017-07-20 11:30:41,679 Epoch[5] Batch [1390]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.158769,	
2017-07-20 11:30:45,581 Epoch[5] Batch [1400]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.158826,	
2017-07-20 11:30:49,799 Epoch[5] Batch [1410]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.158738,	
2017-07-20 11:30:53,737 Epoch[5] Batch [1420]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.158716,	
2017-07-20 11:30:57,499 Epoch[5] Batch [1430]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.158620,	
2017-07-20 11:31:01,652 Epoch[5] Batch [1440]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.158648,	
2017-07-20 11:31:05,640 Epoch[5] Batch [1450]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.158771,	
2017-07-20 11:31:09,680 Epoch[5] Batch [1460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.158706,	
2017-07-20 11:31:13,891 Epoch[5] Batch [1470]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.158681,	
2017-07-20 11:31:18,071 Epoch[5] Batch [1480]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.158506,	
2017-07-20 11:31:20,488 Epoch[5] Train-FCNLogLoss=0.158486
2017-07-20 11:31:20,488 Epoch[5] Time cost=598.250
2017-07-20 11:31:21,341 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0006.params"
2017-07-20 11:31:22,928 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0006.states"
2017-07-20 11:31:27,537 Epoch[6] Batch [10]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.154018,	
2017-07-20 11:31:31,577 Epoch[6] Batch [20]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.149363,	
2017-07-20 11:31:35,323 Epoch[6] Batch [30]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.146396,	
2017-07-20 11:31:39,309 Epoch[6] Batch [40]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.143753,	
2017-07-20 11:31:43,078 Epoch[6] Batch [50]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.140921,	
2017-07-20 11:31:47,025 Epoch[6] Batch [60]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.149638,	
2017-07-20 11:31:50,929 Epoch[6] Batch [70]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.149682,	
2017-07-20 11:31:54,894 Epoch[6] Batch [80]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.147256,	
2017-07-20 11:31:58,850 Epoch[6] Batch [90]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.148516,	
2017-07-20 11:32:02,773 Epoch[6] Batch [100]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.147762,	
2017-07-20 11:32:06,624 Epoch[6] Batch [110]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.148276,	
2017-07-20 11:32:10,669 Epoch[6] Batch [120]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.148487,	
2017-07-20 11:32:14,519 Epoch[6] Batch [130]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.147736,	
2017-07-20 11:32:18,392 Epoch[6] Batch [140]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.146949,	
2017-07-20 11:32:22,275 Epoch[6] Batch [150]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.145934,	
2017-07-20 11:32:26,270 Epoch[6] Batch [160]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.145075,	
2017-07-20 11:32:30,148 Epoch[6] Batch [170]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.146175,	
2017-07-20 11:32:33,996 Epoch[6] Batch [180]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.147935,	
2017-07-20 11:32:37,895 Epoch[6] Batch [190]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.148066,	
2017-07-20 11:32:41,660 Epoch[6] Batch [200]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.149400,	
2017-07-20 11:32:45,584 Epoch[6] Batch [210]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.148973,	
2017-07-20 11:32:49,449 Epoch[6] Batch [220]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.150863,	
2017-07-20 11:32:53,258 Epoch[6] Batch [230]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.151787,	
2017-07-20 11:32:57,213 Epoch[6] Batch [240]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.151552,	
2017-07-20 11:33:01,218 Epoch[6] Batch [250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.151854,	
2017-07-20 11:33:05,228 Epoch[6] Batch [260]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.152233,	
2017-07-20 11:33:09,257 Epoch[6] Batch [270]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.152653,	
2017-07-20 11:33:13,429 Epoch[6] Batch [280]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.153369,	
2017-07-20 11:33:17,530 Epoch[6] Batch [290]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.152570,	
2017-07-20 11:33:21,474 Epoch[6] Batch [300]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.153114,	
2017-07-20 11:33:25,510 Epoch[6] Batch [310]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.153373,	
2017-07-20 11:33:29,560 Epoch[6] Batch [320]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.154047,	
2017-07-20 11:33:33,580 Epoch[6] Batch [330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.153990,	
2017-07-20 11:33:37,643 Epoch[6] Batch [340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.153090,	
2017-07-20 11:33:41,767 Epoch[6] Batch [350]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.152690,	
2017-07-20 11:33:45,720 Epoch[6] Batch [360]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.152429,	
2017-07-20 11:33:49,668 Epoch[6] Batch [370]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.152341,	
2017-07-20 11:33:53,689 Epoch[6] Batch [380]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.151987,	
2017-07-20 11:33:57,715 Epoch[6] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.151660,	
2017-07-20 11:34:01,596 Epoch[6] Batch [400]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.151856,	
2017-07-20 11:34:05,487 Epoch[6] Batch [410]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.151806,	
2017-07-20 11:34:09,559 Epoch[6] Batch [420]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.151977,	
2017-07-20 11:34:13,599 Epoch[6] Batch [430]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.152265,	
2017-07-20 11:34:17,760 Epoch[6] Batch [440]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.152312,	
2017-07-20 11:34:21,638 Epoch[6] Batch [450]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.152377,	
2017-07-20 11:34:25,602 Epoch[6] Batch [460]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.152202,	
2017-07-20 11:34:29,512 Epoch[6] Batch [470]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.151731,	
2017-07-20 11:34:33,606 Epoch[6] Batch [480]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.152123,	
2017-07-20 11:34:37,667 Epoch[6] Batch [490]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.152612,	
2017-07-20 11:34:41,635 Epoch[6] Batch [500]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.152259,	
2017-07-20 11:34:45,484 Epoch[6] Batch [510]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.152139,	
2017-07-20 11:34:49,370 Epoch[6] Batch [520]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.151957,	
2017-07-20 11:34:53,364 Epoch[6] Batch [530]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.151569,	
2017-07-20 11:34:57,228 Epoch[6] Batch [540]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.151398,	
2017-07-20 11:35:01,239 Epoch[6] Batch [550]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.151767,	
2017-07-20 11:35:05,135 Epoch[6] Batch [560]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.151439,	
2017-07-20 11:35:09,328 Epoch[6] Batch [570]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.151308,	
2017-07-20 11:35:13,469 Epoch[6] Batch [580]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.151508,	
2017-07-20 11:35:17,269 Epoch[6] Batch [590]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.151227,	
2017-07-20 11:35:21,272 Epoch[6] Batch [600]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.151363,	
2017-07-20 11:35:25,348 Epoch[6] Batch [610]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.151315,	
2017-07-20 11:35:29,364 Epoch[6] Batch [620]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.151204,	
2017-07-20 11:35:33,455 Epoch[6] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.151202,	
2017-07-20 11:35:37,508 Epoch[6] Batch [640]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.151154,	
2017-07-20 11:35:41,565 Epoch[6] Batch [650]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.150949,	
2017-07-20 11:35:45,632 Epoch[6] Batch [660]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.151030,	
2017-07-20 11:35:49,488 Epoch[6] Batch [670]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.151097,	
2017-07-20 11:35:53,601 Epoch[6] Batch [680]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.151003,	
2017-07-20 11:35:57,525 Epoch[6] Batch [690]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.150773,	
2017-07-20 11:36:01,464 Epoch[6] Batch [700]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.151012,	
2017-07-20 11:36:05,507 Epoch[6] Batch [710]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.151144,	
2017-07-20 11:36:09,613 Epoch[6] Batch [720]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.151195,	
2017-07-20 11:36:13,698 Epoch[6] Batch [730]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.151143,	
2017-07-20 11:36:17,616 Epoch[6] Batch [740]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.151513,	
2017-07-20 11:36:21,723 Epoch[6] Batch [750]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.151277,	
2017-07-20 11:36:25,703 Epoch[6] Batch [760]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.151073,	
2017-07-20 11:36:29,750 Epoch[6] Batch [770]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.150902,	
2017-07-20 11:36:33,799 Epoch[6] Batch [780]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.151222,	
2017-07-20 11:36:38,008 Epoch[6] Batch [790]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.150978,	
2017-07-20 11:36:41,980 Epoch[6] Batch [800]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.151273,	
2017-07-20 11:36:45,876 Epoch[6] Batch [810]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.151114,	
2017-07-20 11:36:49,910 Epoch[6] Batch [820]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.151229,	
2017-07-20 11:36:54,109 Epoch[6] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.151415,	
2017-07-20 11:36:58,191 Epoch[6] Batch [840]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.151310,	
2017-07-20 11:37:02,271 Epoch[6] Batch [850]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.151447,	
2017-07-20 11:37:06,248 Epoch[6] Batch [860]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.151157,	
2017-07-20 11:37:10,230 Epoch[6] Batch [870]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.151211,	
2017-07-20 11:37:14,251 Epoch[6] Batch [880]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.151140,	
2017-07-20 11:37:18,508 Epoch[6] Batch [890]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.151018,	
2017-07-20 11:37:22,603 Epoch[6] Batch [900]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.150877,	
2017-07-20 11:37:26,695 Epoch[6] Batch [910]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.150845,	
2017-07-20 11:37:30,618 Epoch[6] Batch [920]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.150864,	
2017-07-20 11:37:34,509 Epoch[6] Batch [930]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.150659,	
2017-07-20 11:37:38,444 Epoch[6] Batch [940]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.150524,	
2017-07-20 11:37:42,253 Epoch[6] Batch [950]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.150497,	
2017-07-20 11:37:46,191 Epoch[6] Batch [960]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.150384,	
2017-07-20 11:37:50,069 Epoch[6] Batch [970]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.150237,	
2017-07-20 11:37:53,985 Epoch[6] Batch [980]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.150316,	
2017-07-20 11:37:57,922 Epoch[6] Batch [990]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.150462,	
2017-07-20 11:38:01,764 Epoch[6] Batch [1000]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.150317,	
2017-07-20 11:38:05,665 Epoch[6] Batch [1010]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.150290,	
2017-07-20 11:38:09,586 Epoch[6] Batch [1020]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.150278,	
2017-07-20 11:38:13,389 Epoch[6] Batch [1030]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.150268,	
2017-07-20 11:38:17,404 Epoch[6] Batch [1040]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.150429,	
2017-07-20 11:38:21,301 Epoch[6] Batch [1050]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.150226,	
2017-07-20 11:38:25,163 Epoch[6] Batch [1060]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.150049,	
2017-07-20 11:38:28,932 Epoch[6] Batch [1070]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.150053,	
2017-07-20 11:38:32,785 Epoch[6] Batch [1080]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.149897,	
2017-07-20 11:38:36,703 Epoch[6] Batch [1090]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.149812,	
2017-07-20 11:38:40,592 Epoch[6] Batch [1100]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.149769,	
2017-07-20 11:38:44,518 Epoch[6] Batch [1110]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.149568,	
2017-07-20 11:38:48,414 Epoch[6] Batch [1120]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.149544,	
2017-07-20 11:38:52,354 Epoch[6] Batch [1130]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.149459,	
2017-07-20 11:38:56,210 Epoch[6] Batch [1140]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.149304,	
2017-07-20 11:39:00,055 Epoch[6] Batch [1150]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.149265,	
2017-07-20 11:39:03,923 Epoch[6] Batch [1160]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.149230,	
2017-07-20 11:39:07,780 Epoch[6] Batch [1170]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.149110,	
2017-07-20 11:39:11,676 Epoch[6] Batch [1180]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.149210,	
2017-07-20 11:39:15,522 Epoch[6] Batch [1190]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.149085,	
2017-07-20 11:39:19,443 Epoch[6] Batch [1200]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.148970,	
2017-07-20 11:39:23,469 Epoch[6] Batch [1210]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.148919,	
2017-07-20 11:39:27,391 Epoch[6] Batch [1220]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.148964,	
2017-07-20 11:39:31,328 Epoch[6] Batch [1230]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.148828,	
2017-07-20 11:39:35,398 Epoch[6] Batch [1240]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.148606,	
2017-07-20 11:39:39,387 Epoch[6] Batch [1250]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.148425,	
2017-07-20 11:39:43,197 Epoch[6] Batch [1260]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.148327,	
2017-07-20 11:39:47,243 Epoch[6] Batch [1270]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.148191,	
2017-07-20 11:39:51,086 Epoch[6] Batch [1280]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.148649,	
2017-07-20 11:39:54,869 Epoch[6] Batch [1290]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.149129,	
2017-07-20 11:39:58,761 Epoch[6] Batch [1300]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.149159,	
2017-07-20 11:40:02,804 Epoch[6] Batch [1310]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.149272,	
2017-07-20 11:40:06,699 Epoch[6] Batch [1320]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.149401,	
2017-07-20 11:40:10,646 Epoch[6] Batch [1330]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.149334,	
2017-07-20 11:40:14,612 Epoch[6] Batch [1340]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.149253,	
2017-07-20 11:40:18,649 Epoch[6] Batch [1350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.149059,	
2017-07-20 11:40:22,525 Epoch[6] Batch [1360]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.148954,	
2017-07-20 11:40:26,455 Epoch[6] Batch [1370]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.148994,	
2017-07-20 11:40:30,233 Epoch[6] Batch [1380]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.148858,	
2017-07-20 11:40:34,088 Epoch[6] Batch [1390]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.148864,	
2017-07-20 11:40:37,973 Epoch[6] Batch [1400]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.148763,	
2017-07-20 11:40:41,998 Epoch[6] Batch [1410]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.148617,	
2017-07-20 11:40:45,919 Epoch[6] Batch [1420]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.148439,	
2017-07-20 11:40:49,776 Epoch[6] Batch [1430]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.148379,	
2017-07-20 11:40:53,733 Epoch[6] Batch [1440]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.148432,	
2017-07-20 11:40:57,585 Epoch[6] Batch [1450]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.148368,	
2017-07-20 11:41:01,532 Epoch[6] Batch [1460]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.148371,	
2017-07-20 11:41:05,445 Epoch[6] Batch [1470]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.148274,	
2017-07-20 11:41:09,381 Epoch[6] Batch [1480]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.148269,	
2017-07-20 11:41:11,753 Epoch[6] Train-FCNLogLoss=0.148225
2017-07-20 11:41:11,753 Epoch[6] Time cost=588.825
2017-07-20 11:41:12,520 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0007.params"
2017-07-20 11:41:14,068 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0007.states"
2017-07-20 11:41:18,611 Epoch[7] Batch [10]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.127721,	
2017-07-20 11:41:22,433 Epoch[7] Batch [20]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.132141,	
2017-07-20 11:41:26,235 Epoch[7] Batch [30]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.131661,	
2017-07-20 11:41:30,205 Epoch[7] Batch [40]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.135411,	
2017-07-20 11:41:34,309 Epoch[7] Batch [50]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.137491,	
2017-07-20 11:41:38,325 Epoch[7] Batch [60]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.136916,	
2017-07-20 11:41:42,253 Epoch[7] Batch [70]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.138475,	
2017-07-20 11:41:46,055 Epoch[7] Batch [80]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.142037,	
2017-07-20 11:41:49,953 Epoch[7] Batch [90]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.142097,	
2017-07-20 11:41:53,732 Epoch[7] Batch [100]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.140896,	
2017-07-20 11:41:57,629 Epoch[7] Batch [110]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.139651,	
2017-07-20 11:42:01,454 Epoch[7] Batch [120]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.140214,	
2017-07-20 11:42:05,385 Epoch[7] Batch [130]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.138911,	
2017-07-20 11:42:09,177 Epoch[7] Batch [140]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.140144,	
2017-07-20 11:42:12,956 Epoch[7] Batch [150]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.139137,	
2017-07-20 11:42:16,880 Epoch[7] Batch [160]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.139595,	
2017-07-20 11:42:20,765 Epoch[7] Batch [170]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.139318,	
2017-07-20 11:42:24,672 Epoch[7] Batch [180]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.138442,	
2017-07-20 11:42:28,525 Epoch[7] Batch [190]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.138211,	
2017-07-20 11:42:32,427 Epoch[7] Batch [200]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.136762,	
2017-07-20 11:42:36,286 Epoch[7] Batch [210]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.137387,	
2017-07-20 11:42:40,239 Epoch[7] Batch [220]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.137334,	
2017-07-20 11:42:44,133 Epoch[7] Batch [230]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.137017,	
2017-07-20 11:42:48,037 Epoch[7] Batch [240]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.137368,	
2017-07-20 11:42:51,937 Epoch[7] Batch [250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.139278,	
2017-07-20 11:42:55,794 Epoch[7] Batch [260]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.139545,	
2017-07-20 11:42:59,644 Epoch[7] Batch [270]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.139443,	
2017-07-20 11:43:03,513 Epoch[7] Batch [280]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.139580,	
2017-07-20 11:43:07,343 Epoch[7] Batch [290]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.139668,	
2017-07-20 11:43:11,287 Epoch[7] Batch [300]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.139661,	
2017-07-20 11:43:15,250 Epoch[7] Batch [310]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.140036,	
2017-07-20 11:43:19,221 Epoch[7] Batch [320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.140871,	
2017-07-20 11:43:23,470 Epoch[7] Batch [330]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.140820,	
2017-07-20 11:43:27,568 Epoch[7] Batch [340]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.141523,	
2017-07-20 11:43:31,605 Epoch[7] Batch [350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.141736,	
2017-07-20 11:43:35,583 Epoch[7] Batch [360]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.141960,	
2017-07-20 11:43:39,681 Epoch[7] Batch [370]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.142378,	
2017-07-20 11:43:43,738 Epoch[7] Batch [380]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.142152,	
2017-07-20 11:43:47,751 Epoch[7] Batch [390]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.142250,	
2017-07-20 11:43:51,804 Epoch[7] Batch [400]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.142149,	
2017-07-20 11:43:55,914 Epoch[7] Batch [410]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.141956,	
2017-07-20 11:43:59,746 Epoch[7] Batch [420]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.141600,	
2017-07-20 11:44:03,737 Epoch[7] Batch [430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.141323,	
2017-07-20 11:44:07,722 Epoch[7] Batch [440]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.140982,	
2017-07-20 11:44:11,602 Epoch[7] Batch [450]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.140955,	
2017-07-20 11:44:15,694 Epoch[7] Batch [460]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.140963,	
2017-07-20 11:44:19,896 Epoch[7] Batch [470]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.140710,	
2017-07-20 11:44:23,913 Epoch[7] Batch [480]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.141155,	
2017-07-20 11:44:27,827 Epoch[7] Batch [490]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.141020,	
2017-07-20 11:44:31,899 Epoch[7] Batch [500]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.141081,	
2017-07-20 11:44:35,945 Epoch[7] Batch [510]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.141069,	
2017-07-20 11:44:39,934 Epoch[7] Batch [520]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.140831,	
2017-07-20 11:44:43,855 Epoch[7] Batch [530]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.140461,	
2017-07-20 11:44:47,883 Epoch[7] Batch [540]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.140535,	
2017-07-20 11:44:51,802 Epoch[7] Batch [550]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.141024,	
2017-07-20 11:44:56,046 Epoch[7] Batch [560]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.141268,	
2017-07-20 11:45:00,101 Epoch[7] Batch [570]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.141238,	
2017-07-20 11:45:04,049 Epoch[7] Batch [580]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.141234,	
2017-07-20 11:45:07,961 Epoch[7] Batch [590]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.141128,	
2017-07-20 11:45:11,941 Epoch[7] Batch [600]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.141369,	
2017-07-20 11:45:15,852 Epoch[7] Batch [610]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.140890,	
2017-07-20 11:45:19,847 Epoch[7] Batch [620]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.140777,	
2017-07-20 11:45:23,877 Epoch[7] Batch [630]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.140560,	
2017-07-20 11:45:27,735 Epoch[7] Batch [640]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.140498,	
2017-07-20 11:45:31,724 Epoch[7] Batch [650]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.140634,	
2017-07-20 11:45:35,613 Epoch[7] Batch [660]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.140949,	
2017-07-20 11:45:39,567 Epoch[7] Batch [670]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.140582,	
2017-07-20 11:45:43,463 Epoch[7] Batch [680]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.140424,	
2017-07-20 11:45:47,363 Epoch[7] Batch [690]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.140264,	
2017-07-20 11:45:51,472 Epoch[7] Batch [700]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.140116,	
2017-07-20 11:45:55,677 Epoch[7] Batch [710]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.140173,	
2017-07-20 11:45:59,694 Epoch[7] Batch [720]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.140487,	
2017-07-20 11:46:03,625 Epoch[7] Batch [730]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.140279,	
2017-07-20 11:46:07,725 Epoch[7] Batch [740]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.140231,	
2017-07-20 11:46:11,820 Epoch[7] Batch [750]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.140254,	
2017-07-20 11:46:15,871 Epoch[7] Batch [760]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.140162,	
2017-07-20 11:46:19,831 Epoch[7] Batch [770]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.140128,	
2017-07-20 11:46:23,781 Epoch[7] Batch [780]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.140162,	
2017-07-20 11:46:27,720 Epoch[7] Batch [790]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.140176,	
2017-07-20 11:46:31,631 Epoch[7] Batch [800]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.140358,	
2017-07-20 11:46:35,738 Epoch[7] Batch [810]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.140450,	
2017-07-20 11:46:39,757 Epoch[7] Batch [820]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.140395,	
2017-07-20 11:46:43,606 Epoch[7] Batch [830]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.140377,	
2017-07-20 11:46:47,534 Epoch[7] Batch [840]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.140576,	
2017-07-20 11:46:51,415 Epoch[7] Batch [850]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.140615,	
2017-07-20 11:46:55,242 Epoch[7] Batch [860]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.140495,	
2017-07-20 11:46:59,256 Epoch[7] Batch [870]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.140500,	
2017-07-20 11:47:03,126 Epoch[7] Batch [880]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.140516,	
2017-07-20 11:47:07,204 Epoch[7] Batch [890]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.140531,	
2017-07-20 11:47:11,156 Epoch[7] Batch [900]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.140557,	
2017-07-20 11:47:15,193 Epoch[7] Batch [910]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.140642,	
2017-07-20 11:47:19,247 Epoch[7] Batch [920]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.140691,	
2017-07-20 11:47:23,221 Epoch[7] Batch [930]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.140566,	
2017-07-20 11:47:27,176 Epoch[7] Batch [940]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.140766,	
2017-07-20 11:47:31,253 Epoch[7] Batch [950]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.140637,	
2017-07-20 11:47:35,319 Epoch[7] Batch [960]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.140518,	
2017-07-20 11:47:39,299 Epoch[7] Batch [970]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.140499,	
2017-07-20 11:47:43,200 Epoch[7] Batch [980]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.140757,	
2017-07-20 11:47:47,033 Epoch[7] Batch [990]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.140737,	
2017-07-20 11:47:50,868 Epoch[7] Batch [1000]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.140842,	
2017-07-20 11:47:54,764 Epoch[7] Batch [1010]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.140683,	
2017-07-20 11:47:58,571 Epoch[7] Batch [1020]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.140511,	
2017-07-20 11:48:02,450 Epoch[7] Batch [1030]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.140297,	
2017-07-20 11:48:06,445 Epoch[7] Batch [1040]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.140193,	
2017-07-20 11:48:10,360 Epoch[7] Batch [1050]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.140121,	
2017-07-20 11:48:14,275 Epoch[7] Batch [1060]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.140007,	
2017-07-20 11:48:18,204 Epoch[7] Batch [1070]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.140106,	
2017-07-20 11:48:22,045 Epoch[7] Batch [1080]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.140156,	
2017-07-20 11:48:25,936 Epoch[7] Batch [1090]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.140281,	
2017-07-20 11:48:29,785 Epoch[7] Batch [1100]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.140297,	
2017-07-20 11:48:33,661 Epoch[7] Batch [1110]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.140285,	
2017-07-20 11:48:37,453 Epoch[7] Batch [1120]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.140462,	
2017-07-20 11:48:41,481 Epoch[7] Batch [1130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.140461,	
2017-07-20 11:48:45,299 Epoch[7] Batch [1140]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.140536,	
2017-07-20 11:48:49,267 Epoch[7] Batch [1150]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.140639,	
2017-07-20 11:48:53,180 Epoch[7] Batch [1160]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.140646,	
2017-07-20 11:48:57,009 Epoch[7] Batch [1170]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.140584,	
2017-07-20 11:49:01,005 Epoch[7] Batch [1180]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.140559,	
2017-07-20 11:49:04,942 Epoch[7] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.140366,	
2017-07-20 11:49:08,930 Epoch[7] Batch [1200]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.140400,	
2017-07-20 11:49:12,672 Epoch[7] Batch [1210]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.140357,	
2017-07-20 11:49:16,659 Epoch[7] Batch [1220]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.140435,	
2017-07-20 11:49:20,556 Epoch[7] Batch [1230]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.140501,	
2017-07-20 11:49:24,556 Epoch[7] Batch [1240]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.140384,	
2017-07-20 11:49:28,447 Epoch[7] Batch [1250]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.140332,	
2017-07-20 11:49:32,390 Epoch[7] Batch [1260]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.140143,	
2017-07-20 11:49:36,320 Epoch[7] Batch [1270]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.140109,	
2017-07-20 11:49:40,176 Epoch[7] Batch [1280]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.140059,	
2017-07-20 11:49:44,039 Epoch[7] Batch [1290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.139982,	
2017-07-20 11:49:47,953 Epoch[7] Batch [1300]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.139935,	
2017-07-20 11:49:51,919 Epoch[7] Batch [1310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.139794,	
2017-07-20 11:49:55,754 Epoch[7] Batch [1320]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.139627,	
2017-07-20 11:49:59,633 Epoch[7] Batch [1330]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.139673,	
2017-07-20 11:50:03,605 Epoch[7] Batch [1340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.139597,	
2017-07-20 11:50:07,402 Epoch[7] Batch [1350]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.139522,	
2017-07-20 11:50:11,469 Epoch[7] Batch [1360]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.139381,	
2017-07-20 11:50:15,278 Epoch[7] Batch [1370]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.139336,	
2017-07-20 11:50:19,122 Epoch[7] Batch [1380]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.139231,	
2017-07-20 11:50:22,926 Epoch[7] Batch [1390]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.139212,	
2017-07-20 11:50:26,964 Epoch[7] Batch [1400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.139182,	
2017-07-20 11:50:30,967 Epoch[7] Batch [1410]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.139074,	
2017-07-20 11:50:34,669 Epoch[7] Batch [1420]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.138977,	
2017-07-20 11:50:38,601 Epoch[7] Batch [1430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.139149,	
2017-07-20 11:50:42,481 Epoch[7] Batch [1440]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.139220,	
2017-07-20 11:50:46,251 Epoch[7] Batch [1450]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.139248,	
2017-07-20 11:50:50,225 Epoch[7] Batch [1460]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.139303,	
2017-07-20 11:50:54,193 Epoch[7] Batch [1470]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.139336,	
2017-07-20 11:50:58,199 Epoch[7] Batch [1480]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.139320,	
2017-07-20 11:51:00,540 Epoch[7] Train-FCNLogLoss=0.139404
2017-07-20 11:51:00,540 Epoch[7] Time cost=586.471
2017-07-20 11:51:01,256 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0008.params"
2017-07-20 11:51:02,900 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0008.states"
2017-07-20 11:51:07,482 Epoch[8] Batch [10]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.149930,	
2017-07-20 11:51:11,345 Epoch[8] Batch [20]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.146084,	
2017-07-20 11:51:15,214 Epoch[8] Batch [30]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.143111,	
2017-07-20 11:51:19,076 Epoch[8] Batch [40]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.143319,	
2017-07-20 11:51:23,021 Epoch[8] Batch [50]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.140706,	
2017-07-20 11:51:26,904 Epoch[8] Batch [60]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.138458,	
2017-07-20 11:51:30,801 Epoch[8] Batch [70]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.135502,	
2017-07-20 11:51:34,600 Epoch[8] Batch [80]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.136146,	
2017-07-20 11:51:38,517 Epoch[8] Batch [90]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.137293,	
2017-07-20 11:51:42,449 Epoch[8] Batch [100]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.138915,	
2017-07-20 11:51:46,273 Epoch[8] Batch [110]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.140867,	
2017-07-20 11:51:50,164 Epoch[8] Batch [120]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.144383,	
2017-07-20 11:51:53,937 Epoch[8] Batch [130]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.144496,	
2017-07-20 11:51:57,831 Epoch[8] Batch [140]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.143128,	
2017-07-20 11:52:01,726 Epoch[8] Batch [150]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.143514,	
2017-07-20 11:52:05,576 Epoch[8] Batch [160]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.143510,	
2017-07-20 11:52:09,408 Epoch[8] Batch [170]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.141382,	
2017-07-20 11:52:13,137 Epoch[8] Batch [180]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.141737,	
2017-07-20 11:52:17,133 Epoch[8] Batch [190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.141143,	
2017-07-20 11:52:21,069 Epoch[8] Batch [200]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.140863,	
2017-07-20 11:52:24,922 Epoch[8] Batch [210]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.141709,	
2017-07-20 11:52:28,841 Epoch[8] Batch [220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.141859,	
2017-07-20 11:52:32,880 Epoch[8] Batch [230]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.142314,	
2017-07-20 11:52:36,931 Epoch[8] Batch [240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.141697,	
2017-07-20 11:52:40,781 Epoch[8] Batch [250]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.141689,	
2017-07-20 11:52:44,580 Epoch[8] Batch [260]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.140491,	
2017-07-20 11:52:48,390 Epoch[8] Batch [270]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.140419,	
2017-07-20 11:52:52,277 Epoch[8] Batch [280]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.140498,	
2017-07-20 11:52:56,264 Epoch[8] Batch [290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.140163,	
2017-07-20 11:53:00,107 Epoch[8] Batch [300]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.140046,	
2017-07-20 11:53:04,017 Epoch[8] Batch [310]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.140622,	
2017-07-20 11:53:07,802 Epoch[8] Batch [320]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.140660,	
2017-07-20 11:53:11,743 Epoch[8] Batch [330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.140417,	
2017-07-20 11:53:15,719 Epoch[8] Batch [340]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.140659,	
2017-07-20 11:53:19,877 Epoch[8] Batch [350]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.140379,	
2017-07-20 11:53:23,987 Epoch[8] Batch [360]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.140105,	
2017-07-20 11:53:27,964 Epoch[8] Batch [370]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.140116,	
2017-07-20 11:53:32,028 Epoch[8] Batch [380]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.139656,	
2017-07-20 11:53:35,903 Epoch[8] Batch [390]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.139562,	
2017-07-20 11:53:39,935 Epoch[8] Batch [400]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.139388,	
2017-07-20 11:53:43,975 Epoch[8] Batch [410]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.139345,	
2017-07-20 11:53:48,131 Epoch[8] Batch [420]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.138918,	
2017-07-20 11:53:52,106 Epoch[8] Batch [430]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.138530,	
2017-07-20 11:53:56,127 Epoch[8] Batch [440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.138603,	
2017-07-20 11:54:00,362 Epoch[8] Batch [450]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.138650,	
2017-07-20 11:54:04,502 Epoch[8] Batch [460]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.138397,	
2017-07-20 11:54:08,491 Epoch[8] Batch [470]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.138123,	
2017-07-20 11:54:12,597 Epoch[8] Batch [480]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.137930,	
2017-07-20 11:54:16,577 Epoch[8] Batch [490]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.138091,	
2017-07-20 11:54:20,666 Epoch[8] Batch [500]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.138110,	
2017-07-20 11:54:24,650 Epoch[8] Batch [510]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.137800,	
2017-07-20 11:54:28,454 Epoch[8] Batch [520]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.137798,	
2017-07-20 11:54:32,554 Epoch[8] Batch [530]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.138001,	
2017-07-20 11:54:36,510 Epoch[8] Batch [540]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.138100,	
2017-07-20 11:54:40,633 Epoch[8] Batch [550]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.138517,	
2017-07-20 11:54:44,637 Epoch[8] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.138231,	
2017-07-20 11:54:48,523 Epoch[8] Batch [570]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.138481,	
2017-07-20 11:54:52,460 Epoch[8] Batch [580]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.138382,	
2017-07-20 11:54:56,362 Epoch[8] Batch [590]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.139045,	
2017-07-20 11:55:00,498 Epoch[8] Batch [600]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.139049,	
2017-07-20 11:55:04,408 Epoch[8] Batch [610]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.139063,	
2017-07-20 11:55:08,328 Epoch[8] Batch [620]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.139054,	
2017-07-20 11:55:12,235 Epoch[8] Batch [630]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.139204,	
2017-07-20 11:55:16,154 Epoch[8] Batch [640]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.139149,	
2017-07-20 11:55:20,336 Epoch[8] Batch [650]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.138934,	
2017-07-20 11:55:24,484 Epoch[8] Batch [660]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.138947,	
2017-07-20 11:55:28,451 Epoch[8] Batch [670]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.139062,	
2017-07-20 11:55:32,330 Epoch[8] Batch [680]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.139142,	
2017-07-20 11:55:36,341 Epoch[8] Batch [690]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.139080,	
2017-07-20 11:55:40,367 Epoch[8] Batch [700]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.138980,	
2017-07-20 11:55:44,472 Epoch[8] Batch [710]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.138681,	
2017-07-20 11:55:48,423 Epoch[8] Batch [720]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.138617,	
2017-07-20 11:55:52,505 Epoch[8] Batch [730]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.138754,	
2017-07-20 11:55:56,636 Epoch[8] Batch [740]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.138890,	
2017-07-20 11:56:00,714 Epoch[8] Batch [750]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.138937,	
2017-07-20 11:56:04,704 Epoch[8] Batch [760]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.139185,	
2017-07-20 11:56:08,839 Epoch[8] Batch [770]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.139294,	
2017-07-20 11:56:12,885 Epoch[8] Batch [780]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.139264,	
2017-07-20 11:56:16,916 Epoch[8] Batch [790]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.139612,	
2017-07-20 11:56:20,904 Epoch[8] Batch [800]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.139659,	
2017-07-20 11:56:25,011 Epoch[8] Batch [810]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.139542,	
2017-07-20 11:56:29,038 Epoch[8] Batch [820]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.139360,	
2017-07-20 11:56:33,012 Epoch[8] Batch [830]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.139138,	
2017-07-20 11:56:37,097 Epoch[8] Batch [840]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.138970,	
2017-07-20 11:56:41,137 Epoch[8] Batch [850]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.139063,	
2017-07-20 11:56:45,137 Epoch[8] Batch [860]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.139029,	
2017-07-20 11:56:49,185 Epoch[8] Batch [870]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.139095,	
2017-07-20 11:56:53,239 Epoch[8] Batch [880]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.138896,	
2017-07-20 11:56:57,236 Epoch[8] Batch [890]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.138966,	
2017-07-20 11:57:01,377 Epoch[8] Batch [900]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.138979,	
2017-07-20 11:57:05,251 Epoch[8] Batch [910]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.139063,	
2017-07-20 11:57:09,139 Epoch[8] Batch [920]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.138931,	
2017-07-20 11:57:13,032 Epoch[8] Batch [930]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.139176,	
2017-07-20 11:57:16,903 Epoch[8] Batch [940]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.139149,	
2017-07-20 11:57:21,124 Epoch[8] Batch [950]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.139116,	
2017-07-20 11:57:25,241 Epoch[8] Batch [960]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.138945,	
2017-07-20 11:57:29,119 Epoch[8] Batch [970]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.138838,	
2017-07-20 11:57:33,030 Epoch[8] Batch [980]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.138716,	
2017-07-20 11:57:37,143 Epoch[8] Batch [990]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.138581,	
2017-07-20 11:57:41,164 Epoch[8] Batch [1000]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.138592,	
2017-07-20 11:57:45,167 Epoch[8] Batch [1010]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.138440,	
2017-07-20 11:57:49,222 Epoch[8] Batch [1020]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.138432,	
2017-07-20 11:57:53,119 Epoch[8] Batch [1030]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.138544,	
2017-07-20 11:57:57,191 Epoch[8] Batch [1040]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.138660,	
2017-07-20 11:58:01,098 Epoch[8] Batch [1050]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.138782,	
2017-07-20 11:58:05,185 Epoch[8] Batch [1060]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.138721,	
2017-07-20 11:58:09,279 Epoch[8] Batch [1070]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.138702,	
2017-07-20 11:58:13,350 Epoch[8] Batch [1080]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.138767,	
2017-07-20 11:58:17,505 Epoch[8] Batch [1090]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.138759,	
2017-07-20 11:58:21,636 Epoch[8] Batch [1100]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.138861,	
2017-07-20 11:58:25,748 Epoch[8] Batch [1110]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.138989,	
2017-07-20 11:58:29,818 Epoch[8] Batch [1120]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.138917,	
2017-07-20 11:58:33,854 Epoch[8] Batch [1130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.138793,	
2017-07-20 11:58:37,898 Epoch[8] Batch [1140]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.138675,	
2017-07-20 11:58:41,794 Epoch[8] Batch [1150]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.138582,	
2017-07-20 11:58:45,802 Epoch[8] Batch [1160]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.138465,	
2017-07-20 11:58:49,814 Epoch[8] Batch [1170]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.138525,	
2017-07-20 11:58:53,938 Epoch[8] Batch [1180]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.138455,	
2017-07-20 11:58:58,085 Epoch[8] Batch [1190]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.138361,	
2017-07-20 11:59:02,082 Epoch[8] Batch [1200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.138384,	
2017-07-20 11:59:06,131 Epoch[8] Batch [1210]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.138402,	
2017-07-20 11:59:10,229 Epoch[8] Batch [1220]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.138215,	
2017-07-20 11:59:14,113 Epoch[8] Batch [1230]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.138000,	
2017-07-20 11:59:18,116 Epoch[8] Batch [1240]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.137825,	
2017-07-20 11:59:22,101 Epoch[8] Batch [1250]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.137753,	
2017-07-20 11:59:25,956 Epoch[8] Batch [1260]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.137664,	
2017-07-20 11:59:29,904 Epoch[8] Batch [1270]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.137574,	
2017-07-20 11:59:34,133 Epoch[8] Batch [1280]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.137489,	
2017-07-20 11:59:38,000 Epoch[8] Batch [1290]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.137454,	
2017-07-20 11:59:42,009 Epoch[8] Batch [1300]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.137472,	
2017-07-20 11:59:45,884 Epoch[8] Batch [1310]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.137417,	
2017-07-20 11:59:49,928 Epoch[8] Batch [1320]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.137382,	
2017-07-20 11:59:53,862 Epoch[8] Batch [1330]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.137345,	
2017-07-20 11:59:57,805 Epoch[8] Batch [1340]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.137386,	
2017-07-20 12:00:01,832 Epoch[8] Batch [1350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.137366,	
2017-07-20 12:00:05,888 Epoch[8] Batch [1360]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.137434,	
2017-07-20 12:00:09,847 Epoch[8] Batch [1370]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.137395,	
2017-07-20 12:00:13,944 Epoch[8] Batch [1380]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.137357,	
2017-07-20 12:00:18,072 Epoch[8] Batch [1390]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.137407,	
2017-07-20 12:00:22,132 Epoch[8] Batch [1400]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.137336,	
2017-07-20 12:00:26,143 Epoch[8] Batch [1410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.137352,	
2017-07-20 12:00:30,136 Epoch[8] Batch [1420]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.137211,	
2017-07-20 12:00:34,169 Epoch[8] Batch [1430]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.137203,	
2017-07-20 12:00:38,283 Epoch[8] Batch [1440]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.137164,	
2017-07-20 12:00:42,332 Epoch[8] Batch [1450]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.137222,	
2017-07-20 12:00:46,235 Epoch[8] Batch [1460]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.137251,	
2017-07-20 12:00:50,331 Epoch[8] Batch [1470]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.137262,	
2017-07-20 12:00:54,227 Epoch[8] Batch [1480]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.137331,	
2017-07-20 12:00:56,723 Epoch[8] Train-FCNLogLoss=0.137284
2017-07-20 12:00:56,723 Epoch[8] Time cost=593.822
2017-07-20 12:00:57,501 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0009.params"
2017-07-20 12:00:59,147 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0009.states"
2017-07-20 12:01:03,903 Epoch[9] Batch [10]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.131901,	
2017-07-20 12:01:07,846 Epoch[9] Batch [20]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.127441,	
2017-07-20 12:01:11,887 Epoch[9] Batch [30]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.131289,	
2017-07-20 12:01:15,792 Epoch[9] Batch [40]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.131400,	
2017-07-20 12:01:19,828 Epoch[9] Batch [50]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.131136,	
2017-07-20 12:01:23,767 Epoch[9] Batch [60]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.129845,	
2017-07-20 12:01:27,875 Epoch[9] Batch [70]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.128966,	
2017-07-20 12:01:31,832 Epoch[9] Batch [80]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.129616,	
2017-07-20 12:01:35,903 Epoch[9] Batch [90]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.129078,	
2017-07-20 12:01:39,813 Epoch[9] Batch [100]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.128650,	
2017-07-20 12:01:43,808 Epoch[9] Batch [110]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.130101,	
2017-07-20 12:01:47,752 Epoch[9] Batch [120]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.131188,	
2017-07-20 12:01:51,753 Epoch[9] Batch [130]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.130324,	
2017-07-20 12:01:55,715 Epoch[9] Batch [140]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129714,	
2017-07-20 12:01:59,654 Epoch[9] Batch [150]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.128694,	
2017-07-20 12:02:03,590 Epoch[9] Batch [160]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.129809,	
2017-07-20 12:02:07,435 Epoch[9] Batch [170]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.130288,	
2017-07-20 12:02:11,558 Epoch[9] Batch [180]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.130508,	
2017-07-20 12:02:15,549 Epoch[9] Batch [190]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.130424,	
2017-07-20 12:02:19,577 Epoch[9] Batch [200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.129961,	
2017-07-20 12:02:23,558 Epoch[9] Batch [210]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.130161,	
2017-07-20 12:02:27,477 Epoch[9] Batch [220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.129868,	
2017-07-20 12:02:31,543 Epoch[9] Batch [230]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.130463,	
2017-07-20 12:02:35,498 Epoch[9] Batch [240]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.130477,	
2017-07-20 12:02:39,599 Epoch[9] Batch [250]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.129880,	
2017-07-20 12:02:43,630 Epoch[9] Batch [260]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.130390,	
2017-07-20 12:02:47,691 Epoch[9] Batch [270]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.129718,	
2017-07-20 12:02:51,699 Epoch[9] Batch [280]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.129204,	
2017-07-20 12:02:55,677 Epoch[9] Batch [290]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.129492,	
2017-07-20 12:02:59,627 Epoch[9] Batch [300]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.129356,	
2017-07-20 12:03:03,625 Epoch[9] Batch [310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.128852,	
2017-07-20 12:03:07,558 Epoch[9] Batch [320]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.128516,	
2017-07-20 12:03:11,674 Epoch[9] Batch [330]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.129364,	
2017-07-20 12:03:15,628 Epoch[9] Batch [340]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.129124,	
2017-07-20 12:03:19,600 Epoch[9] Batch [350]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.129532,	
2017-07-20 12:03:23,537 Epoch[9] Batch [360]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.129234,	
2017-07-20 12:03:27,460 Epoch[9] Batch [370]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.129322,	
2017-07-20 12:03:31,421 Epoch[9] Batch [380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129518,	
2017-07-20 12:03:35,456 Epoch[9] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.129355,	
2017-07-20 12:03:39,543 Epoch[9] Batch [400]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.129547,	
2017-07-20 12:03:43,479 Epoch[9] Batch [410]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.129472,	
2017-07-20 12:03:47,519 Epoch[9] Batch [420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.129261,	
2017-07-20 12:03:51,416 Epoch[9] Batch [430]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.128793,	
2017-07-20 12:03:55,383 Epoch[9] Batch [440]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.128861,	
2017-07-20 12:03:59,576 Epoch[9] Batch [450]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.129020,	
2017-07-20 12:04:03,644 Epoch[9] Batch [460]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.129062,	
2017-07-20 12:04:07,952 Epoch[9] Batch [470]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.129332,	
2017-07-20 12:04:12,213 Epoch[9] Batch [480]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.129247,	
2017-07-20 12:04:16,379 Epoch[9] Batch [490]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.129518,	
2017-07-20 12:04:20,474 Epoch[9] Batch [500]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.129565,	
2017-07-20 12:04:24,802 Epoch[9] Batch [510]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.129421,	
2017-07-20 12:04:28,974 Epoch[9] Batch [520]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.129342,	
2017-07-20 12:04:33,110 Epoch[9] Batch [530]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.129524,	
2017-07-20 12:04:37,273 Epoch[9] Batch [540]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.129576,	
2017-07-20 12:04:41,376 Epoch[9] Batch [550]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.129762,	
2017-07-20 12:04:45,383 Epoch[9] Batch [560]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.129866,	
2017-07-20 12:04:49,654 Epoch[9] Batch [570]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.129714,	
2017-07-20 12:04:53,900 Epoch[9] Batch [580]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.129761,	
2017-07-20 12:04:58,192 Epoch[9] Batch [590]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.129865,	
2017-07-20 12:05:02,158 Epoch[9] Batch [600]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.129585,	
2017-07-20 12:05:06,410 Epoch[9] Batch [610]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.129394,	
2017-07-20 12:05:10,429 Epoch[9] Batch [620]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.129313,	
2017-07-20 12:05:14,450 Epoch[9] Batch [630]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.129390,	
2017-07-20 12:05:18,585 Epoch[9] Batch [640]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.129604,	
2017-07-20 12:05:22,753 Epoch[9] Batch [650]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.129868,	
2017-07-20 12:05:26,758 Epoch[9] Batch [660]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.130054,	
2017-07-20 12:05:30,806 Epoch[9] Batch [670]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.130104,	
2017-07-20 12:05:35,037 Epoch[9] Batch [680]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.130168,	
2017-07-20 12:05:39,165 Epoch[9] Batch [690]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.130372,	
2017-07-20 12:05:43,366 Epoch[9] Batch [700]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.130288,	
2017-07-20 12:05:47,507 Epoch[9] Batch [710]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.130130,	
2017-07-20 12:05:51,662 Epoch[9] Batch [720]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.130040,	
2017-07-20 12:05:55,811 Epoch[9] Batch [730]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.129938,	
2017-07-20 12:05:59,830 Epoch[9] Batch [740]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.129780,	
2017-07-20 12:06:03,855 Epoch[9] Batch [750]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.129568,	
2017-07-20 12:06:08,000 Epoch[9] Batch [760]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.129626,	
2017-07-20 12:06:12,138 Epoch[9] Batch [770]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.129382,	
2017-07-20 12:06:16,334 Epoch[9] Batch [780]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.129425,	
2017-07-20 12:06:20,430 Epoch[9] Batch [790]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.129360,	
2017-07-20 12:06:24,570 Epoch[9] Batch [800]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.129389,	
2017-07-20 12:06:28,695 Epoch[9] Batch [810]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.129324,	
2017-07-20 12:06:32,769 Epoch[9] Batch [820]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.129366,	
2017-07-20 12:06:36,930 Epoch[9] Batch [830]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.129315,	
2017-07-20 12:06:40,961 Epoch[9] Batch [840]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.129579,	
2017-07-20 12:06:45,040 Epoch[9] Batch [850]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.129351,	
2017-07-20 12:06:49,201 Epoch[9] Batch [860]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.129395,	
2017-07-20 12:06:53,536 Epoch[9] Batch [870]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.129193,	
2017-07-20 12:06:57,787 Epoch[9] Batch [880]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.129104,	
2017-07-20 12:07:01,846 Epoch[9] Batch [890]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.129213,	
2017-07-20 12:07:06,038 Epoch[9] Batch [900]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.129111,	
2017-07-20 12:07:10,144 Epoch[9] Batch [910]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129030,	
2017-07-20 12:07:14,324 Epoch[9] Batch [920]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.128997,	
2017-07-20 12:07:18,498 Epoch[9] Batch [930]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.129052,	
2017-07-20 12:07:22,693 Epoch[9] Batch [940]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.128931,	
2017-07-20 12:07:26,783 Epoch[9] Batch [950]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.128916,	
2017-07-20 12:07:31,009 Epoch[9] Batch [960]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.128839,	
2017-07-20 12:07:35,301 Epoch[9] Batch [970]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.128777,	
2017-07-20 12:07:39,479 Epoch[9] Batch [980]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.128870,	
2017-07-20 12:07:43,563 Epoch[9] Batch [990]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.128804,	
2017-07-20 12:07:47,721 Epoch[9] Batch [1000]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.128714,	
2017-07-20 12:07:51,812 Epoch[9] Batch [1010]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.128515,	
2017-07-20 12:07:55,979 Epoch[9] Batch [1020]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.128511,	
2017-07-20 12:08:00,139 Epoch[9] Batch [1030]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.128431,	
2017-07-20 12:08:04,320 Epoch[9] Batch [1040]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.128344,	
2017-07-20 12:08:08,323 Epoch[9] Batch [1050]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.128421,	
2017-07-20 12:08:12,430 Epoch[9] Batch [1060]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.128415,	
2017-07-20 12:08:16,671 Epoch[9] Batch [1070]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.128610,	
2017-07-20 12:08:20,853 Epoch[9] Batch [1080]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.128747,	
2017-07-20 12:08:25,173 Epoch[9] Batch [1090]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.128709,	
2017-07-20 12:08:29,073 Epoch[9] Batch [1100]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.128643,	
2017-07-20 12:08:33,247 Epoch[9] Batch [1110]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.128639,	
2017-07-20 12:08:37,488 Epoch[9] Batch [1120]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.128675,	
2017-07-20 12:08:41,698 Epoch[9] Batch [1130]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.128697,	
2017-07-20 12:08:45,791 Epoch[9] Batch [1140]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.128883,	
2017-07-20 12:08:49,984 Epoch[9] Batch [1150]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.128929,	
2017-07-20 12:08:54,204 Epoch[9] Batch [1160]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.128900,	
2017-07-20 12:08:58,350 Epoch[9] Batch [1170]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.128866,	
2017-07-20 12:09:02,547 Epoch[9] Batch [1180]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.128802,	
2017-07-20 12:09:06,484 Epoch[9] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.128811,	
2017-07-20 12:09:10,480 Epoch[9] Batch [1200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.128851,	
2017-07-20 12:09:14,396 Epoch[9] Batch [1210]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.128896,	
2017-07-20 12:09:18,369 Epoch[9] Batch [1220]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.128985,	
2017-07-20 12:09:22,311 Epoch[9] Batch [1230]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.128876,	
2017-07-20 12:09:26,336 Epoch[9] Batch [1240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.128988,	
2017-07-20 12:09:30,420 Epoch[9] Batch [1250]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.129126,	
2017-07-20 12:09:34,528 Epoch[9] Batch [1260]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129238,	
2017-07-20 12:09:38,571 Epoch[9] Batch [1270]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.129650,	
2017-07-20 12:09:42,646 Epoch[9] Batch [1280]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.129666,	
2017-07-20 12:09:46,564 Epoch[9] Batch [1290]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.129796,	
2017-07-20 12:09:50,549 Epoch[9] Batch [1300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.129748,	
2017-07-20 12:09:54,496 Epoch[9] Batch [1310]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.129787,	
2017-07-20 12:09:58,562 Epoch[9] Batch [1320]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.129762,	
2017-07-20 12:10:02,634 Epoch[9] Batch [1330]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130029,	
2017-07-20 12:10:06,829 Epoch[9] Batch [1340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.130070,	
2017-07-20 12:10:10,876 Epoch[9] Batch [1350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.130022,	
2017-07-20 12:10:15,000 Epoch[9] Batch [1360]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.130072,	
2017-07-20 12:10:19,089 Epoch[9] Batch [1370]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.130372,	
2017-07-20 12:10:23,184 Epoch[9] Batch [1380]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.130634,	
2017-07-20 12:10:27,181 Epoch[9] Batch [1390]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.130732,	
2017-07-20 12:10:31,183 Epoch[9] Batch [1400]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.130689,	
2017-07-20 12:10:35,188 Epoch[9] Batch [1410]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.130602,	
2017-07-20 12:10:39,200 Epoch[9] Batch [1420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.130663,	
2017-07-20 12:10:43,224 Epoch[9] Batch [1430]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.130654,	
2017-07-20 12:10:47,248 Epoch[9] Batch [1440]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.130665,	
2017-07-20 12:10:51,283 Epoch[9] Batch [1450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.130627,	
2017-07-20 12:10:55,456 Epoch[9] Batch [1460]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.130518,	
2017-07-20 12:10:59,523 Epoch[9] Batch [1470]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.130665,	
2017-07-20 12:11:03,505 Epoch[9] Batch [1480]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.130609,	
2017-07-20 12:11:05,826 Epoch[9] Train-FCNLogLoss=0.130551
2017-07-20 12:11:05,826 Epoch[9] Time cost=606.679
2017-07-20 12:11:06,622 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0010.params"
2017-07-20 12:11:08,396 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0010.states"
2017-07-20 12:11:13,213 Epoch[10] Batch [10]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.119998,	
2017-07-20 12:11:17,406 Epoch[10] Batch [20]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.125939,	
2017-07-20 12:11:21,476 Epoch[10] Batch [30]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.125603,	
2017-07-20 12:11:25,588 Epoch[10] Batch [40]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.131354,	
2017-07-20 12:11:29,550 Epoch[10] Batch [50]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.130116,	
2017-07-20 12:11:33,556 Epoch[10] Batch [60]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.128398,	
2017-07-20 12:11:37,600 Epoch[10] Batch [70]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.138050,	
2017-07-20 12:11:41,546 Epoch[10] Batch [80]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.135069,	
2017-07-20 12:11:45,557 Epoch[10] Batch [90]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.135320,	
2017-07-20 12:11:49,497 Epoch[10] Batch [100]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.133666,	
2017-07-20 12:11:53,475 Epoch[10] Batch [110]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.134037,	
2017-07-20 12:11:57,443 Epoch[10] Batch [120]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.131736,	
2017-07-20 12:12:01,476 Epoch[10] Batch [130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.131273,	
2017-07-20 12:12:05,462 Epoch[10] Batch [140]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.130733,	
2017-07-20 12:12:09,624 Epoch[10] Batch [150]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.130506,	
2017-07-20 12:12:13,569 Epoch[10] Batch [160]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.130184,	
2017-07-20 12:12:17,589 Epoch[10] Batch [170]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.130193,	
2017-07-20 12:12:21,555 Epoch[10] Batch [180]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.130496,	
2017-07-20 12:12:25,552 Epoch[10] Batch [190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.130598,	
2017-07-20 12:12:29,469 Epoch[10] Batch [200]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.130732,	
2017-07-20 12:12:33,454 Epoch[10] Batch [210]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.130065,	
2017-07-20 12:12:37,531 Epoch[10] Batch [220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.129976,	
2017-07-20 12:12:41,497 Epoch[10] Batch [230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.129488,	
2017-07-20 12:12:45,577 Epoch[10] Batch [240]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.129112,	
2017-07-20 12:12:49,560 Epoch[10] Batch [250]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.129516,	
2017-07-20 12:12:53,465 Epoch[10] Batch [260]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.129637,	
2017-07-20 12:12:57,550 Epoch[10] Batch [270]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.129330,	
2017-07-20 12:13:01,522 Epoch[10] Batch [280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.128915,	
2017-07-20 12:13:05,442 Epoch[10] Batch [290]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.128801,	
2017-07-20 12:13:09,564 Epoch[10] Batch [300]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.128432,	
2017-07-20 12:13:13,557 Epoch[10] Batch [310]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.128838,	
2017-07-20 12:13:17,629 Epoch[10] Batch [320]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.128295,	
2017-07-20 12:13:21,551 Epoch[10] Batch [330]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.128220,	
2017-07-20 12:13:25,664 Epoch[10] Batch [340]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.127975,	
2017-07-20 12:13:29,643 Epoch[10] Batch [350]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.127938,	
2017-07-20 12:13:33,714 Epoch[10] Batch [360]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.128174,	
2017-07-20 12:13:37,835 Epoch[10] Batch [370]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.127790,	
2017-07-20 12:13:41,984 Epoch[10] Batch [380]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.127977,	
2017-07-20 12:13:46,022 Epoch[10] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.128133,	
2017-07-20 12:13:50,006 Epoch[10] Batch [400]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.128198,	
2017-07-20 12:13:54,067 Epoch[10] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.128205,	
2017-07-20 12:13:58,011 Epoch[10] Batch [420]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.128353,	
2017-07-20 12:14:01,972 Epoch[10] Batch [430]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.128394,	
2017-07-20 12:14:06,104 Epoch[10] Batch [440]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.128890,	
2017-07-20 12:14:10,048 Epoch[10] Batch [450]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.129510,	
2017-07-20 12:14:14,089 Epoch[10] Batch [460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.129377,	
2017-07-20 12:14:18,159 Epoch[10] Batch [470]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.129679,	
2017-07-20 12:14:22,050 Epoch[10] Batch [480]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.129534,	
2017-07-20 12:14:25,929 Epoch[10] Batch [490]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.129415,	
2017-07-20 12:14:29,976 Epoch[10] Batch [500]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.129207,	
2017-07-20 12:14:34,002 Epoch[10] Batch [510]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.129143,	
2017-07-20 12:14:38,080 Epoch[10] Batch [520]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.129256,	
2017-07-20 12:14:42,178 Epoch[10] Batch [530]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.129606,	
2017-07-20 12:14:46,073 Epoch[10] Batch [540]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.130195,	
2017-07-20 12:14:50,117 Epoch[10] Batch [550]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.130315,	
2017-07-20 12:14:54,197 Epoch[10] Batch [560]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.130227,	
2017-07-20 12:14:58,321 Epoch[10] Batch [570]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.130202,	
2017-07-20 12:15:02,473 Epoch[10] Batch [580]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.130126,	
2017-07-20 12:15:06,588 Epoch[10] Batch [590]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.129867,	
2017-07-20 12:15:10,674 Epoch[10] Batch [600]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.129819,	
2017-07-20 12:15:14,698 Epoch[10] Batch [610]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.129656,	
2017-07-20 12:15:18,857 Epoch[10] Batch [620]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.129983,	
2017-07-20 12:15:22,950 Epoch[10] Batch [630]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.130064,	
2017-07-20 12:15:27,140 Epoch[10] Batch [640]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.130082,	
2017-07-20 12:15:31,195 Epoch[10] Batch [650]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.130045,	
2017-07-20 12:15:35,247 Epoch[10] Batch [660]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.130149,	
2017-07-20 12:15:39,352 Epoch[10] Batch [670]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.130051,	
2017-07-20 12:15:43,729 Epoch[10] Batch [680]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.130279,	
2017-07-20 12:15:47,975 Epoch[10] Batch [690]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.130179,	
2017-07-20 12:15:52,280 Epoch[10] Batch [700]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.129988,	
2017-07-20 12:15:56,267 Epoch[10] Batch [710]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.130080,	
2017-07-20 12:16:00,551 Epoch[10] Batch [720]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.129948,	
2017-07-20 12:16:04,686 Epoch[10] Batch [730]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.130009,	
2017-07-20 12:16:08,715 Epoch[10] Batch [740]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.129974,	
2017-07-20 12:16:12,880 Epoch[10] Batch [750]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.129871,	
2017-07-20 12:16:16,988 Epoch[10] Batch [760]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129878,	
2017-07-20 12:16:21,081 Epoch[10] Batch [770]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.129820,	
2017-07-20 12:16:25,242 Epoch[10] Batch [780]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.129504,	
2017-07-20 12:16:29,375 Epoch[10] Batch [790]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.129397,	
2017-07-20 12:16:33,525 Epoch[10] Batch [800]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.129436,	
2017-07-20 12:16:37,587 Epoch[10] Batch [810]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.129587,	
2017-07-20 12:16:41,787 Epoch[10] Batch [820]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.129605,	
2017-07-20 12:16:45,986 Epoch[10] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.129396,	
2017-07-20 12:16:50,272 Epoch[10] Batch [840]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.129387,	
2017-07-20 12:16:54,540 Epoch[10] Batch [850]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.129244,	
2017-07-20 12:16:58,838 Epoch[10] Batch [860]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.129238,	
2017-07-20 12:17:03,182 Epoch[10] Batch [870]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.128951,	
2017-07-20 12:17:07,325 Epoch[10] Batch [880]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.129071,	
2017-07-20 12:17:11,453 Epoch[10] Batch [890]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.129085,	
2017-07-20 12:17:15,580 Epoch[10] Batch [900]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.129162,	
2017-07-20 12:17:19,709 Epoch[10] Batch [910]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.129508,	
2017-07-20 12:17:23,786 Epoch[10] Batch [920]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.129488,	
2017-07-20 12:17:27,956 Epoch[10] Batch [930]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.129698,	
2017-07-20 12:17:32,096 Epoch[10] Batch [940]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.129755,	
2017-07-20 12:17:36,239 Epoch[10] Batch [950]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.129892,	
2017-07-20 12:17:40,470 Epoch[10] Batch [960]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.129750,	
2017-07-20 12:17:44,541 Epoch[10] Batch [970]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.129946,	
2017-07-20 12:17:48,670 Epoch[10] Batch [980]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.129901,	
2017-07-20 12:17:52,947 Epoch[10] Batch [990]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.129794,	
2017-07-20 12:17:57,094 Epoch[10] Batch [1000]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.129824,	
2017-07-20 12:18:01,302 Epoch[10] Batch [1010]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.129714,	
2017-07-20 12:18:05,583 Epoch[10] Batch [1020]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.129772,	
2017-07-20 12:18:09,686 Epoch[10] Batch [1030]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.129744,	
2017-07-20 12:18:13,765 Epoch[10] Batch [1040]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.129798,	
2017-07-20 12:18:17,803 Epoch[10] Batch [1050]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.129754,	
2017-07-20 12:18:21,960 Epoch[10] Batch [1060]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.129789,	
2017-07-20 12:18:26,089 Epoch[10] Batch [1070]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.129810,	
2017-07-20 12:18:30,358 Epoch[10] Batch [1080]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.129976,	
2017-07-20 12:18:34,443 Epoch[10] Batch [1090]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.129931,	
2017-07-20 12:18:38,699 Epoch[10] Batch [1100]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.129930,	
2017-07-20 12:18:42,893 Epoch[10] Batch [1110]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.129870,	
2017-07-20 12:18:47,014 Epoch[10] Batch [1120]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.129970,	
2017-07-20 12:18:51,054 Epoch[10] Batch [1130]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.129886,	
2017-07-20 12:18:55,137 Epoch[10] Batch [1140]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.129849,	
2017-07-20 12:18:59,260 Epoch[10] Batch [1150]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.129852,	
2017-07-20 12:19:03,454 Epoch[10] Batch [1160]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.129858,	
2017-07-20 12:19:07,450 Epoch[10] Batch [1170]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.129868,	
2017-07-20 12:19:11,531 Epoch[10] Batch [1180]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.129940,	
2017-07-20 12:19:15,470 Epoch[10] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.129951,	
2017-07-20 12:19:19,544 Epoch[10] Batch [1200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130146,	
2017-07-20 12:19:23,653 Epoch[10] Batch [1210]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.130758,	
2017-07-20 12:19:27,570 Epoch[10] Batch [1220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.130962,	
2017-07-20 12:19:31,475 Epoch[10] Batch [1230]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.131047,	
2017-07-20 12:19:35,525 Epoch[10] Batch [1240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.130955,	
2017-07-20 12:19:39,469 Epoch[10] Batch [1250]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.131069,	
2017-07-20 12:19:43,546 Epoch[10] Batch [1260]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.131048,	
2017-07-20 12:19:47,618 Epoch[10] Batch [1270]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130955,	
2017-07-20 12:19:51,718 Epoch[10] Batch [1280]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.130900,	
2017-07-20 12:19:55,832 Epoch[10] Batch [1290]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.130902,	
2017-07-20 12:19:59,799 Epoch[10] Batch [1300]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.130961,	
2017-07-20 12:20:03,771 Epoch[10] Batch [1310]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.130907,	
2017-07-20 12:20:07,845 Epoch[10] Batch [1320]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130849,	
2017-07-20 12:20:11,815 Epoch[10] Batch [1330]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.130945,	
2017-07-20 12:20:15,782 Epoch[10] Batch [1340]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.130855,	
2017-07-20 12:20:19,646 Epoch[10] Batch [1350]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.130861,	
2017-07-20 12:20:23,636 Epoch[10] Batch [1360]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.130885,	
2017-07-20 12:20:27,754 Epoch[10] Batch [1370]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.130848,	
2017-07-20 12:20:31,790 Epoch[10] Batch [1380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.130939,	
2017-07-20 12:20:35,773 Epoch[10] Batch [1390]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.130945,	
2017-07-20 12:20:39,861 Epoch[10] Batch [1400]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.131016,	
2017-07-20 12:20:43,834 Epoch[10] Batch [1410]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.130931,	
2017-07-20 12:20:47,872 Epoch[10] Batch [1420]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.130957,	
2017-07-20 12:20:51,708 Epoch[10] Batch [1430]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.130940,	
2017-07-20 12:20:55,826 Epoch[10] Batch [1440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.130939,	
2017-07-20 12:20:59,733 Epoch[10] Batch [1450]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.130961,	
2017-07-20 12:21:03,753 Epoch[10] Batch [1460]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.130934,	
2017-07-20 12:21:07,735 Epoch[10] Batch [1470]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.131075,	
2017-07-20 12:21:11,858 Epoch[10] Batch [1480]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.131010,	
2017-07-20 12:21:14,253 Epoch[10] Train-FCNLogLoss=0.131022
2017-07-20 12:21:14,253 Epoch[10] Time cost=605.857
2017-07-20 12:21:15,019 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0011.params"
2017-07-20 12:21:16,633 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0011.states"
2017-07-20 12:21:21,456 Epoch[11] Batch [10]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.130402,	
2017-07-20 12:21:25,509 Epoch[11] Batch [20]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.127854,	
2017-07-20 12:21:29,545 Epoch[11] Batch [30]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.126710,	
2017-07-20 12:21:33,490 Epoch[11] Batch [40]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.129128,	
2017-07-20 12:21:37,481 Epoch[11] Batch [50]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.126510,	
2017-07-20 12:21:41,504 Epoch[11] Batch [60]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.129410,	
2017-07-20 12:21:45,461 Epoch[11] Batch [70]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.130663,	
2017-07-20 12:21:49,444 Epoch[11] Batch [80]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.131058,	
2017-07-20 12:21:53,404 Epoch[11] Batch [90]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.132937,	
2017-07-20 12:21:57,465 Epoch[11] Batch [100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.134314,	
2017-07-20 12:22:01,360 Epoch[11] Batch [110]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.133682,	
2017-07-20 12:22:05,472 Epoch[11] Batch [120]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.132566,	
2017-07-20 12:22:09,396 Epoch[11] Batch [130]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.131616,	
2017-07-20 12:22:13,417 Epoch[11] Batch [140]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.130643,	
2017-07-20 12:22:17,342 Epoch[11] Batch [150]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.130655,	
2017-07-20 12:22:21,308 Epoch[11] Batch [160]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.130379,	
2017-07-20 12:22:25,354 Epoch[11] Batch [170]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.129727,	
2017-07-20 12:22:29,484 Epoch[11] Batch [180]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.134870,	
2017-07-20 12:22:33,553 Epoch[11] Batch [190]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.142194,	
2017-07-20 12:22:37,548 Epoch[11] Batch [200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.147915,	
2017-07-20 12:22:41,542 Epoch[11] Batch [210]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.150721,	
2017-07-20 12:22:45,566 Epoch[11] Batch [220]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.151316,	
2017-07-20 12:22:49,576 Epoch[11] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.152079,	
2017-07-20 12:22:53,570 Epoch[11] Batch [240]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.154284,	
2017-07-20 12:22:57,638 Epoch[11] Batch [250]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.154859,	
2017-07-20 12:23:01,554 Epoch[11] Batch [260]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.155101,	
2017-07-20 12:23:05,632 Epoch[11] Batch [270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.154656,	
2017-07-20 12:23:09,794 Epoch[11] Batch [280]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.154079,	
2017-07-20 12:23:13,707 Epoch[11] Batch [290]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.153581,	
2017-07-20 12:23:17,766 Epoch[11] Batch [300]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.152774,	
2017-07-20 12:23:21,767 Epoch[11] Batch [310]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.152233,	
2017-07-20 12:23:25,838 Epoch[11] Batch [320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.152171,	
2017-07-20 12:23:29,845 Epoch[11] Batch [330]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.151390,	
2017-07-20 12:23:33,829 Epoch[11] Batch [340]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.151269,	
2017-07-20 12:23:37,960 Epoch[11] Batch [350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.150727,	
2017-07-20 12:23:41,965 Epoch[11] Batch [360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.150147,	
2017-07-20 12:23:45,856 Epoch[11] Batch [370]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.149408,	
2017-07-20 12:23:49,854 Epoch[11] Batch [380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.149195,	
2017-07-20 12:23:53,822 Epoch[11] Batch [390]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.148860,	
2017-07-20 12:23:57,849 Epoch[11] Batch [400]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.148437,	
2017-07-20 12:24:01,800 Epoch[11] Batch [410]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.148088,	
2017-07-20 12:24:05,864 Epoch[11] Batch [420]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.148280,	
2017-07-20 12:24:09,882 Epoch[11] Batch [430]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.148150,	
2017-07-20 12:24:13,854 Epoch[11] Batch [440]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.147656,	
2017-07-20 12:24:17,798 Epoch[11] Batch [450]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.147552,	
2017-07-20 12:24:21,975 Epoch[11] Batch [460]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.146904,	
2017-07-20 12:24:25,918 Epoch[11] Batch [470]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.146637,	
2017-07-20 12:24:29,934 Epoch[11] Batch [480]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.146273,	
2017-07-20 12:24:33,925 Epoch[11] Batch [490]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.146970,	
2017-07-20 12:24:37,868 Epoch[11] Batch [500]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.147096,	
2017-07-20 12:24:42,002 Epoch[11] Batch [510]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.147421,	
2017-07-20 12:24:46,164 Epoch[11] Batch [520]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.147298,	
2017-07-20 12:24:50,318 Epoch[11] Batch [530]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.147229,	
2017-07-20 12:24:54,472 Epoch[11] Batch [540]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.146943,	
2017-07-20 12:24:58,769 Epoch[11] Batch [550]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.146531,	
2017-07-20 12:25:02,773 Epoch[11] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.146244,	
2017-07-20 12:25:06,896 Epoch[11] Batch [570]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.145619,	
2017-07-20 12:25:11,135 Epoch[11] Batch [580]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.145080,	
2017-07-20 12:25:15,439 Epoch[11] Batch [590]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.144710,	
2017-07-20 12:25:19,461 Epoch[11] Batch [600]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.144374,	
2017-07-20 12:25:23,524 Epoch[11] Batch [610]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.143989,	
2017-07-20 12:25:27,714 Epoch[11] Batch [620]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.144192,	
2017-07-20 12:25:31,917 Epoch[11] Batch [630]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.143909,	
2017-07-20 12:25:36,200 Epoch[11] Batch [640]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.143560,	
2017-07-20 12:25:40,363 Epoch[11] Batch [650]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.143312,	
2017-07-20 12:25:44,433 Epoch[11] Batch [660]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.143111,	
2017-07-20 12:25:48,520 Epoch[11] Batch [670]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.142981,	
2017-07-20 12:25:52,707 Epoch[11] Batch [680]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.142818,	
2017-07-20 12:25:56,836 Epoch[11] Batch [690]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.142579,	
2017-07-20 12:26:01,094 Epoch[11] Batch [700]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.142147,	
2017-07-20 12:26:05,224 Epoch[11] Batch [710]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.141879,	
2017-07-20 12:26:09,382 Epoch[11] Batch [720]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.141574,	
2017-07-20 12:26:13,555 Epoch[11] Batch [730]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.141327,	
2017-07-20 12:26:17,767 Epoch[11] Batch [740]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.141104,	
2017-07-20 12:26:21,937 Epoch[11] Batch [750]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.140852,	
2017-07-20 12:26:26,193 Epoch[11] Batch [760]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.140641,	
2017-07-20 12:26:30,348 Epoch[11] Batch [770]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.140496,	
2017-07-20 12:26:34,537 Epoch[11] Batch [780]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.140205,	
2017-07-20 12:26:38,661 Epoch[11] Batch [790]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.140078,	
2017-07-20 12:26:42,778 Epoch[11] Batch [800]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.140066,	
2017-07-20 12:26:46,875 Epoch[11] Batch [810]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.140005,	
2017-07-20 12:26:51,007 Epoch[11] Batch [820]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.139779,	
2017-07-20 12:26:55,060 Epoch[11] Batch [830]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.139603,	
2017-07-20 12:26:59,129 Epoch[11] Batch [840]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.139633,	
2017-07-20 12:27:03,392 Epoch[11] Batch [850]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.139520,	
2017-07-20 12:27:07,638 Epoch[11] Batch [860]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.139616,	
2017-07-20 12:27:11,712 Epoch[11] Batch [870]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.139405,	
2017-07-20 12:27:15,908 Epoch[11] Batch [880]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.139293,	
2017-07-20 12:27:20,192 Epoch[11] Batch [890]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.138916,	
2017-07-20 12:27:24,516 Epoch[11] Batch [900]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.138833,	
2017-07-20 12:27:28,755 Epoch[11] Batch [910]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.138725,	
2017-07-20 12:27:32,853 Epoch[11] Batch [920]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.138596,	
2017-07-20 12:27:37,005 Epoch[11] Batch [930]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.138507,	
2017-07-20 12:27:41,080 Epoch[11] Batch [940]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.138324,	
2017-07-20 12:27:45,405 Epoch[11] Batch [950]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.138112,	
2017-07-20 12:27:49,448 Epoch[11] Batch [960]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.138717,	
2017-07-20 12:27:53,710 Epoch[11] Batch [970]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.138991,	
2017-07-20 12:27:58,105 Epoch[11] Batch [980]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.139051,	
2017-07-20 12:28:02,268 Epoch[11] Batch [990]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.138829,	
2017-07-20 12:28:06,384 Epoch[11] Batch [1000]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.138984,	
2017-07-20 12:28:10,566 Epoch[11] Batch [1010]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.138910,	
2017-07-20 12:28:14,662 Epoch[11] Batch [1020]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.138830,	
2017-07-20 12:28:18,761 Epoch[11] Batch [1030]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.138886,	
2017-07-20 12:28:22,929 Epoch[11] Batch [1040]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.138812,	
2017-07-20 12:28:27,045 Epoch[11] Batch [1050]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.138928,	
2017-07-20 12:28:31,244 Epoch[11] Batch [1060]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.138847,	
2017-07-20 12:28:35,208 Epoch[11] Batch [1070]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.138912,	
2017-07-20 12:28:39,365 Epoch[11] Batch [1080]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.138801,	
2017-07-20 12:28:43,485 Epoch[11] Batch [1090]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.138573,	
2017-07-20 12:28:47,504 Epoch[11] Batch [1100]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.138467,	
2017-07-20 12:28:51,582 Epoch[11] Batch [1110]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.138316,	
2017-07-20 12:28:55,670 Epoch[11] Batch [1120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.138200,	
2017-07-20 12:28:59,773 Epoch[11] Batch [1130]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.138097,	
2017-07-20 12:29:03,854 Epoch[11] Batch [1140]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.138012,	
2017-07-20 12:29:07,917 Epoch[11] Batch [1150]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.138077,	
2017-07-20 12:29:12,124 Epoch[11] Batch [1160]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.137917,	
2017-07-20 12:29:16,272 Epoch[11] Batch [1170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.138019,	
2017-07-20 12:29:20,285 Epoch[11] Batch [1180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.138083,	
2017-07-20 12:29:24,299 Epoch[11] Batch [1190]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.138048,	
2017-07-20 12:29:28,294 Epoch[11] Batch [1200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.137877,	
2017-07-20 12:29:32,344 Epoch[11] Batch [1210]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.137752,	
2017-07-20 12:29:36,421 Epoch[11] Batch [1220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.137597,	
2017-07-20 12:29:40,550 Epoch[11] Batch [1230]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.137481,	
2017-07-20 12:29:44,589 Epoch[11] Batch [1240]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.137344,	
2017-07-20 12:29:48,685 Epoch[11] Batch [1250]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.137262,	
2017-07-20 12:29:52,672 Epoch[11] Batch [1260]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.137028,	
2017-07-20 12:29:56,663 Epoch[11] Batch [1270]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.136904,	
2017-07-20 12:30:00,751 Epoch[11] Batch [1280]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.136918,	
2017-07-20 12:30:04,894 Epoch[11] Batch [1290]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136866,	
2017-07-20 12:30:08,988 Epoch[11] Batch [1300]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.136795,	
2017-07-20 12:30:13,054 Epoch[11] Batch [1310]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.136695,	
2017-07-20 12:30:17,042 Epoch[11] Batch [1320]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.136650,	
2017-07-20 12:30:21,009 Epoch[11] Batch [1330]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.136544,	
2017-07-20 12:30:25,059 Epoch[11] Batch [1340]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.136429,	
2017-07-20 12:30:29,232 Epoch[11] Batch [1350]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.136287,	
2017-07-20 12:30:33,337 Epoch[11] Batch [1360]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136221,	
2017-07-20 12:30:37,318 Epoch[11] Batch [1370]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.136119,	
2017-07-20 12:30:41,292 Epoch[11] Batch [1380]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.136033,	
2017-07-20 12:30:45,394 Epoch[11] Batch [1390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.135813,	
2017-07-20 12:30:49,469 Epoch[11] Batch [1400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.135615,	
2017-07-20 12:30:53,474 Epoch[11] Batch [1410]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.135698,	
2017-07-20 12:30:57,450 Epoch[11] Batch [1420]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.135630,	
2017-07-20 12:31:01,485 Epoch[11] Batch [1430]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.135630,	
2017-07-20 12:31:05,512 Epoch[11] Batch [1440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.135648,	
2017-07-20 12:31:09,534 Epoch[11] Batch [1450]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.135477,	
2017-07-20 12:31:13,569 Epoch[11] Batch [1460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.135502,	
2017-07-20 12:31:17,527 Epoch[11] Batch [1470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.135443,	
2017-07-20 12:31:21,453 Epoch[11] Batch [1480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.135416,	
2017-07-20 12:31:23,849 Epoch[11] Train-FCNLogLoss=0.135427
2017-07-20 12:31:23,849 Epoch[11] Time cost=607.216
2017-07-20 12:31:24,616 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0012.params"
2017-07-20 12:31:26,216 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0012.states"
2017-07-20 12:31:30,915 Epoch[12] Batch [10]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.128587,	
2017-07-20 12:31:35,082 Epoch[12] Batch [20]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.128728,	
2017-07-20 12:31:39,014 Epoch[12] Batch [30]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.130356,	
2017-07-20 12:31:42,948 Epoch[12] Batch [40]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.128198,	
2017-07-20 12:31:46,952 Epoch[12] Batch [50]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.131502,	
2017-07-20 12:31:51,020 Epoch[12] Batch [60]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.131985,	
2017-07-20 12:31:55,132 Epoch[12] Batch [70]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.130311,	
2017-07-20 12:31:59,255 Epoch[12] Batch [80]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.129967,	
2017-07-20 12:32:03,383 Epoch[12] Batch [90]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.128171,	
2017-07-20 12:32:07,444 Epoch[12] Batch [100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.127642,	
2017-07-20 12:32:11,409 Epoch[12] Batch [110]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.128130,	
2017-07-20 12:32:15,497 Epoch[12] Batch [120]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.127474,	
2017-07-20 12:32:19,598 Epoch[12] Batch [130]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.129459,	
2017-07-20 12:32:23,644 Epoch[12] Batch [140]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.130077,	
2017-07-20 12:32:27,689 Epoch[12] Batch [150]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.129964,	
2017-07-20 12:32:31,844 Epoch[12] Batch [160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.129891,	
2017-07-20 12:32:36,054 Epoch[12] Batch [170]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.129969,	
2017-07-20 12:32:40,115 Epoch[12] Batch [180]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.130072,	
2017-07-20 12:32:44,203 Epoch[12] Batch [190]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.130195,	
2017-07-20 12:32:48,293 Epoch[12] Batch [200]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.130137,	
2017-07-20 12:32:52,246 Epoch[12] Batch [210]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.129717,	
2017-07-20 12:32:56,258 Epoch[12] Batch [220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.128837,	
2017-07-20 12:33:00,243 Epoch[12] Batch [230]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.128950,	
2017-07-20 12:33:04,343 Epoch[12] Batch [240]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.128663,	
2017-07-20 12:33:08,422 Epoch[12] Batch [250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.127976,	
2017-07-20 12:33:12,382 Epoch[12] Batch [260]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.127343,	
2017-07-20 12:33:16,297 Epoch[12] Batch [270]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.126972,	
2017-07-20 12:33:20,261 Epoch[12] Batch [280]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.126542,	
2017-07-20 12:33:24,248 Epoch[12] Batch [290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.126086,	
2017-07-20 12:33:28,302 Epoch[12] Batch [300]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.125680,	
2017-07-20 12:33:32,343 Epoch[12] Batch [310]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.125178,	
2017-07-20 12:33:36,231 Epoch[12] Batch [320]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.125395,	
2017-07-20 12:33:40,211 Epoch[12] Batch [330]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.125561,	
2017-07-20 12:33:44,316 Epoch[12] Batch [340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.125373,	
2017-07-20 12:33:48,338 Epoch[12] Batch [350]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.125772,	
2017-07-20 12:33:52,337 Epoch[12] Batch [360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.125643,	
2017-07-20 12:33:56,348 Epoch[12] Batch [370]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.125832,	
2017-07-20 12:34:00,306 Epoch[12] Batch [380]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.125762,	
2017-07-20 12:34:04,329 Epoch[12] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125550,	
2017-07-20 12:34:08,254 Epoch[12] Batch [400]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.125521,	
2017-07-20 12:34:12,246 Epoch[12] Batch [410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.125430,	
2017-07-20 12:34:16,262 Epoch[12] Batch [420]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.125343,	
2017-07-20 12:34:20,397 Epoch[12] Batch [430]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.125563,	
2017-07-20 12:34:24,359 Epoch[12] Batch [440]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.125734,	
2017-07-20 12:34:28,284 Epoch[12] Batch [450]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.125774,	
2017-07-20 12:34:32,318 Epoch[12] Batch [460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.125448,	
2017-07-20 12:34:36,372 Epoch[12] Batch [470]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.125249,	
2017-07-20 12:34:40,384 Epoch[12] Batch [480]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.124936,	
2017-07-20 12:34:44,355 Epoch[12] Batch [490]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.125036,	
2017-07-20 12:34:48,210 Epoch[12] Batch [500]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.124980,	
2017-07-20 12:34:52,364 Epoch[12] Batch [510]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.124752,	
2017-07-20 12:34:56,584 Epoch[12] Batch [520]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.124516,	
2017-07-20 12:35:00,725 Epoch[12] Batch [530]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.124121,	
2017-07-20 12:35:04,860 Epoch[12] Batch [540]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.124205,	
2017-07-20 12:35:08,953 Epoch[12] Batch [550]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.124343,	
2017-07-20 12:35:13,159 Epoch[12] Batch [560]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.125003,	
2017-07-20 12:35:17,379 Epoch[12] Batch [570]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.125094,	
2017-07-20 12:35:21,570 Epoch[12] Batch [580]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.124930,	
2017-07-20 12:35:25,595 Epoch[12] Batch [590]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125028,	
2017-07-20 12:35:29,645 Epoch[12] Batch [600]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.125104,	
2017-07-20 12:35:33,801 Epoch[12] Batch [610]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.125155,	
2017-07-20 12:35:37,853 Epoch[12] Batch [620]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.125155,	
2017-07-20 12:35:42,255 Epoch[12] Batch [630]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.125208,	
2017-07-20 12:35:46,429 Epoch[12] Batch [640]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.125233,	
2017-07-20 12:35:50,706 Epoch[12] Batch [650]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.125312,	
2017-07-20 12:35:54,928 Epoch[12] Batch [660]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.125402,	
2017-07-20 12:35:59,007 Epoch[12] Batch [670]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.125450,	
2017-07-20 12:36:03,108 Epoch[12] Batch [680]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.125424,	
2017-07-20 12:36:07,108 Epoch[12] Batch [690]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.125426,	
2017-07-20 12:36:11,256 Epoch[12] Batch [700]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.125558,	
2017-07-20 12:36:15,379 Epoch[12] Batch [710]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.125721,	
2017-07-20 12:36:19,536 Epoch[12] Batch [720]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.125720,	
2017-07-20 12:36:23,629 Epoch[12] Batch [730]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.125903,	
2017-07-20 12:36:27,656 Epoch[12] Batch [740]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.125856,	
2017-07-20 12:36:31,845 Epoch[12] Batch [750]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.125947,	
2017-07-20 12:36:36,141 Epoch[12] Batch [760]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.125999,	
2017-07-20 12:36:40,391 Epoch[12] Batch [770]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.126038,	
2017-07-20 12:36:44,652 Epoch[12] Batch [780]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.125968,	
2017-07-20 12:36:48,891 Epoch[12] Batch [790]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.125924,	
2017-07-20 12:36:53,235 Epoch[12] Batch [800]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.125803,	
2017-07-20 12:36:57,261 Epoch[12] Batch [810]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125817,	
2017-07-20 12:37:01,348 Epoch[12] Batch [820]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.125922,	
2017-07-20 12:37:05,465 Epoch[12] Batch [830]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.125825,	
2017-07-20 12:37:09,676 Epoch[12] Batch [840]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.126083,	
2017-07-20 12:37:13,891 Epoch[12] Batch [850]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.126132,	
2017-07-20 12:37:17,890 Epoch[12] Batch [860]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.126035,	
2017-07-20 12:37:21,983 Epoch[12] Batch [870]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.125975,	
2017-07-20 12:37:26,085 Epoch[12] Batch [880]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.126074,	
2017-07-20 12:37:30,192 Epoch[12] Batch [890]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.126021,	
2017-07-20 12:37:34,334 Epoch[12] Batch [900]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.125801,	
2017-07-20 12:37:38,609 Epoch[12] Batch [910]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.125867,	
2017-07-20 12:37:42,808 Epoch[12] Batch [920]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.126112,	
2017-07-20 12:37:47,054 Epoch[12] Batch [930]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.126011,	
2017-07-20 12:37:51,195 Epoch[12] Batch [940]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.126129,	
2017-07-20 12:37:55,247 Epoch[12] Batch [950]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.126028,	
2017-07-20 12:37:59,398 Epoch[12] Batch [960]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.125904,	
2017-07-20 12:38:03,422 Epoch[12] Batch [970]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125922,	
2017-07-20 12:38:07,650 Epoch[12] Batch [980]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.126034,	
2017-07-20 12:38:11,818 Epoch[12] Batch [990]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.126102,	
2017-07-20 12:38:15,942 Epoch[12] Batch [1000]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.126376,	
2017-07-20 12:38:20,158 Epoch[12] Batch [1010]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.126575,	
2017-07-20 12:38:24,230 Epoch[12] Batch [1020]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.126623,	
2017-07-20 12:38:28,262 Epoch[12] Batch [1030]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.126836,	
2017-07-20 12:38:32,503 Epoch[12] Batch [1040]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.126813,	
2017-07-20 12:38:36,622 Epoch[12] Batch [1050]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.126751,	
2017-07-20 12:38:40,773 Epoch[12] Batch [1060]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.126699,	
2017-07-20 12:38:45,054 Epoch[12] Batch [1070]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.126603,	
2017-07-20 12:38:49,224 Epoch[12] Batch [1080]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.126530,	
2017-07-20 12:38:53,455 Epoch[12] Batch [1090]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.126413,	
2017-07-20 12:38:57,575 Epoch[12] Batch [1100]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.126455,	
2017-07-20 12:39:01,711 Epoch[12] Batch [1110]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.126399,	
2017-07-20 12:39:05,925 Epoch[12] Batch [1120]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.126473,	
2017-07-20 12:39:10,136 Epoch[12] Batch [1130]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.126446,	
2017-07-20 12:39:14,224 Epoch[12] Batch [1140]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.126476,	
2017-07-20 12:39:18,426 Epoch[12] Batch [1150]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.126542,	
2017-07-20 12:39:22,572 Epoch[12] Batch [1160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.126652,	
2017-07-20 12:39:26,687 Epoch[12] Batch [1170]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126726,	
2017-07-20 12:39:30,786 Epoch[12] Batch [1180]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.126693,	
2017-07-20 12:39:34,959 Epoch[12] Batch [1190]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.126614,	
2017-07-20 12:39:39,020 Epoch[12] Batch [1200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.126597,	
2017-07-20 12:39:43,094 Epoch[12] Batch [1210]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.126434,	
2017-07-20 12:39:47,150 Epoch[12] Batch [1220]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.126447,	
2017-07-20 12:39:51,359 Epoch[12] Batch [1230]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.126362,	
2017-07-20 12:39:55,437 Epoch[12] Batch [1240]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.126288,	
2017-07-20 12:39:59,386 Epoch[12] Batch [1250]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.126304,	
2017-07-20 12:40:03,567 Epoch[12] Batch [1260]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.126239,	
2017-07-20 12:40:07,470 Epoch[12] Batch [1270]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.126223,	
2017-07-20 12:40:11,496 Epoch[12] Batch [1280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126344,	
2017-07-20 12:40:15,449 Epoch[12] Batch [1290]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.126257,	
2017-07-20 12:40:19,323 Epoch[12] Batch [1300]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.126283,	
2017-07-20 12:40:23,357 Epoch[12] Batch [1310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.126316,	
2017-07-20 12:40:27,488 Epoch[12] Batch [1320]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.126336,	
2017-07-20 12:40:31,436 Epoch[12] Batch [1330]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.126427,	
2017-07-20 12:40:35,316 Epoch[12] Batch [1340]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.126343,	
2017-07-20 12:40:39,275 Epoch[12] Batch [1350]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.126239,	
2017-07-20 12:40:43,301 Epoch[12] Batch [1360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126176,	
2017-07-20 12:40:47,401 Epoch[12] Batch [1370]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.126209,	
2017-07-20 12:40:51,471 Epoch[12] Batch [1380]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.126199,	
2017-07-20 12:40:55,425 Epoch[12] Batch [1390]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.126072,	
2017-07-20 12:40:59,527 Epoch[12] Batch [1400]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.125948,	
2017-07-20 12:41:03,461 Epoch[12] Batch [1410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.125886,	
2017-07-20 12:41:07,423 Epoch[12] Batch [1420]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.125747,	
2017-07-20 12:41:11,418 Epoch[12] Batch [1430]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.125760,	
2017-07-20 12:41:15,345 Epoch[12] Batch [1440]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.125640,	
2017-07-20 12:41:19,372 Epoch[12] Batch [1450]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.125583,	
2017-07-20 12:41:23,261 Epoch[12] Batch [1460]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.125675,	
2017-07-20 12:41:27,263 Epoch[12] Batch [1470]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.125490,	
2017-07-20 12:41:31,149 Epoch[12] Batch [1480]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.125547,	
2017-07-20 12:41:33,515 Epoch[12] Train-FCNLogLoss=0.125599
2017-07-20 12:41:33,516 Epoch[12] Time cost=607.299
2017-07-20 12:41:34,341 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0013.params"
2017-07-20 12:41:35,914 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0013.states"
2017-07-20 12:41:40,816 Epoch[13] Batch [10]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.119862,	
2017-07-20 12:41:44,899 Epoch[13] Batch [20]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118078,	
2017-07-20 12:41:48,856 Epoch[13] Batch [30]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.121830,	
2017-07-20 12:41:52,839 Epoch[13] Batch [40]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.122050,	
2017-07-20 12:41:56,789 Epoch[13] Batch [50]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.122044,	
2017-07-20 12:42:00,784 Epoch[13] Batch [60]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.120279,	
2017-07-20 12:42:04,607 Epoch[13] Batch [70]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.120057,	
2017-07-20 12:42:08,593 Epoch[13] Batch [80]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.121469,	
2017-07-20 12:42:12,739 Epoch[13] Batch [90]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.120546,	
2017-07-20 12:42:16,702 Epoch[13] Batch [100]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.120607,	
2017-07-20 12:42:20,623 Epoch[13] Batch [110]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.119073,	
2017-07-20 12:42:24,573 Epoch[13] Batch [120]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.119795,	
2017-07-20 12:42:28,567 Epoch[13] Batch [130]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.119608,	
2017-07-20 12:42:32,664 Epoch[13] Batch [140]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.119526,	
2017-07-20 12:42:36,829 Epoch[13] Batch [150]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.119186,	
2017-07-20 12:42:40,884 Epoch[13] Batch [160]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.119098,	
2017-07-20 12:42:44,969 Epoch[13] Batch [170]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.120366,	
2017-07-20 12:42:49,033 Epoch[13] Batch [180]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.120786,	
2017-07-20 12:42:53,119 Epoch[13] Batch [190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.121506,	
2017-07-20 12:42:57,033 Epoch[13] Batch [200]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.121392,	
2017-07-20 12:43:01,044 Epoch[13] Batch [210]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.120707,	
2017-07-20 12:43:04,957 Epoch[13] Batch [220]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.120524,	
2017-07-20 12:43:09,049 Epoch[13] Batch [230]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.120449,	
2017-07-20 12:43:13,014 Epoch[13] Batch [240]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.120149,	
2017-07-20 12:43:16,945 Epoch[13] Batch [250]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.120048,	
2017-07-20 12:43:20,917 Epoch[13] Batch [260]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.119812,	
2017-07-20 12:43:24,861 Epoch[13] Batch [270]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.119660,	
2017-07-20 12:43:28,885 Epoch[13] Batch [280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.120296,	
2017-07-20 12:43:32,791 Epoch[13] Batch [290]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.120683,	
2017-07-20 12:43:36,850 Epoch[13] Batch [300]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.121535,	
2017-07-20 12:43:40,875 Epoch[13] Batch [310]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.122423,	
2017-07-20 12:43:44,939 Epoch[13] Batch [320]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.123400,	
2017-07-20 12:43:49,034 Epoch[13] Batch [330]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.123215,	
2017-07-20 12:43:53,098 Epoch[13] Batch [340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.122791,	
2017-07-20 12:43:56,999 Epoch[13] Batch [350]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.122300,	
2017-07-20 12:44:01,015 Epoch[13] Batch [360]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.122516,	
2017-07-20 12:44:05,020 Epoch[13] Batch [370]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.122369,	
2017-07-20 12:44:09,027 Epoch[13] Batch [380]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.122268,	
2017-07-20 12:44:12,964 Epoch[13] Batch [390]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.122449,	
2017-07-20 12:44:16,933 Epoch[13] Batch [400]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.122108,	
2017-07-20 12:44:20,876 Epoch[13] Batch [410]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.121907,	
2017-07-20 12:44:24,773 Epoch[13] Batch [420]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.122043,	
2017-07-20 12:44:28,741 Epoch[13] Batch [430]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.121762,	
2017-07-20 12:44:32,849 Epoch[13] Batch [440]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.121749,	
2017-07-20 12:44:36,780 Epoch[13] Batch [450]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.121616,	
2017-07-20 12:44:40,719 Epoch[13] Batch [460]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.121690,	
2017-07-20 12:44:44,836 Epoch[13] Batch [470]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.121968,	
2017-07-20 12:44:48,764 Epoch[13] Batch [480]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.121852,	
2017-07-20 12:44:52,807 Epoch[13] Batch [490]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.121709,	
2017-07-20 12:44:56,698 Epoch[13] Batch [500]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.121644,	
2017-07-20 12:45:00,539 Epoch[13] Batch [510]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.121492,	
2017-07-20 12:45:04,609 Epoch[13] Batch [520]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.121401,	
2017-07-20 12:45:08,679 Epoch[13] Batch [530]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.121560,	
2017-07-20 12:45:12,672 Epoch[13] Batch [540]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.121501,	
2017-07-20 12:45:16,628 Epoch[13] Batch [550]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.121086,	
2017-07-20 12:45:20,760 Epoch[13] Batch [560]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.121257,	
2017-07-20 12:45:24,804 Epoch[13] Batch [570]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.121213,	
2017-07-20 12:45:28,749 Epoch[13] Batch [580]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.121030,	
2017-07-20 12:45:32,705 Epoch[13] Batch [590]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.120912,	
2017-07-20 12:45:36,891 Epoch[13] Batch [600]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.120846,	
2017-07-20 12:45:40,920 Epoch[13] Batch [610]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.120505,	
2017-07-20 12:45:45,069 Epoch[13] Batch [620]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.120310,	
2017-07-20 12:45:49,354 Epoch[13] Batch [630]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.120244,	
2017-07-20 12:45:53,476 Epoch[13] Batch [640]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.120439,	
2017-07-20 12:45:57,619 Epoch[13] Batch [650]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.120207,	
2017-07-20 12:46:01,786 Epoch[13] Batch [660]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.120031,	
2017-07-20 12:46:06,011 Epoch[13] Batch [670]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.120122,	
2017-07-20 12:46:10,119 Epoch[13] Batch [680]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.120095,	
2017-07-20 12:46:14,268 Epoch[13] Batch [690]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.120141,	
2017-07-20 12:46:18,380 Epoch[13] Batch [700]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.120011,	
2017-07-20 12:46:22,588 Epoch[13] Batch [710]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.120028,	
2017-07-20 12:46:26,839 Epoch[13] Batch [720]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.119981,	
2017-07-20 12:46:30,990 Epoch[13] Batch [730]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.119747,	
2017-07-20 12:46:35,116 Epoch[13] Batch [740]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.119602,	
2017-07-20 12:46:39,270 Epoch[13] Batch [750]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.119624,	
2017-07-20 12:46:43,492 Epoch[13] Batch [760]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.119577,	
2017-07-20 12:46:47,482 Epoch[13] Batch [770]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119578,	
2017-07-20 12:46:51,675 Epoch[13] Batch [780]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.119456,	
2017-07-20 12:46:55,783 Epoch[13] Batch [790]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119373,	
2017-07-20 12:47:00,025 Epoch[13] Batch [800]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.119335,	
2017-07-20 12:47:04,076 Epoch[13] Batch [810]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.119284,	
2017-07-20 12:47:08,150 Epoch[13] Batch [820]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.119231,	
2017-07-20 12:47:12,266 Epoch[13] Batch [830]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.119321,	
2017-07-20 12:47:16,381 Epoch[13] Batch [840]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.119133,	
2017-07-20 12:47:20,537 Epoch[13] Batch [850]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.119266,	
2017-07-20 12:47:24,615 Epoch[13] Batch [860]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.119097,	
2017-07-20 12:47:28,797 Epoch[13] Batch [870]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.119065,	
2017-07-20 12:47:32,980 Epoch[13] Batch [880]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.119079,	
2017-07-20 12:47:37,152 Epoch[13] Batch [890]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.119059,	
2017-07-20 12:47:41,270 Epoch[13] Batch [900]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.119103,	
2017-07-20 12:47:45,318 Epoch[13] Batch [910]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.118985,	
2017-07-20 12:47:49,454 Epoch[13] Batch [920]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.119114,	
2017-07-20 12:47:53,519 Epoch[13] Batch [930]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.119174,	
2017-07-20 12:47:57,653 Epoch[13] Batch [940]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.119136,	
2017-07-20 12:48:01,956 Epoch[13] Batch [950]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.119214,	
2017-07-20 12:48:06,220 Epoch[13] Batch [960]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.119216,	
2017-07-20 12:48:10,387 Epoch[13] Batch [970]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.119217,	
2017-07-20 12:48:14,665 Epoch[13] Batch [980]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.119086,	
2017-07-20 12:48:18,856 Epoch[13] Batch [990]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.119140,	
2017-07-20 12:48:23,024 Epoch[13] Batch [1000]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.118980,	
2017-07-20 12:48:27,125 Epoch[13] Batch [1010]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.118853,	
2017-07-20 12:48:31,048 Epoch[13] Batch [1020]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118939,	
2017-07-20 12:48:35,298 Epoch[13] Batch [1030]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.118904,	
2017-07-20 12:48:39,319 Epoch[13] Batch [1040]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.118963,	
2017-07-20 12:48:43,380 Epoch[13] Batch [1050]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.119017,	
2017-07-20 12:48:47,520 Epoch[13] Batch [1060]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.119003,	
2017-07-20 12:48:51,685 Epoch[13] Batch [1070]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.118861,	
2017-07-20 12:48:55,915 Epoch[13] Batch [1080]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.118829,	
2017-07-20 12:49:00,001 Epoch[13] Batch [1090]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.118804,	
2017-07-20 12:49:04,239 Epoch[13] Batch [1100]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.118728,	
2017-07-20 12:49:08,337 Epoch[13] Batch [1110]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118738,	
2017-07-20 12:49:12,502 Epoch[13] Batch [1120]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.118606,	
2017-07-20 12:49:16,500 Epoch[13] Batch [1130]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118451,	
2017-07-20 12:49:20,614 Epoch[13] Batch [1140]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.118606,	
2017-07-20 12:49:24,655 Epoch[13] Batch [1150]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118602,	
2017-07-20 12:49:28,921 Epoch[13] Batch [1160]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.118601,	
2017-07-20 12:49:33,073 Epoch[13] Batch [1170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.118576,	
2017-07-20 12:49:37,164 Epoch[13] Batch [1180]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.118698,	
2017-07-20 12:49:41,413 Epoch[13] Batch [1190]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.118673,	
2017-07-20 12:49:45,585 Epoch[13] Batch [1200]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.118811,	
2017-07-20 12:49:49,686 Epoch[13] Batch [1210]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.119041,	
2017-07-20 12:49:53,835 Epoch[13] Batch [1220]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.119340,	
2017-07-20 12:49:57,841 Epoch[13] Batch [1230]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119408,	
2017-07-20 12:50:02,061 Epoch[13] Batch [1240]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.119498,	
2017-07-20 12:50:06,263 Epoch[13] Batch [1250]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.119457,	
2017-07-20 12:50:10,420 Epoch[13] Batch [1260]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.119442,	
2017-07-20 12:50:14,524 Epoch[13] Batch [1270]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.119576,	
2017-07-20 12:50:18,661 Epoch[13] Batch [1280]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.119748,	
2017-07-20 12:50:22,995 Epoch[13] Batch [1290]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.119755,	
2017-07-20 12:50:27,105 Epoch[13] Batch [1300]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.119949,	
2017-07-20 12:50:31,122 Epoch[13] Batch [1310]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.120038,	
2017-07-20 12:50:35,210 Epoch[13] Batch [1320]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.120111,	
2017-07-20 12:50:39,252 Epoch[13] Batch [1330]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.120108,	
2017-07-20 12:50:43,307 Epoch[13] Batch [1340]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.120168,	
2017-07-20 12:50:47,445 Epoch[13] Batch [1350]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.120299,	
2017-07-20 12:50:51,470 Epoch[13] Batch [1360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.120252,	
2017-07-20 12:50:55,427 Epoch[13] Batch [1370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.120230,	
2017-07-20 12:50:59,471 Epoch[13] Batch [1380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.120317,	
2017-07-20 12:51:03,457 Epoch[13] Batch [1390]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.120379,	
2017-07-20 12:51:07,416 Epoch[13] Batch [1400]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.120306,	
2017-07-20 12:51:11,489 Epoch[13] Batch [1410]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.120272,	
2017-07-20 12:51:15,559 Epoch[13] Batch [1420]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.120246,	
2017-07-20 12:51:19,623 Epoch[13] Batch [1430]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.120286,	
2017-07-20 12:51:23,548 Epoch[13] Batch [1440]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.120189,	
2017-07-20 12:51:27,660 Epoch[13] Batch [1450]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.120246,	
2017-07-20 12:51:31,688 Epoch[13] Batch [1460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.120238,	
2017-07-20 12:51:35,625 Epoch[13] Batch [1470]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.120181,	
2017-07-20 12:51:39,685 Epoch[13] Batch [1480]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.120172,	
2017-07-20 12:51:42,110 Epoch[13] Train-FCNLogLoss=0.120124
2017-07-20 12:51:42,110 Epoch[13] Time cost=606.195
2017-07-20 12:51:42,882 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0014.params"
2017-07-20 12:51:44,381 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0014.states"
2017-07-20 12:51:49,089 Epoch[14] Batch [10]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.120136,	
2017-07-20 12:51:53,006 Epoch[14] Batch [20]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.113443,	
2017-07-20 12:51:57,028 Epoch[14] Batch [30]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.111983,	
2017-07-20 12:52:00,997 Epoch[14] Batch [40]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.110026,	
2017-07-20 12:52:05,019 Epoch[14] Batch [50]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111691,	
2017-07-20 12:52:08,964 Epoch[14] Batch [60]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.110765,	
2017-07-20 12:52:13,006 Epoch[14] Batch [70]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112699,	
2017-07-20 12:52:16,926 Epoch[14] Batch [80]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112656,	
2017-07-20 12:52:20,848 Epoch[14] Batch [90]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112191,	
2017-07-20 12:52:24,906 Epoch[14] Batch [100]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113638,	
2017-07-20 12:52:29,090 Epoch[14] Batch [110]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.114167,	
2017-07-20 12:52:33,092 Epoch[14] Batch [120]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.114952,	
2017-07-20 12:52:37,077 Epoch[14] Batch [130]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.114461,	
2017-07-20 12:52:41,019 Epoch[14] Batch [140]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.114311,	
2017-07-20 12:52:45,013 Epoch[14] Batch [150]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.115666,	
2017-07-20 12:52:49,048 Epoch[14] Batch [160]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.115957,	
2017-07-20 12:52:53,074 Epoch[14] Batch [170]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116015,	
2017-07-20 12:52:57,211 Epoch[14] Batch [180]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.116065,	
2017-07-20 12:53:01,120 Epoch[14] Batch [190]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.115438,	
2017-07-20 12:53:05,241 Epoch[14] Batch [200]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.115278,	
2017-07-20 12:53:09,306 Epoch[14] Batch [210]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115053,	
2017-07-20 12:53:13,268 Epoch[14] Batch [220]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.115350,	
2017-07-20 12:53:17,222 Epoch[14] Batch [230]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.115179,	
2017-07-20 12:53:21,263 Epoch[14] Batch [240]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114967,	
2017-07-20 12:53:25,291 Epoch[14] Batch [250]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.114891,	
2017-07-20 12:53:29,254 Epoch[14] Batch [260]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.115012,	
2017-07-20 12:53:33,182 Epoch[14] Batch [270]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.115181,	
2017-07-20 12:53:37,193 Epoch[14] Batch [280]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.115412,	
2017-07-20 12:53:41,234 Epoch[14] Batch [290]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115572,	
2017-07-20 12:53:45,159 Epoch[14] Batch [300]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.115458,	
2017-07-20 12:53:49,147 Epoch[14] Batch [310]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.115790,	
2017-07-20 12:53:53,025 Epoch[14] Batch [320]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.115948,	
2017-07-20 12:53:57,102 Epoch[14] Batch [330]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115867,	
2017-07-20 12:54:01,156 Epoch[14] Batch [340]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.115972,	
2017-07-20 12:54:05,018 Epoch[14] Batch [350]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.116073,	
2017-07-20 12:54:08,980 Epoch[14] Batch [360]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.116305,	
2017-07-20 12:54:12,829 Epoch[14] Batch [370]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.116322,	
2017-07-20 12:54:16,865 Epoch[14] Batch [380]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116163,	
2017-07-20 12:54:20,935 Epoch[14] Batch [390]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116362,	
2017-07-20 12:54:25,001 Epoch[14] Batch [400]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116275,	
2017-07-20 12:54:28,987 Epoch[14] Batch [410]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116434,	
2017-07-20 12:54:32,895 Epoch[14] Batch [420]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.116910,	
2017-07-20 12:54:36,826 Epoch[14] Batch [430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116967,	
2017-07-20 12:54:40,899 Epoch[14] Batch [440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117570,	
2017-07-20 12:54:44,928 Epoch[14] Batch [450]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117813,	
2017-07-20 12:54:48,829 Epoch[14] Batch [460]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117731,	
2017-07-20 12:54:52,726 Epoch[14] Batch [470]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117678,	
2017-07-20 12:54:56,739 Epoch[14] Batch [480]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.117774,	
2017-07-20 12:55:00,772 Epoch[14] Batch [490]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.118429,	
2017-07-20 12:55:04,779 Epoch[14] Batch [500]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.118856,	
2017-07-20 12:55:08,575 Epoch[14] Batch [510]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.118882,	
2017-07-20 12:55:12,572 Epoch[14] Batch [520]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118806,	
2017-07-20 12:55:16,641 Epoch[14] Batch [530]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.119060,	
2017-07-20 12:55:20,592 Epoch[14] Batch [540]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.119148,	
2017-07-20 12:55:24,570 Epoch[14] Batch [550]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.119043,	
2017-07-20 12:55:28,686 Epoch[14] Batch [560]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.118997,	
2017-07-20 12:55:32,680 Epoch[14] Batch [570]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118782,	
2017-07-20 12:55:36,786 Epoch[14] Batch [580]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.118566,	
2017-07-20 12:55:40,645 Epoch[14] Batch [590]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.118529,	
2017-07-20 12:55:44,714 Epoch[14] Batch [600]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.118420,	
2017-07-20 12:55:48,743 Epoch[14] Batch [610]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118310,	
2017-07-20 12:55:52,712 Epoch[14] Batch [620]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118208,	
2017-07-20 12:55:56,765 Epoch[14] Batch [630]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118049,	
2017-07-20 12:56:00,667 Epoch[14] Batch [640]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.118147,	
2017-07-20 12:56:04,755 Epoch[14] Batch [650]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.118084,	
2017-07-20 12:56:08,756 Epoch[14] Batch [660]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.118030,	
2017-07-20 12:56:12,858 Epoch[14] Batch [670]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.117918,	
2017-07-20 12:56:17,156 Epoch[14] Batch [680]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.117615,	
2017-07-20 12:56:21,240 Epoch[14] Batch [690]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117503,	
2017-07-20 12:56:25,271 Epoch[14] Batch [700]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.117615,	
2017-07-20 12:56:29,460 Epoch[14] Batch [710]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.117470,	
2017-07-20 12:56:33,637 Epoch[14] Batch [720]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117526,	
2017-07-20 12:56:37,654 Epoch[14] Batch [730]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117498,	
2017-07-20 12:56:41,764 Epoch[14] Batch [740]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117658,	
2017-07-20 12:56:45,866 Epoch[14] Batch [750]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.117619,	
2017-07-20 12:56:50,063 Epoch[14] Batch [760]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.117756,	
2017-07-20 12:56:54,298 Epoch[14] Batch [770]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.117598,	
2017-07-20 12:56:58,365 Epoch[14] Batch [780]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117453,	
2017-07-20 12:57:02,545 Epoch[14] Batch [790]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.117415,	
2017-07-20 12:57:06,643 Epoch[14] Batch [800]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117213,	
2017-07-20 12:57:10,756 Epoch[14] Batch [810]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.117117,	
2017-07-20 12:57:14,844 Epoch[14] Batch [820]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116996,	
2017-07-20 12:57:19,008 Epoch[14] Batch [830]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.117095,	
2017-07-20 12:57:23,279 Epoch[14] Batch [840]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.117245,	
2017-07-20 12:57:27,411 Epoch[14] Batch [850]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.117192,	
2017-07-20 12:57:31,454 Epoch[14] Batch [860]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117258,	
2017-07-20 12:57:35,519 Epoch[14] Batch [870]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117451,	
2017-07-20 12:57:39,695 Epoch[14] Batch [880]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117515,	
2017-07-20 12:57:43,889 Epoch[14] Batch [890]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.117573,	
2017-07-20 12:57:48,186 Epoch[14] Batch [900]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.117376,	
2017-07-20 12:57:52,466 Epoch[14] Batch [910]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.117501,	
2017-07-20 12:57:56,594 Epoch[14] Batch [920]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117469,	
2017-07-20 12:58:00,710 Epoch[14] Batch [930]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117435,	
2017-07-20 12:58:04,768 Epoch[14] Batch [940]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.117427,	
2017-07-20 12:58:08,971 Epoch[14] Batch [950]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.117510,	
2017-07-20 12:58:13,112 Epoch[14] Batch [960]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.117462,	
2017-07-20 12:58:17,136 Epoch[14] Batch [970]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117577,	
2017-07-20 12:58:21,462 Epoch[14] Batch [980]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.117458,	
2017-07-20 12:58:25,588 Epoch[14] Batch [990]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117412,	
2017-07-20 12:58:29,697 Epoch[14] Batch [1000]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117293,	
2017-07-20 12:58:33,890 Epoch[14] Batch [1010]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.117339,	
2017-07-20 12:58:38,048 Epoch[14] Batch [1020]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.117475,	
2017-07-20 12:58:42,244 Epoch[14] Batch [1030]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.117347,	
2017-07-20 12:58:46,341 Epoch[14] Batch [1040]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117264,	
2017-07-20 12:58:50,562 Epoch[14] Batch [1050]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.117259,	
2017-07-20 12:58:54,626 Epoch[14] Batch [1060]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117407,	
2017-07-20 12:58:58,719 Epoch[14] Batch [1070]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117449,	
2017-07-20 12:59:03,008 Epoch[14] Batch [1080]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.117476,	
2017-07-20 12:59:07,185 Epoch[14] Batch [1090]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117461,	
2017-07-20 12:59:11,302 Epoch[14] Batch [1100]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117305,	
2017-07-20 12:59:15,634 Epoch[14] Batch [1110]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.117206,	
2017-07-20 12:59:19,733 Epoch[14] Batch [1120]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117303,	
2017-07-20 12:59:23,800 Epoch[14] Batch [1130]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117278,	
2017-07-20 12:59:27,856 Epoch[14] Batch [1140]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.117286,	
2017-07-20 12:59:32,296 Epoch[14] Batch [1150]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.117327,	
2017-07-20 12:59:36,491 Epoch[14] Batch [1160]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.117545,	
2017-07-20 12:59:40,611 Epoch[14] Batch [1170]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117545,	
2017-07-20 12:59:44,820 Epoch[14] Batch [1180]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.117465,	
2017-07-20 12:59:49,054 Epoch[14] Batch [1190]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.117508,	
2017-07-20 12:59:53,268 Epoch[14] Batch [1200]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.117512,	
2017-07-20 12:59:57,552 Epoch[14] Batch [1210]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.117398,	
2017-07-20 13:00:01,725 Epoch[14] Batch [1220]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.117478,	
2017-07-20 13:00:05,792 Epoch[14] Batch [1230]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117537,	
2017-07-20 13:00:09,850 Epoch[14] Batch [1240]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.117543,	
2017-07-20 13:00:13,987 Epoch[14] Batch [1250]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.117429,	
2017-07-20 13:00:18,081 Epoch[14] Batch [1260]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117392,	
2017-07-20 13:00:22,359 Epoch[14] Batch [1270]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.117353,	
2017-07-20 13:00:26,360 Epoch[14] Batch [1280]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.117435,	
2017-07-20 13:00:30,697 Epoch[14] Batch [1290]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.117377,	
2017-07-20 13:00:34,878 Epoch[14] Batch [1300]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.117424,	
2017-07-20 13:00:39,111 Epoch[14] Batch [1310]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.117410,	
2017-07-20 13:00:43,286 Epoch[14] Batch [1320]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117418,	
2017-07-20 13:00:47,471 Epoch[14] Batch [1330]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.117467,	
2017-07-20 13:00:51,498 Epoch[14] Batch [1340]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117500,	
2017-07-20 13:00:55,591 Epoch[14] Batch [1350]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117495,	
2017-07-20 13:00:59,939 Epoch[14] Batch [1360]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.117499,	
2017-07-20 13:01:04,040 Epoch[14] Batch [1370]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117518,	
2017-07-20 13:01:08,267 Epoch[14] Batch [1380]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117459,	
2017-07-20 13:01:12,449 Epoch[14] Batch [1390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.117419,	
2017-07-20 13:01:16,464 Epoch[14] Batch [1400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117336,	
2017-07-20 13:01:20,669 Epoch[14] Batch [1410]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.117438,	
2017-07-20 13:01:24,708 Epoch[14] Batch [1420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117361,	
2017-07-20 13:01:28,748 Epoch[14] Batch [1430]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117352,	
2017-07-20 13:01:32,799 Epoch[14] Batch [1440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.117316,	
2017-07-20 13:01:36,794 Epoch[14] Batch [1450]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117243,	
2017-07-20 13:01:40,829 Epoch[14] Batch [1460]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117266,	
2017-07-20 13:01:44,925 Epoch[14] Batch [1470]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117260,	
2017-07-20 13:01:49,012 Epoch[14] Batch [1480]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117284,	
2017-07-20 13:01:51,536 Epoch[14] Train-FCNLogLoss=0.117335
2017-07-20 13:01:51,536 Epoch[14] Time cost=607.155
2017-07-20 13:01:52,383 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0015.params"
2017-07-20 13:01:53,996 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0015.states"
2017-07-20 13:01:58,956 Epoch[15] Batch [10]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.110541,	
2017-07-20 13:02:02,862 Epoch[15] Batch [20]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.120046,	
2017-07-20 13:02:07,032 Epoch[15] Batch [30]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.120356,	
2017-07-20 13:02:11,137 Epoch[15] Batch [40]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.121533,	
2017-07-20 13:02:15,159 Epoch[15] Batch [50]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.121329,	
2017-07-20 13:02:19,200 Epoch[15] Batch [60]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.116550,	
2017-07-20 13:02:23,239 Epoch[15] Batch [70]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116820,	
2017-07-20 13:02:27,281 Epoch[15] Batch [80]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118452,	
2017-07-20 13:02:31,276 Epoch[15] Batch [90]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.119909,	
2017-07-20 13:02:35,212 Epoch[15] Batch [100]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.119823,	
2017-07-20 13:02:39,330 Epoch[15] Batch [110]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.119743,	
2017-07-20 13:02:43,347 Epoch[15] Batch [120]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.118780,	
2017-07-20 13:02:47,406 Epoch[15] Batch [130]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.118055,	
2017-07-20 13:02:51,417 Epoch[15] Batch [140]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.117577,	
2017-07-20 13:02:55,496 Epoch[15] Batch [150]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117653,	
2017-07-20 13:02:59,384 Epoch[15] Batch [160]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.118356,	
2017-07-20 13:03:03,322 Epoch[15] Batch [170]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.118434,	
2017-07-20 13:03:07,227 Epoch[15] Batch [180]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.118357,	
2017-07-20 13:03:11,225 Epoch[15] Batch [190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118287,	
2017-07-20 13:03:15,310 Epoch[15] Batch [200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.118187,	
2017-07-20 13:03:19,366 Epoch[15] Batch [210]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.118108,	
2017-07-20 13:03:23,427 Epoch[15] Batch [220]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117929,	
2017-07-20 13:03:27,500 Epoch[15] Batch [230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117804,	
2017-07-20 13:03:31,485 Epoch[15] Batch [240]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.117520,	
2017-07-20 13:03:35,432 Epoch[15] Batch [250]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.116750,	
2017-07-20 13:03:39,386 Epoch[15] Batch [260]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.116769,	
2017-07-20 13:03:43,440 Epoch[15] Batch [270]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.117305,	
2017-07-20 13:03:47,496 Epoch[15] Batch [280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.117193,	
2017-07-20 13:03:51,610 Epoch[15] Batch [290]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117454,	
2017-07-20 13:03:55,798 Epoch[15] Batch [300]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.117876,	
2017-07-20 13:03:59,901 Epoch[15] Batch [310]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.117436,	
2017-07-20 13:04:04,045 Epoch[15] Batch [320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.117352,	
2017-07-20 13:04:08,162 Epoch[15] Batch [330]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117111,	
2017-07-20 13:04:12,286 Epoch[15] Batch [340]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117585,	
2017-07-20 13:04:16,393 Epoch[15] Batch [350]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117092,	
2017-07-20 13:04:20,537 Epoch[15] Batch [360]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.117135,	
2017-07-20 13:04:24,743 Epoch[15] Batch [370]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.117405,	
2017-07-20 13:04:28,827 Epoch[15] Batch [380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117471,	
2017-07-20 13:04:32,942 Epoch[15] Batch [390]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117272,	
2017-07-20 13:04:37,060 Epoch[15] Batch [400]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117778,	
2017-07-20 13:04:41,161 Epoch[15] Batch [410]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117548,	
2017-07-20 13:04:45,409 Epoch[15] Batch [420]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.117404,	
2017-07-20 13:04:49,551 Epoch[15] Batch [430]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.117342,	
2017-07-20 13:04:53,598 Epoch[15] Batch [440]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117407,	
2017-07-20 13:04:57,801 Epoch[15] Batch [450]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.117363,	
2017-07-20 13:05:01,817 Epoch[15] Batch [460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117395,	
2017-07-20 13:05:06,044 Epoch[15] Batch [470]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117377,	
2017-07-20 13:05:10,107 Epoch[15] Batch [480]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117462,	
2017-07-20 13:05:14,334 Epoch[15] Batch [490]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117328,	
2017-07-20 13:05:18,377 Epoch[15] Batch [500]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117197,	
2017-07-20 13:05:22,370 Epoch[15] Batch [510]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.116987,	
2017-07-20 13:05:26,458 Epoch[15] Batch [520]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117474,	
2017-07-20 13:05:30,628 Epoch[15] Batch [530]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.117433,	
2017-07-20 13:05:34,708 Epoch[15] Batch [540]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117456,	
2017-07-20 13:05:38,814 Epoch[15] Batch [550]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117413,	
2017-07-20 13:05:42,914 Epoch[15] Batch [560]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117498,	
2017-07-20 13:05:46,993 Epoch[15] Batch [570]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117252,	
2017-07-20 13:05:51,038 Epoch[15] Batch [580]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117018,	
2017-07-20 13:05:55,188 Epoch[15] Batch [590]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.117023,	
2017-07-20 13:05:59,287 Epoch[15] Batch [600]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117311,	
2017-07-20 13:06:03,312 Epoch[15] Batch [610]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117363,	
2017-07-20 13:06:07,378 Epoch[15] Batch [620]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117252,	
2017-07-20 13:06:11,543 Epoch[15] Batch [630]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.117149,	
2017-07-20 13:06:15,803 Epoch[15] Batch [640]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.117272,	
2017-07-20 13:06:19,847 Epoch[15] Batch [650]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117219,	
2017-07-20 13:06:24,024 Epoch[15] Batch [660]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117185,	
2017-07-20 13:06:28,138 Epoch[15] Batch [670]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117202,	
2017-07-20 13:06:32,287 Epoch[15] Batch [680]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.117227,	
2017-07-20 13:06:36,401 Epoch[15] Batch [690]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117287,	
2017-07-20 13:06:40,469 Epoch[15] Batch [700]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117460,	
2017-07-20 13:06:44,586 Epoch[15] Batch [710]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117399,	
2017-07-20 13:06:48,693 Epoch[15] Batch [720]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117349,	
2017-07-20 13:06:52,686 Epoch[15] Batch [730]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.117257,	
2017-07-20 13:06:56,693 Epoch[15] Batch [740]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.117186,	
2017-07-20 13:07:00,721 Epoch[15] Batch [750]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117179,	
2017-07-20 13:07:04,889 Epoch[15] Batch [760]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.117164,	
2017-07-20 13:07:09,104 Epoch[15] Batch [770]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.117163,	
2017-07-20 13:07:13,333 Epoch[15] Batch [780]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117274,	
2017-07-20 13:07:17,415 Epoch[15] Batch [790]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117249,	
2017-07-20 13:07:21,667 Epoch[15] Batch [800]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.117114,	
2017-07-20 13:07:25,748 Epoch[15] Batch [810]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117018,	
2017-07-20 13:07:30,016 Epoch[15] Batch [820]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.117045,	
2017-07-20 13:07:34,198 Epoch[15] Batch [830]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.116923,	
2017-07-20 13:07:38,567 Epoch[15] Batch [840]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.116916,	
2017-07-20 13:07:42,687 Epoch[15] Batch [850]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117088,	
2017-07-20 13:07:47,013 Epoch[15] Batch [860]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.117066,	
2017-07-20 13:07:51,111 Epoch[15] Batch [870]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116948,	
2017-07-20 13:07:55,352 Epoch[15] Batch [880]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.116894,	
2017-07-20 13:07:59,493 Epoch[15] Batch [890]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116883,	
2017-07-20 13:08:03,602 Epoch[15] Batch [900]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116852,	
2017-07-20 13:08:07,766 Epoch[15] Batch [910]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.116934,	
2017-07-20 13:08:11,908 Epoch[15] Batch [920]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116997,	
2017-07-20 13:08:16,029 Epoch[15] Batch [930]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.116913,	
2017-07-20 13:08:20,275 Epoch[15] Batch [940]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.116890,	
2017-07-20 13:08:24,449 Epoch[15] Batch [950]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.116850,	
2017-07-20 13:08:28,668 Epoch[15] Batch [960]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.116790,	
2017-07-20 13:08:32,902 Epoch[15] Batch [970]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.116709,	
2017-07-20 13:08:37,125 Epoch[15] Batch [980]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.116710,	
2017-07-20 13:08:41,291 Epoch[15] Batch [990]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.116734,	
2017-07-20 13:08:45,465 Epoch[15] Batch [1000]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116732,	
2017-07-20 13:08:49,669 Epoch[15] Batch [1010]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.116717,	
2017-07-20 13:08:53,939 Epoch[15] Batch [1020]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.116744,	
2017-07-20 13:08:58,329 Epoch[15] Batch [1030]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.116730,	
2017-07-20 13:09:02,424 Epoch[15] Batch [1040]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116712,	
2017-07-20 13:09:06,679 Epoch[15] Batch [1050]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.116710,	
2017-07-20 13:09:10,928 Epoch[15] Batch [1060]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.116766,	
2017-07-20 13:09:15,125 Epoch[15] Batch [1070]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.116705,	
2017-07-20 13:09:19,358 Epoch[15] Batch [1080]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.116791,	
2017-07-20 13:09:23,630 Epoch[15] Batch [1090]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.116827,	
2017-07-20 13:09:27,850 Epoch[15] Batch [1100]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.116730,	
2017-07-20 13:09:32,126 Epoch[15] Batch [1110]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.116682,	
2017-07-20 13:09:36,292 Epoch[15] Batch [1120]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.116567,	
2017-07-20 13:09:40,635 Epoch[15] Batch [1130]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.116636,	
2017-07-20 13:09:44,830 Epoch[15] Batch [1140]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.116863,	
2017-07-20 13:09:49,072 Epoch[15] Batch [1150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.116800,	
2017-07-20 13:09:53,274 Epoch[15] Batch [1160]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.116933,	
2017-07-20 13:09:57,584 Epoch[15] Batch [1170]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.117141,	
2017-07-20 13:10:01,798 Epoch[15] Batch [1180]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.117150,	
2017-07-20 13:10:06,201 Epoch[15] Batch [1190]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.117084,	
2017-07-20 13:10:10,483 Epoch[15] Batch [1200]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.117074,	
2017-07-20 13:10:14,604 Epoch[15] Batch [1210]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117026,	
2017-07-20 13:10:18,850 Epoch[15] Batch [1220]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.117062,	
2017-07-20 13:10:23,054 Epoch[15] Batch [1230]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.117150,	
2017-07-20 13:10:27,229 Epoch[15] Batch [1240]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117136,	
2017-07-20 13:10:31,493 Epoch[15] Batch [1250]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.117287,	
2017-07-20 13:10:35,753 Epoch[15] Batch [1260]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.117326,	
2017-07-20 13:10:40,039 Epoch[15] Batch [1270]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.117313,	
2017-07-20 13:10:44,107 Epoch[15] Batch [1280]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117261,	
2017-07-20 13:10:48,299 Epoch[15] Batch [1290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.117296,	
2017-07-20 13:10:52,659 Epoch[15] Batch [1300]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.117128,	
2017-07-20 13:10:56,768 Epoch[15] Batch [1310]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.117175,	
2017-07-20 13:11:00,991 Epoch[15] Batch [1320]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.117127,	
2017-07-20 13:11:05,234 Epoch[15] Batch [1330]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.117083,	
2017-07-20 13:11:09,502 Epoch[15] Batch [1340]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.117112,	
2017-07-20 13:11:13,856 Epoch[15] Batch [1350]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.117094,	
2017-07-20 13:11:18,084 Epoch[15] Batch [1360]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117037,	
2017-07-20 13:11:22,302 Epoch[15] Batch [1370]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.117066,	
2017-07-20 13:11:26,588 Epoch[15] Batch [1380]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.117050,	
2017-07-20 13:11:30,818 Epoch[15] Batch [1390]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.116953,	
2017-07-20 13:11:35,058 Epoch[15] Batch [1400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.116886,	
2017-07-20 13:11:39,276 Epoch[15] Batch [1410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.116948,	
2017-07-20 13:11:43,787 Epoch[15] Batch [1420]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116883,	
2017-07-20 13:11:47,998 Epoch[15] Batch [1430]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.117034,	
2017-07-20 13:11:52,114 Epoch[15] Batch [1440]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117008,	
2017-07-20 13:11:56,355 Epoch[15] Batch [1450]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.116907,	
2017-07-20 13:12:00,511 Epoch[15] Batch [1460]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.116832,	
2017-07-20 13:12:04,794 Epoch[15] Batch [1470]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.116747,	
2017-07-20 13:12:09,058 Epoch[15] Batch [1480]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.116733,	
2017-07-20 13:12:11,638 Epoch[15] Train-FCNLogLoss=0.116649
2017-07-20 13:12:11,638 Epoch[15] Time cost=617.642
2017-07-20 13:12:12,319 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0016.params"
2017-07-20 13:12:13,788 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0016.states"
2017-07-20 13:12:18,648 Epoch[16] Batch [10]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.127931,	
2017-07-20 13:12:22,709 Epoch[16] Batch [20]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.125124,	
2017-07-20 13:12:26,748 Epoch[16] Batch [30]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117299,	
2017-07-20 13:12:30,869 Epoch[16] Batch [40]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111923,	
2017-07-20 13:12:34,860 Epoch[16] Batch [50]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112115,	
2017-07-20 13:12:38,979 Epoch[16] Batch [60]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111566,	
2017-07-20 13:12:43,086 Epoch[16] Batch [70]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.111925,	
2017-07-20 13:12:47,245 Epoch[16] Batch [80]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.111051,	
2017-07-20 13:12:51,297 Epoch[16] Batch [90]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.110664,	
2017-07-20 13:12:55,553 Epoch[16] Batch [100]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111590,	
2017-07-20 13:12:59,592 Epoch[16] Batch [110]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113767,	
2017-07-20 13:13:03,684 Epoch[16] Batch [120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114030,	
2017-07-20 13:13:07,738 Epoch[16] Batch [130]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.115031,	
2017-07-20 13:13:11,908 Epoch[16] Batch [140]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.115149,	
2017-07-20 13:13:16,101 Epoch[16] Batch [150]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.115291,	
2017-07-20 13:13:20,086 Epoch[16] Batch [160]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116331,	
2017-07-20 13:13:24,083 Epoch[16] Batch [170]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.115886,	
2017-07-20 13:13:28,151 Epoch[16] Batch [180]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116139,	
2017-07-20 13:13:32,365 Epoch[16] Batch [190]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.116057,	
2017-07-20 13:13:36,660 Epoch[16] Batch [200]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.115683,	
2017-07-20 13:13:40,747 Epoch[16] Batch [210]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115105,	
2017-07-20 13:13:44,873 Epoch[16] Batch [220]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.114587,	
2017-07-20 13:13:48,909 Epoch[16] Batch [230]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.114384,	
2017-07-20 13:13:53,169 Epoch[16] Batch [240]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.114403,	
2017-07-20 13:13:57,289 Epoch[16] Batch [250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113890,	
2017-07-20 13:14:01,352 Epoch[16] Batch [260]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113822,	
2017-07-20 13:14:05,515 Epoch[16] Batch [270]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.114031,	
2017-07-20 13:14:09,546 Epoch[16] Batch [280]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113310,	
2017-07-20 13:14:13,639 Epoch[16] Batch [290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113792,	
2017-07-20 13:14:17,743 Epoch[16] Batch [300]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113338,	
2017-07-20 13:14:21,819 Epoch[16] Batch [310]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113268,	
2017-07-20 13:14:25,773 Epoch[16] Batch [320]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.113019,	
2017-07-20 13:14:30,021 Epoch[16] Batch [330]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.113367,	
2017-07-20 13:14:34,075 Epoch[16] Batch [340]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113421,	
2017-07-20 13:14:38,054 Epoch[16] Batch [350]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113556,	
2017-07-20 13:14:42,173 Epoch[16] Batch [360]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113578,	
2017-07-20 13:14:46,189 Epoch[16] Batch [370]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113664,	
2017-07-20 13:14:50,336 Epoch[16] Batch [380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113630,	
2017-07-20 13:14:54,554 Epoch[16] Batch [390]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.113764,	
2017-07-20 13:14:58,557 Epoch[16] Batch [400]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.113486,	
2017-07-20 13:15:02,636 Epoch[16] Batch [410]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113348,	
2017-07-20 13:15:06,695 Epoch[16] Batch [420]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113350,	
2017-07-20 13:15:10,808 Epoch[16] Batch [430]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.113314,	
2017-07-20 13:15:14,837 Epoch[16] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113405,	
2017-07-20 13:15:18,879 Epoch[16] Batch [450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113509,	
2017-07-20 13:15:23,076 Epoch[16] Batch [460]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.113358,	
2017-07-20 13:15:27,301 Epoch[16] Batch [470]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113296,	
2017-07-20 13:15:31,576 Epoch[16] Batch [480]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.113282,	
2017-07-20 13:15:35,783 Epoch[16] Batch [490]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.113186,	
2017-07-20 13:15:39,840 Epoch[16] Batch [500]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112966,	
2017-07-20 13:15:44,083 Epoch[16] Batch [510]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.112938,	
2017-07-20 13:15:48,194 Epoch[16] Batch [520]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112789,	
2017-07-20 13:15:52,261 Epoch[16] Batch [530]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.112700,	
2017-07-20 13:15:56,461 Epoch[16] Batch [540]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.112586,	
2017-07-20 13:16:00,550 Epoch[16] Batch [550]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112684,	
2017-07-20 13:16:04,694 Epoch[16] Batch [560]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112701,	
2017-07-20 13:16:08,874 Epoch[16] Batch [570]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112562,	
2017-07-20 13:16:12,970 Epoch[16] Batch [580]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112501,	
2017-07-20 13:16:17,167 Epoch[16] Batch [590]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112626,	
2017-07-20 13:16:21,317 Epoch[16] Batch [600]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112542,	
2017-07-20 13:16:25,359 Epoch[16] Batch [610]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112482,	
2017-07-20 13:16:29,442 Epoch[16] Batch [620]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112612,	
2017-07-20 13:16:33,552 Epoch[16] Batch [630]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112602,	
2017-07-20 13:16:37,661 Epoch[16] Batch [640]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112433,	
2017-07-20 13:16:41,661 Epoch[16] Batch [650]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112335,	
2017-07-20 13:16:45,829 Epoch[16] Batch [660]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.112264,	
2017-07-20 13:16:49,857 Epoch[16] Batch [670]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112263,	
2017-07-20 13:16:53,925 Epoch[16] Batch [680]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.112319,	
2017-07-20 13:16:58,070 Epoch[16] Batch [690]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112456,	
2017-07-20 13:17:02,157 Epoch[16] Batch [700]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112338,	
2017-07-20 13:17:06,319 Epoch[16] Batch [710]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.112274,	
2017-07-20 13:17:10,480 Epoch[16] Batch [720]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.112361,	
2017-07-20 13:17:14,611 Epoch[16] Batch [730]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112274,	
2017-07-20 13:17:18,747 Epoch[16] Batch [740]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.112276,	
2017-07-20 13:17:22,930 Epoch[16] Batch [750]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112120,	
2017-07-20 13:17:27,042 Epoch[16] Batch [760]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112131,	
2017-07-20 13:17:31,184 Epoch[16] Batch [770]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.111964,	
2017-07-20 13:17:35,355 Epoch[16] Batch [780]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.112141,	
2017-07-20 13:17:39,388 Epoch[16] Batch [790]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112251,	
2017-07-20 13:17:43,553 Epoch[16] Batch [800]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.112234,	
2017-07-20 13:17:47,581 Epoch[16] Batch [810]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112297,	
2017-07-20 13:17:51,794 Epoch[16] Batch [820]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.112326,	
2017-07-20 13:17:56,087 Epoch[16] Batch [830]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.112355,	
2017-07-20 13:18:00,522 Epoch[16] Batch [840]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.112315,	
2017-07-20 13:18:04,844 Epoch[16] Batch [850]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.112310,	
2017-07-20 13:18:08,989 Epoch[16] Batch [860]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112304,	
2017-07-20 13:18:13,365 Epoch[16] Batch [870]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.112284,	
2017-07-20 13:18:17,683 Epoch[16] Batch [880]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.112111,	
2017-07-20 13:18:21,826 Epoch[16] Batch [890]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112143,	
2017-07-20 13:18:26,058 Epoch[16] Batch [900]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.112098,	
2017-07-20 13:18:30,308 Epoch[16] Batch [910]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112221,	
2017-07-20 13:18:34,538 Epoch[16] Batch [920]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.112331,	
2017-07-20 13:18:38,793 Epoch[16] Batch [930]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.112378,	
2017-07-20 13:18:43,042 Epoch[16] Batch [940]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112438,	
2017-07-20 13:18:47,323 Epoch[16] Batch [950]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112375,	
2017-07-20 13:18:51,511 Epoch[16] Batch [960]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.112477,	
2017-07-20 13:18:55,769 Epoch[16] Batch [970]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.112454,	
2017-07-20 13:18:59,988 Epoch[16] Batch [980]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.112436,	
2017-07-20 13:19:04,254 Epoch[16] Batch [990]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.112447,	
2017-07-20 13:19:08,523 Epoch[16] Batch [1000]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.112380,	
2017-07-20 13:19:12,840 Epoch[16] Batch [1010]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.112319,	
2017-07-20 13:19:17,146 Epoch[16] Batch [1020]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112393,	
2017-07-20 13:19:21,405 Epoch[16] Batch [1030]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.112305,	
2017-07-20 13:19:25,546 Epoch[16] Batch [1040]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.112247,	
2017-07-20 13:19:29,704 Epoch[16] Batch [1050]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112329,	
2017-07-20 13:19:33,976 Epoch[16] Batch [1060]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.112306,	
2017-07-20 13:19:38,220 Epoch[16] Batch [1070]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.112200,	
2017-07-20 13:19:42,519 Epoch[16] Batch [1080]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.112287,	
2017-07-20 13:19:46,810 Epoch[16] Batch [1090]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.112286,	
2017-07-20 13:19:51,059 Epoch[16] Batch [1100]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.112262,	
2017-07-20 13:19:55,240 Epoch[16] Batch [1110]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112282,	
2017-07-20 13:19:59,517 Epoch[16] Batch [1120]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112189,	
2017-07-20 13:20:03,631 Epoch[16] Batch [1130]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112135,	
2017-07-20 13:20:07,891 Epoch[16] Batch [1140]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.112297,	
2017-07-20 13:20:12,126 Epoch[16] Batch [1150]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.112268,	
2017-07-20 13:20:16,426 Epoch[16] Batch [1160]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.112258,	
2017-07-20 13:20:20,693 Epoch[16] Batch [1170]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.112302,	
2017-07-20 13:20:24,997 Epoch[16] Batch [1180]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112319,	
2017-07-20 13:20:29,301 Epoch[16] Batch [1190]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112365,	
2017-07-20 13:20:33,536 Epoch[16] Batch [1200]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.112277,	
2017-07-20 13:20:37,821 Epoch[16] Batch [1210]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.112305,	
2017-07-20 13:20:42,182 Epoch[16] Batch [1220]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.112309,	
2017-07-20 13:20:46,424 Epoch[16] Batch [1230]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.112263,	
2017-07-20 13:20:50,725 Epoch[16] Batch [1240]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.112141,	
2017-07-20 13:20:54,973 Epoch[16] Batch [1250]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.112108,	
2017-07-20 13:20:59,344 Epoch[16] Batch [1260]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.112132,	
2017-07-20 13:21:03,542 Epoch[16] Batch [1270]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112074,	
2017-07-20 13:21:07,826 Epoch[16] Batch [1280]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.112064,	
2017-07-20 13:21:12,151 Epoch[16] Batch [1290]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.112032,	
2017-07-20 13:21:16,333 Epoch[16] Batch [1300]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112002,	
2017-07-20 13:21:20,555 Epoch[16] Batch [1310]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.112036,	
2017-07-20 13:21:24,954 Epoch[16] Batch [1320]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.112092,	
2017-07-20 13:21:29,108 Epoch[16] Batch [1330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112061,	
2017-07-20 13:21:33,284 Epoch[16] Batch [1340]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112071,	
2017-07-20 13:21:37,594 Epoch[16] Batch [1350]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.112080,	
2017-07-20 13:21:41,851 Epoch[16] Batch [1360]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.112160,	
2017-07-20 13:21:46,028 Epoch[16] Batch [1370]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112362,	
2017-07-20 13:21:50,216 Epoch[16] Batch [1380]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.112502,	
2017-07-20 13:21:54,526 Epoch[16] Batch [1390]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.112572,	
2017-07-20 13:21:58,783 Epoch[16] Batch [1400]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.112704,	
2017-07-20 13:22:02,979 Epoch[16] Batch [1410]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112731,	
2017-07-20 13:22:07,075 Epoch[16] Batch [1420]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112763,	
2017-07-20 13:22:11,405 Epoch[16] Batch [1430]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.112745,	
2017-07-20 13:22:15,452 Epoch[16] Batch [1440]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112702,	
2017-07-20 13:22:19,594 Epoch[16] Batch [1450]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.112652,	
2017-07-20 13:22:23,987 Epoch[16] Batch [1460]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.112914,	
2017-07-20 13:22:28,246 Epoch[16] Batch [1470]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.113156,	
2017-07-20 13:22:32,352 Epoch[16] Batch [1480]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113161,	
2017-07-20 13:22:34,869 Epoch[16] Train-FCNLogLoss=0.113337
2017-07-20 13:22:34,869 Epoch[16] Time cost=621.081
2017-07-20 13:22:35,620 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0017.params"
2017-07-20 13:22:37,289 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0017.states"
2017-07-20 13:22:42,240 Epoch[17] Batch [10]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.106045,	
2017-07-20 13:22:46,563 Epoch[17] Batch [20]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.108112,	
2017-07-20 13:22:50,777 Epoch[17] Batch [30]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109383,	
2017-07-20 13:22:55,056 Epoch[17] Batch [40]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103997,	
2017-07-20 13:22:59,165 Epoch[17] Batch [50]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105767,	
2017-07-20 13:23:03,282 Epoch[17] Batch [60]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.106796,	
2017-07-20 13:23:07,472 Epoch[17] Batch [70]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.107252,	
2017-07-20 13:23:11,579 Epoch[17] Batch [80]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.107874,	
2017-07-20 13:23:15,674 Epoch[17] Batch [90]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108286,	
2017-07-20 13:23:19,753 Epoch[17] Batch [100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109331,	
2017-07-20 13:23:23,938 Epoch[17] Batch [110]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.109001,	
2017-07-20 13:23:28,075 Epoch[17] Batch [120]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.108681,	
2017-07-20 13:23:32,150 Epoch[17] Batch [130]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.110221,	
2017-07-20 13:23:36,182 Epoch[17] Batch [140]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110683,	
2017-07-20 13:23:40,364 Epoch[17] Batch [150]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.111019,	
2017-07-20 13:23:44,382 Epoch[17] Batch [160]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112460,	
2017-07-20 13:23:48,582 Epoch[17] Batch [170]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.113333,	
2017-07-20 13:23:52,866 Epoch[17] Batch [180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.114250,	
2017-07-20 13:23:57,126 Epoch[17] Batch [190]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.114097,	
2017-07-20 13:24:01,119 Epoch[17] Batch [200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.114527,	
2017-07-20 13:24:05,172 Epoch[17] Batch [210]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.114993,	
2017-07-20 13:24:09,300 Epoch[17] Batch [220]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.115068,	
2017-07-20 13:24:13,324 Epoch[17] Batch [230]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114841,	
2017-07-20 13:24:17,470 Epoch[17] Batch [240]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.114521,	
2017-07-20 13:24:21,470 Epoch[17] Batch [250]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.113722,	
2017-07-20 13:24:25,566 Epoch[17] Batch [260]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113398,	
2017-07-20 13:24:29,700 Epoch[17] Batch [270]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113215,	
2017-07-20 13:24:33,807 Epoch[17] Batch [280]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113025,	
2017-07-20 13:24:37,933 Epoch[17] Batch [290]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112763,	
2017-07-20 13:24:41,998 Epoch[17] Batch [300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.112956,	
2017-07-20 13:24:46,018 Epoch[17] Batch [310]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113324,	
2017-07-20 13:24:50,094 Epoch[17] Batch [320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113206,	
2017-07-20 13:24:54,194 Epoch[17] Batch [330]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112952,	
2017-07-20 13:24:58,320 Epoch[17] Batch [340]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.113242,	
2017-07-20 13:25:02,431 Epoch[17] Batch [350]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.113119,	
2017-07-20 13:25:06,566 Epoch[17] Batch [360]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112698,	
2017-07-20 13:25:10,514 Epoch[17] Batch [370]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.112634,	
2017-07-20 13:25:14,669 Epoch[17] Batch [380]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112826,	
2017-07-20 13:25:18,802 Epoch[17] Batch [390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112362,	
2017-07-20 13:25:22,930 Epoch[17] Batch [400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112439,	
2017-07-20 13:25:27,070 Epoch[17] Batch [410]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.112442,	
2017-07-20 13:25:31,279 Epoch[17] Batch [420]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.112744,	
2017-07-20 13:25:35,522 Epoch[17] Batch [430]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.113110,	
2017-07-20 13:25:39,645 Epoch[17] Batch [440]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113040,	
2017-07-20 13:25:43,699 Epoch[17] Batch [450]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112931,	
2017-07-20 13:25:47,774 Epoch[17] Batch [460]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113022,	
2017-07-20 13:25:51,829 Epoch[17] Batch [470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112962,	
2017-07-20 13:25:55,915 Epoch[17] Batch [480]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112605,	
2017-07-20 13:25:59,931 Epoch[17] Batch [490]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112747,	
2017-07-20 13:26:04,109 Epoch[17] Batch [500]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112747,	
2017-07-20 13:26:08,293 Epoch[17] Batch [510]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112622,	
2017-07-20 13:26:12,452 Epoch[17] Batch [520]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112818,	
2017-07-20 13:26:16,620 Epoch[17] Batch [530]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.112821,	
2017-07-20 13:26:20,654 Epoch[17] Batch [540]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112704,	
2017-07-20 13:26:24,660 Epoch[17] Batch [550]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.112676,	
2017-07-20 13:26:28,652 Epoch[17] Batch [560]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112523,	
2017-07-20 13:26:32,742 Epoch[17] Batch [570]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112664,	
2017-07-20 13:26:36,975 Epoch[17] Batch [580]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.112657,	
2017-07-20 13:26:41,173 Epoch[17] Batch [590]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112610,	
2017-07-20 13:26:45,254 Epoch[17] Batch [600]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112871,	
2017-07-20 13:26:49,413 Epoch[17] Batch [610]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112745,	
2017-07-20 13:26:53,437 Epoch[17] Batch [620]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112925,	
2017-07-20 13:26:57,590 Epoch[17] Batch [630]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112895,	
2017-07-20 13:27:01,661 Epoch[17] Batch [640]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.112876,	
2017-07-20 13:27:05,772 Epoch[17] Batch [650]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112611,	
2017-07-20 13:27:09,821 Epoch[17] Batch [660]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112528,	
2017-07-20 13:27:13,849 Epoch[17] Batch [670]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112580,	
2017-07-20 13:27:18,000 Epoch[17] Batch [680]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112630,	
2017-07-20 13:27:22,113 Epoch[17] Batch [690]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112551,	
2017-07-20 13:27:26,224 Epoch[17] Batch [700]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112556,	
2017-07-20 13:27:30,342 Epoch[17] Batch [710]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112718,	
2017-07-20 13:27:34,490 Epoch[17] Batch [720]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112746,	
2017-07-20 13:27:38,697 Epoch[17] Batch [730]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.112785,	
2017-07-20 13:27:42,814 Epoch[17] Batch [740]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112671,	
2017-07-20 13:27:46,973 Epoch[17] Batch [750]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112675,	
2017-07-20 13:27:51,035 Epoch[17] Batch [760]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112769,	
2017-07-20 13:27:55,091 Epoch[17] Batch [770]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112870,	
2017-07-20 13:27:59,210 Epoch[17] Batch [780]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112772,	
2017-07-20 13:28:03,341 Epoch[17] Batch [790]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112645,	
2017-07-20 13:28:07,386 Epoch[17] Batch [800]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112796,	
2017-07-20 13:28:11,674 Epoch[17] Batch [810]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.112703,	
2017-07-20 13:28:15,795 Epoch[17] Batch [820]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112594,	
2017-07-20 13:28:19,940 Epoch[17] Batch [830]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112666,	
2017-07-20 13:28:24,014 Epoch[17] Batch [840]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112815,	
2017-07-20 13:28:28,062 Epoch[17] Batch [850]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112882,	
2017-07-20 13:28:32,086 Epoch[17] Batch [860]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112773,	
2017-07-20 13:28:36,324 Epoch[17] Batch [870]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.112801,	
2017-07-20 13:28:40,375 Epoch[17] Batch [880]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112785,	
2017-07-20 13:28:44,822 Epoch[17] Batch [890]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.112727,	
2017-07-20 13:28:49,079 Epoch[17] Batch [900]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.112807,	
2017-07-20 13:28:53,294 Epoch[17] Batch [910]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.112853,	
2017-07-20 13:28:57,472 Epoch[17] Batch [920]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112869,	
2017-07-20 13:29:01,717 Epoch[17] Batch [930]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.112875,	
2017-07-20 13:29:05,893 Epoch[17] Batch [940]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112772,	
2017-07-20 13:29:10,234 Epoch[17] Batch [950]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.112699,	
2017-07-20 13:29:14,417 Epoch[17] Batch [960]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112584,	
2017-07-20 13:29:18,675 Epoch[17] Batch [970]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.112417,	
2017-07-20 13:29:22,872 Epoch[17] Batch [980]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112352,	
2017-07-20 13:29:27,055 Epoch[17] Batch [990]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112378,	
2017-07-20 13:29:31,353 Epoch[17] Batch [1000]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.112300,	
2017-07-20 13:29:35,553 Epoch[17] Batch [1010]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.112245,	
2017-07-20 13:29:39,704 Epoch[17] Batch [1020]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112315,	
2017-07-20 13:29:44,131 Epoch[17] Batch [1030]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.112337,	
2017-07-20 13:29:48,308 Epoch[17] Batch [1040]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112355,	
2017-07-20 13:29:52,542 Epoch[17] Batch [1050]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.112348,	
2017-07-20 13:29:56,821 Epoch[17] Batch [1060]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112308,	
2017-07-20 13:30:01,088 Epoch[17] Batch [1070]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.112354,	
2017-07-20 13:30:05,148 Epoch[17] Batch [1080]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112348,	
2017-07-20 13:30:09,327 Epoch[17] Batch [1090]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112332,	
2017-07-20 13:30:13,616 Epoch[17] Batch [1100]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.112272,	
2017-07-20 13:30:17,771 Epoch[17] Batch [1110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112291,	
2017-07-20 13:30:22,042 Epoch[17] Batch [1120]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.112357,	
2017-07-20 13:30:26,126 Epoch[17] Batch [1130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112268,	
2017-07-20 13:30:30,369 Epoch[17] Batch [1140]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.112231,	
2017-07-20 13:30:34,633 Epoch[17] Batch [1150]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.112199,	
2017-07-20 13:30:38,727 Epoch[17] Batch [1160]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112059,	
2017-07-20 13:30:42,973 Epoch[17] Batch [1170]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.111918,	
2017-07-20 13:30:47,215 Epoch[17] Batch [1180]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.111932,	
2017-07-20 13:30:51,650 Epoch[17] Batch [1190]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111934,	
2017-07-20 13:30:55,795 Epoch[17] Batch [1200]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112261,	
2017-07-20 13:31:00,136 Epoch[17] Batch [1210]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.112288,	
2017-07-20 13:31:04,237 Epoch[17] Batch [1220]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.112305,	
2017-07-20 13:31:08,295 Epoch[17] Batch [1230]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112375,	
2017-07-20 13:31:12,433 Epoch[17] Batch [1240]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.112379,	
2017-07-20 13:31:16,486 Epoch[17] Batch [1250]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112392,	
2017-07-20 13:31:20,569 Epoch[17] Batch [1260]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112403,	
2017-07-20 13:31:24,768 Epoch[17] Batch [1270]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112378,	
2017-07-20 13:31:28,993 Epoch[17] Batch [1280]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.112369,	
2017-07-20 13:31:33,301 Epoch[17] Batch [1290]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112304,	
2017-07-20 13:31:37,527 Epoch[17] Batch [1300]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.112327,	
2017-07-20 13:31:41,882 Epoch[17] Batch [1310]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.112340,	
2017-07-20 13:31:46,075 Epoch[17] Batch [1320]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.112388,	
2017-07-20 13:31:50,362 Epoch[17] Batch [1330]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.112254,	
2017-07-20 13:31:54,704 Epoch[17] Batch [1340]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.112225,	
2017-07-20 13:31:58,920 Epoch[17] Batch [1350]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.112187,	
2017-07-20 13:32:03,066 Epoch[17] Batch [1360]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112111,	
2017-07-20 13:32:07,336 Epoch[17] Batch [1370]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.112143,	
2017-07-20 13:32:11,585 Epoch[17] Batch [1380]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112078,	
2017-07-20 13:32:15,765 Epoch[17] Batch [1390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112015,	
2017-07-20 13:32:20,124 Epoch[17] Batch [1400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.111990,	
2017-07-20 13:32:24,339 Epoch[17] Batch [1410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.111997,	
2017-07-20 13:32:28,524 Epoch[17] Batch [1420]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.111935,	
2017-07-20 13:32:32,780 Epoch[17] Batch [1430]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111953,	
2017-07-20 13:32:37,037 Epoch[17] Batch [1440]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111974,	
2017-07-20 13:32:41,282 Epoch[17] Batch [1450]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.111953,	
2017-07-20 13:32:45,525 Epoch[17] Batch [1460]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.111887,	
2017-07-20 13:32:49,935 Epoch[17] Batch [1470]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.111894,	
2017-07-20 13:32:54,397 Epoch[17] Batch [1480]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111867,	
2017-07-20 13:32:57,041 Epoch[17] Train-FCNLogLoss=0.111875
2017-07-20 13:32:57,041 Epoch[17] Time cost=619.751
2017-07-20 13:32:57,851 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0018.params"
2017-07-20 13:32:59,499 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0018.states"
2017-07-20 13:33:04,483 Epoch[18] Batch [10]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.104386,	
2017-07-20 13:33:08,640 Epoch[18] Batch [20]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.106254,	
2017-07-20 13:33:12,909 Epoch[18] Batch [30]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.104691,	
2017-07-20 13:33:16,999 Epoch[18] Batch [40]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103233,	
2017-07-20 13:33:21,335 Epoch[18] Batch [50]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.104788,	
2017-07-20 13:33:25,625 Epoch[18] Batch [60]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.105793,	
2017-07-20 13:33:29,879 Epoch[18] Batch [70]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.106918,	
2017-07-20 13:33:34,107 Epoch[18] Batch [80]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.105713,	
2017-07-20 13:33:38,301 Epoch[18] Batch [90]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.107373,	
2017-07-20 13:33:42,507 Epoch[18] Batch [100]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.106638,	
2017-07-20 13:33:46,613 Epoch[18] Batch [110]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.106889,	
2017-07-20 13:33:50,790 Epoch[18] Batch [120]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.106155,	
2017-07-20 13:33:54,840 Epoch[18] Batch [130]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106525,	
2017-07-20 13:33:59,045 Epoch[18] Batch [140]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.106502,	
2017-07-20 13:34:03,278 Epoch[18] Batch [150]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.107479,	
2017-07-20 13:34:07,460 Epoch[18] Batch [160]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.107594,	
2017-07-20 13:34:11,520 Epoch[18] Batch [170]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.107656,	
2017-07-20 13:34:15,774 Epoch[18] Batch [180]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.109280,	
2017-07-20 13:34:19,999 Epoch[18] Batch [190]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.109244,	
2017-07-20 13:34:24,234 Epoch[18] Batch [200]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.109014,	
2017-07-20 13:34:28,375 Epoch[18] Batch [210]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.108573,	
2017-07-20 13:34:32,535 Epoch[18] Batch [220]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.108462,	
2017-07-20 13:34:36,591 Epoch[18] Batch [230]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108839,	
2017-07-20 13:34:40,644 Epoch[18] Batch [240]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108853,	
2017-07-20 13:34:44,800 Epoch[18] Batch [250]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.109079,	
2017-07-20 13:34:48,925 Epoch[18] Batch [260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.109559,	
2017-07-20 13:34:53,109 Epoch[18] Batch [270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.111334,	
2017-07-20 13:34:57,264 Epoch[18] Batch [280]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112218,	
2017-07-20 13:35:01,407 Epoch[18] Batch [290]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112988,	
2017-07-20 13:35:05,486 Epoch[18] Batch [300]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113304,	
2017-07-20 13:35:09,518 Epoch[18] Batch [310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113632,	
2017-07-20 13:35:13,525 Epoch[18] Batch [320]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113516,	
2017-07-20 13:35:17,580 Epoch[18] Batch [330]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113136,	
2017-07-20 13:35:21,632 Epoch[18] Batch [340]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113186,	
2017-07-20 13:35:25,709 Epoch[18] Batch [350]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113481,	
2017-07-20 13:35:29,772 Epoch[18] Batch [360]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113226,	
2017-07-20 13:35:33,794 Epoch[18] Batch [370]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113429,	
2017-07-20 13:35:37,957 Epoch[18] Batch [380]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.113491,	
2017-07-20 13:35:42,197 Epoch[18] Batch [390]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.113184,	
2017-07-20 13:35:46,204 Epoch[18] Batch [400]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113260,	
2017-07-20 13:35:50,349 Epoch[18] Batch [410]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113239,	
2017-07-20 13:35:54,484 Epoch[18] Batch [420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113087,	
2017-07-20 13:35:58,636 Epoch[18] Batch [430]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.113022,	
2017-07-20 13:36:02,736 Epoch[18] Batch [440]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112888,	
2017-07-20 13:36:06,769 Epoch[18] Batch [450]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112697,	
2017-07-20 13:36:10,859 Epoch[18] Batch [460]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112620,	
2017-07-20 13:36:14,812 Epoch[18] Batch [470]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.112437,	
2017-07-20 13:36:18,990 Epoch[18] Batch [480]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112662,	
2017-07-20 13:36:23,110 Epoch[18] Batch [490]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112256,	
2017-07-20 13:36:27,105 Epoch[18] Batch [500]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.111943,	
2017-07-20 13:36:31,133 Epoch[18] Batch [510]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112009,	
2017-07-20 13:36:35,203 Epoch[18] Batch [520]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.111845,	
2017-07-20 13:36:39,445 Epoch[18] Batch [530]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.111534,	
2017-07-20 13:36:43,564 Epoch[18] Batch [540]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111451,	
2017-07-20 13:36:47,696 Epoch[18] Batch [550]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111384,	
2017-07-20 13:36:51,780 Epoch[18] Batch [560]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.111333,	
2017-07-20 13:36:55,923 Epoch[18] Batch [570]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.111255,	
2017-07-20 13:37:00,108 Epoch[18] Batch [580]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.111421,	
2017-07-20 13:37:04,169 Epoch[18] Batch [590]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111322,	
2017-07-20 13:37:08,270 Epoch[18] Batch [600]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111218,	
2017-07-20 13:37:12,238 Epoch[18] Batch [610]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.111138,	
2017-07-20 13:37:16,330 Epoch[18] Batch [620]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.111139,	
2017-07-20 13:37:20,485 Epoch[18] Batch [630]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.111140,	
2017-07-20 13:37:24,537 Epoch[18] Batch [640]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.111279,	
2017-07-20 13:37:28,631 Epoch[18] Batch [650]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.111119,	
2017-07-20 13:37:32,614 Epoch[18] Batch [660]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110913,	
2017-07-20 13:37:36,751 Epoch[18] Batch [670]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.111133,	
2017-07-20 13:37:40,848 Epoch[18] Batch [680]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.111106,	
2017-07-20 13:37:45,010 Epoch[18] Batch [690]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.111093,	
2017-07-20 13:37:49,201 Epoch[18] Batch [700]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110972,	
2017-07-20 13:37:53,359 Epoch[18] Batch [710]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.110993,	
2017-07-20 13:37:57,485 Epoch[18] Batch [720]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.111040,	
2017-07-20 13:38:01,589 Epoch[18] Batch [730]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111017,	
2017-07-20 13:38:05,776 Epoch[18] Batch [740]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.110943,	
2017-07-20 13:38:09,935 Epoch[18] Batch [750]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.110931,	
2017-07-20 13:38:14,142 Epoch[18] Batch [760]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110998,	
2017-07-20 13:38:18,287 Epoch[18] Batch [770]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.111327,	
2017-07-20 13:38:22,330 Epoch[18] Batch [780]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111331,	
2017-07-20 13:38:26,249 Epoch[18] Batch [790]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111357,	
2017-07-20 13:38:30,392 Epoch[18] Batch [800]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.111411,	
2017-07-20 13:38:34,432 Epoch[18] Batch [810]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111195,	
2017-07-20 13:38:38,487 Epoch[18] Batch [820]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.111043,	
2017-07-20 13:38:42,591 Epoch[18] Batch [830]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111338,	
2017-07-20 13:38:46,769 Epoch[18] Batch [840]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.111255,	
2017-07-20 13:38:50,917 Epoch[18] Batch [850]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111187,	
2017-07-20 13:38:54,959 Epoch[18] Batch [860]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111286,	
2017-07-20 13:38:59,086 Epoch[18] Batch [870]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.111085,	
2017-07-20 13:39:03,229 Epoch[18] Batch [880]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.111180,	
2017-07-20 13:39:07,445 Epoch[18] Batch [890]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.111210,	
2017-07-20 13:39:11,482 Epoch[18] Batch [900]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.111260,	
2017-07-20 13:39:15,718 Epoch[18] Batch [910]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.111351,	
2017-07-20 13:39:19,781 Epoch[18] Batch [920]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111321,	
2017-07-20 13:39:24,092 Epoch[18] Batch [930]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.111347,	
2017-07-20 13:39:28,352 Epoch[18] Batch [940]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.111372,	
2017-07-20 13:39:32,395 Epoch[18] Batch [950]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111298,	
2017-07-20 13:39:36,638 Epoch[18] Batch [960]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.111354,	
2017-07-20 13:39:40,976 Epoch[18] Batch [970]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.111272,	
2017-07-20 13:39:45,227 Epoch[18] Batch [980]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112518,	
2017-07-20 13:39:49,410 Epoch[18] Batch [990]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112764,	
2017-07-20 13:39:53,766 Epoch[18] Batch [1000]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.112983,	
2017-07-20 13:39:58,011 Epoch[18] Batch [1010]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.113213,	
2017-07-20 13:40:02,247 Epoch[18] Batch [1020]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.113238,	
2017-07-20 13:40:06,432 Epoch[18] Batch [1030]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.113437,	
2017-07-20 13:40:10,636 Epoch[18] Batch [1040]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.113422,	
2017-07-20 13:40:14,781 Epoch[18] Batch [1050]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113556,	
2017-07-20 13:40:19,025 Epoch[18] Batch [1060]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.113737,	
2017-07-20 13:40:23,077 Epoch[18] Batch [1070]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113824,	
2017-07-20 13:40:27,197 Epoch[18] Batch [1080]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113845,	
2017-07-20 13:40:31,399 Epoch[18] Batch [1090]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.113895,	
2017-07-20 13:40:35,542 Epoch[18] Batch [1100]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113990,	
2017-07-20 13:40:39,727 Epoch[18] Batch [1110]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.114335,	
2017-07-20 13:40:44,097 Epoch[18] Batch [1120]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.114531,	
2017-07-20 13:40:48,396 Epoch[18] Batch [1130]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.114678,	
2017-07-20 13:40:52,718 Epoch[18] Batch [1140]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.114738,	
2017-07-20 13:40:56,940 Epoch[18] Batch [1150]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.114887,	
2017-07-20 13:41:01,224 Epoch[18] Batch [1160]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.114871,	
2017-07-20 13:41:05,372 Epoch[18] Batch [1170]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.115029,	
2017-07-20 13:41:09,601 Epoch[18] Batch [1180]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.114972,	
2017-07-20 13:41:13,781 Epoch[18] Batch [1190]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.114900,	
2017-07-20 13:41:18,102 Epoch[18] Batch [1200]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.114873,	
2017-07-20 13:41:22,339 Epoch[18] Batch [1210]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.114798,	
2017-07-20 13:41:26,730 Epoch[18] Batch [1220]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.114808,	
2017-07-20 13:41:30,985 Epoch[18] Batch [1230]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.114833,	
2017-07-20 13:41:35,232 Epoch[18] Batch [1240]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.114840,	
2017-07-20 13:41:39,241 Epoch[18] Batch [1250]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114744,	
2017-07-20 13:41:43,585 Epoch[18] Batch [1260]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.114772,	
2017-07-20 13:41:47,650 Epoch[18] Batch [1270]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.114729,	
2017-07-20 13:41:52,018 Epoch[18] Batch [1280]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.114743,	
2017-07-20 13:41:56,251 Epoch[18] Batch [1290]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.114816,	
2017-07-20 13:42:00,333 Epoch[18] Batch [1300]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114738,	
2017-07-20 13:42:04,538 Epoch[18] Batch [1310]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.114752,	
2017-07-20 13:42:08,747 Epoch[18] Batch [1320]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.114940,	
2017-07-20 13:42:12,995 Epoch[18] Batch [1330]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.114982,	
2017-07-20 13:42:17,280 Epoch[18] Batch [1340]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.114987,	
2017-07-20 13:42:21,580 Epoch[18] Batch [1350]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.114967,	
2017-07-20 13:42:25,987 Epoch[18] Batch [1360]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.114892,	
2017-07-20 13:42:30,114 Epoch[18] Batch [1370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.114880,	
2017-07-20 13:42:34,402 Epoch[18] Batch [1380]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.114875,	
2017-07-20 13:42:38,675 Epoch[18] Batch [1390]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.114885,	
2017-07-20 13:42:42,978 Epoch[18] Batch [1400]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.114928,	
2017-07-20 13:42:47,156 Epoch[18] Batch [1410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114916,	
2017-07-20 13:42:51,334 Epoch[18] Batch [1420]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.114884,	
2017-07-20 13:42:55,659 Epoch[18] Batch [1430]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.114891,	
2017-07-20 13:42:59,851 Epoch[18] Batch [1440]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.114821,	
2017-07-20 13:43:04,080 Epoch[18] Batch [1450]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.114869,	
2017-07-20 13:43:08,429 Epoch[18] Batch [1460]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.114824,	
2017-07-20 13:43:12,714 Epoch[18] Batch [1470]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.114734,	
2017-07-20 13:43:16,844 Epoch[18] Batch [1480]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.114645,	
2017-07-20 13:43:19,467 Epoch[18] Train-FCNLogLoss=0.114588
2017-07-20 13:43:19,467 Epoch[18] Time cost=619.968
2017-07-20 13:43:20,250 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0019.params"
2017-07-20 13:43:21,720 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0019.states"
2017-07-20 13:43:26,864 Epoch[19] Batch [10]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.093100,	
2017-07-20 13:43:31,104 Epoch[19] Batch [20]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.105615,	
2017-07-20 13:43:35,282 Epoch[19] Batch [30]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.107681,	
2017-07-20 13:43:39,610 Epoch[19] Batch [40]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.109968,	
2017-07-20 13:43:43,955 Epoch[19] Batch [50]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.110637,	
2017-07-20 13:43:48,179 Epoch[19] Batch [60]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.110785,	
2017-07-20 13:43:52,432 Epoch[19] Batch [70]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.113030,	
2017-07-20 13:43:56,636 Epoch[19] Batch [80]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.114143,	
2017-07-20 13:44:00,878 Epoch[19] Batch [90]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.111977,	
2017-07-20 13:44:05,227 Epoch[19] Batch [100]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.111761,	
2017-07-20 13:44:09,509 Epoch[19] Batch [110]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.111471,	
2017-07-20 13:44:13,732 Epoch[19] Batch [120]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.111039,	
2017-07-20 13:44:17,867 Epoch[19] Batch [130]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.110379,	
2017-07-20 13:44:21,983 Epoch[19] Batch [140]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109961,	
2017-07-20 13:44:26,117 Epoch[19] Batch [150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.110742,	
2017-07-20 13:44:30,240 Epoch[19] Batch [160]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110797,	
2017-07-20 13:44:34,315 Epoch[19] Batch [170]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.111010,	
2017-07-20 13:44:38,312 Epoch[19] Batch [180]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.110625,	
2017-07-20 13:44:42,321 Epoch[19] Batch [190]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.110316,	
2017-07-20 13:44:46,338 Epoch[19] Batch [200]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110438,	
2017-07-20 13:44:50,315 Epoch[19] Batch [210]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110250,	
2017-07-20 13:44:54,523 Epoch[19] Batch [220]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110016,	
2017-07-20 13:44:58,662 Epoch[19] Batch [230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.109736,	
2017-07-20 13:45:02,685 Epoch[19] Batch [240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.109610,	
2017-07-20 13:45:06,791 Epoch[19] Batch [250]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.108930,	
2017-07-20 13:45:10,774 Epoch[19] Batch [260]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.108995,	
2017-07-20 13:45:14,890 Epoch[19] Batch [270]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109148,	
2017-07-20 13:45:19,027 Epoch[19] Batch [280]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.108829,	
2017-07-20 13:45:23,200 Epoch[19] Batch [290]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109032,	
2017-07-20 13:45:27,190 Epoch[19] Batch [300]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.108727,	
2017-07-20 13:45:31,323 Epoch[19] Batch [310]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108741,	
2017-07-20 13:45:35,305 Epoch[19] Batch [320]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.108695,	
2017-07-20 13:45:39,307 Epoch[19] Batch [330]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.108453,	
2017-07-20 13:45:43,322 Epoch[19] Batch [340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.108210,	
2017-07-20 13:45:47,468 Epoch[19] Batch [350]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.107979,	
2017-07-20 13:45:51,548 Epoch[19] Batch [360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108087,	
2017-07-20 13:45:55,491 Epoch[19] Batch [370]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.108039,	
2017-07-20 13:45:59,586 Epoch[19] Batch [380]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108283,	
2017-07-20 13:46:03,613 Epoch[19] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.108363,	
2017-07-20 13:46:07,778 Epoch[19] Batch [400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.108171,	
2017-07-20 13:46:11,771 Epoch[19] Batch [410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.108059,	
2017-07-20 13:46:16,028 Epoch[19] Batch [420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.108085,	
2017-07-20 13:46:20,094 Epoch[19] Batch [430]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.108165,	
2017-07-20 13:46:24,113 Epoch[19] Batch [440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.108084,	
2017-07-20 13:46:28,293 Epoch[19] Batch [450]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.108207,	
2017-07-20 13:46:32,350 Epoch[19] Batch [460]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108149,	
2017-07-20 13:46:36,593 Epoch[19] Batch [470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.108106,	
2017-07-20 13:46:40,666 Epoch[19] Batch [480]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.108071,	
2017-07-20 13:46:44,668 Epoch[19] Batch [490]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.108024,	
2017-07-20 13:46:48,933 Epoch[19] Batch [500]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.108112,	
2017-07-20 13:46:52,918 Epoch[19] Batch [510]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.108392,	
2017-07-20 13:46:56,971 Epoch[19] Batch [520]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108527,	
2017-07-20 13:47:01,188 Epoch[19] Batch [530]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.108375,	
2017-07-20 13:47:05,311 Epoch[19] Batch [540]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.108631,	
2017-07-20 13:47:09,359 Epoch[19] Batch [550]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108659,	
2017-07-20 13:47:13,439 Epoch[19] Batch [560]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108593,	
2017-07-20 13:47:17,601 Epoch[19] Batch [570]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.108425,	
2017-07-20 13:47:21,550 Epoch[19] Batch [580]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.108542,	
2017-07-20 13:47:25,802 Epoch[19] Batch [590]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.108247,	
2017-07-20 13:47:29,806 Epoch[19] Batch [600]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.108344,	
2017-07-20 13:47:33,826 Epoch[19] Batch [610]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.108501,	
2017-07-20 13:47:37,867 Epoch[19] Batch [620]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.108467,	
2017-07-20 13:47:41,902 Epoch[19] Batch [630]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.108567,	
2017-07-20 13:47:46,066 Epoch[19] Batch [640]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.108618,	
2017-07-20 13:47:50,099 Epoch[19] Batch [650]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.108572,	
2017-07-20 13:47:54,200 Epoch[19] Batch [660]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.108365,	
2017-07-20 13:47:58,276 Epoch[19] Batch [670]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.108379,	
2017-07-20 13:48:02,388 Epoch[19] Batch [680]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.108411,	
2017-07-20 13:48:06,533 Epoch[19] Batch [690]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.108447,	
2017-07-20 13:48:10,736 Epoch[19] Batch [700]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.108359,	
2017-07-20 13:48:14,789 Epoch[19] Batch [710]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108254,	
2017-07-20 13:48:18,792 Epoch[19] Batch [720]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.108039,	
2017-07-20 13:48:22,920 Epoch[19] Batch [730]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.108051,	
2017-07-20 13:48:26,993 Epoch[19] Batch [740]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.108041,	
2017-07-20 13:48:31,036 Epoch[19] Batch [750]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.107889,	
2017-07-20 13:48:35,089 Epoch[19] Batch [760]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108103,	
2017-07-20 13:48:39,224 Epoch[19] Batch [770]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.108026,	
2017-07-20 13:48:43,404 Epoch[19] Batch [780]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.108080,	
2017-07-20 13:48:47,498 Epoch[19] Batch [790]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.107929,	
2017-07-20 13:48:51,570 Epoch[19] Batch [800]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.108044,	
2017-07-20 13:48:55,683 Epoch[19] Batch [810]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.108108,	
2017-07-20 13:49:00,009 Epoch[19] Batch [820]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.108019,	
2017-07-20 13:49:04,035 Epoch[19] Batch [830]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.108179,	
2017-07-20 13:49:08,247 Epoch[19] Batch [840]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.108135,	
2017-07-20 13:49:12,471 Epoch[19] Batch [850]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.108078,	
2017-07-20 13:49:16,706 Epoch[19] Batch [860]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.108140,	
2017-07-20 13:49:20,904 Epoch[19] Batch [870]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.108046,	
2017-07-20 13:49:24,934 Epoch[19] Batch [880]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108092,	
2017-07-20 13:49:29,026 Epoch[19] Batch [890]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108089,	
2017-07-20 13:49:33,088 Epoch[19] Batch [900]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.108169,	
2017-07-20 13:49:37,082 Epoch[19] Batch [910]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.108143,	
2017-07-20 13:49:40,989 Epoch[19] Batch [920]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.108087,	
2017-07-20 13:49:45,232 Epoch[19] Batch [930]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.108118,	
2017-07-20 13:49:49,294 Epoch[19] Batch [940]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.108139,	
2017-07-20 13:49:53,463 Epoch[19] Batch [950]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.108022,	
2017-07-20 13:49:57,706 Epoch[19] Batch [960]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.108168,	
2017-07-20 13:50:01,982 Epoch[19] Batch [970]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.108219,	
2017-07-20 13:50:06,144 Epoch[19] Batch [980]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.108209,	
2017-07-20 13:50:10,215 Epoch[19] Batch [990]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.108195,	
2017-07-20 13:50:14,554 Epoch[19] Batch [1000]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.108230,	
2017-07-20 13:50:18,807 Epoch[19] Batch [1010]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.108148,	
2017-07-20 13:50:23,108 Epoch[19] Batch [1020]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.108073,	
2017-07-20 13:50:27,363 Epoch[19] Batch [1030]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.108143,	
2017-07-20 13:50:31,658 Epoch[19] Batch [1040]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.108170,	
2017-07-20 13:50:35,874 Epoch[19] Batch [1050]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.108783,	
2017-07-20 13:50:40,157 Epoch[19] Batch [1060]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.108911,	
2017-07-20 13:50:44,396 Epoch[19] Batch [1070]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108927,	
2017-07-20 13:50:48,596 Epoch[19] Batch [1080]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.108866,	
2017-07-20 13:50:52,909 Epoch[19] Batch [1090]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.108939,	
2017-07-20 13:50:57,039 Epoch[19] Batch [1100]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.108975,	
2017-07-20 13:51:01,411 Epoch[19] Batch [1110]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.108931,	
2017-07-20 13:51:05,634 Epoch[19] Batch [1120]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.109078,	
2017-07-20 13:51:09,919 Epoch[19] Batch [1130]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.109058,	
2017-07-20 13:51:14,233 Epoch[19] Batch [1140]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.109108,	
2017-07-20 13:51:18,582 Epoch[19] Batch [1150]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.109157,	
2017-07-20 13:51:22,905 Epoch[19] Batch [1160]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109195,	
2017-07-20 13:51:27,099 Epoch[19] Batch [1170]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.109195,	
2017-07-20 13:51:31,530 Epoch[19] Batch [1180]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.109150,	
2017-07-20 13:51:35,951 Epoch[19] Batch [1190]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.109112,	
2017-07-20 13:51:40,218 Epoch[19] Batch [1200]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.109023,	
2017-07-20 13:51:44,354 Epoch[19] Batch [1210]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.109088,	
2017-07-20 13:51:48,579 Epoch[19] Batch [1220]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.109014,	
2017-07-20 13:51:52,981 Epoch[19] Batch [1230]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108942,	
2017-07-20 13:51:57,084 Epoch[19] Batch [1240]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109002,	
2017-07-20 13:52:01,414 Epoch[19] Batch [1250]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.109004,	
2017-07-20 13:52:05,655 Epoch[19] Batch [1260]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.108998,	
2017-07-20 13:52:09,945 Epoch[19] Batch [1270]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.108976,	
2017-07-20 13:52:14,070 Epoch[19] Batch [1280]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.109246,	
2017-07-20 13:52:18,343 Epoch[19] Batch [1290]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109345,	
2017-07-20 13:52:22,580 Epoch[19] Batch [1300]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109534,	
2017-07-20 13:52:26,732 Epoch[19] Batch [1310]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.109531,	
2017-07-20 13:52:30,992 Epoch[19] Batch [1320]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.109645,	
2017-07-20 13:52:35,242 Epoch[19] Batch [1330]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109654,	
2017-07-20 13:52:39,443 Epoch[19] Batch [1340]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.109667,	
2017-07-20 13:52:43,879 Epoch[19] Batch [1350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.109684,	
2017-07-20 13:52:48,130 Epoch[19] Batch [1360]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109737,	
2017-07-20 13:52:52,259 Epoch[19] Batch [1370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.109797,	
2017-07-20 13:52:56,417 Epoch[19] Batch [1380]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109697,	
2017-07-20 13:53:00,651 Epoch[19] Batch [1390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.109696,	
2017-07-20 13:53:04,835 Epoch[19] Batch [1400]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.109699,	
2017-07-20 13:53:08,950 Epoch[19] Batch [1410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109614,	
2017-07-20 13:53:13,165 Epoch[19] Batch [1420]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109700,	
2017-07-20 13:53:17,331 Epoch[19] Batch [1430]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.109720,	
2017-07-20 13:53:21,765 Epoch[19] Batch [1440]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.109798,	
2017-07-20 13:53:26,126 Epoch[19] Batch [1450]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.109915,	
2017-07-20 13:53:30,237 Epoch[19] Batch [1460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110006,	
2017-07-20 13:53:34,369 Epoch[19] Batch [1470]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109970,	
2017-07-20 13:53:38,745 Epoch[19] Batch [1480]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.109932,	
2017-07-20 13:53:41,299 Epoch[19] Train-FCNLogLoss=0.109912
2017-07-20 13:53:41,299 Epoch[19] Time cost=619.578
2017-07-20 13:53:42,075 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0020.params"
2017-07-20 13:53:43,683 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0020.states"
2017-07-20 13:53:48,558 Epoch[20] Batch [10]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.119179,	
2017-07-20 13:53:52,797 Epoch[20] Batch [20]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.111569,	
2017-07-20 13:53:57,140 Epoch[20] Batch [30]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.111252,	
2017-07-20 13:54:01,222 Epoch[20] Batch [40]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111054,	
2017-07-20 13:54:05,541 Epoch[20] Batch [50]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.108392,	
2017-07-20 13:54:09,730 Epoch[20] Batch [60]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108560,	
2017-07-20 13:54:13,835 Epoch[20] Batch [70]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.107837,	
2017-07-20 13:54:18,177 Epoch[20] Batch [80]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.107674,	
2017-07-20 13:54:22,524 Epoch[20] Batch [90]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.106645,	
2017-07-20 13:54:26,599 Epoch[20] Batch [100]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105788,	
2017-07-20 13:54:30,823 Epoch[20] Batch [110]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105032,	
2017-07-20 13:54:34,708 Epoch[20] Batch [120]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.104994,	
2017-07-20 13:54:38,855 Epoch[20] Batch [130]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104333,	
2017-07-20 13:54:42,845 Epoch[20] Batch [140]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105334,	
2017-07-20 13:54:46,937 Epoch[20] Batch [150]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.105670,	
2017-07-20 13:54:51,010 Epoch[20] Batch [160]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105636,	
2017-07-20 13:54:55,011 Epoch[20] Batch [170]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106310,	
2017-07-20 13:54:59,144 Epoch[20] Batch [180]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105741,	
2017-07-20 13:55:03,254 Epoch[20] Batch [190]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105860,	
2017-07-20 13:55:07,420 Epoch[20] Batch [200]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.106075,	
2017-07-20 13:55:11,674 Epoch[20] Batch [210]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.106471,	
2017-07-20 13:55:15,719 Epoch[20] Batch [220]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.106370,	
2017-07-20 13:55:19,837 Epoch[20] Batch [230]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.106048,	
2017-07-20 13:55:24,008 Epoch[20] Batch [240]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106036,	
2017-07-20 13:55:28,044 Epoch[20] Batch [250]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.106414,	
2017-07-20 13:55:32,172 Epoch[20] Batch [260]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.106741,	
2017-07-20 13:55:36,337 Epoch[20] Batch [270]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.106469,	
2017-07-20 13:55:40,427 Epoch[20] Batch [280]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106623,	
2017-07-20 13:55:44,564 Epoch[20] Batch [290]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.107045,	
2017-07-20 13:55:48,709 Epoch[20] Batch [300]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.107537,	
2017-07-20 13:55:52,787 Epoch[20] Batch [310]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.107927,	
2017-07-20 13:55:56,952 Epoch[20] Batch [320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.108076,	
2017-07-20 13:56:01,045 Epoch[20] Batch [330]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.107913,	
2017-07-20 13:56:05,302 Epoch[20] Batch [340]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.107836,	
2017-07-20 13:56:09,449 Epoch[20] Batch [350]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.108134,	
2017-07-20 13:56:13,552 Epoch[20] Batch [360]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109155,	
2017-07-20 13:56:17,763 Epoch[20] Batch [370]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.109464,	
2017-07-20 13:56:21,824 Epoch[20] Batch [380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109543,	
2017-07-20 13:56:25,930 Epoch[20] Batch [390]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.109714,	
2017-07-20 13:56:29,975 Epoch[20] Batch [400]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110128,	
2017-07-20 13:56:34,036 Epoch[20] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110257,	
2017-07-20 13:56:38,236 Epoch[20] Batch [420]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.110648,	
2017-07-20 13:56:42,331 Epoch[20] Batch [430]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110756,	
2017-07-20 13:56:46,341 Epoch[20] Batch [440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.110823,	
2017-07-20 13:56:50,366 Epoch[20] Batch [450]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110763,	
2017-07-20 13:56:54,505 Epoch[20] Batch [460]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110817,	
2017-07-20 13:56:58,648 Epoch[20] Batch [470]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110879,	
2017-07-20 13:57:02,721 Epoch[20] Batch [480]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.110712,	
2017-07-20 13:57:06,764 Epoch[20] Batch [490]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110336,	
2017-07-20 13:57:10,868 Epoch[20] Batch [500]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.110331,	
2017-07-20 13:57:14,906 Epoch[20] Batch [510]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.110125,	
2017-07-20 13:57:19,049 Epoch[20] Batch [520]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.109997,	
2017-07-20 13:57:23,104 Epoch[20] Batch [530]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.109913,	
2017-07-20 13:57:27,227 Epoch[20] Batch [540]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.109861,	
2017-07-20 13:57:31,258 Epoch[20] Batch [550]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.109792,	
2017-07-20 13:57:35,255 Epoch[20] Batch [560]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.109996,	
2017-07-20 13:57:39,394 Epoch[20] Batch [570]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110049,	
2017-07-20 13:57:43,494 Epoch[20] Batch [580]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110288,	
2017-07-20 13:57:47,637 Epoch[20] Batch [590]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.110240,	
2017-07-20 13:57:51,773 Epoch[20] Batch [600]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.110143,	
2017-07-20 13:57:55,723 Epoch[20] Batch [610]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.110140,	
2017-07-20 13:58:00,001 Epoch[20] Batch [620]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.110038,	
2017-07-20 13:58:04,054 Epoch[20] Batch [630]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.110077,	
2017-07-20 13:58:08,133 Epoch[20] Batch [640]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109860,	
2017-07-20 13:58:12,140 Epoch[20] Batch [650]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.109694,	
2017-07-20 13:58:16,197 Epoch[20] Batch [660]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.109573,	
2017-07-20 13:58:20,329 Epoch[20] Batch [670]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109631,	
2017-07-20 13:58:24,370 Epoch[20] Batch [680]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109669,	
2017-07-20 13:58:28,451 Epoch[20] Batch [690]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109513,	
2017-07-20 13:58:32,582 Epoch[20] Batch [700]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.109419,	
2017-07-20 13:58:36,773 Epoch[20] Batch [710]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.109409,	
2017-07-20 13:58:40,948 Epoch[20] Batch [720]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109483,	
2017-07-20 13:58:45,164 Epoch[20] Batch [730]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109413,	
2017-07-20 13:58:49,321 Epoch[20] Batch [740]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109186,	
2017-07-20 13:58:53,470 Epoch[20] Batch [750]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.109008,	
2017-07-20 13:58:57,548 Epoch[20] Batch [760]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109043,	
2017-07-20 13:59:01,650 Epoch[20] Batch [770]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109107,	
2017-07-20 13:59:05,562 Epoch[20] Batch [780]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.109138,	
2017-07-20 13:59:09,624 Epoch[20] Batch [790]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109084,	
2017-07-20 13:59:13,713 Epoch[20] Batch [800]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109139,	
2017-07-20 13:59:17,769 Epoch[20] Batch [810]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.109132,	
2017-07-20 13:59:21,884 Epoch[20] Batch [820]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109138,	
2017-07-20 13:59:25,956 Epoch[20] Batch [830]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.109164,	
2017-07-20 13:59:30,076 Epoch[20] Batch [840]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.109143,	
2017-07-20 13:59:34,077 Epoch[20] Batch [850]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109186,	
2017-07-20 13:59:38,283 Epoch[20] Batch [860]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.109191,	
2017-07-20 13:59:42,282 Epoch[20] Batch [870]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109132,	
2017-07-20 13:59:46,467 Epoch[20] Batch [880]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.109202,	
2017-07-20 13:59:50,571 Epoch[20] Batch [890]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109134,	
2017-07-20 13:59:54,798 Epoch[20] Batch [900]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.109057,	
2017-07-20 13:59:58,959 Epoch[20] Batch [910]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.109128,	
2017-07-20 14:00:03,083 Epoch[20] Batch [920]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.109089,	
2017-07-20 14:00:07,247 Epoch[20] Batch [930]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.109058,	
2017-07-20 14:00:11,604 Epoch[20] Batch [940]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.108892,	
2017-07-20 14:00:15,841 Epoch[20] Batch [950]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108722,	
2017-07-20 14:00:20,080 Epoch[20] Batch [960]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108628,	
2017-07-20 14:00:24,361 Epoch[20] Batch [970]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.108652,	
2017-07-20 14:00:28,479 Epoch[20] Batch [980]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.108680,	
2017-07-20 14:00:32,801 Epoch[20] Batch [990]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.108672,	
2017-07-20 14:00:37,136 Epoch[20] Batch [1000]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.108645,	
2017-07-20 14:00:41,337 Epoch[20] Batch [1010]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.108543,	
2017-07-20 14:00:45,373 Epoch[20] Batch [1020]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.108419,	
2017-07-20 14:00:49,572 Epoch[20] Batch [1030]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.108493,	
2017-07-20 14:00:53,760 Epoch[20] Batch [1040]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108503,	
2017-07-20 14:00:57,909 Epoch[20] Batch [1050]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.108493,	
2017-07-20 14:01:02,222 Epoch[20] Batch [1060]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.108551,	
2017-07-20 14:01:06,430 Epoch[20] Batch [1070]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.108566,	
2017-07-20 14:01:10,799 Epoch[20] Batch [1080]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.108585,	
2017-07-20 14:01:14,924 Epoch[20] Batch [1090]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.108614,	
2017-07-20 14:01:19,006 Epoch[20] Batch [1100]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108488,	
2017-07-20 14:01:23,238 Epoch[20] Batch [1110]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.108424,	
2017-07-20 14:01:27,511 Epoch[20] Batch [1120]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.108463,	
2017-07-20 14:01:31,748 Epoch[20] Batch [1130]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108479,	
2017-07-20 14:01:35,834 Epoch[20] Batch [1140]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.108382,	
2017-07-20 14:01:40,144 Epoch[20] Batch [1150]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.108327,	
2017-07-20 14:01:44,494 Epoch[20] Batch [1160]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.108312,	
2017-07-20 14:01:48,802 Epoch[20] Batch [1170]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.108223,	
2017-07-20 14:01:52,956 Epoch[20] Batch [1180]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.108123,	
2017-07-20 14:01:57,221 Epoch[20] Batch [1190]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.108007,	
2017-07-20 14:02:01,284 Epoch[20] Batch [1200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.107962,	
2017-07-20 14:02:05,627 Epoch[20] Batch [1210]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.107926,	
2017-07-20 14:02:09,837 Epoch[20] Batch [1220]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.107975,	
2017-07-20 14:02:14,054 Epoch[20] Batch [1230]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.107986,	
2017-07-20 14:02:18,298 Epoch[20] Batch [1240]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.108049,	
2017-07-20 14:02:22,636 Epoch[20] Batch [1250]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.108051,	
2017-07-20 14:02:26,654 Epoch[20] Batch [1260]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.107987,	
2017-07-20 14:02:30,838 Epoch[20] Batch [1270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.108054,	
2017-07-20 14:02:35,250 Epoch[20] Batch [1280]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.108066,	
2017-07-20 14:02:39,578 Epoch[20] Batch [1290]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.108118,	
2017-07-20 14:02:43,726 Epoch[20] Batch [1300]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.108124,	
2017-07-20 14:02:47,976 Epoch[20] Batch [1310]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.108118,	
2017-07-20 14:02:52,289 Epoch[20] Batch [1320]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.108156,	
2017-07-20 14:02:56,393 Epoch[20] Batch [1330]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.108172,	
2017-07-20 14:03:00,821 Epoch[20] Batch [1340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.108135,	
2017-07-20 14:03:04,955 Epoch[20] Batch [1350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108039,	
2017-07-20 14:03:09,159 Epoch[20] Batch [1360]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.108022,	
2017-07-20 14:03:13,450 Epoch[20] Batch [1370]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.108014,	
2017-07-20 14:03:17,809 Epoch[20] Batch [1380]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.107995,	
2017-07-20 14:03:21,986 Epoch[20] Batch [1390]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.107945,	
2017-07-20 14:03:26,218 Epoch[20] Batch [1400]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.107937,	
2017-07-20 14:03:30,446 Epoch[20] Batch [1410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.107912,	
2017-07-20 14:03:34,671 Epoch[20] Batch [1420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.107866,	
2017-07-20 14:03:38,885 Epoch[20] Batch [1430]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.107835,	
2017-07-20 14:03:43,235 Epoch[20] Batch [1440]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.107822,	
2017-07-20 14:03:47,403 Epoch[20] Batch [1450]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.107895,	
2017-07-20 14:03:51,549 Epoch[20] Batch [1460]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.107875,	
2017-07-20 14:03:55,744 Epoch[20] Batch [1470]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.107842,	
2017-07-20 14:04:00,053 Epoch[20] Batch [1480]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.107844,	
2017-07-20 14:04:02,654 Epoch[20] Train-FCNLogLoss=0.107886
2017-07-20 14:04:02,655 Epoch[20] Time cost=618.971
2017-07-20 14:04:03,416 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0021.params"
2017-07-20 14:04:04,952 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0021.states"
2017-07-20 14:04:09,826 Epoch[21] Batch [10]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.093605,	
2017-07-20 14:04:14,169 Epoch[21] Batch [20]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.101261,	
2017-07-20 14:04:18,207 Epoch[21] Batch [30]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101573,	
2017-07-20 14:04:22,462 Epoch[21] Batch [40]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.102301,	
2017-07-20 14:04:26,725 Epoch[21] Batch [50]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.102979,	
2017-07-20 14:04:31,127 Epoch[21] Batch [60]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.103343,	
2017-07-20 14:04:35,505 Epoch[21] Batch [70]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.103313,	
2017-07-20 14:04:39,870 Epoch[21] Batch [80]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.104043,	
2017-07-20 14:04:44,257 Epoch[21] Batch [90]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.105775,	
2017-07-20 14:04:48,522 Epoch[21] Batch [100]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.106157,	
2017-07-20 14:04:52,670 Epoch[21] Batch [110]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105495,	
2017-07-20 14:04:56,800 Epoch[21] Batch [120]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.106143,	
2017-07-20 14:05:00,948 Epoch[21] Batch [130]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105852,	
2017-07-20 14:05:05,050 Epoch[21] Batch [140]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.106574,	
2017-07-20 14:05:09,186 Epoch[21] Batch [150]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.106513,	
2017-07-20 14:05:13,234 Epoch[21] Batch [160]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106714,	
2017-07-20 14:05:17,301 Epoch[21] Batch [170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.106433,	
2017-07-20 14:05:21,485 Epoch[21] Batch [180]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.107226,	
2017-07-20 14:05:25,541 Epoch[21] Batch [190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110800,	
2017-07-20 14:05:29,567 Epoch[21] Batch [200]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111045,	
2017-07-20 14:05:33,661 Epoch[21] Batch [210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113525,	
2017-07-20 14:05:37,711 Epoch[21] Batch [220]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.114266,	
2017-07-20 14:05:41,883 Epoch[21] Batch [230]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.115477,	
2017-07-20 14:05:46,001 Epoch[21] Batch [240]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.115893,	
2017-07-20 14:05:50,144 Epoch[21] Batch [250]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115899,	
2017-07-20 14:05:54,251 Epoch[21] Batch [260]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115725,	
2017-07-20 14:05:58,483 Epoch[21] Batch [270]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.115554,	
2017-07-20 14:06:02,503 Epoch[21] Batch [280]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115470,	
2017-07-20 14:06:06,438 Epoch[21] Batch [290]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.114883,	
2017-07-20 14:06:10,524 Epoch[21] Batch [300]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115374,	
2017-07-20 14:06:14,636 Epoch[21] Batch [310]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.115375,	
2017-07-20 14:06:18,792 Epoch[21] Batch [320]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.115213,	
2017-07-20 14:06:22,857 Epoch[21] Batch [330]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.114901,	
2017-07-20 14:06:27,114 Epoch[21] Batch [340]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.115378,	
2017-07-20 14:06:31,271 Epoch[21] Batch [350]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.115752,	
2017-07-20 14:06:35,353 Epoch[21] Batch [360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116058,	
2017-07-20 14:06:39,605 Epoch[21] Batch [370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.117061,	
2017-07-20 14:06:43,749 Epoch[21] Batch [380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.117306,	
2017-07-20 14:06:47,908 Epoch[21] Batch [390]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.117417,	
2017-07-20 14:06:52,037 Epoch[21] Batch [400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117141,	
2017-07-20 14:06:56,014 Epoch[21] Batch [410]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.117008,	
2017-07-20 14:07:00,220 Epoch[21] Batch [420]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.116988,	
2017-07-20 14:07:04,314 Epoch[21] Batch [430]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117616,	
2017-07-20 14:07:08,344 Epoch[21] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117840,	
2017-07-20 14:07:12,348 Epoch[21] Batch [450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.118037,	
2017-07-20 14:07:16,531 Epoch[21] Batch [460]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.118081,	
2017-07-20 14:07:20,638 Epoch[21] Batch [470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.118067,	
2017-07-20 14:07:24,804 Epoch[21] Batch [480]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.117896,	
2017-07-20 14:07:28,959 Epoch[21] Batch [490]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.117727,	
2017-07-20 14:07:33,178 Epoch[21] Batch [500]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.117554,	
2017-07-20 14:07:37,349 Epoch[21] Batch [510]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.117397,	
2017-07-20 14:07:41,442 Epoch[21] Batch [520]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117452,	
2017-07-20 14:07:45,663 Epoch[21] Batch [530]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.117349,	
2017-07-20 14:07:49,829 Epoch[21] Batch [540]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.117149,	
2017-07-20 14:07:53,983 Epoch[21] Batch [550]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.117247,	
2017-07-20 14:07:58,110 Epoch[21] Batch [560]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117058,	
2017-07-20 14:08:02,163 Epoch[21] Batch [570]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.117140,	
2017-07-20 14:08:06,281 Epoch[21] Batch [580]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.116942,	
2017-07-20 14:08:10,483 Epoch[21] Batch [590]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.117011,	
2017-07-20 14:08:14,563 Epoch[21] Batch [600]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116972,	
2017-07-20 14:08:18,758 Epoch[21] Batch [610]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.116858,	
2017-07-20 14:08:22,945 Epoch[21] Batch [620]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.116741,	
2017-07-20 14:08:27,101 Epoch[21] Batch [630]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.116764,	
2017-07-20 14:08:31,170 Epoch[21] Batch [640]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116651,	
2017-07-20 14:08:35,282 Epoch[21] Batch [650]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116718,	
2017-07-20 14:08:39,303 Epoch[21] Batch [660]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116736,	
2017-07-20 14:08:43,354 Epoch[21] Batch [670]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.116595,	
2017-07-20 14:08:47,551 Epoch[21] Batch [680]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.116734,	
2017-07-20 14:08:51,630 Epoch[21] Batch [690]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116763,	
2017-07-20 14:08:55,767 Epoch[21] Batch [700]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.116548,	
2017-07-20 14:08:59,827 Epoch[21] Batch [710]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116642,	
2017-07-20 14:09:03,805 Epoch[21] Batch [720]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.116646,	
2017-07-20 14:09:07,904 Epoch[21] Batch [730]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116548,	
2017-07-20 14:09:11,934 Epoch[21] Batch [740]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116425,	
2017-07-20 14:09:16,024 Epoch[21] Batch [750]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116384,	
2017-07-20 14:09:20,129 Epoch[21] Batch [760]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.116252,	
2017-07-20 14:09:24,091 Epoch[21] Batch [770]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.116083,	
2017-07-20 14:09:28,154 Epoch[21] Batch [780]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.115983,	
2017-07-20 14:09:32,250 Epoch[21] Batch [790]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.115881,	
2017-07-20 14:09:36,311 Epoch[21] Batch [800]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.115894,	
2017-07-20 14:09:40,453 Epoch[21] Batch [810]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115692,	
2017-07-20 14:09:44,435 Epoch[21] Batch [820]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.115663,	
2017-07-20 14:09:48,571 Epoch[21] Batch [830]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.115767,	
2017-07-20 14:09:52,531 Epoch[21] Batch [840]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.115609,	
2017-07-20 14:09:56,590 Epoch[21] Batch [850]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115491,	
2017-07-20 14:10:00,713 Epoch[21] Batch [860]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.115588,	
2017-07-20 14:10:04,791 Epoch[21] Batch [870]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115428,	
2017-07-20 14:10:08,894 Epoch[21] Batch [880]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.115530,	
2017-07-20 14:10:12,954 Epoch[21] Batch [890]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.115468,	
2017-07-20 14:10:17,011 Epoch[21] Batch [900]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115388,	
2017-07-20 14:10:21,099 Epoch[21] Batch [910]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115281,	
2017-07-20 14:10:25,288 Epoch[21] Batch [920]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.115035,	
2017-07-20 14:10:29,490 Epoch[21] Batch [930]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.114970,	
2017-07-20 14:10:33,620 Epoch[21] Batch [940]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.114986,	
2017-07-20 14:10:37,867 Epoch[21] Batch [950]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.114920,	
2017-07-20 14:10:42,234 Epoch[21] Batch [960]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.114898,	
2017-07-20 14:10:46,646 Epoch[21] Batch [970]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.114781,	
2017-07-20 14:10:50,772 Epoch[21] Batch [980]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.114737,	
2017-07-20 14:10:55,011 Epoch[21] Batch [990]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.114623,	
2017-07-20 14:10:59,309 Epoch[21] Batch [1000]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.114596,	
2017-07-20 14:11:03,570 Epoch[21] Batch [1010]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.114436,	
2017-07-20 14:11:07,981 Epoch[21] Batch [1020]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.114311,	
2017-07-20 14:11:12,079 Epoch[21] Batch [1030]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.114283,	
2017-07-20 14:11:16,381 Epoch[21] Batch [1040]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.114179,	
2017-07-20 14:11:20,530 Epoch[21] Batch [1050]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.114096,	
2017-07-20 14:11:24,840 Epoch[21] Batch [1060]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.113954,	
2017-07-20 14:11:29,087 Epoch[21] Batch [1070]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.113910,	
2017-07-20 14:11:33,455 Epoch[21] Batch [1080]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.113762,	
2017-07-20 14:11:37,619 Epoch[21] Batch [1090]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.113693,	
2017-07-20 14:11:41,937 Epoch[21] Batch [1100]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.113658,	
2017-07-20 14:11:46,303 Epoch[21] Batch [1110]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.113662,	
2017-07-20 14:11:50,495 Epoch[21] Batch [1120]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.113539,	
2017-07-20 14:11:54,707 Epoch[21] Batch [1130]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.113494,	
2017-07-20 14:11:58,865 Epoch[21] Batch [1140]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113499,	
2017-07-20 14:12:03,173 Epoch[21] Batch [1150]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.113318,	
2017-07-20 14:12:07,499 Epoch[21] Batch [1160]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.113243,	
2017-07-20 14:12:11,746 Epoch[21] Batch [1170]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.113130,	
2017-07-20 14:12:16,057 Epoch[21] Batch [1180]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.113103,	
2017-07-20 14:12:20,200 Epoch[21] Batch [1190]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.112984,	
2017-07-20 14:12:24,506 Epoch[21] Batch [1200]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112998,	
2017-07-20 14:12:28,794 Epoch[21] Batch [1210]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.112962,	
2017-07-20 14:12:33,070 Epoch[21] Batch [1220]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.112900,	
2017-07-20 14:12:37,316 Epoch[21] Batch [1230]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.112869,	
2017-07-20 14:12:41,716 Epoch[21] Batch [1240]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.112881,	
2017-07-20 14:12:45,842 Epoch[21] Batch [1250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112852,	
2017-07-20 14:12:50,066 Epoch[21] Batch [1260]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.112755,	
2017-07-20 14:12:54,379 Epoch[21] Batch [1270]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.112730,	
2017-07-20 14:12:58,583 Epoch[21] Batch [1280]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.112687,	
2017-07-20 14:13:02,767 Epoch[21] Batch [1290]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112637,	
2017-07-20 14:13:06,951 Epoch[21] Batch [1300]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112575,	
2017-07-20 14:13:11,206 Epoch[21] Batch [1310]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.112528,	
2017-07-20 14:13:15,478 Epoch[21] Batch [1320]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.112519,	
2017-07-20 14:13:19,795 Epoch[21] Batch [1330]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.112501,	
2017-07-20 14:13:24,222 Epoch[21] Batch [1340]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.112545,	
2017-07-20 14:13:28,295 Epoch[21] Batch [1350]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112542,	
2017-07-20 14:13:32,584 Epoch[21] Batch [1360]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.112463,	
2017-07-20 14:13:36,703 Epoch[21] Batch [1370]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112367,	
2017-07-20 14:13:40,939 Epoch[21] Batch [1380]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.112320,	
2017-07-20 14:13:45,175 Epoch[21] Batch [1390]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.112298,	
2017-07-20 14:13:49,478 Epoch[21] Batch [1400]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.112271,	
2017-07-20 14:13:53,702 Epoch[21] Batch [1410]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.112238,	
2017-07-20 14:13:57,877 Epoch[21] Batch [1420]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112136,	
2017-07-20 14:14:02,100 Epoch[21] Batch [1430]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.112145,	
2017-07-20 14:14:06,533 Epoch[21] Batch [1440]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.112089,	
2017-07-20 14:14:10,768 Epoch[21] Batch [1450]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.111955,	
2017-07-20 14:14:15,151 Epoch[21] Batch [1460]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.111882,	
2017-07-20 14:14:19,311 Epoch[21] Batch [1470]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.111765,	
2017-07-20 14:14:23,682 Epoch[21] Batch [1480]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.111716,	
2017-07-20 14:14:26,243 Epoch[21] Train-FCNLogLoss=0.111687
2017-07-20 14:14:26,244 Epoch[21] Time cost=621.291
2017-07-20 14:14:26,984 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0022.params"
2017-07-20 14:14:28,469 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0022.states"
2017-07-20 14:14:33,374 Epoch[22] Batch [10]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.105483,	
2017-07-20 14:14:37,522 Epoch[22] Batch [20]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.106232,	
2017-07-20 14:14:41,546 Epoch[22] Batch [30]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105200,	
2017-07-20 14:14:45,686 Epoch[22] Batch [40]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.105020,	
2017-07-20 14:14:49,852 Epoch[22] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.105250,	
2017-07-20 14:14:54,143 Epoch[22] Batch [60]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.104053,	
2017-07-20 14:14:58,536 Epoch[22] Batch [70]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.104057,	
2017-07-20 14:15:02,895 Epoch[22] Batch [80]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104530,	
2017-07-20 14:15:07,114 Epoch[22] Batch [90]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.105436,	
2017-07-20 14:15:11,137 Epoch[22] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105335,	
2017-07-20 14:15:15,289 Epoch[22] Batch [110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105149,	
2017-07-20 14:15:19,327 Epoch[22] Batch [120]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105732,	
2017-07-20 14:15:23,486 Epoch[22] Batch [130]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.105892,	
2017-07-20 14:15:27,619 Epoch[22] Batch [140]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105453,	
2017-07-20 14:15:31,860 Epoch[22] Batch [150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106513,	
2017-07-20 14:15:36,054 Epoch[22] Batch [160]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.106623,	
2017-07-20 14:15:40,278 Epoch[22] Batch [170]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.106728,	
2017-07-20 14:15:44,498 Epoch[22] Batch [180]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.107063,	
2017-07-20 14:15:48,838 Epoch[22] Batch [190]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.107067,	
2017-07-20 14:15:52,896 Epoch[22] Batch [200]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.106923,	
2017-07-20 14:15:56,942 Epoch[22] Batch [210]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.107337,	
2017-07-20 14:16:01,061 Epoch[22] Batch [220]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.107950,	
2017-07-20 14:16:05,260 Epoch[22] Batch [230]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.108008,	
2017-07-20 14:16:09,370 Epoch[22] Batch [240]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.107774,	
2017-07-20 14:16:13,410 Epoch[22] Batch [250]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.107197,	
2017-07-20 14:16:17,428 Epoch[22] Batch [260]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.107328,	
2017-07-20 14:16:21,438 Epoch[22] Batch [270]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.107231,	
2017-07-20 14:16:25,446 Epoch[22] Batch [280]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.106881,	
2017-07-20 14:16:29,632 Epoch[22] Batch [290]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.106326,	
2017-07-20 14:16:33,840 Epoch[22] Batch [300]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.106195,	
2017-07-20 14:16:37,984 Epoch[22] Batch [310]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106425,	
2017-07-20 14:16:42,052 Epoch[22] Batch [320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106431,	
2017-07-20 14:16:46,270 Epoch[22] Batch [330]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.106503,	
2017-07-20 14:16:50,465 Epoch[22] Batch [340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.106444,	
2017-07-20 14:16:54,604 Epoch[22] Batch [350]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.106323,	
2017-07-20 14:16:58,778 Epoch[22] Batch [360]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.106478,	
2017-07-20 14:17:03,082 Epoch[22] Batch [370]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.106339,	
2017-07-20 14:17:07,328 Epoch[22] Batch [380]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.106329,	
2017-07-20 14:17:11,412 Epoch[22] Batch [390]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106530,	
2017-07-20 14:17:15,578 Epoch[22] Batch [400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.106976,	
2017-07-20 14:17:19,724 Epoch[22] Batch [410]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.107096,	
2017-07-20 14:17:23,874 Epoch[22] Batch [420]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107136,	
2017-07-20 14:17:27,905 Epoch[22] Batch [430]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.107285,	
2017-07-20 14:17:31,919 Epoch[22] Batch [440]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.107155,	
2017-07-20 14:17:36,203 Epoch[22] Batch [450]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.107460,	
2017-07-20 14:17:40,333 Epoch[22] Batch [460]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.107711,	
2017-07-20 14:17:44,477 Epoch[22] Batch [470]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.107557,	
2017-07-20 14:17:48,508 Epoch[22] Batch [480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.107688,	
2017-07-20 14:17:52,748 Epoch[22] Batch [490]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.107611,	
2017-07-20 14:17:56,863 Epoch[22] Batch [500]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.107402,	
2017-07-20 14:18:01,017 Epoch[22] Batch [510]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.107385,	
2017-07-20 14:18:05,148 Epoch[22] Batch [520]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.107387,	
2017-07-20 14:18:09,255 Epoch[22] Batch [530]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.107397,	
2017-07-20 14:18:13,383 Epoch[22] Batch [540]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.107123,	
2017-07-20 14:18:17,562 Epoch[22] Batch [550]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.106992,	
2017-07-20 14:18:21,712 Epoch[22] Batch [560]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.106685,	
2017-07-20 14:18:25,925 Epoch[22] Batch [570]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106680,	
2017-07-20 14:18:30,028 Epoch[22] Batch [580]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.106625,	
2017-07-20 14:18:34,118 Epoch[22] Batch [590]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106615,	
2017-07-20 14:18:38,296 Epoch[22] Batch [600]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.106522,	
2017-07-20 14:18:42,281 Epoch[22] Batch [610]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.106383,	
2017-07-20 14:18:46,248 Epoch[22] Batch [620]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.106265,	
2017-07-20 14:18:50,419 Epoch[22] Batch [630]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106307,	
2017-07-20 14:18:54,525 Epoch[22] Batch [640]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.106099,	
2017-07-20 14:18:58,625 Epoch[22] Batch [650]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105894,	
2017-07-20 14:19:02,806 Epoch[22] Batch [660]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105912,	
2017-07-20 14:19:06,852 Epoch[22] Batch [670]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.105901,	
2017-07-20 14:19:11,042 Epoch[22] Batch [680]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.105965,	
2017-07-20 14:19:15,147 Epoch[22] Batch [690]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105933,	
2017-07-20 14:19:19,185 Epoch[22] Batch [700]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105937,	
2017-07-20 14:19:23,160 Epoch[22] Batch [710]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.105776,	
2017-07-20 14:19:27,223 Epoch[22] Batch [720]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105672,	
2017-07-20 14:19:31,147 Epoch[22] Batch [730]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.105523,	
2017-07-20 14:19:35,299 Epoch[22] Batch [740]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105479,	
2017-07-20 14:19:39,478 Epoch[22] Batch [750]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105651,	
2017-07-20 14:19:43,518 Epoch[22] Batch [760]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105696,	
2017-07-20 14:19:47,774 Epoch[22] Batch [770]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.105605,	
2017-07-20 14:19:51,735 Epoch[22] Batch [780]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.105689,	
2017-07-20 14:19:55,872 Epoch[22] Batch [790]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105731,	
2017-07-20 14:19:59,817 Epoch[22] Batch [800]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.105858,	
2017-07-20 14:20:03,828 Epoch[22] Batch [810]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.105922,	
2017-07-20 14:20:07,913 Epoch[22] Batch [820]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105668,	
2017-07-20 14:20:12,024 Epoch[22] Batch [830]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105706,	
2017-07-20 14:20:16,136 Epoch[22] Batch [840]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105744,	
2017-07-20 14:20:20,091 Epoch[22] Batch [850]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.105578,	
2017-07-20 14:20:24,258 Epoch[22] Batch [860]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.105470,	
2017-07-20 14:20:28,280 Epoch[22] Batch [870]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105583,	
2017-07-20 14:20:32,396 Epoch[22] Batch [880]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.105566,	
2017-07-20 14:20:36,343 Epoch[22] Batch [890]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.105568,	
2017-07-20 14:20:40,412 Epoch[22] Batch [900]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105671,	
2017-07-20 14:20:44,526 Epoch[22] Batch [910]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.105707,	
2017-07-20 14:20:48,747 Epoch[22] Batch [920]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.105665,	
2017-07-20 14:20:52,981 Epoch[22] Batch [930]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.105646,	
2017-07-20 14:20:57,156 Epoch[22] Batch [940]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.105654,	
2017-07-20 14:21:01,393 Epoch[22] Batch [950]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.105516,	
2017-07-20 14:21:05,540 Epoch[22] Batch [960]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105461,	
2017-07-20 14:21:09,658 Epoch[22] Batch [970]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105340,	
2017-07-20 14:21:13,785 Epoch[22] Batch [980]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.105334,	
2017-07-20 14:21:18,042 Epoch[22] Batch [990]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.105371,	
2017-07-20 14:21:22,190 Epoch[22] Batch [1000]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105333,	
2017-07-20 14:21:26,519 Epoch[22] Batch [1010]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.105283,	
2017-07-20 14:21:30,804 Epoch[22] Batch [1020]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.105386,	
2017-07-20 14:21:35,038 Epoch[22] Batch [1030]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.105364,	
2017-07-20 14:21:39,258 Epoch[22] Batch [1040]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.105305,	
2017-07-20 14:21:43,515 Epoch[22] Batch [1050]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.105220,	
2017-07-20 14:21:47,823 Epoch[22] Batch [1060]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.105158,	
2017-07-20 14:21:52,059 Epoch[22] Batch [1070]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.105159,	
2017-07-20 14:21:56,224 Epoch[22] Batch [1080]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105138,	
2017-07-20 14:22:00,409 Epoch[22] Batch [1090]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.105176,	
2017-07-20 14:22:04,611 Epoch[22] Batch [1100]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.105240,	
2017-07-20 14:22:08,878 Epoch[22] Batch [1110]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.105372,	
2017-07-20 14:22:13,135 Epoch[22] Batch [1120]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.105173,	
2017-07-20 14:22:17,383 Epoch[22] Batch [1130]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.105169,	
2017-07-20 14:22:21,515 Epoch[22] Batch [1140]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105125,	
2017-07-20 14:22:25,813 Epoch[22] Batch [1150]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105017,	
2017-07-20 14:22:30,119 Epoch[22] Batch [1160]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.105106,	
2017-07-20 14:22:34,415 Epoch[22] Batch [1170]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105028,	
2017-07-20 14:22:38,755 Epoch[22] Batch [1180]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.104995,	
2017-07-20 14:22:42,935 Epoch[22] Batch [1190]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.104971,	
2017-07-20 14:22:47,169 Epoch[22] Batch [1200]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.104912,	
2017-07-20 14:22:51,534 Epoch[22] Batch [1210]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104878,	
2017-07-20 14:22:55,669 Epoch[22] Batch [1220]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104836,	
2017-07-20 14:22:59,880 Epoch[22] Batch [1230]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.104835,	
2017-07-20 14:23:04,106 Epoch[22] Batch [1240]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.104784,	
2017-07-20 14:23:08,466 Epoch[22] Batch [1250]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104773,	
2017-07-20 14:23:12,602 Epoch[22] Batch [1260]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104803,	
2017-07-20 14:23:16,939 Epoch[22] Batch [1270]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.104863,	
2017-07-20 14:23:21,178 Epoch[22] Batch [1280]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.104820,	
2017-07-20 14:23:25,395 Epoch[22] Batch [1290]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.104808,	
2017-07-20 14:23:29,762 Epoch[22] Batch [1300]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.104789,	
2017-07-20 14:23:33,834 Epoch[22] Batch [1310]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104862,	
2017-07-20 14:23:38,011 Epoch[22] Batch [1320]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.104847,	
2017-07-20 14:23:42,178 Epoch[22] Batch [1330]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104853,	
2017-07-20 14:23:46,427 Epoch[22] Batch [1340]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.104760,	
2017-07-20 14:23:50,591 Epoch[22] Batch [1350]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.104737,	
2017-07-20 14:23:54,901 Epoch[22] Batch [1360]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.104740,	
2017-07-20 14:23:59,226 Epoch[22] Batch [1370]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.104768,	
2017-07-20 14:24:03,369 Epoch[22] Batch [1380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104644,	
2017-07-20 14:24:07,607 Epoch[22] Batch [1390]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.104642,	
2017-07-20 14:24:11,805 Epoch[22] Batch [1400]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.104614,	
2017-07-20 14:24:15,956 Epoch[22] Batch [1410]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.104672,	
2017-07-20 14:24:20,224 Epoch[22] Batch [1420]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.104669,	
2017-07-20 14:24:24,529 Epoch[22] Batch [1430]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.104626,	
2017-07-20 14:24:28,769 Epoch[22] Batch [1440]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.104605,	
2017-07-20 14:24:33,134 Epoch[22] Batch [1450]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.104560,	
2017-07-20 14:24:37,403 Epoch[22] Batch [1460]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.104496,	
2017-07-20 14:24:41,692 Epoch[22] Batch [1470]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.104526,	
2017-07-20 14:24:45,915 Epoch[22] Batch [1480]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.104579,	
2017-07-20 14:24:48,350 Epoch[22] Train-FCNLogLoss=0.104583
2017-07-20 14:24:48,351 Epoch[22] Time cost=619.882
2017-07-20 14:24:49,183 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0023.params"
2017-07-20 14:24:50,710 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0023.states"
2017-07-20 14:24:55,751 Epoch[23] Batch [10]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.101354,	
2017-07-20 14:24:59,965 Epoch[23] Batch [20]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097496,	
2017-07-20 14:25:04,129 Epoch[23] Batch [30]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.100531,	
2017-07-20 14:25:08,420 Epoch[23] Batch [40]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.098524,	
2017-07-20 14:25:12,586 Epoch[23] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.098814,	
2017-07-20 14:25:16,723 Epoch[23] Batch [60]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097905,	
2017-07-20 14:25:20,856 Epoch[23] Batch [70]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.098023,	
2017-07-20 14:25:25,175 Epoch[23] Batch [80]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097307,	
2017-07-20 14:25:29,453 Epoch[23] Batch [90]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097955,	
2017-07-20 14:25:33,637 Epoch[23] Batch [100]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.098191,	
2017-07-20 14:25:37,700 Epoch[23] Batch [110]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097943,	
2017-07-20 14:25:41,757 Epoch[23] Batch [120]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098260,	
2017-07-20 14:25:45,889 Epoch[23] Batch [130]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.098510,	
2017-07-20 14:25:50,004 Epoch[23] Batch [140]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.098981,	
2017-07-20 14:25:54,202 Epoch[23] Batch [150]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.099025,	
2017-07-20 14:25:58,470 Epoch[23] Batch [160]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.098936,	
2017-07-20 14:26:02,503 Epoch[23] Batch [170]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.098725,	
2017-07-20 14:26:06,690 Epoch[23] Batch [180]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098646,	
2017-07-20 14:26:10,815 Epoch[23] Batch [190]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098677,	
2017-07-20 14:26:14,884 Epoch[23] Batch [200]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.098775,	
2017-07-20 14:26:19,014 Epoch[23] Batch [210]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.098722,	
2017-07-20 14:26:23,116 Epoch[23] Batch [220]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.098924,	
2017-07-20 14:26:27,219 Epoch[23] Batch [230]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.099759,	
2017-07-20 14:26:31,304 Epoch[23] Batch [240]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.099697,	
2017-07-20 14:26:35,394 Epoch[23] Batch [250]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100268,	
2017-07-20 14:26:39,539 Epoch[23] Batch [260]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.100585,	
2017-07-20 14:26:43,630 Epoch[23] Batch [270]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101047,	
2017-07-20 14:26:47,770 Epoch[23] Batch [280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.101136,	
2017-07-20 14:26:51,797 Epoch[23] Batch [290]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.101443,	
2017-07-20 14:26:55,904 Epoch[23] Batch [300]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.102732,	
2017-07-20 14:27:00,020 Epoch[23] Batch [310]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103409,	
2017-07-20 14:27:04,041 Epoch[23] Batch [320]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103556,	
2017-07-20 14:27:07,931 Epoch[23] Batch [330]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.103632,	
2017-07-20 14:27:12,121 Epoch[23] Batch [340]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.103710,	
2017-07-20 14:27:16,265 Epoch[23] Batch [350]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103666,	
2017-07-20 14:27:20,526 Epoch[23] Batch [360]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.103633,	
2017-07-20 14:27:24,605 Epoch[23] Batch [370]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103614,	
2017-07-20 14:27:28,761 Epoch[23] Batch [380]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103897,	
2017-07-20 14:27:32,973 Epoch[23] Batch [390]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.104054,	
2017-07-20 14:27:37,032 Epoch[23] Batch [400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.104212,	
2017-07-20 14:27:41,086 Epoch[23] Batch [410]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104341,	
2017-07-20 14:27:45,174 Epoch[23] Batch [420]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104219,	
2017-07-20 14:27:49,296 Epoch[23] Batch [430]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103955,	
2017-07-20 14:27:53,351 Epoch[23] Batch [440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104012,	
2017-07-20 14:27:57,495 Epoch[23] Batch [450]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104048,	
2017-07-20 14:28:01,633 Epoch[23] Batch [460]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104041,	
2017-07-20 14:28:05,738 Epoch[23] Batch [470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.104174,	
2017-07-20 14:28:09,863 Epoch[23] Batch [480]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.104118,	
2017-07-20 14:28:13,750 Epoch[23] Batch [490]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.104219,	
2017-07-20 14:28:17,964 Epoch[23] Batch [500]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.104320,	
2017-07-20 14:28:22,162 Epoch[23] Batch [510]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.104207,	
2017-07-20 14:28:26,368 Epoch[23] Batch [520]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.104624,	
2017-07-20 14:28:30,463 Epoch[23] Batch [530]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104486,	
2017-07-20 14:28:34,388 Epoch[23] Batch [540]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.104665,	
2017-07-20 14:28:38,515 Epoch[23] Batch [550]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.104406,	
2017-07-20 14:28:42,606 Epoch[23] Batch [560]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104655,	
2017-07-20 14:28:46,566 Epoch[23] Batch [570]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.104862,	
2017-07-20 14:28:50,660 Epoch[23] Batch [580]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104918,	
2017-07-20 14:28:54,697 Epoch[23] Batch [590]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104912,	
2017-07-20 14:28:58,905 Epoch[23] Batch [600]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.104894,	
2017-07-20 14:29:03,060 Epoch[23] Batch [610]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104680,	
2017-07-20 14:29:07,213 Epoch[23] Batch [620]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104702,	
2017-07-20 14:29:11,287 Epoch[23] Batch [630]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104985,	
2017-07-20 14:29:15,272 Epoch[23] Batch [640]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104851,	
2017-07-20 14:29:19,278 Epoch[23] Batch [650]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104871,	
2017-07-20 14:29:23,477 Epoch[23] Batch [660]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.104896,	
2017-07-20 14:29:27,499 Epoch[23] Batch [670]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104929,	
2017-07-20 14:29:31,611 Epoch[23] Batch [680]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105063,	
2017-07-20 14:29:35,720 Epoch[23] Batch [690]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105088,	
2017-07-20 14:29:39,786 Epoch[23] Batch [700]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105026,	
2017-07-20 14:29:44,011 Epoch[23] Batch [710]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105183,	
2017-07-20 14:29:48,152 Epoch[23] Batch [720]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.105056,	
2017-07-20 14:29:52,223 Epoch[23] Batch [730]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105110,	
2017-07-20 14:29:56,369 Epoch[23] Batch [740]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104955,	
2017-07-20 14:30:00,594 Epoch[23] Batch [750]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.104879,	
2017-07-20 14:30:04,706 Epoch[23] Batch [760]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.104767,	
2017-07-20 14:30:08,857 Epoch[23] Batch [770]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.104719,	
2017-07-20 14:30:12,906 Epoch[23] Batch [780]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104776,	
2017-07-20 14:30:17,043 Epoch[23] Batch [790]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104677,	
2017-07-20 14:30:21,130 Epoch[23] Batch [800]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104612,	
2017-07-20 14:30:25,287 Epoch[23] Batch [810]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104516,	
2017-07-20 14:30:29,350 Epoch[23] Batch [820]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.104600,	
2017-07-20 14:30:33,385 Epoch[23] Batch [830]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104494,	
2017-07-20 14:30:37,477 Epoch[23] Batch [840]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104698,	
2017-07-20 14:30:41,498 Epoch[23] Batch [850]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104678,	
2017-07-20 14:30:45,711 Epoch[23] Batch [860]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.104695,	
2017-07-20 14:30:49,829 Epoch[23] Batch [870]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104607,	
2017-07-20 14:30:53,823 Epoch[23] Batch [880]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.104617,	
2017-07-20 14:30:57,864 Epoch[23] Batch [890]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104721,	
2017-07-20 14:31:01,997 Epoch[23] Batch [900]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.104786,	
2017-07-20 14:31:06,174 Epoch[23] Batch [910]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.104718,	
2017-07-20 14:31:10,229 Epoch[23] Batch [920]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104899,	
2017-07-20 14:31:14,333 Epoch[23] Batch [930]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105418,	
2017-07-20 14:31:18,524 Epoch[23] Batch [940]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.105891,	
2017-07-20 14:31:22,710 Epoch[23] Batch [950]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.106133,	
2017-07-20 14:31:26,802 Epoch[23] Batch [960]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106093,	
2017-07-20 14:31:30,965 Epoch[23] Batch [970]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.106164,	
2017-07-20 14:31:35,137 Epoch[23] Batch [980]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106319,	
2017-07-20 14:31:39,185 Epoch[23] Batch [990]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106444,	
2017-07-20 14:31:43,210 Epoch[23] Batch [1000]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.106427,	
2017-07-20 14:31:47,422 Epoch[23] Batch [1010]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106502,	
2017-07-20 14:31:51,550 Epoch[23] Batch [1020]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.106808,	
2017-07-20 14:31:55,644 Epoch[23] Batch [1030]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.107032,	
2017-07-20 14:31:59,648 Epoch[23] Batch [1040]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.107118,	
2017-07-20 14:32:03,738 Epoch[23] Batch [1050]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.107188,	
2017-07-20 14:32:07,988 Epoch[23] Batch [1060]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.107242,	
2017-07-20 14:32:12,025 Epoch[23] Batch [1070]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.107231,	
2017-07-20 14:32:16,205 Epoch[23] Batch [1080]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.107285,	
2017-07-20 14:32:20,394 Epoch[23] Batch [1090]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.107234,	
2017-07-20 14:32:24,403 Epoch[23] Batch [1100]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.107325,	
2017-07-20 14:32:28,600 Epoch[23] Batch [1110]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.107277,	
2017-07-20 14:32:32,689 Epoch[23] Batch [1120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.107351,	
2017-07-20 14:32:36,790 Epoch[23] Batch [1130]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.107368,	
2017-07-20 14:32:40,919 Epoch[23] Batch [1140]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.107348,	
2017-07-20 14:32:44,998 Epoch[23] Batch [1150]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.107361,	
2017-07-20 14:32:49,068 Epoch[23] Batch [1160]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.107279,	
2017-07-20 14:32:53,176 Epoch[23] Batch [1170]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.107264,	
2017-07-20 14:32:57,311 Epoch[23] Batch [1180]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.107221,	
2017-07-20 14:33:01,460 Epoch[23] Batch [1190]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107302,	
2017-07-20 14:33:05,437 Epoch[23] Batch [1200]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.107234,	
2017-07-20 14:33:09,520 Epoch[23] Batch [1210]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.107189,	
2017-07-20 14:33:13,790 Epoch[23] Batch [1220]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.107179,	
2017-07-20 14:33:17,999 Epoch[23] Batch [1230]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.107172,	
2017-07-20 14:33:22,154 Epoch[23] Batch [1240]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.107054,	
2017-07-20 14:33:26,314 Epoch[23] Batch [1250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.107068,	
2017-07-20 14:33:30,528 Epoch[23] Batch [1260]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.107050,	
2017-07-20 14:33:34,589 Epoch[23] Batch [1270]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.107053,	
2017-07-20 14:33:38,617 Epoch[23] Batch [1280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107099,	
2017-07-20 14:33:42,664 Epoch[23] Batch [1290]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.107141,	
2017-07-20 14:33:46,847 Epoch[23] Batch [1300]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.107044,	
2017-07-20 14:33:51,083 Epoch[23] Batch [1310]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.107015,	
2017-07-20 14:33:55,150 Epoch[23] Batch [1320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106973,	
2017-07-20 14:33:59,308 Epoch[23] Batch [1330]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.106856,	
2017-07-20 14:34:03,379 Epoch[23] Batch [1340]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106943,	
2017-07-20 14:34:07,368 Epoch[23] Batch [1350]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.106935,	
2017-07-20 14:34:11,455 Epoch[23] Batch [1360]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.106857,	
2017-07-20 14:34:15,544 Epoch[23] Batch [1370]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106811,	
2017-07-20 14:34:19,732 Epoch[23] Batch [1380]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.106748,	
2017-07-20 14:34:23,918 Epoch[23] Batch [1390]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.106733,	
2017-07-20 14:34:28,065 Epoch[23] Batch [1400]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106744,	
2017-07-20 14:34:32,131 Epoch[23] Batch [1410]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.106707,	
2017-07-20 14:34:36,281 Epoch[23] Batch [1420]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.106647,	
2017-07-20 14:34:40,433 Epoch[23] Batch [1430]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106747,	
2017-07-20 14:34:44,553 Epoch[23] Batch [1440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.106802,	
2017-07-20 14:34:48,578 Epoch[23] Batch [1450]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.106866,	
2017-07-20 14:34:52,670 Epoch[23] Batch [1460]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106766,	
2017-07-20 14:34:56,758 Epoch[23] Batch [1470]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.106887,	
2017-07-20 14:35:00,840 Epoch[23] Batch [1480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106972,	
2017-07-20 14:35:03,277 Epoch[23] Train-FCNLogLoss=0.106995
2017-07-20 14:35:03,277 Epoch[23] Time cost=612.567
2017-07-20 14:35:04,085 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0024.params"
2017-07-20 14:35:05,774 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0024.states"
2017-07-20 14:35:10,648 Epoch[24] Batch [10]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.097808,	
2017-07-20 14:35:14,837 Epoch[24] Batch [20]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.101079,	
2017-07-20 14:35:18,912 Epoch[24] Batch [30]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105843,	
2017-07-20 14:35:23,038 Epoch[24] Batch [40]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.101959,	
2017-07-20 14:35:27,074 Epoch[24] Batch [50]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.102560,	
2017-07-20 14:35:31,243 Epoch[24] Batch [60]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.101840,	
2017-07-20 14:35:35,212 Epoch[24] Batch [70]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.103746,	
2017-07-20 14:35:39,283 Epoch[24] Batch [80]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104173,	
2017-07-20 14:35:43,336 Epoch[24] Batch [90]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105665,	
2017-07-20 14:35:47,564 Epoch[24] Batch [100]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.105775,	
2017-07-20 14:35:51,668 Epoch[24] Batch [110]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104899,	
2017-07-20 14:35:55,770 Epoch[24] Batch [120]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105895,	
2017-07-20 14:35:59,742 Epoch[24] Batch [130]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.106385,	
2017-07-20 14:36:03,911 Epoch[24] Batch [140]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106644,	
2017-07-20 14:36:07,967 Epoch[24] Batch [150]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.107013,	
2017-07-20 14:36:11,972 Epoch[24] Batch [160]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.106805,	
2017-07-20 14:36:16,165 Epoch[24] Batch [170]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.106227,	
2017-07-20 14:36:20,355 Epoch[24] Batch [180]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.106048,	
2017-07-20 14:36:24,461 Epoch[24] Batch [190]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105581,	
2017-07-20 14:36:28,617 Epoch[24] Batch [200]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.105005,	
2017-07-20 14:36:32,758 Epoch[24] Batch [210]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.104587,	
2017-07-20 14:36:36,925 Epoch[24] Batch [220]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.104861,	
2017-07-20 14:36:40,969 Epoch[24] Batch [230]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104521,	
2017-07-20 14:36:45,104 Epoch[24] Batch [240]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104956,	
2017-07-20 14:36:49,254 Epoch[24] Batch [250]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.104872,	
2017-07-20 14:36:53,374 Epoch[24] Batch [260]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104587,	
2017-07-20 14:36:57,517 Epoch[24] Batch [270]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.104377,	
2017-07-20 14:37:01,688 Epoch[24] Batch [280]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.104441,	
2017-07-20 14:37:05,711 Epoch[24] Batch [290]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.104772,	
2017-07-20 14:37:09,848 Epoch[24] Batch [300]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104695,	
2017-07-20 14:37:14,001 Epoch[24] Batch [310]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104323,	
2017-07-20 14:37:18,167 Epoch[24] Batch [320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.104477,	
2017-07-20 14:37:22,247 Epoch[24] Batch [330]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.104554,	
2017-07-20 14:37:26,403 Epoch[24] Batch [340]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104691,	
2017-07-20 14:37:30,522 Epoch[24] Batch [350]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104353,	
2017-07-20 14:37:34,682 Epoch[24] Batch [360]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104513,	
2017-07-20 14:37:38,823 Epoch[24] Batch [370]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.104279,	
2017-07-20 14:37:42,859 Epoch[24] Batch [380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103874,	
2017-07-20 14:37:46,872 Epoch[24] Batch [390]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.103782,	
2017-07-20 14:37:50,946 Epoch[24] Batch [400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.103803,	
2017-07-20 14:37:55,090 Epoch[24] Batch [410]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103588,	
2017-07-20 14:37:59,212 Epoch[24] Batch [420]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103844,	
2017-07-20 14:38:03,439 Epoch[24] Batch [430]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.104001,	
2017-07-20 14:38:07,592 Epoch[24] Batch [440]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103669,	
2017-07-20 14:38:11,740 Epoch[24] Batch [450]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103584,	
2017-07-20 14:38:15,945 Epoch[24] Batch [460]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.103572,	
2017-07-20 14:38:19,975 Epoch[24] Batch [470]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103594,	
2017-07-20 14:38:24,085 Epoch[24] Batch [480]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103702,	
2017-07-20 14:38:28,222 Epoch[24] Batch [490]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103742,	
2017-07-20 14:38:32,351 Epoch[24] Batch [500]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.103725,	
2017-07-20 14:38:36,666 Epoch[24] Batch [510]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.103629,	
2017-07-20 14:38:40,775 Epoch[24] Batch [520]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103430,	
2017-07-20 14:38:44,814 Epoch[24] Batch [530]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.103548,	
2017-07-20 14:38:48,949 Epoch[24] Batch [540]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103600,	
2017-07-20 14:38:53,055 Epoch[24] Batch [550]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103979,	
2017-07-20 14:38:57,077 Epoch[24] Batch [560]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104191,	
2017-07-20 14:39:01,180 Epoch[24] Batch [570]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104321,	
2017-07-20 14:39:05,226 Epoch[24] Batch [580]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104360,	
2017-07-20 14:39:09,289 Epoch[24] Batch [590]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104237,	
2017-07-20 14:39:13,323 Epoch[24] Batch [600]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103998,	
2017-07-20 14:39:17,254 Epoch[24] Batch [610]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.103968,	
2017-07-20 14:39:21,453 Epoch[24] Batch [620]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103952,	
2017-07-20 14:39:25,429 Epoch[24] Batch [630]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.103941,	
2017-07-20 14:39:29,665 Epoch[24] Batch [640]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.103872,	
2017-07-20 14:39:33,866 Epoch[24] Batch [650]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.103759,	
2017-07-20 14:39:37,912 Epoch[24] Batch [660]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.103849,	
2017-07-20 14:39:42,098 Epoch[24] Batch [670]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103961,	
2017-07-20 14:39:46,294 Epoch[24] Batch [680]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.104001,	
2017-07-20 14:39:50,472 Epoch[24] Batch [690]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.103921,	
2017-07-20 14:39:54,528 Epoch[24] Batch [700]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.103770,	
2017-07-20 14:39:58,592 Epoch[24] Batch [710]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.103516,	
2017-07-20 14:40:02,623 Epoch[24] Batch [720]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103485,	
2017-07-20 14:40:06,659 Epoch[24] Batch [730]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103503,	
2017-07-20 14:40:10,848 Epoch[24] Batch [740]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.103446,	
2017-07-20 14:40:14,841 Epoch[24] Batch [750]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.103437,	
2017-07-20 14:40:18,861 Epoch[24] Batch [760]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103376,	
2017-07-20 14:40:22,937 Epoch[24] Batch [770]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103361,	
2017-07-20 14:40:27,099 Epoch[24] Batch [780]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.103287,	
2017-07-20 14:40:31,283 Epoch[24] Batch [790]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103260,	
2017-07-20 14:40:35,375 Epoch[24] Batch [800]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103262,	
2017-07-20 14:40:39,418 Epoch[24] Batch [810]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.103144,	
2017-07-20 14:40:43,465 Epoch[24] Batch [820]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.103089,	
2017-07-20 14:40:47,618 Epoch[24] Batch [830]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103285,	
2017-07-20 14:40:51,707 Epoch[24] Batch [840]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103280,	
2017-07-20 14:40:55,890 Epoch[24] Batch [850]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103265,	
2017-07-20 14:41:00,036 Epoch[24] Batch [860]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103137,	
2017-07-20 14:41:04,213 Epoch[24] Batch [870]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.103224,	
2017-07-20 14:41:08,412 Epoch[24] Batch [880]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103138,	
2017-07-20 14:41:12,587 Epoch[24] Batch [890]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.103164,	
2017-07-20 14:41:16,681 Epoch[24] Batch [900]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103249,	
2017-07-20 14:41:20,838 Epoch[24] Batch [910]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.103133,	
2017-07-20 14:41:24,824 Epoch[24] Batch [920]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.103073,	
2017-07-20 14:41:29,003 Epoch[24] Batch [930]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103191,	
2017-07-20 14:41:33,150 Epoch[24] Batch [940]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103230,	
2017-07-20 14:41:37,181 Epoch[24] Batch [950]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103240,	
2017-07-20 14:41:41,175 Epoch[24] Batch [960]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.103252,	
2017-07-20 14:41:45,291 Epoch[24] Batch [970]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103214,	
2017-07-20 14:41:49,493 Epoch[24] Batch [980]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.103148,	
2017-07-20 14:41:53,616 Epoch[24] Batch [990]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.103036,	
2017-07-20 14:41:57,639 Epoch[24] Batch [1000]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.103013,	
2017-07-20 14:42:01,829 Epoch[24] Batch [1010]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.102982,	
2017-07-20 14:42:06,048 Epoch[24] Batch [1020]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.103002,	
2017-07-20 14:42:10,082 Epoch[24] Batch [1030]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103100,	
2017-07-20 14:42:14,090 Epoch[24] Batch [1040]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.103036,	
2017-07-20 14:42:18,173 Epoch[24] Batch [1050]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103167,	
2017-07-20 14:42:22,478 Epoch[24] Batch [1060]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.103109,	
2017-07-20 14:42:26,496 Epoch[24] Batch [1070]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.103083,	
2017-07-20 14:42:30,568 Epoch[24] Batch [1080]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.102930,	
2017-07-20 14:42:34,671 Epoch[24] Batch [1090]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.102919,	
2017-07-20 14:42:38,841 Epoch[24] Batch [1100]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.102888,	
2017-07-20 14:42:42,955 Epoch[24] Batch [1110]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.102988,	
2017-07-20 14:42:46,927 Epoch[24] Batch [1120]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.103013,	
2017-07-20 14:42:51,120 Epoch[24] Batch [1130]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.102946,	
2017-07-20 14:42:55,233 Epoch[24] Batch [1140]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103089,	
2017-07-20 14:42:59,319 Epoch[24] Batch [1150]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.103009,	
2017-07-20 14:43:03,350 Epoch[24] Batch [1160]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103007,	
2017-07-20 14:43:07,458 Epoch[24] Batch [1170]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103075,	
2017-07-20 14:43:11,539 Epoch[24] Batch [1180]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103148,	
2017-07-20 14:43:15,512 Epoch[24] Batch [1190]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.103130,	
2017-07-20 14:43:19,584 Epoch[24] Batch [1200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.103096,	
2017-07-20 14:43:23,847 Epoch[24] Batch [1210]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.103108,	
2017-07-20 14:43:27,957 Epoch[24] Batch [1220]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103102,	
2017-07-20 14:43:32,090 Epoch[24] Batch [1230]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.102997,	
2017-07-20 14:43:36,235 Epoch[24] Batch [1240]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.102909,	
2017-07-20 14:43:40,329 Epoch[24] Batch [1250]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.102909,	
2017-07-20 14:43:44,504 Epoch[24] Batch [1260]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.102885,	
2017-07-20 14:43:48,526 Epoch[24] Batch [1270]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.102839,	
2017-07-20 14:43:52,564 Epoch[24] Batch [1280]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.102876,	
2017-07-20 14:43:56,699 Epoch[24] Batch [1290]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.102783,	
2017-07-20 14:44:00,815 Epoch[24] Batch [1300]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.102690,	
2017-07-20 14:44:04,883 Epoch[24] Batch [1310]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.102641,	
2017-07-20 14:44:08,968 Epoch[24] Batch [1320]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.102592,	
2017-07-20 14:44:12,979 Epoch[24] Batch [1330]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.102609,	
2017-07-20 14:44:17,059 Epoch[24] Batch [1340]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.102595,	
2017-07-20 14:44:21,127 Epoch[24] Batch [1350]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.102600,	
2017-07-20 14:44:25,130 Epoch[24] Batch [1360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.102560,	
2017-07-20 14:44:29,338 Epoch[24] Batch [1370]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.102600,	
2017-07-20 14:44:33,509 Epoch[24] Batch [1380]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.102698,	
2017-07-20 14:44:37,680 Epoch[24] Batch [1390]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.102761,	
2017-07-20 14:44:41,706 Epoch[24] Batch [1400]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.102718,	
2017-07-20 14:44:45,856 Epoch[24] Batch [1410]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.102702,	
2017-07-20 14:44:49,940 Epoch[24] Batch [1420]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.102800,	
2017-07-20 14:44:54,497 Epoch[24] Batch [1430]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.103035,	
2017-07-20 14:44:59,136 Epoch[24] Batch [1440]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.102993,	
2017-07-20 14:45:03,238 Epoch[24] Batch [1450]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.103009,	
2017-07-20 14:45:07,404 Epoch[24] Batch [1460]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.102947,	
2017-07-20 14:45:11,463 Epoch[24] Batch [1470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.102923,	
2017-07-20 14:45:15,533 Epoch[24] Batch [1480]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.102908,	
2017-07-20 14:45:18,062 Epoch[24] Train-FCNLogLoss=0.102906
2017-07-20 14:45:18,062 Epoch[24] Time cost=612.288
2017-07-20 14:45:18,887 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0025.params"
2017-07-20 14:45:20,477 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0025.states"
2017-07-20 14:45:25,283 Epoch[25] Batch [10]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112909,	
2017-07-20 14:45:29,374 Epoch[25] Batch [20]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112006,	
2017-07-20 14:45:33,403 Epoch[25] Batch [30]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107578,	
2017-07-20 14:45:37,490 Epoch[25] Batch [40]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.107397,	
2017-07-20 14:45:41,633 Epoch[25] Batch [50]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104948,	
2017-07-20 14:45:45,710 Epoch[25] Batch [60]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105391,	
2017-07-20 14:45:49,819 Epoch[25] Batch [70]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.106411,	
2017-07-20 14:45:53,867 Epoch[25] Batch [80]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.107488,	
2017-07-20 14:45:57,947 Epoch[25] Batch [90]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.107032,	
2017-07-20 14:46:02,084 Epoch[25] Batch [100]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.108725,	
2017-07-20 14:46:06,247 Epoch[25] Batch [110]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.110776,	
2017-07-20 14:46:10,291 Epoch[25] Batch [120]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.118495,	
2017-07-20 14:46:14,256 Epoch[25] Batch [130]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.120602,	
2017-07-20 14:46:18,329 Epoch[25] Batch [140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.121444,	
2017-07-20 14:46:22,348 Epoch[25] Batch [150]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.120660,	
2017-07-20 14:46:26,456 Epoch[25] Batch [160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.120356,	
2017-07-20 14:46:30,627 Epoch[25] Batch [170]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.120584,	
2017-07-20 14:46:34,735 Epoch[25] Batch [180]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.120336,	
2017-07-20 14:46:38,838 Epoch[25] Batch [190]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.119773,	
2017-07-20 14:46:42,861 Epoch[25] Batch [200]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.119579,	
2017-07-20 14:46:46,929 Epoch[25] Batch [210]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.119624,	
2017-07-20 14:46:50,944 Epoch[25] Batch [220]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.119292,	
2017-07-20 14:46:54,984 Epoch[25] Batch [230]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118804,	
2017-07-20 14:46:58,935 Epoch[25] Batch [240]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.118164,	
2017-07-20 14:47:03,023 Epoch[25] Batch [250]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117487,	
2017-07-20 14:47:07,118 Epoch[25] Batch [260]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116996,	
2017-07-20 14:47:11,303 Epoch[25] Batch [270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.116471,	
2017-07-20 14:47:15,327 Epoch[25] Batch [280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.116133,	
2017-07-20 14:47:19,462 Epoch[25] Batch [290]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.116387,	
2017-07-20 14:47:23,614 Epoch[25] Batch [300]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.115951,	
2017-07-20 14:47:27,659 Epoch[25] Batch [310]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.115568,	
2017-07-20 14:47:31,725 Epoch[25] Batch [320]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115352,	
2017-07-20 14:47:35,805 Epoch[25] Batch [330]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114874,	
2017-07-20 14:47:39,878 Epoch[25] Batch [340]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114487,	
2017-07-20 14:47:43,837 Epoch[25] Batch [350]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.114221,	
2017-07-20 14:47:47,938 Epoch[25] Batch [360]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.114007,	
2017-07-20 14:47:52,065 Epoch[25] Batch [370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.113624,	
2017-07-20 14:47:56,311 Epoch[25] Batch [380]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.113221,	
2017-07-20 14:48:00,406 Epoch[25] Batch [390]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113130,	
2017-07-20 14:48:04,462 Epoch[25] Batch [400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112867,	
2017-07-20 14:48:08,514 Epoch[25] Batch [410]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112907,	
2017-07-20 14:48:12,715 Epoch[25] Batch [420]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.112595,	
2017-07-20 14:48:16,860 Epoch[25] Batch [430]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112193,	
2017-07-20 14:48:20,912 Epoch[25] Batch [440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.111773,	
2017-07-20 14:48:24,888 Epoch[25] Batch [450]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111714,	
2017-07-20 14:48:28,950 Epoch[25] Batch [460]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111768,	
2017-07-20 14:48:33,032 Epoch[25] Batch [470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111628,	
2017-07-20 14:48:37,179 Epoch[25] Batch [480]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.111317,	
2017-07-20 14:48:41,231 Epoch[25] Batch [490]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.111310,	
2017-07-20 14:48:45,314 Epoch[25] Batch [500]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110861,	
2017-07-20 14:48:49,328 Epoch[25] Batch [510]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.110769,	
2017-07-20 14:48:53,496 Epoch[25] Batch [520]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.110748,	
2017-07-20 14:48:57,566 Epoch[25] Batch [530]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110505,	
2017-07-20 14:49:01,569 Epoch[25] Batch [540]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110195,	
2017-07-20 14:49:05,705 Epoch[25] Batch [550]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.110020,	
2017-07-20 14:49:09,824 Epoch[25] Batch [560]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.109940,	
2017-07-20 14:49:13,923 Epoch[25] Batch [570]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.109896,	
2017-07-20 14:49:18,041 Epoch[25] Batch [580]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.109769,	
2017-07-20 14:49:22,228 Epoch[25] Batch [590]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.109519,	
2017-07-20 14:49:26,288 Epoch[25] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109228,	
2017-07-20 14:49:30,390 Epoch[25] Batch [610]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109055,	
2017-07-20 14:49:34,503 Epoch[25] Batch [620]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.108981,	
2017-07-20 14:49:38,570 Epoch[25] Batch [630]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.108645,	
2017-07-20 14:49:42,603 Epoch[25] Batch [640]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.108501,	
2017-07-20 14:49:46,667 Epoch[25] Batch [650]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.108597,	
2017-07-20 14:49:50,836 Epoch[25] Batch [660]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.108461,	
2017-07-20 14:49:54,944 Epoch[25] Batch [670]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.108188,	
2017-07-20 14:49:58,903 Epoch[25] Batch [680]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.108367,	
2017-07-20 14:50:02,906 Epoch[25] Batch [690]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.108219,	
2017-07-20 14:50:07,043 Epoch[25] Batch [700]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.107901,	
2017-07-20 14:50:11,065 Epoch[25] Batch [710]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107867,	
2017-07-20 14:50:15,060 Epoch[25] Batch [720]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107642,	
2017-07-20 14:50:19,244 Epoch[25] Batch [730]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.107471,	
2017-07-20 14:50:23,525 Epoch[25] Batch [740]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.107267,	
2017-07-20 14:50:27,483 Epoch[25] Batch [750]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107232,	
2017-07-20 14:50:31,559 Epoch[25] Batch [760]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.107232,	
2017-07-20 14:50:35,646 Epoch[25] Batch [770]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.107133,	
2017-07-20 14:50:39,804 Epoch[25] Batch [780]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.107097,	
2017-07-20 14:50:43,870 Epoch[25] Batch [790]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.107113,	
2017-07-20 14:50:47,915 Epoch[25] Batch [800]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.107054,	
2017-07-20 14:50:51,882 Epoch[25] Batch [810]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.107034,	
2017-07-20 14:50:55,896 Epoch[25] Batch [820]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.106806,	
2017-07-20 14:50:59,915 Epoch[25] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.106703,	
2017-07-20 14:51:04,100 Epoch[25] Batch [840]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.106575,	
2017-07-20 14:51:08,254 Epoch[25] Batch [850]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106379,	
2017-07-20 14:51:12,338 Epoch[25] Batch [860]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106348,	
2017-07-20 14:51:16,411 Epoch[25] Batch [870]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.106363,	
2017-07-20 14:51:20,469 Epoch[25] Batch [880]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.106397,	
2017-07-20 14:51:24,640 Epoch[25] Batch [890]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106354,	
2017-07-20 14:51:28,639 Epoch[25] Batch [900]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106195,	
2017-07-20 14:51:32,734 Epoch[25] Batch [910]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.106025,	
2017-07-20 14:51:36,749 Epoch[25] Batch [920]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.106020,	
2017-07-20 14:51:40,853 Epoch[25] Batch [930]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105985,	
2017-07-20 14:51:44,999 Epoch[25] Batch [940]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106030,	
2017-07-20 14:51:49,085 Epoch[25] Batch [950]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105879,	
2017-07-20 14:51:53,243 Epoch[25] Batch [960]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.105817,	
2017-07-20 14:51:57,435 Epoch[25] Batch [970]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.105745,	
2017-07-20 14:52:01,442 Epoch[25] Batch [980]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105704,	
2017-07-20 14:52:05,653 Epoch[25] Batch [990]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.105661,	
2017-07-20 14:52:09,895 Epoch[25] Batch [1000]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.105699,	
2017-07-20 14:52:14,222 Epoch[25] Batch [1010]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.105716,	
2017-07-20 14:52:18,320 Epoch[25] Batch [1020]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105695,	
2017-07-20 14:52:22,513 Epoch[25] Batch [1030]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.105688,	
2017-07-20 14:52:26,544 Epoch[25] Batch [1040]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105671,	
2017-07-20 14:52:30,661 Epoch[25] Batch [1050]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.105553,	
2017-07-20 14:52:34,728 Epoch[25] Batch [1060]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105483,	
2017-07-20 14:52:38,716 Epoch[25] Batch [1070]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105262,	
2017-07-20 14:52:42,619 Epoch[25] Batch [1080]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.105137,	
2017-07-20 14:52:46,724 Epoch[25] Batch [1090]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105221,	
2017-07-20 14:52:50,764 Epoch[25] Batch [1100]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105449,	
2017-07-20 14:52:55,019 Epoch[25] Batch [1110]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.105637,	
2017-07-20 14:52:58,914 Epoch[25] Batch [1120]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.105840,	
2017-07-20 14:53:02,850 Epoch[25] Batch [1130]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.106175,	
2017-07-20 14:53:07,010 Epoch[25] Batch [1140]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.106333,	
2017-07-20 14:53:11,067 Epoch[25] Batch [1150]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.106512,	
2017-07-20 14:53:15,172 Epoch[25] Batch [1160]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.106534,	
2017-07-20 14:53:19,194 Epoch[25] Batch [1170]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.106623,	
2017-07-20 14:53:23,361 Epoch[25] Batch [1180]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.106650,	
2017-07-20 14:53:27,543 Epoch[25] Batch [1190]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.106693,	
2017-07-20 14:53:31,784 Epoch[25] Batch [1200]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106689,	
2017-07-20 14:53:35,734 Epoch[25] Batch [1210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.106637,	
2017-07-20 14:53:39,880 Epoch[25] Batch [1220]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106693,	
2017-07-20 14:53:44,050 Epoch[25] Batch [1230]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106739,	
2017-07-20 14:53:48,046 Epoch[25] Batch [1240]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.106822,	
2017-07-20 14:53:52,094 Epoch[25] Batch [1250]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106790,	
2017-07-20 14:53:56,255 Epoch[25] Batch [1260]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.106755,	
2017-07-20 14:54:00,467 Epoch[25] Batch [1270]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106689,	
2017-07-20 14:54:04,534 Epoch[25] Batch [1280]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106692,	
2017-07-20 14:54:08,776 Epoch[25] Batch [1290]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106637,	
2017-07-20 14:54:12,939 Epoch[25] Batch [1300]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.106641,	
2017-07-20 14:54:17,046 Epoch[25] Batch [1310]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.106598,	
2017-07-20 14:54:21,071 Epoch[25] Batch [1320]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.106576,	
2017-07-20 14:54:25,213 Epoch[25] Batch [1330]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.106612,	
2017-07-20 14:54:29,263 Epoch[25] Batch [1340]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106550,	
2017-07-20 14:54:33,262 Epoch[25] Batch [1350]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106525,	
2017-07-20 14:54:37,314 Epoch[25] Batch [1360]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.106495,	
2017-07-20 14:54:41,450 Epoch[25] Batch [1370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.106503,	
2017-07-20 14:54:45,646 Epoch[25] Batch [1380]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.106477,	
2017-07-20 14:54:49,772 Epoch[25] Batch [1390]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.106486,	
2017-07-20 14:54:53,943 Epoch[25] Batch [1400]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106444,	
2017-07-20 14:54:58,020 Epoch[25] Batch [1410]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.106394,	
2017-07-20 14:55:02,278 Epoch[25] Batch [1420]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.106381,	
2017-07-20 14:55:06,455 Epoch[25] Batch [1430]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.106354,	
2017-07-20 14:55:10,527 Epoch[25] Batch [1440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.106303,	
2017-07-20 14:55:14,680 Epoch[25] Batch [1450]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106286,	
2017-07-20 14:55:18,651 Epoch[25] Batch [1460]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.106203,	
2017-07-20 14:55:22,778 Epoch[25] Batch [1470]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.106190,	
2017-07-20 14:55:26,921 Epoch[25] Batch [1480]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106126,	
2017-07-20 14:55:29,380 Epoch[25] Train-FCNLogLoss=0.106046
2017-07-20 14:55:29,380 Epoch[25] Time cost=608.902
2017-07-20 14:55:30,130 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0026.params"
2017-07-20 14:55:31,872 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0026.states"
2017-07-20 14:55:36,567 Epoch[26] Batch [10]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.102771,	
2017-07-20 14:55:40,549 Epoch[26] Batch [20]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.112700,	
2017-07-20 14:55:44,553 Epoch[26] Batch [30]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.118124,	
2017-07-20 14:55:48,599 Epoch[26] Batch [40]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.119012,	
2017-07-20 14:55:52,656 Epoch[26] Batch [50]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115628,	
2017-07-20 14:55:56,796 Epoch[26] Batch [60]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.114245,	
2017-07-20 14:56:00,781 Epoch[26] Batch [70]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.113425,	
2017-07-20 14:56:04,810 Epoch[26] Batch [80]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113643,	
2017-07-20 14:56:08,873 Epoch[26] Batch [90]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113237,	
2017-07-20 14:56:12,907 Epoch[26] Batch [100]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112006,	
2017-07-20 14:56:17,062 Epoch[26] Batch [110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.111678,	
2017-07-20 14:56:21,087 Epoch[26] Batch [120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111084,	
2017-07-20 14:56:25,156 Epoch[26] Batch [130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110965,	
2017-07-20 14:56:29,300 Epoch[26] Batch [140]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112577,	
2017-07-20 14:56:33,357 Epoch[26] Batch [150]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113963,	
2017-07-20 14:56:37,446 Epoch[26] Batch [160]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114000,	
2017-07-20 14:56:41,602 Epoch[26] Batch [170]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.115754,	
2017-07-20 14:56:45,630 Epoch[26] Batch [180]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116475,	
2017-07-20 14:56:49,636 Epoch[26] Batch [190]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116226,	
2017-07-20 14:56:53,750 Epoch[26] Batch [200]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.116117,	
2017-07-20 14:56:57,775 Epoch[26] Batch [210]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.115863,	
2017-07-20 14:57:01,883 Epoch[26] Batch [220]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115604,	
2017-07-20 14:57:05,961 Epoch[26] Batch [230]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115141,	
2017-07-20 14:57:10,102 Epoch[26] Batch [240]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.114609,	
2017-07-20 14:57:14,222 Epoch[26] Batch [250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.114669,	
2017-07-20 14:57:18,212 Epoch[26] Batch [260]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114843,	
2017-07-20 14:57:22,289 Epoch[26] Batch [270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.114363,	
2017-07-20 14:57:26,316 Epoch[26] Batch [280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.114333,	
2017-07-20 14:57:30,363 Epoch[26] Batch [290]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.113674,	
2017-07-20 14:57:34,416 Epoch[26] Batch [300]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113324,	
2017-07-20 14:57:38,678 Epoch[26] Batch [310]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.113033,	
2017-07-20 14:57:42,878 Epoch[26] Batch [320]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112739,	
2017-07-20 14:57:47,029 Epoch[26] Batch [330]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112422,	
2017-07-20 14:57:51,000 Epoch[26] Batch [340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.112991,	
2017-07-20 14:57:55,261 Epoch[26] Batch [350]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.112957,	
2017-07-20 14:57:59,291 Epoch[26] Batch [360]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112958,	
2017-07-20 14:58:03,296 Epoch[26] Batch [370]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.112977,	
2017-07-20 14:58:07,260 Epoch[26] Batch [380]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.112560,	
2017-07-20 14:58:11,255 Epoch[26] Batch [390]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112358,	
2017-07-20 14:58:15,495 Epoch[26] Batch [400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.112083,	
2017-07-20 14:58:19,537 Epoch[26] Batch [410]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112128,	
2017-07-20 14:58:23,671 Epoch[26] Batch [420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111956,	
2017-07-20 14:58:27,702 Epoch[26] Batch [430]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.111715,	
2017-07-20 14:58:31,861 Epoch[26] Batch [440]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.111153,	
2017-07-20 14:58:35,844 Epoch[26] Batch [450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.111068,	
2017-07-20 14:58:39,994 Epoch[26] Batch [460]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111002,	
2017-07-20 14:58:44,030 Epoch[26] Batch [470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.110868,	
2017-07-20 14:58:48,132 Epoch[26] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.110521,	
2017-07-20 14:58:52,108 Epoch[26] Batch [490]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110331,	
2017-07-20 14:58:56,141 Epoch[26] Batch [500]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110052,	
2017-07-20 14:59:00,143 Epoch[26] Batch [510]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109976,	
2017-07-20 14:59:04,320 Epoch[26] Batch [520]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109755,	
2017-07-20 14:59:08,457 Epoch[26] Batch [530]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.109650,	
2017-07-20 14:59:12,701 Epoch[26] Batch [540]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.109507,	
2017-07-20 14:59:16,875 Epoch[26] Batch [550]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109300,	
2017-07-20 14:59:21,200 Epoch[26] Batch [560]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109371,	
2017-07-20 14:59:25,525 Epoch[26] Batch [570]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109268,	
2017-07-20 14:59:29,676 Epoch[26] Batch [580]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.109051,	
2017-07-20 14:59:34,035 Epoch[26] Batch [590]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.108962,	
2017-07-20 14:59:38,193 Epoch[26] Batch [600]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.108889,	
2017-07-20 14:59:42,459 Epoch[26] Batch [610]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.108861,	
2017-07-20 14:59:46,531 Epoch[26] Batch [620]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.108649,	
2017-07-20 14:59:50,770 Epoch[26] Batch [630]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108508,	
2017-07-20 14:59:55,131 Epoch[26] Batch [640]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.108437,	
2017-07-20 14:59:59,451 Epoch[26] Batch [650]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.108366,	
2017-07-20 15:00:03,695 Epoch[26] Batch [660]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.108265,	
2017-07-20 15:00:07,931 Epoch[26] Batch [670]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108195,	
2017-07-20 15:00:12,174 Epoch[26] Batch [680]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.108014,	
2017-07-20 15:00:16,328 Epoch[26] Batch [690]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.107918,	
2017-07-20 15:00:20,554 Epoch[26] Batch [700]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.107716,	
2017-07-20 15:00:24,841 Epoch[26] Batch [710]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.107567,	
2017-07-20 15:00:29,039 Epoch[26] Batch [720]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.107382,	
2017-07-20 15:00:33,250 Epoch[26] Batch [730]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.107195,	
2017-07-20 15:00:37,417 Epoch[26] Batch [740]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.107147,	
2017-07-20 15:00:41,710 Epoch[26] Batch [750]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.107085,	
2017-07-20 15:00:46,017 Epoch[26] Batch [760]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.107139,	
2017-07-20 15:00:50,167 Epoch[26] Batch [770]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107102,	
2017-07-20 15:00:54,132 Epoch[26] Batch [780]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.106833,	
2017-07-20 15:00:58,331 Epoch[26] Batch [790]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.106668,	
2017-07-20 15:01:02,677 Epoch[26] Batch [800]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.106666,	
2017-07-20 15:01:06,899 Epoch[26] Batch [810]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.106558,	
2017-07-20 15:01:10,966 Epoch[26] Batch [820]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.106612,	
2017-07-20 15:01:15,136 Epoch[26] Batch [830]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106479,	
2017-07-20 15:01:19,433 Epoch[26] Batch [840]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.106597,	
2017-07-20 15:01:23,647 Epoch[26] Batch [850]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.106513,	
2017-07-20 15:01:27,867 Epoch[26] Batch [860]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.106410,	
2017-07-20 15:01:32,181 Epoch[26] Batch [870]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.106449,	
2017-07-20 15:01:36,446 Epoch[26] Batch [880]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.106640,	
2017-07-20 15:01:40,831 Epoch[26] Batch [890]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106610,	
2017-07-20 15:01:45,035 Epoch[26] Batch [900]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.106439,	
2017-07-20 15:01:49,190 Epoch[26] Batch [910]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106408,	
2017-07-20 15:01:53,402 Epoch[26] Batch [920]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106337,	
2017-07-20 15:01:57,597 Epoch[26] Batch [930]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.106268,	
2017-07-20 15:02:01,890 Epoch[26] Batch [940]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.106305,	
2017-07-20 15:02:06,070 Epoch[26] Batch [950]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.106364,	
2017-07-20 15:02:10,269 Epoch[26] Batch [960]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.106168,	
2017-07-20 15:02:14,441 Epoch[26] Batch [970]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106228,	
2017-07-20 15:02:18,765 Epoch[26] Batch [980]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.106170,	
2017-07-20 15:02:22,854 Epoch[26] Batch [990]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106158,	
2017-07-20 15:02:27,155 Epoch[26] Batch [1000]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106173,	
2017-07-20 15:02:31,217 Epoch[26] Batch [1010]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.106232,	
2017-07-20 15:02:35,406 Epoch[26] Batch [1020]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.106069,	
2017-07-20 15:02:39,606 Epoch[26] Batch [1030]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.106088,	
2017-07-20 15:02:43,805 Epoch[26] Batch [1040]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.106104,	
2017-07-20 15:02:47,894 Epoch[26] Batch [1050]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106056,	
2017-07-20 15:02:51,926 Epoch[26] Batch [1060]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105982,	
2017-07-20 15:02:56,096 Epoch[26] Batch [1070]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.105872,	
2017-07-20 15:03:00,307 Epoch[26] Batch [1080]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.105773,	
2017-07-20 15:03:04,505 Epoch[26] Batch [1090]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.105774,	
2017-07-20 15:03:08,845 Epoch[26] Batch [1100]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.105724,	
2017-07-20 15:03:13,026 Epoch[26] Batch [1110]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105570,	
2017-07-20 15:03:17,332 Epoch[26] Batch [1120]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.105542,	
2017-07-20 15:03:21,628 Epoch[26] Batch [1130]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105509,	
2017-07-20 15:03:25,778 Epoch[26] Batch [1140]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105516,	
2017-07-20 15:03:30,089 Epoch[26] Batch [1150]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.105510,	
2017-07-20 15:03:34,352 Epoch[26] Batch [1160]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.105443,	
2017-07-20 15:03:38,636 Epoch[26] Batch [1170]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.105371,	
2017-07-20 15:03:42,801 Epoch[26] Batch [1180]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.105375,	
2017-07-20 15:03:47,041 Epoch[26] Batch [1190]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.105243,	
2017-07-20 15:03:51,213 Epoch[26] Batch [1200]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.105183,	
2017-07-20 15:03:55,437 Epoch[26] Batch [1210]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105127,	
2017-07-20 15:03:59,601 Epoch[26] Batch [1220]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105126,	
2017-07-20 15:04:03,837 Epoch[26] Batch [1230]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.105052,	
2017-07-20 15:04:07,886 Epoch[26] Batch [1240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105009,	
2017-07-20 15:04:12,106 Epoch[26] Batch [1250]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.105386,	
2017-07-20 15:04:16,307 Epoch[26] Batch [1260]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.105440,	
2017-07-20 15:04:20,406 Epoch[26] Batch [1270]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105417,	
2017-07-20 15:04:24,517 Epoch[26] Batch [1280]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105479,	
2017-07-20 15:04:28,593 Epoch[26] Batch [1290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105461,	
2017-07-20 15:04:32,710 Epoch[26] Batch [1300]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.105429,	
2017-07-20 15:04:36,828 Epoch[26] Batch [1310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105398,	
2017-07-20 15:04:41,055 Epoch[26] Batch [1320]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.105379,	
2017-07-20 15:04:45,098 Epoch[26] Batch [1330]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105373,	
2017-07-20 15:04:49,225 Epoch[26] Batch [1340]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.105294,	
2017-07-20 15:04:53,244 Epoch[26] Batch [1350]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105234,	
2017-07-20 15:04:57,363 Epoch[26] Batch [1360]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105164,	
2017-07-20 15:05:01,576 Epoch[26] Batch [1370]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.105152,	
2017-07-20 15:05:05,717 Epoch[26] Batch [1380]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.105114,	
2017-07-20 15:05:09,772 Epoch[26] Batch [1390]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105021,	
2017-07-20 15:05:13,903 Epoch[26] Batch [1400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.105067,	
2017-07-20 15:05:18,087 Epoch[26] Batch [1410]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.105089,	
2017-07-20 15:05:22,266 Epoch[26] Batch [1420]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105162,	
2017-07-20 15:05:26,445 Epoch[26] Batch [1430]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105134,	
2017-07-20 15:05:30,496 Epoch[26] Batch [1440]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105183,	
2017-07-20 15:05:34,605 Epoch[26] Batch [1450]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105234,	
2017-07-20 15:05:38,604 Epoch[26] Batch [1460]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105183,	
2017-07-20 15:05:42,534 Epoch[26] Batch [1470]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105183,	
2017-07-20 15:05:46,628 Epoch[26] Batch [1480]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105195,	
2017-07-20 15:05:49,041 Epoch[26] Train-FCNLogLoss=0.105191
2017-07-20 15:05:49,041 Epoch[26] Time cost=617.169
2017-07-20 15:05:49,825 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0027.params"
2017-07-20 15:05:51,376 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0027.states"
2017-07-20 15:05:56,251 Epoch[27] Batch [10]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.109307,	
2017-07-20 15:06:00,307 Epoch[27] Batch [20]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101882,	
2017-07-20 15:06:04,335 Epoch[27] Batch [30]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.098425,	
2017-07-20 15:06:08,355 Epoch[27] Batch [40]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.099479,	
2017-07-20 15:06:12,485 Epoch[27] Batch [50]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.098956,	
2017-07-20 15:06:16,447 Epoch[27] Batch [60]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.097870,	
2017-07-20 15:06:20,477 Epoch[27] Batch [70]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.098928,	
2017-07-20 15:06:24,541 Epoch[27] Batch [80]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.099348,	
2017-07-20 15:06:28,734 Epoch[27] Batch [90]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.099321,	
2017-07-20 15:06:32,798 Epoch[27] Batch [100]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.099616,	
2017-07-20 15:06:36,890 Epoch[27] Batch [110]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.099325,	
2017-07-20 15:06:41,131 Epoch[27] Batch [120]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.099199,	
2017-07-20 15:06:45,237 Epoch[27] Batch [130]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.099623,	
2017-07-20 15:06:49,309 Epoch[27] Batch [140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.099428,	
2017-07-20 15:06:53,293 Epoch[27] Batch [150]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.099947,	
2017-07-20 15:06:57,390 Epoch[27] Batch [160]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.099559,	
2017-07-20 15:07:01,545 Epoch[27] Batch [170]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.100031,	
2017-07-20 15:07:05,576 Epoch[27] Batch [180]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.099899,	
2017-07-20 15:07:09,747 Epoch[27] Batch [190]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.099757,	
2017-07-20 15:07:13,875 Epoch[27] Batch [200]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.100176,	
2017-07-20 15:07:17,966 Epoch[27] Batch [210]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100159,	
2017-07-20 15:07:21,994 Epoch[27] Batch [220]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.100141,	
2017-07-20 15:07:26,156 Epoch[27] Batch [230]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.099980,	
2017-07-20 15:07:30,171 Epoch[27] Batch [240]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.100893,	
2017-07-20 15:07:34,347 Epoch[27] Batch [250]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.101154,	
2017-07-20 15:07:38,496 Epoch[27] Batch [260]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.101075,	
2017-07-20 15:07:42,624 Epoch[27] Batch [270]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.100811,	
2017-07-20 15:07:46,853 Epoch[27] Batch [280]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100929,	
2017-07-20 15:07:51,030 Epoch[27] Batch [290]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.100855,	
2017-07-20 15:07:55,199 Epoch[27] Batch [300]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.100610,	
2017-07-20 15:07:59,249 Epoch[27] Batch [310]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.100679,	
2017-07-20 15:08:03,431 Epoch[27] Batch [320]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.100762,	
2017-07-20 15:08:07,594 Epoch[27] Batch [330]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.101002,	
2017-07-20 15:08:11,683 Epoch[27] Batch [340]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100962,	
2017-07-20 15:08:15,856 Epoch[27] Batch [350]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.101182,	
2017-07-20 15:08:19,928 Epoch[27] Batch [360]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100925,	
2017-07-20 15:08:24,161 Epoch[27] Batch [370]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.100989,	
2017-07-20 15:08:28,317 Epoch[27] Batch [380]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101609,	
2017-07-20 15:08:32,339 Epoch[27] Batch [390]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.101568,	
2017-07-20 15:08:36,506 Epoch[27] Batch [400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.101449,	
2017-07-20 15:08:40,577 Epoch[27] Batch [410]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101418,	
2017-07-20 15:08:44,778 Epoch[27] Batch [420]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.101319,	
2017-07-20 15:08:48,817 Epoch[27] Batch [430]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101179,	
2017-07-20 15:08:52,906 Epoch[27] Batch [440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101089,	
2017-07-20 15:08:57,032 Epoch[27] Batch [450]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.100906,	
2017-07-20 15:09:01,314 Epoch[27] Batch [460]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.101073,	
2017-07-20 15:09:05,421 Epoch[27] Batch [470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.100967,	
2017-07-20 15:09:09,627 Epoch[27] Batch [480]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.101170,	
2017-07-20 15:09:13,717 Epoch[27] Batch [490]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101191,	
2017-07-20 15:09:17,793 Epoch[27] Batch [500]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101239,	
2017-07-20 15:09:21,804 Epoch[27] Batch [510]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101247,	
2017-07-20 15:09:25,838 Epoch[27] Batch [520]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101152,	
2017-07-20 15:09:29,926 Epoch[27] Batch [530]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.101127,	
2017-07-20 15:09:34,078 Epoch[27] Batch [540]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.101235,	
2017-07-20 15:09:38,207 Epoch[27] Batch [550]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.101300,	
2017-07-20 15:09:42,329 Epoch[27] Batch [560]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.101208,	
2017-07-20 15:09:46,410 Epoch[27] Batch [570]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101129,	
2017-07-20 15:09:50,537 Epoch[27] Batch [580]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.101014,	
2017-07-20 15:09:54,811 Epoch[27] Batch [590]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.101121,	
2017-07-20 15:09:58,942 Epoch[27] Batch [600]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100923,	
2017-07-20 15:10:03,039 Epoch[27] Batch [610]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.100921,	
2017-07-20 15:10:07,177 Epoch[27] Batch [620]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.100889,	
2017-07-20 15:10:11,269 Epoch[27] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100811,	
2017-07-20 15:10:15,316 Epoch[27] Batch [640]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.100892,	
2017-07-20 15:10:19,273 Epoch[27] Batch [650]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.101039,	
2017-07-20 15:10:23,472 Epoch[27] Batch [660]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.101004,	
2017-07-20 15:10:27,511 Epoch[27] Batch [670]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.100950,	
2017-07-20 15:10:31,671 Epoch[27] Batch [680]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.100960,	
2017-07-20 15:10:35,813 Epoch[27] Batch [690]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.100901,	
2017-07-20 15:10:39,977 Epoch[27] Batch [700]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.101094,	
2017-07-20 15:10:44,150 Epoch[27] Batch [710]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.101117,	
2017-07-20 15:10:48,236 Epoch[27] Batch [720]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.101090,	
2017-07-20 15:10:52,262 Epoch[27] Batch [730]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100909,	
2017-07-20 15:10:56,256 Epoch[27] Batch [740]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.100752,	
2017-07-20 15:11:00,355 Epoch[27] Batch [750]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.100785,	
2017-07-20 15:11:04,434 Epoch[27] Batch [760]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.100794,	
2017-07-20 15:11:08,575 Epoch[27] Batch [770]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.100733,	
2017-07-20 15:11:12,539 Epoch[27] Batch [780]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.100738,	
2017-07-20 15:11:16,600 Epoch[27] Batch [790]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100747,	
2017-07-20 15:11:20,645 Epoch[27] Batch [800]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.100705,	
2017-07-20 15:11:24,829 Epoch[27] Batch [810]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.100686,	
2017-07-20 15:11:28,955 Epoch[27] Batch [820]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.100583,	
2017-07-20 15:11:33,078 Epoch[27] Batch [830]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.100573,	
2017-07-20 15:11:37,158 Epoch[27] Batch [840]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100791,	
2017-07-20 15:11:41,210 Epoch[27] Batch [850]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.100671,	
2017-07-20 15:11:45,384 Epoch[27] Batch [860]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.100563,	
2017-07-20 15:11:49,553 Epoch[27] Batch [870]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.100385,	
2017-07-20 15:11:53,505 Epoch[27] Batch [880]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.100425,	
2017-07-20 15:11:57,607 Epoch[27] Batch [890]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.100485,	
2017-07-20 15:12:01,875 Epoch[27] Batch [900]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.100431,	
2017-07-20 15:12:05,947 Epoch[27] Batch [910]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100344,	
2017-07-20 15:12:10,181 Epoch[27] Batch [920]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.100474,	
2017-07-20 15:12:14,175 Epoch[27] Batch [930]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.100437,	
2017-07-20 15:12:18,166 Epoch[27] Batch [940]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.100510,	
2017-07-20 15:12:22,239 Epoch[27] Batch [950]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.100565,	
2017-07-20 15:12:26,472 Epoch[27] Batch [960]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.100592,	
2017-07-20 15:12:30,618 Epoch[27] Batch [970]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.100633,	
2017-07-20 15:12:34,781 Epoch[27] Batch [980]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.100661,	
2017-07-20 15:12:39,019 Epoch[27] Batch [990]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100693,	
2017-07-20 15:12:42,992 Epoch[27] Batch [1000]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.100706,	
2017-07-20 15:12:47,171 Epoch[27] Batch [1010]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.100674,	
2017-07-20 15:12:51,297 Epoch[27] Batch [1020]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.100725,	
2017-07-20 15:12:55,380 Epoch[27] Batch [1030]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100832,	
2017-07-20 15:12:59,367 Epoch[27] Batch [1040]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.100788,	
2017-07-20 15:13:03,609 Epoch[27] Batch [1050]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100844,	
2017-07-20 15:13:07,667 Epoch[27] Batch [1060]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100893,	
2017-07-20 15:13:11,909 Epoch[27] Batch [1070]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100948,	
2017-07-20 15:13:15,907 Epoch[27] Batch [1080]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.100932,	
2017-07-20 15:13:20,074 Epoch[27] Batch [1090]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101049,	
2017-07-20 15:13:24,167 Epoch[27] Batch [1100]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101117,	
2017-07-20 15:13:28,318 Epoch[27] Batch [1110]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.101121,	
2017-07-20 15:13:32,307 Epoch[27] Batch [1120]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.101094,	
2017-07-20 15:13:36,334 Epoch[27] Batch [1130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.101157,	
2017-07-20 15:13:40,498 Epoch[27] Batch [1140]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.101150,	
2017-07-20 15:13:44,573 Epoch[27] Batch [1150]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101063,	
2017-07-20 15:13:48,729 Epoch[27] Batch [1160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101008,	
2017-07-20 15:13:52,892 Epoch[27] Batch [1170]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.101114,	
2017-07-20 15:13:57,048 Epoch[27] Batch [1180]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101191,	
2017-07-20 15:14:00,989 Epoch[27] Batch [1190]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.101207,	
2017-07-20 15:14:05,269 Epoch[27] Batch [1200]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.101136,	
2017-07-20 15:14:09,447 Epoch[27] Batch [1210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.101216,	
2017-07-20 15:14:13,457 Epoch[27] Batch [1220]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101212,	
2017-07-20 15:14:17,662 Epoch[27] Batch [1230]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.101284,	
2017-07-20 15:14:21,811 Epoch[27] Batch [1240]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.101301,	
2017-07-20 15:14:25,868 Epoch[27] Batch [1250]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101376,	
2017-07-20 15:14:30,061 Epoch[27] Batch [1260]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.101290,	
2017-07-20 15:14:34,200 Epoch[27] Batch [1270]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101274,	
2017-07-20 15:14:38,199 Epoch[27] Batch [1280]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101271,	
2017-07-20 15:14:42,336 Epoch[27] Batch [1290]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101218,	
2017-07-20 15:14:46,537 Epoch[27] Batch [1300]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.101161,	
2017-07-20 15:14:50,546 Epoch[27] Batch [1310]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101164,	
2017-07-20 15:14:54,699 Epoch[27] Batch [1320]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101077,	
2017-07-20 15:14:58,832 Epoch[27] Batch [1330]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.101180,	
2017-07-20 15:15:02,928 Epoch[27] Batch [1340]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101166,	
2017-07-20 15:15:06,961 Epoch[27] Batch [1350]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101081,	
2017-07-20 15:15:11,028 Epoch[27] Batch [1360]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101072,	
2017-07-20 15:15:15,116 Epoch[27] Batch [1370]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100999,	
2017-07-20 15:15:19,241 Epoch[27] Batch [1380]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.100949,	
2017-07-20 15:15:23,290 Epoch[27] Batch [1390]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.100960,	
2017-07-20 15:15:27,485 Epoch[27] Batch [1400]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.100957,	
2017-07-20 15:15:31,481 Epoch[27] Batch [1410]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.101021,	
2017-07-20 15:15:35,501 Epoch[27] Batch [1420]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.100973,	
2017-07-20 15:15:39,566 Epoch[27] Batch [1430]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.100986,	
2017-07-20 15:15:43,637 Epoch[27] Batch [1440]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101053,	
2017-07-20 15:15:47,798 Epoch[27] Batch [1450]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101034,	
2017-07-20 15:15:51,796 Epoch[27] Batch [1460]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101075,	
2017-07-20 15:15:55,841 Epoch[27] Batch [1470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.101040,	
2017-07-20 15:15:59,844 Epoch[27] Batch [1480]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.101017,	
2017-07-20 15:16:02,295 Epoch[27] Train-FCNLogLoss=0.101064
2017-07-20 15:16:02,295 Epoch[27] Time cost=610.919
2017-07-20 15:16:03,089 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0028.params"
2017-07-20 15:16:04,627 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0028.states"
2017-07-20 15:16:09,335 Epoch[28] Batch [10]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.098030,	
2017-07-20 15:16:13,485 Epoch[28] Batch [20]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094478,	
2017-07-20 15:16:17,680 Epoch[28] Batch [30]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097626,	
2017-07-20 15:16:21,715 Epoch[28] Batch [40]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097096,	
2017-07-20 15:16:25,788 Epoch[28] Batch [50]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.099028,	
2017-07-20 15:16:29,882 Epoch[28] Batch [60]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.099482,	
2017-07-20 15:16:34,066 Epoch[28] Batch [70]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.099336,	
2017-07-20 15:16:38,192 Epoch[28] Batch [80]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098509,	
2017-07-20 15:16:42,281 Epoch[28] Batch [90]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.098781,	
2017-07-20 15:16:46,373 Epoch[28] Batch [100]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.098611,	
2017-07-20 15:16:50,373 Epoch[28] Batch [110]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.098452,	
2017-07-20 15:16:54,404 Epoch[28] Batch [120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.098401,	
2017-07-20 15:16:58,676 Epoch[28] Batch [130]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.098154,	
2017-07-20 15:17:02,772 Epoch[28] Batch [140]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.098316,	
2017-07-20 15:17:06,848 Epoch[28] Batch [150]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.098914,	
2017-07-20 15:17:10,972 Epoch[28] Batch [160]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.099050,	
2017-07-20 15:17:15,143 Epoch[28] Batch [170]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.098872,	
2017-07-20 15:17:19,260 Epoch[28] Batch [180]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.099106,	
2017-07-20 15:17:23,564 Epoch[28] Batch [190]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.098859,	
2017-07-20 15:17:27,753 Epoch[28] Batch [200]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098581,	
2017-07-20 15:17:31,934 Epoch[28] Batch [210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.098461,	
2017-07-20 15:17:36,055 Epoch[28] Batch [220]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.098209,	
2017-07-20 15:17:40,189 Epoch[28] Batch [230]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.098127,	
2017-07-20 15:17:44,307 Epoch[28] Batch [240]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.098153,	
2017-07-20 15:17:48,404 Epoch[28] Batch [250]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.098020,	
2017-07-20 15:17:52,453 Epoch[28] Batch [260]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097800,	
2017-07-20 15:17:56,529 Epoch[28] Batch [270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.098008,	
2017-07-20 15:18:00,516 Epoch[28] Batch [280]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.098253,	
2017-07-20 15:18:04,526 Epoch[28] Batch [290]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.098570,	
2017-07-20 15:18:08,603 Epoch[28] Batch [300]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.098889,	
2017-07-20 15:18:12,751 Epoch[28] Batch [310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.098812,	
2017-07-20 15:18:17,034 Epoch[28] Batch [320]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.098886,	
2017-07-20 15:18:21,012 Epoch[28] Batch [330]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.098892,	
2017-07-20 15:18:25,070 Epoch[28] Batch [340]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098641,	
2017-07-20 15:18:29,183 Epoch[28] Batch [350]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.098998,	
2017-07-20 15:18:33,353 Epoch[28] Batch [360]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.099154,	
2017-07-20 15:18:37,454 Epoch[28] Batch [370]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.099185,	
2017-07-20 15:18:41,478 Epoch[28] Batch [380]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.099178,	
2017-07-20 15:18:45,464 Epoch[28] Batch [390]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.099049,	
2017-07-20 15:18:49,483 Epoch[28] Batch [400]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.099246,	
2017-07-20 15:18:53,610 Epoch[28] Batch [410]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.099195,	
2017-07-20 15:18:57,788 Epoch[28] Batch [420]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.099340,	
2017-07-20 15:19:01,924 Epoch[28] Batch [430]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.099283,	
2017-07-20 15:19:06,009 Epoch[28] Batch [440]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.099324,	
2017-07-20 15:19:09,927 Epoch[28] Batch [450]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.099343,	
2017-07-20 15:19:13,919 Epoch[28] Batch [460]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.099251,	
2017-07-20 15:19:18,016 Epoch[28] Batch [470]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.099255,	
2017-07-20 15:19:22,225 Epoch[28] Batch [480]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.099108,	
2017-07-20 15:19:26,286 Epoch[28] Batch [490]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.098992,	
2017-07-20 15:19:30,283 Epoch[28] Batch [500]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.099086,	
2017-07-20 15:19:34,358 Epoch[28] Batch [510]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.099048,	
2017-07-20 15:19:38,415 Epoch[28] Batch [520]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098949,	
2017-07-20 15:19:42,671 Epoch[28] Batch [530]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.099111,	
2017-07-20 15:19:46,698 Epoch[28] Batch [540]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.098930,	
2017-07-20 15:19:50,757 Epoch[28] Batch [550]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098683,	
2017-07-20 15:19:54,877 Epoch[28] Batch [560]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.098578,	
2017-07-20 15:19:58,971 Epoch[28] Batch [570]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.098563,	
2017-07-20 15:20:03,256 Epoch[28] Batch [580]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.098456,	
2017-07-20 15:20:07,319 Epoch[28] Batch [590]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.098521,	
2017-07-20 15:20:11,453 Epoch[28] Batch [600]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.098420,	
2017-07-20 15:20:15,524 Epoch[28] Batch [610]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.098324,	
2017-07-20 15:20:19,680 Epoch[28] Batch [620]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.098163,	
2017-07-20 15:20:23,853 Epoch[28] Batch [630]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.098176,	
2017-07-20 15:20:27,957 Epoch[28] Batch [640]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.098023,	
2017-07-20 15:20:32,063 Epoch[28] Batch [650]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.098015,	
2017-07-20 15:20:36,070 Epoch[28] Batch [660]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097957,	
2017-07-20 15:20:40,187 Epoch[28] Batch [670]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097725,	
2017-07-20 15:20:44,330 Epoch[28] Batch [680]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.097768,	
2017-07-20 15:20:48,448 Epoch[28] Batch [690]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097688,	
2017-07-20 15:20:52,545 Epoch[28] Batch [700]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097571,	
2017-07-20 15:20:56,718 Epoch[28] Batch [710]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097686,	
2017-07-20 15:21:00,811 Epoch[28] Batch [720]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097623,	
2017-07-20 15:21:04,800 Epoch[28] Batch [730]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.097613,	
2017-07-20 15:21:08,811 Epoch[28] Batch [740]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.097641,	
2017-07-20 15:21:12,904 Epoch[28] Batch [750]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097750,	
2017-07-20 15:21:16,997 Epoch[28] Batch [760]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097667,	
2017-07-20 15:21:21,090 Epoch[28] Batch [770]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097799,	
2017-07-20 15:21:25,155 Epoch[28] Batch [780]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.097877,	
2017-07-20 15:21:29,177 Epoch[28] Batch [790]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097980,	
2017-07-20 15:21:33,295 Epoch[28] Batch [800]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097971,	
2017-07-20 15:21:37,398 Epoch[28] Batch [810]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.098101,	
2017-07-20 15:21:41,616 Epoch[28] Batch [820]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.097987,	
2017-07-20 15:21:45,798 Epoch[28] Batch [830]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.097971,	
2017-07-20 15:21:49,858 Epoch[28] Batch [840]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097920,	
2017-07-20 15:21:53,866 Epoch[28] Batch [850]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097779,	
2017-07-20 15:21:58,100 Epoch[28] Batch [860]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.097773,	
2017-07-20 15:22:02,230 Epoch[28] Batch [870]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097807,	
2017-07-20 15:22:06,365 Epoch[28] Batch [880]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097797,	
2017-07-20 15:22:10,493 Epoch[28] Batch [890]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097825,	
2017-07-20 15:22:14,516 Epoch[28] Batch [900]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097830,	
2017-07-20 15:22:18,614 Epoch[28] Batch [910]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097962,	
2017-07-20 15:22:22,842 Epoch[28] Batch [920]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.098003,	
2017-07-20 15:22:26,971 Epoch[28] Batch [930]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.098027,	
2017-07-20 15:22:31,212 Epoch[28] Batch [940]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.098044,	
2017-07-20 15:22:35,444 Epoch[28] Batch [950]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.097928,	
2017-07-20 15:22:39,555 Epoch[28] Batch [960]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.097911,	
2017-07-20 15:22:43,749 Epoch[28] Batch [970]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.097958,	
2017-07-20 15:22:47,946 Epoch[28] Batch [980]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097856,	
2017-07-20 15:22:52,095 Epoch[28] Batch [990]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.097692,	
2017-07-20 15:22:56,189 Epoch[28] Batch [1000]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097739,	
2017-07-20 15:23:00,307 Epoch[28] Batch [1010]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097721,	
2017-07-20 15:23:04,456 Epoch[28] Batch [1020]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.097762,	
2017-07-20 15:23:08,506 Epoch[28] Batch [1030]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097696,	
2017-07-20 15:23:12,567 Epoch[28] Batch [1040]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097787,	
2017-07-20 15:23:16,608 Epoch[28] Batch [1050]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.097831,	
2017-07-20 15:23:20,656 Epoch[28] Batch [1060]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097763,	
2017-07-20 15:23:24,718 Epoch[28] Batch [1070]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097794,	
2017-07-20 15:23:28,862 Epoch[28] Batch [1080]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.097784,	
2017-07-20 15:23:32,924 Epoch[28] Batch [1090]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097721,	
2017-07-20 15:23:37,003 Epoch[28] Batch [1100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097708,	
2017-07-20 15:23:41,086 Epoch[28] Batch [1110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.097760,	
2017-07-20 15:23:45,165 Epoch[28] Batch [1120]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097707,	
2017-07-20 15:23:49,314 Epoch[28] Batch [1130]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.097669,	
2017-07-20 15:23:53,376 Epoch[28] Batch [1140]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097665,	
2017-07-20 15:23:57,534 Epoch[28] Batch [1150]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.097648,	
2017-07-20 15:24:01,758 Epoch[28] Batch [1160]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.097579,	
2017-07-20 15:24:06,005 Epoch[28] Batch [1170]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.097465,	
2017-07-20 15:24:10,047 Epoch[28] Batch [1180]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.097434,	
2017-07-20 15:24:14,182 Epoch[28] Batch [1190]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097409,	
2017-07-20 15:24:18,243 Epoch[28] Batch [1200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097345,	
2017-07-20 15:24:22,353 Epoch[28] Batch [1210]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.097272,	
2017-07-20 15:24:26,393 Epoch[28] Batch [1220]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.097374,	
2017-07-20 15:24:30,513 Epoch[28] Batch [1230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097377,	
2017-07-20 15:24:34,614 Epoch[28] Batch [1240]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.097428,	
2017-07-20 15:24:38,691 Epoch[28] Batch [1250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097415,	
2017-07-20 15:24:42,712 Epoch[28] Batch [1260]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097333,	
2017-07-20 15:24:46,898 Epoch[28] Batch [1270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.097296,	
2017-07-20 15:24:51,027 Epoch[28] Batch [1280]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097208,	
2017-07-20 15:24:55,016 Epoch[28] Batch [1290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.097185,	
2017-07-20 15:24:59,081 Epoch[28] Batch [1300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.097208,	
2017-07-20 15:25:03,046 Epoch[28] Batch [1310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.097207,	
2017-07-20 15:25:07,211 Epoch[28] Batch [1320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.097199,	
2017-07-20 15:25:11,273 Epoch[28] Batch [1330]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097176,	
2017-07-20 15:25:15,316 Epoch[28] Batch [1340]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.097232,	
2017-07-20 15:25:19,534 Epoch[28] Batch [1350]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.097186,	
2017-07-20 15:25:23,617 Epoch[28] Batch [1360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.097166,	
2017-07-20 15:25:27,838 Epoch[28] Batch [1370]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.097170,	
2017-07-20 15:25:31,948 Epoch[28] Batch [1380]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.097159,	
2017-07-20 15:25:36,120 Epoch[28] Batch [1390]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097132,	
2017-07-20 15:25:40,298 Epoch[28] Batch [1400]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097128,	
2017-07-20 15:25:44,414 Epoch[28] Batch [1410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097158,	
2017-07-20 15:25:48,531 Epoch[28] Batch [1420]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097088,	
2017-07-20 15:25:52,754 Epoch[28] Batch [1430]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.097111,	
2017-07-20 15:25:56,966 Epoch[28] Batch [1440]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.097076,	
2017-07-20 15:26:01,058 Epoch[28] Batch [1450]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097084,	
2017-07-20 15:26:05,199 Epoch[28] Batch [1460]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097020,	
2017-07-20 15:26:09,268 Epoch[28] Batch [1470]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.097057,	
2017-07-20 15:26:13,596 Epoch[28] Batch [1480]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.097003,	
2017-07-20 15:26:16,091 Epoch[28] Train-FCNLogLoss=0.096985
2017-07-20 15:26:16,091 Epoch[28] Time cost=611.464
2017-07-20 15:26:16,863 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0029.params"
2017-07-20 15:26:18,447 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0029.states"
2017-07-20 15:26:23,214 Epoch[29] Batch [10]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101194,	
2017-07-20 15:26:27,315 Epoch[29] Batch [20]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095851,	
2017-07-20 15:26:31,275 Epoch[29] Batch [30]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.097015,	
2017-07-20 15:26:35,374 Epoch[29] Batch [40]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.098926,	
2017-07-20 15:26:39,515 Epoch[29] Batch [50]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095901,	
2017-07-20 15:26:43,570 Epoch[29] Batch [60]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.096131,	
2017-07-20 15:26:47,761 Epoch[29] Batch [70]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095631,	
2017-07-20 15:26:51,854 Epoch[29] Batch [80]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094891,	
2017-07-20 15:26:56,034 Epoch[29] Batch [90]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095996,	
2017-07-20 15:27:00,100 Epoch[29] Batch [100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096136,	
2017-07-20 15:27:04,252 Epoch[29] Batch [110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095648,	
2017-07-20 15:27:08,349 Epoch[29] Batch [120]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094978,	
2017-07-20 15:27:12,366 Epoch[29] Batch [130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.095368,	
2017-07-20 15:27:16,422 Epoch[29] Batch [140]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096333,	
2017-07-20 15:27:20,542 Epoch[29] Batch [150]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095708,	
2017-07-20 15:27:24,667 Epoch[29] Batch [160]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095884,	
2017-07-20 15:27:28,734 Epoch[29] Batch [170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.095845,	
2017-07-20 15:27:32,937 Epoch[29] Batch [180]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095628,	
2017-07-20 15:27:36,999 Epoch[29] Batch [190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095402,	
2017-07-20 15:27:41,027 Epoch[29] Batch [200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095444,	
2017-07-20 15:27:45,052 Epoch[29] Batch [210]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095479,	
2017-07-20 15:27:48,974 Epoch[29] Batch [220]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.095595,	
2017-07-20 15:27:52,935 Epoch[29] Batch [230]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096110,	
2017-07-20 15:27:57,128 Epoch[29] Batch [240]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096027,	
2017-07-20 15:28:01,214 Epoch[29] Batch [250]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095949,	
2017-07-20 15:28:05,366 Epoch[29] Batch [260]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.095817,	
2017-07-20 15:28:09,551 Epoch[29] Batch [270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095723,	
2017-07-20 15:28:13,595 Epoch[29] Batch [280]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095721,	
2017-07-20 15:28:17,761 Epoch[29] Batch [290]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095924,	
2017-07-20 15:28:21,872 Epoch[29] Batch [300]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095818,	
2017-07-20 15:28:25,965 Epoch[29] Batch [310]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095839,	
2017-07-20 15:28:30,076 Epoch[29] Batch [320]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095876,	
2017-07-20 15:28:34,232 Epoch[29] Batch [330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.096143,	
2017-07-20 15:28:38,411 Epoch[29] Batch [340]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.096312,	
2017-07-20 15:28:42,380 Epoch[29] Batch [350]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096116,	
2017-07-20 15:28:46,384 Epoch[29] Batch [360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096126,	
2017-07-20 15:28:50,441 Epoch[29] Batch [370]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096238,	
2017-07-20 15:28:54,551 Epoch[29] Batch [380]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096252,	
2017-07-20 15:28:58,620 Epoch[29] Batch [390]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.096226,	
2017-07-20 15:29:02,631 Epoch[29] Batch [400]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.096106,	
2017-07-20 15:29:06,694 Epoch[29] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096324,	
2017-07-20 15:29:10,750 Epoch[29] Batch [420]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096488,	
2017-07-20 15:29:14,693 Epoch[29] Batch [430]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.096627,	
2017-07-20 15:29:18,731 Epoch[29] Batch [440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096565,	
2017-07-20 15:29:22,714 Epoch[29] Batch [450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096441,	
2017-07-20 15:29:26,810 Epoch[29] Batch [460]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097038,	
2017-07-20 15:29:30,833 Epoch[29] Batch [470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.097111,	
2017-07-20 15:29:35,047 Epoch[29] Batch [480]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097151,	
2017-07-20 15:29:39,168 Epoch[29] Batch [490]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097148,	
2017-07-20 15:29:43,349 Epoch[29] Batch [500]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097225,	
2017-07-20 15:29:47,498 Epoch[29] Batch [510]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.097302,	
2017-07-20 15:29:51,475 Epoch[29] Batch [520]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.097265,	
2017-07-20 15:29:55,427 Epoch[29] Batch [530]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.097092,	
2017-07-20 15:29:59,568 Epoch[29] Batch [540]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097087,	
2017-07-20 15:30:03,654 Epoch[29] Batch [550]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.097306,	
2017-07-20 15:30:07,898 Epoch[29] Batch [560]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.097227,	
2017-07-20 15:30:11,905 Epoch[29] Batch [570]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097225,	
2017-07-20 15:30:15,920 Epoch[29] Batch [580]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.097245,	
2017-07-20 15:30:20,039 Epoch[29] Batch [590]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097212,	
2017-07-20 15:30:24,103 Epoch[29] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097191,	
2017-07-20 15:30:28,081 Epoch[29] Batch [610]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.096916,	
2017-07-20 15:30:32,249 Epoch[29] Batch [620]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.097013,	
2017-07-20 15:30:36,297 Epoch[29] Batch [630]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097088,	
2017-07-20 15:30:40,303 Epoch[29] Batch [640]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096887,	
2017-07-20 15:30:44,406 Epoch[29] Batch [650]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096804,	
2017-07-20 15:30:48,571 Epoch[29] Batch [660]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096687,	
2017-07-20 15:30:52,603 Epoch[29] Batch [670]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.096632,	
2017-07-20 15:30:56,605 Epoch[29] Batch [680]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096669,	
2017-07-20 15:31:00,594 Epoch[29] Batch [690]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.096605,	
2017-07-20 15:31:04,790 Epoch[29] Batch [700]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096337,	
2017-07-20 15:31:08,758 Epoch[29] Batch [710]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096421,	
2017-07-20 15:31:12,854 Epoch[29] Batch [720]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.096285,	
2017-07-20 15:31:16,784 Epoch[29] Batch [730]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096257,	
2017-07-20 15:31:20,812 Epoch[29] Batch [740]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.096217,	
2017-07-20 15:31:24,851 Epoch[29] Batch [750]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.096308,	
2017-07-20 15:31:28,909 Epoch[29] Batch [760]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096307,	
2017-07-20 15:31:33,021 Epoch[29] Batch [770]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096358,	
2017-07-20 15:31:37,085 Epoch[29] Batch [780]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.096482,	
2017-07-20 15:31:41,135 Epoch[29] Batch [790]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.096556,	
2017-07-20 15:31:45,177 Epoch[29] Batch [800]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.096453,	
2017-07-20 15:31:49,245 Epoch[29] Batch [810]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.096494,	
2017-07-20 15:31:53,343 Epoch[29] Batch [820]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.096507,	
2017-07-20 15:31:57,519 Epoch[29] Batch [830]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.096498,	
2017-07-20 15:32:01,662 Epoch[29] Batch [840]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.096436,	
2017-07-20 15:32:05,725 Epoch[29] Batch [850]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096313,	
2017-07-20 15:32:09,810 Epoch[29] Batch [860]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096299,	
2017-07-20 15:32:13,931 Epoch[29] Batch [870]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.096327,	
2017-07-20 15:32:18,065 Epoch[29] Batch [880]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096281,	
2017-07-20 15:32:22,118 Epoch[29] Batch [890]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.096262,	
2017-07-20 15:32:26,196 Epoch[29] Batch [900]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096283,	
2017-07-20 15:32:30,372 Epoch[29] Batch [910]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.096306,	
2017-07-20 15:32:34,335 Epoch[29] Batch [920]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096267,	
2017-07-20 15:32:38,342 Epoch[29] Batch [930]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.096378,	
2017-07-20 15:32:42,502 Epoch[29] Batch [940]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.096418,	
2017-07-20 15:32:46,635 Epoch[29] Batch [950]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096333,	
2017-07-20 15:32:50,571 Epoch[29] Batch [960]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.096358,	
2017-07-20 15:32:54,659 Epoch[29] Batch [970]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096318,	
2017-07-20 15:32:58,722 Epoch[29] Batch [980]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.096566,	
2017-07-20 15:33:02,800 Epoch[29] Batch [990]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096628,	
2017-07-20 15:33:06,824 Epoch[29] Batch [1000]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096959,	
2017-07-20 15:33:10,877 Epoch[29] Batch [1010]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.097131,	
2017-07-20 15:33:14,882 Epoch[29] Batch [1020]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097211,	
2017-07-20 15:33:18,932 Epoch[29] Batch [1030]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097498,	
2017-07-20 15:33:22,877 Epoch[29] Batch [1040]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.097552,	
2017-07-20 15:33:26,975 Epoch[29] Batch [1050]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097649,	
2017-07-20 15:33:30,979 Epoch[29] Batch [1060]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097698,	
2017-07-20 15:33:34,929 Epoch[29] Batch [1070]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.097712,	
2017-07-20 15:33:38,961 Epoch[29] Batch [1080]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.097610,	
2017-07-20 15:33:43,147 Epoch[29] Batch [1090]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.097667,	
2017-07-20 15:33:47,183 Epoch[29] Batch [1100]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097692,	
2017-07-20 15:33:51,326 Epoch[29] Batch [1110]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097745,	
2017-07-20 15:33:55,324 Epoch[29] Batch [1120]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.097772,	
2017-07-20 15:33:59,440 Epoch[29] Batch [1130]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097772,	
2017-07-20 15:34:03,377 Epoch[29] Batch [1140]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.097829,	
2017-07-20 15:34:07,381 Epoch[29] Batch [1150]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097908,	
2017-07-20 15:34:11,515 Epoch[29] Batch [1160]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097929,	
2017-07-20 15:34:15,593 Epoch[29] Batch [1170]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097987,	
2017-07-20 15:34:19,697 Epoch[29] Batch [1180]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.098048,	
2017-07-20 15:34:23,926 Epoch[29] Batch [1190]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.098193,	
2017-07-20 15:34:28,124 Epoch[29] Batch [1200]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098126,	
2017-07-20 15:34:32,182 Epoch[29] Batch [1210]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098043,	
2017-07-20 15:34:36,191 Epoch[29] Batch [1220]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.098106,	
2017-07-20 15:34:40,262 Epoch[29] Batch [1230]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.098033,	
2017-07-20 15:34:44,435 Epoch[29] Batch [1240]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097910,	
2017-07-20 15:34:48,578 Epoch[29] Batch [1250]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097987,	
2017-07-20 15:34:52,679 Epoch[29] Batch [1260]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.097985,	
2017-07-20 15:34:56,860 Epoch[29] Batch [1270]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097990,	
2017-07-20 15:35:00,983 Epoch[29] Batch [1280]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098013,	
2017-07-20 15:35:05,080 Epoch[29] Batch [1290]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.098057,	
2017-07-20 15:35:09,064 Epoch[29] Batch [1300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.098086,	
2017-07-20 15:35:13,177 Epoch[29] Batch [1310]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.098131,	
2017-07-20 15:35:17,254 Epoch[29] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.098024,	
2017-07-20 15:35:21,339 Epoch[29] Batch [1330]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.098023,	
2017-07-20 15:35:25,541 Epoch[29] Batch [1340]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.098036,	
2017-07-20 15:35:29,619 Epoch[29] Batch [1350]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.098042,	
2017-07-20 15:35:33,636 Epoch[29] Batch [1360]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.098059,	
2017-07-20 15:35:37,735 Epoch[29] Batch [1370]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.098053,	
2017-07-20 15:35:41,986 Epoch[29] Batch [1380]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.098115,	
2017-07-20 15:35:46,091 Epoch[29] Batch [1390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.098053,	
2017-07-20 15:35:50,246 Epoch[29] Batch [1400]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.098096,	
2017-07-20 15:35:54,368 Epoch[29] Batch [1410]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098055,	
2017-07-20 15:35:58,338 Epoch[29] Batch [1420]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.098103,	
2017-07-20 15:36:02,386 Epoch[29] Batch [1430]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.098069,	
2017-07-20 15:36:06,532 Epoch[29] Batch [1440]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.098052,	
2017-07-20 15:36:10,497 Epoch[29] Batch [1450]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.098078,	
2017-07-20 15:36:14,621 Epoch[29] Batch [1460]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098071,	
2017-07-20 15:36:18,703 Epoch[29] Batch [1470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.098121,	
2017-07-20 15:36:22,783 Epoch[29] Batch [1480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.098162,	
2017-07-20 15:36:25,206 Epoch[29] Train-FCNLogLoss=0.098198
2017-07-20 15:36:25,206 Epoch[29] Time cost=606.759
2017-07-20 15:36:25,944 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0030.params"
2017-07-20 15:36:27,576 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0030.states"
2017-07-20 15:36:32,381 Epoch[30] Batch [10]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.097988,	
2017-07-20 15:36:36,568 Epoch[30] Batch [20]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098377,	
2017-07-20 15:36:40,717 Epoch[30] Batch [30]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.098250,	
2017-07-20 15:36:44,826 Epoch[30] Batch [40]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.098918,	
2017-07-20 15:36:48,921 Epoch[30] Batch [50]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097979,	
2017-07-20 15:36:52,899 Epoch[30] Batch [60]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.097982,	
2017-07-20 15:36:57,120 Epoch[30] Batch [70]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.097055,	
2017-07-20 15:37:01,227 Epoch[30] Batch [80]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.097122,	
2017-07-20 15:37:05,415 Epoch[30] Batch [90]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098216,	
2017-07-20 15:37:09,571 Epoch[30] Batch [100]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.097969,	
2017-07-20 15:37:13,753 Epoch[30] Batch [110]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.098349,	
2017-07-20 15:37:17,797 Epoch[30] Batch [120]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.098398,	
2017-07-20 15:37:21,993 Epoch[30] Batch [130]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098200,	
2017-07-20 15:37:26,105 Epoch[30] Batch [140]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.097659,	
2017-07-20 15:37:30,157 Epoch[30] Batch [150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.096861,	
2017-07-20 15:37:34,328 Epoch[30] Batch [160]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097495,	
2017-07-20 15:37:38,431 Epoch[30] Batch [170]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096728,	
2017-07-20 15:37:42,419 Epoch[30] Batch [180]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.096703,	
2017-07-20 15:37:46,454 Epoch[30] Batch [190]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097338,	
2017-07-20 15:37:50,504 Epoch[30] Batch [200]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097303,	
2017-07-20 15:37:54,639 Epoch[30] Batch [210]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097521,	
2017-07-20 15:37:58,748 Epoch[30] Batch [220]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.097314,	
2017-07-20 15:38:02,944 Epoch[30] Batch [230]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097334,	
2017-07-20 15:38:06,980 Epoch[30] Batch [240]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097372,	
2017-07-20 15:38:11,094 Epoch[30] Batch [250]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.096938,	
2017-07-20 15:38:15,280 Epoch[30] Batch [260]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.097141,	
2017-07-20 15:38:19,293 Epoch[30] Batch [270]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.097105,	
2017-07-20 15:38:23,361 Epoch[30] Batch [280]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.097037,	
2017-07-20 15:38:27,288 Epoch[30] Batch [290]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.096739,	
2017-07-20 15:38:31,463 Epoch[30] Batch [300]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.096461,	
2017-07-20 15:38:35,457 Epoch[30] Batch [310]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.096544,	
2017-07-20 15:38:39,603 Epoch[30] Batch [320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.096404,	
2017-07-20 15:38:43,731 Epoch[30] Batch [330]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096289,	
2017-07-20 15:38:47,831 Epoch[30] Batch [340]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095954,	
2017-07-20 15:38:51,972 Epoch[30] Batch [350]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.096038,	
2017-07-20 15:38:56,026 Epoch[30] Batch [360]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095962,	
2017-07-20 15:39:00,214 Epoch[30] Batch [370]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095914,	
2017-07-20 15:39:04,288 Epoch[30] Batch [380]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.096270,	
2017-07-20 15:39:08,379 Epoch[30] Batch [390]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.096429,	
2017-07-20 15:39:12,435 Epoch[30] Batch [400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096279,	
2017-07-20 15:39:16,646 Epoch[30] Batch [410]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.096234,	
2017-07-20 15:39:20,797 Epoch[30] Batch [420]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096283,	
2017-07-20 15:39:24,879 Epoch[30] Batch [430]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.096219,	
2017-07-20 15:39:28,953 Epoch[30] Batch [440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.096272,	
2017-07-20 15:39:32,997 Epoch[30] Batch [450]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.096306,	
2017-07-20 15:39:37,145 Epoch[30] Batch [460]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096235,	
2017-07-20 15:39:41,187 Epoch[30] Batch [470]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.095916,	
2017-07-20 15:39:45,298 Epoch[30] Batch [480]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095962,	
2017-07-20 15:39:49,296 Epoch[30] Batch [490]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096165,	
2017-07-20 15:39:53,396 Epoch[30] Batch [500]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.096139,	
2017-07-20 15:39:57,401 Epoch[30] Batch [510]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096224,	
2017-07-20 15:40:01,482 Epoch[30] Batch [520]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.096239,	
2017-07-20 15:40:05,694 Epoch[30] Batch [530]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.096036,	
2017-07-20 15:40:09,691 Epoch[30] Batch [540]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096128,	
2017-07-20 15:40:13,818 Epoch[30] Batch [550]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096023,	
2017-07-20 15:40:17,847 Epoch[30] Batch [560]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.096231,	
2017-07-20 15:40:22,043 Epoch[30] Batch [570]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096278,	
2017-07-20 15:40:26,189 Epoch[30] Batch [580]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.096507,	
2017-07-20 15:40:30,245 Epoch[30] Batch [590]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096432,	
2017-07-20 15:40:34,261 Epoch[30] Batch [600]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.096301,	
2017-07-20 15:40:38,430 Epoch[30] Batch [610]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.096340,	
2017-07-20 15:40:42,420 Epoch[30] Batch [620]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.096425,	
2017-07-20 15:40:46,513 Epoch[30] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.096535,	
2017-07-20 15:40:50,631 Epoch[30] Batch [640]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.096553,	
2017-07-20 15:40:54,815 Epoch[30] Batch [650]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.096443,	
2017-07-20 15:40:58,808 Epoch[30] Batch [660]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.096417,	
2017-07-20 15:41:02,900 Epoch[30] Batch [670]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.096426,	
2017-07-20 15:41:06,884 Epoch[30] Batch [680]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096393,	
2017-07-20 15:41:10,976 Epoch[30] Batch [690]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.096387,	
2017-07-20 15:41:15,126 Epoch[30] Batch [700]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096317,	
2017-07-20 15:41:19,402 Epoch[30] Batch [710]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.096297,	
2017-07-20 15:41:23,549 Epoch[30] Batch [720]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.096199,	
2017-07-20 15:41:27,597 Epoch[30] Batch [730]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.096258,	
2017-07-20 15:41:31,767 Epoch[30] Batch [740]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.096315,	
2017-07-20 15:41:35,694 Epoch[30] Batch [750]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096173,	
2017-07-20 15:41:39,660 Epoch[30] Batch [760]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096339,	
2017-07-20 15:41:43,828 Epoch[30] Batch [770]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096291,	
2017-07-20 15:41:47,951 Epoch[30] Batch [780]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.096388,	
2017-07-20 15:41:52,028 Epoch[30] Batch [790]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096396,	
2017-07-20 15:41:56,195 Epoch[30] Batch [800]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096509,	
2017-07-20 15:42:00,351 Epoch[30] Batch [810]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.096455,	
2017-07-20 15:42:04,547 Epoch[30] Batch [820]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096425,	
2017-07-20 15:42:08,711 Epoch[30] Batch [830]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.096486,	
2017-07-20 15:42:12,787 Epoch[30] Batch [840]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096539,	
2017-07-20 15:42:16,816 Epoch[30] Batch [850]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.096517,	
2017-07-20 15:42:20,871 Epoch[30] Batch [860]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096457,	
2017-07-20 15:42:25,032 Epoch[30] Batch [870]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.096435,	
2017-07-20 15:42:29,082 Epoch[30] Batch [880]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.096314,	
2017-07-20 15:42:33,104 Epoch[30] Batch [890]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.096322,	
2017-07-20 15:42:37,154 Epoch[30] Batch [900]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.096120,	
2017-07-20 15:42:41,280 Epoch[30] Batch [910]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096017,	
2017-07-20 15:42:45,449 Epoch[30] Batch [920]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095979,	
2017-07-20 15:42:49,546 Epoch[30] Batch [930]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095957,	
2017-07-20 15:42:53,754 Epoch[30] Batch [940]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095990,	
2017-07-20 15:42:57,832 Epoch[30] Batch [950]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096062,	
2017-07-20 15:43:01,907 Epoch[30] Batch [960]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.096020,	
2017-07-20 15:43:05,964 Epoch[30] Batch [970]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096041,	
2017-07-20 15:43:10,097 Epoch[30] Batch [980]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096015,	
2017-07-20 15:43:14,085 Epoch[30] Batch [990]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095983,	
2017-07-20 15:43:18,167 Epoch[30] Batch [1000]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.096123,	
2017-07-20 15:43:22,328 Epoch[30] Batch [1010]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.096162,	
2017-07-20 15:43:26,408 Epoch[30] Batch [1020]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096215,	
2017-07-20 15:43:30,511 Epoch[30] Batch [1030]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096183,	
2017-07-20 15:43:34,586 Epoch[30] Batch [1040]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.096169,	
2017-07-20 15:43:38,732 Epoch[30] Batch [1050]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.096176,	
2017-07-20 15:43:42,957 Epoch[30] Batch [1060]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.096092,	
2017-07-20 15:43:47,105 Epoch[30] Batch [1070]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096060,	
2017-07-20 15:43:51,259 Epoch[30] Batch [1080]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.096032,	
2017-07-20 15:43:55,445 Epoch[30] Batch [1090]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095977,	
2017-07-20 15:43:59,486 Epoch[30] Batch [1100]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.096034,	
2017-07-20 15:44:03,591 Epoch[30] Batch [1110]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095924,	
2017-07-20 15:44:07,639 Epoch[30] Batch [1120]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095909,	
2017-07-20 15:44:11,667 Epoch[30] Batch [1130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095889,	
2017-07-20 15:44:15,779 Epoch[30] Batch [1140]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095951,	
2017-07-20 15:44:19,938 Epoch[30] Batch [1150]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.095967,	
2017-07-20 15:44:24,050 Epoch[30] Batch [1160]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096014,	
2017-07-20 15:44:28,153 Epoch[30] Batch [1170]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095968,	
2017-07-20 15:44:32,481 Epoch[30] Batch [1180]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.095973,	
2017-07-20 15:44:36,544 Epoch[30] Batch [1190]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.095971,	
2017-07-20 15:44:40,537 Epoch[30] Batch [1200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095958,	
2017-07-20 15:44:44,666 Epoch[30] Batch [1210]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095913,	
2017-07-20 15:44:48,862 Epoch[30] Batch [1220]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095926,	
2017-07-20 15:44:52,984 Epoch[30] Batch [1230]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095965,	
2017-07-20 15:44:57,100 Epoch[30] Batch [1240]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095908,	
2017-07-20 15:45:01,178 Epoch[30] Batch [1250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096013,	
2017-07-20 15:45:05,288 Epoch[30] Batch [1260]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095996,	
2017-07-20 15:45:09,337 Epoch[30] Batch [1270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095916,	
2017-07-20 15:45:13,413 Epoch[30] Batch [1280]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095931,	
2017-07-20 15:45:17,372 Epoch[30] Batch [1290]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095883,	
2017-07-20 15:45:21,391 Epoch[30] Batch [1300]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095848,	
2017-07-20 15:45:25,572 Epoch[30] Batch [1310]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095830,	
2017-07-20 15:45:29,595 Epoch[30] Batch [1320]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095806,	
2017-07-20 15:45:33,621 Epoch[30] Batch [1330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095920,	
2017-07-20 15:45:37,737 Epoch[30] Batch [1340]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095856,	
2017-07-20 15:45:41,783 Epoch[30] Batch [1350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095790,	
2017-07-20 15:45:45,880 Epoch[30] Batch [1360]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095834,	
2017-07-20 15:45:49,978 Epoch[30] Batch [1370]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095795,	
2017-07-20 15:45:54,213 Epoch[30] Batch [1380]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095788,	
2017-07-20 15:45:58,392 Epoch[30] Batch [1390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095904,	
2017-07-20 15:46:02,545 Epoch[30] Batch [1400]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095950,	
2017-07-20 15:46:06,665 Epoch[30] Batch [1410]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095974,	
2017-07-20 15:46:10,801 Epoch[30] Batch [1420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.095983,	
2017-07-20 15:46:14,858 Epoch[30] Batch [1430]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096009,	
2017-07-20 15:46:19,036 Epoch[30] Batch [1440]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.096037,	
2017-07-20 15:46:23,145 Epoch[30] Batch [1450]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095952,	
2017-07-20 15:46:27,263 Epoch[30] Batch [1460]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095978,	
2017-07-20 15:46:31,496 Epoch[30] Batch [1470]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095961,	
2017-07-20 15:46:35,473 Epoch[30] Batch [1480]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095983,	
2017-07-20 15:46:37,977 Epoch[30] Train-FCNLogLoss=0.096008
2017-07-20 15:46:37,978 Epoch[30] Time cost=610.401
2017-07-20 15:46:38,694 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0031.params"
2017-07-20 15:46:40,138 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0031.states"
2017-07-20 15:46:44,860 Epoch[31] Batch [10]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095651,	
2017-07-20 15:46:48,998 Epoch[31] Batch [20]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101924,	
2017-07-20 15:46:53,086 Epoch[31] Batch [30]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.101706,	
2017-07-20 15:46:57,199 Epoch[31] Batch [40]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.099246,	
2017-07-20 15:47:01,220 Epoch[31] Batch [50]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.097640,	
2017-07-20 15:47:05,440 Epoch[31] Batch [60]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095449,	
2017-07-20 15:47:09,489 Epoch[31] Batch [70]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.096802,	
2017-07-20 15:47:13,477 Epoch[31] Batch [80]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.096066,	
2017-07-20 15:47:17,510 Epoch[31] Batch [90]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.096716,	
2017-07-20 15:47:21,710 Epoch[31] Batch [100]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096217,	
2017-07-20 15:47:25,671 Epoch[31] Batch [110]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094966,	
2017-07-20 15:47:29,804 Epoch[31] Batch [120]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094803,	
2017-07-20 15:47:33,961 Epoch[31] Batch [130]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.094665,	
2017-07-20 15:47:37,972 Epoch[31] Batch [140]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094029,	
2017-07-20 15:47:42,019 Epoch[31] Batch [150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.093604,	
2017-07-20 15:47:46,110 Epoch[31] Batch [160]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093707,	
2017-07-20 15:47:50,106 Epoch[31] Batch [170]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.093899,	
2017-07-20 15:47:54,237 Epoch[31] Batch [180]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093687,	
2017-07-20 15:47:58,242 Epoch[31] Batch [190]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.093757,	
2017-07-20 15:48:02,266 Epoch[31] Batch [200]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.093283,	
2017-07-20 15:48:06,285 Epoch[31] Batch [210]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.093942,	
2017-07-20 15:48:10,281 Epoch[31] Batch [220]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094127,	
2017-07-20 15:48:14,293 Epoch[31] Batch [230]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094455,	
2017-07-20 15:48:18,251 Epoch[31] Batch [240]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094756,	
2017-07-20 15:48:22,345 Epoch[31] Batch [250]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094747,	
2017-07-20 15:48:26,332 Epoch[31] Batch [260]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094995,	
2017-07-20 15:48:30,408 Epoch[31] Batch [270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094717,	
2017-07-20 15:48:34,505 Epoch[31] Batch [280]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094867,	
2017-07-20 15:48:38,513 Epoch[31] Batch [290]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094762,	
2017-07-20 15:48:42,525 Epoch[31] Batch [300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094568,	
2017-07-20 15:48:46,494 Epoch[31] Batch [310]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094937,	
2017-07-20 15:48:50,586 Epoch[31] Batch [320]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095199,	
2017-07-20 15:48:54,647 Epoch[31] Batch [330]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095075,	
2017-07-20 15:48:58,722 Epoch[31] Batch [340]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.095436,	
2017-07-20 15:49:02,852 Epoch[31] Batch [350]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095463,	
2017-07-20 15:49:06,981 Epoch[31] Batch [360]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095787,	
2017-07-20 15:49:10,937 Epoch[31] Batch [370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095755,	
2017-07-20 15:49:15,053 Epoch[31] Batch [380]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095778,	
2017-07-20 15:49:19,086 Epoch[31] Batch [390]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095635,	
2017-07-20 15:49:23,163 Epoch[31] Batch [400]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095304,	
2017-07-20 15:49:27,309 Epoch[31] Batch [410]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095183,	
2017-07-20 15:49:31,401 Epoch[31] Batch [420]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095291,	
2017-07-20 15:49:35,502 Epoch[31] Batch [430]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095367,	
2017-07-20 15:49:39,605 Epoch[31] Batch [440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095362,	
2017-07-20 15:49:43,710 Epoch[31] Batch [450]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095501,	
2017-07-20 15:49:47,786 Epoch[31] Batch [460]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.095469,	
2017-07-20 15:49:51,842 Epoch[31] Batch [470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.095423,	
2017-07-20 15:49:55,852 Epoch[31] Batch [480]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095541,	
2017-07-20 15:49:59,929 Epoch[31] Batch [490]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095496,	
2017-07-20 15:50:04,084 Epoch[31] Batch [500]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095660,	
2017-07-20 15:50:08,100 Epoch[31] Batch [510]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.095307,	
2017-07-20 15:50:12,151 Epoch[31] Batch [520]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095449,	
2017-07-20 15:50:16,202 Epoch[31] Batch [530]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095410,	
2017-07-20 15:50:20,380 Epoch[31] Batch [540]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.095397,	
2017-07-20 15:50:24,421 Epoch[31] Batch [550]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.095474,	
2017-07-20 15:50:28,476 Epoch[31] Batch [560]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095397,	
2017-07-20 15:50:32,676 Epoch[31] Batch [570]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095405,	
2017-07-20 15:50:36,712 Epoch[31] Batch [580]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.095464,	
2017-07-20 15:50:40,782 Epoch[31] Batch [590]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095565,	
2017-07-20 15:50:45,050 Epoch[31] Batch [600]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095602,	
2017-07-20 15:50:49,094 Epoch[31] Batch [610]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095477,	
2017-07-20 15:50:53,051 Epoch[31] Batch [620]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095463,	
2017-07-20 15:50:56,973 Epoch[31] Batch [630]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.095327,	
2017-07-20 15:51:01,022 Epoch[31] Batch [640]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095264,	
2017-07-20 15:51:04,931 Epoch[31] Batch [650]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095323,	
2017-07-20 15:51:09,007 Epoch[31] Batch [660]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.095335,	
2017-07-20 15:51:13,072 Epoch[31] Batch [670]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.095414,	
2017-07-20 15:51:17,135 Epoch[31] Batch [680]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.095530,	
2017-07-20 15:51:21,155 Epoch[31] Batch [690]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095574,	
2017-07-20 15:51:25,270 Epoch[31] Batch [700]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095714,	
2017-07-20 15:51:29,362 Epoch[31] Batch [710]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095603,	
2017-07-20 15:51:33,510 Epoch[31] Batch [720]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095577,	
2017-07-20 15:51:37,839 Epoch[31] Batch [730]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.095654,	
2017-07-20 15:51:42,146 Epoch[31] Batch [740]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.095615,	
2017-07-20 15:51:46,296 Epoch[31] Batch [750]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.095666,	
2017-07-20 15:51:50,530 Epoch[31] Batch [760]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095622,	
2017-07-20 15:51:54,699 Epoch[31] Batch [770]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095654,	
2017-07-20 15:51:58,799 Epoch[31] Batch [780]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095654,	
2017-07-20 15:52:02,961 Epoch[31] Batch [790]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095672,	
2017-07-20 15:52:07,190 Epoch[31] Batch [800]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.095788,	
2017-07-20 15:52:11,368 Epoch[31] Batch [810]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.095830,	
2017-07-20 15:52:15,702 Epoch[31] Batch [820]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.095949,	
2017-07-20 15:52:19,943 Epoch[31] Batch [830]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.096057,	
2017-07-20 15:52:24,046 Epoch[31] Batch [840]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096105,	
2017-07-20 15:52:28,197 Epoch[31] Batch [850]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096071,	
2017-07-20 15:52:32,383 Epoch[31] Batch [860]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.096121,	
2017-07-20 15:52:36,495 Epoch[31] Batch [870]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096197,	
2017-07-20 15:52:40,767 Epoch[31] Batch [880]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.096223,	
2017-07-20 15:52:44,877 Epoch[31] Batch [890]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096102,	
2017-07-20 15:52:49,071 Epoch[31] Batch [900]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096023,	
2017-07-20 15:52:53,390 Epoch[31] Batch [910]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096026,	
2017-07-20 15:52:57,626 Epoch[31] Batch [920]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.096071,	
2017-07-20 15:53:01,806 Epoch[31] Batch [930]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095982,	
2017-07-20 15:53:06,176 Epoch[31] Batch [940]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096074,	
2017-07-20 15:53:10,492 Epoch[31] Batch [950]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.096036,	
2017-07-20 15:53:14,553 Epoch[31] Batch [960]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096120,	
2017-07-20 15:53:18,749 Epoch[31] Batch [970]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096183,	
2017-07-20 15:53:22,919 Epoch[31] Batch [980]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.096232,	
2017-07-20 15:53:26,944 Epoch[31] Batch [990]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096190,	
2017-07-20 15:53:30,943 Epoch[31] Batch [1000]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.096196,	
2017-07-20 15:53:35,065 Epoch[31] Batch [1010]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.096136,	
2017-07-20 15:53:39,065 Epoch[31] Batch [1020]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.096081,	
2017-07-20 15:53:43,107 Epoch[31] Batch [1030]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.095990,	
2017-07-20 15:53:47,144 Epoch[31] Batch [1040]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096016,	
2017-07-20 15:53:51,287 Epoch[31] Batch [1050]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.096057,	
2017-07-20 15:53:55,462 Epoch[31] Batch [1060]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.095921,	
2017-07-20 15:53:59,698 Epoch[31] Batch [1070]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095820,	
2017-07-20 15:54:03,878 Epoch[31] Batch [1080]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095840,	
2017-07-20 15:54:08,044 Epoch[31] Batch [1090]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095822,	
2017-07-20 15:54:12,170 Epoch[31] Batch [1100]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095824,	
2017-07-20 15:54:16,257 Epoch[31] Batch [1110]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095779,	
2017-07-20 15:54:20,446 Epoch[31] Batch [1120]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095721,	
2017-07-20 15:54:24,451 Epoch[31] Batch [1130]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095657,	
2017-07-20 15:54:28,582 Epoch[31] Batch [1140]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095690,	
2017-07-20 15:54:32,788 Epoch[31] Batch [1150]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095646,	
2017-07-20 15:54:37,142 Epoch[31] Batch [1160]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.095682,	
2017-07-20 15:54:41,373 Epoch[31] Batch [1170]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095656,	
2017-07-20 15:54:45,462 Epoch[31] Batch [1180]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095674,	
2017-07-20 15:54:49,512 Epoch[31] Batch [1190]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095756,	
2017-07-20 15:54:53,683 Epoch[31] Batch [1200]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095708,	
2017-07-20 15:54:57,876 Epoch[31] Batch [1210]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095698,	
2017-07-20 15:55:02,007 Epoch[31] Batch [1220]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095723,	
2017-07-20 15:55:06,270 Epoch[31] Batch [1230]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095762,	
2017-07-20 15:55:10,378 Epoch[31] Batch [1240]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.095762,	
2017-07-20 15:55:14,501 Epoch[31] Batch [1250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095765,	
2017-07-20 15:55:18,724 Epoch[31] Batch [1260]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.095758,	
2017-07-20 15:55:22,953 Epoch[31] Batch [1270]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.095749,	
2017-07-20 15:55:27,095 Epoch[31] Batch [1280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095708,	
2017-07-20 15:55:31,286 Epoch[31] Batch [1290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095606,	
2017-07-20 15:55:35,517 Epoch[31] Batch [1300]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095633,	
2017-07-20 15:55:39,734 Epoch[31] Batch [1310]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.095769,	
2017-07-20 15:55:43,818 Epoch[31] Batch [1320]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095765,	
2017-07-20 15:55:47,959 Epoch[31] Batch [1330]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095704,	
2017-07-20 15:55:52,071 Epoch[31] Batch [1340]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095687,	
2017-07-20 15:55:56,292 Epoch[31] Batch [1350]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095607,	
2017-07-20 15:56:00,462 Epoch[31] Batch [1360]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095594,	
2017-07-20 15:56:04,725 Epoch[31] Batch [1370]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095596,	
2017-07-20 15:56:08,880 Epoch[31] Batch [1380]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095585,	
2017-07-20 15:56:13,011 Epoch[31] Batch [1390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095470,	
2017-07-20 15:56:17,155 Epoch[31] Batch [1400]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095563,	
2017-07-20 15:56:21,386 Epoch[31] Batch [1410]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095669,	
2017-07-20 15:56:25,540 Epoch[31] Batch [1420]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095679,	
2017-07-20 15:56:29,797 Epoch[31] Batch [1430]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.095632,	
2017-07-20 15:56:33,897 Epoch[31] Batch [1440]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095611,	
2017-07-20 15:56:38,147 Epoch[31] Batch [1450]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095628,	
2017-07-20 15:56:42,298 Epoch[31] Batch [1460]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.095581,	
2017-07-20 15:56:46,409 Epoch[31] Batch [1470]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095516,	
2017-07-20 15:56:50,605 Epoch[31] Batch [1480]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095416,	
2017-07-20 15:56:53,010 Epoch[31] Train-FCNLogLoss=0.095439
2017-07-20 15:56:53,010 Epoch[31] Time cost=612.872
2017-07-20 15:56:53,821 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0032.params"
2017-07-20 15:56:55,437 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0032.states"
2017-07-20 15:57:00,418 Epoch[32] Batch [10]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.094000,	
2017-07-20 15:57:04,526 Epoch[32] Batch [20]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090926,	
2017-07-20 15:57:08,751 Epoch[32] Batch [30]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091018,	
2017-07-20 15:57:12,823 Epoch[32] Batch [40]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.089358,	
2017-07-20 15:57:17,058 Epoch[32] Batch [50]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.088264,	
2017-07-20 15:57:21,155 Epoch[32] Batch [60]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.089272,	
2017-07-20 15:57:25,315 Epoch[32] Batch [70]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.090291,	
2017-07-20 15:57:29,488 Epoch[32] Batch [80]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090123,	
2017-07-20 15:57:33,578 Epoch[32] Batch [90]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.091051,	
2017-07-20 15:57:37,655 Epoch[32] Batch [100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092636,	
2017-07-20 15:57:41,902 Epoch[32] Batch [110]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.092321,	
2017-07-20 15:57:46,029 Epoch[32] Batch [120]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091390,	
2017-07-20 15:57:50,213 Epoch[32] Batch [130]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.090758,	
2017-07-20 15:57:54,284 Epoch[32] Batch [140]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.090798,	
2017-07-20 15:57:58,286 Epoch[32] Batch [150]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.090549,	
2017-07-20 15:58:02,395 Epoch[32] Batch [160]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.091370,	
2017-07-20 15:58:06,664 Epoch[32] Batch [170]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.091468,	
2017-07-20 15:58:10,831 Epoch[32] Batch [180]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.091426,	
2017-07-20 15:58:14,898 Epoch[32] Batch [190]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091937,	
2017-07-20 15:58:19,049 Epoch[32] Batch [200]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.092128,	
2017-07-20 15:58:23,148 Epoch[32] Batch [210]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.092211,	
2017-07-20 15:58:27,213 Epoch[32] Batch [220]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.092230,	
2017-07-20 15:58:31,317 Epoch[32] Batch [230]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091705,	
2017-07-20 15:58:35,554 Epoch[32] Batch [240]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091979,	
2017-07-20 15:58:39,898 Epoch[32] Batch [250]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.092240,	
2017-07-20 15:58:44,037 Epoch[32] Batch [260]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.092575,	
2017-07-20 15:58:48,170 Epoch[32] Batch [270]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.093562,	
2017-07-20 15:58:52,232 Epoch[32] Batch [280]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094124,	
2017-07-20 15:58:56,510 Epoch[32] Batch [290]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094610,	
2017-07-20 15:59:00,586 Epoch[32] Batch [300]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094755,	
2017-07-20 15:59:04,787 Epoch[32] Batch [310]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.094828,	
2017-07-20 15:59:08,881 Epoch[32] Batch [320]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094594,	
2017-07-20 15:59:13,113 Epoch[32] Batch [330]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.094391,	
2017-07-20 15:59:17,226 Epoch[32] Batch [340]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.094465,	
2017-07-20 15:59:21,263 Epoch[32] Batch [350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094278,	
2017-07-20 15:59:25,390 Epoch[32] Batch [360]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094238,	
2017-07-20 15:59:29,519 Epoch[32] Batch [370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093999,	
2017-07-20 15:59:33,760 Epoch[32] Batch [380]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.094031,	
2017-07-20 15:59:37,893 Epoch[32] Batch [390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094202,	
2017-07-20 15:59:42,078 Epoch[32] Batch [400]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094320,	
2017-07-20 15:59:46,294 Epoch[32] Batch [410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094474,	
2017-07-20 15:59:50,436 Epoch[32] Batch [420]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094527,	
2017-07-20 15:59:54,493 Epoch[32] Batch [430]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094233,	
2017-07-20 15:59:58,566 Epoch[32] Batch [440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094220,	
2017-07-20 16:00:02,732 Epoch[32] Batch [450]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.093967,	
2017-07-20 16:00:06,756 Epoch[32] Batch [460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094014,	
2017-07-20 16:00:10,863 Epoch[32] Batch [470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093987,	
2017-07-20 16:00:14,968 Epoch[32] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.093719,	
2017-07-20 16:00:19,063 Epoch[32] Batch [490]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093565,	
2017-07-20 16:00:23,128 Epoch[32] Batch [500]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.093887,	
2017-07-20 16:00:27,253 Epoch[32] Batch [510]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.093913,	
2017-07-20 16:00:31,582 Epoch[32] Batch [520]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.093814,	
2017-07-20 16:00:35,704 Epoch[32] Batch [530]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.093819,	
2017-07-20 16:00:39,739 Epoch[32] Batch [540]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094183,	
2017-07-20 16:00:43,780 Epoch[32] Batch [550]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094236,	
2017-07-20 16:00:48,007 Epoch[32] Batch [560]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094154,	
2017-07-20 16:00:52,174 Epoch[32] Batch [570]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094264,	
2017-07-20 16:00:56,360 Epoch[32] Batch [580]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094231,	
2017-07-20 16:01:00,540 Epoch[32] Batch [590]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094272,	
2017-07-20 16:01:04,575 Epoch[32] Batch [600]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094329,	
2017-07-20 16:01:08,792 Epoch[32] Batch [610]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094309,	
2017-07-20 16:01:13,044 Epoch[32] Batch [620]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.094431,	
2017-07-20 16:01:17,218 Epoch[32] Batch [630]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094374,	
2017-07-20 16:01:21,495 Epoch[32] Batch [640]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094572,	
2017-07-20 16:01:25,611 Epoch[32] Batch [650]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.094625,	
2017-07-20 16:01:29,759 Epoch[32] Batch [660]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094704,	
2017-07-20 16:01:33,875 Epoch[32] Batch [670]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.094585,	
2017-07-20 16:01:38,008 Epoch[32] Batch [680]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094453,	
2017-07-20 16:01:42,176 Epoch[32] Batch [690]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094493,	
2017-07-20 16:01:46,542 Epoch[32] Batch [700]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.094530,	
2017-07-20 16:01:50,600 Epoch[32] Batch [710]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094545,	
2017-07-20 16:01:54,694 Epoch[32] Batch [720]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094684,	
2017-07-20 16:01:58,885 Epoch[32] Batch [730]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.094669,	
2017-07-20 16:02:03,025 Epoch[32] Batch [740]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094797,	
2017-07-20 16:02:07,226 Epoch[32] Batch [750]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.094749,	
2017-07-20 16:02:11,441 Epoch[32] Batch [760]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094825,	
2017-07-20 16:02:15,556 Epoch[32] Batch [770]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094692,	
2017-07-20 16:02:19,662 Epoch[32] Batch [780]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094815,	
2017-07-20 16:02:23,806 Epoch[32] Batch [790]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094731,	
2017-07-20 16:02:27,896 Epoch[32] Batch [800]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094800,	
2017-07-20 16:02:31,940 Epoch[32] Batch [810]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094769,	
2017-07-20 16:02:36,041 Epoch[32] Batch [820]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094692,	
2017-07-20 16:02:40,254 Epoch[32] Batch [830]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094616,	
2017-07-20 16:02:44,476 Epoch[32] Batch [840]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094637,	
2017-07-20 16:02:48,574 Epoch[32] Batch [850]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094717,	
2017-07-20 16:02:52,632 Epoch[32] Batch [860]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094651,	
2017-07-20 16:02:56,932 Epoch[32] Batch [870]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094557,	
2017-07-20 16:03:01,053 Epoch[32] Batch [880]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094563,	
2017-07-20 16:03:05,215 Epoch[32] Batch [890]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.094568,	
2017-07-20 16:03:09,289 Epoch[32] Batch [900]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094510,	
2017-07-20 16:03:13,465 Epoch[32] Batch [910]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094473,	
2017-07-20 16:03:17,681 Epoch[32] Batch [920]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094460,	
2017-07-20 16:03:21,745 Epoch[32] Batch [930]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094492,	
2017-07-20 16:03:26,027 Epoch[32] Batch [940]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.094406,	
2017-07-20 16:03:30,094 Epoch[32] Batch [950]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094345,	
2017-07-20 16:03:34,303 Epoch[32] Batch [960]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094320,	
2017-07-20 16:03:38,455 Epoch[32] Batch [970]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094365,	
2017-07-20 16:03:42,748 Epoch[32] Batch [980]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094361,	
2017-07-20 16:03:46,780 Epoch[32] Batch [990]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094376,	
2017-07-20 16:03:50,997 Epoch[32] Batch [1000]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094383,	
2017-07-20 16:03:55,285 Epoch[32] Batch [1010]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.094349,	
2017-07-20 16:03:59,284 Epoch[32] Batch [1020]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.094400,	
2017-07-20 16:04:03,449 Epoch[32] Batch [1030]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.094338,	
2017-07-20 16:04:07,615 Epoch[32] Batch [1040]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094403,	
2017-07-20 16:04:11,822 Epoch[32] Batch [1050]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.094464,	
2017-07-20 16:04:16,100 Epoch[32] Batch [1060]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094483,	
2017-07-20 16:04:20,316 Epoch[32] Batch [1070]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094381,	
2017-07-20 16:04:24,349 Epoch[32] Batch [1080]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094437,	
2017-07-20 16:04:28,477 Epoch[32] Batch [1090]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094381,	
2017-07-20 16:04:32,509 Epoch[32] Batch [1100]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094382,	
2017-07-20 16:04:36,636 Epoch[32] Batch [1110]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094330,	
2017-07-20 16:04:41,001 Epoch[32] Batch [1120]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.094290,	
2017-07-20 16:04:45,143 Epoch[32] Batch [1130]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094363,	
2017-07-20 16:04:49,280 Epoch[32] Batch [1140]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094364,	
2017-07-20 16:04:53,310 Epoch[32] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094379,	
2017-07-20 16:04:57,414 Epoch[32] Batch [1160]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094310,	
2017-07-20 16:05:01,518 Epoch[32] Batch [1170]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094366,	
2017-07-20 16:05:05,542 Epoch[32] Batch [1180]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094328,	
2017-07-20 16:05:09,734 Epoch[32] Batch [1190]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094312,	
2017-07-20 16:05:13,890 Epoch[32] Batch [1200]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094324,	
2017-07-20 16:05:18,093 Epoch[32] Batch [1210]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.094412,	
2017-07-20 16:05:22,401 Epoch[32] Batch [1220]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094404,	
2017-07-20 16:05:26,554 Epoch[32] Batch [1230]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094441,	
2017-07-20 16:05:30,791 Epoch[32] Batch [1240]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.094544,	
2017-07-20 16:05:35,025 Epoch[32] Batch [1250]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.094586,	
2017-07-20 16:05:39,235 Epoch[32] Batch [1260]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094611,	
2017-07-20 16:05:43,448 Epoch[32] Batch [1270]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094579,	
2017-07-20 16:05:47,546 Epoch[32] Batch [1280]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094550,	
2017-07-20 16:05:51,418 Epoch[32] Batch [1290]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.094629,	
2017-07-20 16:05:55,261 Epoch[32] Batch [1300]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.094689,	
2017-07-20 16:05:59,286 Epoch[32] Batch [1310]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094671,	
2017-07-20 16:06:03,227 Epoch[32] Batch [1320]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094664,	
2017-07-20 16:06:07,393 Epoch[32] Batch [1330]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094703,	
2017-07-20 16:06:11,560 Epoch[32] Batch [1340]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094677,	
2017-07-20 16:06:15,820 Epoch[32] Batch [1350]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094619,	
2017-07-20 16:06:20,046 Epoch[32] Batch [1360]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094573,	
2017-07-20 16:06:24,112 Epoch[32] Batch [1370]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094585,	
2017-07-20 16:06:28,333 Epoch[32] Batch [1380]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094587,	
2017-07-20 16:06:32,392 Epoch[32] Batch [1390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094624,	
2017-07-20 16:06:36,493 Epoch[32] Batch [1400]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094656,	
2017-07-20 16:06:40,829 Epoch[32] Batch [1410]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.094666,	
2017-07-20 16:06:45,095 Epoch[32] Batch [1420]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094668,	
2017-07-20 16:06:49,281 Epoch[32] Batch [1430]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094648,	
2017-07-20 16:06:53,317 Epoch[32] Batch [1440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094668,	
2017-07-20 16:06:57,358 Epoch[32] Batch [1450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094604,	
2017-07-20 16:07:01,305 Epoch[32] Batch [1460]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094659,	
2017-07-20 16:07:05,407 Epoch[32] Batch [1470]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094618,	
2017-07-20 16:07:09,536 Epoch[32] Batch [1480]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094656,	
2017-07-20 16:07:11,888 Epoch[32] Train-FCNLogLoss=0.094637
2017-07-20 16:07:11,888 Epoch[32] Time cost=616.450
2017-07-20 16:07:12,684 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0033.params"
2017-07-20 16:07:14,192 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0033.states"
2017-07-20 16:07:19,070 Epoch[33] Batch [10]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.099650,	
2017-07-20 16:07:23,116 Epoch[33] Batch [20]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094040,	
2017-07-20 16:07:27,252 Epoch[33] Batch [30]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094310,	
2017-07-20 16:07:31,357 Epoch[33] Batch [40]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094871,	
2017-07-20 16:07:35,408 Epoch[33] Batch [50]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094311,	
2017-07-20 16:07:39,597 Epoch[33] Batch [60]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.093565,	
2017-07-20 16:07:43,671 Epoch[33] Batch [70]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.093154,	
2017-07-20 16:07:47,764 Epoch[33] Batch [80]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092792,	
2017-07-20 16:07:51,870 Epoch[33] Batch [90]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.092620,	
2017-07-20 16:07:55,908 Epoch[33] Batch [100]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.092333,	
2017-07-20 16:08:00,000 Epoch[33] Batch [110]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.092451,	
2017-07-20 16:08:04,126 Epoch[33] Batch [120]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092470,	
2017-07-20 16:08:08,442 Epoch[33] Batch [130]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.092688,	
2017-07-20 16:08:12,664 Epoch[33] Batch [140]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.093206,	
2017-07-20 16:08:16,874 Epoch[33] Batch [150]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.093155,	
2017-07-20 16:08:20,988 Epoch[33] Batch [160]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093463,	
2017-07-20 16:08:25,069 Epoch[33] Batch [170]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093106,	
2017-07-20 16:08:29,221 Epoch[33] Batch [180]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.093208,	
2017-07-20 16:08:33,447 Epoch[33] Batch [190]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.093270,	
2017-07-20 16:08:37,494 Epoch[33] Batch [200]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.093428,	
2017-07-20 16:08:41,726 Epoch[33] Batch [210]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.093659,	
2017-07-20 16:08:45,843 Epoch[33] Batch [220]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093428,	
2017-07-20 16:08:50,024 Epoch[33] Batch [230]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092786,	
2017-07-20 16:08:54,123 Epoch[33] Batch [240]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.092640,	
2017-07-20 16:08:58,226 Epoch[33] Batch [250]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092908,	
2017-07-20 16:09:02,506 Epoch[33] Batch [260]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.092679,	
2017-07-20 16:09:06,705 Epoch[33] Batch [270]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.092876,	
2017-07-20 16:09:10,853 Epoch[33] Batch [280]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.093027,	
2017-07-20 16:09:15,031 Epoch[33] Batch [290]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.093060,	
2017-07-20 16:09:19,109 Epoch[33] Batch [300]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.093142,	
2017-07-20 16:09:23,365 Epoch[33] Batch [310]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.092961,	
2017-07-20 16:09:27,417 Epoch[33] Batch [320]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.093201,	
2017-07-20 16:09:31,673 Epoch[33] Batch [330]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.093203,	
2017-07-20 16:09:35,691 Epoch[33] Batch [340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.093317,	
2017-07-20 16:09:39,841 Epoch[33] Batch [350]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093470,	
2017-07-20 16:09:43,910 Epoch[33] Batch [360]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.093416,	
2017-07-20 16:09:48,124 Epoch[33] Batch [370]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.093328,	
2017-07-20 16:09:52,215 Epoch[33] Batch [380]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093461,	
2017-07-20 16:09:56,420 Epoch[33] Batch [390]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.093569,	
2017-07-20 16:10:00,792 Epoch[33] Batch [400]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.093697,	
2017-07-20 16:10:04,907 Epoch[33] Batch [410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093739,	
2017-07-20 16:10:08,999 Epoch[33] Batch [420]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093571,	
2017-07-20 16:10:13,079 Epoch[33] Batch [430]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093530,	
2017-07-20 16:10:17,351 Epoch[33] Batch [440]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.093610,	
2017-07-20 16:10:21,443 Epoch[33] Batch [450]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093279,	
2017-07-20 16:10:25,558 Epoch[33] Batch [460]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093250,	
2017-07-20 16:10:29,766 Epoch[33] Batch [470]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.093476,	
2017-07-20 16:10:33,959 Epoch[33] Batch [480]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.093497,	
2017-07-20 16:10:38,040 Epoch[33] Batch [490]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093445,	
2017-07-20 16:10:42,261 Epoch[33] Batch [500]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.093355,	
2017-07-20 16:10:46,313 Epoch[33] Batch [510]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.093663,	
2017-07-20 16:10:50,372 Epoch[33] Batch [520]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.093636,	
2017-07-20 16:10:54,503 Epoch[33] Batch [530]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.093810,	
2017-07-20 16:10:58,633 Epoch[33] Batch [540]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093578,	
2017-07-20 16:11:02,732 Epoch[33] Batch [550]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.093551,	
2017-07-20 16:11:06,878 Epoch[33] Batch [560]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.093560,	
2017-07-20 16:11:11,083 Epoch[33] Batch [570]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.093610,	
2017-07-20 16:11:15,251 Epoch[33] Batch [580]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.093434,	
2017-07-20 16:11:19,440 Epoch[33] Batch [590]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.093379,	
2017-07-20 16:11:23,634 Epoch[33] Batch [600]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.093546,	
2017-07-20 16:11:27,790 Epoch[33] Batch [610]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.093407,	
2017-07-20 16:11:31,999 Epoch[33] Batch [620]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.093364,	
2017-07-20 16:11:36,111 Epoch[33] Batch [630]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.093358,	
2017-07-20 16:11:40,149 Epoch[33] Batch [640]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.093586,	
2017-07-20 16:11:44,224 Epoch[33] Batch [650]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.093542,	
2017-07-20 16:11:48,336 Epoch[33] Batch [660]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.093503,	
2017-07-20 16:11:52,477 Epoch[33] Batch [670]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.093514,	
2017-07-20 16:11:56,576 Epoch[33] Batch [680]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.093388,	
2017-07-20 16:12:00,705 Epoch[33] Batch [690]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093435,	
2017-07-20 16:12:04,794 Epoch[33] Batch [700]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093330,	
2017-07-20 16:12:09,024 Epoch[33] Batch [710]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.093382,	
2017-07-20 16:12:13,188 Epoch[33] Batch [720]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093478,	
2017-07-20 16:12:17,229 Epoch[33] Batch [730]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.093365,	
2017-07-20 16:12:21,429 Epoch[33] Batch [740]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.093291,	
2017-07-20 16:12:25,486 Epoch[33] Batch [750]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.093230,	
2017-07-20 16:12:29,552 Epoch[33] Batch [760]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.093286,	
2017-07-20 16:12:33,749 Epoch[33] Batch [770]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.093376,	
2017-07-20 16:12:37,842 Epoch[33] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093387,	
2017-07-20 16:12:42,131 Epoch[33] Batch [790]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.093324,	
2017-07-20 16:12:46,295 Epoch[33] Batch [800]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093263,	
2017-07-20 16:12:50,269 Epoch[33] Batch [810]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093147,	
2017-07-20 16:12:54,298 Epoch[33] Batch [820]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.093270,	
2017-07-20 16:12:58,375 Epoch[33] Batch [830]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.093210,	
2017-07-20 16:13:02,616 Epoch[33] Batch [840]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.093219,	
2017-07-20 16:13:06,764 Epoch[33] Batch [850]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.093294,	
2017-07-20 16:13:10,875 Epoch[33] Batch [860]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.093350,	
2017-07-20 16:13:15,106 Epoch[33] Batch [870]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.093358,	
2017-07-20 16:13:19,255 Epoch[33] Batch [880]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093290,	
2017-07-20 16:13:23,397 Epoch[33] Batch [890]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.093355,	
2017-07-20 16:13:27,515 Epoch[33] Batch [900]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093266,	
2017-07-20 16:13:31,641 Epoch[33] Batch [910]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093216,	
2017-07-20 16:13:35,791 Epoch[33] Batch [920]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093178,	
2017-07-20 16:13:40,027 Epoch[33] Batch [930]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.093172,	
2017-07-20 16:13:44,166 Epoch[33] Batch [940]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.093158,	
2017-07-20 16:13:48,273 Epoch[33] Batch [950]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093307,	
2017-07-20 16:13:52,394 Epoch[33] Batch [960]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.093376,	
2017-07-20 16:13:56,514 Epoch[33] Batch [970]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093294,	
2017-07-20 16:14:00,536 Epoch[33] Batch [980]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.093366,	
2017-07-20 16:14:04,708 Epoch[33] Batch [990]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.093396,	
2017-07-20 16:14:08,761 Epoch[33] Batch [1000]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.093553,	
2017-07-20 16:14:12,881 Epoch[33] Batch [1010]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.093431,	
2017-07-20 16:14:17,087 Epoch[33] Batch [1020]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.093403,	
2017-07-20 16:14:21,226 Epoch[33] Batch [1030]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.093272,	
2017-07-20 16:14:25,223 Epoch[33] Batch [1040]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.093276,	
2017-07-20 16:14:29,208 Epoch[33] Batch [1050]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.093324,	
2017-07-20 16:14:33,322 Epoch[33] Batch [1060]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.093370,	
2017-07-20 16:14:37,382 Epoch[33] Batch [1070]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.093441,	
2017-07-20 16:14:41,494 Epoch[33] Batch [1080]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.093407,	
2017-07-20 16:14:45,668 Epoch[33] Batch [1090]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093329,	
2017-07-20 16:14:49,846 Epoch[33] Batch [1100]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093301,	
2017-07-20 16:14:53,925 Epoch[33] Batch [1110]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.093336,	
2017-07-20 16:14:57,887 Epoch[33] Batch [1120]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.093362,	
2017-07-20 16:15:02,142 Epoch[33] Batch [1130]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.093353,	
2017-07-20 16:15:06,410 Epoch[33] Batch [1140]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.093327,	
2017-07-20 16:15:10,615 Epoch[33] Batch [1150]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.093329,	
2017-07-20 16:15:14,913 Epoch[33] Batch [1160]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093327,	
2017-07-20 16:15:19,088 Epoch[33] Batch [1170]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093344,	
2017-07-20 16:15:23,164 Epoch[33] Batch [1180]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.093308,	
2017-07-20 16:15:27,377 Epoch[33] Batch [1190]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.093298,	
2017-07-20 16:15:31,403 Epoch[33] Batch [1200]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.093336,	
2017-07-20 16:15:35,525 Epoch[33] Batch [1210]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-20 16:15:39,731 Epoch[33] Batch [1220]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.093351,	
2017-07-20 16:15:43,886 Epoch[33] Batch [1230]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.093326,	
2017-07-20 16:15:48,050 Epoch[33] Batch [1240]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093296,	
2017-07-20 16:15:52,194 Epoch[33] Batch [1250]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.093366,	
2017-07-20 16:15:56,376 Epoch[33] Batch [1260]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.093359,	
2017-07-20 16:16:00,485 Epoch[33] Batch [1270]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093353,	
2017-07-20 16:16:04,640 Epoch[33] Batch [1280]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.093373,	
2017-07-20 16:16:08,893 Epoch[33] Batch [1290]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.093406,	
2017-07-20 16:16:13,132 Epoch[33] Batch [1300]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.093438,	
2017-07-20 16:16:17,209 Epoch[33] Batch [1310]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.093422,	
2017-07-20 16:16:21,291 Epoch[33] Batch [1320]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093442,	
2017-07-20 16:16:25,524 Epoch[33] Batch [1330]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.093388,	
2017-07-20 16:16:29,689 Epoch[33] Batch [1340]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093418,	
2017-07-20 16:16:33,864 Epoch[33] Batch [1350]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093354,	
2017-07-20 16:16:37,895 Epoch[33] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.093305,	
2017-07-20 16:16:41,989 Epoch[33] Batch [1370]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093332,	
2017-07-20 16:16:46,004 Epoch[33] Batch [1380]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.093307,	
2017-07-20 16:16:50,195 Epoch[33] Batch [1390]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.093349,	
2017-07-20 16:16:54,365 Epoch[33] Batch [1400]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.093308,	
2017-07-20 16:16:58,445 Epoch[33] Batch [1410]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093364,	
2017-07-20 16:17:02,456 Epoch[33] Batch [1420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.093318,	
2017-07-20 16:17:06,576 Epoch[33] Batch [1430]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.093321,	
2017-07-20 16:17:10,648 Epoch[33] Batch [1440]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.093348,	
2017-07-20 16:17:14,751 Epoch[33] Batch [1450]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.093302,	
2017-07-20 16:17:18,988 Epoch[33] Batch [1460]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.093319,	
2017-07-20 16:17:23,180 Epoch[33] Batch [1470]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.093269,	
2017-07-20 16:17:27,270 Epoch[33] Batch [1480]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093242,	
2017-07-20 16:17:29,633 Epoch[33] Train-FCNLogLoss=0.093217
2017-07-20 16:17:29,633 Epoch[33] Time cost=615.441
2017-07-20 16:17:30,372 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0034.params"
2017-07-20 16:17:31,993 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0034.states"
2017-07-20 16:17:36,796 Epoch[34] Batch [10]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093526,	
2017-07-20 16:17:40,926 Epoch[34] Batch [20]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091852,	
2017-07-20 16:17:45,057 Epoch[34] Batch [30]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093987,	
2017-07-20 16:17:49,225 Epoch[34] Batch [40]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.092353,	
2017-07-20 16:17:53,326 Epoch[34] Batch [50]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091395,	
2017-07-20 16:17:57,418 Epoch[34] Batch [60]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.090704,	
2017-07-20 16:18:01,640 Epoch[34] Batch [70]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.091906,	
2017-07-20 16:18:05,858 Epoch[34] Batch [80]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092470,	
2017-07-20 16:18:10,016 Epoch[34] Batch [90]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091486,	
2017-07-20 16:18:14,162 Epoch[34] Batch [100]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.091582,	
2017-07-20 16:18:18,261 Epoch[34] Batch [110]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091508,	
2017-07-20 16:18:22,499 Epoch[34] Batch [120]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091714,	
2017-07-20 16:18:26,663 Epoch[34] Batch [130]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091691,	
2017-07-20 16:18:30,882 Epoch[34] Batch [140]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.091471,	
2017-07-20 16:18:34,982 Epoch[34] Batch [150]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.090978,	
2017-07-20 16:18:39,188 Epoch[34] Batch [160]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.090560,	
2017-07-20 16:18:43,412 Epoch[34] Batch [170]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.090683,	
2017-07-20 16:18:47,449 Epoch[34] Batch [180]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.090724,	
2017-07-20 16:18:51,555 Epoch[34] Batch [190]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090903,	
2017-07-20 16:18:55,570 Epoch[34] Batch [200]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.090930,	
2017-07-20 16:18:59,782 Epoch[34] Batch [210]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.090428,	
2017-07-20 16:19:03,897 Epoch[34] Batch [220]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.090371,	
2017-07-20 16:19:08,093 Epoch[34] Batch [230]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.090517,	
2017-07-20 16:19:12,176 Epoch[34] Batch [240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.090684,	
2017-07-20 16:19:16,371 Epoch[34] Batch [250]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.090820,	
2017-07-20 16:19:20,593 Epoch[34] Batch [260]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.090529,	
2017-07-20 16:19:24,810 Epoch[34] Batch [270]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.090801,	
2017-07-20 16:19:28,979 Epoch[34] Batch [280]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.091016,	
2017-07-20 16:19:33,023 Epoch[34] Batch [290]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091023,	
2017-07-20 16:19:37,087 Epoch[34] Batch [300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091252,	
2017-07-20 16:19:41,283 Epoch[34] Batch [310]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091397,	
2017-07-20 16:19:45,402 Epoch[34] Batch [320]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.091569,	
2017-07-20 16:19:49,505 Epoch[34] Batch [330]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091960,	
2017-07-20 16:19:53,714 Epoch[34] Batch [340]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.092189,	
2017-07-20 16:19:57,895 Epoch[34] Batch [350]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092373,	
2017-07-20 16:20:02,132 Epoch[34] Batch [360]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.092568,	
2017-07-20 16:20:06,352 Epoch[34] Batch [370]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092491,	
2017-07-20 16:20:10,630 Epoch[34] Batch [380]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.092482,	
2017-07-20 16:20:14,749 Epoch[34] Batch [390]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.092472,	
2017-07-20 16:20:18,946 Epoch[34] Batch [400]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.092660,	
2017-07-20 16:20:23,003 Epoch[34] Batch [410]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.092668,	
2017-07-20 16:20:27,081 Epoch[34] Batch [420]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092947,	
2017-07-20 16:20:31,091 Epoch[34] Batch [430]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.092974,	
2017-07-20 16:20:35,320 Epoch[34] Batch [440]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.093090,	
2017-07-20 16:20:39,576 Epoch[34] Batch [450]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.092958,	
2017-07-20 16:20:43,702 Epoch[34] Batch [460]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.093013,	
2017-07-20 16:20:47,773 Epoch[34] Batch [470]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.092993,	
2017-07-20 16:20:51,947 Epoch[34] Batch [480]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093131,	
2017-07-20 16:20:56,164 Epoch[34] Batch [490]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.092963,	
2017-07-20 16:21:00,368 Epoch[34] Batch [500]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.092947,	
2017-07-20 16:21:04,485 Epoch[34] Batch [510]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.092835,	
2017-07-20 16:21:08,759 Epoch[34] Batch [520]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.092692,	
2017-07-20 16:21:12,866 Epoch[34] Batch [530]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.092615,	
2017-07-20 16:21:17,088 Epoch[34] Batch [540]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092627,	
2017-07-20 16:21:21,288 Epoch[34] Batch [550]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.092633,	
2017-07-20 16:21:25,389 Epoch[34] Batch [560]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.092569,	
2017-07-20 16:21:29,537 Epoch[34] Batch [570]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.092834,	
2017-07-20 16:21:33,714 Epoch[34] Batch [580]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093036,	
2017-07-20 16:21:37,879 Epoch[34] Batch [590]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093334,	
2017-07-20 16:21:42,174 Epoch[34] Batch [600]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093391,	
2017-07-20 16:21:46,363 Epoch[34] Batch [610]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.093410,	
2017-07-20 16:21:50,448 Epoch[34] Batch [620]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.093257,	
2017-07-20 16:21:54,469 Epoch[34] Batch [630]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.093307,	
2017-07-20 16:21:58,721 Epoch[34] Batch [640]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.093293,	
2017-07-20 16:22:02,811 Epoch[34] Batch [650]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093359,	
2017-07-20 16:22:07,039 Epoch[34] Batch [660]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.093472,	
2017-07-20 16:22:11,236 Epoch[34] Batch [670]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.093406,	
2017-07-20 16:22:15,445 Epoch[34] Batch [680]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.093368,	
2017-07-20 16:22:19,594 Epoch[34] Batch [690]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093359,	
2017-07-20 16:22:23,757 Epoch[34] Batch [700]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093180,	
2017-07-20 16:22:27,814 Epoch[34] Batch [710]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.093171,	
2017-07-20 16:22:32,005 Epoch[34] Batch [720]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.093110,	
2017-07-20 16:22:36,181 Epoch[34] Batch [730]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093184,	
2017-07-20 16:22:40,350 Epoch[34] Batch [740]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.093161,	
2017-07-20 16:22:44,563 Epoch[34] Batch [750]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.093084,	
2017-07-20 16:22:48,798 Epoch[34] Batch [760]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.093028,	
2017-07-20 16:22:52,932 Epoch[34] Batch [770]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.092959,	
2017-07-20 16:22:57,025 Epoch[34] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093014,	
2017-07-20 16:23:01,119 Epoch[34] Batch [790]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092908,	
2017-07-20 16:23:05,347 Epoch[34] Batch [800]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.092759,	
2017-07-20 16:23:09,460 Epoch[34] Batch [810]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.092704,	
2017-07-20 16:23:13,522 Epoch[34] Batch [820]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092741,	
2017-07-20 16:23:17,736 Epoch[34] Batch [830]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.092787,	
2017-07-20 16:23:21,814 Epoch[34] Batch [840]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092840,	
2017-07-20 16:23:25,833 Epoch[34] Batch [850]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.092808,	
2017-07-20 16:23:29,884 Epoch[34] Batch [860]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092856,	
2017-07-20 16:23:34,036 Epoch[34] Batch [870]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.092844,	
2017-07-20 16:23:38,109 Epoch[34] Batch [880]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.092889,	
2017-07-20 16:23:42,233 Epoch[34] Batch [890]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092867,	
2017-07-20 16:23:46,234 Epoch[34] Batch [900]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.092881,	
2017-07-20 16:23:50,361 Epoch[34] Batch [910]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093053,	
2017-07-20 16:23:54,507 Epoch[34] Batch [920]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.093041,	
2017-07-20 16:23:58,678 Epoch[34] Batch [930]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.093073,	
2017-07-20 16:24:02,877 Epoch[34] Batch [940]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.093064,	
2017-07-20 16:24:06,965 Epoch[34] Batch [950]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.092988,	
2017-07-20 16:24:11,011 Epoch[34] Batch [960]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.092932,	
2017-07-20 16:24:15,205 Epoch[34] Batch [970]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.092879,	
2017-07-20 16:24:19,264 Epoch[34] Batch [980]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.092789,	
2017-07-20 16:24:23,406 Epoch[34] Batch [990]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.092810,	
2017-07-20 16:24:27,507 Epoch[34] Batch [1000]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.092843,	
2017-07-20 16:24:31,545 Epoch[34] Batch [1010]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.092768,	
2017-07-20 16:24:35,593 Epoch[34] Batch [1020]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.093038,	
2017-07-20 16:24:39,769 Epoch[34] Batch [1030]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093024,	
2017-07-20 16:24:43,781 Epoch[34] Batch [1040]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.092985,	
2017-07-20 16:24:47,962 Epoch[34] Batch [1050]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092944,	
2017-07-20 16:24:52,021 Epoch[34] Batch [1060]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.092998,	
2017-07-20 16:24:56,192 Epoch[34] Batch [1070]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.093019,	
2017-07-20 16:25:00,358 Epoch[34] Batch [1080]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.093041,	
2017-07-20 16:25:04,485 Epoch[34] Batch [1090]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.092912,	
2017-07-20 16:25:08,470 Epoch[34] Batch [1100]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.092790,	
2017-07-20 16:25:12,550 Epoch[34] Batch [1110]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092903,	
2017-07-20 16:25:16,725 Epoch[34] Batch [1120]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.092859,	
2017-07-20 16:25:20,910 Epoch[34] Batch [1130]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.092822,	
2017-07-20 16:25:25,090 Epoch[34] Batch [1140]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092724,	
2017-07-20 16:25:29,100 Epoch[34] Batch [1150]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.092726,	
2017-07-20 16:25:33,166 Epoch[34] Batch [1160]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.092764,	
2017-07-20 16:25:37,371 Epoch[34] Batch [1170]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.092735,	
2017-07-20 16:25:41,611 Epoch[34] Batch [1180]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.092753,	
2017-07-20 16:25:45,699 Epoch[34] Batch [1190]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.092749,	
2017-07-20 16:25:49,751 Epoch[34] Batch [1200]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092775,	
2017-07-20 16:25:53,805 Epoch[34] Batch [1210]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092773,	
2017-07-20 16:25:57,842 Epoch[34] Batch [1220]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.092746,	
2017-07-20 16:26:01,916 Epoch[34] Batch [1230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.092707,	
2017-07-20 16:26:05,980 Epoch[34] Batch [1240]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.092722,	
2017-07-20 16:26:10,140 Epoch[34] Batch [1250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.092780,	
2017-07-20 16:26:14,211 Epoch[34] Batch [1260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.092830,	
2017-07-20 16:26:18,310 Epoch[34] Batch [1270]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.092832,	
2017-07-20 16:26:22,297 Epoch[34] Batch [1280]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.092790,	
2017-07-20 16:26:26,364 Epoch[34] Batch [1290]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.092818,	
2017-07-20 16:26:30,543 Epoch[34] Batch [1300]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092867,	
2017-07-20 16:26:34,512 Epoch[34] Batch [1310]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.092978,	
2017-07-20 16:26:38,616 Epoch[34] Batch [1320]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092994,	
2017-07-20 16:26:42,768 Epoch[34] Batch [1330]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093066,	
2017-07-20 16:26:46,858 Epoch[34] Batch [1340]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093041,	
2017-07-20 16:26:50,918 Epoch[34] Batch [1350]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.093072,	
2017-07-20 16:26:54,977 Epoch[34] Batch [1360]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.092973,	
2017-07-20 16:26:59,032 Epoch[34] Batch [1370]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092908,	
2017-07-20 16:27:03,234 Epoch[34] Batch [1380]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.092880,	
2017-07-20 16:27:07,194 Epoch[34] Batch [1390]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092897,	
2017-07-20 16:27:11,405 Epoch[34] Batch [1400]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.092912,	
2017-07-20 16:27:15,467 Epoch[34] Batch [1410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.092895,	
2017-07-20 16:27:19,726 Epoch[34] Batch [1420]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.092929,	
2017-07-20 16:27:23,770 Epoch[34] Batch [1430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.092921,	
2017-07-20 16:27:27,848 Epoch[34] Batch [1440]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092876,	
2017-07-20 16:27:31,922 Epoch[34] Batch [1450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.092870,	
2017-07-20 16:27:36,017 Epoch[34] Batch [1460]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092871,	
2017-07-20 16:27:40,101 Epoch[34] Batch [1470]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.092936,	
2017-07-20 16:27:44,119 Epoch[34] Batch [1480]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.092927,	
2017-07-20 16:27:46,697 Epoch[34] Train-FCNLogLoss=0.092881
2017-07-20 16:27:46,697 Epoch[34] Time cost=614.703
2017-07-20 16:27:47,510 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0035.params"
2017-07-20 16:27:49,029 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0035.states"
2017-07-20 16:27:53,815 Epoch[35] Batch [10]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.092725,	
2017-07-20 16:27:57,901 Epoch[35] Batch [20]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.093933,	
2017-07-20 16:28:01,916 Epoch[35] Batch [30]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094944,	
2017-07-20 16:28:05,998 Epoch[35] Batch [40]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.091246,	
2017-07-20 16:28:10,084 Epoch[35] Batch [50]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.091527,	
2017-07-20 16:28:14,135 Epoch[35] Batch [60]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.090327,	
2017-07-20 16:28:18,213 Epoch[35] Batch [70]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.089883,	
2017-07-20 16:28:22,251 Epoch[35] Batch [80]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.090586,	
2017-07-20 16:28:26,367 Epoch[35] Batch [90]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.089828,	
2017-07-20 16:28:30,472 Epoch[35] Batch [100]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.089876,	
2017-07-20 16:28:34,564 Epoch[35] Batch [110]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.089804,	
2017-07-20 16:28:38,704 Epoch[35] Batch [120]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.090231,	
2017-07-20 16:28:42,700 Epoch[35] Batch [130]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.092479,	
2017-07-20 16:28:46,750 Epoch[35] Batch [140]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.098971,	
2017-07-20 16:28:50,832 Epoch[35] Batch [150]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100077,	
2017-07-20 16:28:54,942 Epoch[35] Batch [160]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.100886,	
2017-07-20 16:28:59,097 Epoch[35] Batch [170]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101465,	
2017-07-20 16:29:03,107 Epoch[35] Batch [180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101685,	
2017-07-20 16:29:07,081 Epoch[35] Batch [190]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.101042,	
2017-07-20 16:29:11,184 Epoch[35] Batch [200]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.100914,	
2017-07-20 16:29:15,295 Epoch[35] Batch [210]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.101058,	
2017-07-20 16:29:19,453 Epoch[35] Batch [220]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101359,	
2017-07-20 16:29:23,486 Epoch[35] Batch [230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101179,	
2017-07-20 16:29:27,598 Epoch[35] Batch [240]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.101079,	
2017-07-20 16:29:31,674 Epoch[35] Batch [250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.100698,	
2017-07-20 16:29:35,804 Epoch[35] Batch [260]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.100647,	
2017-07-20 16:29:39,806 Epoch[35] Batch [270]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.100443,	
2017-07-20 16:29:43,959 Epoch[35] Batch [280]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.100150,	
2017-07-20 16:29:48,109 Epoch[35] Batch [290]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.100035,	
2017-07-20 16:29:52,151 Epoch[35] Batch [300]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.099775,	
2017-07-20 16:29:56,358 Epoch[35] Batch [310]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.099611,	
2017-07-20 16:30:00,467 Epoch[35] Batch [320]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.099129,	
2017-07-20 16:30:04,519 Epoch[35] Batch [330]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.099394,	
2017-07-20 16:30:08,549 Epoch[35] Batch [340]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.098872,	
2017-07-20 16:30:12,631 Epoch[35] Batch [350]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.098859,	
2017-07-20 16:30:16,777 Epoch[35] Batch [360]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.098667,	
2017-07-20 16:30:20,864 Epoch[35] Batch [370]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.099932,	
2017-07-20 16:30:24,934 Epoch[35] Batch [380]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100255,	
2017-07-20 16:30:29,117 Epoch[35] Batch [390]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.100364,	
2017-07-20 16:30:33,205 Epoch[35] Batch [400]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100322,	
2017-07-20 16:30:37,297 Epoch[35] Batch [410]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.102748,	
2017-07-20 16:30:41,289 Epoch[35] Batch [420]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.103266,	
2017-07-20 16:30:45,205 Epoch[35] Batch [430]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.103606,	
2017-07-20 16:30:49,266 Epoch[35] Batch [440]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.103667,	
2017-07-20 16:30:53,334 Epoch[35] Batch [450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.103572,	
2017-07-20 16:30:57,530 Epoch[35] Batch [460]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103671,	
2017-07-20 16:31:01,599 Epoch[35] Batch [470]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.103570,	
2017-07-20 16:31:05,587 Epoch[35] Batch [480]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.103359,	
2017-07-20 16:31:09,700 Epoch[35] Batch [490]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103416,	
2017-07-20 16:31:13,769 Epoch[35] Batch [500]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.103295,	
2017-07-20 16:31:17,823 Epoch[35] Batch [510]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.103287,	
2017-07-20 16:31:21,895 Epoch[35] Batch [520]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.103239,	
2017-07-20 16:31:26,038 Epoch[35] Batch [530]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.103167,	
2017-07-20 16:31:30,082 Epoch[35] Batch [540]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.103079,	
2017-07-20 16:31:34,055 Epoch[35] Batch [550]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.103068,	
2017-07-20 16:31:38,016 Epoch[35] Batch [560]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.102810,	
2017-07-20 16:31:42,105 Epoch[35] Batch [570]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.102757,	
2017-07-20 16:31:46,158 Epoch[35] Batch [580]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102653,	
2017-07-20 16:31:50,320 Epoch[35] Batch [590]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.102647,	
2017-07-20 16:31:54,430 Epoch[35] Batch [600]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.102586,	
2017-07-20 16:31:58,516 Epoch[35] Batch [610]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.102556,	
2017-07-20 16:32:02,656 Epoch[35] Batch [620]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.102432,	
2017-07-20 16:32:06,710 Epoch[35] Batch [630]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102257,	
2017-07-20 16:32:10,785 Epoch[35] Batch [640]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.102058,	
2017-07-20 16:32:14,867 Epoch[35] Batch [650]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101810,	
2017-07-20 16:32:18,925 Epoch[35] Batch [660]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101541,	
2017-07-20 16:32:22,939 Epoch[35] Batch [670]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101543,	
2017-07-20 16:32:26,993 Epoch[35] Batch [680]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.101479,	
2017-07-20 16:32:31,063 Epoch[35] Batch [690]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101342,	
2017-07-20 16:32:35,079 Epoch[35] Batch [700]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101211,	
2017-07-20 16:32:39,251 Epoch[35] Batch [710]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.100999,	
2017-07-20 16:32:43,314 Epoch[35] Batch [720]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100989,	
2017-07-20 16:32:47,470 Epoch[35] Batch [730]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.100835,	
2017-07-20 16:32:51,503 Epoch[35] Batch [740]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100825,	
2017-07-20 16:32:55,768 Epoch[35] Batch [750]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.100683,	
2017-07-20 16:32:59,797 Epoch[35] Batch [760]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.100537,	
2017-07-20 16:33:04,060 Epoch[35] Batch [770]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.100513,	
2017-07-20 16:33:08,213 Epoch[35] Batch [780]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.100423,	
2017-07-20 16:33:12,306 Epoch[35] Batch [790]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100415,	
2017-07-20 16:33:16,442 Epoch[35] Batch [800]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.100338,	
2017-07-20 16:33:20,527 Epoch[35] Batch [810]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100277,	
2017-07-20 16:33:24,735 Epoch[35] Batch [820]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.100187,	
2017-07-20 16:33:28,829 Epoch[35] Batch [830]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100156,	
2017-07-20 16:33:32,833 Epoch[35] Batch [840]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.100054,	
2017-07-20 16:33:36,968 Epoch[35] Batch [850]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.099942,	
2017-07-20 16:33:41,080 Epoch[35] Batch [860]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.099826,	
2017-07-20 16:33:45,218 Epoch[35] Batch [870]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.099720,	
2017-07-20 16:33:49,360 Epoch[35] Batch [880]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.099666,	
2017-07-20 16:33:53,389 Epoch[35] Batch [890]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.099675,	
2017-07-20 16:33:57,517 Epoch[35] Batch [900]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.099573,	
2017-07-20 16:34:01,604 Epoch[35] Batch [910]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.099474,	
2017-07-20 16:34:05,627 Epoch[35] Batch [920]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.099406,	
2017-07-20 16:34:09,608 Epoch[35] Batch [930]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.099404,	
2017-07-20 16:34:13,593 Epoch[35] Batch [940]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.099328,	
2017-07-20 16:34:17,629 Epoch[35] Batch [950]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.099265,	
2017-07-20 16:34:21,748 Epoch[35] Batch [960]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.099248,	
2017-07-20 16:34:25,891 Epoch[35] Batch [970]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.099237,	
2017-07-20 16:34:29,950 Epoch[35] Batch [980]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.099112,	
2017-07-20 16:34:34,082 Epoch[35] Batch [990]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.099015,	
2017-07-20 16:34:38,028 Epoch[35] Batch [1000]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.098957,	
2017-07-20 16:34:42,111 Epoch[35] Batch [1010]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.098816,	
2017-07-20 16:34:46,072 Epoch[35] Batch [1020]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.098917,	
2017-07-20 16:34:50,179 Epoch[35] Batch [1030]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.098971,	
2017-07-20 16:34:54,365 Epoch[35] Batch [1040]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.098999,	
2017-07-20 16:34:58,436 Epoch[35] Batch [1050]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.099032,	
2017-07-20 16:35:02,396 Epoch[35] Batch [1060]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.099031,	
2017-07-20 16:35:06,526 Epoch[35] Batch [1070]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.099013,	
2017-07-20 16:35:10,616 Epoch[35] Batch [1080]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.099068,	
2017-07-20 16:35:14,713 Epoch[35] Batch [1090]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.099022,	
2017-07-20 16:35:18,681 Epoch[35] Batch [1100]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.098920,	
2017-07-20 16:35:22,782 Epoch[35] Batch [1110]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.098923,	
2017-07-20 16:35:26,877 Epoch[35] Batch [1120]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.098994,	
2017-07-20 16:35:31,003 Epoch[35] Batch [1130]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.099025,	
2017-07-20 16:35:35,054 Epoch[35] Batch [1140]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.098932,	
2017-07-20 16:35:39,213 Epoch[35] Batch [1150]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.098908,	
2017-07-20 16:35:43,368 Epoch[35] Batch [1160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.098886,	
2017-07-20 16:35:47,340 Epoch[35] Batch [1170]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.098798,	
2017-07-20 16:35:51,324 Epoch[35] Batch [1180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.098741,	
2017-07-20 16:35:55,421 Epoch[35] Batch [1190]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.098706,	
2017-07-20 16:35:59,546 Epoch[35] Batch [1200]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098595,	
2017-07-20 16:36:03,523 Epoch[35] Batch [1210]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.098534,	
2017-07-20 16:36:07,455 Epoch[35] Batch [1220]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.098506,	
2017-07-20 16:36:11,581 Epoch[35] Batch [1230]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098452,	
2017-07-20 16:36:15,584 Epoch[35] Batch [1240]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.098460,	
2017-07-20 16:36:19,609 Epoch[35] Batch [1250]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.098364,	
2017-07-20 16:36:23,723 Epoch[35] Batch [1260]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.098348,	
2017-07-20 16:36:27,751 Epoch[35] Batch [1270]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.098357,	
2017-07-20 16:36:31,767 Epoch[35] Batch [1280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.098297,	
2017-07-20 16:36:35,850 Epoch[35] Batch [1290]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.098317,	
2017-07-20 16:36:39,970 Epoch[35] Batch [1300]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.098298,	
2017-07-20 16:36:43,980 Epoch[35] Batch [1310]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.098327,	
2017-07-20 16:36:48,106 Epoch[35] Batch [1320]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.098318,	
2017-07-20 16:36:52,132 Epoch[35] Batch [1330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.098281,	
2017-07-20 16:36:56,200 Epoch[35] Batch [1340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.098325,	
2017-07-20 16:37:00,356 Epoch[35] Batch [1350]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.098329,	
2017-07-20 16:37:04,448 Epoch[35] Batch [1360]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.098276,	
2017-07-20 16:37:08,636 Epoch[35] Batch [1370]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098217,	
2017-07-20 16:37:12,753 Epoch[35] Batch [1380]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.098252,	
2017-07-20 16:37:17,026 Epoch[35] Batch [1390]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.098209,	
2017-07-20 16:37:21,121 Epoch[35] Batch [1400]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.098234,	
2017-07-20 16:37:25,259 Epoch[35] Batch [1410]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.098250,	
2017-07-20 16:37:29,315 Epoch[35] Batch [1420]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098196,	
2017-07-20 16:37:33,377 Epoch[35] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.098137,	
2017-07-20 16:37:37,447 Epoch[35] Batch [1440]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.098143,	
2017-07-20 16:37:41,611 Epoch[35] Batch [1450]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.098031,	
2017-07-20 16:37:45,676 Epoch[35] Batch [1460]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.098008,	
2017-07-20 16:37:49,774 Epoch[35] Batch [1470]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097990,	
2017-07-20 16:37:53,787 Epoch[35] Batch [1480]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.097933,	
2017-07-20 16:37:56,215 Epoch[35] Train-FCNLogLoss=0.097935
2017-07-20 16:37:56,215 Epoch[35] Time cost=607.185
2017-07-20 16:37:56,992 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0036.params"
2017-07-20 16:37:58,747 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0036.states"
2017-07-20 16:38:03,556 Epoch[36] Batch [10]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.099639,	
2017-07-20 16:38:07,616 Epoch[36] Batch [20]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.090958,	
2017-07-20 16:38:11,586 Epoch[36] Batch [30]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.093160,	
2017-07-20 16:38:15,680 Epoch[36] Batch [40]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091169,	
2017-07-20 16:38:19,727 Epoch[36] Batch [50]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.090652,	
2017-07-20 16:38:23,839 Epoch[36] Batch [60]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.092161,	
2017-07-20 16:38:27,825 Epoch[36] Batch [70]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.091698,	
2017-07-20 16:38:31,825 Epoch[36] Batch [80]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091508,	
2017-07-20 16:38:35,864 Epoch[36] Batch [90]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.091541,	
2017-07-20 16:38:40,020 Epoch[36] Batch [100]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.093180,	
2017-07-20 16:38:44,069 Epoch[36] Batch [110]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.092697,	
2017-07-20 16:38:48,069 Epoch[36] Batch [120]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.092298,	
2017-07-20 16:38:52,139 Epoch[36] Batch [130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.092799,	
2017-07-20 16:38:56,112 Epoch[36] Batch [140]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.092735,	
2017-07-20 16:39:00,062 Epoch[36] Batch [150]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.092303,	
2017-07-20 16:39:04,142 Epoch[36] Batch [160]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091770,	
2017-07-20 16:39:08,173 Epoch[36] Batch [170]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091162,	
2017-07-20 16:39:12,183 Epoch[36] Batch [180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.090898,	
2017-07-20 16:39:16,284 Epoch[36] Batch [190]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.090985,	
2017-07-20 16:39:20,335 Epoch[36] Batch [200]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.090844,	
2017-07-20 16:39:24,478 Epoch[36] Batch [210]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091126,	
2017-07-20 16:39:28,457 Epoch[36] Batch [220]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.090750,	
2017-07-20 16:39:32,504 Epoch[36] Batch [230]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091079,	
2017-07-20 16:39:36,702 Epoch[36] Batch [240]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.091410,	
2017-07-20 16:39:40,807 Epoch[36] Batch [250]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091860,	
2017-07-20 16:39:45,058 Epoch[36] Batch [260]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.092190,	
2017-07-20 16:39:49,081 Epoch[36] Batch [270]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091843,	
2017-07-20 16:39:53,059 Epoch[36] Batch [280]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.091954,	
2017-07-20 16:39:57,108 Epoch[36] Batch [290]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091601,	
2017-07-20 16:40:01,123 Epoch[36] Batch [300]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.091573,	
2017-07-20 16:40:05,222 Epoch[36] Batch [310]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091631,	
2017-07-20 16:40:09,342 Epoch[36] Batch [320]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.091972,	
2017-07-20 16:40:13,319 Epoch[36] Batch [330]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.092244,	
2017-07-20 16:40:17,419 Epoch[36] Batch [340]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.092175,	
2017-07-20 16:40:21,542 Epoch[36] Batch [350]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092147,	
2017-07-20 16:40:25,618 Epoch[36] Batch [360]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092071,	
2017-07-20 16:40:29,776 Epoch[36] Batch [370]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091930,	
2017-07-20 16:40:33,690 Epoch[36] Batch [380]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.092010,	
2017-07-20 16:40:37,697 Epoch[36] Batch [390]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091961,	
2017-07-20 16:40:41,673 Epoch[36] Batch [400]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.091809,	
2017-07-20 16:40:45,667 Epoch[36] Batch [410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.091777,	
2017-07-20 16:40:49,816 Epoch[36] Batch [420]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.092019,	
2017-07-20 16:40:53,841 Epoch[36] Batch [430]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.091779,	
2017-07-20 16:40:58,095 Epoch[36] Batch [440]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.091836,	
2017-07-20 16:41:02,227 Epoch[36] Batch [450]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.091596,	
2017-07-20 16:41:06,435 Epoch[36] Batch [460]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091669,	
2017-07-20 16:41:10,482 Epoch[36] Batch [470]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091823,	
2017-07-20 16:41:14,507 Epoch[36] Batch [480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.091990,	
2017-07-20 16:41:18,630 Epoch[36] Batch [490]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092071,	
2017-07-20 16:41:22,700 Epoch[36] Batch [500]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.091908,	
2017-07-20 16:41:26,768 Epoch[36] Batch [510]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.091807,	
2017-07-20 16:41:30,946 Epoch[36] Batch [520]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.091695,	
2017-07-20 16:41:35,096 Epoch[36] Batch [530]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091545,	
2017-07-20 16:41:39,224 Epoch[36] Batch [540]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091525,	
2017-07-20 16:41:43,262 Epoch[36] Batch [550]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.091673,	
2017-07-20 16:41:47,377 Epoch[36] Batch [560]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091538,	
2017-07-20 16:41:51,571 Epoch[36] Batch [570]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.091575,	
2017-07-20 16:41:55,774 Epoch[36] Batch [580]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091567,	
2017-07-20 16:41:59,902 Epoch[36] Batch [590]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091694,	
2017-07-20 16:42:03,933 Epoch[36] Batch [600]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.091679,	
2017-07-20 16:42:08,177 Epoch[36] Batch [610]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091692,	
2017-07-20 16:42:12,288 Epoch[36] Batch [620]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.091674,	
2017-07-20 16:42:16,403 Epoch[36] Batch [630]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091606,	
2017-07-20 16:42:20,608 Epoch[36] Batch [640]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091629,	
2017-07-20 16:42:24,695 Epoch[36] Batch [650]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.091587,	
2017-07-20 16:42:28,671 Epoch[36] Batch [660]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.091541,	
2017-07-20 16:42:32,660 Epoch[36] Batch [670]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.091646,	
2017-07-20 16:42:36,828 Epoch[36] Batch [680]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.091611,	
2017-07-20 16:42:40,905 Epoch[36] Batch [690]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091671,	
2017-07-20 16:42:44,928 Epoch[36] Batch [700]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.091540,	
2017-07-20 16:42:49,076 Epoch[36] Batch [710]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091450,	
2017-07-20 16:42:53,106 Epoch[36] Batch [720]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.091424,	
2017-07-20 16:42:57,111 Epoch[36] Batch [730]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.091335,	
2017-07-20 16:43:01,246 Epoch[36] Batch [740]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.091419,	
2017-07-20 16:43:05,470 Epoch[36] Batch [750]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091453,	
2017-07-20 16:43:09,401 Epoch[36] Batch [760]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.091411,	
2017-07-20 16:43:13,434 Epoch[36] Batch [770]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091376,	
2017-07-20 16:43:17,529 Epoch[36] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091366,	
2017-07-20 16:43:21,592 Epoch[36] Batch [790]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.091339,	
2017-07-20 16:43:25,670 Epoch[36] Batch [800]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091205,	
2017-07-20 16:43:29,790 Epoch[36] Batch [810]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.091103,	
2017-07-20 16:43:33,834 Epoch[36] Batch [820]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091143,	
2017-07-20 16:43:37,932 Epoch[36] Batch [830]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091186,	
2017-07-20 16:43:42,092 Epoch[36] Batch [840]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091146,	
2017-07-20 16:43:46,253 Epoch[36] Batch [850]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091223,	
2017-07-20 16:43:50,408 Epoch[36] Batch [860]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091238,	
2017-07-20 16:43:54,490 Epoch[36] Batch [870]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.091330,	
2017-07-20 16:43:58,613 Epoch[36] Batch [880]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091327,	
2017-07-20 16:44:02,733 Epoch[36] Batch [890]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.091307,	
2017-07-20 16:44:06,753 Epoch[36] Batch [900]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091422,	
2017-07-20 16:44:10,799 Epoch[36] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091376,	
2017-07-20 16:44:14,803 Epoch[36] Batch [920]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.091516,	
2017-07-20 16:44:18,928 Epoch[36] Batch [930]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091502,	
2017-07-20 16:44:23,091 Epoch[36] Batch [940]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091461,	
2017-07-20 16:44:27,064 Epoch[36] Batch [950]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.091401,	
2017-07-20 16:44:31,032 Epoch[36] Batch [960]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.091361,	
2017-07-20 16:44:35,081 Epoch[36] Batch [970]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091325,	
2017-07-20 16:44:39,076 Epoch[36] Batch [980]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.091502,	
2017-07-20 16:44:43,163 Epoch[36] Batch [990]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.091627,	
2017-07-20 16:44:47,234 Epoch[36] Batch [1000]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.091656,	
2017-07-20 16:44:51,256 Epoch[36] Batch [1010]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091622,	
2017-07-20 16:44:55,221 Epoch[36] Batch [1020]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.091742,	
2017-07-20 16:44:59,223 Epoch[36] Batch [1030]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091727,	
2017-07-20 16:45:03,361 Epoch[36] Batch [1040]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091697,	
2017-07-20 16:45:07,428 Epoch[36] Batch [1050]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091720,	
2017-07-20 16:45:11,439 Epoch[36] Batch [1060]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.091683,	
2017-07-20 16:45:15,435 Epoch[36] Batch [1070]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.091756,	
2017-07-20 16:45:19,467 Epoch[36] Batch [1080]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091897,	
2017-07-20 16:45:23,660 Epoch[36] Batch [1090]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.091785,	
2017-07-20 16:45:27,753 Epoch[36] Batch [1100]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091813,	
2017-07-20 16:45:31,905 Epoch[36] Batch [1110]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091871,	
2017-07-20 16:45:35,844 Epoch[36] Batch [1120]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.091727,	
2017-07-20 16:45:40,008 Epoch[36] Batch [1130]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091679,	
2017-07-20 16:45:44,158 Epoch[36] Batch [1140]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091651,	
2017-07-20 16:45:48,334 Epoch[36] Batch [1150]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091644,	
2017-07-20 16:45:52,283 Epoch[36] Batch [1160]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.091630,	
2017-07-20 16:45:56,505 Epoch[36] Batch [1170]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091693,	
2017-07-20 16:46:00,540 Epoch[36] Batch [1180]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.091589,	
2017-07-20 16:46:04,594 Epoch[36] Batch [1190]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091582,	
2017-07-20 16:46:08,702 Epoch[36] Batch [1200]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091576,	
2017-07-20 16:46:12,895 Epoch[36] Batch [1210]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.091512,	
2017-07-20 16:46:17,141 Epoch[36] Batch [1220]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.091487,	
2017-07-20 16:46:21,315 Epoch[36] Batch [1230]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091427,	
2017-07-20 16:46:25,555 Epoch[36] Batch [1240]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091394,	
2017-07-20 16:46:30,105 Epoch[36] Batch [1250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091369,	
2017-07-20 16:46:34,106 Epoch[36] Batch [1260]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091382,	
2017-07-20 16:46:38,205 Epoch[36] Batch [1270]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091373,	
2017-07-20 16:46:42,298 Epoch[36] Batch [1280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091273,	
2017-07-20 16:46:46,299 Epoch[36] Batch [1290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091297,	
2017-07-20 16:46:50,458 Epoch[36] Batch [1300]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091265,	
2017-07-20 16:46:54,669 Epoch[36] Batch [1310]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.091292,	
2017-07-20 16:46:58,722 Epoch[36] Batch [1320]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091325,	
2017-07-20 16:47:02,789 Epoch[36] Batch [1330]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091263,	
2017-07-20 16:47:07,000 Epoch[36] Batch [1340]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.091279,	
2017-07-20 16:47:11,081 Epoch[36] Batch [1350]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.091343,	
2017-07-20 16:47:15,045 Epoch[36] Batch [1360]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.091294,	
2017-07-20 16:47:19,126 Epoch[36] Batch [1370]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.091362,	
2017-07-20 16:47:23,226 Epoch[36] Batch [1380]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091316,	
2017-07-20 16:47:27,102 Epoch[36] Batch [1390]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.091316,	
2017-07-20 16:47:31,208 Epoch[36] Batch [1400]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091322,	
2017-07-20 16:47:35,211 Epoch[36] Batch [1410]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.091329,	
2017-07-20 16:47:39,360 Epoch[36] Batch [1420]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091350,	
2017-07-20 16:47:43,471 Epoch[36] Batch [1430]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.091446,	
2017-07-20 16:47:47,573 Epoch[36] Batch [1440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091461,	
2017-07-20 16:47:51,640 Epoch[36] Batch [1450]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091420,	
2017-07-20 16:47:55,627 Epoch[36] Batch [1460]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.091423,	
2017-07-20 16:47:59,645 Epoch[36] Batch [1470]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.091407,	
2017-07-20 16:48:03,771 Epoch[36] Batch [1480]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091343,	
2017-07-20 16:48:06,343 Epoch[36] Train-FCNLogLoss=0.091313
2017-07-20 16:48:06,344 Epoch[36] Time cost=607.596
2017-07-20 16:48:07,091 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0037.params"
2017-07-20 16:48:08,620 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0037.states"
2017-07-20 16:48:13,509 Epoch[37] Batch [10]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097140,	
2017-07-20 16:48:17,568 Epoch[37] Batch [20]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.091328,	
2017-07-20 16:48:21,722 Epoch[37] Batch [30]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091093,	
2017-07-20 16:48:25,799 Epoch[37] Batch [40]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.090831,	
2017-07-20 16:48:29,785 Epoch[37] Batch [50]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.089691,	
2017-07-20 16:48:33,906 Epoch[37] Batch [60]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.089503,	
2017-07-20 16:48:37,828 Epoch[37] Batch [70]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.090181,	
2017-07-20 16:48:41,917 Epoch[37] Batch [80]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.090219,	
2017-07-20 16:48:46,015 Epoch[37] Batch [90]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.090011,	
2017-07-20 16:48:49,857 Epoch[37] Batch [100]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.088598,	
2017-07-20 16:48:53,830 Epoch[37] Batch [110]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.089206,	
2017-07-20 16:48:57,957 Epoch[37] Batch [120]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.089377,	
2017-07-20 16:49:02,056 Epoch[37] Batch [130]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.090001,	
2017-07-20 16:49:06,243 Epoch[37] Batch [140]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.090352,	
2017-07-20 16:49:10,361 Epoch[37] Batch [150]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091657,	
2017-07-20 16:49:14,464 Epoch[37] Batch [160]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092994,	
2017-07-20 16:49:18,530 Epoch[37] Batch [170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.093456,	
2017-07-20 16:49:22,778 Epoch[37] Batch [180]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.093216,	
2017-07-20 16:49:26,723 Epoch[37] Batch [190]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093064,	
2017-07-20 16:49:30,848 Epoch[37] Batch [200]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.093504,	
2017-07-20 16:49:34,968 Epoch[37] Batch [210]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.093362,	
2017-07-20 16:49:39,080 Epoch[37] Batch [220]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.093185,	
2017-07-20 16:49:43,231 Epoch[37] Batch [230]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-20 16:49:47,247 Epoch[37] Batch [240]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.092915,	
2017-07-20 16:49:51,373 Epoch[37] Batch [250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092702,	
2017-07-20 16:49:55,444 Epoch[37] Batch [260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.092798,	
2017-07-20 16:49:59,386 Epoch[37] Batch [270]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092615,	
2017-07-20 16:50:03,517 Epoch[37] Batch [280]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.092151,	
2017-07-20 16:50:07,741 Epoch[37] Batch [290]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091709,	
2017-07-20 16:50:11,832 Epoch[37] Batch [300]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.091299,	
2017-07-20 16:50:15,933 Epoch[37] Batch [310]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091232,	
2017-07-20 16:50:20,141 Epoch[37] Batch [320]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091010,	
2017-07-20 16:50:24,113 Epoch[37] Batch [330]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.090912,	
2017-07-20 16:50:28,199 Epoch[37] Batch [340]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.090929,	
2017-07-20 16:50:32,294 Epoch[37] Batch [350]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091020,	
2017-07-20 16:50:36,363 Epoch[37] Batch [360]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.091024,	
2017-07-20 16:50:40,425 Epoch[37] Batch [370]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.091275,	
2017-07-20 16:50:44,561 Epoch[37] Batch [380]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091216,	
2017-07-20 16:50:48,602 Epoch[37] Batch [390]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.091275,	
2017-07-20 16:50:52,743 Epoch[37] Batch [400]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091419,	
2017-07-20 16:50:56,984 Epoch[37] Batch [410]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091172,	
2017-07-20 16:51:01,144 Epoch[37] Batch [420]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091529,	
2017-07-20 16:51:05,335 Epoch[37] Batch [430]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091565,	
2017-07-20 16:51:09,423 Epoch[37] Batch [440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.091624,	
2017-07-20 16:51:13,555 Epoch[37] Batch [450]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.091395,	
2017-07-20 16:51:17,631 Epoch[37] Batch [460]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091345,	
2017-07-20 16:51:21,686 Epoch[37] Batch [470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.091294,	
2017-07-20 16:51:25,739 Epoch[37] Batch [480]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.091442,	
2017-07-20 16:51:29,892 Epoch[37] Batch [490]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091426,	
2017-07-20 16:51:33,974 Epoch[37] Batch [500]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.091415,	
2017-07-20 16:51:37,969 Epoch[37] Batch [510]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.091465,	
2017-07-20 16:51:42,203 Epoch[37] Batch [520]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.091512,	
2017-07-20 16:51:46,318 Epoch[37] Batch [530]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091632,	
2017-07-20 16:51:50,508 Epoch[37] Batch [540]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091857,	
2017-07-20 16:51:54,493 Epoch[37] Batch [550]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.091682,	
2017-07-20 16:51:58,592 Epoch[37] Batch [560]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091953,	
2017-07-20 16:52:02,603 Epoch[37] Batch [570]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.091967,	
2017-07-20 16:52:06,770 Epoch[37] Batch [580]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.091902,	
2017-07-20 16:52:10,915 Epoch[37] Batch [590]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.092108,	
2017-07-20 16:52:15,050 Epoch[37] Batch [600]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091938,	
2017-07-20 16:52:19,115 Epoch[37] Batch [610]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091752,	
2017-07-20 16:52:23,160 Epoch[37] Batch [620]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091825,	
2017-07-20 16:52:27,284 Epoch[37] Batch [630]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091812,	
2017-07-20 16:52:31,450 Epoch[37] Batch [640]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.091686,	
2017-07-20 16:52:35,560 Epoch[37] Batch [650]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.091607,	
2017-07-20 16:52:39,644 Epoch[37] Batch [660]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.091577,	
2017-07-20 16:52:43,925 Epoch[37] Batch [670]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091604,	
2017-07-20 16:52:48,028 Epoch[37] Batch [680]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091409,	
2017-07-20 16:52:52,222 Epoch[37] Batch [690]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.091452,	
2017-07-20 16:52:56,230 Epoch[37] Batch [700]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091479,	
2017-07-20 16:53:00,381 Epoch[37] Batch [710]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091543,	
2017-07-20 16:53:04,569 Epoch[37] Batch [720]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091492,	
2017-07-20 16:53:08,620 Epoch[37] Batch [730]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091303,	
2017-07-20 16:53:12,669 Epoch[37] Batch [740]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091216,	
2017-07-20 16:53:16,712 Epoch[37] Batch [750]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.091137,	
2017-07-20 16:53:20,768 Epoch[37] Batch [760]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.091136,	
2017-07-20 16:53:24,884 Epoch[37] Batch [770]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091111,	
2017-07-20 16:53:29,034 Epoch[37] Batch [780]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091073,	
2017-07-20 16:53:33,105 Epoch[37] Batch [790]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.090979,	
2017-07-20 16:53:37,278 Epoch[37] Batch [800]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090919,	
2017-07-20 16:53:41,554 Epoch[37] Batch [810]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.090867,	
2017-07-20 16:53:45,672 Epoch[37] Batch [820]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.090879,	
2017-07-20 16:53:49,693 Epoch[37] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091020,	
2017-07-20 16:53:53,844 Epoch[37] Batch [840]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091147,	
2017-07-20 16:53:57,960 Epoch[37] Batch [850]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091144,	
2017-07-20 16:54:02,005 Epoch[37] Batch [860]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091122,	
2017-07-20 16:54:06,109 Epoch[37] Batch [870]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091089,	
2017-07-20 16:54:10,230 Epoch[37] Batch [880]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.090896,	
2017-07-20 16:54:14,509 Epoch[37] Batch [890]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.090781,	
2017-07-20 16:54:18,584 Epoch[37] Batch [900]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.090832,	
2017-07-20 16:54:22,614 Epoch[37] Batch [910]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.090901,	
2017-07-20 16:54:26,820 Epoch[37] Batch [920]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.090949,	
2017-07-20 16:54:30,954 Epoch[37] Batch [930]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090934,	
2017-07-20 16:54:35,025 Epoch[37] Batch [940]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.090949,	
2017-07-20 16:54:39,060 Epoch[37] Batch [950]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.090963,	
2017-07-20 16:54:43,175 Epoch[37] Batch [960]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.090936,	
2017-07-20 16:54:47,349 Epoch[37] Batch [970]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.090955,	
2017-07-20 16:54:51,359 Epoch[37] Batch [980]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.090897,	
2017-07-20 16:54:55,360 Epoch[37] Batch [990]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.090875,	
2017-07-20 16:54:59,506 Epoch[37] Batch [1000]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.090928,	
2017-07-20 16:55:03,596 Epoch[37] Batch [1010]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.090864,	
2017-07-20 16:55:07,629 Epoch[37] Batch [1020]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.090848,	
2017-07-20 16:55:11,661 Epoch[37] Batch [1030]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.090900,	
2017-07-20 16:55:15,745 Epoch[37] Batch [1040]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.090845,	
2017-07-20 16:55:19,861 Epoch[37] Batch [1050]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.090799,	
2017-07-20 16:55:24,049 Epoch[37] Batch [1060]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.090782,	
2017-07-20 16:55:28,128 Epoch[37] Batch [1070]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.090771,	
2017-07-20 16:55:32,318 Epoch[37] Batch [1080]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.090776,	
2017-07-20 16:55:36,187 Epoch[37] Batch [1090]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.090828,	
2017-07-20 16:55:40,375 Epoch[37] Batch [1100]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.090805,	
2017-07-20 16:55:44,409 Epoch[37] Batch [1110]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.090830,	
2017-07-20 16:55:48,561 Epoch[37] Batch [1120]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.090825,	
2017-07-20 16:55:52,598 Epoch[37] Batch [1130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.090891,	
2017-07-20 16:55:56,697 Epoch[37] Batch [1140]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.090927,	
2017-07-20 16:56:00,752 Epoch[37] Batch [1150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091020,	
2017-07-20 16:56:04,863 Epoch[37] Batch [1160]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.090958,	
2017-07-20 16:56:08,921 Epoch[37] Batch [1170]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.090938,	
2017-07-20 16:56:13,162 Epoch[37] Batch [1180]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.090957,	
2017-07-20 16:56:17,147 Epoch[37] Batch [1190]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.090990,	
2017-07-20 16:56:21,326 Epoch[37] Batch [1200]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.090987,	
2017-07-20 16:56:25,198 Epoch[37] Batch [1210]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.090990,	
2017-07-20 16:56:29,274 Epoch[37] Batch [1220]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.090984,	
2017-07-20 16:56:33,368 Epoch[37] Batch [1230]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091054,	
2017-07-20 16:56:37,367 Epoch[37] Batch [1240]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091148,	
2017-07-20 16:56:41,470 Epoch[37] Batch [1250]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091113,	
2017-07-20 16:56:45,482 Epoch[37] Batch [1260]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.091109,	
2017-07-20 16:56:49,588 Epoch[37] Batch [1270]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091138,	
2017-07-20 16:56:53,596 Epoch[37] Batch [1280]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091122,	
2017-07-20 16:56:57,671 Epoch[37] Batch [1290]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.091056,	
2017-07-20 16:57:01,877 Epoch[37] Batch [1300]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091036,	
2017-07-20 16:57:05,943 Epoch[37] Batch [1310]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091085,	
2017-07-20 16:57:10,078 Epoch[37] Batch [1320]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091110,	
2017-07-20 16:57:14,156 Epoch[37] Batch [1330]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091143,	
2017-07-20 16:57:18,306 Epoch[37] Batch [1340]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091204,	
2017-07-20 16:57:22,465 Epoch[37] Batch [1350]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091243,	
2017-07-20 16:57:26,492 Epoch[37] Batch [1360]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.091198,	
2017-07-20 16:57:30,632 Epoch[37] Batch [1370]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091243,	
2017-07-20 16:57:34,682 Epoch[37] Batch [1380]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091334,	
2017-07-20 16:57:38,800 Epoch[37] Batch [1390]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.091356,	
2017-07-20 16:57:42,998 Epoch[37] Batch [1400]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.091404,	
2017-07-20 16:57:47,107 Epoch[37] Batch [1410]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091446,	
2017-07-20 16:57:51,108 Epoch[37] Batch [1420]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091433,	
2017-07-20 16:57:55,080 Epoch[37] Batch [1430]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.091349,	
2017-07-20 16:57:59,229 Epoch[37] Batch [1440]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091297,	
2017-07-20 16:58:03,346 Epoch[37] Batch [1450]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091221,	
2017-07-20 16:58:07,309 Epoch[37] Batch [1460]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.091168,	
2017-07-20 16:58:11,355 Epoch[37] Batch [1470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091200,	
2017-07-20 16:58:15,287 Epoch[37] Batch [1480]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.091141,	
2017-07-20 16:58:17,734 Epoch[37] Train-FCNLogLoss=0.091087
2017-07-20 16:58:17,734 Epoch[37] Time cost=609.114
2017-07-20 16:58:18,506 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0038.params"
2017-07-20 16:58:20,029 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0038.states"
2017-07-20 16:58:24,883 Epoch[38] Batch [10]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.090018,	
2017-07-20 16:58:28,960 Epoch[38] Batch [20]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091651,	
2017-07-20 16:58:33,086 Epoch[38] Batch [30]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090232,	
2017-07-20 16:58:37,186 Epoch[38] Batch [40]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.090864,	
2017-07-20 16:58:41,366 Epoch[38] Batch [50]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.091634,	
2017-07-20 16:58:45,374 Epoch[38] Batch [60]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091726,	
2017-07-20 16:58:49,404 Epoch[38] Batch [70]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.092213,	
2017-07-20 16:58:53,612 Epoch[38] Batch [80]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.092105,	
2017-07-20 16:58:57,657 Epoch[38] Batch [90]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.092249,	
2017-07-20 16:59:01,680 Epoch[38] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.092468,	
2017-07-20 16:59:05,789 Epoch[38] Batch [110]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093340,	
2017-07-20 16:59:09,865 Epoch[38] Batch [120]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.092279,	
2017-07-20 16:59:13,854 Epoch[38] Batch [130]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.092020,	
2017-07-20 16:59:17,950 Epoch[38] Batch [140]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091277,	
2017-07-20 16:59:21,982 Epoch[38] Batch [150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091879,	
2017-07-20 16:59:26,058 Epoch[38] Batch [160]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091268,	
2017-07-20 16:59:30,165 Epoch[38] Batch [170]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090855,	
2017-07-20 16:59:34,159 Epoch[38] Batch [180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.090808,	
2017-07-20 16:59:38,107 Epoch[38] Batch [190]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.090669,	
2017-07-20 16:59:42,195 Epoch[38] Batch [200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.090596,	
2017-07-20 16:59:46,267 Epoch[38] Batch [210]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.090975,	
2017-07-20 16:59:50,390 Epoch[38] Batch [220]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090821,	
2017-07-20 16:59:54,386 Epoch[38] Batch [230]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.090836,	
2017-07-20 16:59:58,531 Epoch[38] Batch [240]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.090927,	
2017-07-20 17:00:02,578 Epoch[38] Batch [250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091132,	
2017-07-20 17:00:06,612 Epoch[38] Batch [260]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.090787,	
2017-07-20 17:00:10,653 Epoch[38] Batch [270]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.090664,	
2017-07-20 17:00:14,728 Epoch[38] Batch [280]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.090577,	
2017-07-20 17:00:18,805 Epoch[38] Batch [290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.090483,	
2017-07-20 17:00:22,894 Epoch[38] Batch [300]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.090362,	
2017-07-20 17:00:26,839 Epoch[38] Batch [310]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.090386,	
2017-07-20 17:00:31,051 Epoch[38] Batch [320]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.090274,	
2017-07-20 17:00:35,065 Epoch[38] Batch [330]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.090177,	
2017-07-20 17:00:39,036 Epoch[38] Batch [340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.090124,	
2017-07-20 17:00:43,166 Epoch[38] Batch [350]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.090257,	
2017-07-20 17:00:47,375 Epoch[38] Batch [360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.090488,	
2017-07-20 17:00:51,428 Epoch[38] Batch [370]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.090537,	
2017-07-20 17:00:55,614 Epoch[38] Batch [380]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.090805,	
2017-07-20 17:00:59,663 Epoch[38] Batch [390]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091029,	
2017-07-20 17:01:03,732 Epoch[38] Batch [400]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.091298,	
2017-07-20 17:01:07,837 Epoch[38] Batch [410]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091937,	
2017-07-20 17:01:11,992 Epoch[38] Batch [420]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091950,	
2017-07-20 17:01:16,095 Epoch[38] Batch [430]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092223,	
2017-07-20 17:01:20,127 Epoch[38] Batch [440]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.092246,	
2017-07-20 17:01:24,217 Epoch[38] Batch [450]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.092151,	
2017-07-20 17:01:28,224 Epoch[38] Batch [460]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.092561,	
2017-07-20 17:01:32,308 Epoch[38] Batch [470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.092396,	
2017-07-20 17:01:36,284 Epoch[38] Batch [480]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.092339,	
2017-07-20 17:01:40,414 Epoch[38] Batch [490]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.092426,	
2017-07-20 17:01:44,472 Epoch[38] Batch [500]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.092610,	
2017-07-20 17:01:48,502 Epoch[38] Batch [510]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.092446,	
2017-07-20 17:01:52,549 Epoch[38] Batch [520]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.092442,	
2017-07-20 17:01:56,615 Epoch[38] Batch [530]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.092347,	
2017-07-20 17:02:00,739 Epoch[38] Batch [540]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092333,	
2017-07-20 17:02:04,741 Epoch[38] Batch [550]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.092286,	
2017-07-20 17:02:08,732 Epoch[38] Batch [560]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.092304,	
2017-07-20 17:02:12,894 Epoch[38] Batch [570]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.092298,	
2017-07-20 17:02:16,998 Epoch[38] Batch [580]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092436,	
2017-07-20 17:02:21,039 Epoch[38] Batch [590]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.092325,	
2017-07-20 17:02:25,169 Epoch[38] Batch [600]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.092368,	
2017-07-20 17:02:29,301 Epoch[38] Batch [610]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.092319,	
2017-07-20 17:02:33,208 Epoch[38] Batch [620]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.092346,	
2017-07-20 17:02:37,324 Epoch[38] Batch [630]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.092239,	
2017-07-20 17:02:41,461 Epoch[38] Batch [640]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.092105,	
2017-07-20 17:02:45,603 Epoch[38] Batch [650]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.092063,	
2017-07-20 17:02:49,618 Epoch[38] Batch [660]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.092058,	
2017-07-20 17:02:53,640 Epoch[38] Batch [670]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091852,	
2017-07-20 17:02:57,763 Epoch[38] Batch [680]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091648,	
2017-07-20 17:03:01,698 Epoch[38] Batch [690]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.091592,	
2017-07-20 17:03:05,811 Epoch[38] Batch [700]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.091500,	
2017-07-20 17:03:09,938 Epoch[38] Batch [710]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091565,	
2017-07-20 17:03:14,092 Epoch[38] Batch [720]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091534,	
2017-07-20 17:03:18,252 Epoch[38] Batch [730]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091417,	
2017-07-20 17:03:22,284 Epoch[38] Batch [740]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091358,	
2017-07-20 17:03:26,374 Epoch[38] Batch [750]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.091346,	
2017-07-20 17:03:30,548 Epoch[38] Batch [760]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091343,	
2017-07-20 17:03:34,617 Epoch[38] Batch [770]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.091392,	
2017-07-20 17:03:38,703 Epoch[38] Batch [780]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.091362,	
2017-07-20 17:03:42,889 Epoch[38] Batch [790]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.091348,	
2017-07-20 17:03:46,867 Epoch[38] Batch [800]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.091370,	
2017-07-20 17:03:51,021 Epoch[38] Batch [810]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091375,	
2017-07-20 17:03:55,273 Epoch[38] Batch [820]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.091390,	
2017-07-20 17:03:59,413 Epoch[38] Batch [830]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091369,	
2017-07-20 17:04:03,464 Epoch[38] Batch [840]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091423,	
2017-07-20 17:04:07,615 Epoch[38] Batch [850]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091524,	
2017-07-20 17:04:11,626 Epoch[38] Batch [860]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.091458,	
2017-07-20 17:04:15,767 Epoch[38] Batch [870]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.091382,	
2017-07-20 17:04:20,038 Epoch[38] Batch [880]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.091478,	
2017-07-20 17:04:24,173 Epoch[38] Batch [890]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091338,	
2017-07-20 17:04:28,116 Epoch[38] Batch [900]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.091334,	
2017-07-20 17:04:32,287 Epoch[38] Batch [910]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.091422,	
2017-07-20 17:04:36,296 Epoch[38] Batch [920]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091349,	
2017-07-20 17:04:40,460 Epoch[38] Batch [930]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091285,	
2017-07-20 17:04:44,678 Epoch[38] Batch [940]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.091232,	
2017-07-20 17:04:48,887 Epoch[38] Batch [950]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091163,	
2017-07-20 17:04:52,952 Epoch[38] Batch [960]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091211,	
2017-07-20 17:04:57,288 Epoch[38] Batch [970]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.091251,	
2017-07-20 17:05:01,413 Epoch[38] Batch [980]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091193,	
2017-07-20 17:05:05,592 Epoch[38] Batch [990]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.091217,	
2017-07-20 17:05:09,611 Epoch[38] Batch [1000]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091207,	
2017-07-20 17:05:13,687 Epoch[38] Batch [1010]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.091101,	
2017-07-20 17:05:17,911 Epoch[38] Batch [1020]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091254,	
2017-07-20 17:05:21,828 Epoch[38] Batch [1030]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.091276,	
2017-07-20 17:05:25,768 Epoch[38] Batch [1040]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.091302,	
2017-07-20 17:05:29,723 Epoch[38] Batch [1050]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.091417,	
2017-07-20 17:05:33,737 Epoch[38] Batch [1060]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.091407,	
2017-07-20 17:05:37,756 Epoch[38] Batch [1070]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.091419,	
2017-07-20 17:05:41,793 Epoch[38] Batch [1080]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.091493,	
2017-07-20 17:05:45,821 Epoch[38] Batch [1090]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.091513,	
2017-07-20 17:05:49,900 Epoch[38] Batch [1100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091554,	
2017-07-20 17:05:53,951 Epoch[38] Batch [1110]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091594,	
2017-07-20 17:05:58,189 Epoch[38] Batch [1120]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091547,	
2017-07-20 17:06:02,234 Epoch[38] Batch [1130]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.091514,	
2017-07-20 17:06:06,346 Epoch[38] Batch [1140]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.091541,	
2017-07-20 17:06:10,381 Epoch[38] Batch [1150]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.091439,	
2017-07-20 17:06:14,556 Epoch[38] Batch [1160]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091410,	
2017-07-20 17:06:18,828 Epoch[38] Batch [1170]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.091266,	
2017-07-20 17:06:22,899 Epoch[38] Batch [1180]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.091334,	
2017-07-20 17:06:26,940 Epoch[38] Batch [1190]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.091352,	
2017-07-20 17:06:31,105 Epoch[38] Batch [1200]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091393,	
2017-07-20 17:06:35,180 Epoch[38] Batch [1210]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.091395,	
2017-07-20 17:06:39,205 Epoch[38] Batch [1220]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.091389,	
2017-07-20 17:06:43,256 Epoch[38] Batch [1230]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091350,	
2017-07-20 17:06:47,403 Epoch[38] Batch [1240]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.091283,	
2017-07-20 17:06:51,370 Epoch[38] Batch [1250]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.091334,	
2017-07-20 17:06:55,502 Epoch[38] Batch [1260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091393,	
2017-07-20 17:06:59,556 Epoch[38] Batch [1270]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091378,	
2017-07-20 17:07:03,655 Epoch[38] Batch [1280]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091303,	
2017-07-20 17:07:07,656 Epoch[38] Batch [1290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091245,	
2017-07-20 17:07:11,811 Epoch[38] Batch [1300]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091257,	
2017-07-20 17:07:15,766 Epoch[38] Batch [1310]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.091297,	
2017-07-20 17:07:19,848 Epoch[38] Batch [1320]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.091335,	
2017-07-20 17:07:23,961 Epoch[38] Batch [1330]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.091377,	
2017-07-20 17:07:27,931 Epoch[38] Batch [1340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.091353,	
2017-07-20 17:07:31,987 Epoch[38] Batch [1350]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.091356,	
2017-07-20 17:07:35,986 Epoch[38] Batch [1360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091307,	
2017-07-20 17:07:39,983 Epoch[38] Batch [1370]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.091395,	
2017-07-20 17:07:43,894 Epoch[38] Batch [1380]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.091382,	
2017-07-20 17:07:48,019 Epoch[38] Batch [1390]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091275,	
2017-07-20 17:07:51,965 Epoch[38] Batch [1400]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.091282,	
2017-07-20 17:07:56,069 Epoch[38] Batch [1410]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091356,	
2017-07-20 17:08:00,273 Epoch[38] Batch [1420]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091297,	
2017-07-20 17:08:04,448 Epoch[38] Batch [1430]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091404,	
2017-07-20 17:08:08,502 Epoch[38] Batch [1440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.091453,	
2017-07-20 17:08:12,574 Epoch[38] Batch [1450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.091431,	
2017-07-20 17:08:16,732 Epoch[38] Batch [1460]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091421,	
2017-07-20 17:08:20,654 Epoch[38] Batch [1470]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.091550,	
2017-07-20 17:08:24,679 Epoch[38] Batch [1480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.091570,	
2017-07-20 17:08:27,098 Epoch[38] Train-FCNLogLoss=0.091577
2017-07-20 17:08:27,098 Epoch[38] Time cost=607.069
2017-07-20 17:08:27,761 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0039.params"
2017-07-20 17:08:29,319 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0039.states"
2017-07-20 17:08:34,009 Epoch[39] Batch [10]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.092777,	
2017-07-20 17:08:38,176 Epoch[39] Batch [20]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.090711,	
2017-07-20 17:08:42,277 Epoch[39] Batch [30]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.090039,	
2017-07-20 17:08:46,352 Epoch[39] Batch [40]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.089595,	
2017-07-20 17:08:50,522 Epoch[39] Batch [50]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.089792,	
2017-07-20 17:08:54,414 Epoch[39] Batch [60]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.089078,	
2017-07-20 17:08:58,369 Epoch[39] Batch [70]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.089795,	
2017-07-20 17:09:02,436 Epoch[39] Batch [80]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.089444,	
2017-07-20 17:09:06,457 Epoch[39] Batch [90]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.090020,	
2017-07-20 17:09:10,575 Epoch[39] Batch [100]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.090023,	
2017-07-20 17:09:14,698 Epoch[39] Batch [110]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090352,	
2017-07-20 17:09:18,823 Epoch[39] Batch [120]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090131,	
2017-07-20 17:09:22,876 Epoch[39] Batch [130]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092233,	
2017-07-20 17:09:26,944 Epoch[39] Batch [140]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.092446,	
2017-07-20 17:09:31,161 Epoch[39] Batch [150]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.092467,	
2017-07-20 17:09:35,182 Epoch[39] Batch [160]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.092518,	
2017-07-20 17:09:39,337 Epoch[39] Batch [170]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.092894,	
2017-07-20 17:09:43,392 Epoch[39] Batch [180]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.093057,	
2017-07-20 17:09:47,343 Epoch[39] Batch [190]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.092857,	
2017-07-20 17:09:51,436 Epoch[39] Batch [200]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092266,	
2017-07-20 17:09:55,538 Epoch[39] Batch [210]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092535,	
2017-07-20 17:09:59,444 Epoch[39] Batch [220]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092644,	
2017-07-20 17:10:03,545 Epoch[39] Batch [230]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.092974,	
2017-07-20 17:10:07,606 Epoch[39] Batch [240]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.093053,	
2017-07-20 17:10:11,646 Epoch[39] Batch [250]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.093574,	
2017-07-20 17:10:15,737 Epoch[39] Batch [260]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093670,	
2017-07-20 17:10:19,708 Epoch[39] Batch [270]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093355,	
2017-07-20 17:10:23,735 Epoch[39] Batch [280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.093073,	
2017-07-20 17:10:27,928 Epoch[39] Batch [290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.092981,	
2017-07-20 17:10:32,024 Epoch[39] Batch [300]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093099,	
2017-07-20 17:10:36,172 Epoch[39] Batch [310]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.092805,	
2017-07-20 17:10:40,321 Epoch[39] Batch [320]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.092729,	
2017-07-20 17:10:44,312 Epoch[39] Batch [330]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.092652,	
2017-07-20 17:10:48,387 Epoch[39] Batch [340]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092681,	
2017-07-20 17:10:52,339 Epoch[39] Batch [350]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.092672,	
2017-07-20 17:10:56,387 Epoch[39] Batch [360]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.092521,	
2017-07-20 17:11:00,429 Epoch[39] Batch [370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.092483,	
2017-07-20 17:11:04,393 Epoch[39] Batch [380]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.092330,	
2017-07-20 17:11:08,803 Epoch[39] Batch [390]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.091972,	
2017-07-20 17:11:12,959 Epoch[39] Batch [400]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091990,	
2017-07-20 17:11:17,188 Epoch[39] Batch [410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.091862,	
2017-07-20 17:11:21,293 Epoch[39] Batch [420]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091899,	
2017-07-20 17:11:25,301 Epoch[39] Batch [430]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091971,	
2017-07-20 17:11:29,493 Epoch[39] Batch [440]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091735,	
2017-07-20 17:11:33,633 Epoch[39] Batch [450]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091796,	
2017-07-20 17:11:37,675 Epoch[39] Batch [460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.091646,	
2017-07-20 17:11:41,893 Epoch[39] Batch [470]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.091701,	
2017-07-20 17:11:46,175 Epoch[39] Batch [480]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091941,	
2017-07-20 17:11:50,205 Epoch[39] Batch [490]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091947,	
2017-07-20 17:11:54,306 Epoch[39] Batch [500]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.091852,	
2017-07-20 17:11:58,380 Epoch[39] Batch [510]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.091858,	
2017-07-20 17:12:02,420 Epoch[39] Batch [520]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.091695,	
2017-07-20 17:12:06,554 Epoch[39] Batch [530]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.091507,	
2017-07-20 17:12:10,639 Epoch[39] Batch [540]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.091344,	
2017-07-20 17:12:14,632 Epoch[39] Batch [550]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.091401,	
2017-07-20 17:12:18,812 Epoch[39] Batch [560]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.091238,	
2017-07-20 17:12:22,862 Epoch[39] Batch [570]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.091234,	
2017-07-20 17:12:27,034 Epoch[39] Batch [580]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.091222,	
2017-07-20 17:12:31,112 Epoch[39] Batch [590]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091199,	
2017-07-20 17:12:35,170 Epoch[39] Batch [600]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.091213,	
2017-07-20 17:12:39,310 Epoch[39] Batch [610]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.090924,	
2017-07-20 17:12:43,374 Epoch[39] Batch [620]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.090850,	
2017-07-20 17:12:47,531 Epoch[39] Batch [630]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.090787,	
2017-07-20 17:12:51,466 Epoch[39] Batch [640]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.090792,	
2017-07-20 17:12:55,638 Epoch[39] Batch [650]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090808,	
2017-07-20 17:12:59,656 Epoch[39] Batch [660]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.090730,	
2017-07-20 17:13:03,711 Epoch[39] Batch [670]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.090643,	
2017-07-20 17:13:07,708 Epoch[39] Batch [680]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.090710,	
2017-07-20 17:13:11,840 Epoch[39] Batch [690]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.090621,	
2017-07-20 17:13:15,864 Epoch[39] Batch [700]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.090662,	
2017-07-20 17:13:19,881 Epoch[39] Batch [710]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.090648,	
2017-07-20 17:13:24,040 Epoch[39] Batch [720]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.090632,	
2017-07-20 17:13:28,310 Epoch[39] Batch [730]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.090709,	
2017-07-20 17:13:32,373 Epoch[39] Batch [740]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.090627,	
2017-07-20 17:13:36,339 Epoch[39] Batch [750]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.090612,	
2017-07-20 17:13:40,404 Epoch[39] Batch [760]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.090623,	
2017-07-20 17:13:44,456 Epoch[39] Batch [770]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.090549,	
2017-07-20 17:13:48,628 Epoch[39] Batch [780]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090592,	
2017-07-20 17:13:52,591 Epoch[39] Batch [790]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.090607,	
2017-07-20 17:13:56,696 Epoch[39] Batch [800]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090563,	
2017-07-20 17:14:00,803 Epoch[39] Batch [810]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090587,	
2017-07-20 17:14:04,972 Epoch[39] Batch [820]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.090654,	
2017-07-20 17:14:09,085 Epoch[39] Batch [830]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.090587,	
2017-07-20 17:14:13,039 Epoch[39] Batch [840]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.090610,	
2017-07-20 17:14:17,143 Epoch[39] Batch [850]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.090644,	
2017-07-20 17:14:21,164 Epoch[39] Batch [860]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.090673,	
2017-07-20 17:14:25,277 Epoch[39] Batch [870]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.090715,	
2017-07-20 17:14:29,207 Epoch[39] Batch [880]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.090667,	
2017-07-20 17:14:33,243 Epoch[39] Batch [890]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.090588,	
2017-07-20 17:14:37,237 Epoch[39] Batch [900]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.090594,	
2017-07-20 17:14:41,314 Epoch[39] Batch [910]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.090493,	
2017-07-20 17:14:45,455 Epoch[39] Batch [920]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.090532,	
2017-07-20 17:14:49,762 Epoch[39] Batch [930]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.090497,	
2017-07-20 17:14:53,932 Epoch[39] Batch [940]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090495,	
2017-07-20 17:14:58,090 Epoch[39] Batch [950]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.090493,	
2017-07-20 17:15:02,149 Epoch[39] Batch [960]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.090453,	
2017-07-20 17:15:06,222 Epoch[39] Batch [970]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.090431,	
2017-07-20 17:15:10,299 Epoch[39] Batch [980]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.090446,	
2017-07-20 17:15:14,364 Epoch[39] Batch [990]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.090358,	
2017-07-20 17:15:18,362 Epoch[39] Batch [1000]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.090393,	
2017-07-20 17:15:22,325 Epoch[39] Batch [1010]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.090332,	
2017-07-20 17:15:26,819 Epoch[39] Batch [1020]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090365,	
2017-07-20 17:15:31,025 Epoch[39] Batch [1030]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.090387,	
2017-07-20 17:15:35,152 Epoch[39] Batch [1040]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090390,	
2017-07-20 17:15:39,161 Epoch[39] Batch [1050]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.090458,	
2017-07-20 17:15:43,268 Epoch[39] Batch [1060]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090428,	
2017-07-20 17:15:47,351 Epoch[39] Batch [1070]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.090389,	
2017-07-20 17:15:51,413 Epoch[39] Batch [1080]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.090320,	
2017-07-20 17:15:55,600 Epoch[39] Batch [1090]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.090287,	
2017-07-20 17:15:59,708 Epoch[39] Batch [1100]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090283,	
2017-07-20 17:16:03,716 Epoch[39] Batch [1110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.090264,	
2017-07-20 17:16:07,772 Epoch[39] Batch [1120]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.090292,	
2017-07-20 17:16:11,829 Epoch[39] Batch [1130]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.090315,	
2017-07-20 17:16:15,864 Epoch[39] Batch [1140]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.090299,	
2017-07-20 17:16:19,890 Epoch[39] Batch [1150]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.090331,	
2017-07-20 17:16:24,109 Epoch[39] Batch [1160]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.090257,	
2017-07-20 17:16:28,219 Epoch[39] Batch [1170]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.090180,	
2017-07-20 17:16:32,298 Epoch[39] Batch [1180]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.090184,	
2017-07-20 17:16:36,468 Epoch[39] Batch [1190]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090201,	
2017-07-20 17:16:40,534 Epoch[39] Batch [1200]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.090126,	
2017-07-20 17:16:44,651 Epoch[39] Batch [1210]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.090147,	
2017-07-20 17:16:48,753 Epoch[39] Batch [1220]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.090222,	
2017-07-20 17:16:52,935 Epoch[39] Batch [1230]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.090270,	
2017-07-20 17:16:56,867 Epoch[39] Batch [1240]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.090262,	
2017-07-20 17:17:01,040 Epoch[39] Batch [1250]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090250,	
2017-07-20 17:17:05,066 Epoch[39] Batch [1260]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.090226,	
2017-07-20 17:17:09,190 Epoch[39] Batch [1270]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090154,	
2017-07-20 17:17:13,320 Epoch[39] Batch [1280]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.090170,	
2017-07-20 17:17:17,563 Epoch[39] Batch [1290]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.090164,	
2017-07-20 17:17:21,584 Epoch[39] Batch [1300]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.090112,	
2017-07-20 17:17:25,674 Epoch[39] Batch [1310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.090150,	
2017-07-20 17:17:29,788 Epoch[39] Batch [1320]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.090222,	
2017-07-20 17:17:33,818 Epoch[39] Batch [1330]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.090288,	
2017-07-20 17:17:37,894 Epoch[39] Batch [1340]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.090261,	
2017-07-20 17:17:42,001 Epoch[39] Batch [1350]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090246,	
2017-07-20 17:17:46,063 Epoch[39] Batch [1360]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.090216,	
2017-07-20 17:17:50,156 Epoch[39] Batch [1370]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.090217,	
2017-07-20 17:17:54,194 Epoch[39] Batch [1380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.090258,	
2017-07-20 17:17:58,286 Epoch[39] Batch [1390]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.090301,	
2017-07-20 17:18:02,413 Epoch[39] Batch [1400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.090266,	
2017-07-20 17:18:06,454 Epoch[39] Batch [1410]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.090277,	
2017-07-20 17:18:10,481 Epoch[39] Batch [1420]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.090359,	
2017-07-20 17:18:14,624 Epoch[39] Batch [1430]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.090376,	
2017-07-20 17:18:18,791 Epoch[39] Batch [1440]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.090426,	
2017-07-20 17:18:22,863 Epoch[39] Batch [1450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.090420,	
2017-07-20 17:18:26,971 Epoch[39] Batch [1460]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.090390,	
2017-07-20 17:18:31,048 Epoch[39] Batch [1470]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.090441,	
2017-07-20 17:18:35,160 Epoch[39] Batch [1480]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.090467,	
2017-07-20 17:18:37,689 Epoch[39] Train-FCNLogLoss=0.090437
2017-07-20 17:18:37,690 Epoch[39] Time cost=608.370
2017-07-20 17:18:38,382 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0040.params"
2017-07-20 17:18:39,954 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0040.states"
2017-07-20 17:18:44,839 Epoch[40] Batch [10]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.080036,	
2017-07-20 17:18:48,927 Epoch[40] Batch [20]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.080748,	
2017-07-20 17:18:53,040 Epoch[40] Batch [30]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.081454,	
2017-07-20 17:18:57,111 Epoch[40] Batch [40]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.083469,	
2017-07-20 17:19:01,076 Epoch[40] Batch [50]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.083565,	
2017-07-20 17:19:05,055 Epoch[40] Batch [60]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.083318,	
2017-07-20 17:19:09,244 Epoch[40] Batch [70]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084951,	
2017-07-20 17:19:13,324 Epoch[40] Batch [80]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.085644,	
2017-07-20 17:19:17,380 Epoch[40] Batch [90]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.085822,	
2017-07-20 17:19:21,546 Epoch[40] Batch [100]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.086199,	
2017-07-20 17:19:25,688 Epoch[40] Batch [110]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.086148,	
2017-07-20 17:19:29,967 Epoch[40] Batch [120]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086565,	
2017-07-20 17:19:34,017 Epoch[40] Batch [130]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.086039,	
2017-07-20 17:19:38,014 Epoch[40] Batch [140]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.086663,	
2017-07-20 17:19:42,086 Epoch[40] Batch [150]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.086185,	
2017-07-20 17:19:46,262 Epoch[40] Batch [160]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086046,	
2017-07-20 17:19:50,326 Epoch[40] Batch [170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.086674,	
2017-07-20 17:19:54,505 Epoch[40] Batch [180]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087301,	
2017-07-20 17:19:58,641 Epoch[40] Batch [190]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087585,	
2017-07-20 17:20:02,769 Epoch[40] Batch [200]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.087985,	
2017-07-20 17:20:06,892 Epoch[40] Batch [210]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.088476,	
2017-07-20 17:20:10,956 Epoch[40] Batch [220]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.088544,	
2017-07-20 17:20:15,041 Epoch[40] Batch [230]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.088606,	
2017-07-20 17:20:19,074 Epoch[40] Batch [240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.088933,	
2017-07-20 17:20:23,214 Epoch[40] Batch [250]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.088837,	
2017-07-20 17:20:27,338 Epoch[40] Batch [260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.089073,	
2017-07-20 17:20:31,516 Epoch[40] Batch [270]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.089003,	
2017-07-20 17:20:35,490 Epoch[40] Batch [280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.088793,	
2017-07-20 17:20:39,719 Epoch[40] Batch [290]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.088947,	
2017-07-20 17:20:43,783 Epoch[40] Batch [300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.088927,	
2017-07-20 17:20:47,933 Epoch[40] Batch [310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.088968,	
2017-07-20 17:20:52,062 Epoch[40] Batch [320]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.088943,	
2017-07-20 17:20:56,143 Epoch[40] Batch [330]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.089092,	
2017-07-20 17:21:00,363 Epoch[40] Batch [340]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.089289,	
2017-07-20 17:21:04,467 Epoch[40] Batch [350]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.089456,	
2017-07-20 17:21:08,577 Epoch[40] Batch [360]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.089450,	
2017-07-20 17:21:12,618 Epoch[40] Batch [370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.089625,	
2017-07-20 17:21:16,740 Epoch[40] Batch [380]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.089567,	
2017-07-20 17:21:20,841 Epoch[40] Batch [390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.089426,	
2017-07-20 17:21:24,943 Epoch[40] Batch [400]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.089395,	
2017-07-20 17:21:29,150 Epoch[40] Batch [410]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.089639,	
2017-07-20 17:21:33,242 Epoch[40] Batch [420]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.089467,	
2017-07-20 17:21:37,268 Epoch[40] Batch [430]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.089530,	
2017-07-20 17:21:41,289 Epoch[40] Batch [440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.089376,	
2017-07-20 17:21:45,395 Epoch[40] Batch [450]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.089354,	
2017-07-20 17:21:49,528 Epoch[40] Batch [460]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.089428,	
2017-07-20 17:21:53,602 Epoch[40] Batch [470]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.089393,	
2017-07-20 17:21:57,799 Epoch[40] Batch [480]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.089508,	
2017-07-20 17:22:01,967 Epoch[40] Batch [490]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.089722,	
2017-07-20 17:22:06,067 Epoch[40] Batch [500]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.089596,	
2017-07-20 17:22:10,139 Epoch[40] Batch [510]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.089560,	
2017-07-20 17:22:14,237 Epoch[40] Batch [520]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.089662,	
2017-07-20 17:22:18,267 Epoch[40] Batch [530]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.089503,	
2017-07-20 17:22:22,546 Epoch[40] Batch [540]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089440,	
2017-07-20 17:22:26,709 Epoch[40] Batch [550]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.089406,	
2017-07-20 17:22:30,713 Epoch[40] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.089316,	
2017-07-20 17:22:34,762 Epoch[40] Batch [570]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.089183,	
2017-07-20 17:22:38,976 Epoch[40] Batch [580]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.089091,	
2017-07-20 17:22:43,003 Epoch[40] Batch [590]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.089091,	
2017-07-20 17:22:47,182 Epoch[40] Batch [600]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.088989,	
2017-07-20 17:22:51,470 Epoch[40] Batch [610]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.089079,	
2017-07-20 17:22:55,705 Epoch[40] Batch [620]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.089127,	
2017-07-20 17:23:00,010 Epoch[40] Batch [630]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.089049,	
2017-07-20 17:23:04,213 Epoch[40] Batch [640]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.089104,	
2017-07-20 17:23:08,401 Epoch[40] Batch [650]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.088829,	
2017-07-20 17:23:12,707 Epoch[40] Batch [660]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.088941,	
2017-07-20 17:23:16,856 Epoch[40] Batch [670]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.088914,	
2017-07-20 17:23:21,051 Epoch[40] Batch [680]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.088951,	
2017-07-20 17:23:25,405 Epoch[40] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088955,	
2017-07-20 17:23:29,741 Epoch[40] Batch [700]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.088931,	
2017-07-20 17:23:33,968 Epoch[40] Batch [710]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.088916,	
2017-07-20 17:23:38,298 Epoch[40] Batch [720]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088905,	
2017-07-20 17:23:42,674 Epoch[40] Batch [730]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.088898,	
2017-07-20 17:23:46,905 Epoch[40] Batch [740]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.088797,	
2017-07-20 17:23:51,164 Epoch[40] Batch [750]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088762,	
2017-07-20 17:23:55,300 Epoch[40] Batch [760]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.088828,	
2017-07-20 17:23:59,401 Epoch[40] Batch [770]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.088826,	
2017-07-20 17:24:03,740 Epoch[40] Batch [780]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.088756,	
2017-07-20 17:24:07,961 Epoch[40] Batch [790]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.088749,	
2017-07-20 17:24:12,139 Epoch[40] Batch [800]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.088710,	
2017-07-20 17:24:16,242 Epoch[40] Batch [810]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.088759,	
2017-07-20 17:24:20,489 Epoch[40] Batch [820]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.088778,	
2017-07-20 17:24:24,695 Epoch[40] Batch [830]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.088805,	
2017-07-20 17:24:29,002 Epoch[40] Batch [840]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.088696,	
2017-07-20 17:24:33,190 Epoch[40] Batch [850]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.088776,	
2017-07-20 17:24:37,573 Epoch[40] Batch [860]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088795,	
2017-07-20 17:24:41,669 Epoch[40] Batch [870]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.088862,	
2017-07-20 17:24:46,011 Epoch[40] Batch [880]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088817,	
2017-07-20 17:24:50,210 Epoch[40] Batch [890]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088756,	
2017-07-20 17:24:54,416 Epoch[40] Batch [900]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.088766,	
2017-07-20 17:24:58,537 Epoch[40] Batch [910]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.088726,	
2017-07-20 17:25:02,771 Epoch[40] Batch [920]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.088670,	
2017-07-20 17:25:07,063 Epoch[40] Batch [930]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088636,	
2017-07-20 17:25:11,353 Epoch[40] Batch [940]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088645,	
2017-07-20 17:25:15,669 Epoch[40] Batch [950]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088546,	
2017-07-20 17:25:19,892 Epoch[40] Batch [960]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.088608,	
2017-07-20 17:25:24,180 Epoch[40] Batch [970]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.088587,	
2017-07-20 17:25:28,484 Epoch[40] Batch [980]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.088629,	
2017-07-20 17:25:32,763 Epoch[40] Batch [990]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.088662,	
2017-07-20 17:25:37,076 Epoch[40] Batch [1000]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.088732,	
2017-07-20 17:25:41,481 Epoch[40] Batch [1010]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.088696,	
2017-07-20 17:25:45,612 Epoch[40] Batch [1020]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.088721,	
2017-07-20 17:25:49,780 Epoch[40] Batch [1030]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.088627,	
2017-07-20 17:25:54,091 Epoch[40] Batch [1040]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.088584,	
2017-07-20 17:25:58,434 Epoch[40] Batch [1050]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088542,	
2017-07-20 17:26:02,600 Epoch[40] Batch [1060]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.088509,	
2017-07-20 17:26:06,881 Epoch[40] Batch [1070]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.088456,	
2017-07-20 17:26:11,243 Epoch[40] Batch [1080]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.088467,	
2017-07-20 17:26:15,326 Epoch[40] Batch [1090]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.088562,	
2017-07-20 17:26:19,420 Epoch[40] Batch [1100]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.088622,	
2017-07-20 17:26:23,616 Epoch[40] Batch [1110]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088634,	
2017-07-20 17:26:27,645 Epoch[40] Batch [1120]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.088647,	
2017-07-20 17:26:32,026 Epoch[40] Batch [1130]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088614,	
2017-07-20 17:26:36,340 Epoch[40] Batch [1140]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088584,	
2017-07-20 17:26:40,620 Epoch[40] Batch [1150]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.088587,	
2017-07-20 17:26:44,872 Epoch[40] Batch [1160]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.088577,	
2017-07-20 17:26:49,196 Epoch[40] Batch [1170]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.088503,	
2017-07-20 17:26:53,495 Epoch[40] Batch [1180]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.088545,	
2017-07-20 17:26:57,798 Epoch[40] Batch [1190]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.088509,	
2017-07-20 17:27:01,996 Epoch[40] Batch [1200]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088445,	
2017-07-20 17:27:06,185 Epoch[40] Batch [1210]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.088450,	
2017-07-20 17:27:10,431 Epoch[40] Batch [1220]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.088554,	
2017-07-20 17:27:14,690 Epoch[40] Batch [1230]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088591,	
2017-07-20 17:27:18,968 Epoch[40] Batch [1240]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.088538,	
2017-07-20 17:27:23,223 Epoch[40] Batch [1250]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.088491,	
2017-07-20 17:27:27,342 Epoch[40] Batch [1260]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.088575,	
2017-07-20 17:27:31,604 Epoch[40] Batch [1270]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088661,	
2017-07-20 17:27:35,686 Epoch[40] Batch [1280]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.088716,	
2017-07-20 17:27:39,804 Epoch[40] Batch [1290]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.088623,	
2017-07-20 17:27:43,882 Epoch[40] Batch [1300]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.088780,	
2017-07-20 17:27:47,968 Epoch[40] Batch [1310]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.088829,	
2017-07-20 17:27:51,949 Epoch[40] Batch [1320]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.088898,	
2017-07-20 17:27:56,057 Epoch[40] Batch [1330]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.088914,	
2017-07-20 17:28:00,274 Epoch[40] Batch [1340]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.088895,	
2017-07-20 17:28:04,329 Epoch[40] Batch [1350]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.088900,	
2017-07-20 17:28:08,269 Epoch[40] Batch [1360]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.088931,	
2017-07-20 17:28:12,482 Epoch[40] Batch [1370]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.088876,	
2017-07-20 17:28:16,650 Epoch[40] Batch [1380]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.088853,	
2017-07-20 17:28:20,849 Epoch[40] Batch [1390]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088799,	
2017-07-20 17:28:24,861 Epoch[40] Batch [1400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.088807,	
2017-07-20 17:28:28,961 Epoch[40] Batch [1410]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.088826,	
2017-07-20 17:28:33,116 Epoch[40] Batch [1420]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.088760,	
2017-07-20 17:28:37,180 Epoch[40] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.088708,	
2017-07-20 17:28:41,294 Epoch[40] Batch [1440]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.088709,	
2017-07-20 17:28:45,240 Epoch[40] Batch [1450]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.088735,	
2017-07-20 17:28:49,212 Epoch[40] Batch [1460]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.088706,	
2017-07-20 17:28:53,352 Epoch[40] Batch [1470]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.088723,	
2017-07-20 17:28:57,379 Epoch[40] Batch [1480]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.088721,	
2017-07-20 17:28:59,798 Epoch[40] Train-FCNLogLoss=0.088695
2017-07-20 17:28:59,798 Epoch[40] Time cost=619.844
2017-07-20 17:29:00,488 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0041.params"
2017-07-20 17:29:02,682 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0041.states"
2017-07-20 17:29:07,355 Epoch[41] Batch [10]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.083916,	
2017-07-20 17:29:11,489 Epoch[41] Batch [20]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.084248,	
2017-07-20 17:29:15,516 Epoch[41] Batch [30]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.086769,	
2017-07-20 17:29:19,716 Epoch[41] Batch [40]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085614,	
2017-07-20 17:29:23,885 Epoch[41] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.086255,	
2017-07-20 17:29:28,042 Epoch[41] Batch [60]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.086453,	
2017-07-20 17:29:32,227 Epoch[41] Batch [70]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.086913,	
2017-07-20 17:29:36,340 Epoch[41] Batch [80]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.086287,	
2017-07-20 17:29:40,501 Epoch[41] Batch [90]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.087024,	
2017-07-20 17:29:44,600 Epoch[41] Batch [100]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.086664,	
2017-07-20 17:29:48,664 Epoch[41] Batch [110]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.087046,	
2017-07-20 17:29:52,608 Epoch[41] Batch [120]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.086914,	
2017-07-20 17:29:56,724 Epoch[41] Batch [130]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.086726,	
2017-07-20 17:30:00,673 Epoch[41] Batch [140]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.086793,	
2017-07-20 17:30:04,724 Epoch[41] Batch [150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.086452,	
2017-07-20 17:30:08,820 Epoch[41] Batch [160]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.086706,	
2017-07-20 17:30:12,951 Epoch[41] Batch [170]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.086784,	
2017-07-20 17:30:17,072 Epoch[41] Batch [180]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.086682,	
2017-07-20 17:30:21,160 Epoch[41] Batch [190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087289,	
2017-07-20 17:30:25,223 Epoch[41] Batch [200]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.087061,	
2017-07-20 17:30:29,233 Epoch[41] Batch [210]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.086843,	
2017-07-20 17:30:33,170 Epoch[41] Batch [220]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.086873,	
2017-07-20 17:30:37,221 Epoch[41] Batch [230]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.086953,	
2017-07-20 17:30:41,373 Epoch[41] Batch [240]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.087544,	
2017-07-20 17:30:45,434 Epoch[41] Batch [250]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.087657,	
2017-07-20 17:30:49,569 Epoch[41] Batch [260]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087551,	
2017-07-20 17:30:53,790 Epoch[41] Batch [270]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087354,	
2017-07-20 17:30:57,876 Epoch[41] Batch [280]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087307,	
2017-07-20 17:31:01,888 Epoch[41] Batch [290]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.087354,	
2017-07-20 17:31:05,966 Epoch[41] Batch [300]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.087532,	
2017-07-20 17:31:10,055 Epoch[41] Batch [310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.087501,	
2017-07-20 17:31:14,220 Epoch[41] Batch [320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.087527,	
2017-07-20 17:31:18,255 Epoch[41] Batch [330]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.087564,	
2017-07-20 17:31:22,390 Epoch[41] Batch [340]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087424,	
2017-07-20 17:31:26,478 Epoch[41] Batch [350]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087466,	
2017-07-20 17:31:30,607 Epoch[41] Batch [360]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.087436,	
2017-07-20 17:31:34,858 Epoch[41] Batch [370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087554,	
2017-07-20 17:31:39,039 Epoch[41] Batch [380]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087577,	
2017-07-20 17:31:43,155 Epoch[41] Batch [390]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.087782,	
2017-07-20 17:31:47,178 Epoch[41] Batch [400]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.087768,	
2017-07-20 17:31:51,178 Epoch[41] Batch [410]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.087641,	
2017-07-20 17:31:55,210 Epoch[41] Batch [420]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.087521,	
2017-07-20 17:31:59,331 Epoch[41] Batch [430]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.087371,	
2017-07-20 17:32:03,395 Epoch[41] Batch [440]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.087486,	
2017-07-20 17:32:07,461 Epoch[41] Batch [450]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.087370,	
2017-07-20 17:32:11,599 Epoch[41] Batch [460]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087517,	
2017-07-20 17:32:15,745 Epoch[41] Batch [470]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.087509,	
2017-07-20 17:32:19,902 Epoch[41] Batch [480]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.087557,	
2017-07-20 17:32:24,015 Epoch[41] Batch [490]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.087500,	
2017-07-20 17:32:28,179 Epoch[41] Batch [500]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.087740,	
2017-07-20 17:32:32,338 Epoch[41] Batch [510]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.087718,	
2017-07-20 17:32:36,377 Epoch[41] Batch [520]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.087585,	
2017-07-20 17:32:40,362 Epoch[41] Batch [530]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.087733,	
2017-07-20 17:32:44,405 Epoch[41] Batch [540]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.087854,	
2017-07-20 17:32:48,529 Epoch[41] Batch [550]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.087893,	
2017-07-20 17:32:52,534 Epoch[41] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.087901,	
2017-07-20 17:32:56,569 Epoch[41] Batch [570]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.087938,	
2017-07-20 17:33:00,585 Epoch[41] Batch [580]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.087996,	
2017-07-20 17:33:04,708 Epoch[41] Batch [590]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.087953,	
2017-07-20 17:33:08,650 Epoch[41] Batch [600]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.088251,	
2017-07-20 17:33:12,658 Epoch[41] Batch [610]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.088274,	
2017-07-20 17:33:16,603 Epoch[41] Batch [620]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.088274,	
2017-07-20 17:33:20,594 Epoch[41] Batch [630]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.088394,	
2017-07-20 17:33:24,698 Epoch[41] Batch [640]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.088320,	
2017-07-20 17:33:28,798 Epoch[41] Batch [650]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.088205,	
2017-07-20 17:33:32,949 Epoch[41] Batch [660]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.088255,	
2017-07-20 17:33:37,001 Epoch[41] Batch [670]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.088309,	
2017-07-20 17:33:41,137 Epoch[41] Batch [680]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.088280,	
2017-07-20 17:33:45,222 Epoch[41] Batch [690]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.088373,	
2017-07-20 17:33:49,345 Epoch[41] Batch [700]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.088295,	
2017-07-20 17:33:53,347 Epoch[41] Batch [710]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.088322,	
2017-07-20 17:33:57,546 Epoch[41] Batch [720]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088366,	
2017-07-20 17:34:01,611 Epoch[41] Batch [730]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.088251,	
2017-07-20 17:34:05,657 Epoch[41] Batch [740]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.088399,	
2017-07-20 17:34:09,704 Epoch[41] Batch [750]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.088393,	
2017-07-20 17:34:13,903 Epoch[41] Batch [760]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088419,	
2017-07-20 17:34:17,914 Epoch[41] Batch [770]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.088431,	
2017-07-20 17:34:21,933 Epoch[41] Batch [780]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.088341,	
2017-07-20 17:34:25,928 Epoch[41] Batch [790]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.088363,	
2017-07-20 17:34:29,943 Epoch[41] Batch [800]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.088323,	
2017-07-20 17:34:34,026 Epoch[41] Batch [810]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.088177,	
2017-07-20 17:34:38,175 Epoch[41] Batch [820]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.088208,	
2017-07-20 17:34:42,191 Epoch[41] Batch [830]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.088280,	
2017-07-20 17:34:46,337 Epoch[41] Batch [840]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.088125,	
2017-07-20 17:34:50,403 Epoch[41] Batch [850]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.088163,	
2017-07-20 17:34:54,532 Epoch[41] Batch [860]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.088190,	
2017-07-20 17:34:58,504 Epoch[41] Batch [870]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.088209,	
2017-07-20 17:35:02,448 Epoch[41] Batch [880]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.088261,	
2017-07-20 17:35:08,087 Epoch[41] Batch [890]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.088263,	
2017-07-20 17:35:14,411 Epoch[41] Batch [900]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.088335,	
2017-07-20 17:35:20,360 Epoch[41] Batch [910]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088277,	
2017-07-20 17:35:25,902 Epoch[41] Batch [920]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088276,	
2017-07-20 17:35:30,629 Epoch[41] Batch [930]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088243,	
2017-07-20 17:35:36,032 Epoch[41] Batch [940]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088284,	
2017-07-20 17:35:41,013 Epoch[41] Batch [950]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.088320,	
2017-07-20 17:35:46,673 Epoch[41] Batch [960]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088386,	
2017-07-20 17:35:52,355 Epoch[41] Batch [970]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088456,	
2017-07-20 17:35:57,937 Epoch[41] Batch [980]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088394,	
2017-07-20 17:36:03,068 Epoch[41] Batch [990]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088278,	
2017-07-20 17:36:07,385 Epoch[41] Batch [1000]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088324,	
2017-07-20 17:36:11,947 Epoch[41] Batch [1010]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088377,	
2017-07-20 17:36:16,029 Epoch[41] Batch [1020]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.088309,	
2017-07-20 17:36:20,605 Epoch[41] Batch [1030]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088236,	
2017-07-20 17:36:25,554 Epoch[41] Batch [1040]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088181,	
2017-07-20 17:36:30,370 Epoch[41] Batch [1050]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088176,	
2017-07-20 17:36:35,271 Epoch[41] Batch [1060]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088289,	
2017-07-20 17:36:39,997 Epoch[41] Batch [1070]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088217,	
2017-07-20 17:36:44,384 Epoch[41] Batch [1080]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088149,	
2017-07-20 17:36:48,825 Epoch[41] Batch [1090]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088105,	
2017-07-20 17:36:53,520 Epoch[41] Batch [1100]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088137,	
2017-07-20 17:36:58,164 Epoch[41] Batch [1110]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088126,	
2017-07-20 17:37:02,860 Epoch[41] Batch [1120]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088188,	
2017-07-20 17:37:07,707 Epoch[41] Batch [1130]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088122,	
2017-07-20 17:37:12,202 Epoch[41] Batch [1140]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088151,	
2017-07-20 17:37:16,623 Epoch[41] Batch [1150]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088142,	
2017-07-20 17:37:21,591 Epoch[41] Batch [1160]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088251,	
2017-07-20 17:37:26,304 Epoch[41] Batch [1170]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088326,	
2017-07-20 17:37:31,139 Epoch[41] Batch [1180]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088292,	
2017-07-20 17:37:36,144 Epoch[41] Batch [1190]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088266,	
2017-07-20 17:37:40,576 Epoch[41] Batch [1200]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088323,	
2017-07-20 17:37:45,098 Epoch[41] Batch [1210]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088336,	
2017-07-20 17:37:49,450 Epoch[41] Batch [1220]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088352,	
2017-07-20 17:37:53,709 Epoch[41] Batch [1230]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088338,	
2017-07-20 17:37:57,787 Epoch[41] Batch [1240]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.088346,	
2017-07-20 17:38:02,187 Epoch[41] Batch [1250]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088335,	
2017-07-20 17:38:06,735 Epoch[41] Batch [1260]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088378,	
2017-07-20 17:38:11,362 Epoch[41] Batch [1270]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.088303,	
2017-07-20 17:38:16,252 Epoch[41] Batch [1280]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088293,	
2017-07-20 17:38:21,165 Epoch[41] Batch [1290]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088288,	
2017-07-20 17:38:25,741 Epoch[41] Batch [1300]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088342,	
2017-07-20 17:38:30,517 Epoch[41] Batch [1310]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088409,	
2017-07-20 17:38:35,202 Epoch[41] Batch [1320]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088502,	
2017-07-20 17:38:39,400 Epoch[41] Batch [1330]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088587,	
2017-07-20 17:38:43,996 Epoch[41] Batch [1340]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088737,	
2017-07-20 17:38:48,702 Epoch[41] Batch [1350]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088842,	
2017-07-20 17:38:53,220 Epoch[41] Batch [1360]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088909,	
2017-07-20 17:38:57,484 Epoch[41] Batch [1370]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.089108,	
2017-07-20 17:39:02,029 Epoch[41] Batch [1380]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089375,	
2017-07-20 17:39:06,748 Epoch[41] Batch [1390]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089494,	
2017-07-20 17:39:11,298 Epoch[41] Batch [1400]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089606,	
2017-07-20 17:39:16,715 Epoch[41] Batch [1410]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.089705,	
2017-07-20 17:39:22,350 Epoch[41] Batch [1420]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.089755,	
2017-07-20 17:39:26,785 Epoch[41] Batch [1430]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.089786,	
2017-07-20 17:39:30,859 Epoch[41] Batch [1440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.089843,	
2017-07-20 17:39:34,908 Epoch[41] Batch [1450]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.089883,	
2017-07-20 17:39:38,911 Epoch[41] Batch [1460]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.089971,	
2017-07-20 17:39:42,776 Epoch[41] Batch [1470]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.090016,	
2017-07-20 17:39:46,879 Epoch[41] Batch [1480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.090099,	
2017-07-20 17:39:49,146 Epoch[41] Train-FCNLogLoss=0.090160
2017-07-20 17:39:49,146 Epoch[41] Time cost=646.464
2017-07-20 17:39:50,038 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0042.params"
2017-07-20 17:39:53,237 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0042.states"
2017-07-20 17:39:57,852 Epoch[42] Batch [10]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096425,	
2017-07-20 17:40:01,816 Epoch[42] Batch [20]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095736,	
2017-07-20 17:40:05,802 Epoch[42] Batch [30]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095626,	
2017-07-20 17:40:09,938 Epoch[42] Batch [40]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094559,	
2017-07-20 17:40:13,952 Epoch[42] Batch [50]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.093971,	
2017-07-20 17:40:17,911 Epoch[42] Batch [60]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.093713,	
2017-07-20 17:40:21,839 Epoch[42] Batch [70]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092518,	
2017-07-20 17:40:25,992 Epoch[42] Batch [80]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.093107,	
2017-07-20 17:40:29,977 Epoch[42] Batch [90]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.092743,	
2017-07-20 17:40:33,995 Epoch[42] Batch [100]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.092032,	
2017-07-20 17:40:37,940 Epoch[42] Batch [110]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.091118,	
2017-07-20 17:40:41,755 Epoch[42] Batch [120]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.090675,	
2017-07-20 17:40:45,750 Epoch[42] Batch [130]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.090427,	
2017-07-20 17:40:49,856 Epoch[42] Batch [140]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.090526,	
2017-07-20 17:40:54,014 Epoch[42] Batch [150]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.090458,	
2017-07-20 17:40:58,153 Epoch[42] Batch [160]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.090977,	
2017-07-20 17:41:02,178 Epoch[42] Batch [170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.090759,	
2017-07-20 17:41:06,553 Epoch[42] Batch [180]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.090973,	
2017-07-20 17:41:10,885 Epoch[42] Batch [190]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.090954,	
2017-07-20 17:41:15,372 Epoch[42] Batch [200]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090885,	
2017-07-20 17:41:19,331 Epoch[42] Batch [210]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.090912,	
2017-07-20 17:41:23,390 Epoch[42] Batch [220]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.091010,	
2017-07-20 17:41:27,399 Epoch[42] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091122,	
2017-07-20 17:41:31,621 Epoch[42] Batch [240]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091263,	
2017-07-20 17:41:35,789 Epoch[42] Batch [250]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.090893,	
2017-07-20 17:41:40,047 Epoch[42] Batch [260]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.090610,	
2017-07-20 17:41:44,045 Epoch[42] Batch [270]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.090031,	
2017-07-20 17:41:48,218 Epoch[42] Batch [280]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090398,	
2017-07-20 17:41:52,291 Epoch[42] Batch [290]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.090328,	
2017-07-20 17:41:56,494 Epoch[42] Batch [300]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.090506,	
2017-07-20 17:42:00,403 Epoch[42] Batch [310]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.090192,	
2017-07-20 17:42:04,474 Epoch[42] Batch [320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.090238,	
2017-07-20 17:42:08,492 Epoch[42] Batch [330]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.089986,	
2017-07-20 17:42:12,530 Epoch[42] Batch [340]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.089681,	
2017-07-20 17:42:16,950 Epoch[42] Batch [350]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.089318,	
2017-07-20 17:42:20,944 Epoch[42] Batch [360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.089272,	
2017-07-20 17:42:24,804 Epoch[42] Batch [370]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.089146,	
2017-07-20 17:42:28,832 Epoch[42] Batch [380]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.089204,	
2017-07-20 17:42:32,980 Epoch[42] Batch [390]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.089369,	
2017-07-20 17:42:37,207 Epoch[42] Batch [400]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.090418,	
2017-07-20 17:42:41,359 Epoch[42] Batch [410]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094999,	
2017-07-20 17:42:45,559 Epoch[42] Batch [420]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.098331,	
2017-07-20 17:42:50,072 Epoch[42] Batch [430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.099401,	
2017-07-20 17:42:54,373 Epoch[42] Batch [440]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.100944,	
2017-07-20 17:42:59,005 Epoch[42] Batch [450]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.102009,	
2017-07-20 17:43:03,483 Epoch[42] Batch [460]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103678,	
2017-07-20 17:43:07,711 Epoch[42] Batch [470]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.104270,	
2017-07-20 17:43:11,825 Epoch[42] Batch [480]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.104646,	
2017-07-20 17:43:15,976 Epoch[42] Batch [490]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105111,	
2017-07-20 17:43:20,247 Epoch[42] Batch [500]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.105188,	
2017-07-20 17:43:24,471 Epoch[42] Batch [510]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105496,	
2017-07-20 17:43:28,454 Epoch[42] Batch [520]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.105318,	
2017-07-20 17:43:32,339 Epoch[42] Batch [530]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.105405,	
2017-07-20 17:43:36,329 Epoch[42] Batch [540]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105434,	
2017-07-20 17:43:40,606 Epoch[42] Batch [550]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.105388,	
2017-07-20 17:43:44,853 Epoch[42] Batch [560]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.105224,	
2017-07-20 17:43:48,934 Epoch[42] Batch [570]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105018,	
2017-07-20 17:43:53,233 Epoch[42] Batch [580]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.104795,	
2017-07-20 17:43:57,455 Epoch[42] Batch [590]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.104823,	
2017-07-20 17:44:02,415 Epoch[42] Batch [600]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.104806,	
2017-07-20 17:44:07,624 Epoch[42] Batch [610]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.104936,	
2017-07-20 17:44:12,844 Epoch[42] Batch [620]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.104804,	
2017-07-20 17:44:18,272 Epoch[42] Batch [630]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.104952,	
2017-07-20 17:44:23,723 Epoch[42] Batch [640]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.104797,	
2017-07-20 17:44:29,180 Epoch[42] Batch [650]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.104708,	
2017-07-20 17:44:34,379 Epoch[42] Batch [660]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.104553,	
2017-07-20 17:44:39,345 Epoch[42] Batch [670]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.104419,	
2017-07-20 17:44:44,142 Epoch[42] Batch [680]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.104346,	
2017-07-20 17:44:48,795 Epoch[42] Batch [690]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.104285,	
2017-07-20 17:44:54,033 Epoch[42] Batch [700]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.104296,	
2017-07-20 17:44:58,875 Epoch[42] Batch [710]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.104485,	
2017-07-20 17:45:03,614 Epoch[42] Batch [720]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.104537,	
2017-07-20 17:45:08,071 Epoch[42] Batch [730]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.104517,	
2017-07-20 17:45:12,370 Epoch[42] Batch [740]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105115,	
2017-07-20 17:45:17,005 Epoch[42] Batch [750]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.105003,	
2017-07-20 17:45:21,664 Epoch[42] Batch [760]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.104828,	
2017-07-20 17:45:26,065 Epoch[42] Batch [770]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.104675,	
2017-07-20 17:45:30,682 Epoch[42] Batch [780]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.104482,	
2017-07-20 17:45:35,035 Epoch[42] Batch [790]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.104315,	
2017-07-20 17:45:39,587 Epoch[42] Batch [800]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104280,	
2017-07-20 17:45:44,334 Epoch[42] Batch [810]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.104307,	
2017-07-20 17:45:48,592 Epoch[42] Batch [820]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.104129,	
2017-07-20 17:45:53,027 Epoch[42] Batch [830]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104088,	
2017-07-20 17:45:57,430 Epoch[42] Batch [840]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.104049,	
2017-07-20 17:46:01,427 Epoch[42] Batch [850]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.103932,	
2017-07-20 17:46:05,878 Epoch[42] Batch [860]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.103792,	
2017-07-20 17:46:10,450 Epoch[42] Batch [870]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.103627,	
2017-07-20 17:46:15,212 Epoch[42] Batch [880]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.103548,	
2017-07-20 17:46:19,611 Epoch[42] Batch [890]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.103432,	
2017-07-20 17:46:24,317 Epoch[42] Batch [900]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.103351,	
2017-07-20 17:46:28,934 Epoch[42] Batch [910]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.103250,	
2017-07-20 17:46:33,654 Epoch[42] Batch [920]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.103086,	
2017-07-20 17:46:38,445 Epoch[42] Batch [930]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.102999,	
2017-07-20 17:46:42,754 Epoch[42] Batch [940]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.102933,	
2017-07-20 17:46:47,163 Epoch[42] Batch [950]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.102768,	
2017-07-20 17:46:51,833 Epoch[42] Batch [960]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.102650,	
2017-07-20 17:46:56,656 Epoch[42] Batch [970]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.102610,	
2017-07-20 17:47:00,952 Epoch[42] Batch [980]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.102589,	
2017-07-20 17:47:05,525 Epoch[42] Batch [990]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.102546,	
2017-07-20 17:47:10,187 Epoch[42] Batch [1000]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.102359,	
2017-07-20 17:47:14,618 Epoch[42] Batch [1010]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.102234,	
2017-07-20 17:47:19,415 Epoch[42] Batch [1020]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.102108,	
2017-07-20 17:47:24,256 Epoch[42] Batch [1030]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.101987,	
2017-07-20 17:47:29,097 Epoch[42] Batch [1040]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.101875,	
2017-07-20 17:47:33,812 Epoch[42] Batch [1050]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.101746,	
2017-07-20 17:47:38,252 Epoch[42] Batch [1060]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.101656,	
2017-07-20 17:47:42,867 Epoch[42] Batch [1070]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.101511,	
2017-07-20 17:47:47,343 Epoch[42] Batch [1080]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.101445,	
2017-07-20 17:47:51,584 Epoch[42] Batch [1090]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.101405,	
2017-07-20 17:47:56,102 Epoch[42] Batch [1100]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.101326,	
2017-07-20 17:48:00,834 Epoch[42] Batch [1110]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.101156,	
2017-07-20 17:48:05,411 Epoch[42] Batch [1120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.101018,	
2017-07-20 17:48:10,053 Epoch[42] Batch [1130]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.100849,	
2017-07-20 17:48:14,455 Epoch[42] Batch [1140]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100745,	
2017-07-20 17:48:19,009 Epoch[42] Batch [1150]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.100606,	
2017-07-20 17:48:23,690 Epoch[42] Batch [1160]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.100444,	
2017-07-20 17:48:28,452 Epoch[42] Batch [1170]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.100484,	
2017-07-20 17:48:32,843 Epoch[42] Batch [1180]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.100570,	
2017-07-20 17:48:37,607 Epoch[42] Batch [1190]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.100595,	
2017-07-20 17:48:42,130 Epoch[42] Batch [1200]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.100656,	
2017-07-20 17:48:46,483 Epoch[42] Batch [1210]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.100715,	
2017-07-20 17:48:50,748 Epoch[42] Batch [1220]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.100718,	
2017-07-20 17:48:55,245 Epoch[42] Batch [1230]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.100727,	
2017-07-20 17:48:59,772 Epoch[42] Batch [1240]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.100667,	
2017-07-20 17:49:04,539 Epoch[42] Batch [1250]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.100553,	
2017-07-20 17:49:09,453 Epoch[42] Batch [1260]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.100480,	
2017-07-20 17:49:14,472 Epoch[42] Batch [1270]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.100450,	
2017-07-20 17:49:19,457 Epoch[42] Batch [1280]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.100434,	
2017-07-20 17:49:24,207 Epoch[42] Batch [1290]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.100359,	
2017-07-20 17:49:28,651 Epoch[42] Batch [1300]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.100295,	
2017-07-20 17:49:33,010 Epoch[42] Batch [1310]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.100311,	
2017-07-20 17:49:37,490 Epoch[42] Batch [1320]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.100231,	
2017-07-20 17:49:42,066 Epoch[42] Batch [1330]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.100147,	
2017-07-20 17:49:46,666 Epoch[42] Batch [1340]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.100075,	
2017-07-20 17:49:51,034 Epoch[42] Batch [1350]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.100127,	
2017-07-20 17:49:55,510 Epoch[42] Batch [1360]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.100150,	
2017-07-20 17:50:00,074 Epoch[42] Batch [1370]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.100061,	
2017-07-20 17:50:04,619 Epoch[42] Batch [1380]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.100110,	
2017-07-20 17:50:09,433 Epoch[42] Batch [1390]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.100056,	
2017-07-20 17:50:13,935 Epoch[42] Batch [1400]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.099945,	
2017-07-20 17:50:18,485 Epoch[42] Batch [1410]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.099859,	
2017-07-20 17:50:23,178 Epoch[42] Batch [1420]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.099770,	
2017-07-20 17:50:28,036 Epoch[42] Batch [1430]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.099669,	
2017-07-20 17:50:32,730 Epoch[42] Batch [1440]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.099604,	
2017-07-20 17:50:37,724 Epoch[42] Batch [1450]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.099563,	
2017-07-20 17:50:42,331 Epoch[42] Batch [1460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.099498,	
2017-07-20 17:50:47,057 Epoch[42] Batch [1470]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.099435,	
2017-07-20 17:50:51,877 Epoch[42] Batch [1480]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.099386,	
2017-07-20 17:50:54,597 Epoch[42] Train-FCNLogLoss=0.099378
2017-07-20 17:50:54,597 Epoch[42] Time cost=661.359
2017-07-20 17:50:55,344 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0043.params"
2017-07-20 17:50:58,525 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0043.states"
2017-07-20 17:51:03,980 Epoch[43] Batch [10]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.093754,	
2017-07-20 17:51:08,582 Epoch[43] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089300,	
2017-07-20 17:51:13,153 Epoch[43] Batch [30]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092864,	
2017-07-20 17:51:17,829 Epoch[43] Batch [40]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092242,	
2017-07-20 17:51:22,588 Epoch[43] Batch [50]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092104,	
2017-07-20 17:51:27,486 Epoch[43] Batch [60]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.090614,	
2017-07-20 17:51:32,245 Epoch[43] Batch [70]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089561,	
2017-07-20 17:51:36,854 Epoch[43] Batch [80]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090191,	
2017-07-20 17:51:41,344 Epoch[43] Batch [90]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090480,	
2017-07-20 17:51:46,047 Epoch[43] Batch [100]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090467,	
2017-07-20 17:51:51,077 Epoch[43] Batch [110]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.091027,	
2017-07-20 17:51:55,814 Epoch[43] Batch [120]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090707,	
2017-07-20 17:52:00,223 Epoch[43] Batch [130]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090222,	
2017-07-20 17:52:04,542 Epoch[43] Batch [140]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.089767,	
2017-07-20 17:52:09,154 Epoch[43] Batch [150]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089609,	
2017-07-20 17:52:13,575 Epoch[43] Batch [160]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.089993,	
2017-07-20 17:52:17,895 Epoch[43] Batch [170]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.090316,	
2017-07-20 17:52:22,608 Epoch[43] Batch [180]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090724,	
2017-07-20 17:52:27,227 Epoch[43] Batch [190]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089961,	
2017-07-20 17:52:32,245 Epoch[43] Batch [200]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.090364,	
2017-07-20 17:52:36,816 Epoch[43] Batch [210]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.089845,	
2017-07-20 17:52:41,540 Epoch[43] Batch [220]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089518,	
2017-07-20 17:52:46,313 Epoch[43] Batch [230]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089394,	
2017-07-20 17:52:51,205 Epoch[43] Batch [240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.089789,	
2017-07-20 17:52:55,735 Epoch[43] Batch [250]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090161,	
2017-07-20 17:53:00,596 Epoch[43] Batch [260]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.090455,	
2017-07-20 17:53:04,950 Epoch[43] Batch [270]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.090514,	
2017-07-20 17:53:09,345 Epoch[43] Batch [280]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090267,	
2017-07-20 17:53:14,163 Epoch[43] Batch [290]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.090193,	
2017-07-20 17:53:18,493 Epoch[43] Batch [300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.090429,	
2017-07-20 17:53:22,852 Epoch[43] Batch [310]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.090334,	
2017-07-20 17:53:27,598 Epoch[43] Batch [320]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090159,	
2017-07-20 17:53:32,176 Epoch[43] Batch [330]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090018,	
2017-07-20 17:53:36,851 Epoch[43] Batch [340]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090088,	
2017-07-20 17:53:40,942 Epoch[43] Batch [350]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.090133,	
2017-07-20 17:53:45,567 Epoch[43] Batch [360]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.090142,	
2017-07-20 17:53:50,971 Epoch[43] Batch [370]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090205,	
2017-07-20 17:53:55,774 Epoch[43] Batch [380]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089948,	
2017-07-20 17:54:00,472 Epoch[43] Batch [390]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089716,	
2017-07-20 17:54:05,335 Epoch[43] Batch [400]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089585,	
2017-07-20 17:54:09,971 Epoch[43] Batch [410]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089661,	
2017-07-20 17:54:14,400 Epoch[43] Batch [420]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.089708,	
2017-07-20 17:54:19,124 Epoch[43] Batch [430]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089959,	
2017-07-20 17:54:23,828 Epoch[43] Batch [440]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089918,	
2017-07-20 17:54:29,020 Epoch[43] Batch [450]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089957,	
2017-07-20 17:54:33,560 Epoch[43] Batch [460]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090052,	
2017-07-20 17:54:37,949 Epoch[43] Batch [470]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090137,	
2017-07-20 17:54:42,633 Epoch[43] Batch [480]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090154,	
2017-07-20 17:54:47,233 Epoch[43] Batch [490]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090232,	
2017-07-20 17:54:51,295 Epoch[43] Batch [500]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.090164,	
2017-07-20 17:54:56,030 Epoch[43] Batch [510]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090130,	
2017-07-20 17:55:01,361 Epoch[43] Batch [520]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089942,	
2017-07-20 17:55:06,505 Epoch[43] Batch [530]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.089893,	
2017-07-20 17:55:11,691 Epoch[43] Batch [540]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089941,	
2017-07-20 17:55:16,997 Epoch[43] Batch [550]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089982,	
2017-07-20 17:55:22,093 Epoch[43] Batch [560]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.089879,	
2017-07-20 17:55:27,246 Epoch[43] Batch [570]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.089790,	
2017-07-20 17:55:31,753 Epoch[43] Batch [580]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089564,	
2017-07-20 17:55:36,547 Epoch[43] Batch [590]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089345,	
2017-07-20 17:55:41,483 Epoch[43] Batch [600]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089355,	
2017-07-20 17:55:46,185 Epoch[43] Batch [610]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089369,	
2017-07-20 17:55:51,125 Epoch[43] Batch [620]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089331,	
2017-07-20 17:55:55,628 Epoch[43] Batch [630]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089354,	
2017-07-20 17:56:00,354 Epoch[43] Batch [640]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089366,	
2017-07-20 17:56:05,362 Epoch[43] Batch [650]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089341,	
2017-07-20 17:56:09,910 Epoch[43] Batch [660]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089292,	
2017-07-20 17:56:14,543 Epoch[43] Batch [670]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089223,	
2017-07-20 17:56:19,059 Epoch[43] Batch [680]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089073,	
2017-07-20 17:56:23,755 Epoch[43] Batch [690]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089209,	
2017-07-20 17:56:28,192 Epoch[43] Batch [700]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.089191,	
2017-07-20 17:56:32,968 Epoch[43] Batch [710]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089210,	
2017-07-20 17:56:37,419 Epoch[43] Batch [720]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.089285,	
2017-07-20 17:56:42,936 Epoch[43] Batch [730]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.089164,	
2017-07-20 17:56:47,996 Epoch[43] Batch [740]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089239,	
2017-07-20 17:56:52,870 Epoch[43] Batch [750]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.089201,	
2017-07-20 17:56:57,858 Epoch[43] Batch [760]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089108,	
2017-07-20 17:57:02,594 Epoch[43] Batch [770]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089104,	
2017-07-20 17:57:07,442 Epoch[43] Batch [780]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088996,	
2017-07-20 17:57:12,282 Epoch[43] Batch [790]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088943,	
2017-07-20 17:57:17,030 Epoch[43] Batch [800]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089014,	
2017-07-20 17:57:21,765 Epoch[43] Batch [810]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088972,	
2017-07-20 17:57:26,763 Epoch[43] Batch [820]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089036,	
2017-07-20 17:57:31,887 Epoch[43] Batch [830]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.089085,	
2017-07-20 17:57:36,806 Epoch[43] Batch [840]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.089024,	
2017-07-20 17:57:41,744 Epoch[43] Batch [850]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089075,	
2017-07-20 17:57:46,605 Epoch[43] Batch [860]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089019,	
2017-07-20 17:57:51,092 Epoch[43] Batch [870]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088942,	
2017-07-20 17:57:55,748 Epoch[43] Batch [880]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088833,	
2017-07-20 17:58:00,262 Epoch[43] Batch [890]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088753,	
2017-07-20 17:58:05,078 Epoch[43] Batch [900]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088685,	
2017-07-20 17:58:09,703 Epoch[43] Batch [910]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.088727,	
2017-07-20 17:58:14,360 Epoch[43] Batch [920]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088656,	
2017-07-20 17:58:18,749 Epoch[43] Batch [930]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.088661,	
2017-07-20 17:58:23,099 Epoch[43] Batch [940]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.088603,	
2017-07-20 17:58:27,756 Epoch[43] Batch [950]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088610,	
2017-07-20 17:58:32,196 Epoch[43] Batch [960]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088537,	
2017-07-20 17:58:37,375 Epoch[43] Batch [970]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088516,	
2017-07-20 17:58:42,328 Epoch[43] Batch [980]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088580,	
2017-07-20 17:58:47,672 Epoch[43] Batch [990]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088498,	
2017-07-20 17:58:52,868 Epoch[43] Batch [1000]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088429,	
2017-07-20 17:58:58,685 Epoch[43] Batch [1010]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088403,	
2017-07-20 17:59:04,720 Epoch[43] Batch [1020]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088368,	
2017-07-20 17:59:10,106 Epoch[43] Batch [1030]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088271,	
2017-07-20 17:59:15,936 Epoch[43] Batch [1040]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.088234,	
2017-07-20 17:59:21,742 Epoch[43] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088336,	
2017-07-20 17:59:27,549 Epoch[43] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088302,	
2017-07-20 17:59:33,056 Epoch[43] Batch [1070]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088291,	
2017-07-20 17:59:38,715 Epoch[43] Batch [1080]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088299,	
2017-07-20 17:59:43,845 Epoch[43] Batch [1090]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088192,	
2017-07-20 17:59:48,587 Epoch[43] Batch [1100]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088209,	
2017-07-20 17:59:53,545 Epoch[43] Batch [1110]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088137,	
2017-07-20 17:59:58,768 Epoch[43] Batch [1120]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088129,	
2017-07-20 18:00:03,801 Epoch[43] Batch [1130]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088114,	
2017-07-20 18:00:09,057 Epoch[43] Batch [1140]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088101,	
2017-07-20 18:00:13,957 Epoch[43] Batch [1150]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088064,	
2017-07-20 18:00:19,061 Epoch[43] Batch [1160]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088071,	
2017-07-20 18:00:24,291 Epoch[43] Batch [1170]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088064,	
2017-07-20 18:00:29,600 Epoch[43] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088033,	
2017-07-20 18:00:34,843 Epoch[43] Batch [1190]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088030,	
2017-07-20 18:00:39,968 Epoch[43] Batch [1200]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088094,	
2017-07-20 18:00:44,864 Epoch[43] Batch [1210]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088094,	
2017-07-20 18:00:50,036 Epoch[43] Batch [1220]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.088100,	
2017-07-20 18:00:55,556 Epoch[43] Batch [1230]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087955,	
2017-07-20 18:01:01,098 Epoch[43] Batch [1240]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.087904,	
2017-07-20 18:01:06,168 Epoch[43] Batch [1250]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087933,	
2017-07-20 18:01:11,598 Epoch[43] Batch [1260]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.087882,	
2017-07-20 18:01:16,939 Epoch[43] Batch [1270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087843,	
2017-07-20 18:01:22,666 Epoch[43] Batch [1280]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087861,	
2017-07-20 18:01:28,654 Epoch[43] Batch [1290]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087841,	
2017-07-20 18:01:34,308 Epoch[43] Batch [1300]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.087909,	
2017-07-20 18:01:39,664 Epoch[43] Batch [1310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087850,	
2017-07-20 18:01:44,632 Epoch[43] Batch [1320]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087815,	
2017-07-20 18:01:49,795 Epoch[43] Batch [1330]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087859,	
2017-07-20 18:01:55,100 Epoch[43] Batch [1340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087880,	
2017-07-20 18:02:00,289 Epoch[43] Batch [1350]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.087840,	
2017-07-20 18:02:05,263 Epoch[43] Batch [1360]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087875,	
2017-07-20 18:02:10,451 Epoch[43] Batch [1370]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.087768,	
2017-07-20 18:02:15,770 Epoch[43] Batch [1380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087767,	
2017-07-20 18:02:21,202 Epoch[43] Batch [1390]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087741,	
2017-07-20 18:02:26,529 Epoch[43] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087772,	
2017-07-20 18:02:31,530 Epoch[43] Batch [1410]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087821,	
2017-07-20 18:02:36,689 Epoch[43] Batch [1420]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087842,	
2017-07-20 18:02:42,087 Epoch[43] Batch [1430]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087842,	
2017-07-20 18:02:47,132 Epoch[43] Batch [1440]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087857,	
2017-07-20 18:02:52,613 Epoch[43] Batch [1450]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088003,	
2017-07-20 18:02:57,995 Epoch[43] Batch [1460]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088082,	
2017-07-20 18:03:03,430 Epoch[43] Batch [1470]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088159,	
2017-07-20 18:03:08,838 Epoch[43] Batch [1480]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088227,	
2017-07-20 18:03:12,036 Epoch[43] Train-FCNLogLoss=0.088269
2017-07-20 18:03:12,036 Epoch[43] Time cost=733.510
2017-07-20 18:03:12,980 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0044.params"
2017-07-20 18:03:17,435 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0044.states"
2017-07-20 18:03:23,433 Epoch[44] Batch [10]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089407,	
2017-07-20 18:03:27,974 Epoch[44] Batch [20]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.093883,	
2017-07-20 18:03:32,164 Epoch[44] Batch [30]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.094730,	
2017-07-20 18:03:36,158 Epoch[44] Batch [40]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.090531,	
2017-07-20 18:03:40,239 Epoch[44] Batch [50]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.089133,	
2017-07-20 18:03:44,628 Epoch[44] Batch [60]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.089380,	
2017-07-20 18:03:49,679 Epoch[44] Batch [70]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088795,	
2017-07-20 18:03:54,672 Epoch[44] Batch [80]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088615,	
2017-07-20 18:03:59,706 Epoch[44] Batch [90]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088617,	
2017-07-20 18:04:04,932 Epoch[44] Batch [100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088395,	
2017-07-20 18:04:09,954 Epoch[44] Batch [110]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087930,	
2017-07-20 18:04:14,341 Epoch[44] Batch [120]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088016,	
2017-07-20 18:04:18,987 Epoch[44] Batch [130]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088082,	
2017-07-20 18:04:23,759 Epoch[44] Batch [140]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087684,	
2017-07-20 18:04:28,019 Epoch[44] Batch [150]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087266,	
2017-07-20 18:04:33,019 Epoch[44] Batch [160]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087497,	
2017-07-20 18:04:38,692 Epoch[44] Batch [170]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087455,	
2017-07-20 18:04:44,004 Epoch[44] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087015,	
2017-07-20 18:04:49,309 Epoch[44] Batch [190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087181,	
2017-07-20 18:04:54,729 Epoch[44] Batch [200]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.087042,	
2017-07-20 18:04:59,860 Epoch[44] Batch [210]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086987,	
2017-07-20 18:05:04,797 Epoch[44] Batch [220]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086376,	
2017-07-20 18:05:09,934 Epoch[44] Batch [230]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.085889,	
2017-07-20 18:05:15,291 Epoch[44] Batch [240]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.086118,	
2017-07-20 18:05:20,272 Epoch[44] Batch [250]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086433,	
2017-07-20 18:05:25,114 Epoch[44] Batch [260]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086046,	
2017-07-20 18:05:30,183 Epoch[44] Batch [270]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.085987,	
2017-07-20 18:05:35,098 Epoch[44] Batch [280]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.086273,	
2017-07-20 18:05:40,099 Epoch[44] Batch [290]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.086528,	
2017-07-20 18:05:45,204 Epoch[44] Batch [300]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086761,	
2017-07-20 18:05:50,160 Epoch[44] Batch [310]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.086430,	
2017-07-20 18:05:55,557 Epoch[44] Batch [320]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-20 18:06:00,965 Epoch[44] Batch [330]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.086588,	
2017-07-20 18:06:06,497 Epoch[44] Batch [340]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.086638,	
2017-07-20 18:06:11,815 Epoch[44] Batch [350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086442,	
2017-07-20 18:06:16,886 Epoch[44] Batch [360]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086309,	
2017-07-20 18:06:21,964 Epoch[44] Batch [370]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086265,	
2017-07-20 18:06:26,970 Epoch[44] Batch [380]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.086288,	
2017-07-20 18:06:31,960 Epoch[44] Batch [390]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086172,	
2017-07-20 18:06:37,180 Epoch[44] Batch [400]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086265,	
2017-07-20 18:06:42,031 Epoch[44] Batch [410]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086400,	
2017-07-20 18:06:47,146 Epoch[44] Batch [420]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086422,	
2017-07-20 18:06:52,319 Epoch[44] Batch [430]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086257,	
2017-07-20 18:06:57,441 Epoch[44] Batch [440]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086061,	
2017-07-20 18:07:02,515 Epoch[44] Batch [450]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.085905,	
2017-07-20 18:07:07,910 Epoch[44] Batch [460]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.085845,	
2017-07-20 18:07:13,175 Epoch[44] Batch [470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.085932,	
2017-07-20 18:07:18,428 Epoch[44] Batch [480]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086036,	
2017-07-20 18:07:23,319 Epoch[44] Batch [490]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086025,	
2017-07-20 18:07:28,353 Epoch[44] Batch [500]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086038,	
2017-07-20 18:07:33,441 Epoch[44] Batch [510]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.085979,	
2017-07-20 18:07:38,512 Epoch[44] Batch [520]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086052,	
2017-07-20 18:07:43,630 Epoch[44] Batch [530]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086118,	
2017-07-20 18:07:48,649 Epoch[44] Batch [540]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086018,	
2017-07-20 18:07:53,751 Epoch[44] Batch [550]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086017,	
2017-07-20 18:07:58,584 Epoch[44] Batch [560]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.086212,	
2017-07-20 18:08:03,595 Epoch[44] Batch [570]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.086407,	
2017-07-20 18:08:07,918 Epoch[44] Batch [580]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086256,	
2017-07-20 18:08:11,897 Epoch[44] Batch [590]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.086339,	
2017-07-20 18:08:15,995 Epoch[44] Batch [600]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.086432,	
2017-07-20 18:08:20,322 Epoch[44] Batch [610]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086406,	
2017-07-20 18:08:24,302 Epoch[44] Batch [620]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.086422,	
2017-07-20 18:08:28,306 Epoch[44] Batch [630]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.086346,	
2017-07-20 18:08:32,559 Epoch[44] Batch [640]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.086272,	
2017-07-20 18:08:36,788 Epoch[44] Batch [650]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.086264,	
2017-07-20 18:08:40,804 Epoch[44] Batch [660]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.086332,	
2017-07-20 18:08:44,911 Epoch[44] Batch [670]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.086323,	
2017-07-20 18:08:49,037 Epoch[44] Batch [680]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.086446,	
2017-07-20 18:08:53,070 Epoch[44] Batch [690]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.086358,	
2017-07-20 18:08:56,989 Epoch[44] Batch [700]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.086432,	
2017-07-20 18:09:01,165 Epoch[44] Batch [710]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-20 18:09:05,188 Epoch[44] Batch [720]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.086407,	
2017-07-20 18:09:09,274 Epoch[44] Batch [730]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.086346,	
2017-07-20 18:09:13,481 Epoch[44] Batch [740]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.086337,	
2017-07-20 18:09:17,565 Epoch[44] Batch [750]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.086420,	
2017-07-20 18:09:21,843 Epoch[44] Batch [760]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086488,	
2017-07-20 18:09:26,190 Epoch[44] Batch [770]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.086599,	
2017-07-20 18:09:30,515 Epoch[44] Batch [780]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-20 18:09:34,585 Epoch[44] Batch [790]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.086507,	
2017-07-20 18:09:38,685 Epoch[44] Batch [800]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.086615,	
2017-07-20 18:09:42,790 Epoch[44] Batch [810]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.086507,	
2017-07-20 18:09:46,918 Epoch[44] Batch [820]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.086531,	
2017-07-20 18:09:50,939 Epoch[44] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-20 18:09:55,177 Epoch[44] Batch [840]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.086539,	
2017-07-20 18:09:59,383 Epoch[44] Batch [850]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-20 18:10:03,396 Epoch[44] Batch [860]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.086448,	
2017-07-20 18:10:07,565 Epoch[44] Batch [870]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.086467,	
2017-07-20 18:10:11,573 Epoch[44] Batch [880]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.086559,	
2017-07-20 18:10:15,488 Epoch[44] Batch [890]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.086542,	
2017-07-20 18:10:19,698 Epoch[44] Batch [900]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086533,	
2017-07-20 18:10:23,864 Epoch[44] Batch [910]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.086633,	
2017-07-20 18:10:28,010 Epoch[44] Batch [920]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086653,	
2017-07-20 18:10:32,047 Epoch[44] Batch [930]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.086633,	
2017-07-20 18:10:36,154 Epoch[44] Batch [940]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.086623,	
2017-07-20 18:10:40,419 Epoch[44] Batch [950]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.086795,	
2017-07-20 18:10:44,483 Epoch[44] Batch [960]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.086899,	
2017-07-20 18:10:48,607 Epoch[44] Batch [970]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.086866,	
2017-07-20 18:10:52,818 Epoch[44] Batch [980]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086856,	
2017-07-20 18:10:56,772 Epoch[44] Batch [990]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.086845,	
2017-07-20 18:11:00,977 Epoch[44] Batch [1000]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.086735,	
2017-07-20 18:11:05,087 Epoch[44] Batch [1010]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.086770,	
2017-07-20 18:11:09,244 Epoch[44] Batch [1020]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.086780,	
2017-07-20 18:11:13,409 Epoch[44] Batch [1030]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.086775,	
2017-07-20 18:11:17,691 Epoch[44] Batch [1040]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.086871,	
2017-07-20 18:11:21,755 Epoch[44] Batch [1050]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.086851,	
2017-07-20 18:11:25,898 Epoch[44] Batch [1060]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.086846,	
2017-07-20 18:11:30,083 Epoch[44] Batch [1070]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.086795,	
2017-07-20 18:11:34,237 Epoch[44] Batch [1080]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.086812,	
2017-07-20 18:11:38,319 Epoch[44] Batch [1090]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.086812,	
2017-07-20 18:11:42,407 Epoch[44] Batch [1100]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.086699,	
2017-07-20 18:11:46,660 Epoch[44] Batch [1110]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.086704,	
2017-07-20 18:11:50,981 Epoch[44] Batch [1120]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086648,	
2017-07-20 18:11:55,349 Epoch[44] Batch [1130]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086668,	
2017-07-20 18:11:59,664 Epoch[44] Batch [1140]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086704,	
2017-07-20 18:12:04,051 Epoch[44] Batch [1150]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086802,	
2017-07-20 18:12:08,160 Epoch[44] Batch [1160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.086873,	
2017-07-20 18:12:12,283 Epoch[44] Batch [1170]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.086922,	
2017-07-20 18:12:16,564 Epoch[44] Batch [1180]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086905,	
2017-07-20 18:12:20,680 Epoch[44] Batch [1190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.086882,	
2017-07-20 18:12:24,825 Epoch[44] Batch [1200]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086853,	
2017-07-20 18:12:29,005 Epoch[44] Batch [1210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.086862,	
2017-07-20 18:12:33,196 Epoch[44] Batch [1220]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086785,	
2017-07-20 18:12:37,341 Epoch[44] Batch [1230]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086777,	
2017-07-20 18:12:41,302 Epoch[44] Batch [1240]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.086860,	
2017-07-20 18:12:45,595 Epoch[44] Batch [1250]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.086942,	
2017-07-20 18:12:50,102 Epoch[44] Batch [1260]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086974,	
2017-07-20 18:12:54,433 Epoch[44] Batch [1270]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087027,	
2017-07-20 18:12:59,037 Epoch[44] Batch [1280]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087023,	
2017-07-20 18:13:03,545 Epoch[44] Batch [1290]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.086942,	
2017-07-20 18:13:07,930 Epoch[44] Batch [1300]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086908,	
2017-07-20 18:13:12,084 Epoch[44] Batch [1310]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.086872,	
2017-07-20 18:13:16,236 Epoch[44] Batch [1320]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.086860,	
2017-07-20 18:13:20,411 Epoch[44] Batch [1330]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086847,	
2017-07-20 18:13:24,688 Epoch[44] Batch [1340]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.087018,	
2017-07-20 18:13:28,747 Epoch[44] Batch [1350]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.087042,	
2017-07-20 18:13:32,994 Epoch[44] Batch [1360]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087053,	
2017-07-20 18:13:37,007 Epoch[44] Batch [1370]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.087083,	
2017-07-20 18:13:41,225 Epoch[44] Batch [1380]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.087161,	
2017-07-20 18:13:45,292 Epoch[44] Batch [1390]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.087173,	
2017-07-20 18:13:49,780 Epoch[44] Batch [1400]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087134,	
2017-07-20 18:13:54,231 Epoch[44] Batch [1410]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087084,	
2017-07-20 18:13:58,612 Epoch[44] Batch [1420]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.087031,	
2017-07-20 18:14:03,109 Epoch[44] Batch [1430]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087055,	
2017-07-20 18:14:07,567 Epoch[44] Batch [1440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087097,	
2017-07-20 18:14:12,016 Epoch[44] Batch [1450]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087111,	
2017-07-20 18:14:16,510 Epoch[44] Batch [1460]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087095,	
2017-07-20 18:14:20,836 Epoch[44] Batch [1470]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087052,	
2017-07-20 18:14:25,390 Epoch[44] Batch [1480]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087047,	
2017-07-20 18:14:28,009 Epoch[44] Train-FCNLogLoss=0.087039
2017-07-20 18:14:28,010 Epoch[44] Time cost=670.574
2017-07-20 18:14:28,954 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0045.params"
2017-07-20 18:14:32,005 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0045.states"
2017-07-20 18:14:37,307 Epoch[45] Batch [10]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.079561,	
2017-07-20 18:14:41,856 Epoch[45] Batch [20]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.081889,	
2017-07-20 18:14:46,288 Epoch[45] Batch [30]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.084547,	
2017-07-20 18:14:50,654 Epoch[45] Batch [40]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.085998,	
2017-07-20 18:14:55,146 Epoch[45] Batch [50]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.084657,	
2017-07-20 18:14:59,484 Epoch[45] Batch [60]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.083312,	
2017-07-20 18:15:03,942 Epoch[45] Batch [70]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.083522,	
2017-07-20 18:15:08,182 Epoch[45] Batch [80]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.083753,	
2017-07-20 18:15:12,626 Epoch[45] Batch [90]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.083924,	
2017-07-20 18:15:16,889 Epoch[45] Batch [100]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.083472,	
2017-07-20 18:15:21,372 Epoch[45] Batch [110]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.084550,	
2017-07-20 18:15:25,796 Epoch[45] Batch [120]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.084537,	
2017-07-20 18:15:30,095 Epoch[45] Batch [130]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.084206,	
2017-07-20 18:15:34,559 Epoch[45] Batch [140]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.083953,	
2017-07-20 18:15:38,967 Epoch[45] Batch [150]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.084156,	
2017-07-20 18:15:43,402 Epoch[45] Batch [160]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.084593,	
2017-07-20 18:15:47,865 Epoch[45] Batch [170]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.084909,	
2017-07-20 18:15:52,269 Epoch[45] Batch [180]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.085268,	
2017-07-20 18:15:56,466 Epoch[45] Batch [190]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.085211,	
2017-07-20 18:16:00,858 Epoch[45] Batch [200]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.085203,	
2017-07-20 18:16:05,222 Epoch[45] Batch [210]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.085452,	
2017-07-20 18:16:09,673 Epoch[45] Batch [220]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.085406,	
2017-07-20 18:16:14,045 Epoch[45] Batch [230]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.085205,	
2017-07-20 18:16:18,460 Epoch[45] Batch [240]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.085019,	
2017-07-20 18:16:22,662 Epoch[45] Batch [250]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085065,	
2017-07-20 18:16:26,766 Epoch[45] Batch [260]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.084853,	
2017-07-20 18:16:30,873 Epoch[45] Batch [270]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084566,	
2017-07-20 18:16:34,966 Epoch[45] Batch [280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.084723,	
2017-07-20 18:16:39,149 Epoch[45] Batch [290]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.084779,	
2017-07-20 18:16:43,412 Epoch[45] Batch [300]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.085096,	
2017-07-20 18:16:47,559 Epoch[45] Batch [310]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085073,	
2017-07-20 18:16:51,631 Epoch[45] Batch [320]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.085070,	
2017-07-20 18:16:55,825 Epoch[45] Batch [330]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.085060,	
2017-07-20 18:17:00,109 Epoch[45] Batch [340]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.085149,	
2017-07-20 18:17:04,333 Epoch[45] Batch [350]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.085220,	
2017-07-20 18:17:08,290 Epoch[45] Batch [360]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.085362,	
2017-07-20 18:17:12,528 Epoch[45] Batch [370]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.085391,	
2017-07-20 18:17:16,717 Epoch[45] Batch [380]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.085516,	
2017-07-20 18:17:20,932 Epoch[45] Batch [390]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.085734,	
2017-07-20 18:17:25,134 Epoch[45] Batch [400]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085759,	
2017-07-20 18:17:29,186 Epoch[45] Batch [410]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.085752,	
2017-07-20 18:17:33,321 Epoch[45] Batch [420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.085526,	
2017-07-20 18:17:37,593 Epoch[45] Batch [430]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.085516,	
2017-07-20 18:17:41,773 Epoch[45] Batch [440]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.085650,	
2017-07-20 18:17:45,945 Epoch[45] Batch [450]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.085727,	
2017-07-20 18:17:50,089 Epoch[45] Batch [460]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085527,	
2017-07-20 18:17:54,333 Epoch[45] Batch [470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.085663,	
2017-07-20 18:17:58,502 Epoch[45] Batch [480]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.085698,	
2017-07-20 18:18:02,575 Epoch[45] Batch [490]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.085787,	
2017-07-20 18:18:06,821 Epoch[45] Batch [500]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.086016,	
2017-07-20 18:18:11,005 Epoch[45] Batch [510]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.085926,	
2017-07-20 18:18:15,371 Epoch[45] Batch [520]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086274,	
2017-07-20 18:18:19,538 Epoch[45] Batch [530]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.086694,	
2017-07-20 18:18:23,808 Epoch[45] Batch [540]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.086838,	
2017-07-20 18:18:27,982 Epoch[45] Batch [550]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086873,	
2017-07-20 18:18:32,118 Epoch[45] Batch [560]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087096,	
2017-07-20 18:18:36,460 Epoch[45] Batch [570]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.087216,	
2017-07-20 18:18:40,556 Epoch[45] Batch [580]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.087252,	
2017-07-20 18:18:45,048 Epoch[45] Batch [590]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087467,	
2017-07-20 18:18:49,396 Epoch[45] Batch [600]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087471,	
2017-07-20 18:18:53,763 Epoch[45] Batch [610]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087560,	
2017-07-20 18:18:58,268 Epoch[45] Batch [620]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087549,	
2017-07-20 18:19:02,695 Epoch[45] Batch [630]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087498,	
2017-07-20 18:19:07,088 Epoch[45] Batch [640]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087624,	
2017-07-20 18:19:11,355 Epoch[45] Batch [650]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.087563,	
2017-07-20 18:19:15,593 Epoch[45] Batch [660]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087499,	
2017-07-20 18:19:19,767 Epoch[45] Batch [670]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.087485,	
2017-07-20 18:19:23,843 Epoch[45] Batch [680]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.087640,	
2017-07-20 18:19:27,928 Epoch[45] Batch [690]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087757,	
2017-07-20 18:19:32,094 Epoch[45] Batch [700]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.087714,	
2017-07-20 18:19:36,167 Epoch[45] Batch [710]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.087658,	
2017-07-20 18:19:40,183 Epoch[45] Batch [720]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.087501,	
2017-07-20 18:19:44,268 Epoch[45] Batch [730]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087407,	
2017-07-20 18:19:48,450 Epoch[45] Batch [740]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.087412,	
2017-07-20 18:19:52,681 Epoch[45] Batch [750]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087346,	
2017-07-20 18:19:56,900 Epoch[45] Batch [760]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087390,	
2017-07-20 18:20:01,396 Epoch[45] Batch [770]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087412,	
2017-07-20 18:20:05,736 Epoch[45] Batch [780]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087304,	
2017-07-20 18:20:10,035 Epoch[45] Batch [790]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087351,	
2017-07-20 18:20:14,350 Epoch[45] Batch [800]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087165,	
2017-07-20 18:20:18,626 Epoch[45] Batch [810]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087240,	
2017-07-20 18:20:22,948 Epoch[45] Batch [820]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087254,	
2017-07-20 18:20:27,330 Epoch[45] Batch [830]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.087196,	
2017-07-20 18:20:31,618 Epoch[45] Batch [840]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087328,	
2017-07-20 18:20:35,910 Epoch[45] Batch [850]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.087391,	
2017-07-20 18:20:40,151 Epoch[45] Batch [860]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087414,	
2017-07-20 18:20:44,462 Epoch[45] Batch [870]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.087392,	
2017-07-20 18:20:48,593 Epoch[45] Batch [880]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087383,	
2017-07-20 18:20:52,823 Epoch[45] Batch [890]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087402,	
2017-07-20 18:20:57,033 Epoch[45] Batch [900]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.087590,	
2017-07-20 18:21:01,288 Epoch[45] Batch [910]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.087584,	
2017-07-20 18:21:05,726 Epoch[45] Batch [920]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087563,	
2017-07-20 18:21:10,285 Epoch[45] Batch [930]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087584,	
2017-07-20 18:21:14,748 Epoch[45] Batch [940]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087594,	
2017-07-20 18:21:19,128 Epoch[45] Batch [950]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.087590,	
2017-07-20 18:21:23,637 Epoch[45] Batch [960]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087557,	
2017-07-20 18:21:28,104 Epoch[45] Batch [970]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087608,	
2017-07-20 18:21:32,507 Epoch[45] Batch [980]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087495,	
2017-07-20 18:21:37,034 Epoch[45] Batch [990]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087453,	
2017-07-20 18:21:41,411 Epoch[45] Batch [1000]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087487,	
2017-07-20 18:21:45,956 Epoch[45] Batch [1010]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087508,	
2017-07-20 18:21:50,531 Epoch[45] Batch [1020]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087479,	
2017-07-20 18:21:54,897 Epoch[45] Batch [1030]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087520,	
2017-07-20 18:21:59,217 Epoch[45] Batch [1040]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087437,	
2017-07-20 18:22:04,181 Epoch[45] Batch [1050]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.087531,	
2017-07-20 18:22:08,705 Epoch[45] Batch [1060]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087483,	
2017-07-20 18:22:13,206 Epoch[45] Batch [1070]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087521,	
2017-07-20 18:22:17,798 Epoch[45] Batch [1080]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087524,	
2017-07-20 18:22:22,065 Epoch[45] Batch [1090]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087501,	
2017-07-20 18:22:26,568 Epoch[45] Batch [1100]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087570,	
2017-07-20 18:22:31,069 Epoch[45] Batch [1110]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087618,	
2017-07-20 18:22:35,568 Epoch[45] Batch [1120]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087697,	
2017-07-20 18:22:40,084 Epoch[45] Batch [1130]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087804,	
2017-07-20 18:22:44,626 Epoch[45] Batch [1140]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087729,	
2017-07-20 18:22:49,236 Epoch[45] Batch [1150]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.087797,	
2017-07-20 18:22:53,607 Epoch[45] Batch [1160]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087728,	
2017-07-20 18:22:58,142 Epoch[45] Batch [1170]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087687,	
2017-07-20 18:23:02,497 Epoch[45] Batch [1180]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087690,	
2017-07-20 18:23:06,892 Epoch[45] Batch [1190]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087761,	
2017-07-20 18:23:11,640 Epoch[45] Batch [1200]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087784,	
2017-07-20 18:23:15,980 Epoch[45] Batch [1210]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087747,	
2017-07-20 18:23:20,471 Epoch[45] Batch [1220]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087750,	
2017-07-20 18:23:24,765 Epoch[45] Batch [1230]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.087731,	
2017-07-20 18:23:29,092 Epoch[45] Batch [1240]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087694,	
2017-07-20 18:23:33,493 Epoch[45] Batch [1250]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087665,	
2017-07-20 18:23:37,779 Epoch[45] Batch [1260]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087629,	
2017-07-20 18:23:42,242 Epoch[45] Batch [1270]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087536,	
2017-07-20 18:23:46,816 Epoch[45] Batch [1280]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087538,	
2017-07-20 18:23:51,356 Epoch[45] Batch [1290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087471,	
2017-07-20 18:23:56,095 Epoch[45] Batch [1300]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087411,	
2017-07-20 18:24:00,622 Epoch[45] Batch [1310]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087389,	
2017-07-20 18:24:05,116 Epoch[45] Batch [1320]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087410,	
2017-07-20 18:24:09,818 Epoch[45] Batch [1330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087496,	
2017-07-20 18:24:14,363 Epoch[45] Batch [1340]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087428,	
2017-07-20 18:24:18,731 Epoch[45] Batch [1350]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087399,	
2017-07-20 18:24:23,318 Epoch[45] Batch [1360]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087328,	
2017-07-20 18:24:27,578 Epoch[45] Batch [1370]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087331,	
2017-07-20 18:24:31,865 Epoch[45] Batch [1380]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087308,	
2017-07-20 18:24:36,322 Epoch[45] Batch [1390]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087275,	
2017-07-20 18:24:40,748 Epoch[45] Batch [1400]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087236,	
2017-07-20 18:24:45,047 Epoch[45] Batch [1410]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087207,	
2017-07-20 18:24:49,534 Epoch[45] Batch [1420]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087245,	
2017-07-20 18:24:54,042 Epoch[45] Batch [1430]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087268,	
2017-07-20 18:24:58,721 Epoch[45] Batch [1440]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087292,	
2017-07-20 18:25:03,178 Epoch[45] Batch [1450]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087674,	
2017-07-20 18:25:07,655 Epoch[45] Batch [1460]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087760,	
2017-07-20 18:25:12,026 Epoch[45] Batch [1470]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087856,	
2017-07-20 18:25:16,412 Epoch[45] Batch [1480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087911,	
2017-07-20 18:25:19,116 Epoch[45] Train-FCNLogLoss=0.087927
2017-07-20 18:25:19,117 Epoch[45] Time cost=647.111
2017-07-20 18:25:19,988 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0046.params"
2017-07-20 18:25:21,923 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0046.states"
2017-07-20 18:25:27,284 Epoch[46] Batch [10]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.082977,	
2017-07-20 18:25:31,829 Epoch[46] Batch [20]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.083562,	
2017-07-20 18:25:36,335 Epoch[46] Batch [30]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.084229,	
2017-07-20 18:25:40,631 Epoch[46] Batch [40]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.083421,	
2017-07-20 18:25:45,174 Epoch[46] Batch [50]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.085302,	
2017-07-20 18:25:49,738 Epoch[46] Batch [60]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.084938,	
2017-07-20 18:25:54,101 Epoch[46] Batch [70]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.084434,	
2017-07-20 18:25:58,578 Epoch[46] Batch [80]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.085518,	
2017-07-20 18:26:03,052 Epoch[46] Batch [90]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.085318,	
2017-07-20 18:26:07,633 Epoch[46] Batch [100]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.085273,	
2017-07-20 18:26:12,140 Epoch[46] Batch [110]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.085947,	
2017-07-20 18:26:16,416 Epoch[46] Batch [120]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.086016,	
2017-07-20 18:26:20,814 Epoch[46] Batch [130]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.085897,	
2017-07-20 18:26:25,079 Epoch[46] Batch [140]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.085975,	
2017-07-20 18:26:29,383 Epoch[46] Batch [150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.086866,	
2017-07-20 18:26:33,857 Epoch[46] Batch [160]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.086801,	
2017-07-20 18:26:38,523 Epoch[46] Batch [170]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.086920,	
2017-07-20 18:26:43,102 Epoch[46] Batch [180]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087163,	
2017-07-20 18:26:47,585 Epoch[46] Batch [190]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086692,	
2017-07-20 18:26:52,111 Epoch[46] Batch [200]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-20 18:26:56,535 Epoch[46] Batch [210]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086504,	
2017-07-20 18:27:00,963 Epoch[46] Batch [220]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.086552,	
2017-07-20 18:27:05,339 Epoch[46] Batch [230]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.086694,	
2017-07-20 18:27:10,291 Epoch[46] Batch [240]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087182,	
2017-07-20 18:27:14,921 Epoch[46] Batch [250]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087542,	
2017-07-20 18:27:19,599 Epoch[46] Batch [260]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087561,	
2017-07-20 18:27:24,200 Epoch[46] Batch [270]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087389,	
2017-07-20 18:27:28,635 Epoch[46] Batch [280]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087307,	
2017-07-20 18:27:33,176 Epoch[46] Batch [290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087106,	
2017-07-20 18:27:37,624 Epoch[46] Batch [300]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087014,	
2017-07-20 18:27:42,094 Epoch[46] Batch [310]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086970,	
2017-07-20 18:27:46,602 Epoch[46] Batch [320]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086896,	
2017-07-20 18:27:51,095 Epoch[46] Batch [330]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087073,	
2017-07-20 18:27:55,596 Epoch[46] Batch [340]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.086992,	
2017-07-20 18:28:00,074 Epoch[46] Batch [350]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087031,	
2017-07-20 18:28:04,528 Epoch[46] Batch [360]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087149,	
2017-07-20 18:28:09,057 Epoch[46] Batch [370]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087237,	
2017-07-20 18:28:13,423 Epoch[46] Batch [380]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086974,	
2017-07-20 18:28:17,901 Epoch[46] Batch [390]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087129,	
2017-07-20 18:28:22,324 Epoch[46] Batch [400]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086990,	
2017-07-20 18:28:26,677 Epoch[46] Batch [410]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086757,	
2017-07-20 18:28:31,142 Epoch[46] Batch [420]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.086778,	
2017-07-20 18:28:35,836 Epoch[46] Batch [430]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086830,	
2017-07-20 18:28:40,312 Epoch[46] Batch [440]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.086961,	
2017-07-20 18:28:44,775 Epoch[46] Batch [450]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.086985,	
2017-07-20 18:28:49,219 Epoch[46] Batch [460]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087184,	
2017-07-20 18:28:53,715 Epoch[46] Batch [470]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087204,	
2017-07-20 18:28:58,028 Epoch[46] Batch [480]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087091,	
2017-07-20 18:29:02,223 Epoch[46] Batch [490]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.087069,	
2017-07-20 18:29:06,901 Epoch[46] Batch [500]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.086989,	
2017-07-20 18:29:11,512 Epoch[46] Batch [510]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086894,	
2017-07-20 18:29:16,150 Epoch[46] Batch [520]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086942,	
2017-07-20 18:29:20,520 Epoch[46] Batch [530]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.086736,	
2017-07-20 18:29:24,716 Epoch[46] Batch [540]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.086699,	
2017-07-20 18:29:29,255 Epoch[46] Batch [550]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.086763,	
2017-07-20 18:29:33,732 Epoch[46] Batch [560]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086835,	
2017-07-20 18:29:38,672 Epoch[46] Batch [570]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086967,	
2017-07-20 18:29:43,293 Epoch[46] Batch [580]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087014,	
2017-07-20 18:29:47,940 Epoch[46] Batch [590]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.086931,	
2017-07-20 18:29:52,299 Epoch[46] Batch [600]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086933,	
2017-07-20 18:29:56,601 Epoch[46] Batch [610]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.086965,	
2017-07-20 18:30:01,112 Epoch[46] Batch [620]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087135,	
2017-07-20 18:30:05,578 Epoch[46] Batch [630]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087098,	
2017-07-20 18:30:10,148 Epoch[46] Batch [640]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087130,	
2017-07-20 18:30:14,651 Epoch[46] Batch [650]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087018,	
2017-07-20 18:30:19,231 Epoch[46] Batch [660]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086963,	
2017-07-20 18:30:23,758 Epoch[46] Batch [670]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087015,	
2017-07-20 18:30:28,221 Epoch[46] Batch [680]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.086822,	
2017-07-20 18:30:32,481 Epoch[46] Batch [690]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086900,	
2017-07-20 18:30:37,216 Epoch[46] Batch [700]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.086889,	
2017-07-20 18:30:41,748 Epoch[46] Batch [710]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.086917,	
2017-07-20 18:30:46,248 Epoch[46] Batch [720]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.086920,	
2017-07-20 18:30:50,616 Epoch[46] Batch [730]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087048,	
2017-07-20 18:30:55,027 Epoch[46] Batch [740]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087076,	
2017-07-20 18:30:59,403 Epoch[46] Batch [750]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087016,	
2017-07-20 18:31:03,820 Epoch[46] Batch [760]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.086999,	
2017-07-20 18:31:08,278 Epoch[46] Batch [770]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087042,	
2017-07-20 18:31:12,822 Epoch[46] Batch [780]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.086993,	
2017-07-20 18:31:17,022 Epoch[46] Batch [790]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.086969,	
2017-07-20 18:31:21,288 Epoch[46] Batch [800]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.086948,	
2017-07-20 18:31:25,614 Epoch[46] Batch [810]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086901,	
2017-07-20 18:31:30,069 Epoch[46] Batch [820]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.086902,	
2017-07-20 18:31:34,596 Epoch[46] Batch [830]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086795,	
2017-07-20 18:31:39,118 Epoch[46] Batch [840]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086808,	
2017-07-20 18:31:43,567 Epoch[46] Batch [850]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.086700,	
2017-07-20 18:31:48,208 Epoch[46] Batch [860]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086762,	
2017-07-20 18:31:52,701 Epoch[46] Batch [870]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.086871,	
2017-07-20 18:31:57,086 Epoch[46] Batch [880]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086815,	
2017-07-20 18:32:01,668 Epoch[46] Batch [890]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086737,	
2017-07-20 18:32:06,187 Epoch[46] Batch [900]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086742,	
2017-07-20 18:32:10,613 Epoch[46] Batch [910]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086694,	
2017-07-20 18:32:14,961 Epoch[46] Batch [920]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.086686,	
2017-07-20 18:32:19,443 Epoch[46] Batch [930]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086670,	
2017-07-20 18:32:24,204 Epoch[46] Batch [940]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086709,	
2017-07-20 18:32:28,684 Epoch[46] Batch [950]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086731,	
2017-07-20 18:32:33,245 Epoch[46] Batch [960]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086733,	
2017-07-20 18:32:37,657 Epoch[46] Batch [970]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.086689,	
2017-07-20 18:32:42,096 Epoch[46] Batch [980]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-20 18:32:46,451 Epoch[46] Batch [990]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086765,	
2017-07-20 18:32:51,070 Epoch[46] Batch [1000]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.086831,	
2017-07-20 18:32:55,479 Epoch[46] Batch [1010]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.086724,	
2017-07-20 18:32:59,856 Epoch[46] Batch [1020]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.086789,	
2017-07-20 18:33:04,310 Epoch[46] Batch [1030]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.086797,	
2017-07-20 18:33:08,844 Epoch[46] Batch [1040]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.086724,	
2017-07-20 18:33:13,467 Epoch[46] Batch [1050]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086697,	
2017-07-20 18:33:17,762 Epoch[46] Batch [1060]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.086634,	
2017-07-20 18:33:22,181 Epoch[46] Batch [1070]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.086655,	
2017-07-20 18:33:26,413 Epoch[46] Batch [1080]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.086642,	
2017-07-20 18:33:30,919 Epoch[46] Batch [1090]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086696,	
2017-07-20 18:33:35,441 Epoch[46] Batch [1100]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086626,	
2017-07-20 18:33:40,095 Epoch[46] Batch [1110]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086602,	
2017-07-20 18:33:44,792 Epoch[46] Batch [1120]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086582,	
2017-07-20 18:33:49,318 Epoch[46] Batch [1130]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086613,	
2017-07-20 18:33:53,682 Epoch[46] Batch [1140]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.086506,	
2017-07-20 18:33:58,164 Epoch[46] Batch [1150]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086471,	
2017-07-20 18:34:02,709 Epoch[46] Batch [1160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.086404,	
2017-07-20 18:34:07,185 Epoch[46] Batch [1170]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.086421,	
2017-07-20 18:34:11,566 Epoch[46] Batch [1180]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.086361,	
2017-07-20 18:34:15,882 Epoch[46] Batch [1190]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086312,	
2017-07-20 18:34:20,469 Epoch[46] Batch [1200]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.086199,	
2017-07-20 18:34:24,804 Epoch[46] Batch [1210]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086226,	
2017-07-20 18:34:29,255 Epoch[46] Batch [1220]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.086252,	
2017-07-20 18:34:33,773 Epoch[46] Batch [1230]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086262,	
2017-07-20 18:34:38,180 Epoch[46] Batch [1240]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.086281,	
2017-07-20 18:34:42,862 Epoch[46] Batch [1250]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-20 18:34:47,350 Epoch[46] Batch [1260]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.086285,	
2017-07-20 18:34:51,907 Epoch[46] Batch [1270]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086277,	
2017-07-20 18:34:56,545 Epoch[46] Batch [1280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086322,	
2017-07-20 18:35:00,878 Epoch[46] Batch [1290]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086297,	
2017-07-20 18:35:05,263 Epoch[46] Batch [1300]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086336,	
2017-07-20 18:35:09,721 Epoch[46] Batch [1310]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.086324,	
2017-07-20 18:35:14,380 Epoch[46] Batch [1320]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.086314,	
2017-07-20 18:35:18,857 Epoch[46] Batch [1330]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086259,	
2017-07-20 18:35:23,238 Epoch[46] Batch [1340]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.086207,	
2017-07-20 18:35:27,733 Epoch[46] Batch [1350]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.086176,	
2017-07-20 18:35:32,333 Epoch[46] Batch [1360]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.086169,	
2017-07-20 18:35:36,585 Epoch[46] Batch [1370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.086201,	
2017-07-20 18:35:41,078 Epoch[46] Batch [1380]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.086390,	
2017-07-20 18:35:45,463 Epoch[46] Batch [1390]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086471,	
2017-07-20 18:35:50,044 Epoch[46] Batch [1400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086539,	
2017-07-20 18:35:54,784 Epoch[46] Batch [1410]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.086573,	
2017-07-20 18:35:59,394 Epoch[46] Batch [1420]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.086603,	
2017-07-20 18:36:03,863 Epoch[46] Batch [1430]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086594,	
2017-07-20 18:36:08,465 Epoch[46] Batch [1440]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.086602,	
2017-07-20 18:36:12,899 Epoch[46] Batch [1450]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-20 18:36:17,470 Epoch[46] Batch [1460]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.086638,	
2017-07-20 18:36:22,050 Epoch[46] Batch [1470]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086660,	
2017-07-20 18:36:26,410 Epoch[46] Batch [1480]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086711,	
2017-07-20 18:36:29,048 Epoch[46] Train-FCNLogLoss=0.086697
2017-07-20 18:36:29,049 Epoch[46] Time cost=667.125
2017-07-20 18:36:30,027 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0047.params"
2017-07-20 18:36:31,884 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0047.states"
2017-07-20 18:36:37,374 Epoch[47] Batch [10]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.076103,	
2017-07-20 18:36:41,993 Epoch[47] Batch [20]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089552,	
2017-07-20 18:36:46,364 Epoch[47] Batch [30]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.092365,	
2017-07-20 18:36:51,008 Epoch[47] Batch [40]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090555,	
2017-07-20 18:36:55,527 Epoch[47] Batch [50]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088171,	
2017-07-20 18:37:00,196 Epoch[47] Batch [60]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089598,	
2017-07-20 18:37:04,792 Epoch[47] Batch [70]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090736,	
2017-07-20 18:37:09,200 Epoch[47] Batch [80]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089816,	
2017-07-20 18:37:13,548 Epoch[47] Batch [90]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.088850,	
2017-07-20 18:37:17,830 Epoch[47] Batch [100]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.089232,	
2017-07-20 18:37:22,360 Epoch[47] Batch [110]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088450,	
2017-07-20 18:37:26,898 Epoch[47] Batch [120]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.089126,	
2017-07-20 18:37:31,325 Epoch[47] Batch [130]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.089505,	
2017-07-20 18:37:35,969 Epoch[47] Batch [140]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089120,	
2017-07-20 18:37:40,369 Epoch[47] Batch [150]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089577,	
2017-07-20 18:37:44,844 Epoch[47] Batch [160]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.089236,	
2017-07-20 18:37:49,317 Epoch[47] Batch [170]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.089463,	
2017-07-20 18:37:53,975 Epoch[47] Batch [180]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089351,	
2017-07-20 18:37:58,525 Epoch[47] Batch [190]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089110,	
2017-07-20 18:38:03,061 Epoch[47] Batch [200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088583,	
2017-07-20 18:38:07,424 Epoch[47] Batch [210]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.088538,	
2017-07-20 18:38:11,975 Epoch[47] Batch [220]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088569,	
2017-07-20 18:38:16,385 Epoch[47] Batch [230]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088068,	
2017-07-20 18:38:20,882 Epoch[47] Batch [240]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087732,	
2017-07-20 18:38:25,236 Epoch[47] Batch [250]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088333,	
2017-07-20 18:38:29,702 Epoch[47] Batch [260]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088043,	
2017-07-20 18:38:34,217 Epoch[47] Batch [270]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088051,	
2017-07-20 18:38:38,884 Epoch[47] Batch [280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088259,	
2017-07-20 18:38:43,481 Epoch[47] Batch [290]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088347,	
2017-07-20 18:38:48,162 Epoch[47] Batch [300]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088422,	
2017-07-20 18:38:52,826 Epoch[47] Batch [310]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088254,	
2017-07-20 18:38:57,244 Epoch[47] Batch [320]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.088367,	
2017-07-20 18:39:01,847 Epoch[47] Batch [330]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088517,	
2017-07-20 18:39:06,281 Epoch[47] Batch [340]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088241,	
2017-07-20 18:39:11,088 Epoch[47] Batch [350]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088352,	
2017-07-20 18:39:15,649 Epoch[47] Batch [360]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088231,	
2017-07-20 18:39:20,353 Epoch[47] Batch [370]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088035,	
2017-07-20 18:39:24,922 Epoch[47] Batch [380]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087998,	
2017-07-20 18:39:29,581 Epoch[47] Batch [390]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.087885,	
2017-07-20 18:39:34,038 Epoch[47] Batch [400]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.088000,	
2017-07-20 18:39:38,399 Epoch[47] Batch [410]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087855,	
2017-07-20 18:39:43,283 Epoch[47] Batch [420]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.087827,	
2017-07-20 18:39:47,840 Epoch[47] Batch [430]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087715,	
2017-07-20 18:39:52,274 Epoch[47] Batch [440]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087737,	
2017-07-20 18:39:56,775 Epoch[47] Batch [450]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087865,	
2017-07-20 18:40:01,163 Epoch[47] Batch [460]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087904,	
2017-07-20 18:40:05,708 Epoch[47] Batch [470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087863,	
2017-07-20 18:40:10,201 Epoch[47] Batch [480]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087906,	
2017-07-20 18:40:14,671 Epoch[47] Batch [490]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087876,	
2017-07-20 18:40:19,220 Epoch[47] Batch [500]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087917,	
2017-07-20 18:40:23,871 Epoch[47] Batch [510]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088010,	
2017-07-20 18:40:28,248 Epoch[47] Batch [520]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.088158,	
2017-07-20 18:40:32,650 Epoch[47] Batch [530]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088210,	
2017-07-20 18:40:37,200 Epoch[47] Batch [540]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088154,	
2017-07-20 18:40:41,585 Epoch[47] Batch [550]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088207,	
2017-07-20 18:40:46,315 Epoch[47] Batch [560]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088189,	
2017-07-20 18:40:50,790 Epoch[47] Batch [570]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.088107,	
2017-07-20 18:40:55,243 Epoch[47] Batch [580]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087918,	
2017-07-20 18:40:59,742 Epoch[47] Batch [590]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087821,	
2017-07-20 18:41:04,256 Epoch[47] Batch [600]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087780,	
2017-07-20 18:41:08,897 Epoch[47] Batch [610]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087904,	
2017-07-20 18:41:13,381 Epoch[47] Batch [620]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087779,	
2017-07-20 18:41:18,011 Epoch[47] Batch [630]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087778,	
2017-07-20 18:41:22,494 Epoch[47] Batch [640]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087634,	
2017-07-20 18:41:27,068 Epoch[47] Batch [650]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087621,	
2017-07-20 18:41:31,398 Epoch[47] Batch [660]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087586,	
2017-07-20 18:41:35,930 Epoch[47] Batch [670]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087490,	
2017-07-20 18:41:40,235 Epoch[47] Batch [680]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087475,	
2017-07-20 18:41:44,648 Epoch[47] Batch [690]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087502,	
2017-07-20 18:41:49,324 Epoch[47] Batch [700]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087495,	
2017-07-20 18:41:53,812 Epoch[47] Batch [710]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087514,	
2017-07-20 18:41:57,894 Epoch[47] Batch [720]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.087349,	
2017-07-20 18:42:02,504 Epoch[47] Batch [730]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087350,	
2017-07-20 18:42:06,880 Epoch[47] Batch [740]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087314,	
2017-07-20 18:42:11,488 Epoch[47] Batch [750]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.087194,	
2017-07-20 18:42:15,982 Epoch[47] Batch [760]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087195,	
2017-07-20 18:42:20,590 Epoch[47] Batch [770]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.087186,	
2017-07-20 18:42:24,965 Epoch[47] Batch [780]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087034,	
2017-07-20 18:42:29,296 Epoch[47] Batch [790]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.086985,	
2017-07-20 18:42:33,969 Epoch[47] Batch [800]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.086876,	
2017-07-20 18:42:38,603 Epoch[47] Batch [810]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086868,	
2017-07-20 18:42:43,253 Epoch[47] Batch [820]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086868,	
2017-07-20 18:42:47,818 Epoch[47] Batch [830]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.086782,	
2017-07-20 18:42:52,756 Epoch[47] Batch [840]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086641,	
2017-07-20 18:42:57,033 Epoch[47] Batch [850]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086651,	
2017-07-20 18:43:01,225 Epoch[47] Batch [860]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086669,	
2017-07-20 18:43:05,644 Epoch[47] Batch [870]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.086589,	
2017-07-20 18:43:09,955 Epoch[47] Batch [880]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.086591,	
2017-07-20 18:43:14,354 Epoch[47] Batch [890]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.086598,	
2017-07-20 18:43:18,735 Epoch[47] Batch [900]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.086580,	
2017-07-20 18:43:23,093 Epoch[47] Batch [910]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086523,	
2017-07-20 18:43:27,470 Epoch[47] Batch [920]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.086370,	
2017-07-20 18:43:31,939 Epoch[47] Batch [930]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086385,	
2017-07-20 18:43:36,490 Epoch[47] Batch [940]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086421,	
2017-07-20 18:43:40,951 Epoch[47] Batch [950]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.086514,	
2017-07-20 18:43:45,375 Epoch[47] Batch [960]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086498,	
2017-07-20 18:43:49,813 Epoch[47] Batch [970]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.086541,	
2017-07-20 18:43:54,304 Epoch[47] Batch [980]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.086527,	
2017-07-20 18:43:58,576 Epoch[47] Batch [990]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.086485,	
2017-07-20 18:44:02,968 Epoch[47] Batch [1000]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.086406,	
2017-07-20 18:44:07,485 Epoch[47] Batch [1010]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086459,	
2017-07-20 18:44:11,997 Epoch[47] Batch [1020]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.086423,	
2017-07-20 18:44:16,521 Epoch[47] Batch [1030]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086356,	
2017-07-20 18:44:20,888 Epoch[47] Batch [1040]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086375,	
2017-07-20 18:44:25,509 Epoch[47] Batch [1050]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.086404,	
2017-07-20 18:44:30,192 Epoch[47] Batch [1060]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.086379,	
2017-07-20 18:44:34,676 Epoch[47] Batch [1070]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086362,	
2017-07-20 18:44:39,113 Epoch[47] Batch [1080]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.086302,	
2017-07-20 18:44:43,374 Epoch[47] Batch [1090]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086279,	
2017-07-20 18:44:47,697 Epoch[47] Batch [1100]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086269,	
2017-07-20 18:44:52,273 Epoch[47] Batch [1110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.086223,	
2017-07-20 18:44:57,053 Epoch[47] Batch [1120]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086186,	
2017-07-20 18:45:01,415 Epoch[47] Batch [1130]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.086260,	
2017-07-20 18:45:05,850 Epoch[47] Batch [1140]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.086231,	
2017-07-20 18:45:10,229 Epoch[47] Batch [1150]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.086218,	
2017-07-20 18:45:14,772 Epoch[47] Batch [1160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.086196,	
2017-07-20 18:45:19,398 Epoch[47] Batch [1170]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086153,	
2017-07-20 18:45:23,788 Epoch[47] Batch [1180]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.086171,	
2017-07-20 18:45:28,103 Epoch[47] Batch [1190]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086179,	
2017-07-20 18:45:32,696 Epoch[47] Batch [1200]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.086127,	
2017-07-20 18:45:37,182 Epoch[47] Batch [1210]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086111,	
2017-07-20 18:45:41,607 Epoch[47] Batch [1220]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086135,	
2017-07-20 18:45:46,071 Epoch[47] Batch [1230]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.086079,	
2017-07-20 18:45:50,768 Epoch[47] Batch [1240]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086124,	
2017-07-20 18:45:55,411 Epoch[47] Batch [1250]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086041,	
2017-07-20 18:45:59,979 Epoch[47] Batch [1260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.086089,	
2017-07-20 18:46:04,954 Epoch[47] Batch [1270]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.086031,	
2017-07-20 18:46:09,908 Epoch[47] Batch [1280]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.086028,	
2017-07-20 18:46:14,773 Epoch[47] Batch [1290]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086016,	
2017-07-20 18:46:19,427 Epoch[47] Batch [1300]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.085974,	
2017-07-20 18:46:23,886 Epoch[47] Batch [1310]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.085966,	
2017-07-20 18:46:28,631 Epoch[47] Batch [1320]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.085971,	
2017-07-20 18:46:33,469 Epoch[47] Batch [1330]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.085990,	
2017-07-20 18:46:38,490 Epoch[47] Batch [1340]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.085915,	
2017-07-20 18:46:43,250 Epoch[47] Batch [1350]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.085878,	
2017-07-20 18:46:47,954 Epoch[47] Batch [1360]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.085864,	
2017-07-20 18:46:52,475 Epoch[47] Batch [1370]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.085872,	
2017-07-20 18:46:56,633 Epoch[47] Batch [1380]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.085848,	
2017-07-20 18:47:00,744 Epoch[47] Batch [1390]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.085898,	
2017-07-20 18:47:04,802 Epoch[47] Batch [1400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.085954,	
2017-07-20 18:47:08,888 Epoch[47] Batch [1410]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.085968,	
2017-07-20 18:47:13,113 Epoch[47] Batch [1420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.085893,	
2017-07-20 18:47:17,345 Epoch[47] Batch [1430]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.085890,	
2017-07-20 18:47:21,443 Epoch[47] Batch [1440]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085906,	
2017-07-20 18:47:25,515 Epoch[47] Batch [1450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.085899,	
2017-07-20 18:47:29,560 Epoch[47] Batch [1460]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.085915,	
2017-07-20 18:47:33,661 Epoch[47] Batch [1470]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085899,	
2017-07-20 18:47:37,613 Epoch[47] Batch [1480]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.085890,	
2017-07-20 18:47:40,108 Epoch[47] Train-FCNLogLoss=0.085886
2017-07-20 18:47:40,108 Epoch[47] Time cost=668.223
2017-07-20 18:47:40,805 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0048.params"
2017-07-20 18:47:43,401 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0048.states"
2017-07-20 18:47:48,232 Epoch[48] Batch [10]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.086251,	
2017-07-20 18:47:52,387 Epoch[48] Batch [20]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084711,	
2017-07-20 18:47:56,477 Epoch[48] Batch [30]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.083838,	
2017-07-20 18:48:00,629 Epoch[48] Batch [40]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085512,	
2017-07-20 18:48:04,717 Epoch[48] Batch [50]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.086124,	
2017-07-20 18:48:08,862 Epoch[48] Batch [60]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086745,	
2017-07-20 18:48:12,947 Epoch[48] Batch [70]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.085964,	
2017-07-20 18:48:17,091 Epoch[48] Batch [80]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085685,	
2017-07-20 18:48:21,264 Epoch[48] Batch [90]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.084753,	
2017-07-20 18:48:25,451 Epoch[48] Batch [100]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084090,	
2017-07-20 18:48:29,739 Epoch[48] Batch [110]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.084185,	
2017-07-20 18:48:33,891 Epoch[48] Batch [120]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084566,	
2017-07-20 18:48:38,197 Epoch[48] Batch [130]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.084397,	
2017-07-20 18:48:42,386 Epoch[48] Batch [140]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084344,	
2017-07-20 18:48:46,542 Epoch[48] Batch [150]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.083657,	
2017-07-20 18:48:50,935 Epoch[48] Batch [160]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.083777,	
2017-07-20 18:48:55,016 Epoch[48] Batch [170]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.084136,	
2017-07-20 18:48:59,265 Epoch[48] Batch [180]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.084221,	
2017-07-20 18:49:03,427 Epoch[48] Batch [190]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084204,	
2017-07-20 18:49:07,500 Epoch[48] Batch [200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.084046,	
2017-07-20 18:49:11,852 Epoch[48] Batch [210]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.083933,	
2017-07-20 18:49:16,051 Epoch[48] Batch [220]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.083710,	
2017-07-20 18:49:20,290 Epoch[48] Batch [230]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.083556,	
2017-07-20 18:49:24,550 Epoch[48] Batch [240]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.083534,	
2017-07-20 18:49:28,653 Epoch[48] Batch [250]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.083607,	
2017-07-20 18:49:32,716 Epoch[48] Batch [260]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.083944,	
2017-07-20 18:49:36,955 Epoch[48] Batch [270]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.083866,	
2017-07-20 18:49:40,940 Epoch[48] Batch [280]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.083787,	
2017-07-20 18:49:45,154 Epoch[48] Batch [290]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.083973,	
2017-07-20 18:49:49,297 Epoch[48] Batch [300]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084046,	
2017-07-20 18:49:53,443 Epoch[48] Batch [310]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.083818,	
2017-07-20 18:49:57,692 Epoch[48] Batch [320]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.083745,	
2017-07-20 18:50:01,867 Epoch[48] Batch [330]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.083664,	
2017-07-20 18:50:06,181 Epoch[48] Batch [340]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.083845,	
2017-07-20 18:50:10,227 Epoch[48] Batch [350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.084064,	
2017-07-20 18:50:14,622 Epoch[48] Batch [360]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.083919,	
2017-07-20 18:50:18,759 Epoch[48] Batch [370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.083827,	
2017-07-20 18:50:23,049 Epoch[48] Batch [380]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.083750,	
2017-07-20 18:50:27,128 Epoch[48] Batch [390]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.083847,	
2017-07-20 18:50:31,336 Epoch[48] Batch [400]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.083811,	
2017-07-20 18:50:35,499 Epoch[48] Batch [410]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.083731,	
2017-07-20 18:50:39,781 Epoch[48] Batch [420]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.083838,	
2017-07-20 18:50:44,078 Epoch[48] Batch [430]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.083922,	
2017-07-20 18:50:48,174 Epoch[48] Batch [440]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.084100,	
2017-07-20 18:50:52,343 Epoch[48] Batch [450]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084046,	
2017-07-20 18:50:56,555 Epoch[48] Batch [460]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.083884,	
2017-07-20 18:51:00,782 Epoch[48] Batch [470]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.084016,	
2017-07-20 18:51:04,998 Epoch[48] Batch [480]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.083840,	
2017-07-20 18:51:09,024 Epoch[48] Batch [490]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.083980,	
2017-07-20 18:51:13,180 Epoch[48] Batch [500]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084090,	
2017-07-20 18:51:17,442 Epoch[48] Batch [510]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.084157,	
2017-07-20 18:51:21,594 Epoch[48] Batch [520]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084265,	
2017-07-20 18:51:25,645 Epoch[48] Batch [530]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084522,	
2017-07-20 18:51:29,785 Epoch[48] Batch [540]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084402,	
2017-07-20 18:51:34,013 Epoch[48] Batch [550]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.084476,	
2017-07-20 18:51:38,142 Epoch[48] Batch [560]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084395,	
2017-07-20 18:51:42,324 Epoch[48] Batch [570]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.084289,	
2017-07-20 18:51:46,276 Epoch[48] Batch [580]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.084176,	
2017-07-20 18:51:50,424 Epoch[48] Batch [590]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084171,	
2017-07-20 18:51:54,663 Epoch[48] Batch [600]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.084125,	
2017-07-20 18:51:58,849 Epoch[48] Batch [610]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.084150,	
2017-07-20 18:52:02,975 Epoch[48] Batch [620]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.084077,	
2017-07-20 18:52:07,123 Epoch[48] Batch [630]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084104,	
2017-07-20 18:52:11,168 Epoch[48] Batch [640]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.083976,	
2017-07-20 18:52:15,392 Epoch[48] Batch [650]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.084152,	
2017-07-20 18:52:19,347 Epoch[48] Batch [660]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.084063,	
2017-07-20 18:52:23,509 Epoch[48] Batch [670]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084107,	
2017-07-20 18:52:27,776 Epoch[48] Batch [680]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.084129,	
2017-07-20 18:52:31,935 Epoch[48] Batch [690]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084082,	
2017-07-20 18:52:36,231 Epoch[48] Batch [700]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.084020,	
2017-07-20 18:52:40,353 Epoch[48] Batch [710]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.083980,	
2017-07-20 18:52:44,544 Epoch[48] Batch [720]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084056,	
2017-07-20 18:52:48,629 Epoch[48] Batch [730]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.084106,	
2017-07-20 18:52:52,670 Epoch[48] Batch [740]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.084081,	
2017-07-20 18:52:56,805 Epoch[48] Batch [750]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.084148,	
2017-07-20 18:53:00,887 Epoch[48] Batch [760]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.084212,	
2017-07-20 18:53:04,946 Epoch[48] Batch [770]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.084183,	
2017-07-20 18:53:09,093 Epoch[48] Batch [780]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084084,	
2017-07-20 18:53:13,120 Epoch[48] Batch [790]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.084127,	
2017-07-20 18:53:17,380 Epoch[48] Batch [800]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.084247,	
2017-07-20 18:53:21,614 Epoch[48] Batch [810]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.084199,	
2017-07-20 18:53:25,805 Epoch[48] Batch [820]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084149,	
2017-07-20 18:53:30,060 Epoch[48] Batch [830]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.084119,	
2017-07-20 18:53:34,357 Epoch[48] Batch [840]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.084115,	
2017-07-20 18:53:38,468 Epoch[48] Batch [850]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.084166,	
2017-07-20 18:53:42,527 Epoch[48] Batch [860]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.084199,	
2017-07-20 18:53:46,576 Epoch[48] Batch [870]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084199,	
2017-07-20 18:53:50,697 Epoch[48] Batch [880]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084267,	
2017-07-20 18:53:54,777 Epoch[48] Batch [890]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.084258,	
2017-07-20 18:53:59,017 Epoch[48] Batch [900]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.084206,	
2017-07-20 18:54:03,154 Epoch[48] Batch [910]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.084201,	
2017-07-20 18:54:07,430 Epoch[48] Batch [920]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.084151,	
2017-07-20 18:54:11,606 Epoch[48] Batch [930]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.084188,	
2017-07-20 18:54:15,870 Epoch[48] Batch [940]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.084198,	
2017-07-20 18:54:20,060 Epoch[48] Batch [950]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084104,	
2017-07-20 18:54:24,134 Epoch[48] Batch [960]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.084110,	
2017-07-20 18:54:28,308 Epoch[48] Batch [970]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.084141,	
2017-07-20 18:54:32,579 Epoch[48] Batch [980]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.084184,	
2017-07-20 18:54:36,830 Epoch[48] Batch [990]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.084453,	
2017-07-20 18:54:40,918 Epoch[48] Batch [1000]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.084492,	
2017-07-20 18:54:45,104 Epoch[48] Batch [1010]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.084512,	
2017-07-20 18:54:49,116 Epoch[48] Batch [1020]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.084570,	
2017-07-20 18:54:53,244 Epoch[48] Batch [1030]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084586,	
2017-07-20 18:54:57,574 Epoch[48] Batch [1040]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.084563,	
2017-07-20 18:55:01,640 Epoch[48] Batch [1050]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.084614,	
2017-07-20 18:55:05,935 Epoch[48] Batch [1060]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.084511,	
2017-07-20 18:55:10,141 Epoch[48] Batch [1070]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084624,	
2017-07-20 18:55:14,221 Epoch[48] Batch [1080]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.084724,	
2017-07-20 18:55:18,245 Epoch[48] Batch [1090]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.084922,	
2017-07-20 18:55:22,453 Epoch[48] Batch [1100]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.085051,	
2017-07-20 18:55:26,701 Epoch[48] Batch [1110]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.085323,	
2017-07-20 18:55:30,825 Epoch[48] Batch [1120]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.085460,	
2017-07-20 18:55:34,939 Epoch[48] Batch [1130]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.085612,	
2017-07-20 18:55:39,088 Epoch[48] Batch [1140]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.085835,	
2017-07-20 18:55:43,232 Epoch[48] Batch [1150]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085873,	
2017-07-20 18:55:47,403 Epoch[48] Batch [1160]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.085905,	
2017-07-20 18:55:51,496 Epoch[48] Batch [1170]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.085992,	
2017-07-20 18:55:55,669 Epoch[48] Batch [1180]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.085944,	
2017-07-20 18:55:59,863 Epoch[48] Batch [1190]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.085957,	
2017-07-20 18:56:03,983 Epoch[48] Batch [1200]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.086095,	
2017-07-20 18:56:08,199 Epoch[48] Batch [1210]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.086107,	
2017-07-20 18:56:12,363 Epoch[48] Batch [1220]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.086146,	
2017-07-20 18:56:16,395 Epoch[48] Batch [1230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.086182,	
2017-07-20 18:56:20,573 Epoch[48] Batch [1240]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086128,	
2017-07-20 18:56:24,880 Epoch[48] Batch [1250]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.086075,	
2017-07-20 18:56:28,963 Epoch[48] Batch [1260]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.086103,	
2017-07-20 18:56:33,075 Epoch[48] Batch [1270]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.086050,	
2017-07-20 18:56:37,094 Epoch[48] Batch [1280]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.086016,	
2017-07-20 18:56:41,241 Epoch[48] Batch [1290]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086048,	
2017-07-20 18:56:45,424 Epoch[48] Batch [1300]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.085988,	
2017-07-20 18:56:49,535 Epoch[48] Batch [1310]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.085991,	
2017-07-20 18:56:53,687 Epoch[48] Batch [1320]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085905,	
2017-07-20 18:56:57,938 Epoch[48] Batch [1330]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.085908,	
2017-07-20 18:57:02,019 Epoch[48] Batch [1340]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.085992,	
2017-07-20 18:57:06,296 Epoch[48] Batch [1350]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086042,	
2017-07-20 18:57:10,443 Epoch[48] Batch [1360]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086067,	
2017-07-20 18:57:14,581 Epoch[48] Batch [1370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.086109,	
2017-07-20 18:57:18,785 Epoch[48] Batch [1380]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.086176,	
2017-07-20 18:57:23,048 Epoch[48] Batch [1390]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.086157,	
2017-07-20 18:57:27,200 Epoch[48] Batch [1400]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.086171,	
2017-07-20 18:57:31,334 Epoch[48] Batch [1410]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.086163,	
2017-07-20 18:57:35,351 Epoch[48] Batch [1420]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.086111,	
2017-07-20 18:57:39,578 Epoch[48] Batch [1430]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.086125,	
2017-07-20 18:57:43,816 Epoch[48] Batch [1440]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.086150,	
2017-07-20 18:57:48,007 Epoch[48] Batch [1450]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086117,	
2017-07-20 18:57:52,286 Epoch[48] Batch [1460]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086149,	
2017-07-20 18:57:56,574 Epoch[48] Batch [1470]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.086183,	
2017-07-20 18:58:00,818 Epoch[48] Batch [1480]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.086240,	
2017-07-20 18:58:03,227 Epoch[48] Train-FCNLogLoss=0.086275
2017-07-20 18:58:03,227 Epoch[48] Time cost=619.826
2017-07-20 18:58:03,886 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0049.params"
2017-07-20 18:58:07,081 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0049.states"
2017-07-20 18:58:12,085 Epoch[49] Batch [10]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.089334,	
2017-07-20 18:58:16,015 Epoch[49] Batch [20]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.088949,	
2017-07-20 18:58:20,213 Epoch[49] Batch [30]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.091214,	
2017-07-20 18:58:24,167 Epoch[49] Batch [40]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.089842,	
2017-07-20 18:58:28,461 Epoch[49] Batch [50]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088764,	
2017-07-20 18:58:32,587 Epoch[49] Batch [60]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.089286,	
2017-07-20 18:58:36,765 Epoch[49] Batch [70]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087909,	
2017-07-20 18:58:40,924 Epoch[49] Batch [80]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.087841,	
2017-07-20 18:58:45,025 Epoch[49] Batch [90]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.087474,	
2017-07-20 18:58:49,158 Epoch[49] Batch [100]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087583,	
2017-07-20 18:58:53,390 Epoch[49] Batch [110]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.086441,	
2017-07-20 18:58:57,513 Epoch[49] Batch [120]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.085895,	
2017-07-20 18:59:01,688 Epoch[49] Batch [130]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.085688,	
2017-07-20 18:59:05,915 Epoch[49] Batch [140]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.085593,	
2017-07-20 18:59:10,059 Epoch[49] Batch [150]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086095,	
2017-07-20 18:59:14,145 Epoch[49] Batch [160]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.085629,	
2017-07-20 18:59:18,243 Epoch[49] Batch [170]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085820,	
2017-07-20 18:59:22,394 Epoch[49] Batch [180]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085968,	
2017-07-20 18:59:26,506 Epoch[49] Batch [190]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.086101,	
2017-07-20 18:59:30,729 Epoch[49] Batch [200]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.086166,	
2017-07-20 18:59:34,885 Epoch[49] Batch [210]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.085711,	
2017-07-20 18:59:38,969 Epoch[49] Batch [220]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.085649,	
2017-07-20 18:59:43,049 Epoch[49] Batch [230]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.085561,	
2017-07-20 18:59:47,199 Epoch[49] Batch [240]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085637,	
2017-07-20 18:59:51,292 Epoch[49] Batch [250]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.085993,	
2017-07-20 18:59:55,546 Epoch[49] Batch [260]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.085834,	
2017-07-20 18:59:59,690 Epoch[49] Batch [270]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085642,	
2017-07-20 19:00:03,891 Epoch[49] Batch [280]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.086166,	
2017-07-20 19:00:08,107 Epoch[49] Batch [290]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.086137,	
2017-07-20 19:00:12,264 Epoch[49] Batch [300]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.086168,	
2017-07-20 19:00:16,508 Epoch[49] Batch [310]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.085890,	
2017-07-20 19:00:20,707 Epoch[49] Batch [320]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.085658,	
2017-07-20 19:00:24,821 Epoch[49] Batch [330]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.085529,	
2017-07-20 19:00:29,213 Epoch[49] Batch [340]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.085473,	
2017-07-20 19:00:33,343 Epoch[49] Batch [350]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.085398,	
2017-07-20 19:00:37,551 Epoch[49] Batch [360]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.085474,	
2017-07-20 19:00:41,599 Epoch[49] Batch [370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.085476,	
2017-07-20 19:00:45,805 Epoch[49] Batch [380]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.085548,	
2017-07-20 19:00:49,867 Epoch[49] Batch [390]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.085506,	
2017-07-20 19:00:54,053 Epoch[49] Batch [400]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.085507,	
2017-07-20 19:00:58,449 Epoch[49] Batch [410]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.085441,	
2017-07-20 19:01:02,565 Epoch[49] Batch [420]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.085522,	
2017-07-20 19:01:06,755 Epoch[49] Batch [430]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.085597,	
2017-07-20 19:01:10,827 Epoch[49] Batch [440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.085760,	
2017-07-20 19:01:15,055 Epoch[49] Batch [450]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.085724,	
2017-07-20 19:01:19,196 Epoch[49] Batch [460]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.085773,	
2017-07-20 19:01:23,354 Epoch[49] Batch [470]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.085543,	
2017-07-20 19:01:27,549 Epoch[49] Batch [480]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.085376,	
2017-07-20 19:01:31,561 Epoch[49] Batch [490]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.085226,	
2017-07-20 19:01:35,786 Epoch[49] Batch [500]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.085045,	
2017-07-20 19:01:40,038 Epoch[49] Batch [510]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.084986,	
2017-07-20 19:01:44,300 Epoch[49] Batch [520]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.084828,	
2017-07-20 19:01:48,502 Epoch[49] Batch [530]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.084775,	
2017-07-20 19:01:52,541 Epoch[49] Batch [540]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.084664,	
2017-07-20 19:01:56,729 Epoch[49] Batch [550]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084670,	
2017-07-20 19:02:00,876 Epoch[49] Batch [560]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084583,	
2017-07-20 19:02:04,930 Epoch[49] Batch [570]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.084592,	
2017-07-20 19:02:09,089 Epoch[49] Batch [580]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084397,	
2017-07-20 19:02:13,174 Epoch[49] Batch [590]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.084499,	
2017-07-20 19:02:17,385 Epoch[49] Batch [600]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.084361,	
2017-07-20 19:02:21,456 Epoch[49] Batch [610]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.084420,	
2017-07-20 19:02:25,565 Epoch[49] Batch [620]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084373,	
2017-07-20 19:02:29,612 Epoch[49] Batch [630]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084447,	
2017-07-20 19:02:34,037 Epoch[49] Batch [640]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.084491,	
2017-07-20 19:02:38,271 Epoch[49] Batch [650]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.084485,	
2017-07-20 19:02:42,330 Epoch[49] Batch [660]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.084576,	
2017-07-20 19:02:46,474 Epoch[49] Batch [670]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084704,	
2017-07-20 19:02:50,622 Epoch[49] Batch [680]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084646,	
2017-07-20 19:02:54,851 Epoch[49] Batch [690]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.084611,	
2017-07-20 19:02:59,152 Epoch[49] Batch [700]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.084523,	
2017-07-20 19:03:03,367 Epoch[49] Batch [710]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.084601,	
2017-07-20 19:03:07,614 Epoch[49] Batch [720]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.084640,	
2017-07-20 19:03:11,735 Epoch[49] Batch [730]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084525,	
2017-07-20 19:03:15,913 Epoch[49] Batch [740]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.084456,	
2017-07-20 19:03:20,030 Epoch[49] Batch [750]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.084363,	
2017-07-20 19:03:24,015 Epoch[49] Batch [760]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.084395,	
2017-07-20 19:03:28,125 Epoch[49] Batch [770]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.084407,	
2017-07-20 19:03:32,384 Epoch[49] Batch [780]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.084429,	
2017-07-20 19:03:36,517 Epoch[49] Batch [790]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.084432,	
2017-07-20 19:03:40,793 Epoch[49] Batch [800]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.084368,	
2017-07-20 19:03:44,918 Epoch[49] Batch [810]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.084347,	
2017-07-20 19:03:49,127 Epoch[49] Batch [820]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084435,	
2017-07-20 19:03:53,288 Epoch[49] Batch [830]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084327,	
2017-07-20 19:03:57,447 Epoch[49] Batch [840]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084331,	
2017-07-20 19:04:01,674 Epoch[49] Batch [850]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.084308,	
2017-07-20 19:04:05,900 Epoch[49] Batch [860]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.084287,	
2017-07-20 19:04:09,937 Epoch[49] Batch [870]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.084328,	
2017-07-20 19:04:14,217 Epoch[49] Batch [880]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.084355,	
2017-07-20 19:04:18,513 Epoch[49] Batch [890]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.084424,	
2017-07-20 19:04:22,634 Epoch[49] Batch [900]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084518,	
2017-07-20 19:04:26,784 Epoch[49] Batch [910]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084572,	
2017-07-20 19:04:30,942 Epoch[49] Batch [920]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084561,	
2017-07-20 19:04:35,295 Epoch[49] Batch [930]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.084575,	
2017-07-20 19:04:39,453 Epoch[49] Batch [940]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084464,	
2017-07-20 19:04:43,615 Epoch[49] Batch [950]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084367,	
2017-07-20 19:04:47,789 Epoch[49] Batch [960]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.084343,	
2017-07-20 19:04:52,003 Epoch[49] Batch [970]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.084412,	
2017-07-20 19:04:56,116 Epoch[49] Batch [980]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.084400,	
2017-07-20 19:05:00,142 Epoch[49] Batch [990]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.084355,	
2017-07-20 19:05:04,225 Epoch[49] Batch [1000]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.084350,	
2017-07-20 19:05:08,392 Epoch[49] Batch [1010]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084314,	
2017-07-20 19:05:12,559 Epoch[49] Batch [1020]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084253,	
2017-07-20 19:05:16,719 Epoch[49] Batch [1030]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084254,	
2017-07-20 19:05:20,951 Epoch[49] Batch [1040]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.084282,	
2017-07-20 19:05:25,068 Epoch[49] Batch [1050]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.084216,	
2017-07-20 19:05:29,240 Epoch[49] Batch [1060]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.084289,	
2017-07-20 19:05:33,288 Epoch[49] Batch [1070]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084350,	
2017-07-20 19:05:37,450 Epoch[49] Batch [1080]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084344,	
2017-07-20 19:05:41,523 Epoch[49] Batch [1090]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.084401,	
2017-07-20 19:05:45,632 Epoch[49] Batch [1100]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084383,	
2017-07-20 19:05:49,816 Epoch[49] Batch [1110]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.084392,	
2017-07-20 19:05:54,091 Epoch[49] Batch [1120]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.084409,	
2017-07-20 19:05:58,373 Epoch[49] Batch [1130]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.084414,	
2017-07-20 19:06:02,492 Epoch[49] Batch [1140]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084425,	
2017-07-20 19:06:06,619 Epoch[49] Batch [1150]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084420,	
2017-07-20 19:06:10,824 Epoch[49] Batch [1160]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084421,	
2017-07-20 19:06:14,979 Epoch[49] Batch [1170]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084332,	
2017-07-20 19:06:19,106 Epoch[49] Batch [1180]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084360,	
2017-07-20 19:06:23,267 Epoch[49] Batch [1190]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.084274,	
2017-07-20 19:06:27,399 Epoch[49] Batch [1200]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.084314,	
2017-07-20 19:06:31,654 Epoch[49] Batch [1210]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.084360,	
2017-07-20 19:06:35,694 Epoch[49] Batch [1220]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.084415,	
2017-07-20 19:06:39,813 Epoch[49] Batch [1230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084418,	
2017-07-20 19:06:43,914 Epoch[49] Batch [1240]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.084423,	
2017-07-20 19:06:48,034 Epoch[49] Batch [1250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084401,	
2017-07-20 19:06:52,109 Epoch[49] Batch [1260]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.084396,	
2017-07-20 19:06:56,234 Epoch[49] Batch [1270]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.084346,	
2017-07-20 19:07:00,299 Epoch[49] Batch [1280]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.084291,	
2017-07-20 19:07:04,459 Epoch[49] Batch [1290]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084262,	
2017-07-20 19:07:08,639 Epoch[49] Batch [1300]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084216,	
2017-07-20 19:07:12,832 Epoch[49] Batch [1310]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.084232,	
2017-07-20 19:07:17,089 Epoch[49] Batch [1320]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.084238,	
2017-07-20 19:07:21,220 Epoch[49] Batch [1330]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.084245,	
2017-07-20 19:07:25,367 Epoch[49] Batch [1340]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084220,	
2017-07-20 19:07:29,471 Epoch[49] Batch [1350]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.084281,	
2017-07-20 19:07:33,684 Epoch[49] Batch [1360]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.084288,	
2017-07-20 19:07:38,131 Epoch[49] Batch [1370]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.084334,	
2017-07-20 19:07:42,235 Epoch[49] Batch [1380]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.084390,	
2017-07-20 19:07:46,231 Epoch[49] Batch [1390]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.084456,	
2017-07-20 19:07:50,457 Epoch[49] Batch [1400]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.084456,	
2017-07-20 19:07:54,535 Epoch[49] Batch [1410]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.084400,	
2017-07-20 19:07:58,632 Epoch[49] Batch [1420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.084378,	
2017-07-20 19:08:02,893 Epoch[49] Batch [1430]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.084443,	
2017-07-20 19:08:07,065 Epoch[49] Batch [1440]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.084438,	
2017-07-20 19:08:11,134 Epoch[49] Batch [1450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.084401,	
2017-07-20 19:08:15,300 Epoch[49] Batch [1460]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084455,	
2017-07-20 19:08:19,452 Epoch[49] Batch [1470]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084465,	
2017-07-20 19:08:23,656 Epoch[49] Batch [1480]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084510,	
2017-07-20 19:08:26,014 Epoch[49] Train-FCNLogLoss=0.084495
2017-07-20 19:08:26,014 Epoch[49] Time cost=618.933
2017-07-20 19:08:26,747 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0050.params"
2017-07-20 19:08:29,596 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0050.states"
2017-07-20 19:08:34,477 Epoch[50] Batch [10]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.076406,	
2017-07-20 19:08:38,520 Epoch[50] Batch [20]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.078872,	
2017-07-20 19:08:42,645 Epoch[50] Batch [30]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.081172,	
2017-07-20 19:08:46,921 Epoch[50] Batch [40]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.082700,	
2017-07-20 19:08:50,968 Epoch[50] Batch [50]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.082766,	
2017-07-20 19:08:55,194 Epoch[50] Batch [60]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.082862,	
2017-07-20 19:08:59,374 Epoch[50] Batch [70]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.082402,	
2017-07-20 19:09:03,441 Epoch[50] Batch [80]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.082616,	
2017-07-20 19:09:07,614 Epoch[50] Batch [90]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.083334,	
2017-07-20 19:09:11,821 Epoch[50] Batch [100]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.083588,	
2017-07-20 19:09:16,051 Epoch[50] Batch [110]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.083723,	
2017-07-20 19:09:20,208 Epoch[50] Batch [120]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.083295,	
2017-07-20 19:09:24,293 Epoch[50] Batch [130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.083770,	
2017-07-20 19:09:28,575 Epoch[50] Batch [140]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.083317,	
2017-07-20 19:09:32,688 Epoch[50] Batch [150]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.083221,	
2017-07-20 19:09:36,699 Epoch[50] Batch [160]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.083574,	
2017-07-20 19:09:40,801 Epoch[50] Batch [170]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.083480,	
2017-07-20 19:09:45,057 Epoch[50] Batch [180]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.083574,	
2017-07-20 19:09:49,310 Epoch[50] Batch [190]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.084025,	
2017-07-20 19:09:53,341 Epoch[50] Batch [200]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.084321,	
2017-07-20 19:09:57,486 Epoch[50] Batch [210]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084691,	
2017-07-20 19:10:01,687 Epoch[50] Batch [220]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.084917,	
2017-07-20 19:10:05,873 Epoch[50] Batch [230]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.084937,	
2017-07-20 19:10:10,055 Epoch[50] Batch [240]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.084974,	
2017-07-20 19:10:14,260 Epoch[50] Batch [250]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084497,	
2017-07-20 19:10:18,296 Epoch[50] Batch [260]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.084506,	
2017-07-20 19:10:22,532 Epoch[50] Batch [270]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.084957,	
2017-07-20 19:10:26,652 Epoch[50] Batch [280]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084702,	
2017-07-20 19:10:30,964 Epoch[50] Batch [290]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.084703,	
2017-07-20 19:10:35,044 Epoch[50] Batch [300]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.084590,	
2017-07-20 19:10:39,226 Epoch[50] Batch [310]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.084581,	
2017-07-20 19:10:43,528 Epoch[50] Batch [320]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.084483,	
2017-07-20 19:10:47,681 Epoch[50] Batch [330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084685,	
2017-07-20 19:10:51,808 Epoch[50] Batch [340]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084848,	
2017-07-20 19:10:55,843 Epoch[50] Batch [350]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.084745,	
2017-07-20 19:10:59,982 Epoch[50] Batch [360]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084632,	
2017-07-20 19:11:04,321 Epoch[50] Batch [370]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.084688,	
2017-07-20 19:11:08,598 Epoch[50] Batch [380]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.084523,	
2017-07-20 19:11:12,655 Epoch[50] Batch [390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.084356,	
2017-07-20 19:11:16,903 Epoch[50] Batch [400]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.084461,	
2017-07-20 19:11:20,998 Epoch[50] Batch [410]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.084527,	
2017-07-20 19:11:25,039 Epoch[50] Batch [420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.084414,	
2017-07-20 19:11:29,203 Epoch[50] Batch [430]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084302,	
2017-07-20 19:11:33,335 Epoch[50] Batch [440]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.084531,	
2017-07-20 19:11:37,456 Epoch[50] Batch [450]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084577,	
2017-07-20 19:11:41,415 Epoch[50] Batch [460]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.084528,	
2017-07-20 19:11:45,564 Epoch[50] Batch [470]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084421,	
2017-07-20 19:11:49,658 Epoch[50] Batch [480]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.084342,	
2017-07-20 19:11:53,680 Epoch[50] Batch [490]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.084353,	
2017-07-20 19:11:57,643 Epoch[50] Batch [500]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.084359,	
2017-07-20 19:12:01,808 Epoch[50] Batch [510]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084247,	
2017-07-20 19:12:05,952 Epoch[50] Batch [520]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084316,	
2017-07-20 19:12:10,134 Epoch[50] Batch [530]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.084200,	
2017-07-20 19:12:14,366 Epoch[50] Batch [540]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.084225,	
2017-07-20 19:12:18,434 Epoch[50] Batch [550]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.084325,	
2017-07-20 19:12:22,659 Epoch[50] Batch [560]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.084488,	
2017-07-20 19:12:26,723 Epoch[50] Batch [570]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.084533,	
2017-07-20 19:12:30,833 Epoch[50] Batch [580]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.084674,	
2017-07-20 19:12:34,844 Epoch[50] Batch [590]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.084772,	
2017-07-20 19:12:38,812 Epoch[50] Batch [600]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.084671,	
2017-07-20 19:12:42,918 Epoch[50] Batch [610]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084620,	
2017-07-20 19:12:47,236 Epoch[50] Batch [620]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.084530,	
2017-07-20 19:12:51,222 Epoch[50] Batch [630]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.084443,	
2017-07-20 19:12:55,541 Epoch[50] Batch [640]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.084376,	
2017-07-20 19:12:59,586 Epoch[50] Batch [650]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.084252,	
2017-07-20 19:13:03,765 Epoch[50] Batch [660]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.084170,	
2017-07-20 19:13:08,030 Epoch[50] Batch [670]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.084047,	
2017-07-20 19:13:12,274 Epoch[50] Batch [680]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.084086,	
2017-07-20 19:13:16,421 Epoch[50] Batch [690]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084007,	
2017-07-20 19:13:20,488 Epoch[50] Batch [700]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.084043,	
2017-07-20 19:13:24,598 Epoch[50] Batch [710]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.084156,	
2017-07-20 19:13:28,826 Epoch[50] Batch [720]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.084186,	
2017-07-20 19:13:33,058 Epoch[50] Batch [730]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.084222,	
2017-07-20 19:13:37,145 Epoch[50] Batch [740]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.084254,	
2017-07-20 19:13:41,287 Epoch[50] Batch [750]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084164,	
2017-07-20 19:13:45,452 Epoch[50] Batch [760]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084073,	
2017-07-20 19:13:49,503 Epoch[50] Batch [770]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084087,	
2017-07-20 19:13:53,806 Epoch[50] Batch [780]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.084107,	
2017-07-20 19:13:58,048 Epoch[50] Batch [790]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.084025,	
2017-07-20 19:14:02,459 Epoch[50] Batch [800]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.084083,	
2017-07-20 19:14:06,577 Epoch[50] Batch [810]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084202,	
2017-07-20 19:14:10,624 Epoch[50] Batch [820]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.084238,	
2017-07-20 19:14:14,796 Epoch[50] Batch [830]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.084231,	
2017-07-20 19:14:18,987 Epoch[50] Batch [840]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084283,	
2017-07-20 19:14:23,071 Epoch[50] Batch [850]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.084313,	
2017-07-20 19:14:27,192 Epoch[50] Batch [860]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084350,	
2017-07-20 19:14:31,332 Epoch[50] Batch [870]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084331,	
2017-07-20 19:14:35,447 Epoch[50] Batch [880]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.084281,	
2017-07-20 19:14:39,634 Epoch[50] Batch [890]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084357,	
2017-07-20 19:14:43,869 Epoch[50] Batch [900]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.084234,	
2017-07-20 19:14:47,933 Epoch[50] Batch [910]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.084226,	
2017-07-20 19:14:51,921 Epoch[50] Batch [920]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.084211,	
2017-07-20 19:14:56,136 Epoch[50] Batch [930]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.084262,	
2017-07-20 19:15:00,402 Epoch[50] Batch [940]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.084225,	
2017-07-20 19:15:04,525 Epoch[50] Batch [950]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.084402,	
2017-07-20 19:15:08,571 Epoch[50] Batch [960]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.084574,	
2017-07-20 19:15:12,772 Epoch[50] Batch [970]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.084636,	
2017-07-20 19:15:16,858 Epoch[50] Batch [980]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.084613,	
2017-07-20 19:15:20,882 Epoch[50] Batch [990]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.084618,	
2017-07-20 19:15:24,944 Epoch[50] Batch [1000]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.084645,	
2017-07-20 19:15:29,118 Epoch[50] Batch [1010]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.084633,	
2017-07-20 19:15:33,347 Epoch[50] Batch [1020]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.084624,	
2017-07-20 19:15:37,425 Epoch[50] Batch [1030]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.084666,	
2017-07-20 19:15:41,505 Epoch[50] Batch [1040]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.084615,	
2017-07-20 19:15:45,707 Epoch[50] Batch [1050]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.084680,	
2017-07-20 19:15:49,848 Epoch[50] Batch [1060]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084693,	
2017-07-20 19:15:54,209 Epoch[50] Batch [1070]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.084668,	
2017-07-20 19:15:58,247 Epoch[50] Batch [1080]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.084708,	
2017-07-20 19:16:02,326 Epoch[50] Batch [1090]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.084720,	
2017-07-20 19:16:06,478 Epoch[50] Batch [1100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084672,	
2017-07-20 19:16:10,632 Epoch[50] Batch [1110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084638,	
2017-07-20 19:16:14,643 Epoch[50] Batch [1120]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.084604,	
2017-07-20 19:16:18,849 Epoch[50] Batch [1130]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084582,	
2017-07-20 19:16:22,958 Epoch[50] Batch [1140]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084584,	
2017-07-20 19:16:27,153 Epoch[50] Batch [1150]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.084609,	
2017-07-20 19:16:31,282 Epoch[50] Batch [1160]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084540,	
2017-07-20 19:16:35,406 Epoch[50] Batch [1170]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.084501,	
2017-07-20 19:16:39,570 Epoch[50] Batch [1180]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084433,	
2017-07-20 19:16:43,633 Epoch[50] Batch [1190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.084425,	
2017-07-20 19:16:47,870 Epoch[50] Batch [1200]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.084445,	
2017-07-20 19:16:51,946 Epoch[50] Batch [1210]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.084433,	
2017-07-20 19:16:56,144 Epoch[50] Batch [1220]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.084493,	
2017-07-20 19:17:00,283 Epoch[50] Batch [1230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084499,	
2017-07-20 19:17:04,488 Epoch[50] Batch [1240]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084468,	
2017-07-20 19:17:08,632 Epoch[50] Batch [1250]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084424,	
2017-07-20 19:17:12,788 Epoch[50] Batch [1260]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084570,	
2017-07-20 19:17:16,981 Epoch[50] Batch [1270]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.084593,	
2017-07-20 19:17:21,147 Epoch[50] Batch [1280]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084542,	
2017-07-20 19:17:25,215 Epoch[50] Batch [1290]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.084583,	
2017-07-20 19:17:29,360 Epoch[50] Batch [1300]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084508,	
2017-07-20 19:17:33,461 Epoch[50] Batch [1310]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.084447,	
2017-07-20 19:17:37,578 Epoch[50] Batch [1320]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.084406,	
2017-07-20 19:17:41,767 Epoch[50] Batch [1330]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084473,	
2017-07-20 19:17:45,831 Epoch[50] Batch [1340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.084469,	
2017-07-20 19:17:49,967 Epoch[50] Batch [1350]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.084435,	
2017-07-20 19:17:53,965 Epoch[50] Batch [1360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.084354,	
2017-07-20 19:17:58,015 Epoch[50] Batch [1370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084318,	
2017-07-20 19:18:02,052 Epoch[50] Batch [1380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.084332,	
2017-07-20 19:18:06,187 Epoch[50] Batch [1390]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.084368,	
2017-07-20 19:18:10,335 Epoch[50] Batch [1400]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084438,	
2017-07-20 19:18:14,504 Epoch[50] Batch [1410]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.084491,	
2017-07-20 19:18:18,640 Epoch[50] Batch [1420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.084459,	
2017-07-20 19:18:22,871 Epoch[50] Batch [1430]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.084446,	
2017-07-20 19:18:27,016 Epoch[50] Batch [1440]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084450,	
2017-07-20 19:18:31,135 Epoch[50] Batch [1450]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.084440,	
2017-07-20 19:18:35,252 Epoch[50] Batch [1460]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.084407,	
2017-07-20 19:18:39,445 Epoch[50] Batch [1470]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.084425,	
2017-07-20 19:18:43,633 Epoch[50] Batch [1480]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084390,	
2017-07-20 19:18:46,198 Epoch[50] Train-FCNLogLoss=0.084425
2017-07-20 19:18:46,198 Epoch[50] Time cost=616.601
2017-07-20 19:18:46,888 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0051.params"
2017-07-20 19:18:49,572 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0051.states"
2017-07-20 19:18:54,461 Epoch[51] Batch [10]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.088418,	
2017-07-20 19:18:58,793 Epoch[51] Batch [20]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087488,	
2017-07-20 19:19:03,054 Epoch[51] Batch [30]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086198,	
2017-07-20 19:19:07,246 Epoch[51] Batch [40]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.084054,	
2017-07-20 19:19:11,338 Epoch[51] Batch [50]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.083592,	
2017-07-20 19:19:15,493 Epoch[51] Batch [60]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084098,	
2017-07-20 19:19:19,655 Epoch[51] Batch [70]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.085788,	
2017-07-20 19:19:23,729 Epoch[51] Batch [80]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.084910,	
2017-07-20 19:19:27,778 Epoch[51] Batch [90]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084658,	
2017-07-20 19:19:31,950 Epoch[51] Batch [100]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.084801,	
2017-07-20 19:19:36,167 Epoch[51] Batch [110]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.084658,	
2017-07-20 19:19:40,313 Epoch[51] Batch [120]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085414,	
2017-07-20 19:19:44,467 Epoch[51] Batch [130]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.085289,	
2017-07-20 19:19:48,469 Epoch[51] Batch [140]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.085666,	
2017-07-20 19:19:52,569 Epoch[51] Batch [150]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085607,	
2017-07-20 19:19:56,754 Epoch[51] Batch [160]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.085233,	
2017-07-20 19:20:00,960 Epoch[51] Batch [170]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084746,	
2017-07-20 19:20:05,107 Epoch[51] Batch [180]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085107,	
2017-07-20 19:20:09,319 Epoch[51] Batch [190]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086605,	
2017-07-20 19:20:13,294 Epoch[51] Batch [200]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.087099,	
2017-07-20 19:20:17,654 Epoch[51] Batch [210]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087437,	
2017-07-20 19:20:21,648 Epoch[51] Batch [220]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.087407,	
2017-07-20 19:20:25,722 Epoch[51] Batch [230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.087667,	
2017-07-20 19:20:29,840 Epoch[51] Batch [240]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.087572,	
2017-07-20 19:20:34,081 Epoch[51] Batch [250]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087630,	
2017-07-20 19:20:38,111 Epoch[51] Batch [260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.087596,	
2017-07-20 19:20:42,156 Epoch[51] Batch [270]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.087438,	
2017-07-20 19:20:46,476 Epoch[51] Batch [280]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087344,	
2017-07-20 19:20:50,742 Epoch[51] Batch [290]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.087104,	
2017-07-20 19:20:54,836 Epoch[51] Batch [300]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.087418,	
2017-07-20 19:20:59,028 Epoch[51] Batch [310]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.088494,	
2017-07-20 19:21:03,344 Epoch[51] Batch [320]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.090660,	
2017-07-20 19:21:07,450 Epoch[51] Batch [330]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093062,	
2017-07-20 19:21:11,529 Epoch[51] Batch [340]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094338,	
2017-07-20 19:21:15,718 Epoch[51] Batch [350]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095529,	
2017-07-20 19:21:19,812 Epoch[51] Batch [360]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095928,	
2017-07-20 19:21:23,885 Epoch[51] Batch [370]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.096157,	
2017-07-20 19:21:27,966 Epoch[51] Batch [380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.096246,	
2017-07-20 19:21:32,053 Epoch[51] Batch [390]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095972,	
2017-07-20 19:21:36,258 Epoch[51] Batch [400]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.096025,	
2017-07-20 19:21:40,413 Epoch[51] Batch [410]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.096008,	
2017-07-20 19:21:44,551 Epoch[51] Batch [420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.095921,	
2017-07-20 19:21:48,661 Epoch[51] Batch [430]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095665,	
2017-07-20 19:21:52,690 Epoch[51] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095312,	
2017-07-20 19:21:56,803 Epoch[51] Batch [450]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095247,	
2017-07-20 19:22:01,058 Epoch[51] Batch [460]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.095060,	
2017-07-20 19:22:05,323 Epoch[51] Batch [470]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094863,	
2017-07-20 19:22:09,371 Epoch[51] Batch [480]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094909,	
2017-07-20 19:22:13,395 Epoch[51] Batch [490]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094668,	
2017-07-20 19:22:17,608 Epoch[51] Batch [500]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094556,	
2017-07-20 19:22:21,819 Epoch[51] Batch [510]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094453,	
2017-07-20 19:22:26,196 Epoch[51] Batch [520]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.094382,	
2017-07-20 19:22:30,362 Epoch[51] Batch [530]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094437,	
2017-07-20 19:22:34,440 Epoch[51] Batch [540]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094324,	
2017-07-20 19:22:38,496 Epoch[51] Batch [550]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094526,	
2017-07-20 19:22:42,718 Epoch[51] Batch [560]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094355,	
2017-07-20 19:22:46,927 Epoch[51] Batch [570]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094473,	
2017-07-20 19:22:50,944 Epoch[51] Batch [580]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094717,	
2017-07-20 19:22:54,982 Epoch[51] Batch [590]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094822,	
2017-07-20 19:22:59,136 Epoch[51] Batch [600]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094938,	
2017-07-20 19:23:03,256 Epoch[51] Batch [610]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094851,	
2017-07-20 19:23:07,335 Epoch[51] Batch [620]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094607,	
2017-07-20 19:23:11,509 Epoch[51] Batch [630]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094368,	
2017-07-20 19:23:15,544 Epoch[51] Batch [640]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094141,	
2017-07-20 19:23:19,703 Epoch[51] Batch [650]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.094006,	
2017-07-20 19:23:23,760 Epoch[51] Batch [660]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094039,	
2017-07-20 19:23:27,857 Epoch[51] Batch [670]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094019,	
2017-07-20 19:23:31,952 Epoch[51] Batch [680]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093789,	
2017-07-20 19:23:36,150 Epoch[51] Batch [690]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.093599,	
2017-07-20 19:23:40,277 Epoch[51] Batch [700]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093657,	
2017-07-20 19:23:44,372 Epoch[51] Batch [710]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093555,	
2017-07-20 19:23:48,483 Epoch[51] Batch [720]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.093377,	
2017-07-20 19:23:52,598 Epoch[51] Batch [730]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093564,	
2017-07-20 19:23:56,778 Epoch[51] Batch [740]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.093600,	
2017-07-20 19:24:00,831 Epoch[51] Batch [750]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.093432,	
2017-07-20 19:24:04,925 Epoch[51] Batch [760]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-20 19:24:09,179 Epoch[51] Batch [770]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.093266,	
2017-07-20 19:24:13,355 Epoch[51] Batch [780]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094146,	
2017-07-20 19:24:17,426 Epoch[51] Batch [790]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094793,	
2017-07-20 19:24:21,497 Epoch[51] Batch [800]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095040,	
2017-07-20 19:24:25,676 Epoch[51] Batch [810]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095125,	
2017-07-20 19:24:29,643 Epoch[51] Batch [820]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.095286,	
2017-07-20 19:24:33,752 Epoch[51] Batch [830]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095170,	
2017-07-20 19:24:37,970 Epoch[51] Batch [840]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095188,	
2017-07-20 19:24:42,181 Epoch[51] Batch [850]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.095220,	
2017-07-20 19:24:46,468 Epoch[51] Batch [860]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.095203,	
2017-07-20 19:24:50,715 Epoch[51] Batch [870]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095071,	
2017-07-20 19:24:54,777 Epoch[51] Batch [880]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095086,	
2017-07-20 19:24:59,028 Epoch[51] Batch [890]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095035,	
2017-07-20 19:25:03,225 Epoch[51] Batch [900]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094902,	
2017-07-20 19:25:07,418 Epoch[51] Batch [910]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094760,	
2017-07-20 19:25:11,648 Epoch[51] Batch [920]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094635,	
2017-07-20 19:25:15,768 Epoch[51] Batch [930]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094583,	
2017-07-20 19:25:19,976 Epoch[51] Batch [940]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.094625,	
2017-07-20 19:25:24,327 Epoch[51] Batch [950]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.094589,	
2017-07-20 19:25:28,452 Epoch[51] Batch [960]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094515,	
2017-07-20 19:25:32,593 Epoch[51] Batch [970]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094475,	
2017-07-20 19:25:36,594 Epoch[51] Batch [980]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.094566,	
2017-07-20 19:25:40,706 Epoch[51] Batch [990]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.094562,	
2017-07-20 19:25:44,730 Epoch[51] Batch [1000]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094409,	
2017-07-20 19:25:48,978 Epoch[51] Batch [1010]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.094345,	
2017-07-20 19:25:53,115 Epoch[51] Batch [1020]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094304,	
2017-07-20 19:25:57,164 Epoch[51] Batch [1030]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094304,	
2017-07-20 19:26:01,481 Epoch[51] Batch [1040]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.094296,	
2017-07-20 19:26:05,604 Epoch[51] Batch [1050]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094320,	
2017-07-20 19:26:09,822 Epoch[51] Batch [1060]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094284,	
2017-07-20 19:26:13,954 Epoch[51] Batch [1070]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094196,	
2017-07-20 19:26:18,109 Epoch[51] Batch [1080]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094101,	
2017-07-20 19:26:22,252 Epoch[51] Batch [1090]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094139,	
2017-07-20 19:26:26,603 Epoch[51] Batch [1100]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.094139,	
2017-07-20 19:26:30,592 Epoch[51] Batch [1110]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094160,	
2017-07-20 19:26:34,595 Epoch[51] Batch [1120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094043,	
2017-07-20 19:26:38,677 Epoch[51] Batch [1130]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093965,	
2017-07-20 19:26:42,895 Epoch[51] Batch [1140]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.094007,	
2017-07-20 19:26:47,105 Epoch[51] Batch [1150]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.093884,	
2017-07-20 19:26:51,160 Epoch[51] Batch [1160]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.093786,	
2017-07-20 19:26:55,403 Epoch[51] Batch [1170]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.093803,	
2017-07-20 19:26:59,589 Epoch[51] Batch [1180]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.093654,	
2017-07-20 19:27:03,732 Epoch[51] Batch [1190]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.093601,	
2017-07-20 19:27:07,946 Epoch[51] Batch [1200]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.093582,	
2017-07-20 19:27:12,232 Epoch[51] Batch [1210]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.093530,	
2017-07-20 19:27:16,528 Epoch[51] Batch [1220]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093486,	
2017-07-20 19:27:20,690 Epoch[51] Batch [1230]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093463,	
2017-07-20 19:27:24,939 Epoch[51] Batch [1240]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.093400,	
2017-07-20 19:27:29,044 Epoch[51] Batch [1250]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093402,	
2017-07-20 19:27:33,190 Epoch[51] Batch [1260]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.093336,	
2017-07-20 19:27:37,304 Epoch[51] Batch [1270]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093308,	
2017-07-20 19:27:41,432 Epoch[51] Batch [1280]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093275,	
2017-07-20 19:27:45,595 Epoch[51] Batch [1290]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093200,	
2017-07-20 19:27:49,834 Epoch[51] Batch [1300]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.093122,	
2017-07-20 19:27:53,999 Epoch[51] Batch [1310]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.093054,	
2017-07-20 19:27:58,284 Epoch[51] Batch [1320]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.093049,	
2017-07-20 19:28:02,326 Epoch[51] Batch [1330]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.092923,	
2017-07-20 19:28:06,490 Epoch[51] Batch [1340]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.092941,	
2017-07-20 19:28:10,778 Epoch[51] Batch [1350]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.092941,	
2017-07-20 19:28:14,871 Epoch[51] Batch [1360]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092880,	
2017-07-20 19:28:19,059 Epoch[51] Batch [1370]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.092882,	
2017-07-20 19:28:23,169 Epoch[51] Batch [1380]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.092891,	
2017-07-20 19:28:27,277 Epoch[51] Batch [1390]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.092850,	
2017-07-20 19:28:31,414 Epoch[51] Batch [1400]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.092914,	
2017-07-20 19:28:35,678 Epoch[51] Batch [1410]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.092922,	
2017-07-20 19:28:39,857 Epoch[51] Batch [1420]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092934,	
2017-07-20 19:28:44,057 Epoch[51] Batch [1430]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.092872,	
2017-07-20 19:28:48,264 Epoch[51] Batch [1440]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.092822,	
2017-07-20 19:28:52,305 Epoch[51] Batch [1450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.092760,	
2017-07-20 19:28:56,441 Epoch[51] Batch [1460]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.092703,	
2017-07-20 19:29:00,523 Epoch[51] Batch [1470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.092661,	
2017-07-20 19:29:04,529 Epoch[51] Batch [1480]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.092675,	
2017-07-20 19:29:07,102 Epoch[51] Train-FCNLogLoss=0.092614
2017-07-20 19:29:07,102 Epoch[51] Time cost=617.530
2017-07-20 19:29:07,775 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0052.params"
2017-07-20 19:29:10,979 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0052.states"
2017-07-20 19:29:15,898 Epoch[52] Batch [10]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.080872,	
2017-07-20 19:29:20,089 Epoch[52] Batch [20]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.082566,	
2017-07-20 19:29:24,236 Epoch[52] Batch [30]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.083487,	
2017-07-20 19:29:28,509 Epoch[52] Batch [40]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.083228,	
2017-07-20 19:29:32,800 Epoch[52] Batch [50]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.085052,	
2017-07-20 19:29:37,020 Epoch[52] Batch [60]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.084188,	
2017-07-20 19:29:41,046 Epoch[52] Batch [70]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.085472,	
2017-07-20 19:29:45,121 Epoch[52] Batch [80]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.086212,	
2017-07-20 19:29:49,233 Epoch[52] Batch [90]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.085659,	
2017-07-20 19:29:53,332 Epoch[52] Batch [100]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085177,	
2017-07-20 19:29:57,592 Epoch[52] Batch [110]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.085241,	
2017-07-20 19:30:01,632 Epoch[52] Batch [120]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.085121,	
2017-07-20 19:30:05,729 Epoch[52] Batch [130]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.085713,	
2017-07-20 19:30:09,998 Epoch[52] Batch [140]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.085277,	
2017-07-20 19:30:14,203 Epoch[52] Batch [150]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.085515,	
2017-07-20 19:30:18,516 Epoch[52] Batch [160]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.085445,	
2017-07-20 19:30:22,646 Epoch[52] Batch [170]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.086251,	
2017-07-20 19:30:26,816 Epoch[52] Batch [180]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.086337,	
2017-07-20 19:30:31,058 Epoch[52] Batch [190]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.086800,	
2017-07-20 19:30:35,112 Epoch[52] Batch [200]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.086888,	
2017-07-20 19:30:39,120 Epoch[52] Batch [210]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.086789,	
2017-07-20 19:30:43,279 Epoch[52] Batch [220]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.087344,	
2017-07-20 19:30:47,473 Epoch[52] Batch [230]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.087032,	
2017-07-20 19:30:51,532 Epoch[52] Batch [240]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.086996,	
2017-07-20 19:30:55,742 Epoch[52] Batch [250]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086897,	
2017-07-20 19:30:59,929 Epoch[52] Batch [260]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.086992,	
2017-07-20 19:31:04,157 Epoch[52] Batch [270]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.086821,	
2017-07-20 19:31:08,238 Epoch[52] Batch [280]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.086822,	
2017-07-20 19:31:12,403 Epoch[52] Batch [290]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-20 19:31:16,715 Epoch[52] Batch [300]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.086809,	
2017-07-20 19:31:20,937 Epoch[52] Batch [310]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.087198,	
2017-07-20 19:31:25,017 Epoch[52] Batch [320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.086975,	
2017-07-20 19:31:29,140 Epoch[52] Batch [330]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.087205,	
2017-07-20 19:31:33,258 Epoch[52] Batch [340]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.087267,	
2017-07-20 19:31:37,504 Epoch[52] Batch [350]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087511,	
2017-07-20 19:31:41,618 Epoch[52] Batch [360]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.087392,	
2017-07-20 19:31:45,809 Epoch[52] Batch [370]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.087417,	
2017-07-20 19:31:50,177 Epoch[52] Batch [380]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087414,	
2017-07-20 19:31:54,264 Epoch[52] Batch [390]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087409,	
2017-07-20 19:31:58,511 Epoch[52] Batch [400]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087300,	
2017-07-20 19:32:02,577 Epoch[52] Batch [410]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.087200,	
2017-07-20 19:32:06,710 Epoch[52] Batch [420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087188,	
2017-07-20 19:32:10,844 Epoch[52] Batch [430]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087250,	
2017-07-20 19:32:14,964 Epoch[52] Batch [440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.087199,	
2017-07-20 19:32:19,073 Epoch[52] Batch [450]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.087114,	
2017-07-20 19:32:23,252 Epoch[52] Batch [460]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.086904,	
2017-07-20 19:32:27,374 Epoch[52] Batch [470]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.086722,	
2017-07-20 19:32:31,440 Epoch[52] Batch [480]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.086595,	
2017-07-20 19:32:35,598 Epoch[52] Batch [490]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.086554,	
2017-07-20 19:32:39,696 Epoch[52] Batch [500]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.086356,	
2017-07-20 19:32:43,818 Epoch[52] Batch [510]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.086291,	
2017-07-20 19:32:48,003 Epoch[52] Batch [520]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.086310,	
2017-07-20 19:32:52,065 Epoch[52] Batch [530]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.086256,	
2017-07-20 19:32:56,272 Epoch[52] Batch [540]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.086128,	
2017-07-20 19:33:00,330 Epoch[52] Batch [550]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.086248,	
2017-07-20 19:33:04,402 Epoch[52] Batch [560]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.086162,	
2017-07-20 19:33:08,495 Epoch[52] Batch [570]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.086052,	
2017-07-20 19:33:12,720 Epoch[52] Batch [580]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.086107,	
2017-07-20 19:33:16,832 Epoch[52] Batch [590]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.085990,	
2017-07-20 19:33:20,993 Epoch[52] Batch [600]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.086133,	
2017-07-20 19:33:25,140 Epoch[52] Batch [610]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085950,	
2017-07-20 19:33:29,420 Epoch[52] Batch [620]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.085797,	
2017-07-20 19:33:33,435 Epoch[52] Batch [630]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.085811,	
2017-07-20 19:33:37,707 Epoch[52] Batch [640]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.085781,	
2017-07-20 19:33:41,778 Epoch[52] Batch [650]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.085573,	
2017-07-20 19:33:45,925 Epoch[52] Batch [660]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085570,	
2017-07-20 19:33:50,181 Epoch[52] Batch [670]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.085559,	
2017-07-20 19:33:54,342 Epoch[52] Batch [680]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.085693,	
2017-07-20 19:33:58,474 Epoch[52] Batch [690]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.085534,	
2017-07-20 19:34:02,714 Epoch[52] Batch [700]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.085536,	
2017-07-20 19:34:06,899 Epoch[52] Batch [710]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.085536,	
2017-07-20 19:34:11,058 Epoch[52] Batch [720]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.085572,	
2017-07-20 19:34:15,282 Epoch[52] Batch [730]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.085575,	
2017-07-20 19:34:19,473 Epoch[52] Batch [740]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.085432,	
2017-07-20 19:34:23,553 Epoch[52] Batch [750]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.085496,	
2017-07-20 19:34:27,807 Epoch[52] Batch [760]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.085506,	
2017-07-20 19:34:32,133 Epoch[52] Batch [770]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.085384,	
2017-07-20 19:34:36,370 Epoch[52] Batch [780]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.085389,	
2017-07-20 19:34:40,593 Epoch[52] Batch [790]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.085548,	
2017-07-20 19:34:44,930 Epoch[52] Batch [800]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.085650,	
2017-07-20 19:34:48,916 Epoch[52] Batch [810]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.085606,	
2017-07-20 19:34:53,138 Epoch[52] Batch [820]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.085586,	
2017-07-20 19:34:57,534 Epoch[52] Batch [830]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.085610,	
2017-07-20 19:35:01,684 Epoch[52] Batch [840]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085540,	
2017-07-20 19:35:05,863 Epoch[52] Batch [850]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.085606,	
2017-07-20 19:35:10,012 Epoch[52] Batch [860]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085551,	
2017-07-20 19:35:14,057 Epoch[52] Batch [870]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.085540,	
2017-07-20 19:35:18,128 Epoch[52] Batch [880]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.085447,	
2017-07-20 19:35:22,277 Epoch[52] Batch [890]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085407,	
2017-07-20 19:35:26,374 Epoch[52] Batch [900]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085362,	
2017-07-20 19:35:30,521 Epoch[52] Batch [910]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085330,	
2017-07-20 19:35:34,535 Epoch[52] Batch [920]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.085423,	
2017-07-20 19:35:38,522 Epoch[52] Batch [930]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.085467,	
2017-07-20 19:35:42,722 Epoch[52] Batch [940]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085358,	
2017-07-20 19:35:46,868 Epoch[52] Batch [950]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.085216,	
2017-07-20 19:35:51,188 Epoch[52] Batch [960]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.085227,	
2017-07-20 19:35:55,308 Epoch[52] Batch [970]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.085169,	
2017-07-20 19:35:59,578 Epoch[52] Batch [980]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.085175,	
2017-07-20 19:36:03,612 Epoch[52] Batch [990]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.085201,	
2017-07-20 19:36:07,648 Epoch[52] Batch [1000]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.085161,	
2017-07-20 19:36:11,915 Epoch[52] Batch [1010]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.085130,	
2017-07-20 19:36:16,247 Epoch[52] Batch [1020]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.085152,	
2017-07-20 19:36:20,425 Epoch[52] Batch [1030]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.085206,	
2017-07-20 19:36:24,611 Epoch[52] Batch [1040]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.085266,	
2017-07-20 19:36:28,709 Epoch[52] Batch [1050]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085228,	
2017-07-20 19:36:32,808 Epoch[52] Batch [1060]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085250,	
2017-07-20 19:36:36,961 Epoch[52] Batch [1070]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.085248,	
2017-07-20 19:36:41,113 Epoch[52] Batch [1080]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.085245,	
2017-07-20 19:36:45,283 Epoch[52] Batch [1090]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.085322,	
2017-07-20 19:36:49,297 Epoch[52] Batch [1100]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.085285,	
2017-07-20 19:36:53,447 Epoch[52] Batch [1110]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085224,	
2017-07-20 19:36:57,504 Epoch[52] Batch [1120]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.085209,	
2017-07-20 19:37:01,507 Epoch[52] Batch [1130]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.085164,	
2017-07-20 19:37:05,717 Epoch[52] Batch [1140]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.085170,	
2017-07-20 19:37:09,702 Epoch[52] Batch [1150]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.085149,	
2017-07-20 19:37:13,800 Epoch[52] Batch [1160]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085061,	
2017-07-20 19:37:18,040 Epoch[52] Batch [1170]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.085093,	
2017-07-20 19:37:22,386 Epoch[52] Batch [1180]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.085116,	
2017-07-20 19:37:26,557 Epoch[52] Batch [1190]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.085108,	
2017-07-20 19:37:30,657 Epoch[52] Batch [1200]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085158,	
2017-07-20 19:37:34,841 Epoch[52] Batch [1210]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.085093,	
2017-07-20 19:37:39,071 Epoch[52] Batch [1220]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.085009,	
2017-07-20 19:37:43,317 Epoch[52] Batch [1230]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.085029,	
2017-07-20 19:37:47,592 Epoch[52] Batch [1240]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.085026,	
2017-07-20 19:37:51,868 Epoch[52] Batch [1250]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.084985,	
2017-07-20 19:37:56,037 Epoch[52] Batch [1260]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.085031,	
2017-07-20 19:38:00,104 Epoch[52] Batch [1270]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.085019,	
2017-07-20 19:38:04,162 Epoch[52] Batch [1280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.084986,	
2017-07-20 19:38:08,317 Epoch[52] Batch [1290]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.084940,	
2017-07-20 19:38:12,365 Epoch[52] Batch [1300]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.084897,	
2017-07-20 19:38:16,517 Epoch[52] Batch [1310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.084866,	
2017-07-20 19:38:20,771 Epoch[52] Batch [1320]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.084803,	
2017-07-20 19:38:25,086 Epoch[52] Batch [1330]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.084801,	
2017-07-20 19:38:29,448 Epoch[52] Batch [1340]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.084840,	
2017-07-20 19:38:33,704 Epoch[52] Batch [1350]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.084792,	
2017-07-20 19:38:37,910 Epoch[52] Batch [1360]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.084765,	
2017-07-20 19:38:42,103 Epoch[52] Batch [1370]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.084744,	
2017-07-20 19:38:46,414 Epoch[52] Batch [1380]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.084738,	
2017-07-20 19:38:50,861 Epoch[52] Batch [1390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.084662,	
2017-07-20 19:38:54,987 Epoch[52] Batch [1400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084631,	
2017-07-20 19:38:58,999 Epoch[52] Batch [1410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.084626,	
2017-07-20 19:39:03,162 Epoch[52] Batch [1420]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084635,	
2017-07-20 19:39:07,222 Epoch[52] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.084568,	
2017-07-20 19:39:11,384 Epoch[52] Batch [1440]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.084508,	
2017-07-20 19:39:15,524 Epoch[52] Batch [1450]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084468,	
2017-07-20 19:39:19,796 Epoch[52] Batch [1460]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.084449,	
2017-07-20 19:39:23,734 Epoch[52] Batch [1470]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.084462,	
2017-07-20 19:39:27,812 Epoch[52] Batch [1480]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.084442,	
2017-07-20 19:39:30,228 Epoch[52] Train-FCNLogLoss=0.084496
2017-07-20 19:39:30,229 Epoch[52] Time cost=619.249
2017-07-20 19:39:30,914 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0053.params"
2017-07-20 19:39:34,189 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0053.states"
2017-07-20 19:39:39,131 Epoch[53] Batch [10]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.093259,	
2017-07-20 19:39:43,502 Epoch[53] Batch [20]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091730,	
2017-07-20 19:39:47,640 Epoch[53] Batch [30]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091193,	
2017-07-20 19:39:51,886 Epoch[53] Batch [40]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.091179,	
2017-07-20 19:39:56,078 Epoch[53] Batch [50]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.090361,	
2017-07-20 19:40:00,238 Epoch[53] Batch [60]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.090614,	
2017-07-20 19:40:04,574 Epoch[53] Batch [70]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.091309,	
2017-07-20 19:40:08,823 Epoch[53] Batch [80]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.090620,	
2017-07-20 19:40:13,013 Epoch[53] Batch [90]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.090518,	
2017-07-20 19:40:17,165 Epoch[53] Batch [100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.091340,	
2017-07-20 19:40:21,454 Epoch[53] Batch [110]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.090763,	
2017-07-20 19:40:25,760 Epoch[53] Batch [120]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.090281,	
2017-07-20 19:40:29,942 Epoch[53] Batch [130]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.090265,	
2017-07-20 19:40:34,268 Epoch[53] Batch [140]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.089950,	
2017-07-20 19:40:38,522 Epoch[53] Batch [150]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.089287,	
2017-07-20 19:40:42,713 Epoch[53] Batch [160]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.089718,	
2017-07-20 19:40:46,818 Epoch[53] Batch [170]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.089312,	
2017-07-20 19:40:50,999 Epoch[53] Batch [180]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.089417,	
2017-07-20 19:40:55,134 Epoch[53] Batch [190]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.088888,	
2017-07-20 19:40:59,362 Epoch[53] Batch [200]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.088469,	
2017-07-20 19:41:03,406 Epoch[53] Batch [210]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.088087,	
2017-07-20 19:41:07,610 Epoch[53] Batch [220]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087884,	
2017-07-20 19:41:11,660 Epoch[53] Batch [230]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.087751,	
2017-07-20 19:41:16,020 Epoch[53] Batch [240]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087478,	
2017-07-20 19:41:20,282 Epoch[53] Batch [250]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087226,	
2017-07-20 19:41:24,437 Epoch[53] Batch [260]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.087127,	
2017-07-20 19:41:28,452 Epoch[53] Batch [270]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.087023,	
2017-07-20 19:41:32,567 Epoch[53] Batch [280]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.086574,	
2017-07-20 19:41:36,717 Epoch[53] Batch [290]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.086237,	
2017-07-20 19:41:40,765 Epoch[53] Batch [300]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.086098,	
2017-07-20 19:41:44,908 Epoch[53] Batch [310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.085943,	
2017-07-20 19:41:49,149 Epoch[53] Batch [320]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.086286,	
2017-07-20 19:41:53,223 Epoch[53] Batch [330]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.086038,	
2017-07-20 19:41:57,338 Epoch[53] Batch [340]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.085952,	
2017-07-20 19:42:01,488 Epoch[53] Batch [350]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.085966,	
2017-07-20 19:42:05,659 Epoch[53] Batch [360]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.085836,	
2017-07-20 19:42:09,801 Epoch[53] Batch [370]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.085754,	
2017-07-20 19:42:14,060 Epoch[53] Batch [380]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.085821,	
2017-07-20 19:42:18,263 Epoch[53] Batch [390]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085660,	
2017-07-20 19:42:22,561 Epoch[53] Batch [400]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.085544,	
2017-07-20 19:42:26,675 Epoch[53] Batch [410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.085242,	
2017-07-20 19:42:30,942 Epoch[53] Batch [420]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.085249,	
2017-07-20 19:42:35,182 Epoch[53] Batch [430]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.085179,	
2017-07-20 19:42:39,234 Epoch[53] Batch [440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.085118,	
2017-07-20 19:42:43,401 Epoch[53] Batch [450]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.085160,	
2017-07-20 19:42:47,559 Epoch[53] Batch [460]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.085069,	
2017-07-20 19:42:51,633 Epoch[53] Batch [470]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.084992,	
2017-07-20 19:42:55,741 Epoch[53] Batch [480]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084839,	
2017-07-20 19:42:59,767 Epoch[53] Batch [490]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.084853,	
2017-07-20 19:43:04,045 Epoch[53] Batch [500]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.084806,	
2017-07-20 19:43:08,192 Epoch[53] Batch [510]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084518,	
2017-07-20 19:43:12,443 Epoch[53] Batch [520]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.084464,	
2017-07-20 19:43:16,548 Epoch[53] Batch [530]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084317,	
2017-07-20 19:43:20,656 Epoch[53] Batch [540]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084221,	
2017-07-20 19:43:24,791 Epoch[53] Batch [550]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.084225,	
2017-07-20 19:43:28,836 Epoch[53] Batch [560]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.084133,	
2017-07-20 19:43:32,922 Epoch[53] Batch [570]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.084004,	
2017-07-20 19:43:37,208 Epoch[53] Batch [580]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.084080,	
2017-07-20 19:43:41,252 Epoch[53] Batch [590]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.083982,	
2017-07-20 19:43:45,417 Epoch[53] Batch [600]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.083914,	
2017-07-20 19:43:49,658 Epoch[53] Batch [610]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.083842,	
2017-07-20 19:43:53,880 Epoch[53] Batch [620]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.083743,	
2017-07-20 19:43:58,184 Epoch[53] Batch [630]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.083789,	
2017-07-20 19:44:02,478 Epoch[53] Batch [640]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.083745,	
2017-07-20 19:44:06,777 Epoch[53] Batch [650]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.083797,	
2017-07-20 19:44:10,929 Epoch[53] Batch [660]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.083830,	
2017-07-20 19:44:15,205 Epoch[53] Batch [670]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.083832,	
2017-07-20 19:44:19,470 Epoch[53] Batch [680]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.083888,	
2017-07-20 19:44:23,822 Epoch[53] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.083857,	
2017-07-20 19:44:28,049 Epoch[53] Batch [700]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.083925,	
2017-07-20 19:44:32,443 Epoch[53] Batch [710]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.083933,	
2017-07-20 19:44:36,730 Epoch[53] Batch [720]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.083926,	
2017-07-20 19:44:40,963 Epoch[53] Batch [730]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.083973,	
2017-07-20 19:44:45,208 Epoch[53] Batch [740]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.083798,	
2017-07-20 19:44:49,228 Epoch[53] Batch [750]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.083843,	
2017-07-20 19:44:53,373 Epoch[53] Batch [760]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.083793,	
2017-07-20 19:44:57,671 Epoch[53] Batch [770]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.083805,	
2017-07-20 19:45:01,945 Epoch[53] Batch [780]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.083928,	
2017-07-20 19:45:06,335 Epoch[53] Batch [790]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.083917,	
2017-07-20 19:45:10,747 Epoch[53] Batch [800]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.083853,	
2017-07-20 19:45:14,934 Epoch[53] Batch [810]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.083841,	
2017-07-20 19:45:18,960 Epoch[53] Batch [820]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.083876,	
2017-07-20 19:45:23,218 Epoch[53] Batch [830]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.083803,	
2017-07-20 19:45:27,578 Epoch[53] Batch [840]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.083792,	
2017-07-20 19:45:31,790 Epoch[53] Batch [850]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.083818,	
2017-07-20 19:45:36,135 Epoch[53] Batch [860]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.083876,	
2017-07-20 19:45:40,493 Epoch[53] Batch [870]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.083840,	
2017-07-20 19:45:44,723 Epoch[53] Batch [880]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.083852,	
2017-07-20 19:45:48,926 Epoch[53] Batch [890]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.083858,	
2017-07-20 19:45:53,276 Epoch[53] Batch [900]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.083854,	
2017-07-20 19:45:57,479 Epoch[53] Batch [910]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.083809,	
2017-07-20 19:46:01,733 Epoch[53] Batch [920]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.083853,	
2017-07-20 19:46:06,196 Epoch[53] Batch [930]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.083791,	
2017-07-20 19:46:10,603 Epoch[53] Batch [940]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.083855,	
2017-07-20 19:46:14,815 Epoch[53] Batch [950]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.083870,	
2017-07-20 19:46:19,146 Epoch[53] Batch [960]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.083904,	
2017-07-20 19:46:23,248 Epoch[53] Batch [970]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.083847,	
2017-07-20 19:46:27,578 Epoch[53] Batch [980]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.083722,	
2017-07-20 19:46:31,788 Epoch[53] Batch [990]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.083746,	
2017-07-20 19:46:35,845 Epoch[53] Batch [1000]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.083661,	
2017-07-20 19:46:40,045 Epoch[53] Batch [1010]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.083774,	
2017-07-20 19:46:44,132 Epoch[53] Batch [1020]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.083701,	
2017-07-20 19:46:48,227 Epoch[53] Batch [1030]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.083659,	
2017-07-20 19:46:52,335 Epoch[53] Batch [1040]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.083608,	
2017-07-20 19:46:56,294 Epoch[53] Batch [1050]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.083477,	
2017-07-20 19:47:00,389 Epoch[53] Batch [1060]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.083517,	
2017-07-20 19:47:04,446 Epoch[53] Batch [1070]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.083558,	
2017-07-20 19:47:08,669 Epoch[53] Batch [1080]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.083500,	
2017-07-20 19:47:12,922 Epoch[53] Batch [1090]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.083509,	
2017-07-20 19:47:17,062 Epoch[53] Batch [1100]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.083510,	
2017-07-20 19:47:21,233 Epoch[53] Batch [1110]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.083494,	
2017-07-20 19:47:25,284 Epoch[53] Batch [1120]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.083478,	
2017-07-20 19:47:29,697 Epoch[53] Batch [1130]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.083450,	
2017-07-20 19:47:33,727 Epoch[53] Batch [1140]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.083410,	
2017-07-20 19:47:37,851 Epoch[53] Batch [1150]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.083437,	
2017-07-20 19:47:42,024 Epoch[53] Batch [1160]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.083469,	
2017-07-20 19:47:46,258 Epoch[53] Batch [1170]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.083404,	
2017-07-20 19:47:50,356 Epoch[53] Batch [1180]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.083413,	
2017-07-20 19:47:54,563 Epoch[53] Batch [1190]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.083328,	
2017-07-20 19:47:58,746 Epoch[53] Batch [1200]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.083336,	
2017-07-20 19:48:02,974 Epoch[53] Batch [1210]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.083394,	
2017-07-20 19:48:07,171 Epoch[53] Batch [1220]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.083448,	
2017-07-20 19:48:11,291 Epoch[53] Batch [1230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.083454,	
2017-07-20 19:48:15,577 Epoch[53] Batch [1240]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.083476,	
2017-07-20 19:48:19,723 Epoch[53] Batch [1250]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.083434,	
2017-07-20 19:48:23,780 Epoch[53] Batch [1260]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.083506,	
2017-07-20 19:48:27,692 Epoch[53] Batch [1270]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.083573,	
2017-07-20 19:48:31,869 Epoch[53] Batch [1280]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.083519,	
2017-07-20 19:48:36,112 Epoch[53] Batch [1290]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.083515,	
2017-07-20 19:48:40,334 Epoch[53] Batch [1300]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.083433,	
2017-07-20 19:48:44,376 Epoch[53] Batch [1310]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.083400,	
2017-07-20 19:48:48,545 Epoch[53] Batch [1320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.083336,	
2017-07-20 19:48:52,642 Epoch[53] Batch [1330]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.083257,	
2017-07-20 19:48:56,812 Epoch[53] Batch [1340]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.083226,	
2017-07-20 19:49:00,927 Epoch[53] Batch [1350]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.083181,	
2017-07-20 19:49:05,085 Epoch[53] Batch [1360]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.083148,	
2017-07-20 19:49:09,189 Epoch[53] Batch [1370]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.083108,	
2017-07-20 19:49:13,316 Epoch[53] Batch [1380]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.083088,	
2017-07-20 19:49:17,546 Epoch[53] Batch [1390]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.083123,	
2017-07-20 19:49:21,741 Epoch[53] Batch [1400]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.083129,	
2017-07-20 19:49:25,877 Epoch[53] Batch [1410]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.083141,	
2017-07-20 19:49:29,869 Epoch[53] Batch [1420]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.083173,	
2017-07-20 19:49:34,224 Epoch[53] Batch [1430]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.083198,	
2017-07-20 19:49:38,217 Epoch[53] Batch [1440]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.083287,	
2017-07-20 19:49:42,408 Epoch[53] Batch [1450]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.083389,	
2017-07-20 19:49:46,465 Epoch[53] Batch [1460]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.083425,	
2017-07-20 19:49:50,590 Epoch[53] Batch [1470]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.083469,	
2017-07-20 19:49:54,827 Epoch[53] Batch [1480]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.083512,	
2017-07-20 19:49:57,366 Epoch[53] Train-FCNLogLoss=0.083514
2017-07-20 19:49:57,366 Epoch[53] Time cost=623.176
2017-07-20 19:49:58,081 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0054.params"
2017-07-20 19:50:01,234 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0054.states"
2017-07-20 19:50:06,338 Epoch[54] Batch [10]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.083083,	
2017-07-20 19:50:10,558 Epoch[54] Batch [20]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.085783,	
2017-07-20 19:50:14,694 Epoch[54] Batch [30]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087039,	
2017-07-20 19:50:18,836 Epoch[54] Batch [40]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.083876,	
2017-07-20 19:50:22,868 Epoch[54] Batch [50]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.083227,	
2017-07-20 19:50:26,844 Epoch[54] Batch [60]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.082759,	
2017-07-20 19:50:31,117 Epoch[54] Batch [70]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.082174,	
2017-07-20 19:50:35,259 Epoch[54] Batch [80]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.081366,	
2017-07-20 19:50:39,271 Epoch[54] Batch [90]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.080778,	
2017-07-20 19:50:43,386 Epoch[54] Batch [100]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.081476,	
2017-07-20 19:50:47,496 Epoch[54] Batch [110]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.081703,	
2017-07-20 19:50:51,689 Epoch[54] Batch [120]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.081863,	
2017-07-20 19:50:55,665 Epoch[54] Batch [130]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.081497,	
2017-07-20 19:50:59,865 Epoch[54] Batch [140]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.081122,	
2017-07-20 19:51:04,030 Epoch[54] Batch [150]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.080675,	
2017-07-20 19:51:08,170 Epoch[54] Batch [160]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.080950,	
2017-07-20 19:51:12,436 Epoch[54] Batch [170]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.081142,	
2017-07-20 19:51:16,726 Epoch[54] Batch [180]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.081236,	
2017-07-20 19:51:20,900 Epoch[54] Batch [190]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.081306,	
2017-07-20 19:51:24,945 Epoch[54] Batch [200]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.080652,	
2017-07-20 19:51:29,157 Epoch[54] Batch [210]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.081065,	
2017-07-20 19:51:33,494 Epoch[54] Batch [220]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.081232,	
2017-07-20 19:51:37,826 Epoch[54] Batch [230]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.081188,	
2017-07-20 19:51:42,172 Epoch[54] Batch [240]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.080935,	
2017-07-20 19:51:46,482 Epoch[54] Batch [250]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.080555,	
2017-07-20 19:51:50,699 Epoch[54] Batch [260]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.080811,	
2017-07-20 19:51:54,785 Epoch[54] Batch [270]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.080377,	
2017-07-20 19:51:58,933 Epoch[54] Batch [280]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.080428,	
2017-07-20 19:52:03,314 Epoch[54] Batch [290]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.080633,	
2017-07-20 19:52:07,406 Epoch[54] Batch [300]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.080743,	
2017-07-20 19:52:11,779 Epoch[54] Batch [310]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.080685,	
2017-07-20 19:52:16,309 Epoch[54] Batch [320]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.080565,	
2017-07-20 19:52:20,877 Epoch[54] Batch [330]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.080414,	
2017-07-20 19:52:25,586 Epoch[54] Batch [340]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.080896,	
2017-07-20 19:52:30,253 Epoch[54] Batch [350]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.081046,	
2017-07-20 19:52:34,688 Epoch[54] Batch [360]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.081254,	
2017-07-20 19:52:39,083 Epoch[54] Batch [370]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.081487,	
2017-07-20 19:52:43,817 Epoch[54] Batch [380]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.081539,	
2017-07-20 19:52:48,707 Epoch[54] Batch [390]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.081367,	
2017-07-20 19:52:53,205 Epoch[54] Batch [400]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.081236,	
2017-07-20 19:52:57,856 Epoch[54] Batch [410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.081329,	
2017-07-20 19:53:02,560 Epoch[54] Batch [420]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.081315,	
2017-07-20 19:53:06,992 Epoch[54] Batch [430]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.081242,	
2017-07-20 19:53:11,444 Epoch[54] Batch [440]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.081131,	
2017-07-20 19:53:15,727 Epoch[54] Batch [450]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.081055,	
2017-07-20 19:53:20,324 Epoch[54] Batch [460]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.081043,	
2017-07-20 19:53:25,141 Epoch[54] Batch [470]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.081031,	
2017-07-20 19:53:30,031 Epoch[54] Batch [480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.081248,	
2017-07-20 19:53:34,771 Epoch[54] Batch [490]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.081348,	
2017-07-20 19:53:39,497 Epoch[54] Batch [500]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.081716,	
2017-07-20 19:53:43,659 Epoch[54] Batch [510]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.081997,	
2017-07-20 19:53:48,085 Epoch[54] Batch [520]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.082020,	
2017-07-20 19:53:52,194 Epoch[54] Batch [530]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.082073,	
2017-07-20 19:53:56,482 Epoch[54] Batch [540]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.082191,	
2017-07-20 19:54:00,761 Epoch[54] Batch [550]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.082227,	
2017-07-20 19:54:04,849 Epoch[54] Batch [560]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.082150,	
2017-07-20 19:54:09,067 Epoch[54] Batch [570]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.082074,	
2017-07-20 19:54:13,306 Epoch[54] Batch [580]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.082075,	
2017-07-20 19:54:17,528 Epoch[54] Batch [590]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.082109,	
2017-07-20 19:54:21,761 Epoch[54] Batch [600]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.082090,	
2017-07-20 19:54:25,750 Epoch[54] Batch [610]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.082058,	
2017-07-20 19:54:30,172 Epoch[54] Batch [620]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.082119,	
2017-07-20 19:54:34,312 Epoch[54] Batch [630]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.082128,	
2017-07-20 19:54:38,502 Epoch[54] Batch [640]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.082179,	
2017-07-20 19:54:42,812 Epoch[54] Batch [650]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.082007,	
2017-07-20 19:54:47,128 Epoch[54] Batch [660]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.081892,	
2017-07-20 19:54:51,275 Epoch[54] Batch [670]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.081995,	
2017-07-20 19:54:55,370 Epoch[54] Batch [680]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.082060,	
2017-07-20 19:54:59,564 Epoch[54] Batch [690]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.082093,	
2017-07-20 19:55:03,535 Epoch[54] Batch [700]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.082282,	
2017-07-20 19:55:07,813 Epoch[54] Batch [710]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.082287,	
2017-07-20 19:55:11,939 Epoch[54] Batch [720]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.082134,	
2017-07-20 19:55:16,063 Epoch[54] Batch [730]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.082014,	
2017-07-20 19:55:20,267 Epoch[54] Batch [740]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.082065,	
2017-07-20 19:55:24,486 Epoch[54] Batch [750]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.082137,	
2017-07-20 19:55:28,526 Epoch[54] Batch [760]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.082151,	
2017-07-20 19:55:32,868 Epoch[54] Batch [770]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.082132,	
2017-07-20 19:55:37,258 Epoch[54] Batch [780]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.082110,	
2017-07-20 19:55:41,807 Epoch[54] Batch [790]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.082047,	
2017-07-20 19:55:46,288 Epoch[54] Batch [800]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.081994,	
2017-07-20 19:55:51,164 Epoch[54] Batch [810]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.081938,	
2017-07-20 19:55:55,606 Epoch[54] Batch [820]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.081904,	
2017-07-20 19:56:00,184 Epoch[54] Batch [830]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.081948,	
2017-07-20 19:56:04,588 Epoch[54] Batch [840]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.081998,	
2017-07-20 19:56:09,004 Epoch[54] Batch [850]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.082059,	
2017-07-20 19:56:13,238 Epoch[54] Batch [860]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.082299,	
2017-07-20 19:56:17,545 Epoch[54] Batch [870]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.082582,	
2017-07-20 19:56:22,293 Epoch[54] Batch [880]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.082670,	
2017-07-20 19:56:26,710 Epoch[54] Batch [890]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.082743,	
2017-07-20 19:56:31,658 Epoch[54] Batch [900]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.083940,	
2017-07-20 19:56:36,045 Epoch[54] Batch [910]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.084607,	
2017-07-20 19:56:40,266 Epoch[54] Batch [920]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.085535,	
2017-07-20 19:56:44,678 Epoch[54] Batch [930]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.086911,	
2017-07-20 19:56:49,158 Epoch[54] Batch [940]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087682,	
2017-07-20 19:56:54,165 Epoch[54] Batch [950]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088337,	
2017-07-20 19:56:59,067 Epoch[54] Batch [960]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088683,	
2017-07-20 19:57:03,589 Epoch[54] Batch [970]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088965,	
2017-07-20 19:57:07,820 Epoch[54] Batch [980]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.089207,	
2017-07-20 19:57:12,512 Epoch[54] Batch [990]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089244,	
2017-07-20 19:57:17,301 Epoch[54] Batch [1000]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089461,	
2017-07-20 19:57:21,844 Epoch[54] Batch [1010]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.089983,	
2017-07-20 19:57:26,581 Epoch[54] Batch [1020]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090452,	
2017-07-20 19:57:31,458 Epoch[54] Batch [1030]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.091010,	
2017-07-20 19:57:36,170 Epoch[54] Batch [1040]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.091606,	
2017-07-20 19:57:40,750 Epoch[54] Batch [1050]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091826,	
2017-07-20 19:57:45,361 Epoch[54] Batch [1060]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091940,	
2017-07-20 19:57:50,018 Epoch[54] Batch [1070]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092042,	
2017-07-20 19:57:54,584 Epoch[54] Batch [1080]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092261,	
2017-07-20 19:57:59,347 Epoch[54] Batch [1090]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.092436,	
2017-07-20 19:58:04,001 Epoch[54] Batch [1100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.092671,	
2017-07-20 19:58:08,739 Epoch[54] Batch [1110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092874,	
2017-07-20 19:58:13,262 Epoch[54] Batch [1120]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.093112,	
2017-07-20 19:58:17,947 Epoch[54] Batch [1130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.093151,	
2017-07-20 19:58:22,764 Epoch[54] Batch [1140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.093252,	
2017-07-20 19:58:27,614 Epoch[54] Batch [1150]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.093332,	
2017-07-20 19:58:32,352 Epoch[54] Batch [1160]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.093408,	
2017-07-20 19:58:37,069 Epoch[54] Batch [1170]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.093443,	
2017-07-20 19:58:42,269 Epoch[54] Batch [1180]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093458,	
2017-07-20 19:58:47,141 Epoch[54] Batch [1190]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.093527,	
2017-07-20 19:58:52,128 Epoch[54] Batch [1200]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093463,	
2017-07-20 19:58:56,848 Epoch[54] Batch [1210]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.093455,	
2017-07-20 19:59:01,424 Epoch[54] Batch [1220]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.093447,	
2017-07-20 19:59:06,616 Epoch[54] Batch [1230]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093493,	
2017-07-20 19:59:11,572 Epoch[54] Batch [1240]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093537,	
2017-07-20 19:59:16,484 Epoch[54] Batch [1250]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093594,	
2017-07-20 19:59:21,669 Epoch[54] Batch [1260]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093541,	
2017-07-20 19:59:26,312 Epoch[54] Batch [1270]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.093577,	
2017-07-20 19:59:31,124 Epoch[54] Batch [1280]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.093641,	
2017-07-20 19:59:35,594 Epoch[54] Batch [1290]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.093682,	
2017-07-20 19:59:40,654 Epoch[54] Batch [1300]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.093690,	
2017-07-20 19:59:45,460 Epoch[54] Batch [1310]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.093721,	
2017-07-20 19:59:50,457 Epoch[54] Batch [1320]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093694,	
2017-07-20 19:59:55,692 Epoch[54] Batch [1330]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093724,	
2017-07-20 20:00:00,594 Epoch[54] Batch [1340]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.093742,	
2017-07-20 20:00:05,418 Epoch[54] Batch [1350]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.093814,	
2017-07-20 20:00:09,966 Epoch[54] Batch [1360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093895,	
2017-07-20 20:00:14,488 Epoch[54] Batch [1370]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.093899,	
2017-07-20 20:00:19,362 Epoch[54] Batch [1380]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.093902,	
2017-07-20 20:00:23,928 Epoch[54] Batch [1390]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.093949,	
2017-07-20 20:00:28,633 Epoch[54] Batch [1400]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.094002,	
2017-07-20 20:00:33,402 Epoch[54] Batch [1410]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094041,	
2017-07-20 20:00:38,111 Epoch[54] Batch [1420]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.093997,	
2017-07-20 20:00:42,893 Epoch[54] Batch [1430]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.093974,	
2017-07-20 20:00:47,854 Epoch[54] Batch [1440]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.093929,	
2017-07-20 20:00:52,320 Epoch[54] Batch [1450]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.093886,	
2017-07-20 20:00:56,974 Epoch[54] Batch [1460]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.093843,	
2017-07-20 20:01:01,310 Epoch[54] Batch [1470]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.093840,	
2017-07-20 20:01:05,886 Epoch[54] Batch [1480]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.093781,	
2017-07-20 20:01:08,816 Epoch[54] Train-FCNLogLoss=0.093724
2017-07-20 20:01:08,816 Epoch[54] Time cost=667.582
2017-07-20 20:01:09,602 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0055.params"
2017-07-20 20:01:13,241 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0055.states"
2017-07-20 20:01:19,298 Epoch[55] Batch [10]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.084655,	
2017-07-20 20:01:25,137 Epoch[55] Batch [20]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088364,	
2017-07-20 20:01:30,382 Epoch[55] Batch [30]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087255,	
2017-07-20 20:01:36,075 Epoch[55] Batch [40]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087620,	
2017-07-20 20:01:41,195 Epoch[55] Batch [50]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.091132,	
2017-07-20 20:01:47,134 Epoch[55] Batch [60]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.090457,	
2017-07-20 20:01:52,056 Epoch[55] Batch [70]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090081,	
2017-07-20 20:01:58,142 Epoch[55] Batch [80]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.090242,	
2017-07-20 20:02:03,631 Epoch[55] Batch [90]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.089198,	
2017-07-20 20:02:09,518 Epoch[55] Batch [100]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088560,	
2017-07-20 20:02:14,645 Epoch[55] Batch [110]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.087651,	
2017-07-20 20:02:19,554 Epoch[55] Batch [120]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.087958,	
2017-07-20 20:02:24,183 Epoch[55] Batch [130]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087552,	
2017-07-20 20:02:28,752 Epoch[55] Batch [140]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087773,	
2017-07-20 20:02:33,325 Epoch[55] Batch [150]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088210,	
2017-07-20 20:02:38,156 Epoch[55] Batch [160]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.087858,	
2017-07-20 20:02:42,715 Epoch[55] Batch [170]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086905,	
2017-07-20 20:02:47,479 Epoch[55] Batch [180]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087308,	
2017-07-20 20:02:52,327 Epoch[55] Batch [190]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087090,	
2017-07-20 20:02:57,131 Epoch[55] Batch [200]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086811,	
2017-07-20 20:03:01,866 Epoch[55] Batch [210]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.086880,	
2017-07-20 20:03:06,736 Epoch[55] Batch [220]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086582,	
2017-07-20 20:03:11,685 Epoch[55] Batch [230]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.086733,	
2017-07-20 20:03:16,549 Epoch[55] Batch [240]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086617,	
2017-07-20 20:03:21,432 Epoch[55] Batch [250]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.086816,	
2017-07-20 20:03:25,886 Epoch[55] Batch [260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.086696,	
2017-07-20 20:03:30,695 Epoch[55] Batch [270]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086761,	
2017-07-20 20:03:35,383 Epoch[55] Batch [280]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.086394,	
2017-07-20 20:03:40,365 Epoch[55] Batch [290]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086461,	
2017-07-20 20:03:45,387 Epoch[55] Batch [300]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.086809,	
2017-07-20 20:03:50,082 Epoch[55] Batch [310]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087018,	
2017-07-20 20:03:54,854 Epoch[55] Batch [320]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086616,	
2017-07-20 20:03:59,413 Epoch[55] Batch [330]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086405,	
2017-07-20 20:04:04,336 Epoch[55] Batch [340]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086385,	
2017-07-20 20:04:08,751 Epoch[55] Batch [350]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.086076,	
2017-07-20 20:04:13,618 Epoch[55] Batch [360]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086027,	
2017-07-20 20:04:18,193 Epoch[55] Batch [370]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.085987,	
2017-07-20 20:04:22,750 Epoch[55] Batch [380]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.085664,	
2017-07-20 20:04:27,409 Epoch[55] Batch [390]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.085347,	
2017-07-20 20:04:32,256 Epoch[55] Batch [400]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.085316,	
2017-07-20 20:04:36,833 Epoch[55] Batch [410]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.085311,	
2017-07-20 20:04:41,603 Epoch[55] Batch [420]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.085193,	
2017-07-20 20:04:46,425 Epoch[55] Batch [430]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.085259,	
2017-07-20 20:04:51,224 Epoch[55] Batch [440]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.085393,	
2017-07-20 20:04:56,167 Epoch[55] Batch [450]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.085514,	
2017-07-20 20:05:01,062 Epoch[55] Batch [460]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.085349,	
2017-07-20 20:05:05,925 Epoch[55] Batch [470]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.085482,	
2017-07-20 20:05:10,607 Epoch[55] Batch [480]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.085352,	
2017-07-20 20:05:15,125 Epoch[55] Batch [490]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.085340,	
2017-07-20 20:05:20,235 Epoch[55] Batch [500]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.085464,	
2017-07-20 20:05:25,470 Epoch[55] Batch [510]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.085579,	
2017-07-20 20:05:30,042 Epoch[55] Batch [520]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.085617,	
2017-07-20 20:05:34,738 Epoch[55] Batch [530]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.085411,	
2017-07-20 20:05:39,357 Epoch[55] Batch [540]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.085449,	
2017-07-20 20:05:44,061 Epoch[55] Batch [550]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.085609,	
2017-07-20 20:05:48,790 Epoch[55] Batch [560]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.085609,	
2017-07-20 20:05:53,605 Epoch[55] Batch [570]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.085479,	
2017-07-20 20:05:58,341 Epoch[55] Batch [580]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.085377,	
2017-07-20 20:06:03,142 Epoch[55] Batch [590]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.085294,	
2017-07-20 20:06:07,837 Epoch[55] Batch [600]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.085198,	
2017-07-20 20:06:12,847 Epoch[55] Batch [610]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.085481,	
2017-07-20 20:06:17,440 Epoch[55] Batch [620]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.085373,	
2017-07-20 20:06:22,002 Epoch[55] Batch [630]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.085356,	
2017-07-20 20:06:26,799 Epoch[55] Batch [640]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.085236,	
2017-07-20 20:06:31,444 Epoch[55] Batch [650]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.085196,	
2017-07-20 20:06:36,066 Epoch[55] Batch [660]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.085103,	
2017-07-20 20:06:40,800 Epoch[55] Batch [670]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.085190,	
2017-07-20 20:06:45,635 Epoch[55] Batch [680]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.085298,	
2017-07-20 20:06:50,374 Epoch[55] Batch [690]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.085403,	
2017-07-20 20:06:55,089 Epoch[55] Batch [700]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.085391,	
2017-07-20 20:06:59,565 Epoch[55] Batch [710]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.085394,	
2017-07-20 20:07:04,283 Epoch[55] Batch [720]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.085402,	
2017-07-20 20:07:09,146 Epoch[55] Batch [730]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.085321,	
2017-07-20 20:07:13,913 Epoch[55] Batch [740]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.085257,	
2017-07-20 20:07:18,525 Epoch[55] Batch [750]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.085244,	
2017-07-20 20:07:23,285 Epoch[55] Batch [760]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.085160,	
2017-07-20 20:07:27,795 Epoch[55] Batch [770]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.085261,	
2017-07-20 20:07:32,658 Epoch[55] Batch [780]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.085211,	
2017-07-20 20:07:37,636 Epoch[55] Batch [790]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.085257,	
2017-07-20 20:07:42,211 Epoch[55] Batch [800]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.085312,	
2017-07-20 20:07:46,977 Epoch[55] Batch [810]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.085174,	
2017-07-20 20:07:51,700 Epoch[55] Batch [820]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.085128,	
2017-07-20 20:07:56,208 Epoch[55] Batch [830]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.085170,	
2017-07-20 20:08:01,151 Epoch[55] Batch [840]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.085188,	
2017-07-20 20:08:06,172 Epoch[55] Batch [850]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.085174,	
2017-07-20 20:08:11,151 Epoch[55] Batch [860]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.085215,	
2017-07-20 20:08:15,951 Epoch[55] Batch [870]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.085297,	
2017-07-20 20:08:20,857 Epoch[55] Batch [880]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.085342,	
2017-07-20 20:08:25,381 Epoch[55] Batch [890]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.085316,	
2017-07-20 20:08:29,961 Epoch[55] Batch [900]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.085215,	
2017-07-20 20:08:34,114 Epoch[55] Batch [910]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.085192,	
2017-07-20 20:08:38,735 Epoch[55] Batch [920]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.085202,	
2017-07-20 20:08:43,437 Epoch[55] Batch [930]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.085140,	
2017-07-20 20:08:48,263 Epoch[55] Batch [940]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.085097,	
2017-07-20 20:08:52,898 Epoch[55] Batch [950]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.085101,	
2017-07-20 20:08:57,393 Epoch[55] Batch [960]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.085060,	
2017-07-20 20:09:02,226 Epoch[55] Batch [970]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.085094,	
2017-07-20 20:09:06,656 Epoch[55] Batch [980]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.085091,	
2017-07-20 20:09:11,577 Epoch[55] Batch [990]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.085143,	
2017-07-20 20:09:16,552 Epoch[55] Batch [1000]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.085132,	
2017-07-20 20:09:21,212 Epoch[55] Batch [1010]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.085197,	
2017-07-20 20:09:26,018 Epoch[55] Batch [1020]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.085131,	
2017-07-20 20:09:30,436 Epoch[55] Batch [1030]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.085108,	
2017-07-20 20:09:34,888 Epoch[55] Batch [1040]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.085169,	
2017-07-20 20:09:39,282 Epoch[55] Batch [1050]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.085207,	
2017-07-20 20:09:44,113 Epoch[55] Batch [1060]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.085607,	
2017-07-20 20:09:49,154 Epoch[55] Batch [1070]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.085817,	
2017-07-20 20:09:54,015 Epoch[55] Batch [1080]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.086067,	
2017-07-20 20:09:58,862 Epoch[55] Batch [1090]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086316,	
2017-07-20 20:10:03,408 Epoch[55] Batch [1100]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.086701,	
2017-07-20 20:10:07,990 Epoch[55] Batch [1110]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086900,	
2017-07-20 20:10:12,964 Epoch[55] Batch [1120]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087067,	
2017-07-20 20:10:17,486 Epoch[55] Batch [1130]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087167,	
2017-07-20 20:10:22,296 Epoch[55] Batch [1140]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.087198,	
2017-07-20 20:10:27,636 Epoch[55] Batch [1150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087228,	
2017-07-20 20:10:32,462 Epoch[55] Batch [1160]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087283,	
2017-07-20 20:10:37,165 Epoch[55] Batch [1170]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087255,	
2017-07-20 20:10:41,707 Epoch[55] Batch [1180]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087237,	
2017-07-20 20:10:46,438 Epoch[55] Batch [1190]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087186,	
2017-07-20 20:10:51,197 Epoch[55] Batch [1200]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087213,	
2017-07-20 20:10:55,835 Epoch[55] Batch [1210]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087254,	
2017-07-20 20:11:00,139 Epoch[55] Batch [1220]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087264,	
2017-07-20 20:11:04,956 Epoch[55] Batch [1230]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087246,	
2017-07-20 20:11:09,739 Epoch[55] Batch [1240]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087254,	
2017-07-20 20:11:15,097 Epoch[55] Batch [1250]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087310,	
2017-07-20 20:11:19,916 Epoch[55] Batch [1260]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087269,	
2017-07-20 20:11:24,762 Epoch[55] Batch [1270]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.087204,	
2017-07-20 20:11:29,636 Epoch[55] Batch [1280]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.087196,	
2017-07-20 20:11:34,346 Epoch[55] Batch [1290]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087178,	
2017-07-20 20:11:38,983 Epoch[55] Batch [1300]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087199,	
2017-07-20 20:11:43,843 Epoch[55] Batch [1310]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087224,	
2017-07-20 20:11:48,314 Epoch[55] Batch [1320]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087208,	
2017-07-20 20:11:53,059 Epoch[55] Batch [1330]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087176,	
2017-07-20 20:11:57,627 Epoch[55] Batch [1340]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087157,	
2017-07-20 20:12:02,101 Epoch[55] Batch [1350]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087205,	
2017-07-20 20:12:07,037 Epoch[55] Batch [1360]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.087170,	
2017-07-20 20:12:11,528 Epoch[55] Batch [1370]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087100,	
2017-07-20 20:12:16,363 Epoch[55] Batch [1380]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087089,	
2017-07-20 20:12:20,940 Epoch[55] Batch [1390]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087079,	
2017-07-20 20:12:25,779 Epoch[55] Batch [1400]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087073,	
2017-07-20 20:12:30,534 Epoch[55] Batch [1410]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087042,	
2017-07-20 20:12:35,533 Epoch[55] Batch [1420]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087033,	
2017-07-20 20:12:40,435 Epoch[55] Batch [1430]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086992,	
2017-07-20 20:12:44,949 Epoch[55] Batch [1440]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086995,	
2017-07-20 20:12:50,176 Epoch[55] Batch [1450]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086906,	
2017-07-20 20:12:55,241 Epoch[55] Batch [1460]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086778,	
2017-07-20 20:12:59,911 Epoch[55] Batch [1470]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.086752,	
2017-07-20 20:13:04,791 Epoch[55] Batch [1480]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086734,	
2017-07-20 20:13:07,499 Epoch[55] Train-FCNLogLoss=0.086736
2017-07-20 20:13:07,499 Epoch[55] Time cost=714.258
2017-07-20 20:13:08,563 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0056.params"
2017-07-20 20:13:13,285 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0056.states"
2017-07-20 20:13:19,688 Epoch[56] Batch [10]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.097856,	
2017-07-20 20:13:24,808 Epoch[56] Batch [20]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090595,	
2017-07-20 20:13:30,780 Epoch[56] Batch [30]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.088710,	
2017-07-20 20:13:37,538 Epoch[56] Batch [40]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.090777,	
2017-07-20 20:13:43,243 Epoch[56] Batch [50]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.090627,	
2017-07-20 20:13:48,048 Epoch[56] Batch [60]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090360,	
2017-07-20 20:13:52,444 Epoch[56] Batch [70]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089169,	
2017-07-20 20:13:57,351 Epoch[56] Batch [80]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.088403,	
2017-07-20 20:14:02,250 Epoch[56] Batch [90]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087514,	
2017-07-20 20:14:07,006 Epoch[56] Batch [100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087591,	
2017-07-20 20:14:11,797 Epoch[56] Batch [110]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087336,	
2017-07-20 20:14:16,494 Epoch[56] Batch [120]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086708,	
2017-07-20 20:14:21,207 Epoch[56] Batch [130]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087067,	
2017-07-20 20:14:25,900 Epoch[56] Batch [140]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087042,	
2017-07-20 20:14:30,628 Epoch[56] Batch [150]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.086078,	
2017-07-20 20:14:35,596 Epoch[56] Batch [160]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086846,	
2017-07-20 20:14:40,192 Epoch[56] Batch [170]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087010,	
2017-07-20 20:14:45,174 Epoch[56] Batch [180]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086949,	
2017-07-20 20:14:50,063 Epoch[56] Batch [190]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086967,	
2017-07-20 20:14:54,609 Epoch[56] Batch [200]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087321,	
2017-07-20 20:14:59,542 Epoch[56] Batch [210]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087227,	
2017-07-20 20:15:03,971 Epoch[56] Batch [220]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.086862,	
2017-07-20 20:15:08,880 Epoch[56] Batch [230]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.086588,	
2017-07-20 20:15:13,514 Epoch[56] Batch [240]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087230,	
2017-07-20 20:15:17,968 Epoch[56] Batch [250]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.086909,	
2017-07-20 20:15:22,301 Epoch[56] Batch [260]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086842,	
2017-07-20 20:15:26,934 Epoch[56] Batch [270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.086745,	
2017-07-20 20:15:32,141 Epoch[56] Batch [280]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086575,	
2017-07-20 20:15:36,759 Epoch[56] Batch [290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.086618,	
2017-07-20 20:15:41,569 Epoch[56] Batch [300]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086397,	
2017-07-20 20:15:46,396 Epoch[56] Batch [310]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086310,	
2017-07-20 20:15:51,408 Epoch[56] Batch [320]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-20 20:15:55,812 Epoch[56] Batch [330]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.086245,	
2017-07-20 20:16:00,375 Epoch[56] Batch [340]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086123,	
2017-07-20 20:16:05,188 Epoch[56] Batch [350]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.085978,	
2017-07-20 20:16:09,869 Epoch[56] Batch [360]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.085845,	
2017-07-20 20:16:14,795 Epoch[56] Batch [370]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.085937,	
2017-07-20 20:16:19,078 Epoch[56] Batch [380]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.085819,	
2017-07-20 20:16:23,691 Epoch[56] Batch [390]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.085399,	
2017-07-20 20:16:28,484 Epoch[56] Batch [400]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.085187,	
2017-07-20 20:16:33,222 Epoch[56] Batch [410]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.085134,	
2017-07-20 20:16:38,110 Epoch[56] Batch [420]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.084957,	
2017-07-20 20:16:42,828 Epoch[56] Batch [430]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.084792,	
2017-07-20 20:16:47,400 Epoch[56] Batch [440]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.084599,	
2017-07-20 20:16:52,435 Epoch[56] Batch [450]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.084420,	
2017-07-20 20:16:57,324 Epoch[56] Batch [460]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.084447,	
2017-07-20 20:17:02,684 Epoch[56] Batch [470]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.084469,	
2017-07-20 20:17:07,653 Epoch[56] Batch [480]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.084302,	
2017-07-20 20:17:12,175 Epoch[56] Batch [490]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.084259,	
2017-07-20 20:17:16,910 Epoch[56] Batch [500]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.084400,	
2017-07-20 20:17:21,969 Epoch[56] Batch [510]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.084479,	
2017-07-20 20:17:26,814 Epoch[56] Batch [520]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.084515,	
2017-07-20 20:17:31,743 Epoch[56] Batch [530]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.084376,	
2017-07-20 20:17:36,263 Epoch[56] Batch [540]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.084163,	
2017-07-20 20:17:40,896 Epoch[56] Batch [550]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.084237,	
2017-07-20 20:17:45,770 Epoch[56] Batch [560]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.084430,	
2017-07-20 20:17:50,608 Epoch[56] Batch [570]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.084323,	
2017-07-20 20:17:55,149 Epoch[56] Batch [580]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.084328,	
2017-07-20 20:18:00,071 Epoch[56] Batch [590]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.084481,	
2017-07-20 20:18:05,110 Epoch[56] Batch [600]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.084424,	
2017-07-20 20:18:09,917 Epoch[56] Batch [610]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.084311,	
2017-07-20 20:18:14,907 Epoch[56] Batch [620]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.084186,	
2017-07-20 20:18:19,717 Epoch[56] Batch [630]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.084329,	
2017-07-20 20:18:24,516 Epoch[56] Batch [640]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.084220,	
2017-07-20 20:18:29,929 Epoch[56] Batch [650]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.084250,	
2017-07-20 20:18:35,058 Epoch[56] Batch [660]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.084397,	
2017-07-20 20:18:39,582 Epoch[56] Batch [670]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.084535,	
2017-07-20 20:18:43,970 Epoch[56] Batch [680]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.084580,	
2017-07-20 20:18:48,999 Epoch[56] Batch [690]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.084376,	
2017-07-20 20:18:53,597 Epoch[56] Batch [700]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.084472,	
2017-07-20 20:18:58,238 Epoch[56] Batch [710]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.084454,	
2017-07-20 20:19:02,940 Epoch[56] Batch [720]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.084428,	
2017-07-20 20:19:07,970 Epoch[56] Batch [730]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.084369,	
2017-07-20 20:19:12,697 Epoch[56] Batch [740]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.084287,	
2017-07-20 20:19:17,370 Epoch[56] Batch [750]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.084306,	
2017-07-20 20:19:22,318 Epoch[56] Batch [760]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.084346,	
2017-07-20 20:19:27,040 Epoch[56] Batch [770]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.084336,	
2017-07-20 20:19:31,775 Epoch[56] Batch [780]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.084287,	
2017-07-20 20:19:36,382 Epoch[56] Batch [790]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.084261,	
2017-07-20 20:19:40,865 Epoch[56] Batch [800]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.084331,	
2017-07-20 20:19:45,327 Epoch[56] Batch [810]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.084348,	
2017-07-20 20:19:50,117 Epoch[56] Batch [820]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.084332,	
2017-07-20 20:19:54,720 Epoch[56] Batch [830]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.084478,	
2017-07-20 20:19:59,290 Epoch[56] Batch [840]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.084442,	
2017-07-20 20:20:03,756 Epoch[56] Batch [850]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.084469,	
2017-07-20 20:20:08,276 Epoch[56] Batch [860]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.084548,	
2017-07-20 20:20:12,922 Epoch[56] Batch [870]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.084526,	
2017-07-20 20:20:17,564 Epoch[56] Batch [880]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.084452,	
2017-07-20 20:20:22,411 Epoch[56] Batch [890]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.084419,	
2017-07-20 20:20:26,954 Epoch[56] Batch [900]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.084377,	
2017-07-20 20:20:31,652 Epoch[56] Batch [910]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.084289,	
2017-07-20 20:20:36,128 Epoch[56] Batch [920]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.084214,	
2017-07-20 20:20:41,133 Epoch[56] Batch [930]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.084143,	
2017-07-20 20:20:45,698 Epoch[56] Batch [940]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.084093,	
2017-07-20 20:20:50,528 Epoch[56] Batch [950]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.084066,	
2017-07-20 20:20:55,207 Epoch[56] Batch [960]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.084088,	
2017-07-20 20:20:59,601 Epoch[56] Batch [970]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.084034,	
2017-07-20 20:21:04,308 Epoch[56] Batch [980]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.084021,	
2017-07-20 20:21:09,076 Epoch[56] Batch [990]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.084074,	
2017-07-20 20:21:13,713 Epoch[56] Batch [1000]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.084224,	
2017-07-20 20:21:18,089 Epoch[56] Batch [1010]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.084245,	
2017-07-20 20:21:22,592 Epoch[56] Batch [1020]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.084112,	
2017-07-20 20:21:27,142 Epoch[56] Batch [1030]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.084023,	
2017-07-20 20:21:31,828 Epoch[56] Batch [1040]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.084030,	
2017-07-20 20:21:36,460 Epoch[56] Batch [1050]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.084018,	
2017-07-20 20:21:41,908 Epoch[56] Batch [1060]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.083986,	
2017-07-20 20:21:46,739 Epoch[56] Batch [1070]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.084033,	
2017-07-20 20:21:51,514 Epoch[56] Batch [1080]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.084052,	
2017-07-20 20:21:56,211 Epoch[56] Batch [1090]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.083975,	
2017-07-20 20:22:00,966 Epoch[56] Batch [1100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.084004,	
2017-07-20 20:22:05,810 Epoch[56] Batch [1110]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.084011,	
2017-07-20 20:22:10,986 Epoch[56] Batch [1120]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.084019,	
2017-07-20 20:22:16,697 Epoch[56] Batch [1130]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.083998,	
2017-07-20 20:22:21,134 Epoch[56] Batch [1140]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.083990,	
2017-07-20 20:22:25,557 Epoch[56] Batch [1150]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.084024,	
2017-07-20 20:22:30,006 Epoch[56] Batch [1160]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.084138,	
2017-07-20 20:22:34,973 Epoch[56] Batch [1170]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.084254,	
2017-07-20 20:22:39,531 Epoch[56] Batch [1180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.084316,	
2017-07-20 20:22:44,033 Epoch[56] Batch [1190]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.084352,	
2017-07-20 20:22:48,900 Epoch[56] Batch [1200]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.084425,	
2017-07-20 20:22:53,516 Epoch[56] Batch [1210]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.084429,	
2017-07-20 20:22:58,731 Epoch[56] Batch [1220]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.084498,	
2017-07-20 20:23:03,284 Epoch[56] Batch [1230]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.084475,	
2017-07-20 20:23:08,106 Epoch[56] Batch [1240]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.084473,	
2017-07-20 20:23:12,755 Epoch[56] Batch [1250]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.084486,	
2017-07-20 20:23:17,831 Epoch[56] Batch [1260]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.084527,	
2017-07-20 20:23:22,917 Epoch[56] Batch [1270]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.084553,	
2017-07-20 20:23:27,197 Epoch[56] Batch [1280]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.084552,	
2017-07-20 20:23:31,992 Epoch[56] Batch [1290]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.084519,	
2017-07-20 20:23:36,625 Epoch[56] Batch [1300]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.084454,	
2017-07-20 20:23:41,445 Epoch[56] Batch [1310]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.084456,	
2017-07-20 20:23:46,094 Epoch[56] Batch [1320]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.084462,	
2017-07-20 20:23:51,047 Epoch[56] Batch [1330]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.084499,	
2017-07-20 20:23:55,749 Epoch[56] Batch [1340]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.084494,	
2017-07-20 20:24:00,567 Epoch[56] Batch [1350]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.084458,	
2017-07-20 20:24:05,301 Epoch[56] Batch [1360]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.084408,	
2017-07-20 20:24:10,255 Epoch[56] Batch [1370]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.084303,	
2017-07-20 20:24:14,960 Epoch[56] Batch [1380]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.084254,	
2017-07-20 20:24:19,732 Epoch[56] Batch [1390]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.084251,	
2017-07-20 20:24:24,380 Epoch[56] Batch [1400]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.084226,	
2017-07-20 20:24:29,112 Epoch[56] Batch [1410]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.084181,	
2017-07-20 20:24:33,919 Epoch[56] Batch [1420]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.084201,	
2017-07-20 20:24:38,723 Epoch[56] Batch [1430]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.084182,	
2017-07-20 20:24:43,684 Epoch[56] Batch [1440]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.084200,	
2017-07-20 20:24:48,608 Epoch[56] Batch [1450]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.084214,	
2017-07-20 20:24:53,261 Epoch[56] Batch [1460]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.084172,	
2017-07-20 20:24:57,806 Epoch[56] Batch [1470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.084143,	
2017-07-20 20:25:03,024 Epoch[56] Batch [1480]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.084178,	
2017-07-20 20:25:05,820 Epoch[56] Train-FCNLogLoss=0.084180
2017-07-20 20:25:05,820 Epoch[56] Time cost=712.534
2017-07-20 20:25:06,740 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0057.params"
2017-07-20 20:25:10,437 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0057.states"
2017-07-20 20:25:16,654 Epoch[57] Batch [10]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.081756,	
2017-07-20 20:25:21,450 Epoch[57] Batch [20]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.079492,	
2017-07-20 20:25:26,299 Epoch[57] Batch [30]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.078655,	
2017-07-20 20:25:31,041 Epoch[57] Batch [40]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.079454,	
2017-07-20 20:25:35,993 Epoch[57] Batch [50]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.079745,	
2017-07-20 20:25:40,581 Epoch[57] Batch [60]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.079080,	
2017-07-20 20:25:45,536 Epoch[57] Batch [70]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.079602,	
2017-07-20 20:25:50,394 Epoch[57] Batch [80]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077975,	
2017-07-20 20:25:55,274 Epoch[57] Batch [90]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.077996,	
2017-07-20 20:26:00,206 Epoch[57] Batch [100]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077864,	
2017-07-20 20:26:04,973 Epoch[57] Batch [110]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.078479,	
2017-07-20 20:26:09,860 Epoch[57] Batch [120]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078813,	
2017-07-20 20:26:14,586 Epoch[57] Batch [130]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079214,	
2017-07-20 20:26:19,219 Epoch[57] Batch [140]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.079879,	
2017-07-20 20:26:24,098 Epoch[57] Batch [150]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.080385,	
2017-07-20 20:26:28,639 Epoch[57] Batch [160]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.080404,	
2017-07-20 20:26:33,374 Epoch[57] Batch [170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.080601,	
2017-07-20 20:26:38,113 Epoch[57] Batch [180]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.080800,	
2017-07-20 20:26:42,581 Epoch[57] Batch [190]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.080894,	
2017-07-20 20:26:47,056 Epoch[57] Batch [200]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.080658,	
2017-07-20 20:26:51,914 Epoch[57] Batch [210]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.080793,	
2017-07-20 20:26:56,498 Epoch[57] Batch [220]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.080698,	
2017-07-20 20:27:01,399 Epoch[57] Batch [230]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.080746,	
2017-07-20 20:27:06,137 Epoch[57] Batch [240]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.081173,	
2017-07-20 20:27:10,924 Epoch[57] Batch [250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.081421,	
2017-07-20 20:27:15,543 Epoch[57] Batch [260]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.081872,	
2017-07-20 20:27:20,043 Epoch[57] Batch [270]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.082056,	
2017-07-20 20:27:24,908 Epoch[57] Batch [280]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.082151,	
2017-07-20 20:27:29,552 Epoch[57] Batch [290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.082022,	
2017-07-20 20:27:35,211 Epoch[57] Batch [300]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.081859,	
2017-07-20 20:27:40,177 Epoch[57] Batch [310]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.082056,	
2017-07-20 20:27:44,747 Epoch[57] Batch [320]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.081891,	
2017-07-20 20:27:49,582 Epoch[57] Batch [330]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.081788,	
2017-07-20 20:27:54,286 Epoch[57] Batch [340]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.082055,	
2017-07-20 20:27:58,806 Epoch[57] Batch [350]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.082213,	
2017-07-20 20:28:03,466 Epoch[57] Batch [360]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.082078,	
2017-07-20 20:28:08,138 Epoch[57] Batch [370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.081983,	
2017-07-20 20:28:12,950 Epoch[57] Batch [380]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.081928,	
2017-07-20 20:28:17,618 Epoch[57] Batch [390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.081978,	
2017-07-20 20:28:22,312 Epoch[57] Batch [400]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.081986,	
2017-07-20 20:28:26,891 Epoch[57] Batch [410]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.082091,	
2017-07-20 20:28:31,772 Epoch[57] Batch [420]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.082031,	
2017-07-20 20:28:36,322 Epoch[57] Batch [430]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.082206,	
2017-07-20 20:28:41,250 Epoch[57] Batch [440]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.082145,	
2017-07-20 20:28:46,039 Epoch[57] Batch [450]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.082171,	
2017-07-20 20:28:50,932 Epoch[57] Batch [460]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.082293,	
2017-07-20 20:28:55,673 Epoch[57] Batch [470]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.082319,	
2017-07-20 20:29:00,609 Epoch[57] Batch [480]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.082280,	
2017-07-20 20:29:05,681 Epoch[57] Batch [490]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.082399,	
2017-07-20 20:29:10,711 Epoch[57] Batch [500]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.082376,	
2017-07-20 20:29:15,359 Epoch[57] Batch [510]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.082258,	
2017-07-20 20:29:20,001 Epoch[57] Batch [520]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.082139,	
2017-07-20 20:29:24,691 Epoch[57] Batch [530]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.082132,	
2017-07-20 20:29:29,182 Epoch[57] Batch [540]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.082101,	
2017-07-20 20:29:33,879 Epoch[57] Batch [550]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.082074,	
2017-07-20 20:29:38,648 Epoch[57] Batch [560]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.082142,	
2017-07-20 20:29:43,560 Epoch[57] Batch [570]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.082033,	
2017-07-20 20:29:48,454 Epoch[57] Batch [580]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.081960,	
2017-07-20 20:29:52,946 Epoch[57] Batch [590]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.082035,	
2017-07-20 20:29:57,387 Epoch[57] Batch [600]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.082102,	
2017-07-20 20:30:02,272 Epoch[57] Batch [610]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.082076,	
2017-07-20 20:30:07,164 Epoch[57] Batch [620]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.081948,	
2017-07-20 20:30:12,228 Epoch[57] Batch [630]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.081969,	
2017-07-20 20:30:17,099 Epoch[57] Batch [640]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.082000,	
2017-07-20 20:30:21,802 Epoch[57] Batch [650]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.082194,	
2017-07-20 20:30:26,818 Epoch[57] Batch [660]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.082359,	
2017-07-20 20:30:31,837 Epoch[57] Batch [670]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.082401,	
2017-07-20 20:30:36,484 Epoch[57] Batch [680]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.082310,	
2017-07-20 20:30:40,951 Epoch[57] Batch [690]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.082339,	
2017-07-20 20:30:45,733 Epoch[57] Batch [700]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.082302,	
2017-07-20 20:30:50,565 Epoch[57] Batch [710]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.082245,	
2017-07-20 20:30:55,364 Epoch[57] Batch [720]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.082163,	
2017-07-20 20:31:00,177 Epoch[57] Batch [730]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.082278,	
2017-07-20 20:31:04,774 Epoch[57] Batch [740]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.082172,	
2017-07-20 20:31:09,624 Epoch[57] Batch [750]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.082192,	
2017-07-20 20:31:14,195 Epoch[57] Batch [760]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.082144,	
2017-07-20 20:31:18,846 Epoch[57] Batch [770]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.082117,	
2017-07-20 20:31:23,806 Epoch[57] Batch [780]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.082074,	
2017-07-20 20:31:28,425 Epoch[57] Batch [790]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.082058,	
2017-07-20 20:31:32,845 Epoch[57] Batch [800]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.082140,	
2017-07-20 20:31:37,521 Epoch[57] Batch [810]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.081955,	
2017-07-20 20:31:42,825 Epoch[57] Batch [820]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.081921,	
2017-07-20 20:31:47,965 Epoch[57] Batch [830]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.081920,	
2017-07-20 20:31:52,639 Epoch[57] Batch [840]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.082017,	
2017-07-20 20:31:57,527 Epoch[57] Batch [850]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.081974,	
2017-07-20 20:32:02,266 Epoch[57] Batch [860]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.081965,	
2017-07-20 20:32:06,699 Epoch[57] Batch [870]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.081873,	
2017-07-20 20:32:11,212 Epoch[57] Batch [880]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.081875,	
2017-07-20 20:32:16,118 Epoch[57] Batch [890]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.081864,	
2017-07-20 20:32:20,854 Epoch[57] Batch [900]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.081901,	
2017-07-20 20:32:25,559 Epoch[57] Batch [910]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.081894,	
2017-07-20 20:32:30,192 Epoch[57] Batch [920]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.082025,	
2017-07-20 20:32:34,859 Epoch[57] Batch [930]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.082103,	
2017-07-20 20:32:39,567 Epoch[57] Batch [940]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.082084,	
2017-07-20 20:32:44,400 Epoch[57] Batch [950]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.082051,	
2017-07-20 20:32:49,119 Epoch[57] Batch [960]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.082069,	
2017-07-20 20:32:53,804 Epoch[57] Batch [970]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.082053,	
2017-07-20 20:32:58,488 Epoch[57] Batch [980]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.082145,	
2017-07-20 20:33:03,258 Epoch[57] Batch [990]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.082080,	
2017-07-20 20:33:07,986 Epoch[57] Batch [1000]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.082097,	
2017-07-20 20:33:12,828 Epoch[57] Batch [1010]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.082174,	
2017-07-20 20:33:17,509 Epoch[57] Batch [1020]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.082177,	
2017-07-20 20:33:22,120 Epoch[57] Batch [1030]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.082179,	
2017-07-20 20:33:26,724 Epoch[57] Batch [1040]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.082199,	
2017-07-20 20:33:31,497 Epoch[57] Batch [1050]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.082215,	
2017-07-20 20:33:36,330 Epoch[57] Batch [1060]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.082238,	
2017-07-20 20:33:41,526 Epoch[57] Batch [1070]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.082186,	
2017-07-20 20:33:46,539 Epoch[57] Batch [1080]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.082145,	
2017-07-20 20:33:51,624 Epoch[57] Batch [1090]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.082105,	
2017-07-20 20:33:56,273 Epoch[57] Batch [1100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.082102,	
2017-07-20 20:34:00,790 Epoch[57] Batch [1110]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.082109,	
2017-07-20 20:34:05,142 Epoch[57] Batch [1120]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.082104,	
2017-07-20 20:34:09,979 Epoch[57] Batch [1130]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.082102,	
2017-07-20 20:34:14,600 Epoch[57] Batch [1140]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.082084,	
2017-07-20 20:34:19,694 Epoch[57] Batch [1150]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.081994,	
2017-07-20 20:34:24,807 Epoch[57] Batch [1160]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.081997,	
2017-07-20 20:34:29,657 Epoch[57] Batch [1170]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.082017,	
2017-07-20 20:34:34,362 Epoch[57] Batch [1180]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.082009,	
2017-07-20 20:34:38,971 Epoch[57] Batch [1190]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.081984,	
2017-07-20 20:34:43,389 Epoch[57] Batch [1200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.081967,	
2017-07-20 20:34:48,332 Epoch[57] Batch [1210]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.081947,	
2017-07-20 20:34:53,126 Epoch[57] Batch [1220]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.081923,	
2017-07-20 20:34:57,736 Epoch[57] Batch [1230]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.081931,	
2017-07-20 20:35:02,610 Epoch[57] Batch [1240]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.081934,	
2017-07-20 20:35:07,570 Epoch[57] Batch [1250]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.081862,	
2017-07-20 20:35:12,311 Epoch[57] Batch [1260]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.081927,	
2017-07-20 20:35:16,831 Epoch[57] Batch [1270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.081894,	
2017-07-20 20:35:22,082 Epoch[57] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.081797,	
2017-07-20 20:35:26,609 Epoch[57] Batch [1290]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.081761,	
2017-07-20 20:35:31,139 Epoch[57] Batch [1300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.081797,	
2017-07-20 20:35:36,108 Epoch[57] Batch [1310]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.081865,	
2017-07-20 20:35:40,951 Epoch[57] Batch [1320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.081846,	
2017-07-20 20:35:45,655 Epoch[57] Batch [1330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.081909,	
2017-07-20 20:35:50,340 Epoch[57] Batch [1340]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.081885,	
2017-07-20 20:35:54,933 Epoch[57] Batch [1350]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.081902,	
2017-07-20 20:35:59,468 Epoch[57] Batch [1360]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.081916,	
2017-07-20 20:36:03,949 Epoch[57] Batch [1370]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.081896,	
2017-07-20 20:36:08,384 Epoch[57] Batch [1380]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.081873,	
2017-07-20 20:36:12,983 Epoch[57] Batch [1390]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.081808,	
2017-07-20 20:36:17,311 Epoch[57] Batch [1400]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.081821,	
2017-07-20 20:36:22,016 Epoch[57] Batch [1410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.081798,	
2017-07-20 20:36:26,877 Epoch[57] Batch [1420]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.081771,	
2017-07-20 20:36:31,629 Epoch[57] Batch [1430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.081788,	
2017-07-20 20:36:36,273 Epoch[57] Batch [1440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.081753,	
2017-07-20 20:36:41,201 Epoch[57] Batch [1450]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.081737,	
2017-07-20 20:36:45,788 Epoch[57] Batch [1460]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.081719,	
2017-07-20 20:36:50,860 Epoch[57] Batch [1470]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.081685,	
2017-07-20 20:36:55,738 Epoch[57] Batch [1480]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.081674,	
2017-07-20 20:36:58,670 Epoch[57] Train-FCNLogLoss=0.081678
2017-07-20 20:36:58,671 Epoch[57] Time cost=708.234
2017-07-20 20:36:59,485 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0058.params"
2017-07-20 20:37:02,896 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0058.states"
2017-07-20 20:37:08,710 Epoch[58] Batch [10]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.078118,	
2017-07-20 20:37:13,541 Epoch[58] Batch [20]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078528,	
2017-07-20 20:37:18,206 Epoch[58] Batch [30]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.078889,	
2017-07-20 20:37:23,003 Epoch[58] Batch [40]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.078557,	
2017-07-20 20:37:27,768 Epoch[58] Batch [50]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078911,	
2017-07-20 20:37:32,677 Epoch[58] Batch [60]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.078629,	
2017-07-20 20:37:37,833 Epoch[58] Batch [70]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.078007,	
2017-07-20 20:37:43,163 Epoch[58] Batch [80]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.078441,	
2017-07-20 20:37:48,260 Epoch[58] Batch [90]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.079381,	
2017-07-20 20:37:52,991 Epoch[58] Batch [100]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079712,	
2017-07-20 20:37:57,497 Epoch[58] Batch [110]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.079068,	
2017-07-20 20:38:02,316 Epoch[58] Batch [120]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.078547,	
2017-07-20 20:38:06,939 Epoch[58] Batch [130]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.078719,	
2017-07-20 20:38:11,685 Epoch[58] Batch [140]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.079449,	
2017-07-20 20:38:16,497 Epoch[58] Batch [150]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.079953,	
2017-07-20 20:38:21,042 Epoch[58] Batch [160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.079686,	
2017-07-20 20:38:25,983 Epoch[58] Batch [170]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.079934,	
2017-07-20 20:38:30,787 Epoch[58] Batch [180]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.079662,	
2017-07-20 20:38:35,696 Epoch[58] Batch [190]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.079142,	
2017-07-20 20:38:40,182 Epoch[58] Batch [200]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.079298,	
2017-07-20 20:38:44,734 Epoch[58] Batch [210]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.079317,	
2017-07-20 20:38:49,287 Epoch[58] Batch [220]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.079610,	
2017-07-20 20:38:53,732 Epoch[58] Batch [230]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.080028,	
2017-07-20 20:38:58,483 Epoch[58] Batch [240]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.079923,	
2017-07-20 20:39:03,036 Epoch[58] Batch [250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.079494,	
2017-07-20 20:39:07,782 Epoch[58] Batch [260]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.079442,	
2017-07-20 20:39:12,430 Epoch[58] Batch [270]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.079531,	
2017-07-20 20:39:17,344 Epoch[58] Batch [280]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.079489,	
2017-07-20 20:39:22,293 Epoch[58] Batch [290]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.079448,	
2017-07-20 20:39:26,835 Epoch[58] Batch [300]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.079324,	
2017-07-20 20:39:32,208 Epoch[58] Batch [310]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.079463,	
2017-07-20 20:39:36,651 Epoch[58] Batch [320]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.079638,	
2017-07-20 20:39:41,111 Epoch[58] Batch [330]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.079602,	
2017-07-20 20:39:45,738 Epoch[58] Batch [340]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.079684,	
2017-07-20 20:39:49,953 Epoch[58] Batch [350]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.079678,	
2017-07-20 20:39:54,527 Epoch[58] Batch [360]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.079308,	
2017-07-20 20:39:58,972 Epoch[58] Batch [370]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.079387,	
2017-07-20 20:40:03,485 Epoch[58] Batch [380]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.079355,	
2017-07-20 20:40:07,967 Epoch[58] Batch [390]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.079610,	
2017-07-20 20:40:12,501 Epoch[58] Batch [400]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.079969,	
2017-07-20 20:40:17,279 Epoch[58] Batch [410]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.080060,	
2017-07-20 20:40:21,840 Epoch[58] Batch [420]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.080022,	
2017-07-20 20:40:26,817 Epoch[58] Batch [430]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.080108,	
2017-07-20 20:40:31,565 Epoch[58] Batch [440]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.080178,	
2017-07-20 20:40:36,333 Epoch[58] Batch [450]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.080128,	
2017-07-20 20:40:40,738 Epoch[58] Batch [460]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.079967,	
2017-07-20 20:40:45,399 Epoch[58] Batch [470]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.080089,	
2017-07-20 20:40:50,170 Epoch[58] Batch [480]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.079891,	
2017-07-20 20:40:54,745 Epoch[58] Batch [490]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.079926,	
2017-07-20 20:40:59,513 Epoch[58] Batch [500]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.080100,	
2017-07-20 20:41:04,583 Epoch[58] Batch [510]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.080113,	
2017-07-20 20:41:09,151 Epoch[58] Batch [520]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.080314,	
2017-07-20 20:41:13,940 Epoch[58] Batch [530]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.080405,	
2017-07-20 20:41:18,516 Epoch[58] Batch [540]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.080419,	
2017-07-20 20:41:23,180 Epoch[58] Batch [550]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.080443,	
2017-07-20 20:41:28,407 Epoch[58] Batch [560]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.080397,	
2017-07-20 20:41:32,953 Epoch[58] Batch [570]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.080320,	
2017-07-20 20:41:38,021 Epoch[58] Batch [580]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.080389,	
2017-07-20 20:41:43,170 Epoch[58] Batch [590]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.080449,	
2017-07-20 20:41:48,176 Epoch[58] Batch [600]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.080398,	
2017-07-20 20:41:53,186 Epoch[58] Batch [610]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.080316,	
2017-07-20 20:41:57,823 Epoch[58] Batch [620]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.080269,	
2017-07-20 20:42:02,356 Epoch[58] Batch [630]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.080230,	
2017-07-20 20:42:06,751 Epoch[58] Batch [640]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.080152,	
2017-07-20 20:42:11,387 Epoch[58] Batch [650]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.080266,	
2017-07-20 20:42:15,905 Epoch[58] Batch [660]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.080175,	
2017-07-20 20:42:20,572 Epoch[58] Batch [670]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.080206,	
2017-07-20 20:42:25,040 Epoch[58] Batch [680]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.080177,	
2017-07-20 20:42:29,982 Epoch[58] Batch [690]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.080245,	
2017-07-20 20:42:34,717 Epoch[58] Batch [700]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.080123,	
2017-07-20 20:42:39,206 Epoch[58] Batch [710]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.080121,	
2017-07-20 20:42:43,786 Epoch[58] Batch [720]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.080038,	
2017-07-20 20:42:48,622 Epoch[58] Batch [730]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.079945,	
2017-07-20 20:42:53,081 Epoch[58] Batch [740]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.079801,	
2017-07-20 20:42:57,931 Epoch[58] Batch [750]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.079817,	
2017-07-20 20:43:02,823 Epoch[58] Batch [760]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.079788,	
2017-07-20 20:43:07,851 Epoch[58] Batch [770]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.079807,	
2017-07-20 20:43:13,140 Epoch[58] Batch [780]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.079802,	
2017-07-20 20:43:17,842 Epoch[58] Batch [790]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.079862,	
2017-07-20 20:43:22,464 Epoch[58] Batch [800]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.079805,	
2017-07-20 20:43:27,458 Epoch[58] Batch [810]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.079773,	
2017-07-20 20:43:32,135 Epoch[58] Batch [820]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.079791,	
2017-07-20 20:43:36,805 Epoch[58] Batch [830]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.079787,	
2017-07-20 20:43:41,553 Epoch[58] Batch [840]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.079828,	
2017-07-20 20:43:46,475 Epoch[58] Batch [850]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.079903,	
2017-07-20 20:43:51,269 Epoch[58] Batch [860]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.079914,	
2017-07-20 20:43:56,132 Epoch[58] Batch [870]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.079949,	
2017-07-20 20:44:00,686 Epoch[58] Batch [880]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.080053,	
2017-07-20 20:44:05,340 Epoch[58] Batch [890]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.080074,	
2017-07-20 20:44:10,442 Epoch[58] Batch [900]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.080018,	
2017-07-20 20:44:15,391 Epoch[58] Batch [910]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.080130,	
2017-07-20 20:44:20,235 Epoch[58] Batch [920]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.080119,	
2017-07-20 20:44:25,376 Epoch[58] Batch [930]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.080202,	
2017-07-20 20:44:30,579 Epoch[58] Batch [940]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.080252,	
2017-07-20 20:44:35,469 Epoch[58] Batch [950]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.080300,	
2017-07-20 20:44:40,465 Epoch[58] Batch [960]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.080221,	
2017-07-20 20:44:45,303 Epoch[58] Batch [970]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.080253,	
2017-07-20 20:44:50,248 Epoch[58] Batch [980]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.080250,	
2017-07-20 20:44:54,630 Epoch[58] Batch [990]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.080125,	
2017-07-20 20:44:59,099 Epoch[58] Batch [1000]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.080077,	
2017-07-20 20:45:03,754 Epoch[58] Batch [1010]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.080077,	
2017-07-20 20:45:08,410 Epoch[58] Batch [1020]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.080125,	
2017-07-20 20:45:12,909 Epoch[58] Batch [1030]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.080079,	
2017-07-20 20:45:17,522 Epoch[58] Batch [1040]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.080082,	
2017-07-20 20:45:21,984 Epoch[58] Batch [1050]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.080111,	
2017-07-20 20:45:26,860 Epoch[58] Batch [1060]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.080153,	
2017-07-20 20:45:31,586 Epoch[58] Batch [1070]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.080112,	
2017-07-20 20:45:36,205 Epoch[58] Batch [1080]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.080111,	
2017-07-20 20:45:40,730 Epoch[58] Batch [1090]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.080117,	
2017-07-20 20:45:45,279 Epoch[58] Batch [1100]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.080089,	
2017-07-20 20:45:49,580 Epoch[58] Batch [1110]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.080094,	
2017-07-20 20:45:54,368 Epoch[58] Batch [1120]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.080148,	
2017-07-20 20:45:59,360 Epoch[58] Batch [1130]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.080085,	
2017-07-20 20:46:04,255 Epoch[58] Batch [1140]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.080116,	
2017-07-20 20:46:08,833 Epoch[58] Batch [1150]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.080141,	
2017-07-20 20:46:13,497 Epoch[58] Batch [1160]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.080104,	
2017-07-20 20:46:18,209 Epoch[58] Batch [1170]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.080201,	
2017-07-20 20:46:23,131 Epoch[58] Batch [1180]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.080267,	
2017-07-20 20:46:28,096 Epoch[58] Batch [1190]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.080299,	
2017-07-20 20:46:32,797 Epoch[58] Batch [1200]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.080268,	
2017-07-20 20:46:37,627 Epoch[58] Batch [1210]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.080219,	
2017-07-20 20:46:42,553 Epoch[58] Batch [1220]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.080127,	
2017-07-20 20:46:47,361 Epoch[58] Batch [1230]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.080138,	
2017-07-20 20:46:52,110 Epoch[58] Batch [1240]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.080160,	
2017-07-20 20:46:56,649 Epoch[58] Batch [1250]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.080156,	
2017-07-20 20:47:01,500 Epoch[58] Batch [1260]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.080138,	
2017-07-20 20:47:06,329 Epoch[58] Batch [1270]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.080162,	
2017-07-20 20:47:10,964 Epoch[58] Batch [1280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.080219,	
2017-07-20 20:47:15,634 Epoch[58] Batch [1290]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.080261,	
2017-07-20 20:47:20,194 Epoch[58] Batch [1300]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.080242,	
2017-07-20 20:47:24,788 Epoch[58] Batch [1310]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.080335,	
2017-07-20 20:47:29,296 Epoch[58] Batch [1320]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.080354,	
2017-07-20 20:47:33,790 Epoch[58] Batch [1330]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.080348,	
2017-07-20 20:47:39,382 Epoch[58] Batch [1340]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.080379,	
2017-07-20 20:47:43,959 Epoch[58] Batch [1350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.080437,	
2017-07-20 20:47:48,572 Epoch[58] Batch [1360]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.080411,	
2017-07-20 20:47:53,194 Epoch[58] Batch [1370]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.080400,	
2017-07-20 20:47:57,517 Epoch[58] Batch [1380]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.080427,	
2017-07-20 20:48:02,225 Epoch[58] Batch [1390]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.080401,	
2017-07-20 20:48:06,727 Epoch[58] Batch [1400]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.080393,	
2017-07-20 20:48:11,335 Epoch[58] Batch [1410]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.080369,	
2017-07-20 20:48:15,900 Epoch[58] Batch [1420]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.080270,	
2017-07-20 20:48:20,958 Epoch[58] Batch [1430]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.080287,	
2017-07-20 20:48:25,861 Epoch[58] Batch [1440]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.080310,	
2017-07-20 20:48:30,590 Epoch[58] Batch [1450]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.080330,	
2017-07-20 20:48:35,189 Epoch[58] Batch [1460]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.080412,	
2017-07-20 20:48:40,116 Epoch[58] Batch [1470]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.080399,	
2017-07-20 20:48:44,839 Epoch[58] Batch [1480]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.080376,	
2017-07-20 20:48:47,480 Epoch[58] Train-FCNLogLoss=0.080369
2017-07-20 20:48:47,480 Epoch[58] Time cost=704.584
2017-07-20 20:48:48,413 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0059.params"
2017-07-20 20:48:51,885 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0059.states"
2017-07-20 20:48:57,105 Epoch[59] Batch [10]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088670,	
2017-07-20 20:49:01,438 Epoch[59] Batch [20]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.082923,	
2017-07-20 20:49:05,582 Epoch[59] Batch [30]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.083101,	
2017-07-20 20:49:10,224 Epoch[59] Batch [40]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.082322,	
2017-07-20 20:49:14,685 Epoch[59] Batch [50]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.081654,	
2017-07-20 20:49:19,093 Epoch[59] Batch [60]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.081291,	
2017-07-20 20:49:23,980 Epoch[59] Batch [70]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.081766,	
2017-07-20 20:49:28,579 Epoch[59] Batch [80]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.082008,	
2017-07-20 20:49:33,544 Epoch[59] Batch [90]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.081904,	
2017-07-20 20:49:38,785 Epoch[59] Batch [100]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.081336,	
2017-07-20 20:49:43,635 Epoch[59] Batch [110]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.079817,	
2017-07-20 20:49:48,924 Epoch[59] Batch [120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.079540,	
2017-07-20 20:49:53,693 Epoch[59] Batch [130]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.079522,	
2017-07-20 20:49:58,180 Epoch[59] Batch [140]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.079573,	
2017-07-20 20:50:02,891 Epoch[59] Batch [150]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.079789,	
2017-07-20 20:50:07,501 Epoch[59] Batch [160]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.079110,	
2017-07-20 20:50:12,231 Epoch[59] Batch [170]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079102,	
2017-07-20 20:50:16,798 Epoch[59] Batch [180]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.079704,	
2017-07-20 20:50:21,030 Epoch[59] Batch [190]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.079563,	
2017-07-20 20:50:25,708 Epoch[59] Batch [200]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.079785,	
2017-07-20 20:50:30,244 Epoch[59] Batch [210]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.079553,	
2017-07-20 20:50:34,356 Epoch[59] Batch [220]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.079713,	
2017-07-20 20:50:38,991 Epoch[59] Batch [230]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.079705,	
2017-07-20 20:50:43,665 Epoch[59] Batch [240]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.080426,	
2017-07-20 20:50:48,099 Epoch[59] Batch [250]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.080351,	
2017-07-20 20:50:52,553 Epoch[59] Batch [260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.080457,	
2017-07-20 20:50:57,255 Epoch[59] Batch [270]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.080406,	
2017-07-20 20:51:01,651 Epoch[59] Batch [280]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.080358,	
2017-07-20 20:51:06,052 Epoch[59] Batch [290]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.080105,	
2017-07-20 20:51:10,434 Epoch[59] Batch [300]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.080254,	
2017-07-20 20:51:14,894 Epoch[59] Batch [310]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.080147,	
2017-07-20 20:51:19,457 Epoch[59] Batch [320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.080293,	
2017-07-20 20:51:24,134 Epoch[59] Batch [330]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.080321,	
2017-07-20 20:51:28,418 Epoch[59] Batch [340]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.080221,	
2017-07-20 20:51:32,765 Epoch[59] Batch [350]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.080165,	
2017-07-20 20:51:37,122 Epoch[59] Batch [360]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.079899,	
2017-07-20 20:51:41,593 Epoch[59] Batch [370]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.080070,	
2017-07-20 20:51:46,310 Epoch[59] Batch [380]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.080216,	
2017-07-20 20:51:51,082 Epoch[59] Batch [390]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.080092,	
2017-07-20 20:51:55,752 Epoch[59] Batch [400]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.080034,	
2017-07-20 20:52:00,095 Epoch[59] Batch [410]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.080005,	
2017-07-20 20:52:04,765 Epoch[59] Batch [420]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.080056,	
2017-07-20 20:52:09,255 Epoch[59] Batch [430]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.080130,	
2017-07-20 20:52:13,715 Epoch[59] Batch [440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.080264,	
2017-07-20 20:52:18,543 Epoch[59] Batch [450]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.080168,	
2017-07-20 20:52:23,447 Epoch[59] Batch [460]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.080079,	
2017-07-20 20:52:28,062 Epoch[59] Batch [470]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.079946,	
2017-07-20 20:52:32,654 Epoch[59] Batch [480]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.079870,	
2017-07-20 20:52:37,150 Epoch[59] Batch [490]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.079773,	
2017-07-20 20:52:42,077 Epoch[59] Batch [500]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.079794,	
2017-07-20 20:52:46,744 Epoch[59] Batch [510]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.079819,	
2017-07-20 20:52:51,011 Epoch[59] Batch [520]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.079931,	
2017-07-20 20:52:55,404 Epoch[59] Batch [530]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.079838,	
2017-07-20 20:52:59,743 Epoch[59] Batch [540]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.079810,	
2017-07-20 20:53:04,209 Epoch[59] Batch [550]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.079582,	
2017-07-20 20:53:08,741 Epoch[59] Batch [560]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.079671,	
2017-07-20 20:53:13,152 Epoch[59] Batch [570]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.079813,	
2017-07-20 20:53:17,709 Epoch[59] Batch [580]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.079818,	
2017-07-20 20:53:22,349 Epoch[59] Batch [590]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.079764,	
2017-07-20 20:53:26,912 Epoch[59] Batch [600]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079663,	
2017-07-20 20:53:31,523 Epoch[59] Batch [610]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.079563,	
2017-07-20 20:53:36,205 Epoch[59] Batch [620]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.079581,	
2017-07-20 20:53:41,090 Epoch[59] Batch [630]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.079602,	
2017-07-20 20:53:46,014 Epoch[59] Batch [640]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.079607,	
2017-07-20 20:53:50,644 Epoch[59] Batch [650]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.079684,	
2017-07-20 20:53:55,536 Epoch[59] Batch [660]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.079685,	
2017-07-20 20:54:00,279 Epoch[59] Batch [670]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.079602,	
2017-07-20 20:54:05,008 Epoch[59] Batch [680]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.079727,	
2017-07-20 20:54:09,790 Epoch[59] Batch [690]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.079693,	
2017-07-20 20:54:14,542 Epoch[59] Batch [700]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.079797,	
2017-07-20 20:54:19,005 Epoch[59] Batch [710]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.079959,	
2017-07-20 20:54:23,788 Epoch[59] Batch [720]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.079995,	
2017-07-20 20:54:28,684 Epoch[59] Batch [730]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.080029,	
2017-07-20 20:54:33,176 Epoch[59] Batch [740]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.081018,	
2017-07-20 20:54:37,870 Epoch[59] Batch [750]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.083626,	
2017-07-20 20:54:42,864 Epoch[59] Batch [760]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.085026,	
2017-07-20 20:54:47,503 Epoch[59] Batch [770]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086137,	
2017-07-20 20:54:52,177 Epoch[59] Batch [780]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.086781,	
2017-07-20 20:54:56,805 Epoch[59] Batch [790]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087187,	
2017-07-20 20:55:01,496 Epoch[59] Batch [800]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087704,	
2017-07-20 20:55:06,189 Epoch[59] Batch [810]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088255,	
2017-07-20 20:55:11,361 Epoch[59] Batch [820]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089340,	
2017-07-20 20:55:16,348 Epoch[59] Batch [830]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.090207,	
2017-07-20 20:55:21,517 Epoch[59] Batch [840]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090996,	
2017-07-20 20:55:26,555 Epoch[59] Batch [850]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092544,	
2017-07-20 20:55:31,667 Epoch[59] Batch [860]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.093615,	
2017-07-20 20:55:36,053 Epoch[59] Batch [870]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.094157,	
2017-07-20 20:55:40,669 Epoch[59] Batch [880]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.094692,	
2017-07-20 20:55:45,310 Epoch[59] Batch [890]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.095010,	
2017-07-20 20:55:50,032 Epoch[59] Batch [900]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.095250,	
2017-07-20 20:55:54,492 Epoch[59] Batch [910]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.095403,	
2017-07-20 20:55:58,852 Epoch[59] Batch [920]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095648,	
2017-07-20 20:56:03,222 Epoch[59] Batch [930]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096009,	
2017-07-20 20:56:07,690 Epoch[59] Batch [940]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.096353,	
2017-07-20 20:56:12,168 Epoch[59] Batch [950]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.097075,	
2017-07-20 20:56:16,884 Epoch[59] Batch [960]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.097728,	
2017-07-20 20:56:21,354 Epoch[59] Batch [970]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.098235,	
2017-07-20 20:56:25,938 Epoch[59] Batch [980]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.098518,	
2017-07-20 20:56:30,275 Epoch[59] Batch [990]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.098653,	
2017-07-20 20:56:35,030 Epoch[59] Batch [1000]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098724,	
2017-07-20 20:56:39,440 Epoch[59] Batch [1010]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.098822,	
2017-07-20 20:56:43,905 Epoch[59] Batch [1020]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.099030,	
2017-07-20 20:56:48,388 Epoch[59] Batch [1030]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.099056,	
2017-07-20 20:56:53,244 Epoch[59] Batch [1040]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.099141,	
2017-07-20 20:56:57,512 Epoch[59] Batch [1050]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.099103,	
2017-07-20 20:57:02,057 Epoch[59] Batch [1060]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.099076,	
2017-07-20 20:57:06,914 Epoch[59] Batch [1070]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.099065,	
2017-07-20 20:57:11,594 Epoch[59] Batch [1080]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.099009,	
2017-07-20 20:57:16,083 Epoch[59] Batch [1090]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.099064,	
2017-07-20 20:57:20,777 Epoch[59] Batch [1100]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.099089,	
2017-07-20 20:57:25,475 Epoch[59] Batch [1110]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.099017,	
2017-07-20 20:57:30,050 Epoch[59] Batch [1120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.098997,	
2017-07-20 20:57:34,602 Epoch[59] Batch [1130]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.098902,	
2017-07-20 20:57:39,425 Epoch[59] Batch [1140]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.098887,	
2017-07-20 20:57:44,475 Epoch[59] Batch [1150]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.098760,	
2017-07-20 20:57:49,309 Epoch[59] Batch [1160]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.098706,	
2017-07-20 20:57:53,981 Epoch[59] Batch [1170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.098632,	
2017-07-20 20:57:58,699 Epoch[59] Batch [1180]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.098668,	
2017-07-20 20:58:03,702 Epoch[59] Batch [1190]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098690,	
2017-07-20 20:58:08,526 Epoch[59] Batch [1200]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.098636,	
2017-07-20 20:58:13,296 Epoch[59] Batch [1210]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.098560,	
2017-07-20 20:58:17,858 Epoch[59] Batch [1220]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.098517,	
2017-07-20 20:58:22,230 Epoch[59] Batch [1230]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.098579,	
2017-07-20 20:58:26,631 Epoch[59] Batch [1240]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098734,	
2017-07-20 20:58:30,942 Epoch[59] Batch [1250]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.098692,	
2017-07-20 20:58:35,501 Epoch[59] Batch [1260]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.098663,	
2017-07-20 20:58:40,216 Epoch[59] Batch [1270]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.098701,	
2017-07-20 20:58:44,840 Epoch[59] Batch [1280]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.099136,	
2017-07-20 20:58:49,275 Epoch[59] Batch [1290]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.099269,	
2017-07-20 20:58:54,023 Epoch[59] Batch [1300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099394,	
2017-07-20 20:58:58,623 Epoch[59] Batch [1310]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.099426,	
2017-07-20 20:59:03,338 Epoch[59] Batch [1320]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.099454,	
2017-07-20 20:59:08,151 Epoch[59] Batch [1330]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.099406,	
2017-07-20 20:59:13,153 Epoch[59] Batch [1340]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.099426,	
2017-07-20 20:59:17,687 Epoch[59] Batch [1350]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.099318,	
2017-07-20 20:59:22,435 Epoch[59] Batch [1360]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.099282,	
2017-07-20 20:59:26,908 Epoch[59] Batch [1370]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.099203,	
2017-07-20 20:59:31,522 Epoch[59] Batch [1380]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.099147,	
2017-07-20 20:59:36,325 Epoch[59] Batch [1390]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.099090,	
2017-07-20 20:59:40,839 Epoch[59] Batch [1400]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.099070,	
2017-07-20 20:59:45,877 Epoch[59] Batch [1410]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.099037,	
2017-07-20 20:59:50,131 Epoch[59] Batch [1420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.099008,	
2017-07-20 20:59:54,645 Epoch[59] Batch [1430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.098952,	
2017-07-20 20:59:59,010 Epoch[59] Batch [1440]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.098887,	
2017-07-20 21:00:03,937 Epoch[59] Batch [1450]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.098814,	
2017-07-20 21:00:08,775 Epoch[59] Batch [1460]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.098759,	
2017-07-20 21:00:13,168 Epoch[59] Batch [1470]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.098713,	
2017-07-20 21:00:17,815 Epoch[59] Batch [1480]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.098693,	
2017-07-20 21:00:20,581 Epoch[59] Train-FCNLogLoss=0.098636
2017-07-20 21:00:20,581 Epoch[59] Time cost=688.696
2017-07-20 21:00:21,380 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0060.params"
2017-07-20 21:00:24,884 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0060.states"
2017-07-20 21:00:30,565 Epoch[60] Batch [10]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.085707,	
2017-07-20 21:00:35,285 Epoch[60] Batch [20]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088961,	
2017-07-20 21:00:39,654 Update[89251]: Change learning rate to 5.00000e-05
2017-07-20 21:00:39,926 Epoch[60] Batch [30]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088869,	
2017-07-20 21:00:44,173 Epoch[60] Batch [40]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.093247,	
2017-07-20 21:00:48,561 Epoch[60] Batch [50]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095706,	
2017-07-20 21:00:52,967 Epoch[60] Batch [60]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.093924,	
2017-07-20 21:00:57,568 Epoch[60] Batch [70]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092439,	
2017-07-20 21:01:02,409 Epoch[60] Batch [80]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091829,	
2017-07-20 21:01:06,784 Epoch[60] Batch [90]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.091085,	
2017-07-20 21:01:11,308 Epoch[60] Batch [100]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091129,	
2017-07-20 21:01:15,877 Epoch[60] Batch [110]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090715,	
2017-07-20 21:01:20,306 Epoch[60] Batch [120]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.089665,	
2017-07-20 21:01:25,195 Epoch[60] Batch [130]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.089940,	
2017-07-20 21:01:29,750 Epoch[60] Batch [140]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089748,	
2017-07-20 21:01:34,324 Epoch[60] Batch [150]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088844,	
2017-07-20 21:01:38,880 Epoch[60] Batch [160]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088661,	
2017-07-20 21:01:43,094 Epoch[60] Batch [170]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.088294,	
2017-07-20 21:01:47,299 Epoch[60] Batch [180]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.087989,	
2017-07-20 21:01:51,733 Epoch[60] Batch [190]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088639,	
2017-07-20 21:01:56,210 Epoch[60] Batch [200]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.088589,	
2017-07-20 21:02:00,587 Epoch[60] Batch [210]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.088285,	
2017-07-20 21:02:05,204 Epoch[60] Batch [220]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088444,	
2017-07-20 21:02:09,849 Epoch[60] Batch [230]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088090,	
2017-07-20 21:02:13,949 Epoch[60] Batch [240]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.087842,	
2017-07-20 21:02:18,226 Epoch[60] Batch [250]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.087989,	
2017-07-20 21:02:22,575 Epoch[60] Batch [260]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087836,	
2017-07-20 21:02:26,982 Epoch[60] Batch [270]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087927,	
2017-07-20 21:02:31,465 Epoch[60] Batch [280]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087933,	
2017-07-20 21:02:35,946 Epoch[60] Batch [290]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087566,	
2017-07-20 21:02:40,483 Epoch[60] Batch [300]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087327,	
2017-07-20 21:02:44,997 Epoch[60] Batch [310]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087357,	
2017-07-20 21:02:49,339 Epoch[60] Batch [320]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.087219,	
2017-07-20 21:02:54,101 Epoch[60] Batch [330]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086824,	
2017-07-20 21:02:58,956 Epoch[60] Batch [340]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086558,	
2017-07-20 21:03:03,757 Epoch[60] Batch [350]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086538,	
2017-07-20 21:03:08,303 Epoch[60] Batch [360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.086374,	
2017-07-20 21:03:12,927 Epoch[60] Batch [370]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086515,	
2017-07-20 21:03:17,773 Epoch[60] Batch [380]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086309,	
2017-07-20 21:03:22,912 Epoch[60] Batch [390]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.086215,	
2017-07-20 21:03:27,803 Epoch[60] Batch [400]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086232,	
2017-07-20 21:03:32,514 Epoch[60] Batch [410]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.086340,	
2017-07-20 21:03:37,411 Epoch[60] Batch [420]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086233,	
2017-07-20 21:03:41,927 Epoch[60] Batch [430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086310,	
2017-07-20 21:03:46,678 Epoch[60] Batch [440]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.086252,	
2017-07-20 21:03:51,328 Epoch[60] Batch [450]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086192,	
2017-07-20 21:03:55,707 Epoch[60] Batch [460]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.086186,	
2017-07-20 21:04:00,266 Epoch[60] Batch [470]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086178,	
2017-07-20 21:04:04,920 Epoch[60] Batch [480]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086038,	
2017-07-20 21:04:09,168 Epoch[60] Batch [490]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.086105,	
2017-07-20 21:04:13,692 Epoch[60] Batch [500]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.085993,	
2017-07-20 21:04:18,380 Epoch[60] Batch [510]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.085934,	
2017-07-20 21:04:23,201 Epoch[60] Batch [520]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086029,	
2017-07-20 21:04:28,277 Epoch[60] Batch [530]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.085845,	
2017-07-20 21:04:33,117 Epoch[60] Batch [540]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.085775,	
2017-07-20 21:04:37,898 Epoch[60] Batch [550]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.085787,	
2017-07-20 21:04:42,935 Epoch[60] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.085774,	
2017-07-20 21:04:47,838 Epoch[60] Batch [570]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.085627,	
2017-07-20 21:04:52,577 Epoch[60] Batch [580]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.085746,	
2017-07-20 21:04:57,510 Epoch[60] Batch [590]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.085646,	
2017-07-20 21:05:02,597 Epoch[60] Batch [600]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.085453,	
2017-07-20 21:05:07,177 Epoch[60] Batch [610]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.085458,	
2017-07-20 21:05:12,279 Epoch[60] Batch [620]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.085451,	
2017-07-20 21:05:17,407 Epoch[60] Batch [630]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.085522,	
2017-07-20 21:05:21,859 Epoch[60] Batch [640]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.085508,	
2017-07-20 21:05:26,569 Epoch[60] Batch [650]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.085553,	
2017-07-20 21:05:31,165 Epoch[60] Batch [660]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.085605,	
2017-07-20 21:05:35,802 Epoch[60] Batch [670]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.085597,	
2017-07-20 21:05:40,205 Epoch[60] Batch [680]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.085686,	
2017-07-20 21:05:44,904 Epoch[60] Batch [690]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.085756,	
2017-07-20 21:05:49,592 Epoch[60] Batch [700]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.085743,	
2017-07-20 21:05:54,571 Epoch[60] Batch [710]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.085630,	
2017-07-20 21:05:59,351 Epoch[60] Batch [720]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.085602,	
2017-07-20 21:06:04,832 Epoch[60] Batch [730]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.085656,	
2017-07-20 21:06:09,684 Epoch[60] Batch [740]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.085545,	
2017-07-20 21:06:14,524 Epoch[60] Batch [750]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.085381,	
2017-07-20 21:06:18,920 Epoch[60] Batch [760]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.085256,	
2017-07-20 21:06:23,618 Epoch[60] Batch [770]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.085224,	
2017-07-20 21:06:27,951 Epoch[60] Batch [780]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.085165,	
2017-07-20 21:06:32,487 Epoch[60] Batch [790]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.085124,	
2017-07-20 21:06:37,298 Epoch[60] Batch [800]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.084857,	
2017-07-20 21:06:42,315 Epoch[60] Batch [810]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.084891,	
2017-07-20 21:06:47,122 Epoch[60] Batch [820]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.084829,	
2017-07-20 21:06:52,049 Epoch[60] Batch [830]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.084856,	
2017-07-20 21:06:56,935 Epoch[60] Batch [840]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.084745,	
2017-07-20 21:07:01,584 Epoch[60] Batch [850]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.084719,	
2017-07-20 21:07:06,415 Epoch[60] Batch [860]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.084656,	
2017-07-20 21:07:11,752 Epoch[60] Batch [870]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.084534,	
2017-07-20 21:07:16,249 Epoch[60] Batch [880]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.084488,	
2017-07-20 21:07:20,990 Epoch[60] Batch [890]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.084329,	
2017-07-20 21:07:26,112 Epoch[60] Batch [900]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.084285,	
2017-07-20 21:07:31,222 Epoch[60] Batch [910]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.084322,	
2017-07-20 21:07:35,905 Epoch[60] Batch [920]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.084346,	
2017-07-20 21:07:41,028 Epoch[60] Batch [930]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.084333,	
2017-07-20 21:07:45,920 Epoch[60] Batch [940]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.084384,	
2017-07-20 21:07:50,782 Epoch[60] Batch [950]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.084398,	
2017-07-20 21:07:55,445 Epoch[60] Batch [960]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.084430,	
2017-07-20 21:08:00,139 Epoch[60] Batch [970]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.084417,	
2017-07-20 21:08:04,791 Epoch[60] Batch [980]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.084379,	
2017-07-20 21:08:09,573 Epoch[60] Batch [990]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.084271,	
2017-07-20 21:08:14,957 Epoch[60] Batch [1000]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.084235,	
2017-07-20 21:08:20,016 Epoch[60] Batch [1010]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.084218,	
2017-07-20 21:08:24,719 Epoch[60] Batch [1020]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.084110,	
2017-07-20 21:08:29,349 Epoch[60] Batch [1030]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.084065,	
2017-07-20 21:08:34,189 Epoch[60] Batch [1040]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.084109,	
2017-07-20 21:08:38,934 Epoch[60] Batch [1050]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.084157,	
2017-07-20 21:08:43,652 Epoch[60] Batch [1060]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.084128,	
2017-07-20 21:08:48,272 Epoch[60] Batch [1070]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.084007,	
2017-07-20 21:08:53,190 Epoch[60] Batch [1080]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.084019,	
2017-07-20 21:08:58,038 Epoch[60] Batch [1090]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.084008,	
2017-07-20 21:09:02,827 Epoch[60] Batch [1100]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.083954,	
2017-07-20 21:09:07,780 Epoch[60] Batch [1110]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.083922,	
2017-07-20 21:09:12,522 Epoch[60] Batch [1120]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.083914,	
2017-07-20 21:09:17,496 Epoch[60] Batch [1130]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.083874,	
2017-07-20 21:09:22,469 Epoch[60] Batch [1140]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.083877,	
2017-07-20 21:09:27,712 Epoch[60] Batch [1150]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.083776,	
2017-07-20 21:09:32,888 Epoch[60] Batch [1160]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.083786,	
2017-07-20 21:09:38,012 Epoch[60] Batch [1170]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.083869,	
2017-07-20 21:09:43,049 Epoch[60] Batch [1180]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.083897,	
2017-07-20 21:09:47,986 Epoch[60] Batch [1190]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.083880,	
2017-07-20 21:09:52,796 Epoch[60] Batch [1200]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.083839,	
2017-07-20 21:09:58,060 Epoch[60] Batch [1210]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.083793,	
2017-07-20 21:10:03,014 Epoch[60] Batch [1220]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.083742,	
2017-07-20 21:10:07,789 Epoch[60] Batch [1230]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.083703,	
2017-07-20 21:10:12,454 Epoch[60] Batch [1240]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.083675,	
2017-07-20 21:10:17,054 Epoch[60] Batch [1250]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.083727,	
2017-07-20 21:10:21,931 Epoch[60] Batch [1260]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.083747,	
2017-07-20 21:10:26,677 Epoch[60] Batch [1270]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.083679,	
2017-07-20 21:10:31,344 Epoch[60] Batch [1280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.083695,	
2017-07-20 21:10:36,474 Epoch[60] Batch [1290]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.083632,	
2017-07-20 21:10:41,312 Epoch[60] Batch [1300]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.083624,	
2017-07-20 21:10:45,860 Epoch[60] Batch [1310]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.083553,	
2017-07-20 21:10:50,840 Epoch[60] Batch [1320]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.083554,	
2017-07-20 21:10:55,586 Epoch[60] Batch [1330]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.083521,	
2017-07-20 21:11:00,590 Epoch[60] Batch [1340]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.083475,	
2017-07-20 21:11:05,173 Epoch[60] Batch [1350]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.083391,	
2017-07-20 21:11:09,793 Epoch[60] Batch [1360]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.083398,	
2017-07-20 21:11:14,588 Epoch[60] Batch [1370]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.083374,	
2017-07-20 21:11:19,277 Epoch[60] Batch [1380]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.083355,	
2017-07-20 21:11:23,958 Epoch[60] Batch [1390]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.083325,	
2017-07-20 21:11:28,500 Epoch[60] Batch [1400]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.083256,	
2017-07-20 21:11:33,099 Epoch[60] Batch [1410]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.083291,	
2017-07-20 21:11:37,683 Epoch[60] Batch [1420]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.083294,	
2017-07-20 21:11:42,741 Epoch[60] Batch [1430]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.083309,	
2017-07-20 21:11:47,211 Epoch[60] Batch [1440]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.083273,	
2017-07-20 21:11:51,864 Epoch[60] Batch [1450]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.083267,	
2017-07-20 21:11:56,796 Epoch[60] Batch [1460]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.083262,	
2017-07-20 21:12:01,568 Epoch[60] Batch [1470]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.083201,	
2017-07-20 21:12:06,226 Epoch[60] Batch [1480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.083135,	
2017-07-20 21:12:09,178 Epoch[60] Train-FCNLogLoss=0.083092
2017-07-20 21:12:09,178 Epoch[60] Time cost=704.293
2017-07-20 21:12:10,023 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0061.params"
2017-07-20 21:12:13,338 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0061.states"
2017-07-20 21:12:19,136 Epoch[61] Batch [10]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.082153,	
2017-07-20 21:12:24,157 Epoch[61] Batch [20]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.083717,	
2017-07-20 21:12:28,832 Epoch[61] Batch [30]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.081072,	
2017-07-20 21:12:33,713 Epoch[61] Batch [40]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.082587,	
2017-07-20 21:12:38,810 Epoch[61] Batch [50]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.085216,	
2017-07-20 21:12:43,662 Epoch[61] Batch [60]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.084241,	
2017-07-20 21:12:48,209 Epoch[61] Batch [70]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.083620,	
2017-07-20 21:12:52,675 Epoch[61] Batch [80]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.082628,	
2017-07-20 21:12:57,837 Epoch[61] Batch [90]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.083061,	
2017-07-20 21:13:02,656 Epoch[61] Batch [100]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.082797,	
2017-07-20 21:13:07,260 Epoch[61] Batch [110]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.082367,	
2017-07-20 21:13:11,776 Epoch[61] Batch [120]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.082482,	
2017-07-20 21:13:16,286 Epoch[61] Batch [130]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.081870,	
2017-07-20 21:13:20,775 Epoch[61] Batch [140]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.081625,	
2017-07-20 21:13:25,175 Epoch[61] Batch [150]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.081334,	
2017-07-20 21:13:29,822 Epoch[61] Batch [160]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.081432,	
2017-07-20 21:13:34,416 Epoch[61] Batch [170]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.081865,	
2017-07-20 21:13:38,939 Epoch[61] Batch [180]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.082382,	
2017-07-20 21:13:43,409 Epoch[61] Batch [190]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.082203,	
2017-07-20 21:13:47,824 Epoch[61] Batch [200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.082248,	
2017-07-20 21:13:52,571 Epoch[61] Batch [210]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.082354,	
2017-07-20 21:13:56,984 Epoch[61] Batch [220]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.082160,	
2017-07-20 21:14:01,448 Epoch[61] Batch [230]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.082195,	
2017-07-20 21:14:05,997 Epoch[61] Batch [240]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.081974,	
2017-07-20 21:14:10,670 Epoch[61] Batch [250]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.081868,	
2017-07-20 21:14:15,506 Epoch[61] Batch [260]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.081753,	
2017-07-20 21:14:20,328 Epoch[61] Batch [270]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.081525,	
2017-07-20 21:14:25,125 Epoch[61] Batch [280]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.081746,	
2017-07-20 21:14:30,005 Epoch[61] Batch [290]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.081752,	
2017-07-20 21:14:35,557 Epoch[61] Batch [300]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.081695,	
2017-07-20 21:14:40,730 Epoch[61] Batch [310]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.081391,	
2017-07-20 21:14:45,428 Epoch[61] Batch [320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.081708,	
2017-07-20 21:14:50,909 Epoch[61] Batch [330]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.081677,	
2017-07-20 21:14:55,547 Epoch[61] Batch [340]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.081759,	
2017-07-20 21:15:00,264 Epoch[61] Batch [350]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.081707,	
2017-07-20 21:15:05,087 Epoch[61] Batch [360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.081818,	
2017-07-20 21:15:09,616 Epoch[61] Batch [370]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.081548,	
2017-07-20 21:15:14,109 Epoch[61] Batch [380]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.081361,	
2017-07-20 21:15:18,914 Epoch[61] Batch [390]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.081301,	
2017-07-20 21:15:23,522 Epoch[61] Batch [400]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.081224,	
2017-07-20 21:15:28,160 Epoch[61] Batch [410]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.081051,	
2017-07-20 21:15:33,083 Epoch[61] Batch [420]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.081228,	
2017-07-20 21:15:37,489 Epoch[61] Batch [430]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.081159,	
2017-07-20 21:15:41,747 Epoch[61] Batch [440]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.081085,	
2017-07-20 21:15:46,425 Epoch[61] Batch [450]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.081122,	
2017-07-20 21:15:50,680 Epoch[61] Batch [460]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.081129,	
2017-07-20 21:15:55,033 Epoch[61] Batch [470]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.081178,	
2017-07-20 21:15:59,521 Epoch[61] Batch [480]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.080981,	
2017-07-20 21:16:04,165 Epoch[61] Batch [490]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.080746,	
2017-07-20 21:16:08,745 Epoch[61] Batch [500]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.080676,	
2017-07-20 21:16:13,779 Epoch[61] Batch [510]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.080661,	
2017-07-20 21:16:18,498 Epoch[61] Batch [520]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.080553,	
2017-07-20 21:16:22,890 Epoch[61] Batch [530]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.080474,	
2017-07-20 21:16:27,826 Epoch[61] Batch [540]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.080487,	
2017-07-20 21:16:32,671 Epoch[61] Batch [550]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.080454,	
2017-07-20 21:16:37,785 Epoch[61] Batch [560]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.080511,	
2017-07-20 21:16:42,952 Epoch[61] Batch [570]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.080426,	
2017-07-20 21:16:47,808 Epoch[61] Batch [580]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.080293,	
2017-07-20 21:16:52,607 Epoch[61] Batch [590]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.080424,	
2017-07-20 21:16:57,270 Epoch[61] Batch [600]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.080484,	
2017-07-20 21:17:02,471 Epoch[61] Batch [610]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.080576,	
2017-07-20 21:17:07,173 Epoch[61] Batch [620]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.080561,	
2017-07-20 21:17:12,012 Epoch[61] Batch [630]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.080497,	
2017-07-20 21:17:17,095 Epoch[61] Batch [640]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.080458,	
2017-07-20 21:17:21,698 Epoch[61] Batch [650]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.080482,	
2017-07-20 21:17:26,214 Epoch[61] Batch [660]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.080478,	
2017-07-20 21:17:30,696 Epoch[61] Batch [670]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.080531,	
2017-07-20 21:17:35,451 Epoch[61] Batch [680]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.080515,	
2017-07-20 21:17:40,113 Epoch[61] Batch [690]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.080553,	
2017-07-20 21:17:44,917 Epoch[61] Batch [700]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.080528,	
2017-07-20 21:17:49,326 Epoch[61] Batch [710]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.080618,	
2017-07-20 21:17:54,083 Epoch[61] Batch [720]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.080544,	
2017-07-20 21:17:59,053 Epoch[61] Batch [730]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.080578,	
2017-07-20 21:18:04,172 Epoch[61] Batch [740]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.080572,	
2017-07-20 21:18:08,845 Epoch[61] Batch [750]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.080775,	
2017-07-20 21:18:13,772 Epoch[61] Batch [760]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.080814,	
2017-07-20 21:18:18,849 Epoch[61] Batch [770]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.080781,	
2017-07-20 21:18:23,747 Epoch[61] Batch [780]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.080745,	
2017-07-20 21:18:28,224 Epoch[61] Batch [790]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.080795,	
2017-07-20 21:18:33,019 Epoch[61] Batch [800]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.080803,	
2017-07-20 21:18:37,794 Epoch[61] Batch [810]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.080782,	
2017-07-20 21:18:42,540 Epoch[61] Batch [820]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.080784,	
2017-07-20 21:18:47,092 Epoch[61] Batch [830]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.080731,	
2017-07-20 21:18:51,755 Epoch[61] Batch [840]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.080864,	
2017-07-20 21:18:56,534 Epoch[61] Batch [850]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.080814,	
2017-07-20 21:19:01,377 Epoch[61] Batch [860]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.080857,	
2017-07-20 21:19:06,076 Epoch[61] Batch [870]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.080886,	
2017-07-20 21:19:11,098 Epoch[61] Batch [880]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.080960,	
2017-07-20 21:19:15,799 Epoch[61] Batch [890]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.080960,	
2017-07-20 21:19:20,323 Epoch[61] Batch [900]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.080944,	
2017-07-20 21:19:24,966 Epoch[61] Batch [910]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.081049,	
2017-07-20 21:19:30,142 Epoch[61] Batch [920]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.081069,	
2017-07-20 21:19:34,665 Epoch[61] Batch [930]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.081139,	
2017-07-20 21:19:39,312 Epoch[61] Batch [940]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.081169,	
2017-07-20 21:19:44,505 Epoch[61] Batch [950]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.081160,	
2017-07-20 21:19:49,121 Epoch[61] Batch [960]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.081143,	
2017-07-20 21:19:54,370 Epoch[61] Batch [970]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.081097,	
2017-07-20 21:19:58,752 Epoch[61] Batch [980]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.081090,	
2017-07-20 21:20:03,647 Epoch[61] Batch [990]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.081134,	
2017-07-20 21:20:08,162 Epoch[61] Batch [1000]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.081102,	
2017-07-20 21:20:12,580 Epoch[61] Batch [1010]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.081234,	
2017-07-20 21:20:17,342 Epoch[61] Batch [1020]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.081159,	
2017-07-20 21:20:21,711 Epoch[61] Batch [1030]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.081153,	
2017-07-20 21:20:26,250 Epoch[61] Batch [1040]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.081124,	
2017-07-20 21:20:31,166 Epoch[61] Batch [1050]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.081134,	
2017-07-20 21:20:36,196 Epoch[61] Batch [1060]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.081060,	
2017-07-20 21:20:40,891 Epoch[61] Batch [1070]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.081036,	
2017-07-20 21:20:45,614 Epoch[61] Batch [1080]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.080971,	
2017-07-20 21:20:50,527 Epoch[61] Batch [1090]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.080952,	
2017-07-20 21:20:55,700 Epoch[61] Batch [1100]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.080878,	
2017-07-20 21:21:00,709 Epoch[61] Batch [1110]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.080887,	
2017-07-20 21:21:05,660 Epoch[61] Batch [1120]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.080858,	
2017-07-20 21:21:10,266 Epoch[61] Batch [1130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.080832,	
2017-07-20 21:21:14,882 Epoch[61] Batch [1140]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.080760,	
2017-07-20 21:21:19,773 Epoch[61] Batch [1150]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.080792,	
2017-07-20 21:21:24,584 Epoch[61] Batch [1160]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.080857,	
2017-07-20 21:21:29,751 Epoch[61] Batch [1170]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.080850,	
2017-07-20 21:21:34,154 Epoch[61] Batch [1180]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.080770,	
2017-07-20 21:21:38,824 Epoch[61] Batch [1190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.080786,	
2017-07-20 21:21:43,457 Epoch[61] Batch [1200]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.080743,	
2017-07-20 21:21:47,812 Epoch[61] Batch [1210]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.080771,	
2017-07-20 21:21:52,381 Epoch[61] Batch [1220]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.080826,	
2017-07-20 21:21:56,932 Epoch[61] Batch [1230]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.080736,	
2017-07-20 21:22:01,462 Epoch[61] Batch [1240]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.080731,	
2017-07-20 21:22:06,571 Epoch[61] Batch [1250]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.080685,	
2017-07-20 21:22:11,146 Epoch[61] Batch [1260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.080704,	
2017-07-20 21:22:15,768 Epoch[61] Batch [1270]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.080706,	
2017-07-20 21:22:20,495 Epoch[61] Batch [1280]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.080735,	
2017-07-20 21:22:25,209 Epoch[61] Batch [1290]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.080788,	
2017-07-20 21:22:29,950 Epoch[61] Batch [1300]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.080749,	
2017-07-20 21:22:34,755 Epoch[61] Batch [1310]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.080733,	
2017-07-20 21:22:39,990 Epoch[61] Batch [1320]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.080684,	
2017-07-20 21:22:44,586 Epoch[61] Batch [1330]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.080747,	
2017-07-20 21:22:49,276 Epoch[61] Batch [1340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.080726,	
2017-07-20 21:22:54,015 Epoch[61] Batch [1350]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.080818,	
2017-07-20 21:22:58,640 Epoch[61] Batch [1360]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.080834,	
2017-07-20 21:23:03,397 Epoch[61] Batch [1370]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.080785,	
2017-07-20 21:23:07,871 Epoch[61] Batch [1380]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.080785,	
2017-07-20 21:23:12,237 Epoch[61] Batch [1390]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.080715,	
2017-07-20 21:23:16,821 Epoch[61] Batch [1400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.080694,	
2017-07-20 21:23:21,631 Epoch[61] Batch [1410]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.080632,	
2017-07-20 21:23:26,102 Epoch[61] Batch [1420]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.080635,	
2017-07-20 21:23:30,939 Epoch[61] Batch [1430]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.080601,	
2017-07-20 21:23:35,208 Epoch[61] Batch [1440]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.080572,	
2017-07-20 21:23:39,732 Epoch[61] Batch [1450]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.080543,	
2017-07-20 21:23:44,112 Epoch[61] Batch [1460]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.080596,	
2017-07-20 21:23:48,509 Epoch[61] Batch [1470]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.080598,	
2017-07-20 21:23:52,886 Epoch[61] Batch [1480]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.080578,	
2017-07-20 21:23:55,667 Epoch[61] Train-FCNLogLoss=0.080611
2017-07-20 21:23:55,667 Epoch[61] Time cost=702.328
2017-07-20 21:23:56,463 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0062.params"
2017-07-20 21:23:59,925 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0062.states"
2017-07-20 21:24:05,287 Epoch[62] Batch [10]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.071631,	
2017-07-20 21:24:09,780 Epoch[62] Batch [20]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.074816,	
2017-07-20 21:24:14,250 Epoch[62] Batch [30]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075260,	
2017-07-20 21:24:19,017 Epoch[62] Batch [40]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075339,	
2017-07-20 21:24:23,630 Epoch[62] Batch [50]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.076101,	
2017-07-20 21:24:28,234 Epoch[62] Batch [60]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077438,	
2017-07-20 21:24:33,294 Epoch[62] Batch [70]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.077075,	
2017-07-20 21:24:38,199 Epoch[62] Batch [80]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078194,	
2017-07-20 21:24:42,657 Epoch[62] Batch [90]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.079477,	
2017-07-20 21:24:47,095 Epoch[62] Batch [100]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.079783,	
2017-07-20 21:24:51,693 Epoch[62] Batch [110]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.079627,	
2017-07-20 21:24:56,166 Epoch[62] Batch [120]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.079815,	
2017-07-20 21:25:00,439 Epoch[62] Batch [130]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.080195,	
2017-07-20 21:25:05,170 Epoch[62] Batch [140]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.080550,	
2017-07-20 21:25:09,797 Epoch[62] Batch [150]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.079745,	
2017-07-20 21:25:14,173 Epoch[62] Batch [160]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.079152,	
2017-07-20 21:25:18,451 Epoch[62] Batch [170]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.078963,	
2017-07-20 21:25:22,964 Epoch[62] Batch [180]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.078585,	
2017-07-20 21:25:27,593 Epoch[62] Batch [190]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.078437,	
2017-07-20 21:25:32,470 Epoch[62] Batch [200]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.078431,	
2017-07-20 21:25:37,075 Epoch[62] Batch [210]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.078598,	
2017-07-20 21:25:41,840 Epoch[62] Batch [220]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078857,	
2017-07-20 21:25:46,111 Epoch[62] Batch [230]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.079127,	
2017-07-20 21:25:50,701 Epoch[62] Batch [240]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.079283,	
2017-07-20 21:25:55,132 Epoch[62] Batch [250]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.078746,	
2017-07-20 21:25:59,523 Epoch[62] Batch [260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.079027,	
2017-07-20 21:26:04,045 Epoch[62] Batch [270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.079358,	
2017-07-20 21:26:08,566 Epoch[62] Batch [280]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.079196,	
2017-07-20 21:26:13,064 Epoch[62] Batch [290]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.079305,	
2017-07-20 21:26:17,513 Epoch[62] Batch [300]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.079292,	
2017-07-20 21:26:22,003 Epoch[62] Batch [310]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.079430,	
2017-07-20 21:26:26,567 Epoch[62] Batch [320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079386,	
2017-07-20 21:26:31,003 Epoch[62] Batch [330]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.079323,	
2017-07-20 21:26:35,312 Epoch[62] Batch [340]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.079462,	
2017-07-20 21:26:39,987 Epoch[62] Batch [350]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.079363,	
2017-07-20 21:26:44,895 Epoch[62] Batch [360]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.079236,	
2017-07-20 21:26:49,213 Epoch[62] Batch [370]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.079069,	
2017-07-20 21:26:53,762 Epoch[62] Batch [380]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.079161,	
2017-07-20 21:26:58,575 Epoch[62] Batch [390]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.079041,	
2017-07-20 21:27:03,499 Epoch[62] Batch [400]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.079293,	
2017-07-20 21:27:08,978 Epoch[62] Batch [410]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.079295,	
2017-07-20 21:27:14,081 Epoch[62] Batch [420]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.079298,	
2017-07-20 21:27:18,716 Epoch[62] Batch [430]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.079227,	
2017-07-20 21:27:24,528 Epoch[62] Batch [440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.079076,	
2017-07-20 21:27:29,306 Epoch[62] Batch [450]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.079122,	
2017-07-20 21:27:34,244 Epoch[62] Batch [460]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.079297,	
2017-07-20 21:27:38,742 Epoch[62] Batch [470]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.079542,	
2017-07-20 21:27:43,938 Epoch[62] Batch [480]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.079419,	
2017-07-20 21:27:48,659 Epoch[62] Batch [490]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.079506,	
2017-07-20 21:27:53,164 Epoch[62] Batch [500]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.079543,	
2017-07-20 21:27:57,996 Epoch[62] Batch [510]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.079592,	
2017-07-20 21:28:02,815 Epoch[62] Batch [520]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.079450,	
2017-07-20 21:28:07,746 Epoch[62] Batch [530]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.079523,	
2017-07-20 21:28:12,083 Epoch[62] Batch [540]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.079449,	
2017-07-20 21:28:16,713 Epoch[62] Batch [550]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.079505,	
2017-07-20 21:28:21,345 Epoch[62] Batch [560]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.079489,	
2017-07-20 21:28:25,887 Epoch[62] Batch [570]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.079453,	
2017-07-20 21:28:30,322 Epoch[62] Batch [580]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.079459,	
2017-07-20 21:28:34,758 Epoch[62] Batch [590]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.079549,	
2017-07-20 21:28:39,293 Epoch[62] Batch [600]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.079475,	
2017-07-20 21:28:43,971 Epoch[62] Batch [610]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.079456,	
2017-07-20 21:28:48,840 Epoch[62] Batch [620]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.079452,	
2017-07-20 21:28:53,549 Epoch[62] Batch [630]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.079459,	
2017-07-20 21:28:58,472 Epoch[62] Batch [640]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.079484,	
2017-07-20 21:29:03,199 Epoch[62] Batch [650]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079506,	
2017-07-20 21:29:07,930 Epoch[62] Batch [660]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079510,	
2017-07-20 21:29:13,152 Epoch[62] Batch [670]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.079441,	
2017-07-20 21:29:17,556 Epoch[62] Batch [680]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.079465,	
2017-07-20 21:29:22,323 Epoch[62] Batch [690]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.079540,	
2017-07-20 21:29:27,388 Epoch[62] Batch [700]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.079536,	
2017-07-20 21:29:31,942 Epoch[62] Batch [710]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.079415,	
2017-07-20 21:29:37,261 Epoch[62] Batch [720]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.079450,	
2017-07-20 21:29:42,491 Epoch[62] Batch [730]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.079391,	
2017-07-20 21:29:47,219 Epoch[62] Batch [740]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079397,	
2017-07-20 21:29:52,057 Epoch[62] Batch [750]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.079286,	
2017-07-20 21:29:56,922 Epoch[62] Batch [760]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.079243,	
2017-07-20 21:30:01,728 Epoch[62] Batch [770]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.079281,	
2017-07-20 21:30:06,324 Epoch[62] Batch [780]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.079263,	
2017-07-20 21:30:11,034 Epoch[62] Batch [790]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.079260,	
2017-07-20 21:30:16,325 Epoch[62] Batch [800]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.079308,	
2017-07-20 21:30:21,162 Epoch[62] Batch [810]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.079259,	
2017-07-20 21:30:26,049 Epoch[62] Batch [820]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.079301,	
2017-07-20 21:30:30,880 Epoch[62] Batch [830]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.079446,	
2017-07-20 21:30:35,570 Epoch[62] Batch [840]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.079399,	
2017-07-20 21:30:40,597 Epoch[62] Batch [850]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.079520,	
2017-07-20 21:30:45,207 Epoch[62] Batch [860]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.079535,	
2017-07-20 21:30:50,027 Epoch[62] Batch [870]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.079508,	
2017-07-20 21:30:54,562 Epoch[62] Batch [880]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.079375,	
2017-07-20 21:30:59,380 Epoch[62] Batch [890]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.079337,	
2017-07-20 21:31:04,312 Epoch[62] Batch [900]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.079281,	
2017-07-20 21:31:08,973 Epoch[62] Batch [910]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.079269,	
2017-07-20 21:31:13,954 Epoch[62] Batch [920]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.079275,	
2017-07-20 21:31:19,115 Epoch[62] Batch [930]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.079213,	
2017-07-20 21:31:24,282 Epoch[62] Batch [940]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.079275,	
2017-07-20 21:31:28,880 Epoch[62] Batch [950]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.079307,	
2017-07-20 21:31:33,792 Epoch[62] Batch [960]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.079344,	
2017-07-20 21:31:39,010 Epoch[62] Batch [970]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.079353,	
2017-07-20 21:31:43,577 Epoch[62] Batch [980]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.079303,	
2017-07-20 21:31:48,514 Epoch[62] Batch [990]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.079344,	
2017-07-20 21:31:53,106 Epoch[62] Batch [1000]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.079346,	
2017-07-20 21:31:57,954 Epoch[62] Batch [1010]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.079472,	
2017-07-20 21:32:02,444 Epoch[62] Batch [1020]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.079520,	
2017-07-20 21:32:07,130 Epoch[62] Batch [1030]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.079603,	
2017-07-20 21:32:12,073 Epoch[62] Batch [1040]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.079570,	
2017-07-20 21:32:17,084 Epoch[62] Batch [1050]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.079690,	
2017-07-20 21:32:22,238 Epoch[62] Batch [1060]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.079747,	
2017-07-20 21:32:27,695 Epoch[62] Batch [1070]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.079685,	
2017-07-20 21:32:32,983 Epoch[62] Batch [1080]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.079717,	
2017-07-20 21:32:37,949 Epoch[62] Batch [1090]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.079726,	
2017-07-20 21:32:42,709 Epoch[62] Batch [1100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.079796,	
2017-07-20 21:32:47,575 Epoch[62] Batch [1110]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.079760,	
2017-07-20 21:32:52,411 Epoch[62] Batch [1120]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.079803,	
2017-07-20 21:32:57,277 Epoch[62] Batch [1130]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.079808,	
2017-07-20 21:33:02,516 Epoch[62] Batch [1140]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.079826,	
2017-07-20 21:33:07,182 Epoch[62] Batch [1150]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.079755,	
2017-07-20 21:33:12,127 Epoch[62] Batch [1160]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.079726,	
2017-07-20 21:33:17,054 Epoch[62] Batch [1170]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.079793,	
2017-07-20 21:33:21,952 Epoch[62] Batch [1180]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.079825,	
2017-07-20 21:33:26,845 Epoch[62] Batch [1190]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.079876,	
2017-07-20 21:33:31,507 Epoch[62] Batch [1200]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.079905,	
2017-07-20 21:33:36,068 Epoch[62] Batch [1210]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079879,	
2017-07-20 21:33:40,895 Epoch[62] Batch [1220]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.079913,	
2017-07-20 21:33:45,788 Epoch[62] Batch [1230]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.079929,	
2017-07-20 21:33:50,246 Epoch[62] Batch [1240]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.079902,	
2017-07-20 21:33:54,686 Epoch[62] Batch [1250]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.079885,	
2017-07-20 21:33:59,332 Epoch[62] Batch [1260]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.079886,	
2017-07-20 21:34:04,067 Epoch[62] Batch [1270]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.079883,	
2017-07-20 21:34:09,069 Epoch[62] Batch [1280]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.079868,	
2017-07-20 21:34:13,699 Epoch[62] Batch [1290]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.079915,	
2017-07-20 21:34:18,030 Epoch[62] Batch [1300]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.079851,	
2017-07-20 21:34:22,651 Epoch[62] Batch [1310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.079835,	
2017-07-20 21:34:27,140 Epoch[62] Batch [1320]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.079840,	
2017-07-20 21:34:31,913 Epoch[62] Batch [1330]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.079867,	
2017-07-20 21:34:36,432 Epoch[62] Batch [1340]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.079872,	
2017-07-20 21:34:41,047 Epoch[62] Batch [1350]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.079833,	
2017-07-20 21:34:45,621 Epoch[62] Batch [1360]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.079810,	
2017-07-20 21:34:50,591 Epoch[62] Batch [1370]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.079818,	
2017-07-20 21:34:55,267 Epoch[62] Batch [1380]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.079806,	
2017-07-20 21:35:00,171 Epoch[62] Batch [1390]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.079796,	
2017-07-20 21:35:04,936 Epoch[62] Batch [1400]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.079778,	
2017-07-20 21:35:09,611 Epoch[62] Batch [1410]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.079809,	
2017-07-20 21:35:14,472 Epoch[62] Batch [1420]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.079826,	
2017-07-20 21:35:19,271 Epoch[62] Batch [1430]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.079849,	
2017-07-20 21:35:23,859 Epoch[62] Batch [1440]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.079846,	
2017-07-20 21:35:28,422 Epoch[62] Batch [1450]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079776,	
2017-07-20 21:35:32,939 Epoch[62] Batch [1460]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.079769,	
2017-07-20 21:35:37,662 Epoch[62] Batch [1470]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.079778,	
2017-07-20 21:35:42,380 Epoch[62] Batch [1480]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.079803,	
2017-07-20 21:35:45,443 Epoch[62] Train-FCNLogLoss=0.079759
2017-07-20 21:35:45,444 Epoch[62] Time cost=705.518
2017-07-20 21:35:46,454 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0063.params"
2017-07-20 21:35:50,047 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0063.states"
2017-07-20 21:35:55,897 Epoch[63] Batch [10]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.078548,	
2017-07-20 21:36:01,057 Epoch[63] Batch [20]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.077441,	
2017-07-20 21:36:06,120 Epoch[63] Batch [30]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.077356,	
2017-07-20 21:36:10,866 Epoch[63] Batch [40]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078095,	
2017-07-20 21:36:15,714 Epoch[63] Batch [50]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.078919,	
2017-07-20 21:36:20,226 Epoch[63] Batch [60]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.077892,	
2017-07-20 21:36:24,795 Epoch[63] Batch [70]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.079123,	
2017-07-20 21:36:29,467 Epoch[63] Batch [80]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.079215,	
2017-07-20 21:36:33,935 Epoch[63] Batch [90]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.078067,	
2017-07-20 21:36:38,768 Epoch[63] Batch [100]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.077252,	
2017-07-20 21:36:43,491 Epoch[63] Batch [110]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.078118,	
2017-07-20 21:36:48,034 Epoch[63] Batch [120]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.079058,	
2017-07-20 21:36:52,846 Epoch[63] Batch [130]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.079549,	
2017-07-20 21:36:57,866 Epoch[63] Batch [140]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.079473,	
2017-07-20 21:37:02,351 Epoch[63] Batch [150]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.079756,	
2017-07-20 21:37:06,993 Epoch[63] Batch [160]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.079341,	
2017-07-20 21:37:12,041 Epoch[63] Batch [170]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.079578,	
2017-07-20 21:37:16,779 Epoch[63] Batch [180]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.079077,	
2017-07-20 21:37:21,621 Epoch[63] Batch [190]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.079170,	
2017-07-20 21:37:26,419 Epoch[63] Batch [200]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.079259,	
2017-07-20 21:37:31,284 Epoch[63] Batch [210]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.079187,	
2017-07-20 21:37:36,130 Epoch[63] Batch [220]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.079326,	
2017-07-20 21:37:40,871 Epoch[63] Batch [230]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.079512,	
2017-07-20 21:37:45,438 Epoch[63] Batch [240]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.079474,	
2017-07-20 21:37:50,163 Epoch[63] Batch [250]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.079523,	
2017-07-20 21:37:55,666 Epoch[63] Batch [260]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.079481,	
2017-07-20 21:38:00,552 Epoch[63] Batch [270]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.079485,	
2017-07-20 21:38:05,496 Epoch[63] Batch [280]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.079439,	
2017-07-20 21:38:10,549 Epoch[63] Batch [290]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.079354,	
2017-07-20 21:38:15,555 Epoch[63] Batch [300]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.079422,	
2017-07-20 21:38:20,641 Epoch[63] Batch [310]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.079343,	
2017-07-20 21:38:25,307 Epoch[63] Batch [320]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.079432,	
2017-07-20 21:38:30,139 Epoch[63] Batch [330]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.079375,	
2017-07-20 21:38:34,867 Epoch[63] Batch [340]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079197,	
2017-07-20 21:38:39,779 Epoch[63] Batch [350]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.079093,	
2017-07-20 21:38:44,881 Epoch[63] Batch [360]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.079170,	
2017-07-20 21:38:49,831 Epoch[63] Batch [370]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.079107,	
2017-07-20 21:38:54,827 Epoch[63] Batch [380]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.079314,	
2017-07-20 21:38:59,314 Epoch[63] Batch [390]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.079192,	
2017-07-20 21:39:04,351 Epoch[63] Batch [400]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.079180,	
2017-07-20 21:39:09,200 Epoch[63] Batch [410]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.079216,	
2017-07-20 21:39:13,863 Epoch[63] Batch [420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.079426,	
2017-07-20 21:39:19,096 Epoch[63] Batch [430]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.079492,	
2017-07-20 21:39:24,338 Epoch[63] Batch [440]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.079756,	
2017-07-20 21:39:29,615 Epoch[63] Batch [450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.079987,	
2017-07-20 21:39:34,714 Epoch[63] Batch [460]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.080178,	
2017-07-20 21:39:40,028 Epoch[63] Batch [470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.080172,	
2017-07-20 21:39:44,887 Epoch[63] Batch [480]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.080115,	
2017-07-20 21:39:49,247 Epoch[63] Batch [490]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.080073,	
2017-07-20 21:39:53,963 Epoch[63] Batch [500]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.080115,	
2017-07-20 21:39:58,657 Epoch[63] Batch [510]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.080228,	
2017-07-20 21:40:04,051 Epoch[63] Batch [520]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.080324,	
2017-07-20 21:40:08,838 Epoch[63] Batch [530]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.080522,	
2017-07-20 21:40:13,819 Epoch[63] Batch [540]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.080457,	
2017-07-20 21:40:18,788 Epoch[63] Batch [550]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.080421,	
2017-07-20 21:40:23,416 Epoch[63] Batch [560]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.080374,	
2017-07-20 21:40:28,590 Epoch[63] Batch [570]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.080270,	
2017-07-20 21:40:33,721 Epoch[63] Batch [580]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.080291,	
2017-07-20 21:40:38,806 Epoch[63] Batch [590]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.080291,	
2017-07-20 21:40:43,623 Epoch[63] Batch [600]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.080271,	
2017-07-20 21:40:48,374 Epoch[63] Batch [610]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.080233,	
2017-07-20 21:40:53,405 Epoch[63] Batch [620]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.080271,	
2017-07-20 21:40:58,254 Epoch[63] Batch [630]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.080307,	
2017-07-20 21:41:02,904 Epoch[63] Batch [640]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.080258,	
2017-07-20 21:41:07,871 Epoch[63] Batch [650]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.080266,	
2017-07-20 21:41:12,514 Epoch[63] Batch [660]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.080406,	
2017-07-20 21:41:17,205 Epoch[63] Batch [670]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.080435,	
2017-07-20 21:41:21,896 Epoch[63] Batch [680]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.080349,	
2017-07-20 21:41:26,946 Epoch[63] Batch [690]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.080339,	
2017-07-20 21:41:31,451 Epoch[63] Batch [700]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.080329,	
2017-07-20 21:41:36,272 Epoch[63] Batch [710]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.080308,	
2017-07-20 21:41:40,767 Epoch[63] Batch [720]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.080270,	
2017-07-20 21:41:45,940 Epoch[63] Batch [730]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.080247,	
2017-07-20 21:41:51,117 Epoch[63] Batch [740]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.080238,	
2017-07-20 21:41:56,518 Epoch[63] Batch [750]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.080305,	
2017-07-20 21:42:01,487 Epoch[63] Batch [760]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.080251,	
2017-07-20 21:42:06,247 Epoch[63] Batch [770]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.080279,	
2017-07-20 21:42:11,549 Epoch[63] Batch [780]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.080374,	
2017-07-20 21:42:16,720 Epoch[63] Batch [790]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.080327,	
2017-07-20 21:42:21,381 Epoch[63] Batch [800]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.080375,	
2017-07-20 21:42:26,132 Epoch[63] Batch [810]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.080353,	
2017-07-20 21:42:30,963 Epoch[63] Batch [820]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.080368,	
2017-07-20 21:42:35,685 Epoch[63] Batch [830]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.080292,	
2017-07-20 21:42:40,740 Epoch[63] Batch [840]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.080324,	
2017-07-20 21:42:45,957 Epoch[63] Batch [850]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.080424,	
2017-07-20 21:42:51,107 Epoch[63] Batch [860]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.080414,	
2017-07-20 21:42:56,192 Epoch[63] Batch [870]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.080366,	
2017-07-20 21:43:01,552 Epoch[63] Batch [880]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.080354,	
2017-07-20 21:43:06,728 Epoch[63] Batch [890]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.080318,	
2017-07-20 21:43:11,760 Epoch[63] Batch [900]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.080325,	
2017-07-20 21:43:16,577 Epoch[63] Batch [910]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.080245,	
2017-07-20 21:43:21,408 Epoch[63] Batch [920]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.080286,	
2017-07-20 21:43:26,309 Epoch[63] Batch [930]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.080205,	
2017-07-20 21:43:31,184 Epoch[63] Batch [940]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.080206,	
2017-07-20 21:43:36,100 Epoch[63] Batch [950]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.080246,	
2017-07-20 21:43:40,924 Epoch[63] Batch [960]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.080250,	
2017-07-20 21:43:45,408 Epoch[63] Batch [970]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.080244,	
2017-07-20 21:43:50,411 Epoch[63] Batch [980]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.080198,	
2017-07-20 21:43:55,055 Epoch[63] Batch [990]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.080181,	
2017-07-20 21:44:00,091 Epoch[63] Batch [1000]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.080125,	
2017-07-20 21:44:04,875 Epoch[63] Batch [1010]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.080103,	
2017-07-20 21:44:09,290 Epoch[63] Batch [1020]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.080088,	
2017-07-20 21:44:13,986 Epoch[63] Batch [1030]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.079987,	
2017-07-20 21:44:18,600 Epoch[63] Batch [1040]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.079978,	
2017-07-20 21:44:23,261 Epoch[63] Batch [1050]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.079917,	
2017-07-20 21:44:28,101 Epoch[63] Batch [1060]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.079861,	
2017-07-20 21:44:32,906 Epoch[63] Batch [1070]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.079850,	
2017-07-20 21:44:38,012 Epoch[63] Batch [1080]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.079850,	
2017-07-20 21:44:42,576 Epoch[63] Batch [1090]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079959,	
2017-07-20 21:44:47,063 Epoch[63] Batch [1100]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.079901,	
2017-07-20 21:44:51,802 Epoch[63] Batch [1110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.079844,	
2017-07-20 21:44:56,237 Epoch[63] Batch [1120]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.079769,	
2017-07-20 21:45:01,371 Epoch[63] Batch [1130]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.079794,	
2017-07-20 21:45:06,271 Epoch[63] Batch [1140]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.079749,	
2017-07-20 21:45:11,099 Epoch[63] Batch [1150]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.079705,	
2017-07-20 21:45:15,914 Epoch[63] Batch [1160]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.079676,	
2017-07-20 21:45:20,772 Epoch[63] Batch [1170]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.079673,	
2017-07-20 21:45:25,400 Epoch[63] Batch [1180]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.079647,	
2017-07-20 21:45:30,292 Epoch[63] Batch [1190]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.079664,	
2017-07-20 21:45:35,314 Epoch[63] Batch [1200]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.079672,	
2017-07-20 21:45:39,848 Epoch[63] Batch [1210]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.079666,	
2017-07-20 21:45:44,206 Epoch[63] Batch [1220]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.079677,	
2017-07-20 21:45:48,929 Epoch[63] Batch [1230]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.079717,	
2017-07-20 21:45:53,456 Epoch[63] Batch [1240]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.079667,	
2017-07-20 21:45:57,880 Epoch[63] Batch [1250]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.079639,	
2017-07-20 21:46:02,401 Epoch[63] Batch [1260]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.079663,	
2017-07-20 21:46:07,031 Epoch[63] Batch [1270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.079648,	
2017-07-20 21:46:11,737 Epoch[63] Batch [1280]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.079655,	
2017-07-20 21:46:16,414 Epoch[63] Batch [1290]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.079654,	
2017-07-20 21:46:21,074 Epoch[63] Batch [1300]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.079634,	
2017-07-20 21:46:25,760 Epoch[63] Batch [1310]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.079684,	
2017-07-20 21:46:30,264 Epoch[63] Batch [1320]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.079665,	
2017-07-20 21:46:34,919 Epoch[63] Batch [1330]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.079738,	
2017-07-20 21:46:39,469 Epoch[63] Batch [1340]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.079770,	
2017-07-20 21:46:44,167 Epoch[63] Batch [1350]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.079829,	
2017-07-20 21:46:48,762 Epoch[63] Batch [1360]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.079810,	
2017-07-20 21:46:53,504 Epoch[63] Batch [1370]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.079824,	
2017-07-20 21:46:58,126 Epoch[63] Batch [1380]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.079803,	
2017-07-20 21:47:02,653 Epoch[63] Batch [1390]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.079819,	
2017-07-20 21:47:07,465 Epoch[63] Batch [1400]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.079837,	
2017-07-20 21:47:11,939 Epoch[63] Batch [1410]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.079786,	
2017-07-20 21:47:16,946 Epoch[63] Batch [1420]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.079747,	
2017-07-20 21:47:21,794 Epoch[63] Batch [1430]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.079712,	
2017-07-20 21:47:26,470 Epoch[63] Batch [1440]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.079672,	
2017-07-20 21:47:31,031 Epoch[63] Batch [1450]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079636,	
2017-07-20 21:47:35,578 Epoch[63] Batch [1460]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.079693,	
2017-07-20 21:47:40,189 Epoch[63] Batch [1470]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.079724,	
2017-07-20 21:47:44,920 Epoch[63] Batch [1480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.079690,	
2017-07-20 21:47:47,663 Epoch[63] Train-FCNLogLoss=0.079666
2017-07-20 21:47:47,664 Epoch[63] Time cost=717.616
2017-07-20 21:47:48,694 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0064.params"
2017-07-20 21:47:52,132 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0064.states"
2017-07-20 21:47:57,734 Epoch[64] Batch [10]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.077475,	
2017-07-20 21:48:02,697 Epoch[64] Batch [20]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.081062,	
2017-07-20 21:48:07,325 Epoch[64] Batch [30]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.078068,	
2017-07-20 21:48:12,057 Epoch[64] Batch [40]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.076321,	
2017-07-20 21:48:16,687 Epoch[64] Batch [50]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.078923,	
2017-07-20 21:48:21,414 Epoch[64] Batch [60]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079783,	
2017-07-20 21:48:26,218 Epoch[64] Batch [70]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.079403,	
2017-07-20 21:48:30,923 Epoch[64] Batch [80]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.079625,	
2017-07-20 21:48:35,532 Epoch[64] Batch [90]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.080096,	
2017-07-20 21:48:39,915 Epoch[64] Batch [100]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.080565,	
2017-07-20 21:48:44,439 Epoch[64] Batch [110]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.080265,	
2017-07-20 21:48:48,922 Epoch[64] Batch [120]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.080657,	
2017-07-20 21:48:53,606 Epoch[64] Batch [130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.080224,	
2017-07-20 21:48:58,412 Epoch[64] Batch [140]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.080087,	
2017-07-20 21:49:03,004 Epoch[64] Batch [150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.080623,	
2017-07-20 21:49:07,993 Epoch[64] Batch [160]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.080328,	
2017-07-20 21:49:13,327 Epoch[64] Batch [170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.080292,	
2017-07-20 21:49:17,871 Epoch[64] Batch [180]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.079883,	
2017-07-20 21:49:22,449 Epoch[64] Batch [190]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.080034,	
2017-07-20 21:49:27,339 Epoch[64] Batch [200]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.080036,	
2017-07-20 21:49:32,661 Epoch[64] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.079923,	
2017-07-20 21:49:37,502 Epoch[64] Batch [220]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.079982,	
2017-07-20 21:49:42,160 Epoch[64] Batch [230]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.079548,	
2017-07-20 21:49:47,004 Epoch[64] Batch [240]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.079626,	
2017-07-20 21:49:51,525 Epoch[64] Batch [250]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.079385,	
2017-07-20 21:49:56,252 Epoch[64] Batch [260]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079118,	
2017-07-20 21:50:01,240 Epoch[64] Batch [270]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.079031,	
2017-07-20 21:50:06,256 Epoch[64] Batch [280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.079183,	
2017-07-20 21:50:11,037 Epoch[64] Batch [290]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.079120,	
2017-07-20 21:50:15,498 Epoch[64] Batch [300]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.079216,	
2017-07-20 21:50:20,709 Epoch[64] Batch [310]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.079046,	
2017-07-20 21:50:26,239 Epoch[64] Batch [320]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.079014,	
2017-07-20 21:50:31,376 Epoch[64] Batch [330]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.079146,	
2017-07-20 21:50:36,610 Epoch[64] Batch [340]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.079112,	
2017-07-20 21:50:41,388 Epoch[64] Batch [350]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.079150,	
2017-07-20 21:50:46,270 Epoch[64] Batch [360]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.079246,	
2017-07-20 21:50:51,227 Epoch[64] Batch [370]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.079296,	
2017-07-20 21:50:55,991 Epoch[64] Batch [380]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.079227,	
2017-07-20 21:51:00,873 Epoch[64] Batch [390]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.079024,	
2017-07-20 21:51:05,917 Epoch[64] Batch [400]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.079226,	
2017-07-20 21:51:10,802 Epoch[64] Batch [410]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.079323,	
2017-07-20 21:51:15,730 Epoch[64] Batch [420]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.079474,	
2017-07-20 21:51:20,402 Epoch[64] Batch [430]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.079305,	
2017-07-20 21:51:25,118 Epoch[64] Batch [440]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.079426,	
2017-07-20 21:51:29,854 Epoch[64] Batch [450]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.079391,	
2017-07-20 21:51:34,669 Epoch[64] Batch [460]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.079384,	
2017-07-20 21:51:40,092 Epoch[64] Batch [470]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.079504,	
2017-07-20 21:51:44,966 Epoch[64] Batch [480]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.079617,	
2017-07-20 21:51:50,084 Epoch[64] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.079669,	
2017-07-20 21:51:54,962 Epoch[64] Batch [500]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.079851,	
2017-07-20 21:51:59,672 Epoch[64] Batch [510]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.080006,	
2017-07-20 21:52:04,366 Epoch[64] Batch [520]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.080006,	
2017-07-20 21:52:08,912 Epoch[64] Batch [530]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.080110,	
2017-07-20 21:52:13,427 Epoch[64] Batch [540]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.080087,	
2017-07-20 21:52:18,166 Epoch[64] Batch [550]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.080104,	
2017-07-20 21:52:22,948 Epoch[64] Batch [560]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.080051,	
2017-07-20 21:52:28,299 Epoch[64] Batch [570]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.079915,	
2017-07-20 21:52:33,165 Epoch[64] Batch [580]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.079937,	
2017-07-20 21:52:37,904 Epoch[64] Batch [590]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.079892,	
2017-07-20 21:52:42,578 Epoch[64] Batch [600]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.079850,	
2017-07-20 21:52:47,387 Epoch[64] Batch [610]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.079855,	
2017-07-20 21:52:53,056 Epoch[64] Batch [620]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.079846,	
2017-07-20 21:52:58,167 Epoch[64] Batch [630]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.079798,	
2017-07-20 21:53:03,237 Epoch[64] Batch [640]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.079784,	
2017-07-20 21:53:07,755 Epoch[64] Batch [650]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.079727,	
2017-07-20 21:53:12,301 Epoch[64] Batch [660]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.079650,	
2017-07-20 21:53:17,257 Epoch[64] Batch [670]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.079649,	
2017-07-20 21:53:22,434 Epoch[64] Batch [680]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.079677,	
2017-07-20 21:53:26,995 Epoch[64] Batch [690]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079679,	
2017-07-20 21:53:31,642 Epoch[64] Batch [700]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.079660,	
2017-07-20 21:53:36,068 Epoch[64] Batch [710]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.079705,	
2017-07-20 21:53:40,905 Epoch[64] Batch [720]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.079714,	
2017-07-20 21:53:45,904 Epoch[64] Batch [730]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.079589,	
2017-07-20 21:53:50,683 Epoch[64] Batch [740]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.079651,	
2017-07-20 21:53:55,584 Epoch[64] Batch [750]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.079509,	
2017-07-20 21:54:00,446 Epoch[64] Batch [760]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.079555,	
2017-07-20 21:54:05,218 Epoch[64] Batch [770]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.079488,	
2017-07-20 21:54:10,283 Epoch[64] Batch [780]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.079398,	
2017-07-20 21:54:14,966 Epoch[64] Batch [790]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.079493,	
2017-07-20 21:54:19,862 Epoch[64] Batch [800]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.079444,	
2017-07-20 21:54:25,042 Epoch[64] Batch [810]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.079489,	
2017-07-20 21:54:30,651 Epoch[64] Batch [820]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.079486,	
2017-07-20 21:54:35,166 Epoch[64] Batch [830]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.079372,	
2017-07-20 21:54:39,722 Epoch[64] Batch [840]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.079342,	
2017-07-20 21:54:44,648 Epoch[64] Batch [850]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.079302,	
2017-07-20 21:54:49,522 Epoch[64] Batch [860]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.079347,	
2017-07-20 21:54:54,527 Epoch[64] Batch [870]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.079310,	
2017-07-20 21:54:59,637 Epoch[64] Batch [880]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.079251,	
2017-07-20 21:55:04,243 Epoch[64] Batch [890]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.079183,	
2017-07-20 21:55:09,202 Epoch[64] Batch [900]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.079114,	
2017-07-20 21:55:14,027 Epoch[64] Batch [910]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.079225,	
2017-07-20 21:55:18,885 Epoch[64] Batch [920]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.079219,	
2017-07-20 21:55:23,770 Epoch[64] Batch [930]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.079157,	
2017-07-20 21:55:28,440 Epoch[64] Batch [940]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.079194,	
2017-07-20 21:55:33,204 Epoch[64] Batch [950]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.079151,	
2017-07-20 21:55:37,603 Epoch[64] Batch [960]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.079190,	
2017-07-20 21:55:42,329 Epoch[64] Batch [970]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.079232,	
2017-07-20 21:55:47,299 Epoch[64] Batch [980]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.079237,	
2017-07-20 21:55:52,480 Epoch[64] Batch [990]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.079241,	
2017-07-20 21:55:57,274 Epoch[64] Batch [1000]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.079250,	
2017-07-20 21:56:02,186 Epoch[64] Batch [1010]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.079205,	
2017-07-20 21:56:06,922 Epoch[64] Batch [1020]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.079165,	
2017-07-20 21:56:11,646 Epoch[64] Batch [1030]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.079103,	
2017-07-20 21:56:16,724 Epoch[64] Batch [1040]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.079101,	
2017-07-20 21:56:21,378 Epoch[64] Batch [1050]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.079073,	
2017-07-20 21:56:25,954 Epoch[64] Batch [1060]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.078985,	
2017-07-20 21:56:30,672 Epoch[64] Batch [1070]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.078972,	
2017-07-20 21:56:35,442 Epoch[64] Batch [1080]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.078989,	
2017-07-20 21:56:40,180 Epoch[64] Batch [1090]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.079004,	
2017-07-20 21:56:44,710 Epoch[64] Batch [1100]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.079005,	
2017-07-20 21:56:49,526 Epoch[64] Batch [1110]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.078953,	
2017-07-20 21:56:54,286 Epoch[64] Batch [1120]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078889,	
2017-07-20 21:56:58,776 Epoch[64] Batch [1130]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.078910,	
2017-07-20 21:57:03,440 Epoch[64] Batch [1140]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.078926,	
2017-07-20 21:57:08,129 Epoch[64] Batch [1150]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078875,	
2017-07-20 21:57:13,022 Epoch[64] Batch [1160]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.078828,	
2017-07-20 21:57:17,754 Epoch[64] Batch [1170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078808,	
2017-07-20 21:57:22,419 Epoch[64] Batch [1180]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.078861,	
2017-07-20 21:57:27,155 Epoch[64] Batch [1190]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078828,	
2017-07-20 21:57:31,866 Epoch[64] Batch [1200]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.078876,	
2017-07-20 21:57:36,473 Epoch[64] Batch [1210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.078872,	
2017-07-20 21:57:41,920 Epoch[64] Batch [1220]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.078939,	
2017-07-20 21:57:46,878 Epoch[64] Batch [1230]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078897,	
2017-07-20 21:57:51,566 Epoch[64] Batch [1240]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078933,	
2017-07-20 21:57:56,227 Epoch[64] Batch [1250]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.078888,	
2017-07-20 21:58:00,852 Epoch[64] Batch [1260]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.078837,	
2017-07-20 21:58:05,319 Epoch[64] Batch [1270]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.078854,	
2017-07-20 21:58:10,088 Epoch[64] Batch [1280]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.078849,	
2017-07-20 21:58:14,742 Epoch[64] Batch [1290]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.078938,	
2017-07-20 21:58:19,625 Epoch[64] Batch [1300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078978,	
2017-07-20 21:58:24,373 Epoch[64] Batch [1310]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078953,	
2017-07-20 21:58:29,227 Epoch[64] Batch [1320]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.078980,	
2017-07-20 21:58:33,777 Epoch[64] Batch [1330]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.078953,	
2017-07-20 21:58:38,494 Epoch[64] Batch [1340]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.078942,	
2017-07-20 21:58:43,293 Epoch[64] Batch [1350]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.078923,	
2017-07-20 21:58:48,008 Epoch[64] Batch [1360]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.078963,	
2017-07-20 21:58:52,661 Epoch[64] Batch [1370]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.078943,	
2017-07-20 21:58:57,105 Epoch[64] Batch [1380]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.078988,	
2017-07-20 21:59:02,435 Epoch[64] Batch [1390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.078936,	
2017-07-20 21:59:07,173 Epoch[64] Batch [1400]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.078989,	
2017-07-20 21:59:11,743 Epoch[64] Batch [1410]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.078984,	
2017-07-20 21:59:16,480 Epoch[64] Batch [1420]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.078947,	
2017-07-20 21:59:21,035 Epoch[64] Batch [1430]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.078960,	
2017-07-20 21:59:25,626 Epoch[64] Batch [1440]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.079002,	
2017-07-20 21:59:30,460 Epoch[64] Batch [1450]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078984,	
2017-07-20 21:59:35,415 Epoch[64] Batch [1460]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078965,	
2017-07-20 21:59:40,438 Epoch[64] Batch [1470]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.078964,	
2017-07-20 21:59:45,029 Epoch[64] Batch [1480]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.078913,	
2017-07-20 21:59:47,627 Epoch[64] Train-FCNLogLoss=0.078930
2017-07-20 21:59:47,627 Epoch[64] Time cost=715.494
2017-07-20 21:59:48,564 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0065.params"
2017-07-20 21:59:52,108 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0065.states"
2017-07-20 21:59:57,928 Epoch[65] Batch [10]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077865,	
2017-07-20 22:00:02,745 Epoch[65] Batch [20]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075722,	
2017-07-20 22:00:07,393 Epoch[65] Batch [30]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.074234,	
2017-07-20 22:00:12,206 Epoch[65] Batch [40]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.076984,	
2017-07-20 22:00:17,672 Epoch[65] Batch [50]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.076959,	
2017-07-20 22:00:22,427 Epoch[65] Batch [60]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.075973,	
2017-07-20 22:00:27,116 Epoch[65] Batch [70]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.075777,	
2017-07-20 22:00:32,062 Epoch[65] Batch [80]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.076333,	
2017-07-20 22:00:36,927 Epoch[65] Batch [90]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.075371,	
2017-07-20 22:00:41,744 Epoch[65] Batch [100]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075617,	
2017-07-20 22:00:46,299 Epoch[65] Batch [110]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075758,	
2017-07-20 22:00:51,268 Epoch[65] Batch [120]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.075811,	
2017-07-20 22:00:56,370 Epoch[65] Batch [130]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.075780,	
2017-07-20 22:01:01,322 Epoch[65] Batch [140]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.075721,	
2017-07-20 22:01:06,034 Epoch[65] Batch [150]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.075584,	
2017-07-20 22:01:11,021 Epoch[65] Batch [160]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.076067,	
2017-07-20 22:01:15,790 Epoch[65] Batch [170]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.076577,	
2017-07-20 22:01:20,302 Epoch[65] Batch [180]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.076717,	
2017-07-20 22:01:25,019 Epoch[65] Batch [190]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.077351,	
2017-07-20 22:01:30,402 Epoch[65] Batch [200]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.077475,	
2017-07-20 22:01:34,838 Epoch[65] Batch [210]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.077540,	
2017-07-20 22:01:39,548 Epoch[65] Batch [220]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.077001,	
2017-07-20 22:01:44,446 Epoch[65] Batch [230]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.076849,	
2017-07-20 22:01:49,409 Epoch[65] Batch [240]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.076759,	
2017-07-20 22:01:55,067 Epoch[65] Batch [250]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.077134,	
2017-07-20 22:01:59,698 Epoch[65] Batch [260]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.077316,	
2017-07-20 22:02:04,500 Epoch[65] Batch [270]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.077665,	
2017-07-20 22:02:09,654 Epoch[65] Batch [280]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.077770,	
2017-07-20 22:02:14,489 Epoch[65] Batch [290]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.077694,	
2017-07-20 22:02:19,526 Epoch[65] Batch [300]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.077685,	
2017-07-20 22:02:24,412 Epoch[65] Batch [310]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077972,	
2017-07-20 22:02:29,151 Epoch[65] Batch [320]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.078050,	
2017-07-20 22:02:33,995 Epoch[65] Batch [330]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.077918,	
2017-07-20 22:02:38,602 Epoch[65] Batch [340]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.078052,	
2017-07-20 22:02:43,212 Epoch[65] Batch [350]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.078126,	
2017-07-20 22:02:48,037 Epoch[65] Batch [360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.078288,	
2017-07-20 22:02:53,138 Epoch[65] Batch [370]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.078265,	
2017-07-20 22:02:57,870 Epoch[65] Batch [380]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078449,	
2017-07-20 22:03:03,239 Epoch[65] Batch [390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.078378,	
2017-07-20 22:03:07,907 Epoch[65] Batch [400]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.078447,	
2017-07-20 22:03:12,447 Epoch[65] Batch [410]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.078407,	
2017-07-20 22:03:17,306 Epoch[65] Batch [420]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.078276,	
2017-07-20 22:03:21,782 Epoch[65] Batch [430]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.078269,	
2017-07-20 22:03:26,540 Epoch[65] Batch [440]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.078048,	
2017-07-20 22:03:31,355 Epoch[65] Batch [450]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.078032,	
2017-07-20 22:03:36,360 Epoch[65] Batch [460]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.078032,	
2017-07-20 22:03:41,235 Epoch[65] Batch [470]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.078016,	
2017-07-20 22:03:46,149 Epoch[65] Batch [480]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.078115,	
2017-07-20 22:03:50,865 Epoch[65] Batch [490]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.078102,	
2017-07-20 22:03:56,208 Epoch[65] Batch [500]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.078190,	
2017-07-20 22:04:01,140 Epoch[65] Batch [510]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.078341,	
2017-07-20 22:04:05,798 Epoch[65] Batch [520]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.078410,	
2017-07-20 22:04:10,549 Epoch[65] Batch [530]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078478,	
2017-07-20 22:04:15,501 Epoch[65] Batch [540]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.078450,	
2017-07-20 22:04:20,347 Epoch[65] Batch [550]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.078605,	
2017-07-20 22:04:25,093 Epoch[65] Batch [560]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078699,	
2017-07-20 22:04:29,638 Epoch[65] Batch [570]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.078562,	
2017-07-20 22:04:34,173 Epoch[65] Batch [580]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.078434,	
2017-07-20 22:04:38,884 Epoch[65] Batch [590]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.078323,	
2017-07-20 22:04:43,463 Epoch[65] Batch [600]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.078256,	
2017-07-20 22:04:48,169 Epoch[65] Batch [610]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.078263,	
2017-07-20 22:04:53,231 Epoch[65] Batch [620]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.078297,	
2017-07-20 22:04:57,863 Epoch[65] Batch [630]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.078338,	
2017-07-20 22:05:02,594 Epoch[65] Batch [640]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.078450,	
2017-07-20 22:05:07,251 Epoch[65] Batch [650]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.078468,	
2017-07-20 22:05:12,397 Epoch[65] Batch [660]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.078646,	
2017-07-20 22:05:17,344 Epoch[65] Batch [670]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.078507,	
2017-07-20 22:05:22,139 Epoch[65] Batch [680]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.078653,	
2017-07-20 22:05:27,175 Epoch[65] Batch [690]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.078582,	
2017-07-20 22:05:31,674 Epoch[65] Batch [700]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.078582,	
2017-07-20 22:05:36,379 Epoch[65] Batch [710]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.078518,	
2017-07-20 22:05:41,827 Epoch[65] Batch [720]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.078404,	
2017-07-20 22:05:46,819 Epoch[65] Batch [730]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.078375,	
2017-07-20 22:05:51,947 Epoch[65] Batch [740]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.078523,	
2017-07-20 22:05:56,673 Epoch[65] Batch [750]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.078479,	
2017-07-20 22:06:01,248 Epoch[65] Batch [760]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.078462,	
2017-07-20 22:06:06,032 Epoch[65] Batch [770]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.078457,	
2017-07-20 22:06:10,570 Epoch[65] Batch [780]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.078485,	
2017-07-20 22:06:15,084 Epoch[65] Batch [790]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.078500,	
2017-07-20 22:06:20,113 Epoch[65] Batch [800]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.078581,	
2017-07-20 22:06:25,284 Epoch[65] Batch [810]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.078599,	
2017-07-20 22:06:30,098 Epoch[65] Batch [820]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.078610,	
2017-07-20 22:06:34,888 Epoch[65] Batch [830]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.078564,	
2017-07-20 22:06:39,688 Epoch[65] Batch [840]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.078597,	
2017-07-20 22:06:44,838 Epoch[65] Batch [850]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.078621,	
2017-07-20 22:06:49,662 Epoch[65] Batch [860]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.078731,	
2017-07-20 22:06:54,350 Epoch[65] Batch [870]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078723,	
2017-07-20 22:06:59,009 Epoch[65] Batch [880]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.078680,	
2017-07-20 22:07:03,863 Epoch[65] Batch [890]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.078679,	
2017-07-20 22:07:08,511 Epoch[65] Batch [900]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.078595,	
2017-07-20 22:07:13,562 Epoch[65] Batch [910]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.078634,	
2017-07-20 22:07:18,373 Epoch[65] Batch [920]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.078724,	
2017-07-20 22:07:23,170 Epoch[65] Batch [930]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.078667,	
2017-07-20 22:07:28,075 Epoch[65] Batch [940]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078731,	
2017-07-20 22:07:32,906 Epoch[65] Batch [950]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078709,	
2017-07-20 22:07:37,999 Epoch[65] Batch [960]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.078724,	
2017-07-20 22:07:43,023 Epoch[65] Batch [970]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.078647,	
2017-07-20 22:07:47,732 Epoch[65] Batch [980]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.078671,	
2017-07-20 22:07:52,652 Epoch[65] Batch [990]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.078708,	
2017-07-20 22:07:57,414 Epoch[65] Batch [1000]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078720,	
2017-07-20 22:08:02,746 Epoch[65] Batch [1010]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.078750,	
2017-07-20 22:08:07,718 Epoch[65] Batch [1020]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.078792,	
2017-07-20 22:08:12,793 Epoch[65] Batch [1030]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.078795,	
2017-07-20 22:08:17,389 Epoch[65] Batch [1040]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.078835,	
2017-07-20 22:08:22,005 Epoch[65] Batch [1050]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.078809,	
2017-07-20 22:08:26,380 Epoch[65] Batch [1060]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.078797,	
2017-07-20 22:08:30,642 Epoch[65] Batch [1070]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.078851,	
2017-07-20 22:08:35,339 Epoch[65] Batch [1080]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.078804,	
2017-07-20 22:08:40,435 Epoch[65] Batch [1090]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.078754,	
2017-07-20 22:08:45,040 Epoch[65] Batch [1100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.078843,	
2017-07-20 22:08:49,469 Epoch[65] Batch [1110]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.078862,	
2017-07-20 22:08:54,247 Epoch[65] Batch [1120]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.078810,	
2017-07-20 22:08:58,694 Epoch[65] Batch [1130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.078840,	
2017-07-20 22:09:03,499 Epoch[65] Batch [1140]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.078801,	
2017-07-20 22:09:08,094 Epoch[65] Batch [1150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.078781,	
2017-07-20 22:09:12,930 Epoch[65] Batch [1160]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.078803,	
2017-07-20 22:09:17,806 Epoch[65] Batch [1170]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.078758,	
2017-07-20 22:09:22,779 Epoch[65] Batch [1180]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.078794,	
2017-07-20 22:09:27,608 Epoch[65] Batch [1190]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078767,	
2017-07-20 22:09:32,302 Epoch[65] Batch [1200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.078818,	
2017-07-20 22:09:37,245 Epoch[65] Batch [1210]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.078741,	
2017-07-20 22:09:41,879 Epoch[65] Batch [1220]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.078743,	
2017-07-20 22:09:46,941 Epoch[65] Batch [1230]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.078758,	
2017-07-20 22:09:52,072 Epoch[65] Batch [1240]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.078694,	
2017-07-20 22:09:56,962 Epoch[65] Batch [1250]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.078697,	
2017-07-20 22:10:01,716 Epoch[65] Batch [1260]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078660,	
2017-07-20 22:10:06,862 Epoch[65] Batch [1270]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.078645,	
2017-07-20 22:10:11,495 Epoch[65] Batch [1280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.078615,	
2017-07-20 22:10:16,324 Epoch[65] Batch [1290]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078628,	
2017-07-20 22:10:21,058 Epoch[65] Batch [1300]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078611,	
2017-07-20 22:10:25,830 Epoch[65] Batch [1310]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.078610,	
2017-07-20 22:10:30,516 Epoch[65] Batch [1320]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.078568,	
2017-07-20 22:10:35,502 Epoch[65] Batch [1330]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.078528,	
2017-07-20 22:10:40,606 Epoch[65] Batch [1340]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.078540,	
2017-07-20 22:10:45,155 Epoch[65] Batch [1350]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.078447,	
2017-07-20 22:10:50,318 Epoch[65] Batch [1360]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.078488,	
2017-07-20 22:10:54,925 Epoch[65] Batch [1370]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.078522,	
2017-07-20 22:10:59,632 Epoch[65] Batch [1380]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.078525,	
2017-07-20 22:11:04,249 Epoch[65] Batch [1390]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.078482,	
2017-07-20 22:11:08,928 Epoch[65] Batch [1400]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.078422,	
2017-07-20 22:11:13,870 Epoch[65] Batch [1410]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.078409,	
2017-07-20 22:11:18,839 Epoch[65] Batch [1420]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.078396,	
2017-07-20 22:11:23,859 Epoch[65] Batch [1430]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.078323,	
2017-07-20 22:11:28,821 Epoch[65] Batch [1440]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.078336,	
2017-07-20 22:11:33,769 Epoch[65] Batch [1450]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.078327,	
2017-07-20 22:11:38,385 Epoch[65] Batch [1460]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.078287,	
2017-07-20 22:11:43,080 Epoch[65] Batch [1470]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.078253,	
2017-07-20 22:11:47,749 Epoch[65] Batch [1480]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.078283,	
2017-07-20 22:11:50,535 Epoch[65] Train-FCNLogLoss=0.078259
2017-07-20 22:11:50,535 Epoch[65] Time cost=718.427
2017-07-20 22:11:51,538 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0066.params"
2017-07-20 22:11:54,997 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0066.states"
2017-07-20 22:12:00,629 Epoch[66] Batch [10]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.079316,	
2017-07-20 22:12:05,719 Epoch[66] Batch [20]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077597,	
2017-07-20 22:12:10,436 Epoch[66] Batch [30]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.076177,	
2017-07-20 22:12:15,196 Epoch[66] Batch [40]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.077446,	
2017-07-20 22:12:20,368 Epoch[66] Batch [50]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.077779,	
2017-07-20 22:12:25,237 Epoch[66] Batch [60]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077322,	
2017-07-20 22:12:30,503 Epoch[66] Batch [70]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.078320,	
2017-07-20 22:12:35,527 Epoch[66] Batch [80]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.077685,	
2017-07-20 22:12:40,794 Epoch[66] Batch [90]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.078102,	
2017-07-20 22:12:45,737 Epoch[66] Batch [100]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077976,	
2017-07-20 22:12:50,692 Epoch[66] Batch [110]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078284,	
2017-07-20 22:12:55,722 Epoch[66] Batch [120]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.078427,	
2017-07-20 22:13:00,623 Epoch[66] Batch [130]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.077749,	
2017-07-20 22:13:05,527 Epoch[66] Batch [140]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078008,	
2017-07-20 22:13:10,411 Epoch[66] Batch [150]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077890,	
2017-07-20 22:13:15,290 Epoch[66] Batch [160]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.078015,	
2017-07-20 22:13:20,198 Epoch[66] Batch [170]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.078229,	
2017-07-20 22:13:25,202 Epoch[66] Batch [180]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.078166,	
2017-07-20 22:13:30,086 Epoch[66] Batch [190]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078602,	
2017-07-20 22:13:34,769 Epoch[66] Batch [200]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.078485,	
2017-07-20 22:13:39,690 Epoch[66] Batch [210]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.078656,	
2017-07-20 22:13:44,365 Epoch[66] Batch [220]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.078445,	
2017-07-20 22:13:49,248 Epoch[66] Batch [230]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078285,	
2017-07-20 22:13:54,153 Epoch[66] Batch [240]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078327,	
2017-07-20 22:13:59,475 Epoch[66] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.078547,	
2017-07-20 22:14:04,597 Epoch[66] Batch [260]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.078354,	
2017-07-20 22:14:09,212 Epoch[66] Batch [270]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.078245,	
2017-07-20 22:14:14,096 Epoch[66] Batch [280]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077977,	
2017-07-20 22:14:19,135 Epoch[66] Batch [290]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.078137,	
2017-07-20 22:14:24,257 Epoch[66] Batch [300]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.078319,	
2017-07-20 22:14:29,508 Epoch[66] Batch [310]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.078375,	
2017-07-20 22:14:34,872 Epoch[66] Batch [320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.078472,	
2017-07-20 22:14:40,477 Epoch[66] Batch [330]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.078509,	
2017-07-20 22:14:45,792 Epoch[66] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.078532,	
2017-07-20 22:14:50,526 Epoch[66] Batch [350]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.078546,	
2017-07-20 22:14:55,374 Epoch[66] Batch [360]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.078682,	
2017-07-20 22:15:00,543 Epoch[66] Batch [370]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.078789,	
2017-07-20 22:15:05,704 Epoch[66] Batch [380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.078636,	
2017-07-20 22:15:10,348 Epoch[66] Batch [390]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.078676,	
2017-07-20 22:15:15,224 Epoch[66] Batch [400]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.078747,	
2017-07-20 22:15:19,724 Epoch[66] Batch [410]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.078714,	
2017-07-20 22:15:24,500 Epoch[66] Batch [420]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.078559,	
2017-07-20 22:15:29,184 Epoch[66] Batch [430]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.078686,	
2017-07-20 22:15:34,299 Epoch[66] Batch [440]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.078632,	
2017-07-20 22:15:38,885 Epoch[66] Batch [450]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.078827,	
2017-07-20 22:15:43,713 Epoch[66] Batch [460]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.078818,	
2017-07-20 22:15:48,367 Epoch[66] Batch [470]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.078723,	
2017-07-20 22:15:53,157 Epoch[66] Batch [480]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.078596,	
2017-07-20 22:15:57,913 Epoch[66] Batch [490]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.078592,	
2017-07-20 22:16:02,520 Epoch[66] Batch [500]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.078454,	
2017-07-20 22:16:07,321 Epoch[66] Batch [510]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.078432,	
2017-07-20 22:16:12,352 Epoch[66] Batch [520]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.078395,	
2017-07-20 22:16:17,379 Epoch[66] Batch [530]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.078381,	
2017-07-20 22:16:22,347 Epoch[66] Batch [540]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.078369,	
2017-07-20 22:16:26,886 Epoch[66] Batch [550]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.078278,	
2017-07-20 22:16:31,581 Epoch[66] Batch [560]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.078251,	
2017-07-20 22:16:36,136 Epoch[66] Batch [570]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.078339,	
2017-07-20 22:16:40,817 Epoch[66] Batch [580]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.078375,	
2017-07-20 22:16:46,023 Epoch[66] Batch [590]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.078451,	
2017-07-20 22:16:51,112 Epoch[66] Batch [600]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.078487,	
2017-07-20 22:16:55,915 Epoch[66] Batch [610]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.078370,	
2017-07-20 22:17:00,832 Epoch[66] Batch [620]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.078428,	
2017-07-20 22:17:05,855 Epoch[66] Batch [630]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.078426,	
2017-07-20 22:17:10,398 Epoch[66] Batch [640]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.078350,	
2017-07-20 22:17:15,090 Epoch[66] Batch [650]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078256,	
2017-07-20 22:17:19,661 Epoch[66] Batch [660]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.078429,	
2017-07-20 22:17:24,491 Epoch[66] Batch [670]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078574,	
2017-07-20 22:17:29,359 Epoch[66] Batch [680]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.078599,	
2017-07-20 22:17:34,174 Epoch[66] Batch [690]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.078616,	
2017-07-20 22:17:38,840 Epoch[66] Batch [700]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.078580,	
2017-07-20 22:17:43,602 Epoch[66] Batch [710]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078567,	
2017-07-20 22:17:48,277 Epoch[66] Batch [720]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.078516,	
2017-07-20 22:17:52,979 Epoch[66] Batch [730]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.078504,	
2017-07-20 22:17:57,476 Epoch[66] Batch [740]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.078546,	
2017-07-20 22:18:02,128 Epoch[66] Batch [750]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.078543,	
2017-07-20 22:18:06,720 Epoch[66] Batch [760]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.078588,	
2017-07-20 22:18:11,580 Epoch[66] Batch [770]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.078561,	
2017-07-20 22:18:16,291 Epoch[66] Batch [780]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.078485,	
2017-07-20 22:18:21,188 Epoch[66] Batch [790]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.078517,	
2017-07-20 22:18:26,126 Epoch[66] Batch [800]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.078584,	
2017-07-20 22:18:30,851 Epoch[66] Batch [810]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.078605,	
2017-07-20 22:18:35,916 Epoch[66] Batch [820]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.078574,	
2017-07-20 22:18:40,838 Epoch[66] Batch [830]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.078506,	
2017-07-20 22:18:45,609 Epoch[66] Batch [840]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.078432,	
2017-07-20 22:18:50,586 Epoch[66] Batch [850]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.078538,	
2017-07-20 22:18:55,323 Epoch[66] Batch [860]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078546,	
2017-07-20 22:19:00,167 Epoch[66] Batch [870]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.078601,	
2017-07-20 22:19:05,070 Epoch[66] Batch [880]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078472,	
2017-07-20 22:19:10,112 Epoch[66] Batch [890]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.078486,	
2017-07-20 22:19:14,864 Epoch[66] Batch [900]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078503,	
2017-07-20 22:19:19,438 Epoch[66] Batch [910]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.078501,	
2017-07-20 22:19:23,942 Epoch[66] Batch [920]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.078530,	
2017-07-20 22:19:28,877 Epoch[66] Batch [930]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.078545,	
2017-07-20 22:19:33,461 Epoch[66] Batch [940]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.078446,	
2017-07-20 22:19:37,933 Epoch[66] Batch [950]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.078516,	
2017-07-20 22:19:42,632 Epoch[66] Batch [960]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.078509,	
2017-07-20 22:19:47,467 Epoch[66] Batch [970]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.078512,	
2017-07-20 22:19:52,380 Epoch[66] Batch [980]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.078435,	
2017-07-20 22:19:56,956 Epoch[66] Batch [990]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.078428,	
2017-07-20 22:20:01,792 Epoch[66] Batch [1000]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.078453,	
2017-07-20 22:20:06,450 Epoch[66] Batch [1010]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.078476,	
2017-07-20 22:20:11,101 Epoch[66] Batch [1020]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.078415,	
2017-07-20 22:20:16,030 Epoch[66] Batch [1030]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.078439,	
2017-07-20 22:20:20,898 Epoch[66] Batch [1040]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.078457,	
2017-07-20 22:20:26,305 Epoch[66] Batch [1050]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.078408,	
2017-07-20 22:20:31,349 Epoch[66] Batch [1060]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.078367,	
2017-07-20 22:20:36,140 Epoch[66] Batch [1070]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.078385,	
2017-07-20 22:20:40,891 Epoch[66] Batch [1080]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078433,	
2017-07-20 22:20:45,932 Epoch[66] Batch [1090]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.078416,	
2017-07-20 22:20:50,766 Epoch[66] Batch [1100]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078393,	
2017-07-20 22:20:55,929 Epoch[66] Batch [1110]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.078412,	
2017-07-20 22:21:01,055 Epoch[66] Batch [1120]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.078372,	
2017-07-20 22:21:05,952 Epoch[66] Batch [1130]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.078339,	
2017-07-20 22:21:10,827 Epoch[66] Batch [1140]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.078347,	
2017-07-20 22:21:15,539 Epoch[66] Batch [1150]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.078297,	
2017-07-20 22:21:20,246 Epoch[66] Batch [1160]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.078412,	
2017-07-20 22:21:24,793 Epoch[66] Batch [1170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.078333,	
2017-07-20 22:21:29,344 Epoch[66] Batch [1180]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.078232,	
2017-07-20 22:21:34,264 Epoch[66] Batch [1190]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.078203,	
2017-07-20 22:21:39,187 Epoch[66] Batch [1200]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.078225,	
2017-07-20 22:21:44,242 Epoch[66] Batch [1210]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.078163,	
2017-07-20 22:21:49,648 Epoch[66] Batch [1220]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.078124,	
2017-07-20 22:21:54,298 Epoch[66] Batch [1230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.078148,	
2017-07-20 22:21:58,973 Epoch[66] Batch [1240]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.078146,	
2017-07-20 22:22:03,231 Epoch[66] Batch [1250]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.078169,	
2017-07-20 22:22:07,922 Epoch[66] Batch [1260]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078151,	
2017-07-20 22:22:12,817 Epoch[66] Batch [1270]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.078135,	
2017-07-20 22:22:17,867 Epoch[66] Batch [1280]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.078186,	
2017-07-20 22:22:22,947 Epoch[66] Batch [1290]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.078190,	
2017-07-20 22:22:28,126 Epoch[66] Batch [1300]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.078206,	
2017-07-20 22:22:32,779 Epoch[66] Batch [1310]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.078292,	
2017-07-20 22:22:38,290 Epoch[66] Batch [1320]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.078220,	
2017-07-20 22:22:42,826 Epoch[66] Batch [1330]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.078265,	
2017-07-20 22:22:47,709 Epoch[66] Batch [1340]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078257,	
2017-07-20 22:22:52,284 Epoch[66] Batch [1350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.078248,	
2017-07-20 22:22:57,616 Epoch[66] Batch [1360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.078219,	
2017-07-20 22:23:02,332 Epoch[66] Batch [1370]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.078184,	
2017-07-20 22:23:06,952 Epoch[66] Batch [1380]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.078145,	
2017-07-20 22:23:11,680 Epoch[66] Batch [1390]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.078164,	
2017-07-20 22:23:16,170 Epoch[66] Batch [1400]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.078132,	
2017-07-20 22:23:20,948 Epoch[66] Batch [1410]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.078191,	
2017-07-20 22:23:25,697 Epoch[66] Batch [1420]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078173,	
2017-07-20 22:23:30,261 Epoch[66] Batch [1430]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.078226,	
2017-07-20 22:23:35,493 Epoch[66] Batch [1440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.078295,	
2017-07-20 22:23:40,537 Epoch[66] Batch [1450]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.078279,	
2017-07-20 22:23:45,512 Epoch[66] Batch [1460]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.078303,	
2017-07-20 22:23:50,529 Epoch[66] Batch [1470]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.078291,	
2017-07-20 22:23:55,578 Epoch[66] Batch [1480]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.078302,	
2017-07-20 22:23:58,366 Epoch[66] Train-FCNLogLoss=0.078313
2017-07-20 22:23:58,367 Epoch[66] Time cost=723.369
2017-07-20 22:23:59,267 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0067.params"
2017-07-20 22:24:02,677 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0067.states"
2017-07-20 22:24:07,907 Epoch[67] Batch [10]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.074952,	
2017-07-20 22:24:12,525 Epoch[67] Batch [20]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.074441,	
2017-07-20 22:24:17,348 Epoch[67] Batch [30]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.078589,	
2017-07-20 22:24:21,980 Epoch[67] Batch [40]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.076265,	
2017-07-20 22:24:26,866 Epoch[67] Batch [50]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077219,	
2017-07-20 22:24:31,560 Epoch[67] Batch [60]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.077649,	
2017-07-20 22:24:36,285 Epoch[67] Batch [70]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.078080,	
2017-07-20 22:24:41,149 Epoch[67] Batch [80]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077221,	
2017-07-20 22:24:46,119 Epoch[67] Batch [90]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.076747,	
2017-07-20 22:24:51,304 Epoch[67] Batch [100]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.076374,	
2017-07-20 22:24:56,382 Epoch[67] Batch [110]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.075618,	
2017-07-20 22:25:01,168 Epoch[67] Batch [120]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.076621,	
2017-07-20 22:25:05,901 Epoch[67] Batch [130]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077750,	
2017-07-20 22:25:10,617 Epoch[67] Batch [140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.077480,	
2017-07-20 22:25:15,236 Epoch[67] Batch [150]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.077633,	
2017-07-20 22:25:20,048 Epoch[67] Batch [160]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077654,	
2017-07-20 22:25:24,948 Epoch[67] Batch [170]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.077326,	
2017-07-20 22:25:30,153 Epoch[67] Batch [180]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.077127,	
2017-07-20 22:25:35,541 Epoch[67] Batch [190]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.077139,	
2017-07-20 22:25:40,430 Epoch[67] Batch [200]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.077245,	
2017-07-20 22:25:44,946 Epoch[67] Batch [210]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.077215,	
2017-07-20 22:25:49,482 Epoch[67] Batch [220]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.077157,	
2017-07-20 22:25:54,412 Epoch[67] Batch [230]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077023,	
2017-07-20 22:25:59,360 Epoch[67] Batch [240]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077070,	
2017-07-20 22:26:04,328 Epoch[67] Batch [250]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077351,	
2017-07-20 22:26:09,407 Epoch[67] Batch [260]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077458,	
2017-07-20 22:26:13,915 Epoch[67] Batch [270]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.077576,	
2017-07-20 22:26:18,782 Epoch[67] Batch [280]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077737,	
2017-07-20 22:26:23,517 Epoch[67] Batch [290]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078053,	
2017-07-20 22:26:28,449 Epoch[67] Batch [300]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.078174,	
2017-07-20 22:26:33,123 Epoch[67] Batch [310]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.078362,	
2017-07-20 22:26:37,968 Epoch[67] Batch [320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.078419,	
2017-07-20 22:26:42,980 Epoch[67] Batch [330]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.078466,	
2017-07-20 22:26:47,560 Epoch[67] Batch [340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.078368,	
2017-07-20 22:26:52,244 Epoch[67] Batch [350]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.078653,	
2017-07-20 22:26:57,099 Epoch[67] Batch [360]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.078350,	
2017-07-20 22:27:01,720 Epoch[67] Batch [370]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.078310,	
2017-07-20 22:27:06,300 Epoch[67] Batch [380]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.078293,	
2017-07-20 22:27:10,933 Epoch[67] Batch [390]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.078149,	
2017-07-20 22:27:16,120 Epoch[67] Batch [400]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.078225,	
2017-07-20 22:27:20,840 Epoch[67] Batch [410]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.078091,	
2017-07-20 22:27:25,794 Epoch[67] Batch [420]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078179,	
2017-07-20 22:27:30,562 Epoch[67] Batch [430]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.078388,	
2017-07-20 22:27:35,565 Epoch[67] Batch [440]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.078339,	
2017-07-20 22:27:40,749 Epoch[67] Batch [450]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.078250,	
2017-07-20 22:27:45,474 Epoch[67] Batch [460]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.078290,	
2017-07-20 22:27:50,110 Epoch[67] Batch [470]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.078408,	
2017-07-20 22:27:54,800 Epoch[67] Batch [480]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078353,	
2017-07-20 22:27:59,368 Epoch[67] Batch [490]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.078394,	
2017-07-20 22:28:04,077 Epoch[67] Batch [500]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.078570,	
2017-07-20 22:28:08,787 Epoch[67] Batch [510]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.078581,	
2017-07-20 22:28:13,434 Epoch[67] Batch [520]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.078546,	
2017-07-20 22:28:18,114 Epoch[67] Batch [530]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.078682,	
2017-07-20 22:28:23,007 Epoch[67] Batch [540]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.078657,	
2017-07-20 22:28:27,612 Epoch[67] Batch [550]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.078658,	
2017-07-20 22:28:32,566 Epoch[67] Batch [560]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078507,	
2017-07-20 22:28:37,418 Epoch[67] Batch [570]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.078465,	
2017-07-20 22:28:42,352 Epoch[67] Batch [580]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.078553,	
2017-07-20 22:28:47,123 Epoch[67] Batch [590]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.078581,	
2017-07-20 22:28:51,773 Epoch[67] Batch [600]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.078653,	
2017-07-20 22:28:56,407 Epoch[67] Batch [610]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.078747,	
2017-07-20 22:29:01,257 Epoch[67] Batch [620]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.078879,	
2017-07-20 22:29:06,033 Epoch[67] Batch [630]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.078830,	
2017-07-20 22:29:10,756 Epoch[67] Batch [640]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.078940,	
2017-07-20 22:29:16,184 Epoch[67] Batch [650]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.078959,	
2017-07-20 22:29:21,124 Epoch[67] Batch [660]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.078893,	
2017-07-20 22:29:26,082 Epoch[67] Batch [670]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078920,	
2017-07-20 22:29:30,931 Epoch[67] Batch [680]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.078831,	
2017-07-20 22:29:35,440 Epoch[67] Batch [690]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.078896,	
2017-07-20 22:29:40,343 Epoch[67] Batch [700]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078898,	
2017-07-20 22:29:44,853 Epoch[67] Batch [710]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.078935,	
2017-07-20 22:29:49,467 Epoch[67] Batch [720]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.078928,	
2017-07-20 22:29:54,199 Epoch[67] Batch [730]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078952,	
2017-07-20 22:29:58,899 Epoch[67] Batch [740]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.078893,	
2017-07-20 22:30:03,796 Epoch[67] Batch [750]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.078971,	
2017-07-20 22:30:08,632 Epoch[67] Batch [760]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.078996,	
2017-07-20 22:30:13,395 Epoch[67] Batch [770]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078978,	
2017-07-20 22:30:18,330 Epoch[67] Batch [780]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.078907,	
2017-07-20 22:30:22,978 Epoch[67] Batch [790]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.078849,	
2017-07-20 22:30:27,765 Epoch[67] Batch [800]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.078856,	
2017-07-20 22:30:32,575 Epoch[67] Batch [810]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.078893,	
2017-07-20 22:30:49,510 Epoch[67] Batch [820]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.078840,	
2017-07-20 22:31:09,599 Epoch[67] Batch [830]	Speed: 1.99 samples/sec	Train-FCNLogLoss=0.078748,	
2017-07-20 22:31:31,610 Epoch[67] Batch [840]	Speed: 1.82 samples/sec	Train-FCNLogLoss=0.078658,	
2017-07-20 22:31:51,917 Epoch[67] Batch [850]	Speed: 1.97 samples/sec	Train-FCNLogLoss=0.078712,	
2017-07-20 22:32:14,987 Epoch[67] Batch [860]	Speed: 1.73 samples/sec	Train-FCNLogLoss=0.078683,	
2017-07-20 22:32:36,220 Epoch[67] Batch [870]	Speed: 1.88 samples/sec	Train-FCNLogLoss=0.078703,	
2017-07-20 22:32:41,518 Epoch[67] Batch [880]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.078760,	
2017-07-20 22:32:46,692 Epoch[67] Batch [890]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.078813,	
2017-07-20 22:32:52,422 Epoch[67] Batch [900]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.078752,	
2017-07-20 22:32:58,835 Epoch[67] Batch [910]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.078729,	
2017-07-20 22:33:04,572 Epoch[67] Batch [920]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.078657,	
2017-07-20 22:33:10,511 Epoch[67] Batch [930]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.078632,	
2017-07-20 22:33:16,657 Epoch[67] Batch [940]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.078672,	
2017-07-20 22:33:22,343 Epoch[67] Batch [950]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.078638,	
2017-07-20 22:33:27,611 Epoch[67] Batch [960]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.078581,	
2017-07-20 22:33:32,904 Epoch[67] Batch [970]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.078659,	
2017-07-20 22:33:38,397 Epoch[67] Batch [980]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.078687,	
2017-07-20 22:33:43,373 Epoch[67] Batch [990]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.078655,	
2017-07-20 22:33:48,422 Epoch[67] Batch [1000]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.078656,	
2017-07-20 22:33:53,478 Epoch[67] Batch [1010]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.078642,	
2017-07-20 22:33:58,567 Epoch[67] Batch [1020]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.078669,	
2017-07-20 22:34:03,215 Epoch[67] Batch [1030]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.078674,	
2017-07-20 22:34:08,043 Epoch[67] Batch [1040]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.078677,	
2017-07-20 22:34:12,776 Epoch[67] Batch [1050]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078706,	
2017-07-20 22:34:17,680 Epoch[67] Batch [1060]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078746,	
2017-07-20 22:34:22,591 Epoch[67] Batch [1070]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.078723,	
2017-07-20 22:34:27,548 Epoch[67] Batch [1080]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078731,	
2017-07-20 22:34:32,934 Epoch[67] Batch [1090]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.078744,	
2017-07-20 22:34:37,872 Epoch[67] Batch [1100]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.078701,	
2017-07-20 22:34:42,564 Epoch[67] Batch [1110]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078711,	
2017-07-20 22:34:47,643 Epoch[67] Batch [1120]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.078697,	
2017-07-20 22:34:52,271 Epoch[67] Batch [1130]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.078681,	
2017-07-20 22:34:57,252 Epoch[67] Batch [1140]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.078665,	
2017-07-20 22:35:01,996 Epoch[67] Batch [1150]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078718,	
2017-07-20 22:35:06,753 Epoch[67] Batch [1160]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.078713,	
2017-07-20 22:35:11,781 Epoch[67] Batch [1170]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.078668,	
2017-07-20 22:35:16,666 Epoch[67] Batch [1180]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078645,	
2017-07-20 22:35:21,346 Epoch[67] Batch [1190]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.078606,	
2017-07-20 22:35:26,458 Epoch[67] Batch [1200]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.078561,	
2017-07-20 22:35:31,749 Epoch[67] Batch [1210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.078541,	
2017-07-20 22:35:36,388 Epoch[67] Batch [1220]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.078526,	
2017-07-20 22:35:41,082 Epoch[67] Batch [1230]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.078519,	
2017-07-20 22:35:45,612 Epoch[67] Batch [1240]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.078491,	
2017-07-20 22:35:50,355 Epoch[67] Batch [1250]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078447,	
2017-07-20 22:35:55,424 Epoch[67] Batch [1260]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.078429,	
2017-07-20 22:36:00,190 Epoch[67] Batch [1270]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.078429,	
2017-07-20 22:36:05,047 Epoch[67] Batch [1280]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.078336,	
2017-07-20 22:36:10,162 Epoch[67] Batch [1290]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.078338,	
2017-07-20 22:36:15,171 Epoch[67] Batch [1300]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.078357,	
2017-07-20 22:36:20,141 Epoch[67] Batch [1310]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.078271,	
2017-07-20 22:36:24,679 Epoch[67] Batch [1320]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.078295,	
2017-07-20 22:36:29,499 Epoch[67] Batch [1330]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.078329,	
2017-07-20 22:36:34,402 Epoch[67] Batch [1340]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078310,	
2017-07-20 22:36:39,042 Epoch[67] Batch [1350]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.078349,	
2017-07-20 22:36:44,309 Epoch[67] Batch [1360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.078360,	
2017-07-20 22:36:49,257 Epoch[67] Batch [1370]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.078373,	
2017-07-20 22:36:54,243 Epoch[67] Batch [1380]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.078424,	
2017-07-20 22:36:58,982 Epoch[67] Batch [1390]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.078422,	
2017-07-20 22:37:03,846 Epoch[67] Batch [1400]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.078400,	
2017-07-20 22:37:08,293 Epoch[67] Batch [1410]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.078387,	
2017-07-20 22:37:12,988 Epoch[67] Batch [1420]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.078383,	
2017-07-20 22:37:18,192 Epoch[67] Batch [1430]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.078413,	
2017-07-20 22:37:23,404 Epoch[67] Batch [1440]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.078395,	
2017-07-20 22:37:28,379 Epoch[67] Batch [1450]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.078394,	
2017-07-20 22:37:32,906 Epoch[67] Batch [1460]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.078405,	
2017-07-20 22:37:38,389 Epoch[67] Batch [1470]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.078472,	
2017-07-20 22:37:43,011 Epoch[67] Batch [1480]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.078474,	
2017-07-20 22:37:45,834 Epoch[67] Train-FCNLogLoss=0.078449
2017-07-20 22:37:45,834 Epoch[67] Time cost=823.157
2017-07-20 22:37:46,994 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0068.params"
2017-07-20 22:37:51,540 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0068.states"
2017-07-20 22:37:57,383 Epoch[68] Batch [10]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.079574,	
2017-07-20 22:38:01,944 Epoch[68] Batch [20]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.080397,	
2017-07-20 22:38:06,585 Epoch[68] Batch [30]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.081244,	
2017-07-20 22:38:11,224 Epoch[68] Batch [40]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.082949,	
2017-07-20 22:38:15,688 Epoch[68] Batch [50]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.081561,	
2017-07-20 22:38:20,938 Epoch[68] Batch [60]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.080523,	
2017-07-20 22:38:26,091 Epoch[68] Batch [70]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.079888,	
2017-07-20 22:38:30,751 Epoch[68] Batch [80]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.078934,	
2017-07-20 22:38:35,328 Epoch[68] Batch [90]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.078914,	
2017-07-20 22:38:40,032 Epoch[68] Batch [100]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.078306,	
2017-07-20 22:38:44,724 Epoch[68] Batch [110]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.078744,	
2017-07-20 22:38:49,283 Epoch[68] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.078398,	
2017-07-20 22:38:53,932 Epoch[68] Batch [130]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.078916,	
2017-07-20 22:38:58,698 Epoch[68] Batch [140]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.078973,	
2017-07-20 22:39:03,931 Epoch[68] Batch [150]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.078728,	
2017-07-20 22:39:08,574 Epoch[68] Batch [160]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.078668,	
2017-07-20 22:39:13,092 Epoch[68] Batch [170]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.078515,	
2017-07-20 22:39:17,886 Epoch[68] Batch [180]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.078693,	
2017-07-20 22:39:22,810 Epoch[68] Batch [190]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.078509,	
2017-07-20 22:39:27,753 Epoch[68] Batch [200]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.078300,	
2017-07-20 22:39:32,393 Epoch[68] Batch [210]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.078238,	
2017-07-20 22:39:37,147 Epoch[68] Batch [220]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.078225,	
2017-07-20 22:39:41,827 Epoch[68] Batch [230]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077892,	
2017-07-20 22:39:46,712 Epoch[68] Batch [240]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078267,	
2017-07-20 22:39:51,597 Epoch[68] Batch [250]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078245,	
2017-07-20 22:39:56,342 Epoch[68] Batch [260]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078372,	
2017-07-20 22:40:01,235 Epoch[68] Batch [270]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.078248,	
2017-07-20 22:40:05,968 Epoch[68] Batch [280]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.078349,	
2017-07-20 22:40:10,537 Epoch[68] Batch [290]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.078144,	
2017-07-20 22:40:14,980 Epoch[68] Batch [300]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.078115,	
2017-07-20 22:40:19,740 Epoch[68] Batch [310]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077814,	
2017-07-20 22:40:24,365 Epoch[68] Batch [320]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.077653,	
2017-07-20 22:40:28,933 Epoch[68] Batch [330]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.077441,	
2017-07-20 22:40:33,632 Epoch[68] Batch [340]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077535,	
2017-07-20 22:40:38,606 Epoch[68] Batch [350]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.077424,	
2017-07-20 22:40:43,510 Epoch[68] Batch [360]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.077365,	
2017-07-20 22:40:48,206 Epoch[68] Batch [370]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.077462,	
2017-07-20 22:40:52,735 Epoch[68] Batch [380]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.077521,	
2017-07-20 22:40:57,135 Epoch[68] Batch [390]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.077473,	
2017-07-20 22:41:01,509 Epoch[68] Batch [400]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.077780,	
2017-07-20 22:41:06,023 Epoch[68] Batch [410]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.077623,	
2017-07-20 22:41:10,828 Epoch[68] Batch [420]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.077699,	
2017-07-20 22:41:14,888 Epoch[68] Batch [430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.077550,	
2017-07-20 22:41:19,335 Epoch[68] Batch [440]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.077567,	
2017-07-20 22:41:24,175 Epoch[68] Batch [450]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.077666,	
2017-07-20 22:41:28,884 Epoch[68] Batch [460]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.077551,	
2017-07-20 22:41:33,473 Epoch[68] Batch [470]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.077604,	
2017-07-20 22:41:38,195 Epoch[68] Batch [480]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.077795,	
2017-07-20 22:41:42,940 Epoch[68] Batch [490]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077747,	
2017-07-20 22:41:47,533 Epoch[68] Batch [500]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.077796,	
2017-07-20 22:41:52,046 Epoch[68] Batch [510]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.077770,	
2017-07-20 22:41:57,087 Epoch[68] Batch [520]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.077867,	
2017-07-20 22:42:01,755 Epoch[68] Batch [530]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.077954,	
2017-07-20 22:42:06,406 Epoch[68] Batch [540]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.077953,	
2017-07-20 22:42:11,156 Epoch[68] Batch [550]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078081,	
2017-07-20 22:42:16,194 Epoch[68] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.078164,	
2017-07-20 22:42:21,235 Epoch[68] Batch [570]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.078121,	
2017-07-20 22:42:25,988 Epoch[68] Batch [580]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078036,	
2017-07-20 22:42:30,870 Epoch[68] Batch [590]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078109,	
2017-07-20 22:42:35,632 Epoch[68] Batch [600]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078031,	
2017-07-20 22:42:40,280 Epoch[68] Batch [610]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.078215,	
2017-07-20 22:42:44,885 Epoch[68] Batch [620]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.078297,	
2017-07-20 22:42:49,570 Epoch[68] Batch [630]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.078194,	
2017-07-20 22:42:54,053 Epoch[68] Batch [640]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.078087,	
2017-07-20 22:42:58,737 Epoch[68] Batch [650]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.078102,	
2017-07-20 22:43:03,580 Epoch[68] Batch [660]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.078070,	
2017-07-20 22:43:08,324 Epoch[68] Batch [670]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078155,	
2017-07-20 22:43:13,567 Epoch[68] Batch [680]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.078045,	
2017-07-20 22:43:18,601 Epoch[68] Batch [690]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.078030,	
2017-07-20 22:43:24,051 Epoch[68] Batch [700]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.077828,	
2017-07-20 22:43:28,851 Epoch[68] Batch [710]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.077838,	
2017-07-20 22:43:33,449 Epoch[68] Batch [720]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077823,	
2017-07-20 22:43:38,213 Epoch[68] Batch [730]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077827,	
2017-07-20 22:43:42,995 Epoch[68] Batch [740]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.077737,	
2017-07-20 22:43:48,114 Epoch[68] Batch [750]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077757,	
2017-07-20 22:43:53,073 Epoch[68] Batch [760]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.077843,	
2017-07-20 22:43:57,551 Epoch[68] Batch [770]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.077802,	
2017-07-20 22:44:02,234 Epoch[68] Batch [780]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.077684,	
2017-07-20 22:44:07,447 Epoch[68] Batch [790]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.077702,	
2017-07-20 22:44:12,537 Epoch[68] Batch [800]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077626,	
2017-07-20 22:44:17,570 Epoch[68] Batch [810]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077659,	
2017-07-20 22:44:22,849 Epoch[68] Batch [820]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.077674,	
2017-07-20 22:44:27,824 Epoch[68] Batch [830]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.077707,	
2017-07-20 22:44:32,883 Epoch[68] Batch [840]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.077699,	
2017-07-20 22:44:37,581 Epoch[68] Batch [850]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077763,	
2017-07-20 22:44:42,419 Epoch[68] Batch [860]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.077782,	
2017-07-20 22:44:47,496 Epoch[68] Batch [870]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077815,	
2017-07-20 22:44:52,094 Epoch[68] Batch [880]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077805,	
2017-07-20 22:44:57,297 Epoch[68] Batch [890]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.077819,	
2017-07-20 22:45:02,542 Epoch[68] Batch [900]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.077758,	
2017-07-20 22:45:07,354 Epoch[68] Batch [910]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077833,	
2017-07-20 22:45:11,868 Epoch[68] Batch [920]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.077793,	
2017-07-20 22:45:17,578 Epoch[68] Batch [930]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.077789,	
2017-07-20 22:45:22,277 Epoch[68] Batch [940]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077757,	
2017-07-20 22:45:27,329 Epoch[68] Batch [950]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.077803,	
2017-07-20 22:45:32,402 Epoch[68] Batch [960]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.077844,	
2017-07-20 22:45:37,405 Epoch[68] Batch [970]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.077861,	
2017-07-20 22:45:42,284 Epoch[68] Batch [980]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.077838,	
2017-07-20 22:45:48,200 Epoch[68] Batch [990]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.077824,	
2017-07-20 22:45:53,063 Epoch[68] Batch [1000]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077800,	
2017-07-20 22:45:58,155 Epoch[68] Batch [1010]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077808,	
2017-07-20 22:46:02,923 Epoch[68] Batch [1020]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.077873,	
2017-07-20 22:46:07,388 Epoch[68] Batch [1030]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.077892,	
2017-07-20 22:46:12,861 Epoch[68] Batch [1040]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.077917,	
2017-07-20 22:46:18,091 Epoch[68] Batch [1050]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.077937,	
2017-07-20 22:46:23,126 Epoch[68] Batch [1060]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077910,	
2017-07-20 22:46:28,553 Epoch[68] Batch [1070]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.077933,	
2017-07-20 22:46:33,235 Epoch[68] Batch [1080]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.077867,	
2017-07-20 22:46:38,411 Epoch[68] Batch [1090]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.077863,	
2017-07-20 22:46:43,089 Epoch[68] Batch [1100]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077891,	
2017-07-20 22:46:48,129 Epoch[68] Batch [1110]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.077922,	
2017-07-20 22:46:52,688 Epoch[68] Batch [1120]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.077905,	
2017-07-20 22:46:58,052 Epoch[68] Batch [1130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.077893,	
2017-07-20 22:47:03,047 Epoch[68] Batch [1140]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.077896,	
2017-07-20 22:47:07,827 Epoch[68] Batch [1150]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.077885,	
2017-07-20 22:47:12,632 Epoch[68] Batch [1160]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.077908,	
2017-07-20 22:47:17,256 Epoch[68] Batch [1170]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.077886,	
2017-07-20 22:47:22,419 Epoch[68] Batch [1180]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.077879,	
2017-07-20 22:47:26,972 Epoch[68] Batch [1190]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.077878,	
2017-07-20 22:47:31,730 Epoch[68] Batch [1200]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.077927,	
2017-07-20 22:47:36,382 Epoch[68] Batch [1210]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.077919,	
2017-07-20 22:47:41,175 Epoch[68] Batch [1220]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077958,	
2017-07-20 22:47:46,101 Epoch[68] Batch [1230]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077978,	
2017-07-20 22:47:51,004 Epoch[68] Batch [1240]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078023,	
2017-07-20 22:47:56,146 Epoch[68] Batch [1250]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.078074,	
2017-07-20 22:48:01,345 Epoch[68] Batch [1260]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.078120,	
2017-07-20 22:48:06,248 Epoch[68] Batch [1270]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078147,	
2017-07-20 22:48:11,497 Epoch[68] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.078090,	
2017-07-20 22:48:16,359 Epoch[68] Batch [1290]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.078090,	
2017-07-20 22:48:21,242 Epoch[68] Batch [1300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078074,	
2017-07-20 22:48:25,619 Epoch[68] Batch [1310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.078071,	
2017-07-20 22:48:30,241 Epoch[68] Batch [1320]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.078035,	
2017-07-20 22:48:35,012 Epoch[68] Batch [1330]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.078052,	
2017-07-20 22:48:39,969 Epoch[68] Batch [1340]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078009,	
2017-07-20 22:48:44,780 Epoch[68] Batch [1350]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.078009,	
2017-07-20 22:48:49,731 Epoch[68] Batch [1360]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.078000,	
2017-07-20 22:48:54,406 Epoch[68] Batch [1370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.077995,	
2017-07-20 22:48:59,008 Epoch[68] Batch [1380]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077963,	
2017-07-20 22:49:03,955 Epoch[68] Batch [1390]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.077942,	
2017-07-20 22:49:08,703 Epoch[68] Batch [1400]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077985,	
2017-07-20 22:49:13,519 Epoch[68] Batch [1410]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077965,	
2017-07-20 22:49:18,634 Epoch[68] Batch [1420]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.077905,	
2017-07-20 22:49:23,456 Epoch[68] Batch [1430]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077879,	
2017-07-20 22:49:28,201 Epoch[68] Batch [1440]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077923,	
2017-07-20 22:49:33,057 Epoch[68] Batch [1450]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077912,	
2017-07-20 22:49:37,984 Epoch[68] Batch [1460]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077829,	
2017-07-20 22:49:42,692 Epoch[68] Batch [1470]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077821,	
2017-07-20 22:49:47,155 Epoch[68] Batch [1480]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.077824,	
2017-07-20 22:49:50,143 Epoch[68] Train-FCNLogLoss=0.077833
2017-07-20 22:49:50,143 Epoch[68] Time cost=718.602
2017-07-20 22:49:50,882 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0069.params"
2017-07-20 22:49:54,201 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0069.states"
2017-07-20 22:49:59,863 Epoch[69] Batch [10]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.078785,	
2017-07-20 22:50:05,020 Epoch[69] Batch [20]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.083770,	
2017-07-20 22:50:10,061 Epoch[69] Batch [30]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.082979,	
2017-07-20 22:50:15,224 Epoch[69] Batch [40]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.079787,	
2017-07-20 22:50:20,494 Epoch[69] Batch [50]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.079170,	
2017-07-20 22:50:25,582 Epoch[69] Batch [60]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077830,	
2017-07-20 22:50:30,337 Epoch[69] Batch [70]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.079787,	
2017-07-20 22:50:35,018 Epoch[69] Batch [80]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.078169,	
2017-07-20 22:50:40,008 Epoch[69] Batch [90]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.078745,	
2017-07-20 22:50:44,836 Epoch[69] Batch [100]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.078446,	
2017-07-20 22:50:49,424 Epoch[69] Batch [110]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.078250,	
2017-07-20 22:50:54,121 Epoch[69] Batch [120]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.078226,	
2017-07-20 22:50:58,787 Epoch[69] Batch [130]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.077640,	
2017-07-20 22:51:03,467 Epoch[69] Batch [140]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077399,	
2017-07-20 22:51:08,339 Epoch[69] Batch [150]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.077118,	
2017-07-20 22:51:13,275 Epoch[69] Batch [160]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.076878,	
2017-07-20 22:51:17,899 Epoch[69] Batch [170]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.077382,	
2017-07-20 22:51:22,890 Epoch[69] Batch [180]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077175,	
2017-07-20 22:51:27,817 Epoch[69] Batch [190]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077160,	
2017-07-20 22:51:32,524 Epoch[69] Batch [200]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077303,	
2017-07-20 22:51:37,265 Epoch[69] Batch [210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076946,	
2017-07-20 22:51:42,049 Epoch[69] Batch [220]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.077198,	
2017-07-20 22:51:46,842 Epoch[69] Batch [230]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077198,	
2017-07-20 22:51:51,498 Epoch[69] Batch [240]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.076982,	
2017-07-20 22:51:56,233 Epoch[69] Batch [250]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077059,	
2017-07-20 22:52:00,685 Epoch[69] Batch [260]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.077206,	
2017-07-20 22:52:05,523 Epoch[69] Batch [270]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.077225,	
2017-07-20 22:52:09,934 Epoch[69] Batch [280]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.077374,	
2017-07-20 22:52:14,681 Epoch[69] Batch [290]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077407,	
2017-07-20 22:52:19,567 Epoch[69] Batch [300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077596,	
2017-07-20 22:52:24,333 Epoch[69] Batch [310]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.077500,	
2017-07-20 22:52:29,357 Epoch[69] Batch [320]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.077427,	
2017-07-20 22:52:33,911 Epoch[69] Batch [330]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.077406,	
2017-07-20 22:52:38,674 Epoch[69] Batch [340]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077319,	
2017-07-20 22:52:44,032 Epoch[69] Batch [350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.077255,	
2017-07-20 22:52:48,832 Epoch[69] Batch [360]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.077396,	
2017-07-20 22:52:53,605 Epoch[69] Batch [370]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.077342,	
2017-07-20 22:52:58,299 Epoch[69] Batch [380]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.077278,	
2017-07-20 22:53:02,819 Epoch[69] Batch [390]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.077462,	
2017-07-20 22:53:07,617 Epoch[69] Batch [400]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.077370,	
2017-07-20 22:53:12,574 Epoch[69] Batch [410]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.077399,	
2017-07-20 22:53:17,560 Epoch[69] Batch [420]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077369,	
2017-07-20 22:53:22,816 Epoch[69] Batch [430]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.077283,	
2017-07-20 22:53:27,893 Epoch[69] Batch [440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077279,	
2017-07-20 22:53:32,385 Epoch[69] Batch [450]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.077262,	
2017-07-20 22:53:37,248 Epoch[69] Batch [460]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077100,	
2017-07-20 22:53:42,098 Epoch[69] Batch [470]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.077173,	
2017-07-20 22:53:47,141 Epoch[69] Batch [480]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077358,	
2017-07-20 22:53:51,757 Epoch[69] Batch [490]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.077278,	
2017-07-20 22:53:56,521 Epoch[69] Batch [500]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077336,	
2017-07-20 22:54:01,210 Epoch[69] Batch [510]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.077231,	
2017-07-20 22:54:06,426 Epoch[69] Batch [520]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.077288,	
2017-07-20 22:54:11,271 Epoch[69] Batch [530]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.077307,	
2017-07-20 22:54:15,968 Epoch[69] Batch [540]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.077195,	
2017-07-20 22:54:20,993 Epoch[69] Batch [550]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.076986,	
2017-07-20 22:54:25,767 Epoch[69] Batch [560]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.077079,	
2017-07-20 22:54:31,061 Epoch[69] Batch [570]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.077099,	
2017-07-20 22:54:36,120 Epoch[69] Batch [580]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.077150,	
2017-07-20 22:54:41,021 Epoch[69] Batch [590]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.077208,	
2017-07-20 22:54:45,953 Epoch[69] Batch [600]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077248,	
2017-07-20 22:54:50,501 Epoch[69] Batch [610]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.077269,	
2017-07-20 22:54:55,600 Epoch[69] Batch [620]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.077347,	
2017-07-20 22:55:00,301 Epoch[69] Batch [630]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077463,	
2017-07-20 22:55:04,818 Epoch[69] Batch [640]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.077589,	
2017-07-20 22:55:09,231 Epoch[69] Batch [650]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.077632,	
2017-07-20 22:55:13,890 Epoch[69] Batch [660]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077696,	
2017-07-20 22:55:18,882 Epoch[69] Batch [670]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.077674,	
2017-07-20 22:55:23,833 Epoch[69] Batch [680]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.077709,	
2017-07-20 22:55:28,500 Epoch[69] Batch [690]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.077632,	
2017-07-20 22:55:33,396 Epoch[69] Batch [700]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.077555,	
2017-07-20 22:55:38,170 Epoch[69] Batch [710]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.077517,	
2017-07-20 22:55:43,201 Epoch[69] Batch [720]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077444,	
2017-07-20 22:55:48,399 Epoch[69] Batch [730]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.077404,	
2017-07-20 22:55:53,374 Epoch[69] Batch [740]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.077347,	
2017-07-20 22:55:58,385 Epoch[69] Batch [750]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.077302,	
2017-07-20 22:56:03,328 Epoch[69] Batch [760]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077502,	
2017-07-20 22:56:07,937 Epoch[69] Batch [770]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.077653,	
2017-07-20 22:56:13,062 Epoch[69] Batch [780]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077679,	
2017-07-20 22:56:17,994 Epoch[69] Batch [790]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077673,	
2017-07-20 22:56:22,833 Epoch[69] Batch [800]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.077626,	
2017-07-20 22:56:27,540 Epoch[69] Batch [810]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077542,	
2017-07-20 22:56:32,487 Epoch[69] Batch [820]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077503,	
2017-07-20 22:56:37,277 Epoch[69] Batch [830]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077553,	
2017-07-20 22:56:42,040 Epoch[69] Batch [840]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077550,	
2017-07-20 22:56:46,892 Epoch[69] Batch [850]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077587,	
2017-07-20 22:56:51,862 Epoch[69] Batch [860]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077643,	
2017-07-20 22:56:56,682 Epoch[69] Batch [870]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077743,	
2017-07-20 22:57:01,800 Epoch[69] Batch [880]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.077701,	
2017-07-20 22:57:07,019 Epoch[69] Batch [890]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.077650,	
2017-07-20 22:57:11,946 Epoch[69] Batch [900]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077699,	
2017-07-20 22:57:16,434 Epoch[69] Batch [910]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.077714,	
2017-07-20 22:57:21,330 Epoch[69] Batch [920]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.077736,	
2017-07-20 22:57:26,085 Epoch[69] Batch [930]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.077647,	
2017-07-20 22:57:30,743 Epoch[69] Batch [940]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077636,	
2017-07-20 22:57:35,683 Epoch[69] Batch [950]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.077590,	
2017-07-20 22:57:40,768 Epoch[69] Batch [960]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.077523,	
2017-07-20 22:57:45,877 Epoch[69] Batch [970]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.077530,	
2017-07-20 22:57:50,462 Epoch[69] Batch [980]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.077556,	
2017-07-20 22:57:55,445 Epoch[69] Batch [990]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.077460,	
2017-07-20 22:58:01,231 Epoch[69] Batch [1000]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.077475,	
2017-07-20 22:58:06,887 Epoch[69] Batch [1010]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.077479,	
2017-07-20 22:58:12,206 Epoch[69] Batch [1020]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.077461,	
2017-07-20 22:58:17,213 Epoch[69] Batch [1030]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.077420,	
2017-07-20 22:58:22,216 Epoch[69] Batch [1040]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.077454,	
2017-07-20 22:58:27,143 Epoch[69] Batch [1050]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077474,	
2017-07-20 22:58:31,806 Epoch[69] Batch [1060]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.077469,	
2017-07-20 22:58:36,560 Epoch[69] Batch [1070]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.077514,	
2017-07-20 22:58:41,262 Epoch[69] Batch [1080]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077517,	
2017-07-20 22:58:46,113 Epoch[69] Batch [1090]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.077505,	
2017-07-20 22:58:50,928 Epoch[69] Batch [1100]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077520,	
2017-07-20 22:58:56,105 Epoch[69] Batch [1110]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.077588,	
2017-07-20 22:59:00,712 Epoch[69] Batch [1120]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.077567,	
2017-07-20 22:59:05,497 Epoch[69] Batch [1130]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.077606,	
2017-07-20 22:59:10,245 Epoch[69] Batch [1140]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077596,	
2017-07-20 22:59:15,320 Epoch[69] Batch [1150]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077650,	
2017-07-20 22:59:20,320 Epoch[69] Batch [1160]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.077669,	
2017-07-20 22:59:25,217 Epoch[69] Batch [1170]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.077598,	
2017-07-20 22:59:29,960 Epoch[69] Batch [1180]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.077560,	
2017-07-20 22:59:34,645 Epoch[69] Batch [1190]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.077552,	
2017-07-20 22:59:39,757 Epoch[69] Batch [1200]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.077533,	
2017-07-20 22:59:44,754 Epoch[69] Batch [1210]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.077563,	
2017-07-20 22:59:49,410 Epoch[69] Batch [1220]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077525,	
2017-07-20 22:59:54,611 Epoch[69] Batch [1230]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.077562,	
2017-07-20 22:59:59,078 Epoch[69] Batch [1240]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.077597,	
2017-07-20 23:00:04,024 Epoch[69] Batch [1250]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077650,	
2017-07-20 23:00:08,896 Epoch[69] Batch [1260]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.077650,	
2017-07-20 23:00:13,761 Epoch[69] Batch [1270]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077632,	
2017-07-20 23:00:18,678 Epoch[69] Batch [1280]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.077565,	
2017-07-20 23:00:23,512 Epoch[69] Batch [1290]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.077593,	
2017-07-20 23:00:28,215 Epoch[69] Batch [1300]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077614,	
2017-07-20 23:00:32,938 Epoch[69] Batch [1310]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.077653,	
2017-07-20 23:00:38,696 Epoch[69] Batch [1320]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.077611,	
2017-07-20 23:00:43,663 Epoch[69] Batch [1330]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077640,	
2017-07-20 23:00:48,893 Epoch[69] Batch [1340]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.077680,	
2017-07-20 23:00:53,943 Epoch[69] Batch [1350]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.077667,	
2017-07-20 23:00:59,073 Epoch[69] Batch [1360]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.077640,	
2017-07-20 23:01:04,511 Epoch[69] Batch [1370]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.077702,	
2017-07-20 23:01:09,365 Epoch[69] Batch [1380]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077768,	
2017-07-20 23:01:14,175 Epoch[69] Batch [1390]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.077836,	
2017-07-20 23:01:19,049 Epoch[69] Batch [1400]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.077851,	
2017-07-20 23:01:24,338 Epoch[69] Batch [1410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.077816,	
2017-07-20 23:01:29,264 Epoch[69] Batch [1420]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077841,	
2017-07-20 23:01:34,310 Epoch[69] Batch [1430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077872,	
2017-07-20 23:01:39,168 Epoch[69] Batch [1440]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077864,	
2017-07-20 23:01:44,013 Epoch[69] Batch [1450]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.077871,	
2017-07-20 23:01:48,678 Epoch[69] Batch [1460]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.077891,	
2017-07-20 23:01:53,081 Epoch[69] Batch [1470]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.077872,	
2017-07-20 23:01:57,692 Epoch[69] Batch [1480]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.077894,	
2017-07-20 23:02:00,420 Epoch[69] Train-FCNLogLoss=0.077857
2017-07-20 23:02:00,420 Epoch[69] Time cost=726.219
2017-07-20 23:02:01,398 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0070.params"
2017-07-20 23:02:04,862 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0070.states"
2017-07-20 23:02:10,339 Epoch[70] Batch [10]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.080543,	
2017-07-20 23:02:14,925 Epoch[70] Batch [20]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.076751,	
2017-07-20 23:02:19,844 Epoch[70] Batch [30]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.075760,	
2017-07-20 23:02:24,895 Epoch[70] Batch [40]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.074275,	
2017-07-20 23:02:30,021 Epoch[70] Batch [50]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.075378,	
2017-07-20 23:02:34,652 Epoch[70] Batch [60]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.076622,	
2017-07-20 23:02:39,220 Epoch[70] Batch [70]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.076514,	
2017-07-20 23:02:44,111 Epoch[70] Batch [80]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.076790,	
2017-07-20 23:02:49,101 Epoch[70] Batch [90]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.076441,	
2017-07-20 23:02:53,987 Epoch[70] Batch [100]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076743,	
2017-07-20 23:02:58,914 Epoch[70] Batch [110]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077278,	
2017-07-20 23:03:03,628 Epoch[70] Batch [120]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076655,	
2017-07-20 23:03:08,311 Epoch[70] Batch [130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.077003,	
2017-07-20 23:03:13,502 Epoch[70] Batch [140]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.077049,	
2017-07-20 23:03:32,717 Epoch[70] Batch [150]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.077205,	
2017-07-20 23:03:55,638 Epoch[70] Batch [160]	Speed: 1.75 samples/sec	Train-FCNLogLoss=0.077191,	
2017-07-20 23:04:18,576 Epoch[70] Batch [170]	Speed: 1.74 samples/sec	Train-FCNLogLoss=0.076944,	
2017-07-20 23:04:41,109 Epoch[70] Batch [180]	Speed: 1.78 samples/sec	Train-FCNLogLoss=0.076932,	
2017-07-20 23:05:03,561 Epoch[70] Batch [190]	Speed: 1.78 samples/sec	Train-FCNLogLoss=0.077087,	
2017-07-20 23:05:24,298 Epoch[70] Batch [200]	Speed: 1.93 samples/sec	Train-FCNLogLoss=0.076740,	
2017-07-20 23:05:48,365 Epoch[70] Batch [210]	Speed: 1.66 samples/sec	Train-FCNLogLoss=0.076700,	
2017-07-20 23:05:58,334 Epoch[70] Batch [220]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.076793,	
2017-07-20 23:06:02,925 Epoch[70] Batch [230]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.076554,	
2017-07-20 23:06:08,187 Epoch[70] Batch [240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.076809,	
2017-07-20 23:06:12,860 Epoch[70] Batch [250]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076891,	
2017-07-20 23:06:17,722 Epoch[70] Batch [260]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077039,	
2017-07-20 23:06:22,406 Epoch[70] Batch [270]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.077259,	
2017-07-20 23:06:27,187 Epoch[70] Batch [280]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.077174,	
2017-07-20 23:06:32,107 Epoch[70] Batch [290]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.076968,	
2017-07-20 23:06:36,654 Epoch[70] Batch [300]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.077088,	
2017-07-20 23:06:41,585 Epoch[70] Batch [310]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077012,	
2017-07-20 23:06:47,059 Epoch[70] Batch [320]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.077008,	
2017-07-20 23:06:52,101 Epoch[70] Batch [330]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.076912,	
2017-07-20 23:06:56,741 Epoch[70] Batch [340]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.076860,	
2017-07-20 23:07:01,562 Epoch[70] Batch [350]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.076714,	
2017-07-20 23:07:06,636 Epoch[70] Batch [360]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.076696,	
2017-07-20 23:07:10,992 Epoch[70] Batch [370]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.076515,	
2017-07-20 23:07:15,843 Epoch[70] Batch [380]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.076533,	
2017-07-20 23:07:21,266 Epoch[70] Batch [390]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.076373,	
2017-07-20 23:07:26,025 Epoch[70] Batch [400]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.076376,	
2017-07-20 23:07:30,632 Epoch[70] Batch [410]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076281,	
2017-07-20 23:07:35,598 Epoch[70] Batch [420]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.076239,	
2017-07-20 23:07:40,608 Epoch[70] Batch [430]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.076400,	
2017-07-20 23:07:45,215 Epoch[70] Batch [440]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076352,	
2017-07-20 23:07:50,353 Epoch[70] Batch [450]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.076503,	
2017-07-20 23:07:54,884 Epoch[70] Batch [460]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.076543,	
2017-07-20 23:07:59,781 Epoch[70] Batch [470]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.076655,	
2017-07-20 23:08:04,742 Epoch[70] Batch [480]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.076694,	
2017-07-20 23:08:09,608 Epoch[70] Batch [490]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.076896,	
2017-07-20 23:08:14,792 Epoch[70] Batch [500]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.077018,	
2017-07-20 23:08:20,009 Epoch[70] Batch [510]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.076979,	
2017-07-20 23:08:24,718 Epoch[70] Batch [520]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076941,	
2017-07-20 23:08:29,490 Epoch[70] Batch [530]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.076957,	
2017-07-20 23:08:34,229 Epoch[70] Batch [540]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076942,	
2017-07-20 23:08:38,918 Epoch[70] Batch [550]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.076996,	
2017-07-20 23:08:43,606 Epoch[70] Batch [560]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.076949,	
2017-07-20 23:08:48,209 Epoch[70] Batch [570]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.076927,	
2017-07-20 23:08:53,372 Epoch[70] Batch [580]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.077056,	
2017-07-20 23:08:58,359 Epoch[70] Batch [590]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077071,	
2017-07-20 23:09:03,498 Epoch[70] Batch [600]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.077041,	
2017-07-20 23:09:08,280 Epoch[70] Batch [610]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.077008,	
2017-07-20 23:09:13,306 Epoch[70] Batch [620]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.076951,	
2017-07-20 23:09:18,281 Epoch[70] Batch [630]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.077043,	
2017-07-20 23:09:23,391 Epoch[70] Batch [640]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.077062,	
2017-07-20 23:09:28,122 Epoch[70] Batch [650]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.076949,	
2017-07-20 23:09:32,848 Epoch[70] Batch [660]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.077018,	
2017-07-20 23:09:37,628 Epoch[70] Batch [670]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.076963,	
2017-07-20 23:09:42,247 Epoch[70] Batch [680]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.076903,	
2017-07-20 23:09:46,795 Epoch[70] Batch [690]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.076906,	
2017-07-20 23:09:51,378 Epoch[70] Batch [700]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.077048,	
2017-07-20 23:09:56,431 Epoch[70] Batch [710]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.077039,	
2017-07-20 23:10:02,316 Epoch[70] Batch [720]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.077031,	
2017-07-20 23:10:07,511 Epoch[70] Batch [730]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.077107,	
2017-07-20 23:10:12,572 Epoch[70] Batch [740]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.077151,	
2017-07-20 23:10:17,520 Epoch[70] Batch [750]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077057,	
2017-07-20 23:10:22,504 Epoch[70] Batch [760]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.077093,	
2017-07-20 23:10:27,543 Epoch[70] Batch [770]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.077125,	
2017-07-20 23:10:32,531 Epoch[70] Batch [780]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077013,	
2017-07-20 23:10:37,417 Epoch[70] Batch [790]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076978,	
2017-07-20 23:10:42,208 Epoch[70] Batch [800]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.076908,	
2017-07-20 23:10:47,146 Epoch[70] Batch [810]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.076951,	
2017-07-20 23:10:52,011 Epoch[70] Batch [820]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.076934,	
2017-07-20 23:10:57,172 Epoch[70] Batch [830]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.076967,	
2017-07-20 23:11:01,965 Epoch[70] Batch [840]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077098,	
2017-07-20 23:11:06,978 Epoch[70] Batch [850]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.077027,	
2017-07-20 23:11:11,883 Epoch[70] Batch [860]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.076968,	
2017-07-20 23:11:16,625 Epoch[70] Batch [870]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076888,	
2017-07-20 23:11:21,332 Epoch[70] Batch [880]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076811,	
2017-07-20 23:11:26,053 Epoch[70] Batch [890]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.076762,	
2017-07-20 23:11:31,073 Epoch[70] Batch [900]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.076784,	
2017-07-20 23:11:35,736 Epoch[70] Batch [910]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.076721,	
2017-07-20 23:11:40,487 Epoch[70] Batch [920]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.076829,	
2017-07-20 23:11:45,203 Epoch[70] Batch [930]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.076793,	
2017-07-20 23:11:50,091 Epoch[70] Batch [940]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.076830,	
2017-07-20 23:11:54,832 Epoch[70] Batch [950]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076753,	
2017-07-20 23:11:59,464 Epoch[70] Batch [960]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.076701,	
2017-07-20 23:12:04,137 Epoch[70] Batch [970]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076598,	
2017-07-20 23:12:08,967 Epoch[70] Batch [980]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.076678,	
2017-07-20 23:12:13,354 Epoch[70] Batch [990]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076678,	
2017-07-20 23:12:18,215 Epoch[70] Batch [1000]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.076603,	
2017-07-20 23:12:22,923 Epoch[70] Batch [1010]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076570,	
2017-07-20 23:12:27,747 Epoch[70] Batch [1020]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.076609,	
2017-07-20 23:12:32,726 Epoch[70] Batch [1030]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.076622,	
2017-07-20 23:12:37,700 Epoch[70] Batch [1040]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.076561,	
2017-07-20 23:12:42,885 Epoch[70] Batch [1050]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.076568,	
2017-07-20 23:12:47,615 Epoch[70] Batch [1060]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.076519,	
2017-07-20 23:12:52,237 Epoch[70] Batch [1070]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.076554,	
2017-07-20 23:12:56,875 Epoch[70] Batch [1080]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.076627,	
2017-07-20 23:13:01,758 Epoch[70] Batch [1090]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076639,	
2017-07-20 23:13:06,893 Epoch[70] Batch [1100]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.076625,	
2017-07-20 23:13:11,753 Epoch[70] Batch [1110]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.076648,	
2017-07-20 23:13:16,293 Epoch[70] Batch [1120]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.076697,	
2017-07-20 23:13:21,226 Epoch[70] Batch [1130]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.076716,	
2017-07-20 23:13:25,743 Epoch[70] Batch [1140]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.076696,	
2017-07-20 23:13:30,437 Epoch[70] Batch [1150]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.076637,	
2017-07-20 23:13:34,914 Epoch[70] Batch [1160]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.076647,	
2017-07-20 23:13:39,633 Epoch[70] Batch [1170]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.076684,	
2017-07-20 23:13:44,546 Epoch[70] Batch [1180]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.076740,	
2017-07-20 23:13:49,049 Epoch[70] Batch [1190]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.076792,	
2017-07-20 23:13:53,826 Epoch[70] Batch [1200]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.076860,	
2017-07-20 23:13:58,402 Epoch[70] Batch [1210]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.076843,	
2017-07-20 23:14:03,212 Epoch[70] Batch [1220]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.076871,	
2017-07-20 23:14:08,197 Epoch[70] Batch [1230]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.076833,	
2017-07-20 23:14:13,231 Epoch[70] Batch [1240]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.076888,	
2017-07-20 23:14:18,065 Epoch[70] Batch [1250]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.076912,	
2017-07-20 23:14:22,691 Epoch[70] Batch [1260]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.076952,	
2017-07-20 23:14:27,281 Epoch[70] Batch [1270]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.076936,	
2017-07-20 23:14:32,278 Epoch[70] Batch [1280]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.076939,	
2017-07-20 23:14:36,954 Epoch[70] Batch [1290]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076991,	
2017-07-20 23:14:41,509 Epoch[70] Batch [1300]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.076980,	
2017-07-20 23:14:46,104 Epoch[70] Batch [1310]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.076940,	
2017-07-20 23:14:50,805 Epoch[70] Batch [1320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.076923,	
2017-07-20 23:14:55,619 Epoch[70] Batch [1330]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.076923,	
2017-07-20 23:15:00,595 Epoch[70] Batch [1340]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.076895,	
2017-07-20 23:15:05,285 Epoch[70] Batch [1350]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.076890,	
2017-07-20 23:15:09,995 Epoch[70] Batch [1360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076906,	
2017-07-20 23:15:14,730 Epoch[70] Batch [1370]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.076918,	
2017-07-20 23:15:19,814 Epoch[70] Batch [1380]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.076960,	
2017-07-20 23:15:24,559 Epoch[70] Batch [1390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.076943,	
2017-07-20 23:15:29,589 Epoch[70] Batch [1400]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.076965,	
2017-07-20 23:15:34,344 Epoch[70] Batch [1410]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.076993,	
2017-07-20 23:15:39,484 Epoch[70] Batch [1420]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.077031,	
2017-07-20 23:15:44,022 Epoch[70] Batch [1430]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.077069,	
2017-07-20 23:15:48,571 Epoch[70] Batch [1440]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.077085,	
2017-07-20 23:15:53,395 Epoch[70] Batch [1450]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.077096,	
2017-07-20 23:15:58,196 Epoch[70] Batch [1460]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.077070,	
2017-07-20 23:16:03,053 Epoch[70] Batch [1470]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077082,	
2017-07-20 23:16:07,653 Epoch[70] Batch [1480]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077134,	
2017-07-20 23:16:10,407 Epoch[70] Train-FCNLogLoss=0.077119
2017-07-20 23:16:10,408 Epoch[70] Time cost=845.545
2017-07-20 23:16:11,390 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0071.params"
2017-07-20 23:16:14,957 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0071.states"
2017-07-20 23:16:20,969 Epoch[71] Batch [10]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.079429,	
2017-07-20 23:16:25,692 Epoch[71] Batch [20]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.077816,	
2017-07-20 23:16:31,162 Epoch[71] Batch [30]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.078512,	
2017-07-20 23:16:36,206 Epoch[71] Batch [40]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.078504,	
2017-07-20 23:16:41,341 Epoch[71] Batch [50]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.076674,	
2017-07-20 23:16:46,310 Epoch[71] Batch [60]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077115,	
2017-07-20 23:16:51,098 Epoch[71] Batch [70]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077158,	
2017-07-20 23:16:55,652 Epoch[71] Batch [80]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.076466,	
2017-07-20 23:17:00,213 Epoch[71] Batch [90]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.076841,	
2017-07-20 23:17:05,278 Epoch[71] Batch [100]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.076189,	
2017-07-20 23:17:10,201 Epoch[71] Batch [110]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.075242,	
2017-07-20 23:17:15,436 Epoch[71] Batch [120]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.074948,	
2017-07-20 23:17:20,174 Epoch[71] Batch [130]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.074680,	
2017-07-20 23:17:25,066 Epoch[71] Batch [140]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.074478,	
2017-07-20 23:17:30,173 Epoch[71] Batch [150]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.074605,	
2017-07-20 23:17:34,961 Epoch[71] Batch [160]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.074986,	
2017-07-20 23:17:39,676 Epoch[71] Batch [170]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075281,	
2017-07-20 23:17:44,307 Epoch[71] Batch [180]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075320,	
2017-07-20 23:17:49,422 Epoch[71] Batch [190]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075780,	
2017-07-20 23:17:54,486 Epoch[71] Batch [200]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.075765,	
2017-07-20 23:17:59,336 Epoch[71] Batch [210]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.076144,	
2017-07-20 23:18:04,093 Epoch[71] Batch [220]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.075889,	
2017-07-20 23:18:08,609 Epoch[71] Batch [230]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075975,	
2017-07-20 23:18:13,275 Epoch[71] Batch [240]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.076211,	
2017-07-20 23:18:17,964 Epoch[71] Batch [250]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.075974,	
2017-07-20 23:18:22,741 Epoch[71] Batch [260]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075945,	
2017-07-20 23:18:27,372 Epoch[71] Batch [270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075752,	
2017-07-20 23:18:32,027 Epoch[71] Batch [280]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075872,	
2017-07-20 23:18:36,869 Epoch[71] Batch [290]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075680,	
2017-07-20 23:18:41,603 Epoch[71] Batch [300]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.075590,	
2017-07-20 23:18:46,249 Epoch[71] Batch [310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075792,	
2017-07-20 23:18:50,807 Epoch[71] Batch [320]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075665,	
2017-07-20 23:18:55,717 Epoch[71] Batch [330]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075612,	
2017-07-20 23:19:00,462 Epoch[71] Batch [340]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.075513,	
2017-07-20 23:19:05,378 Epoch[71] Batch [350]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075363,	
2017-07-20 23:19:10,153 Epoch[71] Batch [360]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075547,	
2017-07-20 23:19:15,004 Epoch[71] Batch [370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075464,	
2017-07-20 23:19:19,701 Epoch[71] Batch [380]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075557,	
2017-07-20 23:19:24,468 Epoch[71] Batch [390]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075783,	
2017-07-20 23:19:29,260 Epoch[71] Batch [400]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.075865,	
2017-07-20 23:19:33,941 Epoch[71] Batch [410]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075852,	
2017-07-20 23:19:38,919 Epoch[71] Batch [420]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075878,	
2017-07-20 23:19:43,758 Epoch[71] Batch [430]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.076070,	
2017-07-20 23:19:48,530 Epoch[71] Batch [440]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.076446,	
2017-07-20 23:19:53,412 Epoch[71] Batch [450]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076452,	
2017-07-20 23:19:58,983 Epoch[71] Batch [460]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.076606,	
2017-07-20 23:20:04,221 Epoch[71] Batch [470]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.076571,	
2017-07-20 23:20:09,386 Epoch[71] Batch [480]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.076552,	
2017-07-20 23:20:14,050 Epoch[71] Batch [490]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.076835,	
2017-07-20 23:20:19,005 Epoch[71] Batch [500]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.076699,	
2017-07-20 23:20:23,778 Epoch[71] Batch [510]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.076639,	
2017-07-20 23:20:28,586 Epoch[71] Batch [520]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.076567,	
2017-07-20 23:20:33,355 Epoch[71] Batch [530]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.076587,	
2017-07-20 23:20:37,938 Epoch[71] Batch [540]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.076674,	
2017-07-20 23:20:42,737 Epoch[71] Batch [550]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.076604,	
2017-07-20 23:20:47,706 Epoch[71] Batch [560]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.076688,	
2017-07-20 23:20:52,334 Epoch[71] Batch [570]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.076681,	
2017-07-20 23:20:57,015 Epoch[71] Batch [580]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.076698,	
2017-07-20 23:21:01,951 Epoch[71] Batch [590]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.076603,	
2017-07-20 23:21:06,995 Epoch[71] Batch [600]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.076487,	
2017-07-20 23:21:12,172 Epoch[71] Batch [610]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.076475,	
2017-07-20 23:21:17,068 Epoch[71] Batch [620]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.076530,	
2017-07-20 23:21:21,453 Epoch[71] Batch [630]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076703,	
2017-07-20 23:21:26,492 Epoch[71] Batch [640]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.076805,	
2017-07-20 23:21:31,381 Epoch[71] Batch [650]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.076963,	
2017-07-20 23:21:36,003 Epoch[71] Batch [660]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.077054,	
2017-07-20 23:21:40,681 Epoch[71] Batch [670]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077023,	
2017-07-20 23:21:45,547 Epoch[71] Batch [680]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.076912,	
2017-07-20 23:21:51,127 Epoch[71] Batch [690]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.076986,	
2017-07-20 23:21:55,864 Epoch[71] Batch [700]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076864,	
2017-07-20 23:22:00,898 Epoch[71] Batch [710]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.076816,	
2017-07-20 23:22:05,934 Epoch[71] Batch [720]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.076723,	
2017-07-20 23:22:10,648 Epoch[71] Batch [730]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076651,	
2017-07-20 23:22:15,579 Epoch[71] Batch [740]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.076596,	
2017-07-20 23:22:20,157 Epoch[71] Batch [750]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.076616,	
2017-07-20 23:22:25,088 Epoch[71] Batch [760]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.076662,	
2017-07-20 23:22:30,161 Epoch[71] Batch [770]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.076600,	
2017-07-20 23:22:34,747 Epoch[71] Batch [780]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.076672,	
2017-07-20 23:22:39,544 Epoch[71] Batch [790]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.076692,	
2017-07-20 23:22:44,297 Epoch[71] Batch [800]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.076794,	
2017-07-20 23:22:49,149 Epoch[71] Batch [810]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.076736,	
2017-07-20 23:22:53,977 Epoch[71] Batch [820]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.076760,	
2017-07-20 23:22:58,690 Epoch[71] Batch [830]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076748,	
2017-07-20 23:23:03,523 Epoch[71] Batch [840]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.076811,	
2017-07-20 23:23:08,487 Epoch[71] Batch [850]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.076709,	
2017-07-20 23:23:13,042 Epoch[71] Batch [860]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.076681,	
2017-07-20 23:23:17,719 Epoch[71] Batch [870]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.076650,	
2017-07-20 23:23:22,171 Epoch[71] Batch [880]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.076729,	
2017-07-20 23:23:27,281 Epoch[71] Batch [890]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.076697,	
2017-07-20 23:23:31,747 Epoch[71] Batch [900]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.076716,	
2017-07-20 23:23:36,566 Epoch[71] Batch [910]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.076692,	
2017-07-20 23:23:41,089 Epoch[71] Batch [920]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.076771,	
2017-07-20 23:23:45,830 Epoch[71] Batch [930]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076959,	
2017-07-20 23:23:50,505 Epoch[71] Batch [940]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076982,	
2017-07-20 23:23:55,070 Epoch[71] Batch [950]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.076985,	
2017-07-20 23:23:59,586 Epoch[71] Batch [960]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.076986,	
2017-07-20 23:24:04,106 Epoch[71] Batch [970]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.076878,	
2017-07-20 23:24:08,632 Epoch[71] Batch [980]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.076906,	
2017-07-20 23:24:13,467 Epoch[71] Batch [990]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.076828,	
2017-07-20 23:24:18,472 Epoch[71] Batch [1000]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.076800,	
2017-07-20 23:24:23,355 Epoch[71] Batch [1010]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076861,	
2017-07-20 23:24:28,065 Epoch[71] Batch [1020]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076928,	
2017-07-20 23:24:33,001 Epoch[71] Batch [1030]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.076975,	
2017-07-20 23:24:37,805 Epoch[71] Batch [1040]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.077060,	
2017-07-20 23:24:42,737 Epoch[71] Batch [1050]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077078,	
2017-07-20 23:24:47,628 Epoch[71] Batch [1060]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.077119,	
2017-07-20 23:24:52,602 Epoch[71] Batch [1070]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.077143,	
2017-07-20 23:24:57,611 Epoch[71] Batch [1080]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.077113,	
2017-07-20 23:25:02,409 Epoch[71] Batch [1090]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.077092,	
2017-07-20 23:25:07,501 Epoch[71] Batch [1100]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077127,	
2017-07-20 23:25:12,267 Epoch[71] Batch [1110]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.077113,	
2017-07-20 23:25:17,099 Epoch[71] Batch [1120]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.077063,	
2017-07-20 23:25:21,780 Epoch[71] Batch [1130]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077068,	
2017-07-20 23:25:26,845 Epoch[71] Batch [1140]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.077183,	
2017-07-20 23:25:31,817 Epoch[71] Batch [1150]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077176,	
2017-07-20 23:25:36,582 Epoch[71] Batch [1160]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077150,	
2017-07-20 23:25:41,334 Epoch[71] Batch [1170]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.077123,	
2017-07-20 23:25:46,283 Epoch[71] Batch [1180]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.077133,	
2017-07-20 23:25:51,215 Epoch[71] Batch [1190]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077121,	
2017-07-20 23:25:55,847 Epoch[71] Batch [1200]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.077127,	
2017-07-20 23:26:00,778 Epoch[71] Batch [1210]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077051,	
2017-07-20 23:26:05,631 Epoch[71] Batch [1220]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077105,	
2017-07-20 23:26:10,332 Epoch[71] Batch [1230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077095,	
2017-07-20 23:26:15,129 Epoch[71] Batch [1240]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.077130,	
2017-07-20 23:26:19,862 Epoch[71] Batch [1250]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077178,	
2017-07-20 23:26:24,561 Epoch[71] Batch [1260]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077237,	
2017-07-20 23:26:29,824 Epoch[71] Batch [1270]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.077210,	
2017-07-20 23:26:34,570 Epoch[71] Batch [1280]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077241,	
2017-07-20 23:26:39,158 Epoch[71] Batch [1290]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.077315,	
2017-07-20 23:26:43,957 Epoch[71] Batch [1300]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.077353,	
2017-07-20 23:26:48,749 Epoch[71] Batch [1310]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077326,	
2017-07-20 23:26:53,634 Epoch[71] Batch [1320]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077407,	
2017-07-20 23:26:58,351 Epoch[71] Batch [1330]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.077415,	
2017-07-20 23:27:03,216 Epoch[71] Batch [1340]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077431,	
2017-07-20 23:27:07,948 Epoch[71] Batch [1350]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077408,	
2017-07-20 23:27:12,611 Epoch[71] Batch [1360]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.077392,	
2017-07-20 23:27:17,631 Epoch[71] Batch [1370]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.077407,	
2017-07-20 23:27:22,974 Epoch[71] Batch [1380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.077372,	
2017-07-20 23:27:28,400 Epoch[71] Batch [1390]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.077382,	
2017-07-20 23:27:33,311 Epoch[71] Batch [1400]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.077420,	
2017-07-20 23:27:38,469 Epoch[71] Batch [1410]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.077414,	
2017-07-20 23:27:43,291 Epoch[71] Batch [1420]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077422,	
2017-07-20 23:27:48,334 Epoch[71] Batch [1430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077378,	
2017-07-20 23:27:53,397 Epoch[71] Batch [1440]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.077400,	
2017-07-20 23:27:58,297 Epoch[71] Batch [1450]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.077385,	
2017-07-20 23:28:02,882 Epoch[71] Batch [1460]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.077367,	
2017-07-20 23:28:07,796 Epoch[71] Batch [1470]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.077403,	
2017-07-20 23:28:12,566 Epoch[71] Batch [1480]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.077420,	
2017-07-20 23:28:15,396 Epoch[71] Train-FCNLogLoss=0.077428
2017-07-20 23:28:15,396 Epoch[71] Time cost=720.439
2017-07-20 23:28:16,466 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0072.params"
2017-07-20 23:28:19,963 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0072.states"
2017-07-20 23:28:25,530 Epoch[72] Batch [10]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.076212,	
2017-07-20 23:28:30,355 Epoch[72] Batch [20]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.076449,	
2017-07-20 23:28:35,095 Epoch[72] Batch [30]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.077849,	
2017-07-20 23:28:39,758 Epoch[72] Batch [40]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.077237,	
2017-07-20 23:28:44,519 Epoch[72] Batch [50]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078200,	
2017-07-20 23:28:49,178 Epoch[72] Batch [60]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077096,	
2017-07-20 23:28:53,726 Epoch[72] Batch [70]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.078994,	
2017-07-20 23:28:58,879 Epoch[72] Batch [80]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.077816,	
2017-07-20 23:29:03,807 Epoch[72] Batch [90]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077625,	
2017-07-20 23:29:08,357 Epoch[72] Batch [100]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.077867,	
2017-07-20 23:29:12,719 Epoch[72] Batch [110]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.077502,	
2017-07-20 23:29:17,571 Epoch[72] Batch [120]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.076958,	
2017-07-20 23:29:22,267 Epoch[72] Batch [130]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.077224,	
2017-07-20 23:29:27,327 Epoch[72] Batch [140]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.076946,	
2017-07-20 23:29:32,563 Epoch[72] Batch [150]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.076929,	
2017-07-20 23:29:37,058 Epoch[72] Batch [160]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.076893,	
2017-07-20 23:29:41,653 Epoch[72] Batch [170]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.076828,	
2017-07-20 23:29:46,356 Epoch[72] Batch [180]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.076805,	
2017-07-20 23:29:50,962 Epoch[72] Batch [190]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.077040,	
2017-07-20 23:29:55,714 Epoch[72] Batch [200]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.076907,	
2017-07-20 23:30:00,315 Epoch[72] Batch [210]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077016,	
2017-07-20 23:30:04,914 Epoch[72] Batch [220]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077085,	
2017-07-20 23:30:09,953 Epoch[72] Batch [230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.077227,	
2017-07-20 23:30:14,756 Epoch[72] Batch [240]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.077015,	
2017-07-20 23:30:19,991 Epoch[72] Batch [250]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.076478,	
2017-07-20 23:30:24,944 Epoch[72] Batch [260]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.076862,	
2017-07-20 23:30:29,930 Epoch[72] Batch [270]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.076893,	
2017-07-20 23:30:34,596 Epoch[72] Batch [280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.076981,	
2017-07-20 23:30:39,309 Epoch[72] Batch [290]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076934,	
2017-07-20 23:30:44,458 Epoch[72] Batch [300]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.076989,	
2017-07-20 23:30:49,341 Epoch[72] Batch [310]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076905,	
2017-07-20 23:30:54,471 Epoch[72] Batch [320]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.076811,	
2017-07-20 23:30:59,134 Epoch[72] Batch [330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.076851,	
2017-07-20 23:31:04,140 Epoch[72] Batch [340]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.076949,	
2017-07-20 23:31:08,956 Epoch[72] Batch [350]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077039,	
2017-07-20 23:31:13,777 Epoch[72] Batch [360]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077068,	
2017-07-20 23:31:19,044 Epoch[72] Batch [370]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.076980,	
2017-07-20 23:31:24,151 Epoch[72] Batch [380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.077206,	
2017-07-20 23:31:28,794 Epoch[72] Batch [390]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.077309,	
2017-07-20 23:31:33,528 Epoch[72] Batch [400]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077268,	
2017-07-20 23:31:38,769 Epoch[72] Batch [410]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.077198,	
2017-07-20 23:31:43,436 Epoch[72] Batch [420]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.077060,	
2017-07-20 23:31:48,075 Epoch[72] Batch [430]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.076959,	
2017-07-20 23:31:52,802 Epoch[72] Batch [440]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.076879,	
2017-07-20 23:31:57,730 Epoch[72] Batch [450]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077149,	
2017-07-20 23:32:02,399 Epoch[72] Batch [460]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.077183,	
2017-07-20 23:32:07,613 Epoch[72] Batch [470]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.077030,	
2017-07-20 23:32:12,331 Epoch[72] Batch [480]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.077020,	
2017-07-20 23:32:17,411 Epoch[72] Batch [490]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.077095,	
2017-07-20 23:32:22,251 Epoch[72] Batch [500]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.076840,	
2017-07-20 23:32:27,314 Epoch[72] Batch [510]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.076794,	
2017-07-20 23:32:31,986 Epoch[72] Batch [520]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076903,	
2017-07-20 23:32:36,775 Epoch[72] Batch [530]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.076879,	
2017-07-20 23:32:41,783 Epoch[72] Batch [540]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.076905,	
2017-07-20 23:32:46,560 Epoch[72] Batch [550]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.076839,	
2017-07-20 23:32:51,514 Epoch[72] Batch [560]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.076921,	
2017-07-20 23:32:56,558 Epoch[72] Batch [570]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.076865,	
2017-07-20 23:33:01,417 Epoch[72] Batch [580]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077006,	
2017-07-20 23:33:06,794 Epoch[72] Batch [590]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.076979,	
2017-07-20 23:33:12,366 Epoch[72] Batch [600]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.077025,	
2017-07-20 23:33:17,038 Epoch[72] Batch [610]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076989,	
2017-07-20 23:33:21,847 Epoch[72] Batch [620]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.077023,	
2017-07-20 23:33:26,447 Epoch[72] Batch [630]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.076973,	
2017-07-20 23:33:31,057 Epoch[72] Batch [640]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076916,	
2017-07-20 23:33:35,967 Epoch[72] Batch [650]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.076966,	
2017-07-20 23:33:40,715 Epoch[72] Batch [660]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.076994,	
2017-07-20 23:33:45,660 Epoch[72] Batch [670]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.076977,	
2017-07-20 23:33:50,795 Epoch[72] Batch [680]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.076874,	
2017-07-20 23:34:01,697 Epoch[72] Batch [690]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.077050,	
2017-07-20 23:34:09,784 Epoch[72] Batch [700]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.077111,	
2017-07-20 23:34:15,228 Epoch[72] Batch [710]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.077240,	
2017-07-20 23:34:20,101 Epoch[72] Batch [720]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.077259,	
2017-07-20 23:34:24,758 Epoch[72] Batch [730]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077218,	
2017-07-20 23:34:29,923 Epoch[72] Batch [740]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.077167,	
2017-07-20 23:34:34,773 Epoch[72] Batch [750]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.077319,	
2017-07-20 23:34:39,776 Epoch[72] Batch [760]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.077350,	
2017-07-20 23:34:44,565 Epoch[72] Batch [770]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077396,	
2017-07-20 23:34:49,341 Epoch[72] Batch [780]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.077325,	
2017-07-20 23:34:53,971 Epoch[72] Batch [790]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.077297,	
2017-07-20 23:34:59,152 Epoch[72] Batch [800]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.077283,	
2017-07-20 23:35:04,273 Epoch[72] Batch [810]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077207,	
2017-07-20 23:35:09,002 Epoch[72] Batch [820]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.077252,	
2017-07-20 23:35:14,270 Epoch[72] Batch [830]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.077292,	
2017-07-20 23:35:19,339 Epoch[72] Batch [840]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.077170,	
2017-07-20 23:35:24,147 Epoch[72] Batch [850]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.077210,	
2017-07-20 23:35:28,968 Epoch[72] Batch [860]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077173,	
2017-07-20 23:35:33,842 Epoch[72] Batch [870]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.077195,	
2017-07-20 23:35:38,601 Epoch[72] Batch [880]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.077206,	
2017-07-20 23:35:43,414 Epoch[72] Batch [890]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077291,	
2017-07-20 23:35:48,240 Epoch[72] Batch [900]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077300,	
2017-07-20 23:35:52,854 Epoch[72] Batch [910]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.077223,	
2017-07-20 23:35:57,619 Epoch[72] Batch [920]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077168,	
2017-07-20 23:36:02,214 Epoch[72] Batch [930]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077175,	
2017-07-20 23:36:07,358 Epoch[72] Batch [940]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.077197,	
2017-07-20 23:36:11,770 Epoch[72] Batch [950]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.077218,	
2017-07-20 23:36:16,536 Epoch[72] Batch [960]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.077137,	
2017-07-20 23:36:21,361 Epoch[72] Batch [970]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.077151,	
2017-07-20 23:36:26,171 Epoch[72] Batch [980]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.077192,	
2017-07-20 23:36:30,778 Epoch[72] Batch [990]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.077217,	
2017-07-20 23:36:35,423 Epoch[72] Batch [1000]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.077274,	
2017-07-20 23:36:39,995 Epoch[72] Batch [1010]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.077285,	
2017-07-20 23:36:44,804 Epoch[72] Batch [1020]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.077269,	
2017-07-20 23:36:49,486 Epoch[72] Batch [1030]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.077258,	
2017-07-20 23:36:54,016 Epoch[72] Batch [1040]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.077188,	
2017-07-20 23:36:58,999 Epoch[72] Batch [1050]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.077172,	
2017-07-20 23:37:03,656 Epoch[72] Batch [1060]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077243,	
2017-07-20 23:37:08,399 Epoch[72] Batch [1070]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077270,	
2017-07-20 23:37:13,180 Epoch[72] Batch [1080]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.077316,	
2017-07-20 23:37:18,141 Epoch[72] Batch [1090]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.077283,	
2017-07-20 23:37:22,963 Epoch[72] Batch [1100]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077215,	
2017-07-20 23:37:27,587 Epoch[72] Batch [1110]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.077215,	
2017-07-20 23:37:32,425 Epoch[72] Batch [1120]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.077210,	
2017-07-20 23:37:37,593 Epoch[72] Batch [1130]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.077248,	
2017-07-20 23:37:42,152 Epoch[72] Batch [1140]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.077186,	
2017-07-20 23:37:46,978 Epoch[72] Batch [1150]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.077213,	
2017-07-20 23:37:51,655 Epoch[72] Batch [1160]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077251,	
2017-07-20 23:37:56,225 Epoch[72] Batch [1170]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.077262,	
2017-07-20 23:38:01,165 Epoch[72] Batch [1180]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.077219,	
2017-07-20 23:38:05,980 Epoch[72] Batch [1190]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077225,	
2017-07-20 23:38:10,863 Epoch[72] Batch [1200]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077304,	
2017-07-20 23:38:15,656 Epoch[72] Batch [1210]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.077258,	
2017-07-20 23:38:20,383 Epoch[72] Batch [1220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.077297,	
2017-07-20 23:38:25,263 Epoch[72] Batch [1230]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.077311,	
2017-07-20 23:38:30,631 Epoch[72] Batch [1240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.077272,	
2017-07-20 23:38:35,336 Epoch[72] Batch [1250]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077292,	
2017-07-20 23:38:40,289 Epoch[72] Batch [1260]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.077292,	
2017-07-20 23:38:45,179 Epoch[72] Batch [1270]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.077286,	
2017-07-20 23:38:50,389 Epoch[72] Batch [1280]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.077363,	
2017-07-20 23:38:55,054 Epoch[72] Batch [1290]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.077409,	
2017-07-20 23:38:59,586 Epoch[72] Batch [1300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.077381,	
2017-07-20 23:39:04,500 Epoch[72] Batch [1310]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.077363,	
2017-07-20 23:39:08,998 Epoch[72] Batch [1320]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.077346,	
2017-07-20 23:39:14,180 Epoch[72] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.077362,	
2017-07-20 23:39:19,167 Epoch[72] Batch [1340]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077390,	
2017-07-20 23:39:24,804 Epoch[72] Batch [1350]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.077389,	
2017-07-20 23:39:30,231 Epoch[72] Batch [1360]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.077378,	
2017-07-20 23:39:35,523 Epoch[72] Batch [1370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.077337,	
2017-07-20 23:39:41,125 Epoch[72] Batch [1380]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.077339,	
2017-07-20 23:39:45,503 Epoch[72] Batch [1390]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.077312,	
2017-07-20 23:39:50,842 Epoch[72] Batch [1400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.077275,	
2017-07-20 23:39:55,911 Epoch[72] Batch [1410]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.077256,	
2017-07-20 23:40:01,037 Epoch[72] Batch [1420]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077210,	
2017-07-20 23:40:05,577 Epoch[72] Batch [1430]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.077237,	
2017-07-20 23:40:10,222 Epoch[72] Batch [1440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.077219,	
2017-07-20 23:40:15,341 Epoch[72] Batch [1450]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077216,	
2017-07-20 23:40:20,455 Epoch[72] Batch [1460]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.077181,	
2017-07-20 23:40:25,520 Epoch[72] Batch [1470]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.077178,	
2017-07-20 23:40:30,446 Epoch[72] Batch [1480]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077183,	
2017-07-20 23:40:33,421 Epoch[72] Train-FCNLogLoss=0.077211
2017-07-20 23:40:33,421 Epoch[72] Time cost=733.458
2017-07-20 23:40:34,393 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0073.params"
2017-07-20 23:40:38,340 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0073.states"
2017-07-20 23:40:45,005 Epoch[73] Batch [10]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.074039,	
2017-07-20 23:40:50,670 Epoch[73] Batch [20]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.077908,	
2017-07-20 23:40:56,241 Epoch[73] Batch [30]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.077703,	
2017-07-20 23:41:01,776 Epoch[73] Batch [40]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.077053,	
2017-07-20 23:41:07,227 Epoch[73] Batch [50]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.077346,	
2017-07-20 23:41:12,664 Epoch[73] Batch [60]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.076657,	
2017-07-20 23:41:17,710 Epoch[73] Batch [70]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.076921,	
2017-07-20 23:41:23,721 Epoch[73] Batch [80]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.077139,	
2017-07-20 23:41:29,426 Epoch[73] Batch [90]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.076614,	
2017-07-20 23:41:35,078 Epoch[73] Batch [100]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.076366,	
2017-07-20 23:41:40,516 Epoch[73] Batch [110]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.076178,	
2017-07-20 23:41:45,286 Epoch[73] Batch [120]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.076219,	
2017-07-20 23:41:51,036 Epoch[73] Batch [130]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.076021,	
2017-07-20 23:41:57,297 Epoch[73] Batch [140]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.076180,	
2017-07-20 23:42:02,688 Epoch[73] Batch [150]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.076450,	
2017-07-20 23:42:08,333 Epoch[73] Batch [160]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.077553,	
2017-07-20 23:42:14,558 Epoch[73] Batch [170]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.077413,	
2017-07-20 23:42:20,120 Epoch[73] Batch [180]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.077293,	
2017-07-20 23:42:25,914 Epoch[73] Batch [190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.077871,	
2017-07-20 23:42:32,335 Epoch[73] Batch [200]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.077511,	
2017-07-20 23:42:38,073 Epoch[73] Batch [210]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.077276,	
2017-07-20 23:42:43,494 Epoch[73] Batch [220]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.077294,	
2017-07-20 23:42:49,607 Epoch[73] Batch [230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.077324,	
2017-07-20 23:42:55,059 Epoch[73] Batch [240]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.077259,	
2017-07-20 23:43:01,056 Epoch[73] Batch [250]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.077162,	
2017-07-20 23:43:06,413 Epoch[73] Batch [260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.076961,	
2017-07-20 23:43:11,808 Epoch[73] Batch [270]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.077279,	
2017-07-20 23:43:17,801 Epoch[73] Batch [280]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.077562,	
2017-07-20 23:43:24,121 Epoch[73] Batch [290]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.077633,	
2017-07-20 23:43:30,055 Epoch[73] Batch [300]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.077586,	
2017-07-20 23:43:35,798 Epoch[73] Batch [310]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.077485,	
2017-07-20 23:43:42,197 Epoch[73] Batch [320]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.077601,	
2017-07-20 23:43:48,257 Epoch[73] Batch [330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.077445,	
2017-07-20 23:43:53,670 Epoch[73] Batch [340]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.077476,	
2017-07-20 23:43:59,049 Epoch[73] Batch [350]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.077436,	
2017-07-20 23:44:04,577 Epoch[73] Batch [360]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.077542,	
2017-07-20 23:44:10,647 Epoch[73] Batch [370]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.077416,	
2017-07-20 23:44:16,503 Epoch[73] Batch [380]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.077284,	
2017-07-20 23:44:22,260 Epoch[73] Batch [390]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.077428,	
2017-07-20 23:44:27,662 Epoch[73] Batch [400]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.077339,	
2017-07-20 23:44:33,855 Epoch[73] Batch [410]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.077313,	
2017-07-20 23:44:40,334 Epoch[73] Batch [420]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.077228,	
2017-07-20 23:44:46,999 Epoch[73] Batch [430]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.077222,	
2017-07-20 23:44:52,675 Epoch[73] Batch [440]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.077246,	
2017-07-20 23:44:57,907 Epoch[73] Batch [450]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.077101,	
2017-07-20 23:45:04,558 Epoch[73] Batch [460]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.077036,	
2017-07-20 23:45:11,963 Epoch[73] Batch [470]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.076845,	
2017-07-20 23:45:18,380 Epoch[73] Batch [480]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.076888,	
2017-07-20 23:45:24,027 Epoch[73] Batch [490]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.076783,	
2017-07-20 23:45:29,703 Epoch[73] Batch [500]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.076768,	
2017-07-20 23:45:35,289 Epoch[73] Batch [510]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.076748,	
2017-07-20 23:45:40,776 Epoch[73] Batch [520]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.076736,	
2017-07-20 23:45:46,498 Epoch[73] Batch [530]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.076605,	
2017-07-20 23:45:52,923 Epoch[73] Batch [540]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.076776,	
2017-07-20 23:45:57,903 Epoch[73] Batch [550]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.076771,	
2017-07-20 23:46:03,938 Epoch[73] Batch [560]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.076775,	
2017-07-20 23:46:09,687 Epoch[73] Batch [570]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.076704,	
2017-07-20 23:46:14,580 Epoch[73] Batch [580]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.076733,	
2017-07-20 23:46:20,870 Epoch[73] Batch [590]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.076721,	
2017-07-20 23:46:26,349 Epoch[73] Batch [600]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.076853,	
2017-07-20 23:46:31,494 Epoch[73] Batch [610]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.076853,	
2017-07-20 23:46:36,909 Epoch[73] Batch [620]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.076844,	
2017-07-20 23:46:42,351 Epoch[73] Batch [630]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.076870,	
2017-07-20 23:46:48,251 Epoch[73] Batch [640]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.076991,	
2017-07-20 23:46:53,793 Epoch[73] Batch [650]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.076983,	
2017-07-20 23:46:59,291 Epoch[73] Batch [660]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.076890,	
2017-07-20 23:47:05,140 Epoch[73] Batch [670]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.076911,	
2017-07-20 23:47:10,031 Epoch[73] Batch [680]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.076792,	
2017-07-20 23:47:15,574 Epoch[73] Batch [690]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.076810,	
2017-07-20 23:47:21,873 Epoch[73] Batch [700]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.076770,	
2017-07-20 23:47:27,548 Epoch[73] Batch [710]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.076693,	
2017-07-20 23:47:33,242 Epoch[73] Batch [720]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.076680,	
2017-07-20 23:47:38,899 Epoch[73] Batch [730]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.076635,	
2017-07-20 23:47:43,965 Epoch[73] Batch [740]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.076705,	
2017-07-20 23:47:49,153 Epoch[73] Batch [750]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.076838,	
2017-07-20 23:47:54,761 Epoch[73] Batch [760]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.076847,	
2017-07-20 23:48:00,707 Epoch[73] Batch [770]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.076855,	
2017-07-20 23:48:06,361 Epoch[73] Batch [780]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.076844,	
2017-07-20 23:48:12,339 Epoch[73] Batch [790]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.076758,	
2017-07-20 23:48:18,291 Epoch[73] Batch [800]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.076769,	
2017-07-20 23:48:23,817 Epoch[73] Batch [810]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.076767,	
2017-07-20 23:48:29,494 Epoch[73] Batch [820]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.076826,	
2017-07-20 23:48:35,540 Epoch[73] Batch [830]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.076731,	
2017-07-20 23:48:40,729 Epoch[73] Batch [840]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.076757,	
2017-07-20 23:48:46,386 Epoch[73] Batch [850]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.076710,	
2017-07-20 23:48:51,625 Epoch[73] Batch [860]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.076657,	
2017-07-20 23:48:57,664 Epoch[73] Batch [870]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.076693,	
2017-07-20 23:49:03,365 Epoch[73] Batch [880]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.076725,	
2017-07-20 23:49:08,931 Epoch[73] Batch [890]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.076735,	
2017-07-20 23:49:14,141 Epoch[73] Batch [900]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.076682,	
2017-07-20 23:49:19,417 Epoch[73] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.076759,	
2017-07-20 23:49:25,556 Epoch[73] Batch [920]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.076685,	
2017-07-20 23:49:31,399 Epoch[73] Batch [930]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.076792,	
2017-07-20 23:49:36,273 Epoch[73] Batch [940]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.076785,	
2017-07-20 23:49:41,973 Epoch[73] Batch [950]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.076723,	
2017-07-20 23:49:47,052 Epoch[73] Batch [960]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.076816,	
2017-07-20 23:49:52,481 Epoch[73] Batch [970]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.076742,	
2017-07-20 23:49:57,518 Epoch[73] Batch [980]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.076794,	
2017-07-20 23:50:02,385 Epoch[73] Batch [990]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.076823,	
2017-07-20 23:50:07,960 Epoch[73] Batch [1000]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.076745,	
2017-07-20 23:50:13,563 Epoch[73] Batch [1010]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.076770,	
2017-07-20 23:50:19,526 Epoch[73] Batch [1020]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.076769,	
2017-07-20 23:50:25,963 Epoch[73] Batch [1030]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.076767,	
2017-07-20 23:50:31,605 Epoch[73] Batch [1040]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.076797,	
2017-07-20 23:50:36,880 Epoch[73] Batch [1050]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.076763,	
2017-07-20 23:50:42,598 Epoch[73] Batch [1060]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.076764,	
2017-07-20 23:50:47,669 Epoch[73] Batch [1070]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.076727,	
2017-07-20 23:50:53,501 Epoch[73] Batch [1080]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.076717,	
2017-07-20 23:50:59,595 Epoch[73] Batch [1090]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.076750,	
2017-07-20 23:51:05,245 Epoch[73] Batch [1100]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.076756,	
2017-07-20 23:51:11,342 Epoch[73] Batch [1110]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.076796,	
2017-07-20 23:51:17,042 Epoch[73] Batch [1120]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.076772,	
2017-07-20 23:51:22,628 Epoch[73] Batch [1130]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.076787,	
2017-07-20 23:51:27,576 Epoch[73] Batch [1140]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.076755,	
2017-07-20 23:51:32,760 Epoch[73] Batch [1150]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.076714,	
2017-07-20 23:51:38,332 Epoch[73] Batch [1160]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.076754,	
2017-07-20 23:51:43,887 Epoch[73] Batch [1170]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.076805,	
2017-07-20 23:51:49,568 Epoch[73] Batch [1180]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.076821,	
2017-07-20 23:51:55,737 Epoch[73] Batch [1190]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.076823,	
2017-07-20 23:52:01,210 Epoch[73] Batch [1200]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.076825,	
2017-07-20 23:52:06,411 Epoch[73] Batch [1210]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.076789,	
2017-07-20 23:52:12,513 Epoch[73] Batch [1220]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.076794,	
2017-07-20 23:52:18,116 Epoch[73] Batch [1230]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.076924,	
2017-07-20 23:52:23,545 Epoch[73] Batch [1240]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.076893,	
2017-07-20 23:52:29,625 Epoch[73] Batch [1250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.076895,	
2017-07-20 23:52:35,202 Epoch[73] Batch [1260]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.076901,	
2017-07-20 23:52:41,359 Epoch[73] Batch [1270]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.076919,	
2017-07-20 23:52:46,815 Epoch[73] Batch [1280]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.076979,	
2017-07-20 23:52:52,298 Epoch[73] Batch [1290]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.077078,	
2017-07-20 23:52:57,511 Epoch[73] Batch [1300]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.077114,	
2017-07-20 23:53:03,101 Epoch[73] Batch [1310]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.077084,	
2017-07-20 23:53:09,234 Epoch[73] Batch [1320]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.077069,	
2017-07-20 23:53:14,939 Epoch[73] Batch [1330]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.076990,	
2017-07-20 23:53:20,648 Epoch[73] Batch [1340]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.076994,	
2017-07-20 23:53:26,457 Epoch[73] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.077008,	
2017-07-20 23:53:32,573 Epoch[73] Batch [1360]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.077020,	
2017-07-20 23:53:38,600 Epoch[73] Batch [1370]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.076978,	
2017-07-20 23:53:44,247 Epoch[73] Batch [1380]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.077005,	
2017-07-20 23:53:50,363 Epoch[73] Batch [1390]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.076992,	
2017-07-20 23:53:56,228 Epoch[73] Batch [1400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.077078,	
2017-07-20 23:54:02,348 Epoch[73] Batch [1410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.077056,	
2017-07-20 23:54:08,135 Epoch[73] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.077051,	
2017-07-20 23:54:14,304 Epoch[73] Batch [1430]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.077091,	
2017-07-20 23:54:19,918 Epoch[73] Batch [1440]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.077104,	
2017-07-20 23:54:25,220 Epoch[73] Batch [1450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.077115,	
2017-07-20 23:54:30,658 Epoch[73] Batch [1460]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.077139,	
2017-07-20 23:54:36,344 Epoch[73] Batch [1470]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.077081,	
2017-07-20 23:54:41,607 Epoch[73] Batch [1480]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.077054,	
2017-07-20 23:54:44,463 Epoch[73] Train-FCNLogLoss=0.077064
2017-07-20 23:54:44,464 Epoch[73] Time cost=846.124
2017-07-20 23:54:46,083 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0074.params"
2017-07-20 23:54:50,490 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0074.states"
2017-07-20 23:54:57,370 Epoch[74] Batch [10]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.079301,	
2017-07-20 23:55:02,854 Epoch[74] Batch [20]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.073757,	
2017-07-20 23:55:08,797 Epoch[74] Batch [30]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.077053,	
2017-07-20 23:55:14,773 Epoch[74] Batch [40]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.076179,	
2017-07-20 23:55:19,940 Epoch[74] Batch [50]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.075862,	
2017-07-20 23:55:24,933 Epoch[74] Batch [60]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075840,	
2017-07-20 23:55:29,738 Epoch[74] Batch [70]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.074512,	
2017-07-20 23:55:34,898 Epoch[74] Batch [80]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.074989,	
2017-07-20 23:55:40,052 Epoch[74] Batch [90]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.075037,	
2017-07-20 23:55:45,258 Epoch[74] Batch [100]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.075589,	
2017-07-20 23:55:50,474 Epoch[74] Batch [110]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075701,	
2017-07-20 23:55:55,514 Epoch[74] Batch [120]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075675,	
2017-07-20 23:56:01,071 Epoch[74] Batch [130]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.075160,	
2017-07-20 23:56:05,790 Epoch[74] Batch [140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075519,	
2017-07-20 23:56:11,250 Epoch[74] Batch [150]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.075639,	
2017-07-20 23:56:16,610 Epoch[74] Batch [160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.076294,	
2017-07-20 23:56:21,377 Epoch[74] Batch [170]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.076086,	
2017-07-20 23:56:26,640 Epoch[74] Batch [180]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.076524,	
2017-07-20 23:56:31,826 Epoch[74] Batch [190]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.076673,	
2017-07-20 23:56:37,031 Epoch[74] Batch [200]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.076827,	
2017-07-20 23:56:41,923 Epoch[74] Batch [210]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.076717,	
2017-07-20 23:56:46,777 Epoch[74] Batch [220]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.076630,	
2017-07-20 23:56:51,756 Epoch[74] Batch [230]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.077167,	
2017-07-20 23:56:57,028 Epoch[74] Batch [240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.076805,	
2017-07-20 23:57:01,893 Epoch[74] Batch [250]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077009,	
2017-07-20 23:57:06,714 Epoch[74] Batch [260]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.076817,	
2017-07-20 23:57:11,732 Epoch[74] Batch [270]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.076920,	
2017-07-20 23:57:16,494 Epoch[74] Batch [280]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077035,	
2017-07-20 23:57:20,935 Epoch[74] Batch [290]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.076877,	
2017-07-20 23:57:26,103 Epoch[74] Batch [300]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.076701,	
2017-07-20 23:57:31,082 Epoch[74] Batch [310]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.076579,	
2017-07-20 23:57:36,420 Epoch[74] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.076755,	
2017-07-20 23:57:41,886 Epoch[74] Batch [330]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.076625,	
2017-07-20 23:57:46,912 Epoch[74] Batch [340]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.076919,	
2017-07-20 23:57:51,892 Epoch[74] Batch [350]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.077144,	
2017-07-20 23:57:57,058 Epoch[74] Batch [360]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.077356,	
2017-07-20 23:58:02,209 Epoch[74] Batch [370]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.077432,	
2017-07-20 23:58:07,126 Epoch[74] Batch [380]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.077365,	
2017-07-20 23:58:12,187 Epoch[74] Batch [390]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.077405,	
2017-07-20 23:58:17,859 Epoch[74] Batch [400]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.077493,	
2017-07-20 23:58:22,879 Epoch[74] Batch [410]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.077317,	
2017-07-20 23:58:27,736 Epoch[74] Batch [420]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077343,	
2017-07-20 23:58:32,634 Epoch[74] Batch [430]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.077327,	
2017-07-20 23:58:37,517 Epoch[74] Batch [440]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.077164,	
2017-07-20 23:58:42,250 Epoch[74] Batch [450]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077089,	
2017-07-20 23:58:47,504 Epoch[74] Batch [460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.077158,	
2017-07-20 23:58:52,463 Epoch[74] Batch [470]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.077162,	
2017-07-20 23:58:57,687 Epoch[74] Batch [480]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.077150,	
2017-07-20 23:59:03,068 Epoch[74] Batch [490]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.077215,	
2017-07-20 23:59:08,331 Epoch[74] Batch [500]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.077297,	
2017-07-20 23:59:13,156 Epoch[74] Batch [510]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.077291,	
2017-07-20 23:59:17,832 Epoch[74] Batch [520]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077553,	
2017-07-20 23:59:22,616 Epoch[74] Batch [530]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.077558,	
2017-07-20 23:59:27,557 Epoch[74] Batch [540]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.077613,	
2017-07-20 23:59:32,626 Epoch[74] Batch [550]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.077663,	
2017-07-20 23:59:37,753 Epoch[74] Batch [560]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.077615,	
2017-07-20 23:59:42,759 Epoch[74] Batch [570]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.077588,	
2017-07-20 23:59:47,929 Epoch[74] Batch [580]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.077718,	
2017-07-20 23:59:52,788 Epoch[74] Batch [590]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077646,	
2017-07-20 23:59:58,013 Epoch[74] Batch [600]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.077500,	
2017-07-21 00:00:03,550 Epoch[74] Batch [610]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.077546,	
2017-07-21 00:00:08,589 Epoch[74] Batch [620]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.077613,	
2017-07-21 00:00:13,484 Epoch[74] Batch [630]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.077637,	
2017-07-21 00:00:18,189 Epoch[74] Batch [640]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077649,	
2017-07-21 00:00:23,034 Epoch[74] Batch [650]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.077617,	
2017-07-21 00:00:27,783 Epoch[74] Batch [660]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.077539,	
2017-07-21 00:00:32,569 Epoch[74] Batch [670]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.077474,	
2017-07-21 00:00:37,450 Epoch[74] Batch [680]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.077442,	
2017-07-21 00:00:43,285 Epoch[74] Batch [690]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.077518,	
2017-07-21 00:00:47,993 Epoch[74] Batch [700]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077556,	
2017-07-21 00:00:53,138 Epoch[74] Batch [710]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.077651,	
2017-07-21 00:00:57,843 Epoch[74] Batch [720]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077683,	
2017-07-21 00:01:02,542 Epoch[74] Batch [730]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.077617,	
2017-07-21 00:01:07,511 Epoch[74] Batch [740]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077628,	
2017-07-21 00:01:12,373 Epoch[74] Batch [750]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077656,	
2017-07-21 00:01:17,380 Epoch[74] Batch [760]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.077590,	
2017-07-21 00:01:22,391 Epoch[74] Batch [770]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.077557,	
2017-07-21 00:01:27,263 Epoch[74] Batch [780]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.077525,	
2017-07-21 00:01:32,355 Epoch[74] Batch [790]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077468,	
2017-07-21 00:01:37,392 Epoch[74] Batch [800]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.077531,	
2017-07-21 00:01:42,371 Epoch[74] Batch [810]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.077523,	
2017-07-21 00:01:46,976 Epoch[74] Batch [820]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077533,	
2017-07-21 00:01:51,943 Epoch[74] Batch [830]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077604,	
2017-07-21 00:01:57,495 Epoch[74] Batch [840]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.077460,	
2017-07-21 00:02:02,591 Epoch[74] Batch [850]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.077378,	
2017-07-21 00:02:07,263 Epoch[74] Batch [860]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.077341,	
2017-07-21 00:02:11,997 Epoch[74] Batch [870]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077375,	
2017-07-21 00:02:16,857 Epoch[74] Batch [880]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077312,	
2017-07-21 00:02:21,687 Epoch[74] Batch [890]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.077339,	
2017-07-21 00:02:26,554 Epoch[74] Batch [900]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077362,	
2017-07-21 00:02:31,079 Epoch[74] Batch [910]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.077393,	
2017-07-21 00:02:36,443 Epoch[74] Batch [920]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.077317,	
2017-07-21 00:02:41,060 Epoch[74] Batch [930]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.077314,	
2017-07-21 00:02:46,122 Epoch[74] Batch [940]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.077358,	
2017-07-21 00:02:51,534 Epoch[74] Batch [950]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.077344,	
2017-07-21 00:02:56,471 Epoch[74] Batch [960]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.077329,	
2017-07-21 00:03:01,346 Epoch[74] Batch [970]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.077344,	
2017-07-21 00:03:06,151 Epoch[74] Batch [980]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.077341,	
2017-07-21 00:03:11,058 Epoch[74] Batch [990]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.077310,	
2017-07-21 00:03:15,938 Epoch[74] Batch [1000]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.077246,	
2017-07-21 00:03:21,268 Epoch[74] Batch [1010]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.077261,	
2017-07-21 00:03:26,514 Epoch[74] Batch [1020]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.077255,	
2017-07-21 00:03:31,700 Epoch[74] Batch [1030]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.077200,	
2017-07-21 00:03:36,600 Epoch[74] Batch [1040]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.077198,	
2017-07-21 00:03:41,643 Epoch[74] Batch [1050]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077137,	
2017-07-21 00:03:46,557 Epoch[74] Batch [1060]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.077151,	
2017-07-21 00:03:51,097 Epoch[74] Batch [1070]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.077126,	
2017-07-21 00:03:56,087 Epoch[74] Batch [1080]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077138,	
2017-07-21 00:04:01,270 Epoch[74] Batch [1090]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.077206,	
2017-07-21 00:04:06,247 Epoch[74] Batch [1100]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.077327,	
2017-07-21 00:04:11,278 Epoch[74] Batch [1110]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077371,	
2017-07-21 00:04:16,483 Epoch[74] Batch [1120]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.077373,	
2017-07-21 00:04:20,962 Epoch[74] Batch [1130]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.077318,	
2017-07-21 00:04:26,140 Epoch[74] Batch [1140]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.077319,	
2017-07-21 00:04:31,745 Epoch[74] Batch [1150]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.077309,	
2017-07-21 00:04:36,990 Epoch[74] Batch [1160]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.077363,	
2017-07-21 00:04:42,679 Epoch[74] Batch [1170]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.077456,	
2017-07-21 00:04:47,644 Epoch[74] Batch [1180]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.077452,	
2017-07-21 00:04:52,744 Epoch[74] Batch [1190]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.077467,	
2017-07-21 00:04:57,329 Epoch[74] Batch [1200]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.077430,	
2017-07-21 00:05:02,481 Epoch[74] Batch [1210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.077453,	
2017-07-21 00:05:07,576 Epoch[74] Batch [1220]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.077394,	
2017-07-21 00:05:12,530 Epoch[74] Batch [1230]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.077405,	
2017-07-21 00:05:17,545 Epoch[74] Batch [1240]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.077356,	
2017-07-21 00:05:23,132 Epoch[74] Batch [1250]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.077307,	
2017-07-21 00:05:28,154 Epoch[74] Batch [1260]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.077348,	
2017-07-21 00:05:33,312 Epoch[74] Batch [1270]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.077365,	
2017-07-21 00:05:38,556 Epoch[74] Batch [1280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.077380,	
2017-07-21 00:05:43,985 Epoch[74] Batch [1290]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.077323,	
2017-07-21 00:05:48,902 Epoch[74] Batch [1300]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.077357,	
2017-07-21 00:05:54,068 Epoch[74] Batch [1310]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.077315,	
2017-07-21 00:05:59,074 Epoch[74] Batch [1320]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.077357,	
2017-07-21 00:06:04,298 Epoch[74] Batch [1330]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.077372,	
2017-07-21 00:06:09,146 Epoch[74] Batch [1340]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.077348,	
2017-07-21 00:06:14,100 Epoch[74] Batch [1350]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.077331,	
2017-07-21 00:06:19,328 Epoch[74] Batch [1360]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.077326,	
2017-07-21 00:06:24,495 Epoch[74] Batch [1370]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.077384,	
2017-07-21 00:06:29,573 Epoch[74] Batch [1380]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077351,	
2017-07-21 00:06:34,561 Epoch[74] Batch [1390]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077330,	
2017-07-21 00:06:39,969 Epoch[74] Batch [1400]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.077299,	
2017-07-21 00:06:45,073 Epoch[74] Batch [1410]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.077288,	
2017-07-21 00:06:50,265 Epoch[74] Batch [1420]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.077357,	
2017-07-21 00:06:55,771 Epoch[74] Batch [1430]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.077293,	
2017-07-21 00:07:00,720 Epoch[74] Batch [1440]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.077313,	
2017-07-21 00:07:05,841 Epoch[74] Batch [1450]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077254,	
2017-07-21 00:07:10,940 Epoch[74] Batch [1460]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.077284,	
2017-07-21 00:07:15,892 Epoch[74] Batch [1470]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.077259,	
2017-07-21 00:07:21,151 Epoch[74] Batch [1480]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.077255,	
2017-07-21 00:07:24,218 Epoch[74] Train-FCNLogLoss=0.077242
2017-07-21 00:07:24,218 Epoch[74] Time cost=753.728
2017-07-21 00:07:25,133 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0075.params"
2017-07-21 00:07:29,073 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0075.states"
2017-07-21 00:07:35,975 Epoch[75] Batch [10]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.071421,	
2017-07-21 00:07:42,142 Epoch[75] Batch [20]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.077513,	
2017-07-21 00:07:48,506 Epoch[75] Batch [30]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.078114,	
2017-07-21 00:07:54,548 Epoch[75] Batch [40]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.077902,	
2017-07-21 00:08:00,762 Epoch[75] Batch [50]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.078010,	
2017-07-21 00:08:06,495 Epoch[75] Batch [60]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.079639,	
2017-07-21 00:08:13,210 Epoch[75] Batch [70]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.080009,	
2017-07-21 00:08:18,667 Epoch[75] Batch [80]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.079138,	
2017-07-21 00:08:23,968 Epoch[75] Batch [90]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.079011,	
2017-07-21 00:08:29,221 Epoch[75] Batch [100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.079060,	
2017-07-21 00:08:34,133 Epoch[75] Batch [110]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.078480,	
2017-07-21 00:08:38,892 Epoch[75] Batch [120]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.078688,	
2017-07-21 00:08:44,513 Epoch[75] Batch [130]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.077995,	
2017-07-21 00:08:49,983 Epoch[75] Batch [140]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.078136,	
2017-07-21 00:08:55,530 Epoch[75] Batch [150]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.077426,	
2017-07-21 00:09:01,066 Epoch[75] Batch [160]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.077533,	
2017-07-21 00:09:06,559 Epoch[75] Batch [170]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.078220,	
2017-07-21 00:09:11,714 Epoch[75] Batch [180]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.078248,	
2017-07-21 00:09:16,805 Epoch[75] Batch [190]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.078409,	
2017-07-21 00:09:21,908 Epoch[75] Batch [200]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.078553,	
2017-07-21 00:09:26,981 Epoch[75] Batch [210]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.078390,	
2017-07-21 00:09:31,991 Epoch[75] Batch [220]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.078051,	
2017-07-21 00:09:36,902 Epoch[75] Batch [230]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.077862,	
2017-07-21 00:09:41,986 Epoch[75] Batch [240]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.077908,	
2017-07-21 00:09:46,952 Epoch[75] Batch [250]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077803,	
2017-07-21 00:09:52,278 Epoch[75] Batch [260]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.077719,	
2017-07-21 00:09:57,485 Epoch[75] Batch [270]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.077488,	
2017-07-21 00:10:02,475 Epoch[75] Batch [280]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077214,	
2017-07-21 00:10:07,462 Epoch[75] Batch [290]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077680,	
2017-07-21 00:10:12,765 Epoch[75] Batch [300]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.077788,	
2017-07-21 00:10:18,297 Epoch[75] Batch [310]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.077520,	
2017-07-21 00:10:23,980 Epoch[75] Batch [320]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.077334,	
2017-07-21 00:10:29,111 Epoch[75] Batch [330]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.077209,	
2017-07-21 00:10:34,939 Epoch[75] Batch [340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.077088,	
2017-07-21 00:10:39,986 Epoch[75] Batch [350]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077500,	
2017-07-21 00:10:45,072 Epoch[75] Batch [360]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077586,	
2017-07-21 00:10:50,221 Epoch[75] Batch [370]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.077648,	
2017-07-21 00:10:55,134 Epoch[75] Batch [380]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.077676,	
2017-07-21 00:11:00,188 Epoch[75] Batch [390]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.077803,	
2017-07-21 00:11:05,222 Epoch[75] Batch [400]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077616,	
2017-07-21 00:11:10,496 Epoch[75] Batch [410]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.077486,	
2017-07-21 00:11:16,045 Epoch[75] Batch [420]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.077395,	
2017-07-21 00:11:20,912 Epoch[75] Batch [430]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.077546,	
2017-07-21 00:11:25,990 Epoch[75] Batch [440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077457,	
2017-07-21 00:11:31,495 Epoch[75] Batch [450]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.077542,	
2017-07-21 00:11:36,524 Epoch[75] Batch [460]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077556,	
2017-07-21 00:11:41,444 Epoch[75] Batch [470]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.077639,	
2017-07-21 00:11:46,267 Epoch[75] Batch [480]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.077653,	
2017-07-21 00:11:51,462 Epoch[75] Batch [490]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.077670,	
2017-07-21 00:11:56,476 Epoch[75] Batch [500]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.077588,	
2017-07-21 00:12:01,712 Epoch[75] Batch [510]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.077587,	
2017-07-21 00:12:06,530 Epoch[75] Batch [520]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077549,	
2017-07-21 00:12:11,622 Epoch[75] Batch [530]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077377,	
2017-07-21 00:12:16,652 Epoch[75] Batch [540]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077387,	
2017-07-21 00:12:21,530 Epoch[75] Batch [550]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.077489,	
2017-07-21 00:12:26,951 Epoch[75] Batch [560]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.077528,	
2017-07-21 00:12:32,438 Epoch[75] Batch [570]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.077451,	
2017-07-21 00:12:37,895 Epoch[75] Batch [580]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.077607,	
2017-07-21 00:12:42,997 Epoch[75] Batch [590]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.077583,	
2017-07-21 00:12:47,757 Epoch[75] Batch [600]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.077708,	
2017-07-21 00:12:53,129 Epoch[75] Batch [610]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.077732,	
2017-07-21 00:12:58,220 Epoch[75] Batch [620]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077741,	
2017-07-21 00:13:03,071 Epoch[75] Batch [630]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.077772,	
2017-07-21 00:13:08,932 Epoch[75] Batch [640]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.077767,	
2017-07-21 00:13:14,143 Epoch[75] Batch [650]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.077806,	
2017-07-21 00:13:19,614 Epoch[75] Batch [660]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.077818,	
2017-07-21 00:13:24,758 Epoch[75] Batch [670]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.077816,	
2017-07-21 00:13:29,881 Epoch[75] Batch [680]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077851,	
2017-07-21 00:13:35,101 Epoch[75] Batch [690]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.077850,	
2017-07-21 00:13:40,505 Epoch[75] Batch [700]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.077734,	
2017-07-21 00:13:45,549 Epoch[75] Batch [710]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077834,	
2017-07-21 00:13:50,826 Epoch[75] Batch [720]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.077737,	
2017-07-21 00:13:55,873 Epoch[75] Batch [730]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077724,	
2017-07-21 00:14:01,302 Epoch[75] Batch [740]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.077666,	
2017-07-21 00:14:06,347 Epoch[75] Batch [750]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077753,	
2017-07-21 00:14:11,464 Epoch[75] Batch [760]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.077780,	
2017-07-21 00:14:16,764 Epoch[75] Batch [770]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.077838,	
2017-07-21 00:14:22,040 Epoch[75] Batch [780]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.077840,	
2017-07-21 00:14:27,737 Epoch[75] Batch [790]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.077755,	
2017-07-21 00:14:32,870 Epoch[75] Batch [800]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.077701,	
2017-07-21 00:14:38,591 Epoch[75] Batch [810]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.077616,	
2017-07-21 00:14:43,842 Epoch[75] Batch [820]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.077657,	
2017-07-21 00:14:49,411 Epoch[75] Batch [830]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.077512,	
2017-07-21 00:14:54,628 Epoch[75] Batch [840]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.077492,	
2017-07-21 00:14:59,594 Epoch[75] Batch [850]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.077504,	
2017-07-21 00:15:04,724 Epoch[75] Batch [860]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.077460,	
2017-07-21 00:15:09,887 Epoch[75] Batch [870]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.077437,	
2017-07-21 00:15:15,173 Epoch[75] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.077444,	
2017-07-21 00:15:20,916 Epoch[75] Batch [890]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.077528,	
2017-07-21 00:15:26,320 Epoch[75] Batch [900]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.077497,	
2017-07-21 00:15:31,581 Epoch[75] Batch [910]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.077414,	
2017-07-21 00:15:36,649 Epoch[75] Batch [920]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.077462,	
2017-07-21 00:15:41,835 Epoch[75] Batch [930]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.077408,	
2017-07-21 00:15:46,772 Epoch[75] Batch [940]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.077422,	
2017-07-21 00:15:52,066 Epoch[75] Batch [950]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.077376,	
2017-07-21 00:15:56,973 Epoch[75] Batch [960]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.077401,	
2017-07-21 00:16:02,197 Epoch[75] Batch [970]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.077440,	
2017-07-21 00:16:07,521 Epoch[75] Batch [980]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.077369,	
2017-07-21 00:16:13,091 Epoch[75] Batch [990]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.077340,	
2017-07-21 00:16:27,971 Epoch[75] Batch [1000]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.077408,	
2017-07-21 00:16:50,720 Epoch[75] Batch [1010]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.077448,	
2017-07-21 00:17:14,751 Epoch[75] Batch [1020]	Speed: 1.66 samples/sec	Train-FCNLogLoss=0.077394,	
2017-07-21 00:17:38,765 Epoch[75] Batch [1030]	Speed: 1.67 samples/sec	Train-FCNLogLoss=0.077345,	
2017-07-21 00:18:03,094 Epoch[75] Batch [1040]	Speed: 1.64 samples/sec	Train-FCNLogLoss=0.077346,	
2017-07-21 00:18:24,300 Epoch[75] Batch [1050]	Speed: 1.89 samples/sec	Train-FCNLogLoss=0.077297,	
2017-07-21 00:18:45,612 Epoch[75] Batch [1060]	Speed: 1.88 samples/sec	Train-FCNLogLoss=0.077283,	
2017-07-21 00:18:53,885 Epoch[75] Batch [1070]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.077308,	
2017-07-21 00:18:58,628 Epoch[75] Batch [1080]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077246,	
2017-07-21 00:19:03,622 Epoch[75] Batch [1090]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.077310,	
2017-07-21 00:19:08,702 Epoch[75] Batch [1100]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077352,	
2017-07-21 00:19:13,522 Epoch[75] Batch [1110]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077394,	
2017-07-21 00:19:18,338 Epoch[75] Batch [1120]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.077387,	
2017-07-21 00:19:23,091 Epoch[75] Batch [1130]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.077398,	
2017-07-21 00:19:27,796 Epoch[75] Batch [1140]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077414,	
2017-07-21 00:19:32,554 Epoch[75] Batch [1150]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.077357,	
2017-07-21 00:19:37,305 Epoch[75] Batch [1160]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.077407,	
2017-07-21 00:19:42,262 Epoch[75] Batch [1170]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.077455,	
2017-07-21 00:19:47,159 Epoch[75] Batch [1180]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.077457,	
2017-07-21 00:19:52,163 Epoch[75] Batch [1190]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.077397,	
2017-07-21 00:19:57,131 Epoch[75] Batch [1200]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077432,	
2017-07-21 00:20:02,246 Epoch[75] Batch [1210]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.077443,	
2017-07-21 00:20:06,951 Epoch[75] Batch [1220]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.077539,	
2017-07-21 00:20:11,567 Epoch[75] Batch [1230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.077496,	
2017-07-21 00:20:16,102 Epoch[75] Batch [1240]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.077453,	
2017-07-21 00:20:20,627 Epoch[75] Batch [1250]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.077436,	
2017-07-21 00:20:25,013 Epoch[75] Batch [1260]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.077465,	
2017-07-21 00:20:29,618 Epoch[75] Batch [1270]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077448,	
2017-07-21 00:20:34,248 Epoch[75] Batch [1280]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.077470,	
2017-07-21 00:20:38,634 Epoch[75] Batch [1290]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.077437,	
2017-07-21 00:20:43,199 Epoch[75] Batch [1300]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.077443,	
2017-07-21 00:20:47,624 Epoch[75] Batch [1310]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.077432,	
2017-07-21 00:20:52,212 Epoch[75] Batch [1320]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.077467,	
2017-07-21 00:20:56,905 Epoch[75] Batch [1330]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.077507,	
2017-07-21 00:21:01,456 Epoch[75] Batch [1340]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.077487,	
2017-07-21 00:21:06,055 Epoch[75] Batch [1350]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077494,	
2017-07-21 00:21:10,714 Epoch[75] Batch [1360]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077465,	
2017-07-21 00:21:15,439 Epoch[75] Batch [1370]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.077483,	
2017-07-21 00:21:20,041 Epoch[75] Batch [1380]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077512,	
2017-07-21 00:21:24,759 Epoch[75] Batch [1390]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.077506,	
2017-07-21 00:21:29,496 Epoch[75] Batch [1400]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.077497,	
2017-07-21 00:21:34,150 Epoch[75] Batch [1410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.077477,	
2017-07-21 00:21:38,653 Epoch[75] Batch [1420]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.077467,	
2017-07-21 00:21:43,597 Epoch[75] Batch [1430]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077523,	
2017-07-21 00:21:48,317 Epoch[75] Batch [1440]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.077521,	
2017-07-21 00:21:52,916 Epoch[75] Batch [1450]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077512,	
2017-07-21 00:21:57,443 Epoch[75] Batch [1460]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.077497,	
2017-07-21 00:22:02,119 Epoch[75] Batch [1470]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.077403,	
2017-07-21 00:22:06,688 Epoch[75] Batch [1480]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.077369,	
2017-07-21 00:22:09,777 Epoch[75] Train-FCNLogLoss=0.077353
2017-07-21 00:22:09,778 Epoch[75] Time cost=880.704
2017-07-21 00:22:10,928 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0076.params"
2017-07-21 00:22:14,563 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0076.states"
2017-07-21 00:22:20,977 Epoch[76] Batch [10]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.071723,	
2017-07-21 00:22:26,584 Epoch[76] Batch [20]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.076041,	
2017-07-21 00:22:31,988 Epoch[76] Batch [30]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.075763,	
2017-07-21 00:22:36,945 Epoch[76] Batch [40]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.076369,	
2017-07-21 00:22:41,917 Epoch[76] Batch [50]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.076204,	
2017-07-21 00:22:47,146 Epoch[76] Batch [60]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.076424,	
2017-07-21 00:22:52,170 Epoch[76] Batch [70]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.077662,	
2017-07-21 00:22:57,330 Epoch[76] Batch [80]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.078629,	
2017-07-21 00:23:03,376 Epoch[76] Batch [90]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.078115,	
2017-07-21 00:23:09,589 Epoch[76] Batch [100]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.078250,	
2017-07-21 00:23:16,024 Epoch[76] Batch [110]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.078062,	
2017-07-21 00:23:21,554 Epoch[76] Batch [120]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.077479,	
2017-07-21 00:23:27,223 Epoch[76] Batch [130]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.077917,	
2017-07-21 00:23:32,295 Epoch[76] Batch [140]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.077411,	
2017-07-21 00:23:37,678 Epoch[76] Batch [150]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.077240,	
2017-07-21 00:23:42,937 Epoch[76] Batch [160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.077390,	
2017-07-21 00:23:47,986 Epoch[76] Batch [170]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.077132,	
2017-07-21 00:23:53,361 Epoch[76] Batch [180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.077201,	
2017-07-21 00:23:58,192 Epoch[76] Batch [190]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.077582,	
2017-07-21 00:24:02,963 Epoch[76] Batch [200]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.077366,	
2017-07-21 00:24:08,149 Epoch[76] Batch [210]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.077565,	
2017-07-21 00:24:13,305 Epoch[76] Batch [220]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.077613,	
2017-07-21 00:24:18,427 Epoch[76] Batch [230]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077422,	
2017-07-21 00:24:23,891 Epoch[76] Batch [240]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.077794,	
2017-07-21 00:24:29,379 Epoch[76] Batch [250]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.077763,	
2017-07-21 00:24:34,935 Epoch[76] Batch [260]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.077833,	
2017-07-21 00:24:40,066 Epoch[76] Batch [270]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.077760,	
2017-07-21 00:24:44,925 Epoch[76] Batch [280]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077864,	
2017-07-21 00:24:50,131 Epoch[76] Batch [290]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.077881,	
2017-07-21 00:24:55,221 Epoch[76] Batch [300]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077834,	
2017-07-21 00:25:00,313 Epoch[76] Batch [310]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077697,	
2017-07-21 00:25:05,733 Epoch[76] Batch [320]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.077700,	
2017-07-21 00:25:10,961 Epoch[76] Batch [330]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.077549,	
2017-07-21 00:25:16,635 Epoch[76] Batch [340]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.077768,	
2017-07-21 00:25:21,904 Epoch[76] Batch [350]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.077642,	
2017-07-21 00:25:27,239 Epoch[76] Batch [360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.077644,	
2017-07-21 00:25:32,095 Epoch[76] Batch [370]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.077781,	
2017-07-21 00:25:37,656 Epoch[76] Batch [380]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.077736,	
2017-07-21 00:25:42,891 Epoch[76] Batch [390]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.077857,	
2017-07-21 00:25:48,248 Epoch[76] Batch [400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.077629,	
2017-07-21 00:25:53,507 Epoch[76] Batch [410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.077642,	
2017-07-21 00:25:58,993 Epoch[76] Batch [420]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.077484,	
2017-07-21 00:26:04,024 Epoch[76] Batch [430]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077513,	
2017-07-21 00:26:09,482 Epoch[76] Batch [440]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.077605,	
2017-07-21 00:26:15,000 Epoch[76] Batch [450]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.077837,	
2017-07-21 00:26:20,303 Epoch[76] Batch [460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.077855,	
2017-07-21 00:26:26,031 Epoch[76] Batch [470]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.077937,	
2017-07-21 00:26:31,322 Epoch[76] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.077980,	
2017-07-21 00:26:36,256 Epoch[76] Batch [490]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.077935,	
2017-07-21 00:26:41,092 Epoch[76] Batch [500]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.077907,	
2017-07-21 00:26:46,142 Epoch[76] Batch [510]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.077797,	
2017-07-21 00:26:51,320 Epoch[76] Batch [520]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.077828,	
2017-07-21 00:26:56,364 Epoch[76] Batch [530]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077881,	
2017-07-21 00:27:01,554 Epoch[76] Batch [540]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.078030,	
2017-07-21 00:27:07,064 Epoch[76] Batch [550]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.077935,	
2017-07-21 00:27:12,013 Epoch[76] Batch [560]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.077835,	
2017-07-21 00:27:17,112 Epoch[76] Batch [570]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.077794,	
2017-07-21 00:27:22,092 Epoch[76] Batch [580]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.077726,	
2017-07-21 00:27:27,188 Epoch[76] Batch [590]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.077718,	
2017-07-21 00:27:32,203 Epoch[76] Batch [600]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.077743,	
2017-07-21 00:27:37,699 Epoch[76] Batch [610]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.077541,	
2017-07-21 00:27:42,514 Epoch[76] Batch [620]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077456,	
2017-07-21 00:27:47,668 Epoch[76] Batch [630]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.077446,	
2017-07-21 00:27:53,618 Epoch[76] Batch [640]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.077398,	
2017-07-21 00:27:58,589 Epoch[76] Batch [650]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.077470,	
2017-07-21 00:28:03,544 Epoch[76] Batch [660]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.077482,	
2017-07-21 00:28:08,568 Epoch[76] Batch [670]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.077559,	
2017-07-21 00:28:14,143 Epoch[76] Batch [680]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.077572,	
2017-07-21 00:28:19,230 Epoch[76] Batch [690]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.077476,	
2017-07-21 00:28:24,092 Epoch[76] Batch [700]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.077484,	
2017-07-21 00:28:29,679 Epoch[76] Batch [710]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.077465,	
2017-07-21 00:28:34,800 Epoch[76] Batch [720]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077461,	
2017-07-21 00:28:39,833 Epoch[76] Batch [730]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.077425,	
2017-07-21 00:28:45,361 Epoch[76] Batch [740]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.077404,	
2017-07-21 00:28:50,358 Epoch[76] Batch [750]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.077345,	
2017-07-21 00:28:55,760 Epoch[76] Batch [760]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.077374,	
2017-07-21 00:29:01,033 Epoch[76] Batch [770]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.077338,	
2017-07-21 00:29:06,217 Epoch[76] Batch [780]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.077291,	
2017-07-21 00:29:11,471 Epoch[76] Batch [790]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.077314,	
2017-07-21 00:29:16,753 Epoch[76] Batch [800]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.077312,	
2017-07-21 00:29:22,207 Epoch[76] Batch [810]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.077303,	
2017-07-21 00:29:27,470 Epoch[76] Batch [820]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.077240,	
2017-07-21 00:29:33,045 Epoch[76] Batch [830]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.077222,	
2017-07-21 00:29:38,355 Epoch[76] Batch [840]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.077187,	
2017-07-21 00:29:43,789 Epoch[76] Batch [850]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.077161,	
2017-07-21 00:29:49,044 Epoch[76] Batch [860]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.077141,	
2017-07-21 00:29:54,032 Epoch[76] Batch [870]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.077057,	
2017-07-21 00:29:59,156 Epoch[76] Batch [880]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.077016,	
2017-07-21 00:30:03,811 Epoch[76] Batch [890]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.077078,	
2017-07-21 00:30:09,033 Epoch[76] Batch [900]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.077113,	
2017-07-21 00:30:14,166 Epoch[76] Batch [910]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.077142,	
2017-07-21 00:30:19,426 Epoch[76] Batch [920]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.077133,	
2017-07-21 00:30:25,093 Epoch[76] Batch [930]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.077167,	
2017-07-21 00:30:30,772 Epoch[76] Batch [940]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.077134,	
2017-07-21 00:30:36,389 Epoch[76] Batch [950]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.077180,	
2017-07-21 00:30:41,737 Epoch[76] Batch [960]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.077193,	
2017-07-21 00:30:46,822 Epoch[76] Batch [970]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.077196,	
2017-07-21 00:30:52,030 Epoch[76] Batch [980]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.077148,	
2017-07-21 00:30:57,408 Epoch[76] Batch [990]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.077145,	
2017-07-21 00:31:02,991 Epoch[76] Batch [1000]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.077118,	
2017-07-21 00:31:08,469 Epoch[76] Batch [1010]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.077121,	
2017-07-21 00:31:13,767 Epoch[76] Batch [1020]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.077178,	
2017-07-21 00:31:19,007 Epoch[76] Batch [1030]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.077281,	
2017-07-21 00:31:24,600 Epoch[76] Batch [1040]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.077347,	
2017-07-21 00:31:29,781 Epoch[76] Batch [1050]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.077327,	
2017-07-21 00:31:35,358 Epoch[76] Batch [1060]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.077258,	
2017-07-21 00:31:40,803 Epoch[76] Batch [1070]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.077254,	
2017-07-21 00:31:45,750 Epoch[76] Batch [1080]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077267,	
2017-07-21 00:31:50,951 Epoch[76] Batch [1090]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.077232,	
2017-07-21 00:31:56,292 Epoch[76] Batch [1100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.077149,	
2017-07-21 00:32:01,562 Epoch[76] Batch [1110]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.077125,	
2017-07-21 00:32:06,801 Epoch[76] Batch [1120]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.077159,	
2017-07-21 00:32:11,879 Epoch[76] Batch [1130]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.077137,	
2017-07-21 00:32:17,651 Epoch[76] Batch [1140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.077183,	
2017-07-21 00:32:23,569 Epoch[76] Batch [1150]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.077214,	
2017-07-21 00:32:29,046 Epoch[76] Batch [1160]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.077172,	
2017-07-21 00:32:34,650 Epoch[76] Batch [1170]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.077088,	
2017-07-21 00:32:39,983 Epoch[76] Batch [1180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.077045,	
2017-07-21 00:32:44,910 Epoch[76] Batch [1190]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.077071,	
2017-07-21 00:32:50,036 Epoch[76] Batch [1200]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.076991,	
2017-07-21 00:32:55,481 Epoch[76] Batch [1210]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.076938,	
2017-07-21 00:33:01,208 Epoch[76] Batch [1220]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.076921,	
2017-07-21 00:33:06,442 Epoch[76] Batch [1230]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.076968,	
2017-07-21 00:33:11,661 Epoch[76] Batch [1240]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.076974,	
2017-07-21 00:33:17,162 Epoch[76] Batch [1250]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.077035,	
2017-07-21 00:33:22,921 Epoch[76] Batch [1260]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.077022,	
2017-07-21 00:33:28,599 Epoch[76] Batch [1270]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.077050,	
2017-07-21 00:33:34,639 Epoch[76] Batch [1280]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.077031,	
2017-07-21 00:33:39,946 Epoch[76] Batch [1290]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.077088,	
2017-07-21 00:33:45,809 Epoch[76] Batch [1300]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.077099,	
2017-07-21 00:33:51,398 Epoch[76] Batch [1310]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.077036,	
2017-07-21 00:33:56,771 Epoch[76] Batch [1320]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.076977,	
2017-07-21 00:34:02,429 Epoch[76] Batch [1330]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.076964,	
2017-07-21 00:34:07,914 Epoch[76] Batch [1340]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.076950,	
2017-07-21 00:34:13,431 Epoch[76] Batch [1350]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.076970,	
2017-07-21 00:34:19,218 Epoch[76] Batch [1360]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.076947,	
2017-07-21 00:34:24,417 Epoch[76] Batch [1370]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.076982,	
2017-07-21 00:34:30,152 Epoch[76] Batch [1380]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.076991,	
2017-07-21 00:34:35,713 Epoch[76] Batch [1390]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.076998,	
2017-07-21 00:34:41,361 Epoch[76] Batch [1400]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.076965,	
2017-07-21 00:34:46,627 Epoch[76] Batch [1410]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.076948,	
2017-07-21 00:34:52,232 Epoch[76] Batch [1420]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.076954,	
2017-07-21 00:34:57,879 Epoch[76] Batch [1430]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.076961,	
2017-07-21 00:35:03,626 Epoch[76] Batch [1440]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.076901,	
2017-07-21 00:35:09,217 Epoch[76] Batch [1450]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.076929,	
2017-07-21 00:35:14,236 Epoch[76] Batch [1460]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.076967,	
2017-07-21 00:35:20,059 Epoch[76] Batch [1470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.076961,	
2017-07-21 00:35:25,397 Epoch[76] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.076932,	
2017-07-21 00:35:28,580 Epoch[76] Train-FCNLogLoss=0.076932
2017-07-21 00:35:28,580 Epoch[76] Time cost=794.017
2017-07-21 00:35:29,719 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0077.params"
2017-07-21 00:35:34,272 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0077.states"
2017-07-21 00:35:40,964 Epoch[77] Batch [10]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.078424,	
2017-07-21 00:35:47,274 Epoch[77] Batch [20]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.081977,	
2017-07-21 00:35:53,312 Epoch[77] Batch [30]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.079571,	
2017-07-21 00:36:00,106 Epoch[77] Batch [40]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.079746,	
2017-07-21 00:36:06,832 Epoch[77] Batch [50]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.077894,	
2017-07-21 00:36:13,636 Epoch[77] Batch [60]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.079051,	
2017-07-21 00:36:19,973 Epoch[77] Batch [70]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.078635,	
2017-07-21 00:36:26,219 Epoch[77] Batch [80]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.078365,	
2017-07-21 00:36:32,567 Epoch[77] Batch [90]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.077815,	
2017-07-21 00:36:38,640 Epoch[77] Batch [100]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.077975,	
2017-07-21 00:36:44,975 Epoch[77] Batch [110]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.078995,	
2017-07-21 00:36:51,798 Epoch[77] Batch [120]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.078570,	
2017-07-21 00:36:58,358 Epoch[77] Batch [130]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.078888,	
2017-07-21 00:37:04,816 Epoch[77] Batch [140]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.078368,	
2017-07-21 00:37:11,659 Epoch[77] Batch [150]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.078671,	
2017-07-21 00:37:18,076 Epoch[77] Batch [160]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.078615,	
2017-07-21 00:37:23,717 Epoch[77] Batch [170]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.078399,	
2017-07-21 00:37:30,128 Epoch[77] Batch [180]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.078245,	
2017-07-21 00:37:36,783 Epoch[77] Batch [190]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.078555,	
2017-07-21 00:37:42,941 Epoch[77] Batch [200]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.078114,	
2017-07-21 00:37:48,649 Epoch[77] Batch [210]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.078383,	
2017-07-21 00:37:54,771 Epoch[77] Batch [220]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.078567,	
2017-07-21 00:38:00,833 Epoch[77] Batch [230]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.078734,	
2017-07-21 00:38:06,595 Epoch[77] Batch [240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.078876,	
2017-07-21 00:38:13,038 Epoch[77] Batch [250]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.078779,	
2017-07-21 00:38:18,263 Epoch[77] Batch [260]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.078914,	
2017-07-21 00:38:23,894 Epoch[77] Batch [270]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.078891,	
2017-07-21 00:38:29,915 Epoch[77] Batch [280]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.078901,	
2017-07-21 00:38:35,761 Epoch[77] Batch [290]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.078792,	
2017-07-21 00:38:41,788 Epoch[77] Batch [300]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.078672,	
2017-07-21 00:38:47,987 Epoch[77] Batch [310]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.078969,	
2017-07-21 00:38:53,867 Epoch[77] Batch [320]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.078974,	
2017-07-21 00:38:59,219 Epoch[77] Batch [330]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.079020,	
2017-07-21 00:39:04,950 Epoch[77] Batch [340]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.078917,	
2017-07-21 00:39:10,730 Epoch[77] Batch [350]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.079084,	
2017-07-21 00:39:16,564 Epoch[77] Batch [360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.078767,	
2017-07-21 00:39:23,114 Epoch[77] Batch [370]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.078698,	
2017-07-21 00:39:29,421 Epoch[77] Batch [380]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.078730,	
2017-07-21 00:39:36,071 Epoch[77] Batch [390]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.078724,	
2017-07-21 00:39:42,345 Epoch[77] Batch [400]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.078636,	
2017-07-21 00:39:48,358 Epoch[77] Batch [410]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.078579,	
2017-07-21 00:39:54,011 Epoch[77] Batch [420]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.078525,	
2017-07-21 00:40:00,555 Epoch[77] Batch [430]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.078418,	
2017-07-21 00:40:06,766 Epoch[77] Batch [440]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.078260,	
2017-07-21 00:40:12,883 Epoch[77] Batch [450]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.078220,	
2017-07-21 00:40:19,243 Epoch[77] Batch [460]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.078362,	
2017-07-21 00:40:25,337 Epoch[77] Batch [470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.078324,	
2017-07-21 00:40:31,616 Epoch[77] Batch [480]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.078080,	
2017-07-21 00:40:38,161 Epoch[77] Batch [490]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.078263,	
2017-07-21 00:40:43,699 Epoch[77] Batch [500]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.078020,	
2017-07-21 00:40:49,799 Epoch[77] Batch [510]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.078083,	
2017-07-21 00:40:55,424 Epoch[77] Batch [520]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.078164,	
2017-07-21 00:41:01,284 Epoch[77] Batch [530]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.078188,	
2017-07-21 00:41:07,080 Epoch[77] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.078184,	
2017-07-21 00:41:13,233 Epoch[77] Batch [550]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.078214,	
2017-07-21 00:41:19,677 Epoch[77] Batch [560]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.078106,	
2017-07-21 00:41:26,329 Epoch[77] Batch [570]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.078031,	
2017-07-21 00:41:32,809 Epoch[77] Batch [580]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.077935,	
2017-07-21 00:41:39,114 Epoch[77] Batch [590]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.077816,	
2017-07-21 00:41:45,030 Epoch[77] Batch [600]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.077722,	
2017-07-21 00:41:51,451 Epoch[77] Batch [610]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.077709,	
2017-07-21 00:41:57,517 Epoch[77] Batch [620]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.077667,	
2017-07-21 00:42:03,707 Epoch[77] Batch [630]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.077656,	
2017-07-21 00:42:10,187 Epoch[77] Batch [640]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.077665,	
2017-07-21 00:42:16,871 Epoch[77] Batch [650]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.077699,	
2017-07-21 00:42:23,256 Epoch[77] Batch [660]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.077698,	
2017-07-21 00:42:29,291 Epoch[77] Batch [670]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.077702,	
2017-07-21 00:42:35,348 Epoch[77] Batch [680]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.077735,	
2017-07-21 00:42:42,188 Epoch[77] Batch [690]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.077643,	
2017-07-21 00:42:47,866 Epoch[77] Batch [700]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.077547,	
2017-07-21 00:42:54,285 Epoch[77] Batch [710]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.077500,	
2017-07-21 00:43:00,628 Epoch[77] Batch [720]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.077444,	
2017-07-21 00:43:06,381 Epoch[77] Batch [730]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.077363,	
2017-07-21 00:43:12,784 Epoch[77] Batch [740]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.077324,	
2017-07-21 00:43:19,752 Epoch[77] Batch [750]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.077229,	
2017-07-21 00:43:26,216 Epoch[77] Batch [760]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.077211,	
2017-07-21 00:43:32,274 Epoch[77] Batch [770]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.077280,	
2017-07-21 00:43:38,882 Epoch[77] Batch [780]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.077288,	
2017-07-21 00:43:45,168 Epoch[77] Batch [790]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.077301,	
2017-07-21 00:43:51,133 Epoch[77] Batch [800]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.077304,	
2017-07-21 00:43:57,428 Epoch[77] Batch [810]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.077304,	
2017-07-21 00:44:03,489 Epoch[77] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.077305,	
2017-07-21 00:44:09,588 Epoch[77] Batch [830]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.077268,	
2017-07-21 00:44:16,222 Epoch[77] Batch [840]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.077258,	
2017-07-21 00:44:22,497 Epoch[77] Batch [850]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.077279,	
2017-07-21 00:44:28,904 Epoch[77] Batch [860]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.077259,	
2017-07-21 00:44:34,530 Epoch[77] Batch [870]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.077350,	
2017-07-21 00:44:40,982 Epoch[77] Batch [880]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.077300,	
2017-07-21 00:44:47,243 Epoch[77] Batch [890]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.077280,	
2017-07-21 00:44:53,839 Epoch[77] Batch [900]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.077241,	
2017-07-21 00:44:59,406 Epoch[77] Batch [910]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.077166,	
2017-07-21 00:45:05,617 Epoch[77] Batch [920]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.077083,	
2017-07-21 00:45:11,783 Epoch[77] Batch [930]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.076991,	
2017-07-21 00:45:18,463 Epoch[77] Batch [940]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.076953,	
2017-07-21 00:45:24,446 Epoch[77] Batch [950]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.076935,	
2017-07-21 00:45:30,917 Epoch[77] Batch [960]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.076895,	
2017-07-21 00:45:37,528 Epoch[77] Batch [970]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.076902,	
2017-07-21 00:45:43,188 Epoch[77] Batch [980]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.076934,	
2017-07-21 00:45:49,388 Epoch[77] Batch [990]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.076957,	
2017-07-21 00:45:55,577 Epoch[77] Batch [1000]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.076925,	
2017-07-21 00:46:01,582 Epoch[77] Batch [1010]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.076970,	
2017-07-21 00:46:08,007 Epoch[77] Batch [1020]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.076903,	
2017-07-21 00:46:13,911 Epoch[77] Batch [1030]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.076836,	
2017-07-21 00:46:20,146 Epoch[77] Batch [1040]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.076888,	
2017-07-21 00:46:26,491 Epoch[77] Batch [1050]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.076925,	
2017-07-21 00:46:33,224 Epoch[77] Batch [1060]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.076917,	
2017-07-21 00:46:38,867 Epoch[77] Batch [1070]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.076878,	
2017-07-21 00:46:44,905 Epoch[77] Batch [1080]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.076862,	
2017-07-21 00:46:51,137 Epoch[77] Batch [1090]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.076824,	
2017-07-21 00:46:57,648 Epoch[77] Batch [1100]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.076820,	
2017-07-21 00:47:04,014 Epoch[77] Batch [1110]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.076798,	
2017-07-21 00:47:10,545 Epoch[77] Batch [1120]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.076794,	
2017-07-21 00:47:17,300 Epoch[77] Batch [1130]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.076851,	
2017-07-21 00:47:23,326 Epoch[77] Batch [1140]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.076821,	
2017-07-21 00:47:29,443 Epoch[77] Batch [1150]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.076885,	
2017-07-21 00:47:36,191 Epoch[77] Batch [1160]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.076863,	
2017-07-21 00:47:42,705 Epoch[77] Batch [1170]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.076875,	
2017-07-21 00:47:49,514 Epoch[77] Batch [1180]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.076929,	
2017-07-21 00:47:55,800 Epoch[77] Batch [1190]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.076905,	
2017-07-21 00:48:02,174 Epoch[77] Batch [1200]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.076888,	
2017-07-21 00:48:08,986 Epoch[77] Batch [1210]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.076849,	
2017-07-21 00:48:15,027 Epoch[77] Batch [1220]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.076758,	
2017-07-21 00:48:21,094 Epoch[77] Batch [1230]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.076789,	
2017-07-21 00:48:28,042 Epoch[77] Batch [1240]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.076792,	
2017-07-21 00:48:33,885 Epoch[77] Batch [1250]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.076765,	
2017-07-21 00:48:40,859 Epoch[77] Batch [1260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.076708,	
2017-07-21 00:48:47,426 Epoch[77] Batch [1270]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.076772,	
2017-07-21 00:48:54,488 Epoch[77] Batch [1280]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.076761,	
2017-07-21 00:49:00,583 Epoch[77] Batch [1290]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.076713,	
2017-07-21 00:49:06,544 Epoch[77] Batch [1300]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.076710,	
2017-07-21 00:49:13,156 Epoch[77] Batch [1310]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.076707,	
2017-07-21 00:49:19,635 Epoch[77] Batch [1320]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.076735,	
2017-07-21 00:49:25,882 Epoch[77] Batch [1330]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.076743,	
2017-07-21 00:49:32,326 Epoch[77] Batch [1340]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.076733,	
2017-07-21 00:49:38,819 Epoch[77] Batch [1350]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.076757,	
2017-07-21 00:49:45,269 Epoch[77] Batch [1360]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.076775,	
2017-07-21 00:49:51,586 Epoch[77] Batch [1370]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.076826,	
2017-07-21 00:49:57,561 Epoch[77] Batch [1380]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.076818,	
2017-07-21 00:50:03,872 Epoch[77] Batch [1390]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.076859,	
2017-07-21 00:50:10,827 Epoch[77] Batch [1400]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.076891,	
2017-07-21 00:50:16,884 Epoch[77] Batch [1410]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.076852,	
2017-07-21 00:50:24,055 Epoch[77] Batch [1420]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.076856,	
2017-07-21 00:50:30,643 Epoch[77] Batch [1430]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.076879,	
2017-07-21 00:50:36,431 Epoch[77] Batch [1440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.076891,	
2017-07-21 00:50:43,400 Epoch[77] Batch [1450]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.076859,	
2017-07-21 00:50:49,296 Epoch[77] Batch [1460]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.076842,	
2017-07-21 00:50:55,311 Epoch[77] Batch [1470]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.076798,	
2017-07-21 00:51:01,807 Epoch[77] Batch [1480]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.076816,	
2017-07-21 00:51:05,736 Epoch[77] Train-FCNLogLoss=0.076811
2017-07-21 00:51:05,736 Epoch[77] Time cost=931.463
2017-07-21 00:51:06,774 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0078.params"
2017-07-21 00:51:11,232 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0078.states"
2017-07-21 00:51:18,812 Epoch[78] Batch [10]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.071672,	
2017-07-21 00:51:25,233 Epoch[78] Batch [20]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.071239,	
2017-07-21 00:51:31,625 Epoch[78] Batch [30]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.074947,	
2017-07-21 00:51:38,706 Epoch[78] Batch [40]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.076071,	
2017-07-21 00:51:45,369 Epoch[78] Batch [50]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.075911,	
2017-07-21 00:51:52,103 Epoch[78] Batch [60]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.075863,	
2017-07-21 00:51:58,734 Epoch[78] Batch [70]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.075616,	
2017-07-21 00:52:05,267 Epoch[78] Batch [80]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.075930,	
2017-07-21 00:52:12,101 Epoch[78] Batch [90]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.076863,	
2017-07-21 00:52:18,006 Epoch[78] Batch [100]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.076551,	
2017-07-21 00:52:24,324 Epoch[78] Batch [110]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.076572,	
2017-07-21 00:52:30,811 Epoch[78] Batch [120]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.077150,	
2017-07-21 00:52:37,108 Epoch[78] Batch [130]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.076863,	
2017-07-21 00:52:43,036 Epoch[78] Batch [140]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.076981,	
2017-07-21 00:52:49,178 Epoch[78] Batch [150]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.077140,	
2017-07-21 00:52:55,122 Epoch[78] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.077738,	
2017-07-21 00:53:00,821 Epoch[78] Batch [170]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.077408,	
2017-07-21 00:53:06,830 Epoch[78] Batch [180]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.077077,	
2017-07-21 00:53:13,162 Epoch[78] Batch [190]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.077139,	
2017-07-21 00:53:19,357 Epoch[78] Batch [200]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.077175,	
2017-07-21 00:53:25,495 Epoch[78] Batch [210]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.077278,	
2017-07-21 00:53:31,875 Epoch[78] Batch [220]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.077452,	
2017-07-21 00:53:38,017 Epoch[78] Batch [230]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.077637,	
2017-07-21 00:53:44,803 Epoch[78] Batch [240]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.077677,	
2017-07-21 00:53:50,952 Epoch[78] Batch [250]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.077433,	
2017-07-21 00:53:57,208 Epoch[78] Batch [260]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.077310,	
2017-07-21 00:54:04,227 Epoch[78] Batch [270]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.077178,	
2017-07-21 00:54:10,388 Epoch[78] Batch [280]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.076929,	
2017-07-21 00:54:17,946 Epoch[78] Batch [290]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.076937,	
2017-07-21 00:54:24,567 Epoch[78] Batch [300]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.077053,	
2017-07-21 00:54:30,496 Epoch[78] Batch [310]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.077163,	
2017-07-21 00:54:37,829 Epoch[78] Batch [320]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.077500,	
2017-07-21 00:54:43,983 Epoch[78] Batch [330]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.077240,	
2017-07-21 00:54:50,426 Epoch[78] Batch [340]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.077260,	
2017-07-21 00:54:57,027 Epoch[78] Batch [350]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.076938,	
2017-07-21 00:55:03,855 Epoch[78] Batch [360]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.077064,	
2017-07-21 00:55:10,184 Epoch[78] Batch [370]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.077222,	
2017-07-21 00:55:16,583 Epoch[78] Batch [380]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.077492,	
2017-07-21 00:55:23,462 Epoch[78] Batch [390]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.077437,	
2017-07-21 00:55:30,236 Epoch[78] Batch [400]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.077112,	
2017-07-21 00:55:37,183 Epoch[78] Batch [410]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.076910,	
2017-07-21 00:55:43,645 Epoch[78] Batch [420]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.077076,	
2017-07-21 00:55:50,140 Epoch[78] Batch [430]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.077028,	
2017-07-21 00:55:56,708 Epoch[78] Batch [440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.076944,	
2017-07-21 00:56:03,042 Epoch[78] Batch [450]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.077007,	
2017-07-21 00:56:10,036 Epoch[78] Batch [460]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.076926,	
2017-07-21 00:56:16,315 Epoch[78] Batch [470]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.076745,	
2017-07-21 00:56:22,798 Epoch[78] Batch [480]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.076800,	
2017-07-21 00:56:29,271 Epoch[78] Batch [490]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.076818,	
2017-07-21 00:56:35,912 Epoch[78] Batch [500]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.076789,	
2017-07-21 00:56:42,645 Epoch[78] Batch [510]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.076731,	
2017-07-21 00:56:48,894 Epoch[78] Batch [520]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.076751,	
2017-07-21 00:56:55,182 Epoch[78] Batch [530]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.076760,	
2017-07-21 00:57:01,937 Epoch[78] Batch [540]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.076700,	
2017-07-21 00:57:08,434 Epoch[78] Batch [550]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.076644,	
2017-07-21 00:57:14,866 Epoch[78] Batch [560]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.076638,	
2017-07-21 00:57:21,384 Epoch[78] Batch [570]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.076655,	
2017-07-21 00:57:27,735 Epoch[78] Batch [580]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.076623,	
2017-07-21 00:57:33,937 Epoch[78] Batch [590]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.076454,	
2017-07-21 00:57:40,352 Epoch[78] Batch [600]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.076501,	
2017-07-21 00:57:47,510 Epoch[78] Batch [610]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.076547,	
2017-07-21 00:57:53,660 Epoch[78] Batch [620]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.076612,	
2017-07-21 00:57:59,678 Epoch[78] Batch [630]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.076541,	
2017-07-21 00:58:05,818 Epoch[78] Batch [640]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.076552,	
2017-07-21 00:58:12,046 Epoch[78] Batch [650]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.076656,	
2017-07-21 00:58:18,785 Epoch[78] Batch [660]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.076694,	
2017-07-21 00:58:24,811 Epoch[78] Batch [670]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.076755,	
2017-07-21 00:58:31,030 Epoch[78] Batch [680]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.076739,	
2017-07-21 00:58:37,206 Epoch[78] Batch [690]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.076768,	
2017-07-21 00:58:42,859 Epoch[78] Batch [700]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.076882,	
2017-07-21 00:58:48,909 Epoch[78] Batch [710]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.076877,	
2017-07-21 00:58:54,810 Epoch[78] Batch [720]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.076818,	
2017-07-21 00:59:00,929 Epoch[78] Batch [730]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.076715,	
2017-07-21 00:59:07,191 Epoch[78] Batch [740]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.076717,	
2017-07-21 00:59:13,327 Epoch[78] Batch [750]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.076632,	
2017-07-21 00:59:19,486 Epoch[78] Batch [760]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.076536,	
2017-07-21 00:59:25,733 Epoch[78] Batch [770]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.076397,	
2017-07-21 00:59:31,851 Epoch[78] Batch [780]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.076402,	
2017-07-21 00:59:37,821 Epoch[78] Batch [790]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.076428,	
2017-07-21 00:59:43,390 Epoch[78] Batch [800]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.076380,	
2017-07-21 00:59:49,414 Epoch[78] Batch [810]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.076365,	
2017-07-21 00:59:56,529 Epoch[78] Batch [820]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.076328,	
2017-07-21 01:00:03,724 Epoch[78] Batch [830]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.076328,	
2017-07-21 01:00:10,339 Epoch[78] Batch [840]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.076343,	
2017-07-21 01:00:16,454 Epoch[78] Batch [850]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.076384,	
2017-07-21 01:00:22,296 Epoch[78] Batch [860]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.076434,	
2017-07-21 01:00:28,915 Epoch[78] Batch [870]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.076464,	
2017-07-21 01:00:35,248 Epoch[78] Batch [880]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.076508,	
2017-07-21 01:00:41,577 Epoch[78] Batch [890]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.076534,	
2017-07-21 01:00:47,651 Epoch[78] Batch [900]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.076493,	
2017-07-21 01:00:53,912 Epoch[78] Batch [910]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.076472,	
2017-07-21 01:00:59,976 Epoch[78] Batch [920]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.076392,	
2017-07-21 01:01:06,264 Epoch[78] Batch [930]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.076395,	
2017-07-21 01:01:12,310 Epoch[78] Batch [940]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.076372,	
2017-07-21 01:01:19,285 Epoch[78] Batch [950]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.076360,	
2017-07-21 01:01:26,652 Epoch[78] Batch [960]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.076293,	
2017-07-21 01:01:33,088 Epoch[78] Batch [970]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.076190,	
2017-07-21 01:01:39,362 Epoch[78] Batch [980]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.076247,	
2017-07-21 01:01:46,014 Epoch[78] Batch [990]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.076208,	
2017-07-21 01:01:53,006 Epoch[78] Batch [1000]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.076230,	
2017-07-21 01:01:58,919 Epoch[78] Batch [1010]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.076227,	
2017-07-21 01:02:06,740 Epoch[78] Batch [1020]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.076202,	
2017-07-21 01:02:13,302 Epoch[78] Batch [1030]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.076276,	
2017-07-21 01:02:20,456 Epoch[78] Batch [1040]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.076207,	
2017-07-21 01:02:27,608 Epoch[78] Batch [1050]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.076195,	
2017-07-21 01:02:34,180 Epoch[78] Batch [1060]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.076281,	
2017-07-21 01:02:42,098 Epoch[78] Batch [1070]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.076239,	
2017-07-21 01:02:49,902 Epoch[78] Batch [1080]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.076258,	
2017-07-21 01:02:57,837 Epoch[78] Batch [1090]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.076226,	
2017-07-21 01:03:05,705 Epoch[78] Batch [1100]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.076227,	
2017-07-21 01:03:13,448 Epoch[78] Batch [1110]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.076271,	
2017-07-21 01:03:21,265 Epoch[78] Batch [1120]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.076326,	
2017-07-21 01:03:29,431 Epoch[78] Batch [1130]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.076380,	
2017-07-21 01:03:37,329 Epoch[78] Batch [1140]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.076361,	
2017-07-21 01:03:45,254 Epoch[78] Batch [1150]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.076413,	
2017-07-21 01:03:53,474 Epoch[78] Batch [1160]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.076415,	
2017-07-21 01:04:01,215 Epoch[78] Batch [1170]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.076462,	
2017-07-21 01:04:09,142 Epoch[78] Batch [1180]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.076477,	
2017-07-21 01:04:17,198 Epoch[78] Batch [1190]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.076479,	
2017-07-21 01:04:25,235 Epoch[78] Batch [1200]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.076470,	
2017-07-21 01:04:33,243 Epoch[78] Batch [1210]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.076490,	
2017-07-21 01:04:41,283 Epoch[78] Batch [1220]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.076518,	
2017-07-21 01:04:49,176 Epoch[78] Batch [1230]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.076541,	
2017-07-21 01:04:57,220 Epoch[78] Batch [1240]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.076552,	
2017-07-21 01:05:05,272 Epoch[78] Batch [1250]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.076539,	
2017-07-21 01:05:12,779 Epoch[78] Batch [1260]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.076518,	
2017-07-21 01:05:20,989 Epoch[78] Batch [1270]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.076452,	
2017-07-21 01:05:29,408 Epoch[78] Batch [1280]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.076430,	
2017-07-21 01:05:37,382 Epoch[78] Batch [1290]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.076464,	
2017-07-21 01:05:44,983 Epoch[78] Batch [1300]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.076515,	
2017-07-21 01:05:52,125 Epoch[78] Batch [1310]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.076526,	
2017-07-21 01:05:58,072 Epoch[78] Batch [1320]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.076500,	
2017-07-21 01:06:04,904 Epoch[78] Batch [1330]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.076553,	
2017-07-21 01:06:11,006 Epoch[78] Batch [1340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.076555,	
2017-07-21 01:06:17,532 Epoch[78] Batch [1350]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.076533,	
2017-07-21 01:06:24,491 Epoch[78] Batch [1360]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.076529,	
2017-07-21 01:06:30,730 Epoch[78] Batch [1370]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.076486,	
2017-07-21 01:06:36,951 Epoch[78] Batch [1380]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.076513,	
2017-07-21 01:06:43,507 Epoch[78] Batch [1390]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.076530,	
2017-07-21 01:06:49,860 Epoch[78] Batch [1400]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.076547,	
2017-07-21 01:06:56,295 Epoch[78] Batch [1410]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.076562,	
2017-07-21 01:07:02,160 Epoch[78] Batch [1420]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.076540,	
2017-07-21 01:07:09,086 Epoch[78] Batch [1430]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.076509,	
2017-07-21 01:07:15,887 Epoch[78] Batch [1440]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.076469,	
2017-07-21 01:07:21,656 Epoch[78] Batch [1450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.076485,	
2017-07-21 01:07:27,741 Epoch[78] Batch [1460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.076486,	
2017-07-21 01:07:34,022 Epoch[78] Batch [1470]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.076452,	
2017-07-21 01:07:40,475 Epoch[78] Batch [1480]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.076476,	
2017-07-21 01:07:44,126 Epoch[78] Train-FCNLogLoss=0.076479
2017-07-21 01:07:44,126 Epoch[78] Time cost=992.894
2017-07-21 01:07:45,144 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0079.params"
2017-07-21 01:07:49,636 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0079.states"
2017-07-21 01:07:57,381 Epoch[79] Batch [10]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.074478,	
2017-07-21 01:08:03,687 Epoch[79] Batch [20]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.075246,	
2017-07-21 01:08:09,769 Epoch[79] Batch [30]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.075249,	
2017-07-21 01:08:16,247 Epoch[79] Batch [40]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.074152,	
2017-07-21 01:08:24,128 Epoch[79] Batch [50]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.074443,	
2017-07-21 01:08:30,964 Epoch[79] Batch [60]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.075914,	
2017-07-21 01:08:37,157 Epoch[79] Batch [70]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.075897,	
2017-07-21 01:08:43,224 Epoch[79] Batch [80]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.075321,	
2017-07-21 01:08:49,362 Epoch[79] Batch [90]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.073833,	
2017-07-21 01:08:55,339 Epoch[79] Batch [100]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.074577,	
2017-07-21 01:09:01,580 Epoch[79] Batch [110]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.074823,	
2017-07-21 01:09:08,132 Epoch[79] Batch [120]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.075305,	
2017-07-21 01:09:14,903 Epoch[79] Batch [130]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.075250,	
2017-07-21 01:09:21,153 Epoch[79] Batch [140]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.075065,	
2017-07-21 01:09:27,163 Epoch[79] Batch [150]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.075053,	
2017-07-21 01:09:33,035 Epoch[79] Batch [160]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.075227,	
2017-07-21 01:09:39,628 Epoch[79] Batch [170]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.074925,	
2017-07-21 01:09:45,971 Epoch[79] Batch [180]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.075450,	
2017-07-21 01:09:52,153 Epoch[79] Batch [190]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.075315,	
2017-07-21 01:09:58,522 Epoch[79] Batch [200]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.075258,	
2017-07-21 01:10:04,561 Epoch[79] Batch [210]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.075103,	
2017-07-21 01:10:10,802 Epoch[79] Batch [220]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.075558,	
2017-07-21 01:10:17,600 Epoch[79] Batch [230]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.075759,	
2017-07-21 01:10:24,367 Epoch[79] Batch [240]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.075824,	
2017-07-21 01:10:30,761 Epoch[79] Batch [250]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.075909,	
2017-07-21 01:10:37,370 Epoch[79] Batch [260]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.075734,	
2017-07-21 01:10:44,231 Epoch[79] Batch [270]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.075744,	
2017-07-21 01:10:50,698 Epoch[79] Batch [280]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.075439,	
2017-07-21 01:10:57,411 Epoch[79] Batch [290]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.075253,	
2017-07-21 01:11:03,773 Epoch[79] Batch [300]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.075074,	
2017-07-21 01:11:10,055 Epoch[79] Batch [310]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.075143,	
2017-07-21 01:11:17,141 Epoch[79] Batch [320]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.074953,	
2017-07-21 01:11:23,330 Epoch[79] Batch [330]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.075026,	
2017-07-21 01:11:30,434 Epoch[79] Batch [340]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.075134,	
2017-07-21 01:11:37,660 Epoch[79] Batch [350]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.075105,	
2017-07-21 01:11:44,507 Epoch[79] Batch [360]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.075359,	
2017-07-21 01:11:51,919 Epoch[79] Batch [370]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.075662,	
2017-07-21 01:11:59,870 Epoch[79] Batch [380]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.075534,	
2017-07-21 01:12:06,893 Epoch[79] Batch [390]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.075580,	
2017-07-21 01:12:14,300 Epoch[79] Batch [400]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.075476,	
2017-07-21 01:12:21,527 Epoch[79] Batch [410]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.075553,	
2017-07-21 01:12:29,341 Epoch[79] Batch [420]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.075540,	
2017-07-21 01:12:36,973 Epoch[79] Batch [430]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.075447,	
2017-07-21 01:12:44,455 Epoch[79] Batch [440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.075500,	
2017-07-21 01:12:51,998 Epoch[79] Batch [450]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.075366,	
2017-07-21 01:12:59,356 Epoch[79] Batch [460]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.075240,	
2017-07-21 01:13:06,828 Epoch[79] Batch [470]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.075275,	
2017-07-21 01:13:14,002 Epoch[79] Batch [480]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.075384,	
2017-07-21 01:13:21,556 Epoch[79] Batch [490]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.075344,	
2017-07-21 01:13:29,278 Epoch[79] Batch [500]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.075294,	
2017-07-21 01:13:36,625 Epoch[79] Batch [510]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.075403,	
2017-07-21 01:13:44,053 Epoch[79] Batch [520]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.075459,	
2017-07-21 01:13:51,437 Epoch[79] Batch [530]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.075520,	
2017-07-21 01:13:58,842 Epoch[79] Batch [540]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.075660,	
2017-07-21 01:14:06,054 Epoch[79] Batch [550]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.075741,	
2017-07-21 01:14:14,060 Epoch[79] Batch [560]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.075887,	
2017-07-21 01:14:21,546 Epoch[79] Batch [570]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.075920,	
2017-07-21 01:14:28,620 Epoch[79] Batch [580]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.075945,	
2017-07-21 01:14:36,156 Epoch[79] Batch [590]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.075768,	
2017-07-21 01:14:43,084 Epoch[79] Batch [600]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.075712,	
2017-07-21 01:14:50,343 Epoch[79] Batch [610]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.075825,	
2017-07-21 01:14:57,739 Epoch[79] Batch [620]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.075948,	
2017-07-21 01:15:04,726 Epoch[79] Batch [630]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.075935,	
2017-07-21 01:15:11,335 Epoch[79] Batch [640]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.076007,	
2017-07-21 01:15:18,233 Epoch[79] Batch [650]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.076038,	
2017-07-21 01:15:25,007 Epoch[79] Batch [660]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.076033,	
2017-07-21 01:15:32,097 Epoch[79] Batch [670]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.076095,	
2017-07-21 01:15:39,710 Epoch[79] Batch [680]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.076133,	
2017-07-21 01:15:46,559 Epoch[79] Batch [690]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.076049,	
2017-07-21 01:15:53,485 Epoch[79] Batch [700]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.076063,	
2017-07-21 01:16:00,538 Epoch[79] Batch [710]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.076057,	
2017-07-21 01:16:07,204 Epoch[79] Batch [720]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.075966,	
2017-07-21 01:16:14,227 Epoch[79] Batch [730]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.075913,	
2017-07-21 01:16:21,112 Epoch[79] Batch [740]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.075873,	
2017-07-21 01:16:27,698 Epoch[79] Batch [750]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.075912,	
2017-07-21 01:16:34,513 Epoch[79] Batch [760]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.075894,	
2017-07-21 01:16:41,763 Epoch[79] Batch [770]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.075977,	
2017-07-21 01:16:48,440 Epoch[79] Batch [780]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.076064,	
2017-07-21 01:16:55,472 Epoch[79] Batch [790]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.076038,	
2017-07-21 01:17:02,147 Epoch[79] Batch [800]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.076057,	
2017-07-21 01:17:09,142 Epoch[79] Batch [810]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.075975,	
2017-07-21 01:17:16,523 Epoch[79] Batch [820]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.075814,	
2017-07-21 01:17:23,494 Epoch[79] Batch [830]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.075835,	
2017-07-21 01:17:29,859 Epoch[79] Batch [840]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.075921,	
2017-07-21 01:17:37,221 Epoch[79] Batch [850]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.075902,	
2017-07-21 01:17:43,664 Epoch[79] Batch [860]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.075891,	
2017-07-21 01:17:50,830 Epoch[79] Batch [870]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.075871,	
2017-07-21 01:17:58,259 Epoch[79] Batch [880]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.075811,	
2017-07-21 01:18:05,129 Epoch[79] Batch [890]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.075810,	
2017-07-21 01:18:11,984 Epoch[79] Batch [900]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.075822,	
2017-07-21 01:18:19,317 Epoch[79] Batch [910]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.075800,	
2017-07-21 01:18:25,812 Epoch[79] Batch [920]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.075785,	
2017-07-21 01:18:33,026 Epoch[79] Batch [930]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.075915,	
2017-07-21 01:18:39,825 Epoch[79] Batch [940]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.075965,	
2017-07-21 01:18:47,145 Epoch[79] Batch [950]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.076007,	
2017-07-21 01:18:54,254 Epoch[79] Batch [960]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.076026,	
2017-07-21 01:19:01,664 Epoch[79] Batch [970]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.075947,	
2017-07-21 01:19:08,907 Epoch[79] Batch [980]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.075935,	
2017-07-21 01:19:15,543 Epoch[79] Batch [990]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.075905,	
2017-07-21 01:19:22,707 Epoch[79] Batch [1000]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.075995,	
2017-07-21 01:19:29,701 Epoch[79] Batch [1010]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.075987,	
2017-07-21 01:19:37,223 Epoch[79] Batch [1020]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.075977,	
2017-07-21 01:19:44,349 Epoch[79] Batch [1030]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.076005,	
2017-07-21 01:19:51,684 Epoch[79] Batch [1040]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.076006,	
2017-07-21 01:19:59,016 Epoch[79] Batch [1050]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.076037,	
2017-07-21 01:20:06,014 Epoch[79] Batch [1060]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.075971,	
2017-07-21 01:20:13,400 Epoch[79] Batch [1070]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.076027,	
2017-07-21 01:20:20,445 Epoch[79] Batch [1080]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.076022,	
2017-07-21 01:20:27,940 Epoch[79] Batch [1090]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.075997,	
2017-07-21 01:20:35,501 Epoch[79] Batch [1100]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.076021,	
2017-07-21 01:20:42,597 Epoch[79] Batch [1110]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.076050,	
2017-07-21 01:20:49,901 Epoch[79] Batch [1120]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.075994,	
2017-07-21 01:20:57,011 Epoch[79] Batch [1130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.075937,	
2017-07-21 01:21:04,146 Epoch[79] Batch [1140]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.075924,	
2017-07-21 01:21:11,968 Epoch[79] Batch [1150]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.075927,	
2017-07-21 01:21:18,975 Epoch[79] Batch [1160]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.075862,	
2017-07-21 01:21:26,595 Epoch[79] Batch [1170]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075912,	
2017-07-21 01:21:33,984 Epoch[79] Batch [1180]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.075902,	
2017-07-21 01:21:41,271 Epoch[79] Batch [1190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.075981,	
2017-07-21 01:21:48,609 Epoch[79] Batch [1200]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.076047,	
2017-07-21 01:21:55,545 Epoch[79] Batch [1210]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.076158,	
2017-07-21 01:22:02,756 Epoch[79] Batch [1220]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.076222,	
2017-07-21 01:22:10,049 Epoch[79] Batch [1230]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.076206,	
2017-07-21 01:22:16,889 Epoch[79] Batch [1240]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.076176,	
2017-07-21 01:22:24,167 Epoch[79] Batch [1250]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.076154,	
2017-07-21 01:22:31,387 Epoch[79] Batch [1260]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.076175,	
2017-07-21 01:22:38,730 Epoch[79] Batch [1270]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.076199,	
2017-07-21 01:22:45,937 Epoch[79] Batch [1280]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.076265,	
2017-07-21 01:22:53,511 Epoch[79] Batch [1290]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.076278,	
2017-07-21 01:23:01,105 Epoch[79] Batch [1300]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.076267,	
2017-07-21 01:23:08,065 Epoch[79] Batch [1310]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.076229,	
2017-07-21 01:23:15,579 Epoch[79] Batch [1320]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.076170,	
2017-07-21 01:23:23,053 Epoch[79] Batch [1330]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.076196,	
2017-07-21 01:23:30,139 Epoch[79] Batch [1340]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.076171,	
2017-07-21 01:23:36,917 Epoch[79] Batch [1350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.076183,	
2017-07-21 01:23:44,025 Epoch[79] Batch [1360]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.076180,	
2017-07-21 01:23:51,126 Epoch[79] Batch [1370]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.076178,	
2017-07-21 01:23:58,464 Epoch[79] Batch [1380]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.076196,	
2017-07-21 01:24:05,970 Epoch[79] Batch [1390]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.076154,	
2017-07-21 01:24:12,735 Epoch[79] Batch [1400]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.076115,	
2017-07-21 01:24:18,931 Epoch[79] Batch [1410]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.076124,	
2017-07-21 01:24:25,903 Epoch[79] Batch [1420]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.076126,	
2017-07-21 01:24:32,494 Epoch[79] Batch [1430]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.076131,	
2017-07-21 01:24:38,966 Epoch[79] Batch [1440]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.076136,	
2017-07-21 01:24:46,338 Epoch[79] Batch [1450]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.076147,	
2017-07-21 01:24:52,993 Epoch[79] Batch [1460]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.076192,	
2017-07-21 01:24:59,615 Epoch[79] Batch [1470]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.076247,	
2017-07-21 01:25:06,177 Epoch[79] Batch [1480]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.076222,	
2017-07-21 01:25:10,007 Epoch[79] Train-FCNLogLoss=0.076220
2017-07-21 01:25:10,007 Epoch[79] Time cost=1040.370
2017-07-21 01:25:11,137 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0080.params"
2017-07-21 01:25:15,717 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0080.states"
2017-07-21 01:25:23,749 Epoch[80] Batch [10]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.074412,	
2017-07-21 01:25:31,379 Epoch[80] Batch [20]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.074209,	
2017-07-21 01:25:38,864 Epoch[80] Batch [30]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.074332,	
2017-07-21 01:25:45,983 Epoch[80] Batch [40]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.075218,	
2017-07-21 01:25:53,365 Epoch[80] Batch [50]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.076060,	
2017-07-21 01:26:00,363 Epoch[80] Batch [60]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.076470,	
2017-07-21 01:26:08,226 Epoch[80] Batch [70]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.076514,	
2017-07-21 01:26:16,123 Epoch[80] Batch [80]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.076869,	
2017-07-21 01:26:24,514 Epoch[80] Batch [90]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.077881,	
2017-07-21 01:26:32,745 Epoch[80] Batch [100]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.077966,	
2017-07-21 01:26:41,379 Epoch[80] Batch [110]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.077691,	
2017-07-21 01:26:49,706 Epoch[80] Batch [120]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.078236,	
2017-07-21 01:26:56,870 Epoch[80] Batch [130]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.078229,	
2017-07-21 01:27:04,050 Epoch[80] Batch [140]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.078017,	
2017-07-21 01:27:11,222 Epoch[80] Batch [150]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.077621,	
2017-07-21 01:27:18,153 Epoch[80] Batch [160]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.077199,	
2017-07-21 01:27:25,504 Epoch[80] Batch [170]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.076873,	
2017-07-21 01:27:32,798 Epoch[80] Batch [180]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.076584,	
2017-07-21 01:27:39,744 Epoch[80] Batch [190]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.076519,	
2017-07-21 01:27:46,647 Epoch[80] Batch [200]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.076481,	
2017-07-21 01:27:53,778 Epoch[80] Batch [210]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.076616,	
2017-07-21 01:28:01,068 Epoch[80] Batch [220]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.076650,	
2017-07-21 01:28:08,084 Epoch[80] Batch [230]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.076589,	
2017-07-21 01:28:15,699 Epoch[80] Batch [240]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.076348,	
2017-07-21 01:28:22,614 Epoch[80] Batch [250]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.076425,	
2017-07-21 01:28:29,715 Epoch[80] Batch [260]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.076398,	
2017-07-21 01:28:37,190 Epoch[80] Batch [270]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.076489,	
2017-07-21 01:28:44,367 Epoch[80] Batch [280]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.076449,	
2017-07-21 01:28:51,286 Epoch[80] Batch [290]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.076474,	
2017-07-21 01:28:58,870 Epoch[80] Batch [300]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.076481,	
2017-07-21 01:29:06,688 Epoch[80] Batch [310]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.076353,	
2017-07-21 01:29:14,232 Epoch[80] Batch [320]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.076380,	
2017-07-21 01:29:21,445 Epoch[80] Batch [330]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.076507,	
2017-07-21 01:29:28,986 Epoch[80] Batch [340]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.076497,	
2017-07-21 01:29:36,070 Epoch[80] Batch [350]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.076511,	
2017-07-21 01:29:43,535 Epoch[80] Batch [360]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.076546,	
2017-07-21 01:29:50,922 Epoch[80] Batch [370]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.076653,	
2017-07-21 01:29:58,395 Epoch[80] Batch [380]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.076707,	
2017-07-21 01:30:05,828 Epoch[80] Batch [390]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.076848,	
2017-07-21 01:30:12,900 Epoch[80] Batch [400]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.077029,	
2017-07-21 01:30:20,269 Epoch[80] Batch [410]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.077055,	
2017-07-21 01:30:27,956 Epoch[80] Batch [420]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.077051,	
2017-07-21 01:30:35,403 Epoch[80] Batch [430]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.077365,	
2017-07-21 01:30:42,997 Epoch[80] Batch [440]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.077324,	
2017-07-21 01:30:50,393 Epoch[80] Batch [450]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.077214,	
2017-07-21 01:30:58,067 Epoch[80] Batch [460]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.077203,	
2017-07-21 01:31:05,498 Epoch[80] Batch [470]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.077091,	
2017-07-21 01:31:12,807 Epoch[80] Batch [480]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.077079,	
2017-07-21 01:31:20,596 Epoch[80] Batch [490]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.077080,	
2017-07-21 01:31:28,645 Epoch[80] Batch [500]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.077119,	
2017-07-21 01:31:36,274 Epoch[80] Batch [510]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.077133,	
2017-07-21 01:31:43,969 Epoch[80] Batch [520]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.077108,	
2017-07-21 01:31:51,922 Epoch[80] Batch [530]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.077000,	
2017-07-21 01:31:59,729 Epoch[80] Batch [540]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.076952,	
2017-07-21 01:32:07,276 Epoch[80] Batch [550]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.076939,	
2017-07-21 01:32:14,520 Epoch[80] Batch [560]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.076997,	
2017-07-21 01:32:22,026 Epoch[80] Batch [570]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.077070,	
2017-07-21 01:32:29,342 Epoch[80] Batch [580]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.077168,	
2017-07-21 01:32:36,641 Epoch[80] Batch [590]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.077222,	
2017-07-21 01:32:44,018 Epoch[80] Batch [600]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.077147,	
2017-07-21 01:32:51,383 Epoch[80] Batch [610]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.077141,	
2017-07-21 01:32:58,823 Epoch[80] Batch [620]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.077118,	
2017-07-21 01:33:05,730 Epoch[80] Batch [630]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.077053,	
2017-07-21 01:33:12,793 Epoch[80] Batch [640]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.077114,	
2017-07-21 01:33:19,375 Epoch[80] Batch [650]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.077054,	
2017-07-21 01:33:25,707 Epoch[80] Batch [660]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.077054,	
2017-07-21 01:33:32,510 Epoch[80] Batch [670]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.076943,	
2017-07-21 01:33:39,724 Epoch[80] Batch [680]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.076852,	
2017-07-21 01:33:47,576 Epoch[80] Batch [690]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.076937,	
2017-07-21 01:33:55,132 Epoch[80] Batch [700]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.076969,	
2017-07-21 01:34:01,893 Epoch[80] Batch [710]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.076847,	
2017-07-21 01:34:08,562 Epoch[80] Batch [720]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.076831,	
2017-07-21 01:34:14,899 Epoch[80] Batch [730]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.076782,	
2017-07-21 01:34:21,957 Epoch[80] Batch [740]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.076791,	
2017-07-21 01:34:29,380 Epoch[80] Batch [750]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.076801,	
2017-07-21 01:34:36,945 Epoch[80] Batch [760]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.076813,	
2017-07-21 01:34:44,481 Epoch[80] Batch [770]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.076735,	
2017-07-21 01:34:51,884 Epoch[80] Batch [780]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.076730,	
2017-07-21 01:34:59,413 Epoch[80] Batch [790]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.076737,	
2017-07-21 01:35:06,878 Epoch[80] Batch [800]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.076698,	
2017-07-21 01:35:14,376 Epoch[80] Batch [810]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.076702,	
2017-07-21 01:35:22,175 Epoch[80] Batch [820]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.076746,	
2017-07-21 01:35:30,053 Epoch[80] Batch [830]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.076703,	
2017-07-21 01:35:37,599 Epoch[80] Batch [840]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.076726,	
2017-07-21 01:35:45,415 Epoch[80] Batch [850]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.076808,	
2017-07-21 01:35:52,799 Epoch[80] Batch [860]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.076794,	
2017-07-21 01:36:00,789 Epoch[80] Batch [870]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.076760,	
2017-07-21 01:36:08,776 Epoch[80] Batch [880]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.076746,	
2017-07-21 01:36:16,655 Epoch[80] Batch [890]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.076818,	
2017-07-21 01:36:24,451 Epoch[80] Batch [900]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.076829,	
2017-07-21 01:36:32,079 Epoch[80] Batch [910]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.076845,	
2017-07-21 01:36:40,083 Epoch[80] Batch [920]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.076759,	
2017-07-21 01:36:48,118 Epoch[80] Batch [930]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.076820,	
2017-07-21 01:36:55,785 Epoch[80] Batch [940]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.076869,	
2017-07-21 01:37:03,520 Epoch[80] Batch [950]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.076858,	
2017-07-21 01:37:11,156 Epoch[80] Batch [960]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.076845,	
2017-07-21 01:37:18,846 Epoch[80] Batch [970]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.076847,	
2017-07-21 01:37:26,633 Epoch[80] Batch [980]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.076852,	
2017-07-21 01:37:34,420 Epoch[80] Batch [990]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.076859,	
2017-07-21 01:37:42,738 Epoch[80] Batch [1000]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.076797,	
2017-07-21 01:37:51,502 Epoch[80] Batch [1010]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.076799,	
2017-07-21 01:37:59,508 Epoch[80] Batch [1020]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.076731,	
2017-07-21 01:38:07,595 Epoch[80] Batch [1030]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.076732,	
2017-07-21 01:38:15,688 Epoch[80] Batch [1040]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.076829,	
2017-07-21 01:38:23,902 Epoch[80] Batch [1050]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.076805,	
2017-07-21 01:38:32,081 Epoch[80] Batch [1060]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.076830,	
2017-07-21 01:38:40,030 Epoch[80] Batch [1070]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.076809,	
2017-07-21 01:38:47,973 Epoch[80] Batch [1080]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.076777,	
2017-07-21 01:38:55,785 Epoch[80] Batch [1090]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.076779,	
2017-07-21 01:39:02,324 Epoch[80] Batch [1100]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.076762,	
2017-07-21 01:39:09,526 Epoch[80] Batch [1110]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.076764,	
2017-07-21 01:39:15,836 Epoch[80] Batch [1120]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.076690,	
2017-07-21 01:39:23,326 Epoch[80] Batch [1130]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.076681,	
2017-07-21 01:39:30,246 Epoch[80] Batch [1140]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.076684,	
2017-07-21 01:39:36,810 Epoch[80] Batch [1150]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.076723,	
2017-07-21 01:39:43,925 Epoch[80] Batch [1160]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.076633,	
2017-07-21 01:39:50,684 Epoch[80] Batch [1170]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.076633,	
2017-07-21 01:39:58,210 Epoch[80] Batch [1180]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.076688,	
2017-07-21 01:40:05,366 Epoch[80] Batch [1190]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.076650,	
2017-07-21 01:40:12,496 Epoch[80] Batch [1200]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.076617,	
2017-07-21 01:40:20,143 Epoch[80] Batch [1210]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.076626,	
2017-07-21 01:40:26,556 Epoch[80] Batch [1220]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.076653,	
2017-07-21 01:40:33,605 Epoch[80] Batch [1230]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.076655,	
2017-07-21 01:40:41,703 Epoch[80] Batch [1240]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.076709,	
2017-07-21 01:40:49,504 Epoch[80] Batch [1250]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.076670,	
2017-07-21 01:40:56,910 Epoch[80] Batch [1260]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.076689,	
2017-07-21 01:41:05,059 Epoch[80] Batch [1270]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.076721,	
2017-07-21 01:41:12,704 Epoch[80] Batch [1280]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.076717,	
2017-07-21 01:41:19,918 Epoch[80] Batch [1290]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.076739,	
2017-07-21 01:41:26,692 Epoch[80] Batch [1300]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.076704,	
2017-07-21 01:41:34,212 Epoch[80] Batch [1310]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.076727,	
2017-07-21 01:41:40,908 Epoch[80] Batch [1320]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.076744,	
2017-07-21 01:41:47,796 Epoch[80] Batch [1330]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.076698,	
2017-07-21 01:41:54,871 Epoch[80] Batch [1340]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.076711,	
2017-07-21 01:42:01,509 Epoch[80] Batch [1350]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.076710,	
2017-07-21 01:42:08,795 Epoch[80] Batch [1360]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.076768,	
2017-07-21 01:42:15,741 Epoch[80] Batch [1370]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.076816,	
2017-07-21 01:42:23,312 Epoch[80] Batch [1380]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.076789,	
2017-07-21 01:42:30,490 Epoch[80] Batch [1390]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.076768,	
2017-07-21 01:42:37,478 Epoch[80] Batch [1400]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.076753,	
2017-07-21 01:42:44,911 Epoch[80] Batch [1410]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.076702,	
2017-07-21 01:42:52,440 Epoch[80] Batch [1420]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.076648,	
2017-07-21 01:42:59,470 Epoch[80] Batch [1430]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.076630,	
2017-07-21 01:43:06,925 Epoch[80] Batch [1440]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.076644,	
2017-07-21 01:43:14,321 Epoch[80] Batch [1450]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.076650,	
2017-07-21 01:43:21,427 Epoch[80] Batch [1460]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.076590,	
2017-07-21 01:43:28,678 Epoch[80] Batch [1470]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.076556,	
2017-07-21 01:43:35,641 Epoch[80] Batch [1480]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.076549,	
2017-07-21 01:43:40,097 Epoch[80] Train-FCNLogLoss=0.076564
2017-07-21 01:43:40,097 Epoch[80] Time cost=1104.380
2017-07-21 01:43:41,316 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0081.params"
2017-07-21 01:43:45,778 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0081.states"
2017-07-21 01:43:53,899 Epoch[81] Batch [10]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.079722,	
2017-07-21 01:44:01,333 Epoch[81] Batch [20]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.079342,	
2017-07-21 01:44:08,959 Epoch[81] Batch [30]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.079784,	
2017-07-21 01:44:16,120 Epoch[81] Batch [40]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.078881,	
2017-07-21 01:44:23,652 Epoch[81] Batch [50]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.078145,	
2017-07-21 01:44:30,531 Epoch[81] Batch [60]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.078371,	
2017-07-21 01:44:37,857 Epoch[81] Batch [70]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.078090,	
2017-07-21 01:44:45,072 Epoch[81] Batch [80]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.077653,	
2017-07-21 01:44:52,299 Epoch[81] Batch [90]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.077116,	
2017-07-21 01:44:59,655 Epoch[81] Batch [100]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.077187,	
2017-07-21 01:45:07,106 Epoch[81] Batch [110]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.076642,	
2017-07-21 01:45:14,575 Epoch[81] Batch [120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.076331,	
2017-07-21 01:45:21,492 Epoch[81] Batch [130]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.076146,	
2017-07-21 01:45:28,895 Epoch[81] Batch [140]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.076742,	
2017-07-21 01:45:36,218 Epoch[81] Batch [150]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.076772,	
2017-07-21 01:45:43,647 Epoch[81] Batch [160]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.076806,	
2017-07-21 01:45:51,137 Epoch[81] Batch [170]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.076795,	
2017-07-21 01:45:58,443 Epoch[81] Batch [180]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.076991,	
2017-07-21 01:46:06,053 Epoch[81] Batch [190]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.076505,	
2017-07-21 01:46:13,298 Epoch[81] Batch [200]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.076220,	
2017-07-21 01:46:20,682 Epoch[81] Batch [210]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.076221,	
2017-07-21 01:46:28,174 Epoch[81] Batch [220]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.076642,	
2017-07-21 01:46:35,370 Epoch[81] Batch [230]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.077022,	
2017-07-21 01:46:42,865 Epoch[81] Batch [240]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.076782,	
2017-07-21 01:46:49,973 Epoch[81] Batch [250]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.077125,	
2017-07-21 01:46:57,519 Epoch[81] Batch [260]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.076952,	
2017-07-21 01:47:05,161 Epoch[81] Batch [270]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.076821,	
2017-07-21 01:47:12,845 Epoch[81] Batch [280]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.076734,	
2017-07-21 01:47:20,221 Epoch[81] Batch [290]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.076784,	
2017-07-21 01:47:28,007 Epoch[81] Batch [300]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.076788,	
2017-07-21 01:47:35,165 Epoch[81] Batch [310]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.077047,	
2017-07-21 01:47:42,847 Epoch[81] Batch [320]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.076974,	
2017-07-21 01:47:50,487 Epoch[81] Batch [330]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.076903,	
2017-07-21 01:47:58,748 Epoch[81] Batch [340]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.076941,	
2017-07-21 01:48:06,340 Epoch[81] Batch [350]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.076977,	
2017-07-21 01:48:14,264 Epoch[81] Batch [360]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.076754,	
2017-07-21 01:48:21,603 Epoch[81] Batch [370]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.076874,	
2017-07-21 01:48:29,229 Epoch[81] Batch [380]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.076859,	
2017-07-21 01:48:37,560 Epoch[81] Batch [390]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.076981,	
2017-07-21 01:48:45,757 Epoch[81] Batch [400]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.077009,	
2017-07-21 01:48:54,348 Epoch[81] Batch [410]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076966,	
2017-07-21 01:49:02,338 Epoch[81] Batch [420]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.076935,	
2017-07-21 01:49:10,277 Epoch[81] Batch [430]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.076990,	
2017-07-21 01:49:18,341 Epoch[81] Batch [440]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.077060,	
2017-07-21 01:49:26,687 Epoch[81] Batch [450]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076884,	
2017-07-21 01:49:34,940 Epoch[81] Batch [460]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.076919,	
2017-07-21 01:49:43,143 Epoch[81] Batch [470]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.076959,	
2017-07-21 01:49:51,821 Epoch[81] Batch [480]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.076893,	
2017-07-21 01:50:00,014 Epoch[81] Batch [490]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.076972,	
2017-07-21 01:50:08,089 Epoch[81] Batch [500]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.076898,	
2017-07-21 01:50:16,366 Epoch[81] Batch [510]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.076900,	
2017-07-21 01:50:24,712 Epoch[81] Batch [520]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076917,	
2017-07-21 01:50:32,515 Epoch[81] Batch [530]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.076814,	
2017-07-21 01:50:40,370 Epoch[81] Batch [540]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.076861,	
2017-07-21 01:50:48,517 Epoch[81] Batch [550]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.076911,	
2017-07-21 01:50:56,720 Epoch[81] Batch [560]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.076828,	
2017-07-21 01:51:05,131 Epoch[81] Batch [570]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.076814,	
2017-07-21 01:51:13,047 Epoch[81] Batch [580]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.076894,	
2017-07-21 01:51:21,245 Epoch[81] Batch [590]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.076694,	
2017-07-21 01:51:29,333 Epoch[81] Batch [600]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.076634,	
2017-07-21 01:51:37,682 Epoch[81] Batch [610]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076622,	
2017-07-21 01:51:45,279 Epoch[81] Batch [620]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.076602,	
2017-07-21 01:51:53,280 Epoch[81] Batch [630]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.076781,	
2017-07-21 01:52:01,624 Epoch[81] Batch [640]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076777,	
2017-07-21 01:52:09,777 Epoch[81] Batch [650]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.076788,	
2017-07-21 01:52:18,157 Epoch[81] Batch [660]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.076884,	
2017-07-21 01:52:26,223 Epoch[81] Batch [670]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.076736,	
2017-07-21 01:52:34,582 Epoch[81] Batch [680]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076709,	
2017-07-21 01:52:42,794 Epoch[81] Batch [690]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.076756,	
2017-07-21 01:52:51,236 Epoch[81] Batch [700]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.076847,	
2017-07-21 01:52:59,716 Epoch[81] Batch [710]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.076944,	
2017-07-21 01:53:07,880 Epoch[81] Batch [720]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.076917,	
2017-07-21 01:53:15,776 Epoch[81] Batch [730]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.076959,	
2017-07-21 01:53:23,761 Epoch[81] Batch [740]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.077002,	
2017-07-21 01:53:31,856 Epoch[81] Batch [750]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.076931,	
2017-07-21 01:53:39,970 Epoch[81] Batch [760]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.076913,	
2017-07-21 01:53:48,034 Epoch[81] Batch [770]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.076826,	
2017-07-21 01:53:56,120 Epoch[81] Batch [780]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.076848,	
2017-07-21 01:54:04,521 Epoch[81] Batch [790]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.076889,	
2017-07-21 01:54:13,162 Epoch[81] Batch [800]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.076902,	
2017-07-21 01:54:21,421 Epoch[81] Batch [810]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.076844,	
2017-07-21 01:54:29,837 Epoch[81] Batch [820]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.076776,	
2017-07-21 01:54:38,102 Epoch[81] Batch [830]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.076750,	
2017-07-21 01:54:46,420 Epoch[81] Batch [840]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.076789,	
2017-07-21 01:54:54,550 Epoch[81] Batch [850]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.076853,	
2017-07-21 01:55:02,792 Epoch[81] Batch [860]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.076799,	
2017-07-21 01:55:10,878 Epoch[81] Batch [870]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.076649,	
2017-07-21 01:55:19,457 Epoch[81] Batch [880]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076695,	
2017-07-21 01:55:28,160 Epoch[81] Batch [890]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.076720,	
2017-07-21 01:55:36,861 Epoch[81] Batch [900]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.076723,	
2017-07-21 01:55:45,210 Epoch[81] Batch [910]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076697,	
2017-07-21 01:55:53,846 Epoch[81] Batch [920]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.076600,	
2017-07-21 01:56:02,459 Epoch[81] Batch [930]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076614,	
2017-07-21 01:56:10,666 Epoch[81] Batch [940]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.076550,	
2017-07-21 01:56:19,244 Epoch[81] Batch [950]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076487,	
2017-07-21 01:56:27,325 Epoch[81] Batch [960]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.076601,	
2017-07-21 01:56:35,621 Epoch[81] Batch [970]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.076572,	
2017-07-21 01:56:44,075 Epoch[81] Batch [980]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.076582,	
2017-07-21 01:56:52,253 Epoch[81] Batch [990]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.076539,	
2017-07-21 01:57:00,721 Epoch[81] Batch [1000]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.076536,	
2017-07-21 01:57:09,488 Epoch[81] Batch [1010]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.076554,	
2017-07-21 01:57:18,081 Epoch[81] Batch [1020]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076453,	
2017-07-21 01:57:26,673 Epoch[81] Batch [1030]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076417,	
2017-07-21 01:57:35,290 Epoch[81] Batch [1040]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076413,	
2017-07-21 01:57:43,816 Epoch[81] Batch [1050]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.076370,	
2017-07-21 01:57:52,352 Epoch[81] Batch [1060]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.076368,	
2017-07-21 01:58:01,040 Epoch[81] Batch [1070]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.076326,	
2017-07-21 01:58:09,622 Epoch[81] Batch [1080]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076283,	
2017-07-21 01:58:18,042 Epoch[81] Batch [1090]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.076306,	
2017-07-21 01:58:26,848 Epoch[81] Batch [1100]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.076285,	
2017-07-21 01:58:35,192 Epoch[81] Batch [1110]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076305,	
2017-07-21 01:58:43,852 Epoch[81] Batch [1120]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.076272,	
2017-07-21 01:58:52,599 Epoch[81] Batch [1130]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.076199,	
2017-07-21 01:59:01,323 Epoch[81] Batch [1140]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.076231,	
2017-07-21 01:59:10,003 Epoch[81] Batch [1150]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.076229,	
2017-07-21 01:59:18,819 Epoch[81] Batch [1160]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.076235,	
2017-07-21 01:59:27,491 Epoch[81] Batch [1170]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.076309,	
2017-07-21 01:59:36,146 Epoch[81] Batch [1180]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.076302,	
2017-07-21 01:59:44,642 Epoch[81] Batch [1190]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.076290,	
2017-07-21 01:59:53,380 Epoch[81] Batch [1200]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076242,	
2017-07-21 02:00:02,019 Epoch[81] Batch [1210]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.076242,	
2017-07-21 02:00:10,646 Epoch[81] Batch [1220]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076226,	
2017-07-21 02:00:19,469 Epoch[81] Batch [1230]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.076229,	
2017-07-21 02:00:28,087 Epoch[81] Batch [1240]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076202,	
2017-07-21 02:00:36,631 Epoch[81] Batch [1250]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.076216,	
2017-07-21 02:00:45,003 Epoch[81] Batch [1260]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.076222,	
2017-07-21 02:00:53,813 Epoch[81] Batch [1270]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.076175,	
2017-07-21 02:01:02,336 Epoch[81] Batch [1280]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.076183,	
2017-07-21 02:01:10,982 Epoch[81] Batch [1290]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.076218,	
2017-07-21 02:01:19,276 Epoch[81] Batch [1300]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.076186,	
2017-07-21 02:01:27,209 Epoch[81] Batch [1310]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.076150,	
2017-07-21 02:01:35,754 Epoch[81] Batch [1320]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.076190,	
2017-07-21 02:01:44,243 Epoch[81] Batch [1330]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.076182,	
2017-07-21 02:01:52,538 Epoch[81] Batch [1340]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.076177,	
2017-07-21 02:02:00,658 Epoch[81] Batch [1350]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.076190,	
2017-07-21 02:02:08,351 Epoch[81] Batch [1360]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.076240,	
2017-07-21 02:02:16,295 Epoch[81] Batch [1370]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.076262,	
2017-07-21 02:02:24,395 Epoch[81] Batch [1380]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.076181,	
2017-07-21 02:02:32,594 Epoch[81] Batch [1390]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.076164,	
2017-07-21 02:02:40,961 Epoch[81] Batch [1400]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.076167,	
2017-07-21 02:02:49,265 Epoch[81] Batch [1410]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.076241,	
2017-07-21 02:02:57,206 Epoch[81] Batch [1420]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.076205,	
2017-07-21 02:03:05,180 Epoch[81] Batch [1430]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.076248,	
2017-07-21 02:03:13,556 Epoch[81] Batch [1440]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.076302,	
2017-07-21 02:03:22,249 Epoch[81] Batch [1450]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.076372,	
2017-07-21 02:03:30,655 Epoch[81] Batch [1460]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.076363,	
2017-07-21 02:03:39,089 Epoch[81] Batch [1470]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.076353,	
2017-07-21 02:03:47,276 Epoch[81] Batch [1480]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.076382,	
2017-07-21 02:03:52,325 Epoch[81] Train-FCNLogLoss=0.076349
2017-07-21 02:03:52,326 Epoch[81] Time cost=1206.547
2017-07-21 02:03:53,536 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0082.params"
2017-07-21 02:03:58,103 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0082.states"
2017-07-21 02:04:07,996 Epoch[82] Batch [10]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.076355,	
2017-07-21 02:04:16,448 Epoch[82] Batch [20]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.076494,	
2017-07-21 02:04:24,751 Epoch[82] Batch [30]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.076324,	
2017-07-21 02:04:33,139 Epoch[82] Batch [40]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.074913,	
2017-07-21 02:04:41,383 Epoch[82] Batch [50]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.074429,	
2017-07-21 02:04:49,521 Epoch[82] Batch [60]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.073781,	
2017-07-21 02:04:58,117 Epoch[82] Batch [70]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.075174,	
2017-07-21 02:05:06,319 Epoch[82] Batch [80]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.075300,	
2017-07-21 02:05:14,411 Epoch[82] Batch [90]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.074994,	
2017-07-21 02:05:22,521 Epoch[82] Batch [100]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.075854,	
2017-07-21 02:05:30,668 Epoch[82] Batch [110]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.075291,	
2017-07-21 02:05:38,750 Epoch[82] Batch [120]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.076006,	
2017-07-21 02:05:47,186 Epoch[82] Batch [130]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.075843,	
2017-07-21 02:05:55,582 Epoch[82] Batch [140]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.076189,	
2017-07-21 02:06:03,848 Epoch[82] Batch [150]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.075825,	
2017-07-21 02:06:12,128 Epoch[82] Batch [160]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.076185,	
2017-07-21 02:06:20,492 Epoch[82] Batch [170]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.076017,	
2017-07-21 02:06:29,182 Epoch[82] Batch [180]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.075768,	
2017-07-21 02:06:37,644 Epoch[82] Batch [190]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.076030,	
2017-07-21 02:06:45,959 Epoch[82] Batch [200]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.076213,	
2017-07-21 02:06:54,247 Epoch[82] Batch [210]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.075740,	
2017-07-21 02:07:02,720 Epoch[82] Batch [220]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.075740,	
2017-07-21 02:07:10,848 Epoch[82] Batch [230]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.075663,	
2017-07-21 02:07:19,070 Epoch[82] Batch [240]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.075882,	
2017-07-21 02:07:27,078 Epoch[82] Batch [250]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.075787,	
2017-07-21 02:07:35,241 Epoch[82] Batch [260]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.075559,	
2017-07-21 02:07:43,784 Epoch[82] Batch [270]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.075661,	
2017-07-21 02:07:51,703 Epoch[82] Batch [280]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.075814,	
2017-07-21 02:07:59,463 Epoch[82] Batch [290]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.075739,	
2017-07-21 02:08:07,786 Epoch[82] Batch [300]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.075698,	
2017-07-21 02:08:15,938 Epoch[82] Batch [310]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.075973,	
2017-07-21 02:08:24,171 Epoch[82] Batch [320]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.076105,	
2017-07-21 02:08:32,407 Epoch[82] Batch [330]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.076098,	
2017-07-21 02:08:40,637 Epoch[82] Batch [340]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.076189,	
2017-07-21 02:08:48,930 Epoch[82] Batch [350]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.076095,	
2017-07-21 02:08:56,903 Epoch[82] Batch [360]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.076225,	
2017-07-21 02:09:05,154 Epoch[82] Batch [370]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.076169,	
2017-07-21 02:09:13,468 Epoch[82] Batch [380]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.076238,	
2017-07-21 02:09:21,868 Epoch[82] Batch [390]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.076311,	
2017-07-21 02:09:30,034 Epoch[82] Batch [400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.076085,	
2017-07-21 02:09:38,210 Epoch[82] Batch [410]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.076234,	
2017-07-21 02:09:46,676 Epoch[82] Batch [420]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.075975,	
2017-07-21 02:09:55,109 Epoch[82] Batch [430]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.075911,	
2017-07-21 02:10:03,478 Epoch[82] Batch [440]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.076051,	
2017-07-21 02:10:11,824 Epoch[82] Batch [450]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076153,	
2017-07-21 02:10:20,298 Epoch[82] Batch [460]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.076175,	
2017-07-21 02:10:28,830 Epoch[82] Batch [470]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.076224,	
2017-07-21 02:10:37,446 Epoch[82] Batch [480]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076115,	
2017-07-21 02:10:45,819 Epoch[82] Batch [490]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.076287,	
2017-07-21 02:10:54,200 Epoch[82] Batch [500]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.076219,	
2017-07-21 02:11:02,739 Epoch[82] Batch [510]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.076169,	
2017-07-21 02:11:11,093 Epoch[82] Batch [520]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.076159,	
2017-07-21 02:11:19,584 Epoch[82] Batch [530]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.076115,	
2017-07-21 02:11:27,181 Epoch[82] Batch [540]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.076176,	
2017-07-21 02:11:34,877 Epoch[82] Batch [550]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.076341,	
2017-07-21 02:11:42,701 Epoch[82] Batch [560]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.076331,	
2017-07-21 02:11:50,258 Epoch[82] Batch [570]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.076204,	
2017-07-21 02:11:57,826 Epoch[82] Batch [580]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.076357,	
2017-07-21 02:12:05,405 Epoch[82] Batch [590]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.076412,	
2017-07-21 02:12:12,830 Epoch[82] Batch [600]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.076381,	
2017-07-21 02:12:20,202 Epoch[82] Batch [610]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.076416,	
2017-07-21 02:12:28,426 Epoch[82] Batch [620]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.076241,	
2017-07-21 02:12:37,066 Epoch[82] Batch [630]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.076356,	
2017-07-21 02:12:45,115 Epoch[82] Batch [640]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.076447,	
2017-07-21 02:12:53,311 Epoch[82] Batch [650]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.076419,	
2017-07-21 02:13:02,043 Epoch[82] Batch [660]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076346,	
2017-07-21 02:13:11,468 Epoch[82] Batch [670]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.076292,	
2017-07-21 02:13:20,561 Epoch[82] Batch [680]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.076294,	
2017-07-21 02:13:29,247 Epoch[82] Batch [690]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.076195,	
2017-07-21 02:13:37,729 Epoch[82] Batch [700]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.076231,	
2017-07-21 02:13:45,964 Epoch[82] Batch [710]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.076281,	
2017-07-21 02:13:54,257 Epoch[82] Batch [720]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.076381,	
2017-07-21 02:14:02,990 Epoch[82] Batch [730]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076337,	
2017-07-21 02:14:11,731 Epoch[82] Batch [740]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076179,	
2017-07-21 02:14:20,495 Epoch[82] Batch [750]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.076193,	
2017-07-21 02:14:29,222 Epoch[82] Batch [760]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076196,	
2017-07-21 02:14:37,924 Epoch[82] Batch [770]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.076228,	
2017-07-21 02:14:46,656 Epoch[82] Batch [780]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076300,	
2017-07-21 02:14:55,425 Epoch[82] Batch [790]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.076336,	
2017-07-21 02:15:04,272 Epoch[82] Batch [800]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.076352,	
2017-07-21 02:15:13,244 Epoch[82] Batch [810]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.076315,	
2017-07-21 02:15:21,893 Epoch[82] Batch [820]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.076380,	
2017-07-21 02:15:30,511 Epoch[82] Batch [830]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076322,	
2017-07-21 02:15:39,014 Epoch[82] Batch [840]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.076391,	
2017-07-21 02:15:47,595 Epoch[82] Batch [850]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076440,	
2017-07-21 02:15:56,373 Epoch[82] Batch [860]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.076531,	
2017-07-21 02:16:05,136 Epoch[82] Batch [870]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.076577,	
2017-07-21 02:16:13,724 Epoch[82] Batch [880]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076608,	
2017-07-21 02:16:22,333 Epoch[82] Batch [890]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.076620,	
2017-07-21 02:16:31,068 Epoch[82] Batch [900]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076599,	
2017-07-21 02:16:39,895 Epoch[82] Batch [910]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.076660,	
2017-07-21 02:16:48,630 Epoch[82] Batch [920]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.076651,	
2017-07-21 02:16:57,649 Epoch[82] Batch [930]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.076579,	
2017-07-21 02:17:06,535 Epoch[82] Batch [940]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.076530,	
2017-07-21 02:17:15,335 Epoch[82] Batch [950]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.076464,	
2017-07-21 02:17:23,913 Epoch[82] Batch [960]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.076491,	
2017-07-21 02:17:32,781 Epoch[82] Batch [970]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.076574,	
2017-07-21 02:17:41,601 Epoch[82] Batch [980]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.076562,	
2017-07-21 02:17:50,452 Epoch[82] Batch [990]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.076645,	
2017-07-21 02:17:59,051 Epoch[82] Batch [1000]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.076580,	
2017-07-21 02:18:07,668 Epoch[82] Batch [1010]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076556,	
2017-07-21 02:18:16,288 Epoch[82] Batch [1020]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076548,	
2017-07-21 02:18:24,898 Epoch[82] Batch [1030]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.076606,	
2017-07-21 02:18:33,520 Epoch[82] Batch [1040]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076572,	
2017-07-21 02:18:42,169 Epoch[82] Batch [1050]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.076530,	
2017-07-21 02:18:50,940 Epoch[82] Batch [1060]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.076559,	
2017-07-21 02:18:59,211 Epoch[82] Batch [1070]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.076620,	
2017-07-21 02:19:07,823 Epoch[82] Batch [1080]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.076548,	
2017-07-21 02:19:16,370 Epoch[82] Batch [1090]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.076608,	
2017-07-21 02:19:24,757 Epoch[82] Batch [1100]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.076620,	
2017-07-21 02:19:32,952 Epoch[82] Batch [1110]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.076583,	
2017-07-21 02:19:41,434 Epoch[82] Batch [1120]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.076582,	
2017-07-21 02:19:47,151 Epoch[82] Batch [1130]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.076529,	
2017-07-21 02:19:51,390 Epoch[82] Batch [1140]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.076506,	
2017-07-21 02:19:55,742 Epoch[82] Batch [1150]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.076540,	
2017-07-21 02:20:00,122 Epoch[82] Batch [1160]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.076482,	
2017-07-21 02:20:04,644 Epoch[82] Batch [1170]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.076534,	
2017-07-21 02:20:09,242 Epoch[82] Batch [1180]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.076442,	
2017-07-21 02:20:14,067 Epoch[82] Batch [1190]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.076444,	
2017-07-21 02:20:18,725 Epoch[82] Batch [1200]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.076419,	
2017-07-21 02:20:23,284 Epoch[82] Batch [1210]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.076485,	
2017-07-21 02:20:27,578 Epoch[82] Batch [1220]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.076489,	
2017-07-21 02:20:31,875 Epoch[82] Batch [1230]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.076519,	
2017-07-21 02:20:36,470 Epoch[82] Batch [1240]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.076536,	
2017-07-21 02:20:41,512 Epoch[82] Batch [1250]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.076539,	
2017-07-21 02:20:46,564 Epoch[82] Batch [1260]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.076566,	
2017-07-21 02:20:51,131 Epoch[82] Batch [1270]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.076595,	
2017-07-21 02:20:55,985 Epoch[82] Batch [1280]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.076560,	
2017-07-21 02:21:01,224 Epoch[82] Batch [1290]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.076568,	
2017-07-21 02:21:06,212 Epoch[82] Batch [1300]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.076598,	
2017-07-21 02:21:10,911 Epoch[82] Batch [1310]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.076673,	
2017-07-21 02:21:15,196 Epoch[82] Batch [1320]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.076749,	
2017-07-21 02:21:19,701 Epoch[82] Batch [1330]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.076702,	
2017-07-21 02:21:23,824 Epoch[82] Batch [1340]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.076721,	
2017-07-21 02:21:28,076 Epoch[82] Batch [1350]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076665,	
2017-07-21 02:21:32,447 Epoch[82] Batch [1360]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.076627,	
2017-07-21 02:21:36,680 Epoch[82] Batch [1370]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.076586,	
2017-07-21 02:21:41,283 Epoch[82] Batch [1380]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.076630,	
2017-07-21 02:21:45,788 Epoch[82] Batch [1390]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.076648,	
2017-07-21 02:21:49,957 Epoch[82] Batch [1400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.076691,	
2017-07-21 02:21:54,304 Epoch[82] Batch [1410]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.076637,	
2017-07-21 02:21:58,442 Epoch[82] Batch [1420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.076585,	
2017-07-21 02:22:02,583 Epoch[82] Batch [1430]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.076572,	
2017-07-21 02:22:06,856 Epoch[82] Batch [1440]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.076536,	
2017-07-21 02:22:11,075 Epoch[82] Batch [1450]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.076512,	
2017-07-21 02:22:15,433 Epoch[82] Batch [1460]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.076490,	
2017-07-21 02:22:19,524 Epoch[82] Batch [1470]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.076462,	
2017-07-21 02:22:23,780 Epoch[82] Batch [1480]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076431,	
2017-07-21 02:22:26,437 Epoch[82] Train-FCNLogLoss=0.076462
2017-07-21 02:22:26,438 Epoch[82] Time cost=1108.334
2017-07-21 02:22:27,094 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0083.params"
2017-07-21 02:22:31,309 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0083.states"
2017-07-21 02:22:36,225 Epoch[83] Batch [10]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.074184,	
2017-07-21 02:22:40,490 Epoch[83] Batch [20]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.076517,	
2017-07-21 02:22:44,628 Epoch[83] Batch [30]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.078117,	
2017-07-21 02:22:48,888 Epoch[83] Batch [40]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.075556,	
2017-07-21 02:22:53,094 Epoch[83] Batch [50]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075224,	
2017-07-21 02:22:57,264 Epoch[83] Batch [60]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.075702,	
2017-07-21 02:23:01,548 Epoch[83] Batch [70]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.074803,	
2017-07-21 02:23:05,808 Epoch[83] Batch [80]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.075333,	
2017-07-21 02:23:10,099 Epoch[83] Batch [90]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075061,	
2017-07-21 02:23:14,169 Epoch[83] Batch [100]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.075018,	
2017-07-21 02:23:18,398 Epoch[83] Batch [110]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.075072,	
2017-07-21 02:23:22,672 Epoch[83] Batch [120]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.076486,	
2017-07-21 02:23:27,075 Epoch[83] Batch [130]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076388,	
2017-07-21 02:23:31,216 Epoch[83] Batch [140]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.076423,	
2017-07-21 02:23:35,503 Epoch[83] Batch [150]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.076954,	
2017-07-21 02:23:39,796 Epoch[83] Batch [160]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.076653,	
2017-07-21 02:23:44,029 Epoch[83] Batch [170]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.077092,	
2017-07-21 02:23:48,314 Epoch[83] Batch [180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.076689,	
2017-07-21 02:23:52,475 Epoch[83] Batch [190]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.076198,	
2017-07-21 02:23:56,745 Epoch[83] Batch [200]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.076088,	
2017-07-21 02:24:00,980 Epoch[83] Batch [210]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.076552,	
2017-07-21 02:24:05,248 Epoch[83] Batch [220]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.076873,	
2017-07-21 02:24:09,609 Epoch[83] Batch [230]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.076538,	
2017-07-21 02:24:14,043 Epoch[83] Batch [240]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.076307,	
2017-07-21 02:24:18,087 Epoch[83] Batch [250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.076380,	
2017-07-21 02:24:22,206 Epoch[83] Batch [260]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.076498,	
2017-07-21 02:24:26,621 Epoch[83] Batch [270]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.076484,	
2017-07-21 02:24:30,750 Epoch[83] Batch [280]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.076793,	
2017-07-21 02:24:35,406 Epoch[83] Batch [290]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.076787,	
2017-07-21 02:24:39,733 Epoch[83] Batch [300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.076739,	
2017-07-21 02:24:44,190 Epoch[83] Batch [310]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.076651,	
2017-07-21 02:24:48,546 Epoch[83] Batch [320]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.076713,	
2017-07-21 02:24:52,872 Epoch[83] Batch [330]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.076607,	
2017-07-21 02:24:57,129 Epoch[83] Batch [340]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076536,	
2017-07-21 02:25:01,255 Epoch[83] Batch [350]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.076457,	
2017-07-21 02:25:05,465 Epoch[83] Batch [360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.076596,	
2017-07-21 02:25:09,562 Epoch[83] Batch [370]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.076612,	
2017-07-21 02:25:13,939 Epoch[83] Batch [380]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.076623,	
2017-07-21 02:25:18,289 Epoch[83] Batch [390]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.076515,	
2017-07-21 02:25:22,820 Epoch[83] Batch [400]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.076356,	
2017-07-21 02:25:27,091 Epoch[83] Batch [410]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.076422,	
2017-07-21 02:25:31,699 Epoch[83] Batch [420]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076486,	
2017-07-21 02:25:35,943 Epoch[83] Batch [430]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.076450,	
2017-07-21 02:25:40,232 Epoch[83] Batch [440]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.076507,	
2017-07-21 02:25:44,744 Epoch[83] Batch [450]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.076509,	
2017-07-21 02:25:49,187 Epoch[83] Batch [460]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.076460,	
2017-07-21 02:25:53,971 Epoch[83] Batch [470]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.076425,	
2017-07-21 02:25:58,994 Epoch[83] Batch [480]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.076350,	
2017-07-21 02:26:03,880 Epoch[83] Batch [490]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076254,	
2017-07-21 02:26:08,741 Epoch[83] Batch [500]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.076302,	
2017-07-21 02:26:13,519 Epoch[83] Batch [510]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.076261,	
2017-07-21 02:26:17,904 Epoch[83] Batch [520]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076271,	
2017-07-21 02:26:22,157 Epoch[83] Batch [530]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076213,	
2017-07-21 02:26:26,430 Epoch[83] Batch [540]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.076390,	
2017-07-21 02:26:30,876 Epoch[83] Batch [550]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.076461,	
2017-07-21 02:26:35,079 Epoch[83] Batch [560]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.076247,	
2017-07-21 02:26:39,447 Epoch[83] Batch [570]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.076267,	
2017-07-21 02:26:43,681 Epoch[83] Batch [580]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.076319,	
2017-07-21 02:26:48,249 Epoch[83] Batch [590]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.076300,	
2017-07-21 02:26:52,651 Epoch[83] Batch [600]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076203,	
2017-07-21 02:26:56,871 Epoch[83] Batch [610]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.076225,	
2017-07-21 02:27:01,551 Epoch[83] Batch [620]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.076284,	
2017-07-21 02:27:05,973 Epoch[83] Batch [630]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.076315,	
2017-07-21 02:27:10,343 Epoch[83] Batch [640]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.076350,	
2017-07-21 02:27:15,372 Epoch[83] Batch [650]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.076377,	
2017-07-21 02:27:19,546 Epoch[83] Batch [660]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.076327,	
2017-07-21 02:27:24,378 Epoch[83] Batch [670]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.076277,	
2017-07-21 02:27:29,262 Epoch[83] Batch [680]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076251,	
2017-07-21 02:27:33,846 Epoch[83] Batch [690]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.076305,	
2017-07-21 02:27:38,297 Epoch[83] Batch [700]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.076403,	
2017-07-21 02:27:42,355 Epoch[83] Batch [710]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.076513,	
2017-07-21 02:27:46,758 Epoch[83] Batch [720]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076524,	
2017-07-21 02:27:51,175 Epoch[83] Batch [730]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.076540,	
2017-07-21 02:27:55,571 Epoch[83] Batch [740]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.076417,	
2017-07-21 02:27:59,829 Epoch[83] Batch [750]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.076649,	
2017-07-21 02:28:03,996 Epoch[83] Batch [760]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.076589,	
2017-07-21 02:28:08,298 Epoch[83] Batch [770]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.076549,	
2017-07-21 02:28:12,493 Epoch[83] Batch [780]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.076529,	
2017-07-21 02:28:16,828 Epoch[83] Batch [790]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.076488,	
2017-07-21 02:28:21,006 Epoch[83] Batch [800]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.076447,	
2017-07-21 02:28:25,217 Epoch[83] Batch [810]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.076437,	
2017-07-21 02:28:29,417 Epoch[83] Batch [820]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.076513,	
2017-07-21 02:28:33,716 Epoch[83] Batch [830]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.076538,	
2017-07-21 02:28:38,090 Epoch[83] Batch [840]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.076539,	
2017-07-21 02:28:42,451 Epoch[83] Batch [850]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.076549,	
2017-07-21 02:28:47,028 Epoch[83] Batch [860]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.076539,	
2017-07-21 02:28:51,485 Epoch[83] Batch [870]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.076517,	
2017-07-21 02:28:56,437 Epoch[83] Batch [880]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.076485,	
2017-07-21 02:29:00,983 Epoch[83] Batch [890]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.076478,	
2017-07-21 02:29:05,761 Epoch[83] Batch [900]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.076424,	
2017-07-21 02:29:10,441 Epoch[83] Batch [910]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.076437,	
2017-07-21 02:29:15,145 Epoch[83] Batch [920]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076441,	
2017-07-21 02:29:19,869 Epoch[83] Batch [930]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.076462,	
2017-07-21 02:29:24,341 Epoch[83] Batch [940]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.076491,	
2017-07-21 02:29:28,600 Epoch[83] Batch [950]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.076421,	
2017-07-21 02:29:32,842 Epoch[83] Batch [960]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.076504,	
2017-07-21 02:29:37,161 Epoch[83] Batch [970]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.076469,	
2017-07-21 02:29:41,363 Epoch[83] Batch [980]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.076534,	
2017-07-21 02:29:45,487 Epoch[83] Batch [990]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.076473,	
2017-07-21 02:29:50,268 Epoch[83] Batch [1000]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.076495,	
2017-07-21 02:29:54,694 Epoch[83] Batch [1010]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.076438,	
2017-07-21 02:29:59,794 Epoch[83] Batch [1020]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.076474,	
2017-07-21 02:30:04,887 Epoch[83] Batch [1030]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.076512,	
2017-07-21 02:30:10,181 Epoch[83] Batch [1040]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.076552,	
2017-07-21 02:30:15,137 Epoch[83] Batch [1050]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.076593,	
2017-07-21 02:30:19,705 Epoch[83] Batch [1060]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.076581,	
2017-07-21 02:30:24,600 Epoch[83] Batch [1070]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.076533,	
2017-07-21 02:30:29,483 Epoch[83] Batch [1080]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076514,	
2017-07-21 02:30:33,958 Epoch[83] Batch [1090]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.076491,	
2017-07-21 02:30:38,598 Epoch[83] Batch [1100]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.076604,	
2017-07-21 02:30:43,177 Epoch[83] Batch [1110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.076600,	
2017-07-21 02:30:47,475 Epoch[83] Batch [1120]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.076542,	
2017-07-21 02:30:51,920 Epoch[83] Batch [1130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.076557,	
2017-07-21 02:30:56,381 Epoch[83] Batch [1140]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.076507,	
2017-07-21 02:31:00,793 Epoch[83] Batch [1150]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.076420,	
2017-07-21 02:31:05,246 Epoch[83] Batch [1160]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.076434,	
2017-07-21 02:31:09,510 Epoch[83] Batch [1170]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.076431,	
2017-07-21 02:31:13,859 Epoch[83] Batch [1180]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.076398,	
2017-07-21 02:31:18,837 Epoch[83] Batch [1190]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.076376,	
2017-07-21 02:31:23,372 Epoch[83] Batch [1200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.076302,	
2017-07-21 02:31:27,816 Epoch[83] Batch [1210]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.076302,	
2017-07-21 02:31:32,161 Epoch[83] Batch [1220]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.076297,	
2017-07-21 02:31:36,554 Epoch[83] Batch [1230]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.076246,	
2017-07-21 02:31:40,827 Epoch[83] Batch [1240]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.076217,	
2017-07-21 02:31:45,359 Epoch[83] Batch [1250]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.076213,	
2017-07-21 02:31:49,754 Epoch[83] Batch [1260]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.076170,	
2017-07-21 02:31:54,104 Epoch[83] Batch [1270]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.076183,	
2017-07-21 02:31:58,806 Epoch[83] Batch [1280]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.076167,	
2017-07-21 02:32:04,024 Epoch[83] Batch [1290]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.076203,	
2017-07-21 02:32:08,319 Epoch[83] Batch [1300]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.076243,	
2017-07-21 02:32:12,764 Epoch[83] Batch [1310]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.076217,	
2017-07-21 02:32:17,129 Epoch[83] Batch [1320]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.076264,	
2017-07-21 02:32:21,368 Epoch[83] Batch [1330]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.076272,	
2017-07-21 02:32:25,508 Epoch[83] Batch [1340]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.076328,	
2017-07-21 02:32:29,723 Epoch[83] Batch [1350]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.076260,	
2017-07-21 02:32:33,807 Epoch[83] Batch [1360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.076308,	
2017-07-21 02:32:37,983 Epoch[83] Batch [1370]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.076292,	
2017-07-21 02:32:42,336 Epoch[83] Batch [1380]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.076255,	
2017-07-21 02:32:46,959 Epoch[83] Batch [1390]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.076205,	
2017-07-21 02:32:51,328 Epoch[83] Batch [1400]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.076275,	
2017-07-21 02:32:55,527 Epoch[83] Batch [1410]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.076302,	
2017-07-21 02:32:59,693 Epoch[83] Batch [1420]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.076277,	
2017-07-21 02:33:04,078 Epoch[83] Batch [1430]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076263,	
2017-07-21 02:33:08,269 Epoch[83] Batch [1440]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.076311,	
2017-07-21 02:33:12,650 Epoch[83] Batch [1450]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.076306,	
2017-07-21 02:33:16,903 Epoch[83] Batch [1460]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076311,	
2017-07-21 02:33:21,213 Epoch[83] Batch [1470]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.076350,	
2017-07-21 02:33:25,403 Epoch[83] Batch [1480]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.076222,	
2017-07-21 02:33:27,987 Epoch[83] Train-FCNLogLoss=0.076204
2017-07-21 02:33:27,987 Epoch[83] Time cost=656.678
2017-07-21 02:33:28,670 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0084.params"
2017-07-21 02:33:32,847 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0084.states"
2017-07-21 02:33:38,030 Epoch[84] Batch [10]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.074404,	
2017-07-21 02:33:42,770 Epoch[84] Batch [20]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076777,	
2017-07-21 02:33:47,156 Epoch[84] Batch [30]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076992,	
2017-07-21 02:33:51,684 Epoch[84] Batch [40]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.077444,	
2017-07-21 02:33:56,150 Epoch[84] Batch [50]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.077384,	
2017-07-21 02:34:00,527 Epoch[84] Batch [60]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.076948,	
2017-07-21 02:34:05,121 Epoch[84] Batch [70]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.076528,	
2017-07-21 02:34:09,461 Epoch[84] Batch [80]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.077065,	
2017-07-21 02:34:13,804 Epoch[84] Batch [90]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.076663,	
2017-07-21 02:34:18,144 Epoch[84] Batch [100]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.076265,	
2017-07-21 02:34:22,438 Epoch[84] Batch [110]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.076012,	
2017-07-21 02:34:26,751 Epoch[84] Batch [120]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075996,	
2017-07-21 02:34:31,068 Epoch[84] Batch [130]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.076279,	
2017-07-21 02:34:35,320 Epoch[84] Batch [140]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.075861,	
2017-07-21 02:34:39,798 Epoch[84] Batch [150]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.076094,	
2017-07-21 02:34:44,412 Epoch[84] Batch [160]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.076039,	
2017-07-21 02:34:48,785 Epoch[84] Batch [170]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.075751,	
2017-07-21 02:34:53,463 Epoch[84] Batch [180]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075771,	
2017-07-21 02:34:58,301 Epoch[84] Batch [190]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.076024,	
2017-07-21 02:35:03,111 Epoch[84] Batch [200]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.075731,	
2017-07-21 02:35:07,811 Epoch[84] Batch [210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.075819,	
2017-07-21 02:35:12,352 Epoch[84] Batch [220]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075539,	
2017-07-21 02:35:17,193 Epoch[84] Batch [230]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075462,	
2017-07-21 02:35:21,566 Epoch[84] Batch [240]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.075536,	
2017-07-21 02:35:26,530 Epoch[84] Batch [250]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.075511,	
2017-07-21 02:35:31,096 Epoch[84] Batch [260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075617,	
2017-07-21 02:35:35,736 Epoch[84] Batch [270]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.075503,	
2017-07-21 02:35:40,104 Epoch[84] Batch [280]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.075707,	
2017-07-21 02:35:44,839 Epoch[84] Batch [290]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.075697,	
2017-07-21 02:35:49,335 Epoch[84] Batch [300]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075655,	
2017-07-21 02:35:54,074 Epoch[84] Batch [310]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075711,	
2017-07-21 02:35:58,933 Epoch[84] Batch [320]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075544,	
2017-07-21 02:36:03,535 Epoch[84] Batch [330]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075428,	
2017-07-21 02:36:08,266 Epoch[84] Batch [340]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.075483,	
2017-07-21 02:36:12,646 Epoch[84] Batch [350]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075633,	
2017-07-21 02:36:16,963 Epoch[84] Batch [360]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075540,	
2017-07-21 02:36:21,302 Epoch[84] Batch [370]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.075600,	
2017-07-21 02:36:25,840 Epoch[84] Batch [380]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075572,	
2017-07-21 02:36:30,071 Epoch[84] Batch [390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.075694,	
2017-07-21 02:36:34,395 Epoch[84] Batch [400]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075794,	
2017-07-21 02:36:38,583 Epoch[84] Batch [410]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.075883,	
2017-07-21 02:36:43,079 Epoch[84] Batch [420]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.076046,	
2017-07-21 02:36:47,330 Epoch[84] Batch [430]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076055,	
2017-07-21 02:36:51,609 Epoch[84] Batch [440]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.075911,	
2017-07-21 02:36:55,930 Epoch[84] Batch [450]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075900,	
2017-07-21 02:37:00,258 Epoch[84] Batch [460]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075847,	
2017-07-21 02:37:04,845 Epoch[84] Batch [470]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075920,	
2017-07-21 02:37:09,314 Epoch[84] Batch [480]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075936,	
2017-07-21 02:37:13,625 Epoch[84] Batch [490]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.076015,	
2017-07-21 02:37:17,992 Epoch[84] Batch [500]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.076000,	
2017-07-21 02:37:22,356 Epoch[84] Batch [510]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.076066,	
2017-07-21 02:37:26,713 Epoch[84] Batch [520]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.076106,	
2017-07-21 02:37:31,077 Epoch[84] Batch [530]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.076130,	
2017-07-21 02:37:35,474 Epoch[84] Batch [540]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.076053,	
2017-07-21 02:37:39,943 Epoch[84] Batch [550]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.076157,	
2017-07-21 02:37:44,527 Epoch[84] Batch [560]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.076293,	
2017-07-21 02:37:48,919 Epoch[84] Batch [570]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.076222,	
2017-07-21 02:37:53,418 Epoch[84] Batch [580]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.076213,	
2017-07-21 02:37:57,685 Epoch[84] Batch [590]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.076060,	
2017-07-21 02:38:02,002 Epoch[84] Batch [600]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.076018,	
2017-07-21 02:38:06,489 Epoch[84] Batch [610]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075974,	
2017-07-21 02:38:10,790 Epoch[84] Batch [620]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.075980,	
2017-07-21 02:38:15,350 Epoch[84] Batch [630]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075948,	
2017-07-21 02:38:19,842 Epoch[84] Batch [640]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.076037,	
2017-07-21 02:38:23,884 Epoch[84] Batch [650]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.076003,	
2017-07-21 02:38:28,096 Epoch[84] Batch [660]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.075962,	
2017-07-21 02:38:32,625 Epoch[84] Batch [670]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.075935,	
2017-07-21 02:38:37,090 Epoch[84] Batch [680]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.076032,	
2017-07-21 02:38:41,252 Epoch[84] Batch [690]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.076176,	
2017-07-21 02:38:45,655 Epoch[84] Batch [700]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076191,	
2017-07-21 02:38:49,972 Epoch[84] Batch [710]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.076169,	
2017-07-21 02:38:54,244 Epoch[84] Batch [720]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.076151,	
2017-07-21 02:38:58,890 Epoch[84] Batch [730]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.076091,	
2017-07-21 02:39:03,258 Epoch[84] Batch [740]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.076090,	
2017-07-21 02:39:07,720 Epoch[84] Batch [750]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.076060,	
2017-07-21 02:39:11,750 Epoch[84] Batch [760]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.076024,	
2017-07-21 02:39:15,894 Epoch[84] Batch [770]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.076019,	
2017-07-21 02:39:20,177 Epoch[84] Batch [780]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075893,	
2017-07-21 02:39:24,490 Epoch[84] Batch [790]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075932,	
2017-07-21 02:39:28,751 Epoch[84] Batch [800]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.075828,	
2017-07-21 02:39:32,867 Epoch[84] Batch [810]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.075757,	
2017-07-21 02:39:37,074 Epoch[84] Batch [820]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075632,	
2017-07-21 02:39:41,140 Epoch[84] Batch [830]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.075672,	
2017-07-21 02:39:45,415 Epoch[84] Batch [840]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075681,	
2017-07-21 02:39:49,661 Epoch[84] Batch [850]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.075628,	
2017-07-21 02:39:54,282 Epoch[84] Batch [860]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.075557,	
2017-07-21 02:39:58,769 Epoch[84] Batch [870]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075576,	
2017-07-21 02:40:03,263 Epoch[84] Batch [880]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075525,	
2017-07-21 02:40:07,702 Epoch[84] Batch [890]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075555,	
2017-07-21 02:40:12,615 Epoch[84] Batch [900]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075548,	
2017-07-21 02:40:17,042 Epoch[84] Batch [910]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075596,	
2017-07-21 02:40:21,456 Epoch[84] Batch [920]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075599,	
2017-07-21 02:40:25,634 Epoch[84] Batch [930]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.075668,	
2017-07-21 02:40:29,642 Epoch[84] Batch [940]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.075615,	
2017-07-21 02:40:33,741 Epoch[84] Batch [950]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.075513,	
2017-07-21 02:40:38,063 Epoch[84] Batch [960]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075576,	
2017-07-21 02:40:42,455 Epoch[84] Batch [970]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075662,	
2017-07-21 02:40:46,503 Epoch[84] Batch [980]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.075707,	
2017-07-21 02:40:50,768 Epoch[84] Batch [990]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075587,	
2017-07-21 02:40:55,122 Epoch[84] Batch [1000]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075498,	
2017-07-21 02:40:59,700 Epoch[84] Batch [1010]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075448,	
2017-07-21 02:41:04,077 Epoch[84] Batch [1020]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075492,	
2017-07-21 02:41:08,301 Epoch[84] Batch [1030]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075437,	
2017-07-21 02:41:12,471 Epoch[84] Batch [1040]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.075544,	
2017-07-21 02:41:16,608 Epoch[84] Batch [1050]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.075479,	
2017-07-21 02:41:21,226 Epoch[84] Batch [1060]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.075452,	
2017-07-21 02:41:25,815 Epoch[84] Batch [1070]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075461,	
2017-07-21 02:41:30,271 Epoch[84] Batch [1080]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075432,	
2017-07-21 02:41:34,742 Epoch[84] Batch [1090]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075372,	
2017-07-21 02:41:38,846 Epoch[84] Batch [1100]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.075376,	
2017-07-21 02:41:43,000 Epoch[84] Batch [1110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.075423,	
2017-07-21 02:41:47,504 Epoch[84] Batch [1120]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.075376,	
2017-07-21 02:41:51,780 Epoch[84] Batch [1130]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.075277,	
2017-07-21 02:41:56,193 Epoch[84] Batch [1140]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075312,	
2017-07-21 02:42:00,539 Epoch[84] Batch [1150]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.075304,	
2017-07-21 02:42:04,747 Epoch[84] Batch [1160]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075322,	
2017-07-21 02:42:09,332 Epoch[84] Batch [1170]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075379,	
2017-07-21 02:42:13,628 Epoch[84] Batch [1180]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.075454,	
2017-07-21 02:42:17,708 Epoch[84] Batch [1190]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.075504,	
2017-07-21 02:42:22,109 Epoch[84] Batch [1200]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075551,	
2017-07-21 02:42:26,386 Epoch[84] Batch [1210]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.075558,	
2017-07-21 02:42:30,659 Epoch[84] Batch [1220]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075539,	
2017-07-21 02:42:35,021 Epoch[84] Batch [1230]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075582,	
2017-07-21 02:42:39,614 Epoch[84] Batch [1240]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.075601,	
2017-07-21 02:42:44,391 Epoch[84] Batch [1250]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075625,	
2017-07-21 02:42:48,839 Epoch[84] Batch [1260]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075643,	
2017-07-21 02:42:53,360 Epoch[84] Batch [1270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075647,	
2017-07-21 02:42:58,198 Epoch[84] Batch [1280]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075627,	
2017-07-21 02:43:03,074 Epoch[84] Batch [1290]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075615,	
2017-07-21 02:43:07,961 Epoch[84] Batch [1300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.075562,	
2017-07-21 02:43:12,599 Epoch[84] Batch [1310]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.075618,	
2017-07-21 02:43:17,203 Epoch[84] Batch [1320]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075691,	
2017-07-21 02:43:21,896 Epoch[84] Batch [1330]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075713,	
2017-07-21 02:43:26,385 Epoch[84] Batch [1340]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075690,	
2017-07-21 02:43:30,917 Epoch[84] Batch [1350]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.075729,	
2017-07-21 02:43:35,389 Epoch[84] Batch [1360]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075729,	
2017-07-21 02:43:39,775 Epoch[84] Batch [1370]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075805,	
2017-07-21 02:43:44,323 Epoch[84] Batch [1380]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075821,	
2017-07-21 02:43:48,787 Epoch[84] Batch [1390]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075802,	
2017-07-21 02:43:53,256 Epoch[84] Batch [1400]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075732,	
2017-07-21 02:43:57,531 Epoch[84] Batch [1410]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075676,	
2017-07-21 02:44:01,698 Epoch[84] Batch [1420]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.075714,	
2017-07-21 02:44:06,062 Epoch[84] Batch [1430]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075666,	
2017-07-21 02:44:10,340 Epoch[84] Batch [1440]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.075662,	
2017-07-21 02:44:14,586 Epoch[84] Batch [1450]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.075648,	
2017-07-21 02:44:18,742 Epoch[84] Batch [1460]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.075645,	
2017-07-21 02:44:22,986 Epoch[84] Batch [1470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.075685,	
2017-07-21 02:44:27,374 Epoch[84] Batch [1480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075680,	
2017-07-21 02:44:30,021 Epoch[84] Train-FCNLogLoss=0.075716
2017-07-21 02:44:30,021 Epoch[84] Time cost=657.174
2017-07-21 02:44:31,159 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0085.params"
2017-07-21 02:44:35,547 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0085.states"
2017-07-21 02:44:40,616 Epoch[85] Batch [10]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.067109,	
2017-07-21 02:44:44,853 Epoch[85] Batch [20]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.072070,	
2017-07-21 02:44:49,065 Epoch[85] Batch [30]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.071861,	
2017-07-21 02:44:53,511 Epoch[85] Batch [40]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.073888,	
2017-07-21 02:44:58,013 Epoch[85] Batch [50]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.074626,	
2017-07-21 02:45:02,436 Epoch[85] Batch [60]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.074771,	
2017-07-21 02:45:06,781 Epoch[85] Batch [70]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.076046,	
2017-07-21 02:45:11,537 Epoch[85] Batch [80]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.074763,	
2017-07-21 02:45:16,400 Epoch[85] Batch [90]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.074370,	
2017-07-21 02:45:20,729 Epoch[85] Batch [100]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.074157,	
2017-07-21 02:45:25,361 Epoch[85] Batch [110]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.074255,	
2017-07-21 02:45:29,783 Epoch[85] Batch [120]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.074574,	
2017-07-21 02:45:33,991 Epoch[85] Batch [130]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.074790,	
2017-07-21 02:45:38,154 Epoch[85] Batch [140]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.075195,	
2017-07-21 02:45:42,307 Epoch[85] Batch [150]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.075141,	
2017-07-21 02:45:46,545 Epoch[85] Batch [160]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075208,	
2017-07-21 02:45:50,938 Epoch[85] Batch [170]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075029,	
2017-07-21 02:45:55,331 Epoch[85] Batch [180]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.074572,	
2017-07-21 02:45:59,835 Epoch[85] Batch [190]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.075121,	
2017-07-21 02:46:04,323 Epoch[85] Batch [200]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075216,	
2017-07-21 02:46:08,975 Epoch[85] Batch [210]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075379,	
2017-07-21 02:46:13,208 Epoch[85] Batch [220]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.075156,	
2017-07-21 02:46:17,782 Epoch[85] Batch [230]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.074927,	
2017-07-21 02:46:22,506 Epoch[85] Batch [240]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.075433,	
2017-07-21 02:46:26,992 Epoch[85] Batch [250]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075460,	
2017-07-21 02:46:31,567 Epoch[85] Batch [260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075319,	
2017-07-21 02:46:36,233 Epoch[85] Batch [270]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075736,	
2017-07-21 02:46:40,705 Epoch[85] Batch [280]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075644,	
2017-07-21 02:46:45,082 Epoch[85] Batch [290]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075502,	
2017-07-21 02:46:49,266 Epoch[85] Batch [300]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.075351,	
2017-07-21 02:46:53,518 Epoch[85] Batch [310]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.075161,	
2017-07-21 02:46:57,772 Epoch[85] Batch [320]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.075159,	
2017-07-21 02:47:01,981 Epoch[85] Batch [330]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.075122,	
2017-07-21 02:47:06,760 Epoch[85] Batch [340]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075170,	
2017-07-21 02:47:11,070 Epoch[85] Batch [350]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075190,	
2017-07-21 02:47:15,653 Epoch[85] Batch [360]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.075498,	
2017-07-21 02:47:20,100 Epoch[85] Batch [370]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075577,	
2017-07-21 02:47:24,241 Epoch[85] Batch [380]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.075505,	
2017-07-21 02:47:28,418 Epoch[85] Batch [390]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.075620,	
2017-07-21 02:47:32,655 Epoch[85] Batch [400]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075549,	
2017-07-21 02:47:36,967 Epoch[85] Batch [410]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075560,	
2017-07-21 02:47:41,267 Epoch[85] Batch [420]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.075736,	
2017-07-21 02:47:45,428 Epoch[85] Batch [430]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.075611,	
2017-07-21 02:47:49,858 Epoch[85] Batch [440]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075832,	
2017-07-21 02:47:54,096 Epoch[85] Batch [450]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075862,	
2017-07-21 02:47:58,822 Epoch[85] Batch [460]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.075591,	
2017-07-21 02:48:03,470 Epoch[85] Batch [470]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075668,	
2017-07-21 02:48:07,703 Epoch[85] Batch [480]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.075739,	
2017-07-21 02:48:12,101 Epoch[85] Batch [490]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.075935,	
2017-07-21 02:48:16,409 Epoch[85] Batch [500]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075777,	
2017-07-21 02:48:21,064 Epoch[85] Batch [510]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075811,	
2017-07-21 02:48:25,794 Epoch[85] Batch [520]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.075597,	
2017-07-21 02:48:29,989 Epoch[85] Batch [530]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.075613,	
2017-07-21 02:48:34,311 Epoch[85] Batch [540]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075519,	
2017-07-21 02:48:39,007 Epoch[85] Batch [550]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075447,	
2017-07-21 02:48:43,472 Epoch[85] Batch [560]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075522,	
2017-07-21 02:48:48,072 Epoch[85] Batch [570]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075499,	
2017-07-21 02:48:52,340 Epoch[85] Batch [580]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.075607,	
2017-07-21 02:48:56,578 Epoch[85] Batch [590]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075531,	
2017-07-21 02:49:01,047 Epoch[85] Batch [600]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075514,	
2017-07-21 02:49:05,675 Epoch[85] Batch [610]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075728,	
2017-07-21 02:49:09,962 Epoch[85] Batch [620]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.075774,	
2017-07-21 02:49:14,286 Epoch[85] Batch [630]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075817,	
2017-07-21 02:49:18,778 Epoch[85] Batch [640]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075839,	
2017-07-21 02:49:23,249 Epoch[85] Batch [650]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075917,	
2017-07-21 02:49:27,736 Epoch[85] Batch [660]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075859,	
2017-07-21 02:49:32,481 Epoch[85] Batch [670]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.075912,	
2017-07-21 02:49:37,253 Epoch[85] Batch [680]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075926,	
2017-07-21 02:49:41,614 Epoch[85] Batch [690]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075911,	
2017-07-21 02:49:46,036 Epoch[85] Batch [700]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075839,	
2017-07-21 02:49:50,338 Epoch[85] Batch [710]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.075794,	
2017-07-21 02:49:54,779 Epoch[85] Batch [720]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075818,	
2017-07-21 02:49:59,652 Epoch[85] Batch [730]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.075929,	
2017-07-21 02:50:04,120 Epoch[85] Batch [740]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.076030,	
2017-07-21 02:50:08,733 Epoch[85] Batch [750]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.076043,	
2017-07-21 02:50:13,159 Epoch[85] Batch [760]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.076020,	
2017-07-21 02:50:17,413 Epoch[85] Batch [770]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076065,	
2017-07-21 02:50:21,644 Epoch[85] Batch [780]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.076036,	
2017-07-21 02:50:25,818 Epoch[85] Batch [790]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.076063,	
2017-07-21 02:50:30,194 Epoch[85] Batch [800]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.076038,	
2017-07-21 02:50:34,344 Epoch[85] Batch [810]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.076066,	
2017-07-21 02:50:38,619 Epoch[85] Batch [820]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.076046,	
2017-07-21 02:50:42,797 Epoch[85] Batch [830]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.076023,	
2017-07-21 02:50:47,227 Epoch[85] Batch [840]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.076002,	
2017-07-21 02:50:51,709 Epoch[85] Batch [850]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.075992,	
2017-07-21 02:50:55,939 Epoch[85] Batch [860]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.076080,	
2017-07-21 02:51:00,509 Epoch[85] Batch [870]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.076071,	
2017-07-21 02:51:05,070 Epoch[85] Batch [880]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.076058,	
2017-07-21 02:51:09,508 Epoch[85] Batch [890]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075966,	
2017-07-21 02:51:13,870 Epoch[85] Batch [900]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075957,	
2017-07-21 02:51:18,419 Epoch[85] Batch [910]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.075923,	
2017-07-21 02:51:23,407 Epoch[85] Batch [920]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.075966,	
2017-07-21 02:51:28,287 Epoch[85] Batch [930]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075988,	
2017-07-21 02:51:32,686 Epoch[85] Batch [940]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075989,	
2017-07-21 02:51:36,925 Epoch[85] Batch [950]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075976,	
2017-07-21 02:51:41,062 Epoch[85] Batch [960]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.076022,	
2017-07-21 02:51:45,293 Epoch[85] Batch [970]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.076052,	
2017-07-21 02:51:49,652 Epoch[85] Batch [980]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.076025,	
2017-07-21 02:51:53,947 Epoch[85] Batch [990]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.076005,	
2017-07-21 02:51:58,299 Epoch[85] Batch [1000]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.076043,	
2017-07-21 02:52:02,556 Epoch[85] Batch [1010]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076096,	
2017-07-21 02:52:06,955 Epoch[85] Batch [1020]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076039,	
2017-07-21 02:52:11,325 Epoch[85] Batch [1030]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.076034,	
2017-07-21 02:52:15,842 Epoch[85] Batch [1040]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.076073,	
2017-07-21 02:52:20,382 Epoch[85] Batch [1050]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.076089,	
2017-07-21 02:52:24,871 Epoch[85] Batch [1060]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.076065,	
2017-07-21 02:52:29,330 Epoch[85] Batch [1070]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.076036,	
2017-07-21 02:52:34,436 Epoch[85] Batch [1080]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.076227,	
2017-07-21 02:52:39,175 Epoch[85] Batch [1090]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076245,	
2017-07-21 02:52:43,972 Epoch[85] Batch [1100]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.076198,	
2017-07-21 02:52:48,311 Epoch[85] Batch [1110]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.076187,	
2017-07-21 02:52:52,920 Epoch[85] Batch [1120]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076238,	
2017-07-21 02:52:57,554 Epoch[85] Batch [1130]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.076274,	
2017-07-21 02:53:02,026 Epoch[85] Batch [1140]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.076282,	
2017-07-21 02:53:06,267 Epoch[85] Batch [1150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.076246,	
2017-07-21 02:53:10,867 Epoch[85] Batch [1160]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.076199,	
2017-07-21 02:53:15,124 Epoch[85] Batch [1170]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076182,	
2017-07-21 02:53:19,386 Epoch[85] Batch [1180]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.076235,	
2017-07-21 02:53:23,654 Epoch[85] Batch [1190]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.076218,	
2017-07-21 02:53:28,105 Epoch[85] Batch [1200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.076147,	
2017-07-21 02:53:32,321 Epoch[85] Batch [1210]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.076106,	
2017-07-21 02:53:36,409 Epoch[85] Batch [1220]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.076111,	
2017-07-21 02:53:40,530 Epoch[85] Batch [1230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.076107,	
2017-07-21 02:53:44,763 Epoch[85] Batch [1240]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.076071,	
2017-07-21 02:53:49,254 Epoch[85] Batch [1250]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.076104,	
2017-07-21 02:53:53,561 Epoch[85] Batch [1260]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.076193,	
2017-07-21 02:53:57,937 Epoch[85] Batch [1270]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.076255,	
2017-07-21 02:54:02,117 Epoch[85] Batch [1280]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.076233,	
2017-07-21 02:54:06,505 Epoch[85] Batch [1290]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076248,	
2017-07-21 02:54:11,228 Epoch[85] Batch [1300]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.076228,	
2017-07-21 02:54:15,491 Epoch[85] Batch [1310]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.076319,	
2017-07-21 02:54:19,812 Epoch[85] Batch [1320]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.076305,	
2017-07-21 02:54:24,197 Epoch[85] Batch [1330]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076403,	
2017-07-21 02:54:28,536 Epoch[85] Batch [1340]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.076386,	
2017-07-21 02:54:33,019 Epoch[85] Batch [1350]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.076368,	
2017-07-21 02:54:37,430 Epoch[85] Batch [1360]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.076399,	
2017-07-21 02:54:41,927 Epoch[85] Batch [1370]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.076426,	
2017-07-21 02:54:46,329 Epoch[85] Batch [1380]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076408,	
2017-07-21 02:54:50,820 Epoch[85] Batch [1390]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.076424,	
2017-07-21 02:54:55,341 Epoch[85] Batch [1400]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.076352,	
2017-07-21 02:54:59,365 Epoch[85] Batch [1410]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.076336,	
2017-07-21 02:55:03,602 Epoch[85] Batch [1420]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.076276,	
2017-07-21 02:55:07,915 Epoch[85] Batch [1430]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.076265,	
2017-07-21 02:55:12,410 Epoch[85] Batch [1440]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.076265,	
2017-07-21 02:55:16,884 Epoch[85] Batch [1450]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.076206,	
2017-07-21 02:55:21,016 Epoch[85] Batch [1460]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.076185,	
2017-07-21 02:55:25,265 Epoch[85] Batch [1470]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076218,	
2017-07-21 02:55:29,518 Epoch[85] Batch [1480]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076198,	
2017-07-21 02:55:31,996 Epoch[85] Train-FCNLogLoss=0.076239
2017-07-21 02:55:31,996 Epoch[85] Time cost=656.449
2017-07-21 02:55:32,654 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0086.params"
2017-07-21 02:55:36,820 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0086.states"
2017-07-21 02:55:43,040 Epoch[86] Batch [10]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.077897,	
2017-07-21 02:55:47,552 Epoch[86] Batch [20]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.078016,	
2017-07-21 02:55:51,969 Epoch[86] Batch [30]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.079196,	
2017-07-21 02:55:56,721 Epoch[86] Batch [40]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.080629,	
2017-07-21 02:56:01,200 Epoch[86] Batch [50]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.078894,	
2017-07-21 02:56:05,768 Epoch[86] Batch [60]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.078016,	
2017-07-21 02:56:10,080 Epoch[86] Batch [70]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.078087,	
2017-07-21 02:56:14,940 Epoch[86] Batch [80]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.077388,	
2017-07-21 02:56:19,583 Epoch[86] Batch [90]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.077225,	
2017-07-21 02:56:24,334 Epoch[86] Batch [100]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.077101,	
2017-07-21 02:56:29,280 Epoch[86] Batch [110]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.077597,	
2017-07-21 02:56:33,640 Epoch[86] Batch [120]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.077356,	
2017-07-21 02:56:37,892 Epoch[86] Batch [130]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076797,	
2017-07-21 02:56:42,705 Epoch[86] Batch [140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.076420,	
2017-07-21 02:56:47,204 Epoch[86] Batch [150]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.076470,	
2017-07-21 02:56:51,408 Epoch[86] Batch [160]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.076326,	
2017-07-21 02:56:55,559 Epoch[86] Batch [170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.076112,	
2017-07-21 02:56:59,794 Epoch[86] Batch [180]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.076016,	
2017-07-21 02:57:04,058 Epoch[86] Batch [190]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075823,	
2017-07-21 02:57:08,271 Epoch[86] Batch [200]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.075467,	
2017-07-21 02:57:12,533 Epoch[86] Batch [210]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075439,	
2017-07-21 02:57:16,758 Epoch[86] Batch [220]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075551,	
2017-07-21 02:57:21,396 Epoch[86] Batch [230]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075605,	
2017-07-21 02:57:25,869 Epoch[86] Batch [240]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075957,	
2017-07-21 02:57:30,358 Epoch[86] Batch [250]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075985,	
2017-07-21 02:57:34,814 Epoch[86] Batch [260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075752,	
2017-07-21 02:57:39,202 Epoch[86] Batch [270]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075951,	
2017-07-21 02:57:43,333 Epoch[86] Batch [280]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.075878,	
2017-07-21 02:57:47,787 Epoch[86] Batch [290]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075861,	
2017-07-21 02:57:52,372 Epoch[86] Batch [300]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.075869,	
2017-07-21 02:57:56,703 Epoch[86] Batch [310]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075940,	
2017-07-21 02:58:01,089 Epoch[86] Batch [320]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075568,	
2017-07-21 02:58:05,966 Epoch[86] Batch [330]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075615,	
2017-07-21 02:58:10,783 Epoch[86] Batch [340]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075530,	
2017-07-21 02:58:14,864 Epoch[86] Batch [350]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.075454,	
2017-07-21 02:58:19,053 Epoch[86] Batch [360]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.075561,	
2017-07-21 02:58:23,462 Epoch[86] Batch [370]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075473,	
2017-07-21 02:58:27,743 Epoch[86] Batch [380]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075644,	
2017-07-21 02:58:31,922 Epoch[86] Batch [390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.075711,	
2017-07-21 02:58:36,164 Epoch[86] Batch [400]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.075449,	
2017-07-21 02:58:40,412 Epoch[86] Batch [410]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.075524,	
2017-07-21 02:58:44,637 Epoch[86] Batch [420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075397,	
2017-07-21 02:58:49,049 Epoch[86] Batch [430]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075461,	
2017-07-21 02:58:53,716 Epoch[86] Batch [440]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075233,	
2017-07-21 02:58:58,239 Epoch[86] Batch [450]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.075302,	
2017-07-21 02:59:02,652 Epoch[86] Batch [460]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075324,	
2017-07-21 02:59:07,203 Epoch[86] Batch [470]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.075343,	
2017-07-21 02:59:12,072 Epoch[86] Batch [480]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.075274,	
2017-07-21 02:59:16,353 Epoch[86] Batch [490]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 02:59:20,698 Epoch[86] Batch [500]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.075310,	
2017-07-21 02:59:24,928 Epoch[86] Batch [510]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.075329,	
2017-07-21 02:59:29,376 Epoch[86] Batch [520]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075278,	
2017-07-21 02:59:33,666 Epoch[86] Batch [530]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075328,	
2017-07-21 02:59:38,195 Epoch[86] Batch [540]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.075386,	
2017-07-21 02:59:42,365 Epoch[86] Batch [550]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.075385,	
2017-07-21 02:59:46,937 Epoch[86] Batch [560]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075455,	
2017-07-21 02:59:51,230 Epoch[86] Batch [570]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075647,	
2017-07-21 02:59:55,605 Epoch[86] Batch [580]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075712,	
2017-07-21 02:59:59,925 Epoch[86] Batch [590]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075615,	
2017-07-21 03:00:04,354 Epoch[86] Batch [600]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075640,	
2017-07-21 03:00:08,638 Epoch[86] Batch [610]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075658,	
2017-07-21 03:00:12,861 Epoch[86] Batch [620]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075665,	
2017-07-21 03:00:17,767 Epoch[86] Batch [630]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075623,	
2017-07-21 03:00:22,687 Epoch[86] Batch [640]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.075592,	
2017-07-21 03:00:27,221 Epoch[86] Batch [650]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075703,	
2017-07-21 03:00:32,048 Epoch[86] Batch [660]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075632,	
2017-07-21 03:00:37,054 Epoch[86] Batch [670]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.075647,	
2017-07-21 03:00:41,903 Epoch[86] Batch [680]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075712,	
2017-07-21 03:00:46,439 Epoch[86] Batch [690]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075688,	
2017-07-21 03:00:51,451 Epoch[86] Batch [700]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.075651,	
2017-07-21 03:00:56,555 Epoch[86] Batch [710]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.075788,	
2017-07-21 03:01:01,771 Epoch[86] Batch [720]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075685,	
2017-07-21 03:01:07,049 Epoch[86] Batch [730]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.075709,	
2017-07-21 03:01:11,849 Epoch[86] Batch [740]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.075755,	
2017-07-21 03:01:16,293 Epoch[86] Batch [750]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.075767,	
2017-07-21 03:01:21,106 Epoch[86] Batch [760]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075854,	
2017-07-21 03:01:25,599 Epoch[86] Batch [770]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075935,	
2017-07-21 03:01:30,616 Epoch[86] Batch [780]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.075946,	
2017-07-21 03:01:35,737 Epoch[86] Batch [790]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.075947,	
2017-07-21 03:01:41,091 Epoch[86] Batch [800]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.075989,	
2017-07-21 03:01:45,767 Epoch[86] Batch [810]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076047,	
2017-07-21 03:01:50,737 Epoch[86] Batch [820]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.075987,	
2017-07-21 03:01:55,211 Epoch[86] Batch [830]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075905,	
2017-07-21 03:01:59,485 Epoch[86] Batch [840]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075918,	
2017-07-21 03:02:03,611 Epoch[86] Batch [850]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.076032,	
2017-07-21 03:02:07,909 Epoch[86] Batch [860]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.076096,	
2017-07-21 03:02:12,158 Epoch[86] Batch [870]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076066,	
2017-07-21 03:02:16,325 Epoch[86] Batch [880]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.076121,	
2017-07-21 03:02:20,668 Epoch[86] Batch [890]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.076007,	
2017-07-21 03:02:25,060 Epoch[86] Batch [900]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.076018,	
2017-07-21 03:02:29,567 Epoch[86] Batch [910]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.076043,	
2017-07-21 03:02:33,875 Epoch[86] Batch [920]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.076058,	
2017-07-21 03:02:38,165 Epoch[86] Batch [930]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.076134,	
2017-07-21 03:02:42,473 Epoch[86] Batch [940]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.076158,	
2017-07-21 03:02:46,683 Epoch[86] Batch [950]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.076138,	
2017-07-21 03:02:51,506 Epoch[86] Batch [960]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.076122,	
2017-07-21 03:02:55,762 Epoch[86] Batch [970]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076108,	
2017-07-21 03:03:00,168 Epoch[86] Batch [980]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.076092,	
2017-07-21 03:03:04,628 Epoch[86] Batch [990]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.076139,	
2017-07-21 03:03:09,542 Epoch[86] Batch [1000]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.076105,	
2017-07-21 03:03:14,157 Epoch[86] Batch [1010]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.076196,	
2017-07-21 03:03:18,716 Epoch[86] Batch [1020]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.076153,	
2017-07-21 03:03:23,357 Epoch[86] Batch [1030]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.076150,	
2017-07-21 03:03:27,749 Epoch[86] Batch [1040]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.076158,	
2017-07-21 03:03:32,128 Epoch[86] Batch [1050]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.076106,	
2017-07-21 03:03:36,448 Epoch[86] Batch [1060]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.076060,	
2017-07-21 03:03:40,824 Epoch[86] Batch [1070]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.076072,	
2017-07-21 03:03:45,090 Epoch[86] Batch [1080]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.076103,	
2017-07-21 03:03:49,479 Epoch[86] Batch [1090]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076126,	
2017-07-21 03:03:53,971 Epoch[86] Batch [1100]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.076163,	
2017-07-21 03:03:58,465 Epoch[86] Batch [1110]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.076158,	
2017-07-21 03:04:03,174 Epoch[86] Batch [1120]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076141,	
2017-07-21 03:04:07,663 Epoch[86] Batch [1130]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.076142,	
2017-07-21 03:04:11,879 Epoch[86] Batch [1140]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.076094,	
2017-07-21 03:04:16,194 Epoch[86] Batch [1150]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.076098,	
2017-07-21 03:04:20,433 Epoch[86] Batch [1160]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.076043,	
2017-07-21 03:04:24,761 Epoch[86] Batch [1170]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.076013,	
2017-07-21 03:04:29,207 Epoch[86] Batch [1180]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.075967,	
2017-07-21 03:04:33,472 Epoch[86] Batch [1190]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075894,	
2017-07-21 03:04:37,927 Epoch[86] Batch [1200]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075878,	
2017-07-21 03:04:42,186 Epoch[86] Batch [1210]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.075836,	
2017-07-21 03:04:46,439 Epoch[86] Batch [1220]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.075877,	
2017-07-21 03:04:50,836 Epoch[86] Batch [1230]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.075866,	
2017-07-21 03:04:55,237 Epoch[86] Batch [1240]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075842,	
2017-07-21 03:04:59,351 Epoch[86] Batch [1250]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.075964,	
2017-07-21 03:05:03,766 Epoch[86] Batch [1260]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075967,	
2017-07-21 03:05:08,006 Epoch[86] Batch [1270]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.075906,	
2017-07-21 03:05:12,327 Epoch[86] Batch [1280]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075978,	
2017-07-21 03:05:16,690 Epoch[86] Batch [1290]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075943,	
2017-07-21 03:05:21,208 Epoch[86] Batch [1300]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075871,	
2017-07-21 03:05:25,742 Epoch[86] Batch [1310]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075851,	
2017-07-21 03:05:29,990 Epoch[86] Batch [1320]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.075852,	
2017-07-21 03:05:34,210 Epoch[86] Batch [1330]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.075871,	
2017-07-21 03:05:38,243 Epoch[86] Batch [1340]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.075872,	
2017-07-21 03:05:42,488 Epoch[86] Batch [1350]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.075847,	
2017-07-21 03:05:46,751 Epoch[86] Batch [1360]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075873,	
2017-07-21 03:05:51,316 Epoch[86] Batch [1370]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075887,	
2017-07-21 03:05:55,538 Epoch[86] Batch [1380]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075894,	
2017-07-21 03:05:59,732 Epoch[86] Batch [1390]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.075865,	
2017-07-21 03:06:03,969 Epoch[86] Batch [1400]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075815,	
2017-07-21 03:06:08,416 Epoch[86] Batch [1410]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075840,	
2017-07-21 03:06:12,953 Epoch[86] Batch [1420]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075812,	
2017-07-21 03:06:17,378 Epoch[86] Batch [1430]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075726,	
2017-07-21 03:06:21,932 Epoch[86] Batch [1440]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075721,	
2017-07-21 03:06:26,537 Epoch[86] Batch [1450]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075707,	
2017-07-21 03:06:30,882 Epoch[86] Batch [1460]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.075686,	
2017-07-21 03:06:35,271 Epoch[86] Batch [1470]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075686,	
2017-07-21 03:06:40,131 Epoch[86] Batch [1480]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075607,	
2017-07-21 03:06:42,714 Epoch[86] Train-FCNLogLoss=0.075577
2017-07-21 03:06:42,714 Epoch[86] Time cost=665.894
2017-07-21 03:06:43,502 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0087.params"
2017-07-21 03:06:47,811 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0087.states"
2017-07-21 03:06:53,378 Epoch[87] Batch [10]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.072811,	
2017-07-21 03:06:57,920 Epoch[87] Batch [20]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.073856,	
2017-07-21 03:07:02,613 Epoch[87] Batch [30]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.073650,	
2017-07-21 03:07:07,439 Epoch[87] Batch [40]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.074895,	
2017-07-21 03:07:11,904 Epoch[87] Batch [50]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.077478,	
2017-07-21 03:07:16,652 Epoch[87] Batch [60]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.077766,	
2017-07-21 03:07:21,262 Epoch[87] Batch [70]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.077700,	
2017-07-21 03:07:25,519 Epoch[87] Batch [80]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076834,	
2017-07-21 03:07:30,016 Epoch[87] Batch [90]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.076247,	
2017-07-21 03:07:34,558 Epoch[87] Batch [100]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.076544,	
2017-07-21 03:07:38,979 Epoch[87] Batch [110]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.076257,	
2017-07-21 03:07:43,381 Epoch[87] Batch [120]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076332,	
2017-07-21 03:07:47,770 Epoch[87] Batch [130]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075920,	
2017-07-21 03:07:51,871 Epoch[87] Batch [140]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.075862,	
2017-07-21 03:07:56,216 Epoch[87] Batch [150]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.076038,	
2017-07-21 03:08:00,661 Epoch[87] Batch [160]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.075804,	
2017-07-21 03:08:05,267 Epoch[87] Batch [170]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075659,	
2017-07-21 03:08:10,275 Epoch[87] Batch [180]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.075770,	
2017-07-21 03:08:15,197 Epoch[87] Batch [190]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.075485,	
2017-07-21 03:08:19,713 Epoch[87] Batch [200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075441,	
2017-07-21 03:08:24,285 Epoch[87] Batch [210]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075486,	
2017-07-21 03:08:28,759 Epoch[87] Batch [220]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075571,	
2017-07-21 03:08:33,947 Epoch[87] Batch [230]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.075659,	
2017-07-21 03:08:38,326 Epoch[87] Batch [240]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075590,	
2017-07-21 03:08:43,209 Epoch[87] Batch [250]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.075401,	
2017-07-21 03:08:48,120 Epoch[87] Batch [260]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075694,	
2017-07-21 03:08:52,257 Epoch[87] Batch [270]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.076184,	
2017-07-21 03:08:56,642 Epoch[87] Batch [280]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075989,	
2017-07-21 03:09:01,122 Epoch[87] Batch [290]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.075842,	
2017-07-21 03:09:05,284 Epoch[87] Batch [300]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.076117,	
2017-07-21 03:09:09,492 Epoch[87] Batch [310]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075956,	
2017-07-21 03:09:14,031 Epoch[87] Batch [320]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075964,	
2017-07-21 03:09:18,766 Epoch[87] Batch [330]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.075864,	
2017-07-21 03:09:22,902 Epoch[87] Batch [340]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.075585,	
2017-07-21 03:09:27,747 Epoch[87] Batch [350]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075495,	
2017-07-21 03:09:32,571 Epoch[87] Batch [360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075304,	
2017-07-21 03:09:37,094 Epoch[87] Batch [370]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.074960,	
2017-07-21 03:09:42,004 Epoch[87] Batch [380]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075063,	
2017-07-21 03:09:47,103 Epoch[87] Batch [390]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.075044,	
2017-07-21 03:09:51,904 Epoch[87] Batch [400]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.075095,	
2017-07-21 03:09:55,986 Epoch[87] Batch [410]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.074907,	
2017-07-21 03:10:00,353 Epoch[87] Batch [420]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.074967,	
2017-07-21 03:10:04,509 Epoch[87] Batch [430]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.074898,	
2017-07-21 03:10:08,651 Epoch[87] Batch [440]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.074902,	
2017-07-21 03:10:13,003 Epoch[87] Batch [450]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075029,	
2017-07-21 03:10:17,441 Epoch[87] Batch [460]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075010,	
2017-07-21 03:10:21,977 Epoch[87] Batch [470]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075006,	
2017-07-21 03:10:26,347 Epoch[87] Batch [480]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.075076,	
2017-07-21 03:10:30,786 Epoch[87] Batch [490]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.074895,	
2017-07-21 03:10:35,231 Epoch[87] Batch [500]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.074867,	
2017-07-21 03:10:40,050 Epoch[87] Batch [510]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.074981,	
2017-07-21 03:10:44,497 Epoch[87] Batch [520]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.074928,	
2017-07-21 03:10:48,979 Epoch[87] Batch [530]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.074978,	
2017-07-21 03:10:53,126 Epoch[87] Batch [540]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.074920,	
2017-07-21 03:10:57,270 Epoch[87] Batch [550]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.074945,	
2017-07-21 03:11:01,697 Epoch[87] Batch [560]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.074936,	
2017-07-21 03:11:05,795 Epoch[87] Batch [570]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.075005,	
2017-07-21 03:11:10,328 Epoch[87] Batch [580]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075016,	
2017-07-21 03:11:15,020 Epoch[87] Batch [590]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.074971,	
2017-07-21 03:11:19,298 Epoch[87] Batch [600]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.074889,	
2017-07-21 03:11:23,653 Epoch[87] Batch [610]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.074959,	
2017-07-21 03:11:28,246 Epoch[87] Batch [620]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.074952,	
2017-07-21 03:11:32,574 Epoch[87] Batch [630]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075073,	
2017-07-21 03:11:37,027 Epoch[87] Batch [640]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075244,	
2017-07-21 03:11:41,360 Epoch[87] Batch [650]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.075299,	
2017-07-21 03:11:45,839 Epoch[87] Batch [660]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.075366,	
2017-07-21 03:11:50,288 Epoch[87] Batch [670]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075525,	
2017-07-21 03:11:54,524 Epoch[87] Batch [680]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075460,	
2017-07-21 03:11:58,839 Epoch[87] Batch [690]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075492,	
2017-07-21 03:12:03,017 Epoch[87] Batch [700]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.075553,	
2017-07-21 03:12:07,523 Epoch[87] Batch [710]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.075523,	
2017-07-21 03:12:12,012 Epoch[87] Batch [720]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075434,	
2017-07-21 03:12:16,484 Epoch[87] Batch [730]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075348,	
2017-07-21 03:12:20,973 Epoch[87] Batch [740]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075375,	
2017-07-21 03:12:25,326 Epoch[87] Batch [750]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075440,	
2017-07-21 03:12:29,960 Epoch[87] Batch [760]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075493,	
2017-07-21 03:12:34,389 Epoch[87] Batch [770]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075469,	
2017-07-21 03:12:38,707 Epoch[87] Batch [780]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075494,	
2017-07-21 03:12:42,840 Epoch[87] Batch [790]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.075546,	
2017-07-21 03:12:47,058 Epoch[87] Batch [800]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.075470,	
2017-07-21 03:12:51,374 Epoch[87] Batch [810]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075438,	
2017-07-21 03:12:55,928 Epoch[87] Batch [820]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075449,	
2017-07-21 03:13:00,339 Epoch[87] Batch [830]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075466,	
2017-07-21 03:13:04,874 Epoch[87] Batch [840]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075505,	
2017-07-21 03:13:09,687 Epoch[87] Batch [850]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075546,	
2017-07-21 03:13:14,374 Epoch[87] Batch [860]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075543,	
2017-07-21 03:13:19,137 Epoch[87] Batch [870]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075564,	
2017-07-21 03:13:23,606 Epoch[87] Batch [880]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075562,	
2017-07-21 03:13:28,008 Epoch[87] Batch [890]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075610,	
2017-07-21 03:13:32,782 Epoch[87] Batch [900]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075668,	
2017-07-21 03:13:37,489 Epoch[87] Batch [910]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075661,	
2017-07-21 03:13:42,254 Epoch[87] Batch [920]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075690,	
2017-07-21 03:13:47,057 Epoch[87] Batch [930]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.075747,	
2017-07-21 03:13:51,647 Epoch[87] Batch [940]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075715,	
2017-07-21 03:13:56,036 Epoch[87] Batch [950]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075631,	
2017-07-21 03:14:00,329 Epoch[87] Batch [960]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075645,	
2017-07-21 03:14:04,610 Epoch[87] Batch [970]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075677,	
2017-07-21 03:14:08,881 Epoch[87] Batch [980]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.075686,	
2017-07-21 03:14:13,288 Epoch[87] Batch [990]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075712,	
2017-07-21 03:14:17,528 Epoch[87] Batch [1000]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.075710,	
2017-07-21 03:14:21,957 Epoch[87] Batch [1010]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075679,	
2017-07-21 03:14:26,281 Epoch[87] Batch [1020]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075682,	
2017-07-21 03:14:30,587 Epoch[87] Batch [1030]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075675,	
2017-07-21 03:14:34,906 Epoch[87] Batch [1040]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075705,	
2017-07-21 03:14:39,418 Epoch[87] Batch [1050]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.075677,	
2017-07-21 03:14:43,544 Epoch[87] Batch [1060]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.075684,	
2017-07-21 03:14:47,749 Epoch[87] Batch [1070]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075683,	
2017-07-21 03:14:52,187 Epoch[87] Batch [1080]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075640,	
2017-07-21 03:14:57,140 Epoch[87] Batch [1090]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.075656,	
2017-07-21 03:15:01,791 Epoch[87] Batch [1100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075714,	
2017-07-21 03:15:06,202 Epoch[87] Batch [1110]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075758,	
2017-07-21 03:15:11,143 Epoch[87] Batch [1120]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075747,	
2017-07-21 03:15:15,367 Epoch[87] Batch [1130]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075793,	
2017-07-21 03:15:19,827 Epoch[87] Batch [1140]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.075752,	
2017-07-21 03:15:24,254 Epoch[87] Batch [1150]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075811,	
2017-07-21 03:15:28,682 Epoch[87] Batch [1160]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075786,	
2017-07-21 03:15:32,972 Epoch[87] Batch [1170]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.075754,	
2017-07-21 03:15:37,073 Epoch[87] Batch [1180]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.075763,	
2017-07-21 03:15:41,347 Epoch[87] Batch [1190]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075771,	
2017-07-21 03:15:45,696 Epoch[87] Batch [1200]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.075740,	
2017-07-21 03:15:50,146 Epoch[87] Batch [1210]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075815,	
2017-07-21 03:15:54,832 Epoch[87] Batch [1220]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075846,	
2017-07-21 03:15:59,322 Epoch[87] Batch [1230]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075920,	
2017-07-21 03:16:03,888 Epoch[87] Batch [1240]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075869,	
2017-07-21 03:16:08,275 Epoch[87] Batch [1250]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075813,	
2017-07-21 03:16:12,728 Epoch[87] Batch [1260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075809,	
2017-07-21 03:16:17,276 Epoch[87] Batch [1270]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075755,	
2017-07-21 03:16:21,439 Epoch[87] Batch [1280]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.075735,	
2017-07-21 03:16:25,689 Epoch[87] Batch [1290]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.075735,	
2017-07-21 03:16:30,013 Epoch[87] Batch [1300]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075737,	
2017-07-21 03:16:34,226 Epoch[87] Batch [1310]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.075778,	
2017-07-21 03:16:38,479 Epoch[87] Batch [1320]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.075753,	
2017-07-21 03:16:42,830 Epoch[87] Batch [1330]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075796,	
2017-07-21 03:16:47,106 Epoch[87] Batch [1340]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.075785,	
2017-07-21 03:16:51,326 Epoch[87] Batch [1350]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.075683,	
2017-07-21 03:16:55,468 Epoch[87] Batch [1360]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.075756,	
2017-07-21 03:16:59,776 Epoch[87] Batch [1370]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075753,	
2017-07-21 03:17:04,273 Epoch[87] Batch [1380]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075785,	
2017-07-21 03:17:08,593 Epoch[87] Batch [1390]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075788,	
2017-07-21 03:17:12,970 Epoch[87] Batch [1400]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075788,	
2017-07-21 03:17:17,565 Epoch[87] Batch [1410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.075789,	
2017-07-21 03:17:21,870 Epoch[87] Batch [1420]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075739,	
2017-07-21 03:17:26,266 Epoch[87] Batch [1430]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.075724,	
2017-07-21 03:17:30,561 Epoch[87] Batch [1440]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.075696,	
2017-07-21 03:17:34,809 Epoch[87] Batch [1450]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.075697,	
2017-07-21 03:17:39,209 Epoch[87] Batch [1460]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075706,	
2017-07-21 03:17:43,676 Epoch[87] Batch [1470]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075682,	
2017-07-21 03:17:48,202 Epoch[87] Batch [1480]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.075670,	
2017-07-21 03:17:50,741 Epoch[87] Train-FCNLogLoss=0.075663
2017-07-21 03:17:50,742 Epoch[87] Time cost=662.930
2017-07-21 03:17:51,530 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0088.params"
2017-07-21 03:17:56,064 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0088.states"
2017-07-21 03:18:01,360 Epoch[88] Batch [10]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.077316,	
2017-07-21 03:18:06,328 Epoch[88] Batch [20]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.076719,	
2017-07-21 03:18:10,862 Epoch[88] Batch [30]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.076643,	
2017-07-21 03:18:15,273 Epoch[88] Batch [40]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.078046,	
2017-07-21 03:18:19,736 Epoch[88] Batch [50]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.078559,	
2017-07-21 03:18:24,140 Epoch[88] Batch [60]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.077260,	
2017-07-21 03:18:28,645 Epoch[88] Batch [70]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.077619,	
2017-07-21 03:18:33,019 Epoch[88] Batch [80]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.077879,	
2017-07-21 03:18:37,374 Epoch[88] Batch [90]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.076555,	
2017-07-21 03:18:41,837 Epoch[88] Batch [100]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.076779,	
2017-07-21 03:18:46,594 Epoch[88] Batch [110]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.076734,	
2017-07-21 03:18:50,952 Epoch[88] Batch [120]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.076910,	
2017-07-21 03:18:55,498 Epoch[88] Batch [130]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.076730,	
2017-07-21 03:19:00,281 Epoch[88] Batch [140]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.076279,	
2017-07-21 03:19:05,098 Epoch[88] Batch [150]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075678,	
2017-07-21 03:19:09,947 Epoch[88] Batch [160]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075570,	
2017-07-21 03:19:14,723 Epoch[88] Batch [170]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.074879,	
2017-07-21 03:19:19,469 Epoch[88] Batch [180]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.074966,	
2017-07-21 03:19:24,454 Epoch[88] Batch [190]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.074686,	
2017-07-21 03:19:29,995 Epoch[88] Batch [200]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.074339,	
2017-07-21 03:19:35,007 Epoch[88] Batch [210]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074490,	
2017-07-21 03:19:39,567 Epoch[88] Batch [220]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.074630,	
2017-07-21 03:19:44,331 Epoch[88] Batch [230]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.074657,	
2017-07-21 03:19:49,090 Epoch[88] Batch [240]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.074325,	
2017-07-21 03:19:53,788 Epoch[88] Batch [250]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.074127,	
2017-07-21 03:19:58,218 Epoch[88] Batch [260]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.074306,	
2017-07-21 03:20:02,971 Epoch[88] Batch [270]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.074383,	
2017-07-21 03:20:07,632 Epoch[88] Batch [280]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.074221,	
2017-07-21 03:20:12,223 Epoch[88] Batch [290]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.074203,	
2017-07-21 03:20:17,046 Epoch[88] Batch [300]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.074008,	
2017-07-21 03:20:22,372 Epoch[88] Batch [310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.074151,	
2017-07-21 03:20:27,063 Epoch[88] Batch [320]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.074167,	
2017-07-21 03:20:31,745 Epoch[88] Batch [330]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.074275,	
2017-07-21 03:20:37,137 Epoch[88] Batch [340]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.074200,	
2017-07-21 03:20:42,224 Epoch[88] Batch [350]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.074309,	
2017-07-21 03:20:46,983 Epoch[88] Batch [360]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.074244,	
2017-07-21 03:20:51,742 Epoch[88] Batch [370]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.074479,	
2017-07-21 03:20:57,179 Epoch[88] Batch [380]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.074537,	
2017-07-21 03:21:02,202 Epoch[88] Batch [390]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.074571,	
2017-07-21 03:21:07,054 Epoch[88] Batch [400]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.074783,	
2017-07-21 03:21:11,770 Epoch[88] Batch [410]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.074814,	
2017-07-21 03:21:16,220 Epoch[88] Batch [420]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.074820,	
2017-07-21 03:21:20,675 Epoch[88] Batch [430]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.074985,	
2017-07-21 03:21:24,982 Epoch[88] Batch [440]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.074946,	
2017-07-21 03:21:29,263 Epoch[88] Batch [450]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.074889,	
2017-07-21 03:21:33,353 Epoch[88] Batch [460]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.074942,	
2017-07-21 03:21:37,853 Epoch[88] Batch [470]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075055,	
2017-07-21 03:21:42,282 Epoch[88] Batch [480]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.074948,	
2017-07-21 03:21:46,857 Epoch[88] Batch [490]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075009,	
2017-07-21 03:21:51,547 Epoch[88] Batch [500]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.075189,	
2017-07-21 03:21:56,191 Epoch[88] Batch [510]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075296,	
2017-07-21 03:22:01,166 Epoch[88] Batch [520]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075270,	
2017-07-21 03:22:05,766 Epoch[88] Batch [530]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075169,	
2017-07-21 03:22:10,249 Epoch[88] Batch [540]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075121,	
2017-07-21 03:22:14,929 Epoch[88] Batch [550]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075125,	
2017-07-21 03:22:19,629 Epoch[88] Batch [560]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.075033,	
2017-07-21 03:22:24,546 Epoch[88] Batch [570]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.074912,	
2017-07-21 03:22:29,071 Epoch[88] Batch [580]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.074880,	
2017-07-21 03:22:33,507 Epoch[88] Batch [590]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.074879,	
2017-07-21 03:22:37,886 Epoch[88] Batch [600]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074933,	
2017-07-21 03:22:42,511 Epoch[88] Batch [610]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.074856,	
2017-07-21 03:22:46,776 Epoch[88] Batch [620]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.074987,	
2017-07-21 03:22:51,158 Epoch[88] Batch [630]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074950,	
2017-07-21 03:22:55,693 Epoch[88] Batch [640]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.074974,	
2017-07-21 03:23:00,520 Epoch[88] Batch [650]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075236,	
2017-07-21 03:23:04,830 Epoch[88] Batch [660]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075328,	
2017-07-21 03:23:09,375 Epoch[88] Batch [670]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075374,	
2017-07-21 03:23:13,902 Epoch[88] Batch [680]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.075313,	
2017-07-21 03:23:18,770 Epoch[88] Batch [690]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.075278,	
2017-07-21 03:23:23,605 Epoch[88] Batch [700]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075239,	
2017-07-21 03:23:27,779 Epoch[88] Batch [710]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.075258,	
2017-07-21 03:23:32,828 Epoch[88] Batch [720]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.075278,	
2017-07-21 03:23:37,621 Epoch[88] Batch [730]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.075271,	
2017-07-21 03:23:42,431 Epoch[88] Batch [740]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.075460,	
2017-07-21 03:23:47,296 Epoch[88] Batch [750]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.075441,	
2017-07-21 03:23:52,313 Epoch[88] Batch [760]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.075390,	
2017-07-21 03:23:57,402 Epoch[88] Batch [770]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.075416,	
2017-07-21 03:24:02,372 Epoch[88] Batch [780]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.075394,	
2017-07-21 03:24:06,808 Epoch[88] Batch [790]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075454,	
2017-07-21 03:24:11,208 Epoch[88] Batch [800]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075420,	
2017-07-21 03:24:15,594 Epoch[88] Batch [810]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075371,	
2017-07-21 03:24:19,787 Epoch[88] Batch [820]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.075393,	
2017-07-21 03:24:24,190 Epoch[88] Batch [830]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075399,	
2017-07-21 03:24:28,666 Epoch[88] Batch [840]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075367,	
2017-07-21 03:24:33,630 Epoch[88] Batch [850]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.075265,	
2017-07-21 03:24:38,459 Epoch[88] Batch [860]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.075307,	
2017-07-21 03:24:43,667 Epoch[88] Batch [870]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.075304,	
2017-07-21 03:24:48,414 Epoch[88] Batch [880]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.075294,	
2017-07-21 03:24:53,094 Epoch[88] Batch [890]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075311,	
2017-07-21 03:24:57,414 Epoch[88] Batch [900]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075202,	
2017-07-21 03:25:01,985 Epoch[88] Batch [910]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075236,	
2017-07-21 03:25:06,669 Epoch[88] Batch [920]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 03:25:11,187 Epoch[88] Batch [930]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075241,	
2017-07-21 03:25:16,002 Epoch[88] Batch [940]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075255,	
2017-07-21 03:25:20,359 Epoch[88] Batch [950]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075290,	
2017-07-21 03:25:24,693 Epoch[88] Batch [960]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.075245,	
2017-07-21 03:25:28,821 Epoch[88] Batch [970]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.075326,	
2017-07-21 03:25:33,131 Epoch[88] Batch [980]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075318,	
2017-07-21 03:25:37,691 Epoch[88] Batch [990]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075324,	
2017-07-21 03:25:42,294 Epoch[88] Batch [1000]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075271,	
2017-07-21 03:25:47,121 Epoch[88] Batch [1010]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075297,	
2017-07-21 03:25:52,046 Epoch[88] Batch [1020]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.075306,	
2017-07-21 03:25:56,360 Epoch[88] Batch [1030]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075355,	
2017-07-21 03:26:01,122 Epoch[88] Batch [1040]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075370,	
2017-07-21 03:26:05,989 Epoch[88] Batch [1050]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.075452,	
2017-07-21 03:26:10,437 Epoch[88] Batch [1060]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075578,	
2017-07-21 03:26:15,115 Epoch[88] Batch [1070]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075587,	
2017-07-21 03:26:19,326 Epoch[88] Batch [1080]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.075550,	
2017-07-21 03:26:23,613 Epoch[88] Batch [1090]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.075511,	
2017-07-21 03:26:27,967 Epoch[88] Batch [1100]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075495,	
2017-07-21 03:26:32,133 Epoch[88] Batch [1110]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.075523,	
2017-07-21 03:26:36,686 Epoch[88] Batch [1120]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.075588,	
2017-07-21 03:26:41,110 Epoch[88] Batch [1130]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075538,	
2017-07-21 03:26:45,756 Epoch[88] Batch [1140]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075497,	
2017-07-21 03:26:50,253 Epoch[88] Batch [1150]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075497,	
2017-07-21 03:26:54,975 Epoch[88] Batch [1160]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.075566,	
2017-07-21 03:26:59,428 Epoch[88] Batch [1170]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075622,	
2017-07-21 03:27:04,082 Epoch[88] Batch [1180]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075677,	
2017-07-21 03:27:08,659 Epoch[88] Batch [1190]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075800,	
2017-07-21 03:27:13,213 Epoch[88] Batch [1200]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.075850,	
2017-07-21 03:27:17,593 Epoch[88] Batch [1210]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075795,	
2017-07-21 03:27:22,099 Epoch[88] Batch [1220]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.075818,	
2017-07-21 03:27:26,454 Epoch[88] Batch [1230]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075838,	
2017-07-21 03:27:30,805 Epoch[88] Batch [1240]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075788,	
2017-07-21 03:27:35,112 Epoch[88] Batch [1250]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075736,	
2017-07-21 03:27:39,159 Epoch[88] Batch [1260]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.075754,	
2017-07-21 03:27:43,487 Epoch[88] Batch [1270]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075764,	
2017-07-21 03:27:48,086 Epoch[88] Batch [1280]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075785,	
2017-07-21 03:27:52,660 Epoch[88] Batch [1290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075761,	
2017-07-21 03:27:57,285 Epoch[88] Batch [1300]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075804,	
2017-07-21 03:28:02,141 Epoch[88] Batch [1310]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.075766,	
2017-07-21 03:28:07,095 Epoch[88] Batch [1320]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.075782,	
2017-07-21 03:28:12,248 Epoch[88] Batch [1330]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.075776,	
2017-07-21 03:28:16,564 Epoch[88] Batch [1340]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075787,	
2017-07-21 03:28:20,908 Epoch[88] Batch [1350]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.075774,	
2017-07-21 03:28:25,468 Epoch[88] Batch [1360]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075802,	
2017-07-21 03:28:29,965 Epoch[88] Batch [1370]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075811,	
2017-07-21 03:28:34,159 Epoch[88] Batch [1380]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.075800,	
2017-07-21 03:28:38,476 Epoch[88] Batch [1390]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075727,	
2017-07-21 03:28:43,595 Epoch[88] Batch [1400]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.075734,	
2017-07-21 03:28:48,386 Epoch[88] Batch [1410]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.075669,	
2017-07-21 03:28:53,284 Epoch[88] Batch [1420]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075665,	
2017-07-21 03:28:57,748 Epoch[88] Batch [1430]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075673,	
2017-07-21 03:29:02,216 Epoch[88] Batch [1440]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075657,	
2017-07-21 03:29:07,017 Epoch[88] Batch [1450]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.075666,	
2017-07-21 03:29:11,365 Epoch[88] Batch [1460]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.075662,	
2017-07-21 03:29:15,917 Epoch[88] Batch [1470]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.075680,	
2017-07-21 03:29:20,974 Epoch[88] Batch [1480]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.075682,	
2017-07-21 03:29:23,744 Epoch[88] Train-FCNLogLoss=0.075720
2017-07-21 03:29:23,744 Epoch[88] Time cost=687.679
2017-07-21 03:29:24,521 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0089.params"
2017-07-21 03:29:28,787 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0089.states"
2017-07-21 03:29:34,263 Epoch[89] Batch [10]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.070613,	
2017-07-21 03:29:39,348 Epoch[89] Batch [20]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.071057,	
2017-07-21 03:29:44,200 Epoch[89] Batch [30]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.071607,	
2017-07-21 03:29:48,472 Epoch[89] Batch [40]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.073253,	
2017-07-21 03:29:52,976 Epoch[89] Batch [50]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.073062,	
2017-07-21 03:29:57,191 Epoch[89] Batch [60]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.074255,	
2017-07-21 03:30:01,572 Epoch[89] Batch [70]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075301,	
2017-07-21 03:30:05,878 Epoch[89] Batch [80]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075508,	
2017-07-21 03:30:10,074 Epoch[89] Batch [90]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.075780,	
2017-07-21 03:30:14,504 Epoch[89] Batch [100]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075430,	
2017-07-21 03:30:18,570 Epoch[89] Batch [110]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.076608,	
2017-07-21 03:30:22,893 Epoch[89] Batch [120]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075848,	
2017-07-21 03:30:26,940 Epoch[89] Batch [130]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.076361,	
2017-07-21 03:30:31,193 Epoch[89] Batch [140]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.076379,	
2017-07-21 03:30:35,481 Epoch[89] Batch [150]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.076665,	
2017-07-21 03:30:39,732 Epoch[89] Batch [160]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076555,	
2017-07-21 03:30:44,073 Epoch[89] Batch [170]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.076430,	
2017-07-21 03:30:48,443 Epoch[89] Batch [180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.076397,	
2017-07-21 03:30:53,154 Epoch[89] Batch [190]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076529,	
2017-07-21 03:30:57,607 Epoch[89] Batch [200]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.076626,	
2017-07-21 03:31:02,314 Epoch[89] Batch [210]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076297,	
2017-07-21 03:31:06,907 Epoch[89] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.076012,	
2017-07-21 03:31:11,419 Epoch[89] Batch [230]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.076089,	
2017-07-21 03:31:16,132 Epoch[89] Batch [240]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076238,	
2017-07-21 03:31:21,203 Epoch[89] Batch [250]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.076070,	
2017-07-21 03:31:25,969 Epoch[89] Batch [260]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075879,	
2017-07-21 03:31:30,634 Epoch[89] Batch [270]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075925,	
2017-07-21 03:31:35,533 Epoch[89] Batch [280]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075825,	
2017-07-21 03:31:40,195 Epoch[89] Batch [290]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.075623,	
2017-07-21 03:31:45,360 Epoch[89] Batch [300]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.075909,	
2017-07-21 03:31:49,954 Epoch[89] Batch [310]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.075865,	
2017-07-21 03:31:55,200 Epoch[89] Batch [320]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.076155,	
2017-07-21 03:31:59,712 Epoch[89] Batch [330]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.076255,	
2017-07-21 03:32:04,090 Epoch[89] Batch [340]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.076270,	
2017-07-21 03:32:08,486 Epoch[89] Batch [350]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.076381,	
2017-07-21 03:32:12,820 Epoch[89] Batch [360]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.076097,	
2017-07-21 03:32:17,080 Epoch[89] Batch [370]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.076103,	
2017-07-21 03:32:21,560 Epoch[89] Batch [380]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.076217,	
2017-07-21 03:32:26,037 Epoch[89] Batch [390]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.076304,	
2017-07-21 03:32:30,499 Epoch[89] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.076231,	
2017-07-21 03:32:35,253 Epoch[89] Batch [410]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.076107,	
2017-07-21 03:32:39,476 Epoch[89] Batch [420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.076067,	
2017-07-21 03:32:43,716 Epoch[89] Batch [430]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.076210,	
2017-07-21 03:32:48,500 Epoch[89] Batch [440]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.076311,	
2017-07-21 03:32:53,339 Epoch[89] Batch [450]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.076445,	
2017-07-21 03:32:58,246 Epoch[89] Batch [460]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.076500,	
2017-07-21 03:33:02,679 Epoch[89] Batch [470]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.076451,	
2017-07-21 03:33:07,610 Epoch[89] Batch [480]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.076315,	
2017-07-21 03:33:12,033 Epoch[89] Batch [490]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.076146,	
2017-07-21 03:33:16,778 Epoch[89] Batch [500]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.076160,	
2017-07-21 03:33:21,615 Epoch[89] Batch [510]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.076179,	
2017-07-21 03:33:26,211 Epoch[89] Batch [520]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.076207,	
2017-07-21 03:33:30,632 Epoch[89] Batch [530]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.076181,	
2017-07-21 03:33:34,725 Epoch[89] Batch [540]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.076052,	
2017-07-21 03:33:39,332 Epoch[89] Batch [550]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076235,	
2017-07-21 03:33:43,705 Epoch[89] Batch [560]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.076363,	
2017-07-21 03:33:48,198 Epoch[89] Batch [570]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.076332,	
2017-07-21 03:33:52,973 Epoch[89] Batch [580]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.076373,	
2017-07-21 03:33:57,209 Epoch[89] Batch [590]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.076437,	
2017-07-21 03:34:01,839 Epoch[89] Batch [600]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.076464,	
2017-07-21 03:34:06,125 Epoch[89] Batch [610]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.076509,	
2017-07-21 03:34:10,955 Epoch[89] Batch [620]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.076472,	
2017-07-21 03:34:15,664 Epoch[89] Batch [630]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076313,	
2017-07-21 03:34:20,376 Epoch[89] Batch [640]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076305,	
2017-07-21 03:34:24,779 Epoch[89] Batch [650]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.076242,	
2017-07-21 03:34:29,440 Epoch[89] Batch [660]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.076227,	
2017-07-21 03:34:34,181 Epoch[89] Batch [670]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076244,	
2017-07-21 03:34:38,929 Epoch[89] Batch [680]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.076242,	
2017-07-21 03:34:43,386 Epoch[89] Batch [690]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.076266,	
2017-07-21 03:34:47,733 Epoch[89] Batch [700]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.076224,	
2017-07-21 03:34:52,243 Epoch[89] Batch [710]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.076146,	
2017-07-21 03:34:56,701 Epoch[89] Batch [720]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.076070,	
2017-07-21 03:35:01,268 Epoch[89] Batch [730]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.076122,	
2017-07-21 03:35:05,903 Epoch[89] Batch [740]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.076061,	
2017-07-21 03:35:10,581 Epoch[89] Batch [750]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.076068,	
2017-07-21 03:35:14,734 Epoch[89] Batch [760]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.076024,	
2017-07-21 03:35:19,161 Epoch[89] Batch [770]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075966,	
2017-07-21 03:35:23,580 Epoch[89] Batch [780]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075885,	
2017-07-21 03:35:27,918 Epoch[89] Batch [790]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.075843,	
2017-07-21 03:35:32,418 Epoch[89] Batch [800]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075797,	
2017-07-21 03:35:36,709 Epoch[89] Batch [810]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075914,	
2017-07-21 03:35:41,014 Epoch[89] Batch [820]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075884,	
2017-07-21 03:35:45,469 Epoch[89] Batch [830]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075993,	
2017-07-21 03:35:49,821 Epoch[89] Batch [840]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075980,	
2017-07-21 03:35:54,104 Epoch[89] Batch [850]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075901,	
2017-07-21 03:35:59,061 Epoch[89] Batch [860]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.075840,	
2017-07-21 03:36:04,129 Epoch[89] Batch [870]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.075822,	
2017-07-21 03:36:09,061 Epoch[89] Batch [880]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.075810,	
2017-07-21 03:36:14,291 Epoch[89] Batch [890]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.075786,	
2017-07-21 03:36:19,424 Epoch[89] Batch [900]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.075772,	
2017-07-21 03:36:23,731 Epoch[89] Batch [910]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075697,	
2017-07-21 03:36:28,509 Epoch[89] Batch [920]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075618,	
2017-07-21 03:36:33,381 Epoch[89] Batch [930]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.075591,	
2017-07-21 03:36:38,364 Epoch[89] Batch [940]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.075546,	
2017-07-21 03:36:43,356 Epoch[89] Batch [950]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075492,	
2017-07-21 03:36:47,797 Epoch[89] Batch [960]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075458,	
2017-07-21 03:36:52,060 Epoch[89] Batch [970]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075518,	
2017-07-21 03:36:56,325 Epoch[89] Batch [980]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075560,	
2017-07-21 03:37:00,845 Epoch[89] Batch [990]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.075521,	
2017-07-21 03:37:05,185 Epoch[89] Batch [1000]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.075556,	
2017-07-21 03:37:09,654 Epoch[89] Batch [1010]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075682,	
2017-07-21 03:37:14,107 Epoch[89] Batch [1020]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075648,	
2017-07-21 03:37:19,001 Epoch[89] Batch [1030]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.075583,	
2017-07-21 03:37:23,548 Epoch[89] Batch [1040]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075575,	
2017-07-21 03:37:28,593 Epoch[89] Batch [1050]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.075626,	
2017-07-21 03:37:33,452 Epoch[89] Batch [1060]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075590,	
2017-07-21 03:37:38,492 Epoch[89] Batch [1070]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075574,	
2017-07-21 03:37:43,416 Epoch[89] Batch [1080]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.075526,	
2017-07-21 03:37:47,989 Epoch[89] Batch [1090]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075470,	
2017-07-21 03:37:52,324 Epoch[89] Batch [1100]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.075419,	
2017-07-21 03:37:56,777 Epoch[89] Batch [1110]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075455,	
2017-07-21 03:38:01,461 Epoch[89] Batch [1120]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075572,	
2017-07-21 03:38:05,925 Epoch[89] Batch [1130]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075604,	
2017-07-21 03:38:10,562 Epoch[89] Batch [1140]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075590,	
2017-07-21 03:38:14,893 Epoch[89] Batch [1150]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075594,	
2017-07-21 03:38:19,731 Epoch[89] Batch [1160]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075534,	
2017-07-21 03:38:24,037 Epoch[89] Batch [1170]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075606,	
2017-07-21 03:38:28,412 Epoch[89] Batch [1180]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075660,	
2017-07-21 03:38:33,039 Epoch[89] Batch [1190]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075661,	
2017-07-21 03:38:37,538 Epoch[89] Batch [1200]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075689,	
2017-07-21 03:38:42,279 Epoch[89] Batch [1210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075693,	
2017-07-21 03:38:47,413 Epoch[89] Batch [1220]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.075661,	
2017-07-21 03:38:51,956 Epoch[89] Batch [1230]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075612,	
2017-07-21 03:38:56,776 Epoch[89] Batch [1240]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075589,	
2017-07-21 03:39:01,291 Epoch[89] Batch [1250]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075642,	
2017-07-21 03:39:06,226 Epoch[89] Batch [1260]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.075684,	
2017-07-21 03:39:11,289 Epoch[89] Batch [1270]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.075662,	
2017-07-21 03:39:15,891 Epoch[89] Batch [1280]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075658,	
2017-07-21 03:39:20,576 Epoch[89] Batch [1290]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075635,	
2017-07-21 03:39:25,396 Epoch[89] Batch [1300]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075674,	
2017-07-21 03:39:30,013 Epoch[89] Batch [1310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.075660,	
2017-07-21 03:39:34,418 Epoch[89] Batch [1320]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075666,	
2017-07-21 03:39:38,645 Epoch[89] Batch [1330]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.075717,	
2017-07-21 03:39:43,025 Epoch[89] Batch [1340]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075737,	
2017-07-21 03:39:47,381 Epoch[89] Batch [1350]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075703,	
2017-07-21 03:39:52,242 Epoch[89] Batch [1360]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075728,	
2017-07-21 03:39:56,653 Epoch[89] Batch [1370]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075791,	
2017-07-21 03:40:01,528 Epoch[89] Batch [1380]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.075782,	
2017-07-21 03:40:06,064 Epoch[89] Batch [1390]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075769,	
2017-07-21 03:40:10,729 Epoch[89] Batch [1400]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.075781,	
2017-07-21 03:40:15,378 Epoch[89] Batch [1410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075781,	
2017-07-21 03:40:20,313 Epoch[89] Batch [1420]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075819,	
2017-07-21 03:40:25,364 Epoch[89] Batch [1430]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.075738,	
2017-07-21 03:40:30,413 Epoch[89] Batch [1440]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.075751,	
2017-07-21 03:40:34,742 Epoch[89] Batch [1450]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075718,	
2017-07-21 03:40:39,234 Epoch[89] Batch [1460]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075733,	
2017-07-21 03:40:43,566 Epoch[89] Batch [1470]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.075745,	
2017-07-21 03:40:47,981 Epoch[89] Batch [1480]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075747,	
2017-07-21 03:40:50,567 Epoch[89] Train-FCNLogLoss=0.075762
2017-07-21 03:40:50,567 Epoch[89] Time cost=681.780
2017-07-21 03:40:51,300 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0090.params"
2017-07-21 03:40:55,532 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0090.states"
2017-07-21 03:41:00,606 Epoch[90] Batch [10]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.070745,	
2017-07-21 03:41:05,326 Epoch[90] Batch [20]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.072303,	
2017-07-21 03:41:09,867 Epoch[90] Batch [30]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.071375,	
2017-07-21 03:41:14,252 Epoch[90] Batch [40]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.073832,	
2017-07-21 03:41:18,802 Epoch[90] Batch [50]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.074726,	
2017-07-21 03:41:23,196 Epoch[90] Batch [60]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.075819,	
2017-07-21 03:41:27,599 Epoch[90] Batch [70]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075050,	
2017-07-21 03:41:32,195 Epoch[90] Batch [80]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.073983,	
2017-07-21 03:41:36,740 Epoch[90] Batch [90]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.073892,	
2017-07-21 03:41:41,309 Epoch[90] Batch [100]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.073811,	
2017-07-21 03:41:45,677 Epoch[90] Batch [110]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.073616,	
2017-07-21 03:41:50,159 Epoch[90] Batch [120]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.074016,	
2017-07-21 03:41:54,766 Epoch[90] Batch [130]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.073604,	
2017-07-21 03:41:59,538 Epoch[90] Batch [140]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.073341,	
2017-07-21 03:42:03,846 Epoch[90] Batch [150]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.073734,	
2017-07-21 03:42:08,393 Epoch[90] Batch [160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.073660,	
2017-07-21 03:42:13,079 Epoch[90] Batch [170]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.073461,	
2017-07-21 03:42:17,665 Epoch[90] Batch [180]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.072998,	
2017-07-21 03:42:22,036 Epoch[90] Batch [190]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.073264,	
2017-07-21 03:42:26,695 Epoch[90] Batch [200]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.073740,	
2017-07-21 03:42:31,306 Epoch[90] Batch [210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.073896,	
2017-07-21 03:42:36,050 Epoch[90] Batch [220]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.074473,	
2017-07-21 03:42:40,544 Epoch[90] Batch [230]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.074618,	
2017-07-21 03:42:45,352 Epoch[90] Batch [240]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.074536,	
2017-07-21 03:42:50,647 Epoch[90] Batch [250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.074772,	
2017-07-21 03:42:55,280 Epoch[90] Batch [260]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.074791,	
2017-07-21 03:42:59,942 Epoch[90] Batch [270]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.074820,	
2017-07-21 03:43:04,259 Epoch[90] Batch [280]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075015,	
2017-07-21 03:43:08,771 Epoch[90] Batch [290]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.074874,	
2017-07-21 03:43:13,314 Epoch[90] Batch [300]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075020,	
2017-07-21 03:43:17,768 Epoch[90] Batch [310]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075006,	
2017-07-21 03:43:22,180 Epoch[90] Batch [320]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.074914,	
2017-07-21 03:43:26,858 Epoch[90] Batch [330]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.074926,	
2017-07-21 03:43:31,240 Epoch[90] Batch [340]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074627,	
2017-07-21 03:43:35,865 Epoch[90] Batch [350]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.074665,	
2017-07-21 03:43:40,585 Epoch[90] Batch [360]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.074846,	
2017-07-21 03:43:45,125 Epoch[90] Batch [370]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.074612,	
2017-07-21 03:43:49,618 Epoch[90] Batch [380]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.074516,	
2017-07-21 03:43:54,152 Epoch[90] Batch [390]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.074573,	
2017-07-21 03:43:58,262 Epoch[90] Batch [400]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.074716,	
2017-07-21 03:44:02,567 Epoch[90] Batch [410]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075041,	
2017-07-21 03:44:07,123 Epoch[90] Batch [420]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075121,	
2017-07-21 03:44:11,543 Epoch[90] Batch [430]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075176,	
2017-07-21 03:44:15,615 Epoch[90] Batch [440]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.075203,	
2017-07-21 03:44:20,505 Epoch[90] Batch [450]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.075265,	
2017-07-21 03:44:24,979 Epoch[90] Batch [460]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075182,	
2017-07-21 03:44:30,135 Epoch[90] Batch [470]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.075260,	
2017-07-21 03:44:35,075 Epoch[90] Batch [480]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075183,	
2017-07-21 03:44:39,544 Epoch[90] Batch [490]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075114,	
2017-07-21 03:44:43,980 Epoch[90] Batch [500]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075102,	
2017-07-21 03:44:48,331 Epoch[90] Batch [510]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075023,	
2017-07-21 03:44:52,511 Epoch[90] Batch [520]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.074984,	
2017-07-21 03:44:56,842 Epoch[90] Batch [530]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.074899,	
2017-07-21 03:45:01,198 Epoch[90] Batch [540]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.074852,	
2017-07-21 03:45:05,522 Epoch[90] Batch [550]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.074884,	
2017-07-21 03:45:09,838 Epoch[90] Batch [560]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.074983,	
2017-07-21 03:45:14,376 Epoch[90] Batch [570]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075130,	
2017-07-21 03:45:18,901 Epoch[90] Batch [580]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.075277,	
2017-07-21 03:45:23,384 Epoch[90] Batch [590]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075276,	
2017-07-21 03:45:27,638 Epoch[90] Batch [600]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.075199,	
2017-07-21 03:45:32,304 Epoch[90] Batch [610]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075386,	
2017-07-21 03:45:37,809 Epoch[90] Batch [620]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.075497,	
2017-07-21 03:45:42,995 Epoch[90] Batch [630]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.075563,	
2017-07-21 03:45:47,534 Epoch[90] Batch [640]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075631,	
2017-07-21 03:45:52,340 Epoch[90] Batch [650]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.075576,	
2017-07-21 03:45:57,113 Epoch[90] Batch [660]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075519,	
2017-07-21 03:46:01,883 Epoch[90] Batch [670]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075459,	
2017-07-21 03:46:06,274 Epoch[90] Batch [680]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075452,	
2017-07-21 03:46:10,956 Epoch[90] Batch [690]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075404,	
2017-07-21 03:46:15,186 Epoch[90] Batch [700]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.075451,	
2017-07-21 03:46:19,814 Epoch[90] Batch [710]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075475,	
2017-07-21 03:46:24,139 Epoch[90] Batch [720]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075504,	
2017-07-21 03:46:28,432 Epoch[90] Batch [730]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075513,	
2017-07-21 03:46:32,806 Epoch[90] Batch [740]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.075540,	
2017-07-21 03:46:37,043 Epoch[90] Batch [750]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075563,	
2017-07-21 03:46:41,331 Epoch[90] Batch [760]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.075604,	
2017-07-21 03:46:45,518 Epoch[90] Batch [770]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.075569,	
2017-07-21 03:46:49,907 Epoch[90] Batch [780]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075603,	
2017-07-21 03:46:54,268 Epoch[90] Batch [790]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075670,	
2017-07-21 03:46:58,826 Epoch[90] Batch [800]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075566,	
2017-07-21 03:47:02,970 Epoch[90] Batch [810]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.075575,	
2017-07-21 03:47:07,501 Epoch[90] Batch [820]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.075607,	
2017-07-21 03:47:11,959 Epoch[90] Batch [830]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.075571,	
2017-07-21 03:47:16,715 Epoch[90] Batch [840]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.075599,	
2017-07-21 03:47:21,252 Epoch[90] Batch [850]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075652,	
2017-07-21 03:47:25,766 Epoch[90] Batch [860]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075732,	
2017-07-21 03:47:30,361 Epoch[90] Batch [870]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.075694,	
2017-07-21 03:47:35,031 Epoch[90] Batch [880]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075650,	
2017-07-21 03:47:39,707 Epoch[90] Batch [890]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075729,	
2017-07-21 03:47:43,894 Epoch[90] Batch [900]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.075696,	
2017-07-21 03:47:48,415 Epoch[90] Batch [910]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075693,	
2017-07-21 03:47:53,012 Epoch[90] Batch [920]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075670,	
2017-07-21 03:47:57,555 Epoch[90] Batch [930]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075675,	
2017-07-21 03:48:02,154 Epoch[90] Batch [940]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075685,	
2017-07-21 03:48:06,558 Epoch[90] Batch [950]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075699,	
2017-07-21 03:48:11,041 Epoch[90] Batch [960]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075666,	
2017-07-21 03:48:15,432 Epoch[90] Batch [970]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075691,	
2017-07-21 03:48:19,856 Epoch[90] Batch [980]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075677,	
2017-07-21 03:48:24,637 Epoch[90] Batch [990]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075646,	
2017-07-21 03:48:29,263 Epoch[90] Batch [1000]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075659,	
2017-07-21 03:48:33,752 Epoch[90] Batch [1010]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075689,	
2017-07-21 03:48:38,192 Epoch[90] Batch [1020]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075610,	
2017-07-21 03:48:42,942 Epoch[90] Batch [1030]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.075644,	
2017-07-21 03:48:47,414 Epoch[90] Batch [1040]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075675,	
2017-07-21 03:48:51,839 Epoch[90] Batch [1050]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075700,	
2017-07-21 03:48:56,681 Epoch[90] Batch [1060]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075668,	
2017-07-21 03:49:01,307 Epoch[90] Batch [1070]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075711,	
2017-07-21 03:49:06,091 Epoch[90] Batch [1080]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.075761,	
2017-07-21 03:49:10,791 Epoch[90] Batch [1090]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.075723,	
2017-07-21 03:49:15,915 Epoch[90] Batch [1100]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.075768,	
2017-07-21 03:49:20,540 Epoch[90] Batch [1110]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075749,	
2017-07-21 03:49:25,155 Epoch[90] Batch [1120]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.075695,	
2017-07-21 03:49:30,086 Epoch[90] Batch [1130]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.075699,	
2017-07-21 03:49:35,077 Epoch[90] Batch [1140]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.075747,	
2017-07-21 03:49:39,676 Epoch[90] Batch [1150]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075758,	
2017-07-21 03:49:44,415 Epoch[90] Batch [1160]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075807,	
2017-07-21 03:49:49,214 Epoch[90] Batch [1170]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075810,	
2017-07-21 03:49:53,406 Epoch[90] Batch [1180]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.075822,	
2017-07-21 03:49:57,992 Epoch[90] Batch [1190]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075824,	
2017-07-21 03:50:02,755 Epoch[90] Batch [1200]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075816,	
2017-07-21 03:50:07,547 Epoch[90] Batch [1210]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.075812,	
2017-07-21 03:50:11,930 Epoch[90] Batch [1220]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075759,	
2017-07-21 03:50:16,225 Epoch[90] Batch [1230]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.075823,	
2017-07-21 03:50:20,808 Epoch[90] Batch [1240]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.075788,	
2017-07-21 03:50:25,209 Epoch[90] Batch [1250]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075715,	
2017-07-21 03:50:29,427 Epoch[90] Batch [1260]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.075642,	
2017-07-21 03:50:34,455 Epoch[90] Batch [1270]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.075588,	
2017-07-21 03:50:39,371 Epoch[90] Batch [1280]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075545,	
2017-07-21 03:50:44,121 Epoch[90] Batch [1290]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.075466,	
2017-07-21 03:50:49,101 Epoch[90] Batch [1300]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.075463,	
2017-07-21 03:50:53,936 Epoch[90] Batch [1310]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075441,	
2017-07-21 03:50:58,602 Epoch[90] Batch [1320]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075409,	
2017-07-21 03:51:03,050 Epoch[90] Batch [1330]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075395,	
2017-07-21 03:51:07,483 Epoch[90] Batch [1340]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075338,	
2017-07-21 03:51:12,043 Epoch[90] Batch [1350]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075343,	
2017-07-21 03:51:16,424 Epoch[90] Batch [1360]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075393,	
2017-07-21 03:51:21,072 Epoch[90] Batch [1370]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075428,	
2017-07-21 03:51:26,116 Epoch[90] Batch [1380]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.075442,	
2017-07-21 03:51:30,821 Epoch[90] Batch [1390]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075441,	
2017-07-21 03:51:35,641 Epoch[90] Batch [1400]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075448,	
2017-07-21 03:51:40,362 Epoch[90] Batch [1410]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.075460,	
2017-07-21 03:51:44,595 Epoch[90] Batch [1420]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.075493,	
2017-07-21 03:51:49,359 Epoch[90] Batch [1430]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075481,	
2017-07-21 03:51:53,869 Epoch[90] Batch [1440]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.075516,	
2017-07-21 03:51:58,229 Epoch[90] Batch [1450]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075510,	
2017-07-21 03:52:02,838 Epoch[90] Batch [1460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.075532,	
2017-07-21 03:52:07,328 Epoch[90] Batch [1470]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075501,	
2017-07-21 03:52:12,146 Epoch[90] Batch [1480]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075511,	
2017-07-21 03:52:15,274 Epoch[90] Train-FCNLogLoss=0.075494
2017-07-21 03:52:15,274 Epoch[90] Time cost=679.741
2017-07-21 03:52:16,213 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0091.params"
2017-07-21 03:52:20,865 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0091.states"
2017-07-21 03:52:26,284 Epoch[91] Batch [10]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.082920,	
2017-07-21 03:52:30,910 Epoch[91] Batch [20]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.082864,	
2017-07-21 03:52:35,783 Epoch[91] Batch [30]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.081424,	
2017-07-21 03:52:40,604 Epoch[91] Batch [40]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.079448,	
2017-07-21 03:52:45,089 Epoch[91] Batch [50]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.077098,	
2017-07-21 03:52:49,591 Epoch[91] Batch [60]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.077167,	
2017-07-21 03:52:53,843 Epoch[91] Batch [70]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.076921,	
2017-07-21 03:52:58,349 Epoch[91] Batch [80]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.076843,	
2017-07-21 03:53:02,972 Epoch[91] Batch [90]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.076990,	
2017-07-21 03:53:07,923 Epoch[91] Batch [100]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.076075,	
2017-07-21 03:53:12,373 Epoch[91] Batch [110]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.076086,	
2017-07-21 03:53:16,940 Epoch[91] Batch [120]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075385,	
2017-07-21 03:53:21,416 Epoch[91] Batch [130]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075184,	
2017-07-21 03:53:26,035 Epoch[91] Batch [140]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.076009,	
2017-07-21 03:53:30,632 Epoch[91] Batch [150]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075975,	
2017-07-21 03:53:35,202 Epoch[91] Batch [160]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.076107,	
2017-07-21 03:53:40,045 Epoch[91] Batch [170]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075769,	
2017-07-21 03:53:44,513 Epoch[91] Batch [180]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075874,	
2017-07-21 03:53:49,170 Epoch[91] Batch [190]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.076172,	
2017-07-21 03:53:53,788 Epoch[91] Batch [200]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.075942,	
2017-07-21 03:53:58,204 Epoch[91] Batch [210]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075919,	
2017-07-21 03:54:02,913 Epoch[91] Batch [220]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076106,	
2017-07-21 03:54:07,346 Epoch[91] Batch [230]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.076146,	
2017-07-21 03:54:12,108 Epoch[91] Batch [240]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.076074,	
2017-07-21 03:54:16,651 Epoch[91] Batch [250]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.076098,	
2017-07-21 03:54:20,978 Epoch[91] Batch [260]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.076379,	
2017-07-21 03:54:25,470 Epoch[91] Batch [270]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.076295,	
2017-07-21 03:54:30,157 Epoch[91] Batch [280]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.076316,	
2017-07-21 03:54:34,847 Epoch[91] Batch [290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.076518,	
2017-07-21 03:54:39,380 Epoch[91] Batch [300]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.076381,	
2017-07-21 03:54:43,670 Epoch[91] Batch [310]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.076678,	
2017-07-21 03:54:48,000 Epoch[91] Batch [320]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.076495,	
2017-07-21 03:54:52,410 Epoch[91] Batch [330]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.076470,	
2017-07-21 03:54:57,021 Epoch[91] Batch [340]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076370,	
2017-07-21 03:55:01,393 Epoch[91] Batch [350]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.076377,	
2017-07-21 03:55:05,947 Epoch[91] Batch [360]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.076315,	
2017-07-21 03:55:10,649 Epoch[91] Batch [370]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.076370,	
2017-07-21 03:55:15,155 Epoch[91] Batch [380]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.076367,	
2017-07-21 03:55:19,630 Epoch[91] Batch [390]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.076454,	
2017-07-21 03:55:23,927 Epoch[91] Batch [400]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.076362,	
2017-07-21 03:55:28,213 Epoch[91] Batch [410]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.076300,	
2017-07-21 03:55:33,026 Epoch[91] Batch [420]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.076332,	
2017-07-21 03:55:37,478 Epoch[91] Batch [430]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.076526,	
2017-07-21 03:55:42,012 Epoch[91] Batch [440]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.076604,	
2017-07-21 03:55:46,417 Epoch[91] Batch [450]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.076474,	
2017-07-21 03:55:50,920 Epoch[91] Batch [460]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.076364,	
2017-07-21 03:55:55,355 Epoch[91] Batch [470]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.076278,	
2017-07-21 03:55:59,596 Epoch[91] Batch [480]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.076218,	
2017-07-21 03:56:03,840 Epoch[91] Batch [490]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.076127,	
2017-07-21 03:56:08,370 Epoch[91] Batch [500]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.076123,	
2017-07-21 03:56:12,639 Epoch[91] Batch [510]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.076053,	
2017-07-21 03:56:17,320 Epoch[91] Batch [520]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.076019,	
2017-07-21 03:56:21,861 Epoch[91] Batch [530]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.076118,	
2017-07-21 03:56:26,469 Epoch[91] Batch [540]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.076217,	
2017-07-21 03:56:31,249 Epoch[91] Batch [550]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.076208,	
2017-07-21 03:56:35,871 Epoch[91] Batch [560]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075988,	
2017-07-21 03:56:40,743 Epoch[91] Batch [570]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.076037,	
2017-07-21 03:56:45,042 Epoch[91] Batch [580]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.076101,	
2017-07-21 03:56:49,631 Epoch[91] Batch [590]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.076127,	
2017-07-21 03:56:54,371 Epoch[91] Batch [600]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076054,	
2017-07-21 03:56:58,822 Epoch[91] Batch [610]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.076012,	
2017-07-21 03:57:03,238 Epoch[91] Batch [620]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.076070,	
2017-07-21 03:57:07,548 Epoch[91] Batch [630]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075988,	
2017-07-21 03:57:11,846 Epoch[91] Batch [640]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.075984,	
2017-07-21 03:57:16,184 Epoch[91] Batch [650]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.075922,	
2017-07-21 03:57:20,648 Epoch[91] Batch [660]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075921,	
2017-07-21 03:57:25,006 Epoch[91] Batch [670]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075801,	
2017-07-21 03:57:29,388 Epoch[91] Batch [680]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075653,	
2017-07-21 03:57:33,751 Epoch[91] Batch [690]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075685,	
2017-07-21 03:57:38,104 Epoch[91] Batch [700]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075709,	
2017-07-21 03:57:42,889 Epoch[91] Batch [710]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.075676,	
2017-07-21 03:57:47,180 Epoch[91] Batch [720]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075640,	
2017-07-21 03:57:51,857 Epoch[91] Batch [730]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075595,	
2017-07-21 03:57:56,286 Epoch[91] Batch [740]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075515,	
2017-07-21 03:58:00,826 Epoch[91] Batch [750]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075397,	
2017-07-21 03:58:05,534 Epoch[91] Batch [760]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075389,	
2017-07-21 03:58:10,105 Epoch[91] Batch [770]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075387,	
2017-07-21 03:58:14,805 Epoch[91] Batch [780]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.075283,	
2017-07-21 03:58:19,442 Epoch[91] Batch [790]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075170,	
2017-07-21 03:58:23,774 Epoch[91] Batch [800]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075209,	
2017-07-21 03:58:28,143 Epoch[91] Batch [810]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.075273,	
2017-07-21 03:58:32,505 Epoch[91] Batch [820]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075238,	
2017-07-21 03:58:37,492 Epoch[91] Batch [830]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.075187,	
2017-07-21 03:58:41,868 Epoch[91] Batch [840]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075185,	
2017-07-21 03:58:46,361 Epoch[91] Batch [850]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075201,	
2017-07-21 03:58:50,524 Epoch[91] Batch [860]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.075306,	
2017-07-21 03:58:55,014 Epoch[91] Batch [870]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075417,	
2017-07-21 03:58:59,559 Epoch[91] Batch [880]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075388,	
2017-07-21 03:59:03,904 Epoch[91] Batch [890]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.075394,	
2017-07-21 03:59:08,345 Epoch[91] Batch [900]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075320,	
2017-07-21 03:59:12,933 Epoch[91] Batch [910]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075347,	
2017-07-21 03:59:17,539 Epoch[91] Batch [920]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.075351,	
2017-07-21 03:59:22,022 Epoch[91] Batch [930]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075377,	
2017-07-21 03:59:26,534 Epoch[91] Batch [940]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.075410,	
2017-07-21 03:59:30,923 Epoch[91] Batch [950]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075338,	
2017-07-21 03:59:35,500 Epoch[91] Batch [960]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075336,	
2017-07-21 03:59:40,352 Epoch[91] Batch [970]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.075398,	
2017-07-21 03:59:44,662 Epoch[91] Batch [980]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075394,	
2017-07-21 03:59:49,021 Epoch[91] Batch [990]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075464,	
2017-07-21 03:59:53,405 Epoch[91] Batch [1000]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075399,	
2017-07-21 03:59:57,662 Epoch[91] Batch [1010]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.075538,	
2017-07-21 04:00:01,982 Epoch[91] Batch [1020]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075537,	
2017-07-21 04:00:06,500 Epoch[91] Batch [1030]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075588,	
2017-07-21 04:00:11,045 Epoch[91] Batch [1040]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075572,	
2017-07-21 04:00:15,394 Epoch[91] Batch [1050]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.075544,	
2017-07-21 04:00:19,581 Epoch[91] Batch [1060]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.075461,	
2017-07-21 04:00:24,122 Epoch[91] Batch [1070]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075478,	
2017-07-21 04:00:28,485 Epoch[91] Batch [1080]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075434,	
2017-07-21 04:00:32,941 Epoch[91] Batch [1090]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075439,	
2017-07-21 04:00:37,435 Epoch[91] Batch [1100]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075466,	
2017-07-21 04:00:42,083 Epoch[91] Batch [1110]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075433,	
2017-07-21 04:00:46,345 Epoch[91] Batch [1120]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.075456,	
2017-07-21 04:00:50,940 Epoch[91] Batch [1130]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.075448,	
2017-07-21 04:00:55,430 Epoch[91] Batch [1140]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075438,	
2017-07-21 04:00:59,661 Epoch[91] Batch [1150]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.075425,	
2017-07-21 04:01:04,216 Epoch[91] Batch [1160]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075407,	
2017-07-21 04:01:08,584 Epoch[91] Batch [1170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.075374,	
2017-07-21 04:01:12,824 Epoch[91] Batch [1180]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075377,	
2017-07-21 04:01:17,172 Epoch[91] Batch [1190]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.075416,	
2017-07-21 04:01:21,575 Epoch[91] Batch [1200]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075398,	
2017-07-21 04:01:26,121 Epoch[91] Batch [1210]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075386,	
2017-07-21 04:01:30,768 Epoch[91] Batch [1220]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075344,	
2017-07-21 04:01:35,057 Epoch[91] Batch [1230]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.075330,	
2017-07-21 04:01:39,473 Epoch[91] Batch [1240]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075331,	
2017-07-21 04:01:44,020 Epoch[91] Batch [1250]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075345,	
2017-07-21 04:01:48,218 Epoch[91] Batch [1260]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.075392,	
2017-07-21 04:01:52,444 Epoch[91] Batch [1270]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075380,	
2017-07-21 04:01:56,552 Epoch[91] Batch [1280]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.075406,	
2017-07-21 04:02:01,016 Epoch[91] Batch [1290]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075409,	
2017-07-21 04:02:05,370 Epoch[91] Batch [1300]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075374,	
2017-07-21 04:02:09,398 Epoch[91] Batch [1310]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.075361,	
2017-07-21 04:02:14,251 Epoch[91] Batch [1320]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.075445,	
2017-07-21 04:02:18,789 Epoch[91] Batch [1330]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075478,	
2017-07-21 04:02:23,219 Epoch[91] Batch [1340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075470,	
2017-07-21 04:02:27,739 Epoch[91] Batch [1350]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075430,	
2017-07-21 04:02:32,476 Epoch[91] Batch [1360]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075367,	
2017-07-21 04:02:37,175 Epoch[91] Batch [1370]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.075377,	
2017-07-21 04:02:41,995 Epoch[91] Batch [1380]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075362,	
2017-07-21 04:02:46,905 Epoch[91] Batch [1390]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075362,	
2017-07-21 04:02:51,381 Epoch[91] Batch [1400]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075372,	
2017-07-21 04:02:55,902 Epoch[91] Batch [1410]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075382,	
2017-07-21 04:03:00,351 Epoch[91] Batch [1420]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075354,	
2017-07-21 04:03:05,165 Epoch[91] Batch [1430]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075390,	
2017-07-21 04:03:09,819 Epoch[91] Batch [1440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075431,	
2017-07-21 04:03:14,312 Epoch[91] Batch [1450]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075399,	
2017-07-21 04:03:18,938 Epoch[91] Batch [1460]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075457,	
2017-07-21 04:03:23,598 Epoch[91] Batch [1470]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.075451,	
2017-07-21 04:03:28,248 Epoch[91] Batch [1480]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075467,	
2017-07-21 04:03:30,861 Epoch[91] Train-FCNLogLoss=0.075472
2017-07-21 04:03:30,862 Epoch[91] Time cost=669.996
2017-07-21 04:03:31,741 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0092.params"
2017-07-21 04:03:36,461 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0092.states"
2017-07-21 04:03:42,280 Epoch[92] Batch [10]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.071557,	
2017-07-21 04:03:47,078 Epoch[92] Batch [20]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.076130,	
2017-07-21 04:03:51,564 Epoch[92] Batch [30]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.073806,	
2017-07-21 04:03:56,051 Epoch[92] Batch [40]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075213,	
2017-07-21 04:04:00,757 Epoch[92] Batch [50]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.076349,	
2017-07-21 04:04:05,187 Epoch[92] Batch [60]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075649,	
2017-07-21 04:04:09,407 Epoch[92] Batch [70]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.075962,	
2017-07-21 04:04:13,920 Epoch[92] Batch [80]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.076464,	
2017-07-21 04:04:18,132 Epoch[92] Batch [90]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.076120,	
2017-07-21 04:04:22,707 Epoch[92] Batch [100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.076944,	
2017-07-21 04:04:27,188 Epoch[92] Batch [110]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.076895,	
2017-07-21 04:04:31,849 Epoch[92] Batch [120]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.076723,	
2017-07-21 04:04:36,760 Epoch[92] Batch [130]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075864,	
2017-07-21 04:04:41,508 Epoch[92] Batch [140]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.076027,	
2017-07-21 04:04:46,504 Epoch[92] Batch [150]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075988,	
2017-07-21 04:04:50,989 Epoch[92] Batch [160]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.076253,	
2017-07-21 04:04:55,750 Epoch[92] Batch [170]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.076257,	
2017-07-21 04:05:00,347 Epoch[92] Batch [180]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.076640,	
2017-07-21 04:05:05,112 Epoch[92] Batch [190]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.076454,	
2017-07-21 04:05:09,404 Epoch[92] Batch [200]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.076372,	
2017-07-21 04:05:13,953 Epoch[92] Batch [210]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.076313,	
2017-07-21 04:05:18,675 Epoch[92] Batch [220]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.076504,	
2017-07-21 04:05:23,063 Epoch[92] Batch [230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.076369,	
2017-07-21 04:05:27,791 Epoch[92] Batch [240]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.076383,	
2017-07-21 04:05:32,315 Epoch[92] Batch [250]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.076339,	
2017-07-21 04:05:37,060 Epoch[92] Batch [260]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.076444,	
2017-07-21 04:05:41,623 Epoch[92] Batch [270]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.076489,	
2017-07-21 04:05:46,225 Epoch[92] Batch [280]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.076604,	
2017-07-21 04:05:50,870 Epoch[92] Batch [290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.076531,	
2017-07-21 04:05:55,798 Epoch[92] Batch [300]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.076281,	
2017-07-21 04:06:00,682 Epoch[92] Batch [310]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.076359,	
2017-07-21 04:06:05,423 Epoch[92] Batch [320]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.076360,	
2017-07-21 04:06:10,660 Epoch[92] Batch [330]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.076397,	
2017-07-21 04:06:15,913 Epoch[92] Batch [340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.076443,	
2017-07-21 04:06:20,975 Epoch[92] Batch [350]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.076353,	
2017-07-21 04:06:25,976 Epoch[92] Batch [360]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.076375,	
2017-07-21 04:06:30,909 Epoch[92] Batch [370]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.076404,	
2017-07-21 04:06:35,927 Epoch[92] Batch [380]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.076428,	
2017-07-21 04:06:41,233 Epoch[92] Batch [390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.076476,	
2017-07-21 04:06:46,548 Epoch[92] Batch [400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.076396,	
2017-07-21 04:06:51,722 Epoch[92] Batch [410]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.076454,	
2017-07-21 04:06:57,090 Epoch[92] Batch [420]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.076334,	
2017-07-21 04:07:02,380 Epoch[92] Batch [430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.076141,	
2017-07-21 04:07:06,706 Epoch[92] Batch [440]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.076001,	
2017-07-21 04:07:11,291 Epoch[92] Batch [450]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075973,	
2017-07-21 04:07:16,062 Epoch[92] Batch [460]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075856,	
2017-07-21 04:07:20,477 Epoch[92] Batch [470]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075761,	
2017-07-21 04:07:24,927 Epoch[92] Batch [480]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075787,	
2017-07-21 04:07:29,444 Epoch[92] Batch [490]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075711,	
2017-07-21 04:07:33,800 Epoch[92] Batch [500]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075650,	
2017-07-21 04:07:38,228 Epoch[92] Batch [510]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.075521,	
2017-07-21 04:07:42,540 Epoch[92] Batch [520]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075663,	
2017-07-21 04:07:46,869 Epoch[92] Batch [530]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075592,	
2017-07-21 04:07:51,183 Epoch[92] Batch [540]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075510,	
2017-07-21 04:07:55,694 Epoch[92] Batch [550]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.075617,	
2017-07-21 04:08:00,013 Epoch[92] Batch [560]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075619,	
2017-07-21 04:08:04,622 Epoch[92] Batch [570]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.075622,	
2017-07-21 04:08:09,083 Epoch[92] Batch [580]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.075606,	
2017-07-21 04:08:13,436 Epoch[92] Batch [590]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075642,	
2017-07-21 04:08:17,617 Epoch[92] Batch [600]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.075607,	
2017-07-21 04:08:21,998 Epoch[92] Batch [610]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075514,	
2017-07-21 04:08:26,122 Epoch[92] Batch [620]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.075569,	
2017-07-21 04:08:30,440 Epoch[92] Batch [630]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075639,	
2017-07-21 04:08:35,027 Epoch[92] Batch [640]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075622,	
2017-07-21 04:08:39,710 Epoch[92] Batch [650]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075680,	
2017-07-21 04:08:44,717 Epoch[92] Batch [660]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.075629,	
2017-07-21 04:08:49,382 Epoch[92] Batch [670]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.075628,	
2017-07-21 04:08:53,611 Epoch[92] Batch [680]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.075643,	
2017-07-21 04:08:58,199 Epoch[92] Batch [690]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075663,	
2017-07-21 04:09:02,363 Epoch[92] Batch [700]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.075559,	
2017-07-21 04:09:06,719 Epoch[92] Batch [710]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075508,	
2017-07-21 04:09:10,829 Epoch[92] Batch [720]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.075544,	
2017-07-21 04:09:15,084 Epoch[92] Batch [730]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.075471,	
2017-07-21 04:09:19,407 Epoch[92] Batch [740]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.075411,	
2017-07-21 04:09:23,793 Epoch[92] Batch [750]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075404,	
2017-07-21 04:09:28,243 Epoch[92] Batch [760]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075432,	
2017-07-21 04:09:32,828 Epoch[92] Batch [770]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.075398,	
2017-07-21 04:09:37,188 Epoch[92] Batch [780]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075332,	
2017-07-21 04:09:41,650 Epoch[92] Batch [790]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075385,	
2017-07-21 04:09:45,969 Epoch[92] Batch [800]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075398,	
2017-07-21 04:09:50,487 Epoch[92] Batch [810]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075472,	
2017-07-21 04:09:55,052 Epoch[92] Batch [820]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075496,	
2017-07-21 04:09:59,583 Epoch[92] Batch [830]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.075500,	
2017-07-21 04:10:04,332 Epoch[92] Batch [840]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.075539,	
2017-07-21 04:10:08,894 Epoch[92] Batch [850]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075523,	
2017-07-21 04:10:13,479 Epoch[92] Batch [860]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075475,	
2017-07-21 04:10:18,218 Epoch[92] Batch [870]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075430,	
2017-07-21 04:10:22,593 Epoch[92] Batch [880]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.075448,	
2017-07-21 04:10:27,086 Epoch[92] Batch [890]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075349,	
2017-07-21 04:10:31,754 Epoch[92] Batch [900]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075308,	
2017-07-21 04:10:36,549 Epoch[92] Batch [910]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075434,	
2017-07-21 04:10:41,017 Epoch[92] Batch [920]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075422,	
2017-07-21 04:10:45,650 Epoch[92] Batch [930]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075398,	
2017-07-21 04:10:50,097 Epoch[92] Batch [940]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.075419,	
2017-07-21 04:10:54,629 Epoch[92] Batch [950]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.075464,	
2017-07-21 04:10:58,971 Epoch[92] Batch [960]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.075483,	
2017-07-21 04:11:03,568 Epoch[92] Batch [970]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075568,	
2017-07-21 04:11:08,205 Epoch[92] Batch [980]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075539,	
2017-07-21 04:11:12,654 Epoch[92] Batch [990]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075476,	
2017-07-21 04:11:16,902 Epoch[92] Batch [1000]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.075574,	
2017-07-21 04:11:21,376 Epoch[92] Batch [1010]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075602,	
2017-07-21 04:11:26,022 Epoch[92] Batch [1020]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075605,	
2017-07-21 04:11:30,422 Epoch[92] Batch [1030]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075659,	
2017-07-21 04:11:35,097 Epoch[92] Batch [1040]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075632,	
2017-07-21 04:11:39,927 Epoch[92] Batch [1050]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.075620,	
2017-07-21 04:11:44,214 Epoch[92] Batch [1060]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.075618,	
2017-07-21 04:11:48,990 Epoch[92] Batch [1070]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075540,	
2017-07-21 04:11:53,951 Epoch[92] Batch [1080]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.075566,	
2017-07-21 04:11:58,629 Epoch[92] Batch [1090]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075664,	
2017-07-21 04:12:03,347 Epoch[92] Batch [1100]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075686,	
2017-07-21 04:12:07,789 Epoch[92] Batch [1110]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075660,	
2017-07-21 04:12:12,330 Epoch[92] Batch [1120]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075621,	
2017-07-21 04:12:17,012 Epoch[92] Batch [1130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075654,	
2017-07-21 04:12:21,412 Epoch[92] Batch [1140]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075631,	
2017-07-21 04:12:25,620 Epoch[92] Batch [1150]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075614,	
2017-07-21 04:12:30,244 Epoch[92] Batch [1160]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075669,	
2017-07-21 04:12:34,722 Epoch[92] Batch [1170]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.075668,	
2017-07-21 04:12:39,217 Epoch[92] Batch [1180]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075685,	
2017-07-21 04:12:43,742 Epoch[92] Batch [1190]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.075670,	
2017-07-21 04:12:48,280 Epoch[92] Batch [1200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075644,	
2017-07-21 04:12:52,955 Epoch[92] Batch [1210]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075733,	
2017-07-21 04:12:57,512 Epoch[92] Batch [1220]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075708,	
2017-07-21 04:13:01,951 Epoch[92] Batch [1230]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075668,	
2017-07-21 04:13:06,663 Epoch[92] Batch [1240]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.075654,	
2017-07-21 04:13:11,343 Epoch[92] Batch [1250]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075655,	
2017-07-21 04:13:15,736 Epoch[92] Batch [1260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075663,	
2017-07-21 04:13:20,473 Epoch[92] Batch [1270]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.075750,	
2017-07-21 04:13:24,939 Epoch[92] Batch [1280]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075775,	
2017-07-21 04:13:29,589 Epoch[92] Batch [1290]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075823,	
2017-07-21 04:13:34,191 Epoch[92] Batch [1300]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075778,	
2017-07-21 04:13:38,884 Epoch[92] Batch [1310]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075857,	
2017-07-21 04:13:43,514 Epoch[92] Batch [1320]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075765,	
2017-07-21 04:13:47,952 Epoch[92] Batch [1330]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075759,	
2017-07-21 04:13:52,684 Epoch[92] Batch [1340]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.075758,	
2017-07-21 04:13:57,735 Epoch[92] Batch [1350]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.075781,	
2017-07-21 04:14:02,495 Epoch[92] Batch [1360]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075826,	
2017-07-21 04:14:06,991 Epoch[92] Batch [1370]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075822,	
2017-07-21 04:14:11,397 Epoch[92] Batch [1380]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075762,	
2017-07-21 04:14:15,758 Epoch[92] Batch [1390]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075755,	
2017-07-21 04:14:20,019 Epoch[92] Batch [1400]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.075827,	
2017-07-21 04:14:24,392 Epoch[92] Batch [1410]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.075874,	
2017-07-21 04:14:28,690 Epoch[92] Batch [1420]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.075902,	
2017-07-21 04:14:33,234 Epoch[92] Batch [1430]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075925,	
2017-07-21 04:14:37,719 Epoch[92] Batch [1440]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075891,	
2017-07-21 04:14:42,355 Epoch[92] Batch [1450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075862,	
2017-07-21 04:14:46,930 Epoch[92] Batch [1460]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075842,	
2017-07-21 04:14:51,566 Epoch[92] Batch [1470]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075852,	
2017-07-21 04:14:56,272 Epoch[92] Batch [1480]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075875,	
2017-07-21 04:14:58,988 Epoch[92] Train-FCNLogLoss=0.075879
2017-07-21 04:14:58,988 Epoch[92] Time cost=682.526
2017-07-21 04:15:00,063 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0093.params"
2017-07-21 04:15:03,697 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0093.states"
2017-07-21 04:15:09,395 Epoch[93] Batch [10]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.076301,	
2017-07-21 04:15:14,104 Epoch[93] Batch [20]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076098,	
2017-07-21 04:15:19,092 Epoch[93] Batch [30]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.079206,	
2017-07-21 04:15:23,475 Epoch[93] Batch [40]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.077897,	
2017-07-21 04:15:28,093 Epoch[93] Batch [50]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.076611,	
2017-07-21 04:15:32,737 Epoch[93] Batch [60]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075814,	
2017-07-21 04:15:37,238 Epoch[93] Batch [70]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075744,	
2017-07-21 04:15:41,911 Epoch[93] Batch [80]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075754,	
2017-07-21 04:15:46,630 Epoch[93] Batch [90]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.076116,	
2017-07-21 04:15:51,255 Epoch[93] Batch [100]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.076740,	
2017-07-21 04:15:56,509 Epoch[93] Batch [110]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.076363,	
2017-07-21 04:16:01,543 Epoch[93] Batch [120]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.075634,	
2017-07-21 04:16:06,088 Epoch[93] Batch [130]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.076107,	
2017-07-21 04:16:11,028 Epoch[93] Batch [140]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075567,	
2017-07-21 04:16:16,214 Epoch[93] Batch [150]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.074993,	
2017-07-21 04:16:21,493 Epoch[93] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 04:16:26,654 Epoch[93] Batch [170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.075411,	
2017-07-21 04:16:31,197 Epoch[93] Batch [180]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075475,	
2017-07-21 04:16:35,958 Epoch[93] Batch [190]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075478,	
2017-07-21 04:16:40,995 Epoch[93] Batch [200]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075194,	
2017-07-21 04:16:45,479 Epoch[93] Batch [210]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075064,	
2017-07-21 04:16:50,072 Epoch[93] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.074909,	
2017-07-21 04:16:54,523 Epoch[93] Batch [230]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.074947,	
2017-07-21 04:16:59,323 Epoch[93] Batch [240]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.074718,	
2017-07-21 04:17:04,290 Epoch[93] Batch [250]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.074457,	
2017-07-21 04:17:08,722 Epoch[93] Batch [260]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.074624,	
2017-07-21 04:17:13,090 Epoch[93] Batch [270]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.074484,	
2017-07-21 04:17:17,535 Epoch[93] Batch [280]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.074416,	
2017-07-21 04:17:22,026 Epoch[93] Batch [290]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.074491,	
2017-07-21 04:17:26,382 Epoch[93] Batch [300]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.074542,	
2017-07-21 04:17:30,793 Epoch[93] Batch [310]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.074568,	
2017-07-21 04:17:34,934 Epoch[93] Batch [320]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.074575,	
2017-07-21 04:17:39,328 Epoch[93] Batch [330]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074384,	
2017-07-21 04:17:43,930 Epoch[93] Batch [340]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.074176,	
2017-07-21 04:17:48,359 Epoch[93] Batch [350]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.074219,	
2017-07-21 04:17:52,907 Epoch[93] Batch [360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.074170,	
2017-07-21 04:17:57,242 Epoch[93] Batch [370]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.074216,	
2017-07-21 04:18:01,627 Epoch[93] Batch [380]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.074385,	
2017-07-21 04:18:06,450 Epoch[93] Batch [390]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.074397,	
2017-07-21 04:18:10,939 Epoch[93] Batch [400]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.074472,	
2017-07-21 04:18:15,347 Epoch[93] Batch [410]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.074311,	
2017-07-21 04:18:19,899 Epoch[93] Batch [420]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.074503,	
2017-07-21 04:18:24,203 Epoch[93] Batch [430]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.074472,	
2017-07-21 04:18:28,661 Epoch[93] Batch [440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.074468,	
2017-07-21 04:18:33,185 Epoch[93] Batch [450]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.074769,	
2017-07-21 04:18:37,255 Epoch[93] Batch [460]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.074931,	
2017-07-21 04:18:41,677 Epoch[93] Batch [470]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075088,	
2017-07-21 04:18:46,658 Epoch[93] Batch [480]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.075050,	
2017-07-21 04:18:51,362 Epoch[93] Batch [490]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075026,	
2017-07-21 04:18:56,442 Epoch[93] Batch [500]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.075110,	
2017-07-21 04:19:01,232 Epoch[93] Batch [510]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.075044,	
2017-07-21 04:19:06,625 Epoch[93] Batch [520]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.075166,	
2017-07-21 04:19:11,564 Epoch[93] Batch [530]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075160,	
2017-07-21 04:19:16,010 Epoch[93] Batch [540]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.075189,	
2017-07-21 04:19:20,397 Epoch[93] Batch [550]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075343,	
2017-07-21 04:19:24,793 Epoch[93] Batch [560]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.075355,	
2017-07-21 04:19:29,570 Epoch[93] Batch [570]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075399,	
2017-07-21 04:19:34,170 Epoch[93] Batch [580]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075491,	
2017-07-21 04:19:38,697 Epoch[93] Batch [590]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.075566,	
2017-07-21 04:19:43,161 Epoch[93] Batch [600]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075762,	
2017-07-21 04:19:47,479 Epoch[93] Batch [610]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075733,	
2017-07-21 04:19:52,090 Epoch[93] Batch [620]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.075787,	
2017-07-21 04:19:57,034 Epoch[93] Batch [630]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.075747,	
2017-07-21 04:20:01,950 Epoch[93] Batch [640]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075708,	
2017-07-21 04:20:06,960 Epoch[93] Batch [650]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.075713,	
2017-07-21 04:20:11,971 Epoch[93] Batch [660]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.075718,	
2017-07-21 04:20:16,645 Epoch[93] Batch [670]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075700,	
2017-07-21 04:20:21,334 Epoch[93] Batch [680]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.075625,	
2017-07-21 04:20:26,349 Epoch[93] Batch [690]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.075611,	
2017-07-21 04:20:31,568 Epoch[93] Batch [700]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075639,	
2017-07-21 04:20:36,664 Epoch[93] Batch [710]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.075709,	
2017-07-21 04:20:42,361 Epoch[93] Batch [720]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.075720,	
2017-07-21 04:20:46,981 Epoch[93] Batch [730]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.075749,	
2017-07-21 04:20:51,901 Epoch[93] Batch [740]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.075716,	
2017-07-21 04:20:56,370 Epoch[93] Batch [750]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075719,	
2017-07-21 04:21:00,880 Epoch[93] Batch [760]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.075680,	
2017-07-21 04:21:05,599 Epoch[93] Batch [770]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075774,	
2017-07-21 04:21:10,209 Epoch[93] Batch [780]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.075837,	
2017-07-21 04:21:14,772 Epoch[93] Batch [790]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075805,	
2017-07-21 04:21:19,440 Epoch[93] Batch [800]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075847,	
2017-07-21 04:21:23,915 Epoch[93] Batch [810]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075817,	
2017-07-21 04:21:28,340 Epoch[93] Batch [820]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075865,	
2017-07-21 04:21:32,953 Epoch[93] Batch [830]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.075971,	
2017-07-21 04:21:37,661 Epoch[93] Batch [840]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075858,	
2017-07-21 04:21:42,368 Epoch[93] Batch [850]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075762,	
2017-07-21 04:21:47,027 Epoch[93] Batch [860]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075736,	
2017-07-21 04:21:52,001 Epoch[93] Batch [870]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075725,	
2017-07-21 04:21:56,852 Epoch[93] Batch [880]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075681,	
2017-07-21 04:22:02,205 Epoch[93] Batch [890]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.075730,	
2017-07-21 04:22:06,671 Epoch[93] Batch [900]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075770,	
2017-07-21 04:22:11,466 Epoch[93] Batch [910]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075777,	
2017-07-21 04:22:16,259 Epoch[93] Batch [920]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.075723,	
2017-07-21 04:22:21,632 Epoch[93] Batch [930]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.075752,	
2017-07-21 04:22:26,896 Epoch[93] Batch [940]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.075711,	
2017-07-21 04:22:31,805 Epoch[93] Batch [950]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075770,	
2017-07-21 04:22:36,925 Epoch[93] Batch [960]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.075734,	
2017-07-21 04:22:42,035 Epoch[93] Batch [970]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.075746,	
2017-07-21 04:22:46,968 Epoch[93] Batch [980]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.075757,	
2017-07-21 04:22:51,524 Epoch[93] Batch [990]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075724,	
2017-07-21 04:22:56,747 Epoch[93] Batch [1000]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.075682,	
2017-07-21 04:23:02,126 Epoch[93] Batch [1010]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.075777,	
2017-07-21 04:23:06,942 Epoch[93] Batch [1020]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075805,	
2017-07-21 04:23:11,688 Epoch[93] Batch [1030]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.075784,	
2017-07-21 04:23:16,498 Epoch[93] Batch [1040]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.075754,	
2017-07-21 04:23:20,913 Epoch[93] Batch [1050]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075751,	
2017-07-21 04:23:25,786 Epoch[93] Batch [1060]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.075788,	
2017-07-21 04:23:30,018 Epoch[93] Batch [1070]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.075765,	
2017-07-21 04:23:34,594 Epoch[93] Batch [1080]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075755,	
2017-07-21 04:23:39,304 Epoch[93] Batch [1090]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.075703,	
2017-07-21 04:23:44,334 Epoch[93] Batch [1100]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.075640,	
2017-07-21 04:23:49,211 Epoch[93] Batch [1110]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075627,	
2017-07-21 04:23:54,178 Epoch[93] Batch [1120]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.075678,	
2017-07-21 04:23:59,233 Epoch[93] Batch [1130]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.075628,	
2017-07-21 04:24:04,138 Epoch[93] Batch [1140]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075575,	
2017-07-21 04:24:08,947 Epoch[93] Batch [1150]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.075625,	
2017-07-21 04:24:14,003 Epoch[93] Batch [1160]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.075659,	
2017-07-21 04:24:18,498 Epoch[93] Batch [1170]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075661,	
2017-07-21 04:24:23,599 Epoch[93] Batch [1180]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.075626,	
2017-07-21 04:24:28,460 Epoch[93] Batch [1190]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075572,	
2017-07-21 04:24:33,039 Epoch[93] Batch [1200]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075590,	
2017-07-21 04:24:37,932 Epoch[93] Batch [1210]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.075563,	
2017-07-21 04:24:42,320 Epoch[93] Batch [1220]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.075602,	
2017-07-21 04:24:47,042 Epoch[93] Batch [1230]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.075591,	
2017-07-21 04:24:51,611 Epoch[93] Batch [1240]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075551,	
2017-07-21 04:24:56,694 Epoch[93] Batch [1250]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.075485,	
2017-07-21 04:25:01,517 Epoch[93] Batch [1260]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075480,	
2017-07-21 04:25:06,517 Epoch[93] Batch [1270]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.075454,	
2017-07-21 04:25:11,520 Epoch[93] Batch [1280]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.075445,	
2017-07-21 04:25:16,232 Epoch[93] Batch [1290]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.075427,	
2017-07-21 04:25:21,249 Epoch[93] Batch [1300]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.075417,	
2017-07-21 04:25:25,873 Epoch[93] Batch [1310]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075458,	
2017-07-21 04:25:30,909 Epoch[93] Batch [1320]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075442,	
2017-07-21 04:25:35,782 Epoch[93] Batch [1330]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.075411,	
2017-07-21 04:25:40,997 Epoch[93] Batch [1340]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075396,	
2017-07-21 04:25:45,448 Epoch[93] Batch [1350]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075373,	
2017-07-21 04:25:49,744 Epoch[93] Batch [1360]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.075398,	
2017-07-21 04:25:54,320 Epoch[93] Batch [1370]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075354,	
2017-07-21 04:25:58,691 Epoch[93] Batch [1380]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.075311,	
2017-07-21 04:26:03,215 Epoch[93] Batch [1390]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.075361,	
2017-07-21 04:26:08,112 Epoch[93] Batch [1400]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075371,	
2017-07-21 04:26:13,210 Epoch[93] Batch [1410]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.075332,	
2017-07-21 04:26:18,490 Epoch[93] Batch [1420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.075374,	
2017-07-21 04:26:22,900 Epoch[93] Batch [1430]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075394,	
2017-07-21 04:26:27,388 Epoch[93] Batch [1440]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075334,	
2017-07-21 04:26:31,564 Epoch[93] Batch [1450]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.075348,	
2017-07-21 04:26:35,764 Epoch[93] Batch [1460]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.075355,	
2017-07-21 04:26:40,393 Epoch[93] Batch [1470]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075357,	
2017-07-21 04:26:45,123 Epoch[93] Batch [1480]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.075390,	
2017-07-21 04:26:47,857 Epoch[93] Train-FCNLogLoss=0.075411
2017-07-21 04:26:47,858 Epoch[93] Time cost=704.160
2017-07-21 04:26:48,628 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0094.params"
2017-07-21 04:26:53,113 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0094.states"
2017-07-21 04:26:59,535 Epoch[94] Batch [10]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.078806,	
2017-07-21 04:27:04,413 Epoch[94] Batch [20]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.078852,	
2017-07-21 04:27:09,332 Epoch[94] Batch [30]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.077264,	
2017-07-21 04:27:14,069 Epoch[94] Batch [40]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.076213,	
2017-07-21 04:27:19,511 Epoch[94] Batch [50]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.075911,	
2017-07-21 04:27:24,281 Epoch[94] Batch [60]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075277,	
2017-07-21 04:27:29,059 Epoch[94] Batch [70]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075987,	
2017-07-21 04:27:34,236 Epoch[94] Batch [80]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.076295,	
2017-07-21 04:27:38,910 Epoch[94] Batch [90]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075754,	
2017-07-21 04:27:44,031 Epoch[94] Batch [100]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.075243,	
2017-07-21 04:27:48,543 Epoch[94] Batch [110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.074683,	
2017-07-21 04:27:53,261 Epoch[94] Batch [120]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075266,	
2017-07-21 04:27:58,039 Epoch[94] Batch [130]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075329,	
2017-07-21 04:28:02,894 Epoch[94] Batch [140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.075020,	
2017-07-21 04:28:08,228 Epoch[94] Batch [150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.074568,	
2017-07-21 04:28:12,777 Epoch[94] Batch [160]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.074829,	
2017-07-21 04:28:17,812 Epoch[94] Batch [170]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.074784,	
2017-07-21 04:28:22,252 Epoch[94] Batch [180]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.074416,	
2017-07-21 04:28:26,902 Epoch[94] Batch [190]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.074291,	
2017-07-21 04:28:31,400 Epoch[94] Batch [200]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.074428,	
2017-07-21 04:28:36,015 Epoch[94] Batch [210]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.074780,	
2017-07-21 04:28:40,542 Epoch[94] Batch [220]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.074780,	
2017-07-21 04:28:44,972 Epoch[94] Batch [230]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.074702,	
2017-07-21 04:28:50,388 Epoch[94] Batch [240]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.074653,	
2017-07-21 04:28:55,555 Epoch[94] Batch [250]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.074651,	
2017-07-21 04:29:00,477 Epoch[94] Batch [260]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.074758,	
2017-07-21 04:29:05,376 Epoch[94] Batch [270]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.074736,	
2017-07-21 04:29:09,993 Epoch[94] Batch [280]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.074643,	
2017-07-21 04:29:14,747 Epoch[94] Batch [290]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.074722,	
2017-07-21 04:29:19,077 Epoch[94] Batch [300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.074853,	
2017-07-21 04:29:23,815 Epoch[94] Batch [310]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.074835,	
2017-07-21 04:29:28,706 Epoch[94] Batch [320]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.074969,	
2017-07-21 04:29:33,517 Epoch[94] Batch [330]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.074876,	
2017-07-21 04:29:38,337 Epoch[94] Batch [340]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.074841,	
2017-07-21 04:29:42,788 Epoch[94] Batch [350]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075099,	
2017-07-21 04:29:48,008 Epoch[94] Batch [360]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.075317,	
2017-07-21 04:29:52,546 Epoch[94] Batch [370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.074896,	
2017-07-21 04:29:56,915 Epoch[94] Batch [380]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.074834,	
2017-07-21 04:30:01,376 Epoch[94] Batch [390]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.074826,	
2017-07-21 04:30:06,288 Epoch[94] Batch [400]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.074849,	
2017-07-21 04:30:11,458 Epoch[94] Batch [410]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.074816,	
2017-07-21 04:30:16,654 Epoch[94] Batch [420]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.074944,	
2017-07-21 04:30:21,724 Epoch[94] Batch [430]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.074902,	
2017-07-21 04:30:26,798 Epoch[94] Batch [440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.074832,	
2017-07-21 04:30:31,664 Epoch[94] Batch [450]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074862,	
2017-07-21 04:30:36,729 Epoch[94] Batch [460]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.075018,	
2017-07-21 04:30:41,521 Epoch[94] Batch [470]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.074978,	
2017-07-21 04:30:46,353 Epoch[94] Batch [480]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.074875,	
2017-07-21 04:30:51,595 Epoch[94] Batch [490]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.074819,	
2017-07-21 04:30:56,772 Epoch[94] Batch [500]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.074804,	
2017-07-21 04:31:01,320 Epoch[94] Batch [510]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.074778,	
2017-07-21 04:31:05,813 Epoch[94] Batch [520]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.074738,	
2017-07-21 04:31:10,061 Epoch[94] Batch [530]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.074801,	
2017-07-21 04:31:14,292 Epoch[94] Batch [540]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.074855,	
2017-07-21 04:31:18,656 Epoch[94] Batch [550]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.074795,	
2017-07-21 04:31:22,894 Epoch[94] Batch [560]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.074691,	
2017-07-21 04:31:27,238 Epoch[94] Batch [570]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.074786,	
2017-07-21 04:31:31,562 Epoch[94] Batch [580]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.074807,	
2017-07-21 04:31:36,144 Epoch[94] Batch [590]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.074861,	
2017-07-21 04:31:40,541 Epoch[94] Batch [600]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074868,	
2017-07-21 04:31:45,332 Epoch[94] Batch [610]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.074885,	
2017-07-21 04:31:49,881 Epoch[94] Batch [620]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.074927,	
2017-07-21 04:31:54,283 Epoch[94] Batch [630]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.074859,	
2017-07-21 04:31:58,854 Epoch[94] Batch [640]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.074774,	
2017-07-21 04:32:03,149 Epoch[94] Batch [650]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.074823,	
2017-07-21 04:32:07,653 Epoch[94] Batch [660]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.074811,	
2017-07-21 04:32:12,170 Epoch[94] Batch [670]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.074750,	
2017-07-21 04:32:16,444 Epoch[94] Batch [680]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.074896,	
2017-07-21 04:32:21,061 Epoch[94] Batch [690]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.074895,	
2017-07-21 04:32:26,100 Epoch[94] Batch [700]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.074793,	
2017-07-21 04:32:30,555 Epoch[94] Batch [710]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.074753,	
2017-07-21 04:32:35,686 Epoch[94] Batch [720]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.074684,	
2017-07-21 04:32:40,714 Epoch[94] Batch [730]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.074691,	
2017-07-21 04:32:45,274 Epoch[94] Batch [740]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.074725,	
2017-07-21 04:32:49,977 Epoch[94] Batch [750]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.074853,	
2017-07-21 04:32:54,343 Epoch[94] Batch [760]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.074836,	
2017-07-21 04:32:58,638 Epoch[94] Batch [770]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.074864,	
2017-07-21 04:33:03,328 Epoch[94] Batch [780]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.074918,	
2017-07-21 04:33:07,860 Epoch[94] Batch [790]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.074944,	
2017-07-21 04:33:12,195 Epoch[94] Batch [800]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.074953,	
2017-07-21 04:33:17,312 Epoch[94] Batch [810]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.074903,	
2017-07-21 04:33:22,335 Epoch[94] Batch [820]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.074825,	
2017-07-21 04:33:27,275 Epoch[94] Batch [830]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.074807,	
2017-07-21 04:33:32,637 Epoch[94] Batch [840]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.074738,	
2017-07-21 04:33:37,031 Epoch[94] Batch [850]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074817,	
2017-07-21 04:33:41,409 Epoch[94] Batch [860]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.074875,	
2017-07-21 04:33:45,874 Epoch[94] Batch [870]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.074828,	
2017-07-21 04:33:50,449 Epoch[94] Batch [880]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.074827,	
2017-07-21 04:33:54,725 Epoch[94] Batch [890]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.074945,	
2017-07-21 04:33:59,080 Epoch[94] Batch [900]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075068,	
2017-07-21 04:34:03,667 Epoch[94] Batch [910]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075057,	
2017-07-21 04:34:08,323 Epoch[94] Batch [920]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075016,	
2017-07-21 04:34:12,975 Epoch[94] Batch [930]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075008,	
2017-07-21 04:34:17,647 Epoch[94] Batch [940]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075073,	
2017-07-21 04:34:22,342 Epoch[94] Batch [950]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075109,	
2017-07-21 04:34:27,317 Epoch[94] Batch [960]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075110,	
2017-07-21 04:34:31,972 Epoch[94] Batch [970]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075182,	
2017-07-21 04:34:36,187 Epoch[94] Batch [980]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.075116,	
2017-07-21 04:34:41,058 Epoch[94] Batch [990]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.075034,	
2017-07-21 04:34:46,288 Epoch[94] Batch [1000]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.075189,	
2017-07-21 04:34:51,478 Epoch[94] Batch [1010]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 04:34:56,447 Epoch[94] Batch [1020]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.075162,	
2017-07-21 04:35:01,711 Epoch[94] Batch [1030]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.075138,	
2017-07-21 04:35:06,564 Epoch[94] Batch [1040]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.075158,	
2017-07-21 04:35:11,411 Epoch[94] Batch [1050]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075135,	
2017-07-21 04:35:15,806 Epoch[94] Batch [1060]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.075173,	
2017-07-21 04:35:20,283 Epoch[94] Batch [1070]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075189,	
2017-07-21 04:35:24,819 Epoch[94] Batch [1080]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075232,	
2017-07-21 04:35:29,273 Epoch[94] Batch [1090]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075235,	
2017-07-21 04:35:33,751 Epoch[94] Batch [1100]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.075155,	
2017-07-21 04:35:37,921 Epoch[94] Batch [1110]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.075155,	
2017-07-21 04:35:42,275 Epoch[94] Batch [1120]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075222,	
2017-07-21 04:35:46,686 Epoch[94] Batch [1130]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075300,	
2017-07-21 04:35:50,788 Epoch[94] Batch [1140]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.075311,	
2017-07-21 04:35:54,921 Epoch[94] Batch [1150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.075346,	
2017-07-21 04:35:59,225 Epoch[94] Batch [1160]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075283,	
2017-07-21 04:36:03,497 Epoch[94] Batch [1170]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075239,	
2017-07-21 04:36:07,779 Epoch[94] Batch [1180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075214,	
2017-07-21 04:36:12,252 Epoch[94] Batch [1190]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075207,	
2017-07-21 04:36:16,600 Epoch[94] Batch [1200]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.075182,	
2017-07-21 04:36:21,187 Epoch[94] Batch [1210]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075154,	
2017-07-21 04:36:25,429 Epoch[94] Batch [1220]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.075144,	
2017-07-21 04:36:29,898 Epoch[94] Batch [1230]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075110,	
2017-07-21 04:36:34,488 Epoch[94] Batch [1240]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075146,	
2017-07-21 04:36:38,805 Epoch[94] Batch [1250]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075134,	
2017-07-21 04:36:43,187 Epoch[94] Batch [1260]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075131,	
2017-07-21 04:36:47,581 Epoch[94] Batch [1270]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.075190,	
2017-07-21 04:36:52,393 Epoch[94] Batch [1280]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075183,	
2017-07-21 04:36:56,792 Epoch[94] Batch [1290]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075185,	
2017-07-21 04:37:01,362 Epoch[94] Batch [1300]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 04:37:06,358 Epoch[94] Batch [1310]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075216,	
2017-07-21 04:37:11,376 Epoch[94] Batch [1320]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 04:37:15,929 Epoch[94] Batch [1330]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.075200,	
2017-07-21 04:37:20,412 Epoch[94] Batch [1340]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075146,	
2017-07-21 04:37:24,732 Epoch[94] Batch [1350]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075166,	
2017-07-21 04:37:29,155 Epoch[94] Batch [1360]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075201,	
2017-07-21 04:37:33,781 Epoch[94] Batch [1370]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075214,	
2017-07-21 04:37:38,778 Epoch[94] Batch [1380]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075254,	
2017-07-21 04:37:43,685 Epoch[94] Batch [1390]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075208,	
2017-07-21 04:37:48,087 Epoch[94] Batch [1400]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.075183,	
2017-07-21 04:37:52,932 Epoch[94] Batch [1410]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075199,	
2017-07-21 04:37:57,627 Epoch[94] Batch [1420]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075217,	
2017-07-21 04:38:02,387 Epoch[94] Batch [1430]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075174,	
2017-07-21 04:38:07,391 Epoch[94] Batch [1440]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.075204,	
2017-07-21 04:38:12,451 Epoch[94] Batch [1450]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.075179,	
2017-07-21 04:38:17,627 Epoch[94] Batch [1460]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.075164,	
2017-07-21 04:38:22,522 Epoch[94] Batch [1470]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075147,	
2017-07-21 04:38:27,500 Epoch[94] Batch [1480]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075169,	
2017-07-21 04:38:30,536 Epoch[94] Train-FCNLogLoss=0.075172
2017-07-21 04:38:30,536 Epoch[94] Time cost=697.423
2017-07-21 04:38:31,285 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0095.params"
2017-07-21 04:38:35,912 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0095.states"
2017-07-21 04:38:42,049 Epoch[95] Batch [10]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.074471,	
2017-07-21 04:38:47,345 Epoch[95] Batch [20]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.080643,	
2017-07-21 04:38:52,597 Epoch[95] Batch [30]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.078852,	
2017-07-21 04:38:57,743 Epoch[95] Batch [40]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.076986,	
2017-07-21 04:39:02,414 Epoch[95] Batch [50]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.076481,	
2017-07-21 04:39:07,126 Epoch[95] Batch [60]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.076772,	
2017-07-21 04:39:12,242 Epoch[95] Batch [70]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.076646,	
2017-07-21 04:39:16,598 Epoch[95] Batch [80]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.077202,	
2017-07-21 04:39:21,378 Epoch[95] Batch [90]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.077019,	
2017-07-21 04:39:25,910 Epoch[95] Batch [100]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.076166,	
2017-07-21 04:39:29,975 Epoch[95] Batch [110]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.075310,	
2017-07-21 04:39:34,508 Epoch[95] Batch [120]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075162,	
2017-07-21 04:39:38,841 Epoch[95] Batch [130]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.074522,	
2017-07-21 04:39:43,180 Epoch[95] Batch [140]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.074798,	
2017-07-21 04:39:47,922 Epoch[95] Batch [150]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.074980,	
2017-07-21 04:39:52,371 Epoch[95] Batch [160]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075329,	
2017-07-21 04:39:56,812 Epoch[95] Batch [170]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075233,	
2017-07-21 04:40:01,744 Epoch[95] Batch [180]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.074739,	
2017-07-21 04:40:06,800 Epoch[95] Batch [190]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.074952,	
2017-07-21 04:40:11,497 Epoch[95] Batch [200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.074749,	
2017-07-21 04:40:15,932 Epoch[95] Batch [210]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.074770,	
2017-07-21 04:40:20,810 Epoch[95] Batch [220]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075049,	
2017-07-21 04:40:25,931 Epoch[95] Batch [230]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.074685,	
2017-07-21 04:40:30,588 Epoch[95] Batch [240]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.074443,	
2017-07-21 04:40:35,603 Epoch[95] Batch [250]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074575,	
2017-07-21 04:40:40,289 Epoch[95] Batch [260]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.074615,	
2017-07-21 04:40:45,615 Epoch[95] Batch [270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.074607,	
2017-07-21 04:40:50,592 Epoch[95] Batch [280]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.074519,	
2017-07-21 04:40:55,439 Epoch[95] Batch [290]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.074514,	
2017-07-21 04:41:00,475 Epoch[95] Batch [300]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.074514,	
2017-07-21 04:41:05,674 Epoch[95] Batch [310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.074813,	
2017-07-21 04:41:10,898 Epoch[95] Batch [320]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.074987,	
2017-07-21 04:41:15,825 Epoch[95] Batch [330]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.074921,	
2017-07-21 04:41:21,201 Epoch[95] Batch [340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.074864,	
2017-07-21 04:41:25,993 Epoch[95] Batch [350]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.074762,	
2017-07-21 04:41:31,190 Epoch[95] Batch [360]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.074757,	
2017-07-21 04:41:36,142 Epoch[95] Batch [370]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.074881,	
2017-07-21 04:41:40,954 Epoch[95] Batch [380]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.074823,	
2017-07-21 04:41:45,396 Epoch[95] Batch [390]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.074711,	
2017-07-21 04:41:50,280 Epoch[95] Batch [400]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.074796,	
2017-07-21 04:41:55,245 Epoch[95] Batch [410]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.074881,	
2017-07-21 04:42:00,200 Epoch[95] Batch [420]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.074980,	
2017-07-21 04:42:04,692 Epoch[95] Batch [430]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.075005,	
2017-07-21 04:42:09,431 Epoch[95] Batch [440]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075198,	
2017-07-21 04:42:14,028 Epoch[95] Batch [450]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075091,	
2017-07-21 04:42:18,601 Epoch[95] Batch [460]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075021,	
2017-07-21 04:42:23,398 Epoch[95] Batch [470]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075154,	
2017-07-21 04:42:28,199 Epoch[95] Batch [480]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.075117,	
2017-07-21 04:42:33,336 Epoch[95] Batch [490]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.075069,	
2017-07-21 04:42:38,435 Epoch[95] Batch [500]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.074929,	
2017-07-21 04:42:43,002 Epoch[95] Batch [510]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.074788,	
2017-07-21 04:42:47,791 Epoch[95] Batch [520]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.074719,	
2017-07-21 04:42:52,574 Epoch[95] Batch [530]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.074873,	
2017-07-21 04:42:57,443 Epoch[95] Batch [540]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074926,	
2017-07-21 04:43:02,651 Epoch[95] Batch [550]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.074924,	
2017-07-21 04:43:07,204 Epoch[95] Batch [560]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.074938,	
2017-07-21 04:43:12,348 Epoch[95] Batch [570]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.074891,	
2017-07-21 04:43:17,656 Epoch[95] Batch [580]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.074952,	
2017-07-21 04:43:22,678 Epoch[95] Batch [590]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.074859,	
2017-07-21 04:43:27,630 Epoch[95] Batch [600]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.075024,	
2017-07-21 04:43:32,834 Epoch[95] Batch [610]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.074954,	
2017-07-21 04:43:37,634 Epoch[95] Batch [620]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.074975,	
2017-07-21 04:43:42,216 Epoch[95] Batch [630]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.075008,	
2017-07-21 04:43:47,121 Epoch[95] Batch [640]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.075139,	
2017-07-21 04:43:52,051 Epoch[95] Batch [650]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.075071,	
2017-07-21 04:43:56,832 Epoch[95] Batch [660]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075000,	
2017-07-21 04:44:01,618 Epoch[95] Batch [670]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.075007,	
2017-07-21 04:44:06,685 Epoch[95] Batch [680]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.075106,	
2017-07-21 04:44:11,425 Epoch[95] Batch [690]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075097,	
2017-07-21 04:44:15,938 Epoch[95] Batch [700]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075113,	
2017-07-21 04:44:20,231 Epoch[95] Batch [710]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075176,	
2017-07-21 04:44:24,869 Epoch[95] Batch [720]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.075139,	
2017-07-21 04:44:29,732 Epoch[95] Batch [730]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075187,	
2017-07-21 04:44:33,983 Epoch[95] Batch [740]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.075186,	
2017-07-21 04:44:38,255 Epoch[95] Batch [750]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075138,	
2017-07-21 04:44:42,479 Epoch[95] Batch [760]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075248,	
2017-07-21 04:44:47,391 Epoch[95] Batch [770]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075286,	
2017-07-21 04:44:51,740 Epoch[95] Batch [780]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.075162,	
2017-07-21 04:44:56,131 Epoch[95] Batch [790]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075227,	
2017-07-21 04:45:00,475 Epoch[95] Batch [800]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.075174,	
2017-07-21 04:45:05,061 Epoch[95] Batch [810]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075127,	
2017-07-21 04:45:09,283 Epoch[95] Batch [820]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075056,	
2017-07-21 04:45:14,016 Epoch[95] Batch [830]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.075022,	
2017-07-21 04:45:18,510 Epoch[95] Batch [840]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075011,	
2017-07-21 04:45:22,810 Epoch[95] Batch [850]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.075037,	
2017-07-21 04:45:27,276 Epoch[95] Batch [860]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.075040,	
2017-07-21 04:45:31,912 Epoch[95] Batch [870]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075055,	
2017-07-21 04:45:36,879 Epoch[95] Batch [880]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.075061,	
2017-07-21 04:45:41,819 Epoch[95] Batch [890]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075058,	
2017-07-21 04:45:46,813 Epoch[95] Batch [900]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075081,	
2017-07-21 04:45:51,678 Epoch[95] Batch [910]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.075044,	
2017-07-21 04:45:56,390 Epoch[95] Batch [920]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.075070,	
2017-07-21 04:46:01,204 Epoch[95] Batch [930]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075065,	
2017-07-21 04:46:06,067 Epoch[95] Batch [940]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075074,	
2017-07-21 04:46:10,698 Epoch[95] Batch [950]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075043,	
2017-07-21 04:46:15,549 Epoch[95] Batch [960]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075006,	
2017-07-21 04:46:20,359 Epoch[95] Batch [970]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.074983,	
2017-07-21 04:46:25,090 Epoch[95] Batch [980]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.074867,	
2017-07-21 04:46:29,975 Epoch[95] Batch [990]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.074957,	
2017-07-21 04:46:34,438 Epoch[95] Batch [1000]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.074948,	
2017-07-21 04:46:39,159 Epoch[95] Batch [1010]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.074926,	
2017-07-21 04:46:43,295 Epoch[95] Batch [1020]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.074879,	
2017-07-21 04:46:47,862 Epoch[95] Batch [1030]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.074902,	
2017-07-21 04:46:52,868 Epoch[95] Batch [1040]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.074830,	
2017-07-21 04:46:57,620 Epoch[95] Batch [1050]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.074823,	
2017-07-21 04:47:02,216 Epoch[95] Batch [1060]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.074828,	
2017-07-21 04:47:07,028 Epoch[95] Batch [1070]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.074845,	
2017-07-21 04:47:11,863 Epoch[95] Batch [1080]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.074856,	
2017-07-21 04:47:16,293 Epoch[95] Batch [1090]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.074888,	
2017-07-21 04:47:21,295 Epoch[95] Batch [1100]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.074880,	
2017-07-21 04:47:25,828 Epoch[95] Batch [1110]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.074823,	
2017-07-21 04:47:30,775 Epoch[95] Batch [1120]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.074799,	
2017-07-21 04:47:35,697 Epoch[95] Batch [1130]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.074828,	
2017-07-21 04:47:41,016 Epoch[95] Batch [1140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.074877,	
2017-07-21 04:47:45,453 Epoch[95] Batch [1150]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.074809,	
2017-07-21 04:47:49,806 Epoch[95] Batch [1160]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.074808,	
2017-07-21 04:47:54,407 Epoch[95] Batch [1170]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.074792,	
2017-07-21 04:47:58,769 Epoch[95] Batch [1180]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.074777,	
2017-07-21 04:48:03,355 Epoch[95] Batch [1190]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.074840,	
2017-07-21 04:48:08,127 Epoch[95] Batch [1200]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.074870,	
2017-07-21 04:48:13,147 Epoch[95] Batch [1210]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.074845,	
2017-07-21 04:48:18,011 Epoch[95] Batch [1220]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074939,	
2017-07-21 04:48:23,219 Epoch[95] Batch [1230]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.074996,	
2017-07-21 04:48:28,236 Epoch[95] Batch [1240]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074994,	
2017-07-21 04:48:33,431 Epoch[95] Batch [1250]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.074917,	
2017-07-21 04:48:38,087 Epoch[95] Batch [1260]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.074889,	
2017-07-21 04:48:42,994 Epoch[95] Batch [1270]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.074915,	
2017-07-21 04:48:47,932 Epoch[95] Batch [1280]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.074946,	
2017-07-21 04:48:52,266 Epoch[95] Batch [1290]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.074933,	
2017-07-21 04:48:56,699 Epoch[95] Batch [1300]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.074941,	
2017-07-21 04:49:01,479 Epoch[95] Batch [1310]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.074947,	
2017-07-21 04:49:06,288 Epoch[95] Batch [1320]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.074930,	
2017-07-21 04:49:11,131 Epoch[95] Batch [1330]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.074938,	
2017-07-21 04:49:16,238 Epoch[95] Batch [1340]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.074952,	
2017-07-21 04:49:22,023 Epoch[95] Batch [1350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.074950,	
2017-07-21 04:49:27,931 Epoch[95] Batch [1360]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.074934,	
2017-07-21 04:49:32,930 Epoch[95] Batch [1370]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.074955,	
2017-07-21 04:49:38,076 Epoch[95] Batch [1380]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.074961,	
2017-07-21 04:49:43,503 Epoch[95] Batch [1390]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.074967,	
2017-07-21 04:49:48,420 Epoch[95] Batch [1400]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.074976,	
2017-07-21 04:49:53,611 Epoch[95] Batch [1410]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.074998,	
2017-07-21 04:49:58,303 Epoch[95] Batch [1420]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.075076,	
2017-07-21 04:50:03,421 Epoch[95] Batch [1430]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075107,	
2017-07-21 04:50:08,436 Epoch[95] Batch [1440]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.075134,	
2017-07-21 04:50:13,670 Epoch[95] Batch [1450]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.075112,	
2017-07-21 04:50:18,409 Epoch[95] Batch [1460]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075080,	
2017-07-21 04:50:23,105 Epoch[95] Batch [1470]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075111,	
2017-07-21 04:50:27,666 Epoch[95] Batch [1480]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075100,	
2017-07-21 04:50:30,488 Epoch[95] Train-FCNLogLoss=0.075130
2017-07-21 04:50:30,488 Epoch[95] Time cost=714.576
2017-07-21 04:50:31,317 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0096.params"
2017-07-21 04:50:35,962 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0096.states"
2017-07-21 04:50:41,484 Epoch[96] Batch [10]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.071529,	
2017-07-21 04:50:46,109 Epoch[96] Batch [20]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075859,	
2017-07-21 04:50:50,674 Epoch[96] Batch [30]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.074227,	
2017-07-21 04:50:55,506 Epoch[96] Batch [40]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.073970,	
2017-07-21 04:51:00,508 Epoch[96] Batch [50]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.074890,	
2017-07-21 04:51:05,401 Epoch[96] Batch [60]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.074670,	
2017-07-21 04:51:10,424 Epoch[96] Batch [70]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.074708,	
2017-07-21 04:51:14,884 Epoch[96] Batch [80]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.074711,	
2017-07-21 04:51:19,833 Epoch[96] Batch [90]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.074039,	
2017-07-21 04:51:24,190 Epoch[96] Batch [100]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075009,	
2017-07-21 04:51:28,669 Epoch[96] Batch [110]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.074281,	
2017-07-21 04:51:33,390 Epoch[96] Batch [120]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.073441,	
2017-07-21 04:51:38,560 Epoch[96] Batch [130]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.072438,	
2017-07-21 04:51:43,224 Epoch[96] Batch [140]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.072794,	
2017-07-21 04:51:48,359 Epoch[96] Batch [150]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.073526,	
2017-07-21 04:51:53,100 Epoch[96] Batch [160]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.073154,	
2017-07-21 04:51:57,698 Epoch[96] Batch [170]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.073530,	
2017-07-21 04:52:02,302 Epoch[96] Batch [180]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.073596,	
2017-07-21 04:52:07,173 Epoch[96] Batch [190]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.073480,	
2017-07-21 04:52:12,486 Epoch[96] Batch [200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.073657,	
2017-07-21 04:52:17,416 Epoch[96] Batch [210]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.073914,	
2017-07-21 04:52:22,205 Epoch[96] Batch [220]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.073907,	
2017-07-21 04:52:26,524 Epoch[96] Batch [230]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.073878,	
2017-07-21 04:52:31,635 Epoch[96] Batch [240]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.073650,	
2017-07-21 04:52:36,956 Epoch[96] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.073582,	
2017-07-21 04:52:41,997 Epoch[96] Batch [260]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.073562,	
2017-07-21 04:52:47,160 Epoch[96] Batch [270]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.073805,	
2017-07-21 04:52:52,502 Epoch[96] Batch [280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.073733,	
2017-07-21 04:52:57,202 Epoch[96] Batch [290]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.073997,	
2017-07-21 04:53:02,110 Epoch[96] Batch [300]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.074050,	
2017-07-21 04:53:06,751 Epoch[96] Batch [310]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.074025,	
2017-07-21 04:53:11,102 Epoch[96] Batch [320]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.073999,	
2017-07-21 04:53:15,485 Epoch[96] Batch [330]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074232,	
2017-07-21 04:53:19,958 Epoch[96] Batch [340]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.074140,	
2017-07-21 04:53:24,229 Epoch[96] Batch [350]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.074305,	
2017-07-21 04:53:28,623 Epoch[96] Batch [360]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074371,	
2017-07-21 04:53:33,171 Epoch[96] Batch [370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.074329,	
2017-07-21 04:53:37,438 Epoch[96] Batch [380]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.074384,	
2017-07-21 04:53:41,765 Epoch[96] Batch [390]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.074322,	
2017-07-21 04:53:46,548 Epoch[96] Batch [400]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.074406,	
2017-07-21 04:53:51,310 Epoch[96] Batch [410]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.074544,	
2017-07-21 04:53:56,285 Epoch[96] Batch [420]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.074497,	
2017-07-21 04:54:02,544 Epoch[96] Batch [430]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.074449,	
2017-07-21 04:54:07,134 Epoch[96] Batch [440]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.074486,	
2017-07-21 04:54:11,655 Epoch[96] Batch [450]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.074792,	
2017-07-21 04:54:16,414 Epoch[96] Batch [460]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.074792,	
2017-07-21 04:54:21,111 Epoch[96] Batch [470]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075019,	
2017-07-21 04:54:26,725 Epoch[96] Batch [480]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.075197,	
2017-07-21 04:54:31,420 Epoch[96] Batch [490]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075108,	
2017-07-21 04:54:35,985 Epoch[96] Batch [500]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.074915,	
2017-07-21 04:54:41,320 Epoch[96] Batch [510]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.074971,	
2017-07-21 04:54:46,106 Epoch[96] Batch [520]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.074965,	
2017-07-21 04:54:51,362 Epoch[96] Batch [530]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.074974,	
2017-07-21 04:54:56,220 Epoch[96] Batch [540]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.075012,	
2017-07-21 04:55:01,104 Epoch[96] Batch [550]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.074911,	
2017-07-21 04:55:06,142 Epoch[96] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.074872,	
2017-07-21 04:55:10,926 Epoch[96] Batch [570]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.074901,	
2017-07-21 04:55:15,903 Epoch[96] Batch [580]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.074930,	
2017-07-21 04:55:20,940 Epoch[96] Batch [590]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075036,	
2017-07-21 04:55:25,881 Epoch[96] Batch [600]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075096,	
2017-07-21 04:55:30,774 Epoch[96] Batch [610]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075230,	
2017-07-21 04:55:35,402 Epoch[96] Batch [620]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075234,	
2017-07-21 04:55:39,982 Epoch[96] Batch [630]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.075248,	
2017-07-21 04:55:44,561 Epoch[96] Batch [640]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075195,	
2017-07-21 04:55:49,221 Epoch[96] Batch [650]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.075144,	
2017-07-21 04:55:53,917 Epoch[96] Batch [660]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075212,	
2017-07-21 04:55:58,692 Epoch[96] Batch [670]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075300,	
2017-07-21 04:56:03,433 Epoch[96] Batch [680]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.075372,	
2017-07-21 04:56:08,414 Epoch[96] Batch [690]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.075327,	
2017-07-21 04:56:13,604 Epoch[96] Batch [700]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.075391,	
2017-07-21 04:56:17,846 Epoch[96] Batch [710]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.075330,	
2017-07-21 04:56:22,413 Epoch[96] Batch [720]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075283,	
2017-07-21 04:56:27,131 Epoch[96] Batch [730]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075273,	
2017-07-21 04:56:31,777 Epoch[96] Batch [740]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075310,	
2017-07-21 04:56:36,628 Epoch[96] Batch [750]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075204,	
2017-07-21 04:56:40,929 Epoch[96] Batch [760]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.075263,	
2017-07-21 04:56:45,087 Epoch[96] Batch [770]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.075258,	
2017-07-21 04:56:49,408 Epoch[96] Batch [780]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075219,	
2017-07-21 04:56:53,703 Epoch[96] Batch [790]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075276,	
2017-07-21 04:56:58,228 Epoch[96] Batch [800]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.075225,	
2017-07-21 04:57:02,801 Epoch[96] Batch [810]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.075260,	
2017-07-21 04:57:07,257 Epoch[96] Batch [820]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075283,	
2017-07-21 04:57:12,487 Epoch[96] Batch [830]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.075242,	
2017-07-21 04:57:17,456 Epoch[96] Batch [840]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.075280,	
2017-07-21 04:57:21,659 Epoch[96] Batch [850]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 04:57:26,235 Epoch[96] Batch [860]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075148,	
2017-07-21 04:57:30,696 Epoch[96] Batch [870]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.075070,	
2017-07-21 04:57:35,625 Epoch[96] Batch [880]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.075056,	
2017-07-21 04:57:40,164 Epoch[96] Batch [890]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075113,	
2017-07-21 04:57:45,097 Epoch[96] Batch [900]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.075135,	
2017-07-21 04:57:49,941 Epoch[96] Batch [910]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075107,	
2017-07-21 04:57:54,594 Epoch[96] Batch [920]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075107,	
2017-07-21 04:57:59,573 Epoch[96] Batch [930]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.075075,	
2017-07-21 04:58:04,450 Epoch[96] Batch [940]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075140,	
2017-07-21 04:58:09,289 Epoch[96] Batch [950]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075168,	
2017-07-21 04:58:14,212 Epoch[96] Batch [960]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.075118,	
2017-07-21 04:58:19,138 Epoch[96] Batch [970]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.075112,	
2017-07-21 04:58:24,366 Epoch[96] Batch [980]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.075057,	
2017-07-21 04:58:29,313 Epoch[96] Batch [990]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.074960,	
2017-07-21 04:58:34,180 Epoch[96] Batch [1000]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074974,	
2017-07-21 04:58:38,927 Epoch[96] Batch [1010]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.074979,	
2017-07-21 04:58:43,601 Epoch[96] Batch [1020]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.074944,	
2017-07-21 04:58:48,066 Epoch[96] Batch [1030]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.074962,	
2017-07-21 04:58:52,489 Epoch[96] Batch [1040]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075016,	
2017-07-21 04:58:57,312 Epoch[96] Batch [1050]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075119,	
2017-07-21 04:59:02,402 Epoch[96] Batch [1060]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.075090,	
2017-07-21 04:59:06,940 Epoch[96] Batch [1070]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075154,	
2017-07-21 04:59:11,882 Epoch[96] Batch [1080]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.075181,	
2017-07-21 04:59:17,271 Epoch[96] Batch [1090]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.075153,	
2017-07-21 04:59:22,332 Epoch[96] Batch [1100]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.075227,	
2017-07-21 04:59:27,449 Epoch[96] Batch [1110]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075216,	
2017-07-21 04:59:32,026 Epoch[96] Batch [1120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.075189,	
2017-07-21 04:59:36,675 Epoch[96] Batch [1130]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075157,	
2017-07-21 04:59:41,714 Epoch[96] Batch [1140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075129,	
2017-07-21 04:59:46,008 Epoch[96] Batch [1150]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.075147,	
2017-07-21 04:59:50,524 Epoch[96] Batch [1160]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075168,	
2017-07-21 04:59:54,995 Epoch[96] Batch [1170]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.075206,	
2017-07-21 05:00:00,146 Epoch[96] Batch [1180]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.075196,	
2017-07-21 05:00:04,579 Epoch[96] Batch [1190]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075215,	
2017-07-21 05:00:09,539 Epoch[96] Batch [1200]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.075235,	
2017-07-21 05:00:13,790 Epoch[96] Batch [1210]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.075261,	
2017-07-21 05:00:18,417 Epoch[96] Batch [1220]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075258,	
2017-07-21 05:00:22,556 Epoch[96] Batch [1230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.075225,	
2017-07-21 05:00:27,004 Epoch[96] Batch [1240]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075301,	
2017-07-21 05:00:31,641 Epoch[96] Batch [1250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075283,	
2017-07-21 05:00:36,729 Epoch[96] Batch [1260]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.075246,	
2017-07-21 05:00:41,491 Epoch[96] Batch [1270]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075228,	
2017-07-21 05:00:46,235 Epoch[96] Batch [1280]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.075166,	
2017-07-21 05:00:51,730 Epoch[96] Batch [1290]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.075162,	
2017-07-21 05:00:56,722 Epoch[96] Batch [1300]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075131,	
2017-07-21 05:01:01,756 Epoch[96] Batch [1310]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.075155,	
2017-07-21 05:01:06,790 Epoch[96] Batch [1320]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.075094,	
2017-07-21 05:01:11,819 Epoch[96] Batch [1330]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.075107,	
2017-07-21 05:01:16,864 Epoch[96] Batch [1340]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.075107,	
2017-07-21 05:01:21,635 Epoch[96] Batch [1350]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075126,	
2017-07-21 05:01:26,003 Epoch[96] Batch [1360]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.075184,	
2017-07-21 05:01:30,846 Epoch[96] Batch [1370]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075175,	
2017-07-21 05:01:35,862 Epoch[96] Batch [1380]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.075185,	
2017-07-21 05:01:40,782 Epoch[96] Batch [1390]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.075161,	
2017-07-21 05:01:45,440 Epoch[96] Batch [1400]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075143,	
2017-07-21 05:01:50,712 Epoch[96] Batch [1410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.075167,	
2017-07-21 05:01:55,308 Epoch[96] Batch [1420]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075154,	
2017-07-21 05:01:59,715 Epoch[96] Batch [1430]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075179,	
2017-07-21 05:02:04,149 Epoch[96] Batch [1440]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075223,	
2017-07-21 05:02:08,780 Epoch[96] Batch [1450]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075191,	
2017-07-21 05:02:13,556 Epoch[96] Batch [1460]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075147,	
2017-07-21 05:02:18,544 Epoch[96] Batch [1470]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.075156,	
2017-07-21 05:02:23,220 Epoch[96] Batch [1480]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.075148,	
2017-07-21 05:02:26,179 Epoch[96] Train-FCNLogLoss=0.075110
2017-07-21 05:02:26,179 Epoch[96] Time cost=710.216
2017-07-21 05:02:27,133 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0097.params"
2017-07-21 05:02:31,732 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0097.states"
2017-07-21 05:02:37,621 Epoch[97] Batch [10]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.080266,	
2017-07-21 05:02:42,883 Epoch[97] Batch [20]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.074967,	
2017-07-21 05:02:48,289 Epoch[97] Batch [30]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.076511,	
2017-07-21 05:02:52,790 Epoch[97] Batch [40]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.079867,	
2017-07-21 05:02:57,128 Epoch[97] Batch [50]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.079285,	
2017-07-21 05:03:02,128 Epoch[97] Batch [60]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.078403,	
2017-07-21 05:03:06,485 Epoch[97] Batch [70]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.077937,	
2017-07-21 05:03:10,798 Epoch[97] Batch [80]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.077634,	
2017-07-21 05:03:14,985 Epoch[97] Batch [90]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.077583,	
2017-07-21 05:03:19,350 Epoch[97] Batch [100]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.077370,	
2017-07-21 05:03:23,697 Epoch[97] Batch [110]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.076998,	
2017-07-21 05:03:27,943 Epoch[97] Batch [120]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.077279,	
2017-07-21 05:03:32,299 Epoch[97] Batch [130]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.076640,	
2017-07-21 05:03:37,015 Epoch[97] Batch [140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.077585,	
2017-07-21 05:03:41,182 Epoch[97] Batch [150]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.077385,	
2017-07-21 05:03:45,783 Epoch[97] Batch [160]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077154,	
2017-07-21 05:03:50,361 Epoch[97] Batch [170]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.076799,	
2017-07-21 05:03:54,774 Epoch[97] Batch [180]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.076432,	
2017-07-21 05:03:59,326 Epoch[97] Batch [190]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.076205,	
2017-07-21 05:04:03,934 Epoch[97] Batch [200]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.076176,	
2017-07-21 05:04:09,216 Epoch[97] Batch [210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.075903,	
2017-07-21 05:04:13,710 Epoch[97] Batch [220]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075685,	
2017-07-21 05:04:18,205 Epoch[97] Batch [230]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075363,	
2017-07-21 05:04:22,953 Epoch[97] Batch [240]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.075188,	
2017-07-21 05:04:28,216 Epoch[97] Batch [250]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.075214,	
2017-07-21 05:04:33,215 Epoch[97] Batch [260]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.075387,	
2017-07-21 05:04:37,960 Epoch[97] Batch [270]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.075414,	
2017-07-21 05:04:42,862 Epoch[97] Batch [280]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.075427,	
2017-07-21 05:04:47,295 Epoch[97] Batch [290]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075434,	
2017-07-21 05:04:51,797 Epoch[97] Batch [300]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075397,	
2017-07-21 05:04:56,240 Epoch[97] Batch [310]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.075215,	
2017-07-21 05:05:01,232 Epoch[97] Batch [320]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075294,	
2017-07-21 05:05:06,027 Epoch[97] Batch [330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075256,	
2017-07-21 05:05:10,629 Epoch[97] Batch [340]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075357,	
2017-07-21 05:05:15,463 Epoch[97] Batch [350]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075352,	
2017-07-21 05:05:20,544 Epoch[97] Batch [360]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.075540,	
2017-07-21 05:05:25,696 Epoch[97] Batch [370]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.075573,	
2017-07-21 05:05:30,563 Epoch[97] Batch [380]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.075478,	
2017-07-21 05:05:35,672 Epoch[97] Batch [390]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.075509,	
2017-07-21 05:05:40,300 Epoch[97] Batch [400]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.075428,	
2017-07-21 05:05:44,415 Epoch[97] Batch [410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.075539,	
2017-07-21 05:05:49,217 Epoch[97] Batch [420]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.075340,	
2017-07-21 05:05:53,820 Epoch[97] Batch [430]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075170,	
2017-07-21 05:05:58,148 Epoch[97] Batch [440]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.075060,	
2017-07-21 05:06:02,504 Epoch[97] Batch [450]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075002,	
2017-07-21 05:06:07,220 Epoch[97] Batch [460]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.074899,	
2017-07-21 05:06:11,932 Epoch[97] Batch [470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.074867,	
2017-07-21 05:06:16,285 Epoch[97] Batch [480]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.075049,	
2017-07-21 05:06:20,921 Epoch[97] Batch [490]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075152,	
2017-07-21 05:06:25,462 Epoch[97] Batch [500]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.075070,	
2017-07-21 05:06:30,440 Epoch[97] Batch [510]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075015,	
2017-07-21 05:06:35,108 Epoch[97] Batch [520]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.075040,	
2017-07-21 05:06:39,941 Epoch[97] Batch [530]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.074973,	
2017-07-21 05:06:44,754 Epoch[97] Batch [540]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.074889,	
2017-07-21 05:06:49,504 Epoch[97] Batch [550]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.074941,	
2017-07-21 05:06:54,130 Epoch[97] Batch [560]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075014,	
2017-07-21 05:06:59,033 Epoch[97] Batch [570]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.075080,	
2017-07-21 05:07:04,539 Epoch[97] Batch [580]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.075105,	
2017-07-21 05:07:09,656 Epoch[97] Batch [590]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075100,	
2017-07-21 05:07:14,747 Epoch[97] Batch [600]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.075139,	
2017-07-21 05:07:19,918 Epoch[97] Batch [610]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.075097,	
2017-07-21 05:07:25,513 Epoch[97] Batch [620]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.075121,	
2017-07-21 05:07:30,346 Epoch[97] Batch [630]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.075132,	
2017-07-21 05:07:35,652 Epoch[97] Batch [640]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.075217,	
2017-07-21 05:07:40,767 Epoch[97] Batch [650]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075248,	
2017-07-21 05:07:45,837 Epoch[97] Batch [660]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.075338,	
2017-07-21 05:07:50,829 Epoch[97] Batch [670]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075334,	
2017-07-21 05:07:55,856 Epoch[97] Batch [680]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.075356,	
2017-07-21 05:08:00,682 Epoch[97] Batch [690]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075250,	
2017-07-21 05:08:05,439 Epoch[97] Batch [700]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.075190,	
2017-07-21 05:08:10,493 Epoch[97] Batch [710]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.075178,	
2017-07-21 05:08:15,321 Epoch[97] Batch [720]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075252,	
2017-07-21 05:08:20,007 Epoch[97] Batch [730]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075271,	
2017-07-21 05:08:24,915 Epoch[97] Batch [740]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075254,	
2017-07-21 05:08:29,861 Epoch[97] Batch [750]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.075253,	
2017-07-21 05:08:34,836 Epoch[97] Batch [760]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075207,	
2017-07-21 05:08:39,477 Epoch[97] Batch [770]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.075270,	
2017-07-21 05:08:44,210 Epoch[97] Batch [780]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.075335,	
2017-07-21 05:08:49,429 Epoch[97] Batch [790]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075360,	
2017-07-21 05:08:54,142 Epoch[97] Batch [800]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.075340,	
2017-07-21 05:08:58,979 Epoch[97] Batch [810]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075247,	
2017-07-21 05:09:03,818 Epoch[97] Batch [820]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.075212,	
2017-07-21 05:09:08,599 Epoch[97] Batch [830]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075239,	
2017-07-21 05:09:13,514 Epoch[97] Batch [840]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075306,	
2017-07-21 05:09:18,471 Epoch[97] Batch [850]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.075418,	
2017-07-21 05:09:23,914 Epoch[97] Batch [860]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.075466,	
2017-07-21 05:09:28,796 Epoch[97] Batch [870]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.075510,	
2017-07-21 05:09:33,859 Epoch[97] Batch [880]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.075490,	
2017-07-21 05:09:38,877 Epoch[97] Batch [890]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.075484,	
2017-07-21 05:09:43,912 Epoch[97] Batch [900]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075481,	
2017-07-21 05:09:48,887 Epoch[97] Batch [910]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075419,	
2017-07-21 05:09:53,880 Epoch[97] Batch [920]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075467,	
2017-07-21 05:09:59,228 Epoch[97] Batch [930]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.075451,	
2017-07-21 05:10:04,342 Epoch[97] Batch [940]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075455,	
2017-07-21 05:10:09,255 Epoch[97] Batch [950]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075469,	
2017-07-21 05:10:13,859 Epoch[97] Batch [960]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075486,	
2017-07-21 05:10:18,404 Epoch[97] Batch [970]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.075430,	
2017-07-21 05:10:22,903 Epoch[97] Batch [980]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075414,	
2017-07-21 05:10:28,202 Epoch[97] Batch [990]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.075449,	
2017-07-21 05:10:32,769 Epoch[97] Batch [1000]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075381,	
2017-07-21 05:10:37,646 Epoch[97] Batch [1010]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075417,	
2017-07-21 05:10:42,636 Epoch[97] Batch [1020]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.075484,	
2017-07-21 05:10:47,281 Epoch[97] Batch [1030]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075461,	
2017-07-21 05:10:52,284 Epoch[97] Batch [1040]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.075489,	
2017-07-21 05:10:57,259 Epoch[97] Batch [1050]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.075546,	
2017-07-21 05:11:02,220 Epoch[97] Batch [1060]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.075466,	
2017-07-21 05:11:07,528 Epoch[97] Batch [1070]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.075531,	
2017-07-21 05:11:12,374 Epoch[97] Batch [1080]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.075509,	
2017-07-21 05:11:17,542 Epoch[97] Batch [1090]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.075510,	
2017-07-21 05:11:22,294 Epoch[97] Batch [1100]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.075507,	
2017-07-21 05:11:27,101 Epoch[97] Batch [1110]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.075488,	
2017-07-21 05:11:31,867 Epoch[97] Batch [1120]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075520,	
2017-07-21 05:11:36,389 Epoch[97] Batch [1130]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.075531,	
2017-07-21 05:11:41,564 Epoch[97] Batch [1140]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.075533,	
2017-07-21 05:11:46,324 Epoch[97] Batch [1150]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075617,	
2017-07-21 05:11:50,887 Epoch[97] Batch [1160]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.075606,	
2017-07-21 05:11:55,453 Epoch[97] Batch [1170]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075630,	
2017-07-21 05:11:59,914 Epoch[97] Batch [1180]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.075622,	
2017-07-21 05:12:04,322 Epoch[97] Batch [1190]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075579,	
2017-07-21 05:12:08,961 Epoch[97] Batch [1200]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.075509,	
2017-07-21 05:12:14,002 Epoch[97] Batch [1210]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075544,	
2017-07-21 05:12:19,118 Epoch[97] Batch [1220]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075509,	
2017-07-21 05:12:23,871 Epoch[97] Batch [1230]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.075525,	
2017-07-21 05:12:29,086 Epoch[97] Batch [1240]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075558,	
2017-07-21 05:12:34,302 Epoch[97] Batch [1250]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075563,	
2017-07-21 05:12:39,109 Epoch[97] Batch [1260]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.075583,	
2017-07-21 05:12:44,106 Epoch[97] Batch [1270]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075545,	
2017-07-21 05:12:49,091 Epoch[97] Batch [1280]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.075583,	
2017-07-21 05:12:54,097 Epoch[97] Batch [1290]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.075535,	
2017-07-21 05:12:59,204 Epoch[97] Batch [1300]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.075569,	
2017-07-21 05:13:03,842 Epoch[97] Batch [1310]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.075579,	
2017-07-21 05:13:08,675 Epoch[97] Batch [1320]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.075602,	
2017-07-21 05:13:13,861 Epoch[97] Batch [1330]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.075577,	
2017-07-21 05:13:18,399 Epoch[97] Batch [1340]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.075562,	
2017-07-21 05:13:23,226 Epoch[97] Batch [1350]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.075535,	
2017-07-21 05:13:28,023 Epoch[97] Batch [1360]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075493,	
2017-07-21 05:13:33,218 Epoch[97] Batch [1370]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.075491,	
2017-07-21 05:13:38,155 Epoch[97] Batch [1380]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075437,	
2017-07-21 05:13:42,968 Epoch[97] Batch [1390]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075426,	
2017-07-21 05:13:47,950 Epoch[97] Batch [1400]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.075405,	
2017-07-21 05:13:52,723 Epoch[97] Batch [1410]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075428,	
2017-07-21 05:13:57,167 Epoch[97] Batch [1420]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.075394,	
2017-07-21 05:14:02,587 Epoch[97] Batch [1430]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.075368,	
2017-07-21 05:14:07,801 Epoch[97] Batch [1440]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.075361,	
2017-07-21 05:14:12,759 Epoch[97] Batch [1450]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.075373,	
2017-07-21 05:14:17,854 Epoch[97] Batch [1460]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.075326,	
2017-07-21 05:14:22,259 Epoch[97] Batch [1470]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.075264,	
2017-07-21 05:14:26,892 Epoch[97] Batch [1480]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.075258,	
2017-07-21 05:14:29,557 Epoch[97] Train-FCNLogLoss=0.075237
2017-07-21 05:14:29,557 Epoch[97] Time cost=717.824
2017-07-21 05:14:30,361 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0098.params"
2017-07-21 05:14:34,821 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0098.states"
2017-07-21 05:14:41,362 Epoch[98] Batch [10]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.078036,	
2017-07-21 05:14:46,541 Epoch[98] Batch [20]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.074845,	
2017-07-21 05:14:52,122 Epoch[98] Batch [30]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.074197,	
2017-07-21 05:14:57,672 Epoch[98] Batch [40]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.075339,	
2017-07-21 05:15:02,744 Epoch[98] Batch [50]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.075758,	
2017-07-21 05:15:08,531 Epoch[98] Batch [60]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.075242,	
2017-07-21 05:15:13,934 Epoch[98] Batch [70]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.074420,	
2017-07-21 05:15:19,297 Epoch[98] Batch [80]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.074368,	
2017-07-21 05:15:24,676 Epoch[98] Batch [90]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.074335,	
2017-07-21 05:15:29,224 Epoch[98] Batch [100]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.073950,	
2017-07-21 05:15:33,908 Epoch[98] Batch [110]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.074193,	
2017-07-21 05:15:38,899 Epoch[98] Batch [120]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.074365,	
2017-07-21 05:15:43,397 Epoch[98] Batch [130]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.073884,	
2017-07-21 05:15:48,199 Epoch[98] Batch [140]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.073776,	
2017-07-21 05:15:52,870 Epoch[98] Batch [150]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.073672,	
2017-07-21 05:15:58,104 Epoch[98] Batch [160]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.073310,	
2017-07-21 05:16:02,580 Epoch[98] Batch [170]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.073723,	
2017-07-21 05:16:07,314 Epoch[98] Batch [180]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.074009,	
2017-07-21 05:16:12,296 Epoch[98] Batch [190]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.074021,	
2017-07-21 05:16:17,310 Epoch[98] Batch [200]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074352,	
2017-07-21 05:16:22,726 Epoch[98] Batch [210]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.074105,	
2017-07-21 05:16:27,673 Epoch[98] Batch [220]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.074245,	
2017-07-21 05:16:32,577 Epoch[98] Batch [230]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.073802,	
2017-07-21 05:16:37,892 Epoch[98] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.073957,	
2017-07-21 05:16:42,941 Epoch[98] Batch [250]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.073832,	
2017-07-21 05:16:48,183 Epoch[98] Batch [260]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.073780,	
2017-07-21 05:16:53,280 Epoch[98] Batch [270]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.073565,	
2017-07-21 05:16:58,440 Epoch[98] Batch [280]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.073782,	
2017-07-21 05:17:03,452 Epoch[98] Batch [290]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.073983,	
2017-07-21 05:17:08,771 Epoch[98] Batch [300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.073777,	
2017-07-21 05:17:13,643 Epoch[98] Batch [310]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.073973,	
2017-07-21 05:17:19,107 Epoch[98] Batch [320]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.074036,	
2017-07-21 05:17:24,351 Epoch[98] Batch [330]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.073852,	
2017-07-21 05:17:29,493 Epoch[98] Batch [340]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.073874,	
2017-07-21 05:17:34,717 Epoch[98] Batch [350]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.074061,	
2017-07-21 05:17:40,090 Epoch[98] Batch [360]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.074041,	
2017-07-21 05:17:45,214 Epoch[98] Batch [370]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.074197,	
2017-07-21 05:17:50,119 Epoch[98] Batch [380]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.074192,	
2017-07-21 05:17:54,948 Epoch[98] Batch [390]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.073998,	
2017-07-21 05:17:59,985 Epoch[98] Batch [400]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.074086,	
2017-07-21 05:18:04,879 Epoch[98] Batch [410]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.074208,	
2017-07-21 05:18:09,502 Epoch[98] Batch [420]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.074408,	
2017-07-21 05:18:14,093 Epoch[98] Batch [430]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.074434,	
2017-07-21 05:18:18,815 Epoch[98] Batch [440]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.074478,	
2017-07-21 05:18:24,032 Epoch[98] Batch [450]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.074632,	
2017-07-21 05:18:29,065 Epoch[98] Batch [460]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.074640,	
2017-07-21 05:18:34,426 Epoch[98] Batch [470]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.074383,	
2017-07-21 05:18:39,770 Epoch[98] Batch [480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.074411,	
2017-07-21 05:18:44,422 Epoch[98] Batch [490]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.074281,	
2017-07-21 05:18:48,822 Epoch[98] Batch [500]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.074145,	
2017-07-21 05:18:53,500 Epoch[98] Batch [510]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.074130,	
2017-07-21 05:18:58,056 Epoch[98] Batch [520]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.074166,	
2017-07-21 05:19:02,669 Epoch[98] Batch [530]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.074185,	
2017-07-21 05:19:07,287 Epoch[98] Batch [540]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.074250,	
2017-07-21 05:19:11,567 Epoch[98] Batch [550]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.074228,	
2017-07-21 05:19:16,052 Epoch[98] Batch [560]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.074192,	
2017-07-21 05:19:20,485 Epoch[98] Batch [570]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.074121,	
2017-07-21 05:19:25,481 Epoch[98] Batch [580]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.074161,	
2017-07-21 05:19:31,054 Epoch[98] Batch [590]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.074081,	
2017-07-21 05:19:36,141 Epoch[98] Batch [600]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.074185,	
2017-07-21 05:19:41,402 Epoch[98] Batch [610]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.074168,	
2017-07-21 05:19:46,353 Epoch[98] Batch [620]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.074142,	
2017-07-21 05:19:51,424 Epoch[98] Batch [630]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.074195,	
2017-07-21 05:19:56,456 Epoch[98] Batch [640]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.074283,	
2017-07-21 05:20:01,227 Epoch[98] Batch [650]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.074244,	
2017-07-21 05:20:05,835 Epoch[98] Batch [660]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.074298,	
2017-07-21 05:20:10,887 Epoch[98] Batch [670]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.074350,	
2017-07-21 05:20:15,687 Epoch[98] Batch [680]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.074351,	
2017-07-21 05:20:20,737 Epoch[98] Batch [690]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.074322,	
2017-07-21 05:20:26,031 Epoch[98] Batch [700]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.074297,	
2017-07-21 05:20:31,112 Epoch[98] Batch [710]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.074443,	
2017-07-21 05:20:36,690 Epoch[98] Batch [720]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.074396,	
2017-07-21 05:20:41,771 Epoch[98] Batch [730]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.074245,	
2017-07-21 05:20:47,083 Epoch[98] Batch [740]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.074297,	
2017-07-21 05:20:52,901 Epoch[98] Batch [750]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.074327,	
2017-07-21 05:20:57,603 Epoch[98] Batch [760]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.074263,	
2017-07-21 05:21:02,601 Epoch[98] Batch [770]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.074263,	
2017-07-21 05:21:07,876 Epoch[98] Batch [780]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.074243,	
2017-07-21 05:21:12,644 Epoch[98] Batch [790]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.074289,	
2017-07-21 05:21:17,718 Epoch[98] Batch [800]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.074388,	
2017-07-21 05:21:22,702 Epoch[98] Batch [810]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.074375,	
2017-07-21 05:21:28,158 Epoch[98] Batch [820]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.074376,	
2017-07-21 05:21:33,260 Epoch[98] Batch [830]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.074330,	
2017-07-21 05:21:38,286 Epoch[98] Batch [840]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.074367,	
2017-07-21 05:21:43,294 Epoch[98] Batch [850]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.074308,	
2017-07-21 05:21:48,390 Epoch[98] Batch [860]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.074457,	
2017-07-21 05:21:53,239 Epoch[98] Batch [870]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.074405,	
2017-07-21 05:21:58,470 Epoch[98] Batch [880]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.074390,	
2017-07-21 05:22:04,029 Epoch[98] Batch [890]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.074435,	
2017-07-21 05:22:09,022 Epoch[98] Batch [900]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.074423,	
2017-07-21 05:22:14,205 Epoch[98] Batch [910]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.074514,	
2017-07-21 05:22:19,152 Epoch[98] Batch [920]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.074538,	
2017-07-21 05:22:23,734 Epoch[98] Batch [930]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.074592,	
2017-07-21 05:22:28,231 Epoch[98] Batch [940]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.074578,	
2017-07-21 05:22:33,002 Epoch[98] Batch [950]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.074547,	
2017-07-21 05:22:38,101 Epoch[98] Batch [960]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.074546,	
2017-07-21 05:22:43,444 Epoch[98] Batch [970]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.074597,	
2017-07-21 05:22:48,317 Epoch[98] Batch [980]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.074674,	
2017-07-21 05:22:53,324 Epoch[98] Batch [990]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.074676,	
2017-07-21 05:22:58,181 Epoch[98] Batch [1000]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.074666,	
2017-07-21 05:23:03,226 Epoch[98] Batch [1010]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.074702,	
2017-07-21 05:23:08,037 Epoch[98] Batch [1020]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.074756,	
2017-07-21 05:23:12,676 Epoch[98] Batch [1030]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.074763,	
2017-07-21 05:23:17,195 Epoch[98] Batch [1040]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.074790,	
2017-07-21 05:23:21,587 Epoch[98] Batch [1050]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.074805,	
2017-07-21 05:23:26,257 Epoch[98] Batch [1060]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.074812,	
2017-07-21 05:23:30,550 Epoch[98] Batch [1070]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.074843,	
2017-07-21 05:23:35,532 Epoch[98] Batch [1080]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.074875,	
2017-07-21 05:23:40,670 Epoch[98] Batch [1090]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.074870,	
2017-07-21 05:23:44,962 Epoch[98] Batch [1100]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.074815,	
2017-07-21 05:23:49,540 Epoch[98] Batch [1110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.074789,	
2017-07-21 05:23:54,080 Epoch[98] Batch [1120]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.074771,	
2017-07-21 05:23:58,985 Epoch[98] Batch [1130]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.074861,	
2017-07-21 05:24:03,486 Epoch[98] Batch [1140]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.074892,	
2017-07-21 05:24:07,819 Epoch[98] Batch [1150]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.074899,	
2017-07-21 05:24:12,913 Epoch[98] Batch [1160]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.074907,	
2017-07-21 05:24:18,048 Epoch[98] Batch [1170]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.074920,	
2017-07-21 05:24:22,858 Epoch[98] Batch [1180]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.074917,	
2017-07-21 05:24:27,853 Epoch[98] Batch [1190]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.074933,	
2017-07-21 05:24:32,452 Epoch[98] Batch [1200]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.074882,	
2017-07-21 05:24:37,262 Epoch[98] Batch [1210]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.074877,	
2017-07-21 05:24:41,983 Epoch[98] Batch [1220]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.074930,	
2017-07-21 05:24:46,891 Epoch[98] Batch [1230]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.074893,	
2017-07-21 05:24:51,533 Epoch[98] Batch [1240]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.074892,	
2017-07-21 05:24:56,084 Epoch[98] Batch [1250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.074902,	
2017-07-21 05:25:00,957 Epoch[98] Batch [1260]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.074792,	
2017-07-21 05:25:05,773 Epoch[98] Batch [1270]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.074746,	
2017-07-21 05:25:10,225 Epoch[98] Batch [1280]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.074776,	
2017-07-21 05:25:14,799 Epoch[98] Batch [1290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.074727,	
2017-07-21 05:25:19,104 Epoch[98] Batch [1300]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.074724,	
2017-07-21 05:25:23,810 Epoch[98] Batch [1310]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.074771,	
2017-07-21 05:25:28,267 Epoch[98] Batch [1320]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.074812,	
2017-07-21 05:25:32,568 Epoch[98] Batch [1330]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.074806,	
2017-07-21 05:25:36,870 Epoch[98] Batch [1340]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.074779,	
2017-07-21 05:25:41,415 Epoch[98] Batch [1350]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.074752,	
2017-07-21 05:25:46,085 Epoch[98] Batch [1360]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.074775,	
2017-07-21 05:25:50,568 Epoch[98] Batch [1370]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.074788,	
2017-07-21 05:25:55,028 Epoch[98] Batch [1380]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.074772,	
2017-07-21 05:25:59,261 Epoch[98] Batch [1390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.074750,	
2017-07-21 05:26:04,039 Epoch[98] Batch [1400]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.074719,	
2017-07-21 05:26:08,438 Epoch[98] Batch [1410]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.074720,	
2017-07-21 05:26:13,023 Epoch[98] Batch [1420]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.074728,	
2017-07-21 05:26:17,490 Epoch[98] Batch [1430]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.074719,	
2017-07-21 05:26:21,886 Epoch[98] Batch [1440]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074680,	
2017-07-21 05:26:26,380 Epoch[98] Batch [1450]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.074648,	
2017-07-21 05:26:31,053 Epoch[98] Batch [1460]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.074671,	
2017-07-21 05:26:36,381 Epoch[98] Batch [1470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.074688,	
2017-07-21 05:26:41,524 Epoch[98] Batch [1480]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.074725,	
2017-07-21 05:26:44,545 Epoch[98] Train-FCNLogLoss=0.074743
2017-07-21 05:26:44,545 Epoch[98] Time cost=729.724
2017-07-21 05:26:45,198 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0099.params"
2017-07-21 05:26:49,637 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0099.states"
2017-07-21 05:26:55,925 Epoch[99] Batch [10]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.062532,	
2017-07-21 05:27:00,956 Epoch[99] Batch [20]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.068554,	
2017-07-21 05:27:06,382 Epoch[99] Batch [30]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.069248,	
2017-07-21 05:27:11,416 Epoch[99] Batch [40]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.070133,	
2017-07-21 05:27:16,247 Epoch[99] Batch [50]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.072996,	
2017-07-21 05:27:20,966 Epoch[99] Batch [60]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.073411,	
2017-07-21 05:27:25,541 Epoch[99] Batch [70]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.073502,	
2017-07-21 05:27:30,249 Epoch[99] Batch [80]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.073095,	
2017-07-21 05:27:35,167 Epoch[99] Batch [90]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.074156,	
2017-07-21 05:27:39,675 Epoch[99] Batch [100]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.073466,	
2017-07-21 05:27:45,065 Epoch[99] Batch [110]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.073999,	
2017-07-21 05:27:50,227 Epoch[99] Batch [120]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.074359,	
2017-07-21 05:27:54,909 Epoch[99] Batch [130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.074721,	
2017-07-21 05:28:00,023 Epoch[99] Batch [140]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.075042,	
2017-07-21 05:28:05,147 Epoch[99] Batch [150]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.075495,	
2017-07-21 05:28:10,423 Epoch[99] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.075374,	
2017-07-21 05:28:15,427 Epoch[99] Batch [170]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.075069,	
2017-07-21 05:28:20,458 Epoch[99] Batch [180]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.075279,	
2017-07-21 05:28:25,521 Epoch[99] Batch [190]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.075452,	
2017-07-21 05:28:30,753 Epoch[99] Batch [200]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.075748,	
2017-07-21 05:28:35,790 Epoch[99] Batch [210]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075738,	
2017-07-21 05:28:40,577 Epoch[99] Batch [220]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.076252,	
2017-07-21 05:28:45,255 Epoch[99] Batch [230]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.076149,	
2017-07-21 05:28:49,976 Epoch[99] Batch [240]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.076206,	
2017-07-21 05:28:55,049 Epoch[99] Batch [250]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.076212,	
2017-07-21 05:28:59,996 Epoch[99] Batch [260]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.076304,	
2017-07-21 05:29:04,799 Epoch[99] Batch [270]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.076271,	
2017-07-21 05:29:09,521 Epoch[99] Batch [280]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.076240,	
2017-07-21 05:29:14,417 Epoch[99] Batch [290]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.076208,	
2017-07-21 05:29:19,624 Epoch[99] Batch [300]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.076197,	
2017-07-21 05:29:24,501 Epoch[99] Batch [310]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.076133,	
2017-07-21 05:29:29,425 Epoch[99] Batch [320]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.075923,	
2017-07-21 05:29:34,224 Epoch[99] Batch [330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.076246,	
2017-07-21 05:29:39,250 Epoch[99] Batch [340]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.076179,	
2017-07-21 05:29:44,097 Epoch[99] Batch [350]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.076120,	
2017-07-21 05:29:48,817 Epoch[99] Batch [360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.075876,	
2017-07-21 05:29:53,572 Epoch[99] Batch [370]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.075843,	
2017-07-21 05:29:58,991 Epoch[99] Batch [380]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.075899,	
2017-07-21 05:30:03,836 Epoch[99] Batch [390]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.075942,	
2017-07-21 05:30:08,533 Epoch[99] Batch [400]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075947,	
2017-07-21 05:30:13,432 Epoch[99] Batch [410]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075799,	
2017-07-21 05:30:17,823 Epoch[99] Batch [420]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075727,	
2017-07-21 05:30:22,428 Epoch[99] Batch [430]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075774,	
2017-07-21 05:30:27,072 Epoch[99] Batch [440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075783,	
2017-07-21 05:30:31,565 Epoch[99] Batch [450]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.075684,	
2017-07-21 05:30:36,706 Epoch[99] Batch [460]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.075724,	
2017-07-21 05:30:41,702 Epoch[99] Batch [470]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075781,	
2017-07-21 05:30:46,947 Epoch[99] Batch [480]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.075705,	
2017-07-21 05:30:51,890 Epoch[99] Batch [490]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.075788,	
2017-07-21 05:30:56,915 Epoch[99] Batch [500]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.075882,	
2017-07-21 05:31:01,574 Epoch[99] Batch [510]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075889,	
2017-07-21 05:31:06,432 Epoch[99] Batch [520]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075911,	
2017-07-21 05:31:11,563 Epoch[99] Batch [530]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.075988,	
2017-07-21 05:31:16,335 Epoch[99] Batch [540]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.075950,	
2017-07-21 05:31:20,824 Epoch[99] Batch [550]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.076001,	
2017-07-21 05:31:25,484 Epoch[99] Batch [560]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.075942,	
2017-07-21 05:31:30,243 Epoch[99] Batch [570]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.075863,	
2017-07-21 05:31:34,961 Epoch[99] Batch [580]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075839,	
2017-07-21 05:31:39,611 Epoch[99] Batch [590]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075829,	
2017-07-21 05:31:44,610 Epoch[99] Batch [600]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.075856,	
2017-07-21 05:31:49,560 Epoch[99] Batch [610]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.075883,	
2017-07-21 05:31:55,042 Epoch[99] Batch [620]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.075864,	
2017-07-21 05:32:00,056 Epoch[99] Batch [630]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.075814,	
2017-07-21 05:32:05,357 Epoch[99] Batch [640]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.075796,	
2017-07-21 05:32:10,310 Epoch[99] Batch [650]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.075890,	
2017-07-21 05:32:15,208 Epoch[99] Batch [660]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075867,	
2017-07-21 05:32:20,390 Epoch[99] Batch [670]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.075923,	
2017-07-21 05:32:25,347 Epoch[99] Batch [680]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.075944,	
2017-07-21 05:32:29,821 Epoch[99] Batch [690]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075922,	
2017-07-21 05:32:34,465 Epoch[99] Batch [700]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075862,	
2017-07-21 05:32:38,924 Epoch[99] Batch [710]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.075821,	
2017-07-21 05:32:43,606 Epoch[99] Batch [720]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075778,	
2017-07-21 05:32:48,260 Epoch[99] Batch [730]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.075698,	
2017-07-21 05:32:53,543 Epoch[99] Batch [740]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.075607,	
2017-07-21 05:32:58,935 Epoch[99] Batch [750]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.075631,	
2017-07-21 05:33:03,653 Epoch[99] Batch [760]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.075520,	
2017-07-21 05:33:08,633 Epoch[99] Batch [770]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.075477,	
2017-07-21 05:33:13,537 Epoch[99] Batch [780]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.075361,	
2017-07-21 05:33:18,367 Epoch[99] Batch [790]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.075361,	
2017-07-21 05:33:22,979 Epoch[99] Batch [800]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.075303,	
2017-07-21 05:33:27,975 Epoch[99] Batch [810]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.075347,	
2017-07-21 05:33:33,021 Epoch[99] Batch [820]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.075327,	
2017-07-21 05:33:38,345 Epoch[99] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.075394,	
2017-07-21 05:33:43,789 Epoch[99] Batch [840]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.075343,	
2017-07-21 05:33:48,994 Epoch[99] Batch [850]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.075295,	
2017-07-21 05:33:53,450 Epoch[99] Batch [860]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.075207,	
2017-07-21 05:33:58,164 Epoch[99] Batch [870]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.075164,	
2017-07-21 05:34:02,598 Epoch[99] Batch [880]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075126,	
2017-07-21 05:34:06,825 Epoch[99] Batch [890]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.075177,	
2017-07-21 05:34:11,249 Epoch[99] Batch [900]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.075228,	
2017-07-21 05:34:15,746 Epoch[99] Batch [910]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.075159,	
2017-07-21 05:34:20,334 Epoch[99] Batch [920]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075183,	
2017-07-21 05:34:24,647 Epoch[99] Batch [930]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075172,	
2017-07-21 05:34:29,250 Epoch[99] Batch [940]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.075135,	
2017-07-21 05:34:33,850 Epoch[99] Batch [950]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.075189,	
2017-07-21 05:34:38,496 Epoch[99] Batch [960]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.075175,	
2017-07-21 05:34:43,388 Epoch[99] Batch [970]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.075220,	
2017-07-21 05:34:48,071 Epoch[99] Batch [980]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.075161,	
2017-07-21 05:34:52,835 Epoch[99] Batch [990]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.075147,	
2017-07-21 05:34:57,733 Epoch[99] Batch [1000]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.075200,	
2017-07-21 05:35:02,802 Epoch[99] Batch [1010]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.075205,	
2017-07-21 05:35:07,595 Epoch[99] Batch [1020]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.075244,	
2017-07-21 05:35:12,054 Epoch[99] Batch [1030]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.075250,	
2017-07-21 05:35:16,876 Epoch[99] Batch [1040]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075237,	
2017-07-21 05:35:21,916 Epoch[99] Batch [1050]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.075225,	
2017-07-21 05:35:26,841 Epoch[99] Batch [1060]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.075211,	
2017-07-21 05:35:32,018 Epoch[99] Batch [1070]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.075233,	
2017-07-21 05:35:37,090 Epoch[99] Batch [1080]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.075189,	
2017-07-21 05:35:41,884 Epoch[99] Batch [1090]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075166,	
2017-07-21 05:35:46,826 Epoch[99] Batch [1100]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.075151,	
2017-07-21 05:35:51,603 Epoch[99] Batch [1110]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075067,	
2017-07-21 05:35:56,381 Epoch[99] Batch [1120]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075041,	
2017-07-21 05:36:01,699 Epoch[99] Batch [1130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.074996,	
2017-07-21 05:36:07,069 Epoch[99] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.075005,	
2017-07-21 05:36:12,099 Epoch[99] Batch [1150]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.074973,	
2017-07-21 05:36:17,038 Epoch[99] Batch [1160]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.075017,	
2017-07-21 05:36:21,522 Epoch[99] Batch [1170]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.075037,	
2017-07-21 05:36:26,089 Epoch[99] Batch [1180]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.075096,	
2017-07-21 05:36:30,966 Epoch[99] Batch [1190]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.075105,	
2017-07-21 05:36:35,711 Epoch[99] Batch [1200]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.075184,	
2017-07-21 05:36:40,226 Epoch[99] Batch [1210]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075149,	
2017-07-21 05:36:45,191 Epoch[99] Batch [1220]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.075117,	
2017-07-21 05:36:50,268 Epoch[99] Batch [1230]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.075122,	
2017-07-21 05:36:55,175 Epoch[99] Batch [1240]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.075174,	
2017-07-21 05:36:59,962 Epoch[99] Batch [1250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.075208,	
2017-07-21 05:37:04,740 Epoch[99] Batch [1260]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.075308,	
2017-07-21 05:37:09,654 Epoch[99] Batch [1270]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.075266,	
2017-07-21 05:37:14,206 Epoch[99] Batch [1280]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.075280,	
2017-07-21 05:37:18,913 Epoch[99] Batch [1290]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.075269,	
2017-07-21 05:37:23,607 Epoch[99] Batch [1300]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075243,	
2017-07-21 05:37:28,782 Epoch[99] Batch [1310]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.075249,	
2017-07-21 05:37:33,580 Epoch[99] Batch [1320]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.075234,	
2017-07-21 05:37:38,255 Epoch[99] Batch [1330]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075221,	
2017-07-21 05:37:43,388 Epoch[99] Batch [1340]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.075257,	
2017-07-21 05:37:48,210 Epoch[99] Batch [1350]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.075276,	
2017-07-21 05:37:52,796 Epoch[99] Batch [1360]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.075267,	
2017-07-21 05:37:57,492 Epoch[99] Batch [1370]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.075268,	
2017-07-21 05:38:01,971 Epoch[99] Batch [1380]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.075254,	
2017-07-21 05:38:07,176 Epoch[99] Batch [1390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.075235,	
2017-07-21 05:38:11,992 Epoch[99] Batch [1400]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.075234,	
2017-07-21 05:38:16,893 Epoch[99] Batch [1410]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.075218,	
2017-07-21 05:38:21,564 Epoch[99] Batch [1420]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.075136,	
2017-07-21 05:38:26,419 Epoch[99] Batch [1430]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.075151,	
2017-07-21 05:38:31,189 Epoch[99] Batch [1440]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.075142,	
2017-07-21 05:38:35,606 Epoch[99] Batch [1450]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.075157,	
2017-07-21 05:38:40,080 Epoch[99] Batch [1460]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.075096,	
2017-07-21 05:38:45,071 Epoch[99] Batch [1470]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.075068,	
2017-07-21 05:38:49,855 Epoch[99] Batch [1480]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.075091,	
2017-07-21 05:38:52,665 Epoch[99] Train-FCNLogLoss=0.075108
2017-07-21 05:38:52,665 Epoch[99] Time cost=723.028
2017-07-21 05:38:53,520 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0100.params"
2017-07-21 05:38:58,052 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100-0100.states"
2017-07-21 05:38:58,060 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 100},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 100,
           'lr': 0.0005,
           'lr_step': '60',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch100',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn'}

2017-07-21 05:39:06,073 testing 4/500 data 1.1184s net 0.3035s post 0.0101s
2017-07-21 05:39:07,153 testing 8/500 data 0.9674s net 0.2803s post 0.0083s
2017-07-21 05:39:08,308 testing 12/500 data 0.9416s net 0.2725s post 0.0082s
2017-07-21 05:39:09,043 testing 16/500 data 0.8239s net 0.2687s post 0.0079s
2017-07-21 05:39:10,186 testing 20/500 data 0.8355s net 0.2659s post 0.0076s
2017-07-21 05:39:11,283 testing 24/500 data 0.8353s net 0.2642s post 0.0074s
2017-07-21 05:39:12,409 testing 28/500 data 0.8385s net 0.2635s post 0.0077s
2017-07-21 05:39:13,521 testing 32/500 data 0.8392s net 0.2625s post 0.0083s
2017-07-21 05:39:14,598 testing 36/500 data 0.8355s net 0.2619s post 0.0089s
2017-07-21 05:39:15,764 testing 40/500 data 0.8422s net 0.2614s post 0.0086s
2017-07-21 05:39:16,939 testing 44/500 data 0.8487s net 0.2608s post 0.0085s
2017-07-21 05:39:18,029 testing 48/500 data 0.8467s net 0.2603s post 0.0087s
2017-07-21 05:39:19,154 testing 52/500 data 0.8476s net 0.2600s post 0.0087s
2017-07-21 05:39:20,317 testing 56/500 data 0.8513s net 0.2599s post 0.0086s
2017-07-21 05:39:21,421 testing 60/500 data 0.8502s net 0.2597s post 0.0088s
2017-07-21 05:39:22,498 testing 64/500 data 0.8476s net 0.2596s post 0.0088s
2017-07-21 05:39:23,627 testing 68/500 data 0.8485s net 0.2596s post 0.0087s
2017-07-21 05:39:24,702 testing 72/500 data 0.8464s net 0.2593s post 0.0087s
2017-07-21 05:39:25,777 testing 76/500 data 0.8447s net 0.2591s post 0.0086s
2017-07-21 05:39:26,865 testing 80/500 data 0.8436s net 0.2589s post 0.0087s
2017-07-21 05:39:27,985 testing 84/500 data 0.8437s net 0.2590s post 0.0089s
2017-07-21 05:39:29,069 testing 88/500 data 0.8426s net 0.2588s post 0.0090s
2017-07-21 05:39:30,155 testing 92/500 data 0.8417s net 0.2588s post 0.0089s
2017-07-21 05:39:31,250 testing 96/500 data 0.8412s net 0.2585s post 0.0089s
2017-07-21 05:39:32,344 testing 100/500 data 0.8407s net 0.2586s post 0.0089s
2017-07-21 05:39:33,439 testing 104/500 data 0.8402s net 0.2584s post 0.0090s
2017-07-21 05:39:34,519 testing 108/500 data 0.8392s net 0.2583s post 0.0091s
2017-07-21 05:39:35,601 testing 112/500 data 0.8385s net 0.2582s post 0.0090s
2017-07-21 05:39:36,681 testing 116/500 data 0.8375s net 0.2582s post 0.0091s
2017-07-21 05:39:37,753 testing 120/500 data 0.8366s net 0.2581s post 0.0090s
2017-07-21 05:39:38,856 testing 124/500 data 0.8366s net 0.2581s post 0.0090s
2017-07-21 05:39:39,944 testing 128/500 data 0.8361s net 0.2581s post 0.0090s
2017-07-21 05:39:41,032 testing 132/500 data 0.8356s net 0.2581s post 0.0091s
2017-07-21 05:39:42,183 testing 136/500 data 0.8370s net 0.2580s post 0.0091s
2017-07-21 05:39:43,281 testing 140/500 data 0.8368s net 0.2580s post 0.0092s
2017-07-21 05:39:44,460 testing 144/500 data 0.8391s net 0.2579s post 0.0091s
2017-07-21 05:39:45,610 testing 148/500 data 0.8404s net 0.2578s post 0.0091s
2017-07-21 05:39:46,703 testing 152/500 data 0.8400s net 0.2577s post 0.0092s
2017-07-21 05:39:47,811 testing 156/500 data 0.8401s net 0.2577s post 0.0092s
2017-07-21 05:39:48,888 testing 160/500 data 0.8392s net 0.2577s post 0.0093s
2017-07-21 05:39:49,935 testing 164/500 data 0.8378s net 0.2576s post 0.0093s
2017-07-21 05:39:51,018 testing 168/500 data 0.8374s net 0.2576s post 0.0092s
2017-07-21 05:39:52,078 testing 172/500 data 0.8363s net 0.2576s post 0.0093s
2017-07-21 05:39:53,133 testing 176/500 data 0.8353s net 0.2576s post 0.0093s
2017-07-21 05:39:54,195 testing 180/500 data 0.8344s net 0.2575s post 0.0093s
2017-07-21 05:39:55,255 testing 184/500 data 0.8336s net 0.2575s post 0.0092s
2017-07-21 05:39:56,322 testing 188/500 data 0.8330s net 0.2574s post 0.0092s
2017-07-21 05:39:57,390 testing 192/500 data 0.8323s net 0.2573s post 0.0092s
2017-07-21 05:39:58,036 testing 196/500 data 0.8231s net 0.2573s post 0.0093s
2017-07-21 05:39:59,153 testing 200/500 data 0.8237s net 0.2573s post 0.0092s
2017-07-21 05:40:00,325 testing 204/500 data 0.8254s net 0.2572s post 0.0092s
2017-07-21 05:40:01,405 testing 208/500 data 0.8253s net 0.2572s post 0.0091s
2017-07-21 05:40:02,465 testing 212/500 data 0.8246s net 0.2572s post 0.0092s
2017-07-21 05:40:03,532 testing 216/500 data 0.8242s net 0.2572s post 0.0091s
2017-07-21 05:40:04,614 testing 220/500 data 0.8240s net 0.2572s post 0.0092s
2017-07-21 05:40:05,663 testing 224/500 data 0.8234s net 0.2571s post 0.0091s
2017-07-21 05:40:06,731 testing 228/500 data 0.8231s net 0.2571s post 0.0091s
2017-07-21 05:40:07,802 testing 232/500 data 0.8228s net 0.2570s post 0.0091s
2017-07-21 05:40:08,867 testing 236/500 data 0.8225s net 0.2570s post 0.0091s
2017-07-21 05:40:09,945 testing 240/500 data 0.8224s net 0.2570s post 0.0090s
2017-07-21 05:40:11,027 testing 244/500 data 0.8223s net 0.2570s post 0.0091s
2017-07-21 05:40:12,088 testing 248/500 data 0.8219s net 0.2570s post 0.0090s
2017-07-21 05:40:13,163 testing 252/500 data 0.8216s net 0.2569s post 0.0091s
2017-07-21 05:40:14,210 testing 256/500 data 0.8211s net 0.2569s post 0.0090s
2017-07-21 05:40:15,284 testing 260/500 data 0.8209s net 0.2569s post 0.0090s
2017-07-21 05:40:16,350 testing 264/500 data 0.8206s net 0.2568s post 0.0090s
2017-07-21 05:40:17,412 testing 268/500 data 0.8202s net 0.2568s post 0.0091s
2017-07-21 05:40:18,477 testing 272/500 data 0.8200s net 0.2568s post 0.0091s
2017-07-21 05:40:19,541 testing 276/500 data 0.8197s net 0.2568s post 0.0090s
2017-07-21 05:40:20,641 testing 280/500 data 0.8199s net 0.2568s post 0.0090s
2017-07-21 05:40:21,698 testing 284/500 data 0.8195s net 0.2568s post 0.0090s
2017-07-21 05:40:22,751 testing 288/500 data 0.8191s net 0.2568s post 0.0090s
2017-07-21 05:40:23,850 testing 292/500 data 0.8193s net 0.2567s post 0.0090s
2017-07-21 05:40:24,933 testing 296/500 data 0.8193s net 0.2567s post 0.0090s
2017-07-21 05:40:26,095 testing 300/500 data 0.8204s net 0.2567s post 0.0090s
2017-07-21 05:40:27,147 testing 304/500 data 0.8200s net 0.2566s post 0.0090s
2017-07-21 05:40:28,352 testing 308/500 data 0.8215s net 0.2566s post 0.0090s
2017-07-21 05:40:29,414 testing 312/500 data 0.8212s net 0.2566s post 0.0090s
2017-07-21 05:40:30,734 testing 316/500 data 0.8242s net 0.2566s post 0.0090s
2017-07-21 05:40:31,918 testing 320/500 data 0.8254s net 0.2566s post 0.0090s
2017-07-21 05:40:33,064 testing 324/500 data 0.8261s net 0.2565s post 0.0090s
2017-07-21 05:40:34,151 testing 328/500 data 0.8261s net 0.2565s post 0.0089s
2017-07-21 05:40:35,321 testing 332/500 data 0.8271s net 0.2565s post 0.0089s
2017-07-21 05:40:36,422 testing 336/500 data 0.8273s net 0.2565s post 0.0089s
2017-07-21 05:40:37,160 testing 340/500 data 0.8231s net 0.2564s post 0.0089s
2017-07-21 05:40:38,497 testing 344/500 data 0.8261s net 0.2564s post 0.0089s
2017-07-21 05:40:39,611 testing 348/500 data 0.8264s net 0.2564s post 0.0088s
2017-07-21 05:40:40,662 testing 352/500 data 0.8260s net 0.2564s post 0.0088s
2017-07-21 05:40:41,871 testing 356/500 data 0.8272s net 0.2564s post 0.0089s
2017-07-21 05:40:43,038 testing 360/500 data 0.8281s net 0.2563s post 0.0088s
2017-07-21 05:40:44,224 testing 364/500 data 0.8292s net 0.2563s post 0.0088s
2017-07-21 05:40:45,268 testing 368/500 data 0.8287s net 0.2563s post 0.0088s
2017-07-21 05:40:46,458 testing 372/500 data 0.8298s net 0.2563s post 0.0088s
2017-07-21 05:40:47,521 testing 376/500 data 0.8294s net 0.2563s post 0.0088s
2017-07-21 05:40:48,808 testing 380/500 data 0.8315s net 0.2562s post 0.0088s
2017-07-21 05:40:49,970 testing 384/500 data 0.8322s net 0.2562s post 0.0088s
2017-07-21 05:40:51,221 testing 388/500 data 0.8338s net 0.2562s post 0.0087s
2017-07-21 05:40:52,315 testing 392/500 data 0.8337s net 0.2562s post 0.0088s
2017-07-21 05:40:53,685 testing 396/500 data 0.8364s net 0.2562s post 0.0088s
2017-07-21 05:40:54,859 testing 400/500 data 0.8372s net 0.2562s post 0.0088s
2017-07-21 05:40:55,953 testing 404/500 data 0.8371s net 0.2562s post 0.0088s
2017-07-21 05:40:57,178 testing 408/500 data 0.8384s net 0.2561s post 0.0088s
2017-07-21 05:40:58,282 testing 412/500 data 0.8384s net 0.2561s post 0.0088s
2017-07-21 05:40:59,483 testing 416/500 data 0.8394s net 0.2561s post 0.0087s
2017-07-21 05:41:00,591 testing 420/500 data 0.8394s net 0.2561s post 0.0088s
2017-07-21 05:41:01,706 testing 424/500 data 0.8396s net 0.2561s post 0.0087s
2017-07-21 05:41:02,780 testing 428/500 data 0.8393s net 0.2560s post 0.0087s
2017-07-21 05:41:03,991 testing 432/500 data 0.8403s net 0.2560s post 0.0088s
2017-07-21 05:41:05,052 testing 436/500 data 0.8399s net 0.2560s post 0.0088s
2017-07-21 05:41:06,264 testing 440/500 data 0.8409s net 0.2560s post 0.0087s
2017-07-21 05:41:07,341 testing 444/500 data 0.8407s net 0.2560s post 0.0087s
2017-07-21 05:41:08,586 testing 448/500 data 0.8420s net 0.2560s post 0.0087s
2017-07-21 05:41:09,706 testing 452/500 data 0.8422s net 0.2559s post 0.0087s
2017-07-21 05:41:10,828 testing 456/500 data 0.8423s net 0.2559s post 0.0087s
2017-07-21 05:41:11,936 testing 460/500 data 0.8423s net 0.2559s post 0.0087s
2017-07-21 05:41:13,018 testing 464/500 data 0.8422s net 0.2559s post 0.0086s
2017-07-21 05:41:14,211 testing 468/500 data 0.8429s net 0.2559s post 0.0087s
2017-07-21 05:41:15,331 testing 472/500 data 0.8430s net 0.2559s post 0.0087s
2017-07-21 05:41:16,418 testing 476/500 data 0.8428s net 0.2558s post 0.0087s
2017-07-21 05:41:17,541 testing 480/500 data 0.8430s net 0.2559s post 0.0087s
2017-07-21 05:41:18,651 testing 484/500 data 0.8430s net 0.2559s post 0.0087s
2017-07-21 05:41:19,792 testing 488/500 data 0.8433s net 0.2558s post 0.0087s
2017-07-21 05:41:20,919 testing 492/500 data 0.8434s net 0.2558s post 0.0087s
2017-07-21 05:41:21,999 testing 496/500 data 0.8432s net 0.2558s post 0.0087s
2017-07-21 05:41:23,153 testing 500/500 data 0.8436s net 0.2558s post 0.0086s
2017-07-21 05:43:16,364 evaluate segmentation: 

2017-07-21 05:43:16,364 IU_array:

2017-07-21 05:43:16,364 0.97970
2017-07-21 05:43:16,364 0.83604
2017-07-21 05:43:16,364 0.91741
2017-07-21 05:43:16,364 0.59853
2017-07-21 05:43:16,365 0.57344
2017-07-21 05:43:16,365 0.55150
2017-07-21 05:43:16,365 0.65159
2017-07-21 05:43:16,365 0.74142
2017-07-21 05:43:16,365 0.91625
2017-07-21 05:43:16,365 0.63420
2017-07-21 05:43:16,365 0.93674
2017-07-21 05:43:16,365 0.78784
2017-07-21 05:43:16,365 0.61080
2017-07-21 05:43:16,365 0.94019
2017-07-21 05:43:16,365 0.67398
2017-07-21 05:43:16,365 0.86799
2017-07-21 05:43:16,365 0.72213
2017-07-21 05:43:16,365 0.62973
2017-07-21 05:43:16,365 0.74959
2017-07-21 05:43:16,365 meanIU:0.75364

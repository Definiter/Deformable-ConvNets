2017-07-28 14:11:31,995 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-28 14:12:51,556 Epoch[0] Batch [10]	Speed: 4.51 samples/sec	Train-FCNLogLoss=2.873084,	
2017-07-28 14:13:00,501 Epoch[0] Batch [20]	Speed: 4.47 samples/sec	Train-FCNLogLoss=2.726015,	
2017-07-28 14:13:09,752 Epoch[0] Batch [30]	Speed: 4.32 samples/sec	Train-FCNLogLoss=2.504200,	
2017-07-28 14:13:18,921 Epoch[0] Batch [40]	Speed: 4.36 samples/sec	Train-FCNLogLoss=2.284794,	
2017-07-28 14:13:27,672 Epoch[0] Batch [50]	Speed: 4.57 samples/sec	Train-FCNLogLoss=2.069555,	
2017-07-28 14:13:36,624 Epoch[0] Batch [60]	Speed: 4.47 samples/sec	Train-FCNLogLoss=1.904307,	
2017-07-28 14:13:45,631 Epoch[0] Batch [70]	Speed: 4.44 samples/sec	Train-FCNLogLoss=1.764982,	
2017-07-28 14:13:54,248 Epoch[0] Batch [80]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.650363,	
2017-07-28 14:14:02,866 Epoch[0] Batch [90]	Speed: 4.64 samples/sec	Train-FCNLogLoss=1.551918,	
2017-07-28 14:14:12,274 Epoch[0] Batch [100]	Speed: 4.25 samples/sec	Train-FCNLogLoss=1.464746,	
2017-07-28 14:14:21,748 Epoch[0] Batch [110]	Speed: 4.22 samples/sec	Train-FCNLogLoss=1.387864,	
2017-07-28 14:14:31,550 Epoch[0] Batch [120]	Speed: 4.08 samples/sec	Train-FCNLogLoss=1.323726,	
2017-07-28 14:14:40,938 Epoch[0] Batch [130]	Speed: 4.26 samples/sec	Train-FCNLogLoss=1.265135,	
2017-07-28 14:14:50,639 Epoch[0] Batch [140]	Speed: 4.12 samples/sec	Train-FCNLogLoss=1.217100,	
2017-07-28 14:15:00,218 Epoch[0] Batch [150]	Speed: 4.18 samples/sec	Train-FCNLogLoss=1.177512,	
2017-07-28 14:15:09,889 Epoch[0] Batch [160]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.133157,	
2017-07-28 14:15:19,891 Epoch[0] Batch [170]	Speed: 4.00 samples/sec	Train-FCNLogLoss=1.098263,	
2017-07-28 14:15:29,859 Epoch[0] Batch [180]	Speed: 4.01 samples/sec	Train-FCNLogLoss=1.062631,	
2017-07-28 14:15:39,694 Epoch[0] Batch [190]	Speed: 4.07 samples/sec	Train-FCNLogLoss=1.034720,	
2017-07-28 14:15:49,482 Epoch[0] Batch [200]	Speed: 4.09 samples/sec	Train-FCNLogLoss=1.012221,	
2017-07-28 14:15:59,163 Epoch[0] Batch [210]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.984552,	
2017-07-28 14:16:09,131 Epoch[0] Batch [220]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.961312,	
2017-07-28 14:16:18,842 Epoch[0] Batch [230]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.944658,	
2017-07-28 14:16:28,471 Epoch[0] Batch [240]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.931936,	
2017-07-28 14:16:37,716 Epoch[0] Batch [250]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.917089,	
2017-07-28 14:16:47,061 Epoch[0] Batch [260]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.902317,	
2017-07-28 14:16:56,470 Epoch[0] Batch [270]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.888226,	
2017-07-28 14:17:05,674 Epoch[0] Batch [280]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.872182,	
2017-07-28 14:17:14,518 Epoch[0] Batch [290]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.855497,	
2017-07-28 14:17:23,344 Epoch[0] Batch [300]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.845618,	
2017-07-28 14:17:32,467 Epoch[0] Batch [310]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.830015,	
2017-07-28 14:17:41,682 Epoch[0] Batch [320]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.817616,	
2017-07-28 14:17:50,744 Epoch[0] Batch [330]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.807586,	
2017-07-28 14:17:59,851 Epoch[0] Batch [340]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.797700,	
2017-07-28 14:18:09,221 Epoch[0] Batch [350]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.788579,	
2017-07-28 14:18:18,455 Epoch[0] Batch [360]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.778225,	
2017-07-28 14:18:27,276 Epoch[0] Batch [370]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.768435,	
2017-07-28 14:18:36,181 Epoch[0] Batch [380]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.762909,	
2017-07-28 14:18:45,160 Epoch[0] Batch [390]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.753634,	
2017-07-28 14:18:54,593 Epoch[0] Batch [400]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.745452,	
2017-07-28 14:19:03,491 Epoch[0] Batch [410]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.737719,	
2017-07-28 14:19:12,814 Epoch[0] Batch [420]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.729445,	
2017-07-28 14:19:21,810 Epoch[0] Batch [430]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.721824,	
2017-07-28 14:19:30,616 Epoch[0] Batch [440]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.715112,	
2017-07-28 14:19:39,840 Epoch[0] Batch [450]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.708683,	
2017-07-28 14:19:49,791 Epoch[0] Batch [460]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.701710,	
2017-07-28 14:19:59,604 Epoch[0] Batch [470]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.695366,	
2017-07-28 14:20:09,196 Epoch[0] Batch [480]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.689868,	
2017-07-28 14:20:18,676 Epoch[0] Batch [490]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.684383,	
2017-07-28 14:20:28,140 Epoch[0] Batch [500]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.677751,	
2017-07-28 14:20:37,482 Epoch[0] Batch [510]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.670917,	
2017-07-28 14:20:47,117 Epoch[0] Batch [520]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.663840,	
2017-07-28 14:20:57,090 Epoch[0] Batch [530]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.658820,	
2017-07-28 14:21:07,065 Epoch[0] Batch [540]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.653392,	
2017-07-28 14:21:16,517 Epoch[0] Batch [550]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.647182,	
2017-07-28 14:21:25,798 Epoch[0] Batch [560]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.641740,	
2017-07-28 14:21:35,449 Epoch[0] Batch [570]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.637371,	
2017-07-28 14:21:45,144 Epoch[0] Batch [580]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.631728,	
2017-07-28 14:21:54,813 Epoch[0] Batch [590]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.628479,	
2017-07-28 14:22:04,607 Epoch[0] Batch [600]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.624583,	
2017-07-28 14:22:14,314 Epoch[0] Batch [610]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.620113,	
2017-07-28 14:22:23,959 Epoch[0] Batch [620]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.616444,	
2017-07-28 14:22:33,510 Epoch[0] Batch [630]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.612563,	
2017-07-28 14:22:43,371 Epoch[0] Batch [640]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.608495,	
2017-07-28 14:22:52,973 Epoch[0] Batch [650]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.604368,	
2017-07-28 14:23:02,291 Epoch[0] Batch [660]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.600992,	
2017-07-28 14:23:11,516 Epoch[0] Batch [670]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.598375,	
2017-07-28 14:23:21,099 Epoch[0] Batch [680]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.594668,	
2017-07-28 14:23:30,425 Epoch[0] Batch [690]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.592801,	
2017-07-28 14:23:40,178 Epoch[0] Batch [700]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.590612,	
2017-07-28 14:23:49,589 Epoch[0] Batch [710]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.587962,	
2017-07-28 14:23:58,878 Epoch[0] Batch [720]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.585075,	
2017-07-28 14:24:08,569 Epoch[0] Batch [730]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.582135,	
2017-07-28 14:24:18,086 Epoch[0] Batch [740]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.579040,	
2017-07-28 14:24:27,774 Epoch[0] Batch [750]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.575584,	
2017-07-28 14:24:37,133 Epoch[0] Batch [760]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.572966,	
2017-07-28 14:24:46,559 Epoch[0] Batch [770]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.570333,	
2017-07-28 14:24:56,230 Epoch[0] Batch [780]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.567918,	
2017-07-28 14:25:05,160 Epoch[0] Batch [790]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.565222,	
2017-07-28 14:25:14,320 Epoch[0] Batch [800]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.562146,	
2017-07-28 14:25:23,068 Epoch[0] Batch [810]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.559646,	
2017-07-28 14:25:32,341 Epoch[0] Batch [820]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.557048,	
2017-07-28 14:25:41,516 Epoch[0] Batch [830]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.554500,	
2017-07-28 14:25:50,444 Epoch[0] Batch [840]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.551742,	
2017-07-28 14:25:59,675 Epoch[0] Batch [850]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.549022,	
2017-07-28 14:26:08,600 Epoch[0] Batch [860]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.546836,	
2017-07-28 14:26:17,707 Epoch[0] Batch [870]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.544513,	
2017-07-28 14:26:26,875 Epoch[0] Batch [880]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.542190,	
2017-07-28 14:26:36,592 Epoch[0] Batch [890]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.539586,	
2017-07-28 14:26:45,949 Epoch[0] Batch [900]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.536984,	
2017-07-28 14:26:55,289 Epoch[0] Batch [910]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.534973,	
2017-07-28 14:27:04,723 Epoch[0] Batch [920]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.533044,	
2017-07-28 14:27:14,033 Epoch[0] Batch [930]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.530803,	
2017-07-28 14:27:23,323 Epoch[0] Batch [940]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.529108,	
2017-07-28 14:27:32,710 Epoch[0] Batch [950]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.526908,	
2017-07-28 14:27:42,073 Epoch[0] Batch [960]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.525980,	
2017-07-28 14:27:51,733 Epoch[0] Batch [970]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.524654,	
2017-07-28 14:28:01,132 Epoch[0] Batch [980]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.522758,	
2017-07-28 14:28:10,183 Epoch[0] Batch [990]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.520571,	
2017-07-28 14:28:19,529 Epoch[0] Batch [1000]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.518727,	
2017-07-28 14:28:28,536 Epoch[0] Batch [1010]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.517092,	
2017-07-28 14:28:37,614 Epoch[0] Batch [1020]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.517021,	
2017-07-28 14:28:46,776 Epoch[0] Batch [1030]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.516985,	
2017-07-28 14:28:55,801 Epoch[0] Batch [1040]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.519127,	
2017-07-28 14:29:05,299 Epoch[0] Batch [1050]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.521770,	
2017-07-28 14:29:14,414 Epoch[0] Batch [1060]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.522483,	
2017-07-28 14:29:23,677 Epoch[0] Batch [1070]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.522879,	
2017-07-28 14:29:33,273 Epoch[0] Batch [1080]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.523201,	
2017-07-28 14:29:42,646 Epoch[0] Batch [1090]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.522875,	
2017-07-28 14:29:51,993 Epoch[0] Batch [1100]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.521812,	
2017-07-28 14:30:01,171 Epoch[0] Batch [1110]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.521099,	
2017-07-28 14:30:10,672 Epoch[0] Batch [1120]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.520777,	
2017-07-28 14:30:20,195 Epoch[0] Batch [1130]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.520248,	
2017-07-28 14:30:29,412 Epoch[0] Batch [1140]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.519122,	
2017-07-28 14:30:38,917 Epoch[0] Batch [1150]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.517792,	
2017-07-28 14:30:48,258 Epoch[0] Batch [1160]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.516862,	
2017-07-28 14:30:57,401 Epoch[0] Batch [1170]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.515679,	
2017-07-28 14:31:06,786 Epoch[0] Batch [1180]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.514621,	
2017-07-28 14:31:16,395 Epoch[0] Batch [1190]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.513408,	
2017-07-28 14:31:26,010 Epoch[0] Batch [1200]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.512019,	
2017-07-28 14:31:35,369 Epoch[0] Batch [1210]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.510699,	
2017-07-28 14:31:44,880 Epoch[0] Batch [1220]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.509434,	
2017-07-28 14:31:54,102 Epoch[0] Batch [1230]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.508233,	
2017-07-28 14:32:03,382 Epoch[0] Batch [1240]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.506790,	
2017-07-28 14:32:13,018 Epoch[0] Batch [1250]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.506030,	
2017-07-28 14:32:22,366 Epoch[0] Batch [1260]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.504965,	
2017-07-28 14:32:31,795 Epoch[0] Batch [1270]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.503604,	
2017-07-28 14:32:41,136 Epoch[0] Batch [1280]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.502783,	
2017-07-28 14:32:50,900 Epoch[0] Batch [1290]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.501998,	
2017-07-28 14:33:00,584 Epoch[0] Batch [1300]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.500610,	
2017-07-28 14:33:10,276 Epoch[0] Batch [1310]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.499094,	
2017-07-28 14:33:19,898 Epoch[0] Batch [1320]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.497539,	
2017-07-28 14:33:29,526 Epoch[0] Batch [1330]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.495955,	
2017-07-28 14:33:38,965 Epoch[0] Batch [1340]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.494648,	
2017-07-28 14:33:48,359 Epoch[0] Batch [1350]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.493508,	
2017-07-28 14:33:57,749 Epoch[0] Batch [1360]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.491980,	
2017-07-28 14:34:07,291 Epoch[0] Batch [1370]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.490737,	
2017-07-28 14:34:16,721 Epoch[0] Batch [1380]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.489535,	
2017-07-28 14:34:26,236 Epoch[0] Batch [1390]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.488090,	
2017-07-28 14:34:35,908 Epoch[0] Batch [1400]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.486914,	
2017-07-28 14:34:45,454 Epoch[0] Batch [1410]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.485643,	
2017-07-28 14:34:55,139 Epoch[0] Batch [1420]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.484837,	
2017-07-28 14:35:04,566 Epoch[0] Batch [1430]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.484079,	
2017-07-28 14:35:14,060 Epoch[0] Batch [1440]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.482804,	
2017-07-28 14:35:23,588 Epoch[0] Batch [1450]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.481335,	
2017-07-28 14:35:33,050 Epoch[0] Batch [1460]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.479827,	
2017-07-28 14:35:42,737 Epoch[0] Batch [1470]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.478692,	
2017-07-28 14:35:52,241 Epoch[0] Batch [1480]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.477279,	
2017-07-28 14:35:57,778 Epoch[0] Train-FCNLogLoss=0.476674
2017-07-28 14:35:57,779 Epoch[0] Time cost=1407.694
2017-07-28 14:36:00,054 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-28 14:36:05,071 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-28 14:36:14,402 Epoch[1] Batch [10]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.271959,	
2017-07-28 14:36:22,206 Epoch[1] Batch [20]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.289978,	
2017-07-28 14:36:29,362 Epoch[1] Batch [30]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.294706,	
2017-07-28 14:36:36,910 Epoch[1] Batch [40]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.306721,	
2017-07-28 14:36:44,827 Epoch[1] Batch [50]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.313154,	
2017-07-28 14:36:53,223 Epoch[1] Batch [60]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.312894,	
2017-07-28 14:37:01,511 Epoch[1] Batch [70]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.314222,	
2017-07-28 14:37:09,247 Epoch[1] Batch [80]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.310207,	
2017-07-28 14:37:16,637 Epoch[1] Batch [90]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.306054,	
2017-07-28 14:37:23,394 Epoch[1] Batch [100]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.301143,	
2017-07-28 14:37:30,214 Epoch[1] Batch [110]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.299663,	
2017-07-28 14:37:36,651 Epoch[1] Batch [120]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.297289,	
2017-07-28 14:37:43,575 Epoch[1] Batch [130]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.296447,	
2017-07-28 14:37:50,307 Epoch[1] Batch [140]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.296310,	
2017-07-28 14:37:57,769 Epoch[1] Batch [150]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.296697,	
2017-07-28 14:38:05,577 Epoch[1] Batch [160]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.294190,	
2017-07-28 14:38:12,824 Epoch[1] Batch [170]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.299010,	
2017-07-28 14:38:20,523 Epoch[1] Batch [180]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.298585,	
2017-07-28 14:38:28,316 Epoch[1] Batch [190]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.300188,	
2017-07-28 14:38:36,122 Epoch[1] Batch [200]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.298706,	
2017-07-28 14:38:43,815 Epoch[1] Batch [210]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.297415,	
2017-07-28 14:38:52,023 Epoch[1] Batch [220]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.297242,	
2017-07-28 14:39:00,122 Epoch[1] Batch [230]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.297453,	
2017-07-28 14:39:08,395 Epoch[1] Batch [240]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.296452,	
2017-07-28 14:39:16,716 Epoch[1] Batch [250]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.294164,	
2017-07-28 14:39:24,774 Epoch[1] Batch [260]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.293604,	
2017-07-28 14:39:32,791 Epoch[1] Batch [270]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.291259,	
2017-07-28 14:39:41,110 Epoch[1] Batch [280]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.289610,	
2017-07-28 14:39:49,288 Epoch[1] Batch [290]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.288889,	
2017-07-28 14:39:56,696 Epoch[1] Batch [300]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.287235,	
2017-07-28 14:40:04,519 Epoch[1] Batch [310]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.285930,	
2017-07-28 14:40:11,837 Epoch[1] Batch [320]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.285586,	
2017-07-28 14:40:19,076 Epoch[1] Batch [330]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.285089,	
2017-07-28 14:40:26,106 Epoch[1] Batch [340]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.284257,	
2017-07-28 14:40:33,113 Epoch[1] Batch [350]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.284875,	
2017-07-28 14:40:39,969 Epoch[1] Batch [360]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.284885,	
2017-07-28 14:40:47,213 Epoch[1] Batch [370]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.283984,	
2017-07-28 14:40:54,222 Epoch[1] Batch [380]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.282968,	
2017-07-28 14:41:00,844 Epoch[1] Batch [390]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.282790,	
2017-07-28 14:41:07,698 Epoch[1] Batch [400]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.282094,	
2017-07-28 14:41:14,522 Epoch[1] Batch [410]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.279768,	
2017-07-28 14:41:21,244 Epoch[1] Batch [420]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.279125,	
2017-07-28 14:41:27,830 Epoch[1] Batch [430]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.277866,	
2017-07-28 14:41:34,712 Epoch[1] Batch [440]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.277682,	
2017-07-28 14:41:41,170 Epoch[1] Batch [450]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.276893,	
2017-07-28 14:41:47,728 Epoch[1] Batch [460]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.276789,	
2017-07-28 14:41:54,322 Epoch[1] Batch [470]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.276657,	
2017-07-28 14:42:01,018 Epoch[1] Batch [480]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.277318,	
2017-07-28 14:42:07,577 Epoch[1] Batch [490]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.277179,	
2017-07-28 14:42:14,491 Epoch[1] Batch [500]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.276661,	
2017-07-28 14:42:21,359 Epoch[1] Batch [510]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.276070,	
2017-07-28 14:42:27,730 Epoch[1] Batch [520]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.275018,	
2017-07-28 14:42:34,465 Epoch[1] Batch [530]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.273878,	
2017-07-28 14:42:41,012 Epoch[1] Batch [540]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.272608,	
2017-07-28 14:42:47,881 Epoch[1] Batch [550]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.271969,	
2017-07-28 14:42:54,519 Epoch[1] Batch [560]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.272306,	
2017-07-28 14:43:01,108 Epoch[1] Batch [570]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.271622,	
2017-07-28 14:43:07,715 Epoch[1] Batch [580]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.271140,	
2017-07-28 14:43:14,105 Epoch[1] Batch [590]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.271096,	
2017-07-28 14:43:20,714 Epoch[1] Batch [600]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.270603,	
2017-07-28 14:43:27,257 Epoch[1] Batch [610]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.271472,	
2017-07-28 14:43:33,968 Epoch[1] Batch [620]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.271646,	
2017-07-28 14:43:40,858 Epoch[1] Batch [630]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.271437,	
2017-07-28 14:43:47,491 Epoch[1] Batch [640]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.271797,	
2017-07-28 14:43:53,848 Epoch[1] Batch [650]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.272616,	
2017-07-28 14:44:00,483 Epoch[1] Batch [660]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.272075,	
2017-07-28 14:44:07,851 Epoch[1] Batch [670]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.271721,	
2017-07-28 14:44:15,058 Epoch[1] Batch [680]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.271864,	
2017-07-28 14:44:22,385 Epoch[1] Batch [690]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.271692,	
2017-07-28 14:44:29,724 Epoch[1] Batch [700]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.271342,	
2017-07-28 14:44:37,054 Epoch[1] Batch [710]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.270839,	
2017-07-28 14:44:44,316 Epoch[1] Batch [720]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.270267,	
2017-07-28 14:44:51,766 Epoch[1] Batch [730]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.269707,	
2017-07-28 14:44:59,072 Epoch[1] Batch [740]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.269875,	
2017-07-28 14:45:06,482 Epoch[1] Batch [750]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.269783,	
2017-07-28 14:45:13,824 Epoch[1] Batch [760]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.269715,	
2017-07-28 14:45:21,095 Epoch[1] Batch [770]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.271014,	
2017-07-28 14:45:28,463 Epoch[1] Batch [780]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.271449,	
2017-07-28 14:45:35,530 Epoch[1] Batch [790]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.271595,	
2017-07-28 14:45:42,867 Epoch[1] Batch [800]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.271158,	
2017-07-28 14:45:50,020 Epoch[1] Batch [810]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.270660,	
2017-07-28 14:45:57,376 Epoch[1] Batch [820]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.270140,	
2017-07-28 14:46:04,695 Epoch[1] Batch [830]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.270295,	
2017-07-28 14:46:12,124 Epoch[1] Batch [840]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.270956,	
2017-07-28 14:46:19,436 Epoch[1] Batch [850]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.271485,	
2017-07-28 14:46:26,679 Epoch[1] Batch [860]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.271085,	
2017-07-28 14:46:34,103 Epoch[1] Batch [870]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.270692,	
2017-07-28 14:46:41,509 Epoch[1] Batch [880]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.270512,	
2017-07-28 14:46:48,791 Epoch[1] Batch [890]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.270147,	
2017-07-28 14:46:56,277 Epoch[1] Batch [900]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.269750,	
2017-07-28 14:47:03,405 Epoch[1] Batch [910]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.269301,	
2017-07-28 14:47:10,734 Epoch[1] Batch [920]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.269705,	
2017-07-28 14:47:18,068 Epoch[1] Batch [930]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.269785,	
2017-07-28 14:47:25,522 Epoch[1] Batch [940]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.269261,	
2017-07-28 14:47:32,815 Epoch[1] Batch [950]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.268734,	
2017-07-28 14:47:40,139 Epoch[1] Batch [960]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.268058,	
2017-07-28 14:47:47,504 Epoch[1] Batch [970]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.268114,	
2017-07-28 14:47:54,889 Epoch[1] Batch [980]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.267968,	
2017-07-28 14:48:02,295 Epoch[1] Batch [990]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.267820,	
2017-07-28 14:48:09,691 Epoch[1] Batch [1000]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.269628,	
2017-07-28 14:48:16,861 Epoch[1] Batch [1010]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.269635,	
2017-07-28 14:48:24,054 Epoch[1] Batch [1020]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.269582,	
2017-07-28 14:48:31,722 Epoch[1] Batch [1030]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.269532,	
2017-07-28 14:48:39,135 Epoch[1] Batch [1040]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.269241,	
2017-07-28 14:48:46,684 Epoch[1] Batch [1050]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.268857,	
2017-07-28 14:48:54,247 Epoch[1] Batch [1060]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.268781,	
2017-07-28 14:49:01,814 Epoch[1] Batch [1070]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.268346,	
2017-07-28 14:49:09,201 Epoch[1] Batch [1080]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.268008,	
2017-07-28 14:49:16,812 Epoch[1] Batch [1090]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.268140,	
2017-07-28 14:49:24,390 Epoch[1] Batch [1100]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.268136,	
2017-07-28 14:49:31,828 Epoch[1] Batch [1110]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.268029,	
2017-07-28 14:49:39,355 Epoch[1] Batch [1120]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.268382,	
2017-07-28 14:49:46,703 Epoch[1] Batch [1130]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.267997,	
2017-07-28 14:49:54,162 Epoch[1] Batch [1140]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.267574,	
2017-07-28 14:50:01,648 Epoch[1] Batch [1150]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.267070,	
2017-07-28 14:50:09,254 Epoch[1] Batch [1160]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.266813,	
2017-07-28 14:50:16,781 Epoch[1] Batch [1170]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.266298,	
2017-07-28 14:50:24,281 Epoch[1] Batch [1180]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.266250,	
2017-07-28 14:50:31,709 Epoch[1] Batch [1190]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.265814,	
2017-07-28 14:50:39,227 Epoch[1] Batch [1200]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.265441,	
2017-07-28 14:50:46,587 Epoch[1] Batch [1210]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.265315,	
2017-07-28 14:50:54,037 Epoch[1] Batch [1220]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.265096,	
2017-07-28 14:51:01,618 Epoch[1] Batch [1230]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.264832,	
2017-07-28 14:51:09,026 Epoch[1] Batch [1240]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.264478,	
2017-07-28 14:51:16,499 Epoch[1] Batch [1250]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.264502,	
2017-07-28 14:51:23,946 Epoch[1] Batch [1260]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.264519,	
2017-07-28 14:51:31,401 Epoch[1] Batch [1270]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.265354,	
2017-07-28 14:51:38,786 Epoch[1] Batch [1280]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.265144,	
2017-07-28 14:51:46,192 Epoch[1] Batch [1290]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.265338,	
2017-07-28 14:51:53,760 Epoch[1] Batch [1300]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.265463,	
2017-07-28 14:52:01,166 Epoch[1] Batch [1310]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.265615,	
2017-07-28 14:52:07,613 Epoch[1] Batch [1320]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.265247,	
2017-07-28 14:52:14,251 Epoch[1] Batch [1330]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.265202,	
2017-07-28 14:52:20,955 Epoch[1] Batch [1340]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.264712,	
2017-07-28 14:52:27,137 Epoch[1] Batch [1350]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.264498,	
2017-07-28 14:52:34,064 Epoch[1] Batch [1360]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.264331,	
2017-07-28 14:52:40,805 Epoch[1] Batch [1370]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.264040,	
2017-07-28 14:52:47,420 Epoch[1] Batch [1380]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.263832,	
2017-07-28 14:52:54,101 Epoch[1] Batch [1390]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.263425,	
2017-07-28 14:53:00,685 Epoch[1] Batch [1400]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.263161,	
2017-07-28 14:53:07,331 Epoch[1] Batch [1410]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.262816,	
2017-07-28 14:53:14,039 Epoch[1] Batch [1420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.262477,	
2017-07-28 14:53:20,709 Epoch[1] Batch [1430]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.261983,	
2017-07-28 14:53:27,494 Epoch[1] Batch [1440]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.261653,	
2017-07-28 14:53:34,105 Epoch[1] Batch [1450]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.261650,	
2017-07-28 14:53:40,557 Epoch[1] Batch [1460]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.261511,	
2017-07-28 14:53:47,234 Epoch[1] Batch [1470]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.261380,	
2017-07-28 14:53:53,864 Epoch[1] Batch [1480]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.261164,	
2017-07-28 14:53:58,051 Epoch[1] Train-FCNLogLoss=0.261398
2017-07-28 14:53:58,051 Epoch[1] Time cost=1072.980
2017-07-28 14:53:59,908 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-28 14:54:04,342 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-28 14:54:12,146 Epoch[2] Batch [10]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.298477,	
2017-07-28 14:54:18,526 Epoch[2] Batch [20]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.268550,	
2017-07-28 14:54:24,958 Epoch[2] Batch [30]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.250837,	
2017-07-28 14:54:31,740 Epoch[2] Batch [40]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.250425,	
2017-07-28 14:54:38,572 Epoch[2] Batch [50]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.237972,	
2017-07-28 14:54:45,318 Epoch[2] Batch [60]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.233807,	
2017-07-28 14:54:51,884 Epoch[2] Batch [70]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.234099,	
2017-07-28 14:54:58,503 Epoch[2] Batch [80]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.229142,	
2017-07-28 14:55:05,197 Epoch[2] Batch [90]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.227628,	
2017-07-28 14:55:11,695 Epoch[2] Batch [100]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.224973,	
2017-07-28 14:55:18,424 Epoch[2] Batch [110]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.224061,	
2017-07-28 14:55:25,155 Epoch[2] Batch [120]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.223940,	
2017-07-28 14:55:31,863 Epoch[2] Batch [130]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.220949,	
2017-07-28 14:55:38,570 Epoch[2] Batch [140]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.219647,	
2017-07-28 14:55:45,244 Epoch[2] Batch [150]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.217649,	
2017-07-28 14:55:51,986 Epoch[2] Batch [160]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.218826,	
2017-07-28 14:55:58,525 Epoch[2] Batch [170]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.221071,	
2017-07-28 14:56:05,526 Epoch[2] Batch [180]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.221705,	
2017-07-28 14:56:11,998 Epoch[2] Batch [190]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.221904,	
2017-07-28 14:56:18,523 Epoch[2] Batch [200]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.220970,	
2017-07-28 14:56:25,433 Epoch[2] Batch [210]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.221055,	
2017-07-28 14:56:31,788 Epoch[2] Batch [220]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.224398,	
2017-07-28 14:56:38,313 Epoch[2] Batch [230]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.226615,	
2017-07-28 14:56:45,020 Epoch[2] Batch [240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.226825,	
2017-07-28 14:56:51,464 Epoch[2] Batch [250]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.226247,	
2017-07-28 14:56:58,182 Epoch[2] Batch [260]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.226712,	
2017-07-28 14:57:04,624 Epoch[2] Batch [270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.228314,	
2017-07-28 14:57:11,218 Epoch[2] Batch [280]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.228444,	
2017-07-28 14:57:17,630 Epoch[2] Batch [290]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.227830,	
2017-07-28 14:57:24,313 Epoch[2] Batch [300]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.227335,	
2017-07-28 14:57:30,454 Epoch[2] Batch [310]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.227502,	
2017-07-28 14:57:36,894 Epoch[2] Batch [320]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.227442,	
2017-07-28 14:57:43,373 Epoch[2] Batch [330]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.226482,	
2017-07-28 14:57:50,103 Epoch[2] Batch [340]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.225811,	
2017-07-28 14:57:56,564 Epoch[2] Batch [350]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.225641,	
2017-07-28 14:58:03,039 Epoch[2] Batch [360]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.224612,	
2017-07-28 14:58:09,468 Epoch[2] Batch [370]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.223376,	
2017-07-28 14:58:15,983 Epoch[2] Batch [380]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.222858,	
2017-07-28 14:58:22,583 Epoch[2] Batch [390]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.221860,	
2017-07-28 14:58:29,326 Epoch[2] Batch [400]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.221161,	
2017-07-28 14:58:35,959 Epoch[2] Batch [410]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.220149,	
2017-07-28 14:58:42,978 Epoch[2] Batch [420]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.218920,	
2017-07-28 14:58:50,645 Epoch[2] Batch [430]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.219641,	
2017-07-28 14:59:00,359 Epoch[2] Batch [440]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.219275,	
2017-07-28 14:59:06,984 Epoch[2] Batch [450]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.219568,	
2017-07-28 14:59:15,707 Epoch[2] Batch [460]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.220734,	
2017-07-28 14:59:22,149 Epoch[2] Batch [470]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.220921,	
2017-07-28 14:59:29,616 Epoch[2] Batch [480]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.220548,	
2017-07-28 14:59:36,840 Epoch[2] Batch [490]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.221237,	
2017-07-28 14:59:45,895 Epoch[2] Batch [500]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.220888,	
2017-07-28 14:59:52,609 Epoch[2] Batch [510]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.220776,	
2017-07-28 14:59:59,642 Epoch[2] Batch [520]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.220555,	
2017-07-28 15:00:08,694 Epoch[2] Batch [530]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.220381,	
2017-07-28 15:00:16,891 Epoch[2] Batch [540]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.220024,	
2017-07-28 15:00:26,047 Epoch[2] Batch [550]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.219573,	
2017-07-28 15:00:34,059 Epoch[2] Batch [560]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.218918,	
2017-07-28 15:00:40,912 Epoch[2] Batch [570]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.219231,	
2017-07-28 15:00:48,782 Epoch[2] Batch [580]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.219498,	
2017-07-28 15:00:59,042 Epoch[2] Batch [590]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.220252,	
2017-07-28 15:01:07,247 Epoch[2] Batch [600]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.220006,	
2017-07-28 15:01:14,075 Epoch[2] Batch [610]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.220747,	
2017-07-28 15:01:21,211 Epoch[2] Batch [620]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.220500,	
2017-07-28 15:01:31,045 Epoch[2] Batch [630]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.219901,	
2017-07-28 15:01:38,100 Epoch[2] Batch [640]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.219278,	
2017-07-28 15:01:45,823 Epoch[2] Batch [650]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.218654,	
2017-07-28 15:01:52,901 Epoch[2] Batch [660]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.218628,	
2017-07-28 15:02:01,357 Epoch[2] Batch [670]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.219787,	
2017-07-28 15:02:09,601 Epoch[2] Batch [680]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.220126,	
2017-07-28 15:02:16,521 Epoch[2] Batch [690]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.220440,	
2017-07-28 15:02:23,497 Epoch[2] Batch [700]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.220142,	
2017-07-28 15:02:30,661 Epoch[2] Batch [710]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.219581,	
2017-07-28 15:02:37,788 Epoch[2] Batch [720]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.219401,	
2017-07-28 15:02:44,902 Epoch[2] Batch [730]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.219728,	
2017-07-28 15:02:52,194 Epoch[2] Batch [740]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.219588,	
2017-07-28 15:02:59,313 Epoch[2] Batch [750]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.219446,	
2017-07-28 15:03:06,609 Epoch[2] Batch [760]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.219375,	
2017-07-28 15:03:14,335 Epoch[2] Batch [770]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.219516,	
2017-07-28 15:03:21,604 Epoch[2] Batch [780]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.219778,	
2017-07-28 15:03:28,735 Epoch[2] Batch [790]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.219343,	
2017-07-28 15:03:35,987 Epoch[2] Batch [800]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.219331,	
2017-07-28 15:03:43,184 Epoch[2] Batch [810]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.219028,	
2017-07-28 15:03:50,505 Epoch[2] Batch [820]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.218688,	
2017-07-28 15:03:57,721 Epoch[2] Batch [830]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.218189,	
2017-07-28 15:04:05,067 Epoch[2] Batch [840]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.217666,	
2017-07-28 15:04:12,254 Epoch[2] Batch [850]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.217924,	
2017-07-28 15:04:19,454 Epoch[2] Batch [860]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.217906,	
2017-07-28 15:04:26,880 Epoch[2] Batch [870]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.218101,	
2017-07-28 15:04:34,207 Epoch[2] Batch [880]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.217823,	
2017-07-28 15:04:41,475 Epoch[2] Batch [890]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.218216,	
2017-07-28 15:04:48,532 Epoch[2] Batch [900]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.217861,	
2017-07-28 15:04:55,749 Epoch[2] Batch [910]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.218005,	
2017-07-28 15:05:02,825 Epoch[2] Batch [920]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.217675,	
2017-07-28 15:05:10,072 Epoch[2] Batch [930]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.217419,	
2017-07-28 15:05:17,369 Epoch[2] Batch [940]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.217380,	
2017-07-28 15:05:24,551 Epoch[2] Batch [950]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.217159,	
2017-07-28 15:05:31,820 Epoch[2] Batch [960]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.216761,	
2017-07-28 15:05:39,255 Epoch[2] Batch [970]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.217504,	
2017-07-28 15:05:46,358 Epoch[2] Batch [980]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.218224,	
2017-07-28 15:05:53,642 Epoch[2] Batch [990]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.218365,	
2017-07-28 15:06:00,765 Epoch[2] Batch [1000]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.218649,	
2017-07-28 15:06:08,053 Epoch[2] Batch [1010]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.218594,	
2017-07-28 15:06:15,346 Epoch[2] Batch [1020]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.218553,	
2017-07-28 15:06:22,309 Epoch[2] Batch [1030]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.218387,	
2017-07-28 15:06:29,543 Epoch[2] Batch [1040]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.218190,	
2017-07-28 15:06:36,930 Epoch[2] Batch [1050]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.218379,	
2017-07-28 15:06:45,551 Epoch[2] Batch [1060]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.218531,	
2017-07-28 15:06:54,953 Epoch[2] Batch [1070]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.218836,	
2017-07-28 15:07:02,548 Epoch[2] Batch [1080]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.219002,	
2017-07-28 15:07:11,528 Epoch[2] Batch [1090]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.218952,	
2017-07-28 15:07:21,227 Epoch[2] Batch [1100]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.218976,	
2017-07-28 15:07:28,158 Epoch[2] Batch [1110]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.218686,	
2017-07-28 15:07:36,492 Epoch[2] Batch [1120]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.218302,	
2017-07-28 15:07:45,164 Epoch[2] Batch [1130]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.218728,	
2017-07-28 15:07:54,110 Epoch[2] Batch [1140]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.218687,	
2017-07-28 15:08:00,951 Epoch[2] Batch [1150]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.218607,	
2017-07-28 15:08:08,488 Epoch[2] Batch [1160]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.218760,	
2017-07-28 15:08:17,362 Epoch[2] Batch [1170]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.218646,	
2017-07-28 15:08:26,748 Epoch[2] Batch [1180]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.218488,	
2017-07-28 15:08:36,917 Epoch[2] Batch [1190]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.218388,	
2017-07-28 15:08:47,627 Epoch[2] Batch [1200]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.218393,	
2017-07-28 15:08:55,871 Epoch[2] Batch [1210]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.218385,	
2017-07-28 15:09:05,491 Epoch[2] Batch [1220]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.218241,	
2017-07-28 15:09:14,000 Epoch[2] Batch [1230]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.218367,	
2017-07-28 15:09:22,046 Epoch[2] Batch [1240]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.218289,	
2017-07-28 15:09:31,070 Epoch[2] Batch [1250]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.218009,	
2017-07-28 15:09:40,258 Epoch[2] Batch [1260]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.217838,	
2017-07-28 15:09:47,629 Epoch[2] Batch [1270]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.217738,	
2017-07-28 15:09:56,504 Epoch[2] Batch [1280]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.217797,	
2017-07-28 15:10:05,812 Epoch[2] Batch [1290]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.217701,	
2017-07-28 15:10:16,453 Epoch[2] Batch [1300]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.217506,	
2017-07-28 15:10:25,863 Epoch[2] Batch [1310]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.217468,	
2017-07-28 15:10:35,930 Epoch[2] Batch [1320]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.217321,	
2017-07-28 15:10:46,571 Epoch[2] Batch [1330]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.217177,	
2017-07-28 15:10:54,090 Epoch[2] Batch [1340]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.217465,	
2017-07-28 15:11:02,664 Epoch[2] Batch [1350]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.217175,	
2017-07-28 15:11:10,850 Epoch[2] Batch [1360]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.217221,	
2017-07-28 15:11:19,825 Epoch[2] Batch [1370]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.217260,	
2017-07-28 15:11:28,326 Epoch[2] Batch [1380]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.216951,	
2017-07-28 15:11:38,045 Epoch[2] Batch [1390]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.216692,	
2017-07-28 15:11:46,080 Epoch[2] Batch [1400]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.216632,	
2017-07-28 15:11:54,393 Epoch[2] Batch [1410]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.216343,	
2017-07-28 15:12:02,040 Epoch[2] Batch [1420]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.216101,	
2017-07-28 15:12:09,877 Epoch[2] Batch [1430]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.215899,	
2017-07-28 15:12:15,811 Epoch[2] Batch [1440]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.215698,	
2017-07-28 15:12:22,852 Epoch[2] Batch [1450]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.215699,	
2017-07-28 15:12:32,301 Epoch[2] Batch [1460]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.215498,	
2017-07-28 15:12:40,967 Epoch[2] Batch [1470]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.215334,	
2017-07-28 15:12:51,140 Epoch[2] Batch [1480]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.214995,	
2017-07-28 15:12:55,664 Epoch[2] Train-FCNLogLoss=0.214871
2017-07-28 15:12:55,664 Epoch[2] Time cost=1131.321
2017-07-28 15:12:57,677 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-28 15:13:02,150 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-28 15:13:12,084 Epoch[3] Batch [10]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.184388,	
2017-07-28 15:13:22,930 Epoch[3] Batch [20]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.178831,	
2017-07-28 15:13:30,370 Epoch[3] Batch [30]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.190603,	
2017-07-28 15:13:37,807 Epoch[3] Batch [40]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.212364,	
2017-07-28 15:13:45,250 Epoch[3] Batch [50]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.211140,	
2017-07-28 15:13:52,789 Epoch[3] Batch [60]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.207279,	
2017-07-28 15:14:00,358 Epoch[3] Batch [70]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.204894,	
2017-07-28 15:14:07,911 Epoch[3] Batch [80]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.207553,	
2017-07-28 15:14:15,630 Epoch[3] Batch [90]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.203695,	
2017-07-28 15:14:23,054 Epoch[3] Batch [100]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.204475,	
2017-07-28 15:14:30,276 Epoch[3] Batch [110]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.203533,	
2017-07-28 15:14:37,608 Epoch[3] Batch [120]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.201558,	
2017-07-28 15:14:44,933 Epoch[3] Batch [130]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.199718,	
2017-07-28 15:14:52,338 Epoch[3] Batch [140]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.199464,	
2017-07-28 15:14:59,769 Epoch[3] Batch [150]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.197283,	
2017-07-28 15:15:06,825 Epoch[3] Batch [160]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.197564,	
2017-07-28 15:15:13,936 Epoch[3] Batch [170]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.196947,	
2017-07-28 15:15:21,018 Epoch[3] Batch [180]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.195192,	
2017-07-28 15:15:28,272 Epoch[3] Batch [190]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.196295,	
2017-07-28 15:15:35,409 Epoch[3] Batch [200]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.196289,	
2017-07-28 15:15:42,518 Epoch[3] Batch [210]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.195567,	
2017-07-28 15:15:49,646 Epoch[3] Batch [220]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.195006,	
2017-07-28 15:15:56,892 Epoch[3] Batch [230]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.193427,	
2017-07-28 15:16:03,919 Epoch[3] Batch [240]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.193464,	
2017-07-28 15:16:11,035 Epoch[3] Batch [250]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.192982,	
2017-07-28 15:16:18,342 Epoch[3] Batch [260]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.192496,	
2017-07-28 15:16:25,478 Epoch[3] Batch [270]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.194201,	
2017-07-28 15:16:32,614 Epoch[3] Batch [280]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.194784,	
2017-07-28 15:16:39,910 Epoch[3] Batch [290]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.194858,	
2017-07-28 15:16:47,212 Epoch[3] Batch [300]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.194389,	
2017-07-28 15:16:54,392 Epoch[3] Batch [310]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.194124,	
2017-07-28 15:17:01,405 Epoch[3] Batch [320]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.194205,	
2017-07-28 15:17:08,460 Epoch[3] Batch [330]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.193502,	
2017-07-28 15:17:16,277 Epoch[3] Batch [340]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.193483,	
2017-07-28 15:17:26,370 Epoch[3] Batch [350]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.193524,	
2017-07-28 15:17:36,530 Epoch[3] Batch [360]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.192777,	
2017-07-28 15:17:45,544 Epoch[3] Batch [370]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.192248,	
2017-07-28 15:17:53,244 Epoch[3] Batch [380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.192109,	
2017-07-28 15:18:01,014 Epoch[3] Batch [390]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.192394,	
2017-07-28 15:18:07,396 Epoch[3] Batch [400]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.191877,	
2017-07-28 15:18:13,706 Epoch[3] Batch [410]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.191382,	
2017-07-28 15:18:20,269 Epoch[3] Batch [420]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.191615,	
2017-07-28 15:18:26,776 Epoch[3] Batch [430]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.191147,	
2017-07-28 15:18:33,346 Epoch[3] Batch [440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.190999,	
2017-07-28 15:18:39,636 Epoch[3] Batch [450]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.191311,	
2017-07-28 15:18:46,424 Epoch[3] Batch [460]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.191432,	
2017-07-28 15:18:52,449 Epoch[3] Batch [470]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.191415,	
2017-07-28 15:18:58,650 Epoch[3] Batch [480]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.192742,	
2017-07-28 15:19:04,085 Epoch[3] Batch [490]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.193123,	
2017-07-28 15:19:09,529 Epoch[3] Batch [500]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.192690,	
2017-07-28 15:19:15,756 Epoch[3] Batch [510]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.191912,	
2017-07-28 15:19:21,602 Epoch[3] Batch [520]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.192842,	
2017-07-28 15:19:27,481 Epoch[3] Batch [530]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.193100,	
2017-07-28 15:19:33,420 Epoch[3] Batch [540]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.193052,	
2017-07-28 15:19:39,070 Epoch[3] Batch [550]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.192971,	
2017-07-28 15:19:45,081 Epoch[3] Batch [560]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.192711,	
2017-07-28 15:19:50,799 Epoch[3] Batch [570]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.192750,	
2017-07-28 15:19:56,561 Epoch[3] Batch [580]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.192452,	
2017-07-28 15:20:02,223 Epoch[3] Batch [590]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.193015,	
2017-07-28 15:20:07,981 Epoch[3] Batch [600]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.193398,	
2017-07-28 15:20:13,936 Epoch[3] Batch [610]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.193209,	
2017-07-28 15:20:19,511 Epoch[3] Batch [620]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.193406,	
2017-07-28 15:20:25,302 Epoch[3] Batch [630]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.193252,	
2017-07-28 15:20:31,163 Epoch[3] Batch [640]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.193475,	
2017-07-28 15:20:37,054 Epoch[3] Batch [650]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.193836,	
2017-07-28 15:20:42,695 Epoch[3] Batch [660]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.193570,	
2017-07-28 15:20:48,469 Epoch[3] Batch [670]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.193214,	
2017-07-28 15:20:54,303 Epoch[3] Batch [680]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.192788,	
2017-07-28 15:21:00,042 Epoch[3] Batch [690]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.192890,	
2017-07-28 15:21:05,898 Epoch[3] Batch [700]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.193269,	
2017-07-28 15:21:11,586 Epoch[3] Batch [710]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.193277,	
2017-07-28 15:21:17,403 Epoch[3] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.193565,	
2017-07-28 15:21:23,528 Epoch[3] Batch [730]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.193822,	
2017-07-28 15:21:29,373 Epoch[3] Batch [740]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.193311,	
2017-07-28 15:21:35,251 Epoch[3] Batch [750]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.193209,	
2017-07-28 15:21:41,064 Epoch[3] Batch [760]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.193179,	
2017-07-28 15:21:46,941 Epoch[3] Batch [770]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.193043,	
2017-07-28 15:21:52,746 Epoch[3] Batch [780]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.192821,	
2017-07-28 15:21:58,476 Epoch[3] Batch [790]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.192886,	
2017-07-28 15:22:04,221 Epoch[3] Batch [800]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.192890,	
2017-07-28 15:22:09,984 Epoch[3] Batch [810]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.192602,	
2017-07-28 15:22:15,892 Epoch[3] Batch [820]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.192303,	
2017-07-28 15:22:21,744 Epoch[3] Batch [830]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.192432,	
2017-07-28 15:22:27,545 Epoch[3] Batch [840]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.192555,	
2017-07-28 15:22:33,452 Epoch[3] Batch [850]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.192314,	
2017-07-28 15:22:39,278 Epoch[3] Batch [860]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.192764,	
2017-07-28 15:22:45,073 Epoch[3] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.193045,	
2017-07-28 15:22:50,906 Epoch[3] Batch [880]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.192985,	
2017-07-28 15:22:56,732 Epoch[3] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.192842,	
2017-07-28 15:23:02,618 Epoch[3] Batch [900]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.192807,	
2017-07-28 15:23:08,687 Epoch[3] Batch [910]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.192650,	
2017-07-28 15:23:14,746 Epoch[3] Batch [920]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.192807,	
2017-07-28 15:23:20,614 Epoch[3] Batch [930]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.192406,	
2017-07-28 15:23:26,508 Epoch[3] Batch [940]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.192232,	
2017-07-28 15:23:32,256 Epoch[3] Batch [950]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.192474,	
2017-07-28 15:23:37,889 Epoch[3] Batch [960]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.192428,	
2017-07-28 15:23:43,798 Epoch[3] Batch [970]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.192275,	
2017-07-28 15:23:49,653 Epoch[3] Batch [980]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.192409,	
2017-07-28 15:23:57,050 Epoch[3] Batch [990]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.192308,	
2017-07-28 15:24:03,874 Epoch[3] Batch [1000]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.192208,	
2017-07-28 15:24:10,336 Epoch[3] Batch [1010]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.191998,	
2017-07-28 15:24:16,853 Epoch[3] Batch [1020]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.191631,	
2017-07-28 15:24:23,065 Epoch[3] Batch [1030]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.191268,	
2017-07-28 15:24:29,689 Epoch[3] Batch [1040]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.191150,	
2017-07-28 15:24:36,210 Epoch[3] Batch [1050]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.190913,	
2017-07-28 15:24:43,115 Epoch[3] Batch [1060]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.190855,	
2017-07-28 15:24:50,259 Epoch[3] Batch [1070]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.190692,	
2017-07-28 15:24:57,296 Epoch[3] Batch [1080]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.190352,	
2017-07-28 15:25:04,253 Epoch[3] Batch [1090]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.190406,	
2017-07-28 15:25:11,218 Epoch[3] Batch [1100]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.190247,	
2017-07-28 15:25:18,394 Epoch[3] Batch [1110]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.189979,	
2017-07-28 15:25:25,634 Epoch[3] Batch [1120]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.189689,	
2017-07-28 15:25:32,931 Epoch[3] Batch [1130]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.189580,	
2017-07-28 15:25:40,051 Epoch[3] Batch [1140]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.189369,	
2017-07-28 15:25:46,964 Epoch[3] Batch [1150]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.189155,	
2017-07-28 15:25:53,699 Epoch[3] Batch [1160]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.189081,	
2017-07-28 15:26:00,979 Epoch[3] Batch [1170]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.188961,	
2017-07-28 15:26:07,991 Epoch[3] Batch [1180]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.188926,	
2017-07-28 15:26:15,391 Epoch[3] Batch [1190]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.188760,	
2017-07-28 15:26:22,438 Epoch[3] Batch [1200]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.189022,	
2017-07-28 15:26:29,567 Epoch[3] Batch [1210]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.189516,	
2017-07-28 15:26:36,561 Epoch[3] Batch [1220]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.189783,	
2017-07-28 15:26:43,467 Epoch[3] Batch [1230]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.189989,	
2017-07-28 15:26:50,631 Epoch[3] Batch [1240]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.190082,	
2017-07-28 15:26:58,135 Epoch[3] Batch [1250]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.190219,	
2017-07-28 15:27:05,356 Epoch[3] Batch [1260]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.190368,	
2017-07-28 15:27:13,022 Epoch[3] Batch [1270]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.190731,	
2017-07-28 15:27:19,962 Epoch[3] Batch [1280]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.190965,	
2017-07-28 15:27:26,818 Epoch[3] Batch [1290]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.191169,	
2017-07-28 15:27:33,309 Epoch[3] Batch [1300]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.191207,	
2017-07-28 15:27:40,533 Epoch[3] Batch [1310]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.191050,	
2017-07-28 15:27:47,797 Epoch[3] Batch [1320]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.191038,	
2017-07-28 15:27:54,661 Epoch[3] Batch [1330]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.190852,	
2017-07-28 15:28:01,890 Epoch[3] Batch [1340]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.190889,	
2017-07-28 15:28:08,809 Epoch[3] Batch [1350]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.190697,	
2017-07-28 15:28:15,958 Epoch[3] Batch [1360]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.190774,	
2017-07-28 15:28:23,033 Epoch[3] Batch [1370]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.190788,	
2017-07-28 15:28:30,098 Epoch[3] Batch [1380]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.190771,	
2017-07-28 15:28:37,308 Epoch[3] Batch [1390]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.190625,	
2017-07-28 15:28:44,609 Epoch[3] Batch [1400]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.190435,	
2017-07-28 15:28:51,921 Epoch[3] Batch [1410]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.190328,	
2017-07-28 15:28:58,688 Epoch[3] Batch [1420]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.190346,	
2017-07-28 15:29:06,128 Epoch[3] Batch [1430]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.190452,	
2017-07-28 15:29:13,221 Epoch[3] Batch [1440]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.190252,	
2017-07-28 15:29:19,897 Epoch[3] Batch [1450]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.189890,	
2017-07-28 15:29:26,801 Epoch[3] Batch [1460]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.189824,	
2017-07-28 15:29:33,485 Epoch[3] Batch [1470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.189764,	
2017-07-28 15:29:40,530 Epoch[3] Batch [1480]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.189670,	
2017-07-28 15:29:44,805 Epoch[3] Train-FCNLogLoss=0.189885
2017-07-28 15:29:44,805 Epoch[3] Time cost=1002.654
2017-07-28 15:29:46,744 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.params"
2017-07-28 15:29:51,541 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.states"
2017-07-28 15:29:59,700 Epoch[4] Batch [10]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.181785,	
2017-07-28 15:30:06,745 Epoch[4] Batch [20]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.198224,	
2017-07-28 15:30:13,974 Epoch[4] Batch [30]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.185421,	
2017-07-28 15:30:21,286 Epoch[4] Batch [40]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.189507,	
2017-07-28 15:30:28,307 Epoch[4] Batch [50]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.184082,	
2017-07-28 15:30:35,079 Epoch[4] Batch [60]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.180694,	
2017-07-28 15:30:42,227 Epoch[4] Batch [70]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.177830,	
2017-07-28 15:30:49,126 Epoch[4] Batch [80]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.183206,	
2017-07-28 15:30:56,277 Epoch[4] Batch [90]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.183151,	
2017-07-28 15:31:03,544 Epoch[4] Batch [100]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.182220,	
2017-07-28 15:31:10,852 Epoch[4] Batch [110]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.183187,	
2017-07-28 15:31:17,283 Epoch[4] Batch [120]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.180848,	
2017-07-28 15:31:23,979 Epoch[4] Batch [130]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.181074,	
2017-07-28 15:31:30,213 Epoch[4] Batch [140]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.184592,	
2017-07-28 15:31:35,992 Epoch[4] Batch [150]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.185322,	
2017-07-28 15:31:41,864 Epoch[4] Batch [160]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.185949,	
2017-07-28 15:31:47,933 Epoch[4] Batch [170]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.184964,	
2017-07-28 15:31:53,768 Epoch[4] Batch [180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.183960,	
2017-07-28 15:31:59,617 Epoch[4] Batch [190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.184033,	
2017-07-28 15:32:05,436 Epoch[4] Batch [200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.184053,	
2017-07-28 15:32:11,245 Epoch[4] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.183356,	
2017-07-28 15:32:17,070 Epoch[4] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.183013,	
2017-07-28 15:32:22,954 Epoch[4] Batch [230]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.182727,	
2017-07-28 15:32:28,839 Epoch[4] Batch [240]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.181805,	
2017-07-28 15:32:34,626 Epoch[4] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.181366,	
2017-07-28 15:32:40,430 Epoch[4] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.180422,	
2017-07-28 15:32:46,258 Epoch[4] Batch [270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.179978,	
2017-07-28 15:32:52,296 Epoch[4] Batch [280]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.179592,	
2017-07-28 15:32:58,203 Epoch[4] Batch [290]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.179469,	
2017-07-28 15:33:03,986 Epoch[4] Batch [300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.179525,	
2017-07-28 15:33:09,774 Epoch[4] Batch [310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.179400,	
2017-07-28 15:33:15,592 Epoch[4] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.178952,	
2017-07-28 15:33:21,414 Epoch[4] Batch [330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.180876,	
2017-07-28 15:33:27,256 Epoch[4] Batch [340]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.182530,	
2017-07-28 15:33:33,005 Epoch[4] Batch [350]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.182320,	
2017-07-28 15:33:38,900 Epoch[4] Batch [360]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.181977,	
2017-07-28 15:33:44,686 Epoch[4] Batch [370]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.181593,	
2017-07-28 15:33:50,492 Epoch[4] Batch [380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.181244,	
2017-07-28 15:33:56,336 Epoch[4] Batch [390]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.180434,	
2017-07-28 15:34:02,132 Epoch[4] Batch [400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.180783,	
2017-07-28 15:34:07,879 Epoch[4] Batch [410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.180909,	
2017-07-28 15:34:13,628 Epoch[4] Batch [420]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.180322,	
2017-07-28 15:34:19,245 Epoch[4] Batch [430]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.180333,	
2017-07-28 15:34:24,969 Epoch[4] Batch [440]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.179576,	
2017-07-28 15:34:30,773 Epoch[4] Batch [450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.179488,	
2017-07-28 15:34:36,605 Epoch[4] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.179033,	
2017-07-28 15:34:42,347 Epoch[4] Batch [470]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.179037,	
2017-07-28 15:34:48,263 Epoch[4] Batch [480]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.179380,	
2017-07-28 15:34:54,100 Epoch[4] Batch [490]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.179185,	
2017-07-28 15:34:59,909 Epoch[4] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.179688,	
2017-07-28 15:35:05,679 Epoch[4] Batch [510]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.179688,	
2017-07-28 15:35:11,533 Epoch[4] Batch [520]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.179664,	
2017-07-28 15:35:17,300 Epoch[4] Batch [530]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.179728,	
2017-07-28 15:35:23,114 Epoch[4] Batch [540]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.179899,	
2017-07-28 15:35:28,908 Epoch[4] Batch [550]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.179930,	
2017-07-28 15:35:34,719 Epoch[4] Batch [560]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.180394,	
2017-07-28 15:35:40,529 Epoch[4] Batch [570]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.180472,	
2017-07-28 15:35:46,341 Epoch[4] Batch [580]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.180371,	
2017-07-28 15:35:52,128 Epoch[4] Batch [590]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.179952,	
2017-07-28 15:35:57,875 Epoch[4] Batch [600]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.179614,	
2017-07-28 15:36:02,525 Epoch[4] Batch [610]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.179146,	
2017-07-28 15:36:08,429 Epoch[4] Batch [620]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.179202,	
2017-07-28 15:36:14,296 Epoch[4] Batch [630]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.179262,	
2017-07-28 15:36:20,056 Epoch[4] Batch [640]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.178837,	
2017-07-28 15:36:25,871 Epoch[4] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.178658,	
2017-07-28 15:36:31,705 Epoch[4] Batch [660]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.178377,	
2017-07-28 15:36:37,517 Epoch[4] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.178093,	
2017-07-28 15:36:43,322 Epoch[4] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.177634,	
2017-07-28 15:36:49,140 Epoch[4] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.177559,	
2017-07-28 15:36:54,977 Epoch[4] Batch [700]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.177337,	
2017-07-28 15:37:00,778 Epoch[4] Batch [710]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.177210,	
2017-07-28 15:37:06,595 Epoch[4] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.177561,	
2017-07-28 15:37:12,435 Epoch[4] Batch [730]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.177506,	
2017-07-28 15:37:18,397 Epoch[4] Batch [740]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.177319,	
2017-07-28 15:37:24,292 Epoch[4] Batch [750]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.177172,	
2017-07-28 15:37:30,111 Epoch[4] Batch [760]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.177211,	
2017-07-28 15:37:35,969 Epoch[4] Batch [770]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177124,	
2017-07-28 15:37:41,771 Epoch[4] Batch [780]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176940,	
2017-07-28 15:37:47,570 Epoch[4] Batch [790]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176904,	
2017-07-28 15:37:53,422 Epoch[4] Batch [800]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.176939,	
2017-07-28 15:37:59,253 Epoch[4] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.176823,	
2017-07-28 15:38:05,036 Epoch[4] Batch [820]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.176782,	
2017-07-28 15:38:10,843 Epoch[4] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176701,	
2017-07-28 15:38:16,666 Epoch[4] Batch [840]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.176548,	
2017-07-28 15:38:22,481 Epoch[4] Batch [850]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176499,	
2017-07-28 15:38:28,278 Epoch[4] Batch [860]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176642,	
2017-07-28 15:38:34,089 Epoch[4] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176651,	
2017-07-28 15:38:39,932 Epoch[4] Batch [880]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.176566,	
2017-07-28 15:38:45,753 Epoch[4] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.176818,	
2017-07-28 15:38:51,519 Epoch[4] Batch [900]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.176691,	
2017-07-28 15:38:57,348 Epoch[4] Batch [910]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.176825,	
2017-07-28 15:39:03,176 Epoch[4] Batch [920]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.176479,	
2017-07-28 15:39:09,018 Epoch[4] Batch [930]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.176490,	
2017-07-28 15:39:14,817 Epoch[4] Batch [940]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176559,	
2017-07-28 15:39:20,638 Epoch[4] Batch [950]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.176432,	
2017-07-28 15:39:26,438 Epoch[4] Batch [960]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176546,	
2017-07-28 15:39:32,235 Epoch[4] Batch [970]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176453,	
2017-07-28 15:39:38,067 Epoch[4] Batch [980]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.176493,	
2017-07-28 15:39:43,862 Epoch[4] Batch [990]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176640,	
2017-07-28 15:39:49,689 Epoch[4] Batch [1000]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.176754,	
2017-07-28 15:39:55,536 Epoch[4] Batch [1010]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.176934,	
2017-07-28 15:40:01,345 Epoch[4] Batch [1020]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176990,	
2017-07-28 15:40:07,170 Epoch[4] Batch [1030]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.177362,	
2017-07-28 15:40:12,965 Epoch[4] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.177561,	
2017-07-28 15:40:18,780 Epoch[4] Batch [1050]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.177333,	
2017-07-28 15:40:24,556 Epoch[4] Batch [1060]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.177076,	
2017-07-28 15:40:30,365 Epoch[4] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176947,	
2017-07-28 15:40:36,150 Epoch[4] Batch [1080]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.176804,	
2017-07-28 15:40:41,999 Epoch[4] Batch [1090]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.176726,	
2017-07-28 15:40:47,786 Epoch[4] Batch [1100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.176693,	
2017-07-28 15:40:53,594 Epoch[4] Batch [1110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176526,	
2017-07-28 15:40:59,413 Epoch[4] Batch [1120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.176451,	
2017-07-28 15:41:05,224 Epoch[4] Batch [1130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176389,	
2017-07-28 15:41:11,021 Epoch[4] Batch [1140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176356,	
2017-07-28 15:41:16,813 Epoch[4] Batch [1150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.176253,	
2017-07-28 15:41:22,618 Epoch[4] Batch [1160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.175910,	
2017-07-28 15:41:28,444 Epoch[4] Batch [1170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.175809,	
2017-07-28 15:41:34,231 Epoch[4] Batch [1180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.175894,	
2017-07-28 15:41:40,076 Epoch[4] Batch [1190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.175891,	
2017-07-28 15:41:45,864 Epoch[4] Batch [1200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.175973,	
2017-07-28 15:41:51,709 Epoch[4] Batch [1210]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.176050,	
2017-07-28 15:41:57,491 Epoch[4] Batch [1220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.176106,	
2017-07-28 15:42:03,303 Epoch[4] Batch [1230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176322,	
2017-07-28 15:42:09,121 Epoch[4] Batch [1240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176345,	
2017-07-28 15:42:14,980 Epoch[4] Batch [1250]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.176344,	
2017-07-28 15:42:20,767 Epoch[4] Batch [1260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.176206,	
2017-07-28 15:42:26,542 Epoch[4] Batch [1270]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.176042,	
2017-07-28 15:42:32,373 Epoch[4] Batch [1280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.175995,	
2017-07-28 15:42:38,192 Epoch[4] Batch [1290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.175869,	
2017-07-28 15:42:43,956 Epoch[4] Batch [1300]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.175806,	
2017-07-28 15:42:49,812 Epoch[4] Batch [1310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.175687,	
2017-07-28 15:42:55,576 Epoch[4] Batch [1320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.175584,	
2017-07-28 15:43:01,406 Epoch[4] Batch [1330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.175507,	
2017-07-28 15:43:07,212 Epoch[4] Batch [1340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.175483,	
2017-07-28 15:43:13,036 Epoch[4] Batch [1350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.175433,	
2017-07-28 15:43:18,819 Epoch[4] Batch [1360]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.175370,	
2017-07-28 15:43:24,629 Epoch[4] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.175371,	
2017-07-28 15:43:30,439 Epoch[4] Batch [1380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.175493,	
2017-07-28 15:43:36,234 Epoch[4] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.175502,	
2017-07-28 15:43:42,031 Epoch[4] Batch [1400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.175651,	
2017-07-28 15:43:47,828 Epoch[4] Batch [1410]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.175923,	
2017-07-28 15:43:53,665 Epoch[4] Batch [1420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.176117,	
2017-07-28 15:43:59,453 Epoch[4] Batch [1430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.175905,	
2017-07-28 15:44:05,252 Epoch[4] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.175889,	
2017-07-28 15:44:11,040 Epoch[4] Batch [1450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.175793,	
2017-07-28 15:44:16,870 Epoch[4] Batch [1460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.175672,	
2017-07-28 15:44:22,651 Epoch[4] Batch [1470]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.175665,	
2017-07-28 15:44:28,476 Epoch[4] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.175614,	
2017-07-28 15:44:31,938 Epoch[4] Train-FCNLogLoss=0.175523
2017-07-28 15:44:31,938 Epoch[4] Time cost=880.396
2017-07-28 15:44:33,972 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.params"
2017-07-28 15:44:38,033 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.states"
2017-07-28 15:44:44,617 Epoch[5] Batch [10]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.168775,	
2017-07-28 15:44:50,397 Epoch[5] Batch [20]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.164263,	
2017-07-28 15:44:56,208 Epoch[5] Batch [30]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.155511,	
2017-07-28 15:45:02,046 Epoch[5] Batch [40]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.160494,	
2017-07-28 15:45:07,831 Epoch[5] Batch [50]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.158516,	
2017-07-28 15:45:13,670 Epoch[5] Batch [60]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.158542,	
2017-07-28 15:45:19,460 Epoch[5] Batch [70]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.158956,	
2017-07-28 15:45:25,263 Epoch[5] Batch [80]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.159077,	
2017-07-28 15:45:31,096 Epoch[5] Batch [90]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.160227,	
2017-07-28 15:45:36,879 Epoch[5] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.160352,	
2017-07-28 15:45:42,685 Epoch[5] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.162820,	
2017-07-28 15:45:48,516 Epoch[5] Batch [120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.165382,	
2017-07-28 15:45:54,340 Epoch[5] Batch [130]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.168155,	
2017-07-28 15:46:00,155 Epoch[5] Batch [140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.167804,	
2017-07-28 15:46:05,942 Epoch[5] Batch [150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.168083,	
2017-07-28 15:46:11,755 Epoch[5] Batch [160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.167817,	
2017-07-28 15:46:17,574 Epoch[5] Batch [170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.166627,	
2017-07-28 15:46:23,443 Epoch[5] Batch [180]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.165254,	
2017-07-28 15:46:29,276 Epoch[5] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.164814,	
2017-07-28 15:46:35,073 Epoch[5] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163829,	
2017-07-28 15:46:40,879 Epoch[5] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164933,	
2017-07-28 15:46:46,724 Epoch[5] Batch [220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.165227,	
2017-07-28 15:46:52,551 Epoch[5] Batch [230]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.164602,	
2017-07-28 15:46:58,339 Epoch[5] Batch [240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.163948,	
2017-07-28 15:47:04,153 Epoch[5] Batch [250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164605,	
2017-07-28 15:47:09,996 Epoch[5] Batch [260]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164860,	
2017-07-28 15:47:15,779 Epoch[5] Batch [270]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.164789,	
2017-07-28 15:47:21,621 Epoch[5] Batch [280]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164318,	
2017-07-28 15:47:27,424 Epoch[5] Batch [290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164217,	
2017-07-28 15:47:33,264 Epoch[5] Batch [300]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164635,	
2017-07-28 15:47:39,086 Epoch[5] Batch [310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164665,	
2017-07-28 15:47:44,898 Epoch[5] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.165573,	
2017-07-28 15:47:50,707 Epoch[5] Batch [330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.166099,	
2017-07-28 15:47:56,549 Epoch[5] Batch [340]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.165778,	
2017-07-28 15:48:02,306 Epoch[5] Batch [350]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.165243,	
2017-07-28 15:48:08,119 Epoch[5] Batch [360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164604,	
2017-07-28 15:48:13,962 Epoch[5] Batch [370]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164545,	
2017-07-28 15:48:19,776 Epoch[5] Batch [380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163639,	
2017-07-28 15:48:25,616 Epoch[5] Batch [390]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.163997,	
2017-07-28 15:48:31,427 Epoch[5] Batch [400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164334,	
2017-07-28 15:48:37,255 Epoch[5] Batch [410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163815,	
2017-07-28 15:48:43,101 Epoch[5] Batch [420]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.163762,	
2017-07-28 15:48:48,908 Epoch[5] Batch [430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163887,	
2017-07-28 15:48:54,727 Epoch[5] Batch [440]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164011,	
2017-07-28 15:49:00,534 Epoch[5] Batch [450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163884,	
2017-07-28 15:49:06,328 Epoch[5] Batch [460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163876,	
2017-07-28 15:49:12,151 Epoch[5] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164177,	
2017-07-28 15:49:17,952 Epoch[5] Batch [480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164447,	
2017-07-28 15:49:23,705 Epoch[5] Batch [490]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.164229,	
2017-07-28 15:49:29,515 Epoch[5] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164058,	
2017-07-28 15:49:35,382 Epoch[5] Batch [510]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.164604,	
2017-07-28 15:49:41,230 Epoch[5] Batch [520]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.165808,	
2017-07-28 15:49:47,042 Epoch[5] Batch [530]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.167053,	
2017-07-28 15:49:52,879 Epoch[5] Batch [540]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.167514,	
2017-07-28 15:49:58,678 Epoch[5] Batch [550]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.167238,	
2017-07-28 15:50:04,509 Epoch[5] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.167279,	
2017-07-28 15:50:10,306 Epoch[5] Batch [570]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.167092,	
2017-07-28 15:50:16,122 Epoch[5] Batch [580]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.166939,	
2017-07-28 15:50:21,927 Epoch[5] Batch [590]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.166772,	
2017-07-28 15:50:26,576 Epoch[5] Batch [600]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.166448,	
2017-07-28 15:50:31,416 Epoch[5] Batch [610]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.166344,	
2017-07-28 15:50:37,308 Epoch[5] Batch [620]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.166360,	
2017-07-28 15:50:43,225 Epoch[5] Batch [630]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.166260,	
2017-07-28 15:50:49,023 Epoch[5] Batch [640]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.166151,	
2017-07-28 15:50:54,862 Epoch[5] Batch [650]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.165964,	
2017-07-28 15:51:00,685 Epoch[5] Batch [660]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.166028,	
2017-07-28 15:51:06,475 Epoch[5] Batch [670]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.166257,	
2017-07-28 15:51:12,300 Epoch[5] Batch [680]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.166288,	
2017-07-28 15:51:18,110 Epoch[5] Batch [690]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.166430,	
2017-07-28 15:51:23,836 Epoch[5] Batch [700]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.166789,	
2017-07-28 15:51:29,707 Epoch[5] Batch [710]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.166676,	
2017-07-28 15:51:35,504 Epoch[5] Batch [720]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.166446,	
2017-07-28 15:51:41,349 Epoch[5] Batch [730]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.166124,	
2017-07-28 15:51:47,190 Epoch[5] Batch [740]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.165965,	
2017-07-28 15:51:53,009 Epoch[5] Batch [750]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.165475,	
2017-07-28 15:51:58,876 Epoch[5] Batch [760]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.165363,	
2017-07-28 15:52:04,671 Epoch[5] Batch [770]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.165407,	
2017-07-28 15:52:10,462 Epoch[5] Batch [780]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.165342,	
2017-07-28 15:52:16,323 Epoch[5] Batch [790]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.165196,	
2017-07-28 15:52:22,119 Epoch[5] Batch [800]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164939,	
2017-07-28 15:52:27,913 Epoch[5] Batch [810]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164985,	
2017-07-28 15:52:33,716 Epoch[5] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.165059,	
2017-07-28 15:52:39,510 Epoch[5] Batch [830]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.165096,	
2017-07-28 15:52:45,345 Epoch[5] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.165117,	
2017-07-28 15:52:51,194 Epoch[5] Batch [850]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164952,	
2017-07-28 15:52:56,966 Epoch[5] Batch [860]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.165105,	
2017-07-28 15:53:02,597 Epoch[5] Batch [870]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.165093,	
2017-07-28 15:53:08,410 Epoch[5] Batch [880]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164951,	
2017-07-28 15:53:14,222 Epoch[5] Batch [890]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164764,	
2017-07-28 15:53:20,006 Epoch[5] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.164633,	
2017-07-28 15:53:25,851 Epoch[5] Batch [910]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164510,	
2017-07-28 15:53:31,640 Epoch[5] Batch [920]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.164652,	
2017-07-28 15:53:37,444 Epoch[5] Batch [930]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164569,	
2017-07-28 15:53:43,234 Epoch[5] Batch [940]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.164299,	
2017-07-28 15:53:49,070 Epoch[5] Batch [950]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164249,	
2017-07-28 15:53:54,857 Epoch[5] Batch [960]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.164231,	
2017-07-28 15:54:00,676 Epoch[5] Batch [970]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164085,	
2017-07-28 15:54:06,465 Epoch[5] Batch [980]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.164058,	
2017-07-28 15:54:12,297 Epoch[5] Batch [990]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163978,	
2017-07-28 15:54:18,105 Epoch[5] Batch [1000]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163780,	
2017-07-28 15:54:23,915 Epoch[5] Batch [1010]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163683,	
2017-07-28 15:54:29,766 Epoch[5] Batch [1020]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.163994,	
2017-07-28 15:54:35,569 Epoch[5] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163904,	
2017-07-28 15:54:41,399 Epoch[5] Batch [1040]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163701,	
2017-07-28 15:54:47,195 Epoch[5] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163726,	
2017-07-28 15:54:52,996 Epoch[5] Batch [1060]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163670,	
2017-07-28 15:54:58,801 Epoch[5] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163696,	
2017-07-28 15:55:04,632 Epoch[5] Batch [1080]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163987,	
2017-07-28 15:55:10,448 Epoch[5] Batch [1090]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164092,	
2017-07-28 15:55:16,256 Epoch[5] Batch [1100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164367,	
2017-07-28 15:55:22,058 Epoch[5] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164460,	
2017-07-28 15:55:27,912 Epoch[5] Batch [1120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.164767,	
2017-07-28 15:55:33,714 Epoch[5] Batch [1130]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164899,	
2017-07-28 15:55:39,531 Epoch[5] Batch [1140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164907,	
2017-07-28 15:55:45,344 Epoch[5] Batch [1150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164916,	
2017-07-28 15:55:51,166 Epoch[5] Batch [1160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164859,	
2017-07-28 15:55:56,982 Epoch[5] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164666,	
2017-07-28 15:56:02,803 Epoch[5] Batch [1180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164710,	
2017-07-28 15:56:08,594 Epoch[5] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.164703,	
2017-07-28 15:56:14,410 Epoch[5] Batch [1200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164696,	
2017-07-28 15:56:20,272 Epoch[5] Batch [1210]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.164831,	
2017-07-28 15:56:26,107 Epoch[5] Batch [1220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.164798,	
2017-07-28 15:56:32,035 Epoch[5] Batch [1230]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.165036,	
2017-07-28 15:56:37,971 Epoch[5] Batch [1240]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.165012,	
2017-07-28 15:56:43,828 Epoch[5] Batch [1250]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.164888,	
2017-07-28 15:56:49,656 Epoch[5] Batch [1260]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.164856,	
2017-07-28 15:56:55,457 Epoch[5] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164788,	
2017-07-28 15:57:01,253 Epoch[5] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164895,	
2017-07-28 15:57:07,112 Epoch[5] Batch [1290]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.164896,	
2017-07-28 15:57:12,898 Epoch[5] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.164673,	
2017-07-28 15:57:18,768 Epoch[5] Batch [1310]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.164526,	
2017-07-28 15:57:24,520 Epoch[5] Batch [1320]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.164409,	
2017-07-28 15:57:30,413 Epoch[5] Batch [1330]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.164323,	
2017-07-28 15:57:36,238 Epoch[5] Batch [1340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164097,	
2017-07-28 15:57:42,039 Epoch[5] Batch [1350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164212,	
2017-07-28 15:57:47,865 Epoch[5] Batch [1360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164091,	
2017-07-28 15:57:53,717 Epoch[5] Batch [1370]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.164072,	
2017-07-28 15:57:59,559 Epoch[5] Batch [1380]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.163979,	
2017-07-28 15:58:05,366 Epoch[5] Batch [1390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163890,	
2017-07-28 15:58:11,187 Epoch[5] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.163803,	
2017-07-28 15:58:17,024 Epoch[5] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.163630,	
2017-07-28 15:58:22,807 Epoch[5] Batch [1420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.163736,	
2017-07-28 15:58:28,696 Epoch[5] Batch [1430]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.163949,	
2017-07-28 15:58:34,470 Epoch[5] Batch [1440]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.163981,	
2017-07-28 15:58:40,311 Epoch[5] Batch [1450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.163874,	
2017-07-28 15:58:46,136 Epoch[5] Batch [1460]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.163943,	
2017-07-28 15:58:51,938 Epoch[5] Batch [1470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163966,	
2017-07-28 15:58:57,734 Epoch[5] Batch [1480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163928,	
2017-07-28 15:59:01,274 Epoch[5] Train-FCNLogLoss=0.163907
2017-07-28 15:59:01,275 Epoch[5] Time cost=863.241
2017-07-28 15:59:03,126 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.params"
2017-07-28 15:59:07,651 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.states"
2017-07-28 15:59:14,233 Epoch[6] Batch [10]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.197434,	
2017-07-28 15:59:20,086 Epoch[6] Batch [20]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.196016,	
2017-07-28 15:59:25,933 Epoch[6] Batch [30]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.179866,	
2017-07-28 15:59:31,721 Epoch[6] Batch [40]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.177051,	
2017-07-28 15:59:37,513 Epoch[6] Batch [50]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.175359,	
2017-07-28 15:59:43,124 Epoch[6] Batch [60]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.172986,	
2017-07-28 15:59:48,883 Epoch[6] Batch [70]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.166640,	
2017-07-28 15:59:54,706 Epoch[6] Batch [80]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.163598,	
2017-07-28 16:00:00,507 Epoch[6] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163734,	
2017-07-28 16:00:06,314 Epoch[6] Batch [100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163561,	
2017-07-28 16:00:12,184 Epoch[6] Batch [110]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.162869,	
2017-07-28 16:00:17,985 Epoch[6] Batch [120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163002,	
2017-07-28 16:00:23,784 Epoch[6] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.161596,	
2017-07-28 16:00:29,584 Epoch[6] Batch [140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.161161,	
2017-07-28 16:00:35,401 Epoch[6] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.159314,	
2017-07-28 16:00:41,216 Epoch[6] Batch [160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.158544,	
2017-07-28 16:00:47,012 Epoch[6] Batch [170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.157989,	
2017-07-28 16:00:52,827 Epoch[6] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.158448,	
2017-07-28 16:00:58,635 Epoch[6] Batch [190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.158532,	
2017-07-28 16:01:04,461 Epoch[6] Batch [200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.158470,	
2017-07-28 16:01:10,242 Epoch[6] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.157787,	
2017-07-28 16:01:16,075 Epoch[6] Batch [220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.157314,	
2017-07-28 16:01:21,893 Epoch[6] Batch [230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.156862,	
2017-07-28 16:01:27,700 Epoch[6] Batch [240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.157292,	
2017-07-28 16:01:33,546 Epoch[6] Batch [250]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.157009,	
2017-07-28 16:01:39,337 Epoch[6] Batch [260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.157394,	
2017-07-28 16:01:45,143 Epoch[6] Batch [270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.157094,	
2017-07-28 16:01:50,967 Epoch[6] Batch [280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.156606,	
2017-07-28 16:01:56,805 Epoch[6] Batch [290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.157276,	
2017-07-28 16:02:02,619 Epoch[6] Batch [300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.158235,	
2017-07-28 16:02:08,459 Epoch[6] Batch [310]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.158659,	
2017-07-28 16:02:14,235 Epoch[6] Batch [320]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.158729,	
2017-07-28 16:02:20,017 Epoch[6] Batch [330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.158399,	
2017-07-28 16:02:25,840 Epoch[6] Batch [340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.159459,	
2017-07-28 16:02:31,660 Epoch[6] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.159121,	
2017-07-28 16:02:37,525 Epoch[6] Batch [360]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.159713,	
2017-07-28 16:02:43,293 Epoch[6] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.159708,	
2017-07-28 16:02:49,140 Epoch[6] Batch [380]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.160050,	
2017-07-28 16:02:54,928 Epoch[6] Batch [390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.159924,	
2017-07-28 16:03:00,726 Epoch[6] Batch [400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.160011,	
2017-07-28 16:03:06,526 Epoch[6] Batch [410]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.159857,	
2017-07-28 16:03:12,403 Epoch[6] Batch [420]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.159982,	
2017-07-28 16:03:18,219 Epoch[6] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.159814,	
2017-07-28 16:03:24,019 Epoch[6] Batch [440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.159753,	
2017-07-28 16:03:29,869 Epoch[6] Batch [450]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.159506,	
2017-07-28 16:03:35,709 Epoch[6] Batch [460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.158847,	
2017-07-28 16:03:41,527 Epoch[6] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.159165,	
2017-07-28 16:03:47,335 Epoch[6] Batch [480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.159179,	
2017-07-28 16:03:53,131 Epoch[6] Batch [490]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.159508,	
2017-07-28 16:03:58,997 Epoch[6] Batch [500]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.159472,	
2017-07-28 16:04:04,780 Epoch[6] Batch [510]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.159274,	
2017-07-28 16:04:10,588 Epoch[6] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.158975,	
2017-07-28 16:04:16,369 Epoch[6] Batch [530]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.159293,	
2017-07-28 16:04:22,237 Epoch[6] Batch [540]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.159177,	
2017-07-28 16:04:28,045 Epoch[6] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.158773,	
2017-07-28 16:04:33,855 Epoch[6] Batch [560]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.158566,	
2017-07-28 16:04:39,595 Epoch[6] Batch [570]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.158253,	
2017-07-28 16:04:45,562 Epoch[6] Batch [580]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.157939,	
2017-07-28 16:04:51,356 Epoch[6] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.157761,	
2017-07-28 16:04:56,416 Epoch[6] Batch [600]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.157654,	
2017-07-28 16:05:01,430 Epoch[6] Batch [610]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.157623,	
2017-07-28 16:05:07,255 Epoch[6] Batch [620]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.157481,	
2017-07-28 16:05:13,074 Epoch[6] Batch [630]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.157413,	
2017-07-28 16:05:18,913 Epoch[6] Batch [640]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.157507,	
2017-07-28 16:05:24,710 Epoch[6] Batch [650]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.157307,	
2017-07-28 16:05:30,551 Epoch[6] Batch [660]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.157586,	
2017-07-28 16:05:36,393 Epoch[6] Batch [670]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.157365,	
2017-07-28 16:05:42,214 Epoch[6] Batch [680]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.157179,	
2017-07-28 16:05:47,935 Epoch[6] Batch [690]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.157075,	
2017-07-28 16:05:53,759 Epoch[6] Batch [700]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.156973,	
2017-07-28 16:05:59,656 Epoch[6] Batch [710]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.157313,	
2017-07-28 16:06:05,467 Epoch[6] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.157048,	
2017-07-28 16:06:11,254 Epoch[6] Batch [730]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.157080,	
2017-07-28 16:06:17,076 Epoch[6] Batch [740]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.156810,	
2017-07-28 16:06:22,891 Epoch[6] Batch [750]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.157042,	
2017-07-28 16:06:28,711 Epoch[6] Batch [760]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.156820,	
2017-07-28 16:06:34,542 Epoch[6] Batch [770]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.156915,	
2017-07-28 16:06:40,349 Epoch[6] Batch [780]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.156729,	
2017-07-28 16:06:46,168 Epoch[6] Batch [790]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.156496,	
2017-07-28 16:06:52,001 Epoch[6] Batch [800]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.156391,	
2017-07-28 16:06:57,836 Epoch[6] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.156497,	
2017-07-28 16:07:03,599 Epoch[6] Batch [820]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.156196,	
2017-07-28 16:07:09,384 Epoch[6] Batch [830]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.156217,	
2017-07-28 16:07:15,232 Epoch[6] Batch [840]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.156189,	
2017-07-28 16:07:21,090 Epoch[6] Batch [850]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.155838,	
2017-07-28 16:07:26,919 Epoch[6] Batch [860]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.155653,	
2017-07-28 16:07:32,734 Epoch[6] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.155851,	
2017-07-28 16:07:38,538 Epoch[6] Batch [880]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.156076,	
2017-07-28 16:07:44,363 Epoch[6] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.156071,	
2017-07-28 16:07:50,210 Epoch[6] Batch [900]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.156292,	
2017-07-28 16:07:56,044 Epoch[6] Batch [910]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.156311,	
2017-07-28 16:08:01,830 Epoch[6] Batch [920]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.156362,	
2017-07-28 16:08:07,647 Epoch[6] Batch [930]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.156373,	
2017-07-28 16:08:13,465 Epoch[6] Batch [940]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.156327,	
2017-07-28 16:08:19,325 Epoch[6] Batch [950]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.156434,	
2017-07-28 16:08:25,097 Epoch[6] Batch [960]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.156269,	
2017-07-28 16:08:30,936 Epoch[6] Batch [970]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.156360,	
2017-07-28 16:08:36,739 Epoch[6] Batch [980]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.156279,	
2017-07-28 16:08:42,590 Epoch[6] Batch [990]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.156055,	
2017-07-28 16:08:48,350 Epoch[6] Batch [1000]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.155971,	
2017-07-28 16:08:54,186 Epoch[6] Batch [1010]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.155746,	
2017-07-28 16:08:59,998 Epoch[6] Batch [1020]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.155711,	
2017-07-28 16:09:05,790 Epoch[6] Batch [1030]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.155727,	
2017-07-28 16:09:11,590 Epoch[6] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.155770,	
2017-07-28 16:09:17,461 Epoch[6] Batch [1050]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.155716,	
2017-07-28 16:09:23,238 Epoch[6] Batch [1060]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.155527,	
2017-07-28 16:09:29,058 Epoch[6] Batch [1070]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.155531,	
2017-07-28 16:09:34,891 Epoch[6] Batch [1080]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.155631,	
2017-07-28 16:09:40,701 Epoch[6] Batch [1090]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.155452,	
2017-07-28 16:09:46,499 Epoch[6] Batch [1100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.155280,	
2017-07-28 16:09:52,345 Epoch[6] Batch [1110]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.155306,	
2017-07-28 16:09:58,134 Epoch[6] Batch [1120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.155320,	
2017-07-28 16:10:03,971 Epoch[6] Batch [1130]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.155579,	
2017-07-28 16:10:09,715 Epoch[6] Batch [1140]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.155659,	
2017-07-28 16:10:15,495 Epoch[6] Batch [1150]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.155650,	
2017-07-28 16:10:21,375 Epoch[6] Batch [1160]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.155700,	
2017-07-28 16:10:27,238 Epoch[6] Batch [1170]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.155637,	
2017-07-28 16:10:33,049 Epoch[6] Batch [1180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.155467,	
2017-07-28 16:10:38,839 Epoch[6] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.155378,	
2017-07-28 16:10:44,645 Epoch[6] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.155124,	
2017-07-28 16:10:50,423 Epoch[6] Batch [1210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.154925,	
2017-07-28 16:10:56,274 Epoch[6] Batch [1220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.154843,	
2017-07-28 16:11:02,012 Epoch[6] Batch [1230]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.154809,	
2017-07-28 16:11:07,625 Epoch[6] Batch [1240]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.154775,	
2017-07-28 16:11:13,424 Epoch[6] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.154821,	
2017-07-28 16:11:19,223 Epoch[6] Batch [1260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.154716,	
2017-07-28 16:11:25,064 Epoch[6] Batch [1270]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.154704,	
2017-07-28 16:11:30,888 Epoch[6] Batch [1280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.154603,	
2017-07-28 16:11:36,695 Epoch[6] Batch [1290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.154549,	
2017-07-28 16:11:42,430 Epoch[6] Batch [1300]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.154545,	
2017-07-28 16:11:48,251 Epoch[6] Batch [1310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.154562,	
2017-07-28 16:11:54,128 Epoch[6] Batch [1320]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.154473,	
2017-07-28 16:11:59,999 Epoch[6] Batch [1330]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.154500,	
2017-07-28 16:12:05,814 Epoch[6] Batch [1340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.154379,	
2017-07-28 16:12:11,636 Epoch[6] Batch [1350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.154399,	
2017-07-28 16:12:17,362 Epoch[6] Batch [1360]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.154390,	
2017-07-28 16:12:23,333 Epoch[6] Batch [1370]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.154599,	
2017-07-28 16:12:29,146 Epoch[6] Batch [1380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.154820,	
2017-07-28 16:12:34,968 Epoch[6] Batch [1390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.154759,	
2017-07-28 16:12:40,768 Epoch[6] Batch [1400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.154841,	
2017-07-28 16:12:46,612 Epoch[6] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.154854,	
2017-07-28 16:12:52,407 Epoch[6] Batch [1420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.154782,	
2017-07-28 16:12:57,938 Epoch[6] Batch [1430]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.154755,	
2017-07-28 16:13:03,772 Epoch[6] Batch [1440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.155126,	
2017-07-28 16:13:09,182 Epoch[6] Batch [1450]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.155140,	
2017-07-28 16:13:14,769 Epoch[6] Batch [1460]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.155168,	
2017-07-28 16:13:20,313 Epoch[6] Batch [1470]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.155067,	
2017-07-28 16:13:26,119 Epoch[6] Batch [1480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.154938,	
2017-07-28 16:13:29,676 Epoch[6] Train-FCNLogLoss=0.154860
2017-07-28 16:13:29,676 Epoch[6] Time cost=862.024
2017-07-28 16:13:31,536 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.params"
2017-07-28 16:13:35,502 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.states"
2017-07-28 16:13:41,830 Epoch[7] Batch [10]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.153482,	
2017-07-28 16:13:47,421 Epoch[7] Batch [20]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.153724,	
2017-07-28 16:13:53,212 Epoch[7] Batch [30]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.161163,	
2017-07-28 16:13:59,038 Epoch[7] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.156665,	
2017-07-28 16:14:04,861 Epoch[7] Batch [50]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.154023,	
2017-07-28 16:14:10,667 Epoch[7] Batch [60]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.155249,	
2017-07-28 16:14:16,504 Epoch[7] Batch [70]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151325,	
2017-07-28 16:14:22,315 Epoch[7] Batch [80]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.150437,	
2017-07-28 16:14:28,132 Epoch[7] Batch [90]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.150901,	
2017-07-28 16:14:33,990 Epoch[7] Batch [100]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.149784,	
2017-07-28 16:14:39,784 Epoch[7] Batch [110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.149490,	
2017-07-28 16:14:45,617 Epoch[7] Batch [120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.148595,	
2017-07-28 16:14:51,459 Epoch[7] Batch [130]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.147339,	
2017-07-28 16:14:57,296 Epoch[7] Batch [140]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.146870,	
2017-07-28 16:15:03,071 Epoch[7] Batch [150]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.146916,	
2017-07-28 16:15:08,894 Epoch[7] Batch [160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.147095,	
2017-07-28 16:15:14,704 Epoch[7] Batch [170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.147802,	
2017-07-28 16:15:20,510 Epoch[7] Batch [180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.150060,	
2017-07-28 16:15:26,296 Epoch[7] Batch [190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.149517,	
2017-07-28 16:15:32,177 Epoch[7] Batch [200]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.149259,	
2017-07-28 16:15:38,031 Epoch[7] Batch [210]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.150486,	
2017-07-28 16:15:43,853 Epoch[7] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.150717,	
2017-07-28 16:15:49,636 Epoch[7] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.151394,	
2017-07-28 16:15:55,478 Epoch[7] Batch [240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151533,	
2017-07-28 16:16:01,307 Epoch[7] Batch [250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151302,	
2017-07-28 16:16:07,135 Epoch[7] Batch [260]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151793,	
2017-07-28 16:16:12,959 Epoch[7] Batch [270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151742,	
2017-07-28 16:16:18,779 Epoch[7] Batch [280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.150668,	
2017-07-28 16:16:24,621 Epoch[7] Batch [290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.150175,	
2017-07-28 16:16:30,428 Epoch[7] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.150366,	
2017-07-28 16:16:36,144 Epoch[7] Batch [310]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.150273,	
2017-07-28 16:16:41,972 Epoch[7] Batch [320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.150591,	
2017-07-28 16:16:47,811 Epoch[7] Batch [330]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.150157,	
2017-07-28 16:16:53,712 Epoch[7] Batch [340]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.149684,	
2017-07-28 16:16:59,477 Epoch[7] Batch [350]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.149646,	
2017-07-28 16:17:05,321 Epoch[7] Batch [360]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.149518,	
2017-07-28 16:17:11,171 Epoch[7] Batch [370]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.149268,	
2017-07-28 16:17:16,976 Epoch[7] Batch [380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149061,	
2017-07-28 16:17:22,802 Epoch[7] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.148815,	
2017-07-28 16:17:28,662 Epoch[7] Batch [400]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.148399,	
2017-07-28 16:17:34,454 Epoch[7] Batch [410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.147805,	
2017-07-28 16:17:40,248 Epoch[7] Batch [420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.147569,	
2017-07-28 16:17:46,075 Epoch[7] Batch [430]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.147512,	
2017-07-28 16:17:51,910 Epoch[7] Batch [440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.147122,	
2017-07-28 16:17:57,731 Epoch[7] Batch [450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.146938,	
2017-07-28 16:18:03,582 Epoch[7] Batch [460]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.147321,	
2017-07-28 16:18:09,401 Epoch[7] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.147186,	
2017-07-28 16:18:14,798 Epoch[7] Batch [480]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.147484,	
2017-07-28 16:18:20,679 Epoch[7] Batch [490]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.147362,	
2017-07-28 16:18:26,550 Epoch[7] Batch [500]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.147335,	
2017-07-28 16:18:32,354 Epoch[7] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.147337,	
2017-07-28 16:18:37,911 Epoch[7] Batch [520]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.148277,	
2017-07-28 16:18:43,774 Epoch[7] Batch [530]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.148245,	
2017-07-28 16:18:49,575 Epoch[7] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.148090,	
2017-07-28 16:18:55,370 Epoch[7] Batch [550]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.148081,	
2017-07-28 16:19:01,214 Epoch[7] Batch [560]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.147922,	
2017-07-28 16:19:07,059 Epoch[7] Batch [570]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.147796,	
2017-07-28 16:19:12,852 Epoch[7] Batch [580]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.147899,	
2017-07-28 16:19:18,598 Epoch[7] Batch [590]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.147846,	
2017-07-28 16:19:24,514 Epoch[7] Batch [600]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.148001,	
2017-07-28 16:19:29,896 Epoch[7] Batch [610]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.148209,	
2017-07-28 16:19:35,369 Epoch[7] Batch [620]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.148330,	
2017-07-28 16:19:41,269 Epoch[7] Batch [630]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.148288,	
2017-07-28 16:19:47,076 Epoch[7] Batch [640]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.148388,	
2017-07-28 16:19:52,971 Epoch[7] Batch [650]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.148298,	
2017-07-28 16:19:58,753 Epoch[7] Batch [660]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.148786,	
2017-07-28 16:20:04,414 Epoch[7] Batch [670]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.148585,	
2017-07-28 16:20:10,177 Epoch[7] Batch [680]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.148547,	
2017-07-28 16:20:15,951 Epoch[7] Batch [690]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.148569,	
2017-07-28 16:20:21,766 Epoch[7] Batch [700]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.148841,	
2017-07-28 16:20:27,617 Epoch[7] Batch [710]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.149006,	
2017-07-28 16:20:33,109 Epoch[7] Batch [720]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.148836,	
2017-07-28 16:20:38,908 Epoch[7] Batch [730]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.148970,	
2017-07-28 16:20:44,686 Epoch[7] Batch [740]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.148789,	
2017-07-28 16:20:50,291 Epoch[7] Batch [750]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.148842,	
2017-07-28 16:20:55,999 Epoch[7] Batch [760]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.148900,	
2017-07-28 16:21:01,921 Epoch[7] Batch [770]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.149095,	
2017-07-28 16:21:07,693 Epoch[7] Batch [780]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.149032,	
2017-07-28 16:21:13,294 Epoch[7] Batch [790]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.149059,	
2017-07-28 16:21:18,944 Epoch[7] Batch [800]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.149024,	
2017-07-28 16:21:24,767 Epoch[7] Batch [810]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.148850,	
2017-07-28 16:21:30,576 Epoch[7] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.148919,	
2017-07-28 16:21:36,386 Epoch[7] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149068,	
2017-07-28 16:21:42,198 Epoch[7] Batch [840]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.149177,	
2017-07-28 16:21:47,960 Epoch[7] Batch [850]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.148982,	
2017-07-28 16:21:53,872 Epoch[7] Batch [860]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.148869,	
2017-07-28 16:21:59,687 Epoch[7] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.148780,	
2017-07-28 16:22:05,322 Epoch[7] Batch [880]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.148854,	
2017-07-28 16:22:11,068 Epoch[7] Batch [890]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.148879,	
2017-07-28 16:22:16,792 Epoch[7] Batch [900]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.149969,	
2017-07-28 16:22:22,549 Epoch[7] Batch [910]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.150588,	
2017-07-28 16:22:28,390 Epoch[7] Batch [920]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151297,	
2017-07-28 16:22:34,182 Epoch[7] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.151592,	
2017-07-28 16:22:40,020 Epoch[7] Batch [940]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151592,	
2017-07-28 16:22:45,829 Epoch[7] Batch [950]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.151906,	
2017-07-28 16:22:51,643 Epoch[7] Batch [960]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.152292,	
2017-07-28 16:22:57,469 Epoch[7] Batch [970]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.152350,	
2017-07-28 16:23:03,350 Epoch[7] Batch [980]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.152522,	
2017-07-28 16:23:09,156 Epoch[7] Batch [990]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.152441,	
2017-07-28 16:23:14,771 Epoch[7] Batch [1000]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.152420,	
2017-07-28 16:23:20,542 Epoch[7] Batch [1010]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.152465,	
2017-07-28 16:23:26,403 Epoch[7] Batch [1020]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.152283,	
2017-07-28 16:23:32,208 Epoch[7] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.152318,	
2017-07-28 16:23:38,102 Epoch[7] Batch [1040]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.152223,	
2017-07-28 16:23:43,924 Epoch[7] Batch [1050]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.152323,	
2017-07-28 16:23:49,520 Epoch[7] Batch [1060]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.152218,	
2017-07-28 16:23:55,347 Epoch[7] Batch [1070]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.152173,	
2017-07-28 16:24:01,083 Epoch[7] Batch [1080]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.152083,	
2017-07-28 16:24:06,842 Epoch[7] Batch [1090]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.152006,	
2017-07-28 16:24:12,689 Epoch[7] Batch [1100]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.152185,	
2017-07-28 16:24:18,251 Epoch[7] Batch [1110]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.152189,	
2017-07-28 16:24:24,025 Epoch[7] Batch [1120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.152101,	
2017-07-28 16:24:29,860 Epoch[7] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.152045,	
2017-07-28 16:24:35,682 Epoch[7] Batch [1140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.152051,	
2017-07-28 16:24:41,585 Epoch[7] Batch [1150]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.152018,	
2017-07-28 16:24:47,431 Epoch[7] Batch [1160]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.151989,	
2017-07-28 16:24:53,273 Epoch[7] Batch [1170]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151887,	
2017-07-28 16:24:59,163 Epoch[7] Batch [1180]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.151850,	
2017-07-28 16:25:05,078 Epoch[7] Batch [1190]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.151785,	
2017-07-28 16:25:10,934 Epoch[7] Batch [1200]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.151913,	
2017-07-28 16:25:16,761 Epoch[7] Batch [1210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151907,	
2017-07-28 16:25:22,604 Epoch[7] Batch [1220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151852,	
2017-07-28 16:25:28,422 Epoch[7] Batch [1230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151752,	
2017-07-28 16:25:34,218 Epoch[7] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.151697,	
2017-07-28 16:25:40,028 Epoch[7] Batch [1250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.151666,	
2017-07-28 16:25:45,855 Epoch[7] Batch [1260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151608,	
2017-07-28 16:25:51,681 Epoch[7] Batch [1270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151568,	
2017-07-28 16:25:57,496 Epoch[7] Batch [1280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151617,	
2017-07-28 16:26:03,328 Epoch[7] Batch [1290]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151547,	
2017-07-28 16:26:09,134 Epoch[7] Batch [1300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.151557,	
2017-07-28 16:26:14,975 Epoch[7] Batch [1310]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151497,	
2017-07-28 16:26:20,803 Epoch[7] Batch [1320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151580,	
2017-07-28 16:26:26,626 Epoch[7] Batch [1330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151507,	
2017-07-28 16:26:32,456 Epoch[7] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151406,	
2017-07-28 16:26:38,275 Epoch[7] Batch [1350]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151369,	
2017-07-28 16:26:44,080 Epoch[7] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.151300,	
2017-07-28 16:26:49,887 Epoch[7] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.151320,	
2017-07-28 16:26:55,715 Epoch[7] Batch [1380]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151224,	
2017-07-28 16:27:01,526 Epoch[7] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151147,	
2017-07-28 16:27:07,351 Epoch[7] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151162,	
2017-07-28 16:27:13,140 Epoch[7] Batch [1410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.151054,	
2017-07-28 16:27:18,946 Epoch[7] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.151247,	
2017-07-28 16:27:24,787 Epoch[7] Batch [1430]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.151162,	
2017-07-28 16:27:30,617 Epoch[7] Batch [1440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151285,	
2017-07-28 16:27:36,429 Epoch[7] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151169,	
2017-07-28 16:27:42,229 Epoch[7] Batch [1460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.151135,	
2017-07-28 16:27:48,042 Epoch[7] Batch [1470]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151087,	
2017-07-28 16:27:53,857 Epoch[7] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.150983,	
2017-07-28 16:27:57,334 Epoch[7] Train-FCNLogLoss=0.150898
2017-07-28 16:27:57,334 Epoch[7] Time cost=861.832
2017-07-28 16:27:58,631 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.params"
2017-07-28 16:28:01,595 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.states"
2017-07-28 16:28:08,063 Epoch[8] Batch [10]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.147514,	
2017-07-28 16:28:13,817 Epoch[8] Batch [20]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.136118,	
2017-07-28 16:28:19,615 Epoch[8] Batch [30]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.149524,	
2017-07-28 16:28:25,499 Epoch[8] Batch [40]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.148612,	
2017-07-28 16:28:31,262 Epoch[8] Batch [50]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.147415,	
2017-07-28 16:28:37,026 Epoch[8] Batch [60]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.146429,	
2017-07-28 16:28:42,831 Epoch[8] Batch [70]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.147917,	
2017-07-28 16:28:48,616 Epoch[8] Batch [80]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.144777,	
2017-07-28 16:28:54,477 Epoch[8] Batch [90]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.142766,	
2017-07-28 16:29:00,307 Epoch[8] Batch [100]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141912,	
2017-07-28 16:29:06,115 Epoch[8] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.139601,	
2017-07-28 16:29:11,929 Epoch[8] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.139367,	
2017-07-28 16:29:17,711 Epoch[8] Batch [130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.140346,	
2017-07-28 16:29:23,524 Epoch[8] Batch [140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.140736,	
2017-07-28 16:29:29,352 Epoch[8] Batch [150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141748,	
2017-07-28 16:29:35,156 Epoch[8] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142163,	
2017-07-28 16:29:40,943 Epoch[8] Batch [170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.143285,	
2017-07-28 16:29:46,735 Epoch[8] Batch [180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.142984,	
2017-07-28 16:29:52,536 Epoch[8] Batch [190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143289,	
2017-07-28 16:29:58,298 Epoch[8] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.144049,	
2017-07-28 16:30:04,128 Epoch[8] Batch [210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.144081,	
2017-07-28 16:30:09,866 Epoch[8] Batch [220]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.144166,	
2017-07-28 16:30:15,708 Epoch[8] Batch [230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.143860,	
2017-07-28 16:30:21,554 Epoch[8] Batch [240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.144366,	
2017-07-28 16:30:27,348 Epoch[8] Batch [250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.144443,	
2017-07-28 16:30:33,158 Epoch[8] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.145126,	
2017-07-28 16:30:38,984 Epoch[8] Batch [270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.145879,	
2017-07-28 16:30:44,794 Epoch[8] Batch [280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.145896,	
2017-07-28 16:30:50,609 Epoch[8] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.145379,	
2017-07-28 16:30:56,399 Epoch[8] Batch [300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.144978,	
2017-07-28 16:31:02,216 Epoch[8] Batch [310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.144587,	
2017-07-28 16:31:08,021 Epoch[8] Batch [320]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.144534,	
2017-07-28 16:31:13,843 Epoch[8] Batch [330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.145017,	
2017-07-28 16:31:19,660 Epoch[8] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.145061,	
2017-07-28 16:31:25,495 Epoch[8] Batch [350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.145218,	
2017-07-28 16:31:31,304 Epoch[8] Batch [360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.145592,	
2017-07-28 16:31:37,097 Epoch[8] Batch [370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.145392,	
2017-07-28 16:31:42,872 Epoch[8] Batch [380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.145263,	
2017-07-28 16:31:48,742 Epoch[8] Batch [390]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.145730,	
2017-07-28 16:31:54,583 Epoch[8] Batch [400]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.145709,	
2017-07-28 16:32:00,387 Epoch[8] Batch [410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.145953,	
2017-07-28 16:32:06,241 Epoch[8] Batch [420]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.145698,	
2017-07-28 16:32:12,035 Epoch[8] Batch [430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.145187,	
2017-07-28 16:32:17,855 Epoch[8] Batch [440]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.144922,	
2017-07-28 16:32:23,692 Epoch[8] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.145086,	
2017-07-28 16:32:29,490 Epoch[8] Batch [460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.144972,	
2017-07-28 16:32:35,314 Epoch[8] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.145336,	
2017-07-28 16:32:41,145 Epoch[8] Batch [480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.145447,	
2017-07-28 16:32:46,948 Epoch[8] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.145414,	
2017-07-28 16:32:52,785 Epoch[8] Batch [500]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.145264,	
2017-07-28 16:32:58,638 Epoch[8] Batch [510]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.145011,	
2017-07-28 16:33:04,425 Epoch[8] Batch [520]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.144885,	
2017-07-28 16:33:10,247 Epoch[8] Batch [530]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.144675,	
2017-07-28 16:33:16,084 Epoch[8] Batch [540]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.144568,	
2017-07-28 16:33:21,890 Epoch[8] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.144364,	
2017-07-28 16:33:27,688 Epoch[8] Batch [560]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.144571,	
2017-07-28 16:33:33,276 Epoch[8] Batch [570]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.144196,	
2017-07-28 16:33:39,079 Epoch[8] Batch [580]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.144025,	
2017-07-28 16:33:44,968 Epoch[8] Batch [590]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.144024,	
2017-07-28 16:33:50,740 Epoch[8] Batch [600]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.144476,	
2017-07-28 16:33:56,565 Epoch[8] Batch [610]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.144644,	
2017-07-28 16:34:02,121 Epoch[8] Batch [620]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.144612,	
2017-07-28 16:34:06,427 Epoch[8] Batch [630]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.144534,	
2017-07-28 16:34:12,061 Epoch[8] Batch [640]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.144406,	
2017-07-28 16:34:17,944 Epoch[8] Batch [650]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.144477,	
2017-07-28 16:34:23,770 Epoch[8] Batch [660]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.144231,	
2017-07-28 16:34:29,603 Epoch[8] Batch [670]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.144122,	
2017-07-28 16:34:35,439 Epoch[8] Batch [680]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.144268,	
2017-07-28 16:34:41,249 Epoch[8] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.144095,	
2017-07-28 16:34:47,097 Epoch[8] Batch [700]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.143891,	
2017-07-28 16:34:52,920 Epoch[8] Batch [710]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143544,	
2017-07-28 16:34:58,746 Epoch[8] Batch [720]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143545,	
2017-07-28 16:35:04,558 Epoch[8] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143237,	
2017-07-28 16:35:10,396 Epoch[8] Batch [740]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.143291,	
2017-07-28 16:35:16,210 Epoch[8] Batch [750]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143119,	
2017-07-28 16:35:22,009 Epoch[8] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143219,	
2017-07-28 16:35:27,847 Epoch[8] Batch [770]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.143326,	
2017-07-28 16:35:33,662 Epoch[8] Batch [780]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143425,	
2017-07-28 16:35:39,496 Epoch[8] Batch [790]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.143487,	
2017-07-28 16:35:45,323 Epoch[8] Batch [800]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143765,	
2017-07-28 16:35:51,200 Epoch[8] Batch [810]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.143769,	
2017-07-28 16:35:58,464 Epoch[8] Batch [820]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.143856,	
2017-07-28 16:36:04,438 Epoch[8] Batch [830]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.143784,	
2017-07-28 16:36:11,913 Epoch[8] Batch [840]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.143686,	
2017-07-28 16:36:21,653 Epoch[8] Batch [850]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.143653,	
2017-07-28 16:36:31,485 Epoch[8] Batch [860]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144016,	
2017-07-28 16:36:41,401 Epoch[8] Batch [870]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.144181,	
2017-07-28 16:36:50,374 Epoch[8] Batch [880]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.144286,	
2017-07-28 16:36:58,506 Epoch[8] Batch [890]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.144296,	
2017-07-28 16:37:08,452 Epoch[8] Batch [900]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.144135,	
2017-07-28 16:37:18,104 Epoch[8] Batch [910]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.144019,	
2017-07-28 16:37:27,935 Epoch[8] Batch [920]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144018,	
2017-07-28 16:37:37,712 Epoch[8] Batch [930]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.144123,	
2017-07-28 16:37:47,739 Epoch[8] Batch [940]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.144132,	
2017-07-28 16:37:57,251 Epoch[8] Batch [950]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.144343,	
2017-07-28 16:38:07,067 Epoch[8] Batch [960]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144142,	
2017-07-28 16:38:16,863 Epoch[8] Batch [970]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144142,	
2017-07-28 16:38:26,625 Epoch[8] Batch [980]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.144186,	
2017-07-28 16:38:36,446 Epoch[8] Batch [990]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144230,	
2017-07-28 16:38:46,240 Epoch[8] Batch [1000]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144181,	
2017-07-28 16:38:56,066 Epoch[8] Batch [1010]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144254,	
2017-07-28 16:39:05,832 Epoch[8] Batch [1020]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.144549,	
2017-07-28 16:39:14,486 Epoch[8] Batch [1030]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.144552,	
2017-07-28 16:39:23,457 Epoch[8] Batch [1040]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.144543,	
2017-07-28 16:39:33,241 Epoch[8] Batch [1050]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.144453,	
2017-07-28 16:39:43,004 Epoch[8] Batch [1060]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.144515,	
2017-07-28 16:39:52,844 Epoch[8] Batch [1070]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144511,	
2017-07-28 16:40:02,638 Epoch[8] Batch [1080]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144534,	
2017-07-28 16:40:12,453 Epoch[8] Batch [1090]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144548,	
2017-07-28 16:40:22,252 Epoch[8] Batch [1100]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144579,	
2017-07-28 16:40:32,060 Epoch[8] Batch [1110]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144506,	
2017-07-28 16:40:41,868 Epoch[8] Batch [1120]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144455,	
2017-07-28 16:40:51,693 Epoch[8] Batch [1130]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144363,	
2017-07-28 16:41:01,517 Epoch[8] Batch [1140]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144258,	
2017-07-28 16:41:11,305 Epoch[8] Batch [1150]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.144198,	
2017-07-28 16:41:21,107 Epoch[8] Batch [1160]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.143981,	
2017-07-28 16:41:30,951 Epoch[8] Batch [1170]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.144203,	
2017-07-28 16:41:40,731 Epoch[8] Batch [1180]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.144248,	
2017-07-28 16:41:50,540 Epoch[8] Batch [1190]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144231,	
2017-07-28 16:41:59,954 Epoch[8] Batch [1200]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.144336,	
2017-07-28 16:42:09,792 Epoch[8] Batch [1210]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.144323,	
2017-07-28 16:42:19,592 Epoch[8] Batch [1220]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.144172,	
2017-07-28 16:42:28,631 Epoch[8] Batch [1230]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.144073,	
2017-07-28 16:42:38,714 Epoch[8] Batch [1240]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.144124,	
2017-07-28 16:42:48,466 Epoch[8] Batch [1250]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.143937,	
2017-07-28 16:42:58,316 Epoch[8] Batch [1260]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.143880,	
2017-07-28 16:43:08,137 Epoch[8] Batch [1270]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.143723,	
2017-07-28 16:43:17,967 Epoch[8] Batch [1280]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.143592,	
2017-07-28 16:43:27,776 Epoch[8] Batch [1290]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.143410,	
2017-07-28 16:43:37,544 Epoch[8] Batch [1300]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.143402,	
2017-07-28 16:43:47,439 Epoch[8] Batch [1310]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.143350,	
2017-07-28 16:43:57,288 Epoch[8] Batch [1320]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.143411,	
2017-07-28 16:44:06,966 Epoch[8] Batch [1330]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.143349,	
2017-07-28 16:44:16,705 Epoch[8] Batch [1340]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.143305,	
2017-07-28 16:44:26,144 Epoch[8] Batch [1350]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.143347,	
2017-07-28 16:44:31,943 Epoch[8] Batch [1360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143358,	
2017-07-28 16:44:37,749 Epoch[8] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.143543,	
2017-07-28 16:44:43,611 Epoch[8] Batch [1380]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.143721,	
2017-07-28 16:44:49,453 Epoch[8] Batch [1390]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.143759,	
2017-07-28 16:44:55,288 Epoch[8] Batch [1400]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.143690,	
2017-07-28 16:45:01,113 Epoch[8] Batch [1410]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143618,	
2017-07-28 16:45:06,939 Epoch[8] Batch [1420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143665,	
2017-07-28 16:45:12,762 Epoch[8] Batch [1430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143724,	
2017-07-28 16:45:18,574 Epoch[8] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143816,	
2017-07-28 16:45:24,405 Epoch[8] Batch [1450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.143701,	
2017-07-28 16:45:30,218 Epoch[8] Batch [1460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143641,	
2017-07-28 16:45:36,073 Epoch[8] Batch [1470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.143756,	
2017-07-28 16:45:41,884 Epoch[8] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143802,	
2017-07-28 16:45:45,343 Epoch[8] Train-FCNLogLoss=0.143750
2017-07-28 16:45:45,344 Epoch[8] Time cost=1063.748
2017-07-28 16:45:47,478 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.params"
2017-07-28 16:45:52,193 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.states"
2017-07-28 16:45:58,771 Epoch[9] Batch [10]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123833,	
2017-07-28 16:46:04,592 Epoch[9] Batch [20]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.131560,	
2017-07-28 16:46:10,429 Epoch[9] Batch [30]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.135557,	
2017-07-28 16:46:16,226 Epoch[9] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.132388,	
2017-07-28 16:46:22,087 Epoch[9] Batch [50]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.132621,	
2017-07-28 16:46:27,854 Epoch[9] Batch [60]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.134714,	
2017-07-28 16:46:33,675 Epoch[9] Batch [70]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.132799,	
2017-07-28 16:46:39,502 Epoch[9] Batch [80]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.134577,	
2017-07-28 16:46:45,336 Epoch[9] Batch [90]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135347,	
2017-07-28 16:46:51,130 Epoch[9] Batch [100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.136186,	
2017-07-28 16:46:56,984 Epoch[9] Batch [110]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.138085,	
2017-07-28 16:47:02,773 Epoch[9] Batch [120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.137406,	
2017-07-28 16:47:08,640 Epoch[9] Batch [130]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.137104,	
2017-07-28 16:47:14,471 Epoch[9] Batch [140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.138852,	
2017-07-28 16:47:20,215 Epoch[9] Batch [150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.139003,	
2017-07-28 16:47:25,784 Epoch[9] Batch [160]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.140096,	
2017-07-28 16:47:31,653 Epoch[9] Batch [170]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.141037,	
2017-07-28 16:47:37,445 Epoch[9] Batch [180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.141964,	
2017-07-28 16:47:43,255 Epoch[9] Batch [190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142850,	
2017-07-28 16:47:49,103 Epoch[9] Batch [200]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142849,	
2017-07-28 16:47:54,884 Epoch[9] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.143437,	
2017-07-28 16:48:00,703 Epoch[9] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142900,	
2017-07-28 16:48:06,518 Epoch[9] Batch [230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143519,	
2017-07-28 16:48:12,366 Epoch[9] Batch [240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.143410,	
2017-07-28 16:48:18,078 Epoch[9] Batch [250]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.142920,	
2017-07-28 16:48:23,900 Epoch[9] Batch [260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143002,	
2017-07-28 16:48:29,686 Epoch[9] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.142796,	
2017-07-28 16:48:35,361 Epoch[9] Batch [280]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.142999,	
2017-07-28 16:48:41,158 Epoch[9] Batch [290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143325,	
2017-07-28 16:48:46,916 Epoch[9] Batch [300]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.143129,	
2017-07-28 16:48:52,771 Epoch[9] Batch [310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.142411,	
2017-07-28 16:48:58,621 Epoch[9] Batch [320]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142349,	
2017-07-28 16:49:04,257 Epoch[9] Batch [330]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.141903,	
2017-07-28 16:49:10,105 Epoch[9] Batch [340]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.141737,	
2017-07-28 16:49:15,955 Epoch[9] Batch [350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.141712,	
2017-07-28 16:49:21,803 Epoch[9] Batch [360]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.141713,	
2017-07-28 16:49:27,628 Epoch[9] Batch [370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141333,	
2017-07-28 16:49:33,482 Epoch[9] Batch [380]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.141025,	
2017-07-28 16:49:39,305 Epoch[9] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140746,	
2017-07-28 16:49:45,115 Epoch[9] Batch [400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.140730,	
2017-07-28 16:49:50,931 Epoch[9] Batch [410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.140761,	
2017-07-28 16:49:56,723 Epoch[9] Batch [420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.140766,	
2017-07-28 16:50:02,584 Epoch[9] Batch [430]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.140618,	
2017-07-28 16:50:08,397 Epoch[9] Batch [440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141182,	
2017-07-28 16:50:14,039 Epoch[9] Batch [450]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.141488,	
2017-07-28 16:50:19,616 Epoch[9] Batch [460]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.141346,	
2017-07-28 16:50:25,445 Epoch[9] Batch [470]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141088,	
2017-07-28 16:50:31,285 Epoch[9] Batch [480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141146,	
2017-07-28 16:50:37,070 Epoch[9] Batch [490]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.140953,	
2017-07-28 16:50:42,942 Epoch[9] Batch [500]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.140942,	
2017-07-28 16:50:48,538 Epoch[9] Batch [510]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.140685,	
2017-07-28 16:50:54,045 Epoch[9] Batch [520]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.140997,	
2017-07-28 16:50:59,888 Epoch[9] Batch [530]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.140453,	
2017-07-28 16:51:05,755 Epoch[9] Batch [540]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.140344,	
2017-07-28 16:51:11,622 Epoch[9] Batch [550]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.140046,	
2017-07-28 16:51:17,464 Epoch[9] Batch [560]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.140140,	
2017-07-28 16:51:23,343 Epoch[9] Batch [570]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.140095,	
2017-07-28 16:51:29,118 Epoch[9] Batch [580]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.139825,	
2017-07-28 16:51:34,961 Epoch[9] Batch [590]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.140060,	
2017-07-28 16:51:40,811 Epoch[9] Batch [600]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.140187,	
2017-07-28 16:51:46,660 Epoch[9] Batch [610]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.140319,	
2017-07-28 16:51:52,464 Epoch[9] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.140141,	
2017-07-28 16:51:57,282 Epoch[9] Batch [630]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.140020,	
2017-07-28 16:52:01,991 Epoch[9] Batch [640]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.139702,	
2017-07-28 16:52:07,816 Epoch[9] Batch [650]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.139772,	
2017-07-28 16:52:13,675 Epoch[9] Batch [660]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.139428,	
2017-07-28 16:52:19,496 Epoch[9] Batch [670]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.139390,	
2017-07-28 16:52:25,293 Epoch[9] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.139362,	
2017-07-28 16:52:31,167 Epoch[9] Batch [690]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.139119,	
2017-07-28 16:52:36,968 Epoch[9] Batch [700]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.139117,	
2017-07-28 16:52:42,787 Epoch[9] Batch [710]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.139039,	
2017-07-28 16:52:48,655 Epoch[9] Batch [720]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.139212,	
2017-07-28 16:52:54,510 Epoch[9] Batch [730]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.140106,	
2017-07-28 16:53:00,216 Epoch[9] Batch [740]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.140229,	
2017-07-28 16:53:05,983 Epoch[9] Batch [750]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.140419,	
2017-07-28 16:53:11,894 Epoch[9] Batch [760]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.141018,	
2017-07-28 16:53:18,675 Epoch[9] Batch [770]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.141014,	
2017-07-28 16:53:24,551 Epoch[9] Batch [780]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.141141,	
2017-07-28 16:53:30,433 Epoch[9] Batch [790]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.141408,	
2017-07-28 16:53:36,299 Epoch[9] Batch [800]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.141601,	
2017-07-28 16:53:42,126 Epoch[9] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141793,	
2017-07-28 16:53:47,957 Epoch[9] Batch [820]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142019,	
2017-07-28 16:53:53,774 Epoch[9] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141754,	
2017-07-28 16:53:59,615 Epoch[9] Batch [840]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141626,	
2017-07-28 16:54:05,418 Epoch[9] Batch [850]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141580,	
2017-07-28 16:54:11,246 Epoch[9] Batch [860]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141629,	
2017-07-28 16:54:17,079 Epoch[9] Batch [870]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141609,	
2017-07-28 16:54:22,895 Epoch[9] Batch [880]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141450,	
2017-07-28 16:54:28,701 Epoch[9] Batch [890]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141537,	
2017-07-28 16:54:34,513 Epoch[9] Batch [900]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141644,	
2017-07-28 16:54:40,370 Epoch[9] Batch [910]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.141683,	
2017-07-28 16:54:46,213 Epoch[9] Batch [920]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141679,	
2017-07-28 16:54:51,980 Epoch[9] Batch [930]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.141884,	
2017-07-28 16:54:57,825 Epoch[9] Batch [940]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142038,	
2017-07-28 16:55:03,632 Epoch[9] Batch [950]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141873,	
2017-07-28 16:55:09,458 Epoch[9] Batch [960]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141663,	
2017-07-28 16:55:15,272 Epoch[9] Batch [970]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141651,	
2017-07-28 16:55:21,020 Epoch[9] Batch [980]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.141567,	
2017-07-28 16:55:26,882 Epoch[9] Batch [990]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.141439,	
2017-07-28 16:55:32,702 Epoch[9] Batch [1000]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141383,	
2017-07-28 16:55:38,528 Epoch[9] Batch [1010]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141546,	
2017-07-28 16:55:44,378 Epoch[9] Batch [1020]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.141669,	
2017-07-28 16:55:50,196 Epoch[9] Batch [1030]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141734,	
2017-07-28 16:55:55,983 Epoch[9] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.141685,	
2017-07-28 16:56:01,792 Epoch[9] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141633,	
2017-07-28 16:56:07,610 Epoch[9] Batch [1060]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141550,	
2017-07-28 16:56:13,407 Epoch[9] Batch [1070]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141510,	
2017-07-28 16:56:19,221 Epoch[9] Batch [1080]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141456,	
2017-07-28 16:56:25,061 Epoch[9] Batch [1090]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141405,	
2017-07-28 16:56:30,878 Epoch[9] Batch [1100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141350,	
2017-07-28 16:56:36,687 Epoch[9] Batch [1110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141237,	
2017-07-28 16:56:42,529 Epoch[9] Batch [1120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141370,	
2017-07-28 16:56:48,361 Epoch[9] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141514,	
2017-07-28 16:56:54,136 Epoch[9] Batch [1140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.141554,	
2017-07-28 16:56:59,983 Epoch[9] Batch [1150]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.141611,	
2017-07-28 16:57:05,498 Epoch[9] Batch [1160]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.141626,	
2017-07-28 16:57:11,167 Epoch[9] Batch [1170]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.141812,	
2017-07-28 16:57:17,001 Epoch[9] Batch [1180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141718,	
2017-07-28 16:57:22,847 Epoch[9] Batch [1190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.141734,	
2017-07-28 16:57:28,631 Epoch[9] Batch [1200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.141762,	
2017-07-28 16:57:34,441 Epoch[9] Batch [1210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141626,	
2017-07-28 16:57:40,268 Epoch[9] Batch [1220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141773,	
2017-07-28 16:57:46,094 Epoch[9] Batch [1230]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141750,	
2017-07-28 16:57:51,916 Epoch[9] Batch [1240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141858,	
2017-07-28 16:57:57,733 Epoch[9] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141797,	
2017-07-28 16:58:03,577 Epoch[9] Batch [1260]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141923,	
2017-07-28 16:58:09,374 Epoch[9] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141951,	
2017-07-28 16:58:15,179 Epoch[9] Batch [1280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142045,	
2017-07-28 16:58:21,011 Epoch[9] Batch [1290]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142047,	
2017-07-28 16:58:26,859 Epoch[9] Batch [1300]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142155,	
2017-07-28 16:58:32,657 Epoch[9] Batch [1310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142452,	
2017-07-28 16:58:38,492 Epoch[9] Batch [1320]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142642,	
2017-07-28 16:58:44,303 Epoch[9] Batch [1330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142666,	
2017-07-28 16:58:50,117 Epoch[9] Batch [1340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142756,	
2017-07-28 16:58:55,962 Epoch[9] Batch [1350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142681,	
2017-07-28 16:59:01,767 Epoch[9] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142799,	
2017-07-28 16:59:07,614 Epoch[9] Batch [1370]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142863,	
2017-07-28 16:59:13,459 Epoch[9] Batch [1380]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142800,	
2017-07-28 16:59:19,276 Epoch[9] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142851,	
2017-07-28 16:59:25,099 Epoch[9] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142736,	
2017-07-28 16:59:30,911 Epoch[9] Batch [1410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142621,	
2017-07-28 16:59:36,764 Epoch[9] Batch [1420]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.142525,	
2017-07-28 16:59:42,577 Epoch[9] Batch [1430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142436,	
2017-07-28 16:59:48,418 Epoch[9] Batch [1440]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142382,	
2017-07-28 16:59:54,265 Epoch[9] Batch [1450]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142275,	
2017-07-28 17:00:00,101 Epoch[9] Batch [1460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142418,	
2017-07-28 17:00:05,948 Epoch[9] Batch [1470]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142377,	
2017-07-28 17:00:11,755 Epoch[9] Batch [1480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142337,	
2017-07-28 17:00:15,246 Epoch[9] Train-FCNLogLoss=0.142274
2017-07-28 17:00:15,246 Epoch[9] Time cost=863.052
2017-07-28 17:00:17,027 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.params"
2017-07-28 17:00:21,670 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.states"
2017-07-28 17:00:28,339 Epoch[10] Batch [10]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142972,	
2017-07-28 17:00:34,086 Epoch[10] Batch [20]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.138161,	
2017-07-28 17:00:39,731 Epoch[10] Batch [30]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.140095,	
2017-07-28 17:00:45,499 Epoch[10] Batch [40]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.138642,	
2017-07-28 17:00:51,140 Epoch[10] Batch [50]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.136043,	
2017-07-28 17:00:56,946 Epoch[10] Batch [60]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.136305,	
2017-07-28 17:01:02,703 Epoch[10] Batch [70]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.134594,	
2017-07-28 17:01:08,620 Epoch[10] Batch [80]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.134661,	
2017-07-28 17:01:13,436 Epoch[10] Batch [90]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.135338,	
2017-07-28 17:01:19,179 Epoch[10] Batch [100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.134702,	
2017-07-28 17:01:25,036 Epoch[10] Batch [110]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.135658,	
2017-07-28 17:01:30,862 Epoch[10] Batch [120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135728,	
2017-07-28 17:01:36,505 Epoch[10] Batch [130]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.136763,	
2017-07-28 17:01:42,324 Epoch[10] Batch [140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135702,	
2017-07-28 17:01:48,152 Epoch[10] Batch [150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135640,	
2017-07-28 17:01:54,007 Epoch[10] Batch [160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.135434,	
2017-07-28 17:01:59,836 Epoch[10] Batch [170]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135203,	
2017-07-28 17:02:05,646 Epoch[10] Batch [180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135435,	
2017-07-28 17:02:11,496 Epoch[10] Batch [190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.135054,	
2017-07-28 17:02:17,341 Epoch[10] Batch [200]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.134792,	
2017-07-28 17:02:23,179 Epoch[10] Batch [210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.134269,	
2017-07-28 17:02:28,968 Epoch[10] Batch [220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.135717,	
2017-07-28 17:02:34,787 Epoch[10] Batch [230]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135025,	
2017-07-28 17:02:40,608 Epoch[10] Batch [240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135440,	
2017-07-28 17:02:46,418 Epoch[10] Batch [250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135656,	
2017-07-28 17:02:52,242 Epoch[10] Batch [260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.134883,	
2017-07-28 17:02:58,056 Epoch[10] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135114,	
2017-07-28 17:03:03,858 Epoch[10] Batch [280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135361,	
2017-07-28 17:03:09,716 Epoch[10] Batch [290]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.134977,	
2017-07-28 17:03:15,519 Epoch[10] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135078,	
2017-07-28 17:03:21,343 Epoch[10] Batch [310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.134876,	
2017-07-28 17:03:27,177 Epoch[10] Batch [320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.134485,	
2017-07-28 17:03:33,006 Epoch[10] Batch [330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.134007,	
2017-07-28 17:03:38,822 Epoch[10] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.134131,	
2017-07-28 17:03:44,650 Epoch[10] Batch [350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.133760,	
2017-07-28 17:03:50,480 Epoch[10] Batch [360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.134532,	
2017-07-28 17:03:56,300 Epoch[10] Batch [370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.134583,	
2017-07-28 17:04:02,115 Epoch[10] Batch [380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.134895,	
2017-07-28 17:04:07,934 Epoch[10] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135025,	
2017-07-28 17:04:13,762 Epoch[10] Batch [400]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.134824,	
2017-07-28 17:04:19,534 Epoch[10] Batch [410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.134719,	
2017-07-28 17:04:25,409 Epoch[10] Batch [420]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.134408,	
2017-07-28 17:04:31,197 Epoch[10] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.134520,	
2017-07-28 17:04:36,983 Epoch[10] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.134322,	
2017-07-28 17:04:42,874 Epoch[10] Batch [450]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.134362,	
2017-07-28 17:04:48,718 Epoch[10] Batch [460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.134439,	
2017-07-28 17:04:54,473 Epoch[10] Batch [470]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.134973,	
2017-07-28 17:05:00,353 Epoch[10] Batch [480]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.135152,	
2017-07-28 17:05:05,920 Epoch[10] Batch [490]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.135081,	
2017-07-28 17:05:11,726 Epoch[10] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135256,	
2017-07-28 17:05:17,577 Epoch[10] Batch [510]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.135080,	
2017-07-28 17:05:23,391 Epoch[10] Batch [520]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135065,	
2017-07-28 17:05:29,215 Epoch[10] Batch [530]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135025,	
2017-07-28 17:05:35,016 Epoch[10] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135056,	
2017-07-28 17:05:40,844 Epoch[10] Batch [550]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135243,	
2017-07-28 17:05:46,654 Epoch[10] Batch [560]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135182,	
2017-07-28 17:05:52,451 Epoch[10] Batch [570]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135446,	
2017-07-28 17:05:58,269 Epoch[10] Batch [580]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135658,	
2017-07-28 17:06:04,088 Epoch[10] Batch [590]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135766,	
2017-07-28 17:06:09,888 Epoch[10] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.136336,	
2017-07-28 17:06:15,731 Epoch[10] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.136242,	
2017-07-28 17:06:21,609 Epoch[10] Batch [620]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.136565,	
2017-07-28 17:06:27,374 Epoch[10] Batch [630]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.136525,	
2017-07-28 17:06:33,191 Epoch[10] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136531,	
2017-07-28 17:06:37,523 Epoch[10] Batch [650]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.136526,	
2017-07-28 17:06:42,805 Epoch[10] Batch [660]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.136708,	
2017-07-28 17:06:48,595 Epoch[10] Batch [670]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.136711,	
2017-07-28 17:06:54,401 Epoch[10] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.136634,	
2017-07-28 17:07:00,230 Epoch[10] Batch [690]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.136933,	
2017-07-28 17:07:06,031 Epoch[10] Batch [700]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.136792,	
2017-07-28 17:07:11,846 Epoch[10] Batch [710]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136771,	
2017-07-28 17:07:17,612 Epoch[10] Batch [720]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.136630,	
2017-07-28 17:07:23,457 Epoch[10] Batch [730]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.136298,	
2017-07-28 17:07:29,221 Epoch[10] Batch [740]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.136378,	
2017-07-28 17:07:35,019 Epoch[10] Batch [750]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.136455,	
2017-07-28 17:07:40,840 Epoch[10] Batch [760]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136495,	
2017-07-28 17:07:46,663 Epoch[10] Batch [770]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136375,	
2017-07-28 17:07:52,503 Epoch[10] Batch [780]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.136332,	
2017-07-28 17:07:58,262 Epoch[10] Batch [790]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.136190,	
2017-07-28 17:08:04,076 Epoch[10] Batch [800]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136277,	
2017-07-28 17:08:09,888 Epoch[10] Batch [810]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136195,	
2017-07-28 17:08:15,708 Epoch[10] Batch [820]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136222,	
2017-07-28 17:08:21,490 Epoch[10] Batch [830]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.136346,	
2017-07-28 17:08:27,326 Epoch[10] Batch [840]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.136204,	
2017-07-28 17:08:33,147 Epoch[10] Batch [850]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136245,	
2017-07-28 17:08:38,943 Epoch[10] Batch [860]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.136134,	
2017-07-28 17:08:44,760 Epoch[10] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135833,	
2017-07-28 17:08:50,522 Epoch[10] Batch [880]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.135673,	
2017-07-28 17:08:56,365 Epoch[10] Batch [890]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.135488,	
2017-07-28 17:09:02,195 Epoch[10] Batch [900]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135714,	
2017-07-28 17:09:08,012 Epoch[10] Batch [910]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135766,	
2017-07-28 17:09:13,826 Epoch[10] Batch [920]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135765,	
2017-07-28 17:09:19,626 Epoch[10] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135956,	
2017-07-28 17:09:25,387 Epoch[10] Batch [940]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.136058,	
2017-07-28 17:09:31,218 Epoch[10] Batch [950]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.136077,	
2017-07-28 17:09:37,046 Epoch[10] Batch [960]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.136123,	
2017-07-28 17:09:42,832 Epoch[10] Batch [970]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.136281,	
2017-07-28 17:09:48,643 Epoch[10] Batch [980]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136218,	
2017-07-28 17:09:54,451 Epoch[10] Batch [990]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.136453,	
2017-07-28 17:10:00,273 Epoch[10] Batch [1000]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136412,	
2017-07-28 17:10:06,083 Epoch[10] Batch [1010]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.136302,	
2017-07-28 17:10:11,865 Epoch[10] Batch [1020]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.136299,	
2017-07-28 17:10:17,682 Epoch[10] Batch [1030]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136270,	
2017-07-28 17:10:23,468 Epoch[10] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.136120,	
2017-07-28 17:10:29,278 Epoch[10] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.136074,	
2017-07-28 17:10:35,118 Epoch[10] Batch [1060]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.136128,	
2017-07-28 17:10:40,861 Epoch[10] Batch [1070]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.136373,	
2017-07-28 17:10:46,253 Epoch[10] Batch [1080]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.136326,	
2017-07-28 17:10:52,062 Epoch[10] Batch [1090]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.136242,	
2017-07-28 17:10:57,878 Epoch[10] Batch [1100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136246,	
2017-07-28 17:11:03,728 Epoch[10] Batch [1110]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.136215,	
2017-07-28 17:11:09,518 Epoch[10] Batch [1120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.136176,	
2017-07-28 17:11:15,345 Epoch[10] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.136102,	
2017-07-28 17:11:21,090 Epoch[10] Batch [1140]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.136012,	
2017-07-28 17:11:26,649 Epoch[10] Batch [1150]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.135974,	
2017-07-28 17:11:32,501 Epoch[10] Batch [1160]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.135788,	
2017-07-28 17:11:38,354 Epoch[10] Batch [1170]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.135724,	
2017-07-28 17:11:44,178 Epoch[10] Batch [1180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135759,	
2017-07-28 17:11:49,957 Epoch[10] Batch [1190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.135695,	
2017-07-28 17:11:55,686 Epoch[10] Batch [1200]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.135701,	
2017-07-28 17:12:01,280 Epoch[10] Batch [1210]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.135544,	
2017-07-28 17:12:07,041 Epoch[10] Batch [1220]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.135434,	
2017-07-28 17:12:12,826 Epoch[10] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.135375,	
2017-07-28 17:12:18,625 Epoch[10] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135267,	
2017-07-28 17:12:24,440 Epoch[10] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135252,	
2017-07-28 17:12:30,223 Epoch[10] Batch [1260]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.135266,	
2017-07-28 17:12:36,046 Epoch[10] Batch [1270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135193,	
2017-07-28 17:12:41,903 Epoch[10] Batch [1280]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.135123,	
2017-07-28 17:12:47,714 Epoch[10] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135053,	
2017-07-28 17:12:53,514 Epoch[10] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135100,	
2017-07-28 17:12:59,227 Epoch[10] Batch [1310]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.135072,	
2017-07-28 17:13:05,022 Epoch[10] Batch [1320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135018,	
2017-07-28 17:13:10,931 Epoch[10] Batch [1330]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.134970,	
2017-07-28 17:13:16,718 Epoch[10] Batch [1340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.134952,	
2017-07-28 17:13:22,544 Epoch[10] Batch [1350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135170,	
2017-07-28 17:13:28,370 Epoch[10] Batch [1360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135172,	
2017-07-28 17:13:34,173 Epoch[10] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135060,	
2017-07-28 17:13:39,988 Epoch[10] Batch [1380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135090,	
2017-07-28 17:13:45,779 Epoch[10] Batch [1390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.135192,	
2017-07-28 17:13:51,575 Epoch[10] Batch [1400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135299,	
2017-07-28 17:13:57,361 Epoch[10] Batch [1410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.135228,	
2017-07-28 17:14:03,163 Epoch[10] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135206,	
2017-07-28 17:14:08,974 Epoch[10] Batch [1430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135158,	
2017-07-28 17:14:14,771 Epoch[10] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135122,	
2017-07-28 17:14:20,582 Epoch[10] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.135143,	
2017-07-28 17:14:26,388 Epoch[10] Batch [1460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135216,	
2017-07-28 17:14:32,188 Epoch[10] Batch [1470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135161,	
2017-07-28 17:14:38,017 Epoch[10] Batch [1480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135166,	
2017-07-28 17:14:41,495 Epoch[10] Train-FCNLogLoss=0.135242
2017-07-28 17:14:41,496 Epoch[10] Time cost=859.825
2017-07-28 17:14:43,588 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.params"
2017-07-28 17:14:47,866 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.states"
2017-07-28 17:14:54,511 Epoch[11] Batch [10]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.140787,	
2017-07-28 17:15:00,320 Epoch[11] Batch [20]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.173441,	
2017-07-28 17:15:06,135 Epoch[11] Batch [30]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164075,	
2017-07-28 17:15:11,967 Epoch[11] Batch [40]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.161021,	
2017-07-28 17:15:17,750 Epoch[11] Batch [50]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.162026,	
2017-07-28 17:15:23,608 Epoch[11] Batch [60]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.156629,	
2017-07-28 17:15:29,423 Epoch[11] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151953,	
2017-07-28 17:15:35,217 Epoch[11] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.151206,	
2017-07-28 17:15:40,986 Epoch[11] Batch [90]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.148698,	
2017-07-28 17:15:46,805 Epoch[11] Batch [100]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.147573,	
2017-07-28 17:15:52,622 Epoch[11] Batch [110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.145560,	
2017-07-28 17:15:58,434 Epoch[11] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143644,	
2017-07-28 17:16:04,235 Epoch[11] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141463,	
2017-07-28 17:16:10,063 Epoch[11] Batch [140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.140908,	
2017-07-28 17:16:15,871 Epoch[11] Batch [150]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.140377,	
2017-07-28 17:16:21,705 Epoch[11] Batch [160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.139255,	
2017-07-28 17:16:27,500 Epoch[11] Batch [170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.138808,	
2017-07-28 17:16:33,197 Epoch[11] Batch [180]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.138687,	
2017-07-28 17:16:39,030 Epoch[11] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.137702,	
2017-07-28 17:16:44,879 Epoch[11] Batch [200]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.137892,	
2017-07-28 17:16:50,787 Epoch[11] Batch [210]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.138469,	
2017-07-28 17:16:56,591 Epoch[11] Batch [220]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.139594,	
2017-07-28 17:17:02,193 Epoch[11] Batch [230]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.139838,	
2017-07-28 17:17:07,903 Epoch[11] Batch [240]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.138168,	
2017-07-28 17:17:13,093 Epoch[11] Batch [250]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.138397,	
2017-07-28 17:17:18,890 Epoch[11] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.138394,	
2017-07-28 17:17:24,685 Epoch[11] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.138071,	
2017-07-28 17:17:30,553 Epoch[11] Batch [280]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.137259,	
2017-07-28 17:17:36,332 Epoch[11] Batch [290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.137555,	
2017-07-28 17:17:42,108 Epoch[11] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.137518,	
2017-07-28 17:17:47,944 Epoch[11] Batch [310]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.137265,	
2017-07-28 17:17:53,762 Epoch[11] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136745,	
2017-07-28 17:17:59,582 Epoch[11] Batch [330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136374,	
2017-07-28 17:18:05,431 Epoch[11] Batch [340]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.136128,	
2017-07-28 17:18:11,251 Epoch[11] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135886,	
2017-07-28 17:18:17,045 Epoch[11] Batch [360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.135973,	
2017-07-28 17:18:22,819 Epoch[11] Batch [370]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.135860,	
2017-07-28 17:18:28,089 Epoch[11] Batch [380]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.135700,	
2017-07-28 17:18:33,922 Epoch[11] Batch [390]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135532,	
2017-07-28 17:18:39,744 Epoch[11] Batch [400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135534,	
2017-07-28 17:18:46,478 Epoch[11] Batch [410]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.135118,	
2017-07-28 17:18:52,062 Epoch[11] Batch [420]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.134987,	
2017-07-28 17:18:57,097 Epoch[11] Batch [430]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.134739,	
2017-07-28 17:19:04,481 Epoch[11] Batch [440]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.134279,	
2017-07-28 17:19:09,869 Epoch[11] Batch [450]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.133820,	
2017-07-28 17:19:15,840 Epoch[11] Batch [460]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.133947,	
2017-07-28 17:19:21,828 Epoch[11] Batch [470]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.133886,	
2017-07-28 17:19:26,497 Epoch[11] Batch [480]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.133730,	
2017-07-28 17:19:30,897 Epoch[11] Batch [490]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.133301,	
2017-07-28 17:19:36,365 Epoch[11] Batch [500]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.133256,	
2017-07-28 17:19:41,748 Epoch[11] Batch [510]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.132955,	
2017-07-28 17:19:46,736 Epoch[11] Batch [520]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.132721,	
2017-07-28 17:19:51,749 Epoch[11] Batch [530]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.132330,	
2017-07-28 17:19:55,813 Epoch[11] Batch [540]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.132387,	
2017-07-28 17:20:01,858 Epoch[11] Batch [550]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.132415,	
2017-07-28 17:20:07,115 Epoch[11] Batch [560]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.132394,	
2017-07-28 17:20:11,598 Epoch[11] Batch [570]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.132306,	
2017-07-28 17:20:19,043 Epoch[11] Batch [580]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.132145,	
2017-07-28 17:20:23,814 Epoch[11] Batch [590]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.131984,	
2017-07-28 17:20:29,615 Epoch[11] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131723,	
2017-07-28 17:20:35,847 Epoch[11] Batch [610]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.131418,	
2017-07-28 17:20:41,535 Epoch[11] Batch [620]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.131256,	
2017-07-28 17:20:46,176 Epoch[11] Batch [630]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.131119,	
2017-07-28 17:20:53,536 Epoch[11] Batch [640]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.131375,	
2017-07-28 17:20:58,476 Epoch[11] Batch [650]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.131317,	
2017-07-28 17:21:02,618 Epoch[11] Batch [660]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.131336,	
2017-07-28 17:21:10,075 Epoch[11] Batch [670]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.131377,	
2017-07-28 17:21:15,193 Epoch[11] Batch [680]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.131135,	
2017-07-28 17:21:20,241 Epoch[11] Batch [690]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.131125,	
2017-07-28 17:21:25,231 Epoch[11] Batch [700]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.131170,	
2017-07-28 17:21:31,059 Epoch[11] Batch [710]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.131157,	
2017-07-28 17:21:36,044 Epoch[11] Batch [720]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.131191,	
2017-07-28 17:21:43,253 Epoch[11] Batch [730]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.131047,	
2017-07-28 17:21:49,388 Epoch[11] Batch [740]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.131261,	
2017-07-28 17:21:55,248 Epoch[11] Batch [750]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.131509,	
2017-07-28 17:22:00,203 Epoch[11] Batch [760]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.131581,	
2017-07-28 17:22:08,322 Epoch[11] Batch [770]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.131298,	
2017-07-28 17:22:13,158 Epoch[11] Batch [780]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.131303,	
2017-07-28 17:22:20,585 Epoch[11] Batch [790]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.131336,	
2017-07-28 17:22:26,332 Epoch[11] Batch [800]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.131517,	
2017-07-28 17:22:32,486 Epoch[11] Batch [810]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.131522,	
2017-07-28 17:22:39,901 Epoch[11] Batch [820]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.131541,	
2017-07-28 17:22:45,585 Epoch[11] Batch [830]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.131419,	
2017-07-28 17:22:50,278 Epoch[11] Batch [840]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.131350,	
2017-07-28 17:22:54,504 Epoch[11] Batch [850]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.131195,	
2017-07-28 17:23:01,885 Epoch[11] Batch [860]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.131409,	
2017-07-28 17:23:07,651 Epoch[11] Batch [870]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.131207,	
2017-07-28 17:23:12,905 Epoch[11] Batch [880]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.131188,	
2017-07-28 17:23:17,277 Epoch[11] Batch [890]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.131034,	
2017-07-28 17:23:22,832 Epoch[11] Batch [900]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.131135,	
2017-07-28 17:23:29,060 Epoch[11] Batch [910]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.131168,	
2017-07-28 17:23:34,828 Epoch[11] Batch [920]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.131402,	
2017-07-28 17:23:42,302 Epoch[11] Batch [930]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.131200,	
2017-07-28 17:23:47,797 Epoch[11] Batch [940]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.131172,	
2017-07-28 17:23:52,601 Epoch[11] Batch [950]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.131167,	
2017-07-28 17:23:58,437 Epoch[11] Batch [960]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.131245,	
2017-07-28 17:24:03,824 Epoch[11] Batch [970]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.131118,	
2017-07-28 17:24:09,040 Epoch[11] Batch [980]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.131354,	
2017-07-28 17:24:14,015 Epoch[11] Batch [990]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.131290,	
2017-07-28 17:24:18,076 Epoch[11] Batch [1000]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.131148,	
2017-07-28 17:24:23,340 Epoch[11] Batch [1010]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.131164,	
2017-07-28 17:24:29,716 Epoch[11] Batch [1020]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.131201,	
2017-07-28 17:24:35,394 Epoch[11] Batch [1030]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.131266,	
2017-07-28 17:24:41,171 Epoch[11] Batch [1040]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.131213,	
2017-07-28 17:24:48,037 Epoch[11] Batch [1050]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.131311,	
2017-07-28 17:24:53,021 Epoch[11] Batch [1060]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.131338,	
2017-07-28 17:24:59,087 Epoch[11] Batch [1070]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.131294,	
2017-07-28 17:25:04,644 Epoch[11] Batch [1080]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.131297,	
2017-07-28 17:25:09,873 Epoch[11] Batch [1090]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.131215,	
2017-07-28 17:25:15,865 Epoch[11] Batch [1100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.131132,	
2017-07-28 17:25:23,600 Epoch[11] Batch [1110]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.131036,	
2017-07-28 17:25:30,403 Epoch[11] Batch [1120]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.130974,	
2017-07-28 17:25:35,924 Epoch[11] Batch [1130]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.130966,	
2017-07-28 17:25:42,626 Epoch[11] Batch [1140]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.130779,	
2017-07-28 17:25:48,477 Epoch[11] Batch [1150]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.130588,	
2017-07-28 17:25:55,472 Epoch[11] Batch [1160]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.130650,	
2017-07-28 17:26:01,723 Epoch[11] Batch [1170]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.130819,	
2017-07-28 17:26:07,765 Epoch[11] Batch [1180]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.130718,	
2017-07-28 17:26:14,169 Epoch[11] Batch [1190]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.130726,	
2017-07-28 17:26:20,599 Epoch[11] Batch [1200]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.130742,	
2017-07-28 17:26:27,743 Epoch[11] Batch [1210]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.130759,	
2017-07-28 17:26:32,644 Epoch[11] Batch [1220]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.130766,	
2017-07-28 17:26:37,804 Epoch[11] Batch [1230]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.130664,	
2017-07-28 17:26:44,377 Epoch[11] Batch [1240]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.130621,	
2017-07-28 17:26:49,615 Epoch[11] Batch [1250]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.130550,	
2017-07-28 17:26:54,933 Epoch[11] Batch [1260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130720,	
2017-07-28 17:27:00,440 Epoch[11] Batch [1270]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.130796,	
2017-07-28 17:27:05,899 Epoch[11] Batch [1280]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.130772,	
2017-07-28 17:27:11,428 Epoch[11] Batch [1290]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.130790,	
2017-07-28 17:27:17,258 Epoch[11] Batch [1300]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.130827,	
2017-07-28 17:27:22,869 Epoch[11] Batch [1310]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.130869,	
2017-07-28 17:27:28,563 Epoch[11] Batch [1320]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.130814,	
2017-07-28 17:27:34,250 Epoch[11] Batch [1330]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.130904,	
2017-07-28 17:27:39,816 Epoch[11] Batch [1340]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.131003,	
2017-07-28 17:27:45,676 Epoch[11] Batch [1350]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.130990,	
2017-07-28 17:27:51,251 Epoch[11] Batch [1360]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.131023,	
2017-07-28 17:27:56,849 Epoch[11] Batch [1370]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.131117,	
2017-07-28 17:28:02,479 Epoch[11] Batch [1380]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.131295,	
2017-07-28 17:28:08,069 Epoch[11] Batch [1390]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.131361,	
2017-07-28 17:28:13,661 Epoch[11] Batch [1400]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.131240,	
2017-07-28 17:28:19,214 Epoch[11] Batch [1410]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.131270,	
2017-07-28 17:28:24,799 Epoch[11] Batch [1420]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.131233,	
2017-07-28 17:28:30,413 Epoch[11] Batch [1430]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.131421,	
2017-07-28 17:28:36,213 Epoch[11] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131585,	
2017-07-28 17:28:42,019 Epoch[11] Batch [1450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.131667,	
2017-07-28 17:28:47,875 Epoch[11] Batch [1460]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.131598,	
2017-07-28 17:28:53,484 Epoch[11] Batch [1470]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.131633,	
2017-07-28 17:28:59,220 Epoch[11] Batch [1480]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.131655,	
2017-07-28 17:29:02,485 Epoch[11] Train-FCNLogLoss=0.131650
2017-07-28 17:29:02,485 Epoch[11] Time cost=854.618
2017-07-28 17:29:04,160 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.params"
2017-07-28 17:29:08,807 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.states"
2017-07-28 17:29:15,624 Epoch[12] Batch [10]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.127317,	
2017-07-28 17:29:20,965 Epoch[12] Batch [20]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125116,	
2017-07-28 17:29:26,570 Epoch[12] Batch [30]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.125750,	
2017-07-28 17:29:32,061 Epoch[12] Batch [40]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.125806,	
2017-07-28 17:29:37,469 Epoch[12] Batch [50]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.124332,	
2017-07-28 17:29:42,940 Epoch[12] Batch [60]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.124501,	
2017-07-28 17:29:48,314 Epoch[12] Batch [70]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.124740,	
2017-07-28 17:29:53,734 Epoch[12] Batch [80]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.124130,	
2017-07-28 17:29:59,070 Epoch[12] Batch [90]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126585,	
2017-07-28 17:30:04,783 Epoch[12] Batch [100]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.125805,	
2017-07-28 17:30:10,252 Epoch[12] Batch [110]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.125354,	
2017-07-28 17:30:15,723 Epoch[12] Batch [120]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.125286,	
2017-07-28 17:30:21,106 Epoch[12] Batch [130]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125658,	
2017-07-28 17:30:26,547 Epoch[12] Batch [140]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.125639,	
2017-07-28 17:30:32,477 Epoch[12] Batch [150]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.125647,	
2017-07-28 17:30:38,442 Epoch[12] Batch [160]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.125692,	
2017-07-28 17:30:44,078 Epoch[12] Batch [170]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.126773,	
2017-07-28 17:30:49,745 Epoch[12] Batch [180]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.126787,	
2017-07-28 17:30:55,622 Epoch[12] Batch [190]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.127166,	
2017-07-28 17:31:01,553 Epoch[12] Batch [200]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.127272,	
2017-07-28 17:31:07,273 Epoch[12] Batch [210]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.128285,	
2017-07-28 17:31:13,284 Epoch[12] Batch [220]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.127947,	
2017-07-28 17:31:18,639 Epoch[12] Batch [230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.126973,	
2017-07-28 17:31:24,005 Epoch[12] Batch [240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126216,	
2017-07-28 17:31:29,608 Epoch[12] Batch [250]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.126073,	
2017-07-28 17:31:35,090 Epoch[12] Batch [260]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.125687,	
2017-07-28 17:31:40,469 Epoch[12] Batch [270]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125437,	
2017-07-28 17:31:46,032 Epoch[12] Batch [280]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.125330,	
2017-07-28 17:31:51,824 Epoch[12] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.126945,	
2017-07-28 17:31:57,488 Epoch[12] Batch [300]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.127445,	
2017-07-28 17:32:02,818 Epoch[12] Batch [310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.127970,	
2017-07-28 17:32:08,711 Epoch[12] Batch [320]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.127953,	
2017-07-28 17:32:14,584 Epoch[12] Batch [330]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.127859,	
2017-07-28 17:32:20,110 Epoch[12] Batch [340]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128028,	
2017-07-28 17:32:25,811 Epoch[12] Batch [350]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.128112,	
2017-07-28 17:32:31,463 Epoch[12] Batch [360]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.128110,	
2017-07-28 17:32:37,071 Epoch[12] Batch [370]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.128107,	
2017-07-28 17:32:43,016 Epoch[12] Batch [380]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.128047,	
2017-07-28 17:32:48,721 Epoch[12] Batch [390]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.127791,	
2017-07-28 17:32:54,724 Epoch[12] Batch [400]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.127701,	
2017-07-28 17:33:00,272 Epoch[12] Batch [410]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.127718,	
2017-07-28 17:33:05,877 Epoch[12] Batch [420]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.127399,	
2017-07-28 17:33:11,397 Epoch[12] Batch [430]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.127210,	
2017-07-28 17:33:17,035 Epoch[12] Batch [440]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.126950,	
2017-07-28 17:33:22,653 Epoch[12] Batch [450]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.127212,	
2017-07-28 17:33:28,152 Epoch[12] Batch [460]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.127415,	
2017-07-28 17:33:33,718 Epoch[12] Batch [470]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.127267,	
2017-07-28 17:33:39,349 Epoch[12] Batch [480]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.127247,	
2017-07-28 17:33:44,648 Epoch[12] Batch [490]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.127192,	
2017-07-28 17:33:50,214 Epoch[12] Batch [500]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.127043,	
2017-07-28 17:33:55,813 Epoch[12] Batch [510]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.126916,	
2017-07-28 17:34:01,533 Epoch[12] Batch [520]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.126993,	
2017-07-28 17:34:07,200 Epoch[12] Batch [530]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.126713,	
2017-07-28 17:34:12,889 Epoch[12] Batch [540]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.126709,	
2017-07-28 17:34:18,404 Epoch[12] Batch [550]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.126776,	
2017-07-28 17:34:23,697 Epoch[12] Batch [560]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126426,	
2017-07-28 17:34:29,171 Epoch[12] Batch [570]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.126447,	
2017-07-28 17:34:34,585 Epoch[12] Batch [580]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.126351,	
2017-07-28 17:34:40,387 Epoch[12] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.126009,	
2017-07-28 17:34:45,857 Epoch[12] Batch [600]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.125799,	
2017-07-28 17:34:51,356 Epoch[12] Batch [610]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.125912,	
2017-07-28 17:34:56,997 Epoch[12] Batch [620]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.125832,	
2017-07-28 17:35:02,260 Epoch[12] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125905,	
2017-07-28 17:35:07,710 Epoch[12] Batch [640]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.125808,	
2017-07-28 17:35:13,336 Epoch[12] Batch [650]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.125852,	
2017-07-28 17:35:19,052 Epoch[12] Batch [660]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.125735,	
2017-07-28 17:35:24,868 Epoch[12] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125918,	
2017-07-28 17:35:30,423 Epoch[12] Batch [680]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.125917,	
2017-07-28 17:35:35,970 Epoch[12] Batch [690]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.125912,	
2017-07-28 17:35:41,749 Epoch[12] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.125995,	
2017-07-28 17:35:47,171 Epoch[12] Batch [710]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.125969,	
2017-07-28 17:35:52,656 Epoch[12] Batch [720]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.126348,	
2017-07-28 17:35:58,263 Epoch[12] Batch [730]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.126532,	
2017-07-28 17:36:04,018 Epoch[12] Batch [740]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.126832,	
2017-07-28 17:36:09,443 Epoch[12] Batch [750]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.126807,	
2017-07-28 17:36:15,125 Epoch[12] Batch [760]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.126958,	
2017-07-28 17:36:20,716 Epoch[12] Batch [770]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.127204,	
2017-07-28 17:36:26,414 Epoch[12] Batch [780]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.127076,	
2017-07-28 17:36:32,052 Epoch[12] Batch [790]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.127203,	
2017-07-28 17:36:37,809 Epoch[12] Batch [800]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.127008,	
2017-07-28 17:36:43,734 Epoch[12] Batch [810]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.126880,	
2017-07-28 17:36:49,482 Epoch[12] Batch [820]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.126791,	
2017-07-28 17:36:55,206 Epoch[12] Batch [830]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.126829,	
2017-07-28 17:37:00,956 Epoch[12] Batch [840]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.126853,	
2017-07-28 17:37:06,407 Epoch[12] Batch [850]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.126951,	
2017-07-28 17:37:13,656 Epoch[12] Batch [860]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.127083,	
2017-07-28 17:37:20,124 Epoch[12] Batch [870]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.127070,	
2017-07-28 17:37:25,819 Epoch[12] Batch [880]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.127277,	
2017-07-28 17:37:32,223 Epoch[12] Batch [890]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.127412,	
2017-07-28 17:37:38,432 Epoch[12] Batch [900]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.127299,	
2017-07-28 17:37:44,442 Epoch[12] Batch [910]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.127282,	
2017-07-28 17:37:50,532 Epoch[12] Batch [920]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.127294,	
2017-07-28 17:37:56,332 Epoch[12] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.127193,	
2017-07-28 17:38:03,336 Epoch[12] Batch [940]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.127300,	
2017-07-28 17:38:11,015 Epoch[12] Batch [950]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.127311,	
2017-07-28 17:38:17,332 Epoch[12] Batch [960]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.127535,	
2017-07-28 17:38:25,503 Epoch[12] Batch [970]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.127637,	
2017-07-28 17:38:30,543 Epoch[12] Batch [980]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.127599,	
2017-07-28 17:38:35,685 Epoch[12] Batch [990]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.127550,	
2017-07-28 17:38:42,490 Epoch[12] Batch [1000]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.127477,	
2017-07-28 17:38:49,380 Epoch[12] Batch [1010]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.127561,	
2017-07-28 17:38:56,008 Epoch[12] Batch [1020]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.127534,	
2017-07-28 17:39:00,967 Epoch[12] Batch [1030]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.127757,	
2017-07-28 17:39:05,878 Epoch[12] Batch [1040]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.127899,	
2017-07-28 17:39:11,937 Epoch[12] Batch [1050]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.128326,	
2017-07-28 17:39:18,572 Epoch[12] Batch [1060]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.128455,	
2017-07-28 17:39:23,055 Epoch[12] Batch [1070]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.128815,	
2017-07-28 17:39:29,348 Epoch[12] Batch [1080]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.128801,	
2017-07-28 17:39:34,796 Epoch[12] Batch [1090]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.128830,	
2017-07-28 17:39:39,866 Epoch[12] Batch [1100]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.128805,	
2017-07-28 17:39:45,697 Epoch[12] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.128837,	
2017-07-28 17:39:51,013 Epoch[12] Batch [1120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.128792,	
2017-07-28 17:39:56,194 Epoch[12] Batch [1130]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.128904,	
2017-07-28 17:40:01,328 Epoch[12] Batch [1140]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.128897,	
2017-07-28 17:40:08,259 Epoch[12] Batch [1150]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.128977,	
2017-07-28 17:40:14,307 Epoch[12] Batch [1160]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.129004,	
2017-07-28 17:40:21,607 Epoch[12] Batch [1170]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.129079,	
2017-07-28 17:40:28,748 Epoch[12] Batch [1180]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.129105,	
2017-07-28 17:40:34,845 Epoch[12] Batch [1190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.129119,	
2017-07-28 17:40:41,420 Epoch[12] Batch [1200]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.129118,	
2017-07-28 17:40:46,029 Epoch[12] Batch [1210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.129244,	
2017-07-28 17:40:54,710 Epoch[12] Batch [1220]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.129272,	
2017-07-28 17:41:03,951 Epoch[12] Batch [1230]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.129313,	
2017-07-28 17:41:11,112 Epoch[12] Batch [1240]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.129391,	
2017-07-28 17:41:15,959 Epoch[12] Batch [1250]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.129436,	
2017-07-28 17:41:24,943 Epoch[12] Batch [1260]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.129410,	
2017-07-28 17:41:33,063 Epoch[12] Batch [1270]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.129442,	
2017-07-28 17:41:38,070 Epoch[12] Batch [1280]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.129452,	
2017-07-28 17:41:45,243 Epoch[12] Batch [1290]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.129389,	
2017-07-28 17:41:52,127 Epoch[12] Batch [1300]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.129511,	
2017-07-28 17:41:59,117 Epoch[12] Batch [1310]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.129517,	
2017-07-28 17:42:05,429 Epoch[12] Batch [1320]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.129565,	
2017-07-28 17:42:13,921 Epoch[12] Batch [1330]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.129605,	
2017-07-28 17:42:23,514 Epoch[12] Batch [1340]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.129758,	
2017-07-28 17:42:32,174 Epoch[12] Batch [1350]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.129807,	
2017-07-28 17:42:38,013 Epoch[12] Batch [1360]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.129888,	
2017-07-28 17:42:46,132 Epoch[12] Batch [1370]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.129767,	
2017-07-28 17:42:51,275 Epoch[12] Batch [1380]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.129675,	
2017-07-28 17:42:57,208 Epoch[12] Batch [1390]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.129757,	
2017-07-28 17:43:02,932 Epoch[12] Batch [1400]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.129742,	
2017-07-28 17:43:09,563 Epoch[12] Batch [1410]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.129694,	
2017-07-28 17:43:15,064 Epoch[12] Batch [1420]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.129570,	
2017-07-28 17:43:20,365 Epoch[12] Batch [1430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.129570,	
2017-07-28 17:43:27,965 Epoch[12] Batch [1440]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.129531,	
2017-07-28 17:43:33,468 Epoch[12] Batch [1450]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.129515,	
2017-07-28 17:43:39,409 Epoch[12] Batch [1460]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.129445,	
2017-07-28 17:43:46,780 Epoch[12] Batch [1470]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.129437,	
2017-07-28 17:43:53,119 Epoch[12] Batch [1480]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.129517,	
2017-07-28 17:43:56,303 Epoch[12] Train-FCNLogLoss=0.129583
2017-07-28 17:43:56,303 Epoch[12] Time cost=887.496
2017-07-28 17:43:58,744 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.params"
2017-07-28 17:44:03,431 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.states"
2017-07-28 17:44:10,507 Epoch[13] Batch [10]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.141416,	
2017-07-28 17:44:17,839 Epoch[13] Batch [20]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.128844,	
2017-07-28 17:44:23,610 Epoch[13] Batch [30]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.125215,	
2017-07-28 17:44:31,009 Epoch[13] Batch [40]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.133505,	
2017-07-28 17:44:40,003 Epoch[13] Batch [50]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.129096,	
2017-07-28 17:44:47,237 Epoch[13] Batch [60]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.127108,	
2017-07-28 17:44:54,740 Epoch[13] Batch [70]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.128601,	
2017-07-28 17:45:00,718 Epoch[13] Batch [80]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.128661,	
2017-07-28 17:45:07,268 Epoch[13] Batch [90]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.129316,	
2017-07-28 17:45:15,095 Epoch[13] Batch [100]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.127603,	
2017-07-28 17:45:22,023 Epoch[13] Batch [110]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.127054,	
2017-07-28 17:45:28,805 Epoch[13] Batch [120]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.129880,	
2017-07-28 17:45:36,483 Epoch[13] Batch [130]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.129978,	
2017-07-28 17:45:44,301 Epoch[13] Batch [140]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.130522,	
2017-07-28 17:45:50,400 Epoch[13] Batch [150]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.130100,	
2017-07-28 17:45:57,379 Epoch[13] Batch [160]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.129777,	
2017-07-28 17:46:06,517 Epoch[13] Batch [170]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.129901,	
2017-07-28 17:46:13,742 Epoch[13] Batch [180]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.130972,	
2017-07-28 17:46:20,012 Epoch[13] Batch [190]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.131167,	
2017-07-28 17:46:28,041 Epoch[13] Batch [200]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.131220,	
2017-07-28 17:46:36,391 Epoch[13] Batch [210]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.131038,	
2017-07-28 17:46:43,333 Epoch[13] Batch [220]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.130292,	
2017-07-28 17:46:50,393 Epoch[13] Batch [230]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.130168,	
2017-07-28 17:46:57,763 Epoch[13] Batch [240]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.130030,	
2017-07-28 17:47:04,836 Epoch[13] Batch [250]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.129583,	
2017-07-28 17:47:12,160 Epoch[13] Batch [260]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.129139,	
2017-07-28 17:47:19,648 Epoch[13] Batch [270]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.128737,	
2017-07-28 17:47:26,325 Epoch[13] Batch [280]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.128288,	
2017-07-28 17:47:32,999 Epoch[13] Batch [290]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.127695,	
2017-07-28 17:47:39,989 Epoch[13] Batch [300]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.128059,	
2017-07-28 17:47:46,939 Epoch[13] Batch [310]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.128675,	
2017-07-28 17:47:55,678 Epoch[13] Batch [320]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.129286,	
2017-07-28 17:48:02,898 Epoch[13] Batch [330]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.129380,	
2017-07-28 17:48:10,356 Epoch[13] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.129344,	
2017-07-28 17:48:18,984 Epoch[13] Batch [350]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.129219,	
2017-07-28 17:48:25,820 Epoch[13] Batch [360]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.129635,	
2017-07-28 17:48:33,001 Epoch[13] Batch [370]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.129846,	
2017-07-28 17:48:39,747 Epoch[13] Batch [380]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.129515,	
2017-07-28 17:48:45,239 Epoch[13] Batch [390]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.129772,	
2017-07-28 17:48:53,030 Epoch[13] Batch [400]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.129169,	
2017-07-28 17:49:00,620 Epoch[13] Batch [410]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.128713,	
2017-07-28 17:49:07,918 Epoch[13] Batch [420]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.128641,	
2017-07-28 17:49:13,801 Epoch[13] Batch [430]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.128995,	
2017-07-28 17:49:21,838 Epoch[13] Batch [440]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.128575,	
2017-07-28 17:49:27,865 Epoch[13] Batch [450]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.128383,	
2017-07-28 17:49:34,808 Epoch[13] Batch [460]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.128274,	
2017-07-28 17:49:41,570 Epoch[13] Batch [470]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.128499,	
2017-07-28 17:49:49,212 Epoch[13] Batch [480]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.128326,	
2017-07-28 17:49:58,130 Epoch[13] Batch [490]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.128416,	
2017-07-28 17:50:04,965 Epoch[13] Batch [500]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.128654,	
2017-07-28 17:50:11,932 Epoch[13] Batch [510]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.128979,	
2017-07-28 17:50:18,945 Epoch[13] Batch [520]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.128795,	
2017-07-28 17:50:28,118 Epoch[13] Batch [530]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.129108,	
2017-07-28 17:50:35,289 Epoch[13] Batch [540]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.129226,	
2017-07-28 17:50:44,041 Epoch[13] Batch [550]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.129203,	
2017-07-28 17:50:53,865 Epoch[13] Batch [560]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.129218,	
2017-07-28 17:51:01,016 Epoch[13] Batch [570]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.129167,	
2017-07-28 17:51:07,527 Epoch[13] Batch [580]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.129197,	
2017-07-28 17:51:14,720 Epoch[13] Batch [590]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.129145,	
2017-07-28 17:51:20,656 Epoch[13] Batch [600]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.129013,	
2017-07-28 17:51:26,542 Epoch[13] Batch [610]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.129338,	
2017-07-28 17:51:32,539 Epoch[13] Batch [620]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.129197,	
2017-07-28 17:51:39,009 Epoch[13] Batch [630]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.129373,	
2017-07-28 17:51:45,025 Epoch[13] Batch [640]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.129410,	
2017-07-28 17:51:51,431 Epoch[13] Batch [650]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.129130,	
2017-07-28 17:51:57,314 Epoch[13] Batch [660]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.129035,	
2017-07-28 17:52:03,573 Epoch[13] Batch [670]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.128894,	
2017-07-28 17:52:09,700 Epoch[13] Batch [680]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.128724,	
2017-07-28 17:52:15,467 Epoch[13] Batch [690]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.128578,	
2017-07-28 17:52:21,612 Epoch[13] Batch [700]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.128350,	
2017-07-28 17:52:27,289 Epoch[13] Batch [710]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.128282,	
2017-07-28 17:52:32,880 Epoch[13] Batch [720]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.128105,	
2017-07-28 17:52:38,594 Epoch[13] Batch [730]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.128027,	
2017-07-28 17:52:44,712 Epoch[13] Batch [740]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.127956,	
2017-07-28 17:52:51,130 Epoch[13] Batch [750]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.127884,	
2017-07-28 17:52:57,124 Epoch[13] Batch [760]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.127779,	
2017-07-28 17:53:03,170 Epoch[13] Batch [770]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.127706,	
2017-07-28 17:53:09,085 Epoch[13] Batch [780]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.127574,	
2017-07-28 17:53:14,849 Epoch[13] Batch [790]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.127706,	
2017-07-28 17:53:20,805 Epoch[13] Batch [800]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.127686,	
2017-07-28 17:53:26,942 Epoch[13] Batch [810]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.127564,	
2017-07-28 17:53:32,801 Epoch[13] Batch [820]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.127711,	
2017-07-28 17:53:38,663 Epoch[13] Batch [830]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.127819,	
2017-07-28 17:53:44,178 Epoch[13] Batch [840]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.127783,	
2017-07-28 17:53:50,520 Epoch[13] Batch [850]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.127827,	
2017-07-28 17:53:56,338 Epoch[13] Batch [860]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.127851,	
2017-07-28 17:54:01,657 Epoch[13] Batch [870]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.127736,	
2017-07-28 17:54:07,581 Epoch[13] Batch [880]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.127491,	
2017-07-28 17:54:13,380 Epoch[13] Batch [890]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.127374,	
2017-07-28 17:54:19,589 Epoch[13] Batch [900]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.127478,	
2017-07-28 17:54:26,013 Epoch[13] Batch [910]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.127520,	
2017-07-28 17:54:31,836 Epoch[13] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.127579,	
2017-07-28 17:54:38,116 Epoch[13] Batch [930]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.127462,	
2017-07-28 17:54:44,037 Epoch[13] Batch [940]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.127321,	
2017-07-28 17:54:50,615 Epoch[13] Batch [950]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.127274,	
2017-07-28 17:54:56,866 Epoch[13] Batch [960]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.127187,	
2017-07-28 17:55:02,912 Epoch[13] Batch [970]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.127211,	
2017-07-28 17:55:09,143 Epoch[13] Batch [980]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.127243,	
2017-07-28 17:55:15,516 Epoch[13] Batch [990]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.127112,	
2017-07-28 17:55:21,434 Epoch[13] Batch [1000]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.127244,	
2017-07-28 17:55:27,412 Epoch[13] Batch [1010]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.127133,	
2017-07-28 17:55:33,415 Epoch[13] Batch [1020]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.127015,	
2017-07-28 17:55:39,360 Epoch[13] Batch [1030]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.127053,	
2017-07-28 17:55:45,251 Epoch[13] Batch [1040]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.127028,	
2017-07-28 17:55:51,171 Epoch[13] Batch [1050]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.126915,	
2017-07-28 17:55:57,105 Epoch[13] Batch [1060]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.126924,	
2017-07-28 17:56:03,671 Epoch[13] Batch [1070]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.126981,	
2017-07-28 17:56:09,566 Epoch[13] Batch [1080]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.127100,	
2017-07-28 17:56:15,709 Epoch[13] Batch [1090]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.127244,	
2017-07-28 17:56:21,651 Epoch[13] Batch [1100]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.127631,	
2017-07-28 17:56:27,523 Epoch[13] Batch [1110]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.127868,	
2017-07-28 17:56:33,764 Epoch[13] Batch [1120]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.127983,	
2017-07-28 17:56:39,778 Epoch[13] Batch [1130]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.128018,	
2017-07-28 17:56:45,724 Epoch[13] Batch [1140]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.128143,	
2017-07-28 17:56:51,625 Epoch[13] Batch [1150]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.128203,	
2017-07-28 17:56:58,061 Epoch[13] Batch [1160]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.128244,	
2017-07-28 17:57:04,208 Epoch[13] Batch [1170]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.128287,	
2017-07-28 17:57:09,938 Epoch[13] Batch [1180]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.128177,	
2017-07-28 17:57:21,637 Epoch[13] Batch [1190]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.128212,	
2017-07-28 17:57:30,201 Epoch[13] Batch [1200]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.128125,	
2017-07-28 17:57:36,747 Epoch[13] Batch [1210]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.128132,	
2017-07-28 17:57:46,164 Epoch[13] Batch [1220]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.128170,	
2017-07-28 17:57:55,330 Epoch[13] Batch [1230]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.128081,	
2017-07-28 17:58:03,119 Epoch[13] Batch [1240]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.128077,	
2017-07-28 17:58:09,600 Epoch[13] Batch [1250]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.128078,	
2017-07-28 17:58:17,175 Epoch[13] Batch [1260]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.128184,	
2017-07-28 17:58:25,110 Epoch[13] Batch [1270]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.128253,	
2017-07-28 17:58:32,389 Epoch[13] Batch [1280]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.128452,	
2017-07-28 17:58:41,001 Epoch[13] Batch [1290]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.128415,	
2017-07-28 17:58:47,204 Epoch[13] Batch [1300]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.128563,	
2017-07-28 17:58:55,196 Epoch[13] Batch [1310]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.128462,	
2017-07-28 17:59:00,720 Epoch[13] Batch [1320]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128276,	
2017-07-28 17:59:05,191 Epoch[13] Batch [1330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.128248,	
2017-07-28 17:59:12,759 Epoch[13] Batch [1340]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.128362,	
2017-07-28 17:59:19,651 Epoch[13] Batch [1350]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.128438,	
2017-07-28 17:59:25,783 Epoch[13] Batch [1360]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.128522,	
2017-07-28 17:59:32,773 Epoch[13] Batch [1370]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.128367,	
2017-07-28 17:59:40,313 Epoch[13] Batch [1380]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.128292,	
2017-07-28 17:59:46,657 Epoch[13] Batch [1390]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.128236,	
2017-07-28 17:59:54,952 Epoch[13] Batch [1400]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.128137,	
2017-07-28 18:00:00,389 Epoch[13] Batch [1410]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.128080,	
2017-07-28 18:00:05,967 Epoch[13] Batch [1420]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.128339,	
2017-07-28 18:00:13,357 Epoch[13] Batch [1430]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.128335,	
2017-07-28 18:00:21,500 Epoch[13] Batch [1440]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.128193,	
2017-07-28 18:00:29,763 Epoch[13] Batch [1450]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.128175,	
2017-07-28 18:00:35,237 Epoch[13] Batch [1460]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.128202,	
2017-07-28 18:00:40,999 Epoch[13] Batch [1470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.128231,	
2017-07-28 18:00:46,592 Epoch[13] Batch [1480]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.128269,	
2017-07-28 18:00:49,889 Epoch[13] Train-FCNLogLoss=0.128303
2017-07-28 18:00:49,889 Epoch[13] Time cost=1006.457
2017-07-28 18:00:52,235 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.params"
2017-07-28 18:00:56,954 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.states"
2017-07-28 18:01:03,451 Epoch[14] Batch [10]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.139040,	
2017-07-28 18:01:08,986 Epoch[14] Batch [20]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.129986,	
2017-07-28 18:01:14,754 Epoch[14] Batch [30]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.126253,	
2017-07-28 18:01:20,314 Epoch[14] Batch [40]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.131941,	
2017-07-28 18:01:26,027 Epoch[14] Batch [50]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.130205,	
2017-07-28 18:01:31,608 Epoch[14] Batch [60]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.128848,	
2017-07-28 18:01:37,276 Epoch[14] Batch [70]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.128121,	
2017-07-28 18:01:43,069 Epoch[14] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.129207,	
2017-07-28 18:01:48,693 Epoch[14] Batch [90]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.128488,	
2017-07-28 18:01:54,221 Epoch[14] Batch [100]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128271,	
2017-07-28 18:01:59,901 Epoch[14] Batch [110]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.129017,	
2017-07-28 18:02:05,588 Epoch[14] Batch [120]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.129124,	
2017-07-28 18:02:11,472 Epoch[14] Batch [130]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.128569,	
2017-07-28 18:02:17,007 Epoch[14] Batch [140]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.127728,	
2017-07-28 18:02:22,595 Epoch[14] Batch [150]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.127876,	
2017-07-28 18:02:28,258 Epoch[14] Batch [160]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.128059,	
2017-07-28 18:02:33,850 Epoch[14] Batch [170]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.126963,	
2017-07-28 18:02:39,788 Epoch[14] Batch [180]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.127101,	
2017-07-28 18:02:45,404 Epoch[14] Batch [190]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.127152,	
2017-07-28 18:02:51,084 Epoch[14] Batch [200]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.126790,	
2017-07-28 18:02:56,920 Epoch[14] Batch [210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.126051,	
2017-07-28 18:03:02,389 Epoch[14] Batch [220]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.125941,	
2017-07-28 18:03:07,862 Epoch[14] Batch [230]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.126662,	
2017-07-28 18:03:13,447 Epoch[14] Batch [240]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.127233,	
2017-07-28 18:03:19,049 Epoch[14] Batch [250]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.127550,	
2017-07-28 18:03:24,519 Epoch[14] Batch [260]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.126870,	
2017-07-28 18:03:29,966 Epoch[14] Batch [270]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.126701,	
2017-07-28 18:03:35,845 Epoch[14] Batch [280]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.126759,	
2017-07-28 18:03:41,596 Epoch[14] Batch [290]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.127402,	
2017-07-28 18:03:47,332 Epoch[14] Batch [300]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.127227,	
2017-07-28 18:03:53,191 Epoch[14] Batch [310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.127013,	
2017-07-28 18:03:58,987 Epoch[14] Batch [320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.127282,	
2017-07-28 18:04:04,723 Epoch[14] Batch [330]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.126939,	
2017-07-28 18:04:10,167 Epoch[14] Batch [340]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.126652,	
2017-07-28 18:04:15,674 Epoch[14] Batch [350]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.126542,	
2017-07-28 18:04:21,241 Epoch[14] Batch [360]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.126266,	
2017-07-28 18:04:26,838 Epoch[14] Batch [370]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.126267,	
2017-07-28 18:04:32,372 Epoch[14] Batch [380]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.126218,	
2017-07-28 18:04:37,954 Epoch[14] Batch [390]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.126331,	
2017-07-28 18:04:43,534 Epoch[14] Batch [400]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.126296,	
2017-07-28 18:04:49,478 Epoch[14] Batch [410]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.126482,	
2017-07-28 18:04:55,009 Epoch[14] Batch [420]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.125954,	
2017-07-28 18:05:00,516 Epoch[14] Batch [430]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.125685,	
2017-07-28 18:05:05,872 Epoch[14] Batch [440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125346,	
2017-07-28 18:05:11,450 Epoch[14] Batch [450]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.125051,	
2017-07-28 18:05:16,859 Epoch[14] Batch [460]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.124884,	
2017-07-28 18:05:22,464 Epoch[14] Batch [470]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.124851,	
2017-07-28 18:05:27,612 Epoch[14] Batch [480]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.124790,	
2017-07-28 18:05:33,298 Epoch[14] Batch [490]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.124729,	
2017-07-28 18:05:38,696 Epoch[14] Batch [500]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.124691,	
2017-07-28 18:05:44,029 Epoch[14] Batch [510]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124522,	
2017-07-28 18:05:49,225 Epoch[14] Batch [520]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.124500,	
2017-07-28 18:05:54,380 Epoch[14] Batch [530]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.124418,	
2017-07-28 18:05:59,796 Epoch[14] Batch [540]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.124607,	
2017-07-28 18:06:05,376 Epoch[14] Batch [550]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.124635,	
2017-07-28 18:06:11,281 Epoch[14] Batch [560]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.124673,	
2017-07-28 18:06:17,235 Epoch[14] Batch [570]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.124684,	
2017-07-28 18:06:22,762 Epoch[14] Batch [580]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.124753,	
2017-07-28 18:06:28,398 Epoch[14] Batch [590]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.124690,	
2017-07-28 18:06:33,778 Epoch[14] Batch [600]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.124524,	
2017-07-28 18:06:39,150 Epoch[14] Batch [610]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.124496,	
2017-07-28 18:06:44,670 Epoch[14] Batch [620]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.124377,	
2017-07-28 18:06:50,065 Epoch[14] Batch [630]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.124210,	
2017-07-28 18:06:55,665 Epoch[14] Batch [640]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.124452,	
2017-07-28 18:07:01,545 Epoch[14] Batch [650]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.124295,	
2017-07-28 18:07:07,030 Epoch[14] Batch [660]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.124521,	
2017-07-28 18:07:12,610 Epoch[14] Batch [670]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.124486,	
2017-07-28 18:07:18,099 Epoch[14] Batch [680]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.124358,	
2017-07-28 18:07:24,112 Epoch[14] Batch [690]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.124348,	
2017-07-28 18:07:29,768 Epoch[14] Batch [700]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.124166,	
2017-07-28 18:07:35,069 Epoch[14] Batch [710]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124293,	
2017-07-28 18:07:40,748 Epoch[14] Batch [720]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.124349,	
2017-07-28 18:07:46,496 Epoch[14] Batch [730]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.124409,	
2017-07-28 18:07:52,068 Epoch[14] Batch [740]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.124368,	
2017-07-28 18:07:57,310 Epoch[14] Batch [750]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.124377,	
2017-07-28 18:08:02,623 Epoch[14] Batch [760]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124242,	
2017-07-28 18:08:08,668 Epoch[14] Batch [770]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.124071,	
2017-07-28 18:08:14,903 Epoch[14] Batch [780]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.123946,	
2017-07-28 18:08:20,673 Epoch[14] Batch [790]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.123875,	
2017-07-28 18:08:26,301 Epoch[14] Batch [800]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.123882,	
2017-07-28 18:08:31,945 Epoch[14] Batch [810]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.123947,	
2017-07-28 18:08:37,328 Epoch[14] Batch [820]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.123842,	
2017-07-28 18:08:42,995 Epoch[14] Batch [830]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.123999,	
2017-07-28 18:08:48,576 Epoch[14] Batch [840]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.124218,	
2017-07-28 18:08:54,132 Epoch[14] Batch [850]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.124137,	
2017-07-28 18:08:59,714 Epoch[14] Batch [860]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.124216,	
2017-07-28 18:09:04,081 Epoch[14] Batch [870]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.124198,	
2017-07-28 18:09:09,659 Epoch[14] Batch [880]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.124192,	
2017-07-28 18:09:15,239 Epoch[14] Batch [890]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.124181,	
2017-07-28 18:09:20,649 Epoch[14] Batch [900]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.124074,	
2017-07-28 18:09:26,433 Epoch[14] Batch [910]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.123963,	
2017-07-28 18:09:32,070 Epoch[14] Batch [920]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.123967,	
2017-07-28 18:09:37,490 Epoch[14] Batch [930]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.124182,	
2017-07-28 18:09:43,197 Epoch[14] Batch [940]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.124204,	
2017-07-28 18:09:48,770 Epoch[14] Batch [950]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.124237,	
2017-07-28 18:09:54,413 Epoch[14] Batch [960]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.124210,	
2017-07-28 18:09:59,952 Epoch[14] Batch [970]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.124198,	
2017-07-28 18:10:05,381 Epoch[14] Batch [980]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.124179,	
2017-07-28 18:10:11,120 Epoch[14] Batch [990]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.124111,	
2017-07-28 18:10:17,055 Epoch[14] Batch [1000]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.124106,	
2017-07-28 18:10:22,811 Epoch[14] Batch [1010]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.123935,	
2017-07-28 18:10:28,471 Epoch[14] Batch [1020]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.124004,	
2017-07-28 18:10:33,922 Epoch[14] Batch [1030]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.124112,	
2017-07-28 18:10:39,494 Epoch[14] Batch [1040]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.124392,	
2017-07-28 18:10:44,927 Epoch[14] Batch [1050]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.124372,	
2017-07-28 18:10:50,285 Epoch[14] Batch [1060]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124485,	
2017-07-28 18:10:56,093 Epoch[14] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124380,	
2017-07-28 18:11:01,812 Epoch[14] Batch [1080]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.124419,	
2017-07-28 18:11:07,446 Epoch[14] Batch [1090]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.124482,	
2017-07-28 18:11:13,087 Epoch[14] Batch [1100]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.124499,	
2017-07-28 18:11:18,401 Epoch[14] Batch [1110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124593,	
2017-07-28 18:11:23,941 Epoch[14] Batch [1120]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.124735,	
2017-07-28 18:11:29,309 Epoch[14] Batch [1130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.124698,	
2017-07-28 18:11:34,902 Epoch[14] Batch [1140]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.124585,	
2017-07-28 18:11:40,317 Epoch[14] Batch [1150]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.124565,	
2017-07-28 18:11:45,676 Epoch[14] Batch [1160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.124385,	
2017-07-28 18:11:51,338 Epoch[14] Batch [1170]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.124273,	
2017-07-28 18:11:57,021 Epoch[14] Batch [1180]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.124175,	
2017-07-28 18:12:02,387 Epoch[14] Batch [1190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.124166,	
2017-07-28 18:12:08,200 Epoch[14] Batch [1200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124184,	
2017-07-28 18:12:13,880 Epoch[14] Batch [1210]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.124489,	
2017-07-28 18:12:19,437 Epoch[14] Batch [1220]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.124967,	
2017-07-28 18:12:25,073 Epoch[14] Batch [1230]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.125290,	
2017-07-28 18:12:30,774 Epoch[14] Batch [1240]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.125492,	
2017-07-28 18:12:36,424 Epoch[14] Batch [1250]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.125672,	
2017-07-28 18:12:42,045 Epoch[14] Batch [1260]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.125997,	
2017-07-28 18:12:47,700 Epoch[14] Batch [1270]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.126067,	
2017-07-28 18:12:53,206 Epoch[14] Batch [1280]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.126255,	
2017-07-28 18:12:58,906 Epoch[14] Batch [1290]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.126310,	
2017-07-28 18:13:04,664 Epoch[14] Batch [1300]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.126234,	
2017-07-28 18:13:10,295 Epoch[14] Batch [1310]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.126170,	
2017-07-28 18:13:15,890 Epoch[14] Batch [1320]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.126213,	
2017-07-28 18:13:21,447 Epoch[14] Batch [1330]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.126142,	
2017-07-28 18:13:26,798 Epoch[14] Batch [1340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.126212,	
2017-07-28 18:13:32,124 Epoch[14] Batch [1350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.126304,	
2017-07-28 18:13:37,722 Epoch[14] Batch [1360]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.126250,	
2017-07-28 18:13:43,331 Epoch[14] Batch [1370]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.126213,	
2017-07-28 18:13:48,718 Epoch[14] Batch [1380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.126223,	
2017-07-28 18:13:54,258 Epoch[14] Batch [1390]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.126171,	
2017-07-28 18:13:59,868 Epoch[14] Batch [1400]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.126285,	
2017-07-28 18:14:05,453 Epoch[14] Batch [1410]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.126431,	
2017-07-28 18:14:10,969 Epoch[14] Batch [1420]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.126427,	
2017-07-28 18:14:16,509 Epoch[14] Batch [1430]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.126422,	
2017-07-28 18:14:22,157 Epoch[14] Batch [1440]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.126423,	
2017-07-28 18:14:28,127 Epoch[14] Batch [1450]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.126403,	
2017-07-28 18:14:33,618 Epoch[14] Batch [1460]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.126345,	
2017-07-28 18:14:39,466 Epoch[14] Batch [1470]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.126383,	
2017-07-28 18:14:45,416 Epoch[14] Batch [1480]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.126427,	
2017-07-28 18:14:48,896 Epoch[14] Train-FCNLogLoss=0.126418
2017-07-28 18:14:48,897 Epoch[14] Time cost=831.942
2017-07-28 18:14:50,745 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.params"
2017-07-28 18:14:56,123 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.states"
2017-07-28 18:15:03,275 Epoch[15] Batch [10]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.109593,	
2017-07-28 18:15:10,347 Epoch[15] Batch [20]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.113115,	
2017-07-28 18:15:17,184 Epoch[15] Batch [30]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.120749,	
2017-07-28 18:15:23,478 Epoch[15] Batch [40]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.119287,	
2017-07-28 18:15:29,865 Epoch[15] Batch [50]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.127050,	
2017-07-28 18:15:36,848 Epoch[15] Batch [60]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.128609,	
2017-07-28 18:15:43,126 Epoch[15] Batch [70]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.126001,	
2017-07-28 18:15:49,736 Epoch[15] Batch [80]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.125264,	
2017-07-28 18:15:56,312 Epoch[15] Batch [90]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.124968,	
2017-07-28 18:16:02,655 Epoch[15] Batch [100]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.125534,	
2017-07-28 18:16:09,455 Epoch[15] Batch [110]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.126546,	
2017-07-28 18:16:15,687 Epoch[15] Batch [120]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.126617,	
2017-07-28 18:16:23,297 Epoch[15] Batch [130]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.126821,	
2017-07-28 18:16:30,172 Epoch[15] Batch [140]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.127838,	
2017-07-28 18:16:36,904 Epoch[15] Batch [150]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.127283,	
2017-07-28 18:16:42,994 Epoch[15] Batch [160]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.127373,	
2017-07-28 18:16:49,367 Epoch[15] Batch [170]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.128508,	
2017-07-28 18:16:56,908 Epoch[15] Batch [180]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.128351,	
2017-07-28 18:17:02,935 Epoch[15] Batch [190]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.127960,	
2017-07-28 18:17:09,677 Epoch[15] Batch [200]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.127424,	
2017-07-28 18:17:15,409 Epoch[15] Batch [210]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.126620,	
2017-07-28 18:17:21,791 Epoch[15] Batch [220]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.125763,	
2017-07-28 18:17:28,460 Epoch[15] Batch [230]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.125969,	
2017-07-28 18:17:34,535 Epoch[15] Batch [240]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.125399,	
2017-07-28 18:17:40,203 Epoch[15] Batch [250]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.125503,	
2017-07-28 18:17:46,005 Epoch[15] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125929,	
2017-07-28 18:17:52,447 Epoch[15] Batch [270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.126229,	
2017-07-28 18:17:58,405 Epoch[15] Batch [280]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.126377,	
2017-07-28 18:18:04,388 Epoch[15] Batch [290]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.126258,	
2017-07-28 18:18:10,353 Epoch[15] Batch [300]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.126443,	
2017-07-28 18:18:16,810 Epoch[15] Batch [310]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.126225,	
2017-07-28 18:18:22,811 Epoch[15] Batch [320]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.126018,	
2017-07-28 18:18:28,485 Epoch[15] Batch [330]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.125794,	
2017-07-28 18:18:34,261 Epoch[15] Batch [340]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.125915,	
2017-07-28 18:18:40,683 Epoch[15] Batch [350]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.125812,	
2017-07-28 18:18:46,576 Epoch[15] Batch [360]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.125403,	
2017-07-28 18:18:52,788 Epoch[15] Batch [370]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.125038,	
2017-07-28 18:18:58,528 Epoch[15] Batch [380]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.125031,	
2017-07-28 18:19:04,328 Epoch[15] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124744,	
2017-07-28 18:19:09,920 Epoch[15] Batch [400]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.124318,	
2017-07-28 18:19:15,476 Epoch[15] Batch [410]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.124326,	
2017-07-28 18:19:21,568 Epoch[15] Batch [420]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.123938,	
2017-07-28 18:19:27,503 Epoch[15] Batch [430]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.123910,	
2017-07-28 18:19:32,987 Epoch[15] Batch [440]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.123874,	
2017-07-28 18:19:41,736 Epoch[15] Batch [450]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.123305,	
2017-07-28 18:19:47,376 Epoch[15] Batch [460]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.123348,	
2017-07-28 18:19:52,817 Epoch[15] Batch [470]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.123402,	
2017-07-28 18:19:58,197 Epoch[15] Batch [480]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.123304,	
2017-07-28 18:20:04,341 Epoch[15] Batch [490]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.123244,	
2017-07-28 18:20:09,753 Epoch[15] Batch [500]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.123241,	
2017-07-28 18:20:15,480 Epoch[15] Batch [510]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.123161,	
2017-07-28 18:20:20,959 Epoch[15] Batch [520]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.122926,	
2017-07-28 18:20:26,579 Epoch[15] Batch [530]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.122868,	
2017-07-28 18:20:32,186 Epoch[15] Batch [540]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.122961,	
2017-07-28 18:20:37,616 Epoch[15] Batch [550]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.123000,	
2017-07-28 18:20:43,157 Epoch[15] Batch [560]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.123138,	
2017-07-28 18:20:48,669 Epoch[15] Batch [570]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.123003,	
2017-07-28 18:20:54,022 Epoch[15] Batch [580]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.122855,	
2017-07-28 18:20:59,305 Epoch[15] Batch [590]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.123724,	
2017-07-28 18:21:04,878 Epoch[15] Batch [600]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.125932,	
2017-07-28 18:21:10,408 Epoch[15] Batch [610]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.127960,	
2017-07-28 18:21:15,949 Epoch[15] Batch [620]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.128785,	
2017-07-28 18:21:21,797 Epoch[15] Batch [630]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.129425,	
2017-07-28 18:21:27,548 Epoch[15] Batch [640]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.132151,	
2017-07-28 18:21:33,131 Epoch[15] Batch [650]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.133798,	
2017-07-28 18:21:38,543 Epoch[15] Batch [660]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.134929,	
2017-07-28 18:21:44,163 Epoch[15] Batch [670]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.135236,	
2017-07-28 18:21:49,710 Epoch[15] Batch [680]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.135285,	
2017-07-28 18:21:55,529 Epoch[15] Batch [690]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135408,	
2017-07-28 18:22:01,311 Epoch[15] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.135457,	
2017-07-28 18:22:06,946 Epoch[15] Batch [710]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.135336,	
2017-07-28 18:22:12,480 Epoch[15] Batch [720]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.135617,	
2017-07-28 18:22:18,937 Epoch[15] Batch [730]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.135518,	
2017-07-28 18:22:26,042 Epoch[15] Batch [740]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.135519,	
2017-07-28 18:22:32,038 Epoch[15] Batch [750]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.135403,	
2017-07-28 18:22:37,812 Epoch[15] Batch [760]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.135653,	
2017-07-28 18:22:43,724 Epoch[15] Batch [770]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.135615,	
2017-07-28 18:22:49,482 Epoch[15] Batch [780]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.135576,	
2017-07-28 18:22:55,313 Epoch[15] Batch [790]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.135600,	
2017-07-28 18:23:01,084 Epoch[15] Batch [800]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.135408,	
2017-07-28 18:23:06,719 Epoch[15] Batch [810]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.135299,	
2017-07-28 18:23:12,557 Epoch[15] Batch [820]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.135323,	
2017-07-28 18:23:18,318 Epoch[15] Batch [830]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.135038,	
2017-07-28 18:23:23,829 Epoch[15] Batch [840]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.134987,	
2017-07-28 18:23:29,666 Epoch[15] Batch [850]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.134829,	
2017-07-28 18:23:35,250 Epoch[15] Batch [860]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.134728,	
2017-07-28 18:23:40,612 Epoch[15] Batch [870]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.134788,	
2017-07-28 18:23:46,157 Epoch[15] Batch [880]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.134638,	
2017-07-28 18:23:51,957 Epoch[15] Batch [890]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.134400,	
2017-07-28 18:23:57,461 Epoch[15] Batch [900]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.134422,	
2017-07-28 18:24:03,092 Epoch[15] Batch [910]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.134223,	
2017-07-28 18:24:08,570 Epoch[15] Batch [920]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.134112,	
2017-07-28 18:24:14,271 Epoch[15] Batch [930]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.133960,	
2017-07-28 18:24:20,170 Epoch[15] Batch [940]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.133847,	
2017-07-28 18:24:25,815 Epoch[15] Batch [950]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.133568,	
2017-07-28 18:24:31,564 Epoch[15] Batch [960]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.133582,	
2017-07-28 18:24:37,281 Epoch[15] Batch [970]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.133379,	
2017-07-28 18:24:43,046 Epoch[15] Batch [980]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.133246,	
2017-07-28 18:24:48,588 Epoch[15] Batch [990]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.133200,	
2017-07-28 18:24:54,232 Epoch[15] Batch [1000]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.133070,	
2017-07-28 18:25:00,013 Epoch[15] Batch [1010]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.132989,	
2017-07-28 18:25:05,550 Epoch[15] Batch [1020]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.132995,	
2017-07-28 18:25:12,573 Epoch[15] Batch [1030]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.132900,	
2017-07-28 18:25:18,288 Epoch[15] Batch [1040]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.132809,	
2017-07-28 18:25:24,091 Epoch[15] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.132889,	
2017-07-28 18:25:29,905 Epoch[15] Batch [1060]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.132890,	
2017-07-28 18:25:35,324 Epoch[15] Batch [1070]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.132957,	
2017-07-28 18:25:39,611 Epoch[15] Batch [1080]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.132996,	
2017-07-28 18:25:45,345 Epoch[15] Batch [1090]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.132937,	
2017-07-28 18:25:50,826 Epoch[15] Batch [1100]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.132819,	
2017-07-28 18:25:56,384 Epoch[15] Batch [1110]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.132673,	
2017-07-28 18:26:02,178 Epoch[15] Batch [1120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.132577,	
2017-07-28 18:26:08,971 Epoch[15] Batch [1130]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.132527,	
2017-07-28 18:26:15,595 Epoch[15] Batch [1140]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.132418,	
2017-07-28 18:26:21,100 Epoch[15] Batch [1150]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.132416,	
2017-07-28 18:26:26,282 Epoch[15] Batch [1160]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.132421,	
2017-07-28 18:26:31,418 Epoch[15] Batch [1170]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.132313,	
2017-07-28 18:26:37,220 Epoch[15] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.132097,	
2017-07-28 18:26:43,008 Epoch[15] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.132095,	
2017-07-28 18:26:48,764 Epoch[15] Batch [1200]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.131886,	
2017-07-28 18:26:54,594 Epoch[15] Batch [1210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.131846,	
2017-07-28 18:27:00,436 Epoch[15] Batch [1220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.131804,	
2017-07-28 18:27:06,225 Epoch[15] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.131705,	
2017-07-28 18:27:12,227 Epoch[15] Batch [1240]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.131683,	
2017-07-28 18:27:18,034 Epoch[15] Batch [1250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.131582,	
2017-07-28 18:27:23,803 Epoch[15] Batch [1260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.131490,	
2017-07-28 18:27:29,184 Epoch[15] Batch [1270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.131474,	
2017-07-28 18:27:34,984 Epoch[15] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131413,	
2017-07-28 18:27:40,782 Epoch[15] Batch [1290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131479,	
2017-07-28 18:27:46,597 Epoch[15] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.131432,	
2017-07-28 18:27:52,413 Epoch[15] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.131656,	
2017-07-28 18:27:58,474 Epoch[15] Batch [1320]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.131582,	
2017-07-28 18:28:04,592 Epoch[15] Batch [1330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.131613,	
2017-07-28 18:28:10,389 Epoch[15] Batch [1340]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131447,	
2017-07-28 18:28:16,188 Epoch[15] Batch [1350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131498,	
2017-07-28 18:28:21,990 Epoch[15] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.131311,	
2017-07-28 18:28:27,794 Epoch[15] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.131268,	
2017-07-28 18:28:33,632 Epoch[15] Batch [1380]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.131166,	
2017-07-28 18:28:39,431 Epoch[15] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131091,	
2017-07-28 18:28:45,238 Epoch[15] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.131125,	
2017-07-28 18:28:51,049 Epoch[15] Batch [1410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.131032,	
2017-07-28 18:28:56,833 Epoch[15] Batch [1420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.130951,	
2017-07-28 18:29:02,621 Epoch[15] Batch [1430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.130966,	
2017-07-28 18:29:08,434 Epoch[15] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.130892,	
2017-07-28 18:29:14,456 Epoch[15] Batch [1450]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.130807,	
2017-07-28 18:29:20,252 Epoch[15] Batch [1460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.130773,	
2017-07-28 18:29:26,015 Epoch[15] Batch [1470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.130690,	
2017-07-28 18:29:31,806 Epoch[15] Batch [1480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.130679,	
2017-07-28 18:29:35,299 Epoch[15] Train-FCNLogLoss=0.130671
2017-07-28 18:29:35,299 Epoch[15] Time cost=879.175
2017-07-28 18:29:37,264 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.params"
2017-07-28 18:29:40,976 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.states"
2017-07-28 18:29:47,588 Epoch[16] Batch [10]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.139210,	
2017-07-28 18:29:53,387 Epoch[16] Batch [20]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.134147,	
2017-07-28 18:29:59,204 Epoch[16] Batch [30]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.130152,	
2017-07-28 18:30:05,013 Epoch[16] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.131954,	
2017-07-28 18:30:10,832 Epoch[16] Batch [50]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.126439,	
2017-07-28 18:30:16,636 Epoch[16] Batch [60]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.128337,	
2017-07-28 18:30:22,405 Epoch[16] Batch [70]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.130167,	
2017-07-28 18:30:28,253 Epoch[16] Batch [80]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.128549,	
2017-07-28 18:30:34,012 Epoch[16] Batch [90]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.129986,	
2017-07-28 18:30:39,854 Epoch[16] Batch [100]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.128848,	
2017-07-28 18:30:45,643 Epoch[16] Batch [110]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.127927,	
2017-07-28 18:30:51,450 Epoch[16] Batch [120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.127099,	
2017-07-28 18:30:57,254 Epoch[16] Batch [130]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.127717,	
2017-07-28 18:31:03,073 Epoch[16] Batch [140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.126332,	
2017-07-28 18:31:08,891 Epoch[16] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.126589,	
2017-07-28 18:31:14,683 Epoch[16] Batch [160]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.126367,	
2017-07-28 18:31:20,489 Epoch[16] Batch [170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.126075,	
2017-07-28 18:31:26,284 Epoch[16] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.126079,	
2017-07-28 18:31:32,098 Epoch[16] Batch [190]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125282,	
2017-07-28 18:31:37,895 Epoch[16] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125131,	
2017-07-28 18:31:43,720 Epoch[16] Batch [210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.125446,	
2017-07-28 18:31:49,531 Epoch[16] Batch [220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125220,	
2017-07-28 18:31:55,334 Epoch[16] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125780,	
2017-07-28 18:32:01,125 Epoch[16] Batch [240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125934,	
2017-07-28 18:32:06,927 Epoch[16] Batch [250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125558,	
2017-07-28 18:32:12,753 Epoch[16] Batch [260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.125269,	
2017-07-28 18:32:18,581 Epoch[16] Batch [270]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.124559,	
2017-07-28 18:32:24,593 Epoch[16] Batch [280]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.124471,	
2017-07-28 18:32:30,372 Epoch[16] Batch [290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.125475,	
2017-07-28 18:32:36,239 Epoch[16] Batch [300]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.125271,	
2017-07-28 18:32:42,033 Epoch[16] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125613,	
2017-07-28 18:32:47,843 Epoch[16] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125438,	
2017-07-28 18:32:53,658 Epoch[16] Batch [330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125017,	
2017-07-28 18:32:59,470 Epoch[16] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124880,	
2017-07-28 18:33:05,262 Epoch[16] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124697,	
2017-07-28 18:33:11,064 Epoch[16] Batch [360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124398,	
2017-07-28 18:33:16,861 Epoch[16] Batch [370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124591,	
2017-07-28 18:33:22,656 Epoch[16] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124482,	
2017-07-28 18:33:28,482 Epoch[16] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124358,	
2017-07-28 18:33:34,273 Epoch[16] Batch [400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124180,	
2017-07-28 18:33:40,111 Epoch[16] Batch [410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123836,	
2017-07-28 18:33:45,905 Epoch[16] Batch [420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123912,	
2017-07-28 18:33:51,658 Epoch[16] Batch [430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.123572,	
2017-07-28 18:33:57,488 Epoch[16] Batch [440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123406,	
2017-07-28 18:34:03,263 Epoch[16] Batch [450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.123075,	
2017-07-28 18:34:09,076 Epoch[16] Batch [460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122972,	
2017-07-28 18:34:14,871 Epoch[16] Batch [470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122881,	
2017-07-28 18:34:20,682 Epoch[16] Batch [480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122980,	
2017-07-28 18:34:26,457 Epoch[16] Batch [490]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.122686,	
2017-07-28 18:34:32,282 Epoch[16] Batch [500]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122612,	
2017-07-28 18:34:38,058 Epoch[16] Batch [510]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.122733,	
2017-07-28 18:34:43,877 Epoch[16] Batch [520]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.123069,	
2017-07-28 18:34:49,712 Epoch[16] Batch [530]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123103,	
2017-07-28 18:34:55,489 Epoch[16] Batch [540]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.123070,	
2017-07-28 18:35:01,315 Epoch[16] Batch [550]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122923,	
2017-07-28 18:35:07,084 Epoch[16] Batch [560]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.122784,	
2017-07-28 18:35:12,913 Epoch[16] Batch [570]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122732,	
2017-07-28 18:35:18,682 Epoch[16] Batch [580]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.122817,	
2017-07-28 18:35:24,501 Epoch[16] Batch [590]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122675,	
2017-07-28 18:35:30,308 Epoch[16] Batch [600]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122660,	
2017-07-28 18:35:36,106 Epoch[16] Batch [610]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122631,	
2017-07-28 18:35:41,926 Epoch[16] Batch [620]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122706,	
2017-07-28 18:35:47,717 Epoch[16] Batch [630]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.122584,	
2017-07-28 18:35:53,491 Epoch[16] Batch [640]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.122517,	
2017-07-28 18:35:59,284 Epoch[16] Batch [650]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122283,	
2017-07-28 18:36:05,083 Epoch[16] Batch [660]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122156,	
2017-07-28 18:36:10,881 Epoch[16] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121880,	
2017-07-28 18:36:16,685 Epoch[16] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121662,	
2017-07-28 18:36:22,495 Epoch[16] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121705,	
2017-07-28 18:36:28,309 Epoch[16] Batch [700]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121784,	
2017-07-28 18:36:34,112 Epoch[16] Batch [710]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121650,	
2017-07-28 18:36:39,900 Epoch[16] Batch [720]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121766,	
2017-07-28 18:36:45,708 Epoch[16] Batch [730]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121664,	
2017-07-28 18:36:51,526 Epoch[16] Batch [740]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121472,	
2017-07-28 18:36:57,505 Epoch[16] Batch [750]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.121581,	
2017-07-28 18:37:03,306 Epoch[16] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121483,	
2017-07-28 18:37:09,115 Epoch[16] Batch [770]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121532,	
2017-07-28 18:37:14,947 Epoch[16] Batch [780]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121382,	
2017-07-28 18:37:20,763 Epoch[16] Batch [790]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121382,	
2017-07-28 18:37:26,546 Epoch[16] Batch [800]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121395,	
2017-07-28 18:37:32,330 Epoch[16] Batch [810]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121253,	
2017-07-28 18:37:38,145 Epoch[16] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121170,	
2017-07-28 18:37:43,922 Epoch[16] Batch [830]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121400,	
2017-07-28 18:37:49,761 Epoch[16] Batch [840]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.121317,	
2017-07-28 18:37:55,520 Epoch[16] Batch [850]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121348,	
2017-07-28 18:38:01,322 Epoch[16] Batch [860]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121362,	
2017-07-28 18:38:07,142 Epoch[16] Batch [870]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121442,	
2017-07-28 18:38:12,940 Epoch[16] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121615,	
2017-07-28 18:38:18,760 Epoch[16] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121637,	
2017-07-28 18:38:24,559 Epoch[16] Batch [900]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121499,	
2017-07-28 18:38:30,362 Epoch[16] Batch [910]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121570,	
2017-07-28 18:38:36,174 Epoch[16] Batch [920]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121584,	
2017-07-28 18:38:41,952 Epoch[16] Batch [930]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121633,	
2017-07-28 18:38:47,754 Epoch[16] Batch [940]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121781,	
2017-07-28 18:38:53,551 Epoch[16] Batch [950]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121790,	
2017-07-28 18:38:59,353 Epoch[16] Batch [960]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121972,	
2017-07-28 18:39:05,176 Epoch[16] Batch [970]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121991,	
2017-07-28 18:39:10,955 Epoch[16] Batch [980]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.122015,	
2017-07-28 18:39:16,771 Epoch[16] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122006,	
2017-07-28 18:39:22,575 Epoch[16] Batch [1000]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121942,	
2017-07-28 18:39:28,396 Epoch[16] Batch [1010]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121955,	
2017-07-28 18:39:34,394 Epoch[16] Batch [1020]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.121900,	
2017-07-28 18:39:40,223 Epoch[16] Batch [1030]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121844,	
2017-07-28 18:39:46,026 Epoch[16] Batch [1040]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121740,	
2017-07-28 18:39:51,793 Epoch[16] Batch [1050]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.121677,	
2017-07-28 18:39:57,622 Epoch[16] Batch [1060]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121683,	
2017-07-28 18:40:03,413 Epoch[16] Batch [1070]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121599,	
2017-07-28 18:40:08,438 Epoch[16] Batch [1080]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.121467,	
2017-07-28 18:40:12,436 Epoch[16] Batch [1090]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.121436,	
2017-07-28 18:40:18,220 Epoch[16] Batch [1100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121503,	
2017-07-28 18:40:23,994 Epoch[16] Batch [1110]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121510,	
2017-07-28 18:40:29,854 Epoch[16] Batch [1120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121375,	
2017-07-28 18:40:35,627 Epoch[16] Batch [1130]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121309,	
2017-07-28 18:40:41,430 Epoch[16] Batch [1140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121380,	
2017-07-28 18:40:47,254 Epoch[16] Batch [1150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121382,	
2017-07-28 18:40:53,110 Epoch[16] Batch [1160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121325,	
2017-07-28 18:40:58,908 Epoch[16] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121259,	
2017-07-28 18:41:04,644 Epoch[16] Batch [1180]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.121280,	
2017-07-28 18:41:10,451 Epoch[16] Batch [1190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121276,	
2017-07-28 18:41:16,232 Epoch[16] Batch [1200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121214,	
2017-07-28 18:41:22,026 Epoch[16] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121256,	
2017-07-28 18:41:27,818 Epoch[16] Batch [1220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121209,	
2017-07-28 18:41:33,628 Epoch[16] Batch [1230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121392,	
2017-07-28 18:41:39,420 Epoch[16] Batch [1240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121458,	
2017-07-28 18:41:45,260 Epoch[16] Batch [1250]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.121287,	
2017-07-28 18:41:51,053 Epoch[16] Batch [1260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121163,	
2017-07-28 18:41:56,849 Epoch[16] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121152,	
2017-07-28 18:42:02,643 Epoch[16] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121021,	
2017-07-28 18:42:08,429 Epoch[16] Batch [1290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120945,	
2017-07-28 18:42:14,241 Epoch[16] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120841,	
2017-07-28 18:42:20,060 Epoch[16] Batch [1310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.120879,	
2017-07-28 18:42:25,882 Epoch[16] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.120788,	
2017-07-28 18:42:31,672 Epoch[16] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120764,	
2017-07-28 18:42:37,436 Epoch[16] Batch [1340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.120763,	
2017-07-28 18:42:43,243 Epoch[16] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120612,	
2017-07-28 18:42:49,067 Epoch[16] Batch [1360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.120577,	
2017-07-28 18:42:54,862 Epoch[16] Batch [1370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120506,	
2017-07-28 18:43:00,634 Epoch[16] Batch [1380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120506,	
2017-07-28 18:43:06,435 Epoch[16] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120491,	
2017-07-28 18:43:12,273 Epoch[16] Batch [1400]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.120400,	
2017-07-28 18:43:18,050 Epoch[16] Batch [1410]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.120332,	
2017-07-28 18:43:23,872 Epoch[16] Batch [1420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.120418,	
2017-07-28 18:43:29,676 Epoch[16] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120420,	
2017-07-28 18:43:35,488 Epoch[16] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120411,	
2017-07-28 18:43:41,256 Epoch[16] Batch [1450]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.120455,	
2017-07-28 18:43:47,054 Epoch[16] Batch [1460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120418,	
2017-07-28 18:43:52,855 Epoch[16] Batch [1470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120468,	
2017-07-28 18:43:58,646 Epoch[16] Batch [1480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120500,	
2017-07-28 18:44:02,150 Epoch[16] Train-FCNLogLoss=0.120451
2017-07-28 18:44:02,150 Epoch[16] Time cost=861.173
2017-07-28 18:44:03,665 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.params"
2017-07-28 18:44:08,067 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.states"
2017-07-28 18:44:14,571 Epoch[17] Batch [10]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117665,	
2017-07-28 18:44:20,363 Epoch[17] Batch [20]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110899,	
2017-07-28 18:44:26,138 Epoch[17] Batch [30]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.112966,	
2017-07-28 18:44:31,953 Epoch[17] Batch [40]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108724,	
2017-07-28 18:44:37,538 Epoch[17] Batch [50]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.112003,	
2017-07-28 18:44:43,294 Epoch[17] Batch [60]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.114194,	
2017-07-28 18:44:49,124 Epoch[17] Batch [70]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.115635,	
2017-07-28 18:44:54,922 Epoch[17] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115573,	
2017-07-28 18:45:00,758 Epoch[17] Batch [90]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116689,	
2017-07-28 18:45:06,539 Epoch[17] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118240,	
2017-07-28 18:45:12,305 Epoch[17] Batch [110]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.118671,	
2017-07-28 18:45:18,132 Epoch[17] Batch [120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117638,	
2017-07-28 18:45:23,932 Epoch[17] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117764,	
2017-07-28 18:45:29,701 Epoch[17] Batch [140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116757,	
2017-07-28 18:45:35,526 Epoch[17] Batch [150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115879,	
2017-07-28 18:45:41,289 Epoch[17] Batch [160]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115801,	
2017-07-28 18:45:47,097 Epoch[17] Batch [170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115494,	
2017-07-28 18:45:52,896 Epoch[17] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115292,	
2017-07-28 18:45:58,706 Epoch[17] Batch [190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115166,	
2017-07-28 18:46:04,507 Epoch[17] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115013,	
2017-07-28 18:46:10,298 Epoch[17] Batch [210]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115193,	
2017-07-28 18:46:16,101 Epoch[17] Batch [220]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114875,	
2017-07-28 18:46:21,889 Epoch[17] Batch [230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114529,	
2017-07-28 18:46:27,542 Epoch[17] Batch [240]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.115099,	
2017-07-28 18:46:33,449 Epoch[17] Batch [250]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.115143,	
2017-07-28 18:46:39,270 Epoch[17] Batch [260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115052,	
2017-07-28 18:46:45,117 Epoch[17] Batch [270]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.114814,	
2017-07-28 18:46:50,924 Epoch[17] Batch [280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114605,	
2017-07-28 18:46:56,758 Epoch[17] Batch [290]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.114153,	
2017-07-28 18:47:02,586 Epoch[17] Batch [300]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.114309,	
2017-07-28 18:47:08,364 Epoch[17] Batch [310]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114109,	
2017-07-28 18:47:14,180 Epoch[17] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114107,	
2017-07-28 18:47:19,986 Epoch[17] Batch [330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114190,	
2017-07-28 18:47:25,776 Epoch[17] Batch [340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114362,	
2017-07-28 18:47:31,600 Epoch[17] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114584,	
2017-07-28 18:47:37,510 Epoch[17] Batch [360]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.114457,	
2017-07-28 18:47:43,222 Epoch[17] Batch [370]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.114276,	
2017-07-28 18:47:49,039 Epoch[17] Batch [380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114275,	
2017-07-28 18:47:54,831 Epoch[17] Batch [390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114243,	
2017-07-28 18:48:00,655 Epoch[17] Batch [400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114086,	
2017-07-28 18:48:06,465 Epoch[17] Batch [410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113856,	
2017-07-28 18:48:12,289 Epoch[17] Batch [420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113845,	
2017-07-28 18:48:18,102 Epoch[17] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113923,	
2017-07-28 18:48:23,900 Epoch[17] Batch [440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114218,	
2017-07-28 18:48:29,749 Epoch[17] Batch [450]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.114507,	
2017-07-28 18:48:35,528 Epoch[17] Batch [460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114773,	
2017-07-28 18:48:41,318 Epoch[17] Batch [470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114782,	
2017-07-28 18:48:47,124 Epoch[17] Batch [480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115096,	
2017-07-28 18:48:52,925 Epoch[17] Batch [490]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115585,	
2017-07-28 18:48:58,735 Epoch[17] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115680,	
2017-07-28 18:49:04,558 Epoch[17] Batch [510]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115637,	
2017-07-28 18:49:10,368 Epoch[17] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115721,	
2017-07-28 18:49:16,179 Epoch[17] Batch [530]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115600,	
2017-07-28 18:49:22,212 Epoch[17] Batch [540]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.115691,	
2017-07-28 18:49:28,066 Epoch[17] Batch [550]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.115703,	
2017-07-28 18:49:33,880 Epoch[17] Batch [560]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115683,	
2017-07-28 18:49:39,712 Epoch[17] Batch [570]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.115990,	
2017-07-28 18:49:45,508 Epoch[17] Batch [580]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116143,	
2017-07-28 18:49:51,331 Epoch[17] Batch [590]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116143,	
2017-07-28 18:49:57,138 Epoch[17] Batch [600]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115942,	
2017-07-28 18:50:02,979 Epoch[17] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116189,	
2017-07-28 18:50:08,753 Epoch[17] Batch [620]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116299,	
2017-07-28 18:50:14,589 Epoch[17] Batch [630]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116423,	
2017-07-28 18:50:20,350 Epoch[17] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116518,	
2017-07-28 18:50:26,161 Epoch[17] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116481,	
2017-07-28 18:50:31,978 Epoch[17] Batch [660]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116604,	
2017-07-28 18:50:37,749 Epoch[17] Batch [670]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116673,	
2017-07-28 18:50:43,572 Epoch[17] Batch [680]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116590,	
2017-07-28 18:50:49,373 Epoch[17] Batch [690]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116385,	
2017-07-28 18:50:55,159 Epoch[17] Batch [700]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116154,	
2017-07-28 18:51:00,988 Epoch[17] Batch [710]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116187,	
2017-07-28 18:51:06,794 Epoch[17] Batch [720]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116160,	
2017-07-28 18:51:12,632 Epoch[17] Batch [730]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116181,	
2017-07-28 18:51:18,405 Epoch[17] Batch [740]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116203,	
2017-07-28 18:51:24,173 Epoch[17] Batch [750]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116224,	
2017-07-28 18:51:30,003 Epoch[17] Batch [760]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116329,	
2017-07-28 18:51:35,829 Epoch[17] Batch [770]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116397,	
2017-07-28 18:51:41,640 Epoch[17] Batch [780]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116260,	
2017-07-28 18:51:47,410 Epoch[17] Batch [790]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116283,	
2017-07-28 18:51:53,243 Epoch[17] Batch [800]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116267,	
2017-07-28 18:51:59,030 Epoch[17] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116192,	
2017-07-28 18:52:04,838 Epoch[17] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116226,	
2017-07-28 18:52:10,624 Epoch[17] Batch [830]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116224,	
2017-07-28 18:52:16,442 Epoch[17] Batch [840]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116284,	
2017-07-28 18:52:22,282 Epoch[17] Batch [850]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116290,	
2017-07-28 18:52:28,096 Epoch[17] Batch [860]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116362,	
2017-07-28 18:52:33,913 Epoch[17] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116274,	
2017-07-28 18:52:39,740 Epoch[17] Batch [880]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116396,	
2017-07-28 18:52:45,549 Epoch[17] Batch [890]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116480,	
2017-07-28 18:52:51,292 Epoch[17] Batch [900]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.116419,	
2017-07-28 18:52:57,090 Epoch[17] Batch [910]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116478,	
2017-07-28 18:53:02,911 Epoch[17] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116482,	
2017-07-28 18:53:08,681 Epoch[17] Batch [930]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116516,	
2017-07-28 18:53:14,489 Epoch[17] Batch [940]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116397,	
2017-07-28 18:53:20,283 Epoch[17] Batch [950]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116377,	
2017-07-28 18:53:26,096 Epoch[17] Batch [960]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116376,	
2017-07-28 18:53:31,903 Epoch[17] Batch [970]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116310,	
2017-07-28 18:53:37,731 Epoch[17] Batch [980]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116312,	
2017-07-28 18:53:43,485 Epoch[17] Batch [990]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116401,	
2017-07-28 18:53:49,278 Epoch[17] Batch [1000]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116323,	
2017-07-28 18:53:55,107 Epoch[17] Batch [1010]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116401,	
2017-07-28 18:54:00,909 Epoch[17] Batch [1020]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116301,	
2017-07-28 18:54:06,737 Epoch[17] Batch [1030]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116179,	
2017-07-28 18:54:12,526 Epoch[17] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116237,	
2017-07-28 18:54:18,303 Epoch[17] Batch [1050]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116197,	
2017-07-28 18:54:24,097 Epoch[17] Batch [1060]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116205,	
2017-07-28 18:54:29,905 Epoch[17] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116232,	
2017-07-28 18:54:34,981 Epoch[17] Batch [1080]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.116224,	
2017-07-28 18:54:39,873 Epoch[17] Batch [1090]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.116189,	
2017-07-28 18:54:45,616 Epoch[17] Batch [1100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.116074,	
2017-07-28 18:54:51,418 Epoch[17] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116084,	
2017-07-28 18:54:57,224 Epoch[17] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116067,	
2017-07-28 18:55:03,014 Epoch[17] Batch [1130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116117,	
2017-07-28 18:55:08,823 Epoch[17] Batch [1140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116029,	
2017-07-28 18:55:14,624 Epoch[17] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116078,	
2017-07-28 18:55:20,428 Epoch[17] Batch [1160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116082,	
2017-07-28 18:55:26,227 Epoch[17] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116266,	
2017-07-28 18:55:32,049 Epoch[17] Batch [1180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116336,	
2017-07-28 18:55:37,834 Epoch[17] Batch [1190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116504,	
2017-07-28 18:55:43,639 Epoch[17] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116594,	
2017-07-28 18:55:49,415 Epoch[17] Batch [1210]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116739,	
2017-07-28 18:55:55,229 Epoch[17] Batch [1220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116762,	
2017-07-28 18:56:01,066 Epoch[17] Batch [1230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116834,	
2017-07-28 18:56:06,878 Epoch[17] Batch [1240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116732,	
2017-07-28 18:56:12,683 Epoch[17] Batch [1250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116750,	
2017-07-28 18:56:18,494 Epoch[17] Batch [1260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116705,	
2017-07-28 18:56:24,253 Epoch[17] Batch [1270]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116600,	
2017-07-28 18:56:30,055 Epoch[17] Batch [1280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116525,	
2017-07-28 18:56:35,868 Epoch[17] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116587,	
2017-07-28 18:56:41,677 Epoch[17] Batch [1300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116496,	
2017-07-28 18:56:47,469 Epoch[17] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116414,	
2017-07-28 18:56:53,310 Epoch[17] Batch [1320]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116345,	
2017-07-28 18:56:59,112 Epoch[17] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116271,	
2017-07-28 18:57:04,904 Epoch[17] Batch [1340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116140,	
2017-07-28 18:57:10,711 Epoch[17] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116087,	
2017-07-28 18:57:16,527 Epoch[17] Batch [1360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116065,	
2017-07-28 18:57:22,113 Epoch[17] Batch [1370]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.116100,	
2017-07-28 18:57:27,650 Epoch[17] Batch [1380]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.116045,	
2017-07-28 18:57:33,468 Epoch[17] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115907,	
2017-07-28 18:57:39,280 Epoch[17] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116016,	
2017-07-28 18:57:45,087 Epoch[17] Batch [1410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116050,	
2017-07-28 18:57:50,907 Epoch[17] Batch [1420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116060,	
2017-07-28 18:57:56,730 Epoch[17] Batch [1430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116145,	
2017-07-28 18:58:02,515 Epoch[17] Batch [1440]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116190,	
2017-07-28 18:58:08,344 Epoch[17] Batch [1450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116166,	
2017-07-28 18:58:14,161 Epoch[17] Batch [1460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116115,	
2017-07-28 18:58:19,946 Epoch[17] Batch [1470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116199,	
2017-07-28 18:58:25,768 Epoch[17] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116177,	
2017-07-28 18:58:29,225 Epoch[17] Train-FCNLogLoss=0.116157
2017-07-28 18:58:29,225 Epoch[17] Time cost=861.157
2017-07-28 18:58:31,485 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.params"
2017-07-28 18:58:35,651 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.states"
2017-07-28 18:58:42,379 Epoch[18] Batch [10]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.127539,	
2017-07-28 18:58:48,179 Epoch[18] Batch [20]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120981,	
2017-07-28 18:58:53,963 Epoch[18] Batch [30]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118284,	
2017-07-28 18:58:59,813 Epoch[18] Batch [40]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.115867,	
2017-07-28 18:59:05,592 Epoch[18] Batch [50]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113792,	
2017-07-28 18:59:11,417 Epoch[18] Batch [60]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110711,	
2017-07-28 18:59:17,211 Epoch[18] Batch [70]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110084,	
2017-07-28 18:59:23,029 Epoch[18] Batch [80]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109758,	
2017-07-28 18:59:28,876 Epoch[18] Batch [90]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.109163,	
2017-07-28 18:59:34,664 Epoch[18] Batch [100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110121,	
2017-07-28 18:59:40,453 Epoch[18] Batch [110]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111528,	
2017-07-28 18:59:46,244 Epoch[18] Batch [120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111526,	
2017-07-28 18:59:52,051 Epoch[18] Batch [130]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112371,	
2017-07-28 18:59:57,830 Epoch[18] Batch [140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.111800,	
2017-07-28 19:00:03,620 Epoch[18] Batch [150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111425,	
2017-07-28 19:00:09,447 Epoch[18] Batch [160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111073,	
2017-07-28 19:00:15,237 Epoch[18] Batch [170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111300,	
2017-07-28 19:00:21,087 Epoch[18] Batch [180]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.111152,	
2017-07-28 19:00:26,818 Epoch[18] Batch [190]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.110756,	
2017-07-28 19:00:32,685 Epoch[18] Batch [200]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.110743,	
2017-07-28 19:00:38,447 Epoch[18] Batch [210]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.111140,	
2017-07-28 19:00:44,275 Epoch[18] Batch [220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.111444,	
2017-07-28 19:00:50,020 Epoch[18] Batch [230]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.111657,	
2017-07-28 19:00:55,821 Epoch[18] Batch [240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112298,	
2017-07-28 19:01:01,630 Epoch[18] Batch [250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112322,	
2017-07-28 19:01:07,427 Epoch[18] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112503,	
2017-07-28 19:01:13,265 Epoch[18] Batch [270]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.112178,	
2017-07-28 19:01:19,059 Epoch[18] Batch [280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112241,	
2017-07-28 19:01:24,843 Epoch[18] Batch [290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112489,	
2017-07-28 19:01:30,652 Epoch[18] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112291,	
2017-07-28 19:01:36,472 Epoch[18] Batch [310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112001,	
2017-07-28 19:01:42,237 Epoch[18] Batch [320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.111993,	
2017-07-28 19:01:48,021 Epoch[18] Batch [330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112275,	
2017-07-28 19:01:53,865 Epoch[18] Batch [340]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.111995,	
2017-07-28 19:01:59,646 Epoch[18] Batch [350]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112355,	
2017-07-28 19:02:05,452 Epoch[18] Batch [360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112437,	
2017-07-28 19:02:11,257 Epoch[18] Batch [370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112710,	
2017-07-28 19:02:17,069 Epoch[18] Batch [380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112618,	
2017-07-28 19:02:22,870 Epoch[18] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112316,	
2017-07-28 19:02:28,684 Epoch[18] Batch [400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112447,	
2017-07-28 19:02:34,488 Epoch[18] Batch [410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112696,	
2017-07-28 19:02:40,294 Epoch[18] Batch [420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112490,	
2017-07-28 19:02:46,079 Epoch[18] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112577,	
2017-07-28 19:02:51,869 Epoch[18] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112763,	
2017-07-28 19:02:57,687 Epoch[18] Batch [450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112936,	
2017-07-28 19:03:03,498 Epoch[18] Batch [460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112976,	
2017-07-28 19:03:09,302 Epoch[18] Batch [470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113291,	
2017-07-28 19:03:15,134 Epoch[18] Batch [480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113435,	
2017-07-28 19:03:20,929 Epoch[18] Batch [490]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113417,	
2017-07-28 19:03:26,736 Epoch[18] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113443,	
2017-07-28 19:03:32,549 Epoch[18] Batch [510]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113251,	
2017-07-28 19:03:38,332 Epoch[18] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113462,	
2017-07-28 19:03:44,133 Epoch[18] Batch [530]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113443,	
2017-07-28 19:03:49,910 Epoch[18] Batch [540]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113574,	
2017-07-28 19:03:55,745 Epoch[18] Batch [550]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113902,	
2017-07-28 19:04:01,552 Epoch[18] Batch [560]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114061,	
2017-07-28 19:04:07,355 Epoch[18] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114020,	
2017-07-28 19:04:13,136 Epoch[18] Batch [580]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114074,	
2017-07-28 19:04:18,951 Epoch[18] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114001,	
2017-07-28 19:04:24,734 Epoch[18] Batch [600]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113988,	
2017-07-28 19:04:30,521 Epoch[18] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113810,	
2017-07-28 19:04:36,382 Epoch[18] Batch [620]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.113747,	
2017-07-28 19:04:42,158 Epoch[18] Batch [630]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113818,	
2017-07-28 19:04:47,946 Epoch[18] Batch [640]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113739,	
2017-07-28 19:04:53,751 Epoch[18] Batch [650]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113858,	
2017-07-28 19:04:59,572 Epoch[18] Batch [660]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113977,	
2017-07-28 19:05:05,382 Epoch[18] Batch [670]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114049,	
2017-07-28 19:05:11,199 Epoch[18] Batch [680]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114122,	
2017-07-28 19:05:17,018 Epoch[18] Batch [690]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114053,	
2017-07-28 19:05:22,797 Epoch[18] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114103,	
2017-07-28 19:05:28,641 Epoch[18] Batch [710]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.114043,	
2017-07-28 19:05:34,422 Epoch[18] Batch [720]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114222,	
2017-07-28 19:05:40,204 Epoch[18] Batch [730]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114421,	
2017-07-28 19:05:46,002 Epoch[18] Batch [740]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114318,	
2017-07-28 19:05:51,815 Epoch[18] Batch [750]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114164,	
2017-07-28 19:05:57,663 Epoch[18] Batch [760]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.114199,	
2017-07-28 19:06:03,489 Epoch[18] Batch [770]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114357,	
2017-07-28 19:06:09,281 Epoch[18] Batch [780]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114264,	
2017-07-28 19:06:15,117 Epoch[18] Batch [790]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.114181,	
2017-07-28 19:06:20,912 Epoch[18] Batch [800]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114501,	
2017-07-28 19:06:26,757 Epoch[18] Batch [810]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.115284,	
2017-07-28 19:06:32,548 Epoch[18] Batch [820]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116470,	
2017-07-28 19:06:38,355 Epoch[18] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117192,	
2017-07-28 19:06:44,138 Epoch[18] Batch [840]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117579,	
2017-07-28 19:06:49,947 Epoch[18] Batch [850]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117884,	
2017-07-28 19:06:55,736 Epoch[18] Batch [860]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118056,	
2017-07-28 19:07:01,559 Epoch[18] Batch [870]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.118038,	
2017-07-28 19:07:07,371 Epoch[18] Batch [880]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118032,	
2017-07-28 19:07:13,202 Epoch[18] Batch [890]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.118250,	
2017-07-28 19:07:18,978 Epoch[18] Batch [900]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.118400,	
2017-07-28 19:07:24,798 Epoch[18] Batch [910]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.118547,	
2017-07-28 19:07:30,330 Epoch[18] Batch [920]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.118852,	
2017-07-28 19:07:36,067 Epoch[18] Batch [930]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.119212,	
2017-07-28 19:07:41,716 Epoch[18] Batch [940]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.119590,	
2017-07-28 19:07:47,499 Epoch[18] Batch [950]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.119843,	
2017-07-28 19:07:53,102 Epoch[18] Batch [960]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.120094,	
2017-07-28 19:07:58,920 Epoch[18] Batch [970]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120485,	
2017-07-28 19:08:04,719 Epoch[18] Batch [980]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120516,	
2017-07-28 19:08:10,501 Epoch[18] Batch [990]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.120444,	
2017-07-28 19:08:16,296 Epoch[18] Batch [1000]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120431,	
2017-07-28 19:08:22,084 Epoch[18] Batch [1010]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120388,	
2017-07-28 19:08:27,660 Epoch[18] Batch [1020]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.120362,	
2017-07-28 19:08:33,462 Epoch[18] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120242,	
2017-07-28 19:08:39,254 Epoch[18] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120291,	
2017-07-28 19:08:45,063 Epoch[18] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120177,	
2017-07-28 19:08:50,862 Epoch[18] Batch [1060]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120170,	
2017-07-28 19:08:56,694 Epoch[18] Batch [1070]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120087,	
2017-07-28 19:09:02,526 Epoch[18] Batch [1080]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120070,	
2017-07-28 19:09:07,038 Epoch[18] Batch [1090]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.120074,	
2017-07-28 19:09:12,294 Epoch[18] Batch [1100]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.120138,	
2017-07-28 19:09:18,108 Epoch[18] Batch [1110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120141,	
2017-07-28 19:09:23,902 Epoch[18] Batch [1120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120067,	
2017-07-28 19:09:29,717 Epoch[18] Batch [1130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120118,	
2017-07-28 19:09:35,492 Epoch[18] Batch [1140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120185,	
2017-07-28 19:09:41,293 Epoch[18] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120119,	
2017-07-28 19:09:47,137 Epoch[18] Batch [1160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.120129,	
2017-07-28 19:09:52,911 Epoch[18] Batch [1170]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120195,	
2017-07-28 19:09:58,724 Epoch[18] Batch [1180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120222,	
2017-07-28 19:10:04,494 Epoch[18] Batch [1190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120046,	
2017-07-28 19:10:10,300 Epoch[18] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119996,	
2017-07-28 19:10:16,112 Epoch[18] Batch [1210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120021,	
2017-07-28 19:10:21,905 Epoch[18] Batch [1220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120065,	
2017-07-28 19:10:27,677 Epoch[18] Batch [1230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120034,	
2017-07-28 19:10:33,468 Epoch[18] Batch [1240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.119997,	
2017-07-28 19:10:39,210 Epoch[18] Batch [1250]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.119947,	
2017-07-28 19:10:45,030 Epoch[18] Batch [1260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119897,	
2017-07-28 19:10:50,937 Epoch[18] Batch [1270]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.119843,	
2017-07-28 19:10:56,711 Epoch[18] Batch [1280]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119731,	
2017-07-28 19:11:02,507 Epoch[18] Batch [1290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119702,	
2017-07-28 19:11:08,257 Epoch[18] Batch [1300]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.119632,	
2017-07-28 19:11:14,058 Epoch[18] Batch [1310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119484,	
2017-07-28 19:11:19,849 Epoch[18] Batch [1320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.119690,	
2017-07-28 19:11:25,612 Epoch[18] Batch [1330]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.119770,	
2017-07-28 19:11:31,440 Epoch[18] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.119817,	
2017-07-28 19:11:37,030 Epoch[18] Batch [1350]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.119815,	
2017-07-28 19:11:42,896 Epoch[18] Batch [1360]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.119808,	
2017-07-28 19:11:48,703 Epoch[18] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119824,	
2017-07-28 19:11:54,527 Epoch[18] Batch [1380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119797,	
2017-07-28 19:12:00,333 Epoch[18] Batch [1390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119776,	
2017-07-28 19:12:06,144 Epoch[18] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.119707,	
2017-07-28 19:12:11,916 Epoch[18] Batch [1410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119928,	
2017-07-28 19:12:17,707 Epoch[18] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.119878,	
2017-07-28 19:12:23,550 Epoch[18] Batch [1430]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.119833,	
2017-07-28 19:12:29,314 Epoch[18] Batch [1440]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.119855,	
2017-07-28 19:12:34,915 Epoch[18] Batch [1450]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.119869,	
2017-07-28 19:12:40,708 Epoch[18] Batch [1460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.119915,	
2017-07-28 19:12:46,547 Epoch[18] Batch [1470]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.119918,	
2017-07-28 19:12:52,325 Epoch[18] Batch [1480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.119871,	
2017-07-28 19:12:55,828 Epoch[18] Train-FCNLogLoss=0.119763
2017-07-28 19:12:55,828 Epoch[18] Time cost=860.176
2017-07-28 19:12:57,604 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.params"
2017-07-28 19:13:01,529 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.states"
2017-07-28 19:13:08,364 Epoch[19] Batch [10]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.120297,	
2017-07-28 19:13:14,221 Epoch[19] Batch [20]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.124778,	
2017-07-28 19:13:20,132 Epoch[19] Batch [30]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.122044,	
2017-07-28 19:13:25,965 Epoch[19] Batch [40]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.119341,	
2017-07-28 19:13:31,760 Epoch[19] Batch [50]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118309,	
2017-07-28 19:13:37,554 Epoch[19] Batch [60]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118188,	
2017-07-28 19:13:43,388 Epoch[19] Batch [70]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.118841,	
2017-07-28 19:13:49,200 Epoch[19] Batch [80]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117282,	
2017-07-28 19:13:54,979 Epoch[19] Batch [90]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116502,	
2017-07-28 19:14:00,765 Epoch[19] Batch [100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116439,	
2017-07-28 19:14:06,558 Epoch[19] Batch [110]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118973,	
2017-07-28 19:14:11,935 Epoch[19] Batch [120]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119369,	
2017-07-28 19:14:17,689 Epoch[19] Batch [130]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.119191,	
2017-07-28 19:14:23,507 Epoch[19] Batch [140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118609,	
2017-07-28 19:14:29,326 Epoch[19] Batch [150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119233,	
2017-07-28 19:14:35,131 Epoch[19] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119420,	
2017-07-28 19:14:40,952 Epoch[19] Batch [170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119545,	
2017-07-28 19:14:46,767 Epoch[19] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.119322,	
2017-07-28 19:14:52,561 Epoch[19] Batch [190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119039,	
2017-07-28 19:14:58,365 Epoch[19] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119000,	
2017-07-28 19:15:04,183 Epoch[19] Batch [210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118622,	
2017-07-28 19:15:10,125 Epoch[19] Batch [220]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.118235,	
2017-07-28 19:15:16,096 Epoch[19] Batch [230]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.117920,	
2017-07-28 19:15:21,845 Epoch[19] Batch [240]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.118315,	
2017-07-28 19:15:27,728 Epoch[19] Batch [250]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.117877,	
2017-07-28 19:15:33,580 Epoch[19] Batch [260]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.118090,	
2017-07-28 19:15:39,398 Epoch[19] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117642,	
2017-07-28 19:15:45,195 Epoch[19] Batch [280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117622,	
2017-07-28 19:15:51,026 Epoch[19] Batch [290]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117889,	
2017-07-28 19:15:56,833 Epoch[19] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117710,	
2017-07-28 19:16:02,754 Epoch[19] Batch [310]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.117351,	
2017-07-28 19:16:08,537 Epoch[19] Batch [320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116738,	
2017-07-28 19:16:14,402 Epoch[19] Batch [330]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.116640,	
2017-07-28 19:16:20,168 Epoch[19] Batch [340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116623,	
2017-07-28 19:16:25,660 Epoch[19] Batch [350]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.116599,	
2017-07-28 19:16:31,297 Epoch[19] Batch [360]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.116228,	
2017-07-28 19:16:37,056 Epoch[19] Batch [370]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116234,	
2017-07-28 19:16:42,607 Epoch[19] Batch [380]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.116742,	
2017-07-28 19:16:48,451 Epoch[19] Batch [390]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.117027,	
2017-07-28 19:16:54,311 Epoch[19] Batch [400]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.116963,	
2017-07-28 19:17:00,140 Epoch[19] Batch [410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116794,	
2017-07-28 19:17:05,929 Epoch[19] Batch [420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116938,	
2017-07-28 19:17:11,743 Epoch[19] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117091,	
2017-07-28 19:17:17,548 Epoch[19] Batch [440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117187,	
2017-07-28 19:17:23,347 Epoch[19] Batch [450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117309,	
2017-07-28 19:17:29,063 Epoch[19] Batch [460]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.117214,	
2017-07-28 19:17:34,950 Epoch[19] Batch [470]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.117095,	
2017-07-28 19:17:40,762 Epoch[19] Batch [480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116929,	
2017-07-28 19:17:46,537 Epoch[19] Batch [490]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116865,	
2017-07-28 19:17:52,363 Epoch[19] Batch [500]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116846,	
2017-07-28 19:17:57,972 Epoch[19] Batch [510]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.116522,	
2017-07-28 19:18:03,802 Epoch[19] Batch [520]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117563,	
2017-07-28 19:18:09,632 Epoch[19] Batch [530]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.118423,	
2017-07-28 19:18:15,370 Epoch[19] Batch [540]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.118843,	
2017-07-28 19:18:21,175 Epoch[19] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119138,	
2017-07-28 19:18:27,047 Epoch[19] Batch [560]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.119087,	
2017-07-28 19:18:32,826 Epoch[19] Batch [570]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.119349,	
2017-07-28 19:18:38,640 Epoch[19] Batch [580]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.119590,	
2017-07-28 19:18:44,453 Epoch[19] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.119680,	
2017-07-28 19:18:50,206 Epoch[19] Batch [600]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.120088,	
2017-07-28 19:18:56,004 Epoch[19] Batch [610]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120064,	
2017-07-28 19:19:01,810 Epoch[19] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120156,	
2017-07-28 19:19:07,801 Epoch[19] Batch [630]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.120092,	
2017-07-28 19:19:13,689 Epoch[19] Batch [640]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.120001,	
2017-07-28 19:19:19,492 Epoch[19] Batch [650]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120164,	
2017-07-28 19:19:25,279 Epoch[19] Batch [660]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120155,	
2017-07-28 19:19:31,101 Epoch[19] Batch [670]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.120063,	
2017-07-28 19:19:36,858 Epoch[19] Batch [680]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.119780,	
2017-07-28 19:19:42,675 Epoch[19] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.119756,	
2017-07-28 19:19:48,526 Epoch[19] Batch [700]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.119637,	
2017-07-28 19:19:54,269 Epoch[19] Batch [710]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.119401,	
2017-07-28 19:20:00,071 Epoch[19] Batch [720]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119262,	
2017-07-28 19:20:05,880 Epoch[19] Batch [730]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119233,	
2017-07-28 19:20:11,702 Epoch[19] Batch [740]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119119,	
2017-07-28 19:20:17,436 Epoch[19] Batch [750]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.119031,	
2017-07-28 19:20:23,105 Epoch[19] Batch [760]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.118932,	
2017-07-28 19:20:28,852 Epoch[19] Batch [770]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.118760,	
2017-07-28 19:20:34,390 Epoch[19] Batch [780]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.118964,	
2017-07-28 19:20:40,235 Epoch[19] Batch [790]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.118718,	
2017-07-28 19:20:46,017 Epoch[19] Batch [800]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118468,	
2017-07-28 19:20:51,851 Epoch[19] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.118180,	
2017-07-28 19:20:57,591 Epoch[19] Batch [820]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.118068,	
2017-07-28 19:21:03,425 Epoch[19] Batch [830]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117899,	
2017-07-28 19:21:09,255 Epoch[19] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.118022,	
2017-07-28 19:21:15,215 Epoch[19] Batch [850]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.118050,	
2017-07-28 19:21:21,104 Epoch[19] Batch [860]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.118029,	
2017-07-28 19:21:26,954 Epoch[19] Batch [870]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.117940,	
2017-07-28 19:21:32,731 Epoch[19] Batch [880]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118057,	
2017-07-28 19:21:38,584 Epoch[19] Batch [890]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.118041,	
2017-07-28 19:21:44,394 Epoch[19] Batch [900]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117882,	
2017-07-28 19:21:50,215 Epoch[19] Batch [910]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117821,	
2017-07-28 19:21:56,036 Epoch[19] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117793,	
2017-07-28 19:22:01,830 Epoch[19] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117626,	
2017-07-28 19:22:07,469 Epoch[19] Batch [940]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.117468,	
2017-07-28 19:22:13,149 Epoch[19] Batch [950]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.117333,	
2017-07-28 19:22:18,651 Epoch[19] Batch [960]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.117283,	
2017-07-28 19:22:24,533 Epoch[19] Batch [970]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.117299,	
2017-07-28 19:22:30,107 Epoch[19] Batch [980]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.117269,	
2017-07-28 19:22:35,725 Epoch[19] Batch [990]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.117170,	
2017-07-28 19:22:41,551 Epoch[19] Batch [1000]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117134,	
2017-07-28 19:22:47,375 Epoch[19] Batch [1010]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117198,	
2017-07-28 19:22:53,192 Epoch[19] Batch [1020]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117055,	
2017-07-28 19:22:58,866 Epoch[19] Batch [1030]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.116908,	
2017-07-28 19:23:04,728 Epoch[19] Batch [1040]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.116872,	
2017-07-28 19:23:10,596 Epoch[19] Batch [1050]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.116744,	
2017-07-28 19:23:16,423 Epoch[19] Batch [1060]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116695,	
2017-07-28 19:23:22,212 Epoch[19] Batch [1070]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116637,	
2017-07-28 19:23:28,056 Epoch[19] Batch [1080]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116601,	
2017-07-28 19:23:33,952 Epoch[19] Batch [1090]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.116490,	
2017-07-28 19:23:38,938 Epoch[19] Batch [1100]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.116451,	
2017-07-28 19:23:43,926 Epoch[19] Batch [1110]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.116487,	
2017-07-28 19:23:49,775 Epoch[19] Batch [1120]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116447,	
2017-07-28 19:23:55,557 Epoch[19] Batch [1130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116406,	
2017-07-28 19:24:01,230 Epoch[19] Batch [1140]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.116377,	
2017-07-28 19:24:06,981 Epoch[19] Batch [1150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.116390,	
2017-07-28 19:24:12,842 Epoch[19] Batch [1160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.116423,	
2017-07-28 19:24:18,701 Epoch[19] Batch [1170]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.116366,	
2017-07-28 19:24:24,299 Epoch[19] Batch [1180]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.116287,	
2017-07-28 19:24:29,899 Epoch[19] Batch [1190]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.116261,	
2017-07-28 19:24:35,876 Epoch[19] Batch [1200]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.116267,	
2017-07-28 19:24:41,550 Epoch[19] Batch [1210]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.116287,	
2017-07-28 19:24:47,067 Epoch[19] Batch [1220]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.116195,	
2017-07-28 19:24:52,829 Epoch[19] Batch [1230]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116176,	
2017-07-28 19:24:58,665 Epoch[19] Batch [1240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116232,	
2017-07-28 19:25:04,280 Epoch[19] Batch [1250]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.116242,	
2017-07-28 19:25:10,116 Epoch[19] Batch [1260]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116210,	
2017-07-28 19:25:15,931 Epoch[19] Batch [1270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116189,	
2017-07-28 19:25:21,702 Epoch[19] Batch [1280]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116187,	
2017-07-28 19:25:27,527 Epoch[19] Batch [1290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116162,	
2017-07-28 19:25:33,336 Epoch[19] Batch [1300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116051,	
2017-07-28 19:25:39,117 Epoch[19] Batch [1310]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116073,	
2017-07-28 19:25:44,941 Epoch[19] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116052,	
2017-07-28 19:25:50,713 Epoch[19] Batch [1330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116027,	
2017-07-28 19:25:56,538 Epoch[19] Batch [1340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116037,	
2017-07-28 19:26:02,329 Epoch[19] Batch [1350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116043,	
2017-07-28 19:26:08,121 Epoch[19] Batch [1360]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116109,	
2017-07-28 19:26:13,935 Epoch[19] Batch [1370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116092,	
2017-07-28 19:26:19,726 Epoch[19] Batch [1380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116073,	
2017-07-28 19:26:25,511 Epoch[19] Batch [1390]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116109,	
2017-07-28 19:26:31,324 Epoch[19] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116072,	
2017-07-28 19:26:37,120 Epoch[19] Batch [1410]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116047,	
2017-07-28 19:26:42,930 Epoch[19] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116031,	
2017-07-28 19:26:48,729 Epoch[19] Batch [1430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116094,	
2017-07-28 19:26:54,579 Epoch[19] Batch [1440]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116059,	
2017-07-28 19:27:00,525 Epoch[19] Batch [1450]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.116093,	
2017-07-28 19:27:06,420 Epoch[19] Batch [1460]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.116438,	
2017-07-28 19:27:12,216 Epoch[19] Batch [1470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116429,	
2017-07-28 19:27:17,996 Epoch[19] Batch [1480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116427,	
2017-07-28 19:27:21,488 Epoch[19] Train-FCNLogLoss=0.116446
2017-07-28 19:27:21,488 Epoch[19] Time cost=859.959
2017-07-28 19:27:23,717 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.params"
2017-07-28 19:27:26,319 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.states"
2017-07-28 19:27:32,929 Epoch[20] Batch [10]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119334,	
2017-07-28 19:27:38,749 Epoch[20] Batch [20]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117290,	
2017-07-28 19:27:44,517 Epoch[20] Batch [30]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.118859,	
2017-07-28 19:27:50,334 Epoch[20] Batch [40]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116214,	
2017-07-28 19:27:56,136 Epoch[20] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116822,	
2017-07-28 19:28:01,927 Epoch[20] Batch [60]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113947,	
2017-07-28 19:28:07,718 Epoch[20] Batch [70]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112214,	
2017-07-28 19:28:13,482 Epoch[20] Batch [80]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.112822,	
2017-07-28 19:28:19,304 Epoch[20] Batch [90]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112553,	
2017-07-28 19:28:25,090 Epoch[20] Batch [100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111831,	
2017-07-28 19:28:30,875 Epoch[20] Batch [110]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112972,	
2017-07-28 19:28:36,683 Epoch[20] Batch [120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113791,	
2017-07-28 19:28:42,482 Epoch[20] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114255,	
2017-07-28 19:28:48,279 Epoch[20] Batch [140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114601,	
2017-07-28 19:28:54,067 Epoch[20] Batch [150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114738,	
2017-07-28 19:28:59,862 Epoch[20] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115361,	
2017-07-28 19:29:05,665 Epoch[20] Batch [170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115526,	
2017-07-28 19:29:11,456 Epoch[20] Batch [180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115736,	
2017-07-28 19:29:17,284 Epoch[20] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.115672,	
2017-07-28 19:29:23,046 Epoch[20] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115619,	
2017-07-28 19:29:28,839 Epoch[20] Batch [210]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115620,	
2017-07-28 19:29:34,640 Epoch[20] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115601,	
2017-07-28 19:29:40,423 Epoch[20] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115455,	
2017-07-28 19:29:46,245 Epoch[20] Batch [240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115074,	
2017-07-28 19:29:52,036 Epoch[20] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114649,	
2017-07-28 19:29:57,831 Epoch[20] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114740,	
2017-07-28 19:30:03,626 Epoch[20] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114280,	
2017-07-28 19:30:09,410 Epoch[20] Batch [280]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113923,	
2017-07-28 19:30:15,183 Epoch[20] Batch [290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113577,	
2017-07-28 19:30:21,178 Epoch[20] Batch [300]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.113383,	
2017-07-28 19:30:26,951 Epoch[20] Batch [310]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113058,	
2017-07-28 19:30:32,760 Epoch[20] Batch [320]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113008,	
2017-07-28 19:30:38,582 Epoch[20] Batch [330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113324,	
2017-07-28 19:30:44,385 Epoch[20] Batch [340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113109,	
2017-07-28 19:30:50,373 Epoch[20] Batch [350]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113015,	
2017-07-28 19:30:56,156 Epoch[20] Batch [360]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112669,	
2017-07-28 19:31:01,931 Epoch[20] Batch [370]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.112557,	
2017-07-28 19:31:07,713 Epoch[20] Batch [380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112537,	
2017-07-28 19:31:13,576 Epoch[20] Batch [390]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.112921,	
2017-07-28 19:31:19,375 Epoch[20] Batch [400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113150,	
2017-07-28 19:31:25,186 Epoch[20] Batch [410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113179,	
2017-07-28 19:31:30,971 Epoch[20] Batch [420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113274,	
2017-07-28 19:31:36,759 Epoch[20] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113403,	
2017-07-28 19:31:42,551 Epoch[20] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113305,	
2017-07-28 19:31:48,372 Epoch[20] Batch [450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113298,	
2017-07-28 19:31:54,162 Epoch[20] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113240,	
2017-07-28 19:31:59,998 Epoch[20] Batch [470]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.112955,	
2017-07-28 19:32:05,782 Epoch[20] Batch [480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112711,	
2017-07-28 19:32:11,667 Epoch[20] Batch [490]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.112757,	
2017-07-28 19:32:17,556 Epoch[20] Batch [500]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.112544,	
2017-07-28 19:32:23,357 Epoch[20] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112369,	
2017-07-28 19:32:29,119 Epoch[20] Batch [520]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.112249,	
2017-07-28 19:32:35,024 Epoch[20] Batch [530]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.111932,	
2017-07-28 19:32:40,789 Epoch[20] Batch [540]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.111853,	
2017-07-28 19:32:46,672 Epoch[20] Batch [550]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.111794,	
2017-07-28 19:32:52,618 Epoch[20] Batch [560]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.112089,	
2017-07-28 19:32:58,371 Epoch[20] Batch [570]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.111933,	
2017-07-28 19:33:04,218 Epoch[20] Batch [580]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.111763,	
2017-07-28 19:33:10,068 Epoch[20] Batch [590]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.111774,	
2017-07-28 19:33:15,872 Epoch[20] Batch [600]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111735,	
2017-07-28 19:33:21,682 Epoch[20] Batch [610]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111599,	
2017-07-28 19:33:27,516 Epoch[20] Batch [620]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.111324,	
2017-07-28 19:33:33,269 Epoch[20] Batch [630]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.110920,	
2017-07-28 19:33:39,085 Epoch[20] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110868,	
2017-07-28 19:33:44,870 Epoch[20] Batch [650]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110834,	
2017-07-28 19:33:50,672 Epoch[20] Batch [660]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110864,	
2017-07-28 19:33:56,470 Epoch[20] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110628,	
2017-07-28 19:34:02,274 Epoch[20] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110519,	
2017-07-28 19:34:08,086 Epoch[20] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110530,	
2017-07-28 19:34:13,869 Epoch[20] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110636,	
2017-07-28 19:34:19,668 Epoch[20] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110607,	
2017-07-28 19:34:25,486 Epoch[20] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110564,	
2017-07-28 19:34:31,270 Epoch[20] Batch [730]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110752,	
2017-07-28 19:34:37,078 Epoch[20] Batch [740]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110686,	
2017-07-28 19:34:42,898 Epoch[20] Batch [750]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110680,	
2017-07-28 19:34:48,685 Epoch[20] Batch [760]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110662,	
2017-07-28 19:34:54,499 Epoch[20] Batch [770]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110525,	
2017-07-28 19:35:00,284 Epoch[20] Batch [780]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110442,	
2017-07-28 19:35:06,111 Epoch[20] Batch [790]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110467,	
2017-07-28 19:35:11,915 Epoch[20] Batch [800]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110428,	
2017-07-28 19:35:17,701 Epoch[20] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110390,	
2017-07-28 19:35:23,501 Epoch[20] Batch [820]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110345,	
2017-07-28 19:35:29,292 Epoch[20] Batch [830]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110347,	
2017-07-28 19:35:35,095 Epoch[20] Batch [840]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110235,	
2017-07-28 19:35:40,905 Epoch[20] Batch [850]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110212,	
2017-07-28 19:35:46,682 Epoch[20] Batch [860]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110165,	
2017-07-28 19:35:52,502 Epoch[20] Batch [870]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110107,	
2017-07-28 19:35:58,277 Epoch[20] Batch [880]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110006,	
2017-07-28 19:36:04,074 Epoch[20] Batch [890]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109991,	
2017-07-28 19:36:09,876 Epoch[20] Batch [900]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110045,	
2017-07-28 19:36:15,700 Epoch[20] Batch [910]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110040,	
2017-07-28 19:36:21,467 Epoch[20] Batch [920]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.110031,	
2017-07-28 19:36:27,257 Epoch[20] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110100,	
2017-07-28 19:36:33,111 Epoch[20] Batch [940]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.110081,	
2017-07-28 19:36:38,856 Epoch[20] Batch [950]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.110045,	
2017-07-28 19:36:44,634 Epoch[20] Batch [960]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110082,	
2017-07-28 19:36:50,463 Epoch[20] Batch [970]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110116,	
2017-07-28 19:36:56,259 Epoch[20] Batch [980]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110125,	
2017-07-28 19:37:02,065 Epoch[20] Batch [990]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.109956,	
2017-07-28 19:37:07,869 Epoch[20] Batch [1000]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.109909,	
2017-07-28 19:37:13,674 Epoch[20] Batch [1010]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110017,	
2017-07-28 19:37:19,451 Epoch[20] Batch [1020]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110101,	
2017-07-28 19:37:25,258 Epoch[20] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110057,	
2017-07-28 19:37:31,043 Epoch[20] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110093,	
2017-07-28 19:37:36,828 Epoch[20] Batch [1050]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110025,	
2017-07-28 19:37:42,638 Epoch[20] Batch [1060]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109962,	
2017-07-28 19:37:48,398 Epoch[20] Batch [1070]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.110011,	
2017-07-28 19:37:54,196 Epoch[20] Batch [1080]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110183,	
2017-07-28 19:37:59,981 Epoch[20] Batch [1090]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110231,	
2017-07-28 19:38:04,311 Epoch[20] Batch [1100]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.110236,	
2017-07-28 19:38:10,133 Epoch[20] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110374,	
2017-07-28 19:38:15,912 Epoch[20] Batch [1120]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110485,	
2017-07-28 19:38:21,723 Epoch[20] Batch [1130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110546,	
2017-07-28 19:38:27,545 Epoch[20] Batch [1140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110538,	
2017-07-28 19:38:33,344 Epoch[20] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110489,	
2017-07-28 19:38:39,110 Epoch[20] Batch [1160]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.110444,	
2017-07-28 19:38:44,882 Epoch[20] Batch [1170]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.110508,	
2017-07-28 19:38:50,661 Epoch[20] Batch [1180]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110528,	
2017-07-28 19:38:56,461 Epoch[20] Batch [1190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110422,	
2017-07-28 19:39:02,400 Epoch[20] Batch [1200]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.110450,	
2017-07-28 19:39:08,220 Epoch[20] Batch [1210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110333,	
2017-07-28 19:39:14,007 Epoch[20] Batch [1220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110453,	
2017-07-28 19:39:19,766 Epoch[20] Batch [1230]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.110486,	
2017-07-28 19:39:25,608 Epoch[20] Batch [1240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110497,	
2017-07-28 19:39:31,423 Epoch[20] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110524,	
2017-07-28 19:39:37,214 Epoch[20] Batch [1260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110565,	
2017-07-28 19:39:43,000 Epoch[20] Batch [1270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110474,	
2017-07-28 19:39:48,785 Epoch[20] Batch [1280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110537,	
2017-07-28 19:39:54,606 Epoch[20] Batch [1290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110551,	
2017-07-28 19:40:00,403 Epoch[20] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110555,	
2017-07-28 19:40:06,192 Epoch[20] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110603,	
2017-07-28 19:40:11,989 Epoch[20] Batch [1320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110588,	
2017-07-28 19:40:17,779 Epoch[20] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110582,	
2017-07-28 19:40:23,585 Epoch[20] Batch [1340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110652,	
2017-07-28 19:40:29,404 Epoch[20] Batch [1350]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110716,	
2017-07-28 19:40:35,369 Epoch[20] Batch [1360]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.110744,	
2017-07-28 19:40:41,245 Epoch[20] Batch [1370]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.110905,	
2017-07-28 19:40:47,047 Epoch[20] Batch [1380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111051,	
2017-07-28 19:40:52,820 Epoch[20] Batch [1390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.111178,	
2017-07-28 19:40:58,623 Epoch[20] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111337,	
2017-07-28 19:41:04,614 Epoch[20] Batch [1410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.111375,	
2017-07-28 19:41:10,425 Epoch[20] Batch [1420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111412,	
2017-07-28 19:41:16,233 Epoch[20] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111453,	
2017-07-28 19:41:22,060 Epoch[20] Batch [1440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.111420,	
2017-07-28 19:41:27,868 Epoch[20] Batch [1450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111426,	
2017-07-28 19:41:33,645 Epoch[20] Batch [1460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.111476,	
2017-07-28 19:41:39,449 Epoch[20] Batch [1470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111542,	
2017-07-28 19:41:45,274 Epoch[20] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111606,	
2017-07-28 19:41:48,773 Epoch[20] Train-FCNLogLoss=0.111585
2017-07-28 19:41:48,774 Epoch[20] Time cost=862.455
2017-07-28 19:41:50,505 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.params"
2017-07-28 19:41:52,695 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.states"
2017-07-28 19:41:59,390 Epoch[21] Batch [10]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.123676,	
2017-07-28 19:42:05,222 Epoch[21] Batch [20]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117021,	
2017-07-28 19:42:11,019 Epoch[21] Batch [30]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118592,	
2017-07-28 19:42:16,842 Epoch[21] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117350,	
2017-07-28 19:42:22,653 Epoch[21] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120625,	
2017-07-28 19:42:28,436 Epoch[21] Batch [60]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117797,	
2017-07-28 19:42:34,227 Epoch[21] Batch [70]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117155,	
2017-07-28 19:42:40,020 Epoch[21] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118418,	
2017-07-28 19:42:45,852 Epoch[21] Batch [90]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116340,	
2017-07-28 19:42:51,630 Epoch[21] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115749,	
2017-07-28 19:42:57,427 Epoch[21] Batch [110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114599,	
2017-07-28 19:43:03,239 Epoch[21] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114315,	
2017-07-28 19:43:09,055 Epoch[21] Batch [130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114204,	
2017-07-28 19:43:14,849 Epoch[21] Batch [140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113667,	
2017-07-28 19:43:20,654 Epoch[21] Batch [150]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113527,	
2017-07-28 19:43:26,484 Epoch[21] Batch [160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113592,	
2017-07-28 19:43:32,327 Epoch[21] Batch [170]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.113035,	
2017-07-28 19:43:38,101 Epoch[21] Batch [180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113348,	
2017-07-28 19:43:43,901 Epoch[21] Batch [190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113248,	
2017-07-28 19:43:49,684 Epoch[21] Batch [200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112808,	
2017-07-28 19:43:55,507 Epoch[21] Batch [210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112758,	
2017-07-28 19:44:01,286 Epoch[21] Batch [220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113083,	
2017-07-28 19:44:07,103 Epoch[21] Batch [230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113376,	
2017-07-28 19:44:12,895 Epoch[21] Batch [240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113920,	
2017-07-28 19:44:18,738 Epoch[21] Batch [250]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.113693,	
2017-07-28 19:44:24,494 Epoch[21] Batch [260]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113555,	
2017-07-28 19:44:30,315 Epoch[21] Batch [270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113156,	
2017-07-28 19:44:36,075 Epoch[21] Batch [280]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113070,	
2017-07-28 19:44:41,888 Epoch[21] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112883,	
2017-07-28 19:44:47,680 Epoch[21] Batch [300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112782,	
2017-07-28 19:44:53,471 Epoch[21] Batch [310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112121,	
2017-07-28 19:44:59,273 Epoch[21] Batch [320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112346,	
2017-07-28 19:45:05,083 Epoch[21] Batch [330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112540,	
2017-07-28 19:45:10,884 Epoch[21] Batch [340]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112161,	
2017-07-28 19:45:16,670 Epoch[21] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111992,	
2017-07-28 19:45:22,478 Epoch[21] Batch [360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112380,	
2017-07-28 19:45:28,240 Epoch[21] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.112020,	
2017-07-28 19:45:34,055 Epoch[21] Batch [380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112024,	
2017-07-28 19:45:39,831 Epoch[21] Batch [390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.112067,	
2017-07-28 19:45:45,645 Epoch[21] Batch [400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112048,	
2017-07-28 19:45:51,420 Epoch[21] Batch [410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.111785,	
2017-07-28 19:45:57,300 Epoch[21] Batch [420]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.111490,	
2017-07-28 19:46:03,239 Epoch[21] Batch [430]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.111520,	
2017-07-28 19:46:09,072 Epoch[21] Batch [440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.111258,	
2017-07-28 19:46:14,869 Epoch[21] Batch [450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111400,	
2017-07-28 19:46:20,693 Epoch[21] Batch [460]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111291,	
2017-07-28 19:46:26,432 Epoch[21] Batch [470]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.111332,	
2017-07-28 19:46:32,212 Epoch[21] Batch [480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.111380,	
2017-07-28 19:46:38,034 Epoch[21] Batch [490]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111470,	
2017-07-28 19:46:43,809 Epoch[21] Batch [500]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.111175,	
2017-07-28 19:46:49,597 Epoch[21] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111242,	
2017-07-28 19:46:55,410 Epoch[21] Batch [520]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111115,	
2017-07-28 19:47:01,197 Epoch[21] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110877,	
2017-07-28 19:47:06,999 Epoch[21] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110542,	
2017-07-28 19:47:12,789 Epoch[21] Batch [550]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110735,	
2017-07-28 19:47:18,564 Epoch[21] Batch [560]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110904,	
2017-07-28 19:47:24,443 Epoch[21] Batch [570]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.110978,	
2017-07-28 19:47:30,336 Epoch[21] Batch [580]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.111088,	
2017-07-28 19:47:36,122 Epoch[21] Batch [590]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111150,	
2017-07-28 19:47:42,001 Epoch[21] Batch [600]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.111032,	
2017-07-28 19:47:47,782 Epoch[21] Batch [610]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.111036,	
2017-07-28 19:47:53,579 Epoch[21] Batch [620]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111053,	
2017-07-28 19:47:59,400 Epoch[21] Batch [630]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111160,	
2017-07-28 19:48:05,208 Epoch[21] Batch [640]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111145,	
2017-07-28 19:48:10,985 Epoch[21] Batch [650]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.111142,	
2017-07-28 19:48:16,807 Epoch[21] Batch [660]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111288,	
2017-07-28 19:48:22,561 Epoch[21] Batch [670]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.111185,	
2017-07-28 19:48:28,369 Epoch[21] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111126,	
2017-07-28 19:48:34,161 Epoch[21] Batch [690]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111116,	
2017-07-28 19:48:39,989 Epoch[21] Batch [700]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.111090,	
2017-07-28 19:48:45,827 Epoch[21] Batch [710]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.111209,	
2017-07-28 19:48:51,564 Epoch[21] Batch [720]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.111324,	
2017-07-28 19:48:57,376 Epoch[21] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111176,	
2017-07-28 19:49:03,166 Epoch[21] Batch [740]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111162,	
2017-07-28 19:49:08,990 Epoch[21] Batch [750]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111177,	
2017-07-28 19:49:14,760 Epoch[21] Batch [760]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.111140,	
2017-07-28 19:49:20,563 Epoch[21] Batch [770]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111135,	
2017-07-28 19:49:26,353 Epoch[21] Batch [780]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111220,	
2017-07-28 19:49:32,163 Epoch[21] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111383,	
2017-07-28 19:49:37,955 Epoch[21] Batch [800]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111205,	
2017-07-28 19:49:43,735 Epoch[21] Batch [810]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.111262,	
2017-07-28 19:49:49,547 Epoch[21] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111246,	
2017-07-28 19:49:55,357 Epoch[21] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111257,	
2017-07-28 19:50:01,165 Epoch[21] Batch [840]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111327,	
2017-07-28 19:50:06,952 Epoch[21] Batch [850]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111247,	
2017-07-28 19:50:12,738 Epoch[21] Batch [860]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111242,	
2017-07-28 19:50:18,545 Epoch[21] Batch [870]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111227,	
2017-07-28 19:50:24,375 Epoch[21] Batch [880]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.111227,	
2017-07-28 19:50:30,166 Epoch[21] Batch [890]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111228,	
2017-07-28 19:50:35,965 Epoch[21] Batch [900]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111197,	
2017-07-28 19:50:41,757 Epoch[21] Batch [910]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111214,	
2017-07-28 19:50:47,557 Epoch[21] Batch [920]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111164,	
2017-07-28 19:50:53,375 Epoch[21] Batch [930]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111188,	
2017-07-28 19:50:59,176 Epoch[21] Batch [940]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111178,	
2017-07-28 19:51:04,942 Epoch[21] Batch [950]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.111167,	
2017-07-28 19:51:10,748 Epoch[21] Batch [960]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111126,	
2017-07-28 19:51:16,588 Epoch[21] Batch [970]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.111130,	
2017-07-28 19:51:22,355 Epoch[21] Batch [980]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.111058,	
2017-07-28 19:51:28,165 Epoch[21] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110996,	
2017-07-28 19:51:33,987 Epoch[21] Batch [1000]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110925,	
2017-07-28 19:51:39,798 Epoch[21] Batch [1010]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110831,	
2017-07-28 19:51:45,621 Epoch[21] Batch [1020]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110901,	
2017-07-28 19:51:51,413 Epoch[21] Batch [1030]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110781,	
2017-07-28 19:51:57,212 Epoch[21] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110804,	
2017-07-28 19:52:02,996 Epoch[21] Batch [1050]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110673,	
2017-07-28 19:52:08,816 Epoch[21] Batch [1060]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110707,	
2017-07-28 19:52:14,633 Epoch[21] Batch [1070]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110648,	
2017-07-28 19:52:20,429 Epoch[21] Batch [1080]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110665,	
2017-07-28 19:52:25,068 Epoch[21] Batch [1090]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.110558,	
2017-07-28 19:52:29,974 Epoch[21] Batch [1100]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.110622,	
2017-07-28 19:52:35,772 Epoch[21] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110729,	
2017-07-28 19:52:41,594 Epoch[21] Batch [1120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110760,	
2017-07-28 19:52:47,392 Epoch[21] Batch [1130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110816,	
2017-07-28 19:52:53,226 Epoch[21] Batch [1140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110801,	
2017-07-28 19:52:59,057 Epoch[21] Batch [1150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110807,	
2017-07-28 19:53:04,833 Epoch[21] Batch [1160]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110873,	
2017-07-28 19:53:10,637 Epoch[21] Batch [1170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110805,	
2017-07-28 19:53:16,436 Epoch[21] Batch [1180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110745,	
2017-07-28 19:53:22,237 Epoch[21] Batch [1190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110728,	
2017-07-28 19:53:28,039 Epoch[21] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110786,	
2017-07-28 19:53:33,842 Epoch[21] Batch [1210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110791,	
2017-07-28 19:53:39,685 Epoch[21] Batch [1220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110835,	
2017-07-28 19:53:45,486 Epoch[21] Batch [1230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110825,	
2017-07-28 19:53:51,288 Epoch[21] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110814,	
2017-07-28 19:53:57,155 Epoch[21] Batch [1250]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.110771,	
2017-07-28 19:54:03,118 Epoch[21] Batch [1260]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.110794,	
2017-07-28 19:54:08,880 Epoch[21] Batch [1270]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.110717,	
2017-07-28 19:54:14,721 Epoch[21] Batch [1280]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110770,	
2017-07-28 19:54:20,480 Epoch[21] Batch [1290]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.110852,	
2017-07-28 19:54:26,281 Epoch[21] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110829,	
2017-07-28 19:54:32,137 Epoch[21] Batch [1310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.110766,	
2017-07-28 19:54:37,970 Epoch[21] Batch [1320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110749,	
2017-07-28 19:54:43,740 Epoch[21] Batch [1330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110700,	
2017-07-28 19:54:49,577 Epoch[21] Batch [1340]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110673,	
2017-07-28 19:54:55,367 Epoch[21] Batch [1350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110676,	
2017-07-28 19:55:01,183 Epoch[21] Batch [1360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110556,	
2017-07-28 19:55:07,008 Epoch[21] Batch [1370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110469,	
2017-07-28 19:55:12,709 Epoch[21] Batch [1380]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.110486,	
2017-07-28 19:55:18,528 Epoch[21] Batch [1390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110434,	
2017-07-28 19:55:24,335 Epoch[21] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110406,	
2017-07-28 19:55:30,168 Epoch[21] Batch [1410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110320,	
2017-07-28 19:55:35,974 Epoch[21] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110422,	
2017-07-28 19:55:41,750 Epoch[21] Batch [1430]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110342,	
2017-07-28 19:55:47,547 Epoch[21] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110389,	
2017-07-28 19:55:53,360 Epoch[21] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110340,	
2017-07-28 19:55:59,141 Epoch[21] Batch [1460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110371,	
2017-07-28 19:56:04,912 Epoch[21] Batch [1470]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110324,	
2017-07-28 19:56:10,744 Epoch[21] Batch [1480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110398,	
2017-07-28 19:56:14,202 Epoch[21] Train-FCNLogLoss=0.110335
2017-07-28 19:56:14,203 Epoch[21] Time cost=861.507
2017-07-28 19:56:16,419 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.params"
2017-07-28 19:56:19,092 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.states"
2017-07-28 19:56:25,552 Epoch[22] Batch [10]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.102476,	
2017-07-28 19:56:31,332 Epoch[22] Batch [20]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099392,	
2017-07-28 19:56:37,186 Epoch[22] Batch [30]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099608,	
2017-07-28 19:56:42,990 Epoch[22] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102792,	
2017-07-28 19:56:48,799 Epoch[22] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103402,	
2017-07-28 19:56:54,567 Epoch[22] Batch [60]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103302,	
2017-07-28 19:57:00,384 Epoch[22] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102451,	
2017-07-28 19:57:06,156 Epoch[22] Batch [80]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101982,	
2017-07-28 19:57:11,966 Epoch[22] Batch [90]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103460,	
2017-07-28 19:57:17,773 Epoch[22] Batch [100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103962,	
2017-07-28 19:57:23,565 Epoch[22] Batch [110]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104207,	
2017-07-28 19:57:29,409 Epoch[22] Batch [120]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105695,	
2017-07-28 19:57:35,192 Epoch[22] Batch [130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106299,	
2017-07-28 19:57:40,978 Epoch[22] Batch [140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105722,	
2017-07-28 19:57:46,770 Epoch[22] Batch [150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105832,	
2017-07-28 19:57:52,570 Epoch[22] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105464,	
2017-07-28 19:57:58,382 Epoch[22] Batch [170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105732,	
2017-07-28 19:58:04,186 Epoch[22] Batch [180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105185,	
2017-07-28 19:58:10,016 Epoch[22] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105746,	
2017-07-28 19:58:15,785 Epoch[22] Batch [200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106322,	
2017-07-28 19:58:21,612 Epoch[22] Batch [210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106417,	
2017-07-28 19:58:27,414 Epoch[22] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106128,	
2017-07-28 19:58:33,234 Epoch[22] Batch [230]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106192,	
2017-07-28 19:58:39,021 Epoch[22] Batch [240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106762,	
2017-07-28 19:58:44,838 Epoch[22] Batch [250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106475,	
2017-07-28 19:58:50,623 Epoch[22] Batch [260]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106844,	
2017-07-28 19:58:56,412 Epoch[22] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106882,	
2017-07-28 19:59:02,234 Epoch[22] Batch [280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106450,	
2017-07-28 19:59:07,947 Epoch[22] Batch [290]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.106146,	
2017-07-28 19:59:13,767 Epoch[22] Batch [300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106126,	
2017-07-28 19:59:19,562 Epoch[22] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105940,	
2017-07-28 19:59:25,366 Epoch[22] Batch [320]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106086,	
2017-07-28 19:59:31,211 Epoch[22] Batch [330]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106091,	
2017-07-28 19:59:37,040 Epoch[22] Batch [340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106121,	
2017-07-28 19:59:42,872 Epoch[22] Batch [350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106283,	
2017-07-28 19:59:48,673 Epoch[22] Batch [360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106209,	
2017-07-28 19:59:54,412 Epoch[22] Batch [370]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.105942,	
2017-07-28 20:00:00,197 Epoch[22] Batch [380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106171,	
2017-07-28 20:00:06,033 Epoch[22] Batch [390]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106363,	
2017-07-28 20:00:11,816 Epoch[22] Batch [400]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106288,	
2017-07-28 20:00:17,580 Epoch[22] Batch [410]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106331,	
2017-07-28 20:00:23,409 Epoch[22] Batch [420]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106383,	
2017-07-28 20:00:29,178 Epoch[22] Batch [430]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106457,	
2017-07-28 20:00:34,960 Epoch[22] Batch [440]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.106555,	
2017-07-28 20:00:40,839 Epoch[22] Batch [450]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.106587,	
2017-07-28 20:00:46,671 Epoch[22] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106607,	
2017-07-28 20:00:52,496 Epoch[22] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106733,	
2017-07-28 20:00:58,303 Epoch[22] Batch [480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106586,	
2017-07-28 20:01:04,112 Epoch[22] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106540,	
2017-07-28 20:01:09,851 Epoch[22] Batch [500]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.106654,	
2017-07-28 20:01:15,641 Epoch[22] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107519,	
2017-07-28 20:01:21,482 Epoch[22] Batch [520]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107603,	
2017-07-28 20:01:27,313 Epoch[22] Batch [530]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107941,	
2017-07-28 20:01:33,112 Epoch[22] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108101,	
2017-07-28 20:01:38,927 Epoch[22] Batch [550]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108096,	
2017-07-28 20:01:44,727 Epoch[22] Batch [560]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108155,	
2017-07-28 20:01:50,554 Epoch[22] Batch [570]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108340,	
2017-07-28 20:01:56,346 Epoch[22] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108291,	
2017-07-28 20:02:02,142 Epoch[22] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108396,	
2017-07-28 20:02:07,972 Epoch[22] Batch [600]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108568,	
2017-07-28 20:02:13,773 Epoch[22] Batch [610]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108400,	
2017-07-28 20:02:19,583 Epoch[22] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108397,	
2017-07-28 20:02:25,432 Epoch[22] Batch [630]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.108601,	
2017-07-28 20:02:31,196 Epoch[22] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.108787,	
2017-07-28 20:02:37,033 Epoch[22] Batch [650]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.108669,	
2017-07-28 20:02:42,817 Epoch[22] Batch [660]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108470,	
2017-07-28 20:02:48,618 Epoch[22] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108570,	
2017-07-28 20:02:54,413 Epoch[22] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108521,	
2017-07-28 20:03:00,201 Epoch[22] Batch [690]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108423,	
2017-07-28 20:03:05,993 Epoch[22] Batch [700]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108331,	
2017-07-28 20:03:11,791 Epoch[22] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108268,	
2017-07-28 20:03:17,616 Epoch[22] Batch [720]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108121,	
2017-07-28 20:03:23,402 Epoch[22] Batch [730]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108087,	
2017-07-28 20:03:29,213 Epoch[22] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108174,	
2017-07-28 20:03:35,023 Epoch[22] Batch [750]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108167,	
2017-07-28 20:03:40,827 Epoch[22] Batch [760]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108241,	
2017-07-28 20:03:46,615 Epoch[22] Batch [770]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108232,	
2017-07-28 20:03:52,466 Epoch[22] Batch [780]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.108226,	
2017-07-28 20:03:58,243 Epoch[22] Batch [790]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108201,	
2017-07-28 20:04:04,023 Epoch[22] Batch [800]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108200,	
2017-07-28 20:04:09,832 Epoch[22] Batch [810]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108141,	
2017-07-28 20:04:15,637 Epoch[22] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108193,	
2017-07-28 20:04:21,432 Epoch[22] Batch [830]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108201,	
2017-07-28 20:04:27,240 Epoch[22] Batch [840]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108148,	
2017-07-28 20:04:33,019 Epoch[22] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108063,	
2017-07-28 20:04:38,824 Epoch[22] Batch [860]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107909,	
2017-07-28 20:04:44,636 Epoch[22] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107963,	
2017-07-28 20:04:50,459 Epoch[22] Batch [880]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107904,	
2017-07-28 20:04:56,249 Epoch[22] Batch [890]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108044,	
2017-07-28 20:05:02,079 Epoch[22] Batch [900]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108057,	
2017-07-28 20:05:07,855 Epoch[22] Batch [910]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107984,	
2017-07-28 20:05:13,667 Epoch[22] Batch [920]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107901,	
2017-07-28 20:05:19,494 Epoch[22] Batch [930]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108039,	
2017-07-28 20:05:25,266 Epoch[22] Batch [940]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108039,	
2017-07-28 20:05:31,068 Epoch[22] Batch [950]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107948,	
2017-07-28 20:05:36,886 Epoch[22] Batch [960]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107850,	
2017-07-28 20:05:42,691 Epoch[22] Batch [970]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107991,	
2017-07-28 20:05:48,482 Epoch[22] Batch [980]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107961,	
2017-07-28 20:05:54,287 Epoch[22] Batch [990]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108024,	
2017-07-28 20:06:00,057 Epoch[22] Batch [1000]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108159,	
2017-07-28 20:06:05,855 Epoch[22] Batch [1010]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108210,	
2017-07-28 20:06:11,666 Epoch[22] Batch [1020]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108297,	
2017-07-28 20:06:17,450 Epoch[22] Batch [1030]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108174,	
2017-07-28 20:06:23,234 Epoch[22] Batch [1040]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108154,	
2017-07-28 20:06:29,035 Epoch[22] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108212,	
2017-07-28 20:06:34,830 Epoch[22] Batch [1060]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108165,	
2017-07-28 20:06:40,638 Epoch[22] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108097,	
2017-07-28 20:06:46,467 Epoch[22] Batch [1080]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108144,	
2017-07-28 20:06:50,867 Epoch[22] Batch [1090]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108124,	
2017-07-28 20:06:55,448 Epoch[22] Batch [1100]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.108062,	
2017-07-28 20:07:01,372 Epoch[22] Batch [1110]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107961,	
2017-07-28 20:07:07,243 Epoch[22] Batch [1120]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107974,	
2017-07-28 20:07:13,042 Epoch[22] Batch [1130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107835,	
2017-07-28 20:07:18,845 Epoch[22] Batch [1140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107753,	
2017-07-28 20:07:24,649 Epoch[22] Batch [1150]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107753,	
2017-07-28 20:07:30,460 Epoch[22] Batch [1160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107705,	
2017-07-28 20:07:36,266 Epoch[22] Batch [1170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107700,	
2017-07-28 20:07:42,094 Epoch[22] Batch [1180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107796,	
2017-07-28 20:07:47,901 Epoch[22] Batch [1190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107767,	
2017-07-28 20:07:53,728 Epoch[22] Batch [1200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107761,	
2017-07-28 20:07:59,528 Epoch[22] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107821,	
2017-07-28 20:08:05,333 Epoch[22] Batch [1220]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107808,	
2017-07-28 20:08:11,123 Epoch[22] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107675,	
2017-07-28 20:08:16,975 Epoch[22] Batch [1240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107710,	
2017-07-28 20:08:22,786 Epoch[22] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107903,	
2017-07-28 20:08:28,561 Epoch[22] Batch [1260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107911,	
2017-07-28 20:08:34,373 Epoch[22] Batch [1270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107895,	
2017-07-28 20:08:40,196 Epoch[22] Batch [1280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107903,	
2017-07-28 20:08:46,001 Epoch[22] Batch [1290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107885,	
2017-07-28 20:08:51,807 Epoch[22] Batch [1300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107859,	
2017-07-28 20:08:57,595 Epoch[22] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107818,	
2017-07-28 20:09:03,418 Epoch[22] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107780,	
2017-07-28 20:09:09,256 Epoch[22] Batch [1330]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107750,	
2017-07-28 20:09:15,061 Epoch[22] Batch [1340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107651,	
2017-07-28 20:09:20,881 Epoch[22] Batch [1350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107642,	
2017-07-28 20:09:26,687 Epoch[22] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107632,	
2017-07-28 20:09:32,504 Epoch[22] Batch [1370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107620,	
2017-07-28 20:09:38,295 Epoch[22] Batch [1380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107672,	
2017-07-28 20:09:44,098 Epoch[22] Batch [1390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107760,	
2017-07-28 20:09:49,908 Epoch[22] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107700,	
2017-07-28 20:09:55,744 Epoch[22] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107807,	
2017-07-28 20:10:01,539 Epoch[22] Batch [1420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107799,	
2017-07-28 20:10:07,346 Epoch[22] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107796,	
2017-07-28 20:10:13,160 Epoch[22] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107789,	
2017-07-28 20:10:18,986 Epoch[22] Batch [1450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107854,	
2017-07-28 20:10:24,792 Epoch[22] Batch [1460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107788,	
2017-07-28 20:10:30,598 Epoch[22] Batch [1470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107804,	
2017-07-28 20:10:36,388 Epoch[22] Batch [1480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107866,	
2017-07-28 20:10:39,880 Epoch[22] Train-FCNLogLoss=0.107906
2017-07-28 20:10:39,880 Epoch[22] Time cost=860.787
2017-07-28 20:10:41,459 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.params"
2017-07-28 20:10:44,562 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.states"
2017-07-28 20:10:51,033 Epoch[23] Batch [10]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.109867,	
2017-07-28 20:10:56,827 Epoch[23] Batch [20]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106134,	
2017-07-28 20:11:02,592 Epoch[23] Batch [30]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106650,	
2017-07-28 20:11:08,423 Epoch[23] Batch [40]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106424,	
2017-07-28 20:11:14,222 Epoch[23] Batch [50]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105099,	
2017-07-28 20:11:20,031 Epoch[23] Batch [60]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106923,	
2017-07-28 20:11:25,849 Epoch[23] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105732,	
2017-07-28 20:11:31,696 Epoch[23] Batch [80]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105231,	
2017-07-28 20:11:37,658 Epoch[23] Batch [90]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106581,	
2017-07-28 20:11:43,556 Epoch[23] Batch [100]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108146,	
2017-07-28 20:11:49,357 Epoch[23] Batch [110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108094,	
2017-07-28 20:11:55,143 Epoch[23] Batch [120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109177,	
2017-07-28 20:12:00,943 Epoch[23] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108950,	
2017-07-28 20:12:06,754 Epoch[23] Batch [140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109444,	
2017-07-28 20:12:12,534 Epoch[23] Batch [150]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.109233,	
2017-07-28 20:12:18,341 Epoch[23] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108600,	
2017-07-28 20:12:24,150 Epoch[23] Batch [170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108163,	
2017-07-28 20:12:29,943 Epoch[23] Batch [180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108111,	
2017-07-28 20:12:35,746 Epoch[23] Batch [190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108159,	
2017-07-28 20:12:41,539 Epoch[23] Batch [200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108433,	
2017-07-28 20:12:47,354 Epoch[23] Batch [210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108271,	
2017-07-28 20:12:53,105 Epoch[23] Batch [220]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.107373,	
2017-07-28 20:12:58,964 Epoch[23] Batch [230]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107337,	
2017-07-28 20:13:04,786 Epoch[23] Batch [240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107279,	
2017-07-28 20:13:10,586 Epoch[23] Batch [250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107216,	
2017-07-28 20:13:16,387 Epoch[23] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107056,	
2017-07-28 20:13:22,178 Epoch[23] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106811,	
2017-07-28 20:13:27,997 Epoch[23] Batch [280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106593,	
2017-07-28 20:13:33,790 Epoch[23] Batch [290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106498,	
2017-07-28 20:13:39,586 Epoch[23] Batch [300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106656,	
2017-07-28 20:13:45,406 Epoch[23] Batch [310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106610,	
2017-07-28 20:13:51,231 Epoch[23] Batch [320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108169,	
2017-07-28 20:13:57,000 Epoch[23] Batch [330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107950,	
2017-07-28 20:14:02,792 Epoch[23] Batch [340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108060,	
2017-07-28 20:14:08,617 Epoch[23] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108182,	
2017-07-28 20:14:14,426 Epoch[23] Batch [360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107847,	
2017-07-28 20:14:20,280 Epoch[23] Batch [370]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.108145,	
2017-07-28 20:14:26,049 Epoch[23] Batch [380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108226,	
2017-07-28 20:14:31,831 Epoch[23] Batch [390]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107947,	
2017-07-28 20:14:37,648 Epoch[23] Batch [400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107863,	
2017-07-28 20:14:43,446 Epoch[23] Batch [410]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107935,	
2017-07-28 20:14:49,238 Epoch[23] Batch [420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108278,	
2017-07-28 20:14:55,055 Epoch[23] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108518,	
2017-07-28 20:15:00,846 Epoch[23] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108208,	
2017-07-28 20:15:06,679 Epoch[23] Batch [450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108098,	
2017-07-28 20:15:12,466 Epoch[23] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108162,	
2017-07-28 20:15:18,301 Epoch[23] Batch [470]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108136,	
2017-07-28 20:15:24,077 Epoch[23] Batch [480]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108285,	
2017-07-28 20:15:29,839 Epoch[23] Batch [490]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.108342,	
2017-07-28 20:15:35,641 Epoch[23] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108098,	
2017-07-28 20:15:41,468 Epoch[23] Batch [510]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107879,	
2017-07-28 20:15:47,250 Epoch[23] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108007,	
2017-07-28 20:15:53,054 Epoch[23] Batch [530]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107880,	
2017-07-28 20:15:58,848 Epoch[23] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107872,	
2017-07-28 20:16:04,620 Epoch[23] Batch [550]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107751,	
2017-07-28 20:16:10,425 Epoch[23] Batch [560]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107746,	
2017-07-28 20:16:16,279 Epoch[23] Batch [570]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107773,	
2017-07-28 20:16:22,070 Epoch[23] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107757,	
2017-07-28 20:16:27,908 Epoch[23] Batch [590]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107793,	
2017-07-28 20:16:33,682 Epoch[23] Batch [600]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107567,	
2017-07-28 20:16:39,503 Epoch[23] Batch [610]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107459,	
2017-07-28 20:16:45,271 Epoch[23] Batch [620]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107431,	
2017-07-28 20:16:51,061 Epoch[23] Batch [630]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107476,	
2017-07-28 20:16:56,873 Epoch[23] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107535,	
2017-07-28 20:17:02,707 Epoch[23] Batch [650]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107481,	
2017-07-28 20:17:08,469 Epoch[23] Batch [660]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107509,	
2017-07-28 20:17:14,303 Epoch[23] Batch [670]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107491,	
2017-07-28 20:17:20,073 Epoch[23] Batch [680]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107590,	
2017-07-28 20:17:25,865 Epoch[23] Batch [690]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107731,	
2017-07-28 20:17:31,725 Epoch[23] Batch [700]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107725,	
2017-07-28 20:17:37,463 Epoch[23] Batch [710]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.107827,	
2017-07-28 20:17:43,287 Epoch[23] Batch [720]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107735,	
2017-07-28 20:17:49,097 Epoch[23] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107691,	
2017-07-28 20:17:54,913 Epoch[23] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107524,	
2017-07-28 20:18:00,720 Epoch[23] Batch [750]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107430,	
2017-07-28 20:18:06,520 Epoch[23] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107496,	
2017-07-28 20:18:12,295 Epoch[23] Batch [770]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107404,	
2017-07-28 20:18:18,134 Epoch[23] Batch [780]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107325,	
2017-07-28 20:18:23,934 Epoch[23] Batch [790]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107224,	
2017-07-28 20:18:29,738 Epoch[23] Batch [800]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107180,	
2017-07-28 20:18:35,543 Epoch[23] Batch [810]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107122,	
2017-07-28 20:18:41,327 Epoch[23] Batch [820]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107115,	
2017-07-28 20:18:47,140 Epoch[23] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106990,	
2017-07-28 20:18:52,962 Epoch[23] Batch [840]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107313,	
2017-07-28 20:18:58,794 Epoch[23] Batch [850]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107517,	
2017-07-28 20:19:04,592 Epoch[23] Batch [860]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107773,	
2017-07-28 20:19:10,421 Epoch[23] Batch [870]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107762,	
2017-07-28 20:19:16,211 Epoch[23] Batch [880]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107809,	
2017-07-28 20:19:22,030 Epoch[23] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107852,	
2017-07-28 20:19:28,833 Epoch[23] Batch [900]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.107925,	
2017-07-28 20:19:33,039 Epoch[23] Batch [910]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.108020,	
2017-07-28 20:19:39,405 Epoch[23] Batch [920]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.107955,	
2017-07-28 20:19:44,035 Epoch[23] Batch [930]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.107869,	
2017-07-28 20:19:49,193 Epoch[23] Batch [940]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.107962,	
2017-07-28 20:19:56,908 Epoch[23] Batch [950]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.107876,	
2017-07-28 20:20:02,610 Epoch[23] Batch [960]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107922,	
2017-07-28 20:20:08,751 Epoch[23] Batch [970]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.107918,	
2017-07-28 20:20:15,437 Epoch[23] Batch [980]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.107817,	
2017-07-28 20:20:20,232 Epoch[23] Batch [990]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.107967,	
2017-07-28 20:20:26,236 Epoch[23] Batch [1000]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.108002,	
2017-07-28 20:20:33,818 Epoch[23] Batch [1010]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.107897,	
2017-07-28 20:20:38,162 Epoch[23] Batch [1020]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.107813,	
2017-07-28 20:20:42,687 Epoch[23] Batch [1030]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107746,	
2017-07-28 20:20:47,598 Epoch[23] Batch [1040]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.107698,	
2017-07-28 20:20:55,019 Epoch[23] Batch [1050]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.107593,	
2017-07-28 20:20:59,504 Epoch[23] Batch [1060]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.107533,	
2017-07-28 20:21:05,299 Epoch[23] Batch [1070]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107496,	
2017-07-28 20:21:10,748 Epoch[23] Batch [1080]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.107515,	
2017-07-28 20:21:17,669 Epoch[23] Batch [1090]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.107427,	
2017-07-28 20:21:23,372 Epoch[23] Batch [1100]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.107387,	
2017-07-28 20:21:31,426 Epoch[23] Batch [1110]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.107482,	
2017-07-28 20:21:36,633 Epoch[23] Batch [1120]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.107523,	
2017-07-28 20:21:41,758 Epoch[23] Batch [1130]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.107513,	
2017-07-28 20:21:47,572 Epoch[23] Batch [1140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107444,	
2017-07-28 20:21:55,401 Epoch[23] Batch [1150]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.107516,	
2017-07-28 20:22:01,764 Epoch[23] Batch [1160]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.107581,	
2017-07-28 20:22:06,293 Epoch[23] Batch [1170]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.107505,	
2017-07-28 20:22:11,517 Epoch[23] Batch [1180]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.107502,	
2017-07-28 20:22:17,962 Epoch[23] Batch [1190]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.107485,	
2017-07-28 20:22:23,375 Epoch[23] Batch [1200]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.107543,	
2017-07-28 20:22:28,565 Epoch[23] Batch [1210]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.107461,	
2017-07-28 20:22:34,048 Epoch[23] Batch [1220]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.107425,	
2017-07-28 20:22:42,735 Epoch[23] Batch [1230]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.107321,	
2017-07-28 20:22:48,586 Epoch[23] Batch [1240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107310,	
2017-07-28 20:22:56,290 Epoch[23] Batch [1250]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.107310,	
2017-07-28 20:23:00,493 Epoch[23] Batch [1260]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.107338,	
2017-07-28 20:23:07,728 Epoch[23] Batch [1270]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.107329,	
2017-07-28 20:23:12,442 Epoch[23] Batch [1280]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.107268,	
2017-07-28 20:23:18,374 Epoch[23] Batch [1290]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107326,	
2017-07-28 20:23:24,675 Epoch[23] Batch [1300]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.107307,	
2017-07-28 20:23:29,561 Epoch[23] Batch [1310]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.107404,	
2017-07-28 20:23:35,408 Epoch[23] Batch [1320]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107346,	
2017-07-28 20:23:40,205 Epoch[23] Batch [1330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.107311,	
2017-07-28 20:23:45,898 Epoch[23] Batch [1340]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.107349,	
2017-07-28 20:23:51,069 Epoch[23] Batch [1350]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.107312,	
2017-07-28 20:23:56,456 Epoch[23] Batch [1360]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.107296,	
2017-07-28 20:24:02,967 Epoch[23] Batch [1370]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.107245,	
2017-07-28 20:24:08,450 Epoch[23] Batch [1380]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.107212,	
2017-07-28 20:24:13,231 Epoch[23] Batch [1390]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.107198,	
2017-07-28 20:24:21,068 Epoch[23] Batch [1400]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.107217,	
2017-07-28 20:24:27,960 Epoch[23] Batch [1410]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.107210,	
2017-07-28 20:24:33,964 Epoch[23] Batch [1420]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.107201,	
2017-07-28 20:24:39,259 Epoch[23] Batch [1430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.107214,	
2017-07-28 20:24:46,593 Epoch[23] Batch [1440]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.107243,	
2017-07-28 20:24:51,716 Epoch[23] Batch [1450]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.107240,	
2017-07-28 20:24:58,301 Epoch[23] Batch [1460]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.107150,	
2017-07-28 20:25:03,999 Epoch[23] Batch [1470]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107085,	
2017-07-28 20:25:10,997 Epoch[23] Batch [1480]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.107023,	
2017-07-28 20:25:14,429 Epoch[23] Train-FCNLogLoss=0.107045
2017-07-28 20:25:14,430 Epoch[23] Time cost=869.868
2017-07-28 20:25:17,255 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.params"
2017-07-28 20:25:19,777 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.states"
2017-07-28 20:25:28,364 Epoch[24] Batch [10]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.104058,	
2017-07-28 20:25:33,968 Epoch[24] Batch [20]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.103542,	
2017-07-28 20:25:38,600 Epoch[24] Batch [30]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.100304,	
2017-07-28 20:25:44,384 Epoch[24] Batch [40]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100987,	
2017-07-28 20:25:50,410 Epoch[24] Batch [50]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102056,	
2017-07-28 20:25:55,431 Epoch[24] Batch [60]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.103834,	
2017-07-28 20:26:00,860 Epoch[24] Batch [70]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.105444,	
2017-07-28 20:26:06,182 Epoch[24] Batch [80]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105964,	
2017-07-28 20:26:12,876 Epoch[24] Batch [90]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.106007,	
2017-07-28 20:26:17,783 Epoch[24] Batch [100]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.105184,	
2017-07-28 20:26:23,047 Epoch[24] Batch [110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.104636,	
2017-07-28 20:26:28,244 Epoch[24] Batch [120]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.104071,	
2017-07-28 20:26:33,642 Epoch[24] Batch [130]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.103241,	
2017-07-28 20:26:39,627 Epoch[24] Batch [140]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.103433,	
2017-07-28 20:26:45,514 Epoch[24] Batch [150]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.103766,	
2017-07-28 20:26:52,208 Epoch[24] Batch [160]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.104166,	
2017-07-28 20:26:59,725 Epoch[24] Batch [170]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.104262,	
2017-07-28 20:27:06,953 Epoch[24] Batch [180]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.104205,	
2017-07-28 20:27:13,981 Epoch[24] Batch [190]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.104436,	
2017-07-28 20:27:17,990 Epoch[24] Batch [200]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.104197,	
2017-07-28 20:27:23,629 Epoch[24] Batch [210]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.104481,	
2017-07-28 20:27:28,128 Epoch[24] Batch [220]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.104130,	
2017-07-28 20:27:32,949 Epoch[24] Batch [230]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.104091,	
2017-07-28 20:27:38,975 Epoch[24] Batch [240]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103732,	
2017-07-28 20:27:45,386 Epoch[24] Batch [250]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.103781,	
2017-07-28 20:27:51,549 Epoch[24] Batch [260]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103905,	
2017-07-28 20:27:57,605 Epoch[24] Batch [270]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.104145,	
2017-07-28 20:28:03,035 Epoch[24] Batch [280]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.104497,	
2017-07-28 20:28:10,652 Epoch[24] Batch [290]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.104553,	
2017-07-28 20:28:15,623 Epoch[24] Batch [300]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.104502,	
2017-07-28 20:28:21,193 Epoch[24] Batch [310]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.104579,	
2017-07-28 20:28:26,152 Epoch[24] Batch [320]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.104619,	
2017-07-28 20:28:31,479 Epoch[24] Batch [330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104795,	
2017-07-28 20:28:37,521 Epoch[24] Batch [340]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.104917,	
2017-07-28 20:28:44,221 Epoch[24] Batch [350]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.104551,	
2017-07-28 20:28:49,549 Epoch[24] Batch [360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104687,	
2017-07-28 20:28:55,312 Epoch[24] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.104846,	
2017-07-28 20:29:02,803 Epoch[24] Batch [380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.104768,	
2017-07-28 20:29:10,910 Epoch[24] Batch [390]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.104790,	
2017-07-28 20:29:16,662 Epoch[24] Batch [400]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.104560,	
2017-07-28 20:29:23,172 Epoch[24] Batch [410]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.105875,	
2017-07-28 20:29:29,846 Epoch[24] Batch [420]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.106208,	
2017-07-28 20:29:35,506 Epoch[24] Batch [430]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.106147,	
2017-07-28 20:29:42,393 Epoch[24] Batch [440]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106204,	
2017-07-28 20:29:49,943 Epoch[24] Batch [450]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.106309,	
2017-07-28 20:29:55,481 Epoch[24] Batch [460]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.106554,	
2017-07-28 20:30:00,206 Epoch[24] Batch [470]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.106567,	
2017-07-28 20:30:05,445 Epoch[24] Batch [480]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.106792,	
2017-07-28 20:30:12,708 Epoch[24] Batch [490]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.106607,	
2017-07-28 20:30:18,256 Epoch[24] Batch [500]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.106328,	
2017-07-28 20:30:24,177 Epoch[24] Batch [510]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.106438,	
2017-07-28 20:30:29,780 Epoch[24] Batch [520]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.106422,	
2017-07-28 20:30:35,712 Epoch[24] Batch [530]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106317,	
2017-07-28 20:30:40,540 Epoch[24] Batch [540]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.106154,	
2017-07-28 20:30:46,544 Epoch[24] Batch [550]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106009,	
2017-07-28 20:30:51,030 Epoch[24] Batch [560]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.105983,	
2017-07-28 20:30:56,585 Epoch[24] Batch [570]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.106105,	
2017-07-28 20:31:02,625 Epoch[24] Batch [580]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.106127,	
2017-07-28 20:31:07,167 Epoch[24] Batch [590]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.106134,	
2017-07-28 20:31:11,838 Epoch[24] Batch [600]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106059,	
2017-07-28 20:31:17,871 Epoch[24] Batch [610]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.106093,	
2017-07-28 20:31:22,518 Epoch[24] Batch [620]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.106095,	
2017-07-28 20:31:27,365 Epoch[24] Batch [630]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.106390,	
2017-07-28 20:31:32,287 Epoch[24] Batch [640]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.106423,	
2017-07-28 20:31:37,062 Epoch[24] Batch [650]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.106445,	
2017-07-28 20:31:42,132 Epoch[24] Batch [660]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.106494,	
2017-07-28 20:31:47,157 Epoch[24] Batch [670]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.106503,	
2017-07-28 20:31:52,240 Epoch[24] Batch [680]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.106387,	
2017-07-28 20:31:56,663 Epoch[24] Batch [690]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.106366,	
2017-07-28 20:32:02,866 Epoch[24] Batch [700]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.106314,	
2017-07-28 20:32:08,154 Epoch[24] Batch [710]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.106370,	
2017-07-28 20:32:14,071 Epoch[24] Batch [720]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.106526,	
2017-07-28 20:32:18,932 Epoch[24] Batch [730]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.106924,	
2017-07-28 20:32:25,885 Epoch[24] Batch [740]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.106852,	
2017-07-28 20:32:31,659 Epoch[24] Batch [750]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106761,	
2017-07-28 20:32:37,669 Epoch[24] Batch [760]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106657,	
2017-07-28 20:32:42,943 Epoch[24] Batch [770]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.106725,	
2017-07-28 20:32:49,397 Epoch[24] Batch [780]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.106604,	
2017-07-28 20:32:53,987 Epoch[24] Batch [790]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.106811,	
2017-07-28 20:32:58,863 Epoch[24] Batch [800]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.106702,	
2017-07-28 20:33:04,153 Epoch[24] Batch [810]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.106548,	
2017-07-28 20:33:11,659 Epoch[24] Batch [820]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.106559,	
2017-07-28 20:33:16,583 Epoch[24] Batch [830]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.106563,	
2017-07-28 20:33:21,870 Epoch[24] Batch [840]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.106579,	
2017-07-28 20:33:26,875 Epoch[24] Batch [850]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.106570,	
2017-07-28 20:33:33,329 Epoch[24] Batch [860]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.106610,	
2017-07-28 20:33:38,798 Epoch[24] Batch [870]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.106540,	
2017-07-28 20:33:45,859 Epoch[24] Batch [880]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.106542,	
2017-07-28 20:33:51,157 Epoch[24] Batch [890]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.106602,	
2017-07-28 20:33:57,171 Epoch[24] Batch [900]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.106632,	
2017-07-28 20:34:02,349 Epoch[24] Batch [910]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.106664,	
2017-07-28 20:34:07,252 Epoch[24] Batch [920]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.106530,	
2017-07-28 20:34:14,387 Epoch[24] Batch [930]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.106353,	
2017-07-28 20:34:19,918 Epoch[24] Batch [940]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.106301,	
2017-07-28 20:34:25,745 Epoch[24] Batch [950]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106168,	
2017-07-28 20:34:33,632 Epoch[24] Batch [960]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.106264,	
2017-07-28 20:34:39,736 Epoch[24] Batch [970]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106242,	
2017-07-28 20:34:47,112 Epoch[24] Batch [980]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.106248,	
2017-07-28 20:34:53,299 Epoch[24] Batch [990]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106205,	
2017-07-28 20:34:59,076 Epoch[24] Batch [1000]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106105,	
2017-07-28 20:35:04,515 Epoch[24] Batch [1010]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.106014,	
2017-07-28 20:35:10,114 Epoch[24] Batch [1020]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.106003,	
2017-07-28 20:35:15,837 Epoch[24] Batch [1030]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.106215,	
2017-07-28 20:35:22,432 Epoch[24] Batch [1040]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.106112,	
2017-07-28 20:35:27,328 Epoch[24] Batch [1050]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.106215,	
2017-07-28 20:35:34,462 Epoch[24] Batch [1060]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.106174,	
2017-07-28 20:35:39,780 Epoch[24] Batch [1070]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.106304,	
2017-07-28 20:35:45,185 Epoch[24] Batch [1080]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.106247,	
2017-07-28 20:35:50,193 Epoch[24] Batch [1090]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.106207,	
2017-07-28 20:35:55,574 Epoch[24] Batch [1100]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.106114,	
2017-07-28 20:36:01,581 Epoch[24] Batch [1110]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106101,	
2017-07-28 20:36:07,872 Epoch[24] Batch [1120]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.106187,	
2017-07-28 20:36:13,299 Epoch[24] Batch [1130]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.106169,	
2017-07-28 20:36:18,724 Epoch[24] Batch [1140]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.106114,	
2017-07-28 20:36:24,538 Epoch[24] Batch [1150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106162,	
2017-07-28 20:36:30,359 Epoch[24] Batch [1160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106007,	
2017-07-28 20:36:36,158 Epoch[24] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105949,	
2017-07-28 20:36:41,978 Epoch[24] Batch [1180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105972,	
2017-07-28 20:36:47,766 Epoch[24] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106055,	
2017-07-28 20:36:53,573 Epoch[24] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105978,	
2017-07-28 20:36:59,393 Epoch[24] Batch [1210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106002,	
2017-07-28 20:37:05,210 Epoch[24] Batch [1220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105897,	
2017-07-28 20:37:10,990 Epoch[24] Batch [1230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105840,	
2017-07-28 20:37:16,820 Epoch[24] Batch [1240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105835,	
2017-07-28 20:37:22,621 Epoch[24] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105849,	
2017-07-28 20:37:28,448 Epoch[24] Batch [1260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105824,	
2017-07-28 20:37:34,248 Epoch[24] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105909,	
2017-07-28 20:37:40,064 Epoch[24] Batch [1280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105855,	
2017-07-28 20:37:45,866 Epoch[24] Batch [1290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106010,	
2017-07-28 20:37:51,688 Epoch[24] Batch [1300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105943,	
2017-07-28 20:37:57,501 Epoch[24] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105959,	
2017-07-28 20:38:03,329 Epoch[24] Batch [1320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106108,	
2017-07-28 20:38:09,104 Epoch[24] Batch [1330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106112,	
2017-07-28 20:38:14,894 Epoch[24] Batch [1340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106064,	
2017-07-28 20:38:20,693 Epoch[24] Batch [1350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106009,	
2017-07-28 20:38:26,518 Epoch[24] Batch [1360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105888,	
2017-07-28 20:38:32,319 Epoch[24] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105950,	
2017-07-28 20:38:38,116 Epoch[24] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105900,	
2017-07-28 20:38:43,920 Epoch[24] Batch [1390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105910,	
2017-07-28 20:38:49,779 Epoch[24] Batch [1400]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.105874,	
2017-07-28 20:38:55,538 Epoch[24] Batch [1410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.105943,	
2017-07-28 20:39:01,349 Epoch[24] Batch [1420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105841,	
2017-07-28 20:39:07,148 Epoch[24] Batch [1430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105934,	
2017-07-28 20:39:12,978 Epoch[24] Batch [1440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105899,	
2017-07-28 20:39:18,795 Epoch[24] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105989,	
2017-07-28 20:39:24,577 Epoch[24] Batch [1460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106016,	
2017-07-28 20:39:30,379 Epoch[24] Batch [1470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105979,	
2017-07-28 20:39:36,185 Epoch[24] Batch [1480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105975,	
2017-07-28 20:39:39,684 Epoch[24] Train-FCNLogLoss=0.105949
2017-07-28 20:39:39,685 Epoch[24] Time cost=859.907
2017-07-28 20:39:41,071 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.params"
2017-07-28 20:39:44,082 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.states"
2017-07-28 20:39:50,196 Epoch[25] Batch [10]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096012,	
2017-07-28 20:39:56,004 Epoch[25] Batch [20]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100495,	
2017-07-28 20:40:01,823 Epoch[25] Batch [30]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097489,	
2017-07-28 20:40:07,619 Epoch[25] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098676,	
2017-07-28 20:40:13,437 Epoch[25] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102295,	
2017-07-28 20:40:19,231 Epoch[25] Batch [60]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102088,	
2017-07-28 20:40:25,046 Epoch[25] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101343,	
2017-07-28 20:40:30,852 Epoch[25] Batch [80]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101985,	
2017-07-28 20:40:36,646 Epoch[25] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102422,	
2017-07-28 20:40:42,468 Epoch[25] Batch [100]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101740,	
2017-07-28 20:40:48,233 Epoch[25] Batch [110]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101912,	
2017-07-28 20:40:54,055 Epoch[25] Batch [120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102828,	
2017-07-28 20:40:59,846 Epoch[25] Batch [130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102939,	
2017-07-28 20:41:05,634 Epoch[25] Batch [140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102555,	
2017-07-28 20:41:11,430 Epoch[25] Batch [150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102626,	
2017-07-28 20:41:17,232 Epoch[25] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103047,	
2017-07-28 20:41:23,012 Epoch[25] Batch [170]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102529,	
2017-07-28 20:41:28,811 Epoch[25] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102936,	
2017-07-28 20:41:34,600 Epoch[25] Batch [190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102968,	
2017-07-28 20:41:40,400 Epoch[25] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103112,	
2017-07-28 20:41:46,198 Epoch[25] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103227,	
2017-07-28 20:41:52,033 Epoch[25] Batch [220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102994,	
2017-07-28 20:41:57,804 Epoch[25] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103390,	
2017-07-28 20:42:03,589 Epoch[25] Batch [240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103274,	
2017-07-28 20:42:09,396 Epoch[25] Batch [250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103086,	
2017-07-28 20:42:15,204 Epoch[25] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102822,	
2017-07-28 20:42:20,991 Epoch[25] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102322,	
2017-07-28 20:42:26,790 Epoch[25] Batch [280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102106,	
2017-07-28 20:42:32,575 Epoch[25] Batch [290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101562,	
2017-07-28 20:42:38,425 Epoch[25] Batch [300]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.101307,	
2017-07-28 20:42:44,160 Epoch[25] Batch [310]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.101225,	
2017-07-28 20:42:49,971 Epoch[25] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100993,	
2017-07-28 20:42:55,788 Epoch[25] Batch [330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101191,	
2017-07-28 20:43:01,605 Epoch[25] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100969,	
2017-07-28 20:43:07,414 Epoch[25] Batch [350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100990,	
2017-07-28 20:43:13,240 Epoch[25] Batch [360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101122,	
2017-07-28 20:43:19,053 Epoch[25] Batch [370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101098,	
2017-07-28 20:43:24,846 Epoch[25] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101192,	
2017-07-28 20:43:30,632 Epoch[25] Batch [390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101098,	
2017-07-28 20:43:36,439 Epoch[25] Batch [400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100941,	
2017-07-28 20:43:42,246 Epoch[25] Batch [410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101056,	
2017-07-28 20:43:48,046 Epoch[25] Batch [420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100957,	
2017-07-28 20:43:53,848 Epoch[25] Batch [430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100838,	
2017-07-28 20:43:59,639 Epoch[25] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100930,	
2017-07-28 20:44:05,474 Epoch[25] Batch [450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100849,	
2017-07-28 20:44:11,241 Epoch[25] Batch [460]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101433,	
2017-07-28 20:44:17,040 Epoch[25] Batch [470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101510,	
2017-07-28 20:44:22,859 Epoch[25] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102454,	
2017-07-28 20:44:28,670 Epoch[25] Batch [490]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102731,	
2017-07-28 20:44:34,449 Epoch[25] Batch [500]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102851,	
2017-07-28 20:44:40,252 Epoch[25] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103808,	
2017-07-28 20:44:46,048 Epoch[25] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105368,	
2017-07-28 20:44:51,903 Epoch[25] Batch [530]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106253,	
2017-07-28 20:44:57,691 Epoch[25] Batch [540]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106801,	
2017-07-28 20:45:03,475 Epoch[25] Batch [550]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107743,	
2017-07-28 20:45:09,310 Epoch[25] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108305,	
2017-07-28 20:45:15,082 Epoch[25] Batch [570]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108366,	
2017-07-28 20:45:20,870 Epoch[25] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108493,	
2017-07-28 20:45:26,665 Epoch[25] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108382,	
2017-07-28 20:45:32,488 Epoch[25] Batch [600]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108544,	
2017-07-28 20:45:38,315 Epoch[25] Batch [610]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108671,	
2017-07-28 20:45:44,297 Epoch[25] Batch [620]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.108858,	
2017-07-28 20:45:50,088 Epoch[25] Batch [630]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109200,	
2017-07-28 20:45:55,978 Epoch[25] Batch [640]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.109508,	
2017-07-28 20:46:01,766 Epoch[25] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109545,	
2017-07-28 20:46:07,609 Epoch[25] Batch [660]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.109500,	
2017-07-28 20:46:13,422 Epoch[25] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109424,	
2017-07-28 20:46:19,227 Epoch[25] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.109448,	
2017-07-28 20:46:25,050 Epoch[25] Batch [690]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.109354,	
2017-07-28 20:46:29,044 Epoch[25] Batch [700]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.109347,	
2017-07-28 20:46:34,119 Epoch[25] Batch [710]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.109398,	
2017-07-28 20:46:39,932 Epoch[25] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109219,	
2017-07-28 20:46:45,751 Epoch[25] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109181,	
2017-07-28 20:46:51,533 Epoch[25] Batch [740]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.109052,	
2017-07-28 20:46:57,322 Epoch[25] Batch [750]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109049,	
2017-07-28 20:47:03,197 Epoch[25] Batch [760]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.109083,	
2017-07-28 20:47:09,009 Epoch[25] Batch [770]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108932,	
2017-07-28 20:47:14,825 Epoch[25] Batch [780]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108951,	
2017-07-28 20:47:20,615 Epoch[25] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109060,	
2017-07-28 20:47:26,446 Epoch[25] Batch [800]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.109044,	
2017-07-28 20:47:32,254 Epoch[25] Batch [810]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.109210,	
2017-07-28 20:47:38,065 Epoch[25] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109175,	
2017-07-28 20:47:43,876 Epoch[25] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109272,	
2017-07-28 20:47:49,663 Epoch[25] Batch [840]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109578,	
2017-07-28 20:47:55,490 Epoch[25] Batch [850]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.109673,	
2017-07-28 20:48:01,284 Epoch[25] Batch [860]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109652,	
2017-07-28 20:48:07,076 Epoch[25] Batch [870]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109603,	
2017-07-28 20:48:12,887 Epoch[25] Batch [880]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109473,	
2017-07-28 20:48:18,708 Epoch[25] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.109347,	
2017-07-28 20:48:24,520 Epoch[25] Batch [900]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109197,	
2017-07-28 20:48:30,320 Epoch[25] Batch [910]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109091,	
2017-07-28 20:48:36,135 Epoch[25] Batch [920]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109086,	
2017-07-28 20:48:41,922 Epoch[25] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109007,	
2017-07-28 20:48:47,730 Epoch[25] Batch [940]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108973,	
2017-07-28 20:48:53,556 Epoch[25] Batch [950]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108805,	
2017-07-28 20:48:59,356 Epoch[25] Batch [960]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108782,	
2017-07-28 20:49:05,165 Epoch[25] Batch [970]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108768,	
2017-07-28 20:49:10,969 Epoch[25] Batch [980]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108743,	
2017-07-28 20:49:16,774 Epoch[25] Batch [990]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108694,	
2017-07-28 20:49:22,581 Epoch[25] Batch [1000]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108695,	
2017-07-28 20:49:28,400 Epoch[25] Batch [1010]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108627,	
2017-07-28 20:49:34,193 Epoch[25] Batch [1020]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108586,	
2017-07-28 20:49:40,012 Epoch[25] Batch [1030]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108530,	
2017-07-28 20:49:45,809 Epoch[25] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108502,	
2017-07-28 20:49:51,602 Epoch[25] Batch [1050]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108442,	
2017-07-28 20:49:57,413 Epoch[25] Batch [1060]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108487,	
2017-07-28 20:50:03,220 Epoch[25] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108546,	
2017-07-28 20:50:09,009 Epoch[25] Batch [1080]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108615,	
2017-07-28 20:50:14,876 Epoch[25] Batch [1090]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.108525,	
2017-07-28 20:50:20,651 Epoch[25] Batch [1100]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108496,	
2017-07-28 20:50:26,453 Epoch[25] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108459,	
2017-07-28 20:50:32,244 Epoch[25] Batch [1120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108393,	
2017-07-28 20:50:38,072 Epoch[25] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108299,	
2017-07-28 20:50:43,887 Epoch[25] Batch [1140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108329,	
2017-07-28 20:50:49,659 Epoch[25] Batch [1150]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108379,	
2017-07-28 20:50:55,114 Epoch[25] Batch [1160]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.108328,	
2017-07-28 20:51:00,959 Epoch[25] Batch [1170]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.108308,	
2017-07-28 20:51:06,727 Epoch[25] Batch [1180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108286,	
2017-07-28 20:51:12,544 Epoch[25] Batch [1190]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108268,	
2017-07-28 20:51:18,316 Epoch[25] Batch [1200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108220,	
2017-07-28 20:51:24,115 Epoch[25] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108220,	
2017-07-28 20:51:29,899 Epoch[25] Batch [1220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108190,	
2017-07-28 20:51:35,654 Epoch[25] Batch [1230]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.108093,	
2017-07-28 20:51:41,454 Epoch[25] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108154,	
2017-07-28 20:51:47,256 Epoch[25] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108115,	
2017-07-28 20:51:53,029 Epoch[25] Batch [1260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108079,	
2017-07-28 20:51:58,809 Epoch[25] Batch [1270]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108078,	
2017-07-28 20:52:04,610 Epoch[25] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108019,	
2017-07-28 20:52:10,383 Epoch[25] Batch [1290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107915,	
2017-07-28 20:52:16,199 Epoch[25] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107831,	
2017-07-28 20:52:21,990 Epoch[25] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107746,	
2017-07-28 20:52:27,771 Epoch[25] Batch [1320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107711,	
2017-07-28 20:52:33,566 Epoch[25] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107652,	
2017-07-28 20:52:39,382 Epoch[25] Batch [1340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107653,	
2017-07-28 20:52:45,172 Epoch[25] Batch [1350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107676,	
2017-07-28 20:52:50,966 Epoch[25] Batch [1360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107642,	
2017-07-28 20:52:56,762 Epoch[25] Batch [1370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107583,	
2017-07-28 20:53:02,542 Epoch[25] Batch [1380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107474,	
2017-07-28 20:53:08,330 Epoch[25] Batch [1390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107616,	
2017-07-28 20:53:14,156 Epoch[25] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107593,	
2017-07-28 20:53:19,996 Epoch[25] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107639,	
2017-07-28 20:53:25,807 Epoch[25] Batch [1420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107669,	
2017-07-28 20:53:31,624 Epoch[25] Batch [1430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107652,	
2017-07-28 20:53:37,420 Epoch[25] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107575,	
2017-07-28 20:53:43,191 Epoch[25] Batch [1450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107542,	
2017-07-28 20:53:49,038 Epoch[25] Batch [1460]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107627,	
2017-07-28 20:53:54,767 Epoch[25] Batch [1470]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.107648,	
2017-07-28 20:54:00,559 Epoch[25] Batch [1480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107594,	
2017-07-28 20:54:04,018 Epoch[25] Train-FCNLogLoss=0.107623
2017-07-28 20:54:04,018 Epoch[25] Time cost=859.936
2017-07-28 20:54:05,189 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.params"
2017-07-28 20:54:07,711 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.states"
2017-07-28 20:54:13,871 Epoch[26] Batch [10]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099499,	
2017-07-28 20:54:19,586 Epoch[26] Batch [20]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.100037,	
2017-07-28 20:54:25,379 Epoch[26] Batch [30]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099819,	
2017-07-28 20:54:31,203 Epoch[26] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100337,	
2017-07-28 20:54:37,012 Epoch[26] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099507,	
2017-07-28 20:54:42,817 Epoch[26] Batch [60]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099340,	
2017-07-28 20:54:48,620 Epoch[26] Batch [70]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097238,	
2017-07-28 20:54:54,404 Epoch[26] Batch [80]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098398,	
2017-07-28 20:54:59,901 Epoch[26] Batch [90]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098823,	
2017-07-28 20:55:05,531 Epoch[26] Batch [100]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.099239,	
2017-07-28 20:55:11,214 Epoch[26] Batch [110]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.099568,	
2017-07-28 20:55:16,796 Epoch[26] Batch [120]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098686,	
2017-07-28 20:55:22,624 Epoch[26] Batch [130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098532,	
2017-07-28 20:55:28,409 Epoch[26] Batch [140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098063,	
2017-07-28 20:55:34,213 Epoch[26] Batch [150]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098073,	
2017-07-28 20:55:40,019 Epoch[26] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098435,	
2017-07-28 20:55:45,867 Epoch[26] Batch [170]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098837,	
2017-07-28 20:55:51,687 Epoch[26] Batch [180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099609,	
2017-07-28 20:55:57,496 Epoch[26] Batch [190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099197,	
2017-07-28 20:56:03,292 Epoch[26] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099443,	
2017-07-28 20:56:09,109 Epoch[26] Batch [210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099325,	
2017-07-28 20:56:14,930 Epoch[26] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099625,	
2017-07-28 20:56:20,740 Epoch[26] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099998,	
2017-07-28 20:56:26,507 Epoch[26] Batch [240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099685,	
2017-07-28 20:56:32,323 Epoch[26] Batch [250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099090,	
2017-07-28 20:56:38,144 Epoch[26] Batch [260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098863,	
2017-07-28 20:56:43,921 Epoch[26] Batch [270]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099155,	
2017-07-28 20:56:49,745 Epoch[26] Batch [280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099536,	
2017-07-28 20:56:55,563 Epoch[26] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099751,	
2017-07-28 20:57:01,376 Epoch[26] Batch [300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099751,	
2017-07-28 20:57:07,230 Epoch[26] Batch [310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099973,	
2017-07-28 20:57:13,012 Epoch[26] Batch [320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100431,	
2017-07-28 20:57:18,843 Epoch[26] Batch [330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100636,	
2017-07-28 20:57:24,628 Epoch[26] Batch [340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100796,	
2017-07-28 20:57:30,445 Epoch[26] Batch [350]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100618,	
2017-07-28 20:57:36,241 Epoch[26] Batch [360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100875,	
2017-07-28 20:57:42,047 Epoch[26] Batch [370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100958,	
2017-07-28 20:57:47,882 Epoch[26] Batch [380]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100939,	
2017-07-28 20:57:53,676 Epoch[26] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100953,	
2017-07-28 20:57:59,504 Epoch[26] Batch [400]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101111,	
2017-07-28 20:58:05,291 Epoch[26] Batch [410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101177,	
2017-07-28 20:58:11,104 Epoch[26] Batch [420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101358,	
2017-07-28 20:58:16,936 Epoch[26] Batch [430]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101326,	
2017-07-28 20:58:22,724 Epoch[26] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101265,	
2017-07-28 20:58:28,515 Epoch[26] Batch [450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101392,	
2017-07-28 20:58:34,307 Epoch[26] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101589,	
2017-07-28 20:58:40,076 Epoch[26] Batch [470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101542,	
2017-07-28 20:58:45,903 Epoch[26] Batch [480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101503,	
2017-07-28 20:58:51,653 Epoch[26] Batch [490]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101465,	
2017-07-28 20:58:57,479 Epoch[26] Batch [500]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101423,	
2017-07-28 20:59:03,274 Epoch[26] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101394,	
2017-07-28 20:59:09,086 Epoch[26] Batch [520]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101453,	
2017-07-28 20:59:14,904 Epoch[26] Batch [530]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101558,	
2017-07-28 20:59:20,686 Epoch[26] Batch [540]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102092,	
2017-07-28 20:59:26,521 Epoch[26] Batch [550]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102209,	
2017-07-28 20:59:32,289 Epoch[26] Batch [560]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.102522,	
2017-07-28 20:59:37,750 Epoch[26] Batch [570]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.102520,	
2017-07-28 20:59:43,075 Epoch[26] Batch [580]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.102355,	
2017-07-28 20:59:48,831 Epoch[26] Batch [590]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.102413,	
2017-07-28 20:59:54,625 Epoch[26] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102406,	
2017-07-28 21:00:00,494 Epoch[26] Batch [610]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.102476,	
2017-07-28 21:00:06,243 Epoch[26] Batch [620]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.102362,	
2017-07-28 21:00:12,073 Epoch[26] Batch [630]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102196,	
2017-07-28 21:00:17,912 Epoch[26] Batch [640]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102060,	
2017-07-28 21:00:23,697 Epoch[26] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101970,	
2017-07-28 21:00:29,534 Epoch[26] Batch [660]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101833,	
2017-07-28 21:00:35,341 Epoch[26] Batch [670]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101809,	
2017-07-28 21:00:41,140 Epoch[26] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101725,	
2017-07-28 21:00:46,929 Epoch[26] Batch [690]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101908,	
2017-07-28 21:00:52,755 Epoch[26] Batch [700]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101925,	
2017-07-28 21:00:57,355 Epoch[26] Batch [710]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.101954,	
2017-07-28 21:01:02,486 Epoch[26] Batch [720]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.102019,	
2017-07-28 21:01:08,365 Epoch[26] Batch [730]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.101943,	
2017-07-28 21:01:14,183 Epoch[26] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101892,	
2017-07-28 21:01:20,023 Epoch[26] Batch [750]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101750,	
2017-07-28 21:01:25,805 Epoch[26] Batch [760]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101678,	
2017-07-28 21:01:31,553 Epoch[26] Batch [770]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101647,	
2017-07-28 21:01:37,398 Epoch[26] Batch [780]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.101827,	
2017-07-28 21:01:43,184 Epoch[26] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101812,	
2017-07-28 21:01:48,996 Epoch[26] Batch [800]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101874,	
2017-07-28 21:01:54,781 Epoch[26] Batch [810]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101793,	
2017-07-28 21:02:00,355 Epoch[26] Batch [820]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.101701,	
2017-07-28 21:02:05,910 Epoch[26] Batch [830]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.101709,	
2017-07-28 21:02:11,769 Epoch[26] Batch [840]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.101672,	
2017-07-28 21:02:17,542 Epoch[26] Batch [850]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101820,	
2017-07-28 21:02:23,350 Epoch[26] Batch [860]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101951,	
2017-07-28 21:02:29,149 Epoch[26] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102006,	
2017-07-28 21:02:34,873 Epoch[26] Batch [880]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.102190,	
2017-07-28 21:02:40,494 Epoch[26] Batch [890]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.102224,	
2017-07-28 21:02:46,273 Epoch[26] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102240,	
2017-07-28 21:02:51,974 Epoch[26] Batch [910]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.102239,	
2017-07-28 21:02:57,643 Epoch[26] Batch [920]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.102288,	
2017-07-28 21:03:03,420 Epoch[26] Batch [930]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102262,	
2017-07-28 21:03:09,209 Epoch[26] Batch [940]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102301,	
2017-07-28 21:03:14,987 Epoch[26] Batch [950]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102224,	
2017-07-28 21:03:20,706 Epoch[26] Batch [960]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.102276,	
2017-07-28 21:03:26,254 Epoch[26] Batch [970]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.102381,	
2017-07-28 21:03:32,034 Epoch[26] Batch [980]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102490,	
2017-07-28 21:03:37,863 Epoch[26] Batch [990]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102481,	
2017-07-28 21:03:43,584 Epoch[26] Batch [1000]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.102418,	
2017-07-28 21:03:49,381 Epoch[26] Batch [1010]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102461,	
2017-07-28 21:03:55,175 Epoch[26] Batch [1020]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102360,	
2017-07-28 21:04:00,962 Epoch[26] Batch [1030]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102307,	
2017-07-28 21:04:06,752 Epoch[26] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102240,	
2017-07-28 21:04:12,547 Epoch[26] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102288,	
2017-07-28 21:04:18,322 Epoch[26] Batch [1060]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.102327,	
2017-07-28 21:04:23,933 Epoch[26] Batch [1070]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102354,	
2017-07-28 21:04:29,655 Epoch[26] Batch [1080]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.102413,	
2017-07-28 21:04:35,436 Epoch[26] Batch [1090]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102352,	
2017-07-28 21:04:41,312 Epoch[26] Batch [1100]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.102391,	
2017-07-28 21:04:47,108 Epoch[26] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102353,	
2017-07-28 21:04:52,908 Epoch[26] Batch [1120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102337,	
2017-07-28 21:04:58,688 Epoch[26] Batch [1130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102251,	
2017-07-28 21:05:04,521 Epoch[26] Batch [1140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102319,	
2017-07-28 21:05:10,337 Epoch[26] Batch [1150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102390,	
2017-07-28 21:05:16,173 Epoch[26] Batch [1160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102380,	
2017-07-28 21:05:21,986 Epoch[26] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102366,	
2017-07-28 21:05:27,794 Epoch[26] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102378,	
2017-07-28 21:05:33,586 Epoch[26] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102407,	
2017-07-28 21:05:39,371 Epoch[26] Batch [1200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102437,	
2017-07-28 21:05:45,201 Epoch[26] Batch [1210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102420,	
2017-07-28 21:05:51,001 Epoch[26] Batch [1220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102467,	
2017-07-28 21:05:56,827 Epoch[26] Batch [1230]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102392,	
2017-07-28 21:06:02,642 Epoch[26] Batch [1240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102368,	
2017-07-28 21:06:08,436 Epoch[26] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102396,	
2017-07-28 21:06:14,257 Epoch[26] Batch [1260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102373,	
2017-07-28 21:06:20,046 Epoch[26] Batch [1270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102378,	
2017-07-28 21:06:25,774 Epoch[26] Batch [1280]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.102473,	
2017-07-28 21:06:31,576 Epoch[26] Batch [1290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102368,	
2017-07-28 21:06:37,418 Epoch[26] Batch [1300]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102327,	
2017-07-28 21:06:43,180 Epoch[26] Batch [1310]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102409,	
2017-07-28 21:06:49,006 Epoch[26] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102498,	
2017-07-28 21:06:54,758 Epoch[26] Batch [1330]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.102493,	
2017-07-28 21:07:00,434 Epoch[26] Batch [1340]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.102483,	
2017-07-28 21:07:06,202 Epoch[26] Batch [1350]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102433,	
2017-07-28 21:07:12,005 Epoch[26] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102455,	
2017-07-28 21:07:17,803 Epoch[26] Batch [1370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102421,	
2017-07-28 21:07:23,590 Epoch[26] Batch [1380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102460,	
2017-07-28 21:07:29,401 Epoch[26] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102521,	
2017-07-28 21:07:35,183 Epoch[26] Batch [1400]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102530,	
2017-07-28 21:07:40,493 Epoch[26] Batch [1410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.102537,	
2017-07-28 21:07:45,938 Epoch[26] Batch [1420]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.102588,	
2017-07-28 21:07:51,388 Epoch[26] Batch [1430]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.102651,	
2017-07-28 21:07:56,698 Epoch[26] Batch [1440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.102668,	
2017-07-28 21:08:01,947 Epoch[26] Batch [1450]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.102636,	
2017-07-28 21:08:07,790 Epoch[26] Batch [1460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102592,	
2017-07-28 21:08:13,596 Epoch[26] Batch [1470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102536,	
2017-07-28 21:08:19,434 Epoch[26] Batch [1480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102496,	
2017-07-28 21:08:22,605 Epoch[26] Train-FCNLogLoss=0.102491
2017-07-28 21:08:22,605 Epoch[26] Time cost=854.893
2017-07-28 21:08:24,476 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.params"
2017-07-28 21:08:26,820 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.states"
2017-07-28 21:08:33,077 Epoch[27] Batch [10]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.110953,	
2017-07-28 21:08:38,868 Epoch[27] Batch [20]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109530,	
2017-07-28 21:08:44,692 Epoch[27] Batch [30]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107628,	
2017-07-28 21:08:50,482 Epoch[27] Batch [40]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107404,	
2017-07-28 21:08:56,335 Epoch[27] Batch [50]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107620,	
2017-07-28 21:09:02,314 Epoch[27] Batch [60]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.108594,	
2017-07-28 21:09:08,085 Epoch[27] Batch [70]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107897,	
2017-07-28 21:09:13,962 Epoch[27] Batch [80]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106636,	
2017-07-28 21:09:19,800 Epoch[27] Batch [90]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107912,	
2017-07-28 21:09:25,596 Epoch[27] Batch [100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110767,	
2017-07-28 21:09:31,433 Epoch[27] Batch [110]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.111924,	
2017-07-28 21:09:37,228 Epoch[27] Batch [120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111845,	
2017-07-28 21:09:43,039 Epoch[27] Batch [130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112375,	
2017-07-28 21:09:48,879 Epoch[27] Batch [140]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.112391,	
2017-07-28 21:09:54,630 Epoch[27] Batch [150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.112406,	
2017-07-28 21:10:00,363 Epoch[27] Batch [160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.112483,	
2017-07-28 21:10:06,243 Epoch[27] Batch [170]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.112323,	
2017-07-28 21:10:12,105 Epoch[27] Batch [180]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.111168,	
2017-07-28 21:10:17,889 Epoch[27] Batch [190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.111032,	
2017-07-28 21:10:23,710 Epoch[27] Batch [200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110394,	
2017-07-28 21:10:29,514 Epoch[27] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.109919,	
2017-07-28 21:10:35,351 Epoch[27] Batch [220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110429,	
2017-07-28 21:10:41,124 Epoch[27] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110476,	
2017-07-28 21:10:46,903 Epoch[27] Batch [240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110530,	
2017-07-28 21:10:52,698 Epoch[27] Batch [250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110196,	
2017-07-28 21:10:58,490 Epoch[27] Batch [260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109984,	
2017-07-28 21:11:04,312 Epoch[27] Batch [270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110978,	
2017-07-28 21:11:10,121 Epoch[27] Batch [280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110726,	
2017-07-28 21:11:15,920 Epoch[27] Batch [290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110921,	
2017-07-28 21:11:21,709 Epoch[27] Batch [300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110910,	
2017-07-28 21:11:27,494 Epoch[27] Batch [310]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110490,	
2017-07-28 21:11:33,196 Epoch[27] Batch [320]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.110307,	
2017-07-28 21:11:38,974 Epoch[27] Batch [330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110173,	
2017-07-28 21:11:44,340 Epoch[27] Batch [340]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.109779,	
2017-07-28 21:11:49,948 Epoch[27] Batch [350]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.109533,	
2017-07-28 21:11:55,657 Epoch[27] Batch [360]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.109384,	
2017-07-28 21:12:01,448 Epoch[27] Batch [370]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109107,	
2017-07-28 21:12:07,245 Epoch[27] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108921,	
2017-07-28 21:12:13,049 Epoch[27] Batch [390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108925,	
2017-07-28 21:12:18,827 Epoch[27] Batch [400]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108810,	
2017-07-28 21:12:24,636 Epoch[27] Batch [410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108474,	
2017-07-28 21:12:30,375 Epoch[27] Batch [420]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.108305,	
2017-07-28 21:12:36,146 Epoch[27] Batch [430]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108170,	
2017-07-28 21:12:41,773 Epoch[27] Batch [440]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.107834,	
2017-07-28 21:12:47,293 Epoch[27] Batch [450]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.108478,	
2017-07-28 21:12:53,022 Epoch[27] Batch [460]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.108320,	
2017-07-28 21:12:58,610 Epoch[27] Batch [470]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.108005,	
2017-07-28 21:13:04,169 Epoch[27] Batch [480]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.107891,	
2017-07-28 21:13:09,784 Epoch[27] Batch [490]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.107696,	
2017-07-28 21:13:15,325 Epoch[27] Batch [500]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.107375,	
2017-07-28 21:13:21,175 Epoch[27] Batch [510]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107510,	
2017-07-28 21:13:27,006 Epoch[27] Batch [520]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107373,	
2017-07-28 21:13:32,813 Epoch[27] Batch [530]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107516,	
2017-07-28 21:13:38,582 Epoch[27] Batch [540]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107232,	
2017-07-28 21:13:44,398 Epoch[27] Batch [550]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106964,	
2017-07-28 21:13:50,213 Epoch[27] Batch [560]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106779,	
2017-07-28 21:13:56,024 Epoch[27] Batch [570]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106855,	
2017-07-28 21:14:01,847 Epoch[27] Batch [580]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106787,	
2017-07-28 21:14:07,684 Epoch[27] Batch [590]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106810,	
2017-07-28 21:14:13,496 Epoch[27] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106613,	
2017-07-28 21:14:19,334 Epoch[27] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106449,	
2017-07-28 21:14:25,139 Epoch[27] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106345,	
2017-07-28 21:14:30,953 Epoch[27] Batch [630]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106190,	
2017-07-28 21:14:36,768 Epoch[27] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106325,	
2017-07-28 21:14:42,594 Epoch[27] Batch [650]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106054,	
2017-07-28 21:14:48,392 Epoch[27] Batch [660]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106044,	
2017-07-28 21:14:54,212 Epoch[27] Batch [670]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106105,	
2017-07-28 21:15:00,068 Epoch[27] Batch [680]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106551,	
2017-07-28 21:15:05,862 Epoch[27] Batch [690]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107245,	
2017-07-28 21:15:11,651 Epoch[27] Batch [700]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107464,	
2017-07-28 21:15:17,452 Epoch[27] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107471,	
2017-07-28 21:15:23,263 Epoch[27] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107595,	
2017-07-28 21:15:29,117 Epoch[27] Batch [730]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107710,	
2017-07-28 21:15:33,712 Epoch[27] Batch [740]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107753,	
2017-07-28 21:15:38,397 Epoch[27] Batch [750]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.107643,	
2017-07-28 21:15:43,716 Epoch[27] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.107510,	
2017-07-28 21:15:49,366 Epoch[27] Batch [770]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.107421,	
2017-07-28 21:15:55,150 Epoch[27] Batch [780]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107630,	
2017-07-28 21:16:00,849 Epoch[27] Batch [790]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107743,	
2017-07-28 21:16:06,716 Epoch[27] Batch [800]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.107743,	
2017-07-28 21:16:12,508 Epoch[27] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107814,	
2017-07-28 21:16:18,287 Epoch[27] Batch [820]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107658,	
2017-07-28 21:16:24,138 Epoch[27] Batch [830]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107524,	
2017-07-28 21:16:29,929 Epoch[27] Batch [840]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107545,	
2017-07-28 21:16:35,706 Epoch[27] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107469,	
2017-07-28 21:16:41,431 Epoch[27] Batch [860]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107488,	
2017-07-28 21:16:47,229 Epoch[27] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107488,	
2017-07-28 21:16:53,019 Epoch[27] Batch [880]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107465,	
2017-07-28 21:16:58,849 Epoch[27] Batch [890]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107372,	
2017-07-28 21:17:04,613 Epoch[27] Batch [900]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107368,	
2017-07-28 21:17:10,175 Epoch[27] Batch [910]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.107285,	
2017-07-28 21:17:16,018 Epoch[27] Batch [920]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107344,	
2017-07-28 21:17:21,806 Epoch[27] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107162,	
2017-07-28 21:17:27,616 Epoch[27] Batch [940]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107139,	
2017-07-28 21:17:33,439 Epoch[27] Batch [950]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107072,	
2017-07-28 21:17:39,233 Epoch[27] Batch [960]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106956,	
2017-07-28 21:17:45,076 Epoch[27] Batch [970]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106925,	
2017-07-28 21:17:50,886 Epoch[27] Batch [980]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106746,	
2017-07-28 21:17:56,662 Epoch[27] Batch [990]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106801,	
2017-07-28 21:18:02,477 Epoch[27] Batch [1000]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106817,	
2017-07-28 21:18:08,314 Epoch[27] Batch [1010]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106830,	
2017-07-28 21:18:14,080 Epoch[27] Batch [1020]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106933,	
2017-07-28 21:18:19,889 Epoch[27] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107054,	
2017-07-28 21:18:25,693 Epoch[27] Batch [1040]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106890,	
2017-07-28 21:18:31,482 Epoch[27] Batch [1050]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106821,	
2017-07-28 21:18:37,245 Epoch[27] Batch [1060]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106821,	
2017-07-28 21:18:42,747 Epoch[27] Batch [1070]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.106883,	
2017-07-28 21:18:48,149 Epoch[27] Batch [1080]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.106902,	
2017-07-28 21:18:53,582 Epoch[27] Batch [1090]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.106784,	
2017-07-28 21:18:59,028 Epoch[27] Batch [1100]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.106766,	
2017-07-28 21:19:04,732 Epoch[27] Batch [1110]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.106715,	
2017-07-28 21:19:10,435 Epoch[27] Batch [1120]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.106768,	
2017-07-28 21:19:16,136 Epoch[27] Batch [1130]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.106921,	
2017-07-28 21:19:21,844 Epoch[27] Batch [1140]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.106926,	
2017-07-28 21:19:27,554 Epoch[27] Batch [1150]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.107004,	
2017-07-28 21:19:33,211 Epoch[27] Batch [1160]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.106923,	
2017-07-28 21:19:39,023 Epoch[27] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106890,	
2017-07-28 21:19:44,812 Epoch[27] Batch [1180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106827,	
2017-07-28 21:19:50,645 Epoch[27] Batch [1190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106841,	
2017-07-28 21:19:56,427 Epoch[27] Batch [1200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106733,	
2017-07-28 21:20:02,236 Epoch[27] Batch [1210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106628,	
2017-07-28 21:20:08,061 Epoch[27] Batch [1220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106583,	
2017-07-28 21:20:13,819 Epoch[27] Batch [1230]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106609,	
2017-07-28 21:20:19,553 Epoch[27] Batch [1240]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106559,	
2017-07-28 21:20:24,830 Epoch[27] Batch [1250]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.106564,	
2017-07-28 21:20:30,247 Epoch[27] Batch [1260]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.106544,	
2017-07-28 21:20:35,784 Epoch[27] Batch [1270]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.106575,	
2017-07-28 21:20:41,255 Epoch[27] Batch [1280]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.106556,	
2017-07-28 21:20:47,077 Epoch[27] Batch [1290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106438,	
2017-07-28 21:20:52,812 Epoch[27] Batch [1300]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106359,	
2017-07-28 21:20:58,129 Epoch[27] Batch [1310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.106300,	
2017-07-28 21:21:03,485 Epoch[27] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.106297,	
2017-07-28 21:21:09,307 Epoch[27] Batch [1330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106239,	
2017-07-28 21:21:15,141 Epoch[27] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106265,	
2017-07-28 21:21:20,857 Epoch[27] Batch [1350]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.106329,	
2017-07-28 21:21:26,430 Epoch[27] Batch [1360]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.106279,	
2017-07-28 21:21:32,183 Epoch[27] Batch [1370]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106190,	
2017-07-28 21:21:37,980 Epoch[27] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106147,	
2017-07-28 21:21:43,720 Epoch[27] Batch [1390]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.106110,	
2017-07-28 21:21:49,242 Epoch[27] Batch [1400]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.106058,	
2017-07-28 21:21:55,081 Epoch[27] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106006,	
2017-07-28 21:22:00,880 Epoch[27] Batch [1420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106109,	
2017-07-28 21:22:06,698 Epoch[27] Batch [1430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106037,	
2017-07-28 21:22:12,522 Epoch[27] Batch [1440]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106002,	
2017-07-28 21:22:18,348 Epoch[27] Batch [1450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106018,	
2017-07-28 21:22:24,139 Epoch[27] Batch [1460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106011,	
2017-07-28 21:22:29,902 Epoch[27] Batch [1470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106056,	
2017-07-28 21:22:35,742 Epoch[27] Batch [1480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106029,	
2017-07-28 21:22:39,256 Epoch[27] Train-FCNLogLoss=0.106016
2017-07-28 21:22:39,256 Epoch[27] Time cost=852.436
2017-07-28 21:22:41,115 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.params"
2017-07-28 21:22:43,689 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.states"
2017-07-28 21:22:50,347 Epoch[28] Batch [10]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086175,	
2017-07-28 21:22:56,117 Epoch[28] Batch [20]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.091946,	
2017-07-28 21:23:01,908 Epoch[28] Batch [30]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095985,	
2017-07-28 21:23:07,688 Epoch[28] Batch [40]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.094708,	
2017-07-28 21:23:13,460 Epoch[28] Batch [50]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096204,	
2017-07-28 21:23:19,330 Epoch[28] Batch [60]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.096416,	
2017-07-28 21:23:25,128 Epoch[28] Batch [70]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097026,	
2017-07-28 21:23:30,940 Epoch[28] Batch [80]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097017,	
2017-07-28 21:23:36,749 Epoch[28] Batch [90]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097623,	
2017-07-28 21:23:42,594 Epoch[28] Batch [100]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.097400,	
2017-07-28 21:23:48,373 Epoch[28] Batch [110]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099260,	
2017-07-28 21:23:54,191 Epoch[28] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099411,	
2017-07-28 21:23:59,985 Epoch[28] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100285,	
2017-07-28 21:24:05,756 Epoch[28] Batch [140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100026,	
2017-07-28 21:24:11,573 Epoch[28] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100480,	
2017-07-28 21:24:17,409 Epoch[28] Batch [160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100645,	
2017-07-28 21:24:23,201 Epoch[28] Batch [170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101250,	
2017-07-28 21:24:28,997 Epoch[28] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100920,	
2017-07-28 21:24:34,706 Epoch[28] Batch [190]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100788,	
2017-07-28 21:24:40,530 Epoch[28] Batch [200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100635,	
2017-07-28 21:24:46,311 Epoch[28] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100364,	
2017-07-28 21:24:52,142 Epoch[28] Batch [220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100533,	
2017-07-28 21:24:57,917 Epoch[28] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100059,	
2017-07-28 21:25:03,539 Epoch[28] Batch [240]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.100236,	
2017-07-28 21:25:09,317 Epoch[28] Batch [250]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100249,	
2017-07-28 21:25:15,133 Epoch[28] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100099,	
2017-07-28 21:25:20,919 Epoch[28] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100003,	
2017-07-28 21:25:26,732 Epoch[28] Batch [280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099551,	
2017-07-28 21:25:32,539 Epoch[28] Batch [290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099372,	
2017-07-28 21:25:38,238 Epoch[28] Batch [300]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.099230,	
2017-07-28 21:25:43,807 Epoch[28] Batch [310]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.099245,	
2017-07-28 21:25:49,207 Epoch[28] Batch [320]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.099475,	
2017-07-28 21:25:54,801 Epoch[28] Batch [330]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099084,	
2017-07-28 21:26:00,711 Epoch[28] Batch [340]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099020,	
2017-07-28 21:26:06,262 Epoch[28] Batch [350]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.099000,	
2017-07-28 21:26:12,111 Epoch[28] Batch [360]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.099094,	
2017-07-28 21:26:17,999 Epoch[28] Batch [370]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.099407,	
2017-07-28 21:26:23,776 Epoch[28] Batch [380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099327,	
2017-07-28 21:26:29,641 Epoch[28] Batch [390]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.099337,	
2017-07-28 21:26:35,460 Epoch[28] Batch [400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099498,	
2017-07-28 21:26:41,210 Epoch[28] Batch [410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099655,	
2017-07-28 21:26:47,023 Epoch[28] Batch [420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099809,	
2017-07-28 21:26:52,666 Epoch[28] Batch [430]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.099777,	
2017-07-28 21:26:58,510 Epoch[28] Batch [440]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100046,	
2017-07-28 21:27:04,331 Epoch[28] Batch [450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099874,	
2017-07-28 21:27:10,141 Epoch[28] Batch [460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099990,	
2017-07-28 21:27:15,992 Epoch[28] Batch [470]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.099975,	
2017-07-28 21:27:21,783 Epoch[28] Batch [480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099993,	
2017-07-28 21:27:27,587 Epoch[28] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100266,	
2017-07-28 21:27:33,380 Epoch[28] Batch [500]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100220,	
2017-07-28 21:27:39,184 Epoch[28] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100402,	
2017-07-28 21:27:44,992 Epoch[28] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100435,	
2017-07-28 21:27:50,822 Epoch[28] Batch [530]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100343,	
2017-07-28 21:27:56,643 Epoch[28] Batch [540]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100451,	
2017-07-28 21:28:02,484 Epoch[28] Batch [550]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100572,	
2017-07-28 21:28:08,280 Epoch[28] Batch [560]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100579,	
2017-07-28 21:28:14,088 Epoch[28] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100528,	
2017-07-28 21:28:19,888 Epoch[28] Batch [580]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100583,	
2017-07-28 21:28:25,738 Epoch[28] Batch [590]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100623,	
2017-07-28 21:28:31,313 Epoch[28] Batch [600]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.100641,	
2017-07-28 21:28:37,102 Epoch[28] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100770,	
2017-07-28 21:28:42,913 Epoch[28] Batch [620]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100641,	
2017-07-28 21:28:48,753 Epoch[28] Batch [630]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100551,	
2017-07-28 21:28:54,476 Epoch[28] Batch [640]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.100610,	
2017-07-28 21:28:59,844 Epoch[28] Batch [650]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100588,	
2017-07-28 21:29:05,665 Epoch[28] Batch [660]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100528,	
2017-07-28 21:29:11,410 Epoch[28] Batch [670]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.100635,	
2017-07-28 21:29:16,708 Epoch[28] Batch [680]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100540,	
2017-07-28 21:29:22,066 Epoch[28] Batch [690]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100441,	
2017-07-28 21:29:27,316 Epoch[28] Batch [700]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.100452,	
2017-07-28 21:29:32,414 Epoch[28] Batch [710]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.100611,	
2017-07-28 21:29:37,790 Epoch[28] Batch [720]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.100675,	
2017-07-28 21:29:43,060 Epoch[28] Batch [730]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100749,	
2017-07-28 21:29:48,325 Epoch[28] Batch [740]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.100588,	
2017-07-28 21:29:53,713 Epoch[28] Batch [750]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.100538,	
2017-07-28 21:29:58,964 Epoch[28] Batch [760]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.100563,	
2017-07-28 21:30:04,693 Epoch[28] Batch [770]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.100571,	
2017-07-28 21:30:10,311 Epoch[28] Batch [780]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.100620,	
2017-07-28 21:30:16,146 Epoch[28] Batch [790]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100409,	
2017-07-28 21:30:20,462 Epoch[28] Batch [800]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.100456,	
2017-07-28 21:30:26,174 Epoch[28] Batch [810]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.100415,	
2017-07-28 21:30:31,937 Epoch[28] Batch [820]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100545,	
2017-07-28 21:30:37,754 Epoch[28] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100869,	
2017-07-28 21:30:43,581 Epoch[28] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100906,	
2017-07-28 21:30:49,408 Epoch[28] Batch [850]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101044,	
2017-07-28 21:30:55,213 Epoch[28] Batch [860]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101135,	
2017-07-28 21:31:00,921 Epoch[28] Batch [870]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.101305,	
2017-07-28 21:31:06,672 Epoch[28] Batch [880]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101255,	
2017-07-28 21:31:12,440 Epoch[28] Batch [890]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101194,	
2017-07-28 21:31:18,274 Epoch[28] Batch [900]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101227,	
2017-07-28 21:31:24,045 Epoch[28] Batch [910]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101296,	
2017-07-28 21:31:29,868 Epoch[28] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101394,	
2017-07-28 21:31:35,668 Epoch[28] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101370,	
2017-07-28 21:31:41,468 Epoch[28] Batch [940]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101307,	
2017-07-28 21:31:47,265 Epoch[28] Batch [950]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101227,	
2017-07-28 21:31:53,063 Epoch[28] Batch [960]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101178,	
2017-07-28 21:31:58,854 Epoch[28] Batch [970]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101326,	
2017-07-28 21:32:04,673 Epoch[28] Batch [980]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101208,	
2017-07-28 21:32:10,450 Epoch[28] Batch [990]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101161,	
2017-07-28 21:32:16,188 Epoch[28] Batch [1000]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.101128,	
2017-07-28 21:32:22,080 Epoch[28] Batch [1010]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.101249,	
2017-07-28 21:32:27,879 Epoch[28] Batch [1020]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101236,	
2017-07-28 21:32:33,691 Epoch[28] Batch [1030]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101250,	
2017-07-28 21:32:39,474 Epoch[28] Batch [1040]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101299,	
2017-07-28 21:32:45,330 Epoch[28] Batch [1050]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.101234,	
2017-07-28 21:32:51,139 Epoch[28] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101238,	
2017-07-28 21:32:56,919 Epoch[28] Batch [1070]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101187,	
2017-07-28 21:33:02,746 Epoch[28] Batch [1080]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101266,	
2017-07-28 21:33:08,554 Epoch[28] Batch [1090]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101264,	
2017-07-28 21:33:14,348 Epoch[28] Batch [1100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101207,	
2017-07-28 21:33:20,167 Epoch[28] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101170,	
2017-07-28 21:33:25,695 Epoch[28] Batch [1120]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.101252,	
2017-07-28 21:33:31,384 Epoch[28] Batch [1130]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.101352,	
2017-07-28 21:33:36,920 Epoch[28] Batch [1140]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.101305,	
2017-07-28 21:33:42,577 Epoch[28] Batch [1150]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.101365,	
2017-07-28 21:33:48,419 Epoch[28] Batch [1160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101460,	
2017-07-28 21:33:54,170 Epoch[28] Batch [1170]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101501,	
2017-07-28 21:33:59,971 Epoch[28] Batch [1180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101605,	
2017-07-28 21:34:05,731 Epoch[28] Batch [1190]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101591,	
2017-07-28 21:34:11,538 Epoch[28] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101510,	
2017-07-28 21:34:17,344 Epoch[28] Batch [1210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101484,	
2017-07-28 21:34:23,113 Epoch[28] Batch [1220]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101529,	
2017-07-28 21:34:28,808 Epoch[28] Batch [1230]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.101524,	
2017-07-28 21:34:34,080 Epoch[28] Batch [1240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.101558,	
2017-07-28 21:34:39,930 Epoch[28] Batch [1250]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.101557,	
2017-07-28 21:34:45,692 Epoch[28] Batch [1260]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101546,	
2017-07-28 21:34:51,507 Epoch[28] Batch [1270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101514,	
2017-07-28 21:34:57,190 Epoch[28] Batch [1280]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.101509,	
2017-07-28 21:35:03,079 Epoch[28] Batch [1290]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.101459,	
2017-07-28 21:35:08,887 Epoch[28] Batch [1300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101486,	
2017-07-28 21:35:14,635 Epoch[28] Batch [1310]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101539,	
2017-07-28 21:35:20,453 Epoch[28] Batch [1320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101461,	
2017-07-28 21:35:26,243 Epoch[28] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101450,	
2017-07-28 21:35:32,005 Epoch[28] Batch [1340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101577,	
2017-07-28 21:35:37,703 Epoch[28] Batch [1350]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.101561,	
2017-07-28 21:35:43,475 Epoch[28] Batch [1360]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101493,	
2017-07-28 21:35:49,255 Epoch[28] Batch [1370]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101552,	
2017-07-28 21:35:55,070 Epoch[28] Batch [1380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101525,	
2017-07-28 21:36:00,895 Epoch[28] Batch [1390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101555,	
2017-07-28 21:36:06,664 Epoch[28] Batch [1400]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101470,	
2017-07-28 21:36:12,284 Epoch[28] Batch [1410]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101467,	
2017-07-28 21:36:18,106 Epoch[28] Batch [1420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101403,	
2017-07-28 21:36:23,927 Epoch[28] Batch [1430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101418,	
2017-07-28 21:36:29,737 Epoch[28] Batch [1440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101437,	
2017-07-28 21:36:35,525 Epoch[28] Batch [1450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101402,	
2017-07-28 21:36:41,374 Epoch[28] Batch [1460]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.101396,	
2017-07-28 21:36:47,176 Epoch[28] Batch [1470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101440,	
2017-07-28 21:36:53,000 Epoch[28] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101388,	
2017-07-28 21:36:56,476 Epoch[28] Train-FCNLogLoss=0.101379
2017-07-28 21:36:56,477 Epoch[28] Time cost=852.787
2017-07-28 21:36:58,581 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.params"
2017-07-28 21:37:01,136 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.states"
2017-07-28 21:37:07,736 Epoch[29] Batch [10]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100854,	
2017-07-28 21:37:13,595 Epoch[29] Batch [20]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099608,	
2017-07-28 21:37:19,385 Epoch[29] Batch [30]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097055,	
2017-07-28 21:37:25,220 Epoch[29] Batch [40]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098964,	
2017-07-28 21:37:31,029 Epoch[29] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098665,	
2017-07-28 21:37:36,850 Epoch[29] Batch [60]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099199,	
2017-07-28 21:37:42,657 Epoch[29] Batch [70]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099566,	
2017-07-28 21:37:48,445 Epoch[29] Batch [80]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099996,	
2017-07-28 21:37:53,991 Epoch[29] Batch [90]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.099530,	
2017-07-28 21:37:59,770 Epoch[29] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099798,	
2017-07-28 21:38:05,588 Epoch[29] Batch [110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100466,	
2017-07-28 21:38:11,405 Epoch[29] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099576,	
2017-07-28 21:38:16,846 Epoch[29] Batch [130]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.099171,	
2017-07-28 21:38:22,472 Epoch[29] Batch [140]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.099517,	
2017-07-28 21:38:28,002 Epoch[29] Batch [150]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098610,	
2017-07-28 21:38:33,776 Epoch[29] Batch [160]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099416,	
2017-07-28 21:38:39,595 Epoch[29] Batch [170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099505,	
2017-07-28 21:38:45,316 Epoch[29] Batch [180]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.099691,	
2017-07-28 21:38:51,114 Epoch[29] Batch [190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098790,	
2017-07-28 21:38:56,889 Epoch[29] Batch [200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099021,	
2017-07-28 21:39:02,692 Epoch[29] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098833,	
2017-07-28 21:39:08,447 Epoch[29] Batch [220]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098857,	
2017-07-28 21:39:14,219 Epoch[29] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099042,	
2017-07-28 21:39:19,950 Epoch[29] Batch [240]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099025,	
2017-07-28 21:39:25,801 Epoch[29] Batch [250]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.099541,	
2017-07-28 21:39:31,639 Epoch[29] Batch [260]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099706,	
2017-07-28 21:39:37,476 Epoch[29] Batch [270]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099934,	
2017-07-28 21:39:43,260 Epoch[29] Batch [280]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099973,	
2017-07-28 21:39:49,068 Epoch[29] Batch [290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099691,	
2017-07-28 21:39:54,887 Epoch[29] Batch [300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099641,	
2017-07-28 21:40:00,705 Epoch[29] Batch [310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099330,	
2017-07-28 21:40:06,531 Epoch[29] Batch [320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099399,	
2017-07-28 21:40:12,329 Epoch[29] Batch [330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099518,	
2017-07-28 21:40:18,116 Epoch[29] Batch [340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099636,	
2017-07-28 21:40:23,935 Epoch[29] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099674,	
2017-07-28 21:40:29,753 Epoch[29] Batch [360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099627,	
2017-07-28 21:40:35,553 Epoch[29] Batch [370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099620,	
2017-07-28 21:40:41,332 Epoch[29] Batch [380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099651,	
2017-07-28 21:40:47,142 Epoch[29] Batch [390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099717,	
2017-07-28 21:40:52,938 Epoch[29] Batch [400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099827,	
2017-07-28 21:40:58,668 Epoch[29] Batch [410]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099728,	
2017-07-28 21:41:04,454 Epoch[29] Batch [420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099717,	
2017-07-28 21:41:10,254 Epoch[29] Batch [430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099707,	
2017-07-28 21:41:16,045 Epoch[29] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099752,	
2017-07-28 21:41:21,885 Epoch[29] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099719,	
2017-07-28 21:41:27,686 Epoch[29] Batch [460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099542,	
2017-07-28 21:41:33,481 Epoch[29] Batch [470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099715,	
2017-07-28 21:41:39,302 Epoch[29] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099631,	
2017-07-28 21:41:45,093 Epoch[29] Batch [490]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099583,	
2017-07-28 21:41:50,948 Epoch[29] Batch [500]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099925,	
2017-07-28 21:41:56,740 Epoch[29] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100162,	
2017-07-28 21:42:02,540 Epoch[29] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100030,	
2017-07-28 21:42:08,308 Epoch[29] Batch [530]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100154,	
2017-07-28 21:42:14,069 Epoch[29] Batch [540]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100008,	
2017-07-28 21:42:19,839 Epoch[29] Batch [550]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099905,	
2017-07-28 21:42:25,596 Epoch[29] Batch [560]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099909,	
2017-07-28 21:42:30,961 Epoch[29] Batch [570]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100205,	
2017-07-28 21:42:36,778 Epoch[29] Batch [580]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100248,	
2017-07-28 21:42:42,569 Epoch[29] Batch [590]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100521,	
2017-07-28 21:42:48,355 Epoch[29] Batch [600]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100558,	
2017-07-28 21:42:54,086 Epoch[29] Batch [610]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.100725,	
2017-07-28 21:42:59,892 Epoch[29] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100655,	
2017-07-28 21:43:05,640 Epoch[29] Batch [630]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.100610,	
2017-07-28 21:43:11,288 Epoch[29] Batch [640]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.100705,	
2017-07-28 21:43:17,085 Epoch[29] Batch [650]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100764,	
2017-07-28 21:43:22,776 Epoch[29] Batch [660]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.100704,	
2017-07-28 21:43:28,433 Epoch[29] Batch [670]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.100544,	
2017-07-28 21:43:34,039 Epoch[29] Batch [680]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.100574,	
2017-07-28 21:43:39,522 Epoch[29] Batch [690]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.100701,	
2017-07-28 21:43:45,089 Epoch[29] Batch [700]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.100812,	
2017-07-28 21:43:50,888 Epoch[29] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100633,	
2017-07-28 21:43:56,669 Epoch[29] Batch [720]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100560,	
2017-07-28 21:44:02,261 Epoch[29] Batch [730]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.100663,	
2017-07-28 21:44:07,941 Epoch[29] Batch [740]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.100614,	
2017-07-28 21:44:13,212 Epoch[29] Batch [750]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100565,	
2017-07-28 21:44:18,841 Epoch[29] Batch [760]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.100432,	
2017-07-28 21:44:24,476 Epoch[29] Batch [770]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.100306,	
2017-07-28 21:44:30,031 Epoch[29] Batch [780]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.100463,	
2017-07-28 21:44:35,817 Epoch[29] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100399,	
2017-07-28 21:44:41,687 Epoch[29] Batch [800]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.100461,	
2017-07-28 21:44:47,279 Epoch[29] Batch [810]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.100515,	
2017-07-28 21:44:52,650 Epoch[29] Batch [820]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100577,	
2017-07-28 21:44:56,616 Epoch[29] Batch [830]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.100610,	
2017-07-28 21:45:01,926 Epoch[29] Batch [840]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100472,	
2017-07-28 21:45:07,819 Epoch[29] Batch [850]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.100533,	
2017-07-28 21:45:13,618 Epoch[29] Batch [860]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100709,	
2017-07-28 21:45:19,418 Epoch[29] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100756,	
2017-07-28 21:45:25,218 Epoch[29] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101149,	
2017-07-28 21:45:31,049 Epoch[29] Batch [890]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101191,	
2017-07-28 21:45:36,828 Epoch[29] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101249,	
2017-07-28 21:45:42,628 Epoch[29] Batch [910]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101271,	
2017-07-28 21:45:48,435 Epoch[29] Batch [920]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101345,	
2017-07-28 21:45:54,240 Epoch[29] Batch [930]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101366,	
2017-07-28 21:46:00,082 Epoch[29] Batch [940]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101496,	
2017-07-28 21:46:05,863 Epoch[29] Batch [950]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101523,	
2017-07-28 21:46:11,653 Epoch[29] Batch [960]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101599,	
2017-07-28 21:46:17,464 Epoch[29] Batch [970]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101487,	
2017-07-28 21:46:23,294 Epoch[29] Batch [980]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101561,	
2017-07-28 21:46:29,093 Epoch[29] Batch [990]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101475,	
2017-07-28 21:46:34,654 Epoch[29] Batch [1000]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.101404,	
2017-07-28 21:46:40,370 Epoch[29] Batch [1010]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101526,	
2017-07-28 21:46:46,107 Epoch[29] Batch [1020]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.101461,	
2017-07-28 21:46:51,293 Epoch[29] Batch [1030]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.101491,	
2017-07-28 21:46:56,600 Epoch[29] Batch [1040]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101418,	
2017-07-28 21:47:02,094 Epoch[29] Batch [1050]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.101322,	
2017-07-28 21:47:07,603 Epoch[29] Batch [1060]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.101321,	
2017-07-28 21:47:13,144 Epoch[29] Batch [1070]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.101388,	
2017-07-28 21:47:18,552 Epoch[29] Batch [1080]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.101392,	
2017-07-28 21:47:24,329 Epoch[29] Batch [1090]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101376,	
2017-07-28 21:47:29,846 Epoch[29] Batch [1100]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.101342,	
2017-07-28 21:47:35,455 Epoch[29] Batch [1110]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.101339,	
2017-07-28 21:47:41,295 Epoch[29] Batch [1120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101308,	
2017-07-28 21:47:47,044 Epoch[29] Batch [1130]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101287,	
2017-07-28 21:47:52,794 Epoch[29] Batch [1140]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101283,	
2017-07-28 21:47:58,630 Epoch[29] Batch [1150]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101343,	
2017-07-28 21:48:03,969 Epoch[29] Batch [1160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101303,	
2017-07-28 21:48:09,667 Epoch[29] Batch [1170]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.101236,	
2017-07-28 21:48:15,068 Epoch[29] Batch [1180]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.101115,	
2017-07-28 21:48:20,871 Epoch[29] Batch [1190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101167,	
2017-07-28 21:48:26,709 Epoch[29] Batch [1200]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101007,	
2017-07-28 21:48:32,548 Epoch[29] Batch [1210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100923,	
2017-07-28 21:48:38,292 Epoch[29] Batch [1220]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.100890,	
2017-07-28 21:48:44,133 Epoch[29] Batch [1230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101037,	
2017-07-28 21:48:49,693 Epoch[29] Batch [1240]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.101031,	
2017-07-28 21:48:55,484 Epoch[29] Batch [1250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100976,	
2017-07-28 21:49:00,988 Epoch[29] Batch [1260]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.100953,	
2017-07-28 21:49:06,683 Epoch[29] Batch [1270]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.100854,	
2017-07-28 21:49:12,507 Epoch[29] Batch [1280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100828,	
2017-07-28 21:49:18,280 Epoch[29] Batch [1290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100718,	
2017-07-28 21:49:24,078 Epoch[29] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100651,	
2017-07-28 21:49:29,888 Epoch[29] Batch [1310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100607,	
2017-07-28 21:49:35,704 Epoch[29] Batch [1320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100664,	
2017-07-28 21:49:41,446 Epoch[29] Batch [1330]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100676,	
2017-07-28 21:49:47,071 Epoch[29] Batch [1340]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.100623,	
2017-07-28 21:49:52,902 Epoch[29] Batch [1350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100607,	
2017-07-28 21:49:58,719 Epoch[29] Batch [1360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100640,	
2017-07-28 21:50:04,476 Epoch[29] Batch [1370]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.100682,	
2017-07-28 21:50:10,280 Epoch[29] Batch [1380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100715,	
2017-07-28 21:50:16,125 Epoch[29] Batch [1390]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100698,	
2017-07-28 21:50:21,665 Epoch[29] Batch [1400]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.100675,	
2017-07-28 21:50:26,998 Epoch[29] Batch [1410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100727,	
2017-07-28 21:50:32,593 Epoch[29] Batch [1420]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.100713,	
2017-07-28 21:50:38,383 Epoch[29] Batch [1430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100720,	
2017-07-28 21:50:44,209 Epoch[29] Batch [1440]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100748,	
2017-07-28 21:50:50,025 Epoch[29] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100734,	
2017-07-28 21:50:55,812 Epoch[29] Batch [1460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100778,	
2017-07-28 21:51:01,372 Epoch[29] Batch [1470]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.100764,	
2017-07-28 21:51:06,892 Epoch[29] Batch [1480]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.100783,	
2017-07-28 21:51:10,098 Epoch[29] Train-FCNLogLoss=0.100748
2017-07-28 21:51:10,098 Epoch[29] Time cost=848.962
2017-07-28 21:51:12,242 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.params"
2017-07-28 21:51:14,779 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.states"
2017-07-28 21:51:20,997 Epoch[30] Batch [10]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.117013,	
2017-07-28 21:51:26,716 Epoch[30] Batch [20]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.108147,	
2017-07-28 21:51:32,088 Epoch[30] Batch [30]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.105226,	
2017-07-28 21:51:37,829 Epoch[30] Batch [40]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.105837,	
2017-07-28 21:51:43,147 Epoch[30] Batch [50]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105963,	
2017-07-28 21:51:48,782 Epoch[30] Batch [60]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.103918,	
2017-07-28 21:51:54,554 Epoch[30] Batch [70]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103186,	
2017-07-28 21:52:00,372 Epoch[30] Batch [80]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103290,	
2017-07-28 21:52:06,169 Epoch[30] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102931,	
2017-07-28 21:52:11,725 Epoch[30] Batch [100]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.103621,	
2017-07-28 21:52:17,298 Epoch[30] Batch [110]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.103341,	
2017-07-28 21:52:23,007 Epoch[30] Batch [120]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.103358,	
2017-07-28 21:52:28,543 Epoch[30] Batch [130]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.105303,	
2017-07-28 21:52:34,104 Epoch[30] Batch [140]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.106846,	
2017-07-28 21:52:39,959 Epoch[30] Batch [150]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107935,	
2017-07-28 21:52:45,819 Epoch[30] Batch [160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.108951,	
2017-07-28 21:52:51,616 Epoch[30] Batch [170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112403,	
2017-07-28 21:52:57,424 Epoch[30] Batch [180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113619,	
2017-07-28 21:53:03,225 Epoch[30] Batch [190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113811,	
2017-07-28 21:53:09,010 Epoch[30] Batch [200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113929,	
2017-07-28 21:53:14,830 Epoch[30] Batch [210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114443,	
2017-07-28 21:53:20,620 Epoch[30] Batch [220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114197,	
2017-07-28 21:53:26,397 Epoch[30] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113296,	
2017-07-28 21:53:32,219 Epoch[30] Batch [240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112630,	
2017-07-28 21:53:38,050 Epoch[30] Batch [250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.112213,	
2017-07-28 21:53:43,857 Epoch[30] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111847,	
2017-07-28 21:53:49,658 Epoch[30] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111370,	
2017-07-28 21:53:55,471 Epoch[30] Batch [280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110824,	
2017-07-28 21:54:01,292 Epoch[30] Batch [290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110673,	
2017-07-28 21:54:07,065 Epoch[30] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110367,	
2017-07-28 21:54:12,893 Epoch[30] Batch [310]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.109969,	
2017-07-28 21:54:18,689 Epoch[30] Batch [320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109416,	
2017-07-28 21:54:24,522 Epoch[30] Batch [330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.109179,	
2017-07-28 21:54:30,331 Epoch[30] Batch [340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108890,	
2017-07-28 21:54:36,129 Epoch[30] Batch [350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108490,	
2017-07-28 21:54:41,951 Epoch[30] Batch [360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108620,	
2017-07-28 21:54:47,746 Epoch[30] Batch [370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108169,	
2017-07-28 21:54:53,548 Epoch[30] Batch [380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107815,	
2017-07-28 21:54:59,352 Epoch[30] Batch [390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107540,	
2017-07-28 21:55:05,132 Epoch[30] Batch [400]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107197,	
2017-07-28 21:55:10,700 Epoch[30] Batch [410]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.106958,	
2017-07-28 21:55:16,520 Epoch[30] Batch [420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106838,	
2017-07-28 21:55:22,094 Epoch[30] Batch [430]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.106657,	
2017-07-28 21:55:27,847 Epoch[30] Batch [440]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106702,	
2017-07-28 21:55:33,623 Epoch[30] Batch [450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106641,	
2017-07-28 21:55:39,432 Epoch[30] Batch [460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106396,	
2017-07-28 21:55:45,053 Epoch[30] Batch [470]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.105983,	
2017-07-28 21:55:50,840 Epoch[30] Batch [480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105779,	
2017-07-28 21:55:56,636 Epoch[30] Batch [490]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105528,	
2017-07-28 21:56:02,392 Epoch[30] Batch [500]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.105305,	
2017-07-28 21:56:08,193 Epoch[30] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105139,	
2017-07-28 21:56:13,574 Epoch[30] Batch [520]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.105127,	
2017-07-28 21:56:19,325 Epoch[30] Batch [530]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105030,	
2017-07-28 21:56:25,121 Epoch[30] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.104948,	
2017-07-28 21:56:30,871 Epoch[30] Batch [550]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.104718,	
2017-07-28 21:56:36,673 Epoch[30] Batch [560]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104601,	
2017-07-28 21:56:42,469 Epoch[30] Batch [570]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.104481,	
2017-07-28 21:56:48,063 Epoch[30] Batch [580]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.104452,	
2017-07-28 21:56:53,614 Epoch[30] Batch [590]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.104371,	
2017-07-28 21:56:59,453 Epoch[30] Batch [600]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.104272,	
2017-07-28 21:57:05,020 Epoch[30] Batch [610]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.104376,	
2017-07-28 21:57:10,612 Epoch[30] Batch [620]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.104224,	
2017-07-28 21:57:16,389 Epoch[30] Batch [630]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104147,	
2017-07-28 21:57:22,170 Epoch[30] Batch [640]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103873,	
2017-07-28 21:57:27,949 Epoch[30] Batch [650]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103842,	
2017-07-28 21:57:33,622 Epoch[30] Batch [660]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.103668,	
2017-07-28 21:57:39,335 Epoch[30] Batch [670]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.103556,	
2017-07-28 21:57:45,012 Epoch[30] Batch [680]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.103368,	
2017-07-28 21:57:50,823 Epoch[30] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103373,	
2017-07-28 21:57:56,590 Epoch[30] Batch [700]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103209,	
2017-07-28 21:58:02,202 Epoch[30] Batch [710]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.103188,	
2017-07-28 21:58:08,038 Epoch[30] Batch [720]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103112,	
2017-07-28 21:58:13,561 Epoch[30] Batch [730]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.103125,	
2017-07-28 21:58:19,067 Epoch[30] Batch [740]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.103145,	
2017-07-28 21:58:24,476 Epoch[30] Batch [750]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.103175,	
2017-07-28 21:58:30,082 Epoch[30] Batch [760]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.103147,	
2017-07-28 21:58:35,810 Epoch[30] Batch [770]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.103258,	
2017-07-28 21:58:41,482 Epoch[30] Batch [780]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.103110,	
2017-07-28 21:58:47,309 Epoch[30] Batch [790]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103286,	
2017-07-28 21:58:53,128 Epoch[30] Batch [800]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103469,	
2017-07-28 21:58:58,922 Epoch[30] Batch [810]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103348,	
2017-07-28 21:59:04,738 Epoch[30] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103360,	
2017-07-28 21:59:10,543 Epoch[30] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103304,	
2017-07-28 21:59:16,386 Epoch[30] Batch [840]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103311,	
2017-07-28 21:59:22,173 Epoch[30] Batch [850]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103332,	
2017-07-28 21:59:27,960 Epoch[30] Batch [860]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103409,	
2017-07-28 21:59:33,794 Epoch[30] Batch [870]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103316,	
2017-07-28 21:59:39,526 Epoch[30] Batch [880]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.103310,	
2017-07-28 21:59:43,340 Epoch[30] Batch [890]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.103296,	
2017-07-28 21:59:48,507 Epoch[30] Batch [900]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.103222,	
2017-07-28 21:59:54,260 Epoch[30] Batch [910]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103164,	
2017-07-28 21:59:59,868 Epoch[30] Batch [920]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.103121,	
2017-07-28 22:00:05,691 Epoch[30] Batch [930]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103082,	
2017-07-28 22:00:11,470 Epoch[30] Batch [940]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103062,	
2017-07-28 22:00:17,279 Epoch[30] Batch [950]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103008,	
2017-07-28 22:00:23,039 Epoch[30] Batch [960]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102948,	
2017-07-28 22:00:28,844 Epoch[30] Batch [970]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102878,	
2017-07-28 22:00:34,651 Epoch[30] Batch [980]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102981,	
2017-07-28 22:00:40,444 Epoch[30] Batch [990]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102910,	
2017-07-28 22:00:46,289 Epoch[30] Batch [1000]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.102907,	
2017-07-28 22:00:52,042 Epoch[30] Batch [1010]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.102796,	
2017-07-28 22:00:57,830 Epoch[30] Batch [1020]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102868,	
2017-07-28 22:01:03,640 Epoch[30] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102772,	
2017-07-28 22:01:08,948 Epoch[30] Batch [1040]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.102648,	
2017-07-28 22:01:14,241 Epoch[30] Batch [1050]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.102616,	
2017-07-28 22:01:19,959 Epoch[30] Batch [1060]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.102711,	
2017-07-28 22:01:25,894 Epoch[30] Batch [1070]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102710,	
2017-07-28 22:01:31,637 Epoch[30] Batch [1080]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.102639,	
2017-07-28 22:01:37,438 Epoch[30] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102590,	
2017-07-28 22:01:43,232 Epoch[30] Batch [1100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102494,	
2017-07-28 22:01:49,050 Epoch[30] Batch [1110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102501,	
2017-07-28 22:01:54,862 Epoch[30] Batch [1120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102485,	
2017-07-28 22:02:00,652 Epoch[30] Batch [1130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102400,	
2017-07-28 22:02:06,494 Epoch[30] Batch [1140]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102355,	
2017-07-28 22:02:12,286 Epoch[30] Batch [1150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102412,	
2017-07-28 22:02:18,023 Epoch[30] Batch [1160]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.102416,	
2017-07-28 22:02:23,623 Epoch[30] Batch [1170]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.102305,	
2017-07-28 22:02:29,430 Epoch[30] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102204,	
2017-07-28 22:02:35,245 Epoch[30] Batch [1190]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102192,	
2017-07-28 22:02:41,088 Epoch[30] Batch [1200]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102217,	
2017-07-28 22:02:46,899 Epoch[30] Batch [1210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102251,	
2017-07-28 22:02:52,673 Epoch[30] Batch [1220]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.102196,	
2017-07-28 22:02:58,444 Epoch[30] Batch [1230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.102131,	
2017-07-28 22:03:04,246 Epoch[30] Batch [1240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102079,	
2017-07-28 22:03:10,059 Epoch[30] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102015,	
2017-07-28 22:03:15,875 Epoch[30] Batch [1260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102065,	
2017-07-28 22:03:21,701 Epoch[30] Batch [1270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101956,	
2017-07-28 22:03:27,476 Epoch[30] Batch [1280]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101954,	
2017-07-28 22:03:33,286 Epoch[30] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102004,	
2017-07-28 22:03:39,100 Epoch[30] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101948,	
2017-07-28 22:03:44,914 Epoch[30] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101962,	
2017-07-28 22:03:50,724 Epoch[30] Batch [1320]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102010,	
2017-07-28 22:03:56,554 Epoch[30] Batch [1330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102084,	
2017-07-28 22:04:02,367 Epoch[30] Batch [1340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102168,	
2017-07-28 22:04:08,199 Epoch[30] Batch [1350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102184,	
2017-07-28 22:04:13,937 Epoch[30] Batch [1360]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.102175,	
2017-07-28 22:04:19,755 Epoch[30] Batch [1370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102152,	
2017-07-28 22:04:25,549 Epoch[30] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102068,	
2017-07-28 22:04:31,307 Epoch[30] Batch [1390]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.102014,	
2017-07-28 22:04:36,824 Epoch[30] Batch [1400]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.101962,	
2017-07-28 22:04:42,396 Epoch[30] Batch [1410]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.102001,	
2017-07-28 22:04:48,204 Epoch[30] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101960,	
2017-07-28 22:04:54,012 Epoch[30] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102070,	
2017-07-28 22:04:59,807 Epoch[30] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101966,	
2017-07-28 22:05:05,604 Epoch[30] Batch [1450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101955,	
2017-07-28 22:05:11,359 Epoch[30] Batch [1460]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101892,	
2017-07-28 22:05:17,034 Epoch[30] Batch [1470]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.101901,	
2017-07-28 22:05:22,791 Epoch[30] Batch [1480]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101895,	
2017-07-28 22:05:26,014 Epoch[30] Train-FCNLogLoss=0.101931
2017-07-28 22:05:26,015 Epoch[30] Time cost=851.235
2017-07-28 22:05:27,772 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.params"
2017-07-28 22:05:30,332 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.states"
2017-07-28 22:05:36,522 Epoch[31] Batch [10]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.096354,	
2017-07-28 22:05:42,172 Epoch[31] Batch [20]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.094685,	
2017-07-28 22:05:48,025 Epoch[31] Batch [30]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.093558,	
2017-07-28 22:05:53,763 Epoch[31] Batch [40]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.095934,	
2017-07-28 22:05:59,552 Epoch[31] Batch [50]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095745,	
2017-07-28 22:06:05,185 Epoch[31] Batch [60]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.095625,	
2017-07-28 22:06:11,061 Epoch[31] Batch [70]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.096760,	
2017-07-28 22:06:16,829 Epoch[31] Batch [80]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095077,	
2017-07-28 22:06:22,591 Epoch[31] Batch [90]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.094049,	
2017-07-28 22:06:28,451 Epoch[31] Batch [100]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.094556,	
2017-07-28 22:06:34,222 Epoch[31] Batch [110]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094492,	
2017-07-28 22:06:39,882 Epoch[31] Batch [120]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.094282,	
2017-07-28 22:06:45,648 Epoch[31] Batch [130]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.094494,	
2017-07-28 22:06:51,036 Epoch[31] Batch [140]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.094409,	
2017-07-28 22:06:56,622 Epoch[31] Batch [150]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.094344,	
2017-07-28 22:07:02,420 Epoch[31] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.094357,	
2017-07-28 22:07:08,266 Epoch[31] Batch [170]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.095063,	
2017-07-28 22:07:14,090 Epoch[31] Batch [180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.094600,	
2017-07-28 22:07:19,865 Epoch[31] Batch [190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094909,	
2017-07-28 22:07:25,691 Epoch[31] Batch [200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095073,	
2017-07-28 22:07:31,523 Epoch[31] Batch [210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.095326,	
2017-07-28 22:07:37,336 Epoch[31] Batch [220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095573,	
2017-07-28 22:07:43,149 Epoch[31] Batch [230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095719,	
2017-07-28 22:07:48,954 Epoch[31] Batch [240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095618,	
2017-07-28 22:07:54,744 Epoch[31] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095488,	
2017-07-28 22:08:00,560 Epoch[31] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095364,	
2017-07-28 22:08:06,374 Epoch[31] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095428,	
2017-07-28 22:08:12,197 Epoch[31] Batch [280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096035,	
2017-07-28 22:08:17,983 Epoch[31] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096231,	
2017-07-28 22:08:23,803 Epoch[31] Batch [300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096170,	
2017-07-28 22:08:29,618 Epoch[31] Batch [310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096350,	
2017-07-28 22:08:35,418 Epoch[31] Batch [320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096223,	
2017-07-28 22:08:41,201 Epoch[31] Batch [330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096003,	
2017-07-28 22:08:47,012 Epoch[31] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096276,	
2017-07-28 22:08:52,802 Epoch[31] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096311,	
2017-07-28 22:08:58,597 Epoch[31] Batch [360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096341,	
2017-07-28 22:09:04,348 Epoch[31] Batch [370]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.096348,	
2017-07-28 22:09:10,145 Epoch[31] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096653,	
2017-07-28 22:09:15,781 Epoch[31] Batch [390]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.096593,	
2017-07-28 22:09:21,557 Epoch[31] Batch [400]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096541,	
2017-07-28 22:09:27,098 Epoch[31] Batch [410]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.096579,	
2017-07-28 22:09:32,615 Epoch[31] Batch [420]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.096443,	
2017-07-28 22:09:37,970 Epoch[31] Batch [430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096469,	
2017-07-28 22:09:43,711 Epoch[31] Batch [440]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.096496,	
2017-07-28 22:09:49,548 Epoch[31] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.096452,	
2017-07-28 22:09:55,284 Epoch[31] Batch [460]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.096479,	
2017-07-28 22:10:01,148 Epoch[31] Batch [470]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.096538,	
2017-07-28 22:10:06,961 Epoch[31] Batch [480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097025,	
2017-07-28 22:10:12,816 Epoch[31] Batch [490]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.097362,	
2017-07-28 22:10:18,600 Epoch[31] Batch [500]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097478,	
2017-07-28 22:10:24,427 Epoch[31] Batch [510]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097711,	
2017-07-28 22:10:30,198 Epoch[31] Batch [520]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097767,	
2017-07-28 22:10:36,020 Epoch[31] Batch [530]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097912,	
2017-07-28 22:10:41,828 Epoch[31] Batch [540]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098118,	
2017-07-28 22:10:47,627 Epoch[31] Batch [550]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098350,	
2017-07-28 22:10:53,424 Epoch[31] Batch [560]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098596,	
2017-07-28 22:10:59,246 Epoch[31] Batch [570]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098898,	
2017-07-28 22:11:05,024 Epoch[31] Batch [580]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098882,	
2017-07-28 22:11:10,823 Epoch[31] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099021,	
2017-07-28 22:11:16,622 Epoch[31] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099294,	
2017-07-28 22:11:22,436 Epoch[31] Batch [610]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099301,	
2017-07-28 22:11:28,243 Epoch[31] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099435,	
2017-07-28 22:11:34,061 Epoch[31] Batch [630]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099510,	
2017-07-28 22:11:39,842 Epoch[31] Batch [640]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099629,	
2017-07-28 22:11:45,652 Epoch[31] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099486,	
2017-07-28 22:11:51,456 Epoch[31] Batch [660]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099608,	
2017-07-28 22:11:57,281 Epoch[31] Batch [670]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099645,	
2017-07-28 22:12:03,077 Epoch[31] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099498,	
2017-07-28 22:12:08,873 Epoch[31] Batch [690]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099505,	
2017-07-28 22:12:14,685 Epoch[31] Batch [700]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099532,	
2017-07-28 22:12:20,479 Epoch[31] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099518,	
2017-07-28 22:12:26,291 Epoch[31] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099393,	
2017-07-28 22:12:32,103 Epoch[31] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099249,	
2017-07-28 22:12:37,898 Epoch[31] Batch [740]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099384,	
2017-07-28 22:12:43,703 Epoch[31] Batch [750]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099287,	
2017-07-28 22:12:49,550 Epoch[31] Batch [760]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.099391,	
2017-07-28 22:12:55,355 Epoch[31] Batch [770]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099431,	
2017-07-28 22:13:01,150 Epoch[31] Batch [780]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099228,	
2017-07-28 22:13:06,969 Epoch[31] Batch [790]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099168,	
2017-07-28 22:13:12,783 Epoch[31] Batch [800]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099132,	
2017-07-28 22:13:18,553 Epoch[31] Batch [810]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099164,	
2017-07-28 22:13:24,362 Epoch[31] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099034,	
2017-07-28 22:13:30,186 Epoch[31] Batch [830]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098994,	
2017-07-28 22:13:35,999 Epoch[31] Batch [840]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098961,	
2017-07-28 22:13:41,771 Epoch[31] Batch [850]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098957,	
2017-07-28 22:13:47,585 Epoch[31] Batch [860]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098981,	
2017-07-28 22:13:53,370 Epoch[31] Batch [870]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098876,	
2017-07-28 22:13:59,194 Epoch[31] Batch [880]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098795,	
2017-07-28 22:14:05,021 Epoch[31] Batch [890]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098772,	
2017-07-28 22:14:10,794 Epoch[31] Batch [900]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098673,	
2017-07-28 22:14:16,140 Epoch[31] Batch [910]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098661,	
2017-07-28 22:14:20,580 Epoch[31] Batch [920]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.098598,	
2017-07-28 22:14:26,323 Epoch[31] Batch [930]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.098513,	
2017-07-28 22:14:31,977 Epoch[31] Batch [940]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.098491,	
2017-07-28 22:14:37,774 Epoch[31] Batch [950]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098490,	
2017-07-28 22:14:43,598 Epoch[31] Batch [960]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098647,	
2017-07-28 22:14:49,393 Epoch[31] Batch [970]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098547,	
2017-07-28 22:14:55,228 Epoch[31] Batch [980]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098581,	
2017-07-28 22:15:00,724 Epoch[31] Batch [990]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098547,	
2017-07-28 22:15:06,295 Epoch[31] Batch [1000]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.098518,	
2017-07-28 22:15:12,027 Epoch[31] Batch [1010]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.098493,	
2017-07-28 22:15:17,923 Epoch[31] Batch [1020]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.098473,	
2017-07-28 22:15:23,736 Epoch[31] Batch [1030]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098378,	
2017-07-28 22:15:29,563 Epoch[31] Batch [1040]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098381,	
2017-07-28 22:15:35,394 Epoch[31] Batch [1050]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098485,	
2017-07-28 22:15:41,263 Epoch[31] Batch [1060]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.098514,	
2017-07-28 22:15:47,046 Epoch[31] Batch [1070]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098395,	
2017-07-28 22:15:52,839 Epoch[31] Batch [1080]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098404,	
2017-07-28 22:15:58,638 Epoch[31] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098376,	
2017-07-28 22:16:04,489 Epoch[31] Batch [1100]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098487,	
2017-07-28 22:16:10,311 Epoch[31] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098454,	
2017-07-28 22:16:16,165 Epoch[31] Batch [1120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098530,	
2017-07-28 22:16:21,961 Epoch[31] Batch [1130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098555,	
2017-07-28 22:16:27,754 Epoch[31] Batch [1140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098493,	
2017-07-28 22:16:33,583 Epoch[31] Batch [1150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098463,	
2017-07-28 22:16:39,392 Epoch[31] Batch [1160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098437,	
2017-07-28 22:16:45,185 Epoch[31] Batch [1170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098403,	
2017-07-28 22:16:51,003 Epoch[31] Batch [1180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098335,	
2017-07-28 22:16:56,811 Epoch[31] Batch [1190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098397,	
2017-07-28 22:17:02,617 Epoch[31] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098424,	
2017-07-28 22:17:08,448 Epoch[31] Batch [1210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098480,	
2017-07-28 22:17:13,998 Epoch[31] Batch [1220]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.098456,	
2017-07-28 22:17:19,778 Epoch[31] Batch [1230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098348,	
2017-07-28 22:17:25,589 Epoch[31] Batch [1240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098357,	
2017-07-28 22:17:31,142 Epoch[31] Batch [1250]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.098457,	
2017-07-28 22:17:36,704 Epoch[31] Batch [1260]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.098484,	
2017-07-28 22:17:42,499 Epoch[31] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098446,	
2017-07-28 22:17:48,291 Epoch[31] Batch [1280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098387,	
2017-07-28 22:17:53,827 Epoch[31] Batch [1290]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098521,	
2017-07-28 22:17:59,139 Epoch[31] Batch [1300]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098541,	
2017-07-28 22:18:04,219 Epoch[31] Batch [1310]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.098578,	
2017-07-28 22:18:09,457 Epoch[31] Batch [1320]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.098682,	
2017-07-28 22:18:14,548 Epoch[31] Batch [1330]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.098589,	
2017-07-28 22:18:19,858 Epoch[31] Batch [1340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098628,	
2017-07-28 22:18:25,612 Epoch[31] Batch [1350]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098617,	
2017-07-28 22:18:31,402 Epoch[31] Batch [1360]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098577,	
2017-07-28 22:18:37,160 Epoch[31] Batch [1370]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098589,	
2017-07-28 22:18:42,880 Epoch[31] Batch [1380]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.098504,	
2017-07-28 22:18:48,367 Epoch[31] Batch [1390]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.098493,	
2017-07-28 22:18:54,122 Epoch[31] Batch [1400]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098460,	
2017-07-28 22:18:59,984 Epoch[31] Batch [1410]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.098502,	
2017-07-28 22:19:05,783 Epoch[31] Batch [1420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098567,	
2017-07-28 22:19:11,589 Epoch[31] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098530,	
2017-07-28 22:19:17,404 Epoch[31] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098586,	
2017-07-28 22:19:23,171 Epoch[31] Batch [1450]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098578,	
2017-07-28 22:19:28,983 Epoch[31] Batch [1460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098588,	
2017-07-28 22:19:34,776 Epoch[31] Batch [1470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098563,	
2017-07-28 22:19:40,528 Epoch[31] Batch [1480]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098586,	
2017-07-28 22:19:43,999 Epoch[31] Train-FCNLogLoss=0.098649
2017-07-28 22:19:43,999 Epoch[31] Time cost=853.666
2017-07-28 22:19:44,931 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.params"
2017-07-28 22:19:46,492 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.states"
2017-07-28 22:19:53,082 Epoch[32] Batch [10]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100461,	
2017-07-28 22:19:58,912 Epoch[32] Batch [20]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097888,	
2017-07-28 22:20:04,622 Epoch[32] Batch [30]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100533,	
2017-07-28 22:20:10,394 Epoch[32] Batch [40]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098212,	
2017-07-28 22:20:16,198 Epoch[32] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100264,	
2017-07-28 22:20:21,972 Epoch[32] Batch [60]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098421,	
2017-07-28 22:20:27,793 Epoch[32] Batch [70]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097885,	
2017-07-28 22:20:33,578 Epoch[32] Batch [80]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097356,	
2017-07-28 22:20:39,364 Epoch[32] Batch [90]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096759,	
2017-07-28 22:20:45,152 Epoch[32] Batch [100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097053,	
2017-07-28 22:20:50,948 Epoch[32] Batch [110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096923,	
2017-07-28 22:20:56,734 Epoch[32] Batch [120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096248,	
2017-07-28 22:21:02,524 Epoch[32] Batch [130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096422,	
2017-07-28 22:21:08,333 Epoch[32] Batch [140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096394,	
2017-07-28 22:21:14,123 Epoch[32] Batch [150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096029,	
2017-07-28 22:21:19,894 Epoch[32] Batch [160]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095299,	
2017-07-28 22:21:25,710 Epoch[32] Batch [170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095699,	
2017-07-28 22:21:31,524 Epoch[32] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096137,	
2017-07-28 22:21:37,293 Epoch[32] Batch [190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095695,	
2017-07-28 22:21:43,085 Epoch[32] Batch [200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096046,	
2017-07-28 22:21:48,864 Epoch[32] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095967,	
2017-07-28 22:21:54,685 Epoch[32] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095596,	
2017-07-28 22:22:00,476 Epoch[32] Batch [230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095420,	
2017-07-28 22:22:06,344 Epoch[32] Batch [240]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.095456,	
2017-07-28 22:22:12,070 Epoch[32] Batch [250]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.095688,	
2017-07-28 22:22:17,878 Epoch[32] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095604,	
2017-07-28 22:22:23,692 Epoch[32] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095356,	
2017-07-28 22:22:29,451 Epoch[32] Batch [280]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.095589,	
2017-07-28 22:22:35,266 Epoch[32] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095731,	
2017-07-28 22:22:41,078 Epoch[32] Batch [300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095482,	
2017-07-28 22:22:46,850 Epoch[32] Batch [310]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095511,	
2017-07-28 22:22:52,675 Epoch[32] Batch [320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095486,	
2017-07-28 22:22:58,451 Epoch[32] Batch [330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095647,	
2017-07-28 22:23:04,242 Epoch[32] Batch [340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095796,	
2017-07-28 22:23:10,013 Epoch[32] Batch [350]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096170,	
2017-07-28 22:23:15,862 Epoch[32] Batch [360]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.096246,	
2017-07-28 22:23:21,628 Epoch[32] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096445,	
2017-07-28 22:23:27,462 Epoch[32] Batch [380]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096517,	
2017-07-28 22:23:33,252 Epoch[32] Batch [390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096666,	
2017-07-28 22:23:39,044 Epoch[32] Batch [400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096601,	
2017-07-28 22:23:44,833 Epoch[32] Batch [410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096832,	
2017-07-28 22:23:50,645 Epoch[32] Batch [420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096634,	
2017-07-28 22:23:56,437 Epoch[32] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096700,	
2017-07-28 22:24:02,233 Epoch[32] Batch [440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096632,	
2017-07-28 22:24:08,039 Epoch[32] Batch [450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096562,	
2017-07-28 22:24:13,848 Epoch[32] Batch [460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096532,	
2017-07-28 22:24:19,668 Epoch[32] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096620,	
2017-07-28 22:24:25,470 Epoch[32] Batch [480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096541,	
2017-07-28 22:24:31,287 Epoch[32] Batch [490]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096362,	
2017-07-28 22:24:37,077 Epoch[32] Batch [500]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096510,	
2017-07-28 22:24:42,872 Epoch[32] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096474,	
2017-07-28 22:24:48,677 Epoch[32] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096594,	
2017-07-28 22:24:54,486 Epoch[32] Batch [530]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096725,	
2017-07-28 22:25:00,292 Epoch[32] Batch [540]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096496,	
2017-07-28 22:25:06,083 Epoch[32] Batch [550]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096444,	
2017-07-28 22:25:11,885 Epoch[32] Batch [560]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096319,	
2017-07-28 22:25:17,702 Epoch[32] Batch [570]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096287,	
2017-07-28 22:25:23,537 Epoch[32] Batch [580]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096323,	
2017-07-28 22:25:29,304 Epoch[32] Batch [590]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096285,	
2017-07-28 22:25:35,095 Epoch[32] Batch [600]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096052,	
2017-07-28 22:25:40,907 Epoch[32] Batch [610]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096008,	
2017-07-28 22:25:46,712 Epoch[32] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096143,	
2017-07-28 22:25:52,510 Epoch[32] Batch [630]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096215,	
2017-07-28 22:25:58,325 Epoch[32] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096121,	
2017-07-28 22:26:04,137 Epoch[32] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096329,	
2017-07-28 22:26:09,921 Epoch[32] Batch [660]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096374,	
2017-07-28 22:26:15,771 Epoch[32] Batch [670]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.096595,	
2017-07-28 22:26:21,552 Epoch[32] Batch [680]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096643,	
2017-07-28 22:26:27,400 Epoch[32] Batch [690]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.096659,	
2017-07-28 22:26:33,184 Epoch[32] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096799,	
2017-07-28 22:26:38,969 Epoch[32] Batch [710]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096769,	
2017-07-28 22:26:44,746 Epoch[32] Batch [720]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096700,	
2017-07-28 22:26:50,547 Epoch[32] Batch [730]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096768,	
2017-07-28 22:26:56,361 Epoch[32] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096831,	
2017-07-28 22:27:02,171 Epoch[32] Batch [750]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096808,	
2017-07-28 22:27:07,952 Epoch[32] Batch [760]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096926,	
2017-07-28 22:27:13,752 Epoch[32] Batch [770]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096821,	
2017-07-28 22:27:19,564 Epoch[32] Batch [780]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096929,	
2017-07-28 22:27:25,355 Epoch[32] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096868,	
2017-07-28 22:27:31,171 Epoch[32] Batch [800]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096763,	
2017-07-28 22:27:36,939 Epoch[32] Batch [810]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096965,	
2017-07-28 22:27:42,789 Epoch[32] Batch [820]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.097028,	
2017-07-28 22:27:48,567 Epoch[32] Batch [830]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097083,	
2017-07-28 22:27:54,371 Epoch[32] Batch [840]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097143,	
2017-07-28 22:28:00,151 Epoch[32] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097178,	
2017-07-28 22:28:05,966 Epoch[32] Batch [860]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097234,	
2017-07-28 22:28:11,743 Epoch[32] Batch [870]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097236,	
2017-07-28 22:28:17,535 Epoch[32] Batch [880]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097193,	
2017-07-28 22:28:23,362 Epoch[32] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097334,	
2017-07-28 22:28:29,143 Epoch[32] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097381,	
2017-07-28 22:28:34,901 Epoch[32] Batch [910]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.097452,	
2017-07-28 22:28:40,697 Epoch[32] Batch [920]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097468,	
2017-07-28 22:28:46,490 Epoch[32] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097609,	
2017-07-28 22:28:51,185 Epoch[32] Batch [940]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.097567,	
2017-07-28 22:28:56,717 Epoch[32] Batch [950]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.097525,	
2017-07-28 22:29:02,514 Epoch[32] Batch [960]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097516,	
2017-07-28 22:29:08,246 Epoch[32] Batch [970]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.097492,	
2017-07-28 22:29:14,048 Epoch[32] Batch [980]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097552,	
2017-07-28 22:29:19,836 Epoch[32] Batch [990]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097610,	
2017-07-28 22:29:25,626 Epoch[32] Batch [1000]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097529,	
2017-07-28 22:29:31,356 Epoch[32] Batch [1010]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.097577,	
2017-07-28 22:29:37,167 Epoch[32] Batch [1020]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097542,	
2017-07-28 22:29:42,950 Epoch[32] Batch [1030]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097530,	
2017-07-28 22:29:48,713 Epoch[32] Batch [1040]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097592,	
2017-07-28 22:29:54,495 Epoch[32] Batch [1050]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097612,	
2017-07-28 22:30:00,279 Epoch[32] Batch [1060]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097588,	
2017-07-28 22:30:06,095 Epoch[32] Batch [1070]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097591,	
2017-07-28 22:30:11,871 Epoch[32] Batch [1080]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097544,	
2017-07-28 22:30:17,676 Epoch[32] Batch [1090]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097471,	
2017-07-28 22:30:23,427 Epoch[32] Batch [1100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.097329,	
2017-07-28 22:30:29,223 Epoch[32] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097294,	
2017-07-28 22:30:34,997 Epoch[32] Batch [1120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097283,	
2017-07-28 22:30:40,791 Epoch[32] Batch [1130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097344,	
2017-07-28 22:30:46,591 Epoch[32] Batch [1140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097465,	
2017-07-28 22:30:52,388 Epoch[32] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097643,	
2017-07-28 22:30:58,164 Epoch[32] Batch [1160]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097677,	
2017-07-28 22:31:03,966 Epoch[32] Batch [1170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097684,	
2017-07-28 22:31:09,745 Epoch[32] Batch [1180]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097684,	
2017-07-28 22:31:15,536 Epoch[32] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097692,	
2017-07-28 22:31:21,334 Epoch[32] Batch [1200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097657,	
2017-07-28 22:31:27,115 Epoch[32] Batch [1210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097634,	
2017-07-28 22:31:32,884 Epoch[32] Batch [1220]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097595,	
2017-07-28 22:31:38,691 Epoch[32] Batch [1230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097558,	
2017-07-28 22:31:44,460 Epoch[32] Batch [1240]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097506,	
2017-07-28 22:31:50,289 Epoch[32] Batch [1250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097565,	
2017-07-28 22:31:56,055 Epoch[32] Batch [1260]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097575,	
2017-07-28 22:32:01,867 Epoch[32] Batch [1270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097556,	
2017-07-28 22:32:07,659 Epoch[32] Batch [1280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097555,	
2017-07-28 22:32:13,434 Epoch[32] Batch [1290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097446,	
2017-07-28 22:32:19,251 Epoch[32] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097333,	
2017-07-28 22:32:25,024 Epoch[32] Batch [1310]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097374,	
2017-07-28 22:32:30,805 Epoch[32] Batch [1320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097435,	
2017-07-28 22:32:36,591 Epoch[32] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097455,	
2017-07-28 22:32:42,423 Epoch[32] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097490,	
2017-07-28 22:32:48,192 Epoch[32] Batch [1350]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097516,	
2017-07-28 22:32:53,987 Epoch[32] Batch [1360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097494,	
2017-07-28 22:32:59,764 Epoch[32] Batch [1370]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097471,	
2017-07-28 22:33:05,577 Epoch[32] Batch [1380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097426,	
2017-07-28 22:33:11,374 Epoch[32] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097397,	
2017-07-28 22:33:17,154 Epoch[32] Batch [1400]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097462,	
2017-07-28 22:33:22,954 Epoch[32] Batch [1410]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097527,	
2017-07-28 22:33:28,759 Epoch[32] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097606,	
2017-07-28 22:33:34,554 Epoch[32] Batch [1430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097520,	
2017-07-28 22:33:40,348 Epoch[32] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097471,	
2017-07-28 22:33:46,120 Epoch[32] Batch [1450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097632,	
2017-07-28 22:33:51,952 Epoch[32] Batch [1460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097567,	
2017-07-28 22:33:57,751 Epoch[32] Batch [1470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097689,	
2017-07-28 22:34:03,513 Epoch[32] Batch [1480]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097687,	
2017-07-28 22:34:07,009 Epoch[32] Train-FCNLogLoss=0.097624
2017-07-28 22:34:07,009 Epoch[32] Time cost=860.517
2017-07-28 22:34:07,902 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.params"
2017-07-28 22:34:09,514 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.states"
2017-07-28 22:34:16,111 Epoch[33] Batch [10]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.100276,	
2017-07-28 22:34:21,904 Epoch[33] Batch [20]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101404,	
2017-07-28 22:34:27,685 Epoch[33] Batch [30]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097185,	
2017-07-28 22:34:33,489 Epoch[33] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100236,	
2017-07-28 22:34:39,304 Epoch[33] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100250,	
2017-07-28 22:34:45,068 Epoch[33] Batch [60]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099616,	
2017-07-28 22:34:50,893 Epoch[33] Batch [70]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098951,	
2017-07-28 22:34:56,688 Epoch[33] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098752,	
2017-07-28 22:35:02,479 Epoch[33] Batch [90]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099141,	
2017-07-28 22:35:08,259 Epoch[33] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098439,	
2017-07-28 22:35:14,068 Epoch[33] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098785,	
2017-07-28 22:35:19,854 Epoch[33] Batch [120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098271,	
2017-07-28 22:35:25,662 Epoch[33] Batch [130]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098536,	
2017-07-28 22:35:31,452 Epoch[33] Batch [140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098277,	
2017-07-28 22:35:37,264 Epoch[33] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098415,	
2017-07-28 22:35:43,059 Epoch[33] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098586,	
2017-07-28 22:35:48,833 Epoch[33] Batch [170]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099421,	
2017-07-28 22:35:54,646 Epoch[33] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099293,	
2017-07-28 22:36:00,439 Epoch[33] Batch [190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098915,	
2017-07-28 22:36:06,228 Epoch[33] Batch [200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098504,	
2017-07-28 22:36:12,024 Epoch[33] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098793,	
2017-07-28 22:36:17,871 Epoch[33] Batch [220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098982,	
2017-07-28 22:36:23,640 Epoch[33] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099177,	
2017-07-28 22:36:29,458 Epoch[33] Batch [240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098916,	
2017-07-28 22:36:35,235 Epoch[33] Batch [250]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099289,	
2017-07-28 22:36:41,029 Epoch[33] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099080,	
2017-07-28 22:36:46,827 Epoch[33] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098765,	
2017-07-28 22:36:52,618 Epoch[33] Batch [280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098617,	
2017-07-28 22:36:58,409 Epoch[33] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098225,	
2017-07-28 22:37:04,207 Epoch[33] Batch [300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098373,	
2017-07-28 22:37:09,992 Epoch[33] Batch [310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098394,	
2017-07-28 22:37:15,781 Epoch[33] Batch [320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098206,	
2017-07-28 22:37:21,556 Epoch[33] Batch [330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098158,	
2017-07-28 22:37:27,346 Epoch[33] Batch [340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097849,	
2017-07-28 22:37:33,127 Epoch[33] Batch [350]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097721,	
2017-07-28 22:37:38,908 Epoch[33] Batch [360]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097486,	
2017-07-28 22:37:44,688 Epoch[33] Batch [370]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097539,	
2017-07-28 22:37:50,507 Epoch[33] Batch [380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097560,	
2017-07-28 22:37:56,290 Epoch[33] Batch [390]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097493,	
2017-07-28 22:38:02,087 Epoch[33] Batch [400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097321,	
2017-07-28 22:38:07,901 Epoch[33] Batch [410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097169,	
2017-07-28 22:38:13,689 Epoch[33] Batch [420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097121,	
2017-07-28 22:38:19,501 Epoch[33] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096986,	
2017-07-28 22:38:25,290 Epoch[33] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096920,	
2017-07-28 22:38:31,092 Epoch[33] Batch [450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096994,	
2017-07-28 22:38:36,873 Epoch[33] Batch [460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097069,	
2017-07-28 22:38:42,703 Epoch[33] Batch [470]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096955,	
2017-07-28 22:38:48,484 Epoch[33] Batch [480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096827,	
2017-07-28 22:38:54,287 Epoch[33] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096829,	
2017-07-28 22:39:00,085 Epoch[33] Batch [500]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096735,	
2017-07-28 22:39:05,886 Epoch[33] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096866,	
2017-07-28 22:39:11,666 Epoch[33] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096822,	
2017-07-28 22:39:17,450 Epoch[33] Batch [530]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096914,	
2017-07-28 22:39:23,236 Epoch[33] Batch [540]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096842,	
2017-07-28 22:39:29,003 Epoch[33] Batch [550]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096811,	
2017-07-28 22:39:34,837 Epoch[33] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096968,	
2017-07-28 22:39:40,662 Epoch[33] Batch [570]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097004,	
2017-07-28 22:39:46,412 Epoch[33] Batch [580]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.097131,	
2017-07-28 22:39:52,208 Epoch[33] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097124,	
2017-07-28 22:39:58,003 Epoch[33] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096968,	
2017-07-28 22:40:03,820 Epoch[33] Batch [610]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096887,	
2017-07-28 22:40:09,588 Epoch[33] Batch [620]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096926,	
2017-07-28 22:40:15,395 Epoch[33] Batch [630]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096840,	
2017-07-28 22:40:21,200 Epoch[33] Batch [640]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096846,	
2017-07-28 22:40:26,988 Epoch[33] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097045,	
2017-07-28 22:40:32,800 Epoch[33] Batch [660]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097021,	
2017-07-28 22:40:38,597 Epoch[33] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097145,	
2017-07-28 22:40:44,399 Epoch[33] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097345,	
2017-07-28 22:40:50,200 Epoch[33] Batch [690]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097398,	
2017-07-28 22:40:55,994 Epoch[33] Batch [700]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097436,	
2017-07-28 22:41:01,776 Epoch[33] Batch [710]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097448,	
2017-07-28 22:41:07,554 Epoch[33] Batch [720]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097362,	
2017-07-28 22:41:13,348 Epoch[33] Batch [730]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097402,	
2017-07-28 22:41:19,155 Epoch[33] Batch [740]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097281,	
2017-07-28 22:41:24,953 Epoch[33] Batch [750]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097264,	
2017-07-28 22:41:30,750 Epoch[33] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097158,	
2017-07-28 22:41:36,553 Epoch[33] Batch [770]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097285,	
2017-07-28 22:41:42,363 Epoch[33] Batch [780]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097333,	
2017-07-28 22:41:48,163 Epoch[33] Batch [790]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097280,	
2017-07-28 22:41:53,964 Epoch[33] Batch [800]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097291,	
2017-07-28 22:41:59,771 Epoch[33] Batch [810]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097171,	
2017-07-28 22:42:05,559 Epoch[33] Batch [820]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097258,	
2017-07-28 22:42:11,369 Epoch[33] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097237,	
2017-07-28 22:42:17,183 Epoch[33] Batch [840]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097359,	
2017-07-28 22:42:22,982 Epoch[33] Batch [850]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097520,	
2017-07-28 22:42:28,805 Epoch[33] Batch [860]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097729,	
2017-07-28 22:42:34,587 Epoch[33] Batch [870]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097818,	
2017-07-28 22:42:40,384 Epoch[33] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097956,	
2017-07-28 22:42:46,211 Epoch[33] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097897,	
2017-07-28 22:42:51,993 Epoch[33] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097924,	
2017-07-28 22:42:57,785 Epoch[33] Batch [910]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097890,	
2017-07-28 22:43:03,577 Epoch[33] Batch [920]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098768,	
2017-07-28 22:43:09,362 Epoch[33] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098979,	
2017-07-28 22:43:14,182 Epoch[33] Batch [940]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.099289,	
2017-07-28 22:43:19,693 Epoch[33] Batch [950]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.099442,	
2017-07-28 22:43:25,478 Epoch[33] Batch [960]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099499,	
2017-07-28 22:43:31,275 Epoch[33] Batch [970]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099473,	
2017-07-28 22:43:37,047 Epoch[33] Batch [980]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099517,	
2017-07-28 22:43:42,860 Epoch[33] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099455,	
2017-07-28 22:43:48,662 Epoch[33] Batch [1000]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099435,	
2017-07-28 22:43:54,460 Epoch[33] Batch [1010]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099452,	
2017-07-28 22:44:00,258 Epoch[33] Batch [1020]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099446,	
2017-07-28 22:44:06,017 Epoch[33] Batch [1030]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099446,	
2017-07-28 22:44:11,828 Epoch[33] Batch [1040]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099411,	
2017-07-28 22:44:17,634 Epoch[33] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099436,	
2017-07-28 22:44:23,387 Epoch[33] Batch [1060]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099463,	
2017-07-28 22:44:29,200 Epoch[33] Batch [1070]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099395,	
2017-07-28 22:44:34,973 Epoch[33] Batch [1080]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099568,	
2017-07-28 22:44:40,747 Epoch[33] Batch [1090]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099570,	
2017-07-28 22:44:46,516 Epoch[33] Batch [1100]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099560,	
2017-07-28 22:44:52,313 Epoch[33] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099561,	
2017-07-28 22:44:58,101 Epoch[33] Batch [1120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099415,	
2017-07-28 22:45:03,872 Epoch[33] Batch [1130]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099470,	
2017-07-28 22:45:09,689 Epoch[33] Batch [1140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099448,	
2017-07-28 22:45:15,512 Epoch[33] Batch [1150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099439,	
2017-07-28 22:45:21,253 Epoch[33] Batch [1160]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.099426,	
2017-07-28 22:45:27,048 Epoch[33] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099382,	
2017-07-28 22:45:32,859 Epoch[33] Batch [1180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099360,	
2017-07-28 22:45:38,722 Epoch[33] Batch [1190]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.099325,	
2017-07-28 22:45:44,492 Epoch[33] Batch [1200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099291,	
2017-07-28 22:45:50,277 Epoch[33] Batch [1210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099267,	
2017-07-28 22:45:56,073 Epoch[33] Batch [1220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099322,	
2017-07-28 22:46:01,883 Epoch[33] Batch [1230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099242,	
2017-07-28 22:46:07,640 Epoch[33] Batch [1240]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099135,	
2017-07-28 22:46:13,454 Epoch[33] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099143,	
2017-07-28 22:46:19,259 Epoch[33] Batch [1260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099074,	
2017-07-28 22:46:25,046 Epoch[33] Batch [1270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099079,	
2017-07-28 22:46:30,838 Epoch[33] Batch [1280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099041,	
2017-07-28 22:46:36,650 Epoch[33] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099171,	
2017-07-28 22:46:42,438 Epoch[33] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099166,	
2017-07-28 22:46:48,214 Epoch[33] Batch [1310]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099140,	
2017-07-28 22:46:54,021 Epoch[33] Batch [1320]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099206,	
2017-07-28 22:46:59,822 Epoch[33] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099165,	
2017-07-28 22:47:05,608 Epoch[33] Batch [1340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099233,	
2017-07-28 22:47:11,414 Epoch[33] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099202,	
2017-07-28 22:47:17,210 Epoch[33] Batch [1360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099248,	
2017-07-28 22:47:23,006 Epoch[33] Batch [1370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099275,	
2017-07-28 22:47:28,800 Epoch[33] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099287,	
2017-07-28 22:47:34,612 Epoch[33] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099362,	
2017-07-28 22:47:40,401 Epoch[33] Batch [1400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099327,	
2017-07-28 22:47:46,189 Epoch[33] Batch [1410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099279,	
2017-07-28 22:47:51,961 Epoch[33] Batch [1420]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099338,	
2017-07-28 22:47:57,732 Epoch[33] Batch [1430]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099339,	
2017-07-28 22:48:03,525 Epoch[33] Batch [1440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099255,	
2017-07-28 22:48:09,296 Epoch[33] Batch [1450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099272,	
2017-07-28 22:48:15,104 Epoch[33] Batch [1460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099245,	
2017-07-28 22:48:20,899 Epoch[33] Batch [1470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099274,	
2017-07-28 22:48:26,677 Epoch[33] Batch [1480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099212,	
2017-07-28 22:48:30,161 Epoch[33] Train-FCNLogLoss=0.099199
2017-07-28 22:48:30,161 Epoch[33] Time cost=860.646
2017-07-28 22:48:31,010 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.params"
2017-07-28 22:48:32,821 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.states"
2017-07-28 22:48:39,302 Epoch[34] Batch [10]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100731,	
2017-07-28 22:48:45,120 Epoch[34] Batch [20]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099501,	
2017-07-28 22:48:50,914 Epoch[34] Batch [30]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097718,	
2017-07-28 22:48:56,707 Epoch[34] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098721,	
2017-07-28 22:49:02,506 Epoch[34] Batch [50]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098743,	
2017-07-28 22:49:08,288 Epoch[34] Batch [60]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098151,	
2017-07-28 22:49:14,099 Epoch[34] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098768,	
2017-07-28 22:49:19,914 Epoch[34] Batch [80]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097092,	
2017-07-28 22:49:25,684 Epoch[34] Batch [90]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096550,	
2017-07-28 22:49:31,462 Epoch[34] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096871,	
2017-07-28 22:49:37,267 Epoch[34] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096304,	
2017-07-28 22:49:43,051 Epoch[34] Batch [120]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095715,	
2017-07-28 22:49:48,848 Epoch[34] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095490,	
2017-07-28 22:49:54,677 Epoch[34] Batch [140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.095398,	
2017-07-28 22:50:00,482 Epoch[34] Batch [150]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.094856,	
2017-07-28 22:50:06,260 Epoch[34] Batch [160]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095122,	
2017-07-28 22:50:12,061 Epoch[34] Batch [170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095117,	
2017-07-28 22:50:17,841 Epoch[34] Batch [180]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.094847,	
2017-07-28 22:50:23,622 Epoch[34] Batch [190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.094716,	
2017-07-28 22:50:29,437 Epoch[34] Batch [200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.094715,	
2017-07-28 22:50:35,222 Epoch[34] Batch [210]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.094321,	
2017-07-28 22:50:41,035 Epoch[34] Batch [220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.094318,	
2017-07-28 22:50:46,834 Epoch[34] Batch [230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.094993,	
2017-07-28 22:50:52,633 Epoch[34] Batch [240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095454,	
2017-07-28 22:50:58,483 Epoch[34] Batch [250]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.095687,	
2017-07-28 22:51:04,253 Epoch[34] Batch [260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095149,	
2017-07-28 22:51:10,072 Epoch[34] Batch [270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.094803,	
2017-07-28 22:51:15,835 Epoch[34] Batch [280]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.094646,	
2017-07-28 22:51:21,674 Epoch[34] Batch [290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.094513,	
2017-07-28 22:51:27,443 Epoch[34] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094506,	
2017-07-28 22:51:33,260 Epoch[34] Batch [310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.094537,	
2017-07-28 22:51:39,062 Epoch[34] Batch [320]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.094841,	
2017-07-28 22:51:44,872 Epoch[34] Batch [330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095080,	
2017-07-28 22:51:50,672 Epoch[34] Batch [340]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.094863,	
2017-07-28 22:51:56,463 Epoch[34] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095093,	
2017-07-28 22:52:02,236 Epoch[34] Batch [360]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094787,	
2017-07-28 22:52:08,027 Epoch[34] Batch [370]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.094683,	
2017-07-28 22:52:13,816 Epoch[34] Batch [380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.094801,	
2017-07-28 22:52:19,635 Epoch[34] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095099,	
2017-07-28 22:52:25,462 Epoch[34] Batch [400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095205,	
2017-07-28 22:52:31,235 Epoch[34] Batch [410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095247,	
2017-07-28 22:52:37,051 Epoch[34] Batch [420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095321,	
2017-07-28 22:52:42,829 Epoch[34] Batch [430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095635,	
2017-07-28 22:52:48,631 Epoch[34] Batch [440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095750,	
2017-07-28 22:52:54,409 Epoch[34] Batch [450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095630,	
2017-07-28 22:53:00,197 Epoch[34] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095549,	
2017-07-28 22:53:05,981 Epoch[34] Batch [470]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095469,	
2017-07-28 22:53:11,802 Epoch[34] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095377,	
2017-07-28 22:53:17,616 Epoch[34] Batch [490]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095439,	
2017-07-28 22:53:23,392 Epoch[34] Batch [500]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095533,	
2017-07-28 22:53:29,187 Epoch[34] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095718,	
2017-07-28 22:53:34,982 Epoch[34] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095746,	
2017-07-28 22:53:40,787 Epoch[34] Batch [530]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095621,	
2017-07-28 22:53:46,579 Epoch[34] Batch [540]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095497,	
2017-07-28 22:53:52,383 Epoch[34] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095601,	
2017-07-28 22:53:58,176 Epoch[34] Batch [560]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095609,	
2017-07-28 22:54:04,004 Epoch[34] Batch [570]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.095565,	
2017-07-28 22:54:09,770 Epoch[34] Batch [580]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095679,	
2017-07-28 22:54:15,564 Epoch[34] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095703,	
2017-07-28 22:54:21,344 Epoch[34] Batch [600]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095650,	
2017-07-28 22:54:27,146 Epoch[34] Batch [610]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095813,	
2017-07-28 22:54:32,944 Epoch[34] Batch [620]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095916,	
2017-07-28 22:54:38,742 Epoch[34] Batch [630]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095796,	
2017-07-28 22:54:44,533 Epoch[34] Batch [640]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095691,	
2017-07-28 22:54:50,339 Epoch[34] Batch [650]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095694,	
2017-07-28 22:54:56,099 Epoch[34] Batch [660]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095757,	
2017-07-28 22:55:01,912 Epoch[34] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095750,	
2017-07-28 22:55:07,698 Epoch[34] Batch [680]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095637,	
2017-07-28 22:55:13,529 Epoch[34] Batch [690]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.095490,	
2017-07-28 22:55:19,297 Epoch[34] Batch [700]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095645,	
2017-07-28 22:55:25,106 Epoch[34] Batch [710]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095850,	
2017-07-28 22:55:30,859 Epoch[34] Batch [720]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.096042,	
2017-07-28 22:55:36,673 Epoch[34] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095870,	
2017-07-28 22:55:42,439 Epoch[34] Batch [740]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095884,	
2017-07-28 22:55:48,247 Epoch[34] Batch [750]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095944,	
2017-07-28 22:55:54,028 Epoch[34] Batch [760]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095998,	
2017-07-28 22:55:59,789 Epoch[34] Batch [770]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095902,	
2017-07-28 22:56:05,588 Epoch[34] Batch [780]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095857,	
2017-07-28 22:56:11,362 Epoch[34] Batch [790]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095742,	
2017-07-28 22:56:17,183 Epoch[34] Batch [800]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095670,	
2017-07-28 22:56:22,978 Epoch[34] Batch [810]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095797,	
2017-07-28 22:56:28,768 Epoch[34] Batch [820]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095827,	
2017-07-28 22:56:34,638 Epoch[34] Batch [830]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.095631,	
2017-07-28 22:56:40,358 Epoch[34] Batch [840]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.095675,	
2017-07-28 22:56:46,141 Epoch[34] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095682,	
2017-07-28 22:56:51,924 Epoch[34] Batch [860]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095813,	
2017-07-28 22:56:57,723 Epoch[34] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095964,	
2017-07-28 22:57:03,522 Epoch[34] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096024,	
2017-07-28 22:57:09,310 Epoch[34] Batch [890]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096107,	
2017-07-28 22:57:15,077 Epoch[34] Batch [900]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096064,	
2017-07-28 22:57:20,905 Epoch[34] Batch [910]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096058,	
2017-07-28 22:57:26,676 Epoch[34] Batch [920]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095965,	
2017-07-28 22:57:32,463 Epoch[34] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096004,	
2017-07-28 22:57:37,261 Epoch[34] Batch [940]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.095916,	
2017-07-28 22:57:42,911 Epoch[34] Batch [950]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.095902,	
2017-07-28 22:57:48,650 Epoch[34] Batch [960]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.095921,	
2017-07-28 22:57:54,450 Epoch[34] Batch [970]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095865,	
2017-07-28 22:58:00,246 Epoch[34] Batch [980]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095868,	
2017-07-28 22:58:06,022 Epoch[34] Batch [990]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095766,	
2017-07-28 22:58:11,845 Epoch[34] Batch [1000]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095751,	
2017-07-28 22:58:17,634 Epoch[34] Batch [1010]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095765,	
2017-07-28 22:58:23,448 Epoch[34] Batch [1020]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095998,	
2017-07-28 22:58:29,257 Epoch[34] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096187,	
2017-07-28 22:58:35,038 Epoch[34] Batch [1040]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096296,	
2017-07-28 22:58:40,847 Epoch[34] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096325,	
2017-07-28 22:58:46,608 Epoch[34] Batch [1060]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096382,	
2017-07-28 22:58:52,426 Epoch[34] Batch [1070]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096339,	
2017-07-28 22:58:58,226 Epoch[34] Batch [1080]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096311,	
2017-07-28 22:59:04,023 Epoch[34] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096511,	
2017-07-28 22:59:09,836 Epoch[34] Batch [1100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096598,	
2017-07-28 22:59:15,661 Epoch[34] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096620,	
2017-07-28 22:59:21,502 Epoch[34] Batch [1120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.096710,	
2017-07-28 22:59:27,219 Epoch[34] Batch [1130]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.096643,	
2017-07-28 22:59:33,044 Epoch[34] Batch [1140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096664,	
2017-07-28 22:59:38,811 Epoch[34] Batch [1150]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096623,	
2017-07-28 22:59:44,678 Epoch[34] Batch [1160]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.096599,	
2017-07-28 22:59:50,409 Epoch[34] Batch [1170]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.096564,	
2017-07-28 22:59:56,183 Epoch[34] Batch [1180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096609,	
2017-07-28 23:00:01,982 Epoch[34] Batch [1190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096612,	
2017-07-28 23:00:07,803 Epoch[34] Batch [1200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096641,	
2017-07-28 23:00:13,630 Epoch[34] Batch [1210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096682,	
2017-07-28 23:00:19,376 Epoch[34] Batch [1220]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.096662,	
2017-07-28 23:00:25,238 Epoch[34] Batch [1230]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.096649,	
2017-07-28 23:00:31,147 Epoch[34] Batch [1240]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.096640,	
2017-07-28 23:00:37,054 Epoch[34] Batch [1250]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.096710,	
2017-07-28 23:00:42,775 Epoch[34] Batch [1260]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.096727,	
2017-07-28 23:00:48,583 Epoch[34] Batch [1270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096624,	
2017-07-28 23:00:54,338 Epoch[34] Batch [1280]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.096593,	
2017-07-28 23:01:00,138 Epoch[34] Batch [1290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096575,	
2017-07-28 23:01:05,904 Epoch[34] Batch [1300]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096522,	
2017-07-28 23:01:11,699 Epoch[34] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096596,	
2017-07-28 23:01:17,517 Epoch[34] Batch [1320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096580,	
2017-07-28 23:01:23,270 Epoch[34] Batch [1330]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.096504,	
2017-07-28 23:01:29,057 Epoch[34] Batch [1340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096549,	
2017-07-28 23:01:34,891 Epoch[34] Batch [1350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096561,	
2017-07-28 23:01:40,652 Epoch[34] Batch [1360]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096492,	
2017-07-28 23:01:46,521 Epoch[34] Batch [1370]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.096463,	
2017-07-28 23:01:52,241 Epoch[34] Batch [1380]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.096463,	
2017-07-28 23:01:57,972 Epoch[34] Batch [1390]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.096436,	
2017-07-28 23:02:03,744 Epoch[34] Batch [1400]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096471,	
2017-07-28 23:02:09,528 Epoch[34] Batch [1410]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096451,	
2017-07-28 23:02:15,320 Epoch[34] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096442,	
2017-07-28 23:02:21,175 Epoch[34] Batch [1430]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.096422,	
2017-07-28 23:02:27,024 Epoch[34] Batch [1440]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.096379,	
2017-07-28 23:02:32,785 Epoch[34] Batch [1450]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096368,	
2017-07-28 23:02:38,592 Epoch[34] Batch [1460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096376,	
2017-07-28 23:02:44,356 Epoch[34] Batch [1470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096404,	
2017-07-28 23:02:50,167 Epoch[34] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096395,	
2017-07-28 23:02:53,633 Epoch[34] Train-FCNLogLoss=0.096337
2017-07-28 23:02:53,633 Epoch[34] Time cost=860.812
2017-07-28 23:02:54,520 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.params"
2017-07-28 23:02:57,830 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.states"
2017-07-28 23:03:04,692 Epoch[35] Batch [10]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087116,	
2017-07-28 23:03:10,468 Epoch[35] Batch [20]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085328,	
2017-07-28 23:03:16,491 Epoch[35] Batch [30]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.087189,	
2017-07-28 23:03:22,297 Epoch[35] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088018,	
2017-07-28 23:03:28,123 Epoch[35] Batch [50]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.087909,	
2017-07-28 23:03:33,867 Epoch[35] Batch [60]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088809,	
2017-07-28 23:03:39,788 Epoch[35] Batch [70]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.089546,	
2017-07-28 23:03:45,508 Epoch[35] Batch [80]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.089923,	
2017-07-28 23:03:51,315 Epoch[35] Batch [90]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.090604,	
2017-07-28 23:03:57,276 Epoch[35] Batch [100]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.091160,	
2017-07-28 23:04:03,197 Epoch[35] Batch [110]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.090830,	
2017-07-28 23:04:09,023 Epoch[35] Batch [120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.091117,	
2017-07-28 23:04:14,784 Epoch[35] Batch [130]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.092573,	
2017-07-28 23:04:20,585 Epoch[35] Batch [140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.092677,	
2017-07-28 23:04:26,675 Epoch[35] Batch [150]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.093347,	
2017-07-28 23:04:32,497 Epoch[35] Batch [160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.093323,	
2017-07-28 23:04:38,355 Epoch[35] Batch [170]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.093142,	
2017-07-28 23:04:44,073 Epoch[35] Batch [180]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.093139,	
2017-07-28 23:04:49,823 Epoch[35] Batch [190]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.092947,	
2017-07-28 23:04:55,657 Epoch[35] Batch [200]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.092893,	
2017-07-28 23:05:01,437 Epoch[35] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093043,	
2017-07-28 23:05:07,235 Epoch[35] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093265,	
2017-07-28 23:05:13,054 Epoch[35] Batch [230]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.093099,	
2017-07-28 23:05:18,820 Epoch[35] Batch [240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.093187,	
2017-07-28 23:05:24,573 Epoch[35] Batch [250]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.093194,	
2017-07-28 23:05:30,472 Epoch[35] Batch [260]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093515,	
2017-07-28 23:05:36,499 Epoch[35] Batch [270]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.093677,	
2017-07-28 23:05:42,797 Epoch[35] Batch [280]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.093826,	
2017-07-28 23:05:49,409 Epoch[35] Batch [290]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.093773,	
2017-07-28 23:05:55,749 Epoch[35] Batch [300]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.093824,	
2017-07-28 23:06:02,239 Epoch[35] Batch [310]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.093674,	
2017-07-28 23:06:08,094 Epoch[35] Batch [320]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.093663,	
2017-07-28 23:06:14,231 Epoch[35] Batch [330]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093904,	
2017-07-28 23:06:20,290 Epoch[35] Batch [340]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.093746,	
2017-07-28 23:06:26,195 Epoch[35] Batch [350]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.093920,	
2017-07-28 23:06:32,163 Epoch[35] Batch [360]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.093868,	
2017-07-28 23:06:37,832 Epoch[35] Batch [370]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093530,	
2017-07-28 23:06:43,718 Epoch[35] Batch [380]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093458,	
2017-07-28 23:06:49,548 Epoch[35] Batch [390]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.093649,	
2017-07-28 23:06:55,474 Epoch[35] Batch [400]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.093434,	
2017-07-28 23:07:01,344 Epoch[35] Batch [410]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093635,	
2017-07-28 23:07:07,163 Epoch[35] Batch [420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.093763,	
2017-07-28 23:07:12,991 Epoch[35] Batch [430]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.094619,	
2017-07-28 23:07:18,796 Epoch[35] Batch [440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.094787,	
2017-07-28 23:07:24,683 Epoch[35] Batch [450]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.094951,	
2017-07-28 23:07:30,600 Epoch[35] Batch [460]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.095259,	
2017-07-28 23:07:36,443 Epoch[35] Batch [470]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.095506,	
2017-07-28 23:07:42,237 Epoch[35] Batch [480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095609,	
2017-07-28 23:07:48,000 Epoch[35] Batch [490]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095831,	
2017-07-28 23:07:54,751 Epoch[35] Batch [500]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.095668,	
2017-07-28 23:08:01,268 Epoch[35] Batch [510]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.095731,	
2017-07-28 23:08:07,409 Epoch[35] Batch [520]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.095698,	
2017-07-28 23:08:13,390 Epoch[35] Batch [530]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.095875,	
2017-07-28 23:08:19,135 Epoch[35] Batch [540]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.095878,	
2017-07-28 23:08:24,938 Epoch[35] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095942,	
2017-07-28 23:08:30,743 Epoch[35] Batch [560]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095884,	
2017-07-28 23:08:36,529 Epoch[35] Batch [570]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096009,	
2017-07-28 23:08:42,309 Epoch[35] Batch [580]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096016,	
2017-07-28 23:08:48,108 Epoch[35] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096109,	
2017-07-28 23:08:53,916 Epoch[35] Batch [600]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096036,	
2017-07-28 23:08:59,650 Epoch[35] Batch [610]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.096021,	
2017-07-28 23:09:05,511 Epoch[35] Batch [620]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.096079,	
2017-07-28 23:09:11,434 Epoch[35] Batch [630]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.096071,	
2017-07-28 23:09:17,429 Epoch[35] Batch [640]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.096054,	
2017-07-28 23:09:23,221 Epoch[35] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096072,	
2017-07-28 23:09:29,005 Epoch[35] Batch [660]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.096156,	
2017-07-28 23:09:35,461 Epoch[35] Batch [670]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.096182,	
2017-07-28 23:09:42,228 Epoch[35] Batch [680]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.096169,	
2017-07-28 23:09:48,503 Epoch[35] Batch [690]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.096077,	
2017-07-28 23:09:54,794 Epoch[35] Batch [700]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.095995,	
2017-07-28 23:10:00,645 Epoch[35] Batch [710]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.095999,	
2017-07-28 23:10:06,968 Epoch[35] Batch [720]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.095780,	
2017-07-28 23:10:13,749 Epoch[35] Batch [730]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.095812,	
2017-07-28 23:10:20,491 Epoch[35] Batch [740]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.095847,	
2017-07-28 23:10:27,092 Epoch[35] Batch [750]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.095880,	
2017-07-28 23:10:33,625 Epoch[35] Batch [760]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.095993,	
2017-07-28 23:10:39,982 Epoch[35] Batch [770]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.096043,	
2017-07-28 23:10:46,907 Epoch[35] Batch [780]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.096132,	
2017-07-28 23:10:53,710 Epoch[35] Batch [790]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.096205,	
2017-07-28 23:10:59,431 Epoch[35] Batch [800]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.096288,	
2017-07-28 23:11:05,238 Epoch[35] Batch [810]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096256,	
2017-07-28 23:11:11,320 Epoch[35] Batch [820]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.096244,	
2017-07-28 23:11:17,755 Epoch[35] Batch [830]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.096464,	
2017-07-28 23:11:23,589 Epoch[35] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096457,	
2017-07-28 23:11:29,349 Epoch[35] Batch [850]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096463,	
2017-07-28 23:11:35,212 Epoch[35] Batch [860]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.096441,	
2017-07-28 23:11:41,278 Epoch[35] Batch [870]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.096312,	
2017-07-28 23:11:46,802 Epoch[35] Batch [880]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.096365,	
2017-07-28 23:11:53,106 Epoch[35] Batch [890]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.096290,	
2017-07-28 23:11:59,641 Epoch[35] Batch [900]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.096253,	
2017-07-28 23:12:06,057 Epoch[35] Batch [910]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.096282,	
2017-07-28 23:12:12,811 Epoch[35] Batch [920]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.096366,	
2017-07-28 23:12:19,907 Epoch[35] Batch [930]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.096358,	
2017-07-28 23:12:25,951 Epoch[35] Batch [940]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.096327,	
2017-07-28 23:12:31,817 Epoch[35] Batch [950]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.096220,	
2017-07-28 23:12:37,637 Epoch[35] Batch [960]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096137,	
2017-07-28 23:12:43,637 Epoch[35] Batch [970]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.096141,	
2017-07-28 23:12:49,772 Epoch[35] Batch [980]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.096165,	
2017-07-28 23:12:55,921 Epoch[35] Batch [990]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.096083,	
2017-07-28 23:13:01,936 Epoch[35] Batch [1000]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.096056,	
2017-07-28 23:13:07,820 Epoch[35] Batch [1010]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.096100,	
2017-07-28 23:13:15,040 Epoch[35] Batch [1020]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.096169,	
2017-07-28 23:13:21,693 Epoch[35] Batch [1030]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.096157,	
2017-07-28 23:13:28,868 Epoch[35] Batch [1040]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.096081,	
2017-07-28 23:13:36,540 Epoch[35] Batch [1050]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.096147,	
2017-07-28 23:13:43,519 Epoch[35] Batch [1060]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.096087,	
2017-07-28 23:13:50,724 Epoch[35] Batch [1070]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.096015,	
2017-07-28 23:13:57,750 Epoch[35] Batch [1080]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.095912,	
2017-07-28 23:14:04,839 Epoch[35] Batch [1090]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.096020,	
2017-07-28 23:14:11,689 Epoch[35] Batch [1100]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.096014,	
2017-07-28 23:14:18,936 Epoch[35] Batch [1110]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.095992,	
2017-07-28 23:14:26,305 Epoch[35] Batch [1120]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.095943,	
2017-07-28 23:14:33,721 Epoch[35] Batch [1130]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.095919,	
2017-07-28 23:14:40,509 Epoch[35] Batch [1140]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.095923,	
2017-07-28 23:14:46,624 Epoch[35] Batch [1150]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.095837,	
2017-07-28 23:14:52,553 Epoch[35] Batch [1160]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.095803,	
2017-07-28 23:14:58,288 Epoch[35] Batch [1170]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.095753,	
2017-07-28 23:15:04,355 Epoch[35] Batch [1180]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.095669,	
2017-07-28 23:15:11,044 Epoch[35] Batch [1190]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.095745,	
2017-07-28 23:15:17,812 Epoch[35] Batch [1200]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.095682,	
2017-07-28 23:15:24,271 Epoch[35] Batch [1210]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.095713,	
2017-07-28 23:15:30,095 Epoch[35] Batch [1220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095703,	
2017-07-28 23:15:35,887 Epoch[35] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095579,	
2017-07-28 23:15:41,691 Epoch[35] Batch [1240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095530,	
2017-07-28 23:15:47,481 Epoch[35] Batch [1250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095528,	
2017-07-28 23:15:53,294 Epoch[35] Batch [1260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095469,	
2017-07-28 23:15:59,080 Epoch[35] Batch [1270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095514,	
2017-07-28 23:16:04,873 Epoch[35] Batch [1280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095454,	
2017-07-28 23:16:10,673 Epoch[35] Batch [1290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095300,	
2017-07-28 23:16:16,510 Epoch[35] Batch [1300]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.095296,	
2017-07-28 23:16:22,321 Epoch[35] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095236,	
2017-07-28 23:16:28,085 Epoch[35] Batch [1320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.095411,	
2017-07-28 23:16:33,872 Epoch[35] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095446,	
2017-07-28 23:16:39,653 Epoch[35] Batch [1340]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095401,	
2017-07-28 23:16:45,527 Epoch[35] Batch [1350]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.095414,	
2017-07-28 23:16:51,244 Epoch[35] Batch [1360]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.095460,	
2017-07-28 23:16:57,047 Epoch[35] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095391,	
2017-07-28 23:17:02,884 Epoch[35] Batch [1380]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.095351,	
2017-07-28 23:17:08,655 Epoch[35] Batch [1390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095381,	
2017-07-28 23:17:14,507 Epoch[35] Batch [1400]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.095287,	
2017-07-28 23:17:20,964 Epoch[35] Batch [1410]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.095255,	
2017-07-28 23:17:27,256 Epoch[35] Batch [1420]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.095224,	
2017-07-28 23:17:33,059 Epoch[35] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095251,	
2017-07-28 23:17:38,841 Epoch[35] Batch [1440]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095310,	
2017-07-28 23:17:44,584 Epoch[35] Batch [1450]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.095333,	
2017-07-28 23:17:50,413 Epoch[35] Batch [1460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.095368,	
2017-07-28 23:17:56,164 Epoch[35] Batch [1470]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.095407,	
2017-07-28 23:18:01,984 Epoch[35] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095426,	
2017-07-28 23:18:05,655 Epoch[35] Train-FCNLogLoss=0.095501
2017-07-28 23:18:05,655 Epoch[35] Time cost=907.825
2017-07-28 23:18:06,751 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.params"
2017-07-28 23:18:10,296 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.states"
2017-07-28 23:18:17,053 Epoch[36] Batch [10]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100605,	
2017-07-28 23:18:22,866 Epoch[36] Batch [20]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098385,	
2017-07-28 23:18:28,661 Epoch[36] Batch [30]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096724,	
2017-07-28 23:18:34,484 Epoch[36] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.093871,	
2017-07-28 23:18:40,323 Epoch[36] Batch [50]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.093715,	
2017-07-28 23:18:46,103 Epoch[36] Batch [60]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.092478,	
2017-07-28 23:18:51,957 Epoch[36] Batch [70]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.094822,	
2017-07-28 23:18:58,041 Epoch[36] Batch [80]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097181,	
2017-07-28 23:19:03,865 Epoch[36] Batch [90]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097977,	
2017-07-28 23:19:09,666 Epoch[36] Batch [100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099990,	
2017-07-28 23:19:15,482 Epoch[36] Batch [110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101165,	
2017-07-28 23:19:22,647 Epoch[36] Batch [120]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.100963,	
2017-07-28 23:19:30,138 Epoch[36] Batch [130]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.101436,	
2017-07-28 23:19:37,995 Epoch[36] Batch [140]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.105008,	
2017-07-28 23:19:44,451 Epoch[36] Batch [150]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.105672,	
2017-07-28 23:19:50,665 Epoch[36] Batch [160]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.107228,	
2017-07-28 23:19:57,670 Epoch[36] Batch [170]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.107706,	
2017-07-28 23:20:03,769 Epoch[36] Batch [180]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108125,	
2017-07-28 23:20:10,297 Epoch[36] Batch [190]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.108091,	
2017-07-28 23:20:16,435 Epoch[36] Batch [200]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.108304,	
2017-07-28 23:20:22,239 Epoch[36] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107755,	
2017-07-28 23:20:28,273 Epoch[36] Batch [220]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.107739,	
2017-07-28 23:20:34,675 Epoch[36] Batch [230]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.107562,	
2017-07-28 23:20:40,598 Epoch[36] Batch [240]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106891,	
2017-07-28 23:20:46,883 Epoch[36] Batch [250]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.106113,	
2017-07-28 23:20:53,384 Epoch[36] Batch [260]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.105401,	
2017-07-28 23:20:59,613 Epoch[36] Batch [270]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.105055,	
2017-07-28 23:21:05,928 Epoch[36] Batch [280]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.104722,	
2017-07-28 23:21:12,370 Epoch[36] Batch [290]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.105584,	
2017-07-28 23:21:19,616 Epoch[36] Batch [300]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.105923,	
2017-07-28 23:21:26,410 Epoch[36] Batch [310]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.106926,	
2017-07-28 23:21:32,361 Epoch[36] Batch [320]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106747,	
2017-07-28 23:21:38,476 Epoch[36] Batch [330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107105,	
2017-07-28 23:21:45,422 Epoch[36] Batch [340]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.107241,	
2017-07-28 23:21:51,576 Epoch[36] Batch [350]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.107103,	
2017-07-28 23:21:57,676 Epoch[36] Batch [360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107022,	
2017-07-28 23:22:04,403 Epoch[36] Batch [370]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.106787,	
2017-07-28 23:22:10,768 Epoch[36] Batch [380]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.106731,	
2017-07-28 23:22:17,474 Epoch[36] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.106439,	
2017-07-28 23:22:24,370 Epoch[36] Batch [400]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.106181,	
2017-07-28 23:22:31,209 Epoch[36] Batch [410]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.105939,	
2017-07-28 23:22:37,632 Epoch[36] Batch [420]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.105988,	
2017-07-28 23:22:44,124 Epoch[36] Batch [430]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.105991,	
2017-07-28 23:22:50,912 Epoch[36] Batch [440]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.105938,	
2017-07-28 23:22:58,217 Epoch[36] Batch [450]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.105664,	
2017-07-28 23:23:05,433 Epoch[36] Batch [460]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.105361,	
2017-07-28 23:23:12,724 Epoch[36] Batch [470]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.105211,	
2017-07-28 23:23:19,523 Epoch[36] Batch [480]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.104741,	
2017-07-28 23:23:26,706 Epoch[36] Batch [490]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.104589,	
2017-07-28 23:23:32,707 Epoch[36] Batch [500]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.104589,	
2017-07-28 23:23:38,856 Epoch[36] Batch [510]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.104525,	
2017-07-28 23:23:45,307 Epoch[36] Batch [520]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.104420,	
2017-07-28 23:23:53,118 Epoch[36] Batch [530]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.104354,	
2017-07-28 23:24:01,089 Epoch[36] Batch [540]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.104552,	
2017-07-28 23:24:08,123 Epoch[36] Batch [550]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.104393,	
2017-07-28 23:24:15,656 Epoch[36] Batch [560]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.104210,	
2017-07-28 23:24:23,329 Epoch[36] Batch [570]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.104225,	
2017-07-28 23:24:31,187 Epoch[36] Batch [580]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.104072,	
2017-07-28 23:24:39,037 Epoch[36] Batch [590]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.103940,	
2017-07-28 23:24:47,058 Epoch[36] Batch [600]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.103772,	
2017-07-28 23:24:54,824 Epoch[36] Batch [610]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.103599,	
2017-07-28 23:25:02,508 Epoch[36] Batch [620]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.103559,	
2017-07-28 23:25:10,413 Epoch[36] Batch [630]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.103384,	
2017-07-28 23:25:18,112 Epoch[36] Batch [640]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.103537,	
2017-07-28 23:25:25,795 Epoch[36] Batch [650]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.103491,	
2017-07-28 23:25:31,895 Epoch[36] Batch [660]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103303,	
2017-07-28 23:25:38,526 Epoch[36] Batch [670]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.103283,	
2017-07-28 23:25:45,158 Epoch[36] Batch [680]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.103121,	
2017-07-28 23:25:52,603 Epoch[36] Batch [690]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.102972,	
2017-07-28 23:26:00,115 Epoch[36] Batch [700]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.103090,	
2017-07-28 23:26:07,658 Epoch[36] Batch [710]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.103048,	
2017-07-28 23:26:14,610 Epoch[36] Batch [720]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.102869,	
2017-07-28 23:26:21,020 Epoch[36] Batch [730]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.103092,	
2017-07-28 23:26:26,956 Epoch[36] Batch [740]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103021,	
2017-07-28 23:26:32,782 Epoch[36] Batch [750]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103058,	
2017-07-28 23:26:38,932 Epoch[36] Batch [760]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.103012,	
2017-07-28 23:26:45,039 Epoch[36] Batch [770]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102866,	
2017-07-28 23:26:51,235 Epoch[36] Batch [780]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.102945,	
2017-07-28 23:26:57,297 Epoch[36] Batch [790]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102941,	
2017-07-28 23:27:03,624 Epoch[36] Batch [800]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.102698,	
2017-07-28 23:27:09,638 Epoch[36] Batch [810]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102684,	
2017-07-28 23:27:16,430 Epoch[36] Batch [820]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.102573,	
2017-07-28 23:27:23,373 Epoch[36] Batch [830]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102472,	
2017-07-28 23:27:29,812 Epoch[36] Batch [840]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.102324,	
2017-07-28 23:27:36,560 Epoch[36] Batch [850]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.102167,	
2017-07-28 23:27:43,504 Epoch[36] Batch [860]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102124,	
2017-07-28 23:27:49,853 Epoch[36] Batch [870]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.102048,	
2017-07-28 23:27:56,330 Epoch[36] Batch [880]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.101824,	
2017-07-28 23:28:03,004 Epoch[36] Batch [890]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.101719,	
2017-07-28 23:28:09,496 Epoch[36] Batch [900]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.101607,	
2017-07-28 23:28:16,250 Epoch[36] Batch [910]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.101671,	
2017-07-28 23:28:22,910 Epoch[36] Batch [920]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.101556,	
2017-07-28 23:28:30,023 Epoch[36] Batch [930]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.101463,	
2017-07-28 23:28:37,431 Epoch[36] Batch [940]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.101498,	
2017-07-28 23:28:44,597 Epoch[36] Batch [950]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.101456,	
2017-07-28 23:28:51,769 Epoch[36] Batch [960]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.101470,	
2017-07-28 23:28:58,949 Epoch[36] Batch [970]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.101437,	
2017-07-28 23:29:06,319 Epoch[36] Batch [980]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.101354,	
2017-07-28 23:29:13,556 Epoch[36] Batch [990]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.101438,	
2017-07-28 23:29:20,951 Epoch[36] Batch [1000]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.101308,	
2017-07-28 23:29:27,888 Epoch[36] Batch [1010]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.101195,	
2017-07-28 23:29:34,650 Epoch[36] Batch [1020]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.101172,	
2017-07-28 23:29:41,022 Epoch[36] Batch [1030]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.101136,	
2017-07-28 23:29:47,801 Epoch[36] Batch [1040]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.100994,	
2017-07-28 23:29:54,290 Epoch[36] Batch [1050]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.100878,	
2017-07-28 23:30:00,617 Epoch[36] Batch [1060]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.100771,	
2017-07-28 23:30:07,096 Epoch[36] Batch [1070]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.100662,	
2017-07-28 23:30:13,588 Epoch[36] Batch [1080]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.100526,	
2017-07-28 23:30:20,131 Epoch[36] Batch [1090]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.100478,	
2017-07-28 23:30:26,805 Epoch[36] Batch [1100]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.100492,	
2017-07-28 23:30:33,405 Epoch[36] Batch [1110]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.100379,	
2017-07-28 23:30:39,598 Epoch[36] Batch [1120]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.100347,	
2017-07-28 23:30:46,266 Epoch[36] Batch [1130]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.100299,	
2017-07-28 23:30:53,118 Epoch[36] Batch [1140]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.100265,	
2017-07-28 23:31:00,059 Epoch[36] Batch [1150]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.100199,	
2017-07-28 23:31:07,036 Epoch[36] Batch [1160]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.100058,	
2017-07-28 23:31:13,834 Epoch[36] Batch [1170]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.099991,	
2017-07-28 23:31:20,772 Epoch[36] Batch [1180]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.099965,	
2017-07-28 23:31:27,871 Epoch[36] Batch [1190]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.100007,	
2017-07-28 23:31:34,594 Epoch[36] Batch [1200]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.099981,	
2017-07-28 23:31:41,402 Epoch[36] Batch [1210]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.099891,	
2017-07-28 23:31:48,552 Epoch[36] Batch [1220]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.099899,	
2017-07-28 23:31:54,393 Epoch[36] Batch [1230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099755,	
2017-07-28 23:31:59,664 Epoch[36] Batch [1240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099773,	
2017-07-28 23:32:05,561 Epoch[36] Batch [1250]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.099662,	
2017-07-28 23:32:11,471 Epoch[36] Batch [1260]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099691,	
2017-07-28 23:32:17,255 Epoch[36] Batch [1270]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099575,	
2017-07-28 23:32:22,393 Epoch[36] Batch [1280]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.099468,	
2017-07-28 23:32:27,600 Epoch[36] Batch [1290]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.099373,	
2017-07-28 23:32:32,812 Epoch[36] Batch [1300]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099353,	
2017-07-28 23:32:37,932 Epoch[36] Batch [1310]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.099326,	
2017-07-28 23:32:43,502 Epoch[36] Batch [1320]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.099196,	
2017-07-28 23:32:48,966 Epoch[36] Batch [1330]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.099046,	
2017-07-28 23:32:54,050 Epoch[36] Batch [1340]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.099069,	
2017-07-28 23:32:59,169 Epoch[36] Batch [1350]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.099020,	
2017-07-28 23:33:04,514 Epoch[36] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098972,	
2017-07-28 23:33:09,868 Epoch[36] Batch [1370]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098938,	
2017-07-28 23:33:16,072 Epoch[36] Batch [1380]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.098907,	
2017-07-28 23:33:21,335 Epoch[36] Batch [1390]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.098853,	
2017-07-28 23:33:26,314 Epoch[36] Batch [1400]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.098810,	
2017-07-28 23:33:31,564 Epoch[36] Batch [1410]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098786,	
2017-07-28 23:33:36,857 Epoch[36] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098745,	
2017-07-28 23:33:42,477 Epoch[36] Batch [1430]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.098779,	
2017-07-28 23:33:47,599 Epoch[36] Batch [1440]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.098795,	
2017-07-28 23:33:53,475 Epoch[36] Batch [1450]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.098812,	
2017-07-28 23:33:58,868 Epoch[36] Batch [1460]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098779,	
2017-07-28 23:34:04,436 Epoch[36] Batch [1470]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.098727,	
2017-07-28 23:34:10,070 Epoch[36] Batch [1480]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.098679,	
2017-07-28 23:34:13,330 Epoch[36] Train-FCNLogLoss=0.098692
2017-07-28 23:34:13,330 Epoch[36] Time cost=963.034
2017-07-28 23:34:14,594 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.params"
2017-07-28 23:34:18,090 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.states"
2017-07-28 23:34:24,740 Epoch[37] Batch [10]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.085167,	
2017-07-28 23:34:30,245 Epoch[37] Batch [20]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092294,	
2017-07-28 23:34:35,494 Epoch[37] Batch [30]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090183,	
2017-07-28 23:34:41,142 Epoch[37] Batch [40]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.091350,	
2017-07-28 23:34:46,519 Epoch[37] Batch [50]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092121,	
2017-07-28 23:34:51,497 Epoch[37] Batch [60]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.092233,	
2017-07-28 23:34:57,433 Epoch[37] Batch [70]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.092781,	
2017-07-28 23:35:04,366 Epoch[37] Batch [80]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.091870,	
2017-07-28 23:35:11,024 Epoch[37] Batch [90]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.092553,	
2017-07-28 23:35:17,763 Epoch[37] Batch [100]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.092122,	
2017-07-28 23:35:24,541 Epoch[37] Batch [110]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.092205,	
2017-07-28 23:35:31,073 Epoch[37] Batch [120]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.091747,	
2017-07-28 23:35:37,609 Epoch[37] Batch [130]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.091824,	
2017-07-28 23:35:43,964 Epoch[37] Batch [140]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.091460,	
2017-07-28 23:35:50,210 Epoch[37] Batch [150]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.091905,	
2017-07-28 23:35:56,883 Epoch[37] Batch [160]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.091527,	
2017-07-28 23:36:03,127 Epoch[37] Batch [170]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.091980,	
2017-07-28 23:36:09,054 Epoch[37] Batch [180]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.092301,	
2017-07-28 23:36:15,838 Epoch[37] Batch [190]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.092641,	
2017-07-28 23:36:21,727 Epoch[37] Batch [200]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.093498,	
2017-07-28 23:36:27,623 Epoch[37] Batch [210]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093966,	
2017-07-28 23:36:33,660 Epoch[37] Batch [220]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.094351,	
2017-07-28 23:36:40,397 Epoch[37] Batch [230]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.094324,	
2017-07-28 23:36:47,110 Epoch[37] Batch [240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.094228,	
2017-07-28 23:36:53,950 Epoch[37] Batch [250]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.093645,	
2017-07-28 23:37:01,182 Epoch[37] Batch [260]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.093684,	
2017-07-28 23:37:08,577 Epoch[37] Batch [270]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.093800,	
2017-07-28 23:37:15,816 Epoch[37] Batch [280]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.093775,	
2017-07-28 23:37:23,096 Epoch[37] Batch [290]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.093609,	
2017-07-28 23:37:30,590 Epoch[37] Batch [300]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.093532,	
2017-07-28 23:37:38,931 Epoch[37] Batch [310]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.093805,	
2017-07-28 23:37:45,997 Epoch[37] Batch [320]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.094048,	
2017-07-28 23:37:53,317 Epoch[37] Batch [330]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.094386,	
2017-07-28 23:38:01,074 Epoch[37] Batch [340]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.094458,	
2017-07-28 23:38:09,006 Epoch[37] Batch [350]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.094537,	
2017-07-28 23:38:16,688 Epoch[37] Batch [360]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.094368,	
2017-07-28 23:38:24,486 Epoch[37] Batch [370]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.094177,	
2017-07-28 23:38:32,399 Epoch[37] Batch [380]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.093947,	
2017-07-28 23:38:39,458 Epoch[37] Batch [390]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.094126,	
2017-07-28 23:38:45,623 Epoch[37] Batch [400]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094143,	
2017-07-28 23:38:52,031 Epoch[37] Batch [410]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.094373,	
2017-07-28 23:38:59,029 Epoch[37] Batch [420]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.094145,	
2017-07-28 23:39:06,037 Epoch[37] Batch [430]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.093967,	
2017-07-28 23:39:12,379 Epoch[37] Batch [440]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.093810,	
2017-07-28 23:39:18,781 Epoch[37] Batch [450]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.093700,	
2017-07-28 23:39:24,970 Epoch[37] Batch [460]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.093685,	
2017-07-28 23:39:31,108 Epoch[37] Batch [470]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093725,	
2017-07-28 23:39:37,318 Epoch[37] Batch [480]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093755,	
2017-07-28 23:39:43,667 Epoch[37] Batch [490]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.093611,	
2017-07-28 23:39:49,844 Epoch[37] Batch [500]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.093643,	
2017-07-28 23:39:56,226 Epoch[37] Batch [510]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.093500,	
2017-07-28 23:40:02,272 Epoch[37] Batch [520]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093382,	
2017-07-28 23:40:08,619 Epoch[37] Batch [530]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.093373,	
2017-07-28 23:40:15,382 Epoch[37] Batch [540]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.093405,	
2017-07-28 23:40:21,846 Epoch[37] Batch [550]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.093421,	
2017-07-28 23:40:28,934 Epoch[37] Batch [560]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.093386,	
2017-07-28 23:40:36,003 Epoch[37] Batch [570]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.093403,	
2017-07-28 23:40:42,851 Epoch[37] Batch [580]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.093346,	
2017-07-28 23:40:49,607 Epoch[37] Batch [590]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.093332,	
2017-07-28 23:40:56,512 Epoch[37] Batch [600]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.093364,	
2017-07-28 23:41:03,044 Epoch[37] Batch [610]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.093346,	
2017-07-28 23:41:10,096 Epoch[37] Batch [620]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.093435,	
2017-07-28 23:41:17,245 Epoch[37] Batch [630]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.093557,	
2017-07-28 23:41:23,948 Epoch[37] Batch [640]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.093529,	
2017-07-28 23:41:30,731 Epoch[37] Batch [650]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.093485,	
2017-07-28 23:41:37,452 Epoch[37] Batch [660]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.093374,	
2017-07-28 23:41:44,522 Epoch[37] Batch [670]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.093239,	
2017-07-28 23:41:51,563 Epoch[37] Batch [680]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.093344,	
2017-07-28 23:41:59,127 Epoch[37] Batch [690]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.093319,	
2017-07-28 23:42:07,305 Epoch[37] Batch [700]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.093299,	
2017-07-28 23:42:15,040 Epoch[37] Batch [710]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.093284,	
2017-07-28 23:42:22,646 Epoch[37] Batch [720]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.093254,	
2017-07-28 23:42:30,457 Epoch[37] Batch [730]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.093263,	
2017-07-28 23:42:38,846 Epoch[37] Batch [740]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.093088,	
2017-07-28 23:42:46,787 Epoch[37] Batch [750]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.093067,	
2017-07-28 23:42:54,556 Epoch[37] Batch [760]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.093037,	
2017-07-28 23:43:02,534 Epoch[37] Batch [770]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.093253,	
2017-07-28 23:43:10,208 Epoch[37] Batch [780]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.093358,	
2017-07-28 23:43:18,107 Epoch[37] Batch [790]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.093377,	
2017-07-28 23:43:25,902 Epoch[37] Batch [800]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.093357,	
2017-07-28 23:43:33,704 Epoch[37] Batch [810]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.093267,	
2017-07-28 23:43:41,607 Epoch[37] Batch [820]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.093318,	
2017-07-28 23:43:49,333 Epoch[37] Batch [830]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.093285,	
2017-07-28 23:43:56,974 Epoch[37] Batch [840]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.093243,	
2017-07-28 23:44:04,401 Epoch[37] Batch [850]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.093294,	
2017-07-28 23:44:12,249 Epoch[37] Batch [860]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.093282,	
2017-07-28 23:44:20,401 Epoch[37] Batch [870]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.093308,	
2017-07-28 23:44:27,608 Epoch[37] Batch [880]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.093283,	
2017-07-28 23:44:35,288 Epoch[37] Batch [890]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.093230,	
2017-07-28 23:44:42,854 Epoch[37] Batch [900]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.093280,	
2017-07-28 23:44:50,657 Epoch[37] Batch [910]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.093211,	
2017-07-28 23:44:58,545 Epoch[37] Batch [920]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.093223,	
2017-07-28 23:45:06,761 Epoch[37] Batch [930]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.093292,	
2017-07-28 23:45:14,467 Epoch[37] Batch [940]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.093152,	
2017-07-28 23:45:21,744 Epoch[37] Batch [950]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.093274,	
2017-07-28 23:45:29,226 Epoch[37] Batch [960]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.093318,	
2017-07-28 23:45:36,770 Epoch[37] Batch [970]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.093364,	
2017-07-28 23:45:44,034 Epoch[37] Batch [980]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.093455,	
2017-07-28 23:45:52,265 Epoch[37] Batch [990]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.093388,	
2017-07-28 23:46:00,157 Epoch[37] Batch [1000]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.093349,	
2017-07-28 23:46:07,271 Epoch[37] Batch [1010]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.093363,	
2017-07-28 23:46:13,959 Epoch[37] Batch [1020]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.093369,	
2017-07-28 23:46:20,889 Epoch[37] Batch [1030]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.093347,	
2017-07-28 23:46:28,062 Epoch[37] Batch [1040]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.093361,	
2017-07-28 23:46:35,501 Epoch[37] Batch [1050]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.093482,	
2017-07-28 23:46:42,525 Epoch[37] Batch [1060]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.093725,	
2017-07-28 23:46:49,416 Epoch[37] Batch [1070]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.093817,	
2017-07-28 23:46:56,110 Epoch[37] Batch [1080]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.093925,	
2017-07-28 23:47:02,903 Epoch[37] Batch [1090]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.094101,	
2017-07-28 23:47:09,958 Epoch[37] Batch [1100]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.094161,	
2017-07-28 23:47:17,635 Epoch[37] Batch [1110]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.094078,	
2017-07-28 23:47:25,096 Epoch[37] Batch [1120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094081,	
2017-07-28 23:47:32,810 Epoch[37] Batch [1130]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.094065,	
2017-07-28 23:47:40,404 Epoch[37] Batch [1140]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.094211,	
2017-07-28 23:47:48,134 Epoch[37] Batch [1150]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.094233,	
2017-07-28 23:47:55,579 Epoch[37] Batch [1160]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094263,	
2017-07-28 23:48:03,271 Epoch[37] Batch [1170]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.094252,	
2017-07-28 23:48:10,983 Epoch[37] Batch [1180]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.094337,	
2017-07-28 23:48:18,428 Epoch[37] Batch [1190]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094365,	
2017-07-28 23:48:25,984 Epoch[37] Batch [1200]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.094400,	
2017-07-28 23:48:33,538 Epoch[37] Batch [1210]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.094503,	
2017-07-28 23:48:41,079 Epoch[37] Batch [1220]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.094520,	
2017-07-28 23:48:48,408 Epoch[37] Batch [1230]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.094500,	
2017-07-28 23:48:55,983 Epoch[37] Batch [1240]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.094529,	
2017-07-28 23:49:03,442 Epoch[37] Batch [1250]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094664,	
2017-07-28 23:49:11,366 Epoch[37] Batch [1260]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.094705,	
2017-07-28 23:49:18,768 Epoch[37] Batch [1270]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.094812,	
2017-07-28 23:49:26,241 Epoch[37] Batch [1280]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.094898,	
2017-07-28 23:49:33,896 Epoch[37] Batch [1290]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.094897,	
2017-07-28 23:49:41,260 Epoch[37] Batch [1300]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.094994,	
2017-07-28 23:49:48,502 Epoch[37] Batch [1310]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.095052,	
2017-07-28 23:49:55,746 Epoch[37] Batch [1320]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.095032,	
2017-07-28 23:50:02,542 Epoch[37] Batch [1330]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.094986,	
2017-07-28 23:50:10,010 Epoch[37] Batch [1340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.095083,	
2017-07-28 23:50:17,626 Epoch[37] Batch [1350]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095036,	
2017-07-28 23:50:25,130 Epoch[37] Batch [1360]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.094996,	
2017-07-28 23:50:32,883 Epoch[37] Batch [1370]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.094964,	
2017-07-28 23:50:40,606 Epoch[37] Batch [1380]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.094923,	
2017-07-28 23:50:48,483 Epoch[37] Batch [1390]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.094975,	
2017-07-28 23:50:56,501 Epoch[37] Batch [1400]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.095009,	
2017-07-28 23:51:04,239 Epoch[37] Batch [1410]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.094996,	
2017-07-28 23:51:12,338 Epoch[37] Batch [1420]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.095354,	
2017-07-28 23:51:20,319 Epoch[37] Batch [1430]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.095698,	
2017-07-28 23:51:28,556 Epoch[37] Batch [1440]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.095734,	
2017-07-28 23:51:36,944 Epoch[37] Batch [1450]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.095885,	
2017-07-28 23:51:44,866 Epoch[37] Batch [1460]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.095910,	
2017-07-28 23:51:52,285 Epoch[37] Batch [1470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.096028,	
2017-07-28 23:51:59,932 Epoch[37] Batch [1480]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.096055,	
2017-07-28 23:52:04,505 Epoch[37] Train-FCNLogLoss=0.096055
2017-07-28 23:52:04,505 Epoch[37] Time cost=1066.414
2017-07-28 23:52:05,779 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.params"
2017-07-28 23:52:09,299 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.states"
2017-07-28 23:52:18,148 Epoch[38] Batch [10]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.105488,	
2017-07-28 23:52:26,005 Epoch[38] Batch [20]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098866,	
2017-07-28 23:52:33,606 Epoch[38] Batch [30]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.101122,	
2017-07-28 23:52:40,451 Epoch[38] Batch [40]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.096143,	
2017-07-28 23:52:47,134 Epoch[38] Batch [50]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.097082,	
2017-07-28 23:52:54,287 Epoch[38] Batch [60]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.095811,	
2017-07-28 23:53:01,165 Epoch[38] Batch [70]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.095579,	
2017-07-28 23:53:07,619 Epoch[38] Batch [80]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.095524,	
2017-07-28 23:53:14,487 Epoch[38] Batch [90]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.096958,	
2017-07-28 23:53:21,229 Epoch[38] Batch [100]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.096004,	
2017-07-28 23:53:28,125 Epoch[38] Batch [110]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.095943,	
2017-07-28 23:53:35,239 Epoch[38] Batch [120]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.096888,	
2017-07-28 23:53:42,194 Epoch[38] Batch [130]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.098096,	
2017-07-28 23:53:49,073 Epoch[38] Batch [140]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098143,	
2017-07-28 23:53:55,940 Epoch[38] Batch [150]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.097901,	
2017-07-28 23:54:02,895 Epoch[38] Batch [160]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.097824,	
2017-07-28 23:54:10,087 Epoch[38] Batch [170]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.097318,	
2017-07-28 23:54:17,417 Epoch[38] Batch [180]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.097148,	
2017-07-28 23:54:24,739 Epoch[38] Batch [190]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.096827,	
2017-07-28 23:54:32,316 Epoch[38] Batch [200]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.096782,	
2017-07-28 23:54:39,909 Epoch[38] Batch [210]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096486,	
2017-07-28 23:54:47,544 Epoch[38] Batch [220]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.096014,	
2017-07-28 23:54:55,164 Epoch[38] Batch [230]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095847,	
2017-07-28 23:55:02,580 Epoch[38] Batch [240]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.095572,	
2017-07-28 23:55:09,925 Epoch[38] Batch [250]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.095161,	
2017-07-28 23:55:17,478 Epoch[38] Batch [260]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.094971,	
2017-07-28 23:55:24,876 Epoch[38] Batch [270]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.095054,	
2017-07-28 23:55:32,497 Epoch[38] Batch [280]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095158,	
2017-07-28 23:55:40,070 Epoch[38] Batch [290]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.095383,	
2017-07-28 23:55:47,627 Epoch[38] Batch [300]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.095562,	
2017-07-28 23:55:55,281 Epoch[38] Batch [310]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.095759,	
2017-07-28 23:56:02,686 Epoch[38] Batch [320]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.095891,	
2017-07-28 23:56:10,104 Epoch[38] Batch [330]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.096027,	
2017-07-28 23:56:17,829 Epoch[38] Batch [340]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.095730,	
2017-07-28 23:56:25,073 Epoch[38] Batch [350]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.095941,	
2017-07-28 23:56:32,525 Epoch[38] Batch [360]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.096113,	
2017-07-28 23:56:39,999 Epoch[38] Batch [370]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096253,	
2017-07-28 23:56:47,493 Epoch[38] Batch [380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.096338,	
2017-07-28 23:56:54,994 Epoch[38] Batch [390]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.096054,	
2017-07-28 23:57:02,559 Epoch[38] Batch [400]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096052,	
2017-07-28 23:57:10,196 Epoch[38] Batch [410]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095921,	
2017-07-28 23:57:17,804 Epoch[38] Batch [420]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.096021,	
2017-07-28 23:57:25,369 Epoch[38] Batch [430]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096105,	
2017-07-28 23:57:32,890 Epoch[38] Batch [440]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.096002,	
2017-07-28 23:57:40,177 Epoch[38] Batch [450]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.095551,	
2017-07-28 23:57:44,800 Epoch[38] Batch [460]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.095511,	
2017-07-28 23:57:49,567 Epoch[38] Batch [470]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.095601,	
2017-07-28 23:57:54,438 Epoch[38] Batch [480]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.095453,	
2017-07-28 23:57:59,066 Epoch[38] Batch [490]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095385,	
2017-07-28 23:58:03,927 Epoch[38] Batch [500]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.095335,	
2017-07-28 23:58:08,714 Epoch[38] Batch [510]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.095381,	
2017-07-28 23:58:13,243 Epoch[38] Batch [520]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.095379,	
2017-07-28 23:58:17,907 Epoch[38] Batch [530]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095223,	
2017-07-28 23:58:22,713 Epoch[38] Batch [540]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.095285,	
2017-07-28 23:58:27,117 Epoch[38] Batch [550]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.095338,	
2017-07-28 23:58:31,888 Epoch[38] Batch [560]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.095256,	
2017-07-28 23:58:36,511 Epoch[38] Batch [570]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.095427,	
2017-07-28 23:58:41,054 Epoch[38] Batch [580]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.095302,	
2017-07-28 23:58:45,749 Epoch[38] Batch [590]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.095165,	
2017-07-28 23:58:50,318 Epoch[38] Batch [600]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.095035,	
2017-07-28 23:58:54,967 Epoch[38] Batch [610]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.094813,	
2017-07-28 23:58:59,792 Epoch[38] Batch [620]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.094829,	
2017-07-28 23:59:04,673 Epoch[38] Batch [630]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.094906,	
2017-07-28 23:59:09,433 Epoch[38] Batch [640]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.095007,	
2017-07-28 23:59:14,106 Epoch[38] Batch [650]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.095048,	
2017-07-28 23:59:18,787 Epoch[38] Batch [660]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.094981,	
2017-07-28 23:59:23,691 Epoch[38] Batch [670]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.094959,	
2017-07-28 23:59:28,335 Epoch[38] Batch [680]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.095039,	
2017-07-28 23:59:33,116 Epoch[38] Batch [690]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.095175,	
2017-07-28 23:59:38,274 Epoch[38] Batch [700]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.095345,	
2017-07-28 23:59:42,891 Epoch[38] Batch [710]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.095303,	
2017-07-28 23:59:47,483 Epoch[38] Batch [720]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.095099,	
2017-07-28 23:59:52,375 Epoch[38] Batch [730]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.095150,	
2017-07-28 23:59:57,221 Epoch[38] Batch [740]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.095163,	
2017-07-29 00:00:02,275 Epoch[38] Batch [750]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.095038,	
2017-07-29 00:00:07,055 Epoch[38] Batch [760]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.095020,	
2017-07-29 00:00:11,915 Epoch[38] Batch [770]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.094941,	
2017-07-29 00:00:16,544 Epoch[38] Batch [780]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095028,	
2017-07-29 00:00:21,418 Epoch[38] Batch [790]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.094958,	
2017-07-29 00:00:26,391 Epoch[38] Batch [800]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.094952,	
2017-07-29 00:00:31,418 Epoch[38] Batch [810]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.094881,	
2017-07-29 00:00:36,178 Epoch[38] Batch [820]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.094827,	
2017-07-29 00:00:40,913 Epoch[38] Batch [830]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.094832,	
2017-07-29 00:00:45,525 Epoch[38] Batch [840]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.094827,	
2017-07-29 00:00:50,233 Epoch[38] Batch [850]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.094786,	
2017-07-29 00:00:55,119 Epoch[38] Batch [860]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.094730,	
2017-07-29 00:00:59,961 Epoch[38] Batch [870]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.094773,	
2017-07-29 00:01:04,862 Epoch[38] Batch [880]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.094797,	
2017-07-29 00:01:09,468 Epoch[38] Batch [890]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.094782,	
2017-07-29 00:01:14,278 Epoch[38] Batch [900]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.094735,	
2017-07-29 00:01:18,941 Epoch[38] Batch [910]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.094692,	
2017-07-29 00:01:23,923 Epoch[38] Batch [920]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.094783,	
2017-07-29 00:01:28,636 Epoch[38] Batch [930]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.095025,	
2017-07-29 00:01:33,310 Epoch[38] Batch [940]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.095166,	
2017-07-29 00:01:38,189 Epoch[38] Batch [950]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.096238,	
2017-07-29 00:01:43,235 Epoch[38] Batch [960]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.096348,	
2017-07-29 00:01:48,166 Epoch[38] Batch [970]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.096531,	
2017-07-29 00:01:53,169 Epoch[38] Batch [980]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.096619,	
2017-07-29 00:01:57,859 Epoch[38] Batch [990]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.096731,	
2017-07-29 00:02:02,654 Epoch[38] Batch [1000]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.096849,	
2017-07-29 00:02:07,184 Epoch[38] Batch [1010]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.096850,	
2017-07-29 00:02:11,815 Epoch[38] Batch [1020]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.096791,	
2017-07-29 00:02:16,690 Epoch[38] Batch [1030]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.096852,	
2017-07-29 00:02:21,738 Epoch[38] Batch [1040]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.096889,	
2017-07-29 00:02:26,531 Epoch[38] Batch [1050]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.096996,	
2017-07-29 00:02:31,427 Epoch[38] Batch [1060]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.096963,	
2017-07-29 00:02:36,207 Epoch[38] Batch [1070]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.096909,	
2017-07-29 00:02:40,755 Epoch[38] Batch [1080]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.096842,	
2017-07-29 00:02:45,510 Epoch[38] Batch [1090]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.096841,	
2017-07-29 00:02:50,320 Epoch[38] Batch [1100]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.096906,	
2017-07-29 00:02:55,002 Epoch[38] Batch [1110]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.096902,	
2017-07-29 00:02:59,772 Epoch[38] Batch [1120]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.096829,	
2017-07-29 00:03:04,465 Epoch[38] Batch [1130]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.096930,	
2017-07-29 00:03:09,262 Epoch[38] Batch [1140]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.096903,	
2017-07-29 00:03:14,105 Epoch[38] Batch [1150]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.096816,	
2017-07-29 00:03:18,920 Epoch[38] Batch [1160]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.096842,	
2017-07-29 00:03:23,758 Epoch[38] Batch [1170]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.096769,	
2017-07-29 00:03:28,603 Epoch[38] Batch [1180]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.096843,	
2017-07-29 00:03:33,361 Epoch[38] Batch [1190]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.096935,	
2017-07-29 00:03:38,197 Epoch[38] Batch [1200]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.096938,	
2017-07-29 00:03:42,841 Epoch[38] Batch [1210]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.096953,	
2017-07-29 00:03:47,435 Epoch[38] Batch [1220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.096902,	
2017-07-29 00:03:52,041 Epoch[38] Batch [1230]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.096840,	
2017-07-29 00:03:56,840 Epoch[38] Batch [1240]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.096926,	
2017-07-29 00:04:01,494 Epoch[38] Batch [1250]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.096899,	
2017-07-29 00:04:06,248 Epoch[38] Batch [1260]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.096870,	
2017-07-29 00:04:11,128 Epoch[38] Batch [1270]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.096954,	
2017-07-29 00:04:15,755 Epoch[38] Batch [1280]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.096968,	
2017-07-29 00:04:20,515 Epoch[38] Batch [1290]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.097012,	
2017-07-29 00:04:25,205 Epoch[38] Batch [1300]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.096991,	
2017-07-29 00:04:30,002 Epoch[38] Batch [1310]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.096985,	
2017-07-29 00:04:34,805 Epoch[38] Batch [1320]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.096942,	
2017-07-29 00:04:39,844 Epoch[38] Batch [1330]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.096929,	
2017-07-29 00:04:44,716 Epoch[38] Batch [1340]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.096916,	
2017-07-29 00:04:49,610 Epoch[38] Batch [1350]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.096892,	
2017-07-29 00:04:54,661 Epoch[38] Batch [1360]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.096876,	
2017-07-29 00:04:59,447 Epoch[38] Batch [1370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.096867,	
2017-07-29 00:05:04,270 Epoch[38] Batch [1380]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.096888,	
2017-07-29 00:05:09,140 Epoch[38] Batch [1390]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.096889,	
2017-07-29 00:05:13,765 Epoch[38] Batch [1400]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.096828,	
2017-07-29 00:05:18,398 Epoch[38] Batch [1410]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.096869,	
2017-07-29 00:05:23,222 Epoch[38] Batch [1420]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.096829,	
2017-07-29 00:05:28,061 Epoch[38] Batch [1430]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.096831,	
2017-07-29 00:05:32,723 Epoch[38] Batch [1440]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.096870,	
2017-07-29 00:05:37,535 Epoch[38] Batch [1450]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.096900,	
2017-07-29 00:05:42,394 Epoch[38] Batch [1460]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.096902,	
2017-07-29 00:05:47,450 Epoch[38] Batch [1470]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.096826,	
2017-07-29 00:05:52,086 Epoch[38] Batch [1480]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.096826,	
2017-07-29 00:05:54,901 Epoch[38] Train-FCNLogLoss=0.096806
2017-07-29 00:05:54,901 Epoch[38] Time cost=825.602
2017-07-29 00:05:55,719 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.params"
2017-07-29 00:05:57,586 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.states"
2017-07-29 00:06:03,172 Epoch[39] Batch [10]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.086007,	
2017-07-29 00:06:08,087 Epoch[39] Batch [20]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.085855,	
2017-07-29 00:06:12,890 Epoch[39] Batch [30]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088039,	
2017-07-29 00:06:17,695 Epoch[39] Batch [40]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086294,	
2017-07-29 00:06:22,552 Epoch[39] Batch [50]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.085708,	
2017-07-29 00:06:27,643 Epoch[39] Batch [60]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086409,	
2017-07-29 00:06:32,309 Epoch[39] Batch [70]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087039,	
2017-07-29 00:06:37,318 Epoch[39] Batch [80]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087464,	
2017-07-29 00:06:42,012 Epoch[39] Batch [90]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087512,	
2017-07-29 00:06:46,852 Epoch[39] Batch [100]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088406,	
2017-07-29 00:06:51,704 Epoch[39] Batch [110]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.089508,	
2017-07-29 00:06:56,551 Epoch[39] Batch [120]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090546,	
2017-07-29 00:07:01,406 Epoch[39] Batch [130]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090995,	
2017-07-29 00:07:06,017 Epoch[39] Batch [140]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091506,	
2017-07-29 00:07:10,611 Epoch[39] Batch [150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092028,	
2017-07-29 00:07:15,159 Epoch[39] Batch [160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092684,	
2017-07-29 00:07:19,778 Epoch[39] Batch [170]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092368,	
2017-07-29 00:07:24,395 Epoch[39] Batch [180]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092610,	
2017-07-29 00:07:28,957 Epoch[39] Batch [190]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092726,	
2017-07-29 00:07:33,542 Epoch[39] Batch [200]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092522,	
2017-07-29 00:07:38,241 Epoch[39] Batch [210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092325,	
2017-07-29 00:07:42,838 Epoch[39] Batch [220]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092265,	
2017-07-29 00:07:47,405 Epoch[39] Batch [230]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092121,	
2017-07-29 00:07:52,068 Epoch[39] Batch [240]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091890,	
2017-07-29 00:07:56,789 Epoch[39] Batch [250]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092097,	
2017-07-29 00:08:01,416 Epoch[39] Batch [260]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091795,	
2017-07-29 00:08:06,010 Epoch[39] Batch [270]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.091817,	
2017-07-29 00:08:10,636 Epoch[39] Batch [280]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091877,	
2017-07-29 00:08:15,385 Epoch[39] Batch [290]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.091831,	
2017-07-29 00:08:20,068 Epoch[39] Batch [300]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091859,	
2017-07-29 00:08:24,684 Epoch[39] Batch [310]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091824,	
2017-07-29 00:08:29,339 Epoch[39] Batch [320]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091971,	
2017-07-29 00:08:34,495 Epoch[39] Batch [330]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.091910,	
2017-07-29 00:08:39,174 Epoch[39] Batch [340]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091763,	
2017-07-29 00:08:44,018 Epoch[39] Batch [350]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092017,	
2017-07-29 00:08:48,828 Epoch[39] Batch [360]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091986,	
2017-07-29 00:08:53,726 Epoch[39] Batch [370]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.091944,	
2017-07-29 00:08:58,483 Epoch[39] Batch [380]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092174,	
2017-07-29 00:09:03,232 Epoch[39] Batch [390]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092211,	
2017-07-29 00:09:08,031 Epoch[39] Batch [400]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092350,	
2017-07-29 00:09:12,726 Epoch[39] Batch [410]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.092336,	
2017-07-29 00:09:17,475 Epoch[39] Batch [420]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092303,	
2017-07-29 00:09:22,174 Epoch[39] Batch [430]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092345,	
2017-07-29 00:09:27,055 Epoch[39] Batch [440]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092484,	
2017-07-29 00:09:32,100 Epoch[39] Batch [450]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.092177,	
2017-07-29 00:09:37,237 Epoch[39] Batch [460]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092208,	
2017-07-29 00:09:41,998 Epoch[39] Batch [470]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.092010,	
2017-07-29 00:09:46,841 Epoch[39] Batch [480]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092038,	
2017-07-29 00:09:51,959 Epoch[39] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.092241,	
2017-07-29 00:09:57,052 Epoch[39] Batch [500]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092379,	
2017-07-29 00:10:01,945 Epoch[39] Batch [510]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092471,	
2017-07-29 00:10:06,592 Epoch[39] Batch [520]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092514,	
2017-07-29 00:10:11,173 Epoch[39] Batch [530]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092625,	
2017-07-29 00:10:15,333 Epoch[39] Batch [540]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.092537,	
2017-07-29 00:10:19,112 Epoch[39] Batch [550]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.092572,	
2017-07-29 00:10:24,038 Epoch[39] Batch [560]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092604,	
2017-07-29 00:10:28,731 Epoch[39] Batch [570]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.092566,	
2017-07-29 00:10:33,613 Epoch[39] Batch [580]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092660,	
2017-07-29 00:10:38,440 Epoch[39] Batch [590]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092732,	
2017-07-29 00:10:43,533 Epoch[39] Batch [600]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092785,	
2017-07-29 00:10:48,355 Epoch[39] Batch [610]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092896,	
2017-07-29 00:10:53,394 Epoch[39] Batch [620]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092810,	
2017-07-29 00:10:58,086 Epoch[39] Batch [630]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092735,	
2017-07-29 00:11:03,083 Epoch[39] Batch [640]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.092659,	
2017-07-29 00:11:08,144 Epoch[39] Batch [650]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.092742,	
2017-07-29 00:11:12,831 Epoch[39] Batch [660]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092758,	
2017-07-29 00:11:17,653 Epoch[39] Batch [670]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092780,	
2017-07-29 00:11:22,394 Epoch[39] Batch [680]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092740,	
2017-07-29 00:11:27,339 Epoch[39] Batch [690]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.092723,	
2017-07-29 00:11:32,097 Epoch[39] Batch [700]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092852,	
2017-07-29 00:11:37,011 Epoch[39] Batch [710]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.092902,	
2017-07-29 00:11:41,754 Epoch[39] Batch [720]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092877,	
2017-07-29 00:11:46,676 Epoch[39] Batch [730]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092789,	
2017-07-29 00:11:51,519 Epoch[39] Batch [740]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092815,	
2017-07-29 00:11:56,403 Epoch[39] Batch [750]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092767,	
2017-07-29 00:12:01,390 Epoch[39] Batch [760]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092852,	
2017-07-29 00:12:06,296 Epoch[39] Batch [770]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.092687,	
2017-07-29 00:12:11,086 Epoch[39] Batch [780]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.092626,	
2017-07-29 00:12:15,955 Epoch[39] Batch [790]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092574,	
2017-07-29 00:12:20,771 Epoch[39] Batch [800]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092506,	
2017-07-29 00:12:25,509 Epoch[39] Batch [810]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092488,	
2017-07-29 00:12:30,243 Epoch[39] Batch [820]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.092477,	
2017-07-29 00:12:35,045 Epoch[39] Batch [830]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092410,	
2017-07-29 00:12:39,879 Epoch[39] Batch [840]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092393,	
2017-07-29 00:12:44,518 Epoch[39] Batch [850]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092376,	
2017-07-29 00:12:49,304 Epoch[39] Batch [860]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092415,	
2017-07-29 00:12:54,134 Epoch[39] Batch [870]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092495,	
2017-07-29 00:12:59,056 Epoch[39] Batch [880]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092562,	
2017-07-29 00:13:03,865 Epoch[39] Batch [890]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092560,	
2017-07-29 00:13:08,699 Epoch[39] Batch [900]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092527,	
2017-07-29 00:13:13,720 Epoch[39] Batch [910]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.092483,	
2017-07-29 00:13:18,641 Epoch[39] Batch [920]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092544,	
2017-07-29 00:13:23,477 Epoch[39] Batch [930]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092438,	
2017-07-29 00:13:28,531 Epoch[39] Batch [940]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092362,	
2017-07-29 00:13:33,268 Epoch[39] Batch [950]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092278,	
2017-07-29 00:13:38,027 Epoch[39] Batch [960]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092300,	
2017-07-29 00:13:42,851 Epoch[39] Batch [970]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092291,	
2017-07-29 00:13:47,686 Epoch[39] Batch [980]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092247,	
2017-07-29 00:13:52,542 Epoch[39] Batch [990]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.092279,	
2017-07-29 00:13:57,385 Epoch[39] Batch [1000]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092249,	
2017-07-29 00:14:02,243 Epoch[39] Batch [1010]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.092294,	
2017-07-29 00:14:07,291 Epoch[39] Batch [1020]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092308,	
2017-07-29 00:14:12,155 Epoch[39] Batch [1030]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092273,	
2017-07-29 00:14:16,868 Epoch[39] Batch [1040]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.092349,	
2017-07-29 00:14:21,767 Epoch[39] Batch [1050]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092299,	
2017-07-29 00:14:26,450 Epoch[39] Batch [1060]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092297,	
2017-07-29 00:14:31,266 Epoch[39] Batch [1070]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092362,	
2017-07-29 00:14:36,080 Epoch[39] Batch [1080]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092296,	
2017-07-29 00:14:41,136 Epoch[39] Batch [1090]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092286,	
2017-07-29 00:14:46,071 Epoch[39] Batch [1100]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.092269,	
2017-07-29 00:14:50,869 Epoch[39] Batch [1110]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092240,	
2017-07-29 00:14:55,747 Epoch[39] Batch [1120]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.092288,	
2017-07-29 00:15:00,532 Epoch[39] Batch [1130]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092271,	
2017-07-29 00:15:05,396 Epoch[39] Batch [1140]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092301,	
2017-07-29 00:15:10,164 Epoch[39] Batch [1150]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092450,	
2017-07-29 00:15:15,007 Epoch[39] Batch [1160]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092483,	
2017-07-29 00:15:19,967 Epoch[39] Batch [1170]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.092507,	
2017-07-29 00:15:24,647 Epoch[39] Batch [1180]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.092610,	
2017-07-29 00:15:29,634 Epoch[39] Batch [1190]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092540,	
2017-07-29 00:15:34,715 Epoch[39] Batch [1200]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092540,	
2017-07-29 00:15:39,594 Epoch[39] Batch [1210]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.092606,	
2017-07-29 00:15:44,469 Epoch[39] Batch [1220]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.092648,	
2017-07-29 00:15:49,255 Epoch[39] Batch [1230]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092613,	
2017-07-29 00:15:54,063 Epoch[39] Batch [1240]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092620,	
2017-07-29 00:15:58,641 Epoch[39] Batch [1250]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092712,	
2017-07-29 00:16:03,299 Epoch[39] Batch [1260]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092775,	
2017-07-29 00:16:08,202 Epoch[39] Batch [1270]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092814,	
2017-07-29 00:16:13,110 Epoch[39] Batch [1280]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.092793,	
2017-07-29 00:16:17,710 Epoch[39] Batch [1290]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092778,	
2017-07-29 00:16:22,528 Epoch[39] Batch [1300]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092769,	
2017-07-29 00:16:27,297 Epoch[39] Batch [1310]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092782,	
2017-07-29 00:16:31,864 Epoch[39] Batch [1320]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092773,	
2017-07-29 00:16:36,736 Epoch[39] Batch [1330]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.092710,	
2017-07-29 00:16:41,518 Epoch[39] Batch [1340]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.092672,	
2017-07-29 00:16:46,153 Epoch[39] Batch [1350]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092655,	
2017-07-29 00:16:50,766 Epoch[39] Batch [1360]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092675,	
2017-07-29 00:16:55,371 Epoch[39] Batch [1370]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092726,	
2017-07-29 00:17:00,194 Epoch[39] Batch [1380]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092765,	
2017-07-29 00:17:04,779 Epoch[39] Batch [1390]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092691,	
2017-07-29 00:17:09,504 Epoch[39] Batch [1400]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092684,	
2017-07-29 00:17:14,148 Epoch[39] Batch [1410]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092808,	
2017-07-29 00:17:18,790 Epoch[39] Batch [1420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092868,	
2017-07-29 00:17:23,340 Epoch[39] Batch [1430]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.092913,	
2017-07-29 00:17:28,206 Epoch[39] Batch [1440]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092862,	
2017-07-29 00:17:33,010 Epoch[39] Batch [1450]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092883,	
2017-07-29 00:17:37,835 Epoch[39] Batch [1460]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092926,	
2017-07-29 00:17:42,727 Epoch[39] Batch [1470]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092934,	
2017-07-29 00:17:47,495 Epoch[39] Batch [1480]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092935,	
2017-07-29 00:17:50,262 Epoch[39] Train-FCNLogLoss=0.092865
2017-07-29 00:17:50,262 Epoch[39] Time cost=712.675
2017-07-29 00:17:51,096 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.params"
2017-07-29 00:17:53,240 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.states"
2017-07-29 00:17:58,634 Epoch[40] Batch [10]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090128,	
2017-07-29 00:18:03,303 Epoch[40] Batch [20]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090866,	
2017-07-29 00:18:08,123 Epoch[40] Batch [30]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087671,	
2017-07-29 00:18:13,095 Epoch[40] Batch [40]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089918,	
2017-07-29 00:18:18,011 Epoch[40] Batch [50]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.091525,	
2017-07-29 00:18:22,890 Epoch[40] Batch [60]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.093184,	
2017-07-29 00:18:27,986 Epoch[40] Batch [70]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092506,	
2017-07-29 00:18:32,856 Epoch[40] Batch [80]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.091949,	
2017-07-29 00:18:37,640 Epoch[40] Batch [90]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.093463,	
2017-07-29 00:18:42,485 Epoch[40] Batch [100]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.094384,	
2017-07-29 00:18:47,579 Epoch[40] Batch [110]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094112,	
2017-07-29 00:18:52,558 Epoch[40] Batch [120]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.094275,	
2017-07-29 00:18:57,443 Epoch[40] Batch [130]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.094582,	
2017-07-29 00:19:02,483 Epoch[40] Batch [140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094680,	
2017-07-29 00:19:07,434 Epoch[40] Batch [150]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.094741,	
2017-07-29 00:19:12,340 Epoch[40] Batch [160]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.094610,	
2017-07-29 00:19:17,521 Epoch[40] Batch [170]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095049,	
2017-07-29 00:19:22,390 Epoch[40] Batch [180]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.094555,	
2017-07-29 00:19:27,446 Epoch[40] Batch [190]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.094126,	
2017-07-29 00:19:32,355 Epoch[40] Batch [200]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.093915,	
2017-07-29 00:19:37,357 Epoch[40] Batch [210]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093852,	
2017-07-29 00:19:42,395 Epoch[40] Batch [220]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093669,	
2017-07-29 00:19:47,498 Epoch[40] Batch [230]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.093736,	
2017-07-29 00:19:52,548 Epoch[40] Batch [240]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.093634,	
2017-07-29 00:19:57,433 Epoch[40] Batch [250]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.094108,	
2017-07-29 00:20:02,288 Epoch[40] Batch [260]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.094525,	
2017-07-29 00:20:07,329 Epoch[40] Batch [270]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094532,	
2017-07-29 00:20:12,282 Epoch[40] Batch [280]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.094529,	
2017-07-29 00:20:17,041 Epoch[40] Batch [290]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.094400,	
2017-07-29 00:20:21,810 Epoch[40] Batch [300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094243,	
2017-07-29 00:20:26,681 Epoch[40] Batch [310]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.094019,	
2017-07-29 00:20:31,517 Epoch[40] Batch [320]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.094034,	
2017-07-29 00:20:36,133 Epoch[40] Batch [330]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.093928,	
2017-07-29 00:20:40,938 Epoch[40] Batch [340]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.093746,	
2017-07-29 00:20:45,800 Epoch[40] Batch [350]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.093688,	
2017-07-29 00:20:50,617 Epoch[40] Batch [360]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.093609,	
2017-07-29 00:20:55,646 Epoch[40] Batch [370]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.093620,	
2017-07-29 00:21:00,481 Epoch[40] Batch [380]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093655,	
2017-07-29 00:21:05,271 Epoch[40] Batch [390]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.093636,	
2017-07-29 00:21:10,175 Epoch[40] Batch [400]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.093490,	
2017-07-29 00:21:15,190 Epoch[40] Batch [410]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.093484,	
2017-07-29 00:21:20,063 Epoch[40] Batch [420]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.093518,	
2017-07-29 00:21:24,950 Epoch[40] Batch [430]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.093633,	
2017-07-29 00:21:29,991 Epoch[40] Batch [440]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093757,	
2017-07-29 00:21:34,815 Epoch[40] Batch [450]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.093592,	
2017-07-29 00:21:39,898 Epoch[40] Batch [460]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093600,	
2017-07-29 00:21:44,669 Epoch[40] Batch [470]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.093582,	
2017-07-29 00:21:49,508 Epoch[40] Batch [480]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093407,	
2017-07-29 00:21:54,305 Epoch[40] Batch [490]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093455,	
2017-07-29 00:21:59,099 Epoch[40] Batch [500]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093295,	
2017-07-29 00:22:03,954 Epoch[40] Batch [510]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.093536,	
2017-07-29 00:22:07,829 Update[60000]: Change learning rate to 5.00000e-05
2017-07-29 00:22:08,753 Epoch[40] Batch [520]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093239,	
2017-07-29 00:22:13,559 Epoch[40] Batch [530]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.093244,	
2017-07-29 00:22:18,723 Epoch[40] Batch [540]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093137,	
2017-07-29 00:22:23,565 Epoch[40] Batch [550]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.093114,	
2017-07-29 00:22:28,226 Epoch[40] Batch [560]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.093083,	
2017-07-29 00:22:33,240 Epoch[40] Batch [570]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.093093,	
2017-07-29 00:22:38,296 Epoch[40] Batch [580]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092980,	
2017-07-29 00:22:43,201 Epoch[40] Batch [590]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092972,	
2017-07-29 00:22:48,121 Epoch[40] Batch [600]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092835,	
2017-07-29 00:22:52,989 Epoch[40] Batch [610]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092828,	
2017-07-29 00:22:57,890 Epoch[40] Batch [620]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092674,	
2017-07-29 00:23:02,904 Epoch[40] Batch [630]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.092650,	
2017-07-29 00:23:07,795 Epoch[40] Batch [640]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092472,	
2017-07-29 00:23:12,671 Epoch[40] Batch [650]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.092260,	
2017-07-29 00:23:17,538 Epoch[40] Batch [660]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092290,	
2017-07-29 00:23:22,362 Epoch[40] Batch [670]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092329,	
2017-07-29 00:23:27,233 Epoch[40] Batch [680]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.092215,	
2017-07-29 00:23:32,354 Epoch[40] Batch [690]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.092058,	
2017-07-29 00:23:37,176 Epoch[40] Batch [700]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092054,	
2017-07-29 00:23:41,769 Epoch[40] Batch [710]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092001,	
2017-07-29 00:23:46,789 Epoch[40] Batch [720]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.092034,	
2017-07-29 00:23:51,439 Epoch[40] Batch [730]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091982,	
2017-07-29 00:23:56,547 Epoch[40] Batch [740]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.092052,	
2017-07-29 00:24:01,512 Epoch[40] Batch [750]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.092015,	
2017-07-29 00:24:06,310 Epoch[40] Batch [760]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.091977,	
2017-07-29 00:24:11,109 Epoch[40] Batch [770]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092093,	
2017-07-29 00:24:15,960 Epoch[40] Batch [780]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.092073,	
2017-07-29 00:24:21,040 Epoch[40] Batch [790]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.092103,	
2017-07-29 00:24:25,868 Epoch[40] Batch [800]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092092,	
2017-07-29 00:24:30,972 Epoch[40] Batch [810]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.092124,	
2017-07-29 00:24:35,638 Epoch[40] Batch [820]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.092089,	
2017-07-29 00:24:40,394 Epoch[40] Batch [830]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092009,	
2017-07-29 00:24:45,301 Epoch[40] Batch [840]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.091950,	
2017-07-29 00:24:50,086 Epoch[40] Batch [850]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.091853,	
2017-07-29 00:24:54,914 Epoch[40] Batch [860]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091753,	
2017-07-29 00:24:59,741 Epoch[40] Batch [870]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091733,	
2017-07-29 00:25:04,876 Epoch[40] Batch [880]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.091627,	
2017-07-29 00:25:09,772 Epoch[40] Batch [890]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.091620,	
2017-07-29 00:25:15,041 Epoch[40] Batch [900]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091627,	
2017-07-29 00:25:20,306 Epoch[40] Batch [910]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091588,	
2017-07-29 00:25:25,425 Epoch[40] Batch [920]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.091544,	
2017-07-29 00:25:30,753 Epoch[40] Batch [930]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091521,	
2017-07-29 00:25:36,249 Epoch[40] Batch [940]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.091517,	
2017-07-29 00:25:41,377 Epoch[40] Batch [950]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.091550,	
2017-07-29 00:25:46,637 Epoch[40] Batch [960]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091601,	
2017-07-29 00:25:51,797 Epoch[40] Batch [970]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.091583,	
2017-07-29 00:25:56,792 Epoch[40] Batch [980]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.091610,	
2017-07-29 00:26:02,112 Epoch[40] Batch [990]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091515,	
2017-07-29 00:26:07,460 Epoch[40] Batch [1000]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091501,	
2017-07-29 00:26:12,775 Epoch[40] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091456,	
2017-07-29 00:26:18,137 Epoch[40] Batch [1020]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091425,	
2017-07-29 00:26:23,615 Epoch[40] Batch [1030]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.091398,	
2017-07-29 00:26:28,890 Epoch[40] Batch [1040]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091295,	
2017-07-29 00:26:33,994 Epoch[40] Batch [1050]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.091284,	
2017-07-29 00:26:39,056 Epoch[40] Batch [1060]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.091254,	
2017-07-29 00:26:44,412 Epoch[40] Batch [1070]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091190,	
2017-07-29 00:26:49,263 Epoch[40] Batch [1080]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091165,	
2017-07-29 00:26:54,404 Epoch[40] Batch [1090]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.091048,	
2017-07-29 00:26:59,189 Epoch[40] Batch [1100]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.091000,	
2017-07-29 00:27:04,178 Epoch[40] Batch [1110]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.090970,	
2017-07-29 00:27:09,434 Epoch[40] Batch [1120]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090984,	
2017-07-29 00:27:14,247 Epoch[40] Batch [1130]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091021,	
2017-07-29 00:27:19,565 Epoch[40] Batch [1140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090972,	
2017-07-29 00:27:24,332 Epoch[40] Batch [1150]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090967,	
2017-07-29 00:27:29,118 Epoch[40] Batch [1160]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090910,	
2017-07-29 00:27:33,991 Epoch[40] Batch [1170]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.090895,	
2017-07-29 00:27:38,880 Epoch[40] Batch [1180]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.090861,	
2017-07-29 00:27:44,103 Epoch[40] Batch [1190]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.090881,	
2017-07-29 00:27:48,972 Epoch[40] Batch [1200]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090850,	
2017-07-29 00:27:53,816 Epoch[40] Batch [1210]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090803,	
2017-07-29 00:27:58,823 Epoch[40] Batch [1220]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.090806,	
2017-07-29 00:28:03,824 Epoch[40] Batch [1230]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.090774,	
2017-07-29 00:28:08,811 Epoch[40] Batch [1240]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.090718,	
2017-07-29 00:28:13,684 Epoch[40] Batch [1250]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.090732,	
2017-07-29 00:28:18,525 Epoch[40] Batch [1260]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090802,	
2017-07-29 00:28:23,334 Epoch[40] Batch [1270]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090799,	
2017-07-29 00:28:28,255 Epoch[40] Batch [1280]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090775,	
2017-07-29 00:28:33,248 Epoch[40] Batch [1290]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.090726,	
2017-07-29 00:28:37,878 Epoch[40] Batch [1300]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090632,	
2017-07-29 00:28:42,916 Epoch[40] Batch [1310]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090662,	
2017-07-29 00:28:47,929 Epoch[40] Batch [1320]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.090647,	
2017-07-29 00:28:52,896 Epoch[40] Batch [1330]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.090565,	
2017-07-29 00:28:58,098 Epoch[40] Batch [1340]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.090512,	
2017-07-29 00:29:03,046 Epoch[40] Batch [1350]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.090500,	
2017-07-29 00:29:07,866 Epoch[40] Batch [1360]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.090542,	
2017-07-29 00:29:12,648 Epoch[40] Batch [1370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090508,	
2017-07-29 00:29:17,527 Epoch[40] Batch [1380]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090496,	
2017-07-29 00:29:22,446 Epoch[40] Batch [1390]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090475,	
2017-07-29 00:29:27,337 Epoch[40] Batch [1400]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.090486,	
2017-07-29 00:29:32,139 Epoch[40] Batch [1410]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.090484,	
2017-07-29 00:29:36,939 Epoch[40] Batch [1420]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.090445,	
2017-07-29 00:29:41,810 Epoch[40] Batch [1430]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.090405,	
2017-07-29 00:29:46,800 Epoch[40] Batch [1440]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.090409,	
2017-07-29 00:29:51,590 Epoch[40] Batch [1450]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.090338,	
2017-07-29 00:29:56,096 Epoch[40] Batch [1460]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.090382,	
2017-07-29 00:30:01,131 Epoch[40] Batch [1470]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.090410,	
2017-07-29 00:30:06,007 Epoch[40] Batch [1480]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090380,	
2017-07-29 00:30:08,984 Epoch[40] Train-FCNLogLoss=0.090357
2017-07-29 00:30:08,985 Epoch[40] Time cost=735.744
2017-07-29 00:30:09,657 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.params"
2017-07-29 00:30:11,676 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.states"
2017-07-29 00:30:17,274 Epoch[41] Batch [10]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.097958,	
2017-07-29 00:30:22,089 Epoch[41] Batch [20]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.093274,	
2017-07-29 00:30:27,054 Epoch[41] Batch [30]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.095105,	
2017-07-29 00:30:32,142 Epoch[41] Batch [40]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.094228,	
2017-07-29 00:30:37,147 Epoch[41] Batch [50]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.092340,	
2017-07-29 00:30:42,036 Epoch[41] Batch [60]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092626,	
2017-07-29 00:30:46,954 Epoch[41] Batch [70]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092950,	
2017-07-29 00:30:51,771 Epoch[41] Batch [80]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092198,	
2017-07-29 00:30:57,060 Epoch[41] Batch [90]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091717,	
2017-07-29 00:31:01,928 Epoch[41] Batch [100]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.091471,	
2017-07-29 00:31:06,945 Epoch[41] Batch [110]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.090978,	
2017-07-29 00:31:11,515 Epoch[41] Batch [120]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090599,	
2017-07-29 00:31:16,190 Epoch[41] Batch [130]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090282,	
2017-07-29 00:31:21,241 Epoch[41] Batch [140]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089724,	
2017-07-29 00:31:26,163 Epoch[41] Batch [150]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088977,	
2017-07-29 00:31:31,162 Epoch[41] Batch [160]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089292,	
2017-07-29 00:31:36,194 Epoch[41] Batch [170]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.089342,	
2017-07-29 00:31:41,303 Epoch[41] Batch [180]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089410,	
2017-07-29 00:31:45,959 Epoch[41] Batch [190]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089071,	
2017-07-29 00:31:50,812 Epoch[41] Batch [200]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.089134,	
2017-07-29 00:31:55,619 Epoch[41] Batch [210]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088806,	
2017-07-29 00:32:00,453 Epoch[41] Batch [220]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088738,	
2017-07-29 00:32:05,270 Epoch[41] Batch [230]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088944,	
2017-07-29 00:32:10,195 Epoch[41] Batch [240]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088931,	
2017-07-29 00:32:15,472 Epoch[41] Batch [250]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089006,	
2017-07-29 00:32:20,229 Epoch[41] Batch [260]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089019,	
2017-07-29 00:32:25,028 Epoch[41] Batch [270]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088915,	
2017-07-29 00:32:29,829 Epoch[41] Batch [280]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088970,	
2017-07-29 00:32:34,821 Epoch[41] Batch [290]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089070,	
2017-07-29 00:32:39,581 Epoch[41] Batch [300]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089121,	
2017-07-29 00:32:44,678 Epoch[41] Batch [310]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.089098,	
2017-07-29 00:32:49,905 Epoch[41] Batch [320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088789,	
2017-07-29 00:32:54,867 Epoch[41] Batch [330]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088490,	
2017-07-29 00:32:59,697 Epoch[41] Batch [340]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088568,	
2017-07-29 00:33:04,589 Epoch[41] Batch [350]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088391,	
2017-07-29 00:33:09,433 Epoch[41] Batch [360]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088593,	
2017-07-29 00:33:14,353 Epoch[41] Batch [370]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088558,	
2017-07-29 00:33:19,581 Epoch[41] Batch [380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088443,	
2017-07-29 00:33:24,374 Epoch[41] Batch [390]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088290,	
2017-07-29 00:33:29,256 Epoch[41] Batch [400]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088297,	
2017-07-29 00:33:33,910 Epoch[41] Batch [410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088304,	
2017-07-29 00:33:38,819 Epoch[41] Batch [420]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.088274,	
2017-07-29 00:33:43,363 Epoch[41] Batch [430]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088088,	
2017-07-29 00:33:48,107 Epoch[41] Batch [440]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088059,	
2017-07-29 00:33:52,613 Epoch[41] Batch [450]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.088215,	
2017-07-29 00:33:57,401 Epoch[41] Batch [460]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088199,	
2017-07-29 00:34:01,790 Epoch[41] Batch [470]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.088292,	
2017-07-29 00:34:06,375 Epoch[41] Batch [480]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.088650,	
2017-07-29 00:34:11,145 Epoch[41] Batch [490]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088744,	
2017-07-29 00:34:15,738 Epoch[41] Batch [500]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088739,	
2017-07-29 00:34:20,382 Epoch[41] Batch [510]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088790,	
2017-07-29 00:34:25,213 Epoch[41] Batch [520]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088962,	
2017-07-29 00:34:30,041 Epoch[41] Batch [530]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089076,	
2017-07-29 00:34:34,917 Epoch[41] Batch [540]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089047,	
2017-07-29 00:34:39,587 Epoch[41] Batch [550]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089020,	
2017-07-29 00:34:44,412 Epoch[41] Batch [560]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089028,	
2017-07-29 00:34:49,004 Epoch[41] Batch [570]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088905,	
2017-07-29 00:34:53,629 Epoch[41] Batch [580]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.088849,	
2017-07-29 00:34:59,395 Epoch[41] Batch [590]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.088718,	
2017-07-29 00:35:04,084 Epoch[41] Batch [600]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.088698,	
2017-07-29 00:35:09,104 Epoch[41] Batch [610]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088580,	
2017-07-29 00:35:13,701 Epoch[41] Batch [620]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088523,	
2017-07-29 00:35:18,594 Epoch[41] Batch [630]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088465,	
2017-07-29 00:35:23,575 Epoch[41] Batch [640]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.088429,	
2017-07-29 00:35:28,235 Epoch[41] Batch [650]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088443,	
2017-07-29 00:35:33,020 Epoch[41] Batch [660]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088567,	
2017-07-29 00:35:37,807 Epoch[41] Batch [670]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088564,	
2017-07-29 00:35:42,459 Epoch[41] Batch [680]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088653,	
2017-07-29 00:35:47,222 Epoch[41] Batch [690]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088595,	
2017-07-29 00:35:51,905 Epoch[41] Batch [700]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088505,	
2017-07-29 00:35:56,479 Epoch[41] Batch [710]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088496,	
2017-07-29 00:36:01,132 Epoch[41] Batch [720]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088439,	
2017-07-29 00:36:05,960 Epoch[41] Batch [730]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088387,	
2017-07-29 00:36:10,739 Epoch[41] Batch [740]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088415,	
2017-07-29 00:36:15,563 Epoch[41] Batch [750]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088329,	
2017-07-29 00:36:20,244 Epoch[41] Batch [760]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088435,	
2017-07-29 00:36:25,041 Epoch[41] Batch [770]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088461,	
2017-07-29 00:36:29,799 Epoch[41] Batch [780]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088468,	
2017-07-29 00:36:34,652 Epoch[41] Batch [790]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088477,	
2017-07-29 00:36:39,524 Epoch[41] Batch [800]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088438,	
2017-07-29 00:36:44,304 Epoch[41] Batch [810]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088349,	
2017-07-29 00:36:49,051 Epoch[41] Batch [820]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088453,	
2017-07-29 00:36:53,888 Epoch[41] Batch [830]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088529,	
2017-07-29 00:36:58,705 Epoch[41] Batch [840]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088606,	
2017-07-29 00:37:03,510 Epoch[41] Batch [850]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088617,	
2017-07-29 00:37:08,398 Epoch[41] Batch [860]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088658,	
2017-07-29 00:37:13,276 Epoch[41] Batch [870]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088653,	
2017-07-29 00:37:17,915 Epoch[41] Batch [880]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088688,	
2017-07-29 00:37:22,710 Epoch[41] Batch [890]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088621,	
2017-07-29 00:37:27,382 Epoch[41] Batch [900]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088682,	
2017-07-29 00:37:32,100 Epoch[41] Batch [910]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088595,	
2017-07-29 00:37:36,920 Epoch[41] Batch [920]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088608,	
2017-07-29 00:37:41,793 Epoch[41] Batch [930]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088572,	
2017-07-29 00:37:46,630 Epoch[41] Batch [940]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088602,	
2017-07-29 00:37:51,229 Epoch[41] Batch [950]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088665,	
2017-07-29 00:37:56,203 Epoch[41] Batch [960]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088627,	
2017-07-29 00:38:00,812 Epoch[41] Batch [970]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088592,	
2017-07-29 00:38:05,547 Epoch[41] Batch [980]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088590,	
2017-07-29 00:38:10,642 Epoch[41] Batch [990]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088536,	
2017-07-29 00:38:15,786 Epoch[41] Batch [1000]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088569,	
2017-07-29 00:38:20,660 Epoch[41] Batch [1010]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088680,	
2017-07-29 00:38:25,470 Epoch[41] Batch [1020]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088659,	
2017-07-29 00:38:30,494 Epoch[41] Batch [1030]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088590,	
2017-07-29 00:38:35,590 Epoch[41] Batch [1040]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088664,	
2017-07-29 00:38:40,598 Epoch[41] Batch [1050]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088617,	
2017-07-29 00:38:45,653 Epoch[41] Batch [1060]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088612,	
2017-07-29 00:38:50,657 Epoch[41] Batch [1070]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088600,	
2017-07-29 00:38:55,609 Epoch[41] Batch [1080]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088647,	
2017-07-29 00:39:00,647 Epoch[41] Batch [1090]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088677,	
2017-07-29 00:39:05,863 Epoch[41] Batch [1100]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.088611,	
2017-07-29 00:39:10,782 Epoch[41] Batch [1110]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088573,	
2017-07-29 00:39:15,681 Epoch[41] Batch [1120]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088605,	
2017-07-29 00:39:20,640 Epoch[41] Batch [1130]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088660,	
2017-07-29 00:39:25,511 Epoch[41] Batch [1140]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088663,	
2017-07-29 00:39:30,362 Epoch[41] Batch [1150]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088617,	
2017-07-29 00:39:35,839 Epoch[41] Batch [1160]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088609,	
2017-07-29 00:39:41,042 Epoch[41] Batch [1170]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088657,	
2017-07-29 00:39:45,991 Epoch[41] Batch [1180]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088672,	
2017-07-29 00:39:51,224 Epoch[41] Batch [1190]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088675,	
2017-07-29 00:39:56,263 Epoch[41] Batch [1200]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088677,	
2017-07-29 00:40:01,160 Epoch[41] Batch [1210]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088622,	
2017-07-29 00:40:06,277 Epoch[41] Batch [1220]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088643,	
2017-07-29 00:40:11,520 Epoch[41] Batch [1230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088654,	
2017-07-29 00:40:16,413 Epoch[41] Batch [1240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088583,	
2017-07-29 00:40:21,561 Epoch[41] Batch [1250]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088606,	
2017-07-29 00:40:26,601 Epoch[41] Batch [1260]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088503,	
2017-07-29 00:40:31,464 Epoch[41] Batch [1270]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088499,	
2017-07-29 00:40:36,299 Epoch[41] Batch [1280]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088536,	
2017-07-29 00:40:41,358 Epoch[41] Batch [1290]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088560,	
2017-07-29 00:40:46,457 Epoch[41] Batch [1300]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088547,	
2017-07-29 00:40:51,335 Epoch[41] Batch [1310]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088644,	
2017-07-29 00:40:56,599 Epoch[41] Batch [1320]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088675,	
2017-07-29 00:41:01,618 Epoch[41] Batch [1330]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088706,	
2017-07-29 00:41:06,547 Epoch[41] Batch [1340]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088712,	
2017-07-29 00:41:11,630 Epoch[41] Batch [1350]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088727,	
2017-07-29 00:41:16,704 Epoch[41] Batch [1360]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088737,	
2017-07-29 00:41:21,748 Epoch[41] Batch [1370]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088764,	
2017-07-29 00:41:26,877 Epoch[41] Batch [1380]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088747,	
2017-07-29 00:41:32,149 Epoch[41] Batch [1390]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088770,	
2017-07-29 00:41:37,108 Epoch[41] Batch [1400]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088754,	
2017-07-29 00:41:42,279 Epoch[41] Batch [1410]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088729,	
2017-07-29 00:41:47,558 Epoch[41] Batch [1420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088738,	
2017-07-29 00:41:52,431 Epoch[41] Batch [1430]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088609,	
2017-07-29 00:41:57,499 Epoch[41] Batch [1440]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088568,	
2017-07-29 00:42:02,608 Epoch[41] Batch [1450]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088550,	
2017-07-29 00:42:07,715 Epoch[41] Batch [1460]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088515,	
2017-07-29 00:42:12,522 Epoch[41] Batch [1470]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088508,	
2017-07-29 00:42:17,605 Epoch[41] Batch [1480]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088501,	
2017-07-29 00:42:20,576 Epoch[41] Train-FCNLogLoss=0.088487
2017-07-29 00:42:20,577 Epoch[41] Time cost=728.900
2017-07-29 00:42:21,277 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.params"
2017-07-29 00:42:23,412 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.states"
2017-07-29 00:42:29,005 Epoch[42] Batch [10]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086836,	
2017-07-29 00:42:34,078 Epoch[42] Batch [20]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087676,	
2017-07-29 00:42:39,182 Epoch[42] Batch [30]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087178,	
2017-07-29 00:42:44,116 Epoch[42] Batch [40]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.085794,	
2017-07-29 00:42:49,156 Epoch[42] Batch [50]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.085099,	
2017-07-29 00:42:54,131 Epoch[42] Batch [60]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.084867,	
2017-07-29 00:42:58,947 Epoch[42] Batch [70]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.085196,	
2017-07-29 00:43:03,843 Epoch[42] Batch [80]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.085311,	
2017-07-29 00:43:08,914 Epoch[42] Batch [90]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.085565,	
2017-07-29 00:43:13,935 Epoch[42] Batch [100]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086784,	
2017-07-29 00:43:19,027 Epoch[42] Batch [110]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087635,	
2017-07-29 00:43:24,289 Epoch[42] Batch [120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086797,	
2017-07-29 00:43:29,407 Epoch[42] Batch [130]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086184,	
2017-07-29 00:43:34,250 Epoch[42] Batch [140]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086317,	
2017-07-29 00:43:39,299 Epoch[42] Batch [150]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.086248,	
2017-07-29 00:43:44,344 Epoch[42] Batch [160]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087092,	
2017-07-29 00:43:49,451 Epoch[42] Batch [170]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086989,	
2017-07-29 00:43:54,494 Epoch[42] Batch [180]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087143,	
2017-07-29 00:43:59,491 Epoch[42] Batch [190]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086758,	
2017-07-29 00:44:04,492 Epoch[42] Batch [200]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.086816,	
2017-07-29 00:44:09,593 Epoch[42] Batch [210]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086733,	
2017-07-29 00:44:14,653 Epoch[42] Batch [220]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086689,	
2017-07-29 00:44:19,498 Epoch[42] Batch [230]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086480,	
2017-07-29 00:44:24,542 Epoch[42] Batch [240]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086425,	
2017-07-29 00:44:29,534 Epoch[42] Batch [250]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086188,	
2017-07-29 00:44:34,701 Epoch[42] Batch [260]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086178,	
2017-07-29 00:44:39,832 Epoch[42] Batch [270]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086093,	
2017-07-29 00:44:44,725 Epoch[42] Batch [280]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086569,	
2017-07-29 00:44:49,777 Epoch[42] Batch [290]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.086539,	
2017-07-29 00:44:54,904 Epoch[42] Batch [300]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086304,	
2017-07-29 00:45:00,223 Epoch[42] Batch [310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086482,	
2017-07-29 00:45:05,313 Epoch[42] Batch [320]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086639,	
2017-07-29 00:45:10,278 Epoch[42] Batch [330]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086521,	
2017-07-29 00:45:15,362 Epoch[42] Batch [340]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086474,	
2017-07-29 00:45:20,317 Epoch[42] Batch [350]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.086326,	
2017-07-29 00:45:25,162 Epoch[42] Batch [360]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086417,	
2017-07-29 00:45:30,248 Epoch[42] Batch [370]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086771,	
2017-07-29 00:45:35,308 Epoch[42] Batch [380]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086741,	
2017-07-29 00:45:40,636 Epoch[42] Batch [390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086648,	
2017-07-29 00:45:45,702 Epoch[42] Batch [400]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086602,	
2017-07-29 00:45:50,832 Epoch[42] Batch [410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086716,	
2017-07-29 00:45:55,892 Epoch[42] Batch [420]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086823,	
2017-07-29 00:46:00,742 Epoch[42] Batch [430]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087131,	
2017-07-29 00:46:05,836 Epoch[42] Batch [440]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087227,	
2017-07-29 00:46:10,933 Epoch[42] Batch [450]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087719,	
2017-07-29 00:46:15,962 Epoch[42] Batch [460]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087646,	
2017-07-29 00:46:21,111 Epoch[42] Batch [470]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087674,	
2017-07-29 00:46:26,059 Epoch[42] Batch [480]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087688,	
2017-07-29 00:46:30,993 Epoch[42] Batch [490]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087901,	
2017-07-29 00:46:35,794 Epoch[42] Batch [500]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087981,	
2017-07-29 00:46:40,789 Epoch[42] Batch [510]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088193,	
2017-07-29 00:46:46,083 Epoch[42] Batch [520]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088113,	
2017-07-29 00:46:50,821 Epoch[42] Batch [530]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087917,	
2017-07-29 00:46:55,778 Epoch[42] Batch [540]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.087857,	
2017-07-29 00:47:00,753 Epoch[42] Batch [550]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087846,	
2017-07-29 00:47:05,500 Epoch[42] Batch [560]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087787,	
2017-07-29 00:47:10,453 Epoch[42] Batch [570]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087708,	
2017-07-29 00:47:15,154 Epoch[42] Batch [580]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087860,	
2017-07-29 00:47:19,978 Epoch[42] Batch [590]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087882,	
2017-07-29 00:47:24,934 Epoch[42] Batch [600]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.087709,	
2017-07-29 00:47:29,844 Epoch[42] Batch [610]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.087667,	
2017-07-29 00:47:34,899 Epoch[42] Batch [620]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087708,	
2017-07-29 00:47:39,770 Epoch[42] Batch [630]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.087641,	
2017-07-29 00:47:44,786 Epoch[42] Batch [640]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087788,	
2017-07-29 00:47:49,643 Epoch[42] Batch [650]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.087853,	
2017-07-29 00:47:54,663 Epoch[42] Batch [660]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087888,	
2017-07-29 00:48:00,022 Epoch[42] Batch [670]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087981,	
2017-07-29 00:48:05,051 Epoch[42] Batch [680]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087895,	
2017-07-29 00:48:10,165 Epoch[42] Batch [690]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087972,	
2017-07-29 00:48:14,989 Epoch[42] Batch [700]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088103,	
2017-07-29 00:48:19,789 Epoch[42] Batch [710]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088101,	
2017-07-29 00:48:24,619 Epoch[42] Batch [720]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088091,	
2017-07-29 00:48:29,755 Epoch[42] Batch [730]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088125,	
2017-07-29 00:48:34,791 Epoch[42] Batch [740]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088119,	
2017-07-29 00:48:39,864 Epoch[42] Batch [750]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088247,	
2017-07-29 00:48:44,886 Epoch[42] Batch [760]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088255,	
2017-07-29 00:48:50,044 Epoch[42] Batch [770]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088181,	
2017-07-29 00:48:55,135 Epoch[42] Batch [780]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088237,	
2017-07-29 00:48:59,752 Epoch[42] Batch [790]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088130,	
2017-07-29 00:49:03,562 Epoch[42] Batch [800]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.088293,	
2017-07-29 00:49:08,671 Epoch[42] Batch [810]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088259,	
2017-07-29 00:49:13,844 Epoch[42] Batch [820]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088175,	
2017-07-29 00:49:19,140 Epoch[42] Batch [830]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088116,	
2017-07-29 00:49:24,450 Epoch[42] Batch [840]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088167,	
2017-07-29 00:49:29,684 Epoch[42] Batch [850]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088071,	
2017-07-29 00:49:34,808 Epoch[42] Batch [860]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088118,	
2017-07-29 00:49:39,898 Epoch[42] Batch [870]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088176,	
2017-07-29 00:49:45,181 Epoch[42] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088313,	
2017-07-29 00:49:50,291 Epoch[42] Batch [890]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088211,	
2017-07-29 00:49:55,578 Epoch[42] Batch [900]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088151,	
2017-07-29 00:50:00,679 Epoch[42] Batch [910]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088153,	
2017-07-29 00:50:05,863 Epoch[42] Batch [920]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088038,	
2017-07-29 00:50:10,810 Epoch[42] Batch [930]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088053,	
2017-07-29 00:50:15,806 Epoch[42] Batch [940]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088104,	
2017-07-29 00:50:21,155 Epoch[42] Batch [950]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088177,	
2017-07-29 00:50:26,429 Epoch[42] Batch [960]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088191,	
2017-07-29 00:50:31,776 Epoch[42] Batch [970]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088136,	
2017-07-29 00:50:36,846 Epoch[42] Batch [980]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088178,	
2017-07-29 00:50:41,956 Epoch[42] Batch [990]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088131,	
2017-07-29 00:50:47,228 Epoch[42] Batch [1000]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088050,	
2017-07-29 00:50:52,299 Epoch[42] Batch [1010]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088014,	
2017-07-29 00:50:57,385 Epoch[42] Batch [1020]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088073,	
2017-07-29 00:51:02,418 Epoch[42] Batch [1030]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088175,	
2017-07-29 00:51:07,464 Epoch[42] Batch [1040]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088175,	
2017-07-29 00:51:12,514 Epoch[42] Batch [1050]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088222,	
2017-07-29 00:51:17,436 Epoch[42] Batch [1060]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088194,	
2017-07-29 00:51:22,472 Epoch[42] Batch [1070]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088167,	
2017-07-29 00:51:27,459 Epoch[42] Batch [1080]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088142,	
2017-07-29 00:51:32,443 Epoch[42] Batch [1090]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.088095,	
2017-07-29 00:51:37,541 Epoch[42] Batch [1100]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088145,	
2017-07-29 00:51:42,603 Epoch[42] Batch [1110]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.088120,	
2017-07-29 00:51:47,458 Epoch[42] Batch [1120]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088094,	
2017-07-29 00:51:52,538 Epoch[42] Batch [1130]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088130,	
2017-07-29 00:51:57,530 Epoch[42] Batch [1140]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088128,	
2017-07-29 00:52:02,473 Epoch[42] Batch [1150]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088133,	
2017-07-29 00:52:07,618 Epoch[42] Batch [1160]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088155,	
2017-07-29 00:52:12,637 Epoch[42] Batch [1170]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088143,	
2017-07-29 00:52:17,754 Epoch[42] Batch [1180]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088160,	
2017-07-29 00:52:22,951 Epoch[42] Batch [1190]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088127,	
2017-07-29 00:52:28,135 Epoch[42] Batch [1200]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088149,	
2017-07-29 00:52:33,216 Epoch[42] Batch [1210]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088111,	
2017-07-29 00:52:38,303 Epoch[42] Batch [1220]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088011,	
2017-07-29 00:52:43,553 Epoch[42] Batch [1230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087974,	
2017-07-29 00:52:48,708 Epoch[42] Batch [1240]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088049,	
2017-07-29 00:52:54,030 Epoch[42] Batch [1250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088126,	
2017-07-29 00:52:59,133 Epoch[42] Batch [1260]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088122,	
2017-07-29 00:53:04,125 Epoch[42] Batch [1270]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088152,	
2017-07-29 00:53:09,093 Epoch[42] Batch [1280]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088166,	
2017-07-29 00:53:14,618 Epoch[42] Batch [1290]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088139,	
2017-07-29 00:53:19,885 Epoch[42] Batch [1300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088135,	
2017-07-29 00:53:25,160 Epoch[42] Batch [1310]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088070,	
2017-07-29 00:53:30,333 Epoch[42] Batch [1320]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088078,	
2017-07-29 00:53:35,438 Epoch[42] Batch [1330]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088097,	
2017-07-29 00:53:40,486 Epoch[42] Batch [1340]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088089,	
2017-07-29 00:53:45,566 Epoch[42] Batch [1350]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088110,	
2017-07-29 00:53:50,833 Epoch[42] Batch [1360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088064,	
2017-07-29 00:53:56,108 Epoch[42] Batch [1370]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088059,	
2017-07-29 00:54:01,284 Epoch[42] Batch [1380]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088070,	
2017-07-29 00:54:06,569 Epoch[42] Batch [1390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088064,	
2017-07-29 00:54:11,721 Epoch[42] Batch [1400]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088054,	
2017-07-29 00:54:16,996 Epoch[42] Batch [1410]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088068,	
2017-07-29 00:54:22,128 Epoch[42] Batch [1420]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088052,	
2017-07-29 00:54:27,371 Epoch[42] Batch [1430]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088044,	
2017-07-29 00:54:32,541 Epoch[42] Batch [1440]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.088085,	
2017-07-29 00:54:37,570 Epoch[42] Batch [1450]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088119,	
2017-07-29 00:54:42,858 Epoch[42] Batch [1460]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088187,	
2017-07-29 00:54:47,918 Epoch[42] Batch [1470]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088168,	
2017-07-29 00:54:53,007 Epoch[42] Batch [1480]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088134,	
2017-07-29 00:54:55,799 Epoch[42] Train-FCNLogLoss=0.088133
2017-07-29 00:54:55,799 Epoch[42] Time cost=752.387
2017-07-29 00:54:56,475 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.params"
2017-07-29 00:54:58,597 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.states"
2017-07-29 00:55:04,478 Epoch[43] Batch [10]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093135,	
2017-07-29 00:55:09,804 Epoch[43] Batch [20]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097424,	
2017-07-29 00:55:14,873 Epoch[43] Batch [30]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.095872,	
2017-07-29 00:55:19,971 Epoch[43] Batch [40]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.095365,	
2017-07-29 00:55:24,854 Epoch[43] Batch [50]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.095529,	
2017-07-29 00:55:30,118 Epoch[43] Batch [60]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093127,	
2017-07-29 00:55:35,173 Epoch[43] Batch [70]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090629,	
2017-07-29 00:55:40,194 Epoch[43] Batch [80]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089650,	
2017-07-29 00:55:45,157 Epoch[43] Batch [90]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089230,	
2017-07-29 00:55:50,181 Epoch[43] Batch [100]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088596,	
2017-07-29 00:55:55,293 Epoch[43] Batch [110]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089474,	
2017-07-29 00:56:00,305 Epoch[43] Batch [120]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088673,	
2017-07-29 00:56:05,336 Epoch[43] Batch [130]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.089265,	
2017-07-29 00:56:11,002 Epoch[43] Batch [140]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089120,	
2017-07-29 00:56:16,064 Epoch[43] Batch [150]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.088648,	
2017-07-29 00:56:21,137 Epoch[43] Batch [160]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.089025,	
2017-07-29 00:56:26,452 Epoch[43] Batch [170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088935,	
2017-07-29 00:56:31,549 Epoch[43] Batch [180]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.089653,	
2017-07-29 00:56:36,675 Epoch[43] Batch [190]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.089006,	
2017-07-29 00:56:41,938 Epoch[43] Batch [200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088973,	
2017-07-29 00:56:46,810 Epoch[43] Batch [210]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088419,	
2017-07-29 00:56:51,939 Epoch[43] Batch [220]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088466,	
2017-07-29 00:56:56,975 Epoch[43] Batch [230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088291,	
2017-07-29 00:57:01,868 Epoch[43] Batch [240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088163,	
2017-07-29 00:57:06,714 Epoch[43] Batch [250]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088311,	
2017-07-29 00:57:11,856 Epoch[43] Batch [260]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088223,	
2017-07-29 00:57:16,975 Epoch[43] Batch [270]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088096,	
2017-07-29 00:57:21,910 Epoch[43] Batch [280]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.088248,	
2017-07-29 00:57:27,224 Epoch[43] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088096,	
2017-07-29 00:57:32,207 Epoch[43] Batch [300]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087905,	
2017-07-29 00:57:37,395 Epoch[43] Batch [310]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088188,	
2017-07-29 00:57:42,427 Epoch[43] Batch [320]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087936,	
2017-07-29 00:57:47,300 Epoch[43] Batch [330]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088057,	
2017-07-29 00:57:52,363 Epoch[43] Batch [340]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087996,	
2017-07-29 00:57:57,430 Epoch[43] Batch [350]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088179,	
2017-07-29 00:58:02,521 Epoch[43] Batch [360]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088127,	
2017-07-29 00:58:07,610 Epoch[43] Batch [370]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088131,	
2017-07-29 00:58:12,710 Epoch[43] Batch [380]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088175,	
2017-07-29 00:58:17,522 Epoch[43] Batch [390]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088243,	
2017-07-29 00:58:22,538 Epoch[43] Batch [400]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088277,	
2017-07-29 00:58:27,625 Epoch[43] Batch [410]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088349,	
2017-07-29 00:58:32,671 Epoch[43] Batch [420]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088262,	
2017-07-29 00:58:37,812 Epoch[43] Batch [430]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088147,	
2017-07-29 00:58:42,881 Epoch[43] Batch [440]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088105,	
2017-07-29 00:58:47,735 Epoch[43] Batch [450]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088017,	
2017-07-29 00:58:52,584 Epoch[43] Batch [460]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087945,	
2017-07-29 00:58:57,633 Epoch[43] Batch [470]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087750,	
2017-07-29 00:59:02,670 Epoch[43] Batch [480]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087669,	
2017-07-29 00:59:07,793 Epoch[43] Batch [490]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087584,	
2017-07-29 00:59:12,893 Epoch[43] Batch [500]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087534,	
2017-07-29 00:59:17,923 Epoch[43] Batch [510]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087716,	
2017-07-29 00:59:23,050 Epoch[43] Batch [520]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.087720,	
2017-07-29 00:59:28,249 Epoch[43] Batch [530]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087623,	
2017-07-29 00:59:33,219 Epoch[43] Batch [540]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087496,	
2017-07-29 00:59:38,258 Epoch[43] Batch [550]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087709,	
2017-07-29 00:59:43,093 Epoch[43] Batch [560]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087688,	
2017-07-29 00:59:47,802 Epoch[43] Batch [570]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087850,	
2017-07-29 00:59:52,864 Epoch[43] Batch [580]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087864,	
2017-07-29 00:59:57,687 Epoch[43] Batch [590]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087848,	
2017-07-29 01:00:02,783 Epoch[43] Batch [600]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087705,	
2017-07-29 01:00:07,878 Epoch[43] Batch [610]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087838,	
2017-07-29 01:00:12,955 Epoch[43] Batch [620]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087882,	
2017-07-29 01:00:17,776 Epoch[43] Batch [630]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087855,	
2017-07-29 01:00:22,765 Epoch[43] Batch [640]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088023,	
2017-07-29 01:00:27,475 Epoch[43] Batch [650]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088040,	
2017-07-29 01:00:32,537 Epoch[43] Batch [660]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087903,	
2017-07-29 01:00:37,554 Epoch[43] Batch [670]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087965,	
2017-07-29 01:00:42,607 Epoch[43] Batch [680]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087851,	
2017-07-29 01:00:47,778 Epoch[43] Batch [690]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.087842,	
2017-07-29 01:00:52,893 Epoch[43] Batch [700]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087922,	
2017-07-29 01:00:57,948 Epoch[43] Batch [710]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087891,	
2017-07-29 01:01:02,984 Epoch[43] Batch [720]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087844,	
2017-07-29 01:01:08,050 Epoch[43] Batch [730]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087901,	
2017-07-29 01:01:13,131 Epoch[43] Batch [740]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087886,	
2017-07-29 01:01:18,231 Epoch[43] Batch [750]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087952,	
2017-07-29 01:01:23,302 Epoch[43] Batch [760]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087908,	
2017-07-29 01:01:28,360 Epoch[43] Batch [770]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087845,	
2017-07-29 01:01:33,498 Epoch[43] Batch [780]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087838,	
2017-07-29 01:01:38,722 Epoch[43] Batch [790]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087826,	
2017-07-29 01:01:43,809 Epoch[43] Batch [800]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087789,	
2017-07-29 01:01:48,907 Epoch[43] Batch [810]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087665,	
2017-07-29 01:01:54,147 Epoch[43] Batch [820]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087666,	
2017-07-29 01:01:59,546 Epoch[43] Batch [830]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087682,	
2017-07-29 01:02:04,843 Epoch[43] Batch [840]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087752,	
2017-07-29 01:02:09,967 Epoch[43] Batch [850]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087848,	
2017-07-29 01:02:15,116 Epoch[43] Batch [860]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087851,	
2017-07-29 01:02:20,259 Epoch[43] Batch [870]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.087826,	
2017-07-29 01:02:25,393 Epoch[43] Batch [880]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087809,	
2017-07-29 01:02:30,502 Epoch[43] Batch [890]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087733,	
2017-07-29 01:02:36,071 Epoch[43] Batch [900]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087881,	
2017-07-29 01:02:41,352 Epoch[43] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087777,	
2017-07-29 01:02:46,402 Epoch[43] Batch [920]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087648,	
2017-07-29 01:02:51,403 Epoch[43] Batch [930]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087681,	
2017-07-29 01:02:56,673 Epoch[43] Batch [940]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087592,	
2017-07-29 01:03:01,566 Epoch[43] Batch [950]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.087622,	
2017-07-29 01:03:06,408 Epoch[43] Batch [960]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.087587,	
2017-07-29 01:03:11,436 Epoch[43] Batch [970]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087620,	
2017-07-29 01:03:16,595 Epoch[43] Batch [980]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087609,	
2017-07-29 01:03:21,608 Epoch[43] Batch [990]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087667,	
2017-07-29 01:03:26,458 Epoch[43] Batch [1000]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087651,	
2017-07-29 01:03:31,499 Epoch[43] Batch [1010]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087514,	
2017-07-29 01:03:36,593 Epoch[43] Batch [1020]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087508,	
2017-07-29 01:03:41,673 Epoch[43] Batch [1030]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087444,	
2017-07-29 01:03:46,903 Epoch[43] Batch [1040]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087453,	
2017-07-29 01:03:52,104 Epoch[43] Batch [1050]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087403,	
2017-07-29 01:03:57,269 Epoch[43] Batch [1060]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.087423,	
2017-07-29 01:04:02,134 Epoch[43] Batch [1070]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.087498,	
2017-07-29 01:04:07,535 Epoch[43] Batch [1080]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087496,	
2017-07-29 01:04:12,464 Epoch[43] Batch [1090]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.087567,	
2017-07-29 01:04:17,601 Epoch[43] Batch [1100]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087628,	
2017-07-29 01:04:22,825 Epoch[43] Batch [1110]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087595,	
2017-07-29 01:04:27,932 Epoch[43] Batch [1120]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087525,	
2017-07-29 01:04:33,012 Epoch[43] Batch [1130]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087514,	
2017-07-29 01:04:38,114 Epoch[43] Batch [1140]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087550,	
2017-07-29 01:04:42,962 Epoch[43] Batch [1150]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087588,	
2017-07-29 01:04:48,398 Epoch[43] Batch [1160]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087586,	
2017-07-29 01:04:53,808 Epoch[43] Batch [1170]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.087530,	
2017-07-29 01:04:58,761 Epoch[43] Batch [1180]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087582,	
2017-07-29 01:05:03,751 Epoch[43] Batch [1190]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087577,	
2017-07-29 01:05:08,716 Epoch[43] Batch [1200]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.087552,	
2017-07-29 01:05:14,157 Epoch[43] Batch [1210]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087499,	
2017-07-29 01:05:19,332 Epoch[43] Batch [1220]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087475,	
2017-07-29 01:05:24,419 Epoch[43] Batch [1230]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087483,	
2017-07-29 01:05:29,571 Epoch[43] Batch [1240]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.087522,	
2017-07-29 01:05:34,862 Epoch[43] Batch [1250]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087580,	
2017-07-29 01:05:39,614 Epoch[43] Batch [1260]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087593,	
2017-07-29 01:05:45,182 Epoch[43] Batch [1270]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087519,	
2017-07-29 01:05:50,873 Epoch[43] Batch [1280]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087543,	
2017-07-29 01:05:55,965 Epoch[43] Batch [1290]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087545,	
2017-07-29 01:06:01,118 Epoch[43] Batch [1300]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.087563,	
2017-07-29 01:06:06,231 Epoch[43] Batch [1310]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087579,	
2017-07-29 01:06:11,338 Epoch[43] Batch [1320]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087555,	
2017-07-29 01:06:16,697 Epoch[43] Batch [1330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087561,	
2017-07-29 01:06:21,350 Epoch[43] Batch [1340]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.087558,	
2017-07-29 01:06:26,341 Epoch[43] Batch [1350]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087633,	
2017-07-29 01:06:31,492 Epoch[43] Batch [1360]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087559,	
2017-07-29 01:06:36,675 Epoch[43] Batch [1370]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.087609,	
2017-07-29 01:06:41,769 Epoch[43] Batch [1380]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087566,	
2017-07-29 01:06:47,122 Epoch[43] Batch [1390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087583,	
2017-07-29 01:06:52,057 Epoch[43] Batch [1400]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087555,	
2017-07-29 01:06:57,089 Epoch[43] Batch [1410]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087536,	
2017-07-29 01:07:02,174 Epoch[43] Batch [1420]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087515,	
2017-07-29 01:07:07,478 Epoch[43] Batch [1430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087454,	
2017-07-29 01:07:13,038 Epoch[43] Batch [1440]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.087424,	
2017-07-29 01:07:18,242 Epoch[43] Batch [1450]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087398,	
2017-07-29 01:07:23,703 Epoch[43] Batch [1460]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.087384,	
2017-07-29 01:07:28,552 Epoch[43] Batch [1470]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087319,	
2017-07-29 01:07:33,728 Epoch[43] Batch [1480]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087328,	
2017-07-29 01:07:36,711 Epoch[43] Train-FCNLogLoss=0.087344
2017-07-29 01:07:36,711 Epoch[43] Time cost=758.114
2017-07-29 01:07:37,823 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.params"
2017-07-29 01:07:41,357 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.states"
2017-07-29 01:07:47,614 Epoch[44] Batch [10]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.078367,	
2017-07-29 01:07:52,719 Epoch[44] Batch [20]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.078153,	
2017-07-29 01:07:57,675 Epoch[44] Batch [30]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.080175,	
2017-07-29 01:08:03,532 Epoch[44] Batch [40]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.079774,	
2017-07-29 01:08:09,026 Epoch[44] Batch [50]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.081194,	
2017-07-29 01:08:14,774 Epoch[44] Batch [60]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.082271,	
2017-07-29 01:08:19,801 Epoch[44] Batch [70]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.082338,	
2017-07-29 01:08:25,038 Epoch[44] Batch [80]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.083496,	
2017-07-29 01:08:29,988 Epoch[44] Batch [90]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.084757,	
2017-07-29 01:08:35,384 Epoch[44] Batch [100]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.084222,	
2017-07-29 01:08:40,491 Epoch[44] Batch [110]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.084784,	
2017-07-29 01:08:45,987 Epoch[44] Batch [120]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.083533,	
2017-07-29 01:08:51,341 Epoch[44] Batch [130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.084154,	
2017-07-29 01:08:56,753 Epoch[44] Batch [140]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.084439,	
2017-07-29 01:09:01,894 Epoch[44] Batch [150]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.084638,	
2017-07-29 01:09:07,317 Epoch[44] Batch [160]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.085210,	
2017-07-29 01:09:12,481 Epoch[44] Batch [170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.085357,	
2017-07-29 01:09:17,579 Epoch[44] Batch [180]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.085475,	
2017-07-29 01:09:22,547 Epoch[44] Batch [190]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.085392,	
2017-07-29 01:09:27,699 Epoch[44] Batch [200]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.085411,	
2017-07-29 01:09:32,882 Epoch[44] Batch [210]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.085483,	
2017-07-29 01:09:38,325 Epoch[44] Batch [220]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.085322,	
2017-07-29 01:09:43,783 Epoch[44] Batch [230]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.085642,	
2017-07-29 01:09:49,456 Epoch[44] Batch [240]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.085386,	
2017-07-29 01:09:54,966 Epoch[44] Batch [250]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.085719,	
2017-07-29 01:09:59,913 Epoch[44] Batch [260]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.085720,	
2017-07-29 01:10:05,431 Epoch[44] Batch [270]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.085928,	
2017-07-29 01:10:10,623 Epoch[44] Batch [280]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.085974,	
2017-07-29 01:10:16,024 Epoch[44] Batch [290]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.086270,	
2017-07-29 01:10:21,045 Epoch[44] Batch [300]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086392,	
2017-07-29 01:10:26,279 Epoch[44] Batch [310]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086392,	
2017-07-29 01:10:31,709 Epoch[44] Batch [320]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.086329,	
2017-07-29 01:10:36,970 Epoch[44] Batch [330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086153,	
2017-07-29 01:10:42,660 Epoch[44] Batch [340]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.085901,	
2017-07-29 01:10:47,977 Epoch[44] Batch [350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086003,	
2017-07-29 01:10:53,451 Epoch[44] Batch [360]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.085927,	
2017-07-29 01:10:58,819 Epoch[44] Batch [370]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.085852,	
2017-07-29 01:11:04,400 Epoch[44] Batch [380]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.085712,	
2017-07-29 01:11:09,659 Epoch[44] Batch [390]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.085454,	
2017-07-29 01:11:15,096 Epoch[44] Batch [400]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085345,	
2017-07-29 01:11:20,143 Epoch[44] Batch [410]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.085209,	
2017-07-29 01:11:25,350 Epoch[44] Batch [420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.085172,	
2017-07-29 01:11:31,132 Epoch[44] Batch [430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085178,	
2017-07-29 01:11:36,857 Epoch[44] Batch [440]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.085253,	
2017-07-29 01:11:42,912 Epoch[44] Batch [450]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085496,	
2017-07-29 01:11:48,972 Epoch[44] Batch [460]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.085677,	
2017-07-29 01:11:54,969 Epoch[44] Batch [470]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085693,	
2017-07-29 01:12:00,907 Epoch[44] Batch [480]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.085830,	
2017-07-29 01:12:07,025 Epoch[44] Batch [490]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.085817,	
2017-07-29 01:12:12,741 Epoch[44] Batch [500]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.085921,	
2017-07-29 01:12:18,372 Epoch[44] Batch [510]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.085902,	
2017-07-29 01:12:23,862 Epoch[44] Batch [520]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.085994,	
2017-07-29 01:12:28,820 Epoch[44] Batch [530]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.086142,	
2017-07-29 01:12:33,794 Epoch[44] Batch [540]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.086270,	
2017-07-29 01:12:39,017 Epoch[44] Batch [550]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086435,	
2017-07-29 01:12:43,923 Epoch[44] Batch [560]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086418,	
2017-07-29 01:12:48,810 Epoch[44] Batch [570]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.086476,	
2017-07-29 01:12:53,916 Epoch[44] Batch [580]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086685,	
2017-07-29 01:12:58,778 Epoch[44] Batch [590]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.086589,	
2017-07-29 01:13:03,631 Epoch[44] Batch [600]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086489,	
2017-07-29 01:13:08,469 Epoch[44] Batch [610]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.086247,	
2017-07-29 01:13:13,282 Epoch[44] Batch [620]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.086346,	
2017-07-29 01:13:18,152 Epoch[44] Batch [630]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086351,	
2017-07-29 01:13:23,228 Epoch[44] Batch [640]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086355,	
2017-07-29 01:13:28,307 Epoch[44] Batch [650]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086320,	
2017-07-29 01:13:33,386 Epoch[44] Batch [660]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086320,	
2017-07-29 01:13:38,475 Epoch[44] Batch [670]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086387,	
2017-07-29 01:13:43,338 Epoch[44] Batch [680]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.086337,	
2017-07-29 01:13:48,190 Epoch[44] Batch [690]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086328,	
2017-07-29 01:13:53,101 Epoch[44] Batch [700]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.086393,	
2017-07-29 01:13:58,133 Epoch[44] Batch [710]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086390,	
2017-07-29 01:14:03,281 Epoch[44] Batch [720]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086340,	
2017-07-29 01:14:08,140 Epoch[44] Batch [730]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.086332,	
2017-07-29 01:14:13,175 Epoch[44] Batch [740]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086376,	
2017-07-29 01:14:18,193 Epoch[44] Batch [750]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-29 01:14:23,406 Epoch[44] Batch [760]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086246,	
2017-07-29 01:14:28,740 Epoch[44] Batch [770]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086220,	
2017-07-29 01:14:33,841 Epoch[44] Batch [780]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086273,	
2017-07-29 01:14:39,458 Epoch[44] Batch [790]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.086310,	
2017-07-29 01:14:44,353 Epoch[44] Batch [800]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086296,	
2017-07-29 01:14:49,688 Epoch[44] Batch [810]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086339,	
2017-07-29 01:14:54,623 Epoch[44] Batch [820]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086287,	
2017-07-29 01:15:00,234 Epoch[44] Batch [830]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.086265,	
2017-07-29 01:15:05,554 Epoch[44] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086264,	
2017-07-29 01:15:10,538 Epoch[44] Batch [850]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086291,	
2017-07-29 01:15:15,372 Epoch[44] Batch [860]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.086437,	
2017-07-29 01:15:20,710 Epoch[44] Batch [870]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086491,	
2017-07-29 01:15:25,974 Epoch[44] Batch [880]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086593,	
2017-07-29 01:15:31,168 Epoch[44] Batch [890]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.086599,	
2017-07-29 01:15:36,375 Epoch[44] Batch [900]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086558,	
2017-07-29 01:15:41,783 Epoch[44] Batch [910]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.086594,	
2017-07-29 01:15:47,425 Epoch[44] Batch [920]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086638,	
2017-07-29 01:15:52,719 Epoch[44] Batch [930]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086541,	
2017-07-29 01:15:58,763 Epoch[44] Batch [940]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086634,	
2017-07-29 01:16:04,592 Epoch[44] Batch [950]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.086633,	
2017-07-29 01:16:10,544 Epoch[44] Batch [960]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.086553,	
2017-07-29 01:16:16,452 Epoch[44] Batch [970]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.086653,	
2017-07-29 01:16:22,761 Epoch[44] Batch [980]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086777,	
2017-07-29 01:16:28,912 Epoch[44] Batch [990]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.086878,	
2017-07-29 01:16:34,789 Epoch[44] Batch [1000]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086849,	
2017-07-29 01:16:41,005 Epoch[44] Batch [1010]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086785,	
2017-07-29 01:16:46,964 Epoch[44] Batch [1020]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086784,	
2017-07-29 01:16:52,332 Epoch[44] Batch [1030]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.086751,	
2017-07-29 01:16:58,245 Epoch[44] Batch [1040]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.086709,	
2017-07-29 01:17:04,470 Epoch[44] Batch [1050]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086719,	
2017-07-29 01:17:10,325 Epoch[44] Batch [1060]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086726,	
2017-07-29 01:17:16,701 Epoch[44] Batch [1070]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.086742,	
2017-07-29 01:17:23,271 Epoch[44] Batch [1080]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.086707,	
2017-07-29 01:17:29,613 Epoch[44] Batch [1090]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.086706,	
2017-07-29 01:17:35,855 Epoch[44] Batch [1100]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.086805,	
2017-07-29 01:17:42,101 Epoch[44] Batch [1110]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086820,	
2017-07-29 01:17:48,433 Epoch[44] Batch [1120]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086903,	
2017-07-29 01:17:54,806 Epoch[44] Batch [1130]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086970,	
2017-07-29 01:18:01,554 Epoch[44] Batch [1140]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.086944,	
2017-07-29 01:18:07,721 Epoch[44] Batch [1150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.086972,	
2017-07-29 01:18:14,231 Epoch[44] Batch [1160]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.087015,	
2017-07-29 01:18:20,524 Epoch[44] Batch [1170]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087028,	
2017-07-29 01:18:26,681 Epoch[44] Batch [1180]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087092,	
2017-07-29 01:18:33,146 Epoch[44] Batch [1190]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087088,	
2017-07-29 01:18:39,946 Epoch[44] Batch [1200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087051,	
2017-07-29 01:18:46,868 Epoch[44] Batch [1210]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.086979,	
2017-07-29 01:18:53,552 Epoch[44] Batch [1220]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086951,	
2017-07-29 01:19:00,447 Epoch[44] Batch [1230]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086937,	
2017-07-29 01:19:06,947 Epoch[44] Batch [1240]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.086983,	
2017-07-29 01:19:13,169 Epoch[44] Batch [1250]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086923,	
2017-07-29 01:19:19,556 Epoch[44] Batch [1260]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.086870,	
2017-07-29 01:19:25,890 Epoch[44] Batch [1270]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086898,	
2017-07-29 01:19:32,084 Epoch[44] Batch [1280]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.086958,	
2017-07-29 01:19:38,098 Epoch[44] Batch [1290]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.086895,	
2017-07-29 01:19:44,154 Epoch[44] Batch [1300]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.086944,	
2017-07-29 01:19:50,487 Epoch[44] Batch [1310]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086958,	
2017-07-29 01:19:56,556 Epoch[44] Batch [1320]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.086994,	
2017-07-29 01:20:02,941 Epoch[44] Batch [1330]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.087010,	
2017-07-29 01:20:09,020 Epoch[44] Batch [1340]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.086990,	
2017-07-29 01:20:15,168 Epoch[44] Batch [1350]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086891,	
2017-07-29 01:20:21,633 Epoch[44] Batch [1360]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.086922,	
2017-07-29 01:20:27,592 Epoch[44] Batch [1370]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086902,	
2017-07-29 01:20:33,923 Epoch[44] Batch [1380]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086924,	
2017-07-29 01:20:40,358 Epoch[44] Batch [1390]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.086913,	
2017-07-29 01:20:46,758 Epoch[44] Batch [1400]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.086887,	
2017-07-29 01:20:52,718 Epoch[44] Batch [1410]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086904,	
2017-07-29 01:20:58,993 Epoch[44] Batch [1420]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.086914,	
2017-07-29 01:21:04,945 Epoch[44] Batch [1430]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.086931,	
2017-07-29 01:21:11,311 Epoch[44] Batch [1440]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086919,	
2017-07-29 01:21:17,685 Epoch[44] Batch [1450]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086926,	
2017-07-29 01:21:24,181 Epoch[44] Batch [1460]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.087081,	
2017-07-29 01:21:30,414 Epoch[44] Batch [1470]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087127,	
2017-07-29 01:21:36,939 Epoch[44] Batch [1480]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.087136,	
2017-07-29 01:21:40,628 Epoch[44] Train-FCNLogLoss=0.087098
2017-07-29 01:21:40,628 Epoch[44] Time cost=839.270
2017-07-29 01:21:41,568 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.params"
2017-07-29 01:21:45,022 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.states"
2017-07-29 01:21:52,391 Epoch[45] Batch [10]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.089367,	
2017-07-29 01:21:58,954 Epoch[45] Batch [20]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.086896,	
2017-07-29 01:22:05,284 Epoch[45] Batch [30]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088394,	
2017-07-29 01:22:11,807 Epoch[45] Batch [40]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.086958,	
2017-07-29 01:22:18,411 Epoch[45] Batch [50]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.085617,	
2017-07-29 01:22:24,759 Epoch[45] Batch [60]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086155,	
2017-07-29 01:22:31,040 Epoch[45] Batch [70]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.085058,	
2017-07-29 01:22:37,497 Epoch[45] Batch [80]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.085824,	
2017-07-29 01:22:43,829 Epoch[45] Batch [90]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087046,	
2017-07-29 01:22:50,254 Epoch[45] Batch [100]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086622,	
2017-07-29 01:22:57,116 Epoch[45] Batch [110]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086508,	
2017-07-29 01:23:03,824 Epoch[45] Batch [120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-29 01:23:10,307 Epoch[45] Batch [130]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086706,	
2017-07-29 01:23:16,975 Epoch[45] Batch [140]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086222,	
2017-07-29 01:23:23,676 Epoch[45] Batch [150]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086747,	
2017-07-29 01:23:30,138 Epoch[45] Batch [160]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087039,	
2017-07-29 01:23:36,998 Epoch[45] Batch [170]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086750,	
2017-07-29 01:23:43,616 Epoch[45] Batch [180]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.086735,	
2017-07-29 01:23:49,957 Epoch[45] Batch [190]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.086678,	
2017-07-29 01:23:56,710 Epoch[45] Batch [200]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086829,	
2017-07-29 01:24:03,548 Epoch[45] Batch [210]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.086841,	
2017-07-29 01:24:10,169 Epoch[45] Batch [220]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.086834,	
2017-07-29 01:24:17,053 Epoch[45] Batch [230]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.086888,	
2017-07-29 01:24:23,948 Epoch[45] Batch [240]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087036,	
2017-07-29 01:24:31,221 Epoch[45] Batch [250]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.086860,	
2017-07-29 01:24:38,436 Epoch[45] Batch [260]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087247,	
2017-07-29 01:24:45,141 Epoch[45] Batch [270]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.087415,	
2017-07-29 01:24:52,058 Epoch[45] Batch [280]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087359,	
2017-07-29 01:24:58,993 Epoch[45] Batch [290]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.087431,	
2017-07-29 01:25:05,927 Epoch[45] Batch [300]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.087240,	
2017-07-29 01:25:12,903 Epoch[45] Batch [310]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.087609,	
2017-07-29 01:25:19,819 Epoch[45] Batch [320]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087389,	
2017-07-29 01:25:26,815 Epoch[45] Batch [330]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087518,	
2017-07-29 01:25:33,733 Epoch[45] Batch [340]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087730,	
2017-07-29 01:25:40,872 Epoch[45] Batch [350]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087969,	
2017-07-29 01:25:48,048 Epoch[45] Batch [360]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088103,	
2017-07-29 01:25:55,372 Epoch[45] Batch [370]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.088208,	
2017-07-29 01:26:02,579 Epoch[45] Batch [380]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.088340,	
2017-07-29 01:26:09,768 Epoch[45] Batch [390]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088248,	
2017-07-29 01:26:17,060 Epoch[45] Batch [400]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.088301,	
2017-07-29 01:26:24,059 Epoch[45] Batch [410]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.088229,	
2017-07-29 01:26:30,973 Epoch[45] Batch [420]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088038,	
2017-07-29 01:26:38,209 Epoch[45] Batch [430]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087987,	
2017-07-29 01:26:45,130 Epoch[45] Batch [440]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088045,	
2017-07-29 01:26:52,202 Epoch[45] Batch [450]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087991,	
2017-07-29 01:26:59,735 Epoch[45] Batch [460]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087975,	
2017-07-29 01:27:06,920 Epoch[45] Batch [470]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088107,	
2017-07-29 01:27:13,851 Epoch[45] Batch [480]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.088136,	
2017-07-29 01:27:20,940 Epoch[45] Batch [490]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087950,	
2017-07-29 01:27:28,104 Epoch[45] Batch [500]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.087907,	
2017-07-29 01:27:35,119 Epoch[45] Batch [510]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088051,	
2017-07-29 01:27:42,441 Epoch[45] Batch [520]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087998,	
2017-07-29 01:27:49,356 Epoch[45] Batch [530]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088110,	
2017-07-29 01:27:56,377 Epoch[45] Batch [540]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088050,	
2017-07-29 01:28:03,290 Epoch[45] Batch [550]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.087884,	
2017-07-29 01:28:10,397 Epoch[45] Batch [560]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.087812,	
2017-07-29 01:28:17,460 Epoch[45] Batch [570]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087949,	
2017-07-29 01:28:24,662 Epoch[45] Batch [580]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087834,	
2017-07-29 01:28:31,881 Epoch[45] Batch [590]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087750,	
2017-07-29 01:28:38,584 Epoch[45] Batch [600]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.087573,	
2017-07-29 01:28:45,707 Epoch[45] Batch [610]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087544,	
2017-07-29 01:28:52,749 Epoch[45] Batch [620]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087783,	
2017-07-29 01:28:59,795 Epoch[45] Batch [630]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087808,	
2017-07-29 01:29:06,922 Epoch[45] Batch [640]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087727,	
2017-07-29 01:29:14,091 Epoch[45] Batch [650]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.087594,	
2017-07-29 01:29:21,325 Epoch[45] Batch [660]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087665,	
2017-07-29 01:29:28,454 Epoch[45] Batch [670]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087657,	
2017-07-29 01:29:35,604 Epoch[45] Batch [680]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087634,	
2017-07-29 01:29:42,846 Epoch[45] Batch [690]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087724,	
2017-07-29 01:29:50,178 Epoch[45] Batch [700]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087589,	
2017-07-29 01:29:57,048 Epoch[45] Batch [710]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.087520,	
2017-07-29 01:30:04,298 Epoch[45] Batch [720]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087502,	
2017-07-29 01:30:11,438 Epoch[45] Batch [730]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087337,	
2017-07-29 01:30:18,684 Epoch[45] Batch [740]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087268,	
2017-07-29 01:30:25,957 Epoch[45] Batch [750]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.087226,	
2017-07-29 01:30:33,147 Epoch[45] Batch [760]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087139,	
2017-07-29 01:30:40,343 Epoch[45] Batch [770]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.087060,	
2017-07-29 01:30:47,430 Epoch[45] Batch [780]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087114,	
2017-07-29 01:30:54,637 Epoch[45] Batch [790]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087033,	
2017-07-29 01:31:01,650 Epoch[45] Batch [800]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086895,	
2017-07-29 01:31:08,596 Epoch[45] Batch [810]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.086804,	
2017-07-29 01:31:15,686 Epoch[45] Batch [820]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086742,	
2017-07-29 01:31:23,114 Epoch[45] Batch [830]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.086753,	
2017-07-29 01:31:30,291 Epoch[45] Batch [840]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086714,	
2017-07-29 01:31:37,286 Epoch[45] Batch [850]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086574,	
2017-07-29 01:31:44,390 Epoch[45] Batch [860]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086640,	
2017-07-29 01:31:51,579 Epoch[45] Batch [870]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086653,	
2017-07-29 01:31:58,720 Epoch[45] Batch [880]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086610,	
2017-07-29 01:32:05,871 Epoch[45] Batch [890]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086696,	
2017-07-29 01:32:13,068 Epoch[45] Batch [900]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086759,	
2017-07-29 01:32:20,004 Epoch[45] Batch [910]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.086779,	
2017-07-29 01:32:27,157 Epoch[45] Batch [920]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086845,	
2017-07-29 01:32:34,656 Epoch[45] Batch [930]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.086969,	
2017-07-29 01:32:41,852 Epoch[45] Batch [940]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086966,	
2017-07-29 01:32:49,147 Epoch[45] Batch [950]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086971,	
2017-07-29 01:32:56,639 Epoch[45] Batch [960]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087021,	
2017-07-29 01:33:03,898 Epoch[45] Batch [970]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087009,	
2017-07-29 01:33:11,122 Epoch[45] Batch [980]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087086,	
2017-07-29 01:33:18,621 Epoch[45] Batch [990]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087108,	
2017-07-29 01:33:25,918 Epoch[45] Batch [1000]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087160,	
2017-07-29 01:33:33,308 Epoch[45] Batch [1010]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087184,	
2017-07-29 01:33:40,750 Epoch[45] Batch [1020]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.087126,	
2017-07-29 01:33:48,239 Epoch[45] Batch [1030]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087134,	
2017-07-29 01:33:55,859 Epoch[45] Batch [1040]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087162,	
2017-07-29 01:34:03,305 Epoch[45] Batch [1050]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087088,	
2017-07-29 01:34:10,919 Epoch[45] Batch [1060]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087052,	
2017-07-29 01:34:18,525 Epoch[45] Batch [1070]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.086977,	
2017-07-29 01:34:26,047 Epoch[45] Batch [1080]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.087016,	
2017-07-29 01:34:33,541 Epoch[45] Batch [1090]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.087037,	
2017-07-29 01:34:41,016 Epoch[45] Batch [1100]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087047,	
2017-07-29 01:34:48,421 Epoch[45] Batch [1110]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.086982,	
2017-07-29 01:34:55,942 Epoch[45] Batch [1120]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.087011,	
2017-07-29 01:35:03,635 Epoch[45] Batch [1130]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087001,	
2017-07-29 01:35:10,981 Epoch[45] Batch [1140]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.086999,	
2017-07-29 01:35:18,516 Epoch[45] Batch [1150]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087040,	
2017-07-29 01:35:26,025 Epoch[45] Batch [1160]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.086965,	
2017-07-29 01:35:33,439 Epoch[45] Batch [1170]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087002,	
2017-07-29 01:35:41,154 Epoch[45] Batch [1180]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.086996,	
2017-07-29 01:35:48,655 Epoch[45] Batch [1190]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087012,	
2017-07-29 01:35:55,880 Epoch[45] Batch [1200]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086992,	
2017-07-29 01:36:02,968 Epoch[45] Batch [1210]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086975,	
2017-07-29 01:36:07,789 Epoch[45] Batch [1220]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086942,	
2017-07-29 01:36:12,772 Epoch[45] Batch [1230]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086983,	
2017-07-29 01:36:17,629 Epoch[45] Batch [1240]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086998,	
2017-07-29 01:36:22,429 Epoch[45] Batch [1250]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087006,	
2017-07-29 01:36:27,406 Epoch[45] Batch [1260]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087010,	
2017-07-29 01:36:32,482 Epoch[45] Batch [1270]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087026,	
2017-07-29 01:36:37,504 Epoch[45] Batch [1280]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086955,	
2017-07-29 01:36:42,239 Epoch[45] Batch [1290]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.086932,	
2017-07-29 01:36:47,547 Epoch[45] Batch [1300]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086932,	
2017-07-29 01:36:52,566 Epoch[45] Batch [1310]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086927,	
2017-07-29 01:36:57,575 Epoch[45] Batch [1320]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087002,	
2017-07-29 01:37:02,775 Epoch[45] Batch [1330]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087065,	
2017-07-29 01:37:07,637 Epoch[45] Batch [1340]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087017,	
2017-07-29 01:37:12,450 Epoch[45] Batch [1350]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087065,	
2017-07-29 01:37:17,318 Epoch[45] Batch [1360]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.087031,	
2017-07-29 01:37:22,412 Epoch[45] Batch [1370]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086997,	
2017-07-29 01:37:27,453 Epoch[45] Batch [1380]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087008,	
2017-07-29 01:37:32,747 Epoch[45] Batch [1390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086968,	
2017-07-29 01:37:37,861 Epoch[45] Batch [1400]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087016,	
2017-07-29 01:37:42,995 Epoch[45] Batch [1410]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087022,	
2017-07-29 01:37:48,471 Epoch[45] Batch [1420]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.087007,	
2017-07-29 01:37:53,497 Epoch[45] Batch [1430]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087012,	
2017-07-29 01:37:58,635 Epoch[45] Batch [1440]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087029,	
2017-07-29 01:38:03,710 Epoch[45] Batch [1450]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087020,	
2017-07-29 01:38:08,763 Epoch[45] Batch [1460]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087001,	
2017-07-29 01:38:13,933 Epoch[45] Batch [1470]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.087019,	
2017-07-29 01:38:18,922 Epoch[45] Batch [1480]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087046,	
2017-07-29 01:38:21,955 Epoch[45] Train-FCNLogLoss=0.087030
2017-07-29 01:38:21,955 Epoch[45] Time cost=996.933
2017-07-29 01:38:22,614 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.params"
2017-07-29 01:38:25,967 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.states"
2017-07-29 01:38:31,763 Epoch[46] Batch [10]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.085464,	
2017-07-29 01:38:36,631 Epoch[46] Batch [20]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.082366,	
2017-07-29 01:38:41,692 Epoch[46] Batch [30]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.081797,	
2017-07-29 01:38:46,717 Epoch[46] Batch [40]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.083410,	
2017-07-29 01:38:51,671 Epoch[46] Batch [50]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.085826,	
2017-07-29 01:38:56,905 Epoch[46] Batch [60]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.085486,	
2017-07-29 01:39:01,844 Epoch[46] Batch [70]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086399,	
2017-07-29 01:39:06,667 Epoch[46] Batch [80]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086506,	
2017-07-29 01:39:11,795 Epoch[46] Batch [90]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.085682,	
2017-07-29 01:39:16,646 Epoch[46] Batch [100]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.085629,	
2017-07-29 01:39:21,697 Epoch[46] Batch [110]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.085893,	
2017-07-29 01:39:26,550 Epoch[46] Batch [120]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.085745,	
2017-07-29 01:39:31,588 Epoch[46] Batch [130]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.085179,	
2017-07-29 01:39:36,641 Epoch[46] Batch [140]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.085504,	
2017-07-29 01:39:41,701 Epoch[46] Batch [150]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.084959,	
2017-07-29 01:39:46,550 Epoch[46] Batch [160]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.084965,	
2017-07-29 01:39:51,426 Epoch[46] Batch [170]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.084906,	
2017-07-29 01:39:56,289 Epoch[46] Batch [180]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.085087,	
2017-07-29 01:40:01,240 Epoch[46] Batch [190]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.085200,	
2017-07-29 01:40:06,154 Epoch[46] Batch [200]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.085084,	
2017-07-29 01:40:11,048 Epoch[46] Batch [210]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.085374,	
2017-07-29 01:40:16,108 Epoch[46] Batch [220]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.085622,	
2017-07-29 01:40:20,949 Epoch[46] Batch [230]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.085370,	
2017-07-29 01:40:25,770 Epoch[46] Batch [240]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.085426,	
2017-07-29 01:40:30,590 Epoch[46] Batch [250]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.085463,	
2017-07-29 01:40:35,558 Epoch[46] Batch [260]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.085261,	
2017-07-29 01:40:40,405 Epoch[46] Batch [270]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.085189,	
2017-07-29 01:40:45,401 Epoch[46] Batch [280]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.085005,	
2017-07-29 01:40:50,329 Epoch[46] Batch [290]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.085320,	
2017-07-29 01:40:55,467 Epoch[46] Batch [300]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.085775,	
2017-07-29 01:41:00,673 Epoch[46] Batch [310]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.085784,	
2017-07-29 01:41:05,633 Epoch[46] Batch [320]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.085989,	
2017-07-29 01:41:10,473 Epoch[46] Batch [330]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.086157,	
2017-07-29 01:41:15,474 Epoch[46] Batch [340]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.086173,	
2017-07-29 01:41:20,633 Epoch[46] Batch [350]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.086095,	
2017-07-29 01:41:25,595 Epoch[46] Batch [360]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086098,	
2017-07-29 01:41:30,637 Epoch[46] Batch [370]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086211,	
2017-07-29 01:41:35,683 Epoch[46] Batch [380]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086327,	
2017-07-29 01:41:40,763 Epoch[46] Batch [390]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086399,	
2017-07-29 01:41:45,826 Epoch[46] Batch [400]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086357,	
2017-07-29 01:41:50,687 Epoch[46] Batch [410]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.086408,	
2017-07-29 01:41:55,858 Epoch[46] Batch [420]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086273,	
2017-07-29 01:42:00,905 Epoch[46] Batch [430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086227,	
2017-07-29 01:42:05,984 Epoch[46] Batch [440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086313,	
2017-07-29 01:42:10,874 Epoch[46] Batch [450]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086510,	
2017-07-29 01:42:16,098 Epoch[46] Batch [460]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086358,	
2017-07-29 01:42:21,137 Epoch[46] Batch [470]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.086359,	
2017-07-29 01:42:26,456 Epoch[46] Batch [480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086375,	
2017-07-29 01:42:31,706 Epoch[46] Batch [490]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086304,	
2017-07-29 01:42:36,763 Epoch[46] Batch [500]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086303,	
2017-07-29 01:42:41,939 Epoch[46] Batch [510]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086431,	
2017-07-29 01:42:46,990 Epoch[46] Batch [520]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.086422,	
2017-07-29 01:42:51,871 Epoch[46] Batch [530]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086625,	
2017-07-29 01:42:56,939 Epoch[46] Batch [540]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086538,	
2017-07-29 01:43:01,972 Epoch[46] Batch [550]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086416,	
2017-07-29 01:43:07,036 Epoch[46] Batch [560]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086498,	
2017-07-29 01:43:12,140 Epoch[46] Batch [570]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086530,	
2017-07-29 01:43:17,394 Epoch[46] Batch [580]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086578,	
2017-07-29 01:43:22,413 Epoch[46] Batch [590]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086480,	
2017-07-29 01:43:27,396 Epoch[46] Batch [600]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086462,	
2017-07-29 01:43:32,396 Epoch[46] Batch [610]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.086603,	
2017-07-29 01:43:37,296 Epoch[46] Batch [620]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086596,	
2017-07-29 01:43:42,358 Epoch[46] Batch [630]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086593,	
2017-07-29 01:43:47,247 Epoch[46] Batch [640]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086662,	
2017-07-29 01:43:52,165 Epoch[46] Batch [650]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.086712,	
2017-07-29 01:43:57,116 Epoch[46] Batch [660]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.086728,	
2017-07-29 01:44:02,197 Epoch[46] Batch [670]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086704,	
2017-07-29 01:44:07,253 Epoch[46] Batch [680]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086657,	
2017-07-29 01:44:12,295 Epoch[46] Batch [690]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086650,	
2017-07-29 01:44:17,892 Epoch[46] Batch [700]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.086626,	
2017-07-29 01:44:23,823 Epoch[46] Batch [710]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.086573,	
2017-07-29 01:44:29,757 Epoch[46] Batch [720]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.086457,	
2017-07-29 01:44:35,210 Epoch[46] Batch [730]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.086466,	
2017-07-29 01:44:40,997 Epoch[46] Batch [740]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.086441,	
2017-07-29 01:44:46,284 Epoch[46] Batch [750]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086436,	
2017-07-29 01:44:51,965 Epoch[46] Batch [760]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086510,	
2017-07-29 01:44:57,618 Epoch[46] Batch [770]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086530,	
2017-07-29 01:45:03,229 Epoch[46] Batch [780]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.086488,	
2017-07-29 01:45:09,147 Epoch[46] Batch [790]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086503,	
2017-07-29 01:45:15,267 Epoch[46] Batch [800]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086485,	
2017-07-29 01:45:21,098 Epoch[46] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.086445,	
2017-07-29 01:45:27,015 Epoch[46] Batch [820]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086433,	
2017-07-29 01:45:32,477 Epoch[46] Batch [830]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.086399,	
2017-07-29 01:45:37,927 Epoch[46] Batch [840]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.086412,	
2017-07-29 01:45:44,001 Epoch[46] Batch [850]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.086382,	
2017-07-29 01:45:49,928 Epoch[46] Batch [860]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.086321,	
2017-07-29 01:45:55,441 Epoch[46] Batch [870]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086381,	
2017-07-29 01:46:00,159 Epoch[46] Batch [880]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.086555,	
2017-07-29 01:46:05,660 Epoch[46] Batch [890]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.086477,	
2017-07-29 01:46:10,883 Epoch[46] Batch [900]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086474,	
2017-07-29 01:46:15,960 Epoch[46] Batch [910]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086518,	
2017-07-29 01:46:21,209 Epoch[46] Batch [920]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086477,	
2017-07-29 01:46:27,228 Epoch[46] Batch [930]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.086445,	
2017-07-29 01:46:32,883 Epoch[46] Batch [940]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.086453,	
2017-07-29 01:46:38,418 Epoch[46] Batch [950]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.086479,	
2017-07-29 01:46:44,112 Epoch[46] Batch [960]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086500,	
2017-07-29 01:46:49,842 Epoch[46] Batch [970]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086555,	
2017-07-29 01:46:55,408 Epoch[46] Batch [980]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.086472,	
2017-07-29 01:47:01,296 Epoch[46] Batch [990]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.086380,	
2017-07-29 01:47:07,050 Epoch[46] Batch [1000]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086394,	
2017-07-29 01:47:13,350 Epoch[46] Batch [1010]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.086302,	
2017-07-29 01:47:19,675 Epoch[46] Batch [1020]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086302,	
2017-07-29 01:47:26,861 Epoch[46] Batch [1030]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086244,	
2017-07-29 01:47:34,019 Epoch[46] Batch [1040]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086278,	
2017-07-29 01:47:39,773 Epoch[46] Batch [1050]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086324,	
2017-07-29 01:47:47,021 Epoch[46] Batch [1060]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086353,	
2017-07-29 01:47:53,406 Epoch[46] Batch [1070]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.086292,	
2017-07-29 01:48:00,750 Epoch[46] Batch [1080]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.086443,	
2017-07-29 01:48:07,731 Epoch[46] Batch [1090]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086450,	
2017-07-29 01:48:14,852 Epoch[46] Batch [1100]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.086400,	
2017-07-29 01:48:21,175 Epoch[46] Batch [1110]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.086504,	
2017-07-29 01:48:27,814 Epoch[46] Batch [1120]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.086561,	
2017-07-29 01:48:33,517 Epoch[46] Batch [1130]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-29 01:48:39,029 Epoch[46] Batch [1140]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086515,	
2017-07-29 01:48:44,780 Epoch[46] Batch [1150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086444,	
2017-07-29 01:48:50,403 Epoch[46] Batch [1160]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-29 01:48:57,579 Epoch[46] Batch [1170]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086439,	
2017-07-29 01:49:03,389 Epoch[46] Batch [1180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086478,	
2017-07-29 01:49:09,338 Epoch[46] Batch [1190]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.086537,	
2017-07-29 01:49:15,199 Epoch[46] Batch [1200]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086508,	
2017-07-29 01:49:21,779 Epoch[46] Batch [1210]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.086590,	
2017-07-29 01:49:28,203 Epoch[46] Batch [1220]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086518,	
2017-07-29 01:49:34,833 Epoch[46] Batch [1230]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.086631,	
2017-07-29 01:49:41,499 Epoch[46] Batch [1240]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086613,	
2017-07-29 01:49:48,074 Epoch[46] Batch [1250]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.086648,	
2017-07-29 01:49:54,826 Epoch[46] Batch [1260]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086623,	
2017-07-29 01:50:01,505 Epoch[46] Batch [1270]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086584,	
2017-07-29 01:50:08,427 Epoch[46] Batch [1280]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.086569,	
2017-07-29 01:50:15,422 Epoch[46] Batch [1290]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086556,	
2017-07-29 01:50:22,102 Epoch[46] Batch [1300]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086617,	
2017-07-29 01:50:29,003 Epoch[46] Batch [1310]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086599,	
2017-07-29 01:50:35,653 Epoch[46] Batch [1320]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.086670,	
2017-07-29 01:50:42,390 Epoch[46] Batch [1330]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.086634,	
2017-07-29 01:50:49,339 Epoch[46] Batch [1340]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.086611,	
2017-07-29 01:50:55,789 Epoch[46] Batch [1350]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.086571,	
2017-07-29 01:51:02,774 Epoch[46] Batch [1360]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086510,	
2017-07-29 01:51:09,961 Epoch[46] Batch [1370]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086456,	
2017-07-29 01:51:17,213 Epoch[46] Batch [1380]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086444,	
2017-07-29 01:51:24,349 Epoch[46] Batch [1390]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086480,	
2017-07-29 01:51:31,682 Epoch[46] Batch [1400]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.086541,	
2017-07-29 01:51:38,923 Epoch[46] Batch [1410]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086536,	
2017-07-29 01:51:46,130 Epoch[46] Batch [1420]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086621,	
2017-07-29 01:51:54,025 Epoch[46] Batch [1430]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.086618,	
2017-07-29 01:52:01,940 Epoch[46] Batch [1440]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086621,	
2017-07-29 01:52:09,115 Epoch[46] Batch [1450]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086662,	
2017-07-29 01:52:16,190 Epoch[46] Batch [1460]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086653,	
2017-07-29 01:52:23,237 Epoch[46] Batch [1470]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086684,	
2017-07-29 01:52:30,207 Epoch[46] Batch [1480]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.086735,	
2017-07-29 01:52:34,733 Epoch[46] Train-FCNLogLoss=0.086747
2017-07-29 01:52:34,733 Epoch[46] Time cost=848.765
2017-07-29 01:52:35,516 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.params"
2017-07-29 01:52:39,013 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.states"
2017-07-29 01:52:47,874 Epoch[47] Batch [10]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.086196,	
2017-07-29 01:52:54,975 Epoch[47] Batch [20]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.084352,	
2017-07-29 01:53:02,096 Epoch[47] Batch [30]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.084424,	
2017-07-29 01:53:09,522 Epoch[47] Batch [40]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.085969,	
2017-07-29 01:53:16,768 Epoch[47] Batch [50]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-29 01:53:23,996 Epoch[47] Batch [60]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086089,	
2017-07-29 01:53:31,387 Epoch[47] Batch [70]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.086887,	
2017-07-29 01:53:38,653 Epoch[47] Batch [80]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.086105,	
2017-07-29 01:53:45,816 Epoch[47] Batch [90]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.085592,	
2017-07-29 01:53:53,075 Epoch[47] Batch [100]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.085088,	
2017-07-29 01:54:00,380 Epoch[47] Batch [110]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.085045,	
2017-07-29 01:54:07,551 Epoch[47] Batch [120]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.084685,	
2017-07-29 01:54:14,704 Epoch[47] Batch [130]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.084662,	
2017-07-29 01:54:22,057 Epoch[47] Batch [140]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.085249,	
2017-07-29 01:54:29,299 Epoch[47] Batch [150]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.084967,	
2017-07-29 01:54:36,565 Epoch[47] Batch [160]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.084850,	
2017-07-29 01:54:43,745 Epoch[47] Batch [170]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.085201,	
2017-07-29 01:54:51,078 Epoch[47] Batch [180]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.084981,	
2017-07-29 01:54:58,383 Epoch[47] Batch [190]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.084792,	
2017-07-29 01:55:05,526 Epoch[47] Batch [200]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.085298,	
2017-07-29 01:55:12,829 Epoch[47] Batch [210]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.085560,	
2017-07-29 01:55:19,950 Epoch[47] Batch [220]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.085804,	
2017-07-29 01:55:27,666 Epoch[47] Batch [230]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.085873,	
2017-07-29 01:55:35,392 Epoch[47] Batch [240]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.085502,	
2017-07-29 01:55:43,137 Epoch[47] Batch [250]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.085757,	
2017-07-29 01:55:50,453 Epoch[47] Batch [260]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.086104,	
2017-07-29 01:55:57,091 Epoch[47] Batch [270]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.085939,	
2017-07-29 01:56:03,866 Epoch[47] Batch [280]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086151,	
2017-07-29 01:56:10,051 Epoch[47] Batch [290]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085937,	
2017-07-29 01:56:16,494 Epoch[47] Batch [300]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086134,	
2017-07-29 01:56:23,256 Epoch[47] Batch [310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.085952,	
2017-07-29 01:56:29,652 Epoch[47] Batch [320]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.086189,	
2017-07-29 01:56:36,380 Epoch[47] Batch [330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086037,	
2017-07-29 01:56:42,759 Epoch[47] Batch [340]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.086027,	
2017-07-29 01:56:49,930 Epoch[47] Batch [350]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086279,	
2017-07-29 01:56:56,927 Epoch[47] Batch [360]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086511,	
2017-07-29 01:57:03,807 Epoch[47] Batch [370]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.086615,	
2017-07-29 01:57:10,770 Epoch[47] Batch [380]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086705,	
2017-07-29 01:57:17,921 Epoch[47] Batch [390]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086998,	
2017-07-29 01:57:24,879 Epoch[47] Batch [400]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087247,	
2017-07-29 01:57:32,300 Epoch[47] Batch [410]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.087221,	
2017-07-29 01:57:39,860 Epoch[47] Batch [420]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.087215,	
2017-07-29 01:57:47,659 Epoch[47] Batch [430]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087157,	
2017-07-29 01:57:55,489 Epoch[47] Batch [440]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.087161,	
2017-07-29 01:58:03,663 Epoch[47] Batch [450]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.087199,	
2017-07-29 01:58:10,760 Epoch[47] Batch [460]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087162,	
2017-07-29 01:58:17,808 Epoch[47] Batch [470]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087056,	
2017-07-29 01:58:24,923 Epoch[47] Batch [480]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087199,	
2017-07-29 01:58:31,846 Epoch[47] Batch [490]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087343,	
2017-07-29 01:58:39,176 Epoch[47] Batch [500]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087507,	
2017-07-29 01:58:46,338 Epoch[47] Batch [510]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087507,	
2017-07-29 01:58:53,919 Epoch[47] Batch [520]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.087415,	
2017-07-29 01:59:01,892 Epoch[47] Batch [530]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.087436,	
2017-07-29 01:59:09,781 Epoch[47] Batch [540]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087480,	
2017-07-29 01:59:17,780 Epoch[47] Batch [550]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087490,	
2017-07-29 01:59:25,407 Epoch[47] Batch [560]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.087513,	
2017-07-29 01:59:33,092 Epoch[47] Batch [570]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087420,	
2017-07-29 01:59:40,604 Epoch[47] Batch [580]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.087357,	
2017-07-29 01:59:48,376 Epoch[47] Batch [590]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.087387,	
2017-07-29 01:59:56,071 Epoch[47] Batch [600]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087492,	
2017-07-29 02:00:03,534 Epoch[47] Batch [610]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.087563,	
2017-07-29 02:00:11,056 Epoch[47] Batch [620]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.087453,	
2017-07-29 02:00:18,591 Epoch[47] Batch [630]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087518,	
2017-07-29 02:00:26,153 Epoch[47] Batch [640]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.087539,	
2017-07-29 02:00:32,795 Epoch[47] Batch [650]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087601,	
2017-07-29 02:00:40,800 Epoch[47] Batch [660]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087753,	
2017-07-29 02:00:48,966 Epoch[47] Batch [670]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.087692,	
2017-07-29 02:00:56,138 Epoch[47] Batch [680]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.087672,	
2017-07-29 02:01:03,343 Epoch[47] Batch [690]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.087583,	
2017-07-29 02:01:11,233 Epoch[47] Batch [700]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087450,	
2017-07-29 02:01:19,120 Epoch[47] Batch [710]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087448,	
2017-07-29 02:01:26,595 Epoch[47] Batch [720]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087473,	
2017-07-29 02:01:34,297 Epoch[47] Batch [730]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.087632,	
2017-07-29 02:01:41,923 Epoch[47] Batch [740]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087587,	
2017-07-29 02:01:49,520 Epoch[47] Batch [750]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.087629,	
2017-07-29 02:01:57,196 Epoch[47] Batch [760]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087600,	
2017-07-29 02:02:04,657 Epoch[47] Batch [770]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.087607,	
2017-07-29 02:02:11,940 Epoch[47] Batch [780]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.087495,	
2017-07-29 02:02:19,093 Epoch[47] Batch [790]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087455,	
2017-07-29 02:02:25,857 Epoch[47] Batch [800]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.087375,	
2017-07-29 02:02:32,306 Epoch[47] Batch [810]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.087437,	
2017-07-29 02:02:39,380 Epoch[47] Batch [820]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087493,	
2017-07-29 02:02:47,157 Epoch[47] Batch [830]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.087642,	
2017-07-29 02:02:54,936 Epoch[47] Batch [840]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.087619,	
2017-07-29 02:03:02,560 Epoch[47] Batch [850]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087509,	
2017-07-29 02:03:10,191 Epoch[47] Batch [860]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.087558,	
2017-07-29 02:03:17,908 Epoch[47] Batch [870]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087534,	
2017-07-29 02:03:25,577 Epoch[47] Batch [880]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087390,	
2017-07-29 02:03:33,335 Epoch[47] Batch [890]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087480,	
2017-07-29 02:03:41,321 Epoch[47] Batch [900]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.087378,	
2017-07-29 02:03:49,341 Epoch[47] Batch [910]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087402,	
2017-07-29 02:03:56,611 Epoch[47] Batch [920]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.087246,	
2017-07-29 02:04:03,431 Epoch[47] Batch [930]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087295,	
2017-07-29 02:04:09,850 Epoch[47] Batch [940]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087223,	
2017-07-29 02:04:16,854 Epoch[47] Batch [950]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.087233,	
2017-07-29 02:04:23,439 Epoch[47] Batch [960]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.087205,	
2017-07-29 02:04:30,824 Epoch[47] Batch [970]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.087223,	
2017-07-29 02:04:37,554 Epoch[47] Batch [980]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087285,	
2017-07-29 02:04:44,209 Epoch[47] Batch [990]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087244,	
2017-07-29 02:04:51,080 Epoch[47] Batch [1000]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.087215,	
2017-07-29 02:04:57,683 Epoch[47] Batch [1010]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087269,	
2017-07-29 02:05:04,072 Epoch[47] Batch [1020]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.087208,	
2017-07-29 02:05:10,546 Epoch[47] Batch [1030]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.087180,	
2017-07-29 02:05:16,994 Epoch[47] Batch [1040]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.087185,	
2017-07-29 02:05:23,835 Epoch[47] Batch [1050]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.087154,	
2017-07-29 02:05:30,179 Epoch[47] Batch [1060]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087153,	
2017-07-29 02:05:37,393 Epoch[47] Batch [1070]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087091,	
2017-07-29 02:05:44,528 Epoch[47] Batch [1080]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087129,	
2017-07-29 02:05:51,670 Epoch[47] Batch [1090]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087127,	
2017-07-29 02:05:58,289 Epoch[47] Batch [1100]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087116,	
2017-07-29 02:06:04,717 Epoch[47] Batch [1110]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087068,	
2017-07-29 02:06:11,458 Epoch[47] Batch [1120]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087018,	
2017-07-29 02:06:18,487 Epoch[47] Batch [1130]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086965,	
2017-07-29 02:06:25,156 Epoch[47] Batch [1140]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086882,	
2017-07-29 02:06:31,195 Epoch[47] Batch [1150]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086974,	
2017-07-29 02:06:37,546 Epoch[47] Batch [1160]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086949,	
2017-07-29 02:06:44,356 Epoch[47] Batch [1170]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.086971,	
2017-07-29 02:06:50,546 Epoch[47] Batch [1180]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.086892,	
2017-07-29 02:06:56,872 Epoch[47] Batch [1190]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086855,	
2017-07-29 02:07:03,107 Epoch[47] Batch [1200]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.086860,	
2017-07-29 02:07:09,242 Epoch[47] Batch [1210]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086916,	
2017-07-29 02:07:15,284 Epoch[47] Batch [1220]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086952,	
2017-07-29 02:07:21,345 Epoch[47] Batch [1230]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.086978,	
2017-07-29 02:07:27,320 Epoch[47] Batch [1240]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086938,	
2017-07-29 02:07:33,420 Epoch[47] Batch [1250]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086972,	
2017-07-29 02:07:39,546 Epoch[47] Batch [1260]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.086899,	
2017-07-29 02:07:45,969 Epoch[47] Batch [1270]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086818,	
2017-07-29 02:07:52,722 Epoch[47] Batch [1280]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086793,	
2017-07-29 02:07:58,820 Epoch[47] Batch [1290]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086760,	
2017-07-29 02:08:05,278 Epoch[47] Batch [1300]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.086716,	
2017-07-29 02:08:11,740 Epoch[47] Batch [1310]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.086729,	
2017-07-29 02:08:17,904 Epoch[47] Batch [1320]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.086670,	
2017-07-29 02:08:24,024 Epoch[47] Batch [1330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086644,	
2017-07-29 02:08:30,379 Epoch[47] Batch [1340]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.086700,	
2017-07-29 02:08:36,574 Epoch[47] Batch [1350]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.086615,	
2017-07-29 02:08:43,323 Epoch[47] Batch [1360]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.086648,	
2017-07-29 02:08:49,943 Epoch[47] Batch [1370]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 02:08:56,333 Epoch[47] Batch [1380]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.086619,	
2017-07-29 02:09:02,533 Epoch[47] Batch [1390]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086608,	
2017-07-29 02:09:08,643 Epoch[47] Batch [1400]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.086579,	
2017-07-29 02:09:14,994 Epoch[47] Batch [1410]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086526,	
2017-07-29 02:09:21,726 Epoch[47] Batch [1420]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.086552,	
2017-07-29 02:09:28,157 Epoch[47] Batch [1430]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.086530,	
2017-07-29 02:09:34,638 Epoch[47] Batch [1440]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086472,	
2017-07-29 02:09:41,190 Epoch[47] Batch [1450]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.086450,	
2017-07-29 02:09:47,726 Epoch[47] Batch [1460]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.086500,	
2017-07-29 02:09:54,009 Epoch[47] Batch [1470]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.086420,	
2017-07-29 02:10:00,428 Epoch[47] Batch [1480]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086435,	
2017-07-29 02:10:04,253 Epoch[47] Train-FCNLogLoss=0.086513
2017-07-29 02:10:04,253 Epoch[47] Time cost=1045.239
2017-07-29 02:10:05,449 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.params"
2017-07-29 02:10:08,900 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.states"
2017-07-29 02:10:16,283 Epoch[48] Batch [10]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.083447,	
2017-07-29 02:10:23,103 Epoch[48] Batch [20]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087295,	
2017-07-29 02:10:29,629 Epoch[48] Batch [30]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.090124,	
2017-07-29 02:10:36,479 Epoch[48] Batch [40]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086631,	
2017-07-29 02:10:43,028 Epoch[48] Batch [50]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087438,	
2017-07-29 02:10:50,006 Epoch[48] Batch [60]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086351,	
2017-07-29 02:10:56,802 Epoch[48] Batch [70]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.084998,	
2017-07-29 02:11:03,429 Epoch[48] Batch [80]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.084849,	
2017-07-29 02:11:10,082 Epoch[48] Batch [90]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.084381,	
2017-07-29 02:11:16,694 Epoch[48] Batch [100]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.085055,	
2017-07-29 02:11:23,780 Epoch[48] Batch [110]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.085105,	
2017-07-29 02:11:30,756 Epoch[48] Batch [120]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.085535,	
2017-07-29 02:11:37,861 Epoch[48] Batch [130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.085656,	
2017-07-29 02:11:45,174 Epoch[48] Batch [140]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.085517,	
2017-07-29 02:11:52,351 Epoch[48] Batch [150]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.085382,	
2017-07-29 02:11:59,637 Epoch[48] Batch [160]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.085376,	
2017-07-29 02:12:07,105 Epoch[48] Batch [170]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.085806,	
2017-07-29 02:12:13,965 Epoch[48] Batch [180]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086167,	
2017-07-29 02:12:21,612 Epoch[48] Batch [190]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.086301,	
2017-07-29 02:12:29,004 Epoch[48] Batch [200]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.085608,	
2017-07-29 02:12:36,461 Epoch[48] Batch [210]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.085476,	
2017-07-29 02:12:44,593 Epoch[48] Batch [220]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.085441,	
2017-07-29 02:12:51,690 Epoch[48] Batch [230]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.085229,	
2017-07-29 02:12:59,581 Epoch[48] Batch [240]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.085408,	
2017-07-29 02:13:06,597 Epoch[48] Batch [250]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.085366,	
2017-07-29 02:13:14,537 Epoch[48] Batch [260]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.085329,	
2017-07-29 02:13:22,606 Epoch[48] Batch [270]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.085624,	
2017-07-29 02:13:30,415 Epoch[48] Batch [280]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.085716,	
2017-07-29 02:13:38,319 Epoch[48] Batch [290]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.085662,	
2017-07-29 02:13:46,148 Epoch[48] Batch [300]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.085681,	
2017-07-29 02:13:54,063 Epoch[48] Batch [310]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.085856,	
2017-07-29 02:14:01,999 Epoch[48] Batch [320]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.085714,	
2017-07-29 02:14:09,951 Epoch[48] Batch [330]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.085702,	
2017-07-29 02:14:18,182 Epoch[48] Batch [340]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.085789,	
2017-07-29 02:14:25,782 Epoch[48] Batch [350]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.085732,	
2017-07-29 02:14:33,877 Epoch[48] Batch [360]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.085945,	
2017-07-29 02:14:42,195 Epoch[48] Batch [370]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.085983,	
2017-07-29 02:14:50,451 Epoch[48] Batch [380]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.085927,	
2017-07-29 02:14:58,444 Epoch[48] Batch [390]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.086103,	
2017-07-29 02:15:05,608 Epoch[48] Batch [400]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.085947,	
2017-07-29 02:15:13,175 Epoch[48] Batch [410]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.086027,	
2017-07-29 02:15:20,426 Epoch[48] Batch [420]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.085901,	
2017-07-29 02:15:27,714 Epoch[48] Batch [430]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.085864,	
2017-07-29 02:15:35,112 Epoch[48] Batch [440]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.085863,	
2017-07-29 02:15:42,069 Epoch[48] Batch [450]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.085979,	
2017-07-29 02:15:49,322 Epoch[48] Batch [460]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086183,	
2017-07-29 02:15:56,773 Epoch[48] Batch [470]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086194,	
2017-07-29 02:16:04,760 Epoch[48] Batch [480]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.086348,	
2017-07-29 02:16:12,470 Epoch[48] Batch [490]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.086546,	
2017-07-29 02:16:20,411 Epoch[48] Batch [500]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.086469,	
2017-07-29 02:16:47,398 Epoch[48] Batch [510]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.086553,	
2017-07-29 02:17:22,673 Epoch[48] Batch [520]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.086639,	
2017-07-29 02:17:32,962 Epoch[48] Batch [530]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.086584,	
2017-07-29 02:17:40,761 Epoch[48] Batch [540]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.086563,	
2017-07-29 02:17:48,299 Epoch[48] Batch [550]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086513,	
2017-07-29 02:17:56,147 Epoch[48] Batch [560]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086659,	
2017-07-29 02:18:03,825 Epoch[48] Batch [570]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.086784,	
2017-07-29 02:18:11,551 Epoch[48] Batch [580]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.086890,	
2017-07-29 02:18:19,453 Epoch[48] Batch [590]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.086770,	
2017-07-29 02:18:26,824 Epoch[48] Batch [600]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.086804,	
2017-07-29 02:18:34,782 Epoch[48] Batch [610]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.086663,	
2017-07-29 02:18:42,544 Epoch[48] Batch [620]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.086644,	
2017-07-29 02:18:50,355 Epoch[48] Batch [630]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.086738,	
2017-07-29 02:18:58,145 Epoch[48] Batch [640]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.086842,	
2017-07-29 02:19:05,868 Epoch[48] Batch [650]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.086869,	
2017-07-29 02:19:13,597 Epoch[48] Batch [660]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.086868,	
2017-07-29 02:19:21,466 Epoch[48] Batch [670]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.086954,	
2017-07-29 02:19:29,288 Epoch[48] Batch [680]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.086997,	
2017-07-29 02:19:36,768 Epoch[48] Batch [690]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.087040,	
2017-07-29 02:19:44,367 Epoch[48] Batch [700]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.087067,	
2017-07-29 02:19:52,116 Epoch[48] Batch [710]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.087183,	
2017-07-29 02:19:59,995 Epoch[48] Batch [720]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.087223,	
2017-07-29 02:20:07,795 Epoch[48] Batch [730]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087105,	
2017-07-29 02:20:15,654 Epoch[48] Batch [740]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087001,	
2017-07-29 02:20:23,363 Epoch[48] Batch [750]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.087077,	
2017-07-29 02:20:31,188 Epoch[48] Batch [760]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.087149,	
2017-07-29 02:20:39,229 Epoch[48] Batch [770]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.087174,	
2017-07-29 02:20:47,161 Epoch[48] Batch [780]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.087110,	
2017-07-29 02:20:54,842 Epoch[48] Batch [790]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087098,	
2017-07-29 02:21:02,606 Epoch[48] Batch [800]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.087230,	
2017-07-29 02:21:10,472 Epoch[48] Batch [810]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087233,	
2017-07-29 02:21:18,314 Epoch[48] Batch [820]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.087128,	
2017-07-29 02:21:26,224 Epoch[48] Batch [830]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087092,	
2017-07-29 02:21:34,124 Epoch[48] Batch [840]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.086998,	
2017-07-29 02:21:41,931 Epoch[48] Batch [850]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.087002,	
2017-07-29 02:21:49,770 Epoch[48] Batch [860]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086946,	
2017-07-29 02:21:57,764 Epoch[48] Batch [870]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.086887,	
2017-07-29 02:22:05,682 Epoch[48] Batch [880]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086851,	
2017-07-29 02:22:14,857 Epoch[48] Batch [890]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.086872,	
2017-07-29 02:22:48,912 Epoch[48] Batch [900]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.086944,	
2017-07-29 02:23:19,165 Epoch[48] Batch [910]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.086864,	
2017-07-29 02:23:50,495 Epoch[48] Batch [920]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.086837,	
2017-07-29 02:24:23,116 Epoch[48] Batch [930]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.086820,	
2017-07-29 02:24:54,961 Epoch[48] Batch [940]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.086878,	
2017-07-29 02:25:28,899 Epoch[48] Batch [950]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.086901,	
2017-07-29 02:26:01,590 Epoch[48] Batch [960]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086932,	
2017-07-29 02:26:32,154 Epoch[48] Batch [970]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.086898,	
2017-07-29 02:27:04,403 Epoch[48] Batch [980]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.086905,	
2017-07-29 02:27:39,637 Epoch[48] Batch [990]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.086833,	
2017-07-29 02:28:11,219 Epoch[48] Batch [1000]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.086840,	
2017-07-29 02:28:42,167 Epoch[48] Batch [1010]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.086884,	
2017-07-29 02:29:14,672 Epoch[48] Batch [1020]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.086882,	
2017-07-29 02:29:45,974 Epoch[48] Batch [1030]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.086848,	
2017-07-29 02:30:16,404 Epoch[48] Batch [1040]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.086792,	
2017-07-29 02:30:45,541 Epoch[48] Batch [1050]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.086736,	
2017-07-29 02:31:12,543 Epoch[48] Batch [1060]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.086678,	
2017-07-29 02:31:44,865 Epoch[48] Batch [1070]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.086719,	
2017-07-29 02:32:17,330 Epoch[48] Batch [1080]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.086741,	
2017-07-29 02:32:50,667 Epoch[48] Batch [1090]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.086767,	
2017-07-29 02:33:20,952 Epoch[48] Batch [1100]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.086719,	
2017-07-29 02:33:55,120 Epoch[48] Batch [1110]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.086645,	
2017-07-29 02:34:29,972 Epoch[48] Batch [1120]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.086664,	
2017-07-29 02:35:03,200 Epoch[48] Batch [1130]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.086548,	
2017-07-29 02:35:37,280 Epoch[48] Batch [1140]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.086542,	
2017-07-29 02:36:11,491 Epoch[48] Batch [1150]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.086498,	
2017-07-29 02:36:47,846 Epoch[48] Batch [1160]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-29 02:37:21,813 Epoch[48] Batch [1170]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.086476,	
2017-07-29 02:37:57,176 Epoch[48] Batch [1180]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.086534,	
2017-07-29 02:38:29,441 Epoch[48] Batch [1190]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.086606,	
2017-07-29 02:39:02,179 Epoch[48] Batch [1200]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086628,	
2017-07-29 02:39:35,770 Epoch[48] Batch [1210]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.086599,	
2017-07-29 02:40:06,636 Epoch[48] Batch [1220]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.086564,	
2017-07-29 02:40:38,756 Epoch[48] Batch [1230]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.086591,	
2017-07-29 02:41:13,741 Epoch[48] Batch [1240]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.086528,	
2017-07-29 02:41:45,697 Epoch[48] Batch [1250]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.086540,	
2017-07-29 02:42:19,795 Epoch[48] Batch [1260]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.086545,	
2017-07-29 02:42:55,028 Epoch[48] Batch [1270]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.086543,	
2017-07-29 02:43:24,542 Epoch[48] Batch [1280]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.086534,	
2017-07-29 02:44:00,976 Epoch[48] Batch [1290]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.086458,	
2017-07-29 02:44:31,390 Epoch[48] Batch [1300]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.086430,	
2017-07-29 02:45:02,464 Epoch[48] Batch [1310]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.086435,	
2017-07-29 02:45:38,407 Epoch[48] Batch [1320]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.086397,	
2017-07-29 02:46:13,721 Epoch[48] Batch [1330]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.086357,	
2017-07-29 02:46:48,764 Epoch[48] Batch [1340]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.086375,	
2017-07-29 02:47:19,427 Epoch[48] Batch [1350]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.086361,	
2017-07-29 02:47:52,991 Epoch[48] Batch [1360]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.086335,	
2017-07-29 02:48:26,992 Epoch[48] Batch [1370]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.086345,	
2017-07-29 02:48:59,661 Epoch[48] Batch [1380]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086387,	
2017-07-29 02:49:31,260 Epoch[48] Batch [1390]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.086423,	
2017-07-29 02:50:04,696 Epoch[48] Batch [1400]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.086415,	
2017-07-29 02:50:38,938 Epoch[48] Batch [1410]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.086414,	
2017-07-29 02:51:12,662 Epoch[48] Batch [1420]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.086365,	
2017-07-29 02:51:45,427 Epoch[48] Batch [1430]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086414,	
2017-07-29 02:52:14,774 Epoch[48] Batch [1440]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.086403,	
2017-07-29 02:52:50,732 Epoch[48] Batch [1450]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.086343,	
2017-07-29 02:53:27,533 Epoch[48] Batch [1460]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.086388,	
2017-07-29 02:54:03,201 Epoch[48] Batch [1470]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.086312,	
2017-07-29 02:54:38,205 Epoch[48] Batch [1480]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-29 02:54:58,943 Epoch[48] Train-FCNLogLoss=0.086321
2017-07-29 02:54:58,943 Epoch[48] Time cost=2690.043
2017-07-29 02:55:04,933 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.params"
2017-07-29 02:55:25,017 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.states"
2017-07-29 02:56:02,421 Epoch[49] Batch [10]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.083970,	
2017-07-29 02:56:29,523 Epoch[49] Batch [20]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.085693,	
2017-07-29 02:57:04,842 Epoch[49] Batch [30]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.088158,	
2017-07-29 02:57:40,470 Epoch[49] Batch [40]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.089403,	
2017-07-29 02:58:17,270 Epoch[49] Batch [50]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.089192,	
2017-07-29 02:58:54,066 Epoch[49] Batch [60]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.090796,	
2017-07-29 02:59:27,100 Epoch[49] Batch [70]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.089844,	
2017-07-29 02:59:55,388 Epoch[49] Batch [80]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.088808,	
2017-07-29 03:00:29,626 Epoch[49] Batch [90]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.088816,	
2017-07-29 03:00:59,478 Epoch[49] Batch [100]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.088503,	
2017-07-29 03:01:36,541 Epoch[49] Batch [110]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.088934,	
2017-07-29 03:02:13,560 Epoch[49] Batch [120]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.087787,	
2017-07-29 03:02:51,809 Epoch[49] Batch [130]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.087524,	
2017-07-29 03:03:26,323 Epoch[49] Batch [140]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.087519,	
2017-07-29 03:03:59,014 Epoch[49] Batch [150]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.087397,	
2017-07-29 03:04:30,934 Epoch[49] Batch [160]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.087052,	
2017-07-29 03:05:03,590 Epoch[49] Batch [170]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086794,	
2017-07-29 03:05:37,997 Epoch[49] Batch [180]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.086354,	
2017-07-29 03:06:14,368 Epoch[49] Batch [190]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.086138,	
2017-07-29 03:06:52,216 Epoch[49] Batch [200]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.085974,	
2017-07-29 03:07:27,524 Epoch[49] Batch [210]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.085932,	
2017-07-29 03:08:02,221 Epoch[49] Batch [220]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.085722,	
2017-07-29 03:08:32,380 Epoch[49] Batch [230]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.085556,	
2017-07-29 03:09:05,042 Epoch[49] Batch [240]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086087,	
2017-07-29 03:09:43,350 Epoch[49] Batch [250]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.086109,	
2017-07-29 03:10:15,593 Epoch[49] Batch [260]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.086020,	
2017-07-29 03:10:52,669 Epoch[49] Batch [270]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.085998,	
2017-07-29 03:11:26,550 Epoch[49] Batch [280]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.085925,	
2017-07-29 03:12:06,505 Epoch[49] Batch [290]	Speed: 1.00 samples/sec	Train-FCNLogLoss=0.086347,	
2017-07-29 03:12:38,885 Epoch[49] Batch [300]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.086162,	
2017-07-29 03:13:13,241 Epoch[49] Batch [310]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.086468,	
2017-07-29 03:13:41,918 Epoch[49] Batch [320]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.086324,	
2017-07-29 03:14:14,940 Epoch[49] Batch [330]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.086173,	
2017-07-29 03:14:52,125 Epoch[49] Batch [340]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.086172,	
2017-07-29 03:15:28,330 Epoch[49] Batch [350]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.086052,	
2017-07-29 03:16:06,524 Epoch[49] Batch [360]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.086361,	
2017-07-29 03:16:38,609 Epoch[49] Batch [370]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.086362,	
2017-07-29 03:17:11,292 Epoch[49] Batch [380]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086301,	
2017-07-29 03:17:49,216 Epoch[49] Batch [390]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.086039,	
2017-07-29 03:18:24,089 Epoch[49] Batch [400]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.086054,	
2017-07-29 03:18:58,676 Epoch[49] Batch [410]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.085911,	
2017-07-29 03:19:33,016 Epoch[49] Batch [420]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.085973,	
2017-07-29 03:20:10,687 Epoch[49] Batch [430]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.085947,	
2017-07-29 03:20:44,095 Epoch[49] Batch [440]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.085992,	
2017-07-29 03:21:17,680 Epoch[49] Batch [450]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.085941,	
2017-07-29 03:21:50,101 Epoch[49] Batch [460]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.085888,	
2017-07-29 03:22:22,873 Epoch[49] Batch [470]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.085989,	
2017-07-29 03:22:58,821 Epoch[49] Batch [480]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.085861,	
2017-07-29 03:23:33,314 Epoch[49] Batch [490]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.085973,	
2017-07-29 03:24:07,196 Epoch[49] Batch [500]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.086091,	
2017-07-29 03:24:45,543 Epoch[49] Batch [510]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.086024,	
2017-07-29 03:25:18,330 Epoch[49] Batch [520]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086104,	
2017-07-29 03:25:53,628 Epoch[49] Batch [530]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.085995,	
2017-07-29 03:26:26,547 Epoch[49] Batch [540]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.086071,	
2017-07-29 03:26:46,411 Epoch[49] Batch [550]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.086220,	
2017-07-29 03:26:52,280 Epoch[49] Batch [560]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086259,	
2017-07-29 03:26:58,247 Epoch[49] Batch [570]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086070,	
2017-07-29 03:27:03,987 Epoch[49] Batch [580]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.086074,	
2017-07-29 03:27:09,803 Epoch[49] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086151,	
2017-07-29 03:27:15,644 Epoch[49] Batch [600]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086161,	
2017-07-29 03:27:21,421 Epoch[49] Batch [610]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086289,	
2017-07-29 03:27:27,299 Epoch[49] Batch [620]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086260,	
2017-07-29 03:27:33,004 Epoch[49] Batch [630]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086385,	
2017-07-29 03:27:38,828 Epoch[49] Batch [640]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086396,	
2017-07-29 03:27:44,582 Epoch[49] Batch [650]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086408,	
2017-07-29 03:27:50,388 Epoch[49] Batch [660]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086287,	
2017-07-29 03:27:56,181 Epoch[49] Batch [670]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.086329,	
2017-07-29 03:28:02,001 Epoch[49] Batch [680]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086298,	
2017-07-29 03:28:07,821 Epoch[49] Batch [690]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086398,	
2017-07-29 03:28:13,633 Epoch[49] Batch [700]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086433,	
2017-07-29 03:28:19,433 Epoch[49] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086505,	
2017-07-29 03:28:25,269 Epoch[49] Batch [720]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086537,	
2017-07-29 03:28:31,001 Epoch[49] Batch [730]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086514,	
2017-07-29 03:28:36,800 Epoch[49] Batch [740]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086422,	
2017-07-29 03:28:42,637 Epoch[49] Batch [750]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086412,	
2017-07-29 03:28:48,411 Epoch[49] Batch [760]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086315,	
2017-07-29 03:28:54,250 Epoch[49] Batch [770]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086326,	
2017-07-29 03:29:00,044 Epoch[49] Batch [780]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086306,	
2017-07-29 03:29:05,807 Epoch[49] Batch [790]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086158,	
2017-07-29 03:29:11,631 Epoch[49] Batch [800]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086159,	
2017-07-29 03:29:17,434 Epoch[49] Batch [810]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086181,	
2017-07-29 03:29:23,233 Epoch[49] Batch [820]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086222,	
2017-07-29 03:29:29,079 Epoch[49] Batch [830]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086263,	
2017-07-29 03:29:34,825 Epoch[49] Batch [840]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086183,	
2017-07-29 03:29:40,641 Epoch[49] Batch [850]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086199,	
2017-07-29 03:29:46,411 Epoch[49] Batch [860]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086237,	
2017-07-29 03:29:52,241 Epoch[49] Batch [870]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.086322,	
2017-07-29 03:29:58,018 Epoch[49] Batch [880]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086190,	
2017-07-29 03:30:03,826 Epoch[49] Batch [890]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086294,	
2017-07-29 03:30:09,615 Epoch[49] Batch [900]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.086455,	
2017-07-29 03:30:15,427 Epoch[49] Batch [910]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086517,	
2017-07-29 03:30:21,873 Epoch[49] Batch [920]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086581,	
2017-07-29 03:30:28,325 Epoch[49] Batch [930]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.086510,	
2017-07-29 03:30:34,637 Epoch[49] Batch [940]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086582,	
2017-07-29 03:30:41,036 Epoch[49] Batch [950]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.086636,	
2017-07-29 03:30:47,895 Epoch[49] Batch [960]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086616,	
2017-07-29 03:30:54,935 Epoch[49] Batch [970]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086571,	
2017-07-29 03:31:01,723 Epoch[49] Batch [980]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.086519,	
2017-07-29 03:31:07,430 Epoch[49] Batch [990]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086526,	
2017-07-29 03:31:13,345 Epoch[49] Batch [1000]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086582,	
2017-07-29 03:31:19,526 Epoch[49] Batch [1010]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.086619,	
2017-07-29 03:31:25,791 Epoch[49] Batch [1020]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.086629,	
2017-07-29 03:31:31,935 Epoch[49] Batch [1030]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086563,	
2017-07-29 03:31:38,016 Epoch[49] Batch [1040]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.086559,	
2017-07-29 03:31:44,545 Epoch[49] Batch [1050]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.086608,	
2017-07-29 03:31:50,951 Epoch[49] Batch [1060]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.086652,	
2017-07-29 03:31:57,954 Epoch[49] Batch [1070]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086610,	
2017-07-29 03:32:03,730 Epoch[49] Batch [1080]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086624,	
2017-07-29 03:32:10,398 Epoch[49] Batch [1090]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086666,	
2017-07-29 03:32:16,834 Epoch[49] Batch [1100]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.086672,	
2017-07-29 03:32:23,492 Epoch[49] Batch [1110]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086688,	
2017-07-29 03:32:29,847 Epoch[49] Batch [1120]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.086709,	
2017-07-29 03:32:36,273 Epoch[49] Batch [1130]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086745,	
2017-07-29 03:32:43,367 Epoch[49] Batch [1140]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086750,	
2017-07-29 03:32:50,214 Epoch[49] Batch [1150]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086769,	
2017-07-29 03:32:56,750 Epoch[49] Batch [1160]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.086754,	
2017-07-29 03:33:03,791 Epoch[49] Batch [1170]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086742,	
2017-07-29 03:33:10,713 Epoch[49] Batch [1180]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.086675,	
2017-07-29 03:33:17,976 Epoch[49] Batch [1190]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.086659,	
2017-07-29 03:33:24,927 Epoch[49] Batch [1200]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086599,	
2017-07-29 03:33:32,071 Epoch[49] Batch [1210]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086642,	
2017-07-29 03:33:37,944 Epoch[49] Batch [1220]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086635,	
2017-07-29 03:33:43,813 Epoch[49] Batch [1230]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086627,	
2017-07-29 03:33:50,522 Epoch[49] Batch [1240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.086559,	
2017-07-29 03:33:57,293 Epoch[49] Batch [1250]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.086595,	
2017-07-29 03:34:03,100 Epoch[49] Batch [1260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086541,	
2017-07-29 03:34:09,223 Epoch[49] Batch [1270]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.086535,	
2017-07-29 03:34:15,032 Epoch[49] Batch [1280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086524,	
2017-07-29 03:34:21,346 Epoch[49] Batch [1290]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086601,	
2017-07-29 03:34:27,837 Epoch[49] Batch [1300]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.086571,	
2017-07-29 03:34:33,691 Epoch[49] Batch [1310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086564,	
2017-07-29 03:34:39,429 Epoch[49] Batch [1320]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.086558,	
2017-07-29 03:34:45,941 Epoch[49] Batch [1330]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.086563,	
2017-07-29 03:34:52,146 Epoch[49] Batch [1340]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.086586,	
2017-07-29 03:34:58,584 Epoch[49] Batch [1350]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086584,	
2017-07-29 03:35:05,050 Epoch[49] Batch [1360]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.086560,	
2017-07-29 03:35:11,704 Epoch[49] Batch [1370]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086571,	
2017-07-29 03:35:18,068 Epoch[49] Batch [1380]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.086551,	
2017-07-29 03:35:24,869 Epoch[49] Batch [1390]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086494,	
2017-07-29 03:35:31,200 Epoch[49] Batch [1400]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086513,	
2017-07-29 03:35:37,132 Epoch[49] Batch [1410]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.086463,	
2017-07-29 03:35:43,271 Epoch[49] Batch [1420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086457,	
2017-07-29 03:35:49,688 Epoch[49] Batch [1430]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086440,	
2017-07-29 03:35:56,696 Epoch[49] Batch [1440]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086416,	
2017-07-29 03:36:03,333 Epoch[49] Batch [1450]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.086351,	
2017-07-29 03:36:10,284 Epoch[49] Batch [1460]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086351,	
2017-07-29 03:36:17,320 Epoch[49] Batch [1470]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086277,	
2017-07-29 03:36:24,181 Epoch[49] Batch [1480]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086293,	
2017-07-29 03:36:28,307 Epoch[49] Train-FCNLogLoss=0.086241
2017-07-29 03:36:28,307 Epoch[49] Time cost=2463.290
2017-07-29 03:36:29,316 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.params"
2017-07-29 03:36:32,980 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.states"
2017-07-29 03:36:40,553 Epoch[50] Batch [10]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.092738,	
2017-07-29 03:36:46,895 Epoch[50] Batch [20]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.089697,	
2017-07-29 03:36:53,351 Epoch[50] Batch [30]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.089507,	
2017-07-29 03:36:59,602 Epoch[50] Batch [40]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.087703,	
2017-07-29 03:37:05,916 Epoch[50] Batch [50]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.085225,	
2017-07-29 03:37:11,676 Epoch[50] Batch [60]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.085305,	
2017-07-29 03:37:17,789 Epoch[50] Batch [70]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.085617,	
2017-07-29 03:37:23,607 Epoch[50] Batch [80]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.085400,	
2017-07-29 03:37:29,499 Epoch[50] Batch [90]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085666,	
2017-07-29 03:37:35,900 Epoch[50] Batch [100]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.085282,	
2017-07-29 03:37:41,957 Epoch[50] Batch [110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.084988,	
2017-07-29 03:37:47,739 Epoch[50] Batch [120]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085219,	
2017-07-29 03:37:53,513 Epoch[50] Batch [130]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.084770,	
2017-07-29 03:37:59,321 Epoch[50] Batch [140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.085565,	
2017-07-29 03:38:06,023 Epoch[50] Batch [150]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.085458,	
2017-07-29 03:38:13,601 Epoch[50] Batch [160]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.084910,	
2017-07-29 03:38:20,392 Epoch[50] Batch [170]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.085547,	
2017-07-29 03:38:26,824 Epoch[50] Batch [180]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.085724,	
2017-07-29 03:38:33,646 Epoch[50] Batch [190]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.085264,	
2017-07-29 03:38:39,995 Epoch[50] Batch [200]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086072,	
2017-07-29 03:38:46,733 Epoch[50] Batch [210]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.086161,	
2017-07-29 03:38:53,300 Epoch[50] Batch [220]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.086458,	
2017-07-29 03:39:00,214 Epoch[50] Batch [230]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086529,	
2017-07-29 03:39:07,017 Epoch[50] Batch [240]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086466,	
2017-07-29 03:39:14,505 Epoch[50] Batch [250]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.086545,	
2017-07-29 03:39:21,639 Epoch[50] Batch [260]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086394,	
2017-07-29 03:39:28,987 Epoch[50] Batch [270]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.086075,	
2017-07-29 03:39:35,459 Epoch[50] Batch [280]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.085864,	
2017-07-29 03:39:42,224 Epoch[50] Batch [290]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.085662,	
2017-07-29 03:39:49,425 Epoch[50] Batch [300]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.085932,	
2017-07-29 03:39:56,784 Epoch[50] Batch [310]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.085880,	
2017-07-29 03:40:03,981 Epoch[50] Batch [320]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086086,	
2017-07-29 03:40:10,029 Epoch[50] Batch [330]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085830,	
2017-07-29 03:40:16,808 Epoch[50] Batch [340]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.085777,	
2017-07-29 03:40:23,164 Epoch[50] Batch [350]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.085907,	
2017-07-29 03:40:30,076 Epoch[50] Batch [360]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086016,	
2017-07-29 03:40:36,902 Epoch[50] Batch [370]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.086140,	
2017-07-29 03:40:43,854 Epoch[50] Batch [380]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086172,	
2017-07-29 03:40:50,957 Epoch[50] Batch [390]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086152,	
2017-07-29 03:40:57,990 Epoch[50] Batch [400]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086396,	
2017-07-29 03:41:04,447 Epoch[50] Batch [410]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.086598,	
2017-07-29 03:41:10,592 Epoch[50] Batch [420]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086712,	
2017-07-29 03:41:17,722 Epoch[50] Batch [430]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087000,	
2017-07-29 03:41:25,175 Epoch[50] Batch [440]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086941,	
2017-07-29 03:41:32,626 Epoch[50] Batch [450]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086915,	
2017-07-29 03:41:39,618 Epoch[50] Batch [460]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086784,	
2017-07-29 03:41:45,684 Epoch[50] Batch [470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.086717,	
2017-07-29 03:41:53,261 Epoch[50] Batch [480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.086612,	
2017-07-29 03:42:00,857 Epoch[50] Batch [490]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.086442,	
2017-07-29 03:42:08,030 Epoch[50] Batch [500]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086406,	
2017-07-29 03:42:15,025 Epoch[50] Batch [510]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086393,	
2017-07-29 03:42:22,156 Epoch[50] Batch [520]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086400,	
2017-07-29 03:42:29,206 Epoch[50] Batch [530]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086196,	
2017-07-29 03:42:35,987 Epoch[50] Batch [540]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086205,	
2017-07-29 03:42:43,124 Epoch[50] Batch [550]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086284,	
2017-07-29 03:42:50,830 Epoch[50] Batch [560]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.086353,	
2017-07-29 03:42:57,882 Epoch[50] Batch [570]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-29 03:43:05,234 Epoch[50] Batch [580]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.086443,	
2017-07-29 03:43:12,076 Epoch[50] Batch [590]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.086467,	
2017-07-29 03:43:19,218 Epoch[50] Batch [600]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086480,	
2017-07-29 03:43:25,569 Epoch[50] Batch [610]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086419,	
2017-07-29 03:43:31,813 Epoch[50] Batch [620]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.086401,	
2017-07-29 03:43:38,335 Epoch[50] Batch [630]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.086311,	
2017-07-29 03:43:44,991 Epoch[50] Batch [640]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086298,	
2017-07-29 03:43:52,037 Epoch[50] Batch [650]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086099,	
2017-07-29 03:43:59,420 Epoch[50] Batch [660]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.086167,	
2017-07-29 03:44:06,356 Epoch[50] Batch [670]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.086204,	
2017-07-29 03:44:13,089 Epoch[50] Batch [680]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.086297,	
2017-07-29 03:44:19,748 Epoch[50] Batch [690]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086280,	
2017-07-29 03:44:26,961 Epoch[50] Batch [700]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086326,	
2017-07-29 03:44:34,038 Epoch[50] Batch [710]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086369,	
2017-07-29 03:44:42,055 Epoch[50] Batch [720]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.086392,	
2017-07-29 03:44:48,901 Epoch[50] Batch [730]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086485,	
2017-07-29 03:44:55,992 Epoch[50] Batch [740]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086484,	
2017-07-29 03:45:03,291 Epoch[50] Batch [750]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086417,	
2017-07-29 03:45:10,559 Epoch[50] Batch [760]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.086358,	
2017-07-29 03:45:16,843 Epoch[50] Batch [770]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.086534,	
2017-07-29 03:45:23,012 Epoch[50] Batch [780]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.086448,	
2017-07-29 03:45:30,483 Epoch[50] Batch [790]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086475,	
2017-07-29 03:45:37,618 Epoch[50] Batch [800]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086501,	
2017-07-29 03:45:44,936 Epoch[50] Batch [810]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.086560,	
2017-07-29 03:45:52,182 Epoch[50] Batch [820]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-29 03:45:58,280 Epoch[50] Batch [830]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086553,	
2017-07-29 03:46:05,579 Epoch[50] Batch [840]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086480,	
2017-07-29 03:46:13,056 Epoch[50] Batch [850]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086557,	
2017-07-29 03:46:19,689 Epoch[50] Batch [860]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.086587,	
2017-07-29 03:46:26,582 Epoch[50] Batch [870]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 03:46:33,657 Epoch[50] Batch [880]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086630,	
2017-07-29 03:46:41,512 Epoch[50] Batch [890]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.086664,	
2017-07-29 03:46:49,453 Epoch[50] Batch [900]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.086644,	
2017-07-29 03:46:56,705 Epoch[50] Batch [910]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086543,	
2017-07-29 03:47:04,631 Epoch[50] Batch [920]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086497,	
2017-07-29 03:47:11,701 Epoch[50] Batch [930]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.086455,	
2017-07-29 03:47:18,612 Epoch[50] Batch [940]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086509,	
2017-07-29 03:47:25,868 Epoch[50] Batch [950]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.086403,	
2017-07-29 03:47:33,909 Epoch[50] Batch [960]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.086372,	
2017-07-29 03:47:41,639 Epoch[50] Batch [970]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.086307,	
2017-07-29 03:47:49,366 Epoch[50] Batch [980]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.086360,	
2017-07-29 03:47:57,143 Epoch[50] Batch [990]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.086336,	
2017-07-29 03:48:04,365 Epoch[50] Batch [1000]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086313,	
2017-07-29 03:48:11,465 Epoch[50] Batch [1010]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086284,	
2017-07-29 03:48:19,552 Epoch[50] Batch [1020]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.086343,	
2017-07-29 03:48:26,253 Epoch[50] Batch [1030]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086342,	
2017-07-29 03:48:34,365 Epoch[50] Batch [1040]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.086387,	
2017-07-29 03:48:42,126 Epoch[50] Batch [1050]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.086423,	
2017-07-29 03:48:49,754 Epoch[50] Batch [1060]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.086371,	
2017-07-29 03:48:56,562 Epoch[50] Batch [1070]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086416,	
2017-07-29 03:49:03,576 Epoch[50] Batch [1080]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086391,	
2017-07-29 03:49:10,758 Epoch[50] Batch [1090]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086335,	
2017-07-29 03:49:17,940 Epoch[50] Batch [1100]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086330,	
2017-07-29 03:49:25,286 Epoch[50] Batch [1110]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.086322,	
2017-07-29 03:49:32,167 Epoch[50] Batch [1120]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.086316,	
2017-07-29 03:49:39,218 Epoch[50] Batch [1130]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086396,	
2017-07-29 03:49:46,480 Epoch[50] Batch [1140]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.086388,	
2017-07-29 03:49:53,380 Epoch[50] Batch [1150]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086414,	
2017-07-29 03:50:00,092 Epoch[50] Batch [1160]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.086388,	
2017-07-29 03:50:06,294 Epoch[50] Batch [1170]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086335,	
2017-07-29 03:50:13,688 Epoch[50] Batch [1180]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.086343,	
2017-07-29 03:50:20,185 Epoch[50] Batch [1190]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.086334,	
2017-07-29 03:50:27,295 Epoch[50] Batch [1200]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086316,	
2017-07-29 03:50:33,716 Epoch[50] Batch [1210]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086246,	
2017-07-29 03:50:40,440 Epoch[50] Batch [1220]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086231,	
2017-07-29 03:50:48,065 Epoch[50] Batch [1230]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.086124,	
2017-07-29 03:50:55,552 Epoch[50] Batch [1240]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.086168,	
2017-07-29 03:51:03,102 Epoch[50] Batch [1250]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.086152,	
2017-07-29 03:51:10,391 Epoch[50] Batch [1260]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086156,	
2017-07-29 03:51:17,390 Epoch[50] Batch [1270]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086142,	
2017-07-29 03:51:24,855 Epoch[50] Batch [1280]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086071,	
2017-07-29 03:51:32,139 Epoch[50] Batch [1290]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086057,	
2017-07-29 03:51:39,426 Epoch[50] Batch [1300]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086080,	
2017-07-29 03:51:46,869 Epoch[50] Batch [1310]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086049,	
2017-07-29 03:51:54,299 Epoch[50] Batch [1320]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.086094,	
2017-07-29 03:52:01,751 Epoch[50] Batch [1330]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086172,	
2017-07-29 03:52:08,583 Epoch[50] Batch [1340]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.086267,	
2017-07-29 03:52:14,355 Epoch[50] Batch [1350]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086293,	
2017-07-29 03:52:21,390 Epoch[50] Batch [1360]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086307,	
2017-07-29 03:52:28,632 Epoch[50] Batch [1370]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086301,	
2017-07-29 03:52:36,047 Epoch[50] Batch [1380]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.086204,	
2017-07-29 03:52:43,127 Epoch[50] Batch [1390]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086224,	
2017-07-29 03:52:50,270 Epoch[50] Batch [1400]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086249,	
2017-07-29 03:52:57,656 Epoch[50] Batch [1410]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.086272,	
2017-07-29 03:53:04,697 Epoch[50] Batch [1420]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086195,	
2017-07-29 03:53:12,147 Epoch[50] Batch [1430]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086194,	
2017-07-29 03:53:19,248 Epoch[50] Batch [1440]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086181,	
2017-07-29 03:53:26,500 Epoch[50] Batch [1450]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.086172,	
2017-07-29 03:53:33,954 Epoch[50] Batch [1460]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086159,	
2017-07-29 03:53:41,629 Epoch[50] Batch [1470]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.086212,	
2017-07-29 03:53:48,733 Epoch[50] Batch [1480]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086231,	
2017-07-29 03:53:53,097 Epoch[50] Train-FCNLogLoss=0.086246
2017-07-29 03:53:53,097 Epoch[50] Time cost=1040.116
2017-07-29 03:53:54,070 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.params"
2017-07-29 03:53:57,513 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.states"
2017-07-29 03:54:06,273 Epoch[51] Batch [10]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087417,	
2017-07-29 03:54:13,665 Epoch[51] Batch [20]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.083741,	
2017-07-29 03:54:21,467 Epoch[51] Batch [30]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.086050,	
2017-07-29 03:54:28,330 Epoch[51] Batch [40]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086786,	
2017-07-29 03:54:35,703 Epoch[51] Batch [50]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.086407,	
2017-07-29 03:54:43,181 Epoch[51] Batch [60]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086945,	
2017-07-29 03:54:50,550 Epoch[51] Batch [70]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.087054,	
2017-07-29 03:54:57,585 Epoch[51] Batch [80]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088024,	
2017-07-29 03:55:04,820 Epoch[51] Batch [90]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087911,	
2017-07-29 03:55:11,665 Epoch[51] Batch [100]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.087896,	
2017-07-29 03:55:18,322 Epoch[51] Batch [110]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088051,	
2017-07-29 03:55:26,044 Epoch[51] Batch [120]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.088174,	
2017-07-29 03:55:33,141 Epoch[51] Batch [130]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088077,	
2017-07-29 03:55:39,958 Epoch[51] Batch [140]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.088488,	
2017-07-29 03:55:47,257 Epoch[51] Batch [150]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.087660,	
2017-07-29 03:55:54,386 Epoch[51] Batch [160]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087356,	
2017-07-29 03:56:01,562 Epoch[51] Batch [170]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086856,	
2017-07-29 03:56:08,924 Epoch[51] Batch [180]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.087058,	
2017-07-29 03:56:15,988 Epoch[51] Batch [190]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.086944,	
2017-07-29 03:56:23,204 Epoch[51] Batch [200]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087033,	
2017-07-29 03:56:30,595 Epoch[51] Batch [210]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.087143,	
2017-07-29 03:56:37,270 Epoch[51] Batch [220]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086731,	
2017-07-29 03:56:44,618 Epoch[51] Batch [230]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.086805,	
2017-07-29 03:56:52,160 Epoch[51] Batch [240]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.086662,	
2017-07-29 03:56:59,499 Epoch[51] Batch [250]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.087150,	
2017-07-29 03:57:06,225 Epoch[51] Batch [260]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086827,	
2017-07-29 03:57:13,339 Epoch[51] Batch [270]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.086803,	
2017-07-29 03:57:20,154 Epoch[51] Batch [280]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.086555,	
2017-07-29 03:57:27,490 Epoch[51] Batch [290]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.086845,	
2017-07-29 03:57:34,543 Epoch[51] Batch [300]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086881,	
2017-07-29 03:57:41,794 Epoch[51] Batch [310]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087042,	
2017-07-29 03:57:48,710 Epoch[51] Batch [320]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.086968,	
2017-07-29 03:57:55,613 Epoch[51] Batch [330]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086800,	
2017-07-29 03:58:02,658 Epoch[51] Batch [340]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086606,	
2017-07-29 03:58:09,802 Epoch[51] Batch [350]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086610,	
2017-07-29 03:58:17,092 Epoch[51] Batch [360]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086904,	
2017-07-29 03:58:24,183 Epoch[51] Batch [370]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086844,	
2017-07-29 03:58:30,268 Epoch[51] Batch [380]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.086859,	
2017-07-29 03:58:37,714 Epoch[51] Batch [390]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.086876,	
2017-07-29 03:58:44,907 Epoch[51] Batch [400]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086866,	
2017-07-29 03:58:51,549 Epoch[51] Batch [410]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.086708,	
2017-07-29 03:58:59,046 Epoch[51] Batch [420]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.086698,	
2017-07-29 03:59:06,054 Epoch[51] Batch [430]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086572,	
2017-07-29 03:59:13,072 Epoch[51] Batch [440]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086538,	
2017-07-29 03:59:18,930 Epoch[51] Batch [450]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086674,	
2017-07-29 03:59:26,026 Epoch[51] Batch [460]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.086607,	
2017-07-29 03:59:32,832 Epoch[51] Batch [470]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086474,	
2017-07-29 03:59:39,878 Epoch[51] Batch [480]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086625,	
2017-07-29 03:59:46,709 Epoch[51] Batch [490]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.086647,	
2017-07-29 03:59:53,762 Epoch[51] Batch [500]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086733,	
2017-07-29 04:00:00,134 Epoch[51] Batch [510]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086616,	
2017-07-29 04:00:05,952 Epoch[51] Batch [520]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086405,	
2017-07-29 04:00:11,829 Epoch[51] Batch [530]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086452,	
2017-07-29 04:00:17,880 Epoch[51] Batch [540]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.086404,	
2017-07-29 04:00:24,248 Epoch[51] Batch [550]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086488,	
2017-07-29 04:00:30,819 Epoch[51] Batch [560]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.086537,	
2017-07-29 04:00:37,899 Epoch[51] Batch [570]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086538,	
2017-07-29 04:00:43,868 Epoch[51] Batch [580]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086725,	
2017-07-29 04:00:50,999 Epoch[51] Batch [590]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086814,	
2017-07-29 04:00:58,283 Epoch[51] Batch [600]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086853,	
2017-07-29 04:01:05,443 Epoch[51] Batch [610]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086860,	
2017-07-29 04:01:12,218 Epoch[51] Batch [620]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086890,	
2017-07-29 04:01:19,328 Epoch[51] Batch [630]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086924,	
2017-07-29 04:01:25,618 Epoch[51] Batch [640]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.086925,	
2017-07-29 04:01:32,375 Epoch[51] Batch [650]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.087018,	
2017-07-29 04:01:39,518 Epoch[51] Batch [660]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.087073,	
2017-07-29 04:01:46,137 Epoch[51] Batch [670]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087123,	
2017-07-29 04:01:52,796 Epoch[51] Batch [680]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087055,	
2017-07-29 04:01:59,787 Epoch[51] Batch [690]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086983,	
2017-07-29 04:02:06,293 Epoch[51] Batch [700]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.086999,	
2017-07-29 04:02:13,202 Epoch[51] Batch [710]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086903,	
2017-07-29 04:02:19,875 Epoch[51] Batch [720]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086820,	
2017-07-29 04:02:27,285 Epoch[51] Batch [730]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.086940,	
2017-07-29 04:02:34,513 Epoch[51] Batch [740]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086863,	
2017-07-29 04:02:41,323 Epoch[51] Batch [750]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.086880,	
2017-07-29 04:02:48,343 Epoch[51] Batch [760]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086889,	
2017-07-29 04:02:55,118 Epoch[51] Batch [770]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086912,	
2017-07-29 04:03:01,791 Epoch[51] Batch [780]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086794,	
2017-07-29 04:03:08,033 Epoch[51] Batch [790]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.086673,	
2017-07-29 04:03:14,331 Epoch[51] Batch [800]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.086614,	
2017-07-29 04:03:20,251 Epoch[51] Batch [810]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086702,	
2017-07-29 04:03:26,997 Epoch[51] Batch [820]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.086700,	
2017-07-29 04:03:33,466 Epoch[51] Batch [830]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.086627,	
2017-07-29 04:03:39,636 Epoch[51] Batch [840]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.086572,	
2017-07-29 04:03:46,302 Epoch[51] Batch [850]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086558,	
2017-07-29 04:03:53,091 Epoch[51] Batch [860]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.086613,	
2017-07-29 04:04:00,017 Epoch[51] Batch [870]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.086604,	
2017-07-29 04:04:07,004 Epoch[51] Batch [880]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086557,	
2017-07-29 04:04:13,140 Epoch[51] Batch [890]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086526,	
2017-07-29 04:04:19,715 Epoch[51] Batch [900]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.086530,	
2017-07-29 04:04:26,717 Epoch[51] Batch [910]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086515,	
2017-07-29 04:04:33,373 Epoch[51] Batch [920]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086593,	
2017-07-29 04:04:39,966 Epoch[51] Batch [930]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.086606,	
2017-07-29 04:04:46,280 Epoch[51] Batch [940]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086626,	
2017-07-29 04:04:52,491 Epoch[51] Batch [950]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.086600,	
2017-07-29 04:04:59,505 Epoch[51] Batch [960]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086625,	
2017-07-29 04:05:05,998 Epoch[51] Batch [970]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.086694,	
2017-07-29 04:05:13,012 Epoch[51] Batch [980]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086851,	
2017-07-29 04:05:19,388 Epoch[51] Batch [990]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.086844,	
2017-07-29 04:05:26,374 Epoch[51] Batch [1000]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086932,	
2017-07-29 04:05:33,684 Epoch[51] Batch [1010]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.086961,	
2017-07-29 04:05:40,550 Epoch[51] Batch [1020]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086958,	
2017-07-29 04:05:47,202 Epoch[51] Batch [1030]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086877,	
2017-07-29 04:05:53,760 Epoch[51] Batch [1040]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.086811,	
2017-07-29 04:06:00,819 Epoch[51] Batch [1050]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086752,	
2017-07-29 04:06:07,901 Epoch[51] Batch [1060]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086732,	
2017-07-29 04:06:15,006 Epoch[51] Batch [1070]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086755,	
2017-07-29 04:06:21,422 Epoch[51] Batch [1080]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086747,	
2017-07-29 04:06:27,737 Epoch[51] Batch [1090]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.086701,	
2017-07-29 04:06:33,715 Epoch[51] Batch [1100]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 04:06:40,121 Epoch[51] Batch [1110]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.086554,	
2017-07-29 04:06:47,111 Epoch[51] Batch [1120]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086529,	
2017-07-29 04:06:54,061 Epoch[51] Batch [1130]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.086526,	
2017-07-29 04:07:00,758 Epoch[51] Batch [1140]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086520,	
2017-07-29 04:07:07,911 Epoch[51] Batch [1150]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086499,	
2017-07-29 04:07:14,876 Epoch[51] Batch [1160]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.086578,	
2017-07-29 04:07:21,446 Epoch[51] Batch [1170]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.086625,	
2017-07-29 04:07:27,443 Epoch[51] Batch [1180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.086637,	
2017-07-29 04:07:33,809 Epoch[51] Batch [1190]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086634,	
2017-07-29 04:07:40,441 Epoch[51] Batch [1200]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.086552,	
2017-07-29 04:07:47,705 Epoch[51] Batch [1210]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.086547,	
2017-07-29 04:07:54,601 Epoch[51] Batch [1220]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086507,	
2017-07-29 04:08:01,371 Epoch[51] Batch [1230]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.086465,	
2017-07-29 04:08:08,836 Epoch[51] Batch [1240]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086405,	
2017-07-29 04:08:16,021 Epoch[51] Batch [1250]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086449,	
2017-07-29 04:08:23,193 Epoch[51] Batch [1260]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086465,	
2017-07-29 04:08:30,002 Epoch[51] Batch [1270]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086471,	
2017-07-29 04:08:36,689 Epoch[51] Batch [1280]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.086411,	
2017-07-29 04:08:42,524 Epoch[51] Batch [1290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086450,	
2017-07-29 04:08:48,556 Epoch[51] Batch [1300]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086442,	
2017-07-29 04:08:54,688 Epoch[51] Batch [1310]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086419,	
2017-07-29 04:09:00,961 Epoch[51] Batch [1320]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.086400,	
2017-07-29 04:09:08,062 Epoch[51] Batch [1330]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086399,	
2017-07-29 04:09:14,802 Epoch[51] Batch [1340]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.086454,	
2017-07-29 04:09:21,852 Epoch[51] Batch [1350]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086470,	
2017-07-29 04:09:28,660 Epoch[51] Batch [1360]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086426,	
2017-07-29 04:09:35,652 Epoch[51] Batch [1370]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086444,	
2017-07-29 04:09:42,470 Epoch[51] Batch [1380]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.086445,	
2017-07-29 04:09:49,594 Epoch[51] Batch [1390]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086448,	
2017-07-29 04:09:56,303 Epoch[51] Batch [1400]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.086416,	
2017-07-29 04:10:03,351 Epoch[51] Batch [1410]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086402,	
2017-07-29 04:10:10,151 Epoch[51] Batch [1420]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086382,	
2017-07-29 04:10:16,518 Epoch[51] Batch [1430]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086358,	
2017-07-29 04:10:23,411 Epoch[51] Batch [1440]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086302,	
2017-07-29 04:10:29,921 Epoch[51] Batch [1450]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.086340,	
2017-07-29 04:10:36,983 Epoch[51] Batch [1460]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.086381,	
2017-07-29 04:10:43,772 Epoch[51] Batch [1470]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.086369,	
2017-07-29 04:10:50,857 Epoch[51] Batch [1480]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086335,	
2017-07-29 04:10:54,562 Epoch[51] Train-FCNLogLoss=0.086303
2017-07-29 04:10:54,562 Epoch[51] Time cost=1017.049
2017-07-29 04:10:55,551 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.params"
2017-07-29 04:10:59,037 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.states"
2017-07-29 04:11:06,917 Epoch[52] Batch [10]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.083733,	
2017-07-29 04:11:13,556 Epoch[52] Batch [20]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.082366,	
2017-07-29 04:11:20,050 Epoch[52] Batch [30]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.083454,	
2017-07-29 04:11:27,093 Epoch[52] Batch [40]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086118,	
2017-07-29 04:11:33,947 Epoch[52] Batch [50]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086918,	
2017-07-29 04:11:39,709 Epoch[52] Batch [60]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086553,	
2017-07-29 04:11:46,173 Epoch[52] Batch [70]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087050,	
2017-07-29 04:11:53,067 Epoch[52] Batch [80]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087951,	
2017-07-29 04:11:59,528 Epoch[52] Batch [90]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088081,	
2017-07-29 04:12:05,885 Epoch[52] Batch [100]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087949,	
2017-07-29 04:12:12,457 Epoch[52] Batch [110]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.088094,	
2017-07-29 04:12:18,695 Epoch[52] Batch [120]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.088255,	
2017-07-29 04:12:25,933 Epoch[52] Batch [130]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.087359,	
2017-07-29 04:12:33,476 Epoch[52] Batch [140]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.087601,	
2017-07-29 04:12:39,527 Epoch[52] Batch [150]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.088008,	
2017-07-29 04:12:46,612 Epoch[52] Batch [160]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.088108,	
2017-07-29 04:12:53,015 Epoch[52] Batch [170]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087915,	
2017-07-29 04:13:00,470 Epoch[52] Batch [180]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.087760,	
2017-07-29 04:13:07,516 Epoch[52] Batch [190]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087913,	
2017-07-29 04:13:14,332 Epoch[52] Batch [200]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087859,	
2017-07-29 04:13:20,810 Epoch[52] Batch [210]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.087212,	
2017-07-29 04:13:27,909 Epoch[52] Batch [220]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086826,	
2017-07-29 04:13:34,403 Epoch[52] Batch [230]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.086655,	
2017-07-29 04:13:40,985 Epoch[52] Batch [240]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.086526,	
2017-07-29 04:13:47,601 Epoch[52] Batch [250]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.086538,	
2017-07-29 04:13:54,928 Epoch[52] Batch [260]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.086341,	
2017-07-29 04:14:01,691 Epoch[52] Batch [270]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086707,	
2017-07-29 04:14:08,903 Epoch[52] Batch [280]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086354,	
2017-07-29 04:14:16,259 Epoch[52] Batch [290]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.086707,	
2017-07-29 04:14:23,643 Epoch[52] Batch [300]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.086296,	
2017-07-29 04:14:31,394 Epoch[52] Batch [310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.086692,	
2017-07-29 04:14:38,560 Epoch[52] Batch [320]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.086608,	
2017-07-29 04:14:45,278 Epoch[52] Batch [330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086624,	
2017-07-29 04:14:52,231 Epoch[52] Batch [340]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086832,	
2017-07-29 04:14:58,885 Epoch[52] Batch [350]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086964,	
2017-07-29 04:15:05,547 Epoch[52] Batch [360]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086779,	
2017-07-29 04:15:11,392 Epoch[52] Batch [370]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086779,	
2017-07-29 04:15:18,431 Epoch[52] Batch [380]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086830,	
2017-07-29 04:15:25,260 Epoch[52] Batch [390]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.086584,	
2017-07-29 04:15:32,361 Epoch[52] Batch [400]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.086576,	
2017-07-29 04:15:39,082 Epoch[52] Batch [410]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086462,	
2017-07-29 04:15:45,883 Epoch[52] Batch [420]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086533,	
2017-07-29 04:15:52,463 Epoch[52] Batch [430]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.086362,	
2017-07-29 04:15:59,430 Epoch[52] Batch [440]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.086279,	
2017-07-29 04:16:06,132 Epoch[52] Batch [450]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086174,	
2017-07-29 04:16:13,073 Epoch[52] Batch [460]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.086181,	
2017-07-29 04:16:19,818 Epoch[52] Batch [470]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.086087,	
2017-07-29 04:16:26,957 Epoch[52] Batch [480]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086194,	
2017-07-29 04:16:34,191 Epoch[52] Batch [490]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086329,	
2017-07-29 04:16:40,777 Epoch[52] Batch [500]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.086315,	
2017-07-29 04:16:48,497 Epoch[52] Batch [510]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.086342,	
2017-07-29 04:16:55,303 Epoch[52] Batch [520]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086291,	
2017-07-29 04:17:01,670 Epoch[52] Batch [530]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086145,	
2017-07-29 04:17:08,222 Epoch[52] Batch [540]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.086358,	
2017-07-29 04:17:14,834 Epoch[52] Batch [550]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.086396,	
2017-07-29 04:17:21,989 Epoch[52] Batch [560]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.086498,	
2017-07-29 04:17:29,006 Epoch[52] Batch [570]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086492,	
2017-07-29 04:17:35,824 Epoch[52] Batch [580]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.086255,	
2017-07-29 04:17:42,678 Epoch[52] Batch [590]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086423,	
2017-07-29 04:17:49,657 Epoch[52] Batch [600]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086464,	
2017-07-29 04:17:56,720 Epoch[52] Batch [610]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.086660,	
2017-07-29 04:18:03,267 Epoch[52] Batch [620]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.086629,	
2017-07-29 04:18:10,320 Epoch[52] Batch [630]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086691,	
2017-07-29 04:18:17,232 Epoch[52] Batch [640]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086905,	
2017-07-29 04:18:24,236 Epoch[52] Batch [650]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086925,	
2017-07-29 04:18:31,319 Epoch[52] Batch [660]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.086830,	
2017-07-29 04:18:38,367 Epoch[52] Batch [670]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086775,	
2017-07-29 04:18:45,841 Epoch[52] Batch [680]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086949,	
2017-07-29 04:18:53,173 Epoch[52] Batch [690]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.086961,	
2017-07-29 04:19:00,217 Epoch[52] Batch [700]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.086954,	
2017-07-29 04:19:06,885 Epoch[52] Batch [710]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086839,	
2017-07-29 04:19:14,255 Epoch[52] Batch [720]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.086936,	
2017-07-29 04:19:21,449 Epoch[52] Batch [730]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086887,	
2017-07-29 04:19:28,685 Epoch[52] Batch [740]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.086934,	
2017-07-29 04:19:35,390 Epoch[52] Batch [750]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086959,	
2017-07-29 04:19:42,422 Epoch[52] Batch [760]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086900,	
2017-07-29 04:19:48,895 Epoch[52] Batch [770]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.086782,	
2017-07-29 04:19:55,572 Epoch[52] Batch [780]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086672,	
2017-07-29 04:20:02,059 Epoch[52] Batch [790]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086678,	
2017-07-29 04:20:08,866 Epoch[52] Batch [800]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.086648,	
2017-07-29 04:20:14,645 Epoch[52] Batch [810]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086619,	
2017-07-29 04:20:20,392 Epoch[52] Batch [820]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086618,	
2017-07-29 04:20:26,654 Epoch[52] Batch [830]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.086622,	
2017-07-29 04:20:33,061 Epoch[52] Batch [840]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.086698,	
2017-07-29 04:20:40,534 Epoch[52] Batch [850]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086683,	
2017-07-29 04:20:48,244 Epoch[52] Batch [860]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.086753,	
2017-07-29 04:20:56,290 Epoch[52] Batch [870]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.086824,	
2017-07-29 04:21:03,952 Epoch[52] Batch [880]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.086852,	
2017-07-29 04:21:12,125 Epoch[52] Batch [890]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.086744,	
2017-07-29 04:21:19,830 Epoch[52] Batch [900]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.086720,	
2017-07-29 04:21:27,056 Epoch[52] Batch [910]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086702,	
2017-07-29 04:21:34,405 Epoch[52] Batch [920]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.086676,	
2017-07-29 04:21:41,473 Epoch[52] Batch [930]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.086675,	
2017-07-29 04:21:47,913 Epoch[52] Batch [940]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086648,	
2017-07-29 04:21:53,543 Epoch[52] Batch [950]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.086612,	
2017-07-29 04:21:59,257 Epoch[52] Batch [960]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.086567,	
2017-07-29 04:22:05,109 Epoch[52] Batch [970]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086444,	
2017-07-29 04:22:10,836 Epoch[52] Batch [980]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086470,	
2017-07-29 04:22:16,846 Epoch[52] Batch [990]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.086454,	
2017-07-29 04:22:23,449 Epoch[52] Batch [1000]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.086379,	
2017-07-29 04:22:29,783 Epoch[52] Batch [1010]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.086415,	
2017-07-29 04:22:36,131 Epoch[52] Batch [1020]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086379,	
2017-07-29 04:22:41,903 Epoch[52] Batch [1030]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086418,	
2017-07-29 04:22:49,112 Epoch[52] Batch [1040]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086441,	
2017-07-29 04:22:56,080 Epoch[52] Batch [1050]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.086408,	
2017-07-29 04:23:02,953 Epoch[52] Batch [1060]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.086405,	
2017-07-29 04:23:09,964 Epoch[52] Batch [1070]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.086236,	
2017-07-29 04:23:16,495 Epoch[52] Batch [1080]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.086257,	
2017-07-29 04:23:23,614 Epoch[52] Batch [1090]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.086278,	
2017-07-29 04:23:30,822 Epoch[52] Batch [1100]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.086214,	
2017-07-29 04:23:38,111 Epoch[52] Batch [1110]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.086249,	
2017-07-29 04:23:44,992 Epoch[52] Batch [1120]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.086306,	
2017-07-29 04:23:52,020 Epoch[52] Batch [1130]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086280,	
2017-07-29 04:23:58,552 Epoch[52] Batch [1140]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.086282,	
2017-07-29 04:24:04,871 Epoch[52] Batch [1150]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.086319,	
2017-07-29 04:24:11,628 Epoch[52] Batch [1160]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086329,	
2017-07-29 04:24:18,380 Epoch[52] Batch [1170]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086330,	
2017-07-29 04:24:25,415 Epoch[52] Batch [1180]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086377,	
2017-07-29 04:24:32,373 Epoch[52] Batch [1190]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086336,	
2017-07-29 04:24:39,324 Epoch[52] Batch [1200]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.086341,	
2017-07-29 04:24:46,342 Epoch[52] Batch [1210]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086262,	
2017-07-29 04:24:53,115 Epoch[52] Batch [1220]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.086318,	
2017-07-29 04:25:00,244 Epoch[52] Batch [1230]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086312,	
2017-07-29 04:25:07,437 Epoch[52] Batch [1240]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086281,	
2017-07-29 04:25:14,579 Epoch[52] Batch [1250]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.086284,	
2017-07-29 04:25:21,552 Epoch[52] Batch [1260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.086248,	
2017-07-29 04:25:28,496 Epoch[52] Batch [1270]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.086259,	
2017-07-29 04:25:35,720 Epoch[52] Batch [1280]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086270,	
2017-07-29 04:25:42,919 Epoch[52] Batch [1290]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-29 04:25:48,957 Epoch[52] Batch [1300]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086276,	
2017-07-29 04:25:54,641 Epoch[52] Batch [1310]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086296,	
2017-07-29 04:26:00,304 Epoch[52] Batch [1320]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086239,	
2017-07-29 04:26:06,005 Epoch[52] Batch [1330]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086230,	
2017-07-29 04:26:11,716 Epoch[52] Batch [1340]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.086216,	
2017-07-29 04:26:17,342 Epoch[52] Batch [1350]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.086202,	
2017-07-29 04:26:23,056 Epoch[52] Batch [1360]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.086235,	
2017-07-29 04:26:28,879 Epoch[52] Batch [1370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086194,	
2017-07-29 04:26:34,614 Epoch[52] Batch [1380]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086154,	
2017-07-29 04:26:40,671 Epoch[52] Batch [1390]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.086204,	
2017-07-29 04:26:46,329 Epoch[52] Batch [1400]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.086224,	
2017-07-29 04:26:52,021 Epoch[52] Batch [1410]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086201,	
2017-07-29 04:26:57,710 Epoch[52] Batch [1420]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086206,	
2017-07-29 04:27:03,383 Epoch[52] Batch [1430]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086243,	
2017-07-29 04:27:09,376 Epoch[52] Batch [1440]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.086237,	
2017-07-29 04:27:15,652 Epoch[52] Batch [1450]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.086219,	
2017-07-29 04:27:23,169 Epoch[52] Batch [1460]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.086192,	
2017-07-29 04:27:30,186 Epoch[52] Batch [1470]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.086182,	
2017-07-29 04:27:36,497 Epoch[52] Batch [1480]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086202,	
2017-07-29 04:27:40,223 Epoch[52] Train-FCNLogLoss=0.086211
2017-07-29 04:27:40,223 Epoch[52] Time cost=1001.186
2017-07-29 04:27:41,242 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.params"
2017-07-29 04:27:44,798 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.states"
2017-07-29 04:27:44,831 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-29 04:27:59,191 testing 4/500 data 1.3565s net 0.4473s post 0.0078s
2017-07-29 04:28:00,608 testing 8/500 data 1.1925s net 0.4114s post 0.0103s
2017-07-29 04:28:01,877 testing 12/500 data 1.1021s net 0.3880s post 0.0090s
2017-07-29 04:28:03,189 testing 16/500 data 1.0661s net 0.3765s post 0.0097s
2017-07-29 04:28:04,460 testing 20/500 data 1.0364s net 0.3706s post 0.0090s
2017-07-29 04:28:05,791 testing 24/500 data 1.0295s net 0.3638s post 0.0086s
2017-07-29 04:28:07,066 testing 28/500 data 1.0197s net 0.3558s post 0.0082s
2017-07-29 04:28:08,390 testing 32/500 data 1.0141s net 0.3543s post 0.0079s
2017-07-29 04:28:09,683 testing 36/500 data 1.0030s net 0.3562s post 0.0078s
2017-07-29 04:28:10,990 testing 40/500 data 0.9990s net 0.3544s post 0.0077s
2017-07-29 04:28:12,316 testing 44/500 data 1.0010s net 0.3491s post 0.0078s
2017-07-29 04:28:13,667 testing 48/500 data 1.0032s net 0.3463s post 0.0077s
2017-07-29 04:28:17,926 testing 52/500 data 1.2296s net 0.3433s post 0.0076s
2017-07-29 04:28:19,249 testing 56/500 data 1.2116s net 0.3428s post 0.0077s
2017-07-29 04:28:20,599 testing 60/500 data 1.1958s net 0.3445s post 0.0077s
2017-07-29 04:28:21,908 testing 64/500 data 1.1772s net 0.3482s post 0.0076s
2017-07-29 04:28:23,208 testing 68/500 data 1.1613s net 0.3504s post 0.0076s
2017-07-29 04:28:24,510 testing 72/500 data 1.1487s net 0.3508s post 0.0078s
2017-07-29 04:28:25,785 testing 76/500 data 1.1367s net 0.3505s post 0.0078s
2017-07-29 04:28:27,052 testing 80/500 data 1.1261s net 0.3496s post 0.0079s
2017-07-29 04:28:28,348 testing 84/500 data 1.1191s net 0.3477s post 0.0079s
2017-07-29 04:28:29,647 testing 88/500 data 1.1118s net 0.3470s post 0.0079s
2017-07-29 04:28:30,934 testing 92/500 data 1.1053s net 0.3455s post 0.0081s
2017-07-29 04:28:32,216 testing 96/500 data 1.0987s net 0.3446s post 0.0082s
2017-07-29 04:28:33,531 testing 100/500 data 1.0935s net 0.3444s post 0.0082s
2017-07-29 04:28:34,845 testing 104/500 data 1.0887s net 0.3442s post 0.0081s
2017-07-29 04:28:36,154 testing 108/500 data 1.0852s net 0.3429s post 0.0080s
2017-07-29 04:28:37,470 testing 112/500 data 1.0821s net 0.3417s post 0.0080s
2017-07-29 04:28:38,860 testing 116/500 data 1.0807s net 0.3416s post 0.0080s
2017-07-29 04:28:40,204 testing 120/500 data 1.0768s net 0.3427s post 0.0080s
2017-07-29 04:28:41,508 testing 124/500 data 1.0715s net 0.3440s post 0.0080s
2017-07-29 04:28:42,774 testing 128/500 data 1.0677s net 0.3429s post 0.0079s
2017-07-29 04:28:44,054 testing 132/500 data 1.0649s net 0.3415s post 0.0079s
2017-07-29 04:28:45,426 testing 136/500 data 1.0627s net 0.3425s post 0.0079s
2017-07-29 04:28:46,701 testing 140/500 data 1.0585s net 0.3427s post 0.0079s
2017-07-29 04:28:47,957 testing 144/500 data 1.0540s net 0.3431s post 0.0078s
2017-07-29 04:28:49,237 testing 148/500 data 1.0506s net 0.3431s post 0.0078s
2017-07-29 04:28:50,490 testing 152/500 data 1.0468s net 0.3430s post 0.0078s
2017-07-29 04:28:51,858 testing 156/500 data 1.0444s net 0.3447s post 0.0078s
2017-07-29 04:28:53,141 testing 160/500 data 1.0404s net 0.3459s post 0.0078s
2017-07-29 04:28:54,411 testing 164/500 data 1.0368s net 0.3465s post 0.0077s
2017-07-29 04:28:55,642 testing 168/500 data 1.0330s net 0.3465s post 0.0077s
2017-07-29 04:28:56,907 testing 172/500 data 1.0301s net 0.3464s post 0.0078s
2017-07-29 04:28:58,172 testing 176/500 data 1.0276s net 0.3462s post 0.0079s
2017-07-29 04:28:59,451 testing 180/500 data 1.0253s net 0.3462s post 0.0078s
2017-07-29 04:29:00,819 testing 184/500 data 1.0254s net 0.3459s post 0.0079s
2017-07-29 04:29:02,118 testing 188/500 data 1.0243s net 0.3453s post 0.0079s
2017-07-29 04:29:03,428 testing 192/500 data 1.0231s net 0.3450s post 0.0079s
2017-07-29 04:29:04,726 testing 196/500 data 1.0212s net 0.3453s post 0.0079s
2017-07-29 04:29:06,040 testing 200/500 data 1.0187s net 0.3466s post 0.0079s
2017-07-29 04:29:07,302 testing 204/500 data 1.0152s net 0.3480s post 0.0078s
2017-07-29 04:29:08,593 testing 208/500 data 1.0127s net 0.3489s post 0.0079s
2017-07-29 04:29:09,869 testing 212/500 data 1.0103s net 0.3495s post 0.0079s
2017-07-29 04:29:11,190 testing 216/500 data 1.0083s net 0.3506s post 0.0080s
2017-07-29 04:29:12,427 testing 220/500 data 1.0056s net 0.3508s post 0.0080s
2017-07-29 04:29:13,712 testing 224/500 data 1.0040s net 0.3509s post 0.0081s
2017-07-29 04:29:14,977 testing 228/500 data 1.0021s net 0.3511s post 0.0081s
2017-07-29 04:29:16,284 testing 232/500 data 1.0018s net 0.3505s post 0.0081s
2017-07-29 04:29:17,582 testing 236/500 data 1.0009s net 0.3503s post 0.0082s
2017-07-29 04:29:18,864 testing 240/500 data 0.9997s net 0.3502s post 0.0082s
2017-07-29 04:29:20,128 testing 244/500 data 0.9988s net 0.3495s post 0.0082s
2017-07-29 04:29:21,412 testing 248/500 data 0.9978s net 0.3493s post 0.0082s
2017-07-29 04:29:22,672 testing 252/500 data 0.9965s net 0.3492s post 0.0082s
2017-07-29 04:29:23,919 testing 256/500 data 0.9954s net 0.3486s post 0.0081s
2017-07-29 04:29:25,252 testing 260/500 data 0.9959s net 0.3479s post 0.0081s
2017-07-29 04:29:26,569 testing 264/500 data 0.9961s net 0.3471s post 0.0081s
2017-07-29 04:29:27,899 testing 268/500 data 0.9959s net 0.3470s post 0.0081s
2017-07-29 04:29:29,250 testing 272/500 data 0.9952s net 0.3477s post 0.0082s
2017-07-29 04:29:30,519 testing 276/500 data 0.9934s net 0.3484s post 0.0081s
2017-07-29 04:29:31,704 testing 280/500 data 0.9917s net 0.3477s post 0.0081s
2017-07-29 04:29:33,020 testing 284/500 data 0.9916s net 0.3472s post 0.0082s
2017-07-29 04:29:34,374 testing 288/500 data 0.9922s net 0.3468s post 0.0082s
2017-07-29 04:29:35,662 testing 292/500 data 0.9914s net 0.3467s post 0.0082s
2017-07-29 04:29:36,999 testing 296/500 data 0.9906s net 0.3474s post 0.0082s
2017-07-29 04:29:38,330 testing 300/500 data 0.9895s net 0.3484s post 0.0082s
2017-07-29 04:29:39,578 testing 304/500 data 0.9872s net 0.3493s post 0.0082s
2017-07-29 04:29:40,810 testing 308/500 data 0.9853s net 0.3497s post 0.0083s
2017-07-29 04:29:42,131 testing 312/500 data 0.9851s net 0.3496s post 0.0083s
2017-07-29 04:29:43,395 testing 316/500 data 0.9847s net 0.3490s post 0.0082s
2017-07-29 04:29:44,683 testing 320/500 data 0.9840s net 0.3490s post 0.0083s
2017-07-29 04:29:45,985 testing 324/500 data 0.9837s net 0.3488s post 0.0083s
2017-07-29 04:29:47,293 testing 328/500 data 0.9837s net 0.3483s post 0.0083s
2017-07-29 04:29:48,286 testing 332/500 data 0.9800s net 0.3479s post 0.0083s
2017-07-29 04:29:49,664 testing 336/500 data 0.9808s net 0.3476s post 0.0083s
2017-07-29 04:29:51,023 testing 340/500 data 0.9815s net 0.3472s post 0.0083s
2017-07-29 04:29:52,397 testing 344/500 data 0.9823s net 0.3468s post 0.0083s
2017-07-29 04:29:53,702 testing 348/500 data 0.9824s net 0.3464s post 0.0083s
2017-07-29 04:29:54,991 testing 352/500 data 0.9822s net 0.3460s post 0.0083s
2017-07-29 04:29:56,489 testing 356/500 data 0.9833s net 0.3467s post 0.0083s
2017-07-29 04:29:57,750 testing 360/500 data 0.9822s net 0.3469s post 0.0083s
2017-07-29 04:29:59,088 testing 364/500 data 0.9824s net 0.3468s post 0.0083s
2017-07-29 04:30:00,403 testing 368/500 data 0.9820s net 0.3469s post 0.0083s
2017-07-29 04:30:01,775 testing 372/500 data 0.9822s net 0.3471s post 0.0084s
2017-07-29 04:30:03,054 testing 376/500 data 0.9817s net 0.3469s post 0.0083s
2017-07-29 04:30:04,410 testing 380/500 data 0.9819s net 0.3469s post 0.0084s
2017-07-29 04:30:05,762 testing 384/500 data 0.9824s net 0.3465s post 0.0084s
2017-07-29 04:30:07,109 testing 388/500 data 0.9828s net 0.3463s post 0.0084s
2017-07-29 04:30:08,476 testing 392/500 data 0.9831s net 0.3462s post 0.0084s
2017-07-29 04:30:09,792 testing 396/500 data 0.9833s net 0.3459s post 0.0084s
2017-07-29 04:30:11,331 testing 400/500 data 0.9850s net 0.3461s post 0.0083s
2017-07-29 04:30:12,626 testing 404/500 data 0.9847s net 0.3460s post 0.0083s
2017-07-29 04:30:13,937 testing 408/500 data 0.9845s net 0.3460s post 0.0083s
2017-07-29 04:30:15,210 testing 412/500 data 0.9839s net 0.3459s post 0.0084s
2017-07-29 04:30:16,529 testing 416/500 data 0.9840s net 0.3456s post 0.0083s
2017-07-29 04:30:17,823 testing 420/500 data 0.9839s net 0.3453s post 0.0083s
2017-07-29 04:30:19,143 testing 424/500 data 0.9839s net 0.3451s post 0.0084s
2017-07-29 04:30:20,483 testing 428/500 data 0.9843s net 0.3447s post 0.0084s
2017-07-29 04:30:21,856 testing 432/500 data 0.9849s net 0.3444s post 0.0084s
2017-07-29 04:30:23,171 testing 436/500 data 0.9850s net 0.3441s post 0.0084s
2017-07-29 04:30:24,503 testing 440/500 data 0.9853s net 0.3438s post 0.0084s
2017-07-29 04:30:28,230 testing 444/500 data 1.0064s net 0.3442s post 0.0084s
2017-07-29 04:30:31,001 testing 448/500 data 1.0189s net 0.3442s post 0.0084s
2017-07-29 04:30:34,045 testing 452/500 data 1.0333s net 0.3447s post 0.0084s
2017-07-29 04:30:36,650 testing 456/500 data 1.0439s net 0.3447s post 0.0085s
2017-07-29 04:30:39,099 testing 460/500 data 1.0528s net 0.3450s post 0.0084s
2017-07-29 04:30:41,038 testing 464/500 data 1.0578s net 0.3446s post 0.0084s
2017-07-29 04:30:42,767 testing 468/500 data 1.0608s net 0.3444s post 0.0084s
2017-07-29 04:30:44,507 testing 472/500 data 1.0636s net 0.3443s post 0.0084s
2017-07-29 04:30:46,171 testing 476/500 data 1.0653s net 0.3447s post 0.0084s
2017-07-29 04:30:47,797 testing 480/500 data 1.0666s net 0.3452s post 0.0084s
2017-07-29 04:30:49,297 testing 484/500 data 1.0673s net 0.3451s post 0.0084s
2017-07-29 04:30:51,215 testing 488/500 data 1.0709s net 0.3456s post 0.0084s
2017-07-29 04:30:52,734 testing 492/500 data 1.0720s net 0.3452s post 0.0084s
2017-07-29 04:30:54,401 testing 496/500 data 1.0743s net 0.3449s post 0.0083s
2017-07-29 04:30:56,043 testing 500/500 data 1.0758s net 0.3451s post 0.0084s
2017-07-29 04:32:54,337 evaluate segmentation: 

2017-07-29 04:32:54,337 IU_array:

2017-07-29 04:32:54,337 0.97915
2017-07-29 04:32:54,337 0.83181
2017-07-29 04:32:54,337 0.91265
2017-07-29 04:32:54,337 0.49738
2017-07-29 04:32:54,337 0.53552
2017-07-29 04:32:54,337 0.53511
2017-07-29 04:32:54,337 0.63487
2017-07-29 04:32:54,337 0.73459
2017-07-29 04:32:54,337 0.91487
2017-07-29 04:32:54,337 0.61664
2017-07-29 04:32:54,338 0.93669
2017-07-29 04:32:54,338 0.78191
2017-07-29 04:32:54,338 0.58791
2017-07-29 04:32:54,338 0.93791
2017-07-29 04:32:54,338 0.61794
2017-07-29 04:32:54,338 0.81977
2017-07-29 04:32:54,338 0.63666
2017-07-29 04:32:54,338 0.61149
2017-07-29 04:32:54,338 0.74196
2017-07-29 04:32:54,338 meanIU:0.72973

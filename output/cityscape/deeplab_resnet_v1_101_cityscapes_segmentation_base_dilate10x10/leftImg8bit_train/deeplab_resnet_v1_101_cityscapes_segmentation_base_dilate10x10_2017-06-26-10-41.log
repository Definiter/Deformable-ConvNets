2017-06-26 10:41:22,456 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate10x10'}

2017-06-26 10:42:52,603 Epoch[0] Batch [10]	Speed: 1.83 samples/sec	Train-FCNLogLoss=2.886666,	
2017-06-26 10:43:17,954 Epoch[0] Batch [20]	Speed: 1.58 samples/sec	Train-FCNLogLoss=2.761536,	
2017-06-26 10:43:27,383 Epoch[0] Batch [30]	Speed: 4.24 samples/sec	Train-FCNLogLoss=2.535397,	
2017-06-26 10:43:36,335 Epoch[0] Batch [40]	Speed: 4.47 samples/sec	Train-FCNLogLoss=2.275961,	
2017-06-26 10:43:53,658 Epoch[0] Batch [50]	Speed: 2.31 samples/sec	Train-FCNLogLoss=2.051910,	
2017-06-26 10:44:02,774 Epoch[0] Batch [60]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.894356,	
2017-06-26 10:44:12,123 Epoch[0] Batch [70]	Speed: 4.28 samples/sec	Train-FCNLogLoss=1.771248,	
2017-06-26 10:44:20,882 Epoch[0] Batch [80]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.649590,	
2017-06-26 10:44:29,610 Epoch[0] Batch [90]	Speed: 4.58 samples/sec	Train-FCNLogLoss=1.559380,	
2017-06-26 10:44:37,681 Epoch[0] Batch [100]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.477210,	
2017-06-26 10:44:45,478 Epoch[0] Batch [110]	Speed: 5.13 samples/sec	Train-FCNLogLoss=1.405363,	
2017-06-26 10:44:53,779 Epoch[0] Batch [120]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.344691,	
2017-06-26 10:45:01,392 Epoch[0] Batch [130]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.296837,	
2017-06-26 10:45:09,557 Epoch[0] Batch [140]	Speed: 4.90 samples/sec	Train-FCNLogLoss=1.249717,	
2017-06-26 10:45:16,930 Epoch[0] Batch [150]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.213145,	
2017-06-26 10:45:24,101 Epoch[0] Batch [160]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.176296,	
2017-06-26 10:45:31,273 Epoch[0] Batch [170]	Speed: 5.58 samples/sec	Train-FCNLogLoss=1.148447,	
2017-06-26 10:45:38,009 Epoch[0] Batch [180]	Speed: 5.94 samples/sec	Train-FCNLogLoss=1.115857,	
2017-06-26 10:45:45,747 Epoch[0] Batch [190]	Speed: 5.17 samples/sec	Train-FCNLogLoss=1.084273,	
2017-06-26 10:45:53,453 Epoch[0] Batch [200]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.057318,	
2017-06-26 10:46:01,591 Epoch[0] Batch [210]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.032461,	
2017-06-26 10:46:10,800 Epoch[0] Batch [220]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.011301,	
2017-06-26 10:46:16,632 Epoch[0] Batch [230]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.994178,	
2017-06-26 10:46:23,134 Epoch[0] Batch [240]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.973094,	
2017-06-26 10:46:30,574 Epoch[0] Batch [250]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.951761,	
2017-06-26 10:46:39,156 Epoch[0] Batch [260]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.934388,	
2017-06-26 10:46:47,109 Epoch[0] Batch [270]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.917260,	
2017-06-26 10:47:00,252 Epoch[0] Batch [280]	Speed: 3.04 samples/sec	Train-FCNLogLoss=0.906597,	
2017-06-26 10:47:08,312 Epoch[0] Batch [290]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.892754,	
2017-06-26 10:47:18,226 Epoch[0] Batch [300]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.878770,	
2017-06-26 10:47:26,611 Epoch[0] Batch [310]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.864658,	
2017-06-26 10:47:34,404 Epoch[0] Batch [320]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.852007,	
2017-06-26 10:47:42,208 Epoch[0] Batch [330]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.840977,	
2017-06-26 10:47:49,669 Epoch[0] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.829213,	
2017-06-26 10:47:58,164 Epoch[0] Batch [350]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.816593,	
2017-06-26 10:48:06,613 Epoch[0] Batch [360]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.804183,	
2017-06-26 10:48:14,383 Epoch[0] Batch [370]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.793938,	
2017-06-26 10:48:22,306 Epoch[0] Batch [380]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.783537,	
2017-06-26 10:48:30,173 Epoch[0] Batch [390]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.775190,	
2017-06-26 10:48:37,557 Epoch[0] Batch [400]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.765428,	
2017-06-26 10:48:45,619 Epoch[0] Batch [410]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.756529,	
2017-06-26 10:48:54,280 Epoch[0] Batch [420]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.749432,	
2017-06-26 10:49:02,550 Epoch[0] Batch [430]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.741130,	
2017-06-26 10:49:11,671 Epoch[0] Batch [440]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.733780,	
2017-06-26 10:49:21,213 Epoch[0] Batch [450]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.726964,	
2017-06-26 10:49:30,741 Epoch[0] Batch [460]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.720736,	
2017-06-26 10:49:39,774 Epoch[0] Batch [470]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.714540,	
2017-06-26 10:49:48,547 Epoch[0] Batch [480]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.707837,	
2017-06-26 10:49:57,381 Epoch[0] Batch [490]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.702487,	
2017-06-26 10:50:05,943 Epoch[0] Batch [500]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.696880,	
2017-06-26 10:50:14,757 Epoch[0] Batch [510]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.691311,	
2017-06-26 10:50:23,578 Epoch[0] Batch [520]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.685004,	
2017-06-26 10:50:32,365 Epoch[0] Batch [530]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.679447,	
2017-06-26 10:50:41,180 Epoch[0] Batch [540]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.674317,	
2017-06-26 10:50:50,440 Epoch[0] Batch [550]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.669640,	
2017-06-26 10:50:59,593 Epoch[0] Batch [560]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.665948,	
2017-06-26 10:51:08,578 Epoch[0] Batch [570]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.661340,	
2017-06-26 10:51:17,849 Epoch[0] Batch [580]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.657357,	
2017-06-26 10:51:26,962 Epoch[0] Batch [590]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.653972,	
2017-06-26 10:51:36,087 Epoch[0] Batch [600]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.650586,	
2017-06-26 10:51:45,275 Epoch[0] Batch [610]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.646778,	
2017-06-26 10:51:54,611 Epoch[0] Batch [620]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.643437,	
2017-06-26 10:52:04,003 Epoch[0] Batch [630]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.640611,	
2017-06-26 10:52:13,163 Epoch[0] Batch [640]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.636788,	
2017-06-26 10:52:22,642 Epoch[0] Batch [650]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.633077,	
2017-06-26 10:52:31,991 Epoch[0] Batch [660]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.628803,	
2017-06-26 10:52:41,183 Epoch[0] Batch [670]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.625439,	
2017-06-26 10:52:50,513 Epoch[0] Batch [680]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.621945,	
2017-06-26 10:52:59,650 Epoch[0] Batch [690]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.617653,	
2017-06-26 10:53:08,804 Epoch[0] Batch [700]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.614494,	
2017-06-26 10:53:18,147 Epoch[0] Batch [710]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.610802,	
2017-06-26 10:53:27,124 Epoch[0] Batch [720]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.606882,	
2017-06-26 10:53:36,216 Epoch[0] Batch [730]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.604143,	
2017-06-26 10:53:45,812 Epoch[0] Batch [740]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.600941,	
2017-06-26 10:53:55,087 Epoch[0] Batch [750]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.597230,	
2017-06-26 10:54:04,104 Epoch[0] Batch [760]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.593628,	
2017-06-26 10:54:13,274 Epoch[0] Batch [770]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.589634,	
2017-06-26 10:54:22,269 Epoch[0] Batch [780]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.587342,	
2017-06-26 10:54:31,215 Epoch[0] Batch [790]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.584638,	
2017-06-26 10:54:40,109 Epoch[0] Batch [800]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.581682,	
2017-06-26 10:54:49,310 Epoch[0] Batch [810]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.578990,	
2017-06-26 10:54:58,389 Epoch[0] Batch [820]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.575562,	
2017-06-26 10:55:07,501 Epoch[0] Batch [830]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.573474,	
2017-06-26 10:55:16,640 Epoch[0] Batch [840]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.571241,	
2017-06-26 10:55:26,051 Epoch[0] Batch [850]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.568004,	
2017-06-26 10:55:35,366 Epoch[0] Batch [860]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.565333,	
2017-06-26 10:55:44,642 Epoch[0] Batch [870]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.562233,	
2017-06-26 10:55:54,121 Epoch[0] Batch [880]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.559390,	
2017-06-26 10:56:03,349 Epoch[0] Batch [890]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.557009,	
2017-06-26 10:56:12,372 Epoch[0] Batch [900]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.554756,	
2017-06-26 10:56:21,603 Epoch[0] Batch [910]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.552135,	
2017-06-26 10:56:30,936 Epoch[0] Batch [920]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.549622,	
2017-06-26 10:56:40,370 Epoch[0] Batch [930]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.546839,	
2017-06-26 10:56:50,011 Epoch[0] Batch [940]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.543923,	
2017-06-26 10:56:59,591 Epoch[0] Batch [950]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.542004,	
2017-06-26 10:57:08,903 Epoch[0] Batch [960]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.539745,	
2017-06-26 10:57:18,419 Epoch[0] Batch [970]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.537073,	
2017-06-26 10:57:27,600 Epoch[0] Batch [980]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.535140,	
2017-06-26 10:57:37,330 Epoch[0] Batch [990]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.533083,	
2017-06-26 10:57:47,153 Epoch[0] Batch [1000]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.531491,	
2017-06-26 10:57:56,637 Epoch[0] Batch [1010]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.532998,	
2017-06-26 10:58:05,885 Epoch[0] Batch [1020]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.533899,	
2017-06-26 10:58:14,725 Epoch[0] Batch [1030]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.534289,	
2017-06-26 10:58:23,924 Epoch[0] Batch [1040]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.533750,	
2017-06-26 10:58:32,926 Epoch[0] Batch [1050]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.533030,	
2017-06-26 10:58:41,956 Epoch[0] Batch [1060]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.531596,	
2017-06-26 10:58:51,223 Epoch[0] Batch [1070]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.530769,	
2017-06-26 10:59:00,090 Epoch[0] Batch [1080]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.529792,	
2017-06-26 10:59:09,211 Epoch[0] Batch [1090]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.528862,	
2017-06-26 10:59:17,836 Epoch[0] Batch [1100]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.528047,	
2017-06-26 10:59:26,593 Epoch[0] Batch [1110]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.526485,	
2017-06-26 10:59:36,006 Epoch[0] Batch [1120]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.525277,	
2017-06-26 10:59:45,541 Epoch[0] Batch [1130]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.523899,	
2017-06-26 10:59:54,983 Epoch[0] Batch [1140]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.522698,	
2017-06-26 11:00:04,260 Epoch[0] Batch [1150]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.521373,	
2017-06-26 11:00:13,511 Epoch[0] Batch [1160]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.520497,	
2017-06-26 11:00:23,070 Epoch[0] Batch [1170]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.519793,	
2017-06-26 11:00:32,308 Epoch[0] Batch [1180]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.518061,	
2017-06-26 11:00:41,765 Epoch[0] Batch [1190]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.516471,	
2017-06-26 11:00:51,385 Epoch[0] Batch [1200]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.514767,	
2017-06-26 11:01:00,636 Epoch[0] Batch [1210]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.514144,	
2017-06-26 11:01:09,812 Epoch[0] Batch [1220]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.512974,	
2017-06-26 11:01:18,838 Epoch[0] Batch [1230]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.511165,	
2017-06-26 11:01:28,099 Epoch[0] Batch [1240]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.509838,	
2017-06-26 11:01:37,488 Epoch[0] Batch [1250]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.508107,	
2017-06-26 11:01:46,545 Epoch[0] Batch [1260]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.506792,	
2017-06-26 11:01:55,560 Epoch[0] Batch [1270]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.505203,	
2017-06-26 11:02:04,772 Epoch[0] Batch [1280]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.503429,	
2017-06-26 11:02:14,198 Epoch[0] Batch [1290]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.501972,	
2017-06-26 11:02:23,848 Epoch[0] Batch [1300]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.500852,	
2017-06-26 11:02:33,708 Epoch[0] Batch [1310]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.499683,	
2017-06-26 11:02:43,440 Epoch[0] Batch [1320]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.498310,	
2017-06-26 11:02:53,290 Epoch[0] Batch [1330]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.496827,	
2017-06-26 11:03:03,075 Epoch[0] Batch [1340]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.495667,	
2017-06-26 11:03:12,633 Epoch[0] Batch [1350]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.494157,	
2017-06-26 11:03:22,347 Epoch[0] Batch [1360]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.492469,	
2017-06-26 11:03:31,858 Epoch[0] Batch [1370]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.490706,	
2017-06-26 11:03:41,573 Epoch[0] Batch [1380]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.489079,	
2017-06-26 11:03:51,266 Epoch[0] Batch [1390]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.487778,	
2017-06-26 11:04:00,959 Epoch[0] Batch [1400]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.486217,	
2017-06-26 11:04:10,795 Epoch[0] Batch [1410]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.484590,	
2017-06-26 11:04:20,068 Epoch[0] Batch [1420]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.483377,	
2017-06-26 11:04:29,136 Epoch[0] Batch [1430]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.482218,	
2017-06-26 11:04:38,262 Epoch[0] Batch [1440]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.480727,	
2017-06-26 11:04:48,009 Epoch[0] Batch [1450]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.479645,	
2017-06-26 11:04:57,932 Epoch[0] Batch [1460]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.478658,	
2017-06-26 11:05:07,757 Epoch[0] Batch [1470]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.477395,	
2017-06-26 11:05:16,950 Epoch[0] Batch [1480]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.477242,	
2017-06-26 11:05:22,632 Epoch[0] Train-FCNLogLoss=0.476751
2017-06-26 11:05:22,632 Epoch[0] Time cost=1385.794
2017-06-26 11:05:24,094 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0001.params"
2017-06-26 11:05:29,699 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0001.states"
2017-06-26 11:05:38,602 Epoch[1] Batch [10]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.301916,	
2017-06-26 11:05:46,888 Epoch[1] Batch [20]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.329095,	
2017-06-26 11:05:55,198 Epoch[1] Batch [30]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.323573,	
2017-06-26 11:06:03,270 Epoch[1] Batch [40]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.304994,	
2017-06-26 11:06:11,126 Epoch[1] Batch [50]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.296992,	
2017-06-26 11:06:19,290 Epoch[1] Batch [60]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.297716,	
2017-06-26 11:06:27,777 Epoch[1] Batch [70]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.291300,	
2017-06-26 11:06:35,964 Epoch[1] Batch [80]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.287373,	
2017-06-26 11:06:44,030 Epoch[1] Batch [90]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.282540,	
2017-06-26 11:06:52,711 Epoch[1] Batch [100]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.279244,	
2017-06-26 11:07:01,455 Epoch[1] Batch [110]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.275767,	
2017-06-26 11:07:09,925 Epoch[1] Batch [120]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.274815,	
2017-06-26 11:07:18,262 Epoch[1] Batch [130]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.276878,	
2017-06-26 11:07:26,682 Epoch[1] Batch [140]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.279384,	
2017-06-26 11:07:35,133 Epoch[1] Batch [150]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.288457,	
2017-06-26 11:07:43,473 Epoch[1] Batch [160]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.293157,	
2017-06-26 11:07:51,411 Epoch[1] Batch [170]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.293956,	
2017-06-26 11:07:59,304 Epoch[1] Batch [180]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.294556,	
2017-06-26 11:08:07,274 Epoch[1] Batch [190]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.294228,	
2017-06-26 11:08:15,171 Epoch[1] Batch [200]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.294834,	
2017-06-26 11:08:22,959 Epoch[1] Batch [210]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.294175,	
2017-06-26 11:08:30,608 Epoch[1] Batch [220]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.292975,	
2017-06-26 11:08:38,523 Epoch[1] Batch [230]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.291572,	
2017-06-26 11:08:46,073 Epoch[1] Batch [240]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.289788,	
2017-06-26 11:08:53,894 Epoch[1] Batch [250]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.288293,	
2017-06-26 11:09:01,836 Epoch[1] Batch [260]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.288807,	
2017-06-26 11:09:09,634 Epoch[1] Batch [270]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.288352,	
2017-06-26 11:09:17,368 Epoch[1] Batch [280]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.288034,	
2017-06-26 11:09:25,019 Epoch[1] Batch [290]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.288600,	
2017-06-26 11:09:32,626 Epoch[1] Batch [300]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.286907,	
2017-06-26 11:09:40,123 Epoch[1] Batch [310]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.286722,	
2017-06-26 11:09:47,720 Epoch[1] Batch [320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.286059,	
2017-06-26 11:09:55,299 Epoch[1] Batch [330]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.285600,	
2017-06-26 11:10:02,894 Epoch[1] Batch [340]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.285314,	
2017-06-26 11:10:10,575 Epoch[1] Batch [350]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.284514,	
2017-06-26 11:10:18,195 Epoch[1] Batch [360]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.282793,	
2017-06-26 11:10:25,811 Epoch[1] Batch [370]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.283031,	
2017-06-26 11:10:33,572 Epoch[1] Batch [380]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.282336,	
2017-06-26 11:10:41,163 Epoch[1] Batch [390]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.281830,	
2017-06-26 11:10:48,729 Epoch[1] Batch [400]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.281433,	
2017-06-26 11:10:56,419 Epoch[1] Batch [410]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.281823,	
2017-06-26 11:11:04,018 Epoch[1] Batch [420]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.280546,	
2017-06-26 11:11:11,484 Epoch[1] Batch [430]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.279945,	
2017-06-26 11:11:19,138 Epoch[1] Batch [440]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.279433,	
2017-06-26 11:11:26,959 Epoch[1] Batch [450]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.278576,	
2017-06-26 11:11:34,621 Epoch[1] Batch [460]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.277629,	
2017-06-26 11:11:42,218 Epoch[1] Batch [470]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.275938,	
2017-06-26 11:11:49,878 Epoch[1] Batch [480]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.274883,	
2017-06-26 11:11:57,464 Epoch[1] Batch [490]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.274223,	
2017-06-26 11:12:04,977 Epoch[1] Batch [500]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.274755,	
2017-06-26 11:12:12,708 Epoch[1] Batch [510]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.274354,	
2017-06-26 11:12:20,299 Epoch[1] Batch [520]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.274140,	
2017-06-26 11:12:27,295 Epoch[1] Batch [530]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.274029,	
2017-06-26 11:12:34,430 Epoch[1] Batch [540]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.273947,	
2017-06-26 11:12:40,922 Epoch[1] Batch [550]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.273577,	
2017-06-26 11:12:47,756 Epoch[1] Batch [560]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.274635,	
2017-06-26 11:12:54,728 Epoch[1] Batch [570]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.274309,	
2017-06-26 11:13:01,921 Epoch[1] Batch [580]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.274166,	
2017-06-26 11:13:08,438 Epoch[1] Batch [590]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.273490,	
2017-06-26 11:13:15,102 Epoch[1] Batch [600]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.272812,	
2017-06-26 11:13:22,144 Epoch[1] Batch [610]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.272519,	
2017-06-26 11:13:29,524 Epoch[1] Batch [620]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.273097,	
2017-06-26 11:13:37,036 Epoch[1] Batch [630]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.273132,	
2017-06-26 11:13:44,655 Epoch[1] Batch [640]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.273263,	
2017-06-26 11:13:52,170 Epoch[1] Batch [650]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.272683,	
2017-06-26 11:13:59,607 Epoch[1] Batch [660]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.271681,	
2017-06-26 11:14:07,059 Epoch[1] Batch [670]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.270918,	
2017-06-26 11:14:14,332 Epoch[1] Batch [680]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.270052,	
2017-06-26 11:14:21,843 Epoch[1] Batch [690]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.268999,	
2017-06-26 11:14:29,589 Epoch[1] Batch [700]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.267878,	
2017-06-26 11:14:36,897 Epoch[1] Batch [710]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.267621,	
2017-06-26 11:14:43,824 Epoch[1] Batch [720]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.267147,	
2017-06-26 11:14:51,031 Epoch[1] Batch [730]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.267271,	
2017-06-26 11:14:58,476 Epoch[1] Batch [740]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.267033,	
2017-06-26 11:15:05,052 Epoch[1] Batch [750]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.266288,	
2017-06-26 11:15:11,827 Epoch[1] Batch [760]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.266444,	
2017-06-26 11:15:19,092 Epoch[1] Batch [770]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.266190,	
2017-06-26 11:15:26,518 Epoch[1] Batch [780]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.265456,	
2017-06-26 11:15:33,595 Epoch[1] Batch [790]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.264790,	
2017-06-26 11:15:40,854 Epoch[1] Batch [800]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.264346,	
2017-06-26 11:15:48,228 Epoch[1] Batch [810]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.264642,	
2017-06-26 11:15:55,177 Epoch[1] Batch [820]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.264438,	
2017-06-26 11:16:02,719 Epoch[1] Batch [830]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.264912,	
2017-06-26 11:16:10,292 Epoch[1] Batch [840]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.264742,	
2017-06-26 11:16:18,096 Epoch[1] Batch [850]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.264334,	
2017-06-26 11:16:25,685 Epoch[1] Batch [860]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.264312,	
2017-06-26 11:16:32,706 Epoch[1] Batch [870]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.264160,	
2017-06-26 11:16:39,983 Epoch[1] Batch [880]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.263924,	
2017-06-26 11:16:47,185 Epoch[1] Batch [890]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.263756,	
2017-06-26 11:16:54,131 Epoch[1] Batch [900]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.262992,	
2017-06-26 11:17:01,252 Epoch[1] Batch [910]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.263082,	
2017-06-26 11:17:08,413 Epoch[1] Batch [920]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.262471,	
2017-06-26 11:17:15,849 Epoch[1] Batch [930]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.262456,	
2017-06-26 11:17:22,868 Epoch[1] Batch [940]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.262326,	
2017-06-26 11:17:30,423 Epoch[1] Batch [950]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.262089,	
2017-06-26 11:17:37,741 Epoch[1] Batch [960]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.262077,	
2017-06-26 11:17:44,742 Epoch[1] Batch [970]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.262238,	
2017-06-26 11:17:52,069 Epoch[1] Batch [980]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.262130,	
2017-06-26 11:17:59,177 Epoch[1] Batch [990]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.262230,	
2017-06-26 11:18:06,389 Epoch[1] Batch [1000]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.262268,	
2017-06-26 11:18:13,896 Epoch[1] Batch [1010]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.262146,	
2017-06-26 11:18:21,730 Epoch[1] Batch [1020]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.261949,	
2017-06-26 11:18:29,274 Epoch[1] Batch [1030]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.261459,	
2017-06-26 11:18:37,164 Epoch[1] Batch [1040]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.261069,	
2017-06-26 11:18:44,863 Epoch[1] Batch [1050]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.261066,	
2017-06-26 11:18:52,601 Epoch[1] Batch [1060]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.261181,	
2017-06-26 11:19:00,127 Epoch[1] Batch [1070]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.260957,	
2017-06-26 11:19:07,615 Epoch[1] Batch [1080]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.261321,	
2017-06-26 11:19:14,940 Epoch[1] Batch [1090]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.261307,	
2017-06-26 11:19:21,976 Epoch[1] Batch [1100]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.261280,	
2017-06-26 11:19:29,769 Epoch[1] Batch [1110]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.261168,	
2017-06-26 11:19:37,807 Epoch[1] Batch [1120]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.260948,	
2017-06-26 11:19:44,986 Epoch[1] Batch [1130]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.261038,	
2017-06-26 11:19:52,084 Epoch[1] Batch [1140]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.260555,	
2017-06-26 11:19:59,161 Epoch[1] Batch [1150]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.260561,	
2017-06-26 11:20:06,383 Epoch[1] Batch [1160]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.260123,	
2017-06-26 11:20:13,673 Epoch[1] Batch [1170]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.260154,	
2017-06-26 11:20:20,994 Epoch[1] Batch [1180]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.259764,	
2017-06-26 11:20:28,262 Epoch[1] Batch [1190]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.259633,	
2017-06-26 11:20:35,090 Epoch[1] Batch [1200]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.259538,	
2017-06-26 11:20:42,348 Epoch[1] Batch [1210]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.259381,	
2017-06-26 11:20:49,520 Epoch[1] Batch [1220]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.259226,	
2017-06-26 11:20:56,653 Epoch[1] Batch [1230]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.258753,	
2017-06-26 11:21:04,183 Epoch[1] Batch [1240]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.258714,	
2017-06-26 11:21:11,695 Epoch[1] Batch [1250]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.258536,	
2017-06-26 11:21:19,348 Epoch[1] Batch [1260]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.258209,	
2017-06-26 11:21:27,003 Epoch[1] Batch [1270]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.257811,	
2017-06-26 11:21:35,166 Epoch[1] Batch [1280]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.257416,	
2017-06-26 11:21:42,469 Epoch[1] Batch [1290]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.257250,	
2017-06-26 11:21:50,432 Epoch[1] Batch [1300]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.256709,	
2017-06-26 11:21:58,007 Epoch[1] Batch [1310]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.256681,	
2017-06-26 11:22:05,748 Epoch[1] Batch [1320]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.256981,	
2017-06-26 11:22:13,801 Epoch[1] Batch [1330]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.256945,	
2017-06-26 11:22:21,414 Epoch[1] Batch [1340]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.256486,	
2017-06-26 11:22:29,075 Epoch[1] Batch [1350]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.256074,	
2017-06-26 11:22:36,542 Epoch[1] Batch [1360]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.255603,	
2017-06-26 11:22:44,131 Epoch[1] Batch [1370]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.255419,	
2017-06-26 11:22:51,379 Epoch[1] Batch [1380]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.255094,	
2017-06-26 11:22:58,791 Epoch[1] Batch [1390]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.254630,	
2017-06-26 11:23:06,127 Epoch[1] Batch [1400]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.254446,	
2017-06-26 11:23:13,532 Epoch[1] Batch [1410]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.254360,	
2017-06-26 11:23:20,754 Epoch[1] Batch [1420]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.253931,	
2017-06-26 11:23:28,225 Epoch[1] Batch [1430]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.253720,	
2017-06-26 11:23:35,163 Epoch[1] Batch [1440]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.253567,	
2017-06-26 11:23:42,494 Epoch[1] Batch [1450]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.253321,	
2017-06-26 11:23:49,941 Epoch[1] Batch [1460]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.253136,	
2017-06-26 11:23:57,446 Epoch[1] Batch [1470]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.253008,	
2017-06-26 11:24:04,925 Epoch[1] Batch [1480]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.252948,	
2017-06-26 11:24:09,387 Epoch[1] Train-FCNLogLoss=0.252976
2017-06-26 11:24:09,387 Epoch[1] Time cost=1119.687
2017-06-26 11:24:10,592 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0002.params"
2017-06-26 11:24:14,308 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0002.states"
2017-06-26 11:24:22,590 Epoch[2] Batch [10]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.243286,	
2017-06-26 11:24:30,425 Epoch[2] Batch [20]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.228014,	
2017-06-26 11:24:38,131 Epoch[2] Batch [30]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.219218,	
2017-06-26 11:24:45,869 Epoch[2] Batch [40]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.214389,	
2017-06-26 11:24:53,269 Epoch[2] Batch [50]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.221073,	
2017-06-26 11:25:00,891 Epoch[2] Batch [60]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.224920,	
2017-06-26 11:25:08,616 Epoch[2] Batch [70]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.224922,	
2017-06-26 11:25:16,287 Epoch[2] Batch [80]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.227683,	
2017-06-26 11:25:23,584 Epoch[2] Batch [90]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.231456,	
2017-06-26 11:25:31,261 Epoch[2] Batch [100]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.229010,	
2017-06-26 11:25:38,858 Epoch[2] Batch [110]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.230893,	
2017-06-26 11:25:46,553 Epoch[2] Batch [120]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.230451,	
2017-06-26 11:25:54,187 Epoch[2] Batch [130]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.229815,	
2017-06-26 11:26:02,204 Epoch[2] Batch [140]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.228098,	
2017-06-26 11:26:10,207 Epoch[2] Batch [150]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.227155,	
2017-06-26 11:26:18,068 Epoch[2] Batch [160]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.225122,	
2017-06-26 11:26:25,894 Epoch[2] Batch [170]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.225143,	
2017-06-26 11:26:33,570 Epoch[2] Batch [180]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.223646,	
2017-06-26 11:26:41,305 Epoch[2] Batch [190]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.222862,	
2017-06-26 11:26:48,705 Epoch[2] Batch [200]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.221543,	
2017-06-26 11:26:55,313 Epoch[2] Batch [210]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.221364,	
2017-06-26 11:27:02,514 Epoch[2] Batch [220]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.220603,	
2017-06-26 11:27:10,129 Epoch[2] Batch [230]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.220756,	
2017-06-26 11:27:17,272 Epoch[2] Batch [240]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.221635,	
2017-06-26 11:27:25,431 Epoch[2] Batch [250]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.221189,	
2017-06-26 11:27:33,192 Epoch[2] Batch [260]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.220699,	
2017-06-26 11:27:40,644 Epoch[2] Batch [270]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.219555,	
2017-06-26 11:27:48,541 Epoch[2] Batch [280]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.220763,	
2017-06-26 11:27:56,403 Epoch[2] Batch [290]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.220423,	
2017-06-26 11:28:04,101 Epoch[2] Batch [300]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.219018,	
2017-06-26 11:28:11,937 Epoch[2] Batch [310]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.218581,	
2017-06-26 11:28:19,492 Epoch[2] Batch [320]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.217492,	
2017-06-26 11:28:26,773 Epoch[2] Batch [330]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.217613,	
2017-06-26 11:28:34,242 Epoch[2] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.216653,	
2017-06-26 11:28:42,085 Epoch[2] Batch [350]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.216083,	
2017-06-26 11:28:49,278 Epoch[2] Batch [360]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.217158,	
2017-06-26 11:28:56,798 Epoch[2] Batch [370]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.217400,	
2017-06-26 11:29:04,114 Epoch[2] Batch [380]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.216609,	
2017-06-26 11:29:11,778 Epoch[2] Batch [390]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.215896,	
2017-06-26 11:29:19,061 Epoch[2] Batch [400]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.215542,	
2017-06-26 11:29:26,326 Epoch[2] Batch [410]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.215690,	
2017-06-26 11:29:34,065 Epoch[2] Batch [420]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.215625,	
2017-06-26 11:29:41,965 Epoch[2] Batch [430]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.215625,	
2017-06-26 11:29:49,808 Epoch[2] Batch [440]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.215049,	
2017-06-26 11:29:57,086 Epoch[2] Batch [450]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.214538,	
2017-06-26 11:30:04,620 Epoch[2] Batch [460]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.214914,	
2017-06-26 11:30:12,273 Epoch[2] Batch [470]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.214657,	
2017-06-26 11:30:19,935 Epoch[2] Batch [480]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.214692,	
2017-06-26 11:30:27,734 Epoch[2] Batch [490]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.214429,	
2017-06-26 11:30:35,587 Epoch[2] Batch [500]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.214692,	
2017-06-26 11:30:43,177 Epoch[2] Batch [510]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.214726,	
2017-06-26 11:30:50,673 Epoch[2] Batch [520]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.215247,	
2017-06-26 11:30:58,276 Epoch[2] Batch [530]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.214676,	
2017-06-26 11:31:05,910 Epoch[2] Batch [540]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.214000,	
2017-06-26 11:31:13,473 Epoch[2] Batch [550]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.214588,	
2017-06-26 11:31:21,053 Epoch[2] Batch [560]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.213900,	
2017-06-26 11:31:28,818 Epoch[2] Batch [570]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.213858,	
2017-06-26 11:31:36,755 Epoch[2] Batch [580]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.213076,	
2017-06-26 11:31:44,613 Epoch[2] Batch [590]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.212392,	
2017-06-26 11:31:52,768 Epoch[2] Batch [600]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.212648,	
2017-06-26 11:32:00,936 Epoch[2] Batch [610]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.212834,	
2017-06-26 11:32:09,005 Epoch[2] Batch [620]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.212798,	
2017-06-26 11:32:16,548 Epoch[2] Batch [630]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.212719,	
2017-06-26 11:32:23,998 Epoch[2] Batch [640]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.212658,	
2017-06-26 11:32:31,483 Epoch[2] Batch [650]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.213083,	
2017-06-26 11:32:38,964 Epoch[2] Batch [660]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.213225,	
2017-06-26 11:32:46,642 Epoch[2] Batch [670]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.213020,	
2017-06-26 11:32:54,104 Epoch[2] Batch [680]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.212984,	
2017-06-26 11:33:01,585 Epoch[2] Batch [690]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.212864,	
2017-06-26 11:33:09,060 Epoch[2] Batch [700]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.212472,	
2017-06-26 11:33:16,676 Epoch[2] Batch [710]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.212230,	
2017-06-26 11:33:24,243 Epoch[2] Batch [720]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.213049,	
2017-06-26 11:33:31,925 Epoch[2] Batch [730]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.213396,	
2017-06-26 11:33:39,631 Epoch[2] Batch [740]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.213433,	
2017-06-26 11:33:47,341 Epoch[2] Batch [750]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.213368,	
2017-06-26 11:33:55,301 Epoch[2] Batch [760]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.213207,	
2017-06-26 11:34:03,078 Epoch[2] Batch [770]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.213686,	
2017-06-26 11:34:10,898 Epoch[2] Batch [780]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.214539,	
2017-06-26 11:34:18,533 Epoch[2] Batch [790]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.214009,	
2017-06-26 11:34:26,356 Epoch[2] Batch [800]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.215885,	
2017-06-26 11:34:34,120 Epoch[2] Batch [810]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.218518,	
2017-06-26 11:34:42,046 Epoch[2] Batch [820]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.220096,	
2017-06-26 11:34:49,973 Epoch[2] Batch [830]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.220387,	
2017-06-26 11:34:57,740 Epoch[2] Batch [840]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.220375,	
2017-06-26 11:35:05,567 Epoch[2] Batch [850]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.220548,	
2017-06-26 11:35:13,442 Epoch[2] Batch [860]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.220890,	
2017-06-26 11:35:21,366 Epoch[2] Batch [870]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.221021,	
2017-06-26 11:35:29,318 Epoch[2] Batch [880]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.220904,	
2017-06-26 11:35:37,230 Epoch[2] Batch [890]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.220597,	
2017-06-26 11:35:45,311 Epoch[2] Batch [900]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.220409,	
2017-06-26 11:35:53,800 Epoch[2] Batch [910]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.220583,	
2017-06-26 11:36:01,945 Epoch[2] Batch [920]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.220560,	
2017-06-26 11:36:09,657 Epoch[2] Batch [930]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.220360,	
2017-06-26 11:36:17,391 Epoch[2] Batch [940]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.221197,	
2017-06-26 11:36:24,948 Epoch[2] Batch [950]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.221343,	
2017-06-26 11:36:32,535 Epoch[2] Batch [960]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.221318,	
2017-06-26 11:36:40,149 Epoch[2] Batch [970]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.221165,	
2017-06-26 11:36:47,582 Epoch[2] Batch [980]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.221390,	
2017-06-26 11:36:54,986 Epoch[2] Batch [990]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.221525,	
2017-06-26 11:37:02,769 Epoch[2] Batch [1000]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.221328,	
2017-06-26 11:37:10,514 Epoch[2] Batch [1010]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.220979,	
2017-06-26 11:37:18,043 Epoch[2] Batch [1020]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.220717,	
2017-06-26 11:37:25,643 Epoch[2] Batch [1030]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.220452,	
2017-06-26 11:37:33,343 Epoch[2] Batch [1040]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.220242,	
2017-06-26 11:37:41,169 Epoch[2] Batch [1050]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.220284,	
2017-06-26 11:37:48,843 Epoch[2] Batch [1060]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.219976,	
2017-06-26 11:37:56,840 Epoch[2] Batch [1070]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.219645,	
2017-06-26 11:38:04,582 Epoch[2] Batch [1080]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.219496,	
2017-06-26 11:38:12,179 Epoch[2] Batch [1090]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.219601,	
2017-06-26 11:38:19,822 Epoch[2] Batch [1100]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.219272,	
2017-06-26 11:38:27,394 Epoch[2] Batch [1110]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.219340,	
2017-06-26 11:38:35,094 Epoch[2] Batch [1120]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.219715,	
2017-06-26 11:38:42,851 Epoch[2] Batch [1130]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.219575,	
2017-06-26 11:38:50,604 Epoch[2] Batch [1140]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.219361,	
2017-06-26 11:38:58,419 Epoch[2] Batch [1150]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.219474,	
2017-06-26 11:39:06,145 Epoch[2] Batch [1160]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.219469,	
2017-06-26 11:39:14,025 Epoch[2] Batch [1170]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.219344,	
2017-06-26 11:39:22,118 Epoch[2] Batch [1180]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.219341,	
2017-06-26 11:39:30,005 Epoch[2] Batch [1190]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.219157,	
2017-06-26 11:39:37,752 Epoch[2] Batch [1200]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.218817,	
2017-06-26 11:39:45,462 Epoch[2] Batch [1210]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.218778,	
2017-06-26 11:39:53,180 Epoch[2] Batch [1220]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.218894,	
2017-06-26 11:40:00,922 Epoch[2] Batch [1230]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.218965,	
2017-06-26 11:40:08,571 Epoch[2] Batch [1240]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.219507,	
2017-06-26 11:40:16,316 Epoch[2] Batch [1250]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.219375,	
2017-06-26 11:40:23,951 Epoch[2] Batch [1260]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.219274,	
2017-06-26 11:40:31,392 Epoch[2] Batch [1270]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.219143,	
2017-06-26 11:40:38,528 Epoch[2] Batch [1280]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.219229,	
2017-06-26 11:40:45,925 Epoch[2] Batch [1290]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.219133,	
2017-06-26 11:40:53,304 Epoch[2] Batch [1300]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.219005,	
2017-06-26 11:41:00,697 Epoch[2] Batch [1310]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.218584,	
2017-06-26 11:41:07,756 Epoch[2] Batch [1320]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.218504,	
2017-06-26 11:41:14,803 Epoch[2] Batch [1330]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.218342,	
2017-06-26 11:41:21,797 Epoch[2] Batch [1340]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.218203,	
2017-06-26 11:41:28,703 Epoch[2] Batch [1350]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.218080,	
2017-06-26 11:41:35,934 Epoch[2] Batch [1360]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.217917,	
2017-06-26 11:41:43,869 Epoch[2] Batch [1370]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.218018,	
2017-06-26 11:41:51,220 Epoch[2] Batch [1380]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.217805,	
2017-06-26 11:41:58,829 Epoch[2] Batch [1390]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.217804,	
2017-06-26 11:42:06,225 Epoch[2] Batch [1400]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.217754,	
2017-06-26 11:42:13,218 Epoch[2] Batch [1410]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.217705,	
2017-06-26 11:42:20,632 Epoch[2] Batch [1420]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.217592,	
2017-06-26 11:42:27,809 Epoch[2] Batch [1430]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.217497,	
2017-06-26 11:42:35,392 Epoch[2] Batch [1440]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.217275,	
2017-06-26 11:42:43,301 Epoch[2] Batch [1450]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.217300,	
2017-06-26 11:42:50,730 Epoch[2] Batch [1460]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.217181,	
2017-06-26 11:42:58,280 Epoch[2] Batch [1470]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.216979,	
2017-06-26 11:43:05,654 Epoch[2] Batch [1480]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.217041,	
2017-06-26 11:43:10,478 Epoch[2] Train-FCNLogLoss=0.216905
2017-06-26 11:43:10,479 Epoch[2] Time cost=1136.170
2017-06-26 11:43:11,596 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0003.params"
2017-06-26 11:43:15,427 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0003.states"
2017-06-26 11:43:24,506 Epoch[3] Batch [10]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.194998,	
2017-06-26 11:43:32,668 Epoch[3] Batch [20]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.215675,	
2017-06-26 11:43:40,771 Epoch[3] Batch [30]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.220828,	
2017-06-26 11:43:48,226 Epoch[3] Batch [40]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.219660,	
2017-06-26 11:43:55,820 Epoch[3] Batch [50]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.219164,	
2017-06-26 11:44:03,303 Epoch[3] Batch [60]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.219099,	
2017-06-26 11:44:10,812 Epoch[3] Batch [70]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.214136,	
2017-06-26 11:44:18,334 Epoch[3] Batch [80]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.205806,	
2017-06-26 11:44:25,638 Epoch[3] Batch [90]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.202034,	
2017-06-26 11:44:32,769 Epoch[3] Batch [100]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.201064,	
2017-06-26 11:44:40,366 Epoch[3] Batch [110]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.200863,	
2017-06-26 11:44:47,631 Epoch[3] Batch [120]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.199582,	
2017-06-26 11:44:54,658 Epoch[3] Batch [130]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.197889,	
2017-06-26 11:45:01,983 Epoch[3] Batch [140]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.196547,	
2017-06-26 11:45:09,373 Epoch[3] Batch [150]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.197207,	
2017-06-26 11:45:16,880 Epoch[3] Batch [160]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.195509,	
2017-06-26 11:45:24,262 Epoch[3] Batch [170]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.195562,	
2017-06-26 11:45:31,667 Epoch[3] Batch [180]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.200558,	
2017-06-26 11:45:39,805 Epoch[3] Batch [190]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.203958,	
2017-06-26 11:45:47,835 Epoch[3] Batch [200]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.206792,	
2017-06-26 11:45:54,925 Epoch[3] Batch [210]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.207939,	
2017-06-26 11:46:02,481 Epoch[3] Batch [220]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.207222,	
2017-06-26 11:46:10,448 Epoch[3] Batch [230]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.208849,	
2017-06-26 11:46:17,892 Epoch[3] Batch [240]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.211796,	
2017-06-26 11:46:25,414 Epoch[3] Batch [250]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.212567,	
2017-06-26 11:46:33,029 Epoch[3] Batch [260]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.214195,	
2017-06-26 11:46:40,871 Epoch[3] Batch [270]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.214078,	
2017-06-26 11:46:49,293 Epoch[3] Batch [280]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.213181,	
2017-06-26 11:46:56,273 Epoch[3] Batch [290]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.212330,	
2017-06-26 11:47:03,222 Epoch[3] Batch [300]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.211256,	
2017-06-26 11:47:10,405 Epoch[3] Batch [310]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.210757,	
2017-06-26 11:47:17,727 Epoch[3] Batch [320]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.209926,	
2017-06-26 11:47:24,896 Epoch[3] Batch [330]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.209369,	
2017-06-26 11:47:32,194 Epoch[3] Batch [340]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.210034,	
2017-06-26 11:47:40,103 Epoch[3] Batch [350]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.209466,	
2017-06-26 11:47:47,972 Epoch[3] Batch [360]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.209806,	
2017-06-26 11:47:55,471 Epoch[3] Batch [370]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.209477,	
2017-06-26 11:48:02,956 Epoch[3] Batch [380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.208955,	
2017-06-26 11:48:10,502 Epoch[3] Batch [390]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.209226,	
2017-06-26 11:48:18,303 Epoch[3] Batch [400]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.209522,	
2017-06-26 11:48:25,985 Epoch[3] Batch [410]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.209150,	
2017-06-26 11:48:33,440 Epoch[3] Batch [420]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.208813,	
2017-06-26 11:48:40,287 Epoch[3] Batch [430]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.208423,	
2017-06-26 11:48:46,257 Epoch[3] Batch [440]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.207524,	
2017-06-26 11:48:52,421 Epoch[3] Batch [450]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.207405,	
2017-06-26 11:48:58,499 Epoch[3] Batch [460]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.207309,	
2017-06-26 11:49:04,660 Epoch[3] Batch [470]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.207891,	
2017-06-26 11:49:10,755 Epoch[3] Batch [480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.207110,	
2017-06-26 11:49:16,890 Epoch[3] Batch [490]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.206582,	
2017-06-26 11:49:23,035 Epoch[3] Batch [500]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.205911,	
2017-06-26 11:49:29,130 Epoch[3] Batch [510]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.206224,	
2017-06-26 11:49:35,217 Epoch[3] Batch [520]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.206017,	
2017-06-26 11:49:41,308 Epoch[3] Batch [530]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.206210,	
2017-06-26 11:49:47,462 Epoch[3] Batch [540]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.205840,	
2017-06-26 11:49:53,563 Epoch[3] Batch [550]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.205849,	
2017-06-26 11:49:59,657 Epoch[3] Batch [560]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.205357,	
2017-06-26 11:50:05,779 Epoch[3] Batch [570]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.205535,	
2017-06-26 11:50:11,873 Epoch[3] Batch [580]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.205043,	
2017-06-26 11:50:17,987 Epoch[3] Batch [590]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.204673,	
2017-06-26 11:50:24,111 Epoch[3] Batch [600]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.204285,	
2017-06-26 11:50:30,238 Epoch[3] Batch [610]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.204105,	
2017-06-26 11:50:36,350 Epoch[3] Batch [620]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.204073,	
2017-06-26 11:50:42,442 Epoch[3] Batch [630]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.204330,	
2017-06-26 11:50:48,582 Epoch[3] Batch [640]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.204990,	
2017-06-26 11:50:54,718 Epoch[3] Batch [650]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.205028,	
2017-06-26 11:51:00,798 Epoch[3] Batch [660]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.205271,	
2017-06-26 11:51:07,234 Epoch[3] Batch [670]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.205562,	
2017-06-26 11:51:13,609 Epoch[3] Batch [680]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.205202,	
2017-06-26 11:51:19,749 Epoch[3] Batch [690]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.205106,	
2017-06-26 11:51:25,924 Epoch[3] Batch [700]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.204781,	
2017-06-26 11:51:32,016 Epoch[3] Batch [710]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.204313,	
2017-06-26 11:51:38,206 Epoch[3] Batch [720]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.204198,	
2017-06-26 11:51:44,343 Epoch[3] Batch [730]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.203924,	
2017-06-26 11:51:50,447 Epoch[3] Batch [740]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.204336,	
2017-06-26 11:51:56,495 Epoch[3] Batch [750]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.204679,	
2017-06-26 11:52:02,634 Epoch[3] Batch [760]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.204979,	
2017-06-26 11:52:08,739 Epoch[3] Batch [770]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.204452,	
2017-06-26 11:52:14,883 Epoch[3] Batch [780]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.204210,	
2017-06-26 11:52:20,919 Epoch[3] Batch [790]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.204274,	
2017-06-26 11:52:27,055 Epoch[3] Batch [800]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.204149,	
2017-06-26 11:52:33,139 Epoch[3] Batch [810]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.203850,	
2017-06-26 11:52:39,287 Epoch[3] Batch [820]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.203550,	
2017-06-26 11:52:45,400 Epoch[3] Batch [830]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.203072,	
2017-06-26 11:52:51,523 Epoch[3] Batch [840]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.202913,	
2017-06-26 11:52:57,628 Epoch[3] Batch [850]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.202978,	
2017-06-26 11:53:03,691 Epoch[3] Batch [860]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.202884,	
2017-06-26 11:53:09,783 Epoch[3] Batch [870]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.202570,	
2017-06-26 11:53:15,865 Epoch[3] Batch [880]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.202456,	
2017-06-26 11:53:21,976 Epoch[3] Batch [890]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.202429,	
2017-06-26 11:53:28,088 Epoch[3] Batch [900]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.202588,	
2017-06-26 11:53:34,213 Epoch[3] Batch [910]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.202353,	
2017-06-26 11:53:40,331 Epoch[3] Batch [920]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.202730,	
2017-06-26 11:53:46,476 Epoch[3] Batch [930]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.202822,	
2017-06-26 11:53:52,542 Epoch[3] Batch [940]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.202472,	
2017-06-26 11:53:58,676 Epoch[3] Batch [950]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.202143,	
2017-06-26 11:54:04,786 Epoch[3] Batch [960]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.201778,	
2017-06-26 11:54:10,873 Epoch[3] Batch [970]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.201701,	
2017-06-26 11:54:16,982 Epoch[3] Batch [980]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.201390,	
2017-06-26 11:54:23,096 Epoch[3] Batch [990]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.201282,	
2017-06-26 11:54:29,200 Epoch[3] Batch [1000]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.200947,	
2017-06-26 11:54:35,322 Epoch[3] Batch [1010]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.201014,	
2017-06-26 11:54:41,454 Epoch[3] Batch [1020]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.200653,	
2017-06-26 11:54:47,553 Epoch[3] Batch [1030]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.200587,	
2017-06-26 11:54:53,664 Epoch[3] Batch [1040]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.200224,	
2017-06-26 11:54:59,768 Epoch[3] Batch [1050]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.200194,	
2017-06-26 11:55:06,089 Epoch[3] Batch [1060]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.200072,	
2017-06-26 11:55:12,742 Epoch[3] Batch [1070]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.199777,	
2017-06-26 11:55:18,698 Epoch[3] Batch [1080]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.199632,	
2017-06-26 11:55:24,848 Epoch[3] Batch [1090]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.199606,	
2017-06-26 11:55:30,894 Epoch[3] Batch [1100]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.199968,	
2017-06-26 11:55:37,047 Epoch[3] Batch [1110]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.199990,	
2017-06-26 11:55:43,088 Epoch[3] Batch [1120]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.200181,	
2017-06-26 11:55:49,197 Epoch[3] Batch [1130]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.200053,	
2017-06-26 11:55:55,312 Epoch[3] Batch [1140]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.200035,	
2017-06-26 11:56:01,447 Epoch[3] Batch [1150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.200175,	
2017-06-26 11:56:07,542 Epoch[3] Batch [1160]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.200068,	
2017-06-26 11:56:13,673 Epoch[3] Batch [1170]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.199877,	
2017-06-26 11:56:19,717 Epoch[3] Batch [1180]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.199835,	
2017-06-26 11:56:25,825 Epoch[3] Batch [1190]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.199779,	
2017-06-26 11:56:31,950 Epoch[3] Batch [1200]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.199538,	
2017-06-26 11:56:38,095 Epoch[3] Batch [1210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.199795,	
2017-06-26 11:56:44,226 Epoch[3] Batch [1220]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.199758,	
2017-06-26 11:56:50,332 Epoch[3] Batch [1230]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.199608,	
2017-06-26 11:56:56,486 Epoch[3] Batch [1240]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.199372,	
2017-06-26 11:57:02,593 Epoch[3] Batch [1250]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.199514,	
2017-06-26 11:57:08,715 Epoch[3] Batch [1260]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.199308,	
2017-06-26 11:57:14,843 Epoch[3] Batch [1270]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.199174,	
2017-06-26 11:57:20,892 Epoch[3] Batch [1280]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.199204,	
2017-06-26 11:57:26,994 Epoch[3] Batch [1290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.198811,	
2017-06-26 11:57:33,069 Epoch[3] Batch [1300]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.198507,	
2017-06-26 11:57:39,173 Epoch[3] Batch [1310]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.198390,	
2017-06-26 11:57:45,257 Epoch[3] Batch [1320]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.198359,	
2017-06-26 11:57:51,364 Epoch[3] Batch [1330]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.198145,	
2017-06-26 11:57:57,487 Epoch[3] Batch [1340]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.198037,	
2017-06-26 11:58:03,547 Epoch[3] Batch [1350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.197972,	
2017-06-26 11:58:09,613 Epoch[3] Batch [1360]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.197794,	
2017-06-26 11:58:15,705 Epoch[3] Batch [1370]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.197718,	
2017-06-26 11:58:21,736 Epoch[3] Batch [1380]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.197754,	
2017-06-26 11:58:26,253 Epoch[3] Batch [1390]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.197663,	
2017-06-26 11:58:32,311 Epoch[3] Batch [1400]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.197771,	
2017-06-26 11:58:38,494 Epoch[3] Batch [1410]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.197628,	
2017-06-26 11:58:44,648 Epoch[3] Batch [1420]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.197697,	
2017-06-26 11:58:50,803 Epoch[3] Batch [1430]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.197549,	
2017-06-26 11:58:56,891 Epoch[3] Batch [1440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.197469,	
2017-06-26 11:59:03,157 Epoch[3] Batch [1450]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.197422,	
2017-06-26 11:59:09,824 Epoch[3] Batch [1460]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.197339,	
2017-06-26 11:59:15,897 Epoch[3] Batch [1470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.197281,	
2017-06-26 11:59:22,179 Epoch[3] Batch [1480]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.197157,	
2017-06-26 11:59:25,934 Epoch[3] Train-FCNLogLoss=0.197067
2017-06-26 11:59:25,935 Epoch[3] Time cost=970.507
2017-06-26 11:59:27,128 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0004.params"
2017-06-26 11:59:31,138 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0004.states"
2017-06-26 11:59:38,251 Epoch[4] Batch [10]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.179734,	
2017-06-26 11:59:44,324 Epoch[4] Batch [20]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.184610,	
2017-06-26 11:59:50,418 Epoch[4] Batch [30]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.184537,	
2017-06-26 11:59:56,496 Epoch[4] Batch [40]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.185421,	
2017-06-26 12:00:02,606 Epoch[4] Batch [50]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.185129,	
2017-06-26 12:00:08,672 Epoch[4] Batch [60]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.188368,	
2017-06-26 12:00:14,747 Epoch[4] Batch [70]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.187151,	
2017-06-26 12:00:20,887 Epoch[4] Batch [80]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.185182,	
2017-06-26 12:00:26,943 Epoch[4] Batch [90]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.188569,	
2017-06-26 12:00:33,030 Epoch[4] Batch [100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.187694,	
2017-06-26 12:00:39,213 Epoch[4] Batch [110]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.186051,	
2017-06-26 12:00:45,269 Epoch[4] Batch [120]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.186408,	
2017-06-26 12:00:51,367 Epoch[4] Batch [130]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.183904,	
2017-06-26 12:00:57,492 Epoch[4] Batch [140]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.182234,	
2017-06-26 12:01:03,639 Epoch[4] Batch [150]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.181773,	
2017-06-26 12:01:09,745 Epoch[4] Batch [160]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.180750,	
2017-06-26 12:01:15,875 Epoch[4] Batch [170]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.179851,	
2017-06-26 12:01:21,967 Epoch[4] Batch [180]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.178946,	
2017-06-26 12:01:28,070 Epoch[4] Batch [190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.177582,	
2017-06-26 12:01:34,195 Epoch[4] Batch [200]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.177362,	
2017-06-26 12:01:40,302 Epoch[4] Batch [210]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.176894,	
2017-06-26 12:01:46,373 Epoch[4] Batch [220]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.175669,	
2017-06-26 12:01:52,386 Epoch[4] Batch [230]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.175328,	
2017-06-26 12:01:58,511 Epoch[4] Batch [240]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.176840,	
2017-06-26 12:02:04,629 Epoch[4] Batch [250]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.177417,	
2017-06-26 12:02:10,719 Epoch[4] Batch [260]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.178083,	
2017-06-26 12:02:16,844 Epoch[4] Batch [270]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.177790,	
2017-06-26 12:02:22,941 Epoch[4] Batch [280]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.177767,	
2017-06-26 12:02:29,038 Epoch[4] Batch [290]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.177515,	
2017-06-26 12:02:35,170 Epoch[4] Batch [300]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.177768,	
2017-06-26 12:02:41,263 Epoch[4] Batch [310]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.177492,	
2017-06-26 12:02:47,360 Epoch[4] Batch [320]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.177057,	
2017-06-26 12:02:53,430 Epoch[4] Batch [330]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.177168,	
2017-06-26 12:03:00,192 Epoch[4] Batch [340]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.176687,	
2017-06-26 12:03:06,279 Epoch[4] Batch [350]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.177630,	
2017-06-26 12:03:12,403 Epoch[4] Batch [360]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.176981,	
2017-06-26 12:03:18,454 Epoch[4] Batch [370]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.176870,	
2017-06-26 12:03:24,523 Epoch[4] Batch [380]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.177445,	
2017-06-26 12:03:30,646 Epoch[4] Batch [390]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.177797,	
2017-06-26 12:03:36,687 Epoch[4] Batch [400]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.177333,	
2017-06-26 12:03:42,816 Epoch[4] Batch [410]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.177498,	
2017-06-26 12:03:49,046 Epoch[4] Batch [420]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.177819,	
2017-06-26 12:03:55,112 Epoch[4] Batch [430]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.177897,	
2017-06-26 12:04:01,232 Epoch[4] Batch [440]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.177952,	
2017-06-26 12:04:07,416 Epoch[4] Batch [450]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.178144,	
2017-06-26 12:04:13,536 Epoch[4] Batch [460]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.179067,	
2017-06-26 12:04:19,695 Epoch[4] Batch [470]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.178838,	
2017-06-26 12:04:25,801 Epoch[4] Batch [480]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.178919,	
2017-06-26 12:04:31,929 Epoch[4] Batch [490]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.178687,	
2017-06-26 12:04:38,061 Epoch[4] Batch [500]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.178688,	
2017-06-26 12:04:44,203 Epoch[4] Batch [510]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.178906,	
2017-06-26 12:04:50,327 Epoch[4] Batch [520]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.178750,	
2017-06-26 12:04:56,475 Epoch[4] Batch [530]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.179624,	
2017-06-26 12:05:02,550 Epoch[4] Batch [540]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.180529,	
2017-06-26 12:05:08,671 Epoch[4] Batch [550]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.181694,	
2017-06-26 12:05:14,799 Epoch[4] Batch [560]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.182251,	
2017-06-26 12:05:20,896 Epoch[4] Batch [570]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.181698,	
2017-06-26 12:05:27,080 Epoch[4] Batch [580]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.181524,	
2017-06-26 12:05:33,151 Epoch[4] Batch [590]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.181390,	
2017-06-26 12:05:39,207 Epoch[4] Batch [600]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.181011,	
2017-06-26 12:05:45,454 Epoch[4] Batch [610]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.180276,	
2017-06-26 12:05:51,465 Epoch[4] Batch [620]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.180176,	
2017-06-26 12:05:57,636 Epoch[4] Batch [630]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.179961,	
2017-06-26 12:06:03,658 Epoch[4] Batch [640]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.180335,	
2017-06-26 12:06:09,735 Epoch[4] Batch [650]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.180100,	
2017-06-26 12:06:15,958 Epoch[4] Batch [660]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.179784,	
2017-06-26 12:06:22,041 Epoch[4] Batch [670]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.180030,	
2017-06-26 12:06:28,063 Epoch[4] Batch [680]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.180511,	
2017-06-26 12:06:34,183 Epoch[4] Batch [690]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.180408,	
2017-06-26 12:06:40,247 Epoch[4] Batch [700]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.180210,	
2017-06-26 12:06:46,365 Epoch[4] Batch [710]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.180147,	
2017-06-26 12:06:52,412 Epoch[4] Batch [720]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.180416,	
2017-06-26 12:06:58,742 Epoch[4] Batch [730]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.180174,	
2017-06-26 12:07:05,402 Epoch[4] Batch [740]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.180271,	
2017-06-26 12:07:11,331 Epoch[4] Batch [750]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.179822,	
2017-06-26 12:07:17,426 Epoch[4] Batch [760]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.179491,	
2017-06-26 12:07:23,543 Epoch[4] Batch [770]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.179531,	
2017-06-26 12:07:29,651 Epoch[4] Batch [780]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.179300,	
2017-06-26 12:07:35,822 Epoch[4] Batch [790]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.178755,	
2017-06-26 12:07:41,933 Epoch[4] Batch [800]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.178480,	
2017-06-26 12:07:48,017 Epoch[4] Batch [810]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.179001,	
2017-06-26 12:07:54,158 Epoch[4] Batch [820]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.179507,	
2017-06-26 12:08:00,239 Epoch[4] Batch [830]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.179699,	
2017-06-26 12:08:06,285 Epoch[4] Batch [840]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.179837,	
2017-06-26 12:08:12,453 Epoch[4] Batch [850]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.180225,	
2017-06-26 12:08:18,590 Epoch[4] Batch [860]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.180310,	
2017-06-26 12:08:24,735 Epoch[4] Batch [870]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.180443,	
2017-06-26 12:08:30,766 Epoch[4] Batch [880]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.180400,	
2017-06-26 12:08:36,907 Epoch[4] Batch [890]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.180020,	
2017-06-26 12:08:42,929 Epoch[4] Batch [900]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.180092,	
2017-06-26 12:08:49,072 Epoch[4] Batch [910]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.180228,	
2017-06-26 12:08:55,179 Epoch[4] Batch [920]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.180537,	
2017-06-26 12:09:01,259 Epoch[4] Batch [930]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.180661,	
2017-06-26 12:09:07,421 Epoch[4] Batch [940]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.180839,	
2017-06-26 12:09:13,583 Epoch[4] Batch [950]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.180692,	
2017-06-26 12:09:19,617 Epoch[4] Batch [960]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.180725,	
2017-06-26 12:09:25,741 Epoch[4] Batch [970]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.180825,	
2017-06-26 12:09:31,898 Epoch[4] Batch [980]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.180837,	
2017-06-26 12:09:37,943 Epoch[4] Batch [990]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.180690,	
2017-06-26 12:09:44,071 Epoch[4] Batch [1000]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.180689,	
2017-06-26 12:09:50,206 Epoch[4] Batch [1010]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.180620,	
2017-06-26 12:09:56,237 Epoch[4] Batch [1020]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.180396,	
2017-06-26 12:10:02,360 Epoch[4] Batch [1030]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.180302,	
2017-06-26 12:10:08,499 Epoch[4] Batch [1040]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.180177,	
2017-06-26 12:10:14,685 Epoch[4] Batch [1050]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.180024,	
2017-06-26 12:10:20,638 Epoch[4] Batch [1060]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.180128,	
2017-06-26 12:10:26,740 Epoch[4] Batch [1070]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.179990,	
2017-06-26 12:10:32,887 Epoch[4] Batch [1080]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.179766,	
2017-06-26 12:10:39,026 Epoch[4] Batch [1090]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.179777,	
2017-06-26 12:10:45,027 Epoch[4] Batch [1100]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.179671,	
2017-06-26 12:10:51,193 Epoch[4] Batch [1110]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.179364,	
2017-06-26 12:10:57,146 Epoch[4] Batch [1120]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.179434,	
2017-06-26 12:11:03,899 Epoch[4] Batch [1130]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.179268,	
2017-06-26 12:11:10,190 Epoch[4] Batch [1140]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.179065,	
2017-06-26 12:11:16,320 Epoch[4] Batch [1150]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.178953,	
2017-06-26 12:11:22,447 Epoch[4] Batch [1160]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.178774,	
2017-06-26 12:11:28,595 Epoch[4] Batch [1170]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.178743,	
2017-06-26 12:11:34,630 Epoch[4] Batch [1180]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.178670,	
2017-06-26 12:11:40,769 Epoch[4] Batch [1190]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.178647,	
2017-06-26 12:11:46,878 Epoch[4] Batch [1200]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.178740,	
2017-06-26 12:11:53,009 Epoch[4] Batch [1210]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.178468,	
2017-06-26 12:11:59,103 Epoch[4] Batch [1220]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.178537,	
2017-06-26 12:12:05,201 Epoch[4] Batch [1230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.178754,	
2017-06-26 12:12:11,314 Epoch[4] Batch [1240]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.178854,	
2017-06-26 12:12:17,459 Epoch[4] Batch [1250]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.178892,	
2017-06-26 12:12:23,552 Epoch[4] Batch [1260]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.178901,	
2017-06-26 12:12:29,710 Epoch[4] Batch [1270]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.178754,	
2017-06-26 12:12:35,788 Epoch[4] Batch [1280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.178670,	
2017-06-26 12:12:41,868 Epoch[4] Batch [1290]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.178518,	
2017-06-26 12:12:47,985 Epoch[4] Batch [1300]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.178375,	
2017-06-26 12:12:54,123 Epoch[4] Batch [1310]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.178119,	
2017-06-26 12:13:00,196 Epoch[4] Batch [1320]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.178001,	
2017-06-26 12:13:06,350 Epoch[4] Batch [1330]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.177783,	
2017-06-26 12:13:12,386 Epoch[4] Batch [1340]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.177869,	
2017-06-26 12:13:18,523 Epoch[4] Batch [1350]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.177908,	
2017-06-26 12:13:24,616 Epoch[4] Batch [1360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.177876,	
2017-06-26 12:13:30,764 Epoch[4] Batch [1370]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.177635,	
2017-06-26 12:13:36,420 Epoch[4] Batch [1380]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.177604,	
2017-06-26 12:13:42,114 Epoch[4] Batch [1390]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.177668,	
2017-06-26 12:13:48,130 Epoch[4] Batch [1400]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.177611,	
2017-06-26 12:13:54,274 Epoch[4] Batch [1410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.177601,	
2017-06-26 12:14:00,392 Epoch[4] Batch [1420]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.177514,	
2017-06-26 12:14:06,483 Epoch[4] Batch [1430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.177495,	
2017-06-26 12:14:12,547 Epoch[4] Batch [1440]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.177652,	
2017-06-26 12:14:18,696 Epoch[4] Batch [1450]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.177604,	
2017-06-26 12:14:24,741 Epoch[4] Batch [1460]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.177605,	
2017-06-26 12:14:30,823 Epoch[4] Batch [1470]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.177499,	
2017-06-26 12:14:36,935 Epoch[4] Batch [1480]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.177421,	
2017-06-26 12:14:40,613 Epoch[4] Train-FCNLogLoss=0.177528
2017-06-26 12:14:40,613 Epoch[4] Time cost=909.474
2017-06-26 12:14:41,710 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0005.params"
2017-06-26 12:14:45,462 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0005.states"
2017-06-26 12:14:52,684 Epoch[5] Batch [10]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.174228,	
2017-06-26 12:14:58,987 Epoch[5] Batch [20]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.175412,	
2017-06-26 12:15:05,055 Epoch[5] Batch [30]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.163870,	
2017-06-26 12:15:11,168 Epoch[5] Batch [40]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.170103,	
2017-06-26 12:15:17,218 Epoch[5] Batch [50]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.168788,	
2017-06-26 12:15:23,327 Epoch[5] Batch [60]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.168332,	
2017-06-26 12:15:29,416 Epoch[5] Batch [70]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.168392,	
2017-06-26 12:15:35,563 Epoch[5] Batch [80]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.168484,	
2017-06-26 12:15:41,684 Epoch[5] Batch [90]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.171527,	
2017-06-26 12:15:47,808 Epoch[5] Batch [100]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.174364,	
2017-06-26 12:15:53,963 Epoch[5] Batch [110]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.173559,	
2017-06-26 12:16:00,035 Epoch[5] Batch [120]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.175074,	
2017-06-26 12:16:06,139 Epoch[5] Batch [130]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.172768,	
2017-06-26 12:16:12,328 Epoch[5] Batch [140]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.170957,	
2017-06-26 12:16:18,356 Epoch[5] Batch [150]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.169687,	
2017-06-26 12:16:24,493 Epoch[5] Batch [160]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.169659,	
2017-06-26 12:16:30,552 Epoch[5] Batch [170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.170153,	
2017-06-26 12:16:36,648 Epoch[5] Batch [180]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.170156,	
2017-06-26 12:16:42,726 Epoch[5] Batch [190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.171293,	
2017-06-26 12:16:48,834 Epoch[5] Batch [200]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.171719,	
2017-06-26 12:16:54,979 Epoch[5] Batch [210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.171347,	
2017-06-26 12:17:01,021 Epoch[5] Batch [220]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.171474,	
2017-06-26 12:17:07,180 Epoch[5] Batch [230]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.171044,	
2017-06-26 12:17:13,185 Epoch[5] Batch [240]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.171231,	
2017-06-26 12:17:19,322 Epoch[5] Batch [250]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.170749,	
2017-06-26 12:17:25,501 Epoch[5] Batch [260]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.170414,	
2017-06-26 12:17:31,610 Epoch[5] Batch [270]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.171262,	
2017-06-26 12:17:37,751 Epoch[5] Batch [280]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.171028,	
2017-06-26 12:17:43,924 Epoch[5] Batch [290]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.170672,	
2017-06-26 12:17:49,957 Epoch[5] Batch [300]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.169929,	
2017-06-26 12:17:56,071 Epoch[5] Batch [310]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.168952,	
2017-06-26 12:18:02,170 Epoch[5] Batch [320]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.168686,	
2017-06-26 12:18:08,339 Epoch[5] Batch [330]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.168389,	
2017-06-26 12:18:14,403 Epoch[5] Batch [340]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.167824,	
2017-06-26 12:18:20,524 Epoch[5] Batch [350]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.167347,	
2017-06-26 12:18:26,703 Epoch[5] Batch [360]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.166706,	
2017-06-26 12:18:32,767 Epoch[5] Batch [370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.166744,	
2017-06-26 12:18:38,869 Epoch[5] Batch [380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.166480,	
2017-06-26 12:18:44,977 Epoch[5] Batch [390]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166207,	
2017-06-26 12:18:51,101 Epoch[5] Batch [400]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.166535,	
2017-06-26 12:18:57,652 Epoch[5] Batch [410]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.166619,	
2017-06-26 12:19:03,898 Epoch[5] Batch [420]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.166219,	
2017-06-26 12:19:09,996 Epoch[5] Batch [430]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.166163,	
2017-06-26 12:19:16,104 Epoch[5] Batch [440]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165830,	
2017-06-26 12:19:22,267 Epoch[5] Batch [450]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.165700,	
2017-06-26 12:19:28,394 Epoch[5] Batch [460]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165745,	
2017-06-26 12:19:34,436 Epoch[5] Batch [470]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.166108,	
2017-06-26 12:19:40,521 Epoch[5] Batch [480]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166128,	
2017-06-26 12:19:46,604 Epoch[5] Batch [490]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.166625,	
2017-06-26 12:19:52,737 Epoch[5] Batch [500]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.166906,	
2017-06-26 12:19:58,864 Epoch[5] Batch [510]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.167226,	
2017-06-26 12:20:04,914 Epoch[5] Batch [520]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.167182,	
2017-06-26 12:20:11,030 Epoch[5] Batch [530]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.167471,	
2017-06-26 12:20:17,202 Epoch[5] Batch [540]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.167856,	
2017-06-26 12:20:23,246 Epoch[5] Batch [550]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.167845,	
2017-06-26 12:20:29,343 Epoch[5] Batch [560]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.167409,	
2017-06-26 12:20:35,424 Epoch[5] Batch [570]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.167579,	
2017-06-26 12:20:41,414 Epoch[5] Batch [580]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.167599,	
2017-06-26 12:20:47,539 Epoch[5] Batch [590]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.167621,	
2017-06-26 12:20:53,611 Epoch[5] Batch [600]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.167542,	
2017-06-26 12:20:59,715 Epoch[5] Batch [610]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.167269,	
2017-06-26 12:21:05,956 Epoch[5] Batch [620]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.167051,	
2017-06-26 12:21:11,925 Epoch[5] Batch [630]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.166777,	
2017-06-26 12:21:17,977 Epoch[5] Batch [640]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.166516,	
2017-06-26 12:21:24,117 Epoch[5] Batch [650]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.166531,	
2017-06-26 12:21:30,232 Epoch[5] Batch [660]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.166461,	
2017-06-26 12:21:36,358 Epoch[5] Batch [670]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165878,	
2017-06-26 12:21:42,476 Epoch[5] Batch [680]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.165766,	
2017-06-26 12:21:48,572 Epoch[5] Batch [690]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.165721,	
2017-06-26 12:21:54,709 Epoch[5] Batch [700]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.165660,	
2017-06-26 12:22:00,830 Epoch[5] Batch [710]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.165874,	
2017-06-26 12:22:06,919 Epoch[5] Batch [720]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.165930,	
2017-06-26 12:22:13,032 Epoch[5] Batch [730]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.166069,	
2017-06-26 12:22:19,099 Epoch[5] Batch [740]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.165875,	
2017-06-26 12:22:25,237 Epoch[5] Batch [750]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.165587,	
2017-06-26 12:22:31,343 Epoch[5] Batch [760]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165324,	
2017-06-26 12:22:37,465 Epoch[5] Batch [770]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165762,	
2017-06-26 12:22:43,500 Epoch[5] Batch [780]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.166104,	
2017-06-26 12:22:49,517 Epoch[5] Batch [790]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.166344,	
2017-06-26 12:22:55,514 Epoch[5] Batch [800]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.166390,	
2017-06-26 12:23:02,165 Epoch[5] Batch [810]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.166367,	
2017-06-26 12:23:08,425 Epoch[5] Batch [820]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.166295,	
2017-06-26 12:23:14,509 Epoch[5] Batch [830]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.166548,	
2017-06-26 12:23:20,640 Epoch[5] Batch [840]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.166711,	
2017-06-26 12:23:26,761 Epoch[5] Batch [850]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.166437,	
2017-06-26 12:23:32,833 Epoch[5] Batch [860]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.166289,	
2017-06-26 12:23:39,000 Epoch[5] Batch [870]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.166227,	
2017-06-26 12:23:45,069 Epoch[5] Batch [880]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.166230,	
2017-06-26 12:23:51,129 Epoch[5] Batch [890]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.166553,	
2017-06-26 12:23:57,216 Epoch[5] Batch [900]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166710,	
2017-06-26 12:24:03,464 Epoch[5] Batch [910]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.166695,	
2017-06-26 12:24:09,563 Epoch[5] Batch [920]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.166575,	
2017-06-26 12:24:15,624 Epoch[5] Batch [930]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.166770,	
2017-06-26 12:24:21,716 Epoch[5] Batch [940]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166984,	
2017-06-26 12:24:27,853 Epoch[5] Batch [950]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.167153,	
2017-06-26 12:24:33,958 Epoch[5] Batch [960]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.167109,	
2017-06-26 12:24:40,092 Epoch[5] Batch [970]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.166954,	
2017-06-26 12:24:46,212 Epoch[5] Batch [980]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.166923,	
2017-06-26 12:24:52,386 Epoch[5] Batch [990]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.166765,	
2017-06-26 12:24:58,458 Epoch[5] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.166766,	
2017-06-26 12:25:04,563 Epoch[5] Batch [1010]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166720,	
2017-06-26 12:25:10,672 Epoch[5] Batch [1020]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166876,	
2017-06-26 12:25:16,787 Epoch[5] Batch [1030]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.166669,	
2017-06-26 12:25:22,923 Epoch[5] Batch [1040]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.166493,	
2017-06-26 12:25:29,115 Epoch[5] Batch [1050]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.166377,	
2017-06-26 12:25:35,164 Epoch[5] Batch [1060]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.166387,	
2017-06-26 12:25:41,256 Epoch[5] Batch [1070]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166397,	
2017-06-26 12:25:47,408 Epoch[5] Batch [1080]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.166575,	
2017-06-26 12:25:53,464 Epoch[5] Batch [1090]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.166508,	
2017-06-26 12:25:59,507 Epoch[5] Batch [1100]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.166559,	
2017-06-26 12:26:05,595 Epoch[5] Batch [1110]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166427,	
2017-06-26 12:26:11,684 Epoch[5] Batch [1120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166520,	
2017-06-26 12:26:17,765 Epoch[5] Batch [1130]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.166354,	
2017-06-26 12:26:23,851 Epoch[5] Batch [1140]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166295,	
2017-06-26 12:26:29,999 Epoch[5] Batch [1150]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.166278,	
2017-06-26 12:26:36,139 Epoch[5] Batch [1160]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.166143,	
2017-06-26 12:26:42,250 Epoch[5] Batch [1170]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166058,	
2017-06-26 12:26:48,376 Epoch[5] Batch [1180]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165951,	
2017-06-26 12:26:54,438 Epoch[5] Batch [1190]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.165804,	
2017-06-26 12:27:00,494 Epoch[5] Batch [1200]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.165616,	
2017-06-26 12:27:07,119 Epoch[5] Batch [1210]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.165526,	
2017-06-26 12:27:13,355 Epoch[5] Batch [1220]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.165364,	
2017-06-26 12:27:19,440 Epoch[5] Batch [1230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.165265,	
2017-06-26 12:27:25,668 Epoch[5] Batch [1240]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.165324,	
2017-06-26 12:27:32,446 Epoch[5] Batch [1250]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.165129,	
2017-06-26 12:27:38,492 Epoch[5] Batch [1260]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.165170,	
2017-06-26 12:27:44,579 Epoch[5] Batch [1270]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.165037,	
2017-06-26 12:27:50,689 Epoch[5] Batch [1280]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164877,	
2017-06-26 12:27:56,794 Epoch[5] Batch [1290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165105,	
2017-06-26 12:28:02,916 Epoch[5] Batch [1300]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165160,	
2017-06-26 12:28:09,221 Epoch[5] Batch [1310]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.165533,	
2017-06-26 12:28:15,213 Epoch[5] Batch [1320]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.166176,	
2017-06-26 12:28:21,687 Epoch[5] Batch [1330]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.166544,	
2017-06-26 12:28:28,482 Epoch[5] Batch [1340]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.166742,	
2017-06-26 12:28:34,992 Epoch[5] Batch [1350]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.166873,	
2017-06-26 12:28:41,083 Epoch[5] Batch [1360]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166939,	
2017-06-26 12:28:46,960 Epoch[5] Batch [1370]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.166898,	
2017-06-26 12:28:52,463 Epoch[5] Batch [1380]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.167005,	
2017-06-26 12:28:58,573 Epoch[5] Batch [1390]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166876,	
2017-06-26 12:29:04,747 Epoch[5] Batch [1400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.166825,	
2017-06-26 12:29:10,866 Epoch[5] Batch [1410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.166864,	
2017-06-26 12:29:16,974 Epoch[5] Batch [1420]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166845,	
2017-06-26 12:29:23,099 Epoch[5] Batch [1430]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.167034,	
2017-06-26 12:29:29,379 Epoch[5] Batch [1440]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.166945,	
2017-06-26 12:29:35,346 Epoch[5] Batch [1450]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.166981,	
2017-06-26 12:29:41,644 Epoch[5] Batch [1460]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.167379,	
2017-06-26 12:29:47,815 Epoch[5] Batch [1470]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.167531,	
2017-06-26 12:29:53,927 Epoch[5] Batch [1480]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.167732,	
2017-06-26 12:29:57,572 Epoch[5] Train-FCNLogLoss=0.167678
2017-06-26 12:29:57,572 Epoch[5] Time cost=912.110
2017-06-26 12:29:58,964 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0006.params"
2017-06-26 12:30:02,692 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0006.states"
2017-06-26 12:30:09,532 Epoch[6] Batch [10]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.175697,	
2017-06-26 12:30:15,591 Epoch[6] Batch [20]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.167876,	
2017-06-26 12:30:21,737 Epoch[6] Batch [30]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.172291,	
2017-06-26 12:30:27,956 Epoch[6] Batch [40]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.169765,	
2017-06-26 12:30:34,373 Epoch[6] Batch [50]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.168051,	
2017-06-26 12:30:40,421 Epoch[6] Batch [60]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.167729,	
2017-06-26 12:30:46,738 Epoch[6] Batch [70]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.167001,	
2017-06-26 12:30:53,358 Epoch[6] Batch [80]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.169142,	
2017-06-26 12:30:59,341 Epoch[6] Batch [90]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.169090,	
2017-06-26 12:31:05,427 Epoch[6] Batch [100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.167469,	
2017-06-26 12:31:11,623 Epoch[6] Batch [110]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.166331,	
2017-06-26 12:31:17,713 Epoch[6] Batch [120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166052,	
2017-06-26 12:31:23,828 Epoch[6] Batch [130]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.169669,	
2017-06-26 12:31:30,124 Epoch[6] Batch [140]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.170602,	
2017-06-26 12:31:36,189 Epoch[6] Batch [150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.169788,	
2017-06-26 12:31:42,234 Epoch[6] Batch [160]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.169445,	
2017-06-26 12:31:48,414 Epoch[6] Batch [170]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.168284,	
2017-06-26 12:31:54,790 Epoch[6] Batch [180]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.167710,	
2017-06-26 12:32:00,820 Epoch[6] Batch [190]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.167008,	
2017-06-26 12:32:06,911 Epoch[6] Batch [200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166659,	
2017-06-26 12:32:12,996 Epoch[6] Batch [210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.166717,	
2017-06-26 12:32:19,601 Epoch[6] Batch [220]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.166836,	
2017-06-26 12:32:26,350 Epoch[6] Batch [230]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.166879,	
2017-06-26 12:32:32,855 Epoch[6] Batch [240]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.166939,	
2017-06-26 12:32:38,964 Epoch[6] Batch [250]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166943,	
2017-06-26 12:32:45,364 Epoch[6] Batch [260]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.165909,	
2017-06-26 12:32:51,478 Epoch[6] Batch [270]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.165303,	
2017-06-26 12:32:57,599 Epoch[6] Batch [280]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.164499,	
2017-06-26 12:33:03,579 Epoch[6] Batch [290]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.164216,	
2017-06-26 12:33:09,734 Epoch[6] Batch [300]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.163524,	
2017-06-26 12:33:15,846 Epoch[6] Batch [310]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.163420,	
2017-06-26 12:33:21,853 Epoch[6] Batch [320]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.163344,	
2017-06-26 12:33:27,941 Epoch[6] Batch [330]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.163714,	
2017-06-26 12:33:34,069 Epoch[6] Batch [340]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.163966,	
2017-06-26 12:33:40,105 Epoch[6] Batch [350]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.164871,	
2017-06-26 12:33:46,207 Epoch[6] Batch [360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.165024,	
2017-06-26 12:33:52,349 Epoch[6] Batch [370]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.165168,	
2017-06-26 12:33:58,419 Epoch[6] Batch [380]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.165604,	
2017-06-26 12:34:04,845 Epoch[6] Batch [390]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.166063,	
2017-06-26 12:34:10,913 Epoch[6] Batch [400]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.165822,	
2017-06-26 12:34:17,030 Epoch[6] Batch [410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.166224,	
2017-06-26 12:34:23,192 Epoch[6] Batch [420]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.166251,	
2017-06-26 12:34:29,267 Epoch[6] Batch [430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.166148,	
2017-06-26 12:34:35,324 Epoch[6] Batch [440]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.165998,	
2017-06-26 12:34:41,506 Epoch[6] Batch [450]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.165752,	
2017-06-26 12:34:47,690 Epoch[6] Batch [460]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.165711,	
2017-06-26 12:34:54,375 Epoch[6] Batch [470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.165177,	
2017-06-26 12:35:00,333 Epoch[6] Batch [480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.164831,	
2017-06-26 12:35:06,526 Epoch[6] Batch [490]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.164581,	
2017-06-26 12:35:12,723 Epoch[6] Batch [500]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.164571,	
2017-06-26 12:35:19,201 Epoch[6] Batch [510]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.164647,	
2017-06-26 12:35:25,757 Epoch[6] Batch [520]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.164611,	
2017-06-26 12:35:32,523 Epoch[6] Batch [530]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.164339,	
2017-06-26 12:35:38,630 Epoch[6] Batch [540]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164464,	
2017-06-26 12:35:44,738 Epoch[6] Batch [550]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164501,	
2017-06-26 12:35:50,948 Epoch[6] Batch [560]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.164126,	
2017-06-26 12:35:57,580 Epoch[6] Batch [570]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.164494,	
2017-06-26 12:36:04,068 Epoch[6] Batch [580]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.163941,	
2017-06-26 12:36:10,452 Epoch[6] Batch [590]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.164086,	
2017-06-26 12:36:16,766 Epoch[6] Batch [600]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.164066,	
2017-06-26 12:36:22,831 Epoch[6] Batch [610]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.164495,	
2017-06-26 12:36:28,960 Epoch[6] Batch [620]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.164507,	
2017-06-26 12:36:35,251 Epoch[6] Batch [630]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.164809,	
2017-06-26 12:36:41,690 Epoch[6] Batch [640]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.165163,	
2017-06-26 12:36:48,076 Epoch[6] Batch [650]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.165303,	
2017-06-26 12:36:54,227 Epoch[6] Batch [660]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.165365,	
2017-06-26 12:37:00,633 Epoch[6] Batch [670]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.165201,	
2017-06-26 12:37:06,689 Epoch[6] Batch [680]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.165512,	
2017-06-26 12:37:12,800 Epoch[6] Batch [690]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165477,	
2017-06-26 12:37:18,904 Epoch[6] Batch [700]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165654,	
2017-06-26 12:37:24,964 Epoch[6] Batch [710]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.165875,	
2017-06-26 12:37:31,116 Epoch[6] Batch [720]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.165475,	
2017-06-26 12:37:37,190 Epoch[6] Batch [730]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.165487,	
2017-06-26 12:37:43,358 Epoch[6] Batch [740]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.165477,	
2017-06-26 12:37:49,648 Epoch[6] Batch [750]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.165240,	
2017-06-26 12:37:55,946 Epoch[6] Batch [760]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.165320,	
2017-06-26 12:38:02,771 Epoch[6] Batch [770]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.165023,	
2017-06-26 12:38:09,113 Epoch[6] Batch [780]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.165103,	
2017-06-26 12:38:15,451 Epoch[6] Batch [790]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.165055,	
2017-06-26 12:38:21,916 Epoch[6] Batch [800]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.164930,	
2017-06-26 12:38:28,357 Epoch[6] Batch [810]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.164987,	
2017-06-26 12:38:35,008 Epoch[6] Batch [820]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.164942,	
2017-06-26 12:38:41,788 Epoch[6] Batch [830]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.164838,	
2017-06-26 12:38:48,345 Epoch[6] Batch [840]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.164979,	
2017-06-26 12:38:54,539 Epoch[6] Batch [850]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.164843,	
2017-06-26 12:39:00,641 Epoch[6] Batch [860]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.164730,	
2017-06-26 12:39:06,752 Epoch[6] Batch [870]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164430,	
2017-06-26 12:39:12,833 Epoch[6] Batch [880]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.164250,	
2017-06-26 12:39:18,965 Epoch[6] Batch [890]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.164323,	
2017-06-26 12:39:25,091 Epoch[6] Batch [900]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.164183,	
2017-06-26 12:39:31,563 Epoch[6] Batch [910]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.164099,	
2017-06-26 12:39:37,651 Epoch[6] Batch [920]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.163969,	
2017-06-26 12:39:43,742 Epoch[6] Batch [930]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.163859,	
2017-06-26 12:39:50,148 Epoch[6] Batch [940]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.163976,	
2017-06-26 12:39:56,486 Epoch[6] Batch [950]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.164149,	
2017-06-26 12:40:03,250 Epoch[6] Batch [960]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.163850,	
2017-06-26 12:40:09,995 Epoch[6] Batch [970]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.163784,	
2017-06-26 12:40:16,171 Epoch[6] Batch [980]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.163587,	
2017-06-26 12:40:22,364 Epoch[6] Batch [990]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.163512,	
2017-06-26 12:40:28,627 Epoch[6] Batch [1000]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.163432,	
2017-06-26 12:40:34,942 Epoch[6] Batch [1010]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.163216,	
2017-06-26 12:40:41,680 Epoch[6] Batch [1020]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.163158,	
2017-06-26 12:40:47,947 Epoch[6] Batch [1030]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.163035,	
2017-06-26 12:40:54,781 Epoch[6] Batch [1040]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.162898,	
2017-06-26 12:41:01,642 Epoch[6] Batch [1050]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.162849,	
2017-06-26 12:41:08,351 Epoch[6] Batch [1060]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.162785,	
2017-06-26 12:41:14,854 Epoch[6] Batch [1070]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.162821,	
2017-06-26 12:41:21,531 Epoch[6] Batch [1080]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.163126,	
2017-06-26 12:41:27,826 Epoch[6] Batch [1090]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.163110,	
2017-06-26 12:41:34,135 Epoch[6] Batch [1100]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.163083,	
2017-06-26 12:41:40,282 Epoch[6] Batch [1110]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.163003,	
2017-06-26 12:41:46,441 Epoch[6] Batch [1120]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.162937,	
2017-06-26 12:41:52,440 Epoch[6] Batch [1130]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.162703,	
2017-06-26 12:41:58,650 Epoch[6] Batch [1140]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.162577,	
2017-06-26 12:42:04,709 Epoch[6] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.162398,	
2017-06-26 12:42:10,825 Epoch[6] Batch [1160]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.162165,	
2017-06-26 12:42:17,011 Epoch[6] Batch [1170]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.162212,	
2017-06-26 12:42:23,114 Epoch[6] Batch [1180]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.162211,	
2017-06-26 12:42:29,119 Epoch[6] Batch [1190]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.162275,	
2017-06-26 12:42:35,302 Epoch[6] Batch [1200]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.162464,	
2017-06-26 12:42:41,693 Epoch[6] Batch [1210]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.162531,	
2017-06-26 12:42:48,175 Epoch[6] Batch [1220]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.162495,	
2017-06-26 12:42:54,245 Epoch[6] Batch [1230]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.162657,	
2017-06-26 12:43:00,440 Epoch[6] Batch [1240]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.162621,	
2017-06-26 12:43:07,263 Epoch[6] Batch [1250]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.162539,	
2017-06-26 12:43:13,689 Epoch[6] Batch [1260]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.162821,	
2017-06-26 12:43:19,733 Epoch[6] Batch [1270]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.162845,	
2017-06-26 12:43:25,920 Epoch[6] Batch [1280]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.162615,	
2017-06-26 12:43:32,047 Epoch[6] Batch [1290]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.162867,	
2017-06-26 12:43:38,202 Epoch[6] Batch [1300]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.162860,	
2017-06-26 12:43:44,885 Epoch[6] Batch [1310]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.162782,	
2017-06-26 12:43:51,432 Epoch[6] Batch [1320]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.162808,	
2017-06-26 12:43:58,546 Epoch[6] Batch [1330]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.162800,	
2017-06-26 12:44:05,772 Epoch[6] Batch [1340]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.162804,	
2017-06-26 12:44:12,968 Epoch[6] Batch [1350]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.163001,	
2017-06-26 12:44:20,015 Epoch[6] Batch [1360]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.163001,	
2017-06-26 12:44:27,335 Epoch[6] Batch [1370]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.163031,	
2017-06-26 12:44:33,403 Epoch[6] Batch [1380]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.163041,	
2017-06-26 12:44:39,517 Epoch[6] Batch [1390]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.163009,	
2017-06-26 12:44:45,503 Epoch[6] Batch [1400]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.163029,	
2017-06-26 12:44:51,599 Epoch[6] Batch [1410]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.162961,	
2017-06-26 12:44:57,699 Epoch[6] Batch [1420]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.163048,	
2017-06-26 12:45:03,778 Epoch[6] Batch [1430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.162910,	
2017-06-26 12:45:09,885 Epoch[6] Batch [1440]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.162985,	
2017-06-26 12:45:15,913 Epoch[6] Batch [1450]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.162970,	
2017-06-26 12:45:22,001 Epoch[6] Batch [1460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.162853,	
2017-06-26 12:45:28,229 Epoch[6] Batch [1470]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.162840,	
2017-06-26 12:45:34,380 Epoch[6] Batch [1480]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.162725,	
2017-06-26 12:45:38,151 Epoch[6] Train-FCNLogLoss=0.162657
2017-06-26 12:45:38,151 Epoch[6] Time cost=935.459
2017-06-26 12:45:39,418 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0007.params"
2017-06-26 12:45:43,322 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0007.states"
2017-06-26 12:45:50,673 Epoch[7] Batch [10]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.138240,	
2017-06-26 12:45:57,474 Epoch[7] Batch [20]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.143503,	
2017-06-26 12:46:03,620 Epoch[7] Batch [30]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.149259,	
2017-06-26 12:46:09,698 Epoch[7] Batch [40]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.153188,	
2017-06-26 12:46:15,798 Epoch[7] Batch [50]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155428,	
2017-06-26 12:46:22,459 Epoch[7] Batch [60]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.156383,	
2017-06-26 12:46:28,666 Epoch[7] Batch [70]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.157507,	
2017-06-26 12:46:34,781 Epoch[7] Batch [80]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.156698,	
2017-06-26 12:46:40,934 Epoch[7] Batch [90]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.159044,	
2017-06-26 12:46:47,078 Epoch[7] Batch [100]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.158349,	
2017-06-26 12:46:53,408 Epoch[7] Batch [110]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.160345,	
2017-06-26 12:46:59,576 Epoch[7] Batch [120]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.159313,	
2017-06-26 12:47:05,590 Epoch[7] Batch [130]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.158139,	
2017-06-26 12:47:11,679 Epoch[7] Batch [140]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.159964,	
2017-06-26 12:47:17,850 Epoch[7] Batch [150]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.159831,	
2017-06-26 12:47:23,937 Epoch[7] Batch [160]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.160580,	
2017-06-26 12:47:30,139 Epoch[7] Batch [170]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.160047,	
2017-06-26 12:47:36,205 Epoch[7] Batch [180]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.158592,	
2017-06-26 12:47:42,220 Epoch[7] Batch [190]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.158537,	
2017-06-26 12:47:48,415 Epoch[7] Batch [200]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.158463,	
2017-06-26 12:47:54,464 Epoch[7] Batch [210]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.157453,	
2017-06-26 12:48:00,567 Epoch[7] Batch [220]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.156754,	
2017-06-26 12:48:06,593 Epoch[7] Batch [230]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.156639,	
2017-06-26 12:48:12,808 Epoch[7] Batch [240]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.156874,	
2017-06-26 12:48:18,864 Epoch[7] Batch [250]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.157143,	
2017-06-26 12:48:24,919 Epoch[7] Batch [260]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.156922,	
2017-06-26 12:48:30,960 Epoch[7] Batch [270]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.156120,	
2017-06-26 12:48:37,093 Epoch[7] Batch [280]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.156188,	
2017-06-26 12:48:43,217 Epoch[7] Batch [290]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.156627,	
2017-06-26 12:48:49,276 Epoch[7] Batch [300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.156938,	
2017-06-26 12:48:55,475 Epoch[7] Batch [310]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.157005,	
2017-06-26 12:49:01,501 Epoch[7] Batch [320]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.157272,	
2017-06-26 12:49:07,648 Epoch[7] Batch [330]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.157583,	
2017-06-26 12:49:13,660 Epoch[7] Batch [340]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.157764,	
2017-06-26 12:49:19,905 Epoch[7] Batch [350]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.157402,	
2017-06-26 12:49:26,069 Epoch[7] Batch [360]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.157362,	
2017-06-26 12:49:32,213 Epoch[7] Batch [370]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.157450,	
2017-06-26 12:49:38,239 Epoch[7] Batch [380]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.156913,	
2017-06-26 12:49:44,482 Epoch[7] Batch [390]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.157144,	
2017-06-26 12:49:50,588 Epoch[7] Batch [400]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.156896,	
2017-06-26 12:49:56,758 Epoch[7] Batch [410]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.156966,	
2017-06-26 12:50:02,830 Epoch[7] Batch [420]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.156911,	
2017-06-26 12:50:08,892 Epoch[7] Batch [430]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.156832,	
2017-06-26 12:50:15,031 Epoch[7] Batch [440]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.156889,	
2017-06-26 12:50:21,277 Epoch[7] Batch [450]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.157168,	
2017-06-26 12:50:27,889 Epoch[7] Batch [460]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.157002,	
2017-06-26 12:50:33,919 Epoch[7] Batch [470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.156793,	
2017-06-26 12:50:40,049 Epoch[7] Batch [480]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.157026,	
2017-06-26 12:50:46,463 Epoch[7] Batch [490]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.157169,	
2017-06-26 12:50:52,599 Epoch[7] Batch [500]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.157125,	
2017-06-26 12:50:58,763 Epoch[7] Batch [510]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.157117,	
2017-06-26 12:51:05,181 Epoch[7] Batch [520]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.157045,	
2017-06-26 12:51:11,716 Epoch[7] Batch [530]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.157470,	
2017-06-26 12:51:17,739 Epoch[7] Batch [540]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.157368,	
2017-06-26 12:51:23,903 Epoch[7] Batch [550]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.156880,	
2017-06-26 12:51:29,878 Epoch[7] Batch [560]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.156983,	
2017-06-26 12:51:35,952 Epoch[7] Batch [570]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.157099,	
2017-06-26 12:51:42,171 Epoch[7] Batch [580]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.157174,	
2017-06-26 12:51:48,336 Epoch[7] Batch [590]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.156936,	
2017-06-26 12:51:54,498 Epoch[7] Batch [600]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.157150,	
2017-06-26 12:52:00,559 Epoch[7] Batch [610]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.157011,	
2017-06-26 12:52:06,733 Epoch[7] Batch [620]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.156833,	
2017-06-26 12:52:12,852 Epoch[7] Batch [630]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.156613,	
2017-06-26 12:52:19,027 Epoch[7] Batch [640]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.156753,	
2017-06-26 12:52:25,219 Epoch[7] Batch [650]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.156491,	
2017-06-26 12:52:31,293 Epoch[7] Batch [660]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.156263,	
2017-06-26 12:52:37,449 Epoch[7] Batch [670]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.156231,	
2017-06-26 12:52:43,663 Epoch[7] Batch [680]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.156259,	
2017-06-26 12:52:50,392 Epoch[7] Batch [690]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.156043,	
2017-06-26 12:52:57,132 Epoch[7] Batch [700]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.155905,	
2017-06-26 12:53:04,294 Epoch[7] Batch [710]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.155631,	
2017-06-26 12:53:10,830 Epoch[7] Batch [720]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.155703,	
2017-06-26 12:53:17,387 Epoch[7] Batch [730]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.155709,	
2017-06-26 12:53:23,974 Epoch[7] Batch [740]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.155911,	
2017-06-26 12:53:30,372 Epoch[7] Batch [750]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.156216,	
2017-06-26 12:53:36,782 Epoch[7] Batch [760]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.156365,	
2017-06-26 12:53:42,972 Epoch[7] Batch [770]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.156301,	
2017-06-26 12:53:49,349 Epoch[7] Batch [780]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.156330,	
2017-06-26 12:53:55,469 Epoch[7] Batch [790]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.156125,	
2017-06-26 12:54:01,734 Epoch[7] Batch [800]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.156082,	
2017-06-26 12:54:07,982 Epoch[7] Batch [810]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.156121,	
2017-06-26 12:54:14,093 Epoch[7] Batch [820]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.156166,	
2017-06-26 12:54:20,417 Epoch[7] Batch [830]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.156247,	
2017-06-26 12:54:27,040 Epoch[7] Batch [840]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.156190,	
2017-06-26 12:54:33,129 Epoch[7] Batch [850]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.156192,	
2017-06-26 12:54:39,522 Epoch[7] Batch [860]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.156183,	
2017-06-26 12:54:46,559 Epoch[7] Batch [870]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.156328,	
2017-06-26 12:54:53,116 Epoch[7] Batch [880]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.156232,	
2017-06-26 12:55:00,230 Epoch[7] Batch [890]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.155924,	
2017-06-26 12:55:06,339 Epoch[7] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.155854,	
2017-06-26 12:55:12,450 Epoch[7] Batch [910]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.155478,	
2017-06-26 12:55:18,517 Epoch[7] Batch [920]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.155390,	
2017-06-26 12:55:24,600 Epoch[7] Batch [930]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.155233,	
2017-06-26 12:55:30,684 Epoch[7] Batch [940]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.155112,	
2017-06-26 12:55:36,815 Epoch[7] Batch [950]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.155068,	
2017-06-26 12:55:42,887 Epoch[7] Batch [960]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.155009,	
2017-06-26 12:55:48,982 Epoch[7] Batch [970]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155257,	
2017-06-26 12:55:55,090 Epoch[7] Batch [980]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.155428,	
2017-06-26 12:56:01,191 Epoch[7] Batch [990]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155319,	
2017-06-26 12:56:07,325 Epoch[7] Batch [1000]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.155209,	
2017-06-26 12:56:13,380 Epoch[7] Batch [1010]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.154943,	
2017-06-26 12:56:19,501 Epoch[7] Batch [1020]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.155057,	
2017-06-26 12:56:25,533 Epoch[7] Batch [1030]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.155145,	
2017-06-26 12:56:31,635 Epoch[7] Batch [1040]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155146,	
2017-06-26 12:56:37,711 Epoch[7] Batch [1050]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.154989,	
2017-06-26 12:56:43,813 Epoch[7] Batch [1060]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155062,	
2017-06-26 12:56:49,982 Epoch[7] Batch [1070]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.154852,	
2017-06-26 12:56:56,015 Epoch[7] Batch [1080]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.154790,	
2017-06-26 12:57:02,163 Epoch[7] Batch [1090]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.154839,	
2017-06-26 12:57:08,290 Epoch[7] Batch [1100]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.154920,	
2017-06-26 12:57:14,467 Epoch[7] Batch [1110]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.154954,	
2017-06-26 12:57:20,835 Epoch[7] Batch [1120]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.155063,	
2017-06-26 12:57:27,408 Epoch[7] Batch [1130]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.154934,	
2017-06-26 12:57:33,916 Epoch[7] Batch [1140]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.154899,	
2017-06-26 12:57:40,083 Epoch[7] Batch [1150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.154990,	
2017-06-26 12:57:46,422 Epoch[7] Batch [1160]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.154851,	
2017-06-26 12:57:52,607 Epoch[7] Batch [1170]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.154844,	
2017-06-26 12:57:58,783 Epoch[7] Batch [1180]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.154772,	
2017-06-26 12:58:05,621 Epoch[7] Batch [1190]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.154857,	
2017-06-26 12:58:12,383 Epoch[7] Batch [1200]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.154652,	
2017-06-26 12:58:18,794 Epoch[7] Batch [1210]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.154730,	
2017-06-26 12:58:25,293 Epoch[7] Batch [1220]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.154736,	
2017-06-26 12:58:31,433 Epoch[7] Batch [1230]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.154733,	
2017-06-26 12:58:37,535 Epoch[7] Batch [1240]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.154797,	
2017-06-26 12:58:43,925 Epoch[7] Batch [1250]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.154877,	
2017-06-26 12:58:49,950 Epoch[7] Batch [1260]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.154806,	
2017-06-26 12:58:56,139 Epoch[7] Batch [1270]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.154734,	
2017-06-26 12:59:02,315 Epoch[7] Batch [1280]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.154731,	
2017-06-26 12:59:08,654 Epoch[7] Batch [1290]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.154586,	
2017-06-26 12:59:15,214 Epoch[7] Batch [1300]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.154584,	
2017-06-26 12:59:21,384 Epoch[7] Batch [1310]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.154563,	
2017-06-26 12:59:27,474 Epoch[7] Batch [1320]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.154526,	
2017-06-26 12:59:33,991 Epoch[7] Batch [1330]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.154673,	
2017-06-26 12:59:40,275 Epoch[7] Batch [1340]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.154763,	
2017-06-26 12:59:47,061 Epoch[7] Batch [1350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.154670,	
2017-06-26 12:59:53,284 Epoch[7] Batch [1360]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.154796,	
2017-06-26 12:59:59,508 Epoch[7] Batch [1370]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.154716,	
2017-06-26 13:00:05,628 Epoch[7] Batch [1380]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.154587,	
2017-06-26 13:00:11,673 Epoch[7] Batch [1390]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.154554,	
2017-06-26 13:00:17,766 Epoch[7] Batch [1400]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.154588,	
2017-06-26 13:00:23,885 Epoch[7] Batch [1410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.154584,	
2017-06-26 13:00:29,964 Epoch[7] Batch [1420]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.154517,	
2017-06-26 13:00:36,095 Epoch[7] Batch [1430]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.154506,	
2017-06-26 13:00:42,328 Epoch[7] Batch [1440]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.154503,	
2017-06-26 13:00:48,418 Epoch[7] Batch [1450]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.154436,	
2017-06-26 13:00:54,883 Epoch[7] Batch [1460]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.154558,	
2017-06-26 13:01:01,363 Epoch[7] Batch [1470]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.154438,	
2017-06-26 13:01:07,879 Epoch[7] Batch [1480]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.154376,	
2017-06-26 13:01:11,762 Epoch[7] Train-FCNLogLoss=0.154486
2017-06-26 13:01:11,762 Epoch[7] Time cost=928.439
2017-06-26 13:01:12,921 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0008.params"
2017-06-26 13:01:16,839 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0008.states"
2017-06-26 13:01:24,841 Epoch[8] Batch [10]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.137888,	
2017-06-26 13:01:31,257 Epoch[8] Batch [20]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.143839,	
2017-06-26 13:01:37,423 Epoch[8] Batch [30]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.144313,	
2017-06-26 13:01:43,572 Epoch[8] Batch [40]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.142946,	
2017-06-26 13:01:49,759 Epoch[8] Batch [50]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.145859,	
2017-06-26 13:01:55,700 Epoch[8] Batch [60]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.144607,	
2017-06-26 13:02:02,262 Epoch[8] Batch [70]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.148044,	
2017-06-26 13:02:08,513 Epoch[8] Batch [80]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.148708,	
2017-06-26 13:02:15,043 Epoch[8] Batch [90]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.148260,	
2017-06-26 13:02:21,575 Epoch[8] Batch [100]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.149875,	
2017-06-26 13:02:27,855 Epoch[8] Batch [110]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.152946,	
2017-06-26 13:02:34,050 Epoch[8] Batch [120]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.153247,	
2017-06-26 13:02:40,483 Epoch[8] Batch [130]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.151058,	
2017-06-26 13:02:46,576 Epoch[8] Batch [140]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.151102,	
2017-06-26 13:02:52,724 Epoch[8] Batch [150]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.156590,	
2017-06-26 13:02:59,256 Epoch[8] Batch [160]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.158756,	
2017-06-26 13:03:05,398 Epoch[8] Batch [170]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.159963,	
2017-06-26 13:03:11,795 Epoch[8] Batch [180]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.160172,	
2017-06-26 13:03:18,312 Epoch[8] Batch [190]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.158948,	
2017-06-26 13:03:24,756 Epoch[8] Batch [200]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.158749,	
2017-06-26 13:03:31,235 Epoch[8] Batch [210]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.158367,	
2017-06-26 13:03:37,637 Epoch[8] Batch [220]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.157883,	
2017-06-26 13:03:43,796 Epoch[8] Batch [230]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.158079,	
2017-06-26 13:03:49,896 Epoch[8] Batch [240]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.157377,	
2017-06-26 13:03:55,980 Epoch[8] Batch [250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.157378,	
2017-06-26 13:04:02,092 Epoch[8] Batch [260]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.158826,	
2017-06-26 13:04:08,190 Epoch[8] Batch [270]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.158853,	
2017-06-26 13:04:14,350 Epoch[8] Batch [280]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.158404,	
2017-06-26 13:04:20,719 Epoch[8] Batch [290]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.158512,	
2017-06-26 13:04:26,807 Epoch[8] Batch [300]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.158414,	
2017-06-26 13:04:32,877 Epoch[8] Batch [310]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.157402,	
2017-06-26 13:04:39,040 Epoch[8] Batch [320]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.157181,	
2017-06-26 13:04:45,099 Epoch[8] Batch [330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.156488,	
2017-06-26 13:04:51,247 Epoch[8] Batch [340]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.156151,	
2017-06-26 13:04:57,309 Epoch[8] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.155574,	
2017-06-26 13:05:03,407 Epoch[8] Batch [360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155311,	
2017-06-26 13:05:09,571 Epoch[8] Batch [370]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.155654,	
2017-06-26 13:05:15,673 Epoch[8] Batch [380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155421,	
2017-06-26 13:05:21,775 Epoch[8] Batch [390]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155530,	
2017-06-26 13:05:27,814 Epoch[8] Batch [400]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.155364,	
2017-06-26 13:05:33,963 Epoch[8] Batch [410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.154889,	
2017-06-26 13:05:40,172 Epoch[8] Batch [420]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.154374,	
2017-06-26 13:05:46,171 Epoch[8] Batch [430]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.154295,	
2017-06-26 13:05:52,337 Epoch[8] Batch [440]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.153913,	
2017-06-26 13:05:58,498 Epoch[8] Batch [450]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.153584,	
2017-06-26 13:06:05,145 Epoch[8] Batch [460]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.153655,	
2017-06-26 13:06:11,157 Epoch[8] Batch [470]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.153921,	
2017-06-26 13:06:17,384 Epoch[8] Batch [480]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.153930,	
2017-06-26 13:06:23,370 Epoch[8] Batch [490]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.154038,	
2017-06-26 13:06:29,626 Epoch[8] Batch [500]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.153775,	
2017-06-26 13:06:36,791 Epoch[8] Batch [510]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.153470,	
2017-06-26 13:06:43,631 Epoch[8] Batch [520]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.153312,	
2017-06-26 13:06:49,773 Epoch[8] Batch [530]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.153090,	
2017-06-26 13:06:55,880 Epoch[8] Batch [540]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.152841,	
2017-06-26 13:07:01,986 Epoch[8] Batch [550]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.152559,	
2017-06-26 13:07:08,185 Epoch[8] Batch [560]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.152828,	
2017-06-26 13:07:14,218 Epoch[8] Batch [570]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.153096,	
2017-06-26 13:07:20,350 Epoch[8] Batch [580]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.153082,	
2017-06-26 13:07:26,434 Epoch[8] Batch [590]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.153052,	
2017-06-26 13:07:32,568 Epoch[8] Batch [600]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.152902,	
2017-06-26 13:07:38,654 Epoch[8] Batch [610]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.152945,	
2017-06-26 13:07:45,227 Epoch[8] Batch [620]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.153145,	
2017-06-26 13:07:51,674 Epoch[8] Batch [630]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.153045,	
2017-06-26 13:07:57,827 Epoch[8] Batch [640]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.152900,	
2017-06-26 13:08:04,413 Epoch[8] Batch [650]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.152537,	
2017-06-26 13:08:10,519 Epoch[8] Batch [660]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.152445,	
2017-06-26 13:08:16,572 Epoch[8] Batch [670]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.152517,	
2017-06-26 13:08:22,593 Epoch[8] Batch [680]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.152670,	
2017-06-26 13:08:28,665 Epoch[8] Batch [690]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.152382,	
2017-06-26 13:08:34,732 Epoch[8] Batch [700]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.152087,	
2017-06-26 13:08:40,840 Epoch[8] Batch [710]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.152153,	
2017-06-26 13:08:47,025 Epoch[8] Batch [720]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.152075,	
2017-06-26 13:08:53,190 Epoch[8] Batch [730]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.151784,	
2017-06-26 13:08:59,330 Epoch[8] Batch [740]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.151812,	
2017-06-26 13:09:05,405 Epoch[8] Batch [750]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.151702,	
2017-06-26 13:09:11,879 Epoch[8] Batch [760]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.151570,	
2017-06-26 13:09:17,902 Epoch[8] Batch [770]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.151511,	
2017-06-26 13:09:23,945 Epoch[8] Batch [780]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.151571,	
2017-06-26 13:09:30,046 Epoch[8] Batch [790]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.151458,	
2017-06-26 13:09:36,140 Epoch[8] Batch [800]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.151284,	
2017-06-26 13:09:42,219 Epoch[8] Batch [810]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.150911,	
2017-06-26 13:09:48,425 Epoch[8] Batch [820]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.150922,	
2017-06-26 13:09:54,366 Epoch[8] Batch [830]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.150808,	
2017-06-26 13:10:01,017 Epoch[8] Batch [840]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.150646,	
2017-06-26 13:10:07,367 Epoch[8] Batch [850]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.150689,	
2017-06-26 13:10:13,332 Epoch[8] Batch [860]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.150687,	
2017-06-26 13:10:19,563 Epoch[8] Batch [870]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.150435,	
2017-06-26 13:10:26,351 Epoch[8] Batch [880]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.150638,	
2017-06-26 13:10:32,762 Epoch[8] Batch [890]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.150648,	
2017-06-26 13:10:39,313 Epoch[8] Batch [900]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.150487,	
2017-06-26 13:10:45,374 Epoch[8] Batch [910]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.150483,	
2017-06-26 13:10:51,453 Epoch[8] Batch [920]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.150354,	
2017-06-26 13:10:57,870 Epoch[8] Batch [930]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.150293,	
2017-06-26 13:11:03,928 Epoch[8] Batch [940]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.150311,	
2017-06-26 13:11:10,053 Epoch[8] Batch [950]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.150015,	
2017-06-26 13:11:16,135 Epoch[8] Batch [960]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.150191,	
2017-06-26 13:11:22,252 Epoch[8] Batch [970]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.150237,	
2017-06-26 13:11:28,351 Epoch[8] Batch [980]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.150008,	
2017-06-26 13:11:34,413 Epoch[8] Batch [990]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.149826,	
2017-06-26 13:11:40,548 Epoch[8] Batch [1000]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.149788,	
2017-06-26 13:11:46,633 Epoch[8] Batch [1010]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.149741,	
2017-06-26 13:11:52,805 Epoch[8] Batch [1020]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.149656,	
2017-06-26 13:11:58,975 Epoch[8] Batch [1030]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.149649,	
2017-06-26 13:12:05,837 Epoch[8] Batch [1040]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.149596,	
2017-06-26 13:12:12,064 Epoch[8] Batch [1050]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.149498,	
2017-06-26 13:12:18,574 Epoch[8] Batch [1060]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.149435,	
2017-06-26 13:12:25,417 Epoch[8] Batch [1070]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.149359,	
2017-06-26 13:12:31,527 Epoch[8] Batch [1080]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.149456,	
2017-06-26 13:12:37,640 Epoch[8] Batch [1090]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.149371,	
2017-06-26 13:12:43,770 Epoch[8] Batch [1100]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.149500,	
2017-06-26 13:12:49,955 Epoch[8] Batch [1110]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.149280,	
2017-06-26 13:12:56,329 Epoch[8] Batch [1120]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.149194,	
2017-06-26 13:13:02,818 Epoch[8] Batch [1130]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.149058,	
2017-06-26 13:13:09,313 Epoch[8] Batch [1140]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.148972,	
2017-06-26 13:13:15,744 Epoch[8] Batch [1150]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.149048,	
2017-06-26 13:13:21,726 Epoch[8] Batch [1160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.149348,	
2017-06-26 13:13:27,859 Epoch[8] Batch [1170]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.149332,	
2017-06-26 13:13:33,982 Epoch[8] Batch [1180]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.149308,	
2017-06-26 13:13:40,085 Epoch[8] Batch [1190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.149214,	
2017-06-26 13:13:45,917 Epoch[8] Batch [1200]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.149269,	
2017-06-26 13:13:51,975 Epoch[8] Batch [1210]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.149106,	
2017-06-26 13:13:58,672 Epoch[8] Batch [1220]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.149125,	
2017-06-26 13:14:04,648 Epoch[8] Batch [1230]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.149037,	
2017-06-26 13:14:10,692 Epoch[8] Batch [1240]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.149024,	
2017-06-26 13:14:16,777 Epoch[8] Batch [1250]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.148998,	
2017-06-26 13:14:22,918 Epoch[8] Batch [1260]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.148855,	
2017-06-26 13:14:29,009 Epoch[8] Batch [1270]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.148872,	
2017-06-26 13:14:35,716 Epoch[8] Batch [1280]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.149124,	
2017-06-26 13:14:41,721 Epoch[8] Batch [1290]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.149063,	
2017-06-26 13:14:47,918 Epoch[8] Batch [1300]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.149259,	
2017-06-26 13:14:53,886 Epoch[8] Batch [1310]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.149186,	
2017-06-26 13:14:59,964 Epoch[8] Batch [1320]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.149255,	
2017-06-26 13:15:06,112 Epoch[8] Batch [1330]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.149244,	
2017-06-26 13:15:12,184 Epoch[8] Batch [1340]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.149227,	
2017-06-26 13:15:18,262 Epoch[8] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.149361,	
2017-06-26 13:15:24,373 Epoch[8] Batch [1360]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.149208,	
2017-06-26 13:15:30,491 Epoch[8] Batch [1370]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.148995,	
2017-06-26 13:15:36,621 Epoch[8] Batch [1380]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.148839,	
2017-06-26 13:15:42,964 Epoch[8] Batch [1390]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.148767,	
2017-06-26 13:15:49,112 Epoch[8] Batch [1400]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.148716,	
2017-06-26 13:15:55,196 Epoch[8] Batch [1410]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.148573,	
2017-06-26 13:16:01,300 Epoch[8] Batch [1420]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.148508,	
2017-06-26 13:16:07,518 Epoch[8] Batch [1430]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.148398,	
2017-06-26 13:16:13,696 Epoch[8] Batch [1440]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.148498,	
2017-06-26 13:16:20,045 Epoch[8] Batch [1450]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.148339,	
2017-06-26 13:16:26,575 Epoch[8] Batch [1460]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.148355,	
2017-06-26 13:16:32,630 Epoch[8] Batch [1470]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.148355,	
2017-06-26 13:16:38,686 Epoch[8] Batch [1480]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.148712,	
2017-06-26 13:16:42,403 Epoch[8] Train-FCNLogLoss=0.148651
2017-06-26 13:16:42,404 Epoch[8] Time cost=925.564
2017-06-26 13:16:43,829 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0009.params"
2017-06-26 13:16:47,764 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0009.states"
2017-06-26 13:16:54,886 Epoch[9] Batch [10]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.144075,	
2017-06-26 13:17:01,424 Epoch[9] Batch [20]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.144586,	
2017-06-26 13:17:07,547 Epoch[9] Batch [30]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.143433,	
2017-06-26 13:17:13,642 Epoch[9] Batch [40]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.145184,	
2017-06-26 13:17:19,784 Epoch[9] Batch [50]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.144761,	
2017-06-26 13:17:25,869 Epoch[9] Batch [60]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.141978,	
2017-06-26 13:17:32,254 Epoch[9] Batch [70]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.142562,	
2017-06-26 13:17:38,481 Epoch[9] Batch [80]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.141664,	
2017-06-26 13:17:45,133 Epoch[9] Batch [90]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.142683,	
2017-06-26 13:17:51,260 Epoch[9] Batch [100]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.142139,	
2017-06-26 13:17:57,660 Epoch[9] Batch [110]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.140872,	
2017-06-26 13:18:04,148 Epoch[9] Batch [120]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.141619,	
2017-06-26 13:18:10,644 Epoch[9] Batch [130]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.143177,	
2017-06-26 13:18:17,085 Epoch[9] Batch [140]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.142358,	
2017-06-26 13:18:23,951 Epoch[9] Batch [150]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.142753,	
2017-06-26 13:18:30,946 Epoch[9] Batch [160]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.142500,	
2017-06-26 13:18:37,621 Epoch[9] Batch [170]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.142473,	
2017-06-26 13:18:44,570 Epoch[9] Batch [180]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.141226,	
2017-06-26 13:18:51,028 Epoch[9] Batch [190]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.140723,	
2017-06-26 13:18:57,966 Epoch[9] Batch [200]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.141078,	
2017-06-26 13:19:04,368 Epoch[9] Batch [210]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.141851,	
2017-06-26 13:19:10,432 Epoch[9] Batch [220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.141957,	
2017-06-26 13:19:16,529 Epoch[9] Batch [230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.141526,	
2017-06-26 13:19:22,600 Epoch[9] Batch [240]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.141311,	
2017-06-26 13:19:28,820 Epoch[9] Batch [250]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.140345,	
2017-06-26 13:19:35,217 Epoch[9] Batch [260]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.140323,	
2017-06-26 13:19:41,357 Epoch[9] Batch [270]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.139848,	
2017-06-26 13:19:47,527 Epoch[9] Batch [280]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.140087,	
2017-06-26 13:19:53,581 Epoch[9] Batch [290]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.140256,	
2017-06-26 13:19:59,732 Epoch[9] Batch [300]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.140927,	
2017-06-26 13:20:05,899 Epoch[9] Batch [310]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.140810,	
2017-06-26 13:20:11,969 Epoch[9] Batch [320]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.140679,	
2017-06-26 13:20:18,933 Epoch[9] Batch [330]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.140950,	
2017-06-26 13:20:26,094 Epoch[9] Batch [340]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.141848,	
2017-06-26 13:20:32,922 Epoch[9] Batch [350]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.141874,	
2017-06-26 13:20:39,648 Epoch[9] Batch [360]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.141878,	
2017-06-26 13:20:45,916 Epoch[9] Batch [370]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.142074,	
2017-06-26 13:20:52,073 Epoch[9] Batch [380]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.142512,	
2017-06-26 13:20:58,134 Epoch[9] Batch [390]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.142225,	
2017-06-26 13:21:04,549 Epoch[9] Batch [400]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.142258,	
2017-06-26 13:21:10,708 Epoch[9] Batch [410]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.142125,	
2017-06-26 13:21:16,836 Epoch[9] Batch [420]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.141994,	
2017-06-26 13:21:23,537 Epoch[9] Batch [430]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.142092,	
2017-06-26 13:21:30,556 Epoch[9] Batch [440]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.142511,	
2017-06-26 13:21:37,158 Epoch[9] Batch [450]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.142606,	
2017-06-26 13:21:43,208 Epoch[9] Batch [460]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.142671,	
2017-06-26 13:21:49,240 Epoch[9] Batch [470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.142621,	
2017-06-26 13:21:55,303 Epoch[9] Batch [480]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.142245,	
2017-06-26 13:22:01,434 Epoch[9] Batch [490]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.141953,	
2017-06-26 13:22:07,601 Epoch[9] Batch [500]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.141646,	
2017-06-26 13:22:13,806 Epoch[9] Batch [510]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.141300,	
2017-06-26 13:22:19,941 Epoch[9] Batch [520]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.141152,	
2017-06-26 13:22:26,291 Epoch[9] Batch [530]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.141165,	
2017-06-26 13:22:32,452 Epoch[9] Batch [540]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.141012,	
2017-06-26 13:22:38,612 Epoch[9] Batch [550]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.140969,	
2017-06-26 13:22:44,727 Epoch[9] Batch [560]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.140634,	
2017-06-26 13:22:50,827 Epoch[9] Batch [570]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.141094,	
2017-06-26 13:22:56,942 Epoch[9] Batch [580]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.140857,	
2017-06-26 13:23:03,072 Epoch[9] Batch [590]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.140657,	
2017-06-26 13:23:09,169 Epoch[9] Batch [600]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.140660,	
2017-06-26 13:23:15,369 Epoch[9] Batch [610]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.140572,	
2017-06-26 13:23:21,468 Epoch[9] Batch [620]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.140719,	
2017-06-26 13:23:27,479 Epoch[9] Batch [630]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.141360,	
2017-06-26 13:23:33,597 Epoch[9] Batch [640]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.141477,	
2017-06-26 13:23:40,438 Epoch[9] Batch [650]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.141456,	
2017-06-26 13:23:47,030 Epoch[9] Batch [660]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.141675,	
2017-06-26 13:23:53,358 Epoch[9] Batch [670]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.141753,	
2017-06-26 13:23:59,875 Epoch[9] Batch [680]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.141821,	
2017-06-26 13:24:06,372 Epoch[9] Batch [690]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.142164,	
2017-06-26 13:24:13,333 Epoch[9] Batch [700]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.142424,	
2017-06-26 13:24:19,966 Epoch[9] Batch [710]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.142473,	
2017-06-26 13:24:27,129 Epoch[9] Batch [720]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.142273,	
2017-06-26 13:24:33,630 Epoch[9] Batch [730]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.142074,	
2017-06-26 13:24:40,195 Epoch[9] Batch [740]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.142054,	
2017-06-26 13:24:46,628 Epoch[9] Batch [750]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.141904,	
2017-06-26 13:24:53,095 Epoch[9] Batch [760]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.141903,	
2017-06-26 13:24:59,094 Epoch[9] Batch [770]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.141725,	
2017-06-26 13:25:05,181 Epoch[9] Batch [780]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.141670,	
2017-06-26 13:25:11,275 Epoch[9] Batch [790]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.141456,	
2017-06-26 13:25:17,332 Epoch[9] Batch [800]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.141325,	
2017-06-26 13:25:23,448 Epoch[9] Batch [810]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.141285,	
2017-06-26 13:25:29,698 Epoch[9] Batch [820]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.141277,	
2017-06-26 13:25:36,379 Epoch[9] Batch [830]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.141172,	
2017-06-26 13:25:42,294 Epoch[9] Batch [840]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.141306,	
2017-06-26 13:25:48,412 Epoch[9] Batch [850]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.141275,	
2017-06-26 13:25:54,574 Epoch[9] Batch [860]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.141055,	
2017-06-26 13:26:00,656 Epoch[9] Batch [870]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.140970,	
2017-06-26 13:26:06,836 Epoch[9] Batch [880]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.141017,	
2017-06-26 13:26:13,003 Epoch[9] Batch [890]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.140953,	
2017-06-26 13:26:19,064 Epoch[9] Batch [900]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.141388,	
2017-06-26 13:26:25,503 Epoch[9] Batch [910]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.141191,	
2017-06-26 13:26:31,678 Epoch[9] Batch [920]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.141152,	
2017-06-26 13:26:37,745 Epoch[9] Batch [930]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.141115,	
2017-06-26 13:26:43,795 Epoch[9] Batch [940]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.141084,	
2017-06-26 13:26:49,903 Epoch[9] Batch [950]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.141168,	
2017-06-26 13:26:56,396 Epoch[9] Batch [960]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.141274,	
2017-06-26 13:27:03,715 Epoch[9] Batch [970]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.141451,	
2017-06-26 13:27:10,539 Epoch[9] Batch [980]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.141541,	
2017-06-26 13:27:18,024 Epoch[9] Batch [990]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.141605,	
2017-06-26 13:27:24,862 Epoch[9] Batch [1000]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.141612,	
2017-06-26 13:27:31,612 Epoch[9] Batch [1010]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.141593,	
2017-06-26 13:27:38,189 Epoch[9] Batch [1020]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.141506,	
2017-06-26 13:27:44,937 Epoch[9] Batch [1030]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.141443,	
2017-06-26 13:27:51,750 Epoch[9] Batch [1040]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.141538,	
2017-06-26 13:27:58,215 Epoch[9] Batch [1050]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.141511,	
2017-06-26 13:28:04,451 Epoch[9] Batch [1060]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.141535,	
2017-06-26 13:28:11,350 Epoch[9] Batch [1070]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.141582,	
2017-06-26 13:28:18,723 Epoch[9] Batch [1080]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.141587,	
2017-06-26 13:28:25,168 Epoch[9] Batch [1090]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.141486,	
2017-06-26 13:28:31,663 Epoch[9] Batch [1100]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.141406,	
2017-06-26 13:28:37,841 Epoch[9] Batch [1110]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.141492,	
2017-06-26 13:28:43,784 Epoch[9] Batch [1120]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.141474,	
2017-06-26 13:28:49,897 Epoch[9] Batch [1130]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.141592,	
2017-06-26 13:28:56,033 Epoch[9] Batch [1140]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.141691,	
2017-06-26 13:29:02,840 Epoch[9] Batch [1150]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.141647,	
2017-06-26 13:29:09,349 Epoch[9] Batch [1160]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.141640,	
2017-06-26 13:29:15,662 Epoch[9] Batch [1170]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.141800,	
2017-06-26 13:29:22,199 Epoch[9] Batch [1180]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.141854,	
2017-06-26 13:29:28,261 Epoch[9] Batch [1190]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.141646,	
2017-06-26 13:29:34,418 Epoch[9] Batch [1200]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.141676,	
2017-06-26 13:29:40,531 Epoch[9] Batch [1210]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.141633,	
2017-06-26 13:29:46,582 Epoch[9] Batch [1220]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.141701,	
2017-06-26 13:29:52,967 Epoch[9] Batch [1230]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.141691,	
2017-06-26 13:29:58,990 Epoch[9] Batch [1240]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.141648,	
2017-06-26 13:30:04,907 Epoch[9] Batch [1250]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.141659,	
2017-06-26 13:30:10,977 Epoch[9] Batch [1260]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.141642,	
2017-06-26 13:30:17,026 Epoch[9] Batch [1270]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.141767,	
2017-06-26 13:30:23,161 Epoch[9] Batch [1280]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.141857,	
2017-06-26 13:30:29,372 Epoch[9] Batch [1290]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.141865,	
2017-06-26 13:30:35,812 Epoch[9] Batch [1300]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.141848,	
2017-06-26 13:30:41,851 Epoch[9] Batch [1310]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.141741,	
2017-06-26 13:30:47,920 Epoch[9] Batch [1320]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.141558,	
2017-06-26 13:30:54,067 Epoch[9] Batch [1330]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.141497,	
2017-06-26 13:31:00,126 Epoch[9] Batch [1340]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.141447,	
2017-06-26 13:31:06,263 Epoch[9] Batch [1350]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.141395,	
2017-06-26 13:31:12,367 Epoch[9] Batch [1360]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.141336,	
2017-06-26 13:31:18,517 Epoch[9] Batch [1370]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.141167,	
2017-06-26 13:31:25,001 Epoch[9] Batch [1380]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.141187,	
2017-06-26 13:31:31,162 Epoch[9] Batch [1390]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.141249,	
2017-06-26 13:31:37,741 Epoch[9] Batch [1400]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.141252,	
2017-06-26 13:31:43,882 Epoch[9] Batch [1410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.141201,	
2017-06-26 13:31:50,076 Epoch[9] Batch [1420]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.141219,	
2017-06-26 13:31:56,127 Epoch[9] Batch [1430]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.141094,	
2017-06-26 13:32:02,210 Epoch[9] Batch [1440]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.141133,	
2017-06-26 13:32:08,211 Epoch[9] Batch [1450]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.141071,	
2017-06-26 13:32:14,482 Epoch[9] Batch [1460]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.141181,	
2017-06-26 13:32:21,271 Epoch[9] Batch [1470]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.141123,	
2017-06-26 13:32:27,593 Epoch[9] Batch [1480]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.141079,	
2017-06-26 13:32:31,252 Epoch[9] Train-FCNLogLoss=0.141101
2017-06-26 13:32:31,253 Epoch[9] Time cost=943.488
2017-06-26 13:32:32,536 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0010.params"
2017-06-26 13:32:36,433 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0010.states"
2017-06-26 13:32:43,603 Epoch[10] Batch [10]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.135315,	
2017-06-26 13:32:50,043 Epoch[10] Batch [20]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.129691,	
2017-06-26 13:32:56,529 Epoch[10] Batch [30]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.129740,	
2017-06-26 13:33:02,840 Epoch[10] Batch [40]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.135058,	
2017-06-26 13:33:09,466 Epoch[10] Batch [50]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.137205,	
2017-06-26 13:33:15,713 Epoch[10] Batch [60]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.136592,	
2017-06-26 13:33:21,770 Epoch[10] Batch [70]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.136917,	
2017-06-26 13:33:27,903 Epoch[10] Batch [80]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.138484,	
2017-06-26 13:33:34,001 Epoch[10] Batch [90]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.137298,	
2017-06-26 13:33:40,054 Epoch[10] Batch [100]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.137264,	
2017-06-26 13:33:46,177 Epoch[10] Batch [110]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.138428,	
2017-06-26 13:33:52,273 Epoch[10] Batch [120]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.138207,	
2017-06-26 13:33:58,390 Epoch[10] Batch [130]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.137670,	
2017-06-26 13:34:04,598 Epoch[10] Batch [140]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.138140,	
2017-06-26 13:34:10,737 Epoch[10] Batch [150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.138288,	
2017-06-26 13:34:16,918 Epoch[10] Batch [160]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.138064,	
2017-06-26 13:34:22,911 Epoch[10] Batch [170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.138621,	
2017-06-26 13:34:29,027 Epoch[10] Batch [180]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.138516,	
2017-06-26 13:34:35,196 Epoch[10] Batch [190]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.137708,	
2017-06-26 13:34:41,266 Epoch[10] Batch [200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.138756,	
2017-06-26 13:34:47,374 Epoch[10] Batch [210]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.139591,	
2017-06-26 13:34:53,477 Epoch[10] Batch [220]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.139539,	
2017-06-26 13:34:59,605 Epoch[10] Batch [230]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.140051,	
2017-06-26 13:35:05,697 Epoch[10] Batch [240]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.140195,	
2017-06-26 13:35:11,828 Epoch[10] Batch [250]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.141275,	
2017-06-26 13:35:17,913 Epoch[10] Batch [260]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.143310,	
2017-06-26 13:35:24,091 Epoch[10] Batch [270]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.144011,	
2017-06-26 13:35:30,152 Epoch[10] Batch [280]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.143884,	
2017-06-26 13:35:36,264 Epoch[10] Batch [290]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.144154,	
2017-06-26 13:35:42,432 Epoch[10] Batch [300]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.144736,	
2017-06-26 13:35:48,490 Epoch[10] Batch [310]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.145290,	
2017-06-26 13:35:54,582 Epoch[10] Batch [320]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.146705,	
2017-06-26 13:36:00,704 Epoch[10] Batch [330]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.147917,	
2017-06-26 13:36:06,811 Epoch[10] Batch [340]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.148131,	
2017-06-26 13:36:12,933 Epoch[10] Batch [350]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.148526,	
2017-06-26 13:36:19,031 Epoch[10] Batch [360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.148999,	
2017-06-26 13:36:25,238 Epoch[10] Batch [370]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.148846,	
2017-06-26 13:36:31,284 Epoch[10] Batch [380]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.148571,	
2017-06-26 13:36:37,369 Epoch[10] Batch [390]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.148051,	
2017-06-26 13:36:43,458 Epoch[10] Batch [400]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.147815,	
2017-06-26 13:36:49,555 Epoch[10] Batch [410]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.148386,	
2017-06-26 13:36:55,614 Epoch[10] Batch [420]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.148112,	
2017-06-26 13:37:01,741 Epoch[10] Batch [430]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.147871,	
2017-06-26 13:37:08,091 Epoch[10] Batch [440]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.147680,	
2017-06-26 13:37:14,717 Epoch[10] Batch [450]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.147790,	
2017-06-26 13:37:20,772 Epoch[10] Batch [460]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.147796,	
2017-06-26 13:37:27,202 Epoch[10] Batch [470]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.147657,	
2017-06-26 13:37:33,868 Epoch[10] Batch [480]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.147516,	
2017-06-26 13:37:39,971 Epoch[10] Batch [490]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.147041,	
2017-06-26 13:37:46,121 Epoch[10] Batch [500]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.146671,	
2017-06-26 13:37:52,156 Epoch[10] Batch [510]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.146588,	
2017-06-26 13:37:58,371 Epoch[10] Batch [520]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.146220,	
2017-06-26 13:38:04,826 Epoch[10] Batch [530]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.146462,	
2017-06-26 13:38:11,823 Epoch[10] Batch [540]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.146136,	
2017-06-26 13:38:18,118 Epoch[10] Batch [550]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.146096,	
2017-06-26 13:38:24,784 Epoch[10] Batch [560]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.145850,	
2017-06-26 13:38:31,163 Epoch[10] Batch [570]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.146553,	
2017-06-26 13:38:37,250 Epoch[10] Batch [580]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.146640,	
2017-06-26 13:38:43,387 Epoch[10] Batch [590]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.146546,	
2017-06-26 13:38:49,542 Epoch[10] Batch [600]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.146650,	
2017-06-26 13:38:55,627 Epoch[10] Batch [610]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.146971,	
2017-06-26 13:39:01,765 Epoch[10] Batch [620]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.146841,	
2017-06-26 13:39:08,141 Epoch[10] Batch [630]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.146979,	
2017-06-26 13:39:14,197 Epoch[10] Batch [640]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.146834,	
2017-06-26 13:39:20,373 Epoch[10] Batch [650]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.146550,	
2017-06-26 13:39:26,664 Epoch[10] Batch [660]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.146412,	
2017-06-26 13:39:32,898 Epoch[10] Batch [670]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.146401,	
2017-06-26 13:39:38,985 Epoch[10] Batch [680]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.146525,	
2017-06-26 13:39:45,092 Epoch[10] Batch [690]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.146549,	
2017-06-26 13:39:51,172 Epoch[10] Batch [700]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.146533,	
2017-06-26 13:39:57,240 Epoch[10] Batch [710]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.146726,	
2017-06-26 13:40:03,354 Epoch[10] Batch [720]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.146422,	
2017-06-26 13:40:09,463 Epoch[10] Batch [730]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.146264,	
2017-06-26 13:40:15,676 Epoch[10] Batch [740]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.145871,	
2017-06-26 13:40:21,867 Epoch[10] Batch [750]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.145814,	
2017-06-26 13:40:28,197 Epoch[10] Batch [760]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.145770,	
2017-06-26 13:40:34,628 Epoch[10] Batch [770]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.145454,	
2017-06-26 13:40:41,184 Epoch[10] Batch [780]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.145567,	
2017-06-26 13:40:47,659 Epoch[10] Batch [790]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.145899,	
2017-06-26 13:40:53,982 Epoch[10] Batch [800]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.146210,	
2017-06-26 13:41:00,110 Epoch[10] Batch [810]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.146135,	
2017-06-26 13:41:06,383 Epoch[10] Batch [820]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.146218,	
2017-06-26 13:41:12,990 Epoch[10] Batch [830]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.146000,	
2017-06-26 13:41:18,433 Epoch[10] Batch [840]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.145778,	
2017-06-26 13:41:23,920 Epoch[10] Batch [850]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.145653,	
2017-06-26 13:41:29,292 Epoch[10] Batch [860]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.145544,	
2017-06-26 13:41:34,615 Epoch[10] Batch [870]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.145428,	
2017-06-26 13:41:39,999 Epoch[10] Batch [880]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.145278,	
2017-06-26 13:41:45,346 Epoch[10] Batch [890]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.145240,	
2017-06-26 13:41:50,682 Epoch[10] Batch [900]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.145102,	
2017-06-26 13:41:56,012 Epoch[10] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.145087,	
2017-06-26 13:42:01,356 Epoch[10] Batch [920]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.145026,	
2017-06-26 13:42:06,697 Epoch[10] Batch [930]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.145106,	
2017-06-26 13:42:12,056 Epoch[10] Batch [940]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.145020,	
2017-06-26 13:42:17,406 Epoch[10] Batch [950]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.145028,	
2017-06-26 13:42:22,732 Epoch[10] Batch [960]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.145159,	
2017-06-26 13:42:28,065 Epoch[10] Batch [970]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.144976,	
2017-06-26 13:42:33,468 Epoch[10] Batch [980]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.145026,	
2017-06-26 13:42:38,787 Epoch[10] Batch [990]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.144970,	
2017-06-26 13:42:44,095 Epoch[10] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.144992,	
2017-06-26 13:42:49,483 Epoch[10] Batch [1010]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.145089,	
2017-06-26 13:42:54,734 Epoch[10] Batch [1020]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.144973,	
2017-06-26 13:43:00,062 Epoch[10] Batch [1030]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.144940,	
2017-06-26 13:43:05,413 Epoch[10] Batch [1040]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.144827,	
2017-06-26 13:43:10,748 Epoch[10] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.144897,	
2017-06-26 13:43:16,097 Epoch[10] Batch [1060]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.144932,	
2017-06-26 13:43:21,365 Epoch[10] Batch [1070]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.144774,	
2017-06-26 13:43:26,301 Epoch[10] Batch [1080]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.144646,	
2017-06-26 13:43:31,870 Epoch[10] Batch [1090]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.144566,	
2017-06-26 13:43:37,276 Epoch[10] Batch [1100]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.144300,	
2017-06-26 13:43:42,607 Epoch[10] Batch [1110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.144130,	
2017-06-26 13:43:48,002 Epoch[10] Batch [1120]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.144101,	
2017-06-26 13:43:53,282 Epoch[10] Batch [1130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.144085,	
2017-06-26 13:43:58,708 Epoch[10] Batch [1140]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.143909,	
2017-06-26 13:44:03,998 Epoch[10] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.143959,	
2017-06-26 13:44:09,385 Epoch[10] Batch [1160]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.143866,	
2017-06-26 13:44:14,689 Epoch[10] Batch [1170]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.143652,	
2017-06-26 13:44:20,009 Epoch[10] Batch [1180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.143608,	
2017-06-26 13:44:25,349 Epoch[10] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.143513,	
2017-06-26 13:44:30,692 Epoch[10] Batch [1200]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.143383,	
2017-06-26 13:44:36,020 Epoch[10] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.143419,	
2017-06-26 13:44:41,310 Epoch[10] Batch [1220]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.143489,	
2017-06-26 13:44:46,700 Epoch[10] Batch [1230]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.143480,	
2017-06-26 13:44:52,048 Epoch[10] Batch [1240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.143440,	
2017-06-26 13:44:57,411 Epoch[10] Batch [1250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.143339,	
2017-06-26 13:45:02,759 Epoch[10] Batch [1260]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.143155,	
2017-06-26 13:45:08,063 Epoch[10] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.143049,	
2017-06-26 13:45:13,422 Epoch[10] Batch [1280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.143071,	
2017-06-26 13:45:18,743 Epoch[10] Batch [1290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.143026,	
2017-06-26 13:45:24,121 Epoch[10] Batch [1300]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.142874,	
2017-06-26 13:45:29,512 Epoch[10] Batch [1310]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.142725,	
2017-06-26 13:45:34,853 Epoch[10] Batch [1320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.142658,	
2017-06-26 13:45:40,072 Epoch[10] Batch [1330]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142616,	
2017-06-26 13:45:45,440 Epoch[10] Batch [1340]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.142705,	
2017-06-26 13:45:50,765 Epoch[10] Batch [1350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.142717,	
2017-06-26 13:45:56,171 Epoch[10] Batch [1360]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.142639,	
2017-06-26 13:46:01,316 Epoch[10] Batch [1370]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.142575,	
2017-06-26 13:46:06,638 Epoch[10] Batch [1380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.142381,	
2017-06-26 13:46:11,945 Epoch[10] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.142314,	
2017-06-26 13:46:17,316 Epoch[10] Batch [1400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.142286,	
2017-06-26 13:46:22,705 Epoch[10] Batch [1410]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.142318,	
2017-06-26 13:46:28,017 Epoch[10] Batch [1420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.142360,	
2017-06-26 13:46:33,339 Epoch[10] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.142416,	
2017-06-26 13:46:38,700 Epoch[10] Batch [1440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.142345,	
2017-06-26 13:46:44,016 Epoch[10] Batch [1450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.142264,	
2017-06-26 13:46:49,353 Epoch[10] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.142242,	
2017-06-26 13:46:54,670 Epoch[10] Batch [1470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.142338,	
2017-06-26 13:47:00,015 Epoch[10] Batch [1480]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.142459,	
2017-06-26 13:47:03,236 Epoch[10] Train-FCNLogLoss=0.142454
2017-06-26 13:47:03,236 Epoch[10] Time cost=866.803
2017-06-26 13:47:04,266 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0011.params"
2017-06-26 13:47:07,953 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0011.states"
2017-06-26 13:47:14,258 Epoch[11] Batch [10]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.148592,	
2017-06-26 13:47:19,574 Epoch[11] Batch [20]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.151796,	
2017-06-26 13:47:24,980 Epoch[11] Batch [30]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.146085,	
2017-06-26 13:47:30,273 Epoch[11] Batch [40]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.147156,	
2017-06-26 13:47:35,552 Epoch[11] Batch [50]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.148338,	
2017-06-26 13:47:40,957 Epoch[11] Batch [60]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.149749,	
2017-06-26 13:47:46,285 Epoch[11] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.147984,	
2017-06-26 13:47:51,584 Epoch[11] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.146159,	
2017-06-26 13:47:56,921 Epoch[11] Batch [90]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.143431,	
2017-06-26 13:48:02,284 Epoch[11] Batch [100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.141826,	
2017-06-26 13:48:07,621 Epoch[11] Batch [110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.141373,	
2017-06-26 13:48:12,941 Epoch[11] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.141332,	
2017-06-26 13:48:18,289 Epoch[11] Batch [130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.140346,	
2017-06-26 13:48:23,602 Epoch[11] Batch [140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.140833,	
2017-06-26 13:48:28,958 Epoch[11] Batch [150]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.141691,	
2017-06-26 13:48:34,318 Epoch[11] Batch [160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.141656,	
2017-06-26 13:48:39,612 Epoch[11] Batch [170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.141572,	
2017-06-26 13:48:44,970 Epoch[11] Batch [180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.140936,	
2017-06-26 13:48:50,329 Epoch[11] Batch [190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.140137,	
2017-06-26 13:48:55,783 Epoch[11] Batch [200]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.139248,	
2017-06-26 13:49:00,945 Epoch[11] Batch [210]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.138898,	
2017-06-26 13:49:06,254 Epoch[11] Batch [220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.138770,	
2017-06-26 13:49:11,572 Epoch[11] Batch [230]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.138569,	
2017-06-26 13:49:16,945 Epoch[11] Batch [240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.138496,	
2017-06-26 13:49:22,271 Epoch[11] Batch [250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.138994,	
2017-06-26 13:49:27,584 Epoch[11] Batch [260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.138887,	
2017-06-26 13:49:32,963 Epoch[11] Batch [270]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.138525,	
2017-06-26 13:49:38,317 Epoch[11] Batch [280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.137962,	
2017-06-26 13:49:43,654 Epoch[11] Batch [290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.138244,	
2017-06-26 13:49:48,977 Epoch[11] Batch [300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.137865,	
2017-06-26 13:49:54,310 Epoch[11] Batch [310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.137660,	
2017-06-26 13:49:59,674 Epoch[11] Batch [320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.137325,	
2017-06-26 13:50:05,005 Epoch[11] Batch [330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.137480,	
2017-06-26 13:50:10,328 Epoch[11] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.137616,	
2017-06-26 13:50:15,677 Epoch[11] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.137588,	
2017-06-26 13:50:21,072 Epoch[11] Batch [360]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.137407,	
2017-06-26 13:50:26,355 Epoch[11] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.136941,	
2017-06-26 13:50:31,699 Epoch[11] Batch [380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.137190,	
2017-06-26 13:50:37,075 Epoch[11] Batch [390]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.136662,	
2017-06-26 13:50:42,362 Epoch[11] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.136931,	
2017-06-26 13:50:47,737 Epoch[11] Batch [410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.136688,	
2017-06-26 13:50:53,062 Epoch[11] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136477,	
2017-06-26 13:50:58,383 Epoch[11] Batch [430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.136993,	
2017-06-26 13:51:03,775 Epoch[11] Batch [440]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.136925,	
2017-06-26 13:51:09,133 Epoch[11] Batch [450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.136924,	
2017-06-26 13:51:14,403 Epoch[11] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.136798,	
2017-06-26 13:51:19,761 Epoch[11] Batch [470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.136655,	
2017-06-26 13:51:25,166 Epoch[11] Batch [480]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.136516,	
2017-06-26 13:51:30,499 Epoch[11] Batch [490]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136276,	
2017-06-26 13:51:35,801 Epoch[11] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.136454,	
2017-06-26 13:51:41,172 Epoch[11] Batch [510]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.136471,	
2017-06-26 13:51:46,505 Epoch[11] Batch [520]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136297,	
2017-06-26 13:51:51,785 Epoch[11] Batch [530]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.137153,	
2017-06-26 13:51:57,176 Epoch[11] Batch [540]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.137357,	
2017-06-26 13:52:02,536 Epoch[11] Batch [550]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.137477,	
2017-06-26 13:52:07,847 Epoch[11] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.137238,	
2017-06-26 13:52:13,177 Epoch[11] Batch [570]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136897,	
2017-06-26 13:52:18,581 Epoch[11] Batch [580]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.136761,	
2017-06-26 13:52:23,984 Epoch[11] Batch [590]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.136927,	
2017-06-26 13:52:29,239 Epoch[11] Batch [600]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.136839,	
2017-06-26 13:52:34,644 Epoch[11] Batch [610]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.137204,	
2017-06-26 13:52:39,935 Epoch[11] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.137009,	
2017-06-26 13:52:45,305 Epoch[11] Batch [630]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.137002,	
2017-06-26 13:52:50,611 Epoch[11] Batch [640]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.136796,	
2017-06-26 13:52:56,005 Epoch[11] Batch [650]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.136623,	
2017-06-26 13:53:01,301 Epoch[11] Batch [660]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.136827,	
2017-06-26 13:53:06,673 Epoch[11] Batch [670]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.136640,	
2017-06-26 13:53:12,008 Epoch[11] Batch [680]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136757,	
2017-06-26 13:53:17,359 Epoch[11] Batch [690]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136732,	
2017-06-26 13:53:22,689 Epoch[11] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136451,	
2017-06-26 13:53:28,018 Epoch[11] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136221,	
2017-06-26 13:53:33,354 Epoch[11] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136483,	
2017-06-26 13:53:38,708 Epoch[11] Batch [730]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.136513,	
2017-06-26 13:53:44,043 Epoch[11] Batch [740]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136382,	
2017-06-26 13:53:49,420 Epoch[11] Batch [750]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.136404,	
2017-06-26 13:53:54,893 Epoch[11] Batch [760]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.136274,	
2017-06-26 13:54:00,286 Epoch[11] Batch [770]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.136131,	
2017-06-26 13:54:05,603 Epoch[11] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.136002,	
2017-06-26 13:54:10,985 Epoch[11] Batch [790]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.135924,	
2017-06-26 13:54:16,273 Epoch[11] Batch [800]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.135901,	
2017-06-26 13:54:21,615 Epoch[11] Batch [810]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.135872,	
2017-06-26 13:54:26,963 Epoch[11] Batch [820]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135856,	
2017-06-26 13:54:32,280 Epoch[11] Batch [830]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.136279,	
2017-06-26 13:54:37,609 Epoch[11] Batch [840]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136752,	
2017-06-26 13:54:42,931 Epoch[11] Batch [850]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.136742,	
2017-06-26 13:54:48,325 Epoch[11] Batch [860]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.136888,	
2017-06-26 13:54:53,664 Epoch[11] Batch [870]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.137354,	
2017-06-26 13:54:58,983 Epoch[11] Batch [880]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.137345,	
2017-06-26 13:55:04,364 Epoch[11] Batch [890]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.137511,	
2017-06-26 13:55:09,727 Epoch[11] Batch [900]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.137374,	
2017-06-26 13:55:15,056 Epoch[11] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.137344,	
2017-06-26 13:55:20,450 Epoch[11] Batch [920]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.137469,	
2017-06-26 13:55:25,766 Epoch[11] Batch [930]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.137298,	
2017-06-26 13:55:31,175 Epoch[11] Batch [940]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.137374,	
2017-06-26 13:55:36,478 Epoch[11] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.137365,	
2017-06-26 13:55:41,795 Epoch[11] Batch [960]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.137481,	
2017-06-26 13:55:47,084 Epoch[11] Batch [970]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.137394,	
2017-06-26 13:55:52,435 Epoch[11] Batch [980]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.137393,	
2017-06-26 13:55:57,785 Epoch[11] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.137442,	
2017-06-26 13:56:03,132 Epoch[11] Batch [1000]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.137642,	
2017-06-26 13:56:08,447 Epoch[11] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.137783,	
2017-06-26 13:56:13,752 Epoch[11] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.137822,	
2017-06-26 13:56:19,103 Epoch[11] Batch [1030]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.138014,	
2017-06-26 13:56:24,428 Epoch[11] Batch [1040]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.138029,	
2017-06-26 13:56:29,758 Epoch[11] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.138045,	
2017-06-26 13:56:35,119 Epoch[11] Batch [1060]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.137973,	
2017-06-26 13:56:40,090 Epoch[11] Batch [1070]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.138105,	
2017-06-26 13:56:45,157 Epoch[11] Batch [1080]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.138353,	
2017-06-26 13:56:50,375 Epoch[11] Batch [1090]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.138239,	
2017-06-26 13:56:55,732 Epoch[11] Batch [1100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.138286,	
2017-06-26 13:57:01,034 Epoch[11] Batch [1110]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.138394,	
2017-06-26 13:57:06,473 Epoch[11] Batch [1120]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.138345,	
2017-06-26 13:57:11,669 Epoch[11] Batch [1130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.138334,	
2017-06-26 13:57:17,108 Epoch[11] Batch [1140]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.138424,	
2017-06-26 13:57:22,337 Epoch[11] Batch [1150]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.138513,	
2017-06-26 13:57:27,687 Epoch[11] Batch [1160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.138537,	
2017-06-26 13:57:33,104 Epoch[11] Batch [1170]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.138451,	
2017-06-26 13:57:38,392 Epoch[11] Batch [1180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.138544,	
2017-06-26 13:57:43,706 Epoch[11] Batch [1190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.138400,	
2017-06-26 13:57:49,169 Epoch[11] Batch [1200]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.138416,	
2017-06-26 13:57:54,480 Epoch[11] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.138309,	
2017-06-26 13:57:59,898 Epoch[11] Batch [1220]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.138218,	
2017-06-26 13:58:05,179 Epoch[11] Batch [1230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.138152,	
2017-06-26 13:58:10,544 Epoch[11] Batch [1240]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.138099,	
2017-06-26 13:58:15,903 Epoch[11] Batch [1250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.138037,	
2017-06-26 13:58:21,222 Epoch[11] Batch [1260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.138107,	
2017-06-26 13:58:26,596 Epoch[11] Batch [1270]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.138118,	
2017-06-26 13:58:31,961 Epoch[11] Batch [1280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.138111,	
2017-06-26 13:58:37,341 Epoch[11] Batch [1290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.138215,	
2017-06-26 13:58:42,568 Epoch[11] Batch [1300]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.138199,	
2017-06-26 13:58:47,905 Epoch[11] Batch [1310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.138317,	
2017-06-26 13:58:53,235 Epoch[11] Batch [1320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.138389,	
2017-06-26 13:58:58,558 Epoch[11] Batch [1330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.138394,	
2017-06-26 13:59:03,908 Epoch[11] Batch [1340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.138268,	
2017-06-26 13:59:09,215 Epoch[11] Batch [1350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.138274,	
2017-06-26 13:59:14,570 Epoch[11] Batch [1360]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.138199,	
2017-06-26 13:59:20,024 Epoch[11] Batch [1370]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.138202,	
2017-06-26 13:59:25,280 Epoch[11] Batch [1380]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.138117,	
2017-06-26 13:59:30,583 Epoch[11] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.138095,	
2017-06-26 13:59:35,922 Epoch[11] Batch [1400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.138108,	
2017-06-26 13:59:41,217 Epoch[11] Batch [1410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.138106,	
2017-06-26 13:59:46,665 Epoch[11] Batch [1420]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.138098,	
2017-06-26 13:59:51,874 Epoch[11] Batch [1430]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.138020,	
2017-06-26 13:59:57,225 Epoch[11] Batch [1440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.137803,	
2017-06-26 14:00:02,565 Epoch[11] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.137839,	
2017-06-26 14:00:07,922 Epoch[11] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.137986,	
2017-06-26 14:00:13,259 Epoch[11] Batch [1470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.138151,	
2017-06-26 14:00:18,609 Epoch[11] Batch [1480]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.138241,	
2017-06-26 14:00:21,798 Epoch[11] Train-FCNLogLoss=0.138286
2017-06-26 14:00:21,798 Epoch[11] Time cost=793.845
2017-06-26 14:00:22,849 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0012.params"
2017-06-26 14:00:26,363 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0012.states"
2017-06-26 14:00:32,435 Epoch[12] Batch [10]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.145884,	
2017-06-26 14:00:37,744 Epoch[12] Batch [20]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.145437,	
2017-06-26 14:00:43,080 Epoch[12] Batch [30]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.152477,	
2017-06-26 14:00:48,417 Epoch[12] Batch [40]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.147295,	
2017-06-26 14:00:53,751 Epoch[12] Batch [50]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.143980,	
2017-06-26 14:00:59,116 Epoch[12] Batch [60]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.139852,	
2017-06-26 14:01:04,459 Epoch[12] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.137066,	
2017-06-26 14:01:09,779 Epoch[12] Batch [80]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.138264,	
2017-06-26 14:01:15,110 Epoch[12] Batch [90]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.138563,	
2017-06-26 14:01:20,518 Epoch[12] Batch [100]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.138448,	
2017-06-26 14:01:25,845 Epoch[12] Batch [110]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136658,	
2017-06-26 14:01:31,172 Epoch[12] Batch [120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136161,	
2017-06-26 14:01:36,515 Epoch[12] Batch [130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.136338,	
2017-06-26 14:01:41,815 Epoch[12] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.136899,	
2017-06-26 14:01:47,163 Epoch[12] Batch [150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136764,	
2017-06-26 14:01:52,476 Epoch[12] Batch [160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.136515,	
2017-06-26 14:01:57,805 Epoch[12] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136594,	
2017-06-26 14:02:03,153 Epoch[12] Batch [180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136937,	
2017-06-26 14:02:08,529 Epoch[12] Batch [190]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.136760,	
2017-06-26 14:02:13,835 Epoch[12] Batch [200]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.136863,	
2017-06-26 14:02:19,155 Epoch[12] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.137300,	
2017-06-26 14:02:24,508 Epoch[12] Batch [220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.137485,	
2017-06-26 14:02:29,902 Epoch[12] Batch [230]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.137428,	
2017-06-26 14:02:35,346 Epoch[12] Batch [240]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.136952,	
2017-06-26 14:02:40,554 Epoch[12] Batch [250]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.137374,	
2017-06-26 14:02:45,863 Epoch[12] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.137024,	
2017-06-26 14:02:51,219 Epoch[12] Batch [270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.137741,	
2017-06-26 14:02:56,604 Epoch[12] Batch [280]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.137454,	
2017-06-26 14:03:01,864 Epoch[12] Batch [290]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.137115,	
2017-06-26 14:03:07,172 Epoch[12] Batch [300]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.137345,	
2017-06-26 14:03:12,593 Epoch[12] Batch [310]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.137082,	
2017-06-26 14:03:17,930 Epoch[12] Batch [320]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136847,	
2017-06-26 14:03:23,236 Epoch[12] Batch [330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.136557,	
2017-06-26 14:03:28,519 Epoch[12] Batch [340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.136414,	
2017-06-26 14:03:33,868 Epoch[12] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136196,	
2017-06-26 14:03:39,280 Epoch[12] Batch [360]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.136090,	
2017-06-26 14:03:44,629 Epoch[12] Batch [370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135880,	
2017-06-26 14:03:49,993 Epoch[12] Batch [380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.135651,	
2017-06-26 14:03:55,244 Epoch[12] Batch [390]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.135081,	
2017-06-26 14:04:00,653 Epoch[12] Batch [400]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.134557,	
2017-06-26 14:04:05,984 Epoch[12] Batch [410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135426,	
2017-06-26 14:04:11,282 Epoch[12] Batch [420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.135573,	
2017-06-26 14:04:16,656 Epoch[12] Batch [430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.135044,	
2017-06-26 14:04:21,926 Epoch[12] Batch [440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.134869,	
2017-06-26 14:04:27,314 Epoch[12] Batch [450]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.134936,	
2017-06-26 14:04:32,693 Epoch[12] Batch [460]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.134802,	
2017-06-26 14:04:37,990 Epoch[12] Batch [470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.134759,	
2017-06-26 14:04:43,303 Epoch[12] Batch [480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.134659,	
2017-06-26 14:04:48,625 Epoch[12] Batch [490]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134742,	
2017-06-26 14:04:53,935 Epoch[12] Batch [500]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.134714,	
2017-06-26 14:04:59,283 Epoch[12] Batch [510]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.134790,	
2017-06-26 14:05:04,593 Epoch[12] Batch [520]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.134651,	
2017-06-26 14:05:09,907 Epoch[12] Batch [530]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.134937,	
2017-06-26 14:05:15,250 Epoch[12] Batch [540]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.135254,	
2017-06-26 14:05:20,600 Epoch[12] Batch [550]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135358,	
2017-06-26 14:05:25,897 Epoch[12] Batch [560]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.135342,	
2017-06-26 14:05:31,265 Epoch[12] Batch [570]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.135271,	
2017-06-26 14:05:36,554 Epoch[12] Batch [580]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.135056,	
2017-06-26 14:05:42,010 Epoch[12] Batch [590]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.134761,	
2017-06-26 14:05:47,236 Epoch[12] Batch [600]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.134684,	
2017-06-26 14:05:52,481 Epoch[12] Batch [610]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.134557,	
2017-06-26 14:05:57,837 Epoch[12] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134500,	
2017-06-26 14:06:03,143 Epoch[12] Batch [630]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.134122,	
2017-06-26 14:06:08,498 Epoch[12] Batch [640]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134083,	
2017-06-26 14:06:13,811 Epoch[12] Batch [650]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133886,	
2017-06-26 14:06:19,245 Epoch[12] Batch [660]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.134029,	
2017-06-26 14:06:24,640 Epoch[12] Batch [670]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.133868,	
2017-06-26 14:06:29,962 Epoch[12] Batch [680]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134075,	
2017-06-26 14:06:35,303 Epoch[12] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134371,	
2017-06-26 14:06:40,707 Epoch[12] Batch [700]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.134354,	
2017-06-26 14:06:45,936 Epoch[12] Batch [710]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.134581,	
2017-06-26 14:06:51,357 Epoch[12] Batch [720]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.134869,	
2017-06-26 14:06:56,543 Epoch[12] Batch [730]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.134804,	
2017-06-26 14:07:01,885 Epoch[12] Batch [740]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134710,	
2017-06-26 14:07:07,266 Epoch[12] Batch [750]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.134508,	
2017-06-26 14:07:12,626 Epoch[12] Batch [760]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.134519,	
2017-06-26 14:07:17,911 Epoch[12] Batch [770]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.134135,	
2017-06-26 14:07:23,218 Epoch[12] Batch [780]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.134028,	
2017-06-26 14:07:28,574 Epoch[12] Batch [790]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.133956,	
2017-06-26 14:07:33,945 Epoch[12] Batch [800]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133855,	
2017-06-26 14:07:39,236 Epoch[12] Batch [810]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.133797,	
2017-06-26 14:07:44,613 Epoch[12] Batch [820]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.133831,	
2017-06-26 14:07:49,977 Epoch[12] Batch [830]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133721,	
2017-06-26 14:07:55,296 Epoch[12] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133763,	
2017-06-26 14:08:00,671 Epoch[12] Batch [850]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.133581,	
2017-06-26 14:08:06,052 Epoch[12] Batch [860]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133482,	
2017-06-26 14:08:11,306 Epoch[12] Batch [870]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.133291,	
2017-06-26 14:08:16,650 Epoch[12] Batch [880]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133229,	
2017-06-26 14:08:21,966 Epoch[12] Batch [890]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.132970,	
2017-06-26 14:08:27,281 Epoch[12] Batch [900]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.132841,	
2017-06-26 14:08:32,624 Epoch[12] Batch [910]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.132628,	
2017-06-26 14:08:37,952 Epoch[12] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.132575,	
2017-06-26 14:08:43,326 Epoch[12] Batch [930]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.132357,	
2017-06-26 14:08:48,686 Epoch[12] Batch [940]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132348,	
2017-06-26 14:08:54,052 Epoch[12] Batch [950]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132292,	
2017-06-26 14:08:59,439 Epoch[12] Batch [960]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.132148,	
2017-06-26 14:09:04,716 Epoch[12] Batch [970]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.131974,	
2017-06-26 14:09:10,062 Epoch[12] Batch [980]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131844,	
2017-06-26 14:09:15,410 Epoch[12] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131670,	
2017-06-26 14:09:20,780 Epoch[12] Batch [1000]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131595,	
2017-06-26 14:09:26,087 Epoch[12] Batch [1010]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131633,	
2017-06-26 14:09:31,418 Epoch[12] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131618,	
2017-06-26 14:09:36,763 Epoch[12] Batch [1030]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131629,	
2017-06-26 14:09:42,129 Epoch[12] Batch [1040]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131605,	
2017-06-26 14:09:47,390 Epoch[12] Batch [1050]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.131748,	
2017-06-26 14:09:52,724 Epoch[12] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131919,	
2017-06-26 14:09:57,449 Epoch[12] Batch [1070]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.131813,	
2017-06-26 14:10:02,768 Epoch[12] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131720,	
2017-06-26 14:10:08,051 Epoch[12] Batch [1090]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.131780,	
2017-06-26 14:10:13,431 Epoch[12] Batch [1100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.131798,	
2017-06-26 14:10:18,756 Epoch[12] Batch [1110]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131701,	
2017-06-26 14:10:24,124 Epoch[12] Batch [1120]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131513,	
2017-06-26 14:10:29,496 Epoch[12] Batch [1130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131522,	
2017-06-26 14:10:34,822 Epoch[12] Batch [1140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131517,	
2017-06-26 14:10:40,189 Epoch[12] Batch [1150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131530,	
2017-06-26 14:10:45,439 Epoch[12] Batch [1160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.131564,	
2017-06-26 14:10:50,814 Epoch[12] Batch [1170]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.131487,	
2017-06-26 14:10:56,142 Epoch[12] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131410,	
2017-06-26 14:11:01,502 Epoch[12] Batch [1190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131679,	
2017-06-26 14:11:06,796 Epoch[12] Batch [1200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131638,	
2017-06-26 14:11:12,170 Epoch[12] Batch [1210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.131563,	
2017-06-26 14:11:17,502 Epoch[12] Batch [1220]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131479,	
2017-06-26 14:11:22,878 Epoch[12] Batch [1230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.131602,	
2017-06-26 14:11:28,179 Epoch[12] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.131551,	
2017-06-26 14:11:33,521 Epoch[12] Batch [1250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131620,	
2017-06-26 14:11:38,890 Epoch[12] Batch [1260]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131648,	
2017-06-26 14:11:44,212 Epoch[12] Batch [1270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131627,	
2017-06-26 14:11:49,593 Epoch[12] Batch [1280]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.131618,	
2017-06-26 14:11:54,935 Epoch[12] Batch [1290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131647,	
2017-06-26 14:12:00,211 Epoch[12] Batch [1300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.131745,	
2017-06-26 14:12:05,562 Epoch[12] Batch [1310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131703,	
2017-06-26 14:12:10,971 Epoch[12] Batch [1320]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.131658,	
2017-06-26 14:12:16,261 Epoch[12] Batch [1330]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131592,	
2017-06-26 14:12:21,512 Epoch[12] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.131517,	
2017-06-26 14:12:26,914 Epoch[12] Batch [1350]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.131520,	
2017-06-26 14:12:32,233 Epoch[12] Batch [1360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131452,	
2017-06-26 14:12:37,556 Epoch[12] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131391,	
2017-06-26 14:12:42,857 Epoch[12] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.131352,	
2017-06-26 14:12:48,193 Epoch[12] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131290,	
2017-06-26 14:12:53,552 Epoch[12] Batch [1400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131327,	
2017-06-26 14:12:58,898 Epoch[12] Batch [1410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131291,	
2017-06-26 14:13:04,309 Epoch[12] Batch [1420]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.131424,	
2017-06-26 14:13:09,705 Epoch[12] Batch [1430]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.131367,	
2017-06-26 14:13:14,974 Epoch[12] Batch [1440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.131318,	
2017-06-26 14:13:20,355 Epoch[12] Batch [1450]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.131586,	
2017-06-26 14:13:25,659 Epoch[12] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131624,	
2017-06-26 14:13:31,078 Epoch[12] Batch [1470]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.131644,	
2017-06-26 14:13:36,307 Epoch[12] Batch [1480]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.131645,	
2017-06-26 14:13:39,540 Epoch[12] Train-FCNLogLoss=0.131613
2017-06-26 14:13:39,540 Epoch[12] Time cost=793.177
2017-06-26 14:13:40,603 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0013.params"
2017-06-26 14:13:44,329 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0013.states"
2017-06-26 14:13:50,643 Epoch[13] Batch [10]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.138966,	
2017-06-26 14:13:55,979 Epoch[13] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.140931,	
2017-06-26 14:14:01,297 Epoch[13] Batch [30]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.138526,	
2017-06-26 14:14:06,562 Epoch[13] Batch [40]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.139430,	
2017-06-26 14:14:11,915 Epoch[13] Batch [50]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.136209,	
2017-06-26 14:14:17,239 Epoch[13] Batch [60]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136011,	
2017-06-26 14:14:22,567 Epoch[13] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136466,	
2017-06-26 14:14:27,947 Epoch[13] Batch [80]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.135384,	
2017-06-26 14:14:33,246 Epoch[13] Batch [90]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.133431,	
2017-06-26 14:14:38,618 Epoch[13] Batch [100]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.133620,	
2017-06-26 14:14:43,928 Epoch[13] Batch [110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.132377,	
2017-06-26 14:14:49,262 Epoch[13] Batch [120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131145,	
2017-06-26 14:14:54,561 Epoch[13] Batch [130]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130036,	
2017-06-26 14:14:59,841 Epoch[13] Batch [140]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130486,	
2017-06-26 14:15:05,562 Epoch[13] Batch [150]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.131014,	
2017-06-26 14:15:10,857 Epoch[13] Batch [160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.131256,	
2017-06-26 14:15:16,491 Epoch[13] Batch [170]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.131343,	
2017-06-26 14:15:21,683 Epoch[13] Batch [180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.131315,	
2017-06-26 14:15:27,024 Epoch[13] Batch [190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130723,	
2017-06-26 14:15:32,360 Epoch[13] Batch [200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131647,	
2017-06-26 14:15:37,733 Epoch[13] Batch [210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131271,	
2017-06-26 14:15:43,289 Epoch[13] Batch [220]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.130864,	
2017-06-26 14:15:48,573 Epoch[13] Batch [230]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.131750,	
2017-06-26 14:15:53,886 Epoch[13] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.131793,	
2017-06-26 14:15:59,298 Epoch[13] Batch [250]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.131468,	
2017-06-26 14:16:04,664 Epoch[13] Batch [260]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.130835,	
2017-06-26 14:16:10,099 Epoch[13] Batch [270]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.132728,	
2017-06-26 14:16:15,344 Epoch[13] Batch [280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.133414,	
2017-06-26 14:16:20,739 Epoch[13] Batch [290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.135054,	
2017-06-26 14:16:26,108 Epoch[13] Batch [300]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.135626,	
2017-06-26 14:16:31,406 Epoch[13] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.135984,	
2017-06-26 14:16:36,719 Epoch[13] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.135471,	
2017-06-26 14:16:42,174 Epoch[13] Batch [330]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.135707,	
2017-06-26 14:16:47,698 Epoch[13] Batch [340]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.135881,	
2017-06-26 14:16:52,972 Epoch[13] Batch [350]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.135666,	
2017-06-26 14:16:58,395 Epoch[13] Batch [360]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.135778,	
2017-06-26 14:17:03,764 Epoch[13] Batch [370]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.135845,	
2017-06-26 14:17:09,064 Epoch[13] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.135879,	
2017-06-26 14:17:14,333 Epoch[13] Batch [390]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.135729,	
2017-06-26 14:17:19,691 Epoch[13] Batch [400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.135375,	
2017-06-26 14:17:24,997 Epoch[13] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.135072,	
2017-06-26 14:17:30,398 Epoch[13] Batch [420]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.134708,	
2017-06-26 14:17:35,682 Epoch[13] Batch [430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.134351,	
2017-06-26 14:17:41,002 Epoch[13] Batch [440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134225,	
2017-06-26 14:17:46,383 Epoch[13] Batch [450]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133748,	
2017-06-26 14:17:51,705 Epoch[13] Batch [460]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133913,	
2017-06-26 14:17:57,048 Epoch[13] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133729,	
2017-06-26 14:18:02,684 Epoch[13] Batch [480]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.133253,	
2017-06-26 14:18:08,334 Epoch[13] Batch [490]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.132861,	
2017-06-26 14:18:13,956 Epoch[13] Batch [500]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.132645,	
2017-06-26 14:18:19,134 Epoch[13] Batch [510]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.132553,	
2017-06-26 14:18:25,071 Epoch[13] Batch [520]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.132174,	
2017-06-26 14:18:31,248 Epoch[13] Batch [530]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.132151,	
2017-06-26 14:18:36,825 Epoch[13] Batch [540]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.132041,	
2017-06-26 14:18:42,164 Epoch[13] Batch [550]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131831,	
2017-06-26 14:18:47,557 Epoch[13] Batch [560]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.131797,	
2017-06-26 14:18:52,872 Epoch[13] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.131686,	
2017-06-26 14:18:58,497 Epoch[13] Batch [580]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.131405,	
2017-06-26 14:19:03,833 Epoch[13] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130982,	
2017-06-26 14:19:09,185 Epoch[13] Batch [600]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130843,	
2017-06-26 14:19:14,553 Epoch[13] Batch [610]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.130805,	
2017-06-26 14:19:19,910 Epoch[13] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130881,	
2017-06-26 14:19:25,186 Epoch[13] Batch [630]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130895,	
2017-06-26 14:19:30,579 Epoch[13] Batch [640]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.130565,	
2017-06-26 14:19:35,793 Epoch[13] Batch [650]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.130931,	
2017-06-26 14:19:41,127 Epoch[13] Batch [660]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131168,	
2017-06-26 14:19:46,474 Epoch[13] Batch [670]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131669,	
2017-06-26 14:19:51,809 Epoch[13] Batch [680]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131765,	
2017-06-26 14:19:57,165 Epoch[13] Batch [690]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131851,	
2017-06-26 14:20:02,490 Epoch[13] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131815,	
2017-06-26 14:20:07,862 Epoch[13] Batch [710]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.132265,	
2017-06-26 14:20:13,177 Epoch[13] Batch [720]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.132327,	
2017-06-26 14:20:18,485 Epoch[13] Batch [730]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.132379,	
2017-06-26 14:20:23,834 Epoch[13] Batch [740]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.132319,	
2017-06-26 14:20:29,142 Epoch[13] Batch [750]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.132174,	
2017-06-26 14:20:34,479 Epoch[13] Batch [760]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.132062,	
2017-06-26 14:20:39,819 Epoch[13] Batch [770]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131930,	
2017-06-26 14:20:45,148 Epoch[13] Batch [780]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131971,	
2017-06-26 14:20:50,479 Epoch[13] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131988,	
2017-06-26 14:20:55,837 Epoch[13] Batch [800]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131815,	
2017-06-26 14:21:01,151 Epoch[13] Batch [810]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.131719,	
2017-06-26 14:21:06,762 Epoch[13] Batch [820]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.132241,	
2017-06-26 14:21:12,143 Epoch[13] Batch [830]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.132742,	
2017-06-26 14:21:17,498 Epoch[13] Batch [840]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.132855,	
2017-06-26 14:21:22,789 Epoch[13] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.133471,	
2017-06-26 14:21:28,129 Epoch[13] Batch [860]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133874,	
2017-06-26 14:21:33,511 Epoch[13] Batch [870]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.134324,	
2017-06-26 14:21:38,805 Epoch[13] Batch [880]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.134459,	
2017-06-26 14:21:44,184 Epoch[13] Batch [890]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.135202,	
2017-06-26 14:21:49,507 Epoch[13] Batch [900]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135321,	
2017-06-26 14:21:54,834 Epoch[13] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135240,	
2017-06-26 14:22:00,151 Epoch[13] Batch [920]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.135114,	
2017-06-26 14:22:05,484 Epoch[13] Batch [930]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.135126,	
2017-06-26 14:22:10,887 Epoch[13] Batch [940]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.135157,	
2017-06-26 14:22:16,242 Epoch[13] Batch [950]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.135154,	
2017-06-26 14:22:21,554 Epoch[13] Batch [960]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.135022,	
2017-06-26 14:22:26,916 Epoch[13] Batch [970]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.135048,	
2017-06-26 14:22:32,229 Epoch[13] Batch [980]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.134880,	
2017-06-26 14:22:37,572 Epoch[13] Batch [990]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.135013,	
2017-06-26 14:22:42,935 Epoch[13] Batch [1000]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.135107,	
2017-06-26 14:22:48,264 Epoch[13] Batch [1010]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134991,	
2017-06-26 14:22:53,596 Epoch[13] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.134952,	
2017-06-26 14:22:58,940 Epoch[13] Batch [1030]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134917,	
2017-06-26 14:23:04,260 Epoch[13] Batch [1040]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134940,	
2017-06-26 14:23:08,773 Epoch[13] Batch [1050]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.135033,	
2017-06-26 14:23:14,078 Epoch[13] Batch [1060]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.134994,	
2017-06-26 14:23:19,435 Epoch[13] Batch [1070]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134988,	
2017-06-26 14:23:24,776 Epoch[13] Batch [1080]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.135108,	
2017-06-26 14:23:30,104 Epoch[13] Batch [1090]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134959,	
2017-06-26 14:23:35,436 Epoch[13] Batch [1100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.135076,	
2017-06-26 14:23:40,814 Epoch[13] Batch [1110]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.134900,	
2017-06-26 14:23:46,133 Epoch[13] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134943,	
2017-06-26 14:23:51,483 Epoch[13] Batch [1130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.134899,	
2017-06-26 14:23:56,805 Epoch[13] Batch [1140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134771,	
2017-06-26 14:24:02,137 Epoch[13] Batch [1150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.134755,	
2017-06-26 14:24:07,523 Epoch[13] Batch [1160]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.134862,	
2017-06-26 14:24:13,092 Epoch[13] Batch [1170]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.134759,	
2017-06-26 14:24:18,701 Epoch[13] Batch [1180]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.134733,	
2017-06-26 14:24:24,025 Epoch[13] Batch [1190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134679,	
2017-06-26 14:24:29,343 Epoch[13] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134717,	
2017-06-26 14:24:34,699 Epoch[13] Batch [1210]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134659,	
2017-06-26 14:24:40,048 Epoch[13] Batch [1220]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.134491,	
2017-06-26 14:24:45,427 Epoch[13] Batch [1230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.134443,	
2017-06-26 14:24:50,715 Epoch[13] Batch [1240]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.134255,	
2017-06-26 14:24:56,175 Epoch[13] Batch [1250]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.134233,	
2017-06-26 14:25:01,371 Epoch[13] Batch [1260]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.134059,	
2017-06-26 14:25:06,633 Epoch[13] Batch [1270]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.133961,	
2017-06-26 14:25:11,931 Epoch[13] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.133899,	
2017-06-26 14:25:17,307 Epoch[13] Batch [1290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.133754,	
2017-06-26 14:25:22,644 Epoch[13] Batch [1300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133665,	
2017-06-26 14:25:28,048 Epoch[13] Batch [1310]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.133606,	
2017-06-26 14:25:33,369 Epoch[13] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133581,	
2017-06-26 14:25:38,700 Epoch[13] Batch [1330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133605,	
2017-06-26 14:25:44,059 Epoch[13] Batch [1340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133597,	
2017-06-26 14:25:49,452 Epoch[13] Batch [1350]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.133519,	
2017-06-26 14:25:54,802 Epoch[13] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133362,	
2017-06-26 14:26:00,172 Epoch[13] Batch [1370]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.133242,	
2017-06-26 14:26:05,447 Epoch[13] Batch [1380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.133173,	
2017-06-26 14:26:10,759 Epoch[13] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133090,	
2017-06-26 14:26:16,156 Epoch[13] Batch [1400]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.133008,	
2017-06-26 14:26:21,409 Epoch[13] Batch [1410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.132947,	
2017-06-26 14:26:26,802 Epoch[13] Batch [1420]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.132924,	
2017-06-26 14:26:32,170 Epoch[13] Batch [1430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.132886,	
2017-06-26 14:26:37,418 Epoch[13] Batch [1440]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.132831,	
2017-06-26 14:26:42,748 Epoch[13] Batch [1450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.132825,	
2017-06-26 14:26:48,163 Epoch[13] Batch [1460]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.132812,	
2017-06-26 14:26:53,444 Epoch[13] Batch [1470]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.132849,	
2017-06-26 14:26:58,762 Epoch[13] Batch [1480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.132918,	
2017-06-26 14:27:01,898 Epoch[13] Train-FCNLogLoss=0.132920
2017-06-26 14:27:01,898 Epoch[13] Time cost=797.569
2017-06-26 14:27:02,996 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0014.params"
2017-06-26 14:27:06,679 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0014.states"
2017-06-26 14:27:12,930 Epoch[14] Batch [10]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.134773,	
2017-06-26 14:27:18,315 Epoch[14] Batch [20]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.135934,	
2017-06-26 14:27:23,643 Epoch[14] Batch [30]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134455,	
2017-06-26 14:27:29,026 Epoch[14] Batch [40]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.132360,	
2017-06-26 14:27:34,369 Epoch[14] Batch [50]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130915,	
2017-06-26 14:27:39,713 Epoch[14] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130596,	
2017-06-26 14:27:45,296 Epoch[14] Batch [70]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.129446,	
2017-06-26 14:27:50,994 Epoch[14] Batch [80]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.129078,	
2017-06-26 14:27:56,625 Epoch[14] Batch [90]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.127545,	
2017-06-26 14:28:01,989 Epoch[14] Batch [100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.126651,	
2017-06-26 14:28:07,239 Epoch[14] Batch [110]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.128652,	
2017-06-26 14:28:12,655 Epoch[14] Batch [120]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.127692,	
2017-06-26 14:28:18,458 Epoch[14] Batch [130]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.128340,	
2017-06-26 14:28:23,749 Epoch[14] Batch [140]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.129288,	
2017-06-26 14:28:29,093 Epoch[14] Batch [150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129309,	
2017-06-26 14:28:34,487 Epoch[14] Batch [160]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.128565,	
2017-06-26 14:28:39,761 Epoch[14] Batch [170]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.128620,	
2017-06-26 14:28:45,206 Epoch[14] Batch [180]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.128247,	
2017-06-26 14:28:50,537 Epoch[14] Batch [190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.128372,	
2017-06-26 14:28:55,737 Epoch[14] Batch [200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127974,	
2017-06-26 14:29:01,116 Epoch[14] Batch [210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.128756,	
2017-06-26 14:29:06,456 Epoch[14] Batch [220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128177,	
2017-06-26 14:29:11,724 Epoch[14] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.128205,	
2017-06-26 14:29:17,104 Epoch[14] Batch [240]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.128308,	
2017-06-26 14:29:22,499 Epoch[14] Batch [250]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.128276,	
2017-06-26 14:29:27,786 Epoch[14] Batch [260]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.128176,	
2017-06-26 14:29:33,113 Epoch[14] Batch [270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.127668,	
2017-06-26 14:29:38,445 Epoch[14] Batch [280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.127479,	
2017-06-26 14:29:43,790 Epoch[14] Batch [290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.126976,	
2017-06-26 14:29:49,126 Epoch[14] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.127043,	
2017-06-26 14:29:54,430 Epoch[14] Batch [310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.127186,	
2017-06-26 14:29:59,782 Epoch[14] Batch [320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.127236,	
2017-06-26 14:30:05,202 Epoch[14] Batch [330]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.127491,	
2017-06-26 14:30:11,008 Epoch[14] Batch [340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.127899,	
2017-06-26 14:30:16,377 Epoch[14] Batch [350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.127947,	
2017-06-26 14:30:22,278 Epoch[14] Batch [360]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.128086,	
2017-06-26 14:30:28,513 Epoch[14] Batch [370]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.127904,	
2017-06-26 14:30:34,697 Epoch[14] Batch [380]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.128706,	
2017-06-26 14:30:39,998 Epoch[14] Batch [390]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.128991,	
2017-06-26 14:30:45,283 Epoch[14] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.128586,	
2017-06-26 14:30:50,677 Epoch[14] Batch [410]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.128866,	
2017-06-26 14:30:55,934 Epoch[14] Batch [420]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.128939,	
2017-06-26 14:31:01,291 Epoch[14] Batch [430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.129033,	
2017-06-26 14:31:06,648 Epoch[14] Batch [440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.129063,	
2017-06-26 14:31:11,989 Epoch[14] Batch [450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129053,	
2017-06-26 14:31:17,343 Epoch[14] Batch [460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.128953,	
2017-06-26 14:31:22,713 Epoch[14] Batch [470]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.129329,	
2017-06-26 14:31:28,079 Epoch[14] Batch [480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.129388,	
2017-06-26 14:31:33,416 Epoch[14] Batch [490]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.129309,	
2017-06-26 14:31:38,722 Epoch[14] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.129321,	
2017-06-26 14:31:44,060 Epoch[14] Batch [510]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129233,	
2017-06-26 14:31:49,398 Epoch[14] Batch [520]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129234,	
2017-06-26 14:31:54,729 Epoch[14] Batch [530]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.129289,	
2017-06-26 14:32:00,120 Epoch[14] Batch [540]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.129075,	
2017-06-26 14:32:05,439 Epoch[14] Batch [550]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129100,	
2017-06-26 14:32:10,760 Epoch[14] Batch [560]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129179,	
2017-06-26 14:32:16,096 Epoch[14] Batch [570]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.129332,	
2017-06-26 14:32:21,407 Epoch[14] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129304,	
2017-06-26 14:32:26,747 Epoch[14] Batch [590]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129236,	
2017-06-26 14:32:32,110 Epoch[14] Batch [600]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.129056,	
2017-06-26 14:32:37,416 Epoch[14] Batch [610]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.128961,	
2017-06-26 14:32:42,771 Epoch[14] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.128926,	
2017-06-26 14:32:48,099 Epoch[14] Batch [630]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.128904,	
2017-06-26 14:32:53,435 Epoch[14] Batch [640]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.128714,	
2017-06-26 14:32:58,783 Epoch[14] Batch [650]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.128417,	
2017-06-26 14:33:04,114 Epoch[14] Batch [660]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.128428,	
2017-06-26 14:33:09,475 Epoch[14] Batch [670]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.128569,	
2017-06-26 14:33:14,822 Epoch[14] Batch [680]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.128434,	
2017-06-26 14:33:20,142 Epoch[14] Batch [690]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.128366,	
2017-06-26 14:33:25,502 Epoch[14] Batch [700]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.128194,	
2017-06-26 14:33:30,852 Epoch[14] Batch [710]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.128228,	
2017-06-26 14:33:36,195 Epoch[14] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128589,	
2017-06-26 14:33:41,536 Epoch[14] Batch [730]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128767,	
2017-06-26 14:33:46,874 Epoch[14] Batch [740]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129263,	
2017-06-26 14:33:52,196 Epoch[14] Batch [750]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129272,	
2017-06-26 14:33:57,565 Epoch[14] Batch [760]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.129372,	
2017-06-26 14:34:02,928 Epoch[14] Batch [770]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.129356,	
2017-06-26 14:34:08,232 Epoch[14] Batch [780]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130022,	
2017-06-26 14:34:13,603 Epoch[14] Batch [790]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.130075,	
2017-06-26 14:34:18,894 Epoch[14] Batch [800]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.130264,	
2017-06-26 14:34:24,248 Epoch[14] Batch [810]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130280,	
2017-06-26 14:34:29,535 Epoch[14] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130243,	
2017-06-26 14:34:34,897 Epoch[14] Batch [830]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130141,	
2017-06-26 14:34:40,244 Epoch[14] Batch [840]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130348,	
2017-06-26 14:34:45,680 Epoch[14] Batch [850]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.130281,	
2017-06-26 14:34:50,948 Epoch[14] Batch [860]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.130521,	
2017-06-26 14:34:56,223 Epoch[14] Batch [870]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130440,	
2017-06-26 14:35:01,635 Epoch[14] Batch [880]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.130416,	
2017-06-26 14:35:06,910 Epoch[14] Batch [890]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130758,	
2017-06-26 14:35:12,298 Epoch[14] Batch [900]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.130724,	
2017-06-26 14:35:17,647 Epoch[14] Batch [910]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130742,	
2017-06-26 14:35:22,904 Epoch[14] Batch [920]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.130633,	
2017-06-26 14:35:28,288 Epoch[14] Batch [930]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.130631,	
2017-06-26 14:35:33,651 Epoch[14] Batch [940]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130660,	
2017-06-26 14:35:38,924 Epoch[14] Batch [950]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.130499,	
2017-06-26 14:35:44,295 Epoch[14] Batch [960]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.130528,	
2017-06-26 14:35:49,603 Epoch[14] Batch [970]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130653,	
2017-06-26 14:35:54,962 Epoch[14] Batch [980]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130491,	
2017-06-26 14:36:00,308 Epoch[14] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130818,	
2017-06-26 14:36:05,701 Epoch[14] Batch [1000]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.130865,	
2017-06-26 14:36:11,033 Epoch[14] Batch [1010]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130869,	
2017-06-26 14:36:16,001 Epoch[14] Batch [1020]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.130709,	
2017-06-26 14:36:20,587 Epoch[14] Batch [1030]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.130791,	
2017-06-26 14:36:25,825 Epoch[14] Batch [1040]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.130867,	
2017-06-26 14:36:31,191 Epoch[14] Batch [1050]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130851,	
2017-06-26 14:36:36,550 Epoch[14] Batch [1060]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130988,	
2017-06-26 14:36:41,885 Epoch[14] Batch [1070]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131004,	
2017-06-26 14:36:47,197 Epoch[14] Batch [1080]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130999,	
2017-06-26 14:36:52,592 Epoch[14] Batch [1090]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.131033,	
2017-06-26 14:36:57,977 Epoch[14] Batch [1100]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.130944,	
2017-06-26 14:37:03,264 Epoch[14] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130981,	
2017-06-26 14:37:08,633 Epoch[14] Batch [1120]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.130756,	
2017-06-26 14:37:13,969 Epoch[14] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130548,	
2017-06-26 14:37:19,316 Epoch[14] Batch [1140]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130467,	
2017-06-26 14:37:24,659 Epoch[14] Batch [1150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130418,	
2017-06-26 14:37:30,022 Epoch[14] Batch [1160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130382,	
2017-06-26 14:37:35,392 Epoch[14] Batch [1170]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.130385,	
2017-06-26 14:37:40,707 Epoch[14] Batch [1180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130277,	
2017-06-26 14:37:46,013 Epoch[14] Batch [1190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130477,	
2017-06-26 14:37:51,346 Epoch[14] Batch [1200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130454,	
2017-06-26 14:37:56,684 Epoch[14] Batch [1210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130477,	
2017-06-26 14:38:02,004 Epoch[14] Batch [1220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130463,	
2017-06-26 14:38:07,345 Epoch[14] Batch [1230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130560,	
2017-06-26 14:38:12,725 Epoch[14] Batch [1240]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.130574,	
2017-06-26 14:38:18,545 Epoch[14] Batch [1250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.130427,	
2017-06-26 14:38:24,183 Epoch[14] Batch [1260]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.130363,	
2017-06-26 14:38:29,523 Epoch[14] Batch [1270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130297,	
2017-06-26 14:38:34,977 Epoch[14] Batch [1280]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.130540,	
2017-06-26 14:38:40,195 Epoch[14] Batch [1290]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.130511,	
2017-06-26 14:38:45,614 Epoch[14] Batch [1300]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.130580,	
2017-06-26 14:38:50,956 Epoch[14] Batch [1310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130531,	
2017-06-26 14:38:56,306 Epoch[14] Batch [1320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130611,	
2017-06-26 14:39:01,725 Epoch[14] Batch [1330]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.130529,	
2017-06-26 14:39:07,053 Epoch[14] Batch [1340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130490,	
2017-06-26 14:39:12,364 Epoch[14] Batch [1350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130448,	
2017-06-26 14:39:17,607 Epoch[14] Batch [1360]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.130518,	
2017-06-26 14:39:23,034 Epoch[14] Batch [1370]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.130492,	
2017-06-26 14:39:28,353 Epoch[14] Batch [1380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130470,	
2017-06-26 14:39:33,709 Epoch[14] Batch [1390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130402,	
2017-06-26 14:39:39,038 Epoch[14] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130381,	
2017-06-26 14:39:44,358 Epoch[14] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130272,	
2017-06-26 14:39:49,688 Epoch[14] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130283,	
2017-06-26 14:39:54,997 Epoch[14] Batch [1430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130179,	
2017-06-26 14:40:00,374 Epoch[14] Batch [1440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.130129,	
2017-06-26 14:40:05,726 Epoch[14] Batch [1450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130173,	
2017-06-26 14:40:11,068 Epoch[14] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130156,	
2017-06-26 14:40:16,591 Epoch[14] Batch [1470]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.130115,	
2017-06-26 14:40:21,736 Epoch[14] Batch [1480]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.130095,	
2017-06-26 14:40:24,913 Epoch[14] Train-FCNLogLoss=0.130047
2017-06-26 14:40:24,914 Epoch[14] Time cost=798.234
2017-06-26 14:40:25,925 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0015.params"
2017-06-26 14:40:29,710 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0015.states"
2017-06-26 14:40:35,963 Epoch[15] Batch [10]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.108590,	
2017-06-26 14:40:41,175 Epoch[15] Batch [20]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111093,	
2017-06-26 14:40:46,551 Epoch[15] Batch [30]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.116428,	
2017-06-26 14:40:51,849 Epoch[15] Batch [40]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121554,	
2017-06-26 14:40:57,188 Epoch[15] Batch [50]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125364,	
2017-06-26 14:41:02,529 Epoch[15] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.127625,	
2017-06-26 14:41:07,829 Epoch[15] Batch [70]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.127242,	
2017-06-26 14:41:13,167 Epoch[15] Batch [80]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.127192,	
2017-06-26 14:41:18,550 Epoch[15] Batch [90]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125855,	
2017-06-26 14:41:23,832 Epoch[15] Batch [100]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125110,	
2017-06-26 14:41:29,186 Epoch[15] Batch [110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.123804,	
2017-06-26 14:41:34,502 Epoch[15] Batch [120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123460,	
2017-06-26 14:41:39,834 Epoch[15] Batch [130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.122689,	
2017-06-26 14:41:45,220 Epoch[15] Batch [140]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.123051,	
2017-06-26 14:41:50,535 Epoch[15] Batch [150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123244,	
2017-06-26 14:41:55,900 Epoch[15] Batch [160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.122643,	
2017-06-26 14:42:01,268 Epoch[15] Batch [170]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122476,	
2017-06-26 14:42:06,640 Epoch[15] Batch [180]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121636,	
2017-06-26 14:42:11,973 Epoch[15] Batch [190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121465,	
2017-06-26 14:42:17,232 Epoch[15] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121446,	
2017-06-26 14:42:22,585 Epoch[15] Batch [210]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.120804,	
2017-06-26 14:42:27,984 Epoch[15] Batch [220]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.121675,	
2017-06-26 14:42:33,253 Epoch[15] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.122044,	
2017-06-26 14:42:38,586 Epoch[15] Batch [240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.122741,	
2017-06-26 14:42:43,960 Epoch[15] Batch [250]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.122855,	
2017-06-26 14:42:49,264 Epoch[15] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.123135,	
2017-06-26 14:42:54,715 Epoch[15] Batch [270]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.123556,	
2017-06-26 14:42:59,952 Epoch[15] Batch [280]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.123991,	
2017-06-26 14:43:05,310 Epoch[15] Batch [290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.123924,	
2017-06-26 14:43:10,702 Epoch[15] Batch [300]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.124046,	
2017-06-26 14:43:15,938 Epoch[15] Batch [310]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.124391,	
2017-06-26 14:43:21,277 Epoch[15] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125448,	
2017-06-26 14:43:26,690 Epoch[15] Batch [330]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.125098,	
2017-06-26 14:43:31,979 Epoch[15] Batch [340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.124920,	
2017-06-26 14:43:37,303 Epoch[15] Batch [350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125108,	
2017-06-26 14:43:42,625 Epoch[15] Batch [360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.124725,	
2017-06-26 14:43:47,994 Epoch[15] Batch [370]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.124779,	
2017-06-26 14:43:53,291 Epoch[15] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124777,	
2017-06-26 14:43:58,839 Epoch[15] Batch [390]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.124898,	
2017-06-26 14:44:04,100 Epoch[15] Batch [400]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124973,	
2017-06-26 14:44:09,450 Epoch[15] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125035,	
2017-06-26 14:44:14,736 Epoch[15] Batch [420]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124923,	
2017-06-26 14:44:20,139 Epoch[15] Batch [430]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.125265,	
2017-06-26 14:44:25,510 Epoch[15] Batch [440]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125287,	
2017-06-26 14:44:30,902 Epoch[15] Batch [450]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125082,	
2017-06-26 14:44:36,127 Epoch[15] Batch [460]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.125213,	
2017-06-26 14:44:41,520 Epoch[15] Batch [470]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125597,	
2017-06-26 14:44:46,821 Epoch[15] Batch [480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125551,	
2017-06-26 14:44:52,195 Epoch[15] Batch [490]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125723,	
2017-06-26 14:44:57,487 Epoch[15] Batch [500]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125465,	
2017-06-26 14:45:02,915 Epoch[15] Batch [510]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.125507,	
2017-06-26 14:45:08,232 Epoch[15] Batch [520]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125517,	
2017-06-26 14:45:13,633 Epoch[15] Batch [530]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.125696,	
2017-06-26 14:45:18,946 Epoch[15] Batch [540]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125576,	
2017-06-26 14:45:24,322 Epoch[15] Batch [550]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125679,	
2017-06-26 14:45:29,661 Epoch[15] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125558,	
2017-06-26 14:45:35,000 Epoch[15] Batch [570]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125376,	
2017-06-26 14:45:40,357 Epoch[15] Batch [580]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125209,	
2017-06-26 14:45:45,688 Epoch[15] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125176,	
2017-06-26 14:45:50,977 Epoch[15] Batch [600]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125098,	
2017-06-26 14:45:56,353 Epoch[15] Batch [610]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.124966,	
2017-06-26 14:46:01,760 Epoch[15] Batch [620]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.125493,	
2017-06-26 14:46:07,038 Epoch[15] Batch [630]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125579,	
2017-06-26 14:46:12,369 Epoch[15] Batch [640]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125808,	
2017-06-26 14:46:17,750 Epoch[15] Batch [650]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125847,	
2017-06-26 14:46:23,095 Epoch[15] Batch [660]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125892,	
2017-06-26 14:46:28,418 Epoch[15] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125806,	
2017-06-26 14:46:33,735 Epoch[15] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125837,	
2017-06-26 14:46:39,112 Epoch[15] Batch [690]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125657,	
2017-06-26 14:46:44,398 Epoch[15] Batch [700]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125541,	
2017-06-26 14:46:49,804 Epoch[15] Batch [710]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.125334,	
2017-06-26 14:46:55,093 Epoch[15] Batch [720]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125525,	
2017-06-26 14:47:00,401 Epoch[15] Batch [730]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125677,	
2017-06-26 14:47:05,741 Epoch[15] Batch [740]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125556,	
2017-06-26 14:47:11,099 Epoch[15] Batch [750]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125446,	
2017-06-26 14:47:16,292 Epoch[15] Batch [760]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.125446,	
2017-06-26 14:47:21,819 Epoch[15] Batch [770]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.125439,	
2017-06-26 14:47:26,978 Epoch[15] Batch [780]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.125323,	
2017-06-26 14:47:32,328 Epoch[15] Batch [790]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125296,	
2017-06-26 14:47:38,032 Epoch[15] Batch [800]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.125507,	
2017-06-26 14:47:43,288 Epoch[15] Batch [810]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125496,	
2017-06-26 14:47:48,613 Epoch[15] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125708,	
2017-06-26 14:47:53,931 Epoch[15] Batch [830]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125714,	
2017-06-26 14:47:59,271 Epoch[15] Batch [840]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125535,	
2017-06-26 14:48:04,580 Epoch[15] Batch [850]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125460,	
2017-06-26 14:48:10,031 Epoch[15] Batch [860]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.125473,	
2017-06-26 14:48:15,516 Epoch[15] Batch [870]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.125223,	
2017-06-26 14:48:20,722 Epoch[15] Batch [880]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.125209,	
2017-06-26 14:48:26,082 Epoch[15] Batch [890]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125146,	
2017-06-26 14:48:31,447 Epoch[15] Batch [900]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125017,	
2017-06-26 14:48:36,951 Epoch[15] Batch [910]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.124961,	
2017-06-26 14:48:42,229 Epoch[15] Batch [920]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.124829,	
2017-06-26 14:48:47,567 Epoch[15] Batch [930]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124820,	
2017-06-26 14:48:52,895 Epoch[15] Batch [940]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124883,	
2017-06-26 14:48:58,282 Epoch[15] Batch [950]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.124753,	
2017-06-26 14:49:03,537 Epoch[15] Batch [960]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.124765,	
2017-06-26 14:49:08,997 Epoch[15] Batch [970]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.124693,	
2017-06-26 14:49:14,341 Epoch[15] Batch [980]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124574,	
2017-06-26 14:49:19,693 Epoch[15] Batch [990]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124461,	
2017-06-26 14:49:24,993 Epoch[15] Batch [1000]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124460,	
2017-06-26 14:49:29,856 Epoch[15] Batch [1010]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.124440,	
2017-06-26 14:49:35,084 Epoch[15] Batch [1020]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.124286,	
2017-06-26 14:49:40,542 Epoch[15] Batch [1030]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.124395,	
2017-06-26 14:49:45,862 Epoch[15] Batch [1040]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.124351,	
2017-06-26 14:49:51,201 Epoch[15] Batch [1050]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124352,	
2017-06-26 14:49:56,613 Epoch[15] Batch [1060]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.124344,	
2017-06-26 14:50:02,177 Epoch[15] Batch [1070]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.124657,	
2017-06-26 14:50:07,850 Epoch[15] Batch [1080]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.124931,	
2017-06-26 14:50:13,188 Epoch[15] Batch [1090]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124999,	
2017-06-26 14:50:18,543 Epoch[15] Batch [1100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125073,	
2017-06-26 14:50:23,914 Epoch[15] Batch [1110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125130,	
2017-06-26 14:50:29,240 Epoch[15] Batch [1120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125217,	
2017-06-26 14:50:34,621 Epoch[15] Batch [1130]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125082,	
2017-06-26 14:50:39,917 Epoch[15] Batch [1140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125086,	
2017-06-26 14:50:45,288 Epoch[15] Batch [1150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125138,	
2017-06-26 14:50:50,631 Epoch[15] Batch [1160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125040,	
2017-06-26 14:50:55,982 Epoch[15] Batch [1170]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125064,	
2017-06-26 14:51:01,269 Epoch[15] Batch [1180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125221,	
2017-06-26 14:51:06,638 Epoch[15] Batch [1190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125265,	
2017-06-26 14:51:11,969 Epoch[15] Batch [1200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125271,	
2017-06-26 14:51:17,349 Epoch[15] Batch [1210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125344,	
2017-06-26 14:51:22,717 Epoch[15] Batch [1220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125341,	
2017-06-26 14:51:28,202 Epoch[15] Batch [1230]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.125402,	
2017-06-26 14:51:33,580 Epoch[15] Batch [1240]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125342,	
2017-06-26 14:51:38,920 Epoch[15] Batch [1250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125661,	
2017-06-26 14:51:44,214 Epoch[15] Batch [1260]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125643,	
2017-06-26 14:51:49,605 Epoch[15] Batch [1270]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125658,	
2017-06-26 14:51:54,901 Epoch[15] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125635,	
2017-06-26 14:52:00,195 Epoch[15] Batch [1290]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125576,	
2017-06-26 14:52:05,524 Epoch[15] Batch [1300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125691,	
2017-06-26 14:52:10,913 Epoch[15] Batch [1310]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125742,	
2017-06-26 14:52:16,257 Epoch[15] Batch [1320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125747,	
2017-06-26 14:52:21,556 Epoch[15] Batch [1330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125635,	
2017-06-26 14:52:26,859 Epoch[15] Batch [1340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125643,	
2017-06-26 14:52:32,211 Epoch[15] Batch [1350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125593,	
2017-06-26 14:52:37,514 Epoch[15] Batch [1360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125723,	
2017-06-26 14:52:42,954 Epoch[15] Batch [1370]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.125772,	
2017-06-26 14:52:48,299 Epoch[15] Batch [1380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125789,	
2017-06-26 14:52:53,643 Epoch[15] Batch [1390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125710,	
2017-06-26 14:52:59,011 Epoch[15] Batch [1400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125643,	
2017-06-26 14:53:04,604 Epoch[15] Batch [1410]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.125592,	
2017-06-26 14:53:09,969 Epoch[15] Batch [1420]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125584,	
2017-06-26 14:53:15,307 Epoch[15] Batch [1430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125471,	
2017-06-26 14:53:20,666 Epoch[15] Batch [1440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125500,	
2017-06-26 14:53:25,991 Epoch[15] Batch [1450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125498,	
2017-06-26 14:53:31,319 Epoch[15] Batch [1460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125472,	
2017-06-26 14:53:36,667 Epoch[15] Batch [1470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125395,	
2017-06-26 14:53:41,984 Epoch[15] Batch [1480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125441,	
2017-06-26 14:53:45,240 Epoch[15] Train-FCNLogLoss=0.125431
2017-06-26 14:53:45,240 Epoch[15] Time cost=795.529
2017-06-26 14:53:46,457 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0016.params"
2017-06-26 14:53:50,200 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0016.states"
2017-06-26 14:53:56,581 Epoch[16] Batch [10]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.112642,	
2017-06-26 14:54:01,885 Epoch[16] Batch [20]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118735,	
2017-06-26 14:54:07,210 Epoch[16] Batch [30]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121928,	
2017-06-26 14:54:12,824 Epoch[16] Batch [40]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.122672,	
2017-06-26 14:54:19,539 Epoch[16] Batch [50]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.120679,	
2017-06-26 14:54:25,263 Epoch[16] Batch [60]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.120680,	
2017-06-26 14:54:30,860 Epoch[16] Batch [70]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.123192,	
2017-06-26 14:54:36,683 Epoch[16] Batch [80]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122004,	
2017-06-26 14:54:42,373 Epoch[16] Batch [90]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.120731,	
2017-06-26 14:54:47,879 Epoch[16] Batch [100]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.121489,	
2017-06-26 14:54:53,322 Epoch[16] Batch [110]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.120043,	
2017-06-26 14:54:58,689 Epoch[16] Batch [120]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119682,	
2017-06-26 14:55:03,963 Epoch[16] Batch [130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.120009,	
2017-06-26 14:55:09,616 Epoch[16] Batch [140]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.119555,	
2017-06-26 14:55:15,433 Epoch[16] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118937,	
2017-06-26 14:55:21,060 Epoch[16] Batch [160]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.119510,	
2017-06-26 14:55:26,474 Epoch[16] Batch [170]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.119517,	
2017-06-26 14:55:31,849 Epoch[16] Batch [180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119907,	
2017-06-26 14:55:37,136 Epoch[16] Batch [190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.120551,	
2017-06-26 14:55:42,488 Epoch[16] Batch [200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.120056,	
2017-06-26 14:55:47,804 Epoch[16] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119681,	
2017-06-26 14:55:53,121 Epoch[16] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119706,	
2017-06-26 14:55:58,643 Epoch[16] Batch [230]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.119906,	
2017-06-26 14:56:03,944 Epoch[16] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.120772,	
2017-06-26 14:56:09,447 Epoch[16] Batch [250]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.120710,	
2017-06-26 14:56:14,646 Epoch[16] Batch [260]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.120476,	
2017-06-26 14:56:20,210 Epoch[16] Batch [270]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.120451,	
2017-06-26 14:56:25,720 Epoch[16] Batch [280]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.120570,	
2017-06-26 14:56:31,186 Epoch[16] Batch [290]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.120293,	
2017-06-26 14:56:36,894 Epoch[16] Batch [300]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.119953,	
2017-06-26 14:56:42,566 Epoch[16] Batch [310]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.120405,	
2017-06-26 14:56:47,913 Epoch[16] Batch [320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.120329,	
2017-06-26 14:56:53,319 Epoch[16] Batch [330]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.120368,	
2017-06-26 14:56:58,691 Epoch[16] Batch [340]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.120375,	
2017-06-26 14:57:04,237 Epoch[16] Batch [350]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.120511,	
2017-06-26 14:57:09,507 Epoch[16] Batch [360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.120824,	
2017-06-26 14:57:14,911 Epoch[16] Batch [370]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.120914,	
2017-06-26 14:57:20,169 Epoch[16] Batch [380]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.120950,	
2017-06-26 14:57:25,504 Epoch[16] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.120800,	
2017-06-26 14:57:30,930 Epoch[16] Batch [400]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.120811,	
2017-06-26 14:57:36,171 Epoch[16] Batch [410]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120926,	
2017-06-26 14:57:41,536 Epoch[16] Batch [420]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.120660,	
2017-06-26 14:57:46,940 Epoch[16] Batch [430]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.120513,	
2017-06-26 14:57:52,290 Epoch[16] Batch [440]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.120404,	
2017-06-26 14:57:57,662 Epoch[16] Batch [450]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.120493,	
2017-06-26 14:58:03,218 Epoch[16] Batch [460]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.120331,	
2017-06-26 14:58:08,533 Epoch[16] Batch [470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.120601,	
2017-06-26 14:58:13,848 Epoch[16] Batch [480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.120548,	
2017-06-26 14:58:19,243 Epoch[16] Batch [490]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.120724,	
2017-06-26 14:58:24,829 Epoch[16] Batch [500]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.120898,	
2017-06-26 14:58:30,087 Epoch[16] Batch [510]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.120808,	
2017-06-26 14:58:35,433 Epoch[16] Batch [520]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121111,	
2017-06-26 14:58:40,768 Epoch[16] Batch [530]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121531,	
2017-06-26 14:58:46,266 Epoch[16] Batch [540]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.121451,	
2017-06-26 14:58:52,025 Epoch[16] Batch [550]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121433,	
2017-06-26 14:58:57,290 Epoch[16] Batch [560]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121242,	
2017-06-26 14:59:02,609 Epoch[16] Batch [570]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121303,	
2017-06-26 14:59:08,023 Epoch[16] Batch [580]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.121643,	
2017-06-26 14:59:13,874 Epoch[16] Batch [590]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.121794,	
2017-06-26 14:59:19,776 Epoch[16] Batch [600]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.121853,	
2017-06-26 14:59:25,117 Epoch[16] Batch [610]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121868,	
2017-06-26 14:59:30,455 Epoch[16] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121655,	
2017-06-26 14:59:35,694 Epoch[16] Batch [630]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.121820,	
2017-06-26 14:59:41,089 Epoch[16] Batch [640]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.121489,	
2017-06-26 14:59:46,400 Epoch[16] Batch [650]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121281,	
2017-06-26 14:59:51,789 Epoch[16] Batch [660]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.121540,	
2017-06-26 14:59:57,094 Epoch[16] Batch [670]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121525,	
2017-06-26 15:00:02,460 Epoch[16] Batch [680]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.121430,	
2017-06-26 15:00:07,720 Epoch[16] Batch [690]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121395,	
2017-06-26 15:00:13,102 Epoch[16] Batch [700]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.121284,	
2017-06-26 15:00:18,374 Epoch[16] Batch [710]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121797,	
2017-06-26 15:00:23,711 Epoch[16] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121894,	
2017-06-26 15:00:29,435 Epoch[16] Batch [730]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.121865,	
2017-06-26 15:00:35,401 Epoch[16] Batch [740]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.121851,	
2017-06-26 15:00:40,890 Epoch[16] Batch [750]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.121675,	
2017-06-26 15:00:46,207 Epoch[16] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121692,	
2017-06-26 15:00:51,521 Epoch[16] Batch [770]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121562,	
2017-06-26 15:00:56,890 Epoch[16] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121434,	
2017-06-26 15:01:02,264 Epoch[16] Batch [790]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121526,	
2017-06-26 15:01:07,565 Epoch[16] Batch [800]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121416,	
2017-06-26 15:01:12,979 Epoch[16] Batch [810]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.121465,	
2017-06-26 15:01:18,264 Epoch[16] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121361,	
2017-06-26 15:01:23,826 Epoch[16] Batch [830]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.121385,	
2017-06-26 15:01:29,115 Epoch[16] Batch [840]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.121324,	
2017-06-26 15:01:34,514 Epoch[16] Batch [850]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.121243,	
2017-06-26 15:01:39,799 Epoch[16] Batch [860]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121362,	
2017-06-26 15:01:45,147 Epoch[16] Batch [870]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121473,	
2017-06-26 15:01:50,468 Epoch[16] Batch [880]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121452,	
2017-06-26 15:01:55,803 Epoch[16] Batch [890]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121828,	
2017-06-26 15:02:01,146 Epoch[16] Batch [900]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121906,	
2017-06-26 15:02:06,548 Epoch[16] Batch [910]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.121727,	
2017-06-26 15:02:12,111 Epoch[16] Batch [920]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.121823,	
2017-06-26 15:02:17,416 Epoch[16] Batch [930]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121926,	
2017-06-26 15:02:22,796 Epoch[16] Batch [940]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121823,	
2017-06-26 15:02:28,094 Epoch[16] Batch [950]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121848,	
2017-06-26 15:02:33,147 Epoch[16] Batch [960]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.121927,	
2017-06-26 15:02:37,926 Epoch[16] Batch [970]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.121876,	
2017-06-26 15:02:43,161 Epoch[16] Batch [980]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.121849,	
2017-06-26 15:02:48,562 Epoch[16] Batch [990]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.122000,	
2017-06-26 15:02:53,880 Epoch[16] Batch [1000]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.122062,	
2017-06-26 15:02:59,157 Epoch[16] Batch [1010]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121982,	
2017-06-26 15:03:04,567 Epoch[16] Batch [1020]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.121894,	
2017-06-26 15:03:09,870 Epoch[16] Batch [1030]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121725,	
2017-06-26 15:03:15,362 Epoch[16] Batch [1040]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.121697,	
2017-06-26 15:03:20,811 Epoch[16] Batch [1050]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.121680,	
2017-06-26 15:03:26,201 Epoch[16] Batch [1060]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.121664,	
2017-06-26 15:03:31,582 Epoch[16] Batch [1070]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121749,	
2017-06-26 15:03:36,924 Epoch[16] Batch [1080]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121706,	
2017-06-26 15:03:42,186 Epoch[16] Batch [1090]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121630,	
2017-06-26 15:03:47,521 Epoch[16] Batch [1100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121602,	
2017-06-26 15:03:52,822 Epoch[16] Batch [1110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121525,	
2017-06-26 15:03:58,153 Epoch[16] Batch [1120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121513,	
2017-06-26 15:04:03,495 Epoch[16] Batch [1130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121464,	
2017-06-26 15:04:08,868 Epoch[16] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121437,	
2017-06-26 15:04:14,138 Epoch[16] Batch [1150]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121522,	
2017-06-26 15:04:19,517 Epoch[16] Batch [1160]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121626,	
2017-06-26 15:04:24,930 Epoch[16] Batch [1170]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.121531,	
2017-06-26 15:04:30,258 Epoch[16] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121603,	
2017-06-26 15:04:35,524 Epoch[16] Batch [1190]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121557,	
2017-06-26 15:04:40,898 Epoch[16] Batch [1200]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121537,	
2017-06-26 15:04:46,202 Epoch[16] Batch [1210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121481,	
2017-06-26 15:04:51,559 Epoch[16] Batch [1220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121412,	
2017-06-26 15:04:56,911 Epoch[16] Batch [1230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121440,	
2017-06-26 15:05:02,283 Epoch[16] Batch [1240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121361,	
2017-06-26 15:05:07,659 Epoch[16] Batch [1250]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121433,	
2017-06-26 15:05:13,203 Epoch[16] Batch [1260]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.121351,	
2017-06-26 15:05:18,515 Epoch[16] Batch [1270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121303,	
2017-06-26 15:05:23,802 Epoch[16] Batch [1280]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121213,	
2017-06-26 15:05:29,131 Epoch[16] Batch [1290]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121210,	
2017-06-26 15:05:34,484 Epoch[16] Batch [1300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121191,	
2017-06-26 15:05:39,806 Epoch[16] Batch [1310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121209,	
2017-06-26 15:05:45,236 Epoch[16] Batch [1320]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.121118,	
2017-06-26 15:05:50,837 Epoch[16] Batch [1330]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.121103,	
2017-06-26 15:05:56,191 Epoch[16] Batch [1340]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121112,	
2017-06-26 15:06:01,566 Epoch[16] Batch [1350]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121138,	
2017-06-26 15:06:06,877 Epoch[16] Batch [1360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121117,	
2017-06-26 15:06:12,279 Epoch[16] Batch [1370]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.121094,	
2017-06-26 15:06:17,578 Epoch[16] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121095,	
2017-06-26 15:06:23,003 Epoch[16] Batch [1390]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.121353,	
2017-06-26 15:06:28,350 Epoch[16] Batch [1400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121297,	
2017-06-26 15:06:33,607 Epoch[16] Batch [1410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121399,	
2017-06-26 15:06:38,988 Epoch[16] Batch [1420]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121444,	
2017-06-26 15:06:44,275 Epoch[16] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121382,	
2017-06-26 15:06:49,651 Epoch[16] Batch [1440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121451,	
2017-06-26 15:06:55,021 Epoch[16] Batch [1450]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121360,	
2017-06-26 15:07:00,273 Epoch[16] Batch [1460]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121225,	
2017-06-26 15:07:05,602 Epoch[16] Batch [1470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121153,	
2017-06-26 15:07:10,965 Epoch[16] Batch [1480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.121066,	
2017-06-26 15:07:14,145 Epoch[16] Train-FCNLogLoss=0.121163
2017-06-26 15:07:14,145 Epoch[16] Time cost=803.945
2017-06-26 15:07:15,403 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0017.params"
2017-06-26 15:07:18,846 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0017.states"
2017-06-26 15:07:25,244 Epoch[17] Batch [10]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.121113,	
2017-06-26 15:07:30,884 Epoch[17] Batch [20]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.120462,	
2017-06-26 15:07:36,417 Epoch[17] Batch [30]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.123495,	
2017-06-26 15:07:41,765 Epoch[17] Batch [40]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.127490,	
2017-06-26 15:07:47,353 Epoch[17] Batch [50]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.127596,	
2017-06-26 15:07:53,145 Epoch[17] Batch [60]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.127031,	
2017-06-26 15:07:58,471 Epoch[17] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.126786,	
2017-06-26 15:08:03,777 Epoch[17] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.127163,	
2017-06-26 15:08:09,199 Epoch[17] Batch [90]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.128394,	
2017-06-26 15:08:14,498 Epoch[17] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.128346,	
2017-06-26 15:08:19,811 Epoch[17] Batch [110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129291,	
2017-06-26 15:08:25,408 Epoch[17] Batch [120]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.129177,	
2017-06-26 15:08:31,309 Epoch[17] Batch [130]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.127721,	
2017-06-26 15:08:37,007 Epoch[17] Batch [140]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.126040,	
2017-06-26 15:08:42,816 Epoch[17] Batch [150]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.126728,	
2017-06-26 15:08:48,764 Epoch[17] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.126949,	
2017-06-26 15:08:54,065 Epoch[17] Batch [170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.127257,	
2017-06-26 15:08:59,326 Epoch[17] Batch [180]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.126094,	
2017-06-26 15:09:05,058 Epoch[17] Batch [190]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.125094,	
2017-06-26 15:09:10,454 Epoch[17] Batch [200]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.124431,	
2017-06-26 15:09:15,765 Epoch[17] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123347,	
2017-06-26 15:09:21,166 Epoch[17] Batch [220]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.123575,	
2017-06-26 15:09:26,478 Epoch[17] Batch [230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.122971,	
2017-06-26 15:09:32,095 Epoch[17] Batch [240]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.122940,	
2017-06-26 15:09:37,914 Epoch[17] Batch [250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122437,	
2017-06-26 15:09:43,203 Epoch[17] Batch [260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122539,	
2017-06-26 15:09:48,504 Epoch[17] Batch [270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.122429,	
2017-06-26 15:09:53,855 Epoch[17] Batch [280]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122321,	
2017-06-26 15:09:59,199 Epoch[17] Batch [290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.122200,	
2017-06-26 15:10:04,563 Epoch[17] Batch [300]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.121951,	
2017-06-26 15:10:09,892 Epoch[17] Batch [310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121583,	
2017-06-26 15:10:15,235 Epoch[17] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121234,	
2017-06-26 15:10:20,589 Epoch[17] Batch [330]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121260,	
2017-06-26 15:10:25,917 Epoch[17] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121506,	
2017-06-26 15:10:31,327 Epoch[17] Batch [350]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.121489,	
2017-06-26 15:10:36,615 Epoch[17] Batch [360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121067,	
2017-06-26 15:10:41,935 Epoch[17] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.120647,	
2017-06-26 15:10:47,323 Epoch[17] Batch [380]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.120815,	
2017-06-26 15:10:52,679 Epoch[17] Batch [390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121046,	
2017-06-26 15:10:58,055 Epoch[17] Batch [400]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121187,	
2017-06-26 15:11:03,457 Epoch[17] Batch [410]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.121552,	
2017-06-26 15:11:08,713 Epoch[17] Batch [420]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121581,	
2017-06-26 15:11:14,381 Epoch[17] Batch [430]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.121432,	
2017-06-26 15:11:20,285 Epoch[17] Batch [440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.121425,	
2017-06-26 15:11:25,817 Epoch[17] Batch [450]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.121379,	
2017-06-26 15:11:31,080 Epoch[17] Batch [460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121635,	
2017-06-26 15:11:36,498 Epoch[17] Batch [470]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.121494,	
2017-06-26 15:11:41,795 Epoch[17] Batch [480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121541,	
2017-06-26 15:11:47,125 Epoch[17] Batch [490]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121827,	
2017-06-26 15:11:52,534 Epoch[17] Batch [500]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.121479,	
2017-06-26 15:11:57,962 Epoch[17] Batch [510]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.121662,	
2017-06-26 15:12:03,310 Epoch[17] Batch [520]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122077,	
2017-06-26 15:12:08,650 Epoch[17] Batch [530]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.122548,	
2017-06-26 15:12:14,012 Epoch[17] Batch [540]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.124218,	
2017-06-26 15:12:19,320 Epoch[17] Batch [550]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124905,	
2017-06-26 15:12:24,719 Epoch[17] Batch [560]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.125370,	
2017-06-26 15:12:30,044 Epoch[17] Batch [570]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125725,	
2017-06-26 15:12:35,355 Epoch[17] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125857,	
2017-06-26 15:12:40,724 Epoch[17] Batch [590]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125969,	
2017-06-26 15:12:46,056 Epoch[17] Batch [600]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126063,	
2017-06-26 15:12:51,722 Epoch[17] Batch [610]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.125890,	
2017-06-26 15:12:57,010 Epoch[17] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125939,	
2017-06-26 15:13:02,302 Epoch[17] Batch [630]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125782,	
2017-06-26 15:13:07,777 Epoch[17] Batch [640]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.125609,	
2017-06-26 15:13:13,044 Epoch[17] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125526,	
2017-06-26 15:13:18,407 Epoch[17] Batch [660]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125949,	
2017-06-26 15:13:23,732 Epoch[17] Batch [670]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125751,	
2017-06-26 15:13:29,089 Epoch[17] Batch [680]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.126014,	
2017-06-26 15:13:34,469 Epoch[17] Batch [690]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.126168,	
2017-06-26 15:13:39,746 Epoch[17] Batch [700]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.126324,	
2017-06-26 15:13:45,122 Epoch[17] Batch [710]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.126259,	
2017-06-26 15:13:50,455 Epoch[17] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126457,	
2017-06-26 15:13:55,822 Epoch[17] Batch [730]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126293,	
2017-06-26 15:14:01,130 Epoch[17] Batch [740]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.126180,	
2017-06-26 15:14:06,511 Epoch[17] Batch [750]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.126087,	
2017-06-26 15:14:11,948 Epoch[17] Batch [760]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.125973,	
2017-06-26 15:14:17,160 Epoch[17] Batch [770]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.125922,	
2017-06-26 15:14:22,622 Epoch[17] Batch [780]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.126005,	
2017-06-26 15:14:27,880 Epoch[17] Batch [790]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125852,	
2017-06-26 15:14:33,258 Epoch[17] Batch [800]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125797,	
2017-06-26 15:14:38,465 Epoch[17] Batch [810]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.125782,	
2017-06-26 15:14:43,803 Epoch[17] Batch [820]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125716,	
2017-06-26 15:14:49,174 Epoch[17] Batch [830]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125718,	
2017-06-26 15:14:54,452 Epoch[17] Batch [840]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125730,	
2017-06-26 15:14:59,747 Epoch[17] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125735,	
2017-06-26 15:15:05,145 Epoch[17] Batch [860]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.126030,	
2017-06-26 15:15:11,115 Epoch[17] Batch [870]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.126159,	
2017-06-26 15:15:16,770 Epoch[17] Batch [880]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.126101,	
2017-06-26 15:15:22,329 Epoch[17] Batch [890]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.126334,	
2017-06-26 15:15:27,946 Epoch[17] Batch [900]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.126404,	
2017-06-26 15:15:33,735 Epoch[17] Batch [910]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.126506,	
2017-06-26 15:15:39,030 Epoch[17] Batch [920]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126553,	
2017-06-26 15:15:44,557 Epoch[17] Batch [930]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.126486,	
2017-06-26 15:15:50,300 Epoch[17] Batch [940]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.126460,	
2017-06-26 15:15:56,210 Epoch[17] Batch [950]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.126477,	
2017-06-26 15:16:01,586 Epoch[17] Batch [960]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.126376,	
2017-06-26 15:16:07,439 Epoch[17] Batch [970]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.126263,	
2017-06-26 15:16:12,719 Epoch[17] Batch [980]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.126289,	
2017-06-26 15:16:18,084 Epoch[17] Batch [990]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.126250,	
2017-06-26 15:16:23,423 Epoch[17] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.126262,	
2017-06-26 15:16:28,733 Epoch[17] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.126207,	
2017-06-26 15:16:34,157 Epoch[17] Batch [1020]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.126110,	
2017-06-26 15:16:39,514 Epoch[17] Batch [1030]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125931,	
2017-06-26 15:16:44,873 Epoch[17] Batch [1040]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125827,	
2017-06-26 15:16:50,212 Epoch[17] Batch [1050]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125756,	
2017-06-26 15:16:55,541 Epoch[17] Batch [1060]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125629,	
2017-06-26 15:17:00,927 Epoch[17] Batch [1070]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125603,	
2017-06-26 15:17:06,526 Epoch[17] Batch [1080]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.125492,	
2017-06-26 15:17:11,831 Epoch[17] Batch [1090]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125498,	
2017-06-26 15:17:17,497 Epoch[17] Batch [1100]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.125400,	
2017-06-26 15:17:23,046 Epoch[17] Batch [1110]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.125524,	
2017-06-26 15:17:28,285 Epoch[17] Batch [1120]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125563,	
2017-06-26 15:17:33,603 Epoch[17] Batch [1130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125466,	
2017-06-26 15:17:38,944 Epoch[17] Batch [1140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125415,	
2017-06-26 15:17:44,256 Epoch[17] Batch [1150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125293,	
2017-06-26 15:17:49,630 Epoch[17] Batch [1160]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125219,	
2017-06-26 15:17:55,304 Epoch[17] Batch [1170]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.125159,	
2017-06-26 15:18:00,965 Epoch[17] Batch [1180]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.125037,	
2017-06-26 15:18:06,442 Epoch[17] Batch [1190]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.124935,	
2017-06-26 15:18:11,827 Epoch[17] Batch [1200]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125043,	
2017-06-26 15:18:17,435 Epoch[17] Batch [1210]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.125040,	
2017-06-26 15:18:22,687 Epoch[17] Batch [1220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.124864,	
2017-06-26 15:18:28,054 Epoch[17] Batch [1230]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.124705,	
2017-06-26 15:18:33,363 Epoch[17] Batch [1240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124778,	
2017-06-26 15:18:38,750 Epoch[17] Batch [1250]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.124732,	
2017-06-26 15:18:44,105 Epoch[17] Batch [1260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124733,	
2017-06-26 15:18:49,483 Epoch[17] Batch [1270]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.124696,	
2017-06-26 15:18:54,750 Epoch[17] Batch [1280]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124932,	
2017-06-26 15:19:00,115 Epoch[17] Batch [1290]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125239,	
2017-06-26 15:19:05,460 Epoch[17] Batch [1300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125306,	
2017-06-26 15:19:10,785 Epoch[17] Batch [1310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125271,	
2017-06-26 15:19:16,110 Epoch[17] Batch [1320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125277,	
2017-06-26 15:19:21,541 Epoch[17] Batch [1330]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.125363,	
2017-06-26 15:19:26,806 Epoch[17] Batch [1340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125414,	
2017-06-26 15:19:32,175 Epoch[17] Batch [1350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125388,	
2017-06-26 15:19:37,466 Epoch[17] Batch [1360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125334,	
2017-06-26 15:19:42,911 Epoch[17] Batch [1370]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.125250,	
2017-06-26 15:19:48,184 Epoch[17] Batch [1380]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.125264,	
2017-06-26 15:19:53,553 Epoch[17] Batch [1390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125265,	
2017-06-26 15:19:59,063 Epoch[17] Batch [1400]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.125237,	
2017-06-26 15:20:04,436 Epoch[17] Batch [1410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125240,	
2017-06-26 15:20:09,758 Epoch[17] Batch [1420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125262,	
2017-06-26 15:20:15,110 Epoch[17] Batch [1430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125242,	
2017-06-26 15:20:20,418 Epoch[17] Batch [1440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125245,	
2017-06-26 15:20:25,804 Epoch[17] Batch [1450]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125229,	
2017-06-26 15:20:31,163 Epoch[17] Batch [1460]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125291,	
2017-06-26 15:20:36,460 Epoch[17] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125276,	
2017-06-26 15:20:41,757 Epoch[17] Batch [1480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125193,	
2017-06-26 15:20:45,020 Epoch[17] Train-FCNLogLoss=0.125144
2017-06-26 15:20:45,021 Epoch[17] Time cost=806.173
2017-06-26 15:20:46,197 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0018.params"
2017-06-26 15:20:49,482 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0018.states"
2017-06-26 15:20:55,668 Epoch[18] Batch [10]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126389,	
2017-06-26 15:21:01,063 Epoch[18] Batch [20]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.120519,	
2017-06-26 15:21:06,899 Epoch[18] Batch [30]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.119195,	
2017-06-26 15:21:12,786 Epoch[18] Batch [40]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.119113,	
2017-06-26 15:21:18,658 Epoch[18] Batch [50]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.118304,	
2017-06-26 15:21:24,326 Epoch[18] Batch [60]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.118967,	
2017-06-26 15:21:29,642 Epoch[18] Batch [70]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119003,	
2017-06-26 15:21:34,994 Epoch[18] Batch [80]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.119991,	
2017-06-26 15:21:40,338 Epoch[18] Batch [90]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.120162,	
2017-06-26 15:21:45,677 Epoch[18] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118965,	
2017-06-26 15:21:51,041 Epoch[18] Batch [110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119148,	
2017-06-26 15:21:56,386 Epoch[18] Batch [120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119911,	
2017-06-26 15:22:01,804 Epoch[18] Batch [130]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.120039,	
2017-06-26 15:22:07,130 Epoch[18] Batch [140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119366,	
2017-06-26 15:22:12,428 Epoch[18] Batch [150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.119028,	
2017-06-26 15:22:17,761 Epoch[18] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119057,	
2017-06-26 15:22:23,095 Epoch[18] Batch [170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118867,	
2017-06-26 15:22:28,415 Epoch[18] Batch [180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118174,	
2017-06-26 15:22:33,744 Epoch[18] Batch [190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117639,	
2017-06-26 15:22:39,119 Epoch[18] Batch [200]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117808,	
2017-06-26 15:22:44,438 Epoch[18] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.117878,	
2017-06-26 15:22:49,800 Epoch[18] Batch [220]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117702,	
2017-06-26 15:22:55,108 Epoch[18] Batch [230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117198,	
2017-06-26 15:23:00,516 Epoch[18] Batch [240]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.117030,	
2017-06-26 15:23:05,865 Epoch[18] Batch [250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117285,	
2017-06-26 15:23:11,117 Epoch[18] Batch [260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.116993,	
2017-06-26 15:23:16,414 Epoch[18] Batch [270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116799,	
2017-06-26 15:23:21,792 Epoch[18] Batch [280]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.116759,	
2017-06-26 15:23:27,089 Epoch[18] Batch [290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.117182,	
2017-06-26 15:23:32,444 Epoch[18] Batch [300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117943,	
2017-06-26 15:23:37,790 Epoch[18] Batch [310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118436,	
2017-06-26 15:23:43,182 Epoch[18] Batch [320]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.118920,	
2017-06-26 15:23:48,486 Epoch[18] Batch [330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118890,	
2017-06-26 15:23:53,810 Epoch[18] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118334,	
2017-06-26 15:23:59,186 Epoch[18] Batch [350]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118473,	
2017-06-26 15:24:04,501 Epoch[18] Batch [360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118703,	
2017-06-26 15:24:09,822 Epoch[18] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118734,	
2017-06-26 15:24:15,167 Epoch[18] Batch [380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118643,	
2017-06-26 15:24:20,528 Epoch[18] Batch [390]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118446,	
2017-06-26 15:24:25,899 Epoch[18] Batch [400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118616,	
2017-06-26 15:24:31,193 Epoch[18] Batch [410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118777,	
2017-06-26 15:24:36,569 Epoch[18] Batch [420]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118384,	
2017-06-26 15:24:41,884 Epoch[18] Batch [430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118219,	
2017-06-26 15:24:47,207 Epoch[18] Batch [440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118130,	
2017-06-26 15:24:52,547 Epoch[18] Batch [450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118091,	
2017-06-26 15:24:57,930 Epoch[18] Batch [460]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118040,	
2017-06-26 15:25:03,217 Epoch[18] Batch [470]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.118078,	
2017-06-26 15:25:08,596 Epoch[18] Batch [480]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117931,	
2017-06-26 15:25:13,940 Epoch[18] Batch [490]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118051,	
2017-06-26 15:25:19,213 Epoch[18] Batch [500]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118202,	
2017-06-26 15:25:24,549 Epoch[18] Batch [510]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118201,	
2017-06-26 15:25:29,964 Epoch[18] Batch [520]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.118351,	
2017-06-26 15:25:35,285 Epoch[18] Batch [530]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118445,	
2017-06-26 15:25:40,697 Epoch[18] Batch [540]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.118640,	
2017-06-26 15:25:45,903 Epoch[18] Batch [550]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.118423,	
2017-06-26 15:25:51,258 Epoch[18] Batch [560]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118382,	
2017-06-26 15:25:56,624 Epoch[18] Batch [570]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118391,	
2017-06-26 15:26:01,974 Epoch[18] Batch [580]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118685,	
2017-06-26 15:26:07,250 Epoch[18] Batch [590]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119155,	
2017-06-26 15:26:12,634 Epoch[18] Batch [600]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.119038,	
2017-06-26 15:26:17,930 Epoch[18] Batch [610]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118779,	
2017-06-26 15:26:23,330 Epoch[18] Batch [620]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.119068,	
2017-06-26 15:26:28,665 Epoch[18] Batch [630]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119560,	
2017-06-26 15:26:33,990 Epoch[18] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119665,	
2017-06-26 15:26:39,394 Epoch[18] Batch [650]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.119569,	
2017-06-26 15:26:44,673 Epoch[18] Batch [660]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119420,	
2017-06-26 15:26:50,064 Epoch[18] Batch [670]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119423,	
2017-06-26 15:26:55,387 Epoch[18] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119312,	
2017-06-26 15:27:00,747 Epoch[18] Batch [690]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119454,	
2017-06-26 15:27:06,051 Epoch[18] Batch [700]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119603,	
2017-06-26 15:27:11,362 Epoch[18] Batch [710]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119429,	
2017-06-26 15:27:16,688 Epoch[18] Batch [720]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119712,	
2017-06-26 15:27:22,061 Epoch[18] Batch [730]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119668,	
2017-06-26 15:27:27,353 Epoch[18] Batch [740]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.119640,	
2017-06-26 15:27:32,837 Epoch[18] Batch [750]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.119633,	
2017-06-26 15:27:38,055 Epoch[18] Batch [760]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.119699,	
2017-06-26 15:27:43,407 Epoch[18] Batch [770]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119549,	
2017-06-26 15:27:48,727 Epoch[18] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119600,	
2017-06-26 15:27:54,049 Epoch[18] Batch [790]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119599,	
2017-06-26 15:27:59,409 Epoch[18] Batch [800]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119552,	
2017-06-26 15:28:04,713 Epoch[18] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119577,	
2017-06-26 15:28:10,147 Epoch[18] Batch [820]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.119542,	
2017-06-26 15:28:15,397 Epoch[18] Batch [830]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.119414,	
2017-06-26 15:28:20,769 Epoch[18] Batch [840]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119386,	
2017-06-26 15:28:26,063 Epoch[18] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.119382,	
2017-06-26 15:28:31,408 Epoch[18] Batch [860]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119344,	
2017-06-26 15:28:36,872 Epoch[18] Batch [870]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.119467,	
2017-06-26 15:28:42,331 Epoch[18] Batch [880]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.119545,	
2017-06-26 15:28:47,659 Epoch[18] Batch [890]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119555,	
2017-06-26 15:28:52,837 Epoch[18] Batch [900]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.119541,	
2017-06-26 15:28:58,336 Epoch[18] Batch [910]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.119595,	
2017-06-26 15:29:03,673 Epoch[18] Batch [920]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119831,	
2017-06-26 15:29:09,111 Epoch[18] Batch [930]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.119634,	
2017-06-26 15:29:14,724 Epoch[18] Batch [940]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.119529,	
2017-06-26 15:29:20,065 Epoch[18] Batch [950]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119638,	
2017-06-26 15:29:25,337 Epoch[18] Batch [960]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119602,	
2017-06-26 15:29:30,927 Epoch[18] Batch [970]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.119893,	
2017-06-26 15:29:36,238 Epoch[18] Batch [980]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119874,	
2017-06-26 15:29:41,677 Epoch[18] Batch [990]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.119955,	
2017-06-26 15:29:47,250 Epoch[18] Batch [1000]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.119941,	
2017-06-26 15:29:52,567 Epoch[18] Batch [1010]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119854,	
2017-06-26 15:29:57,854 Epoch[18] Batch [1020]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.119828,	
2017-06-26 15:30:03,186 Epoch[18] Batch [1030]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119739,	
2017-06-26 15:30:08,653 Epoch[18] Batch [1040]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.119493,	
2017-06-26 15:30:14,734 Epoch[18] Batch [1050]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.119491,	
2017-06-26 15:30:20,397 Epoch[18] Batch [1060]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.119573,	
2017-06-26 15:30:25,638 Epoch[18] Batch [1070]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.119492,	
2017-06-26 15:30:31,072 Epoch[18] Batch [1080]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.119440,	
2017-06-26 15:30:36,981 Epoch[18] Batch [1090]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.119385,	
2017-06-26 15:30:42,927 Epoch[18] Batch [1100]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.119295,	
2017-06-26 15:30:48,291 Epoch[18] Batch [1110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119392,	
2017-06-26 15:30:54,120 Epoch[18] Batch [1120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.119290,	
2017-06-26 15:30:59,408 Epoch[18] Batch [1130]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.119150,	
2017-06-26 15:31:04,718 Epoch[18] Batch [1140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119075,	
2017-06-26 15:31:10,077 Epoch[18] Batch [1150]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.119183,	
2017-06-26 15:31:15,426 Epoch[18] Batch [1160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119109,	
2017-06-26 15:31:20,887 Epoch[18] Batch [1170]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.119141,	
2017-06-26 15:31:26,080 Epoch[18] Batch [1180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.118988,	
2017-06-26 15:31:31,411 Epoch[18] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119050,	
2017-06-26 15:31:36,768 Epoch[18] Batch [1200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.119027,	
2017-06-26 15:31:42,084 Epoch[18] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118939,	
2017-06-26 15:31:47,430 Epoch[18] Batch [1220]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118966,	
2017-06-26 15:31:52,738 Epoch[18] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118933,	
2017-06-26 15:31:58,077 Epoch[18] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118899,	
2017-06-26 15:32:03,429 Epoch[18] Batch [1250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119042,	
2017-06-26 15:32:08,772 Epoch[18] Batch [1260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119098,	
2017-06-26 15:32:14,133 Epoch[18] Batch [1270]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119248,	
2017-06-26 15:32:19,523 Epoch[18] Batch [1280]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119175,	
2017-06-26 15:32:24,827 Epoch[18] Batch [1290]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119185,	
2017-06-26 15:32:30,224 Epoch[18] Batch [1300]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.119237,	
2017-06-26 15:32:35,581 Epoch[18] Batch [1310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.119260,	
2017-06-26 15:32:40,896 Epoch[18] Batch [1320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119202,	
2017-06-26 15:32:46,271 Epoch[18] Batch [1330]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119238,	
2017-06-26 15:32:51,583 Epoch[18] Batch [1340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119337,	
2017-06-26 15:32:56,928 Epoch[18] Batch [1350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119294,	
2017-06-26 15:33:02,312 Epoch[18] Batch [1360]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.119225,	
2017-06-26 15:33:07,610 Epoch[18] Batch [1370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.119143,	
2017-06-26 15:33:12,947 Epoch[18] Batch [1380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119062,	
2017-06-26 15:33:18,329 Epoch[18] Batch [1390]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118997,	
2017-06-26 15:33:23,842 Epoch[18] Batch [1400]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.118991,	
2017-06-26 15:33:29,028 Epoch[18] Batch [1410]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.118977,	
2017-06-26 15:33:34,469 Epoch[18] Batch [1420]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.118934,	
2017-06-26 15:33:39,717 Epoch[18] Batch [1430]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.119016,	
2017-06-26 15:33:45,163 Epoch[18] Batch [1440]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.119086,	
2017-06-26 15:33:50,436 Epoch[18] Batch [1450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119084,	
2017-06-26 15:33:55,741 Epoch[18] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119054,	
2017-06-26 15:34:01,319 Epoch[18] Batch [1470]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.119073,	
2017-06-26 15:34:06,644 Epoch[18] Batch [1480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119028,	
2017-06-26 15:34:09,801 Epoch[18] Train-FCNLogLoss=0.119060
2017-06-26 15:34:09,801 Epoch[18] Time cost=800.319
2017-06-26 15:34:11,149 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0019.params"
2017-06-26 15:34:14,964 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0019.states"
2017-06-26 15:34:21,384 Epoch[19] Batch [10]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.114528,	
2017-06-26 15:34:26,750 Epoch[19] Batch [20]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.107827,	
2017-06-26 15:34:32,107 Epoch[19] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.107479,	
2017-06-26 15:34:37,414 Epoch[19] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.109876,	
2017-06-26 15:34:42,770 Epoch[19] Batch [50]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.111553,	
2017-06-26 15:34:48,063 Epoch[19] Batch [60]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.111539,	
2017-06-26 15:34:53,452 Epoch[19] Batch [70]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.112486,	
2017-06-26 15:34:58,818 Epoch[19] Batch [80]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.113444,	
2017-06-26 15:35:04,146 Epoch[19] Batch [90]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113270,	
2017-06-26 15:35:09,481 Epoch[19] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.112331,	
2017-06-26 15:35:14,904 Epoch[19] Batch [110]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.112022,	
2017-06-26 15:35:20,204 Epoch[19] Batch [120]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111343,	
2017-06-26 15:35:25,651 Epoch[19] Batch [130]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.112394,	
2017-06-26 15:35:30,865 Epoch[19] Batch [140]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112448,	
2017-06-26 15:35:36,161 Epoch[19] Batch [150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.112783,	
2017-06-26 15:35:42,009 Epoch[19] Batch [160]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.112066,	
2017-06-26 15:35:48,278 Epoch[19] Batch [170]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.111454,	
2017-06-26 15:35:54,810 Epoch[19] Batch [180]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.111708,	
2017-06-26 15:36:01,068 Epoch[19] Batch [190]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.111621,	
2017-06-26 15:36:06,983 Epoch[19] Batch [200]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.111970,	
2017-06-26 15:36:12,581 Epoch[19] Batch [210]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.112189,	
2017-06-26 15:36:18,713 Epoch[19] Batch [220]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.113528,	
2017-06-26 15:36:24,274 Epoch[19] Batch [230]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.113876,	
2017-06-26 15:36:30,263 Epoch[19] Batch [240]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113886,	
2017-06-26 15:36:35,854 Epoch[19] Batch [250]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.113932,	
2017-06-26 15:36:41,409 Epoch[19] Batch [260]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.114262,	
2017-06-26 15:36:46,926 Epoch[19] Batch [270]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.114147,	
2017-06-26 15:36:52,488 Epoch[19] Batch [280]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.114289,	
2017-06-26 15:36:57,962 Epoch[19] Batch [290]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.114162,	
2017-06-26 15:37:03,234 Epoch[19] Batch [300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113832,	
2017-06-26 15:37:08,641 Epoch[19] Batch [310]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.113993,	
2017-06-26 15:37:14,007 Epoch[19] Batch [320]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114400,	
2017-06-26 15:37:20,098 Epoch[19] Batch [330]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.114714,	
2017-06-26 15:37:26,774 Epoch[19] Batch [340]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.115277,	
2017-06-26 15:37:32,990 Epoch[19] Batch [350]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.115246,	
2017-06-26 15:37:38,589 Epoch[19] Batch [360]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.114983,	
2017-06-26 15:37:43,932 Epoch[19] Batch [370]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114903,	
2017-06-26 15:37:49,273 Epoch[19] Batch [380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114990,	
2017-06-26 15:37:54,645 Epoch[19] Batch [390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.115279,	
2017-06-26 15:37:59,893 Epoch[19] Batch [400]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.115437,	
2017-06-26 15:38:05,261 Epoch[19] Batch [410]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.115075,	
2017-06-26 15:38:10,600 Epoch[19] Batch [420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.115007,	
2017-06-26 15:38:16,087 Epoch[19] Batch [430]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.114770,	
2017-06-26 15:38:21,330 Epoch[19] Batch [440]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.114561,	
2017-06-26 15:38:26,620 Epoch[19] Batch [450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.114644,	
2017-06-26 15:38:31,893 Epoch[19] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.114207,	
2017-06-26 15:38:37,193 Epoch[19] Batch [470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.114357,	
2017-06-26 15:38:42,639 Epoch[19] Batch [480]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.114300,	
2017-06-26 15:38:47,994 Epoch[19] Batch [490]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.114257,	
2017-06-26 15:38:53,870 Epoch[19] Batch [500]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.114293,	
2017-06-26 15:38:59,587 Epoch[19] Batch [510]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.114416,	
2017-06-26 15:39:05,126 Epoch[19] Batch [520]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.114844,	
2017-06-26 15:39:10,367 Epoch[19] Batch [530]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.114757,	
2017-06-26 15:39:15,694 Epoch[19] Batch [540]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114771,	
2017-06-26 15:39:21,090 Epoch[19] Batch [550]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.114776,	
2017-06-26 15:39:26,395 Epoch[19] Batch [560]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114558,	
2017-06-26 15:39:31,768 Epoch[19] Batch [570]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114395,	
2017-06-26 15:39:37,097 Epoch[19] Batch [580]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114325,	
2017-06-26 15:39:42,349 Epoch[19] Batch [590]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.114370,	
2017-06-26 15:39:47,730 Epoch[19] Batch [600]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.114364,	
2017-06-26 15:39:53,132 Epoch[19] Batch [610]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.114441,	
2017-06-26 15:39:58,368 Epoch[19] Batch [620]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.114372,	
2017-06-26 15:40:03,785 Epoch[19] Batch [630]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.114740,	
2017-06-26 15:40:09,719 Epoch[19] Batch [640]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.114781,	
2017-06-26 15:40:15,558 Epoch[19] Batch [650]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.114714,	
2017-06-26 15:40:22,591 Epoch[19] Batch [660]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.114631,	
2017-06-26 15:40:28,478 Epoch[19] Batch [670]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.114626,	
2017-06-26 15:40:34,025 Epoch[19] Batch [680]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.114571,	
2017-06-26 15:40:39,425 Epoch[19] Batch [690]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.114597,	
2017-06-26 15:40:44,795 Epoch[19] Batch [700]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114630,	
2017-06-26 15:40:50,112 Epoch[19] Batch [710]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114680,	
2017-06-26 15:40:55,424 Epoch[19] Batch [720]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.114663,	
2017-06-26 15:41:00,816 Epoch[19] Batch [730]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.114502,	
2017-06-26 15:41:06,142 Epoch[19] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114607,	
2017-06-26 15:41:11,489 Epoch[19] Batch [750]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114622,	
2017-06-26 15:41:16,817 Epoch[19] Batch [760]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114600,	
2017-06-26 15:41:22,184 Epoch[19] Batch [770]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114580,	
2017-06-26 15:41:27,523 Epoch[19] Batch [780]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114508,	
2017-06-26 15:41:32,973 Epoch[19] Batch [790]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.114601,	
2017-06-26 15:41:38,262 Epoch[19] Batch [800]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.114574,	
2017-06-26 15:41:43,544 Epoch[19] Batch [810]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.114331,	
2017-06-26 15:41:48,868 Epoch[19] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114324,	
2017-06-26 15:41:54,212 Epoch[19] Batch [830]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114181,	
2017-06-26 15:41:59,252 Epoch[19] Batch [840]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.114212,	
2017-06-26 15:42:04,465 Epoch[19] Batch [850]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.114147,	
2017-06-26 15:42:09,830 Epoch[19] Batch [860]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.113987,	
2017-06-26 15:42:15,178 Epoch[19] Batch [870]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114036,	
2017-06-26 15:42:20,526 Epoch[19] Batch [880]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114018,	
2017-06-26 15:42:25,909 Epoch[19] Batch [890]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.114017,	
2017-06-26 15:42:31,251 Epoch[19] Batch [900]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113941,	
2017-06-26 15:42:36,545 Epoch[19] Batch [910]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.113914,	
2017-06-26 15:42:41,883 Epoch[19] Batch [920]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113892,	
2017-06-26 15:42:47,178 Epoch[19] Batch [930]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.113858,	
2017-06-26 15:42:52,531 Epoch[19] Batch [940]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113930,	
2017-06-26 15:42:57,873 Epoch[19] Batch [950]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113922,	
2017-06-26 15:43:03,624 Epoch[19] Batch [960]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.113932,	
2017-06-26 15:43:08,840 Epoch[19] Batch [970]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.113989,	
2017-06-26 15:43:14,460 Epoch[19] Batch [980]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.114148,	
2017-06-26 15:43:21,184 Epoch[19] Batch [990]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.114209,	
2017-06-26 15:43:26,941 Epoch[19] Batch [1000]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.114265,	
2017-06-26 15:43:32,517 Epoch[19] Batch [1010]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.114342,	
2017-06-26 15:43:38,025 Epoch[19] Batch [1020]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.114594,	
2017-06-26 15:43:43,324 Epoch[19] Batch [1030]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.114869,	
2017-06-26 15:43:48,734 Epoch[19] Batch [1040]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.114955,	
2017-06-26 15:43:54,033 Epoch[19] Batch [1050]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.115089,	
2017-06-26 15:43:59,405 Epoch[19] Batch [1060]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114996,	
2017-06-26 15:44:04,709 Epoch[19] Batch [1070]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114969,	
2017-06-26 15:44:10,070 Epoch[19] Batch [1080]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.115106,	
2017-06-26 15:44:15,403 Epoch[19] Batch [1090]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.115296,	
2017-06-26 15:44:21,011 Epoch[19] Batch [1100]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.115199,	
2017-06-26 15:44:26,545 Epoch[19] Batch [1110]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.115100,	
2017-06-26 15:44:31,865 Epoch[19] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.115152,	
2017-06-26 15:44:37,129 Epoch[19] Batch [1130]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.115266,	
2017-06-26 15:44:42,498 Epoch[19] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.115232,	
2017-06-26 15:44:47,794 Epoch[19] Batch [1150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.115390,	
2017-06-26 15:44:53,117 Epoch[19] Batch [1160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.115388,	
2017-06-26 15:44:58,515 Epoch[19] Batch [1170]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.115381,	
2017-06-26 15:45:03,797 Epoch[19] Batch [1180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.115389,	
2017-06-26 15:45:09,164 Epoch[19] Batch [1190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.115507,	
2017-06-26 15:45:14,486 Epoch[19] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.115482,	
2017-06-26 15:45:19,846 Epoch[19] Batch [1210]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.115431,	
2017-06-26 15:45:25,209 Epoch[19] Batch [1220]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.115530,	
2017-06-26 15:45:30,514 Epoch[19] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.115560,	
2017-06-26 15:45:35,992 Epoch[19] Batch [1240]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.115590,	
2017-06-26 15:45:41,253 Epoch[19] Batch [1250]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.115588,	
2017-06-26 15:45:46,585 Epoch[19] Batch [1260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.115690,	
2017-06-26 15:45:51,876 Epoch[19] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.115797,	
2017-06-26 15:45:57,277 Epoch[19] Batch [1280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.115881,	
2017-06-26 15:46:02,539 Epoch[19] Batch [1290]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.115847,	
2017-06-26 15:46:07,992 Epoch[19] Batch [1300]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.115940,	
2017-06-26 15:46:13,198 Epoch[19] Batch [1310]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.115888,	
2017-06-26 15:46:18,575 Epoch[19] Batch [1320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.115856,	
2017-06-26 15:46:23,852 Epoch[19] Batch [1330]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.115868,	
2017-06-26 15:46:29,261 Epoch[19] Batch [1340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.115989,	
2017-06-26 15:46:34,620 Epoch[19] Batch [1350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116035,	
2017-06-26 15:46:40,038 Epoch[19] Batch [1360]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.116013,	
2017-06-26 15:46:45,320 Epoch[19] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116131,	
2017-06-26 15:46:50,673 Epoch[19] Batch [1380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116177,	
2017-06-26 15:46:56,112 Epoch[19] Batch [1390]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.116262,	
2017-06-26 15:47:01,388 Epoch[19] Batch [1400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.116371,	
2017-06-26 15:47:06,754 Epoch[19] Batch [1410]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116436,	
2017-06-26 15:47:12,052 Epoch[19] Batch [1420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116497,	
2017-06-26 15:47:17,688 Epoch[19] Batch [1430]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.116474,	
2017-06-26 15:47:23,022 Epoch[19] Batch [1440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116549,	
2017-06-26 15:47:28,331 Epoch[19] Batch [1450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116535,	
2017-06-26 15:47:33,576 Epoch[19] Batch [1460]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.116584,	
2017-06-26 15:47:38,950 Epoch[19] Batch [1470]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.116705,	
2017-06-26 15:47:44,314 Epoch[19] Batch [1480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116747,	
2017-06-26 15:47:47,574 Epoch[19] Train-FCNLogLoss=0.116677
2017-06-26 15:47:47,574 Epoch[19] Time cost=812.610
2017-06-26 15:47:48,934 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0020.params"
2017-06-26 15:47:52,624 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0020.states"
2017-06-26 15:47:59,080 Epoch[20] Batch [10]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.118478,	
2017-06-26 15:48:04,455 Epoch[20] Batch [20]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.120208,	
2017-06-26 15:48:10,282 Epoch[20] Batch [30]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120305,	
2017-06-26 15:48:15,584 Epoch[20] Batch [40]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121560,	
2017-06-26 15:48:20,913 Epoch[20] Batch [50]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121282,	
2017-06-26 15:48:26,203 Epoch[20] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122348,	
2017-06-26 15:48:31,591 Epoch[20] Batch [70]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.123603,	
2017-06-26 15:48:36,966 Epoch[20] Batch [80]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.123248,	
2017-06-26 15:48:42,275 Epoch[20] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.122729,	
2017-06-26 15:48:47,612 Epoch[20] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.122285,	
2017-06-26 15:48:53,037 Epoch[20] Batch [110]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.122674,	
2017-06-26 15:48:58,284 Epoch[20] Batch [120]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.122483,	
2017-06-26 15:49:03,631 Epoch[20] Batch [130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121600,	
2017-06-26 15:49:09,526 Epoch[20] Batch [140]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.121448,	
2017-06-26 15:49:14,928 Epoch[20] Batch [150]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.121029,	
2017-06-26 15:49:20,971 Epoch[20] Batch [160]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.119995,	
2017-06-26 15:49:27,060 Epoch[20] Batch [170]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.119923,	
2017-06-26 15:49:33,083 Epoch[20] Batch [180]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.119489,	
2017-06-26 15:49:39,340 Epoch[20] Batch [190]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.119129,	
2017-06-26 15:49:45,429 Epoch[20] Batch [200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.119684,	
2017-06-26 15:49:50,823 Epoch[20] Batch [210]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119031,	
2017-06-26 15:49:56,050 Epoch[20] Batch [220]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.118572,	
2017-06-26 15:50:01,439 Epoch[20] Batch [230]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.118207,	
2017-06-26 15:50:06,802 Epoch[20] Batch [240]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117635,	
2017-06-26 15:50:12,127 Epoch[20] Batch [250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117396,	
2017-06-26 15:50:17,525 Epoch[20] Batch [260]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.117384,	
2017-06-26 15:50:22,883 Epoch[20] Batch [270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117687,	
2017-06-26 15:50:28,197 Epoch[20] Batch [280]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117326,	
2017-06-26 15:50:33,530 Epoch[20] Batch [290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117289,	
2017-06-26 15:50:38,870 Epoch[20] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117502,	
2017-06-26 15:50:44,233 Epoch[20] Batch [310]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117437,	
2017-06-26 15:50:49,543 Epoch[20] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117490,	
2017-06-26 15:50:54,890 Epoch[20] Batch [330]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117667,	
2017-06-26 15:51:00,229 Epoch[20] Batch [340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117173,	
2017-06-26 15:51:05,560 Epoch[20] Batch [350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116271,	
2017-06-26 15:51:10,917 Epoch[20] Batch [360]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116119,	
2017-06-26 15:51:16,282 Epoch[20] Batch [370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116131,	
2017-06-26 15:51:21,584 Epoch[20] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116051,	
2017-06-26 15:51:26,950 Epoch[20] Batch [390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116123,	
2017-06-26 15:51:32,252 Epoch[20] Batch [400]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116102,	
2017-06-26 15:51:37,566 Epoch[20] Batch [410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.116014,	
2017-06-26 15:51:42,878 Epoch[20] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.116419,	
2017-06-26 15:51:48,282 Epoch[20] Batch [430]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.116936,	
2017-06-26 15:51:53,509 Epoch[20] Batch [440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.117661,	
2017-06-26 15:51:58,899 Epoch[20] Batch [450]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117948,	
2017-06-26 15:52:04,410 Epoch[20] Batch [460]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.117994,	
2017-06-26 15:52:10,438 Epoch[20] Batch [470]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.118360,	
2017-06-26 15:52:16,276 Epoch[20] Batch [480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118693,	
2017-06-26 15:52:21,753 Epoch[20] Batch [490]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.118414,	
2017-06-26 15:52:26,995 Epoch[20] Batch [500]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.118639,	
2017-06-26 15:52:32,417 Epoch[20] Batch [510]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.118991,	
2017-06-26 15:52:37,747 Epoch[20] Batch [520]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119049,	
2017-06-26 15:52:43,058 Epoch[20] Batch [530]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118938,	
2017-06-26 15:52:48,413 Epoch[20] Batch [540]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118804,	
2017-06-26 15:52:53,733 Epoch[20] Batch [550]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119033,	
2017-06-26 15:52:59,101 Epoch[20] Batch [560]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119032,	
2017-06-26 15:53:04,410 Epoch[20] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118992,	
2017-06-26 15:53:09,757 Epoch[20] Batch [580]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118964,	
2017-06-26 15:53:15,093 Epoch[20] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118868,	
2017-06-26 15:53:20,438 Epoch[20] Batch [600]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118831,	
2017-06-26 15:53:25,737 Epoch[20] Batch [610]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118779,	
2017-06-26 15:53:31,080 Epoch[20] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118969,	
2017-06-26 15:53:36,425 Epoch[20] Batch [630]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119059,	
2017-06-26 15:53:41,738 Epoch[20] Batch [640]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119073,	
2017-06-26 15:53:47,080 Epoch[20] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118971,	
2017-06-26 15:53:52,421 Epoch[20] Batch [660]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118749,	
2017-06-26 15:53:57,765 Epoch[20] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118841,	
2017-06-26 15:54:03,080 Epoch[20] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119026,	
2017-06-26 15:54:08,451 Epoch[20] Batch [690]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119143,	
2017-06-26 15:54:13,772 Epoch[20] Batch [700]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119342,	
2017-06-26 15:54:19,122 Epoch[20] Batch [710]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119362,	
2017-06-26 15:54:24,467 Epoch[20] Batch [720]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119463,	
2017-06-26 15:54:29,780 Epoch[20] Batch [730]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119580,	
2017-06-26 15:54:35,149 Epoch[20] Batch [740]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119557,	
2017-06-26 15:54:40,482 Epoch[20] Batch [750]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119589,	
2017-06-26 15:54:45,809 Epoch[20] Batch [760]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119709,	
2017-06-26 15:54:51,149 Epoch[20] Batch [770]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119703,	
2017-06-26 15:54:56,494 Epoch[20] Batch [780]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119611,	
2017-06-26 15:55:01,221 Epoch[20] Batch [790]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.119683,	
2017-06-26 15:55:06,110 Epoch[20] Batch [800]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.119644,	
2017-06-26 15:55:11,446 Epoch[20] Batch [810]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119583,	
2017-06-26 15:55:16,822 Epoch[20] Batch [820]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119547,	
2017-06-26 15:55:22,134 Epoch[20] Batch [830]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119559,	
2017-06-26 15:55:27,524 Epoch[20] Batch [840]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119500,	
2017-06-26 15:55:32,825 Epoch[20] Batch [850]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.119299,	
2017-06-26 15:55:38,216 Epoch[20] Batch [860]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119168,	
2017-06-26 15:55:43,569 Epoch[20] Batch [870]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.119026,	
2017-06-26 15:55:48,899 Epoch[20] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119201,	
2017-06-26 15:55:54,295 Epoch[20] Batch [890]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.119494,	
2017-06-26 15:55:59,677 Epoch[20] Batch [900]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.119445,	
2017-06-26 15:56:05,001 Epoch[20] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119399,	
2017-06-26 15:56:10,328 Epoch[20] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119394,	
2017-06-26 15:56:15,802 Epoch[20] Batch [930]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.119472,	
2017-06-26 15:56:21,824 Epoch[20] Batch [940]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.119368,	
2017-06-26 15:56:27,846 Epoch[20] Batch [950]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.119390,	
2017-06-26 15:56:33,825 Epoch[20] Batch [960]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.119363,	
2017-06-26 15:56:39,800 Epoch[20] Batch [970]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.119226,	
2017-06-26 15:56:45,803 Epoch[20] Batch [980]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.119171,	
2017-06-26 15:56:51,834 Epoch[20] Batch [990]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.119090,	
2017-06-26 15:56:57,900 Epoch[20] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.118989,	
2017-06-26 15:57:04,047 Epoch[20] Batch [1010]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.118829,	
2017-06-26 15:57:10,042 Epoch[20] Batch [1020]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.118677,	
2017-06-26 15:57:15,984 Epoch[20] Batch [1030]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.118597,	
2017-06-26 15:57:22,005 Epoch[20] Batch [1040]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.118629,	
2017-06-26 15:57:27,964 Epoch[20] Batch [1050]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.118630,	
2017-06-26 15:57:33,921 Epoch[20] Batch [1060]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.118642,	
2017-06-26 15:57:39,891 Epoch[20] Batch [1070]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.118639,	
2017-06-26 15:57:45,861 Epoch[20] Batch [1080]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.118511,	
2017-06-26 15:57:51,841 Epoch[20] Batch [1090]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.118478,	
2017-06-26 15:57:57,781 Epoch[20] Batch [1100]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.118375,	
2017-06-26 15:58:03,817 Epoch[20] Batch [1110]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.118390,	
2017-06-26 15:58:09,744 Epoch[20] Batch [1120]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.118365,	
2017-06-26 15:58:15,723 Epoch[20] Batch [1130]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.118280,	
2017-06-26 15:58:21,817 Epoch[20] Batch [1140]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.118240,	
2017-06-26 15:58:27,687 Epoch[20] Batch [1150]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.118065,	
2017-06-26 15:58:33,686 Epoch[20] Batch [1160]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.117915,	
2017-06-26 15:58:39,752 Epoch[20] Batch [1170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.117767,	
2017-06-26 15:58:46,232 Epoch[20] Batch [1180]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.117775,	
2017-06-26 15:58:52,247 Epoch[20] Batch [1190]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.117732,	
2017-06-26 15:58:58,235 Epoch[20] Batch [1200]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.117812,	
2017-06-26 15:59:04,163 Epoch[20] Batch [1210]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.117696,	
2017-06-26 15:59:10,122 Epoch[20] Batch [1220]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.117661,	
2017-06-26 15:59:16,092 Epoch[20] Batch [1230]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.117640,	
2017-06-26 15:59:22,060 Epoch[20] Batch [1240]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.117661,	
2017-06-26 15:59:28,067 Epoch[20] Batch [1250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.117627,	
2017-06-26 15:59:33,981 Epoch[20] Batch [1260]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.117630,	
2017-06-26 15:59:39,998 Epoch[20] Batch [1270]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.117626,	
2017-06-26 15:59:45,933 Epoch[20] Batch [1280]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.117626,	
2017-06-26 15:59:51,881 Epoch[20] Batch [1290]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.117501,	
2017-06-26 15:59:57,403 Epoch[20] Batch [1300]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.117481,	
2017-06-26 16:00:02,889 Epoch[20] Batch [1310]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.117423,	
2017-06-26 16:00:08,473 Epoch[20] Batch [1320]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.117430,	
2017-06-26 16:00:14,076 Epoch[20] Batch [1330]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.117461,	
2017-06-26 16:00:19,801 Epoch[20] Batch [1340]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.117397,	
2017-06-26 16:00:25,811 Epoch[20] Batch [1350]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.117269,	
2017-06-26 16:00:31,754 Epoch[20] Batch [1360]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.117256,	
2017-06-26 16:00:37,726 Epoch[20] Batch [1370]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.117275,	
2017-06-26 16:00:43,686 Epoch[20] Batch [1380]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.117365,	
2017-06-26 16:00:49,633 Epoch[20] Batch [1390]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.117349,	
2017-06-26 16:00:55,665 Epoch[20] Batch [1400]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.117261,	
2017-06-26 16:01:01,579 Epoch[20] Batch [1410]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.117335,	
2017-06-26 16:01:07,522 Epoch[20] Batch [1420]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.117302,	
2017-06-26 16:01:13,502 Epoch[20] Batch [1430]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.117377,	
2017-06-26 16:01:19,448 Epoch[20] Batch [1440]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.117320,	
2017-06-26 16:01:25,440 Epoch[20] Batch [1450]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.117232,	
2017-06-26 16:01:31,356 Epoch[20] Batch [1460]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.117348,	
2017-06-26 16:01:37,336 Epoch[20] Batch [1470]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.117297,	
2017-06-26 16:01:43,295 Epoch[20] Batch [1480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.117331,	
2017-06-26 16:01:46,860 Epoch[20] Train-FCNLogLoss=0.117382
2017-06-26 16:01:46,860 Epoch[20] Time cost=834.236
2017-06-26 16:01:48,025 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0021.params"
2017-06-26 16:01:51,515 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0021.states"
2017-06-26 16:01:58,267 Epoch[21] Batch [10]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.118518,	
2017-06-26 16:02:04,202 Epoch[21] Batch [20]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.124387,	
2017-06-26 16:02:10,217 Epoch[21] Batch [30]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.115293,	
2017-06-26 16:02:16,172 Epoch[21] Batch [40]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.117740,	
2017-06-26 16:02:22,149 Epoch[21] Batch [50]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.116505,	
2017-06-26 16:02:28,104 Epoch[21] Batch [60]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.116766,	
2017-06-26 16:02:34,092 Epoch[21] Batch [70]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.114332,	
2017-06-26 16:02:40,099 Epoch[21] Batch [80]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.113192,	
2017-06-26 16:02:46,082 Epoch[21] Batch [90]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.111684,	
2017-06-26 16:02:52,091 Epoch[21] Batch [100]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.112023,	
2017-06-26 16:02:57,987 Epoch[21] Batch [110]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.112746,	
2017-06-26 16:03:03,945 Epoch[21] Batch [120]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.113301,	
2017-06-26 16:03:09,878 Epoch[21] Batch [130]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.113832,	
2017-06-26 16:03:15,853 Epoch[21] Batch [140]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.114270,	
2017-06-26 16:03:21,836 Epoch[21] Batch [150]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.115371,	
2017-06-26 16:03:27,822 Epoch[21] Batch [160]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.114853,	
2017-06-26 16:03:33,793 Epoch[21] Batch [170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.115954,	
2017-06-26 16:03:39,745 Epoch[21] Batch [180]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.116914,	
2017-06-26 16:03:45,748 Epoch[21] Batch [190]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.117450,	
2017-06-26 16:03:51,656 Epoch[21] Batch [200]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.117040,	
2017-06-26 16:03:57,684 Epoch[21] Batch [210]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.117631,	
2017-06-26 16:04:03,622 Epoch[21] Batch [220]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.117629,	
2017-06-26 16:04:09,065 Epoch[21] Batch [230]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.117608,	
2017-06-26 16:04:14,527 Epoch[21] Batch [240]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.117681,	
2017-06-26 16:04:20,080 Epoch[21] Batch [250]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.118741,	
2017-06-26 16:04:25,595 Epoch[21] Batch [260]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.118550,	
2017-06-26 16:04:31,238 Epoch[21] Batch [270]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.118108,	
2017-06-26 16:04:36,743 Epoch[21] Batch [280]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.118387,	
2017-06-26 16:04:42,165 Epoch[21] Batch [290]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.118535,	
2017-06-26 16:04:47,645 Epoch[21] Batch [300]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.118388,	
2017-06-26 16:04:53,070 Epoch[21] Batch [310]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.117954,	
2017-06-26 16:04:58,966 Epoch[21] Batch [320]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.117795,	
2017-06-26 16:05:04,984 Epoch[21] Batch [330]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.117833,	
2017-06-26 16:05:10,849 Epoch[21] Batch [340]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.117718,	
2017-06-26 16:05:16,898 Epoch[21] Batch [350]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.117377,	
2017-06-26 16:05:22,817 Epoch[21] Batch [360]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.116961,	
2017-06-26 16:05:28,785 Epoch[21] Batch [370]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.117090,	
2017-06-26 16:05:34,784 Epoch[21] Batch [380]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.116802,	
2017-06-26 16:05:40,710 Epoch[21] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.116532,	
2017-06-26 16:05:46,659 Epoch[21] Batch [400]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.116405,	
2017-06-26 16:05:52,649 Epoch[21] Batch [410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.116613,	
2017-06-26 16:05:58,588 Epoch[21] Batch [420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.116593,	
2017-06-26 16:06:04,604 Epoch[21] Batch [430]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.116399,	
2017-06-26 16:06:10,502 Epoch[21] Batch [440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.116417,	
2017-06-26 16:06:16,534 Epoch[21] Batch [450]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.116374,	
2017-06-26 16:06:22,483 Epoch[21] Batch [460]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.116137,	
2017-06-26 16:06:28,442 Epoch[21] Batch [470]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.115794,	
2017-06-26 16:06:34,399 Epoch[21] Batch [480]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.115640,	
2017-06-26 16:06:40,381 Epoch[21] Batch [490]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.115300,	
2017-06-26 16:06:46,383 Epoch[21] Batch [500]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.115256,	
2017-06-26 16:06:52,404 Epoch[21] Batch [510]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.115608,	
2017-06-26 16:06:58,325 Epoch[21] Batch [520]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.115438,	
2017-06-26 16:07:04,395 Epoch[21] Batch [530]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115378,	
2017-06-26 16:07:10,309 Epoch[21] Batch [540]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.115260,	
2017-06-26 16:07:16,284 Epoch[21] Batch [550]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.114944,	
2017-06-26 16:07:22,312 Epoch[21] Batch [560]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.114835,	
2017-06-26 16:07:28,274 Epoch[21] Batch [570]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.114565,	
2017-06-26 16:07:34,337 Epoch[21] Batch [580]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.114903,	
2017-06-26 16:07:40,244 Epoch[21] Batch [590]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.115458,	
2017-06-26 16:07:46,209 Epoch[21] Batch [600]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.115730,	
2017-06-26 16:07:52,190 Epoch[21] Batch [610]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.115489,	
2017-06-26 16:07:58,138 Epoch[21] Batch [620]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.115478,	
2017-06-26 16:08:04,205 Epoch[21] Batch [630]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115413,	
2017-06-26 16:08:10,081 Epoch[21] Batch [640]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.115775,	
2017-06-26 16:08:16,045 Epoch[21] Batch [650]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.115638,	
2017-06-26 16:08:22,077 Epoch[21] Batch [660]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.115646,	
2017-06-26 16:08:28,023 Epoch[21] Batch [670]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.115951,	
2017-06-26 16:08:33,991 Epoch[21] Batch [680]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.116169,	
2017-06-26 16:08:39,741 Epoch[21] Batch [690]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.116040,	
2017-06-26 16:08:45,242 Epoch[21] Batch [700]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.116110,	
2017-06-26 16:08:51,013 Epoch[21] Batch [710]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.115978,	
2017-06-26 16:08:56,887 Epoch[21] Batch [720]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.116041,	
2017-06-26 16:09:02,895 Epoch[21] Batch [730]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.116138,	
2017-06-26 16:09:08,368 Epoch[21] Batch [740]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.116069,	
2017-06-26 16:09:13,811 Epoch[21] Batch [750]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.116044,	
2017-06-26 16:09:20,146 Epoch[21] Batch [760]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.116102,	
2017-06-26 16:09:26,115 Epoch[21] Batch [770]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.116087,	
2017-06-26 16:09:31,762 Epoch[21] Batch [780]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.116319,	
2017-06-26 16:09:37,739 Epoch[21] Batch [790]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.116390,	
2017-06-26 16:09:43,711 Epoch[21] Batch [800]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.116428,	
2017-06-26 16:09:49,685 Epoch[21] Batch [810]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.116493,	
2017-06-26 16:09:55,133 Epoch[21] Batch [820]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.116387,	
2017-06-26 16:10:00,631 Epoch[21] Batch [830]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.116430,	
2017-06-26 16:10:06,017 Epoch[21] Batch [840]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.116381,	
2017-06-26 16:10:11,352 Epoch[21] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116383,	
2017-06-26 16:10:16,639 Epoch[21] Batch [860]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116332,	
2017-06-26 16:10:21,964 Epoch[21] Batch [870]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116286,	
2017-06-26 16:10:27,323 Epoch[21] Batch [880]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116193,	
2017-06-26 16:10:32,600 Epoch[21] Batch [890]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.116089,	
2017-06-26 16:10:37,933 Epoch[21] Batch [900]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116162,	
2017-06-26 16:10:43,310 Epoch[21] Batch [910]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.116074,	
2017-06-26 16:10:48,658 Epoch[21] Batch [920]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.115961,	
2017-06-26 16:10:54,333 Epoch[21] Batch [930]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.116015,	
2017-06-26 16:10:59,892 Epoch[21] Batch [940]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.115942,	
2017-06-26 16:11:05,343 Epoch[21] Batch [950]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.116108,	
2017-06-26 16:11:10,668 Epoch[21] Batch [960]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.115943,	
2017-06-26 16:11:16,027 Epoch[21] Batch [970]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.115934,	
2017-06-26 16:11:21,505 Epoch[21] Batch [980]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.115924,	
2017-06-26 16:11:26,832 Epoch[21] Batch [990]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.115999,	
2017-06-26 16:11:32,260 Epoch[21] Batch [1000]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.115866,	
2017-06-26 16:11:37,672 Epoch[21] Batch [1010]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.115755,	
2017-06-26 16:11:42,967 Epoch[21] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.115679,	
2017-06-26 16:11:48,574 Epoch[21] Batch [1030]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.115677,	
2017-06-26 16:11:54,675 Epoch[21] Batch [1040]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.115631,	
2017-06-26 16:12:00,759 Epoch[21] Batch [1050]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.115567,	
2017-06-26 16:12:06,817 Epoch[21] Batch [1060]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.115587,	
2017-06-26 16:12:12,891 Epoch[21] Batch [1070]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115615,	
2017-06-26 16:12:18,972 Epoch[21] Batch [1080]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.115547,	
2017-06-26 16:12:25,061 Epoch[21] Batch [1090]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.115537,	
2017-06-26 16:12:31,145 Epoch[21] Batch [1100]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.115524,	
2017-06-26 16:12:37,161 Epoch[21] Batch [1110]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.115439,	
2017-06-26 16:12:43,222 Epoch[21] Batch [1120]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.115416,	
2017-06-26 16:12:49,335 Epoch[21] Batch [1130]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.115417,	
2017-06-26 16:12:55,409 Epoch[21] Batch [1140]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115321,	
2017-06-26 16:13:01,492 Epoch[21] Batch [1150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.115194,	
2017-06-26 16:13:07,603 Epoch[21] Batch [1160]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.115226,	
2017-06-26 16:13:13,665 Epoch[21] Batch [1170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.115141,	
2017-06-26 16:13:19,765 Epoch[21] Batch [1180]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.115195,	
2017-06-26 16:13:25,813 Epoch[21] Batch [1190]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.115196,	
2017-06-26 16:13:31,948 Epoch[21] Batch [1200]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.115202,	
2017-06-26 16:13:38,122 Epoch[21] Batch [1210]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.115207,	
2017-06-26 16:13:44,233 Epoch[21] Batch [1220]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.115293,	
2017-06-26 16:13:50,445 Epoch[21] Batch [1230]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.115397,	
2017-06-26 16:13:56,572 Epoch[21] Batch [1240]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.115396,	
2017-06-26 16:14:02,616 Epoch[21] Batch [1250]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.115445,	
2017-06-26 16:14:08,780 Epoch[21] Batch [1260]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.115396,	
2017-06-26 16:14:14,795 Epoch[21] Batch [1270]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.115471,	
2017-06-26 16:14:20,932 Epoch[21] Batch [1280]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.115388,	
2017-06-26 16:14:27,007 Epoch[21] Batch [1290]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115301,	
2017-06-26 16:14:33,144 Epoch[21] Batch [1300]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.115308,	
2017-06-26 16:14:39,379 Epoch[21] Batch [1310]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.115306,	
2017-06-26 16:14:45,459 Epoch[21] Batch [1320]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.115132,	
2017-06-26 16:14:51,623 Epoch[21] Batch [1330]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.115130,	
2017-06-26 16:14:57,998 Epoch[21] Batch [1340]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.115142,	
2017-06-26 16:15:04,246 Epoch[21] Batch [1350]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.115206,	
2017-06-26 16:15:10,335 Epoch[21] Batch [1360]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.115179,	
2017-06-26 16:15:16,826 Epoch[21] Batch [1370]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.115121,	
2017-06-26 16:15:23,273 Epoch[21] Batch [1380]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.115059,	
2017-06-26 16:15:29,838 Epoch[21] Batch [1390]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.115109,	
2017-06-26 16:15:37,323 Epoch[21] Batch [1400]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.115084,	
2017-06-26 16:15:44,679 Epoch[21] Batch [1410]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.115007,	
2017-06-26 16:15:51,323 Epoch[21] Batch [1420]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.114998,	
2017-06-26 16:15:57,335 Epoch[21] Batch [1430]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.115059,	
2017-06-26 16:16:03,090 Epoch[21] Batch [1440]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.115095,	
2017-06-26 16:16:08,774 Epoch[21] Batch [1450]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.115182,	
2017-06-26 16:16:14,518 Epoch[21] Batch [1460]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.115174,	
2017-06-26 16:16:20,715 Epoch[21] Batch [1470]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.115154,	
2017-06-26 16:16:26,831 Epoch[21] Batch [1480]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.115152,	
2017-06-26 16:16:30,542 Epoch[21] Train-FCNLogLoss=0.115091
2017-06-26 16:16:30,543 Epoch[21] Time cost=879.027
2017-06-26 16:16:31,827 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0022.params"
2017-06-26 16:16:35,591 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0022.states"
2017-06-26 16:16:42,481 Epoch[22] Batch [10]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.110155,	
2017-06-26 16:16:48,716 Epoch[22] Batch [20]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.119030,	
2017-06-26 16:16:54,844 Epoch[22] Batch [30]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.117608,	
2017-06-26 16:17:01,066 Epoch[22] Batch [40]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.129986,	
2017-06-26 16:17:07,159 Epoch[22] Batch [50]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.132042,	
2017-06-26 16:17:13,359 Epoch[22] Batch [60]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.131157,	
2017-06-26 16:17:19,490 Epoch[22] Batch [70]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.135140,	
2017-06-26 16:17:25,596 Epoch[22] Batch [80]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.134919,	
2017-06-26 16:17:31,709 Epoch[22] Batch [90]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.133189,	
2017-06-26 16:17:37,893 Epoch[22] Batch [100]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.134280,	
2017-06-26 16:17:43,994 Epoch[22] Batch [110]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.133458,	
2017-06-26 16:17:50,243 Epoch[22] Batch [120]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.131441,	
2017-06-26 16:17:56,375 Epoch[22] Batch [130]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.130733,	
2017-06-26 16:18:02,623 Epoch[22] Batch [140]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.129624,	
2017-06-26 16:18:08,969 Epoch[22] Batch [150]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.128307,	
2017-06-26 16:18:15,070 Epoch[22] Batch [160]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.126685,	
2017-06-26 16:18:21,254 Epoch[22] Batch [170]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.126852,	
2017-06-26 16:18:27,408 Epoch[22] Batch [180]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.126587,	
2017-06-26 16:18:34,058 Epoch[22] Batch [190]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.126422,	
2017-06-26 16:18:40,635 Epoch[22] Batch [200]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.125162,	
2017-06-26 16:18:46,743 Epoch[22] Batch [210]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.124788,	
2017-06-26 16:18:52,895 Epoch[22] Batch [220]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.124993,	
2017-06-26 16:18:58,972 Epoch[22] Batch [230]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.124664,	
2017-06-26 16:19:05,104 Epoch[22] Batch [240]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.124551,	
2017-06-26 16:19:11,492 Epoch[22] Batch [250]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.124217,	
2017-06-26 16:19:18,022 Epoch[22] Batch [260]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.124553,	
2017-06-26 16:19:24,549 Epoch[22] Batch [270]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.124819,	
2017-06-26 16:19:30,681 Epoch[22] Batch [280]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.124639,	
2017-06-26 16:19:37,066 Epoch[22] Batch [290]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.124039,	
2017-06-26 16:19:43,303 Epoch[22] Batch [300]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.123990,	
2017-06-26 16:19:49,410 Epoch[22] Batch [310]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.123651,	
2017-06-26 16:19:55,548 Epoch[22] Batch [320]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.123224,	
2017-06-26 16:20:02,259 Epoch[22] Batch [330]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.123167,	
2017-06-26 16:20:08,314 Epoch[22] Batch [340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.122914,	
2017-06-26 16:20:14,569 Epoch[22] Batch [350]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.122745,	
2017-06-26 16:20:20,593 Epoch[22] Batch [360]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.122658,	
2017-06-26 16:20:26,790 Epoch[22] Batch [370]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.122083,	
2017-06-26 16:20:32,531 Epoch[22] Batch [380]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.122130,	
2017-06-26 16:20:38,330 Epoch[22] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121732,	
2017-06-26 16:20:44,058 Epoch[22] Batch [400]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.121442,	
2017-06-26 16:20:49,796 Epoch[22] Batch [410]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.121561,	
2017-06-26 16:20:55,676 Epoch[22] Batch [420]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.122053,	
2017-06-26 16:21:01,635 Epoch[22] Batch [430]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.121905,	
2017-06-26 16:21:07,586 Epoch[22] Batch [440]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.121928,	
2017-06-26 16:21:13,668 Epoch[22] Batch [450]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.121882,	
2017-06-26 16:21:19,808 Epoch[22] Batch [460]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.121394,	
2017-06-26 16:21:25,967 Epoch[22] Batch [470]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.121284,	
2017-06-26 16:21:32,028 Epoch[22] Batch [480]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.121065,	
2017-06-26 16:21:38,101 Epoch[22] Batch [490]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.120832,	
2017-06-26 16:21:44,282 Epoch[22] Batch [500]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.120698,	
2017-06-26 16:21:50,413 Epoch[22] Batch [510]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.120846,	
2017-06-26 16:21:56,592 Epoch[22] Batch [520]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.120767,	
2017-06-26 16:22:02,807 Epoch[22] Batch [530]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.120518,	
2017-06-26 16:22:08,942 Epoch[22] Batch [540]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.120501,	
2017-06-26 16:22:15,072 Epoch[22] Batch [550]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.120594,	
2017-06-26 16:22:21,235 Epoch[22] Batch [560]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.120633,	
2017-06-26 16:22:27,483 Epoch[22] Batch [570]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.120378,	
2017-06-26 16:22:33,632 Epoch[22] Batch [580]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.120228,	
2017-06-26 16:22:39,932 Epoch[22] Batch [590]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.120036,	
2017-06-26 16:22:46,076 Epoch[22] Batch [600]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.119934,	
2017-06-26 16:22:52,188 Epoch[22] Batch [610]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.119859,	
2017-06-26 16:22:58,247 Epoch[22] Batch [620]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.119733,	
2017-06-26 16:23:04,328 Epoch[22] Batch [630]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.119637,	
2017-06-26 16:23:10,431 Epoch[22] Batch [640]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.119698,	
2017-06-26 16:23:16,606 Epoch[22] Batch [650]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.119619,	
2017-06-26 16:23:22,983 Epoch[22] Batch [660]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.119404,	
2017-06-26 16:23:29,500 Epoch[22] Batch [670]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.119284,	
2017-06-26 16:23:36,055 Epoch[22] Batch [680]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.119254,	
2017-06-26 16:23:42,888 Epoch[22] Batch [690]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.119065,	
2017-06-26 16:23:50,290 Epoch[22] Batch [700]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.119003,	
2017-06-26 16:23:57,056 Epoch[22] Batch [710]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.118842,	
2017-06-26 16:24:03,912 Epoch[22] Batch [720]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.118747,	
2017-06-26 16:24:10,709 Epoch[22] Batch [730]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.118647,	
2017-06-26 16:24:17,604 Epoch[22] Batch [740]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.118613,	
2017-06-26 16:24:24,387 Epoch[22] Batch [750]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.118469,	
2017-06-26 16:24:31,077 Epoch[22] Batch [760]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.118263,	
2017-06-26 16:24:37,662 Epoch[22] Batch [770]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.117979,	
2017-06-26 16:24:44,323 Epoch[22] Batch [780]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.118011,	
2017-06-26 16:24:51,043 Epoch[22] Batch [790]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.117807,	
2017-06-26 16:24:57,689 Epoch[22] Batch [800]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.117842,	
2017-06-26 16:25:03,727 Epoch[22] Batch [810]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.117784,	
2017-06-26 16:25:10,278 Epoch[22] Batch [820]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.117769,	
2017-06-26 16:25:17,262 Epoch[22] Batch [830]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.117811,	
2017-06-26 16:25:24,460 Epoch[22] Batch [840]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.117604,	
2017-06-26 16:25:31,627 Epoch[22] Batch [850]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.117429,	
2017-06-26 16:25:37,953 Epoch[22] Batch [860]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.117379,	
2017-06-26 16:25:45,043 Epoch[22] Batch [870]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.117074,	
2017-06-26 16:25:52,171 Epoch[22] Batch [880]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.116976,	
2017-06-26 16:25:58,884 Epoch[22] Batch [890]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.116980,	
2017-06-26 16:26:06,807 Epoch[22] Batch [900]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.116995,	
2017-06-26 16:26:13,923 Epoch[22] Batch [910]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.116793,	
2017-06-26 16:26:20,824 Epoch[22] Batch [920]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.116766,	
2017-06-26 16:26:28,012 Epoch[22] Batch [930]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.116692,	
2017-06-26 16:26:34,980 Epoch[22] Batch [940]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.116662,	
2017-06-26 16:26:42,517 Epoch[22] Batch [950]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.116481,	
2017-06-26 16:26:49,706 Epoch[22] Batch [960]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.116330,	
2017-06-26 16:26:56,841 Epoch[22] Batch [970]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.116219,	
2017-06-26 16:27:04,007 Epoch[22] Batch [980]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.116067,	
2017-06-26 16:27:10,773 Epoch[22] Batch [990]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.115892,	
2017-06-26 16:27:18,057 Epoch[22] Batch [1000]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.115840,	
2017-06-26 16:27:24,816 Epoch[22] Batch [1010]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.115831,	
2017-06-26 16:27:32,207 Epoch[22] Batch [1020]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.115912,	
2017-06-26 16:27:39,436 Epoch[22] Batch [1030]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.115771,	
2017-06-26 16:27:46,782 Epoch[22] Batch [1040]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.115660,	
2017-06-26 16:27:53,681 Epoch[22] Batch [1050]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.115571,	
2017-06-26 16:28:00,836 Epoch[22] Batch [1060]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.115634,	
2017-06-26 16:28:08,088 Epoch[22] Batch [1070]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.115797,	
2017-06-26 16:28:15,137 Epoch[22] Batch [1080]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.115844,	
2017-06-26 16:28:22,189 Epoch[22] Batch [1090]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.115910,	
2017-06-26 16:28:29,503 Epoch[22] Batch [1100]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.115955,	
2017-06-26 16:28:36,765 Epoch[22] Batch [1110]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.116010,	
2017-06-26 16:28:43,640 Epoch[22] Batch [1120]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.116124,	
2017-06-26 16:28:50,843 Epoch[22] Batch [1130]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.115944,	
2017-06-26 16:28:58,116 Epoch[22] Batch [1140]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.115906,	
2017-06-26 16:29:05,451 Epoch[22] Batch [1150]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.116021,	
2017-06-26 16:29:13,113 Epoch[22] Batch [1160]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.116052,	
2017-06-26 16:29:19,974 Epoch[22] Batch [1170]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.116090,	
2017-06-26 16:29:27,454 Epoch[22] Batch [1180]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.116010,	
2017-06-26 16:29:34,747 Epoch[22] Batch [1190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.116063,	
2017-06-26 16:29:41,866 Epoch[22] Batch [1200]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.116040,	
2017-06-26 16:29:49,070 Epoch[22] Batch [1210]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.116042,	
2017-06-26 16:29:55,628 Epoch[22] Batch [1220]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.115996,	
2017-06-26 16:30:02,192 Epoch[22] Batch [1230]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.115964,	
2017-06-26 16:30:08,892 Epoch[22] Batch [1240]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.115955,	
2017-06-26 16:30:15,339 Epoch[22] Batch [1250]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.115975,	
2017-06-26 16:30:22,170 Epoch[22] Batch [1260]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.116009,	
2017-06-26 16:30:29,436 Epoch[22] Batch [1270]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.116046,	
2017-06-26 16:30:36,323 Epoch[22] Batch [1280]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.115938,	
2017-06-26 16:30:42,909 Epoch[22] Batch [1290]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.115883,	
2017-06-26 16:30:49,743 Epoch[22] Batch [1300]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.115911,	
2017-06-26 16:30:56,877 Epoch[22] Batch [1310]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.115886,	
2017-06-26 16:31:03,602 Epoch[22] Batch [1320]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.115765,	
2017-06-26 16:31:10,782 Epoch[22] Batch [1330]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.115861,	
2017-06-26 16:31:17,693 Epoch[22] Batch [1340]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.115863,	
2017-06-26 16:31:24,735 Epoch[22] Batch [1350]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.116052,	
2017-06-26 16:31:31,831 Epoch[22] Batch [1360]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.115971,	
2017-06-26 16:31:38,689 Epoch[22] Batch [1370]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.115990,	
2017-06-26 16:31:45,796 Epoch[22] Batch [1380]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.115972,	
2017-06-26 16:31:52,653 Epoch[22] Batch [1390]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.115913,	
2017-06-26 16:32:00,144 Epoch[22] Batch [1400]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.115832,	
2017-06-26 16:32:07,006 Epoch[22] Batch [1410]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.115848,	
2017-06-26 16:32:14,377 Epoch[22] Batch [1420]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.115916,	
2017-06-26 16:32:21,612 Epoch[22] Batch [1430]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.115940,	
2017-06-26 16:32:28,860 Epoch[22] Batch [1440]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.115935,	
2017-06-26 16:32:35,930 Epoch[22] Batch [1450]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.115809,	
2017-06-26 16:32:43,634 Epoch[22] Batch [1460]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.115839,	
2017-06-26 16:32:51,472 Epoch[22] Batch [1470]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.115942,	
2017-06-26 16:32:58,826 Epoch[22] Batch [1480]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.116000,	
2017-06-26 16:33:02,696 Epoch[22] Train-FCNLogLoss=0.115921
2017-06-26 16:33:02,696 Epoch[22] Time cost=987.105
2017-06-26 16:33:03,681 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0023.params"
2017-06-26 16:33:07,275 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0023.states"
2017-06-26 16:33:14,164 Epoch[23] Batch [10]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.121339,	
2017-06-26 16:33:20,252 Epoch[23] Batch [20]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.117554,	
2017-06-26 16:33:26,361 Epoch[23] Batch [30]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.116176,	
2017-06-26 16:33:32,541 Epoch[23] Batch [40]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.117419,	
2017-06-26 16:33:38,777 Epoch[23] Batch [50]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.113942,	
2017-06-26 16:33:44,943 Epoch[23] Batch [60]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.114264,	
2017-06-26 16:33:51,203 Epoch[23] Batch [70]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.111948,	
2017-06-26 16:33:57,307 Epoch[23] Batch [80]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.112778,	
2017-06-26 16:34:03,527 Epoch[23] Batch [90]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.114738,	
2017-06-26 16:34:09,679 Epoch[23] Batch [100]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.114369,	
2017-06-26 16:34:15,881 Epoch[23] Batch [110]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.115212,	
2017-06-26 16:34:22,207 Epoch[23] Batch [120]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.117857,	
2017-06-26 16:34:28,933 Epoch[23] Batch [130]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.120604,	
2017-06-26 16:34:35,863 Epoch[23] Batch [140]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.120351,	
2017-06-26 16:34:42,877 Epoch[23] Batch [150]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.122354,	
2017-06-26 16:34:49,734 Epoch[23] Batch [160]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.122580,	
2017-06-26 16:34:56,542 Epoch[23] Batch [170]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.123127,	
2017-06-26 16:35:03,615 Epoch[23] Batch [180]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.124070,	
2017-06-26 16:35:10,308 Epoch[23] Batch [190]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.123336,	
2017-06-26 16:35:17,157 Epoch[23] Batch [200]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.123228,	
2017-06-26 16:35:24,066 Epoch[23] Batch [210]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.123230,	
2017-06-26 16:35:30,706 Epoch[23] Batch [220]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.123390,	
2017-06-26 16:35:37,150 Epoch[23] Batch [230]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.129734,	
2017-06-26 16:35:43,606 Epoch[23] Batch [240]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.132049,	
2017-06-26 16:35:50,517 Epoch[23] Batch [250]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.135189,	
2017-06-26 16:35:57,063 Epoch[23] Batch [260]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.136075,	
2017-06-26 16:36:03,781 Epoch[23] Batch [270]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.137562,	
2017-06-26 16:36:10,643 Epoch[23] Batch [280]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.138609,	
2017-06-26 16:36:17,852 Epoch[23] Batch [290]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.138975,	
2017-06-26 16:36:24,975 Epoch[23] Batch [300]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.138402,	
2017-06-26 16:36:31,514 Epoch[23] Batch [310]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.137787,	
2017-06-26 16:36:38,282 Epoch[23] Batch [320]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.137357,	
2017-06-26 16:36:45,525 Epoch[23] Batch [330]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.137066,	
2017-06-26 16:36:52,379 Epoch[23] Batch [340]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.136867,	
2017-06-26 16:36:58,973 Epoch[23] Batch [350]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.136964,	
2017-06-26 16:37:05,862 Epoch[23] Batch [360]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.137082,	
2017-06-26 16:37:12,781 Epoch[23] Batch [370]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.137282,	
2017-06-26 16:37:18,974 Epoch[23] Batch [380]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.139186,	
2017-06-26 16:37:25,211 Epoch[23] Batch [390]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.140685,	
2017-06-26 16:37:31,401 Epoch[23] Batch [400]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.140450,	
2017-06-26 16:37:37,540 Epoch[23] Batch [410]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.140497,	
2017-06-26 16:37:43,672 Epoch[23] Batch [420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.140417,	
2017-06-26 16:37:49,921 Epoch[23] Batch [430]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.140560,	
2017-06-26 16:37:56,044 Epoch[23] Batch [440]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.140352,	
2017-06-26 16:38:02,181 Epoch[23] Batch [450]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.140017,	
2017-06-26 16:38:08,301 Epoch[23] Batch [460]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.139436,	
2017-06-26 16:38:14,475 Epoch[23] Batch [470]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.138901,	
2017-06-26 16:38:20,622 Epoch[23] Batch [480]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.138439,	
2017-06-26 16:38:26,792 Epoch[23] Batch [490]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.137984,	
2017-06-26 16:38:33,171 Epoch[23] Batch [500]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.137963,	
2017-06-26 16:38:39,252 Epoch[23] Batch [510]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.137512,	
2017-06-26 16:38:45,959 Epoch[23] Batch [520]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.137234,	
2017-06-26 16:38:53,029 Epoch[23] Batch [530]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.136623,	
2017-06-26 16:39:00,480 Epoch[23] Batch [540]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.136294,	
2017-06-26 16:39:07,906 Epoch[23] Batch [550]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.135899,	
2017-06-26 16:39:15,133 Epoch[23] Batch [560]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.135796,	
2017-06-26 16:39:22,369 Epoch[23] Batch [570]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.135543,	
2017-06-26 16:39:29,492 Epoch[23] Batch [580]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.135154,	
2017-06-26 16:39:36,497 Epoch[23] Batch [590]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.134921,	
2017-06-26 16:39:43,435 Epoch[23] Batch [600]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.134503,	
2017-06-26 16:39:50,435 Epoch[23] Batch [610]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.134433,	
2017-06-26 16:39:57,356 Epoch[23] Batch [620]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.134238,	
2017-06-26 16:40:05,027 Epoch[23] Batch [630]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.133868,	
2017-06-26 16:40:12,333 Epoch[23] Batch [640]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.133535,	
2017-06-26 16:40:19,376 Epoch[23] Batch [650]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.133229,	
2017-06-26 16:40:26,256 Epoch[23] Batch [660]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.133176,	
2017-06-26 16:40:33,542 Epoch[23] Batch [670]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.132807,	
2017-06-26 16:40:40,718 Epoch[23] Batch [680]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.133387,	
2017-06-26 16:40:47,515 Epoch[23] Batch [690]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.133244,	
2017-06-26 16:40:54,637 Epoch[23] Batch [700]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.132995,	
2017-06-26 16:41:01,314 Epoch[23] Batch [710]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.132888,	
2017-06-26 16:41:08,021 Epoch[23] Batch [720]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.132829,	
2017-06-26 16:41:14,819 Epoch[23] Batch [730]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.132789,	
2017-06-26 16:41:22,062 Epoch[23] Batch [740]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.132373,	
2017-06-26 16:41:28,917 Epoch[23] Batch [750]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.132223,	
2017-06-26 16:41:35,801 Epoch[23] Batch [760]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.132146,	
2017-06-26 16:41:42,713 Epoch[23] Batch [770]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.132125,	
2017-06-26 16:41:49,508 Epoch[23] Batch [780]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.131837,	
2017-06-26 16:41:56,354 Epoch[23] Batch [790]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.131508,	
2017-06-26 16:42:03,440 Epoch[23] Batch [800]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.131082,	
2017-06-26 16:42:11,980 Epoch[23] Batch [810]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.130831,	
2017-06-26 16:42:19,570 Epoch[23] Batch [820]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.130712,	
2017-06-26 16:42:27,834 Epoch[23] Batch [830]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.130572,	
2017-06-26 16:42:35,195 Epoch[23] Batch [840]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.130317,	
2017-06-26 16:42:42,208 Epoch[23] Batch [850]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.130110,	
2017-06-26 16:42:49,437 Epoch[23] Batch [860]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.129887,	
2017-06-26 16:42:56,552 Epoch[23] Batch [870]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.129679,	
2017-06-26 16:43:03,254 Epoch[23] Batch [880]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.129462,	
2017-06-26 16:43:10,163 Epoch[23] Batch [890]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.129401,	
2017-06-26 16:43:17,314 Epoch[23] Batch [900]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.129246,	
2017-06-26 16:43:24,628 Epoch[23] Batch [910]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.129016,	
2017-06-26 16:43:32,087 Epoch[23] Batch [920]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.128800,	
2017-06-26 16:43:39,336 Epoch[23] Batch [930]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.128588,	
2017-06-26 16:43:46,557 Epoch[23] Batch [940]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.128439,	
2017-06-26 16:43:53,495 Epoch[23] Batch [950]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.128220,	
2017-06-26 16:44:00,566 Epoch[23] Batch [960]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.128102,	
2017-06-26 16:44:07,608 Epoch[23] Batch [970]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.128012,	
2017-06-26 16:44:13,758 Epoch[23] Batch [980]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.127830,	
2017-06-26 16:44:19,701 Epoch[23] Batch [990]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.127685,	
2017-06-26 16:44:25,896 Epoch[23] Batch [1000]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.127586,	
2017-06-26 16:44:31,712 Epoch[23] Batch [1010]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.127411,	
2017-06-26 16:44:38,010 Epoch[23] Batch [1020]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.127400,	
2017-06-26 16:44:44,419 Epoch[23] Batch [1030]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.127229,	
2017-06-26 16:44:50,955 Epoch[23] Batch [1040]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.127057,	
2017-06-26 16:44:57,803 Epoch[23] Batch [1050]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.126866,	
2017-06-26 16:45:04,528 Epoch[23] Batch [1060]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.126718,	
2017-06-26 16:45:11,350 Epoch[23] Batch [1070]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.126556,	
2017-06-26 16:45:18,327 Epoch[23] Batch [1080]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.126517,	
2017-06-26 16:45:25,628 Epoch[23] Batch [1090]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.126352,	
2017-06-26 16:45:32,680 Epoch[23] Batch [1100]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.126134,	
2017-06-26 16:45:39,312 Epoch[23] Batch [1110]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.126052,	
2017-06-26 16:45:45,980 Epoch[23] Batch [1120]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.125951,	
2017-06-26 16:45:52,619 Epoch[23] Batch [1130]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.125746,	
2017-06-26 16:46:00,130 Epoch[23] Batch [1140]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.125474,	
2017-06-26 16:46:07,469 Epoch[23] Batch [1150]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.125369,	
2017-06-26 16:46:14,662 Epoch[23] Batch [1160]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.125278,	
2017-06-26 16:46:21,188 Epoch[23] Batch [1170]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.125168,	
2017-06-26 16:46:27,307 Epoch[23] Batch [1180]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.124971,	
2017-06-26 16:46:33,563 Epoch[23] Batch [1190]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.124887,	
2017-06-26 16:46:39,913 Epoch[23] Batch [1200]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.124811,	
2017-06-26 16:46:46,228 Epoch[23] Batch [1210]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.124729,	
2017-06-26 16:46:52,715 Epoch[23] Batch [1220]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.124747,	
2017-06-26 16:46:59,464 Epoch[23] Batch [1230]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.124555,	
2017-06-26 16:47:06,318 Epoch[23] Batch [1240]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.124487,	
2017-06-26 16:47:12,992 Epoch[23] Batch [1250]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.124309,	
2017-06-26 16:47:19,493 Epoch[23] Batch [1260]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.124282,	
2017-06-26 16:47:26,355 Epoch[23] Batch [1270]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.124154,	
2017-06-26 16:47:32,917 Epoch[23] Batch [1280]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.124074,	
2017-06-26 16:47:39,827 Epoch[23] Batch [1290]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.124008,	
2017-06-26 16:47:46,155 Epoch[23] Batch [1300]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.123841,	
2017-06-26 16:47:52,558 Epoch[23] Batch [1310]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.123757,	
2017-06-26 16:47:59,345 Epoch[23] Batch [1320]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.123735,	
2017-06-26 16:48:05,903 Epoch[23] Batch [1330]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.123774,	
2017-06-26 16:48:12,831 Epoch[23] Batch [1340]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.123677,	
2017-06-26 16:48:19,420 Epoch[23] Batch [1350]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.123633,	
2017-06-26 16:48:25,852 Epoch[23] Batch [1360]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.123548,	
2017-06-26 16:48:32,450 Epoch[23] Batch [1370]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.123423,	
2017-06-26 16:48:38,783 Epoch[23] Batch [1380]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.123353,	
2017-06-26 16:48:46,157 Epoch[23] Batch [1390]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.123243,	
2017-06-26 16:48:52,363 Epoch[23] Batch [1400]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.123210,	
2017-06-26 16:48:58,628 Epoch[23] Batch [1410]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.123195,	
2017-06-26 16:49:05,125 Epoch[23] Batch [1420]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.123090,	
2017-06-26 16:49:11,819 Epoch[23] Batch [1430]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.123084,	
2017-06-26 16:49:18,437 Epoch[23] Batch [1440]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.123024,	
2017-06-26 16:49:25,211 Epoch[23] Batch [1450]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.122969,	
2017-06-26 16:49:31,937 Epoch[23] Batch [1460]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.122911,	
2017-06-26 16:49:38,822 Epoch[23] Batch [1470]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.122893,	
2017-06-26 16:49:45,990 Epoch[23] Batch [1480]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.122834,	
2017-06-26 16:49:49,922 Epoch[23] Train-FCNLogLoss=0.122710
2017-06-26 16:49:49,923 Epoch[23] Time cost=1002.647
2017-06-26 16:49:51,335 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0024.params"
2017-06-26 16:49:55,100 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0024.states"
2017-06-26 16:50:03,075 Epoch[24] Batch [10]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.101799,	
2017-06-26 16:50:10,149 Epoch[24] Batch [20]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.101588,	
2017-06-26 16:50:17,073 Epoch[24] Batch [30]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.104840,	
2017-06-26 16:50:24,061 Epoch[24] Batch [40]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.102992,	
2017-06-26 16:50:31,231 Epoch[24] Batch [50]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.104911,	
2017-06-26 16:50:38,488 Epoch[24] Batch [60]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.105020,	
2017-06-26 16:50:45,321 Epoch[24] Batch [70]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.106249,	
2017-06-26 16:50:52,177 Epoch[24] Batch [80]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.107347,	
2017-06-26 16:50:59,273 Epoch[24] Batch [90]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.107776,	
2017-06-26 16:51:06,191 Epoch[24] Batch [100]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.109164,	
2017-06-26 16:51:12,894 Epoch[24] Batch [110]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.109240,	
2017-06-26 16:51:19,817 Epoch[24] Batch [120]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.109230,	
2017-06-26 16:51:26,623 Epoch[24] Batch [130]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.109024,	
2017-06-26 16:51:33,435 Epoch[24] Batch [140]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.108887,	
2017-06-26 16:51:40,698 Epoch[24] Batch [150]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.108655,	
2017-06-26 16:51:47,246 Epoch[24] Batch [160]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.109095,	
2017-06-26 16:51:54,415 Epoch[24] Batch [170]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.109417,	
2017-06-26 16:52:01,202 Epoch[24] Batch [180]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.108991,	
2017-06-26 16:52:07,898 Epoch[24] Batch [190]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.109051,	
2017-06-26 16:52:14,372 Epoch[24] Batch [200]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.109357,	
2017-06-26 16:52:21,125 Epoch[24] Batch [210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.109590,	
2017-06-26 16:52:27,939 Epoch[24] Batch [220]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.109549,	
2017-06-26 16:52:34,359 Epoch[24] Batch [230]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.109049,	
2017-06-26 16:52:41,223 Epoch[24] Batch [240]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.109116,	
2017-06-26 16:52:47,773 Epoch[24] Batch [250]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.109005,	
2017-06-26 16:52:53,959 Epoch[24] Batch [260]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.109017,	
2017-06-26 16:53:00,550 Epoch[24] Batch [270]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.108837,	
2017-06-26 16:53:07,110 Epoch[24] Batch [280]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.109592,	
2017-06-26 16:53:13,768 Epoch[24] Batch [290]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.110208,	
2017-06-26 16:53:20,642 Epoch[24] Batch [300]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.110396,	
2017-06-26 16:53:27,468 Epoch[24] Batch [310]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.110359,	
2017-06-26 16:53:34,307 Epoch[24] Batch [320]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.110446,	
2017-06-26 16:53:41,405 Epoch[24] Batch [330]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.110572,	
2017-06-26 16:53:48,332 Epoch[24] Batch [340]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.110347,	
2017-06-26 16:53:55,270 Epoch[24] Batch [350]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.110289,	
2017-06-26 16:54:02,247 Epoch[24] Batch [360]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.110485,	
2017-06-26 16:54:09,543 Epoch[24] Batch [370]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.110587,	
2017-06-26 16:54:16,806 Epoch[24] Batch [380]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.110569,	
2017-06-26 16:54:23,599 Epoch[24] Batch [390]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.110421,	
2017-06-26 16:54:30,588 Epoch[24] Batch [400]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.110250,	
2017-06-26 16:54:37,490 Epoch[24] Batch [410]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.109931,	
2017-06-26 16:54:43,754 Epoch[24] Batch [420]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.109885,	
2017-06-26 16:54:50,252 Epoch[24] Batch [430]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.109855,	
2017-06-26 16:54:56,683 Epoch[24] Batch [440]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.109879,	
2017-06-26 16:55:02,936 Epoch[24] Batch [450]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.109822,	
2017-06-26 16:55:09,904 Epoch[24] Batch [460]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.109761,	
2017-06-26 16:55:16,821 Epoch[24] Batch [470]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.109782,	
2017-06-26 16:55:23,965 Epoch[24] Batch [480]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.109653,	
2017-06-26 16:55:31,079 Epoch[24] Batch [490]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.109475,	
2017-06-26 16:55:38,362 Epoch[24] Batch [500]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.109431,	
2017-06-26 16:55:45,429 Epoch[24] Batch [510]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.109570,	
2017-06-26 16:55:52,193 Epoch[24] Batch [520]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.109347,	
2017-06-26 16:55:59,263 Epoch[24] Batch [530]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.109390,	
2017-06-26 16:56:06,766 Epoch[24] Batch [540]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.109387,	
2017-06-26 16:56:13,765 Epoch[24] Batch [550]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.109269,	
2017-06-26 16:56:21,132 Epoch[24] Batch [560]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.109333,	
2017-06-26 16:56:28,190 Epoch[24] Batch [570]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.109465,	
2017-06-26 16:56:35,267 Epoch[24] Batch [580]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.109605,	
2017-06-26 16:56:42,510 Epoch[24] Batch [590]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.109427,	
2017-06-26 16:56:49,740 Epoch[24] Batch [600]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.109434,	
2017-06-26 16:56:57,074 Epoch[24] Batch [610]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.109427,	
2017-06-26 16:57:03,455 Epoch[24] Batch [620]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.109409,	
2017-06-26 16:57:10,608 Epoch[24] Batch [630]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.109286,	
2017-06-26 16:57:17,243 Epoch[24] Batch [640]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.109451,	
2017-06-26 16:57:23,746 Epoch[24] Batch [650]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.109464,	
2017-06-26 16:57:30,322 Epoch[24] Batch [660]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.109345,	
2017-06-26 16:57:37,642 Epoch[24] Batch [670]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.109201,	
2017-06-26 16:57:44,556 Epoch[24] Batch [680]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.109218,	
2017-06-26 16:57:51,398 Epoch[24] Batch [690]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.109247,	
2017-06-26 16:57:58,141 Epoch[24] Batch [700]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.109225,	
2017-06-26 16:58:05,682 Epoch[24] Batch [710]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.108995,	
2017-06-26 16:58:12,821 Epoch[24] Batch [720]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.109099,	
2017-06-26 16:58:19,982 Epoch[24] Batch [730]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.109527,	
2017-06-26 16:58:26,746 Epoch[24] Batch [740]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.109841,	
2017-06-26 16:58:34,027 Epoch[24] Batch [750]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.109878,	
2017-06-26 16:58:40,819 Epoch[24] Batch [760]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.109892,	
2017-06-26 16:58:47,624 Epoch[24] Batch [770]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.110076,	
2017-06-26 16:58:54,613 Epoch[24] Batch [780]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.110022,	
2017-06-26 16:59:01,954 Epoch[24] Batch [790]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.110066,	
2017-06-26 16:59:09,398 Epoch[24] Batch [800]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.110299,	
2017-06-26 16:59:16,354 Epoch[24] Batch [810]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.110297,	
2017-06-26 16:59:23,196 Epoch[24] Batch [820]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.110570,	
2017-06-26 16:59:29,821 Epoch[24] Batch [830]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.110795,	
2017-06-26 16:59:37,004 Epoch[24] Batch [840]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.110879,	
2017-06-26 16:59:44,056 Epoch[24] Batch [850]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.111142,	
2017-06-26 16:59:51,021 Epoch[24] Batch [860]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.111222,	
2017-06-26 16:59:58,167 Epoch[24] Batch [870]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.111226,	
2017-06-26 17:00:05,395 Epoch[24] Batch [880]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.111345,	
2017-06-26 17:00:13,252 Epoch[24] Batch [890]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.111337,	
2017-06-26 17:00:21,110 Epoch[24] Batch [900]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.111263,	
2017-06-26 17:00:28,509 Epoch[24] Batch [910]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.111148,	
2017-06-26 17:00:36,174 Epoch[24] Batch [920]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.111238,	
2017-06-26 17:00:44,195 Epoch[24] Batch [930]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.111292,	
2017-06-26 17:00:50,530 Epoch[24] Batch [940]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.111426,	
2017-06-26 17:00:56,634 Epoch[24] Batch [950]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.111437,	
2017-06-26 17:01:02,746 Epoch[24] Batch [960]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.111583,	
2017-06-26 17:01:08,829 Epoch[24] Batch [970]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111637,	
2017-06-26 17:01:15,003 Epoch[24] Batch [980]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.111697,	
2017-06-26 17:01:21,122 Epoch[24] Batch [990]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.111706,	
2017-06-26 17:01:27,252 Epoch[24] Batch [1000]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111730,	
2017-06-26 17:01:33,289 Epoch[24] Batch [1010]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.111658,	
2017-06-26 17:01:39,454 Epoch[24] Batch [1020]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.111583,	
2017-06-26 17:01:45,553 Epoch[24] Batch [1030]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.111758,	
2017-06-26 17:01:51,770 Epoch[24] Batch [1040]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.112019,	
2017-06-26 17:01:58,158 Epoch[24] Batch [1050]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.112009,	
2017-06-26 17:02:04,589 Epoch[24] Batch [1060]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.112058,	
2017-06-26 17:02:11,020 Epoch[24] Batch [1070]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.112092,	
2017-06-26 17:02:17,412 Epoch[24] Batch [1080]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.112144,	
2017-06-26 17:02:24,556 Epoch[24] Batch [1090]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.112194,	
2017-06-26 17:02:31,257 Epoch[24] Batch [1100]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.112179,	
2017-06-26 17:02:37,846 Epoch[24] Batch [1110]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.112367,	
2017-06-26 17:02:44,874 Epoch[24] Batch [1120]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.112375,	
2017-06-26 17:02:51,800 Epoch[24] Batch [1130]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.112373,	
2017-06-26 17:02:58,769 Epoch[24] Batch [1140]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.112399,	
2017-06-26 17:03:05,341 Epoch[24] Batch [1150]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.112395,	
2017-06-26 17:03:11,930 Epoch[24] Batch [1160]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.112384,	
2017-06-26 17:03:18,855 Epoch[24] Batch [1170]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.112495,	
2017-06-26 17:03:25,696 Epoch[24] Batch [1180]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.112508,	
2017-06-26 17:03:32,409 Epoch[24] Batch [1190]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.112480,	
2017-06-26 17:03:39,833 Epoch[24] Batch [1200]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.112456,	
2017-06-26 17:03:47,161 Epoch[24] Batch [1210]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.112423,	
2017-06-26 17:03:53,935 Epoch[24] Batch [1220]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.112333,	
2017-06-26 17:04:00,840 Epoch[24] Batch [1230]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.112291,	
2017-06-26 17:04:07,906 Epoch[24] Batch [1240]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.112260,	
2017-06-26 17:04:14,888 Epoch[24] Batch [1250]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.112273,	
2017-06-26 17:04:21,454 Epoch[24] Batch [1260]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.112233,	
2017-06-26 17:04:28,079 Epoch[24] Batch [1270]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.112355,	
2017-06-26 17:04:34,971 Epoch[24] Batch [1280]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.112393,	
2017-06-26 17:04:41,730 Epoch[24] Batch [1290]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.112393,	
2017-06-26 17:04:48,183 Epoch[24] Batch [1300]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.112473,	
2017-06-26 17:04:55,200 Epoch[24] Batch [1310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.112447,	
2017-06-26 17:05:02,196 Epoch[24] Batch [1320]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.112460,	
2017-06-26 17:05:08,939 Epoch[24] Batch [1330]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.112494,	
2017-06-26 17:05:15,988 Epoch[24] Batch [1340]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.112594,	
2017-06-26 17:05:23,042 Epoch[24] Batch [1350]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.112610,	
2017-06-26 17:05:30,452 Epoch[24] Batch [1360]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.112552,	
2017-06-26 17:05:37,322 Epoch[24] Batch [1370]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.112546,	
2017-06-26 17:05:44,031 Epoch[24] Batch [1380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.112530,	
2017-06-26 17:05:50,786 Epoch[24] Batch [1390]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.112586,	
2017-06-26 17:05:57,796 Epoch[24] Batch [1400]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.112521,	
2017-06-26 17:06:04,266 Epoch[24] Batch [1410]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.112478,	
2017-06-26 17:06:11,370 Epoch[24] Batch [1420]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.112446,	
2017-06-26 17:06:18,554 Epoch[24] Batch [1430]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.112499,	
2017-06-26 17:06:25,626 Epoch[24] Batch [1440]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.112516,	
2017-06-26 17:06:32,547 Epoch[24] Batch [1450]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.112462,	
2017-06-26 17:06:39,769 Epoch[24] Batch [1460]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.112475,	
2017-06-26 17:06:46,589 Epoch[24] Batch [1470]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.112478,	
2017-06-26 17:06:53,413 Epoch[24] Batch [1480]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.112502,	
2017-06-26 17:06:57,584 Epoch[24] Train-FCNLogLoss=0.112600
2017-06-26 17:06:57,584 Epoch[24] Time cost=1022.484
2017-06-26 17:06:59,007 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0025.params"
2017-06-26 17:07:02,790 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0025.states"
2017-06-26 17:07:10,354 Epoch[25] Batch [10]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.118825,	
2017-06-26 17:07:17,402 Epoch[25] Batch [20]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.116818,	
2017-06-26 17:07:24,287 Epoch[25] Batch [30]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.120627,	
2017-06-26 17:07:31,316 Epoch[25] Batch [40]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.117703,	
2017-06-26 17:07:38,110 Epoch[25] Batch [50]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.117102,	
2017-06-26 17:07:45,183 Epoch[25] Batch [60]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.116162,	
2017-06-26 17:07:51,304 Epoch[25] Batch [70]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.115915,	
2017-06-26 17:07:57,423 Epoch[25] Batch [80]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.116944,	
2017-06-26 17:08:03,625 Epoch[25] Batch [90]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.115573,	
2017-06-26 17:08:09,750 Epoch[25] Batch [100]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.117161,	
2017-06-26 17:08:15,853 Epoch[25] Batch [110]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.116477,	
2017-06-26 17:08:22,494 Epoch[25] Batch [120]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.116604,	
2017-06-26 17:08:29,125 Epoch[25] Batch [130]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.117080,	
2017-06-26 17:08:35,771 Epoch[25] Batch [140]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.116779,	
2017-06-26 17:08:42,258 Epoch[25] Batch [150]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.115460,	
2017-06-26 17:08:49,447 Epoch[25] Batch [160]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.114449,	
2017-06-26 17:08:56,108 Epoch[25] Batch [170]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.114329,	
2017-06-26 17:09:02,991 Epoch[25] Batch [180]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.113692,	
2017-06-26 17:09:09,950 Epoch[25] Batch [190]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.114161,	
2017-06-26 17:09:16,833 Epoch[25] Batch [200]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.113984,	
2017-06-26 17:09:24,468 Epoch[25] Batch [210]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.113589,	
2017-06-26 17:09:31,495 Epoch[25] Batch [220]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.112830,	
2017-06-26 17:09:38,780 Epoch[25] Batch [230]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.112585,	
2017-06-26 17:09:45,962 Epoch[25] Batch [240]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.111875,	
2017-06-26 17:09:52,905 Epoch[25] Batch [250]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.111299,	
2017-06-26 17:09:59,929 Epoch[25] Batch [260]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.111599,	
2017-06-26 17:10:07,038 Epoch[25] Batch [270]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.111438,	
2017-06-26 17:10:14,249 Epoch[25] Batch [280]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.111390,	
2017-06-26 17:10:21,364 Epoch[25] Batch [290]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.111449,	
2017-06-26 17:10:28,841 Epoch[25] Batch [300]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.111470,	
2017-06-26 17:10:36,071 Epoch[25] Batch [310]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.111264,	
2017-06-26 17:10:43,292 Epoch[25] Batch [320]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.111153,	
2017-06-26 17:10:49,835 Epoch[25] Batch [330]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.111029,	
2017-06-26 17:10:56,634 Epoch[25] Batch [340]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.111001,	
2017-06-26 17:11:03,826 Epoch[25] Batch [350]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.110958,	
2017-06-26 17:11:10,587 Epoch[25] Batch [360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.110646,	
2017-06-26 17:11:17,256 Epoch[25] Batch [370]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.110229,	
2017-06-26 17:11:23,987 Epoch[25] Batch [380]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.110355,	
2017-06-26 17:11:30,990 Epoch[25] Batch [390]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.110082,	
2017-06-26 17:11:37,934 Epoch[25] Batch [400]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.110317,	
2017-06-26 17:11:45,046 Epoch[25] Batch [410]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.110410,	
2017-06-26 17:11:51,684 Epoch[25] Batch [420]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.110156,	
2017-06-26 17:11:58,675 Epoch[25] Batch [430]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.110244,	
2017-06-26 17:12:05,416 Epoch[25] Batch [440]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.110375,	
2017-06-26 17:12:12,288 Epoch[25] Batch [450]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.110283,	
2017-06-26 17:12:19,371 Epoch[25] Batch [460]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.110118,	
2017-06-26 17:12:25,539 Epoch[25] Batch [470]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.109882,	
2017-06-26 17:12:31,739 Epoch[25] Batch [480]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.109778,	
2017-06-26 17:12:37,946 Epoch[25] Batch [490]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.110143,	
2017-06-26 17:12:44,059 Epoch[25] Batch [500]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.110205,	
2017-06-26 17:12:50,195 Epoch[25] Batch [510]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.109991,	
2017-06-26 17:12:56,438 Epoch[25] Batch [520]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.109996,	
2017-06-26 17:13:02,533 Epoch[25] Batch [530]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.109933,	
2017-06-26 17:13:08,653 Epoch[25] Batch [540]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.109921,	
2017-06-26 17:13:14,806 Epoch[25] Batch [550]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.109816,	
2017-06-26 17:13:20,908 Epoch[25] Batch [560]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.109817,	
2017-06-26 17:13:27,287 Epoch[25] Batch [570]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.109593,	
2017-06-26 17:13:33,504 Epoch[25] Batch [580]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.109484,	
2017-06-26 17:13:40,712 Epoch[25] Batch [590]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.109475,	
2017-06-26 17:13:48,042 Epoch[25] Batch [600]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.109425,	
2017-06-26 17:13:54,998 Epoch[25] Batch [610]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.109399,	
2017-06-26 17:14:02,736 Epoch[25] Batch [620]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.109427,	
2017-06-26 17:14:10,113 Epoch[25] Batch [630]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.109532,	
2017-06-26 17:14:17,718 Epoch[25] Batch [640]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.109431,	
2017-06-26 17:14:25,320 Epoch[25] Batch [650]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.109314,	
2017-06-26 17:14:32,248 Epoch[25] Batch [660]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.109400,	
2017-06-26 17:14:38,990 Epoch[25] Batch [670]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.109442,	
2017-06-26 17:14:45,554 Epoch[25] Batch [680]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.109323,	
2017-06-26 17:14:51,792 Epoch[25] Batch [690]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.109509,	
2017-06-26 17:14:57,961 Epoch[25] Batch [700]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.109436,	
2017-06-26 17:15:04,943 Epoch[25] Batch [710]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.109555,	
2017-06-26 17:15:12,234 Epoch[25] Batch [720]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.109496,	
2017-06-26 17:15:19,192 Epoch[25] Batch [730]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.109530,	
2017-06-26 17:15:25,912 Epoch[25] Batch [740]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.109460,	
2017-06-26 17:15:32,731 Epoch[25] Batch [750]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.109552,	
2017-06-26 17:15:39,893 Epoch[25] Batch [760]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.109513,	
2017-06-26 17:15:47,003 Epoch[25] Batch [770]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109582,	
2017-06-26 17:15:54,475 Epoch[25] Batch [780]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.109577,	
2017-06-26 17:16:01,504 Epoch[25] Batch [790]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.109412,	
2017-06-26 17:16:08,362 Epoch[25] Batch [800]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.109515,	
2017-06-26 17:16:15,025 Epoch[25] Batch [810]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109737,	
2017-06-26 17:16:20,960 Epoch[25] Batch [820]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.109726,	
2017-06-26 17:16:27,034 Epoch[25] Batch [830]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109792,	
2017-06-26 17:16:33,298 Epoch[25] Batch [840]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.109712,	
2017-06-26 17:16:39,344 Epoch[25] Batch [850]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109677,	
2017-06-26 17:16:45,630 Epoch[25] Batch [860]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.109601,	
2017-06-26 17:16:51,681 Epoch[25] Batch [870]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109823,	
2017-06-26 17:16:57,778 Epoch[25] Batch [880]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.109928,	
2017-06-26 17:17:04,380 Epoch[25] Batch [890]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.109839,	
2017-06-26 17:17:10,682 Epoch[25] Batch [900]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.109867,	
2017-06-26 17:17:16,796 Epoch[25] Batch [910]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.109816,	
2017-06-26 17:17:23,288 Epoch[25] Batch [920]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.109690,	
2017-06-26 17:17:30,275 Epoch[25] Batch [930]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.109625,	
2017-06-26 17:17:37,449 Epoch[25] Batch [940]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.109675,	
2017-06-26 17:17:45,062 Epoch[25] Batch [950]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.109645,	
2017-06-26 17:17:52,445 Epoch[25] Batch [960]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.109665,	
2017-06-26 17:17:59,686 Epoch[25] Batch [970]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.109653,	
2017-06-26 17:18:07,404 Epoch[25] Batch [980]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.109486,	
2017-06-26 17:18:14,784 Epoch[25] Batch [990]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.109513,	
2017-06-26 17:18:22,674 Epoch[25] Batch [1000]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.109463,	
2017-06-26 17:18:29,852 Epoch[25] Batch [1010]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.109493,	
2017-06-26 17:18:37,373 Epoch[25] Batch [1020]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.109424,	
2017-06-26 17:18:45,125 Epoch[25] Batch [1030]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.109495,	
2017-06-26 17:18:53,101 Epoch[25] Batch [1040]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.109465,	
2017-06-26 17:19:00,891 Epoch[25] Batch [1050]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.109392,	
2017-06-26 17:19:08,309 Epoch[25] Batch [1060]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.109423,	
2017-06-26 17:19:15,528 Epoch[25] Batch [1070]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.109463,	
2017-06-26 17:19:22,642 Epoch[25] Batch [1080]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.109394,	
2017-06-26 17:19:29,988 Epoch[25] Batch [1090]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.109409,	
2017-06-26 17:19:37,059 Epoch[25] Batch [1100]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.109356,	
2017-06-26 17:19:44,544 Epoch[25] Batch [1110]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.109300,	
2017-06-26 17:19:51,475 Epoch[25] Batch [1120]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.109288,	
2017-06-26 17:19:58,579 Epoch[25] Batch [1130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109262,	
2017-06-26 17:20:05,977 Epoch[25] Batch [1140]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.109221,	
2017-06-26 17:20:12,728 Epoch[25] Batch [1150]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.109253,	
2017-06-26 17:20:20,232 Epoch[25] Batch [1160]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.109214,	
2017-06-26 17:20:27,676 Epoch[25] Batch [1170]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.109353,	
2017-06-26 17:20:34,518 Epoch[25] Batch [1180]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.109367,	
2017-06-26 17:20:41,565 Epoch[25] Batch [1190]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.109414,	
2017-06-26 17:20:48,372 Epoch[25] Batch [1200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.109486,	
2017-06-26 17:20:55,554 Epoch[25] Batch [1210]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.109372,	
2017-06-26 17:21:03,293 Epoch[25] Batch [1220]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.109338,	
2017-06-26 17:21:10,596 Epoch[25] Batch [1230]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.109299,	
2017-06-26 17:21:17,555 Epoch[25] Batch [1240]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.109471,	
2017-06-26 17:21:24,890 Epoch[25] Batch [1250]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.109482,	
2017-06-26 17:21:32,202 Epoch[25] Batch [1260]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.109444,	
2017-06-26 17:21:39,112 Epoch[25] Batch [1270]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.109451,	
2017-06-26 17:21:46,223 Epoch[25] Batch [1280]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109477,	
2017-06-26 17:21:53,708 Epoch[25] Batch [1290]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.109489,	
2017-06-26 17:22:00,749 Epoch[25] Batch [1300]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.109475,	
2017-06-26 17:22:08,324 Epoch[25] Batch [1310]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.109638,	
2017-06-26 17:22:15,611 Epoch[25] Batch [1320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.109629,	
2017-06-26 17:22:22,551 Epoch[25] Batch [1330]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.109680,	
2017-06-26 17:22:30,084 Epoch[25] Batch [1340]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.109725,	
2017-06-26 17:22:37,278 Epoch[25] Batch [1350]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.109845,	
2017-06-26 17:22:44,844 Epoch[25] Batch [1360]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.109878,	
2017-06-26 17:22:52,305 Epoch[25] Batch [1370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.109809,	
2017-06-26 17:22:59,238 Epoch[25] Batch [1380]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.109877,	
2017-06-26 17:23:06,304 Epoch[25] Batch [1390]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.109869,	
2017-06-26 17:23:13,228 Epoch[25] Batch [1400]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.109862,	
2017-06-26 17:23:20,212 Epoch[25] Batch [1410]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.109930,	
2017-06-26 17:23:26,965 Epoch[25] Batch [1420]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.109901,	
2017-06-26 17:23:33,751 Epoch[25] Batch [1430]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.109884,	
2017-06-26 17:23:40,842 Epoch[25] Batch [1440]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.109889,	
2017-06-26 17:23:48,187 Epoch[25] Batch [1450]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.109937,	
2017-06-26 17:23:55,668 Epoch[25] Batch [1460]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.109917,	
2017-06-26 17:24:02,703 Epoch[25] Batch [1470]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.109858,	
2017-06-26 17:24:10,150 Epoch[25] Batch [1480]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.109799,	
2017-06-26 17:24:14,484 Epoch[25] Train-FCNLogLoss=0.109779
2017-06-26 17:24:14,484 Epoch[25] Time cost=1031.694
2017-06-26 17:24:15,888 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0026.params"
2017-06-26 17:24:19,646 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0026.states"
2017-06-26 17:24:28,111 Epoch[26] Batch [10]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.104840,	
2017-06-26 17:24:35,264 Epoch[26] Batch [20]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.110683,	
2017-06-26 17:24:42,216 Epoch[26] Batch [30]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.108352,	
2017-06-26 17:24:48,989 Epoch[26] Batch [40]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.104182,	
2017-06-26 17:24:55,802 Epoch[26] Batch [50]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.103908,	
2017-06-26 17:25:02,492 Epoch[26] Batch [60]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.102391,	
2017-06-26 17:25:10,077 Epoch[26] Batch [70]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.102550,	
2017-06-26 17:25:17,217 Epoch[26] Batch [80]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.103661,	
2017-06-26 17:25:24,032 Epoch[26] Batch [90]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.103297,	
2017-06-26 17:25:30,973 Epoch[26] Batch [100]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102496,	
2017-06-26 17:25:38,197 Epoch[26] Batch [110]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.101758,	
2017-06-26 17:25:45,595 Epoch[26] Batch [120]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.101517,	
2017-06-26 17:25:52,807 Epoch[26] Batch [130]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.101511,	
2017-06-26 17:25:59,744 Epoch[26] Batch [140]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.102522,	
2017-06-26 17:26:06,720 Epoch[26] Batch [150]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.102983,	
2017-06-26 17:26:13,987 Epoch[26] Batch [160]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.102635,	
2017-06-26 17:26:20,897 Epoch[26] Batch [170]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.102515,	
2017-06-26 17:26:28,531 Epoch[26] Batch [180]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.102076,	
2017-06-26 17:26:35,443 Epoch[26] Batch [190]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.101848,	
2017-06-26 17:26:41,857 Epoch[26] Batch [200]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.102115,	
2017-06-26 17:26:48,108 Epoch[26] Batch [210]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.102320,	
2017-06-26 17:26:53,517 Epoch[26] Batch [220]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.103383,	
2017-06-26 17:27:00,109 Epoch[26] Batch [230]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.103489,	
2017-06-26 17:27:06,029 Epoch[26] Batch [240]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.103612,	
2017-06-26 17:27:12,626 Epoch[26] Batch [250]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.103559,	
2017-06-26 17:27:18,985 Epoch[26] Batch [260]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.103418,	
2017-06-26 17:27:25,808 Epoch[26] Batch [270]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.103038,	
2017-06-26 17:27:33,219 Epoch[26] Batch [280]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.103074,	
2017-06-26 17:27:40,438 Epoch[26] Batch [290]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.103867,	
2017-06-26 17:27:47,749 Epoch[26] Batch [300]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.103932,	
2017-06-26 17:27:54,749 Epoch[26] Batch [310]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.104512,	
2017-06-26 17:28:02,228 Epoch[26] Batch [320]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.104446,	
2017-06-26 17:28:09,131 Epoch[26] Batch [330]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.104658,	
2017-06-26 17:28:16,848 Epoch[26] Batch [340]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.104882,	
2017-06-26 17:28:26,178 Epoch[26] Batch [350]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.105096,	
2017-06-26 17:28:35,693 Epoch[26] Batch [360]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.105424,	
2017-06-26 17:28:43,900 Epoch[26] Batch [370]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.105547,	
2017-06-26 17:28:50,545 Epoch[26] Batch [380]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.105359,	
2017-06-26 17:28:56,806 Epoch[26] Batch [390]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.105722,	
2017-06-26 17:29:02,951 Epoch[26] Batch [400]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.105661,	
2017-06-26 17:29:09,367 Epoch[26] Batch [410]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.105675,	
2017-06-26 17:29:15,467 Epoch[26] Batch [420]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.105544,	
2017-06-26 17:29:22,426 Epoch[26] Batch [430]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.105418,	
2017-06-26 17:29:29,410 Epoch[26] Batch [440]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.105613,	
2017-06-26 17:29:36,707 Epoch[26] Batch [450]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.105792,	
2017-06-26 17:29:44,131 Epoch[26] Batch [460]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.106147,	
2017-06-26 17:29:51,371 Epoch[26] Batch [470]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.106116,	
2017-06-26 17:29:58,734 Epoch[26] Batch [480]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.106183,	
2017-06-26 17:30:06,050 Epoch[26] Batch [490]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.106258,	
2017-06-26 17:30:13,054 Epoch[26] Batch [500]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.106510,	
2017-06-26 17:30:20,151 Epoch[26] Batch [510]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.106640,	
2017-06-26 17:30:27,372 Epoch[26] Batch [520]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.106788,	
2017-06-26 17:30:34,529 Epoch[26] Batch [530]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.106706,	
2017-06-26 17:30:41,735 Epoch[26] Batch [540]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.106912,	
2017-06-26 17:30:48,953 Epoch[26] Batch [550]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.106910,	
2017-06-26 17:30:56,506 Epoch[26] Batch [560]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.107361,	
2017-06-26 17:31:03,219 Epoch[26] Batch [570]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.107397,	
2017-06-26 17:31:09,026 Epoch[26] Batch [580]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107436,	
2017-06-26 17:31:15,140 Epoch[26] Batch [590]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107478,	
2017-06-26 17:31:21,277 Epoch[26] Batch [600]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.107564,	
2017-06-26 17:31:27,450 Epoch[26] Batch [610]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.107576,	
2017-06-26 17:31:33,660 Epoch[26] Batch [620]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.107517,	
2017-06-26 17:31:39,805 Epoch[26] Batch [630]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.107449,	
2017-06-26 17:31:45,928 Epoch[26] Batch [640]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.107234,	
2017-06-26 17:31:52,128 Epoch[26] Batch [650]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.107186,	
2017-06-26 17:31:58,242 Epoch[26] Batch [660]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107298,	
2017-06-26 17:32:04,375 Epoch[26] Batch [670]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.107332,	
2017-06-26 17:32:11,311 Epoch[26] Batch [680]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.107333,	
2017-06-26 17:32:18,573 Epoch[26] Batch [690]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.107243,	
2017-06-26 17:32:25,633 Epoch[26] Batch [700]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.107118,	
2017-06-26 17:32:33,260 Epoch[26] Batch [710]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.107044,	
2017-06-26 17:32:40,910 Epoch[26] Batch [720]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.106907,	
2017-06-26 17:32:49,027 Epoch[26] Batch [730]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.106932,	
2017-06-26 17:32:57,246 Epoch[26] Batch [740]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.106878,	
2017-06-26 17:33:05,470 Epoch[26] Batch [750]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.106770,	
2017-06-26 17:33:12,933 Epoch[26] Batch [760]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.106920,	
2017-06-26 17:33:20,547 Epoch[26] Batch [770]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.106886,	
2017-06-26 17:33:27,965 Epoch[26] Batch [780]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.106893,	
2017-06-26 17:33:35,376 Epoch[26] Batch [790]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.106786,	
2017-06-26 17:33:42,258 Epoch[26] Batch [800]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106873,	
2017-06-26 17:33:48,848 Epoch[26] Batch [810]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.106875,	
2017-06-26 17:33:55,086 Epoch[26] Batch [820]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106825,	
2017-06-26 17:34:00,765 Epoch[26] Batch [830]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.106783,	
2017-06-26 17:34:06,495 Epoch[26] Batch [840]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106748,	
2017-06-26 17:34:12,380 Epoch[26] Batch [850]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.106895,	
2017-06-26 17:34:18,256 Epoch[26] Batch [860]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106857,	
2017-06-26 17:34:24,561 Epoch[26] Batch [870]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.107045,	
2017-06-26 17:34:31,057 Epoch[26] Batch [880]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.106959,	
2017-06-26 17:34:37,372 Epoch[26] Batch [890]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.106955,	
2017-06-26 17:34:43,585 Epoch[26] Batch [900]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.106812,	
2017-06-26 17:34:49,641 Epoch[26] Batch [910]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106935,	
2017-06-26 17:34:55,830 Epoch[26] Batch [920]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.106949,	
2017-06-26 17:35:01,941 Epoch[26] Batch [930]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.107035,	
2017-06-26 17:35:08,048 Epoch[26] Batch [940]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106989,	
2017-06-26 17:35:14,115 Epoch[26] Batch [950]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106863,	
2017-06-26 17:35:20,248 Epoch[26] Batch [960]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.106976,	
2017-06-26 17:35:26,335 Epoch[26] Batch [970]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107077,	
2017-06-26 17:35:32,684 Epoch[26] Batch [980]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.107227,	
2017-06-26 17:35:38,911 Epoch[26] Batch [990]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.107407,	
2017-06-26 17:35:45,466 Epoch[26] Batch [1000]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.107296,	
2017-06-26 17:35:51,867 Epoch[26] Batch [1010]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.107264,	
2017-06-26 17:35:58,730 Epoch[26] Batch [1020]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.107191,	
2017-06-26 17:36:05,810 Epoch[26] Batch [1030]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.107163,	
2017-06-26 17:36:13,108 Epoch[26] Batch [1040]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.107336,	
2017-06-26 17:36:20,003 Epoch[26] Batch [1050]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.107427,	
2017-06-26 17:36:27,531 Epoch[26] Batch [1060]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.107528,	
2017-06-26 17:36:34,818 Epoch[26] Batch [1070]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.107476,	
2017-06-26 17:36:41,826 Epoch[26] Batch [1080]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.107538,	
2017-06-26 17:36:49,019 Epoch[26] Batch [1090]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.107532,	
2017-06-26 17:36:55,939 Epoch[26] Batch [1100]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.107619,	
2017-06-26 17:37:03,066 Epoch[26] Batch [1110]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.107661,	
2017-06-26 17:37:10,099 Epoch[26] Batch [1120]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.107714,	
2017-06-26 17:37:17,148 Epoch[26] Batch [1130]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.107808,	
2017-06-26 17:37:24,035 Epoch[26] Batch [1140]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.107942,	
2017-06-26 17:37:31,241 Epoch[26] Batch [1150]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.107944,	
2017-06-26 17:37:37,973 Epoch[26] Batch [1160]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.107873,	
2017-06-26 17:37:44,883 Epoch[26] Batch [1170]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.107830,	
2017-06-26 17:37:51,925 Epoch[26] Batch [1180]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.107836,	
2017-06-26 17:37:58,928 Epoch[26] Batch [1190]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.107806,	
2017-06-26 17:38:06,077 Epoch[26] Batch [1200]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.107695,	
2017-06-26 17:38:13,023 Epoch[26] Batch [1210]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.107712,	
2017-06-26 17:38:20,477 Epoch[26] Batch [1220]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.107727,	
2017-06-26 17:38:27,831 Epoch[26] Batch [1230]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.108035,	
2017-06-26 17:38:35,292 Epoch[26] Batch [1240]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.108140,	
2017-06-26 17:38:42,684 Epoch[26] Batch [1250]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.108173,	
2017-06-26 17:38:50,092 Epoch[26] Batch [1260]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.108274,	
2017-06-26 17:38:57,691 Epoch[26] Batch [1270]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.108298,	
2017-06-26 17:39:04,835 Epoch[26] Batch [1280]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.108584,	
2017-06-26 17:39:11,840 Epoch[26] Batch [1290]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.108663,	
2017-06-26 17:39:18,842 Epoch[26] Batch [1300]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.108989,	
2017-06-26 17:39:25,915 Epoch[26] Batch [1310]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.109107,	
2017-06-26 17:39:32,919 Epoch[26] Batch [1320]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.109149,	
2017-06-26 17:39:39,988 Epoch[26] Batch [1330]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.109143,	
2017-06-26 17:39:47,002 Epoch[26] Batch [1340]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.109125,	
2017-06-26 17:39:54,496 Epoch[26] Batch [1350]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.109111,	
2017-06-26 17:40:01,454 Epoch[26] Batch [1360]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.109090,	
2017-06-26 17:40:08,911 Epoch[26] Batch [1370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.109084,	
2017-06-26 17:40:15,841 Epoch[26] Batch [1380]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.109138,	
2017-06-26 17:40:22,943 Epoch[26] Batch [1390]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109139,	
2017-06-26 17:40:29,830 Epoch[26] Batch [1400]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.109145,	
2017-06-26 17:40:36,822 Epoch[26] Batch [1410]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.109164,	
2017-06-26 17:40:43,682 Epoch[26] Batch [1420]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.109226,	
2017-06-26 17:40:50,884 Epoch[26] Batch [1430]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.109294,	
2017-06-26 17:40:57,859 Epoch[26] Batch [1440]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.109271,	
2017-06-26 17:41:05,182 Epoch[26] Batch [1450]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.109330,	
2017-06-26 17:41:12,186 Epoch[26] Batch [1460]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.109348,	
2017-06-26 17:41:18,849 Epoch[26] Batch [1470]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109392,	
2017-06-26 17:41:26,142 Epoch[26] Batch [1480]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.109378,	
2017-06-26 17:41:30,762 Epoch[26] Train-FCNLogLoss=0.109374
2017-06-26 17:41:30,763 Epoch[26] Time cost=1031.116
2017-06-26 17:41:32,280 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0027.params"
2017-06-26 17:41:36,133 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0027.states"
2017-06-26 17:41:44,462 Epoch[27] Batch [10]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.117057,	
2017-06-26 17:41:51,865 Epoch[27] Batch [20]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.114051,	
2017-06-26 17:41:59,760 Epoch[27] Batch [30]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.113671,	
2017-06-26 17:42:07,124 Epoch[27] Batch [40]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.112163,	
2017-06-26 17:42:14,390 Epoch[27] Batch [50]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.110977,	
2017-06-26 17:42:21,391 Epoch[27] Batch [60]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.108245,	
2017-06-26 17:42:28,457 Epoch[27] Batch [70]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.108067,	
2017-06-26 17:42:35,745 Epoch[27] Batch [80]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.108417,	
2017-06-26 17:42:42,696 Epoch[27] Batch [90]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.108620,	
2017-06-26 17:42:50,150 Epoch[27] Batch [100]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.108454,	
2017-06-26 17:42:57,063 Epoch[27] Batch [110]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.108483,	
2017-06-26 17:43:04,276 Epoch[27] Batch [120]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.107089,	
2017-06-26 17:43:11,521 Epoch[27] Batch [130]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.107095,	
2017-06-26 17:43:18,929 Epoch[27] Batch [140]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.106698,	
2017-06-26 17:43:26,103 Epoch[27] Batch [150]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.107481,	
2017-06-26 17:43:33,274 Epoch[27] Batch [160]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.107341,	
2017-06-26 17:43:40,646 Epoch[27] Batch [170]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.107917,	
2017-06-26 17:43:47,033 Epoch[27] Batch [180]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.108360,	
2017-06-26 17:43:53,321 Epoch[27] Batch [190]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.108471,	
2017-06-26 17:43:59,401 Epoch[27] Batch [200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108255,	
2017-06-26 17:44:05,614 Epoch[27] Batch [210]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.108459,	
2017-06-26 17:44:11,726 Epoch[27] Batch [220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.108509,	
2017-06-26 17:44:18,732 Epoch[27] Batch [230]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.108603,	
2017-06-26 17:44:25,401 Epoch[27] Batch [240]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.108291,	
2017-06-26 17:44:32,647 Epoch[27] Batch [250]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.108772,	
2017-06-26 17:44:39,318 Epoch[27] Batch [260]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109610,	
2017-06-26 17:44:46,459 Epoch[27] Batch [270]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.109605,	
2017-06-26 17:44:53,983 Epoch[27] Batch [280]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.109181,	
2017-06-26 17:45:00,895 Epoch[27] Batch [290]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.109593,	
2017-06-26 17:45:07,912 Epoch[27] Batch [300]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.109476,	
2017-06-26 17:45:14,702 Epoch[27] Batch [310]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.109362,	
2017-06-26 17:45:21,794 Epoch[27] Batch [320]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.109104,	
2017-06-26 17:45:29,422 Epoch[27] Batch [330]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.108848,	
2017-06-26 17:45:36,588 Epoch[27] Batch [340]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.108682,	
2017-06-26 17:45:43,972 Epoch[27] Batch [350]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.108255,	
2017-06-26 17:45:51,545 Epoch[27] Batch [360]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.108132,	
2017-06-26 17:45:58,586 Epoch[27] Batch [370]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.107875,	
2017-06-26 17:46:05,012 Epoch[27] Batch [380]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.107832,	
2017-06-26 17:46:11,282 Epoch[27] Batch [390]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.107843,	
2017-06-26 17:46:17,719 Epoch[27] Batch [400]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.107580,	
2017-06-26 17:46:24,731 Epoch[27] Batch [410]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.107423,	
2017-06-26 17:46:32,015 Epoch[27] Batch [420]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.107454,	
2017-06-26 17:46:39,542 Epoch[27] Batch [430]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.107432,	
2017-06-26 17:46:46,878 Epoch[27] Batch [440]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.107350,	
2017-06-26 17:46:54,338 Epoch[27] Batch [450]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.107348,	
2017-06-26 17:47:01,703 Epoch[27] Batch [460]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.107117,	
2017-06-26 17:47:08,930 Epoch[27] Batch [470]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.106994,	
2017-06-26 17:47:16,563 Epoch[27] Batch [480]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.107235,	
2017-06-26 17:47:24,029 Epoch[27] Batch [490]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.106914,	
2017-06-26 17:47:31,110 Epoch[27] Batch [500]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.106816,	
2017-06-26 17:47:38,524 Epoch[27] Batch [510]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.106887,	
2017-06-26 17:47:45,936 Epoch[27] Batch [520]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.106944,	
2017-06-26 17:47:53,327 Epoch[27] Batch [530]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.107040,	
2017-06-26 17:48:00,374 Epoch[27] Batch [540]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.107014,	
2017-06-26 17:48:07,441 Epoch[27] Batch [550]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.106820,	
2017-06-26 17:48:14,137 Epoch[27] Batch [560]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.106748,	
2017-06-26 17:48:21,153 Epoch[27] Batch [570]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.106683,	
2017-06-26 17:48:28,364 Epoch[27] Batch [580]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.106726,	
2017-06-26 17:48:35,723 Epoch[27] Batch [590]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.106780,	
2017-06-26 17:48:43,508 Epoch[27] Batch [600]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.106889,	
2017-06-26 17:48:50,816 Epoch[27] Batch [610]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.106793,	
2017-06-26 17:48:58,600 Epoch[27] Batch [620]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.106772,	
2017-06-26 17:49:06,797 Epoch[27] Batch [630]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.106676,	
2017-06-26 17:49:14,593 Epoch[27] Batch [640]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.106725,	
2017-06-26 17:49:22,576 Epoch[27] Batch [650]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.106655,	
2017-06-26 17:49:30,187 Epoch[27] Batch [660]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.106755,	
2017-06-26 17:49:38,043 Epoch[27] Batch [670]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.106819,	
2017-06-26 17:49:45,733 Epoch[27] Batch [680]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.106893,	
2017-06-26 17:49:53,324 Epoch[27] Batch [690]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.106954,	
2017-06-26 17:50:00,770 Epoch[27] Batch [700]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.107168,	
2017-06-26 17:50:08,474 Epoch[27] Batch [710]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.106968,	
2017-06-26 17:50:15,989 Epoch[27] Batch [720]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.107016,	
2017-06-26 17:50:23,512 Epoch[27] Batch [730]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.106939,	
2017-06-26 17:50:30,970 Epoch[27] Batch [740]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.107050,	
2017-06-26 17:50:38,990 Epoch[27] Batch [750]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.107305,	
2017-06-26 17:50:46,677 Epoch[27] Batch [760]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.107273,	
2017-06-26 17:50:54,017 Epoch[27] Batch [770]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.107242,	
2017-06-26 17:51:01,220 Epoch[27] Batch [780]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.107080,	
2017-06-26 17:51:08,566 Epoch[27] Batch [790]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.107126,	
2017-06-26 17:51:16,028 Epoch[27] Batch [800]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.106977,	
2017-06-26 17:51:23,327 Epoch[27] Batch [810]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.106983,	
2017-06-26 17:51:31,028 Epoch[27] Batch [820]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.107281,	
2017-06-26 17:51:38,709 Epoch[27] Batch [830]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.107367,	
2017-06-26 17:51:46,043 Epoch[27] Batch [840]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.107323,	
2017-06-26 17:51:53,434 Epoch[27] Batch [850]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.107352,	
2017-06-26 17:52:00,819 Epoch[27] Batch [860]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.107283,	
2017-06-26 17:52:08,307 Epoch[27] Batch [870]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.107351,	
2017-06-26 17:52:16,021 Epoch[27] Batch [880]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.107182,	
2017-06-26 17:52:23,745 Epoch[27] Batch [890]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.107241,	
2017-06-26 17:52:31,363 Epoch[27] Batch [900]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.107212,	
2017-06-26 17:52:38,913 Epoch[27] Batch [910]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.107244,	
2017-06-26 17:52:46,368 Epoch[27] Batch [920]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.107316,	
2017-06-26 17:52:53,831 Epoch[27] Batch [930]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.107312,	
2017-06-26 17:53:01,255 Epoch[27] Batch [940]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.107113,	
2017-06-26 17:53:08,553 Epoch[27] Batch [950]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.107141,	
2017-06-26 17:53:15,870 Epoch[27] Batch [960]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.107127,	
2017-06-26 17:53:23,542 Epoch[27] Batch [970]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.107139,	
2017-06-26 17:53:30,763 Epoch[27] Batch [980]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.107228,	
2017-06-26 17:53:38,040 Epoch[27] Batch [990]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.107274,	
2017-06-26 17:53:45,385 Epoch[27] Batch [1000]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.107240,	
2017-06-26 17:53:52,885 Epoch[27] Batch [1010]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.107151,	
2017-06-26 17:54:00,513 Epoch[27] Batch [1020]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.107149,	
2017-06-26 17:54:08,482 Epoch[27] Batch [1030]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.107097,	
2017-06-26 17:54:16,138 Epoch[27] Batch [1040]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.107136,	
2017-06-26 17:54:24,111 Epoch[27] Batch [1050]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.107162,	
2017-06-26 17:54:32,399 Epoch[27] Batch [1060]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.107081,	
2017-06-26 17:54:40,038 Epoch[27] Batch [1070]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.107101,	
2017-06-26 17:54:47,862 Epoch[27] Batch [1080]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.107123,	
2017-06-26 17:54:55,628 Epoch[27] Batch [1090]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.107200,	
2017-06-26 17:55:03,181 Epoch[27] Batch [1100]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.107028,	
2017-06-26 17:55:10,595 Epoch[27] Batch [1110]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.106986,	
2017-06-26 17:55:18,238 Epoch[27] Batch [1120]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.107040,	
2017-06-26 17:55:26,182 Epoch[27] Batch [1130]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.106954,	
2017-06-26 17:55:33,658 Epoch[27] Batch [1140]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.107024,	
2017-06-26 17:55:41,498 Epoch[27] Batch [1150]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.106956,	
2017-06-26 17:55:48,834 Epoch[27] Batch [1160]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.106930,	
2017-06-26 17:55:55,456 Epoch[27] Batch [1170]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.106927,	
2017-06-26 17:56:01,582 Epoch[27] Batch [1180]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106935,	
2017-06-26 17:56:07,837 Epoch[27] Batch [1190]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.106923,	
2017-06-26 17:56:14,044 Epoch[27] Batch [1200]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.106859,	
2017-06-26 17:56:20,489 Epoch[27] Batch [1210]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.106837,	
2017-06-26 17:56:26,482 Epoch[27] Batch [1220]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106863,	
2017-06-26 17:56:33,047 Epoch[27] Batch [1230]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.106898,	
2017-06-26 17:56:39,347 Epoch[27] Batch [1240]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.106717,	
2017-06-26 17:56:45,869 Epoch[27] Batch [1250]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.106694,	
2017-06-26 17:56:52,462 Epoch[27] Batch [1260]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.106712,	
2017-06-26 17:56:58,970 Epoch[27] Batch [1270]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.106669,	
2017-06-26 17:57:06,260 Epoch[27] Batch [1280]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.106734,	
2017-06-26 17:57:12,986 Epoch[27] Batch [1290]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.106743,	
2017-06-26 17:57:20,229 Epoch[27] Batch [1300]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.106713,	
2017-06-26 17:57:28,183 Epoch[27] Batch [1310]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.106641,	
2017-06-26 17:57:36,045 Epoch[27] Batch [1320]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.106693,	
2017-06-26 17:57:43,387 Epoch[27] Batch [1330]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.106643,	
2017-06-26 17:57:50,731 Epoch[27] Batch [1340]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.106632,	
2017-06-26 17:57:58,064 Epoch[27] Batch [1350]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.106540,	
2017-06-26 17:58:05,670 Epoch[27] Batch [1360]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.106533,	
2017-06-26 17:58:12,606 Epoch[27] Batch [1370]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.106605,	
2017-06-26 17:58:19,609 Epoch[27] Batch [1380]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.106609,	
2017-06-26 17:58:26,388 Epoch[27] Batch [1390]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.106721,	
2017-06-26 17:58:32,899 Epoch[27] Batch [1400]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.106748,	
2017-06-26 17:58:40,419 Epoch[27] Batch [1410]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.106741,	
2017-06-26 17:58:47,908 Epoch[27] Batch [1420]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.106705,	
2017-06-26 17:58:55,116 Epoch[27] Batch [1430]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.106727,	
2017-06-26 17:59:02,722 Epoch[27] Batch [1440]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.106805,	
2017-06-26 17:59:10,610 Epoch[27] Batch [1450]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.106936,	
2017-06-26 17:59:18,031 Epoch[27] Batch [1460]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.106953,	
2017-06-26 17:59:25,458 Epoch[27] Batch [1470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.106932,	
2017-06-26 17:59:33,034 Epoch[27] Batch [1480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.106936,	
2017-06-26 17:59:37,524 Epoch[27] Train-FCNLogLoss=0.107062
2017-06-26 17:59:37,524 Epoch[27] Time cost=1081.390
2017-06-26 17:59:38,895 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0028.params"
2017-06-26 17:59:42,495 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0028.states"
2017-06-26 17:59:51,200 Epoch[28] Batch [10]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.113289,	
2017-06-26 17:59:58,863 Epoch[28] Batch [20]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.107707,	
2017-06-26 18:00:06,034 Epoch[28] Batch [30]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.110763,	
2017-06-26 18:00:13,575 Epoch[28] Batch [40]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.110385,	
2017-06-26 18:00:20,667 Epoch[28] Batch [50]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.108668,	
2017-06-26 18:00:27,879 Epoch[28] Batch [60]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.107649,	
2017-06-26 18:00:35,194 Epoch[28] Batch [70]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.106358,	
2017-06-26 18:00:42,913 Epoch[28] Batch [80]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.111269,	
2017-06-26 18:00:50,382 Epoch[28] Batch [90]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.111425,	
2017-06-26 18:00:57,828 Epoch[28] Batch [100]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.111748,	
2017-06-26 18:01:05,412 Epoch[28] Batch [110]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.111326,	
2017-06-26 18:01:12,674 Epoch[28] Batch [120]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.110854,	
2017-06-26 18:01:20,004 Epoch[28] Batch [130]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.110658,	
2017-06-26 18:01:27,224 Epoch[28] Batch [140]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.110746,	
2017-06-26 18:01:34,373 Epoch[28] Batch [150]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.110817,	
2017-06-26 18:01:41,876 Epoch[28] Batch [160]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.110545,	
2017-06-26 18:01:49,540 Epoch[28] Batch [170]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.110841,	
2017-06-26 18:01:56,898 Epoch[28] Batch [180]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.110826,	
2017-06-26 18:02:04,342 Epoch[28] Batch [190]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.110689,	
2017-06-26 18:02:11,915 Epoch[28] Batch [200]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.110566,	
2017-06-26 18:02:19,383 Epoch[28] Batch [210]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.110803,	
2017-06-26 18:02:26,861 Epoch[28] Batch [220]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.110550,	
2017-06-26 18:02:34,179 Epoch[28] Batch [230]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.110372,	
2017-06-26 18:02:41,827 Epoch[28] Batch [240]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.110189,	
2017-06-26 18:02:48,114 Epoch[28] Batch [250]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.110369,	
2017-06-26 18:02:53,790 Epoch[28] Batch [260]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.110242,	
2017-06-26 18:02:59,439 Epoch[28] Batch [270]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.110018,	
2017-06-26 18:03:05,237 Epoch[28] Batch [280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109715,	
2017-06-26 18:03:11,221 Epoch[28] Batch [290]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.109659,	
2017-06-26 18:03:17,262 Epoch[28] Batch [300]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109273,	
2017-06-26 18:03:23,391 Epoch[28] Batch [310]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.108990,	
2017-06-26 18:03:29,511 Epoch[28] Batch [320]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.109300,	
2017-06-26 18:03:35,556 Epoch[28] Batch [330]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109361,	
2017-06-26 18:03:41,619 Epoch[28] Batch [340]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.109520,	
2017-06-26 18:03:47,758 Epoch[28] Batch [350]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.109006,	
2017-06-26 18:03:53,771 Epoch[28] Batch [360]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.108717,	
2017-06-26 18:03:59,794 Epoch[28] Batch [370]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.108978,	
2017-06-26 18:04:05,862 Epoch[28] Batch [380]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109196,	
2017-06-26 18:04:11,960 Epoch[28] Batch [390]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.109215,	
2017-06-26 18:04:18,009 Epoch[28] Batch [400]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109117,	
2017-06-26 18:04:24,087 Epoch[28] Batch [410]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109124,	
2017-06-26 18:04:30,186 Epoch[28] Batch [420]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108973,	
2017-06-26 18:04:36,179 Epoch[28] Batch [430]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.108957,	
2017-06-26 18:04:42,243 Epoch[28] Batch [440]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108787,	
2017-06-26 18:04:48,308 Epoch[28] Batch [450]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108809,	
2017-06-26 18:04:54,382 Epoch[28] Batch [460]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108769,	
2017-06-26 18:05:00,395 Epoch[28] Batch [470]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.108814,	
2017-06-26 18:05:06,485 Epoch[28] Batch [480]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108638,	
2017-06-26 18:05:12,547 Epoch[28] Batch [490]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108549,	
2017-06-26 18:05:18,619 Epoch[28] Batch [500]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108886,	
2017-06-26 18:05:24,654 Epoch[28] Batch [510]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.108905,	
2017-06-26 18:05:30,719 Epoch[28] Batch [520]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108737,	
2017-06-26 18:05:36,831 Epoch[28] Batch [530]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.108495,	
2017-06-26 18:05:42,857 Epoch[28] Batch [540]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.108229,	
2017-06-26 18:05:48,957 Epoch[28] Batch [550]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108261,	
2017-06-26 18:05:55,054 Epoch[28] Batch [560]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108318,	
2017-06-26 18:06:01,129 Epoch[28] Batch [570]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108084,	
2017-06-26 18:06:07,201 Epoch[28] Batch [580]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108036,	
2017-06-26 18:06:13,299 Epoch[28] Batch [590]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107860,	
2017-06-26 18:06:19,392 Epoch[28] Batch [600]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107905,	
2017-06-26 18:06:25,481 Epoch[28] Batch [610]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107848,	
2017-06-26 18:06:31,581 Epoch[28] Batch [620]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107735,	
2017-06-26 18:06:37,672 Epoch[28] Batch [630]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107648,	
2017-06-26 18:06:43,726 Epoch[28] Batch [640]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107592,	
2017-06-26 18:06:49,827 Epoch[28] Batch [650]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107451,	
2017-06-26 18:06:55,854 Epoch[28] Batch [660]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.107398,	
2017-06-26 18:07:01,583 Epoch[28] Batch [670]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.107419,	
2017-06-26 18:07:07,226 Epoch[28] Batch [680]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.107447,	
2017-06-26 18:07:12,839 Epoch[28] Batch [690]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.107373,	
2017-06-26 18:07:18,569 Epoch[28] Batch [700]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.107372,	
2017-06-26 18:07:24,206 Epoch[28] Batch [710]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.107262,	
2017-06-26 18:07:29,793 Epoch[28] Batch [720]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.107227,	
2017-06-26 18:07:35,383 Epoch[28] Batch [730]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.107084,	
2017-06-26 18:07:40,960 Epoch[28] Batch [740]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.106847,	
2017-06-26 18:07:46,568 Epoch[28] Batch [750]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.106884,	
2017-06-26 18:07:52,529 Epoch[28] Batch [760]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106813,	
2017-06-26 18:07:58,604 Epoch[28] Batch [770]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106655,	
2017-06-26 18:08:04,698 Epoch[28] Batch [780]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.106564,	
2017-06-26 18:08:10,773 Epoch[28] Batch [790]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106620,	
2017-06-26 18:08:16,885 Epoch[28] Batch [800]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106532,	
2017-06-26 18:08:22,975 Epoch[28] Batch [810]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106373,	
2017-06-26 18:08:29,068 Epoch[28] Batch [820]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106269,	
2017-06-26 18:08:35,184 Epoch[28] Batch [830]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106255,	
2017-06-26 18:08:41,264 Epoch[28] Batch [840]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106250,	
2017-06-26 18:08:47,341 Epoch[28] Batch [850]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106368,	
2017-06-26 18:08:53,435 Epoch[28] Batch [860]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.106290,	
2017-06-26 18:08:59,499 Epoch[28] Batch [870]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106129,	
2017-06-26 18:09:05,580 Epoch[28] Batch [880]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106092,	
2017-06-26 18:09:11,661 Epoch[28] Batch [890]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106057,	
2017-06-26 18:09:17,743 Epoch[28] Batch [900]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106951,	
2017-06-26 18:09:23,842 Epoch[28] Batch [910]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107278,	
2017-06-26 18:09:29,870 Epoch[28] Batch [920]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.107546,	
2017-06-26 18:09:35,948 Epoch[28] Batch [930]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107616,	
2017-06-26 18:09:42,021 Epoch[28] Batch [940]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107636,	
2017-06-26 18:09:48,100 Epoch[28] Batch [950]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107665,	
2017-06-26 18:09:54,152 Epoch[28] Batch [960]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107657,	
2017-06-26 18:10:00,253 Epoch[28] Batch [970]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107640,	
2017-06-26 18:10:06,334 Epoch[28] Batch [980]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107595,	
2017-06-26 18:10:12,399 Epoch[28] Batch [990]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107753,	
2017-06-26 18:10:18,505 Epoch[28] Batch [1000]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.107701,	
2017-06-26 18:10:24,555 Epoch[28] Batch [1010]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107616,	
2017-06-26 18:10:30,630 Epoch[28] Batch [1020]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107536,	
2017-06-26 18:10:36,692 Epoch[28] Batch [1030]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107556,	
2017-06-26 18:10:42,816 Epoch[28] Batch [1040]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.107551,	
2017-06-26 18:10:48,879 Epoch[28] Batch [1050]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107542,	
2017-06-26 18:10:54,955 Epoch[28] Batch [1060]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107589,	
2017-06-26 18:11:01,026 Epoch[28] Batch [1070]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107611,	
2017-06-26 18:11:07,077 Epoch[28] Batch [1080]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107475,	
2017-06-26 18:11:13,177 Epoch[28] Batch [1090]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107506,	
2017-06-26 18:11:19,228 Epoch[28] Batch [1100]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107480,	
2017-06-26 18:11:25,302 Epoch[28] Batch [1110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107425,	
2017-06-26 18:11:31,379 Epoch[28] Batch [1120]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107389,	
2017-06-26 18:11:37,469 Epoch[28] Batch [1130]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107290,	
2017-06-26 18:11:43,460 Epoch[28] Batch [1140]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.107237,	
2017-06-26 18:11:49,319 Epoch[28] Batch [1150]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107231,	
2017-06-26 18:11:55,160 Epoch[28] Batch [1160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107175,	
2017-06-26 18:12:00,986 Epoch[28] Batch [1170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107171,	
2017-06-26 18:12:06,790 Epoch[28] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107298,	
2017-06-26 18:12:12,713 Epoch[28] Batch [1190]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107296,	
2017-06-26 18:12:18,780 Epoch[28] Batch [1200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107453,	
2017-06-26 18:12:24,866 Epoch[28] Batch [1210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107543,	
2017-06-26 18:12:30,951 Epoch[28] Batch [1220]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108122,	
2017-06-26 18:12:37,019 Epoch[28] Batch [1230]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109224,	
2017-06-26 18:12:43,129 Epoch[28] Batch [1240]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.109653,	
2017-06-26 18:12:49,249 Epoch[28] Batch [1250]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.109925,	
2017-06-26 18:12:55,280 Epoch[28] Batch [1260]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.110010,	
2017-06-26 18:13:01,441 Epoch[28] Batch [1270]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.110166,	
2017-06-26 18:13:07,469 Epoch[28] Batch [1280]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.110255,	
2017-06-26 18:13:13,545 Epoch[28] Batch [1290]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110480,	
2017-06-26 18:13:19,619 Epoch[28] Batch [1300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110584,	
2017-06-26 18:13:25,702 Epoch[28] Batch [1310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110675,	
2017-06-26 18:13:31,775 Epoch[28] Batch [1320]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110692,	
2017-06-26 18:13:37,863 Epoch[28] Batch [1330]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.110692,	
2017-06-26 18:13:43,922 Epoch[28] Batch [1340]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.110666,	
2017-06-26 18:13:50,043 Epoch[28] Batch [1350]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.110768,	
2017-06-26 18:13:56,104 Epoch[28] Batch [1360]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.110717,	
2017-06-26 18:14:02,173 Epoch[28] Batch [1370]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110661,	
2017-06-26 18:14:08,272 Epoch[28] Batch [1380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.110616,	
2017-06-26 18:14:14,354 Epoch[28] Batch [1390]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110623,	
2017-06-26 18:14:20,407 Epoch[28] Batch [1400]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.110596,	
2017-06-26 18:14:26,540 Epoch[28] Batch [1410]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.110666,	
2017-06-26 18:14:32,600 Epoch[28] Batch [1420]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.110691,	
2017-06-26 18:14:38,710 Epoch[28] Batch [1430]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.110691,	
2017-06-26 18:14:44,776 Epoch[28] Batch [1440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110676,	
2017-06-26 18:14:50,873 Epoch[28] Batch [1450]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.110666,	
2017-06-26 18:14:56,692 Epoch[28] Batch [1460]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110676,	
2017-06-26 18:15:02,586 Epoch[28] Batch [1470]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.110669,	
2017-06-26 18:15:08,541 Epoch[28] Batch [1480]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.110699,	
2017-06-26 18:15:12,156 Epoch[28] Train-FCNLogLoss=0.110686
2017-06-26 18:15:12,156 Epoch[28] Time cost=929.660
2017-06-26 18:15:13,475 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0029.params"
2017-06-26 18:15:17,300 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0029.states"
2017-06-26 18:15:24,308 Epoch[29] Batch [10]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.116209,	
2017-06-26 18:15:30,343 Epoch[29] Batch [20]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.115047,	
2017-06-26 18:15:36,391 Epoch[29] Batch [30]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109690,	
2017-06-26 18:15:42,466 Epoch[29] Batch [40]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.115586,	
2017-06-26 18:15:48,589 Epoch[29] Batch [50]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.114566,	
2017-06-26 18:15:54,684 Epoch[29] Batch [60]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.114715,	
2017-06-26 18:16:00,584 Epoch[29] Batch [70]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.113773,	
2017-06-26 18:16:06,316 Epoch[29] Batch [80]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.112496,	
2017-06-26 18:16:12,113 Epoch[29] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113210,	
2017-06-26 18:16:17,821 Epoch[29] Batch [100]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.111782,	
2017-06-26 18:16:23,451 Epoch[29] Batch [110]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.110873,	
2017-06-26 18:16:29,131 Epoch[29] Batch [120]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.110255,	
2017-06-26 18:16:34,763 Epoch[29] Batch [130]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.110618,	
2017-06-26 18:16:40,822 Epoch[29] Batch [140]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.110369,	
2017-06-26 18:16:46,924 Epoch[29] Batch [150]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.110075,	
2017-06-26 18:16:53,038 Epoch[29] Batch [160]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.109416,	
2017-06-26 18:16:59,068 Epoch[29] Batch [170]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.108647,	
2017-06-26 18:17:05,146 Epoch[29] Batch [180]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108237,	
2017-06-26 18:17:11,211 Epoch[29] Batch [190]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108678,	
2017-06-26 18:17:17,287 Epoch[29] Batch [200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109150,	
2017-06-26 18:17:23,397 Epoch[29] Batch [210]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.109449,	
2017-06-26 18:17:29,648 Epoch[29] Batch [220]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.109696,	
2017-06-26 18:17:35,763 Epoch[29] Batch [230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.109838,	
2017-06-26 18:17:41,835 Epoch[29] Batch [240]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109845,	
2017-06-26 18:17:47,963 Epoch[29] Batch [250]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.109949,	
2017-06-26 18:17:54,051 Epoch[29] Batch [260]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.109465,	
2017-06-26 18:18:00,118 Epoch[29] Batch [270]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109367,	
2017-06-26 18:18:06,201 Epoch[29] Batch [280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108925,	
2017-06-26 18:18:12,245 Epoch[29] Batch [290]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108344,	
2017-06-26 18:18:18,339 Epoch[29] Batch [300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108075,	
2017-06-26 18:18:24,438 Epoch[29] Batch [310]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107931,	
2017-06-26 18:18:30,472 Epoch[29] Batch [320]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.108106,	
2017-06-26 18:18:36,549 Epoch[29] Batch [330]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107857,	
2017-06-26 18:18:42,633 Epoch[29] Batch [340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108147,	
2017-06-26 18:18:48,778 Epoch[29] Batch [350]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.107892,	
2017-06-26 18:18:54,790 Epoch[29] Batch [360]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107804,	
2017-06-26 18:19:00,850 Epoch[29] Batch [370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107622,	
2017-06-26 18:19:07,072 Epoch[29] Batch [380]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.107009,	
2017-06-26 18:19:13,047 Epoch[29] Batch [390]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.107431,	
2017-06-26 18:19:19,132 Epoch[29] Batch [400]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107311,	
2017-06-26 18:19:25,248 Epoch[29] Batch [410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107495,	
2017-06-26 18:19:31,381 Epoch[29] Batch [420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.107584,	
2017-06-26 18:19:37,394 Epoch[29] Batch [430]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107568,	
2017-06-26 18:19:43,480 Epoch[29] Batch [440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107514,	
2017-06-26 18:19:49,637 Epoch[29] Batch [450]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.107397,	
2017-06-26 18:19:55,897 Epoch[29] Batch [460]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.107604,	
2017-06-26 18:20:01,989 Epoch[29] Batch [470]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107287,	
2017-06-26 18:20:08,159 Epoch[29] Batch [480]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.107101,	
2017-06-26 18:20:14,233 Epoch[29] Batch [490]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107067,	
2017-06-26 18:20:20,289 Epoch[29] Batch [500]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106972,	
2017-06-26 18:20:26,385 Epoch[29] Batch [510]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.106876,	
2017-06-26 18:20:32,278 Epoch[29] Batch [520]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106612,	
2017-06-26 18:20:37,908 Epoch[29] Batch [530]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.106472,	
2017-06-26 18:20:43,450 Epoch[29] Batch [540]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.106549,	
2017-06-26 18:20:49,077 Epoch[29] Batch [550]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.106514,	
2017-06-26 18:20:54,736 Epoch[29] Batch [560]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.106462,	
2017-06-26 18:21:00,214 Epoch[29] Batch [570]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.106515,	
2017-06-26 18:21:05,804 Epoch[29] Batch [580]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.106402,	
2017-06-26 18:21:11,401 Epoch[29] Batch [590]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.106520,	
2017-06-26 18:21:16,999 Epoch[29] Batch [600]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.106476,	
2017-06-26 18:21:22,582 Epoch[29] Batch [610]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.106488,	
2017-06-26 18:21:28,673 Epoch[29] Batch [620]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106640,	
2017-06-26 18:21:34,739 Epoch[29] Batch [630]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106357,	
2017-06-26 18:21:40,815 Epoch[29] Batch [640]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106295,	
2017-06-26 18:21:46,902 Epoch[29] Batch [650]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106319,	
2017-06-26 18:21:52,991 Epoch[29] Batch [660]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106106,	
2017-06-26 18:21:59,288 Epoch[29] Batch [670]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.106043,	
2017-06-26 18:22:05,369 Epoch[29] Batch [680]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.105886,	
2017-06-26 18:22:11,511 Epoch[29] Batch [690]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.105946,	
2017-06-26 18:22:17,558 Epoch[29] Batch [700]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106309,	
2017-06-26 18:22:23,719 Epoch[29] Batch [710]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.106411,	
2017-06-26 18:22:29,723 Epoch[29] Batch [720]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106521,	
2017-06-26 18:22:35,804 Epoch[29] Batch [730]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106645,	
2017-06-26 18:22:41,972 Epoch[29] Batch [740]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.106608,	
2017-06-26 18:22:47,955 Epoch[29] Batch [750]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106589,	
2017-06-26 18:22:54,167 Epoch[29] Batch [760]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.106575,	
2017-06-26 18:23:00,141 Epoch[29] Batch [770]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106516,	
2017-06-26 18:23:06,211 Epoch[29] Batch [780]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106520,	
2017-06-26 18:23:12,536 Epoch[29] Batch [790]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.106593,	
2017-06-26 18:23:18,657 Epoch[29] Batch [800]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106533,	
2017-06-26 18:23:24,760 Epoch[29] Batch [810]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106681,	
2017-06-26 18:23:30,847 Epoch[29] Batch [820]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106600,	
2017-06-26 18:23:36,959 Epoch[29] Batch [830]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106592,	
2017-06-26 18:23:43,204 Epoch[29] Batch [840]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106546,	
2017-06-26 18:23:49,147 Epoch[29] Batch [850]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106431,	
2017-06-26 18:23:55,205 Epoch[29] Batch [860]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106446,	
2017-06-26 18:24:01,336 Epoch[29] Batch [870]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.106479,	
2017-06-26 18:24:07,356 Epoch[29] Batch [880]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.106444,	
2017-06-26 18:24:13,467 Epoch[29] Batch [890]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106263,	
2017-06-26 18:24:19,617 Epoch[29] Batch [900]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.106174,	
2017-06-26 18:24:25,624 Epoch[29] Batch [910]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106143,	
2017-06-26 18:24:31,713 Epoch[29] Batch [920]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106249,	
2017-06-26 18:24:37,797 Epoch[29] Batch [930]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106269,	
2017-06-26 18:24:43,883 Epoch[29] Batch [940]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106159,	
2017-06-26 18:24:49,986 Epoch[29] Batch [950]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106252,	
2017-06-26 18:24:56,072 Epoch[29] Batch [960]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106177,	
2017-06-26 18:25:02,165 Epoch[29] Batch [970]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.106181,	
2017-06-26 18:25:08,194 Epoch[29] Batch [980]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.106283,	
2017-06-26 18:25:14,277 Epoch[29] Batch [990]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106460,	
2017-06-26 18:25:20,209 Epoch[29] Batch [1000]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106396,	
2017-06-26 18:25:25,786 Epoch[29] Batch [1010]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.106382,	
2017-06-26 18:25:31,891 Epoch[29] Batch [1020]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106366,	
2017-06-26 18:25:37,756 Epoch[29] Batch [1030]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106208,	
2017-06-26 18:25:43,645 Epoch[29] Batch [1040]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106243,	
2017-06-26 18:25:49,571 Epoch[29] Batch [1050]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106153,	
2017-06-26 18:25:55,077 Epoch[29] Batch [1060]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.106107,	
2017-06-26 18:26:00,683 Epoch[29] Batch [1070]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.106005,	
2017-06-26 18:26:06,242 Epoch[29] Batch [1080]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.106098,	
2017-06-26 18:26:11,938 Epoch[29] Batch [1090]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.106120,	
2017-06-26 18:26:18,058 Epoch[29] Batch [1100]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106108,	
2017-06-26 18:26:24,146 Epoch[29] Batch [1110]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106144,	
2017-06-26 18:26:30,239 Epoch[29] Batch [1120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106131,	
2017-06-26 18:26:36,302 Epoch[29] Batch [1130]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106180,	
2017-06-26 18:26:42,392 Epoch[29] Batch [1140]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106237,	
2017-06-26 18:26:48,529 Epoch[29] Batch [1150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.106230,	
2017-06-26 18:26:54,588 Epoch[29] Batch [1160]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106229,	
2017-06-26 18:27:00,702 Epoch[29] Batch [1170]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106200,	
2017-06-26 18:27:06,771 Epoch[29] Batch [1180]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106158,	
2017-06-26 18:27:12,837 Epoch[29] Batch [1190]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106106,	
2017-06-26 18:27:18,886 Epoch[29] Batch [1200]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106222,	
2017-06-26 18:27:25,005 Epoch[29] Batch [1210]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106237,	
2017-06-26 18:27:31,041 Epoch[29] Batch [1220]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.106214,	
2017-06-26 18:27:37,222 Epoch[29] Batch [1230]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106213,	
2017-06-26 18:27:43,205 Epoch[29] Batch [1240]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106142,	
2017-06-26 18:27:49,284 Epoch[29] Batch [1250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106157,	
2017-06-26 18:27:55,392 Epoch[29] Batch [1260]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106065,	
2017-06-26 18:28:01,527 Epoch[29] Batch [1270]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.105990,	
2017-06-26 18:28:07,763 Epoch[29] Batch [1280]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.105956,	
2017-06-26 18:28:13,829 Epoch[29] Batch [1290]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106035,	
2017-06-26 18:28:19,900 Epoch[29] Batch [1300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.105918,	
2017-06-26 18:28:25,978 Epoch[29] Batch [1310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.105894,	
2017-06-26 18:28:32,019 Epoch[29] Batch [1320]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.105903,	
2017-06-26 18:28:38,114 Epoch[29] Batch [1330]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.105839,	
2017-06-26 18:28:44,239 Epoch[29] Batch [1340]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.105809,	
2017-06-26 18:28:50,314 Epoch[29] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.105914,	
2017-06-26 18:28:56,367 Epoch[29] Batch [1360]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.105910,	
2017-06-26 18:29:02,461 Epoch[29] Batch [1370]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.105821,	
2017-06-26 18:29:08,509 Epoch[29] Batch [1380]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.105816,	
2017-06-26 18:29:14,635 Epoch[29] Batch [1390]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.105863,	
2017-06-26 18:29:20,907 Epoch[29] Batch [1400]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.105878,	
2017-06-26 18:29:27,026 Epoch[29] Batch [1410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.105928,	
2017-06-26 18:29:33,087 Epoch[29] Batch [1420]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.105843,	
2017-06-26 18:29:39,169 Epoch[29] Batch [1430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.105880,	
2017-06-26 18:29:44,997 Epoch[29] Batch [1440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105956,	
2017-06-26 18:29:50,703 Epoch[29] Batch [1450]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.105916,	
2017-06-26 18:29:56,767 Epoch[29] Batch [1460]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.105964,	
2017-06-26 18:30:02,867 Epoch[29] Batch [1470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.105970,	
2017-06-26 18:30:08,442 Epoch[29] Batch [1480]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.105980,	
2017-06-26 18:30:11,761 Epoch[29] Train-FCNLogLoss=0.105975
2017-06-26 18:30:11,761 Epoch[29] Time cost=894.461
2017-06-26 18:30:12,955 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0030.params"
2017-06-26 18:30:16,806 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0030.states"
2017-06-26 18:30:23,677 Epoch[30] Batch [10]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106034,	
2017-06-26 18:30:29,254 Epoch[30] Batch [20]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.104677,	
2017-06-26 18:30:34,821 Epoch[30] Batch [30]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.104009,	
2017-06-26 18:30:40,920 Epoch[30] Batch [40]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101078,	
2017-06-26 18:30:46,513 Epoch[30] Batch [50]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102590,	
2017-06-26 18:30:52,149 Epoch[30] Batch [60]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.103903,	
2017-06-26 18:30:58,219 Epoch[30] Batch [70]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.104486,	
2017-06-26 18:31:04,248 Epoch[30] Batch [80]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103371,	
2017-06-26 18:31:10,343 Epoch[30] Batch [90]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103242,	
2017-06-26 18:31:16,450 Epoch[30] Batch [100]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102840,	
2017-06-26 18:31:22,520 Epoch[30] Batch [110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.104006,	
2017-06-26 18:31:28,621 Epoch[30] Batch [120]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.104212,	
2017-06-26 18:31:34,777 Epoch[30] Batch [130]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.103962,	
2017-06-26 18:31:41,003 Epoch[30] Batch [140]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.104281,	
2017-06-26 18:31:47,119 Epoch[30] Batch [150]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.104312,	
2017-06-26 18:31:53,197 Epoch[30] Batch [160]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103977,	
2017-06-26 18:31:59,339 Epoch[30] Batch [170]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103960,	
2017-06-26 18:32:05,402 Epoch[30] Batch [180]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103609,	
2017-06-26 18:32:11,507 Epoch[30] Batch [190]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103914,	
2017-06-26 18:32:17,561 Epoch[30] Batch [200]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.104367,	
2017-06-26 18:32:23,600 Epoch[30] Batch [210]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.104856,	
2017-06-26 18:32:29,685 Epoch[30] Batch [220]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.104632,	
2017-06-26 18:32:35,743 Epoch[30] Batch [230]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104360,	
2017-06-26 18:32:41,954 Epoch[30] Batch [240]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.104389,	
2017-06-26 18:32:48,169 Epoch[30] Batch [250]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.104618,	
2017-06-26 18:32:54,172 Epoch[30] Batch [260]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.104456,	
2017-06-26 18:33:00,226 Epoch[30] Batch [270]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.104781,	
2017-06-26 18:33:06,333 Epoch[30] Batch [280]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104231,	
2017-06-26 18:33:12,357 Epoch[30] Batch [290]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103875,	
2017-06-26 18:33:18,438 Epoch[30] Batch [300]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103817,	
2017-06-26 18:33:24,450 Epoch[30] Batch [310]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.103708,	
2017-06-26 18:33:30,515 Epoch[30] Batch [320]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103703,	
2017-06-26 18:33:36,578 Epoch[30] Batch [330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103577,	
2017-06-26 18:33:42,699 Epoch[30] Batch [340]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103449,	
2017-06-26 18:33:48,777 Epoch[30] Batch [350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103890,	
2017-06-26 18:33:54,887 Epoch[30] Batch [360]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104525,	
2017-06-26 18:34:00,968 Epoch[30] Batch [370]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.105638,	
2017-06-26 18:34:07,021 Epoch[30] Batch [380]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106959,	
2017-06-26 18:34:13,112 Epoch[30] Batch [390]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107786,	
2017-06-26 18:34:19,195 Epoch[30] Batch [400]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108152,	
2017-06-26 18:34:25,254 Epoch[30] Batch [410]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108415,	
2017-06-26 18:34:31,332 Epoch[30] Batch [420]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109518,	
2017-06-26 18:34:37,443 Epoch[30] Batch [430]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.109896,	
2017-06-26 18:34:43,494 Epoch[30] Batch [440]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.110083,	
2017-06-26 18:34:49,557 Epoch[30] Batch [450]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.109989,	
2017-06-26 18:34:55,504 Epoch[30] Batch [460]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.110167,	
2017-06-26 18:35:01,391 Epoch[30] Batch [470]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.110030,	
2017-06-26 18:35:07,208 Epoch[30] Batch [480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109958,	
2017-06-26 18:35:12,971 Epoch[30] Batch [490]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.110120,	
2017-06-26 18:35:18,707 Epoch[30] Batch [500]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.110309,	
2017-06-26 18:35:24,317 Epoch[30] Batch [510]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.110590,	
2017-06-26 18:35:30,388 Epoch[30] Batch [520]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110571,	
2017-06-26 18:35:36,472 Epoch[30] Batch [530]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110810,	
2017-06-26 18:35:42,629 Epoch[30] Batch [540]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.110831,	
2017-06-26 18:35:48,645 Epoch[30] Batch [550]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.110804,	
2017-06-26 18:35:54,724 Epoch[30] Batch [560]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110858,	
2017-06-26 18:36:00,768 Epoch[30] Batch [570]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.111511,	
2017-06-26 18:36:06,887 Epoch[30] Batch [580]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.111529,	
2017-06-26 18:36:12,960 Epoch[30] Batch [590]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.111755,	
2017-06-26 18:36:19,069 Epoch[30] Batch [600]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.111926,	
2017-06-26 18:36:25,131 Epoch[30] Batch [610]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.112044,	
2017-06-26 18:36:31,315 Epoch[30] Batch [620]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.111999,	
2017-06-26 18:36:37,307 Epoch[30] Batch [630]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.112161,	
2017-06-26 18:36:43,408 Epoch[30] Batch [640]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.112031,	
2017-06-26 18:36:49,460 Epoch[30] Batch [650]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.111964,	
2017-06-26 18:36:55,550 Epoch[30] Batch [660]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.111960,	
2017-06-26 18:37:01,608 Epoch[30] Batch [670]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.111865,	
2017-06-26 18:37:07,698 Epoch[30] Batch [680]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.111637,	
2017-06-26 18:37:13,796 Epoch[30] Batch [690]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.111597,	
2017-06-26 18:37:19,868 Epoch[30] Batch [700]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.111524,	
2017-06-26 18:37:25,950 Epoch[30] Batch [710]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111480,	
2017-06-26 18:37:32,062 Epoch[30] Batch [720]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.111273,	
2017-06-26 18:37:38,142 Epoch[30] Batch [730]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111122,	
2017-06-26 18:37:44,229 Epoch[30] Batch [740]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.110965,	
2017-06-26 18:37:50,337 Epoch[30] Batch [750]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.110871,	
2017-06-26 18:37:56,385 Epoch[30] Batch [760]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.110759,	
2017-06-26 18:38:02,673 Epoch[30] Batch [770]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.110797,	
2017-06-26 18:38:08,756 Epoch[30] Batch [780]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110592,	
2017-06-26 18:38:14,817 Epoch[30] Batch [790]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.110501,	
2017-06-26 18:38:20,827 Epoch[30] Batch [800]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.110501,	
2017-06-26 18:38:26,897 Epoch[30] Batch [810]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110364,	
2017-06-26 18:38:32,967 Epoch[30] Batch [820]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110346,	
2017-06-26 18:38:39,023 Epoch[30] Batch [830]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.110227,	
2017-06-26 18:38:45,101 Epoch[30] Batch [840]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110133,	
2017-06-26 18:38:51,119 Epoch[30] Batch [850]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.110215,	
2017-06-26 18:38:57,183 Epoch[30] Batch [860]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.110130,	
2017-06-26 18:39:03,266 Epoch[30] Batch [870]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110091,	
2017-06-26 18:39:09,306 Epoch[30] Batch [880]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109952,	
2017-06-26 18:39:15,377 Epoch[30] Batch [890]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109847,	
2017-06-26 18:39:21,283 Epoch[30] Batch [900]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.109797,	
2017-06-26 18:39:26,910 Epoch[30] Batch [910]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.109754,	
2017-06-26 18:39:32,483 Epoch[30] Batch [920]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.109761,	
2017-06-26 18:39:38,128 Epoch[30] Batch [930]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.109720,	
2017-06-26 18:39:43,671 Epoch[30] Batch [940]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.109493,	
2017-06-26 18:39:49,240 Epoch[30] Batch [950]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.109425,	
2017-06-26 18:39:54,794 Epoch[30] Batch [960]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.109387,	
2017-06-26 18:40:00,419 Epoch[30] Batch [970]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.109254,	
2017-06-26 18:40:06,045 Epoch[30] Batch [980]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.109192,	
2017-06-26 18:40:11,571 Epoch[30] Batch [990]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.109062,	
2017-06-26 18:40:17,532 Epoch[30] Batch [1000]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.109081,	
2017-06-26 18:40:23,656 Epoch[30] Batch [1010]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.109152,	
2017-06-26 18:40:29,757 Epoch[30] Batch [1020]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108962,	
2017-06-26 18:40:35,859 Epoch[30] Batch [1030]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.109150,	
2017-06-26 18:40:41,899 Epoch[30] Batch [1040]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109009,	
2017-06-26 18:40:47,983 Epoch[30] Batch [1050]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109016,	
2017-06-26 18:40:54,056 Epoch[30] Batch [1060]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108946,	
2017-06-26 18:41:00,195 Epoch[30] Batch [1070]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.108864,	
2017-06-26 18:41:06,235 Epoch[30] Batch [1080]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108806,	
2017-06-26 18:41:12,324 Epoch[30] Batch [1090]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108849,	
2017-06-26 18:41:18,427 Epoch[30] Batch [1100]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.108865,	
2017-06-26 18:41:24,498 Epoch[30] Batch [1110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108732,	
2017-06-26 18:41:30,540 Epoch[30] Batch [1120]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108671,	
2017-06-26 18:41:36,676 Epoch[30] Batch [1130]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.108638,	
2017-06-26 18:41:42,732 Epoch[30] Batch [1140]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.108629,	
2017-06-26 18:41:48,769 Epoch[30] Batch [1150]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.108573,	
2017-06-26 18:41:54,883 Epoch[30] Batch [1160]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.108565,	
2017-06-26 18:42:00,965 Epoch[30] Batch [1170]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108577,	
2017-06-26 18:42:06,988 Epoch[30] Batch [1180]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.108460,	
2017-06-26 18:42:13,079 Epoch[30] Batch [1190]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108441,	
2017-06-26 18:42:19,152 Epoch[30] Batch [1200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108405,	
2017-06-26 18:42:25,234 Epoch[30] Batch [1210]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108320,	
2017-06-26 18:42:31,356 Epoch[30] Batch [1220]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.108303,	
2017-06-26 18:42:37,396 Epoch[30] Batch [1230]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108262,	
2017-06-26 18:42:43,479 Epoch[30] Batch [1240]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108150,	
2017-06-26 18:42:49,562 Epoch[30] Batch [1250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108255,	
2017-06-26 18:42:55,628 Epoch[30] Batch [1260]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108258,	
2017-06-26 18:43:01,718 Epoch[30] Batch [1270]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108174,	
2017-06-26 18:43:07,803 Epoch[30] Batch [1280]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108174,	
2017-06-26 18:43:13,949 Epoch[30] Batch [1290]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.108148,	
2017-06-26 18:43:19,986 Epoch[30] Batch [1300]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.108050,	
2017-06-26 18:43:26,074 Epoch[30] Batch [1310]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107992,	
2017-06-26 18:43:32,167 Epoch[30] Batch [1320]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107952,	
2017-06-26 18:43:38,234 Epoch[30] Batch [1330]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108029,	
2017-06-26 18:43:44,349 Epoch[30] Batch [1340]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.108035,	
2017-06-26 18:43:50,414 Epoch[30] Batch [1350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107882,	
2017-06-26 18:43:56,481 Epoch[30] Batch [1360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107849,	
2017-06-26 18:44:02,539 Epoch[30] Batch [1370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107899,	
2017-06-26 18:44:08,627 Epoch[30] Batch [1380]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107924,	
2017-06-26 18:44:14,189 Epoch[30] Batch [1390]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.107871,	
2017-06-26 18:44:19,789 Epoch[30] Batch [1400]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.107881,	
2017-06-26 18:44:25,340 Epoch[30] Batch [1410]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.107843,	
2017-06-26 18:44:31,015 Epoch[30] Batch [1420]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.107812,	
2017-06-26 18:44:36,373 Epoch[30] Batch [1430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.107702,	
2017-06-26 18:44:41,929 Epoch[30] Batch [1440]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.107788,	
2017-06-26 18:44:47,467 Epoch[30] Batch [1450]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.107747,	
2017-06-26 18:44:53,114 Epoch[30] Batch [1460]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.107795,	
2017-06-26 18:44:58,661 Epoch[30] Batch [1470]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.107671,	
2017-06-26 18:45:04,654 Epoch[30] Batch [1480]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.107608,	
2017-06-26 18:45:08,302 Epoch[30] Train-FCNLogLoss=0.107569
2017-06-26 18:45:08,302 Epoch[30] Time cost=891.496
2017-06-26 18:45:09,683 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0031.params"
2017-06-26 18:45:13,512 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0031.states"
2017-06-26 18:45:20,461 Epoch[31] Batch [10]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093726,	
2017-06-26 18:45:26,488 Epoch[31] Batch [20]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.093266,	
2017-06-26 18:45:32,515 Epoch[31] Batch [30]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097301,	
2017-06-26 18:45:38,667 Epoch[31] Batch [40]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.096864,	
2017-06-26 18:45:44,632 Epoch[31] Batch [50]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.096462,	
2017-06-26 18:45:50,699 Epoch[31] Batch [60]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097586,	
2017-06-26 18:45:56,765 Epoch[31] Batch [70]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097732,	
2017-06-26 18:46:02,831 Epoch[31] Batch [80]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098247,	
2017-06-26 18:46:08,983 Epoch[31] Batch [90]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.098363,	
2017-06-26 18:46:14,990 Epoch[31] Batch [100]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100353,	
2017-06-26 18:46:21,054 Epoch[31] Batch [110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099259,	
2017-06-26 18:46:27,163 Epoch[31] Batch [120]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099788,	
2017-06-26 18:46:33,254 Epoch[31] Batch [130]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099655,	
2017-06-26 18:46:39,357 Epoch[31] Batch [140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099754,	
2017-06-26 18:46:45,438 Epoch[31] Batch [150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100035,	
2017-06-26 18:46:51,497 Epoch[31] Batch [160]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100195,	
2017-06-26 18:46:57,552 Epoch[31] Batch [170]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100692,	
2017-06-26 18:47:03,652 Epoch[31] Batch [180]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100473,	
2017-06-26 18:47:09,730 Epoch[31] Batch [190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100858,	
2017-06-26 18:47:15,824 Epoch[31] Batch [200]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101682,	
2017-06-26 18:47:21,893 Epoch[31] Batch [210]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102785,	
2017-06-26 18:47:27,916 Epoch[31] Batch [220]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103541,	
2017-06-26 18:47:34,043 Epoch[31] Batch [230]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103849,	
2017-06-26 18:47:40,121 Epoch[31] Batch [240]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103798,	
2017-06-26 18:47:46,231 Epoch[31] Batch [250]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103155,	
2017-06-26 18:47:52,305 Epoch[31] Batch [260]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103193,	
2017-06-26 18:47:58,428 Epoch[31] Batch [270]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103858,	
2017-06-26 18:48:04,440 Epoch[31] Batch [280]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.104423,	
2017-06-26 18:48:10,548 Epoch[31] Batch [290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104357,	
2017-06-26 18:48:16,620 Epoch[31] Batch [300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.104100,	
2017-06-26 18:48:22,739 Epoch[31] Batch [310]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.104223,	
2017-06-26 18:48:28,920 Epoch[31] Batch [320]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.103747,	
2017-06-26 18:48:35,039 Epoch[31] Batch [330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103745,	
2017-06-26 18:48:41,131 Epoch[31] Batch [340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103717,	
2017-06-26 18:48:47,192 Epoch[31] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103813,	
2017-06-26 18:48:53,153 Epoch[31] Batch [360]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.104005,	
2017-06-26 18:48:58,668 Epoch[31] Batch [370]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.103556,	
2017-06-26 18:49:04,273 Epoch[31] Batch [380]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.103453,	
2017-06-26 18:49:09,847 Epoch[31] Batch [390]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.103414,	
2017-06-26 18:49:15,603 Epoch[31] Batch [400]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103432,	
2017-06-26 18:49:21,311 Epoch[31] Batch [410]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.103312,	
2017-06-26 18:49:26,814 Epoch[31] Batch [420]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.103635,	
2017-06-26 18:49:32,410 Epoch[31] Batch [430]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.103662,	
2017-06-26 18:49:38,327 Epoch[31] Batch [440]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.103505,	
2017-06-26 18:49:43,805 Epoch[31] Batch [450]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.103384,	
2017-06-26 18:49:49,843 Epoch[31] Batch [460]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103645,	
2017-06-26 18:49:55,946 Epoch[31] Batch [470]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103683,	
2017-06-26 18:50:02,044 Epoch[31] Batch [480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103716,	
2017-06-26 18:50:08,183 Epoch[31] Batch [490]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.103590,	
2017-06-26 18:50:14,282 Epoch[31] Batch [500]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103555,	
2017-06-26 18:50:20,366 Epoch[31] Batch [510]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103555,	
2017-06-26 18:50:26,653 Epoch[31] Batch [520]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.103509,	
2017-06-26 18:50:32,745 Epoch[31] Batch [530]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103355,	
2017-06-26 18:50:38,828 Epoch[31] Batch [540]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103430,	
2017-06-26 18:50:44,956 Epoch[31] Batch [550]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103370,	
2017-06-26 18:50:51,038 Epoch[31] Batch [560]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103425,	
2017-06-26 18:50:57,162 Epoch[31] Batch [570]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103376,	
2017-06-26 18:51:03,234 Epoch[31] Batch [580]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103390,	
2017-06-26 18:51:09,316 Epoch[31] Batch [590]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103536,	
2017-06-26 18:51:15,382 Epoch[31] Batch [600]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103422,	
2017-06-26 18:51:21,466 Epoch[31] Batch [610]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103506,	
2017-06-26 18:51:27,492 Epoch[31] Batch [620]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103489,	
2017-06-26 18:51:33,581 Epoch[31] Batch [630]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103601,	
2017-06-26 18:51:39,688 Epoch[31] Batch [640]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103597,	
2017-06-26 18:51:45,775 Epoch[31] Batch [650]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103410,	
2017-06-26 18:51:51,838 Epoch[31] Batch [660]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103296,	
2017-06-26 18:51:57,937 Epoch[31] Batch [670]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103446,	
2017-06-26 18:52:04,020 Epoch[31] Batch [680]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103371,	
2017-06-26 18:52:10,100 Epoch[31] Batch [690]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103372,	
2017-06-26 18:52:16,199 Epoch[31] Batch [700]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103310,	
2017-06-26 18:52:22,348 Epoch[31] Batch [710]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103178,	
2017-06-26 18:52:28,316 Epoch[31] Batch [720]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103262,	
2017-06-26 18:52:34,431 Epoch[31] Batch [730]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103208,	
2017-06-26 18:52:40,490 Epoch[31] Batch [740]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103366,	
2017-06-26 18:52:46,567 Epoch[31] Batch [750]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103348,	
2017-06-26 18:52:52,640 Epoch[31] Batch [760]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103442,	
2017-06-26 18:52:58,704 Epoch[31] Batch [770]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103490,	
2017-06-26 18:53:04,767 Epoch[31] Batch [780]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103419,	
2017-06-26 18:53:10,852 Epoch[31] Batch [790]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103366,	
2017-06-26 18:53:16,917 Epoch[31] Batch [800]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103456,	
2017-06-26 18:53:22,993 Epoch[31] Batch [810]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103543,	
2017-06-26 18:53:29,111 Epoch[31] Batch [820]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103448,	
2017-06-26 18:53:35,236 Epoch[31] Batch [830]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103444,	
2017-06-26 18:53:41,104 Epoch[31] Batch [840]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103542,	
2017-06-26 18:53:46,875 Epoch[31] Batch [850]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103547,	
2017-06-26 18:53:52,610 Epoch[31] Batch [860]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.103455,	
2017-06-26 18:53:58,366 Epoch[31] Batch [870]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103484,	
2017-06-26 18:54:04,221 Epoch[31] Batch [880]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103424,	
2017-06-26 18:54:09,972 Epoch[31] Batch [890]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103438,	
2017-06-26 18:54:15,889 Epoch[31] Batch [900]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.103421,	
2017-06-26 18:54:22,003 Epoch[31] Batch [910]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103541,	
2017-06-26 18:54:28,083 Epoch[31] Batch [920]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103625,	
2017-06-26 18:54:34,134 Epoch[31] Batch [930]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.103716,	
2017-06-26 18:54:40,240 Epoch[31] Batch [940]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103656,	
2017-06-26 18:54:46,333 Epoch[31] Batch [950]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103638,	
2017-06-26 18:54:52,403 Epoch[31] Batch [960]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103682,	
2017-06-26 18:54:58,482 Epoch[31] Batch [970]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103592,	
2017-06-26 18:55:04,547 Epoch[31] Batch [980]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103626,	
2017-06-26 18:55:10,637 Epoch[31] Batch [990]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103738,	
2017-06-26 18:55:16,706 Epoch[31] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103716,	
2017-06-26 18:55:22,802 Epoch[31] Batch [1010]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103809,	
2017-06-26 18:55:28,878 Epoch[31] Batch [1020]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103733,	
2017-06-26 18:55:34,949 Epoch[31] Batch [1030]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103590,	
2017-06-26 18:55:41,048 Epoch[31] Batch [1040]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103508,	
2017-06-26 18:55:47,168 Epoch[31] Batch [1050]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103462,	
2017-06-26 18:55:53,407 Epoch[31] Batch [1060]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.103421,	
2017-06-26 18:55:59,444 Epoch[31] Batch [1070]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103374,	
2017-06-26 18:56:05,460 Epoch[31] Batch [1080]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.103329,	
2017-06-26 18:56:11,583 Epoch[31] Batch [1090]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103263,	
2017-06-26 18:56:17,545 Epoch[31] Batch [1100]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103245,	
2017-06-26 18:56:23,572 Epoch[31] Batch [1110]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103333,	
2017-06-26 18:56:29,652 Epoch[31] Batch [1120]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103399,	
2017-06-26 18:56:35,774 Epoch[31] Batch [1130]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103283,	
2017-06-26 18:56:41,792 Epoch[31] Batch [1140]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.103255,	
2017-06-26 18:56:47,902 Epoch[31] Batch [1150]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103271,	
2017-06-26 18:56:53,964 Epoch[31] Batch [1160]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103302,	
2017-06-26 18:57:00,041 Epoch[31] Batch [1170]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103368,	
2017-06-26 18:57:06,078 Epoch[31] Batch [1180]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103388,	
2017-06-26 18:57:12,159 Epoch[31] Batch [1190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103448,	
2017-06-26 18:57:18,293 Epoch[31] Batch [1200]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.103414,	
2017-06-26 18:57:24,336 Epoch[31] Batch [1210]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103352,	
2017-06-26 18:57:30,401 Epoch[31] Batch [1220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103344,	
2017-06-26 18:57:36,567 Epoch[31] Batch [1230]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103232,	
2017-06-26 18:57:42,559 Epoch[31] Batch [1240]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.103146,	
2017-06-26 18:57:48,607 Epoch[31] Batch [1250]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103124,	
2017-06-26 18:57:54,638 Epoch[31] Batch [1260]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103047,	
2017-06-26 18:58:00,721 Epoch[31] Batch [1270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102944,	
2017-06-26 18:58:06,878 Epoch[31] Batch [1280]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.102906,	
2017-06-26 18:58:12,356 Epoch[31] Batch [1290]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.102933,	
2017-06-26 18:58:17,938 Epoch[31] Batch [1300]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.102999,	
2017-06-26 18:58:23,557 Epoch[31] Batch [1310]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.102962,	
2017-06-26 18:58:29,168 Epoch[31] Batch [1320]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102995,	
2017-06-26 18:58:34,986 Epoch[31] Batch [1330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103006,	
2017-06-26 18:58:40,452 Epoch[31] Batch [1340]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.102982,	
2017-06-26 18:58:46,475 Epoch[31] Batch [1350]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102902,	
2017-06-26 18:58:52,225 Epoch[31] Batch [1360]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.102932,	
2017-06-26 18:58:57,778 Epoch[31] Batch [1370]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.102910,	
2017-06-26 18:59:03,874 Epoch[31] Batch [1380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102943,	
2017-06-26 18:59:10,002 Epoch[31] Batch [1390]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102971,	
2017-06-26 18:59:16,100 Epoch[31] Batch [1400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102892,	
2017-06-26 18:59:21,025 Epoch[31] Batch [1410]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.102824,	
2017-06-26 18:59:26,828 Epoch[31] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102815,	
2017-06-26 18:59:32,858 Epoch[31] Batch [1430]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102782,	
2017-06-26 18:59:38,964 Epoch[31] Batch [1440]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102771,	
2017-06-26 18:59:45,054 Epoch[31] Batch [1450]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102756,	
2017-06-26 18:59:51,144 Epoch[31] Batch [1460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102791,	
2017-06-26 18:59:57,224 Epoch[31] Batch [1470]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102668,	
2017-06-26 19:00:03,311 Epoch[31] Batch [1480]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102600,	
2017-06-26 19:00:06,941 Epoch[31] Train-FCNLogLoss=0.102540
2017-06-26 19:00:06,941 Epoch[31] Time cost=893.429
2017-06-26 19:00:07,885 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0032.params"
2017-06-26 19:00:11,665 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0032.states"
2017-06-26 19:00:18,590 Epoch[32] Batch [10]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101330,	
2017-06-26 19:00:24,684 Epoch[32] Batch [20]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099901,	
2017-06-26 19:00:30,736 Epoch[32] Batch [30]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101887,	
2017-06-26 19:00:36,843 Epoch[32] Batch [40]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103023,	
2017-06-26 19:00:42,925 Epoch[32] Batch [50]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102309,	
2017-06-26 19:00:49,039 Epoch[32] Batch [60]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103133,	
2017-06-26 19:00:55,109 Epoch[32] Batch [70]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103351,	
2017-06-26 19:01:01,220 Epoch[32] Batch [80]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101828,	
2017-06-26 19:01:07,334 Epoch[32] Batch [90]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101187,	
2017-06-26 19:01:13,356 Epoch[32] Batch [100]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101622,	
2017-06-26 19:01:19,431 Epoch[32] Batch [110]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101970,	
2017-06-26 19:01:25,677 Epoch[32] Batch [120]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.101598,	
2017-06-26 19:01:31,807 Epoch[32] Batch [130]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101793,	
2017-06-26 19:01:37,870 Epoch[32] Batch [140]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101611,	
2017-06-26 19:01:43,950 Epoch[32] Batch [150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102332,	
2017-06-26 19:01:50,076 Epoch[32] Batch [160]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102008,	
2017-06-26 19:01:56,154 Epoch[32] Batch [170]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102441,	
2017-06-26 19:02:02,218 Epoch[32] Batch [180]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102393,	
2017-06-26 19:02:08,292 Epoch[32] Batch [190]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102497,	
2017-06-26 19:02:14,373 Epoch[32] Batch [200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102285,	
2017-06-26 19:02:20,461 Epoch[32] Batch [210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102023,	
2017-06-26 19:02:26,521 Epoch[32] Batch [220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102162,	
2017-06-26 19:02:32,675 Epoch[32] Batch [230]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.102299,	
2017-06-26 19:02:38,700 Epoch[32] Batch [240]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102210,	
2017-06-26 19:02:44,838 Epoch[32] Batch [250]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102288,	
2017-06-26 19:02:50,457 Epoch[32] Batch [260]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.102378,	
2017-06-26 19:02:56,052 Epoch[32] Batch [270]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102027,	
2017-06-26 19:03:01,611 Epoch[32] Batch [280]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.101777,	
2017-06-26 19:03:07,202 Epoch[32] Batch [290]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.101778,	
2017-06-26 19:03:12,995 Epoch[32] Batch [300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101281,	
2017-06-26 19:03:18,641 Epoch[32] Batch [310]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.100915,	
2017-06-26 19:03:24,167 Epoch[32] Batch [320]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.101191,	
2017-06-26 19:03:29,738 Epoch[32] Batch [330]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.101172,	
2017-06-26 19:03:35,874 Epoch[32] Batch [340]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.100925,	
2017-06-26 19:03:41,580 Epoch[32] Batch [350]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100715,	
2017-06-26 19:03:47,656 Epoch[32] Batch [360]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100979,	
2017-06-26 19:03:53,775 Epoch[32] Batch [370]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101085,	
2017-06-26 19:03:59,797 Epoch[32] Batch [380]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.100980,	
2017-06-26 19:04:06,049 Epoch[32] Batch [390]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.101009,	
2017-06-26 19:04:12,221 Epoch[32] Batch [400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.100985,	
2017-06-26 19:04:18,316 Epoch[32] Batch [410]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100889,	
2017-06-26 19:04:24,394 Epoch[32] Batch [420]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100924,	
2017-06-26 19:04:30,478 Epoch[32] Batch [430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101065,	
2017-06-26 19:04:36,531 Epoch[32] Batch [440]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101101,	
2017-06-26 19:04:42,690 Epoch[32] Batch [450]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101280,	
2017-06-26 19:04:48,669 Epoch[32] Batch [460]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.101259,	
2017-06-26 19:04:54,838 Epoch[32] Batch [470]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101407,	
2017-06-26 19:05:00,826 Epoch[32] Batch [480]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.101363,	
2017-06-26 19:05:06,978 Epoch[32] Batch [490]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.101210,	
2017-06-26 19:05:13,014 Epoch[32] Batch [500]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101355,	
2017-06-26 19:05:19,051 Epoch[32] Batch [510]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101300,	
2017-06-26 19:05:25,155 Epoch[32] Batch [520]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101422,	
2017-06-26 19:05:31,305 Epoch[32] Batch [530]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.101518,	
2017-06-26 19:05:37,559 Epoch[32] Batch [540]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-26 19:05:43,567 Epoch[32] Batch [550]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101488,	
2017-06-26 19:05:49,650 Epoch[32] Batch [560]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101401,	
2017-06-26 19:05:55,735 Epoch[32] Batch [570]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101297,	
2017-06-26 19:06:01,803 Epoch[32] Batch [580]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101260,	
2017-06-26 19:06:07,857 Epoch[32] Batch [590]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101100,	
2017-06-26 19:06:13,935 Epoch[32] Batch [600]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100897,	
2017-06-26 19:06:19,976 Epoch[32] Batch [610]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100932,	
2017-06-26 19:06:26,029 Epoch[32] Batch [620]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101001,	
2017-06-26 19:06:32,115 Epoch[32] Batch [630]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100835,	
2017-06-26 19:06:38,134 Epoch[32] Batch [640]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.100901,	
2017-06-26 19:06:44,238 Epoch[32] Batch [650]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100817,	
2017-06-26 19:06:50,278 Epoch[32] Batch [660]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100933,	
2017-06-26 19:06:56,333 Epoch[32] Batch [670]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100942,	
2017-06-26 19:07:02,392 Epoch[32] Batch [680]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100812,	
2017-06-26 19:07:08,451 Epoch[32] Batch [690]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100765,	
2017-06-26 19:07:14,537 Epoch[32] Batch [700]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100654,	
2017-06-26 19:07:20,587 Epoch[32] Batch [710]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100641,	
2017-06-26 19:07:26,666 Epoch[32] Batch [720]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100584,	
2017-06-26 19:07:32,709 Epoch[32] Batch [730]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100591,	
2017-06-26 19:07:38,586 Epoch[32] Batch [740]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.100468,	
2017-06-26 19:07:44,310 Epoch[32] Batch [750]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.100516,	
2017-06-26 19:07:50,019 Epoch[32] Batch [760]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100567,	
2017-06-26 19:07:55,761 Epoch[32] Batch [770]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100721,	
2017-06-26 19:08:01,443 Epoch[32] Batch [780]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.100957,	
2017-06-26 19:08:07,192 Epoch[32] Batch [790]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101128,	
2017-06-26 19:08:12,855 Epoch[32] Batch [800]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.101190,	
2017-06-26 19:08:18,929 Epoch[32] Batch [810]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101276,	
2017-06-26 19:08:24,979 Epoch[32] Batch [820]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101259,	
2017-06-26 19:08:31,004 Epoch[32] Batch [830]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101234,	
2017-06-26 19:08:37,165 Epoch[32] Batch [840]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101205,	
2017-06-26 19:08:43,255 Epoch[32] Batch [850]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101221,	
2017-06-26 19:08:49,366 Epoch[32] Batch [860]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101317,	
2017-06-26 19:08:55,419 Epoch[32] Batch [870]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101345,	
2017-06-26 19:09:01,470 Epoch[32] Batch [880]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101208,	
2017-06-26 19:09:07,558 Epoch[32] Batch [890]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101274,	
2017-06-26 19:09:13,657 Epoch[32] Batch [900]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101367,	
2017-06-26 19:09:19,766 Epoch[32] Batch [910]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101220,	
2017-06-26 19:09:25,817 Epoch[32] Batch [920]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101306,	
2017-06-26 19:09:31,935 Epoch[32] Batch [930]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101293,	
2017-06-26 19:09:38,063 Epoch[32] Batch [940]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101365,	
2017-06-26 19:09:44,144 Epoch[32] Batch [950]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101447,	
2017-06-26 19:09:50,159 Epoch[32] Batch [960]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101417,	
2017-06-26 19:09:56,197 Epoch[32] Batch [970]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102677,	
2017-06-26 19:10:02,277 Epoch[32] Batch [980]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103100,	
2017-06-26 19:10:08,403 Epoch[32] Batch [990]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103485,	
2017-06-26 19:10:14,477 Epoch[32] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103733,	
2017-06-26 19:10:20,497 Epoch[32] Batch [1010]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103885,	
2017-06-26 19:10:26,554 Epoch[32] Batch [1020]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103827,	
2017-06-26 19:10:32,663 Epoch[32] Batch [1030]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103797,	
2017-06-26 19:10:38,705 Epoch[32] Batch [1040]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103821,	
2017-06-26 19:10:44,796 Epoch[32] Batch [1050]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103892,	
2017-06-26 19:10:50,984 Epoch[32] Batch [1060]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.103900,	
2017-06-26 19:10:56,947 Epoch[32] Batch [1070]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103853,	
2017-06-26 19:11:03,051 Epoch[32] Batch [1080]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103824,	
2017-06-26 19:11:09,101 Epoch[32] Batch [1090]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.103823,	
2017-06-26 19:11:15,195 Epoch[32] Batch [1100]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103791,	
2017-06-26 19:11:21,266 Epoch[32] Batch [1110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103677,	
2017-06-26 19:11:27,328 Epoch[32] Batch [1120]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103603,	
2017-06-26 19:11:33,396 Epoch[32] Batch [1130]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103473,	
2017-06-26 19:11:39,501 Epoch[32] Batch [1140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103667,	
2017-06-26 19:11:45,615 Epoch[32] Batch [1150]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103762,	
2017-06-26 19:11:51,644 Epoch[32] Batch [1160]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103720,	
2017-06-26 19:11:57,790 Epoch[32] Batch [1170]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103835,	
2017-06-26 19:12:03,852 Epoch[32] Batch [1180]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103873,	
2017-06-26 19:12:09,695 Epoch[32] Batch [1190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103838,	
2017-06-26 19:12:15,335 Epoch[32] Batch [1200]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.103800,	
2017-06-26 19:12:20,839 Epoch[32] Batch [1210]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.104021,	
2017-06-26 19:12:26,405 Epoch[32] Batch [1220]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.104185,	
2017-06-26 19:12:31,989 Epoch[32] Batch [1230]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.104249,	
2017-06-26 19:12:37,548 Epoch[32] Batch [1240]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.104283,	
2017-06-26 19:12:43,166 Epoch[32] Batch [1250]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.104223,	
2017-06-26 19:12:48,696 Epoch[32] Batch [1260]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.104253,	
2017-06-26 19:12:54,608 Epoch[32] Batch [1270]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104302,	
2017-06-26 19:13:00,542 Epoch[32] Batch [1280]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.104302,	
2017-06-26 19:13:06,970 Epoch[32] Batch [1290]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.104285,	
2017-06-26 19:13:12,978 Epoch[32] Batch [1300]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.104219,	
2017-06-26 19:13:19,042 Epoch[32] Batch [1310]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104195,	
2017-06-26 19:13:25,147 Epoch[32] Batch [1320]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104217,	
2017-06-26 19:13:31,212 Epoch[32] Batch [1330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104197,	
2017-06-26 19:13:37,268 Epoch[32] Batch [1340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.104162,	
2017-06-26 19:13:43,352 Epoch[32] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104130,	
2017-06-26 19:13:49,446 Epoch[32] Batch [1360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.104066,	
2017-06-26 19:13:55,560 Epoch[32] Batch [1370]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.104127,	
2017-06-26 19:14:01,558 Epoch[32] Batch [1380]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.104167,	
2017-06-26 19:14:07,267 Epoch[32] Batch [1390]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.104184,	
2017-06-26 19:14:12,977 Epoch[32] Batch [1400]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.104312,	
2017-06-26 19:14:19,033 Epoch[32] Batch [1410]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.104256,	
2017-06-26 19:14:25,166 Epoch[32] Batch [1420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.104301,	
2017-06-26 19:14:31,192 Epoch[32] Batch [1430]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.104294,	
2017-06-26 19:14:37,511 Epoch[32] Batch [1440]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.104280,	
2017-06-26 19:14:43,587 Epoch[32] Batch [1450]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104276,	
2017-06-26 19:14:49,668 Epoch[32] Batch [1460]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104218,	
2017-06-26 19:14:55,825 Epoch[32] Batch [1470]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.104224,	
2017-06-26 19:15:01,819 Epoch[32] Batch [1480]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.104238,	
2017-06-26 19:15:05,468 Epoch[32] Train-FCNLogLoss=0.104236
2017-06-26 19:15:05,468 Epoch[32] Time cost=893.802
2017-06-26 19:15:06,774 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0033.params"
2017-06-26 19:15:10,260 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0033.states"
2017-06-26 19:15:17,223 Epoch[33] Batch [10]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100627,	
2017-06-26 19:15:23,392 Epoch[33] Batch [20]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.102772,	
2017-06-26 19:15:29,388 Epoch[33] Batch [30]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102740,	
2017-06-26 19:15:35,441 Epoch[33] Batch [40]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101578,	
2017-06-26 19:15:41,512 Epoch[33] Batch [50]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100967,	
2017-06-26 19:15:47,617 Epoch[33] Batch [60]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101627,	
2017-06-26 19:15:53,761 Epoch[33] Batch [70]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102267,	
2017-06-26 19:15:59,870 Epoch[33] Batch [80]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102138,	
2017-06-26 19:16:05,871 Epoch[33] Batch [90]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.101420,	
2017-06-26 19:16:11,987 Epoch[33] Batch [100]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101056,	
2017-06-26 19:16:18,076 Epoch[33] Batch [110]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100916,	
2017-06-26 19:16:24,087 Epoch[33] Batch [120]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101854,	
2017-06-26 19:16:30,221 Epoch[33] Batch [130]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101745,	
2017-06-26 19:16:36,274 Epoch[33] Batch [140]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101896,	
2017-06-26 19:16:42,358 Epoch[33] Batch [150]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101452,	
2017-06-26 19:16:48,559 Epoch[33] Batch [160]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.100958,	
2017-06-26 19:16:54,265 Epoch[33] Batch [170]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100366,	
2017-06-26 19:16:59,922 Epoch[33] Batch [180]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.100282,	
2017-06-26 19:17:05,426 Epoch[33] Batch [190]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.100057,	
2017-06-26 19:17:10,996 Epoch[33] Batch [200]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.099729,	
2017-06-26 19:17:16,570 Epoch[33] Batch [210]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.099751,	
2017-06-26 19:17:22,108 Epoch[33] Batch [220]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.100455,	
2017-06-26 19:17:27,701 Epoch[33] Batch [230]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099900,	
2017-06-26 19:17:33,274 Epoch[33] Batch [240]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.099818,	
2017-06-26 19:17:38,882 Epoch[33] Batch [250]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.099699,	
2017-06-26 19:17:44,547 Epoch[33] Batch [260]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.099421,	
2017-06-26 19:17:50,573 Epoch[33] Batch [270]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099280,	
2017-06-26 19:17:56,620 Epoch[33] Batch [280]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.099295,	
2017-06-26 19:18:02,684 Epoch[33] Batch [290]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099783,	
2017-06-26 19:18:08,802 Epoch[33] Batch [300]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.099655,	
2017-06-26 19:18:14,864 Epoch[33] Batch [310]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099548,	
2017-06-26 19:18:21,010 Epoch[33] Batch [320]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.099469,	
2017-06-26 19:18:27,039 Epoch[33] Batch [330]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099501,	
2017-06-26 19:18:33,128 Epoch[33] Batch [340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099174,	
2017-06-26 19:18:39,193 Epoch[33] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099162,	
2017-06-26 19:18:45,306 Epoch[33] Batch [360]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.099249,	
2017-06-26 19:18:51,370 Epoch[33] Batch [370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099276,	
2017-06-26 19:18:57,458 Epoch[33] Batch [380]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099444,	
2017-06-26 19:19:03,524 Epoch[33] Batch [390]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099554,	
2017-06-26 19:19:09,605 Epoch[33] Batch [400]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099474,	
2017-06-26 19:19:15,901 Epoch[33] Batch [410]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.099365,	
2017-06-26 19:19:21,964 Epoch[33] Batch [420]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099535,	
2017-06-26 19:19:28,017 Epoch[33] Batch [430]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099585,	
2017-06-26 19:19:34,112 Epoch[33] Batch [440]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099720,	
2017-06-26 19:19:40,181 Epoch[33] Batch [450]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099968,	
2017-06-26 19:19:46,254 Epoch[33] Batch [460]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100006,	
2017-06-26 19:19:52,324 Epoch[33] Batch [470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100025,	
2017-06-26 19:19:58,419 Epoch[33] Batch [480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100217,	
2017-06-26 19:20:04,482 Epoch[33] Batch [490]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100275,	
2017-06-26 19:20:10,558 Epoch[33] Batch [500]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100118,	
2017-06-26 19:20:16,638 Epoch[33] Batch [510]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099844,	
2017-06-26 19:20:22,711 Epoch[33] Batch [520]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099786,	
2017-06-26 19:20:28,875 Epoch[33] Batch [530]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.099784,	
2017-06-26 19:20:34,860 Epoch[33] Batch [540]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.099973,	
2017-06-26 19:20:41,026 Epoch[33] Batch [550]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.100506,	
2017-06-26 19:20:47,048 Epoch[33] Batch [560]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.100984,	
2017-06-26 19:20:53,183 Epoch[33] Batch [570]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101169,	
2017-06-26 19:20:59,221 Epoch[33] Batch [580]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101532,	
2017-06-26 19:21:05,355 Epoch[33] Batch [590]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102244,	
2017-06-26 19:21:11,391 Epoch[33] Batch [600]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102701,	
2017-06-26 19:21:17,545 Epoch[33] Batch [610]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.102632,	
2017-06-26 19:21:23,552 Epoch[33] Batch [620]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102682,	
2017-06-26 19:21:29,647 Epoch[33] Batch [630]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102658,	
2017-06-26 19:21:35,694 Epoch[33] Batch [640]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102601,	
2017-06-26 19:21:41,753 Epoch[33] Batch [650]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102645,	
2017-06-26 19:21:47,408 Epoch[33] Batch [660]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.102575,	
2017-06-26 19:21:52,986 Epoch[33] Batch [670]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.102773,	
2017-06-26 19:21:58,600 Epoch[33] Batch [680]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102727,	
2017-06-26 19:22:04,203 Epoch[33] Batch [690]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.102769,	
2017-06-26 19:22:09,921 Epoch[33] Batch [700]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.102645,	
2017-06-26 19:22:15,556 Epoch[33] Batch [710]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.102635,	
2017-06-26 19:22:21,149 Epoch[33] Batch [720]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102563,	
2017-06-26 19:22:26,733 Epoch[33] Batch [730]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.102565,	
2017-06-26 19:22:32,378 Epoch[33] Batch [740]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.102565,	
2017-06-26 19:22:38,507 Epoch[33] Batch [750]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102575,	
2017-06-26 19:22:44,571 Epoch[33] Batch [760]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102574,	
2017-06-26 19:22:50,680 Epoch[33] Batch [770]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102536,	
2017-06-26 19:22:56,753 Epoch[33] Batch [780]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102365,	
2017-06-26 19:23:02,850 Epoch[33] Batch [790]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102316,	
2017-06-26 19:23:08,948 Epoch[33] Batch [800]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102395,	
2017-06-26 19:23:15,013 Epoch[33] Batch [810]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102349,	
2017-06-26 19:23:21,133 Epoch[33] Batch [820]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102387,	
2017-06-26 19:23:27,182 Epoch[33] Batch [830]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102219,	
2017-06-26 19:23:33,300 Epoch[33] Batch [840]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102176,	
2017-06-26 19:23:39,356 Epoch[33] Batch [850]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102093,	
2017-06-26 19:23:45,436 Epoch[33] Batch [860]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101907,	
2017-06-26 19:23:51,702 Epoch[33] Batch [870]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.102013,	
2017-06-26 19:23:57,796 Epoch[33] Batch [880]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101972,	
2017-06-26 19:24:03,849 Epoch[33] Batch [890]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101982,	
2017-06-26 19:24:09,862 Epoch[33] Batch [900]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101983,	
2017-06-26 19:24:16,064 Epoch[33] Batch [910]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.102049,	
2017-06-26 19:24:22,093 Epoch[33] Batch [920]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102074,	
2017-06-26 19:24:28,163 Epoch[33] Batch [930]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102189,	
2017-06-26 19:24:34,310 Epoch[33] Batch [940]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102192,	
2017-06-26 19:24:40,316 Epoch[33] Batch [950]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102117,	
2017-06-26 19:24:46,411 Epoch[33] Batch [960]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102198,	
2017-06-26 19:24:52,480 Epoch[33] Batch [970]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102263,	
2017-06-26 19:24:58,532 Epoch[33] Batch [980]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102303,	
2017-06-26 19:25:04,667 Epoch[33] Batch [990]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102337,	
2017-06-26 19:25:10,682 Epoch[33] Batch [1000]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102327,	
2017-06-26 19:25:16,778 Epoch[33] Batch [1010]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102333,	
2017-06-26 19:25:22,851 Epoch[33] Batch [1020]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102273,	
2017-06-26 19:25:28,973 Epoch[33] Batch [1030]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102304,	
2017-06-26 19:25:35,005 Epoch[33] Batch [1040]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102262,	
2017-06-26 19:25:41,103 Epoch[33] Batch [1050]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102277,	
2017-06-26 19:25:47,154 Epoch[33] Batch [1060]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102186,	
2017-06-26 19:25:53,270 Epoch[33] Batch [1070]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102127,	
2017-06-26 19:25:59,291 Epoch[33] Batch [1080]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102092,	
2017-06-26 19:26:05,362 Epoch[33] Batch [1090]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102025,	
2017-06-26 19:26:11,495 Epoch[33] Batch [1100]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101988,	
2017-06-26 19:26:17,512 Epoch[33] Batch [1110]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102079,	
2017-06-26 19:26:23,585 Epoch[33] Batch [1120]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102024,	
2017-06-26 19:26:29,484 Epoch[33] Batch [1130]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.102059,	
2017-06-26 19:26:35,175 Epoch[33] Batch [1140]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.102097,	
2017-06-26 19:26:40,880 Epoch[33] Batch [1150]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.102073,	
2017-06-26 19:26:46,607 Epoch[33] Batch [1160]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.102084,	
2017-06-26 19:26:52,323 Epoch[33] Batch [1170]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.102140,	
2017-06-26 19:26:58,004 Epoch[33] Batch [1180]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.102080,	
2017-06-26 19:27:03,658 Epoch[33] Batch [1190]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.102027,	
2017-06-26 19:27:09,583 Epoch[33] Batch [1200]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.102000,	
2017-06-26 19:27:15,669 Epoch[33] Batch [1210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102101,	
2017-06-26 19:27:21,782 Epoch[33] Batch [1220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102083,	
2017-06-26 19:27:27,862 Epoch[33] Batch [1230]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102195,	
2017-06-26 19:27:33,941 Epoch[33] Batch [1240]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102217,	
2017-06-26 19:27:40,044 Epoch[33] Batch [1250]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102197,	
2017-06-26 19:27:46,095 Epoch[33] Batch [1260]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102181,	
2017-06-26 19:27:52,208 Epoch[33] Batch [1270]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102222,	
2017-06-26 19:27:58,273 Epoch[33] Batch [1280]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102220,	
2017-06-26 19:28:04,352 Epoch[33] Batch [1290]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102262,	
2017-06-26 19:28:10,451 Epoch[33] Batch [1300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102289,	
2017-06-26 19:28:16,534 Epoch[33] Batch [1310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102332,	
2017-06-26 19:28:22,577 Epoch[33] Batch [1320]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102262,	
2017-06-26 19:28:28,699 Epoch[33] Batch [1330]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102284,	
2017-06-26 19:28:34,753 Epoch[33] Batch [1340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102315,	
2017-06-26 19:28:40,842 Epoch[33] Batch [1350]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102357,	
2017-06-26 19:28:46,913 Epoch[33] Batch [1360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102263,	
2017-06-26 19:28:53,003 Epoch[33] Batch [1370]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102329,	
2017-06-26 19:28:58,336 Epoch[33] Batch [1380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102376,	
2017-06-26 19:29:04,387 Epoch[33] Batch [1390]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102317,	
2017-06-26 19:29:10,450 Epoch[33] Batch [1400]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102318,	
2017-06-26 19:29:16,504 Epoch[33] Batch [1410]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102359,	
2017-06-26 19:29:22,618 Epoch[33] Batch [1420]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102269,	
2017-06-26 19:29:28,679 Epoch[33] Batch [1430]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102258,	
2017-06-26 19:29:34,788 Epoch[33] Batch [1440]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102173,	
2017-06-26 19:29:40,826 Epoch[33] Batch [1450]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102162,	
2017-06-26 19:29:47,000 Epoch[33] Batch [1460]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.102119,	
2017-06-26 19:29:53,175 Epoch[33] Batch [1470]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.102024,	
2017-06-26 19:29:59,324 Epoch[33] Batch [1480]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102150,	
2017-06-26 19:30:02,981 Epoch[33] Train-FCNLogLoss=0.102132
2017-06-26 19:30:02,983 Epoch[33] Time cost=892.723
2017-06-26 19:30:04,257 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0034.params"
2017-06-26 19:30:08,118 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0034.states"
2017-06-26 19:30:15,214 Epoch[34] Batch [10]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.101836,	
2017-06-26 19:30:21,297 Epoch[34] Batch [20]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097574,	
2017-06-26 19:30:27,328 Epoch[34] Batch [30]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101315,	
2017-06-26 19:30:33,541 Epoch[34] Batch [40]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.098369,	
2017-06-26 19:30:39,574 Epoch[34] Batch [50]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.094505,	
2017-06-26 19:30:45,645 Epoch[34] Batch [60]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.095818,	
2017-06-26 19:30:51,713 Epoch[34] Batch [70]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.095112,	
2017-06-26 19:30:57,395 Epoch[34] Batch [80]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.094784,	
2017-06-26 19:31:02,990 Epoch[34] Batch [90]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.094727,	
2017-06-26 19:31:08,562 Epoch[34] Batch [100]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.094794,	
2017-06-26 19:31:14,195 Epoch[34] Batch [110]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.095806,	
2017-06-26 19:31:19,756 Epoch[34] Batch [120]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.096857,	
2017-06-26 19:31:25,348 Epoch[34] Batch [130]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098225,	
2017-06-26 19:31:30,935 Epoch[34] Batch [140]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.099589,	
2017-06-26 19:31:36,562 Epoch[34] Batch [150]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.099438,	
2017-06-26 19:31:42,186 Epoch[34] Batch [160]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.099065,	
2017-06-26 19:31:48,213 Epoch[34] Batch [170]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099209,	
2017-06-26 19:31:54,290 Epoch[34] Batch [180]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099392,	
2017-06-26 19:32:00,395 Epoch[34] Batch [190]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100051,	
2017-06-26 19:32:06,432 Epoch[34] Batch [200]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100303,	
2017-06-26 19:32:12,480 Epoch[34] Batch [210]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100513,	
2017-06-26 19:32:18,572 Epoch[34] Batch [220]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100082,	
2017-06-26 19:32:24,688 Epoch[34] Batch [230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100263,	
2017-06-26 19:32:30,757 Epoch[34] Batch [240]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100720,	
2017-06-26 19:32:36,814 Epoch[34] Batch [250]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101174,	
2017-06-26 19:32:42,915 Epoch[34] Batch [260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101462,	
2017-06-26 19:32:49,017 Epoch[34] Batch [270]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101326,	
2017-06-26 19:32:55,132 Epoch[34] Batch [280]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101134,	
2017-06-26 19:33:01,187 Epoch[34] Batch [290]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101220,	
2017-06-26 19:33:07,251 Epoch[34] Batch [300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101464,	
2017-06-26 19:33:13,348 Epoch[34] Batch [310]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101287,	
2017-06-26 19:33:19,429 Epoch[34] Batch [320]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101237,	
2017-06-26 19:33:25,544 Epoch[34] Batch [330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101017,	
2017-06-26 19:33:31,665 Epoch[34] Batch [340]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101145,	
2017-06-26 19:33:37,697 Epoch[34] Batch [350]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100990,	
2017-06-26 19:33:43,768 Epoch[34] Batch [360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100779,	
2017-06-26 19:33:49,871 Epoch[34] Batch [370]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100950,	
2017-06-26 19:33:55,950 Epoch[34] Batch [380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100651,	
2017-06-26 19:34:01,988 Epoch[34] Batch [390]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100587,	
2017-06-26 19:34:08,059 Epoch[34] Batch [400]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100556,	
2017-06-26 19:34:14,172 Epoch[34] Batch [410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100627,	
2017-06-26 19:34:20,243 Epoch[34] Batch [420]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100441,	
2017-06-26 19:34:26,326 Epoch[34] Batch [430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100464,	
2017-06-26 19:34:32,367 Epoch[34] Batch [440]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100302,	
2017-06-26 19:34:38,467 Epoch[34] Batch [450]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100145,	
2017-06-26 19:34:44,578 Epoch[34] Batch [460]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100057,	
2017-06-26 19:34:50,608 Epoch[34] Batch [470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099989,	
2017-06-26 19:34:56,694 Epoch[34] Batch [480]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100472,	
2017-06-26 19:35:02,764 Epoch[34] Batch [490]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100682,	
2017-06-26 19:35:08,853 Epoch[34] Batch [500]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100704,	
2017-06-26 19:35:14,928 Epoch[34] Batch [510]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100774,	
2017-06-26 19:35:20,999 Epoch[34] Batch [520]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100834,	
2017-06-26 19:35:27,095 Epoch[34] Batch [530]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100741,	
2017-06-26 19:35:33,175 Epoch[34] Batch [540]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100654,	
2017-06-26 19:35:39,148 Epoch[34] Batch [550]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.100686,	
2017-06-26 19:35:44,754 Epoch[34] Batch [560]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.100532,	
2017-06-26 19:35:50,294 Epoch[34] Batch [570]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.100430,	
2017-06-26 19:35:55,945 Epoch[34] Batch [580]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.100308,	
2017-06-26 19:36:01,462 Epoch[34] Batch [590]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.100230,	
2017-06-26 19:36:07,031 Epoch[34] Batch [600]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.100194,	
2017-06-26 19:36:12,701 Epoch[34] Batch [610]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.100129,	
2017-06-26 19:36:18,260 Epoch[34] Batch [620]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.100168,	
2017-06-26 19:36:23,825 Epoch[34] Batch [630]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.100236,	
2017-06-26 19:36:29,765 Epoch[34] Batch [640]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.100092,	
2017-06-26 19:36:35,806 Epoch[34] Batch [650]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100124,	
2017-06-26 19:36:41,912 Epoch[34] Batch [660]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100198,	
2017-06-26 19:36:48,034 Epoch[34] Batch [670]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.100032,	
2017-06-26 19:36:54,116 Epoch[34] Batch [680]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100112,	
2017-06-26 19:37:00,330 Epoch[34] Batch [690]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.099968,	
2017-06-26 19:37:06,458 Epoch[34] Batch [700]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.100015,	
2017-06-26 19:37:12,497 Epoch[34] Batch [710]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100004,	
2017-06-26 19:37:18,554 Epoch[34] Batch [720]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099988,	
2017-06-26 19:37:24,628 Epoch[34] Batch [730]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100001,	
2017-06-26 19:37:30,693 Epoch[34] Batch [740]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100181,	
2017-06-26 19:37:36,729 Epoch[34] Batch [750]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100081,	
2017-06-26 19:37:42,825 Epoch[34] Batch [760]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100108,	
2017-06-26 19:37:48,878 Epoch[34] Batch [770]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100033,	
2017-06-26 19:37:54,942 Epoch[34] Batch [780]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099975,	
2017-06-26 19:38:01,002 Epoch[34] Batch [790]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100127,	
2017-06-26 19:38:07,128 Epoch[34] Batch [800]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.100310,	
2017-06-26 19:38:13,248 Epoch[34] Batch [810]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100298,	
2017-06-26 19:38:19,316 Epoch[34] Batch [820]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100114,	
2017-06-26 19:38:25,411 Epoch[34] Batch [830]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100194,	
2017-06-26 19:38:31,485 Epoch[34] Batch [840]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100065,	
2017-06-26 19:38:37,546 Epoch[34] Batch [850]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100111,	
2017-06-26 19:38:43,622 Epoch[34] Batch [860]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100137,	
2017-06-26 19:38:49,730 Epoch[34] Batch [870]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100210,	
2017-06-26 19:38:55,815 Epoch[34] Batch [880]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100326,	
2017-06-26 19:39:02,117 Epoch[34] Batch [890]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100518,	
2017-06-26 19:39:08,187 Epoch[34] Batch [900]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100613,	
2017-06-26 19:39:14,239 Epoch[34] Batch [910]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100774,	
2017-06-26 19:39:20,365 Epoch[34] Batch [920]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.100941,	
2017-06-26 19:39:26,479 Epoch[34] Batch [930]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100933,	
2017-06-26 19:39:32,562 Epoch[34] Batch [940]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100897,	
2017-06-26 19:39:38,639 Epoch[34] Batch [950]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101059,	
2017-06-26 19:39:44,755 Epoch[34] Batch [960]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101022,	
2017-06-26 19:39:50,788 Epoch[34] Batch [970]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100951,	
2017-06-26 19:39:56,910 Epoch[34] Batch [980]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101015,	
2017-06-26 19:40:02,956 Epoch[34] Batch [990]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101007,	
2017-06-26 19:40:09,049 Epoch[34] Batch [1000]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101043,	
2017-06-26 19:40:15,128 Epoch[34] Batch [1010]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100968,	
2017-06-26 19:40:21,209 Epoch[34] Batch [1020]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101035,	
2017-06-26 19:40:26,948 Epoch[34] Batch [1030]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100984,	
2017-06-26 19:40:32,593 Epoch[34] Batch [1040]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.100917,	
2017-06-26 19:40:38,486 Epoch[34] Batch [1050]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.100822,	
2017-06-26 19:40:43,993 Epoch[34] Batch [1060]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.100762,	
2017-06-26 19:40:49,628 Epoch[34] Batch [1070]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.100709,	
2017-06-26 19:40:55,491 Epoch[34] Batch [1080]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.100758,	
2017-06-26 19:41:01,173 Epoch[34] Batch [1090]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.100726,	
2017-06-26 19:41:06,818 Epoch[34] Batch [1100]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.100785,	
2017-06-26 19:41:12,339 Epoch[34] Batch [1110]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.100671,	
2017-06-26 19:41:17,688 Epoch[34] Batch [1120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100706,	
2017-06-26 19:41:23,112 Epoch[34] Batch [1130]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.100689,	
2017-06-26 19:41:28,479 Epoch[34] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100664,	
2017-06-26 19:41:33,803 Epoch[34] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100630,	
2017-06-26 19:41:39,177 Epoch[34] Batch [1160]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.100611,	
2017-06-26 19:41:44,504 Epoch[34] Batch [1170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100604,	
2017-06-26 19:41:49,842 Epoch[34] Batch [1180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100623,	
2017-06-26 19:41:55,208 Epoch[34] Batch [1190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100631,	
2017-06-26 19:42:00,559 Epoch[34] Batch [1200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100535,	
2017-06-26 19:42:05,896 Epoch[34] Batch [1210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100652,	
2017-06-26 19:42:11,262 Epoch[34] Batch [1220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100673,	
2017-06-26 19:42:16,605 Epoch[34] Batch [1230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100632,	
2017-06-26 19:42:21,905 Epoch[34] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100654,	
2017-06-26 19:42:27,260 Epoch[34] Batch [1250]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100712,	
2017-06-26 19:42:32,624 Epoch[34] Batch [1260]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100800,	
2017-06-26 19:42:37,927 Epoch[34] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.100661,	
2017-06-26 19:42:43,280 Epoch[34] Batch [1280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100775,	
2017-06-26 19:42:48,617 Epoch[34] Batch [1290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100795,	
2017-06-26 19:42:53,969 Epoch[34] Batch [1300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100850,	
2017-06-26 19:42:59,315 Epoch[34] Batch [1310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100926,	
2017-06-26 19:43:04,675 Epoch[34] Batch [1320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100916,	
2017-06-26 19:43:10,004 Epoch[34] Batch [1330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100896,	
2017-06-26 19:43:15,355 Epoch[34] Batch [1340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100913,	
2017-06-26 19:43:20,671 Epoch[34] Batch [1350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.101013,	
2017-06-26 19:43:26,030 Epoch[34] Batch [1360]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100946,	
2017-06-26 19:43:30,566 Epoch[34] Batch [1370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.100930,	
2017-06-26 19:43:35,859 Epoch[34] Batch [1380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100959,	
2017-06-26 19:43:41,168 Epoch[34] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100978,	
2017-06-26 19:43:46,549 Epoch[34] Batch [1400]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.100995,	
2017-06-26 19:43:51,863 Epoch[34] Batch [1410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100985,	
2017-06-26 19:43:57,204 Epoch[34] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100945,	
2017-06-26 19:44:02,534 Epoch[34] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100922,	
2017-06-26 19:44:07,890 Epoch[34] Batch [1440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101024,	
2017-06-26 19:44:13,198 Epoch[34] Batch [1450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.100950,	
2017-06-26 19:44:18,521 Epoch[34] Batch [1460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101006,	
2017-06-26 19:44:23,869 Epoch[34] Batch [1470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.101253,	
2017-06-26 19:44:29,207 Epoch[34] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101417,	
2017-06-26 19:44:32,381 Epoch[34] Train-FCNLogLoss=0.101462
2017-06-26 19:44:32,381 Epoch[34] Time cost=864.263
2017-06-26 19:44:33,232 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0035.params"
2017-06-26 19:44:34,934 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0035.states"
2017-06-26 19:44:40,946 Epoch[35] Batch [10]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.131492,	
2017-06-26 19:44:46,282 Epoch[35] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.127607,	
2017-06-26 19:44:51,619 Epoch[35] Batch [30]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125991,	
2017-06-26 19:44:56,924 Epoch[35] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.123619,	
2017-06-26 19:45:02,358 Epoch[35] Batch [50]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.123290,	
2017-06-26 19:45:07,644 Epoch[35] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.120546,	
2017-06-26 19:45:12,973 Epoch[35] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117124,	
2017-06-26 19:45:18,337 Epoch[35] Batch [80]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.115502,	
2017-06-26 19:45:23,656 Epoch[35] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114866,	
2017-06-26 19:45:28,959 Epoch[35] Batch [100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.115042,	
2017-06-26 19:45:34,268 Epoch[35] Batch [110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113689,	
2017-06-26 19:45:39,616 Epoch[35] Batch [120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.112193,	
2017-06-26 19:45:44,963 Epoch[35] Batch [130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.111418,	
2017-06-26 19:45:50,260 Epoch[35] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.111112,	
2017-06-26 19:45:55,594 Epoch[35] Batch [150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.110790,	
2017-06-26 19:46:00,930 Epoch[35] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.110304,	
2017-06-26 19:46:06,279 Epoch[35] Batch [170]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.110401,	
2017-06-26 19:46:11,661 Epoch[35] Batch [180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.109324,	
2017-06-26 19:46:16,979 Epoch[35] Batch [190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.108541,	
2017-06-26 19:46:22,301 Epoch[35] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.108342,	
2017-06-26 19:46:27,646 Epoch[35] Batch [210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108108,	
2017-06-26 19:46:32,926 Epoch[35] Batch [220]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.108474,	
2017-06-26 19:46:38,271 Epoch[35] Batch [230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108231,	
2017-06-26 19:46:43,638 Epoch[35] Batch [240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.107940,	
2017-06-26 19:46:48,923 Epoch[35] Batch [250]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.107647,	
2017-06-26 19:46:54,278 Epoch[35] Batch [260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.107465,	
2017-06-26 19:46:59,580 Epoch[35] Batch [270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.106841,	
2017-06-26 19:47:04,958 Epoch[35] Batch [280]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.106606,	
2017-06-26 19:47:10,271 Epoch[35] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.106475,	
2017-06-26 19:47:15,606 Epoch[35] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.106506,	
2017-06-26 19:47:20,942 Epoch[35] Batch [310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.106614,	
2017-06-26 19:47:26,258 Epoch[35] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.106270,	
2017-06-26 19:47:31,634 Epoch[35] Batch [330]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.105866,	
2017-06-26 19:47:36,990 Epoch[35] Batch [340]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105915,	
2017-06-26 19:47:42,336 Epoch[35] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.105807,	
2017-06-26 19:47:47,619 Epoch[35] Batch [360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.105765,	
2017-06-26 19:47:52,956 Epoch[35] Batch [370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105400,	
2017-06-26 19:47:58,276 Epoch[35] Batch [380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105004,	
2017-06-26 19:48:03,611 Epoch[35] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105071,	
2017-06-26 19:48:08,897 Epoch[35] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.105180,	
2017-06-26 19:48:14,281 Epoch[35] Batch [410]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.104843,	
2017-06-26 19:48:19,610 Epoch[35] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104710,	
2017-06-26 19:48:24,974 Epoch[35] Batch [430]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.105086,	
2017-06-26 19:48:30,269 Epoch[35] Batch [440]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.104630,	
2017-06-26 19:48:35,617 Epoch[35] Batch [450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.104519,	
2017-06-26 19:48:40,939 Epoch[35] Batch [460]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104608,	
2017-06-26 19:48:46,263 Epoch[35] Batch [470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104383,	
2017-06-26 19:48:51,620 Epoch[35] Batch [480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.104492,	
2017-06-26 19:48:56,981 Epoch[35] Batch [490]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104342,	
2017-06-26 19:49:02,298 Epoch[35] Batch [500]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104222,	
2017-06-26 19:49:07,613 Epoch[35] Batch [510]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.104168,	
2017-06-26 19:49:12,952 Epoch[35] Batch [520]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.104057,	
2017-06-26 19:49:18,303 Epoch[35] Batch [530]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103790,	
2017-06-26 19:49:23,632 Epoch[35] Batch [540]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.103694,	
2017-06-26 19:49:28,958 Epoch[35] Batch [550]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.103704,	
2017-06-26 19:49:34,285 Epoch[35] Batch [560]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.103691,	
2017-06-26 19:49:39,663 Epoch[35] Batch [570]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.103424,	
2017-06-26 19:49:45,006 Epoch[35] Batch [580]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.103354,	
2017-06-26 19:49:50,335 Epoch[35] Batch [590]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.103371,	
2017-06-26 19:49:55,684 Epoch[35] Batch [600]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103361,	
2017-06-26 19:50:01,001 Epoch[35] Batch [610]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.103398,	
2017-06-26 19:50:06,355 Epoch[35] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.103657,	
2017-06-26 19:50:11,694 Epoch[35] Batch [630]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.103571,	
2017-06-26 19:50:17,041 Epoch[35] Batch [640]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103504,	
2017-06-26 19:50:22,528 Epoch[35] Batch [650]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.103408,	
2017-06-26 19:50:27,952 Epoch[35] Batch [660]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.103339,	
2017-06-26 19:50:33,358 Epoch[35] Batch [670]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.103300,	
2017-06-26 19:50:38,796 Epoch[35] Batch [680]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.103119,	
2017-06-26 19:50:44,106 Epoch[35] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.102980,	
2017-06-26 19:50:49,456 Epoch[35] Batch [700]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102912,	
2017-06-26 19:50:54,792 Epoch[35] Batch [710]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102753,	
2017-06-26 19:51:00,271 Epoch[35] Batch [720]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.102753,	
2017-06-26 19:51:05,563 Epoch[35] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.102679,	
2017-06-26 19:51:10,929 Epoch[35] Batch [740]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.102784,	
2017-06-26 19:51:16,413 Epoch[35] Batch [750]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.102753,	
2017-06-26 19:51:21,713 Epoch[35] Batch [760]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.102728,	
2017-06-26 19:51:27,176 Epoch[35] Batch [770]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.102664,	
2017-06-26 19:51:32,440 Epoch[35] Batch [780]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.102622,	
2017-06-26 19:51:37,757 Epoch[35] Batch [790]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.102630,	
2017-06-26 19:51:43,123 Epoch[35] Batch [800]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.102568,	
2017-06-26 19:51:48,581 Epoch[35] Batch [810]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.102467,	
2017-06-26 19:51:53,903 Epoch[35] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.102439,	
2017-06-26 19:51:59,249 Epoch[35] Batch [830]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102465,	
2017-06-26 19:52:04,626 Epoch[35] Batch [840]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.102298,	
2017-06-26 19:52:09,922 Epoch[35] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.102188,	
2017-06-26 19:52:15,338 Epoch[35] Batch [860]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.102026,	
2017-06-26 19:52:20,608 Epoch[35] Batch [870]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.101999,	
2017-06-26 19:52:26,005 Epoch[35] Batch [880]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.101962,	
2017-06-26 19:52:31,366 Epoch[35] Batch [890]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.101995,	
2017-06-26 19:52:36,802 Epoch[35] Batch [900]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.101993,	
2017-06-26 19:52:42,163 Epoch[35] Batch [910]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.101937,	
2017-06-26 19:52:47,467 Epoch[35] Batch [920]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101959,	
2017-06-26 19:52:52,817 Epoch[35] Batch [930]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.101857,	
2017-06-26 19:52:58,153 Epoch[35] Batch [940]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101786,	
2017-06-26 19:53:03,458 Epoch[35] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101705,	
2017-06-26 19:53:08,822 Epoch[35] Batch [960]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.101672,	
2017-06-26 19:53:14,327 Epoch[35] Batch [970]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.101784,	
2017-06-26 19:53:19,632 Epoch[35] Batch [980]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101821,	
2017-06-26 19:53:24,970 Epoch[35] Batch [990]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101741,	
2017-06-26 19:53:30,321 Epoch[35] Batch [1000]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.101685,	
2017-06-26 19:53:35,676 Epoch[35] Batch [1010]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101597,	
2017-06-26 19:53:40,981 Epoch[35] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101506,	
2017-06-26 19:53:46,334 Epoch[35] Batch [1030]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101531,	
2017-06-26 19:53:51,702 Epoch[35] Batch [1040]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.101434,	
2017-06-26 19:53:57,030 Epoch[35] Batch [1050]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101400,	
2017-06-26 19:54:02,290 Epoch[35] Batch [1060]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.101219,	
2017-06-26 19:54:07,685 Epoch[35] Batch [1070]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.101273,	
2017-06-26 19:54:12,991 Epoch[35] Batch [1080]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101198,	
2017-06-26 19:54:18,346 Epoch[35] Batch [1090]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101209,	
2017-06-26 19:54:23,700 Epoch[35] Batch [1100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101168,	
2017-06-26 19:54:29,036 Epoch[35] Batch [1110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101208,	
2017-06-26 19:54:34,356 Epoch[35] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.101070,	
2017-06-26 19:54:39,703 Epoch[35] Batch [1130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.101014,	
2017-06-26 19:54:45,062 Epoch[35] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101148,	
2017-06-26 19:54:50,374 Epoch[35] Batch [1150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.101035,	
2017-06-26 19:54:55,677 Epoch[35] Batch [1160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101022,	
2017-06-26 19:55:01,059 Epoch[35] Batch [1170]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101046,	
2017-06-26 19:55:06,387 Epoch[35] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101079,	
2017-06-26 19:55:11,744 Epoch[35] Batch [1190]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101074,	
2017-06-26 19:55:17,093 Epoch[35] Batch [1200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100992,	
2017-06-26 19:55:22,360 Epoch[35] Batch [1210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.101004,	
2017-06-26 19:55:27,708 Epoch[35] Batch [1220]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.101018,	
2017-06-26 19:55:33,092 Epoch[35] Batch [1230]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101036,	
2017-06-26 19:55:38,431 Epoch[35] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101055,	
2017-06-26 19:55:43,755 Epoch[35] Batch [1250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101058,	
2017-06-26 19:55:49,076 Epoch[35] Batch [1260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.101065,	
2017-06-26 19:55:54,423 Epoch[35] Batch [1270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.101061,	
2017-06-26 19:55:59,741 Epoch[35] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100994,	
2017-06-26 19:56:05,037 Epoch[35] Batch [1290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.101082,	
2017-06-26 19:56:10,418 Epoch[35] Batch [1300]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101067,	
2017-06-26 19:56:15,731 Epoch[35] Batch [1310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100987,	
2017-06-26 19:56:21,076 Epoch[35] Batch [1320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100969,	
2017-06-26 19:56:26,398 Epoch[35] Batch [1330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100910,	
2017-06-26 19:56:31,770 Epoch[35] Batch [1340]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100888,	
2017-06-26 19:56:37,080 Epoch[35] Batch [1350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100923,	
2017-06-26 19:56:42,418 Epoch[35] Batch [1360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100869,	
2017-06-26 19:56:46,920 Epoch[35] Batch [1370]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.100932,	
2017-06-26 19:56:52,200 Epoch[35] Batch [1380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.100950,	
2017-06-26 19:56:57,517 Epoch[35] Batch [1390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.101043,	
2017-06-26 19:57:02,869 Epoch[35] Batch [1400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101021,	
2017-06-26 19:57:08,200 Epoch[35] Batch [1410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100938,	
2017-06-26 19:57:13,555 Epoch[35] Batch [1420]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100953,	
2017-06-26 19:57:18,894 Epoch[35] Batch [1430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100981,	
2017-06-26 19:57:24,249 Epoch[35] Batch [1440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100979,	
2017-06-26 19:57:29,580 Epoch[35] Batch [1450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100899,	
2017-06-26 19:57:34,935 Epoch[35] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100964,	
2017-06-26 19:57:40,262 Epoch[35] Batch [1470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100944,	
2017-06-26 19:57:45,572 Epoch[35] Batch [1480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.101029,	
2017-06-26 19:57:48,818 Epoch[35] Train-FCNLogLoss=0.100995
2017-06-26 19:57:48,818 Epoch[35] Time cost=793.883
2017-06-26 19:57:49,710 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0036.params"
2017-06-26 19:57:51,279 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0036.states"
2017-06-26 19:57:57,270 Epoch[36] Batch [10]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098944,	
2017-06-26 19:58:02,606 Epoch[36] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102212,	
2017-06-26 19:58:07,934 Epoch[36] Batch [30]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101073,	
2017-06-26 19:58:13,260 Epoch[36] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100553,	
2017-06-26 19:58:18,578 Epoch[36] Batch [50]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099716,	
2017-06-26 19:58:23,928 Epoch[36] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098823,	
2017-06-26 19:58:29,274 Epoch[36] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098339,	
2017-06-26 19:58:34,657 Epoch[36] Batch [80]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098006,	
2017-06-26 19:58:39,915 Epoch[36] Batch [90]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096511,	
2017-06-26 19:58:45,278 Epoch[36] Batch [100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097038,	
2017-06-26 19:58:50,627 Epoch[36] Batch [110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097365,	
2017-06-26 19:58:55,953 Epoch[36] Batch [120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097683,	
2017-06-26 19:59:01,369 Epoch[36] Batch [130]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.098300,	
2017-06-26 19:59:06,667 Epoch[36] Batch [140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098103,	
2017-06-26 19:59:12,026 Epoch[36] Batch [150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097632,	
2017-06-26 19:59:17,362 Epoch[36] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097030,	
2017-06-26 19:59:22,707 Epoch[36] Batch [170]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097061,	
2017-06-26 19:59:28,087 Epoch[36] Batch [180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.097429,	
2017-06-26 19:59:33,507 Epoch[36] Batch [190]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.097117,	
2017-06-26 19:59:38,838 Epoch[36] Batch [200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096795,	
2017-06-26 19:59:44,253 Epoch[36] Batch [210]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.097360,	
2017-06-26 19:59:49,636 Epoch[36] Batch [220]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.097541,	
2017-06-26 19:59:55,132 Epoch[36] Batch [230]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.097410,	
2017-06-26 20:00:00,499 Epoch[36] Batch [240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096878,	
2017-06-26 20:00:05,814 Epoch[36] Batch [250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096799,	
2017-06-26 20:00:11,134 Epoch[36] Batch [260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097108,	
2017-06-26 20:00:16,472 Epoch[36] Batch [270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096915,	
2017-06-26 20:00:22,028 Epoch[36] Batch [280]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097179,	
2017-06-26 20:00:27,314 Epoch[36] Batch [290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098077,	
2017-06-26 20:00:32,623 Epoch[36] Batch [300]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097872,	
2017-06-26 20:00:38,092 Epoch[36] Batch [310]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.097652,	
2017-06-26 20:00:43,457 Epoch[36] Batch [320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098023,	
2017-06-26 20:00:48,800 Epoch[36] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097879,	
2017-06-26 20:00:54,114 Epoch[36] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098127,	
2017-06-26 20:00:59,451 Epoch[36] Batch [350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098375,	
2017-06-26 20:01:04,868 Epoch[36] Batch [360]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098299,	
2017-06-26 20:01:10,187 Epoch[36] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098199,	
2017-06-26 20:01:15,552 Epoch[36] Batch [380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098291,	
2017-06-26 20:01:21,014 Epoch[36] Batch [390]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.098562,	
2017-06-26 20:01:26,291 Epoch[36] Batch [400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098549,	
2017-06-26 20:01:31,662 Epoch[36] Batch [410]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098403,	
2017-06-26 20:01:37,001 Epoch[36] Batch [420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098592,	
2017-06-26 20:01:42,342 Epoch[36] Batch [430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098822,	
2017-06-26 20:01:47,657 Epoch[36] Batch [440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098623,	
2017-06-26 20:01:53,121 Epoch[36] Batch [450]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.098621,	
2017-06-26 20:01:58,548 Epoch[36] Batch [460]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098666,	
2017-06-26 20:02:03,826 Epoch[36] Batch [470]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098906,	
2017-06-26 20:02:09,182 Epoch[36] Batch [480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.099030,	
2017-06-26 20:02:14,520 Epoch[36] Batch [490]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.099219,	
2017-06-26 20:02:19,854 Epoch[36] Batch [500]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099112,	
2017-06-26 20:02:25,238 Epoch[36] Batch [510]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.099083,	
2017-06-26 20:02:30,524 Epoch[36] Batch [520]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098927,	
2017-06-26 20:02:35,875 Epoch[36] Batch [530]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099071,	
2017-06-26 20:02:41,237 Epoch[36] Batch [540]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098931,	
2017-06-26 20:02:46,766 Epoch[36] Batch [550]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.098730,	
2017-06-26 20:02:52,105 Epoch[36] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098928,	
2017-06-26 20:02:57,413 Epoch[36] Batch [570]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098898,	
2017-06-26 20:03:02,766 Epoch[36] Batch [580]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098872,	
2017-06-26 20:03:08,149 Epoch[36] Batch [590]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.099264,	
2017-06-26 20:03:13,459 Epoch[36] Batch [600]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099477,	
2017-06-26 20:03:18,763 Epoch[36] Batch [610]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099558,	
2017-06-26 20:03:24,135 Epoch[36] Batch [620]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.099571,	
2017-06-26 20:03:29,449 Epoch[36] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099267,	
2017-06-26 20:03:34,804 Epoch[36] Batch [640]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.099035,	
2017-06-26 20:03:40,125 Epoch[36] Batch [650]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099354,	
2017-06-26 20:03:45,446 Epoch[36] Batch [660]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099273,	
2017-06-26 20:03:50,751 Epoch[36] Batch [670]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099128,	
2017-06-26 20:03:56,124 Epoch[36] Batch [680]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.099257,	
2017-06-26 20:04:01,439 Epoch[36] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098997,	
2017-06-26 20:04:06,802 Epoch[36] Batch [700]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098930,	
2017-06-26 20:04:12,086 Epoch[36] Batch [710]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098931,	
2017-06-26 20:04:17,425 Epoch[36] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098763,	
2017-06-26 20:04:22,827 Epoch[36] Batch [730]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098797,	
2017-06-26 20:04:28,125 Epoch[36] Batch [740]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098794,	
2017-06-26 20:04:33,473 Epoch[36] Batch [750]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098701,	
2017-06-26 20:04:38,783 Epoch[36] Batch [760]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098783,	
2017-06-26 20:04:44,127 Epoch[36] Batch [770]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098879,	
2017-06-26 20:04:49,448 Epoch[36] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098936,	
2017-06-26 20:04:54,789 Epoch[36] Batch [790]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098932,	
2017-06-26 20:05:00,117 Epoch[36] Batch [800]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098754,	
2017-06-26 20:05:05,468 Epoch[36] Batch [810]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098744,	
2017-06-26 20:05:10,827 Epoch[36] Batch [820]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098708,	
2017-06-26 20:05:16,159 Epoch[36] Batch [830]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098732,	
2017-06-26 20:05:21,440 Epoch[36] Batch [840]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098628,	
2017-06-26 20:05:26,823 Epoch[36] Batch [850]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098720,	
2017-06-26 20:05:32,126 Epoch[36] Batch [860]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098755,	
2017-06-26 20:05:37,422 Epoch[36] Batch [870]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098711,	
2017-06-26 20:05:42,805 Epoch[36] Batch [880]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098672,	
2017-06-26 20:05:48,098 Epoch[36] Batch [890]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098654,	
2017-06-26 20:05:53,461 Epoch[36] Batch [900]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098695,	
2017-06-26 20:05:58,759 Epoch[36] Batch [910]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098683,	
2017-06-26 20:06:04,123 Epoch[36] Batch [920]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098581,	
2017-06-26 20:06:09,440 Epoch[36] Batch [930]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098594,	
2017-06-26 20:06:14,830 Epoch[36] Batch [940]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098553,	
2017-06-26 20:06:20,157 Epoch[36] Batch [950]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098524,	
2017-06-26 20:06:25,509 Epoch[36] Batch [960]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098688,	
2017-06-26 20:06:30,822 Epoch[36] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098644,	
2017-06-26 20:06:36,143 Epoch[36] Batch [980]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098687,	
2017-06-26 20:06:41,560 Epoch[36] Batch [990]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098625,	
2017-06-26 20:06:46,866 Epoch[36] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098706,	
2017-06-26 20:06:52,192 Epoch[36] Batch [1010]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098729,	
2017-06-26 20:06:57,527 Epoch[36] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098722,	
2017-06-26 20:07:02,830 Epoch[36] Batch [1030]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098773,	
2017-06-26 20:07:08,209 Epoch[36] Batch [1040]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098805,	
2017-06-26 20:07:13,581 Epoch[36] Batch [1050]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098821,	
2017-06-26 20:07:18,863 Epoch[36] Batch [1060]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098870,	
2017-06-26 20:07:24,170 Epoch[36] Batch [1070]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098853,	
2017-06-26 20:07:29,544 Epoch[36] Batch [1080]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099039,	
2017-06-26 20:07:34,835 Epoch[36] Batch [1090]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098956,	
2017-06-26 20:07:40,293 Epoch[36] Batch [1100]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.098909,	
2017-06-26 20:07:45,612 Epoch[36] Batch [1110]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098896,	
2017-06-26 20:07:50,971 Epoch[36] Batch [1120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098972,	
2017-06-26 20:07:56,310 Epoch[36] Batch [1130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.099011,	
2017-06-26 20:08:01,655 Epoch[36] Batch [1140]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098981,	
2017-06-26 20:08:06,991 Epoch[36] Batch [1150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098902,	
2017-06-26 20:08:12,416 Epoch[36] Batch [1160]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098823,	
2017-06-26 20:08:17,799 Epoch[36] Batch [1170]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098760,	
2017-06-26 20:08:23,151 Epoch[36] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098770,	
2017-06-26 20:08:28,509 Epoch[36] Batch [1190]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098749,	
2017-06-26 20:08:33,847 Epoch[36] Batch [1200]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098719,	
2017-06-26 20:08:39,394 Epoch[36] Batch [1210]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.098715,	
2017-06-26 20:08:44,704 Epoch[36] Batch [1220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098793,	
2017-06-26 20:08:50,062 Epoch[36] Batch [1230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098831,	
2017-06-26 20:08:55,415 Epoch[36] Batch [1240]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098913,	
2017-06-26 20:09:00,776 Epoch[36] Batch [1250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098916,	
2017-06-26 20:09:06,193 Epoch[36] Batch [1260]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098889,	
2017-06-26 20:09:11,513 Epoch[36] Batch [1270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098770,	
2017-06-26 20:09:16,961 Epoch[36] Batch [1280]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098776,	
2017-06-26 20:09:22,308 Epoch[36] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098790,	
2017-06-26 20:09:27,663 Epoch[36] Batch [1300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098738,	
2017-06-26 20:09:32,958 Epoch[36] Batch [1310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098769,	
2017-06-26 20:09:38,447 Epoch[36] Batch [1320]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.098732,	
2017-06-26 20:09:43,812 Epoch[36] Batch [1330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098778,	
2017-06-26 20:09:49,211 Epoch[36] Batch [1340]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098769,	
2017-06-26 20:09:54,553 Epoch[36] Batch [1350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098759,	
2017-06-26 20:09:59,842 Epoch[36] Batch [1360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098844,	
2017-06-26 20:10:04,484 Epoch[36] Batch [1370]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.098840,	
2017-06-26 20:10:09,758 Epoch[36] Batch [1380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098930,	
2017-06-26 20:10:15,068 Epoch[36] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098870,	
2017-06-26 20:10:20,407 Epoch[36] Batch [1400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098838,	
2017-06-26 20:10:25,767 Epoch[36] Batch [1410]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098912,	
2017-06-26 20:10:31,195 Epoch[36] Batch [1420]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098930,	
2017-06-26 20:10:36,566 Epoch[36] Batch [1430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098944,	
2017-06-26 20:10:41,904 Epoch[36] Batch [1440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098963,	
2017-06-26 20:10:47,198 Epoch[36] Batch [1450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098996,	
2017-06-26 20:10:52,713 Epoch[36] Batch [1460]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.099001,	
2017-06-26 20:10:58,015 Epoch[36] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.099036,	
2017-06-26 20:11:03,368 Epoch[36] Batch [1480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098984,	
2017-06-26 20:11:06,551 Epoch[36] Train-FCNLogLoss=0.098907
2017-06-26 20:11:06,551 Epoch[36] Time cost=795.271
2017-06-26 20:11:07,484 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0037.params"
2017-06-26 20:11:09,289 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0037.states"
2017-06-26 20:11:15,195 Epoch[37] Batch [10]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.085252,	
2017-06-26 20:11:20,510 Epoch[37] Batch [20]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089772,	
2017-06-26 20:11:25,846 Epoch[37] Batch [30]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091651,	
2017-06-26 20:11:31,207 Epoch[37] Batch [40]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094244,	
2017-06-26 20:11:36,500 Epoch[37] Batch [50]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092056,	
2017-06-26 20:11:41,880 Epoch[37] Batch [60]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093802,	
2017-06-26 20:11:47,227 Epoch[37] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094388,	
2017-06-26 20:11:52,575 Epoch[37] Batch [80]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095424,	
2017-06-26 20:11:57,887 Epoch[37] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095749,	
2017-06-26 20:12:03,259 Epoch[37] Batch [100]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095772,	
2017-06-26 20:12:08,582 Epoch[37] Batch [110]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096212,	
2017-06-26 20:12:13,933 Epoch[37] Batch [120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096262,	
2017-06-26 20:12:19,240 Epoch[37] Batch [130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096456,	
2017-06-26 20:12:24,560 Epoch[37] Batch [140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096149,	
2017-06-26 20:12:29,907 Epoch[37] Batch [150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096014,	
2017-06-26 20:12:35,263 Epoch[37] Batch [160]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096260,	
2017-06-26 20:12:40,642 Epoch[37] Batch [170]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096578,	
2017-06-26 20:12:45,965 Epoch[37] Batch [180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096394,	
2017-06-26 20:12:51,321 Epoch[37] Batch [190]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096553,	
2017-06-26 20:12:56,631 Epoch[37] Batch [200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096722,	
2017-06-26 20:13:02,013 Epoch[37] Batch [210]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096249,	
2017-06-26 20:13:07,346 Epoch[37] Batch [220]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096565,	
2017-06-26 20:13:12,665 Epoch[37] Batch [230]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096636,	
2017-06-26 20:13:18,006 Epoch[37] Batch [240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097061,	
2017-06-26 20:13:23,371 Epoch[37] Batch [250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097295,	
2017-06-26 20:13:28,684 Epoch[37] Batch [260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097013,	
2017-06-26 20:13:34,027 Epoch[37] Batch [270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096668,	
2017-06-26 20:13:39,365 Epoch[37] Batch [280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096824,	
2017-06-26 20:13:44,708 Epoch[37] Batch [290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097082,	
2017-06-26 20:13:50,030 Epoch[37] Batch [300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096979,	
2017-06-26 20:13:55,351 Epoch[37] Batch [310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096837,	
2017-06-26 20:14:00,661 Epoch[37] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097272,	
2017-06-26 20:14:06,001 Epoch[37] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097264,	
2017-06-26 20:14:11,373 Epoch[37] Batch [340]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097531,	
2017-06-26 20:14:16,688 Epoch[37] Batch [350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097772,	
2017-06-26 20:14:22,015 Epoch[37] Batch [360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098091,	
2017-06-26 20:14:27,339 Epoch[37] Batch [370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097856,	
2017-06-26 20:14:32,676 Epoch[37] Batch [380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097976,	
2017-06-26 20:14:37,961 Epoch[37] Batch [390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097940,	
2017-06-26 20:14:43,367 Epoch[37] Batch [400]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.097734,	
2017-06-26 20:14:48,694 Epoch[37] Batch [410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097849,	
2017-06-26 20:14:54,017 Epoch[37] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098204,	
2017-06-26 20:14:59,326 Epoch[37] Batch [430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098114,	
2017-06-26 20:15:04,692 Epoch[37] Batch [440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098743,	
2017-06-26 20:15:09,996 Epoch[37] Batch [450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098534,	
2017-06-26 20:15:15,357 Epoch[37] Batch [460]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098538,	
2017-06-26 20:15:20,671 Epoch[37] Batch [470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098454,	
2017-06-26 20:15:26,005 Epoch[37] Batch [480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098434,	
2017-06-26 20:15:31,324 Epoch[37] Batch [490]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098465,	
2017-06-26 20:15:36,678 Epoch[37] Batch [500]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098441,	
2017-06-26 20:15:41,979 Epoch[37] Batch [510]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098396,	
2017-06-26 20:15:47,306 Epoch[37] Batch [520]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098342,	
2017-06-26 20:15:52,687 Epoch[37] Batch [530]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098204,	
2017-06-26 20:15:57,976 Epoch[37] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098224,	
2017-06-26 20:16:03,368 Epoch[37] Batch [550]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098124,	
2017-06-26 20:16:08,636 Epoch[37] Batch [560]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.098217,	
2017-06-26 20:16:13,988 Epoch[37] Batch [570]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098339,	
2017-06-26 20:16:19,382 Epoch[37] Batch [580]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098193,	
2017-06-26 20:16:24,788 Epoch[37] Batch [590]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.098263,	
2017-06-26 20:16:30,094 Epoch[37] Batch [600]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098256,	
2017-06-26 20:16:35,470 Epoch[37] Batch [610]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098139,	
2017-06-26 20:16:40,784 Epoch[37] Batch [620]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098330,	
2017-06-26 20:16:46,100 Epoch[37] Batch [630]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098164,	
2017-06-26 20:16:51,427 Epoch[37] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098095,	
2017-06-26 20:16:56,918 Epoch[37] Batch [650]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.098114,	
2017-06-26 20:17:02,317 Epoch[37] Batch [660]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098117,	
2017-06-26 20:17:07,690 Epoch[37] Batch [670]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098065,	
2017-06-26 20:17:12,970 Epoch[37] Batch [680]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098087,	
2017-06-26 20:17:18,334 Epoch[37] Batch [690]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098171,	
2017-06-26 20:17:23,668 Epoch[37] Batch [700]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098137,	
2017-06-26 20:17:29,186 Epoch[37] Batch [710]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.098079,	
2017-06-26 20:17:34,479 Epoch[37] Batch [720]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098116,	
2017-06-26 20:17:39,906 Epoch[37] Batch [730]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098188,	
2017-06-26 20:17:45,270 Epoch[37] Batch [740]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097998,	
2017-06-26 20:17:50,604 Epoch[37] Batch [750]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097876,	
2017-06-26 20:17:56,123 Epoch[37] Batch [760]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.097898,	
2017-06-26 20:18:01,429 Epoch[37] Batch [770]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097960,	
2017-06-26 20:18:06,921 Epoch[37] Batch [780]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098028,	
2017-06-26 20:18:12,230 Epoch[37] Batch [790]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098089,	
2017-06-26 20:18:17,683 Epoch[37] Batch [800]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098078,	
2017-06-26 20:18:23,070 Epoch[37] Batch [810]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098018,	
2017-06-26 20:18:28,367 Epoch[37] Batch [820]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097918,	
2017-06-26 20:18:33,740 Epoch[37] Batch [830]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097928,	
2017-06-26 20:18:39,213 Epoch[37] Batch [840]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.097797,	
2017-06-26 20:18:44,584 Epoch[37] Batch [850]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097824,	
2017-06-26 20:18:49,901 Epoch[37] Batch [860]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097842,	
2017-06-26 20:18:55,199 Epoch[37] Batch [870]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097926,	
2017-06-26 20:19:00,582 Epoch[37] Batch [880]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098032,	
2017-06-26 20:19:05,955 Epoch[37] Batch [890]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098088,	
2017-06-26 20:19:11,300 Epoch[37] Batch [900]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098009,	
2017-06-26 20:19:16,689 Epoch[37] Batch [910]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097955,	
2017-06-26 20:19:22,109 Epoch[37] Batch [920]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098011,	
2017-06-26 20:19:27,464 Epoch[37] Batch [930]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098042,	
2017-06-26 20:19:32,775 Epoch[37] Batch [940]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098020,	
2017-06-26 20:19:38,103 Epoch[37] Batch [950]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097924,	
2017-06-26 20:19:43,479 Epoch[37] Batch [960]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097883,	
2017-06-26 20:19:48,914 Epoch[37] Batch [970]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.097877,	
2017-06-26 20:19:54,196 Epoch[37] Batch [980]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097776,	
2017-06-26 20:19:59,556 Epoch[37] Batch [990]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097739,	
2017-06-26 20:20:04,891 Epoch[37] Batch [1000]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097833,	
2017-06-26 20:20:10,241 Epoch[37] Batch [1010]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097894,	
2017-06-26 20:20:15,570 Epoch[37] Batch [1020]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097875,	
2017-06-26 20:20:20,879 Epoch[37] Batch [1030]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097977,	
2017-06-26 20:20:26,308 Epoch[37] Batch [1040]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.097876,	
2017-06-26 20:20:31,697 Epoch[37] Batch [1050]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097932,	
2017-06-26 20:20:37,004 Epoch[37] Batch [1060]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097931,	
2017-06-26 20:20:42,361 Epoch[37] Batch [1070]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097928,	
2017-06-26 20:20:47,691 Epoch[37] Batch [1080]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097924,	
2017-06-26 20:20:53,030 Epoch[37] Batch [1090]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-26 20:20:58,543 Epoch[37] Batch [1100]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.098019,	
2017-06-26 20:21:03,845 Epoch[37] Batch [1110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098064,	
2017-06-26 20:21:09,187 Epoch[37] Batch [1120]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098032,	
2017-06-26 20:21:14,496 Epoch[37] Batch [1130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098019,	
2017-06-26 20:21:19,873 Epoch[37] Batch [1140]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098059,	
2017-06-26 20:21:25,238 Epoch[37] Batch [1150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098045,	
2017-06-26 20:21:30,558 Epoch[37] Batch [1160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098008,	
2017-06-26 20:21:35,913 Epoch[37] Batch [1170]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097965,	
2017-06-26 20:21:41,214 Epoch[37] Batch [1180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097964,	
2017-06-26 20:21:46,560 Epoch[37] Batch [1190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097989,	
2017-06-26 20:21:51,918 Epoch[37] Batch [1200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097979,	
2017-06-26 20:21:57,289 Epoch[37] Batch [1210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097940,	
2017-06-26 20:22:02,575 Epoch[37] Batch [1220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097947,	
2017-06-26 20:22:07,896 Epoch[37] Batch [1230]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097889,	
2017-06-26 20:22:13,237 Epoch[37] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097856,	
2017-06-26 20:22:18,569 Epoch[37] Batch [1250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097865,	
2017-06-26 20:22:23,941 Epoch[37] Batch [1260]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097879,	
2017-06-26 20:22:29,291 Epoch[37] Batch [1270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097805,	
2017-06-26 20:22:34,590 Epoch[37] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097829,	
2017-06-26 20:22:39,941 Epoch[37] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097840,	
2017-06-26 20:22:45,279 Epoch[37] Batch [1300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097801,	
2017-06-26 20:22:50,678 Epoch[37] Batch [1310]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097892,	
2017-06-26 20:22:56,004 Epoch[37] Batch [1320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097901,	
2017-06-26 20:23:01,336 Epoch[37] Batch [1330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097938,	
2017-06-26 20:23:06,629 Epoch[37] Batch [1340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097999,	
2017-06-26 20:23:11,982 Epoch[37] Batch [1350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097919,	
2017-06-26 20:23:17,316 Epoch[37] Batch [1360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-26 20:23:21,920 Epoch[37] Batch [1370]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.097832,	
2017-06-26 20:23:27,242 Epoch[37] Batch [1380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097866,	
2017-06-26 20:23:32,605 Epoch[37] Batch [1390]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097854,	
2017-06-26 20:23:37,965 Epoch[37] Batch [1400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097871,	
2017-06-26 20:23:43,290 Epoch[37] Batch [1410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097895,	
2017-06-26 20:23:48,615 Epoch[37] Batch [1420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097862,	
2017-06-26 20:23:53,928 Epoch[37] Batch [1430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097787,	
2017-06-26 20:23:59,273 Epoch[37] Batch [1440]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097636,	
2017-06-26 20:24:04,621 Epoch[37] Batch [1450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097594,	
2017-06-26 20:24:09,980 Epoch[37] Batch [1460]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097551,	
2017-06-26 20:24:15,329 Epoch[37] Batch [1470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097523,	
2017-06-26 20:24:20,628 Epoch[37] Batch [1480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097545,	
2017-06-26 20:24:23,855 Epoch[37] Train-FCNLogLoss=0.097556
2017-06-26 20:24:23,855 Epoch[37] Time cost=794.566
2017-06-26 20:24:24,768 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0038.params"
2017-06-26 20:24:26,754 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0038.states"
2017-06-26 20:24:32,739 Epoch[38] Batch [10]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.102376,	
2017-06-26 20:24:38,089 Epoch[38] Batch [20]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096697,	
2017-06-26 20:24:43,441 Epoch[38] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096656,	
2017-06-26 20:24:48,765 Epoch[38] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098844,	
2017-06-26 20:24:54,123 Epoch[38] Batch [50]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096099,	
2017-06-26 20:24:59,473 Epoch[38] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097598,	
2017-06-26 20:25:04,800 Epoch[38] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096498,	
2017-06-26 20:25:10,147 Epoch[38] Batch [80]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095719,	
2017-06-26 20:25:15,494 Epoch[38] Batch [90]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095676,	
2017-06-26 20:25:20,876 Epoch[38] Batch [100]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095670,	
2017-06-26 20:25:26,234 Epoch[38] Batch [110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096853,	
2017-06-26 20:25:31,528 Epoch[38] Batch [120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096948,	
2017-06-26 20:25:36,882 Epoch[38] Batch [130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097494,	
2017-06-26 20:25:42,225 Epoch[38] Batch [140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097348,	
2017-06-26 20:25:47,525 Epoch[38] Batch [150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097715,	
2017-06-26 20:25:52,885 Epoch[38] Batch [160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098457,	
2017-06-26 20:25:58,240 Epoch[38] Batch [170]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098661,	
2017-06-26 20:26:03,687 Epoch[38] Batch [180]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098251,	
2017-06-26 20:26:09,052 Epoch[38] Batch [190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098199,	
2017-06-26 20:26:14,392 Epoch[38] Batch [200]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098200,	
2017-06-26 20:26:19,717 Epoch[38] Batch [210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098072,	
2017-06-26 20:26:25,126 Epoch[38] Batch [220]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.097945,	
2017-06-26 20:26:30,494 Epoch[38] Batch [230]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098136,	
2017-06-26 20:26:35,831 Epoch[38] Batch [240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097949,	
2017-06-26 20:26:41,176 Epoch[38] Batch [250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098015,	
2017-06-26 20:26:46,625 Epoch[38] Batch [260]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098501,	
2017-06-26 20:26:51,989 Epoch[38] Batch [270]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098397,	
2017-06-26 20:26:57,385 Epoch[38] Batch [280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098366,	
2017-06-26 20:27:02,738 Epoch[38] Batch [290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098877,	
2017-06-26 20:27:08,213 Epoch[38] Batch [300]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.098597,	
2017-06-26 20:27:13,573 Epoch[38] Batch [310]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099213,	
2017-06-26 20:27:18,891 Epoch[38] Batch [320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099113,	
2017-06-26 20:27:24,267 Epoch[38] Batch [330]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098765,	
2017-06-26 20:27:29,616 Epoch[38] Batch [340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098484,	
2017-06-26 20:27:34,975 Epoch[38] Batch [350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098368,	
2017-06-26 20:27:40,344 Epoch[38] Batch [360]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098273,	
2017-06-26 20:27:45,800 Epoch[38] Batch [370]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.098385,	
2017-06-26 20:27:51,150 Epoch[38] Batch [380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098700,	
2017-06-26 20:27:56,526 Epoch[38] Batch [390]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098840,	
2017-06-26 20:28:01,955 Epoch[38] Batch [400]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098909,	
2017-06-26 20:28:07,367 Epoch[38] Batch [410]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.098838,	
2017-06-26 20:28:12,711 Epoch[38] Batch [420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098916,	
2017-06-26 20:28:18,031 Epoch[38] Batch [430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098826,	
2017-06-26 20:28:23,549 Epoch[38] Batch [440]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.098867,	
2017-06-26 20:28:28,903 Epoch[38] Batch [450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.099130,	
2017-06-26 20:28:34,232 Epoch[38] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099258,	
2017-06-26 20:28:39,578 Epoch[38] Batch [470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099343,	
2017-06-26 20:28:44,942 Epoch[38] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099235,	
2017-06-26 20:28:50,274 Epoch[38] Batch [490]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099133,	
2017-06-26 20:28:55,598 Epoch[38] Batch [500]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099218,	
2017-06-26 20:29:01,043 Epoch[38] Batch [510]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.098972,	
2017-06-26 20:29:06,397 Epoch[38] Batch [520]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098934,	
2017-06-26 20:29:11,769 Epoch[38] Batch [530]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098940,	
2017-06-26 20:29:17,164 Epoch[38] Batch [540]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098863,	
2017-06-26 20:29:22,494 Epoch[38] Batch [550]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098729,	
2017-06-26 20:29:27,821 Epoch[38] Batch [560]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098917,	
2017-06-26 20:29:33,149 Epoch[38] Batch [570]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099036,	
2017-06-26 20:29:38,535 Epoch[38] Batch [580]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.099118,	
2017-06-26 20:29:43,824 Epoch[38] Batch [590]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099016,	
2017-06-26 20:29:49,278 Epoch[38] Batch [600]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.098918,	
2017-06-26 20:29:54,648 Epoch[38] Batch [610]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098990,	
2017-06-26 20:30:00,000 Epoch[38] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.099161,	
2017-06-26 20:30:05,298 Epoch[38] Batch [630]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.099124,	
2017-06-26 20:30:10,622 Epoch[38] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099124,	
2017-06-26 20:30:15,967 Epoch[38] Batch [650]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099100,	
2017-06-26 20:30:21,302 Epoch[38] Batch [660]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098950,	
2017-06-26 20:30:26,627 Epoch[38] Batch [670]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098763,	
2017-06-26 20:30:31,982 Epoch[38] Batch [680]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098782,	
2017-06-26 20:30:37,321 Epoch[38] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098715,	
2017-06-26 20:30:42,666 Epoch[38] Batch [700]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098758,	
2017-06-26 20:30:48,005 Epoch[38] Batch [710]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098753,	
2017-06-26 20:30:53,350 Epoch[38] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098797,	
2017-06-26 20:30:58,674 Epoch[38] Batch [730]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098496,	
2017-06-26 20:31:04,020 Epoch[38] Batch [740]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098279,	
2017-06-26 20:31:09,360 Epoch[38] Batch [750]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098187,	
2017-06-26 20:31:14,705 Epoch[38] Batch [760]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098093,	
2017-06-26 20:31:20,016 Epoch[38] Batch [770]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098070,	
2017-06-26 20:31:25,355 Epoch[38] Batch [780]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098196,	
2017-06-26 20:31:30,704 Epoch[38] Batch [790]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098310,	
2017-06-26 20:31:36,036 Epoch[38] Batch [800]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098552,	
2017-06-26 20:31:41,410 Epoch[38] Batch [810]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098799,	
2017-06-26 20:31:46,729 Epoch[38] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098842,	
2017-06-26 20:31:52,075 Epoch[38] Batch [830]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098802,	
2017-06-26 20:31:57,466 Epoch[38] Batch [840]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098776,	
2017-06-26 20:32:02,799 Epoch[38] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098717,	
2017-06-26 20:32:08,172 Epoch[38] Batch [860]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098740,	
2017-06-26 20:32:13,464 Epoch[38] Batch [870]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098660,	
2017-06-26 20:32:18,794 Epoch[38] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098590,	
2017-06-26 20:32:24,119 Epoch[38] Batch [890]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098525,	
2017-06-26 20:32:29,483 Epoch[38] Batch [900]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098486,	
2017-06-26 20:32:34,822 Epoch[38] Batch [910]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098403,	
2017-06-26 20:32:40,140 Epoch[38] Batch [920]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098365,	
2017-06-26 20:32:45,504 Epoch[38] Batch [930]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098282,	
2017-06-26 20:32:50,841 Epoch[38] Batch [940]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098306,	
2017-06-26 20:32:56,173 Epoch[38] Batch [950]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098323,	
2017-06-26 20:33:01,507 Epoch[38] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098332,	
2017-06-26 20:33:06,852 Epoch[38] Batch [970]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098321,	
2017-06-26 20:33:12,218 Epoch[38] Batch [980]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098221,	
2017-06-26 20:33:17,554 Epoch[38] Batch [990]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098232,	
2017-06-26 20:33:22,916 Epoch[38] Batch [1000]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098151,	
2017-06-26 20:33:28,226 Epoch[38] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098172,	
2017-06-26 20:33:33,571 Epoch[38] Batch [1020]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098246,	
2017-06-26 20:33:38,929 Epoch[38] Batch [1030]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098257,	
2017-06-26 20:33:44,255 Epoch[38] Batch [1040]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098332,	
2017-06-26 20:33:49,617 Epoch[38] Batch [1050]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098371,	
2017-06-26 20:33:54,953 Epoch[38] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098334,	
2017-06-26 20:34:00,271 Epoch[38] Batch [1070]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098277,	
2017-06-26 20:34:05,608 Epoch[38] Batch [1080]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098214,	
2017-06-26 20:34:10,968 Epoch[38] Batch [1090]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098176,	
2017-06-26 20:34:16,301 Epoch[38] Batch [1100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098187,	
2017-06-26 20:34:21,613 Epoch[38] Batch [1110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098368,	
2017-06-26 20:34:26,940 Epoch[38] Batch [1120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098369,	
2017-06-26 20:34:32,326 Epoch[38] Batch [1130]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098411,	
2017-06-26 20:34:37,636 Epoch[38] Batch [1140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098470,	
2017-06-26 20:34:42,988 Epoch[38] Batch [1150]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098409,	
2017-06-26 20:34:48,326 Epoch[38] Batch [1160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098333,	
2017-06-26 20:34:53,698 Epoch[38] Batch [1170]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098450,	
2017-06-26 20:34:59,076 Epoch[38] Batch [1180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098522,	
2017-06-26 20:35:04,433 Epoch[38] Batch [1190]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098547,	
2017-06-26 20:35:09,835 Epoch[38] Batch [1200]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.098499,	
2017-06-26 20:35:15,366 Epoch[38] Batch [1210]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098456,	
2017-06-26 20:35:20,681 Epoch[38] Batch [1220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098432,	
2017-06-26 20:35:26,042 Epoch[38] Batch [1230]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098412,	
2017-06-26 20:35:31,359 Epoch[38] Batch [1240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098268,	
2017-06-26 20:35:36,769 Epoch[38] Batch [1250]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098214,	
2017-06-26 20:35:42,132 Epoch[38] Batch [1260]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098167,	
2017-06-26 20:35:47,486 Epoch[38] Batch [1270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098080,	
2017-06-26 20:35:52,879 Epoch[38] Batch [1280]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098083,	
2017-06-26 20:35:58,234 Epoch[38] Batch [1290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098043,	
2017-06-26 20:36:03,582 Epoch[38] Batch [1300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098049,	
2017-06-26 20:36:09,059 Epoch[38] Batch [1310]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.097978,	
2017-06-26 20:36:14,435 Epoch[38] Batch [1320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097836,	
2017-06-26 20:36:19,774 Epoch[38] Batch [1330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097898,	
2017-06-26 20:36:25,183 Epoch[38] Batch [1340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.097881,	
2017-06-26 20:36:30,501 Epoch[38] Batch [1350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097888,	
2017-06-26 20:36:35,867 Epoch[38] Batch [1360]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097855,	
2017-06-26 20:36:40,874 Epoch[38] Batch [1370]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.097805,	
2017-06-26 20:36:46,228 Epoch[38] Batch [1380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097806,	
2017-06-26 20:36:51,528 Epoch[38] Batch [1390]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097800,	
2017-06-26 20:36:56,856 Epoch[38] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097847,	
2017-06-26 20:37:02,255 Epoch[38] Batch [1410]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097825,	
2017-06-26 20:37:07,511 Epoch[38] Batch [1420]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097906,	
2017-06-26 20:37:12,858 Epoch[38] Batch [1430]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097965,	
2017-06-26 20:37:18,221 Epoch[38] Batch [1440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097834,	
2017-06-26 20:37:23,523 Epoch[38] Batch [1450]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097851,	
2017-06-26 20:37:28,882 Epoch[38] Batch [1460]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-26 20:37:34,195 Epoch[38] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098156,	
2017-06-26 20:37:39,542 Epoch[38] Batch [1480]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098235,	
2017-06-26 20:37:42,843 Epoch[38] Train-FCNLogLoss=0.098364
2017-06-26 20:37:42,843 Epoch[38] Time cost=796.089
2017-06-26 20:37:43,625 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0039.params"
2017-06-26 20:37:47,278 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0039.states"
2017-06-26 20:37:53,254 Epoch[39] Batch [10]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.098077,	
2017-06-26 20:37:58,563 Epoch[39] Batch [20]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.103674,	
2017-06-26 20:38:03,863 Epoch[39] Batch [30]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.102845,	
2017-06-26 20:38:09,224 Epoch[39] Batch [40]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.101512,	
2017-06-26 20:38:14,578 Epoch[39] Batch [50]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100893,	
2017-06-26 20:38:19,917 Epoch[39] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.099346,	
2017-06-26 20:38:25,267 Epoch[39] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099213,	
2017-06-26 20:38:30,575 Epoch[39] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098430,	
2017-06-26 20:38:35,887 Epoch[39] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098155,	
2017-06-26 20:38:41,220 Epoch[39] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098151,	
2017-06-26 20:38:46,517 Epoch[39] Batch [110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097935,	
2017-06-26 20:38:51,870 Epoch[39] Batch [120]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098554,	
2017-06-26 20:38:57,223 Epoch[39] Batch [130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098314,	
2017-06-26 20:39:02,649 Epoch[39] Batch [140]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098176,	
2017-06-26 20:39:07,903 Epoch[39] Batch [150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097554,	
2017-06-26 20:39:13,231 Epoch[39] Batch [160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097554,	
2017-06-26 20:39:18,549 Epoch[39] Batch [170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097387,	
2017-06-26 20:39:23,881 Epoch[39] Batch [180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096992,	
2017-06-26 20:39:29,262 Epoch[39] Batch [190]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096529,	
2017-06-26 20:39:34,538 Epoch[39] Batch [200]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096698,	
2017-06-26 20:39:39,853 Epoch[39] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096918,	
2017-06-26 20:39:45,245 Epoch[39] Batch [220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.096868,	
2017-06-26 20:39:50,527 Epoch[39] Batch [230]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096786,	
2017-06-26 20:39:55,824 Epoch[39] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096899,	
2017-06-26 20:40:01,169 Epoch[39] Batch [250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096773,	
2017-06-26 20:40:06,487 Epoch[39] Batch [260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096480,	
2017-06-26 20:40:11,813 Epoch[39] Batch [270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096971,	
2017-06-26 20:40:17,207 Epoch[39] Batch [280]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097273,	
2017-06-26 20:40:22,473 Epoch[39] Batch [290]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.097387,	
2017-06-26 20:40:27,925 Epoch[39] Batch [300]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.097736,	
2017-06-26 20:40:33,180 Epoch[39] Batch [310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097940,	
2017-06-26 20:40:38,447 Epoch[39] Batch [320]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.097887,	
2017-06-26 20:40:43,831 Epoch[39] Batch [330]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.097872,	
2017-06-26 20:40:49,195 Epoch[39] Batch [340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098105,	
2017-06-26 20:40:54,539 Epoch[39] Batch [350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098068,	
2017-06-26 20:40:59,800 Epoch[39] Batch [360]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.098056,	
2017-06-26 20:41:05,118 Epoch[39] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099672,	
2017-06-26 20:41:10,444 Epoch[39] Batch [380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.102211,	
2017-06-26 20:41:15,764 Epoch[39] Batch [390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.103200,	
2017-06-26 20:41:21,081 Epoch[39] Batch [400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104257,	
2017-06-26 20:41:26,459 Epoch[39] Batch [410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.105671,	
2017-06-26 20:41:31,730 Epoch[39] Batch [420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.106575,	
2017-06-26 20:41:37,071 Epoch[39] Batch [430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.109545,	
2017-06-26 20:41:42,458 Epoch[39] Batch [440]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.111783,	
2017-06-26 20:41:47,703 Epoch[39] Batch [450]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.113353,	
2017-06-26 20:41:53,031 Epoch[39] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117343,	
2017-06-26 20:41:58,374 Epoch[39] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119648,	
2017-06-26 20:42:03,691 Epoch[39] Batch [480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.122749,	
2017-06-26 20:42:09,020 Epoch[39] Batch [490]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124075,	
2017-06-26 20:42:14,391 Epoch[39] Batch [500]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.124585,	
2017-06-26 20:42:19,679 Epoch[39] Batch [510]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125240,	
2017-06-26 20:42:25,012 Epoch[39] Batch [520]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125454,	
2017-06-26 20:42:30,359 Epoch[39] Batch [530]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.126077,	
2017-06-26 20:42:35,702 Epoch[39] Batch [540]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.127175,	
2017-06-26 20:42:40,979 Epoch[39] Batch [550]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.128551,	
2017-06-26 20:42:46,406 Epoch[39] Batch [560]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.128627,	
2017-06-26 20:42:51,636 Epoch[39] Batch [570]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.128819,	
2017-06-26 20:42:56,977 Epoch[39] Batch [580]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128836,	
2017-06-26 20:43:02,319 Epoch[39] Batch [590]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128799,	
2017-06-26 20:43:07,698 Epoch[39] Batch [600]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.129120,	
2017-06-26 20:43:12,967 Epoch[39] Batch [610]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.129147,	
2017-06-26 20:43:18,289 Epoch[39] Batch [620]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129358,	
2017-06-26 20:43:23,630 Epoch[39] Batch [630]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128985,	
2017-06-26 20:43:28,972 Epoch[39] Batch [640]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128505,	
2017-06-26 20:43:34,315 Epoch[39] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128403,	
2017-06-26 20:43:39,620 Epoch[39] Batch [660]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.128152,	
2017-06-26 20:43:44,956 Epoch[39] Batch [670]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.127934,	
2017-06-26 20:43:50,342 Epoch[39] Batch [680]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.127912,	
2017-06-26 20:43:55,634 Epoch[39] Batch [690]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.127540,	
2017-06-26 20:44:00,941 Epoch[39] Batch [700]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.127216,	
2017-06-26 20:44:06,312 Epoch[39] Batch [710]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126916,	
2017-06-26 20:44:11,625 Epoch[39] Batch [720]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.126679,	
2017-06-26 20:44:16,960 Epoch[39] Batch [730]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126306,	
2017-06-26 20:44:22,294 Epoch[39] Batch [740]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126035,	
2017-06-26 20:44:27,704 Epoch[39] Batch [750]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.125727,	
2017-06-26 20:44:33,019 Epoch[39] Batch [760]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125425,	
2017-06-26 20:44:38,277 Epoch[39] Batch [770]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125142,	
2017-06-26 20:44:43,603 Epoch[39] Batch [780]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124795,	
2017-06-26 20:44:48,940 Epoch[39] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124498,	
2017-06-26 20:44:54,362 Epoch[39] Batch [800]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.124272,	
2017-06-26 20:44:59,866 Epoch[39] Batch [810]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.124365,	
2017-06-26 20:45:05,200 Epoch[39] Batch [820]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124201,	
2017-06-26 20:45:10,550 Epoch[39] Batch [830]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.123940,	
2017-06-26 20:45:15,853 Epoch[39] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124072,	
2017-06-26 20:45:21,205 Epoch[39] Batch [850]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.123912,	
2017-06-26 20:45:26,533 Epoch[39] Batch [860]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.123792,	
2017-06-26 20:45:31,921 Epoch[39] Batch [870]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.123658,	
2017-06-26 20:45:37,319 Epoch[39] Batch [880]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.123487,	
2017-06-26 20:45:42,599 Epoch[39] Batch [890]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.123332,	
2017-06-26 20:45:48,057 Epoch[39] Batch [900]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.123156,	
2017-06-26 20:45:53,431 Epoch[39] Batch [910]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.123032,	
2017-06-26 20:45:58,667 Epoch[39] Batch [920]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122887,	
2017-06-26 20:46:04,025 Epoch[39] Batch [930]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.122770,	
2017-06-26 20:46:09,509 Epoch[39] Batch [940]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.122596,	
2017-06-26 20:46:14,925 Epoch[39] Batch [950]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.122438,	
2017-06-26 20:46:20,349 Epoch[39] Batch [960]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.122387,	
2017-06-26 20:46:25,676 Epoch[39] Batch [970]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122471,	
2017-06-26 20:46:30,963 Epoch[39] Batch [980]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122363,	
2017-06-26 20:46:36,442 Epoch[39] Batch [990]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.122380,	
2017-06-26 20:46:41,741 Epoch[39] Batch [1000]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.122213,	
2017-06-26 20:46:47,055 Epoch[39] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121934,	
2017-06-26 20:46:52,388 Epoch[39] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121794,	
2017-06-26 20:46:57,701 Epoch[39] Batch [1030]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121572,	
2017-06-26 20:47:03,080 Epoch[39] Batch [1040]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121448,	
2017-06-26 20:47:08,483 Epoch[39] Batch [1050]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.121284,	
2017-06-26 20:47:13,790 Epoch[39] Batch [1060]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.120970,	
2017-06-26 20:47:19,793 Epoch[39] Batch [1070]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.120821,	
2017-06-26 20:47:25,169 Epoch[39] Batch [1080]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.120620,	
2017-06-26 20:47:30,467 Epoch[39] Batch [1090]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.120408,	
2017-06-26 20:47:35,796 Epoch[39] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120215,	
2017-06-26 20:47:41,147 Epoch[39] Batch [1110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.120028,	
2017-06-26 20:47:46,479 Epoch[39] Batch [1120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119743,	
2017-06-26 20:47:51,848 Epoch[39] Batch [1130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119518,	
2017-06-26 20:47:57,192 Epoch[39] Batch [1140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119289,	
2017-06-26 20:48:02,499 Epoch[39] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119127,	
2017-06-26 20:48:07,857 Epoch[39] Batch [1160]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118976,	
2017-06-26 20:48:13,191 Epoch[39] Batch [1170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118784,	
2017-06-26 20:48:18,531 Epoch[39] Batch [1180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118602,	
2017-06-26 20:48:23,864 Epoch[39] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118483,	
2017-06-26 20:48:29,200 Epoch[39] Batch [1200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118371,	
2017-06-26 20:48:34,547 Epoch[39] Batch [1210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118215,	
2017-06-26 20:48:39,867 Epoch[39] Batch [1220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118054,	
2017-06-26 20:48:45,214 Epoch[39] Batch [1230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118019,	
2017-06-26 20:48:50,557 Epoch[39] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117869,	
2017-06-26 20:48:55,970 Epoch[39] Batch [1250]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.117715,	
2017-06-26 20:49:01,260 Epoch[39] Batch [1260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.117681,	
2017-06-26 20:49:06,564 Epoch[39] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117549,	
2017-06-26 20:49:11,945 Epoch[39] Batch [1280]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.117480,	
2017-06-26 20:49:17,224 Epoch[39] Batch [1290]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.117676,	
2017-06-26 20:49:22,627 Epoch[39] Batch [1300]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.117834,	
2017-06-26 20:49:27,973 Epoch[39] Batch [1310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118037,	
2017-06-26 20:49:33,313 Epoch[39] Batch [1320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118005,	
2017-06-26 20:49:38,644 Epoch[39] Batch [1330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117974,	
2017-06-26 20:49:43,946 Epoch[39] Batch [1340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117975,	
2017-06-26 20:49:49,338 Epoch[39] Batch [1350]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117857,	
2017-06-26 20:49:54,091 Epoch[39] Batch [1360]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.117737,	
2017-06-26 20:49:59,436 Epoch[39] Batch [1370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117650,	
2017-06-26 20:50:04,975 Epoch[39] Batch [1380]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.117638,	
2017-06-26 20:50:10,369 Epoch[39] Batch [1390]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117685,	
2017-06-26 20:50:16,907 Epoch[39] Batch [1400]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.117731,	
2017-06-26 20:50:21,726 Epoch[39] Batch [1410]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.117631,	
2017-06-26 20:50:26,788 Epoch[39] Batch [1420]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.117480,	
2017-06-26 20:50:32,072 Epoch[39] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.117407,	
2017-06-26 20:50:37,656 Epoch[39] Batch [1440]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.117460,	
2017-06-26 20:50:42,814 Epoch[39] Batch [1450]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.117522,	
2017-06-26 20:50:48,226 Epoch[39] Batch [1460]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.117486,	
2017-06-26 20:50:54,672 Epoch[39] Batch [1470]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.117452,	
2017-06-26 20:51:00,033 Epoch[39] Batch [1480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117331,	
2017-06-26 20:51:04,777 Epoch[39] Train-FCNLogLoss=0.117238
2017-06-26 20:51:04,777 Epoch[39] Time cost=797.499
2017-06-26 20:51:05,573 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0040.params"
2017-06-26 20:51:10,236 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0040.states"
2017-06-26 20:51:18,132 Epoch[40] Batch [10]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.103673,	
2017-06-26 20:51:24,459 Epoch[40] Batch [20]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.101369,	
2017-06-26 20:51:29,597 Epoch[40] Batch [30]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.097949,	
2017-06-26 20:51:34,925 Epoch[40] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098260,	
2017-06-26 20:51:40,431 Epoch[40] Batch [50]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.098990,	
2017-06-26 20:51:46,746 Epoch[40] Batch [60]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.098940,	
2017-06-26 20:51:51,781 Epoch[40] Batch [70]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.098408,	
2017-06-26 20:51:57,051 Epoch[40] Batch [80]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097306,	
2017-06-26 20:52:03,220 Epoch[40] Batch [90]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.096843,	
2017-06-26 20:52:09,270 Epoch[40] Batch [100]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097943,	
2017-06-26 20:52:14,555 Epoch[40] Batch [110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097969,	
2017-06-26 20:52:19,891 Epoch[40] Batch [120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097839,	
2017-06-26 20:52:25,234 Epoch[40] Batch [130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097550,	
2017-06-26 20:52:30,551 Epoch[40] Batch [140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098012,	
2017-06-26 20:52:35,917 Epoch[40] Batch [150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097972,	
2017-06-26 20:52:41,193 Epoch[40] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097977,	
2017-06-26 20:52:46,590 Epoch[40] Batch [170]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097623,	
2017-06-26 20:52:51,856 Epoch[40] Batch [180]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.097631,	
2017-06-26 20:52:57,187 Epoch[40] Batch [190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097751,	
2017-06-26 20:53:02,538 Epoch[40] Batch [200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097756,	
2017-06-26 20:53:07,890 Epoch[40] Batch [210]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098268,	
2017-06-26 20:53:13,453 Epoch[40] Batch [220]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.098073,	
2017-06-26 20:53:18,778 Epoch[40] Batch [230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098339,	
2017-06-26 20:53:24,117 Epoch[40] Batch [240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098835,	
2017-06-26 20:53:29,539 Epoch[40] Batch [250]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.099151,	
2017-06-26 20:53:34,993 Epoch[40] Batch [260]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.099720,	
2017-06-26 20:53:40,358 Epoch[40] Batch [270]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099894,	
2017-06-26 20:53:45,666 Epoch[40] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.100136,	
2017-06-26 20:53:51,145 Epoch[40] Batch [290]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.099972,	
2017-06-26 20:53:56,595 Epoch[40] Batch [300]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.100131,	
2017-06-26 20:54:01,839 Epoch[40] Batch [310]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.100267,	
2017-06-26 20:54:07,306 Epoch[40] Batch [320]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.100253,	
2017-06-26 20:54:12,704 Epoch[40] Batch [330]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.099750,	
2017-06-26 20:54:18,046 Epoch[40] Batch [340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.099452,	
2017-06-26 20:54:23,411 Epoch[40] Batch [350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.099777,	
2017-06-26 20:54:28,679 Epoch[40] Batch [360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100127,	
2017-06-26 20:54:34,138 Epoch[40] Batch [370]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.100253,	
2017-06-26 20:54:39,571 Epoch[40] Batch [380]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.100073,	
2017-06-26 20:54:44,905 Epoch[40] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099941,	
2017-06-26 20:54:50,251 Epoch[40] Batch [400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099863,	
2017-06-26 20:54:55,629 Epoch[40] Batch [410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099914,	
2017-06-26 20:55:01,108 Epoch[40] Batch [420]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.099793,	
2017-06-26 20:55:06,393 Epoch[40] Batch [430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099886,	
2017-06-26 20:55:11,800 Epoch[40] Batch [440]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.099810,	
2017-06-26 20:55:17,165 Epoch[40] Batch [450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099619,	
2017-06-26 20:55:22,480 Epoch[40] Batch [460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099449,	
2017-06-26 20:55:27,861 Epoch[40] Batch [470]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099472,	
2017-06-26 20:55:33,202 Epoch[40] Batch [480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.099619,	
2017-06-26 20:55:38,619 Epoch[40] Batch [490]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.099828,	
2017-06-26 20:55:43,926 Epoch[40] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099882,	
2017-06-26 20:55:49,361 Epoch[40] Batch [510]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.100008,	
2017-06-26 20:55:53,537 Update[60000]: Change learning rate to 5.00000e-05
2017-06-26 20:55:54,581 Epoch[40] Batch [520]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099842,	
2017-06-26 20:55:59,966 Epoch[40] Batch [530]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.100087,	
2017-06-26 20:56:05,380 Epoch[40] Batch [540]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.100125,	
2017-06-26 20:56:10,679 Epoch[40] Batch [550]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100178,	
2017-06-26 20:56:16,008 Epoch[40] Batch [560]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100178,	
2017-06-26 20:56:21,430 Epoch[40] Batch [570]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.100352,	
2017-06-26 20:56:26,716 Epoch[40] Batch [580]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.100376,	
2017-06-26 20:56:32,053 Epoch[40] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100376,	
2017-06-26 20:56:37,399 Epoch[40] Batch [600]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100522,	
2017-06-26 20:56:42,746 Epoch[40] Batch [610]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.100552,	
2017-06-26 20:56:48,032 Epoch[40] Batch [620]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.100495,	
2017-06-26 20:56:53,387 Epoch[40] Batch [630]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100318,	
2017-06-26 20:56:58,757 Epoch[40] Batch [640]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100316,	
2017-06-26 20:57:04,074 Epoch[40] Batch [650]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100344,	
2017-06-26 20:57:09,435 Epoch[40] Batch [660]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100393,	
2017-06-26 20:57:14,754 Epoch[40] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100329,	
2017-06-26 20:57:20,088 Epoch[40] Batch [680]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100365,	
2017-06-26 20:57:25,538 Epoch[40] Batch [690]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.100195,	
2017-06-26 20:57:30,766 Epoch[40] Batch [700]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.100171,	
2017-06-26 20:57:36,103 Epoch[40] Batch [710]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100082,	
2017-06-26 20:57:41,456 Epoch[40] Batch [720]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100052,	
2017-06-26 20:57:46,791 Epoch[40] Batch [730]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099871,	
2017-06-26 20:57:52,116 Epoch[40] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099755,	
2017-06-26 20:57:57,461 Epoch[40] Batch [750]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099668,	
2017-06-26 20:58:02,789 Epoch[40] Batch [760]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099483,	
2017-06-26 20:58:08,147 Epoch[40] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.099521,	
2017-06-26 20:58:13,464 Epoch[40] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099591,	
2017-06-26 20:58:18,774 Epoch[40] Batch [790]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099454,	
2017-06-26 20:58:24,134 Epoch[40] Batch [800]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099448,	
2017-06-26 20:58:29,500 Epoch[40] Batch [810]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.099402,	
2017-06-26 20:58:34,819 Epoch[40] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099208,	
2017-06-26 20:58:40,216 Epoch[40] Batch [830]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.099102,	
2017-06-26 20:58:45,464 Epoch[40] Batch [840]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098985,	
2017-06-26 20:58:50,788 Epoch[40] Batch [850]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098882,	
2017-06-26 20:58:56,138 Epoch[40] Batch [860]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098792,	
2017-06-26 20:59:01,445 Epoch[40] Batch [870]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098832,	
2017-06-26 20:59:06,777 Epoch[40] Batch [880]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098699,	
2017-06-26 20:59:12,195 Epoch[40] Batch [890]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098643,	
2017-06-26 20:59:17,482 Epoch[40] Batch [900]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098695,	
2017-06-26 20:59:22,841 Epoch[40] Batch [910]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098591,	
2017-06-26 20:59:28,137 Epoch[40] Batch [920]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098433,	
2017-06-26 20:59:33,449 Epoch[40] Batch [930]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098454,	
2017-06-26 20:59:38,779 Epoch[40] Batch [940]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098443,	
2017-06-26 20:59:44,232 Epoch[40] Batch [950]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098408,	
2017-06-26 20:59:49,453 Epoch[40] Batch [960]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.098381,	
2017-06-26 20:59:54,823 Epoch[40] Batch [970]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098258,	
2017-06-26 21:00:00,141 Epoch[40] Batch [980]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098239,	
2017-06-26 21:00:05,462 Epoch[40] Batch [990]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098128,	
2017-06-26 21:00:10,803 Epoch[40] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098023,	
2017-06-26 21:00:16,152 Epoch[40] Batch [1010]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097965,	
2017-06-26 21:00:21,507 Epoch[40] Batch [1020]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097943,	
2017-06-26 21:00:26,821 Epoch[40] Batch [1030]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097872,	
2017-06-26 21:00:32,151 Epoch[40] Batch [1040]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097801,	
2017-06-26 21:00:37,477 Epoch[40] Batch [1050]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097721,	
2017-06-26 21:00:42,900 Epoch[40] Batch [1060]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.097617,	
2017-06-26 21:00:48,199 Epoch[40] Batch [1070]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097570,	
2017-06-26 21:00:53,510 Epoch[40] Batch [1080]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097545,	
2017-06-26 21:00:58,820 Epoch[40] Batch [1090]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097645,	
2017-06-26 21:01:04,229 Epoch[40] Batch [1100]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.097640,	
2017-06-26 21:01:09,505 Epoch[40] Batch [1110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097661,	
2017-06-26 21:01:14,850 Epoch[40] Batch [1120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097685,	
2017-06-26 21:01:20,244 Epoch[40] Batch [1130]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097677,	
2017-06-26 21:01:25,514 Epoch[40] Batch [1140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097707,	
2017-06-26 21:01:30,858 Epoch[40] Batch [1150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097642,	
2017-06-26 21:01:36,177 Epoch[40] Batch [1160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097720,	
2017-06-26 21:01:41,555 Epoch[40] Batch [1170]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097636,	
2017-06-26 21:01:46,902 Epoch[40] Batch [1180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097556,	
2017-06-26 21:01:52,234 Epoch[40] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097606,	
2017-06-26 21:01:57,567 Epoch[40] Batch [1200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097636,	
2017-06-26 21:02:02,870 Epoch[40] Batch [1210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097576,	
2017-06-26 21:02:08,268 Epoch[40] Batch [1220]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097497,	
2017-06-26 21:02:13,529 Epoch[40] Batch [1230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.097390,	
2017-06-26 21:02:18,883 Epoch[40] Batch [1240]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097395,	
2017-06-26 21:02:24,220 Epoch[40] Batch [1250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097359,	
2017-06-26 21:02:29,701 Epoch[40] Batch [1260]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.097224,	
2017-06-26 21:02:34,937 Epoch[40] Batch [1270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097132,	
2017-06-26 21:02:40,336 Epoch[40] Batch [1280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097110,	
2017-06-26 21:02:45,702 Epoch[40] Batch [1290]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097030,	
2017-06-26 21:02:51,018 Epoch[40] Batch [1300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096996,	
2017-06-26 21:02:56,400 Epoch[40] Batch [1310]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096955,	
2017-06-26 21:03:01,758 Epoch[40] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096889,	
2017-06-26 21:03:07,051 Epoch[40] Batch [1330]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096876,	
2017-06-26 21:03:12,457 Epoch[40] Batch [1340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.096907,	
2017-06-26 21:03:17,324 Epoch[40] Batch [1350]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.096823,	
2017-06-26 21:03:23,117 Epoch[40] Batch [1360]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096815,	
2017-06-26 21:03:28,713 Epoch[40] Batch [1370]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.096771,	
2017-06-26 21:03:33,975 Epoch[40] Batch [1380]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096785,	
2017-06-26 21:03:39,341 Epoch[40] Batch [1390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096769,	
2017-06-26 21:03:44,653 Epoch[40] Batch [1400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096726,	
2017-06-26 21:03:50,057 Epoch[40] Batch [1410]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.096619,	
2017-06-26 21:03:55,363 Epoch[40] Batch [1420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096664,	
2017-06-26 21:04:00,682 Epoch[40] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096610,	
2017-06-26 21:04:06,053 Epoch[40] Batch [1440]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096604,	
2017-06-26 21:04:11,379 Epoch[40] Batch [1450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096583,	
2017-06-26 21:04:16,774 Epoch[40] Batch [1460]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.096628,	
2017-06-26 21:04:22,109 Epoch[40] Batch [1470]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096616,	
2017-06-26 21:04:27,632 Epoch[40] Batch [1480]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.096561,	
2017-06-26 21:04:30,813 Epoch[40] Train-FCNLogLoss=0.096516
2017-06-26 21:04:30,813 Epoch[40] Time cost=800.577
2017-06-26 21:04:31,597 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0041.params"
2017-06-26 21:04:35,413 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0041.states"
2017-06-26 21:04:41,493 Epoch[41] Batch [10]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.099183,	
2017-06-26 21:04:46,827 Epoch[41] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095262,	
2017-06-26 21:04:52,190 Epoch[41] Batch [30]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100614,	
2017-06-26 21:04:57,509 Epoch[41] Batch [40]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099885,	
2017-06-26 21:05:02,891 Epoch[41] Batch [50]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.097501,	
2017-06-26 21:05:08,173 Epoch[41] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096847,	
2017-06-26 21:05:13,558 Epoch[41] Batch [70]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098483,	
2017-06-26 21:05:18,917 Epoch[41] Batch [80]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097514,	
2017-06-26 21:05:24,185 Epoch[41] Batch [90]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097116,	
2017-06-26 21:05:29,550 Epoch[41] Batch [100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096331,	
2017-06-26 21:05:35,016 Epoch[41] Batch [110]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.095933,	
2017-06-26 21:05:40,302 Epoch[41] Batch [120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095707,	
2017-06-26 21:05:45,560 Epoch[41] Batch [130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096037,	
2017-06-26 21:05:50,910 Epoch[41] Batch [140]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095741,	
2017-06-26 21:05:56,296 Epoch[41] Batch [150]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096696,	
2017-06-26 21:06:01,560 Epoch[41] Batch [160]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096523,	
2017-06-26 21:06:06,919 Epoch[41] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096414,	
2017-06-26 21:06:12,237 Epoch[41] Batch [180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096375,	
2017-06-26 21:06:17,647 Epoch[41] Batch [190]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.096620,	
2017-06-26 21:06:22,901 Epoch[41] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096606,	
2017-06-26 21:06:28,260 Epoch[41] Batch [210]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096530,	
2017-06-26 21:06:33,650 Epoch[41] Batch [220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.096265,	
2017-06-26 21:06:38,961 Epoch[41] Batch [230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096233,	
2017-06-26 21:06:44,274 Epoch[41] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095602,	
2017-06-26 21:06:49,608 Epoch[41] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095511,	
2017-06-26 21:06:54,939 Epoch[41] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095411,	
2017-06-26 21:07:00,284 Epoch[41] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095541,	
2017-06-26 21:07:05,612 Epoch[41] Batch [280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095238,	
2017-06-26 21:07:10,969 Epoch[41] Batch [290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095173,	
2017-06-26 21:07:16,315 Epoch[41] Batch [300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095090,	
2017-06-26 21:07:21,703 Epoch[41] Batch [310]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095022,	
2017-06-26 21:07:26,956 Epoch[41] Batch [320]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.095387,	
2017-06-26 21:07:32,332 Epoch[41] Batch [330]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095269,	
2017-06-26 21:07:37,646 Epoch[41] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095102,	
2017-06-26 21:07:43,006 Epoch[41] Batch [350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095105,	
2017-06-26 21:07:48,276 Epoch[41] Batch [360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095492,	
2017-06-26 21:07:53,611 Epoch[41] Batch [370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095566,	
2017-06-26 21:07:58,963 Epoch[41] Batch [380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095443,	
2017-06-26 21:08:04,310 Epoch[41] Batch [390]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095853,	
2017-06-26 21:08:09,602 Epoch[41] Batch [400]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095868,	
2017-06-26 21:08:14,978 Epoch[41] Batch [410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095683,	
2017-06-26 21:08:20,287 Epoch[41] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095756,	
2017-06-26 21:08:25,655 Epoch[41] Batch [430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095693,	
2017-06-26 21:08:30,966 Epoch[41] Batch [440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095627,	
2017-06-26 21:08:36,277 Epoch[41] Batch [450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095356,	
2017-06-26 21:08:41,591 Epoch[41] Batch [460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095287,	
2017-06-26 21:08:46,904 Epoch[41] Batch [470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095103,	
2017-06-26 21:08:52,269 Epoch[41] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095118,	
2017-06-26 21:08:57,598 Epoch[41] Batch [490]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095105,	
2017-06-26 21:09:02,972 Epoch[41] Batch [500]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095109,	
2017-06-26 21:09:08,343 Epoch[41] Batch [510]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094932,	
2017-06-26 21:09:13,616 Epoch[41] Batch [520]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094700,	
2017-06-26 21:09:18,977 Epoch[41] Batch [530]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094709,	
2017-06-26 21:09:24,291 Epoch[41] Batch [540]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094740,	
2017-06-26 21:09:29,670 Epoch[41] Batch [550]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094646,	
2017-06-26 21:09:35,009 Epoch[41] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094581,	
2017-06-26 21:09:40,402 Epoch[41] Batch [570]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.094556,	
2017-06-26 21:09:45,712 Epoch[41] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094534,	
2017-06-26 21:09:51,029 Epoch[41] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094516,	
2017-06-26 21:09:56,351 Epoch[41] Batch [600]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094463,	
2017-06-26 21:10:01,693 Epoch[41] Batch [610]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094438,	
2017-06-26 21:10:07,062 Epoch[41] Batch [620]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094483,	
2017-06-26 21:10:12,384 Epoch[41] Batch [630]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-26 21:10:17,752 Epoch[41] Batch [640]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094433,	
2017-06-26 21:10:23,082 Epoch[41] Batch [650]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094341,	
2017-06-26 21:10:28,409 Epoch[41] Batch [660]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094291,	
2017-06-26 21:10:33,746 Epoch[41] Batch [670]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094312,	
2017-06-26 21:10:39,101 Epoch[41] Batch [680]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094251,	
2017-06-26 21:10:44,440 Epoch[41] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094085,	
2017-06-26 21:10:49,798 Epoch[41] Batch [700]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094109,	
2017-06-26 21:10:55,124 Epoch[41] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094194,	
2017-06-26 21:11:00,428 Epoch[41] Batch [720]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094029,	
2017-06-26 21:11:05,787 Epoch[41] Batch [730]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093954,	
2017-06-26 21:11:11,108 Epoch[41] Batch [740]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093912,	
2017-06-26 21:11:16,434 Epoch[41] Batch [750]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093955,	
2017-06-26 21:11:21,780 Epoch[41] Batch [760]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093773,	
2017-06-26 21:11:27,143 Epoch[41] Batch [770]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093737,	
2017-06-26 21:11:32,478 Epoch[41] Batch [780]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093850,	
2017-06-26 21:11:37,882 Epoch[41] Batch [790]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093892,	
2017-06-26 21:11:43,287 Epoch[41] Batch [800]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093771,	
2017-06-26 21:11:48,628 Epoch[41] Batch [810]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093750,	
2017-06-26 21:11:53,964 Epoch[41] Batch [820]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093762,	
2017-06-26 21:11:59,358 Epoch[41] Batch [830]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093669,	
2017-06-26 21:12:04,763 Epoch[41] Batch [840]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093695,	
2017-06-26 21:12:10,641 Epoch[41] Batch [850]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093641,	
2017-06-26 21:12:16,304 Epoch[41] Batch [860]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093653,	
2017-06-26 21:12:21,774 Epoch[41] Batch [870]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.093726,	
2017-06-26 21:12:27,188 Epoch[41] Batch [880]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093743,	
2017-06-26 21:12:32,675 Epoch[41] Batch [890]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.093738,	
2017-06-26 21:12:37,980 Epoch[41] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093728,	
2017-06-26 21:12:43,474 Epoch[41] Batch [910]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093662,	
2017-06-26 21:12:48,698 Epoch[41] Batch [920]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093708,	
2017-06-26 21:12:54,119 Epoch[41] Batch [930]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.093718,	
2017-06-26 21:12:59,728 Epoch[41] Batch [940]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.093726,	
2017-06-26 21:13:05,136 Epoch[41] Batch [950]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093680,	
2017-06-26 21:13:10,803 Epoch[41] Batch [960]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093730,	
2017-06-26 21:13:16,197 Epoch[41] Batch [970]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093667,	
2017-06-26 21:13:21,541 Epoch[41] Batch [980]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093783,	
2017-06-26 21:13:26,832 Epoch[41] Batch [990]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093726,	
2017-06-26 21:13:32,459 Epoch[41] Batch [1000]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093792,	
2017-06-26 21:13:38,092 Epoch[41] Batch [1010]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093718,	
2017-06-26 21:13:43,428 Epoch[41] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093603,	
2017-06-26 21:13:49,111 Epoch[41] Batch [1030]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.093519,	
2017-06-26 21:13:54,647 Epoch[41] Batch [1040]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093453,	
2017-06-26 21:14:00,007 Epoch[41] Batch [1050]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093396,	
2017-06-26 21:14:05,427 Epoch[41] Batch [1060]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.093416,	
2017-06-26 21:14:10,759 Epoch[41] Batch [1070]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093514,	
2017-06-26 21:14:16,140 Epoch[41] Batch [1080]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093367,	
2017-06-26 21:14:21,537 Epoch[41] Batch [1090]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093288,	
2017-06-26 21:14:26,812 Epoch[41] Batch [1100]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093260,	
2017-06-26 21:14:32,188 Epoch[41] Batch [1110]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093195,	
2017-06-26 21:14:37,503 Epoch[41] Batch [1120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093148,	
2017-06-26 21:14:43,021 Epoch[41] Batch [1130]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.093211,	
2017-06-26 21:14:48,393 Epoch[41] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093202,	
2017-06-26 21:14:53,676 Epoch[41] Batch [1150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093213,	
2017-06-26 21:14:59,028 Epoch[41] Batch [1160]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093131,	
2017-06-26 21:15:04,442 Epoch[41] Batch [1170]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093113,	
2017-06-26 21:15:09,744 Epoch[41] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093093,	
2017-06-26 21:15:15,316 Epoch[41] Batch [1190]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.092979,	
2017-06-26 21:15:20,629 Epoch[41] Batch [1200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092973,	
2017-06-26 21:15:26,223 Epoch[41] Batch [1210]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092966,	
2017-06-26 21:15:32,084 Epoch[41] Batch [1220]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.093118,	
2017-06-26 21:15:37,823 Epoch[41] Batch [1230]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.093143,	
2017-06-26 21:15:42,977 Epoch[41] Batch [1240]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093220,	
2017-06-26 21:15:48,413 Epoch[41] Batch [1250]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093229,	
2017-06-26 21:15:54,259 Epoch[41] Batch [1260]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093237,	
2017-06-26 21:16:00,246 Epoch[41] Batch [1270]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.093274,	
2017-06-26 21:16:05,415 Epoch[41] Batch [1280]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093332,	
2017-06-26 21:16:10,798 Epoch[41] Batch [1290]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093342,	
2017-06-26 21:16:16,084 Epoch[41] Batch [1300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093285,	
2017-06-26 21:16:21,497 Epoch[41] Batch [1310]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093288,	
2017-06-26 21:16:26,787 Epoch[41] Batch [1320]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093241,	
2017-06-26 21:16:32,705 Epoch[41] Batch [1330]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.093342,	
2017-06-26 21:16:38,242 Epoch[41] Batch [1340]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.093298,	
2017-06-26 21:16:43,513 Epoch[41] Batch [1350]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093336,	
2017-06-26 21:16:49,179 Epoch[41] Batch [1360]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093393,	
2017-06-26 21:16:55,113 Epoch[41] Batch [1370]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093363,	
2017-06-26 21:17:00,984 Epoch[41] Batch [1380]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093364,	
2017-06-26 21:17:06,531 Epoch[41] Batch [1390]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093398,	
2017-06-26 21:17:11,903 Epoch[41] Batch [1400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093365,	
2017-06-26 21:17:17,159 Epoch[41] Batch [1410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093328,	
2017-06-26 21:17:22,499 Epoch[41] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093326,	
2017-06-26 21:17:27,807 Epoch[41] Batch [1430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093362,	
2017-06-26 21:17:33,266 Epoch[41] Batch [1440]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093426,	
2017-06-26 21:17:38,630 Epoch[41] Batch [1450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093404,	
2017-06-26 21:17:44,344 Epoch[41] Batch [1460]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.093514,	
2017-06-26 21:17:50,272 Epoch[41] Batch [1470]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.093546,	
2017-06-26 21:17:55,603 Epoch[41] Batch [1480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093504,	
2017-06-26 21:17:58,732 Epoch[41] Train-FCNLogLoss=0.093511
2017-06-26 21:17:58,732 Epoch[41] Time cost=803.319
2017-06-26 21:18:00,102 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0042.params"
2017-06-26 21:18:03,935 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0042.states"
2017-06-26 21:18:10,240 Epoch[42] Batch [10]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094452,	
2017-06-26 21:18:15,822 Epoch[42] Batch [20]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.093463,	
2017-06-26 21:18:21,474 Epoch[42] Batch [30]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.093223,	
2017-06-26 21:18:27,091 Epoch[42] Batch [40]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.093591,	
2017-06-26 21:18:32,648 Epoch[42] Batch [50]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.091902,	
2017-06-26 21:18:38,465 Epoch[42] Batch [60]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.090680,	
2017-06-26 21:18:44,097 Epoch[42] Batch [70]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.090370,	
2017-06-26 21:18:49,835 Epoch[42] Batch [80]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.090585,	
2017-06-26 21:18:55,760 Epoch[42] Batch [90]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.090141,	
2017-06-26 21:19:01,176 Epoch[42] Batch [100]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.089506,	
2017-06-26 21:19:06,554 Epoch[42] Batch [110]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089269,	
2017-06-26 21:19:11,782 Epoch[42] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.089226,	
2017-06-26 21:19:17,411 Epoch[42] Batch [130]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.088779,	
2017-06-26 21:19:22,847 Epoch[42] Batch [140]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090123,	
2017-06-26 21:19:28,478 Epoch[42] Batch [150]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.090876,	
2017-06-26 21:19:34,346 Epoch[42] Batch [160]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.091032,	
2017-06-26 21:19:40,237 Epoch[42] Batch [170]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.090515,	
2017-06-26 21:19:46,114 Epoch[42] Batch [180]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.090282,	
2017-06-26 21:19:51,649 Epoch[42] Batch [190]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.090389,	
2017-06-26 21:19:57,290 Epoch[42] Batch [200]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.090431,	
2017-06-26 21:20:03,466 Epoch[42] Batch [210]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.090534,	
2017-06-26 21:20:09,381 Epoch[42] Batch [220]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.090277,	
2017-06-26 21:20:14,777 Epoch[42] Batch [230]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090044,	
2017-06-26 21:20:20,241 Epoch[42] Batch [240]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.090146,	
2017-06-26 21:20:25,759 Epoch[42] Batch [250]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.090314,	
2017-06-26 21:20:31,007 Epoch[42] Batch [260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090274,	
2017-06-26 21:20:36,417 Epoch[42] Batch [270]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090395,	
2017-06-26 21:20:42,011 Epoch[42] Batch [280]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.090482,	
2017-06-26 21:20:47,333 Epoch[42] Batch [290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090504,	
2017-06-26 21:20:52,893 Epoch[42] Batch [300]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.090820,	
2017-06-26 21:20:58,142 Epoch[42] Batch [310]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090533,	
2017-06-26 21:21:03,516 Epoch[42] Batch [320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090566,	
2017-06-26 21:21:08,946 Epoch[42] Batch [330]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090532,	
2017-06-26 21:21:14,404 Epoch[42] Batch [340]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.090649,	
2017-06-26 21:21:19,824 Epoch[42] Batch [350]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.090596,	
2017-06-26 21:21:25,380 Epoch[42] Batch [360]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.090685,	
2017-06-26 21:21:30,776 Epoch[42] Batch [370]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090744,	
2017-06-26 21:21:36,147 Epoch[42] Batch [380]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090836,	
2017-06-26 21:21:41,608 Epoch[42] Batch [390]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.090805,	
2017-06-26 21:21:46,945 Epoch[42] Batch [400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090713,	
2017-06-26 21:21:52,239 Epoch[42] Batch [410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090761,	
2017-06-26 21:21:57,599 Epoch[42] Batch [420]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090901,	
2017-06-26 21:22:03,007 Epoch[42] Batch [430]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090874,	
2017-06-26 21:22:08,360 Epoch[42] Batch [440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091002,	
2017-06-26 21:22:13,808 Epoch[42] Batch [450]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.091435,	
2017-06-26 21:22:19,072 Epoch[42] Batch [460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091566,	
2017-06-26 21:22:24,423 Epoch[42] Batch [470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091736,	
2017-06-26 21:22:29,855 Epoch[42] Batch [480]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.091695,	
2017-06-26 21:22:35,450 Epoch[42] Batch [490]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.091654,	
2017-06-26 21:22:40,805 Epoch[42] Batch [500]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091481,	
2017-06-26 21:22:46,755 Epoch[42] Batch [510]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.091492,	
2017-06-26 21:22:52,480 Epoch[42] Batch [520]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.091443,	
2017-06-26 21:22:57,789 Epoch[42] Batch [530]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091418,	
2017-06-26 21:23:03,319 Epoch[42] Batch [540]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.091176,	
2017-06-26 21:23:09,020 Epoch[42] Batch [550]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.091256,	
2017-06-26 21:23:14,376 Epoch[42] Batch [560]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.091274,	
2017-06-26 21:23:19,694 Epoch[42] Batch [570]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091329,	
2017-06-26 21:23:25,044 Epoch[42] Batch [580]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091230,	
2017-06-26 21:23:30,391 Epoch[42] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091254,	
2017-06-26 21:23:35,699 Epoch[42] Batch [600]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091278,	
2017-06-26 21:23:41,331 Epoch[42] Batch [610]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.091259,	
2017-06-26 21:23:47,280 Epoch[42] Batch [620]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.091312,	
2017-06-26 21:23:52,641 Epoch[42] Batch [630]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091264,	
2017-06-26 21:23:57,970 Epoch[42] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091268,	
2017-06-26 21:24:03,278 Epoch[42] Batch [650]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091269,	
2017-06-26 21:24:08,578 Epoch[42] Batch [660]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091530,	
2017-06-26 21:24:13,966 Epoch[42] Batch [670]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091694,	
2017-06-26 21:24:19,322 Epoch[42] Batch [680]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091645,	
2017-06-26 21:24:24,653 Epoch[42] Batch [690]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091582,	
2017-06-26 21:24:30,002 Epoch[42] Batch [700]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091905,	
2017-06-26 21:24:35,333 Epoch[42] Batch [710]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091874,	
2017-06-26 21:24:40,707 Epoch[42] Batch [720]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091823,	
2017-06-26 21:24:46,041 Epoch[42] Batch [730]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091772,	
2017-06-26 21:24:51,782 Epoch[42] Batch [740]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.091910,	
2017-06-26 21:24:57,045 Epoch[42] Batch [750]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091935,	
2017-06-26 21:25:02,409 Epoch[42] Batch [760]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091917,	
2017-06-26 21:25:07,751 Epoch[42] Batch [770]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091965,	
2017-06-26 21:25:13,066 Epoch[42] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091924,	
2017-06-26 21:25:18,411 Epoch[42] Batch [790]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091918,	
2017-06-26 21:25:23,762 Epoch[42] Batch [800]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091861,	
2017-06-26 21:25:29,109 Epoch[42] Batch [810]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091919,	
2017-06-26 21:25:34,437 Epoch[42] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091882,	
2017-06-26 21:25:40,067 Epoch[42] Batch [830]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.092127,	
2017-06-26 21:25:45,374 Epoch[42] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091999,	
2017-06-26 21:25:50,748 Epoch[42] Batch [850]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091963,	
2017-06-26 21:25:56,094 Epoch[42] Batch [860]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092040,	
2017-06-26 21:26:01,413 Epoch[42] Batch [870]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092139,	
2017-06-26 21:26:06,712 Epoch[42] Batch [880]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092149,	
2017-06-26 21:26:12,054 Epoch[42] Batch [890]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092137,	
2017-06-26 21:26:17,398 Epoch[42] Batch [900]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092151,	
2017-06-26 21:26:22,725 Epoch[42] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092222,	
2017-06-26 21:26:28,011 Epoch[42] Batch [920]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092182,	
2017-06-26 21:26:33,256 Epoch[42] Batch [930]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092109,	
2017-06-26 21:26:39,050 Epoch[42] Batch [940]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.092179,	
2017-06-26 21:26:44,490 Epoch[42] Batch [950]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.092280,	
2017-06-26 21:26:49,853 Epoch[42] Batch [960]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092285,	
2017-06-26 21:26:55,274 Epoch[42] Batch [970]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092364,	
2017-06-26 21:27:00,624 Epoch[42] Batch [980]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092425,	
2017-06-26 21:27:05,948 Epoch[42] Batch [990]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092481,	
2017-06-26 21:27:11,456 Epoch[42] Batch [1000]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.092570,	
2017-06-26 21:27:16,784 Epoch[42] Batch [1010]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092574,	
2017-06-26 21:27:22,140 Epoch[42] Batch [1020]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092554,	
2017-06-26 21:27:27,521 Epoch[42] Batch [1030]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092528,	
2017-06-26 21:27:32,859 Epoch[42] Batch [1040]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092460,	
2017-06-26 21:27:38,096 Epoch[42] Batch [1050]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.092447,	
2017-06-26 21:27:43,431 Epoch[42] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092429,	
2017-06-26 21:27:48,771 Epoch[42] Batch [1070]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092399,	
2017-06-26 21:27:54,118 Epoch[42] Batch [1080]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092455,	
2017-06-26 21:27:59,462 Epoch[42] Batch [1090]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092400,	
2017-06-26 21:28:04,768 Epoch[42] Batch [1100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092500,	
2017-06-26 21:28:10,130 Epoch[42] Batch [1110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092493,	
2017-06-26 21:28:15,474 Epoch[42] Batch [1120]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092513,	
2017-06-26 21:28:20,862 Epoch[42] Batch [1130]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092495,	
2017-06-26 21:28:26,217 Epoch[42] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092590,	
2017-06-26 21:28:32,063 Epoch[42] Batch [1150]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.092594,	
2017-06-26 21:28:37,860 Epoch[42] Batch [1160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.092482,	
2017-06-26 21:28:43,311 Epoch[42] Batch [1170]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092449,	
2017-06-26 21:28:48,684 Epoch[42] Batch [1180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092439,	
2017-06-26 21:28:54,301 Epoch[42] Batch [1190]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.092534,	
2017-06-26 21:28:59,831 Epoch[42] Batch [1200]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.092501,	
2017-06-26 21:29:05,559 Epoch[42] Batch [1210]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.092530,	
2017-06-26 21:29:11,459 Epoch[42] Batch [1220]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.092606,	
2017-06-26 21:29:17,222 Epoch[42] Batch [1230]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.092620,	
2017-06-26 21:29:22,853 Epoch[42] Batch [1240]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.092609,	
2017-06-26 21:29:28,642 Epoch[42] Batch [1250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.092639,	
2017-06-26 21:29:34,227 Epoch[42] Batch [1260]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.092572,	
2017-06-26 21:29:39,498 Epoch[42] Batch [1270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092519,	
2017-06-26 21:29:45,048 Epoch[42] Batch [1280]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.092656,	
2017-06-26 21:29:50,501 Epoch[42] Batch [1290]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092817,	
2017-06-26 21:29:56,278 Epoch[42] Batch [1300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.092834,	
2017-06-26 21:30:02,291 Epoch[42] Batch [1310]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.092773,	
2017-06-26 21:30:08,167 Epoch[42] Batch [1320]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.092741,	
2017-06-26 21:30:13,797 Epoch[42] Batch [1330]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.092802,	
2017-06-26 21:30:19,607 Epoch[42] Batch [1340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.092791,	
2017-06-26 21:30:25,113 Epoch[42] Batch [1350]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092744,	
2017-06-26 21:30:30,359 Epoch[42] Batch [1360]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092733,	
2017-06-26 21:30:35,743 Epoch[42] Batch [1370]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092675,	
2017-06-26 21:30:41,199 Epoch[42] Batch [1380]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.092711,	
2017-06-26 21:30:46,667 Epoch[42] Batch [1390]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.092719,	
2017-06-26 21:30:52,137 Epoch[42] Batch [1400]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.092729,	
2017-06-26 21:30:57,641 Epoch[42] Batch [1410]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092685,	
2017-06-26 21:31:03,125 Epoch[42] Batch [1420]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092698,	
2017-06-26 21:31:08,628 Epoch[42] Batch [1430]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092684,	
2017-06-26 21:31:13,876 Epoch[42] Batch [1440]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092628,	
2017-06-26 21:31:19,300 Epoch[42] Batch [1450]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092629,	
2017-06-26 21:31:24,575 Epoch[42] Batch [1460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.092651,	
2017-06-26 21:31:29,890 Epoch[42] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092681,	
2017-06-26 21:31:35,160 Epoch[42] Batch [1480]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092781,	
2017-06-26 21:31:38,336 Epoch[42] Train-FCNLogLoss=0.092790
2017-06-26 21:31:38,336 Epoch[42] Time cost=814.400
2017-06-26 21:31:39,697 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0043.params"
2017-06-26 21:31:43,524 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0043.states"
2017-06-26 21:31:49,813 Epoch[43] Batch [10]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.096557,	
2017-06-26 21:31:55,523 Epoch[43] Batch [20]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.095822,	
2017-06-26 21:32:01,427 Epoch[43] Batch [30]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093945,	
2017-06-26 21:32:07,378 Epoch[43] Batch [40]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.095302,	
2017-06-26 21:32:13,054 Epoch[43] Batch [50]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.097457,	
2017-06-26 21:32:18,730 Epoch[43] Batch [60]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.096806,	
2017-06-26 21:32:24,342 Epoch[43] Batch [70]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.097863,	
2017-06-26 21:32:29,723 Epoch[43] Batch [80]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096869,	
2017-06-26 21:32:35,081 Epoch[43] Batch [90]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095981,	
2017-06-26 21:32:40,424 Epoch[43] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095296,	
2017-06-26 21:32:46,317 Epoch[43] Batch [110]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.094599,	
2017-06-26 21:32:52,087 Epoch[43] Batch [120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.093957,	
2017-06-26 21:32:57,612 Epoch[43] Batch [130]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.093592,	
2017-06-26 21:33:03,794 Epoch[43] Batch [140]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.093642,	
2017-06-26 21:33:09,742 Epoch[43] Batch [150]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093653,	
2017-06-26 21:33:15,674 Epoch[43] Batch [160]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093597,	
2017-06-26 21:33:21,622 Epoch[43] Batch [170]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093573,	
2017-06-26 21:33:27,707 Epoch[43] Batch [180]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.093816,	
2017-06-26 21:33:33,331 Epoch[43] Batch [190]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093433,	
2017-06-26 21:33:39,209 Epoch[43] Batch [200]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093382,	
2017-06-26 21:33:44,479 Epoch[43] Batch [210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093463,	
2017-06-26 21:33:49,734 Epoch[43] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093542,	
2017-06-26 21:33:55,076 Epoch[43] Batch [230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093441,	
2017-06-26 21:34:00,433 Epoch[43] Batch [240]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093479,	
2017-06-26 21:34:05,764 Epoch[43] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093492,	
2017-06-26 21:34:11,127 Epoch[43] Batch [260]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093674,	
2017-06-26 21:34:16,399 Epoch[43] Batch [270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093340,	
2017-06-26 21:34:21,760 Epoch[43] Batch [280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093389,	
2017-06-26 21:34:27,135 Epoch[43] Batch [290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093239,	
2017-06-26 21:34:32,541 Epoch[43] Batch [300]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093003,	
2017-06-26 21:34:37,781 Epoch[43] Batch [310]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093008,	
2017-06-26 21:34:43,189 Epoch[43] Batch [320]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092782,	
2017-06-26 21:34:48,747 Epoch[43] Batch [330]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093133,	
2017-06-26 21:34:55,136 Epoch[43] Batch [340]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.092761,	
2017-06-26 21:35:00,856 Epoch[43] Batch [350]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.092682,	
2017-06-26 21:35:06,145 Epoch[43] Batch [360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092634,	
2017-06-26 21:35:11,819 Epoch[43] Batch [370]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.092768,	
2017-06-26 21:35:18,028 Epoch[43] Batch [380]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.092824,	
2017-06-26 21:35:23,448 Epoch[43] Batch [390]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092983,	
2017-06-26 21:35:28,749 Epoch[43] Batch [400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093082,	
2017-06-26 21:35:34,151 Epoch[43] Batch [410]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093242,	
2017-06-26 21:35:39,448 Epoch[43] Batch [420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093293,	
2017-06-26 21:35:44,772 Epoch[43] Batch [430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093159,	
2017-06-26 21:35:50,127 Epoch[43] Batch [440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092972,	
2017-06-26 21:35:55,443 Epoch[43] Batch [450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092751,	
2017-06-26 21:36:00,812 Epoch[43] Batch [460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093007,	
2017-06-26 21:36:06,139 Epoch[43] Batch [470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092971,	
2017-06-26 21:36:11,662 Epoch[43] Batch [480]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.093084,	
2017-06-26 21:36:17,267 Epoch[43] Batch [490]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.093227,	
2017-06-26 21:36:22,720 Epoch[43] Batch [500]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093286,	
2017-06-26 21:36:28,206 Epoch[43] Batch [510]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093144,	
2017-06-26 21:36:33,747 Epoch[43] Batch [520]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.093310,	
2017-06-26 21:36:39,037 Epoch[43] Batch [530]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093238,	
2017-06-26 21:36:44,467 Epoch[43] Batch [540]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.093123,	
2017-06-26 21:36:50,549 Epoch[43] Batch [550]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.093492,	
2017-06-26 21:36:56,218 Epoch[43] Batch [560]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093380,	
2017-06-26 21:37:01,699 Epoch[43] Batch [570]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093373,	
2017-06-26 21:37:07,335 Epoch[43] Batch [580]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093382,	
2017-06-26 21:37:12,814 Epoch[43] Batch [590]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093226,	
2017-06-26 21:37:18,111 Epoch[43] Batch [600]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093271,	
2017-06-26 21:37:23,511 Epoch[43] Batch [610]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093386,	
2017-06-26 21:37:28,757 Epoch[43] Batch [620]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093247,	
2017-06-26 21:37:34,126 Epoch[43] Batch [630]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093270,	
2017-06-26 21:37:39,477 Epoch[43] Batch [640]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093158,	
2017-06-26 21:37:45,063 Epoch[43] Batch [650]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093116,	
2017-06-26 21:37:50,722 Epoch[43] Batch [660]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.093284,	
2017-06-26 21:37:56,200 Epoch[43] Batch [670]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093166,	
2017-06-26 21:38:01,526 Epoch[43] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093097,	
2017-06-26 21:38:07,018 Epoch[43] Batch [690]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093135,	
2017-06-26 21:38:12,284 Epoch[43] Batch [700]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093140,	
2017-06-26 21:38:17,610 Epoch[43] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093120,	
2017-06-26 21:38:22,967 Epoch[43] Batch [720]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093045,	
2017-06-26 21:38:28,318 Epoch[43] Batch [730]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092988,	
2017-06-26 21:38:33,623 Epoch[43] Batch [740]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093047,	
2017-06-26 21:38:39,034 Epoch[43] Batch [750]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093132,	
2017-06-26 21:38:44,336 Epoch[43] Batch [760]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093134,	
2017-06-26 21:38:49,674 Epoch[43] Batch [770]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093141,	
2017-06-26 21:38:55,176 Epoch[43] Batch [780]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093059,	
2017-06-26 21:39:00,582 Epoch[43] Batch [790]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093110,	
2017-06-26 21:39:05,956 Epoch[43] Batch [800]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093083,	
2017-06-26 21:39:11,315 Epoch[43] Batch [810]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092937,	
2017-06-26 21:39:16,641 Epoch[43] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092837,	
2017-06-26 21:39:22,050 Epoch[43] Batch [830]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092833,	
2017-06-26 21:39:27,438 Epoch[43] Batch [840]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092735,	
2017-06-26 21:39:33,256 Epoch[43] Batch [850]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.092750,	
2017-06-26 21:39:38,675 Epoch[43] Batch [860]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092667,	
2017-06-26 21:39:43,870 Epoch[43] Batch [870]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092496,	
2017-06-26 21:39:49,220 Epoch[43] Batch [880]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092350,	
2017-06-26 21:39:54,560 Epoch[43] Batch [890]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092225,	
2017-06-26 21:39:59,934 Epoch[43] Batch [900]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092237,	
2017-06-26 21:40:05,303 Epoch[43] Batch [910]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092259,	
2017-06-26 21:40:10,823 Epoch[43] Batch [920]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.092300,	
2017-06-26 21:40:16,443 Epoch[43] Batch [930]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.092288,	
2017-06-26 21:40:22,314 Epoch[43] Batch [940]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.092305,	
2017-06-26 21:40:27,897 Epoch[43] Batch [950]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.092401,	
2017-06-26 21:40:33,632 Epoch[43] Batch [960]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.092389,	
2017-06-26 21:40:39,128 Epoch[43] Batch [970]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.092421,	
2017-06-26 21:40:44,811 Epoch[43] Batch [980]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.092447,	
2017-06-26 21:40:50,403 Epoch[43] Batch [990]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092369,	
2017-06-26 21:40:56,195 Epoch[43] Batch [1000]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.092289,	
2017-06-26 21:41:01,945 Epoch[43] Batch [1010]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.092362,	
2017-06-26 21:41:07,373 Epoch[43] Batch [1020]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.092246,	
2017-06-26 21:41:12,927 Epoch[43] Batch [1030]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.092148,	
2017-06-26 21:41:18,298 Epoch[43] Batch [1040]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092125,	
2017-06-26 21:41:24,014 Epoch[43] Batch [1050]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.092161,	
2017-06-26 21:41:29,391 Epoch[43] Batch [1060]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092158,	
2017-06-26 21:41:34,714 Epoch[43] Batch [1070]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092029,	
2017-06-26 21:41:40,014 Epoch[43] Batch [1080]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091983,	
2017-06-26 21:41:45,387 Epoch[43] Batch [1090]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092004,	
2017-06-26 21:41:50,697 Epoch[43] Batch [1100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092070,	
2017-06-26 21:41:56,148 Epoch[43] Batch [1110]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092136,	
2017-06-26 21:42:01,516 Epoch[43] Batch [1120]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092063,	
2017-06-26 21:42:06,879 Epoch[43] Batch [1130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092034,	
2017-06-26 21:42:12,360 Epoch[43] Batch [1140]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.092038,	
2017-06-26 21:42:17,651 Epoch[43] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091934,	
2017-06-26 21:42:22,769 Epoch[43] Batch [1160]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.092051,	
2017-06-26 21:42:28,291 Epoch[43] Batch [1170]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.092112,	
2017-06-26 21:42:33,644 Epoch[43] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092183,	
2017-06-26 21:42:39,049 Epoch[43] Batch [1190]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092336,	
2017-06-26 21:42:44,577 Epoch[43] Batch [1200]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.092290,	
2017-06-26 21:42:49,838 Epoch[43] Batch [1210]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092248,	
2017-06-26 21:42:55,167 Epoch[43] Batch [1220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092233,	
2017-06-26 21:43:01,001 Epoch[43] Batch [1230]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.092201,	
2017-06-26 21:43:06,584 Epoch[43] Batch [1240]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.092154,	
2017-06-26 21:43:12,111 Epoch[43] Batch [1250]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.092178,	
2017-06-26 21:43:17,945 Epoch[43] Batch [1260]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.092223,	
2017-06-26 21:43:23,229 Epoch[43] Batch [1270]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092221,	
2017-06-26 21:43:28,485 Epoch[43] Batch [1280]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092191,	
2017-06-26 21:43:33,878 Epoch[43] Batch [1290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092212,	
2017-06-26 21:43:39,225 Epoch[43] Batch [1300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092248,	
2017-06-26 21:43:44,560 Epoch[43] Batch [1310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092180,	
2017-06-26 21:43:50,118 Epoch[43] Batch [1320]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.092170,	
2017-06-26 21:43:55,765 Epoch[43] Batch [1330]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.092210,	
2017-06-26 21:44:01,171 Epoch[43] Batch [1340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092195,	
2017-06-26 21:44:06,501 Epoch[43] Batch [1350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092177,	
2017-06-26 21:44:12,007 Epoch[43] Batch [1360]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092305,	
2017-06-26 21:44:17,325 Epoch[43] Batch [1370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092289,	
2017-06-26 21:44:22,631 Epoch[43] Batch [1380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092283,	
2017-06-26 21:44:28,014 Epoch[43] Batch [1390]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092307,	
2017-06-26 21:44:33,286 Epoch[43] Batch [1400]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092240,	
2017-06-26 21:44:38,608 Epoch[43] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092295,	
2017-06-26 21:44:44,011 Epoch[43] Batch [1420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092314,	
2017-06-26 21:44:49,386 Epoch[43] Batch [1430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092346,	
2017-06-26 21:44:54,711 Epoch[43] Batch [1440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092340,	
2017-06-26 21:45:00,354 Epoch[43] Batch [1450]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.092329,	
2017-06-26 21:45:05,637 Epoch[43] Batch [1460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092331,	
2017-06-26 21:45:11,044 Epoch[43] Batch [1470]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092264,	
2017-06-26 21:45:16,437 Epoch[43] Batch [1480]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092276,	
2017-06-26 21:45:19,734 Epoch[43] Train-FCNLogLoss=0.092279
2017-06-26 21:45:19,735 Epoch[43] Time cost=816.210
2017-06-26 21:45:20,847 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0044.params"
2017-06-26 21:45:24,508 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0044.states"
2017-06-26 21:45:30,651 Epoch[44] Batch [10]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.101413,	
2017-06-26 21:45:36,004 Epoch[44] Batch [20]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098900,	
2017-06-26 21:45:41,517 Epoch[44] Batch [30]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.097799,	
2017-06-26 21:45:46,806 Epoch[44] Batch [40]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097325,	
2017-06-26 21:45:52,183 Epoch[44] Batch [50]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095532,	
2017-06-26 21:45:57,772 Epoch[44] Batch [60]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093902,	
2017-06-26 21:46:03,081 Epoch[44] Batch [70]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094243,	
2017-06-26 21:46:08,524 Epoch[44] Batch [80]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.094286,	
2017-06-26 21:46:14,068 Epoch[44] Batch [90]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.094305,	
2017-06-26 21:46:19,386 Epoch[44] Batch [100]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094608,	
2017-06-26 21:46:24,834 Epoch[44] Batch [110]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093751,	
2017-06-26 21:46:30,486 Epoch[44] Batch [120]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.093074,	
2017-06-26 21:46:35,718 Epoch[44] Batch [130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093005,	
2017-06-26 21:46:41,271 Epoch[44] Batch [140]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.094145,	
2017-06-26 21:46:46,635 Epoch[44] Batch [150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093646,	
2017-06-26 21:46:52,193 Epoch[44] Batch [160]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093192,	
2017-06-26 21:46:57,553 Epoch[44] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092879,	
2017-06-26 21:47:02,772 Epoch[44] Batch [180]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093083,	
2017-06-26 21:47:08,135 Epoch[44] Batch [190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093049,	
2017-06-26 21:47:13,425 Epoch[44] Batch [200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093154,	
2017-06-26 21:47:18,765 Epoch[44] Batch [210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093292,	
2017-06-26 21:47:24,081 Epoch[44] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093268,	
2017-06-26 21:47:29,476 Epoch[44] Batch [230]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093368,	
2017-06-26 21:47:34,995 Epoch[44] Batch [240]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.093161,	
2017-06-26 21:47:40,501 Epoch[44] Batch [250]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.092523,	
2017-06-26 21:47:46,093 Epoch[44] Batch [260]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092598,	
2017-06-26 21:47:51,480 Epoch[44] Batch [270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092869,	
2017-06-26 21:47:56,896 Epoch[44] Batch [280]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.092537,	
2017-06-26 21:48:02,552 Epoch[44] Batch [290]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.092616,	
2017-06-26 21:48:07,901 Epoch[44] Batch [300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092069,	
2017-06-26 21:48:13,488 Epoch[44] Batch [310]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.091943,	
2017-06-26 21:48:18,800 Epoch[44] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091771,	
2017-06-26 21:48:24,465 Epoch[44] Batch [330]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.092071,	
2017-06-26 21:48:30,084 Epoch[44] Batch [340]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.091865,	
2017-06-26 21:48:35,692 Epoch[44] Batch [350]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.091835,	
2017-06-26 21:48:41,413 Epoch[44] Batch [360]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.091881,	
2017-06-26 21:48:46,889 Epoch[44] Batch [370]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.091687,	
2017-06-26 21:48:52,326 Epoch[44] Batch [380]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091600,	
2017-06-26 21:48:57,729 Epoch[44] Batch [390]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.091421,	
2017-06-26 21:49:03,045 Epoch[44] Batch [400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091557,	
2017-06-26 21:49:08,400 Epoch[44] Batch [410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091749,	
2017-06-26 21:49:13,856 Epoch[44] Batch [420]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091801,	
2017-06-26 21:49:19,672 Epoch[44] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.091734,	
2017-06-26 21:49:25,209 Epoch[44] Batch [440]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.091615,	
2017-06-26 21:49:30,493 Epoch[44] Batch [450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091324,	
2017-06-26 21:49:36,038 Epoch[44] Batch [460]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.091431,	
2017-06-26 21:49:41,298 Epoch[44] Batch [470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091431,	
2017-06-26 21:49:46,715 Epoch[44] Batch [480]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.091469,	
2017-06-26 21:49:52,614 Epoch[44] Batch [490]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.091495,	
2017-06-26 21:49:57,994 Epoch[44] Batch [500]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091324,	
2017-06-26 21:50:03,363 Epoch[44] Batch [510]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091223,	
2017-06-26 21:50:08,791 Epoch[44] Batch [520]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.091314,	
2017-06-26 21:50:14,103 Epoch[44] Batch [530]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091172,	
2017-06-26 21:50:19,371 Epoch[44] Batch [540]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091341,	
2017-06-26 21:50:24,826 Epoch[44] Batch [550]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091333,	
2017-06-26 21:50:30,348 Epoch[44] Batch [560]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.091373,	
2017-06-26 21:50:35,684 Epoch[44] Batch [570]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091409,	
2017-06-26 21:50:40,991 Epoch[44] Batch [580]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091298,	
2017-06-26 21:50:46,349 Epoch[44] Batch [590]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091361,	
2017-06-26 21:50:51,708 Epoch[44] Batch [600]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091534,	
2017-06-26 21:50:57,018 Epoch[44] Batch [610]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091448,	
2017-06-26 21:51:02,352 Epoch[44] Batch [620]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091434,	
2017-06-26 21:51:07,688 Epoch[44] Batch [630]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091323,	
2017-06-26 21:51:13,331 Epoch[44] Batch [640]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.091353,	
2017-06-26 21:51:18,716 Epoch[44] Batch [650]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091392,	
2017-06-26 21:51:24,203 Epoch[44] Batch [660]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.091326,	
2017-06-26 21:51:29,471 Epoch[44] Batch [670]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091405,	
2017-06-26 21:51:34,811 Epoch[44] Batch [680]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091425,	
2017-06-26 21:51:40,097 Epoch[44] Batch [690]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091339,	
2017-06-26 21:51:45,488 Epoch[44] Batch [700]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091351,	
2017-06-26 21:51:50,873 Epoch[44] Batch [710]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091541,	
2017-06-26 21:51:56,511 Epoch[44] Batch [720]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.091534,	
2017-06-26 21:52:01,875 Epoch[44] Batch [730]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091565,	
2017-06-26 21:52:07,202 Epoch[44] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091540,	
2017-06-26 21:52:12,572 Epoch[44] Batch [750]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091496,	
2017-06-26 21:52:19,174 Epoch[44] Batch [760]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.091633,	
2017-06-26 21:52:24,632 Epoch[44] Batch [770]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091676,	
2017-06-26 21:52:29,981 Epoch[44] Batch [780]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091692,	
2017-06-26 21:52:35,331 Epoch[44] Batch [790]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091659,	
2017-06-26 21:52:40,659 Epoch[44] Batch [800]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091520,	
2017-06-26 21:52:45,934 Epoch[44] Batch [810]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091543,	
2017-06-26 21:52:51,327 Epoch[44] Batch [820]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091601,	
2017-06-26 21:52:56,641 Epoch[44] Batch [830]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091558,	
2017-06-26 21:53:01,992 Epoch[44] Batch [840]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091473,	
2017-06-26 21:53:07,339 Epoch[44] Batch [850]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091502,	
2017-06-26 21:53:12,651 Epoch[44] Batch [860]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091520,	
2017-06-26 21:53:17,996 Epoch[44] Batch [870]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091501,	
2017-06-26 21:53:23,380 Epoch[44] Batch [880]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091497,	
2017-06-26 21:53:28,687 Epoch[44] Batch [890]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091462,	
2017-06-26 21:53:34,011 Epoch[44] Batch [900]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091533,	
2017-06-26 21:53:39,326 Epoch[44] Batch [910]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091607,	
2017-06-26 21:53:44,676 Epoch[44] Batch [920]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091518,	
2017-06-26 21:53:50,032 Epoch[44] Batch [930]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091592,	
2017-06-26 21:53:55,355 Epoch[44] Batch [940]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091547,	
2017-06-26 21:54:00,890 Epoch[44] Batch [950]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.091447,	
2017-06-26 21:54:06,196 Epoch[44] Batch [960]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091436,	
2017-06-26 21:54:11,607 Epoch[44] Batch [970]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091469,	
2017-06-26 21:54:16,995 Epoch[44] Batch [980]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091443,	
2017-06-26 21:54:22,350 Epoch[44] Batch [990]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091548,	
2017-06-26 21:54:27,597 Epoch[44] Batch [1000]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.091585,	
2017-06-26 21:54:33,166 Epoch[44] Batch [1010]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.091632,	
2017-06-26 21:54:38,468 Epoch[44] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091580,	
2017-06-26 21:54:43,890 Epoch[44] Batch [1030]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.091699,	
2017-06-26 21:54:49,178 Epoch[44] Batch [1040]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091734,	
2017-06-26 21:54:54,554 Epoch[44] Batch [1050]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091690,	
2017-06-26 21:55:00,345 Epoch[44] Batch [1060]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.091713,	
2017-06-26 21:55:05,593 Epoch[44] Batch [1070]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.091716,	
2017-06-26 21:55:10,972 Epoch[44] Batch [1080]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091781,	
2017-06-26 21:55:16,608 Epoch[44] Batch [1090]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.091810,	
2017-06-26 21:55:22,105 Epoch[44] Batch [1100]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.091765,	
2017-06-26 21:55:27,270 Epoch[44] Batch [1110]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.091826,	
2017-06-26 21:55:32,738 Epoch[44] Batch [1120]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.091878,	
2017-06-26 21:55:38,007 Epoch[44] Batch [1130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091791,	
2017-06-26 21:55:43,639 Epoch[44] Batch [1140]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.091747,	
2017-06-26 21:55:48,969 Epoch[44] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091686,	
2017-06-26 21:55:54,637 Epoch[44] Batch [1160]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.091700,	
2017-06-26 21:55:59,835 Epoch[44] Batch [1170]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.091736,	
2017-06-26 21:56:05,168 Epoch[44] Batch [1180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091614,	
2017-06-26 21:56:10,572 Epoch[44] Batch [1190]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.091595,	
2017-06-26 21:56:15,963 Epoch[44] Batch [1200]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091627,	
2017-06-26 21:56:21,279 Epoch[44] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091667,	
2017-06-26 21:56:26,891 Epoch[44] Batch [1220]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.091713,	
2017-06-26 21:56:32,152 Epoch[44] Batch [1230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091725,	
2017-06-26 21:56:37,463 Epoch[44] Batch [1240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091723,	
2017-06-26 21:56:42,849 Epoch[44] Batch [1250]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091711,	
2017-06-26 21:56:48,099 Epoch[44] Batch [1260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.091812,	
2017-06-26 21:56:53,483 Epoch[44] Batch [1270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091954,	
2017-06-26 21:56:58,783 Epoch[44] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092043,	
2017-06-26 21:57:04,100 Epoch[44] Batch [1290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092078,	
2017-06-26 21:57:09,600 Epoch[44] Batch [1300]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092045,	
2017-06-26 21:57:14,934 Epoch[44] Batch [1310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092088,	
2017-06-26 21:57:20,249 Epoch[44] Batch [1320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092105,	
2017-06-26 21:57:25,689 Epoch[44] Batch [1330]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.092086,	
2017-06-26 21:57:30,931 Epoch[44] Batch [1340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092090,	
2017-06-26 21:57:36,405 Epoch[44] Batch [1350]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.092016,	
2017-06-26 21:57:41,764 Epoch[44] Batch [1360]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092051,	
2017-06-26 21:57:47,081 Epoch[44] Batch [1370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091943,	
2017-06-26 21:57:52,460 Epoch[44] Batch [1380]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092034,	
2017-06-26 21:57:57,839 Epoch[44] Batch [1390]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092007,	
2017-06-26 21:58:03,268 Epoch[44] Batch [1400]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.092017,	
2017-06-26 21:58:08,510 Epoch[44] Batch [1410]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092018,	
2017-06-26 21:58:13,872 Epoch[44] Batch [1420]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092034,	
2017-06-26 21:58:19,248 Epoch[44] Batch [1430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092048,	
2017-06-26 21:58:24,588 Epoch[44] Batch [1440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092068,	
2017-06-26 21:58:29,978 Epoch[44] Batch [1450]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092046,	
2017-06-26 21:58:35,310 Epoch[44] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092058,	
2017-06-26 21:58:40,644 Epoch[44] Batch [1470]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092041,	
2017-06-26 21:58:46,577 Epoch[44] Batch [1480]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.092038,	
2017-06-26 21:58:49,815 Epoch[44] Train-FCNLogLoss=0.092091
2017-06-26 21:58:49,815 Epoch[44] Time cost=805.307
2017-06-26 21:58:50,752 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0045.params"
2017-06-26 21:58:54,552 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0045.states"
2017-06-26 21:59:00,817 Epoch[45] Batch [10]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.084980,	
2017-06-26 21:59:06,163 Epoch[45] Batch [20]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.085342,	
2017-06-26 21:59:11,688 Epoch[45] Batch [30]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.091281,	
2017-06-26 21:59:17,004 Epoch[45] Batch [40]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090847,	
2017-06-26 21:59:22,962 Epoch[45] Batch [50]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.093171,	
2017-06-26 21:59:28,236 Epoch[45] Batch [60]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092299,	
2017-06-26 21:59:33,639 Epoch[45] Batch [70]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092164,	
2017-06-26 21:59:39,257 Epoch[45] Batch [80]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.093636,	
2017-06-26 21:59:44,824 Epoch[45] Batch [90]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.092451,	
2017-06-26 21:59:50,352 Epoch[45] Batch [100]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.092074,	
2017-06-26 21:59:55,727 Epoch[45] Batch [110]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092208,	
2017-06-26 22:00:01,016 Epoch[45] Batch [120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092124,	
2017-06-26 22:00:06,497 Epoch[45] Batch [130]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093391,	
2017-06-26 22:00:11,941 Epoch[45] Batch [140]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093235,	
2017-06-26 22:00:17,887 Epoch[45] Batch [150]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093315,	
2017-06-26 22:00:23,866 Epoch[45] Batch [160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.093627,	
2017-06-26 22:00:29,737 Epoch[45] Batch [170]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093632,	
2017-06-26 22:00:35,097 Epoch[45] Batch [180]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092830,	
2017-06-26 22:00:41,182 Epoch[45] Batch [190]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.092624,	
2017-06-26 22:00:46,440 Epoch[45] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092654,	
2017-06-26 22:00:52,108 Epoch[45] Batch [210]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.092991,	
2017-06-26 22:00:57,530 Epoch[45] Batch [220]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.093015,	
2017-06-26 22:01:02,841 Epoch[45] Batch [230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092866,	
2017-06-26 22:01:08,189 Epoch[45] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092854,	
2017-06-26 22:01:13,495 Epoch[45] Batch [250]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093035,	
2017-06-26 22:01:18,870 Epoch[45] Batch [260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092847,	
2017-06-26 22:01:24,192 Epoch[45] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092697,	
2017-06-26 22:01:29,555 Epoch[45] Batch [280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092828,	
2017-06-26 22:01:35,076 Epoch[45] Batch [290]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.092936,	
2017-06-26 22:01:40,498 Epoch[45] Batch [300]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092929,	
2017-06-26 22:01:45,732 Epoch[45] Batch [310]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.092918,	
2017-06-26 22:01:51,103 Epoch[45] Batch [320]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093573,	
2017-06-26 22:01:56,472 Epoch[45] Batch [330]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093658,	
2017-06-26 22:02:02,601 Epoch[45] Batch [340]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093533,	
2017-06-26 22:02:07,960 Epoch[45] Batch [350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093546,	
2017-06-26 22:02:13,258 Epoch[45] Batch [360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093430,	
2017-06-26 22:02:18,859 Epoch[45] Batch [370]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.093031,	
2017-06-26 22:02:24,526 Epoch[45] Batch [380]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093319,	
2017-06-26 22:02:29,831 Epoch[45] Batch [390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093390,	
2017-06-26 22:02:35,440 Epoch[45] Batch [400]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.093373,	
2017-06-26 22:02:40,787 Epoch[45] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093257,	
2017-06-26 22:02:46,088 Epoch[45] Batch [420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093153,	
2017-06-26 22:02:51,435 Epoch[45] Batch [430]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092794,	
2017-06-26 22:02:56,760 Epoch[45] Batch [440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092670,	
2017-06-26 22:03:02,078 Epoch[45] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092804,	
2017-06-26 22:03:07,420 Epoch[45] Batch [460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092652,	
2017-06-26 22:03:12,775 Epoch[45] Batch [470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092752,	
2017-06-26 22:03:18,071 Epoch[45] Batch [480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092882,	
2017-06-26 22:03:23,436 Epoch[45] Batch [490]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092730,	
2017-06-26 22:03:28,933 Epoch[45] Batch [500]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.092715,	
2017-06-26 22:03:34,330 Epoch[45] Batch [510]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092681,	
2017-06-26 22:03:39,836 Epoch[45] Batch [520]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092801,	
2017-06-26 22:03:45,349 Epoch[45] Batch [530]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.092796,	
2017-06-26 22:03:50,623 Epoch[45] Batch [540]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.092592,	
2017-06-26 22:03:56,120 Epoch[45] Batch [550]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.092555,	
2017-06-26 22:04:01,492 Epoch[45] Batch [560]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092672,	
2017-06-26 22:04:06,777 Epoch[45] Batch [570]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092648,	
2017-06-26 22:04:12,654 Epoch[45] Batch [580]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.092412,	
2017-06-26 22:04:18,261 Epoch[45] Batch [590]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.092172,	
2017-06-26 22:04:23,543 Epoch[45] Batch [600]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092266,	
2017-06-26 22:04:28,985 Epoch[45] Batch [610]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.092193,	
2017-06-26 22:04:34,822 Epoch[45] Batch [620]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.092017,	
2017-06-26 22:04:40,371 Epoch[45] Batch [630]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.091904,	
2017-06-26 22:04:45,810 Epoch[45] Batch [640]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091864,	
2017-06-26 22:04:51,385 Epoch[45] Batch [650]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.092023,	
2017-06-26 22:04:56,730 Epoch[45] Batch [660]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092030,	
2017-06-26 22:05:02,035 Epoch[45] Batch [670]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092022,	
2017-06-26 22:05:07,386 Epoch[45] Batch [680]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091880,	
2017-06-26 22:05:12,832 Epoch[45] Batch [690]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091746,	
2017-06-26 22:05:18,324 Epoch[45] Batch [700]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.091746,	
2017-06-26 22:05:23,925 Epoch[45] Batch [710]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.091774,	
2017-06-26 22:05:29,289 Epoch[45] Batch [720]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091905,	
2017-06-26 22:05:34,810 Epoch[45] Batch [730]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.091875,	
2017-06-26 22:05:40,716 Epoch[45] Batch [740]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.091723,	
2017-06-26 22:05:45,994 Epoch[45] Batch [750]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091627,	
2017-06-26 22:05:51,576 Epoch[45] Batch [760]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.091538,	
2017-06-26 22:05:56,857 Epoch[45] Batch [770]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091614,	
2017-06-26 22:06:02,154 Epoch[45] Batch [780]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091693,	
2017-06-26 22:06:07,643 Epoch[45] Batch [790]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.091780,	
2017-06-26 22:06:13,075 Epoch[45] Batch [800]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091648,	
2017-06-26 22:06:18,444 Epoch[45] Batch [810]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091706,	
2017-06-26 22:06:24,068 Epoch[45] Batch [820]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.091666,	
2017-06-26 22:06:29,628 Epoch[45] Batch [830]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.091602,	
2017-06-26 22:06:35,081 Epoch[45] Batch [840]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.091731,	
2017-06-26 22:06:40,452 Epoch[45] Batch [850]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091680,	
2017-06-26 22:06:45,790 Epoch[45] Batch [860]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091699,	
2017-06-26 22:06:51,690 Epoch[45] Batch [870]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.091713,	
2017-06-26 22:06:57,376 Epoch[45] Batch [880]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.091729,	
2017-06-26 22:07:02,678 Epoch[45] Batch [890]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091785,	
2017-06-26 22:07:08,393 Epoch[45] Batch [900]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.091763,	
2017-06-26 22:07:14,046 Epoch[45] Batch [910]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.091788,	
2017-06-26 22:07:19,374 Epoch[45] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091734,	
2017-06-26 22:07:25,110 Epoch[45] Batch [930]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.091771,	
2017-06-26 22:07:30,697 Epoch[45] Batch [940]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.091774,	
2017-06-26 22:07:36,263 Epoch[45] Batch [950]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.091823,	
2017-06-26 22:07:41,623 Epoch[45] Batch [960]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091746,	
2017-06-26 22:07:47,008 Epoch[45] Batch [970]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091691,	
2017-06-26 22:07:52,299 Epoch[45] Batch [980]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091773,	
2017-06-26 22:07:57,699 Epoch[45] Batch [990]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091780,	
2017-06-26 22:08:03,037 Epoch[45] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091843,	
2017-06-26 22:08:08,492 Epoch[45] Batch [1010]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091833,	
2017-06-26 22:08:13,785 Epoch[45] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091828,	
2017-06-26 22:08:19,146 Epoch[45] Batch [1030]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091857,	
2017-06-26 22:08:24,454 Epoch[45] Batch [1040]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091789,	
2017-06-26 22:08:30,194 Epoch[45] Batch [1050]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.091835,	
2017-06-26 22:08:35,600 Epoch[45] Batch [1060]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.091872,	
2017-06-26 22:08:41,253 Epoch[45] Batch [1070]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.091897,	
2017-06-26 22:08:46,434 Epoch[45] Batch [1080]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.091924,	
2017-06-26 22:08:51,702 Epoch[45] Batch [1090]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091907,	
2017-06-26 22:08:57,078 Epoch[45] Batch [1100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091874,	
2017-06-26 22:09:02,429 Epoch[45] Batch [1110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091915,	
2017-06-26 22:09:07,791 Epoch[45] Batch [1120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091869,	
2017-06-26 22:09:13,203 Epoch[45] Batch [1130]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091814,	
2017-06-26 22:09:18,769 Epoch[45] Batch [1140]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.091826,	
2017-06-26 22:09:24,410 Epoch[45] Batch [1150]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.091803,	
2017-06-26 22:09:29,985 Epoch[45] Batch [1160]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.091746,	
2017-06-26 22:09:35,613 Epoch[45] Batch [1170]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.091744,	
2017-06-26 22:09:41,158 Epoch[45] Batch [1180]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.091679,	
2017-06-26 22:09:46,752 Epoch[45] Batch [1190]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.091577,	
2017-06-26 22:09:52,017 Epoch[45] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091557,	
2017-06-26 22:09:57,841 Epoch[45] Batch [1210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.091545,	
2017-06-26 22:10:03,143 Epoch[45] Batch [1220]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091622,	
2017-06-26 22:10:08,470 Epoch[45] Batch [1230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091625,	
2017-06-26 22:10:13,831 Epoch[45] Batch [1240]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091614,	
2017-06-26 22:10:19,156 Epoch[45] Batch [1250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091550,	
2017-06-26 22:10:24,464 Epoch[45] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091552,	
2017-06-26 22:10:29,847 Epoch[45] Batch [1270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091648,	
2017-06-26 22:10:35,163 Epoch[45] Batch [1280]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091600,	
2017-06-26 22:10:40,595 Epoch[45] Batch [1290]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091601,	
2017-06-26 22:10:45,857 Epoch[45] Batch [1300]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091598,	
2017-06-26 22:10:51,364 Epoch[45] Batch [1310]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.091560,	
2017-06-26 22:10:56,618 Epoch[45] Batch [1320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.091607,	
2017-06-26 22:11:02,052 Epoch[45] Batch [1330]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091712,	
2017-06-26 22:11:07,514 Epoch[45] Batch [1340]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.091689,	
2017-06-26 22:11:12,846 Epoch[45] Batch [1350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091635,	
2017-06-26 22:11:18,143 Epoch[45] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091649,	
2017-06-26 22:11:23,506 Epoch[45] Batch [1370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091654,	
2017-06-26 22:11:28,771 Epoch[45] Batch [1380]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091608,	
2017-06-26 22:11:34,186 Epoch[45] Batch [1390]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091687,	
2017-06-26 22:11:39,471 Epoch[45] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091719,	
2017-06-26 22:11:44,795 Epoch[45] Batch [1410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091772,	
2017-06-26 22:11:50,208 Epoch[45] Batch [1420]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091745,	
2017-06-26 22:11:55,581 Epoch[45] Batch [1430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091781,	
2017-06-26 22:12:00,884 Epoch[45] Batch [1440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091853,	
2017-06-26 22:12:06,230 Epoch[45] Batch [1450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091791,	
2017-06-26 22:12:11,572 Epoch[45] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091840,	
2017-06-26 22:12:16,926 Epoch[45] Batch [1470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091886,	
2017-06-26 22:12:22,368 Epoch[45] Batch [1480]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091889,	
2017-06-26 22:12:25,448 Epoch[45] Train-FCNLogLoss=0.091968
2017-06-26 22:12:25,449 Epoch[45] Time cost=810.896
2017-06-26 22:12:26,751 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0046.params"
2017-06-26 22:12:30,529 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0046.states"
2017-06-26 22:12:37,161 Epoch[46] Batch [10]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086698,	
2017-06-26 22:12:42,562 Epoch[46] Batch [20]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088945,	
2017-06-26 22:12:48,186 Epoch[46] Batch [30]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.090603,	
2017-06-26 22:12:53,505 Epoch[46] Batch [40]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089656,	
2017-06-26 22:12:59,180 Epoch[46] Batch [50]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.090404,	
2017-06-26 22:13:05,024 Epoch[46] Batch [60]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.089589,	
2017-06-26 22:13:10,840 Epoch[46] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.090467,	
2017-06-26 22:13:16,231 Epoch[46] Batch [80]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089099,	
2017-06-26 22:13:21,560 Epoch[46] Batch [90]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088948,	
2017-06-26 22:13:26,949 Epoch[46] Batch [100]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089794,	
2017-06-26 22:13:32,573 Epoch[46] Batch [110]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.089506,	
2017-06-26 22:13:37,940 Epoch[46] Batch [120]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089500,	
2017-06-26 22:13:43,184 Epoch[46] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089514,	
2017-06-26 22:13:48,499 Epoch[46] Batch [140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088949,	
2017-06-26 22:13:53,813 Epoch[46] Batch [150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088965,	
2017-06-26 22:13:59,222 Epoch[46] Batch [160]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088853,	
2017-06-26 22:14:04,550 Epoch[46] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-26 22:14:10,068 Epoch[46] Batch [180]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088665,	
2017-06-26 22:14:15,459 Epoch[46] Batch [190]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088885,	
2017-06-26 22:14:21,015 Epoch[46] Batch [200]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088904,	
2017-06-26 22:14:26,284 Epoch[46] Batch [210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088898,	
2017-06-26 22:14:32,043 Epoch[46] Batch [220]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088690,	
2017-06-26 22:14:37,645 Epoch[46] Batch [230]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.089149,	
2017-06-26 22:14:43,301 Epoch[46] Batch [240]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.089441,	
2017-06-26 22:14:48,667 Epoch[46] Batch [250]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089469,	
2017-06-26 22:14:54,160 Epoch[46] Batch [260]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.089613,	
2017-06-26 22:14:59,513 Epoch[46] Batch [270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089495,	
2017-06-26 22:15:05,007 Epoch[46] Batch [280]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.089375,	
2017-06-26 22:15:10,632 Epoch[46] Batch [290]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.089447,	
2017-06-26 22:15:16,553 Epoch[46] Batch [300]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.089852,	
2017-06-26 22:15:21,918 Epoch[46] Batch [310]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090195,	
2017-06-26 22:15:28,125 Epoch[46] Batch [320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.090159,	
2017-06-26 22:15:34,434 Epoch[46] Batch [330]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.090120,	
2017-06-26 22:15:40,087 Epoch[46] Batch [340]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.090143,	
2017-06-26 22:15:45,500 Epoch[46] Batch [350]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090144,	
2017-06-26 22:15:51,006 Epoch[46] Batch [360]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.090408,	
2017-06-26 22:15:56,498 Epoch[46] Batch [370]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090580,	
2017-06-26 22:16:01,927 Epoch[46] Batch [380]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090461,	
2017-06-26 22:16:07,177 Epoch[46] Batch [390]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090595,	
2017-06-26 22:16:12,558 Epoch[46] Batch [400]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090657,	
2017-06-26 22:16:17,935 Epoch[46] Batch [410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090701,	
2017-06-26 22:16:23,271 Epoch[46] Batch [420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090870,	
2017-06-26 22:16:28,568 Epoch[46] Batch [430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090807,	
2017-06-26 22:16:34,058 Epoch[46] Batch [440]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.090766,	
2017-06-26 22:16:39,787 Epoch[46] Batch [450]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.090645,	
2017-06-26 22:16:45,571 Epoch[46] Batch [460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.090983,	
2017-06-26 22:16:50,926 Epoch[46] Batch [470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090991,	
2017-06-26 22:16:56,301 Epoch[46] Batch [480]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091202,	
2017-06-26 22:17:01,662 Epoch[46] Batch [490]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091136,	
2017-06-26 22:17:07,102 Epoch[46] Batch [500]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091108,	
2017-06-26 22:17:12,314 Epoch[46] Batch [510]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.091039,	
2017-06-26 22:17:17,698 Epoch[46] Batch [520]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091117,	
2017-06-26 22:17:23,216 Epoch[46] Batch [530]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.091173,	
2017-06-26 22:17:28,896 Epoch[46] Batch [540]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.091271,	
2017-06-26 22:17:34,432 Epoch[46] Batch [550]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.091126,	
2017-06-26 22:17:39,821 Epoch[46] Batch [560]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091081,	
2017-06-26 22:17:45,140 Epoch[46] Batch [570]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091170,	
2017-06-26 22:17:50,539 Epoch[46] Batch [580]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091094,	
2017-06-26 22:17:55,846 Epoch[46] Batch [590]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091162,	
2017-06-26 22:18:01,767 Epoch[46] Batch [600]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.091232,	
2017-06-26 22:18:07,364 Epoch[46] Batch [610]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.091282,	
2017-06-26 22:18:12,706 Epoch[46] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091276,	
2017-06-26 22:18:18,091 Epoch[46] Batch [630]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091391,	
2017-06-26 22:18:23,505 Epoch[46] Batch [640]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091426,	
2017-06-26 22:18:29,088 Epoch[46] Batch [650]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.091402,	
2017-06-26 22:18:34,642 Epoch[46] Batch [660]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.091354,	
2017-06-26 22:18:40,792 Epoch[46] Batch [670]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.091227,	
2017-06-26 22:18:46,292 Epoch[46] Batch [680]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.091274,	
2017-06-26 22:18:52,191 Epoch[46] Batch [690]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.091273,	
2017-06-26 22:18:57,793 Epoch[46] Batch [700]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.091167,	
2017-06-26 22:19:03,390 Epoch[46] Batch [710]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.091259,	
2017-06-26 22:19:09,027 Epoch[46] Batch [720]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.091405,	
2017-06-26 22:19:15,599 Epoch[46] Batch [730]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.091365,	
2017-06-26 22:19:21,422 Epoch[46] Batch [740]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.091466,	
2017-06-26 22:19:27,321 Epoch[46] Batch [750]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.091425,	
2017-06-26 22:19:32,862 Epoch[46] Batch [760]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.091401,	
2017-06-26 22:19:38,393 Epoch[46] Batch [770]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.091323,	
2017-06-26 22:19:43,761 Epoch[46] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091353,	
2017-06-26 22:19:49,317 Epoch[46] Batch [790]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.091295,	
2017-06-26 22:19:54,753 Epoch[46] Batch [800]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091385,	
2017-06-26 22:20:00,522 Epoch[46] Batch [810]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.091412,	
2017-06-26 22:20:05,947 Epoch[46] Batch [820]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.091405,	
2017-06-26 22:20:11,839 Epoch[46] Batch [830]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.091371,	
2017-06-26 22:20:17,438 Epoch[46] Batch [840]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.091367,	
2017-06-26 22:20:23,280 Epoch[46] Batch [850]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.091405,	
2017-06-26 22:20:28,555 Epoch[46] Batch [860]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091281,	
2017-06-26 22:20:33,930 Epoch[46] Batch [870]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091228,	
2017-06-26 22:20:39,201 Epoch[46] Batch [880]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091076,	
2017-06-26 22:20:44,533 Epoch[46] Batch [890]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091170,	
2017-06-26 22:20:50,151 Epoch[46] Batch [900]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.091266,	
2017-06-26 22:20:55,773 Epoch[46] Batch [910]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.091237,	
2017-06-26 22:21:01,117 Epoch[46] Batch [920]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091310,	
2017-06-26 22:21:06,732 Epoch[46] Batch [930]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.091337,	
2017-06-26 22:21:12,672 Epoch[46] Batch [940]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.091274,	
2017-06-26 22:21:18,149 Epoch[46] Batch [950]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.091105,	
2017-06-26 22:21:23,420 Epoch[46] Batch [960]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091154,	
2017-06-26 22:21:29,588 Epoch[46] Batch [970]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.091239,	
2017-06-26 22:21:35,203 Epoch[46] Batch [980]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.091241,	
2017-06-26 22:21:40,834 Epoch[46] Batch [990]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.091283,	
2017-06-26 22:21:46,402 Epoch[46] Batch [1000]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.091274,	
2017-06-26 22:21:51,705 Epoch[46] Batch [1010]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091317,	
2017-06-26 22:21:57,013 Epoch[46] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091311,	
2017-06-26 22:22:02,338 Epoch[46] Batch [1030]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091323,	
2017-06-26 22:22:07,655 Epoch[46] Batch [1040]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091383,	
2017-06-26 22:22:13,005 Epoch[46] Batch [1050]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091394,	
2017-06-26 22:22:18,303 Epoch[46] Batch [1060]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091395,	
2017-06-26 22:22:23,630 Epoch[46] Batch [1070]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091360,	
2017-06-26 22:22:28,922 Epoch[46] Batch [1080]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091341,	
2017-06-26 22:22:34,310 Epoch[46] Batch [1090]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091331,	
2017-06-26 22:22:39,645 Epoch[46] Batch [1100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091362,	
2017-06-26 22:22:44,952 Epoch[46] Batch [1110]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091394,	
2017-06-26 22:22:50,291 Epoch[46] Batch [1120]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091433,	
2017-06-26 22:22:55,630 Epoch[46] Batch [1130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091459,	
2017-06-26 22:23:00,922 Epoch[46] Batch [1140]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091493,	
2017-06-26 22:23:06,291 Epoch[46] Batch [1150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091597,	
2017-06-26 22:23:11,621 Epoch[46] Batch [1160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091553,	
2017-06-26 22:23:16,952 Epoch[46] Batch [1170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091610,	
2017-06-26 22:23:22,307 Epoch[46] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091541,	
2017-06-26 22:23:27,649 Epoch[46] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091582,	
2017-06-26 22:23:32,976 Epoch[46] Batch [1200]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091628,	
2017-06-26 22:23:38,354 Epoch[46] Batch [1210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091606,	
2017-06-26 22:23:43,713 Epoch[46] Batch [1220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091623,	
2017-06-26 22:23:49,020 Epoch[46] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091574,	
2017-06-26 22:23:54,635 Epoch[46] Batch [1240]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.091629,	
2017-06-26 22:23:59,913 Epoch[46] Batch [1250]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091650,	
2017-06-26 22:24:05,241 Epoch[46] Batch [1260]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091658,	
2017-06-26 22:24:10,725 Epoch[46] Batch [1270]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.091596,	
2017-06-26 22:24:16,045 Epoch[46] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091657,	
2017-06-26 22:24:21,329 Epoch[46] Batch [1290]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091701,	
2017-06-26 22:24:26,786 Epoch[46] Batch [1300]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091746,	
2017-06-26 22:24:32,255 Epoch[46] Batch [1310]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.091733,	
2017-06-26 22:24:37,562 Epoch[46] Batch [1320]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091760,	
2017-06-26 22:24:42,889 Epoch[46] Batch [1330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091777,	
2017-06-26 22:24:48,212 Epoch[46] Batch [1340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091779,	
2017-06-26 22:24:53,819 Epoch[46] Batch [1350]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.091744,	
2017-06-26 22:24:59,113 Epoch[46] Batch [1360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091657,	
2017-06-26 22:25:04,485 Epoch[46] Batch [1370]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091635,	
2017-06-26 22:25:09,929 Epoch[46] Batch [1380]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091671,	
2017-06-26 22:25:15,247 Epoch[46] Batch [1390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091648,	
2017-06-26 22:25:20,575 Epoch[46] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091648,	
2017-06-26 22:25:26,103 Epoch[46] Batch [1410]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.091585,	
2017-06-26 22:25:31,433 Epoch[46] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091598,	
2017-06-26 22:25:36,726 Epoch[46] Batch [1430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091514,	
2017-06-26 22:25:42,122 Epoch[46] Batch [1440]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091587,	
2017-06-26 22:25:47,497 Epoch[46] Batch [1450]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091624,	
2017-06-26 22:25:52,832 Epoch[46] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091589,	
2017-06-26 22:25:58,181 Epoch[46] Batch [1470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091577,	
2017-06-26 22:26:03,520 Epoch[46] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091644,	
2017-06-26 22:26:06,868 Epoch[46] Train-FCNLogLoss=0.091693
2017-06-26 22:26:06,868 Epoch[46] Time cost=816.338
2017-06-26 22:26:07,630 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0047.params"
2017-06-26 22:26:09,429 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0047.states"
2017-06-26 22:26:15,645 Epoch[47] Batch [10]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093627,	
2017-06-26 22:26:20,968 Epoch[47] Batch [20]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092480,	
2017-06-26 22:26:26,303 Epoch[47] Batch [30]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094409,	
2017-06-26 22:26:31,650 Epoch[47] Batch [40]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094282,	
2017-06-26 22:26:36,945 Epoch[47] Batch [50]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092451,	
2017-06-26 22:26:42,276 Epoch[47] Batch [60]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091693,	
2017-06-26 22:26:47,769 Epoch[47] Batch [70]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.091907,	
2017-06-26 22:26:53,073 Epoch[47] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091559,	
2017-06-26 22:26:58,391 Epoch[47] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092395,	
2017-06-26 22:27:03,742 Epoch[47] Batch [100]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091752,	
2017-06-26 22:27:09,094 Epoch[47] Batch [110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093071,	
2017-06-26 22:27:14,439 Epoch[47] Batch [120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093334,	
2017-06-26 22:27:19,759 Epoch[47] Batch [130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093116,	
2017-06-26 22:27:25,093 Epoch[47] Batch [140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093395,	
2017-06-26 22:27:30,462 Epoch[47] Batch [150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093296,	
2017-06-26 22:27:35,779 Epoch[47] Batch [160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092799,	
2017-06-26 22:27:41,280 Epoch[47] Batch [170]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092703,	
2017-06-26 22:27:46,584 Epoch[47] Batch [180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092601,	
2017-06-26 22:27:51,909 Epoch[47] Batch [190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092659,	
2017-06-26 22:27:57,283 Epoch[47] Batch [200]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092897,	
2017-06-26 22:28:02,605 Epoch[47] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092750,	
2017-06-26 22:28:07,941 Epoch[47] Batch [220]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092201,	
2017-06-26 22:28:13,280 Epoch[47] Batch [230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091967,	
2017-06-26 22:28:18,667 Epoch[47] Batch [240]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091742,	
2017-06-26 22:28:23,958 Epoch[47] Batch [250]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091764,	
2017-06-26 22:28:29,279 Epoch[47] Batch [260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091771,	
2017-06-26 22:28:34,686 Epoch[47] Batch [270]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.091674,	
2017-06-26 22:28:39,996 Epoch[47] Batch [280]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091627,	
2017-06-26 22:28:45,291 Epoch[47] Batch [290]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091720,	
2017-06-26 22:28:50,642 Epoch[47] Batch [300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092024,	
2017-06-26 22:28:55,994 Epoch[47] Batch [310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091953,	
2017-06-26 22:29:01,293 Epoch[47] Batch [320]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091892,	
2017-06-26 22:29:06,657 Epoch[47] Batch [330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092047,	
2017-06-26 22:29:11,935 Epoch[47] Batch [340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091980,	
2017-06-26 22:29:17,302 Epoch[47] Batch [350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092200,	
2017-06-26 22:29:22,652 Epoch[47] Batch [360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092029,	
2017-06-26 22:29:27,968 Epoch[47] Batch [370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091708,	
2017-06-26 22:29:33,319 Epoch[47] Batch [380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091588,	
2017-06-26 22:29:38,672 Epoch[47] Batch [390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091321,	
2017-06-26 22:29:43,956 Epoch[47] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091566,	
2017-06-26 22:29:49,332 Epoch[47] Batch [410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091380,	
2017-06-26 22:29:54,660 Epoch[47] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091456,	
2017-06-26 22:29:59,963 Epoch[47] Batch [430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091526,	
2017-06-26 22:30:05,300 Epoch[47] Batch [440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091219,	
2017-06-26 22:30:10,615 Epoch[47] Batch [450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091307,	
2017-06-26 22:30:15,936 Epoch[47] Batch [460]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091136,	
2017-06-26 22:30:21,338 Epoch[47] Batch [470]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091176,	
2017-06-26 22:30:26,635 Epoch[47] Batch [480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091065,	
2017-06-26 22:30:31,963 Epoch[47] Batch [490]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091154,	
2017-06-26 22:30:37,291 Epoch[47] Batch [500]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090939,	
2017-06-26 22:30:42,660 Epoch[47] Batch [510]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090919,	
2017-06-26 22:30:47,923 Epoch[47] Batch [520]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091071,	
2017-06-26 22:30:53,300 Epoch[47] Batch [530]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090909,	
2017-06-26 22:30:58,618 Epoch[47] Batch [540]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090770,	
2017-06-26 22:31:03,961 Epoch[47] Batch [550]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090789,	
2017-06-26 22:31:09,283 Epoch[47] Batch [560]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090696,	
2017-06-26 22:31:14,597 Epoch[47] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090848,	
2017-06-26 22:31:19,962 Epoch[47] Batch [580]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090908,	
2017-06-26 22:31:25,370 Epoch[47] Batch [590]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090961,	
2017-06-26 22:31:30,659 Epoch[47] Batch [600]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090973,	
2017-06-26 22:31:36,044 Epoch[47] Batch [610]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091041,	
2017-06-26 22:31:41,336 Epoch[47] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091046,	
2017-06-26 22:31:46,687 Epoch[47] Batch [630]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091010,	
2017-06-26 22:31:52,027 Epoch[47] Batch [640]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091206,	
2017-06-26 22:31:57,363 Epoch[47] Batch [650]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091358,	
2017-06-26 22:32:02,673 Epoch[47] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091546,	
2017-06-26 22:32:08,031 Epoch[47] Batch [670]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091734,	
2017-06-26 22:32:13,508 Epoch[47] Batch [680]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.091630,	
2017-06-26 22:32:18,814 Epoch[47] Batch [690]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091698,	
2017-06-26 22:32:24,139 Epoch[47] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091649,	
2017-06-26 22:32:29,532 Epoch[47] Batch [710]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091760,	
2017-06-26 22:32:34,852 Epoch[47] Batch [720]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091736,	
2017-06-26 22:32:40,180 Epoch[47] Batch [730]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091828,	
2017-06-26 22:32:45,683 Epoch[47] Batch [740]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.091936,	
2017-06-26 22:32:51,039 Epoch[47] Batch [750]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091824,	
2017-06-26 22:32:56,426 Epoch[47] Batch [760]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091960,	
2017-06-26 22:33:01,788 Epoch[47] Batch [770]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091937,	
2017-06-26 22:33:07,110 Epoch[47] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091800,	
2017-06-26 22:33:12,444 Epoch[47] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091894,	
2017-06-26 22:33:17,876 Epoch[47] Batch [800]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091831,	
2017-06-26 22:33:23,315 Epoch[47] Batch [810]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091728,	
2017-06-26 22:33:28,627 Epoch[47] Batch [820]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091659,	
2017-06-26 22:33:34,009 Epoch[47] Batch [830]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091606,	
2017-06-26 22:33:39,520 Epoch[47] Batch [840]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.091538,	
2017-06-26 22:33:44,875 Epoch[47] Batch [850]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091587,	
2017-06-26 22:33:50,254 Epoch[47] Batch [860]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091468,	
2017-06-26 22:33:55,618 Epoch[47] Batch [870]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091330,	
2017-06-26 22:34:00,931 Epoch[47] Batch [880]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091240,	
2017-06-26 22:34:06,466 Epoch[47] Batch [890]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.091169,	
2017-06-26 22:34:11,840 Epoch[47] Batch [900]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091199,	
2017-06-26 22:34:17,088 Epoch[47] Batch [910]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.091199,	
2017-06-26 22:34:22,577 Epoch[47] Batch [920]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.091164,	
2017-06-26 22:34:27,940 Epoch[47] Batch [930]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091187,	
2017-06-26 22:34:33,284 Epoch[47] Batch [940]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091193,	
2017-06-26 22:34:38,659 Epoch[47] Batch [950]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091221,	
2017-06-26 22:34:43,135 Epoch[47] Batch [960]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091191,	
2017-06-26 22:34:48,477 Epoch[47] Batch [970]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091181,	
2017-06-26 22:34:53,785 Epoch[47] Batch [980]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091133,	
2017-06-26 22:34:59,189 Epoch[47] Batch [990]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.091091,	
2017-06-26 22:35:04,493 Epoch[47] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091114,	
2017-06-26 22:35:09,796 Epoch[47] Batch [1010]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091087,	
2017-06-26 22:35:15,171 Epoch[47] Batch [1020]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091014,	
2017-06-26 22:35:20,462 Epoch[47] Batch [1030]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090933,	
2017-06-26 22:35:25,863 Epoch[47] Batch [1040]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090838,	
2017-06-26 22:35:31,187 Epoch[47] Batch [1050]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090852,	
2017-06-26 22:35:36,553 Epoch[47] Batch [1060]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090947,	
2017-06-26 22:35:41,891 Epoch[47] Batch [1070]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090942,	
2017-06-26 22:35:47,286 Epoch[47] Batch [1080]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090865,	
2017-06-26 22:35:52,662 Epoch[47] Batch [1090]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090897,	
2017-06-26 22:35:57,917 Epoch[47] Batch [1100]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090919,	
2017-06-26 22:36:03,359 Epoch[47] Batch [1110]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.090920,	
2017-06-26 22:36:08,664 Epoch[47] Batch [1120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090889,	
2017-06-26 22:36:13,999 Epoch[47] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090986,	
2017-06-26 22:36:19,362 Epoch[47] Batch [1140]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090959,	
2017-06-26 22:36:24,710 Epoch[47] Batch [1150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090946,	
2017-06-26 22:36:30,135 Epoch[47] Batch [1160]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090908,	
2017-06-26 22:36:35,469 Epoch[47] Batch [1170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090859,	
2017-06-26 22:36:40,808 Epoch[47] Batch [1180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090883,	
2017-06-26 22:36:46,179 Epoch[47] Batch [1190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090885,	
2017-06-26 22:36:51,468 Epoch[47] Batch [1200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090904,	
2017-06-26 22:36:56,828 Epoch[47] Batch [1210]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090896,	
2017-06-26 22:37:02,169 Epoch[47] Batch [1220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090976,	
2017-06-26 22:37:07,501 Epoch[47] Batch [1230]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090972,	
2017-06-26 22:37:12,925 Epoch[47] Batch [1240]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.091015,	
2017-06-26 22:37:18,265 Epoch[47] Batch [1250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091127,	
2017-06-26 22:37:23,580 Epoch[47] Batch [1260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091093,	
2017-06-26 22:37:28,869 Epoch[47] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091150,	
2017-06-26 22:37:34,250 Epoch[47] Batch [1280]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091113,	
2017-06-26 22:37:39,599 Epoch[47] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091158,	
2017-06-26 22:37:44,905 Epoch[47] Batch [1300]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091074,	
2017-06-26 22:37:50,237 Epoch[47] Batch [1310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091116,	
2017-06-26 22:37:55,558 Epoch[47] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091141,	
2017-06-26 22:38:00,889 Epoch[47] Batch [1330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091114,	
2017-06-26 22:38:06,248 Epoch[47] Batch [1340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091075,	
2017-06-26 22:38:11,572 Epoch[47] Batch [1350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091113,	
2017-06-26 22:38:16,923 Epoch[47] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091209,	
2017-06-26 22:38:22,225 Epoch[47] Batch [1370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091298,	
2017-06-26 22:38:27,599 Epoch[47] Batch [1380]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091330,	
2017-06-26 22:38:32,904 Epoch[47] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091289,	
2017-06-26 22:38:38,232 Epoch[47] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091336,	
2017-06-26 22:38:43,577 Epoch[47] Batch [1410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091323,	
2017-06-26 22:38:48,945 Epoch[47] Batch [1420]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091242,	
2017-06-26 22:38:54,262 Epoch[47] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091167,	
2017-06-26 22:38:59,555 Epoch[47] Batch [1440]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091172,	
2017-06-26 22:39:04,936 Epoch[47] Batch [1450]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091173,	
2017-06-26 22:39:10,245 Epoch[47] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091141,	
2017-06-26 22:39:15,610 Epoch[47] Batch [1470]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091137,	
2017-06-26 22:39:20,931 Epoch[47] Batch [1480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091171,	
2017-06-26 22:39:24,110 Epoch[47] Train-FCNLogLoss=0.091125
2017-06-26 22:39:24,110 Epoch[47] Time cost=794.680
2017-06-26 22:39:24,905 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0048.params"
2017-06-26 22:39:27,131 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0048.states"
2017-06-26 22:39:33,198 Epoch[48] Batch [10]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089342,	
2017-06-26 22:39:38,480 Epoch[48] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091843,	
2017-06-26 22:39:43,829 Epoch[48] Batch [30]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092719,	
2017-06-26 22:39:49,120 Epoch[48] Batch [40]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093074,	
2017-06-26 22:39:54,445 Epoch[48] Batch [50]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092782,	
2017-06-26 22:39:59,826 Epoch[48] Batch [60]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092680,	
2017-06-26 22:40:05,169 Epoch[48] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094555,	
2017-06-26 22:40:10,470 Epoch[48] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094231,	
2017-06-26 22:40:15,851 Epoch[48] Batch [90]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093552,	
2017-06-26 22:40:21,189 Epoch[48] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092570,	
2017-06-26 22:40:26,539 Epoch[48] Batch [110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092668,	
2017-06-26 22:40:31,840 Epoch[48] Batch [120]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092437,	
2017-06-26 22:40:37,207 Epoch[48] Batch [130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092935,	
2017-06-26 22:40:42,476 Epoch[48] Batch [140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093451,	
2017-06-26 22:40:47,838 Epoch[48] Batch [150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094022,	
2017-06-26 22:40:53,316 Epoch[48] Batch [160]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094054,	
2017-06-26 22:40:58,644 Epoch[48] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094168,	
2017-06-26 22:41:03,958 Epoch[48] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094349,	
2017-06-26 22:41:09,320 Epoch[48] Batch [190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094997,	
2017-06-26 22:41:14,834 Epoch[48] Batch [200]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.094862,	
2017-06-26 22:41:20,126 Epoch[48] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094925,	
2017-06-26 22:41:25,495 Epoch[48] Batch [220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095007,	
2017-06-26 22:41:30,825 Epoch[48] Batch [230]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095119,	
2017-06-26 22:41:36,229 Epoch[48] Batch [240]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.095064,	
2017-06-26 22:41:41,554 Epoch[48] Batch [250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095017,	
2017-06-26 22:41:46,895 Epoch[48] Batch [260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094888,	
2017-06-26 22:41:52,240 Epoch[48] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094587,	
2017-06-26 22:41:57,595 Epoch[48] Batch [280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094809,	
2017-06-26 22:42:03,186 Epoch[48] Batch [290]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.094963,	
2017-06-26 22:42:08,455 Epoch[48] Batch [300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094863,	
2017-06-26 22:42:13,865 Epoch[48] Batch [310]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094678,	
2017-06-26 22:42:19,231 Epoch[48] Batch [320]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094449,	
2017-06-26 22:42:24,618 Epoch[48] Batch [330]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.094548,	
2017-06-26 22:42:30,051 Epoch[48] Batch [340]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094542,	
2017-06-26 22:42:35,471 Epoch[48] Batch [350]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.094398,	
2017-06-26 22:42:40,833 Epoch[48] Batch [360]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094443,	
2017-06-26 22:42:46,146 Epoch[48] Batch [370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094429,	
2017-06-26 22:42:51,603 Epoch[48] Batch [380]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094314,	
2017-06-26 22:42:56,954 Epoch[48] Batch [390]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094207,	
2017-06-26 22:43:02,294 Epoch[48] Batch [400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093924,	
2017-06-26 22:43:07,649 Epoch[48] Batch [410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093867,	
2017-06-26 22:43:13,098 Epoch[48] Batch [420]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093707,	
2017-06-26 22:43:18,532 Epoch[48] Batch [430]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093432,	
2017-06-26 22:43:23,872 Epoch[48] Batch [440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093201,	
2017-06-26 22:43:29,200 Epoch[48] Batch [450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093167,	
2017-06-26 22:43:34,515 Epoch[48] Batch [460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093072,	
2017-06-26 22:43:39,888 Epoch[48] Batch [470]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093034,	
2017-06-26 22:43:45,381 Epoch[48] Batch [480]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.092870,	
2017-06-26 22:43:50,670 Epoch[48] Batch [490]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092836,	
2017-06-26 22:43:56,019 Epoch[48] Batch [500]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092668,	
2017-06-26 22:44:01,346 Epoch[48] Batch [510]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092530,	
2017-06-26 22:44:06,710 Epoch[48] Batch [520]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092624,	
2017-06-26 22:44:12,060 Epoch[48] Batch [530]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092479,	
2017-06-26 22:44:17,483 Epoch[48] Batch [540]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092402,	
2017-06-26 22:44:22,815 Epoch[48] Batch [550]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092450,	
2017-06-26 22:44:28,159 Epoch[48] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092499,	
2017-06-26 22:44:33,499 Epoch[48] Batch [570]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092531,	
2017-06-26 22:44:38,798 Epoch[48] Batch [580]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092498,	
2017-06-26 22:44:44,180 Epoch[48] Batch [590]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092428,	
2017-06-26 22:44:49,464 Epoch[48] Batch [600]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092311,	
2017-06-26 22:44:54,872 Epoch[48] Batch [610]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092263,	
2017-06-26 22:45:00,183 Epoch[48] Batch [620]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092099,	
2017-06-26 22:45:05,524 Epoch[48] Batch [630]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092106,	
2017-06-26 22:45:10,873 Epoch[48] Batch [640]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092120,	
2017-06-26 22:45:16,206 Epoch[48] Batch [650]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092018,	
2017-06-26 22:45:21,505 Epoch[48] Batch [660]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091934,	
2017-06-26 22:45:26,859 Epoch[48] Batch [670]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091960,	
2017-06-26 22:45:32,174 Epoch[48] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091886,	
2017-06-26 22:45:37,514 Epoch[48] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091823,	
2017-06-26 22:45:42,871 Epoch[48] Batch [700]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091788,	
2017-06-26 22:45:48,175 Epoch[48] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091767,	
2017-06-26 22:45:53,526 Epoch[48] Batch [720]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091786,	
2017-06-26 22:45:58,883 Epoch[48] Batch [730]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091692,	
2017-06-26 22:46:04,240 Epoch[48] Batch [740]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091757,	
2017-06-26 22:46:09,535 Epoch[48] Batch [750]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091656,	
2017-06-26 22:46:14,884 Epoch[48] Batch [760]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091596,	
2017-06-26 22:46:20,242 Epoch[48] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091435,	
2017-06-26 22:46:25,558 Epoch[48] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091463,	
2017-06-26 22:46:30,900 Epoch[48] Batch [790]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091447,	
2017-06-26 22:46:36,229 Epoch[48] Batch [800]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091540,	
2017-06-26 22:46:41,540 Epoch[48] Batch [810]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091528,	
2017-06-26 22:46:46,916 Epoch[48] Batch [820]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091703,	
2017-06-26 22:46:52,258 Epoch[48] Batch [830]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091699,	
2017-06-26 22:46:57,536 Epoch[48] Batch [840]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091557,	
2017-06-26 22:47:02,903 Epoch[48] Batch [850]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091494,	
2017-06-26 22:47:08,280 Epoch[48] Batch [860]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091498,	
2017-06-26 22:47:13,592 Epoch[48] Batch [870]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091467,	
2017-06-26 22:47:18,902 Epoch[48] Batch [880]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091439,	
2017-06-26 22:47:24,249 Epoch[48] Batch [890]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091364,	
2017-06-26 22:47:29,563 Epoch[48] Batch [900]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091416,	
2017-06-26 22:47:34,928 Epoch[48] Batch [910]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091344,	
2017-06-26 22:47:40,199 Epoch[48] Batch [920]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091329,	
2017-06-26 22:47:45,557 Epoch[48] Batch [930]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091340,	
2017-06-26 22:47:50,933 Epoch[48] Batch [940]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091425,	
2017-06-26 22:47:56,265 Epoch[48] Batch [950]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091310,	
2017-06-26 22:48:01,081 Epoch[48] Batch [960]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091314,	
2017-06-26 22:48:06,332 Epoch[48] Batch [970]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.091333,	
2017-06-26 22:48:11,679 Epoch[48] Batch [980]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091478,	
2017-06-26 22:48:16,990 Epoch[48] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091451,	
2017-06-26 22:48:22,330 Epoch[48] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091530,	
2017-06-26 22:48:27,676 Epoch[48] Batch [1010]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091531,	
2017-06-26 22:48:33,010 Epoch[48] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091451,	
2017-06-26 22:48:38,375 Epoch[48] Batch [1030]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091360,	
2017-06-26 22:48:43,670 Epoch[48] Batch [1040]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091339,	
2017-06-26 22:48:49,040 Epoch[48] Batch [1050]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091409,	
2017-06-26 22:48:54,395 Epoch[48] Batch [1060]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091334,	
2017-06-26 22:48:59,710 Epoch[48] Batch [1070]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091406,	
2017-06-26 22:49:05,032 Epoch[48] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091366,	
2017-06-26 22:49:10,387 Epoch[48] Batch [1090]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091357,	
2017-06-26 22:49:15,717 Epoch[48] Batch [1100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091363,	
2017-06-26 22:49:21,081 Epoch[48] Batch [1110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091326,	
2017-06-26 22:49:26,432 Epoch[48] Batch [1120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091335,	
2017-06-26 22:49:31,764 Epoch[48] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091352,	
2017-06-26 22:49:37,069 Epoch[48] Batch [1140]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091365,	
2017-06-26 22:49:42,402 Epoch[48] Batch [1150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091368,	
2017-06-26 22:49:47,730 Epoch[48] Batch [1160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091366,	
2017-06-26 22:49:53,089 Epoch[48] Batch [1170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091384,	
2017-06-26 22:49:58,503 Epoch[48] Batch [1180]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091394,	
2017-06-26 22:50:03,833 Epoch[48] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091363,	
2017-06-26 22:50:09,284 Epoch[48] Batch [1200]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.091365,	
2017-06-26 22:50:14,625 Epoch[48] Batch [1210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091383,	
2017-06-26 22:50:20,000 Epoch[48] Batch [1220]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091307,	
2017-06-26 22:50:25,366 Epoch[48] Batch [1230]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091351,	
2017-06-26 22:50:30,685 Epoch[48] Batch [1240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091426,	
2017-06-26 22:50:36,055 Epoch[48] Batch [1250]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091478,	
2017-06-26 22:50:41,454 Epoch[48] Batch [1260]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091466,	
2017-06-26 22:50:46,825 Epoch[48] Batch [1270]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091453,	
2017-06-26 22:50:52,272 Epoch[48] Batch [1280]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.091439,	
2017-06-26 22:50:57,658 Epoch[48] Batch [1290]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091499,	
2017-06-26 22:51:03,114 Epoch[48] Batch [1300]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091400,	
2017-06-26 22:51:08,433 Epoch[48] Batch [1310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091312,	
2017-06-26 22:51:13,822 Epoch[48] Batch [1320]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091302,	
2017-06-26 22:51:19,306 Epoch[48] Batch [1330]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.091296,	
2017-06-26 22:51:24,643 Epoch[48] Batch [1340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091297,	
2017-06-26 22:51:30,007 Epoch[48] Batch [1350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091417,	
2017-06-26 22:51:35,559 Epoch[48] Batch [1360]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.091413,	
2017-06-26 22:51:40,888 Epoch[48] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091348,	
2017-06-26 22:51:46,345 Epoch[48] Batch [1380]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091319,	
2017-06-26 22:51:51,681 Epoch[48] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091358,	
2017-06-26 22:51:57,231 Epoch[48] Batch [1400]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.091324,	
2017-06-26 22:52:02,551 Epoch[48] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091315,	
2017-06-26 22:52:07,885 Epoch[48] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091363,	
2017-06-26 22:52:13,257 Epoch[48] Batch [1430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091257,	
2017-06-26 22:52:18,635 Epoch[48] Batch [1440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091236,	
2017-06-26 22:52:23,965 Epoch[48] Batch [1450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091171,	
2017-06-26 22:52:29,412 Epoch[48] Batch [1460]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.091132,	
2017-06-26 22:52:34,867 Epoch[48] Batch [1470]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091137,	
2017-06-26 22:52:40,145 Epoch[48] Batch [1480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091124,	
2017-06-26 22:52:43,360 Epoch[48] Train-FCNLogLoss=0.091100
2017-06-26 22:52:43,360 Epoch[48] Time cost=796.229
2017-06-26 22:52:44,106 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0049.params"
2017-06-26 22:52:46,147 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0049.states"
2017-06-26 22:52:52,217 Epoch[49] Batch [10]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094867,	
2017-06-26 22:52:57,570 Epoch[49] Batch [20]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092257,	
2017-06-26 22:53:02,972 Epoch[49] Batch [30]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089809,	
2017-06-26 22:53:08,306 Epoch[49] Batch [40]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091672,	
2017-06-26 22:53:13,705 Epoch[49] Batch [50]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092804,	
2017-06-26 22:53:19,023 Epoch[49] Batch [60]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092886,	
2017-06-26 22:53:24,344 Epoch[49] Batch [70]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090606,	
2017-06-26 22:53:29,854 Epoch[49] Batch [80]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.089584,	
2017-06-26 22:53:35,173 Epoch[49] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089621,	
2017-06-26 22:53:40,522 Epoch[49] Batch [100]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090056,	
2017-06-26 22:53:45,927 Epoch[49] Batch [110]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089589,	
2017-06-26 22:53:51,257 Epoch[49] Batch [120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091260,	
2017-06-26 22:53:56,659 Epoch[49] Batch [130]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091926,	
2017-06-26 22:54:02,018 Epoch[49] Batch [140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091503,	
2017-06-26 22:54:07,336 Epoch[49] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090559,	
2017-06-26 22:54:12,691 Epoch[49] Batch [160]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091215,	
2017-06-26 22:54:17,988 Epoch[49] Batch [170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090479,	
2017-06-26 22:54:23,380 Epoch[49] Batch [180]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090362,	
2017-06-26 22:54:28,856 Epoch[49] Batch [190]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.090309,	
2017-06-26 22:54:34,225 Epoch[49] Batch [200]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090444,	
2017-06-26 22:54:39,531 Epoch[49] Batch [210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090360,	
2017-06-26 22:54:44,847 Epoch[49] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090163,	
2017-06-26 22:54:50,158 Epoch[49] Batch [230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090144,	
2017-06-26 22:54:55,569 Epoch[49] Batch [240]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090493,	
2017-06-26 22:55:00,878 Epoch[49] Batch [250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090585,	
2017-06-26 22:55:06,199 Epoch[49] Batch [260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090453,	
2017-06-26 22:55:11,546 Epoch[49] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090451,	
2017-06-26 22:55:16,989 Epoch[49] Batch [280]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.090357,	
2017-06-26 22:55:22,304 Epoch[49] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090640,	
2017-06-26 22:55:27,610 Epoch[49] Batch [300]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090239,	
2017-06-26 22:55:32,935 Epoch[49] Batch [310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090085,	
2017-06-26 22:55:38,403 Epoch[49] Batch [320]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.090011,	
2017-06-26 22:55:43,788 Epoch[49] Batch [330]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089742,	
2017-06-26 22:55:49,072 Epoch[49] Batch [340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089998,	
2017-06-26 22:55:54,437 Epoch[49] Batch [350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090026,	
2017-06-26 22:55:59,772 Epoch[49] Batch [360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089927,	
2017-06-26 22:56:05,097 Epoch[49] Batch [370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089831,	
2017-06-26 22:56:10,488 Epoch[49] Batch [380]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090155,	
2017-06-26 22:56:15,773 Epoch[49] Batch [390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090042,	
2017-06-26 22:56:21,123 Epoch[49] Batch [400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089986,	
2017-06-26 22:56:26,424 Epoch[49] Batch [410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090024,	
2017-06-26 22:56:31,779 Epoch[49] Batch [420]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090057,	
2017-06-26 22:56:37,125 Epoch[49] Batch [430]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090145,	
2017-06-26 22:56:42,484 Epoch[49] Batch [440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090136,	
2017-06-26 22:56:47,768 Epoch[49] Batch [450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090201,	
2017-06-26 22:56:53,117 Epoch[49] Batch [460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090091,	
2017-06-26 22:56:58,476 Epoch[49] Batch [470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089916,	
2017-06-26 22:57:03,841 Epoch[49] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090009,	
2017-06-26 22:57:09,102 Epoch[49] Batch [490]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089971,	
2017-06-26 22:57:14,473 Epoch[49] Batch [500]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090010,	
2017-06-26 22:57:19,798 Epoch[49] Batch [510]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089941,	
2017-06-26 22:57:25,126 Epoch[49] Batch [520]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090088,	
2017-06-26 22:57:30,440 Epoch[49] Batch [530]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090131,	
2017-06-26 22:57:35,805 Epoch[49] Batch [540]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090065,	
2017-06-26 22:57:41,145 Epoch[49] Batch [550]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090225,	
2017-06-26 22:57:46,495 Epoch[49] Batch [560]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090304,	
2017-06-26 22:57:51,836 Epoch[49] Batch [570]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090097,	
2017-06-26 22:57:57,174 Epoch[49] Batch [580]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089981,	
2017-06-26 22:58:02,495 Epoch[49] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090056,	
2017-06-26 22:58:07,818 Epoch[49] Batch [600]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090084,	
2017-06-26 22:58:13,217 Epoch[49] Batch [610]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090019,	
2017-06-26 22:58:18,538 Epoch[49] Batch [620]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090065,	
2017-06-26 22:58:23,849 Epoch[49] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090153,	
2017-06-26 22:58:29,226 Epoch[49] Batch [640]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090139,	
2017-06-26 22:58:34,488 Epoch[49] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089991,	
2017-06-26 22:58:39,879 Epoch[49] Batch [660]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089954,	
2017-06-26 22:58:45,335 Epoch[49] Batch [670]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089996,	
2017-06-26 22:58:50,757 Epoch[49] Batch [680]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.089954,	
2017-06-26 22:58:56,077 Epoch[49] Batch [690]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090024,	
2017-06-26 22:59:01,401 Epoch[49] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-26 22:59:06,730 Epoch[49] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089889,	
2017-06-26 22:59:12,076 Epoch[49] Batch [720]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089946,	
2017-06-26 22:59:17,668 Epoch[49] Batch [730]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.089946,	
2017-06-26 22:59:22,946 Epoch[49] Batch [740]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089918,	
2017-06-26 22:59:28,312 Epoch[49] Batch [750]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089980,	
2017-06-26 22:59:33,632 Epoch[49] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089882,	
2017-06-26 22:59:39,099 Epoch[49] Batch [770]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.089749,	
2017-06-26 22:59:44,466 Epoch[49] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089862,	
2017-06-26 22:59:49,808 Epoch[49] Batch [790]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089818,	
2017-06-26 22:59:55,201 Epoch[49] Batch [800]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089805,	
2017-06-26 23:00:00,603 Epoch[49] Batch [810]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089798,	
2017-06-26 23:00:06,059 Epoch[49] Batch [820]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089938,	
2017-06-26 23:00:11,377 Epoch[49] Batch [830]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089994,	
2017-06-26 23:00:16,891 Epoch[49] Batch [840]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.090081,	
2017-06-26 23:00:22,242 Epoch[49] Batch [850]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090261,	
2017-06-26 23:00:27,608 Epoch[49] Batch [860]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090337,	
2017-06-26 23:00:32,997 Epoch[49] Batch [870]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090215,	
2017-06-26 23:00:38,491 Epoch[49] Batch [880]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090187,	
2017-06-26 23:00:43,856 Epoch[49] Batch [890]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090090,	
2017-06-26 23:00:49,201 Epoch[49] Batch [900]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090081,	
2017-06-26 23:00:54,560 Epoch[49] Batch [910]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090076,	
2017-06-26 23:00:59,846 Epoch[49] Batch [920]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090066,	
2017-06-26 23:01:05,476 Epoch[49] Batch [930]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.090092,	
2017-06-26 23:01:10,833 Epoch[49] Batch [940]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090106,	
2017-06-26 23:01:16,221 Epoch[49] Batch [950]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090166,	
2017-06-26 23:01:20,796 Epoch[49] Batch [960]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090111,	
2017-06-26 23:01:25,863 Epoch[49] Batch [970]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.090033,	
2017-06-26 23:01:31,196 Epoch[49] Batch [980]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089964,	
2017-06-26 23:01:36,570 Epoch[49] Batch [990]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090012,	
2017-06-26 23:01:41,911 Epoch[49] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089981,	
2017-06-26 23:01:47,225 Epoch[49] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090049,	
2017-06-26 23:01:52,569 Epoch[49] Batch [1020]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090220,	
2017-06-26 23:01:57,866 Epoch[49] Batch [1030]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090176,	
2017-06-26 23:02:03,285 Epoch[49] Batch [1040]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.090269,	
2017-06-26 23:02:08,777 Epoch[49] Batch [1050]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090277,	
2017-06-26 23:02:14,060 Epoch[49] Batch [1060]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090336,	
2017-06-26 23:02:19,580 Epoch[49] Batch [1070]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.090464,	
2017-06-26 23:02:24,986 Epoch[49] Batch [1080]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090453,	
2017-06-26 23:02:30,309 Epoch[49] Batch [1090]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090382,	
2017-06-26 23:02:35,648 Epoch[49] Batch [1100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090400,	
2017-06-26 23:02:40,961 Epoch[49] Batch [1110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090401,	
2017-06-26 23:02:46,345 Epoch[49] Batch [1120]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090390,	
2017-06-26 23:02:51,688 Epoch[49] Batch [1130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090386,	
2017-06-26 23:02:57,045 Epoch[49] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090451,	
2017-06-26 23:03:02,548 Epoch[49] Batch [1150]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.090448,	
2017-06-26 23:03:07,831 Epoch[49] Batch [1160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090369,	
2017-06-26 23:03:13,235 Epoch[49] Batch [1170]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090388,	
2017-06-26 23:03:18,535 Epoch[49] Batch [1180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-26 23:03:23,941 Epoch[49] Batch [1190]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090433,	
2017-06-26 23:03:29,311 Epoch[49] Batch [1200]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090445,	
2017-06-26 23:03:34,706 Epoch[49] Batch [1210]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090390,	
2017-06-26 23:03:40,051 Epoch[49] Batch [1220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090421,	
2017-06-26 23:03:45,365 Epoch[49] Batch [1230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090415,	
2017-06-26 23:03:50,661 Epoch[49] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090436,	
2017-06-26 23:03:56,107 Epoch[49] Batch [1250]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.090424,	
2017-06-26 23:04:01,523 Epoch[49] Batch [1260]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090372,	
2017-06-26 23:04:06,857 Epoch[49] Batch [1270]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090402,	
2017-06-26 23:04:12,161 Epoch[49] Batch [1280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090430,	
2017-06-26 23:04:17,504 Epoch[49] Batch [1290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090414,	
2017-06-26 23:04:22,853 Epoch[49] Batch [1300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090412,	
2017-06-26 23:04:28,230 Epoch[49] Batch [1310]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090394,	
2017-06-26 23:04:33,514 Epoch[49] Batch [1320]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090445,	
2017-06-26 23:04:38,882 Epoch[49] Batch [1330]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090410,	
2017-06-26 23:04:44,220 Epoch[49] Batch [1340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090445,	
2017-06-26 23:04:49,558 Epoch[49] Batch [1350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090421,	
2017-06-26 23:04:54,910 Epoch[49] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090414,	
2017-06-26 23:05:00,300 Epoch[49] Batch [1370]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090431,	
2017-06-26 23:05:05,602 Epoch[49] Batch [1380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090493,	
2017-06-26 23:05:10,949 Epoch[49] Batch [1390]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090524,	
2017-06-26 23:05:16,284 Epoch[49] Batch [1400]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090481,	
2017-06-26 23:05:21,626 Epoch[49] Batch [1410]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090509,	
2017-06-26 23:05:26,961 Epoch[49] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090585,	
2017-06-26 23:05:32,321 Epoch[49] Batch [1430]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090635,	
2017-06-26 23:05:37,657 Epoch[49] Batch [1440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090616,	
2017-06-26 23:05:42,997 Epoch[49] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090663,	
2017-06-26 23:05:48,349 Epoch[49] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090683,	
2017-06-26 23:05:53,677 Epoch[49] Batch [1470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090659,	
2017-06-26 23:05:59,022 Epoch[49] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090670,	
2017-06-26 23:06:02,256 Epoch[49] Train-FCNLogLoss=0.090659
2017-06-26 23:06:02,256 Epoch[49] Time cost=796.108
2017-06-26 23:06:02,944 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0050.params"
2017-06-26 23:06:04,793 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0050.states"
2017-06-26 23:06:10,857 Epoch[50] Batch [10]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091909,	
2017-06-26 23:06:16,192 Epoch[50] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087200,	
2017-06-26 23:06:21,534 Epoch[50] Batch [30]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087669,	
2017-06-26 23:06:26,893 Epoch[50] Batch [40]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087600,	
2017-06-26 23:06:32,238 Epoch[50] Batch [50]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087757,	
2017-06-26 23:06:37,559 Epoch[50] Batch [60]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088860,	
2017-06-26 23:06:42,911 Epoch[50] Batch [70]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089059,	
2017-06-26 23:06:48,238 Epoch[50] Batch [80]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089027,	
2017-06-26 23:06:53,606 Epoch[50] Batch [90]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089354,	
2017-06-26 23:06:59,070 Epoch[50] Batch [100]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-26 23:07:04,031 Epoch[50] Batch [110]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088602,	
2017-06-26 23:07:09,895 Epoch[50] Batch [120]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.089377,	
2017-06-26 23:07:15,351 Epoch[50] Batch [130]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089031,	
2017-06-26 23:07:21,440 Epoch[50] Batch [140]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.088809,	
2017-06-26 23:07:26,697 Epoch[50] Batch [150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088843,	
2017-06-26 23:07:32,007 Epoch[50] Batch [160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088706,	
2017-06-26 23:07:37,414 Epoch[50] Batch [170]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089142,	
2017-06-26 23:07:42,691 Epoch[50] Batch [180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089299,	
2017-06-26 23:07:48,068 Epoch[50] Batch [190]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089262,	
2017-06-26 23:07:53,413 Epoch[50] Batch [200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089107,	
2017-06-26 23:07:58,717 Epoch[50] Batch [210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089618,	
2017-06-26 23:08:04,081 Epoch[50] Batch [220]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089927,	
2017-06-26 23:08:09,235 Epoch[50] Batch [230]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.090593,	
2017-06-26 23:08:14,532 Epoch[50] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090621,	
2017-06-26 23:08:19,674 Epoch[50] Batch [250]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090564,	
2017-06-26 23:08:24,703 Epoch[50] Batch [260]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.090674,	
2017-06-26 23:08:29,836 Epoch[50] Batch [270]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090358,	
2017-06-26 23:08:35,283 Epoch[50] Batch [280]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.090297,	
2017-06-26 23:08:40,402 Epoch[50] Batch [290]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090247,	
2017-06-26 23:08:45,743 Epoch[50] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090237,	
2017-06-26 23:08:51,095 Epoch[50] Batch [310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090152,	
2017-06-26 23:08:56,619 Epoch[50] Batch [320]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.090197,	
2017-06-26 23:09:01,971 Epoch[50] Batch [330]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090781,	
2017-06-26 23:09:07,027 Epoch[50] Batch [340]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090961,	
2017-06-26 23:09:12,355 Epoch[50] Batch [350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091105,	
2017-06-26 23:09:17,627 Epoch[50] Batch [360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091187,	
2017-06-26 23:09:22,948 Epoch[50] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091058,	
2017-06-26 23:09:28,306 Epoch[50] Batch [380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091043,	
2017-06-26 23:09:33,399 Epoch[50] Batch [390]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090776,	
2017-06-26 23:09:38,392 Epoch[50] Batch [400]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.090709,	
2017-06-26 23:09:43,621 Epoch[50] Batch [410]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090575,	
2017-06-26 23:09:48,851 Epoch[50] Batch [420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090570,	
2017-06-26 23:09:54,271 Epoch[50] Batch [430]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.090503,	
2017-06-26 23:09:59,687 Epoch[50] Batch [440]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090481,	
2017-06-26 23:10:05,010 Epoch[50] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090418,	
2017-06-26 23:10:10,349 Epoch[50] Batch [460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090415,	
2017-06-26 23:10:15,712 Epoch[50] Batch [470]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090502,	
2017-06-26 23:10:21,043 Epoch[50] Batch [480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090291,	
2017-06-26 23:10:26,392 Epoch[50] Batch [490]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090324,	
2017-06-26 23:10:31,705 Epoch[50] Batch [500]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090448,	
2017-06-26 23:10:37,038 Epoch[50] Batch [510]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090400,	
2017-06-26 23:10:42,398 Epoch[50] Batch [520]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090300,	
2017-06-26 23:10:47,794 Epoch[50] Batch [530]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090171,	
2017-06-26 23:10:53,074 Epoch[50] Batch [540]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090183,	
2017-06-26 23:10:58,598 Epoch[50] Batch [550]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.090207,	
2017-06-26 23:11:03,881 Epoch[50] Batch [560]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090288,	
2017-06-26 23:11:09,196 Epoch[50] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090267,	
2017-06-26 23:11:14,550 Epoch[50] Batch [580]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090092,	
2017-06-26 23:11:19,887 Epoch[50] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090094,	
2017-06-26 23:11:25,201 Epoch[50] Batch [600]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090009,	
2017-06-26 23:11:30,574 Epoch[50] Batch [610]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090176,	
2017-06-26 23:11:35,878 Epoch[50] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090356,	
2017-06-26 23:11:41,166 Epoch[50] Batch [630]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090392,	
2017-06-26 23:11:46,556 Epoch[50] Batch [640]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090389,	
2017-06-26 23:11:51,908 Epoch[50] Batch [650]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090409,	
2017-06-26 23:11:57,188 Epoch[50] Batch [660]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090385,	
2017-06-26 23:12:02,527 Epoch[50] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090320,	
2017-06-26 23:12:07,947 Epoch[50] Batch [680]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.090099,	
2017-06-26 23:12:13,145 Epoch[50] Batch [690]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.090191,	
2017-06-26 23:12:18,335 Epoch[50] Batch [700]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090046,	
2017-06-26 23:12:23,589 Epoch[50] Batch [710]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090103,	
2017-06-26 23:12:28,959 Epoch[50] Batch [720]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090201,	
2017-06-26 23:12:34,292 Epoch[50] Batch [730]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090029,	
2017-06-26 23:12:39,643 Epoch[50] Batch [740]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090127,	
2017-06-26 23:12:44,951 Epoch[50] Batch [750]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090088,	
2017-06-26 23:12:50,273 Epoch[50] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089991,	
2017-06-26 23:12:55,604 Epoch[50] Batch [770]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090082,	
2017-06-26 23:13:00,944 Epoch[50] Batch [780]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090113,	
2017-06-26 23:13:06,271 Epoch[50] Batch [790]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090280,	
2017-06-26 23:13:11,580 Epoch[50] Batch [800]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090309,	
2017-06-26 23:13:16,933 Epoch[50] Batch [810]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090366,	
2017-06-26 23:13:22,306 Epoch[50] Batch [820]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090409,	
2017-06-26 23:13:27,622 Epoch[50] Batch [830]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090398,	
2017-06-26 23:13:32,980 Epoch[50] Batch [840]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090486,	
2017-06-26 23:13:38,242 Epoch[50] Batch [850]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090464,	
2017-06-26 23:13:43,591 Epoch[50] Batch [860]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090605,	
2017-06-26 23:13:48,894 Epoch[50] Batch [870]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090544,	
2017-06-26 23:13:54,319 Epoch[50] Batch [880]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090560,	
2017-06-26 23:13:59,683 Epoch[50] Batch [890]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090539,	
2017-06-26 23:14:04,922 Epoch[50] Batch [900]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.090473,	
2017-06-26 23:14:10,296 Epoch[50] Batch [910]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090480,	
2017-06-26 23:14:15,642 Epoch[50] Batch [920]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090511,	
2017-06-26 23:14:20,906 Epoch[50] Batch [930]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090572,	
2017-06-26 23:14:26,280 Epoch[50] Batch [940]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090613,	
2017-06-26 23:14:31,646 Epoch[50] Batch [950]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090665,	
2017-06-26 23:14:36,974 Epoch[50] Batch [960]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090687,	
2017-06-26 23:14:42,240 Epoch[50] Batch [970]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090709,	
2017-06-26 23:14:47,013 Epoch[50] Batch [980]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.090851,	
2017-06-26 23:14:52,197 Epoch[50] Batch [990]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090775,	
2017-06-26 23:14:57,544 Epoch[50] Batch [1000]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090749,	
2017-06-26 23:15:02,782 Epoch[50] Batch [1010]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.090700,	
2017-06-26 23:15:08,032 Epoch[50] Batch [1020]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090664,	
2017-06-26 23:15:13,448 Epoch[50] Batch [1030]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090591,	
2017-06-26 23:15:18,715 Epoch[50] Batch [1040]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090523,	
2017-06-26 23:15:23,798 Epoch[50] Batch [1050]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.090529,	
2017-06-26 23:15:28,704 Epoch[50] Batch [1060]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.090643,	
2017-06-26 23:15:33,587 Epoch[50] Batch [1070]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.090648,	
2017-06-26 23:15:38,522 Epoch[50] Batch [1080]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090624,	
2017-06-26 23:15:43,729 Epoch[50] Batch [1090]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090595,	
2017-06-26 23:15:49,133 Epoch[50] Batch [1100]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090560,	
2017-06-26 23:15:54,476 Epoch[50] Batch [1110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090558,	
2017-06-26 23:15:59,813 Epoch[50] Batch [1120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090644,	
2017-06-26 23:16:05,212 Epoch[50] Batch [1130]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090625,	
2017-06-26 23:16:10,469 Epoch[50] Batch [1140]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090574,	
2017-06-26 23:16:15,778 Epoch[50] Batch [1150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090639,	
2017-06-26 23:16:21,143 Epoch[50] Batch [1160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090665,	
2017-06-26 23:16:26,453 Epoch[50] Batch [1170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090588,	
2017-06-26 23:16:31,796 Epoch[50] Batch [1180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090491,	
2017-06-26 23:16:37,141 Epoch[50] Batch [1190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090492,	
2017-06-26 23:16:42,455 Epoch[50] Batch [1200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090509,	
2017-06-26 23:16:47,833 Epoch[50] Batch [1210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090496,	
2017-06-26 23:16:53,233 Epoch[50] Batch [1220]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090587,	
2017-06-26 23:16:58,518 Epoch[50] Batch [1230]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090534,	
2017-06-26 23:17:03,867 Epoch[50] Batch [1240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090565,	
2017-06-26 23:17:09,214 Epoch[50] Batch [1250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090469,	
2017-06-26 23:17:14,537 Epoch[50] Batch [1260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090461,	
2017-06-26 23:17:19,873 Epoch[50] Batch [1270]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090338,	
2017-06-26 23:17:25,214 Epoch[50] Batch [1280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090295,	
2017-06-26 23:17:30,543 Epoch[50] Batch [1290]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090331,	
2017-06-26 23:17:35,889 Epoch[50] Batch [1300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-26 23:17:41,213 Epoch[50] Batch [1310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090359,	
2017-06-26 23:17:46,570 Epoch[50] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090313,	
2017-06-26 23:17:51,903 Epoch[50] Batch [1330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090344,	
2017-06-26 23:17:57,232 Epoch[50] Batch [1340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090339,	
2017-06-26 23:18:02,584 Epoch[50] Batch [1350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090368,	
2017-06-26 23:18:07,909 Epoch[50] Batch [1360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090346,	
2017-06-26 23:18:13,164 Epoch[50] Batch [1370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090313,	
2017-06-26 23:18:18,313 Epoch[50] Batch [1380]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.090275,	
2017-06-26 23:18:23,623 Epoch[50] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090331,	
2017-06-26 23:18:28,737 Epoch[50] Batch [1400]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.090332,	
2017-06-26 23:18:33,901 Epoch[50] Batch [1410]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090332,	
2017-06-26 23:18:39,193 Epoch[50] Batch [1420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090352,	
2017-06-26 23:18:44,588 Epoch[50] Batch [1430]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090300,	
2017-06-26 23:18:49,775 Epoch[50] Batch [1440]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090283,	
2017-06-26 23:18:54,828 Epoch[50] Batch [1450]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.090331,	
2017-06-26 23:19:00,158 Epoch[50] Batch [1460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090300,	
2017-06-26 23:19:05,327 Epoch[50] Batch [1470]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090292,	
2017-06-26 23:19:10,476 Epoch[50] Batch [1480]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.090328,	
2017-06-26 23:19:13,574 Epoch[50] Train-FCNLogLoss=0.090340
2017-06-26 23:19:13,574 Epoch[50] Time cost=788.781
2017-06-26 23:19:14,257 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0051.params"
2017-06-26 23:19:16,227 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0051.states"
2017-06-26 23:19:22,270 Epoch[51] Batch [10]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.078224,	
2017-06-26 23:19:27,376 Epoch[51] Batch [20]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.079876,	
2017-06-26 23:19:32,560 Epoch[51] Batch [30]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.081991,	
2017-06-26 23:19:37,886 Epoch[51] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.082441,	
2017-06-26 23:19:43,151 Epoch[51] Batch [50]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.083527,	
2017-06-26 23:19:48,386 Epoch[51] Batch [60]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.085169,	
2017-06-26 23:19:53,771 Epoch[51] Batch [70]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.084784,	
2017-06-26 23:19:59,078 Epoch[51] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086525,	
2017-06-26 23:20:04,410 Epoch[51] Batch [90]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.085856,	
2017-06-26 23:20:09,840 Epoch[51] Batch [100]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.085421,	
2017-06-26 23:20:15,066 Epoch[51] Batch [110]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.085558,	
2017-06-26 23:20:20,454 Epoch[51] Batch [120]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.086341,	
2017-06-26 23:20:25,817 Epoch[51] Batch [130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086399,	
2017-06-26 23:20:30,888 Epoch[51] Batch [140]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087188,	
2017-06-26 23:20:36,222 Epoch[51] Batch [150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088648,	
2017-06-26 23:20:40,873 Epoch[51] Batch [160]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088238,	
2017-06-26 23:20:45,882 Epoch[51] Batch [170]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088450,	
2017-06-26 23:20:51,269 Epoch[51] Batch [180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089079,	
2017-06-26 23:20:56,484 Epoch[51] Batch [190]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.089077,	
2017-06-26 23:21:01,621 Epoch[51] Batch [200]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089176,	
2017-06-26 23:21:07,009 Epoch[51] Batch [210]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089263,	
2017-06-26 23:21:12,127 Epoch[51] Batch [220]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089237,	
2017-06-26 23:21:17,287 Epoch[51] Batch [230]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089712,	
2017-06-26 23:21:22,294 Epoch[51] Batch [240]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089838,	
2017-06-26 23:21:27,663 Epoch[51] Batch [250]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089681,	
2017-06-26 23:21:32,553 Epoch[51] Batch [260]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.089669,	
2017-06-26 23:21:38,161 Epoch[51] Batch [270]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.089845,	
2017-06-26 23:21:43,296 Epoch[51] Batch [280]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089746,	
2017-06-26 23:21:48,648 Epoch[51] Batch [290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090210,	
2017-06-26 23:21:53,974 Epoch[51] Batch [300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090381,	
2017-06-26 23:21:59,316 Epoch[51] Batch [310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090199,	
2017-06-26 23:22:04,261 Epoch[51] Batch [320]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.090001,	
2017-06-26 23:22:09,626 Epoch[51] Batch [330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089886,	
2017-06-26 23:22:14,952 Epoch[51] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089392,	
2017-06-26 23:22:20,188 Epoch[51] Batch [350]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089475,	
2017-06-26 23:22:25,116 Epoch[51] Batch [360]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089542,	
2017-06-26 23:22:30,402 Epoch[51] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089882,	
2017-06-26 23:22:35,683 Epoch[51] Batch [380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089928,	
2017-06-26 23:22:41,020 Epoch[51] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089863,	
2017-06-26 23:22:45,968 Epoch[51] Batch [400]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.090141,	
2017-06-26 23:22:51,033 Epoch[51] Batch [410]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090149,	
2017-06-26 23:22:56,112 Epoch[51] Batch [420]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.090195,	
2017-06-26 23:23:01,200 Epoch[51] Batch [430]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.090062,	
2017-06-26 23:23:06,217 Epoch[51] Batch [440]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.090144,	
2017-06-26 23:23:11,279 Epoch[51] Batch [450]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090242,	
2017-06-26 23:23:16,407 Epoch[51] Batch [460]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.090327,	
2017-06-26 23:23:21,472 Epoch[51] Batch [470]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090127,	
2017-06-26 23:23:26,657 Epoch[51] Batch [480]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090080,	
2017-06-26 23:23:32,020 Epoch[51] Batch [490]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090132,	
2017-06-26 23:23:37,365 Epoch[51] Batch [500]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090071,	
2017-06-26 23:23:42,721 Epoch[51] Batch [510]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090147,	
2017-06-26 23:23:48,043 Epoch[51] Batch [520]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-26 23:23:53,389 Epoch[51] Batch [530]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090031,	
2017-06-26 23:23:58,394 Epoch[51] Batch [540]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089996,	
2017-06-26 23:24:03,672 Epoch[51] Batch [550]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090002,	
2017-06-26 23:24:08,653 Epoch[51] Batch [560]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.089971,	
2017-06-26 23:24:13,672 Epoch[51] Batch [570]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.090164,	
2017-06-26 23:24:18,783 Epoch[51] Batch [580]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.090152,	
2017-06-26 23:24:23,882 Epoch[51] Batch [590]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090137,	
2017-06-26 23:24:29,044 Epoch[51] Batch [600]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090055,	
2017-06-26 23:24:34,275 Epoch[51] Batch [610]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090055,	
2017-06-26 23:24:39,412 Epoch[51] Batch [620]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090025,	
2017-06-26 23:24:44,680 Epoch[51] Batch [630]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089938,	
2017-06-26 23:24:49,814 Epoch[51] Batch [640]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089954,	
2017-06-26 23:24:54,960 Epoch[51] Batch [650]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089955,	
2017-06-26 23:25:00,557 Epoch[51] Batch [660]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.089911,	
2017-06-26 23:25:06,042 Epoch[51] Batch [670]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.089982,	
2017-06-26 23:25:11,401 Epoch[51] Batch [680]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090013,	
2017-06-26 23:25:16,408 Epoch[51] Batch [690]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.090072,	
2017-06-26 23:25:21,795 Epoch[51] Batch [700]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090184,	
2017-06-26 23:25:26,996 Epoch[51] Batch [710]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.090143,	
2017-06-26 23:25:32,358 Epoch[51] Batch [720]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090165,	
2017-06-26 23:25:37,516 Epoch[51] Batch [730]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.090168,	
2017-06-26 23:25:42,898 Epoch[51] Batch [740]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090152,	
2017-06-26 23:25:48,206 Epoch[51] Batch [750]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090281,	
2017-06-26 23:25:53,550 Epoch[51] Batch [760]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090335,	
2017-06-26 23:25:58,904 Epoch[51] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-26 23:26:04,274 Epoch[51] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090465,	
2017-06-26 23:26:09,361 Epoch[51] Batch [790]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.090464,	
2017-06-26 23:26:14,539 Epoch[51] Batch [800]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.090277,	
2017-06-26 23:26:19,820 Epoch[51] Batch [810]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090347,	
2017-06-26 23:26:24,977 Epoch[51] Batch [820]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.090234,	
2017-06-26 23:26:30,057 Epoch[51] Batch [830]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.090180,	
2017-06-26 23:26:35,207 Epoch[51] Batch [840]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.090181,	
2017-06-26 23:26:40,385 Epoch[51] Batch [850]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.090045,	
2017-06-26 23:26:45,728 Epoch[51] Batch [860]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090136,	
2017-06-26 23:26:50,968 Epoch[51] Batch [870]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090162,	
2017-06-26 23:26:56,253 Epoch[51] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090110,	
2017-06-26 23:27:01,952 Epoch[51] Batch [890]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.090094,	
2017-06-26 23:27:07,744 Epoch[51] Batch [900]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.090081,	
2017-06-26 23:27:12,996 Epoch[51] Batch [910]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090074,	
2017-06-26 23:27:18,408 Epoch[51] Batch [920]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090018,	
2017-06-26 23:27:23,514 Epoch[51] Batch [930]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.089993,	
2017-06-26 23:27:29,012 Epoch[51] Batch [940]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.089938,	
2017-06-26 23:27:34,350 Epoch[51] Batch [950]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089897,	
2017-06-26 23:27:39,744 Epoch[51] Batch [960]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089900,	
2017-06-26 23:27:45,132 Epoch[51] Batch [970]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089890,	
2017-06-26 23:27:50,508 Epoch[51] Batch [980]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089805,	
2017-06-26 23:27:55,631 Epoch[51] Batch [990]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.089860,	
2017-06-26 23:28:00,948 Epoch[51] Batch [1000]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089912,	
2017-06-26 23:28:06,226 Epoch[51] Batch [1010]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089813,	
2017-06-26 23:28:11,368 Epoch[51] Batch [1020]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.089924,	
2017-06-26 23:28:16,420 Epoch[51] Batch [1030]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089970,	
2017-06-26 23:28:21,489 Epoch[51] Batch [1040]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.089871,	
2017-06-26 23:28:26,739 Epoch[51] Batch [1050]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089931,	
2017-06-26 23:28:31,923 Epoch[51] Batch [1060]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089930,	
2017-06-26 23:28:37,167 Epoch[51] Batch [1070]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089942,	
2017-06-26 23:28:42,460 Epoch[51] Batch [1080]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089972,	
2017-06-26 23:28:47,759 Epoch[51] Batch [1090]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089974,	
2017-06-26 23:28:53,172 Epoch[51] Batch [1100]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.089947,	
2017-06-26 23:28:58,454 Epoch[51] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090031,	
2017-06-26 23:29:03,655 Epoch[51] Batch [1120]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089990,	
2017-06-26 23:29:09,798 Epoch[51] Batch [1130]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.089931,	
2017-06-26 23:29:16,517 Epoch[51] Batch [1140]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.089994,	
2017-06-26 23:29:21,950 Epoch[51] Batch [1150]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090130,	
2017-06-26 23:29:27,813 Epoch[51] Batch [1160]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.090106,	
2017-06-26 23:29:33,130 Epoch[51] Batch [1170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090093,	
2017-06-26 23:29:39,289 Epoch[51] Batch [1180]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.090100,	
2017-06-26 23:29:44,612 Epoch[51] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090098,	
2017-06-26 23:29:49,754 Epoch[51] Batch [1200]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090087,	
2017-06-26 23:29:55,314 Epoch[51] Batch [1210]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.090196,	
2017-06-26 23:30:01,316 Epoch[51] Batch [1220]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.090222,	
2017-06-26 23:30:07,084 Epoch[51] Batch [1230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.090248,	
2017-06-26 23:30:12,451 Epoch[51] Batch [1240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090239,	
2017-06-26 23:30:17,949 Epoch[51] Batch [1250]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090259,	
2017-06-26 23:30:24,136 Epoch[51] Batch [1260]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090229,	
2017-06-26 23:30:29,877 Epoch[51] Batch [1270]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.090214,	
2017-06-26 23:30:35,528 Epoch[51] Batch [1280]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.090201,	
2017-06-26 23:30:41,084 Epoch[51] Batch [1290]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.090231,	
2017-06-26 23:30:46,518 Epoch[51] Batch [1300]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090213,	
2017-06-26 23:30:52,314 Epoch[51] Batch [1310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.090180,	
2017-06-26 23:30:57,739 Epoch[51] Batch [1320]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090177,	
2017-06-26 23:31:03,562 Epoch[51] Batch [1330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.090207,	
2017-06-26 23:31:09,206 Epoch[51] Batch [1340]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.090262,	
2017-06-26 23:31:14,592 Epoch[51] Batch [1350]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090216,	
2017-06-26 23:31:20,168 Epoch[51] Batch [1360]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.090201,	
2017-06-26 23:31:25,761 Epoch[51] Batch [1370]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.090196,	
2017-06-26 23:31:31,545 Epoch[51] Batch [1380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.090179,	
2017-06-26 23:31:36,750 Epoch[51] Batch [1390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.090226,	
2017-06-26 23:31:42,367 Epoch[51] Batch [1400]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.090274,	
2017-06-26 23:31:48,036 Epoch[51] Batch [1410]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.090282,	
2017-06-26 23:31:53,287 Epoch[51] Batch [1420]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090208,	
2017-06-26 23:31:58,777 Epoch[51] Batch [1430]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.090252,	
2017-06-26 23:32:04,687 Epoch[51] Batch [1440]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.090210,	
2017-06-26 23:32:10,386 Epoch[51] Batch [1450]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.090204,	
2017-06-26 23:32:16,481 Epoch[51] Batch [1460]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.090206,	
2017-06-26 23:32:21,981 Epoch[51] Batch [1470]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.090198,	
2017-06-26 23:32:27,837 Epoch[51] Batch [1480]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.090159,	
2017-06-26 23:32:31,314 Epoch[51] Train-FCNLogLoss=0.090165
2017-06-26 23:32:31,314 Epoch[51] Time cost=795.086
2017-06-26 23:32:31,965 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0052.params"
2017-06-26 23:32:33,488 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0052.states"
2017-06-26 23:32:39,627 Epoch[52] Batch [10]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088980,	
2017-06-26 23:32:45,927 Epoch[52] Batch [20]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.086492,	
2017-06-26 23:32:51,831 Epoch[52] Batch [30]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087009,	
2017-06-26 23:32:57,965 Epoch[52] Batch [40]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085257,	
2017-06-26 23:33:03,795 Epoch[52] Batch [50]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.089151,	
2017-06-26 23:33:10,281 Epoch[52] Batch [60]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088959,	
2017-06-26 23:33:16,234 Epoch[52] Batch [70]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.089383,	
2017-06-26 23:33:22,054 Epoch[52] Batch [80]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.090961,	
2017-06-26 23:33:28,020 Epoch[52] Batch [90]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.089922,	
2017-06-26 23:33:33,771 Epoch[52] Batch [100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.089584,	
2017-06-26 23:33:39,597 Epoch[52] Batch [110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.090365,	
2017-06-26 23:33:45,260 Epoch[52] Batch [120]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089704,	
2017-06-26 23:33:50,928 Epoch[52] Batch [130]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089612,	
2017-06-26 23:33:55,580 Epoch[52] Batch [140]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089287,	
2017-06-26 23:34:00,113 Epoch[52] Batch [150]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089136,	
2017-06-26 23:34:04,327 Epoch[52] Batch [160]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.089240,	
2017-06-26 23:34:08,659 Epoch[52] Batch [170]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.089155,	
2017-06-26 23:34:13,084 Epoch[52] Batch [180]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088942,	
2017-06-26 23:34:17,263 Epoch[52] Batch [190]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.089051,	
2017-06-26 23:34:21,741 Epoch[52] Batch [200]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088833,	
2017-06-26 23:34:26,193 Epoch[52] Batch [210]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.089147,	
2017-06-26 23:34:30,464 Epoch[52] Batch [220]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.088916,	
2017-06-26 23:34:34,873 Epoch[52] Batch [230]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089079,	
2017-06-26 23:34:39,220 Epoch[52] Batch [240]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.089076,	
2017-06-26 23:34:43,593 Epoch[52] Batch [250]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-26 23:34:48,064 Epoch[52] Batch [260]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088925,	
2017-06-26 23:34:52,413 Epoch[52] Batch [270]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.089002,	
2017-06-26 23:34:56,696 Epoch[52] Batch [280]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.089278,	
2017-06-26 23:35:01,159 Epoch[52] Batch [290]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.089760,	
2017-06-26 23:35:05,511 Epoch[52] Batch [300]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-26 23:35:09,742 Epoch[52] Batch [310]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.089909,	
2017-06-26 23:35:14,071 Epoch[52] Batch [320]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.089846,	
2017-06-26 23:35:18,464 Epoch[52] Batch [330]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090108,	
2017-06-26 23:35:22,889 Epoch[52] Batch [340]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.090108,	
2017-06-26 23:35:27,323 Epoch[52] Batch [350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090256,	
2017-06-26 23:35:31,885 Epoch[52] Batch [360]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090190,	
2017-06-26 23:35:36,432 Epoch[52] Batch [370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090213,	
2017-06-26 23:35:40,694 Epoch[52] Batch [380]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.090108,	
2017-06-26 23:35:44,999 Epoch[52] Batch [390]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.089981,	
2017-06-26 23:35:49,550 Epoch[52] Batch [400]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089926,	
2017-06-26 23:35:53,946 Epoch[52] Batch [410]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089886,	
2017-06-26 23:35:58,254 Epoch[52] Batch [420]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.090048,	
2017-06-26 23:36:02,594 Epoch[52] Batch [430]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.090019,	
2017-06-26 23:36:06,799 Epoch[52] Batch [440]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.090140,	
2017-06-26 23:36:11,170 Epoch[52] Batch [450]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.090127,	
2017-06-26 23:36:15,560 Epoch[52] Batch [460]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090111,	
2017-06-26 23:36:19,921 Epoch[52] Batch [470]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.090015,	
2017-06-26 23:36:24,271 Epoch[52] Batch [480]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.089732,	
2017-06-26 23:36:28,685 Epoch[52] Batch [490]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.089796,	
2017-06-26 23:36:33,168 Epoch[52] Batch [500]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.089752,	
2017-06-26 23:36:37,648 Epoch[52] Batch [510]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089704,	
2017-06-26 23:36:41,993 Epoch[52] Batch [520]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.089709,	
2017-06-26 23:36:46,322 Epoch[52] Batch [530]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.089786,	
2017-06-26 23:36:50,760 Epoch[52] Batch [540]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.089896,	
2017-06-26 23:36:55,298 Epoch[52] Batch [550]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.089932,	
2017-06-26 23:36:59,678 Epoch[52] Batch [560]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.090124,	
2017-06-26 23:37:04,041 Epoch[52] Batch [570]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.090091,	
2017-06-26 23:37:08,307 Epoch[52] Batch [580]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.090244,	
2017-06-26 23:37:12,664 Epoch[52] Batch [590]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.090168,	
2017-06-26 23:37:17,073 Epoch[52] Batch [600]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090032,	
2017-06-26 23:37:21,239 Epoch[52] Batch [610]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.090068,	
2017-06-26 23:37:25,725 Epoch[52] Batch [620]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.090043,	
2017-06-26 23:37:29,954 Epoch[52] Batch [630]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.090191,	
2017-06-26 23:37:34,449 Epoch[52] Batch [640]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090163,	
2017-06-26 23:37:38,815 Epoch[52] Batch [650]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.090132,	
2017-06-26 23:37:43,392 Epoch[52] Batch [660]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090135,	
2017-06-26 23:37:47,874 Epoch[52] Batch [670]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.090041,	
2017-06-26 23:37:52,252 Epoch[52] Batch [680]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.090128,	
2017-06-26 23:37:56,423 Epoch[52] Batch [690]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090125,	
2017-06-26 23:38:00,818 Epoch[52] Batch [700]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090133,	
2017-06-26 23:38:05,184 Epoch[52] Batch [710]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.090224,	
2017-06-26 23:38:09,609 Epoch[52] Batch [720]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.090236,	
2017-06-26 23:38:14,019 Epoch[52] Batch [730]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090152,	
2017-06-26 23:38:18,316 Epoch[52] Batch [740]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.090257,	
2017-06-26 23:38:22,729 Epoch[52] Batch [750]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090289,	
2017-06-26 23:38:26,975 Epoch[52] Batch [760]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.090216,	
2017-06-26 23:38:31,341 Epoch[52] Batch [770]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.090143,	
2017-06-26 23:38:35,600 Epoch[52] Batch [780]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.090147,	
2017-06-26 23:38:39,996 Epoch[52] Batch [790]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090104,	
2017-06-26 23:38:44,256 Epoch[52] Batch [800]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.090096,	
2017-06-26 23:38:49,008 Epoch[52] Batch [810]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089971,	
2017-06-26 23:38:53,433 Epoch[52] Batch [820]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.090060,	
2017-06-26 23:38:57,976 Epoch[52] Batch [830]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090020,	
2017-06-26 23:39:02,524 Epoch[52] Batch [840]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089968,	
2017-06-26 23:39:06,726 Epoch[52] Batch [850]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.089987,	
2017-06-26 23:39:11,321 Epoch[52] Batch [860]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089966,	
2017-06-26 23:39:15,618 Epoch[52] Batch [870]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.089977,	
2017-06-26 23:39:20,191 Epoch[52] Batch [880]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090048,	
2017-06-26 23:39:24,580 Epoch[52] Batch [890]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090052,	
2017-06-26 23:39:28,981 Epoch[52] Batch [900]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.090173,	
2017-06-26 23:39:33,371 Epoch[52] Batch [910]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090337,	
2017-06-26 23:39:37,821 Epoch[52] Batch [920]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.090364,	
2017-06-26 23:39:41,983 Epoch[52] Batch [930]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.090502,	
2017-06-26 23:39:46,388 Epoch[52] Batch [940]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090505,	
2017-06-26 23:39:51,005 Epoch[52] Batch [950]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090437,	
2017-06-26 23:39:55,324 Epoch[52] Batch [960]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.090456,	
2017-06-26 23:39:59,498 Epoch[52] Batch [970]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.090380,	
2017-06-26 23:40:03,687 Epoch[52] Batch [980]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.090367,	
2017-06-26 23:40:08,087 Epoch[52] Batch [990]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.090445,	
2017-06-26 23:40:12,568 Epoch[52] Batch [1000]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.090339,	
2017-06-26 23:40:16,810 Epoch[52] Batch [1010]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.090270,	
2017-06-26 23:40:21,053 Epoch[52] Batch [1020]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.090185,	
2017-06-26 23:40:25,426 Epoch[52] Batch [1030]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.090237,	
2017-06-26 23:40:29,698 Epoch[52] Batch [1040]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.090098,	
2017-06-26 23:40:33,881 Epoch[52] Batch [1050]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.090100,	
2017-06-26 23:40:38,498 Epoch[52] Batch [1060]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090201,	
2017-06-26 23:40:42,811 Epoch[52] Batch [1070]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.090167,	
2017-06-26 23:40:47,186 Epoch[52] Batch [1080]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.090199,	
2017-06-26 23:40:51,467 Epoch[52] Batch [1090]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.090189,	
2017-06-26 23:40:55,926 Epoch[52] Batch [1100]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.090259,	
2017-06-26 23:41:00,463 Epoch[52] Batch [1110]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090222,	
2017-06-26 23:41:05,219 Epoch[52] Batch [1120]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090178,	
2017-06-26 23:41:09,664 Epoch[52] Batch [1130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090309,	
2017-06-26 23:41:14,008 Epoch[52] Batch [1140]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.090394,	
2017-06-26 23:41:18,350 Epoch[52] Batch [1150]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.090374,	
2017-06-26 23:41:22,780 Epoch[52] Batch [1160]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.090358,	
2017-06-26 23:41:27,034 Epoch[52] Batch [1170]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.090386,	
2017-06-26 23:41:31,407 Epoch[52] Batch [1180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.090435,	
2017-06-26 23:41:35,665 Epoch[52] Batch [1190]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.090384,	
2017-06-26 23:41:40,072 Epoch[52] Batch [1200]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090429,	
2017-06-26 23:41:44,565 Epoch[52] Batch [1210]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090500,	
2017-06-26 23:41:48,862 Epoch[52] Batch [1220]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.090466,	
2017-06-26 23:41:53,315 Epoch[52] Batch [1230]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090394,	
2017-06-26 23:41:57,608 Epoch[52] Batch [1240]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.090370,	
2017-06-26 23:42:02,058 Epoch[52] Batch [1250]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.090405,	
2017-06-26 23:42:06,472 Epoch[52] Batch [1260]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.090360,	
2017-06-26 23:42:10,739 Epoch[52] Batch [1270]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.090349,	
2017-06-26 23:42:15,150 Epoch[52] Batch [1280]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090327,	
2017-06-26 23:42:19,632 Epoch[52] Batch [1290]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.090369,	
2017-06-26 23:42:23,910 Epoch[52] Batch [1300]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.090298,	
2017-06-26 23:42:28,300 Epoch[52] Batch [1310]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090258,	
2017-06-26 23:42:32,625 Epoch[52] Batch [1320]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.090281,	
2017-06-26 23:42:36,888 Epoch[52] Batch [1330]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.090327,	
2017-06-26 23:42:41,134 Epoch[52] Batch [1340]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.090311,	
2017-06-26 23:42:45,351 Epoch[52] Batch [1350]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.090391,	
2017-06-26 23:42:49,776 Epoch[52] Batch [1360]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.090365,	
2017-06-26 23:42:54,239 Epoch[52] Batch [1370]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.090462,	
2017-06-26 23:42:58,709 Epoch[52] Batch [1380]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.090526,	
2017-06-26 23:43:03,039 Epoch[52] Batch [1390]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.090477,	
2017-06-26 23:43:07,418 Epoch[52] Batch [1400]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.090460,	
2017-06-26 23:43:11,716 Epoch[52] Batch [1410]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-26 23:43:16,077 Epoch[52] Batch [1420]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.090382,	
2017-06-26 23:43:20,459 Epoch[52] Batch [1430]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.090384,	
2017-06-26 23:43:24,713 Epoch[52] Batch [1440]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.090312,	
2017-06-26 23:43:29,060 Epoch[52] Batch [1450]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.090218,	
2017-06-26 23:43:33,504 Epoch[52] Batch [1460]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090203,	
2017-06-26 23:43:37,805 Epoch[52] Batch [1470]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.090213,	
2017-06-26 23:43:42,196 Epoch[52] Batch [1480]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090196,	
2017-06-26 23:43:44,781 Epoch[52] Train-FCNLogLoss=0.090188
2017-06-26 23:43:44,782 Epoch[52] Time cost=671.293
2017-06-26 23:43:45,429 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0053.params"
2017-06-26 23:43:47,288 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10-0053.states"
2017-06-26 23:43:47,297 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate10x10',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate10x10'}

2017-06-26 23:43:56,213 testing 4/500 data 0.6836s net 0.3059s post 0.0108s
2017-06-26 23:43:56,854 testing 8/500 data 0.5324s net 0.2766s post 0.0116s
2017-06-26 23:43:57,571 testing 12/500 data 0.5061s net 0.2687s post 0.0116s
2017-06-26 23:43:58,236 testing 16/500 data 0.4817s net 0.2626s post 0.0115s
2017-06-26 23:43:58,889 testing 20/500 data 0.4654s net 0.2592s post 0.0106s
2017-06-26 23:43:59,515 testing 24/500 data 0.4494s net 0.2568s post 0.0109s
2017-06-26 23:44:00,119 testing 28/500 data 0.4349s net 0.2551s post 0.0108s
2017-06-26 23:44:00,715 testing 32/500 data 0.4237s net 0.2537s post 0.0104s
2017-06-26 23:44:01,291 testing 36/500 data 0.4127s net 0.2527s post 0.0100s
2017-06-26 23:44:01,882 testing 40/500 data 0.4050s net 0.2519s post 0.0101s
2017-06-26 23:44:02,448 testing 44/500 data 0.3963s net 0.2513s post 0.0102s
2017-06-26 23:44:03,025 testing 48/500 data 0.3901s net 0.2510s post 0.0100s
2017-06-26 23:44:03,615 testing 52/500 data 0.3858s net 0.2506s post 0.0100s
2017-06-26 23:44:04,191 testing 56/500 data 0.3812s net 0.2501s post 0.0100s
2017-06-26 23:44:04,770 testing 60/500 data 0.3774s net 0.2499s post 0.0098s
2017-06-26 23:44:05,343 testing 64/500 data 0.3737s net 0.2496s post 0.0099s
2017-06-26 23:44:05,911 testing 68/500 data 0.3703s net 0.2492s post 0.0098s
2017-06-26 23:44:06,493 testing 72/500 data 0.3679s net 0.2489s post 0.0099s
2017-06-26 23:44:07,062 testing 76/500 data 0.3650s net 0.2487s post 0.0100s
2017-06-26 23:44:07,630 testing 80/500 data 0.3626s net 0.2484s post 0.0098s
2017-06-26 23:44:08,211 testing 84/500 data 0.3608s net 0.2482s post 0.0100s
2017-06-26 23:44:08,785 testing 88/500 data 0.3588s net 0.2481s post 0.0100s
2017-06-26 23:44:09,354 testing 92/500 data 0.3570s net 0.2479s post 0.0099s
2017-06-26 23:44:09,950 testing 96/500 data 0.3562s net 0.2478s post 0.0100s
2017-06-26 23:44:10,532 testing 100/500 data 0.3550s net 0.2477s post 0.0100s
2017-06-26 23:44:11,106 testing 104/500 data 0.3535s net 0.2476s post 0.0101s
2017-06-26 23:44:11,694 testing 108/500 data 0.3528s net 0.2475s post 0.0102s
2017-06-26 23:44:12,275 testing 112/500 data 0.3519s net 0.2474s post 0.0101s
2017-06-26 23:44:12,864 testing 116/500 data 0.3512s net 0.2474s post 0.0101s
2017-06-26 23:44:13,440 testing 120/500 data 0.3502s net 0.2473s post 0.0101s
2017-06-26 23:44:14,027 testing 124/500 data 0.3497s net 0.2472s post 0.0101s
2017-06-26 23:44:14,602 testing 128/500 data 0.3487s net 0.2471s post 0.0101s
2017-06-26 23:44:15,185 testing 132/500 data 0.3482s net 0.2470s post 0.0100s
2017-06-26 23:44:15,779 testing 136/500 data 0.3479s net 0.2470s post 0.0100s
2017-06-26 23:44:16,361 testing 140/500 data 0.3472s net 0.2470s post 0.0101s
2017-06-26 23:44:16,930 testing 144/500 data 0.3463s net 0.2468s post 0.0101s
2017-06-26 23:44:17,519 testing 148/500 data 0.3459s net 0.2468s post 0.0101s
2017-06-26 23:44:18,108 testing 152/500 data 0.3456s net 0.2468s post 0.0101s
2017-06-26 23:44:18,800 testing 156/500 data 0.3479s net 0.2468s post 0.0101s
2017-06-26 23:44:19,498 testing 160/500 data 0.3501s net 0.2469s post 0.0102s
2017-06-26 23:44:20,107 testing 164/500 data 0.3502s net 0.2468s post 0.0102s
2017-06-26 23:44:20,797 testing 168/500 data 0.3521s net 0.2468s post 0.0102s
2017-06-26 23:44:21,513 testing 172/500 data 0.3545s net 0.2468s post 0.0103s
2017-06-26 23:44:22,196 testing 176/500 data 0.3562s net 0.2468s post 0.0103s
2017-06-26 23:44:22,830 testing 180/500 data 0.3567s net 0.2467s post 0.0103s
2017-06-26 23:44:23,542 testing 184/500 data 0.3589s net 0.2467s post 0.0103s
2017-06-26 23:44:24,218 testing 188/500 data 0.3602s net 0.2466s post 0.0103s
2017-06-26 23:44:24,909 testing 192/500 data 0.3616s net 0.2467s post 0.0103s
2017-06-26 23:44:25,608 testing 196/500 data 0.3632s net 0.2467s post 0.0104s
2017-06-26 23:44:26,350 testing 200/500 data 0.3656s net 0.2467s post 0.0104s
2017-06-26 23:44:27,072 testing 204/500 data 0.3676s net 0.2466s post 0.0105s
2017-06-26 23:44:27,703 testing 208/500 data 0.3678s net 0.2466s post 0.0105s
2017-06-26 23:44:28,417 testing 212/500 data 0.3694s net 0.2466s post 0.0105s
2017-06-26 23:44:29,091 testing 216/500 data 0.3704s net 0.2465s post 0.0104s
2017-06-26 23:44:29,773 testing 220/500 data 0.3716s net 0.2465s post 0.0104s
2017-06-26 23:44:30,350 testing 224/500 data 0.3706s net 0.2464s post 0.0104s
2017-06-26 23:44:30,970 testing 228/500 data 0.3704s net 0.2465s post 0.0104s
2017-06-26 23:44:31,609 testing 232/500 data 0.3706s net 0.2464s post 0.0105s
2017-06-26 23:44:32,347 testing 236/500 data 0.3725s net 0.2464s post 0.0105s
2017-06-26 23:44:33,049 testing 240/500 data 0.3737s net 0.2464s post 0.0105s
2017-06-26 23:44:33,747 testing 244/500 data 0.3749s net 0.2464s post 0.0105s
2017-06-26 23:44:34,455 testing 248/500 data 0.3763s net 0.2463s post 0.0104s
2017-06-26 23:44:35,164 testing 252/500 data 0.3776s net 0.2462s post 0.0103s
2017-06-26 23:44:35,751 testing 256/500 data 0.3769s net 0.2462s post 0.0103s
2017-06-26 23:44:36,331 testing 260/500 data 0.3762s net 0.2462s post 0.0102s
2017-06-26 23:44:36,925 testing 264/500 data 0.3756s net 0.2462s post 0.0102s
2017-06-26 23:44:37,499 testing 268/500 data 0.3748s net 0.2461s post 0.0102s
2017-06-26 23:44:38,076 testing 272/500 data 0.3740s net 0.2461s post 0.0103s
2017-06-26 23:44:38,656 testing 276/500 data 0.3732s net 0.2460s post 0.0103s
2017-06-26 23:44:39,217 testing 280/500 data 0.3723s net 0.2460s post 0.0103s
2017-06-26 23:44:39,777 testing 284/500 data 0.3713s net 0.2460s post 0.0103s
2017-06-26 23:44:40,363 testing 288/500 data 0.3708s net 0.2460s post 0.0103s
2017-06-26 23:44:40,930 testing 292/500 data 0.3699s net 0.2461s post 0.0103s
2017-06-26 23:44:41,509 testing 296/500 data 0.3693s net 0.2460s post 0.0103s
2017-06-26 23:44:42,084 testing 300/500 data 0.3686s net 0.2460s post 0.0103s
2017-06-26 23:44:42,756 testing 304/500 data 0.3693s net 0.2460s post 0.0103s
2017-06-26 23:44:43,354 testing 308/500 data 0.3691s net 0.2459s post 0.0102s
2017-06-26 23:44:43,931 testing 312/500 data 0.3685s net 0.2459s post 0.0102s
2017-06-26 23:44:44,502 testing 316/500 data 0.3678s net 0.2459s post 0.0102s
2017-06-26 23:44:45,082 testing 320/500 data 0.3673s net 0.2459s post 0.0102s
2017-06-26 23:44:45,656 testing 324/500 data 0.3668s net 0.2458s post 0.0101s
2017-06-26 23:44:46,239 testing 328/500 data 0.3663s net 0.2458s post 0.0102s
2017-06-26 23:44:46,797 testing 332/500 data 0.3655s net 0.2458s post 0.0102s
2017-06-26 23:44:47,376 testing 336/500 data 0.3650s net 0.2458s post 0.0102s
2017-06-26 23:44:47,953 testing 340/500 data 0.3645s net 0.2458s post 0.0102s
2017-06-26 23:44:48,528 testing 344/500 data 0.3639s net 0.2458s post 0.0102s
2017-06-26 23:44:49,086 testing 348/500 data 0.3633s net 0.2458s post 0.0102s
2017-06-26 23:44:49,657 testing 352/500 data 0.3628s net 0.2457s post 0.0102s
2017-06-26 23:44:50,241 testing 356/500 data 0.3625s net 0.2457s post 0.0101s
2017-06-26 23:44:50,827 testing 360/500 data 0.3621s net 0.2457s post 0.0101s
2017-06-26 23:44:51,409 testing 364/500 data 0.3618s net 0.2457s post 0.0101s
2017-06-26 23:44:51,961 testing 368/500 data 0.3611s net 0.2457s post 0.0100s
2017-06-26 23:44:52,529 testing 372/500 data 0.3606s net 0.2457s post 0.0101s
2017-06-26 23:44:53,087 testing 376/500 data 0.3600s net 0.2457s post 0.0100s
2017-06-26 23:44:53,650 testing 380/500 data 0.3595s net 0.2457s post 0.0100s
2017-06-26 23:44:54,353 testing 384/500 data 0.3604s net 0.2456s post 0.0100s
2017-06-26 23:44:54,988 testing 388/500 data 0.3606s net 0.2456s post 0.0100s
2017-06-26 23:44:55,573 testing 392/500 data 0.3603s net 0.2456s post 0.0101s
2017-06-26 23:44:56,143 testing 396/500 data 0.3598s net 0.2456s post 0.0101s
2017-06-26 23:44:56,732 testing 400/500 data 0.3596s net 0.2456s post 0.0101s
2017-06-26 23:44:57,296 testing 404/500 data 0.3591s net 0.2455s post 0.0101s
2017-06-26 23:44:57,862 testing 408/500 data 0.3586s net 0.2455s post 0.0101s
2017-06-26 23:44:58,453 testing 412/500 data 0.3585s net 0.2455s post 0.0100s
2017-06-26 23:44:59,133 testing 416/500 data 0.3591s net 0.2455s post 0.0100s
2017-06-26 23:44:59,727 testing 420/500 data 0.3589s net 0.2454s post 0.0100s
2017-06-26 23:45:00,375 testing 424/500 data 0.3593s net 0.2454s post 0.0100s
2017-06-26 23:45:01,057 testing 428/500 data 0.3599s net 0.2455s post 0.0100s
2017-06-26 23:45:01,638 testing 432/500 data 0.3596s net 0.2454s post 0.0100s
2017-06-26 23:45:02,207 testing 436/500 data 0.3592s net 0.2454s post 0.0100s
2017-06-26 23:45:02,781 testing 440/500 data 0.3588s net 0.2454s post 0.0100s
2017-06-26 23:45:03,342 testing 444/500 data 0.3583s net 0.2454s post 0.0100s
2017-06-26 23:45:03,921 testing 448/500 data 0.3580s net 0.2454s post 0.0100s
2017-06-26 23:45:04,512 testing 452/500 data 0.3579s net 0.2454s post 0.0100s
2017-06-26 23:45:05,078 testing 456/500 data 0.3575s net 0.2454s post 0.0100s
2017-06-26 23:45:05,647 testing 460/500 data 0.3571s net 0.2454s post 0.0100s
2017-06-26 23:45:06,344 testing 464/500 data 0.3578s net 0.2454s post 0.0100s
2017-06-26 23:45:06,916 testing 468/500 data 0.3575s net 0.2454s post 0.0100s
2017-06-26 23:45:07,492 testing 472/500 data 0.3572s net 0.2454s post 0.0100s
2017-06-26 23:45:08,066 testing 476/500 data 0.3569s net 0.2454s post 0.0100s
2017-06-26 23:45:08,644 testing 480/500 data 0.3566s net 0.2453s post 0.0100s
2017-06-26 23:45:09,229 testing 484/500 data 0.3564s net 0.2453s post 0.0100s
2017-06-26 23:45:09,798 testing 488/500 data 0.3561s net 0.2453s post 0.0100s
2017-06-26 23:45:10,384 testing 492/500 data 0.3559s net 0.2453s post 0.0100s
2017-06-26 23:45:10,968 testing 496/500 data 0.3557s net 0.2453s post 0.0100s
2017-06-26 23:45:11,555 testing 500/500 data 0.3555s net 0.2453s post 0.0099s
2017-06-26 23:47:03,518 evaluate segmentation: 

2017-06-26 23:47:03,518 IU_array:

2017-06-26 23:47:03,518 0.97946
2017-06-26 23:47:03,518 0.83090
2017-06-26 23:47:03,519 0.91282
2017-06-26 23:47:03,519 0.52024
2017-06-26 23:47:03,519 0.53432
2017-06-26 23:47:03,519 0.53688
2017-06-26 23:47:03,519 0.63027
2017-06-26 23:47:03,519 0.72701
2017-06-26 23:47:03,519 0.91367
2017-06-26 23:47:03,519 0.61375
2017-06-26 23:47:03,519 0.93525
2017-06-26 23:47:03,519 0.77952
2017-06-26 23:47:03,519 0.56800
2017-06-26 23:47:03,519 0.93537
2017-06-26 23:47:03,519 0.63925
2017-06-26 23:47:03,519 0.79967
2017-06-26 23:47:03,519 0.66667
2017-06-26 23:47:03,519 0.55610
2017-06-26 23:47:03,519 0.73490
2017-06-26 23:47:03,519 meanIU:0.72706

2017-08-03 16:03:26,318 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': True,
           'SHUFFLE': True,
           'begin_epoch': 20,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-08-03 16:04:43,871 Epoch[20] Batch [10]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.126898,	
2017-08-03 16:04:51,497 Epoch[20] Batch [20]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.127874,	
2017-08-03 16:05:00,193 Epoch[20] Batch [30]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.125341,	
2017-08-03 16:05:08,942 Epoch[20] Batch [40]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.122036,	
2017-08-03 16:05:17,389 Epoch[20] Batch [50]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.119967,	
2017-08-03 16:05:24,984 Epoch[20] Batch [60]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.118140,	
2017-08-03 16:05:32,296 Epoch[20] Batch [70]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.117605,	
2017-08-03 16:05:39,777 Epoch[20] Batch [80]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.115273,	
2017-08-03 16:05:47,767 Epoch[20] Batch [90]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.113856,	
2017-08-03 16:05:55,794 Epoch[20] Batch [100]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.114297,	
2017-08-03 16:06:03,276 Epoch[20] Batch [110]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.114033,	
2017-08-03 16:06:10,149 Epoch[20] Batch [120]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.113951,	
2017-08-03 16:06:17,117 Epoch[20] Batch [130]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.114393,	
2017-08-03 16:06:24,382 Epoch[20] Batch [140]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.114926,	
2017-08-03 16:06:31,056 Epoch[20] Batch [150]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.114104,	
2017-08-03 16:06:38,224 Epoch[20] Batch [160]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.113045,	
2017-08-03 16:06:45,586 Epoch[20] Batch [170]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.113284,	
2017-08-03 16:06:52,685 Epoch[20] Batch [180]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.112643,	
2017-08-03 16:07:00,776 Epoch[20] Batch [190]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.112908,	
2017-08-03 16:07:09,061 Epoch[20] Batch [200]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.113022,	
2017-08-03 16:07:18,273 Epoch[20] Batch [210]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.112673,	
2017-08-03 16:07:27,681 Epoch[20] Batch [220]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.112488,	
2017-08-03 16:07:36,488 Epoch[20] Batch [230]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.112286,	
2017-08-03 16:07:44,680 Epoch[20] Batch [240]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.112327,	
2017-08-03 16:07:52,791 Epoch[20] Batch [250]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.111469,	
2017-08-03 16:08:00,549 Epoch[20] Batch [260]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.111130,	
2017-08-03 16:08:08,145 Epoch[20] Batch [270]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.111340,	
2017-08-03 16:08:15,746 Epoch[20] Batch [280]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.111127,	
2017-08-03 16:08:23,816 Epoch[20] Batch [290]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.110785,	
2017-08-03 16:08:31,846 Epoch[20] Batch [300]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.110558,	
2017-08-03 16:08:39,919 Epoch[20] Batch [310]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.110795,	
2017-08-03 16:08:47,749 Epoch[20] Batch [320]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.110400,	
2017-08-03 16:08:55,989 Epoch[20] Batch [330]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.110288,	
2017-08-03 16:09:05,292 Epoch[20] Batch [340]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.110483,	
2017-08-03 16:09:14,750 Epoch[20] Batch [350]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.110789,	
2017-08-03 16:09:23,947 Epoch[20] Batch [360]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.110666,	
2017-08-03 16:09:33,001 Epoch[20] Batch [370]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.110860,	
2017-08-03 16:09:41,629 Epoch[20] Batch [380]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.110680,	
2017-08-03 16:09:49,285 Epoch[20] Batch [390]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.110352,	
2017-08-03 16:09:56,957 Epoch[20] Batch [400]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.110180,	
2017-08-03 16:10:04,763 Epoch[20] Batch [410]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.110401,	
2017-08-03 16:10:12,374 Epoch[20] Batch [420]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.110411,	
2017-08-03 16:10:20,129 Epoch[20] Batch [430]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.110074,	
2017-08-03 16:10:27,670 Epoch[20] Batch [440]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.109936,	
2017-08-03 16:10:35,340 Epoch[20] Batch [450]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.110364,	
2017-08-03 16:10:42,977 Epoch[20] Batch [460]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.110499,	
2017-08-03 16:10:50,866 Epoch[20] Batch [470]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.110299,	
2017-08-03 16:10:58,549 Epoch[20] Batch [480]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.110228,	
2017-08-03 16:11:06,114 Epoch[20] Batch [490]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.110342,	
2017-08-03 16:11:13,515 Epoch[20] Batch [500]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.110441,	
2017-08-03 16:11:21,189 Epoch[20] Batch [510]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.110508,	
2017-08-03 16:11:28,880 Epoch[20] Batch [520]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.110411,	
2017-08-03 16:11:37,613 Epoch[20] Batch [530]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.110421,	
2017-08-03 16:11:45,941 Epoch[20] Batch [540]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.110375,	
2017-08-03 16:11:53,797 Epoch[20] Batch [550]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.110459,	
2017-08-03 16:12:02,575 Epoch[20] Batch [560]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.110396,	
2017-08-03 16:12:11,525 Epoch[20] Batch [570]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.110289,	
2017-08-03 16:12:19,357 Epoch[20] Batch [580]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.110097,	
2017-08-03 16:12:27,363 Epoch[20] Batch [590]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.110310,	
2017-08-03 16:12:36,761 Epoch[20] Batch [600]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.110049,	
2017-08-03 16:12:44,779 Epoch[20] Batch [610]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.110169,	
2017-08-03 16:12:52,931 Epoch[20] Batch [620]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.110197,	
2017-08-03 16:13:01,114 Epoch[20] Batch [630]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.110284,	
2017-08-03 16:13:09,244 Epoch[20] Batch [640]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.110339,	
2017-08-03 16:13:19,487 Epoch[20] Batch [650]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.110347,	
2017-08-03 16:13:27,103 Epoch[20] Batch [660]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.110211,	
2017-08-03 16:13:35,828 Epoch[20] Batch [670]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.110257,	
2017-08-03 16:13:44,603 Epoch[20] Batch [680]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.110280,	
2017-08-03 16:13:52,868 Epoch[20] Batch [690]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.110275,	
2017-08-03 16:14:00,848 Epoch[20] Batch [700]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.110434,	
2017-08-03 16:14:08,717 Epoch[20] Batch [710]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.110364,	
2017-08-03 16:14:16,661 Epoch[20] Batch [720]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.110237,	
2017-08-03 16:14:24,521 Epoch[20] Batch [730]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.110098,	
2017-08-03 16:14:33,052 Epoch[20] Batch [740]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.109970,	
2017-08-03 16:14:42,458 Epoch[20] Batch [750]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.109882,	
2017-08-03 16:14:50,835 Epoch[20] Batch [760]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.109796,	
2017-08-03 16:15:00,160 Epoch[20] Batch [770]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.109616,	
2017-08-03 16:15:10,861 Epoch[20] Batch [780]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.109573,	
2017-08-03 16:15:18,589 Epoch[20] Batch [790]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.109712,	
2017-08-03 16:15:28,294 Epoch[20] Batch [800]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.109485,	
2017-08-03 16:15:38,041 Epoch[20] Batch [810]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.109465,	
2017-08-03 16:15:47,268 Epoch[20] Batch [820]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.109579,	
2017-08-03 16:15:55,509 Epoch[20] Batch [830]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.109580,	
2017-08-03 16:16:03,127 Epoch[20] Batch [840]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.109625,	
2017-08-03 16:16:12,334 Epoch[20] Batch [850]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.109649,	
2017-08-03 16:16:22,277 Epoch[20] Batch [860]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.109590,	
2017-08-03 16:16:31,763 Epoch[20] Batch [870]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.109536,	
2017-08-03 16:16:40,340 Epoch[20] Batch [880]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.109565,	
2017-08-03 16:16:48,037 Epoch[20] Batch [890]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.109758,	
2017-08-03 16:16:56,016 Epoch[20] Batch [900]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.109734,	
2017-08-03 16:17:03,755 Epoch[20] Batch [910]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.109746,	
2017-08-03 16:17:11,801 Epoch[20] Batch [920]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.109729,	
2017-08-03 16:17:20,990 Epoch[20] Batch [930]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.109796,	
2017-08-03 16:17:28,906 Epoch[20] Batch [940]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.109791,	
2017-08-03 16:17:37,189 Epoch[20] Batch [950]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.109843,	
2017-08-03 16:17:45,324 Epoch[20] Batch [960]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.109785,	
2017-08-03 16:17:53,485 Epoch[20] Batch [970]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.109828,	
2017-08-03 16:18:02,471 Epoch[20] Batch [980]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.109753,	
2017-08-03 16:18:10,614 Epoch[20] Batch [990]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.109717,	
2017-08-03 16:18:18,944 Epoch[20] Batch [1000]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.109818,	
2017-08-03 16:18:28,041 Epoch[20] Batch [1010]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.109833,	
2017-08-03 16:18:35,369 Epoch[20] Batch [1020]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.109786,	
2017-08-03 16:18:43,284 Epoch[20] Batch [1030]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.109901,	
2017-08-03 16:18:52,420 Epoch[20] Batch [1040]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.109841,	
2017-08-03 16:19:01,915 Epoch[20] Batch [1050]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.109760,	
2017-08-03 16:19:09,643 Epoch[20] Batch [1060]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.109761,	
2017-08-03 16:19:18,366 Epoch[20] Batch [1070]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.109959,	
2017-08-03 16:19:26,342 Epoch[20] Batch [1080]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.110097,	
2017-08-03 16:19:35,939 Epoch[20] Batch [1090]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.110121,	
2017-08-03 16:19:44,072 Epoch[20] Batch [1100]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.110100,	
2017-08-03 16:19:52,438 Epoch[20] Batch [1110]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.110060,	
2017-08-03 16:20:01,066 Epoch[20] Batch [1120]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.110055,	
2017-08-03 16:20:10,277 Epoch[20] Batch [1130]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.110220,	
2017-08-03 16:20:19,675 Epoch[20] Batch [1140]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.110290,	
2017-08-03 16:20:29,141 Epoch[20] Batch [1150]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.110326,	
2017-08-03 16:20:38,032 Epoch[20] Batch [1160]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.110377,	
2017-08-03 16:20:47,081 Epoch[20] Batch [1170]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.110365,	
2017-08-03 16:20:55,420 Epoch[20] Batch [1180]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.110303,	
2017-08-03 16:21:03,303 Epoch[20] Batch [1190]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.110314,	
2017-08-03 16:21:11,364 Epoch[20] Batch [1200]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.110397,	
2017-08-03 16:21:20,085 Epoch[20] Batch [1210]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.110451,	
2017-08-03 16:21:27,714 Epoch[20] Batch [1220]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.110505,	
2017-08-03 16:21:35,473 Epoch[20] Batch [1230]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.110467,	
2017-08-03 16:21:45,219 Epoch[20] Batch [1240]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.110468,	
2017-08-03 16:21:54,534 Epoch[20] Batch [1250]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.110446,	
2017-08-03 16:22:02,594 Epoch[20] Batch [1260]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.110397,	
2017-08-03 16:22:10,336 Epoch[20] Batch [1270]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.110748,	
2017-08-03 16:22:19,289 Epoch[20] Batch [1280]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.114009,	
2017-08-03 16:22:29,382 Epoch[20] Batch [1290]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.117150,	
2017-08-03 16:22:37,344 Epoch[20] Batch [1300]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.119096,	
2017-08-03 16:22:45,522 Epoch[20] Batch [1310]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.121280,	
2017-08-03 16:22:53,004 Epoch[20] Batch [1320]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.123183,	
2017-08-03 16:23:00,820 Epoch[20] Batch [1330]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.124090,	
2017-08-03 16:23:08,114 Epoch[20] Batch [1340]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.125397,	
2017-08-03 16:23:16,298 Epoch[20] Batch [1350]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.126038,	
2017-08-03 16:23:26,431 Epoch[20] Batch [1360]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.126623,	
2017-08-03 16:23:37,377 Epoch[20] Batch [1370]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.127054,	
2017-08-03 16:23:49,261 Epoch[20] Batch [1380]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.127640,	
2017-08-03 16:23:57,941 Epoch[20] Batch [1390]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.127938,	
2017-08-03 16:24:06,186 Epoch[20] Batch [1400]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.128480,	
2017-08-03 16:24:14,514 Epoch[20] Batch [1410]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.128606,	
2017-08-03 16:24:22,464 Epoch[20] Batch [1420]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.128862,	
2017-08-03 16:24:30,127 Epoch[20] Batch [1430]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.128993,	
2017-08-03 16:24:39,404 Epoch[20] Batch [1440]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.129339,	
2017-08-03 16:24:48,110 Epoch[20] Batch [1450]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.129589,	
2017-08-03 16:24:55,976 Epoch[20] Batch [1460]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.129644,	
2017-08-03 16:25:04,847 Epoch[20] Batch [1470]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.129957,	
2017-08-03 16:25:14,081 Epoch[20] Batch [1480]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.130246,	
2017-08-03 16:25:18,638 Epoch[20] Train-FCNLogLoss=0.130439
2017-08-03 16:25:18,638 Epoch[20] Time cost=1250.643
2017-08-03 16:25:19,902 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0021.params"
2017-08-03 16:25:25,910 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0021.states"
2017-08-03 16:25:36,451 Epoch[21] Batch [10]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.190624,	
2017-08-03 16:25:45,317 Epoch[21] Batch [20]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.192122,	
2017-08-03 16:25:53,388 Epoch[21] Batch [30]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.186987,	
2017-08-03 16:26:01,103 Epoch[21] Batch [40]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.183682,	
2017-08-03 16:26:09,780 Epoch[21] Batch [50]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.181930,	
2017-08-03 16:26:17,959 Epoch[21] Batch [60]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.177730,	
2017-08-03 16:26:26,988 Epoch[21] Batch [70]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.176651,	
2017-08-03 16:26:35,556 Epoch[21] Batch [80]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.174343,	
2017-08-03 16:26:43,950 Epoch[21] Batch [90]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.173863,	
2017-08-03 16:26:52,136 Epoch[21] Batch [100]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.171131,	
2017-08-03 16:27:00,473 Epoch[21] Batch [110]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.169735,	
2017-08-03 16:27:08,355 Epoch[21] Batch [120]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.167201,	
2017-08-03 16:27:15,977 Epoch[21] Batch [130]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.165177,	
2017-08-03 16:27:24,016 Epoch[21] Batch [140]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.162624,	
2017-08-03 16:27:32,066 Epoch[21] Batch [150]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.161252,	
2017-08-03 16:27:40,322 Epoch[21] Batch [160]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.160290,	
2017-08-03 16:27:47,759 Epoch[21] Batch [170]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.158863,	
2017-08-03 16:27:56,593 Epoch[21] Batch [180]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.159649,	
2017-08-03 16:28:04,732 Epoch[21] Batch [190]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.160024,	
2017-08-03 16:28:12,653 Epoch[21] Batch [200]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.161183,	
2017-08-03 16:28:22,735 Epoch[21] Batch [210]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.161507,	
2017-08-03 16:28:32,008 Epoch[21] Batch [220]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.160453,	
2017-08-03 16:28:39,692 Epoch[21] Batch [230]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.159720,	
2017-08-03 16:28:48,842 Epoch[21] Batch [240]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.161248,	
2017-08-03 16:28:59,504 Epoch[21] Batch [250]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.160758,	
2017-08-03 16:29:07,991 Epoch[21] Batch [260]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.160104,	
2017-08-03 16:29:16,442 Epoch[21] Batch [270]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.158789,	
2017-08-03 16:29:26,339 Epoch[21] Batch [280]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.158906,	
2017-08-03 16:29:35,248 Epoch[21] Batch [290]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.158311,	
2017-08-03 16:29:42,831 Epoch[21] Batch [300]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.157508,	
2017-08-03 16:29:50,714 Epoch[21] Batch [310]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.156644,	
2017-08-03 16:29:58,073 Epoch[21] Batch [320]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.155249,	
2017-08-03 16:30:07,791 Epoch[21] Batch [330]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.154527,	
2017-08-03 16:30:17,656 Epoch[21] Batch [340]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.153757,	
2017-08-03 16:30:25,314 Epoch[21] Batch [350]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.153072,	
2017-08-03 16:30:34,412 Epoch[21] Batch [360]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.152490,	
2017-08-03 16:30:42,633 Epoch[21] Batch [370]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.152102,	
2017-08-03 16:30:50,122 Epoch[21] Batch [380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.152929,	
2017-08-03 16:30:59,514 Epoch[21] Batch [390]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.152188,	
2017-08-03 16:31:07,467 Epoch[21] Batch [400]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.151489,	
2017-08-03 16:31:15,160 Epoch[21] Batch [410]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.151372,	
2017-08-03 16:31:23,629 Epoch[21] Batch [420]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.151120,	
2017-08-03 16:31:32,171 Epoch[21] Batch [430]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.150208,	
2017-08-03 16:31:41,087 Epoch[21] Batch [440]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.149862,	
2017-08-03 16:31:48,780 Epoch[21] Batch [450]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.149692,	
2017-08-03 16:31:58,121 Epoch[21] Batch [460]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.149153,	
2017-08-03 16:32:06,664 Epoch[21] Batch [470]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.148926,	
2017-08-03 16:32:15,060 Epoch[21] Batch [480]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.148420,	
2017-08-03 16:32:24,156 Epoch[21] Batch [490]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.147895,	
2017-08-03 16:32:32,220 Epoch[21] Batch [500]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.147532,	
2017-08-03 16:32:41,531 Epoch[21] Batch [510]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.146938,	
2017-08-03 16:32:50,825 Epoch[21] Batch [520]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.146422,	
2017-08-03 16:32:58,910 Epoch[21] Batch [530]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.145988,	
2017-08-03 16:33:06,618 Epoch[21] Batch [540]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.145512,	
2017-08-03 16:33:14,920 Epoch[21] Batch [550]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.144994,	
2017-08-03 16:33:23,253 Epoch[21] Batch [560]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.144270,	
2017-08-03 16:33:32,180 Epoch[21] Batch [570]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.143931,	
2017-08-03 16:33:40,468 Epoch[21] Batch [580]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.143871,	
2017-08-03 16:33:49,270 Epoch[21] Batch [590]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.143577,	
2017-08-03 16:33:57,447 Epoch[21] Batch [600]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.143451,	
2017-08-03 16:34:05,939 Epoch[21] Batch [610]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.143013,	
2017-08-03 16:34:14,042 Epoch[21] Batch [620]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.142582,	
2017-08-03 16:34:22,394 Epoch[21] Batch [630]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.142279,	
2017-08-03 16:34:29,848 Epoch[21] Batch [640]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.142002,	
2017-08-03 16:34:38,322 Epoch[21] Batch [650]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.141542,	
2017-08-03 16:34:47,487 Epoch[21] Batch [660]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.141294,	
2017-08-03 16:34:56,251 Epoch[21] Batch [670]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.141168,	
2017-08-03 16:35:06,242 Epoch[21] Batch [680]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.140944,	
2017-08-03 16:35:14,076 Epoch[21] Batch [690]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.140788,	
2017-08-03 16:35:21,936 Epoch[21] Batch [700]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.140668,	
2017-08-03 16:35:29,817 Epoch[21] Batch [710]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.140251,	
2017-08-03 16:35:37,478 Epoch[21] Batch [720]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.139981,	
2017-08-03 16:35:45,387 Epoch[21] Batch [730]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.139747,	
2017-08-03 16:35:54,093 Epoch[21] Batch [740]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.139574,	
2017-08-03 16:36:03,416 Epoch[21] Batch [750]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.139311,	
2017-08-03 16:36:11,415 Epoch[21] Batch [760]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.139066,	
2017-08-03 16:36:20,212 Epoch[21] Batch [770]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.139076,	
2017-08-03 16:36:27,728 Epoch[21] Batch [780]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.139120,	
2017-08-03 16:36:37,054 Epoch[21] Batch [790]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.138987,	
2017-08-03 16:36:45,294 Epoch[21] Batch [800]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.138929,	
2017-08-03 16:36:54,540 Epoch[21] Batch [810]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.138924,	
2017-08-03 16:37:02,280 Epoch[21] Batch [820]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.138734,	
2017-08-03 16:37:10,129 Epoch[21] Batch [830]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.138529,	
2017-08-03 16:37:18,565 Epoch[21] Batch [840]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.138158,	
2017-08-03 16:37:27,900 Epoch[21] Batch [850]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.138058,	
2017-08-03 16:37:37,066 Epoch[21] Batch [860]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.137905,	
2017-08-03 16:37:45,502 Epoch[21] Batch [870]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.137787,	
2017-08-03 16:37:53,329 Epoch[21] Batch [880]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.137752,	
2017-08-03 16:38:02,877 Epoch[21] Batch [890]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.137562,	
2017-08-03 16:38:12,981 Epoch[21] Batch [900]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.137593,	
2017-08-03 16:38:23,048 Epoch[21] Batch [910]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.137640,	
2017-08-03 16:38:32,364 Epoch[21] Batch [920]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.137508,	
2017-08-03 16:38:40,394 Epoch[21] Batch [930]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.137338,	
2017-08-03 16:38:48,829 Epoch[21] Batch [940]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.137251,	
2017-08-03 16:38:57,899 Epoch[21] Batch [950]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.136971,	
2017-08-03 16:39:06,148 Epoch[21] Batch [960]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.137322,	
2017-08-03 16:39:15,839 Epoch[21] Batch [970]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.137460,	
2017-08-03 16:39:25,525 Epoch[21] Batch [980]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.137440,	
2017-08-03 16:39:35,163 Epoch[21] Batch [990]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.137472,	
2017-08-03 16:39:45,165 Epoch[21] Batch [1000]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.137549,	
2017-08-03 16:39:53,468 Epoch[21] Batch [1010]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.137447,	
2017-08-03 16:40:01,854 Epoch[21] Batch [1020]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.137371,	
2017-08-03 16:40:09,920 Epoch[21] Batch [1030]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.137284,	
2017-08-03 16:40:18,206 Epoch[21] Batch [1040]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.137193,	
2017-08-03 16:40:26,564 Epoch[21] Batch [1050]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.137262,	
2017-08-03 16:40:35,043 Epoch[21] Batch [1060]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.137124,	
2017-08-03 16:40:42,957 Epoch[21] Batch [1070]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.137029,	
2017-08-03 16:40:52,602 Epoch[21] Batch [1080]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.137022,	
2017-08-03 16:41:00,284 Epoch[21] Batch [1090]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.137014,	
2017-08-03 16:41:09,086 Epoch[21] Batch [1100]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.137096,	
2017-08-03 16:41:18,559 Epoch[21] Batch [1110]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.137140,	
2017-08-03 16:41:26,453 Epoch[21] Batch [1120]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.137226,	
2017-08-03 16:41:34,949 Epoch[21] Batch [1130]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.137238,	
2017-08-03 16:41:43,326 Epoch[21] Batch [1140]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.137002,	
2017-08-03 16:41:52,348 Epoch[21] Batch [1150]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.137046,	
2017-08-03 16:42:00,291 Epoch[21] Batch [1160]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.137028,	
2017-08-03 16:42:09,462 Epoch[21] Batch [1170]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.136895,	
2017-08-03 16:42:19,229 Epoch[21] Batch [1180]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.137336,	
2017-08-03 16:42:27,030 Epoch[21] Batch [1190]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.137668,	
2017-08-03 16:42:35,230 Epoch[21] Batch [1200]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.138283,	
2017-08-03 16:42:43,928 Epoch[21] Batch [1210]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.138387,	
2017-08-03 16:42:51,194 Epoch[21] Batch [1220]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.138600,	
2017-08-03 16:43:00,104 Epoch[21] Batch [1230]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.138734,	
2017-08-03 16:43:09,313 Epoch[21] Batch [1240]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.138688,	
2017-08-03 16:43:17,575 Epoch[21] Batch [1250]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.138655,	
2017-08-03 16:43:25,525 Epoch[21] Batch [1260]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.138479,	
2017-08-03 16:43:33,700 Epoch[21] Batch [1270]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.138632,	
2017-08-03 16:43:40,035 Epoch[21] Batch [1280]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.138491,	
2017-08-03 16:43:47,584 Epoch[21] Batch [1290]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.138682,	
2017-08-03 16:43:55,001 Epoch[21] Batch [1300]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.138616,	
2017-08-03 16:44:03,587 Epoch[21] Batch [1310]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.138648,	
2017-08-03 16:44:12,218 Epoch[21] Batch [1320]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.138544,	
2017-08-03 16:44:20,414 Epoch[21] Batch [1330]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.138438,	
2017-08-03 16:44:27,023 Epoch[21] Batch [1340]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.138315,	
2017-08-03 16:44:34,466 Epoch[21] Batch [1350]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.138342,	
2017-08-03 16:44:40,996 Epoch[21] Batch [1360]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.138340,	
2017-08-03 16:44:48,457 Epoch[21] Batch [1370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.138305,	
2017-08-03 16:44:54,793 Epoch[21] Batch [1380]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.138333,	
2017-08-03 16:45:01,359 Epoch[21] Batch [1390]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.138159,	
2017-08-03 16:45:09,996 Epoch[21] Batch [1400]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.138062,	
2017-08-03 16:45:16,904 Epoch[21] Batch [1410]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.138228,	
2017-08-03 16:45:25,154 Epoch[21] Batch [1420]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.138223,	
2017-08-03 16:45:33,278 Epoch[21] Batch [1430]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.138160,	
2017-08-03 16:45:40,403 Epoch[21] Batch [1440]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.138030,	
2017-08-03 16:45:46,745 Epoch[21] Batch [1450]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.137917,	
2017-08-03 16:45:53,942 Epoch[21] Batch [1460]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.137720,	
2017-08-03 16:46:00,870 Epoch[21] Batch [1470]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.137656,	
2017-08-03 16:46:07,578 Epoch[21] Batch [1480]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.137565,	
2017-08-03 16:46:11,966 Epoch[21] Train-FCNLogLoss=0.137501
2017-08-03 16:46:11,967 Epoch[21] Time cost=1246.056
2017-08-03 16:46:12,897 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0022.params"
2017-08-03 16:46:16,427 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0022.states"
2017-08-03 16:46:24,161 Epoch[22] Batch [10]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.125226,	
2017-08-03 16:46:31,446 Epoch[22] Batch [20]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.123569,	
2017-08-03 16:46:38,400 Epoch[22] Batch [30]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.119584,	
2017-08-03 16:46:45,493 Epoch[22] Batch [40]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.116501,	
2017-08-03 16:46:53,166 Epoch[22] Batch [50]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.114109,	
2017-08-03 16:47:00,629 Epoch[22] Batch [60]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.116451,	
2017-08-03 16:47:07,143 Epoch[22] Batch [70]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.117418,	
2017-08-03 16:47:13,736 Epoch[22] Batch [80]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.118422,	
2017-08-03 16:47:20,400 Epoch[22] Batch [90]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.119157,	
2017-08-03 16:47:27,031 Epoch[22] Batch [100]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.121117,	
2017-08-03 16:47:33,382 Epoch[22] Batch [110]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.121529,	
2017-08-03 16:47:39,958 Epoch[22] Batch [120]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.122180,	
2017-08-03 16:47:46,674 Epoch[22] Batch [130]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.122774,	
2017-08-03 16:47:53,397 Epoch[22] Batch [140]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.122551,	
2017-08-03 16:47:59,842 Epoch[22] Batch [150]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.122571,	
2017-08-03 16:48:06,875 Epoch[22] Batch [160]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.123854,	
2017-08-03 16:48:13,669 Epoch[22] Batch [170]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.124160,	
2017-08-03 16:48:20,417 Epoch[22] Batch [180]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.124385,	
2017-08-03 16:48:27,154 Epoch[22] Batch [190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.124431,	
2017-08-03 16:48:33,600 Epoch[22] Batch [200]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.124350,	
2017-08-03 16:48:40,153 Epoch[22] Batch [210]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.123674,	
2017-08-03 16:48:46,890 Epoch[22] Batch [220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.124113,	
2017-08-03 16:48:53,420 Epoch[22] Batch [230]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.124165,	
2017-08-03 16:49:00,119 Epoch[22] Batch [240]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.124023,	
2017-08-03 16:49:06,953 Epoch[22] Batch [250]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.123756,	
2017-08-03 16:49:13,469 Epoch[22] Batch [260]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.123117,	
2017-08-03 16:49:20,271 Epoch[22] Batch [270]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.123017,	
2017-08-03 16:49:26,808 Epoch[22] Batch [280]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.122857,	
2017-08-03 16:49:33,528 Epoch[22] Batch [290]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.122507,	
2017-08-03 16:49:40,082 Epoch[22] Batch [300]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.122037,	
2017-08-03 16:49:46,783 Epoch[22] Batch [310]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.121426,	
2017-08-03 16:49:53,700 Epoch[22] Batch [320]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.121573,	
2017-08-03 16:50:00,529 Epoch[22] Batch [330]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.121334,	
2017-08-03 16:50:07,309 Epoch[22] Batch [340]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.121317,	
2017-08-03 16:50:13,709 Epoch[22] Batch [350]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.121046,	
2017-08-03 16:50:19,806 Epoch[22] Batch [360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.120749,	
2017-08-03 16:50:26,512 Epoch[22] Batch [370]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.120497,	
2017-08-03 16:50:33,577 Epoch[22] Batch [380]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.121005,	
2017-08-03 16:50:41,504 Epoch[22] Batch [390]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.120890,	
2017-08-03 16:50:48,423 Epoch[22] Batch [400]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.120801,	
2017-08-03 16:50:54,874 Epoch[22] Batch [410]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.120828,	
2017-08-03 16:51:03,167 Epoch[22] Batch [420]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.120699,	
2017-08-03 16:51:10,723 Epoch[22] Batch [430]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.120512,	
2017-08-03 16:51:18,589 Epoch[22] Batch [440]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.120142,	
2017-08-03 16:51:25,084 Epoch[22] Batch [450]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.119978,	
2017-08-03 16:51:31,763 Epoch[22] Batch [460]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.120166,	
2017-08-03 16:51:38,317 Epoch[22] Batch [470]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.120260,	
2017-08-03 16:51:44,629 Epoch[22] Batch [480]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.120107,	
2017-08-03 16:51:51,373 Epoch[22] Batch [490]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.120048,	
2017-08-03 16:51:58,201 Epoch[22] Batch [500]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.120236,	
2017-08-03 16:52:04,794 Epoch[22] Batch [510]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.120494,	
2017-08-03 16:52:11,776 Epoch[22] Batch [520]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.120742,	
2017-08-03 16:52:18,170 Epoch[22] Batch [530]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.120680,	
2017-08-03 16:52:24,812 Epoch[22] Batch [540]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.120447,	
2017-08-03 16:52:31,568 Epoch[22] Batch [550]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.120556,	
2017-08-03 16:52:38,229 Epoch[22] Batch [560]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.121007,	
2017-08-03 16:52:44,893 Epoch[22] Batch [570]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.121332,	
2017-08-03 16:52:51,786 Epoch[22] Batch [580]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.121511,	
2017-08-03 16:52:58,490 Epoch[22] Batch [590]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.121470,	
2017-08-03 16:53:05,316 Epoch[22] Batch [600]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.121800,	
2017-08-03 16:53:12,109 Epoch[22] Batch [610]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.121885,	
2017-08-03 16:53:18,711 Epoch[22] Batch [620]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.121777,	
2017-08-03 16:53:25,588 Epoch[22] Batch [630]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.121704,	
2017-08-03 16:53:32,688 Epoch[22] Batch [640]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.121735,	
2017-08-03 16:53:39,808 Epoch[22] Batch [650]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.121595,	
2017-08-03 16:53:46,315 Epoch[22] Batch [660]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.121538,	
2017-08-03 16:53:52,575 Epoch[22] Batch [670]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.121462,	
2017-08-03 16:53:59,111 Epoch[22] Batch [680]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.121265,	
2017-08-03 16:54:05,539 Epoch[22] Batch [690]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.121257,	
2017-08-03 16:54:11,816 Epoch[22] Batch [700]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.121141,	
2017-08-03 16:54:18,030 Epoch[22] Batch [710]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.121326,	
2017-08-03 16:54:24,487 Epoch[22] Batch [720]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.121534,	
2017-08-03 16:54:30,973 Epoch[22] Batch [730]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.121699,	
2017-08-03 16:54:37,408 Epoch[22] Batch [740]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.121774,	
2017-08-03 16:54:43,707 Epoch[22] Batch [750]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.121727,	
2017-08-03 16:54:49,697 Epoch[22] Batch [760]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.121865,	
2017-08-03 16:54:55,886 Epoch[22] Batch [770]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.122000,	
2017-08-03 16:55:02,464 Epoch[22] Batch [780]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.122054,	
2017-08-03 16:55:08,859 Epoch[22] Batch [790]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.121896,	
2017-08-03 16:55:15,700 Epoch[22] Batch [800]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.121758,	
2017-08-03 16:55:22,224 Epoch[22] Batch [810]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.121672,	
2017-08-03 16:55:28,811 Epoch[22] Batch [820]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.121721,	
2017-08-03 16:55:34,964 Epoch[22] Batch [830]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.121809,	
2017-08-03 16:55:41,409 Epoch[22] Batch [840]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.122218,	
2017-08-03 16:55:47,880 Epoch[22] Batch [850]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.122235,	
2017-08-03 16:55:54,326 Epoch[22] Batch [860]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.122342,	
2017-08-03 16:56:01,017 Epoch[22] Batch [870]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.122318,	
2017-08-03 16:56:07,646 Epoch[22] Batch [880]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.122435,	
2017-08-03 16:56:13,966 Epoch[22] Batch [890]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.122382,	
2017-08-03 16:56:20,262 Epoch[22] Batch [900]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.122556,	
2017-08-03 16:56:26,378 Epoch[22] Batch [910]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.122559,	
2017-08-03 16:56:32,525 Epoch[22] Batch [920]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.122561,	
2017-08-03 16:56:38,979 Epoch[22] Batch [930]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.122688,	
2017-08-03 16:56:45,367 Epoch[22] Batch [940]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.122639,	
2017-08-03 16:56:51,844 Epoch[22] Batch [950]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.122557,	
2017-08-03 16:56:57,768 Epoch[22] Batch [960]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.122509,	
2017-08-03 16:57:03,846 Epoch[22] Batch [970]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.122548,	
2017-08-03 16:57:10,070 Epoch[22] Batch [980]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.122577,	
2017-08-03 16:57:16,444 Epoch[22] Batch [990]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.122576,	
2017-08-03 16:57:22,504 Epoch[22] Batch [1000]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.122598,	
2017-08-03 16:57:28,524 Epoch[22] Batch [1010]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.122490,	
2017-08-03 16:57:34,783 Epoch[22] Batch [1020]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.122541,	
2017-08-03 16:57:41,008 Epoch[22] Batch [1030]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.122575,	
2017-08-03 16:57:47,432 Epoch[22] Batch [1040]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.122513,	
2017-08-03 16:57:53,633 Epoch[22] Batch [1050]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.122538,	
2017-08-03 16:57:59,778 Epoch[22] Batch [1060]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.122676,	
2017-08-03 16:58:06,419 Epoch[22] Batch [1070]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.122822,	
2017-08-03 16:58:12,643 Epoch[22] Batch [1080]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.122909,	
2017-08-03 16:58:18,755 Epoch[22] Batch [1090]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.122931,	
2017-08-03 16:58:25,018 Epoch[22] Batch [1100]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.122969,	
2017-08-03 16:58:31,309 Epoch[22] Batch [1110]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.122966,	
2017-08-03 16:58:37,533 Epoch[22] Batch [1120]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.122823,	
2017-08-03 16:58:43,790 Epoch[22] Batch [1130]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.122788,	
2017-08-03 16:58:50,163 Epoch[22] Batch [1140]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.122906,	
2017-08-03 16:58:56,737 Epoch[22] Batch [1150]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.122854,	
2017-08-03 16:59:03,251 Epoch[22] Batch [1160]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.122780,	
2017-08-03 16:59:09,680 Epoch[22] Batch [1170]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.122982,	
2017-08-03 16:59:15,680 Epoch[22] Batch [1180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.122912,	
2017-08-03 16:59:22,054 Epoch[22] Batch [1190]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.122891,	
2017-08-03 16:59:28,359 Epoch[22] Batch [1200]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.122927,	
2017-08-03 16:59:34,769 Epoch[22] Batch [1210]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.122961,	
2017-08-03 16:59:41,032 Epoch[22] Batch [1220]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.122903,	
2017-08-03 16:59:47,589 Epoch[22] Batch [1230]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.122894,	
2017-08-03 16:59:53,928 Epoch[22] Batch [1240]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.122881,	
2017-08-03 17:00:00,104 Epoch[22] Batch [1250]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.122921,	
2017-08-03 17:00:06,563 Epoch[22] Batch [1260]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.122955,	
2017-08-03 17:00:12,924 Epoch[22] Batch [1270]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.122907,	
2017-08-03 17:00:19,142 Epoch[22] Batch [1280]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.122913,	
2017-08-03 17:00:25,367 Epoch[22] Batch [1290]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.122982,	
2017-08-03 17:00:31,516 Epoch[22] Batch [1300]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.122946,	
2017-08-03 17:00:38,195 Epoch[22] Batch [1310]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.122915,	
2017-08-03 17:00:44,445 Epoch[22] Batch [1320]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.122875,	
2017-08-03 17:00:50,900 Epoch[22] Batch [1330]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.122722,	
2017-08-03 17:00:56,943 Epoch[22] Batch [1340]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.122660,	
2017-08-03 17:01:01,764 Epoch[22] Batch [1350]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.122579,	
2017-08-03 17:01:05,987 Epoch[22] Batch [1360]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.122671,	
2017-08-03 17:01:10,215 Epoch[22] Batch [1370]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.122646,	
2017-08-03 17:01:14,731 Epoch[22] Batch [1380]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.122657,	
2017-08-03 17:01:19,009 Epoch[22] Batch [1390]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.122621,	
2017-08-03 17:01:23,442 Epoch[22] Batch [1400]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.122674,	
2017-08-03 17:01:27,744 Epoch[22] Batch [1410]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.122629,	
2017-08-03 17:01:32,052 Epoch[22] Batch [1420]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.122631,	
2017-08-03 17:01:36,248 Epoch[22] Batch [1430]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.122531,	
2017-08-03 17:01:40,562 Epoch[22] Batch [1440]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.122543,	
2017-08-03 17:01:44,704 Epoch[22] Batch [1450]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.122507,	
2017-08-03 17:01:49,155 Epoch[22] Batch [1460]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.122561,	
2017-08-03 17:01:53,445 Epoch[22] Batch [1470]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.122588,	
2017-08-03 17:01:58,229 Epoch[22] Batch [1480]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.122679,	
2017-08-03 17:02:00,774 Epoch[22] Train-FCNLogLoss=0.122659
2017-08-03 17:02:00,775 Epoch[22] Time cost=944.347
2017-08-03 17:02:01,792 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0023.params"
2017-08-03 17:02:04,590 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0023.states"
2017-08-03 17:02:09,426 Epoch[23] Batch [10]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.129153,	
2017-08-03 17:02:13,624 Epoch[23] Batch [20]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.118093,	
2017-08-03 17:02:17,632 Epoch[23] Batch [30]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112174,	
2017-08-03 17:02:21,904 Epoch[23] Batch [40]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.112284,	
2017-08-03 17:02:26,395 Epoch[23] Batch [50]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.114542,	
2017-08-03 17:02:30,536 Epoch[23] Batch [60]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115604,	
2017-08-03 17:02:34,868 Epoch[23] Batch [70]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.116545,	
2017-08-03 17:02:39,225 Epoch[23] Batch [80]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.115114,	
2017-08-03 17:02:43,439 Epoch[23] Batch [90]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.114467,	
2017-08-03 17:02:48,281 Epoch[23] Batch [100]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.114135,	
2017-08-03 17:02:52,505 Epoch[23] Batch [110]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113570,	
2017-08-03 17:02:56,761 Epoch[23] Batch [120]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.112583,	
2017-08-03 17:03:01,150 Epoch[23] Batch [130]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.111709,	
2017-08-03 17:03:06,144 Epoch[23] Batch [140]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.112038,	
2017-08-03 17:03:10,967 Epoch[23] Batch [150]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.112508,	
2017-08-03 17:03:16,662 Epoch[23] Batch [160]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.112842,	
2017-08-03 17:03:21,556 Epoch[23] Batch [170]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.113797,	
2017-08-03 17:03:26,583 Epoch[23] Batch [180]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.114780,	
2017-08-03 17:03:32,139 Epoch[23] Batch [190]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.114780,	
2017-08-03 17:03:36,887 Epoch[23] Batch [200]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.115632,	
2017-08-03 17:03:42,558 Epoch[23] Batch [210]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.116364,	
2017-08-03 17:03:47,569 Epoch[23] Batch [220]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.116625,	
2017-08-03 17:03:52,522 Epoch[23] Batch [230]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.117386,	
2017-08-03 17:03:58,432 Epoch[23] Batch [240]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.118095,	
2017-08-03 17:04:03,142 Epoch[23] Batch [250]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.118466,	
2017-08-03 17:04:09,088 Epoch[23] Batch [260]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.118664,	
2017-08-03 17:04:13,955 Epoch[23] Batch [270]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.118587,	
2017-08-03 17:04:19,704 Epoch[23] Batch [280]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.118165,	
2017-08-03 17:04:24,772 Epoch[23] Batch [290]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.117741,	
2017-08-03 17:04:30,651 Epoch[23] Batch [300]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.117597,	
2017-08-03 17:04:35,574 Epoch[23] Batch [310]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.117500,	
2017-08-03 17:04:41,568 Epoch[23] Batch [320]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.117809,	
2017-08-03 17:04:46,557 Epoch[23] Batch [330]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.117817,	
2017-08-03 17:04:52,775 Epoch[23] Batch [340]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.117830,	
2017-08-03 17:04:57,623 Epoch[23] Batch [350]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.117615,	
2017-08-03 17:05:03,627 Epoch[23] Batch [360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.117810,	
2017-08-03 17:05:08,761 Epoch[23] Batch [370]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.118016,	
2017-08-03 17:05:14,966 Epoch[23] Batch [380]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.117919,	
2017-08-03 17:05:20,044 Epoch[23] Batch [390]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118102,	
2017-08-03 17:05:26,098 Epoch[23] Batch [400]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.118245,	
2017-08-03 17:05:31,143 Epoch[23] Batch [410]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.118888,	
2017-08-03 17:05:36,787 Epoch[23] Batch [420]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.119065,	
2017-08-03 17:05:42,095 Epoch[23] Batch [430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119082,	
2017-08-03 17:05:47,174 Epoch[23] Batch [440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118913,	
2017-08-03 17:05:53,093 Epoch[23] Batch [450]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.118945,	
2017-08-03 17:05:58,715 Epoch[23] Batch [460]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.118561,	
2017-08-03 17:06:04,574 Epoch[23] Batch [470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.118154,	
2017-08-03 17:06:10,830 Epoch[23] Batch [480]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.117993,	
2017-08-03 17:06:16,890 Epoch[23] Batch [490]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.117830,	
2017-08-03 17:06:22,620 Epoch[23] Batch [500]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.117747,	
2017-08-03 17:06:29,136 Epoch[23] Batch [510]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.117980,	
2017-08-03 17:06:34,264 Epoch[23] Batch [520]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.118052,	
2017-08-03 17:06:40,419 Epoch[23] Batch [530]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.118041,	
2017-08-03 17:06:45,839 Epoch[23] Batch [540]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.118184,	
2017-08-03 17:06:51,944 Epoch[23] Batch [550]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.118197,	
2017-08-03 17:06:57,562 Epoch[23] Batch [560]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.118126,	
2017-08-03 17:07:03,167 Epoch[23] Batch [570]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.118070,	
2017-08-03 17:07:08,638 Epoch[23] Batch [580]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.117986,	
2017-08-03 17:07:14,452 Epoch[23] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117968,	
2017-08-03 17:07:20,243 Epoch[23] Batch [600]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118145,	
2017-08-03 17:07:26,631 Epoch[23] Batch [610]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.118205,	
2017-08-03 17:07:32,225 Epoch[23] Batch [620]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.118195,	
2017-08-03 17:07:38,501 Epoch[23] Batch [630]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.118182,	
2017-08-03 17:07:44,368 Epoch[23] Batch [640]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.117999,	
2017-08-03 17:07:50,122 Epoch[23] Batch [650]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.118006,	
2017-08-03 17:07:56,535 Epoch[23] Batch [660]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.117856,	
2017-08-03 17:08:02,491 Epoch[23] Batch [670]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.117793,	
2017-08-03 17:08:08,922 Epoch[23] Batch [680]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.117893,	
2017-08-03 17:08:14,670 Epoch[23] Batch [690]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.117848,	
2017-08-03 17:08:20,271 Epoch[23] Batch [700]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.117951,	
2017-08-03 17:08:25,489 Epoch[23] Batch [710]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.117689,	
2017-08-03 17:08:31,739 Epoch[23] Batch [720]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.117535,	
2017-08-03 17:08:36,953 Epoch[23] Batch [730]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.117391,	
2017-08-03 17:08:42,706 Epoch[23] Batch [740]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.117595,	
2017-08-03 17:08:49,088 Epoch[23] Batch [750]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.117511,	
2017-08-03 17:08:54,290 Epoch[23] Batch [760]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.117533,	
2017-08-03 17:09:00,173 Epoch[23] Batch [770]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.117409,	
2017-08-03 17:09:05,738 Epoch[23] Batch [780]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.117533,	
2017-08-03 17:09:11,748 Epoch[23] Batch [790]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.117605,	
2017-08-03 17:09:17,398 Epoch[23] Batch [800]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.117484,	
2017-08-03 17:09:24,188 Epoch[23] Batch [810]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.117455,	
2017-08-03 17:09:29,547 Epoch[23] Batch [820]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117499,	
2017-08-03 17:09:35,208 Epoch[23] Batch [830]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.117798,	
2017-08-03 17:09:42,109 Epoch[23] Batch [840]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.117831,	
2017-08-03 17:09:47,685 Epoch[23] Batch [850]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.117763,	
2017-08-03 17:09:53,364 Epoch[23] Batch [860]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.117780,	
2017-08-03 17:09:59,506 Epoch[23] Batch [870]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.117789,	
2017-08-03 17:10:05,486 Epoch[23] Batch [880]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.118099,	
2017-08-03 17:10:11,071 Epoch[23] Batch [890]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.118197,	
2017-08-03 17:10:17,422 Epoch[23] Batch [900]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.118297,	
2017-08-03 17:10:23,319 Epoch[23] Batch [910]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.118336,	
2017-08-03 17:10:29,331 Epoch[23] Batch [920]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.118428,	
2017-08-03 17:10:35,143 Epoch[23] Batch [930]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118760,	
2017-08-03 17:10:41,050 Epoch[23] Batch [940]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.118810,	
2017-08-03 17:10:46,859 Epoch[23] Batch [950]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119099,	
2017-08-03 17:10:53,129 Epoch[23] Batch [960]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.119099,	
2017-08-03 17:10:59,390 Epoch[23] Batch [970]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.119064,	
2017-08-03 17:11:05,240 Epoch[23] Batch [980]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.119186,	
2017-08-03 17:11:10,971 Epoch[23] Batch [990]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.119228,	
2017-08-03 17:11:16,400 Epoch[23] Batch [1000]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.119113,	
2017-08-03 17:11:21,336 Epoch[23] Batch [1010]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.119137,	
2017-08-03 17:11:25,983 Epoch[23] Batch [1020]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.118966,	
2017-08-03 17:11:31,228 Epoch[23] Batch [1030]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.118942,	
2017-08-03 17:11:36,501 Epoch[23] Batch [1040]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118815,	
2017-08-03 17:11:41,376 Epoch[23] Batch [1050]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.118712,	
2017-08-03 17:11:46,626 Epoch[23] Batch [1060]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.118595,	
2017-08-03 17:11:52,248 Epoch[23] Batch [1070]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.118645,	
2017-08-03 17:11:57,324 Epoch[23] Batch [1080]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118716,	
2017-08-03 17:12:02,480 Epoch[23] Batch [1090]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.118737,	
2017-08-03 17:12:08,611 Epoch[23] Batch [1100]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.118663,	
2017-08-03 17:12:15,160 Epoch[23] Batch [1110]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.118665,	
2017-08-03 17:12:21,443 Epoch[23] Batch [1120]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.118809,	
2017-08-03 17:12:27,348 Epoch[23] Batch [1130]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.118791,	
2017-08-03 17:12:32,858 Epoch[23] Batch [1140]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.118873,	
2017-08-03 17:12:38,075 Epoch[23] Batch [1150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.118864,	
2017-08-03 17:12:44,352 Epoch[23] Batch [1160]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.118906,	
2017-08-03 17:12:50,087 Epoch[23] Batch [1170]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.119038,	
2017-08-03 17:12:55,471 Epoch[23] Batch [1180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.119028,	
2017-08-03 17:13:00,709 Epoch[23] Batch [1190]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.119100,	
2017-08-03 17:13:05,675 Epoch[23] Batch [1200]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.119156,	
2017-08-03 17:13:10,737 Epoch[23] Batch [1210]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.119224,	
2017-08-03 17:13:16,132 Epoch[23] Batch [1220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119228,	
2017-08-03 17:13:21,294 Epoch[23] Batch [1230]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.119360,	
2017-08-03 17:13:26,809 Epoch[23] Batch [1240]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.119407,	
2017-08-03 17:13:33,003 Epoch[23] Batch [1250]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.119322,	
2017-08-03 17:13:38,233 Epoch[23] Batch [1260]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.119403,	
2017-08-03 17:13:43,509 Epoch[23] Batch [1270]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119351,	
2017-08-03 17:13:48,850 Epoch[23] Batch [1280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119242,	
2017-08-03 17:13:54,548 Epoch[23] Batch [1290]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.119219,	
2017-08-03 17:14:00,814 Epoch[23] Batch [1300]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.119111,	
2017-08-03 17:14:09,129 Epoch[23] Batch [1310]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.119046,	
2017-08-03 17:14:17,693 Epoch[23] Batch [1320]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.119100,	
2017-08-03 17:14:26,061 Epoch[23] Batch [1330]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.119200,	
2017-08-03 17:14:34,544 Epoch[23] Batch [1340]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.119205,	
2017-08-03 17:14:43,097 Epoch[23] Batch [1350]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.119152,	
2017-08-03 17:14:51,338 Epoch[23] Batch [1360]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.119128,	
2017-08-03 17:15:00,064 Epoch[23] Batch [1370]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.119088,	
2017-08-03 17:15:08,792 Epoch[23] Batch [1380]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.119058,	
2017-08-03 17:15:17,289 Epoch[23] Batch [1390]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.118998,	
2017-08-03 17:15:25,992 Epoch[23] Batch [1400]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.119003,	
2017-08-03 17:15:34,772 Epoch[23] Batch [1410]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.119008,	
2017-08-03 17:15:43,173 Epoch[23] Batch [1420]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.118968,	
2017-08-03 17:15:51,838 Epoch[23] Batch [1430]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.118994,	
2017-08-03 17:16:00,252 Epoch[23] Batch [1440]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.119005,	
2017-08-03 17:16:08,972 Epoch[23] Batch [1450]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.119102,	
2017-08-03 17:16:17,403 Epoch[23] Batch [1460]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.119128,	
2017-08-03 17:16:26,079 Epoch[23] Batch [1470]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.119036,	
2017-08-03 17:16:34,858 Epoch[23] Batch [1480]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.119038,	
2017-08-03 17:16:39,970 Epoch[23] Train-FCNLogLoss=0.119030
2017-08-03 17:16:39,970 Epoch[23] Time cost=875.380
2017-08-03 17:16:40,736 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0024.params"
2017-08-03 17:16:44,229 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0024.states"
2017-08-03 17:16:53,852 Epoch[24] Batch [10]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.116827,	
2017-08-03 17:17:02,446 Epoch[24] Batch [20]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.115017,	
2017-08-03 17:17:11,187 Epoch[24] Batch [30]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.117733,	
2017-08-03 17:17:19,555 Epoch[24] Batch [40]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.116468,	
2017-08-03 17:17:28,228 Epoch[24] Batch [50]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.115909,	
2017-08-03 17:17:36,919 Epoch[24] Batch [60]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.115644,	
2017-08-03 17:17:45,594 Epoch[24] Batch [70]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.116453,	
2017-08-03 17:17:54,157 Epoch[24] Batch [80]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.116256,	
2017-08-03 17:18:02,931 Epoch[24] Batch [90]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.115599,	
2017-08-03 17:18:08,890 Epoch[24] Batch [100]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.116700,	
2017-08-03 17:18:14,726 Epoch[24] Batch [110]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.117499,	
2017-08-03 17:18:20,884 Epoch[24] Batch [120]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.117338,	
2017-08-03 17:18:26,710 Epoch[24] Batch [130]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116542,	
2017-08-03 17:18:32,735 Epoch[24] Batch [140]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.115584,	
2017-08-03 17:18:38,691 Epoch[24] Batch [150]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.115577,	
2017-08-03 17:18:44,797 Epoch[24] Batch [160]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.115424,	
2017-08-03 17:18:50,666 Epoch[24] Batch [170]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.116276,	
2017-08-03 17:18:56,385 Epoch[24] Batch [180]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.116130,	
2017-08-03 17:19:02,022 Epoch[24] Batch [190]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.116079,	
2017-08-03 17:19:07,924 Epoch[24] Batch [200]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.116981,	
2017-08-03 17:19:13,443 Epoch[24] Batch [210]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.117431,	
2017-08-03 17:19:19,014 Epoch[24] Batch [220]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.117603,	
2017-08-03 17:19:24,873 Epoch[24] Batch [230]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.117881,	
2017-08-03 17:19:30,755 Epoch[24] Batch [240]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.117549,	
2017-08-03 17:19:36,795 Epoch[24] Batch [250]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.118041,	
2017-08-03 17:19:42,173 Epoch[24] Batch [260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117949,	
2017-08-03 17:19:47,758 Epoch[24] Batch [270]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.117958,	
2017-08-03 17:19:53,649 Epoch[24] Batch [280]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.117597,	
2017-08-03 17:19:59,584 Epoch[24] Batch [290]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.117356,	
2017-08-03 17:20:05,442 Epoch[24] Batch [300]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.117008,	
2017-08-03 17:20:11,561 Epoch[24] Batch [310]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.116626,	
2017-08-03 17:20:17,357 Epoch[24] Batch [320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116741,	
2017-08-03 17:20:24,758 Epoch[24] Batch [330]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.116342,	
2017-08-03 17:20:33,032 Epoch[24] Batch [340]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.116385,	
2017-08-03 17:20:41,405 Epoch[24] Batch [350]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.116075,	
2017-08-03 17:20:49,848 Epoch[24] Batch [360]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.116239,	
2017-08-03 17:20:58,356 Epoch[24] Batch [370]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116478,	
2017-08-03 17:21:06,793 Epoch[24] Batch [380]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.116241,	
2017-08-03 17:21:15,451 Epoch[24] Batch [390]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.116033,	
2017-08-03 17:21:24,275 Epoch[24] Batch [400]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.115954,	
2017-08-03 17:21:32,809 Epoch[24] Batch [410]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.115750,	
2017-08-03 17:21:41,536 Epoch[24] Batch [420]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.115587,	
2017-08-03 17:21:50,317 Epoch[24] Batch [430]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.115672,	
2017-08-03 17:21:58,739 Epoch[24] Batch [440]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.115193,	
2017-08-03 17:22:07,102 Epoch[24] Batch [450]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.115192,	
2017-08-03 17:22:15,906 Epoch[24] Batch [460]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.115004,	
2017-08-03 17:22:24,598 Epoch[24] Batch [470]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.115387,	
2017-08-03 17:22:33,039 Epoch[24] Batch [480]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.115460,	
2017-08-03 17:22:41,804 Epoch[24] Batch [490]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.115789,	
2017-08-03 17:22:50,510 Epoch[24] Batch [500]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.115590,	
2017-08-03 17:22:59,107 Epoch[24] Batch [510]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.115728,	
2017-08-03 17:23:07,649 Epoch[24] Batch [520]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.115845,	
2017-08-03 17:23:16,362 Epoch[24] Batch [530]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.115988,	
2017-08-03 17:23:25,230 Epoch[24] Batch [540]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.115886,	
2017-08-03 17:23:33,589 Epoch[24] Batch [550]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.116131,	
2017-08-03 17:23:42,332 Epoch[24] Batch [560]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.116353,	
2017-08-03 17:23:51,032 Epoch[24] Batch [570]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.116229,	
2017-08-03 17:23:59,612 Epoch[24] Batch [580]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.116316,	
2017-08-03 17:24:08,162 Epoch[24] Batch [590]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.116403,	
2017-08-03 17:24:16,797 Epoch[24] Batch [600]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.116586,	
2017-08-03 17:24:25,605 Epoch[24] Batch [610]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.116671,	
2017-08-03 17:24:32,141 Epoch[24] Batch [620]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.116474,	
2017-08-03 17:24:38,278 Epoch[24] Batch [630]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.116590,	
2017-08-03 17:24:44,314 Epoch[24] Batch [640]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.116852,	
2017-08-03 17:24:50,496 Epoch[24] Batch [650]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.117057,	
2017-08-03 17:24:56,459 Epoch[24] Batch [660]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.117348,	
2017-08-03 17:25:02,723 Epoch[24] Batch [670]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.117565,	
2017-08-03 17:25:09,326 Epoch[24] Batch [680]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.117824,	
2017-08-03 17:25:15,627 Epoch[24] Batch [690]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.118211,	
2017-08-03 17:25:21,951 Epoch[24] Batch [700]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.118624,	
2017-08-03 17:25:28,187 Epoch[24] Batch [710]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.118881,	
2017-08-03 17:25:34,583 Epoch[24] Batch [720]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.119076,	
2017-08-03 17:25:41,104 Epoch[24] Batch [730]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.119227,	
2017-08-03 17:25:47,612 Epoch[24] Batch [740]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.119386,	
2017-08-03 17:25:53,967 Epoch[24] Batch [750]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.119764,	
2017-08-03 17:26:00,388 Epoch[24] Batch [760]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.119879,	
2017-08-03 17:26:06,556 Epoch[24] Batch [770]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.119909,	
2017-08-03 17:26:12,811 Epoch[24] Batch [780]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.120022,	
2017-08-03 17:26:19,466 Epoch[24] Batch [790]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.119979,	
2017-08-03 17:26:25,722 Epoch[24] Batch [800]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.119706,	
2017-08-03 17:26:31,324 Epoch[24] Batch [810]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.119791,	
2017-08-03 17:26:37,451 Epoch[24] Batch [820]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.119743,	
2017-08-03 17:26:43,601 Epoch[24] Batch [830]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.119490,	
2017-08-03 17:26:51,350 Epoch[24] Batch [840]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.119436,	
2017-08-03 17:26:59,938 Epoch[24] Batch [850]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.119434,	
2017-08-03 17:27:08,305 Epoch[24] Batch [860]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.119337,	
2017-08-03 17:27:16,659 Epoch[24] Batch [870]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.119275,	
2017-08-03 17:27:25,002 Epoch[24] Batch [880]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.119365,	
2017-08-03 17:27:33,579 Epoch[24] Batch [890]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.119282,	
2017-08-03 17:27:41,815 Epoch[24] Batch [900]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.119186,	
2017-08-03 17:27:50,375 Epoch[24] Batch [910]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.119358,	
2017-08-03 17:27:59,075 Epoch[24] Batch [920]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.119405,	
2017-08-03 17:28:07,627 Epoch[24] Batch [930]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.119372,	
2017-08-03 17:28:16,207 Epoch[24] Batch [940]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.119218,	
2017-08-03 17:28:24,854 Epoch[24] Batch [950]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.119436,	
2017-08-03 17:28:33,552 Epoch[24] Batch [960]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.119388,	
2017-08-03 17:28:41,838 Epoch[24] Batch [970]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.119394,	
2017-08-03 17:28:50,647 Epoch[24] Batch [980]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.119392,	
2017-08-03 17:28:59,534 Epoch[24] Batch [990]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.119610,	
2017-08-03 17:29:08,038 Epoch[24] Batch [1000]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.119785,	
2017-08-03 17:29:16,453 Epoch[24] Batch [1010]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.119680,	
2017-08-03 17:29:25,182 Epoch[24] Batch [1020]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.119688,	
2017-08-03 17:29:33,936 Epoch[24] Batch [1030]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.119627,	
2017-08-03 17:29:42,417 Epoch[24] Batch [1040]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.119682,	
2017-08-03 17:29:50,987 Epoch[24] Batch [1050]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.119685,	
2017-08-03 17:29:59,918 Epoch[24] Batch [1060]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.119633,	
2017-08-03 17:30:08,481 Epoch[24] Batch [1070]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.119592,	
2017-08-03 17:30:17,219 Epoch[24] Batch [1080]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.119537,	
2017-08-03 17:30:26,047 Epoch[24] Batch [1090]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.119566,	
2017-08-03 17:30:34,710 Epoch[24] Batch [1100]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.119596,	
2017-08-03 17:30:43,117 Epoch[24] Batch [1110]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.119524,	
2017-08-03 17:30:51,994 Epoch[24] Batch [1120]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.119615,	
2017-08-03 17:30:58,337 Epoch[24] Batch [1130]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.119545,	
2017-08-03 17:31:04,215 Epoch[24] Batch [1140]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.119503,	
2017-08-03 17:31:10,228 Epoch[24] Batch [1150]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.119411,	
2017-08-03 17:31:15,901 Epoch[24] Batch [1160]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.119379,	
2017-08-03 17:31:21,511 Epoch[24] Batch [1170]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.119287,	
2017-08-03 17:31:27,037 Epoch[24] Batch [1180]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.119204,	
2017-08-03 17:31:32,470 Epoch[24] Batch [1190]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.119241,	
2017-08-03 17:31:38,121 Epoch[24] Batch [1200]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.119278,	
2017-08-03 17:31:43,737 Epoch[24] Batch [1210]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.119192,	
2017-08-03 17:31:49,210 Epoch[24] Batch [1220]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.119084,	
2017-08-03 17:31:54,193 Epoch[24] Batch [1230]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.119063,	
2017-08-03 17:31:59,916 Epoch[24] Batch [1240]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.119070,	
2017-08-03 17:32:05,231 Epoch[24] Batch [1250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118964,	
2017-08-03 17:32:10,874 Epoch[24] Batch [1260]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.118918,	
2017-08-03 17:32:16,435 Epoch[24] Batch [1270]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.118983,	
2017-08-03 17:32:21,936 Epoch[24] Batch [1280]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.118954,	
2017-08-03 17:32:28,022 Epoch[24] Batch [1290]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.118961,	
2017-08-03 17:32:33,840 Epoch[24] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.119023,	
2017-08-03 17:32:39,815 Epoch[24] Batch [1310]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.119067,	
2017-08-03 17:32:45,427 Epoch[24] Batch [1320]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.119029,	
2017-08-03 17:32:51,185 Epoch[24] Batch [1330]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.119024,	
2017-08-03 17:32:57,882 Epoch[24] Batch [1340]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.118940,	
2017-08-03 17:33:03,337 Epoch[24] Batch [1350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.118975,	
2017-08-03 17:33:08,861 Epoch[24] Batch [1360]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.118995,	
2017-08-03 17:33:14,083 Epoch[24] Batch [1370]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.118929,	
2017-08-03 17:33:22,074 Epoch[24] Batch [1380]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.118922,	
2017-08-03 17:33:30,367 Epoch[24] Batch [1390]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.119107,	
2017-08-03 17:33:38,789 Epoch[24] Batch [1400]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.119070,	
2017-08-03 17:33:47,061 Epoch[24] Batch [1410]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.119213,	
2017-08-03 17:33:55,665 Epoch[24] Batch [1420]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.119255,	
2017-08-03 17:34:03,902 Epoch[24] Batch [1430]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.119215,	
2017-08-03 17:34:12,548 Epoch[24] Batch [1440]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.119282,	
2017-08-03 17:34:21,408 Epoch[24] Batch [1450]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.119329,	
2017-08-03 17:34:29,743 Epoch[24] Batch [1460]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.119458,	
2017-08-03 17:34:38,438 Epoch[24] Batch [1470]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.119464,	
2017-08-03 17:34:47,231 Epoch[24] Batch [1480]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.119518,	
2017-08-03 17:34:52,122 Epoch[24] Train-FCNLogLoss=0.119552
2017-08-03 17:34:52,122 Epoch[24] Time cost=1087.889
2017-08-03 17:34:53,001 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0025.params"
2017-08-03 17:34:56,415 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0025.states"
2017-08-03 17:35:06,097 Epoch[25] Batch [10]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.120567,	
2017-08-03 17:35:14,618 Epoch[25] Batch [20]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.114606,	
2017-08-03 17:35:23,483 Epoch[25] Batch [30]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.117914,	
2017-08-03 17:35:31,968 Epoch[25] Batch [40]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.116943,	
2017-08-03 17:35:40,500 Epoch[25] Batch [50]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.114723,	
2017-08-03 17:35:49,283 Epoch[25] Batch [60]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.114967,	
2017-08-03 17:35:57,641 Epoch[25] Batch [70]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.116531,	
2017-08-03 17:36:06,103 Epoch[25] Batch [80]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.116462,	
2017-08-03 17:36:14,707 Epoch[25] Batch [90]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.117306,	
2017-08-03 17:36:23,604 Epoch[25] Batch [100]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.116617,	
2017-08-03 17:36:32,088 Epoch[25] Batch [110]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.116848,	
2017-08-03 17:36:40,880 Epoch[25] Batch [120]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.118024,	
2017-08-03 17:36:49,543 Epoch[25] Batch [130]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.118486,	
2017-08-03 17:36:57,934 Epoch[25] Batch [140]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.117411,	
2017-08-03 17:37:06,650 Epoch[25] Batch [150]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.117165,	
2017-08-03 17:37:15,435 Epoch[25] Batch [160]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.117553,	
2017-08-03 17:37:22,579 Epoch[25] Batch [170]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.117535,	
2017-08-03 17:37:28,395 Epoch[25] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116956,	
2017-08-03 17:37:34,242 Epoch[25] Batch [190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116412,	
2017-08-03 17:37:39,978 Epoch[25] Batch [200]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.115886,	
2017-08-03 17:37:46,370 Epoch[25] Batch [210]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.115859,	
2017-08-03 17:37:51,973 Epoch[25] Batch [220]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.116293,	
2017-08-03 17:37:57,435 Epoch[25] Batch [230]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.116444,	
2017-08-03 17:38:02,698 Epoch[25] Batch [240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.116332,	
2017-08-03 17:38:08,328 Epoch[25] Batch [250]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.116661,	
2017-08-03 17:38:13,473 Epoch[25] Batch [260]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.116462,	
2017-08-03 17:38:19,036 Epoch[25] Batch [270]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.116836,	
2017-08-03 17:38:24,265 Epoch[25] Batch [280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.116758,	
2017-08-03 17:38:29,289 Epoch[25] Batch [290]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.116651,	
2017-08-03 17:38:34,681 Epoch[25] Batch [300]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.116591,	
2017-08-03 17:38:40,002 Epoch[25] Batch [310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.116807,	
2017-08-03 17:38:45,189 Epoch[25] Batch [320]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.117136,	
2017-08-03 17:38:50,828 Epoch[25] Batch [330]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.117180,	
2017-08-03 17:38:56,473 Epoch[25] Batch [340]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.117161,	
2017-08-03 17:39:02,191 Epoch[25] Batch [350]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.116741,	
2017-08-03 17:39:07,581 Epoch[25] Batch [360]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.116470,	
2017-08-03 17:39:12,694 Epoch[25] Batch [370]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.116581,	
2017-08-03 17:39:18,241 Epoch[25] Batch [380]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.116265,	
2017-08-03 17:39:23,626 Epoch[25] Batch [390]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.115897,	
2017-08-03 17:39:29,076 Epoch[25] Batch [400]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.116298,	
2017-08-03 17:39:34,683 Epoch[25] Batch [410]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.116447,	
2017-08-03 17:39:40,449 Epoch[25] Batch [420]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116568,	
2017-08-03 17:39:47,345 Epoch[25] Batch [430]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.116736,	
2017-08-03 17:39:55,702 Epoch[25] Batch [440]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.116551,	
2017-08-03 17:40:03,923 Epoch[25] Batch [450]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.116555,	
2017-08-03 17:40:12,497 Epoch[25] Batch [460]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.116844,	
2017-08-03 17:40:20,904 Epoch[25] Batch [470]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.116589,	
2017-08-03 17:40:29,363 Epoch[25] Batch [480]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.116697,	
2017-08-03 17:40:37,993 Epoch[25] Batch [490]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.116537,	
2017-08-03 17:40:46,690 Epoch[25] Batch [500]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.116502,	
2017-08-03 17:40:55,075 Epoch[25] Batch [510]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.116366,	
2017-08-03 17:41:03,893 Epoch[25] Batch [520]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.116524,	
2017-08-03 17:41:12,687 Epoch[25] Batch [530]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.116388,	
2017-08-03 17:41:21,273 Epoch[25] Batch [540]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.116295,	
2017-08-03 17:41:29,828 Epoch[25] Batch [550]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.116261,	
2017-08-03 17:41:38,594 Epoch[25] Batch [560]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.116213,	
2017-08-03 17:41:47,089 Epoch[25] Batch [570]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.115935,	
2017-08-03 17:41:55,446 Epoch[25] Batch [580]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.115876,	
2017-08-03 17:42:04,128 Epoch[25] Batch [590]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.115585,	
2017-08-03 17:42:12,898 Epoch[25] Batch [600]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.115847,	
2017-08-03 17:42:21,290 Epoch[25] Batch [610]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.116305,	
2017-08-03 17:42:30,060 Epoch[25] Batch [620]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.116435,	
2017-08-03 17:42:38,899 Epoch[25] Batch [630]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.116566,	
2017-08-03 17:42:47,254 Epoch[25] Batch [640]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.116617,	
2017-08-03 17:42:55,849 Epoch[25] Batch [650]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.116476,	
2017-08-03 17:43:04,722 Epoch[25] Batch [660]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.116381,	
2017-08-03 17:43:13,294 Epoch[25] Batch [670]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.116358,	
2017-08-03 17:43:21,836 Epoch[25] Batch [680]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.116267,	
2017-08-03 17:43:30,348 Epoch[25] Batch [690]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116167,	
2017-08-03 17:43:39,041 Epoch[25] Batch [700]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.116229,	
2017-08-03 17:43:47,506 Epoch[25] Batch [710]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.116096,	
2017-08-03 17:43:54,683 Epoch[25] Batch [720]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.115919,	
2017-08-03 17:44:01,393 Epoch[25] Batch [730]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.116028,	
2017-08-03 17:44:08,317 Epoch[25] Batch [740]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.115950,	
2017-08-03 17:44:15,403 Epoch[25] Batch [750]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.115926,	
2017-08-03 17:44:22,517 Epoch[25] Batch [760]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.116075,	
2017-08-03 17:44:29,732 Epoch[25] Batch [770]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.116028,	
2017-08-03 17:44:36,647 Epoch[25] Batch [780]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.116211,	
2017-08-03 17:44:43,801 Epoch[25] Batch [790]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.116411,	
2017-08-03 17:44:50,733 Epoch[25] Batch [800]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.116503,	
2017-08-03 17:44:58,161 Epoch[25] Batch [810]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.116513,	
2017-08-03 17:45:05,193 Epoch[25] Batch [820]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.116734,	
2017-08-03 17:45:12,000 Epoch[25] Batch [830]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.117031,	
2017-08-03 17:45:18,622 Epoch[25] Batch [840]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.117004,	
2017-08-03 17:45:25,232 Epoch[25] Batch [850]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.117259,	
2017-08-03 17:45:32,058 Epoch[25] Batch [860]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.117308,	
2017-08-03 17:45:38,545 Epoch[25] Batch [870]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.117163,	
2017-08-03 17:45:45,146 Epoch[25] Batch [880]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.117175,	
2017-08-03 17:45:51,968 Epoch[25] Batch [890]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.117352,	
2017-08-03 17:45:58,572 Epoch[25] Batch [900]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.117484,	
2017-08-03 17:46:05,433 Epoch[25] Batch [910]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.117508,	
2017-08-03 17:46:13,782 Epoch[25] Batch [920]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.117546,	
2017-08-03 17:46:22,100 Epoch[25] Batch [930]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.117475,	
2017-08-03 17:46:30,534 Epoch[25] Batch [940]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.117364,	
2017-08-03 17:46:39,133 Epoch[25] Batch [950]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.117232,	
2017-08-03 17:46:47,335 Epoch[25] Batch [960]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.117159,	
2017-08-03 17:46:55,958 Epoch[25] Batch [970]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.117035,	
2017-08-03 17:47:04,641 Epoch[25] Batch [980]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.117012,	
2017-08-03 17:47:13,050 Epoch[25] Batch [990]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.116995,	
2017-08-03 17:47:21,797 Epoch[25] Batch [1000]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.117019,	
2017-08-03 17:47:30,559 Epoch[25] Batch [1010]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.116912,	
2017-08-03 17:47:39,079 Epoch[25] Batch [1020]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116817,	
2017-08-03 17:47:47,509 Epoch[25] Batch [1030]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.116663,	
2017-08-03 17:47:56,173 Epoch[25] Batch [1040]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.116515,	
2017-08-03 17:48:04,798 Epoch[25] Batch [1050]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.116535,	
2017-08-03 17:48:13,090 Epoch[25] Batch [1060]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.116514,	
2017-08-03 17:48:21,738 Epoch[25] Batch [1070]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.116422,	
2017-08-03 17:48:30,549 Epoch[25] Batch [1080]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.116403,	
2017-08-03 17:48:39,146 Epoch[25] Batch [1090]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.116349,	
2017-08-03 17:48:47,743 Epoch[25] Batch [1100]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.116294,	
2017-08-03 17:48:56,540 Epoch[25] Batch [1110]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.116252,	
2017-08-03 17:49:05,306 Epoch[25] Batch [1120]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.116277,	
2017-08-03 17:49:13,912 Epoch[25] Batch [1130]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.116430,	
2017-08-03 17:49:22,555 Epoch[25] Batch [1140]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.116503,	
2017-08-03 17:49:31,399 Epoch[25] Batch [1150]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.116398,	
2017-08-03 17:49:39,797 Epoch[25] Batch [1160]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.116432,	
2017-08-03 17:49:48,452 Epoch[25] Batch [1170]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.116496,	
2017-08-03 17:49:57,321 Epoch[25] Batch [1180]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.116504,	
2017-08-03 17:50:05,765 Epoch[25] Batch [1190]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.116534,	
2017-08-03 17:50:13,964 Epoch[25] Batch [1200]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.116608,	
2017-08-03 17:50:20,179 Epoch[25] Batch [1210]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.116547,	
2017-08-03 17:50:26,608 Epoch[25] Batch [1220]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.116413,	
2017-08-03 17:50:33,576 Epoch[25] Batch [1230]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.116402,	
2017-08-03 17:50:40,472 Epoch[25] Batch [1240]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.116252,	
2017-08-03 17:50:47,003 Epoch[25] Batch [1250]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.116182,	
2017-08-03 17:50:53,878 Epoch[25] Batch [1260]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.116115,	
2017-08-03 17:51:00,739 Epoch[25] Batch [1270]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.116022,	
2017-08-03 17:51:07,477 Epoch[25] Batch [1280]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.115961,	
2017-08-03 17:51:14,289 Epoch[25] Batch [1290]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.115984,	
2017-08-03 17:51:21,360 Epoch[25] Batch [1300]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.115881,	
2017-08-03 17:51:28,291 Epoch[25] Batch [1310]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.115863,	
2017-08-03 17:51:34,818 Epoch[25] Batch [1320]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.115857,	
2017-08-03 17:51:41,600 Epoch[25] Batch [1330]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.115825,	
2017-08-03 17:51:48,415 Epoch[25] Batch [1340]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.115837,	
2017-08-03 17:51:55,745 Epoch[25] Batch [1350]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.115824,	
2017-08-03 17:52:03,183 Epoch[25] Batch [1360]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.115792,	
2017-08-03 17:52:10,638 Epoch[25] Batch [1370]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.115817,	
2017-08-03 17:52:17,748 Epoch[25] Batch [1380]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.115865,	
2017-08-03 17:52:24,986 Epoch[25] Batch [1390]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.115919,	
2017-08-03 17:52:33,016 Epoch[25] Batch [1400]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.115901,	
2017-08-03 17:52:41,301 Epoch[25] Batch [1410]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.115807,	
2017-08-03 17:52:49,719 Epoch[25] Batch [1420]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.115690,	
2017-08-03 17:52:58,310 Epoch[25] Batch [1430]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.115762,	
2017-08-03 17:53:06,634 Epoch[25] Batch [1440]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.115725,	
2017-08-03 17:53:14,971 Epoch[25] Batch [1450]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.115728,	
2017-08-03 17:53:23,697 Epoch[25] Batch [1460]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.115813,	
2017-08-03 17:53:32,017 Epoch[25] Batch [1470]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.115720,	
2017-08-03 17:53:40,505 Epoch[25] Batch [1480]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.115702,	
2017-08-03 17:53:45,757 Epoch[25] Train-FCNLogLoss=0.115675
2017-08-03 17:53:45,757 Epoch[25] Time cost=1129.342
2017-08-03 17:53:46,829 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0026.params"
2017-08-03 17:53:50,345 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0026.states"
2017-08-03 17:53:59,869 Epoch[26] Batch [10]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.111220,	
2017-08-03 17:54:08,776 Epoch[26] Batch [20]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.107990,	
2017-08-03 17:54:17,401 Epoch[26] Batch [30]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.109919,	
2017-08-03 17:54:25,884 Epoch[26] Batch [40]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.112116,	
2017-08-03 17:54:34,451 Epoch[26] Batch [50]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.111398,	
2017-08-03 17:54:43,106 Epoch[26] Batch [60]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.113918,	
2017-08-03 17:54:51,813 Epoch[26] Batch [70]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.114567,	
2017-08-03 17:55:00,267 Epoch[26] Batch [80]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115129,	
2017-08-03 17:55:09,025 Epoch[26] Batch [90]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.113877,	
2017-08-03 17:55:17,710 Epoch[26] Batch [100]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.113748,	
2017-08-03 17:55:26,302 Epoch[26] Batch [110]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.113614,	
2017-08-03 17:55:34,830 Epoch[26] Batch [120]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.112597,	
2017-08-03 17:55:43,583 Epoch[26] Batch [130]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.112577,	
2017-08-03 17:55:52,309 Epoch[26] Batch [140]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.112670,	
2017-08-03 17:56:00,736 Epoch[26] Batch [150]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.112986,	
2017-08-03 17:56:09,779 Epoch[26] Batch [160]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.113799,	
2017-08-03 17:56:18,517 Epoch[26] Batch [170]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.113665,	
2017-08-03 17:56:27,121 Epoch[26] Batch [180]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.113202,	
2017-08-03 17:56:35,137 Epoch[26] Batch [190]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.113922,	
2017-08-03 17:56:42,958 Epoch[26] Batch [200]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.114172,	
2017-08-03 17:56:50,679 Epoch[26] Batch [210]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.114300,	
2017-08-03 17:56:58,432 Epoch[26] Batch [220]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.114695,	
2017-08-03 17:57:06,315 Epoch[26] Batch [230]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.114652,	
2017-08-03 17:57:14,031 Epoch[26] Batch [240]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.113682,	
2017-08-03 17:57:21,812 Epoch[26] Batch [250]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.113311,	
2017-08-03 17:57:29,309 Epoch[26] Batch [260]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.113412,	
2017-08-03 17:57:36,981 Epoch[26] Batch [270]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.113955,	
2017-08-03 17:57:44,717 Epoch[26] Batch [280]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.114185,	
2017-08-03 17:57:52,331 Epoch[26] Batch [290]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.113658,	
2017-08-03 17:57:59,658 Epoch[26] Batch [300]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.113509,	
2017-08-03 17:58:07,665 Epoch[26] Batch [310]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.113654,	
2017-08-03 17:58:15,598 Epoch[26] Batch [320]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.113686,	
2017-08-03 17:58:23,432 Epoch[26] Batch [330]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.113603,	
2017-08-03 17:58:31,180 Epoch[26] Batch [340]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.114007,	
2017-08-03 17:58:38,935 Epoch[26] Batch [350]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.114022,	
2017-08-03 17:58:46,741 Epoch[26] Batch [360]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.113952,	
2017-08-03 17:58:53,182 Epoch[26] Batch [370]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.114248,	
2017-08-03 17:59:01,777 Epoch[26] Batch [380]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.114660,	
2017-08-03 17:59:10,089 Epoch[26] Batch [390]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.114543,	
2017-08-03 17:59:18,473 Epoch[26] Batch [400]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.114583,	
2017-08-03 17:59:27,035 Epoch[26] Batch [410]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.114675,	
2017-08-03 17:59:35,417 Epoch[26] Batch [420]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.114655,	
2017-08-03 17:59:43,797 Epoch[26] Batch [430]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.114544,	
2017-08-03 17:59:52,301 Epoch[26] Batch [440]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.114237,	
2017-08-03 18:00:00,828 Epoch[26] Batch [450]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.114195,	
2017-08-03 18:00:09,364 Epoch[26] Batch [460]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.113999,	
2017-08-03 18:00:18,026 Epoch[26] Batch [470]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.113857,	
2017-08-03 18:00:26,739 Epoch[26] Batch [480]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.113841,	
2017-08-03 18:00:35,164 Epoch[26] Batch [490]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.113818,	
2017-08-03 18:00:43,739 Epoch[26] Batch [500]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.113859,	
2017-08-03 18:00:52,361 Epoch[26] Batch [510]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.114304,	
2017-08-03 18:01:00,988 Epoch[26] Batch [520]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.114375,	
2017-08-03 18:01:09,456 Epoch[26] Batch [530]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.114112,	
2017-08-03 18:01:18,233 Epoch[26] Batch [540]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.113707,	
2017-08-03 18:01:26,873 Epoch[26] Batch [550]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.113738,	
2017-08-03 18:01:35,444 Epoch[26] Batch [560]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.113896,	
2017-08-03 18:01:43,973 Epoch[26] Batch [570]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.113603,	
2017-08-03 18:01:52,849 Epoch[26] Batch [580]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.113639,	
2017-08-03 18:02:01,234 Epoch[26] Batch [590]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.114125,	
2017-08-03 18:02:09,802 Epoch[26] Batch [600]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.114098,	
2017-08-03 18:02:18,652 Epoch[26] Batch [610]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.114176,	
2017-08-03 18:02:27,232 Epoch[26] Batch [620]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.114180,	
2017-08-03 18:02:35,727 Epoch[26] Batch [630]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.114401,	
2017-08-03 18:02:44,389 Epoch[26] Batch [640]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.114529,	
2017-08-03 18:02:53,234 Epoch[26] Batch [650]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.114470,	
2017-08-03 18:03:00,614 Epoch[26] Batch [660]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.114324,	
2017-08-03 18:03:07,491 Epoch[26] Batch [670]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.114157,	
2017-08-03 18:03:14,530 Epoch[26] Batch [680]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.114484,	
2017-08-03 18:03:21,323 Epoch[26] Batch [690]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.114313,	
2017-08-03 18:03:28,638 Epoch[26] Batch [700]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.114220,	
2017-08-03 18:03:35,587 Epoch[26] Batch [710]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.114425,	
2017-08-03 18:03:42,799 Epoch[26] Batch [720]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.114901,	
2017-08-03 18:03:49,731 Epoch[26] Batch [730]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.115711,	
2017-08-03 18:03:56,806 Epoch[26] Batch [740]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.116106,	
2017-08-03 18:04:04,052 Epoch[26] Batch [750]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.116129,	
2017-08-03 18:04:11,003 Epoch[26] Batch [760]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.116630,	
2017-08-03 18:04:17,821 Epoch[26] Batch [770]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.116538,	
2017-08-03 18:04:24,866 Epoch[26] Batch [780]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.116591,	
2017-08-03 18:04:32,310 Epoch[26] Batch [790]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.116611,	
2017-08-03 18:04:39,296 Epoch[26] Batch [800]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.116747,	
2017-08-03 18:04:46,220 Epoch[26] Batch [810]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.116825,	
2017-08-03 18:04:53,220 Epoch[26] Batch [820]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.116830,	
2017-08-03 18:05:00,213 Epoch[26] Batch [830]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.116629,	
2017-08-03 18:05:07,395 Epoch[26] Batch [840]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.116384,	
2017-08-03 18:05:14,736 Epoch[26] Batch [850]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.116327,	
2017-08-03 18:05:22,426 Epoch[26] Batch [860]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.116438,	
2017-08-03 18:05:30,845 Epoch[26] Batch [870]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.116316,	
2017-08-03 18:05:39,361 Epoch[26] Batch [880]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116377,	
2017-08-03 18:05:47,614 Epoch[26] Batch [890]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.116567,	
2017-08-03 18:05:56,053 Epoch[26] Batch [900]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.116708,	
2017-08-03 18:06:04,627 Epoch[26] Batch [910]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.116729,	
2017-08-03 18:06:12,945 Epoch[26] Batch [920]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.116637,	
2017-08-03 18:06:21,460 Epoch[26] Batch [930]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116747,	
2017-08-03 18:06:30,171 Epoch[26] Batch [940]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.116958,	
2017-08-03 18:06:38,898 Epoch[26] Batch [950]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.116928,	
2017-08-03 18:06:47,356 Epoch[26] Batch [960]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.116965,	
2017-08-03 18:06:55,935 Epoch[26] Batch [970]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.116960,	
2017-08-03 18:07:04,723 Epoch[26] Batch [980]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.116965,	
2017-08-03 18:07:13,239 Epoch[26] Batch [990]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116877,	
2017-08-03 18:07:21,918 Epoch[26] Batch [1000]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.116886,	
2017-08-03 18:07:30,720 Epoch[26] Batch [1010]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.116920,	
2017-08-03 18:07:39,342 Epoch[26] Batch [1020]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.116956,	
2017-08-03 18:07:47,757 Epoch[26] Batch [1030]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.116816,	
2017-08-03 18:07:56,538 Epoch[26] Batch [1040]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.116725,	
2017-08-03 18:08:05,350 Epoch[26] Batch [1050]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.116660,	
2017-08-03 18:08:13,699 Epoch[26] Batch [1060]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.116704,	
2017-08-03 18:08:22,305 Epoch[26] Batch [1070]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.116789,	
2017-08-03 18:08:30,845 Epoch[26] Batch [1080]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.116869,	
2017-08-03 18:08:39,712 Epoch[26] Batch [1090]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.116630,	
2017-08-03 18:08:48,214 Epoch[26] Batch [1100]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116637,	
2017-08-03 18:08:56,681 Epoch[26] Batch [1110]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.116700,	
2017-08-03 18:09:05,390 Epoch[26] Batch [1120]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.116585,	
2017-08-03 18:09:13,942 Epoch[26] Batch [1130]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.116602,	
2017-08-03 18:09:22,698 Epoch[26] Batch [1140]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.116845,	
2017-08-03 18:09:30,506 Epoch[26] Batch [1150]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.116842,	
2017-08-03 18:09:38,200 Epoch[26] Batch [1160]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.116732,	
2017-08-03 18:09:45,917 Epoch[26] Batch [1170]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.116793,	
2017-08-03 18:09:53,774 Epoch[26] Batch [1180]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.116768,	
2017-08-03 18:10:01,492 Epoch[26] Batch [1190]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.116755,	
2017-08-03 18:10:09,067 Epoch[26] Batch [1200]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.116849,	
2017-08-03 18:10:16,944 Epoch[26] Batch [1210]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.116930,	
2017-08-03 18:10:24,295 Epoch[26] Batch [1220]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.116794,	
2017-08-03 18:10:31,924 Epoch[26] Batch [1230]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.116699,	
2017-08-03 18:10:39,433 Epoch[26] Batch [1240]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.116724,	
2017-08-03 18:10:46,886 Epoch[26] Batch [1250]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.116721,	
2017-08-03 18:10:54,416 Epoch[26] Batch [1260]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.116858,	
2017-08-03 18:11:02,085 Epoch[26] Batch [1270]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.116973,	
2017-08-03 18:11:10,371 Epoch[26] Batch [1280]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.116958,	
2017-08-03 18:11:18,204 Epoch[26] Batch [1290]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.117087,	
2017-08-03 18:11:25,825 Epoch[26] Batch [1300]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.117224,	
2017-08-03 18:11:33,320 Epoch[26] Batch [1310]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.117220,	
2017-08-03 18:11:40,867 Epoch[26] Batch [1320]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.117210,	
2017-08-03 18:11:49,225 Epoch[26] Batch [1330]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.117169,	
2017-08-03 18:11:57,405 Epoch[26] Batch [1340]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.117194,	
2017-08-03 18:12:05,988 Epoch[26] Batch [1350]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.117208,	
2017-08-03 18:12:14,512 Epoch[26] Batch [1360]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.117251,	
2017-08-03 18:12:22,793 Epoch[26] Batch [1370]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.117364,	
2017-08-03 18:12:31,323 Epoch[26] Batch [1380]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.117273,	
2017-08-03 18:12:39,940 Epoch[26] Batch [1390]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.117245,	
2017-08-03 18:12:48,478 Epoch[26] Batch [1400]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.117245,	
2017-08-03 18:12:56,873 Epoch[26] Batch [1410]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.117285,	
2017-08-03 18:13:06,037 Epoch[26] Batch [1420]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.117208,	
2017-08-03 18:13:15,396 Epoch[26] Batch [1430]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.117228,	
2017-08-03 18:13:24,405 Epoch[26] Batch [1440]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.117267,	
2017-08-03 18:13:33,247 Epoch[26] Batch [1450]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.117281,	
2017-08-03 18:13:42,410 Epoch[26] Batch [1460]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.117259,	
2017-08-03 18:13:51,119 Epoch[26] Batch [1470]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.117232,	
2017-08-03 18:14:00,071 Epoch[26] Batch [1480]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.117292,	
2017-08-03 18:14:05,189 Epoch[26] Train-FCNLogLoss=0.117219
2017-08-03 18:14:05,190 Epoch[26] Time cost=1214.844
2017-08-03 18:14:06,479 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0027.params"
2017-08-03 18:14:11,003 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0027.states"
2017-08-03 18:14:21,407 Epoch[27] Batch [10]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.106331,	
2017-08-03 18:14:30,270 Epoch[27] Batch [20]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.113386,	
2017-08-03 18:14:38,820 Epoch[27] Batch [30]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.111783,	
2017-08-03 18:14:47,554 Epoch[27] Batch [40]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.109346,	
2017-08-03 18:14:56,250 Epoch[27] Batch [50]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.108433,	
2017-08-03 18:15:04,806 Epoch[27] Batch [60]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.107864,	
2017-08-03 18:15:13,399 Epoch[27] Batch [70]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.108025,	
2017-08-03 18:15:22,247 Epoch[27] Batch [80]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.107785,	
2017-08-03 18:15:30,898 Epoch[27] Batch [90]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.108471,	
2017-08-03 18:15:39,399 Epoch[27] Batch [100]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.108209,	
2017-08-03 18:15:47,618 Epoch[27] Batch [110]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.107464,	
2017-08-03 18:15:55,043 Epoch[27] Batch [120]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.107242,	
2017-08-03 18:16:02,448 Epoch[27] Batch [130]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.107033,	
2017-08-03 18:16:09,932 Epoch[27] Batch [140]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.106999,	
2017-08-03 18:16:17,496 Epoch[27] Batch [150]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.106841,	
2017-08-03 18:16:24,895 Epoch[27] Batch [160]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.109873,	
2017-08-03 18:16:32,420 Epoch[27] Batch [170]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.109629,	
2017-08-03 18:16:52,996 Epoch[27] Batch [180]	Speed: 1.94 samples/sec	Train-FCNLogLoss=0.110349,	
2017-08-03 18:17:25,866 Epoch[27] Batch [190]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.110270,	
2017-08-03 18:17:52,863 Epoch[27] Batch [200]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.111173,	
2017-08-03 18:18:19,308 Epoch[27] Batch [210]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.110909,	
2017-08-03 18:18:47,718 Epoch[27] Batch [220]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.110894,	
2017-08-03 18:19:12,514 Epoch[27] Batch [230]	Speed: 1.61 samples/sec	Train-FCNLogLoss=0.111044,	
2017-08-03 18:19:43,041 Epoch[27] Batch [240]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.111196,	
2017-08-03 18:20:20,201 Epoch[27] Batch [250]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.111271,	
2017-08-03 18:20:57,749 Epoch[27] Batch [260]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.111726,	
2017-08-03 18:21:34,208 Epoch[27] Batch [270]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.111387,	
2017-08-03 18:22:08,877 Epoch[27] Batch [280]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.111726,	
2017-08-03 18:22:39,126 Epoch[27] Batch [290]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.111928,	
2017-08-03 18:23:12,325 Epoch[27] Batch [300]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.111896,	
2017-08-03 18:23:47,030 Epoch[27] Batch [310]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.111805,	
2017-08-03 18:24:28,716 Epoch[27] Batch [320]	Speed: 0.96 samples/sec	Train-FCNLogLoss=0.111571,	
2017-08-03 18:25:07,559 Epoch[27] Batch [330]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.110973,	
2017-08-03 18:25:48,346 Epoch[27] Batch [340]	Speed: 0.98 samples/sec	Train-FCNLogLoss=0.111789,	
2017-08-03 18:26:23,332 Epoch[27] Batch [350]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.112246,	
2017-08-03 18:26:59,169 Epoch[27] Batch [360]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.113426,	
2017-08-03 18:27:34,810 Epoch[27] Batch [370]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.113574,	
2017-08-03 18:28:12,261 Epoch[27] Batch [380]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.114268,	
2017-08-03 18:28:47,250 Epoch[27] Batch [390]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.114428,	
2017-08-03 18:29:22,694 Epoch[27] Batch [400]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.114504,	
2017-08-03 18:29:59,436 Epoch[27] Batch [410]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.114727,	
2017-08-03 18:30:42,170 Epoch[27] Batch [420]	Speed: 0.94 samples/sec	Train-FCNLogLoss=0.114889,	
2017-08-03 18:31:14,198 Epoch[27] Batch [430]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.114943,	
2017-08-03 18:31:33,478 Epoch[27] Batch [440]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.114720,	
2017-08-03 18:31:42,052 Epoch[27] Batch [450]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.114856,	
2017-08-03 18:31:50,774 Epoch[27] Batch [460]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.114963,	
2017-08-03 18:31:58,150 Epoch[27] Batch [470]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.115544,	
2017-08-03 18:32:05,672 Epoch[27] Batch [480]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.115936,	
2017-08-03 18:32:12,905 Epoch[27] Batch [490]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.116125,	
2017-08-03 18:32:20,086 Epoch[27] Batch [500]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.116419,	
2017-08-03 18:32:27,387 Epoch[27] Batch [510]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.116460,	
2017-08-03 18:32:34,710 Epoch[27] Batch [520]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.116568,	
2017-08-03 18:32:42,044 Epoch[27] Batch [530]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.116421,	
2017-08-03 18:32:49,456 Epoch[27] Batch [540]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.116654,	
2017-08-03 18:32:56,841 Epoch[27] Batch [550]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.116745,	
2017-08-03 18:33:04,382 Epoch[27] Batch [560]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.116664,	
2017-08-03 18:33:11,702 Epoch[27] Batch [570]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.116734,	
2017-08-03 18:33:19,112 Epoch[27] Batch [580]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.116656,	
2017-08-03 18:33:26,364 Epoch[27] Batch [590]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.116654,	
2017-08-03 18:33:33,812 Epoch[27] Batch [600]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.116900,	
2017-08-03 18:33:41,474 Epoch[27] Batch [610]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.116840,	
2017-08-03 18:33:48,781 Epoch[27] Batch [620]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.116911,	
2017-08-03 18:33:56,201 Epoch[27] Batch [630]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.116801,	
2017-08-03 18:34:03,646 Epoch[27] Batch [640]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.116806,	
2017-08-03 18:34:11,242 Epoch[27] Batch [650]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.116705,	
2017-08-03 18:34:19,659 Epoch[27] Batch [660]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.116647,	
2017-08-03 18:34:27,833 Epoch[27] Batch [670]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.116561,	
2017-08-03 18:34:36,159 Epoch[27] Batch [680]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.116617,	
2017-08-03 18:34:44,806 Epoch[27] Batch [690]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.116567,	
2017-08-03 18:34:53,108 Epoch[27] Batch [700]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.116485,	
2017-08-03 18:35:01,378 Epoch[27] Batch [710]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.116258,	
2017-08-03 18:35:09,891 Epoch[27] Batch [720]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116118,	
2017-08-03 18:35:18,671 Epoch[27] Batch [730]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.115956,	
2017-08-03 18:35:26,998 Epoch[27] Batch [740]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.116050,	
2017-08-03 18:35:35,586 Epoch[27] Batch [750]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.116129,	
2017-08-03 18:35:44,323 Epoch[27] Batch [760]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.116286,	
2017-08-03 18:35:52,844 Epoch[27] Batch [770]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.116402,	
2017-08-03 18:36:01,353 Epoch[27] Batch [780]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116577,	
2017-08-03 18:36:10,027 Epoch[27] Batch [790]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.116686,	
2017-08-03 18:36:18,740 Epoch[27] Batch [800]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.116786,	
2017-08-03 18:36:27,237 Epoch[27] Batch [810]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.116795,	
2017-08-03 18:36:35,828 Epoch[27] Batch [820]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.116684,	
2017-08-03 18:36:58,576 Epoch[27] Batch [830]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.116663,	
2017-08-03 18:37:29,954 Epoch[27] Batch [840]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.116376,	
2017-08-03 18:37:57,656 Epoch[27] Batch [850]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.116163,	
2017-08-03 18:38:23,659 Epoch[27] Batch [860]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.116027,	
2017-08-03 18:38:48,957 Epoch[27] Batch [870]	Speed: 1.58 samples/sec	Train-FCNLogLoss=0.116022,	
2017-08-03 18:39:11,897 Epoch[27] Batch [880]	Speed: 1.74 samples/sec	Train-FCNLogLoss=0.116087,	
2017-08-03 18:39:40,183 Epoch[27] Batch [890]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.115920,	
2017-08-03 18:40:09,427 Epoch[27] Batch [900]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.115942,	
2017-08-03 18:40:43,715 Epoch[27] Batch [910]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.115947,	
2017-08-03 18:41:17,057 Epoch[27] Batch [920]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.115954,	
2017-08-03 18:41:49,131 Epoch[27] Batch [930]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.115982,	
2017-08-03 18:42:18,004 Epoch[27] Batch [940]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.115990,	
2017-08-03 18:42:48,523 Epoch[27] Batch [950]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.115955,	
2017-08-03 18:43:18,743 Epoch[27] Batch [960]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.115937,	
2017-08-03 18:43:45,149 Epoch[27] Batch [970]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.115946,	
2017-08-03 18:44:02,501 Epoch[27] Batch [980]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.115859,	
2017-08-03 18:44:10,218 Epoch[27] Batch [990]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.115858,	
2017-08-03 18:44:17,790 Epoch[27] Batch [1000]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.115649,	
2017-08-03 18:44:25,273 Epoch[27] Batch [1010]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.115492,	
2017-08-03 18:44:32,802 Epoch[27] Batch [1020]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.115371,	
2017-08-03 18:44:40,412 Epoch[27] Batch [1030]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.115207,	
2017-08-03 18:44:47,933 Epoch[27] Batch [1040]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.115182,	
2017-08-03 18:44:55,652 Epoch[27] Batch [1050]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.115142,	
2017-08-03 18:45:03,323 Epoch[27] Batch [1060]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.115073,	
2017-08-03 18:45:10,894 Epoch[27] Batch [1070]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.114909,	
2017-08-03 18:45:18,814 Epoch[27] Batch [1080]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.115014,	
2017-08-03 18:45:26,561 Epoch[27] Batch [1090]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.114885,	
2017-08-03 18:45:35,020 Epoch[27] Batch [1100]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115146,	
2017-08-03 18:45:43,470 Epoch[27] Batch [1110]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115226,	
2017-08-03 18:45:52,098 Epoch[27] Batch [1120]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.115373,	
2017-08-03 18:46:00,277 Epoch[27] Batch [1130]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.115441,	
2017-08-03 18:46:08,728 Epoch[27] Batch [1140]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115351,	
2017-08-03 18:46:17,136 Epoch[27] Batch [1150]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.115451,	
2017-08-03 18:46:25,590 Epoch[27] Batch [1160]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115403,	
2017-08-03 18:46:34,087 Epoch[27] Batch [1170]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.115431,	
2017-08-03 18:46:42,756 Epoch[27] Batch [1180]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.115242,	
2017-08-03 18:46:51,432 Epoch[27] Batch [1190]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.115357,	
2017-08-03 18:46:59,903 Epoch[27] Batch [1200]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.115373,	
2017-08-03 18:47:08,464 Epoch[27] Batch [1210]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.115322,	
2017-08-03 18:47:17,302 Epoch[27] Batch [1220]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.115480,	
2017-08-03 18:47:25,906 Epoch[27] Batch [1230]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.115332,	
2017-08-03 18:47:34,515 Epoch[27] Batch [1240]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.115270,	
2017-08-03 18:47:43,166 Epoch[27] Batch [1250]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.115212,	
2017-08-03 18:47:51,800 Epoch[27] Batch [1260]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.115353,	
2017-08-03 18:48:00,511 Epoch[27] Batch [1270]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.115318,	
2017-08-03 18:48:09,118 Epoch[27] Batch [1280]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.115374,	
2017-08-03 18:48:17,878 Epoch[27] Batch [1290]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.115500,	
2017-08-03 18:48:26,473 Epoch[27] Batch [1300]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.115478,	
2017-08-03 18:48:35,131 Epoch[27] Batch [1310]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.115433,	
2017-08-03 18:48:43,695 Epoch[27] Batch [1320]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.115439,	
2017-08-03 18:48:52,495 Epoch[27] Batch [1330]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.115317,	
2017-08-03 18:49:00,933 Epoch[27] Batch [1340]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.115372,	
2017-08-03 18:49:09,742 Epoch[27] Batch [1350]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.115359,	
2017-08-03 18:49:18,438 Epoch[27] Batch [1360]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.115376,	
2017-08-03 18:49:27,124 Epoch[27] Batch [1370]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.115321,	
2017-08-03 18:49:41,951 Epoch[27] Batch [1380]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.115253,	
2017-08-03 18:50:08,211 Epoch[27] Batch [1390]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.115229,	
2017-08-03 18:50:37,142 Epoch[27] Batch [1400]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.115213,	
2017-08-03 18:51:06,333 Epoch[27] Batch [1410]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.115295,	
2017-08-03 18:51:16,900 Epoch[27] Batch [1420]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.115281,	
2017-08-03 18:51:24,317 Epoch[27] Batch [1430]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.115394,	
2017-08-03 18:51:31,608 Epoch[27] Batch [1440]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.115473,	
2017-08-03 18:51:38,764 Epoch[27] Batch [1450]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.115597,	
2017-08-03 18:51:46,186 Epoch[27] Batch [1460]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.115638,	
2017-08-03 18:51:53,926 Epoch[27] Batch [1470]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.115715,	
2017-08-03 18:52:02,202 Epoch[27] Batch [1480]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.115806,	
2017-08-03 18:52:07,162 Epoch[27] Train-FCNLogLoss=0.115793
2017-08-03 18:52:07,163 Epoch[27] Time cost=2276.159
2017-08-03 18:52:08,234 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0028.params"
2017-08-03 18:52:11,726 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0028.states"
2017-08-03 18:52:21,606 Epoch[28] Batch [10]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.111782,	
2017-08-03 18:52:29,855 Epoch[28] Batch [20]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.113926,	
2017-08-03 18:52:38,196 Epoch[28] Batch [30]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.113077,	
2017-08-03 18:52:46,728 Epoch[28] Batch [40]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.113553,	
2017-08-03 18:52:55,177 Epoch[28] Batch [50]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115305,	
2017-08-03 18:53:03,350 Epoch[28] Batch [60]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.117023,	
2017-08-03 18:53:12,099 Epoch[28] Batch [70]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.115617,	
2017-08-03 18:53:20,903 Epoch[28] Batch [80]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.115887,	
2017-08-03 18:53:29,240 Epoch[28] Batch [90]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.115526,	
2017-08-03 18:53:37,715 Epoch[28] Batch [100]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.114311,	
2017-08-03 18:53:46,516 Epoch[28] Batch [110]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.113629,	
2017-08-03 18:53:54,930 Epoch[28] Batch [120]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.114455,	
2017-08-03 18:54:03,397 Epoch[28] Batch [130]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.115440,	
2017-08-03 18:54:11,901 Epoch[28] Batch [140]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.115085,	
2017-08-03 18:54:20,579 Epoch[28] Batch [150]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.115536,	
2017-08-03 18:54:29,110 Epoch[28] Batch [160]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.114867,	
2017-08-03 18:54:37,598 Epoch[28] Batch [170]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.115330,	
2017-08-03 18:54:46,332 Epoch[28] Batch [180]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.114178,	
2017-08-03 18:54:54,781 Epoch[28] Batch [190]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.114210,	
2017-08-03 18:55:03,448 Epoch[28] Batch [200]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.113828,	
2017-08-03 18:55:12,013 Epoch[28] Batch [210]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.113600,	
2017-08-03 18:55:20,809 Epoch[28] Batch [220]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.113279,	
2017-08-03 18:55:29,128 Epoch[28] Batch [230]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.113418,	
2017-08-03 18:55:37,948 Epoch[28] Batch [240]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.113845,	
2017-08-03 18:55:46,572 Epoch[28] Batch [250]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.113399,	
2017-08-03 18:55:54,984 Epoch[28] Batch [260]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.113462,	
2017-08-03 18:56:02,294 Epoch[28] Batch [270]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.113635,	
2017-08-03 18:56:09,736 Epoch[28] Batch [280]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.113622,	
2017-08-03 18:56:17,299 Epoch[28] Batch [290]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.113371,	
2017-08-03 18:56:24,926 Epoch[28] Batch [300]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.113367,	
2017-08-03 18:56:32,386 Epoch[28] Batch [310]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.113360,	
2017-08-03 18:56:39,763 Epoch[28] Batch [320]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.113186,	
2017-08-03 18:56:47,195 Epoch[28] Batch [330]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.112932,	
2017-08-03 18:56:54,684 Epoch[28] Batch [340]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.113131,	
2017-08-03 18:57:02,532 Epoch[28] Batch [350]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.113105,	
2017-08-03 18:57:09,950 Epoch[28] Batch [360]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.112850,	
2017-08-03 18:57:17,658 Epoch[28] Batch [370]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.112950,	
2017-08-03 18:57:25,142 Epoch[28] Batch [380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.112634,	
2017-08-03 18:57:32,984 Epoch[28] Batch [390]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.112548,	
2017-08-03 18:57:40,336 Epoch[28] Batch [400]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.112520,	
2017-08-03 18:57:47,762 Epoch[28] Batch [410]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.112662,	
2017-08-03 18:57:55,314 Epoch[28] Batch [420]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.112489,	
2017-08-03 18:58:03,167 Epoch[28] Batch [430]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.112281,	
2017-08-03 18:58:10,821 Epoch[28] Batch [440]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.111992,	
2017-08-03 18:58:19,429 Epoch[28] Batch [450]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.111997,	
2017-08-03 18:58:27,885 Epoch[28] Batch [460]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.112076,	
2017-08-03 18:58:36,424 Epoch[28] Batch [470]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.112093,	
2017-08-03 18:58:44,639 Epoch[28] Batch [480]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.111953,	
2017-08-03 18:58:54,862 Epoch[28] Batch [490]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.111761,	
2017-08-03 18:59:27,957 Epoch[28] Batch [500]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.111593,	
2017-08-03 19:00:00,375 Epoch[28] Batch [510]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.111596,	
2017-08-03 19:00:30,114 Epoch[28] Batch [520]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.111632,	
2017-08-03 19:00:49,326 Epoch[28] Batch [530]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.111575,	
2017-08-03 19:00:57,977 Epoch[28] Batch [540]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.111580,	
2017-08-03 19:01:06,458 Epoch[28] Batch [550]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.111604,	
2017-08-03 19:01:15,096 Epoch[28] Batch [560]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.111489,	
2017-08-03 19:01:23,651 Epoch[28] Batch [570]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.111329,	
2017-08-03 19:01:32,477 Epoch[28] Batch [580]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.111339,	
2017-08-03 19:01:40,858 Epoch[28] Batch [590]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.111271,	
2017-08-03 19:01:49,090 Epoch[28] Batch [600]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.111416,	
2017-08-03 19:01:55,663 Epoch[28] Batch [610]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.111312,	
2017-08-03 19:02:02,184 Epoch[28] Batch [620]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.111217,	
2017-08-03 19:02:08,983 Epoch[28] Batch [630]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.111178,	
2017-08-03 19:02:15,738 Epoch[28] Batch [640]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.111128,	
2017-08-03 19:02:22,420 Epoch[28] Batch [650]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.110953,	
2017-08-03 19:02:28,967 Epoch[28] Batch [660]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.110849,	
2017-08-03 19:02:35,138 Epoch[28] Batch [670]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.110930,	
2017-08-03 19:02:42,025 Epoch[28] Batch [680]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.110919,	
2017-08-03 19:02:48,636 Epoch[28] Batch [690]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.110760,	
2017-08-03 19:02:55,530 Epoch[28] Batch [700]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.110777,	
2017-08-03 19:03:02,179 Epoch[28] Batch [710]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.110660,	
2017-08-03 19:03:08,927 Epoch[28] Batch [720]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.110504,	
2017-08-03 19:03:15,455 Epoch[28] Batch [730]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.110745,	
2017-08-03 19:03:22,057 Epoch[28] Batch [740]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.111081,	
2017-08-03 19:03:28,608 Epoch[28] Batch [750]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.112071,	
2017-08-03 19:03:35,321 Epoch[28] Batch [760]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.113063,	
2017-08-03 19:03:42,254 Epoch[28] Batch [770]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.114320,	
2017-08-03 19:03:49,224 Epoch[28] Batch [780]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.115116,	
2017-08-03 19:03:56,397 Epoch[28] Batch [790]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.115396,	
2017-08-03 19:04:03,158 Epoch[28] Batch [800]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.116244,	
2017-08-03 19:04:11,369 Epoch[28] Batch [810]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.116704,	
2017-08-03 19:04:19,945 Epoch[28] Batch [820]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.117069,	
2017-08-03 19:04:28,169 Epoch[28] Batch [830]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.117266,	
2017-08-03 19:04:36,483 Epoch[28] Batch [840]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.117365,	
2017-08-03 19:04:45,061 Epoch[28] Batch [850]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.117635,	
2017-08-03 19:04:53,470 Epoch[28] Batch [860]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.117720,	
2017-08-03 19:05:01,900 Epoch[28] Batch [870]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.117812,	
2017-08-03 19:05:10,336 Epoch[28] Batch [880]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.117946,	
2017-08-03 19:05:19,058 Epoch[28] Batch [890]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.118146,	
2017-08-03 19:05:27,451 Epoch[28] Batch [900]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.118235,	
2017-08-03 19:05:36,070 Epoch[28] Batch [910]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.118360,	
2017-08-03 19:05:44,822 Epoch[28] Batch [920]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.118456,	
2017-08-03 19:05:53,266 Epoch[28] Batch [930]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.118537,	
2017-08-03 19:06:01,993 Epoch[28] Batch [940]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.118390,	
2017-08-03 19:06:10,683 Epoch[28] Batch [950]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.118630,	
2017-08-03 19:06:19,126 Epoch[28] Batch [960]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.118572,	
2017-08-03 19:06:27,711 Epoch[28] Batch [970]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.118687,	
2017-08-03 19:06:36,387 Epoch[28] Batch [980]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.118748,	
2017-08-03 19:06:45,053 Epoch[28] Batch [990]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.118707,	
2017-08-03 19:06:53,453 Epoch[28] Batch [1000]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.118790,	
2017-08-03 19:07:02,027 Epoch[28] Batch [1010]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.118727,	
2017-08-03 19:07:10,727 Epoch[28] Batch [1020]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.118786,	
2017-08-03 19:07:19,087 Epoch[28] Batch [1030]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.118664,	
2017-08-03 19:07:27,929 Epoch[28] Batch [1040]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.118816,	
2017-08-03 19:07:36,603 Epoch[28] Batch [1050]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.118809,	
2017-08-03 19:07:45,012 Epoch[28] Batch [1060]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.118844,	
2017-08-03 19:07:53,623 Epoch[28] Batch [1070]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.118768,	
2017-08-03 19:08:02,434 Epoch[28] Batch [1080]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.118897,	
2017-08-03 19:08:10,879 Epoch[28] Batch [1090]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.118906,	
2017-08-03 19:08:17,717 Epoch[28] Batch [1100]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.118813,	
2017-08-03 19:08:25,271 Epoch[28] Batch [1110]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.118863,	
2017-08-03 19:08:32,722 Epoch[28] Batch [1120]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.118758,	
2017-08-03 19:08:40,124 Epoch[28] Batch [1130]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.118794,	
2017-08-03 19:08:47,738 Epoch[28] Batch [1140]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.118736,	
2017-08-03 19:08:55,002 Epoch[28] Batch [1150]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.118726,	
2017-08-03 19:09:02,319 Epoch[28] Batch [1160]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.118818,	
2017-08-03 19:09:10,023 Epoch[28] Batch [1170]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.118856,	
2017-08-03 19:09:17,508 Epoch[28] Batch [1180]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.118898,	
2017-08-03 19:09:24,894 Epoch[28] Batch [1190]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.118934,	
2017-08-03 19:09:32,392 Epoch[28] Batch [1200]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.118833,	
2017-08-03 19:09:40,036 Epoch[28] Batch [1210]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.118747,	
2017-08-03 19:09:47,653 Epoch[28] Batch [1220]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.118863,	
2017-08-03 19:09:55,268 Epoch[28] Batch [1230]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.118778,	
2017-08-03 19:10:02,812 Epoch[28] Batch [1240]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.118679,	
2017-08-03 19:10:10,164 Epoch[28] Batch [1250]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.118557,	
2017-08-03 19:10:17,917 Epoch[28] Batch [1260]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.118409,	
2017-08-03 19:10:25,286 Epoch[28] Batch [1270]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.118397,	
2017-08-03 19:10:33,914 Epoch[28] Batch [1280]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.118413,	
2017-08-03 19:10:42,249 Epoch[28] Batch [1290]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.118310,	
2017-08-03 19:10:50,771 Epoch[28] Batch [1300]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.118336,	
2017-08-03 19:10:59,011 Epoch[28] Batch [1310]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.118378,	
2017-08-03 19:11:07,443 Epoch[28] Batch [1320]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.118293,	
2017-08-03 19:11:16,124 Epoch[28] Batch [1330]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.118188,	
2017-08-03 19:11:24,386 Epoch[28] Batch [1340]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.118211,	
2017-08-03 19:11:32,906 Epoch[28] Batch [1350]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.118241,	
2017-08-03 19:11:41,598 Epoch[28] Batch [1360]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.118467,	
2017-08-03 19:11:49,986 Epoch[28] Batch [1370]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.118573,	
2017-08-03 19:11:58,580 Epoch[28] Batch [1380]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.118726,	
2017-08-03 19:12:07,148 Epoch[28] Batch [1390]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.118742,	
2017-08-03 19:12:15,897 Epoch[28] Batch [1400]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.118806,	
2017-08-03 19:12:24,243 Epoch[28] Batch [1410]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.118777,	
2017-08-03 19:12:32,925 Epoch[28] Batch [1420]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.118778,	
2017-08-03 19:12:41,795 Epoch[28] Batch [1430]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.118755,	
2017-08-03 19:12:50,236 Epoch[28] Batch [1440]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.118700,	
2017-08-03 19:12:58,781 Epoch[28] Batch [1450]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.118702,	
2017-08-03 19:13:07,382 Epoch[28] Batch [1460]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.118718,	
2017-08-03 19:13:16,012 Epoch[28] Batch [1470]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.118706,	
2017-08-03 19:13:24,569 Epoch[28] Batch [1480]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.118663,	
2017-08-03 19:13:29,725 Epoch[28] Train-FCNLogLoss=0.118655
2017-08-03 19:13:29,725 Epoch[28] Time cost=1277.999
2017-08-03 19:13:30,699 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0029.params"
2017-08-03 19:13:34,290 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0029.states"
2017-08-03 19:13:44,263 Epoch[29] Batch [10]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.100704,	
2017-08-03 19:13:52,926 Epoch[29] Batch [20]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.107633,	
2017-08-03 19:14:01,438 Epoch[29] Batch [30]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116509,	
2017-08-03 19:14:10,251 Epoch[29] Batch [40]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.115314,	
2017-08-03 19:14:18,725 Epoch[29] Batch [50]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.115434,	
2017-08-03 19:14:27,216 Epoch[29] Batch [60]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.115409,	
2017-08-03 19:14:34,926 Epoch[29] Batch [70]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.117482,	
2017-08-03 19:14:43,018 Epoch[29] Batch [80]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.116530,	
2017-08-03 19:14:51,262 Epoch[29] Batch [90]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.116152,	
2017-08-03 19:14:59,658 Epoch[29] Batch [100]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.116188,	
2017-08-03 19:15:08,399 Epoch[29] Batch [110]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.115621,	
2017-08-03 19:15:16,887 Epoch[29] Batch [120]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.115936,	
2017-08-03 19:15:25,458 Epoch[29] Batch [130]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.116845,	
2017-08-03 19:15:34,071 Epoch[29] Batch [140]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.115656,	
2017-08-03 19:15:42,812 Epoch[29] Batch [150]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.115560,	
2017-08-03 19:15:51,448 Epoch[29] Batch [160]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.115278,	
2017-08-03 19:16:00,180 Epoch[29] Batch [170]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.114284,	
2017-08-03 19:16:08,844 Epoch[29] Batch [180]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.114005,	
2017-08-03 19:16:17,329 Epoch[29] Batch [190]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.113811,	
2017-08-03 19:16:25,741 Epoch[29] Batch [200]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.114715,	
2017-08-03 19:16:34,452 Epoch[29] Batch [210]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.114503,	
2017-08-03 19:16:43,246 Epoch[29] Batch [220]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.114021,	
2017-08-03 19:16:51,704 Epoch[29] Batch [230]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.114138,	
2017-08-03 19:17:00,411 Epoch[29] Batch [240]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.113703,	
2017-08-03 19:17:09,099 Epoch[29] Batch [250]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.113672,	
2017-08-03 19:17:17,744 Epoch[29] Batch [260]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.113545,	
2017-08-03 19:17:26,212 Epoch[29] Batch [270]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.113752,	
2017-08-03 19:17:34,861 Epoch[29] Batch [280]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.113282,	
2017-08-03 19:17:43,768 Epoch[29] Batch [290]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.112968,	
2017-08-03 19:17:52,245 Epoch[29] Batch [300]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.112834,	
2017-08-03 19:18:00,978 Epoch[29] Batch [310]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.112341,	
2017-08-03 19:18:09,622 Epoch[29] Batch [320]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.112018,	
2017-08-03 19:18:17,927 Epoch[29] Batch [330]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.112057,	
2017-08-03 19:18:26,808 Epoch[29] Batch [340]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.112069,	
2017-08-03 19:18:35,610 Epoch[29] Batch [350]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.111858,	
2017-08-03 19:18:44,093 Epoch[29] Batch [360]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.111785,	
2017-08-03 19:18:51,614 Epoch[29] Batch [370]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.111812,	
2017-08-03 19:18:59,968 Epoch[29] Batch [380]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.111599,	
2017-08-03 19:19:08,482 Epoch[29] Batch [390]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.111309,	
2017-08-03 19:19:16,987 Epoch[29] Batch [400]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.111263,	
2017-08-03 19:19:25,276 Epoch[29] Batch [410]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.111137,	
2017-08-03 19:19:33,973 Epoch[29] Batch [420]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.111040,	
2017-08-03 19:19:42,829 Epoch[29] Batch [430]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.111293,	
2017-08-03 19:19:51,364 Epoch[29] Batch [440]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.111087,	
2017-08-03 19:19:59,780 Epoch[29] Batch [450]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.111222,	
2017-08-03 19:20:08,547 Epoch[29] Batch [460]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.111173,	
2017-08-03 19:20:17,205 Epoch[29] Batch [470]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.111036,	
2017-08-03 19:20:25,655 Epoch[29] Batch [480]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.111038,	
2017-08-03 19:20:34,184 Epoch[29] Batch [490]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.110871,	
2017-08-03 19:20:43,126 Epoch[29] Batch [500]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.110769,	
2017-08-03 19:20:51,607 Epoch[29] Batch [510]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.110652,	
2017-08-03 19:21:00,203 Epoch[29] Batch [520]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.110628,	
2017-08-03 19:21:09,003 Epoch[29] Batch [530]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.110857,	
2017-08-03 19:21:17,495 Epoch[29] Batch [540]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.110705,	
2017-08-03 19:21:26,010 Epoch[29] Batch [550]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.110722,	
2017-08-03 19:21:34,684 Epoch[29] Batch [560]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.110715,	
2017-08-03 19:21:43,388 Epoch[29] Batch [570]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.110666,	
2017-08-03 19:21:51,866 Epoch[29] Batch [580]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.110664,	
2017-08-03 19:22:00,509 Epoch[29] Batch [590]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.110748,	
2017-08-03 19:22:09,264 Epoch[29] Batch [600]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.110732,	
2017-08-03 19:22:17,703 Epoch[29] Batch [610]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.110722,	
2017-08-03 19:22:26,379 Epoch[29] Batch [620]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.110829,	
2017-08-03 19:22:34,979 Epoch[29] Batch [630]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.111069,	
2017-08-03 19:22:43,531 Epoch[29] Batch [640]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.110939,	
2017-08-03 19:22:51,943 Epoch[29] Batch [650]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.111140,	
2017-08-03 19:23:00,613 Epoch[29] Batch [660]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.111039,	
2017-08-03 19:23:08,044 Epoch[29] Batch [670]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.110997,	
2017-08-03 19:23:15,795 Epoch[29] Batch [680]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.111000,	
2017-08-03 19:23:24,362 Epoch[29] Batch [690]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.111058,	
2017-08-03 19:23:32,919 Epoch[29] Batch [700]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.110895,	
2017-08-03 19:23:41,257 Epoch[29] Batch [710]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.111171,	
2017-08-03 19:23:49,941 Epoch[29] Batch [720]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.111097,	
2017-08-03 19:23:58,674 Epoch[29] Batch [730]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.111269,	
2017-08-03 19:24:07,249 Epoch[29] Batch [740]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.111250,	
2017-08-03 19:24:15,874 Epoch[29] Batch [750]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.111412,	
2017-08-03 19:24:24,436 Epoch[29] Batch [760]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.111526,	
2017-08-03 19:24:33,064 Epoch[29] Batch [770]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.111478,	
2017-08-03 19:24:41,361 Epoch[29] Batch [780]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.111562,	
2017-08-03 19:24:50,030 Epoch[29] Batch [790]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.111432,	
2017-08-03 19:24:58,825 Epoch[29] Batch [800]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.111502,	
2017-08-03 19:25:07,298 Epoch[29] Batch [810]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.111389,	
2017-08-03 19:25:15,778 Epoch[29] Batch [820]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.111300,	
2017-08-03 19:25:24,397 Epoch[29] Batch [830]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.111438,	
2017-08-03 19:25:33,264 Epoch[29] Batch [840]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.111421,	
2017-08-03 19:25:41,656 Epoch[29] Batch [850]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.111351,	
2017-08-03 19:25:50,128 Epoch[29] Batch [860]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.111266,	
2017-08-03 19:25:58,947 Epoch[29] Batch [870]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.111365,	
2017-08-03 19:26:07,409 Epoch[29] Batch [880]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.111482,	
2017-08-03 19:26:16,041 Epoch[29] Batch [890]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.111448,	
2017-08-03 19:26:24,631 Epoch[29] Batch [900]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.111748,	
2017-08-03 19:26:33,332 Epoch[29] Batch [910]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.111659,	
2017-08-03 19:26:41,718 Epoch[29] Batch [920]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.111539,	
2017-08-03 19:26:50,319 Epoch[29] Batch [930]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.111597,	
2017-08-03 19:26:58,968 Epoch[29] Batch [940]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.111588,	
2017-08-03 19:27:07,687 Epoch[29] Batch [950]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.111521,	
2017-08-03 19:27:16,069 Epoch[29] Batch [960]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.111432,	
2017-08-03 19:27:23,863 Epoch[29] Batch [970]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.111271,	
2017-08-03 19:27:32,315 Epoch[29] Batch [980]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.111386,	
2017-08-03 19:27:40,935 Epoch[29] Batch [990]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.111388,	
2017-08-03 19:27:49,270 Epoch[29] Batch [1000]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.111473,	
2017-08-03 19:27:57,643 Epoch[29] Batch [1010]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.111383,	
2017-08-03 19:28:06,449 Epoch[29] Batch [1020]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.111260,	
2017-08-03 19:28:15,017 Epoch[29] Batch [1030]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.111128,	
2017-08-03 19:28:23,634 Epoch[29] Batch [1040]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.111311,	
2017-08-03 19:28:32,223 Epoch[29] Batch [1050]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.111370,	
2017-08-03 19:28:40,688 Epoch[29] Batch [1060]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.111379,	
2017-08-03 19:28:49,357 Epoch[29] Batch [1070]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.111390,	
2017-08-03 19:28:57,738 Epoch[29] Batch [1080]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.111313,	
2017-08-03 19:29:06,397 Epoch[29] Batch [1090]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.111342,	
2017-08-03 19:29:15,194 Epoch[29] Batch [1100]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.111383,	
2017-08-03 19:29:23,657 Epoch[29] Batch [1110]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.111359,	
2017-08-03 19:29:32,367 Epoch[29] Batch [1120]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.111378,	
2017-08-03 19:29:40,902 Epoch[29] Batch [1130]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.111395,	
2017-08-03 19:29:49,702 Epoch[29] Batch [1140]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.111355,	
2017-08-03 19:29:58,128 Epoch[29] Batch [1150]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.111465,	
2017-08-03 19:30:06,746 Epoch[29] Batch [1160]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.111576,	
2017-08-03 19:30:15,437 Epoch[29] Batch [1170]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.111504,	
2017-08-03 19:30:23,949 Epoch[29] Batch [1180]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.111519,	
2017-08-03 19:30:32,624 Epoch[29] Batch [1190]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.111525,	
2017-08-03 19:30:41,438 Epoch[29] Batch [1200]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.111561,	
2017-08-03 19:30:49,989 Epoch[29] Batch [1210]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.111601,	
2017-08-03 19:30:58,644 Epoch[29] Batch [1220]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.111530,	
2017-08-03 19:31:07,167 Epoch[29] Batch [1230]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.111469,	
2017-08-03 19:31:15,846 Epoch[29] Batch [1240]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.111356,	
2017-08-03 19:31:24,085 Epoch[29] Batch [1250]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.111441,	
2017-08-03 19:31:32,962 Epoch[29] Batch [1260]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.111457,	
2017-08-03 19:31:40,664 Epoch[29] Batch [1270]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.111410,	
2017-08-03 19:31:49,224 Epoch[29] Batch [1280]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.111259,	
2017-08-03 19:31:57,543 Epoch[29] Batch [1290]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.111187,	
2017-08-03 19:32:06,037 Epoch[29] Batch [1300]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.111178,	
2017-08-03 19:32:14,808 Epoch[29] Batch [1310]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.111160,	
2017-08-03 19:32:23,322 Epoch[29] Batch [1320]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.111153,	
2017-08-03 19:32:31,821 Epoch[29] Batch [1330]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.111205,	
2017-08-03 19:32:40,495 Epoch[29] Batch [1340]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.111151,	
2017-08-03 19:32:49,149 Epoch[29] Batch [1350]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.111222,	
2017-08-03 19:32:57,611 Epoch[29] Batch [1360]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.111155,	
2017-08-03 19:33:06,251 Epoch[29] Batch [1370]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.111160,	
2017-08-03 19:33:15,049 Epoch[29] Batch [1380]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.111163,	
2017-08-03 19:33:23,466 Epoch[29] Batch [1390]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.111191,	
2017-08-03 19:33:32,009 Epoch[29] Batch [1400]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.111262,	
2017-08-03 19:33:40,601 Epoch[29] Batch [1410]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.111190,	
2017-08-03 19:34:03,383 Epoch[29] Batch [1420]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.111191,	
2017-08-03 19:34:30,746 Epoch[29] Batch [1430]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.111228,	
2017-08-03 19:35:00,329 Epoch[29] Batch [1440]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.111188,	
2017-08-03 19:35:28,984 Epoch[29] Batch [1450]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.111151,	
2017-08-03 19:35:57,689 Epoch[29] Batch [1460]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.111210,	
2017-08-03 19:36:29,878 Epoch[29] Batch [1470]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.111218,	
2017-08-03 19:37:02,355 Epoch[29] Batch [1480]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.111249,	
2017-08-03 19:37:22,669 Epoch[29] Train-FCNLogLoss=0.111264
2017-08-03 19:37:22,669 Epoch[29] Time cost=1428.379
2017-08-03 19:37:25,069 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0030.params"
2017-08-03 19:37:49,247 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0030.states"
2017-08-03 19:38:21,323 Epoch[30] Batch [10]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.121172,	
2017-08-03 19:38:48,054 Epoch[30] Batch [20]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.114310,	
2017-08-03 19:39:17,106 Epoch[30] Batch [30]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.109528,	
2017-08-03 19:39:46,840 Epoch[30] Batch [40]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.106673,	
2017-08-03 19:40:16,945 Epoch[30] Batch [50]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.107727,	
2017-08-03 19:40:44,484 Epoch[30] Batch [60]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.107356,	
2017-08-03 19:41:16,064 Epoch[30] Batch [70]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.107969,	
2017-08-03 19:41:46,857 Epoch[30] Batch [80]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.110142,	
2017-08-03 19:42:13,484 Epoch[30] Batch [90]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.111337,	
2017-08-03 19:42:42,595 Epoch[30] Batch [100]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.116624,	
2017-08-03 19:43:17,197 Epoch[30] Batch [110]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.117761,	
2017-08-03 19:43:46,684 Epoch[30] Batch [120]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.118025,	
2017-08-03 19:44:22,624 Epoch[30] Batch [130]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.120333,	
2017-08-03 19:44:52,695 Epoch[30] Batch [140]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.121083,	
2017-08-03 19:45:25,912 Epoch[30] Batch [150]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.120181,	
2017-08-03 19:45:52,665 Epoch[30] Batch [160]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.120436,	
2017-08-03 19:46:25,325 Epoch[30] Batch [170]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.120485,	
2017-08-03 19:46:57,281 Epoch[30] Batch [180]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.120260,	
2017-08-03 19:47:25,849 Epoch[30] Batch [190]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.119984,	
2017-08-03 19:47:59,443 Epoch[30] Batch [200]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.119611,	
2017-08-03 19:48:31,180 Epoch[30] Batch [210]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.118927,	
2017-08-03 19:48:59,212 Epoch[30] Batch [220]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.118740,	
2017-08-03 19:49:26,590 Epoch[30] Batch [230]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.117814,	
2017-08-03 19:49:34,909 Epoch[30] Batch [240]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.118716,	
2017-08-03 19:49:43,509 Epoch[30] Batch [250]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.118397,	
2017-08-03 19:49:52,133 Epoch[30] Batch [260]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.118372,	
2017-08-03 19:50:00,829 Epoch[30] Batch [270]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.118180,	
2017-08-03 19:50:09,144 Epoch[30] Batch [280]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.118229,	
2017-08-03 19:50:17,761 Epoch[30] Batch [290]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.118234,	
2017-08-03 19:50:26,262 Epoch[30] Batch [300]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.118194,	
2017-08-03 19:50:34,938 Epoch[30] Batch [310]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.118106,	
2017-08-03 19:50:43,364 Epoch[30] Batch [320]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.117602,	
2017-08-03 19:50:52,065 Epoch[30] Batch [330]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.117414,	
2017-08-03 19:51:00,710 Epoch[30] Batch [340]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.117073,	
2017-08-03 19:51:09,275 Epoch[30] Batch [350]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.116838,	
2017-08-03 19:51:17,776 Epoch[30] Batch [360]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.116566,	
2017-08-03 19:51:26,366 Epoch[30] Batch [370]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.116394,	
2017-08-03 19:51:35,071 Epoch[30] Batch [380]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.116676,	
2017-08-03 19:51:43,775 Epoch[30] Batch [390]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.116650,	
2017-08-03 19:51:52,530 Epoch[30] Batch [400]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.116781,	
2017-08-03 19:52:01,208 Epoch[30] Batch [410]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.116779,	
2017-08-03 19:52:09,719 Epoch[30] Batch [420]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.116620,	
2017-08-03 19:52:18,427 Epoch[30] Batch [430]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.116637,	
2017-08-03 19:52:27,166 Epoch[30] Batch [440]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.116364,	
2017-08-03 19:52:35,619 Epoch[30] Batch [450]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.116244,	
2017-08-03 19:52:44,184 Epoch[30] Batch [460]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.116198,	
2017-08-03 19:52:52,155 Epoch[30] Batch [470]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.115952,	
2017-08-03 19:52:59,557 Epoch[30] Batch [480]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.115704,	
2017-08-03 19:53:08,163 Epoch[30] Batch [490]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.115700,	
2017-08-03 19:53:16,745 Epoch[30] Batch [500]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.115480,	
2017-08-03 19:53:25,062 Epoch[30] Batch [510]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.115444,	
2017-08-03 19:53:33,780 Epoch[30] Batch [520]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.115477,	
2017-08-03 19:53:42,409 Epoch[30] Batch [530]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.115457,	
2017-08-03 19:53:50,936 Epoch[30] Batch [540]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.115005,	
2017-08-03 19:53:59,567 Epoch[30] Batch [550]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.114866,	
2017-08-03 19:54:08,443 Epoch[30] Batch [560]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.114673,	
2017-08-03 19:54:16,990 Epoch[30] Batch [570]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.114535,	
2017-08-03 19:54:25,382 Epoch[30] Batch [580]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.114625,	
2017-08-03 19:54:34,064 Epoch[30] Batch [590]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.114729,	
2017-08-03 19:54:42,817 Epoch[30] Batch [600]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.114556,	
2017-08-03 19:54:51,379 Epoch[30] Batch [610]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.114468,	
2017-08-03 19:54:59,828 Epoch[30] Batch [620]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.114461,	
2017-08-03 19:55:08,601 Epoch[30] Batch [630]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.114417,	
2017-08-03 19:55:17,216 Epoch[30] Batch [640]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.114418,	
2017-08-03 19:55:25,764 Epoch[30] Batch [650]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.114303,	
2017-08-03 19:55:34,375 Epoch[30] Batch [660]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.114294,	
2017-08-03 19:55:43,167 Epoch[30] Batch [670]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.114188,	
2017-08-03 19:55:51,672 Epoch[30] Batch [680]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.114009,	
2017-08-03 19:56:00,320 Epoch[30] Batch [690]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.113970,	
2017-08-03 19:56:09,149 Epoch[30] Batch [700]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.113943,	
2017-08-03 19:56:17,469 Epoch[30] Batch [710]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.113801,	
2017-08-03 19:56:26,237 Epoch[30] Batch [720]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.113784,	
2017-08-03 19:56:34,989 Epoch[30] Batch [730]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.113575,	
2017-08-03 19:56:43,496 Epoch[30] Batch [740]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.113600,	
2017-08-03 19:56:52,153 Epoch[30] Batch [750]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.113756,	
2017-08-03 19:57:00,741 Epoch[30] Batch [760]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.113567,	
2017-08-03 19:57:08,531 Epoch[30] Batch [770]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.113510,	
2017-08-03 19:57:16,944 Epoch[30] Batch [780]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.113438,	
2017-08-03 19:57:25,239 Epoch[30] Batch [790]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.113562,	
2017-08-03 19:57:33,709 Epoch[30] Batch [800]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.113517,	
2017-08-03 19:57:42,316 Epoch[30] Batch [810]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.113473,	
2017-08-03 19:57:50,750 Epoch[30] Batch [820]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.113314,	
2017-08-03 19:57:59,338 Epoch[30] Batch [830]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.113267,	
2017-08-03 19:58:07,995 Epoch[30] Batch [840]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.113144,	
2017-08-03 19:58:16,566 Epoch[30] Batch [850]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.113062,	
2017-08-03 19:58:24,983 Epoch[30] Batch [860]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.112822,	
2017-08-03 19:58:48,686 Epoch[30] Batch [870]	Speed: 1.69 samples/sec	Train-FCNLogLoss=0.112757,	
2017-08-03 19:59:24,524 Epoch[30] Batch [880]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.112765,	
2017-08-03 20:00:07,503 Epoch[30] Batch [890]	Speed: 0.93 samples/sec	Train-FCNLogLoss=0.112624,	
2017-08-03 20:00:40,194 Epoch[30] Batch [900]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.112669,	
2017-08-03 20:01:09,969 Epoch[30] Batch [910]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.112734,	
2017-08-03 20:01:44,673 Epoch[30] Batch [920]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.112666,	
2017-08-03 20:02:16,960 Epoch[30] Batch [930]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.112616,	
2017-08-03 20:02:52,603 Epoch[30] Batch [940]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.112501,	
2017-08-03 20:03:24,847 Epoch[30] Batch [950]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.112470,	
2017-08-03 20:03:59,324 Epoch[30] Batch [960]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.112484,	
2017-08-03 20:04:27,758 Epoch[30] Batch [970]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.112437,	
2017-08-03 20:05:04,138 Epoch[30] Batch [980]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.112310,	
2017-08-03 20:05:37,474 Epoch[30] Batch [990]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.112354,	
2017-08-03 20:06:11,781 Epoch[30] Batch [1000]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.112354,	
2017-08-03 20:06:50,115 Epoch[30] Batch [1010]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.112275,	
2017-08-03 20:07:26,512 Epoch[30] Batch [1020]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.112179,	
2017-08-03 20:08:02,674 Epoch[30] Batch [1030]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.112069,	
2017-08-03 20:08:35,665 Epoch[30] Batch [1040]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.112107,	
2017-08-03 20:09:09,561 Epoch[30] Batch [1050]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.112157,	
2017-08-03 20:09:45,334 Epoch[30] Batch [1060]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.112088,	
2017-08-03 20:10:21,548 Epoch[30] Batch [1070]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.111986,	
2017-08-03 20:10:54,131 Epoch[30] Batch [1080]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.112001,	
2017-08-03 20:11:25,120 Epoch[30] Batch [1090]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.112023,	
2017-08-03 20:11:59,350 Epoch[30] Batch [1100]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.111978,	
2017-08-03 20:12:34,176 Epoch[30] Batch [1110]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.111898,	
2017-08-03 20:13:09,462 Epoch[30] Batch [1120]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.111866,	
2017-08-03 20:13:42,397 Epoch[30] Batch [1130]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.111745,	
2017-08-03 20:14:15,580 Epoch[30] Batch [1140]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.111744,	
2017-08-03 20:14:52,797 Epoch[30] Batch [1150]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.111711,	
2017-08-03 20:15:25,661 Epoch[30] Batch [1160]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.111590,	
2017-08-03 20:15:58,779 Epoch[30] Batch [1170]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.111530,	
2017-08-03 20:16:28,902 Epoch[30] Batch [1180]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.111546,	
2017-08-03 20:17:06,412 Epoch[30] Batch [1190]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.111465,	
2017-08-03 20:17:37,921 Epoch[30] Batch [1200]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.111366,	
2017-08-03 20:18:13,802 Epoch[30] Batch [1210]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.111357,	
2017-08-03 20:18:50,516 Epoch[30] Batch [1220]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.111185,	
2017-08-03 20:19:27,078 Epoch[30] Batch [1230]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.111065,	
2017-08-03 20:19:59,806 Epoch[30] Batch [1240]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.111100,	
2017-08-03 20:20:32,947 Epoch[30] Batch [1250]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.111423,	
2017-08-03 20:21:06,252 Epoch[30] Batch [1260]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.111387,	
2017-08-03 20:21:42,654 Epoch[30] Batch [1270]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.111367,	
2017-08-03 20:22:14,128 Epoch[30] Batch [1280]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.111355,	
2017-08-03 20:22:52,524 Epoch[30] Batch [1290]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.111297,	
2017-08-03 20:23:24,945 Epoch[30] Batch [1300]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.111290,	
2017-08-03 20:24:05,428 Epoch[30] Batch [1310]	Speed: 0.99 samples/sec	Train-FCNLogLoss=0.111292,	
2017-08-03 20:24:37,308 Epoch[30] Batch [1320]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.111222,	
2017-08-03 20:25:12,858 Epoch[30] Batch [1330]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.111214,	
2017-08-03 20:25:46,794 Epoch[30] Batch [1340]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.111136,	
2017-08-03 20:26:24,647 Epoch[30] Batch [1350]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.111135,	
2017-08-03 20:27:00,218 Epoch[30] Batch [1360]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.111145,	
2017-08-03 20:27:31,201 Epoch[30] Batch [1370]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.111189,	
2017-08-03 20:28:03,920 Epoch[30] Batch [1380]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.111144,	
2017-08-03 20:28:38,550 Epoch[30] Batch [1390]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.111092,	
2017-08-03 20:29:13,322 Epoch[30] Batch [1400]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.111136,	
2017-08-03 20:29:49,913 Epoch[30] Batch [1410]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.111130,	
2017-08-03 20:30:26,015 Epoch[30] Batch [1420]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.111074,	
2017-08-03 20:31:02,615 Epoch[30] Batch [1430]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.111067,	
2017-08-03 20:31:40,134 Epoch[30] Batch [1440]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.111083,	
2017-08-03 20:32:18,007 Epoch[30] Batch [1450]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.111056,	
2017-08-03 20:32:56,002 Epoch[30] Batch [1460]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.111031,	
2017-08-03 20:33:28,996 Epoch[30] Batch [1470]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.111022,	
2017-08-03 20:34:04,075 Epoch[30] Batch [1480]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.110917,	
2017-08-03 20:34:25,698 Epoch[30] Train-FCNLogLoss=0.110909
2017-08-03 20:34:25,698 Epoch[30] Time cost=3396.451
2017-08-03 20:34:28,532 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0031.params"
2017-08-03 20:34:48,978 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0031.states"
2017-08-03 20:35:31,027 Epoch[31] Batch [10]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.113200,	
2017-08-03 20:36:10,092 Epoch[31] Batch [20]	Speed: 1.02 samples/sec	Train-FCNLogLoss=0.108459,	
2017-08-03 20:36:45,934 Epoch[31] Batch [30]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.110377,	
2017-08-03 20:37:22,048 Epoch[31] Batch [40]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.111918,	
2017-08-03 20:37:56,197 Epoch[31] Batch [50]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.113093,	
2017-08-03 20:38:31,067 Epoch[31] Batch [60]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.111171,	
2017-08-03 20:39:05,632 Epoch[31] Batch [70]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.110401,	
2017-08-03 20:39:36,454 Epoch[31] Batch [80]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.108886,	
2017-08-03 20:40:13,111 Epoch[31] Batch [90]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.110089,	
2017-08-03 20:40:45,556 Epoch[31] Batch [100]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.109935,	
2017-08-03 20:41:20,383 Epoch[31] Batch [110]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.108760,	
2017-08-03 20:41:54,191 Epoch[31] Batch [120]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.108715,	
2017-08-03 20:42:31,388 Epoch[31] Batch [130]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.108612,	
2017-08-03 20:43:06,781 Epoch[31] Batch [140]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.107788,	
2017-08-03 20:43:41,544 Epoch[31] Batch [150]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.106838,	
2017-08-03 20:44:15,471 Epoch[31] Batch [160]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.106594,	
2017-08-03 20:44:51,431 Epoch[31] Batch [170]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.106370,	
2017-08-03 20:45:24,019 Epoch[31] Batch [180]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.106551,	
2017-08-03 20:45:59,244 Epoch[31] Batch [190]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.106654,	
2017-08-03 20:46:33,109 Epoch[31] Batch [200]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.107331,	
2017-08-03 20:47:06,305 Epoch[31] Batch [210]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.107731,	
2017-08-03 20:47:41,958 Epoch[31] Batch [220]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.108227,	
2017-08-03 20:48:19,555 Epoch[31] Batch [230]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.108429,	
2017-08-03 20:48:53,516 Epoch[31] Batch [240]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.108994,	
2017-08-03 20:49:28,920 Epoch[31] Batch [250]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.108521,	
2017-08-03 20:50:01,847 Epoch[31] Batch [260]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.108018,	
2017-08-03 20:50:36,267 Epoch[31] Batch [270]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.107968,	
2017-08-03 20:51:10,622 Epoch[31] Batch [280]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.108083,	
2017-08-03 20:51:45,998 Epoch[31] Batch [290]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.107447,	
2017-08-03 20:52:17,304 Epoch[31] Batch [300]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.107688,	
2017-08-03 20:52:52,365 Epoch[31] Batch [310]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.107444,	
2017-08-03 20:53:28,111 Epoch[31] Batch [320]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.107557,	
2017-08-03 20:54:03,406 Epoch[31] Batch [330]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.107612,	
2017-08-03 20:54:36,916 Epoch[31] Batch [340]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.107852,	
2017-08-03 20:55:08,809 Epoch[31] Batch [350]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.108057,	
2017-08-03 20:55:41,431 Epoch[31] Batch [360]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.108693,	
2017-08-03 20:56:15,386 Epoch[31] Batch [370]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.108690,	
2017-08-03 20:56:46,470 Epoch[31] Batch [380]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.108663,	
2017-08-03 20:57:19,461 Epoch[31] Batch [390]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.108639,	
2017-08-03 20:57:54,101 Epoch[31] Batch [400]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.108898,	
2017-08-03 20:58:30,024 Epoch[31] Batch [410]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.108971,	
2017-08-03 20:59:08,493 Epoch[31] Batch [420]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.109064,	
2017-08-03 20:59:47,983 Epoch[31] Batch [430]	Speed: 1.01 samples/sec	Train-FCNLogLoss=0.108982,	
2017-08-03 21:00:23,038 Epoch[31] Batch [440]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.108736,	
2017-08-03 21:00:59,191 Epoch[31] Batch [450]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.108491,	
2017-08-03 21:01:38,808 Epoch[31] Batch [460]	Speed: 1.01 samples/sec	Train-FCNLogLoss=0.108615,	
2017-08-03 21:02:15,779 Epoch[31] Batch [470]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.108472,	
2017-08-03 21:02:57,212 Epoch[31] Batch [480]	Speed: 0.97 samples/sec	Train-FCNLogLoss=0.108192,	
2017-08-03 21:03:38,748 Epoch[31] Batch [490]	Speed: 0.96 samples/sec	Train-FCNLogLoss=0.108181,	
2017-08-03 21:04:16,711 Epoch[31] Batch [500]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.108245,	
2017-08-03 21:04:49,331 Epoch[31] Batch [510]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.108111,	
2017-08-03 21:05:25,575 Epoch[31] Batch [520]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.108138,	
2017-08-03 21:06:01,885 Epoch[31] Batch [530]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.108107,	
2017-08-03 21:06:40,690 Epoch[31] Batch [540]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.108168,	
2017-08-03 21:07:18,989 Epoch[31] Batch [550]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.108143,	
2017-08-03 21:07:53,294 Epoch[31] Batch [560]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.108363,	
2017-08-03 21:08:32,759 Epoch[31] Batch [570]	Speed: 1.01 samples/sec	Train-FCNLogLoss=0.108481,	
2017-08-03 21:09:01,820 Epoch[31] Batch [580]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.108392,	
2017-08-03 21:09:37,709 Epoch[31] Batch [590]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.108637,	
2017-08-03 21:10:09,188 Epoch[31] Batch [600]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.108708,	
2017-08-03 21:10:44,011 Epoch[31] Batch [610]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.108649,	
2017-08-03 21:11:18,013 Epoch[31] Batch [620]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.108523,	
2017-08-03 21:11:51,312 Epoch[31] Batch [630]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.108593,	
2017-08-03 21:12:22,380 Epoch[31] Batch [640]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.108831,	
2017-08-03 21:12:53,903 Epoch[31] Batch [650]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.108940,	
2017-08-03 21:13:27,166 Epoch[31] Batch [660]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.109079,	
2017-08-03 21:13:59,887 Epoch[31] Batch [670]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.109138,	
2017-08-03 21:14:33,264 Epoch[31] Batch [680]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.108949,	
2017-08-03 21:15:06,519 Epoch[31] Batch [690]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.109031,	
2017-08-03 21:15:39,780 Epoch[31] Batch [700]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.109096,	
2017-08-03 21:16:13,157 Epoch[31] Batch [710]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.108894,	
2017-08-03 21:16:47,018 Epoch[31] Batch [720]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.108859,	
2017-08-03 21:17:14,387 Epoch[31] Batch [730]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.108999,	
2017-08-03 21:17:49,135 Epoch[31] Batch [740]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.108861,	
2017-08-03 21:18:23,393 Epoch[31] Batch [750]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.108796,	
2017-08-03 21:18:56,105 Epoch[31] Batch [760]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.108758,	
2017-08-03 21:19:26,210 Epoch[31] Batch [770]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.108900,	
2017-08-03 21:19:54,743 Epoch[31] Batch [780]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.108895,	
2017-08-03 21:20:26,486 Epoch[31] Batch [790]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.109095,	
2017-08-03 21:20:55,561 Epoch[31] Batch [800]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.109293,	
2017-08-03 21:21:26,621 Epoch[31] Batch [810]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.109401,	
2017-08-03 21:22:01,686 Epoch[31] Batch [820]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.109338,	
2017-08-03 21:22:35,781 Epoch[31] Batch [830]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.109318,	
2017-08-03 21:23:07,273 Epoch[31] Batch [840]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.109258,	
2017-08-03 21:23:45,250 Epoch[31] Batch [850]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.109243,	
2017-08-03 21:24:19,998 Epoch[31] Batch [860]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.109380,	
2017-08-03 21:24:54,664 Epoch[31] Batch [870]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.109371,	
2017-08-03 21:25:28,751 Epoch[31] Batch [880]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.109340,	
2017-08-03 21:26:02,804 Epoch[31] Batch [890]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.109293,	
2017-08-03 21:26:36,994 Epoch[31] Batch [900]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.109398,	
2017-08-03 21:27:08,461 Epoch[31] Batch [910]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.109532,	
2017-08-03 21:27:39,001 Epoch[31] Batch [920]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.109981,	
2017-08-03 21:28:17,948 Epoch[31] Batch [930]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.110047,	
2017-08-03 21:28:49,036 Epoch[31] Batch [940]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.110084,	
2017-08-03 21:29:24,298 Epoch[31] Batch [950]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.110072,	
2017-08-03 21:30:01,414 Epoch[31] Batch [960]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.110071,	
2017-08-03 21:30:36,588 Epoch[31] Batch [970]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.110012,	
2017-08-03 21:31:11,239 Epoch[31] Batch [980]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.110084,	
2017-08-03 21:31:49,001 Epoch[31] Batch [990]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.110127,	
2017-08-03 21:32:19,637 Epoch[31] Batch [1000]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.110017,	
2017-08-03 21:32:50,909 Epoch[31] Batch [1010]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.109908,	
2017-08-03 21:33:22,247 Epoch[31] Batch [1020]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.109924,	
2017-08-03 21:33:55,729 Epoch[31] Batch [1030]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109836,	
2017-08-03 21:34:27,798 Epoch[31] Batch [1040]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.109710,	
2017-08-03 21:35:05,289 Epoch[31] Batch [1050]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.109683,	
2017-08-03 21:35:42,073 Epoch[31] Batch [1060]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.109607,	
2017-08-03 21:36:10,932 Epoch[31] Batch [1070]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.109593,	
2017-08-03 21:36:47,387 Epoch[31] Batch [1080]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.109647,	
2017-08-03 21:37:18,138 Epoch[31] Batch [1090]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.109682,	
2017-08-03 21:37:54,457 Epoch[31] Batch [1100]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.109653,	
2017-08-03 21:38:27,971 Epoch[31] Batch [1110]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109645,	
2017-08-03 21:39:01,114 Epoch[31] Batch [1120]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.109698,	
2017-08-03 21:39:33,403 Epoch[31] Batch [1130]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.109740,	
2017-08-03 21:40:09,670 Epoch[31] Batch [1140]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.109695,	
2017-08-03 21:40:39,480 Epoch[31] Batch [1150]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.109765,	
2017-08-03 21:41:17,719 Epoch[31] Batch [1160]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.109765,	
2017-08-03 21:41:51,438 Epoch[31] Batch [1170]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109669,	
2017-08-03 21:42:29,890 Epoch[31] Batch [1180]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.109605,	
2017-08-03 21:43:00,725 Epoch[31] Batch [1190]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.109561,	
2017-08-03 21:43:33,688 Epoch[31] Batch [1200]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.109458,	
2017-08-03 21:44:04,218 Epoch[31] Batch [1210]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.109516,	
2017-08-03 21:44:37,786 Epoch[31] Batch [1220]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109504,	
2017-08-03 21:45:13,510 Epoch[31] Batch [1230]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.109535,	
2017-08-03 21:45:49,580 Epoch[31] Batch [1240]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.109579,	
2017-08-03 21:46:21,928 Epoch[31] Batch [1250]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.109573,	
2017-08-03 21:46:58,018 Epoch[31] Batch [1260]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.109593,	
2017-08-03 21:47:30,638 Epoch[31] Batch [1270]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.109778,	
2017-08-03 21:48:04,863 Epoch[31] Batch [1280]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.109813,	
2017-08-03 21:48:39,584 Epoch[31] Batch [1290]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.109793,	
2017-08-03 21:49:13,125 Epoch[31] Batch [1300]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109788,	
2017-08-03 21:49:48,836 Epoch[31] Batch [1310]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.109789,	
2017-08-03 21:50:22,571 Epoch[31] Batch [1320]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109718,	
2017-08-03 21:50:52,829 Epoch[31] Batch [1330]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.109661,	
2017-08-03 21:51:29,371 Epoch[31] Batch [1340]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.109711,	
2017-08-03 21:52:05,347 Epoch[31] Batch [1350]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.109655,	
2017-08-03 21:52:39,122 Epoch[31] Batch [1360]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.109639,	
2017-08-03 21:53:13,625 Epoch[31] Batch [1370]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.109649,	
2017-08-03 21:53:48,486 Epoch[31] Batch [1380]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.109543,	
2017-08-03 21:54:23,923 Epoch[31] Batch [1390]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.109467,	
2017-08-03 21:54:58,660 Epoch[31] Batch [1400]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.109501,	
2017-08-03 21:55:33,566 Epoch[31] Batch [1410]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.109446,	
2017-08-03 21:56:06,637 Epoch[31] Batch [1420]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.109381,	
2017-08-03 21:56:40,379 Epoch[31] Batch [1430]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109406,	
2017-08-03 21:57:10,338 Epoch[31] Batch [1440]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.109316,	
2017-08-03 21:57:43,276 Epoch[31] Batch [1450]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.109333,	
2017-08-03 21:58:14,863 Epoch[31] Batch [1460]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.109307,	
2017-08-03 21:58:56,014 Epoch[31] Batch [1470]	Speed: 0.97 samples/sec	Train-FCNLogLoss=0.109226,	
2017-08-03 21:59:31,350 Epoch[31] Batch [1480]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.109167,	
2017-08-03 21:59:52,364 Epoch[31] Train-FCNLogLoss=0.109157
2017-08-03 21:59:52,364 Epoch[31] Time cost=5103.385
2017-08-03 21:59:54,532 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0032.params"
2017-08-03 22:00:17,116 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0032.states"
2017-08-03 22:00:30,420 Epoch[32] Batch [10]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.103682,	
2017-08-03 22:00:38,729 Epoch[32] Batch [20]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.097745,	
2017-08-03 22:00:47,331 Epoch[32] Batch [30]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.100448,	
2017-08-03 22:00:55,685 Epoch[32] Batch [40]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.100470,	
2017-08-03 22:01:04,074 Epoch[32] Batch [50]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.101613,	
2017-08-03 22:01:12,743 Epoch[32] Batch [60]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.102729,	
2017-08-03 22:01:21,382 Epoch[32] Batch [70]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.102713,	
2017-08-03 22:01:29,626 Epoch[32] Batch [80]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.103514,	
2017-08-03 22:01:38,165 Epoch[32] Batch [90]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.102565,	
2017-08-03 22:01:46,956 Epoch[32] Batch [100]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.102457,	
2017-08-03 22:01:55,514 Epoch[32] Batch [110]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.103202,	
2017-08-03 22:02:04,134 Epoch[32] Batch [120]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.102648,	
2017-08-03 22:02:12,665 Epoch[32] Batch [130]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.102569,	
2017-08-03 22:02:21,219 Epoch[32] Batch [140]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.103062,	
2017-08-03 22:02:29,534 Epoch[32] Batch [150]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.103743,	
2017-08-03 22:02:38,130 Epoch[32] Batch [160]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.103795,	
2017-08-03 22:02:46,879 Epoch[32] Batch [170]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.104335,	
2017-08-03 22:02:55,118 Epoch[32] Batch [180]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.104227,	
2017-08-03 22:03:03,714 Epoch[32] Batch [190]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.103948,	
2017-08-03 22:03:12,443 Epoch[32] Batch [200]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.104317,	
2017-08-03 22:03:21,043 Epoch[32] Batch [210]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.104866,	
2017-08-03 22:03:29,512 Epoch[32] Batch [220]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.104897,	
2017-08-03 22:03:38,131 Epoch[32] Batch [230]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.105100,	
2017-08-03 22:03:46,681 Epoch[32] Batch [240]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.104939,	
2017-08-03 22:03:55,253 Epoch[32] Batch [250]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.104770,	
2017-08-03 22:04:06,041 Epoch[32] Batch [260]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.104618,	
2017-08-03 22:04:14,755 Epoch[32] Batch [270]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.104412,	
2017-08-03 22:04:23,135 Epoch[32] Batch [280]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.103903,	
2017-08-03 22:04:30,818 Epoch[32] Batch [290]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.103843,	
2017-08-03 22:04:38,773 Epoch[32] Batch [300]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.104249,	
2017-08-03 22:04:47,074 Epoch[32] Batch [310]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.104380,	
2017-08-03 22:04:55,426 Epoch[32] Batch [320]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.104038,	
2017-08-03 22:05:03,931 Epoch[32] Batch [330]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.103868,	
2017-08-03 22:05:12,222 Epoch[32] Batch [340]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.103786,	
2017-08-03 22:05:20,804 Epoch[32] Batch [350]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.104316,	
2017-08-03 22:05:29,545 Epoch[32] Batch [360]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.104210,	
2017-08-03 22:05:37,812 Epoch[32] Batch [370]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.104158,	
2017-08-03 22:05:46,492 Epoch[32] Batch [380]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.104293,	
2017-08-03 22:05:54,981 Epoch[32] Batch [390]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.104235,	
2017-08-03 22:06:03,428 Epoch[32] Batch [400]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.104156,	
2017-08-03 22:06:11,878 Epoch[32] Batch [410]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.104487,	
2017-08-03 22:06:20,374 Epoch[32] Batch [420]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.104301,	
2017-08-03 22:06:29,146 Epoch[32] Batch [430]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.104445,	
2017-08-03 22:06:37,397 Epoch[32] Batch [440]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.104535,	
2017-08-03 22:06:45,879 Epoch[32] Batch [450]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.104596,	
2017-08-03 22:06:54,337 Epoch[32] Batch [460]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.104888,	
2017-08-03 22:07:02,923 Epoch[32] Batch [470]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.105056,	
2017-08-03 22:07:11,318 Epoch[32] Batch [480]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.105201,	
2017-08-03 22:07:19,816 Epoch[32] Batch [490]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.105089,	
2017-08-03 22:07:28,497 Epoch[32] Batch [500]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.105117,	
2017-08-03 22:07:36,849 Epoch[32] Batch [510]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.105116,	
2017-08-03 22:07:45,219 Epoch[32] Batch [520]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.105311,	
2017-08-03 22:07:53,731 Epoch[32] Batch [530]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.105309,	
2017-08-03 22:08:02,353 Epoch[32] Batch [540]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.105497,	
2017-08-03 22:08:10,776 Epoch[32] Batch [550]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.105612,	
2017-08-03 22:08:19,289 Epoch[32] Batch [560]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.105382,	
2017-08-03 22:08:27,850 Epoch[32] Batch [570]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.105555,	
2017-08-03 22:08:36,249 Epoch[32] Batch [580]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.105585,	
2017-08-03 22:08:43,681 Epoch[32] Batch [590]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.105757,	
2017-08-03 22:08:51,445 Epoch[32] Batch [600]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.105937,	
2017-08-03 22:08:59,783 Epoch[32] Batch [610]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.105707,	
2017-08-03 22:09:08,293 Epoch[32] Batch [620]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.105846,	
2017-08-03 22:09:16,797 Epoch[32] Batch [630]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.105710,	
2017-08-03 22:09:25,229 Epoch[32] Batch [640]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.105683,	
2017-08-03 22:09:33,850 Epoch[32] Batch [650]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.105919,	
2017-08-03 22:09:42,358 Epoch[32] Batch [660]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.106024,	
2017-08-03 22:09:50,570 Epoch[32] Batch [670]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.106221,	
2017-08-03 22:09:59,013 Epoch[32] Batch [680]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.106348,	
2017-08-03 22:10:07,758 Epoch[32] Batch [690]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.106367,	
2017-08-03 22:10:16,111 Epoch[32] Batch [700]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.106391,	
2017-08-03 22:10:24,432 Epoch[32] Batch [710]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.106395,	
2017-08-03 22:10:32,994 Epoch[32] Batch [720]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.106593,	
2017-08-03 22:10:41,580 Epoch[32] Batch [730]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.106660,	
2017-08-03 22:10:49,882 Epoch[32] Batch [740]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.106777,	
2017-08-03 22:10:58,496 Epoch[32] Batch [750]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.106771,	
2017-08-03 22:11:07,046 Epoch[32] Batch [760]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.106848,	
2017-08-03 22:11:15,322 Epoch[32] Batch [770]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.106809,	
2017-08-03 22:11:23,880 Epoch[32] Batch [780]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.106926,	
2017-08-03 22:11:32,363 Epoch[32] Batch [790]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.106857,	
2017-08-03 22:11:40,793 Epoch[32] Batch [800]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.106815,	
2017-08-03 22:11:49,306 Epoch[32] Batch [810]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.106901,	
2017-08-03 22:11:57,761 Epoch[32] Batch [820]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.106883,	
2017-08-03 22:12:06,478 Epoch[32] Batch [830]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.106941,	
2017-08-03 22:12:14,822 Epoch[32] Batch [840]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.106882,	
2017-08-03 22:12:23,272 Epoch[32] Batch [850]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.106922,	
2017-08-03 22:12:31,980 Epoch[32] Batch [860]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.106793,	
2017-08-03 22:12:40,280 Epoch[32] Batch [870]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.106927,	
2017-08-03 22:12:48,900 Epoch[32] Batch [880]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.107084,	
2017-08-03 22:12:56,475 Epoch[32] Batch [890]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.107148,	
2017-08-03 22:13:04,968 Epoch[32] Batch [900]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.107178,	
2017-08-03 22:13:13,118 Epoch[32] Batch [910]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.107165,	
2017-08-03 22:13:21,465 Epoch[32] Batch [920]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.107080,	
2017-08-03 22:13:30,167 Epoch[32] Batch [930]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.107061,	
2017-08-03 22:13:38,591 Epoch[32] Batch [940]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.106988,	
2017-08-03 22:13:47,100 Epoch[32] Batch [950]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.106914,	
2017-08-03 22:13:55,715 Epoch[32] Batch [960]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.107082,	
2017-08-03 22:14:04,117 Epoch[32] Batch [970]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.107105,	
2017-08-03 22:14:12,711 Epoch[32] Batch [980]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.107229,	
2017-08-03 22:14:21,185 Epoch[32] Batch [990]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.107096,	
2017-08-03 22:14:37,796 Epoch[32] Batch [1000]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.107130,	
2017-08-03 22:15:03,108 Epoch[32] Batch [1010]	Speed: 1.58 samples/sec	Train-FCNLogLoss=0.107014,	
2017-08-03 22:15:33,828 Epoch[32] Batch [1020]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.107042,	
2017-08-03 22:16:05,822 Epoch[32] Batch [1030]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.107184,	
2017-08-03 22:16:36,848 Epoch[32] Batch [1040]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.107284,	
2017-08-03 22:17:06,320 Epoch[32] Batch [1050]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.107454,	
2017-08-03 22:17:39,424 Epoch[32] Batch [1060]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.107457,	
2017-08-03 22:18:07,297 Epoch[32] Batch [1070]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.107386,	
2017-08-03 22:18:39,756 Epoch[32] Batch [1080]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.107277,	
2017-08-03 22:19:08,292 Epoch[32] Batch [1090]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.107153,	
2017-08-03 22:19:37,177 Epoch[32] Batch [1100]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.107001,	
2017-08-03 22:20:11,326 Epoch[32] Batch [1110]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.106898,	
2017-08-03 22:20:42,231 Epoch[32] Batch [1120]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.106826,	
2017-08-03 22:21:17,420 Epoch[32] Batch [1130]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.106815,	
2017-08-03 22:21:49,229 Epoch[32] Batch [1140]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.106734,	
2017-08-03 22:22:19,045 Epoch[32] Batch [1150]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.106711,	
2017-08-03 22:22:48,747 Epoch[32] Batch [1160]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.106745,	
2017-08-03 22:23:19,390 Epoch[32] Batch [1170]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.106765,	
2017-08-03 22:23:48,219 Epoch[32] Batch [1180]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.106740,	
2017-08-03 22:24:18,132 Epoch[32] Batch [1190]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.106867,	
2017-08-03 22:24:50,620 Epoch[32] Batch [1200]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.106959,	
2017-08-03 22:25:24,089 Epoch[32] Batch [1210]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.107001,	
2017-08-03 22:25:53,502 Epoch[32] Batch [1220]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.107107,	
2017-08-03 22:26:24,498 Epoch[32] Batch [1230]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.107102,	
2017-08-03 22:26:57,720 Epoch[32] Batch [1240]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.107086,	
2017-08-03 22:27:28,265 Epoch[32] Batch [1250]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.107251,	
2017-08-03 22:27:57,378 Epoch[32] Batch [1260]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.107177,	
2017-08-03 22:28:26,959 Epoch[32] Batch [1270]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.107141,	
2017-08-03 22:28:57,384 Epoch[32] Batch [1280]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.107193,	
2017-08-03 22:29:28,560 Epoch[32] Batch [1290]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.107367,	
2017-08-03 22:29:59,845 Epoch[32] Batch [1300]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.107314,	
2017-08-03 22:30:29,313 Epoch[32] Batch [1310]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.107356,	
2017-08-03 22:30:57,428 Epoch[32] Batch [1320]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.107343,	
2017-08-03 22:31:29,584 Epoch[32] Batch [1330]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.107392,	
2017-08-03 22:32:04,775 Epoch[32] Batch [1340]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.107303,	
2017-08-03 22:32:35,422 Epoch[32] Batch [1350]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.107251,	
2017-08-03 22:33:11,045 Epoch[32] Batch [1360]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.107223,	
2017-08-03 22:33:46,646 Epoch[32] Batch [1370]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.107233,	
2017-08-03 22:34:18,929 Epoch[32] Batch [1380]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.107193,	
2017-08-03 22:34:51,485 Epoch[32] Batch [1390]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.107260,	
2017-08-03 22:35:20,169 Epoch[32] Batch [1400]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.107325,	
2017-08-03 22:35:54,859 Epoch[32] Batch [1410]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.107238,	
2017-08-03 22:36:27,035 Epoch[32] Batch [1420]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.107337,	
2017-08-03 22:36:56,005 Epoch[32] Batch [1430]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.107301,	
2017-08-03 22:37:26,240 Epoch[32] Batch [1440]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.107303,	
2017-08-03 22:37:57,540 Epoch[32] Batch [1450]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.107256,	
2017-08-03 22:38:33,156 Epoch[32] Batch [1460]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.107241,	
2017-08-03 22:39:04,157 Epoch[32] Batch [1470]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.107261,	
2017-08-03 22:39:35,615 Epoch[32] Batch [1480]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.107253,	
2017-08-03 22:39:53,539 Epoch[32] Train-FCNLogLoss=0.107197
2017-08-03 22:39:53,539 Epoch[32] Time cost=2376.422
2017-08-03 22:39:56,746 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0033.params"
2017-08-03 22:40:17,889 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0033.states"
2017-08-03 22:40:54,645 Epoch[33] Batch [10]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100867,	
2017-08-03 22:41:26,614 Epoch[33] Batch [20]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.110582,	
2017-08-03 22:42:00,187 Epoch[33] Batch [30]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.109483,	
2017-08-03 22:42:31,096 Epoch[33] Batch [40]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.108429,	
2017-08-03 22:42:57,097 Epoch[33] Batch [50]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.108795,	
2017-08-03 22:43:25,953 Epoch[33] Batch [60]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.106477,	
2017-08-03 22:43:54,795 Epoch[33] Batch [70]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.106801,	
2017-08-03 22:44:26,008 Epoch[33] Batch [80]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.108448,	
2017-08-03 22:44:55,760 Epoch[33] Batch [90]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.108397,	
2017-08-03 22:45:27,367 Epoch[33] Batch [100]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.107828,	
2017-08-03 22:45:53,210 Epoch[33] Batch [110]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.107935,	
2017-08-03 22:46:25,395 Epoch[33] Batch [120]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.107462,	
2017-08-03 22:46:55,415 Epoch[33] Batch [130]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.108172,	
2017-08-03 22:47:25,884 Epoch[33] Batch [140]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.108682,	
2017-08-03 22:48:03,999 Epoch[33] Batch [150]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.107832,	
2017-08-03 22:48:36,558 Epoch[33] Batch [160]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.107481,	
2017-08-03 22:49:09,041 Epoch[33] Batch [170]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.107694,	
2017-08-03 22:49:37,910 Epoch[33] Batch [180]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.107259,	
2017-08-03 22:50:09,002 Epoch[33] Batch [190]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.106518,	
2017-08-03 22:50:44,193 Epoch[33] Batch [200]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.106195,	
2017-08-03 22:51:15,232 Epoch[33] Batch [210]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.105502,	
2017-08-03 22:51:48,266 Epoch[33] Batch [220]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.105050,	
2017-08-03 22:52:18,535 Epoch[33] Batch [230]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.105133,	
2017-08-03 22:52:49,715 Epoch[33] Batch [240]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.105263,	
2017-08-03 22:53:23,604 Epoch[33] Batch [250]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.105471,	
2017-08-03 22:53:57,134 Epoch[33] Batch [260]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.105307,	
2017-08-03 22:54:27,430 Epoch[33] Batch [270]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.105042,	
2017-08-03 22:54:59,111 Epoch[33] Batch [280]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.105053,	
2017-08-03 22:55:29,865 Epoch[33] Batch [290]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.105066,	
2017-08-03 22:55:59,518 Epoch[33] Batch [300]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.105099,	
2017-08-03 22:56:29,779 Epoch[33] Batch [310]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.105310,	
2017-08-03 22:56:58,549 Epoch[33] Batch [320]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.105118,	
2017-08-03 22:57:29,961 Epoch[33] Batch [330]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.105764,	
2017-08-03 22:58:05,267 Epoch[33] Batch [340]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.106135,	
2017-08-03 22:58:36,453 Epoch[33] Batch [350]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.106379,	
2017-08-03 22:59:13,278 Epoch[33] Batch [360]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.106710,	
2017-08-03 22:59:56,495 Epoch[33] Batch [370]	Speed: 0.93 samples/sec	Train-FCNLogLoss=0.106792,	
2017-08-03 23:00:29,667 Epoch[33] Batch [380]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.106780,	
2017-08-03 23:01:07,840 Epoch[33] Batch [390]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.106621,	
2017-08-03 23:01:40,336 Epoch[33] Batch [400]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.106693,	
2017-08-03 23:02:14,672 Epoch[33] Batch [410]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.106545,	
2017-08-03 23:02:46,818 Epoch[33] Batch [420]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.106451,	
2017-08-03 23:03:18,572 Epoch[33] Batch [430]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.106309,	
2017-08-03 23:03:49,376 Epoch[33] Batch [440]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.106171,	
2017-08-03 23:04:21,365 Epoch[33] Batch [450]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.105998,	
2017-08-03 23:04:55,521 Epoch[33] Batch [460]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.105962,	
2017-08-03 23:05:30,374 Epoch[33] Batch [470]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.106355,	
2017-08-03 23:06:06,097 Epoch[33] Batch [480]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.106333,	
2017-08-03 23:06:36,936 Epoch[33] Batch [490]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.106270,	
2017-08-03 23:07:05,614 Epoch[33] Batch [500]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.106271,	
2017-08-03 23:07:35,761 Epoch[33] Batch [510]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.106144,	
2017-08-03 23:08:04,560 Epoch[33] Batch [520]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.106190,	
2017-08-03 23:08:33,120 Epoch[33] Batch [530]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.106295,	
2017-08-03 23:09:07,777 Epoch[33] Batch [540]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.106317,	
2017-08-03 23:09:36,438 Epoch[33] Batch [550]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.106285,	
2017-08-03 23:10:07,247 Epoch[33] Batch [560]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.106215,	
2017-08-03 23:10:33,660 Epoch[33] Batch [570]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.106340,	
2017-08-03 23:11:09,236 Epoch[33] Batch [580]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.106485,	
2017-08-03 23:11:43,803 Epoch[33] Batch [590]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.106504,	
2017-08-03 23:12:16,461 Epoch[33] Batch [600]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.106514,	
2017-08-03 23:12:47,061 Epoch[33] Batch [610]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.106438,	
2017-08-03 23:13:22,305 Epoch[33] Batch [620]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.106483,	
2017-08-03 23:13:50,388 Epoch[33] Batch [630]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.106223,	
2017-08-03 23:14:21,726 Epoch[33] Batch [640]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.106115,	
2017-08-03 23:14:51,833 Epoch[33] Batch [650]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.106122,	
2017-08-03 23:15:20,344 Epoch[33] Batch [660]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.106026,	
2017-08-03 23:15:51,958 Epoch[33] Batch [670]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.105892,	
2017-08-03 23:16:25,171 Epoch[33] Batch [680]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.105702,	
2017-08-03 23:16:58,003 Epoch[33] Batch [690]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.105810,	
2017-08-03 23:17:31,166 Epoch[33] Batch [700]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.105768,	
2017-08-03 23:18:02,110 Epoch[33] Batch [710]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.105775,	
2017-08-03 23:18:30,554 Epoch[33] Batch [720]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.105776,	
2017-08-03 23:19:04,102 Epoch[33] Batch [730]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.106007,	
2017-08-03 23:19:36,761 Epoch[33] Batch [740]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.106422,	
2017-08-03 23:20:05,117 Epoch[33] Batch [750]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.106392,	
2017-08-03 23:20:36,774 Epoch[33] Batch [760]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.106488,	
2017-08-03 23:21:07,587 Epoch[33] Batch [770]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.106643,	
2017-08-03 23:21:39,527 Epoch[33] Batch [780]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.106590,	
2017-08-03 23:22:11,686 Epoch[33] Batch [790]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.106563,	
2017-08-03 23:22:38,943 Epoch[33] Batch [800]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.106560,	
2017-08-03 23:23:12,058 Epoch[33] Batch [810]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.106595,	
2017-08-03 23:23:41,177 Epoch[33] Batch [820]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.106756,	
2017-08-03 23:24:12,337 Epoch[33] Batch [830]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.106672,	
2017-08-03 23:24:41,415 Epoch[33] Batch [840]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.106709,	
2017-08-03 23:25:10,924 Epoch[33] Batch [850]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.106724,	
2017-08-03 23:25:41,326 Epoch[33] Batch [860]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.106917,	
2017-08-03 23:26:10,096 Epoch[33] Batch [870]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.107232,	
2017-08-03 23:26:42,317 Epoch[33] Batch [880]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.107342,	
2017-08-03 23:27:12,614 Epoch[33] Batch [890]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.107396,	
2017-08-03 23:27:46,655 Epoch[33] Batch [900]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.107389,	
2017-08-03 23:28:19,009 Epoch[33] Batch [910]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.107355,	
2017-08-03 23:28:48,236 Epoch[33] Batch [920]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.107297,	
2017-08-03 23:29:23,447 Epoch[33] Batch [930]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.107308,	
2017-08-03 23:29:51,875 Epoch[33] Batch [940]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.107205,	
2017-08-03 23:30:22,505 Epoch[33] Batch [950]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.107137,	
2017-08-03 23:30:53,005 Epoch[33] Batch [960]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.107154,	
2017-08-03 23:31:24,964 Epoch[33] Batch [970]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.107162,	
2017-08-03 23:32:03,014 Epoch[33] Batch [980]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.107110,	
2017-08-03 23:32:34,051 Epoch[33] Batch [990]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.107123,	
2017-08-03 23:33:01,587 Epoch[33] Batch [1000]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.107127,	
2017-08-03 23:33:30,580 Epoch[33] Batch [1010]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.107090,	
2017-08-03 23:33:58,697 Epoch[33] Batch [1020]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.107142,	
2017-08-03 23:34:25,056 Epoch[33] Batch [1030]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.107206,	
2017-08-03 23:34:56,895 Epoch[33] Batch [1040]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.107138,	
2017-08-03 23:35:24,880 Epoch[33] Batch [1050]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.107097,	
2017-08-03 23:35:54,022 Epoch[33] Batch [1060]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.107158,	
2017-08-03 23:36:21,969 Epoch[33] Batch [1070]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.107177,	
2017-08-03 23:36:53,036 Epoch[33] Batch [1080]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.107191,	
2017-08-03 23:37:21,899 Epoch[33] Batch [1090]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.107139,	
2017-08-03 23:37:49,788 Epoch[33] Batch [1100]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.107169,	
2017-08-03 23:38:21,585 Epoch[33] Batch [1110]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.107333,	
2017-08-03 23:38:53,279 Epoch[33] Batch [1120]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.107353,	
2017-08-03 23:39:20,546 Epoch[33] Batch [1130]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.107322,	
2017-08-03 23:39:53,098 Epoch[33] Batch [1140]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.107418,	
2017-08-03 23:40:27,619 Epoch[33] Batch [1150]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.107403,	
2017-08-03 23:40:57,593 Epoch[33] Batch [1160]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.107390,	
2017-08-03 23:41:27,706 Epoch[33] Batch [1170]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.107386,	
2017-08-03 23:42:02,902 Epoch[33] Batch [1180]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.107369,	
2017-08-03 23:42:35,875 Epoch[33] Batch [1190]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.107366,	
2017-08-03 23:43:07,272 Epoch[33] Batch [1200]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.107257,	
2017-08-03 23:43:37,276 Epoch[33] Batch [1210]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.107267,	
2017-08-03 23:44:07,443 Epoch[33] Batch [1220]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.107198,	
2017-08-03 23:44:37,600 Epoch[33] Batch [1230]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.107137,	
2017-08-03 23:45:06,802 Epoch[33] Batch [1240]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.107168,	
2017-08-03 23:45:37,889 Epoch[33] Batch [1250]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.107014,	
2017-08-03 23:46:06,501 Epoch[33] Batch [1260]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.107020,	
2017-08-03 23:46:38,552 Epoch[33] Batch [1270]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.106995,	
2017-08-03 23:47:06,038 Epoch[33] Batch [1280]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.107031,	
2017-08-03 23:47:37,442 Epoch[33] Batch [1290]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.106952,	
2017-08-03 23:48:08,676 Epoch[33] Batch [1300]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.106988,	
2017-08-03 23:48:41,896 Epoch[33] Batch [1310]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.107017,	
2017-08-03 23:49:12,828 Epoch[33] Batch [1320]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.106929,	
2017-08-03 23:49:43,520 Epoch[33] Batch [1330]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.106883,	
2017-08-03 23:50:16,352 Epoch[33] Batch [1340]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.106880,	
2017-08-03 23:50:45,002 Epoch[33] Batch [1350]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.107036,	
2017-08-03 23:51:16,754 Epoch[33] Batch [1360]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.106945,	
2017-08-03 23:51:47,962 Epoch[33] Batch [1370]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.107087,	
2017-08-03 23:52:21,638 Epoch[33] Batch [1380]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.107161,	
2017-08-03 23:52:51,232 Epoch[33] Batch [1390]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.107156,	
2017-08-03 23:53:24,249 Epoch[33] Batch [1400]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.107038,	
2017-08-03 23:53:57,151 Epoch[33] Batch [1410]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.107072,	
2017-08-03 23:54:30,687 Epoch[33] Batch [1420]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.107120,	
2017-08-03 23:55:05,015 Epoch[33] Batch [1430]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.107200,	
2017-08-03 23:55:34,699 Epoch[33] Batch [1440]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.107094,	
2017-08-03 23:56:04,944 Epoch[33] Batch [1450]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.107127,	
2017-08-03 23:56:37,575 Epoch[33] Batch [1460]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.107077,	
2017-08-03 23:57:10,671 Epoch[33] Batch [1470]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.107043,	
2017-08-03 23:57:41,239 Epoch[33] Batch [1480]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.106945,	
2017-08-03 23:58:00,401 Epoch[33] Train-FCNLogLoss=0.106891
2017-08-03 23:58:00,401 Epoch[33] Time cost=4662.512
2017-08-03 23:58:03,953 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0034.params"
2017-08-03 23:58:26,952 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0034.states"
2017-08-03 23:58:58,375 Epoch[34] Batch [10]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.101365,	
2017-08-03 23:59:30,682 Epoch[34] Batch [20]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.096515,	
2017-08-04 00:00:00,579 Epoch[34] Batch [30]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.098734,	
2017-08-04 00:00:31,424 Epoch[34] Batch [40]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.098572,	
2017-08-04 00:00:59,383 Epoch[34] Batch [50]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.099200,	
2017-08-04 00:01:29,513 Epoch[34] Batch [60]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.097299,	
2017-08-04 00:01:56,832 Epoch[34] Batch [70]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.096735,	
2017-08-04 00:02:24,318 Epoch[34] Batch [80]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.097658,	
2017-08-04 00:02:57,915 Epoch[34] Batch [90]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.099827,	
2017-08-04 00:03:25,515 Epoch[34] Batch [100]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.100184,	
2017-08-04 00:03:53,622 Epoch[34] Batch [110]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.099822,	
2017-08-04 00:04:20,730 Epoch[34] Batch [120]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.100050,	
2017-08-04 00:04:48,760 Epoch[34] Batch [130]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.099947,	
2017-08-04 00:05:23,239 Epoch[34] Batch [140]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.100685,	
2017-08-04 00:05:55,943 Epoch[34] Batch [150]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.100229,	
2017-08-04 00:06:29,747 Epoch[34] Batch [160]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.100857,	
2017-08-04 00:07:01,989 Epoch[34] Batch [170]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101456,	
2017-08-04 00:07:32,752 Epoch[34] Batch [180]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.101061,	
2017-08-04 00:08:07,846 Epoch[34] Batch [190]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.101444,	
2017-08-04 00:08:43,386 Epoch[34] Batch [200]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.101338,	
2017-08-04 00:09:17,766 Epoch[34] Batch [210]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.101152,	
2017-08-04 00:09:51,527 Epoch[34] Batch [220]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101348,	
2017-08-04 00:10:22,905 Epoch[34] Batch [230]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101240,	
2017-08-04 00:10:48,084 Epoch[34] Batch [240]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.101139,	
2017-08-04 00:11:18,774 Epoch[34] Batch [250]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.101077,	
2017-08-04 00:11:51,311 Epoch[34] Batch [260]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100995,	
2017-08-04 00:12:24,093 Epoch[34] Batch [270]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.101226,	
2017-08-04 00:12:52,772 Epoch[34] Batch [280]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.101203,	
2017-08-04 00:13:23,839 Epoch[34] Batch [290]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101009,	
2017-08-04 00:13:51,959 Epoch[34] Batch [300]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.101134,	
2017-08-04 00:14:20,970 Epoch[34] Batch [310]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.101549,	
2017-08-04 00:14:51,694 Epoch[34] Batch [320]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.101280,	
2017-08-04 00:15:26,203 Epoch[34] Batch [330]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.101341,	
2017-08-04 00:16:02,693 Epoch[34] Batch [340]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.101619,	
2017-08-04 00:16:33,902 Epoch[34] Batch [350]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.101628,	
2017-08-04 00:17:06,800 Epoch[34] Batch [360]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.101816,	
2017-08-04 00:17:42,948 Epoch[34] Batch [370]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.101919,	
2017-08-04 00:18:15,248 Epoch[34] Batch [380]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101633,	
2017-08-04 00:18:46,666 Epoch[34] Batch [390]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101787,	
2017-08-04 00:19:19,657 Epoch[34] Batch [400]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101516,	
2017-08-04 00:19:50,439 Epoch[34] Batch [410]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.101740,	
2017-08-04 00:20:20,534 Epoch[34] Batch [420]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101749,	
2017-08-04 00:20:51,070 Epoch[34] Batch [430]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101712,	
2017-08-04 00:21:20,182 Epoch[34] Batch [440]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.101865,	
2017-08-04 00:21:50,653 Epoch[34] Batch [450]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101896,	
2017-08-04 00:22:21,787 Epoch[34] Batch [460]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.101903,	
2017-08-04 00:22:54,542 Epoch[34] Batch [470]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.102064,	
2017-08-04 00:23:27,734 Epoch[34] Batch [480]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102262,	
2017-08-04 00:23:57,595 Epoch[34] Batch [490]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.102365,	
2017-08-04 00:24:27,295 Epoch[34] Batch [500]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.102300,	
2017-08-04 00:25:02,447 Epoch[34] Batch [510]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.102381,	
2017-08-04 00:25:37,663 Epoch[34] Batch [520]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.102534,	
2017-08-04 00:26:08,173 Epoch[34] Batch [530]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102555,	
2017-08-04 00:26:41,262 Epoch[34] Batch [540]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102567,	
2017-08-04 00:27:13,310 Epoch[34] Batch [550]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.102538,	
2017-08-04 00:27:47,082 Epoch[34] Batch [560]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.102512,	
2017-08-04 00:28:19,387 Epoch[34] Batch [570]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.102434,	
2017-08-04 00:28:49,324 Epoch[34] Batch [580]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.102598,	
2017-08-04 00:29:22,311 Epoch[34] Batch [590]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102647,	
2017-08-04 00:29:58,739 Epoch[34] Batch [600]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.102569,	
2017-08-04 00:30:34,768 Epoch[34] Batch [610]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.102533,	
2017-08-04 00:31:08,144 Epoch[34] Batch [620]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.102565,	
2017-08-04 00:31:40,015 Epoch[34] Batch [630]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.102613,	
2017-08-04 00:32:13,877 Epoch[34] Batch [640]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.102663,	
2017-08-04 00:32:51,291 Epoch[34] Batch [650]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.102511,	
2017-08-04 00:33:32,809 Epoch[34] Batch [660]	Speed: 0.96 samples/sec	Train-FCNLogLoss=0.102579,	
2017-08-04 00:34:04,937 Epoch[34] Batch [670]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.102582,	
2017-08-04 00:34:55,074 Epoch[34] Batch [680]	Speed: 0.80 samples/sec	Train-FCNLogLoss=0.102456,	
2017-08-04 00:35:46,277 Epoch[34] Batch [690]	Speed: 0.78 samples/sec	Train-FCNLogLoss=0.102399,	
2017-08-04 00:36:38,322 Epoch[34] Batch [700]	Speed: 0.77 samples/sec	Train-FCNLogLoss=0.102417,	
2017-08-04 00:37:19,880 Epoch[34] Batch [710]	Speed: 0.96 samples/sec	Train-FCNLogLoss=0.102563,	
2017-08-04 00:38:01,443 Epoch[34] Batch [720]	Speed: 0.96 samples/sec	Train-FCNLogLoss=0.102615,	
2017-08-04 00:38:41,744 Epoch[34] Batch [730]	Speed: 0.99 samples/sec	Train-FCNLogLoss=0.102672,	
2017-08-04 00:39:25,497 Epoch[34] Batch [740]	Speed: 0.91 samples/sec	Train-FCNLogLoss=0.102539,	
2017-08-04 00:40:05,195 Epoch[34] Batch [750]	Speed: 1.01 samples/sec	Train-FCNLogLoss=0.102687,	
2017-08-04 00:40:40,345 Epoch[34] Batch [760]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.102679,	
2017-08-04 00:41:16,078 Epoch[34] Batch [770]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.102511,	
2017-08-04 00:41:49,079 Epoch[34] Batch [780]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102432,	
2017-08-04 00:42:22,298 Epoch[34] Batch [790]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.102356,	
2017-08-04 00:42:50,967 Epoch[34] Batch [800]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.102561,	
2017-08-04 00:43:21,857 Epoch[34] Batch [810]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102531,	
2017-08-04 00:43:54,089 Epoch[34] Batch [820]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.102379,	
2017-08-04 00:44:21,136 Epoch[34] Batch [830]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.102371,	
2017-08-04 00:44:53,658 Epoch[34] Batch [840]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.102232,	
2017-08-04 00:45:25,942 Epoch[34] Batch [850]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.102155,	
2017-08-04 00:45:56,507 Epoch[34] Batch [860]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102199,	
2017-08-04 00:46:29,520 Epoch[34] Batch [870]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102213,	
2017-08-04 00:47:00,262 Epoch[34] Batch [880]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102150,	
2017-08-04 00:47:28,830 Epoch[34] Batch [890]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.102082,	
2017-08-04 00:48:02,905 Epoch[34] Batch [900]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.101994,	
2017-08-04 00:48:34,326 Epoch[34] Batch [910]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101887,	
2017-08-04 00:49:07,482 Epoch[34] Batch [920]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101871,	
2017-08-04 00:49:39,174 Epoch[34] Batch [930]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101818,	
2017-08-04 00:50:11,773 Epoch[34] Batch [940]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101855,	
2017-08-04 00:50:41,161 Epoch[34] Batch [950]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.101994,	
2017-08-04 00:51:14,711 Epoch[34] Batch [960]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.102041,	
2017-08-04 00:51:42,903 Epoch[34] Batch [970]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.102022,	
2017-08-04 00:52:14,361 Epoch[34] Batch [980]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101955,	
2017-08-04 00:52:48,054 Epoch[34] Batch [990]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.101860,	
2017-08-04 00:53:21,112 Epoch[34] Batch [1000]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101959,	
2017-08-04 00:53:53,642 Epoch[34] Batch [1010]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.102065,	
2017-08-04 00:54:25,884 Epoch[34] Batch [1020]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.102039,	
2017-08-04 00:54:57,913 Epoch[34] Batch [1030]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.102088,	
2017-08-04 00:55:31,370 Epoch[34] Batch [1040]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.102084,	
2017-08-04 00:56:04,736 Epoch[34] Batch [1050]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101969,	
2017-08-04 00:56:32,342 Epoch[34] Batch [1060]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.101931,	
2017-08-04 00:57:05,541 Epoch[34] Batch [1070]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101926,	
2017-08-04 00:57:35,461 Epoch[34] Batch [1080]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101870,	
2017-08-04 00:58:09,645 Epoch[34] Batch [1090]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.101897,	
2017-08-04 00:58:37,954 Epoch[34] Batch [1100]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.101920,	
2017-08-04 00:59:13,437 Epoch[34] Batch [1110]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.102040,	
2017-08-04 00:59:44,139 Epoch[34] Batch [1120]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102041,	
2017-08-04 01:00:12,746 Epoch[34] Batch [1130]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.102004,	
2017-08-04 01:00:43,738 Epoch[34] Batch [1140]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101956,	
2017-08-04 01:01:09,308 Epoch[34] Batch [1150]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.101887,	
2017-08-04 01:01:38,668 Epoch[34] Batch [1160]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.101891,	
2017-08-04 01:02:06,072 Epoch[34] Batch [1170]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.101896,	
2017-08-04 01:02:39,005 Epoch[34] Batch [1180]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101853,	
2017-08-04 01:03:14,163 Epoch[34] Batch [1190]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.101887,	
2017-08-04 01:03:44,296 Epoch[34] Batch [1200]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101915,	
2017-08-04 01:04:15,915 Epoch[34] Batch [1210]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101907,	
2017-08-04 01:04:46,460 Epoch[34] Batch [1220]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101887,	
2017-08-04 01:05:17,104 Epoch[34] Batch [1230]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101823,	
2017-08-04 01:05:47,656 Epoch[34] Batch [1240]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101828,	
2017-08-04 01:06:18,700 Epoch[34] Batch [1250]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101859,	
2017-08-04 01:06:52,002 Epoch[34] Batch [1260]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101814,	
2017-08-04 01:07:23,039 Epoch[34] Batch [1270]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101799,	
2017-08-04 01:07:56,981 Epoch[34] Batch [1280]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101770,	
2017-08-04 01:08:29,599 Epoch[34] Batch [1290]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101858,	
2017-08-04 01:09:06,072 Epoch[34] Batch [1300]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.101894,	
2017-08-04 01:09:46,788 Epoch[34] Batch [1310]	Speed: 0.98 samples/sec	Train-FCNLogLoss=0.101884,	
2017-08-04 01:10:28,048 Epoch[34] Batch [1320]	Speed: 0.97 samples/sec	Train-FCNLogLoss=0.101890,	
2017-08-04 01:11:05,784 Epoch[34] Batch [1330]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.101855,	
2017-08-04 01:11:35,493 Epoch[34] Batch [1340]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101835,	
2017-08-04 01:12:07,289 Epoch[34] Batch [1350]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101847,	
2017-08-04 01:12:39,214 Epoch[34] Batch [1360]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101867,	
2017-08-04 01:13:12,896 Epoch[34] Batch [1370]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.101931,	
2017-08-04 01:13:47,656 Epoch[34] Batch [1380]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.102070,	
2017-08-04 01:14:17,878 Epoch[34] Batch [1390]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.102105,	
2017-08-04 01:14:48,885 Epoch[34] Batch [1400]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102072,	
2017-08-04 01:15:19,761 Epoch[34] Batch [1410]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102075,	
2017-08-04 01:15:50,505 Epoch[34] Batch [1420]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102055,	
2017-08-04 01:16:20,679 Epoch[34] Batch [1430]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.102042,	
2017-08-04 01:16:53,724 Epoch[34] Batch [1440]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102054,	
2017-08-04 01:17:22,673 Epoch[34] Batch [1450]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.102129,	
2017-08-04 01:18:01,286 Epoch[34] Batch [1460]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.102096,	
2017-08-04 01:18:39,151 Epoch[34] Batch [1470]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.102149,	
2017-08-04 01:19:09,980 Epoch[34] Batch [1480]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102127,	
2017-08-04 01:19:29,217 Epoch[34] Train-FCNLogLoss=0.102159
2017-08-04 01:19:29,217 Epoch[34] Time cost=4862.265
2017-08-04 01:19:32,755 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0035.params"
2017-08-04 01:19:53,515 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0035.states"
2017-08-04 01:20:32,104 Epoch[35] Batch [10]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.090133,	
2017-08-04 01:21:02,453 Epoch[35] Batch [20]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.099649,	
2017-08-04 01:21:32,849 Epoch[35] Batch [30]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.099699,	
2017-08-04 01:22:04,014 Epoch[35] Batch [40]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.098639,	
2017-08-04 01:22:32,522 Epoch[35] Batch [50]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.099232,	
2017-08-04 01:23:02,363 Epoch[35] Batch [60]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.099929,	
2017-08-04 01:23:34,554 Epoch[35] Batch [70]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.100127,	
2017-08-04 01:24:06,508 Epoch[35] Batch [80]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101389,	
2017-08-04 01:24:36,031 Epoch[35] Batch [90]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101554,	
2017-08-04 01:25:09,574 Epoch[35] Batch [100]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.102207,	
2017-08-04 01:25:38,355 Epoch[35] Batch [110]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.101257,	
2017-08-04 01:26:11,409 Epoch[35] Batch [120]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101862,	
2017-08-04 01:26:43,103 Epoch[35] Batch [130]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101743,	
2017-08-04 01:27:11,075 Epoch[35] Batch [140]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.101589,	
2017-08-04 01:27:40,459 Epoch[35] Batch [150]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.101147,	
2017-08-04 01:28:10,525 Epoch[35] Batch [160]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.100968,	
2017-08-04 01:28:42,028 Epoch[35] Batch [170]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.100364,	
2017-08-04 01:29:12,530 Epoch[35] Batch [180]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.100448,	
2017-08-04 01:29:42,054 Epoch[35] Batch [190]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.100751,	
2017-08-04 01:30:11,143 Epoch[35] Batch [200]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.101138,	
2017-08-04 01:30:38,605 Epoch[35] Batch [210]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.101645,	
2017-08-04 01:31:07,137 Epoch[35] Batch [220]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.101988,	
2017-08-04 01:31:38,117 Epoch[35] Batch [230]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102083,	
2017-08-04 01:32:09,337 Epoch[35] Batch [240]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.101748,	
2017-08-04 01:32:43,757 Epoch[35] Batch [250]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.102724,	
2017-08-04 01:33:19,912 Epoch[35] Batch [260]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.102852,	
2017-08-04 01:33:50,508 Epoch[35] Batch [270]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102835,	
2017-08-04 01:34:24,770 Epoch[35] Batch [280]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.102892,	
2017-08-04 01:34:57,924 Epoch[35] Batch [290]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102866,	
2017-08-04 01:35:30,776 Epoch[35] Batch [300]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.102876,	
2017-08-04 01:36:04,436 Epoch[35] Batch [310]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.102931,	
2017-08-04 01:36:33,870 Epoch[35] Batch [320]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.102937,	
2017-08-04 01:37:04,262 Epoch[35] Batch [330]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.103123,	
2017-08-04 01:37:30,777 Epoch[35] Batch [340]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.103532,	
2017-08-04 01:38:00,945 Epoch[35] Batch [350]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.103718,	
2017-08-04 01:38:32,864 Epoch[35] Batch [360]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.103604,	
2017-08-04 01:39:06,645 Epoch[35] Batch [370]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.103343,	
2017-08-04 01:39:39,924 Epoch[35] Batch [380]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.103112,	
2017-08-04 01:40:12,977 Epoch[35] Batch [390]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.102996,	
2017-08-04 01:40:41,756 Epoch[35] Batch [400]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.103009,	
2017-08-04 01:41:09,000 Epoch[35] Batch [410]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.103113,	
2017-08-04 01:41:39,477 Epoch[35] Batch [420]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102982,	
2017-08-04 01:42:04,432 Epoch[35] Batch [430]	Speed: 1.60 samples/sec	Train-FCNLogLoss=0.102757,	
2017-08-04 01:42:35,144 Epoch[35] Batch [440]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102743,	
2017-08-04 01:43:07,068 Epoch[35] Batch [450]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.102503,	
2017-08-04 01:43:35,191 Epoch[35] Batch [460]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.102656,	
2017-08-04 01:44:07,579 Epoch[35] Batch [470]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.103309,	
2017-08-04 01:44:40,964 Epoch[35] Batch [480]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.103571,	
2017-08-04 01:45:11,615 Epoch[35] Batch [490]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.103941,	
2017-08-04 01:45:40,056 Epoch[35] Batch [500]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.103935,	
2017-08-04 01:46:12,430 Epoch[35] Batch [510]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.103921,	
2017-08-04 01:46:43,176 Epoch[35] Batch [520]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.104083,	
2017-08-04 01:47:13,363 Epoch[35] Batch [530]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.104208,	
2017-08-04 01:47:45,037 Epoch[35] Batch [540]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.104156,	
2017-08-04 01:48:16,366 Epoch[35] Batch [550]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.104092,	
2017-08-04 01:48:48,383 Epoch[35] Batch [560]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.104079,	
2017-08-04 01:49:18,561 Epoch[35] Batch [570]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.104109,	
2017-08-04 01:49:52,086 Epoch[35] Batch [580]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.104071,	
2017-08-04 01:50:26,074 Epoch[35] Batch [590]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.103976,	
2017-08-04 01:51:01,006 Epoch[35] Batch [600]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.104069,	
2017-08-04 01:51:32,941 Epoch[35] Batch [610]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.104042,	
2017-08-04 01:52:05,052 Epoch[35] Batch [620]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.103884,	
2017-08-04 01:52:35,378 Epoch[35] Batch [630]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.103871,	
2017-08-04 01:53:07,401 Epoch[35] Batch [640]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.104001,	
2017-08-04 01:53:38,726 Epoch[35] Batch [650]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.103946,	
2017-08-04 01:54:09,666 Epoch[35] Batch [660]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.103835,	
2017-08-04 01:54:42,948 Epoch[35] Batch [670]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.103926,	
2017-08-04 01:55:18,034 Epoch[35] Batch [680]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.103790,	
2017-08-04 01:55:51,264 Epoch[35] Batch [690]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.103836,	
2017-08-04 01:56:23,948 Epoch[35] Batch [700]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.103838,	
2017-08-04 01:56:58,435 Epoch[35] Batch [710]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.103719,	
2017-08-04 01:57:30,711 Epoch[35] Batch [720]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.103797,	
2017-08-04 01:58:01,713 Epoch[35] Batch [730]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.103833,	
2017-08-04 01:58:36,634 Epoch[35] Batch [740]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.103839,	
2017-08-04 01:59:12,599 Epoch[35] Batch [750]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.104031,	
2017-08-04 01:59:44,929 Epoch[35] Batch [760]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.103988,	
2017-08-04 02:00:18,866 Epoch[35] Batch [770]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.103998,	
2017-08-04 02:00:55,088 Epoch[35] Batch [780]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.103931,	
2017-08-04 02:01:25,004 Epoch[35] Batch [790]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.103927,	
2017-08-04 02:01:56,316 Epoch[35] Batch [800]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.103781,	
2017-08-04 02:02:26,622 Epoch[35] Batch [810]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.103823,	
2017-08-04 02:02:57,630 Epoch[35] Batch [820]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.103732,	
2017-08-04 02:03:26,823 Epoch[35] Batch [830]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.103521,	
2017-08-04 02:03:58,815 Epoch[35] Batch [840]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.103506,	
2017-08-04 02:04:30,956 Epoch[35] Batch [850]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.103581,	
2017-08-04 02:05:01,239 Epoch[35] Batch [860]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.103639,	
2017-08-04 02:05:31,231 Epoch[35] Batch [870]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.103640,	
2017-08-04 02:06:09,738 Epoch[35] Batch [880]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.103578,	
2017-08-04 02:06:40,683 Epoch[35] Batch [890]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.103549,	
2017-08-04 02:07:13,335 Epoch[35] Batch [900]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.103489,	
2017-08-04 02:07:43,335 Epoch[35] Batch [910]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.103364,	
2017-08-04 02:08:13,934 Epoch[35] Batch [920]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.103297,	
2017-08-04 02:08:44,246 Epoch[35] Batch [930]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.103269,	
2017-08-04 02:09:13,902 Epoch[35] Batch [940]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.103301,	
2017-08-04 02:09:41,491 Epoch[35] Batch [950]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.103245,	
2017-08-04 02:09:50,442 Epoch[35] Batch [960]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.103188,	
2017-08-04 02:09:59,026 Epoch[35] Batch [970]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.103228,	
2017-08-04 02:10:07,860 Epoch[35] Batch [980]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.103158,	
2017-08-04 02:10:16,611 Epoch[35] Batch [990]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.103170,	
2017-08-04 02:10:25,798 Epoch[35] Batch [1000]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.103047,	
2017-08-04 02:10:34,148 Epoch[35] Batch [1010]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.103028,	
2017-08-04 02:10:43,343 Epoch[35] Batch [1020]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.102969,	
2017-08-04 02:10:52,414 Epoch[35] Batch [1030]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.103062,	
2017-08-04 02:11:01,438 Epoch[35] Batch [1040]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.103068,	
2017-08-04 02:11:10,211 Epoch[35] Batch [1050]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.103012,	
2017-08-04 02:11:19,086 Epoch[35] Batch [1060]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.103061,	
2017-08-04 02:11:27,867 Epoch[35] Batch [1070]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.103015,	
2017-08-04 02:11:36,520 Epoch[35] Batch [1080]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.103084,	
2017-08-04 02:11:45,480 Epoch[35] Batch [1090]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.103085,	
2017-08-04 02:11:54,375 Epoch[35] Batch [1100]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.103079,	
2017-08-04 02:12:03,196 Epoch[35] Batch [1110]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.103010,	
2017-08-04 02:12:12,701 Epoch[35] Batch [1120]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.103080,	
2017-08-04 02:12:21,374 Epoch[35] Batch [1130]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.103073,	
2017-08-04 02:12:30,682 Epoch[35] Batch [1140]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.103119,	
2017-08-04 02:12:40,186 Epoch[35] Batch [1150]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.103202,	
2017-08-04 02:12:49,045 Epoch[35] Batch [1160]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.103284,	
2017-08-04 02:12:57,998 Epoch[35] Batch [1170]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.103271,	
2017-08-04 02:13:07,858 Epoch[35] Batch [1180]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.103245,	
2017-08-04 02:13:17,772 Epoch[35] Batch [1190]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.103274,	
2017-08-04 02:13:26,853 Epoch[35] Batch [1200]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.103219,	
2017-08-04 02:13:35,616 Epoch[35] Batch [1210]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.103206,	
2017-08-04 02:13:44,469 Epoch[35] Batch [1220]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.103135,	
2017-08-04 02:13:53,580 Epoch[35] Batch [1230]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.103057,	
2017-08-04 02:14:02,643 Epoch[35] Batch [1240]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.103082,	
2017-08-04 02:14:11,415 Epoch[35] Batch [1250]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.103141,	
2017-08-04 02:14:20,728 Epoch[35] Batch [1260]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.103037,	
2017-08-04 02:14:29,790 Epoch[35] Batch [1270]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.102981,	
2017-08-04 02:14:38,882 Epoch[35] Batch [1280]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.102977,	
2017-08-04 02:14:47,696 Epoch[35] Batch [1290]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.102969,	
2017-08-04 02:14:56,997 Epoch[35] Batch [1300]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.102834,	
2017-08-04 02:15:05,694 Epoch[35] Batch [1310]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.102882,	
2017-08-04 02:15:14,737 Epoch[35] Batch [1320]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.102873,	
2017-08-04 02:15:23,944 Epoch[35] Batch [1330]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.102845,	
2017-08-04 02:15:32,830 Epoch[35] Batch [1340]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.102886,	
2017-08-04 02:15:41,690 Epoch[35] Batch [1350]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.102882,	
2017-08-04 02:15:50,781 Epoch[35] Batch [1360]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.102887,	
2017-08-04 02:15:59,687 Epoch[35] Batch [1370]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.102793,	
2017-08-04 02:16:25,942 Epoch[35] Batch [1380]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.102922,	
2017-08-04 02:16:54,945 Epoch[35] Batch [1390]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.102964,	
2017-08-04 02:17:29,458 Epoch[35] Batch [1400]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.102983,	
2017-08-04 02:18:01,003 Epoch[35] Batch [1410]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.103382,	
2017-08-04 02:18:34,141 Epoch[35] Batch [1420]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.103362,	
2017-08-04 02:19:06,247 Epoch[35] Batch [1430]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.103376,	
2017-08-04 02:19:38,989 Epoch[35] Batch [1440]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.103334,	
2017-08-04 02:20:10,266 Epoch[35] Batch [1450]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.103363,	
2017-08-04 02:20:44,931 Epoch[35] Batch [1460]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.103273,	
2017-08-04 02:21:22,755 Epoch[35] Batch [1470]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.103295,	
2017-08-04 02:22:01,064 Epoch[35] Batch [1480]	Speed: 1.04 samples/sec	Train-FCNLogLoss=0.103383,	
2017-08-04 02:22:24,880 Epoch[35] Train-FCNLogLoss=0.103362
2017-08-04 02:22:24,880 Epoch[35] Time cost=3751.365
2017-08-04 02:22:27,663 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0036.params"
2017-08-04 02:22:49,715 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0036.states"
2017-08-04 02:23:29,666 Epoch[36] Batch [10]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.108087,	
2017-08-04 02:24:09,818 Epoch[36] Batch [20]	Speed: 1.00 samples/sec	Train-FCNLogLoss=0.101517,	
2017-08-04 02:24:47,945 Epoch[36] Batch [30]	Speed: 1.05 samples/sec	Train-FCNLogLoss=0.099542,	
2017-08-04 02:25:25,061 Epoch[36] Batch [40]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.099285,	
2017-08-04 02:26:02,026 Epoch[36] Batch [50]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.098571,	
2017-08-04 02:26:33,945 Epoch[36] Batch [60]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.097898,	
2017-08-04 02:27:04,591 Epoch[36] Batch [70]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.096659,	
2017-08-04 02:27:36,457 Epoch[36] Batch [80]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.097802,	
2017-08-04 02:28:08,977 Epoch[36] Batch [90]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100296,	
2017-08-04 02:28:43,925 Epoch[36] Batch [100]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.101871,	
2017-08-04 02:29:15,198 Epoch[36] Batch [110]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.103294,	
2017-08-04 02:29:44,271 Epoch[36] Batch [120]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.103660,	
2017-08-04 02:30:13,887 Epoch[36] Batch [130]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.104239,	
2017-08-04 02:30:41,461 Epoch[36] Batch [140]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.103565,	
2017-08-04 02:31:12,314 Epoch[36] Batch [150]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.103737,	
2017-08-04 02:31:43,048 Epoch[36] Batch [160]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.104706,	
2017-08-04 02:32:13,597 Epoch[36] Batch [170]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.104297,	
2017-08-04 02:32:45,451 Epoch[36] Batch [180]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.104468,	
2017-08-04 02:33:20,648 Epoch[36] Batch [190]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.104589,	
2017-08-04 02:33:50,085 Epoch[36] Batch [200]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.104348,	
2017-08-04 02:34:17,647 Epoch[36] Batch [210]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.103783,	
2017-08-04 02:34:50,338 Epoch[36] Batch [220]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.103724,	
2017-08-04 02:35:23,945 Epoch[36] Batch [230]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.103755,	
2017-08-04 02:35:54,290 Epoch[36] Batch [240]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.103451,	
2017-08-04 02:36:22,323 Epoch[36] Batch [250]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.102797,	
2017-08-04 02:36:53,181 Epoch[36] Batch [260]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102892,	
2017-08-04 02:37:24,073 Epoch[36] Batch [270]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102332,	
2017-08-04 02:37:53,953 Epoch[36] Batch [280]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.102260,	
2017-08-04 02:38:25,454 Epoch[36] Batch [290]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.102473,	
2017-08-04 02:38:57,047 Epoch[36] Batch [300]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.102353,	
2017-08-04 02:39:27,475 Epoch[36] Batch [310]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102587,	
2017-08-04 02:39:56,059 Epoch[36] Batch [320]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.102223,	
2017-08-04 02:40:29,707 Epoch[36] Batch [330]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.102345,	
2017-08-04 02:40:59,592 Epoch[36] Batch [340]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.102421,	
2017-08-04 02:41:30,220 Epoch[36] Batch [350]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102371,	
2017-08-04 02:42:00,140 Epoch[36] Batch [360]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.102576,	
2017-08-04 02:42:30,241 Epoch[36] Batch [370]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.102364,	
2017-08-04 02:43:01,238 Epoch[36] Batch [380]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102253,	
2017-08-04 02:43:32,319 Epoch[36] Batch [390]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102285,	
2017-08-04 02:44:02,153 Epoch[36] Batch [400]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.102323,	
2017-08-04 02:44:31,100 Epoch[36] Batch [410]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.102146,	
2017-08-04 02:45:05,112 Epoch[36] Batch [420]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.102207,	
2017-08-04 02:45:36,175 Epoch[36] Batch [430]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102351,	
2017-08-04 02:46:05,231 Epoch[36] Batch [440]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.102369,	
2017-08-04 02:46:37,247 Epoch[36] Batch [450]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.102498,	
2017-08-04 02:47:11,033 Epoch[36] Batch [460]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.102513,	
2017-08-04 02:47:41,122 Epoch[36] Batch [470]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.102324,	
2017-08-04 02:48:11,758 Epoch[36] Batch [480]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102103,	
2017-08-04 02:48:43,516 Epoch[36] Batch [490]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.102004,	
2017-08-04 02:49:14,622 Epoch[36] Batch [500]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101785,	
2017-08-04 02:49:50,056 Epoch[36] Batch [510]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.101580,	
2017-08-04 02:50:18,923 Epoch[36] Batch [520]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.101514,	
2017-08-04 02:50:54,574 Epoch[36] Batch [530]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.101380,	
2017-08-04 02:51:28,585 Epoch[36] Batch [540]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101435,	
2017-08-04 02:51:59,027 Epoch[36] Batch [550]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101351,	
2017-08-04 02:52:29,313 Epoch[36] Batch [560]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.101457,	
2017-08-04 02:53:01,254 Epoch[36] Batch [570]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101587,	
2017-08-04 02:53:31,781 Epoch[36] Batch [580]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101645,	
2017-08-04 02:54:04,915 Epoch[36] Batch [590]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101441,	
2017-08-04 02:54:36,435 Epoch[36] Batch [600]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101490,	
2017-08-04 02:55:06,155 Epoch[36] Batch [610]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101440,	
2017-08-04 02:55:43,451 Epoch[36] Batch [620]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.101504,	
2017-08-04 02:56:16,757 Epoch[36] Batch [630]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101329,	
2017-08-04 02:56:48,618 Epoch[36] Batch [640]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101197,	
2017-08-04 02:57:21,251 Epoch[36] Batch [650]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101168,	
2017-08-04 02:57:51,883 Epoch[36] Batch [660]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101154,	
2017-08-04 02:58:26,264 Epoch[36] Batch [670]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.101118,	
2017-08-04 02:59:05,271 Epoch[36] Batch [680]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.101173,	
2017-08-04 02:59:44,752 Epoch[36] Batch [690]	Speed: 1.01 samples/sec	Train-FCNLogLoss=0.101075,	
2017-08-04 03:00:25,393 Epoch[36] Batch [700]	Speed: 0.98 samples/sec	Train-FCNLogLoss=0.101217,	
2017-08-04 03:01:02,229 Epoch[36] Batch [710]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.101379,	
2017-08-04 03:01:34,208 Epoch[36] Batch [720]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101221,	
2017-08-04 03:02:06,663 Epoch[36] Batch [730]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101210,	
2017-08-04 03:02:38,275 Epoch[36] Batch [740]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101263,	
2017-08-04 03:03:07,806 Epoch[36] Batch [750]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101380,	
2017-08-04 03:03:42,307 Epoch[36] Batch [760]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.101243,	
2017-08-04 03:04:13,791 Epoch[36] Batch [770]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101296,	
2017-08-04 03:04:45,676 Epoch[36] Batch [780]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101300,	
2017-08-04 03:05:19,711 Epoch[36] Batch [790]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101353,	
2017-08-04 03:05:57,251 Epoch[36] Batch [800]	Speed: 1.07 samples/sec	Train-FCNLogLoss=0.101621,	
2017-08-04 03:06:34,145 Epoch[36] Batch [810]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.101727,	
2017-08-04 03:07:07,455 Epoch[36] Batch [820]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101705,	
2017-08-04 03:07:39,878 Epoch[36] Batch [830]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101857,	
2017-08-04 03:08:10,254 Epoch[36] Batch [840]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.101951,	
2017-08-04 03:08:40,155 Epoch[36] Batch [850]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101897,	
2017-08-04 03:09:14,136 Epoch[36] Batch [860]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101923,	
2017-08-04 03:09:47,253 Epoch[36] Batch [870]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101955,	
2017-08-04 03:10:20,552 Epoch[36] Batch [880]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101907,	
2017-08-04 03:10:49,770 Epoch[36] Batch [890]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.101905,	
2017-08-04 03:11:19,587 Epoch[36] Batch [900]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101928,	
2017-08-04 03:11:49,299 Epoch[36] Batch [910]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101847,	
2017-08-04 03:12:22,799 Epoch[36] Batch [920]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.101759,	
2017-08-04 03:12:52,057 Epoch[36] Batch [930]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.101738,	
2017-08-04 03:13:26,292 Epoch[36] Batch [940]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.101556,	
2017-08-04 03:14:00,677 Epoch[36] Batch [950]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.101514,	
2017-08-04 03:14:30,451 Epoch[36] Batch [960]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101587,	
2017-08-04 03:15:03,824 Epoch[36] Batch [970]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101698,	
2017-08-04 03:15:37,634 Epoch[36] Batch [980]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101753,	
2017-08-04 03:16:11,353 Epoch[36] Batch [990]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.101762,	
2017-08-04 03:16:43,610 Epoch[36] Batch [1000]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101737,	
2017-08-04 03:17:16,000 Epoch[36] Batch [1010]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101780,	
2017-08-04 03:17:45,624 Epoch[36] Batch [1020]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101840,	
2017-08-04 03:18:20,205 Epoch[36] Batch [1030]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.101900,	
2017-08-04 03:18:54,422 Epoch[36] Batch [1040]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.101923,	
2017-08-04 03:19:23,708 Epoch[36] Batch [1050]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.101893,	
2017-08-04 03:19:54,423 Epoch[36] Batch [1060]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.101913,	
2017-08-04 03:20:30,583 Epoch[36] Batch [1070]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.102033,	
2017-08-04 03:21:05,522 Epoch[36] Batch [1080]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.102084,	
2017-08-04 03:21:34,105 Epoch[36] Batch [1090]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.102052,	
2017-08-04 03:22:02,348 Epoch[36] Batch [1100]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.101973,	
2017-08-04 03:22:33,114 Epoch[36] Batch [1110]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.101931,	
2017-08-04 03:23:05,360 Epoch[36] Batch [1120]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101917,	
2017-08-04 03:23:34,704 Epoch[36] Batch [1130]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.101994,	
2017-08-04 03:24:04,707 Epoch[36] Batch [1140]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101927,	
2017-08-04 03:24:34,287 Epoch[36] Batch [1150]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101890,	
2017-08-04 03:25:04,898 Epoch[36] Batch [1160]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101829,	
2017-08-04 03:25:38,817 Epoch[36] Batch [1170]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101889,	
2017-08-04 03:26:09,923 Epoch[36] Batch [1180]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101961,	
2017-08-04 03:26:37,440 Epoch[36] Batch [1190]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.101935,	
2017-08-04 03:27:06,362 Epoch[36] Batch [1200]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.102002,	
2017-08-04 03:27:37,424 Epoch[36] Batch [1210]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102044,	
2017-08-04 03:28:09,797 Epoch[36] Batch [1220]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.102026,	
2017-08-04 03:28:43,378 Epoch[36] Batch [1230]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.102066,	
2017-08-04 03:29:14,051 Epoch[36] Batch [1240]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.102026,	
2017-08-04 03:29:46,998 Epoch[36] Batch [1250]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101985,	
2017-08-04 03:30:15,002 Epoch[36] Batch [1260]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.101886,	
2017-08-04 03:30:47,339 Epoch[36] Batch [1270]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101858,	
2017-08-04 03:31:20,051 Epoch[36] Batch [1280]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.101881,	
2017-08-04 03:31:50,077 Epoch[36] Batch [1290]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101855,	
2017-08-04 03:32:20,108 Epoch[36] Batch [1300]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101876,	
2017-08-04 03:32:51,096 Epoch[36] Batch [1310]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101924,	
2017-08-04 03:33:20,369 Epoch[36] Batch [1320]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.101976,	
2017-08-04 03:33:48,755 Epoch[36] Batch [1330]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.101950,	
2017-08-04 03:34:19,150 Epoch[36] Batch [1340]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.101860,	
2017-08-04 03:34:49,752 Epoch[36] Batch [1350]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.101847,	
2017-08-04 03:35:20,015 Epoch[36] Batch [1360]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.101886,	
2017-08-04 03:35:52,961 Epoch[36] Batch [1370]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.101861,	
2017-08-04 03:36:22,787 Epoch[36] Batch [1380]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101897,	
2017-08-04 03:36:54,217 Epoch[36] Batch [1390]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.101945,	
2017-08-04 03:37:32,973 Epoch[36] Batch [1400]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.101892,	
2017-08-04 03:38:11,644 Epoch[36] Batch [1410]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.101840,	
2017-08-04 03:38:42,022 Epoch[36] Batch [1420]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.101879,	
2017-08-04 03:39:16,236 Epoch[36] Batch [1430]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.101850,	
2017-08-04 03:39:48,572 Epoch[36] Batch [1440]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101842,	
2017-08-04 03:40:18,631 Epoch[36] Batch [1450]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101849,	
2017-08-04 03:40:48,990 Epoch[36] Batch [1460]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.101793,	
2017-08-04 03:41:21,472 Epoch[36] Batch [1470]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101869,	
2017-08-04 03:41:53,627 Epoch[36] Batch [1480]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101850,	
2017-08-04 03:42:13,899 Epoch[36] Train-FCNLogLoss=0.101853
2017-08-04 03:42:13,900 Epoch[36] Time cost=4764.184
2017-08-04 03:42:17,934 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0037.params"
2017-08-04 03:42:40,485 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0037.states"
2017-08-04 03:43:17,810 Epoch[37] Batch [10]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.093803,	
2017-08-04 03:43:49,715 Epoch[37] Batch [20]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.096497,	
2017-08-04 03:44:19,200 Epoch[37] Batch [30]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.098479,	
2017-08-04 03:44:50,357 Epoch[37] Batch [40]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.101361,	
2017-08-04 03:45:25,068 Epoch[37] Batch [50]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.099274,	
2017-08-04 03:45:58,080 Epoch[37] Batch [60]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.098078,	
2017-08-04 03:46:26,630 Epoch[37] Batch [70]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.096760,	
2017-08-04 03:46:57,661 Epoch[37] Batch [80]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.096367,	
2017-08-04 03:47:29,447 Epoch[37] Batch [90]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.095791,	
2017-08-04 03:48:00,687 Epoch[37] Batch [100]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.096482,	
2017-08-04 03:48:29,979 Epoch[37] Batch [110]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.096736,	
2017-08-04 03:48:59,889 Epoch[37] Batch [120]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.097708,	
2017-08-04 03:49:32,193 Epoch[37] Batch [130]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.098097,	
2017-08-04 03:50:03,770 Epoch[37] Batch [140]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.098526,	
2017-08-04 03:50:41,554 Epoch[37] Batch [150]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.098279,	
2017-08-04 03:51:13,792 Epoch[37] Batch [160]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.097948,	
2017-08-04 03:51:42,807 Epoch[37] Batch [170]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.098191,	
2017-08-04 03:52:16,452 Epoch[37] Batch [180]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.098406,	
2017-08-04 03:52:47,436 Epoch[37] Batch [190]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.098732,	
2017-08-04 03:53:17,982 Epoch[37] Batch [200]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.098991,	
2017-08-04 03:53:52,604 Epoch[37] Batch [210]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.099988,	
2017-08-04 03:54:31,577 Epoch[37] Batch [220]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.100142,	
2017-08-04 03:55:06,052 Epoch[37] Batch [230]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.100690,	
2017-08-04 03:55:37,904 Epoch[37] Batch [240]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.100677,	
2017-08-04 03:56:08,734 Epoch[37] Batch [250]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.100968,	
2017-08-04 03:56:38,116 Epoch[37] Batch [260]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.100858,	
2017-08-04 03:57:09,740 Epoch[37] Batch [270]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.100393,	
2017-08-04 03:57:44,835 Epoch[37] Batch [280]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.100579,	
2017-08-04 03:58:17,906 Epoch[37] Batch [290]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.100644,	
2017-08-04 03:58:48,389 Epoch[37] Batch [300]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.100473,	
2017-08-04 03:59:20,544 Epoch[37] Batch [310]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.100873,	
2017-08-04 03:59:53,956 Epoch[37] Batch [320]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101124,	
2017-08-04 04:00:28,497 Epoch[37] Batch [330]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.101292,	
2017-08-04 04:01:03,800 Epoch[37] Batch [340]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.101195,	
2017-08-04 04:01:39,413 Epoch[37] Batch [350]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.101546,	
2017-08-04 04:02:12,615 Epoch[37] Batch [360]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.101606,	
2017-08-04 04:02:44,609 Epoch[37] Batch [370]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101331,	
2017-08-04 04:03:15,553 Epoch[37] Batch [380]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101420,	
2017-08-04 04:03:47,314 Epoch[37] Batch [390]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101270,	
2017-08-04 04:04:19,133 Epoch[37] Batch [400]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101126,	
2017-08-04 04:04:50,857 Epoch[37] Batch [410]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101053,	
2017-08-04 04:05:24,465 Epoch[37] Batch [420]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.100758,	
2017-08-04 04:05:55,486 Epoch[37] Batch [430]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.100732,	
2017-08-04 04:06:28,075 Epoch[37] Batch [440]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100968,	
2017-08-04 04:06:56,395 Epoch[37] Batch [450]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.101086,	
2017-08-04 04:07:31,036 Epoch[37] Batch [460]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.100968,	
2017-08-04 04:08:01,847 Epoch[37] Batch [470]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.100798,	
2017-08-04 04:08:33,100 Epoch[37] Batch [480]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.100877,	
2017-08-04 04:09:02,639 Epoch[37] Batch [490]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.101169,	
2017-08-04 04:09:34,530 Epoch[37] Batch [500]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101228,	
2017-08-04 04:10:06,163 Epoch[37] Batch [510]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101144,	
2017-08-04 04:10:40,356 Epoch[37] Batch [520]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.101111,	
2017-08-04 04:11:14,349 Epoch[37] Batch [530]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.101075,	
2017-08-04 04:11:46,873 Epoch[37] Batch [540]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100916,	
2017-08-04 04:12:22,726 Epoch[37] Batch [550]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.100905,	
2017-08-04 04:12:53,263 Epoch[37] Batch [560]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.100666,	
2017-08-04 04:13:25,546 Epoch[37] Batch [570]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.100434,	
2017-08-04 04:14:01,821 Epoch[37] Batch [580]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.100376,	
2017-08-04 04:14:41,251 Epoch[37] Batch [590]	Speed: 1.01 samples/sec	Train-FCNLogLoss=0.100218,	
2017-08-04 04:15:15,854 Epoch[37] Batch [600]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.100234,	
2017-08-04 04:15:50,050 Epoch[37] Batch [610]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.100284,	
2017-08-04 04:16:22,967 Epoch[37] Batch [620]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.100236,	
2017-08-04 04:16:53,269 Epoch[37] Batch [630]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.100108,	
2017-08-04 04:17:26,788 Epoch[37] Batch [640]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.100102,	
2017-08-04 04:18:02,638 Epoch[37] Batch [650]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.100168,	
2017-08-04 04:18:38,848 Epoch[37] Batch [660]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.100199,	
2017-08-04 04:19:15,373 Epoch[37] Batch [670]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.100217,	
2017-08-04 04:19:41,842 Epoch[37] Batch [680]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.100309,	
2017-08-04 04:20:08,838 Epoch[37] Batch [690]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.100367,	
2017-08-04 04:20:41,605 Epoch[37] Batch [700]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.100417,	
2017-08-04 04:21:08,157 Epoch[37] Batch [710]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.100303,	
2017-08-04 04:21:40,793 Epoch[37] Batch [720]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100201,	
2017-08-04 04:22:13,340 Epoch[37] Batch [730]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100327,	
2017-08-04 04:22:47,181 Epoch[37] Batch [740]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.100361,	
2017-08-04 04:23:20,302 Epoch[37] Batch [750]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.100494,	
2017-08-04 04:23:55,436 Epoch[37] Batch [760]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.100659,	
2017-08-04 04:24:26,277 Epoch[37] Batch [770]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.100703,	
2017-08-04 04:24:53,612 Epoch[37] Batch [780]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.100753,	
2017-08-04 04:25:18,551 Epoch[37] Batch [790]	Speed: 1.60 samples/sec	Train-FCNLogLoss=0.100912,	
2017-08-04 04:25:46,551 Epoch[37] Batch [800]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.100801,	
2017-08-04 04:26:14,233 Epoch[37] Batch [810]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.100812,	
2017-08-04 04:26:41,057 Epoch[37] Batch [820]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.100928,	
2017-08-04 04:27:16,125 Epoch[37] Batch [830]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.101077,	
2017-08-04 04:27:50,805 Epoch[37] Batch [840]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.101120,	
2017-08-04 04:28:27,967 Epoch[37] Batch [850]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.101101,	
2017-08-04 04:28:57,212 Epoch[37] Batch [860]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.101012,	
2017-08-04 04:29:30,998 Epoch[37] Batch [870]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.100953,	
2017-08-04 04:30:00,367 Epoch[37] Batch [880]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.100899,	
2017-08-04 04:30:28,546 Epoch[37] Batch [890]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.100922,	
2017-08-04 04:31:00,071 Epoch[37] Batch [900]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.100853,	
2017-08-04 04:31:30,275 Epoch[37] Batch [910]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.100904,	
2017-08-04 04:31:58,975 Epoch[37] Batch [920]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.100856,	
2017-08-04 04:32:31,173 Epoch[37] Batch [930]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.100899,	
2017-08-04 04:33:05,173 Epoch[37] Batch [940]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.100800,	
2017-08-04 04:33:36,782 Epoch[37] Batch [950]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.100716,	
2017-08-04 04:34:14,667 Epoch[37] Batch [960]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.100543,	
2017-08-04 04:34:47,819 Epoch[37] Batch [970]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.100606,	
2017-08-04 04:35:20,242 Epoch[37] Batch [980]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100614,	
2017-08-04 04:35:46,735 Epoch[37] Batch [990]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.100601,	
2017-08-04 04:36:11,845 Epoch[37] Batch [1000]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.100643,	
2017-08-04 04:36:39,097 Epoch[37] Batch [1010]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.100589,	
2017-08-04 04:37:05,152 Epoch[37] Batch [1020]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.100760,	
2017-08-04 04:37:33,796 Epoch[37] Batch [1030]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.100711,	
2017-08-04 04:38:03,484 Epoch[37] Batch [1040]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.100711,	
2017-08-04 04:38:34,147 Epoch[37] Batch [1050]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.100776,	
2017-08-04 04:39:06,158 Epoch[37] Batch [1060]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.100723,	
2017-08-04 04:39:37,788 Epoch[37] Batch [1070]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.100701,	
2017-08-04 04:40:07,222 Epoch[37] Batch [1080]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.100564,	
2017-08-04 04:40:39,256 Epoch[37] Batch [1090]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.100543,	
2017-08-04 04:41:12,472 Epoch[37] Batch [1100]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.100573,	
2017-08-04 04:41:44,022 Epoch[37] Batch [1110]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.100533,	
2017-08-04 04:42:12,925 Epoch[37] Batch [1120]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.100584,	
2017-08-04 04:42:43,106 Epoch[37] Batch [1130]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.100646,	
2017-08-04 04:43:17,557 Epoch[37] Batch [1140]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.100675,	
2017-08-04 04:43:50,703 Epoch[37] Batch [1150]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.100737,	
2017-08-04 04:44:21,433 Epoch[37] Batch [1160]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.100795,	
2017-08-04 04:44:53,809 Epoch[37] Batch [1170]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.100867,	
2017-08-04 04:45:23,444 Epoch[37] Batch [1180]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.100870,	
2017-08-04 04:46:00,489 Epoch[37] Batch [1190]	Speed: 1.08 samples/sec	Train-FCNLogLoss=0.100914,	
2017-08-04 04:46:27,476 Epoch[37] Batch [1200]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.101036,	
2017-08-04 04:46:50,766 Epoch[37] Batch [1210]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.100956,	
2017-08-04 04:47:16,364 Epoch[37] Batch [1220]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.100925,	
2017-08-04 04:47:43,769 Epoch[37] Batch [1230]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.100827,	
2017-08-04 04:48:15,556 Epoch[37] Batch [1240]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.100863,	
2017-08-04 04:48:47,001 Epoch[37] Batch [1250]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.100886,	
2017-08-04 04:49:25,891 Epoch[37] Batch [1260]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.100836,	
2017-08-04 04:50:05,384 Epoch[37] Batch [1270]	Speed: 1.01 samples/sec	Train-FCNLogLoss=0.100758,	
2017-08-04 04:50:43,172 Epoch[37] Batch [1280]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.100686,	
2017-08-04 04:51:19,815 Epoch[37] Batch [1290]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.100659,	
2017-08-04 04:51:50,029 Epoch[37] Batch [1300]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.100654,	
2017-08-04 04:52:22,441 Epoch[37] Batch [1310]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.100681,	
2017-08-04 04:52:59,196 Epoch[37] Batch [1320]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.100615,	
2017-08-04 04:53:33,564 Epoch[37] Batch [1330]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.100670,	
2017-08-04 04:54:04,579 Epoch[37] Batch [1340]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.100756,	
2017-08-04 04:54:35,551 Epoch[37] Batch [1350]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.100768,	
2017-08-04 04:55:05,325 Epoch[37] Batch [1360]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.100801,	
2017-08-04 04:55:38,633 Epoch[37] Batch [1370]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.100843,	
2017-08-04 04:56:11,758 Epoch[37] Batch [1380]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.100840,	
2017-08-04 04:56:47,365 Epoch[37] Batch [1390]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.100785,	
2017-08-04 04:57:15,737 Epoch[37] Batch [1400]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.100802,	
2017-08-04 04:57:46,544 Epoch[37] Batch [1410]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.100880,	
2017-08-04 04:58:12,364 Epoch[37] Batch [1420]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.100891,	
2017-08-04 04:58:40,218 Epoch[37] Batch [1430]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.100843,	
2017-08-04 04:59:14,023 Epoch[37] Batch [1440]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.100849,	
2017-08-04 04:59:45,267 Epoch[37] Batch [1450]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.101135,	
2017-08-04 05:00:17,034 Epoch[37] Batch [1460]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101163,	
2017-08-04 05:00:47,003 Epoch[37] Batch [1470]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101183,	
2017-08-04 05:01:19,438 Epoch[37] Batch [1480]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101226,	
2017-08-04 05:01:36,975 Epoch[37] Train-FCNLogLoss=0.101219
2017-08-04 05:01:36,976 Epoch[37] Time cost=4736.490
2017-08-04 05:01:39,768 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0038.params"
2017-08-04 05:02:02,178 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0038.states"
2017-08-04 05:02:35,108 Epoch[38] Batch [10]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.100173,	
2017-08-04 05:03:05,791 Epoch[38] Batch [20]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.096897,	
2017-08-04 05:03:35,305 Epoch[38] Batch [30]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.101297,	
2017-08-04 05:04:05,146 Epoch[38] Batch [40]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101085,	
2017-08-04 05:04:34,536 Epoch[38] Batch [50]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.100506,	
2017-08-04 05:05:02,514 Epoch[38] Batch [60]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.099305,	
2017-08-04 05:05:35,435 Epoch[38] Batch [70]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.098124,	
2017-08-04 05:06:07,427 Epoch[38] Batch [80]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.098215,	
2017-08-04 05:06:36,599 Epoch[38] Batch [90]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.099372,	
2017-08-04 05:07:11,306 Epoch[38] Batch [100]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.099893,	
2017-08-04 05:07:43,396 Epoch[38] Batch [110]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.099546,	
2017-08-04 05:08:16,112 Epoch[38] Batch [120]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.099506,	
2017-08-04 05:08:45,660 Epoch[38] Batch [130]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.099369,	
2017-08-04 05:09:21,601 Epoch[38] Batch [140]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.099081,	
2017-08-04 05:09:56,669 Epoch[38] Batch [150]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.099094,	
2017-08-04 05:10:32,354 Epoch[38] Batch [160]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.099348,	
2017-08-04 05:11:04,457 Epoch[38] Batch [170]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.099318,	
2017-08-04 05:11:38,894 Epoch[38] Batch [180]	Speed: 1.16 samples/sec	Train-FCNLogLoss=0.099105,	
2017-08-04 05:12:10,254 Epoch[38] Batch [190]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.099255,	
2017-08-04 05:12:41,581 Epoch[38] Batch [200]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.099866,	
2017-08-04 05:13:08,688 Epoch[38] Batch [210]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.100281,	
2017-08-04 05:13:36,125 Epoch[38] Batch [220]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.099707,	
2017-08-04 05:14:00,577 Epoch[38] Batch [230]	Speed: 1.64 samples/sec	Train-FCNLogLoss=0.099549,	
2017-08-04 05:14:23,696 Epoch[38] Batch [240]	Speed: 1.73 samples/sec	Train-FCNLogLoss=0.099851,	
2017-08-04 05:14:51,602 Epoch[38] Batch [250]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.099841,	
2017-08-04 05:15:19,801 Epoch[38] Batch [260]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.099979,	
2017-08-04 05:15:45,663 Epoch[38] Batch [270]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.099795,	
2017-08-04 05:16:18,963 Epoch[38] Batch [280]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.099983,	
2017-08-04 05:16:48,968 Epoch[38] Batch [290]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.100354,	
2017-08-04 05:17:24,565 Epoch[38] Batch [300]	Speed: 1.12 samples/sec	Train-FCNLogLoss=0.101509,	
2017-08-04 05:17:55,531 Epoch[38] Batch [310]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101575,	
2017-08-04 05:18:27,818 Epoch[38] Batch [320]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101750,	
2017-08-04 05:19:00,545 Epoch[38] Batch [330]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.101865,	
2017-08-04 05:19:27,182 Epoch[38] Batch [340]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.101827,	
2017-08-04 05:19:54,564 Epoch[38] Batch [350]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.102352,	
2017-08-04 05:20:17,334 Epoch[38] Batch [360]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.102629,	
2017-08-04 05:20:45,733 Epoch[38] Batch [370]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.103100,	
2017-08-04 05:21:16,233 Epoch[38] Batch [380]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.103309,	
2017-08-04 05:21:45,562 Epoch[38] Batch [390]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.103633,	
2017-08-04 05:22:18,846 Epoch[38] Batch [400]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.103226,	
2017-08-04 05:22:52,021 Epoch[38] Batch [410]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.103539,	
2017-08-04 05:23:23,432 Epoch[38] Batch [420]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.103681,	
2017-08-04 05:23:57,007 Epoch[38] Batch [430]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.103444,	
2017-08-04 05:24:28,748 Epoch[38] Batch [440]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.103560,	
2017-08-04 05:24:56,168 Epoch[38] Batch [450]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.103419,	
2017-08-04 05:25:21,228 Epoch[38] Batch [460]	Speed: 1.60 samples/sec	Train-FCNLogLoss=0.103425,	
2017-08-04 05:25:47,982 Epoch[38] Batch [470]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.103363,	
2017-08-04 05:26:14,071 Epoch[38] Batch [480]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.103222,	
2017-08-04 05:26:40,755 Epoch[38] Batch [490]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.103245,	
2017-08-04 05:27:11,499 Epoch[38] Batch [500]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.103102,	
2017-08-04 05:27:41,437 Epoch[38] Batch [510]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.103531,	
2017-08-04 05:28:14,661 Epoch[38] Batch [520]	Speed: 1.20 samples/sec	Train-FCNLogLoss=0.103466,	
2017-08-04 05:28:49,906 Epoch[38] Batch [530]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.103369,	
2017-08-04 05:29:26,499 Epoch[38] Batch [540]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.103188,	
2017-08-04 05:29:59,215 Epoch[38] Batch [550]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.103064,	
2017-08-04 05:30:30,377 Epoch[38] Batch [560]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.103004,	
2017-08-04 05:30:57,523 Epoch[38] Batch [570]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.102942,	
2017-08-04 05:31:31,690 Epoch[38] Batch [580]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.102764,	
2017-08-04 05:32:01,725 Epoch[38] Batch [590]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.102828,	
2017-08-04 05:32:33,747 Epoch[38] Batch [600]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.102821,	
2017-08-04 05:33:02,741 Epoch[38] Batch [610]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.103356,	
2017-08-04 05:33:35,562 Epoch[38] Batch [620]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.103321,	
2017-08-04 05:34:05,831 Epoch[38] Batch [630]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.103339,	
2017-08-04 05:34:37,118 Epoch[38] Batch [640]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.103325,	
2017-08-04 05:35:09,406 Epoch[38] Batch [650]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.103244,	
2017-08-04 05:35:40,386 Epoch[38] Batch [660]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.103024,	
2017-08-04 05:36:09,985 Epoch[38] Batch [670]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.103081,	
2017-08-04 05:36:40,595 Epoch[38] Batch [680]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102957,	
2017-08-04 05:37:06,623 Epoch[38] Batch [690]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.103040,	
2017-08-04 05:37:35,890 Epoch[38] Batch [700]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.102980,	
2017-08-04 05:38:02,317 Epoch[38] Batch [710]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.102900,	
2017-08-04 05:38:35,195 Epoch[38] Batch [720]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.102906,	
2017-08-04 05:39:05,286 Epoch[38] Batch [730]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.102843,	
2017-08-04 05:39:36,423 Epoch[38] Batch [740]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.102643,	
2017-08-04 05:40:08,099 Epoch[38] Batch [750]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.102503,	
2017-08-04 05:40:38,650 Epoch[38] Batch [760]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102390,	
2017-08-04 05:41:17,377 Epoch[38] Batch [770]	Speed: 1.03 samples/sec	Train-FCNLogLoss=0.102330,	
2017-08-04 05:41:48,471 Epoch[38] Batch [780]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.102261,	
2017-08-04 05:42:18,466 Epoch[38] Batch [790]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.102109,	
2017-08-04 05:42:48,389 Epoch[38] Batch [800]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.102185,	
2017-08-04 05:43:18,817 Epoch[38] Batch [810]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.102192,	
2017-08-04 05:43:50,614 Epoch[38] Batch [820]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101978,	
2017-08-04 05:44:21,729 Epoch[38] Batch [830]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101873,	
2017-08-04 05:44:54,023 Epoch[38] Batch [840]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101830,	
2017-08-04 05:45:29,012 Epoch[38] Batch [850]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.101817,	
2017-08-04 05:46:08,384 Epoch[38] Batch [860]	Speed: 1.02 samples/sec	Train-FCNLogLoss=0.101893,	
2017-08-04 05:46:43,447 Epoch[38] Batch [870]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.101922,	
2017-08-04 05:47:19,572 Epoch[38] Batch [880]	Speed: 1.11 samples/sec	Train-FCNLogLoss=0.101853,	
2017-08-04 05:47:54,808 Epoch[38] Batch [890]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.101877,	
2017-08-04 05:48:32,450 Epoch[38] Batch [900]	Speed: 1.06 samples/sec	Train-FCNLogLoss=0.101939,	
2017-08-04 05:49:05,107 Epoch[38] Batch [910]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.101894,	
2017-08-04 05:49:41,544 Epoch[38] Batch [920]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.101849,	
2017-08-04 05:50:09,440 Epoch[38] Batch [930]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.101874,	
2017-08-04 05:50:36,585 Epoch[38] Batch [940]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.101845,	
2017-08-04 05:51:08,834 Epoch[38] Batch [950]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.101780,	
2017-08-04 05:51:38,589 Epoch[38] Batch [960]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101942,	
2017-08-04 05:52:11,031 Epoch[38] Batch [970]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.101910,	
2017-08-04 05:52:42,729 Epoch[38] Batch [980]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.101853,	
2017-08-04 05:53:10,049 Epoch[38] Batch [990]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.101803,	
2017-08-04 05:53:40,118 Epoch[38] Batch [1000]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.101806,	
2017-08-04 05:54:04,773 Epoch[38] Batch [1010]	Speed: 1.62 samples/sec	Train-FCNLogLoss=0.101832,	
2017-08-04 05:54:32,906 Epoch[38] Batch [1020]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.101908,	
2017-08-04 05:55:02,659 Epoch[38] Batch [1030]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.101990,	
2017-08-04 05:55:33,542 Epoch[38] Batch [1040]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.101928,	
2017-08-04 05:56:04,632 Epoch[38] Batch [1050]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.101825,	
2017-08-04 05:56:39,505 Epoch[38] Batch [1060]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.101765,	
2017-08-04 05:57:14,327 Epoch[38] Batch [1070]	Speed: 1.15 samples/sec	Train-FCNLogLoss=0.101730,	
2017-08-04 05:57:51,057 Epoch[38] Batch [1080]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.101741,	
2017-08-04 05:58:23,909 Epoch[38] Batch [1090]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.101689,	
2017-08-04 05:58:31,361 Epoch[38] Batch [1100]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.101805,	
2017-08-04 05:58:38,641 Epoch[38] Batch [1110]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.101772,	
2017-08-04 05:58:45,670 Epoch[38] Batch [1120]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.101724,	
2017-08-04 05:58:52,277 Epoch[38] Batch [1130]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.101651,	
2017-08-04 05:58:58,996 Epoch[38] Batch [1140]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.101703,	
2017-08-04 05:59:05,743 Epoch[38] Batch [1150]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.101819,	
2017-08-04 05:59:12,563 Epoch[38] Batch [1160]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.101878,	
2017-08-04 05:59:19,147 Epoch[38] Batch [1170]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.101885,	
2017-08-04 05:59:26,295 Epoch[38] Batch [1180]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.102028,	
2017-08-04 05:59:34,106 Epoch[38] Batch [1190]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.102050,	
2017-08-04 05:59:41,901 Epoch[38] Batch [1200]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.102085,	
2017-08-04 05:59:49,019 Epoch[38] Batch [1210]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.102085,	
2017-08-04 05:59:56,017 Epoch[38] Batch [1220]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.102190,	
2017-08-04 06:00:03,106 Epoch[38] Batch [1230]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.102149,	
2017-08-04 06:00:09,628 Epoch[38] Batch [1240]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.102126,	
2017-08-04 06:00:16,287 Epoch[38] Batch [1250]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.102171,	
2017-08-04 06:00:23,321 Epoch[38] Batch [1260]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.102241,	
2017-08-04 06:00:30,217 Epoch[38] Batch [1270]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.102326,	
2017-08-04 06:00:37,096 Epoch[38] Batch [1280]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.102351,	
2017-08-04 06:00:45,374 Epoch[38] Batch [1290]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.102420,	
2017-08-04 06:00:53,626 Epoch[38] Batch [1300]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.102565,	
2017-08-04 06:01:01,789 Epoch[38] Batch [1310]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.102573,	
2017-08-04 06:01:10,124 Epoch[38] Batch [1320]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.102541,	
2017-08-04 06:01:18,596 Epoch[38] Batch [1330]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.102505,	
2017-08-04 06:01:26,742 Epoch[38] Batch [1340]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.102464,	
2017-08-04 06:01:35,092 Epoch[38] Batch [1350]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.102469,	
2017-08-04 06:01:43,702 Epoch[38] Batch [1360]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.102556,	
2017-08-04 06:01:51,906 Epoch[38] Batch [1370]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.102580,	
2017-08-04 06:02:00,135 Epoch[38] Batch [1380]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.102631,	
2017-08-04 06:02:08,484 Epoch[38] Batch [1390]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.102586,	
2017-08-04 06:02:17,040 Epoch[38] Batch [1400]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.102526,	
2017-08-04 06:02:25,246 Epoch[38] Batch [1410]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.102550,	
2017-08-04 06:02:33,540 Epoch[38] Batch [1420]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.102592,	
2017-08-04 06:02:42,110 Epoch[38] Batch [1430]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.102574,	
2017-08-04 06:02:50,428 Epoch[38] Batch [1440]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.102681,	
2017-08-04 06:02:58,797 Epoch[38] Batch [1450]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.102665,	
2017-08-04 06:03:07,218 Epoch[38] Batch [1460]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.102683,	
2017-08-04 06:03:15,710 Epoch[38] Batch [1470]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.102653,	
2017-08-04 06:03:23,864 Epoch[38] Batch [1480]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.102587,	
2017-08-04 06:03:29,120 Epoch[38] Train-FCNLogLoss=0.102550
2017-08-04 06:03:29,120 Epoch[38] Time cost=3686.941
2017-08-04 06:03:29,974 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0039.params"
2017-08-04 06:03:33,425 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0039.states"
2017-08-04 06:03:43,364 Epoch[39] Batch [10]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.095312,	
2017-08-04 06:03:51,690 Epoch[39] Batch [20]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.095738,	
2017-08-04 06:04:00,053 Epoch[39] Batch [30]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.096372,	
2017-08-04 06:04:08,439 Epoch[39] Batch [40]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.096184,	
2017-08-04 06:04:18,116 Epoch[39] Batch [50]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.096816,	
2017-08-04 06:04:26,577 Epoch[39] Batch [60]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.096364,	
2017-08-04 06:04:35,072 Epoch[39] Batch [70]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.097129,	
2017-08-04 06:04:42,812 Epoch[39] Batch [80]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095949,	
2017-08-04 06:04:50,575 Epoch[39] Batch [90]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.096450,	
2017-08-04 06:04:58,574 Epoch[39] Batch [100]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.095903,	
2017-08-04 06:05:06,454 Epoch[39] Batch [110]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.097601,	
2017-08-04 06:05:14,208 Epoch[39] Batch [120]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.097754,	
2017-08-04 06:05:22,010 Epoch[39] Batch [130]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.097746,	
2017-08-04 06:05:29,476 Epoch[39] Batch [140]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.097513,	
2017-08-04 06:05:36,927 Epoch[39] Batch [150]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.097062,	
2017-08-04 06:05:44,730 Epoch[39] Batch [160]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096748,	
2017-08-04 06:05:52,234 Epoch[39] Batch [170]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.096616,	
2017-08-04 06:06:00,126 Epoch[39] Batch [180]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.097572,	
2017-08-04 06:06:08,174 Epoch[39] Batch [190]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.097697,	
2017-08-04 06:06:15,918 Epoch[39] Batch [200]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098083,	
2017-08-04 06:06:23,477 Epoch[39] Batch [210]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098039,	
2017-08-04 06:06:31,363 Epoch[39] Batch [220]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.098138,	
2017-08-04 06:06:39,214 Epoch[39] Batch [230]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098375,	
2017-08-04 06:06:47,091 Epoch[39] Batch [240]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.098598,	
2017-08-04 06:06:54,927 Epoch[39] Batch [250]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.098510,	
2017-08-04 06:07:01,008 Epoch[39] Batch [260]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098479,	
2017-08-04 06:07:06,420 Epoch[39] Batch [270]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.099140,	
2017-08-04 06:07:11,460 Epoch[39] Batch [280]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.099295,	
2017-08-04 06:07:16,422 Epoch[39] Batch [290]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.099273,	
2017-08-04 06:07:21,745 Epoch[39] Batch [300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099264,	
2017-08-04 06:07:26,996 Epoch[39] Batch [310]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.099244,	
2017-08-04 06:07:31,864 Epoch[39] Batch [320]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.099286,	
2017-08-04 06:07:37,117 Epoch[39] Batch [330]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099416,	
2017-08-04 06:07:42,437 Epoch[39] Batch [340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099486,	
2017-08-04 06:07:47,703 Epoch[39] Batch [350]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099346,	
2017-08-04 06:07:52,531 Epoch[39] Batch [360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.099393,	
2017-08-04 06:07:57,978 Epoch[39] Batch [370]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.099274,	
2017-08-04 06:08:03,597 Epoch[39] Batch [380]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.099327,	
2017-08-04 06:08:09,090 Epoch[39] Batch [390]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.099330,	
2017-08-04 06:08:14,588 Epoch[39] Batch [400]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.099616,	
2017-08-04 06:08:20,012 Epoch[39] Batch [410]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.099505,	
2017-08-04 06:08:24,681 Epoch[39] Batch [420]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.099421,	
2017-08-04 06:08:29,533 Epoch[39] Batch [430]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.099459,	
2017-08-04 06:08:35,125 Epoch[39] Batch [440]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099559,	
2017-08-04 06:08:40,488 Epoch[39] Batch [450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099667,	
2017-08-04 06:08:45,989 Epoch[39] Batch [460]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.099664,	
2017-08-04 06:08:51,199 Epoch[39] Batch [470]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.099553,	
2017-08-04 06:08:56,802 Epoch[39] Batch [480]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.099611,	
2017-08-04 06:09:01,907 Epoch[39] Batch [490]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099476,	
2017-08-04 06:09:06,746 Epoch[39] Batch [500]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.100048,	
2017-08-04 06:09:11,607 Epoch[39] Batch [510]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.099905,	
2017-08-04 06:09:16,415 Epoch[39] Batch [520]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.099778,	
2017-08-04 06:09:21,302 Epoch[39] Batch [530]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.099921,	
2017-08-04 06:09:26,047 Epoch[39] Batch [540]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099755,	
2017-08-04 06:09:30,714 Epoch[39] Batch [550]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.099608,	
2017-08-04 06:09:35,465 Epoch[39] Batch [560]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.099575,	
2017-08-04 06:09:40,399 Epoch[39] Batch [570]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.099486,	
2017-08-04 06:09:45,387 Epoch[39] Batch [580]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.099510,	
2017-08-04 06:09:50,663 Epoch[39] Batch [590]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099743,	
2017-08-04 06:09:55,715 Epoch[39] Batch [600]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.099620,	
2017-08-04 06:10:00,927 Epoch[39] Batch [610]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099742,	
2017-08-04 06:10:05,998 Epoch[39] Batch [620]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.099530,	
2017-08-04 06:10:10,877 Epoch[39] Batch [630]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.099579,	
2017-08-04 06:10:15,718 Epoch[39] Batch [640]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.099544,	
2017-08-04 06:10:21,057 Epoch[39] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.099819,	
2017-08-04 06:10:25,967 Epoch[39] Batch [660]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.099866,	
2017-08-04 06:10:30,969 Epoch[39] Batch [670]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.099893,	
2017-08-04 06:10:35,921 Epoch[39] Batch [680]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.099796,	
2017-08-04 06:10:41,022 Epoch[39] Batch [690]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.100170,	
2017-08-04 06:10:45,685 Epoch[39] Batch [700]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.100294,	
2017-08-04 06:10:51,075 Epoch[39] Batch [710]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.100469,	
2017-08-04 06:10:55,865 Epoch[39] Batch [720]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.100487,	
2017-08-04 06:11:00,505 Epoch[39] Batch [730]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.100372,	
2017-08-04 06:11:05,495 Epoch[39] Batch [740]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.100953,	
2017-08-04 06:11:10,245 Epoch[39] Batch [750]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.100991,	
2017-08-04 06:11:14,836 Epoch[39] Batch [760]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.101271,	
2017-08-04 06:11:19,838 Epoch[39] Batch [770]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.101230,	
2017-08-04 06:11:25,005 Epoch[39] Batch [780]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.101219,	
2017-08-04 06:11:29,928 Epoch[39] Batch [790]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.101164,	
2017-08-04 06:11:34,850 Epoch[39] Batch [800]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.101019,	
2017-08-04 06:11:39,976 Epoch[39] Batch [810]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.100998,	
2017-08-04 06:11:45,079 Epoch[39] Batch [820]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.101119,	
2017-08-04 06:11:49,974 Epoch[39] Batch [830]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.101253,	
2017-08-04 06:11:55,354 Epoch[39] Batch [840]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.101291,	
2017-08-04 06:12:00,688 Epoch[39] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101447,	
2017-08-04 06:12:05,836 Epoch[39] Batch [860]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.101446,	
2017-08-04 06:12:11,238 Epoch[39] Batch [870]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.101484,	
2017-08-04 06:12:16,528 Epoch[39] Batch [880]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.101513,	
2017-08-04 06:12:21,610 Epoch[39] Batch [890]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.101473,	
2017-08-04 06:12:27,227 Epoch[39] Batch [900]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101701,	
2017-08-04 06:12:32,621 Epoch[39] Batch [910]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.101757,	
2017-08-04 06:12:37,632 Epoch[39] Batch [920]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.101877,	
2017-08-04 06:12:43,238 Epoch[39] Batch [930]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.101961,	
2017-08-04 06:12:48,693 Epoch[39] Batch [940]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.102409,	
2017-08-04 06:12:54,041 Epoch[39] Batch [950]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102478,	
2017-08-04 06:13:00,286 Epoch[39] Batch [960]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.103249,	
2017-08-04 06:13:06,730 Epoch[39] Batch [970]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.103539,	
2017-08-04 06:13:12,326 Epoch[39] Batch [980]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.103812,	
2017-08-04 06:13:17,936 Epoch[39] Batch [990]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.104069,	
2017-08-04 06:13:23,086 Epoch[39] Batch [1000]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.104318,	
2017-08-04 06:13:28,083 Epoch[39] Batch [1010]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.104328,	
2017-08-04 06:13:33,490 Epoch[39] Batch [1020]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.104328,	
2017-08-04 06:13:38,465 Epoch[39] Batch [1030]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.104505,	
2017-08-04 06:13:43,895 Epoch[39] Batch [1040]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.104550,	
2017-08-04 06:13:49,755 Epoch[39] Batch [1050]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.104415,	
2017-08-04 06:13:55,786 Epoch[39] Batch [1060]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.104706,	
2017-08-04 06:14:01,730 Epoch[39] Batch [1070]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104684,	
2017-08-04 06:14:07,160 Epoch[39] Batch [1080]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.104787,	
2017-08-04 06:14:12,414 Epoch[39] Batch [1090]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.104802,	
2017-08-04 06:14:17,774 Epoch[39] Batch [1100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104843,	
2017-08-04 06:14:23,114 Epoch[39] Batch [1110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.104852,	
2017-08-04 06:14:27,868 Epoch[39] Batch [1120]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.104790,	
2017-08-04 06:14:32,911 Epoch[39] Batch [1130]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.104871,	
2017-08-04 06:14:37,705 Epoch[39] Batch [1140]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.105055,	
2017-08-04 06:14:42,572 Epoch[39] Batch [1150]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.105164,	
2017-08-04 06:14:47,687 Epoch[39] Batch [1160]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.105266,	
2017-08-04 06:14:52,730 Epoch[39] Batch [1170]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.105221,	
2017-08-04 06:14:57,648 Epoch[39] Batch [1180]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.105217,	
2017-08-04 06:15:02,658 Epoch[39] Batch [1190]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.105341,	
2017-08-04 06:15:08,145 Epoch[39] Batch [1200]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.105449,	
2017-08-04 06:15:13,677 Epoch[39] Batch [1210]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.105498,	
2017-08-04 06:15:18,979 Epoch[39] Batch [1220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.105426,	
2017-08-04 06:15:24,297 Epoch[39] Batch [1230]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105379,	
2017-08-04 06:15:29,711 Epoch[39] Batch [1240]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.105296,	
2017-08-04 06:15:34,951 Epoch[39] Batch [1250]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.105251,	
2017-08-04 06:15:39,915 Epoch[39] Batch [1260]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.105194,	
2017-08-04 06:15:45,543 Epoch[39] Batch [1270]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.105175,	
2017-08-04 06:15:51,089 Epoch[39] Batch [1280]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.105150,	
2017-08-04 06:15:56,482 Epoch[39] Batch [1290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.105118,	
2017-08-04 06:16:02,119 Epoch[39] Batch [1300]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.105106,	
2017-08-04 06:16:07,698 Epoch[39] Batch [1310]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.105198,	
2017-08-04 06:16:13,279 Epoch[39] Batch [1320]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.105330,	
2017-08-04 06:16:18,403 Epoch[39] Batch [1330]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.105298,	
2017-08-04 06:16:23,668 Epoch[39] Batch [1340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.105741,	
2017-08-04 06:16:29,311 Epoch[39] Batch [1350]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.105899,	
2017-08-04 06:16:35,382 Epoch[39] Batch [1360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106043,	
2017-08-04 06:16:40,919 Epoch[39] Batch [1370]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.106088,	
2017-08-04 06:16:46,390 Epoch[39] Batch [1380]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.106119,	
2017-08-04 06:16:52,689 Epoch[39] Batch [1390]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.106109,	
2017-08-04 06:16:58,645 Epoch[39] Batch [1400]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106057,	
2017-08-04 06:17:03,449 Epoch[39] Batch [1410]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.105970,	
2017-08-04 06:17:08,300 Epoch[39] Batch [1420]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.105932,	
2017-08-04 06:17:13,523 Epoch[39] Batch [1430]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105915,	
2017-08-04 06:17:18,595 Epoch[39] Batch [1440]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.105932,	
2017-08-04 06:17:23,950 Epoch[39] Batch [1450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105973,	
2017-08-04 06:17:29,029 Epoch[39] Batch [1460]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.106004,	
2017-08-04 06:17:34,028 Epoch[39] Batch [1470]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.106001,	
2017-08-04 06:17:38,741 Epoch[39] Batch [1480]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.106035,	
2017-08-04 06:17:41,921 Epoch[39] Train-FCNLogLoss=0.106011
2017-08-04 06:17:41,921 Epoch[39] Time cost=848.495
2017-08-04 06:17:43,230 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0040.params"
2017-08-04 06:17:47,330 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0040.states"
2017-08-04 06:17:53,855 Epoch[40] Batch [10]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.111564,	
2017-08-04 06:17:59,719 Epoch[40] Batch [20]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.104962,	
2017-08-04 06:18:05,551 Epoch[40] Batch [30]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105179,	
2017-08-04 06:18:11,330 Epoch[40] Batch [40]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106813,	
2017-08-04 06:18:17,171 Epoch[40] Batch [50]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103297,	
2017-08-04 06:18:22,621 Epoch[40] Batch [60]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.102143,	
2017-08-04 06:18:28,494 Epoch[40] Batch [70]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.100564,	
2017-08-04 06:18:34,448 Epoch[40] Batch [80]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.101438,	
2017-08-04 06:18:40,067 Epoch[40] Batch [90]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101035,	
2017-08-04 06:18:46,053 Epoch[40] Batch [100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.101377,	
2017-08-04 06:18:51,670 Epoch[40] Batch [110]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101744,	
2017-08-04 06:18:57,055 Epoch[40] Batch [120]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101799,	
2017-08-04 06:19:02,714 Epoch[40] Batch [130]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.102406,	
2017-08-04 06:19:08,157 Epoch[40] Batch [140]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.102178,	
2017-08-04 06:19:14,071 Epoch[40] Batch [150]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.102679,	
2017-08-04 06:19:19,716 Epoch[40] Batch [160]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.102657,	
2017-08-04 06:19:25,391 Epoch[40] Batch [170]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.102475,	
2017-08-04 06:19:30,784 Epoch[40] Batch [180]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.102232,	
2017-08-04 06:19:36,133 Epoch[40] Batch [190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.101461,	
2017-08-04 06:19:42,188 Epoch[40] Batch [200]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101060,	
2017-08-04 06:19:47,818 Epoch[40] Batch [210]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.100703,	
2017-08-04 06:19:53,655 Epoch[40] Batch [220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101069,	
2017-08-04 06:19:59,434 Epoch[40] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101106,	
2017-08-04 06:20:05,117 Epoch[40] Batch [240]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.101472,	
2017-08-04 06:20:10,683 Epoch[40] Batch [250]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.101443,	
2017-08-04 06:20:16,497 Epoch[40] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100997,	
2017-08-04 06:20:22,365 Epoch[40] Batch [270]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.100791,	
2017-08-04 06:20:28,086 Epoch[40] Batch [280]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.100967,	
2017-08-04 06:20:33,666 Epoch[40] Batch [290]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.100875,	
2017-08-04 06:20:39,133 Epoch[40] Batch [300]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.100892,	
2017-08-04 06:20:44,678 Epoch[40] Batch [310]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.100723,	
2017-08-04 06:20:50,238 Epoch[40] Batch [320]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.101169,	
2017-08-04 06:20:55,240 Epoch[40] Batch [330]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.101032,	
2017-08-04 06:21:00,617 Epoch[40] Batch [340]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.101076,	
2017-08-04 06:21:06,297 Epoch[40] Batch [350]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.100982,	
2017-08-04 06:21:11,966 Epoch[40] Batch [360]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.101164,	
2017-08-04 06:21:17,716 Epoch[40] Batch [370]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101321,	
2017-08-04 06:21:23,582 Epoch[40] Batch [380]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.101109,	
2017-08-04 06:21:29,048 Epoch[40] Batch [390]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.101206,	
2017-08-04 06:21:35,278 Epoch[40] Batch [400]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.101473,	
2017-08-04 06:21:40,995 Epoch[40] Batch [410]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101531,	
2017-08-04 06:21:46,385 Epoch[40] Batch [420]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.101531,	
2017-08-04 06:21:52,124 Epoch[40] Batch [430]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.101356,	
2017-08-04 06:21:57,822 Epoch[40] Batch [440]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.101335,	
2017-08-04 06:22:03,748 Epoch[40] Batch [450]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.101347,	
2017-08-04 06:22:09,160 Epoch[40] Batch [460]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.101286,	
2017-08-04 06:22:14,587 Epoch[40] Batch [470]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.101058,	
2017-08-04 06:22:20,257 Epoch[40] Batch [480]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.100990,	
2017-08-04 06:22:26,310 Epoch[40] Batch [490]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100768,	
2017-08-04 06:22:31,780 Epoch[40] Batch [500]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.100922,	
2017-08-04 06:22:36,460 Update[30250]: Change learning rate to 5.00000e-05
2017-08-04 06:22:37,370 Epoch[40] Batch [510]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.100945,	
2017-08-04 06:22:42,916 Epoch[40] Batch [520]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.100741,	
2017-08-04 06:22:48,520 Epoch[40] Batch [530]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.100641,	
2017-08-04 06:22:53,967 Epoch[40] Batch [540]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.100573,	
2017-08-04 06:22:59,585 Epoch[40] Batch [550]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.100485,	
2017-08-04 06:23:05,050 Epoch[40] Batch [560]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.100562,	
2017-08-04 06:23:10,612 Epoch[40] Batch [570]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.100491,	
2017-08-04 06:23:15,561 Epoch[40] Batch [580]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.100366,	
2017-08-04 06:23:21,230 Epoch[40] Batch [590]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.100394,	
2017-08-04 06:23:27,038 Epoch[40] Batch [600]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100371,	
2017-08-04 06:23:32,723 Epoch[40] Batch [610]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.100325,	
2017-08-04 06:23:38,197 Epoch[40] Batch [620]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.100050,	
2017-08-04 06:23:43,935 Epoch[40] Batch [630]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100169,	
2017-08-04 06:23:49,262 Epoch[40] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100163,	
2017-08-04 06:23:54,667 Epoch[40] Batch [650]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.100163,	
2017-08-04 06:24:00,255 Epoch[40] Batch [660]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.100191,	
2017-08-04 06:24:05,608 Epoch[40] Batch [670]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100466,	
2017-08-04 06:24:10,650 Epoch[40] Batch [680]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.100307,	
2017-08-04 06:24:15,593 Epoch[40] Batch [690]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.100270,	
2017-08-04 06:24:20,649 Epoch[40] Batch [700]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.100499,	
2017-08-04 06:24:26,794 Epoch[40] Batch [710]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.100362,	
2017-08-04 06:24:32,340 Epoch[40] Batch [720]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.100326,	
2017-08-04 06:24:37,750 Epoch[40] Batch [730]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.100278,	
2017-08-04 06:24:43,007 Epoch[40] Batch [740]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.100122,	
2017-08-04 06:24:48,711 Epoch[40] Batch [750]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.099933,	
2017-08-04 06:24:54,867 Epoch[40] Batch [760]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.099831,	
2017-08-04 06:25:01,235 Epoch[40] Batch [770]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.099761,	
2017-08-04 06:25:06,693 Epoch[40] Batch [780]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.099725,	
2017-08-04 06:25:12,286 Epoch[40] Batch [790]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099550,	
2017-08-04 06:25:18,032 Epoch[40] Batch [800]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099530,	
2017-08-04 06:25:23,511 Epoch[40] Batch [810]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.099572,	
2017-08-04 06:25:29,175 Epoch[40] Batch [820]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.099600,	
2017-08-04 06:25:34,434 Epoch[40] Batch [830]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099705,	
2017-08-04 06:25:39,565 Epoch[40] Batch [840]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.099750,	
2017-08-04 06:25:44,480 Epoch[40] Batch [850]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.099695,	
2017-08-04 06:25:49,588 Epoch[40] Batch [860]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.099652,	
2017-08-04 06:25:54,791 Epoch[40] Batch [870]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099700,	
2017-08-04 06:26:00,288 Epoch[40] Batch [880]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.099579,	
2017-08-04 06:26:05,607 Epoch[40] Batch [890]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099577,	
2017-08-04 06:26:11,907 Epoch[40] Batch [900]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.099531,	
2017-08-04 06:26:17,269 Epoch[40] Batch [910]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099509,	
2017-08-04 06:26:22,647 Epoch[40] Batch [920]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099451,	
2017-08-04 06:26:28,211 Epoch[40] Batch [930]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.099363,	
2017-08-04 06:26:33,759 Epoch[40] Batch [940]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.099336,	
2017-08-04 06:26:39,351 Epoch[40] Batch [950]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099287,	
2017-08-04 06:26:45,217 Epoch[40] Batch [960]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.099269,	
2017-08-04 06:26:50,902 Epoch[40] Batch [970]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.099198,	
2017-08-04 06:26:56,619 Epoch[40] Batch [980]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.099229,	
2017-08-04 06:27:01,992 Epoch[40] Batch [990]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099218,	
2017-08-04 06:27:07,144 Epoch[40] Batch [1000]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.099146,	
2017-08-04 06:27:12,414 Epoch[40] Batch [1010]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099226,	
2017-08-04 06:27:17,611 Epoch[40] Batch [1020]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099315,	
2017-08-04 06:27:22,667 Epoch[40] Batch [1030]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.099207,	
2017-08-04 06:27:28,300 Epoch[40] Batch [1040]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.099260,	
2017-08-04 06:27:33,713 Epoch[40] Batch [1050]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.099147,	
2017-08-04 06:27:39,450 Epoch[40] Batch [1060]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.099103,	
2017-08-04 06:27:45,772 Epoch[40] Batch [1070]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.099053,	
2017-08-04 06:27:51,258 Epoch[40] Batch [1080]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.099031,	
2017-08-04 06:27:56,792 Epoch[40] Batch [1090]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098984,	
2017-08-04 06:28:02,137 Epoch[40] Batch [1100]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098947,	
2017-08-04 06:28:07,210 Epoch[40] Batch [1110]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.098851,	
2017-08-04 06:28:11,911 Epoch[40] Batch [1120]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.098819,	
2017-08-04 06:28:17,041 Epoch[40] Batch [1130]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.098883,	
2017-08-04 06:28:22,175 Epoch[40] Batch [1140]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.098813,	
2017-08-04 06:28:27,907 Epoch[40] Batch [1150]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.098812,	
2017-08-04 06:28:33,618 Epoch[40] Batch [1160]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.098783,	
2017-08-04 06:28:38,712 Epoch[40] Batch [1170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.098685,	
2017-08-04 06:28:43,951 Epoch[40] Batch [1180]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098694,	
2017-08-04 06:28:49,253 Epoch[40] Batch [1190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098716,	
2017-08-04 06:28:54,677 Epoch[40] Batch [1200]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098630,	
2017-08-04 06:28:59,896 Epoch[40] Batch [1210]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.098559,	
2017-08-04 06:29:05,497 Epoch[40] Batch [1220]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098594,	
2017-08-04 06:29:10,646 Epoch[40] Batch [1230]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.098597,	
2017-08-04 06:29:15,746 Epoch[40] Batch [1240]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.098615,	
2017-08-04 06:29:20,959 Epoch[40] Batch [1250]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.098666,	
2017-08-04 06:29:26,302 Epoch[40] Batch [1260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098642,	
2017-08-04 06:29:32,002 Epoch[40] Batch [1270]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.098585,	
2017-08-04 06:29:37,719 Epoch[40] Batch [1280]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.098665,	
2017-08-04 06:29:43,303 Epoch[40] Batch [1290]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.098673,	
2017-08-04 06:29:48,494 Epoch[40] Batch [1300]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098637,	
2017-08-04 06:29:53,670 Epoch[40] Batch [1310]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.098569,	
2017-08-04 06:29:59,312 Epoch[40] Batch [1320]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.098476,	
2017-08-04 06:30:04,558 Epoch[40] Batch [1330]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.098410,	
2017-08-04 06:30:09,636 Epoch[40] Batch [1340]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.098471,	
2017-08-04 06:30:15,270 Epoch[40] Batch [1350]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.098426,	
2017-08-04 06:30:20,378 Epoch[40] Batch [1360]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.098494,	
2017-08-04 06:30:25,245 Epoch[40] Batch [1370]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.098468,	
2017-08-04 06:30:30,252 Epoch[40] Batch [1380]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.098464,	
2017-08-04 06:30:35,027 Epoch[40] Batch [1390]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.098467,	
2017-08-04 06:30:40,614 Epoch[40] Batch [1400]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.098503,	
2017-08-04 06:30:45,740 Epoch[40] Batch [1410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.098454,	
2017-08-04 06:30:51,079 Epoch[40] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098457,	
2017-08-04 06:30:55,962 Epoch[40] Batch [1430]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.098552,	
2017-08-04 06:31:00,953 Epoch[40] Batch [1440]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.098517,	
2017-08-04 06:31:06,068 Epoch[40] Batch [1450]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.098525,	
2017-08-04 06:31:11,497 Epoch[40] Batch [1460]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098467,	
2017-08-04 06:31:16,539 Epoch[40] Batch [1470]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.098440,	
2017-08-04 06:31:21,763 Epoch[40] Batch [1480]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.098407,	
2017-08-04 06:31:25,096 Epoch[40] Train-FCNLogLoss=0.098404
2017-08-04 06:31:25,096 Epoch[40] Time cost=817.765
2017-08-04 06:31:26,476 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0041.params"
2017-08-04 06:31:30,306 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0041.states"
2017-08-04 06:31:36,268 Epoch[41] Batch [10]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.097954,	
2017-08-04 06:31:41,376 Epoch[41] Batch [20]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.094136,	
2017-08-04 06:31:46,926 Epoch[41] Batch [30]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093364,	
2017-08-04 06:31:52,253 Epoch[41] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093439,	
2017-08-04 06:31:57,512 Epoch[41] Batch [50]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094337,	
2017-08-04 06:32:02,218 Epoch[41] Batch [60]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.092553,	
2017-08-04 06:32:07,507 Epoch[41] Batch [70]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093456,	
2017-08-04 06:32:12,683 Epoch[41] Batch [80]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092474,	
2017-08-04 06:32:17,974 Epoch[41] Batch [90]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092069,	
2017-08-04 06:32:23,446 Epoch[41] Batch [100]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.091884,	
2017-08-04 06:32:28,888 Epoch[41] Batch [110]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091540,	
2017-08-04 06:32:34,436 Epoch[41] Batch [120]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.092887,	
2017-08-04 06:32:39,847 Epoch[41] Batch [130]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.092598,	
2017-08-04 06:32:45,009 Epoch[41] Batch [140]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092912,	
2017-08-04 06:32:49,908 Epoch[41] Batch [150]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092555,	
2017-08-04 06:32:54,954 Epoch[41] Batch [160]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.092176,	
2017-08-04 06:33:00,045 Epoch[41] Batch [170]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.091968,	
2017-08-04 06:33:04,962 Epoch[41] Batch [180]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.091670,	
2017-08-04 06:33:09,962 Epoch[41] Batch [190]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092113,	
2017-08-04 06:33:15,354 Epoch[41] Batch [200]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091927,	
2017-08-04 06:33:20,696 Epoch[41] Batch [210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091717,	
2017-08-04 06:33:25,876 Epoch[41] Batch [220]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092008,	
2017-08-04 06:33:30,913 Epoch[41] Batch [230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092069,	
2017-08-04 06:33:35,916 Epoch[41] Batch [240]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.092509,	
2017-08-04 06:33:40,923 Epoch[41] Batch [250]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.091930,	
2017-08-04 06:33:46,076 Epoch[41] Batch [260]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092258,	
2017-08-04 06:33:50,874 Epoch[41] Batch [270]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092100,	
2017-08-04 06:33:55,918 Epoch[41] Batch [280]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.091934,	
2017-08-04 06:34:01,072 Epoch[41] Batch [290]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092151,	
2017-08-04 06:34:06,413 Epoch[41] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092267,	
2017-08-04 06:34:11,333 Epoch[41] Batch [310]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092494,	
2017-08-04 06:34:16,786 Epoch[41] Batch [320]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092297,	
2017-08-04 06:34:21,863 Epoch[41] Batch [330]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.091940,	
2017-08-04 06:34:27,048 Epoch[41] Batch [340]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092038,	
2017-08-04 06:34:32,246 Epoch[41] Batch [350]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092329,	
2017-08-04 06:34:37,306 Epoch[41] Batch [360]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092339,	
2017-08-04 06:34:42,443 Epoch[41] Batch [370]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092630,	
2017-08-04 06:34:47,209 Epoch[41] Batch [380]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092682,	
2017-08-04 06:34:52,375 Epoch[41] Batch [390]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092776,	
2017-08-04 06:34:57,570 Epoch[41] Batch [400]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092976,	
2017-08-04 06:35:02,489 Epoch[41] Batch [410]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092923,	
2017-08-04 06:35:07,823 Epoch[41] Batch [420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093053,	
2017-08-04 06:35:12,742 Epoch[41] Batch [430]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.093144,	
2017-08-04 06:35:17,876 Epoch[41] Batch [440]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093169,	
2017-08-04 06:35:22,912 Epoch[41] Batch [450]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093193,	
2017-08-04 06:35:28,186 Epoch[41] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093272,	
2017-08-04 06:35:33,283 Epoch[41] Batch [470]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093246,	
2017-08-04 06:35:38,647 Epoch[41] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093201,	
2017-08-04 06:35:44,291 Epoch[41] Batch [490]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.093132,	
2017-08-04 06:35:49,171 Epoch[41] Batch [500]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.093240,	
2017-08-04 06:35:54,578 Epoch[41] Batch [510]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093254,	
2017-08-04 06:35:59,408 Epoch[41] Batch [520]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.093380,	
2017-08-04 06:36:04,574 Epoch[41] Batch [530]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093365,	
2017-08-04 06:36:09,918 Epoch[41] Batch [540]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093578,	
2017-08-04 06:36:14,887 Epoch[41] Batch [550]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.093384,	
2017-08-04 06:36:20,114 Epoch[41] Batch [560]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093247,	
2017-08-04 06:36:24,917 Epoch[41] Batch [570]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.093453,	
2017-08-04 06:36:30,388 Epoch[41] Batch [580]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.093519,	
2017-08-04 06:36:35,813 Epoch[41] Batch [590]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.093463,	
2017-08-04 06:36:41,256 Epoch[41] Batch [600]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093548,	
2017-08-04 06:36:47,164 Epoch[41] Batch [610]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.093564,	
2017-08-04 06:36:52,300 Epoch[41] Batch [620]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093564,	
2017-08-04 06:36:57,576 Epoch[41] Batch [630]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093567,	
2017-08-04 06:37:02,598 Epoch[41] Batch [640]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093569,	
2017-08-04 06:37:07,975 Epoch[41] Batch [650]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093566,	
2017-08-04 06:37:13,004 Epoch[41] Batch [660]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.093585,	
2017-08-04 06:37:17,897 Epoch[41] Batch [670]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093606,	
2017-08-04 06:37:23,004 Epoch[41] Batch [680]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.093687,	
2017-08-04 06:37:28,179 Epoch[41] Batch [690]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093640,	
2017-08-04 06:37:33,220 Epoch[41] Batch [700]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093767,	
2017-08-04 06:37:38,948 Epoch[41] Batch [710]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.093680,	
2017-08-04 06:37:44,167 Epoch[41] Batch [720]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.093512,	
2017-08-04 06:37:49,100 Epoch[41] Batch [730]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.093374,	
2017-08-04 06:37:54,015 Epoch[41] Batch [740]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093512,	
2017-08-04 06:37:59,147 Epoch[41] Batch [750]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.093590,	
2017-08-04 06:38:04,417 Epoch[41] Batch [760]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093583,	
2017-08-04 06:38:09,305 Epoch[41] Batch [770]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093505,	
2017-08-04 06:38:14,519 Epoch[41] Batch [780]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.093555,	
2017-08-04 06:38:19,373 Epoch[41] Batch [790]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.093568,	
2017-08-04 06:38:24,725 Epoch[41] Batch [800]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093586,	
2017-08-04 06:38:29,861 Epoch[41] Batch [810]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093599,	
2017-08-04 06:38:35,036 Epoch[41] Batch [820]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093702,	
2017-08-04 06:38:40,103 Epoch[41] Batch [830]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093617,	
2017-08-04 06:38:45,373 Epoch[41] Batch [840]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093626,	
2017-08-04 06:38:49,941 Epoch[41] Batch [850]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.093632,	
2017-08-04 06:38:55,107 Epoch[41] Batch [860]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093877,	
2017-08-04 06:39:00,205 Epoch[41] Batch [870]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093967,	
2017-08-04 06:39:05,585 Epoch[41] Batch [880]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093963,	
2017-08-04 06:39:10,828 Epoch[41] Batch [890]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094007,	
2017-08-04 06:39:16,022 Epoch[41] Batch [900]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094017,	
2017-08-04 06:39:20,859 Epoch[41] Batch [910]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093957,	
2017-08-04 06:39:25,861 Epoch[41] Batch [920]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093999,	
2017-08-04 06:39:30,646 Epoch[41] Batch [930]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.093964,	
2017-08-04 06:39:35,417 Epoch[41] Batch [940]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.094050,	
2017-08-04 06:39:40,542 Epoch[41] Batch [950]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094041,	
2017-08-04 06:39:45,851 Epoch[41] Batch [960]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094034,	
2017-08-04 06:39:50,984 Epoch[41] Batch [970]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.094030,	
2017-08-04 06:39:56,157 Epoch[41] Batch [980]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094094,	
2017-08-04 06:40:01,360 Epoch[41] Batch [990]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094098,	
2017-08-04 06:40:06,167 Epoch[41] Batch [1000]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.093968,	
2017-08-04 06:40:11,050 Epoch[41] Batch [1010]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.093955,	
2017-08-04 06:40:16,455 Epoch[41] Batch [1020]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093873,	
2017-08-04 06:40:21,601 Epoch[41] Batch [1030]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093853,	
2017-08-04 06:40:26,825 Epoch[41] Batch [1040]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094007,	
2017-08-04 06:40:31,946 Epoch[41] Batch [1050]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094029,	
2017-08-04 06:40:36,852 Epoch[41] Batch [1060]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.093958,	
2017-08-04 06:40:41,883 Epoch[41] Batch [1070]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.093989,	
2017-08-04 06:40:47,489 Epoch[41] Batch [1080]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.093987,	
2017-08-04 06:40:52,449 Epoch[41] Batch [1090]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093955,	
2017-08-04 06:40:57,551 Epoch[41] Batch [1100]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.093892,	
2017-08-04 06:41:02,954 Epoch[41] Batch [1110]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093911,	
2017-08-04 06:41:08,013 Epoch[41] Batch [1120]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.093955,	
2017-08-04 06:41:13,208 Epoch[41] Batch [1130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093991,	
2017-08-04 06:41:18,559 Epoch[41] Batch [1140]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093952,	
2017-08-04 06:41:23,811 Epoch[41] Batch [1150]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093998,	
2017-08-04 06:41:29,225 Epoch[41] Batch [1160]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094013,	
2017-08-04 06:41:34,381 Epoch[41] Batch [1170]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094162,	
2017-08-04 06:41:39,726 Epoch[41] Batch [1180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094127,	
2017-08-04 06:41:44,758 Epoch[41] Batch [1190]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.094103,	
2017-08-04 06:41:49,841 Epoch[41] Batch [1200]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.094101,	
2017-08-04 06:41:55,113 Epoch[41] Batch [1210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094100,	
2017-08-04 06:42:00,520 Epoch[41] Batch [1220]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.094087,	
2017-08-04 06:42:05,599 Epoch[41] Batch [1230]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.094134,	
2017-08-04 06:42:10,797 Epoch[41] Batch [1240]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094075,	
2017-08-04 06:42:15,723 Epoch[41] Batch [1250]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.094086,	
2017-08-04 06:42:20,901 Epoch[41] Batch [1260]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094087,	
2017-08-04 06:42:25,986 Epoch[41] Batch [1270]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.094060,	
2017-08-04 06:42:30,815 Epoch[41] Batch [1280]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.094201,	
2017-08-04 06:42:35,954 Epoch[41] Batch [1290]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.094157,	
2017-08-04 06:42:40,912 Epoch[41] Batch [1300]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.094188,	
2017-08-04 06:42:45,925 Epoch[41] Batch [1310]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.094157,	
2017-08-04 06:42:51,269 Epoch[41] Batch [1320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094207,	
2017-08-04 06:42:56,475 Epoch[41] Batch [1330]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094249,	
2017-08-04 06:43:01,549 Epoch[41] Batch [1340]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.094256,	
2017-08-04 06:43:06,356 Epoch[41] Batch [1350]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.094214,	
2017-08-04 06:43:11,602 Epoch[41] Batch [1360]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094194,	
2017-08-04 06:43:16,990 Epoch[41] Batch [1370]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.094175,	
2017-08-04 06:43:21,960 Epoch[41] Batch [1380]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.094113,	
2017-08-04 06:43:27,239 Epoch[41] Batch [1390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094200,	
2017-08-04 06:43:32,720 Epoch[41] Batch [1400]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094221,	
2017-08-04 06:43:37,872 Epoch[41] Batch [1410]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094248,	
2017-08-04 06:43:42,941 Epoch[41] Batch [1420]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.094261,	
2017-08-04 06:43:48,227 Epoch[41] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094328,	
2017-08-04 06:43:53,545 Epoch[41] Batch [1440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094348,	
2017-08-04 06:43:58,345 Epoch[41] Batch [1450]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.094385,	
2017-08-04 06:44:03,110 Epoch[41] Batch [1460]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.094433,	
2017-08-04 06:44:07,967 Epoch[41] Batch [1470]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.094479,	
2017-08-04 06:44:13,070 Epoch[41] Batch [1480]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.094478,	
2017-08-04 06:44:15,941 Epoch[41] Train-FCNLogLoss=0.094467
2017-08-04 06:44:15,942 Epoch[41] Time cost=765.636
2017-08-04 06:44:17,072 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0042.params"
2017-08-04 06:44:20,926 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0042.states"
2017-08-04 06:44:27,050 Epoch[42] Batch [10]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.082079,	
2017-08-04 06:44:32,179 Epoch[42] Batch [20]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.090080,	
2017-08-04 06:44:37,595 Epoch[42] Batch [30]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091722,	
2017-08-04 06:44:42,842 Epoch[42] Batch [40]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093505,	
2017-08-04 06:44:47,635 Epoch[42] Batch [50]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.093481,	
2017-08-04 06:44:52,637 Epoch[42] Batch [60]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098402,	
2017-08-04 06:45:00,024 Epoch[42] Batch [70]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.097377,	
2017-08-04 06:45:05,079 Epoch[42] Batch [80]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.097220,	
2017-08-04 06:45:10,393 Epoch[42] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096760,	
2017-08-04 06:45:15,334 Epoch[42] Batch [100]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.096880,	
2017-08-04 06:45:20,584 Epoch[42] Batch [110]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097270,	
2017-08-04 06:45:25,611 Epoch[42] Batch [120]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.097673,	
2017-08-04 06:45:30,508 Epoch[42] Batch [130]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.097881,	
2017-08-04 06:45:35,716 Epoch[42] Batch [140]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.097050,	
2017-08-04 06:45:40,922 Epoch[42] Batch [150]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096910,	
2017-08-04 06:45:46,083 Epoch[42] Batch [160]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.096955,	
2017-08-04 06:45:51,752 Epoch[42] Batch [170]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.096618,	
2017-08-04 06:45:57,041 Epoch[42] Batch [180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096144,	
2017-08-04 06:46:01,746 Epoch[42] Batch [190]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.095428,	
2017-08-04 06:46:06,921 Epoch[42] Batch [200]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095196,	
2017-08-04 06:46:11,796 Epoch[42] Batch [210]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.094981,	
2017-08-04 06:46:16,967 Epoch[42] Batch [220]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094651,	
2017-08-04 06:46:22,215 Epoch[42] Batch [230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094086,	
2017-08-04 06:46:27,698 Epoch[42] Batch [240]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094215,	
2017-08-04 06:46:33,147 Epoch[42] Batch [250]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.094428,	
2017-08-04 06:46:38,168 Epoch[42] Batch [260]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.094855,	
2017-08-04 06:46:43,247 Epoch[42] Batch [270]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.095024,	
2017-08-04 06:46:48,326 Epoch[42] Batch [280]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.094796,	
2017-08-04 06:46:53,800 Epoch[42] Batch [290]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.094537,	
2017-08-04 06:46:59,034 Epoch[42] Batch [300]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.094775,	
2017-08-04 06:47:03,946 Epoch[42] Batch [310]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.094830,	
2017-08-04 06:47:09,524 Epoch[42] Batch [320]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.095124,	
2017-08-04 06:47:20,525 Epoch[42] Batch [330]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.095335,	
2017-08-04 06:47:25,958 Epoch[42] Batch [340]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.095431,	
2017-08-04 06:47:31,425 Epoch[42] Batch [350]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.095651,	
2017-08-04 06:47:36,806 Epoch[42] Batch [360]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095617,	
2017-08-04 06:47:41,945 Epoch[42] Batch [370]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.095614,	
2017-08-04 06:47:46,756 Epoch[42] Batch [380]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.095430,	
2017-08-04 06:47:51,788 Epoch[42] Batch [390]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.095241,	
2017-08-04 06:47:56,861 Epoch[42] Batch [400]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.095368,	
2017-08-04 06:48:01,961 Epoch[42] Batch [410]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.095266,	
2017-08-04 06:48:07,392 Epoch[42] Batch [420]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.095193,	
2017-08-04 06:48:12,108 Epoch[42] Batch [430]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.094904,	
2017-08-04 06:48:17,003 Epoch[42] Batch [440]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.095000,	
2017-08-04 06:48:21,886 Epoch[42] Batch [450]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.095261,	
2017-08-04 06:48:27,259 Epoch[42] Batch [460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095153,	
2017-08-04 06:48:32,597 Epoch[42] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095090,	
2017-08-04 06:48:37,604 Epoch[42] Batch [480]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.095093,	
2017-08-04 06:48:42,591 Epoch[42] Batch [490]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.095096,	
2017-08-04 06:48:48,011 Epoch[42] Batch [500]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.095246,	
2017-08-04 06:48:53,364 Epoch[42] Batch [510]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095248,	
2017-08-04 06:48:58,806 Epoch[42] Batch [520]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.095220,	
2017-08-04 06:49:04,059 Epoch[42] Batch [530]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.095185,	
2017-08-04 06:49:09,407 Epoch[42] Batch [540]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095217,	
2017-08-04 06:49:14,618 Epoch[42] Batch [550]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095159,	
2017-08-04 06:49:19,658 Epoch[42] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.095282,	
2017-08-04 06:49:24,602 Epoch[42] Batch [570]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.095235,	
2017-08-04 06:49:29,558 Epoch[42] Batch [580]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.095073,	
2017-08-04 06:49:34,805 Epoch[42] Batch [590]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095074,	
2017-08-04 06:49:40,260 Epoch[42] Batch [600]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.095204,	
2017-08-04 06:49:45,051 Epoch[42] Batch [610]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.095175,	
2017-08-04 06:49:50,149 Epoch[42] Batch [620]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.095180,	
2017-08-04 06:49:55,307 Epoch[42] Batch [630]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.095165,	
2017-08-04 06:50:00,267 Epoch[42] Batch [640]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.095142,	
2017-08-04 06:50:05,441 Epoch[42] Batch [650]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095160,	
2017-08-04 06:50:10,382 Epoch[42] Batch [660]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.095168,	
2017-08-04 06:50:15,865 Epoch[42] Batch [670]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.095117,	
2017-08-04 06:50:21,196 Epoch[42] Batch [680]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095172,	
2017-08-04 06:50:25,942 Epoch[42] Batch [690]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.095156,	
2017-08-04 06:50:31,015 Epoch[42] Batch [700]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.094965,	
2017-08-04 06:50:36,282 Epoch[42] Batch [710]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094987,	
2017-08-04 06:50:41,658 Epoch[42] Batch [720]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094912,	
2017-08-04 06:50:46,879 Epoch[42] Batch [730]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094858,	
2017-08-04 06:50:52,345 Epoch[42] Batch [740]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.094926,	
2017-08-04 06:50:57,479 Epoch[42] Batch [750]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.094849,	
2017-08-04 06:51:02,584 Epoch[42] Batch [760]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.094772,	
2017-08-04 06:51:07,941 Epoch[42] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094757,	
2017-08-04 06:51:13,057 Epoch[42] Batch [780]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.094593,	
2017-08-04 06:51:18,003 Epoch[42] Batch [790]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.094622,	
2017-08-04 06:51:23,172 Epoch[42] Batch [800]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094532,	
2017-08-04 06:51:28,407 Epoch[42] Batch [810]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.094468,	
2017-08-04 06:51:33,512 Epoch[42] Batch [820]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.094393,	
2017-08-04 06:51:38,597 Epoch[42] Batch [830]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.094410,	
2017-08-04 06:51:43,834 Epoch[42] Batch [840]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.094552,	
2017-08-04 06:51:49,163 Epoch[42] Batch [850]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094627,	
2017-08-04 06:51:54,593 Epoch[42] Batch [860]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094635,	
2017-08-04 06:51:59,909 Epoch[42] Batch [870]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094696,	
2017-08-04 06:52:05,029 Epoch[42] Batch [880]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094678,	
2017-08-04 06:52:10,041 Epoch[42] Batch [890]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.094749,	
2017-08-04 06:52:14,917 Epoch[42] Batch [900]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.094759,	
2017-08-04 06:52:19,724 Epoch[42] Batch [910]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.094789,	
2017-08-04 06:52:24,636 Epoch[42] Batch [920]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.094831,	
2017-08-04 06:52:29,986 Epoch[42] Batch [930]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094817,	
2017-08-04 06:52:35,022 Epoch[42] Batch [940]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094784,	
2017-08-04 06:52:40,052 Epoch[42] Batch [950]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.094766,	
2017-08-04 06:52:44,898 Epoch[42] Batch [960]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.094676,	
2017-08-04 06:52:50,029 Epoch[42] Batch [970]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.094678,	
2017-08-04 06:52:55,015 Epoch[42] Batch [980]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.094660,	
2017-08-04 06:53:00,310 Epoch[42] Batch [990]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094652,	
2017-08-04 06:53:05,358 Epoch[42] Batch [1000]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.094650,	
2017-08-04 06:53:10,396 Epoch[42] Batch [1010]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094582,	
2017-08-04 06:53:15,087 Epoch[42] Batch [1020]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.094466,	
2017-08-04 06:53:19,923 Epoch[42] Batch [1030]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.094590,	
2017-08-04 06:53:25,379 Epoch[42] Batch [1040]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094558,	
2017-08-04 06:53:30,550 Epoch[42] Batch [1050]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094579,	
2017-08-04 06:53:35,533 Epoch[42] Batch [1060]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.094472,	
2017-08-04 06:53:40,763 Epoch[42] Batch [1070]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094567,	
2017-08-04 06:53:46,043 Epoch[42] Batch [1080]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094549,	
2017-08-04 06:53:51,421 Epoch[42] Batch [1090]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094476,	
2017-08-04 06:53:56,535 Epoch[42] Batch [1100]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.094509,	
2017-08-04 06:54:01,749 Epoch[42] Batch [1110]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094477,	
2017-08-04 06:54:06,843 Epoch[42] Batch [1120]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094539,	
2017-08-04 06:54:11,439 Epoch[42] Batch [1130]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.094528,	
2017-08-04 06:54:16,691 Epoch[42] Batch [1140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094531,	
2017-08-04 06:54:21,815 Epoch[42] Batch [1150]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094456,	
2017-08-04 06:54:26,920 Epoch[42] Batch [1160]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.094467,	
2017-08-04 06:54:32,588 Epoch[42] Batch [1170]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.094429,	
2017-08-04 06:54:37,354 Epoch[42] Batch [1180]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094388,	
2017-08-04 06:54:42,923 Epoch[42] Batch [1190]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.094358,	
2017-08-04 06:54:48,217 Epoch[42] Batch [1200]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094348,	
2017-08-04 06:54:53,247 Epoch[42] Batch [1210]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.094372,	
2017-08-04 06:54:58,471 Epoch[42] Batch [1220]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094376,	
2017-08-04 06:55:03,268 Epoch[42] Batch [1230]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.094364,	
2017-08-04 06:55:08,365 Epoch[42] Batch [1240]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094310,	
2017-08-04 06:55:13,543 Epoch[42] Batch [1250]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094463,	
2017-08-04 06:55:18,808 Epoch[42] Batch [1260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094399,	
2017-08-04 06:55:24,265 Epoch[42] Batch [1270]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094474,	
2017-08-04 06:55:29,536 Epoch[42] Batch [1280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094486,	
2017-08-04 06:55:34,478 Epoch[42] Batch [1290]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.094501,	
2017-08-04 06:55:39,329 Epoch[42] Batch [1300]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.094510,	
2017-08-04 06:55:44,491 Epoch[42] Batch [1310]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094525,	
2017-08-04 06:55:49,470 Epoch[42] Batch [1320]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.094483,	
2017-08-04 06:55:54,654 Epoch[42] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094518,	
2017-08-04 06:55:59,636 Epoch[42] Batch [1340]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.094581,	
2017-08-04 06:56:04,806 Epoch[42] Batch [1350]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094627,	
2017-08-04 06:56:10,170 Epoch[42] Batch [1360]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094640,	
2017-08-04 06:56:15,659 Epoch[42] Batch [1370]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.094604,	
2017-08-04 06:56:21,013 Epoch[42] Batch [1380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094554,	
2017-08-04 06:56:25,816 Epoch[42] Batch [1390]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.094615,	
2017-08-04 06:56:30,963 Epoch[42] Batch [1400]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094569,	
2017-08-04 06:56:36,270 Epoch[42] Batch [1410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094496,	
2017-08-04 06:56:41,288 Epoch[42] Batch [1420]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.094490,	
2017-08-04 06:56:46,313 Epoch[42] Batch [1430]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.094496,	
2017-08-04 06:56:51,819 Epoch[42] Batch [1440]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.094526,	
2017-08-04 06:56:56,958 Epoch[42] Batch [1450]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.094561,	
2017-08-04 06:57:02,201 Epoch[42] Batch [1460]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094525,	
2017-08-04 06:57:07,373 Epoch[42] Batch [1470]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094534,	
2017-08-04 06:57:12,537 Epoch[42] Batch [1480]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094484,	
2017-08-04 06:57:15,612 Epoch[42] Train-FCNLogLoss=0.094455
2017-08-04 06:57:15,612 Epoch[42] Time cost=774.686
2017-08-04 06:57:16,671 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0043.params"
2017-08-04 06:57:20,698 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0043.states"
2017-08-04 06:57:27,202 Epoch[43] Batch [10]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.100149,	
2017-08-04 06:57:32,534 Epoch[43] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096883,	
2017-08-04 06:57:38,338 Epoch[43] Batch [30]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.095870,	
2017-08-04 06:57:43,707 Epoch[43] Batch [40]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096207,	
2017-08-04 06:57:49,340 Epoch[43] Batch [50]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.094573,	
2017-08-04 06:57:54,186 Epoch[43] Batch [60]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.095284,	
2017-08-04 06:57:59,889 Epoch[43] Batch [70]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.094637,	
2017-08-04 06:58:05,345 Epoch[43] Batch [80]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094693,	
2017-08-04 06:58:10,755 Epoch[43] Batch [90]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093952,	
2017-08-04 06:58:16,579 Epoch[43] Batch [100]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.094073,	
2017-08-04 06:58:22,041 Epoch[43] Batch [110]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.094133,	
2017-08-04 06:58:28,325 Epoch[43] Batch [120]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.094662,	
2017-08-04 06:58:33,836 Epoch[43] Batch [130]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.094141,	
2017-08-04 06:58:39,689 Epoch[43] Batch [140]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.093634,	
2017-08-04 06:58:45,185 Epoch[43] Batch [150]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093810,	
2017-08-04 06:58:51,413 Epoch[43] Batch [160]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093925,	
2017-08-04 06:58:57,074 Epoch[43] Batch [170]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.094117,	
2017-08-04 06:59:03,550 Epoch[43] Batch [180]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.094083,	
2017-08-04 06:59:08,703 Epoch[43] Batch [190]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094281,	
2017-08-04 06:59:13,833 Epoch[43] Batch [200]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.094647,	
2017-08-04 06:59:18,666 Epoch[43] Batch [210]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.094320,	
2017-08-04 06:59:24,164 Epoch[43] Batch [220]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.094158,	
2017-08-04 06:59:29,325 Epoch[43] Batch [230]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094411,	
2017-08-04 06:59:34,330 Epoch[43] Batch [240]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.094461,	
2017-08-04 06:59:39,961 Epoch[43] Batch [250]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.094405,	
2017-08-04 06:59:44,985 Epoch[43] Batch [260]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.094369,	
2017-08-04 06:59:50,030 Epoch[43] Batch [270]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.094264,	
2017-08-04 06:59:55,913 Epoch[43] Batch [280]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.094178,	
2017-08-04 07:00:01,140 Epoch[43] Batch [290]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094187,	
2017-08-04 07:00:06,638 Epoch[43] Batch [300]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.094075,	
2017-08-04 07:00:11,398 Epoch[43] Batch [310]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.093879,	
2017-08-04 07:00:16,506 Epoch[43] Batch [320]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.094009,	
2017-08-04 07:00:22,203 Epoch[43] Batch [330]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.093696,	
2017-08-04 07:00:27,970 Epoch[43] Batch [340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.093945,	
2017-08-04 07:00:33,614 Epoch[43] Batch [350]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.094074,	
2017-08-04 07:00:38,701 Epoch[43] Batch [360]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.094057,	
2017-08-04 07:00:44,189 Epoch[43] Batch [370]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.094183,	
2017-08-04 07:00:49,890 Epoch[43] Batch [380]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.094232,	
2017-08-04 07:00:55,348 Epoch[43] Batch [390]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094089,	
2017-08-04 07:01:00,271 Epoch[43] Batch [400]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.094157,	
2017-08-04 07:01:05,804 Epoch[43] Batch [410]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093933,	
2017-08-04 07:01:11,712 Epoch[43] Batch [420]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.093908,	
2017-08-04 07:01:17,187 Epoch[43] Batch [430]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.093810,	
2017-08-04 07:01:22,713 Epoch[43] Batch [440]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.094190,	
2017-08-04 07:01:28,757 Epoch[43] Batch [450]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093893,	
2017-08-04 07:01:34,027 Epoch[43] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093631,	
2017-08-04 07:01:39,809 Epoch[43] Batch [470]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093631,	
2017-08-04 07:01:45,065 Epoch[43] Batch [480]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093752,	
2017-08-04 07:01:50,428 Epoch[43] Batch [490]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093691,	
2017-08-04 07:01:55,930 Epoch[43] Batch [500]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093838,	
2017-08-04 07:02:01,205 Epoch[43] Batch [510]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093756,	
2017-08-04 07:02:06,450 Epoch[43] Batch [520]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093635,	
2017-08-04 07:02:12,937 Epoch[43] Batch [530]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.093525,	
2017-08-04 07:02:18,897 Epoch[43] Batch [540]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.093589,	
2017-08-04 07:02:24,945 Epoch[43] Batch [550]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.093487,	
2017-08-04 07:02:30,603 Epoch[43] Batch [560]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.093339,	
2017-08-04 07:02:35,865 Epoch[43] Batch [570]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093415,	
2017-08-04 07:02:41,396 Epoch[43] Batch [580]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093230,	
2017-08-04 07:02:46,690 Epoch[43] Batch [590]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093191,	
2017-08-04 07:02:52,686 Epoch[43] Batch [600]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.093062,	
2017-08-04 07:02:58,767 Epoch[43] Batch [610]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.093329,	
2017-08-04 07:03:04,095 Epoch[43] Batch [620]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093544,	
2017-08-04 07:03:09,111 Epoch[43] Batch [630]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093489,	
2017-08-04 07:03:14,658 Epoch[43] Batch [640]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093617,	
2017-08-04 07:03:19,784 Epoch[43] Batch [650]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.093547,	
2017-08-04 07:03:24,579 Epoch[43] Batch [660]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093647,	
2017-08-04 07:03:29,311 Epoch[43] Batch [670]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.093604,	
2017-08-04 07:03:33,773 Epoch[43] Batch [680]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.093756,	
2017-08-04 07:03:38,337 Epoch[43] Batch [690]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.093780,	
2017-08-04 07:03:43,900 Epoch[43] Batch [700]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093745,	
2017-08-04 07:03:49,449 Epoch[43] Batch [710]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093737,	
2017-08-04 07:03:55,514 Epoch[43] Batch [720]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.093788,	
2017-08-04 07:04:01,561 Epoch[43] Batch [730]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093856,	
2017-08-04 07:04:06,616 Epoch[43] Batch [740]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.093890,	
2017-08-04 07:04:12,613 Epoch[43] Batch [750]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.093921,	
2017-08-04 07:04:18,027 Epoch[43] Batch [760]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093894,	
2017-08-04 07:04:23,595 Epoch[43] Batch [770]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.093846,	
2017-08-04 07:04:29,602 Epoch[43] Batch [780]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.093825,	
2017-08-04 07:04:35,079 Epoch[43] Batch [790]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093770,	
2017-08-04 07:04:40,487 Epoch[43] Batch [800]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093855,	
2017-08-04 07:04:45,924 Epoch[43] Batch [810]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093761,	
2017-08-04 07:04:51,214 Epoch[43] Batch [820]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093733,	
2017-08-04 07:04:56,661 Epoch[43] Batch [830]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093790,	
2017-08-04 07:05:02,010 Epoch[43] Batch [840]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093829,	
2017-08-04 07:05:06,969 Epoch[43] Batch [850]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093937,	
2017-08-04 07:05:11,938 Epoch[43] Batch [860]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.093906,	
2017-08-04 07:05:17,618 Epoch[43] Batch [870]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.094038,	
2017-08-04 07:05:23,074 Epoch[43] Batch [880]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094110,	
2017-08-04 07:05:28,071 Epoch[43] Batch [890]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.094144,	
2017-08-04 07:05:33,936 Epoch[43] Batch [900]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.094215,	
2017-08-04 07:05:39,281 Epoch[43] Batch [910]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094313,	
2017-08-04 07:05:44,288 Epoch[43] Batch [920]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.094217,	
2017-08-04 07:05:50,118 Epoch[43] Batch [930]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.094311,	
2017-08-04 07:05:54,851 Epoch[43] Batch [940]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.094310,	
2017-08-04 07:05:59,429 Epoch[43] Batch [950]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.094334,	
2017-08-04 07:06:04,194 Epoch[43] Batch [960]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094374,	
2017-08-04 07:06:09,346 Epoch[43] Batch [970]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094403,	
2017-08-04 07:06:14,243 Epoch[43] Batch [980]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.094474,	
2017-08-04 07:06:18,828 Epoch[43] Batch [990]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.094509,	
2017-08-04 07:06:24,217 Epoch[43] Batch [1000]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.094466,	
2017-08-04 07:06:29,574 Epoch[43] Batch [1010]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094594,	
2017-08-04 07:06:34,924 Epoch[43] Batch [1020]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094596,	
2017-08-04 07:06:40,406 Epoch[43] Batch [1030]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094543,	
2017-08-04 07:06:46,572 Epoch[43] Batch [1040]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094542,	
2017-08-04 07:06:52,220 Epoch[43] Batch [1050]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.094452,	
2017-08-04 07:06:57,630 Epoch[43] Batch [1060]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.094433,	
2017-08-04 07:07:02,618 Epoch[43] Batch [1070]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.094462,	
2017-08-04 07:07:08,247 Epoch[43] Batch [1080]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.094499,	
2017-08-04 07:07:13,834 Epoch[43] Batch [1090]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.094418,	
2017-08-04 07:07:19,085 Epoch[43] Batch [1100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094428,	
2017-08-04 07:07:24,391 Epoch[43] Batch [1110]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094378,	
2017-08-04 07:07:29,628 Epoch[43] Batch [1120]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.094471,	
2017-08-04 07:07:35,279 Epoch[43] Batch [1130]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.094483,	
2017-08-04 07:07:41,407 Epoch[43] Batch [1140]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.094490,	
2017-08-04 07:07:46,811 Epoch[43] Batch [1150]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.094535,	
2017-08-04 07:07:52,159 Epoch[43] Batch [1160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094507,	
2017-08-04 07:07:57,617 Epoch[43] Batch [1170]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094562,	
2017-08-04 07:08:03,102 Epoch[43] Batch [1180]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.094505,	
2017-08-04 07:08:08,924 Epoch[43] Batch [1190]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.094482,	
2017-08-04 07:08:14,584 Epoch[43] Batch [1200]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.094467,	
2017-08-04 07:08:20,033 Epoch[43] Batch [1210]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.094498,	
2017-08-04 07:08:25,643 Epoch[43] Batch [1220]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.094431,	
2017-08-04 07:08:31,098 Epoch[43] Batch [1230]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094448,	
2017-08-04 07:08:36,762 Epoch[43] Batch [1240]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.094408,	
2017-08-04 07:08:42,780 Epoch[43] Batch [1250]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.094413,	
2017-08-04 07:08:48,005 Epoch[43] Batch [1260]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094392,	
2017-08-04 07:08:53,392 Epoch[43] Batch [1270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.094389,	
2017-08-04 07:08:58,717 Epoch[43] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094358,	
2017-08-04 07:09:04,237 Epoch[43] Batch [1290]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094319,	
2017-08-04 07:09:09,332 Epoch[43] Batch [1300]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094285,	
2017-08-04 07:09:14,954 Epoch[43] Batch [1310]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.094294,	
2017-08-04 07:09:20,274 Epoch[43] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094288,	
2017-08-04 07:09:26,065 Epoch[43] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.094240,	
2017-08-04 07:09:31,283 Epoch[43] Batch [1340]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094200,	
2017-08-04 07:09:36,902 Epoch[43] Batch [1350]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.094175,	
2017-08-04 07:09:42,492 Epoch[43] Batch [1360]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.094265,	
2017-08-04 07:09:48,134 Epoch[43] Batch [1370]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.094223,	
2017-08-04 07:09:53,644 Epoch[43] Batch [1380]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.094194,	
2017-08-04 07:09:59,309 Epoch[43] Batch [1390]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.094160,	
2017-08-04 07:10:05,021 Epoch[43] Batch [1400]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.094121,	
2017-08-04 07:10:10,773 Epoch[43] Batch [1410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094196,	
2017-08-04 07:10:16,916 Epoch[43] Batch [1420]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.094207,	
2017-08-04 07:10:22,223 Epoch[43] Batch [1430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094145,	
2017-08-04 07:10:27,472 Epoch[43] Batch [1440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094170,	
2017-08-04 07:10:33,052 Epoch[43] Batch [1450]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.094216,	
2017-08-04 07:10:38,485 Epoch[43] Batch [1460]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094137,	
2017-08-04 07:10:44,350 Epoch[43] Batch [1470]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.094113,	
2017-08-04 07:10:49,867 Epoch[43] Batch [1480]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094012,	
2017-08-04 07:10:53,229 Epoch[43] Train-FCNLogLoss=0.094042
2017-08-04 07:10:53,229 Epoch[43] Time cost=812.530
2017-08-04 07:10:54,969 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0044.params"
2017-08-04 07:11:00,251 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0044.states"
2017-08-04 07:11:06,090 Epoch[44] Batch [10]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.092966,	
2017-08-04 07:11:12,190 Epoch[44] Batch [20]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.093601,	
2017-08-04 07:11:18,016 Epoch[44] Batch [30]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.092008,	
2017-08-04 07:11:23,422 Epoch[44] Batch [40]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090850,	
2017-08-04 07:11:29,694 Epoch[44] Batch [50]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.092215,	
2017-08-04 07:11:36,129 Epoch[44] Batch [60]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.092315,	
2017-08-04 07:11:41,522 Epoch[44] Batch [70]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093355,	
2017-08-04 07:11:46,850 Epoch[44] Batch [80]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092842,	
2017-08-04 07:11:51,985 Epoch[44] Batch [90]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092200,	
2017-08-04 07:11:57,353 Epoch[44] Batch [100]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092160,	
2017-08-04 07:12:02,463 Epoch[44] Batch [110]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.093906,	
2017-08-04 07:12:08,021 Epoch[44] Batch [120]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.094220,	
2017-08-04 07:12:13,250 Epoch[44] Batch [130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093893,	
2017-08-04 07:12:19,646 Epoch[44] Batch [140]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.093383,	
2017-08-04 07:12:25,786 Epoch[44] Batch [150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093535,	
2017-08-04 07:12:31,344 Epoch[44] Batch [160]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093604,	
2017-08-04 07:12:36,956 Epoch[44] Batch [170]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.094278,	
2017-08-04 07:12:42,368 Epoch[44] Batch [180]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094730,	
2017-08-04 07:12:47,879 Epoch[44] Batch [190]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.095008,	
2017-08-04 07:12:53,573 Epoch[44] Batch [200]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.094482,	
2017-08-04 07:12:59,246 Epoch[44] Batch [210]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.094920,	
2017-08-04 07:13:04,655 Epoch[44] Batch [220]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094455,	
2017-08-04 07:13:10,576 Epoch[44] Batch [230]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.094519,	
2017-08-04 07:13:16,096 Epoch[44] Batch [240]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094289,	
2017-08-04 07:13:22,081 Epoch[44] Batch [250]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094176,	
2017-08-04 07:13:27,962 Epoch[44] Batch [260]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.094321,	
2017-08-04 07:13:33,133 Epoch[44] Batch [270]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094105,	
2017-08-04 07:13:39,102 Epoch[44] Batch [280]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.094259,	
2017-08-04 07:13:44,787 Epoch[44] Batch [290]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.094154,	
2017-08-04 07:13:50,556 Epoch[44] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.093970,	
2017-08-04 07:13:55,870 Epoch[44] Batch [310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093816,	
2017-08-04 07:14:01,799 Epoch[44] Batch [320]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.093663,	
2017-08-04 07:14:06,957 Epoch[44] Batch [330]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093682,	
2017-08-04 07:14:12,641 Epoch[44] Batch [340]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.093718,	
2017-08-04 07:14:18,229 Epoch[44] Batch [350]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093689,	
2017-08-04 07:14:23,876 Epoch[44] Batch [360]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.093692,	
2017-08-04 07:14:29,539 Epoch[44] Batch [370]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093570,	
2017-08-04 07:14:35,118 Epoch[44] Batch [380]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.093566,	
2017-08-04 07:14:40,514 Epoch[44] Batch [390]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093339,	
2017-08-04 07:14:45,706 Epoch[44] Batch [400]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093623,	
2017-08-04 07:14:50,820 Epoch[44] Batch [410]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.093598,	
2017-08-04 07:14:55,891 Epoch[44] Batch [420]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093423,	
2017-08-04 07:15:01,136 Epoch[44] Batch [430]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093498,	
2017-08-04 07:15:06,302 Epoch[44] Batch [440]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093445,	
2017-08-04 07:15:11,378 Epoch[44] Batch [450]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.093442,	
2017-08-04 07:15:16,642 Epoch[44] Batch [460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093333,	
2017-08-04 07:15:21,913 Epoch[44] Batch [470]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093552,	
2017-08-04 07:15:27,247 Epoch[44] Batch [480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093440,	
2017-08-04 07:15:33,725 Epoch[44] Batch [490]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.093458,	
2017-08-04 07:15:40,144 Epoch[44] Batch [500]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.093370,	
2017-08-04 07:15:46,408 Epoch[44] Batch [510]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.093481,	
2017-08-04 07:15:51,943 Epoch[44] Batch [520]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093365,	
2017-08-04 07:15:57,964 Epoch[44] Batch [530]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.093513,	
2017-08-04 07:16:03,876 Epoch[44] Batch [540]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093475,	
2017-08-04 07:16:09,524 Epoch[44] Batch [550]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.093551,	
2017-08-04 07:16:14,609 Epoch[44] Batch [560]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093497,	
2017-08-04 07:16:20,142 Epoch[44] Batch [570]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093559,	
2017-08-04 07:16:25,971 Epoch[44] Batch [580]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.093453,	
2017-08-04 07:16:31,465 Epoch[44] Batch [590]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093576,	
2017-08-04 07:16:36,696 Epoch[44] Batch [600]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093525,	
2017-08-04 07:16:42,165 Epoch[44] Batch [610]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.093497,	
2017-08-04 07:16:47,667 Epoch[44] Batch [620]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093481,	
2017-08-04 07:16:52,818 Epoch[44] Batch [630]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093541,	
2017-08-04 07:16:58,498 Epoch[44] Batch [640]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.093625,	
2017-08-04 07:17:03,725 Epoch[44] Batch [650]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093686,	
2017-08-04 07:17:09,216 Epoch[44] Batch [660]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093656,	
2017-08-04 07:17:14,531 Epoch[44] Batch [670]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093528,	
2017-08-04 07:17:19,733 Epoch[44] Batch [680]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093545,	
2017-08-04 07:17:25,039 Epoch[44] Batch [690]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093495,	
2017-08-04 07:17:31,062 Epoch[44] Batch [700]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.093438,	
2017-08-04 07:17:36,860 Epoch[44] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093377,	
2017-08-04 07:17:42,535 Epoch[44] Batch [720]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.093472,	
2017-08-04 07:17:48,565 Epoch[44] Batch [730]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.093479,	
2017-08-04 07:17:53,770 Epoch[44] Batch [740]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093536,	
2017-08-04 07:17:58,729 Epoch[44] Batch [750]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093442,	
2017-08-04 07:18:04,653 Epoch[44] Batch [760]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.093397,	
2017-08-04 07:18:10,975 Epoch[44] Batch [770]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.093502,	
2017-08-04 07:18:16,714 Epoch[44] Batch [780]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.093581,	
2017-08-04 07:18:22,458 Epoch[44] Batch [790]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.093524,	
2017-08-04 07:18:28,570 Epoch[44] Batch [800]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.093640,	
2017-08-04 07:18:34,168 Epoch[44] Batch [810]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.093747,	
2017-08-04 07:18:39,908 Epoch[44] Batch [820]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.093812,	
2017-08-04 07:18:45,279 Epoch[44] Batch [830]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093776,	
2017-08-04 07:18:50,865 Epoch[44] Batch [840]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093773,	
2017-08-04 07:18:56,189 Epoch[44] Batch [850]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093687,	
2017-08-04 07:19:02,062 Epoch[44] Batch [860]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093614,	
2017-08-04 07:19:08,112 Epoch[44] Batch [870]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.093669,	
2017-08-04 07:19:13,512 Epoch[44] Batch [880]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093730,	
2017-08-04 07:19:18,862 Epoch[44] Batch [890]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093662,	
2017-08-04 07:19:24,212 Epoch[44] Batch [900]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093662,	
2017-08-04 07:19:30,064 Epoch[44] Batch [910]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093594,	
2017-08-04 07:19:35,899 Epoch[44] Batch [920]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.093607,	
2017-08-04 07:19:41,640 Epoch[44] Batch [930]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.093560,	
2017-08-04 07:19:46,789 Epoch[44] Batch [940]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093561,	
2017-08-04 07:19:51,683 Epoch[44] Batch [950]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.093573,	
2017-08-04 07:19:56,751 Epoch[44] Batch [960]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093554,	
2017-08-04 07:20:02,214 Epoch[44] Batch [970]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.093597,	
2017-08-04 07:20:07,740 Epoch[44] Batch [980]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.093653,	
2017-08-04 07:20:13,127 Epoch[44] Batch [990]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093512,	
2017-08-04 07:20:19,054 Epoch[44] Batch [1000]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.093479,	
2017-08-04 07:20:24,469 Epoch[44] Batch [1010]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093426,	
2017-08-04 07:20:29,910 Epoch[44] Batch [1020]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093400,	
2017-08-04 07:20:35,753 Epoch[44] Batch [1030]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.093371,	
2017-08-04 07:20:41,238 Epoch[44] Batch [1040]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093322,	
2017-08-04 07:20:46,088 Epoch[44] Batch [1050]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.093273,	
2017-08-04 07:20:51,548 Epoch[44] Batch [1060]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093249,	
2017-08-04 07:20:57,046 Epoch[44] Batch [1070]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093333,	
2017-08-04 07:21:02,224 Epoch[44] Batch [1080]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093328,	
2017-08-04 07:21:08,295 Epoch[44] Batch [1090]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093381,	
2017-08-04 07:21:13,497 Epoch[44] Batch [1100]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093477,	
2017-08-04 07:21:18,926 Epoch[44] Batch [1110]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.093549,	
2017-08-04 07:21:24,068 Epoch[44] Batch [1120]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093621,	
2017-08-04 07:21:28,991 Epoch[44] Batch [1130]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.093647,	
2017-08-04 07:21:34,647 Epoch[44] Batch [1140]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.093601,	
2017-08-04 07:21:40,064 Epoch[44] Batch [1150]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093551,	
2017-08-04 07:21:45,694 Epoch[44] Batch [1160]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093620,	
2017-08-04 07:21:50,933 Epoch[44] Batch [1170]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093641,	
2017-08-04 07:21:56,528 Epoch[44] Batch [1180]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.093670,	
2017-08-04 07:22:01,821 Epoch[44] Batch [1190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093718,	
2017-08-04 07:22:08,000 Epoch[44] Batch [1200]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.093747,	
2017-08-04 07:22:13,885 Epoch[44] Batch [1210]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093779,	
2017-08-04 07:22:19,494 Epoch[44] Batch [1220]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.093760,	
2017-08-04 07:22:25,144 Epoch[44] Batch [1230]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.093762,	
2017-08-04 07:22:30,955 Epoch[44] Batch [1240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.093740,	
2017-08-04 07:22:36,731 Epoch[44] Batch [1250]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.093647,	
2017-08-04 07:22:42,823 Epoch[44] Batch [1260]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.093673,	
2017-08-04 07:22:48,517 Epoch[44] Batch [1270]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.093644,	
2017-08-04 07:22:54,464 Epoch[44] Batch [1280]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093663,	
2017-08-04 07:22:59,648 Epoch[44] Batch [1290]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093559,	
2017-08-04 07:23:05,040 Epoch[44] Batch [1300]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093502,	
2017-08-04 07:23:10,475 Epoch[44] Batch [1310]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093467,	
2017-08-04 07:23:16,024 Epoch[44] Batch [1320]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093436,	
2017-08-04 07:23:20,868 Epoch[44] Batch [1330]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.093442,	
2017-08-04 07:23:25,413 Epoch[44] Batch [1340]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093463,	
2017-08-04 07:23:30,254 Epoch[44] Batch [1350]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.093482,	
2017-08-04 07:23:35,585 Epoch[44] Batch [1360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093463,	
2017-08-04 07:23:41,163 Epoch[44] Batch [1370]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.093460,	
2017-08-04 07:23:47,439 Epoch[44] Batch [1380]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.093477,	
2017-08-04 07:23:53,255 Epoch[44] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.093489,	
2017-08-04 07:23:58,477 Epoch[44] Batch [1400]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093493,	
2017-08-04 07:24:04,267 Epoch[44] Batch [1410]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093494,	
2017-08-04 07:24:09,121 Epoch[44] Batch [1420]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.093526,	
2017-08-04 07:24:14,497 Epoch[44] Batch [1430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093545,	
2017-08-04 07:24:20,948 Epoch[44] Batch [1440]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.093581,	
2017-08-04 07:24:26,479 Epoch[44] Batch [1450]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093640,	
2017-08-04 07:24:32,748 Epoch[44] Batch [1460]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.093723,	
2017-08-04 07:24:38,137 Epoch[44] Batch [1470]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093660,	
2017-08-04 07:24:43,412 Epoch[44] Batch [1480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093653,	
2017-08-04 07:24:46,505 Epoch[44] Train-FCNLogLoss=0.093669
2017-08-04 07:24:46,505 Epoch[44] Time cost=826.253
2017-08-04 07:24:47,958 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0045.params"
2017-08-04 07:24:52,701 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0045.states"
2017-08-04 07:24:59,304 Epoch[45] Batch [10]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.088279,	
2017-08-04 07:25:04,821 Epoch[45] Batch [20]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.089509,	
2017-08-04 07:25:10,270 Epoch[45] Batch [30]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093667,	
2017-08-04 07:25:16,105 Epoch[45] Batch [40]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.094966,	
2017-08-04 07:25:21,916 Epoch[45] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.093803,	
2017-08-04 07:25:27,064 Epoch[45] Batch [60]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094155,	
2017-08-04 07:25:32,240 Epoch[45] Batch [70]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093574,	
2017-08-04 07:25:37,243 Epoch[45] Batch [80]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.094327,	
2017-08-04 07:25:42,603 Epoch[45] Batch [90]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093457,	
2017-08-04 07:25:48,959 Epoch[45] Batch [100]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.093020,	
2017-08-04 07:25:55,055 Epoch[45] Batch [110]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.093338,	
2017-08-04 07:26:00,990 Epoch[45] Batch [120]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093896,	
2017-08-04 07:26:06,557 Epoch[45] Batch [130]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093667,	
2017-08-04 07:26:11,596 Epoch[45] Batch [140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093776,	
2017-08-04 07:26:17,201 Epoch[45] Batch [150]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.093937,	
2017-08-04 07:26:23,150 Epoch[45] Batch [160]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094112,	
2017-08-04 07:26:29,041 Epoch[45] Batch [170]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.094593,	
2017-08-04 07:26:34,791 Epoch[45] Batch [180]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094545,	
2017-08-04 07:26:40,643 Epoch[45] Batch [190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093870,	
2017-08-04 07:26:45,888 Epoch[45] Batch [200]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093855,	
2017-08-04 07:26:51,848 Epoch[45] Batch [210]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.093890,	
2017-08-04 07:26:57,482 Epoch[45] Batch [220]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093897,	
2017-08-04 07:27:03,496 Epoch[45] Batch [230]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.093684,	
2017-08-04 07:27:08,951 Epoch[45] Batch [240]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093844,	
2017-08-04 07:27:14,589 Epoch[45] Batch [250]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.094472,	
2017-08-04 07:27:20,024 Epoch[45] Batch [260]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094476,	
2017-08-04 07:27:25,226 Epoch[45] Batch [270]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094241,	
2017-08-04 07:27:30,422 Epoch[45] Batch [280]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094012,	
2017-08-04 07:27:35,721 Epoch[45] Batch [290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094038,	
2017-08-04 07:27:41,456 Epoch[45] Batch [300]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.094074,	
2017-08-04 07:27:47,342 Epoch[45] Batch [310]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093596,	
2017-08-04 07:27:52,750 Epoch[45] Batch [320]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093404,	
2017-08-04 07:27:58,090 Epoch[45] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093381,	
2017-08-04 07:28:03,330 Epoch[45] Batch [340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093239,	
2017-08-04 07:28:08,964 Epoch[45] Batch [350]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093450,	
2017-08-04 07:28:14,418 Epoch[45] Batch [360]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093457,	
2017-08-04 07:28:19,980 Epoch[45] Batch [370]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093504,	
2017-08-04 07:28:25,980 Epoch[45] Batch [380]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.093330,	
2017-08-04 07:28:31,459 Epoch[45] Batch [390]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093168,	
2017-08-04 07:28:36,913 Epoch[45] Batch [400]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093360,	
2017-08-04 07:28:42,476 Epoch[45] Batch [410]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093441,	
2017-08-04 07:28:47,789 Epoch[45] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093309,	
2017-08-04 07:28:53,516 Epoch[45] Batch [430]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.093062,	
2017-08-04 07:28:59,602 Epoch[45] Batch [440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.093114,	
2017-08-04 07:29:05,252 Epoch[45] Batch [450]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.093145,	
2017-08-04 07:29:10,452 Epoch[45] Batch [460]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093215,	
2017-08-04 07:29:16,381 Epoch[45] Batch [470]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.093311,	
2017-08-04 07:29:21,985 Epoch[45] Batch [480]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.093561,	
2017-08-04 07:29:27,457 Epoch[45] Batch [490]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.093746,	
2017-08-04 07:29:32,918 Epoch[45] Batch [500]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.094019,	
2017-08-04 07:29:38,141 Epoch[45] Batch [510]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093929,	
2017-08-04 07:29:43,444 Epoch[45] Batch [520]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093845,	
2017-08-04 07:29:48,886 Epoch[45] Batch [530]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093653,	
2017-08-04 07:29:53,765 Epoch[45] Batch [540]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.093551,	
2017-08-04 07:29:58,900 Epoch[45] Batch [550]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093581,	
2017-08-04 07:30:04,040 Epoch[45] Batch [560]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093390,	
2017-08-04 07:30:09,351 Epoch[45] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093308,	
2017-08-04 07:30:14,344 Epoch[45] Batch [580]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.093443,	
2017-08-04 07:30:19,624 Epoch[45] Batch [590]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093566,	
2017-08-04 07:30:25,169 Epoch[45] Batch [600]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093592,	
2017-08-04 07:30:30,174 Epoch[45] Batch [610]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.093579,	
2017-08-04 07:30:35,367 Epoch[45] Batch [620]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093516,	
2017-08-04 07:30:41,997 Epoch[45] Batch [630]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.093450,	
2017-08-04 07:30:48,010 Epoch[45] Batch [640]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.093378,	
2017-08-04 07:30:53,181 Epoch[45] Batch [650]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093286,	
2017-08-04 07:30:59,048 Epoch[45] Batch [660]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.093431,	
2017-08-04 07:31:04,645 Epoch[45] Batch [670]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.093366,	
2017-08-04 07:31:09,837 Epoch[45] Batch [680]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093429,	
2017-08-04 07:31:14,962 Epoch[45] Batch [690]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093472,	
2017-08-04 07:31:21,046 Epoch[45] Batch [700]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.093365,	
2017-08-04 07:31:26,764 Epoch[45] Batch [710]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.093521,	
2017-08-04 07:31:32,167 Epoch[45] Batch [720]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093507,	
2017-08-04 07:31:37,404 Epoch[45] Batch [730]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093559,	
2017-08-04 07:31:42,695 Epoch[45] Batch [740]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093609,	
2017-08-04 07:31:48,463 Epoch[45] Batch [750]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.093683,	
2017-08-04 07:31:54,496 Epoch[45] Batch [760]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.093708,	
2017-08-04 07:31:59,894 Epoch[45] Batch [770]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093600,	
2017-08-04 07:32:05,232 Epoch[45] Batch [780]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093570,	
2017-08-04 07:32:11,273 Epoch[45] Batch [790]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093714,	
2017-08-04 07:32:16,904 Epoch[45] Batch [800]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093665,	
2017-08-04 07:32:22,022 Epoch[45] Batch [810]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.093603,	
2017-08-04 07:32:27,389 Epoch[45] Batch [820]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093643,	
2017-08-04 07:32:33,353 Epoch[45] Batch [830]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.093678,	
2017-08-04 07:32:38,930 Epoch[45] Batch [840]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.093723,	
2017-08-04 07:32:44,164 Epoch[45] Batch [850]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093813,	
2017-08-04 07:32:49,452 Epoch[45] Batch [860]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093832,	
2017-08-04 07:32:55,033 Epoch[45] Batch [870]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.093940,	
2017-08-04 07:33:00,359 Epoch[45] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093926,	
2017-08-04 07:33:06,137 Epoch[45] Batch [890]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.094008,	
2017-08-04 07:33:11,804 Epoch[45] Batch [900]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093961,	
2017-08-04 07:33:17,807 Epoch[45] Batch [910]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.093939,	
2017-08-04 07:33:23,741 Epoch[45] Batch [920]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093999,	
2017-08-04 07:33:29,527 Epoch[45] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.094006,	
2017-08-04 07:33:35,512 Epoch[45] Batch [940]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.093960,	
2017-08-04 07:33:40,665 Epoch[45] Batch [950]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093933,	
2017-08-04 07:33:46,177 Epoch[45] Batch [960]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.093945,	
2017-08-04 07:33:51,499 Epoch[45] Batch [970]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094070,	
2017-08-04 07:33:57,117 Epoch[45] Batch [980]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.094106,	
2017-08-04 07:34:02,523 Epoch[45] Batch [990]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.094157,	
2017-08-04 07:34:08,409 Epoch[45] Batch [1000]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.094243,	
2017-08-04 07:34:14,634 Epoch[45] Batch [1010]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.094265,	
2017-08-04 07:34:21,156 Epoch[45] Batch [1020]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.094266,	
2017-08-04 07:34:26,760 Epoch[45] Batch [1030]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.094350,	
2017-08-04 07:34:32,546 Epoch[45] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.094265,	
2017-08-04 07:34:37,694 Epoch[45] Batch [1050]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094226,	
2017-08-04 07:34:43,279 Epoch[45] Batch [1060]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.094148,	
2017-08-04 07:34:48,695 Epoch[45] Batch [1070]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094066,	
2017-08-04 07:34:54,256 Epoch[45] Batch [1080]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.094123,	
2017-08-04 07:34:59,666 Epoch[45] Batch [1090]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094082,	
2017-08-04 07:35:05,100 Epoch[45] Batch [1100]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094105,	
2017-08-04 07:35:10,105 Epoch[45] Batch [1110]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.094060,	
2017-08-04 07:35:15,830 Epoch[45] Batch [1120]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.093931,	
2017-08-04 07:35:20,952 Epoch[45] Batch [1130]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093979,	
2017-08-04 07:35:26,495 Epoch[45] Batch [1140]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.093968,	
2017-08-04 07:35:31,747 Epoch[45] Batch [1150]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093948,	
2017-08-04 07:35:37,107 Epoch[45] Batch [1160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093885,	
2017-08-04 07:35:42,745 Epoch[45] Batch [1170]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093906,	
2017-08-04 07:35:48,100 Epoch[45] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094002,	
2017-08-04 07:35:53,374 Epoch[45] Batch [1190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094058,	
2017-08-04 07:35:59,333 Epoch[45] Batch [1200]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.094029,	
2017-08-04 07:36:05,317 Epoch[45] Batch [1210]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.094047,	
2017-08-04 07:36:11,990 Epoch[45] Batch [1220]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094194,	
2017-08-04 07:36:18,129 Epoch[45] Batch [1230]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.094095,	
2017-08-04 07:36:23,978 Epoch[45] Batch [1240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.094108,	
2017-08-04 07:36:29,903 Epoch[45] Batch [1250]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.094077,	
2017-08-04 07:36:35,201 Epoch[45] Batch [1260]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094059,	
2017-08-04 07:36:41,273 Epoch[45] Batch [1270]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.094056,	
2017-08-04 07:36:46,897 Epoch[45] Batch [1280]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093997,	
2017-08-04 07:36:52,849 Epoch[45] Batch [1290]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094036,	
2017-08-04 07:36:58,568 Epoch[45] Batch [1300]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.093957,	
2017-08-04 07:37:03,811 Epoch[45] Batch [1310]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093996,	
2017-08-04 07:37:09,079 Epoch[45] Batch [1320]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093980,	
2017-08-04 07:37:14,664 Epoch[45] Batch [1330]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093961,	
2017-08-04 07:37:20,168 Epoch[45] Batch [1340]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093975,	
2017-08-04 07:37:25,993 Epoch[45] Batch [1350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.093857,	
2017-08-04 07:37:31,720 Epoch[45] Batch [1360]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.093928,	
2017-08-04 07:37:36,900 Epoch[45] Batch [1370]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093877,	
2017-08-04 07:37:42,387 Epoch[45] Batch [1380]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093856,	
2017-08-04 07:37:47,440 Epoch[45] Batch [1390]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.093765,	
2017-08-04 07:37:52,662 Epoch[45] Batch [1400]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093751,	
2017-08-04 07:37:58,487 Epoch[45] Batch [1410]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.093684,	
2017-08-04 07:38:04,216 Epoch[45] Batch [1420]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.093755,	
2017-08-04 07:38:09,993 Epoch[45] Batch [1430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093763,	
2017-08-04 07:38:15,670 Epoch[45] Batch [1440]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.093902,	
2017-08-04 07:38:21,313 Epoch[45] Batch [1450]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.093856,	
2017-08-04 07:38:27,003 Epoch[45] Batch [1460]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.093818,	
2017-08-04 07:38:32,183 Epoch[45] Batch [1470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093918,	
2017-08-04 07:38:36,699 Epoch[45] Batch [1480]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.093893,	
2017-08-04 07:38:40,015 Epoch[45] Train-FCNLogLoss=0.093869
2017-08-04 07:38:40,015 Epoch[45] Time cost=827.314
2017-08-04 07:38:40,978 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0046.params"
2017-08-04 07:38:46,008 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0046.states"
2017-08-04 07:38:51,856 Epoch[46] Batch [10]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.101321,	
2017-08-04 07:38:56,697 Epoch[46] Batch [20]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.100478,	
2017-08-04 07:39:02,662 Epoch[46] Batch [30]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.096737,	
2017-08-04 07:39:08,466 Epoch[46] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097320,	
2017-08-04 07:39:14,445 Epoch[46] Batch [50]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.096918,	
2017-08-04 07:39:20,074 Epoch[46] Batch [60]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.097048,	
2017-08-04 07:39:26,059 Epoch[46] Batch [70]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.096854,	
2017-08-04 07:39:32,050 Epoch[46] Batch [80]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.097064,	
2017-08-04 07:39:37,898 Epoch[46] Batch [90]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.096936,	
2017-08-04 07:39:43,271 Epoch[46] Batch [100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095974,	
2017-08-04 07:39:48,824 Epoch[46] Batch [110]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.095710,	
2017-08-04 07:39:54,708 Epoch[46] Batch [120]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.094525,	
2017-08-04 07:40:00,132 Epoch[46] Batch [130]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.093958,	
2017-08-04 07:40:05,542 Epoch[46] Batch [140]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.094339,	
2017-08-04 07:40:10,812 Epoch[46] Batch [150]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094213,	
2017-08-04 07:40:17,073 Epoch[46] Batch [160]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.094515,	
2017-08-04 07:40:22,777 Epoch[46] Batch [170]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.094678,	
2017-08-04 07:40:28,996 Epoch[46] Batch [180]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.094622,	
2017-08-04 07:40:34,830 Epoch[46] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.094245,	
2017-08-04 07:40:40,682 Epoch[46] Batch [200]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.094762,	
2017-08-04 07:40:45,961 Epoch[46] Batch [210]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094440,	
2017-08-04 07:40:51,709 Epoch[46] Batch [220]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094472,	
2017-08-04 07:40:56,977 Epoch[46] Batch [230]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094572,	
2017-08-04 07:41:02,113 Epoch[46] Batch [240]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.094473,	
2017-08-04 07:41:07,602 Epoch[46] Batch [250]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.094495,	
2017-08-04 07:41:13,131 Epoch[46] Batch [260]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.094646,	
2017-08-04 07:41:18,545 Epoch[46] Batch [270]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094651,	
2017-08-04 07:41:24,510 Epoch[46] Batch [280]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.094638,	
2017-08-04 07:41:29,549 Epoch[46] Batch [290]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094688,	
2017-08-04 07:41:35,134 Epoch[46] Batch [300]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.094839,	
2017-08-04 07:41:41,131 Epoch[46] Batch [310]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.095063,	
2017-08-04 07:41:46,928 Epoch[46] Batch [320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.094586,	
2017-08-04 07:41:52,857 Epoch[46] Batch [330]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.094363,	
2017-08-04 07:41:58,596 Epoch[46] Batch [340]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.094298,	
2017-08-04 07:42:03,840 Epoch[46] Batch [350]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094092,	
2017-08-04 07:42:09,354 Epoch[46] Batch [360]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094161,	
2017-08-04 07:42:14,123 Epoch[46] Batch [370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094532,	
2017-08-04 07:42:19,038 Epoch[46] Batch [380]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.094327,	
2017-08-04 07:42:24,756 Epoch[46] Batch [390]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.094317,	
2017-08-04 07:42:30,971 Epoch[46] Batch [400]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.094149,	
2017-08-04 07:42:36,277 Epoch[46] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094063,	
2017-08-04 07:42:41,536 Epoch[46] Batch [420]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094172,	
2017-08-04 07:42:47,150 Epoch[46] Batch [430]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.094139,	
2017-08-04 07:42:52,867 Epoch[46] Batch [440]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.093901,	
2017-08-04 07:42:58,374 Epoch[46] Batch [450]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.093848,	
2017-08-04 07:43:07,168 Epoch[46] Batch [460]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.093820,	
2017-08-04 07:43:26,046 Epoch[46] Batch [470]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.094002,	
2017-08-04 07:43:41,355 Epoch[46] Batch [480]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.093956,	
2017-08-04 07:43:53,828 Epoch[46] Batch [490]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.094036,	
2017-08-04 07:44:14,014 Epoch[46] Batch [500]	Speed: 1.98 samples/sec	Train-FCNLogLoss=0.093885,	
2017-08-04 07:44:32,687 Epoch[46] Batch [510]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.093767,	
2017-08-04 07:44:51,280 Epoch[46] Batch [520]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.093649,	
2017-08-04 07:45:11,708 Epoch[46] Batch [530]	Speed: 1.96 samples/sec	Train-FCNLogLoss=0.093693,	
2017-08-04 07:45:28,198 Epoch[46] Batch [540]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.093912,	
2017-08-04 07:45:44,739 Epoch[46] Batch [550]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.094091,	
2017-08-04 07:46:01,292 Epoch[46] Batch [560]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.094003,	
2017-08-04 07:46:19,129 Epoch[46] Batch [570]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.094190,	
2017-08-04 07:46:39,269 Epoch[46] Batch [580]	Speed: 1.99 samples/sec	Train-FCNLogLoss=0.094145,	
2017-08-04 07:46:53,458 Epoch[46] Batch [590]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.094116,	
2017-08-04 07:47:12,478 Epoch[46] Batch [600]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.094363,	
2017-08-04 07:47:25,601 Epoch[46] Batch [610]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.094286,	
2017-08-04 07:47:34,395 Epoch[46] Batch [620]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.094100,	
2017-08-04 07:47:39,591 Epoch[46] Batch [630]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093949,	
2017-08-04 07:47:44,935 Epoch[46] Batch [640]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093947,	
2017-08-04 07:47:50,370 Epoch[46] Batch [650]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093808,	
2017-08-04 07:47:55,906 Epoch[46] Batch [660]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093893,	
2017-08-04 07:48:01,358 Epoch[46] Batch [670]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.094044,	
2017-08-04 07:48:06,485 Epoch[46] Batch [680]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.093984,	
2017-08-04 07:48:11,360 Epoch[46] Batch [690]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.093811,	
2017-08-04 07:48:16,396 Epoch[46] Batch [700]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093828,	
2017-08-04 07:48:21,590 Epoch[46] Batch [710]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093882,	
2017-08-04 07:48:26,407 Epoch[46] Batch [720]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.093763,	
2017-08-04 07:48:31,657 Epoch[46] Batch [730]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093683,	
2017-08-04 07:48:37,005 Epoch[46] Batch [740]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093689,	
2017-08-04 07:48:41,833 Epoch[46] Batch [750]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.093600,	
2017-08-04 07:48:47,091 Epoch[46] Batch [760]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093606,	
2017-08-04 07:48:52,464 Epoch[46] Batch [770]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093687,	
2017-08-04 07:48:57,818 Epoch[46] Batch [780]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093655,	
2017-08-04 07:49:02,732 Epoch[46] Batch [790]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093587,	
2017-08-04 07:49:07,891 Epoch[46] Batch [800]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093510,	
2017-08-04 07:49:13,013 Epoch[46] Batch [810]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093427,	
2017-08-04 07:49:18,055 Epoch[46] Batch [820]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.093518,	
2017-08-04 07:49:22,980 Epoch[46] Batch [830]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.093510,	
2017-08-04 07:49:28,430 Epoch[46] Batch [840]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093496,	
2017-08-04 07:49:33,621 Epoch[46] Batch [850]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093560,	
2017-08-04 07:49:38,992 Epoch[46] Batch [860]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093657,	
2017-08-04 07:49:44,134 Epoch[46] Batch [870]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093644,	
2017-08-04 07:49:49,072 Epoch[46] Batch [880]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093740,	
2017-08-04 07:49:54,447 Epoch[46] Batch [890]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093741,	
2017-08-04 07:49:59,547 Epoch[46] Batch [900]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.093787,	
2017-08-04 07:50:04,896 Epoch[46] Batch [910]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093686,	
2017-08-04 07:50:10,251 Epoch[46] Batch [920]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093639,	
2017-08-04 07:50:15,637 Epoch[46] Batch [930]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093647,	
2017-08-04 07:50:21,121 Epoch[46] Batch [940]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093687,	
2017-08-04 07:50:26,775 Epoch[46] Batch [950]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.093747,	
2017-08-04 07:50:31,784 Epoch[46] Batch [960]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.093702,	
2017-08-04 07:50:37,015 Epoch[46] Batch [970]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093696,	
2017-08-04 07:50:42,220 Epoch[46] Batch [980]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093656,	
2017-08-04 07:50:47,459 Epoch[46] Batch [990]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093688,	
2017-08-04 07:50:52,601 Epoch[46] Batch [1000]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093627,	
2017-08-04 07:50:58,026 Epoch[46] Batch [1010]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.093574,	
2017-08-04 07:51:03,176 Epoch[46] Batch [1020]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093485,	
2017-08-04 07:51:08,432 Epoch[46] Batch [1030]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093586,	
2017-08-04 07:51:13,377 Epoch[46] Batch [1040]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.093610,	
2017-08-04 07:51:18,515 Epoch[46] Batch [1050]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093564,	
2017-08-04 07:51:23,579 Epoch[46] Batch [1060]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.093564,	
2017-08-04 07:51:28,766 Epoch[46] Batch [1070]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093537,	
2017-08-04 07:51:33,928 Epoch[46] Batch [1080]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093518,	
2017-08-04 07:51:38,807 Epoch[46] Batch [1090]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.093473,	
2017-08-04 07:51:44,041 Epoch[46] Batch [1100]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093383,	
2017-08-04 07:51:49,179 Epoch[46] Batch [1110]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093313,	
2017-08-04 07:51:54,799 Epoch[46] Batch [1120]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.093331,	
2017-08-04 07:52:00,386 Epoch[46] Batch [1130]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093287,	
2017-08-04 07:52:05,408 Epoch[46] Batch [1140]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093281,	
2017-08-04 07:52:10,593 Epoch[46] Batch [1150]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093363,	
2017-08-04 07:52:15,897 Epoch[46] Batch [1160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093386,	
2017-08-04 07:52:21,081 Epoch[46] Batch [1170]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093399,	
2017-08-04 07:52:25,973 Epoch[46] Batch [1180]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093388,	
2017-08-04 07:52:30,923 Epoch[46] Batch [1190]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.093418,	
2017-08-04 07:52:35,942 Epoch[46] Batch [1200]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093428,	
2017-08-04 07:52:40,958 Epoch[46] Batch [1210]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093378,	
2017-08-04 07:52:45,957 Epoch[46] Batch [1220]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093412,	
2017-08-04 07:52:50,896 Epoch[46] Batch [1230]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093423,	
2017-08-04 07:52:56,114 Epoch[46] Batch [1240]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.093430,	
2017-08-04 07:53:01,493 Epoch[46] Batch [1250]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093390,	
2017-08-04 07:53:06,795 Epoch[46] Batch [1260]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093420,	
2017-08-04 07:53:11,843 Epoch[46] Batch [1270]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.093424,	
2017-08-04 07:53:16,882 Epoch[46] Batch [1280]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093408,	
2017-08-04 07:53:21,736 Epoch[46] Batch [1290]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.093327,	
2017-08-04 07:53:26,819 Epoch[46] Batch [1300]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093324,	
2017-08-04 07:53:31,885 Epoch[46] Batch [1310]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.093255,	
2017-08-04 07:53:37,306 Epoch[46] Batch [1320]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.093218,	
2017-08-04 07:53:42,557 Epoch[46] Batch [1330]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093283,	
2017-08-04 07:53:47,836 Epoch[46] Batch [1340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093280,	
2017-08-04 07:53:52,834 Epoch[46] Batch [1350]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093260,	
2017-08-04 07:53:58,072 Epoch[46] Batch [1360]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093308,	
2017-08-04 07:54:03,577 Epoch[46] Batch [1370]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093324,	
2017-08-04 07:54:08,346 Epoch[46] Batch [1380]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.093376,	
2017-08-04 07:54:13,125 Epoch[46] Batch [1390]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.093469,	
2017-08-04 07:54:18,214 Epoch[46] Batch [1400]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.093463,	
2017-08-04 07:54:23,227 Epoch[46] Batch [1410]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.093454,	
2017-08-04 07:54:28,055 Epoch[46] Batch [1420]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.093523,	
2017-08-04 07:54:33,171 Epoch[46] Batch [1430]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.093540,	
2017-08-04 07:54:38,245 Epoch[46] Batch [1440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.093497,	
2017-08-04 07:54:43,411 Epoch[46] Batch [1450]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093477,	
2017-08-04 07:54:48,482 Epoch[46] Batch [1460]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093491,	
2017-08-04 07:54:53,522 Epoch[46] Batch [1470]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093500,	
2017-08-04 07:54:58,388 Epoch[46] Batch [1480]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.093492,	
2017-08-04 07:55:01,679 Epoch[46] Train-FCNLogLoss=0.093553
2017-08-04 07:55:01,679 Epoch[46] Time cost=975.670
2017-08-04 07:55:03,149 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0047.params"
2017-08-04 07:55:07,314 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0047.states"
2017-08-04 07:55:13,001 Epoch[47] Batch [10]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089649,	
2017-08-04 07:55:17,962 Epoch[47] Batch [20]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088590,	
2017-08-04 07:55:23,402 Epoch[47] Batch [30]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087656,	
2017-08-04 07:55:28,530 Epoch[47] Batch [40]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086104,	
2017-08-04 07:55:33,556 Epoch[47] Batch [50]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.085852,	
2017-08-04 07:55:38,805 Epoch[47] Batch [60]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090242,	
2017-08-04 07:55:44,115 Epoch[47] Batch [70]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091264,	
2017-08-04 07:55:48,920 Epoch[47] Batch [80]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091682,	
2017-08-04 07:55:54,194 Epoch[47] Batch [90]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091158,	
2017-08-04 07:55:59,146 Epoch[47] Batch [100]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.091832,	
2017-08-04 07:56:04,550 Epoch[47] Batch [110]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092123,	
2017-08-04 07:56:09,494 Epoch[47] Batch [120]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.091423,	
2017-08-04 07:56:14,426 Epoch[47] Batch [130]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.091553,	
2017-08-04 07:56:19,669 Epoch[47] Batch [140]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.091305,	
2017-08-04 07:56:24,757 Epoch[47] Batch [150]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.091635,	
2017-08-04 07:56:29,577 Epoch[47] Batch [160]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.091365,	
2017-08-04 07:56:34,504 Epoch[47] Batch [170]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.090979,	
2017-08-04 07:56:39,226 Epoch[47] Batch [180]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091202,	
2017-08-04 07:56:44,320 Epoch[47] Batch [190]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.091217,	
2017-08-04 07:56:49,352 Epoch[47] Batch [200]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.091258,	
2017-08-04 07:56:54,280 Epoch[47] Batch [210]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.091264,	
2017-08-04 07:56:59,535 Epoch[47] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.091256,	
2017-08-04 07:57:04,358 Epoch[47] Batch [230]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.091089,	
2017-08-04 07:57:10,069 Epoch[47] Batch [240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.091031,	
2017-08-04 07:57:15,206 Epoch[47] Batch [250]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090922,	
2017-08-04 07:57:20,517 Epoch[47] Batch [260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091226,	
2017-08-04 07:57:25,728 Epoch[47] Batch [270]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.091347,	
2017-08-04 07:57:31,250 Epoch[47] Batch [280]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.091243,	
2017-08-04 07:57:36,272 Epoch[47] Batch [290]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.091636,	
2017-08-04 07:57:41,791 Epoch[47] Batch [300]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.092004,	
2017-08-04 07:57:46,900 Epoch[47] Batch [310]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.092043,	
2017-08-04 07:57:52,506 Epoch[47] Batch [320]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.092315,	
2017-08-04 07:57:57,810 Epoch[47] Batch [330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092276,	
2017-08-04 07:58:03,145 Epoch[47] Batch [340]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092119,	
2017-08-04 07:58:08,515 Epoch[47] Batch [350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092356,	
2017-08-04 07:58:13,902 Epoch[47] Batch [360]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092569,	
2017-08-04 07:58:19,074 Epoch[47] Batch [370]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092373,	
2017-08-04 07:58:24,071 Epoch[47] Batch [380]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092317,	
2017-08-04 07:58:29,274 Epoch[47] Batch [390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092428,	
2017-08-04 07:58:34,637 Epoch[47] Batch [400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092167,	
2017-08-04 07:58:39,708 Epoch[47] Batch [410]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092015,	
2017-08-04 07:58:45,003 Epoch[47] Batch [420]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091930,	
2017-08-04 07:58:50,351 Epoch[47] Batch [430]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091895,	
2017-08-04 07:58:55,582 Epoch[47] Batch [440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.092066,	
2017-08-04 07:59:00,944 Epoch[47] Batch [450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092046,	
2017-08-04 07:59:06,320 Epoch[47] Batch [460]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091813,	
2017-08-04 07:59:11,378 Epoch[47] Batch [470]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.091816,	
2017-08-04 07:59:17,078 Epoch[47] Batch [480]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.091929,	
2017-08-04 07:59:22,045 Epoch[47] Batch [490]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.091991,	
2017-08-04 07:59:26,967 Epoch[47] Batch [500]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.091993,	
2017-08-04 07:59:31,913 Epoch[47] Batch [510]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.091901,	
2017-08-04 07:59:37,250 Epoch[47] Batch [520]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091981,	
2017-08-04 07:59:42,588 Epoch[47] Batch [530]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091849,	
2017-08-04 07:59:47,830 Epoch[47] Batch [540]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.091850,	
2017-08-04 07:59:52,912 Epoch[47] Batch [550]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.091829,	
2017-08-04 07:59:58,182 Epoch[47] Batch [560]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.091942,	
2017-08-04 08:00:03,912 Epoch[47] Batch [570]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.092048,	
2017-08-04 08:00:09,022 Epoch[47] Batch [580]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.092181,	
2017-08-04 08:00:14,054 Epoch[47] Batch [590]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.092121,	
2017-08-04 08:00:19,444 Epoch[47] Batch [600]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092115,	
2017-08-04 08:00:24,402 Epoch[47] Batch [610]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092011,	
2017-08-04 08:00:29,426 Epoch[47] Batch [620]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092118,	
2017-08-04 08:00:34,474 Epoch[47] Batch [630]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092238,	
2017-08-04 08:00:39,565 Epoch[47] Batch [640]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092143,	
2017-08-04 08:00:44,499 Epoch[47] Batch [650]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.092141,	
2017-08-04 08:00:49,676 Epoch[47] Batch [660]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092070,	
2017-08-04 08:00:55,057 Epoch[47] Batch [670]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092154,	
2017-08-04 08:00:59,888 Epoch[47] Batch [680]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092301,	
2017-08-04 08:01:05,042 Epoch[47] Batch [690]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092323,	
2017-08-04 08:01:10,212 Epoch[47] Batch [700]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092263,	
2017-08-04 08:01:15,877 Epoch[47] Batch [710]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.092150,	
2017-08-04 08:01:21,054 Epoch[47] Batch [720]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092124,	
2017-08-04 08:01:25,804 Epoch[47] Batch [730]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092076,	
2017-08-04 08:01:31,030 Epoch[47] Batch [740]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.092134,	
2017-08-04 08:01:36,078 Epoch[47] Batch [750]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.092142,	
2017-08-04 08:01:41,800 Epoch[47] Batch [760]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.092084,	
2017-08-04 08:01:47,177 Epoch[47] Batch [770]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092084,	
2017-08-04 08:01:52,345 Epoch[47] Batch [780]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092108,	
2017-08-04 08:01:57,441 Epoch[47] Batch [790]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092042,	
2017-08-04 08:02:02,751 Epoch[47] Batch [800]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092085,	
2017-08-04 08:02:07,912 Epoch[47] Batch [810]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092164,	
2017-08-04 08:02:13,168 Epoch[47] Batch [820]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092140,	
2017-08-04 08:02:18,714 Epoch[47] Batch [830]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.092159,	
2017-08-04 08:02:24,166 Epoch[47] Batch [840]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092084,	
2017-08-04 08:02:29,613 Epoch[47] Batch [850]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092032,	
2017-08-04 08:02:34,451 Epoch[47] Batch [860]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092169,	
2017-08-04 08:02:39,715 Epoch[47] Batch [870]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092235,	
2017-08-04 08:02:44,865 Epoch[47] Batch [880]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.092124,	
2017-08-04 08:02:49,982 Epoch[47] Batch [890]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.092237,	
2017-08-04 08:02:55,081 Epoch[47] Batch [900]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092384,	
2017-08-04 08:02:59,729 Epoch[47] Batch [910]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092383,	
2017-08-04 08:03:04,310 Epoch[47] Batch [920]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092484,	
2017-08-04 08:03:08,872 Epoch[47] Batch [930]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092429,	
2017-08-04 08:03:13,779 Epoch[47] Batch [940]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.092491,	
2017-08-04 08:03:18,608 Epoch[47] Batch [950]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092501,	
2017-08-04 08:03:24,267 Epoch[47] Batch [960]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.092502,	
2017-08-04 08:03:29,752 Epoch[47] Batch [970]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092615,	
2017-08-04 08:03:35,085 Epoch[47] Batch [980]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092759,	
2017-08-04 08:03:40,299 Epoch[47] Batch [990]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.092815,	
2017-08-04 08:03:45,743 Epoch[47] Batch [1000]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.092742,	
2017-08-04 08:03:50,773 Epoch[47] Batch [1010]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.092844,	
2017-08-04 08:03:56,012 Epoch[47] Batch [1020]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.092917,	
2017-08-04 08:04:01,464 Epoch[47] Batch [1030]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092852,	
2017-08-04 08:04:06,301 Epoch[47] Batch [1040]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092767,	
2017-08-04 08:04:11,056 Epoch[47] Batch [1050]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092807,	
2017-08-04 08:04:24,997 Epoch[47] Batch [1060]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.092762,	
2017-08-04 08:04:43,292 Epoch[47] Batch [1070]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.092857,	
2017-08-04 08:04:58,357 Epoch[47] Batch [1080]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.092854,	
2017-08-04 08:05:04,423 Epoch[47] Batch [1090]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.092853,	
2017-08-04 08:05:09,959 Epoch[47] Batch [1100]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.092865,	
2017-08-04 08:05:15,141 Epoch[47] Batch [1110]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092944,	
2017-08-04 08:05:20,144 Epoch[47] Batch [1120]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092993,	
2017-08-04 08:05:24,952 Epoch[47] Batch [1130]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092997,	
2017-08-04 08:05:29,991 Epoch[47] Batch [1140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093054,	
2017-08-04 08:05:34,934 Epoch[47] Batch [1150]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.093032,	
2017-08-04 08:05:40,016 Epoch[47] Batch [1160]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092980,	
2017-08-04 08:05:45,363 Epoch[47] Batch [1170]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092978,	
2017-08-04 08:05:50,658 Epoch[47] Batch [1180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092951,	
2017-08-04 08:05:56,004 Epoch[47] Batch [1190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092994,	
2017-08-04 08:06:01,194 Epoch[47] Batch [1200]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093031,	
2017-08-04 08:06:06,580 Epoch[47] Batch [1210]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092983,	
2017-08-04 08:06:11,612 Epoch[47] Batch [1220]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.092943,	
2017-08-04 08:06:16,797 Epoch[47] Batch [1230]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092976,	
2017-08-04 08:06:22,084 Epoch[47] Batch [1240]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092967,	
2017-08-04 08:06:27,130 Epoch[47] Batch [1250]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.092987,	
2017-08-04 08:06:32,246 Epoch[47] Batch [1260]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.093009,	
2017-08-04 08:06:37,684 Epoch[47] Batch [1270]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.092970,	
2017-08-04 08:06:42,760 Epoch[47] Batch [1280]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.092962,	
2017-08-04 08:06:47,973 Epoch[47] Batch [1290]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.092935,	
2017-08-04 08:06:52,877 Epoch[47] Batch [1300]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092942,	
2017-08-04 08:06:58,205 Epoch[47] Batch [1310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092923,	
2017-08-04 08:07:03,164 Epoch[47] Batch [1320]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092863,	
2017-08-04 08:07:08,375 Epoch[47] Batch [1330]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.092857,	
2017-08-04 08:07:14,000 Epoch[47] Batch [1340]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.092818,	
2017-08-04 08:07:19,456 Epoch[47] Batch [1350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.092854,	
2017-08-04 08:07:24,544 Epoch[47] Batch [1360]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092943,	
2017-08-04 08:07:29,541 Epoch[47] Batch [1370]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092958,	
2017-08-04 08:07:34,991 Epoch[47] Batch [1380]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092939,	
2017-08-04 08:07:40,173 Epoch[47] Batch [1390]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092955,	
2017-08-04 08:07:45,501 Epoch[47] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092873,	
2017-08-04 08:07:50,570 Epoch[47] Batch [1410]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092867,	
2017-08-04 08:07:55,886 Epoch[47] Batch [1420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092877,	
2017-08-04 08:08:00,917 Epoch[47] Batch [1430]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.092925,	
2017-08-04 08:08:05,950 Epoch[47] Batch [1440]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.092875,	
2017-08-04 08:08:10,904 Epoch[47] Batch [1450]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.092911,	
2017-08-04 08:08:16,468 Epoch[47] Batch [1460]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.092904,	
2017-08-04 08:08:21,821 Epoch[47] Batch [1470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092928,	
2017-08-04 08:08:27,078 Epoch[47] Batch [1480]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092898,	
2017-08-04 08:08:30,440 Epoch[47] Train-FCNLogLoss=0.092942
2017-08-04 08:08:30,440 Epoch[47] Time cost=803.125
2017-08-04 08:08:31,437 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0048.params"
2017-08-04 08:08:35,019 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0048.states"
2017-08-04 08:08:40,518 Epoch[48] Batch [10]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.098072,	
2017-08-04 08:08:45,192 Epoch[48] Batch [20]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.094145,	
2017-08-04 08:08:50,072 Epoch[48] Batch [30]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.095853,	
2017-08-04 08:08:55,031 Epoch[48] Batch [40]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.094778,	
2017-08-04 08:09:00,068 Epoch[48] Batch [50]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093340,	
2017-08-04 08:09:05,111 Epoch[48] Batch [60]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.091914,	
2017-08-04 08:09:10,319 Epoch[48] Batch [70]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.091248,	
2017-08-04 08:09:15,389 Epoch[48] Batch [80]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.091119,	
2017-08-04 08:09:20,016 Epoch[48] Batch [90]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091796,	
2017-08-04 08:09:24,796 Epoch[48] Batch [100]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.093113,	
2017-08-04 08:09:29,724 Epoch[48] Batch [110]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.093114,	
2017-08-04 08:09:34,585 Epoch[48] Batch [120]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.092897,	
2017-08-04 08:09:39,553 Epoch[48] Batch [130]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.092966,	
2017-08-04 08:09:44,250 Epoch[48] Batch [140]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.093036,	
2017-08-04 08:09:48,910 Epoch[48] Batch [150]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092472,	
2017-08-04 08:09:53,961 Epoch[48] Batch [160]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092101,	
2017-08-04 08:09:58,731 Epoch[48] Batch [170]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092633,	
2017-08-04 08:10:03,595 Epoch[48] Batch [180]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092591,	
2017-08-04 08:10:08,436 Epoch[48] Batch [190]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092884,	
2017-08-04 08:10:13,337 Epoch[48] Batch [200]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.093075,	
2017-08-04 08:10:18,343 Epoch[48] Batch [210]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.093006,	
2017-08-04 08:10:23,781 Epoch[48] Batch [220]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.092559,	
2017-08-04 08:10:28,938 Epoch[48] Batch [230]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092262,	
2017-08-04 08:10:33,807 Epoch[48] Batch [240]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092449,	
2017-08-04 08:10:38,246 Epoch[48] Batch [250]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.092287,	
2017-08-04 08:10:42,945 Epoch[48] Batch [260]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092274,	
2017-08-04 08:10:47,778 Epoch[48] Batch [270]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092366,	
2017-08-04 08:10:52,828 Epoch[48] Batch [280]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092173,	
2017-08-04 08:10:58,021 Epoch[48] Batch [290]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092541,	
2017-08-04 08:11:03,029 Epoch[48] Batch [300]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.092839,	
2017-08-04 08:11:08,060 Epoch[48] Batch [310]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.092782,	
2017-08-04 08:11:13,378 Epoch[48] Batch [320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092992,	
2017-08-04 08:11:18,637 Epoch[48] Batch [330]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093034,	
2017-08-04 08:11:23,962 Epoch[48] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092922,	
2017-08-04 08:11:29,181 Epoch[48] Batch [350]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.093466,	
2017-08-04 08:11:34,563 Epoch[48] Batch [360]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093595,	
2017-08-04 08:11:39,902 Epoch[48] Batch [370]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093702,	
2017-08-04 08:11:44,885 Epoch[48] Batch [380]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.093480,	
2017-08-04 08:11:49,984 Epoch[48] Batch [390]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093627,	
2017-08-04 08:11:54,937 Epoch[48] Batch [400]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.093474,	
2017-08-04 08:12:00,374 Epoch[48] Batch [410]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093409,	
2017-08-04 08:12:05,354 Epoch[48] Batch [420]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.093334,	
2017-08-04 08:12:10,317 Epoch[48] Batch [430]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.093564,	
2017-08-04 08:12:15,226 Epoch[48] Batch [440]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.093656,	
2017-08-04 08:12:20,001 Epoch[48] Batch [450]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.093619,	
2017-08-04 08:12:25,062 Epoch[48] Batch [460]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.093676,	
2017-08-04 08:12:29,850 Epoch[48] Batch [470]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.093678,	
2017-08-04 08:12:34,921 Epoch[48] Batch [480]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093575,	
2017-08-04 08:12:40,154 Epoch[48] Batch [490]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093607,	
2017-08-04 08:12:45,240 Epoch[48] Batch [500]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093450,	
2017-08-04 08:12:50,533 Epoch[48] Batch [510]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093453,	
2017-08-04 08:12:55,451 Epoch[48] Batch [520]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.093330,	
2017-08-04 08:13:00,940 Epoch[48] Batch [530]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093261,	
2017-08-04 08:13:06,073 Epoch[48] Batch [540]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093346,	
2017-08-04 08:13:11,310 Epoch[48] Batch [550]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093274,	
2017-08-04 08:13:16,276 Epoch[48] Batch [560]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.093362,	
2017-08-04 08:13:21,375 Epoch[48] Batch [570]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093374,	
2017-08-04 08:13:26,441 Epoch[48] Batch [580]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.093163,	
2017-08-04 08:13:31,348 Epoch[48] Batch [590]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.093365,	
2017-08-04 08:13:36,562 Epoch[48] Batch [600]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.093417,	
2017-08-04 08:13:42,151 Epoch[48] Batch [610]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093387,	
2017-08-04 08:13:46,847 Epoch[48] Batch [620]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.093453,	
2017-08-04 08:13:51,979 Epoch[48] Batch [630]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.093399,	
2017-08-04 08:13:57,068 Epoch[48] Batch [640]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.093397,	
2017-08-04 08:14:02,312 Epoch[48] Batch [650]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093315,	
2017-08-04 08:14:07,413 Epoch[48] Batch [660]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.093361,	
2017-08-04 08:14:12,559 Epoch[48] Batch [670]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093367,	
2017-08-04 08:14:18,160 Epoch[48] Batch [680]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.093632,	
2017-08-04 08:14:23,627 Epoch[48] Batch [690]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.093602,	
2017-08-04 08:14:28,957 Epoch[48] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093683,	
2017-08-04 08:14:33,988 Epoch[48] Batch [710]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.093677,	
2017-08-04 08:14:39,445 Epoch[48] Batch [720]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093537,	
2017-08-04 08:14:44,337 Epoch[48] Batch [730]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093573,	
2017-08-04 08:14:49,455 Epoch[48] Batch [740]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.093574,	
2017-08-04 08:14:54,455 Epoch[48] Batch [750]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093636,	
2017-08-04 08:14:59,501 Epoch[48] Batch [760]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.093602,	
2017-08-04 08:15:04,773 Epoch[48] Batch [770]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093660,	
2017-08-04 08:15:09,749 Epoch[48] Batch [780]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.093588,	
2017-08-04 08:15:14,425 Epoch[48] Batch [790]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.093532,	
2017-08-04 08:15:19,629 Epoch[48] Batch [800]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093650,	
2017-08-04 08:15:25,173 Epoch[48] Batch [810]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.093743,	
2017-08-04 08:15:30,195 Epoch[48] Batch [820]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093574,	
2017-08-04 08:15:35,112 Epoch[48] Batch [830]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093583,	
2017-08-04 08:15:40,181 Epoch[48] Batch [840]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093585,	
2017-08-04 08:15:45,562 Epoch[48] Batch [850]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093800,	
2017-08-04 08:15:51,003 Epoch[48] Batch [860]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093845,	
2017-08-04 08:15:56,913 Epoch[48] Batch [870]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.093800,	
2017-08-04 08:16:02,231 Epoch[48] Batch [880]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.093701,	
2017-08-04 08:16:06,990 Epoch[48] Batch [890]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.093566,	
2017-08-04 08:16:12,001 Epoch[48] Batch [900]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.093598,	
2017-08-04 08:16:17,194 Epoch[48] Batch [910]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093417,	
2017-08-04 08:16:22,883 Epoch[48] Batch [920]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.093417,	
2017-08-04 08:16:27,981 Epoch[48] Batch [930]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093386,	
2017-08-04 08:16:33,279 Epoch[48] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093379,	
2017-08-04 08:16:38,564 Epoch[48] Batch [950]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093366,	
2017-08-04 08:16:43,873 Epoch[48] Batch [960]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093363,	
2017-08-04 08:16:48,864 Epoch[48] Batch [970]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093360,	
2017-08-04 08:16:54,302 Epoch[48] Batch [980]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093328,	
2017-08-04 08:16:59,786 Epoch[48] Batch [990]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093387,	
2017-08-04 08:17:04,862 Epoch[48] Batch [1000]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.093407,	
2017-08-04 08:17:09,690 Epoch[48] Batch [1010]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.093381,	
2017-08-04 08:17:15,248 Epoch[48] Batch [1020]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093428,	
2017-08-04 08:17:20,466 Epoch[48] Batch [1030]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.093359,	
2017-08-04 08:17:25,252 Epoch[48] Batch [1040]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.093327,	
2017-08-04 08:17:30,056 Epoch[48] Batch [1050]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.093273,	
2017-08-04 08:17:35,092 Epoch[48] Batch [1060]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093237,	
2017-08-04 08:17:39,990 Epoch[48] Batch [1070]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.093190,	
2017-08-04 08:17:44,894 Epoch[48] Batch [1080]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.093099,	
2017-08-04 08:17:50,000 Epoch[48] Batch [1090]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.093115,	
2017-08-04 08:17:55,036 Epoch[48] Batch [1100]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093136,	
2017-08-04 08:18:00,660 Epoch[48] Batch [1110]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093182,	
2017-08-04 08:18:06,062 Epoch[48] Batch [1120]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093132,	
2017-08-04 08:18:11,572 Epoch[48] Batch [1130]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.093184,	
2017-08-04 08:18:16,492 Epoch[48] Batch [1140]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.093164,	
2017-08-04 08:18:21,481 Epoch[48] Batch [1150]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093120,	
2017-08-04 08:18:26,212 Epoch[48] Batch [1160]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.093152,	
2017-08-04 08:18:31,823 Epoch[48] Batch [1170]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.093122,	
2017-08-04 08:18:36,744 Epoch[48] Batch [1180]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.093039,	
2017-08-04 08:18:41,642 Epoch[48] Batch [1190]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.093080,	
2017-08-04 08:18:46,722 Epoch[48] Batch [1200]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093078,	
2017-08-04 08:18:52,002 Epoch[48] Batch [1210]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093039,	
2017-08-04 08:18:57,786 Epoch[48] Batch [1220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093051,	
2017-08-04 08:19:03,096 Epoch[48] Batch [1230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093020,	
2017-08-04 08:19:07,866 Epoch[48] Batch [1240]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.093058,	
2017-08-04 08:19:12,807 Epoch[48] Batch [1250]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093076,	
2017-08-04 08:19:17,904 Epoch[48] Batch [1260]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093077,	
2017-08-04 08:19:22,690 Epoch[48] Batch [1270]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.093096,	
2017-08-04 08:19:27,848 Epoch[48] Batch [1280]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093029,	
2017-08-04 08:19:32,935 Epoch[48] Batch [1290]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092995,	
2017-08-04 08:19:37,817 Epoch[48] Batch [1300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092995,	
2017-08-04 08:19:43,099 Epoch[48] Batch [1310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093013,	
2017-08-04 08:19:47,947 Epoch[48] Batch [1320]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.093036,	
2017-08-04 08:19:52,922 Epoch[48] Batch [1330]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.093013,	
2017-08-04 08:19:57,941 Epoch[48] Batch [1340]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093003,	
2017-08-04 08:20:03,048 Epoch[48] Batch [1350]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.093021,	
2017-08-04 08:20:08,393 Epoch[48] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093018,	
2017-08-04 08:20:13,581 Epoch[48] Batch [1370]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093009,	
2017-08-04 08:20:18,716 Epoch[48] Batch [1380]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093013,	
2017-08-04 08:20:23,977 Epoch[48] Batch [1390]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092943,	
2017-08-04 08:20:28,863 Epoch[48] Batch [1400]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092927,	
2017-08-04 08:20:33,885 Epoch[48] Batch [1410]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.092927,	
2017-08-04 08:20:38,857 Epoch[48] Batch [1420]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.092924,	
2017-08-04 08:20:43,646 Epoch[48] Batch [1430]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.092907,	
2017-08-04 08:20:48,437 Epoch[48] Batch [1440]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.092951,	
2017-08-04 08:20:53,127 Epoch[48] Batch [1450]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092925,	
2017-08-04 08:20:57,961 Epoch[48] Batch [1460]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092964,	
2017-08-04 08:21:02,728 Epoch[48] Batch [1470]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092945,	
2017-08-04 08:21:07,780 Epoch[48] Batch [1480]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092922,	
2017-08-04 08:21:10,888 Epoch[48] Train-FCNLogLoss=0.092927
2017-08-04 08:21:10,888 Epoch[48] Time cost=755.869
2017-08-04 08:21:12,030 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0049.params"
2017-08-04 08:21:15,496 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0049.states"
2017-08-04 08:21:21,035 Epoch[49] Batch [10]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091651,	
2017-08-04 08:21:25,570 Epoch[49] Batch [20]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.091534,	
2017-08-04 08:21:29,978 Epoch[49] Batch [30]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.091540,	
2017-08-04 08:21:34,573 Epoch[49] Batch [40]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.093673,	
2017-08-04 08:21:39,047 Epoch[49] Batch [50]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092048,	
2017-08-04 08:21:43,580 Epoch[49] Batch [60]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090323,	
2017-08-04 08:21:48,128 Epoch[49] Batch [70]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089400,	
2017-08-04 08:21:52,899 Epoch[49] Batch [80]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089831,	
2017-08-04 08:21:57,780 Epoch[49] Batch [90]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090605,	
2017-08-04 08:22:02,658 Epoch[49] Batch [100]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090576,	
2017-08-04 08:22:07,465 Epoch[49] Batch [110]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092066,	
2017-08-04 08:22:12,331 Epoch[49] Batch [120]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092085,	
2017-08-04 08:22:17,139 Epoch[49] Batch [130]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092145,	
2017-08-04 08:22:21,815 Epoch[49] Batch [140]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092563,	
2017-08-04 08:22:26,656 Epoch[49] Batch [150]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092366,	
2017-08-04 08:22:31,766 Epoch[49] Batch [160]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.092845,	
2017-08-04 08:22:36,601 Epoch[49] Batch [170]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092852,	
2017-08-04 08:22:41,629 Epoch[49] Batch [180]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092257,	
2017-08-04 08:22:46,353 Epoch[49] Batch [190]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092222,	
2017-08-04 08:22:51,136 Epoch[49] Batch [200]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092164,	
2017-08-04 08:22:55,836 Epoch[49] Batch [210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092065,	
2017-08-04 08:23:00,792 Epoch[49] Batch [220]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092016,	
2017-08-04 08:23:05,684 Epoch[49] Batch [230]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092063,	
2017-08-04 08:23:10,658 Epoch[49] Batch [240]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.091825,	
2017-08-04 08:23:15,472 Epoch[49] Batch [250]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091763,	
2017-08-04 08:23:20,186 Epoch[49] Batch [260]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.091814,	
2017-08-04 08:23:24,767 Epoch[49] Batch [270]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092160,	
2017-08-04 08:23:29,839 Epoch[49] Batch [280]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092357,	
2017-08-04 08:23:34,977 Epoch[49] Batch [290]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092165,	
2017-08-04 08:23:39,681 Epoch[49] Batch [300]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091987,	
2017-08-04 08:23:44,406 Epoch[49] Batch [310]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092264,	
2017-08-04 08:23:49,212 Epoch[49] Batch [320]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092177,	
2017-08-04 08:23:53,897 Epoch[49] Batch [330]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092300,	
2017-08-04 08:23:58,876 Epoch[49] Batch [340]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.092518,	
2017-08-04 08:24:03,628 Epoch[49] Batch [350]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092416,	
2017-08-04 08:24:08,382 Epoch[49] Batch [360]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092444,	
2017-08-04 08:24:13,322 Epoch[49] Batch [370]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.092510,	
2017-08-04 08:24:18,233 Epoch[49] Batch [380]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.092228,	
2017-08-04 08:24:23,504 Epoch[49] Batch [390]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092192,	
2017-08-04 08:24:28,660 Epoch[49] Batch [400]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092231,	
2017-08-04 08:24:33,744 Epoch[49] Batch [410]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092138,	
2017-08-04 08:24:38,887 Epoch[49] Batch [420]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.092371,	
2017-08-04 08:24:43,895 Epoch[49] Batch [430]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.092248,	
2017-08-04 08:24:48,819 Epoch[49] Batch [440]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092308,	
2017-08-04 08:24:54,091 Epoch[49] Batch [450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092300,	
2017-08-04 08:24:59,342 Epoch[49] Batch [460]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092004,	
2017-08-04 08:25:04,729 Epoch[49] Batch [470]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091841,	
2017-08-04 08:25:09,664 Epoch[49] Batch [480]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.091801,	
2017-08-04 08:25:14,773 Epoch[49] Batch [490]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.091637,	
2017-08-04 08:25:19,799 Epoch[49] Batch [500]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.091591,	
2017-08-04 08:25:24,728 Epoch[49] Batch [510]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.091516,	
2017-08-04 08:25:29,599 Epoch[49] Batch [520]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.091616,	
2017-08-04 08:25:34,530 Epoch[49] Batch [530]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.091815,	
2017-08-04 08:25:39,556 Epoch[49] Batch [540]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.091940,	
2017-08-04 08:25:44,629 Epoch[49] Batch [550]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.091851,	
2017-08-04 08:25:49,306 Epoch[49] Batch [560]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091902,	
2017-08-04 08:25:54,200 Epoch[49] Batch [570]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.091763,	
2017-08-04 08:25:59,574 Epoch[49] Batch [580]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091869,	
2017-08-04 08:26:04,387 Epoch[49] Batch [590]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091873,	
2017-08-04 08:26:09,470 Epoch[49] Batch [600]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.091899,	
2017-08-04 08:26:14,507 Epoch[49] Batch [610]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092002,	
2017-08-04 08:26:19,234 Epoch[49] Batch [620]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.092012,	
2017-08-04 08:26:24,531 Epoch[49] Batch [630]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091900,	
2017-08-04 08:26:29,515 Epoch[49] Batch [640]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.091793,	
2017-08-04 08:26:34,830 Epoch[49] Batch [650]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091751,	
2017-08-04 08:26:39,937 Epoch[49] Batch [660]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.091837,	
2017-08-04 08:26:44,697 Epoch[49] Batch [670]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.091679,	
2017-08-04 08:26:49,450 Epoch[49] Batch [680]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.091636,	
2017-08-04 08:26:54,250 Epoch[49] Batch [690]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.091764,	
2017-08-04 08:26:59,093 Epoch[49] Batch [700]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091696,	
2017-08-04 08:27:03,741 Epoch[49] Batch [710]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091666,	
2017-08-04 08:27:08,424 Epoch[49] Batch [720]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091682,	
2017-08-04 08:27:13,094 Epoch[49] Batch [730]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091715,	
2017-08-04 08:27:17,922 Epoch[49] Batch [740]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091548,	
2017-08-04 08:27:22,767 Epoch[49] Batch [750]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091554,	
2017-08-04 08:27:27,682 Epoch[49] Batch [760]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.091626,	
2017-08-04 08:27:32,302 Epoch[49] Batch [770]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091618,	
2017-08-04 08:27:37,064 Epoch[49] Batch [780]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.091718,	
2017-08-04 08:27:41,925 Epoch[49] Batch [790]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.091719,	
2017-08-04 08:27:47,204 Epoch[49] Batch [800]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091673,	
2017-08-04 08:27:52,132 Epoch[49] Batch [810]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.091573,	
2017-08-04 08:27:57,159 Epoch[49] Batch [820]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.091751,	
2017-08-04 08:28:02,530 Epoch[49] Batch [830]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091819,	
2017-08-04 08:28:07,658 Epoch[49] Batch [840]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.091734,	
2017-08-04 08:28:13,220 Epoch[49] Batch [850]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.091680,	
2017-08-04 08:28:18,942 Epoch[49] Batch [860]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.091733,	
2017-08-04 08:28:24,355 Epoch[49] Batch [870]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091746,	
2017-08-04 08:28:29,497 Epoch[49] Batch [880]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.091758,	
2017-08-04 08:28:34,520 Epoch[49] Batch [890]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.091840,	
2017-08-04 08:28:39,381 Epoch[49] Batch [900]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.091955,	
2017-08-04 08:28:44,443 Epoch[49] Batch [910]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.091906,	
2017-08-04 08:28:49,647 Epoch[49] Batch [920]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.091852,	
2017-08-04 08:28:55,167 Epoch[49] Batch [930]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.091768,	
2017-08-04 08:29:00,054 Epoch[49] Batch [940]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091812,	
2017-08-04 08:29:04,974 Epoch[49] Batch [950]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.091879,	
2017-08-04 08:29:09,943 Epoch[49] Batch [960]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.092043,	
2017-08-04 08:29:14,924 Epoch[49] Batch [970]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.092098,	
2017-08-04 08:29:20,054 Epoch[49] Batch [980]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.092029,	
2017-08-04 08:29:25,309 Epoch[49] Batch [990]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092057,	
2017-08-04 08:29:30,378 Epoch[49] Batch [1000]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092051,	
2017-08-04 08:29:35,209 Epoch[49] Batch [1010]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092082,	
2017-08-04 08:29:40,289 Epoch[49] Batch [1020]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092108,	
2017-08-04 08:29:45,945 Epoch[49] Batch [1030]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.092119,	
2017-08-04 08:29:51,031 Epoch[49] Batch [1040]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092154,	
2017-08-04 08:29:56,275 Epoch[49] Batch [1050]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092208,	
2017-08-04 08:30:01,216 Epoch[49] Batch [1060]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.092235,	
2017-08-04 08:30:06,170 Epoch[49] Batch [1070]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092236,	
2017-08-04 08:30:11,195 Epoch[49] Batch [1080]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092304,	
2017-08-04 08:30:16,655 Epoch[49] Batch [1090]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.092325,	
2017-08-04 08:30:21,981 Epoch[49] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092300,	
2017-08-04 08:30:27,505 Epoch[49] Batch [1110]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.092348,	
2017-08-04 08:30:32,686 Epoch[49] Batch [1120]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092276,	
2017-08-04 08:30:37,608 Epoch[49] Batch [1130]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092267,	
2017-08-04 08:30:42,878 Epoch[49] Batch [1140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092254,	
2017-08-04 08:30:47,926 Epoch[49] Batch [1150]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092192,	
2017-08-04 08:30:52,766 Epoch[49] Batch [1160]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092187,	
2017-08-04 08:30:57,860 Epoch[49] Batch [1170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092189,	
2017-08-04 08:31:03,211 Epoch[49] Batch [1180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092192,	
2017-08-04 08:31:08,288 Epoch[49] Batch [1190]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.092183,	
2017-08-04 08:31:13,555 Epoch[49] Batch [1200]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092219,	
2017-08-04 08:31:18,591 Epoch[49] Batch [1210]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092311,	
2017-08-04 08:31:23,493 Epoch[49] Batch [1220]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092354,	
2017-08-04 08:31:28,456 Epoch[49] Batch [1230]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.092370,	
2017-08-04 08:31:33,191 Epoch[49] Batch [1240]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.092373,	
2017-08-04 08:31:38,262 Epoch[49] Batch [1250]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092339,	
2017-08-04 08:31:43,254 Epoch[49] Batch [1260]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.092331,	
2017-08-04 08:31:48,434 Epoch[49] Batch [1270]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092310,	
2017-08-04 08:31:53,417 Epoch[49] Batch [1280]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.092283,	
2017-08-04 08:31:58,488 Epoch[49] Batch [1290]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092245,	
2017-08-04 08:32:03,519 Epoch[49] Batch [1300]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.092262,	
2017-08-04 08:32:08,722 Epoch[49] Batch [1310]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092182,	
2017-08-04 08:32:13,807 Epoch[49] Batch [1320]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092191,	
2017-08-04 08:32:19,341 Epoch[49] Batch [1330]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.092255,	
2017-08-04 08:32:24,716 Epoch[49] Batch [1340]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092199,	
2017-08-04 08:32:29,930 Epoch[49] Batch [1350]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.092228,	
2017-08-04 08:32:34,880 Epoch[49] Batch [1360]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.092246,	
2017-08-04 08:32:40,279 Epoch[49] Batch [1370]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092222,	
2017-08-04 08:32:45,361 Epoch[49] Batch [1380]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092156,	
2017-08-04 08:32:50,406 Epoch[49] Batch [1390]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.092159,	
2017-08-04 08:32:56,038 Epoch[49] Batch [1400]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.092211,	
2017-08-04 08:33:01,794 Epoch[49] Batch [1410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092277,	
2017-08-04 08:33:06,722 Epoch[49] Batch [1420]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092323,	
2017-08-04 08:33:11,806 Epoch[49] Batch [1430]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092388,	
2017-08-04 08:33:16,868 Epoch[49] Batch [1440]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.092398,	
2017-08-04 08:33:22,201 Epoch[49] Batch [1450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092342,	
2017-08-04 08:33:27,380 Epoch[49] Batch [1460]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092407,	
2017-08-04 08:33:32,970 Epoch[49] Batch [1470]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.092420,	
2017-08-04 08:33:38,341 Epoch[49] Batch [1480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092392,	
2017-08-04 08:33:41,423 Epoch[49] Train-FCNLogLoss=0.092408
2017-08-04 08:33:41,423 Epoch[49] Time cost=745.927
2017-08-04 08:33:42,665 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0050.params"
2017-08-04 08:33:46,784 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0050.states"
2017-08-04 08:33:52,769 Epoch[50] Batch [10]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.078692,	
2017-08-04 08:33:57,870 Epoch[50] Batch [20]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.084292,	
2017-08-04 08:34:02,915 Epoch[50] Batch [30]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086234,	
2017-08-04 08:34:07,841 Epoch[50] Batch [40]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088857,	
2017-08-04 08:34:13,030 Epoch[50] Batch [50]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090763,	
2017-08-04 08:34:18,154 Epoch[50] Batch [60]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093095,	
2017-08-04 08:34:23,203 Epoch[50] Batch [70]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.093154,	
2017-08-04 08:34:28,688 Epoch[50] Batch [80]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092591,	
2017-08-04 08:34:34,012 Epoch[50] Batch [90]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092973,	
2017-08-04 08:34:38,898 Epoch[50] Batch [100]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092300,	
2017-08-04 08:34:43,764 Epoch[50] Batch [110]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.093261,	
2017-08-04 08:34:49,535 Epoch[50] Batch [120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094477,	
2017-08-04 08:34:54,344 Epoch[50] Batch [130]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.093671,	
2017-08-04 08:34:59,795 Epoch[50] Batch [140]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093926,	
2017-08-04 08:35:04,585 Epoch[50] Batch [150]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.094051,	
2017-08-04 08:35:09,541 Epoch[50] Batch [160]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093722,	
2017-08-04 08:35:14,696 Epoch[50] Batch [170]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093664,	
2017-08-04 08:35:19,844 Epoch[50] Batch [180]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093452,	
2017-08-04 08:35:25,300 Epoch[50] Batch [190]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093102,	
2017-08-04 08:35:30,446 Epoch[50] Batch [200]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.092840,	
2017-08-04 08:35:35,711 Epoch[50] Batch [210]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092814,	
2017-08-04 08:35:41,020 Epoch[50] Batch [220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092715,	
2017-08-04 08:35:45,721 Epoch[50] Batch [230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092925,	
2017-08-04 08:35:50,907 Epoch[50] Batch [240]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092737,	
2017-08-04 08:35:55,857 Epoch[50] Batch [250]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.092709,	
2017-08-04 08:36:00,701 Epoch[50] Batch [260]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092446,	
2017-08-04 08:36:05,838 Epoch[50] Batch [270]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092394,	
2017-08-04 08:36:11,329 Epoch[50] Batch [280]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092004,	
2017-08-04 08:36:16,433 Epoch[50] Batch [290]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.091913,	
2017-08-04 08:36:21,576 Epoch[50] Batch [300]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.091716,	
2017-08-04 08:36:26,612 Epoch[50] Batch [310]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.091823,	
2017-08-04 08:36:31,448 Epoch[50] Batch [320]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092073,	
2017-08-04 08:36:36,522 Epoch[50] Batch [330]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.092109,	
2017-08-04 08:36:41,394 Epoch[50] Batch [340]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.092273,	
2017-08-04 08:36:46,550 Epoch[50] Batch [350]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092284,	
2017-08-04 08:36:51,435 Epoch[50] Batch [360]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092067,	
2017-08-04 08:36:56,391 Epoch[50] Batch [370]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092342,	
2017-08-04 08:37:01,646 Epoch[50] Batch [380]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092524,	
2017-08-04 08:37:06,497 Epoch[50] Batch [390]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.092492,	
2017-08-04 08:37:11,671 Epoch[50] Batch [400]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092721,	
2017-08-04 08:37:16,891 Epoch[50] Batch [410]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.092802,	
2017-08-04 08:37:22,250 Epoch[50] Batch [420]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092963,	
2017-08-04 08:37:27,388 Epoch[50] Batch [430]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093093,	
2017-08-04 08:37:32,544 Epoch[50] Batch [440]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092992,	
2017-08-04 08:37:37,392 Epoch[50] Batch [450]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.093081,	
2017-08-04 08:37:42,462 Epoch[50] Batch [460]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093390,	
2017-08-04 08:37:47,422 Epoch[50] Batch [470]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093203,	
2017-08-04 08:37:52,803 Epoch[50] Batch [480]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093230,	
2017-08-04 08:37:57,884 Epoch[50] Batch [490]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093313,	
2017-08-04 08:38:02,967 Epoch[50] Batch [500]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093503,	
2017-08-04 08:38:09,178 Epoch[50] Batch [510]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093403,	
2017-08-04 08:38:14,301 Epoch[50] Batch [520]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093574,	
2017-08-04 08:38:19,292 Epoch[50] Batch [530]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093601,	
2017-08-04 08:38:24,405 Epoch[50] Batch [540]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.093645,	
2017-08-04 08:38:29,243 Epoch[50] Batch [550]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093557,	
2017-08-04 08:38:33,919 Epoch[50] Batch [560]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.093694,	
2017-08-04 08:38:38,938 Epoch[50] Batch [570]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093608,	
2017-08-04 08:38:43,911 Epoch[50] Batch [580]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.093537,	
2017-08-04 08:38:48,825 Epoch[50] Batch [590]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093614,	
2017-08-04 08:38:54,118 Epoch[50] Batch [600]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093725,	
2017-08-04 08:38:59,197 Epoch[50] Batch [610]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.093792,	
2017-08-04 08:39:04,310 Epoch[50] Batch [620]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.093844,	
2017-08-04 08:39:09,402 Epoch[50] Batch [630]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.093817,	
2017-08-04 08:39:14,196 Epoch[50] Batch [640]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.093739,	
2017-08-04 08:39:19,490 Epoch[50] Batch [650]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093703,	
2017-08-04 08:39:25,265 Epoch[50] Batch [660]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.093699,	
2017-08-04 08:39:30,629 Epoch[50] Batch [670]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093720,	
2017-08-04 08:39:35,752 Epoch[50] Batch [680]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093801,	
2017-08-04 08:39:41,267 Epoch[50] Batch [690]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.093554,	
2017-08-04 08:39:46,518 Epoch[50] Batch [700]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093396,	
2017-08-04 08:39:51,317 Epoch[50] Batch [710]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093412,	
2017-08-04 08:39:56,461 Epoch[50] Batch [720]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093397,	
2017-08-04 08:40:01,399 Epoch[50] Batch [730]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093569,	
2017-08-04 08:40:06,449 Epoch[50] Batch [740]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.093558,	
2017-08-04 08:40:11,339 Epoch[50] Batch [750]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093574,	
2017-08-04 08:40:16,052 Epoch[50] Batch [760]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093532,	
2017-08-04 08:40:21,428 Epoch[50] Batch [770]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093566,	
2017-08-04 08:40:26,722 Epoch[50] Batch [780]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093710,	
2017-08-04 08:40:31,866 Epoch[50] Batch [790]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093740,	
2017-08-04 08:40:37,530 Epoch[50] Batch [800]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.093635,	
2017-08-04 08:40:42,868 Epoch[50] Batch [810]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093654,	
2017-08-04 08:40:48,266 Epoch[50] Batch [820]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.093574,	
2017-08-04 08:40:53,742 Epoch[50] Batch [830]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093510,	
2017-08-04 08:40:59,153 Epoch[50] Batch [840]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093442,	
2017-08-04 08:41:04,031 Epoch[50] Batch [850]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.093479,	
2017-08-04 08:41:08,797 Epoch[50] Batch [860]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.093393,	
2017-08-04 08:41:14,004 Epoch[50] Batch [870]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.093276,	
2017-08-04 08:41:19,319 Epoch[50] Batch [880]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093292,	
2017-08-04 08:41:24,579 Epoch[50] Batch [890]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.093301,	
2017-08-04 08:41:29,684 Epoch[50] Batch [900]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.093324,	
2017-08-04 08:41:34,669 Epoch[50] Batch [910]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.093301,	
2017-08-04 08:41:39,993 Epoch[50] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093278,	
2017-08-04 08:41:44,866 Epoch[50] Batch [930]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.093151,	
2017-08-04 08:41:50,033 Epoch[50] Batch [940]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093187,	
2017-08-04 08:41:55,605 Epoch[50] Batch [950]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.093219,	
2017-08-04 08:42:00,712 Epoch[50] Batch [960]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.093253,	
2017-08-04 08:42:06,171 Epoch[50] Batch [970]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093169,	
2017-08-04 08:42:11,249 Epoch[50] Batch [980]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.093098,	
2017-08-04 08:42:16,544 Epoch[50] Batch [990]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093120,	
2017-08-04 08:42:21,576 Epoch[50] Batch [1000]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.093008,	
2017-08-04 08:42:26,591 Epoch[50] Batch [1010]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.092940,	
2017-08-04 08:42:31,669 Epoch[50] Batch [1020]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.092903,	
2017-08-04 08:42:36,942 Epoch[50] Batch [1030]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092924,	
2017-08-04 08:42:41,707 Epoch[50] Batch [1040]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.092839,	
2017-08-04 08:42:46,975 Epoch[50] Batch [1050]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092970,	
2017-08-04 08:42:51,871 Epoch[50] Batch [1060]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092901,	
2017-08-04 08:42:57,032 Epoch[50] Batch [1070]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092916,	
2017-08-04 08:43:02,167 Epoch[50] Batch [1080]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092931,	
2017-08-04 08:43:07,106 Epoch[50] Batch [1090]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.092922,	
2017-08-04 08:43:11,946 Epoch[50] Batch [1100]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092884,	
2017-08-04 08:43:17,000 Epoch[50] Batch [1110]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092887,	
2017-08-04 08:43:22,027 Epoch[50] Batch [1120]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092979,	
2017-08-04 08:43:27,162 Epoch[50] Batch [1130]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092946,	
2017-08-04 08:43:32,405 Epoch[50] Batch [1140]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093007,	
2017-08-04 08:43:37,699 Epoch[50] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092898,	
2017-08-04 08:43:43,025 Epoch[50] Batch [1160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092909,	
2017-08-04 08:43:48,173 Epoch[50] Batch [1170]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.092939,	
2017-08-04 08:43:53,129 Epoch[50] Batch [1180]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092916,	
2017-08-04 08:43:58,037 Epoch[50] Batch [1190]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.092980,	
2017-08-04 08:44:03,036 Epoch[50] Batch [1200]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093033,	
2017-08-04 08:44:08,361 Epoch[50] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092971,	
2017-08-04 08:44:13,618 Epoch[50] Batch [1220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093014,	
2017-08-04 08:44:19,006 Epoch[50] Batch [1230]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092993,	
2017-08-04 08:44:24,346 Epoch[50] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092982,	
2017-08-04 08:44:29,908 Epoch[50] Batch [1250]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093011,	
2017-08-04 08:44:35,248 Epoch[50] Batch [1260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092947,	
2017-08-04 08:44:40,852 Epoch[50] Batch [1270]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.092950,	
2017-08-04 08:44:46,105 Epoch[50] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092927,	
2017-08-04 08:44:51,120 Epoch[50] Batch [1290]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.092908,	
2017-08-04 08:44:56,211 Epoch[50] Batch [1300]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092909,	
2017-08-04 08:45:01,459 Epoch[50] Batch [1310]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092905,	
2017-08-04 08:45:06,577 Epoch[50] Batch [1320]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.092960,	
2017-08-04 08:45:11,467 Epoch[50] Batch [1330]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093000,	
2017-08-04 08:45:16,255 Epoch[50] Batch [1340]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.093045,	
2017-08-04 08:45:21,204 Epoch[50] Batch [1350]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.092990,	
2017-08-04 08:45:26,203 Epoch[50] Batch [1360]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093017,	
2017-08-04 08:45:31,189 Epoch[50] Batch [1370]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093079,	
2017-08-04 08:45:36,346 Epoch[50] Batch [1380]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093061,	
2017-08-04 08:45:41,086 Epoch[50] Batch [1390]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.093082,	
2017-08-04 08:45:46,182 Epoch[50] Batch [1400]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093046,	
2017-08-04 08:45:51,175 Epoch[50] Batch [1410]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.092989,	
2017-08-04 08:45:56,737 Epoch[50] Batch [1420]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093044,	
2017-08-04 08:46:01,900 Epoch[50] Batch [1430]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092973,	
2017-08-04 08:46:07,331 Epoch[50] Batch [1440]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.092974,	
2017-08-04 08:46:12,647 Epoch[50] Batch [1450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092936,	
2017-08-04 08:46:17,622 Epoch[50] Batch [1460]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.092865,	
2017-08-04 08:46:22,692 Epoch[50] Batch [1470]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092912,	
2017-08-04 08:46:27,859 Epoch[50] Batch [1480]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093013,	
2017-08-04 08:46:30,868 Epoch[50] Train-FCNLogLoss=0.093053
2017-08-04 08:46:30,868 Epoch[50] Time cost=764.084
2017-08-04 08:46:32,156 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0051.params"
2017-08-04 08:46:36,101 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0051.states"
2017-08-04 08:46:42,415 Epoch[51] Batch [10]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.104855,	
2017-08-04 08:46:47,795 Epoch[51] Batch [20]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098498,	
2017-08-04 08:46:52,882 Epoch[51] Batch [30]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.098957,	
2017-08-04 08:46:58,166 Epoch[51] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098170,	
2017-08-04 08:47:02,797 Epoch[51] Batch [50]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.096690,	
2017-08-04 08:47:07,460 Epoch[51] Batch [60]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095767,	
2017-08-04 08:47:12,806 Epoch[51] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094611,	
2017-08-04 08:47:18,452 Epoch[51] Batch [80]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.094542,	
2017-08-04 08:47:23,955 Epoch[51] Batch [90]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092825,	
2017-08-04 08:47:29,421 Epoch[51] Batch [100]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.093154,	
2017-08-04 08:47:34,804 Epoch[51] Batch [110]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092887,	
2017-08-04 08:47:39,821 Epoch[51] Batch [120]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093393,	
2017-08-04 08:47:44,813 Epoch[51] Batch [130]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.093933,	
2017-08-04 08:47:50,158 Epoch[51] Batch [140]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093437,	
2017-08-04 08:47:55,221 Epoch[51] Batch [150]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.093154,	
2017-08-04 08:48:00,478 Epoch[51] Batch [160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093294,	
2017-08-04 08:48:05,607 Epoch[51] Batch [170]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.093299,	
2017-08-04 08:48:11,042 Epoch[51] Batch [180]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093530,	
2017-08-04 08:48:16,713 Epoch[51] Batch [190]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.093694,	
2017-08-04 08:48:21,551 Epoch[51] Batch [200]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093521,	
2017-08-04 08:48:26,490 Epoch[51] Batch [210]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093544,	
2017-08-04 08:48:31,306 Epoch[51] Batch [220]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.093640,	
2017-08-04 08:48:36,314 Epoch[51] Batch [230]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.093815,	
2017-08-04 08:48:41,628 Epoch[51] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093594,	
2017-08-04 08:48:46,927 Epoch[51] Batch [250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093558,	
2017-08-04 08:48:52,000 Epoch[51] Batch [260]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093429,	
2017-08-04 08:48:56,981 Epoch[51] Batch [270]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.093406,	
2017-08-04 08:49:01,933 Epoch[51] Batch [280]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.094118,	
2017-08-04 08:49:07,202 Epoch[51] Batch [290]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093881,	
2017-08-04 08:49:12,368 Epoch[51] Batch [300]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093939,	
2017-08-04 08:49:17,872 Epoch[51] Batch [310]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093897,	
2017-08-04 08:49:22,821 Epoch[51] Batch [320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.094138,	
2017-08-04 08:49:27,846 Epoch[51] Batch [330]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.094111,	
2017-08-04 08:49:33,126 Epoch[51] Batch [340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093727,	
2017-08-04 08:49:38,664 Epoch[51] Batch [350]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.093426,	
2017-08-04 08:49:43,490 Epoch[51] Batch [360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.093331,	
2017-08-04 08:49:48,416 Epoch[51] Batch [370]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.093680,	
2017-08-04 08:49:53,383 Epoch[51] Batch [380]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.093534,	
2017-08-04 08:49:58,546 Epoch[51] Batch [390]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093633,	
2017-08-04 08:50:03,516 Epoch[51] Batch [400]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.093626,	
2017-08-04 08:50:08,650 Epoch[51] Batch [410]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093376,	
2017-08-04 08:50:14,040 Epoch[51] Batch [420]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093650,	
2017-08-04 08:50:19,329 Epoch[51] Batch [430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093750,	
2017-08-04 08:50:24,608 Epoch[51] Batch [440]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093673,	
2017-08-04 08:50:29,898 Epoch[51] Batch [450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093767,	
2017-08-04 08:50:34,834 Epoch[51] Batch [460]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093583,	
2017-08-04 08:50:39,747 Epoch[51] Batch [470]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093685,	
2017-08-04 08:50:44,683 Epoch[51] Batch [480]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093665,	
2017-08-04 08:50:50,088 Epoch[51] Batch [490]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093713,	
2017-08-04 08:50:55,467 Epoch[51] Batch [500]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093604,	
2017-08-04 08:51:00,436 Epoch[51] Batch [510]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.093535,	
2017-08-04 08:51:05,392 Epoch[51] Batch [520]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093482,	
2017-08-04 08:51:10,453 Epoch[51] Batch [530]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.093459,	
2017-08-04 08:51:15,494 Epoch[51] Batch [540]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093484,	
2017-08-04 08:51:20,547 Epoch[51] Batch [550]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.093421,	
2017-08-04 08:51:25,476 Epoch[51] Batch [560]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.093291,	
2017-08-04 08:51:30,553 Epoch[51] Batch [570]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.093299,	
2017-08-04 08:51:35,729 Epoch[51] Batch [580]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093498,	
2017-08-04 08:51:40,958 Epoch[51] Batch [590]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093539,	
2017-08-04 08:51:45,929 Epoch[51] Batch [600]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.093505,	
2017-08-04 08:51:50,740 Epoch[51] Batch [610]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.093464,	
2017-08-04 08:51:55,749 Epoch[51] Batch [620]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.093388,	
2017-08-04 08:52:00,970 Epoch[51] Batch [630]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093397,	
2017-08-04 08:52:06,607 Epoch[51] Batch [640]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093459,	
2017-08-04 08:52:11,798 Epoch[51] Batch [650]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093474,	
2017-08-04 08:52:17,099 Epoch[51] Batch [660]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093501,	
2017-08-04 08:52:22,127 Epoch[51] Batch [670]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.093720,	
2017-08-04 08:52:27,424 Epoch[51] Batch [680]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093702,	
2017-08-04 08:52:32,605 Epoch[51] Batch [690]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093602,	
2017-08-04 08:52:37,977 Epoch[51] Batch [700]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093705,	
2017-08-04 08:52:42,975 Epoch[51] Batch [710]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093551,	
2017-08-04 08:52:48,199 Epoch[51] Batch [720]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.093566,	
2017-08-04 08:52:52,963 Epoch[51] Batch [730]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.093567,	
2017-08-04 08:52:57,933 Epoch[51] Batch [740]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.093509,	
2017-08-04 08:53:03,485 Epoch[51] Batch [750]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093659,	
2017-08-04 08:53:09,311 Epoch[51] Batch [760]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.093561,	
2017-08-04 08:53:14,723 Epoch[51] Batch [770]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.093503,	
2017-08-04 08:53:20,220 Epoch[51] Batch [780]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093430,	
2017-08-04 08:53:25,489 Epoch[51] Batch [790]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.093536,	
2017-08-04 08:53:30,193 Epoch[51] Batch [800]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.093507,	
2017-08-04 08:53:35,142 Epoch[51] Batch [810]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.093463,	
2017-08-04 08:53:40,003 Epoch[51] Batch [820]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.093372,	
2017-08-04 08:53:45,069 Epoch[51] Batch [830]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.093516,	
2017-08-04 08:53:50,055 Epoch[51] Batch [840]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093477,	
2017-08-04 08:53:55,156 Epoch[51] Batch [850]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.093518,	
2017-08-04 08:54:00,576 Epoch[51] Batch [860]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.093446,	
2017-08-04 08:54:06,063 Epoch[51] Batch [870]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093513,	
2017-08-04 08:54:11,343 Epoch[51] Batch [880]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093424,	
2017-08-04 08:54:16,795 Epoch[51] Batch [890]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093374,	
2017-08-04 08:54:22,342 Epoch[51] Batch [900]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093401,	
2017-08-04 08:54:27,237 Epoch[51] Batch [910]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.093479,	
2017-08-04 08:54:32,804 Epoch[51] Batch [920]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.093491,	
2017-08-04 08:54:38,168 Epoch[51] Batch [930]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093487,	
2017-08-04 08:54:43,019 Epoch[51] Batch [940]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.093501,	
2017-08-04 08:54:48,037 Epoch[51] Batch [950]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093447,	
2017-08-04 08:54:53,123 Epoch[51] Batch [960]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.093356,	
2017-08-04 08:54:58,084 Epoch[51] Batch [970]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093384,	
2017-08-04 08:55:02,989 Epoch[51] Batch [980]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.093420,	
2017-08-04 08:55:08,341 Epoch[51] Batch [990]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093439,	
2017-08-04 08:55:13,505 Epoch[51] Batch [1000]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093189,	
2017-08-04 08:55:18,712 Epoch[51] Batch [1010]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.093207,	
2017-08-04 08:55:24,065 Epoch[51] Batch [1020]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093111,	
2017-08-04 08:55:28,905 Epoch[51] Batch [1030]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.093074,	
2017-08-04 08:55:34,248 Epoch[51] Batch [1040]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092964,	
2017-08-04 08:55:39,798 Epoch[51] Batch [1050]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.093066,	
2017-08-04 08:55:45,649 Epoch[51] Batch [1060]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.092967,	
2017-08-04 08:55:50,827 Epoch[51] Batch [1070]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092966,	
2017-08-04 08:55:56,498 Epoch[51] Batch [1080]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.092930,	
2017-08-04 08:56:01,708 Epoch[51] Batch [1090]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.092965,	
2017-08-04 08:56:06,940 Epoch[51] Batch [1100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.092964,	
2017-08-04 08:56:11,809 Epoch[51] Batch [1110]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.092949,	
2017-08-04 08:56:16,875 Epoch[51] Batch [1120]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.092944,	
2017-08-04 08:56:22,054 Epoch[51] Batch [1130]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092999,	
2017-08-04 08:56:27,336 Epoch[51] Batch [1140]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092912,	
2017-08-04 08:56:32,277 Epoch[51] Batch [1150]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.092863,	
2017-08-04 08:56:37,024 Epoch[51] Batch [1160]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092845,	
2017-08-04 08:56:41,994 Epoch[51] Batch [1170]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.092891,	
2017-08-04 08:56:47,266 Epoch[51] Batch [1180]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092922,	
2017-08-04 08:56:52,660 Epoch[51] Batch [1190]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092891,	
2017-08-04 08:56:58,321 Epoch[51] Batch [1200]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.092861,	
2017-08-04 08:57:03,689 Epoch[51] Batch [1210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092912,	
2017-08-04 08:57:08,786 Epoch[51] Batch [1220]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092851,	
2017-08-04 08:57:13,707 Epoch[51] Batch [1230]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092828,	
2017-08-04 08:57:18,511 Epoch[51] Batch [1240]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092860,	
2017-08-04 08:57:23,520 Epoch[51] Batch [1250]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.092871,	
2017-08-04 08:57:28,708 Epoch[51] Batch [1260]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092794,	
2017-08-04 08:57:33,748 Epoch[51] Batch [1270]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092751,	
2017-08-04 08:57:38,651 Epoch[51] Batch [1280]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092736,	
2017-08-04 08:57:44,011 Epoch[51] Batch [1290]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092704,	
2017-08-04 08:57:49,295 Epoch[51] Batch [1300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092591,	
2017-08-04 08:57:54,347 Epoch[51] Batch [1310]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092558,	
2017-08-04 08:57:59,726 Epoch[51] Batch [1320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092565,	
2017-08-04 08:58:04,894 Epoch[51] Batch [1330]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092556,	
2017-08-04 08:58:09,987 Epoch[51] Batch [1340]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092601,	
2017-08-04 08:58:15,044 Epoch[51] Batch [1350]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092607,	
2017-08-04 08:58:20,341 Epoch[51] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.092598,	
2017-08-04 08:58:25,939 Epoch[51] Batch [1370]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092549,	
2017-08-04 08:58:31,178 Epoch[51] Batch [1380]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092496,	
2017-08-04 08:58:36,311 Epoch[51] Batch [1390]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092437,	
2017-08-04 08:58:41,448 Epoch[51] Batch [1400]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092414,	
2017-08-04 08:58:46,503 Epoch[51] Batch [1410]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092376,	
2017-08-04 08:58:51,554 Epoch[51] Batch [1420]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092408,	
2017-08-04 08:58:56,640 Epoch[51] Batch [1430]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092380,	
2017-08-04 08:59:01,694 Epoch[51] Batch [1440]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092399,	
2017-08-04 08:59:06,734 Epoch[51] Batch [1450]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092385,	
2017-08-04 08:59:12,064 Epoch[51] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092316,	
2017-08-04 08:59:17,037 Epoch[51] Batch [1470]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.092366,	
2017-08-04 08:59:22,047 Epoch[51] Batch [1480]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.092385,	
2017-08-04 08:59:25,001 Epoch[51] Train-FCNLogLoss=0.092307
2017-08-04 08:59:25,001 Epoch[51] Time cost=768.899
2017-08-04 08:59:26,379 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0052.params"
2017-08-04 08:59:30,913 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0052.states"
2017-08-04 08:59:36,982 Epoch[52] Batch [10]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.095073,	
2017-08-04 08:59:42,683 Epoch[52] Batch [20]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.096198,	
2017-08-04 08:59:48,137 Epoch[52] Batch [30]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.096383,	
2017-08-04 08:59:53,867 Epoch[52] Batch [40]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.094614,	
2017-08-04 08:59:59,050 Epoch[52] Batch [50]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094114,	
2017-08-04 09:00:04,187 Epoch[52] Batch [60]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092588,	
2017-08-04 09:00:09,227 Epoch[52] Batch [70]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092090,	
2017-08-04 09:00:15,069 Epoch[52] Batch [80]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.091490,	
2017-08-04 09:00:20,381 Epoch[52] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091934,	
2017-08-04 09:00:26,056 Epoch[52] Batch [100]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.091166,	
2017-08-04 09:00:31,711 Epoch[52] Batch [110]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.090713,	
2017-08-04 09:00:37,641 Epoch[52] Batch [120]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.090049,	
2017-08-04 09:00:44,794 Epoch[52] Batch [130]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.089940,	
2017-08-04 09:01:02,356 Epoch[52] Batch [140]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.091017,	
2017-08-04 09:01:20,014 Epoch[52] Batch [150]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.090303,	
2017-08-04 09:01:41,066 Epoch[52] Batch [160]	Speed: 1.90 samples/sec	Train-FCNLogLoss=0.091231,	
2017-08-04 09:01:55,588 Epoch[52] Batch [170]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.090981,	
2017-08-04 09:02:09,522 Epoch[52] Batch [180]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.091105,	
2017-08-04 09:02:28,659 Epoch[52] Batch [190]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.091454,	
2017-08-04 09:02:45,451 Epoch[52] Batch [200]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.091368,	
2017-08-04 09:03:01,797 Epoch[52] Batch [210]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.090942,	
2017-08-04 09:03:16,896 Epoch[52] Batch [220]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.090730,	
2017-08-04 09:03:27,810 Epoch[52] Batch [230]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.091188,	
2017-08-04 09:03:33,401 Epoch[52] Batch [240]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.091368,	
2017-08-04 09:03:38,787 Epoch[52] Batch [250]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091448,	
2017-08-04 09:03:44,046 Epoch[52] Batch [260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.091501,	
2017-08-04 09:03:48,852 Epoch[52] Batch [270]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091620,	
2017-08-04 09:03:53,801 Epoch[52] Batch [280]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.091500,	
2017-08-04 09:03:58,912 Epoch[52] Batch [290]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.091365,	
2017-08-04 09:04:04,121 Epoch[52] Batch [300]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.091198,	
2017-08-04 09:04:09,058 Epoch[52] Batch [310]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.091064,	
2017-08-04 09:04:14,039 Epoch[52] Batch [320]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.091177,	
2017-08-04 09:04:18,909 Epoch[52] Batch [330]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.091108,	
2017-08-04 09:04:23,887 Epoch[52] Batch [340]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.091278,	
2017-08-04 09:04:29,083 Epoch[52] Batch [350]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.091395,	
2017-08-04 09:04:34,309 Epoch[52] Batch [360]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.091454,	
2017-08-04 09:04:39,519 Epoch[52] Batch [370]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.091356,	
2017-08-04 09:04:44,511 Epoch[52] Batch [380]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.091637,	
2017-08-04 09:04:49,615 Epoch[52] Batch [390]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.091568,	
2017-08-04 09:04:55,201 Epoch[52] Batch [400]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.091730,	
2017-08-04 09:05:00,613 Epoch[52] Batch [410]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091764,	
2017-08-04 09:05:05,828 Epoch[52] Batch [420]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.091750,	
2017-08-04 09:05:11,022 Epoch[52] Batch [430]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.091662,	
2017-08-04 09:05:16,091 Epoch[52] Batch [440]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.091607,	
2017-08-04 09:05:20,993 Epoch[52] Batch [450]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.091703,	
2017-08-04 09:05:26,036 Epoch[52] Batch [460]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.091966,	
2017-08-04 09:05:31,218 Epoch[52] Batch [470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.091872,	
2017-08-04 09:05:36,657 Epoch[52] Batch [480]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091859,	
2017-08-04 09:05:42,034 Epoch[52] Batch [490]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092162,	
2017-08-04 09:05:47,423 Epoch[52] Batch [500]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092165,	
2017-08-04 09:05:52,932 Epoch[52] Batch [510]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.092069,	
2017-08-04 09:05:58,968 Epoch[52] Batch [520]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.092145,	
2017-08-04 09:06:03,957 Epoch[52] Batch [530]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092051,	
2017-08-04 09:06:08,937 Epoch[52] Batch [540]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.092054,	
2017-08-04 09:06:13,989 Epoch[52] Batch [550]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.092029,	
2017-08-04 09:06:19,208 Epoch[52] Batch [560]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.092060,	
2017-08-04 09:06:24,084 Epoch[52] Batch [570]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092133,	
2017-08-04 09:06:28,903 Epoch[52] Batch [580]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092113,	
2017-08-04 09:06:34,095 Epoch[52] Batch [590]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092218,	
2017-08-04 09:06:39,134 Epoch[52] Batch [600]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092255,	
2017-08-04 09:06:48,422 Epoch[52] Batch [610]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.092262,	
2017-08-04 09:07:02,676 Epoch[52] Batch [620]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.092295,	
2017-08-04 09:07:08,068 Epoch[52] Batch [630]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092419,	
2017-08-04 09:07:13,228 Epoch[52] Batch [640]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092270,	
2017-08-04 09:07:18,470 Epoch[52] Batch [650]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092276,	
2017-08-04 09:07:23,495 Epoch[52] Batch [660]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092427,	
2017-08-04 09:07:28,555 Epoch[52] Batch [670]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092546,	
2017-08-04 09:07:34,168 Epoch[52] Batch [680]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.092437,	
2017-08-04 09:07:39,673 Epoch[52] Batch [690]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092475,	
2017-08-04 09:07:44,651 Epoch[52] Batch [700]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.092420,	
2017-08-04 09:07:49,636 Epoch[52] Batch [710]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.092414,	
2017-08-04 09:07:54,590 Epoch[52] Batch [720]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092457,	
2017-08-04 09:07:59,797 Epoch[52] Batch [730]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.092351,	
2017-08-04 09:08:04,742 Epoch[52] Batch [740]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.092311,	
2017-08-04 09:08:09,732 Epoch[52] Batch [750]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092332,	
2017-08-04 09:08:14,821 Epoch[52] Batch [760]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092236,	
2017-08-04 09:08:20,499 Epoch[52] Batch [770]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.092253,	
2017-08-04 09:08:24,974 Epoch[52] Batch [780]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092318,	
2017-08-04 09:08:30,532 Epoch[52] Batch [790]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.092415,	
2017-08-04 09:08:36,045 Epoch[52] Batch [800]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.092312,	
2017-08-04 09:08:41,237 Epoch[52] Batch [810]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092247,	
2017-08-04 09:08:46,333 Epoch[52] Batch [820]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092281,	
2017-08-04 09:08:52,025 Epoch[52] Batch [830]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.092208,	
2017-08-04 09:08:57,578 Epoch[52] Batch [840]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.092148,	
2017-08-04 09:09:02,350 Epoch[52] Batch [850]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092098,	
2017-08-04 09:09:07,750 Epoch[52] Batch [860]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092045,	
2017-08-04 09:09:13,254 Epoch[52] Batch [870]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092075,	
2017-08-04 09:09:18,896 Epoch[52] Batch [880]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.092125,	
2017-08-04 09:09:23,800 Epoch[52] Batch [890]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092124,	
2017-08-04 09:09:29,003 Epoch[52] Batch [900]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092193,	
2017-08-04 09:09:34,421 Epoch[52] Batch [910]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092184,	
2017-08-04 09:09:39,420 Epoch[52] Batch [920]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092132,	
2017-08-04 09:09:44,734 Epoch[52] Batch [930]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092240,	
2017-08-04 09:09:49,924 Epoch[52] Batch [940]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092230,	
2017-08-04 09:09:54,831 Epoch[52] Batch [950]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092279,	
2017-08-04 09:09:59,989 Epoch[52] Batch [960]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092287,	
2017-08-04 09:10:05,017 Epoch[52] Batch [970]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092348,	
2017-08-04 09:10:10,185 Epoch[52] Batch [980]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092334,	
2017-08-04 09:10:15,117 Epoch[52] Batch [990]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.092242,	
2017-08-04 09:10:20,116 Epoch[52] Batch [1000]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092222,	
2017-08-04 09:10:25,116 Epoch[52] Batch [1010]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092162,	
2017-08-04 09:10:30,540 Epoch[52] Batch [1020]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092165,	
2017-08-04 09:10:35,645 Epoch[52] Batch [1030]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.092097,	
2017-08-04 09:10:41,197 Epoch[52] Batch [1040]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.092158,	
2017-08-04 09:10:46,776 Epoch[52] Batch [1050]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.092148,	
2017-08-04 09:10:52,066 Epoch[52] Batch [1060]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092150,	
2017-08-04 09:10:57,258 Epoch[52] Batch [1070]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092154,	
2017-08-04 09:11:02,454 Epoch[52] Batch [1080]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092226,	
2017-08-04 09:11:07,626 Epoch[52] Batch [1090]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092227,	
2017-08-04 09:11:13,248 Epoch[52] Batch [1100]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.092202,	
2017-08-04 09:11:18,322 Epoch[52] Batch [1110]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.092276,	
2017-08-04 09:11:23,444 Epoch[52] Batch [1120]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.092274,	
2017-08-04 09:11:28,424 Epoch[52] Batch [1130]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.092231,	
2017-08-04 09:11:33,847 Epoch[52] Batch [1140]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092219,	
2017-08-04 09:11:38,931 Epoch[52] Batch [1150]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.092129,	
2017-08-04 09:11:43,915 Epoch[52] Batch [1160]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.092114,	
2017-08-04 09:11:48,953 Epoch[52] Batch [1170]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.092196,	
2017-08-04 09:11:54,245 Epoch[52] Batch [1180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092201,	
2017-08-04 09:11:59,289 Epoch[52] Batch [1190]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.092211,	
2017-08-04 09:12:04,122 Epoch[52] Batch [1200]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092297,	
2017-08-04 09:12:09,186 Epoch[52] Batch [1210]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.092343,	
2017-08-04 09:12:14,325 Epoch[52] Batch [1220]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.092329,	
2017-08-04 09:12:19,506 Epoch[52] Batch [1230]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092316,	
2017-08-04 09:12:24,494 Epoch[52] Batch [1240]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092265,	
2017-08-04 09:12:29,450 Epoch[52] Batch [1250]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092198,	
2017-08-04 09:12:34,654 Epoch[52] Batch [1260]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092267,	
2017-08-04 09:12:40,143 Epoch[52] Batch [1270]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092341,	
2017-08-04 09:12:45,592 Epoch[52] Batch [1280]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092294,	
2017-08-04 09:12:50,457 Epoch[52] Batch [1290]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092315,	
2017-08-04 09:12:55,444 Epoch[52] Batch [1300]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092283,	
2017-08-04 09:13:00,439 Epoch[52] Batch [1310]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.092311,	
2017-08-04 09:13:05,430 Epoch[52] Batch [1320]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092266,	
2017-08-04 09:13:10,613 Epoch[52] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092227,	
2017-08-04 09:13:15,603 Epoch[52] Batch [1340]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092271,	
2017-08-04 09:13:20,615 Epoch[52] Batch [1350]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.092240,	
2017-08-04 09:13:25,808 Epoch[52] Batch [1360]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092293,	
2017-08-04 09:13:30,583 Epoch[52] Batch [1370]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092298,	
2017-08-04 09:13:35,693 Epoch[52] Batch [1380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.092252,	
2017-08-04 09:13:41,128 Epoch[52] Batch [1390]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.092217,	
2017-08-04 09:13:46,548 Epoch[52] Batch [1400]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092234,	
2017-08-04 09:13:52,126 Epoch[52] Batch [1410]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.092228,	
2017-08-04 09:13:57,393 Epoch[52] Batch [1420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092223,	
2017-08-04 09:14:02,386 Epoch[52] Batch [1430]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.092290,	
2017-08-04 09:14:07,269 Epoch[52] Batch [1440]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092276,	
2017-08-04 09:14:12,158 Epoch[52] Batch [1450]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092271,	
2017-08-04 09:14:17,169 Epoch[52] Batch [1460]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.092279,	
2017-08-04 09:14:22,478 Epoch[52] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092301,	
2017-08-04 09:14:27,819 Epoch[52] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092192,	
2017-08-04 09:14:31,307 Epoch[52] Train-FCNLogLoss=0.092167
2017-08-04 09:14:31,307 Epoch[52] Time cost=900.393
2017-08-04 09:14:32,612 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0053.params"
2017-08-04 09:14:36,087 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup_resume/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup-0053.states"
2017-08-04 09:14:36,101 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': True,
           'SHUFFLE': True,
           'begin_epoch': 20,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn_warmup',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-08-04 09:14:43,424 testing 4/500 data 0.6654s net 0.3148s post 0.0096s
2017-08-04 09:14:43,929 testing 8/500 data 0.4519s net 0.2869s post 0.0089s
2017-08-04 09:14:44,506 testing 12/500 data 0.4044s net 0.2767s post 0.0094s
2017-08-04 09:14:45,960 testing 16/500 data 0.6002s net 0.2714s post 0.0099s
2017-08-04 09:14:47,308 testing 20/500 data 0.6961s net 0.2684s post 0.0103s
2017-08-04 09:14:48,117 testing 24/500 data 0.6704s net 0.2661s post 0.0105s
2017-08-04 09:14:48,714 testing 28/500 data 0.6225s net 0.2642s post 0.0105s
2017-08-04 09:14:50,185 testing 32/500 data 0.6949s net 0.2633s post 0.0105s
2017-08-04 09:14:51,517 testing 36/500 data 0.7346s net 0.2638s post 0.0108s
2017-08-04 09:14:52,892 testing 40/500 data 0.7704s net 0.2644s post 0.0110s
2017-08-04 09:14:54,182 testing 44/500 data 0.7922s net 0.2646s post 0.0112s
2017-08-04 09:14:55,419 testing 48/500 data 0.8070s net 0.2640s post 0.0111s
2017-08-04 09:14:56,119 testing 52/500 data 0.7777s net 0.2635s post 0.0115s
2017-08-04 09:14:57,303 testing 56/500 data 0.7875s net 0.2630s post 0.0116s
2017-08-04 09:14:58,444 testing 60/500 data 0.7933s net 0.2628s post 0.0112s
2017-08-04 09:14:59,663 testing 64/500 data 0.8028s net 0.2626s post 0.0114s
2017-08-04 09:15:00,783 testing 68/500 data 0.8057s net 0.2622s post 0.0115s
2017-08-04 09:15:02,072 testing 72/500 data 0.8155s net 0.2641s post 0.0114s
2017-08-04 09:15:03,432 testing 76/500 data 0.8299s net 0.2638s post 0.0115s
2017-08-04 09:15:04,670 testing 80/500 data 0.8371s net 0.2633s post 0.0113s
2017-08-04 09:15:05,835 testing 84/500 data 0.8400s net 0.2630s post 0.0114s
2017-08-04 09:15:07,218 testing 88/500 data 0.8524s net 0.2627s post 0.0115s
2017-08-04 09:15:08,391 testing 92/500 data 0.8541s net 0.2628s post 0.0117s
2017-08-04 09:15:09,619 testing 96/500 data 0.8585s net 0.2626s post 0.0115s
2017-08-04 09:15:10,917 testing 100/500 data 0.8653s net 0.2624s post 0.0116s
2017-08-04 09:15:12,142 testing 104/500 data 0.8690s net 0.2620s post 0.0116s
2017-08-04 09:15:13,250 testing 108/500 data 0.8679s net 0.2618s post 0.0116s
2017-08-04 09:15:14,503 testing 112/500 data 0.8721s net 0.2615s post 0.0117s
2017-08-04 09:15:15,305 testing 116/500 data 0.8605s net 0.2613s post 0.0117s
2017-08-04 09:15:16,100 testing 120/500 data 0.8495s net 0.2611s post 0.0115s
2017-08-04 09:15:17,305 testing 124/500 data 0.8521s net 0.2613s post 0.0114s
2017-08-04 09:15:18,440 testing 128/500 data 0.8526s net 0.2612s post 0.0114s
2017-08-04 09:15:19,571 testing 132/500 data 0.8529s net 0.2610s post 0.0114s
2017-08-04 09:15:20,360 testing 136/500 data 0.8432s net 0.2609s post 0.0113s
2017-08-04 09:15:21,643 testing 140/500 data 0.8482s net 0.2607s post 0.0114s
2017-08-04 09:15:22,325 testing 144/500 data 0.8361s net 0.2607s post 0.0114s
2017-08-04 09:15:22,900 testing 148/500 data 0.8216s net 0.2606s post 0.0114s
2017-08-04 09:15:24,017 testing 152/500 data 0.8223s net 0.2606s post 0.0114s
2017-08-04 09:15:25,381 testing 156/500 data 0.8289s net 0.2609s post 0.0114s
2017-08-04 09:15:26,697 testing 160/500 data 0.8343s net 0.2608s post 0.0114s
2017-08-04 09:15:27,990 testing 164/500 data 0.8390s net 0.2607s post 0.0114s
2017-08-04 09:15:29,124 testing 168/500 data 0.8398s net 0.2605s post 0.0113s
2017-08-04 09:15:30,005 testing 172/500 data 0.8345s net 0.2604s post 0.0113s
2017-08-04 09:15:31,249 testing 176/500 data 0.8378s net 0.2603s post 0.0113s
2017-08-04 09:15:32,524 testing 180/500 data 0.8415s net 0.2603s post 0.0113s
2017-08-04 09:15:33,824 testing 184/500 data 0.8452s net 0.2607s post 0.0113s
2017-08-04 09:15:34,584 testing 188/500 data 0.8377s net 0.2606s post 0.0113s
2017-08-04 09:15:35,960 testing 192/500 data 0.8433s net 0.2606s post 0.0113s
2017-08-04 09:15:36,673 testing 196/500 data 0.8350s net 0.2606s post 0.0113s
2017-08-04 09:15:37,998 testing 200/500 data 0.8394s net 0.2606s post 0.0113s
2017-08-04 09:15:39,401 testing 204/500 data 0.8445s net 0.2611s post 0.0113s
2017-08-04 09:15:40,884 testing 208/500 data 0.8516s net 0.2611s post 0.0113s
2017-08-04 09:15:41,897 testing 212/500 data 0.8495s net 0.2611s post 0.0114s
2017-08-04 09:15:42,823 testing 216/500 data 0.8459s net 0.2610s post 0.0114s
2017-08-04 09:15:44,017 testing 220/500 data 0.8473s net 0.2609s post 0.0114s
2017-08-04 09:15:44,909 testing 224/500 data 0.8434s net 0.2608s post 0.0113s
2017-08-04 09:15:46,116 testing 228/500 data 0.8451s net 0.2608s post 0.0113s
2017-08-04 09:15:47,299 testing 232/500 data 0.8458s net 0.2612s post 0.0113s
2017-08-04 09:15:48,433 testing 236/500 data 0.8461s net 0.2611s post 0.0113s
2017-08-04 09:15:49,287 testing 240/500 data 0.8419s net 0.2611s post 0.0113s
2017-08-04 09:15:50,472 testing 244/500 data 0.8431s net 0.2610s post 0.0113s
2017-08-04 09:15:51,661 testing 248/500 data 0.8443s net 0.2610s post 0.0113s
2017-08-04 09:15:52,928 testing 252/500 data 0.8467s net 0.2610s post 0.0113s
2017-08-04 09:15:54,144 testing 256/500 data 0.8480s net 0.2612s post 0.0113s
2017-08-04 09:15:55,267 testing 260/500 data 0.8480s net 0.2613s post 0.0112s
2017-08-04 09:15:56,399 testing 264/500 data 0.8483s net 0.2612s post 0.0112s
2017-08-04 09:15:57,555 testing 268/500 data 0.8489s net 0.2611s post 0.0112s
2017-08-04 09:15:58,711 testing 272/500 data 0.8495s net 0.2610s post 0.0112s
2017-08-04 09:15:59,770 testing 276/500 data 0.8488s net 0.2609s post 0.0112s
2017-08-04 09:16:00,923 testing 280/500 data 0.8493s net 0.2608s post 0.0112s
2017-08-04 09:16:01,783 testing 284/500 data 0.8454s net 0.2609s post 0.0112s
2017-08-04 09:16:03,117 testing 288/500 data 0.8485s net 0.2609s post 0.0112s
2017-08-04 09:16:04,277 testing 292/500 data 0.8491s net 0.2608s post 0.0113s
2017-08-04 09:16:05,446 testing 296/500 data 0.8499s net 0.2607s post 0.0112s
2017-08-04 09:16:06,600 testing 300/500 data 0.8502s net 0.2608s post 0.0112s
2017-08-04 09:16:07,620 testing 304/500 data 0.8490s net 0.2607s post 0.0112s
2017-08-04 09:16:09,067 testing 308/500 data 0.8533s net 0.2607s post 0.0111s
2017-08-04 09:16:10,245 testing 312/500 data 0.8541s net 0.2606s post 0.0111s
2017-08-04 09:16:11,357 testing 316/500 data 0.8541s net 0.2605s post 0.0110s
2017-08-04 09:16:12,470 testing 320/500 data 0.8541s net 0.2604s post 0.0110s
2017-08-04 09:16:13,578 testing 324/500 data 0.8540s net 0.2603s post 0.0109s
2017-08-04 09:16:14,697 testing 328/500 data 0.8540s net 0.2602s post 0.0109s
2017-08-04 09:16:15,714 testing 332/500 data 0.8527s net 0.2602s post 0.0109s
2017-08-04 09:16:16,876 testing 336/500 data 0.8533s net 0.2602s post 0.0109s
2017-08-04 09:16:17,713 testing 340/500 data 0.8500s net 0.2601s post 0.0108s
2017-08-04 09:16:18,891 testing 344/500 data 0.8507s net 0.2600s post 0.0109s
2017-08-04 09:16:20,023 testing 348/500 data 0.8508s net 0.2600s post 0.0109s
2017-08-04 09:16:21,274 testing 352/500 data 0.8524s net 0.2599s post 0.0109s
2017-08-04 09:16:22,353 testing 356/500 data 0.8520s net 0.2598s post 0.0109s
2017-08-04 09:16:23,425 testing 360/500 data 0.8515s net 0.2597s post 0.0109s
2017-08-04 09:16:24,553 testing 364/500 data 0.8515s net 0.2597s post 0.0109s
2017-08-04 09:16:25,671 testing 368/500 data 0.8515s net 0.2597s post 0.0110s
2017-08-04 09:16:26,768 testing 372/500 data 0.8513s net 0.2596s post 0.0110s
2017-08-04 09:16:27,713 testing 376/500 data 0.8495s net 0.2596s post 0.0109s
2017-08-04 09:16:28,830 testing 380/500 data 0.8495s net 0.2595s post 0.0109s
2017-08-04 09:16:29,977 testing 384/500 data 0.8499s net 0.2595s post 0.0109s
2017-08-04 09:16:31,103 testing 388/500 data 0.8500s net 0.2594s post 0.0109s
2017-08-04 09:16:32,334 testing 392/500 data 0.8512s net 0.2594s post 0.0109s
2017-08-04 09:16:33,400 testing 396/500 data 0.8507s net 0.2594s post 0.0108s
2017-08-04 09:16:34,294 testing 400/500 data 0.8485s net 0.2593s post 0.0108s
2017-08-04 09:16:35,447 testing 404/500 data 0.8489s net 0.2592s post 0.0108s
2017-08-04 09:16:36,554 testing 408/500 data 0.8488s net 0.2592s post 0.0108s
2017-08-04 09:16:37,733 testing 412/500 data 0.8494s net 0.2592s post 0.0108s
2017-08-04 09:16:38,870 testing 416/500 data 0.8496s net 0.2591s post 0.0108s
2017-08-04 09:16:39,998 testing 420/500 data 0.8497s net 0.2591s post 0.0108s
2017-08-04 09:16:41,203 testing 424/500 data 0.8506s net 0.2590s post 0.0108s
2017-08-04 09:16:42,351 testing 428/500 data 0.8509s net 0.2590s post 0.0108s
2017-08-04 09:16:43,510 testing 432/500 data 0.8513s net 0.2590s post 0.0108s
2017-08-04 09:16:44,742 testing 436/500 data 0.8523s net 0.2589s post 0.0108s
2017-08-04 09:16:45,946 testing 440/500 data 0.8531s net 0.2589s post 0.0108s
2017-08-04 09:16:47,117 testing 444/500 data 0.8536s net 0.2589s post 0.0108s
2017-08-04 09:16:48,214 testing 448/500 data 0.8534s net 0.2588s post 0.0108s
2017-08-04 09:16:49,535 testing 452/500 data 0.8552s net 0.2588s post 0.0108s
2017-08-04 09:16:50,807 testing 456/500 data 0.8565s net 0.2587s post 0.0108s
2017-08-04 09:16:51,930 testing 460/500 data 0.8566s net 0.2587s post 0.0108s
2017-08-04 09:16:53,123 testing 464/500 data 0.8572s net 0.2587s post 0.0108s
2017-08-04 09:16:54,304 testing 468/500 data 0.8577s net 0.2586s post 0.0108s
2017-08-04 09:16:55,435 testing 472/500 data 0.8578s net 0.2586s post 0.0107s
2017-08-04 09:16:56,653 testing 476/500 data 0.8586s net 0.2586s post 0.0107s
2017-08-04 09:16:57,821 testing 480/500 data 0.8590s net 0.2586s post 0.0107s
2017-08-04 09:16:58,971 testing 484/500 data 0.8592s net 0.2585s post 0.0106s
2017-08-04 09:17:00,260 testing 488/500 data 0.8606s net 0.2585s post 0.0106s
2017-08-04 09:17:01,595 testing 492/500 data 0.8623s net 0.2584s post 0.0107s
2017-08-04 09:17:02,768 testing 496/500 data 0.8626s net 0.2584s post 0.0107s
2017-08-04 09:17:03,527 testing 500/500 data 0.8597s net 0.2584s post 0.0107s
2017-08-04 09:19:03,174 evaluate segmentation: 

2017-08-04 09:19:03,174 IU_array:

2017-08-04 09:19:03,174 0.97906
2017-08-04 09:19:03,174 0.83166
2017-08-04 09:19:03,174 0.91412
2017-08-04 09:19:03,174 0.55353
2017-08-04 09:19:03,174 0.54561
2017-08-04 09:19:03,174 0.52987
2017-08-04 09:19:03,174 0.63592
2017-08-04 09:19:03,174 0.73010
2017-08-04 09:19:03,174 0.91499
2017-08-04 09:19:03,175 0.61790
2017-08-04 09:19:03,175 0.93280
2017-08-04 09:19:03,175 0.78056
2017-08-04 09:19:03,175 0.58058
2017-08-04 09:19:03,175 0.93781
2017-08-04 09:19:03,175 0.66785
2017-08-04 09:19:03,175 0.85530
2017-08-04 09:19:03,175 0.73644
2017-08-04 09:19:03,175 0.61617
2017-08-04 09:19:03,175 0.74078
2017-08-04 09:19:03,175 meanIU:0.74216

2017-07-10 10:49:10,265 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-10 10:51:25,732 Epoch[0] Batch [10]	Speed: 3.49 samples/sec	Train-FCNLogLoss=2.894231,	
2017-07-10 10:51:34,245 Epoch[0] Batch [20]	Speed: 3.52 samples/sec	Train-FCNLogLoss=2.807173,	
2017-07-10 10:51:42,385 Epoch[0] Batch [30]	Speed: 3.69 samples/sec	Train-FCNLogLoss=2.647225,	
2017-07-10 10:51:49,122 Epoch[0] Batch [40]	Speed: 4.45 samples/sec	Train-FCNLogLoss=2.468927,	
2017-07-10 10:51:57,505 Epoch[0] Batch [50]	Speed: 3.58 samples/sec	Train-FCNLogLoss=2.289310,	
2017-07-10 10:52:05,557 Epoch[0] Batch [60]	Speed: 3.73 samples/sec	Train-FCNLogLoss=2.125216,	
2017-07-10 10:52:13,581 Epoch[0] Batch [70]	Speed: 3.74 samples/sec	Train-FCNLogLoss=1.989822,	
2017-07-10 10:52:21,711 Epoch[0] Batch [80]	Speed: 3.69 samples/sec	Train-FCNLogLoss=1.852391,	
2017-07-10 10:52:29,748 Epoch[0] Batch [90]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.735702,	
2017-07-10 10:52:37,848 Epoch[0] Batch [100]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.641252,	
2017-07-10 10:52:45,582 Epoch[0] Batch [110]	Speed: 3.88 samples/sec	Train-FCNLogLoss=1.559848,	
2017-07-10 10:52:53,377 Epoch[0] Batch [120]	Speed: 3.85 samples/sec	Train-FCNLogLoss=1.488897,	
2017-07-10 10:53:00,976 Epoch[0] Batch [130]	Speed: 3.95 samples/sec	Train-FCNLogLoss=1.434204,	
2017-07-10 10:53:09,212 Epoch[0] Batch [140]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.378341,	
2017-07-10 10:53:17,203 Epoch[0] Batch [150]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.326572,	
2017-07-10 10:53:25,130 Epoch[0] Batch [160]	Speed: 3.78 samples/sec	Train-FCNLogLoss=1.283927,	
2017-07-10 10:53:33,434 Epoch[0] Batch [170]	Speed: 3.61 samples/sec	Train-FCNLogLoss=1.243791,	
2017-07-10 10:53:40,826 Epoch[0] Batch [180]	Speed: 4.06 samples/sec	Train-FCNLogLoss=1.207989,	
2017-07-10 10:53:48,859 Epoch[0] Batch [190]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.168475,	
2017-07-10 10:53:56,527 Epoch[0] Batch [200]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.141197,	
2017-07-10 10:54:04,630 Epoch[0] Batch [210]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.114812,	
2017-07-10 10:54:13,172 Epoch[0] Batch [220]	Speed: 3.51 samples/sec	Train-FCNLogLoss=1.086684,	
2017-07-10 10:54:21,542 Epoch[0] Batch [230]	Speed: 3.58 samples/sec	Train-FCNLogLoss=1.066013,	
2017-07-10 10:54:29,547 Epoch[0] Batch [240]	Speed: 3.75 samples/sec	Train-FCNLogLoss=1.039199,	
2017-07-10 10:54:37,589 Epoch[0] Batch [250]	Speed: 3.73 samples/sec	Train-FCNLogLoss=1.016868,	
2017-07-10 10:54:45,836 Epoch[0] Batch [260]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.998586,	
2017-07-10 10:54:53,514 Epoch[0] Batch [270]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.987553,	
2017-07-10 10:55:01,414 Epoch[0] Batch [280]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.971755,	
2017-07-10 10:55:09,373 Epoch[0] Batch [290]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.955902,	
2017-07-10 10:55:17,786 Epoch[0] Batch [300]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.938020,	
2017-07-10 10:55:26,163 Epoch[0] Batch [310]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.920689,	
2017-07-10 10:55:34,250 Epoch[0] Batch [320]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.906637,	
2017-07-10 10:55:42,543 Epoch[0] Batch [330]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.894825,	
2017-07-10 10:55:50,308 Epoch[0] Batch [340]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.884420,	
2017-07-10 10:55:58,642 Epoch[0] Batch [350]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.875793,	
2017-07-10 10:56:06,543 Epoch[0] Batch [360]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.862852,	
2017-07-10 10:56:14,670 Epoch[0] Batch [370]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.852563,	
2017-07-10 10:56:22,789 Epoch[0] Batch [380]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.842376,	
2017-07-10 10:56:30,972 Epoch[0] Batch [390]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.832472,	
2017-07-10 10:56:38,905 Epoch[0] Batch [400]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.821926,	
2017-07-10 10:56:47,208 Epoch[0] Batch [410]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.814147,	
2017-07-10 10:56:55,791 Epoch[0] Batch [420]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.805946,	
2017-07-10 10:57:04,240 Epoch[0] Batch [430]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.796716,	
2017-07-10 10:57:12,348 Epoch[0] Batch [440]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.786269,	
2017-07-10 10:57:19,881 Epoch[0] Batch [450]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.778336,	
2017-07-10 10:57:27,951 Epoch[0] Batch [460]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.770489,	
2017-07-10 10:57:36,219 Epoch[0] Batch [470]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.762883,	
2017-07-10 10:57:44,200 Epoch[0] Batch [480]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.756200,	
2017-07-10 10:57:52,691 Epoch[0] Batch [490]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.750290,	
2017-07-10 10:58:00,495 Epoch[0] Batch [500]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.743656,	
2017-07-10 10:58:08,380 Epoch[0] Batch [510]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.735564,	
2017-07-10 10:58:16,255 Epoch[0] Batch [520]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.729004,	
2017-07-10 10:58:24,452 Epoch[0] Batch [530]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.722035,	
2017-07-10 10:58:33,001 Epoch[0] Batch [540]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.716410,	
2017-07-10 10:58:42,989 Epoch[0] Batch [550]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.710353,	
2017-07-10 10:58:51,197 Epoch[0] Batch [560]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.702794,	
2017-07-10 10:58:58,270 Epoch[0] Batch [570]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.698143,	
2017-07-10 10:59:05,982 Epoch[0] Batch [580]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.692929,	
2017-07-10 10:59:13,887 Epoch[0] Batch [590]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.687590,	
2017-07-10 10:59:21,482 Epoch[0] Batch [600]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.682254,	
2017-07-10 10:59:28,953 Epoch[0] Batch [610]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.677076,	
2017-07-10 10:59:36,210 Epoch[0] Batch [620]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.672450,	
2017-07-10 10:59:43,989 Epoch[0] Batch [630]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.667250,	
2017-07-10 10:59:51,830 Epoch[0] Batch [640]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.662570,	
2017-07-10 10:59:59,525 Epoch[0] Batch [650]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.657480,	
2017-07-10 11:00:07,094 Epoch[0] Batch [660]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.653961,	
2017-07-10 11:00:14,817 Epoch[0] Batch [670]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.649554,	
2017-07-10 11:00:22,407 Epoch[0] Batch [680]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.645798,	
2017-07-10 11:00:29,955 Epoch[0] Batch [690]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.642012,	
2017-07-10 11:00:38,702 Epoch[0] Batch [700]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.638270,	
2017-07-10 11:00:46,996 Epoch[0] Batch [710]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.635244,	
2017-07-10 11:00:55,252 Epoch[0] Batch [720]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.632582,	
2017-07-10 11:01:03,395 Epoch[0] Batch [730]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.628981,	
2017-07-10 11:01:11,712 Epoch[0] Batch [740]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.625197,	
2017-07-10 11:01:19,855 Epoch[0] Batch [750]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.622610,	
2017-07-10 11:01:28,243 Epoch[0] Batch [760]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.618978,	
2017-07-10 11:01:36,163 Epoch[0] Batch [770]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.617546,	
2017-07-10 11:01:44,210 Epoch[0] Batch [780]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.614751,	
2017-07-10 11:01:52,072 Epoch[0] Batch [790]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.612104,	
2017-07-10 11:01:59,944 Epoch[0] Batch [800]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.609186,	
2017-07-10 11:02:07,799 Epoch[0] Batch [810]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.605944,	
2017-07-10 11:02:15,934 Epoch[0] Batch [820]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.602649,	
2017-07-10 11:02:23,845 Epoch[0] Batch [830]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.599776,	
2017-07-10 11:02:31,578 Epoch[0] Batch [840]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.596995,	
2017-07-10 11:02:39,447 Epoch[0] Batch [850]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.593730,	
2017-07-10 11:02:46,877 Epoch[0] Batch [860]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.590910,	
2017-07-10 11:02:54,473 Epoch[0] Batch [870]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.587827,	
2017-07-10 11:03:02,183 Epoch[0] Batch [880]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.585082,	
2017-07-10 11:03:10,247 Epoch[0] Batch [890]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.581822,	
2017-07-10 11:03:17,785 Epoch[0] Batch [900]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.579666,	
2017-07-10 11:03:25,527 Epoch[0] Batch [910]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.577234,	
2017-07-10 11:03:33,260 Epoch[0] Batch [920]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.575009,	
2017-07-10 11:03:40,923 Epoch[0] Batch [930]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.573200,	
2017-07-10 11:03:48,442 Epoch[0] Batch [940]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.570472,	
2017-07-10 11:03:56,355 Epoch[0] Batch [950]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.568302,	
2017-07-10 11:04:04,066 Epoch[0] Batch [960]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.565222,	
2017-07-10 11:04:12,474 Epoch[0] Batch [970]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.563525,	
2017-07-10 11:04:20,643 Epoch[0] Batch [980]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.561551,	
2017-07-10 11:04:28,961 Epoch[0] Batch [990]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.559348,	
2017-07-10 11:04:36,920 Epoch[0] Batch [1000]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.556765,	
2017-07-10 11:04:44,851 Epoch[0] Batch [1010]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.555913,	
2017-07-10 11:04:52,933 Epoch[0] Batch [1020]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.555897,	
2017-07-10 11:05:01,133 Epoch[0] Batch [1030]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.554042,	
2017-07-10 11:05:09,087 Epoch[0] Batch [1040]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.555009,	
2017-07-10 11:05:16,857 Epoch[0] Batch [1050]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.558679,	
2017-07-10 11:05:24,955 Epoch[0] Batch [1060]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.560602,	
2017-07-10 11:05:32,736 Epoch[0] Batch [1070]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.560541,	
2017-07-10 11:05:40,460 Epoch[0] Batch [1080]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.561437,	
2017-07-10 11:05:48,023 Epoch[0] Batch [1090]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.561690,	
2017-07-10 11:05:56,018 Epoch[0] Batch [1100]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.560330,	
2017-07-10 11:06:03,893 Epoch[0] Batch [1110]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.559070,	
2017-07-10 11:06:11,783 Epoch[0] Batch [1120]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.557830,	
2017-07-10 11:06:20,017 Epoch[0] Batch [1130]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.557233,	
2017-07-10 11:06:28,158 Epoch[0] Batch [1140]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.556405,	
2017-07-10 11:06:36,262 Epoch[0] Batch [1150]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.555123,	
2017-07-10 11:06:44,216 Epoch[0] Batch [1160]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.553941,	
2017-07-10 11:06:51,963 Epoch[0] Batch [1170]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.552741,	
2017-07-10 11:06:59,802 Epoch[0] Batch [1180]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.551397,	
2017-07-10 11:07:08,089 Epoch[0] Batch [1190]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.549918,	
2017-07-10 11:07:16,185 Epoch[0] Batch [1200]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.548402,	
2017-07-10 11:07:23,959 Epoch[0] Batch [1210]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.546743,	
2017-07-10 11:07:31,853 Epoch[0] Batch [1220]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.544633,	
2017-07-10 11:07:39,667 Epoch[0] Batch [1230]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.542749,	
2017-07-10 11:07:47,412 Epoch[0] Batch [1240]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.541142,	
2017-07-10 11:07:55,195 Epoch[0] Batch [1250]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.539289,	
2017-07-10 11:08:03,082 Epoch[0] Batch [1260]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.537712,	
2017-07-10 11:08:10,939 Epoch[0] Batch [1270]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.536701,	
2017-07-10 11:08:19,155 Epoch[0] Batch [1280]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.535472,	
2017-07-10 11:08:26,753 Epoch[0] Batch [1290]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.533890,	
2017-07-10 11:08:34,460 Epoch[0] Batch [1300]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.531802,	
2017-07-10 11:08:42,731 Epoch[0] Batch [1310]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.530017,	
2017-07-10 11:08:50,596 Epoch[0] Batch [1320]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.528370,	
2017-07-10 11:08:58,698 Epoch[0] Batch [1330]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.526937,	
2017-07-10 11:09:06,379 Epoch[0] Batch [1340]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.526202,	
2017-07-10 11:09:14,420 Epoch[0] Batch [1350]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.525005,	
2017-07-10 11:09:22,357 Epoch[0] Batch [1360]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.523411,	
2017-07-10 11:09:30,294 Epoch[0] Batch [1370]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.521416,	
2017-07-10 11:09:37,962 Epoch[0] Batch [1380]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.520181,	
2017-07-10 11:09:46,122 Epoch[0] Batch [1390]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.519057,	
2017-07-10 11:09:53,819 Epoch[0] Batch [1400]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.517659,	
2017-07-10 11:10:01,764 Epoch[0] Batch [1410]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.516046,	
2017-07-10 11:10:09,298 Epoch[0] Batch [1420]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.514697,	
2017-07-10 11:10:16,940 Epoch[0] Batch [1430]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.513043,	
2017-07-10 11:10:24,702 Epoch[0] Batch [1440]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.511158,	
2017-07-10 11:10:32,422 Epoch[0] Batch [1450]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.509747,	
2017-07-10 11:10:40,153 Epoch[0] Batch [1460]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.508345,	
2017-07-10 11:10:47,865 Epoch[0] Batch [1470]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.506544,	
2017-07-10 11:10:55,856 Epoch[0] Batch [1480]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.506620,	
2017-07-10 11:11:03,776 Epoch[0] Batch [1490]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.505875,	
2017-07-10 11:11:11,758 Epoch[0] Batch [1500]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.504921,	
2017-07-10 11:11:19,196 Epoch[0] Batch [1510]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.504250,	
2017-07-10 11:11:27,014 Epoch[0] Batch [1520]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.503334,	
2017-07-10 11:11:34,941 Epoch[0] Batch [1530]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.502136,	
2017-07-10 11:11:42,854 Epoch[0] Batch [1540]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.500917,	
2017-07-10 11:11:50,565 Epoch[0] Batch [1550]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.500215,	
2017-07-10 11:11:58,753 Epoch[0] Batch [1560]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.499065,	
2017-07-10 11:12:07,025 Epoch[0] Batch [1570]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.497962,	
2017-07-10 11:12:14,684 Epoch[0] Batch [1580]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.496572,	
2017-07-10 11:12:22,574 Epoch[0] Batch [1590]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.495266,	
2017-07-10 11:12:30,755 Epoch[0] Batch [1600]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.493696,	
2017-07-10 11:12:38,603 Epoch[0] Batch [1610]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.492349,	
2017-07-10 11:12:46,308 Epoch[0] Batch [1620]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.491556,	
2017-07-10 11:12:54,315 Epoch[0] Batch [1630]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.490258,	
2017-07-10 11:13:02,323 Epoch[0] Batch [1640]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.488790,	
2017-07-10 11:13:10,166 Epoch[0] Batch [1650]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.487621,	
2017-07-10 11:13:17,993 Epoch[0] Batch [1660]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.486418,	
2017-07-10 11:13:25,848 Epoch[0] Batch [1670]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.485589,	
2017-07-10 11:13:33,603 Epoch[0] Batch [1680]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.484507,	
2017-07-10 11:13:41,656 Epoch[0] Batch [1690]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.483093,	
2017-07-10 11:13:49,602 Epoch[0] Batch [1700]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.482062,	
2017-07-10 11:13:57,789 Epoch[0] Batch [1710]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.481146,	
2017-07-10 11:14:05,917 Epoch[0] Batch [1720]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.480210,	
2017-07-10 11:14:14,052 Epoch[0] Batch [1730]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.479029,	
2017-07-10 11:14:21,712 Epoch[0] Batch [1740]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.477847,	
2017-07-10 11:14:29,437 Epoch[0] Batch [1750]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.476655,	
2017-07-10 11:14:37,140 Epoch[0] Batch [1760]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.475394,	
2017-07-10 11:14:45,449 Epoch[0] Batch [1770]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.474357,	
2017-07-10 11:14:53,619 Epoch[0] Batch [1780]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.473209,	
2017-07-10 11:15:01,980 Epoch[0] Batch [1790]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.472180,	
2017-07-10 11:15:10,369 Epoch[0] Batch [1800]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.471563,	
2017-07-10 11:15:18,069 Epoch[0] Batch [1810]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.470501,	
2017-07-10 11:15:25,847 Epoch[0] Batch [1820]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.469888,	
2017-07-10 11:15:33,397 Epoch[0] Batch [1830]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.468971,	
2017-07-10 11:15:40,640 Epoch[0] Batch [1840]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.467924,	
2017-07-10 11:15:48,312 Epoch[0] Batch [1850]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.466965,	
2017-07-10 11:15:56,038 Epoch[0] Batch [1860]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.465731,	
2017-07-10 11:16:03,977 Epoch[0] Batch [1870]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.464675,	
2017-07-10 11:16:11,424 Epoch[0] Batch [1880]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.463602,	
2017-07-10 11:16:19,160 Epoch[0] Batch [1890]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.462690,	
2017-07-10 11:16:27,111 Epoch[0] Batch [1900]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.461912,	
2017-07-10 11:16:35,157 Epoch[0] Batch [1910]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.460975,	
2017-07-10 11:16:42,828 Epoch[0] Batch [1920]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.459966,	
2017-07-10 11:16:50,661 Epoch[0] Batch [1930]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.458872,	
2017-07-10 11:16:58,817 Epoch[0] Batch [1940]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.458509,	
2017-07-10 11:17:06,703 Epoch[0] Batch [1950]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.457585,	
2017-07-10 11:17:14,906 Epoch[0] Batch [1960]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.456560,	
2017-07-10 11:17:22,963 Epoch[0] Batch [1970]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.455799,	
2017-07-10 11:17:30,764 Epoch[0] Batch [1980]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.455103,	
2017-07-10 11:17:32,284 Epoch[0] Train-FCNLogLoss=0.455034
2017-07-10 11:17:32,285 Epoch[0] Time cost=1583.439
2017-07-10 11:17:33,245 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-10 11:17:38,166 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-10 11:17:45,690 Epoch[1] Batch [10]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.306343,	
2017-07-10 11:17:52,257 Epoch[1] Batch [20]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.276515,	
2017-07-10 11:17:58,921 Epoch[1] Batch [30]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.298244,	
2017-07-10 11:18:05,535 Epoch[1] Batch [40]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.312428,	
2017-07-10 11:18:12,198 Epoch[1] Batch [50]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.302183,	
2017-07-10 11:18:18,843 Epoch[1] Batch [60]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.298241,	
2017-07-10 11:18:25,424 Epoch[1] Batch [70]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.292225,	
2017-07-10 11:18:32,346 Epoch[1] Batch [80]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.298501,	
2017-07-10 11:18:38,888 Epoch[1] Batch [90]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.301997,	
2017-07-10 11:18:45,509 Epoch[1] Batch [100]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.295499,	
2017-07-10 11:18:52,130 Epoch[1] Batch [110]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.290911,	
2017-07-10 11:18:58,816 Epoch[1] Batch [120]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.284716,	
2017-07-10 11:19:05,518 Epoch[1] Batch [130]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.284374,	
2017-07-10 11:19:12,162 Epoch[1] Batch [140]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.286710,	
2017-07-10 11:19:18,842 Epoch[1] Batch [150]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.284088,	
2017-07-10 11:19:25,485 Epoch[1] Batch [160]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.283600,	
2017-07-10 11:19:32,163 Epoch[1] Batch [170]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.280681,	
2017-07-10 11:19:38,815 Epoch[1] Batch [180]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.282058,	
2017-07-10 11:19:45,620 Epoch[1] Batch [190]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.279940,	
2017-07-10 11:19:52,312 Epoch[1] Batch [200]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.277437,	
2017-07-10 11:19:58,926 Epoch[1] Batch [210]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.274392,	
2017-07-10 11:20:05,513 Epoch[1] Batch [220]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.277090,	
2017-07-10 11:20:12,014 Epoch[1] Batch [230]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.277130,	
2017-07-10 11:20:18,536 Epoch[1] Batch [240]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.276340,	
2017-07-10 11:20:25,186 Epoch[1] Batch [250]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.275188,	
2017-07-10 11:20:31,787 Epoch[1] Batch [260]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.276259,	
2017-07-10 11:20:38,347 Epoch[1] Batch [270]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.274868,	
2017-07-10 11:20:44,905 Epoch[1] Batch [280]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.273605,	
2017-07-10 11:20:51,204 Epoch[1] Batch [290]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.272887,	
2017-07-10 11:20:57,676 Epoch[1] Batch [300]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.272092,	
2017-07-10 11:21:04,326 Epoch[1] Batch [310]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.270960,	
2017-07-10 11:21:10,769 Epoch[1] Batch [320]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.272458,	
2017-07-10 11:21:17,018 Epoch[1] Batch [330]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.271494,	
2017-07-10 11:21:23,556 Epoch[1] Batch [340]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.270317,	
2017-07-10 11:21:30,097 Epoch[1] Batch [350]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.269350,	
2017-07-10 11:21:36,492 Epoch[1] Batch [360]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.268852,	
2017-07-10 11:21:42,920 Epoch[1] Batch [370]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.270894,	
2017-07-10 11:21:49,477 Epoch[1] Batch [380]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.270779,	
2017-07-10 11:21:55,881 Epoch[1] Batch [390]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.269774,	
2017-07-10 11:22:02,191 Epoch[1] Batch [400]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.268852,	
2017-07-10 11:22:08,426 Epoch[1] Batch [410]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.267456,	
2017-07-10 11:22:14,903 Epoch[1] Batch [420]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.267083,	
2017-07-10 11:22:21,560 Epoch[1] Batch [430]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.265668,	
2017-07-10 11:22:28,211 Epoch[1] Batch [440]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.264954,	
2017-07-10 11:22:34,816 Epoch[1] Batch [450]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.265656,	
2017-07-10 11:22:41,557 Epoch[1] Batch [460]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.267253,	
2017-07-10 11:22:48,224 Epoch[1] Batch [470]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.267181,	
2017-07-10 11:22:54,876 Epoch[1] Batch [480]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.267076,	
2017-07-10 11:23:01,573 Epoch[1] Batch [490]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.269341,	
2017-07-10 11:23:08,242 Epoch[1] Batch [500]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.269442,	
2017-07-10 11:23:14,877 Epoch[1] Batch [510]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.270625,	
2017-07-10 11:23:21,671 Epoch[1] Batch [520]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.269836,	
2017-07-10 11:23:28,433 Epoch[1] Batch [530]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.269274,	
2017-07-10 11:23:35,199 Epoch[1] Batch [540]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.268307,	
2017-07-10 11:23:41,783 Epoch[1] Batch [550]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.268003,	
2017-07-10 11:23:48,539 Epoch[1] Batch [560]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.268133,	
2017-07-10 11:23:55,185 Epoch[1] Batch [570]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.267709,	
2017-07-10 11:24:01,792 Epoch[1] Batch [580]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.266831,	
2017-07-10 11:24:08,520 Epoch[1] Batch [590]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.266086,	
2017-07-10 11:24:15,287 Epoch[1] Batch [600]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.264770,	
2017-07-10 11:24:22,102 Epoch[1] Batch [610]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.263579,	
2017-07-10 11:24:28,813 Epoch[1] Batch [620]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.263662,	
2017-07-10 11:24:35,219 Epoch[1] Batch [630]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.263387,	
2017-07-10 11:24:41,466 Epoch[1] Batch [640]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.262636,	
2017-07-10 11:24:47,792 Epoch[1] Batch [650]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.262383,	
2017-07-10 11:24:54,471 Epoch[1] Batch [660]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.262148,	
2017-07-10 11:25:01,489 Epoch[1] Batch [670]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.262392,	
2017-07-10 11:25:08,029 Epoch[1] Batch [680]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.262089,	

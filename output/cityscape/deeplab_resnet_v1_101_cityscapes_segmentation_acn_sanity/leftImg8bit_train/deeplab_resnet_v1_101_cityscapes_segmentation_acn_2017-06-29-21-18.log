2017-06-29 21:18:14,740 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-06-29 21:18:36,816 Epoch[0] Batch [10]	Speed: 2.59 samples/sec	Train-FCNLogLoss=2.903099,	
2017-06-29 21:18:40,560 Epoch[0] Batch [20]	Speed: 2.67 samples/sec	Train-FCNLogLoss=2.877467,	
2017-06-29 21:18:44,507 Epoch[0] Batch [30]	Speed: 2.53 samples/sec	Train-FCNLogLoss=2.848457,	
2017-06-29 21:18:48,343 Epoch[0] Batch [40]	Speed: 2.61 samples/sec	Train-FCNLogLoss=2.808526,	
2017-06-29 21:18:52,367 Epoch[0] Batch [50]	Speed: 2.48 samples/sec	Train-FCNLogLoss=2.760575,	
2017-06-29 21:18:56,360 Epoch[0] Batch [60]	Speed: 2.50 samples/sec	Train-FCNLogLoss=2.677922,	
2017-06-29 21:19:00,197 Epoch[0] Batch [70]	Speed: 2.61 samples/sec	Train-FCNLogLoss=2.583159,	
2017-06-29 21:19:04,084 Epoch[0] Batch [80]	Speed: 2.57 samples/sec	Train-FCNLogLoss=2.479247,	
2017-06-29 21:19:07,978 Epoch[0] Batch [90]	Speed: 2.57 samples/sec	Train-FCNLogLoss=2.398693,	
2017-06-29 21:19:11,941 Epoch[0] Batch [100]	Speed: 2.52 samples/sec	Train-FCNLogLoss=2.335673,	
2017-06-29 21:19:15,964 Epoch[0] Batch [110]	Speed: 2.49 samples/sec	Train-FCNLogLoss=2.275395,	
2017-06-29 21:19:19,735 Epoch[0] Batch [120]	Speed: 2.65 samples/sec	Train-FCNLogLoss=2.188338,	
2017-06-29 21:19:23,678 Epoch[0] Batch [130]	Speed: 2.54 samples/sec	Train-FCNLogLoss=2.141260,	
2017-06-29 21:19:27,557 Epoch[0] Batch [140]	Speed: 2.58 samples/sec	Train-FCNLogLoss=2.097521,	
2017-06-29 21:19:31,342 Epoch[0] Batch [150]	Speed: 2.64 samples/sec	Train-FCNLogLoss=2.034035,	
2017-06-29 21:19:35,145 Epoch[0] Batch [160]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.976003,	
2017-06-29 21:19:38,834 Epoch[0] Batch [170]	Speed: 2.71 samples/sec	Train-FCNLogLoss=1.933329,	
2017-06-29 21:19:42,743 Epoch[0] Batch [180]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.877920,	
2017-06-29 21:19:46,652 Epoch[0] Batch [190]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.833881,	
2017-06-29 21:19:50,578 Epoch[0] Batch [200]	Speed: 2.55 samples/sec	Train-FCNLogLoss=1.783553,	
2017-06-29 21:19:54,400 Epoch[0] Batch [210]	Speed: 2.62 samples/sec	Train-FCNLogLoss=1.739815,	
2017-06-29 21:19:58,354 Epoch[0] Batch [220]	Speed: 2.53 samples/sec	Train-FCNLogLoss=1.701038,	
2017-06-29 21:20:02,169 Epoch[0] Batch [230]	Speed: 2.62 samples/sec	Train-FCNLogLoss=1.661681,	
2017-06-29 21:20:06,098 Epoch[0] Batch [240]	Speed: 2.55 samples/sec	Train-FCNLogLoss=1.625286,	
2017-06-29 21:20:09,783 Epoch[0] Batch [250]	Speed: 2.71 samples/sec	Train-FCNLogLoss=1.590643,	
2017-06-29 21:20:13,442 Epoch[0] Batch [260]	Speed: 2.73 samples/sec	Train-FCNLogLoss=1.565774,	
2017-06-29 21:20:17,148 Epoch[0] Batch [270]	Speed: 2.70 samples/sec	Train-FCNLogLoss=1.531001,	
2017-06-29 21:20:20,923 Epoch[0] Batch [280]	Speed: 2.65 samples/sec	Train-FCNLogLoss=1.502106,	
2017-06-29 21:20:24,824 Epoch[0] Batch [290]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.475527,	
2017-06-29 21:20:28,764 Epoch[0] Batch [300]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.450623,	
2017-06-29 21:20:32,833 Epoch[0] Batch [310]	Speed: 2.46 samples/sec	Train-FCNLogLoss=1.426360,	
2017-06-29 21:20:36,745 Epoch[0] Batch [320]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.401068,	
2017-06-29 21:20:40,589 Epoch[0] Batch [330]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.377311,	
2017-06-29 21:20:44,394 Epoch[0] Batch [340]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.355154,	
2017-06-29 21:20:48,204 Epoch[0] Batch [350]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.335696,	
2017-06-29 21:20:52,145 Epoch[0] Batch [360]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.316410,	
2017-06-29 21:20:56,081 Epoch[0] Batch [370]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.297804,	
2017-06-29 21:21:00,102 Epoch[0] Batch [380]	Speed: 2.49 samples/sec	Train-FCNLogLoss=1.280708,	
2017-06-29 21:21:03,964 Epoch[0] Batch [390]	Speed: 2.59 samples/sec	Train-FCNLogLoss=1.267105,	
2017-06-29 21:21:07,764 Epoch[0] Batch [400]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.250187,	
2017-06-29 21:21:11,594 Epoch[0] Batch [410]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.233036,	
2017-06-29 21:21:15,692 Epoch[0] Batch [420]	Speed: 2.44 samples/sec	Train-FCNLogLoss=1.221924,	
2017-06-29 21:21:19,572 Epoch[0] Batch [430]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.204340,	
2017-06-29 21:21:23,403 Epoch[0] Batch [440]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.191474,	
2017-06-29 21:21:27,307 Epoch[0] Batch [450]	Speed: 2.56 samples/sec	Train-FCNLogLoss=1.177599,	
2017-06-29 21:21:31,134 Epoch[0] Batch [460]	Speed: 2.61 samples/sec	Train-FCNLogLoss=1.164572,	
2017-06-29 21:21:34,976 Epoch[0] Batch [470]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.155650,	
2017-06-29 21:21:38,829 Epoch[0] Batch [480]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.144148,	
2017-06-29 21:21:42,834 Epoch[0] Batch [490]	Speed: 2.50 samples/sec	Train-FCNLogLoss=1.134676,	
2017-06-29 21:21:46,863 Epoch[0] Batch [500]	Speed: 2.48 samples/sec	Train-FCNLogLoss=1.121676,	
2017-06-29 21:21:50,748 Epoch[0] Batch [510]	Speed: 2.57 samples/sec	Train-FCNLogLoss=1.111156,	
2017-06-29 21:21:54,683 Epoch[0] Batch [520]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.098435,	
2017-06-29 21:21:58,617 Epoch[0] Batch [530]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.087480,	
2017-06-29 21:22:02,416 Epoch[0] Batch [540]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.077954,	
2017-06-29 21:22:06,463 Epoch[0] Batch [550]	Speed: 2.47 samples/sec	Train-FCNLogLoss=1.068868,	
2017-06-29 21:22:10,696 Epoch[0] Batch [560]	Speed: 2.36 samples/sec	Train-FCNLogLoss=1.058960,	
2017-06-29 21:22:14,510 Epoch[0] Batch [570]	Speed: 2.62 samples/sec	Train-FCNLogLoss=1.048662,	
2017-06-29 21:22:18,509 Epoch[0] Batch [580]	Speed: 2.50 samples/sec	Train-FCNLogLoss=1.036942,	
2017-06-29 21:22:22,306 Epoch[0] Batch [590]	Speed: 2.63 samples/sec	Train-FCNLogLoss=1.028066,	
2017-06-29 21:22:26,159 Epoch[0] Batch [600]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.025785,	
2017-06-29 21:22:30,151 Epoch[0] Batch [610]	Speed: 2.51 samples/sec	Train-FCNLogLoss=1.017109,	
2017-06-29 21:22:34,034 Epoch[0] Batch [620]	Speed: 2.58 samples/sec	Train-FCNLogLoss=1.010074,	
2017-06-29 21:22:37,884 Epoch[0] Batch [630]	Speed: 2.60 samples/sec	Train-FCNLogLoss=1.001555,	
2017-06-29 21:22:41,774 Epoch[0] Batch [640]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.991105,	
2017-06-29 21:22:45,605 Epoch[0] Batch [650]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.987199,	
2017-06-29 21:22:49,356 Epoch[0] Batch [660]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.982796,	
2017-06-29 21:22:53,260 Epoch[0] Batch [670]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.977992,	
2017-06-29 21:22:57,012 Epoch[0] Batch [680]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.970332,	
2017-06-29 21:23:00,669 Epoch[0] Batch [690]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.963208,	
2017-06-29 21:23:04,241 Epoch[0] Batch [700]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.955749,	
2017-06-29 21:23:08,225 Epoch[0] Batch [710]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.951398,	
2017-06-29 21:23:12,089 Epoch[0] Batch [720]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.944833,	
2017-06-29 21:23:15,874 Epoch[0] Batch [730]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.937193,	
2017-06-29 21:23:19,724 Epoch[0] Batch [740]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.930356,	
2017-06-29 21:23:23,600 Epoch[0] Batch [750]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.926376,	
2017-06-29 21:23:27,522 Epoch[0] Batch [760]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.918498,	
2017-06-29 21:23:31,492 Epoch[0] Batch [770]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.911888,	
2017-06-29 21:23:35,227 Epoch[0] Batch [780]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.906595,	
2017-06-29 21:23:39,033 Epoch[0] Batch [790]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.900504,	
2017-06-29 21:23:42,601 Epoch[0] Batch [800]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.896276,	
2017-06-29 21:23:46,410 Epoch[0] Batch [810]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.889758,	
2017-06-29 21:23:50,143 Epoch[0] Batch [820]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.885275,	
2017-06-29 21:23:54,113 Epoch[0] Batch [830]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.880865,	
2017-06-29 21:23:57,838 Epoch[0] Batch [840]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.876738,	
2017-06-29 21:24:01,409 Epoch[0] Batch [850]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.871985,	
2017-06-29 21:24:05,506 Epoch[0] Batch [860]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.867179,	
2017-06-29 21:24:09,594 Epoch[0] Batch [870]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.865864,	
2017-06-29 21:24:13,647 Epoch[0] Batch [880]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.862507,	
2017-06-29 21:24:17,847 Epoch[0] Batch [890]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.857141,	
2017-06-29 21:24:21,989 Epoch[0] Batch [900]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.853970,	
2017-06-29 21:24:25,727 Epoch[0] Batch [910]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.850371,	
2017-06-29 21:24:29,590 Epoch[0] Batch [920]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.847369,	
2017-06-29 21:24:33,363 Epoch[0] Batch [930]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.842968,	
2017-06-29 21:24:37,195 Epoch[0] Batch [940]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.839277,	
2017-06-29 21:24:40,902 Epoch[0] Batch [950]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.834860,	
2017-06-29 21:24:44,641 Epoch[0] Batch [960]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.830131,	
2017-06-29 21:24:48,628 Epoch[0] Batch [970]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.825400,	
2017-06-29 21:24:52,602 Epoch[0] Batch [980]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.821349,	
2017-06-29 21:24:56,365 Epoch[0] Batch [990]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.817798,	
2017-06-29 21:25:00,252 Epoch[0] Batch [1000]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.814696,	
2017-06-29 21:25:04,113 Epoch[0] Batch [1010]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.812280,	
2017-06-29 21:25:07,848 Epoch[0] Batch [1020]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.809698,	
2017-06-29 21:25:11,153 Epoch[0] Batch [1030]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.808146,	
2017-06-29 21:25:14,966 Epoch[0] Batch [1040]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.805959,	
2017-06-29 21:25:18,816 Epoch[0] Batch [1050]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.803841,	
2017-06-29 21:25:22,449 Epoch[0] Batch [1060]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.802439,	
2017-06-29 21:25:26,285 Epoch[0] Batch [1070]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.799714,	
2017-06-29 21:25:30,097 Epoch[0] Batch [1080]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.795620,	
2017-06-29 21:25:33,909 Epoch[0] Batch [1090]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.793417,	
2017-06-29 21:25:37,588 Epoch[0] Batch [1100]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.792475,	
2017-06-29 21:25:41,335 Epoch[0] Batch [1110]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.789855,	
2017-06-29 21:25:45,071 Epoch[0] Batch [1120]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.789143,	
2017-06-29 21:25:48,756 Epoch[0] Batch [1130]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.786666,	
2017-06-29 21:25:52,728 Epoch[0] Batch [1140]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.785779,	
2017-06-29 21:25:56,621 Epoch[0] Batch [1150]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.782439,	
2017-06-29 21:26:00,581 Epoch[0] Batch [1160]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.779319,	
2017-06-29 21:26:04,439 Epoch[0] Batch [1170]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.777978,	
2017-06-29 21:26:08,320 Epoch[0] Batch [1180]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.775665,	
2017-06-29 21:26:12,093 Epoch[0] Batch [1190]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.772388,	
2017-06-29 21:26:15,886 Epoch[0] Batch [1200]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.768857,	
2017-06-29 21:26:19,572 Epoch[0] Batch [1210]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.767156,	
2017-06-29 21:26:23,356 Epoch[0] Batch [1220]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.765392,	
2017-06-29 21:26:27,394 Epoch[0] Batch [1230]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.762692,	
2017-06-29 21:26:31,283 Epoch[0] Batch [1240]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.759711,	
2017-06-29 21:26:35,094 Epoch[0] Batch [1250]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.757795,	
2017-06-29 21:26:38,123 Epoch[0] Batch [1260]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.757389,	
2017-06-29 21:26:42,036 Epoch[0] Batch [1270]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.754528,	
2017-06-29 21:26:46,200 Epoch[0] Batch [1280]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.751418,	
2017-06-29 21:26:50,164 Epoch[0] Batch [1290]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.748856,	
2017-06-29 21:26:53,647 Epoch[0] Batch [1300]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.746868,	
2017-06-29 21:26:56,996 Epoch[0] Batch [1310]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.745365,	
2017-06-29 21:27:00,428 Epoch[0] Batch [1320]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.742602,	
2017-06-29 21:27:03,804 Epoch[0] Batch [1330]	Speed: 2.96 samples/sec	Train-FCNLogLoss=0.740280,	
2017-06-29 21:27:07,114 Epoch[0] Batch [1340]	Speed: 3.02 samples/sec	Train-FCNLogLoss=0.737875,	
2017-06-29 21:27:10,377 Epoch[0] Batch [1350]	Speed: 3.06 samples/sec	Train-FCNLogLoss=0.735913,	
2017-06-29 21:27:13,700 Epoch[0] Batch [1360]	Speed: 3.01 samples/sec	Train-FCNLogLoss=0.733238,	
2017-06-29 21:27:16,864 Epoch[0] Batch [1370]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.730243,	
2017-06-29 21:27:20,047 Epoch[0] Batch [1380]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.727536,	
2017-06-29 21:27:23,254 Epoch[0] Batch [1390]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.724795,	
2017-06-29 21:27:26,626 Epoch[0] Batch [1400]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.723027,	
2017-06-29 21:27:30,135 Epoch[0] Batch [1410]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.720833,	
2017-06-29 21:27:33,760 Epoch[0] Batch [1420]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.720681,	
2017-06-29 21:27:37,102 Epoch[0] Batch [1430]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.717594,	
2017-06-29 21:27:40,790 Epoch[0] Batch [1440]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.716307,	
2017-06-29 21:27:44,297 Epoch[0] Batch [1450]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.714810,	
2017-06-29 21:27:48,138 Epoch[0] Batch [1460]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.712357,	
2017-06-29 21:27:51,632 Epoch[0] Batch [1470]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.709522,	
2017-06-29 21:27:55,095 Epoch[0] Batch [1480]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.706968,	
2017-06-29 21:27:58,580 Epoch[0] Batch [1490]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.704552,	
2017-06-29 21:28:02,026 Epoch[0] Batch [1500]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.703271,	
2017-06-29 21:28:05,285 Epoch[0] Batch [1510]	Speed: 3.07 samples/sec	Train-FCNLogLoss=0.703054,	
2017-06-29 21:28:08,708 Epoch[0] Batch [1520]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.702253,	
2017-06-29 21:28:12,081 Epoch[0] Batch [1530]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.700683,	
2017-06-29 21:28:15,341 Epoch[0] Batch [1540]	Speed: 3.07 samples/sec	Train-FCNLogLoss=0.698727,	
2017-06-29 21:28:18,786 Epoch[0] Batch [1550]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.696876,	
2017-06-29 21:28:22,021 Epoch[0] Batch [1560]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.694486,	
2017-06-29 21:28:25,199 Epoch[0] Batch [1570]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.691992,	
2017-06-29 21:28:28,489 Epoch[0] Batch [1580]	Speed: 3.04 samples/sec	Train-FCNLogLoss=0.690947,	
2017-06-29 21:28:31,851 Epoch[0] Batch [1590]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.688906,	
2017-06-29 21:28:35,304 Epoch[0] Batch [1600]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.687729,	
2017-06-29 21:28:38,960 Epoch[0] Batch [1610]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.686139,	
2017-06-29 21:28:42,382 Epoch[0] Batch [1620]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.685269,	
2017-06-29 21:28:45,851 Epoch[0] Batch [1630]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.683528,	
2017-06-29 21:28:49,479 Epoch[0] Batch [1640]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.682619,	
2017-06-29 21:28:53,132 Epoch[0] Batch [1650]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.682499,	
2017-06-29 21:28:56,703 Epoch[0] Batch [1660]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.680549,	
2017-06-29 21:29:00,140 Epoch[0] Batch [1670]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.679661,	
2017-06-29 21:29:03,570 Epoch[0] Batch [1680]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.678018,	
2017-06-29 21:29:07,148 Epoch[0] Batch [1690]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.675963,	
2017-06-29 21:29:10,891 Epoch[0] Batch [1700]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.673725,	
2017-06-29 21:29:14,685 Epoch[0] Batch [1710]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.672975,	
2017-06-29 21:29:18,381 Epoch[0] Batch [1720]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.671743,	
2017-06-29 21:29:22,184 Epoch[0] Batch [1730]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.670201,	
2017-06-29 21:29:25,901 Epoch[0] Batch [1740]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.668502,	
2017-06-29 21:29:29,524 Epoch[0] Batch [1750]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.667266,	
2017-06-29 21:29:33,196 Epoch[0] Batch [1760]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.665534,	
2017-06-29 21:29:36,786 Epoch[0] Batch [1770]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.664121,	
2017-06-29 21:29:40,573 Epoch[0] Batch [1780]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.662221,	
2017-06-29 21:29:44,270 Epoch[0] Batch [1790]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.660690,	
2017-06-29 21:29:48,138 Epoch[0] Batch [1800]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.659739,	
2017-06-29 21:29:52,008 Epoch[0] Batch [1810]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.657650,	
2017-06-29 21:29:55,879 Epoch[0] Batch [1820]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.656101,	
2017-06-29 21:29:59,803 Epoch[0] Batch [1830]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.654099,	
2017-06-29 21:30:03,579 Epoch[0] Batch [1840]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.652204,	
2017-06-29 21:30:07,244 Epoch[0] Batch [1850]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.651146,	
2017-06-29 21:30:11,153 Epoch[0] Batch [1860]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.649238,	
2017-06-29 21:30:15,065 Epoch[0] Batch [1870]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.647880,	
2017-06-29 21:30:19,074 Epoch[0] Batch [1880]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.646971,	
2017-06-29 21:30:22,980 Epoch[0] Batch [1890]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.645311,	
2017-06-29 21:30:26,863 Epoch[0] Batch [1900]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.643739,	
2017-06-29 21:30:30,863 Epoch[0] Batch [1910]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.643177,	
2017-06-29 21:30:34,735 Epoch[0] Batch [1920]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.642039,	
2017-06-29 21:30:38,449 Epoch[0] Batch [1930]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.640603,	
2017-06-29 21:30:42,355 Epoch[0] Batch [1940]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.639934,	
2017-06-29 21:30:46,136 Epoch[0] Batch [1950]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.638945,	
2017-06-29 21:30:49,952 Epoch[0] Batch [1960]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.637742,	
2017-06-29 21:30:53,594 Epoch[0] Batch [1970]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.636389,	
2017-06-29 21:30:57,323 Epoch[0] Batch [1980]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.635979,	
2017-06-29 21:31:01,041 Epoch[0] Batch [1990]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.634274,	
2017-06-29 21:31:04,840 Epoch[0] Batch [2000]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.633291,	
2017-06-29 21:31:08,844 Epoch[0] Batch [2010]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.631522,	
2017-06-29 21:31:12,605 Epoch[0] Batch [2020]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.629714,	
2017-06-29 21:31:16,432 Epoch[0] Batch [2030]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.627752,	
2017-06-29 21:31:20,175 Epoch[0] Batch [2040]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.626295,	
2017-06-29 21:31:23,897 Epoch[0] Batch [2050]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.624771,	
2017-06-29 21:31:27,646 Epoch[0] Batch [2060]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.623503,	
2017-06-29 21:31:31,587 Epoch[0] Batch [2070]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.622053,	
2017-06-29 21:31:35,419 Epoch[0] Batch [2080]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.620381,	
2017-06-29 21:31:39,215 Epoch[0] Batch [2090]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.619173,	
2017-06-29 21:31:43,033 Epoch[0] Batch [2100]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.618515,	
2017-06-29 21:31:46,780 Epoch[0] Batch [2110]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.617445,	
2017-06-29 21:31:50,771 Epoch[0] Batch [2120]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.616614,	
2017-06-29 21:31:54,879 Epoch[0] Batch [2130]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.615336,	
2017-06-29 21:31:58,640 Epoch[0] Batch [2140]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.615166,	
2017-06-29 21:32:02,664 Epoch[0] Batch [2150]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.613877,	
2017-06-29 21:32:06,533 Epoch[0] Batch [2160]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.612204,	
2017-06-29 21:32:10,496 Epoch[0] Batch [2170]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.611784,	
2017-06-29 21:32:14,465 Epoch[0] Batch [2180]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.610808,	
2017-06-29 21:32:18,537 Epoch[0] Batch [2190]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.609496,	
2017-06-29 21:32:22,502 Epoch[0] Batch [2200]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.608326,	
2017-06-29 21:32:26,385 Epoch[0] Batch [2210]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.607173,	
2017-06-29 21:32:30,407 Epoch[0] Batch [2220]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.606189,	
2017-06-29 21:32:34,372 Epoch[0] Batch [2230]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.605068,	
2017-06-29 21:32:38,137 Epoch[0] Batch [2240]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.603914,	
2017-06-29 21:32:41,899 Epoch[0] Batch [2250]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.602643,	
2017-06-29 21:32:45,825 Epoch[0] Batch [2260]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.601458,	
2017-06-29 21:32:49,741 Epoch[0] Batch [2270]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.599994,	
2017-06-29 21:32:53,595 Epoch[0] Batch [2280]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.598879,	
2017-06-29 21:32:57,410 Epoch[0] Batch [2290]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.597326,	
2017-06-29 21:33:01,303 Epoch[0] Batch [2300]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.596420,	
2017-06-29 21:33:05,274 Epoch[0] Batch [2310]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.594977,	
2017-06-29 21:33:09,186 Epoch[0] Batch [2320]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.593540,	
2017-06-29 21:33:13,009 Epoch[0] Batch [2330]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.592595,	
2017-06-29 21:33:17,004 Epoch[0] Batch [2340]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.591843,	
2017-06-29 21:33:20,976 Epoch[0] Batch [2350]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.590587,	
2017-06-29 21:33:24,775 Epoch[0] Batch [2360]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.589761,	
2017-06-29 21:33:28,618 Epoch[0] Batch [2370]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.588706,	
2017-06-29 21:33:32,592 Epoch[0] Batch [2380]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.587452,	
2017-06-29 21:33:36,511 Epoch[0] Batch [2390]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.586495,	
2017-06-29 21:33:40,322 Epoch[0] Batch [2400]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.585347,	
2017-06-29 21:33:44,326 Epoch[0] Batch [2410]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.584127,	
2017-06-29 21:33:48,075 Epoch[0] Batch [2420]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.582846,	
2017-06-29 21:33:51,968 Epoch[0] Batch [2430]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.582062,	
2017-06-29 21:33:55,848 Epoch[0] Batch [2440]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.580870,	
2017-06-29 21:33:59,702 Epoch[0] Batch [2450]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.579639,	
2017-06-29 21:34:03,475 Epoch[0] Batch [2460]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.579966,	
2017-06-29 21:34:07,346 Epoch[0] Batch [2470]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.579472,	
2017-06-29 21:34:11,175 Epoch[0] Batch [2480]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.578373,	
2017-06-29 21:34:14,956 Epoch[0] Batch [2490]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.577593,	
2017-06-29 21:34:18,999 Epoch[0] Batch [2500]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.576391,	
2017-06-29 21:34:22,866 Epoch[0] Batch [2510]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.574993,	
2017-06-29 21:34:26,745 Epoch[0] Batch [2520]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.573779,	
2017-06-29 21:34:30,592 Epoch[0] Batch [2530]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.573278,	
2017-06-29 21:34:34,151 Epoch[0] Batch [2540]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.572575,	
2017-06-29 21:34:37,931 Epoch[0] Batch [2550]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.571786,	
2017-06-29 21:34:41,760 Epoch[0] Batch [2560]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.570814,	
2017-06-29 21:34:45,494 Epoch[0] Batch [2570]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.569766,	
2017-06-29 21:34:49,311 Epoch[0] Batch [2580]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.568402,	
2017-06-29 21:34:53,258 Epoch[0] Batch [2590]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.567215,	
2017-06-29 21:34:57,059 Epoch[0] Batch [2600]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.566111,	
2017-06-29 21:35:00,840 Epoch[0] Batch [2610]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.565406,	
2017-06-29 21:35:04,767 Epoch[0] Batch [2620]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.564549,	
2017-06-29 21:35:08,787 Epoch[0] Batch [2630]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.563402,	
2017-06-29 21:35:12,568 Epoch[0] Batch [2640]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.562517,	
2017-06-29 21:35:16,413 Epoch[0] Batch [2650]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.561660,	
2017-06-29 21:35:20,179 Epoch[0] Batch [2660]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.560718,	
2017-06-29 21:35:23,468 Epoch[0] Batch [2670]	Speed: 3.04 samples/sec	Train-FCNLogLoss=0.559570,	
2017-06-29 21:35:27,286 Epoch[0] Batch [2680]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.558604,	
2017-06-29 21:35:31,308 Epoch[0] Batch [2690]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.557827,	
2017-06-29 21:35:35,379 Epoch[0] Batch [2700]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.556800,	
2017-06-29 21:35:39,152 Epoch[0] Batch [2710]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.555853,	
2017-06-29 21:35:42,965 Epoch[0] Batch [2720]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.554550,	
2017-06-29 21:35:46,915 Epoch[0] Batch [2730]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.553708,	
2017-06-29 21:35:50,656 Epoch[0] Batch [2740]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.552548,	
2017-06-29 21:35:54,525 Epoch[0] Batch [2750]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.551447,	
2017-06-29 21:35:58,433 Epoch[0] Batch [2760]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.550579,	
2017-06-29 21:36:02,522 Epoch[0] Batch [2770]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.549766,	
2017-06-29 21:36:06,206 Epoch[0] Batch [2780]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.549059,	
2017-06-29 21:36:09,928 Epoch[0] Batch [2790]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.548187,	
2017-06-29 21:36:13,499 Epoch[0] Batch [2800]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.547143,	
2017-06-29 21:36:16,866 Epoch[0] Batch [2810]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.546221,	
2017-06-29 21:36:20,317 Epoch[0] Batch [2820]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.545244,	
2017-06-29 21:36:23,875 Epoch[0] Batch [2830]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.544327,	
2017-06-29 21:36:27,503 Epoch[0] Batch [2840]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.543318,	
2017-06-29 21:36:31,179 Epoch[0] Batch [2850]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.542282,	
2017-06-29 21:36:34,619 Epoch[0] Batch [2860]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.541060,	
2017-06-29 21:36:38,043 Epoch[0] Batch [2870]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.540330,	
2017-06-29 21:36:41,410 Epoch[0] Batch [2880]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.539290,	
2017-06-29 21:36:44,486 Epoch[0] Batch [2890]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.538021,	
2017-06-29 21:36:47,846 Epoch[0] Batch [2900]	Speed: 2.98 samples/sec	Train-FCNLogLoss=0.537198,	
2017-06-29 21:36:51,146 Epoch[0] Batch [2910]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.536219,	
2017-06-29 21:36:54,473 Epoch[0] Batch [2920]	Speed: 3.01 samples/sec	Train-FCNLogLoss=0.535398,	
2017-06-29 21:36:58,082 Epoch[0] Batch [2930]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.534679,	
2017-06-29 21:37:01,563 Epoch[0] Batch [2940]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.533718,	
2017-06-29 21:37:05,234 Epoch[0] Batch [2950]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.532657,	
2017-06-29 21:37:08,848 Epoch[0] Batch [2960]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.531787,	
2017-06-29 21:37:12,414 Epoch[0] Batch [2970]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.530819,	
2017-06-29 21:37:15,808 Epoch[0] Batch [2980]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.529951,	
2017-06-29 21:37:19,347 Epoch[0] Batch [2990]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.529515,	
2017-06-29 21:37:22,490 Epoch[0] Batch [3000]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.528758,	
2017-06-29 21:37:25,599 Epoch[0] Batch [3010]	Speed: 3.22 samples/sec	Train-FCNLogLoss=0.527917,	
2017-06-29 21:37:29,074 Epoch[0] Batch [3020]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.527370,	
2017-06-29 21:37:32,515 Epoch[0] Batch [3030]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.526510,	
2017-06-29 21:37:35,988 Epoch[0] Batch [3040]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.525912,	
2017-06-29 21:37:39,519 Epoch[0] Batch [3050]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.525171,	
2017-06-29 21:37:43,017 Epoch[0] Batch [3060]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.524471,	
2017-06-29 21:37:46,405 Epoch[0] Batch [3070]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.523761,	
2017-06-29 21:37:49,617 Epoch[0] Batch [3080]	Speed: 3.11 samples/sec	Train-FCNLogLoss=0.523092,	
2017-06-29 21:37:52,802 Epoch[0] Batch [3090]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.522407,	
2017-06-29 21:37:56,162 Epoch[0] Batch [3100]	Speed: 2.98 samples/sec	Train-FCNLogLoss=0.521620,	
2017-06-29 21:37:59,438 Epoch[0] Batch [3110]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.520798,	
2017-06-29 21:38:02,904 Epoch[0] Batch [3120]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.521043,	
2017-06-29 21:38:06,121 Epoch[0] Batch [3130]	Speed: 3.11 samples/sec	Train-FCNLogLoss=0.520385,	
2017-06-29 21:38:09,356 Epoch[0] Batch [3140]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.519568,	
2017-06-29 21:38:12,873 Epoch[0] Batch [3150]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.519259,	
2017-06-29 21:38:16,684 Epoch[0] Batch [3160]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.518429,	
2017-06-29 21:38:20,299 Epoch[0] Batch [3170]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.517676,	
2017-06-29 21:38:23,739 Epoch[0] Batch [3180]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.517299,	
2017-06-29 21:38:27,543 Epoch[0] Batch [3190]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.516460,	
2017-06-29 21:38:30,982 Epoch[0] Batch [3200]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.516439,	
2017-06-29 21:38:34,461 Epoch[0] Batch [3210]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.515710,	
2017-06-29 21:38:37,907 Epoch[0] Batch [3220]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.514926,	
2017-06-29 21:38:41,363 Epoch[0] Batch [3230]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.514081,	
2017-06-29 21:38:44,806 Epoch[0] Batch [3240]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.513197,	
2017-06-29 21:38:48,458 Epoch[0] Batch [3250]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.512491,	
2017-06-29 21:38:52,157 Epoch[0] Batch [3260]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.511866,	
2017-06-29 21:38:55,454 Epoch[0] Batch [3270]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.511120,	
2017-06-29 21:38:58,964 Epoch[0] Batch [3280]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.510278,	
2017-06-29 21:39:02,427 Epoch[0] Batch [3290]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.509494,	
2017-06-29 21:39:06,105 Epoch[0] Batch [3300]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.508483,	
2017-06-29 21:39:09,609 Epoch[0] Batch [3310]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.507966,	
2017-06-29 21:39:13,336 Epoch[0] Batch [3320]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.507090,	
2017-06-29 21:39:16,985 Epoch[0] Batch [3330]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.506199,	
2017-06-29 21:39:20,454 Epoch[0] Batch [3340]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.505515,	
2017-06-29 21:39:24,063 Epoch[0] Batch [3350]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.504730,	
2017-06-29 21:39:27,569 Epoch[0] Batch [3360]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.503950,	
2017-06-29 21:39:31,283 Epoch[0] Batch [3370]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.503237,	
2017-06-29 21:39:34,783 Epoch[0] Batch [3380]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.502669,	
2017-06-29 21:39:38,147 Epoch[0] Batch [3390]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.502177,	
2017-06-29 21:39:41,341 Epoch[0] Batch [3400]	Speed: 3.13 samples/sec	Train-FCNLogLoss=0.501362,	
2017-06-29 21:39:44,847 Epoch[0] Batch [3410]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.500740,	
2017-06-29 21:39:48,150 Epoch[0] Batch [3420]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.500203,	
2017-06-29 21:39:51,304 Epoch[0] Batch [3430]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.499354,	
2017-06-29 21:39:54,749 Epoch[0] Batch [3440]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.498506,	
2017-06-29 21:39:57,820 Epoch[0] Batch [3450]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.497761,	
2017-06-29 21:40:01,032 Epoch[0] Batch [3460]	Speed: 3.11 samples/sec	Train-FCNLogLoss=0.497110,	
2017-06-29 21:40:04,461 Epoch[0] Batch [3470]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.496513,	
2017-06-29 21:40:07,504 Epoch[0] Batch [3480]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.495898,	
2017-06-29 21:40:10,887 Epoch[0] Batch [3490]	Speed: 2.96 samples/sec	Train-FCNLogLoss=0.495362,	
2017-06-29 21:40:14,204 Epoch[0] Batch [3500]	Speed: 3.01 samples/sec	Train-FCNLogLoss=0.494796,	
2017-06-29 21:40:17,632 Epoch[0] Batch [3510]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.494132,	
2017-06-29 21:40:21,008 Epoch[0] Batch [3520]	Speed: 2.96 samples/sec	Train-FCNLogLoss=0.493626,	
2017-06-29 21:40:24,479 Epoch[0] Batch [3530]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.492798,	
2017-06-29 21:40:28,158 Epoch[0] Batch [3540]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.492439,	
2017-06-29 21:40:31,432 Epoch[0] Batch [3550]	Speed: 3.06 samples/sec	Train-FCNLogLoss=0.491731,	
2017-06-29 21:40:34,915 Epoch[0] Batch [3560]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.491158,	
2017-06-29 21:40:38,375 Epoch[0] Batch [3570]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.490505,	
2017-06-29 21:40:41,838 Epoch[0] Batch [3580]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.489944,	
2017-06-29 21:40:45,220 Epoch[0] Batch [3590]	Speed: 2.96 samples/sec	Train-FCNLogLoss=0.489255,	
2017-06-29 21:40:48,808 Epoch[0] Batch [3600]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.488286,	
2017-06-29 21:40:52,205 Epoch[0] Batch [3610]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.487527,	
2017-06-29 21:40:55,594 Epoch[0] Batch [3620]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.487051,	
2017-06-29 21:40:59,052 Epoch[0] Batch [3630]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.486342,	
2017-06-29 21:41:02,566 Epoch[0] Batch [3640]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.485715,	
2017-06-29 21:41:05,822 Epoch[0] Batch [3650]	Speed: 3.07 samples/sec	Train-FCNLogLoss=0.485095,	
2017-06-29 21:41:09,375 Epoch[0] Batch [3660]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.484456,	
2017-06-29 21:41:13,182 Epoch[0] Batch [3670]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.483735,	
2017-06-29 21:41:16,999 Epoch[0] Batch [3680]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.483254,	
2017-06-29 21:41:20,688 Epoch[0] Batch [3690]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.482774,	
2017-06-29 21:41:24,214 Epoch[0] Batch [3700]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.482095,	
2017-06-29 21:41:27,732 Epoch[0] Batch [3710]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.481696,	
2017-06-29 21:41:31,127 Epoch[0] Batch [3720]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.481276,	
2017-06-29 21:41:34,582 Epoch[0] Batch [3730]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.480823,	
2017-06-29 21:41:37,948 Epoch[0] Batch [3740]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.480376,	
2017-06-29 21:41:41,472 Epoch[0] Batch [3750]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.479763,	
2017-06-29 21:41:44,868 Epoch[0] Batch [3760]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.479088,	
2017-06-29 21:41:47,989 Epoch[0] Batch [3770]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.478365,	
2017-06-29 21:41:51,428 Epoch[0] Batch [3780]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.477728,	
2017-06-29 21:41:54,639 Epoch[0] Batch [3790]	Speed: 3.11 samples/sec	Train-FCNLogLoss=0.477464,	
2017-06-29 21:41:57,957 Epoch[0] Batch [3800]	Speed: 3.01 samples/sec	Train-FCNLogLoss=0.477109,	
2017-06-29 21:42:01,121 Epoch[0] Batch [3810]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.476684,	
2017-06-29 21:42:04,509 Epoch[0] Batch [3820]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.476172,	
2017-06-29 21:42:07,666 Epoch[0] Batch [3830]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.475591,	
2017-06-29 21:42:11,299 Epoch[0] Batch [3840]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.476143,	
2017-06-29 21:42:15,152 Epoch[0] Batch [3850]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.475785,	
2017-06-29 21:42:18,710 Epoch[0] Batch [3860]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.475350,	
2017-06-29 21:42:22,426 Epoch[0] Batch [3870]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.475071,	
2017-06-29 21:42:26,275 Epoch[0] Batch [3880]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.474475,	
2017-06-29 21:42:29,964 Epoch[0] Batch [3890]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.473940,	
2017-06-29 21:42:33,818 Epoch[0] Batch [3900]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.474150,	
2017-06-29 21:42:37,668 Epoch[0] Batch [3910]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.474109,	
2017-06-29 21:42:41,727 Epoch[0] Batch [3920]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.473485,	
2017-06-29 21:42:45,539 Epoch[0] Batch [3930]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.473009,	
2017-06-29 21:42:49,344 Epoch[0] Batch [3940]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.472703,	
2017-06-29 21:42:53,221 Epoch[0] Batch [3950]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.472123,	
2017-06-29 21:42:57,013 Epoch[0] Batch [3960]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.471601,	
2017-06-29 21:43:00,998 Epoch[0] Batch [3970]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.470917,	
2017-06-29 21:43:04,949 Epoch[0] Batch [3980]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.470666,	
2017-06-29 21:43:08,681 Epoch[0] Batch [3990]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.470428,	
2017-06-29 21:43:12,470 Epoch[0] Batch [4000]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.469899,	
2017-06-29 21:43:16,175 Epoch[0] Batch [4010]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.469271,	
2017-06-29 21:43:20,095 Epoch[0] Batch [4020]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.468619,	
2017-06-29 21:43:23,777 Epoch[0] Batch [4030]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.468031,	
2017-06-29 21:43:27,766 Epoch[0] Batch [4040]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.467582,	
2017-06-29 21:43:31,702 Epoch[0] Batch [4050]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.467070,	
2017-06-29 21:43:35,883 Epoch[0] Batch [4060]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.466785,	
2017-06-29 21:43:39,786 Epoch[0] Batch [4070]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.466112,	
2017-06-29 21:43:43,674 Epoch[0] Batch [4080]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.465813,	
2017-06-29 21:43:47,457 Epoch[0] Batch [4090]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.465465,	
2017-06-29 21:43:51,171 Epoch[0] Batch [4100]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.465045,	
2017-06-29 21:43:54,952 Epoch[0] Batch [4110]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.464495,	
2017-06-29 21:43:58,744 Epoch[0] Batch [4120]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.463922,	
2017-06-29 21:44:02,488 Epoch[0] Batch [4130]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.463468,	
2017-06-29 21:44:06,339 Epoch[0] Batch [4140]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.463180,	
2017-06-29 21:44:10,187 Epoch[0] Batch [4150]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.462774,	
2017-06-29 21:44:13,898 Epoch[0] Batch [4160]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.462242,	
2017-06-29 21:44:17,725 Epoch[0] Batch [4170]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.461749,	
2017-06-29 21:44:21,500 Epoch[0] Batch [4180]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.461273,	
2017-06-29 21:44:25,246 Epoch[0] Batch [4190]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.460672,	
2017-06-29 21:44:28,903 Epoch[0] Batch [4200]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.460339,	
2017-06-29 21:44:32,593 Epoch[0] Batch [4210]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.459844,	
2017-06-29 21:44:36,431 Epoch[0] Batch [4220]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.459440,	
2017-06-29 21:44:40,314 Epoch[0] Batch [4230]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.458817,	
2017-06-29 21:44:44,183 Epoch[0] Batch [4240]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.458415,	
2017-06-29 21:44:47,934 Epoch[0] Batch [4250]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.458638,	
2017-06-29 21:44:51,810 Epoch[0] Batch [4260]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.458948,	
2017-06-29 21:44:55,754 Epoch[0] Batch [4270]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.458695,	
2017-06-29 21:44:59,596 Epoch[0] Batch [4280]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.458368,	
2017-06-29 21:45:03,242 Epoch[0] Batch [4290]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.457849,	
2017-06-29 21:45:07,144 Epoch[0] Batch [4300]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.457274,	
2017-06-29 21:45:11,005 Epoch[0] Batch [4310]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.456611,	
2017-06-29 21:45:14,844 Epoch[0] Batch [4320]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.456056,	
2017-06-29 21:45:18,613 Epoch[0] Batch [4330]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.455631,	
2017-06-29 21:45:22,658 Epoch[0] Batch [4340]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.455296,	
2017-06-29 21:45:26,665 Epoch[0] Batch [4350]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.454926,	
2017-06-29 21:45:30,622 Epoch[0] Batch [4360]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.454523,	
2017-06-29 21:45:34,505 Epoch[0] Batch [4370]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.454870,	
2017-06-29 21:45:38,394 Epoch[0] Batch [4380]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.454599,	
2017-06-29 21:45:42,377 Epoch[0] Batch [4390]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.454257,	
2017-06-29 21:45:46,340 Epoch[0] Batch [4400]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.453986,	
2017-06-29 21:45:50,318 Epoch[0] Batch [4410]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.453512,	
2017-06-29 21:45:54,290 Epoch[0] Batch [4420]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.453186,	
2017-06-29 21:45:58,214 Epoch[0] Batch [4430]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.452819,	
2017-06-29 21:46:01,967 Epoch[0] Batch [4440]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.452249,	
2017-06-29 21:46:05,837 Epoch[0] Batch [4450]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.451752,	
2017-06-29 21:46:09,702 Epoch[0] Batch [4460]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.451417,	
2017-06-29 21:46:13,806 Epoch[0] Batch [4470]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.450894,	
2017-06-29 21:46:17,843 Epoch[0] Batch [4480]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.450529,	
2017-06-29 21:46:21,619 Epoch[0] Batch [4490]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.450154,	
2017-06-29 21:46:25,526 Epoch[0] Batch [4500]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.449726,	
2017-06-29 21:46:29,245 Epoch[0] Batch [4510]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.449381,	
2017-06-29 21:46:33,231 Epoch[0] Batch [4520]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.448968,	
2017-06-29 21:46:37,050 Epoch[0] Batch [4530]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.448513,	
2017-06-29 21:46:40,980 Epoch[0] Batch [4540]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.448155,	
2017-06-29 21:46:44,790 Epoch[0] Batch [4550]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.447687,	
2017-06-29 21:46:48,575 Epoch[0] Batch [4560]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.447321,	
2017-06-29 21:46:52,547 Epoch[0] Batch [4570]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.446758,	
2017-06-29 21:46:56,389 Epoch[0] Batch [4580]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.446580,	
2017-06-29 21:47:00,218 Epoch[0] Batch [4590]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.446267,	
2017-06-29 21:47:03,995 Epoch[0] Batch [4600]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.446274,	
2017-06-29 21:47:07,947 Epoch[0] Batch [4610]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.445898,	
2017-06-29 21:47:11,710 Epoch[0] Batch [4620]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.445468,	
2017-06-29 21:47:15,613 Epoch[0] Batch [4630]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.445006,	
2017-06-29 21:47:19,281 Epoch[0] Batch [4640]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.444726,	
2017-06-29 21:47:22,947 Epoch[0] Batch [4650]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.444151,	
2017-06-29 21:47:26,780 Epoch[0] Batch [4660]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.444295,	
2017-06-29 21:47:30,922 Epoch[0] Batch [4670]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.443990,	
2017-06-29 21:47:34,972 Epoch[0] Batch [4680]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.443550,	
2017-06-29 21:47:38,783 Epoch[0] Batch [4690]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.443277,	
2017-06-29 21:47:42,465 Epoch[0] Batch [4700]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.443304,	
2017-06-29 21:47:46,338 Epoch[0] Batch [4710]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.442876,	
2017-06-29 21:47:50,317 Epoch[0] Batch [4720]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.442374,	
2017-06-29 21:47:54,233 Epoch[0] Batch [4730]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.442001,	
2017-06-29 21:47:58,017 Epoch[0] Batch [4740]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.441802,	
2017-06-29 21:48:01,939 Epoch[0] Batch [4750]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.441359,	
2017-06-29 21:48:05,731 Epoch[0] Batch [4760]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.440994,	
2017-06-29 21:48:09,688 Epoch[0] Batch [4770]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.440625,	
2017-06-29 21:48:13,626 Epoch[0] Batch [4780]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.440435,	
2017-06-29 21:48:17,562 Epoch[0] Batch [4790]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.440099,	
2017-06-29 21:48:21,263 Epoch[0] Batch [4800]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.439629,	
2017-06-29 21:48:25,131 Epoch[0] Batch [4810]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.439159,	
2017-06-29 21:48:28,790 Epoch[0] Batch [4820]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.438811,	
2017-06-29 21:48:32,662 Epoch[0] Batch [4830]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.438482,	
2017-06-29 21:48:36,744 Epoch[0] Batch [4840]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.438223,	
2017-06-29 21:48:40,813 Epoch[0] Batch [4850]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.437959,	
2017-06-29 21:48:44,670 Epoch[0] Batch [4860]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.437608,	
2017-06-29 21:48:48,569 Epoch[0] Batch [4870]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.437224,	
2017-06-29 21:48:52,492 Epoch[0] Batch [4880]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.436837,	
2017-06-29 21:48:56,567 Epoch[0] Batch [4890]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.436331,	
2017-06-29 21:49:00,328 Epoch[0] Batch [4900]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.435966,	
2017-06-29 21:49:04,110 Epoch[0] Batch [4910]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.435779,	
2017-06-29 21:49:07,805 Epoch[0] Batch [4920]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.435322,	
2017-06-29 21:49:11,605 Epoch[0] Batch [4930]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.435036,	
2017-06-29 21:49:15,316 Epoch[0] Batch [4940]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.434690,	
2017-06-29 21:49:19,177 Epoch[0] Batch [4950]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.434375,	
2017-06-29 21:49:23,040 Epoch[0] Batch [4960]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.434053,	
2017-06-29 21:49:26,860 Epoch[0] Batch [4970]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.433765,	
2017-06-29 21:49:30,810 Epoch[0] Batch [4980]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.433593,	
2017-06-29 21:49:34,430 Epoch[0] Batch [4990]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.433184,	
2017-06-29 21:49:37,964 Epoch[0] Batch [5000]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.432787,	
2017-06-29 21:49:41,809 Epoch[0] Batch [5010]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.432399,	
2017-06-29 21:49:45,481 Epoch[0] Batch [5020]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.431871,	
2017-06-29 21:49:48,930 Epoch[0] Batch [5030]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.431489,	
2017-06-29 21:49:52,854 Epoch[0] Batch [5040]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.431098,	
2017-06-29 21:49:56,602 Epoch[0] Batch [5050]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.430598,	
2017-06-29 21:50:00,473 Epoch[0] Batch [5060]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.430223,	
2017-06-29 21:50:04,404 Epoch[0] Batch [5070]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.429733,	
2017-06-29 21:50:08,299 Epoch[0] Batch [5080]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.429486,	
2017-06-29 21:50:12,210 Epoch[0] Batch [5090]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.429348,	
2017-06-29 21:50:16,030 Epoch[0] Batch [5100]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.428890,	
2017-06-29 21:50:20,006 Epoch[0] Batch [5110]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.428403,	
2017-06-29 21:50:23,862 Epoch[0] Batch [5120]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.427970,	
2017-06-29 21:50:27,724 Epoch[0] Batch [5130]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.427642,	
2017-06-29 21:50:31,598 Epoch[0] Batch [5140]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.427260,	
2017-06-29 21:50:35,595 Epoch[0] Batch [5150]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.426934,	
2017-06-29 21:50:39,483 Epoch[0] Batch [5160]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.426606,	
2017-06-29 21:50:43,387 Epoch[0] Batch [5170]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.426264,	
2017-06-29 21:50:47,408 Epoch[0] Batch [5180]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.425913,	
2017-06-29 21:50:51,558 Epoch[0] Batch [5190]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.425579,	
2017-06-29 21:50:55,513 Epoch[0] Batch [5200]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.425267,	
2017-06-29 21:50:59,523 Epoch[0] Batch [5210]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.424923,	
2017-06-29 21:51:03,473 Epoch[0] Batch [5220]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.424549,	
2017-06-29 21:51:07,490 Epoch[0] Batch [5230]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.424198,	
2017-06-29 21:51:11,375 Epoch[0] Batch [5240]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.423795,	
2017-06-29 21:51:14,993 Epoch[0] Batch [5250]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.423526,	
2017-06-29 21:51:18,453 Epoch[0] Batch [5260]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.423110,	
2017-06-29 21:51:22,213 Epoch[0] Batch [5270]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.423260,	
2017-06-29 21:51:25,849 Epoch[0] Batch [5280]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.423016,	
2017-06-29 21:51:29,484 Epoch[0] Batch [5290]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.422877,	
2017-06-29 21:51:33,157 Epoch[0] Batch [5300]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.422560,	
2017-06-29 21:51:36,547 Epoch[0] Batch [5310]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.422116,	
2017-06-29 21:51:40,030 Epoch[0] Batch [5320]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.421765,	
2017-06-29 21:51:43,364 Epoch[0] Batch [5330]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.421753,	
2017-06-29 21:51:46,703 Epoch[0] Batch [5340]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.421359,	
2017-06-29 21:51:50,173 Epoch[0] Batch [5350]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.421481,	
2017-06-29 21:51:53,648 Epoch[0] Batch [5360]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.421208,	
2017-06-29 21:51:57,201 Epoch[0] Batch [5370]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.421274,	
2017-06-29 21:52:00,700 Epoch[0] Batch [5380]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.421010,	
2017-06-29 21:52:04,279 Epoch[0] Batch [5390]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.420626,	
2017-06-29 21:52:07,961 Epoch[0] Batch [5400]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.420276,	
2017-06-29 21:52:11,765 Epoch[0] Batch [5410]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.419877,	
2017-06-29 21:52:15,458 Epoch[0] Batch [5420]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.419602,	
2017-06-29 21:52:19,266 Epoch[0] Batch [5430]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.419445,	
2017-06-29 21:52:22,994 Epoch[0] Batch [5440]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.419041,	
2017-06-29 21:52:26,675 Epoch[0] Batch [5450]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.418754,	
2017-06-29 21:52:30,103 Epoch[0] Batch [5460]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.418397,	
2017-06-29 21:52:33,480 Epoch[0] Batch [5470]	Speed: 2.96 samples/sec	Train-FCNLogLoss=0.418062,	
2017-06-29 21:52:37,376 Epoch[0] Batch [5480]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.417887,	
2017-06-29 21:52:41,142 Epoch[0] Batch [5490]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.417518,	
2017-06-29 21:52:44,945 Epoch[0] Batch [5500]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.417164,	
2017-06-29 21:52:48,795 Epoch[0] Batch [5510]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.416865,	
2017-06-29 21:52:52,569 Epoch[0] Batch [5520]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.416515,	
2017-06-29 21:52:56,287 Epoch[0] Batch [5530]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.416146,	
2017-06-29 21:53:00,109 Epoch[0] Batch [5540]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.415767,	
2017-06-29 21:53:03,802 Epoch[0] Batch [5550]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.415442,	
2017-06-29 21:53:07,257 Epoch[0] Batch [5560]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.415041,	
2017-06-29 21:53:10,881 Epoch[0] Batch [5570]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.414764,	
2017-06-29 21:53:14,675 Epoch[0] Batch [5580]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.414432,	
2017-06-29 21:53:18,327 Epoch[0] Batch [5590]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.414050,	
2017-06-29 21:53:22,166 Epoch[0] Batch [5600]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.413676,	
2017-06-29 21:53:25,874 Epoch[0] Batch [5610]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.413256,	
2017-06-29 21:53:29,477 Epoch[0] Batch [5620]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.413259,	
2017-06-29 21:53:33,033 Epoch[0] Batch [5630]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.412920,	
2017-06-29 21:53:36,383 Epoch[0] Batch [5640]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.412643,	
2017-06-29 21:53:39,827 Epoch[0] Batch [5650]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.412326,	
2017-06-29 21:53:43,312 Epoch[0] Batch [5660]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.412014,	
2017-06-29 21:53:47,013 Epoch[0] Batch [5670]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.411687,	
2017-06-29 21:53:50,781 Epoch[0] Batch [5680]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.411369,	
2017-06-29 21:53:54,532 Epoch[0] Batch [5690]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.411179,	
2017-06-29 21:53:57,995 Epoch[0] Batch [5700]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.411172,	
2017-06-29 21:54:01,227 Epoch[0] Batch [5710]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.410936,	
2017-06-29 21:54:04,668 Epoch[0] Batch [5720]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.410913,	
2017-06-29 21:54:08,070 Epoch[0] Batch [5730]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.410690,	
2017-06-29 21:54:11,349 Epoch[0] Batch [5740]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.410333,	
2017-06-29 21:54:14,736 Epoch[0] Batch [5750]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.410137,	
2017-06-29 21:54:18,029 Epoch[0] Batch [5760]	Speed: 3.04 samples/sec	Train-FCNLogLoss=0.409798,	
2017-06-29 21:54:21,509 Epoch[0] Batch [5770]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.409687,	
2017-06-29 21:54:24,795 Epoch[0] Batch [5780]	Speed: 3.04 samples/sec	Train-FCNLogLoss=0.409544,	
2017-06-29 21:54:28,070 Epoch[0] Batch [5790]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.409307,	
2017-06-29 21:54:31,221 Epoch[0] Batch [5800]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.408996,	
2017-06-29 21:54:34,308 Epoch[0] Batch [5810]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.408757,	
2017-06-29 21:54:37,676 Epoch[0] Batch [5820]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.408583,	
2017-06-29 21:54:41,045 Epoch[0] Batch [5830]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.408277,	
2017-06-29 21:54:44,171 Epoch[0] Batch [5840]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.407973,	
2017-06-29 21:54:47,695 Epoch[0] Batch [5850]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.407754,	
2017-06-29 21:54:51,101 Epoch[0] Batch [5860]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.407492,	
2017-06-29 21:54:54,490 Epoch[0] Batch [5870]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.407185,	
2017-06-29 21:54:57,613 Epoch[0] Batch [5880]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.406799,	
2017-06-29 21:55:00,313 Epoch[0] Batch [5890]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.406446,	
2017-06-29 21:55:02,966 Epoch[0] Batch [5900]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.406258,	
2017-06-29 21:55:05,766 Epoch[0] Batch [5910]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.406063,	
2017-06-29 21:55:08,599 Epoch[0] Batch [5920]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.405810,	
2017-06-29 21:55:11,286 Epoch[0] Batch [5930]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.405625,	
2017-06-29 21:55:14,050 Epoch[0] Batch [5940]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.405403,	
2017-06-29 21:55:16,752 Epoch[0] Train-FCNLogLoss=0.405167
2017-06-29 21:55:16,753 Epoch[0] Time cost=2204.634

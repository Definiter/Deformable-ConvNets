2017-06-05 11:40:45,840 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn'}

2017-06-05 13:00:45,639 Epoch[0] Batch [10]	Speed: 5.86 samples/sec	Train-FCNLogLoss=2.895658,	
2017-06-05 13:00:53,211 Epoch[0] Batch [20]	Speed: 5.28 samples/sec	Train-FCNLogLoss=2.788252,	
2017-06-05 13:01:00,324 Epoch[0] Batch [30]	Speed: 5.62 samples/sec	Train-FCNLogLoss=2.567515,	
2017-06-05 13:01:08,363 Epoch[0] Batch [40]	Speed: 4.98 samples/sec	Train-FCNLogLoss=2.326786,	
2017-06-05 13:01:15,419 Epoch[0] Batch [50]	Speed: 5.67 samples/sec	Train-FCNLogLoss=2.113632,	
2017-06-05 13:01:22,924 Epoch[0] Batch [60]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.945665,	
2017-06-05 13:01:30,004 Epoch[0] Batch [70]	Speed: 5.65 samples/sec	Train-FCNLogLoss=1.791560,	
2017-06-05 13:01:37,409 Epoch[0] Batch [80]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.664375,	
2017-06-05 13:01:44,683 Epoch[0] Batch [90]	Speed: 5.50 samples/sec	Train-FCNLogLoss=1.560001,	
2017-06-05 13:01:51,760 Epoch[0] Batch [100]	Speed: 5.65 samples/sec	Train-FCNLogLoss=1.475365,	
2017-06-05 13:01:59,170 Epoch[0] Batch [110]	Speed: 5.40 samples/sec	Train-FCNLogLoss=1.411600,	
2017-06-05 13:02:06,642 Epoch[0] Batch [120]	Speed: 5.35 samples/sec	Train-FCNLogLoss=1.358430,	
2017-06-05 13:02:14,947 Epoch[0] Batch [130]	Speed: 4.82 samples/sec	Train-FCNLogLoss=1.309057,	
2017-06-05 13:02:22,853 Epoch[0] Batch [140]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.254889,	
2017-06-05 13:02:30,797 Epoch[0] Batch [150]	Speed: 5.04 samples/sec	Train-FCNLogLoss=1.213783,	
2017-06-05 13:02:38,423 Epoch[0] Batch [160]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.173889,	
2017-06-05 13:02:45,868 Epoch[0] Batch [170]	Speed: 5.37 samples/sec	Train-FCNLogLoss=1.135923,	
2017-06-05 13:02:53,496 Epoch[0] Batch [180]	Speed: 5.24 samples/sec	Train-FCNLogLoss=1.097375,	
2017-06-05 13:03:00,892 Epoch[0] Batch [190]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.060857,	
2017-06-05 13:03:08,953 Epoch[0] Batch [200]	Speed: 4.96 samples/sec	Train-FCNLogLoss=1.030466,	
2017-06-05 13:03:16,139 Epoch[0] Batch [210]	Speed: 5.57 samples/sec	Train-FCNLogLoss=1.004879,	
2017-06-05 13:03:24,013 Epoch[0] Batch [220]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.980433,	
2017-06-05 13:03:31,234 Epoch[0] Batch [230]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.963055,	
2017-06-05 13:03:38,532 Epoch[0] Batch [240]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.946108,	
2017-06-05 13:03:45,976 Epoch[0] Batch [250]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.928268,	
2017-06-05 13:03:52,949 Epoch[0] Batch [260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.908877,	
2017-06-05 13:04:00,719 Epoch[0] Batch [270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.890231,	
2017-06-05 13:04:07,960 Epoch[0] Batch [280]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.875057,	
2017-06-05 13:04:15,949 Epoch[0] Batch [290]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.864063,	
2017-06-05 13:04:23,601 Epoch[0] Batch [300]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.850615,	
2017-06-05 13:04:31,336 Epoch[0] Batch [310]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.838264,	
2017-06-05 13:04:38,600 Epoch[0] Batch [320]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.825777,	
2017-06-05 13:04:46,322 Epoch[0] Batch [330]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.813351,	
2017-06-05 13:04:53,939 Epoch[0] Batch [340]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.802191,	
2017-06-05 13:05:01,227 Epoch[0] Batch [350]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.790741,	
2017-06-05 13:05:08,255 Epoch[0] Batch [360]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.780747,	
2017-06-05 13:05:15,584 Epoch[0] Batch [370]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.771095,	
2017-06-05 13:05:22,768 Epoch[0] Batch [380]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.762587,	
2017-06-05 13:05:30,684 Epoch[0] Batch [390]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.753240,	
2017-06-05 13:05:38,364 Epoch[0] Batch [400]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.742580,	
2017-06-05 13:05:45,542 Epoch[0] Batch [410]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.733676,	
2017-06-05 13:05:53,163 Epoch[0] Batch [420]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.725401,	
2017-06-05 13:06:00,628 Epoch[0] Batch [430]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.717434,	
2017-06-05 13:06:07,948 Epoch[0] Batch [440]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.709045,	
2017-06-05 13:06:15,348 Epoch[0] Batch [450]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.701758,	
2017-06-05 13:06:23,681 Epoch[0] Batch [460]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.695254,	
2017-06-05 13:06:31,560 Epoch[0] Batch [470]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.688764,	
2017-06-05 13:06:39,066 Epoch[0] Batch [480]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.682984,	
2017-06-05 13:06:46,967 Epoch[0] Batch [490]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.677284,	
2017-06-05 13:06:55,214 Epoch[0] Batch [500]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.670987,	
2017-06-05 13:07:03,090 Epoch[0] Batch [510]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.664710,	
2017-06-05 13:07:11,206 Epoch[0] Batch [520]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.659551,	
2017-06-05 13:07:18,651 Epoch[0] Batch [530]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.654680,	
2017-06-05 13:07:26,595 Epoch[0] Batch [540]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.649897,	
2017-06-05 13:07:34,940 Epoch[0] Batch [550]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.644313,	
2017-06-05 13:07:42,765 Epoch[0] Batch [560]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.638870,	
2017-06-05 13:07:50,504 Epoch[0] Batch [570]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.633892,	
2017-06-05 13:07:58,657 Epoch[0] Batch [580]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.629217,	
2017-06-05 13:08:06,883 Epoch[0] Batch [590]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.624174,	
2017-06-05 13:08:14,484 Epoch[0] Batch [600]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.620275,	
2017-06-05 13:08:22,391 Epoch[0] Batch [610]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.616248,	
2017-06-05 13:08:31,119 Epoch[0] Batch [620]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.611736,	
2017-06-05 13:08:39,120 Epoch[0] Batch [630]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.607460,	
2017-06-05 13:08:46,764 Epoch[0] Batch [640]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.603570,	
2017-06-05 13:08:54,604 Epoch[0] Batch [650]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.599399,	
2017-06-05 13:09:02,446 Epoch[0] Batch [660]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.597197,	
2017-06-05 13:09:10,038 Epoch[0] Batch [670]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.593187,	
2017-06-05 13:09:17,650 Epoch[0] Batch [680]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.589589,	
2017-06-05 13:09:25,359 Epoch[0] Batch [690]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.586307,	
2017-06-05 13:09:33,417 Epoch[0] Batch [700]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.582698,	
2017-06-05 13:09:41,798 Epoch[0] Batch [710]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.579926,	
2017-06-05 13:09:49,503 Epoch[0] Batch [720]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.576936,	
2017-06-05 13:09:57,039 Epoch[0] Batch [730]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.573960,	
2017-06-05 13:10:04,577 Epoch[0] Batch [740]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.571191,	
2017-06-05 13:10:12,525 Epoch[0] Batch [750]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.568453,	
2017-06-05 13:10:20,334 Epoch[0] Batch [760]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.565473,	
2017-06-05 13:10:28,112 Epoch[0] Batch [770]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.562547,	
2017-06-05 13:10:35,790 Epoch[0] Batch [780]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.559202,	
2017-06-05 13:10:43,653 Epoch[0] Batch [790]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.556281,	
2017-06-05 13:10:52,059 Epoch[0] Batch [800]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.554072,	
2017-06-05 13:11:00,189 Epoch[0] Batch [810]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.551332,	
2017-06-05 13:11:07,734 Epoch[0] Batch [820]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.548298,	
2017-06-05 13:11:15,648 Epoch[0] Batch [830]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.545290,	
2017-06-05 13:11:23,959 Epoch[0] Batch [840]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.542531,	
2017-06-05 13:11:31,493 Epoch[0] Batch [850]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.541153,	
2017-06-05 13:11:38,804 Epoch[0] Batch [860]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.538740,	
2017-06-05 13:11:46,557 Epoch[0] Batch [870]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.536255,	
2017-06-05 13:11:53,359 Epoch[0] Batch [880]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.533529,	
2017-06-05 13:12:01,493 Epoch[0] Batch [890]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.531100,	
2017-06-05 13:12:08,758 Epoch[0] Batch [900]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.528786,	
2017-06-05 13:12:15,540 Epoch[0] Batch [910]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.526728,	
2017-06-05 13:12:20,386 Epoch[0] Batch [920]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.524700,	
2017-06-05 13:12:25,359 Epoch[0] Batch [930]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.522354,	
2017-06-05 13:12:29,956 Epoch[0] Batch [940]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.520273,	
2017-06-05 13:12:34,661 Epoch[0] Batch [950]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.517728,	
2017-06-05 13:12:39,277 Epoch[0] Batch [960]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.515414,	
2017-06-05 13:12:44,152 Epoch[0] Batch [970]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.513363,	
2017-06-05 13:12:48,695 Epoch[0] Batch [980]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.511296,	
2017-06-05 13:12:53,429 Epoch[0] Batch [990]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.509252,	
2017-06-05 13:12:58,185 Epoch[0] Batch [1000]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.507886,	
2017-06-05 13:13:03,081 Epoch[0] Batch [1010]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.506780,	
2017-06-05 13:13:08,010 Epoch[0] Batch [1020]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.510771,	
2017-06-05 13:13:12,782 Epoch[0] Batch [1030]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.511413,	
2017-06-05 13:13:17,193 Epoch[0] Batch [1040]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.511935,	
2017-06-05 13:13:21,847 Epoch[0] Batch [1050]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.512566,	
2017-06-05 13:13:26,196 Epoch[0] Batch [1060]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.512664,	
2017-06-05 13:13:30,915 Epoch[0] Batch [1070]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.512105,	
2017-06-05 13:13:35,745 Epoch[0] Batch [1080]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.510744,	
2017-06-05 13:13:40,515 Epoch[0] Batch [1090]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.509389,	
2017-06-05 13:13:45,261 Epoch[0] Batch [1100]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.508456,	
2017-06-05 13:13:49,769 Epoch[0] Batch [1110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.508061,	
2017-06-05 13:13:54,523 Epoch[0] Batch [1120]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.507359,	
2017-06-05 13:13:59,334 Epoch[0] Batch [1130]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.506045,	
2017-06-05 13:14:04,069 Epoch[0] Batch [1140]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.504725,	
2017-06-05 13:14:08,606 Epoch[0] Batch [1150]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.503436,	
2017-06-05 13:14:13,383 Epoch[0] Batch [1160]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.502554,	
2017-06-05 13:14:18,142 Epoch[0] Batch [1170]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.502468,	
2017-06-05 13:14:22,980 Epoch[0] Batch [1180]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.500944,	
2017-06-05 13:14:27,822 Epoch[0] Batch [1190]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.501202,	
2017-06-05 13:14:32,577 Epoch[0] Batch [1200]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.501236,	
2017-06-05 13:14:37,379 Epoch[0] Batch [1210]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.500791,	
2017-06-05 13:14:42,108 Epoch[0] Batch [1220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.500039,	
2017-06-05 13:14:46,961 Epoch[0] Batch [1230]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.498529,	
2017-06-05 13:14:51,784 Epoch[0] Batch [1240]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.497049,	
2017-06-05 13:14:56,627 Epoch[0] Batch [1250]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.495824,	
2017-06-05 13:15:01,171 Epoch[0] Batch [1260]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.494553,	
2017-06-05 13:15:05,950 Epoch[0] Batch [1270]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.492894,	
2017-06-05 13:15:10,526 Epoch[0] Batch [1280]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.491743,	
2017-06-05 13:15:15,141 Epoch[0] Batch [1290]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.490362,	
2017-06-05 13:15:19,919 Epoch[0] Batch [1300]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.489058,	
2017-06-05 13:15:24,456 Epoch[0] Batch [1310]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.487409,	
2017-06-05 13:15:29,030 Epoch[0] Batch [1320]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.486055,	
2017-06-05 13:15:33,638 Epoch[0] Batch [1330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.484414,	
2017-06-05 13:15:38,551 Epoch[0] Batch [1340]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.483866,	
2017-06-05 13:15:43,389 Epoch[0] Batch [1350]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.484426,	
2017-06-05 13:15:48,198 Epoch[0] Batch [1360]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.483607,	
2017-06-05 13:15:52,983 Epoch[0] Batch [1370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.482867,	
2017-06-05 13:15:57,636 Epoch[0] Batch [1380]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.482014,	
2017-06-05 13:16:02,649 Epoch[0] Batch [1390]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.480662,	
2017-06-05 13:16:07,471 Epoch[0] Batch [1400]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.479237,	
2017-06-05 13:16:12,230 Epoch[0] Batch [1410]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.477850,	
2017-06-05 13:16:16,759 Epoch[0] Batch [1420]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.476466,	
2017-06-05 13:16:20,933 Epoch[0] Batch [1430]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.475386,	
2017-06-05 13:16:25,686 Epoch[0] Batch [1440]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.474477,	
2017-06-05 13:16:30,646 Epoch[0] Batch [1450]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.473263,	
2017-06-05 13:16:35,471 Epoch[0] Batch [1460]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.471763,	
2017-06-05 13:16:40,203 Epoch[0] Batch [1470]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.470237,	
2017-06-05 13:16:44,926 Epoch[0] Batch [1480]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.469191,	
2017-06-05 13:16:47,807 Epoch[0] Train-FCNLogLoss=0.468304
2017-06-05 13:16:47,807 Epoch[0] Time cost=974.590
2017-06-05 13:16:48,922 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn-0001.params"
2017-06-05 13:16:50,746 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn-0001.states"
2017-06-05 13:16:56,208 Epoch[1] Batch [10]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.274775,	
2017-06-05 13:17:00,507 Epoch[1] Batch [20]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.295360,	
2017-06-05 13:17:05,242 Epoch[1] Batch [30]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.310326,	
2017-06-05 13:17:09,783 Epoch[1] Batch [40]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.330835,	
2017-06-05 13:17:14,464 Epoch[1] Batch [50]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.333770,	
2017-06-05 13:17:19,121 Epoch[1] Batch [60]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.328554,	
2017-06-05 13:17:23,682 Epoch[1] Batch [70]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.320574,	
2017-06-05 13:17:28,176 Epoch[1] Batch [80]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.317704,	
2017-06-05 13:17:32,561 Epoch[1] Batch [90]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.312024,	
2017-06-05 13:17:37,025 Epoch[1] Batch [100]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.304913,	
2017-06-05 13:17:41,661 Epoch[1] Batch [110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.302956,	
2017-06-05 13:17:46,195 Epoch[1] Batch [120]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.295379,	
2017-06-05 13:17:50,649 Epoch[1] Batch [130]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.294608,	
2017-06-05 13:17:55,370 Epoch[1] Batch [140]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.289602,	
2017-06-05 13:17:59,764 Epoch[1] Batch [150]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.288570,	
2017-06-05 13:18:04,247 Epoch[1] Batch [160]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.290558,	
2017-06-05 13:18:08,858 Epoch[1] Batch [170]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.289804,	
2017-06-05 13:18:13,875 Epoch[1] Batch [180]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.287053,	
2017-06-05 13:18:18,619 Epoch[1] Batch [190]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.285406,	
2017-06-05 13:18:23,231 Epoch[1] Batch [200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.280982,	
2017-06-05 13:18:27,635 Epoch[1] Batch [210]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.278913,	
2017-06-05 13:18:32,313 Epoch[1] Batch [220]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.277534,	
2017-06-05 13:18:36,730 Epoch[1] Batch [230]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.276354,	
2017-06-05 13:18:41,210 Epoch[1] Batch [240]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.276746,	
2017-06-05 13:18:45,995 Epoch[1] Batch [250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.276422,	
2017-06-05 13:18:50,502 Epoch[1] Batch [260]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.276358,	
2017-06-05 13:18:54,884 Epoch[1] Batch [270]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.273996,	
2017-06-05 13:18:59,667 Epoch[1] Batch [280]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.273359,	
2017-06-05 13:19:04,020 Epoch[1] Batch [290]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.273337,	
2017-06-05 13:19:08,742 Epoch[1] Batch [300]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.272273,	
2017-06-05 13:19:13,296 Epoch[1] Batch [310]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.270673,	
2017-06-05 13:19:17,640 Epoch[1] Batch [320]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.269414,	
2017-06-05 13:19:22,233 Epoch[1] Batch [330]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.268376,	
2017-06-05 13:19:27,051 Epoch[1] Batch [340]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.266821,	
2017-06-05 13:19:31,804 Epoch[1] Batch [350]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.270031,	
2017-06-05 13:19:36,556 Epoch[1] Batch [360]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.270801,	
2017-06-05 13:19:41,193 Epoch[1] Batch [370]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.271514,	
2017-06-05 13:19:45,677 Epoch[1] Batch [380]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.270870,	
2017-06-05 13:19:50,379 Epoch[1] Batch [390]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.270500,	
2017-06-05 13:19:54,893 Epoch[1] Batch [400]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.268935,	
2017-06-05 13:19:59,603 Epoch[1] Batch [410]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.268206,	
2017-06-05 13:20:04,194 Epoch[1] Batch [420]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.266952,	
2017-06-05 13:20:09,093 Epoch[1] Batch [430]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.266197,	
2017-06-05 13:20:13,331 Epoch[1] Batch [440]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.265552,	
2017-06-05 13:20:18,117 Epoch[1] Batch [450]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.264382,	
2017-06-05 13:20:22,467 Epoch[1] Batch [460]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.264678,	
2017-06-05 13:20:27,152 Epoch[1] Batch [470]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.264353,	
2017-06-05 13:20:31,486 Epoch[1] Batch [480]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.263095,	
2017-06-05 13:20:35,794 Epoch[1] Batch [490]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.263276,	
2017-06-05 13:20:40,431 Epoch[1] Batch [500]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.263332,	
2017-06-05 13:20:45,016 Epoch[1] Batch [510]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.262538,	
2017-06-05 13:20:49,662 Epoch[1] Batch [520]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.261507,	
2017-06-05 13:20:54,238 Epoch[1] Batch [530]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.261088,	
2017-06-05 13:20:58,681 Epoch[1] Batch [540]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.260743,	
2017-06-05 13:21:03,151 Epoch[1] Batch [550]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.260340,	
2017-06-05 13:21:07,802 Epoch[1] Batch [560]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.260457,	
2017-06-05 13:21:12,720 Epoch[1] Batch [570]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.260411,	
2017-06-05 13:21:17,478 Epoch[1] Batch [580]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.260786,	
2017-06-05 13:21:22,170 Epoch[1] Batch [590]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.260220,	
2017-06-05 13:21:26,618 Epoch[1] Batch [600]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.260805,	
2017-06-05 13:21:30,737 Epoch[1] Batch [610]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.260797,	
2017-06-05 13:21:35,094 Epoch[1] Batch [620]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.261167,	
2017-06-05 13:21:39,683 Epoch[1] Batch [630]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.261778,	
2017-06-05 13:21:44,040 Epoch[1] Batch [640]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.261885,	
2017-06-05 13:21:48,583 Epoch[1] Batch [650]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.261289,	
2017-06-05 13:21:53,494 Epoch[1] Batch [660]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.260935,	
2017-06-05 13:21:58,069 Epoch[1] Batch [670]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.260642,	
2017-06-05 13:22:02,738 Epoch[1] Batch [680]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.260853,	
2017-06-05 13:22:07,534 Epoch[1] Batch [690]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.260896,	
2017-06-05 13:22:11,847 Epoch[1] Batch [700]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.260334,	
2017-06-05 13:22:16,575 Epoch[1] Batch [710]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.259565,	
2017-06-05 13:22:21,277 Epoch[1] Batch [720]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.258534,	
2017-06-05 13:22:25,682 Epoch[1] Batch [730]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.258232,	
2017-06-05 13:22:30,062 Epoch[1] Batch [740]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.258001,	
2017-06-05 13:22:34,722 Epoch[1] Batch [750]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.256977,	
2017-06-05 13:22:39,429 Epoch[1] Batch [760]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.256201,	
2017-06-05 13:22:44,142 Epoch[1] Batch [770]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.255364,	
2017-06-05 13:22:48,994 Epoch[1] Batch [780]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.254680,	
2017-06-05 13:22:53,818 Epoch[1] Batch [790]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.254073,	
2017-06-05 13:22:58,379 Epoch[1] Batch [800]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.253581,	
2017-06-05 13:23:02,827 Epoch[1] Batch [810]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.253253,	
2017-06-05 13:23:07,250 Epoch[1] Batch [820]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.253432,	
2017-06-05 13:23:11,740 Epoch[1] Batch [830]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.253965,	
2017-06-05 13:23:16,467 Epoch[1] Batch [840]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.254398,	
2017-06-05 13:23:20,908 Epoch[1] Batch [850]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.253951,	
2017-06-05 13:23:25,455 Epoch[1] Batch [860]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.253263,	
2017-06-05 13:23:30,022 Epoch[1] Batch [870]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.252623,	
2017-06-05 13:23:34,540 Epoch[1] Batch [880]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.252472,	
2017-06-05 13:23:38,894 Epoch[1] Batch [890]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.252573,	
2017-06-05 13:23:43,640 Epoch[1] Batch [900]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.251845,	
2017-06-05 13:23:48,111 Epoch[1] Batch [910]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.252626,	
2017-06-05 13:23:52,646 Epoch[1] Batch [920]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.253027,	
2017-06-05 13:23:57,315 Epoch[1] Batch [930]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.253014,	
2017-06-05 13:24:01,820 Epoch[1] Batch [940]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.252625,	
2017-06-05 13:24:06,356 Epoch[1] Batch [950]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.252712,	
2017-06-05 13:24:10,853 Epoch[1] Batch [960]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.252541,	
2017-06-05 13:24:15,064 Epoch[1] Batch [970]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.252360,	
2017-06-05 13:24:19,578 Epoch[1] Batch [980]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.252729,	
2017-06-05 13:24:24,224 Epoch[1] Batch [990]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.252091,	
2017-06-05 13:24:29,021 Epoch[1] Batch [1000]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.252066,	
2017-06-05 13:24:33,498 Epoch[1] Batch [1010]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.251817,	
2017-06-05 13:24:38,318 Epoch[1] Batch [1020]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.251254,	
2017-06-05 13:24:42,850 Epoch[1] Batch [1030]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.251388,	
2017-06-05 13:24:47,449 Epoch[1] Batch [1040]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.251229,	
2017-06-05 13:24:51,877 Epoch[1] Batch [1050]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.251022,	
2017-06-05 13:24:56,739 Epoch[1] Batch [1060]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.250636,	
2017-06-05 13:25:01,196 Epoch[1] Batch [1070]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.250174,	
2017-06-05 13:25:05,471 Epoch[1] Batch [1080]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.249628,	
2017-06-05 13:25:09,923 Epoch[1] Batch [1090]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.249201,	
2017-06-05 13:25:14,736 Epoch[1] Batch [1100]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.249041,	
2017-06-05 13:25:19,515 Epoch[1] Batch [1110]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.248924,	
2017-06-05 13:25:24,157 Epoch[1] Batch [1120]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.249078,	
2017-06-05 13:25:29,089 Epoch[1] Batch [1130]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.249130,	
2017-06-05 13:25:33,667 Epoch[1] Batch [1140]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.249365,	
2017-06-05 13:25:38,152 Epoch[1] Batch [1150]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.249137,	
2017-06-05 13:25:42,730 Epoch[1] Batch [1160]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.249251,	
2017-06-05 13:25:47,545 Epoch[1] Batch [1170]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.249765,	
2017-06-05 13:25:52,081 Epoch[1] Batch [1180]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.250291,	
2017-06-05 13:25:56,551 Epoch[1] Batch [1190]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.250216,	
2017-06-05 13:26:01,092 Epoch[1] Batch [1200]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.250005,	
2017-06-05 13:26:05,505 Epoch[1] Batch [1210]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.249983,	
2017-06-05 13:26:10,079 Epoch[1] Batch [1220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.249867,	
2017-06-05 13:26:14,521 Epoch[1] Batch [1230]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.249836,	
2017-06-05 13:26:19,049 Epoch[1] Batch [1240]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.249582,	
2017-06-05 13:26:23,563 Epoch[1] Batch [1250]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.249658,	
2017-06-05 13:26:28,370 Epoch[1] Batch [1260]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.249293,	
2017-06-05 13:26:33,198 Epoch[1] Batch [1270]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.248986,	
2017-06-05 13:26:37,749 Epoch[1] Batch [1280]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.248835,	
2017-06-05 13:26:42,327 Epoch[1] Batch [1290]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.249054,	
2017-06-05 13:26:47,049 Epoch[1] Batch [1300]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.249213,	
2017-06-05 13:26:51,604 Epoch[1] Batch [1310]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.248981,	
2017-06-05 13:26:55,935 Epoch[1] Batch [1320]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.248648,	
2017-06-05 13:27:00,341 Epoch[1] Batch [1330]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.248360,	
2017-06-05 13:27:05,219 Epoch[1] Batch [1340]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.248225,	
2017-06-05 13:27:09,873 Epoch[1] Batch [1350]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.247855,	
2017-06-05 13:27:14,582 Epoch[1] Batch [1360]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.247556,	
2017-06-05 13:27:19,348 Epoch[1] Batch [1370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.247525,	
2017-06-05 13:27:23,807 Epoch[1] Batch [1380]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.247577,	
2017-06-05 13:27:28,556 Epoch[1] Batch [1390]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.247188,	
2017-06-05 13:27:33,207 Epoch[1] Batch [1400]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.246866,	
2017-06-05 13:27:37,569 Epoch[1] Batch [1410]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.246745,	
2017-06-05 13:27:41,963 Epoch[1] Batch [1420]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.246622,	
2017-06-05 13:27:46,588 Epoch[1] Batch [1430]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.246188,	
2017-06-05 13:27:50,911 Epoch[1] Batch [1440]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.246023,	
2017-06-05 13:27:55,387 Epoch[1] Batch [1450]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.245909,	
2017-06-05 13:27:59,898 Epoch[1] Batch [1460]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.245923,	
2017-06-05 13:28:04,324 Epoch[1] Batch [1470]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.245990,	
2017-06-05 13:28:09,158 Epoch[1] Batch [1480]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.245831,	
2017-06-05 13:28:12,001 Epoch[1] Train-FCNLogLoss=0.245614
2017-06-05 13:28:12,001 Epoch[1] Time cost=681.255
2017-06-05 13:28:12,979 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn-0002.params"
2017-06-05 13:28:14,649 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn-0002.states"
2017-06-05 13:28:20,262 Epoch[2] Batch [10]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.196298,	
2017-06-05 13:28:25,031 Epoch[2] Batch [20]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.204796,	
2017-06-05 13:28:29,601 Epoch[2] Batch [30]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.205984,	
2017-06-05 13:28:34,159 Epoch[2] Batch [40]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.209705,	
2017-06-05 13:28:38,634 Epoch[2] Batch [50]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.202326,	
2017-06-05 13:28:43,231 Epoch[2] Batch [60]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.198468,	
2017-06-05 13:28:47,658 Epoch[2] Batch [70]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.197167,	
2017-06-05 13:28:52,432 Epoch[2] Batch [80]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.200000,	
2017-06-05 13:28:57,048 Epoch[2] Batch [90]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.200996,	
2017-06-05 13:29:01,898 Epoch[2] Batch [100]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.203184,	
2017-06-05 13:29:06,768 Epoch[2] Batch [110]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.201018,	
2017-06-05 13:29:11,664 Epoch[2] Batch [120]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.200543,	
2017-06-05 13:29:16,232 Epoch[2] Batch [130]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.197380,	
2017-06-05 13:29:21,055 Epoch[2] Batch [140]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.199131,	
2017-06-05 13:29:25,789 Epoch[2] Batch [150]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.198855,	
2017-06-05 13:29:30,165 Epoch[2] Batch [160]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.199086,	
2017-06-05 13:29:34,760 Epoch[2] Batch [170]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.198922,	
2017-06-05 13:29:39,195 Epoch[2] Batch [180]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.199789,	
2017-06-05 13:29:43,490 Epoch[2] Batch [190]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.200227,	
2017-06-05 13:29:47,845 Epoch[2] Batch [200]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.199964,	
2017-06-05 13:29:52,419 Epoch[2] Batch [210]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.201576,	
2017-06-05 13:29:57,133 Epoch[2] Batch [220]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.200614,	
2017-06-05 13:30:01,632 Epoch[2] Batch [230]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.199058,	
2017-06-05 13:30:05,994 Epoch[2] Batch [240]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.203280,	
2017-06-05 13:30:10,606 Epoch[2] Batch [250]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.205915,	
2017-06-05 13:30:15,273 Epoch[2] Batch [260]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.206867,	
2017-06-05 13:30:20,228 Epoch[2] Batch [270]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.209857,	
2017-06-05 13:30:24,754 Epoch[2] Batch [280]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.209836,	
2017-06-05 13:30:29,531 Epoch[2] Batch [290]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.209807,	
2017-06-05 13:30:33,682 Epoch[2] Batch [300]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.209113,	
2017-06-05 13:30:37,822 Epoch[2] Batch [310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.213419,	
2017-06-05 13:30:42,129 Epoch[2] Batch [320]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.215322,	
2017-06-05 13:30:47,037 Epoch[2] Batch [330]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.217133,	
2017-06-05 13:30:51,817 Epoch[2] Batch [340]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.218623,	
2017-06-05 13:30:56,436 Epoch[2] Batch [350]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.217847,	
2017-06-05 13:31:00,876 Epoch[2] Batch [360]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.217608,	
2017-06-05 13:31:05,729 Epoch[2] Batch [370]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.216848,	
2017-06-05 13:31:10,444 Epoch[2] Batch [380]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.216782,	
2017-06-05 13:31:15,243 Epoch[2] Batch [390]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.216243,	
2017-06-05 13:31:19,916 Epoch[2] Batch [400]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.215402,	
2017-06-05 13:31:24,200 Epoch[2] Batch [410]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.215298,	
2017-06-05 13:31:28,658 Epoch[2] Batch [420]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.215036,	
2017-06-05 13:31:33,410 Epoch[2] Batch [430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.214608,	
2017-06-05 13:31:38,051 Epoch[2] Batch [440]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.214705,	
2017-06-05 13:31:42,510 Epoch[2] Batch [450]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.213837,	
2017-06-05 13:31:47,277 Epoch[2] Batch [460]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.213344,	
2017-06-05 13:31:51,808 Epoch[2] Batch [470]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.213435,	
2017-06-05 13:31:56,349 Epoch[2] Batch [480]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.212908,	
2017-06-05 13:32:00,845 Epoch[2] Batch [490]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.212818,	
2017-06-05 13:32:05,267 Epoch[2] Batch [500]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.212664,	
2017-06-05 13:32:09,445 Epoch[2] Batch [510]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.212411,	
2017-06-05 13:32:14,008 Epoch[2] Batch [520]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.212540,	
2017-06-05 13:32:18,283 Epoch[2] Batch [530]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.212704,	
2017-06-05 13:32:22,264 Epoch[2] Batch [540]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.211999,	
2017-06-05 13:32:26,897 Epoch[2] Batch [550]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.211710,	
2017-06-05 13:32:31,330 Epoch[2] Batch [560]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.211115,	
2017-06-05 13:32:35,779 Epoch[2] Batch [570]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.211832,	
2017-06-05 13:32:40,291 Epoch[2] Batch [580]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.212074,	
2017-06-05 13:32:45,078 Epoch[2] Batch [590]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.212436,	
2017-06-05 13:32:49,777 Epoch[2] Batch [600]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.212731,	
2017-06-05 13:32:54,271 Epoch[2] Batch [610]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.213635,	
2017-06-05 13:32:59,129 Epoch[2] Batch [620]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.213410,	
2017-06-05 13:33:03,906 Epoch[2] Batch [630]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.213411,	
2017-06-05 13:33:08,526 Epoch[2] Batch [640]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.212834,	
2017-06-05 13:33:13,045 Epoch[2] Batch [650]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.212390,	
2017-06-05 13:33:17,715 Epoch[2] Batch [660]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.213729,	
2017-06-05 13:33:22,029 Epoch[2] Batch [670]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.213842,	
2017-06-05 13:33:26,851 Epoch[2] Batch [680]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.213319,	
2017-06-05 13:33:31,314 Epoch[2] Batch [690]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.213105,	
2017-06-05 13:33:35,672 Epoch[2] Batch [700]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.212679,	
2017-06-05 13:33:40,286 Epoch[2] Batch [710]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.212128,	
2017-06-05 13:33:45,024 Epoch[2] Batch [720]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.211742,	
2017-06-05 13:33:49,290 Epoch[2] Batch [730]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.211476,	
2017-06-05 13:33:53,713 Epoch[2] Batch [740]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.210850,	
2017-06-05 13:33:58,011 Epoch[2] Batch [750]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.210692,	
2017-06-05 13:34:02,607 Epoch[2] Batch [760]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.210564,	
2017-06-05 13:34:07,335 Epoch[2] Batch [770]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.210188,	
2017-06-05 13:34:11,857 Epoch[2] Batch [780]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.209913,	
2017-06-05 13:34:16,655 Epoch[2] Batch [790]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.210406,	
2017-06-05 13:34:21,253 Epoch[2] Batch [800]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.210500,	
2017-06-05 13:34:25,584 Epoch[2] Batch [810]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.210262,	
2017-06-05 13:34:30,111 Epoch[2] Batch [820]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.209951,	
2017-06-05 13:34:34,743 Epoch[2] Batch [830]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.209712,	
2017-06-05 13:34:39,409 Epoch[2] Batch [840]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.209621,	
2017-06-05 13:34:43,626 Epoch[2] Batch [850]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.209475,	
2017-06-05 13:34:48,419 Epoch[2] Batch [860]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.209259,	
2017-06-05 13:34:52,708 Epoch[2] Batch [870]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.209048,	
2017-06-05 13:34:57,253 Epoch[2] Batch [880]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.208826,	
2017-06-05 13:35:01,106 Epoch[2] Batch [890]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.208869,	
2017-06-05 13:35:05,572 Epoch[2] Batch [900]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.208733,	
2017-06-05 13:35:10,261 Epoch[2] Batch [910]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.208596,	
2017-06-05 13:35:14,891 Epoch[2] Batch [920]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.208409,	
2017-06-05 13:35:19,683 Epoch[2] Batch [930]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.208367,	
2017-06-05 13:35:24,150 Epoch[2] Batch [940]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.208234,	
2017-06-05 13:35:28,709 Epoch[2] Batch [950]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.208558,	
2017-06-05 13:35:33,554 Epoch[2] Batch [960]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.208533,	
2017-06-05 13:35:38,126 Epoch[2] Batch [970]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.208233,	
2017-06-05 13:35:42,905 Epoch[2] Batch [980]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.208671,	
2017-06-05 13:35:47,330 Epoch[2] Batch [990]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.209184,	
2017-06-05 13:35:52,139 Epoch[2] Batch [1000]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.208883,	
2017-06-05 13:35:56,690 Epoch[2] Batch [1010]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.209180,	
2017-06-05 13:36:01,279 Epoch[2] Batch [1020]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.209003,	
2017-06-05 13:36:05,613 Epoch[2] Batch [1030]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.208861,	
2017-06-05 13:36:10,080 Epoch[2] Batch [1040]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.208730,	
2017-06-05 13:36:14,731 Epoch[2] Batch [1050]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.208397,	
2017-06-05 13:36:19,355 Epoch[2] Batch [1060]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.208101,	
2017-06-05 13:36:23,948 Epoch[2] Batch [1070]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.207910,	
2017-06-05 13:36:28,581 Epoch[2] Batch [1080]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.207820,	
2017-06-05 13:36:33,206 Epoch[2] Batch [1090]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.207480,	
2017-06-05 13:36:37,945 Epoch[2] Batch [1100]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.207206,	
2017-06-05 13:36:42,464 Epoch[2] Batch [1110]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.206969,	
2017-06-05 13:36:47,107 Epoch[2] Batch [1120]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.206698,	
2017-06-05 13:36:51,644 Epoch[2] Batch [1130]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.206447,	
2017-06-05 13:36:56,093 Epoch[2] Batch [1140]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.206386,	
2017-06-05 13:37:00,855 Epoch[2] Batch [1150]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.206225,	
2017-06-05 13:37:05,517 Epoch[2] Batch [1160]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.205877,	
2017-06-05 13:37:09,497 Epoch[2] Batch [1170]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.205713,	
2017-06-05 13:37:13,910 Epoch[2] Batch [1180]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.205707,	
2017-06-05 13:37:18,772 Epoch[2] Batch [1190]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.205745,	
2017-06-05 13:37:23,533 Epoch[2] Batch [1200]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.205586,	
2017-06-05 13:37:27,929 Epoch[2] Batch [1210]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.205574,	
2017-06-05 13:37:32,528 Epoch[2] Batch [1220]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.205539,	
2017-06-05 13:37:37,089 Epoch[2] Batch [1230]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.205553,	
2017-06-05 13:37:41,727 Epoch[2] Batch [1240]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.205416,	
2017-06-05 13:37:46,267 Epoch[2] Batch [1250]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.205118,	
2017-06-05 13:37:50,725 Epoch[2] Batch [1260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.204862,	
2017-06-05 13:37:55,569 Epoch[2] Batch [1270]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.204545,	
2017-06-05 13:38:00,163 Epoch[2] Batch [1280]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.204319,	
2017-06-05 13:38:04,823 Epoch[2] Batch [1290]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.204634,	
2017-06-05 13:38:09,280 Epoch[2] Batch [1300]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.204691,	
2017-06-05 13:38:14,089 Epoch[2] Batch [1310]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.205092,	
2017-06-05 13:38:18,735 Epoch[2] Batch [1320]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.205228,	
2017-06-05 13:38:23,289 Epoch[2] Batch [1330]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.205368,	
2017-06-05 13:38:27,627 Epoch[2] Batch [1340]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.205125,	
2017-06-05 13:38:31,840 Epoch[2] Batch [1350]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.205023,	
2017-06-05 13:38:36,333 Epoch[2] Batch [1360]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.204998,	
2017-06-05 13:38:41,075 Epoch[2] Batch [1370]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.205001,	
2017-06-05 13:38:45,567 Epoch[2] Batch [1380]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.205049,	
2017-06-05 13:38:50,012 Epoch[2] Batch [1390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.204946,	
2017-06-05 13:38:54,241 Epoch[2] Batch [1400]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.204448,	
2017-06-05 13:38:58,886 Epoch[2] Batch [1410]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.204436,	
2017-06-05 13:39:03,716 Epoch[2] Batch [1420]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.204472,	
2017-06-05 13:39:08,394 Epoch[2] Batch [1430]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.204302,	
2017-06-05 13:39:12,989 Epoch[2] Batch [1440]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.204299,	
2017-06-05 13:39:17,522 Epoch[2] Batch [1450]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.204100,	
2017-06-05 13:39:22,081 Epoch[2] Batch [1460]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.203890,	
2017-06-05 13:39:26,804 Epoch[2] Batch [1470]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.203507,	
2017-06-05 13:39:31,474 Epoch[2] Batch [1480]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.203283,	
2017-06-05 13:39:34,344 Epoch[2] Train-FCNLogLoss=0.203094
2017-06-05 13:39:34,344 Epoch[2] Time cost=679.694
2017-06-05 13:39:35,270 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn-0003.params"
2017-06-05 13:39:36,896 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn-0003.states"
2017-06-05 13:39:42,459 Epoch[3] Batch [10]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.163020,	
2017-06-05 13:39:47,393 Epoch[3] Batch [20]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.175294,	
2017-06-05 13:39:51,611 Epoch[3] Batch [30]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.171410,	
2017-06-05 13:39:56,298 Epoch[3] Batch [40]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.181490,	
2017-06-05 13:40:00,695 Epoch[3] Batch [50]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.191968,	
2017-06-05 13:40:04,942 Epoch[3] Batch [60]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.193111,	
2017-06-05 13:40:08,953 Epoch[3] Batch [70]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.191888,	
2017-06-05 13:40:13,532 Epoch[3] Batch [80]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.190901,	
2017-06-05 13:40:18,281 Epoch[3] Batch [90]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.190202,	
2017-06-05 13:40:22,700 Epoch[3] Batch [100]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.189118,	
2017-06-05 13:40:27,101 Epoch[3] Batch [110]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.190820,	
2017-06-05 13:40:31,801 Epoch[3] Batch [120]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.189882,	
2017-06-05 13:40:36,214 Epoch[3] Batch [130]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.189677,	
2017-06-05 13:40:41,028 Epoch[3] Batch [140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.190108,	
2017-06-05 13:40:45,796 Epoch[3] Batch [150]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.188888,	
2017-06-05 13:40:50,231 Epoch[3] Batch [160]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.187413,	
2017-06-05 13:40:54,700 Epoch[3] Batch [170]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.187341,	
2017-06-05 13:40:59,129 Epoch[3] Batch [180]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.189183,	
2017-06-05 13:41:03,698 Epoch[3] Batch [190]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.188831,	
2017-06-05 13:41:08,262 Epoch[3] Batch [200]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.188345,	
2017-06-05 13:41:13,069 Epoch[3] Batch [210]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.188067,	
2017-06-05 13:41:17,711 Epoch[3] Batch [220]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.187905,	
2017-06-05 13:41:22,364 Epoch[3] Batch [230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.187604,	
2017-06-05 13:41:26,377 Epoch[3] Batch [240]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.187155,	
2017-06-05 13:41:30,543 Epoch[3] Batch [250]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.186268,	
2017-06-05 13:41:35,003 Epoch[3] Batch [260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.185718,	
2017-06-05 13:41:39,310 Epoch[3] Batch [270]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.184306,	
2017-06-05 13:41:43,697 Epoch[3] Batch [280]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.183166,	
2017-06-05 13:41:48,279 Epoch[3] Batch [290]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.182479,	
2017-06-05 13:41:52,610 Epoch[3] Batch [300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.182078,	
2017-06-05 13:41:57,169 Epoch[3] Batch [310]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.181894,	
2017-06-05 13:42:01,528 Epoch[3] Batch [320]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.181643,	
2017-06-05 13:42:06,325 Epoch[3] Batch [330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.183026,	
2017-06-05 13:42:11,014 Epoch[3] Batch [340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.183941,	
2017-06-05 13:42:15,660 Epoch[3] Batch [350]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.185116,	
2017-06-05 13:42:20,104 Epoch[3] Batch [360]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.185741,	
2017-06-05 13:42:24,755 Epoch[3] Batch [370]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.185691,	
2017-06-05 13:42:29,210 Epoch[3] Batch [380]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.185998,	
2017-06-05 13:42:33,647 Epoch[3] Batch [390]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.186265,	
2017-06-05 13:42:38,279 Epoch[3] Batch [400]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.186458,	
2017-06-05 13:42:42,899 Epoch[3] Batch [410]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.186252,	
2017-06-05 13:42:47,234 Epoch[3] Batch [420]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.186098,	
2017-06-05 13:42:51,939 Epoch[3] Batch [430]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.185786,	
2017-06-05 13:42:56,461 Epoch[3] Batch [440]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.185421,	
2017-06-05 13:43:01,212 Epoch[3] Batch [450]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.185455,	
2017-06-05 13:43:05,813 Epoch[3] Batch [460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.184973,	
2017-06-05 13:43:09,864 Epoch[3] Batch [470]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.185447,	
2017-06-05 13:43:14,186 Epoch[3] Batch [480]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.185303,	
2017-06-05 13:43:18,758 Epoch[3] Batch [490]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.185014,	
2017-06-05 13:43:23,201 Epoch[3] Batch [500]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.184580,	
2017-06-05 13:43:27,707 Epoch[3] Batch [510]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.184346,	
2017-06-05 13:43:32,010 Epoch[3] Batch [520]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.183733,	
2017-06-05 13:43:36,449 Epoch[3] Batch [530]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.183234,	
2017-06-05 13:43:41,054 Epoch[3] Batch [540]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.182735,	
2017-06-05 13:43:45,692 Epoch[3] Batch [550]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.183065,	
2017-06-05 13:43:50,152 Epoch[3] Batch [560]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.182601,	
2017-06-05 13:43:54,360 Epoch[3] Batch [570]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.182594,	
2017-06-05 13:43:58,885 Epoch[3] Batch [580]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.182386,	
2017-06-05 13:44:03,160 Epoch[3] Batch [590]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.182681,	
2017-06-05 13:44:07,261 Epoch[3] Batch [600]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.182338,	
2017-06-05 13:44:11,693 Epoch[3] Batch [610]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.182158,	
2017-06-05 13:44:16,131 Epoch[3] Batch [620]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.181910,	
2017-06-05 13:44:20,372 Epoch[3] Batch [630]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.181761,	
2017-06-05 13:44:25,219 Epoch[3] Batch [640]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.181471,	
2017-06-05 13:44:29,934 Epoch[3] Batch [650]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.180953,	
2017-06-05 13:44:34,471 Epoch[3] Batch [660]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.180766,	
2017-06-05 13:44:39,006 Epoch[3] Batch [670]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.180300,	
2017-06-05 13:44:43,563 Epoch[3] Batch [680]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.180417,	
2017-06-05 13:44:48,092 Epoch[3] Batch [690]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.180197,	
2017-06-05 13:44:52,583 Epoch[3] Batch [700]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.180289,	
2017-06-05 13:44:57,128 Epoch[3] Batch [710]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.180209,	
2017-06-05 13:45:01,663 Epoch[3] Batch [720]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.180046,	
2017-06-05 13:45:06,434 Epoch[3] Batch [730]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.180237,	
2017-06-05 13:45:11,134 Epoch[3] Batch [740]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.179924,	
2017-06-05 13:45:15,348 Epoch[3] Batch [750]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.179943,	
2017-06-05 13:45:19,678 Epoch[3] Batch [760]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.179828,	
2017-06-05 13:45:24,098 Epoch[3] Batch [770]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.180171,	
2017-06-05 13:45:28,698 Epoch[3] Batch [780]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.180426,	
2017-06-05 13:45:33,372 Epoch[3] Batch [790]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.180311,	
2017-06-05 13:45:37,563 Epoch[3] Batch [800]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.180717,	
2017-06-05 13:45:42,528 Epoch[3] Batch [810]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.180515,	
2017-06-05 13:45:47,079 Epoch[3] Batch [820]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.180584,	
2017-06-05 13:45:51,800 Epoch[3] Batch [830]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.180386,	
2017-06-05 13:45:56,347 Epoch[3] Batch [840]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.180259,	
2017-06-05 13:46:00,777 Epoch[3] Batch [850]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.179849,	
2017-06-05 13:46:05,168 Epoch[3] Batch [860]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.179430,	
2017-06-05 13:46:09,753 Epoch[3] Batch [870]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.179658,	
2017-06-05 13:46:14,431 Epoch[3] Batch [880]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.179652,	
2017-06-05 13:46:18,931 Epoch[3] Batch [890]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.179421,	
2017-06-05 13:46:23,448 Epoch[3] Batch [900]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.179662,	
2017-06-05 13:46:28,070 Epoch[3] Batch [910]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.179663,	
2017-06-05 13:46:32,704 Epoch[3] Batch [920]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.179625,	
2017-06-05 13:46:37,289 Epoch[3] Batch [930]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.179392,	
2017-06-05 13:46:41,709 Epoch[3] Batch [940]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.179740,	
2017-06-05 13:46:46,399 Epoch[3] Batch [950]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.179957,	
2017-06-05 13:46:51,044 Epoch[3] Batch [960]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.179902,	
2017-06-05 13:46:55,724 Epoch[3] Batch [970]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.180321,	
2017-06-05 13:47:00,392 Epoch[3] Batch [980]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.180366,	
2017-06-05 13:47:04,849 Epoch[3] Batch [990]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.180354,	
2017-06-05 13:47:09,591 Epoch[3] Batch [1000]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.180138,	
2017-06-05 13:47:14,202 Epoch[3] Batch [1010]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.180007,	
2017-06-05 13:47:18,506 Epoch[3] Batch [1020]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.179817,	
2017-06-05 13:47:23,207 Epoch[3] Batch [1030]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.179660,	
2017-06-05 13:47:28,150 Epoch[3] Batch [1040]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.179474,	
2017-06-05 13:47:32,689 Epoch[3] Batch [1050]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.179430,	
2017-06-05 13:47:37,331 Epoch[3] Batch [1060]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.179368,	
2017-06-05 13:47:42,124 Epoch[3] Batch [1070]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.179311,	
2017-06-05 13:47:46,416 Epoch[3] Batch [1080]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.179048,	
2017-06-05 13:47:50,676 Epoch[3] Batch [1090]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.178987,	
2017-06-05 13:47:54,950 Epoch[3] Batch [1100]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.178956,	
2017-06-05 13:47:59,450 Epoch[3] Batch [1110]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.179002,	
2017-06-05 13:48:04,116 Epoch[3] Batch [1120]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.178811,	
2017-06-05 13:48:08,691 Epoch[3] Batch [1130]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.178673,	
2017-06-05 13:48:13,275 Epoch[3] Batch [1140]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.178477,	
2017-06-05 13:48:17,948 Epoch[3] Batch [1150]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.178455,	
2017-06-05 13:48:22,202 Epoch[3] Batch [1160]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.178289,	
2017-06-05 13:48:26,641 Epoch[3] Batch [1170]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.178336,	
2017-06-05 13:48:31,408 Epoch[3] Batch [1180]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.178074,	

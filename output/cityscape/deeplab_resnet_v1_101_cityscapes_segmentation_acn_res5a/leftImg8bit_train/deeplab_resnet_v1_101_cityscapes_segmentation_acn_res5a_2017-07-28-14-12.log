2017-07-28 14:12:39,365 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn_res5a'}

2017-07-28 14:14:17,123 Epoch[0] Batch [10]	Speed: 4.02 samples/sec	Train-FCNLogLoss=2.871370,	
2017-07-28 14:14:26,885 Epoch[0] Batch [20]	Speed: 4.10 samples/sec	Train-FCNLogLoss=2.731445,	
2017-07-28 14:14:36,416 Epoch[0] Batch [30]	Speed: 4.20 samples/sec	Train-FCNLogLoss=2.516233,	
2017-07-28 14:14:46,660 Epoch[0] Batch [40]	Speed: 3.91 samples/sec	Train-FCNLogLoss=2.304839,	
2017-07-28 14:14:57,863 Epoch[0] Batch [50]	Speed: 3.57 samples/sec	Train-FCNLogLoss=2.104039,	
2017-07-28 14:15:08,643 Epoch[0] Batch [60]	Speed: 3.71 samples/sec	Train-FCNLogLoss=1.945366,	
2017-07-28 14:15:19,639 Epoch[0] Batch [70]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.798083,	
2017-07-28 14:15:30,622 Epoch[0] Batch [80]	Speed: 3.64 samples/sec	Train-FCNLogLoss=1.697029,	
2017-07-28 14:15:41,590 Epoch[0] Batch [90]	Speed: 3.65 samples/sec	Train-FCNLogLoss=1.609405,	
2017-07-28 14:15:52,641 Epoch[0] Batch [100]	Speed: 3.62 samples/sec	Train-FCNLogLoss=1.527463,	
2017-07-28 14:16:03,448 Epoch[0] Batch [110]	Speed: 3.70 samples/sec	Train-FCNLogLoss=1.441434,	
2017-07-28 14:16:13,554 Epoch[0] Batch [120]	Speed: 3.96 samples/sec	Train-FCNLogLoss=1.392026,	
2017-07-28 14:16:23,002 Epoch[0] Batch [130]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.345099,	
2017-07-28 14:16:32,653 Epoch[0] Batch [140]	Speed: 4.14 samples/sec	Train-FCNLogLoss=1.301856,	
2017-07-28 14:16:42,121 Epoch[0] Batch [150]	Speed: 4.23 samples/sec	Train-FCNLogLoss=1.253169,	
2017-07-28 14:16:53,065 Epoch[0] Batch [160]	Speed: 3.66 samples/sec	Train-FCNLogLoss=1.214559,	
2017-07-28 14:17:04,810 Epoch[0] Batch [170]	Speed: 3.41 samples/sec	Train-FCNLogLoss=1.175865,	
2017-07-28 14:17:17,021 Epoch[0] Batch [180]	Speed: 3.28 samples/sec	Train-FCNLogLoss=1.141149,	
2017-07-28 14:17:29,088 Epoch[0] Batch [190]	Speed: 3.31 samples/sec	Train-FCNLogLoss=1.106483,	
2017-07-28 14:17:41,082 Epoch[0] Batch [200]	Speed: 3.34 samples/sec	Train-FCNLogLoss=1.075545,	
2017-07-28 14:17:53,254 Epoch[0] Batch [210]	Speed: 3.29 samples/sec	Train-FCNLogLoss=1.049172,	
2017-07-28 14:18:04,834 Epoch[0] Batch [220]	Speed: 3.45 samples/sec	Train-FCNLogLoss=1.022765,	
2017-07-28 14:18:16,416 Epoch[0] Batch [230]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.997739,	
2017-07-28 14:18:28,335 Epoch[0] Batch [240]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.976849,	
2017-07-28 14:18:37,985 Epoch[0] Batch [250]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.957983,	
2017-07-28 14:18:47,835 Epoch[0] Batch [260]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.938570,	
2017-07-28 14:18:57,681 Epoch[0] Batch [270]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.921656,	
2017-07-28 14:19:07,255 Epoch[0] Batch [280]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.902383,	
2017-07-28 14:19:16,889 Epoch[0] Batch [290]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.888150,	
2017-07-28 14:19:26,394 Epoch[0] Batch [300]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.871919,	
2017-07-28 14:19:36,033 Epoch[0] Batch [310]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.858066,	
2017-07-28 14:19:45,395 Epoch[0] Batch [320]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.846318,	
2017-07-28 14:19:54,855 Epoch[0] Batch [330]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.835300,	
2017-07-28 14:20:04,761 Epoch[0] Batch [340]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.823004,	
2017-07-28 14:20:14,371 Epoch[0] Batch [350]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.811256,	
2017-07-28 14:20:23,977 Epoch[0] Batch [360]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.802465,	
2017-07-28 14:20:33,241 Epoch[0] Batch [370]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.791957,	
2017-07-28 14:20:43,321 Epoch[0] Batch [380]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.782282,	
2017-07-28 14:20:53,181 Epoch[0] Batch [390]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.771540,	
2017-07-28 14:21:03,045 Epoch[0] Batch [400]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.762630,	
2017-07-28 14:21:12,981 Epoch[0] Batch [410]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.753329,	
2017-07-28 14:21:22,644 Epoch[0] Batch [420]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.744665,	
2017-07-28 14:21:32,423 Epoch[0] Batch [430]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.737263,	
2017-07-28 14:21:42,090 Epoch[0] Batch [440]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.729585,	
2017-07-28 14:21:51,728 Epoch[0] Batch [450]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.720799,	
2017-07-28 14:22:01,585 Epoch[0] Batch [460]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.713461,	
2017-07-28 14:22:11,210 Epoch[0] Batch [470]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.706414,	
2017-07-28 14:22:21,091 Epoch[0] Batch [480]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.698675,	
2017-07-28 14:22:30,793 Epoch[0] Batch [490]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.691433,	
2017-07-28 14:22:40,409 Epoch[0] Batch [500]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.685681,	
2017-07-28 14:22:50,267 Epoch[0] Batch [510]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.680273,	
2017-07-28 14:22:59,972 Epoch[0] Batch [520]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.673842,	
2017-07-28 14:23:09,345 Epoch[0] Batch [530]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.668870,	
2017-07-28 14:23:18,758 Epoch[0] Batch [540]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.664958,	
2017-07-28 14:23:28,372 Epoch[0] Batch [550]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.660054,	
2017-07-28 14:23:37,849 Epoch[0] Batch [560]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.655582,	
2017-07-28 14:23:47,299 Epoch[0] Batch [570]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.650836,	
2017-07-28 14:23:56,880 Epoch[0] Batch [580]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.646480,	
2017-07-28 14:24:06,304 Epoch[0] Batch [590]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.641332,	
2017-07-28 14:24:15,844 Epoch[0] Batch [600]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.635643,	
2017-07-28 14:24:25,249 Epoch[0] Batch [610]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.631005,	
2017-07-28 14:24:34,776 Epoch[0] Batch [620]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.626774,	
2017-07-28 14:24:44,247 Epoch[0] Batch [630]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.621597,	
2017-07-28 14:24:53,797 Epoch[0] Batch [640]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.617418,	
2017-07-28 14:25:03,516 Epoch[0] Batch [650]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.613776,	
2017-07-28 14:25:13,297 Epoch[0] Batch [660]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.609477,	
2017-07-28 14:25:23,355 Epoch[0] Batch [670]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.606575,	
2017-07-28 14:25:32,945 Epoch[0] Batch [680]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.603074,	
2017-07-28 14:25:42,585 Epoch[0] Batch [690]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.599530,	
2017-07-28 14:25:52,003 Epoch[0] Batch [700]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.597027,	
2017-07-28 14:26:01,630 Epoch[0] Batch [710]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.593829,	
2017-07-28 14:26:10,878 Epoch[0] Batch [720]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.591235,	
2017-07-28 14:26:20,125 Epoch[0] Batch [730]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.588735,	
2017-07-28 14:26:29,567 Epoch[0] Batch [740]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.585981,	
2017-07-28 14:26:38,992 Epoch[0] Batch [750]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.583305,	
2017-07-28 14:26:48,446 Epoch[0] Batch [760]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.579931,	
2017-07-28 14:26:58,289 Epoch[0] Batch [770]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.576434,	
2017-07-28 14:27:07,647 Epoch[0] Batch [780]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.573679,	
2017-07-28 14:27:17,201 Epoch[0] Batch [790]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.570997,	
2017-07-28 14:27:26,742 Epoch[0] Batch [800]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.567949,	
2017-07-28 14:27:36,153 Epoch[0] Batch [810]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.564688,	
2017-07-28 14:27:45,598 Epoch[0] Batch [820]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.561632,	
2017-07-28 14:27:54,866 Epoch[0] Batch [830]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.559306,	
2017-07-28 14:28:04,401 Epoch[0] Batch [840]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.556681,	
2017-07-28 14:28:14,115 Epoch[0] Batch [850]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.553629,	
2017-07-28 14:28:24,046 Epoch[0] Batch [860]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.551355,	
2017-07-28 14:28:33,638 Epoch[0] Batch [870]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.549078,	
2017-07-28 14:28:43,490 Epoch[0] Batch [880]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.547032,	
2017-07-28 14:28:52,757 Epoch[0] Batch [890]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.544914,	
2017-07-28 14:29:02,427 Epoch[0] Batch [900]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.543202,	
2017-07-28 14:29:12,203 Epoch[0] Batch [910]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.540897,	
2017-07-28 14:29:21,652 Epoch[0] Batch [920]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.538113,	
2017-07-28 14:29:31,473 Epoch[0] Batch [930]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.535601,	
2017-07-28 14:29:41,467 Epoch[0] Batch [940]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.533601,	
2017-07-28 14:29:51,359 Epoch[0] Batch [950]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.531059,	
2017-07-28 14:30:01,001 Epoch[0] Batch [960]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.528894,	
2017-07-28 14:30:10,518 Epoch[0] Batch [970]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.526620,	
2017-07-28 14:30:20,598 Epoch[0] Batch [980]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.524561,	
2017-07-28 14:30:30,067 Epoch[0] Batch [990]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.522928,	
2017-07-28 14:30:39,256 Epoch[0] Batch [1000]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.521131,	
2017-07-28 14:30:48,811 Epoch[0] Batch [1010]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.519730,	
2017-07-28 14:30:58,101 Epoch[0] Batch [1020]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.518947,	
2017-07-28 14:31:07,583 Epoch[0] Batch [1030]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.522303,	
2017-07-28 14:31:17,361 Epoch[0] Batch [1040]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.524729,	
2017-07-28 14:31:27,349 Epoch[0] Batch [1050]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.524759,	
2017-07-28 14:31:36,970 Epoch[0] Batch [1060]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.524774,	
2017-07-28 14:31:47,064 Epoch[0] Batch [1070]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.524061,	
2017-07-28 14:31:56,628 Epoch[0] Batch [1080]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.523435,	
2017-07-28 14:32:06,459 Epoch[0] Batch [1090]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.523144,	
2017-07-28 14:32:16,213 Epoch[0] Batch [1100]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.522117,	
2017-07-28 14:32:25,865 Epoch[0] Batch [1110]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.522094,	
2017-07-28 14:32:35,286 Epoch[0] Batch [1120]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.520723,	
2017-07-28 14:32:44,879 Epoch[0] Batch [1130]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.519287,	
2017-07-28 14:32:54,596 Epoch[0] Batch [1140]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.518503,	
2017-07-28 14:33:04,342 Epoch[0] Batch [1150]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.517973,	
2017-07-28 14:33:13,744 Epoch[0] Batch [1160]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.517440,	
2017-07-28 14:33:23,830 Epoch[0] Batch [1170]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.515914,	
2017-07-28 14:33:33,589 Epoch[0] Batch [1180]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.514776,	
2017-07-28 14:33:43,147 Epoch[0] Batch [1190]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.513201,	
2017-07-28 14:33:52,648 Epoch[0] Batch [1200]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.511696,	
2017-07-28 14:34:02,223 Epoch[0] Batch [1210]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.510590,	
2017-07-28 14:34:11,826 Epoch[0] Batch [1220]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.510025,	
2017-07-28 14:34:21,778 Epoch[0] Batch [1230]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.508752,	
2017-07-28 14:34:31,732 Epoch[0] Batch [1240]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.507359,	
2017-07-28 14:34:41,399 Epoch[0] Batch [1250]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.505723,	
2017-07-28 14:34:51,019 Epoch[0] Batch [1260]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.504420,	
2017-07-28 14:35:00,544 Epoch[0] Batch [1270]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.503153,	
2017-07-28 14:35:10,245 Epoch[0] Batch [1280]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.501945,	
2017-07-28 14:35:20,137 Epoch[0] Batch [1290]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.500592,	
2017-07-28 14:35:29,757 Epoch[0] Batch [1300]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.499817,	
2017-07-28 14:35:39,396 Epoch[0] Batch [1310]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.498425,	
2017-07-28 14:35:48,946 Epoch[0] Batch [1320]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.496980,	
2017-07-28 14:35:58,522 Epoch[0] Batch [1330]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.495535,	
2017-07-28 14:36:07,845 Epoch[0] Batch [1340]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.494252,	
2017-07-28 14:36:17,838 Epoch[0] Batch [1350]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.493017,	
2017-07-28 14:36:28,096 Epoch[0] Batch [1360]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.491622,	
2017-07-28 14:36:38,032 Epoch[0] Batch [1370]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.490230,	
2017-07-28 14:36:48,253 Epoch[0] Batch [1380]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.488891,	
2017-07-28 14:36:57,951 Epoch[0] Batch [1390]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.487558,	
2017-07-28 14:37:08,328 Epoch[0] Batch [1400]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.486184,	
2017-07-28 14:37:18,026 Epoch[0] Batch [1410]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.485103,	
2017-07-28 14:37:27,771 Epoch[0] Batch [1420]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.484184,	
2017-07-28 14:37:37,880 Epoch[0] Batch [1430]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.482939,	
2017-07-28 14:37:48,143 Epoch[0] Batch [1440]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.481838,	
2017-07-28 14:37:58,051 Epoch[0] Batch [1450]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.480750,	
2017-07-28 14:38:07,812 Epoch[0] Batch [1460]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.479372,	
2017-07-28 14:38:17,741 Epoch[0] Batch [1470]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.478624,	
2017-07-28 14:38:27,592 Epoch[0] Batch [1480]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.477505,	
2017-07-28 14:38:33,530 Epoch[0] Train-FCNLogLoss=0.477024
2017-07-28 14:38:33,530 Epoch[0] Time cost=1487.750
2017-07-28 14:38:35,020 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0001.params"
2017-07-28 14:38:39,704 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0001.states"
2017-07-28 14:38:48,670 Epoch[1] Batch [10]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.438981,	
2017-07-28 14:38:56,530 Epoch[1] Batch [20]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.404610,	
2017-07-28 14:39:04,402 Epoch[1] Batch [30]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.536542,	
2017-07-28 14:39:11,930 Epoch[1] Batch [40]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.569719,	
2017-07-28 14:39:19,712 Epoch[1] Batch [50]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.547027,	
2017-07-28 14:39:27,612 Epoch[1] Batch [60]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.527805,	
2017-07-28 14:39:35,570 Epoch[1] Batch [70]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.514267,	
2017-07-28 14:39:43,685 Epoch[1] Batch [80]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.489149,	
2017-07-28 14:39:51,310 Epoch[1] Batch [90]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.470306,	
2017-07-28 14:39:59,193 Epoch[1] Batch [100]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.460547,	
2017-07-28 14:40:06,919 Epoch[1] Batch [110]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.443625,	
2017-07-28 14:40:14,649 Epoch[1] Batch [120]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.433281,	
2017-07-28 14:40:21,695 Epoch[1] Batch [130]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.425478,	
2017-07-28 14:40:28,525 Epoch[1] Batch [140]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.416363,	
2017-07-28 14:40:35,760 Epoch[1] Batch [150]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.408415,	
2017-07-28 14:40:43,211 Epoch[1] Batch [160]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.406050,	
2017-07-28 14:40:50,191 Epoch[1] Batch [170]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.403319,	
2017-07-28 14:40:57,288 Epoch[1] Batch [180]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.397627,	
2017-07-28 14:41:04,504 Epoch[1] Batch [190]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.394308,	
2017-07-28 14:41:11,308 Epoch[1] Batch [200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.389941,	
2017-07-28 14:41:18,218 Epoch[1] Batch [210]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.384831,	
2017-07-28 14:41:25,346 Epoch[1] Batch [220]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.378050,	
2017-07-28 14:41:32,478 Epoch[1] Batch [230]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.373271,	
2017-07-28 14:41:39,552 Epoch[1] Batch [240]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.372059,	
2017-07-28 14:41:46,610 Epoch[1] Batch [250]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.369091,	
2017-07-28 14:41:54,039 Epoch[1] Batch [260]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.363906,	
2017-07-28 14:42:01,299 Epoch[1] Batch [270]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.359458,	
2017-07-28 14:42:08,670 Epoch[1] Batch [280]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.355904,	
2017-07-28 14:42:16,068 Epoch[1] Batch [290]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.353882,	
2017-07-28 14:42:23,525 Epoch[1] Batch [300]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.353252,	
2017-07-28 14:42:30,824 Epoch[1] Batch [310]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.353309,	
2017-07-28 14:42:38,027 Epoch[1] Batch [320]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.351455,	
2017-07-28 14:42:44,854 Epoch[1] Batch [330]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.349143,	
2017-07-28 14:42:51,793 Epoch[1] Batch [340]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.350190,	
2017-07-28 14:42:58,868 Epoch[1] Batch [350]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.348135,	
2017-07-28 14:43:06,044 Epoch[1] Batch [360]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.346307,	
2017-07-28 14:43:13,228 Epoch[1] Batch [370]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.343637,	
2017-07-28 14:43:20,482 Epoch[1] Batch [380]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.342697,	
2017-07-28 14:43:27,530 Epoch[1] Batch [390]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.341268,	
2017-07-28 14:43:34,250 Epoch[1] Batch [400]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.339611,	
2017-07-28 14:43:41,130 Epoch[1] Batch [410]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.336256,	
2017-07-28 14:43:47,951 Epoch[1] Batch [420]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.335021,	
2017-07-28 14:43:55,093 Epoch[1] Batch [430]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.332646,	
2017-07-28 14:44:02,690 Epoch[1] Batch [440]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.331257,	
2017-07-28 14:44:10,918 Epoch[1] Batch [450]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.329223,	
2017-07-28 14:44:18,501 Epoch[1] Batch [460]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.328275,	
2017-07-28 14:44:26,383 Epoch[1] Batch [470]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.327837,	
2017-07-28 14:44:34,332 Epoch[1] Batch [480]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.327911,	
2017-07-28 14:44:42,015 Epoch[1] Batch [490]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.327196,	
2017-07-28 14:44:49,969 Epoch[1] Batch [500]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.325154,	
2017-07-28 14:44:57,907 Epoch[1] Batch [510]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.324632,	
2017-07-28 14:45:05,841 Epoch[1] Batch [520]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.323574,	
2017-07-28 14:45:13,524 Epoch[1] Batch [530]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.322419,	
2017-07-28 14:45:21,437 Epoch[1] Batch [540]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.322171,	
2017-07-28 14:45:29,918 Epoch[1] Batch [550]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.321080,	
2017-07-28 14:45:37,480 Epoch[1] Batch [560]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.321398,	
2017-07-28 14:45:45,382 Epoch[1] Batch [570]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.320117,	
2017-07-28 14:45:53,561 Epoch[1] Batch [580]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.319169,	
2017-07-28 14:46:01,593 Epoch[1] Batch [590]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.318333,	
2017-07-28 14:46:09,433 Epoch[1] Batch [600]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.317754,	
2017-07-28 14:46:17,847 Epoch[1] Batch [610]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.316965,	
2017-07-28 14:46:25,991 Epoch[1] Batch [620]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.316117,	
2017-07-28 14:46:33,794 Epoch[1] Batch [630]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.315536,	
2017-07-28 14:46:41,886 Epoch[1] Batch [640]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.314407,	
2017-07-28 14:46:50,191 Epoch[1] Batch [650]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.314620,	
2017-07-28 14:46:58,591 Epoch[1] Batch [660]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.314141,	
2017-07-28 14:47:06,730 Epoch[1] Batch [670]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.313389,	
2017-07-28 14:47:14,506 Epoch[1] Batch [680]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.312585,	
2017-07-28 14:47:22,243 Epoch[1] Batch [690]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.311990,	
2017-07-28 14:47:30,208 Epoch[1] Batch [700]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.311023,	
2017-07-28 14:47:38,240 Epoch[1] Batch [710]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.310321,	
2017-07-28 14:47:46,370 Epoch[1] Batch [720]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.309622,	
2017-07-28 14:47:54,410 Epoch[1] Batch [730]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.309076,	
2017-07-28 14:48:02,313 Epoch[1] Batch [740]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.308894,	
2017-07-28 14:48:10,507 Epoch[1] Batch [750]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.308026,	
2017-07-28 14:48:18,079 Epoch[1] Batch [760]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.306980,	
2017-07-28 14:48:25,985 Epoch[1] Batch [770]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.306002,	
2017-07-28 14:48:33,884 Epoch[1] Batch [780]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.305085,	
2017-07-28 14:48:42,293 Epoch[1] Batch [790]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.304186,	
2017-07-28 14:48:50,514 Epoch[1] Batch [800]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.303368,	
2017-07-28 14:48:58,396 Epoch[1] Batch [810]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.302994,	
2017-07-28 14:49:06,700 Epoch[1] Batch [820]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.302474,	
2017-07-28 14:49:14,947 Epoch[1] Batch [830]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.301235,	
2017-07-28 14:49:23,106 Epoch[1] Batch [840]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.300609,	
2017-07-28 14:49:31,482 Epoch[1] Batch [850]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.300506,	
2017-07-28 14:49:39,869 Epoch[1] Batch [860]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.300254,	
2017-07-28 14:49:48,528 Epoch[1] Batch [870]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.299790,	
2017-07-28 14:49:56,981 Epoch[1] Batch [880]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.299236,	
2017-07-28 14:50:05,718 Epoch[1] Batch [890]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.298441,	
2017-07-28 14:50:13,779 Epoch[1] Batch [900]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.297624,	
2017-07-28 14:50:21,628 Epoch[1] Batch [910]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.296993,	
2017-07-28 14:50:29,780 Epoch[1] Batch [920]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.296796,	
2017-07-28 14:50:38,106 Epoch[1] Batch [930]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.296168,	
2017-07-28 14:50:46,223 Epoch[1] Batch [940]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.295753,	
2017-07-28 14:50:54,354 Epoch[1] Batch [950]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.294951,	
2017-07-28 14:51:03,210 Epoch[1] Batch [960]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.294335,	
2017-07-28 14:51:11,332 Epoch[1] Batch [970]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.293823,	
2017-07-28 14:51:19,675 Epoch[1] Batch [980]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.293539,	
2017-07-28 14:51:27,258 Epoch[1] Batch [990]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.292831,	
2017-07-28 14:51:35,382 Epoch[1] Batch [1000]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.292234,	
2017-07-28 14:51:43,444 Epoch[1] Batch [1010]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.291642,	
2017-07-28 14:51:51,258 Epoch[1] Batch [1020]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.290950,	
2017-07-28 14:51:59,264 Epoch[1] Batch [1030]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.290831,	
2017-07-28 14:52:06,642 Epoch[1] Batch [1040]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.290297,	
2017-07-28 14:52:14,019 Epoch[1] Batch [1050]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.289586,	
2017-07-28 14:52:21,599 Epoch[1] Batch [1060]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.288725,	
2017-07-28 14:52:28,979 Epoch[1] Batch [1070]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.288572,	
2017-07-28 14:52:36,246 Epoch[1] Batch [1080]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.287873,	
2017-07-28 14:52:43,418 Epoch[1] Batch [1090]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.287368,	
2017-07-28 14:52:50,332 Epoch[1] Batch [1100]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.286824,	
2017-07-28 14:52:57,480 Epoch[1] Batch [1110]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.286262,	
2017-07-28 14:53:04,856 Epoch[1] Batch [1120]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.286054,	
2017-07-28 14:53:12,116 Epoch[1] Batch [1130]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.286708,	
2017-07-28 14:53:19,217 Epoch[1] Batch [1140]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.286603,	
2017-07-28 14:53:26,504 Epoch[1] Batch [1150]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.285945,	
2017-07-28 14:53:33,632 Epoch[1] Batch [1160]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.285341,	
2017-07-28 14:53:40,838 Epoch[1] Batch [1170]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.284590,	
2017-07-28 14:53:47,968 Epoch[1] Batch [1180]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.283759,	
2017-07-28 14:53:55,150 Epoch[1] Batch [1190]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.283202,	
2017-07-28 14:54:01,805 Epoch[1] Batch [1200]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.282592,	
2017-07-28 14:54:08,626 Epoch[1] Batch [1210]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.282463,	
2017-07-28 14:54:15,608 Epoch[1] Batch [1220]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.282047,	
2017-07-28 14:54:23,171 Epoch[1] Batch [1230]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.281785,	
2017-07-28 14:54:29,935 Epoch[1] Batch [1240]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.281382,	
2017-07-28 14:54:36,777 Epoch[1] Batch [1250]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.281017,	
2017-07-28 14:54:43,652 Epoch[1] Batch [1260]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.280740,	
2017-07-28 14:54:51,254 Epoch[1] Batch [1270]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.280099,	
2017-07-28 14:54:58,442 Epoch[1] Batch [1280]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.279936,	
2017-07-28 14:55:05,708 Epoch[1] Batch [1290]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.279764,	
2017-07-28 14:55:13,070 Epoch[1] Batch [1300]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.279219,	
2017-07-28 14:55:20,092 Epoch[1] Batch [1310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.278894,	
2017-07-28 14:55:27,374 Epoch[1] Batch [1320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.278438,	
2017-07-28 14:55:34,545 Epoch[1] Batch [1330]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.278109,	
2017-07-28 14:55:41,704 Epoch[1] Batch [1340]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.277589,	
2017-07-28 14:55:48,595 Epoch[1] Batch [1350]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.277258,	
2017-07-28 14:55:55,353 Epoch[1] Batch [1360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.276690,	
2017-07-28 14:56:02,276 Epoch[1] Batch [1370]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.276479,	
2017-07-28 14:56:09,653 Epoch[1] Batch [1380]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.275969,	
2017-07-28 14:56:16,711 Epoch[1] Batch [1390]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.275621,	
2017-07-28 14:56:23,572 Epoch[1] Batch [1400]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.275198,	
2017-07-28 14:56:30,510 Epoch[1] Batch [1410]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.274921,	
2017-07-28 14:56:38,089 Epoch[1] Batch [1420]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.274729,	
2017-07-28 14:56:45,554 Epoch[1] Batch [1430]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.274794,	
2017-07-28 14:56:52,792 Epoch[1] Batch [1440]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.274633,	
2017-07-28 14:57:00,079 Epoch[1] Batch [1450]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.274373,	
2017-07-28 14:57:07,520 Epoch[1] Batch [1460]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.274012,	
2017-07-28 14:57:14,425 Epoch[1] Batch [1470]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.273534,	
2017-07-28 14:57:21,217 Epoch[1] Batch [1480]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.273441,	
2017-07-28 14:57:25,568 Epoch[1] Train-FCNLogLoss=0.273169
2017-07-28 14:57:25,568 Epoch[1] Time cost=1125.864
2017-07-28 14:57:26,771 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0002.params"
2017-07-28 14:57:30,465 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0002.states"
2017-07-28 14:57:38,543 Epoch[2] Batch [10]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.244158,	
2017-07-28 14:57:45,606 Epoch[2] Batch [20]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.210428,	
2017-07-28 14:57:52,816 Epoch[2] Batch [30]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.201562,	
2017-07-28 14:57:59,823 Epoch[2] Batch [40]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.205906,	
2017-07-28 14:58:07,029 Epoch[2] Batch [50]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.207712,	
2017-07-28 14:58:14,302 Epoch[2] Batch [60]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.212271,	
2017-07-28 14:58:21,413 Epoch[2] Batch [70]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.211953,	
2017-07-28 14:58:28,843 Epoch[2] Batch [80]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.209898,	
2017-07-28 14:58:41,289 Epoch[2] Batch [90]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.212098,	
2017-07-28 14:58:53,114 Epoch[2] Batch [100]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.211900,	
2017-07-28 14:59:04,459 Epoch[2] Batch [110]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.210868,	
2017-07-28 14:59:16,092 Epoch[2] Batch [120]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.207990,	
2017-07-28 14:59:27,944 Epoch[2] Batch [130]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.209798,	
2017-07-28 14:59:37,066 Epoch[2] Batch [140]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.211646,	
2017-07-28 14:59:48,303 Epoch[2] Batch [150]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.212628,	
2017-07-28 14:59:59,063 Epoch[2] Batch [160]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.212376,	
2017-07-28 15:00:10,065 Epoch[2] Batch [170]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.210954,	
2017-07-28 15:00:18,736 Epoch[2] Batch [180]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.211468,	
2017-07-28 15:00:34,413 Epoch[2] Batch [190]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.212332,	
2017-07-28 15:00:46,127 Epoch[2] Batch [200]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.213323,	
2017-07-28 15:01:00,591 Epoch[2] Batch [210]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.212126,	
2017-07-28 15:01:14,934 Epoch[2] Batch [220]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.213335,	
2017-07-28 15:01:28,628 Epoch[2] Batch [230]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.213915,	
2017-07-28 15:01:39,183 Epoch[2] Batch [240]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.216594,	
2017-07-28 15:01:50,714 Epoch[2] Batch [250]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.219326,	
2017-07-28 15:02:00,643 Epoch[2] Batch [260]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.223431,	
2017-07-28 15:02:09,520 Epoch[2] Batch [270]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.224969,	
2017-07-28 15:02:16,869 Epoch[2] Batch [280]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.223906,	
2017-07-28 15:02:24,285 Epoch[2] Batch [290]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.225062,	
2017-07-28 15:02:31,692 Epoch[2] Batch [300]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.225347,	
2017-07-28 15:02:39,045 Epoch[2] Batch [310]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.225594,	
2017-07-28 15:02:46,695 Epoch[2] Batch [320]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.224985,	
2017-07-28 15:02:54,254 Epoch[2] Batch [330]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.224609,	
2017-07-28 15:03:01,882 Epoch[2] Batch [340]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.224757,	
2017-07-28 15:03:09,684 Epoch[2] Batch [350]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.224142,	
2017-07-28 15:03:17,407 Epoch[2] Batch [360]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.224675,	
2017-07-28 15:03:25,074 Epoch[2] Batch [370]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.223657,	
2017-07-28 15:03:32,720 Epoch[2] Batch [380]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.222635,	
2017-07-28 15:03:40,540 Epoch[2] Batch [390]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.221570,	
2017-07-28 15:03:48,636 Epoch[2] Batch [400]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.222431,	
2017-07-28 15:03:56,578 Epoch[2] Batch [410]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.221383,	
2017-07-28 15:04:04,023 Epoch[2] Batch [420]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.221514,	
2017-07-28 15:04:11,971 Epoch[2] Batch [430]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.223037,	
2017-07-28 15:04:19,786 Epoch[2] Batch [440]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.223816,	
2017-07-28 15:04:27,327 Epoch[2] Batch [450]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.223749,	
2017-07-28 15:04:35,121 Epoch[2] Batch [460]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.223420,	
2017-07-28 15:04:42,457 Epoch[2] Batch [470]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.223570,	
2017-07-28 15:04:50,061 Epoch[2] Batch [480]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.222840,	
2017-07-28 15:04:57,904 Epoch[2] Batch [490]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.221401,	
2017-07-28 15:05:05,631 Epoch[2] Batch [500]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.221333,	
2017-07-28 15:05:13,919 Epoch[2] Batch [510]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.220488,	
2017-07-28 15:05:21,862 Epoch[2] Batch [520]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.220403,	
2017-07-28 15:05:29,696 Epoch[2] Batch [530]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.220845,	
2017-07-28 15:05:38,169 Epoch[2] Batch [540]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.220043,	
2017-07-28 15:05:46,157 Epoch[2] Batch [550]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.219745,	
2017-07-28 15:05:54,221 Epoch[2] Batch [560]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.219702,	
2017-07-28 15:06:02,640 Epoch[2] Batch [570]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.219542,	
2017-07-28 15:06:11,272 Epoch[2] Batch [580]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.219421,	
2017-07-28 15:06:19,927 Epoch[2] Batch [590]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.219755,	
2017-07-28 15:06:28,413 Epoch[2] Batch [600]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.219243,	
2017-07-28 15:06:41,603 Epoch[2] Batch [610]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.218583,	
2017-07-28 15:06:55,742 Epoch[2] Batch [620]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.218406,	
2017-07-28 15:07:12,154 Epoch[2] Batch [630]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.218242,	
2017-07-28 15:07:25,694 Epoch[2] Batch [640]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.218390,	
2017-07-28 15:07:42,247 Epoch[2] Batch [650]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.218238,	
2017-07-28 15:07:56,211 Epoch[2] Batch [660]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.218602,	
2017-07-28 15:08:10,531 Epoch[2] Batch [670]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.218510,	
2017-07-28 15:08:22,511 Epoch[2] Batch [680]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.218685,	
2017-07-28 15:08:32,023 Epoch[2] Batch [690]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.219189,	
2017-07-28 15:08:41,107 Epoch[2] Batch [700]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.219276,	
2017-07-28 15:08:50,518 Epoch[2] Batch [710]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.219025,	
2017-07-28 15:09:00,784 Epoch[2] Batch [720]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.219664,	
2017-07-28 15:09:10,210 Epoch[2] Batch [730]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.219492,	
2017-07-28 15:09:20,848 Epoch[2] Batch [740]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.219113,	
2017-07-28 15:09:30,469 Epoch[2] Batch [750]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.218997,	
2017-07-28 15:09:41,769 Epoch[2] Batch [760]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.219900,	
2017-07-28 15:09:54,736 Epoch[2] Batch [770]	Speed: 3.08 samples/sec	Train-FCNLogLoss=0.220153,	
2017-07-28 15:10:11,817 Epoch[2] Batch [780]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.220221,	
2017-07-28 15:10:21,405 Epoch[2] Batch [790]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.220361,	
2017-07-28 15:10:30,700 Epoch[2] Batch [800]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.220384,	
2017-07-28 15:10:38,081 Epoch[2] Batch [810]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.220301,	
2017-07-28 15:10:48,264 Epoch[2] Batch [820]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.220210,	
2017-07-28 15:11:04,362 Epoch[2] Batch [830]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.220071,	
2017-07-28 15:11:17,461 Epoch[2] Batch [840]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.220191,	
2017-07-28 15:11:27,634 Epoch[2] Batch [850]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.220260,	
2017-07-28 15:11:40,138 Epoch[2] Batch [860]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.220003,	
2017-07-28 15:11:52,866 Epoch[2] Batch [870]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.220076,	
2017-07-28 15:12:02,261 Epoch[2] Batch [880]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.219763,	
2017-07-28 15:12:15,467 Epoch[2] Batch [890]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.220068,	
2017-07-28 15:12:27,395 Epoch[2] Batch [900]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.219898,	
2017-07-28 15:12:36,272 Epoch[2] Batch [910]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.219586,	
2017-07-28 15:12:46,924 Epoch[2] Batch [920]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.219711,	
2017-07-28 15:12:58,357 Epoch[2] Batch [930]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.220505,	
2017-07-28 15:13:08,896 Epoch[2] Batch [940]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.220686,	
2017-07-28 15:13:18,935 Epoch[2] Batch [950]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.220531,	
2017-07-28 15:13:28,461 Epoch[2] Batch [960]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.220390,	
2017-07-28 15:13:36,695 Epoch[2] Batch [970]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.220991,	
2017-07-28 15:13:44,813 Epoch[2] Batch [980]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.220915,	
2017-07-28 15:13:52,548 Epoch[2] Batch [990]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.220786,	
2017-07-28 15:14:00,643 Epoch[2] Batch [1000]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.220190,	
2017-07-28 15:14:08,255 Epoch[2] Batch [1010]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.219875,	
2017-07-28 15:14:16,113 Epoch[2] Batch [1020]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.219658,	
2017-07-28 15:14:24,109 Epoch[2] Batch [1030]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.219916,	
2017-07-28 15:14:32,089 Epoch[2] Batch [1040]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.220111,	
2017-07-28 15:14:40,074 Epoch[2] Batch [1050]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.220024,	
2017-07-28 15:14:47,722 Epoch[2] Batch [1060]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.219900,	
2017-07-28 15:14:55,682 Epoch[2] Batch [1070]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.219360,	
2017-07-28 15:15:03,309 Epoch[2] Batch [1080]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.219026,	
2017-07-28 15:15:10,990 Epoch[2] Batch [1090]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.218977,	
2017-07-28 15:15:19,165 Epoch[2] Batch [1100]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.219144,	
2017-07-28 15:15:26,990 Epoch[2] Batch [1110]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.218962,	
2017-07-28 15:15:34,397 Epoch[2] Batch [1120]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.218920,	
2017-07-28 15:15:42,241 Epoch[2] Batch [1130]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.218910,	
2017-07-28 15:15:49,942 Epoch[2] Batch [1140]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.218952,	
2017-07-28 15:15:57,815 Epoch[2] Batch [1150]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.218743,	
2017-07-28 15:16:05,235 Epoch[2] Batch [1160]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.218479,	
2017-07-28 15:16:12,908 Epoch[2] Batch [1170]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.218042,	
2017-07-28 15:16:20,799 Epoch[2] Batch [1180]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.217845,	
2017-07-28 15:16:28,802 Epoch[2] Batch [1190]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.217566,	
2017-07-28 15:16:36,681 Epoch[2] Batch [1200]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.217412,	
2017-07-28 15:16:44,150 Epoch[2] Batch [1210]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.217118,	
2017-07-28 15:16:52,553 Epoch[2] Batch [1220]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.216763,	
2017-07-28 15:17:00,266 Epoch[2] Batch [1230]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.216838,	
2017-07-28 15:17:07,821 Epoch[2] Batch [1240]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.216695,	
2017-07-28 15:17:16,871 Epoch[2] Batch [1250]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.216520,	
2017-07-28 15:17:28,709 Epoch[2] Batch [1260]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.216145,	
2017-07-28 15:17:39,078 Epoch[2] Batch [1270]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.215902,	
2017-07-28 15:17:47,919 Epoch[2] Batch [1280]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.216173,	
2017-07-28 15:17:57,196 Epoch[2] Batch [1290]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.216164,	
2017-07-28 15:18:04,018 Epoch[2] Batch [1300]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.216221,	
2017-07-28 15:18:10,943 Epoch[2] Batch [1310]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.216115,	
2017-07-28 15:18:18,406 Epoch[2] Batch [1320]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.215814,	
2017-07-28 15:18:24,918 Epoch[2] Batch [1330]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.215738,	
2017-07-28 15:18:32,061 Epoch[2] Batch [1340]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.215468,	
2017-07-28 15:18:39,262 Epoch[2] Batch [1350]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.215256,	
2017-07-28 15:18:46,045 Epoch[2] Batch [1360]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.215089,	
2017-07-28 15:18:52,506 Epoch[2] Batch [1370]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.215154,	
2017-07-28 15:18:58,441 Epoch[2] Batch [1380]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.215034,	
2017-07-28 15:19:04,940 Epoch[2] Batch [1390]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.215270,	
2017-07-28 15:19:11,425 Epoch[2] Batch [1400]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.214981,	
2017-07-28 15:19:17,256 Epoch[2] Batch [1410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.214586,	
2017-07-28 15:19:23,199 Epoch[2] Batch [1420]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.214335,	
2017-07-28 15:19:29,053 Epoch[2] Batch [1430]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.214207,	
2017-07-28 15:19:35,221 Epoch[2] Batch [1440]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.214157,	
2017-07-28 15:19:41,021 Epoch[2] Batch [1450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.214281,	
2017-07-28 15:19:46,880 Epoch[2] Batch [1460]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.214301,	
2017-07-28 15:19:52,771 Epoch[2] Batch [1470]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.214388,	
2017-07-28 15:19:58,662 Epoch[2] Batch [1480]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.214311,	
2017-07-28 15:20:02,429 Epoch[2] Train-FCNLogLoss=0.214375
2017-07-28 15:20:02,429 Epoch[2] Time cost=1351.964
2017-07-28 15:20:03,391 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0003.params"
2017-07-28 15:20:06,935 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0003.states"
2017-07-28 15:20:13,764 Epoch[3] Batch [10]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.189946,	
2017-07-28 15:20:19,903 Epoch[3] Batch [20]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.190542,	
2017-07-28 15:20:25,890 Epoch[3] Batch [30]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.193792,	
2017-07-28 15:20:31,563 Epoch[3] Batch [40]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.188284,	
2017-07-28 15:20:37,683 Epoch[3] Batch [50]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.196666,	
2017-07-28 15:20:43,513 Epoch[3] Batch [60]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.196154,	
2017-07-28 15:20:49,396 Epoch[3] Batch [70]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.197527,	
2017-07-28 15:20:55,374 Epoch[3] Batch [80]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.195971,	
2017-07-28 15:21:01,355 Epoch[3] Batch [90]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.197487,	
2017-07-28 15:21:07,261 Epoch[3] Batch [100]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.197184,	
2017-07-28 15:21:13,224 Epoch[3] Batch [110]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.194186,	
2017-07-28 15:21:19,212 Epoch[3] Batch [120]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.190747,	
2017-07-28 15:21:24,890 Epoch[3] Batch [130]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.190455,	
2017-07-28 15:21:30,811 Epoch[3] Batch [140]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.189617,	
2017-07-28 15:21:36,642 Epoch[3] Batch [150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.188083,	
2017-07-28 15:21:42,534 Epoch[3] Batch [160]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.189031,	
2017-07-28 15:21:48,438 Epoch[3] Batch [170]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.189960,	
2017-07-28 15:21:54,313 Epoch[3] Batch [180]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.194464,	
2017-07-28 15:22:00,345 Epoch[3] Batch [190]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.195379,	
2017-07-28 15:22:06,333 Epoch[3] Batch [200]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.195523,	
2017-07-28 15:22:12,171 Epoch[3] Batch [210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.195710,	
2017-07-28 15:22:17,901 Epoch[3] Batch [220]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.196092,	
2017-07-28 15:22:23,836 Epoch[3] Batch [230]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.195836,	
2017-07-28 15:22:29,686 Epoch[3] Batch [240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.195376,	
2017-07-28 15:22:35,569 Epoch[3] Batch [250]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.193270,	
2017-07-28 15:22:41,359 Epoch[3] Batch [260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.193024,	
2017-07-28 15:22:47,202 Epoch[3] Batch [270]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.192884,	
2017-07-28 15:22:52,993 Epoch[3] Batch [280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.192233,	
2017-07-28 15:22:59,283 Epoch[3] Batch [290]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.192057,	
2017-07-28 15:23:05,423 Epoch[3] Batch [300]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.191396,	
2017-07-28 15:23:11,894 Epoch[3] Batch [310]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.191621,	
2017-07-28 15:23:18,273 Epoch[3] Batch [320]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.191562,	
2017-07-28 15:23:24,404 Epoch[3] Batch [330]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.190797,	
2017-07-28 15:23:30,561 Epoch[3] Batch [340]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.191246,	
2017-07-28 15:23:36,524 Epoch[3] Batch [350]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.192737,	
2017-07-28 15:23:42,348 Epoch[3] Batch [360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.191979,	
2017-07-28 15:23:48,163 Epoch[3] Batch [370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.191782,	
2017-07-28 15:23:54,909 Epoch[3] Batch [380]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.191667,	
2017-07-28 15:24:01,755 Epoch[3] Batch [390]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.191339,	
2017-07-28 15:24:08,832 Epoch[3] Batch [400]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.190654,	
2017-07-28 15:24:15,530 Epoch[3] Batch [410]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.190088,	
2017-07-28 15:24:22,054 Epoch[3] Batch [420]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.189962,	
2017-07-28 15:24:28,686 Epoch[3] Batch [430]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.189615,	
2017-07-28 15:24:35,155 Epoch[3] Batch [440]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.189478,	
2017-07-28 15:24:42,756 Epoch[3] Batch [450]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.188590,	
2017-07-28 15:24:49,917 Epoch[3] Batch [460]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.188927,	
2017-07-28 15:24:57,095 Epoch[3] Batch [470]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.188559,	
2017-07-28 15:25:04,441 Epoch[3] Batch [480]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.188128,	
2017-07-28 15:25:11,460 Epoch[3] Batch [490]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.188584,	
2017-07-28 15:25:18,704 Epoch[3] Batch [500]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.188748,	
2017-07-28 15:25:26,015 Epoch[3] Batch [510]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.189282,	
2017-07-28 15:25:33,583 Epoch[3] Batch [520]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.189417,	
2017-07-28 15:25:40,501 Epoch[3] Batch [530]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.189458,	
2017-07-28 15:25:47,717 Epoch[3] Batch [540]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.189739,	
2017-07-28 15:25:54,832 Epoch[3] Batch [550]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.189695,	
2017-07-28 15:26:01,987 Epoch[3] Batch [560]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.189521,	
2017-07-28 15:26:09,117 Epoch[3] Batch [570]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.189273,	
2017-07-28 15:26:16,304 Epoch[3] Batch [580]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.189172,	
2017-07-28 15:26:23,432 Epoch[3] Batch [590]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.188870,	
2017-07-28 15:26:30,557 Epoch[3] Batch [600]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.188707,	
2017-07-28 15:26:37,420 Epoch[3] Batch [610]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.188574,	
2017-07-28 15:26:44,453 Epoch[3] Batch [620]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.188010,	
2017-07-28 15:26:51,608 Epoch[3] Batch [630]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.187826,	
2017-07-28 15:26:58,830 Epoch[3] Batch [640]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.187817,	
2017-07-28 15:27:05,811 Epoch[3] Batch [650]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.188172,	
2017-07-28 15:27:12,810 Epoch[3] Batch [660]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.188144,	
2017-07-28 15:27:19,777 Epoch[3] Batch [670]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.188232,	
2017-07-28 15:27:26,642 Epoch[3] Batch [680]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.188206,	
2017-07-28 15:27:33,628 Epoch[3] Batch [690]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.188502,	
2017-07-28 15:27:40,868 Epoch[3] Batch [700]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.188764,	
2017-07-28 15:27:48,272 Epoch[3] Batch [710]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.188542,	
2017-07-28 15:27:55,864 Epoch[3] Batch [720]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.189986,	
2017-07-28 15:28:02,886 Epoch[3] Batch [730]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.190611,	
2017-07-28 15:28:09,892 Epoch[3] Batch [740]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.191364,	
2017-07-28 15:28:16,988 Epoch[3] Batch [750]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.191469,	
2017-07-28 15:28:24,071 Epoch[3] Batch [760]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.192679,	
2017-07-28 15:28:31,186 Epoch[3] Batch [770]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.193191,	
2017-07-28 15:28:38,551 Epoch[3] Batch [780]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.193096,	
2017-07-28 15:28:45,584 Epoch[3] Batch [790]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.193112,	
2017-07-28 15:28:52,987 Epoch[3] Batch [800]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.193894,	
2017-07-28 15:29:00,226 Epoch[3] Batch [810]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.193664,	
2017-07-28 15:29:07,624 Epoch[3] Batch [820]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.193326,	
2017-07-28 15:29:14,443 Epoch[3] Batch [830]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.193142,	
2017-07-28 15:29:21,099 Epoch[3] Batch [840]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.192936,	
2017-07-28 15:29:27,881 Epoch[3] Batch [850]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.192878,	
2017-07-28 15:29:34,880 Epoch[3] Batch [860]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.193370,	
2017-07-28 15:29:41,689 Epoch[3] Batch [870]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.193441,	
2017-07-28 15:29:48,022 Epoch[3] Batch [880]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.194058,	
2017-07-28 15:29:54,828 Epoch[3] Batch [890]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.193980,	
2017-07-28 15:30:02,118 Epoch[3] Batch [900]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.194135,	
2017-07-28 15:30:09,216 Epoch[3] Batch [910]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.194464,	
2017-07-28 15:30:16,505 Epoch[3] Batch [920]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.194406,	
2017-07-28 15:30:23,076 Epoch[3] Batch [930]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.193969,	
2017-07-28 15:30:30,279 Epoch[3] Batch [940]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.193873,	
2017-07-28 15:30:37,542 Epoch[3] Batch [950]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.193902,	
2017-07-28 15:30:44,570 Epoch[3] Batch [960]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.193808,	
2017-07-28 15:30:51,534 Epoch[3] Batch [970]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.193674,	
2017-07-28 15:30:58,714 Epoch[3] Batch [980]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.193571,	
2017-07-28 15:31:05,717 Epoch[3] Batch [990]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.193630,	
2017-07-28 15:31:12,836 Epoch[3] Batch [1000]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.193778,	
2017-07-28 15:31:19,328 Epoch[3] Batch [1010]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.193621,	
2017-07-28 15:31:25,665 Epoch[3] Batch [1020]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.193569,	
2017-07-28 15:31:31,990 Epoch[3] Batch [1030]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.193581,	
2017-07-28 15:31:37,912 Epoch[3] Batch [1040]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.193514,	
2017-07-28 15:31:43,585 Epoch[3] Batch [1050]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.193322,	
2017-07-28 15:31:49,418 Epoch[3] Batch [1060]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.193453,	
2017-07-28 15:31:55,245 Epoch[3] Batch [1070]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.193432,	
2017-07-28 15:32:01,150 Epoch[3] Batch [1080]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.193471,	
2017-07-28 15:32:06,878 Epoch[3] Batch [1090]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.193768,	
2017-07-28 15:32:12,737 Epoch[3] Batch [1100]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.193544,	
2017-07-28 15:32:18,637 Epoch[3] Batch [1110]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.193568,	
2017-07-28 15:32:24,514 Epoch[3] Batch [1120]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.193797,	
2017-07-28 15:32:30,142 Epoch[3] Batch [1130]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.193557,	
2017-07-28 15:32:35,963 Epoch[3] Batch [1140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.193401,	
2017-07-28 15:32:41,805 Epoch[3] Batch [1150]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.193104,	
2017-07-28 15:32:47,559 Epoch[3] Batch [1160]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.193233,	
2017-07-28 15:32:53,147 Epoch[3] Batch [1170]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.193435,	
2017-07-28 15:32:58,933 Epoch[3] Batch [1180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.193848,	
2017-07-28 15:33:04,727 Epoch[3] Batch [1190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.193771,	
2017-07-28 15:33:10,542 Epoch[3] Batch [1200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.193590,	
2017-07-28 15:33:16,340 Epoch[3] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.193668,	
2017-07-28 15:33:22,168 Epoch[3] Batch [1220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.193544,	
2017-07-28 15:33:27,974 Epoch[3] Batch [1230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.193327,	
2017-07-28 15:33:33,765 Epoch[3] Batch [1240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.193013,	
2017-07-28 15:33:39,653 Epoch[3] Batch [1250]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.193037,	
2017-07-28 15:33:45,401 Epoch[3] Batch [1260]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.192813,	
2017-07-28 15:33:51,264 Epoch[3] Batch [1270]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.192606,	
2017-07-28 15:33:57,082 Epoch[3] Batch [1280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.192503,	
2017-07-28 15:34:02,901 Epoch[3] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.192615,	
2017-07-28 15:34:08,886 Epoch[3] Batch [1300]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.192984,	
2017-07-28 15:34:15,019 Epoch[3] Batch [1310]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.193061,	
2017-07-28 15:34:21,023 Epoch[3] Batch [1320]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.193368,	
2017-07-28 15:34:26,922 Epoch[3] Batch [1330]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.193611,	
2017-07-28 15:34:32,784 Epoch[3] Batch [1340]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.193638,	
2017-07-28 15:34:38,553 Epoch[3] Batch [1350]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.193445,	
2017-07-28 15:34:44,506 Epoch[3] Batch [1360]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.193325,	
2017-07-28 15:34:50,240 Epoch[3] Batch [1370]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.193231,	
2017-07-28 15:34:56,004 Epoch[3] Batch [1380]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.193058,	
2017-07-28 15:35:01,794 Epoch[3] Batch [1390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.193412,	
2017-07-28 15:35:07,600 Epoch[3] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.193450,	
2017-07-28 15:35:13,409 Epoch[3] Batch [1410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.193450,	
2017-07-28 15:35:19,224 Epoch[3] Batch [1420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.193657,	
2017-07-28 15:35:25,037 Epoch[3] Batch [1430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.193791,	
2017-07-28 15:35:30,834 Epoch[3] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.193786,	
2017-07-28 15:35:36,643 Epoch[3] Batch [1450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.193846,	
2017-07-28 15:35:42,400 Epoch[3] Batch [1460]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.193822,	
2017-07-28 15:35:48,249 Epoch[3] Batch [1470]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.193740,	
2017-07-28 15:35:54,062 Epoch[3] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.193450,	
2017-07-28 15:35:57,550 Epoch[3] Train-FCNLogLoss=0.193364
2017-07-28 15:35:57,550 Epoch[3] Time cost=950.614
2017-07-28 15:35:58,360 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0004.params"
2017-07-28 15:36:01,154 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0004.states"
2017-07-28 15:36:07,595 Epoch[4] Batch [10]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.180431,	
2017-07-28 15:36:13,306 Epoch[4] Batch [20]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.170733,	
2017-07-28 15:36:19,090 Epoch[4] Batch [30]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.170006,	
2017-07-28 15:36:24,911 Epoch[4] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.177592,	
2017-07-28 15:36:30,726 Epoch[4] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.175442,	
2017-07-28 15:36:36,526 Epoch[4] Batch [60]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.177288,	
2017-07-28 15:36:42,358 Epoch[4] Batch [70]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.177848,	
2017-07-28 15:36:48,190 Epoch[4] Batch [80]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.178585,	
2017-07-28 15:36:53,961 Epoch[4] Batch [90]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.179291,	
2017-07-28 15:36:59,826 Epoch[4] Batch [100]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.182606,	
2017-07-28 15:37:05,625 Epoch[4] Batch [110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.182240,	
2017-07-28 15:37:11,411 Epoch[4] Batch [120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.186204,	
2017-07-28 15:37:17,080 Epoch[4] Batch [130]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.186379,	
2017-07-28 15:37:22,854 Epoch[4] Batch [140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.185763,	
2017-07-28 15:37:28,580 Epoch[4] Batch [150]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.184852,	
2017-07-28 15:37:34,413 Epoch[4] Batch [160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.183627,	
2017-07-28 15:37:40,243 Epoch[4] Batch [170]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.183537,	
2017-07-28 15:37:46,063 Epoch[4] Batch [180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.182364,	
2017-07-28 15:37:51,846 Epoch[4] Batch [190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.180885,	
2017-07-28 15:37:57,651 Epoch[4] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.179992,	
2017-07-28 15:38:03,482 Epoch[4] Batch [210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.181799,	
2017-07-28 15:38:09,335 Epoch[4] Batch [220]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.181900,	
2017-07-28 15:38:15,082 Epoch[4] Batch [230]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.181532,	
2017-07-28 15:38:20,957 Epoch[4] Batch [240]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.180390,	
2017-07-28 15:38:26,744 Epoch[4] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.180900,	
2017-07-28 15:38:32,563 Epoch[4] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.180492,	
2017-07-28 15:38:38,368 Epoch[4] Batch [270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.180010,	
2017-07-28 15:38:44,189 Epoch[4] Batch [280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.179321,	
2017-07-28 15:38:49,995 Epoch[4] Batch [290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.179576,	
2017-07-28 15:38:55,846 Epoch[4] Batch [300]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.179529,	
2017-07-28 15:39:01,648 Epoch[4] Batch [310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.179662,	
2017-07-28 15:39:07,440 Epoch[4] Batch [320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.180932,	
2017-07-28 15:39:13,268 Epoch[4] Batch [330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.180914,	
2017-07-28 15:39:19,104 Epoch[4] Batch [340]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.180540,	
2017-07-28 15:39:24,894 Epoch[4] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.180561,	
2017-07-28 15:39:30,706 Epoch[4] Batch [360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.181358,	
2017-07-28 15:39:36,515 Epoch[4] Batch [370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.180910,	
2017-07-28 15:39:42,342 Epoch[4] Batch [380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.180904,	
2017-07-28 15:39:48,137 Epoch[4] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.180845,	
2017-07-28 15:39:53,989 Epoch[4] Batch [400]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.180540,	
2017-07-28 15:39:59,803 Epoch[4] Batch [410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.180407,	
2017-07-28 15:40:05,615 Epoch[4] Batch [420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.179717,	
2017-07-28 15:40:11,400 Epoch[4] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.179490,	
2017-07-28 15:40:17,202 Epoch[4] Batch [440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.178816,	
2017-07-28 15:40:23,061 Epoch[4] Batch [450]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.178978,	
2017-07-28 15:40:28,823 Epoch[4] Batch [460]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.179043,	
2017-07-28 15:40:34,634 Epoch[4] Batch [470]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.179583,	
2017-07-28 15:40:40,436 Epoch[4] Batch [480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.179987,	
2017-07-28 15:40:46,268 Epoch[4] Batch [490]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.179303,	
2017-07-28 15:40:52,073 Epoch[4] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.179339,	
2017-07-28 15:40:57,849 Epoch[4] Batch [510]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.179552,	
2017-07-28 15:41:03,667 Epoch[4] Batch [520]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.179212,	
2017-07-28 15:41:09,459 Epoch[4] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.178812,	
2017-07-28 15:41:15,276 Epoch[4] Batch [540]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.178332,	
2017-07-28 15:41:21,104 Epoch[4] Batch [550]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.177645,	
2017-07-28 15:41:26,891 Epoch[4] Batch [560]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.177783,	
2017-07-28 15:41:32,702 Epoch[4] Batch [570]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.177675,	
2017-07-28 15:41:38,484 Epoch[4] Batch [580]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.177824,	
2017-07-28 15:41:44,308 Epoch[4] Batch [590]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.177954,	
2017-07-28 15:41:50,150 Epoch[4] Batch [600]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.177654,	
2017-07-28 15:41:56,018 Epoch[4] Batch [610]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.177416,	
2017-07-28 15:42:01,764 Epoch[4] Batch [620]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.177515,	
2017-07-28 15:42:07,595 Epoch[4] Batch [630]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.177559,	
2017-07-28 15:42:13,362 Epoch[4] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.177420,	
2017-07-28 15:42:19,153 Epoch[4] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.177437,	
2017-07-28 15:42:25,025 Epoch[4] Batch [660]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.177017,	
2017-07-28 15:42:30,821 Epoch[4] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176853,	
2017-07-28 15:42:36,625 Epoch[4] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176810,	
2017-07-28 15:42:42,471 Epoch[4] Batch [690]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.176842,	
2017-07-28 15:42:48,237 Epoch[4] Batch [700]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.176869,	
2017-07-28 15:42:54,073 Epoch[4] Batch [710]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.176540,	
2017-07-28 15:42:59,858 Epoch[4] Batch [720]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.176626,	
2017-07-28 15:43:05,623 Epoch[4] Batch [730]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.176532,	
2017-07-28 15:43:11,438 Epoch[4] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176349,	
2017-07-28 15:43:17,283 Epoch[4] Batch [750]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.176034,	
2017-07-28 15:43:23,050 Epoch[4] Batch [760]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.176005,	
2017-07-28 15:43:28,913 Epoch[4] Batch [770]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.175752,	
2017-07-28 15:43:34,669 Epoch[4] Batch [780]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.175505,	
2017-07-28 15:43:40,471 Epoch[4] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176165,	
2017-07-28 15:43:46,331 Epoch[4] Batch [800]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177233,	
2017-07-28 15:43:52,119 Epoch[4] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.177517,	
2017-07-28 15:43:58,055 Epoch[4] Batch [820]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.178197,	
2017-07-28 15:44:03,736 Epoch[4] Batch [830]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.178272,	
2017-07-28 15:44:09,517 Epoch[4] Batch [840]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.178428,	
2017-07-28 15:44:15,330 Epoch[4] Batch [850]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.178374,	
2017-07-28 15:44:21,104 Epoch[4] Batch [860]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.178558,	
2017-07-28 15:44:26,909 Epoch[4] Batch [870]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.178534,	
2017-07-28 15:44:32,571 Epoch[4] Batch [880]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.178455,	
2017-07-28 15:44:37,474 Epoch[4] Batch [890]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.178491,	
2017-07-28 15:44:43,055 Epoch[4] Batch [900]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.178464,	
2017-07-28 15:44:48,877 Epoch[4] Batch [910]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.178126,	
2017-07-28 15:44:54,698 Epoch[4] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.177850,	
2017-07-28 15:45:00,484 Epoch[4] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.177774,	
2017-07-28 15:45:06,313 Epoch[4] Batch [940]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.178045,	
2017-07-28 15:45:12,087 Epoch[4] Batch [950]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.178457,	
2017-07-28 15:45:17,930 Epoch[4] Batch [960]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.178536,	
2017-07-28 15:45:23,783 Epoch[4] Batch [970]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.178478,	
2017-07-28 15:45:29,553 Epoch[4] Batch [980]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.178588,	
2017-07-28 15:45:35,364 Epoch[4] Batch [990]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.178674,	
2017-07-28 15:45:41,212 Epoch[4] Batch [1000]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.178559,	
2017-07-28 15:45:46,961 Epoch[4] Batch [1010]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.178580,	
2017-07-28 15:45:52,765 Epoch[4] Batch [1020]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.178491,	
2017-07-28 15:45:58,621 Epoch[4] Batch [1030]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.178166,	
2017-07-28 15:46:04,400 Epoch[4] Batch [1040]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.178151,	
2017-07-28 15:46:10,246 Epoch[4] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.178012,	
2017-07-28 15:46:16,104 Epoch[4] Batch [1060]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177871,	
2017-07-28 15:46:21,903 Epoch[4] Batch [1070]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.177995,	
2017-07-28 15:46:27,682 Epoch[4] Batch [1080]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.178169,	
2017-07-28 15:46:33,526 Epoch[4] Batch [1090]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.178091,	
2017-07-28 15:46:39,342 Epoch[4] Batch [1100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.178098,	
2017-07-28 15:46:45,182 Epoch[4] Batch [1110]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.177954,	
2017-07-28 15:46:50,984 Epoch[4] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.177909,	
2017-07-28 15:46:56,771 Epoch[4] Batch [1130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.177802,	
2017-07-28 15:47:02,616 Epoch[4] Batch [1140]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.178149,	
2017-07-28 15:47:08,399 Epoch[4] Batch [1150]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.178164,	
2017-07-28 15:47:14,303 Epoch[4] Batch [1160]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.178345,	
2017-07-28 15:47:20,072 Epoch[4] Batch [1170]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.178282,	
2017-07-28 15:47:25,937 Epoch[4] Batch [1180]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.178328,	
2017-07-28 15:47:31,711 Epoch[4] Batch [1190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.178358,	
2017-07-28 15:47:37,542 Epoch[4] Batch [1200]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.178375,	
2017-07-28 15:47:43,329 Epoch[4] Batch [1210]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.178092,	
2017-07-28 15:47:49,182 Epoch[4] Batch [1220]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.178162,	
2017-07-28 15:47:54,973 Epoch[4] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.178064,	
2017-07-28 15:48:00,745 Epoch[4] Batch [1240]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.177866,	
2017-07-28 15:48:06,603 Epoch[4] Batch [1250]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.178095,	
2017-07-28 15:48:12,428 Epoch[4] Batch [1260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.177909,	
2017-07-28 15:48:18,259 Epoch[4] Batch [1270]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.177954,	
2017-07-28 15:48:24,060 Epoch[4] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.177773,	
2017-07-28 15:48:29,913 Epoch[4] Batch [1290]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177959,	
2017-07-28 15:48:35,704 Epoch[4] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.178062,	
2017-07-28 15:48:41,550 Epoch[4] Batch [1310]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.178027,	
2017-07-28 15:48:47,386 Epoch[4] Batch [1320]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.177954,	
2017-07-28 15:48:53,185 Epoch[4] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.177876,	
2017-07-28 15:48:58,953 Epoch[4] Batch [1340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.177844,	
2017-07-28 15:49:04,807 Epoch[4] Batch [1350]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177930,	
2017-07-28 15:49:10,618 Epoch[4] Batch [1360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.177887,	
2017-07-28 15:49:16,432 Epoch[4] Batch [1370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.178064,	
2017-07-28 15:49:22,266 Epoch[4] Batch [1380]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.178226,	
2017-07-28 15:49:28,188 Epoch[4] Batch [1390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.178117,	
2017-07-28 15:49:33,957 Epoch[4] Batch [1400]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.178244,	
2017-07-28 15:49:39,686 Epoch[4] Batch [1410]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.178438,	
2017-07-28 15:49:45,515 Epoch[4] Batch [1420]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.178465,	
2017-07-28 15:49:51,337 Epoch[4] Batch [1430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.178240,	
2017-07-28 15:49:57,169 Epoch[4] Batch [1440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.178056,	
2017-07-28 15:50:02,975 Epoch[4] Batch [1450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.177944,	
2017-07-28 15:50:08,840 Epoch[4] Batch [1460]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.177941,	
2017-07-28 15:50:14,582 Epoch[4] Batch [1470]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.177880,	
2017-07-28 15:50:20,418 Epoch[4] Batch [1480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.177990,	
2017-07-28 15:50:23,904 Epoch[4] Train-FCNLogLoss=0.178135
2017-07-28 15:50:23,904 Epoch[4] Time cost=862.750
2017-07-28 15:50:25,041 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0005.params"
2017-07-28 15:50:28,675 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0005.states"
2017-07-28 15:50:35,379 Epoch[5] Batch [10]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.190448,	
2017-07-28 15:50:41,138 Epoch[5] Batch [20]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.177983,	
2017-07-28 15:50:46,927 Epoch[5] Batch [30]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.170253,	
2017-07-28 15:50:52,728 Epoch[5] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.170569,	
2017-07-28 15:50:58,544 Epoch[5] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.170830,	
2017-07-28 15:51:04,462 Epoch[5] Batch [60]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.167289,	
2017-07-28 15:51:10,191 Epoch[5] Batch [70]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.166881,	
2017-07-28 15:51:16,071 Epoch[5] Batch [80]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.165446,	
2017-07-28 15:51:21,839 Epoch[5] Batch [90]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.164259,	
2017-07-28 15:51:27,588 Epoch[5] Batch [100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.165516,	
2017-07-28 15:51:33,447 Epoch[5] Batch [110]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.165841,	
2017-07-28 15:51:39,238 Epoch[5] Batch [120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.165606,	
2017-07-28 15:51:45,068 Epoch[5] Batch [130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.168969,	
2017-07-28 15:51:50,891 Epoch[5] Batch [140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.172187,	
2017-07-28 15:51:56,809 Epoch[5] Batch [150]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.174687,	
2017-07-28 15:52:02,578 Epoch[5] Batch [160]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.179597,	
2017-07-28 15:52:08,456 Epoch[5] Batch [170]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.179776,	
2017-07-28 15:52:14,255 Epoch[5] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.180513,	
2017-07-28 15:52:19,999 Epoch[5] Batch [190]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.179460,	
2017-07-28 15:52:25,814 Epoch[5] Batch [200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.179650,	
2017-07-28 15:52:31,580 Epoch[5] Batch [210]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.179864,	
2017-07-28 15:52:37,435 Epoch[5] Batch [220]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177956,	
2017-07-28 15:52:43,329 Epoch[5] Batch [230]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.177504,	
2017-07-28 15:52:49,108 Epoch[5] Batch [240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.176689,	
2017-07-28 15:52:54,991 Epoch[5] Batch [250]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.177489,	
2017-07-28 15:53:00,848 Epoch[5] Batch [260]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177331,	
2017-07-28 15:53:06,897 Epoch[5] Batch [270]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.177089,	
2017-07-28 15:53:12,690 Epoch[5] Batch [280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.176588,	
2017-07-28 15:53:18,475 Epoch[5] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.176043,	
2017-07-28 15:53:24,294 Epoch[5] Batch [300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.175946,	
2017-07-28 15:53:30,098 Epoch[5] Batch [310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176582,	
2017-07-28 15:53:35,914 Epoch[5] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176029,	
2017-07-28 15:53:41,710 Epoch[5] Batch [330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176524,	
2017-07-28 15:53:47,526 Epoch[5] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.176269,	
2017-07-28 15:53:53,326 Epoch[5] Batch [350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.175605,	
2017-07-28 15:53:59,111 Epoch[5] Batch [360]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.175462,	
2017-07-28 15:54:04,941 Epoch[5] Batch [370]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.175756,	
2017-07-28 15:54:10,738 Epoch[5] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.175781,	
2017-07-28 15:54:16,567 Epoch[5] Batch [390]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.175481,	
2017-07-28 15:54:22,409 Epoch[5] Batch [400]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.175570,	
2017-07-28 15:54:28,179 Epoch[5] Batch [410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.175505,	
2017-07-28 15:54:34,021 Epoch[5] Batch [420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.174857,	
2017-07-28 15:54:39,859 Epoch[5] Batch [430]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.174382,	
2017-07-28 15:54:45,661 Epoch[5] Batch [440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.174307,	
2017-07-28 15:54:51,496 Epoch[5] Batch [450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.174169,	
2017-07-28 15:54:57,293 Epoch[5] Batch [460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.174591,	
2017-07-28 15:55:03,050 Epoch[5] Batch [470]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.174747,	
2017-07-28 15:55:08,875 Epoch[5] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.174500,	
2017-07-28 15:55:14,713 Epoch[5] Batch [490]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.174563,	
2017-07-28 15:55:20,591 Epoch[5] Batch [500]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.174440,	
2017-07-28 15:55:26,364 Epoch[5] Batch [510]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.174402,	
2017-07-28 15:55:32,147 Epoch[5] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.174001,	
2017-07-28 15:55:37,983 Epoch[5] Batch [530]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.173762,	
2017-07-28 15:55:43,796 Epoch[5] Batch [540]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.173829,	
2017-07-28 15:55:49,622 Epoch[5] Batch [550]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.173520,	
2017-07-28 15:55:55,459 Epoch[5] Batch [560]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.173905,	
2017-07-28 15:56:01,230 Epoch[5] Batch [570]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.174125,	
2017-07-28 15:56:07,071 Epoch[5] Batch [580]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.173891,	
2017-07-28 15:56:12,889 Epoch[5] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.173312,	
2017-07-28 15:56:18,716 Epoch[5] Batch [600]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.172977,	
2017-07-28 15:56:24,536 Epoch[5] Batch [610]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.173367,	
2017-07-28 15:56:30,439 Epoch[5] Batch [620]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.173222,	
2017-07-28 15:56:36,008 Epoch[5] Batch [630]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.172877,	
2017-07-28 15:56:41,778 Epoch[5] Batch [640]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.173180,	
2017-07-28 15:56:47,513 Epoch[5] Batch [650]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.172981,	
2017-07-28 15:56:53,350 Epoch[5] Batch [660]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.173035,	
2017-07-28 15:56:59,163 Epoch[5] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.172385,	
2017-07-28 15:57:05,039 Epoch[5] Batch [680]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.172868,	
2017-07-28 15:57:10,808 Epoch[5] Batch [690]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.172718,	
2017-07-28 15:57:16,609 Epoch[5] Batch [700]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.172834,	
2017-07-28 15:57:22,633 Epoch[5] Batch [710]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.173141,	
2017-07-28 15:57:28,467 Epoch[5] Batch [720]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.172953,	
2017-07-28 15:57:34,098 Epoch[5] Batch [730]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.172726,	
2017-07-28 15:57:39,931 Epoch[5] Batch [740]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.173144,	
2017-07-28 15:57:45,743 Epoch[5] Batch [750]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.173200,	
2017-07-28 15:57:51,596 Epoch[5] Batch [760]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.172992,	
2017-07-28 15:57:57,398 Epoch[5] Batch [770]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.172901,	
2017-07-28 15:58:03,381 Epoch[5] Batch [780]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.172676,	
2017-07-28 15:58:09,077 Epoch[5] Batch [790]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.172443,	
2017-07-28 15:58:14,911 Epoch[5] Batch [800]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.172473,	
2017-07-28 15:58:20,709 Epoch[5] Batch [810]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.172450,	
2017-07-28 15:58:26,544 Epoch[5] Batch [820]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.172249,	
2017-07-28 15:58:32,347 Epoch[5] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.172129,	
2017-07-28 15:58:38,179 Epoch[5] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.171983,	
2017-07-28 15:58:44,005 Epoch[5] Batch [850]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.171842,	
2017-07-28 15:58:49,913 Epoch[5] Batch [860]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.171571,	
2017-07-28 15:58:55,627 Epoch[5] Batch [870]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.171202,	
2017-07-28 15:59:01,496 Epoch[5] Batch [880]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.171168,	
2017-07-28 15:59:07,344 Epoch[5] Batch [890]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.170983,	
2017-07-28 15:59:13,288 Epoch[5] Batch [900]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.170967,	
2017-07-28 15:59:19,181 Epoch[5] Batch [910]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.170744,	
2017-07-28 15:59:24,992 Epoch[5] Batch [920]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.170533,	
2017-07-28 15:59:30,764 Epoch[5] Batch [930]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.170279,	
2017-07-28 15:59:36,702 Epoch[5] Batch [940]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.170044,	
2017-07-28 15:59:42,854 Epoch[5] Batch [950]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.170043,	
2017-07-28 15:59:48,689 Epoch[5] Batch [960]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.170018,	
2017-07-28 15:59:54,510 Epoch[5] Batch [970]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.169660,	
2017-07-28 16:00:00,330 Epoch[5] Batch [980]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.169416,	
2017-07-28 16:00:06,086 Epoch[5] Batch [990]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.169286,	
2017-07-28 16:00:11,800 Epoch[5] Batch [1000]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.169060,	
2017-07-28 16:00:17,646 Epoch[5] Batch [1010]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.168912,	
2017-07-28 16:00:23,381 Epoch[5] Batch [1020]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.168898,	
2017-07-28 16:00:29,195 Epoch[5] Batch [1030]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.169095,	
2017-07-28 16:00:35,029 Epoch[5] Batch [1040]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.168877,	
2017-07-28 16:00:40,820 Epoch[5] Batch [1050]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.168800,	
2017-07-28 16:00:46,626 Epoch[5] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.168661,	
2017-07-28 16:00:52,464 Epoch[5] Batch [1070]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.168309,	
2017-07-28 16:00:58,321 Epoch[5] Batch [1080]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.168056,	
2017-07-28 16:01:04,084 Epoch[5] Batch [1090]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.168114,	
2017-07-28 16:01:09,878 Epoch[5] Batch [1100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.168073,	
2017-07-28 16:01:15,703 Epoch[5] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.168027,	
2017-07-28 16:01:21,509 Epoch[5] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.167877,	
2017-07-28 16:01:27,367 Epoch[5] Batch [1130]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.168028,	
2017-07-28 16:01:33,156 Epoch[5] Batch [1140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.167968,	
2017-07-28 16:01:38,947 Epoch[5] Batch [1150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.167744,	
2017-07-28 16:01:44,774 Epoch[5] Batch [1160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.167725,	
2017-07-28 16:01:50,581 Epoch[5] Batch [1170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.167599,	
2017-07-28 16:01:56,370 Epoch[5] Batch [1180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.167509,	
2017-07-28 16:02:02,251 Epoch[5] Batch [1190]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.167686,	
2017-07-28 16:02:08,057 Epoch[5] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.167769,	
2017-07-28 16:02:13,869 Epoch[5] Batch [1210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.167707,	
2017-07-28 16:02:19,680 Epoch[5] Batch [1220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.167471,	
2017-07-28 16:02:25,453 Epoch[5] Batch [1230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.167533,	
2017-07-28 16:02:31,262 Epoch[5] Batch [1240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.167543,	
2017-07-28 16:02:37,130 Epoch[5] Batch [1250]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.167509,	
2017-07-28 16:02:42,900 Epoch[5] Batch [1260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.167297,	
2017-07-28 16:02:48,751 Epoch[5] Batch [1270]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.167316,	
2017-07-28 16:02:54,505 Epoch[5] Batch [1280]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.167669,	
2017-07-28 16:03:00,368 Epoch[5] Batch [1290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.167615,	
2017-07-28 16:03:06,238 Epoch[5] Batch [1300]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.167876,	
2017-07-28 16:03:12,023 Epoch[5] Batch [1310]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.168048,	
2017-07-28 16:03:17,894 Epoch[5] Batch [1320]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.168454,	
2017-07-28 16:03:23,704 Epoch[5] Batch [1330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.168611,	
2017-07-28 16:03:29,466 Epoch[5] Batch [1340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.168713,	
2017-07-28 16:03:35,319 Epoch[5] Batch [1350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.168617,	
2017-07-28 16:03:41,144 Epoch[5] Batch [1360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.169050,	
2017-07-28 16:03:46,945 Epoch[5] Batch [1370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.169419,	
2017-07-28 16:03:52,767 Epoch[5] Batch [1380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.169365,	
2017-07-28 16:03:58,583 Epoch[5] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.169679,	
2017-07-28 16:04:04,410 Epoch[5] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.169657,	
2017-07-28 16:04:10,315 Epoch[5] Batch [1410]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.169774,	
2017-07-28 16:04:16,034 Epoch[5] Batch [1420]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.169748,	
2017-07-28 16:04:21,839 Epoch[5] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.169665,	
2017-07-28 16:04:27,687 Epoch[5] Batch [1440]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.169753,	
2017-07-28 16:04:33,482 Epoch[5] Batch [1450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.169676,	
2017-07-28 16:04:39,495 Epoch[5] Batch [1460]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.169530,	
2017-07-28 16:04:45,180 Epoch[5] Batch [1470]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.169528,	
2017-07-28 16:04:51,058 Epoch[5] Batch [1480]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.169689,	
2017-07-28 16:04:54,485 Epoch[5] Train-FCNLogLoss=0.169679
2017-07-28 16:04:54,485 Epoch[5] Time cost=865.810
2017-07-28 16:04:55,474 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0006.params"
2017-07-28 16:04:59,089 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0006.states"
2017-07-28 16:05:05,805 Epoch[6] Batch [10]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.156350,	
2017-07-28 16:05:11,535 Epoch[6] Batch [20]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.154174,	
2017-07-28 16:05:17,393 Epoch[6] Batch [30]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.145135,	
2017-07-28 16:05:23,215 Epoch[6] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.149513,	
2017-07-28 16:05:29,009 Epoch[6] Batch [50]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.148138,	
2017-07-28 16:05:34,849 Epoch[6] Batch [60]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.153990,	
2017-07-28 16:05:40,648 Epoch[6] Batch [70]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.157151,	
2017-07-28 16:05:46,560 Epoch[6] Batch [80]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.156201,	
2017-07-28 16:05:52,383 Epoch[6] Batch [90]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.155628,	
2017-07-28 16:05:58,163 Epoch[6] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.154804,	
2017-07-28 16:06:03,940 Epoch[6] Batch [110]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.156655,	
2017-07-28 16:06:09,690 Epoch[6] Batch [120]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.158292,	
2017-07-28 16:06:15,516 Epoch[6] Batch [130]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.158581,	
2017-07-28 16:06:21,377 Epoch[6] Batch [140]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.157335,	
2017-07-28 16:06:27,219 Epoch[6] Batch [150]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.157095,	
2017-07-28 16:06:33,016 Epoch[6] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.160825,	
2017-07-28 16:06:38,779 Epoch[6] Batch [170]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.161421,	
2017-07-28 16:06:44,605 Epoch[6] Batch [180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.163262,	
2017-07-28 16:06:50,472 Epoch[6] Batch [190]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.164082,	
2017-07-28 16:06:56,261 Epoch[6] Batch [200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.165202,	
2017-07-28 16:07:02,348 Epoch[6] Batch [210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.165094,	
2017-07-28 16:07:08,156 Epoch[6] Batch [220]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164774,	
2017-07-28 16:07:13,937 Epoch[6] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.163962,	
2017-07-28 16:07:19,661 Epoch[6] Batch [240]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.163537,	
2017-07-28 16:07:25,396 Epoch[6] Batch [250]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.163597,	
2017-07-28 16:07:31,211 Epoch[6] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.162904,	
2017-07-28 16:07:37,003 Epoch[6] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.162616,	
2017-07-28 16:07:42,850 Epoch[6] Batch [280]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.163646,	
2017-07-28 16:07:48,643 Epoch[6] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.162620,	
2017-07-28 16:07:54,485 Epoch[6] Batch [300]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.162625,	
2017-07-28 16:08:00,279 Epoch[6] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163082,	
2017-07-28 16:08:06,126 Epoch[6] Batch [320]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.162582,	
2017-07-28 16:08:11,910 Epoch[6] Batch [330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.163154,	
2017-07-28 16:08:17,734 Epoch[6] Batch [340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.163961,	
2017-07-28 16:08:23,580 Epoch[6] Batch [350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.165079,	
2017-07-28 16:08:29,409 Epoch[6] Batch [360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.165874,	
2017-07-28 16:08:35,254 Epoch[6] Batch [370]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.166190,	
2017-07-28 16:08:41,009 Epoch[6] Batch [380]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.166011,	
2017-07-28 16:08:46,828 Epoch[6] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.165609,	
2017-07-28 16:08:52,634 Epoch[6] Batch [400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.165121,	
2017-07-28 16:08:58,455 Epoch[6] Batch [410]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164597,	
2017-07-28 16:09:04,298 Epoch[6] Batch [420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164082,	
2017-07-28 16:09:10,055 Epoch[6] Batch [430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.163728,	
2017-07-28 16:09:15,871 Epoch[6] Batch [440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163314,	
2017-07-28 16:09:21,700 Epoch[6] Batch [450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163372,	
2017-07-28 16:09:27,505 Epoch[6] Batch [460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163075,	
2017-07-28 16:09:33,358 Epoch[6] Batch [470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.162834,	
2017-07-28 16:09:39,183 Epoch[6] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.162963,	
2017-07-28 16:09:45,051 Epoch[6] Batch [490]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.163391,	
2017-07-28 16:09:50,792 Epoch[6] Batch [500]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.163411,	
2017-07-28 16:09:56,611 Epoch[6] Batch [510]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163773,	
2017-07-28 16:10:02,378 Epoch[6] Batch [520]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.163513,	
2017-07-28 16:10:08,399 Epoch[6] Batch [530]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.163113,	
2017-07-28 16:10:14,133 Epoch[6] Batch [540]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.162835,	
2017-07-28 16:10:19,965 Epoch[6] Batch [550]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163376,	
2017-07-28 16:10:25,662 Epoch[6] Batch [560]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.163100,	
2017-07-28 16:10:31,436 Epoch[6] Batch [570]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.162949,	
2017-07-28 16:10:37,284 Epoch[6] Batch [580]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.163390,	
2017-07-28 16:10:43,095 Epoch[6] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163211,	
2017-07-28 16:10:48,919 Epoch[6] Batch [600]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.163077,	
2017-07-28 16:10:54,729 Epoch[6] Batch [610]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163091,	
2017-07-28 16:11:00,505 Epoch[6] Batch [620]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.162850,	
2017-07-28 16:11:06,447 Epoch[6] Batch [630]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.162565,	
2017-07-28 16:11:12,470 Epoch[6] Batch [640]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.162157,	
2017-07-28 16:11:18,254 Epoch[6] Batch [650]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.161854,	
2017-07-28 16:11:24,105 Epoch[6] Batch [660]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.161584,	
2017-07-28 16:11:29,930 Epoch[6] Batch [670]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.161683,	
2017-07-28 16:11:35,743 Epoch[6] Batch [680]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.161728,	
2017-07-28 16:11:41,781 Epoch[6] Batch [690]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.162111,	
2017-07-28 16:11:47,481 Epoch[6] Batch [700]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.162303,	
2017-07-28 16:11:53,252 Epoch[6] Batch [710]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.162226,	
2017-07-28 16:11:59,053 Epoch[6] Batch [720]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.162516,	
2017-07-28 16:12:04,872 Epoch[6] Batch [730]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.162928,	
2017-07-28 16:12:10,702 Epoch[6] Batch [740]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163859,	
2017-07-28 16:12:16,604 Epoch[6] Batch [750]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.164049,	
2017-07-28 16:12:22,396 Epoch[6] Batch [760]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.163985,	
2017-07-28 16:12:28,205 Epoch[6] Batch [770]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.164385,	
2017-07-28 16:12:34,006 Epoch[6] Batch [780]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.164789,	
2017-07-28 16:12:39,838 Epoch[6] Batch [790]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.164853,	
2017-07-28 16:12:45,675 Epoch[6] Batch [800]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.165027,	
2017-07-28 16:12:51,574 Epoch[6] Batch [810]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.164953,	
2017-07-28 16:12:57,767 Epoch[6] Batch [820]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.164700,	
2017-07-28 16:13:03,599 Epoch[6] Batch [830]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.164735,	
2017-07-28 16:13:10,183 Epoch[6] Batch [840]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.164874,	
2017-07-28 16:13:16,200 Epoch[6] Batch [850]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.164883,	
2017-07-28 16:13:22,368 Epoch[6] Batch [860]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.164805,	
2017-07-28 16:13:28,214 Epoch[6] Batch [870]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164580,	
2017-07-28 16:13:33,618 Epoch[6] Batch [880]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.164517,	
2017-07-28 16:13:39,803 Epoch[6] Batch [890]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.164427,	
2017-07-28 16:13:45,847 Epoch[6] Batch [900]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.164558,	
2017-07-28 16:13:51,757 Epoch[6] Batch [910]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.164677,	
2017-07-28 16:13:57,622 Epoch[6] Batch [920]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.164629,	
2017-07-28 16:14:03,393 Epoch[6] Batch [930]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.164837,	
2017-07-28 16:14:09,135 Epoch[6] Batch [940]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.164835,	
2017-07-28 16:14:14,954 Epoch[6] Batch [950]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164649,	
2017-07-28 16:14:20,802 Epoch[6] Batch [960]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164662,	
2017-07-28 16:14:26,627 Epoch[6] Batch [970]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164785,	
2017-07-28 16:14:32,439 Epoch[6] Batch [980]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164650,	
2017-07-28 16:14:38,257 Epoch[6] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164523,	
2017-07-28 16:14:44,155 Epoch[6] Batch [1000]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.164626,	
2017-07-28 16:14:49,868 Epoch[6] Batch [1010]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.164721,	
2017-07-28 16:14:55,730 Epoch[6] Batch [1020]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.164852,	
2017-07-28 16:15:01,504 Epoch[6] Batch [1030]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.164500,	
2017-07-28 16:15:07,361 Epoch[6] Batch [1040]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.164645,	
2017-07-28 16:15:13,181 Epoch[6] Batch [1050]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164687,	
2017-07-28 16:15:19,019 Epoch[6] Batch [1060]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164534,	
2017-07-28 16:15:24,946 Epoch[6] Batch [1070]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.164322,	
2017-07-28 16:15:30,758 Epoch[6] Batch [1080]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.164656,	
2017-07-28 16:15:36,497 Epoch[6] Batch [1090]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.164679,	
2017-07-28 16:15:42,333 Epoch[6] Batch [1100]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164626,	
2017-07-28 16:15:48,154 Epoch[6] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164553,	
2017-07-28 16:15:53,980 Epoch[6] Batch [1120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.164992,	
2017-07-28 16:15:59,829 Epoch[6] Batch [1130]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.165059,	
2017-07-28 16:16:05,606 Epoch[6] Batch [1140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.164875,	
2017-07-28 16:16:11,442 Epoch[6] Batch [1150]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164474,	
2017-07-28 16:16:17,221 Epoch[6] Batch [1160]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.164370,	
2017-07-28 16:16:23,087 Epoch[6] Batch [1170]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.164295,	
2017-07-28 16:16:28,887 Epoch[6] Batch [1180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.164112,	
2017-07-28 16:16:34,743 Epoch[6] Batch [1190]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.164021,	
2017-07-28 16:16:40,606 Epoch[6] Batch [1200]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.163862,	
2017-07-28 16:16:46,306 Epoch[6] Batch [1210]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.163588,	
2017-07-28 16:16:52,123 Epoch[6] Batch [1220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163566,	
2017-07-28 16:16:57,964 Epoch[6] Batch [1230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.163568,	
2017-07-28 16:17:03,762 Epoch[6] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.163430,	
2017-07-28 16:17:09,592 Epoch[6] Batch [1250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163337,	
2017-07-28 16:17:15,555 Epoch[6] Batch [1260]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.163454,	
2017-07-28 16:17:21,264 Epoch[6] Batch [1270]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.163409,	
2017-07-28 16:17:27,131 Epoch[6] Batch [1280]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.163249,	
2017-07-28 16:17:32,996 Epoch[6] Batch [1290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.163400,	
2017-07-28 16:17:38,702 Epoch[6] Batch [1300]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.163391,	
2017-07-28 16:17:44,540 Epoch[6] Batch [1310]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.163245,	
2017-07-28 16:17:50,372 Epoch[6] Batch [1320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163165,	
2017-07-28 16:17:56,218 Epoch[6] Batch [1330]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.163144,	
2017-07-28 16:18:01,986 Epoch[6] Batch [1340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.163085,	
2017-07-28 16:18:07,901 Epoch[6] Batch [1350]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.163057,	
2017-07-28 16:18:14,078 Epoch[6] Batch [1360]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.162848,	
2017-07-28 16:18:19,818 Epoch[6] Batch [1370]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.162883,	
2017-07-28 16:18:25,582 Epoch[6] Batch [1380]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.162909,	
2017-07-28 16:18:31,387 Epoch[6] Batch [1390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.163055,	
2017-07-28 16:18:37,671 Epoch[6] Batch [1400]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.162998,	
2017-07-28 16:18:43,486 Epoch[6] Batch [1410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163217,	
2017-07-28 16:18:49,258 Epoch[6] Batch [1420]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.163247,	
2017-07-28 16:18:55,048 Epoch[6] Batch [1430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.163467,	
2017-07-28 16:19:00,865 Epoch[6] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163575,	
2017-07-28 16:19:06,696 Epoch[6] Batch [1450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.163443,	
2017-07-28 16:19:12,513 Epoch[6] Batch [1460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.163418,	
2017-07-28 16:19:18,416 Epoch[6] Batch [1470]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.163269,	
2017-07-28 16:19:24,134 Epoch[6] Batch [1480]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.163327,	
2017-07-28 16:19:27,585 Epoch[6] Train-FCNLogLoss=0.163230
2017-07-28 16:19:27,585 Epoch[6] Time cost=868.496
2017-07-28 16:19:28,573 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0007.params"
2017-07-28 16:19:32,595 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0007.states"
2017-07-28 16:19:39,390 Epoch[7] Batch [10]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.161466,	
2017-07-28 16:19:45,145 Epoch[7] Batch [20]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.157487,	
2017-07-28 16:19:50,988 Epoch[7] Batch [30]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.153054,	
2017-07-28 16:19:56,823 Epoch[7] Batch [40]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.150452,	
2017-07-28 16:20:02,654 Epoch[7] Batch [50]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.149632,	
2017-07-28 16:20:08,755 Epoch[7] Batch [60]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.148596,	
2017-07-28 16:20:14,642 Epoch[7] Batch [70]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.148092,	
2017-07-28 16:20:20,491 Epoch[7] Batch [80]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.147704,	
2017-07-28 16:20:26,341 Epoch[7] Batch [90]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.148055,	
2017-07-28 16:20:32,570 Epoch[7] Batch [100]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.149604,	
2017-07-28 16:20:38,500 Epoch[7] Batch [110]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.149092,	
2017-07-28 16:20:44,388 Epoch[7] Batch [120]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.149059,	
2017-07-28 16:20:50,579 Epoch[7] Batch [130]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.149443,	
2017-07-28 16:20:56,439 Epoch[7] Batch [140]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.149881,	
2017-07-28 16:21:02,324 Epoch[7] Batch [150]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.149365,	
2017-07-28 16:21:08,122 Epoch[7] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.149990,	
2017-07-28 16:21:14,461 Epoch[7] Batch [170]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.151731,	
2017-07-28 16:21:20,289 Epoch[7] Batch [180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151449,	
2017-07-28 16:21:26,129 Epoch[7] Batch [190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.152124,	
2017-07-28 16:21:31,949 Epoch[7] Batch [200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.152307,	
2017-07-28 16:21:37,752 Epoch[7] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.151198,	
2017-07-28 16:21:43,726 Epoch[7] Batch [220]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.150891,	
2017-07-28 16:21:49,560 Epoch[7] Batch [230]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.150466,	
2017-07-28 16:21:55,346 Epoch[7] Batch [240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.150787,	
2017-07-28 16:22:01,243 Epoch[7] Batch [250]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.151481,	
2017-07-28 16:22:07,360 Epoch[7] Batch [260]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.151315,	
2017-07-28 16:22:13,298 Epoch[7] Batch [270]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.151946,	
2017-07-28 16:22:19,248 Epoch[7] Batch [280]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.152249,	
2017-07-28 16:22:25,058 Epoch[7] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.152152,	
2017-07-28 16:22:30,946 Epoch[7] Batch [300]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.151864,	
2017-07-28 16:22:36,743 Epoch[7] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.150952,	
2017-07-28 16:22:42,529 Epoch[7] Batch [320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.150601,	
2017-07-28 16:22:48,422 Epoch[7] Batch [330]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.150963,	
2017-07-28 16:22:54,280 Epoch[7] Batch [340]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.151822,	
2017-07-28 16:23:00,108 Epoch[7] Batch [350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151790,	
2017-07-28 16:23:05,887 Epoch[7] Batch [360]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.151992,	
2017-07-28 16:23:11,841 Epoch[7] Batch [370]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.152621,	
2017-07-28 16:23:18,017 Epoch[7] Batch [380]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.152871,	
2017-07-28 16:23:23,862 Epoch[7] Batch [390]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.152880,	
2017-07-28 16:23:29,724 Epoch[7] Batch [400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.152658,	
2017-07-28 16:23:35,568 Epoch[7] Batch [410]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.152533,	
2017-07-28 16:23:41,470 Epoch[7] Batch [420]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.152758,	
2017-07-28 16:23:47,285 Epoch[7] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.152923,	
2017-07-28 16:23:53,331 Epoch[7] Batch [440]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.153253,	
2017-07-28 16:23:59,200 Epoch[7] Batch [450]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.153046,	
2017-07-28 16:24:05,291 Epoch[7] Batch [460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.153160,	
2017-07-28 16:24:11,114 Epoch[7] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.152628,	
2017-07-28 16:24:17,013 Epoch[7] Batch [480]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.152524,	
2017-07-28 16:24:23,211 Epoch[7] Batch [490]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.152085,	
2017-07-28 16:24:29,080 Epoch[7] Batch [500]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.152173,	
2017-07-28 16:24:34,892 Epoch[7] Batch [510]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151914,	
2017-07-28 16:24:40,660 Epoch[7] Batch [520]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.151756,	
2017-07-28 16:24:46,479 Epoch[7] Batch [530]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.152061,	
2017-07-28 16:24:52,304 Epoch[7] Batch [540]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.152133,	
2017-07-28 16:24:58,120 Epoch[7] Batch [550]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.152579,	
2017-07-28 16:25:03,747 Epoch[7] Batch [560]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.152586,	
2017-07-28 16:25:09,500 Epoch[7] Batch [570]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.152494,	
2017-07-28 16:25:15,273 Epoch[7] Batch [580]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.152364,	
2017-07-28 16:25:21,133 Epoch[7] Batch [590]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.152106,	
2017-07-28 16:25:26,856 Epoch[7] Batch [600]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.151957,	
2017-07-28 16:25:32,705 Epoch[7] Batch [610]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.151642,	
2017-07-28 16:25:38,506 Epoch[7] Batch [620]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.151370,	
2017-07-28 16:25:44,321 Epoch[7] Batch [630]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151234,	
2017-07-28 16:25:50,149 Epoch[7] Batch [640]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151200,	
2017-07-28 16:25:55,966 Epoch[7] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.151352,	
2017-07-28 16:26:01,801 Epoch[7] Batch [660]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151147,	
2017-07-28 16:26:07,709 Epoch[7] Batch [670]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.151001,	
2017-07-28 16:26:13,450 Epoch[7] Batch [680]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.150697,	
2017-07-28 16:26:19,266 Epoch[7] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.150547,	
2017-07-28 16:26:25,102 Epoch[7] Batch [700]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.150341,	
2017-07-28 16:26:30,908 Epoch[7] Batch [710]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.150370,	
2017-07-28 16:26:36,750 Epoch[7] Batch [720]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.150390,	
2017-07-28 16:26:42,539 Epoch[7] Batch [730]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.150083,	
2017-07-28 16:26:48,370 Epoch[7] Batch [740]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.150218,	
2017-07-28 16:26:54,146 Epoch[7] Batch [750]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.149992,	
2017-07-28 16:27:00,039 Epoch[7] Batch [760]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.150029,	
2017-07-28 16:27:05,828 Epoch[7] Batch [770]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.150024,	
2017-07-28 16:27:11,698 Epoch[7] Batch [780]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.149686,	
2017-07-28 16:27:17,427 Epoch[7] Batch [790]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.149429,	
2017-07-28 16:27:23,285 Epoch[7] Batch [800]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.149510,	
2017-07-28 16:27:29,055 Epoch[7] Batch [810]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.149200,	
2017-07-28 16:27:34,921 Epoch[7] Batch [820]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.149194,	
2017-07-28 16:27:40,674 Epoch[7] Batch [830]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.149340,	
2017-07-28 16:27:46,521 Epoch[7] Batch [840]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.149364,	
2017-07-28 16:27:52,314 Epoch[7] Batch [850]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.149286,	
2017-07-28 16:27:57,947 Epoch[7] Batch [860]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.149180,	
2017-07-28 16:28:03,249 Epoch[7] Batch [870]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.149189,	
2017-07-28 16:28:08,987 Epoch[7] Batch [880]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.149015,	
2017-07-28 16:28:14,766 Epoch[7] Batch [890]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.149125,	
2017-07-28 16:28:20,603 Epoch[7] Batch [900]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.149154,	
2017-07-28 16:28:26,329 Epoch[7] Batch [910]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.149116,	
2017-07-28 16:28:32,217 Epoch[7] Batch [920]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.149088,	
2017-07-28 16:28:37,960 Epoch[7] Batch [930]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.149103,	
2017-07-28 16:28:43,830 Epoch[7] Batch [940]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.149092,	
2017-07-28 16:28:49,548 Epoch[7] Batch [950]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.149052,	
2017-07-28 16:28:55,303 Epoch[7] Batch [960]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.149158,	
2017-07-28 16:29:01,091 Epoch[7] Batch [970]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.149254,	
2017-07-28 16:29:06,932 Epoch[7] Batch [980]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.149189,	
2017-07-28 16:29:12,659 Epoch[7] Batch [990]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.149101,	
2017-07-28 16:29:18,537 Epoch[7] Batch [1000]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.149086,	
2017-07-28 16:29:24,305 Epoch[7] Batch [1010]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.149248,	
2017-07-28 16:29:30,176 Epoch[7] Batch [1020]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.149261,	
2017-07-28 16:29:35,915 Epoch[7] Batch [1030]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.149029,	
2017-07-28 16:29:41,706 Epoch[7] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.149054,	
2017-07-28 16:29:47,506 Epoch[7] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.149094,	
2017-07-28 16:29:53,348 Epoch[7] Batch [1060]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.149019,	
2017-07-28 16:29:59,081 Epoch[7] Batch [1070]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.148918,	
2017-07-28 16:30:04,924 Epoch[7] Batch [1080]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.149205,	
2017-07-28 16:30:10,726 Epoch[7] Batch [1090]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149243,	
2017-07-28 16:30:16,557 Epoch[7] Batch [1100]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.149139,	
2017-07-28 16:30:22,362 Epoch[7] Batch [1110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149227,	
2017-07-28 16:30:28,165 Epoch[7] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149522,	
2017-07-28 16:30:33,993 Epoch[7] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.149722,	
2017-07-28 16:30:39,837 Epoch[7] Batch [1140]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.149922,	
2017-07-28 16:30:45,580 Epoch[7] Batch [1150]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.149907,	
2017-07-28 16:30:51,434 Epoch[7] Batch [1160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.149817,	
2017-07-28 16:30:57,235 Epoch[7] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.149844,	
2017-07-28 16:31:02,999 Epoch[7] Batch [1180]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.149892,	
2017-07-28 16:31:08,838 Epoch[7] Batch [1190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.149875,	
2017-07-28 16:31:14,651 Epoch[7] Batch [1200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.149981,	
2017-07-28 16:31:20,476 Epoch[7] Batch [1210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.149865,	
2017-07-28 16:31:26,327 Epoch[7] Batch [1220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.150140,	
2017-07-28 16:31:32,116 Epoch[7] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.150270,	
2017-07-28 16:31:37,919 Epoch[7] Batch [1240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.150386,	
2017-07-28 16:31:43,714 Epoch[7] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.150463,	
2017-07-28 16:31:49,566 Epoch[7] Batch [1260]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.150531,	
2017-07-28 16:31:55,360 Epoch[7] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.150658,	
2017-07-28 16:32:01,195 Epoch[7] Batch [1280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.150688,	
2017-07-28 16:32:07,072 Epoch[7] Batch [1290]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.150777,	
2017-07-28 16:32:12,850 Epoch[7] Batch [1300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.150664,	
2017-07-28 16:32:18,642 Epoch[7] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.150704,	
2017-07-28 16:32:24,472 Epoch[7] Batch [1320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.150604,	
2017-07-28 16:32:30,315 Epoch[7] Batch [1330]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.150628,	
2017-07-28 16:32:36,139 Epoch[7] Batch [1340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.150697,	
2017-07-28 16:32:41,905 Epoch[7] Batch [1350]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.150688,	
2017-07-28 16:32:47,749 Epoch[7] Batch [1360]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.150688,	
2017-07-28 16:32:53,647 Epoch[7] Batch [1370]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.151009,	
2017-07-28 16:32:59,423 Epoch[7] Batch [1380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.151076,	
2017-07-28 16:33:05,242 Epoch[7] Batch [1390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151011,	
2017-07-28 16:33:11,070 Epoch[7] Batch [1400]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151057,	
2017-07-28 16:33:16,890 Epoch[7] Batch [1410]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151194,	
2017-07-28 16:33:22,691 Epoch[7] Batch [1420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.151212,	
2017-07-28 16:33:28,515 Epoch[7] Batch [1430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151284,	
2017-07-28 16:33:34,725 Epoch[7] Batch [1440]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.151204,	
2017-07-28 16:33:40,455 Epoch[7] Batch [1450]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.151217,	
2017-07-28 16:33:46,287 Epoch[7] Batch [1460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151255,	
2017-07-28 16:33:52,151 Epoch[7] Batch [1470]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.151142,	
2017-07-28 16:33:57,972 Epoch[7] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.151195,	
2017-07-28 16:34:01,391 Epoch[7] Train-FCNLogLoss=0.151180
2017-07-28 16:34:01,391 Epoch[7] Time cost=868.796
2017-07-28 16:34:02,448 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0008.params"
2017-07-28 16:34:06,252 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0008.states"
2017-07-28 16:34:12,968 Epoch[8] Batch [10]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.138182,	
2017-07-28 16:34:18,736 Epoch[8] Batch [20]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.133764,	
2017-07-28 16:34:24,556 Epoch[8] Batch [30]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.138495,	
2017-07-28 16:34:30,452 Epoch[8] Batch [40]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.140963,	
2017-07-28 16:34:36,236 Epoch[8] Batch [50]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.141848,	
2017-07-28 16:34:42,114 Epoch[8] Batch [60]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.142714,	
2017-07-28 16:34:47,896 Epoch[8] Batch [70]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.142890,	
2017-07-28 16:34:53,737 Epoch[8] Batch [80]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142328,	
2017-07-28 16:34:59,592 Epoch[8] Batch [90]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.142195,	
2017-07-28 16:35:05,345 Epoch[8] Batch [100]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.140621,	
2017-07-28 16:35:11,167 Epoch[8] Batch [110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140628,	
2017-07-28 16:35:17,010 Epoch[8] Batch [120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142018,	
2017-07-28 16:35:22,835 Epoch[8] Batch [130]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142108,	
2017-07-28 16:35:28,629 Epoch[8] Batch [140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142412,	
2017-07-28 16:35:34,514 Epoch[8] Batch [150]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.142756,	
2017-07-28 16:35:40,426 Epoch[8] Batch [160]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.143442,	
2017-07-28 16:35:46,219 Epoch[8] Batch [170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141761,	
2017-07-28 16:35:51,994 Epoch[8] Batch [180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.141102,	
2017-07-28 16:35:59,285 Epoch[8] Batch [190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.141046,	
2017-07-28 16:36:05,236 Epoch[8] Batch [200]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.141159,	
2017-07-28 16:36:13,340 Epoch[8] Batch [210]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.140031,	
2017-07-28 16:36:22,778 Epoch[8] Batch [220]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.139433,	
2017-07-28 16:36:32,513 Epoch[8] Batch [230]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.139414,	
2017-07-28 16:36:42,216 Epoch[8] Batch [240]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.139550,	
2017-07-28 16:36:51,185 Epoch[8] Batch [250]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.139693,	
2017-07-28 16:37:01,300 Epoch[8] Batch [260]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.139910,	
2017-07-28 16:37:11,078 Epoch[8] Batch [270]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.140194,	
2017-07-28 16:37:20,887 Epoch[8] Batch [280]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.140534,	
2017-07-28 16:37:30,700 Epoch[8] Batch [290]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.140269,	
2017-07-28 16:37:40,511 Epoch[8] Batch [300]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.140758,	
2017-07-28 16:37:50,278 Epoch[8] Batch [310]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.141655,	
2017-07-28 16:38:00,043 Epoch[8] Batch [320]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.141934,	
2017-07-28 16:38:09,830 Epoch[8] Batch [330]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.141809,	
2017-07-28 16:38:19,637 Epoch[8] Batch [340]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142021,	
2017-07-28 16:38:29,422 Epoch[8] Batch [350]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.142079,	
2017-07-28 16:38:39,202 Epoch[8] Batch [360]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.142366,	
2017-07-28 16:38:49,014 Epoch[8] Batch [370]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142359,	
2017-07-28 16:38:58,826 Epoch[8] Batch [380]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142655,	
2017-07-28 16:39:08,237 Epoch[8] Batch [390]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.142903,	
2017-07-28 16:39:16,401 Epoch[8] Batch [400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.143276,	
2017-07-28 16:39:26,234 Epoch[8] Batch [410]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.142926,	
2017-07-28 16:39:36,018 Epoch[8] Batch [420]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.142842,	
2017-07-28 16:39:45,792 Epoch[8] Batch [430]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.142878,	
2017-07-28 16:39:55,589 Epoch[8] Batch [440]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142824,	
2017-07-28 16:40:05,410 Epoch[8] Batch [450]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.142857,	
2017-07-28 16:40:15,227 Epoch[8] Batch [460]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.143352,	
2017-07-28 16:40:25,039 Epoch[8] Batch [470]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142930,	
2017-07-28 16:40:34,849 Epoch[8] Batch [480]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142591,	
2017-07-28 16:40:44,636 Epoch[8] Batch [490]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.142532,	
2017-07-28 16:40:54,458 Epoch[8] Batch [500]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.142447,	
2017-07-28 16:41:04,270 Epoch[8] Batch [510]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142468,	
2017-07-28 16:41:14,082 Epoch[8] Batch [520]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142364,	
2017-07-28 16:41:23,879 Epoch[8] Batch [530]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142652,	
2017-07-28 16:41:33,693 Epoch[8] Batch [540]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142916,	
2017-07-28 16:41:43,502 Epoch[8] Batch [550]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142935,	
2017-07-28 16:41:52,904 Epoch[8] Batch [560]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.142999,	
2017-07-28 16:42:02,721 Epoch[8] Batch [570]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.143218,	
2017-07-28 16:42:12,544 Epoch[8] Batch [580]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.143249,	
2017-07-28 16:42:22,344 Epoch[8] Batch [590]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.142978,	
2017-07-28 16:42:31,014 Epoch[8] Batch [600]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.143079,	
2017-07-28 16:42:40,488 Epoch[8] Batch [610]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.143465,	
2017-07-28 16:42:50,273 Epoch[8] Batch [620]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.143348,	
2017-07-28 16:43:00,074 Epoch[8] Batch [630]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.145204,	
2017-07-28 16:43:09,908 Epoch[8] Batch [640]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.145920,	
2017-07-28 16:43:19,714 Epoch[8] Batch [650]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.146354,	
2017-07-28 16:43:29,515 Epoch[8] Batch [660]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.146443,	
2017-07-28 16:43:39,333 Epoch[8] Batch [670]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.146652,	
2017-07-28 16:43:49,125 Epoch[8] Batch [680]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.147080,	
2017-07-28 16:43:58,945 Epoch[8] Batch [690]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.147369,	
2017-07-28 16:44:08,742 Epoch[8] Batch [700]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.147711,	
2017-07-28 16:44:18,545 Epoch[8] Batch [710]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.147667,	
2017-07-28 16:44:27,125 Epoch[8] Batch [720]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.148282,	
2017-07-28 16:44:32,940 Epoch[8] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.148451,	
2017-07-28 16:44:38,747 Epoch[8] Batch [740]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149182,	
2017-07-28 16:44:44,434 Epoch[8] Batch [750]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.149172,	
2017-07-28 16:44:50,266 Epoch[8] Batch [760]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.149139,	
2017-07-28 16:44:56,086 Epoch[8] Batch [770]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.148974,	
2017-07-28 16:45:01,919 Epoch[8] Batch [780]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.149088,	
2017-07-28 16:45:07,842 Epoch[8] Batch [790]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.149243,	
2017-07-28 16:45:13,534 Epoch[8] Batch [800]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.149120,	
2017-07-28 16:45:19,376 Epoch[8] Batch [810]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.149200,	
2017-07-28 16:45:25,213 Epoch[8] Batch [820]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.148969,	
2017-07-28 16:45:31,038 Epoch[8] Batch [830]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.149318,	
2017-07-28 16:45:36,846 Epoch[8] Batch [840]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149434,	
2017-07-28 16:45:42,682 Epoch[8] Batch [850]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.149293,	
2017-07-28 16:45:47,697 Epoch[8] Batch [860]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.149307,	
2017-07-28 16:45:53,767 Epoch[8] Batch [870]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.149093,	
2017-07-28 16:45:59,526 Epoch[8] Batch [880]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.149123,	
2017-07-28 16:46:05,403 Epoch[8] Batch [890]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.149192,	
2017-07-28 16:46:11,204 Epoch[8] Batch [900]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.149071,	
2017-07-28 16:46:16,996 Epoch[8] Batch [910]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.149048,	
2017-07-28 16:46:22,866 Epoch[8] Batch [920]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.149051,	
2017-07-28 16:46:28,693 Epoch[8] Batch [930]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.148844,	
2017-07-28 16:46:34,534 Epoch[8] Batch [940]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.148719,	
2017-07-28 16:46:40,319 Epoch[8] Batch [950]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.148611,	
2017-07-28 16:46:46,160 Epoch[8] Batch [960]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.148401,	
2017-07-28 16:46:52,024 Epoch[8] Batch [970]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.148431,	
2017-07-28 16:46:57,784 Epoch[8] Batch [980]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.148245,	
2017-07-28 16:47:03,624 Epoch[8] Batch [990]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.148076,	
2017-07-28 16:47:09,377 Epoch[8] Batch [1000]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.147980,	
2017-07-28 16:47:15,221 Epoch[8] Batch [1010]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.147931,	
2017-07-28 16:47:21,148 Epoch[8] Batch [1020]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.147827,	
2017-07-28 16:47:27,215 Epoch[8] Batch [1030]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.147776,	
2017-07-28 16:47:33,045 Epoch[8] Batch [1040]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.147776,	
2017-07-28 16:47:38,919 Epoch[8] Batch [1050]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.147640,	
2017-07-28 16:47:44,734 Epoch[8] Batch [1060]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.147595,	
2017-07-28 16:47:50,440 Epoch[8] Batch [1070]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.147494,	
2017-07-28 16:47:56,248 Epoch[8] Batch [1080]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.147531,	
2017-07-28 16:48:02,060 Epoch[8] Batch [1090]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.147415,	
2017-07-28 16:48:07,907 Epoch[8] Batch [1100]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.147360,	
2017-07-28 16:48:13,769 Epoch[8] Batch [1110]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.147191,	
2017-07-28 16:48:19,611 Epoch[8] Batch [1120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.147322,	
2017-07-28 16:48:25,492 Epoch[8] Batch [1130]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.147349,	
2017-07-28 16:48:31,478 Epoch[8] Batch [1140]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.147189,	
2017-07-28 16:48:37,257 Epoch[8] Batch [1150]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.147534,	
2017-07-28 16:48:43,245 Epoch[8] Batch [1160]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.147631,	
2017-07-28 16:48:49,102 Epoch[8] Batch [1170]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.147640,	
2017-07-28 16:48:54,821 Epoch[8] Batch [1180]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.147541,	
2017-07-28 16:49:01,135 Epoch[8] Batch [1190]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.147530,	
2017-07-28 16:49:06,839 Epoch[8] Batch [1200]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.147561,	
2017-07-28 16:49:12,657 Epoch[8] Batch [1210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.147488,	
2017-07-28 16:49:18,492 Epoch[8] Batch [1220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.147398,	
2017-07-28 16:49:24,359 Epoch[8] Batch [1230]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.147448,	
2017-07-28 16:49:30,168 Epoch[8] Batch [1240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.147501,	
2017-07-28 16:49:36,086 Epoch[8] Batch [1250]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.147441,	
2017-07-28 16:49:41,849 Epoch[8] Batch [1260]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.147287,	
2017-07-28 16:49:47,669 Epoch[8] Batch [1270]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.147214,	
2017-07-28 16:49:53,644 Epoch[8] Batch [1280]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.147968,	
2017-07-28 16:49:59,480 Epoch[8] Batch [1290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.147998,	
2017-07-28 16:50:05,315 Epoch[8] Batch [1300]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.148149,	
2017-07-28 16:50:11,154 Epoch[8] Batch [1310]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.148240,	
2017-07-28 16:50:17,530 Epoch[8] Batch [1320]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.148264,	
2017-07-28 16:50:23,342 Epoch[8] Batch [1330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.148218,	
2017-07-28 16:50:29,214 Epoch[8] Batch [1340]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.148095,	
2017-07-28 16:50:35,006 Epoch[8] Batch [1350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.148088,	
2017-07-28 16:50:40,898 Epoch[8] Batch [1360]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.148153,	
2017-07-28 16:50:46,725 Epoch[8] Batch [1370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.148154,	
2017-07-28 16:50:53,338 Epoch[8] Batch [1380]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.148172,	
2017-07-28 16:50:59,325 Epoch[8] Batch [1390]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.148261,	
2017-07-28 16:51:04,850 Epoch[8] Batch [1400]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.148285,	
2017-07-28 16:51:10,758 Epoch[8] Batch [1410]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.148275,	
2017-07-28 16:51:16,498 Epoch[8] Batch [1420]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.148260,	
2017-07-28 16:51:22,371 Epoch[8] Batch [1430]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.148192,	
2017-07-28 16:51:28,180 Epoch[8] Batch [1440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.148125,	
2017-07-28 16:51:34,019 Epoch[8] Batch [1450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.148108,	
2017-07-28 16:51:39,933 Epoch[8] Batch [1460]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.148005,	
2017-07-28 16:51:45,804 Epoch[8] Batch [1470]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.148025,	
2017-07-28 16:51:51,524 Epoch[8] Batch [1480]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.147981,	
2017-07-28 16:51:55,037 Epoch[8] Train-FCNLogLoss=0.147965
2017-07-28 16:51:55,037 Epoch[8] Time cost=1068.785
2017-07-28 16:51:56,297 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0009.params"
2017-07-28 16:52:00,111 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0009.states"
2017-07-28 16:52:06,875 Epoch[9] Batch [10]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.155606,	
2017-07-28 16:52:12,742 Epoch[9] Batch [20]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.150341,	
2017-07-28 16:52:18,532 Epoch[9] Batch [30]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.146666,	
2017-07-28 16:52:24,377 Epoch[9] Batch [40]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142959,	
2017-07-28 16:52:30,275 Epoch[9] Batch [50]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.143359,	
2017-07-28 16:52:36,133 Epoch[9] Batch [60]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.143390,	
2017-07-28 16:52:41,862 Epoch[9] Batch [70]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.143073,	
2017-07-28 16:52:47,715 Epoch[9] Batch [80]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.142868,	
2017-07-28 16:52:53,509 Epoch[9] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142713,	
2017-07-28 16:52:59,359 Epoch[9] Batch [100]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142509,	
2017-07-28 16:53:05,219 Epoch[9] Batch [110]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.141627,	
2017-07-28 16:53:10,977 Epoch[9] Batch [120]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.141965,	
2017-07-28 16:53:16,542 Epoch[9] Batch [130]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.140479,	
2017-07-28 16:53:23,218 Epoch[9] Batch [140]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.140121,	
2017-07-28 16:53:29,049 Epoch[9] Batch [150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.139621,	
2017-07-28 16:53:34,780 Epoch[9] Batch [160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.139490,	
2017-07-28 16:53:40,601 Epoch[9] Batch [170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140527,	
2017-07-28 16:53:46,434 Epoch[9] Batch [180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.140144,	
2017-07-28 16:53:52,273 Epoch[9] Batch [190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.139795,	
2017-07-28 16:53:58,098 Epoch[9] Batch [200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.139851,	
2017-07-28 16:54:03,922 Epoch[9] Batch [210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140454,	
2017-07-28 16:54:09,746 Epoch[9] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140396,	
2017-07-28 16:54:15,534 Epoch[9] Batch [230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.140109,	
2017-07-28 16:54:21,387 Epoch[9] Batch [240]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.141043,	
2017-07-28 16:54:27,197 Epoch[9] Batch [250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141164,	
2017-07-28 16:54:33,033 Epoch[9] Batch [260]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.140603,	
2017-07-28 16:54:38,906 Epoch[9] Batch [270]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.141034,	
2017-07-28 16:54:44,648 Epoch[9] Batch [280]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.140706,	
2017-07-28 16:54:50,524 Epoch[9] Batch [290]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.140426,	
2017-07-28 16:54:56,300 Epoch[9] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.139831,	
2017-07-28 16:55:02,172 Epoch[9] Batch [310]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.139486,	
2017-07-28 16:55:07,912 Epoch[9] Batch [320]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.139727,	
2017-07-28 16:55:13,710 Epoch[9] Batch [330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.140036,	
2017-07-28 16:55:19,588 Epoch[9] Batch [340]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.140705,	
2017-07-28 16:55:25,430 Epoch[9] Batch [350]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141443,	
2017-07-28 16:55:31,202 Epoch[9] Batch [360]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.141846,	
2017-07-28 16:55:37,034 Epoch[9] Batch [370]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141611,	
2017-07-28 16:55:42,863 Epoch[9] Batch [380]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.141326,	
2017-07-28 16:55:48,653 Epoch[9] Batch [390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.141482,	
2017-07-28 16:55:54,468 Epoch[9] Batch [400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142470,	
2017-07-28 16:56:00,283 Epoch[9] Batch [410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142264,	
2017-07-28 16:56:06,063 Epoch[9] Batch [420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.142343,	
2017-07-28 16:56:11,897 Epoch[9] Batch [430]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142338,	
2017-07-28 16:56:17,809 Epoch[9] Batch [440]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.142456,	
2017-07-28 16:56:23,505 Epoch[9] Batch [450]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.142717,	
2017-07-28 16:56:29,329 Epoch[9] Batch [460]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142633,	
2017-07-28 16:56:35,177 Epoch[9] Batch [470]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142108,	
2017-07-28 16:56:41,044 Epoch[9] Batch [480]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.142145,	
2017-07-28 16:56:46,846 Epoch[9] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142258,	
2017-07-28 16:56:52,629 Epoch[9] Batch [500]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.142600,	
2017-07-28 16:56:58,440 Epoch[9] Batch [510]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143063,	
2017-07-28 16:57:04,755 Epoch[9] Batch [520]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.143138,	
2017-07-28 16:57:10,921 Epoch[9] Batch [530]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.143262,	
2017-07-28 16:57:16,648 Epoch[9] Batch [540]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.143177,	
2017-07-28 16:57:22,468 Epoch[9] Batch [550]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143239,	
2017-07-28 16:57:28,284 Epoch[9] Batch [560]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143383,	
2017-07-28 16:57:34,143 Epoch[9] Batch [570]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.142968,	
2017-07-28 16:57:39,943 Epoch[9] Batch [580]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142906,	
2017-07-28 16:57:45,764 Epoch[9] Batch [590]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142795,	
2017-07-28 16:57:51,570 Epoch[9] Batch [600]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142522,	
2017-07-28 16:57:57,336 Epoch[9] Batch [610]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.142819,	
2017-07-28 16:58:03,169 Epoch[9] Batch [620]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142602,	
2017-07-28 16:58:09,067 Epoch[9] Batch [630]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.142768,	
2017-07-28 16:58:14,834 Epoch[9] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.142759,	
2017-07-28 16:58:20,658 Epoch[9] Batch [650]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142699,	
2017-07-28 16:58:26,487 Epoch[9] Batch [660]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142439,	
2017-07-28 16:58:32,302 Epoch[9] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142264,	
2017-07-28 16:58:38,103 Epoch[9] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142199,	
2017-07-28 16:58:43,942 Epoch[9] Batch [690]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142074,	
2017-07-28 16:58:49,778 Epoch[9] Batch [700]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142772,	
2017-07-28 16:58:55,579 Epoch[9] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143091,	
2017-07-28 16:59:01,399 Epoch[9] Batch [720]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142904,	
2017-07-28 16:59:07,267 Epoch[9] Batch [730]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.143015,	
2017-07-28 16:59:13,069 Epoch[9] Batch [740]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143161,	
2017-07-28 16:59:18,892 Epoch[9] Batch [750]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143432,	
2017-07-28 16:59:24,755 Epoch[9] Batch [760]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.143313,	
2017-07-28 16:59:30,616 Epoch[9] Batch [770]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.143305,	
2017-07-28 16:59:36,404 Epoch[9] Batch [780]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.143503,	
2017-07-28 16:59:42,261 Epoch[9] Batch [790]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.143732,	
2017-07-28 16:59:48,144 Epoch[9] Batch [800]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.143891,	
2017-07-28 16:59:53,971 Epoch[9] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.144022,	
2017-07-28 16:59:59,773 Epoch[9] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.144029,	
2017-07-28 17:00:05,586 Epoch[9] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143938,	
2017-07-28 17:00:11,429 Epoch[9] Batch [840]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.144009,	
2017-07-28 17:00:16,891 Epoch[9] Batch [850]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.143934,	
2017-07-28 17:00:22,769 Epoch[9] Batch [860]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.143899,	
2017-07-28 17:00:28,565 Epoch[9] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.144093,	
2017-07-28 17:00:34,508 Epoch[9] Batch [880]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.143911,	
2017-07-28 17:00:40,690 Epoch[9] Batch [890]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.143764,	
2017-07-28 17:00:46,527 Epoch[9] Batch [900]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.143793,	
2017-07-28 17:00:52,565 Epoch[9] Batch [910]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.143632,	
2017-07-28 17:00:58,507 Epoch[9] Batch [920]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.143690,	
2017-07-28 17:01:04,536 Epoch[9] Batch [930]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.143842,	
2017-07-28 17:01:14,968 Epoch[9] Batch [940]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.143620,	
2017-07-28 17:01:20,791 Epoch[9] Batch [950]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143619,	
2017-07-28 17:01:26,584 Epoch[9] Batch [960]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143463,	
2017-07-28 17:01:32,434 Epoch[9] Batch [970]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.143606,	
2017-07-28 17:01:38,534 Epoch[9] Batch [980]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.143669,	
2017-07-28 17:01:44,347 Epoch[9] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143583,	
2017-07-28 17:01:50,180 Epoch[9] Batch [1000]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.143539,	
2017-07-28 17:01:55,954 Epoch[9] Batch [1010]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.143604,	
2017-07-28 17:02:01,776 Epoch[9] Batch [1020]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143479,	
2017-07-28 17:02:07,602 Epoch[9] Batch [1030]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.143305,	
2017-07-28 17:02:13,472 Epoch[9] Batch [1040]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.143105,	
2017-07-28 17:02:19,323 Epoch[9] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.143241,	
2017-07-28 17:02:25,120 Epoch[9] Batch [1060]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143134,	
2017-07-28 17:02:30,982 Epoch[9] Batch [1070]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.143080,	
2017-07-28 17:02:36,795 Epoch[9] Batch [1080]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142907,	
2017-07-28 17:02:42,602 Epoch[9] Batch [1090]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142807,	
2017-07-28 17:02:48,389 Epoch[9] Batch [1100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.142573,	
2017-07-28 17:02:54,257 Epoch[9] Batch [1110]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.142502,	
2017-07-28 17:03:00,031 Epoch[9] Batch [1120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.142443,	
2017-07-28 17:03:05,882 Epoch[9] Batch [1130]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142362,	
2017-07-28 17:03:11,669 Epoch[9] Batch [1140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.142297,	
2017-07-28 17:03:17,531 Epoch[9] Batch [1150]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.142218,	
2017-07-28 17:03:23,358 Epoch[9] Batch [1160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142121,	
2017-07-28 17:03:29,152 Epoch[9] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142168,	
2017-07-28 17:03:35,000 Epoch[9] Batch [1180]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.142010,	
2017-07-28 17:03:40,836 Epoch[9] Batch [1190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141934,	
2017-07-28 17:03:46,656 Epoch[9] Batch [1200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141870,	
2017-07-28 17:03:52,476 Epoch[9] Batch [1210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.141901,	
2017-07-28 17:03:58,222 Epoch[9] Batch [1220]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.141847,	
2017-07-28 17:04:04,082 Epoch[9] Batch [1230]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.141928,	
2017-07-28 17:04:09,918 Epoch[9] Batch [1240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141900,	
2017-07-28 17:04:15,740 Epoch[9] Batch [1250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141846,	
2017-07-28 17:04:21,541 Epoch[9] Batch [1260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141918,	
2017-07-28 17:04:27,347 Epoch[9] Batch [1270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141816,	
2017-07-28 17:04:33,220 Epoch[9] Batch [1280]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.141827,	
2017-07-28 17:04:39,133 Epoch[9] Batch [1290]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.141715,	
2017-07-28 17:04:44,893 Epoch[9] Batch [1300]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.141701,	
2017-07-28 17:04:50,698 Epoch[9] Batch [1310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141717,	
2017-07-28 17:04:56,541 Epoch[9] Batch [1320]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141708,	
2017-07-28 17:05:02,493 Epoch[9] Batch [1330]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.141747,	
2017-07-28 17:05:08,474 Epoch[9] Batch [1340]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.141820,	
2017-07-28 17:05:14,276 Epoch[9] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.141931,	
2017-07-28 17:05:20,298 Epoch[9] Batch [1360]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.141979,	
2017-07-28 17:05:25,975 Epoch[9] Batch [1370]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.141903,	
2017-07-28 17:05:31,760 Epoch[9] Batch [1380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.141886,	
2017-07-28 17:05:37,558 Epoch[9] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142076,	
2017-07-28 17:05:43,400 Epoch[9] Batch [1400]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142208,	
2017-07-28 17:05:49,233 Epoch[9] Batch [1410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142080,	
2017-07-28 17:05:54,989 Epoch[9] Batch [1420]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.142209,	
2017-07-28 17:06:00,847 Epoch[9] Batch [1430]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.142280,	
2017-07-28 17:06:06,636 Epoch[9] Batch [1440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.142242,	
2017-07-28 17:06:12,447 Epoch[9] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.142285,	
2017-07-28 17:06:18,285 Epoch[9] Batch [1460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142410,	
2017-07-28 17:06:24,139 Epoch[9] Batch [1470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.142326,	
2017-07-28 17:06:29,964 Epoch[9] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.142301,	
2017-07-28 17:06:33,418 Epoch[9] Train-FCNLogLoss=0.142219
2017-07-28 17:06:33,419 Epoch[9] Time cost=873.307
2017-07-28 17:06:34,491 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0010.params"
2017-07-28 17:06:38,186 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0010.states"
2017-07-28 17:06:44,893 Epoch[10] Batch [10]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.165169,	
2017-07-28 17:06:50,677 Epoch[10] Batch [20]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.151437,	
2017-07-28 17:06:56,445 Epoch[10] Batch [30]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.147086,	
2017-07-28 17:07:02,180 Epoch[10] Batch [40]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.144056,	
2017-07-28 17:07:07,954 Epoch[10] Batch [50]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.143882,	
2017-07-28 17:07:13,776 Epoch[10] Batch [60]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141765,	
2017-07-28 17:07:19,586 Epoch[10] Batch [70]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.139913,	
2017-07-28 17:07:25,382 Epoch[10] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.137753,	
2017-07-28 17:07:31,190 Epoch[10] Batch [90]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.135657,	
2017-07-28 17:07:36,973 Epoch[10] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.133934,	
2017-07-28 17:07:42,911 Epoch[10] Batch [110]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.133420,	
2017-07-28 17:07:48,651 Epoch[10] Batch [120]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.132459,	
2017-07-28 17:07:54,396 Epoch[10] Batch [130]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.133619,	
2017-07-28 17:08:00,217 Epoch[10] Batch [140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135028,	
2017-07-28 17:08:06,054 Epoch[10] Batch [150]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.136374,	
2017-07-28 17:08:11,873 Epoch[10] Batch [160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136251,	
2017-07-28 17:08:17,752 Epoch[10] Batch [170]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.136961,	
2017-07-28 17:08:23,470 Epoch[10] Batch [180]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.137840,	
2017-07-28 17:08:29,287 Epoch[10] Batch [190]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.138548,	
2017-07-28 17:08:35,071 Epoch[10] Batch [200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.138592,	
2017-07-28 17:08:40,940 Epoch[10] Batch [210]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.140816,	
2017-07-28 17:08:46,761 Epoch[10] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141064,	
2017-07-28 17:08:52,501 Epoch[10] Batch [230]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.141734,	
2017-07-28 17:08:58,373 Epoch[10] Batch [240]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.142021,	
2017-07-28 17:09:04,153 Epoch[10] Batch [250]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.141895,	
2017-07-28 17:09:09,950 Epoch[10] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141968,	
2017-07-28 17:09:15,746 Epoch[10] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.142174,	
2017-07-28 17:09:21,596 Epoch[10] Batch [280]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.141635,	
2017-07-28 17:09:27,389 Epoch[10] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.141505,	
2017-07-28 17:09:33,160 Epoch[10] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.141391,	
2017-07-28 17:09:38,960 Epoch[10] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.140985,	
2017-07-28 17:09:44,748 Epoch[10] Batch [320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.141166,	
2017-07-28 17:09:50,636 Epoch[10] Batch [330]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.140706,	
2017-07-28 17:09:56,389 Epoch[10] Batch [340]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.140210,	
2017-07-28 17:10:02,175 Epoch[10] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.140530,	
2017-07-28 17:10:07,998 Epoch[10] Batch [360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140410,	
2017-07-28 17:10:13,821 Epoch[10] Batch [370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140758,	
2017-07-28 17:10:19,621 Epoch[10] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.140510,	
2017-07-28 17:10:25,440 Epoch[10] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140429,	
2017-07-28 17:10:31,228 Epoch[10] Batch [400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.140366,	
2017-07-28 17:10:37,052 Epoch[10] Batch [410]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.140573,	
2017-07-28 17:10:43,307 Epoch[10] Batch [420]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.140418,	
2017-07-28 17:10:49,408 Epoch[10] Batch [430]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.140602,	
2017-07-28 17:10:55,167 Epoch[10] Batch [440]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.140873,	
2017-07-28 17:11:00,987 Epoch[10] Batch [450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.141487,	
2017-07-28 17:11:06,886 Epoch[10] Batch [460]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.141528,	
2017-07-28 17:11:12,622 Epoch[10] Batch [470]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.141421,	
2017-07-28 17:11:18,422 Epoch[10] Batch [480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141615,	
2017-07-28 17:11:24,787 Epoch[10] Batch [490]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.141368,	
2017-07-28 17:11:30,582 Epoch[10] Batch [500]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.141390,	
2017-07-28 17:11:36,246 Epoch[10] Batch [510]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.140974,	
2017-07-28 17:11:42,051 Epoch[10] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.140772,	
2017-07-28 17:11:47,919 Epoch[10] Batch [530]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.140684,	
2017-07-28 17:11:53,732 Epoch[10] Batch [540]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.140194,	
2017-07-28 17:11:59,783 Epoch[10] Batch [550]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.140023,	
2017-07-28 17:12:05,611 Epoch[10] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.140051,	
2017-07-28 17:12:11,513 Epoch[10] Batch [570]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.139757,	
2017-07-28 17:12:17,313 Epoch[10] Batch [580]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.140049,	
2017-07-28 17:12:23,055 Epoch[10] Batch [590]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.139998,	
2017-07-28 17:12:28,870 Epoch[10] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.139689,	
2017-07-28 17:12:34,604 Epoch[10] Batch [610]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.139658,	
2017-07-28 17:12:40,378 Epoch[10] Batch [620]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.139676,	
2017-07-28 17:12:46,156 Epoch[10] Batch [630]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.139593,	
2017-07-28 17:12:52,050 Epoch[10] Batch [640]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.139628,	
2017-07-28 17:12:57,838 Epoch[10] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.139840,	
2017-07-28 17:13:03,696 Epoch[10] Batch [660]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.139961,	
2017-07-28 17:13:09,465 Epoch[10] Batch [670]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.139773,	
2017-07-28 17:13:15,188 Epoch[10] Batch [680]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.139654,	
2017-07-28 17:13:21,038 Epoch[10] Batch [690]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.139413,	
2017-07-28 17:13:26,827 Epoch[10] Batch [700]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.139295,	
2017-07-28 17:13:32,618 Epoch[10] Batch [710]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.138950,	
2017-07-28 17:13:38,422 Epoch[10] Batch [720]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.138924,	
2017-07-28 17:13:44,218 Epoch[10] Batch [730]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.138769,	
2017-07-28 17:13:50,026 Epoch[10] Batch [740]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.138574,	
2017-07-28 17:13:55,864 Epoch[10] Batch [750]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.138321,	
2017-07-28 17:14:01,655 Epoch[10] Batch [760]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.138281,	
2017-07-28 17:14:07,483 Epoch[10] Batch [770]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.137954,	
2017-07-28 17:14:13,238 Epoch[10] Batch [780]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.138138,	
2017-07-28 17:14:19,063 Epoch[10] Batch [790]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.138126,	
2017-07-28 17:14:24,885 Epoch[10] Batch [800]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.138211,	
2017-07-28 17:14:30,660 Epoch[10] Batch [810]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.138016,	
2017-07-28 17:14:36,476 Epoch[10] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.137911,	
2017-07-28 17:14:42,142 Epoch[10] Batch [830]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.137842,	
2017-07-28 17:14:47,510 Epoch[10] Batch [840]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.138003,	
2017-07-28 17:14:53,163 Epoch[10] Batch [850]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.137908,	
2017-07-28 17:14:59,000 Epoch[10] Batch [860]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.137901,	
2017-07-28 17:15:04,759 Epoch[10] Batch [870]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.137911,	
2017-07-28 17:15:10,650 Epoch[10] Batch [880]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.138008,	
2017-07-28 17:15:16,331 Epoch[10] Batch [890]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.137980,	
2017-07-28 17:15:22,074 Epoch[10] Batch [900]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.137972,	
2017-07-28 17:15:27,942 Epoch[10] Batch [910]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.137840,	
2017-07-28 17:15:33,701 Epoch[10] Batch [920]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.137831,	
2017-07-28 17:15:39,474 Epoch[10] Batch [930]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.137704,	
2017-07-28 17:15:45,284 Epoch[10] Batch [940]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.137549,	
2017-07-28 17:15:51,126 Epoch[10] Batch [950]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.137614,	
2017-07-28 17:15:56,911 Epoch[10] Batch [960]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.137596,	
2017-07-28 17:16:02,685 Epoch[10] Batch [970]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.137709,	
2017-07-28 17:16:08,543 Epoch[10] Batch [980]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.137588,	
2017-07-28 17:16:14,363 Epoch[10] Batch [990]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.137678,	
2017-07-28 17:16:20,144 Epoch[10] Batch [1000]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.137817,	
2017-07-28 17:16:25,972 Epoch[10] Batch [1010]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.137783,	
2017-07-28 17:16:31,907 Epoch[10] Batch [1020]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.137762,	
2017-07-28 17:16:37,728 Epoch[10] Batch [1030]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.137690,	
2017-07-28 17:16:43,576 Epoch[10] Batch [1040]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.137856,	
2017-07-28 17:16:49,265 Epoch[10] Batch [1050]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.137877,	
2017-07-28 17:16:55,076 Epoch[10] Batch [1060]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.137864,	
2017-07-28 17:17:01,048 Epoch[10] Batch [1070]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.137927,	
2017-07-28 17:17:07,228 Epoch[10] Batch [1080]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.137947,	
2017-07-28 17:17:13,974 Epoch[10] Batch [1090]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.137981,	
2017-07-28 17:17:19,665 Epoch[10] Batch [1100]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.138008,	
2017-07-28 17:17:25,479 Epoch[10] Batch [1110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.138148,	
2017-07-28 17:17:31,306 Epoch[10] Batch [1120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.138341,	
2017-07-28 17:17:37,095 Epoch[10] Batch [1130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.138318,	
2017-07-28 17:17:42,929 Epoch[10] Batch [1140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.138377,	
2017-07-28 17:17:48,773 Epoch[10] Batch [1150]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.138512,	
2017-07-28 17:17:54,603 Epoch[10] Batch [1160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.138490,	
2017-07-28 17:18:00,409 Epoch[10] Batch [1170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.138368,	
2017-07-28 17:18:06,211 Epoch[10] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.138343,	
2017-07-28 17:18:12,037 Epoch[10] Batch [1190]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.138292,	
2017-07-28 17:18:17,854 Epoch[10] Batch [1200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.138340,	
2017-07-28 17:18:23,697 Epoch[10] Batch [1210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.138400,	
2017-07-28 17:18:30,283 Epoch[10] Batch [1220]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.138591,	
2017-07-28 17:18:39,436 Epoch[10] Batch [1230]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.138568,	
2017-07-28 17:18:56,072 Epoch[10] Batch [1240]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.138596,	
2017-07-28 17:19:14,862 Epoch[10] Batch [1250]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.138623,	
2017-07-28 17:19:33,105 Epoch[10] Batch [1260]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.138702,	
2017-07-28 17:19:50,439 Epoch[10] Batch [1270]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.138720,	
2017-07-28 17:20:07,330 Epoch[10] Batch [1280]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.138675,	
2017-07-28 17:20:22,384 Epoch[10] Batch [1290]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.138604,	
2017-07-28 17:20:41,334 Epoch[10] Batch [1300]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.138637,	
2017-07-28 17:20:58,147 Epoch[10] Batch [1310]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.138640,	
2017-07-28 17:21:15,880 Epoch[10] Batch [1320]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.138666,	
2017-07-28 17:21:33,263 Epoch[10] Batch [1330]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.138519,	
2017-07-28 17:21:49,716 Epoch[10] Batch [1340]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.138548,	
2017-07-28 17:22:06,694 Epoch[10] Batch [1350]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.138376,	
2017-07-28 17:22:24,723 Epoch[10] Batch [1360]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.138272,	
2017-07-28 17:22:41,400 Epoch[10] Batch [1370]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.138378,	
2017-07-28 17:22:59,878 Epoch[10] Batch [1380]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.138372,	
2017-07-28 17:23:15,654 Epoch[10] Batch [1390]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.138290,	
2017-07-28 17:23:33,094 Epoch[10] Batch [1400]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.138318,	
2017-07-28 17:23:49,288 Epoch[10] Batch [1410]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.138296,	
2017-07-28 17:24:06,225 Epoch[10] Batch [1420]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.138233,	
2017-07-28 17:24:25,743 Epoch[10] Batch [1430]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.138321,	
2017-07-28 17:24:43,636 Epoch[10] Batch [1440]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.138263,	
2017-07-28 17:25:01,776 Epoch[10] Batch [1450]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.138315,	
2017-07-28 17:25:18,138 Epoch[10] Batch [1460]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.138358,	
2017-07-28 17:25:32,681 Epoch[10] Batch [1470]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.138289,	
2017-07-28 17:25:49,315 Epoch[10] Batch [1480]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.138295,	
2017-07-28 17:25:59,405 Epoch[10] Train-FCNLogLoss=0.138318
2017-07-28 17:25:59,405 Epoch[10] Time cost=1161.219
2017-07-28 17:26:03,254 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0011.params"
2017-07-28 17:26:24,689 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0011.states"
2017-07-28 17:26:44,052 Epoch[11] Batch [10]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.137894,	
2017-07-28 17:26:53,976 Epoch[11] Batch [20]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.134906,	
2017-07-28 17:27:00,351 Epoch[11] Batch [30]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.133627,	
2017-07-28 17:27:06,763 Epoch[11] Batch [40]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.136420,	
2017-07-28 17:27:12,918 Epoch[11] Batch [50]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.140715,	
2017-07-28 17:27:18,951 Epoch[11] Batch [60]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.137916,	
2017-07-28 17:27:24,981 Epoch[11] Batch [70]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.136264,	
2017-07-28 17:27:31,114 Epoch[11] Batch [80]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.135695,	
2017-07-28 17:27:37,230 Epoch[11] Batch [90]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.135773,	
2017-07-28 17:27:43,167 Epoch[11] Batch [100]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.134832,	
2017-07-28 17:27:49,251 Epoch[11] Batch [110]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.140889,	
2017-07-28 17:27:55,411 Epoch[11] Batch [120]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.143240,	
2017-07-28 17:28:01,516 Epoch[11] Batch [130]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.141993,	
2017-07-28 17:28:07,709 Epoch[11] Batch [140]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.140877,	
2017-07-28 17:28:14,058 Epoch[11] Batch [150]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.140537,	
2017-07-28 17:28:20,192 Epoch[11] Batch [160]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.140961,	
2017-07-28 17:28:26,375 Epoch[11] Batch [170]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.140026,	
2017-07-28 17:28:32,525 Epoch[11] Batch [180]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.139365,	
2017-07-28 17:28:38,397 Epoch[11] Batch [190]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.138283,	
2017-07-28 17:28:44,184 Epoch[11] Batch [200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.137563,	
2017-07-28 17:28:50,182 Epoch[11] Batch [210]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.137270,	
2017-07-28 17:28:56,129 Epoch[11] Batch [220]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.137453,	
2017-07-28 17:29:02,304 Epoch[11] Batch [230]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.136613,	
2017-07-28 17:29:08,523 Epoch[11] Batch [240]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.135586,	
2017-07-28 17:29:14,782 Epoch[11] Batch [250]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.135000,	
2017-07-28 17:29:21,201 Epoch[11] Batch [260]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.134897,	
2017-07-28 17:29:27,499 Epoch[11] Batch [270]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.134429,	
2017-07-28 17:29:33,932 Epoch[11] Batch [280]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.134337,	
2017-07-28 17:29:40,381 Epoch[11] Batch [290]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.134677,	
2017-07-28 17:29:46,916 Epoch[11] Batch [300]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.134067,	
2017-07-28 17:29:53,652 Epoch[11] Batch [310]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.133862,	
2017-07-28 17:30:00,356 Epoch[11] Batch [320]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.133419,	
2017-07-28 17:30:06,448 Epoch[11] Batch [330]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.133876,	
2017-07-28 17:30:12,717 Epoch[11] Batch [340]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.133929,	
2017-07-28 17:30:19,464 Epoch[11] Batch [350]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.134290,	
2017-07-28 17:30:26,003 Epoch[11] Batch [360]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.133992,	
2017-07-28 17:30:32,269 Epoch[11] Batch [370]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.133552,	
2017-07-28 17:30:38,148 Epoch[11] Batch [380]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.133525,	
2017-07-28 17:30:44,433 Epoch[11] Batch [390]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.133729,	
2017-07-28 17:30:50,460 Epoch[11] Batch [400]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.133800,	
2017-07-28 17:30:56,417 Epoch[11] Batch [410]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.134161,	
2017-07-28 17:31:02,533 Epoch[11] Batch [420]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.133873,	
2017-07-28 17:31:09,132 Epoch[11] Batch [430]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.133661,	
2017-07-28 17:31:15,696 Epoch[11] Batch [440]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.134083,	
2017-07-28 17:31:22,439 Epoch[11] Batch [450]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.133794,	
2017-07-28 17:31:28,484 Epoch[11] Batch [460]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.133962,	
2017-07-28 17:31:34,965 Epoch[11] Batch [470]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.134091,	
2017-07-28 17:31:41,271 Epoch[11] Batch [480]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.134442,	
2017-07-28 17:31:47,572 Epoch[11] Batch [490]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.134547,	
2017-07-28 17:31:54,123 Epoch[11] Batch [500]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.134414,	
2017-07-28 17:32:00,427 Epoch[11] Batch [510]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.134430,	
2017-07-28 17:32:06,732 Epoch[11] Batch [520]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.134140,	
2017-07-28 17:32:13,109 Epoch[11] Batch [530]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.134548,	
2017-07-28 17:32:19,360 Epoch[11] Batch [540]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.134778,	
2017-07-28 17:32:25,455 Epoch[11] Batch [550]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.134952,	
2017-07-28 17:32:31,683 Epoch[11] Batch [560]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.135021,	
2017-07-28 17:32:37,996 Epoch[11] Batch [570]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.134868,	
2017-07-28 17:32:43,978 Epoch[11] Batch [580]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.135493,	
2017-07-28 17:32:50,225 Epoch[11] Batch [590]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.135555,	
2017-07-28 17:32:56,202 Epoch[11] Batch [600]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.135360,	
2017-07-28 17:33:02,409 Epoch[11] Batch [610]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.135323,	
2017-07-28 17:33:08,848 Epoch[11] Batch [620]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.135414,	
2017-07-28 17:33:14,954 Epoch[11] Batch [630]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135215,	
2017-07-28 17:33:21,135 Epoch[11] Batch [640]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.135507,	
2017-07-28 17:33:27,326 Epoch[11] Batch [650]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.135822,	
2017-07-28 17:33:33,420 Epoch[11] Batch [660]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.135648,	
2017-07-28 17:33:39,705 Epoch[11] Batch [670]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.135884,	
2017-07-28 17:33:46,438 Epoch[11] Batch [680]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.135688,	
2017-07-28 17:33:52,549 Epoch[11] Batch [690]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135340,	
2017-07-28 17:33:58,764 Epoch[11] Batch [700]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.135190,	
2017-07-28 17:34:05,105 Epoch[11] Batch [710]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.135086,	
2017-07-28 17:34:11,431 Epoch[11] Batch [720]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.134932,	
2017-07-28 17:34:17,651 Epoch[11] Batch [730]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.134791,	
2017-07-28 17:34:24,565 Epoch[11] Batch [740]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.134696,	
2017-07-28 17:34:31,021 Epoch[11] Batch [750]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.134909,	
2017-07-28 17:34:37,175 Epoch[11] Batch [760]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.134783,	
2017-07-28 17:34:43,442 Epoch[11] Batch [770]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.134631,	
2017-07-28 17:34:49,626 Epoch[11] Batch [780]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.134452,	
2017-07-28 17:34:56,168 Epoch[11] Batch [790]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.134438,	
2017-07-28 17:35:02,884 Epoch[11] Batch [800]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.134307,	
2017-07-28 17:35:09,169 Epoch[11] Batch [810]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.134112,	
2017-07-28 17:35:15,721 Epoch[11] Batch [820]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.134019,	
2017-07-28 17:35:21,924 Epoch[11] Batch [830]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.133893,	
2017-07-28 17:35:28,241 Epoch[11] Batch [840]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.133669,	
2017-07-28 17:35:34,472 Epoch[11] Batch [850]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.133574,	
2017-07-28 17:35:40,859 Epoch[11] Batch [860]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.133507,	
2017-07-28 17:35:47,359 Epoch[11] Batch [870]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.133453,	
2017-07-28 17:35:53,902 Epoch[11] Batch [880]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.133747,	
2017-07-28 17:36:00,075 Epoch[11] Batch [890]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.133698,	
2017-07-28 17:36:06,449 Epoch[11] Batch [900]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.133577,	
2017-07-28 17:36:12,997 Epoch[11] Batch [910]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.133548,	
2017-07-28 17:36:19,647 Epoch[11] Batch [920]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.133361,	
2017-07-28 17:36:26,083 Epoch[11] Batch [930]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.133321,	
2017-07-28 17:36:32,244 Epoch[11] Batch [940]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.133333,	
2017-07-28 17:36:38,286 Epoch[11] Batch [950]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.133480,	
2017-07-28 17:36:44,590 Epoch[11] Batch [960]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.133473,	
2017-07-28 17:36:50,614 Epoch[11] Batch [970]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.133549,	
2017-07-28 17:36:56,646 Epoch[11] Batch [980]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.134478,	
2017-07-28 17:37:03,103 Epoch[11] Batch [990]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.135213,	
2017-07-28 17:37:15,348 Epoch[11] Batch [1000]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.136095,	
2017-07-28 17:37:31,837 Epoch[11] Batch [1010]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.136431,	
2017-07-28 17:37:48,457 Epoch[11] Batch [1020]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.136620,	
2017-07-28 17:38:06,059 Epoch[11] Batch [1030]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.136616,	
2017-07-28 17:38:21,847 Epoch[11] Batch [1040]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.136779,	
2017-07-28 17:38:38,504 Epoch[11] Batch [1050]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.137055,	
2017-07-28 17:38:53,438 Epoch[11] Batch [1060]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.137095,	
2017-07-28 17:39:11,277 Epoch[11] Batch [1070]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.136923,	
2017-07-28 17:39:26,396 Epoch[11] Batch [1080]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.137033,	
2017-07-28 17:39:42,596 Epoch[11] Batch [1090]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.137426,	
2017-07-28 17:39:58,756 Epoch[11] Batch [1100]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.137491,	
2017-07-28 17:40:14,918 Epoch[11] Batch [1110]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.137765,	
2017-07-28 17:40:31,723 Epoch[11] Batch [1120]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.137886,	
2017-07-28 17:40:48,062 Epoch[11] Batch [1130]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.137877,	
2017-07-28 17:41:02,009 Epoch[11] Batch [1140]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.138145,	
2017-07-28 17:41:20,309 Epoch[11] Batch [1150]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.138226,	
2017-07-28 17:41:37,735 Epoch[11] Batch [1160]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.138810,	
2017-07-28 17:41:51,412 Epoch[11] Batch [1170]	Speed: 2.92 samples/sec	Train-FCNLogLoss=0.138941,	
2017-07-28 17:42:05,157 Epoch[11] Batch [1180]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.138855,	
2017-07-28 17:42:17,603 Epoch[11] Batch [1190]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.138935,	
2017-07-28 17:42:32,813 Epoch[11] Batch [1200]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.138955,	
2017-07-28 17:42:48,986 Epoch[11] Batch [1210]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.138840,	
2017-07-28 17:43:06,902 Epoch[11] Batch [1220]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.138758,	
2017-07-28 17:43:22,891 Epoch[11] Batch [1230]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.138676,	
2017-07-28 17:43:39,067 Epoch[11] Batch [1240]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.138514,	
2017-07-28 17:43:55,791 Epoch[11] Batch [1250]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.138461,	
2017-07-28 17:44:11,602 Epoch[11] Batch [1260]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.138673,	
2017-07-28 17:44:30,628 Epoch[11] Batch [1270]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.138552,	
2017-07-28 17:44:45,801 Epoch[11] Batch [1280]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.138464,	
2017-07-28 17:45:01,046 Epoch[11] Batch [1290]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.138447,	
2017-07-28 17:45:19,532 Epoch[11] Batch [1300]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.138426,	
2017-07-28 17:45:35,072 Epoch[11] Batch [1310]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.138253,	
2017-07-28 17:45:51,003 Epoch[11] Batch [1320]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.138023,	
2017-07-28 17:46:08,269 Epoch[11] Batch [1330]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.137969,	
2017-07-28 17:46:22,258 Epoch[11] Batch [1340]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.137925,	
2017-07-28 17:46:36,934 Epoch[11] Batch [1350]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.137761,	
2017-07-28 17:46:52,310 Epoch[11] Batch [1360]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.137760,	
2017-07-28 17:47:10,435 Epoch[11] Batch [1370]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.137763,	
2017-07-28 17:47:27,192 Epoch[11] Batch [1380]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.137596,	
2017-07-28 17:47:42,067 Epoch[11] Batch [1390]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.137655,	
2017-07-28 17:47:55,482 Epoch[11] Batch [1400]	Speed: 2.98 samples/sec	Train-FCNLogLoss=0.137694,	
2017-07-28 17:48:09,309 Epoch[11] Batch [1410]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.137649,	
2017-07-28 17:48:25,750 Epoch[11] Batch [1420]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.137548,	
2017-07-28 17:48:42,055 Epoch[11] Batch [1430]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.137628,	
2017-07-28 17:48:57,804 Epoch[11] Batch [1440]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.137652,	
2017-07-28 17:49:14,466 Epoch[11] Batch [1450]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.137638,	
2017-07-28 17:49:31,063 Epoch[11] Batch [1460]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.137607,	
2017-07-28 17:49:47,519 Epoch[11] Batch [1470]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.137665,	
2017-07-28 17:50:04,638 Epoch[11] Batch [1480]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.137566,	
2017-07-28 17:50:14,214 Epoch[11] Train-FCNLogLoss=0.137491
2017-07-28 17:50:14,214 Epoch[11] Time cost=1429.525
2017-07-28 17:50:17,194 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0012.params"
2017-07-28 17:50:32,995 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0012.states"
2017-07-28 17:50:50,664 Epoch[12] Batch [10]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.130142,	
2017-07-28 17:51:05,771 Epoch[12] Batch [20]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.123516,	
2017-07-28 17:51:15,621 Epoch[12] Batch [30]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.123585,	
2017-07-28 17:51:22,166 Epoch[12] Batch [40]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.122268,	
2017-07-28 17:51:29,091 Epoch[12] Batch [50]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.121496,	
2017-07-28 17:51:35,545 Epoch[12] Batch [60]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.123388,	
2017-07-28 17:51:42,020 Epoch[12] Batch [70]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.128746,	
2017-07-28 17:51:48,534 Epoch[12] Batch [80]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.128280,	
2017-07-28 17:51:54,729 Epoch[12] Batch [90]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.128104,	
2017-07-28 17:52:01,895 Epoch[12] Batch [100]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.128813,	
2017-07-28 17:52:08,676 Epoch[12] Batch [110]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.129515,	
2017-07-28 17:52:15,184 Epoch[12] Batch [120]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.130491,	
2017-07-28 17:52:21,856 Epoch[12] Batch [130]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.130343,	
2017-07-28 17:52:28,447 Epoch[12] Batch [140]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.129874,	
2017-07-28 17:52:34,908 Epoch[12] Batch [150]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.130065,	
2017-07-28 17:52:41,652 Epoch[12] Batch [160]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.131205,	
2017-07-28 17:52:48,274 Epoch[12] Batch [170]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.130594,	
2017-07-28 17:52:54,448 Epoch[12] Batch [180]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.130339,	
2017-07-28 17:53:00,446 Epoch[12] Batch [190]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.129672,	
2017-07-28 17:53:06,962 Epoch[12] Batch [200]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.129806,	
2017-07-28 17:53:13,191 Epoch[12] Batch [210]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.129399,	
2017-07-28 17:53:19,792 Epoch[12] Batch [220]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.129543,	
2017-07-28 17:53:26,173 Epoch[12] Batch [230]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.129599,	
2017-07-28 17:53:32,506 Epoch[12] Batch [240]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.129043,	
2017-07-28 17:53:39,081 Epoch[12] Batch [250]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.130142,	
2017-07-28 17:53:45,871 Epoch[12] Batch [260]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.131117,	
2017-07-28 17:53:52,524 Epoch[12] Batch [270]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.130788,	
2017-07-28 17:53:59,269 Epoch[12] Batch [280]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.130861,	
2017-07-28 17:54:05,917 Epoch[12] Batch [290]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.131635,	
2017-07-28 17:54:12,321 Epoch[12] Batch [300]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.131674,	
2017-07-28 17:54:19,039 Epoch[12] Batch [310]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.131502,	
2017-07-28 17:54:25,769 Epoch[12] Batch [320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.131355,	
2017-07-28 17:54:32,868 Epoch[12] Batch [330]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.131602,	
2017-07-28 17:54:39,828 Epoch[12] Batch [340]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.131453,	
2017-07-28 17:54:47,011 Epoch[12] Batch [350]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.131657,	
2017-07-28 17:54:53,911 Epoch[12] Batch [360]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.131385,	
2017-07-28 17:55:00,928 Epoch[12] Batch [370]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.131894,	
2017-07-28 17:55:07,954 Epoch[12] Batch [380]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.131941,	
2017-07-28 17:55:14,524 Epoch[12] Batch [390]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.132102,	
2017-07-28 17:55:21,055 Epoch[12] Batch [400]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.132160,	
2017-07-28 17:55:27,875 Epoch[12] Batch [410]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.132246,	
2017-07-28 17:55:34,421 Epoch[12] Batch [420]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.132168,	
2017-07-28 17:55:40,899 Epoch[12] Batch [430]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.132024,	
2017-07-28 17:55:47,468 Epoch[12] Batch [440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.131944,	
2017-07-28 17:55:54,301 Epoch[12] Batch [450]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.131808,	
2017-07-28 17:56:00,781 Epoch[12] Batch [460]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.131889,	
2017-07-28 17:56:07,860 Epoch[12] Batch [470]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.131610,	
2017-07-28 17:56:14,772 Epoch[12] Batch [480]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.131659,	
2017-07-28 17:56:21,570 Epoch[12] Batch [490]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.131675,	
2017-07-28 17:56:28,459 Epoch[12] Batch [500]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.131692,	
2017-07-28 17:56:34,962 Epoch[12] Batch [510]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.131796,	
2017-07-28 17:56:41,611 Epoch[12] Batch [520]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.131502,	
2017-07-28 17:56:48,203 Epoch[12] Batch [530]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.131603,	
2017-07-28 17:56:54,559 Epoch[12] Batch [540]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.132074,	
2017-07-28 17:57:01,168 Epoch[12] Batch [550]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.132109,	
2017-07-28 17:57:07,244 Epoch[12] Batch [560]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.132015,	
2017-07-28 17:57:20,994 Epoch[12] Batch [570]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.132300,	
2017-07-28 17:57:37,928 Epoch[12] Batch [580]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.132385,	
2017-07-28 17:57:53,970 Epoch[12] Batch [590]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.132332,	
2017-07-28 17:58:12,003 Epoch[12] Batch [600]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.132243,	
2017-07-28 17:58:31,499 Epoch[12] Batch [610]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.132300,	
2017-07-28 17:58:47,479 Epoch[12] Batch [620]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.132205,	
2017-07-28 17:59:05,556 Epoch[12] Batch [630]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.132278,	
2017-07-28 17:59:23,433 Epoch[12] Batch [640]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.132179,	
2017-07-28 17:59:39,979 Epoch[12] Batch [650]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.131959,	
2017-07-28 17:59:58,390 Epoch[12] Batch [660]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.132031,	
2017-07-28 18:00:15,989 Epoch[12] Batch [670]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.132321,	
2017-07-28 18:00:28,811 Epoch[12] Batch [680]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.132525,	
2017-07-28 18:00:34,930 Epoch[12] Batch [690]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.132345,	
2017-07-28 18:00:40,853 Epoch[12] Batch [700]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.132034,	
2017-07-28 18:00:47,006 Epoch[12] Batch [710]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.132244,	
2017-07-28 18:00:53,239 Epoch[12] Batch [720]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.132299,	
2017-07-28 18:01:00,206 Epoch[12] Batch [730]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.132041,	
2017-07-28 18:01:06,240 Epoch[12] Batch [740]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.131932,	
2017-07-28 18:01:12,297 Epoch[12] Batch [750]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.132352,	
2017-07-28 18:01:18,330 Epoch[12] Batch [760]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.132753,	
2017-07-28 18:01:24,571 Epoch[12] Batch [770]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.132970,	
2017-07-28 18:01:30,714 Epoch[12] Batch [780]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.132888,	
2017-07-28 18:01:36,970 Epoch[12] Batch [790]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.132782,	
2017-07-28 18:01:42,891 Epoch[12] Batch [800]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.132628,	
2017-07-28 18:01:48,997 Epoch[12] Batch [810]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.132652,	
2017-07-28 18:01:55,236 Epoch[12] Batch [820]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.132359,	
2017-07-28 18:02:01,292 Epoch[12] Batch [830]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.132391,	
2017-07-28 18:02:07,159 Epoch[12] Batch [840]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.132641,	
2017-07-28 18:02:13,172 Epoch[12] Batch [850]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.132702,	
2017-07-28 18:02:19,434 Epoch[12] Batch [860]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.132727,	
2017-07-28 18:02:25,563 Epoch[12] Batch [870]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.132659,	
2017-07-28 18:02:31,471 Epoch[12] Batch [880]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.132782,	
2017-07-28 18:02:37,467 Epoch[12] Batch [890]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.132724,	
2017-07-28 18:02:43,579 Epoch[12] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.132635,	
2017-07-28 18:02:49,755 Epoch[12] Batch [910]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.132610,	
2017-07-28 18:02:55,502 Epoch[12] Batch [920]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.132597,	
2017-07-28 18:03:01,688 Epoch[12] Batch [930]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.132669,	
2017-07-28 18:03:08,179 Epoch[12] Batch [940]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.132761,	
2017-07-28 18:03:14,399 Epoch[12] Batch [950]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.132786,	
2017-07-28 18:03:20,717 Epoch[12] Batch [960]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.132576,	
2017-07-28 18:03:27,504 Epoch[12] Batch [970]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.132648,	
2017-07-28 18:03:33,311 Epoch[12] Batch [980]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.132864,	
2017-07-28 18:03:39,186 Epoch[12] Batch [990]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.132854,	
2017-07-28 18:03:45,276 Epoch[12] Batch [1000]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.132865,	
2017-07-28 18:03:51,156 Epoch[12] Batch [1010]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.132816,	
2017-07-28 18:03:57,030 Epoch[12] Batch [1020]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.132882,	
2017-07-28 18:04:02,868 Epoch[12] Batch [1030]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.132820,	
2017-07-28 18:04:09,012 Epoch[12] Batch [1040]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.132601,	
2017-07-28 18:04:15,894 Epoch[12] Batch [1050]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.132616,	
2017-07-28 18:04:22,160 Epoch[12] Batch [1060]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.132477,	
2017-07-28 18:04:28,363 Epoch[12] Batch [1070]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.132406,	
2017-07-28 18:04:34,771 Epoch[12] Batch [1080]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.132326,	
2017-07-28 18:04:40,972 Epoch[12] Batch [1090]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.132285,	
2017-07-28 18:04:47,183 Epoch[12] Batch [1100]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.132262,	
2017-07-28 18:04:54,020 Epoch[12] Batch [1110]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.132120,	
2017-07-28 18:05:00,295 Epoch[12] Batch [1120]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.132007,	
2017-07-28 18:05:06,780 Epoch[12] Batch [1130]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.131970,	
2017-07-28 18:05:13,412 Epoch[12] Batch [1140]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.131945,	
2017-07-28 18:05:19,548 Epoch[12] Batch [1150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.131983,	
2017-07-28 18:05:26,485 Epoch[12] Batch [1160]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.131883,	
2017-07-28 18:05:32,981 Epoch[12] Batch [1170]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.131785,	
2017-07-28 18:05:39,582 Epoch[12] Batch [1180]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.131773,	
2017-07-28 18:05:46,530 Epoch[12] Batch [1190]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.131693,	
2017-07-28 18:05:54,032 Epoch[12] Batch [1200]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.131727,	
2017-07-28 18:06:01,181 Epoch[12] Batch [1210]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.131964,	
2017-07-28 18:06:07,867 Epoch[12] Batch [1220]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.131853,	
2017-07-28 18:06:14,347 Epoch[12] Batch [1230]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.131910,	
2017-07-28 18:06:20,505 Epoch[12] Batch [1240]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.131804,	
2017-07-28 18:06:26,890 Epoch[12] Batch [1250]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.131681,	
2017-07-28 18:06:33,459 Epoch[12] Batch [1260]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.131694,	
2017-07-28 18:06:40,112 Epoch[12] Batch [1270]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.131656,	
2017-07-28 18:06:46,326 Epoch[12] Batch [1280]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.131741,	
2017-07-28 18:06:53,111 Epoch[12] Batch [1290]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.131649,	
2017-07-28 18:06:59,513 Epoch[12] Batch [1300]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.131513,	
2017-07-28 18:07:06,109 Epoch[12] Batch [1310]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.131538,	
2017-07-28 18:07:12,262 Epoch[12] Batch [1320]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.131492,	
2017-07-28 18:07:18,637 Epoch[12] Batch [1330]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.131582,	
2017-07-28 18:07:25,015 Epoch[12] Batch [1340]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.131539,	
2017-07-28 18:07:31,571 Epoch[12] Batch [1350]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.131482,	
2017-07-28 18:07:37,782 Epoch[12] Batch [1360]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.131460,	
2017-07-28 18:07:43,941 Epoch[12] Batch [1370]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.131422,	
2017-07-28 18:07:50,129 Epoch[12] Batch [1380]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.131517,	
2017-07-28 18:07:56,768 Epoch[12] Batch [1390]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.131449,	
2017-07-28 18:08:03,911 Epoch[12] Batch [1400]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.131325,	
2017-07-28 18:08:10,456 Epoch[12] Batch [1410]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.131446,	
2017-07-28 18:08:17,049 Epoch[12] Batch [1420]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.131589,	
2017-07-28 18:08:23,842 Epoch[12] Batch [1430]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.131579,	
2017-07-28 18:08:30,222 Epoch[12] Batch [1440]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.131555,	
2017-07-28 18:08:37,048 Epoch[12] Batch [1450]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.131607,	
2017-07-28 18:08:43,633 Epoch[12] Batch [1460]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.131587,	
2017-07-28 18:08:50,105 Epoch[12] Batch [1470]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.131705,	
2017-07-28 18:08:56,441 Epoch[12] Batch [1480]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.131705,	
2017-07-28 18:08:59,992 Epoch[12] Train-FCNLogLoss=0.131631
2017-07-28 18:08:59,993 Epoch[12] Time cost=1106.997
2017-07-28 18:09:01,000 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0013.params"
2017-07-28 18:09:04,791 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0013.states"
2017-07-28 18:09:11,744 Epoch[13] Batch [10]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106273,	
2017-07-28 18:09:18,333 Epoch[13] Batch [20]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.105762,	
2017-07-28 18:09:24,401 Epoch[13] Batch [30]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.119731,	
2017-07-28 18:09:30,583 Epoch[13] Batch [40]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.128702,	
2017-07-28 18:09:36,884 Epoch[13] Batch [50]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.127492,	
2017-07-28 18:09:43,057 Epoch[13] Batch [60]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.126471,	
2017-07-28 18:09:49,089 Epoch[13] Batch [70]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.126122,	
2017-07-28 18:09:55,355 Epoch[13] Batch [80]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.124329,	
2017-07-28 18:10:01,760 Epoch[13] Batch [90]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.123686,	
2017-07-28 18:10:07,916 Epoch[13] Batch [100]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.124538,	
2017-07-28 18:10:13,976 Epoch[13] Batch [110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.127206,	
2017-07-28 18:10:20,161 Epoch[13] Batch [120]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.127168,	
2017-07-28 18:10:26,156 Epoch[13] Batch [130]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.127208,	
2017-07-28 18:10:32,565 Epoch[13] Batch [140]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.126393,	
2017-07-28 18:10:38,740 Epoch[13] Batch [150]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.126271,	
2017-07-28 18:10:45,196 Epoch[13] Batch [160]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.126205,	
2017-07-28 18:10:51,791 Epoch[13] Batch [170]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.125968,	
2017-07-28 18:10:58,090 Epoch[13] Batch [180]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.126732,	
2017-07-28 18:11:04,214 Epoch[13] Batch [190]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.127700,	
2017-07-28 18:11:10,400 Epoch[13] Batch [200]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.127470,	
2017-07-28 18:11:16,603 Epoch[13] Batch [210]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.127867,	
2017-07-28 18:11:23,111 Epoch[13] Batch [220]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.128719,	
2017-07-28 18:11:29,729 Epoch[13] Batch [230]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.129939,	
2017-07-28 18:11:36,231 Epoch[13] Batch [240]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.130109,	
2017-07-28 18:11:42,661 Epoch[13] Batch [250]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.130012,	
2017-07-28 18:11:48,921 Epoch[13] Batch [260]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.130420,	
2017-07-28 18:11:54,938 Epoch[13] Batch [270]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.130505,	
2017-07-28 18:12:01,501 Epoch[13] Batch [280]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.131001,	
2017-07-28 18:12:07,463 Epoch[13] Batch [290]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.130785,	
2017-07-28 18:12:13,485 Epoch[13] Batch [300]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.130627,	
2017-07-28 18:12:19,720 Epoch[13] Batch [310]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.130416,	
2017-07-28 18:12:25,832 Epoch[13] Batch [320]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.130118,	
2017-07-28 18:12:32,067 Epoch[13] Batch [330]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.130016,	
2017-07-28 18:12:37,934 Epoch[13] Batch [340]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.129756,	
2017-07-28 18:12:44,108 Epoch[13] Batch [350]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.129314,	
2017-07-28 18:12:50,504 Epoch[13] Batch [360]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.130477,	
2017-07-28 18:12:56,605 Epoch[13] Batch [370]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.130329,	
2017-07-28 18:13:03,242 Epoch[13] Batch [380]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.130521,	
2017-07-28 18:13:09,389 Epoch[13] Batch [390]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.130434,	
2017-07-28 18:13:15,488 Epoch[13] Batch [400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.130523,	
2017-07-28 18:13:21,725 Epoch[13] Batch [410]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.130797,	
2017-07-28 18:13:28,594 Epoch[13] Batch [420]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.130685,	
2017-07-28 18:13:34,866 Epoch[13] Batch [430]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.130480,	
2017-07-28 18:13:41,266 Epoch[13] Batch [440]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.130692,	
2017-07-28 18:13:47,852 Epoch[13] Batch [450]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.130607,	
2017-07-28 18:13:53,938 Epoch[13] Batch [460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.130202,	
2017-07-28 18:14:00,115 Epoch[13] Batch [470]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.130275,	
2017-07-28 18:14:06,300 Epoch[13] Batch [480]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.130249,	
2017-07-28 18:14:12,837 Epoch[13] Batch [490]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.130059,	
2017-07-28 18:14:19,287 Epoch[13] Batch [500]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.130004,	
2017-07-28 18:14:25,926 Epoch[13] Batch [510]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.129637,	
2017-07-28 18:14:32,812 Epoch[13] Batch [520]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.129627,	
2017-07-28 18:14:39,851 Epoch[13] Batch [530]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.129356,	
2017-07-28 18:14:46,826 Epoch[13] Batch [540]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.129118,	
2017-07-28 18:14:53,918 Epoch[13] Batch [550]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.128980,	
2017-07-28 18:15:06,600 Epoch[13] Batch [560]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.128821,	
2017-07-28 18:15:14,981 Epoch[13] Batch [570]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.128574,	
2017-07-28 18:15:22,551 Epoch[13] Batch [580]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.128621,	
2017-07-28 18:15:30,203 Epoch[13] Batch [590]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.128375,	
2017-07-28 18:15:38,368 Epoch[13] Batch [600]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.128519,	
2017-07-28 18:15:46,639 Epoch[13] Batch [610]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.128528,	
2017-07-28 18:15:54,318 Epoch[13] Batch [620]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.128675,	
2017-07-28 18:16:02,976 Epoch[13] Batch [630]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.128692,	
2017-07-28 18:16:11,597 Epoch[13] Batch [640]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.128434,	
2017-07-28 18:16:20,287 Epoch[13] Batch [650]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.128449,	
2017-07-28 18:16:28,459 Epoch[13] Batch [660]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.128393,	
2017-07-28 18:16:35,970 Epoch[13] Batch [670]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.128287,	
2017-07-28 18:16:43,277 Epoch[13] Batch [680]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.128300,	
2017-07-28 18:16:51,156 Epoch[13] Batch [690]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.128273,	
2017-07-28 18:16:59,903 Epoch[13] Batch [700]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.128383,	
2017-07-28 18:17:07,249 Epoch[13] Batch [710]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.128315,	
2017-07-28 18:17:14,833 Epoch[13] Batch [720]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.128504,	
2017-07-28 18:17:22,318 Epoch[13] Batch [730]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.128457,	
2017-07-28 18:17:29,991 Epoch[13] Batch [740]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.128627,	
2017-07-28 18:17:36,616 Epoch[13] Batch [750]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.128743,	
2017-07-28 18:17:43,973 Epoch[13] Batch [760]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.128861,	
2017-07-28 18:17:51,708 Epoch[13] Batch [770]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.129055,	
2017-07-28 18:17:58,982 Epoch[13] Batch [780]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.128965,	
2017-07-28 18:18:05,979 Epoch[13] Batch [790]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.128873,	
2017-07-28 18:18:13,101 Epoch[13] Batch [800]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.128776,	
2017-07-28 18:18:19,525 Epoch[13] Batch [810]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.128571,	
2017-07-28 18:18:25,979 Epoch[13] Batch [820]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.128494,	
2017-07-28 18:18:32,872 Epoch[13] Batch [830]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.128550,	
2017-07-28 18:18:39,792 Epoch[13] Batch [840]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.128418,	
2017-07-28 18:18:46,830 Epoch[13] Batch [850]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.128208,	
2017-07-28 18:18:53,857 Epoch[13] Batch [860]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.128226,	
2017-07-28 18:19:00,554 Epoch[13] Batch [870]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.128122,	
2017-07-28 18:19:08,448 Epoch[13] Batch [880]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.128022,	
2017-07-28 18:19:15,644 Epoch[13] Batch [890]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.127866,	
2017-07-28 18:19:22,497 Epoch[13] Batch [900]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.127752,	
2017-07-28 18:19:29,497 Epoch[13] Batch [910]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.127794,	
2017-07-28 18:19:38,026 Epoch[13] Batch [920]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.127911,	
2017-07-28 18:19:46,254 Epoch[13] Batch [930]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.128029,	
2017-07-28 18:19:53,153 Epoch[13] Batch [940]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.127999,	
2017-07-28 18:20:00,100 Epoch[13] Batch [950]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.127994,	
2017-07-28 18:20:06,858 Epoch[13] Batch [960]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.128004,	
2017-07-28 18:20:13,452 Epoch[13] Batch [970]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.127978,	
2017-07-28 18:20:19,999 Epoch[13] Batch [980]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.127932,	
2017-07-28 18:20:26,142 Epoch[13] Batch [990]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.127886,	
2017-07-28 18:20:32,582 Epoch[13] Batch [1000]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.127870,	
2017-07-28 18:20:39,007 Epoch[13] Batch [1010]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.127719,	
2017-07-28 18:20:45,737 Epoch[13] Batch [1020]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.127707,	
2017-07-28 18:20:52,271 Epoch[13] Batch [1030]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.127764,	
2017-07-28 18:20:58,975 Epoch[13] Batch [1040]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.127720,	
2017-07-28 18:21:05,264 Epoch[13] Batch [1050]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.127747,	
2017-07-28 18:21:11,693 Epoch[13] Batch [1060]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.127731,	
2017-07-28 18:21:17,931 Epoch[13] Batch [1070]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.127706,	
2017-07-28 18:21:23,783 Epoch[13] Batch [1080]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.127802,	
2017-07-28 18:21:29,697 Epoch[13] Batch [1090]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.127768,	
2017-07-28 18:21:36,433 Epoch[13] Batch [1100]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.127737,	
2017-07-28 18:21:42,412 Epoch[13] Batch [1110]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.127729,	
2017-07-28 18:21:48,482 Epoch[13] Batch [1120]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.127732,	
2017-07-28 18:21:54,743 Epoch[13] Batch [1130]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.127880,	
2017-07-28 18:22:00,535 Epoch[13] Batch [1140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.128030,	
2017-07-28 18:22:06,641 Epoch[13] Batch [1150]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.127990,	
2017-07-28 18:22:12,850 Epoch[13] Batch [1160]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.127915,	
2017-07-28 18:22:20,535 Epoch[13] Batch [1170]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.127867,	
2017-07-28 18:22:28,777 Epoch[13] Batch [1180]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.127763,	
2017-07-28 18:22:34,539 Epoch[13] Batch [1190]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.127749,	
2017-07-28 18:22:40,431 Epoch[13] Batch [1200]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.127767,	
2017-07-28 18:22:46,313 Epoch[13] Batch [1210]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.127867,	
2017-07-28 18:22:52,140 Epoch[13] Batch [1220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.127922,	
2017-07-28 18:22:57,824 Epoch[13] Batch [1230]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.127823,	
2017-07-28 18:23:04,076 Epoch[13] Batch [1240]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.127833,	
2017-07-28 18:23:09,867 Epoch[13] Batch [1250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.127843,	
2017-07-28 18:23:15,696 Epoch[13] Batch [1260]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.127903,	
2017-07-28 18:23:21,660 Epoch[13] Batch [1270]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.127788,	
2017-07-28 18:23:28,170 Epoch[13] Batch [1280]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.127761,	
2017-07-28 18:23:33,955 Epoch[13] Batch [1290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.127752,	
2017-07-28 18:23:40,861 Epoch[13] Batch [1300]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.127704,	
2017-07-28 18:23:46,999 Epoch[13] Batch [1310]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.127546,	
2017-07-28 18:23:52,728 Epoch[13] Batch [1320]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.127508,	
2017-07-28 18:23:59,234 Epoch[13] Batch [1330]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.127387,	
2017-07-28 18:24:05,333 Epoch[13] Batch [1340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.127372,	
2017-07-28 18:24:11,818 Epoch[13] Batch [1350]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.127223,	
2017-07-28 18:24:17,529 Epoch[13] Batch [1360]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.127183,	
2017-07-28 18:24:23,393 Epoch[13] Batch [1370]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.127038,	
2017-07-28 18:24:29,493 Epoch[13] Batch [1380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.126992,	
2017-07-28 18:24:35,322 Epoch[13] Batch [1390]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.127015,	
2017-07-28 18:24:41,549 Epoch[13] Batch [1400]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.127114,	
2017-07-28 18:24:47,854 Epoch[13] Batch [1410]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.127107,	
2017-07-28 18:24:53,875 Epoch[13] Batch [1420]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.127082,	
2017-07-28 18:24:59,638 Epoch[13] Batch [1430]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.127139,	
2017-07-28 18:25:06,014 Epoch[13] Batch [1440]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.127129,	
2017-07-28 18:25:13,383 Epoch[13] Batch [1450]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.127202,	
2017-07-28 18:25:19,304 Epoch[13] Batch [1460]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.127188,	
2017-07-28 18:25:25,125 Epoch[13] Batch [1470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.127340,	
2017-07-28 18:25:30,984 Epoch[13] Batch [1480]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.127433,	
2017-07-28 18:25:34,360 Epoch[13] Train-FCNLogLoss=0.127478
2017-07-28 18:25:34,360 Epoch[13] Time cost=989.568
2017-07-28 18:25:35,526 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0014.params"
2017-07-28 18:25:39,127 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0014.states"
2017-07-28 18:25:46,160 Epoch[14] Batch [10]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.127465,	
2017-07-28 18:25:52,264 Epoch[14] Batch [20]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.139329,	
2017-07-28 18:25:58,386 Epoch[14] Batch [30]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.137042,	
2017-07-28 18:26:04,318 Epoch[14] Batch [40]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.133022,	
2017-07-28 18:26:11,822 Epoch[14] Batch [50]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.131788,	
2017-07-28 18:26:18,097 Epoch[14] Batch [60]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.131556,	
2017-07-28 18:26:27,099 Epoch[14] Batch [70]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.129647,	
2017-07-28 18:26:34,104 Epoch[14] Batch [80]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.130335,	
2017-07-28 18:26:39,855 Epoch[14] Batch [90]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.128450,	
2017-07-28 18:26:45,675 Epoch[14] Batch [100]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.127633,	
2017-07-28 18:26:51,465 Epoch[14] Batch [110]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.126905,	
2017-07-28 18:26:57,186 Epoch[14] Batch [120]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.127342,	
2017-07-28 18:27:02,944 Epoch[14] Batch [130]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.125549,	
2017-07-28 18:27:08,738 Epoch[14] Batch [140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125335,	
2017-07-28 18:27:14,321 Epoch[14] Batch [150]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.124073,	
2017-07-28 18:27:20,142 Epoch[14] Batch [160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124467,	
2017-07-28 18:27:26,523 Epoch[14] Batch [170]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.125151,	
2017-07-28 18:27:32,258 Epoch[14] Batch [180]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.125517,	
2017-07-28 18:27:38,105 Epoch[14] Batch [190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.125834,	
2017-07-28 18:27:43,902 Epoch[14] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125401,	
2017-07-28 18:27:49,642 Epoch[14] Batch [210]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.125217,	
2017-07-28 18:27:55,311 Epoch[14] Batch [220]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.125970,	
2017-07-28 18:28:00,987 Epoch[14] Batch [230]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.126173,	
2017-07-28 18:28:06,503 Epoch[14] Batch [240]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.126118,	
2017-07-28 18:28:12,325 Epoch[14] Batch [250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.125887,	
2017-07-28 18:28:18,131 Epoch[14] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125693,	
2017-07-28 18:28:23,927 Epoch[14] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125240,	
2017-07-28 18:28:29,738 Epoch[14] Batch [280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125559,	
2017-07-28 18:28:35,526 Epoch[14] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125525,	
2017-07-28 18:28:41,328 Epoch[14] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125677,	
2017-07-28 18:28:47,114 Epoch[14] Batch [310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125202,	
2017-07-28 18:28:52,925 Epoch[14] Batch [320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125205,	
2017-07-28 18:28:58,737 Epoch[14] Batch [330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124956,	
2017-07-28 18:29:04,490 Epoch[14] Batch [340]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.125306,	
2017-07-28 18:29:10,198 Epoch[14] Batch [350]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.125235,	
2017-07-28 18:29:15,964 Epoch[14] Batch [360]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.125137,	
2017-07-28 18:29:21,763 Epoch[14] Batch [370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125208,	
2017-07-28 18:29:27,562 Epoch[14] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124879,	
2017-07-28 18:29:33,346 Epoch[14] Batch [390]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.125030,	
2017-07-28 18:29:37,969 Epoch[14] Batch [400]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.124993,	
2017-07-28 18:29:43,201 Epoch[14] Batch [410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.124821,	
2017-07-28 18:29:48,999 Epoch[14] Batch [420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124817,	
2017-07-28 18:29:54,781 Epoch[14] Batch [430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124794,	
2017-07-28 18:30:00,565 Epoch[14] Batch [440]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.125174,	
2017-07-28 18:30:06,370 Epoch[14] Batch [450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125421,	
2017-07-28 18:30:12,200 Epoch[14] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.125673,	
2017-07-28 18:30:17,963 Epoch[14] Batch [470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.125346,	
2017-07-28 18:30:23,799 Epoch[14] Batch [480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.125187,	
2017-07-28 18:30:29,580 Epoch[14] Batch [490]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124960,	
2017-07-28 18:30:35,353 Epoch[14] Batch [500]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.125109,	
2017-07-28 18:30:41,135 Epoch[14] Batch [510]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.125291,	
2017-07-28 18:30:47,036 Epoch[14] Batch [520]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.125047,	
2017-07-28 18:30:52,822 Epoch[14] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125018,	
2017-07-28 18:30:58,617 Epoch[14] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125095,	
2017-07-28 18:31:04,433 Epoch[14] Batch [550]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125343,	
2017-07-28 18:31:10,260 Epoch[14] Batch [560]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.125259,	
2017-07-28 18:31:16,047 Epoch[14] Batch [570]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125115,	
2017-07-28 18:31:21,879 Epoch[14] Batch [580]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.125175,	
2017-07-28 18:31:27,667 Epoch[14] Batch [590]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125236,	
2017-07-28 18:31:33,497 Epoch[14] Batch [600]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.125241,	
2017-07-28 18:31:39,335 Epoch[14] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.125112,	
2017-07-28 18:31:45,052 Epoch[14] Batch [620]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.125293,	
2017-07-28 18:31:50,922 Epoch[14] Batch [630]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.125135,	
2017-07-28 18:31:56,689 Epoch[14] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.125206,	
2017-07-28 18:32:02,485 Epoch[14] Batch [650]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125221,	
2017-07-28 18:32:08,349 Epoch[14] Batch [660]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.124959,	
2017-07-28 18:32:14,100 Epoch[14] Batch [670]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.124655,	
2017-07-28 18:32:19,851 Epoch[14] Batch [680]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.124275,	
2017-07-28 18:32:25,530 Epoch[14] Batch [690]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.123963,	
2017-07-28 18:32:31,352 Epoch[14] Batch [700]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124023,	
2017-07-28 18:32:37,043 Epoch[14] Batch [710]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.123968,	
2017-07-28 18:32:42,810 Epoch[14] Batch [720]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.123918,	
2017-07-28 18:32:48,689 Epoch[14] Batch [730]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.124005,	
2017-07-28 18:32:54,434 Epoch[14] Batch [740]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.124004,	
2017-07-28 18:33:00,215 Epoch[14] Batch [750]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124042,	
2017-07-28 18:33:06,084 Epoch[14] Batch [760]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.124198,	
2017-07-28 18:33:11,853 Epoch[14] Batch [770]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.124038,	
2017-07-28 18:33:17,714 Epoch[14] Batch [780]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.124092,	
2017-07-28 18:33:23,455 Epoch[14] Batch [790]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.124055,	
2017-07-28 18:33:29,278 Epoch[14] Batch [800]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124086,	
2017-07-28 18:33:35,105 Epoch[14] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.124484,	
2017-07-28 18:33:40,905 Epoch[14] Batch [820]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124533,	
2017-07-28 18:33:46,686 Epoch[14] Batch [830]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124699,	
2017-07-28 18:33:52,446 Epoch[14] Batch [840]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.124926,	
2017-07-28 18:33:58,267 Epoch[14] Batch [850]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124838,	
2017-07-28 18:34:04,057 Epoch[14] Batch [860]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124735,	
2017-07-28 18:34:09,851 Epoch[14] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124780,	
2017-07-28 18:34:15,634 Epoch[14] Batch [880]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124700,	
2017-07-28 18:34:21,458 Epoch[14] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124714,	
2017-07-28 18:34:27,262 Epoch[14] Batch [900]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124793,	
2017-07-28 18:34:33,104 Epoch[14] Batch [910]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.124898,	
2017-07-28 18:34:38,870 Epoch[14] Batch [920]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.124737,	
2017-07-28 18:34:44,655 Epoch[14] Batch [930]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124600,	
2017-07-28 18:34:50,472 Epoch[14] Batch [940]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124560,	
2017-07-28 18:34:56,273 Epoch[14] Batch [950]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124566,	
2017-07-28 18:35:02,085 Epoch[14] Batch [960]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124617,	
2017-07-28 18:35:07,947 Epoch[14] Batch [970]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.124680,	
2017-07-28 18:35:13,675 Epoch[14] Batch [980]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.124814,	
2017-07-28 18:35:19,512 Epoch[14] Batch [990]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.124861,	
2017-07-28 18:35:25,280 Epoch[14] Batch [1000]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.124812,	
2017-07-28 18:35:31,168 Epoch[14] Batch [1010]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.124944,	
2017-07-28 18:35:36,855 Epoch[14] Batch [1020]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.124882,	
2017-07-28 18:35:42,782 Epoch[14] Batch [1030]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.124872,	
2017-07-28 18:35:48,438 Epoch[14] Batch [1040]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.124643,	
2017-07-28 18:35:54,258 Epoch[14] Batch [1050]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124636,	
2017-07-28 18:36:00,065 Epoch[14] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124513,	
2017-07-28 18:36:05,870 Epoch[14] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124496,	
2017-07-28 18:36:11,731 Epoch[14] Batch [1080]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.124496,	
2017-07-28 18:36:17,531 Epoch[14] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124434,	
2017-07-28 18:36:23,277 Epoch[14] Batch [1100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.124503,	
2017-07-28 18:36:29,103 Epoch[14] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124525,	
2017-07-28 18:36:34,911 Epoch[14] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124430,	
2017-07-28 18:36:40,716 Epoch[14] Batch [1130]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124430,	
2017-07-28 18:36:46,509 Epoch[14] Batch [1140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124362,	
2017-07-28 18:36:52,307 Epoch[14] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124256,	
2017-07-28 18:36:57,910 Epoch[14] Batch [1160]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.124323,	
2017-07-28 18:37:03,708 Epoch[14] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124377,	
2017-07-28 18:37:09,422 Epoch[14] Batch [1180]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.124368,	
2017-07-28 18:37:15,180 Epoch[14] Batch [1190]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.124469,	
2017-07-28 18:37:20,950 Epoch[14] Batch [1200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.124753,	
2017-07-28 18:37:26,748 Epoch[14] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124697,	
2017-07-28 18:37:32,606 Epoch[14] Batch [1220]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.124767,	
2017-07-28 18:37:38,317 Epoch[14] Batch [1230]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.124770,	
2017-07-28 18:37:44,138 Epoch[14] Batch [1240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124691,	
2017-07-28 18:37:49,857 Epoch[14] Batch [1250]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.124678,	
2017-07-28 18:37:55,722 Epoch[14] Batch [1260]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.124757,	
2017-07-28 18:38:01,522 Epoch[14] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124727,	
2017-07-28 18:38:07,348 Epoch[14] Batch [1280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124797,	
2017-07-28 18:38:13,148 Epoch[14] Batch [1290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124873,	
2017-07-28 18:38:18,959 Epoch[14] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124974,	
2017-07-28 18:38:24,767 Epoch[14] Batch [1310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124971,	
2017-07-28 18:38:30,535 Epoch[14] Batch [1320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.124939,	
2017-07-28 18:38:36,325 Epoch[14] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124943,	
2017-07-28 18:38:42,137 Epoch[14] Batch [1340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124912,	
2017-07-28 18:38:47,931 Epoch[14] Batch [1350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124936,	
2017-07-28 18:38:53,767 Epoch[14] Batch [1360]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.124928,	
2017-07-28 18:38:59,566 Epoch[14] Batch [1370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124866,	
2017-07-28 18:39:05,365 Epoch[14] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124865,	
2017-07-28 18:39:11,202 Epoch[14] Batch [1390]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.124889,	
2017-07-28 18:39:17,003 Epoch[14] Batch [1400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124757,	
2017-07-28 18:39:22,795 Epoch[14] Batch [1410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124686,	
2017-07-28 18:39:28,589 Epoch[14] Batch [1420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124595,	
2017-07-28 18:39:34,230 Epoch[14] Batch [1430]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.124572,	
2017-07-28 18:39:40,019 Epoch[14] Batch [1440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124691,	
2017-07-28 18:39:45,792 Epoch[14] Batch [1450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.124823,	
2017-07-28 18:39:51,589 Epoch[14] Batch [1460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124876,	
2017-07-28 18:39:57,408 Epoch[14] Batch [1470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.125010,	
2017-07-28 18:40:03,188 Epoch[14] Batch [1480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.125036,	
2017-07-28 18:40:06,688 Epoch[14] Train-FCNLogLoss=0.124958
2017-07-28 18:40:06,688 Epoch[14] Time cost=867.561
2017-07-28 18:40:07,785 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0015.params"
2017-07-28 18:40:11,390 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0015.states"
2017-07-28 18:40:18,023 Epoch[15] Batch [10]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.108274,	
2017-07-28 18:40:23,817 Epoch[15] Batch [20]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114756,	
2017-07-28 18:40:29,624 Epoch[15] Batch [30]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114346,	
2017-07-28 18:40:35,423 Epoch[15] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116210,	
2017-07-28 18:40:41,235 Epoch[15] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117994,	
2017-07-28 18:40:47,054 Epoch[15] Batch [60]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119846,	
2017-07-28 18:40:52,733 Epoch[15] Batch [70]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.119205,	
2017-07-28 18:40:58,570 Epoch[15] Batch [80]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118632,	
2017-07-28 18:41:04,428 Epoch[15] Batch [90]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.118486,	
2017-07-28 18:41:10,270 Epoch[15] Batch [100]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118270,	
2017-07-28 18:41:15,918 Epoch[15] Batch [110]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.118462,	
2017-07-28 18:41:21,630 Epoch[15] Batch [120]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.118198,	
2017-07-28 18:41:27,476 Epoch[15] Batch [130]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.118718,	
2017-07-28 18:41:33,275 Epoch[15] Batch [140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119203,	
2017-07-28 18:41:39,114 Epoch[15] Batch [150]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118569,	
2017-07-28 18:41:44,909 Epoch[15] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118490,	
2017-07-28 18:41:50,692 Epoch[15] Batch [170]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.119075,	
2017-07-28 18:41:56,463 Epoch[15] Batch [180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119144,	
2017-07-28 18:42:02,295 Epoch[15] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.119901,	
2017-07-28 18:42:08,041 Epoch[15] Batch [200]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.121279,	
2017-07-28 18:42:13,874 Epoch[15] Batch [210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121500,	
2017-07-28 18:42:19,727 Epoch[15] Batch [220]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121086,	
2017-07-28 18:42:25,516 Epoch[15] Batch [230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123438,	
2017-07-28 18:42:31,231 Epoch[15] Batch [240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.123597,	
2017-07-28 18:42:37,142 Epoch[15] Batch [250]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.122930,	
2017-07-28 18:42:42,918 Epoch[15] Batch [260]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.122895,	
2017-07-28 18:42:48,714 Epoch[15] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122558,	
2017-07-28 18:42:54,513 Epoch[15] Batch [280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123194,	
2017-07-28 18:43:00,337 Epoch[15] Batch [290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122853,	
2017-07-28 18:43:06,079 Epoch[15] Batch [300]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.122946,	
2017-07-28 18:43:11,883 Epoch[15] Batch [310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.123012,	
2017-07-28 18:43:17,664 Epoch[15] Batch [320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.123016,	
2017-07-28 18:43:23,474 Epoch[15] Batch [330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122939,	
2017-07-28 18:43:29,280 Epoch[15] Batch [340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122774,	
2017-07-28 18:43:35,077 Epoch[15] Batch [350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123015,	
2017-07-28 18:43:40,838 Epoch[15] Batch [360]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122660,	
2017-07-28 18:43:46,648 Epoch[15] Batch [370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122697,	
2017-07-28 18:43:52,483 Epoch[15] Batch [380]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122526,	
2017-07-28 18:43:58,330 Epoch[15] Batch [390]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.123474,	
2017-07-28 18:44:03,644 Epoch[15] Batch [400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123698,	
2017-07-28 18:44:09,095 Epoch[15] Batch [410]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.123617,	
2017-07-28 18:44:14,745 Epoch[15] Batch [420]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.123905,	
2017-07-28 18:44:20,560 Epoch[15] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123670,	
2017-07-28 18:44:26,346 Epoch[15] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124550,	
2017-07-28 18:44:32,155 Epoch[15] Batch [450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124675,	
2017-07-28 18:44:38,258 Epoch[15] Batch [460]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.124878,	
2017-07-28 18:44:44,160 Epoch[15] Batch [470]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.124620,	
2017-07-28 18:44:49,941 Epoch[15] Batch [480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124957,	
2017-07-28 18:44:55,677 Epoch[15] Batch [490]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.124950,	
2017-07-28 18:45:01,501 Epoch[15] Batch [500]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124872,	
2017-07-28 18:45:07,293 Epoch[15] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124992,	
2017-07-28 18:45:13,119 Epoch[15] Batch [520]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124569,	
2017-07-28 18:45:18,919 Epoch[15] Batch [530]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124302,	
2017-07-28 18:45:24,716 Epoch[15] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124109,	
2017-07-28 18:45:30,521 Epoch[15] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124098,	
2017-07-28 18:45:36,267 Epoch[15] Batch [560]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.124165,	
2017-07-28 18:45:42,072 Epoch[15] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124196,	
2017-07-28 18:45:47,897 Epoch[15] Batch [580]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124173,	
2017-07-28 18:45:53,698 Epoch[15] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124161,	
2017-07-28 18:45:59,498 Epoch[15] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124195,	
2017-07-28 18:46:05,285 Epoch[15] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124183,	
2017-07-28 18:46:11,030 Epoch[15] Batch [620]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.123875,	
2017-07-28 18:46:16,895 Epoch[15] Batch [630]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.123750,	
2017-07-28 18:46:22,682 Epoch[15] Batch [640]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123738,	
2017-07-28 18:46:28,748 Epoch[15] Batch [650]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.123719,	
2017-07-28 18:46:34,488 Epoch[15] Batch [660]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.123795,	
2017-07-28 18:46:40,214 Epoch[15] Batch [670]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.123726,	
2017-07-28 18:46:45,888 Epoch[15] Batch [680]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.123616,	
2017-07-28 18:46:51,730 Epoch[15] Batch [690]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123747,	
2017-07-28 18:46:57,569 Epoch[15] Batch [700]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123795,	
2017-07-28 18:47:03,349 Epoch[15] Batch [710]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.123709,	
2017-07-28 18:47:09,144 Epoch[15] Batch [720]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123621,	
2017-07-28 18:47:14,982 Epoch[15] Batch [730]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123791,	
2017-07-28 18:47:20,741 Epoch[15] Batch [740]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.123936,	
2017-07-28 18:47:26,592 Epoch[15] Batch [750]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.123821,	
2017-07-28 18:47:32,390 Epoch[15] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124101,	
2017-07-28 18:47:38,189 Epoch[15] Batch [770]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123986,	
2017-07-28 18:47:44,036 Epoch[15] Batch [780]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.124068,	
2017-07-28 18:47:49,840 Epoch[15] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124025,	
2017-07-28 18:47:55,618 Epoch[15] Batch [800]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.123734,	
2017-07-28 18:48:01,458 Epoch[15] Batch [810]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123616,	
2017-07-28 18:48:07,241 Epoch[15] Batch [820]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.123621,	
2017-07-28 18:48:13,066 Epoch[15] Batch [830]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.123701,	
2017-07-28 18:48:18,838 Epoch[15] Batch [840]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.123708,	
2017-07-28 18:48:24,654 Epoch[15] Batch [850]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123598,	
2017-07-28 18:48:30,478 Epoch[15] Batch [860]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.123540,	
2017-07-28 18:48:36,267 Epoch[15] Batch [870]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123716,	
2017-07-28 18:48:42,096 Epoch[15] Batch [880]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123735,	
2017-07-28 18:48:47,960 Epoch[15] Batch [890]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.123532,	
2017-07-28 18:48:53,714 Epoch[15] Batch [900]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.123372,	
2017-07-28 18:48:59,553 Epoch[15] Batch [910]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123349,	
2017-07-28 18:49:05,357 Epoch[15] Batch [920]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.123242,	
2017-07-28 18:49:11,205 Epoch[15] Batch [930]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.123152,	
2017-07-28 18:49:16,933 Epoch[15] Batch [940]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.123017,	
2017-07-28 18:49:22,513 Epoch[15] Batch [950]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.122951,	
2017-07-28 18:49:28,261 Epoch[15] Batch [960]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.122811,	
2017-07-28 18:49:34,137 Epoch[15] Batch [970]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.122837,	
2017-07-28 18:49:40,025 Epoch[15] Batch [980]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.122737,	
2017-07-28 18:49:45,787 Epoch[15] Batch [990]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122691,	
2017-07-28 18:49:51,542 Epoch[15] Batch [1000]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.122594,	
2017-07-28 18:49:57,345 Epoch[15] Batch [1010]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122470,	
2017-07-28 18:50:03,150 Epoch[15] Batch [1020]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122583,	
2017-07-28 18:50:08,938 Epoch[15] Batch [1030]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.122445,	
2017-07-28 18:50:14,732 Epoch[15] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122355,	
2017-07-28 18:50:20,536 Epoch[15] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122239,	
2017-07-28 18:50:26,367 Epoch[15] Batch [1060]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122321,	
2017-07-28 18:50:32,131 Epoch[15] Batch [1070]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122285,	
2017-07-28 18:50:37,952 Epoch[15] Batch [1080]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122294,	
2017-07-28 18:50:43,752 Epoch[15] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122186,	
2017-07-28 18:50:49,561 Epoch[15] Batch [1100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122116,	
2017-07-28 18:50:55,391 Epoch[15] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122037,	
2017-07-28 18:51:01,239 Epoch[15] Batch [1120]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.122021,	
2017-07-28 18:51:07,023 Epoch[15] Batch [1130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121964,	
2017-07-28 18:51:12,776 Epoch[15] Batch [1140]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121843,	
2017-07-28 18:51:18,631 Epoch[15] Batch [1150]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121824,	
2017-07-28 18:51:24,455 Epoch[15] Batch [1160]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121806,	
2017-07-28 18:51:30,229 Epoch[15] Batch [1170]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121789,	
2017-07-28 18:51:36,059 Epoch[15] Batch [1180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121948,	
2017-07-28 18:51:41,815 Epoch[15] Batch [1190]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121962,	
2017-07-28 18:51:47,679 Epoch[15] Batch [1200]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.122100,	
2017-07-28 18:51:53,436 Epoch[15] Batch [1210]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.122055,	
2017-07-28 18:51:59,269 Epoch[15] Batch [1220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122059,	
2017-07-28 18:52:05,066 Epoch[15] Batch [1230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121919,	
2017-07-28 18:52:10,839 Epoch[15] Batch [1240]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121963,	
2017-07-28 18:52:16,656 Epoch[15] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123195,	
2017-07-28 18:52:22,485 Epoch[15] Batch [1260]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123711,	
2017-07-28 18:52:28,374 Epoch[15] Batch [1270]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.124188,	
2017-07-28 18:52:34,201 Epoch[15] Batch [1280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.124462,	
2017-07-28 18:52:39,917 Epoch[15] Batch [1290]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.124700,	
2017-07-28 18:52:45,726 Epoch[15] Batch [1300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124918,	
2017-07-28 18:52:51,627 Epoch[15] Batch [1310]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.125011,	
2017-07-28 18:52:57,285 Epoch[15] Batch [1320]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.125067,	
2017-07-28 18:53:03,082 Epoch[15] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125171,	
2017-07-28 18:53:08,942 Epoch[15] Batch [1340]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.125321,	
2017-07-28 18:53:14,704 Epoch[15] Batch [1350]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.125333,	
2017-07-28 18:53:20,499 Epoch[15] Batch [1360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125299,	
2017-07-28 18:53:26,329 Epoch[15] Batch [1370]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.125365,	
2017-07-28 18:53:32,185 Epoch[15] Batch [1380]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.125372,	
2017-07-28 18:53:37,960 Epoch[15] Batch [1390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.125321,	
2017-07-28 18:53:43,753 Epoch[15] Batch [1400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125216,	
2017-07-28 18:53:49,504 Epoch[15] Batch [1410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.125167,	
2017-07-28 18:53:55,321 Epoch[15] Batch [1420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.125205,	
2017-07-28 18:54:01,117 Epoch[15] Batch [1430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.125252,	
2017-07-28 18:54:06,985 Epoch[15] Batch [1440]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.125401,	
2017-07-28 18:54:12,739 Epoch[15] Batch [1450]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.125314,	
2017-07-28 18:54:18,565 Epoch[15] Batch [1460]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.125455,	
2017-07-28 18:54:24,323 Epoch[15] Batch [1470]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.125690,	
2017-07-28 18:54:30,128 Epoch[15] Batch [1480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125722,	
2017-07-28 18:54:33,585 Epoch[15] Train-FCNLogLoss=0.125749
2017-07-28 18:54:33,585 Epoch[15] Time cost=862.195
2017-07-28 18:54:34,657 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0016.params"
2017-07-28 18:54:38,469 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0016.states"
2017-07-28 18:54:45,215 Epoch[16] Batch [10]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.150234,	
2017-07-28 18:54:51,169 Epoch[16] Batch [20]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.138840,	
2017-07-28 18:54:56,857 Epoch[16] Batch [30]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.129153,	
2017-07-28 18:55:02,660 Epoch[16] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.124336,	
2017-07-28 18:55:08,387 Epoch[16] Batch [50]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.122430,	
2017-07-28 18:55:14,224 Epoch[16] Batch [60]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.121746,	
2017-07-28 18:55:20,039 Epoch[16] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120543,	
2017-07-28 18:55:25,865 Epoch[16] Batch [80]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122875,	
2017-07-28 18:55:31,662 Epoch[16] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123658,	
2017-07-28 18:55:37,536 Epoch[16] Batch [100]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.123769,	
2017-07-28 18:55:43,287 Epoch[16] Batch [110]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.123281,	
2017-07-28 18:55:49,086 Epoch[16] Batch [120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124745,	
2017-07-28 18:55:54,879 Epoch[16] Batch [130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123658,	
2017-07-28 18:56:00,700 Epoch[16] Batch [140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.123903,	
2017-07-28 18:56:06,514 Epoch[16] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.124627,	
2017-07-28 18:56:12,299 Epoch[16] Batch [160]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.125335,	
2017-07-28 18:56:18,118 Epoch[16] Batch [170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.124304,	
2017-07-28 18:56:23,880 Epoch[16] Batch [180]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.124872,	
2017-07-28 18:56:29,715 Epoch[16] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.124185,	
2017-07-28 18:56:35,479 Epoch[16] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.123836,	
2017-07-28 18:56:41,344 Epoch[16] Batch [210]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.123435,	
2017-07-28 18:56:47,100 Epoch[16] Batch [220]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.124037,	
2017-07-28 18:56:52,897 Epoch[16] Batch [230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124013,	
2017-07-28 18:56:58,726 Epoch[16] Batch [240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123959,	
2017-07-28 18:57:04,523 Epoch[16] Batch [250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.124469,	
2017-07-28 18:57:10,358 Epoch[16] Batch [260]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123997,	
2017-07-28 18:57:16,174 Epoch[16] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123822,	
2017-07-28 18:57:22,401 Epoch[16] Batch [280]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.123797,	
2017-07-28 18:57:28,474 Epoch[16] Batch [290]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.123666,	
2017-07-28 18:57:34,235 Epoch[16] Batch [300]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.123443,	
2017-07-28 18:57:40,164 Epoch[16] Batch [310]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.123208,	
2017-07-28 18:57:46,009 Epoch[16] Batch [320]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.123158,	
2017-07-28 18:57:51,753 Epoch[16] Batch [330]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.122882,	
2017-07-28 18:57:57,530 Epoch[16] Batch [340]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.122648,	
2017-07-28 18:58:03,322 Epoch[16] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.122318,	
2017-07-28 18:58:09,136 Epoch[16] Batch [360]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122158,	
2017-07-28 18:58:14,928 Epoch[16] Batch [370]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121891,	
2017-07-28 18:58:20,708 Epoch[16] Batch [380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.122088,	
2017-07-28 18:58:26,524 Epoch[16] Batch [390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121541,	
2017-07-28 18:58:31,680 Epoch[16] Batch [400]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.121837,	
2017-07-28 18:58:37,436 Epoch[16] Batch [410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121863,	
2017-07-28 18:58:43,170 Epoch[16] Batch [420]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.121548,	
2017-07-28 18:58:48,956 Epoch[16] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121716,	
2017-07-28 18:58:54,732 Epoch[16] Batch [440]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121965,	
2017-07-28 18:59:00,571 Epoch[16] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122070,	
2017-07-28 18:59:06,374 Epoch[16] Batch [460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122506,	
2017-07-28 18:59:12,201 Epoch[16] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122591,	
2017-07-28 18:59:18,034 Epoch[16] Batch [480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122635,	
2017-07-28 18:59:23,864 Epoch[16] Batch [490]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122236,	
2017-07-28 18:59:29,632 Epoch[16] Batch [500]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122372,	
2017-07-28 18:59:35,425 Epoch[16] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122320,	
2017-07-28 18:59:41,271 Epoch[16] Batch [520]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.122235,	
2017-07-28 18:59:47,033 Epoch[16] Batch [530]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122083,	
2017-07-28 18:59:52,864 Epoch[16] Batch [540]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121848,	
2017-07-28 18:59:58,619 Epoch[16] Batch [550]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121796,	
2017-07-28 19:00:04,475 Epoch[16] Batch [560]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121770,	
2017-07-28 19:00:10,197 Epoch[16] Batch [570]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.121529,	
2017-07-28 19:00:16,044 Epoch[16] Batch [580]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.121616,	
2017-07-28 19:00:21,803 Epoch[16] Batch [590]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121620,	
2017-07-28 19:00:27,651 Epoch[16] Batch [600]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.121692,	
2017-07-28 19:00:33,510 Epoch[16] Batch [610]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121699,	
2017-07-28 19:00:39,278 Epoch[16] Batch [620]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.121931,	
2017-07-28 19:00:45,107 Epoch[16] Batch [630]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121924,	
2017-07-28 19:00:50,814 Epoch[16] Batch [640]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.121786,	
2017-07-28 19:00:56,656 Epoch[16] Batch [650]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.121809,	
2017-07-28 19:01:02,420 Epoch[16] Batch [660]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122087,	
2017-07-28 19:01:08,235 Epoch[16] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122054,	
2017-07-28 19:01:14,043 Epoch[16] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122040,	
2017-07-28 19:01:19,810 Epoch[16] Batch [690]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122103,	
2017-07-28 19:01:25,664 Epoch[16] Batch [700]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.122124,	
2017-07-28 19:01:31,432 Epoch[16] Batch [710]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122067,	
2017-07-28 19:01:37,225 Epoch[16] Batch [720]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121971,	
2017-07-28 19:01:43,050 Epoch[16] Batch [730]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121867,	
2017-07-28 19:01:48,797 Epoch[16] Batch [740]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.121912,	
2017-07-28 19:01:54,655 Epoch[16] Batch [750]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121635,	
2017-07-28 19:02:00,468 Epoch[16] Batch [760]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121704,	
2017-07-28 19:02:06,354 Epoch[16] Batch [770]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.121554,	
2017-07-28 19:02:12,054 Epoch[16] Batch [780]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.121431,	
2017-07-28 19:02:17,864 Epoch[16] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121380,	
2017-07-28 19:02:23,727 Epoch[16] Batch [800]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.121495,	
2017-07-28 19:02:29,439 Epoch[16] Batch [810]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.121414,	
2017-07-28 19:02:35,312 Epoch[16] Batch [820]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.121276,	
2017-07-28 19:02:41,079 Epoch[16] Batch [830]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.121074,	
2017-07-28 19:02:46,862 Epoch[16] Batch [840]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121035,	
2017-07-28 19:02:52,669 Epoch[16] Batch [850]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121099,	
2017-07-28 19:02:58,526 Epoch[16] Batch [860]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121011,	
2017-07-28 19:03:04,324 Epoch[16] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121014,	
2017-07-28 19:03:10,130 Epoch[16] Batch [880]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120856,	
2017-07-28 19:03:15,897 Epoch[16] Batch [890]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.120834,	
2017-07-28 19:03:21,771 Epoch[16] Batch [900]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.120999,	
2017-07-28 19:03:27,470 Epoch[16] Batch [910]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.120917,	
2017-07-28 19:03:33,302 Epoch[16] Batch [920]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120768,	
2017-07-28 19:03:39,081 Epoch[16] Batch [930]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.120704,	
2017-07-28 19:03:44,911 Epoch[16] Batch [940]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120703,	
2017-07-28 19:03:50,711 Epoch[16] Batch [950]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120696,	
2017-07-28 19:03:56,569 Epoch[16] Batch [960]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.120798,	
2017-07-28 19:04:02,336 Epoch[16] Batch [970]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.120777,	
2017-07-28 19:04:08,134 Epoch[16] Batch [980]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120737,	
2017-07-28 19:04:13,900 Epoch[16] Batch [990]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.120756,	
2017-07-28 19:04:19,733 Epoch[16] Batch [1000]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120810,	
2017-07-28 19:04:25,512 Epoch[16] Batch [1010]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.120674,	
2017-07-28 19:04:31,416 Epoch[16] Batch [1020]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.120719,	
2017-07-28 19:04:37,093 Epoch[16] Batch [1030]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.120598,	
2017-07-28 19:04:42,909 Epoch[16] Batch [1040]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120613,	
2017-07-28 19:04:48,804 Epoch[16] Batch [1050]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.120721,	
2017-07-28 19:04:54,555 Epoch[16] Batch [1060]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.120746,	
2017-07-28 19:05:00,354 Epoch[16] Batch [1070]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120743,	
2017-07-28 19:05:06,143 Epoch[16] Batch [1080]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121131,	
2017-07-28 19:05:12,017 Epoch[16] Batch [1090]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.121174,	
2017-07-28 19:05:17,776 Epoch[16] Batch [1100]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121336,	
2017-07-28 19:05:23,545 Epoch[16] Batch [1110]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.121476,	
2017-07-28 19:05:29,398 Epoch[16] Batch [1120]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.121466,	
2017-07-28 19:05:35,193 Epoch[16] Batch [1130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121402,	
2017-07-28 19:05:41,001 Epoch[16] Batch [1140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121367,	
2017-07-28 19:05:46,813 Epoch[16] Batch [1150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121415,	
2017-07-28 19:05:52,678 Epoch[16] Batch [1160]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.121400,	
2017-07-28 19:05:58,494 Epoch[16] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121409,	
2017-07-28 19:06:04,239 Epoch[16] Batch [1180]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.121417,	
2017-07-28 19:06:10,099 Epoch[16] Batch [1190]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121504,	
2017-07-28 19:06:15,887 Epoch[16] Batch [1200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121568,	
2017-07-28 19:06:21,715 Epoch[16] Batch [1210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121561,	
2017-07-28 19:06:27,565 Epoch[16] Batch [1220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.121535,	
2017-07-28 19:06:33,347 Epoch[16] Batch [1230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121565,	
2017-07-28 19:06:39,134 Epoch[16] Batch [1240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121563,	
2017-07-28 19:06:44,934 Epoch[16] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121424,	
2017-07-28 19:06:50,717 Epoch[16] Batch [1260]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121435,	
2017-07-28 19:06:56,519 Epoch[16] Batch [1270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121515,	
2017-07-28 19:07:02,400 Epoch[16] Batch [1280]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.121804,	
2017-07-28 19:07:08,138 Epoch[16] Batch [1290]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.121912,	
2017-07-28 19:07:13,954 Epoch[16] Batch [1300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122108,	
2017-07-28 19:07:19,756 Epoch[16] Batch [1310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122229,	
2017-07-28 19:07:25,608 Epoch[16] Batch [1320]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.122306,	
2017-07-28 19:07:31,762 Epoch[16] Batch [1330]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.122370,	
2017-07-28 19:07:37,830 Epoch[16] Batch [1340]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.122302,	
2017-07-28 19:07:43,711 Epoch[16] Batch [1350]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.122372,	
2017-07-28 19:07:49,628 Epoch[16] Batch [1360]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.122414,	
2017-07-28 19:07:55,660 Epoch[16] Batch [1370]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.122401,	
2017-07-28 19:08:01,425 Epoch[16] Batch [1380]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122497,	
2017-07-28 19:08:07,225 Epoch[16] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122427,	
2017-07-28 19:08:13,029 Epoch[16] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122414,	
2017-07-28 19:08:18,867 Epoch[16] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122654,	
2017-07-28 19:08:25,007 Epoch[16] Batch [1420]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.122728,	
2017-07-28 19:08:30,756 Epoch[16] Batch [1430]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.122622,	
2017-07-28 19:08:36,541 Epoch[16] Batch [1440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.122581,	
2017-07-28 19:08:42,355 Epoch[16] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122535,	
2017-07-28 19:08:48,154 Epoch[16] Batch [1460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122529,	
2017-07-28 19:08:53,977 Epoch[16] Batch [1470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122465,	
2017-07-28 19:08:59,815 Epoch[16] Batch [1480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122553,	
2017-07-28 19:09:03,225 Epoch[16] Train-FCNLogLoss=0.122576
2017-07-28 19:09:03,226 Epoch[16] Time cost=864.757
2017-07-28 19:09:04,362 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0017.params"
2017-07-28 19:09:08,113 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0017.states"
2017-07-28 19:09:14,944 Epoch[17] Batch [10]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.111787,	
2017-07-28 19:09:20,591 Epoch[17] Batch [20]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.110108,	
2017-07-28 19:09:26,415 Epoch[17] Batch [30]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.109737,	
2017-07-28 19:09:32,235 Epoch[17] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116904,	
2017-07-28 19:09:38,022 Epoch[17] Batch [50]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116611,	
2017-07-28 19:09:43,832 Epoch[17] Batch [60]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117917,	
2017-07-28 19:09:49,684 Epoch[17] Batch [70]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.117060,	
2017-07-28 19:09:55,549 Epoch[17] Batch [80]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.117907,	
2017-07-28 19:10:01,208 Epoch[17] Batch [90]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.116905,	
2017-07-28 19:10:07,036 Epoch[17] Batch [100]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116502,	
2017-07-28 19:10:12,798 Epoch[17] Batch [110]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115758,	
2017-07-28 19:10:18,626 Epoch[17] Batch [120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.115959,	
2017-07-28 19:10:24,410 Epoch[17] Batch [130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116866,	
2017-07-28 19:10:30,213 Epoch[17] Batch [140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116922,	
2017-07-28 19:10:35,971 Epoch[17] Batch [150]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116617,	
2017-07-28 19:10:42,033 Epoch[17] Batch [160]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.116320,	
2017-07-28 19:10:47,748 Epoch[17] Batch [170]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.115987,	
2017-07-28 19:10:53,442 Epoch[17] Batch [180]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.116885,	
2017-07-28 19:10:59,222 Epoch[17] Batch [190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116829,	
2017-07-28 19:11:05,043 Epoch[17] Batch [200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116406,	
2017-07-28 19:11:10,981 Epoch[17] Batch [210]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.117540,	
2017-07-28 19:11:16,747 Epoch[17] Batch [220]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117140,	
2017-07-28 19:11:22,509 Epoch[17] Batch [230]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116915,	
2017-07-28 19:11:28,380 Epoch[17] Batch [240]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.116485,	
2017-07-28 19:11:34,397 Epoch[17] Batch [250]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.116926,	
2017-07-28 19:11:40,298 Epoch[17] Batch [260]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.118185,	
2017-07-28 19:11:46,078 Epoch[17] Batch [270]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118133,	
2017-07-28 19:11:51,817 Epoch[17] Batch [280]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.118020,	
2017-07-28 19:11:57,621 Epoch[17] Batch [290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.118165,	
2017-07-28 19:12:03,421 Epoch[17] Batch [300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119170,	
2017-07-28 19:12:09,216 Epoch[17] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119030,	
2017-07-28 19:12:15,049 Epoch[17] Batch [320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.119177,	
2017-07-28 19:12:20,835 Epoch[17] Batch [330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118797,	
2017-07-28 19:12:26,655 Epoch[17] Batch [340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.118753,	
2017-07-28 19:12:32,707 Epoch[17] Batch [350]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.119056,	
2017-07-28 19:12:38,610 Epoch[17] Batch [360]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.118940,	
2017-07-28 19:12:44,410 Epoch[17] Batch [370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119066,	
2017-07-28 19:12:50,248 Epoch[17] Batch [380]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118995,	
2017-07-28 19:12:55,999 Epoch[17] Batch [390]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.118689,	
2017-07-28 19:13:01,936 Epoch[17] Batch [400]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.118488,	
2017-07-28 19:13:07,790 Epoch[17] Batch [410]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.118548,	
2017-07-28 19:13:13,473 Epoch[17] Batch [420]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.118653,	
2017-07-28 19:13:19,172 Epoch[17] Batch [430]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.119163,	
2017-07-28 19:13:25,010 Epoch[17] Batch [440]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.119730,	
2017-07-28 19:13:30,811 Epoch[17] Batch [450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119700,	
2017-07-28 19:13:36,646 Epoch[17] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120291,	
2017-07-28 19:13:42,401 Epoch[17] Batch [470]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.120658,	
2017-07-28 19:13:48,194 Epoch[17] Batch [480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121472,	
2017-07-28 19:13:54,062 Epoch[17] Batch [490]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.122730,	
2017-07-28 19:13:59,883 Epoch[17] Batch [500]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122903,	
2017-07-28 19:14:05,645 Epoch[17] Batch [510]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.123026,	
2017-07-28 19:14:12,060 Epoch[17] Batch [520]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.122915,	
2017-07-28 19:14:17,937 Epoch[17] Batch [530]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.123056,	
2017-07-28 19:14:23,745 Epoch[17] Batch [540]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.123290,	
2017-07-28 19:14:29,566 Epoch[17] Batch [550]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.123259,	
2017-07-28 19:14:35,363 Epoch[17] Batch [560]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123169,	
2017-07-28 19:14:41,195 Epoch[17] Batch [570]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123146,	
2017-07-28 19:14:46,961 Epoch[17] Batch [580]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.123293,	
2017-07-28 19:14:52,760 Epoch[17] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123327,	
2017-07-28 19:14:58,578 Epoch[17] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123485,	
2017-07-28 19:15:04,369 Epoch[17] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123649,	
2017-07-28 19:15:10,014 Epoch[17] Batch [620]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.123613,	
2017-07-28 19:15:15,691 Epoch[17] Batch [630]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.123794,	
2017-07-28 19:15:21,677 Epoch[17] Batch [640]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.123764,	
2017-07-28 19:15:27,415 Epoch[17] Batch [650]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.123573,	
2017-07-28 19:15:33,233 Epoch[17] Batch [660]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123619,	
2017-07-28 19:15:39,048 Epoch[17] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123447,	
2017-07-28 19:15:44,888 Epoch[17] Batch [680]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123364,	
2017-07-28 19:15:50,685 Epoch[17] Batch [690]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123381,	
2017-07-28 19:15:56,641 Epoch[17] Batch [700]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.123311,	
2017-07-28 19:16:02,378 Epoch[17] Batch [710]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.123199,	
2017-07-28 19:16:08,173 Epoch[17] Batch [720]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123181,	
2017-07-28 19:16:13,962 Epoch[17] Batch [730]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123099,	
2017-07-28 19:16:19,855 Epoch[17] Batch [740]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.122868,	
2017-07-28 19:16:26,159 Epoch[17] Batch [750]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.122656,	
2017-07-28 19:16:32,215 Epoch[17] Batch [760]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.122541,	
2017-07-28 19:16:38,161 Epoch[17] Batch [770]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.122628,	
2017-07-28 19:16:44,201 Epoch[17] Batch [780]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.122444,	
2017-07-28 19:16:49,994 Epoch[17] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.122357,	
2017-07-28 19:16:55,736 Epoch[17] Batch [800]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.122368,	
2017-07-28 19:17:01,479 Epoch[17] Batch [810]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.122263,	
2017-07-28 19:17:07,282 Epoch[17] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122476,	
2017-07-28 19:17:13,161 Epoch[17] Batch [830]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.122632,	
2017-07-28 19:17:18,922 Epoch[17] Batch [840]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.122539,	
2017-07-28 19:17:24,791 Epoch[17] Batch [850]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.122566,	
2017-07-28 19:17:30,631 Epoch[17] Batch [860]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122367,	
2017-07-28 19:17:36,350 Epoch[17] Batch [870]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.122408,	
2017-07-28 19:17:42,164 Epoch[17] Batch [880]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122255,	
2017-07-28 19:17:48,254 Epoch[17] Batch [890]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.122346,	
2017-07-28 19:17:53,973 Epoch[17] Batch [900]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.122137,	
2017-07-28 19:17:59,970 Epoch[17] Batch [910]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.122066,	
2017-07-28 19:18:05,704 Epoch[17] Batch [920]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.122219,	
2017-07-28 19:18:11,537 Epoch[17] Batch [930]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122105,	
2017-07-28 19:18:17,508 Epoch[17] Batch [940]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.122139,	
2017-07-28 19:18:23,155 Epoch[17] Batch [950]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.122104,	
2017-07-28 19:18:28,986 Epoch[17] Batch [960]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.122178,	
2017-07-28 19:18:34,754 Epoch[17] Batch [970]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.122110,	
2017-07-28 19:18:40,563 Epoch[17] Batch [980]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121943,	
2017-07-28 19:18:46,353 Epoch[17] Batch [990]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121900,	
2017-07-28 19:18:52,188 Epoch[17] Batch [1000]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.121802,	
2017-07-28 19:18:57,935 Epoch[17] Batch [1010]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.121591,	
2017-07-28 19:19:03,731 Epoch[17] Batch [1020]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121637,	
2017-07-28 19:19:09,381 Epoch[17] Batch [1030]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.121629,	
2017-07-28 19:19:15,050 Epoch[17] Batch [1040]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.121542,	
2017-07-28 19:19:20,845 Epoch[17] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.121483,	
2017-07-28 19:19:26,634 Epoch[17] Batch [1060]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121608,	
2017-07-28 19:19:32,476 Epoch[17] Batch [1070]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.121638,	
2017-07-28 19:19:38,213 Epoch[17] Batch [1080]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.121745,	
2017-07-28 19:19:44,005 Epoch[17] Batch [1090]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121838,	
2017-07-28 19:19:49,807 Epoch[17] Batch [1100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121834,	
2017-07-28 19:19:55,639 Epoch[17] Batch [1110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121778,	
2017-07-28 19:20:01,465 Epoch[17] Batch [1120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121740,	
2017-07-28 19:20:07,287 Epoch[17] Batch [1130]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121705,	
2017-07-28 19:20:13,153 Epoch[17] Batch [1140]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.121613,	
2017-07-28 19:20:19,198 Epoch[17] Batch [1150]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.121533,	
2017-07-28 19:20:25,057 Epoch[17] Batch [1160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.121571,	
2017-07-28 19:20:30,975 Epoch[17] Batch [1170]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.121752,	
2017-07-28 19:20:36,965 Epoch[17] Batch [1180]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.121760,	
2017-07-28 19:20:42,752 Epoch[17] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121806,	
2017-07-28 19:20:48,558 Epoch[17] Batch [1200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121923,	
2017-07-28 19:20:54,343 Epoch[17] Batch [1210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121950,	
2017-07-28 19:21:00,129 Epoch[17] Batch [1220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.122102,	
2017-07-28 19:21:05,935 Epoch[17] Batch [1230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122160,	
2017-07-28 19:21:11,751 Epoch[17] Batch [1240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122185,	
2017-07-28 19:21:17,313 Epoch[17] Batch [1250]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.122193,	
2017-07-28 19:21:23,114 Epoch[17] Batch [1260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122266,	
2017-07-28 19:21:28,932 Epoch[17] Batch [1270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.122370,	
2017-07-28 19:21:34,767 Epoch[17] Batch [1280]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122301,	
2017-07-28 19:21:40,577 Epoch[17] Batch [1290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122349,	
2017-07-28 19:21:46,360 Epoch[17] Batch [1300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.122341,	
2017-07-28 19:21:52,165 Epoch[17] Batch [1310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.122566,	
2017-07-28 19:21:58,007 Epoch[17] Batch [1320]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122678,	
2017-07-28 19:22:03,938 Epoch[17] Batch [1330]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.122813,	
2017-07-28 19:22:10,058 Epoch[17] Batch [1340]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.122926,	
2017-07-28 19:22:16,196 Epoch[17] Batch [1350]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.123032,	
2017-07-28 19:22:22,024 Epoch[17] Batch [1360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.123206,	
2017-07-28 19:22:28,113 Epoch[17] Batch [1370]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.123297,	
2017-07-28 19:22:34,220 Epoch[17] Batch [1380]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.123360,	
2017-07-28 19:22:40,074 Epoch[17] Batch [1390]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.123433,	
2017-07-28 19:22:45,826 Epoch[17] Batch [1400]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.123424,	
2017-07-28 19:22:51,608 Epoch[17] Batch [1410]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.123349,	
2017-07-28 19:22:57,492 Epoch[17] Batch [1420]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.123261,	
2017-07-28 19:23:03,386 Epoch[17] Batch [1430]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.123182,	
2017-07-28 19:23:09,092 Epoch[17] Batch [1440]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.123249,	
2017-07-28 19:23:14,873 Epoch[17] Batch [1450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.123253,	
2017-07-28 19:23:20,686 Epoch[17] Batch [1460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123156,	
2017-07-28 19:23:26,560 Epoch[17] Batch [1470]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.123049,	
2017-07-28 19:23:32,280 Epoch[17] Batch [1480]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.123054,	
2017-07-28 19:23:35,618 Epoch[17] Train-FCNLogLoss=0.122977
2017-07-28 19:23:35,618 Epoch[17] Time cost=867.504
2017-07-28 19:23:36,803 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0018.params"
2017-07-28 19:23:40,670 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0018.states"
2017-07-28 19:23:47,799 Epoch[18] Batch [10]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.124361,	
2017-07-28 19:23:53,539 Epoch[18] Batch [20]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.125806,	
2017-07-28 19:23:59,668 Epoch[18] Batch [30]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.122632,	
2017-07-28 19:24:05,556 Epoch[18] Batch [40]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.120730,	
2017-07-28 19:24:11,329 Epoch[18] Batch [50]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120914,	
2017-07-28 19:24:17,079 Epoch[18] Batch [60]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.120047,	
2017-07-28 19:24:23,113 Epoch[18] Batch [70]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.120945,	
2017-07-28 19:24:29,202 Epoch[18] Batch [80]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.121273,	
2017-07-28 19:24:35,069 Epoch[18] Batch [90]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.120382,	
2017-07-28 19:24:40,907 Epoch[18] Batch [100]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.119513,	
2017-07-28 19:24:47,311 Epoch[18] Batch [110]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.120357,	
2017-07-28 19:24:53,234 Epoch[18] Batch [120]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.120100,	
2017-07-28 19:24:59,287 Epoch[18] Batch [130]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.120814,	
2017-07-28 19:25:05,095 Epoch[18] Batch [140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119619,	
2017-07-28 19:25:10,905 Epoch[18] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120033,	
2017-07-28 19:25:16,748 Epoch[18] Batch [160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.120105,	
2017-07-28 19:25:22,646 Epoch[18] Batch [170]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.120698,	
2017-07-28 19:25:28,325 Epoch[18] Batch [180]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.121316,	
2017-07-28 19:25:34,107 Epoch[18] Batch [190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.121455,	
2017-07-28 19:25:39,910 Epoch[18] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.121566,	
2017-07-28 19:25:45,705 Epoch[18] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120996,	
2017-07-28 19:25:51,507 Epoch[18] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.120973,	
2017-07-28 19:25:57,308 Epoch[18] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120913,	
2017-07-28 19:26:03,128 Epoch[18] Batch [240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.121009,	
2017-07-28 19:26:08,887 Epoch[18] Batch [250]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.121063,	
2017-07-28 19:26:14,705 Epoch[18] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120888,	
2017-07-28 19:26:20,493 Epoch[18] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120611,	
2017-07-28 19:26:26,279 Epoch[18] Batch [280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.120266,	
2017-07-28 19:26:32,086 Epoch[18] Batch [290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.120118,	
2017-07-28 19:26:37,911 Epoch[18] Batch [300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119826,	
2017-07-28 19:26:43,731 Epoch[18] Batch [310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119571,	
2017-07-28 19:26:49,493 Epoch[18] Batch [320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.119497,	
2017-07-28 19:26:55,200 Epoch[18] Batch [330]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.119280,	
2017-07-28 19:27:00,876 Epoch[18] Batch [340]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.119165,	
2017-07-28 19:27:06,570 Epoch[18] Batch [350]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.119068,	
2017-07-28 19:27:12,411 Epoch[18] Batch [360]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.119077,	
2017-07-28 19:27:18,199 Epoch[18] Batch [370]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.119300,	
2017-07-28 19:27:23,221 Epoch[18] Batch [380]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.119414,	
2017-07-28 19:27:27,410 Epoch[18] Batch [390]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.119391,	
2017-07-28 19:27:33,153 Epoch[18] Batch [400]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.119106,	
2017-07-28 19:27:38,921 Epoch[18] Batch [410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119285,	
2017-07-28 19:27:44,698 Epoch[18] Batch [420]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119408,	
2017-07-28 19:27:50,521 Epoch[18] Batch [430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119683,	
2017-07-28 19:27:56,297 Epoch[18] Batch [440]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119971,	
2017-07-28 19:28:02,120 Epoch[18] Batch [450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119927,	
2017-07-28 19:28:07,915 Epoch[18] Batch [460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119603,	
2017-07-28 19:28:13,713 Epoch[18] Batch [470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119793,	
2017-07-28 19:28:19,485 Epoch[18] Batch [480]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.119589,	
2017-07-28 19:28:25,293 Epoch[18] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119379,	
2017-07-28 19:28:31,120 Epoch[18] Batch [500]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119508,	
2017-07-28 19:28:36,888 Epoch[18] Batch [510]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.119339,	
2017-07-28 19:28:42,686 Epoch[18] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119541,	
2017-07-28 19:28:48,475 Epoch[18] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.119443,	
2017-07-28 19:28:54,271 Epoch[18] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.119138,	
2017-07-28 19:29:00,044 Epoch[18] Batch [550]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.118957,	
2017-07-28 19:29:05,856 Epoch[18] Batch [560]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118705,	
2017-07-28 19:29:11,655 Epoch[18] Batch [570]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118494,	
2017-07-28 19:29:17,451 Epoch[18] Batch [580]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118436,	
2017-07-28 19:29:23,246 Epoch[18] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118352,	
2017-07-28 19:29:29,037 Epoch[18] Batch [600]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118482,	
2017-07-28 19:29:34,877 Epoch[18] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118655,	
2017-07-28 19:29:40,659 Epoch[18] Batch [620]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118549,	
2017-07-28 19:29:46,438 Epoch[18] Batch [630]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118521,	
2017-07-28 19:29:52,221 Epoch[18] Batch [640]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118315,	
2017-07-28 19:29:58,014 Epoch[18] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118230,	
2017-07-28 19:30:03,823 Epoch[18] Batch [660]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.118017,	
2017-07-28 19:30:09,565 Epoch[18] Batch [670]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.118294,	
2017-07-28 19:30:15,350 Epoch[18] Batch [680]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118505,	
2017-07-28 19:30:20,997 Epoch[18] Batch [690]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.118682,	
2017-07-28 19:30:26,762 Epoch[18] Batch [700]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.118842,	
2017-07-28 19:30:32,448 Epoch[18] Batch [710]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.118741,	
2017-07-28 19:30:38,207 Epoch[18] Batch [720]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.118851,	
2017-07-28 19:30:43,965 Epoch[18] Batch [730]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.118914,	
2017-07-28 19:30:49,684 Epoch[18] Batch [740]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.118998,	
2017-07-28 19:30:55,384 Epoch[18] Batch [750]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.118976,	
2017-07-28 19:31:01,165 Epoch[18] Batch [760]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118840,	
2017-07-28 19:31:06,948 Epoch[18] Batch [770]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118830,	
2017-07-28 19:31:12,614 Epoch[18] Batch [780]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.118678,	
2017-07-28 19:31:18,400 Epoch[18] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118595,	
2017-07-28 19:31:24,207 Epoch[18] Batch [800]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.118565,	
2017-07-28 19:31:29,993 Epoch[18] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118516,	
2017-07-28 19:31:35,790 Epoch[18] Batch [820]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118649,	
2017-07-28 19:31:41,584 Epoch[18] Batch [830]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118641,	
2017-07-28 19:31:47,379 Epoch[18] Batch [840]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118554,	
2017-07-28 19:31:53,207 Epoch[18] Batch [850]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.118399,	
2017-07-28 19:31:59,018 Epoch[18] Batch [860]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118400,	
2017-07-28 19:32:04,802 Epoch[18] Batch [870]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.118354,	
2017-07-28 19:32:10,568 Epoch[18] Batch [880]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.118201,	
2017-07-28 19:32:16,206 Epoch[18] Batch [890]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.118299,	
2017-07-28 19:32:21,977 Epoch[18] Batch [900]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.118105,	
2017-07-28 19:32:27,793 Epoch[18] Batch [910]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117994,	
2017-07-28 19:32:33,472 Epoch[18] Batch [920]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.117929,	
2017-07-28 19:32:39,265 Epoch[18] Batch [930]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117948,	
2017-07-28 19:32:45,059 Epoch[18] Batch [940]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118012,	
2017-07-28 19:32:50,665 Epoch[18] Batch [950]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.117975,	
2017-07-28 19:32:56,457 Epoch[18] Batch [960]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118039,	
2017-07-28 19:33:02,198 Epoch[18] Batch [970]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.118243,	
2017-07-28 19:33:07,914 Epoch[18] Batch [980]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.118225,	
2017-07-28 19:33:13,750 Epoch[18] Batch [990]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118114,	
2017-07-28 19:33:19,550 Epoch[18] Batch [1000]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118097,	
2017-07-28 19:33:25,319 Epoch[18] Batch [1010]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.118028,	
2017-07-28 19:33:31,122 Epoch[18] Batch [1020]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117890,	
2017-07-28 19:33:36,950 Epoch[18] Batch [1030]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117718,	
2017-07-28 19:33:42,746 Epoch[18] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117618,	
2017-07-28 19:33:48,528 Epoch[18] Batch [1050]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117547,	
2017-07-28 19:33:54,334 Epoch[18] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117542,	
2017-07-28 19:34:00,131 Epoch[18] Batch [1070]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117820,	
2017-07-28 19:34:05,887 Epoch[18] Batch [1080]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.117797,	
2017-07-28 19:34:11,721 Epoch[18] Batch [1090]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117748,	
2017-07-28 19:34:17,525 Epoch[18] Batch [1100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117834,	
2017-07-28 19:34:23,341 Epoch[18] Batch [1110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117811,	
2017-07-28 19:34:29,159 Epoch[18] Batch [1120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117861,	
2017-07-28 19:34:34,994 Epoch[18] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117815,	
2017-07-28 19:34:40,762 Epoch[18] Batch [1140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117927,	
2017-07-28 19:34:46,592 Epoch[18] Batch [1150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117865,	
2017-07-28 19:34:52,378 Epoch[18] Batch [1160]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117885,	
2017-07-28 19:34:58,188 Epoch[18] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117855,	
2017-07-28 19:35:03,983 Epoch[18] Batch [1180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117899,	
2017-07-28 19:35:09,768 Epoch[18] Batch [1190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117849,	
2017-07-28 19:35:15,589 Epoch[18] Batch [1200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117913,	
2017-07-28 19:35:21,356 Epoch[18] Batch [1210]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117859,	
2017-07-28 19:35:27,192 Epoch[18] Batch [1220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117860,	
2017-07-28 19:35:32,952 Epoch[18] Batch [1230]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117890,	
2017-07-28 19:35:38,749 Epoch[18] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117752,	
2017-07-28 19:35:44,572 Epoch[18] Batch [1250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117735,	
2017-07-28 19:35:50,365 Epoch[18] Batch [1260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117714,	
2017-07-28 19:35:56,139 Epoch[18] Batch [1270]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117608,	
2017-07-28 19:36:01,937 Epoch[18] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117487,	
2017-07-28 19:36:07,724 Epoch[18] Batch [1290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117433,	
2017-07-28 19:36:13,519 Epoch[18] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117274,	
2017-07-28 19:36:19,333 Epoch[18] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117231,	
2017-07-28 19:36:25,097 Epoch[18] Batch [1320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117269,	
2017-07-28 19:36:30,912 Epoch[18] Batch [1330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117246,	
2017-07-28 19:36:36,742 Epoch[18] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117204,	
2017-07-28 19:36:42,559 Epoch[18] Batch [1350]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117115,	
2017-07-28 19:36:48,340 Epoch[18] Batch [1360]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117078,	
2017-07-28 19:36:54,132 Epoch[18] Batch [1370]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117179,	
2017-07-28 19:36:59,929 Epoch[18] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117283,	
2017-07-28 19:37:05,741 Epoch[18] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117420,	
2017-07-28 19:37:11,512 Epoch[18] Batch [1400]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117515,	
2017-07-28 19:37:17,300 Epoch[18] Batch [1410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117467,	
2017-07-28 19:37:23,092 Epoch[18] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117514,	
2017-07-28 19:37:28,845 Epoch[18] Batch [1430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.117471,	
2017-07-28 19:37:34,652 Epoch[18] Batch [1440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117500,	
2017-07-28 19:37:40,474 Epoch[18] Batch [1450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117492,	
2017-07-28 19:37:46,237 Epoch[18] Batch [1460]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117516,	
2017-07-28 19:37:52,080 Epoch[18] Batch [1470]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.117518,	
2017-07-28 19:37:57,854 Epoch[18] Batch [1480]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117496,	
2017-07-28 19:38:01,355 Epoch[18] Train-FCNLogLoss=0.117499
2017-07-28 19:38:01,356 Epoch[18] Time cost=860.685
2017-07-28 19:38:02,175 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0019.params"
2017-07-28 19:38:03,779 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0019.states"
2017-07-28 19:38:10,319 Epoch[19] Batch [10]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.130342,	
2017-07-28 19:38:16,127 Epoch[19] Batch [20]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.125577,	
2017-07-28 19:38:21,927 Epoch[19] Batch [30]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117645,	
2017-07-28 19:38:27,711 Epoch[19] Batch [40]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114210,	
2017-07-28 19:38:33,504 Epoch[19] Batch [50]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114513,	
2017-07-28 19:38:39,238 Epoch[19] Batch [60]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.113122,	
2017-07-28 19:38:45,089 Epoch[19] Batch [70]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116234,	
2017-07-28 19:38:50,869 Epoch[19] Batch [80]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115176,	
2017-07-28 19:38:56,666 Epoch[19] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115885,	
2017-07-28 19:39:02,323 Epoch[19] Batch [100]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.116642,	
2017-07-28 19:39:08,056 Epoch[19] Batch [110]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.117237,	
2017-07-28 19:39:13,775 Epoch[19] Batch [120]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.116609,	
2017-07-28 19:39:19,540 Epoch[19] Batch [130]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116283,	
2017-07-28 19:39:25,241 Epoch[19] Batch [140]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.116585,	
2017-07-28 19:39:31,012 Epoch[19] Batch [150]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116201,	
2017-07-28 19:39:36,821 Epoch[19] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115495,	
2017-07-28 19:39:42,616 Epoch[19] Batch [170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115278,	
2017-07-28 19:39:48,426 Epoch[19] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115344,	
2017-07-28 19:39:54,220 Epoch[19] Batch [190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115362,	
2017-07-28 19:40:00,003 Epoch[19] Batch [200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115496,	
2017-07-28 19:40:05,787 Epoch[19] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115398,	
2017-07-28 19:40:11,599 Epoch[19] Batch [220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115981,	
2017-07-28 19:40:17,399 Epoch[19] Batch [230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116299,	
2017-07-28 19:40:23,179 Epoch[19] Batch [240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116609,	
2017-07-28 19:40:29,016 Epoch[19] Batch [250]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116654,	
2017-07-28 19:40:34,574 Epoch[19] Batch [260]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.116559,	
2017-07-28 19:40:40,266 Epoch[19] Batch [270]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.116999,	
2017-07-28 19:40:46,100 Epoch[19] Batch [280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117140,	
2017-07-28 19:40:51,849 Epoch[19] Batch [290]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.116867,	
2017-07-28 19:40:57,655 Epoch[19] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116656,	
2017-07-28 19:41:03,257 Epoch[19] Batch [310]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.116111,	
2017-07-28 19:41:09,023 Epoch[19] Batch [320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115820,	
2017-07-28 19:41:14,824 Epoch[19] Batch [330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115778,	
2017-07-28 19:41:20,489 Epoch[19] Batch [340]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.115683,	
2017-07-28 19:41:26,319 Epoch[19] Batch [350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.115499,	
2017-07-28 19:41:32,091 Epoch[19] Batch [360]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.115586,	
2017-07-28 19:41:37,931 Epoch[19] Batch [370]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115816,	
2017-07-28 19:41:43,721 Epoch[19] Batch [380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115644,	
2017-07-28 19:41:49,383 Epoch[19] Batch [390]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.115495,	
2017-07-28 19:41:53,403 Epoch[19] Batch [400]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115455,	
2017-07-28 19:41:59,098 Epoch[19] Batch [410]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.115782,	
2017-07-28 19:42:04,879 Epoch[19] Batch [420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116136,	
2017-07-28 19:42:10,632 Epoch[19] Batch [430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116101,	
2017-07-28 19:42:16,431 Epoch[19] Batch [440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116155,	
2017-07-28 19:42:22,246 Epoch[19] Batch [450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116140,	
2017-07-28 19:42:28,033 Epoch[19] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116017,	
2017-07-28 19:42:33,857 Epoch[19] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116062,	
2017-07-28 19:42:39,647 Epoch[19] Batch [480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115819,	
2017-07-28 19:42:45,446 Epoch[19] Batch [490]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115624,	
2017-07-28 19:42:51,243 Epoch[19] Batch [500]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115584,	
2017-07-28 19:42:57,033 Epoch[19] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115717,	
2017-07-28 19:43:02,876 Epoch[19] Batch [520]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115983,	
2017-07-28 19:43:08,672 Epoch[19] Batch [530]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116626,	
2017-07-28 19:43:14,484 Epoch[19] Batch [540]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117089,	
2017-07-28 19:43:20,284 Epoch[19] Batch [550]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117102,	
2017-07-28 19:43:26,112 Epoch[19] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117262,	
2017-07-28 19:43:31,991 Epoch[19] Batch [570]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.117273,	
2017-07-28 19:43:37,722 Epoch[19] Batch [580]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.117245,	
2017-07-28 19:43:43,516 Epoch[19] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117392,	
2017-07-28 19:43:49,294 Epoch[19] Batch [600]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117542,	
2017-07-28 19:43:55,102 Epoch[19] Batch [610]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.118006,	
2017-07-28 19:44:00,927 Epoch[19] Batch [620]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.118344,	
2017-07-28 19:44:06,721 Epoch[19] Batch [630]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118472,	
2017-07-28 19:44:12,526 Epoch[19] Batch [640]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.118642,	
2017-07-28 19:44:18,299 Epoch[19] Batch [650]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.118485,	
2017-07-28 19:44:24,110 Epoch[19] Batch [660]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118462,	
2017-07-28 19:44:29,907 Epoch[19] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118333,	
2017-07-28 19:44:35,695 Epoch[19] Batch [680]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118392,	
2017-07-28 19:44:41,486 Epoch[19] Batch [690]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118417,	
2017-07-28 19:44:47,276 Epoch[19] Batch [700]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118312,	
2017-07-28 19:44:53,112 Epoch[19] Batch [710]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118125,	
2017-07-28 19:44:58,887 Epoch[19] Batch [720]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.118107,	
2017-07-28 19:45:04,703 Epoch[19] Batch [730]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.118128,	
2017-07-28 19:45:10,457 Epoch[19] Batch [740]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.118180,	
2017-07-28 19:45:16,254 Epoch[19] Batch [750]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118013,	
2017-07-28 19:45:22,052 Epoch[19] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117889,	
2017-07-28 19:45:27,865 Epoch[19] Batch [770]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117974,	
2017-07-28 19:45:33,662 Epoch[19] Batch [780]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117758,	
2017-07-28 19:45:39,447 Epoch[19] Batch [790]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117680,	
2017-07-28 19:45:45,235 Epoch[19] Batch [800]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117576,	
2017-07-28 19:45:51,029 Epoch[19] Batch [810]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117398,	
2017-07-28 19:45:56,791 Epoch[19] Batch [820]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117464,	
2017-07-28 19:46:02,440 Epoch[19] Batch [830]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.117489,	
2017-07-28 19:46:08,158 Epoch[19] Batch [840]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.117477,	
2017-07-28 19:46:13,945 Epoch[19] Batch [850]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117411,	
2017-07-28 19:46:19,674 Epoch[19] Batch [860]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.117415,	
2017-07-28 19:46:25,501 Epoch[19] Batch [870]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117347,	
2017-07-28 19:46:31,265 Epoch[19] Batch [880]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117244,	
2017-07-28 19:46:37,085 Epoch[19] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117182,	
2017-07-28 19:46:42,850 Epoch[19] Batch [900]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117262,	
2017-07-28 19:46:48,659 Epoch[19] Batch [910]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117462,	
2017-07-28 19:46:54,432 Epoch[19] Batch [920]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117410,	
2017-07-28 19:47:00,259 Epoch[19] Batch [930]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117219,	
2017-07-28 19:47:06,030 Epoch[19] Batch [940]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117321,	
2017-07-28 19:47:11,812 Epoch[19] Batch [950]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117092,	
2017-07-28 19:47:17,588 Epoch[19] Batch [960]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117102,	
2017-07-28 19:47:23,343 Epoch[19] Batch [970]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.117178,	
2017-07-28 19:47:28,975 Epoch[19] Batch [980]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.116962,	
2017-07-28 19:47:34,756 Epoch[19] Batch [990]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117218,	
2017-07-28 19:47:40,467 Epoch[19] Batch [1000]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.117329,	
2017-07-28 19:47:46,248 Epoch[19] Batch [1010]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117413,	
2017-07-28 19:47:52,049 Epoch[19] Batch [1020]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117584,	
2017-07-28 19:47:57,818 Epoch[19] Batch [1030]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117588,	
2017-07-28 19:48:03,642 Epoch[19] Batch [1040]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117641,	
2017-07-28 19:48:09,461 Epoch[19] Batch [1050]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117508,	
2017-07-28 19:48:15,205 Epoch[19] Batch [1060]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.117531,	
2017-07-28 19:48:21,001 Epoch[19] Batch [1070]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117463,	
2017-07-28 19:48:26,844 Epoch[19] Batch [1080]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.117301,	
2017-07-28 19:48:32,631 Epoch[19] Batch [1090]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117356,	
2017-07-28 19:48:38,448 Epoch[19] Batch [1100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117217,	
2017-07-28 19:48:44,209 Epoch[19] Batch [1110]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117178,	
2017-07-28 19:48:50,016 Epoch[19] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117120,	
2017-07-28 19:48:55,856 Epoch[19] Batch [1130]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.117081,	
2017-07-28 19:49:01,627 Epoch[19] Batch [1140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117041,	
2017-07-28 19:49:07,438 Epoch[19] Batch [1150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117072,	
2017-07-28 19:49:13,248 Epoch[19] Batch [1160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117073,	
2017-07-28 19:49:19,014 Epoch[19] Batch [1170]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117100,	
2017-07-28 19:49:24,817 Epoch[19] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117156,	
2017-07-28 19:49:30,634 Epoch[19] Batch [1190]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117148,	
2017-07-28 19:49:36,421 Epoch[19] Batch [1200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.117272,	
2017-07-28 19:49:42,225 Epoch[19] Batch [1210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117270,	
2017-07-28 19:49:48,041 Epoch[19] Batch [1220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117347,	
2017-07-28 19:49:53,820 Epoch[19] Batch [1230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117340,	
2017-07-28 19:49:59,625 Epoch[19] Batch [1240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117249,	
2017-07-28 19:50:05,423 Epoch[19] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117295,	
2017-07-28 19:50:11,222 Epoch[19] Batch [1260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117197,	
2017-07-28 19:50:17,091 Epoch[19] Batch [1270]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.117119,	
2017-07-28 19:50:22,823 Epoch[19] Batch [1280]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.116974,	
2017-07-28 19:50:28,603 Epoch[19] Batch [1290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116995,	
2017-07-28 19:50:34,424 Epoch[19] Batch [1300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117031,	
2017-07-28 19:50:40,218 Epoch[19] Batch [1310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117017,	
2017-07-28 19:50:46,019 Epoch[19] Batch [1320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116986,	
2017-07-28 19:50:51,825 Epoch[19] Batch [1330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116949,	
2017-07-28 19:50:57,615 Epoch[19] Batch [1340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116950,	
2017-07-28 19:51:03,410 Epoch[19] Batch [1350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116988,	
2017-07-28 19:51:09,213 Epoch[19] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116955,	
2017-07-28 19:51:15,067 Epoch[19] Batch [1370]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.116974,	
2017-07-28 19:51:20,853 Epoch[19] Batch [1380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116856,	
2017-07-28 19:51:26,608 Epoch[19] Batch [1390]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116732,	
2017-07-28 19:51:32,387 Epoch[19] Batch [1400]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116648,	
2017-07-28 19:51:38,286 Epoch[19] Batch [1410]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.116650,	
2017-07-28 19:51:44,063 Epoch[19] Batch [1420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116576,	
2017-07-28 19:51:49,846 Epoch[19] Batch [1430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116457,	
2017-07-28 19:51:55,639 Epoch[19] Batch [1440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116373,	
2017-07-28 19:52:01,448 Epoch[19] Batch [1450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116263,	
2017-07-28 19:52:07,409 Epoch[19] Batch [1460]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.116102,	
2017-07-28 19:52:13,064 Epoch[19] Batch [1470]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.116123,	
2017-07-28 19:52:18,909 Epoch[19] Batch [1480]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116189,	
2017-07-28 19:52:22,388 Epoch[19] Train-FCNLogLoss=0.116282
2017-07-28 19:52:22,388 Epoch[19] Time cost=858.608
2017-07-28 19:52:23,427 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0020.params"
2017-07-28 19:52:27,046 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0020.states"
2017-07-28 19:52:33,666 Epoch[20] Batch [10]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.099788,	
2017-07-28 19:52:39,481 Epoch[20] Batch [20]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109251,	
2017-07-28 19:52:45,302 Epoch[20] Batch [30]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114045,	
2017-07-28 19:52:51,100 Epoch[20] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114354,	
2017-07-28 19:52:56,893 Epoch[20] Batch [50]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115428,	
2017-07-28 19:53:02,693 Epoch[20] Batch [60]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113859,	
2017-07-28 19:53:08,530 Epoch[20] Batch [70]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.114229,	
2017-07-28 19:53:14,338 Epoch[20] Batch [80]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111993,	
2017-07-28 19:53:20,112 Epoch[20] Batch [90]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110842,	
2017-07-28 19:53:25,903 Epoch[20] Batch [100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111432,	
2017-07-28 19:53:31,753 Epoch[20] Batch [110]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.111706,	
2017-07-28 19:53:37,564 Epoch[20] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111187,	
2017-07-28 19:53:43,385 Epoch[20] Batch [130]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111459,	
2017-07-28 19:53:49,175 Epoch[20] Batch [140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111539,	
2017-07-28 19:53:54,925 Epoch[20] Batch [150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.110761,	
2017-07-28 19:54:00,659 Epoch[20] Batch [160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.111171,	
2017-07-28 19:54:06,379 Epoch[20] Batch [170]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.110891,	
2017-07-28 19:54:12,290 Epoch[20] Batch [180]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.110964,	
2017-07-28 19:54:17,996 Epoch[20] Batch [190]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.110511,	
2017-07-28 19:54:23,768 Epoch[20] Batch [200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110850,	
2017-07-28 19:54:29,567 Epoch[20] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110570,	
2017-07-28 19:54:35,260 Epoch[20] Batch [220]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.111044,	
2017-07-28 19:54:41,050 Epoch[20] Batch [230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111065,	
2017-07-28 19:54:46,875 Epoch[20] Batch [240]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.111075,	
2017-07-28 19:54:52,666 Epoch[20] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110929,	
2017-07-28 19:54:58,484 Epoch[20] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111302,	
2017-07-28 19:55:04,273 Epoch[20] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110904,	
2017-07-28 19:55:10,148 Epoch[20] Batch [280]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.110857,	
2017-07-28 19:55:15,994 Epoch[20] Batch [290]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.110952,	
2017-07-28 19:55:21,753 Epoch[20] Batch [300]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.111977,	
2017-07-28 19:55:27,473 Epoch[20] Batch [310]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.112451,	
2017-07-28 19:55:33,325 Epoch[20] Batch [320]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113090,	
2017-07-28 19:55:39,092 Epoch[20] Batch [330]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113341,	
2017-07-28 19:55:44,916 Epoch[20] Batch [340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113334,	
2017-07-28 19:55:50,671 Epoch[20] Batch [350]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113146,	
2017-07-28 19:55:56,426 Epoch[20] Batch [360]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113035,	
2017-07-28 19:56:02,196 Epoch[20] Batch [370]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.112776,	
2017-07-28 19:56:08,071 Epoch[20] Batch [380]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.112738,	
2017-07-28 19:56:13,849 Epoch[20] Batch [390]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112808,	
2017-07-28 19:56:18,679 Epoch[20] Batch [400]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.113021,	
2017-07-28 19:56:24,194 Epoch[20] Batch [410]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.113039,	
2017-07-28 19:56:29,969 Epoch[20] Batch [420]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113008,	
2017-07-28 19:56:35,661 Epoch[20] Batch [430]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.112649,	
2017-07-28 19:56:41,556 Epoch[20] Batch [440]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.112720,	
2017-07-28 19:56:47,246 Epoch[20] Batch [450]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.112781,	
2017-07-28 19:56:53,075 Epoch[20] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.112816,	
2017-07-28 19:56:58,835 Epoch[20] Batch [470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.112998,	
2017-07-28 19:57:04,722 Epoch[20] Batch [480]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.113013,	
2017-07-28 19:57:10,415 Epoch[20] Batch [490]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.112823,	
2017-07-28 19:57:16,222 Epoch[20] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112630,	
2017-07-28 19:57:22,063 Epoch[20] Batch [510]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.112494,	
2017-07-28 19:57:27,885 Epoch[20] Batch [520]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112362,	
2017-07-28 19:57:33,678 Epoch[20] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112401,	
2017-07-28 19:57:39,424 Epoch[20] Batch [540]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.112374,	
2017-07-28 19:57:45,246 Epoch[20] Batch [550]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112261,	
2017-07-28 19:57:51,099 Epoch[20] Batch [560]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.112173,	
2017-07-28 19:57:56,836 Epoch[20] Batch [570]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.112210,	
2017-07-28 19:58:02,731 Epoch[20] Batch [580]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.112158,	
2017-07-28 19:58:08,527 Epoch[20] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111948,	
2017-07-28 19:58:14,276 Epoch[20] Batch [600]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.112095,	
2017-07-28 19:58:20,127 Epoch[20] Batch [610]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.111967,	
2017-07-28 19:58:25,964 Epoch[20] Batch [620]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.111686,	
2017-07-28 19:58:31,682 Epoch[20] Batch [630]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.111595,	
2017-07-28 19:58:37,566 Epoch[20] Batch [640]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.111755,	
2017-07-28 19:58:43,281 Epoch[20] Batch [650]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.111830,	
2017-07-28 19:58:49,102 Epoch[20] Batch [660]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112162,	
2017-07-28 19:58:54,875 Epoch[20] Batch [670]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113685,	
2017-07-28 19:59:00,741 Epoch[20] Batch [680]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113886,	
2017-07-28 19:59:06,687 Epoch[20] Batch [690]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.114064,	
2017-07-28 19:59:12,443 Epoch[20] Batch [700]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.114391,	
2017-07-28 19:59:18,229 Epoch[20] Batch [710]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114955,	
2017-07-28 19:59:24,086 Epoch[20] Batch [720]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.115065,	
2017-07-28 19:59:29,714 Epoch[20] Batch [730]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.115324,	
2017-07-28 19:59:35,530 Epoch[20] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115639,	
2017-07-28 19:59:41,302 Epoch[20] Batch [750]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.115539,	
2017-07-28 19:59:47,102 Epoch[20] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115716,	
2017-07-28 19:59:53,053 Epoch[20] Batch [770]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.115648,	
2017-07-28 19:59:58,873 Epoch[20] Batch [780]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115714,	
2017-07-28 20:00:04,634 Epoch[20] Batch [790]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115725,	
2017-07-28 20:00:10,423 Epoch[20] Batch [800]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115690,	
2017-07-28 20:00:16,244 Epoch[20] Batch [810]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115760,	
2017-07-28 20:00:22,018 Epoch[20] Batch [820]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.115783,	
2017-07-28 20:00:27,761 Epoch[20] Batch [830]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.116114,	
2017-07-28 20:00:33,674 Epoch[20] Batch [840]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.116093,	
2017-07-28 20:00:39,393 Epoch[20] Batch [850]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.116041,	
2017-07-28 20:00:45,158 Epoch[20] Batch [860]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115879,	
2017-07-28 20:00:50,978 Epoch[20] Batch [870]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115942,	
2017-07-28 20:00:56,774 Epoch[20] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115911,	
2017-07-28 20:01:02,610 Epoch[20] Batch [890]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115949,	
2017-07-28 20:01:08,387 Epoch[20] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115961,	
2017-07-28 20:01:14,186 Epoch[20] Batch [910]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116024,	
2017-07-28 20:01:20,035 Epoch[20] Batch [920]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116148,	
2017-07-28 20:01:25,799 Epoch[20] Batch [930]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116197,	
2017-07-28 20:01:31,591 Epoch[20] Batch [940]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116175,	
2017-07-28 20:01:37,369 Epoch[20] Batch [950]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116150,	
2017-07-28 20:01:43,182 Epoch[20] Batch [960]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116200,	
2017-07-28 20:01:49,010 Epoch[20] Batch [970]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.116091,	
2017-07-28 20:01:54,911 Epoch[20] Batch [980]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.116132,	
2017-07-28 20:02:00,634 Epoch[20] Batch [990]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.116001,	
2017-07-28 20:02:06,431 Epoch[20] Batch [1000]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116072,	
2017-07-28 20:02:12,223 Epoch[20] Batch [1010]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116004,	
2017-07-28 20:02:18,050 Epoch[20] Batch [1020]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115957,	
2017-07-28 20:02:23,890 Epoch[20] Batch [1030]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116083,	
2017-07-28 20:02:29,683 Epoch[20] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116120,	
2017-07-28 20:02:35,522 Epoch[20] Batch [1050]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116024,	
2017-07-28 20:02:41,331 Epoch[20] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115931,	
2017-07-28 20:02:47,080 Epoch[20] Batch [1070]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.115825,	
2017-07-28 20:02:52,876 Epoch[20] Batch [1080]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115902,	
2017-07-28 20:02:58,697 Epoch[20] Batch [1090]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115785,	
2017-07-28 20:03:04,476 Epoch[20] Batch [1100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115878,	
2017-07-28 20:03:10,307 Epoch[20] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.115967,	
2017-07-28 20:03:16,070 Epoch[20] Batch [1120]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116114,	
2017-07-28 20:03:21,890 Epoch[20] Batch [1130]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116217,	
2017-07-28 20:03:27,664 Epoch[20] Batch [1140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116178,	
2017-07-28 20:03:33,486 Epoch[20] Batch [1150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116224,	
2017-07-28 20:03:39,299 Epoch[20] Batch [1160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116189,	
2017-07-28 20:03:45,091 Epoch[20] Batch [1170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116150,	
2017-07-28 20:03:50,901 Epoch[20] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116195,	
2017-07-28 20:03:56,682 Epoch[20] Batch [1190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116198,	
2017-07-28 20:04:02,472 Epoch[20] Batch [1200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116207,	
2017-07-28 20:04:08,285 Epoch[20] Batch [1210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116286,	
2017-07-28 20:04:14,121 Epoch[20] Batch [1220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116179,	
2017-07-28 20:04:19,921 Epoch[20] Batch [1230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116271,	
2017-07-28 20:04:25,698 Epoch[20] Batch [1240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116181,	
2017-07-28 20:04:31,462 Epoch[20] Batch [1250]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116523,	
2017-07-28 20:04:37,307 Epoch[20] Batch [1260]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116657,	
2017-07-28 20:04:43,186 Epoch[20] Batch [1270]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.116791,	
2017-07-28 20:04:48,899 Epoch[20] Batch [1280]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.116834,	
2017-07-28 20:04:54,686 Epoch[20] Batch [1290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116875,	
2017-07-28 20:05:00,506 Epoch[20] Batch [1300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116954,	
2017-07-28 20:05:06,307 Epoch[20] Batch [1310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117067,	
2017-07-28 20:05:12,132 Epoch[20] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116995,	
2017-07-28 20:05:17,970 Epoch[20] Batch [1330]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.117012,	
2017-07-28 20:05:23,739 Epoch[20] Batch [1340]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117130,	
2017-07-28 20:05:29,521 Epoch[20] Batch [1350]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117116,	
2017-07-28 20:05:35,355 Epoch[20] Batch [1360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117117,	
2017-07-28 20:05:41,185 Epoch[20] Batch [1370]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117057,	
2017-07-28 20:05:46,938 Epoch[20] Batch [1380]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116962,	
2017-07-28 20:05:52,754 Epoch[20] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116867,	
2017-07-28 20:05:58,563 Epoch[20] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116869,	
2017-07-28 20:06:04,318 Epoch[20] Batch [1410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116855,	
2017-07-28 20:06:10,107 Epoch[20] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116847,	
2017-07-28 20:06:15,911 Epoch[20] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116799,	
2017-07-28 20:06:21,731 Epoch[20] Batch [1440]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.116877,	
2017-07-28 20:06:27,511 Epoch[20] Batch [1450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116750,	
2017-07-28 20:06:33,363 Epoch[20] Batch [1460]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116802,	
2017-07-28 20:06:39,152 Epoch[20] Batch [1470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116849,	
2017-07-28 20:06:44,921 Epoch[20] Batch [1480]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116881,	
2017-07-28 20:06:48,380 Epoch[20] Train-FCNLogLoss=0.116817
2017-07-28 20:06:48,380 Epoch[20] Time cost=861.333
2017-07-28 20:06:49,640 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0021.params"
2017-07-28 20:06:53,463 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0021.states"
2017-07-28 20:07:00,000 Epoch[21] Batch [10]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.140571,	
2017-07-28 20:07:05,758 Epoch[21] Batch [20]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.132528,	
2017-07-28 20:07:11,502 Epoch[21] Batch [30]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.124484,	
2017-07-28 20:07:17,317 Epoch[21] Batch [40]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.120068,	
2017-07-28 20:07:23,223 Epoch[21] Batch [50]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.117819,	
2017-07-28 20:07:28,945 Epoch[21] Batch [60]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.117725,	
2017-07-28 20:07:34,713 Epoch[21] Batch [70]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116180,	
2017-07-28 20:07:40,555 Epoch[21] Batch [80]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116091,	
2017-07-28 20:07:46,361 Epoch[21] Batch [90]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115301,	
2017-07-28 20:07:52,199 Epoch[21] Batch [100]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115741,	
2017-07-28 20:07:58,007 Epoch[21] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116223,	
2017-07-28 20:08:03,774 Epoch[21] Batch [120]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116395,	
2017-07-28 20:08:09,721 Epoch[21] Batch [130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.117299,	
2017-07-28 20:08:15,439 Epoch[21] Batch [140]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.116763,	
2017-07-28 20:08:21,234 Epoch[21] Batch [150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115617,	
2017-07-28 20:08:27,071 Epoch[21] Batch [160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115438,	
2017-07-28 20:08:32,847 Epoch[21] Batch [170]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116205,	
2017-07-28 20:08:38,647 Epoch[21] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116110,	
2017-07-28 20:08:44,438 Epoch[21] Batch [190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116755,	
2017-07-28 20:08:50,296 Epoch[21] Batch [200]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.116485,	
2017-07-28 20:08:56,143 Epoch[21] Batch [210]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116760,	
2017-07-28 20:09:01,888 Epoch[21] Batch [220]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.117447,	
2017-07-28 20:09:07,691 Epoch[21] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117297,	
2017-07-28 20:09:13,536 Epoch[21] Batch [240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.117334,	
2017-07-28 20:09:19,365 Epoch[21] Batch [250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117372,	
2017-07-28 20:09:25,159 Epoch[21] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117250,	
2017-07-28 20:09:30,961 Epoch[21] Batch [270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117019,	
2017-07-28 20:09:36,757 Epoch[21] Batch [280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117090,	
2017-07-28 20:09:42,547 Epoch[21] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116730,	
2017-07-28 20:09:48,384 Epoch[21] Batch [300]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116436,	
2017-07-28 20:09:54,287 Epoch[21] Batch [310]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.116204,	
2017-07-28 20:10:00,059 Epoch[21] Batch [320]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116318,	
2017-07-28 20:10:05,798 Epoch[21] Batch [330]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.116278,	
2017-07-28 20:10:11,613 Epoch[21] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115912,	
2017-07-28 20:10:17,433 Epoch[21] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115535,	
2017-07-28 20:10:23,234 Epoch[21] Batch [360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115415,	
2017-07-28 20:10:29,030 Epoch[21] Batch [370]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115252,	
2017-07-28 20:10:34,849 Epoch[21] Batch [380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114862,	
2017-07-28 20:10:40,513 Epoch[21] Batch [390]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.114486,	
2017-07-28 20:10:45,417 Epoch[21] Batch [400]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.114273,	
2017-07-28 20:10:51,252 Epoch[21] Batch [410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.114385,	
2017-07-28 20:10:57,000 Epoch[21] Batch [420]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.114825,	
2017-07-28 20:11:02,831 Epoch[21] Batch [430]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.114855,	
2017-07-28 20:11:08,682 Epoch[21] Batch [440]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.115375,	
2017-07-28 20:11:14,467 Epoch[21] Batch [450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115658,	
2017-07-28 20:11:20,256 Epoch[21] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115649,	
2017-07-28 20:11:26,055 Epoch[21] Batch [470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115690,	
2017-07-28 20:11:31,958 Epoch[21] Batch [480]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.115870,	
2017-07-28 20:11:37,507 Epoch[21] Batch [490]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.116010,	
2017-07-28 20:11:43,261 Epoch[21] Batch [500]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.115952,	
2017-07-28 20:11:49,008 Epoch[21] Batch [510]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.115969,	
2017-07-28 20:11:54,758 Epoch[21] Batch [520]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.115947,	
2017-07-28 20:12:00,632 Epoch[21] Batch [530]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.115716,	
2017-07-28 20:12:06,363 Epoch[21] Batch [540]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.115578,	
2017-07-28 20:12:12,140 Epoch[21] Batch [550]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115226,	
2017-07-28 20:12:17,961 Epoch[21] Batch [560]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.115063,	
2017-07-28 20:12:23,789 Epoch[21] Batch [570]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.115041,	
2017-07-28 20:12:29,606 Epoch[21] Batch [580]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114733,	
2017-07-28 20:12:35,328 Epoch[21] Batch [590]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.114904,	
2017-07-28 20:12:41,144 Epoch[21] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114837,	
2017-07-28 20:12:47,083 Epoch[21] Batch [610]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.114845,	
2017-07-28 20:12:52,926 Epoch[21] Batch [620]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.114645,	
2017-07-28 20:12:58,621 Epoch[21] Batch [630]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.114643,	
2017-07-28 20:13:04,414 Epoch[21] Batch [640]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114510,	
2017-07-28 20:13:10,310 Epoch[21] Batch [650]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.114409,	
2017-07-28 20:13:16,014 Epoch[21] Batch [660]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.114392,	
2017-07-28 20:13:21,828 Epoch[21] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114053,	
2017-07-28 20:13:27,598 Epoch[21] Batch [680]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113977,	
2017-07-28 20:13:33,409 Epoch[21] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114115,	
2017-07-28 20:13:39,273 Epoch[21] Batch [700]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113981,	
2017-07-28 20:13:45,058 Epoch[21] Batch [710]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113844,	
2017-07-28 20:13:50,850 Epoch[21] Batch [720]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113755,	
2017-07-28 20:13:56,597 Epoch[21] Batch [730]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.113612,	
2017-07-28 20:14:02,472 Epoch[21] Batch [740]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.113641,	
2017-07-28 20:14:08,300 Epoch[21] Batch [750]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113600,	
2017-07-28 20:14:14,088 Epoch[21] Batch [760]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113393,	
2017-07-28 20:14:19,879 Epoch[21] Batch [770]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113378,	
2017-07-28 20:14:25,694 Epoch[21] Batch [780]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113241,	
2017-07-28 20:14:31,486 Epoch[21] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113179,	
2017-07-28 20:14:37,243 Epoch[21] Batch [800]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113206,	
2017-07-28 20:14:43,074 Epoch[21] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113223,	
2017-07-28 20:14:48,867 Epoch[21] Batch [820]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113074,	
2017-07-28 20:14:54,695 Epoch[21] Batch [830]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112992,	
2017-07-28 20:15:00,536 Epoch[21] Batch [840]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.112877,	
2017-07-28 20:15:06,293 Epoch[21] Batch [850]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.112876,	
2017-07-28 20:15:12,117 Epoch[21] Batch [860]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112828,	
2017-07-28 20:15:17,901 Epoch[21] Batch [870]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112884,	
2017-07-28 20:15:23,696 Epoch[21] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112854,	
2017-07-28 20:15:29,462 Epoch[21] Batch [890]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.112806,	
2017-07-28 20:15:35,318 Epoch[21] Batch [900]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.112886,	
2017-07-28 20:15:41,087 Epoch[21] Batch [910]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.112887,	
2017-07-28 20:15:46,919 Epoch[21] Batch [920]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.112922,	
2017-07-28 20:15:52,661 Epoch[21] Batch [930]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.112861,	
2017-07-28 20:15:58,481 Epoch[21] Batch [940]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113083,	
2017-07-28 20:16:04,270 Epoch[21] Batch [950]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113017,	
2017-07-28 20:16:10,083 Epoch[21] Batch [960]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113202,	
2017-07-28 20:16:15,906 Epoch[21] Batch [970]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113279,	
2017-07-28 20:16:21,750 Epoch[21] Batch [980]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113528,	
2017-07-28 20:16:27,531 Epoch[21] Batch [990]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113625,	
2017-07-28 20:16:33,324 Epoch[21] Batch [1000]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113793,	
2017-07-28 20:16:39,232 Epoch[21] Batch [1010]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.113830,	
2017-07-28 20:16:44,868 Epoch[21] Batch [1020]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.113956,	
2017-07-28 20:16:50,683 Epoch[21] Batch [1030]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114041,	
2017-07-28 20:16:56,517 Epoch[21] Batch [1040]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.114004,	
2017-07-28 20:17:02,321 Epoch[21] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114014,	
2017-07-28 20:17:08,085 Epoch[21] Batch [1060]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113909,	
2017-07-28 20:17:13,947 Epoch[21] Batch [1070]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.114085,	
2017-07-28 20:17:19,693 Epoch[21] Batch [1080]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.114100,	
2017-07-28 20:17:25,489 Epoch[21] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114015,	
2017-07-28 20:17:31,295 Epoch[21] Batch [1100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114063,	
2017-07-28 20:17:37,153 Epoch[21] Batch [1110]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.114018,	
2017-07-28 20:17:42,947 Epoch[21] Batch [1120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113993,	
2017-07-28 20:17:48,737 Epoch[21] Batch [1130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113946,	
2017-07-28 20:17:54,626 Epoch[21] Batch [1140]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.113821,	
2017-07-28 20:18:00,380 Epoch[21] Batch [1150]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113905,	
2017-07-28 20:18:06,131 Epoch[21] Batch [1160]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.113985,	
2017-07-28 20:18:12,026 Epoch[21] Batch [1170]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.114029,	
2017-07-28 20:18:17,833 Epoch[21] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114005,	
2017-07-28 20:18:23,607 Epoch[21] Batch [1190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.114007,	
2017-07-28 20:18:29,356 Epoch[21] Batch [1200]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.113824,	
2017-07-28 20:18:35,156 Epoch[21] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113882,	
2017-07-28 20:18:40,974 Epoch[21] Batch [1220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113936,	
2017-07-28 20:18:46,775 Epoch[21] Batch [1230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113966,	
2017-07-28 20:18:52,609 Epoch[21] Batch [1240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113877,	
2017-07-28 20:18:58,440 Epoch[21] Batch [1250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113877,	
2017-07-28 20:19:04,213 Epoch[21] Batch [1260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113808,	
2017-07-28 20:19:10,084 Epoch[21] Batch [1270]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.113819,	
2017-07-28 20:19:15,840 Epoch[21] Batch [1280]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113910,	
2017-07-28 20:19:21,650 Epoch[21] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113890,	
2017-07-28 20:19:37,964 Epoch[21] Batch [1300]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.113876,	
2017-07-28 20:19:50,814 Epoch[21] Batch [1310]	Speed: 3.11 samples/sec	Train-FCNLogLoss=0.113863,	
2017-07-28 20:20:05,877 Epoch[21] Batch [1320]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.113913,	
2017-07-28 20:20:21,258 Epoch[21] Batch [1330]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.113893,	
2017-07-28 20:20:38,660 Epoch[21] Batch [1340]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.113784,	
2017-07-28 20:20:54,687 Epoch[21] Batch [1350]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.113649,	
2017-07-28 20:21:11,367 Epoch[21] Batch [1360]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.113497,	
2017-07-28 20:21:27,346 Epoch[21] Batch [1370]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.113444,	
2017-07-28 20:21:43,950 Epoch[21] Batch [1380]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.113424,	
2017-07-28 20:21:59,903 Epoch[21] Batch [1390]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.113450,	
2017-07-28 20:22:17,294 Epoch[21] Batch [1400]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.113491,	
2017-07-28 20:22:34,851 Epoch[21] Batch [1410]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.113497,	
2017-07-28 20:22:51,582 Epoch[21] Batch [1420]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.113454,	
2017-07-28 20:23:04,706 Epoch[21] Batch [1430]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.113522,	
2017-07-28 20:23:19,450 Epoch[21] Batch [1440]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.113658,	
2017-07-28 20:23:33,962 Epoch[21] Batch [1450]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.113737,	
2017-07-28 20:23:51,234 Epoch[21] Batch [1460]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.113775,	
2017-07-28 20:24:06,059 Epoch[21] Batch [1470]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.113871,	
2017-07-28 20:24:20,931 Epoch[21] Batch [1480]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.113923,	
2017-07-28 20:24:30,023 Epoch[21] Train-FCNLogLoss=0.113928
2017-07-28 20:24:30,024 Epoch[21] Time cost=1056.560
2017-07-28 20:24:34,128 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0022.params"
2017-07-28 20:24:51,976 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0022.states"
2017-07-28 20:25:10,818 Epoch[22] Batch [10]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.100933,	
2017-07-28 20:25:24,129 Epoch[22] Batch [20]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.106658,	
2017-07-28 20:25:42,251 Epoch[22] Batch [30]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.107570,	
2017-07-28 20:25:57,269 Epoch[22] Batch [40]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.105876,	
2017-07-28 20:26:13,204 Epoch[22] Batch [50]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.105869,	
2017-07-28 20:26:28,742 Epoch[22] Batch [60]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.105332,	
2017-07-28 20:26:44,245 Epoch[22] Batch [70]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.105611,	
2017-07-28 20:26:59,466 Epoch[22] Batch [80]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.106930,	
2017-07-28 20:27:12,437 Epoch[22] Batch [90]	Speed: 3.08 samples/sec	Train-FCNLogLoss=0.106889,	
2017-07-28 20:27:28,478 Epoch[22] Batch [100]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.108301,	
2017-07-28 20:27:43,183 Epoch[22] Batch [110]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.108319,	
2017-07-28 20:27:59,111 Epoch[22] Batch [120]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.109657,	
2017-07-28 20:28:15,461 Epoch[22] Batch [130]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.110371,	
2017-07-28 20:28:29,865 Epoch[22] Batch [140]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.109972,	
2017-07-28 20:28:46,502 Epoch[22] Batch [150]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.110218,	
2017-07-28 20:29:02,015 Epoch[22] Batch [160]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.109845,	
2017-07-28 20:29:18,856 Epoch[22] Batch [170]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.109371,	
2017-07-28 20:29:29,612 Epoch[22] Batch [180]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.109642,	
2017-07-28 20:29:44,429 Epoch[22] Batch [190]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.109280,	
2017-07-28 20:29:59,925 Epoch[22] Batch [200]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.109003,	
2017-07-28 20:30:14,119 Epoch[22] Batch [210]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.108715,	
2017-07-28 20:30:30,736 Epoch[22] Batch [220]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.109396,	
2017-07-28 20:30:47,617 Epoch[22] Batch [230]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.109442,	
2017-07-28 20:31:01,723 Epoch[22] Batch [240]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.109478,	
2017-07-28 20:31:17,942 Epoch[22] Batch [250]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.109317,	
2017-07-28 20:31:34,398 Epoch[22] Batch [260]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.109037,	
2017-07-28 20:31:49,893 Epoch[22] Batch [270]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.109201,	
2017-07-28 20:32:05,981 Epoch[22] Batch [280]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.108816,	
2017-07-28 20:32:22,743 Epoch[22] Batch [290]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.109164,	
2017-07-28 20:32:40,741 Epoch[22] Batch [300]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.109232,	
2017-07-28 20:32:57,397 Epoch[22] Batch [310]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.109390,	
2017-07-28 20:33:12,230 Epoch[22] Batch [320]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.109753,	
2017-07-28 20:33:28,484 Epoch[22] Batch [330]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.111073,	
2017-07-28 20:33:46,880 Epoch[22] Batch [340]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.111344,	
2017-07-28 20:34:04,377 Epoch[22] Batch [350]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.111692,	
2017-07-28 20:34:19,695 Epoch[22] Batch [360]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.112166,	
2017-07-28 20:34:35,907 Epoch[22] Batch [370]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.112041,	
2017-07-28 20:34:50,209 Epoch[22] Batch [380]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.112248,	
2017-07-28 20:35:05,785 Epoch[22] Batch [390]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.112227,	
2017-07-28 20:35:24,611 Epoch[22] Batch [400]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.112012,	
2017-07-28 20:35:40,465 Epoch[22] Batch [410]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.112127,	
2017-07-28 20:35:56,397 Epoch[22] Batch [420]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.111955,	
2017-07-28 20:36:10,847 Epoch[22] Batch [430]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.112219,	
2017-07-28 20:36:19,008 Epoch[22] Batch [440]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.112193,	
2017-07-28 20:36:24,788 Epoch[22] Batch [450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112186,	
2017-07-28 20:36:30,596 Epoch[22] Batch [460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112578,	
2017-07-28 20:36:36,387 Epoch[22] Batch [470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112770,	
2017-07-28 20:36:42,203 Epoch[22] Batch [480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112836,	
2017-07-28 20:36:48,007 Epoch[22] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112794,	
2017-07-28 20:36:53,814 Epoch[22] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112863,	
2017-07-28 20:36:59,615 Epoch[22] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113354,	
2017-07-28 20:37:05,410 Epoch[22] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113445,	
2017-07-28 20:37:11,192 Epoch[22] Batch [530]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113730,	
2017-07-28 20:37:17,009 Epoch[22] Batch [540]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113809,	
2017-07-28 20:37:22,823 Epoch[22] Batch [550]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113722,	
2017-07-28 20:37:28,669 Epoch[22] Batch [560]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113587,	
2017-07-28 20:37:34,514 Epoch[22] Batch [570]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113649,	
2017-07-28 20:37:40,291 Epoch[22] Batch [580]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113405,	
2017-07-28 20:37:46,082 Epoch[22] Batch [590]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113485,	
2017-07-28 20:37:51,946 Epoch[22] Batch [600]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113673,	
2017-07-28 20:37:57,724 Epoch[22] Batch [610]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113665,	
2017-07-28 20:38:03,561 Epoch[22] Batch [620]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.113946,	
2017-07-28 20:38:09,300 Epoch[22] Batch [630]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.113766,	
2017-07-28 20:38:15,118 Epoch[22] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113792,	
2017-07-28 20:38:20,987 Epoch[22] Batch [650]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.114061,	
2017-07-28 20:38:26,777 Epoch[22] Batch [660]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114364,	
2017-07-28 20:38:32,539 Epoch[22] Batch [670]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.114652,	
2017-07-28 20:38:38,337 Epoch[22] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114671,	
2017-07-28 20:38:44,188 Epoch[22] Batch [690]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.114741,	
2017-07-28 20:38:49,951 Epoch[22] Batch [700]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115052,	
2017-07-28 20:38:55,762 Epoch[22] Batch [710]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115006,	
2017-07-28 20:39:01,534 Epoch[22] Batch [720]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.114842,	
2017-07-28 20:39:07,362 Epoch[22] Batch [730]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.114783,	
2017-07-28 20:39:13,154 Epoch[22] Batch [740]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114784,	
2017-07-28 20:39:18,995 Epoch[22] Batch [750]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115096,	
2017-07-28 20:39:24,809 Epoch[22] Batch [760]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115019,	
2017-07-28 20:39:30,665 Epoch[22] Batch [770]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.115050,	
2017-07-28 20:39:36,416 Epoch[22] Batch [780]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.114976,	
2017-07-28 20:39:41,586 Epoch[22] Batch [790]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.114807,	
2017-07-28 20:39:47,502 Epoch[22] Batch [800]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.114906,	
2017-07-28 20:39:53,338 Epoch[22] Batch [810]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115024,	
2017-07-28 20:39:59,144 Epoch[22] Batch [820]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114949,	
2017-07-28 20:40:04,923 Epoch[22] Batch [830]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114923,	
2017-07-28 20:40:10,773 Epoch[22] Batch [840]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.114632,	
2017-07-28 20:40:16,504 Epoch[22] Batch [850]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.114496,	
2017-07-28 20:40:22,418 Epoch[22] Batch [860]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.114592,	
2017-07-28 20:40:28,136 Epoch[22] Batch [870]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.114611,	
2017-07-28 20:40:34,023 Epoch[22] Batch [880]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.114487,	
2017-07-28 20:40:39,741 Epoch[22] Batch [890]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.114557,	
2017-07-28 20:40:45,539 Epoch[22] Batch [900]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114444,	
2017-07-28 20:40:51,337 Epoch[22] Batch [910]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114422,	
2017-07-28 20:40:57,137 Epoch[22] Batch [920]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114350,	
2017-07-28 20:41:02,955 Epoch[22] Batch [930]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114280,	
2017-07-28 20:41:08,732 Epoch[22] Batch [940]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114190,	
2017-07-28 20:41:14,532 Epoch[22] Batch [950]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114129,	
2017-07-28 20:41:20,394 Epoch[22] Batch [960]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.114170,	
2017-07-28 20:41:26,117 Epoch[22] Batch [970]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.113971,	
2017-07-28 20:41:31,906 Epoch[22] Batch [980]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113914,	
2017-07-28 20:41:37,735 Epoch[22] Batch [990]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113760,	
2017-07-28 20:41:43,501 Epoch[22] Batch [1000]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113685,	
2017-07-28 20:41:49,290 Epoch[22] Batch [1010]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113561,	
2017-07-28 20:41:55,083 Epoch[22] Batch [1020]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113477,	
2017-07-28 20:42:00,880 Epoch[22] Batch [1030]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113553,	
2017-07-28 20:42:06,700 Epoch[22] Batch [1040]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113456,	
2017-07-28 20:42:12,545 Epoch[22] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113573,	
2017-07-28 20:42:18,246 Epoch[22] Batch [1060]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.113473,	
2017-07-28 20:42:24,099 Epoch[22] Batch [1070]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113468,	
2017-07-28 20:42:29,935 Epoch[22] Batch [1080]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.113516,	
2017-07-28 20:42:35,640 Epoch[22] Batch [1090]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.113449,	
2017-07-28 20:42:41,502 Epoch[22] Batch [1100]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113323,	
2017-07-28 20:42:47,337 Epoch[22] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113309,	
2017-07-28 20:42:53,099 Epoch[22] Batch [1120]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113370,	
2017-07-28 20:42:58,912 Epoch[22] Batch [1130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113339,	
2017-07-28 20:43:04,827 Epoch[22] Batch [1140]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.113497,	
2017-07-28 20:43:10,541 Epoch[22] Batch [1150]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.113461,	
2017-07-28 20:43:16,353 Epoch[22] Batch [1160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113466,	
2017-07-28 20:43:22,161 Epoch[22] Batch [1170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113528,	
2017-07-28 20:43:27,951 Epoch[22] Batch [1180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113480,	
2017-07-28 20:43:33,801 Epoch[22] Batch [1190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113474,	
2017-07-28 20:43:39,555 Epoch[22] Batch [1200]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113409,	
2017-07-28 20:43:45,335 Epoch[22] Batch [1210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113377,	
2017-07-28 20:43:51,184 Epoch[22] Batch [1220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113213,	
2017-07-28 20:43:56,962 Epoch[22] Batch [1230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113168,	
2017-07-28 20:44:02,748 Epoch[22] Batch [1240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113115,	
2017-07-28 20:44:08,563 Epoch[22] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113132,	
2017-07-28 20:44:14,349 Epoch[22] Batch [1260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113013,	
2017-07-28 20:44:20,214 Epoch[22] Batch [1270]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.112988,	
2017-07-28 20:44:25,952 Epoch[22] Batch [1280]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.113055,	
2017-07-28 20:44:31,755 Epoch[22] Batch [1290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113050,	
2017-07-28 20:44:37,543 Epoch[22] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113145,	
2017-07-28 20:44:43,361 Epoch[22] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113179,	
2017-07-28 20:44:49,181 Epoch[22] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113247,	
2017-07-28 20:44:54,937 Epoch[22] Batch [1330]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113234,	
2017-07-28 20:45:00,738 Epoch[22] Batch [1340]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113226,	
2017-07-28 20:45:06,587 Epoch[22] Batch [1350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113149,	
2017-07-28 20:45:12,415 Epoch[22] Batch [1360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.113244,	
2017-07-28 20:45:18,181 Epoch[22] Batch [1370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113258,	
2017-07-28 20:45:24,051 Epoch[22] Batch [1380]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.113284,	
2017-07-28 20:45:29,916 Epoch[22] Batch [1390]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113260,	
2017-07-28 20:45:35,642 Epoch[22] Batch [1400]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.113271,	
2017-07-28 20:45:41,211 Epoch[22] Batch [1410]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.113260,	
2017-07-28 20:45:46,997 Epoch[22] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113151,	
2017-07-28 20:45:52,783 Epoch[22] Batch [1430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113064,	
2017-07-28 20:45:58,479 Epoch[22] Batch [1440]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.113054,	
2017-07-28 20:46:04,431 Epoch[22] Batch [1450]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.113074,	
2017-07-28 20:46:10,126 Epoch[22] Batch [1460]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.113000,	
2017-07-28 20:46:15,957 Epoch[22] Batch [1470]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.112885,	
2017-07-28 20:46:21,791 Epoch[22] Batch [1480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.112815,	
2017-07-28 20:46:25,233 Epoch[22] Train-FCNLogLoss=0.112731
2017-07-28 20:46:25,234 Epoch[22] Time cost=1293.257
2017-07-28 20:46:26,541 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0023.params"
2017-07-28 20:46:30,298 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0023.states"
2017-07-28 20:46:36,805 Epoch[23] Batch [10]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.102051,	
2017-07-28 20:46:42,617 Epoch[23] Batch [20]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.114564,	
2017-07-28 20:46:48,476 Epoch[23] Batch [30]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.113424,	
2017-07-28 20:46:54,221 Epoch[23] Batch [40]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.111401,	
2017-07-28 20:47:00,027 Epoch[23] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108404,	
2017-07-28 20:47:05,737 Epoch[23] Batch [60]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.106768,	
2017-07-28 20:47:11,592 Epoch[23] Batch [70]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107859,	
2017-07-28 20:47:17,389 Epoch[23] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117487,	
2017-07-28 20:47:23,164 Epoch[23] Batch [90]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120884,	
2017-07-28 20:47:28,997 Epoch[23] Batch [100]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.127353,	
2017-07-28 20:47:34,799 Epoch[23] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.129339,	
2017-07-28 20:47:40,599 Epoch[23] Batch [120]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131387,	
2017-07-28 20:47:46,397 Epoch[23] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.131213,	
2017-07-28 20:47:52,253 Epoch[23] Batch [140]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.129855,	
2017-07-28 20:47:58,030 Epoch[23] Batch [150]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.129671,	
2017-07-28 20:48:03,827 Epoch[23] Batch [160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.128352,	
2017-07-28 20:48:09,631 Epoch[23] Batch [170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.127332,	
2017-07-28 20:48:15,398 Epoch[23] Batch [180]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.126393,	
2017-07-28 20:48:21,301 Epoch[23] Batch [190]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.125484,	
2017-07-28 20:48:27,067 Epoch[23] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.124888,	
2017-07-28 20:48:32,829 Epoch[23] Batch [210]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.124958,	
2017-07-28 20:48:38,654 Epoch[23] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.123971,	
2017-07-28 20:48:44,446 Epoch[23] Batch [230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123135,	
2017-07-28 20:48:50,287 Epoch[23] Batch [240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122515,	
2017-07-28 20:48:56,100 Epoch[23] Batch [250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121767,	
2017-07-28 20:49:01,805 Epoch[23] Batch [260]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.121448,	
2017-07-28 20:49:07,702 Epoch[23] Batch [270]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.120774,	
2017-07-28 20:49:13,487 Epoch[23] Batch [280]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.120091,	
2017-07-28 20:49:19,303 Epoch[23] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.119495,	
2017-07-28 20:49:25,129 Epoch[23] Batch [300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.119050,	
2017-07-28 20:49:30,908 Epoch[23] Batch [310]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.119086,	
2017-07-28 20:49:36,761 Epoch[23] Batch [320]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.118464,	
2017-07-28 20:49:42,553 Epoch[23] Batch [330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.118052,	
2017-07-28 20:49:48,315 Epoch[23] Batch [340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117873,	
2017-07-28 20:49:54,108 Epoch[23] Batch [350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117757,	
2017-07-28 20:49:59,932 Epoch[23] Batch [360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117620,	
2017-07-28 20:50:05,764 Epoch[23] Batch [370]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117456,	
2017-07-28 20:50:11,633 Epoch[23] Batch [380]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.117282,	
2017-07-28 20:50:17,403 Epoch[23] Batch [390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117252,	
2017-07-28 20:50:23,201 Epoch[23] Batch [400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117339,	
2017-07-28 20:50:28,970 Epoch[23] Batch [410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.117477,	
2017-07-28 20:50:34,818 Epoch[23] Batch [420]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.117357,	
2017-07-28 20:50:40,569 Epoch[23] Batch [430]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.117383,	
2017-07-28 20:50:46,415 Epoch[23] Batch [440]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.117308,	
2017-07-28 20:50:52,597 Epoch[23] Batch [450]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.116914,	
2017-07-28 20:50:58,426 Epoch[23] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.117048,	
2017-07-28 20:51:04,224 Epoch[23] Batch [470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117288,	
2017-07-28 20:51:10,043 Epoch[23] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117594,	
2017-07-28 20:51:15,798 Epoch[23] Batch [490]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.117788,	
2017-07-28 20:51:21,580 Epoch[23] Batch [500]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.117979,	
2017-07-28 20:51:27,333 Epoch[23] Batch [510]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.117953,	
2017-07-28 20:51:33,141 Epoch[23] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117877,	
2017-07-28 20:51:39,001 Epoch[23] Batch [530]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.117581,	
2017-07-28 20:51:44,700 Epoch[23] Batch [540]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.117505,	
2017-07-28 20:51:50,517 Epoch[23] Batch [550]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117241,	
2017-07-28 20:51:56,364 Epoch[23] Batch [560]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.117346,	
2017-07-28 20:52:02,162 Epoch[23] Batch [570]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.117471,	
2017-07-28 20:52:07,888 Epoch[23] Batch [580]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.117429,	
2017-07-28 20:52:13,647 Epoch[23] Batch [590]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.117106,	
2017-07-28 20:52:19,483 Epoch[23] Batch [600]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116996,	
2017-07-28 20:52:25,260 Epoch[23] Batch [610]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.116784,	
2017-07-28 20:52:31,123 Epoch[23] Batch [620]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.116655,	
2017-07-28 20:52:36,826 Epoch[23] Batch [630]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.116581,	
2017-07-28 20:52:42,634 Epoch[23] Batch [640]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116970,	
2017-07-28 20:52:48,480 Epoch[23] Batch [650]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.117000,	
2017-07-28 20:52:54,284 Epoch[23] Batch [660]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117012,	
2017-07-28 20:53:00,048 Epoch[23] Batch [670]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.116978,	
2017-07-28 20:53:05,795 Epoch[23] Batch [680]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.117108,	
2017-07-28 20:53:11,669 Epoch[23] Batch [690]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.117086,	
2017-07-28 20:53:17,334 Epoch[23] Batch [700]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.116957,	
2017-07-28 20:53:23,102 Epoch[23] Batch [710]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116891,	
2017-07-28 20:53:28,899 Epoch[23] Batch [720]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.116613,	
2017-07-28 20:53:34,690 Epoch[23] Batch [730]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.116686,	
2017-07-28 20:53:40,527 Epoch[23] Batch [740]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116572,	
2017-07-28 20:53:46,367 Epoch[23] Batch [750]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.116600,	
2017-07-28 20:53:52,098 Epoch[23] Batch [760]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.116431,	
2017-07-28 20:53:57,856 Epoch[23] Batch [770]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.116317,	
2017-07-28 20:54:03,670 Epoch[23] Batch [780]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.116357,	
2017-07-28 20:54:08,347 Epoch[23] Batch [790]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.116339,	
2017-07-28 20:54:14,620 Epoch[23] Batch [800]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.116173,	
2017-07-28 20:54:20,684 Epoch[23] Batch [810]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.115965,	
2017-07-28 20:54:26,350 Epoch[23] Batch [820]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.115856,	
2017-07-28 20:54:32,042 Epoch[23] Batch [830]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.115951,	
2017-07-28 20:54:37,818 Epoch[23] Batch [840]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.115874,	
2017-07-28 20:54:43,597 Epoch[23] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115719,	
2017-07-28 20:54:49,411 Epoch[23] Batch [860]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115723,	
2017-07-28 20:54:55,194 Epoch[23] Batch [870]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.115620,	
2017-07-28 20:55:01,491 Epoch[23] Batch [880]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.115428,	
2017-07-28 20:55:07,566 Epoch[23] Batch [890]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115288,	
2017-07-28 20:55:13,734 Epoch[23] Batch [900]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.115287,	
2017-07-28 20:55:19,543 Epoch[23] Batch [910]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.115164,	
2017-07-28 20:55:25,406 Epoch[23] Batch [920]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.115182,	
2017-07-28 20:55:31,094 Epoch[23] Batch [930]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.115228,	
2017-07-28 20:55:36,937 Epoch[23] Batch [940]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115176,	
2017-07-28 20:55:42,694 Epoch[23] Batch [950]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.115126,	
2017-07-28 20:55:48,441 Epoch[23] Batch [960]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.115073,	
2017-07-28 20:55:54,235 Epoch[23] Batch [970]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.115034,	
2017-07-28 20:56:00,085 Epoch[23] Batch [980]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.115020,	
2017-07-28 20:56:05,880 Epoch[23] Batch [990]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114944,	
2017-07-28 20:56:11,631 Epoch[23] Batch [1000]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.114837,	
2017-07-28 20:56:17,422 Epoch[23] Batch [1010]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114740,	
2017-07-28 20:56:23,241 Epoch[23] Batch [1020]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114624,	
2017-07-28 20:56:29,029 Epoch[23] Batch [1030]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.114658,	
2017-07-28 20:56:34,868 Epoch[23] Batch [1040]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.114578,	
2017-07-28 20:56:40,688 Epoch[23] Batch [1050]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.114565,	
2017-07-28 20:56:46,460 Epoch[23] Batch [1060]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.114457,	
2017-07-28 20:56:52,338 Epoch[23] Batch [1070]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.114361,	
2017-07-28 20:56:58,093 Epoch[23] Batch [1080]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.114395,	
2017-07-28 20:57:03,950 Epoch[23] Batch [1090]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.114390,	
2017-07-28 20:57:09,760 Epoch[23] Batch [1100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114278,	
2017-07-28 20:57:15,558 Epoch[23] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.114198,	
2017-07-28 20:57:21,438 Epoch[23] Batch [1120]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.113973,	
2017-07-28 20:57:27,150 Epoch[23] Batch [1130]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.113919,	
2017-07-28 20:57:33,039 Epoch[23] Batch [1140]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.113706,	
2017-07-28 20:57:38,792 Epoch[23] Batch [1150]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113734,	
2017-07-28 20:57:44,598 Epoch[23] Batch [1160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113895,	
2017-07-28 20:57:50,411 Epoch[23] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113792,	
2017-07-28 20:57:56,219 Epoch[23] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113716,	
2017-07-28 20:58:02,004 Epoch[23] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113762,	
2017-07-28 20:58:07,895 Epoch[23] Batch [1200]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.113751,	
2017-07-28 20:58:13,703 Epoch[23] Batch [1210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113726,	
2017-07-28 20:58:19,473 Epoch[23] Batch [1220]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113697,	
2017-07-28 20:58:25,278 Epoch[23] Batch [1230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113617,	
2017-07-28 20:58:31,055 Epoch[23] Batch [1240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.113548,	
2017-07-28 20:58:36,819 Epoch[23] Batch [1250]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113455,	
2017-07-28 20:58:42,636 Epoch[23] Batch [1260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113384,	
2017-07-28 20:58:48,393 Epoch[23] Batch [1270]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.113525,	
2017-07-28 20:58:54,212 Epoch[23] Batch [1280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113526,	
2017-07-28 20:59:00,021 Epoch[23] Batch [1290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113483,	
2017-07-28 20:59:05,811 Epoch[23] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.113477,	
2017-07-28 20:59:11,613 Epoch[23] Batch [1310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113451,	
2017-07-28 20:59:17,412 Epoch[23] Batch [1320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113387,	
2017-07-28 20:59:23,228 Epoch[23] Batch [1330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113378,	
2017-07-28 20:59:29,023 Epoch[23] Batch [1340]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113321,	
2017-07-28 20:59:34,923 Epoch[23] Batch [1350]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.113254,	
2017-07-28 20:59:41,661 Epoch[23] Batch [1360]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.113201,	
2017-07-28 20:59:47,486 Epoch[23] Batch [1370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.113143,	
2017-07-28 20:59:53,290 Epoch[23] Batch [1380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.113107,	
2017-07-28 20:59:59,099 Epoch[23] Batch [1390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112969,	
2017-07-28 21:00:04,912 Epoch[23] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112981,	
2017-07-28 21:00:10,659 Epoch[23] Batch [1410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.112974,	
2017-07-28 21:00:16,362 Epoch[23] Batch [1420]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.112965,	
2017-07-28 21:00:22,150 Epoch[23] Batch [1430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112916,	
2017-07-28 21:00:28,048 Epoch[23] Batch [1440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.112914,	
2017-07-28 21:00:33,794 Epoch[23] Batch [1450]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.112872,	
2017-07-28 21:00:39,685 Epoch[23] Batch [1460]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.112877,	
2017-07-28 21:00:45,414 Epoch[23] Batch [1470]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.112820,	
2017-07-28 21:00:51,213 Epoch[23] Batch [1480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112677,	
2017-07-28 21:00:54,670 Epoch[23] Train-FCNLogLoss=0.112694
2017-07-28 21:00:54,671 Epoch[23] Time cost=864.373
2017-07-28 21:00:55,808 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0024.params"
2017-07-28 21:00:59,602 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0024.states"
2017-07-28 21:01:06,343 Epoch[24] Batch [10]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098128,	
2017-07-28 21:01:12,063 Epoch[24] Batch [20]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.103538,	
2017-07-28 21:01:17,948 Epoch[24] Batch [30]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.104307,	
2017-07-28 21:01:23,744 Epoch[24] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107941,	
2017-07-28 21:01:29,460 Epoch[24] Batch [50]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.107041,	
2017-07-28 21:01:35,354 Epoch[24] Batch [60]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.107828,	
2017-07-28 21:01:41,118 Epoch[24] Batch [70]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107958,	
2017-07-28 21:01:46,905 Epoch[24] Batch [80]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106387,	
2017-07-28 21:01:52,721 Epoch[24] Batch [90]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107750,	
2017-07-28 21:01:58,916 Epoch[24] Batch [100]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.107431,	
2017-07-28 21:02:04,933 Epoch[24] Batch [110]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.108296,	
2017-07-28 21:02:10,816 Epoch[24] Batch [120]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107930,	
2017-07-28 21:02:16,633 Epoch[24] Batch [130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108015,	
2017-07-28 21:02:22,393 Epoch[24] Batch [140]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.109014,	
2017-07-28 21:02:28,193 Epoch[24] Batch [150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109161,	
2017-07-28 21:02:34,065 Epoch[24] Batch [160]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.108892,	
2017-07-28 21:02:40,081 Epoch[24] Batch [170]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.109014,	
2017-07-28 21:02:45,882 Epoch[24] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108398,	
2017-07-28 21:02:51,793 Epoch[24] Batch [190]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.108408,	
2017-07-28 21:02:57,834 Epoch[24] Batch [200]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108257,	
2017-07-28 21:03:03,629 Epoch[24] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108573,	
2017-07-28 21:03:09,423 Epoch[24] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108355,	
2017-07-28 21:03:15,225 Epoch[24] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.108164,	
2017-07-28 21:03:21,199 Epoch[24] Batch [240]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.108416,	
2017-07-28 21:03:27,240 Epoch[24] Batch [250]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108119,	
2017-07-28 21:03:33,000 Epoch[24] Batch [260]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107840,	
2017-07-28 21:03:38,852 Epoch[24] Batch [270]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107117,	
2017-07-28 21:03:44,666 Epoch[24] Batch [280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107334,	
2017-07-28 21:03:50,344 Epoch[24] Batch [290]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.107353,	
2017-07-28 21:03:56,149 Epoch[24] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107410,	
2017-07-28 21:04:01,982 Epoch[24] Batch [310]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107508,	
2017-07-28 21:04:07,733 Epoch[24] Batch [320]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.107746,	
2017-07-28 21:04:13,579 Epoch[24] Batch [330]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107725,	
2017-07-28 21:04:19,272 Epoch[24] Batch [340]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.107678,	
2017-07-28 21:04:25,347 Epoch[24] Batch [350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107562,	
2017-07-28 21:04:31,207 Epoch[24] Batch [360]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107461,	
2017-07-28 21:04:36,942 Epoch[24] Batch [370]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.107349,	
2017-07-28 21:04:42,719 Epoch[24] Batch [380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107316,	
2017-07-28 21:04:48,487 Epoch[24] Batch [390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107204,	
2017-07-28 21:04:54,351 Epoch[24] Batch [400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.107123,	
2017-07-28 21:05:00,152 Epoch[24] Batch [410]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107063,	
2017-07-28 21:05:05,935 Epoch[24] Batch [420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107130,	
2017-07-28 21:05:11,715 Epoch[24] Batch [430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107257,	
2017-07-28 21:05:17,509 Epoch[24] Batch [440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107245,	
2017-07-28 21:05:23,435 Epoch[24] Batch [450]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107295,	
2017-07-28 21:05:29,164 Epoch[24] Batch [460]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.107619,	
2017-07-28 21:05:35,055 Epoch[24] Batch [470]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.107465,	
2017-07-28 21:05:40,781 Epoch[24] Batch [480]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107458,	
2017-07-28 21:05:46,608 Epoch[24] Batch [490]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107196,	
2017-07-28 21:05:52,386 Epoch[24] Batch [500]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107578,	
2017-07-28 21:05:58,288 Epoch[24] Batch [510]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.107693,	
2017-07-28 21:06:04,048 Epoch[24] Batch [520]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107602,	
2017-07-28 21:06:09,837 Epoch[24] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107705,	
2017-07-28 21:06:15,636 Epoch[24] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107489,	
2017-07-28 21:06:21,532 Epoch[24] Batch [550]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.107384,	
2017-07-28 21:06:27,339 Epoch[24] Batch [560]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107405,	
2017-07-28 21:06:33,129 Epoch[24] Batch [570]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107393,	
2017-07-28 21:06:38,973 Epoch[24] Batch [580]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107320,	
2017-07-28 21:06:44,743 Epoch[24] Batch [590]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107409,	
2017-07-28 21:06:50,537 Epoch[24] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107423,	
2017-07-28 21:06:56,367 Epoch[24] Batch [610]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107179,	
2017-07-28 21:07:02,326 Epoch[24] Batch [620]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.107204,	
2017-07-28 21:07:08,148 Epoch[24] Batch [630]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107272,	
2017-07-28 21:07:13,998 Epoch[24] Batch [640]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107134,	
2017-07-28 21:07:19,781 Epoch[24] Batch [650]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107164,	
2017-07-28 21:07:25,550 Epoch[24] Batch [660]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107144,	
2017-07-28 21:07:31,332 Epoch[24] Batch [670]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107160,	
2017-07-28 21:07:37,376 Epoch[24] Batch [680]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.107116,	
2017-07-28 21:07:43,939 Epoch[24] Batch [690]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.107018,	
2017-07-28 21:07:50,302 Epoch[24] Batch [700]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.106827,	
2017-07-28 21:07:56,932 Epoch[24] Batch [710]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.106760,	
2017-07-28 21:08:03,466 Epoch[24] Batch [720]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.106837,	
2017-07-28 21:08:09,188 Epoch[24] Batch [730]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.106732,	
2017-07-28 21:08:14,962 Epoch[24] Batch [740]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106725,	
2017-07-28 21:08:21,000 Epoch[24] Batch [750]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.106575,	
2017-07-28 21:08:26,726 Epoch[24] Batch [760]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.106710,	
2017-07-28 21:08:32,685 Epoch[24] Batch [770]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106706,	
2017-07-28 21:08:38,513 Epoch[24] Batch [780]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106638,	
2017-07-28 21:08:44,325 Epoch[24] Batch [790]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106656,	
2017-07-28 21:08:50,131 Epoch[24] Batch [800]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106678,	
2017-07-28 21:08:55,920 Epoch[24] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106685,	
2017-07-28 21:09:01,553 Epoch[24] Batch [820]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.106578,	
2017-07-28 21:09:07,423 Epoch[24] Batch [830]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106462,	
2017-07-28 21:09:13,013 Epoch[24] Batch [840]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.106995,	
2017-07-28 21:09:18,869 Epoch[24] Batch [850]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107214,	
2017-07-28 21:09:24,661 Epoch[24] Batch [860]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107313,	
2017-07-28 21:09:30,482 Epoch[24] Batch [870]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107229,	
2017-07-28 21:09:36,273 Epoch[24] Batch [880]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107289,	
2017-07-28 21:09:42,064 Epoch[24] Batch [890]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107214,	
2017-07-28 21:09:48,046 Epoch[24] Batch [900]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.107103,	
2017-07-28 21:09:53,812 Epoch[24] Batch [910]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107184,	
2017-07-28 21:09:59,626 Epoch[24] Batch [920]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107100,	
2017-07-28 21:10:05,393 Epoch[24] Batch [930]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107111,	
2017-07-28 21:10:11,158 Epoch[24] Batch [940]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107024,	
2017-07-28 21:10:16,990 Epoch[24] Batch [950]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107037,	
2017-07-28 21:10:22,770 Epoch[24] Batch [960]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107024,	
2017-07-28 21:10:28,614 Epoch[24] Batch [970]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106908,	
2017-07-28 21:10:34,342 Epoch[24] Batch [980]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106881,	
2017-07-28 21:10:40,155 Epoch[24] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106909,	
2017-07-28 21:10:45,943 Epoch[24] Batch [1000]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106905,	
2017-07-28 21:10:51,741 Epoch[24] Batch [1010]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106887,	
2017-07-28 21:10:57,568 Epoch[24] Batch [1020]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106901,	
2017-07-28 21:11:03,348 Epoch[24] Batch [1030]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106718,	
2017-07-28 21:11:09,156 Epoch[24] Batch [1040]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106649,	
2017-07-28 21:11:14,975 Epoch[24] Batch [1050]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106532,	
2017-07-28 21:11:20,728 Epoch[24] Batch [1060]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106560,	
2017-07-28 21:11:26,557 Epoch[24] Batch [1070]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106599,	
2017-07-28 21:11:32,401 Epoch[24] Batch [1080]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106519,	
2017-07-28 21:11:38,199 Epoch[24] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106459,	
2017-07-28 21:11:44,469 Epoch[24] Batch [1100]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.106424,	
2017-07-28 21:11:50,750 Epoch[24] Batch [1110]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.106509,	
2017-07-28 21:11:56,452 Epoch[24] Batch [1120]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.106492,	
2017-07-28 21:12:02,244 Epoch[24] Batch [1130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106482,	
2017-07-28 21:12:08,028 Epoch[24] Batch [1140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106500,	
2017-07-28 21:12:13,826 Epoch[24] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106525,	
2017-07-28 21:12:19,628 Epoch[24] Batch [1160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106524,	
2017-07-28 21:12:25,448 Epoch[24] Batch [1170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106506,	
2017-07-28 21:12:31,335 Epoch[24] Batch [1180]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106464,	
2017-07-28 21:12:37,147 Epoch[24] Batch [1190]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106519,	
2017-07-28 21:12:43,229 Epoch[24] Batch [1200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106676,	
2017-07-28 21:12:49,320 Epoch[24] Batch [1210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106759,	
2017-07-28 21:12:55,404 Epoch[24] Batch [1220]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106856,	
2017-07-28 21:13:01,533 Epoch[24] Batch [1230]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106775,	
2017-07-28 21:13:07,761 Epoch[24] Batch [1240]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.106673,	
2017-07-28 21:13:13,839 Epoch[24] Batch [1250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106608,	
2017-07-28 21:13:19,691 Epoch[24] Batch [1260]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106692,	
2017-07-28 21:13:25,457 Epoch[24] Batch [1270]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106668,	
2017-07-28 21:13:31,245 Epoch[24] Batch [1280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106723,	
2017-07-28 21:13:37,070 Epoch[24] Batch [1290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106774,	
2017-07-28 21:13:42,867 Epoch[24] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106783,	
2017-07-28 21:13:48,711 Epoch[24] Batch [1310]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106808,	
2017-07-28 21:13:54,540 Epoch[24] Batch [1320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106786,	
2017-07-28 21:14:00,458 Epoch[24] Batch [1330]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.106774,	
2017-07-28 21:14:06,153 Epoch[24] Batch [1340]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.106719,	
2017-07-28 21:14:11,982 Epoch[24] Batch [1350]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106689,	
2017-07-28 21:14:17,803 Epoch[24] Batch [1360]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106688,	
2017-07-28 21:14:23,661 Epoch[24] Batch [1370]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106659,	
2017-07-28 21:14:29,437 Epoch[24] Batch [1380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106757,	
2017-07-28 21:14:35,284 Epoch[24] Batch [1390]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106750,	
2017-07-28 21:14:41,024 Epoch[24] Batch [1400]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.106711,	
2017-07-28 21:14:46,862 Epoch[24] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106618,	
2017-07-28 21:14:52,699 Epoch[24] Batch [1420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106565,	
2017-07-28 21:14:58,498 Epoch[24] Batch [1430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106535,	
2017-07-28 21:15:04,298 Epoch[24] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106467,	
2017-07-28 21:15:10,111 Epoch[24] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106502,	
2017-07-28 21:15:15,947 Epoch[24] Batch [1460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106556,	
2017-07-28 21:15:21,738 Epoch[24] Batch [1470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106485,	
2017-07-28 21:15:27,603 Epoch[24] Batch [1480]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106480,	
2017-07-28 21:15:31,072 Epoch[24] Train-FCNLogLoss=0.106471
2017-07-28 21:15:31,072 Epoch[24] Time cost=871.470
2017-07-28 21:15:32,233 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0025.params"
2017-07-28 21:15:36,087 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0025.states"
2017-07-28 21:15:43,579 Epoch[25] Batch [10]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.105032,	
2017-07-28 21:15:49,593 Epoch[25] Batch [20]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.116696,	
2017-07-28 21:15:55,409 Epoch[25] Batch [30]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108036,	
2017-07-28 21:16:01,357 Epoch[25] Batch [40]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.111247,	
2017-07-28 21:16:07,084 Epoch[25] Batch [50]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.110597,	
2017-07-28 21:16:12,863 Epoch[25] Batch [60]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110401,	
2017-07-28 21:16:18,678 Epoch[25] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109386,	
2017-07-28 21:16:24,305 Epoch[25] Batch [80]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.108579,	
2017-07-28 21:16:30,138 Epoch[25] Batch [90]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108261,	
2017-07-28 21:16:36,053 Epoch[25] Batch [100]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107335,	
2017-07-28 21:16:41,846 Epoch[25] Batch [110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108049,	
2017-07-28 21:16:47,649 Epoch[25] Batch [120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107789,	
2017-07-28 21:16:53,425 Epoch[25] Batch [130]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107159,	
2017-07-28 21:16:59,213 Epoch[25] Batch [140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107252,	
2017-07-28 21:17:05,236 Epoch[25] Batch [150]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.107452,	
2017-07-28 21:17:11,107 Epoch[25] Batch [160]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107512,	
2017-07-28 21:17:16,827 Epoch[25] Batch [170]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107673,	
2017-07-28 21:17:22,614 Epoch[25] Batch [180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106977,	
2017-07-28 21:17:28,449 Epoch[25] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106820,	
2017-07-28 21:17:34,209 Epoch[25] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107037,	
2017-07-28 21:17:40,079 Epoch[25] Batch [210]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106925,	
2017-07-28 21:17:45,887 Epoch[25] Batch [220]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106858,	
2017-07-28 21:17:51,654 Epoch[25] Batch [230]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106869,	
2017-07-28 21:17:57,493 Epoch[25] Batch [240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106933,	
2017-07-28 21:18:03,262 Epoch[25] Batch [250]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106607,	
2017-07-28 21:18:09,072 Epoch[25] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106117,	
2017-07-28 21:18:14,883 Epoch[25] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106270,	
2017-07-28 21:18:20,728 Epoch[25] Batch [280]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105892,	
2017-07-28 21:18:26,541 Epoch[25] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105859,	
2017-07-28 21:18:32,345 Epoch[25] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106467,	
2017-07-28 21:18:38,278 Epoch[25] Batch [310]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106617,	
2017-07-28 21:18:44,690 Epoch[25] Batch [320]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.106487,	
2017-07-28 21:18:51,019 Epoch[25] Batch [330]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.106473,	
2017-07-28 21:18:57,615 Epoch[25] Batch [340]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.106300,	
2017-07-28 21:19:03,521 Epoch[25] Batch [350]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106411,	
2017-07-28 21:19:09,549 Epoch[25] Batch [360]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.106195,	
2017-07-28 21:19:15,495 Epoch[25] Batch [370]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106218,	
2017-07-28 21:19:21,488 Epoch[25] Batch [380]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.106267,	
2017-07-28 21:19:27,418 Epoch[25] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106534,	
2017-07-28 21:19:33,446 Epoch[25] Batch [400]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.106884,	
2017-07-28 21:19:39,219 Epoch[25] Batch [410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106933,	
2017-07-28 21:19:45,047 Epoch[25] Batch [420]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106982,	
2017-07-28 21:19:50,867 Epoch[25] Batch [430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106830,	
2017-07-28 21:19:56,702 Epoch[25] Batch [440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106555,	
2017-07-28 21:20:02,482 Epoch[25] Batch [450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106527,	
2017-07-28 21:20:08,241 Epoch[25] Batch [460]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106607,	
2017-07-28 21:20:14,043 Epoch[25] Batch [470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106424,	
2017-07-28 21:20:20,239 Epoch[25] Batch [480]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.106345,	
2017-07-28 21:20:26,765 Epoch[25] Batch [490]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.106354,	
2017-07-28 21:20:32,890 Epoch[25] Batch [500]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106419,	
2017-07-28 21:20:39,342 Epoch[25] Batch [510]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.106365,	
2017-07-28 21:20:45,122 Epoch[25] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106253,	
2017-07-28 21:20:50,929 Epoch[25] Batch [530]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106206,	
2017-07-28 21:20:57,340 Epoch[25] Batch [540]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.106328,	
2017-07-28 21:21:03,768 Epoch[25] Batch [550]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106300,	
2017-07-28 21:21:09,621 Epoch[25] Batch [560]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106517,	
2017-07-28 21:21:15,339 Epoch[25] Batch [570]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.106725,	
2017-07-28 21:21:21,119 Epoch[25] Batch [580]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106722,	
2017-07-28 21:21:27,282 Epoch[25] Batch [590]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.106903,	
2017-07-28 21:21:33,012 Epoch[25] Batch [600]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106782,	
2017-07-28 21:21:38,815 Epoch[25] Batch [610]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106664,	
2017-07-28 21:21:44,688 Epoch[25] Batch [620]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106784,	
2017-07-28 21:21:50,872 Epoch[25] Batch [630]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106785,	
2017-07-28 21:21:56,687 Epoch[25] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106676,	
2017-07-28 21:22:02,448 Epoch[25] Batch [650]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106723,	
2017-07-28 21:22:08,208 Epoch[25] Batch [660]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106700,	
2017-07-28 21:22:13,990 Epoch[25] Batch [670]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106628,	
2017-07-28 21:22:19,758 Epoch[25] Batch [680]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106681,	
2017-07-28 21:22:25,564 Epoch[25] Batch [690]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106578,	
2017-07-28 21:22:31,465 Epoch[25] Batch [700]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106634,	
2017-07-28 21:22:37,248 Epoch[25] Batch [710]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106534,	
2017-07-28 21:22:42,333 Epoch[25] Batch [720]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.106498,	
2017-07-28 21:22:47,804 Epoch[25] Batch [730]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.106497,	
2017-07-28 21:22:53,596 Epoch[25] Batch [740]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106322,	
2017-07-28 21:22:59,406 Epoch[25] Batch [750]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106348,	
2017-07-28 21:23:05,176 Epoch[25] Batch [760]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106530,	
2017-07-28 21:23:10,999 Epoch[25] Batch [770]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106569,	
2017-07-28 21:23:16,678 Epoch[25] Batch [780]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.106448,	
2017-07-28 21:23:22,451 Epoch[25] Batch [790]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106531,	
2017-07-28 21:23:28,302 Epoch[25] Batch [800]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106514,	
2017-07-28 21:23:34,077 Epoch[25] Batch [810]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106348,	
2017-07-28 21:23:39,889 Epoch[25] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106444,	
2017-07-28 21:23:45,702 Epoch[25] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106510,	
2017-07-28 21:23:51,501 Epoch[25] Batch [840]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106527,	
2017-07-28 21:23:57,334 Epoch[25] Batch [850]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106463,	
2017-07-28 21:24:03,115 Epoch[25] Batch [860]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106315,	
2017-07-28 21:24:08,910 Epoch[25] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106323,	
2017-07-28 21:24:14,691 Epoch[25] Batch [880]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106269,	
2017-07-28 21:24:20,511 Epoch[25] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106239,	
2017-07-28 21:24:26,313 Epoch[25] Batch [900]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106150,	
2017-07-28 21:24:32,268 Epoch[25] Batch [910]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106188,	
2017-07-28 21:24:38,062 Epoch[25] Batch [920]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106143,	
2017-07-28 21:24:43,846 Epoch[25] Batch [930]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106075,	
2017-07-28 21:24:49,626 Epoch[25] Batch [940]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106109,	
2017-07-28 21:24:55,394 Epoch[25] Batch [950]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106208,	
2017-07-28 21:25:01,199 Epoch[25] Batch [960]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106263,	
2017-07-28 21:25:07,208 Epoch[25] Batch [970]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106322,	
2017-07-28 21:25:13,110 Epoch[25] Batch [980]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106341,	
2017-07-28 21:25:18,804 Epoch[25] Batch [990]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.106247,	
2017-07-28 21:25:24,624 Epoch[25] Batch [1000]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106186,	
2017-07-28 21:25:30,424 Epoch[25] Batch [1010]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106113,	
2017-07-28 21:25:36,290 Epoch[25] Batch [1020]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106013,	
2017-07-28 21:25:42,379 Epoch[25] Batch [1030]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106107,	
2017-07-28 21:25:48,807 Epoch[25] Batch [1040]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106188,	
2017-07-28 21:25:54,898 Epoch[25] Batch [1050]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106168,	
2017-07-28 21:26:00,572 Epoch[25] Batch [1060]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.106222,	
2017-07-28 21:26:06,689 Epoch[25] Batch [1070]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106063,	
2017-07-28 21:26:12,442 Epoch[25] Batch [1080]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106226,	
2017-07-28 21:26:18,216 Epoch[25] Batch [1090]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106270,	
2017-07-28 21:26:24,109 Epoch[25] Batch [1100]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106282,	
2017-07-28 21:26:29,873 Epoch[25] Batch [1110]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106224,	
2017-07-28 21:26:35,706 Epoch[25] Batch [1120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106062,	
2017-07-28 21:26:41,599 Epoch[25] Batch [1130]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106000,	
2017-07-28 21:26:47,417 Epoch[25] Batch [1140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106065,	
2017-07-28 21:26:53,472 Epoch[25] Batch [1150]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106129,	
2017-07-28 21:26:59,320 Epoch[25] Batch [1160]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106054,	
2017-07-28 21:27:05,279 Epoch[25] Batch [1170]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106147,	
2017-07-28 21:27:10,994 Epoch[25] Batch [1180]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.106094,	
2017-07-28 21:27:16,790 Epoch[25] Batch [1190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106139,	
2017-07-28 21:27:22,586 Epoch[25] Batch [1200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106160,	
2017-07-28 21:27:28,443 Epoch[25] Batch [1210]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106190,	
2017-07-28 21:27:34,214 Epoch[25] Batch [1220]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106095,	
2017-07-28 21:27:39,969 Epoch[25] Batch [1230]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106089,	
2017-07-28 21:27:45,798 Epoch[25] Batch [1240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106196,	
2017-07-28 21:27:51,641 Epoch[25] Batch [1250]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106228,	
2017-07-28 21:27:57,458 Epoch[25] Batch [1260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106263,	
2017-07-28 21:28:03,239 Epoch[25] Batch [1270]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106311,	
2017-07-28 21:28:09,138 Epoch[25] Batch [1280]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106323,	
2017-07-28 21:28:14,872 Epoch[25] Batch [1290]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106257,	
2017-07-28 21:28:20,733 Epoch[25] Batch [1300]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106175,	
2017-07-28 21:28:26,608 Epoch[25] Batch [1310]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106125,	
2017-07-28 21:28:32,699 Epoch[25] Batch [1320]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106093,	
2017-07-28 21:28:38,586 Epoch[25] Batch [1330]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106058,	
2017-07-28 21:28:44,313 Epoch[25] Batch [1340]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106084,	
2017-07-28 21:28:50,115 Epoch[25] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106073,	
2017-07-28 21:28:56,272 Epoch[25] Batch [1360]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.105997,	
2017-07-28 21:29:02,377 Epoch[25] Batch [1370]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.106033,	
2017-07-28 21:29:08,175 Epoch[25] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106100,	
2017-07-28 21:29:14,228 Epoch[25] Batch [1390]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106154,	
2017-07-28 21:29:21,050 Epoch[25] Batch [1400]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.106186,	
2017-07-28 21:29:27,759 Epoch[25] Batch [1410]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.106215,	
2017-07-28 21:29:34,471 Epoch[25] Batch [1420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.106261,	
2017-07-28 21:29:41,573 Epoch[25] Batch [1430]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.106274,	
2017-07-28 21:29:48,085 Epoch[25] Batch [1440]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.106194,	
2017-07-28 21:29:54,455 Epoch[25] Batch [1450]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.106159,	
2017-07-28 21:30:00,950 Epoch[25] Batch [1460]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.106082,	
2017-07-28 21:30:06,846 Epoch[25] Batch [1470]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106050,	
2017-07-28 21:30:12,865 Epoch[25] Batch [1480]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.106013,	
2017-07-28 21:30:16,342 Epoch[25] Train-FCNLogLoss=0.106001
2017-07-28 21:30:16,342 Epoch[25] Time cost=880.255
2017-07-28 21:30:17,417 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0026.params"
2017-07-28 21:30:21,094 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0026.states"
2017-07-28 21:30:27,690 Epoch[26] Batch [10]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099971,	
2017-07-28 21:30:33,421 Epoch[26] Batch [20]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.101009,	
2017-07-28 21:30:39,161 Epoch[26] Batch [30]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100588,	
2017-07-28 21:30:44,965 Epoch[26] Batch [40]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102513,	
2017-07-28 21:30:50,784 Epoch[26] Batch [50]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100828,	
2017-07-28 21:30:56,517 Epoch[26] Batch [60]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.102449,	
2017-07-28 21:31:02,305 Epoch[26] Batch [70]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102451,	
2017-07-28 21:31:08,080 Epoch[26] Batch [80]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.102854,	
2017-07-28 21:31:13,832 Epoch[26] Batch [90]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106857,	
2017-07-28 21:31:19,661 Epoch[26] Batch [100]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105600,	
2017-07-28 21:31:25,422 Epoch[26] Batch [110]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.105079,	
2017-07-28 21:31:31,237 Epoch[26] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106098,	
2017-07-28 21:31:37,037 Epoch[26] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107577,	
2017-07-28 21:31:42,849 Epoch[26] Batch [140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107738,	
2017-07-28 21:31:48,741 Epoch[26] Batch [150]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.108399,	
2017-07-28 21:31:54,469 Epoch[26] Batch [160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.111283,	
2017-07-28 21:32:00,234 Epoch[26] Batch [170]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.111875,	
2017-07-28 21:32:06,028 Epoch[26] Batch [180]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.112452,	
2017-07-28 21:32:11,836 Epoch[26] Batch [190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.112416,	
2017-07-28 21:32:17,694 Epoch[26] Batch [200]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.112355,	
2017-07-28 21:32:23,495 Epoch[26] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.111961,	
2017-07-28 21:32:29,262 Epoch[26] Batch [220]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.111644,	
2017-07-28 21:32:35,068 Epoch[26] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.111391,	
2017-07-28 21:32:40,988 Epoch[26] Batch [240]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.110804,	
2017-07-28 21:32:46,727 Epoch[26] Batch [250]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.110683,	
2017-07-28 21:32:52,626 Epoch[26] Batch [260]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.110601,	
2017-07-28 21:32:58,322 Epoch[26] Batch [270]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.110495,	
2017-07-28 21:33:04,132 Epoch[26] Batch [280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.110179,	
2017-07-28 21:33:09,996 Epoch[26] Batch [290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.109898,	
2017-07-28 21:33:15,716 Epoch[26] Batch [300]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.109833,	
2017-07-28 21:33:21,663 Epoch[26] Batch [310]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109761,	
2017-07-28 21:33:27,702 Epoch[26] Batch [320]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109449,	
2017-07-28 21:33:33,843 Epoch[26] Batch [330]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.109308,	
2017-07-28 21:33:40,067 Epoch[26] Batch [340]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.109087,	
2017-07-28 21:33:45,751 Epoch[26] Batch [350]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.109417,	
2017-07-28 21:33:51,582 Epoch[26] Batch [360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.109415,	
2017-07-28 21:33:57,431 Epoch[26] Batch [370]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.109434,	
2017-07-28 21:34:03,221 Epoch[26] Batch [380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109395,	
2017-07-28 21:34:09,031 Epoch[26] Batch [390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109288,	
2017-07-28 21:34:14,819 Epoch[26] Batch [400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109108,	
2017-07-28 21:34:20,792 Epoch[26] Batch [410]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.109103,	
2017-07-28 21:34:26,456 Epoch[26] Batch [420]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.108779,	
2017-07-28 21:34:32,959 Epoch[26] Batch [430]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.108577,	
2017-07-28 21:34:39,006 Epoch[26] Batch [440]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108580,	
2017-07-28 21:34:44,773 Epoch[26] Batch [450]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.108492,	
2017-07-28 21:34:50,618 Epoch[26] Batch [460]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.108232,	
2017-07-28 21:34:56,482 Epoch[26] Batch [470]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.108234,	
2017-07-28 21:35:02,303 Epoch[26] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.108267,	
2017-07-28 21:35:08,072 Epoch[26] Batch [490]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108044,	
2017-07-28 21:35:13,849 Epoch[26] Batch [500]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.108109,	
2017-07-28 21:35:19,793 Epoch[26] Batch [510]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.107987,	
2017-07-28 21:35:25,562 Epoch[26] Batch [520]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107725,	
2017-07-28 21:35:31,293 Epoch[26] Batch [530]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.107601,	
2017-07-28 21:35:37,356 Epoch[26] Batch [540]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107557,	
2017-07-28 21:35:43,184 Epoch[26] Batch [550]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107371,	
2017-07-28 21:35:49,091 Epoch[26] Batch [560]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.107312,	
2017-07-28 21:35:54,876 Epoch[26] Batch [570]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107268,	
2017-07-28 21:36:00,752 Epoch[26] Batch [580]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107298,	
2017-07-28 21:36:06,463 Epoch[26] Batch [590]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.107324,	
2017-07-28 21:36:12,476 Epoch[26] Batch [600]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107206,	
2017-07-28 21:36:18,341 Epoch[26] Batch [610]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106964,	
2017-07-28 21:36:24,165 Epoch[26] Batch [620]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106943,	
2017-07-28 21:36:29,969 Epoch[26] Batch [630]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106904,	
2017-07-28 21:36:35,758 Epoch[26] Batch [640]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107009,	
2017-07-28 21:36:41,585 Epoch[26] Batch [650]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.107131,	
2017-07-28 21:36:47,407 Epoch[26] Batch [660]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107107,	
2017-07-28 21:36:53,216 Epoch[26] Batch [670]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107102,	
2017-07-28 21:36:58,610 Epoch[26] Batch [680]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.106982,	
2017-07-28 21:37:03,950 Epoch[26] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.107176,	
2017-07-28 21:37:09,727 Epoch[26] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107184,	
2017-07-28 21:37:15,514 Epoch[26] Batch [710]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107060,	
2017-07-28 21:37:21,363 Epoch[26] Batch [720]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107025,	
2017-07-28 21:37:27,199 Epoch[26] Batch [730]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106883,	
2017-07-28 21:37:32,990 Epoch[26] Batch [740]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106824,	
2017-07-28 21:37:38,813 Epoch[26] Batch [750]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106595,	
2017-07-28 21:37:44,557 Epoch[26] Batch [760]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.106511,	
2017-07-28 21:37:50,801 Epoch[26] Batch [770]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106425,	
2017-07-28 21:37:56,608 Epoch[26] Batch [780]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106300,	
2017-07-28 21:38:02,424 Epoch[26] Batch [790]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106270,	
2017-07-28 21:38:08,136 Epoch[26] Batch [800]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.106140,	
2017-07-28 21:38:13,968 Epoch[26] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106413,	
2017-07-28 21:38:20,441 Epoch[26] Batch [820]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.106631,	
2017-07-28 21:38:26,239 Epoch[26] Batch [830]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106682,	
2017-07-28 21:38:32,282 Epoch[26] Batch [840]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.106716,	
2017-07-28 21:38:38,102 Epoch[26] Batch [850]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106785,	
2017-07-28 21:38:43,956 Epoch[26] Batch [860]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106642,	
2017-07-28 21:38:49,753 Epoch[26] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106428,	
2017-07-28 21:38:55,589 Epoch[26] Batch [880]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106418,	
2017-07-28 21:39:01,297 Epoch[26] Batch [890]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.106288,	
2017-07-28 21:39:07,103 Epoch[26] Batch [900]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106201,	
2017-07-28 21:39:12,817 Epoch[26] Batch [910]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.106290,	
2017-07-28 21:39:18,643 Epoch[26] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106194,	
2017-07-28 21:39:24,438 Epoch[26] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106225,	
2017-07-28 21:39:30,238 Epoch[26] Batch [940]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106188,	
2017-07-28 21:39:35,994 Epoch[26] Batch [950]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106225,	
2017-07-28 21:39:41,791 Epoch[26] Batch [960]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106049,	
2017-07-28 21:39:47,579 Epoch[26] Batch [970]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106055,	
2017-07-28 21:39:53,352 Epoch[26] Batch [980]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106176,	
2017-07-28 21:39:59,216 Epoch[26] Batch [990]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106079,	
2017-07-28 21:40:05,056 Epoch[26] Batch [1000]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105943,	
2017-07-28 21:40:10,778 Epoch[26] Batch [1010]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.105938,	
2017-07-28 21:40:16,721 Epoch[26] Batch [1020]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106002,	
2017-07-28 21:40:22,410 Epoch[26] Batch [1030]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.105972,	
2017-07-28 21:40:28,204 Epoch[26] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105916,	
2017-07-28 21:40:34,028 Epoch[26] Batch [1050]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105883,	
2017-07-28 21:40:39,830 Epoch[26] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105867,	
2017-07-28 21:40:45,623 Epoch[26] Batch [1070]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105911,	
2017-07-28 21:40:51,399 Epoch[26] Batch [1080]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105905,	
2017-07-28 21:40:57,181 Epoch[26] Batch [1090]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105799,	
2017-07-28 21:41:02,931 Epoch[26] Batch [1100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105790,	
2017-07-28 21:41:08,739 Epoch[26] Batch [1110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105721,	
2017-07-28 21:41:14,572 Epoch[26] Batch [1120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105682,	
2017-07-28 21:41:20,323 Epoch[26] Batch [1130]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105624,	
2017-07-28 21:41:26,169 Epoch[26] Batch [1140]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105603,	
2017-07-28 21:41:32,028 Epoch[26] Batch [1150]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.105548,	
2017-07-28 21:41:37,763 Epoch[26] Batch [1160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.105528,	
2017-07-28 21:41:43,579 Epoch[26] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105484,	
2017-07-28 21:41:49,439 Epoch[26] Batch [1180]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.105459,	
2017-07-28 21:41:55,208 Epoch[26] Batch [1190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105348,	
2017-07-28 21:42:01,054 Epoch[26] Batch [1200]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105386,	
2017-07-28 21:42:06,935 Epoch[26] Batch [1210]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.105637,	
2017-07-28 21:42:12,660 Epoch[26] Batch [1220]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.105648,	
2017-07-28 21:42:18,502 Epoch[26] Batch [1230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105641,	
2017-07-28 21:42:24,298 Epoch[26] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105631,	
2017-07-28 21:42:30,659 Epoch[26] Batch [1250]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.105545,	
2017-07-28 21:42:36,410 Epoch[26] Batch [1260]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105501,	
2017-07-28 21:42:42,217 Epoch[26] Batch [1270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105436,	
2017-07-28 21:42:48,004 Epoch[26] Batch [1280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105497,	
2017-07-28 21:42:53,908 Epoch[26] Batch [1290]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105480,	
2017-07-28 21:42:59,733 Epoch[26] Batch [1300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105410,	
2017-07-28 21:43:05,521 Epoch[26] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105432,	
2017-07-28 21:43:11,488 Epoch[26] Batch [1320]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105421,	
2017-07-28 21:43:17,386 Epoch[26] Batch [1330]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105366,	
2017-07-28 21:43:23,246 Epoch[26] Batch [1340]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.105370,	
2017-07-28 21:43:29,484 Epoch[26] Batch [1350]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.105328,	
2017-07-28 21:43:35,572 Epoch[26] Batch [1360]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.105321,	
2017-07-28 21:43:41,828 Epoch[26] Batch [1370]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.105291,	
2017-07-28 21:43:47,641 Epoch[26] Batch [1380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105429,	
2017-07-28 21:43:53,454 Epoch[26] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105475,	
2017-07-28 21:43:59,421 Epoch[26] Batch [1400]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105424,	
2017-07-28 21:44:05,399 Epoch[26] Batch [1410]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105408,	
2017-07-28 21:44:11,905 Epoch[26] Batch [1420]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.105355,	
2017-07-28 21:44:18,014 Epoch[26] Batch [1430]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.105300,	
2017-07-28 21:44:24,181 Epoch[26] Batch [1440]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.105189,	
2017-07-28 21:44:30,362 Epoch[26] Batch [1450]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.105189,	
2017-07-28 21:44:36,247 Epoch[26] Batch [1460]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.105199,	
2017-07-28 21:44:42,064 Epoch[26] Batch [1470]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105173,	
2017-07-28 21:44:48,170 Epoch[26] Batch [1480]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.105214,	
2017-07-28 21:44:51,696 Epoch[26] Train-FCNLogLoss=0.105171
2017-07-28 21:44:51,696 Epoch[26] Time cost=870.602
2017-07-28 21:44:52,903 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0027.params"
2017-07-28 21:44:56,618 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0027.states"
2017-07-28 21:45:03,507 Epoch[27] Batch [10]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.109947,	
2017-07-28 21:45:09,228 Epoch[27] Batch [20]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.106813,	
2017-07-28 21:45:15,015 Epoch[27] Batch [30]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105489,	
2017-07-28 21:45:20,802 Epoch[27] Batch [40]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102703,	
2017-07-28 21:45:26,638 Epoch[27] Batch [50]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102994,	
2017-07-28 21:45:32,405 Epoch[27] Batch [60]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102289,	
2017-07-28 21:45:38,239 Epoch[27] Batch [70]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102455,	
2017-07-28 21:45:44,024 Epoch[27] Batch [80]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103279,	
2017-07-28 21:45:49,844 Epoch[27] Batch [90]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103021,	
2017-07-28 21:45:55,634 Epoch[27] Batch [100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102409,	
2017-07-28 21:46:01,413 Epoch[27] Batch [110]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102704,	
2017-07-28 21:46:07,231 Epoch[27] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102423,	
2017-07-28 21:46:12,998 Epoch[27] Batch [130]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102897,	
2017-07-28 21:46:18,869 Epoch[27] Batch [140]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.102727,	
2017-07-28 21:46:24,646 Epoch[27] Batch [150]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102853,	
2017-07-28 21:46:30,492 Epoch[27] Batch [160]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.102546,	
2017-07-28 21:46:36,718 Epoch[27] Batch [170]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.102500,	
2017-07-28 21:46:42,549 Epoch[27] Batch [180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101950,	
2017-07-28 21:46:48,676 Epoch[27] Batch [190]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.100913,	
2017-07-28 21:46:55,716 Epoch[27] Batch [200]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.100687,	
2017-07-28 21:47:01,944 Epoch[27] Batch [210]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.100657,	
2017-07-28 21:47:08,108 Epoch[27] Batch [220]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.100259,	
2017-07-28 21:47:14,450 Epoch[27] Batch [230]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.100435,	
2017-07-28 21:47:20,523 Epoch[27] Batch [240]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100401,	
2017-07-28 21:47:26,774 Epoch[27] Batch [250]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.100707,	
2017-07-28 21:47:32,783 Epoch[27] Batch [260]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100875,	
2017-07-28 21:47:38,582 Epoch[27] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100781,	
2017-07-28 21:47:44,403 Epoch[27] Batch [280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101384,	
2017-07-28 21:47:50,311 Epoch[27] Batch [290]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.101960,	
2017-07-28 21:47:56,094 Epoch[27] Batch [300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101896,	
2017-07-28 21:48:02,279 Epoch[27] Batch [310]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.101935,	
2017-07-28 21:48:08,367 Epoch[27] Batch [320]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102146,	
2017-07-28 21:48:14,808 Epoch[27] Batch [330]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.102116,	
2017-07-28 21:48:20,558 Epoch[27] Batch [340]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.102310,	
2017-07-28 21:48:26,399 Epoch[27] Batch [350]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102130,	
2017-07-28 21:48:32,145 Epoch[27] Batch [360]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.102165,	
2017-07-28 21:48:38,035 Epoch[27] Batch [370]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.102377,	
2017-07-28 21:48:43,777 Epoch[27] Batch [380]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.102925,	
2017-07-28 21:48:49,931 Epoch[27] Batch [390]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.102893,	
2017-07-28 21:48:55,764 Epoch[27] Batch [400]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102986,	
2017-07-28 21:49:02,271 Epoch[27] Batch [410]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.103359,	
2017-07-28 21:49:08,074 Epoch[27] Batch [420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103375,	
2017-07-28 21:49:13,858 Epoch[27] Batch [430]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103694,	
2017-07-28 21:49:19,676 Epoch[27] Batch [440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103488,	
2017-07-28 21:49:25,530 Epoch[27] Batch [450]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103518,	
2017-07-28 21:49:31,311 Epoch[27] Batch [460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103292,	
2017-07-28 21:49:37,116 Epoch[27] Batch [470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103217,	
2017-07-28 21:49:43,329 Epoch[27] Batch [480]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.102916,	
2017-07-28 21:49:49,078 Epoch[27] Batch [490]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.102949,	
2017-07-28 21:49:54,879 Epoch[27] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102844,	
2017-07-28 21:50:00,658 Epoch[27] Batch [510]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102976,	
2017-07-28 21:50:06,606 Epoch[27] Batch [520]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.103097,	
2017-07-28 21:50:12,373 Epoch[27] Batch [530]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103504,	
2017-07-28 21:50:18,457 Epoch[27] Batch [540]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103619,	
2017-07-28 21:50:24,921 Epoch[27] Batch [550]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.103928,	
2017-07-28 21:50:31,187 Epoch[27] Batch [560]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.104065,	
2017-07-28 21:50:36,887 Epoch[27] Batch [570]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.104451,	
2017-07-28 21:50:42,709 Epoch[27] Batch [580]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.104756,	
2017-07-28 21:50:48,594 Epoch[27] Batch [590]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.104729,	
2017-07-28 21:50:54,313 Epoch[27] Batch [600]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.104914,	
2017-07-28 21:51:00,434 Epoch[27] Batch [610]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.104994,	
2017-07-28 21:51:06,579 Epoch[27] Batch [620]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.105223,	
2017-07-28 21:51:12,644 Epoch[27] Batch [630]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.105338,	
2017-07-28 21:51:18,958 Epoch[27] Batch [640]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.105682,	
2017-07-28 21:51:24,886 Epoch[27] Batch [650]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106006,	
2017-07-28 21:51:31,208 Epoch[27] Batch [660]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.106234,	
2017-07-28 21:51:37,120 Epoch[27] Batch [670]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106431,	
2017-07-28 21:51:43,624 Epoch[27] Batch [680]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.106510,	
2017-07-28 21:51:49,588 Epoch[27] Batch [690]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106471,	
2017-07-28 21:51:55,381 Epoch[27] Batch [700]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106383,	
2017-07-28 21:52:01,149 Epoch[27] Batch [710]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106359,	
2017-07-28 21:52:07,236 Epoch[27] Batch [720]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106254,	
2017-07-28 21:52:13,112 Epoch[27] Batch [730]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106301,	
2017-07-28 21:52:19,280 Epoch[27] Batch [740]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.106279,	
2017-07-28 21:52:25,467 Epoch[27] Batch [750]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106287,	
2017-07-28 21:52:31,628 Epoch[27] Batch [760]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.106228,	
2017-07-28 21:52:37,414 Epoch[27] Batch [770]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106327,	
2017-07-28 21:52:43,186 Epoch[27] Batch [780]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106135,	
2017-07-28 21:52:48,980 Epoch[27] Batch [790]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106256,	
2017-07-28 21:52:54,707 Epoch[27] Batch [800]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106401,	
2017-07-28 21:53:00,593 Epoch[27] Batch [810]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.106514,	
2017-07-28 21:53:06,332 Epoch[27] Batch [820]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.106577,	
2017-07-28 21:53:12,145 Epoch[27] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106874,	
2017-07-28 21:53:17,936 Epoch[27] Batch [840]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106998,	
2017-07-28 21:53:23,730 Epoch[27] Batch [850]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107026,	
2017-07-28 21:53:29,547 Epoch[27] Batch [860]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106913,	
2017-07-28 21:53:35,397 Epoch[27] Batch [870]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106858,	
2017-07-28 21:53:41,187 Epoch[27] Batch [880]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106891,	
2017-07-28 21:53:46,984 Epoch[27] Batch [890]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106963,	
2017-07-28 21:53:52,808 Epoch[27] Batch [900]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106828,	
2017-07-28 21:53:58,557 Epoch[27] Batch [910]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.106864,	
2017-07-28 21:54:04,379 Epoch[27] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106842,	
2017-07-28 21:54:10,241 Epoch[27] Batch [930]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106892,	
2017-07-28 21:54:16,043 Epoch[27] Batch [940]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106880,	
2017-07-28 21:54:21,893 Epoch[27] Batch [950]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106803,	
2017-07-28 21:54:27,624 Epoch[27] Batch [960]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106679,	
2017-07-28 21:54:33,440 Epoch[27] Batch [970]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106578,	
2017-07-28 21:54:39,231 Epoch[27] Batch [980]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106490,	
2017-07-28 21:54:45,038 Epoch[27] Batch [990]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106395,	
2017-07-28 21:54:50,876 Epoch[27] Batch [1000]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106736,	
2017-07-28 21:54:56,669 Epoch[27] Batch [1010]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106728,	
2017-07-28 21:55:02,577 Epoch[27] Batch [1020]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106763,	
2017-07-28 21:55:08,904 Epoch[27] Batch [1030]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.106735,	
2017-07-28 21:55:14,596 Epoch[27] Batch [1040]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.106582,	
2017-07-28 21:55:20,605 Epoch[27] Batch [1050]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106717,	
2017-07-28 21:55:26,550 Epoch[27] Batch [1060]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106549,	
2017-07-28 21:55:32,341 Epoch[27] Batch [1070]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106480,	
2017-07-28 21:55:38,102 Epoch[27] Batch [1080]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106368,	
2017-07-28 21:55:44,099 Epoch[27] Batch [1090]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.106304,	
2017-07-28 21:55:49,898 Epoch[27] Batch [1100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106355,	
2017-07-28 21:55:55,685 Epoch[27] Batch [1110]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106361,	
2017-07-28 21:56:01,527 Epoch[27] Batch [1120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106341,	
2017-07-28 21:56:07,466 Epoch[27] Batch [1130]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106365,	
2017-07-28 21:56:13,839 Epoch[27] Batch [1140]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.106287,	
2017-07-28 21:56:19,702 Epoch[27] Batch [1150]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106303,	
2017-07-28 21:56:25,459 Epoch[27] Batch [1160]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106345,	
2017-07-28 21:56:31,254 Epoch[27] Batch [1170]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106398,	
2017-07-28 21:56:37,034 Epoch[27] Batch [1180]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106364,	
2017-07-28 21:56:42,838 Epoch[27] Batch [1190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106381,	
2017-07-28 21:56:48,900 Epoch[27] Batch [1200]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106452,	
2017-07-28 21:56:55,025 Epoch[27] Batch [1210]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106329,	
2017-07-28 21:57:00,921 Epoch[27] Batch [1220]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106269,	
2017-07-28 21:57:07,186 Epoch[27] Batch [1230]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.106273,	
2017-07-28 21:57:13,160 Epoch[27] Batch [1240]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106282,	
2017-07-28 21:57:19,140 Epoch[27] Batch [1250]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106432,	
2017-07-28 21:57:24,940 Epoch[27] Batch [1260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106487,	
2017-07-28 21:57:30,750 Epoch[27] Batch [1270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106601,	
2017-07-28 21:57:36,903 Epoch[27] Batch [1280]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.106593,	
2017-07-28 21:57:42,696 Epoch[27] Batch [1290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106611,	
2017-07-28 21:57:48,695 Epoch[27] Batch [1300]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.106569,	
2017-07-28 21:57:54,732 Epoch[27] Batch [1310]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.106596,	
2017-07-28 21:58:00,764 Epoch[27] Batch [1320]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.106655,	
2017-07-28 21:58:06,520 Epoch[27] Batch [1330]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106756,	
2017-07-28 21:58:12,693 Epoch[27] Batch [1340]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.106770,	
2017-07-28 21:58:18,960 Epoch[27] Batch [1350]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.106875,	
2017-07-28 21:58:25,755 Epoch[27] Batch [1360]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.106820,	
2017-07-28 21:58:31,479 Epoch[27] Batch [1370]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.106746,	
2017-07-28 21:58:37,638 Epoch[27] Batch [1380]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.106720,	
2017-07-28 21:58:43,436 Epoch[27] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106666,	
2017-07-28 21:58:49,261 Epoch[27] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106602,	
2017-07-28 21:58:55,119 Epoch[27] Batch [1410]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106518,	
2017-07-28 21:59:00,905 Epoch[27] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106610,	
2017-07-28 21:59:06,697 Epoch[27] Batch [1430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106550,	
2017-07-28 21:59:12,512 Epoch[27] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106543,	
2017-07-28 21:59:18,325 Epoch[27] Batch [1450]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106460,	
2017-07-28 21:59:24,127 Epoch[27] Batch [1460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106375,	
2017-07-28 21:59:29,949 Epoch[27] Batch [1470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106374,	
2017-07-28 21:59:35,735 Epoch[27] Batch [1480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106349,	
2017-07-28 21:59:39,205 Epoch[27] Train-FCNLogLoss=0.106308
2017-07-28 21:59:39,205 Epoch[27] Time cost=882.587
2017-07-28 21:59:40,267 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0028.params"
2017-07-28 21:59:44,242 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0028.states"
2017-07-28 21:59:51,238 Epoch[28] Batch [10]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103596,	
2017-07-28 21:59:56,972 Epoch[28] Batch [20]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099996,	
2017-07-28 22:00:02,993 Epoch[28] Batch [30]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099453,	
2017-07-28 22:00:08,872 Epoch[28] Batch [40]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.099952,	
2017-07-28 22:00:14,608 Epoch[28] Batch [50]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100679,	
2017-07-28 22:00:20,395 Epoch[28] Batch [60]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102894,	
2017-07-28 22:00:26,157 Epoch[28] Batch [70]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102876,	
2017-07-28 22:00:32,016 Epoch[28] Batch [80]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.102849,	
2017-07-28 22:00:37,810 Epoch[28] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103224,	
2017-07-28 22:00:43,587 Epoch[28] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105689,	
2017-07-28 22:00:49,414 Epoch[28] Batch [110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106600,	
2017-07-28 22:00:55,184 Epoch[28] Batch [120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106870,	
2017-07-28 22:01:01,063 Epoch[28] Batch [130]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.106387,	
2017-07-28 22:01:07,249 Epoch[28] Batch [140]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.105892,	
2017-07-28 22:01:13,825 Epoch[28] Batch [150]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.105446,	
2017-07-28 22:01:19,764 Epoch[28] Batch [160]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105178,	
2017-07-28 22:01:25,595 Epoch[28] Batch [170]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105196,	
2017-07-28 22:01:31,400 Epoch[28] Batch [180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105263,	
2017-07-28 22:01:37,093 Epoch[28] Batch [190]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.105130,	
2017-07-28 22:01:42,891 Epoch[28] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105046,	
2017-07-28 22:01:48,710 Epoch[28] Batch [210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.104627,	
2017-07-28 22:01:54,549 Epoch[28] Batch [220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.104334,	
2017-07-28 22:02:00,288 Epoch[28] Batch [230]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.104484,	
2017-07-28 22:02:06,130 Epoch[28] Batch [240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105021,	
2017-07-28 22:02:11,912 Epoch[28] Batch [250]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105311,	
2017-07-28 22:02:17,732 Epoch[28] Batch [260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105931,	
2017-07-28 22:02:23,847 Epoch[28] Batch [270]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106437,	
2017-07-28 22:02:29,661 Epoch[28] Batch [280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.106468,	
2017-07-28 22:02:35,491 Epoch[28] Batch [290]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106639,	
2017-07-28 22:02:41,295 Epoch[28] Batch [300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106258,	
2017-07-28 22:02:47,080 Epoch[28] Batch [310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106239,	
2017-07-28 22:02:52,871 Epoch[28] Batch [320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106137,	
2017-07-28 22:02:58,697 Epoch[28] Batch [330]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106248,	
2017-07-28 22:03:04,502 Epoch[28] Batch [340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106269,	
2017-07-28 22:03:10,280 Epoch[28] Batch [350]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106126,	
2017-07-28 22:03:16,154 Epoch[28] Batch [360]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106230,	
2017-07-28 22:03:22,046 Epoch[28] Batch [370]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.105766,	
2017-07-28 22:03:27,736 Epoch[28] Batch [380]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.105705,	
2017-07-28 22:03:33,579 Epoch[28] Batch [390]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105676,	
2017-07-28 22:03:39,303 Epoch[28] Batch [400]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.105994,	
2017-07-28 22:03:45,131 Epoch[28] Batch [410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105825,	
2017-07-28 22:03:50,962 Epoch[28] Batch [420]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105678,	
2017-07-28 22:03:56,789 Epoch[28] Batch [430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105752,	
2017-07-28 22:04:02,623 Epoch[28] Batch [440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.105557,	
2017-07-28 22:04:08,460 Epoch[28] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105501,	
2017-07-28 22:04:14,203 Epoch[28] Batch [460]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.105482,	
2017-07-28 22:04:19,938 Epoch[28] Batch [470]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.105403,	
2017-07-28 22:04:25,831 Epoch[28] Batch [480]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.105440,	
2017-07-28 22:04:31,647 Epoch[28] Batch [490]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105500,	
2017-07-28 22:04:38,132 Epoch[28] Batch [500]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.105838,	
2017-07-28 22:04:44,003 Epoch[28] Batch [510]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.105925,	
2017-07-28 22:04:49,756 Epoch[28] Batch [520]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.105913,	
2017-07-28 22:04:55,546 Epoch[28] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105893,	
2017-07-28 22:05:01,335 Epoch[28] Batch [540]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105911,	
2017-07-28 22:05:07,121 Epoch[28] Batch [550]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105832,	
2017-07-28 22:05:13,123 Epoch[28] Batch [560]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.105856,	
2017-07-28 22:05:18,927 Epoch[28] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105687,	
2017-07-28 22:05:24,713 Epoch[28] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105558,	
2017-07-28 22:05:30,725 Epoch[28] Batch [590]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.105389,	
2017-07-28 22:05:37,171 Epoch[28] Batch [600]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.105178,	
2017-07-28 22:05:43,095 Epoch[28] Batch [610]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105083,	
2017-07-28 22:05:48,842 Epoch[28] Batch [620]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105142,	
2017-07-28 22:05:54,691 Epoch[28] Batch [630]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105050,	
2017-07-28 22:06:00,901 Epoch[28] Batch [640]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.104875,	
2017-07-28 22:06:06,777 Epoch[28] Batch [650]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104859,	
2017-07-28 22:06:12,614 Epoch[28] Batch [660]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.104926,	
2017-07-28 22:06:18,422 Epoch[28] Batch [670]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104753,	
2017-07-28 22:06:24,209 Epoch[28] Batch [680]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104778,	
2017-07-28 22:06:30,040 Epoch[28] Batch [690]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.104689,	
2017-07-28 22:06:35,832 Epoch[28] Batch [700]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104614,	
2017-07-28 22:06:41,822 Epoch[28] Batch [710]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.104449,	
2017-07-28 22:06:47,843 Epoch[28] Batch [720]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.104341,	
2017-07-28 22:06:54,390 Epoch[28] Batch [730]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.104480,	
2017-07-28 22:07:00,379 Epoch[28] Batch [740]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.104481,	
2017-07-28 22:07:06,191 Epoch[28] Batch [750]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104416,	
2017-07-28 22:07:11,942 Epoch[28] Batch [760]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.104405,	
2017-07-28 22:07:17,771 Epoch[28] Batch [770]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.104491,	
2017-07-28 22:07:23,622 Epoch[28] Batch [780]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.104476,	
2017-07-28 22:07:29,493 Epoch[28] Batch [790]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104439,	
2017-07-28 22:07:35,254 Epoch[28] Batch [800]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.104272,	
2017-07-28 22:07:41,030 Epoch[28] Batch [810]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.104298,	
2017-07-28 22:07:46,853 Epoch[28] Batch [820]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.104213,	
2017-07-28 22:07:52,660 Epoch[28] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104196,	
2017-07-28 22:07:58,462 Epoch[28] Batch [840]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.104208,	
2017-07-28 22:08:04,267 Epoch[28] Batch [850]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104288,	
2017-07-28 22:08:10,074 Epoch[28] Batch [860]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104130,	
2017-07-28 22:08:15,922 Epoch[28] Batch [870]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.104072,	
2017-07-28 22:08:21,703 Epoch[28] Batch [880]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104156,	
2017-07-28 22:08:27,515 Epoch[28] Batch [890]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104014,	
2017-07-28 22:08:33,312 Epoch[28] Batch [900]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103922,	
2017-07-28 22:08:39,080 Epoch[28] Batch [910]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103926,	
2017-07-28 22:08:44,942 Epoch[28] Batch [920]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.104010,	
2017-07-28 22:08:50,741 Epoch[28] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103926,	
2017-07-28 22:08:56,482 Epoch[28] Batch [940]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.104036,	
2017-07-28 22:09:02,340 Epoch[28] Batch [950]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.104012,	
2017-07-28 22:09:08,227 Epoch[28] Batch [960]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.103884,	
2017-07-28 22:09:14,312 Epoch[28] Batch [970]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103831,	
2017-07-28 22:09:20,056 Epoch[28] Batch [980]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.103770,	
2017-07-28 22:09:26,131 Epoch[28] Batch [990]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103705,	
2017-07-28 22:09:32,393 Epoch[28] Batch [1000]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.103618,	
2017-07-28 22:09:38,819 Epoch[28] Batch [1010]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.103635,	
2017-07-28 22:09:44,696 Epoch[28] Batch [1020]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.103632,	
2017-07-28 22:09:50,471 Epoch[28] Batch [1030]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103453,	
2017-07-28 22:09:56,262 Epoch[28] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103458,	
2017-07-28 22:10:01,958 Epoch[28] Batch [1050]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.103437,	
2017-07-28 22:10:07,767 Epoch[28] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103305,	
2017-07-28 22:10:13,572 Epoch[28] Batch [1070]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103312,	
2017-07-28 22:10:19,384 Epoch[28] Batch [1080]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103301,	
2017-07-28 22:10:25,216 Epoch[28] Batch [1090]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103306,	
2017-07-28 22:10:31,011 Epoch[28] Batch [1100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103192,	
2017-07-28 22:10:36,823 Epoch[28] Batch [1110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103115,	
2017-07-28 22:10:42,606 Epoch[28] Batch [1120]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103105,	
2017-07-28 22:10:48,422 Epoch[28] Batch [1130]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102997,	
2017-07-28 22:10:54,232 Epoch[28] Batch [1140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102917,	
2017-07-28 22:11:00,025 Epoch[28] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102926,	
2017-07-28 22:11:05,810 Epoch[28] Batch [1160]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102802,	
2017-07-28 22:11:11,594 Epoch[28] Batch [1170]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102731,	
2017-07-28 22:11:17,426 Epoch[28] Batch [1180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102842,	
2017-07-28 22:11:23,206 Epoch[28] Batch [1190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102861,	
2017-07-28 22:11:29,035 Epoch[28] Batch [1200]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102859,	
2017-07-28 22:11:34,829 Epoch[28] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102856,	
2017-07-28 22:11:40,652 Epoch[28] Batch [1220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102794,	
2017-07-28 22:11:46,443 Epoch[28] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102788,	
2017-07-28 22:11:52,283 Epoch[28] Batch [1240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102776,	
2017-07-28 22:11:58,066 Epoch[28] Batch [1250]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102807,	
2017-07-28 22:12:03,864 Epoch[28] Batch [1260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103301,	
2017-07-28 22:12:09,673 Epoch[28] Batch [1270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103340,	
2017-07-28 22:12:15,470 Epoch[28] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103327,	
2017-07-28 22:12:21,309 Epoch[28] Batch [1290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103462,	
2017-07-28 22:12:27,105 Epoch[28] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103601,	
2017-07-28 22:12:32,967 Epoch[28] Batch [1310]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103633,	
2017-07-28 22:12:38,703 Epoch[28] Batch [1320]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.103624,	
2017-07-28 22:12:44,510 Epoch[28] Batch [1330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103597,	
2017-07-28 22:12:50,343 Epoch[28] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103556,	
2017-07-28 22:12:56,132 Epoch[28] Batch [1350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103606,	
2017-07-28 22:13:01,973 Epoch[28] Batch [1360]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103576,	
2017-07-28 22:13:07,779 Epoch[28] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103556,	
2017-07-28 22:13:13,654 Epoch[28] Batch [1380]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.103561,	
2017-07-28 22:13:19,377 Epoch[28] Batch [1390]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.103499,	
2017-07-28 22:13:25,164 Epoch[28] Batch [1400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103513,	
2017-07-28 22:13:30,972 Epoch[28] Batch [1410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103510,	
2017-07-28 22:13:36,734 Epoch[28] Batch [1420]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103522,	
2017-07-28 22:13:42,573 Epoch[28] Batch [1430]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103636,	
2017-07-28 22:13:48,356 Epoch[28] Batch [1440]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103625,	
2017-07-28 22:13:54,267 Epoch[28] Batch [1450]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103739,	
2017-07-28 22:13:59,998 Epoch[28] Batch [1460]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.103717,	
2017-07-28 22:14:05,800 Epoch[28] Batch [1470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103669,	
2017-07-28 22:14:11,653 Epoch[28] Batch [1480]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103655,	
2017-07-28 22:14:15,088 Epoch[28] Train-FCNLogLoss=0.103570
2017-07-28 22:14:15,088 Epoch[28] Time cost=870.845
2017-07-28 22:14:16,073 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0029.params"
2017-07-28 22:14:19,997 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0029.states"
2017-07-28 22:14:26,751 Epoch[29] Batch [10]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105055,	
2017-07-28 22:14:32,759 Epoch[29] Batch [20]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101703,	
2017-07-28 22:14:38,560 Epoch[29] Batch [30]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098244,	
2017-07-28 22:14:44,390 Epoch[29] Batch [40]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098019,	
2017-07-28 22:14:50,195 Epoch[29] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096504,	
2017-07-28 22:14:56,106 Epoch[29] Batch [60]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.096868,	
2017-07-28 22:15:02,451 Epoch[29] Batch [70]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.095194,	
2017-07-28 22:15:08,462 Epoch[29] Batch [80]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.095173,	
2017-07-28 22:15:14,174 Epoch[29] Batch [90]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.096594,	
2017-07-28 22:15:19,965 Epoch[29] Batch [100]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.095223,	
2017-07-28 22:15:25,769 Epoch[29] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096554,	
2017-07-28 22:15:31,532 Epoch[29] Batch [120]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097543,	
2017-07-28 22:15:37,331 Epoch[29] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097555,	
2017-07-28 22:15:43,173 Epoch[29] Batch [140]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.098151,	
2017-07-28 22:15:48,989 Epoch[29] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098205,	
2017-07-28 22:15:54,839 Epoch[29] Batch [160]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098584,	
2017-07-28 22:16:00,619 Epoch[29] Batch [170]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098294,	
2017-07-28 22:16:06,475 Epoch[29] Batch [180]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099224,	
2017-07-28 22:16:12,303 Epoch[29] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099745,	
2017-07-28 22:16:18,074 Epoch[29] Batch [200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100203,	
2017-07-28 22:16:23,885 Epoch[29] Batch [210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100295,	
2017-07-28 22:16:29,736 Epoch[29] Batch [220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100323,	
2017-07-28 22:16:35,598 Epoch[29] Batch [230]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.100453,	
2017-07-28 22:16:41,380 Epoch[29] Batch [240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100731,	
2017-07-28 22:16:47,141 Epoch[29] Batch [250]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101272,	
2017-07-28 22:16:52,959 Epoch[29] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101308,	
2017-07-28 22:16:58,809 Epoch[29] Batch [270]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.101062,	
2017-07-28 22:17:04,641 Epoch[29] Batch [280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101089,	
2017-07-28 22:17:10,390 Epoch[29] Batch [290]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.100883,	
2017-07-28 22:17:16,566 Epoch[29] Batch [300]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101161,	
2017-07-28 22:17:22,301 Epoch[29] Batch [310]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.101087,	
2017-07-28 22:17:28,192 Epoch[29] Batch [320]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.101235,	
2017-07-28 22:17:34,266 Epoch[29] Batch [330]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101369,	
2017-07-28 22:17:40,406 Epoch[29] Batch [340]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101240,	
2017-07-28 22:17:46,199 Epoch[29] Batch [350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101257,	
2017-07-28 22:17:52,338 Epoch[29] Batch [360]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101634,	
2017-07-28 22:17:58,845 Epoch[29] Batch [370]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.102628,	
2017-07-28 22:18:05,739 Epoch[29] Batch [380]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.102960,	
2017-07-28 22:18:12,714 Epoch[29] Batch [390]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.102970,	
2017-07-28 22:18:19,567 Epoch[29] Batch [400]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.103619,	
2017-07-28 22:18:25,416 Epoch[29] Batch [410]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.103753,	
2017-07-28 22:18:31,198 Epoch[29] Batch [420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104004,	
2017-07-28 22:18:36,939 Epoch[29] Batch [430]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.103872,	
2017-07-28 22:18:42,983 Epoch[29] Batch [440]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103853,	
2017-07-28 22:18:49,126 Epoch[29] Batch [450]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103832,	
2017-07-28 22:18:54,916 Epoch[29] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103961,	
2017-07-28 22:19:00,783 Epoch[29] Batch [470]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103974,	
2017-07-28 22:19:06,595 Epoch[29] Batch [480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104438,	
2017-07-28 22:19:12,350 Epoch[29] Batch [490]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.104921,	
2017-07-28 22:19:18,150 Epoch[29] Batch [500]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.104927,	
2017-07-28 22:19:23,948 Epoch[29] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105299,	
2017-07-28 22:19:29,710 Epoch[29] Batch [520]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.105286,	
2017-07-28 22:19:35,526 Epoch[29] Batch [530]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105283,	
2017-07-28 22:19:41,300 Epoch[29] Batch [540]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105259,	
2017-07-28 22:19:46,146 Epoch[29] Batch [550]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.105041,	
2017-07-28 22:19:51,583 Epoch[29] Batch [560]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.104860,	
2017-07-28 22:19:57,374 Epoch[29] Batch [570]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104711,	
2017-07-28 22:20:03,095 Epoch[29] Batch [580]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.104696,	
2017-07-28 22:20:08,867 Epoch[29] Batch [590]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.104849,	
2017-07-28 22:20:14,656 Epoch[29] Batch [600]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104843,	
2017-07-28 22:20:20,457 Epoch[29] Batch [610]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.104966,	
2017-07-28 22:20:26,248 Epoch[29] Batch [620]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104807,	
2017-07-28 22:20:32,032 Epoch[29] Batch [630]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104718,	
2017-07-28 22:20:37,853 Epoch[29] Batch [640]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.104553,	
2017-07-28 22:20:43,623 Epoch[29] Batch [650]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.104679,	
2017-07-28 22:20:49,405 Epoch[29] Batch [660]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104548,	
2017-07-28 22:20:55,193 Epoch[29] Batch [670]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104610,	
2017-07-28 22:21:00,982 Epoch[29] Batch [680]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104551,	
2017-07-28 22:21:06,797 Epoch[29] Batch [690]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104493,	
2017-07-28 22:21:12,544 Epoch[29] Batch [700]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.104293,	
2017-07-28 22:21:18,401 Epoch[29] Batch [710]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.104130,	
2017-07-28 22:21:24,142 Epoch[29] Batch [720]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.104237,	
2017-07-28 22:21:29,924 Epoch[29] Batch [730]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104114,	
2017-07-28 22:21:35,764 Epoch[29] Batch [740]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.104098,	
2017-07-28 22:21:41,528 Epoch[29] Batch [750]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103977,	
2017-07-28 22:21:47,346 Epoch[29] Batch [760]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104046,	
2017-07-28 22:21:53,126 Epoch[29] Batch [770]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104237,	
2017-07-28 22:21:58,916 Epoch[29] Batch [780]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104217,	
2017-07-28 22:22:04,720 Epoch[29] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104232,	
2017-07-28 22:22:10,550 Epoch[29] Batch [800]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.104092,	
2017-07-28 22:22:16,373 Epoch[29] Batch [810]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.104168,	
2017-07-28 22:22:22,142 Epoch[29] Batch [820]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.104244,	
2017-07-28 22:22:27,945 Epoch[29] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104099,	
2017-07-28 22:22:33,721 Epoch[29] Batch [840]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104030,	
2017-07-28 22:22:39,503 Epoch[29] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104110,	
2017-07-28 22:22:45,309 Epoch[29] Batch [860]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104108,	
2017-07-28 22:22:51,125 Epoch[29] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104047,	
2017-07-28 22:22:56,907 Epoch[29] Batch [880]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104211,	
2017-07-28 22:23:02,710 Epoch[29] Batch [890]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104182,	
2017-07-28 22:23:08,488 Epoch[29] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104090,	
2017-07-28 22:23:14,297 Epoch[29] Batch [910]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104157,	
2017-07-28 22:23:20,118 Epoch[29] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.104105,	
2017-07-28 22:23:25,900 Epoch[29] Batch [930]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104057,	
2017-07-28 22:23:31,682 Epoch[29] Batch [940]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104046,	
2017-07-28 22:23:37,462 Epoch[29] Batch [950]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104014,	
2017-07-28 22:23:43,319 Epoch[29] Batch [960]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103979,	
2017-07-28 22:23:49,079 Epoch[29] Batch [970]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103822,	
2017-07-28 22:23:54,904 Epoch[29] Batch [980]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103787,	
2017-07-28 22:24:00,697 Epoch[29] Batch [990]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103787,	
2017-07-28 22:24:06,532 Epoch[29] Batch [1000]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103803,	
2017-07-28 22:24:12,299 Epoch[29] Batch [1010]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103784,	
2017-07-28 22:24:18,122 Epoch[29] Batch [1020]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103770,	
2017-07-28 22:24:23,894 Epoch[29] Batch [1030]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103784,	
2017-07-28 22:24:29,682 Epoch[29] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103759,	
2017-07-28 22:24:35,481 Epoch[29] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103645,	
2017-07-28 22:24:41,345 Epoch[29] Batch [1060]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103609,	
2017-07-28 22:24:47,172 Epoch[29] Batch [1070]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103635,	
2017-07-28 22:24:52,958 Epoch[29] Batch [1080]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103694,	
2017-07-28 22:24:58,749 Epoch[29] Batch [1090]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103714,	
2017-07-28 22:25:04,514 Epoch[29] Batch [1100]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103587,	
2017-07-28 22:25:10,367 Epoch[29] Batch [1110]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103409,	
2017-07-28 22:25:16,156 Epoch[29] Batch [1120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103295,	
2017-07-28 22:25:21,999 Epoch[29] Batch [1130]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103225,	
2017-07-28 22:25:27,794 Epoch[29] Batch [1140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103216,	
2017-07-28 22:25:33,596 Epoch[29] Batch [1150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103182,	
2017-07-28 22:25:39,365 Epoch[29] Batch [1160]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103162,	
2017-07-28 22:25:45,177 Epoch[29] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103204,	
2017-07-28 22:25:51,000 Epoch[29] Batch [1180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103182,	
2017-07-28 22:25:56,795 Epoch[29] Batch [1190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103284,	
2017-07-28 22:26:02,626 Epoch[29] Batch [1200]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103307,	
2017-07-28 22:26:08,408 Epoch[29] Batch [1210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103348,	
2017-07-28 22:26:14,209 Epoch[29] Batch [1220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103316,	
2017-07-28 22:26:20,021 Epoch[29] Batch [1230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103282,	
2017-07-28 22:26:25,822 Epoch[29] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103185,	
2017-07-28 22:26:31,630 Epoch[29] Batch [1250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103222,	
2017-07-28 22:26:37,441 Epoch[29] Batch [1260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103247,	
2017-07-28 22:26:43,216 Epoch[29] Batch [1270]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103207,	
2017-07-28 22:26:49,039 Epoch[29] Batch [1280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103231,	
2017-07-28 22:26:54,832 Epoch[29] Batch [1290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103233,	
2017-07-28 22:27:00,633 Epoch[29] Batch [1300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103289,	
2017-07-28 22:27:06,430 Epoch[29] Batch [1310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103280,	
2017-07-28 22:27:12,193 Epoch[29] Batch [1320]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103228,	
2017-07-28 22:27:18,027 Epoch[29] Batch [1330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103277,	
2017-07-28 22:27:23,838 Epoch[29] Batch [1340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103228,	
2017-07-28 22:27:29,640 Epoch[29] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103138,	
2017-07-28 22:27:35,427 Epoch[29] Batch [1360]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103099,	
2017-07-28 22:27:41,214 Epoch[29] Batch [1370]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103111,	
2017-07-28 22:27:47,061 Epoch[29] Batch [1380]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.103058,	
2017-07-28 22:27:52,807 Epoch[29] Batch [1390]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.103140,	
2017-07-28 22:27:58,646 Epoch[29] Batch [1400]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103111,	
2017-07-28 22:28:04,419 Epoch[29] Batch [1410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103113,	
2017-07-28 22:28:10,257 Epoch[29] Batch [1420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103125,	
2017-07-28 22:28:15,997 Epoch[29] Batch [1430]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.103112,	
2017-07-28 22:28:21,798 Epoch[29] Batch [1440]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103103,	
2017-07-28 22:28:27,588 Epoch[29] Batch [1450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103043,	
2017-07-28 22:28:33,373 Epoch[29] Batch [1460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103008,	
2017-07-28 22:28:39,184 Epoch[29] Batch [1470]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102963,	
2017-07-28 22:28:44,992 Epoch[29] Batch [1480]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103023,	
2017-07-28 22:28:48,439 Epoch[29] Train-FCNLogLoss=0.102997
2017-07-28 22:28:48,439 Epoch[29] Time cost=868.442
2017-07-28 22:28:49,224 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0030.params"
2017-07-28 22:28:51,041 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0030.states"
2017-07-28 22:28:57,657 Epoch[30] Batch [10]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100411,	
2017-07-28 22:29:03,474 Epoch[30] Batch [20]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100640,	
2017-07-28 22:29:09,223 Epoch[30] Batch [30]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099638,	
2017-07-28 22:29:14,989 Epoch[30] Batch [40]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100959,	
2017-07-28 22:29:20,760 Epoch[30] Batch [50]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.099784,	
2017-07-28 22:29:26,556 Epoch[30] Batch [60]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098498,	
2017-07-28 22:29:32,336 Epoch[30] Batch [70]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098935,	
2017-07-28 22:29:38,097 Epoch[30] Batch [80]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098586,	
2017-07-28 22:29:43,911 Epoch[30] Batch [90]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097928,	
2017-07-28 22:29:49,705 Epoch[30] Batch [100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098452,	
2017-07-28 22:29:55,498 Epoch[30] Batch [110]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098380,	
2017-07-28 22:30:01,270 Epoch[30] Batch [120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098736,	
2017-07-28 22:30:07,062 Epoch[30] Batch [130]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099182,	
2017-07-28 22:30:12,844 Epoch[30] Batch [140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099847,	
2017-07-28 22:30:18,643 Epoch[30] Batch [150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100076,	
2017-07-28 22:30:24,459 Epoch[30] Batch [160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100140,	
2017-07-28 22:30:30,209 Epoch[30] Batch [170]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099866,	
2017-07-28 22:30:36,010 Epoch[30] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100187,	
2017-07-28 22:30:41,799 Epoch[30] Batch [190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099745,	
2017-07-28 22:30:47,562 Epoch[30] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099496,	
2017-07-28 22:30:53,372 Epoch[30] Batch [210]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099142,	
2017-07-28 22:30:59,149 Epoch[30] Batch [220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099513,	
2017-07-28 22:31:04,953 Epoch[30] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100294,	
2017-07-28 22:31:10,717 Epoch[30] Batch [240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100326,	
2017-07-28 22:31:16,505 Epoch[30] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100218,	
2017-07-28 22:31:22,305 Epoch[30] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099966,	
2017-07-28 22:31:28,090 Epoch[30] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099994,	
2017-07-28 22:31:33,882 Epoch[30] Batch [280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100439,	
2017-07-28 22:31:39,654 Epoch[30] Batch [290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100613,	
2017-07-28 22:31:45,492 Epoch[30] Batch [300]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100704,	
2017-07-28 22:31:51,259 Epoch[30] Batch [310]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100672,	
2017-07-28 22:31:57,037 Epoch[30] Batch [320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100739,	
2017-07-28 22:32:02,817 Epoch[30] Batch [330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100825,	
2017-07-28 22:32:08,635 Epoch[30] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100572,	
2017-07-28 22:32:14,437 Epoch[30] Batch [350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100247,	
2017-07-28 22:32:20,172 Epoch[30] Batch [360]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100469,	
2017-07-28 22:32:26,029 Epoch[30] Batch [370]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.100313,	
2017-07-28 22:32:31,780 Epoch[30] Batch [380]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.100497,	
2017-07-28 22:32:37,582 Epoch[30] Batch [390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100465,	
2017-07-28 22:32:43,392 Epoch[30] Batch [400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100494,	
2017-07-28 22:32:49,159 Epoch[30] Batch [410]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100591,	
2017-07-28 22:32:54,954 Epoch[30] Batch [420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100602,	
2017-07-28 22:33:00,765 Epoch[30] Batch [430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100589,	
2017-07-28 22:33:06,533 Epoch[30] Batch [440]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100393,	
2017-07-28 22:33:12,371 Epoch[30] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100418,	
2017-07-28 22:33:18,144 Epoch[30] Batch [460]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100571,	
2017-07-28 22:33:23,958 Epoch[30] Batch [470]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100766,	
2017-07-28 22:33:29,742 Epoch[30] Batch [480]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100772,	
2017-07-28 22:33:35,531 Epoch[30] Batch [490]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100645,	
2017-07-28 22:33:41,337 Epoch[30] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101014,	
2017-07-28 22:33:47,123 Epoch[30] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100974,	
2017-07-28 22:33:52,904 Epoch[30] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100988,	
2017-07-28 22:33:58,698 Epoch[30] Batch [530]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100959,	
2017-07-28 22:34:04,491 Epoch[30] Batch [540]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100896,	
2017-07-28 22:34:09,217 Epoch[30] Batch [550]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.100991,	
2017-07-28 22:34:14,577 Epoch[30] Batch [560]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100841,	
2017-07-28 22:34:20,388 Epoch[30] Batch [570]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100470,	
2017-07-28 22:34:26,182 Epoch[30] Batch [580]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100323,	
2017-07-28 22:34:31,953 Epoch[30] Batch [590]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100342,	
2017-07-28 22:34:37,764 Epoch[30] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100237,	
2017-07-28 22:34:43,560 Epoch[30] Batch [610]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100154,	
2017-07-28 22:34:49,333 Epoch[30] Batch [620]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100325,	
2017-07-28 22:34:55,136 Epoch[30] Batch [630]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100304,	
2017-07-28 22:35:00,957 Epoch[30] Batch [640]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100317,	
2017-07-28 22:35:06,768 Epoch[30] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100448,	
2017-07-28 22:35:12,522 Epoch[30] Batch [660]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.100503,	
2017-07-28 22:35:18,343 Epoch[30] Batch [670]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100333,	
2017-07-28 22:35:24,114 Epoch[30] Batch [680]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100209,	
2017-07-28 22:35:29,919 Epoch[30] Batch [690]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100204,	
2017-07-28 22:35:35,744 Epoch[30] Batch [700]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100084,	
2017-07-28 22:35:41,503 Epoch[30] Batch [710]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.100106,	
2017-07-28 22:35:47,322 Epoch[30] Batch [720]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100048,	
2017-07-28 22:35:53,123 Epoch[30] Batch [730]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100106,	
2017-07-28 22:35:58,886 Epoch[30] Batch [740]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100244,	
2017-07-28 22:36:04,710 Epoch[30] Batch [750]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100192,	
2017-07-28 22:36:10,497 Epoch[30] Batch [760]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100113,	
2017-07-28 22:36:16,286 Epoch[30] Batch [770]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100102,	
2017-07-28 22:36:22,118 Epoch[30] Batch [780]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100029,	
2017-07-28 22:36:27,943 Epoch[30] Batch [790]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100020,	
2017-07-28 22:36:33,735 Epoch[30] Batch [800]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100054,	
2017-07-28 22:36:39,475 Epoch[30] Batch [810]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.099935,	
2017-07-28 22:36:45,288 Epoch[30] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100055,	
2017-07-28 22:36:51,069 Epoch[30] Batch [830]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100017,	
2017-07-28 22:36:56,888 Epoch[30] Batch [840]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100014,	
2017-07-28 22:37:02,648 Epoch[30] Batch [850]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100024,	
2017-07-28 22:37:08,499 Epoch[30] Batch [860]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100024,	
2017-07-28 22:37:14,281 Epoch[30] Batch [870]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099931,	
2017-07-28 22:37:20,025 Epoch[30] Batch [880]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099836,	
2017-07-28 22:37:25,760 Epoch[30] Batch [890]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099684,	
2017-07-28 22:37:31,587 Epoch[30] Batch [900]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099659,	
2017-07-28 22:37:37,365 Epoch[30] Batch [910]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099630,	
2017-07-28 22:37:43,190 Epoch[30] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099655,	
2017-07-28 22:37:48,952 Epoch[30] Batch [930]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099671,	
2017-07-28 22:37:54,760 Epoch[30] Batch [940]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099687,	
2017-07-28 22:38:00,578 Epoch[30] Batch [950]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099679,	
2017-07-28 22:38:06,370 Epoch[30] Batch [960]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099671,	
2017-07-28 22:38:12,147 Epoch[30] Batch [970]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099620,	
2017-07-28 22:38:17,962 Epoch[30] Batch [980]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099595,	
2017-07-28 22:38:23,757 Epoch[30] Batch [990]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099624,	
2017-07-28 22:38:29,571 Epoch[30] Batch [1000]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099759,	
2017-07-28 22:38:35,338 Epoch[30] Batch [1010]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099692,	
2017-07-28 22:38:41,171 Epoch[30] Batch [1020]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099740,	
2017-07-28 22:38:46,980 Epoch[30] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099849,	
2017-07-28 22:38:52,760 Epoch[30] Batch [1040]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099854,	
2017-07-28 22:38:58,549 Epoch[30] Batch [1050]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099828,	
2017-07-28 22:39:04,354 Epoch[30] Batch [1060]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099923,	
2017-07-28 22:39:10,110 Epoch[30] Batch [1070]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099855,	
2017-07-28 22:39:15,890 Epoch[30] Batch [1080]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099803,	
2017-07-28 22:39:21,688 Epoch[30] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099794,	
2017-07-28 22:39:27,446 Epoch[30] Batch [1100]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099721,	
2017-07-28 22:39:33,280 Epoch[30] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099653,	
2017-07-28 22:39:39,087 Epoch[30] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099600,	
2017-07-28 22:39:44,884 Epoch[30] Batch [1130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099509,	
2017-07-28 22:39:50,663 Epoch[30] Batch [1140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099499,	
2017-07-28 22:39:56,483 Epoch[30] Batch [1150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099488,	
2017-07-28 22:40:02,282 Epoch[30] Batch [1160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099573,	
2017-07-28 22:40:08,046 Epoch[30] Batch [1170]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099609,	
2017-07-28 22:40:13,855 Epoch[30] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099666,	
2017-07-28 22:40:19,642 Epoch[30] Batch [1190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099636,	
2017-07-28 22:40:25,428 Epoch[30] Batch [1200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099607,	
2017-07-28 22:40:31,253 Epoch[30] Batch [1210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099574,	
2017-07-28 22:40:37,075 Epoch[30] Batch [1220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099588,	
2017-07-28 22:40:42,864 Epoch[30] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099694,	
2017-07-28 22:40:48,681 Epoch[30] Batch [1240]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099649,	
2017-07-28 22:40:54,504 Epoch[30] Batch [1250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099614,	
2017-07-28 22:41:00,255 Epoch[30] Batch [1260]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099536,	
2017-07-28 22:41:06,017 Epoch[30] Batch [1270]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099539,	
2017-07-28 22:41:11,814 Epoch[30] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099621,	
2017-07-28 22:41:17,625 Epoch[30] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099645,	
2017-07-28 22:41:23,447 Epoch[30] Batch [1300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099732,	
2017-07-28 22:41:29,287 Epoch[30] Batch [1310]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099662,	
2017-07-28 22:41:35,003 Epoch[30] Batch [1320]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.099654,	
2017-07-28 22:41:40,807 Epoch[30] Batch [1330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099622,	
2017-07-28 22:41:46,637 Epoch[30] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099577,	
2017-07-28 22:41:52,402 Epoch[30] Batch [1350]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099571,	
2017-07-28 22:41:58,204 Epoch[30] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099610,	
2017-07-28 22:42:04,026 Epoch[30] Batch [1370]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099558,	
2017-07-28 22:42:09,825 Epoch[30] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099639,	
2017-07-28 22:42:15,623 Epoch[30] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099630,	
2017-07-28 22:42:21,437 Epoch[30] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099687,	
2017-07-28 22:42:27,278 Epoch[30] Batch [1410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099650,	
2017-07-28 22:42:33,009 Epoch[30] Batch [1420]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099722,	
2017-07-28 22:42:38,828 Epoch[30] Batch [1430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099671,	
2017-07-28 22:42:44,662 Epoch[30] Batch [1440]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099698,	
2017-07-28 22:42:50,461 Epoch[30] Batch [1450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099713,	
2017-07-28 22:42:56,248 Epoch[30] Batch [1460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099695,	
2017-07-28 22:43:02,047 Epoch[30] Batch [1470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099704,	
2017-07-28 22:43:07,863 Epoch[30] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099653,	
2017-07-28 22:43:11,340 Epoch[30] Train-FCNLogLoss=0.099669
2017-07-28 22:43:11,341 Epoch[30] Time cost=860.299
2017-07-28 22:43:12,185 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0031.params"
2017-07-28 22:43:14,093 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0031.states"
2017-07-28 22:43:20,665 Epoch[31] Batch [10]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103686,	
2017-07-28 22:43:26,471 Epoch[31] Batch [20]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102124,	
2017-07-28 22:43:32,242 Epoch[31] Batch [30]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098174,	
2017-07-28 22:43:38,022 Epoch[31] Batch [40]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102194,	
2017-07-28 22:43:43,830 Epoch[31] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099090,	
2017-07-28 22:43:49,626 Epoch[31] Batch [60]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099109,	
2017-07-28 22:43:55,438 Epoch[31] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098899,	
2017-07-28 22:44:01,199 Epoch[31] Batch [80]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098554,	
2017-07-28 22:44:06,979 Epoch[31] Batch [90]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098378,	
2017-07-28 22:44:12,789 Epoch[31] Batch [100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098060,	
2017-07-28 22:44:18,596 Epoch[31] Batch [110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098416,	
2017-07-28 22:44:24,348 Epoch[31] Batch [120]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.097468,	
2017-07-28 22:44:30,191 Epoch[31] Batch [130]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.096876,	
2017-07-28 22:44:35,951 Epoch[31] Batch [140]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096863,	
2017-07-28 22:44:41,766 Epoch[31] Batch [150]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096828,	
2017-07-28 22:44:47,531 Epoch[31] Batch [160]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097294,	
2017-07-28 22:44:53,313 Epoch[31] Batch [170]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097064,	
2017-07-28 22:44:59,067 Epoch[31] Batch [180]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.096869,	
2017-07-28 22:45:04,895 Epoch[31] Batch [190]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096670,	
2017-07-28 22:45:10,677 Epoch[31] Batch [200]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097382,	
2017-07-28 22:45:16,477 Epoch[31] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097050,	
2017-07-28 22:45:22,271 Epoch[31] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097048,	
2017-07-28 22:45:28,056 Epoch[31] Batch [230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097410,	
2017-07-28 22:45:33,767 Epoch[31] Batch [240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.097838,	
2017-07-28 22:45:39,498 Epoch[31] Batch [250]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.097331,	
2017-07-28 22:45:45,269 Epoch[31] Batch [260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097418,	
2017-07-28 22:45:51,060 Epoch[31] Batch [270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097554,	
2017-07-28 22:45:56,849 Epoch[31] Batch [280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097534,	
2017-07-28 22:46:02,633 Epoch[31] Batch [290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097747,	
2017-07-28 22:46:08,421 Epoch[31] Batch [300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097456,	
2017-07-28 22:46:14,292 Epoch[31] Batch [310]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.097399,	
2017-07-28 22:46:20,011 Epoch[31] Batch [320]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.097507,	
2017-07-28 22:46:25,851 Epoch[31] Batch [330]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.097655,	
2017-07-28 22:46:31,621 Epoch[31] Batch [340]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097435,	
2017-07-28 22:46:37,407 Epoch[31] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097559,	
2017-07-28 22:46:43,190 Epoch[31] Batch [360]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097168,	
2017-07-28 22:46:49,029 Epoch[31] Batch [370]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.097141,	
2017-07-28 22:46:54,808 Epoch[31] Batch [380]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097120,	
2017-07-28 22:47:00,605 Epoch[31] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097093,	
2017-07-28 22:47:06,398 Epoch[31] Batch [400]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097100,	
2017-07-28 22:47:12,193 Epoch[31] Batch [410]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097308,	
2017-07-28 22:47:17,988 Epoch[31] Batch [420]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097500,	
2017-07-28 22:47:23,793 Epoch[31] Batch [430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097779,	
2017-07-28 22:47:29,615 Epoch[31] Batch [440]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.097816,	
2017-07-28 22:47:35,385 Epoch[31] Batch [450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098024,	
2017-07-28 22:47:41,228 Epoch[31] Batch [460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.097982,	
2017-07-28 22:47:46,946 Epoch[31] Batch [470]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.097947,	
2017-07-28 22:47:52,711 Epoch[31] Batch [480]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097856,	
2017-07-28 22:47:58,502 Epoch[31] Batch [490]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097748,	
2017-07-28 22:48:04,275 Epoch[31] Batch [500]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097591,	
2017-07-28 22:48:10,106 Epoch[31] Batch [510]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097879,	
2017-07-28 22:48:15,872 Epoch[31] Batch [520]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097823,	
2017-07-28 22:48:21,663 Epoch[31] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097849,	
2017-07-28 22:48:27,467 Epoch[31] Batch [540]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097808,	
2017-07-28 22:48:32,361 Epoch[31] Batch [550]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.097716,	
2017-07-28 22:48:37,786 Epoch[31] Batch [560]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.097682,	
2017-07-28 22:48:43,596 Epoch[31] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097711,	
2017-07-28 22:48:49,366 Epoch[31] Batch [580]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097664,	
2017-07-28 22:48:55,176 Epoch[31] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097672,	
2017-07-28 22:49:00,992 Epoch[31] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097593,	
2017-07-28 22:49:06,748 Epoch[31] Batch [610]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.097771,	
2017-07-28 22:49:12,565 Epoch[31] Batch [620]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097721,	
2017-07-28 22:49:18,340 Epoch[31] Batch [630]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097535,	
2017-07-28 22:49:24,135 Epoch[31] Batch [640]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097692,	
2017-07-28 22:49:29,953 Epoch[31] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097734,	
2017-07-28 22:49:35,725 Epoch[31] Batch [660]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097632,	
2017-07-28 22:49:41,527 Epoch[31] Batch [670]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.097683,	
2017-07-28 22:49:47,328 Epoch[31] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097681,	
2017-07-28 22:49:53,098 Epoch[31] Batch [690]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097679,	
2017-07-28 22:49:58,898 Epoch[31] Batch [700]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097743,	
2017-07-28 22:50:04,687 Epoch[31] Batch [710]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097630,	
2017-07-28 22:50:10,519 Epoch[31] Batch [720]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097698,	
2017-07-28 22:50:16,265 Epoch[31] Batch [730]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.097888,	
2017-07-28 22:50:22,080 Epoch[31] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097764,	
2017-07-28 22:50:27,912 Epoch[31] Batch [750]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097791,	
2017-07-28 22:50:33,708 Epoch[31] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097831,	
2017-07-28 22:50:39,500 Epoch[31] Batch [770]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097830,	
2017-07-28 22:50:45,316 Epoch[31] Batch [780]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097890,	
2017-07-28 22:50:51,109 Epoch[31] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097912,	
2017-07-28 22:50:56,920 Epoch[31] Batch [800]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097887,	
2017-07-28 22:51:02,705 Epoch[31] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097942,	
2017-07-28 22:51:08,517 Epoch[31] Batch [820]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097892,	
2017-07-28 22:51:14,310 Epoch[31] Batch [830]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.097964,	
2017-07-28 22:51:20,144 Epoch[31] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097899,	
2017-07-28 22:51:25,860 Epoch[31] Batch [850]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.097954,	
2017-07-28 22:51:31,718 Epoch[31] Batch [860]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098024,	
2017-07-28 22:51:37,533 Epoch[31] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098123,	
2017-07-28 22:51:43,327 Epoch[31] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098100,	
2017-07-28 22:51:49,092 Epoch[31] Batch [890]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098047,	
2017-07-28 22:51:54,909 Epoch[31] Batch [900]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.097987,	
2017-07-28 22:52:00,720 Epoch[31] Batch [910]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098063,	
2017-07-28 22:52:06,492 Epoch[31] Batch [920]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098136,	
2017-07-28 22:52:12,298 Epoch[31] Batch [930]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098206,	
2017-07-28 22:52:18,081 Epoch[31] Batch [940]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098179,	
2017-07-28 22:52:23,884 Epoch[31] Batch [950]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098177,	
2017-07-28 22:52:29,671 Epoch[31] Batch [960]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098258,	
2017-07-28 22:52:35,527 Epoch[31] Batch [970]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098328,	
2017-07-28 22:52:41,266 Epoch[31] Batch [980]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.098284,	
2017-07-28 22:52:47,077 Epoch[31] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098489,	
2017-07-28 22:52:52,894 Epoch[31] Batch [1000]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098585,	
2017-07-28 22:52:58,665 Epoch[31] Batch [1010]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098415,	
2017-07-28 22:53:04,491 Epoch[31] Batch [1020]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098380,	
2017-07-28 22:53:10,241 Epoch[31] Batch [1030]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098403,	
2017-07-28 22:53:16,029 Epoch[31] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098415,	
2017-07-28 22:53:21,878 Epoch[31] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098463,	
2017-07-28 22:53:27,633 Epoch[31] Batch [1060]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098511,	
2017-07-28 22:53:33,456 Epoch[31] Batch [1070]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098435,	
2017-07-28 22:53:39,200 Epoch[31] Batch [1080]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098452,	
2017-07-28 22:53:45,044 Epoch[31] Batch [1090]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098388,	
2017-07-28 22:53:50,810 Epoch[31] Batch [1100]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098414,	
2017-07-28 22:53:56,675 Epoch[31] Batch [1110]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.098537,	
2017-07-28 22:54:02,426 Epoch[31] Batch [1120]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098498,	
2017-07-28 22:54:08,206 Epoch[31] Batch [1130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098481,	
2017-07-28 22:54:14,025 Epoch[31] Batch [1140]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098541,	
2017-07-28 22:54:19,798 Epoch[31] Batch [1150]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098530,	
2017-07-28 22:54:25,632 Epoch[31] Batch [1160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098553,	
2017-07-28 22:54:31,389 Epoch[31] Batch [1170]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098513,	
2017-07-28 22:54:37,221 Epoch[31] Batch [1180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098536,	
2017-07-28 22:54:43,003 Epoch[31] Batch [1190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098569,	
2017-07-28 22:54:48,769 Epoch[31] Batch [1200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098690,	
2017-07-28 22:54:54,590 Epoch[31] Batch [1210]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098688,	
2017-07-28 22:55:00,361 Epoch[31] Batch [1220]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098681,	
2017-07-28 22:55:06,172 Epoch[31] Batch [1230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098674,	
2017-07-28 22:55:11,968 Epoch[31] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098778,	
2017-07-28 22:55:17,770 Epoch[31] Batch [1250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098821,	
2017-07-28 22:55:23,532 Epoch[31] Batch [1260]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098727,	
2017-07-28 22:55:29,333 Epoch[31] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098690,	
2017-07-28 22:55:35,139 Epoch[31] Batch [1280]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098704,	
2017-07-28 22:55:40,931 Epoch[31] Batch [1290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098700,	
2017-07-28 22:55:46,718 Epoch[31] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098790,	
2017-07-28 22:55:52,534 Epoch[31] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098837,	
2017-07-28 22:55:58,277 Epoch[31] Batch [1320]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098893,	
2017-07-28 22:56:04,067 Epoch[31] Batch [1330]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098934,	
2017-07-28 22:56:09,866 Epoch[31] Batch [1340]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098953,	
2017-07-28 22:56:15,656 Epoch[31] Batch [1350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099031,	
2017-07-28 22:56:21,416 Epoch[31] Batch [1360]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099068,	
2017-07-28 22:56:27,225 Epoch[31] Batch [1370]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099068,	
2017-07-28 22:56:32,985 Epoch[31] Batch [1380]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099042,	
2017-07-28 22:56:38,803 Epoch[31] Batch [1390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099048,	
2017-07-28 22:56:44,613 Epoch[31] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099046,	
2017-07-28 22:56:50,405 Epoch[31] Batch [1410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099047,	
2017-07-28 22:56:56,192 Epoch[31] Batch [1420]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099150,	
2017-07-28 22:57:01,995 Epoch[31] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099116,	
2017-07-28 22:57:07,760 Epoch[31] Batch [1440]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099118,	
2017-07-28 22:57:13,582 Epoch[31] Batch [1450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099140,	
2017-07-28 22:57:19,316 Epoch[31] Batch [1460]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099125,	
2017-07-28 22:57:25,107 Epoch[31] Batch [1470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099139,	
2017-07-28 22:57:30,849 Epoch[31] Batch [1480]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.099135,	
2017-07-28 22:57:34,371 Epoch[31] Train-FCNLogLoss=0.099078
2017-07-28 22:57:34,371 Epoch[31] Time cost=860.277
2017-07-28 22:57:35,186 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0032.params"
2017-07-28 22:57:36,979 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0032.states"
2017-07-28 22:57:43,647 Epoch[32] Batch [10]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103324,	
2017-07-28 22:57:49,476 Epoch[32] Batch [20]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099443,	
2017-07-28 22:57:55,196 Epoch[32] Batch [30]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.099350,	
2017-07-28 22:58:01,021 Epoch[32] Batch [40]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101075,	
2017-07-28 22:58:06,801 Epoch[32] Batch [50]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099586,	
2017-07-28 22:58:12,623 Epoch[32] Batch [60]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098641,	
2017-07-28 22:58:18,426 Epoch[32] Batch [70]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100540,	
2017-07-28 22:58:24,232 Epoch[32] Batch [80]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100682,	
2017-07-28 22:58:30,012 Epoch[32] Batch [90]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100559,	
2017-07-28 22:58:35,796 Epoch[32] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102908,	
2017-07-28 22:58:41,580 Epoch[32] Batch [110]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103160,	
2017-07-28 22:58:47,439 Epoch[32] Batch [120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103809,	
2017-07-28 22:58:53,221 Epoch[32] Batch [130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103437,	
2017-07-28 22:58:59,006 Epoch[32] Batch [140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103330,	
2017-07-28 22:59:04,811 Epoch[32] Batch [150]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102969,	
2017-07-28 22:59:10,649 Epoch[32] Batch [160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103065,	
2017-07-28 22:59:16,412 Epoch[32] Batch [170]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102433,	
2017-07-28 22:59:22,186 Epoch[32] Batch [180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.102253,	
2017-07-28 22:59:27,970 Epoch[32] Batch [190]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102509,	
2017-07-28 22:59:33,771 Epoch[32] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102124,	
2017-07-28 22:59:39,575 Epoch[32] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101932,	
2017-07-28 22:59:45,366 Epoch[32] Batch [220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102597,	
2017-07-28 22:59:51,250 Epoch[32] Batch [230]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.102005,	
2017-07-28 22:59:56,967 Epoch[32] Batch [240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101686,	
2017-07-28 23:00:02,803 Epoch[32] Batch [250]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101928,	
2017-07-28 23:00:08,550 Epoch[32] Batch [260]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101869,	
2017-07-28 23:00:14,362 Epoch[32] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102266,	
2017-07-28 23:00:20,141 Epoch[32] Batch [280]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102470,	
2017-07-28 23:00:25,920 Epoch[32] Batch [290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102471,	
2017-07-28 23:00:31,561 Epoch[32] Batch [300]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.102492,	
2017-07-28 23:00:37,348 Epoch[32] Batch [310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102395,	
2017-07-28 23:00:43,140 Epoch[32] Batch [320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102349,	
2017-07-28 23:00:48,947 Epoch[32] Batch [330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102005,	
2017-07-28 23:00:54,714 Epoch[32] Batch [340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101818,	
2017-07-28 23:01:00,507 Epoch[32] Batch [350]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101832,	
2017-07-28 23:01:06,301 Epoch[32] Batch [360]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101708,	
2017-07-28 23:01:12,074 Epoch[32] Batch [370]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101778,	
2017-07-28 23:01:17,871 Epoch[32] Batch [380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101645,	
2017-07-28 23:01:23,685 Epoch[32] Batch [390]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101883,	
2017-07-28 23:01:29,451 Epoch[32] Batch [400]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101788,	
2017-07-28 23:01:35,262 Epoch[32] Batch [410]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101594,	
2017-07-28 23:01:41,083 Epoch[32] Batch [420]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101843,	
2017-07-28 23:01:46,831 Epoch[32] Batch [430]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101771,	
2017-07-28 23:01:52,561 Epoch[32] Batch [440]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.101809,	
2017-07-28 23:01:58,332 Epoch[32] Batch [450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101677,	
2017-07-28 23:02:04,129 Epoch[32] Batch [460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101462,	
2017-07-28 23:02:09,917 Epoch[32] Batch [470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101318,	
2017-07-28 23:02:15,652 Epoch[32] Batch [480]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.101357,	
2017-07-28 23:02:21,407 Epoch[32] Batch [490]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101226,	
2017-07-28 23:02:27,203 Epoch[32] Batch [500]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100987,	
2017-07-28 23:02:33,011 Epoch[32] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100900,	
2017-07-28 23:02:38,784 Epoch[32] Batch [520]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100953,	
2017-07-28 23:02:44,572 Epoch[32] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100820,	
2017-07-28 23:02:50,369 Epoch[32] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100641,	
2017-07-28 23:02:55,402 Epoch[32] Batch [550]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.100429,	
2017-07-28 23:03:00,309 Epoch[32] Batch [560]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.100539,	
2017-07-28 23:03:06,023 Epoch[32] Batch [570]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.100458,	
2017-07-28 23:03:11,683 Epoch[32] Batch [580]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.100350,	
2017-07-28 23:03:17,491 Epoch[32] Batch [590]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100403,	
2017-07-28 23:03:23,296 Epoch[32] Batch [600]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101011,	
2017-07-28 23:03:29,017 Epoch[32] Batch [610]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.101458,	
2017-07-28 23:03:34,784 Epoch[32] Batch [620]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101848,	
2017-07-28 23:03:40,506 Epoch[32] Batch [630]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.102983,	
2017-07-28 23:03:46,272 Epoch[32] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103493,	
2017-07-28 23:03:52,066 Epoch[32] Batch [650]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.104382,	
2017-07-28 23:03:57,645 Epoch[32] Batch [660]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.104926,	
2017-07-28 23:04:03,405 Epoch[32] Batch [670]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.104920,	
2017-07-28 23:04:09,172 Epoch[32] Batch [680]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.105012,	
2017-07-28 23:04:14,993 Epoch[32] Batch [690]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105817,	
2017-07-28 23:04:20,722 Epoch[32] Batch [700]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.106107,	
2017-07-28 23:04:26,264 Epoch[32] Batch [710]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.106310,	
2017-07-28 23:04:32,069 Epoch[32] Batch [720]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106388,	
2017-07-28 23:04:37,836 Epoch[32] Batch [730]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106531,	
2017-07-28 23:04:43,690 Epoch[32] Batch [740]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106457,	
2017-07-28 23:04:49,477 Epoch[32] Batch [750]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106429,	
2017-07-28 23:04:55,244 Epoch[32] Batch [760]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106380,	
2017-07-28 23:05:01,013 Epoch[32] Batch [770]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106479,	
2017-07-28 23:05:06,835 Epoch[32] Batch [780]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.106249,	
2017-07-28 23:05:12,641 Epoch[32] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106223,	
2017-07-28 23:05:18,419 Epoch[32] Batch [800]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.106028,	
2017-07-28 23:05:24,224 Epoch[32] Batch [810]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106036,	
2017-07-28 23:05:29,985 Epoch[32] Batch [820]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.105976,	
2017-07-28 23:05:35,540 Epoch[32] Batch [830]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.106044,	
2017-07-28 23:05:41,062 Epoch[32] Batch [840]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.105979,	
2017-07-28 23:05:46,430 Epoch[32] Batch [850]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.105994,	
2017-07-28 23:05:51,779 Epoch[32] Batch [860]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.105976,	
2017-07-28 23:05:57,105 Epoch[32] Batch [870]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.105933,	
2017-07-28 23:06:02,489 Epoch[32] Batch [880]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.105853,	
2017-07-28 23:06:08,201 Epoch[32] Batch [890]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.105787,	
2017-07-28 23:06:13,753 Epoch[32] Batch [900]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.105767,	
2017-07-28 23:06:19,323 Epoch[32] Batch [910]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.105802,	
2017-07-28 23:06:25,070 Epoch[32] Batch [920]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105817,	
2017-07-28 23:06:30,715 Epoch[32] Batch [930]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.105752,	
2017-07-28 23:06:36,462 Epoch[32] Batch [940]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105821,	
2017-07-28 23:06:42,133 Epoch[32] Batch [950]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.105896,	
2017-07-28 23:06:48,005 Epoch[32] Batch [960]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.105901,	
2017-07-28 23:06:53,582 Epoch[32] Batch [970]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.105921,	
2017-07-28 23:06:59,392 Epoch[32] Batch [980]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105861,	
2017-07-28 23:07:05,175 Epoch[32] Batch [990]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105924,	
2017-07-28 23:07:10,938 Epoch[32] Batch [1000]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.106057,	
2017-07-28 23:07:16,660 Epoch[32] Batch [1010]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.106024,	
2017-07-28 23:07:22,409 Epoch[32] Batch [1020]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.106023,	
2017-07-28 23:07:28,076 Epoch[32] Batch [1030]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.105939,	
2017-07-28 23:07:33,887 Epoch[32] Batch [1040]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105931,	
2017-07-28 23:07:39,668 Epoch[32] Batch [1050]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105904,	
2017-07-28 23:07:45,470 Epoch[32] Batch [1060]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105845,	
2017-07-28 23:07:51,145 Epoch[32] Batch [1070]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.105827,	
2017-07-28 23:07:56,174 Epoch[32] Batch [1080]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.105811,	
2017-07-28 23:08:01,511 Epoch[32] Batch [1090]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105841,	
2017-07-28 23:08:06,980 Epoch[32] Batch [1100]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.105805,	
2017-07-28 23:08:12,585 Epoch[32] Batch [1110]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.105814,	
2017-07-28 23:08:18,354 Epoch[32] Batch [1120]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105717,	
2017-07-28 23:08:24,163 Epoch[32] Batch [1130]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105774,	
2017-07-28 23:08:29,940 Epoch[32] Batch [1140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105661,	
2017-07-28 23:08:35,730 Epoch[32] Batch [1150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105620,	
2017-07-28 23:08:41,515 Epoch[32] Batch [1160]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105531,	
2017-07-28 23:08:47,302 Epoch[32] Batch [1170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105493,	
2017-07-28 23:08:53,099 Epoch[32] Batch [1180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105420,	
2017-07-28 23:08:58,898 Epoch[32] Batch [1190]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105392,	
2017-07-28 23:09:04,684 Epoch[32] Batch [1200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105373,	
2017-07-28 23:09:10,424 Epoch[32] Batch [1210]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.105278,	
2017-07-28 23:09:16,059 Epoch[32] Batch [1220]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.105199,	
2017-07-28 23:09:21,842 Epoch[32] Batch [1230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105200,	
2017-07-28 23:09:27,610 Epoch[32] Batch [1240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.105221,	
2017-07-28 23:09:33,289 Epoch[32] Batch [1250]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.105126,	
2017-07-28 23:09:38,389 Epoch[32] Batch [1260]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.105159,	
2017-07-28 23:09:43,637 Epoch[32] Batch [1270]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.105255,	
2017-07-28 23:09:49,086 Epoch[32] Batch [1280]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.105404,	
2017-07-28 23:09:54,564 Epoch[32] Batch [1290]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.105450,	
2017-07-28 23:10:00,243 Epoch[32] Batch [1300]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.105383,	
2017-07-28 23:10:05,772 Epoch[32] Batch [1310]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.105347,	
2017-07-28 23:10:11,118 Epoch[32] Batch [1320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.105409,	
2017-07-28 23:10:16,203 Epoch[32] Batch [1330]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.105415,	
2017-07-28 23:10:21,359 Epoch[32] Batch [1340]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.105439,	
2017-07-28 23:10:26,615 Epoch[32] Batch [1350]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.105431,	
2017-07-28 23:10:31,936 Epoch[32] Batch [1360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105348,	
2017-07-28 23:10:37,506 Epoch[32] Batch [1370]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.105295,	
2017-07-28 23:10:42,541 Epoch[32] Batch [1380]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.105231,	
2017-07-28 23:10:47,720 Epoch[32] Batch [1390]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105123,	
2017-07-28 23:10:52,842 Epoch[32] Batch [1400]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.105077,	
2017-07-28 23:10:58,633 Epoch[32] Batch [1410]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105014,	
2017-07-28 23:11:04,411 Epoch[32] Batch [1420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104957,	
2017-07-28 23:11:10,056 Epoch[32] Batch [1430]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.104858,	
2017-07-28 23:11:15,467 Epoch[32] Batch [1440]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.104823,	
2017-07-28 23:11:21,005 Epoch[32] Batch [1450]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.104782,	
2017-07-28 23:11:26,808 Epoch[32] Batch [1460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104741,	
2017-07-28 23:11:32,487 Epoch[32] Batch [1470]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.104649,	
2017-07-28 23:11:38,013 Epoch[32] Batch [1480]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.104636,	
2017-07-28 23:11:41,477 Epoch[32] Train-FCNLogLoss=0.104560
2017-07-28 23:11:41,477 Epoch[32] Time cost=844.497
2017-07-28 23:11:42,322 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0033.params"
2017-07-28 23:11:43,958 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0033.states"
2017-07-28 23:11:50,453 Epoch[33] Batch [10]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.090238,	
2017-07-28 23:11:55,624 Epoch[33] Batch [20]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.091031,	
2017-07-28 23:12:00,992 Epoch[33] Batch [30]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091516,	
2017-07-28 23:12:06,346 Epoch[33] Batch [40]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095430,	
2017-07-28 23:12:11,347 Epoch[33] Batch [50]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098676,	
2017-07-28 23:12:16,627 Epoch[33] Batch [60]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.100519,	
2017-07-28 23:12:21,710 Epoch[33] Batch [70]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.098650,	
2017-07-28 23:12:27,459 Epoch[33] Batch [80]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098086,	
2017-07-28 23:12:33,184 Epoch[33] Batch [90]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.099503,	
2017-07-28 23:12:38,902 Epoch[33] Batch [100]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.100706,	
2017-07-28 23:12:44,572 Epoch[33] Batch [110]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.105035,	
2017-07-28 23:12:50,100 Epoch[33] Batch [120]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.108467,	
2017-07-28 23:12:55,593 Epoch[33] Batch [130]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.112847,	
2017-07-28 23:13:01,162 Epoch[33] Batch [140]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.115062,	
2017-07-28 23:13:06,923 Epoch[33] Batch [150]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.115335,	
2017-07-28 23:13:11,956 Epoch[33] Batch [160]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.115022,	
2017-07-28 23:13:16,932 Epoch[33] Batch [170]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.115198,	
2017-07-28 23:13:22,217 Epoch[33] Batch [180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.114205,	
2017-07-28 23:13:27,388 Epoch[33] Batch [190]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.113370,	
2017-07-28 23:13:32,315 Epoch[33] Batch [200]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.113420,	
2017-07-28 23:13:37,127 Epoch[33] Batch [210]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.113007,	
2017-07-28 23:13:42,133 Epoch[33] Batch [220]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.112582,	
2017-07-28 23:13:47,424 Epoch[33] Batch [230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.111781,	
2017-07-28 23:13:52,412 Epoch[33] Batch [240]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.111487,	
2017-07-28 23:13:57,451 Epoch[33] Batch [250]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.110504,	
2017-07-28 23:14:02,496 Epoch[33] Batch [260]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.110396,	
2017-07-28 23:14:07,672 Epoch[33] Batch [270]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.110205,	
2017-07-28 23:14:12,826 Epoch[33] Batch [280]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.109749,	
2017-07-28 23:14:17,838 Epoch[33] Batch [290]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.109185,	
2017-07-28 23:14:22,608 Epoch[33] Batch [300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.109159,	
2017-07-28 23:14:27,617 Epoch[33] Batch [310]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.108726,	
2017-07-28 23:14:32,605 Epoch[33] Batch [320]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.108560,	
2017-07-28 23:14:37,666 Epoch[33] Batch [330]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.108461,	
2017-07-28 23:14:43,075 Epoch[33] Batch [340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.108026,	
2017-07-28 23:14:48,722 Epoch[33] Batch [350]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.108097,	
2017-07-28 23:14:54,459 Epoch[33] Batch [360]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.107664,	
2017-07-28 23:15:00,226 Epoch[33] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.107548,	
2017-07-28 23:15:05,590 Epoch[33] Batch [380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.107295,	
2017-07-28 23:15:10,782 Epoch[33] Batch [390]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.107186,	
2017-07-28 23:15:16,079 Epoch[33] Batch [400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.107453,	
2017-07-28 23:15:21,397 Epoch[33] Batch [410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.107471,	
2017-07-28 23:15:26,896 Epoch[33] Batch [420]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.107561,	
2017-07-28 23:15:32,654 Epoch[33] Batch [430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.107496,	
2017-07-28 23:15:38,458 Epoch[33] Batch [440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.107468,	
2017-07-28 23:15:44,234 Epoch[33] Batch [450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107310,	
2017-07-28 23:15:50,014 Epoch[33] Batch [460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107046,	
2017-07-28 23:15:55,817 Epoch[33] Batch [470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106843,	
2017-07-28 23:16:01,611 Epoch[33] Batch [480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106685,	
2017-07-28 23:16:07,403 Epoch[33] Batch [490]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106643,	
2017-07-28 23:16:13,194 Epoch[33] Batch [500]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106470,	
2017-07-28 23:16:19,002 Epoch[33] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106261,	
2017-07-28 23:16:24,804 Epoch[33] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106174,	
2017-07-28 23:16:30,559 Epoch[33] Batch [530]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106740,	
2017-07-28 23:16:36,355 Epoch[33] Batch [540]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.106723,	
2017-07-28 23:16:42,143 Epoch[33] Batch [550]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106792,	
2017-07-28 23:16:47,931 Epoch[33] Batch [560]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106675,	
2017-07-28 23:16:53,773 Epoch[33] Batch [570]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106534,	
2017-07-28 23:16:59,620 Epoch[33] Batch [580]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106304,	
2017-07-28 23:17:05,397 Epoch[33] Batch [590]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.106090,	
2017-07-28 23:17:11,155 Epoch[33] Batch [600]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.106027,	
2017-07-28 23:17:17,056 Epoch[33] Batch [610]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106076,	
2017-07-28 23:17:22,691 Epoch[33] Batch [620]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.105944,	
2017-07-28 23:17:28,538 Epoch[33] Batch [630]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105836,	
2017-07-28 23:17:34,348 Epoch[33] Batch [640]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105630,	
2017-07-28 23:17:40,139 Epoch[33] Batch [650]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105609,	
2017-07-28 23:17:45,937 Epoch[33] Batch [660]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105366,	
2017-07-28 23:17:51,741 Epoch[33] Batch [670]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105205,	
2017-07-28 23:17:57,500 Epoch[33] Batch [680]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.105188,	
2017-07-28 23:18:03,248 Epoch[33] Batch [690]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105129,	
2017-07-28 23:18:07,823 Epoch[33] Batch [700]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.105064,	
2017-07-28 23:18:12,616 Epoch[33] Batch [710]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.105107,	
2017-07-28 23:18:18,418 Epoch[33] Batch [720]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105087,	
2017-07-28 23:18:24,221 Epoch[33] Batch [730]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105000,	
2017-07-28 23:18:30,028 Epoch[33] Batch [740]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.104730,	
2017-07-28 23:18:35,820 Epoch[33] Batch [750]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104573,	
2017-07-28 23:18:41,622 Epoch[33] Batch [760]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.104359,	
2017-07-28 23:18:47,469 Epoch[33] Batch [770]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.104305,	
2017-07-28 23:18:53,256 Epoch[33] Batch [780]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104199,	
2017-07-28 23:18:58,840 Epoch[33] Batch [790]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.104045,	
2017-07-28 23:19:04,606 Epoch[33] Batch [800]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103912,	
2017-07-28 23:19:10,442 Epoch[33] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103922,	
2017-07-28 23:19:16,270 Epoch[33] Batch [820]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103895,	
2017-07-28 23:19:21,352 Epoch[33] Batch [830]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.103793,	
2017-07-28 23:19:26,262 Epoch[33] Batch [840]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.103742,	
2017-07-28 23:19:31,193 Epoch[33] Batch [850]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.103760,	
2017-07-28 23:19:35,910 Epoch[33] Batch [860]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.103636,	
2017-07-28 23:19:41,001 Epoch[33] Batch [870]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.103476,	
2017-07-28 23:19:46,288 Epoch[33] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.103407,	
2017-07-28 23:19:51,855 Epoch[33] Batch [890]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.103271,	
2017-07-28 23:19:57,053 Epoch[33] Batch [900]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.103173,	
2017-07-28 23:20:02,385 Epoch[33] Batch [910]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.103187,	
2017-07-28 23:20:07,942 Epoch[33] Batch [920]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.103171,	
2017-07-28 23:20:13,241 Epoch[33] Batch [930]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.103170,	
2017-07-28 23:20:18,961 Epoch[33] Batch [940]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.103168,	
2017-07-28 23:20:24,845 Epoch[33] Batch [950]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.103121,	
2017-07-28 23:20:30,248 Epoch[33] Batch [960]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.103027,	
2017-07-28 23:20:35,642 Epoch[33] Batch [970]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.103052,	
2017-07-28 23:20:41,350 Epoch[33] Batch [980]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.103002,	
2017-07-28 23:20:46,846 Epoch[33] Batch [990]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.102925,	
2017-07-28 23:20:52,171 Epoch[33] Batch [1000]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.102797,	
2017-07-28 23:20:57,558 Epoch[33] Batch [1010]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.102835,	
2017-07-28 23:21:02,973 Epoch[33] Batch [1020]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.102931,	
2017-07-28 23:21:08,244 Epoch[33] Batch [1030]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.102895,	
2017-07-28 23:21:13,513 Epoch[33] Batch [1040]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.102858,	
2017-07-28 23:21:18,595 Epoch[33] Batch [1050]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.102989,	
2017-07-28 23:21:23,611 Epoch[33] Batch [1060]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.102948,	
2017-07-28 23:21:29,042 Epoch[33] Batch [1070]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.102914,	
2017-07-28 23:21:34,682 Epoch[33] Batch [1080]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.102896,	
2017-07-28 23:21:40,189 Epoch[33] Batch [1090]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.102835,	
2017-07-28 23:21:45,330 Epoch[33] Batch [1100]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.102789,	
2017-07-28 23:21:50,781 Epoch[33] Batch [1110]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.103138,	
2017-07-28 23:21:56,236 Epoch[33] Batch [1120]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.103500,	
2017-07-28 23:22:01,545 Epoch[33] Batch [1130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.103664,	
2017-07-28 23:22:07,053 Epoch[33] Batch [1140]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.103826,	
2017-07-28 23:22:12,251 Epoch[33] Batch [1150]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.104082,	
2017-07-28 23:22:17,566 Epoch[33] Batch [1160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.104228,	
2017-07-28 23:22:22,660 Epoch[33] Batch [1170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.104239,	
2017-07-28 23:22:27,699 Epoch[33] Batch [1180]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.104357,	
2017-07-28 23:22:32,942 Epoch[33] Batch [1190]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.104285,	
2017-07-28 23:22:38,472 Epoch[33] Batch [1200]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.104222,	
2017-07-28 23:22:43,777 Epoch[33] Batch [1210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.104231,	
2017-07-28 23:22:49,051 Epoch[33] Batch [1220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.104273,	
2017-07-28 23:22:54,068 Epoch[33] Batch [1230]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.104208,	
2017-07-28 23:22:59,110 Epoch[33] Batch [1240]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.104127,	
2017-07-28 23:23:04,091 Epoch[33] Batch [1250]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.104152,	
2017-07-28 23:23:09,130 Epoch[33] Batch [1260]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.104137,	
2017-07-28 23:23:14,214 Epoch[33] Batch [1270]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.104186,	
2017-07-28 23:23:19,286 Epoch[33] Batch [1280]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.104283,	
2017-07-28 23:23:24,455 Epoch[33] Batch [1290]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.104166,	
2017-07-28 23:23:29,675 Epoch[33] Batch [1300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.104156,	
2017-07-28 23:23:35,200 Epoch[33] Batch [1310]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.104400,	
2017-07-28 23:23:41,225 Epoch[33] Batch [1320]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.104658,	
2017-07-28 23:23:47,871 Epoch[33] Batch [1330]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.104827,	
2017-07-28 23:23:55,764 Epoch[33] Batch [1340]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.104932,	
2017-07-28 23:24:03,301 Epoch[33] Batch [1350]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.104907,	
2017-07-28 23:24:10,836 Epoch[33] Batch [1360]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.104843,	
2017-07-28 23:24:18,305 Epoch[33] Batch [1370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.104829,	
2017-07-28 23:24:26,004 Epoch[33] Batch [1380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.104765,	
2017-07-28 23:24:33,855 Epoch[33] Batch [1390]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.104784,	
2017-07-28 23:24:41,685 Epoch[33] Batch [1400]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.104766,	
2017-07-28 23:24:49,120 Epoch[33] Batch [1410]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.104807,	
2017-07-28 23:24:56,653 Epoch[33] Batch [1420]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.104850,	
2017-07-28 23:25:04,305 Epoch[33] Batch [1430]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.104874,	
2017-07-28 23:25:11,851 Epoch[33] Batch [1440]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.104798,	
2017-07-28 23:25:19,390 Epoch[33] Batch [1450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.104745,	
2017-07-28 23:25:27,184 Epoch[33] Batch [1460]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.104723,	
2017-07-28 23:25:34,688 Epoch[33] Batch [1470]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.104658,	
2017-07-28 23:25:42,028 Epoch[33] Batch [1480]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.104659,	
2017-07-28 23:25:46,480 Epoch[33] Train-FCNLogLoss=0.104667
2017-07-28 23:25:46,480 Epoch[33] Time cost=842.522
2017-07-28 23:25:47,496 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0034.params"
2017-07-28 23:25:51,268 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0034.states"
2017-07-28 23:25:59,914 Epoch[34] Batch [10]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.102083,	
2017-07-28 23:26:07,379 Epoch[34] Batch [20]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.108278,	
2017-07-28 23:26:14,982 Epoch[34] Batch [30]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.105818,	
2017-07-28 23:26:22,853 Epoch[34] Batch [40]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.104817,	
2017-07-28 23:26:30,764 Epoch[34] Batch [50]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.103187,	
2017-07-28 23:26:40,254 Epoch[34] Batch [60]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.100376,	
2017-07-28 23:26:48,514 Epoch[34] Batch [70]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.099348,	
2017-07-28 23:26:56,457 Epoch[34] Batch [80]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.098027,	
2017-07-28 23:27:05,722 Epoch[34] Batch [90]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.097520,	
2017-07-28 23:27:15,236 Epoch[34] Batch [100]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.097936,	
2017-07-28 23:27:25,105 Epoch[34] Batch [110]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.097832,	
2017-07-28 23:27:35,336 Epoch[34] Batch [120]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.098405,	
2017-07-28 23:27:45,413 Epoch[34] Batch [130]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.098965,	
2017-07-28 23:27:55,400 Epoch[34] Batch [140]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.098744,	
2017-07-28 23:28:05,787 Epoch[34] Batch [150]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.098587,	
2017-07-28 23:28:15,932 Epoch[34] Batch [160]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.098118,	
2017-07-28 23:28:26,348 Epoch[34] Batch [170]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.098033,	
2017-07-28 23:28:36,570 Epoch[34] Batch [180]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.097696,	
2017-07-28 23:28:47,173 Epoch[34] Batch [190]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.097462,	
2017-07-28 23:28:57,459 Epoch[34] Batch [200]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.097219,	
2017-07-28 23:29:08,037 Epoch[34] Batch [210]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.097018,	
2017-07-28 23:29:18,457 Epoch[34] Batch [220]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.097070,	
2017-07-28 23:29:28,996 Epoch[34] Batch [230]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.097094,	
2017-07-28 23:29:39,435 Epoch[34] Batch [240]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.097137,	
2017-07-28 23:29:49,526 Epoch[34] Batch [250]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.097184,	
2017-07-28 23:29:59,749 Epoch[34] Batch [260]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.097147,	
2017-07-28 23:30:09,459 Epoch[34] Batch [270]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.097455,	
2017-07-28 23:30:18,559 Epoch[34] Batch [280]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.097313,	
2017-07-28 23:30:28,320 Epoch[34] Batch [290]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.097303,	
2017-07-28 23:30:38,401 Epoch[34] Batch [300]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.097433,	
2017-07-28 23:30:48,616 Epoch[34] Batch [310]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.097811,	
2017-07-28 23:30:58,664 Epoch[34] Batch [320]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.097916,	
2017-07-28 23:31:08,693 Epoch[34] Batch [330]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.097932,	
2017-07-28 23:31:18,424 Epoch[34] Batch [340]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.097912,	
2017-07-28 23:31:28,695 Epoch[34] Batch [350]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.097815,	
2017-07-28 23:31:38,502 Epoch[34] Batch [360]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.097727,	
2017-07-28 23:31:48,714 Epoch[34] Batch [370]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.097948,	
2017-07-28 23:31:58,934 Epoch[34] Batch [380]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.098000,	
2017-07-28 23:32:08,996 Epoch[34] Batch [390]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.098123,	
2017-07-28 23:32:18,212 Epoch[34] Batch [400]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.098234,	
2017-07-28 23:32:26,983 Epoch[34] Batch [410]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.098221,	
2017-07-28 23:32:35,893 Epoch[34] Batch [420]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.098228,	
2017-07-28 23:32:44,709 Epoch[34] Batch [430]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.098233,	
2017-07-28 23:32:53,706 Epoch[34] Batch [440]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.098510,	
2017-07-28 23:33:02,791 Epoch[34] Batch [450]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.098711,	
2017-07-28 23:33:12,127 Epoch[34] Batch [460]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.098429,	
2017-07-28 23:33:22,038 Epoch[34] Batch [470]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.098317,	
2017-07-28 23:33:31,203 Epoch[34] Batch [480]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.098322,	
2017-07-28 23:33:40,764 Epoch[34] Batch [490]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.098516,	
2017-07-28 23:33:49,796 Epoch[34] Batch [500]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.098727,	
2017-07-28 23:33:59,566 Epoch[34] Batch [510]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.098714,	
2017-07-28 23:34:08,892 Epoch[34] Batch [520]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.098761,	
2017-07-28 23:34:18,353 Epoch[34] Batch [530]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.098702,	
2017-07-28 23:34:27,418 Epoch[34] Batch [540]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.098617,	
2017-07-28 23:34:36,564 Epoch[34] Batch [550]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.098416,	
2017-07-28 23:34:45,618 Epoch[34] Batch [560]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.098576,	
2017-07-28 23:34:54,593 Epoch[34] Batch [570]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.098439,	
2017-07-28 23:35:03,236 Epoch[34] Batch [580]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.098376,	
2017-07-28 23:35:12,194 Epoch[34] Batch [590]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.098293,	
2017-07-28 23:35:21,333 Epoch[34] Batch [600]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.098228,	
2017-07-28 23:35:30,443 Epoch[34] Batch [610]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.098192,	
2017-07-28 23:35:39,702 Epoch[34] Batch [620]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.098189,	
2017-07-28 23:35:48,809 Epoch[34] Batch [630]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.098250,	
2017-07-28 23:35:57,222 Epoch[34] Batch [640]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.098229,	
2017-07-28 23:36:06,185 Epoch[34] Batch [650]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.098232,	
2017-07-28 23:36:15,357 Epoch[34] Batch [660]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.098260,	
2017-07-28 23:36:23,889 Epoch[34] Batch [670]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.098425,	
2017-07-28 23:36:32,853 Epoch[34] Batch [680]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.098515,	
2017-07-28 23:36:41,972 Epoch[34] Batch [690]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.098600,	
2017-07-28 23:36:50,899 Epoch[34] Batch [700]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.098421,	
2017-07-28 23:36:59,946 Epoch[34] Batch [710]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.098341,	
2017-07-28 23:37:09,182 Epoch[34] Batch [720]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.098216,	
2017-07-28 23:37:18,684 Epoch[34] Batch [730]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.098341,	
2017-07-28 23:37:27,996 Epoch[34] Batch [740]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.098342,	
2017-07-28 23:37:37,183 Epoch[34] Batch [750]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.098435,	
2017-07-28 23:37:46,523 Epoch[34] Batch [760]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.098368,	
2017-07-28 23:37:55,799 Epoch[34] Batch [770]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.098232,	
2017-07-28 23:38:05,147 Epoch[34] Batch [780]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.098107,	
2017-07-28 23:38:14,148 Epoch[34] Batch [790]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.098149,	
2017-07-28 23:38:23,317 Epoch[34] Batch [800]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.098085,	
2017-07-28 23:38:32,193 Epoch[34] Batch [810]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.098023,	
2017-07-28 23:38:41,123 Epoch[34] Batch [820]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.097972,	
2017-07-28 23:38:49,758 Epoch[34] Batch [830]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.097916,	
2017-07-28 23:38:58,702 Epoch[34] Batch [840]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.097775,	
2017-07-28 23:39:07,650 Epoch[34] Batch [850]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.097753,	
2017-07-28 23:39:16,558 Epoch[34] Batch [860]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.097993,	
2017-07-28 23:39:25,585 Epoch[34] Batch [870]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.098032,	
2017-07-28 23:39:34,173 Epoch[34] Batch [880]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.097922,	
2017-07-28 23:39:42,565 Epoch[34] Batch [890]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.097807,	
2017-07-28 23:39:51,385 Epoch[34] Batch [900]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.097979,	
2017-07-28 23:40:00,188 Epoch[34] Batch [910]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.097953,	
2017-07-28 23:40:09,014 Epoch[34] Batch [920]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.098021,	
2017-07-28 23:40:17,665 Epoch[34] Batch [930]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.098185,	
2017-07-28 23:40:26,997 Epoch[34] Batch [940]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.098268,	
2017-07-28 23:40:35,710 Epoch[34] Batch [950]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.098261,	
2017-07-28 23:40:44,764 Epoch[34] Batch [960]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.098211,	
2017-07-28 23:40:53,555 Epoch[34] Batch [970]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.098225,	
2017-07-28 23:41:02,641 Epoch[34] Batch [980]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.098174,	
2017-07-28 23:41:11,702 Epoch[34] Batch [990]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.098184,	
2017-07-28 23:41:20,516 Epoch[34] Batch [1000]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.098145,	
2017-07-28 23:41:29,589 Epoch[34] Batch [1010]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.098141,	
2017-07-28 23:41:38,499 Epoch[34] Batch [1020]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.098092,	
2017-07-28 23:41:47,711 Epoch[34] Batch [1030]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.098060,	
2017-07-28 23:41:56,950 Epoch[34] Batch [1040]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.098068,	
2017-07-28 23:42:06,069 Epoch[34] Batch [1050]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.098016,	
2017-07-28 23:42:15,251 Epoch[34] Batch [1060]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.097967,	
2017-07-28 23:42:24,129 Epoch[34] Batch [1070]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.097857,	
2017-07-28 23:42:33,423 Epoch[34] Batch [1080]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.097869,	
2017-07-28 23:42:42,551 Epoch[34] Batch [1090]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.097829,	
2017-07-28 23:42:51,591 Epoch[34] Batch [1100]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.097804,	
2017-07-28 23:43:00,465 Epoch[34] Batch [1110]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.097822,	
2017-07-28 23:43:09,638 Epoch[34] Batch [1120]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.097756,	
2017-07-28 23:43:18,708 Epoch[34] Batch [1130]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.097803,	
2017-07-28 23:43:27,927 Epoch[34] Batch [1140]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.097795,	
2017-07-28 23:43:36,884 Epoch[34] Batch [1150]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.097712,	
2017-07-28 23:43:45,825 Epoch[34] Batch [1160]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.097654,	
2017-07-28 23:43:54,917 Epoch[34] Batch [1170]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.097694,	
2017-07-28 23:44:03,986 Epoch[34] Batch [1180]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.097650,	
2017-07-28 23:44:12,812 Epoch[34] Batch [1190]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.097686,	
2017-07-28 23:44:22,082 Epoch[34] Batch [1200]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.097669,	
2017-07-28 23:44:31,008 Epoch[34] Batch [1210]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.097695,	
2017-07-28 23:44:40,064 Epoch[34] Batch [1220]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.097722,	
2017-07-28 23:44:48,904 Epoch[34] Batch [1230]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.097678,	
2017-07-28 23:44:57,979 Epoch[34] Batch [1240]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.097766,	
2017-07-28 23:45:06,963 Epoch[34] Batch [1250]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.097714,	
2017-07-28 23:45:15,704 Epoch[34] Batch [1260]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.097751,	
2017-07-28 23:45:24,509 Epoch[34] Batch [1270]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.097738,	
2017-07-28 23:45:33,453 Epoch[34] Batch [1280]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.097691,	
2017-07-28 23:45:42,776 Epoch[34] Batch [1290]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.097667,	
2017-07-28 23:45:51,976 Epoch[34] Batch [1300]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.097664,	
2017-07-28 23:46:01,161 Epoch[34] Batch [1310]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.097708,	
2017-07-28 23:46:10,237 Epoch[34] Batch [1320]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.097688,	
2017-07-28 23:46:19,130 Epoch[34] Batch [1330]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.097798,	
2017-07-28 23:46:28,966 Epoch[34] Batch [1340]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.097841,	
2017-07-28 23:46:38,184 Epoch[34] Batch [1350]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.097861,	
2017-07-28 23:46:47,529 Epoch[34] Batch [1360]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.097843,	
2017-07-28 23:46:56,568 Epoch[34] Batch [1370]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.097893,	
2017-07-28 23:47:05,837 Epoch[34] Batch [1380]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.097834,	
2017-07-28 23:47:14,746 Epoch[34] Batch [1390]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.097860,	
2017-07-28 23:47:23,553 Epoch[34] Batch [1400]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.097905,	
2017-07-28 23:47:32,459 Epoch[34] Batch [1410]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.097943,	
2017-07-28 23:47:41,488 Epoch[34] Batch [1420]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.097946,	
2017-07-28 23:47:50,574 Epoch[34] Batch [1430]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.097873,	
2017-07-28 23:47:59,365 Epoch[34] Batch [1440]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.097799,	
2017-07-28 23:48:08,205 Epoch[34] Batch [1450]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.097793,	
2017-07-28 23:48:17,215 Epoch[34] Batch [1460]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.097682,	
2017-07-28 23:48:26,227 Epoch[34] Batch [1470]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.097656,	
2017-07-28 23:48:35,314 Epoch[34] Batch [1480]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.097620,	
2017-07-28 23:48:40,526 Epoch[34] Train-FCNLogLoss=0.097609
2017-07-28 23:48:40,527 Epoch[34] Time cost=1369.258
2017-07-28 23:48:41,979 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0035.params"
2017-07-28 23:48:46,671 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0035.states"
2017-07-28 23:48:56,938 Epoch[35] Batch [10]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.103786,	
2017-07-28 23:49:05,712 Epoch[35] Batch [20]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.124496,	
2017-07-28 23:49:14,715 Epoch[35] Batch [30]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.120381,	
2017-07-28 23:49:23,795 Epoch[35] Batch [40]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.117864,	
2017-07-28 23:49:32,745 Epoch[35] Batch [50]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.115510,	
2017-07-28 23:49:41,837 Epoch[35] Batch [60]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.115366,	
2017-07-28 23:49:51,037 Epoch[35] Batch [70]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.114696,	
2017-07-28 23:50:00,126 Epoch[35] Batch [80]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.112973,	
2017-07-28 23:50:09,184 Epoch[35] Batch [90]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.111494,	
2017-07-28 23:50:18,327 Epoch[35] Batch [100]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.109702,	
2017-07-28 23:50:27,398 Epoch[35] Batch [110]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.108585,	
2017-07-28 23:50:36,522 Epoch[35] Batch [120]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.107529,	
2017-07-28 23:50:45,385 Epoch[35] Batch [130]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.106816,	
2017-07-28 23:50:54,460 Epoch[35] Batch [140]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.105707,	
2017-07-28 23:51:03,750 Epoch[35] Batch [150]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.104663,	
2017-07-28 23:51:12,587 Epoch[35] Batch [160]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.103840,	
2017-07-28 23:51:21,525 Epoch[35] Batch [170]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.103773,	
2017-07-28 23:51:30,012 Epoch[35] Batch [180]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.103007,	
2017-07-28 23:51:38,987 Epoch[35] Batch [190]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.102316,	
2017-07-28 23:51:48,067 Epoch[35] Batch [200]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.101816,	
2017-07-28 23:51:57,073 Epoch[35] Batch [210]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.101482,	
2017-07-28 23:52:06,086 Epoch[35] Batch [220]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.101563,	
2017-07-28 23:52:14,951 Epoch[35] Batch [230]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.101307,	
2017-07-28 23:52:23,945 Epoch[35] Batch [240]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.100991,	
2017-07-28 23:52:32,843 Epoch[35] Batch [250]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.101099,	
2017-07-28 23:52:41,572 Epoch[35] Batch [260]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.100849,	
2017-07-28 23:52:50,400 Epoch[35] Batch [270]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.100359,	
2017-07-28 23:52:59,255 Epoch[35] Batch [280]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.100364,	
2017-07-28 23:53:08,079 Epoch[35] Batch [290]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.100231,	
2017-07-28 23:53:16,879 Epoch[35] Batch [300]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.100009,	
2017-07-28 23:53:25,805 Epoch[35] Batch [310]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.099857,	
2017-07-28 23:53:34,486 Epoch[35] Batch [320]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.099766,	
2017-07-28 23:53:43,159 Epoch[35] Batch [330]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.100329,	
2017-07-28 23:53:52,077 Epoch[35] Batch [340]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.100250,	
2017-07-28 23:54:00,986 Epoch[35] Batch [350]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.100296,	
2017-07-28 23:54:09,806 Epoch[35] Batch [360]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.100748,	
2017-07-28 23:54:19,060 Epoch[35] Batch [370]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.100724,	
2017-07-28 23:54:28,134 Epoch[35] Batch [380]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.101272,	
2017-07-28 23:54:37,164 Epoch[35] Batch [390]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.100943,	
2017-07-28 23:54:46,317 Epoch[35] Batch [400]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.100909,	
2017-07-28 23:54:55,327 Epoch[35] Batch [410]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.100853,	
2017-07-28 23:55:04,261 Epoch[35] Batch [420]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.101142,	
2017-07-28 23:55:13,351 Epoch[35] Batch [430]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.101014,	
2017-07-28 23:55:22,277 Epoch[35] Batch [440]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.100926,	
2017-07-28 23:55:31,301 Epoch[35] Batch [450]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.100908,	
2017-07-28 23:55:40,345 Epoch[35] Batch [460]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.100731,	
2017-07-28 23:55:48,955 Epoch[35] Batch [470]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.100583,	
2017-07-28 23:55:57,951 Epoch[35] Batch [480]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.100329,	
2017-07-28 23:56:06,817 Epoch[35] Batch [490]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.100213,	
2017-07-28 23:56:15,772 Epoch[35] Batch [500]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.100199,	
2017-07-28 23:56:24,637 Epoch[35] Batch [510]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.100213,	
2017-07-28 23:56:33,602 Epoch[35] Batch [520]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.100226,	
2017-07-28 23:56:42,554 Epoch[35] Batch [530]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.100208,	
2017-07-28 23:56:51,842 Epoch[35] Batch [540]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.100174,	
2017-07-28 23:57:00,864 Epoch[35] Batch [550]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.100138,	
2017-07-28 23:57:09,985 Epoch[35] Batch [560]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.100296,	
2017-07-28 23:57:19,076 Epoch[35] Batch [570]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.100331,	
2017-07-28 23:57:28,004 Epoch[35] Batch [580]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.100223,	
2017-07-28 23:57:36,927 Epoch[35] Batch [590]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.100157,	
2017-07-28 23:57:45,874 Epoch[35] Batch [600]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.100140,	
2017-07-28 23:57:54,235 Epoch[35] Batch [610]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.100107,	
2017-07-28 23:58:02,369 Epoch[35] Batch [620]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.100104,	
2017-07-28 23:58:11,601 Epoch[35] Batch [630]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.100079,	
2017-07-28 23:58:20,033 Epoch[35] Batch [640]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.099878,	
2017-07-28 23:58:29,155 Epoch[35] Batch [650]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.099829,	
2017-07-28 23:58:38,059 Epoch[35] Batch [660]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.099650,	
2017-07-28 23:58:47,025 Epoch[35] Batch [670]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.099537,	
2017-07-28 23:58:56,180 Epoch[35] Batch [680]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.099399,	
2017-07-28 23:59:04,843 Epoch[35] Batch [690]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.099285,	
2017-07-28 23:59:13,775 Epoch[35] Batch [700]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.099447,	
2017-07-28 23:59:22,723 Epoch[35] Batch [710]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.099266,	
2017-07-28 23:59:31,020 Epoch[35] Batch [720]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.099312,	
2017-07-28 23:59:39,800 Epoch[35] Batch [730]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.099348,	
2017-07-28 23:59:48,383 Epoch[35] Batch [740]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.099349,	
2017-07-28 23:59:56,923 Epoch[35] Batch [750]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.099312,	
2017-07-29 00:00:05,354 Epoch[35] Batch [760]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.099186,	
2017-07-29 00:00:13,451 Epoch[35] Batch [770]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.099132,	
2017-07-29 00:00:21,612 Epoch[35] Batch [780]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.099160,	
2017-07-29 00:00:29,779 Epoch[35] Batch [790]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.099055,	
2017-07-29 00:00:37,965 Epoch[35] Batch [800]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.098950,	
2017-07-29 00:00:47,563 Epoch[35] Batch [810]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.098823,	
2017-07-29 00:00:55,431 Epoch[35] Batch [820]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.098734,	
2017-07-29 00:01:03,598 Epoch[35] Batch [830]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.098901,	
2017-07-29 00:01:12,474 Epoch[35] Batch [840]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.099067,	
2017-07-29 00:01:20,710 Epoch[35] Batch [850]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.099114,	
2017-07-29 00:01:29,254 Epoch[35] Batch [860]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.099055,	
2017-07-29 00:01:37,534 Epoch[35] Batch [870]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.099140,	
2017-07-29 00:01:45,195 Epoch[35] Batch [880]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.099103,	
2017-07-29 00:01:53,062 Epoch[35] Batch [890]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.099028,	
2017-07-29 00:02:01,197 Epoch[35] Batch [900]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.099078,	
2017-07-29 00:02:10,203 Epoch[35] Batch [910]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.098998,	
2017-07-29 00:02:18,428 Epoch[35] Batch [920]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.099026,	
2017-07-29 00:02:26,374 Epoch[35] Batch [930]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.099026,	
2017-07-29 00:02:34,282 Epoch[35] Batch [940]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.099256,	
2017-07-29 00:02:43,350 Epoch[35] Batch [950]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.099291,	
2017-07-29 00:02:52,075 Epoch[35] Batch [960]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.099233,	
2017-07-29 00:03:00,374 Epoch[35] Batch [970]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.099193,	
2017-07-29 00:03:08,672 Epoch[35] Batch [980]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.099239,	
2017-07-29 00:03:16,852 Epoch[35] Batch [990]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.099176,	
2017-07-29 00:03:25,002 Epoch[35] Batch [1000]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.099056,	
2017-07-29 00:03:33,019 Epoch[35] Batch [1010]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.099075,	
2017-07-29 00:03:41,657 Epoch[35] Batch [1020]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.099101,	
2017-07-29 00:03:50,143 Epoch[35] Batch [1030]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.099203,	
2017-07-29 00:03:59,147 Epoch[35] Batch [1040]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.099272,	
2017-07-29 00:04:07,852 Epoch[35] Batch [1050]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.099230,	
2017-07-29 00:04:16,198 Epoch[35] Batch [1060]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.099257,	
2017-07-29 00:04:24,608 Epoch[35] Batch [1070]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.099248,	
2017-07-29 00:04:32,713 Epoch[35] Batch [1080]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.099235,	
2017-07-29 00:04:40,444 Epoch[35] Batch [1090]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.099192,	
2017-07-29 00:04:48,230 Epoch[35] Batch [1100]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.099026,	
2017-07-29 00:04:55,981 Epoch[35] Batch [1110]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.098975,	
2017-07-29 00:05:04,117 Epoch[35] Batch [1120]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.098855,	
2017-07-29 00:05:12,390 Epoch[35] Batch [1130]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.098948,	
2017-07-29 00:05:21,436 Epoch[35] Batch [1140]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.098876,	
2017-07-29 00:05:29,736 Epoch[35] Batch [1150]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.099003,	
2017-07-29 00:05:38,232 Epoch[35] Batch [1160]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.098942,	
2017-07-29 00:05:45,722 Epoch[35] Batch [1170]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098957,	
2017-07-29 00:05:54,239 Epoch[35] Batch [1180]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.098885,	
2017-07-29 00:06:02,141 Epoch[35] Batch [1190]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.098877,	
2017-07-29 00:06:09,762 Epoch[35] Batch [1200]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.099015,	
2017-07-29 00:06:18,049 Epoch[35] Batch [1210]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.099027,	
2017-07-29 00:06:25,868 Epoch[35] Batch [1220]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.099020,	
2017-07-29 00:06:34,091 Epoch[35] Batch [1230]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.098949,	
2017-07-29 00:06:42,287 Epoch[35] Batch [1240]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.098979,	
2017-07-29 00:06:50,218 Epoch[35] Batch [1250]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.098980,	
2017-07-29 00:06:58,292 Epoch[35] Batch [1260]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.099023,	
2017-07-29 00:07:07,256 Epoch[35] Batch [1270]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.099057,	
2017-07-29 00:07:16,403 Epoch[35] Batch [1280]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.099004,	
2017-07-29 00:07:25,570 Epoch[35] Batch [1290]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.099067,	
2017-07-29 00:07:34,907 Epoch[35] Batch [1300]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.099137,	
2017-07-29 00:07:44,055 Epoch[35] Batch [1310]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.099105,	
2017-07-29 00:07:53,115 Epoch[35] Batch [1320]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.099091,	
2017-07-29 00:08:02,043 Epoch[35] Batch [1330]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.099056,	
2017-07-29 00:08:11,165 Epoch[35] Batch [1340]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.099005,	
2017-07-29 00:08:19,818 Epoch[35] Batch [1350]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.099057,	
2017-07-29 00:08:28,961 Epoch[35] Batch [1360]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.098952,	
2017-07-29 00:08:37,672 Epoch[35] Batch [1370]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.098899,	
2017-07-29 00:08:46,251 Epoch[35] Batch [1380]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.098893,	
2017-07-29 00:08:54,328 Epoch[35] Batch [1390]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.098906,	
2017-07-29 00:09:02,959 Epoch[35] Batch [1400]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.098815,	
2017-07-29 00:09:11,263 Epoch[35] Batch [1410]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.098856,	
2017-07-29 00:09:20,067 Epoch[35] Batch [1420]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.098827,	
2017-07-29 00:09:27,951 Epoch[35] Batch [1430]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.098776,	
2017-07-29 00:09:35,669 Epoch[35] Batch [1440]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098753,	
2017-07-29 00:09:43,339 Epoch[35] Batch [1450]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.098882,	
2017-07-29 00:09:51,135 Epoch[35] Batch [1460]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.098845,	
2017-07-29 00:09:58,622 Epoch[35] Batch [1470]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098749,	
2017-07-29 00:10:06,915 Epoch[35] Batch [1480]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.098660,	
2017-07-29 00:10:12,444 Epoch[35] Train-FCNLogLoss=0.098655
2017-07-29 00:10:12,445 Epoch[35] Time cost=1285.773
2017-07-29 00:10:13,946 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0036.params"
2017-07-29 00:10:18,832 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0036.states"
2017-07-29 00:10:28,176 Epoch[36] Batch [10]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.097557,	
2017-07-29 00:10:36,320 Epoch[36] Batch [20]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.092006,	
2017-07-29 00:10:43,790 Epoch[36] Batch [30]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.089783,	
2017-07-29 00:10:51,560 Epoch[36] Batch [40]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.091204,	
2017-07-29 00:10:59,911 Epoch[36] Batch [50]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.091851,	
2017-07-29 00:11:07,360 Epoch[36] Batch [60]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092370,	
2017-07-29 00:11:15,731 Epoch[36] Batch [70]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.092509,	
2017-07-29 00:11:24,009 Epoch[36] Batch [80]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.094647,	
2017-07-29 00:11:31,883 Epoch[36] Batch [90]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096392,	
2017-07-29 00:11:40,012 Epoch[36] Batch [100]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.096818,	
2017-07-29 00:11:47,862 Epoch[36] Batch [110]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.096108,	
2017-07-29 00:11:55,731 Epoch[36] Batch [120]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096599,	
2017-07-29 00:12:03,778 Epoch[36] Batch [130]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.095966,	
2017-07-29 00:12:11,528 Epoch[36] Batch [140]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.095469,	
2017-07-29 00:12:19,637 Epoch[36] Batch [150]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.096207,	
2017-07-29 00:12:27,941 Epoch[36] Batch [160]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.095571,	
2017-07-29 00:12:36,411 Epoch[36] Batch [170]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.095122,	
2017-07-29 00:12:44,914 Epoch[36] Batch [180]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.094980,	
2017-07-29 00:12:53,000 Epoch[36] Batch [190]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.094509,	
2017-07-29 00:13:01,105 Epoch[36] Batch [200]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.094833,	
2017-07-29 00:13:08,983 Epoch[36] Batch [210]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.094697,	
2017-07-29 00:13:16,880 Epoch[36] Batch [220]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.094525,	
2017-07-29 00:13:24,383 Epoch[36] Batch [230]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.094861,	
2017-07-29 00:13:32,476 Epoch[36] Batch [240]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.094482,	
2017-07-29 00:13:40,859 Epoch[36] Batch [250]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.094440,	
2017-07-29 00:13:48,833 Epoch[36] Batch [260]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.094532,	
2017-07-29 00:13:56,991 Epoch[36] Batch [270]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.094616,	
2017-07-29 00:14:04,983 Epoch[36] Batch [280]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.095080,	
2017-07-29 00:14:12,516 Epoch[36] Batch [290]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095041,	
2017-07-29 00:14:20,987 Epoch[36] Batch [300]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.094644,	
2017-07-29 00:14:29,226 Epoch[36] Batch [310]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.094625,	
2017-07-29 00:14:37,303 Epoch[36] Batch [320]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.094676,	
2017-07-29 00:14:44,910 Epoch[36] Batch [330]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.094844,	
2017-07-29 00:14:53,009 Epoch[36] Batch [340]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.094722,	
2017-07-29 00:15:01,224 Epoch[36] Batch [350]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.094701,	
2017-07-29 00:15:09,301 Epoch[36] Batch [360]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.094880,	
2017-07-29 00:15:17,346 Epoch[36] Batch [370]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.094632,	
2017-07-29 00:15:25,500 Epoch[36] Batch [380]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.094629,	
2017-07-29 00:15:32,992 Epoch[36] Batch [390]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.094646,	
2017-07-29 00:15:40,936 Epoch[36] Batch [400]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.094847,	
2017-07-29 00:15:49,001 Epoch[36] Batch [410]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.094906,	
2017-07-29 00:15:57,463 Epoch[36] Batch [420]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.094775,	
2017-07-29 00:16:06,090 Epoch[36] Batch [430]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.094960,	
2017-07-29 00:16:14,586 Epoch[36] Batch [440]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.094603,	
2017-07-29 00:16:22,845 Epoch[36] Batch [450]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.094654,	
2017-07-29 00:16:31,563 Epoch[36] Batch [460]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.094533,	
2017-07-29 00:16:39,793 Epoch[36] Batch [470]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.094619,	
2017-07-29 00:16:48,391 Epoch[36] Batch [480]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.094707,	
2017-07-29 00:16:57,116 Epoch[36] Batch [490]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.094970,	
2017-07-29 00:17:05,919 Epoch[36] Batch [500]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.095064,	
2017-07-29 00:17:14,517 Epoch[36] Batch [510]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.094932,	
2017-07-29 00:17:23,660 Epoch[36] Batch [520]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.094887,	
2017-07-29 00:17:31,627 Epoch[36] Batch [530]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.094992,	
2017-07-29 00:17:39,680 Epoch[36] Batch [540]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.095256,	
2017-07-29 00:17:48,187 Epoch[36] Batch [550]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.095193,	
2017-07-29 00:17:55,997 Epoch[36] Batch [560]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095291,	
2017-07-29 00:18:04,481 Epoch[36] Batch [570]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.095239,	
2017-07-29 00:18:12,350 Epoch[36] Batch [580]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.095145,	
2017-07-29 00:18:20,220 Epoch[36] Batch [590]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.095152,	
2017-07-29 00:18:27,651 Epoch[36] Batch [600]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095115,	
2017-07-29 00:18:35,631 Epoch[36] Batch [610]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.095061,	
2017-07-29 00:18:43,426 Epoch[36] Batch [620]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095130,	
2017-07-29 00:18:50,874 Epoch[36] Batch [630]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.095082,	
2017-07-29 00:18:58,653 Epoch[36] Batch [640]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.095105,	
2017-07-29 00:19:06,141 Epoch[36] Batch [650]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.095310,	
2017-07-29 00:19:13,694 Epoch[36] Batch [660]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095383,	
2017-07-29 00:19:21,218 Epoch[36] Batch [670]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095217,	
2017-07-29 00:19:28,521 Epoch[36] Batch [680]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.095374,	
2017-07-29 00:19:36,199 Epoch[36] Batch [690]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.095206,	
2017-07-29 00:19:43,636 Epoch[36] Batch [700]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095128,	
2017-07-29 00:19:50,790 Epoch[36] Batch [710]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.095087,	
2017-07-29 00:19:58,664 Epoch[36] Batch [720]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.095161,	
2017-07-29 00:20:06,441 Epoch[36] Batch [730]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.095056,	
2017-07-29 00:20:13,938 Epoch[36] Batch [740]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.095124,	
2017-07-29 00:20:22,150 Epoch[36] Batch [750]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.095169,	
2017-07-29 00:20:30,295 Epoch[36] Batch [760]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095281,	
2017-07-29 00:20:39,045 Epoch[36] Batch [770]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.095227,	
2017-07-29 00:20:47,303 Epoch[36] Batch [780]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.095376,	
2017-07-29 00:20:55,057 Epoch[36] Batch [790]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.095385,	
2017-07-29 00:21:03,257 Epoch[36] Batch [800]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.095422,	
2017-07-29 00:21:11,093 Epoch[36] Batch [810]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.095325,	
2017-07-29 00:21:19,179 Epoch[36] Batch [820]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.095221,	
2017-07-29 00:21:26,662 Epoch[36] Batch [830]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095182,	
2017-07-29 00:21:34,248 Epoch[36] Batch [840]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.095300,	
2017-07-29 00:21:41,723 Epoch[36] Batch [850]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095406,	
2017-07-29 00:21:49,795 Epoch[36] Batch [860]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.095551,	
2017-07-29 00:21:58,037 Epoch[36] Batch [870]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.095503,	
2017-07-29 00:22:06,019 Epoch[36] Batch [880]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.095608,	
2017-07-29 00:22:14,289 Epoch[36] Batch [890]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.095617,	
2017-07-29 00:22:21,747 Epoch[36] Batch [900]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.095500,	
2017-07-29 00:22:29,776 Epoch[36] Batch [910]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.095458,	
2017-07-29 00:22:37,437 Epoch[36] Batch [920]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.095466,	
2017-07-29 00:22:45,113 Epoch[36] Batch [930]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.095488,	
2017-07-29 00:22:52,861 Epoch[36] Batch [940]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.095450,	
2017-07-29 00:23:00,648 Epoch[36] Batch [950]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.095554,	
2017-07-29 00:23:08,371 Epoch[36] Batch [960]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.095659,	
2017-07-29 00:23:16,258 Epoch[36] Batch [970]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.095720,	
2017-07-29 00:23:24,130 Epoch[36] Batch [980]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.095619,	
2017-07-29 00:23:31,937 Epoch[36] Batch [990]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095654,	
2017-07-29 00:23:40,208 Epoch[36] Batch [1000]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.095613,	
2017-07-29 00:23:48,380 Epoch[36] Batch [1010]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.095558,	
2017-07-29 00:23:55,908 Epoch[36] Batch [1020]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095524,	
2017-07-29 00:24:04,044 Epoch[36] Batch [1030]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.095511,	
2017-07-29 00:24:12,208 Epoch[36] Batch [1040]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.095426,	
2017-07-29 00:24:19,798 Epoch[36] Batch [1050]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.095427,	
2017-07-29 00:24:27,366 Epoch[36] Batch [1060]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.095399,	
2017-07-29 00:24:35,776 Epoch[36] Batch [1070]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.095471,	
2017-07-29 00:24:44,055 Epoch[36] Batch [1080]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.095436,	
2017-07-29 00:24:52,277 Epoch[36] Batch [1090]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.095455,	
2017-07-29 00:25:00,300 Epoch[36] Batch [1100]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.095482,	
2017-07-29 00:25:07,707 Epoch[36] Batch [1110]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.095445,	
2017-07-29 00:25:14,727 Epoch[36] Batch [1120]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.095424,	
2017-07-29 00:25:21,496 Epoch[36] Batch [1130]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.095358,	
2017-07-29 00:25:28,339 Epoch[36] Batch [1140]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.095347,	
2017-07-29 00:25:34,729 Epoch[36] Batch [1150]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.095307,	
2017-07-29 00:25:41,601 Epoch[36] Batch [1160]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.095277,	
2017-07-29 00:25:48,179 Epoch[36] Batch [1170]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.095234,	
2017-07-29 00:25:55,662 Epoch[36] Batch [1180]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095108,	
2017-07-29 00:26:02,385 Epoch[36] Batch [1190]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.095091,	
2017-07-29 00:26:09,191 Epoch[36] Batch [1200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.095069,	
2017-07-29 00:26:15,636 Epoch[36] Batch [1210]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.095098,	
2017-07-29 00:26:22,234 Epoch[36] Batch [1220]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.095092,	
2017-07-29 00:26:28,917 Epoch[36] Batch [1230]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.095165,	
2017-07-29 00:26:35,885 Epoch[36] Batch [1240]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.095210,	
2017-07-29 00:26:42,997 Epoch[36] Batch [1250]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.095204,	
2017-07-29 00:26:50,424 Epoch[36] Batch [1260]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.095145,	
2017-07-29 00:26:58,242 Epoch[36] Batch [1270]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095153,	
2017-07-29 00:27:05,574 Epoch[36] Batch [1280]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.095165,	
2017-07-29 00:27:13,437 Epoch[36] Batch [1290]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.095182,	
2017-07-29 00:27:20,373 Epoch[36] Batch [1300]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.095222,	
2017-07-29 00:27:28,516 Epoch[36] Batch [1310]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095266,	
2017-07-29 00:27:36,365 Epoch[36] Batch [1320]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.095231,	
2017-07-29 00:27:43,797 Epoch[36] Batch [1330]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095174,	
2017-07-29 00:27:51,978 Epoch[36] Batch [1340]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.095230,	
2017-07-29 00:27:59,508 Epoch[36] Batch [1350]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095266,	
2017-07-29 00:28:06,802 Epoch[36] Batch [1360]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.095269,	
2017-07-29 00:28:14,854 Epoch[36] Batch [1370]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.095246,	
2017-07-29 00:28:22,999 Epoch[36] Batch [1380]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095201,	
2017-07-29 00:28:30,822 Epoch[36] Batch [1390]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.095224,	
2017-07-29 00:28:38,698 Epoch[36] Batch [1400]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.095155,	
2017-07-29 00:28:46,275 Epoch[36] Batch [1410]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.095151,	
2017-07-29 00:28:53,730 Epoch[36] Batch [1420]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.095185,	
2017-07-29 00:29:01,069 Epoch[36] Batch [1430]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.095218,	
2017-07-29 00:29:09,351 Epoch[36] Batch [1440]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.095219,	
2017-07-29 00:29:17,410 Epoch[36] Batch [1450]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.095231,	
2017-07-29 00:29:25,252 Epoch[36] Batch [1460]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.095192,	
2017-07-29 00:29:33,353 Epoch[36] Batch [1470]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.095163,	
2017-07-29 00:29:41,250 Epoch[36] Batch [1480]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.095152,	
2017-07-29 00:29:46,200 Epoch[36] Train-FCNLogLoss=0.095151
2017-07-29 00:29:46,200 Epoch[36] Time cost=1167.367
2017-07-29 00:29:47,337 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0037.params"
2017-07-29 00:29:52,328 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0037.states"
2017-07-29 00:30:00,935 Epoch[37] Batch [10]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.091891,	
2017-07-29 00:30:08,440 Epoch[37] Batch [20]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.092576,	
2017-07-29 00:30:15,799 Epoch[37] Batch [30]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.094889,	
2017-07-29 00:30:23,860 Epoch[37] Batch [40]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.092316,	
2017-07-29 00:30:31,038 Epoch[37] Batch [50]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.090893,	
2017-07-29 00:30:38,675 Epoch[37] Batch [60]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.091451,	
2017-07-29 00:30:46,323 Epoch[37] Batch [70]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.091585,	
2017-07-29 00:30:54,130 Epoch[37] Batch [80]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.091765,	
2017-07-29 00:31:01,572 Epoch[37] Batch [90]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092202,	
2017-07-29 00:31:09,741 Epoch[37] Batch [100]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.093210,	
2017-07-29 00:31:18,133 Epoch[37] Batch [110]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.093407,	
2017-07-29 00:31:25,525 Epoch[37] Batch [120]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.093552,	
2017-07-29 00:31:33,371 Epoch[37] Batch [130]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.094819,	
2017-07-29 00:31:40,503 Epoch[37] Batch [140]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.094640,	
2017-07-29 00:31:48,759 Epoch[37] Batch [150]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.095377,	
2017-07-29 00:31:56,921 Epoch[37] Batch [160]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.095589,	
2017-07-29 00:32:04,946 Epoch[37] Batch [170]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.095861,	
2017-07-29 00:32:12,404 Epoch[37] Batch [180]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.095868,	
2017-07-29 00:32:20,121 Epoch[37] Batch [190]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.095849,	
2017-07-29 00:32:28,458 Epoch[37] Batch [200]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.095431,	
2017-07-29 00:32:36,161 Epoch[37] Batch [210]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.095748,	
2017-07-29 00:32:43,592 Epoch[37] Batch [220]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095055,	
2017-07-29 00:32:50,506 Epoch[37] Batch [230]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.095562,	
2017-07-29 00:32:58,733 Epoch[37] Batch [240]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.095880,	
2017-07-29 00:33:06,399 Epoch[37] Batch [250]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.095979,	
2017-07-29 00:33:14,516 Epoch[37] Batch [260]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.095820,	
2017-07-29 00:33:21,885 Epoch[37] Batch [270]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.095520,	
2017-07-29 00:33:29,613 Epoch[37] Batch [280]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.096096,	
2017-07-29 00:33:38,504 Epoch[37] Batch [290]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.095908,	
2017-07-29 00:33:47,410 Epoch[37] Batch [300]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.095828,	
2017-07-29 00:33:56,317 Epoch[37] Batch [310]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.095720,	
2017-07-29 00:34:05,849 Epoch[37] Batch [320]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.095535,	
2017-07-29 00:34:15,233 Epoch[37] Batch [330]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.095256,	
2017-07-29 00:34:24,078 Epoch[37] Batch [340]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.095065,	
2017-07-29 00:34:32,847 Epoch[37] Batch [350]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.094846,	
2017-07-29 00:34:41,783 Epoch[37] Batch [360]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.094976,	
2017-07-29 00:34:50,154 Epoch[37] Batch [370]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.095090,	
2017-07-29 00:34:59,244 Epoch[37] Batch [380]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.095282,	
2017-07-29 00:35:07,457 Epoch[37] Batch [390]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.095114,	
2017-07-29 00:35:15,884 Epoch[37] Batch [400]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.095121,	
2017-07-29 00:35:23,413 Epoch[37] Batch [410]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.094974,	
2017-07-29 00:35:31,788 Epoch[37] Batch [420]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.094864,	
2017-07-29 00:35:40,316 Epoch[37] Batch [430]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.094689,	
2017-07-29 00:35:48,592 Epoch[37] Batch [440]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.094664,	
2017-07-29 00:35:58,070 Epoch[37] Batch [450]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.094600,	
2017-07-29 00:36:06,253 Epoch[37] Batch [460]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.094527,	
2017-07-29 00:36:14,490 Epoch[37] Batch [470]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.094519,	
2017-07-29 00:36:22,944 Epoch[37] Batch [480]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.094308,	
2017-07-29 00:36:31,506 Epoch[37] Batch [490]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.094160,	
2017-07-29 00:36:39,348 Epoch[37] Batch [500]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.094224,	
2017-07-29 00:36:47,738 Epoch[37] Batch [510]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.094363,	
2017-07-29 00:36:55,725 Epoch[37] Batch [520]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.094338,	
2017-07-29 00:37:04,131 Epoch[37] Batch [530]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.094430,	
2017-07-29 00:37:12,177 Epoch[37] Batch [540]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.094374,	
2017-07-29 00:37:20,650 Epoch[37] Batch [550]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.094230,	
2017-07-29 00:37:29,348 Epoch[37] Batch [560]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.094343,	
2017-07-29 00:37:37,533 Epoch[37] Batch [570]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.094291,	
2017-07-29 00:37:45,495 Epoch[37] Batch [580]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.094233,	
2017-07-29 00:37:53,951 Epoch[37] Batch [590]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.094204,	
2017-07-29 00:38:02,493 Epoch[37] Batch [600]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.094146,	
2017-07-29 00:38:09,873 Epoch[37] Batch [610]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.094100,	
2017-07-29 00:38:16,938 Epoch[37] Batch [620]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.094110,	
2017-07-29 00:38:24,839 Epoch[37] Batch [630]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.094286,	
2017-07-29 00:38:32,415 Epoch[37] Batch [640]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.094255,	
2017-07-29 00:38:39,575 Epoch[37] Batch [650]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.094339,	
2017-07-29 00:38:46,897 Epoch[37] Batch [660]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.094346,	
2017-07-29 00:38:54,415 Epoch[37] Batch [670]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.094380,	
2017-07-29 00:39:01,595 Epoch[37] Batch [680]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.094482,	
2017-07-29 00:39:08,983 Epoch[37] Batch [690]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.094491,	
2017-07-29 00:39:16,613 Epoch[37] Batch [700]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.094430,	
2017-07-29 00:39:24,311 Epoch[37] Batch [710]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.094227,	
2017-07-29 00:39:31,886 Epoch[37] Batch [720]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.094137,	
2017-07-29 00:39:38,745 Epoch[37] Batch [730]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.094250,	
2017-07-29 00:39:46,166 Epoch[37] Batch [740]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.094158,	
2017-07-29 00:39:53,259 Epoch[37] Batch [750]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.094188,	
2017-07-29 00:40:00,820 Epoch[37] Batch [760]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.094156,	
2017-07-29 00:40:07,776 Epoch[37] Batch [770]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.094232,	
2017-07-29 00:40:15,299 Epoch[37] Batch [780]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.094296,	
2017-07-29 00:40:22,691 Epoch[37] Batch [790]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.094430,	
2017-07-29 00:40:30,317 Epoch[37] Batch [800]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.094462,	
2017-07-29 00:40:38,175 Epoch[37] Batch [810]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.094471,	
2017-07-29 00:40:45,390 Epoch[37] Batch [820]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.094408,	
2017-07-29 00:40:52,829 Epoch[37] Batch [830]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.094282,	
2017-07-29 00:40:59,919 Epoch[37] Batch [840]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.094213,	
2017-07-29 00:41:07,384 Epoch[37] Batch [850]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094218,	
2017-07-29 00:41:14,920 Epoch[37] Batch [860]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.094192,	
2017-07-29 00:41:22,172 Epoch[37] Batch [870]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.094174,	
2017-07-29 00:41:29,032 Epoch[37] Batch [880]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.094281,	
2017-07-29 00:41:36,460 Epoch[37] Batch [890]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.094320,	
2017-07-29 00:41:43,510 Epoch[37] Batch [900]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.094328,	
2017-07-29 00:41:50,722 Epoch[37] Batch [910]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.094324,	
2017-07-29 00:41:57,950 Epoch[37] Batch [920]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.094332,	
2017-07-29 00:42:05,082 Epoch[37] Batch [930]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.094212,	
2017-07-29 00:42:12,767 Epoch[37] Batch [940]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.094229,	
2017-07-29 00:42:20,275 Epoch[37] Batch [950]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.094223,	
2017-07-29 00:42:27,555 Epoch[37] Batch [960]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.094149,	
2017-07-29 00:42:34,858 Epoch[37] Batch [970]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.094125,	
2017-07-29 00:42:41,979 Epoch[37] Batch [980]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.094029,	
2017-07-29 00:42:49,697 Epoch[37] Batch [990]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.094024,	
2017-07-29 00:42:57,292 Epoch[37] Batch [1000]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.094065,	
2017-07-29 00:43:04,772 Epoch[37] Batch [1010]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.094047,	
2017-07-29 00:43:12,093 Epoch[37] Batch [1020]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.094027,	
2017-07-29 00:43:19,316 Epoch[37] Batch [1030]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.094013,	
2017-07-29 00:43:26,196 Epoch[37] Batch [1040]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.093880,	
2017-07-29 00:43:33,893 Epoch[37] Batch [1050]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.093827,	
2017-07-29 00:43:41,199 Epoch[37] Batch [1060]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.093793,	
2017-07-29 00:43:48,363 Epoch[37] Batch [1070]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.093801,	
2017-07-29 00:43:55,846 Epoch[37] Batch [1080]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.093784,	
2017-07-29 00:44:03,640 Epoch[37] Batch [1090]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.094070,	
2017-07-29 00:44:10,747 Epoch[37] Batch [1100]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094057,	
2017-07-29 00:44:18,479 Epoch[37] Batch [1110]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.094120,	
2017-07-29 00:44:25,903 Epoch[37] Batch [1120]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.094146,	
2017-07-29 00:44:33,037 Epoch[37] Batch [1130]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.094124,	
2017-07-29 00:44:40,400 Epoch[37] Batch [1140]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.094049,	
2017-07-29 00:44:48,039 Epoch[37] Batch [1150]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.094035,	
2017-07-29 00:44:55,152 Epoch[37] Batch [1160]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.094015,	
2017-07-29 00:45:01,973 Epoch[37] Batch [1170]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.094096,	
2017-07-29 00:45:09,620 Epoch[37] Batch [1180]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.094111,	
2017-07-29 00:45:17,097 Epoch[37] Batch [1190]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.094162,	
2017-07-29 00:45:24,814 Epoch[37] Batch [1200]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.094081,	
2017-07-29 00:45:31,992 Epoch[37] Batch [1210]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.094142,	
2017-07-29 00:45:39,057 Epoch[37] Batch [1220]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.094086,	
2017-07-29 00:45:46,308 Epoch[37] Batch [1230]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.094184,	
2017-07-29 00:45:53,358 Epoch[37] Batch [1240]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.094198,	
2017-07-29 00:46:01,076 Epoch[37] Batch [1250]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.094169,	
2017-07-29 00:46:08,537 Epoch[37] Batch [1260]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.094178,	
2017-07-29 00:46:15,837 Epoch[37] Batch [1270]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.094183,	
2017-07-29 00:46:22,934 Epoch[37] Batch [1280]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.094182,	
2017-07-29 00:46:30,660 Epoch[37] Batch [1290]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.094215,	
2017-07-29 00:46:38,175 Epoch[37] Batch [1300]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.094227,	
2017-07-29 00:46:45,243 Epoch[37] Batch [1310]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.094275,	
2017-07-29 00:46:53,186 Epoch[37] Batch [1320]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.094273,	
2017-07-29 00:47:00,824 Epoch[37] Batch [1330]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.094288,	
2017-07-29 00:47:08,808 Epoch[37] Batch [1340]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.094272,	
2017-07-29 00:47:17,068 Epoch[37] Batch [1350]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.094301,	
2017-07-29 00:47:24,879 Epoch[37] Batch [1360]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094323,	
2017-07-29 00:47:32,567 Epoch[37] Batch [1370]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.094405,	
2017-07-29 00:47:40,086 Epoch[37] Batch [1380]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.094416,	
2017-07-29 00:47:47,527 Epoch[37] Batch [1390]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.094368,	
2017-07-29 00:47:55,026 Epoch[37] Batch [1400]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.094391,	
2017-07-29 00:48:01,911 Epoch[37] Batch [1410]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.094424,	
2017-07-29 00:48:09,059 Epoch[37] Batch [1420]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.094476,	
2017-07-29 00:48:17,134 Epoch[37] Batch [1430]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.094525,	
2017-07-29 00:48:25,039 Epoch[37] Batch [1440]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.094558,	
2017-07-29 00:48:32,157 Epoch[37] Batch [1450]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.094516,	
2017-07-29 00:48:39,662 Epoch[37] Batch [1460]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.094524,	
2017-07-29 00:48:47,055 Epoch[37] Batch [1470]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.094470,	
2017-07-29 00:48:54,248 Epoch[37] Batch [1480]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.094448,	
2017-07-29 00:48:58,386 Epoch[37] Train-FCNLogLoss=0.094454
2017-07-29 00:48:58,386 Epoch[37] Time cost=1146.058
2017-07-29 00:48:59,472 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0038.params"
2017-07-29 00:49:03,225 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0038.states"
2017-07-29 00:49:11,081 Epoch[38] Batch [10]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.093767,	
2017-07-29 00:49:17,919 Epoch[38] Batch [20]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.091803,	
2017-07-29 00:49:24,818 Epoch[38] Batch [30]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.092215,	
2017-07-29 00:49:31,643 Epoch[38] Batch [40]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.090734,	
2017-07-29 00:49:38,797 Epoch[38] Batch [50]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.090868,	
2017-07-29 00:49:45,892 Epoch[38] Batch [60]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.090518,	
2017-07-29 00:49:52,668 Epoch[38] Batch [70]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.089831,	
2017-07-29 00:49:59,865 Epoch[38] Batch [80]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089208,	
2017-07-29 00:50:06,848 Epoch[38] Batch [90]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.089387,	
2017-07-29 00:50:14,510 Epoch[38] Batch [100]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.090239,	
2017-07-29 00:50:21,315 Epoch[38] Batch [110]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.090275,	
2017-07-29 00:50:27,982 Epoch[38] Batch [120]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.090669,	
2017-07-29 00:50:35,087 Epoch[38] Batch [130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.091116,	
2017-07-29 00:50:42,165 Epoch[38] Batch [140]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.091908,	
2017-07-29 00:50:49,018 Epoch[38] Batch [150]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.092713,	
2017-07-29 00:50:56,203 Epoch[38] Batch [160]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.093481,	
2017-07-29 00:51:03,666 Epoch[38] Batch [170]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.093453,	
2017-07-29 00:51:10,914 Epoch[38] Batch [180]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.093376,	
2017-07-29 00:51:18,639 Epoch[38] Batch [190]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.093635,	
2017-07-29 00:51:26,099 Epoch[38] Batch [200]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.093319,	
2017-07-29 00:51:33,416 Epoch[38] Batch [210]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.093369,	
2017-07-29 00:51:40,810 Epoch[38] Batch [220]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.093308,	
2017-07-29 00:51:48,414 Epoch[38] Batch [230]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.092900,	
2017-07-29 00:51:55,943 Epoch[38] Batch [240]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.092954,	
2017-07-29 00:52:03,392 Epoch[38] Batch [250]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092844,	
2017-07-29 00:52:10,606 Epoch[38] Batch [260]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.092775,	
2017-07-29 00:52:17,997 Epoch[38] Batch [270]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.093258,	
2017-07-29 00:52:25,025 Epoch[38] Batch [280]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.093588,	
2017-07-29 00:52:32,112 Epoch[38] Batch [290]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.093757,	
2017-07-29 00:52:39,217 Epoch[38] Batch [300]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.093851,	
2017-07-29 00:52:46,049 Epoch[38] Batch [310]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.093463,	
2017-07-29 00:52:53,164 Epoch[38] Batch [320]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.093623,	
2017-07-29 00:53:00,368 Epoch[38] Batch [330]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.093613,	
2017-07-29 00:53:07,890 Epoch[38] Batch [340]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.093381,	
2017-07-29 00:53:14,342 Epoch[38] Batch [350]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.093399,	
2017-07-29 00:53:21,072 Epoch[38] Batch [360]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.093464,	
2017-07-29 00:53:28,035 Epoch[38] Batch [370]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.093650,	
2017-07-29 00:53:35,177 Epoch[38] Batch [380]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.093660,	
2017-07-29 00:53:42,437 Epoch[38] Batch [390]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.093685,	
2017-07-29 00:53:49,239 Epoch[38] Batch [400]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.093511,	
2017-07-29 00:53:56,131 Epoch[38] Batch [410]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.093247,	
2017-07-29 00:54:03,153 Epoch[38] Batch [420]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.093204,	
2017-07-29 00:54:10,053 Epoch[38] Batch [430]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.093071,	
2017-07-29 00:54:16,812 Epoch[38] Batch [440]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.093070,	
2017-07-29 00:54:23,916 Epoch[38] Batch [450]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.092878,	
2017-07-29 00:54:30,701 Epoch[38] Batch [460]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.092707,	
2017-07-29 00:54:37,792 Epoch[38] Batch [470]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.092566,	
2017-07-29 00:54:44,710 Epoch[38] Batch [480]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.092712,	
2017-07-29 00:54:51,944 Epoch[38] Batch [490]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.092672,	
2017-07-29 00:55:00,117 Epoch[38] Batch [500]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.092814,	
2017-07-29 00:55:06,846 Epoch[38] Batch [510]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.092942,	
2017-07-29 00:55:13,787 Epoch[38] Batch [520]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.092830,	
2017-07-29 00:55:21,199 Epoch[38] Batch [530]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.092735,	
2017-07-29 00:55:28,357 Epoch[38] Batch [540]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.092735,	
2017-07-29 00:55:35,499 Epoch[38] Batch [550]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.092751,	
2017-07-29 00:55:43,096 Epoch[38] Batch [560]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.092688,	
2017-07-29 00:55:50,544 Epoch[38] Batch [570]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092593,	
2017-07-29 00:55:57,881 Epoch[38] Batch [580]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.092823,	
2017-07-29 00:56:05,265 Epoch[38] Batch [590]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.092970,	
2017-07-29 00:56:11,339 Epoch[38] Batch [600]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.092959,	
2017-07-29 00:56:18,680 Epoch[38] Batch [610]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.092913,	
2017-07-29 00:56:25,448 Epoch[38] Batch [620]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.092833,	
2017-07-29 00:56:32,519 Epoch[38] Batch [630]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.092855,	
2017-07-29 00:56:39,592 Epoch[38] Batch [640]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.092971,	
2017-07-29 00:56:47,093 Epoch[38] Batch [650]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.092994,	
2017-07-29 00:56:54,440 Epoch[38] Batch [660]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.093014,	
2017-07-29 00:57:02,143 Epoch[38] Batch [670]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.092994,	
2017-07-29 00:57:09,729 Epoch[38] Batch [680]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.092955,	
2017-07-29 00:57:16,886 Epoch[38] Batch [690]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.093028,	
2017-07-29 00:57:24,199 Epoch[38] Batch [700]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.093235,	
2017-07-29 00:57:31,337 Epoch[38] Batch [710]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.093287,	
2017-07-29 00:57:38,255 Epoch[38] Batch [720]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.093267,	
2017-07-29 00:57:45,903 Epoch[38] Batch [730]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.093384,	
2017-07-29 00:57:53,530 Epoch[38] Batch [740]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.093434,	
2017-07-29 00:58:00,838 Epoch[38] Batch [750]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.093511,	
2017-07-29 00:58:08,027 Epoch[38] Batch [760]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.093488,	
2017-07-29 00:58:15,409 Epoch[38] Batch [770]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.093439,	
2017-07-29 00:58:23,156 Epoch[38] Batch [780]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-29 00:58:30,486 Epoch[38] Batch [790]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.093325,	
2017-07-29 00:58:37,517 Epoch[38] Batch [800]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.093320,	
2017-07-29 00:58:44,941 Epoch[38] Batch [810]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.093345,	
2017-07-29 00:58:52,896 Epoch[38] Batch [820]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.093306,	
2017-07-29 00:59:00,291 Epoch[38] Batch [830]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.093266,	
2017-07-29 00:59:07,533 Epoch[38] Batch [840]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.093181,	
2017-07-29 00:59:14,795 Epoch[38] Batch [850]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.093276,	
2017-07-29 00:59:21,923 Epoch[38] Batch [860]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.093248,	
2017-07-29 00:59:29,077 Epoch[38] Batch [870]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.093180,	
2017-07-29 00:59:36,625 Epoch[38] Batch [880]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.093248,	
2017-07-29 00:59:45,039 Epoch[38] Batch [890]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.093199,	
2017-07-29 00:59:52,535 Epoch[38] Batch [900]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.093272,	
2017-07-29 01:00:00,421 Epoch[38] Batch [910]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.093246,	
2017-07-29 01:00:07,211 Epoch[38] Batch [920]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.093256,	
2017-07-29 01:00:15,032 Epoch[38] Batch [930]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.093240,	
2017-07-29 01:00:22,650 Epoch[38] Batch [940]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.093187,	
2017-07-29 01:00:30,751 Epoch[38] Batch [950]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.093148,	
2017-07-29 01:00:38,204 Epoch[38] Batch [960]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.093150,	
2017-07-29 01:00:45,398 Epoch[38] Batch [970]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.093160,	
2017-07-29 01:00:52,301 Epoch[38] Batch [980]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.093137,	
2017-07-29 01:00:59,753 Epoch[38] Batch [990]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.093057,	
2017-07-29 01:01:07,128 Epoch[38] Batch [1000]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.093017,	
2017-07-29 01:01:14,228 Epoch[38] Batch [1010]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.092994,	
2017-07-29 01:01:21,561 Epoch[38] Batch [1020]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.093018,	
2017-07-29 01:01:28,727 Epoch[38] Batch [1030]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.092972,	
2017-07-29 01:01:35,516 Epoch[38] Batch [1040]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.093029,	
2017-07-29 01:01:42,943 Epoch[38] Batch [1050]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.092999,	
2017-07-29 01:01:49,845 Epoch[38] Batch [1060]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.093011,	
2017-07-29 01:01:56,563 Epoch[38] Batch [1070]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.092993,	
2017-07-29 01:02:03,107 Epoch[38] Batch [1080]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.092927,	
2017-07-29 01:02:10,154 Epoch[38] Batch [1090]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.092895,	
2017-07-29 01:02:17,322 Epoch[38] Batch [1100]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.092942,	
2017-07-29 01:02:24,436 Epoch[38] Batch [1110]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.093049,	
2017-07-29 01:02:31,314 Epoch[38] Batch [1120]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.093057,	
2017-07-29 01:02:37,468 Epoch[38] Batch [1130]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.093092,	
2017-07-29 01:02:44,592 Epoch[38] Batch [1140]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.093229,	
2017-07-29 01:02:51,808 Epoch[38] Batch [1150]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.093209,	
2017-07-29 01:02:58,628 Epoch[38] Batch [1160]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.093187,	
2017-07-29 01:03:06,630 Epoch[38] Batch [1170]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.093218,	
2017-07-29 01:03:13,843 Epoch[38] Batch [1180]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.093195,	
2017-07-29 01:03:21,148 Epoch[38] Batch [1190]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.093241,	
2017-07-29 01:03:28,846 Epoch[38] Batch [1200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.093240,	
2017-07-29 01:03:36,311 Epoch[38] Batch [1210]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.093168,	
2017-07-29 01:03:43,524 Epoch[38] Batch [1220]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.093251,	
2017-07-29 01:03:50,861 Epoch[38] Batch [1230]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.093237,	
2017-07-29 01:03:58,171 Epoch[38] Batch [1240]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.093257,	
2017-07-29 01:04:06,589 Epoch[38] Batch [1250]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.093405,	
2017-07-29 01:04:14,653 Epoch[38] Batch [1260]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.093543,	
2017-07-29 01:04:22,464 Epoch[38] Batch [1270]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094105,	
2017-07-29 01:04:29,713 Epoch[38] Batch [1280]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.094559,	
2017-07-29 01:04:37,023 Epoch[38] Batch [1290]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.095025,	
2017-07-29 01:04:44,863 Epoch[38] Batch [1300]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.095228,	
2017-07-29 01:04:52,242 Epoch[38] Batch [1310]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.095571,	
2017-07-29 01:04:59,931 Epoch[38] Batch [1320]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.095749,	
2017-07-29 01:05:07,479 Epoch[38] Batch [1330]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095814,	
2017-07-29 01:05:15,297 Epoch[38] Batch [1340]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.096068,	
2017-07-29 01:05:22,643 Epoch[38] Batch [1350]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.096141,	
2017-07-29 01:05:29,914 Epoch[38] Batch [1360]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.096226,	
2017-07-29 01:05:37,418 Epoch[38] Batch [1370]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.096249,	
2017-07-29 01:05:45,643 Epoch[38] Batch [1380]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.096451,	
2017-07-29 01:05:53,722 Epoch[38] Batch [1390]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.096474,	
2017-07-29 01:06:00,790 Epoch[38] Batch [1400]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.096638,	
2017-07-29 01:06:08,070 Epoch[38] Batch [1410]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.096729,	
2017-07-29 01:06:15,844 Epoch[38] Batch [1420]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.096741,	
2017-07-29 01:06:24,095 Epoch[38] Batch [1430]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.096722,	
2017-07-29 01:06:31,857 Epoch[38] Batch [1440]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.096731,	
2017-07-29 01:06:39,358 Epoch[38] Batch [1450]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.096787,	
2017-07-29 01:06:46,291 Epoch[38] Batch [1460]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.096975,	
2017-07-29 01:06:53,825 Epoch[38] Batch [1470]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.096999,	
2017-07-29 01:07:01,085 Epoch[38] Batch [1480]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.096999,	
2017-07-29 01:07:05,511 Epoch[38] Train-FCNLogLoss=0.097002
2017-07-29 01:07:05,511 Epoch[38] Time cost=1082.285
2017-07-29 01:07:06,652 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0039.params"
2017-07-29 01:07:10,882 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0039.states"
2017-07-29 01:07:19,669 Epoch[39] Batch [10]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.102855,	
2017-07-29 01:07:27,301 Epoch[39] Batch [20]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.106092,	
2017-07-29 01:07:34,649 Epoch[39] Batch [30]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.102434,	
2017-07-29 01:07:42,567 Epoch[39] Batch [40]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.103638,	
2017-07-29 01:07:50,406 Epoch[39] Batch [50]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.103305,	
2017-07-29 01:07:57,986 Epoch[39] Batch [60]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.101771,	
2017-07-29 01:08:05,535 Epoch[39] Batch [70]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.100849,	
2017-07-29 01:08:12,902 Epoch[39] Batch [80]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.100042,	
2017-07-29 01:08:20,551 Epoch[39] Batch [90]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098110,	
2017-07-29 01:08:27,903 Epoch[39] Batch [100]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.097838,	
2017-07-29 01:08:35,794 Epoch[39] Batch [110]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.097697,	
2017-07-29 01:08:43,613 Epoch[39] Batch [120]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.097753,	
2017-07-29 01:08:51,095 Epoch[39] Batch [130]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.097101,	
2017-07-29 01:08:59,098 Epoch[39] Batch [140]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.096977,	
2017-07-29 01:09:07,014 Epoch[39] Batch [150]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.097327,	
2017-07-29 01:09:14,362 Epoch[39] Batch [160]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.098508,	
2017-07-29 01:09:22,261 Epoch[39] Batch [170]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.099005,	
2017-07-29 01:09:29,757 Epoch[39] Batch [180]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.100515,	
2017-07-29 01:09:37,826 Epoch[39] Batch [190]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.101867,	
2017-07-29 01:09:45,659 Epoch[39] Batch [200]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.102248,	
2017-07-29 01:09:54,007 Epoch[39] Batch [210]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.102195,	
2017-07-29 01:10:02,770 Epoch[39] Batch [220]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.102054,	
2017-07-29 01:10:11,063 Epoch[39] Batch [230]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.101884,	
2017-07-29 01:10:19,186 Epoch[39] Batch [240]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.101453,	
2017-07-29 01:10:26,679 Epoch[39] Batch [250]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.101275,	
2017-07-29 01:10:34,263 Epoch[39] Batch [260]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.101036,	
2017-07-29 01:10:41,759 Epoch[39] Batch [270]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.101266,	
2017-07-29 01:10:49,237 Epoch[39] Batch [280]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.100994,	
2017-07-29 01:10:56,725 Epoch[39] Batch [290]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.101153,	
2017-07-29 01:11:04,228 Epoch[39] Batch [300]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.101561,	
2017-07-29 01:11:12,196 Epoch[39] Batch [310]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.101409,	
2017-07-29 01:11:19,707 Epoch[39] Batch [320]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.101400,	
2017-07-29 01:11:27,434 Epoch[39] Batch [330]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.101594,	
2017-07-29 01:11:35,262 Epoch[39] Batch [340]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.101305,	
2017-07-29 01:11:42,652 Epoch[39] Batch [350]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.101299,	
2017-07-29 01:11:50,328 Epoch[39] Batch [360]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.100848,	
2017-07-29 01:11:57,719 Epoch[39] Batch [370]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.100596,	
2017-07-29 01:12:05,395 Epoch[39] Batch [380]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.100494,	
2017-07-29 01:12:13,079 Epoch[39] Batch [390]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.100298,	
2017-07-29 01:12:21,024 Epoch[39] Batch [400]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.099910,	
2017-07-29 01:12:28,886 Epoch[39] Batch [410]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.099851,	
2017-07-29 01:12:36,060 Epoch[39] Batch [420]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.099885,	
2017-07-29 01:12:43,633 Epoch[39] Batch [430]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.099571,	
2017-07-29 01:12:51,250 Epoch[39] Batch [440]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.099527,	
2017-07-29 01:12:59,129 Epoch[39] Batch [450]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.099544,	
2017-07-29 01:13:07,315 Epoch[39] Batch [460]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.099212,	
2017-07-29 01:13:15,754 Epoch[39] Batch [470]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.099155,	
2017-07-29 01:13:22,866 Epoch[39] Batch [480]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.098968,	
2017-07-29 01:13:30,221 Epoch[39] Batch [490]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.098780,	
2017-07-29 01:13:37,559 Epoch[39] Batch [500]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098597,	
2017-07-29 01:13:45,200 Epoch[39] Batch [510]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098559,	
2017-07-29 01:13:53,414 Epoch[39] Batch [520]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.098505,	
2017-07-29 01:14:00,897 Epoch[39] Batch [530]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.098436,	
2017-07-29 01:14:08,348 Epoch[39] Batch [540]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.098400,	
2017-07-29 01:14:15,969 Epoch[39] Batch [550]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.098295,	
2017-07-29 01:14:23,311 Epoch[39] Batch [560]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098256,	
2017-07-29 01:14:30,869 Epoch[39] Batch [570]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098378,	
2017-07-29 01:14:38,610 Epoch[39] Batch [580]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098613,	
2017-07-29 01:14:46,205 Epoch[39] Batch [590]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.099003,	
2017-07-29 01:14:53,946 Epoch[39] Batch [600]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098997,	
2017-07-29 01:15:01,699 Epoch[39] Batch [610]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.099083,	
2017-07-29 01:15:09,453 Epoch[39] Batch [620]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.099164,	
2017-07-29 01:15:17,114 Epoch[39] Batch [630]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.099057,	
2017-07-29 01:15:24,221 Epoch[39] Batch [640]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.098936,	
2017-07-29 01:15:31,931 Epoch[39] Batch [650]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.098892,	
2017-07-29 01:15:39,293 Epoch[39] Batch [660]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.098870,	
2017-07-29 01:15:46,823 Epoch[39] Batch [670]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098936,	
2017-07-29 01:15:54,687 Epoch[39] Batch [680]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098907,	
2017-07-29 01:16:02,454 Epoch[39] Batch [690]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.098732,	
2017-07-29 01:16:10,521 Epoch[39] Batch [700]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.098706,	
2017-07-29 01:16:18,540 Epoch[39] Batch [710]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.098775,	
2017-07-29 01:16:26,168 Epoch[39] Batch [720]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098768,	
2017-07-29 01:16:34,145 Epoch[39] Batch [730]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.098855,	
2017-07-29 01:16:42,420 Epoch[39] Batch [740]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.098811,	
2017-07-29 01:16:51,263 Epoch[39] Batch [750]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.098780,	
2017-07-29 01:16:59,447 Epoch[39] Batch [760]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.098664,	
2017-07-29 01:17:07,362 Epoch[39] Batch [770]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.098565,	
2017-07-29 01:17:15,522 Epoch[39] Batch [780]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.098563,	
2017-07-29 01:17:23,251 Epoch[39] Batch [790]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098423,	
2017-07-29 01:17:31,039 Epoch[39] Batch [800]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.098455,	
2017-07-29 01:17:38,675 Epoch[39] Batch [810]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098518,	
2017-07-29 01:17:46,713 Epoch[39] Batch [820]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.098444,	
2017-07-29 01:17:54,504 Epoch[39] Batch [830]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.098297,	
2017-07-29 01:18:02,352 Epoch[39] Batch [840]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.098285,	
2017-07-29 01:18:10,044 Epoch[39] Batch [850]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098326,	
2017-07-29 01:18:17,735 Epoch[39] Batch [860]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098369,	
2017-07-29 01:18:25,680 Epoch[39] Batch [870]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.098341,	
2017-07-29 01:18:33,451 Epoch[39] Batch [880]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.098203,	
2017-07-29 01:18:41,241 Epoch[39] Batch [890]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.098108,	
2017-07-29 01:18:49,034 Epoch[39] Batch [900]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.098050,	
2017-07-29 01:18:56,733 Epoch[39] Batch [910]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.097931,	
2017-07-29 01:19:04,864 Epoch[39] Batch [920]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.097870,	
2017-07-29 01:19:12,889 Epoch[39] Batch [930]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.097820,	
2017-07-29 01:19:20,666 Epoch[39] Batch [940]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.097814,	
2017-07-29 01:19:28,579 Epoch[39] Batch [950]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.097804,	
2017-07-29 01:19:36,214 Epoch[39] Batch [960]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.097841,	
2017-07-29 01:19:43,832 Epoch[39] Batch [970]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.097756,	
2017-07-29 01:19:51,883 Epoch[39] Batch [980]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.097613,	
2017-07-29 01:20:00,166 Epoch[39] Batch [990]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.097523,	
2017-07-29 01:20:08,575 Epoch[39] Batch [1000]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.097501,	
2017-07-29 01:20:16,651 Epoch[39] Batch [1010]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.097510,	
2017-07-29 01:20:24,747 Epoch[39] Batch [1020]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.097365,	
2017-07-29 01:20:32,663 Epoch[39] Batch [1030]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.097328,	
2017-07-29 01:20:40,689 Epoch[39] Batch [1040]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.097275,	
2017-07-29 01:20:48,976 Epoch[39] Batch [1050]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.097326,	
2017-07-29 01:20:57,300 Epoch[39] Batch [1060]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.097226,	
2017-07-29 01:21:05,365 Epoch[39] Batch [1070]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.097197,	
2017-07-29 01:21:13,504 Epoch[39] Batch [1080]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.097213,	
2017-07-29 01:21:21,737 Epoch[39] Batch [1090]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.097065,	
2017-07-29 01:21:29,469 Epoch[39] Batch [1100]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.096976,	
2017-07-29 01:21:37,444 Epoch[39] Batch [1110]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.096831,	
2017-07-29 01:21:45,090 Epoch[39] Batch [1120]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.096824,	
2017-07-29 01:21:52,792 Epoch[39] Batch [1130]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.096766,	
2017-07-29 01:22:00,395 Epoch[39] Batch [1140]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.096769,	
2017-07-29 01:22:08,152 Epoch[39] Batch [1150]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.096726,	
2017-07-29 01:22:16,081 Epoch[39] Batch [1160]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.096746,	
2017-07-29 01:22:24,201 Epoch[39] Batch [1170]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.096735,	
2017-07-29 01:22:32,137 Epoch[39] Batch [1180]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.096760,	
2017-07-29 01:22:39,969 Epoch[39] Batch [1190]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.096764,	
2017-07-29 01:22:47,857 Epoch[39] Batch [1200]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.096755,	
2017-07-29 01:22:55,264 Epoch[39] Batch [1210]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.096686,	
2017-07-29 01:23:03,371 Epoch[39] Batch [1220]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.096632,	
2017-07-29 01:23:11,236 Epoch[39] Batch [1230]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.096628,	
2017-07-29 01:23:18,908 Epoch[39] Batch [1240]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.096556,	
2017-07-29 01:23:26,723 Epoch[39] Batch [1250]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.096528,	
2017-07-29 01:23:34,291 Epoch[39] Batch [1260]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096425,	
2017-07-29 01:23:42,131 Epoch[39] Batch [1270]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.096415,	
2017-07-29 01:23:50,219 Epoch[39] Batch [1280]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.096356,	
2017-07-29 01:23:57,763 Epoch[39] Batch [1290]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.096336,	
2017-07-29 01:24:05,578 Epoch[39] Batch [1300]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.096373,	
2017-07-29 01:24:13,816 Epoch[39] Batch [1310]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.096412,	
2017-07-29 01:24:21,983 Epoch[39] Batch [1320]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.096459,	
2017-07-29 01:24:30,143 Epoch[39] Batch [1330]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.096546,	
2017-07-29 01:24:38,235 Epoch[39] Batch [1340]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.096622,	
2017-07-29 01:24:46,177 Epoch[39] Batch [1350]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.096557,	
2017-07-29 01:24:53,971 Epoch[39] Batch [1360]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096547,	
2017-07-29 01:25:01,935 Epoch[39] Batch [1370]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.096552,	
2017-07-29 01:25:09,627 Epoch[39] Batch [1380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.096577,	
2017-07-29 01:25:17,421 Epoch[39] Batch [1390]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096625,	
2017-07-29 01:25:25,617 Epoch[39] Batch [1400]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.096634,	
2017-07-29 01:25:34,142 Epoch[39] Batch [1410]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.096663,	
2017-07-29 01:25:42,105 Epoch[39] Batch [1420]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.096623,	
2017-07-29 01:25:49,830 Epoch[39] Batch [1430]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.096615,	
2017-07-29 01:25:57,552 Epoch[39] Batch [1440]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.096681,	
2017-07-29 01:26:05,348 Epoch[39] Batch [1450]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096707,	
2017-07-29 01:26:13,703 Epoch[39] Batch [1460]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.096639,	
2017-07-29 01:26:21,532 Epoch[39] Batch [1470]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.096585,	
2017-07-29 01:26:29,506 Epoch[39] Batch [1480]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.096620,	
2017-07-29 01:26:34,426 Epoch[39] Train-FCNLogLoss=0.096671
2017-07-29 01:26:34,426 Epoch[39] Time cost=1163.543
2017-07-29 01:26:35,765 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0040.params"
2017-07-29 01:26:40,376 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0040.states"
2017-07-29 01:26:49,688 Epoch[40] Batch [10]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.091826,	
2017-07-29 01:26:57,748 Epoch[40] Batch [20]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.094450,	
2017-07-29 01:27:05,923 Epoch[40] Batch [30]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.092696,	
2017-07-29 01:27:13,664 Epoch[40] Batch [40]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.090211,	
2017-07-29 01:27:21,258 Epoch[40] Batch [50]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.090682,	
2017-07-29 01:27:29,068 Epoch[40] Batch [60]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.089599,	
2017-07-29 01:27:37,095 Epoch[40] Batch [70]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.090362,	
2017-07-29 01:27:45,541 Epoch[40] Batch [80]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.091335,	
2017-07-29 01:27:53,887 Epoch[40] Batch [90]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.092782,	
2017-07-29 01:28:01,473 Epoch[40] Batch [100]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.092710,	
2017-07-29 01:28:09,414 Epoch[40] Batch [110]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.093014,	
2017-07-29 01:28:17,307 Epoch[40] Batch [120]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.092699,	
2017-07-29 01:28:25,153 Epoch[40] Batch [130]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.093487,	
2017-07-29 01:28:33,418 Epoch[40] Batch [140]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.093595,	
2017-07-29 01:28:41,184 Epoch[40] Batch [150]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.094173,	
2017-07-29 01:28:49,578 Epoch[40] Batch [160]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.093929,	
2017-07-29 01:28:57,753 Epoch[40] Batch [170]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.094895,	
2017-07-29 01:29:05,882 Epoch[40] Batch [180]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.094891,	
2017-07-29 01:29:13,841 Epoch[40] Batch [190]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.095332,	
2017-07-29 01:29:21,992 Epoch[40] Batch [200]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095700,	
2017-07-29 01:29:30,247 Epoch[40] Batch [210]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.095415,	
2017-07-29 01:29:38,573 Epoch[40] Batch [220]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.095158,	
2017-07-29 01:29:46,734 Epoch[40] Batch [230]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.095845,	
2017-07-29 01:29:54,887 Epoch[40] Batch [240]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095621,	
2017-07-29 01:30:03,006 Epoch[40] Batch [250]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.095493,	
2017-07-29 01:30:10,943 Epoch[40] Batch [260]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.095541,	
2017-07-29 01:30:19,187 Epoch[40] Batch [270]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.095233,	
2017-07-29 01:30:27,505 Epoch[40] Batch [280]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.095670,	
2017-07-29 01:30:35,195 Epoch[40] Batch [290]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.095692,	
2017-07-29 01:30:43,001 Epoch[40] Batch [300]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095702,	
2017-07-29 01:30:50,732 Epoch[40] Batch [310]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095787,	
2017-07-29 01:30:59,086 Epoch[40] Batch [320]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.095840,	
2017-07-29 01:31:07,043 Epoch[40] Batch [330]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.095848,	
2017-07-29 01:31:15,346 Epoch[40] Batch [340]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.095720,	
2017-07-29 01:31:23,492 Epoch[40] Batch [350]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095647,	
2017-07-29 01:31:31,899 Epoch[40] Batch [360]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.095295,	
2017-07-29 01:31:40,047 Epoch[40] Batch [370]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.095418,	
2017-07-29 01:31:47,933 Epoch[40] Batch [380]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.095325,	
2017-07-29 01:31:56,157 Epoch[40] Batch [390]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.095528,	
2017-07-29 01:32:04,052 Epoch[40] Batch [400]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.095643,	
2017-07-29 01:32:11,991 Epoch[40] Batch [410]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.095742,	
2017-07-29 01:32:20,312 Epoch[40] Batch [420]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.095676,	
2017-07-29 01:32:28,256 Epoch[40] Batch [430]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.095508,	
2017-07-29 01:32:36,173 Epoch[40] Batch [440]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.095576,	
2017-07-29 01:32:43,787 Epoch[40] Batch [450]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095297,	
2017-07-29 01:32:51,854 Epoch[40] Batch [460]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.095187,	
2017-07-29 01:32:59,937 Epoch[40] Batch [470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.094999,	
2017-07-29 01:33:08,065 Epoch[40] Batch [480]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.095154,	
2017-07-29 01:33:16,012 Epoch[40] Batch [490]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.095019,	
2017-07-29 01:33:24,060 Epoch[40] Batch [500]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.094866,	
2017-07-29 01:33:31,541 Epoch[40] Batch [510]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.094737,	
2017-07-29 01:33:38,360 Update[60000]: Change learning rate to 5.00000e-05
2017-07-29 01:33:39,496 Epoch[40] Batch [520]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.094774,	
2017-07-29 01:33:47,091 Epoch[40] Batch [530]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.094724,	
2017-07-29 01:33:54,878 Epoch[40] Batch [540]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.094680,	
2017-07-29 01:34:02,902 Epoch[40] Batch [550]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.094524,	
2017-07-29 01:34:10,642 Epoch[40] Batch [560]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.094422,	
2017-07-29 01:34:18,765 Epoch[40] Batch [570]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.094099,	
2017-07-29 01:34:26,573 Epoch[40] Batch [580]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094092,	
2017-07-29 01:34:34,555 Epoch[40] Batch [590]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.094124,	
2017-07-29 01:34:42,267 Epoch[40] Batch [600]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.094314,	
2017-07-29 01:34:50,239 Epoch[40] Batch [610]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.094299,	
2017-07-29 01:34:57,981 Epoch[40] Batch [620]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.094212,	
2017-07-29 01:35:05,943 Epoch[40] Batch [630]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.094195,	
2017-07-29 01:35:13,807 Epoch[40] Batch [640]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.094279,	
2017-07-29 01:35:22,446 Epoch[40] Batch [650]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.094202,	
2017-07-29 01:35:30,768 Epoch[40] Batch [660]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.094202,	
2017-07-29 01:35:39,138 Epoch[40] Batch [670]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.094147,	
2017-07-29 01:35:47,635 Epoch[40] Batch [680]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.094097,	
2017-07-29 01:35:56,192 Epoch[40] Batch [690]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.094145,	
2017-07-29 01:36:03,927 Epoch[40] Batch [700]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.093992,	
2017-07-29 01:36:11,617 Epoch[40] Batch [710]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.093954,	
2017-07-29 01:36:19,449 Epoch[40] Batch [720]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.093966,	
2017-07-29 01:36:27,357 Epoch[40] Batch [730]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.093985,	
2017-07-29 01:36:34,372 Epoch[40] Batch [740]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.093968,	
2017-07-29 01:36:42,501 Epoch[40] Batch [750]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.093840,	
2017-07-29 01:36:49,391 Epoch[40] Batch [760]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.093863,	
2017-07-29 01:36:56,883 Epoch[40] Batch [770]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.093826,	
2017-07-29 01:37:03,984 Epoch[40] Batch [780]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.093755,	
2017-07-29 01:37:12,018 Epoch[40] Batch [790]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.093724,	
2017-07-29 01:37:19,754 Epoch[40] Batch [800]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.093606,	
2017-07-29 01:37:27,148 Epoch[40] Batch [810]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.093498,	
2017-07-29 01:37:33,987 Epoch[40] Batch [820]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.093479,	
2017-07-29 01:37:40,851 Epoch[40] Batch [830]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.093338,	
2017-07-29 01:37:47,638 Epoch[40] Batch [840]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.093236,	
2017-07-29 01:37:54,798 Epoch[40] Batch [850]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.093201,	
2017-07-29 01:38:01,960 Epoch[40] Batch [860]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.093203,	
2017-07-29 01:38:09,219 Epoch[40] Batch [870]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.093047,	
2017-07-29 01:38:16,357 Epoch[40] Batch [880]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.092973,	
2017-07-29 01:38:23,749 Epoch[40] Batch [890]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.092940,	
2017-07-29 01:38:31,591 Epoch[40] Batch [900]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.092965,	
2017-07-29 01:38:39,056 Epoch[40] Batch [910]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.092886,	
2017-07-29 01:38:46,675 Epoch[40] Batch [920]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.092957,	
2017-07-29 01:38:54,027 Epoch[40] Batch [930]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.092904,	
2017-07-29 01:39:01,317 Epoch[40] Batch [940]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.092795,	
2017-07-29 01:39:08,825 Epoch[40] Batch [950]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.092715,	
2017-07-29 01:39:16,810 Epoch[40] Batch [960]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.092698,	
2017-07-29 01:39:24,430 Epoch[40] Batch [970]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.092612,	
2017-07-29 01:39:31,905 Epoch[40] Batch [980]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.092543,	
2017-07-29 01:39:39,435 Epoch[40] Batch [990]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.092592,	
2017-07-29 01:39:47,192 Epoch[40] Batch [1000]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.092654,	
2017-07-29 01:39:55,043 Epoch[40] Batch [1010]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.092600,	
2017-07-29 01:40:02,869 Epoch[40] Batch [1020]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.092602,	
2017-07-29 01:40:10,480 Epoch[40] Batch [1030]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.092570,	
2017-07-29 01:40:18,018 Epoch[40] Batch [1040]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.092599,	
2017-07-29 01:40:26,081 Epoch[40] Batch [1050]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.092601,	
2017-07-29 01:40:34,324 Epoch[40] Batch [1060]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.092711,	
2017-07-29 01:40:42,289 Epoch[40] Batch [1070]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.092692,	
2017-07-29 01:40:49,887 Epoch[40] Batch [1080]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.092674,	
2017-07-29 01:40:56,959 Epoch[40] Batch [1090]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.092659,	
2017-07-29 01:41:04,461 Epoch[40] Batch [1100]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.092732,	
2017-07-29 01:41:12,222 Epoch[40] Batch [1110]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.092685,	
2017-07-29 01:41:19,774 Epoch[40] Batch [1120]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.092677,	
2017-07-29 01:41:27,223 Epoch[40] Batch [1130]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092723,	
2017-07-29 01:41:34,520 Epoch[40] Batch [1140]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.092658,	
2017-07-29 01:41:41,678 Epoch[40] Batch [1150]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.092590,	
2017-07-29 01:41:49,456 Epoch[40] Batch [1160]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.092548,	
2017-07-29 01:41:56,997 Epoch[40] Batch [1170]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.092515,	
2017-07-29 01:42:04,264 Epoch[40] Batch [1180]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.092514,	
2017-07-29 01:42:12,168 Epoch[40] Batch [1190]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.092501,	
2017-07-29 01:42:19,811 Epoch[40] Batch [1200]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.092547,	
2017-07-29 01:42:27,463 Epoch[40] Batch [1210]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.092443,	
2017-07-29 01:42:35,089 Epoch[40] Batch [1220]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.092453,	
2017-07-29 01:42:42,334 Epoch[40] Batch [1230]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.092354,	
2017-07-29 01:42:49,846 Epoch[40] Batch [1240]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.092298,	
2017-07-29 01:42:57,532 Epoch[40] Batch [1250]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.092338,	
2017-07-29 01:43:04,873 Epoch[40] Batch [1260]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.092302,	
2017-07-29 01:43:12,354 Epoch[40] Batch [1270]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.092286,	
2017-07-29 01:43:19,406 Epoch[40] Batch [1280]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.092256,	
2017-07-29 01:43:26,854 Epoch[40] Batch [1290]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.092154,	
2017-07-29 01:43:34,565 Epoch[40] Batch [1300]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.092192,	
2017-07-29 01:43:42,071 Epoch[40] Batch [1310]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.092166,	
2017-07-29 01:43:49,936 Epoch[40] Batch [1320]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.092133,	
2017-07-29 01:43:57,365 Epoch[40] Batch [1330]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.092178,	
2017-07-29 01:44:04,704 Epoch[40] Batch [1340]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.092166,	
2017-07-29 01:44:12,126 Epoch[40] Batch [1350]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.092188,	
2017-07-29 01:44:19,486 Epoch[40] Batch [1360]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.092162,	
2017-07-29 01:44:27,460 Epoch[40] Batch [1370]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.092162,	
2017-07-29 01:44:34,868 Epoch[40] Batch [1380]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.092171,	
2017-07-29 01:44:42,288 Epoch[40] Batch [1390]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.092126,	
2017-07-29 01:44:49,561 Epoch[40] Batch [1400]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.092050,	
2017-07-29 01:44:57,318 Epoch[40] Batch [1410]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.092034,	
2017-07-29 01:45:05,516 Epoch[40] Batch [1420]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.091970,	
2017-07-29 01:45:13,246 Epoch[40] Batch [1430]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.092001,	
2017-07-29 01:45:20,704 Epoch[40] Batch [1440]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.092032,	
2017-07-29 01:45:28,043 Epoch[40] Batch [1450]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.091942,	
2017-07-29 01:45:36,419 Epoch[40] Batch [1460]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.091851,	
2017-07-29 01:45:44,456 Epoch[40] Batch [1470]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.091885,	
2017-07-29 01:45:52,553 Epoch[40] Batch [1480]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.091850,	
2017-07-29 01:45:57,129 Epoch[40] Train-FCNLogLoss=0.091896
2017-07-29 01:45:57,129 Epoch[40] Time cost=1156.752
2017-07-29 01:45:58,238 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0041.params"
2017-07-29 01:46:02,135 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0041.states"
2017-07-29 01:46:10,543 Epoch[41] Batch [10]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.088028,	
2017-07-29 01:46:17,804 Epoch[41] Batch [20]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.088508,	
2017-07-29 01:46:25,491 Epoch[41] Batch [30]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089136,	
2017-07-29 01:46:33,216 Epoch[41] Batch [40]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.087899,	
2017-07-29 01:46:41,084 Epoch[41] Batch [50]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.086908,	
2017-07-29 01:46:48,745 Epoch[41] Batch [60]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.088035,	
2017-07-29 01:46:56,395 Epoch[41] Batch [70]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.087573,	
2017-07-29 01:47:04,171 Epoch[41] Batch [80]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.088287,	
2017-07-29 01:47:11,711 Epoch[41] Batch [90]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.087337,	
2017-07-29 01:47:19,384 Epoch[41] Batch [100]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.087536,	
2017-07-29 01:47:27,277 Epoch[41] Batch [110]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.089957,	
2017-07-29 01:47:35,046 Epoch[41] Batch [120]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089724,	
2017-07-29 01:47:42,937 Epoch[41] Batch [130]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.089406,	
2017-07-29 01:47:50,706 Epoch[41] Batch [140]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089679,	
2017-07-29 01:47:58,247 Epoch[41] Batch [150]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.090131,	
2017-07-29 01:48:05,865 Epoch[41] Batch [160]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.089902,	
2017-07-29 01:48:13,688 Epoch[41] Batch [170]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089500,	
2017-07-29 01:48:21,434 Epoch[41] Batch [180]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089888,	
2017-07-29 01:48:29,397 Epoch[41] Batch [190]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089269,	
2017-07-29 01:48:36,890 Epoch[41] Batch [200]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.089324,	
2017-07-29 01:48:44,472 Epoch[41] Batch [210]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.089511,	
2017-07-29 01:48:52,286 Epoch[41] Batch [220]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.089428,	
2017-07-29 01:49:01,027 Epoch[41] Batch [230]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.089567,	
2017-07-29 01:49:09,161 Epoch[41] Batch [240]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.089639,	
2017-07-29 01:49:16,870 Epoch[41] Batch [250]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089442,	
2017-07-29 01:49:24,715 Epoch[41] Batch [260]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.089539,	
2017-07-29 01:49:32,431 Epoch[41] Batch [270]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.089722,	
2017-07-29 01:49:40,092 Epoch[41] Batch [280]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.089805,	
2017-07-29 01:49:48,199 Epoch[41] Batch [290]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089445,	
2017-07-29 01:49:55,941 Epoch[41] Batch [300]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.089273,	
2017-07-29 01:50:04,003 Epoch[41] Batch [310]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.089244,	
2017-07-29 01:50:12,034 Epoch[41] Batch [320]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.089466,	
2017-07-29 01:50:19,957 Epoch[41] Batch [330]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.089610,	
2017-07-29 01:50:27,950 Epoch[41] Batch [340]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.089608,	
2017-07-29 01:50:35,887 Epoch[41] Batch [350]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.089386,	
2017-07-29 01:50:43,612 Epoch[41] Batch [360]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.089497,	
2017-07-29 01:50:51,647 Epoch[41] Batch [370]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.089369,	
2017-07-29 01:50:59,314 Epoch[41] Batch [380]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.089576,	
2017-07-29 01:51:07,319 Epoch[41] Batch [390]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089736,	
2017-07-29 01:51:15,400 Epoch[41] Batch [400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.089720,	
2017-07-29 01:51:23,555 Epoch[41] Batch [410]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.089503,	
2017-07-29 01:51:31,587 Epoch[41] Batch [420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.089608,	
2017-07-29 01:51:39,358 Epoch[41] Batch [430]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089680,	
2017-07-29 01:51:47,334 Epoch[41] Batch [440]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089464,	
2017-07-29 01:51:55,387 Epoch[41] Batch [450]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.089598,	
2017-07-29 01:52:03,215 Epoch[41] Batch [460]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089619,	
2017-07-29 01:52:11,415 Epoch[41] Batch [470]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.089584,	
2017-07-29 01:52:19,415 Epoch[41] Batch [480]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089652,	
2017-07-29 01:52:27,683 Epoch[41] Batch [490]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.089630,	
2017-07-29 01:52:35,796 Epoch[41] Batch [500]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089607,	
2017-07-29 01:52:43,661 Epoch[41] Batch [510]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.089460,	
2017-07-29 01:52:51,608 Epoch[41] Batch [520]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.089396,	
2017-07-29 01:52:59,290 Epoch[41] Batch [530]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.089217,	
2017-07-29 01:53:06,947 Epoch[41] Batch [540]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.089282,	
2017-07-29 01:53:14,732 Epoch[41] Batch [550]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089414,	
2017-07-29 01:53:22,426 Epoch[41] Batch [560]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089338,	
2017-07-29 01:53:30,791 Epoch[41] Batch [570]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.089496,	
2017-07-29 01:53:38,666 Epoch[41] Batch [580]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.089368,	
2017-07-29 01:53:46,848 Epoch[41] Batch [590]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.089492,	
2017-07-29 01:53:54,871 Epoch[41] Batch [600]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.089492,	
2017-07-29 01:54:02,703 Epoch[41] Batch [610]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089609,	
2017-07-29 01:54:10,517 Epoch[41] Batch [620]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.089538,	
2017-07-29 01:54:18,413 Epoch[41] Batch [630]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.089360,	
2017-07-29 01:54:26,387 Epoch[41] Batch [640]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089372,	
2017-07-29 01:54:34,761 Epoch[41] Batch [650]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.089293,	
2017-07-29 01:54:43,301 Epoch[41] Batch [660]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.089237,	
2017-07-29 01:54:51,731 Epoch[41] Batch [670]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.089158,	
2017-07-29 01:54:59,927 Epoch[41] Batch [680]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.089186,	
2017-07-29 01:55:07,900 Epoch[41] Batch [690]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089174,	
2017-07-29 01:55:15,923 Epoch[41] Batch [700]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.089163,	
2017-07-29 01:55:24,232 Epoch[41] Batch [710]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.089187,	
2017-07-29 01:55:32,575 Epoch[41] Batch [720]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.089098,	
2017-07-29 01:55:40,697 Epoch[41] Batch [730]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089068,	
2017-07-29 01:55:49,141 Epoch[41] Batch [740]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.089045,	
2017-07-29 01:55:56,762 Epoch[41] Batch [750]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.088967,	
2017-07-29 01:56:04,540 Epoch[41] Batch [760]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.088865,	
2017-07-29 01:56:12,261 Epoch[41] Batch [770]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.088901,	
2017-07-29 01:56:20,109 Epoch[41] Batch [780]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.088797,	
2017-07-29 01:56:27,508 Epoch[41] Batch [790]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.088965,	
2017-07-29 01:56:35,348 Epoch[41] Batch [800]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.089008,	
2017-07-29 01:56:43,017 Epoch[41] Batch [810]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.088920,	
2017-07-29 01:56:50,711 Epoch[41] Batch [820]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.088868,	
2017-07-29 01:56:58,477 Epoch[41] Batch [830]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088881,	
2017-07-29 01:57:06,414 Epoch[41] Batch [840]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.088898,	
2017-07-29 01:57:14,784 Epoch[41] Batch [850]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.088953,	
2017-07-29 01:57:22,688 Epoch[41] Batch [860]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.088887,	
2017-07-29 01:57:30,430 Epoch[41] Batch [870]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.089004,	
2017-07-29 01:57:38,112 Epoch[41] Batch [880]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.089057,	
2017-07-29 01:57:45,764 Epoch[41] Batch [890]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.089086,	
2017-07-29 01:57:53,406 Epoch[41] Batch [900]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.089099,	
2017-07-29 01:58:01,240 Epoch[41] Batch [910]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089038,	
2017-07-29 01:58:08,928 Epoch[41] Batch [920]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089044,	
2017-07-29 01:58:16,635 Epoch[41] Batch [930]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089066,	
2017-07-29 01:58:24,483 Epoch[41] Batch [940]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.089111,	
2017-07-29 01:58:32,079 Epoch[41] Batch [950]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.089143,	
2017-07-29 01:58:39,653 Epoch[41] Batch [960]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.089195,	
2017-07-29 01:58:47,408 Epoch[41] Batch [970]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089315,	
2017-07-29 01:58:55,201 Epoch[41] Batch [980]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089318,	
2017-07-29 01:59:03,004 Epoch[41] Batch [990]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089282,	
2017-07-29 01:59:10,861 Epoch[41] Batch [1000]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.089368,	
2017-07-29 01:59:18,644 Epoch[41] Batch [1010]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089407,	
2017-07-29 01:59:26,523 Epoch[41] Batch [1020]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.089318,	
2017-07-29 01:59:34,363 Epoch[41] Batch [1030]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.089313,	
2017-07-29 01:59:42,526 Epoch[41] Batch [1040]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.089253,	
2017-07-29 01:59:50,599 Epoch[41] Batch [1050]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.089249,	
2017-07-29 01:59:58,596 Epoch[41] Batch [1060]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089236,	
2017-07-29 02:00:06,568 Epoch[41] Batch [1070]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089263,	
2017-07-29 02:00:14,367 Epoch[41] Batch [1080]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089285,	
2017-07-29 02:00:22,143 Epoch[41] Batch [1090]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089213,	
2017-07-29 02:00:30,044 Epoch[41] Batch [1100]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.089228,	
2017-07-29 02:00:37,812 Epoch[41] Batch [1110]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089260,	
2017-07-29 02:00:45,601 Epoch[41] Batch [1120]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089314,	
2017-07-29 02:00:53,591 Epoch[41] Batch [1130]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.089315,	
2017-07-29 02:01:01,776 Epoch[41] Batch [1140]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.089355,	
2017-07-29 02:01:09,891 Epoch[41] Batch [1150]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089455,	
2017-07-29 02:01:17,368 Epoch[41] Batch [1160]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.089458,	
2017-07-29 02:01:25,317 Epoch[41] Batch [1170]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.089446,	
2017-07-29 02:01:33,102 Epoch[41] Batch [1180]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089383,	
2017-07-29 02:01:41,419 Epoch[41] Batch [1190]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.089352,	
2017-07-29 02:01:49,218 Epoch[41] Batch [1200]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089305,	
2017-07-29 02:01:57,442 Epoch[41] Batch [1210]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.089300,	
2017-07-29 02:02:05,093 Epoch[41] Batch [1220]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.089361,	
2017-07-29 02:02:13,056 Epoch[41] Batch [1230]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089279,	
2017-07-29 02:02:21,094 Epoch[41] Batch [1240]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.089234,	
2017-07-29 02:02:28,736 Epoch[41] Batch [1250]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.089149,	
2017-07-29 02:02:36,685 Epoch[41] Batch [1260]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.089067,	
2017-07-29 02:02:44,395 Epoch[41] Batch [1270]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089093,	
2017-07-29 02:02:52,164 Epoch[41] Batch [1280]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089049,	
2017-07-29 02:02:59,850 Epoch[41] Batch [1290]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089043,	
2017-07-29 02:03:07,529 Epoch[41] Batch [1300]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.089050,	
2017-07-29 02:03:15,363 Epoch[41] Batch [1310]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089154,	
2017-07-29 02:03:22,970 Epoch[41] Batch [1320]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.089149,	
2017-07-29 02:03:30,686 Epoch[41] Batch [1330]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.089073,	
2017-07-29 02:03:38,958 Epoch[41] Batch [1340]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.089080,	
2017-07-29 02:03:46,751 Epoch[41] Batch [1350]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089110,	
2017-07-29 02:03:54,788 Epoch[41] Batch [1360]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.089027,	
2017-07-29 02:04:02,909 Epoch[41] Batch [1370]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089090,	
2017-07-29 02:04:10,408 Epoch[41] Batch [1380]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.089058,	
2017-07-29 02:04:18,306 Epoch[41] Batch [1390]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.089057,	
2017-07-29 02:04:26,078 Epoch[41] Batch [1400]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089106,	
2017-07-29 02:04:34,169 Epoch[41] Batch [1410]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.089119,	
2017-07-29 02:04:41,946 Epoch[41] Batch [1420]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089089,	
2017-07-29 02:04:49,686 Epoch[41] Batch [1430]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.089131,	
2017-07-29 02:04:57,391 Epoch[41] Batch [1440]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089117,	
2017-07-29 02:05:05,111 Epoch[41] Batch [1450]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.089093,	
2017-07-29 02:05:13,485 Epoch[41] Batch [1460]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.089038,	
2017-07-29 02:05:21,312 Epoch[41] Batch [1470]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089021,	
2017-07-29 02:05:29,057 Epoch[41] Batch [1480]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089020,	
2017-07-29 02:05:33,546 Epoch[41] Train-FCNLogLoss=0.088971
2017-07-29 02:05:33,546 Epoch[41] Time cost=1171.410
2017-07-29 02:05:34,773 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0042.params"
2017-07-29 02:05:38,545 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0042.states"
2017-07-29 02:05:47,545 Epoch[42] Batch [10]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.081225,	
2017-07-29 02:05:55,376 Epoch[42] Batch [20]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.088384,	
2017-07-29 02:06:03,395 Epoch[42] Batch [30]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.093402,	
2017-07-29 02:06:11,127 Epoch[42] Batch [40]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.089998,	
2017-07-29 02:06:18,816 Epoch[42] Batch [50]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.090316,	
2017-07-29 02:06:26,469 Epoch[42] Batch [60]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.091528,	
2017-07-29 02:06:34,080 Epoch[42] Batch [70]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.091300,	
2017-07-29 02:06:41,857 Epoch[42] Batch [80]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.090916,	
2017-07-29 02:06:49,551 Epoch[42] Batch [90]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089996,	
2017-07-29 02:06:57,254 Epoch[42] Batch [100]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.091265,	
2017-07-29 02:07:04,771 Epoch[42] Batch [110]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.091231,	
2017-07-29 02:07:12,575 Epoch[42] Batch [120]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.091092,	
2017-07-29 02:07:20,274 Epoch[42] Batch [130]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.090617,	
2017-07-29 02:07:27,685 Epoch[42] Batch [140]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.090867,	
2017-07-29 02:07:35,470 Epoch[42] Batch [150]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.090636,	
2017-07-29 02:07:43,188 Epoch[42] Batch [160]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.090274,	
2017-07-29 02:07:51,052 Epoch[42] Batch [170]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.090078,	
2017-07-29 02:07:58,810 Epoch[42] Batch [180]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.090008,	
2017-07-29 02:08:06,273 Epoch[42] Batch [190]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.089853,	
2017-07-29 02:08:13,849 Epoch[42] Batch [200]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.089991,	
2017-07-29 02:08:21,349 Epoch[42] Batch [210]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.089648,	
2017-07-29 02:08:28,998 Epoch[42] Batch [220]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.089719,	
2017-07-29 02:08:36,858 Epoch[42] Batch [230]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.089333,	
2017-07-29 02:08:44,409 Epoch[42] Batch [240]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.089332,	
2017-07-29 02:08:52,166 Epoch[42] Batch [250]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089255,	
2017-07-29 02:09:00,053 Epoch[42] Batch [260]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.089538,	
2017-07-29 02:09:07,583 Epoch[42] Batch [270]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.089263,	
2017-07-29 02:09:15,336 Epoch[42] Batch [280]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089096,	
2017-07-29 02:09:23,143 Epoch[42] Batch [290]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.088827,	
2017-07-29 02:09:31,073 Epoch[42] Batch [300]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.089158,	
2017-07-29 02:09:38,967 Epoch[42] Batch [310]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.088736,	
2017-07-29 02:09:46,504 Epoch[42] Batch [320]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.088481,	
2017-07-29 02:09:54,281 Epoch[42] Batch [330]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.088774,	
2017-07-29 02:10:01,805 Epoch[42] Batch [340]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.089075,	
2017-07-29 02:10:09,815 Epoch[42] Batch [350]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.089049,	
2017-07-29 02:10:17,796 Epoch[42] Batch [360]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088909,	
2017-07-29 02:10:25,298 Epoch[42] Batch [370]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088875,	
2017-07-29 02:10:33,276 Epoch[42] Batch [380]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088951,	
2017-07-29 02:10:41,129 Epoch[42] Batch [390]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.088928,	
2017-07-29 02:10:48,884 Epoch[42] Batch [400]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089014,	
2017-07-29 02:10:56,632 Epoch[42] Batch [410]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089121,	
2017-07-29 02:11:04,417 Epoch[42] Batch [420]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089392,	
2017-07-29 02:11:12,349 Epoch[42] Batch [430]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.089435,	
2017-07-29 02:11:20,185 Epoch[42] Batch [440]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.089257,	
2017-07-29 02:11:27,963 Epoch[42] Batch [450]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089107,	
2017-07-29 02:11:35,653 Epoch[42] Batch [460]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089143,	
2017-07-29 02:11:43,409 Epoch[42] Batch [470]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089289,	
2017-07-29 02:11:51,205 Epoch[42] Batch [480]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089196,	
2017-07-29 02:11:58,892 Epoch[42] Batch [490]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.089079,	
2017-07-29 02:12:06,797 Epoch[42] Batch [500]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.089124,	
2017-07-29 02:12:15,011 Epoch[42] Batch [510]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.089096,	
2017-07-29 02:12:23,345 Epoch[42] Batch [520]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.089081,	
2017-07-29 02:12:31,814 Epoch[42] Batch [530]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.089076,	
2017-07-29 02:12:40,130 Epoch[42] Batch [540]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.088954,	
2017-07-29 02:12:48,494 Epoch[42] Batch [550]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.089105,	
2017-07-29 02:12:56,834 Epoch[42] Batch [560]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.089083,	
2017-07-29 02:13:05,357 Epoch[42] Batch [570]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.089129,	
2017-07-29 02:13:14,078 Epoch[42] Batch [580]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.088977,	
2017-07-29 02:13:22,944 Epoch[42] Batch [590]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.088978,	
2017-07-29 02:13:31,458 Epoch[42] Batch [600]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.088867,	
2017-07-29 02:13:39,894 Epoch[42] Batch [610]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.088817,	
2017-07-29 02:13:48,081 Epoch[42] Batch [620]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.088645,	
2017-07-29 02:13:55,852 Epoch[42] Batch [630]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088712,	
2017-07-29 02:14:03,249 Epoch[42] Batch [640]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.088709,	
2017-07-29 02:14:11,019 Epoch[42] Batch [650]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088756,	
2017-07-29 02:14:18,674 Epoch[42] Batch [660]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.088947,	
2017-07-29 02:14:26,385 Epoch[42] Batch [670]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.088832,	
2017-07-29 02:14:34,205 Epoch[42] Batch [680]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.088864,	
2017-07-29 02:14:41,846 Epoch[42] Batch [690]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.088983,	
2017-07-29 02:14:49,882 Epoch[42] Batch [700]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.089042,	
2017-07-29 02:14:58,005 Epoch[42] Batch [710]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.089168,	
2017-07-29 02:15:05,961 Epoch[42] Batch [720]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.089142,	
2017-07-29 02:15:14,214 Epoch[42] Batch [730]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.089030,	
2017-07-29 02:15:22,116 Epoch[42] Batch [740]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.089098,	
2017-07-29 02:15:30,121 Epoch[42] Batch [750]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089157,	
2017-07-29 02:15:38,175 Epoch[42] Batch [760]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.089329,	
2017-07-29 02:15:46,299 Epoch[42] Batch [770]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.089389,	
2017-07-29 02:15:54,244 Epoch[42] Batch [780]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.089342,	
2017-07-29 02:16:02,180 Epoch[42] Batch [790]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.089390,	
2017-07-29 02:16:09,817 Epoch[42] Batch [800]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.089421,	
2017-07-29 02:16:17,635 Epoch[42] Batch [810]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.089437,	
2017-07-29 02:16:26,883 Epoch[42] Batch [820]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.089447,	
2017-07-29 02:16:38,398 Epoch[42] Batch [830]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.089364,	
2017-07-29 02:16:48,979 Epoch[42] Batch [840]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.089321,	
2017-07-29 02:16:57,731 Epoch[42] Batch [850]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.089191,	
2017-07-29 02:17:06,241 Epoch[42] Batch [860]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.089117,	
2017-07-29 02:17:15,569 Epoch[42] Batch [870]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.089231,	
2017-07-29 02:17:24,096 Epoch[42] Batch [880]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.089236,	
2017-07-29 02:17:31,923 Epoch[42] Batch [890]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089175,	
2017-07-29 02:17:39,921 Epoch[42] Batch [900]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.089200,	
2017-07-29 02:17:47,911 Epoch[42] Batch [910]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.089116,	
2017-07-29 02:17:55,685 Epoch[42] Batch [920]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089152,	
2017-07-29 02:18:03,440 Epoch[42] Batch [930]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.089169,	
2017-07-29 02:18:11,176 Epoch[42] Batch [940]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.089037,	
2017-07-29 02:18:19,230 Epoch[42] Batch [950]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.088999,	
2017-07-29 02:18:27,124 Epoch[42] Batch [960]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.089050,	
2017-07-29 02:18:35,101 Epoch[42] Batch [970]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.089148,	
2017-07-29 02:18:42,906 Epoch[42] Batch [980]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.089108,	
2017-07-29 02:18:50,691 Epoch[42] Batch [990]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089143,	
2017-07-29 02:18:58,459 Epoch[42] Batch [1000]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.089152,	
2017-07-29 02:19:06,170 Epoch[42] Batch [1010]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089175,	
2017-07-29 02:19:14,006 Epoch[42] Batch [1020]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.089169,	
2017-07-29 02:19:21,925 Epoch[42] Batch [1030]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.089207,	
2017-07-29 02:19:29,836 Epoch[42] Batch [1040]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.089149,	
2017-07-29 02:19:37,902 Epoch[42] Batch [1050]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.089160,	
2017-07-29 02:19:45,532 Epoch[42] Batch [1060]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.089147,	
2017-07-29 02:19:53,239 Epoch[42] Batch [1070]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.089083,	
2017-07-29 02:20:01,084 Epoch[42] Batch [1080]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.089055,	
2017-07-29 02:20:08,944 Epoch[42] Batch [1090]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.089019,	
2017-07-29 02:20:16,765 Epoch[42] Batch [1100]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.088952,	
2017-07-29 02:20:24,444 Epoch[42] Batch [1110]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.088974,	
2017-07-29 02:20:32,206 Epoch[42] Batch [1120]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088925,	
2017-07-29 02:20:39,904 Epoch[42] Batch [1130]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088983,	
2017-07-29 02:20:47,682 Epoch[42] Batch [1140]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.089012,	
2017-07-29 02:20:55,248 Epoch[42] Batch [1150]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.088955,	
2017-07-29 02:21:02,957 Epoch[42] Batch [1160]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.088961,	
2017-07-29 02:21:10,804 Epoch[42] Batch [1170]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.088859,	
2017-07-29 02:21:18,590 Epoch[42] Batch [1180]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.088913,	
2017-07-29 02:21:26,560 Epoch[42] Batch [1190]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.088837,	
2017-07-29 02:21:34,463 Epoch[42] Batch [1200]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.088833,	
2017-07-29 02:21:42,280 Epoch[42] Batch [1210]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.088806,	
2017-07-29 02:21:50,225 Epoch[42] Batch [1220]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.088900,	
2017-07-29 02:21:58,319 Epoch[42] Batch [1230]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.088921,	
2017-07-29 02:22:06,214 Epoch[42] Batch [1240]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.088946,	
2017-07-29 02:22:14,157 Epoch[42] Batch [1250]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.088893,	
2017-07-29 02:22:22,499 Epoch[42] Batch [1260]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.088918,	
2017-07-29 02:22:32,425 Epoch[42] Batch [1270]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.088919,	
2017-07-29 02:22:41,313 Epoch[42] Batch [1280]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.088925,	
2017-07-29 02:22:50,407 Epoch[42] Batch [1290]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.088887,	
2017-07-29 02:23:00,774 Epoch[42] Batch [1300]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.088931,	
2017-07-29 02:23:12,361 Epoch[42] Batch [1310]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.088907,	
2017-07-29 02:23:22,302 Epoch[42] Batch [1320]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.088851,	
2017-07-29 02:23:32,390 Epoch[42] Batch [1330]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.088837,	
2017-07-29 02:23:41,617 Epoch[42] Batch [1340]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.088861,	
2017-07-29 02:23:51,176 Epoch[42] Batch [1350]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.088961,	
2017-07-29 02:24:03,160 Epoch[42] Batch [1360]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.088980,	
2017-07-29 02:24:16,075 Epoch[42] Batch [1370]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.088964,	
2017-07-29 02:24:26,332 Epoch[42] Batch [1380]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.088919,	
2017-07-29 02:24:37,860 Epoch[42] Batch [1390]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.088962,	
2017-07-29 02:24:49,494 Epoch[42] Batch [1400]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.089005,	
2017-07-29 02:25:01,113 Epoch[42] Batch [1410]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.089006,	
2017-07-29 02:25:13,096 Epoch[42] Batch [1420]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.089018,	
2017-07-29 02:25:26,210 Epoch[42] Batch [1430]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.089020,	
2017-07-29 02:25:38,798 Epoch[42] Batch [1440]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.088991,	
2017-07-29 02:25:48,335 Epoch[42] Batch [1450]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.088956,	
2017-07-29 02:25:59,334 Epoch[42] Batch [1460]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.089021,	
2017-07-29 02:26:10,880 Epoch[42] Batch [1470]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.088999,	
2017-07-29 02:26:20,375 Epoch[42] Batch [1480]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.089005,	
2017-07-29 02:26:25,515 Epoch[42] Train-FCNLogLoss=0.089003
2017-07-29 02:26:25,515 Epoch[42] Time cost=1246.970
2017-07-29 02:26:26,577 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0043.params"
2017-07-29 02:26:30,231 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0043.states"
2017-07-29 02:26:39,820 Epoch[43] Batch [10]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.086631,	
2017-07-29 02:26:48,124 Epoch[43] Batch [20]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.092417,	
2017-07-29 02:26:57,795 Epoch[43] Batch [30]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.092004,	
2017-07-29 02:27:09,461 Epoch[43] Batch [40]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.090652,	
2017-07-29 02:27:21,526 Epoch[43] Batch [50]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.089832,	
2017-07-29 02:27:33,354 Epoch[43] Batch [60]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.089651,	
2017-07-29 02:27:47,128 Epoch[43] Batch [70]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.088705,	
2017-07-29 02:27:57,511 Epoch[43] Batch [80]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.089355,	
2017-07-29 02:28:10,130 Epoch[43] Batch [90]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.091255,	
2017-07-29 02:28:20,151 Epoch[43] Batch [100]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.091040,	
2017-07-29 02:28:30,024 Epoch[43] Batch [110]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.091104,	
2017-07-29 02:28:42,861 Epoch[43] Batch [120]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.091144,	
2017-07-29 02:28:54,883 Epoch[43] Batch [130]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.090656,	
2017-07-29 02:29:05,778 Epoch[43] Batch [140]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.090227,	
2017-07-29 02:29:15,736 Epoch[43] Batch [150]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.089296,	
2017-07-29 02:29:27,548 Epoch[43] Batch [160]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.088586,	
2017-07-29 02:29:40,644 Epoch[43] Batch [170]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.088646,	
2017-07-29 02:29:48,682 Epoch[43] Batch [180]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.088688,	
2017-07-29 02:29:58,029 Epoch[43] Batch [190]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.089217,	
2017-07-29 02:30:07,224 Epoch[43] Batch [200]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.089145,	
2017-07-29 02:30:16,223 Epoch[43] Batch [210]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.089075,	
2017-07-29 02:30:24,119 Epoch[43] Batch [220]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.089029,	
2017-07-29 02:30:33,522 Epoch[43] Batch [230]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.088525,	
2017-07-29 02:30:41,749 Epoch[43] Batch [240]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088739,	
2017-07-29 02:30:49,700 Epoch[43] Batch [250]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.088699,	
2017-07-29 02:30:57,984 Epoch[43] Batch [260]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.088577,	
2017-07-29 02:31:08,158 Epoch[43] Batch [270]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.088568,	
2017-07-29 02:31:16,580 Epoch[43] Batch [280]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.088429,	
2017-07-29 02:31:26,997 Epoch[43] Batch [290]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.088066,	
2017-07-29 02:31:36,294 Epoch[43] Batch [300]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.087972,	
2017-07-29 02:31:48,063 Epoch[43] Batch [310]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.088119,	
2017-07-29 02:32:01,614 Epoch[43] Batch [320]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.088068,	
2017-07-29 02:32:11,803 Epoch[43] Batch [330]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.088065,	
2017-07-29 02:32:20,680 Epoch[43] Batch [340]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.088499,	
2017-07-29 02:32:31,687 Epoch[43] Batch [350]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.088636,	
2017-07-29 02:32:42,061 Epoch[43] Batch [360]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.088696,	
2017-07-29 02:32:55,621 Epoch[43] Batch [370]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.088715,	
2017-07-29 02:33:11,098 Epoch[43] Batch [380]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.088859,	
2017-07-29 02:33:26,793 Epoch[43] Batch [390]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.089028,	
2017-07-29 02:33:38,777 Epoch[43] Batch [400]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.089026,	
2017-07-29 02:33:49,741 Epoch[43] Batch [410]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.089029,	
2017-07-29 02:33:58,554 Epoch[43] Batch [420]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.088875,	
2017-07-29 02:34:06,668 Epoch[43] Batch [430]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088871,	
2017-07-29 02:34:16,142 Epoch[43] Batch [440]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.088858,	
2017-07-29 02:34:24,259 Epoch[43] Batch [450]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088598,	
2017-07-29 02:34:34,794 Epoch[43] Batch [460]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.088570,	
2017-07-29 02:34:45,311 Epoch[43] Batch [470]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.088683,	
2017-07-29 02:34:53,068 Epoch[43] Batch [480]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088578,	
2017-07-29 02:35:01,404 Epoch[43] Batch [490]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.088503,	
2017-07-29 02:35:10,261 Epoch[43] Batch [500]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.088440,	
2017-07-29 02:35:18,251 Epoch[43] Batch [510]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088501,	
2017-07-29 02:35:26,894 Epoch[43] Batch [520]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.088454,	
2017-07-29 02:35:35,579 Epoch[43] Batch [530]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.088448,	
2017-07-29 02:35:46,492 Epoch[43] Batch [540]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.088374,	
2017-07-29 02:35:56,421 Epoch[43] Batch [550]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.088368,	
2017-07-29 02:36:04,539 Epoch[43] Batch [560]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088339,	
2017-07-29 02:36:15,354 Epoch[43] Batch [570]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.088413,	
2017-07-29 02:36:24,815 Epoch[43] Batch [580]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.088556,	
2017-07-29 02:36:37,428 Epoch[43] Batch [590]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.088552,	
2017-07-29 02:36:47,182 Epoch[43] Batch [600]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.088555,	
2017-07-29 02:36:56,608 Epoch[43] Batch [610]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.088527,	
2017-07-29 02:37:06,674 Epoch[43] Batch [620]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.088756,	
2017-07-29 02:37:20,349 Epoch[43] Batch [630]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.088778,	
2017-07-29 02:37:32,690 Epoch[43] Batch [640]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.088783,	
2017-07-29 02:37:41,950 Epoch[43] Batch [650]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.088691,	
2017-07-29 02:37:53,420 Epoch[43] Batch [660]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.088508,	
2017-07-29 02:38:06,386 Epoch[43] Batch [670]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.088511,	
2017-07-29 02:38:16,676 Epoch[43] Batch [680]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.088416,	
2017-07-29 02:38:24,909 Epoch[43] Batch [690]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088354,	
2017-07-29 02:38:33,173 Epoch[43] Batch [700]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.088361,	
2017-07-29 02:38:42,148 Epoch[43] Batch [710]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.088418,	
2017-07-29 02:38:50,415 Epoch[43] Batch [720]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.088412,	
2017-07-29 02:38:58,702 Epoch[43] Batch [730]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.088477,	
2017-07-29 02:39:06,905 Epoch[43] Batch [740]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.088489,	
2017-07-29 02:39:15,329 Epoch[43] Batch [750]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.088422,	
2017-07-29 02:39:24,583 Epoch[43] Batch [760]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.088479,	
2017-07-29 02:39:33,793 Epoch[43] Batch [770]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.088473,	
2017-07-29 02:39:43,093 Epoch[43] Batch [780]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.088551,	
2017-07-29 02:39:53,619 Epoch[43] Batch [790]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.088432,	
2017-07-29 02:40:06,063 Epoch[43] Batch [800]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.088466,	
2017-07-29 02:40:16,726 Epoch[43] Batch [810]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.088420,	
2017-07-29 02:40:29,628 Epoch[43] Batch [820]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.088312,	
2017-07-29 02:40:42,576 Epoch[43] Batch [830]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.088403,	
2017-07-29 02:40:52,502 Epoch[43] Batch [840]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.088421,	
2017-07-29 02:41:02,466 Epoch[43] Batch [850]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.088398,	
2017-07-29 02:41:13,208 Epoch[43] Batch [860]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.088406,	
2017-07-29 02:41:22,731 Epoch[43] Batch [870]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.088374,	
2017-07-29 02:41:31,812 Epoch[43] Batch [880]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.088370,	
2017-07-29 02:41:42,961 Epoch[43] Batch [890]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.088358,	
2017-07-29 02:41:51,625 Epoch[43] Batch [900]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.088296,	
2017-07-29 02:42:03,465 Epoch[43] Batch [910]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.088395,	
2017-07-29 02:42:13,371 Epoch[43] Batch [920]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.088340,	
2017-07-29 02:42:22,550 Epoch[43] Batch [930]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.088241,	
2017-07-29 02:42:31,918 Epoch[43] Batch [940]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.088267,	
2017-07-29 02:42:39,623 Epoch[43] Batch [950]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.088279,	
2017-07-29 02:42:47,994 Epoch[43] Batch [960]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.088262,	
2017-07-29 02:42:57,026 Epoch[43] Batch [970]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.088347,	
2017-07-29 02:43:05,317 Epoch[43] Batch [980]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.088265,	
2017-07-29 02:43:14,008 Epoch[43] Batch [990]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.088322,	
2017-07-29 02:43:22,042 Epoch[43] Batch [1000]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.088336,	
2017-07-29 02:43:30,269 Epoch[43] Batch [1010]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088390,	
2017-07-29 02:43:39,384 Epoch[43] Batch [1020]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.088324,	
2017-07-29 02:43:47,993 Epoch[43] Batch [1030]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.088400,	
2017-07-29 02:43:57,567 Epoch[43] Batch [1040]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.088477,	
2017-07-29 02:44:07,819 Epoch[43] Batch [1050]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.088405,	
2017-07-29 02:44:17,008 Epoch[43] Batch [1060]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.088450,	
2017-07-29 02:44:26,689 Epoch[43] Batch [1070]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.088516,	
2017-07-29 02:44:38,329 Epoch[43] Batch [1080]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.088456,	
2017-07-29 02:44:48,466 Epoch[43] Batch [1090]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.088457,	
2017-07-29 02:44:58,971 Epoch[43] Batch [1100]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.088524,	
2017-07-29 02:45:09,192 Epoch[43] Batch [1110]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.088598,	
2017-07-29 02:45:20,635 Epoch[43] Batch [1120]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.088519,	
2017-07-29 02:45:32,114 Epoch[43] Batch [1130]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.088458,	
2017-07-29 02:45:43,212 Epoch[43] Batch [1140]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.088397,	
2017-07-29 02:45:53,124 Epoch[43] Batch [1150]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.088302,	
2017-07-29 02:46:03,218 Epoch[43] Batch [1160]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.088314,	
2017-07-29 02:46:14,062 Epoch[43] Batch [1170]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.088299,	
2017-07-29 02:46:26,399 Epoch[43] Batch [1180]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.088298,	
2017-07-29 02:46:34,953 Epoch[43] Batch [1190]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.088316,	
2017-07-29 02:46:44,844 Epoch[43] Batch [1200]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.088302,	
2017-07-29 02:46:52,881 Epoch[43] Batch [1210]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.088206,	
2017-07-29 02:47:01,640 Epoch[43] Batch [1220]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.088182,	
2017-07-29 02:47:09,331 Epoch[43] Batch [1230]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.088144,	
2017-07-29 02:47:17,564 Epoch[43] Batch [1240]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088037,	
2017-07-29 02:47:26,139 Epoch[43] Batch [1250]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.088063,	
2017-07-29 02:47:36,988 Epoch[43] Batch [1260]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.087984,	
2017-07-29 02:47:44,745 Epoch[43] Batch [1270]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.088005,	
2017-07-29 02:47:53,356 Epoch[43] Batch [1280]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.088002,	
2017-07-29 02:48:00,975 Epoch[43] Batch [1290]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.087962,	
2017-07-29 02:48:09,307 Epoch[43] Batch [1300]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.087980,	
2017-07-29 02:48:18,052 Epoch[43] Batch [1310]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.087946,	
2017-07-29 02:48:27,329 Epoch[43] Batch [1320]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.087973,	
2017-07-29 02:48:37,570 Epoch[43] Batch [1330]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.088116,	
2017-07-29 02:48:47,565 Epoch[43] Batch [1340]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.088142,	
2017-07-29 02:48:56,846 Epoch[43] Batch [1350]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.088162,	
2017-07-29 02:49:09,394 Epoch[43] Batch [1360]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.088122,	
2017-07-29 02:49:18,781 Epoch[43] Batch [1370]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.088164,	
2017-07-29 02:49:32,356 Epoch[43] Batch [1380]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.088141,	
2017-07-29 02:49:44,221 Epoch[43] Batch [1390]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.088139,	
2017-07-29 02:49:56,355 Epoch[43] Batch [1400]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.088202,	
2017-07-29 02:50:08,673 Epoch[43] Batch [1410]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.088220,	
2017-07-29 02:50:19,617 Epoch[43] Batch [1420]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.088203,	
2017-07-29 02:50:29,762 Epoch[43] Batch [1430]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.088248,	
2017-07-29 02:50:42,341 Epoch[43] Batch [1440]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.088203,	
2017-07-29 02:50:54,433 Epoch[43] Batch [1450]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.088255,	
2017-07-29 02:51:03,727 Epoch[43] Batch [1460]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.088252,	
2017-07-29 02:51:11,613 Epoch[43] Batch [1470]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.088202,	
2017-07-29 02:51:21,622 Epoch[43] Batch [1480]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.088282,	
2017-07-29 02:51:26,306 Epoch[43] Train-FCNLogLoss=0.088306
2017-07-29 02:51:26,306 Epoch[43] Time cost=1496.074
2017-07-29 02:51:27,430 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0044.params"
2017-07-29 02:51:31,248 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0044.states"
2017-07-29 02:51:40,097 Epoch[44] Batch [10]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.091418,	
2017-07-29 02:51:48,487 Epoch[44] Batch [20]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.085066,	
2017-07-29 02:51:56,494 Epoch[44] Batch [30]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.088038,	
2017-07-29 02:52:05,613 Epoch[44] Batch [40]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.088273,	
2017-07-29 02:52:14,452 Epoch[44] Batch [50]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.088399,	
2017-07-29 02:52:22,845 Epoch[44] Batch [60]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.087958,	
2017-07-29 02:52:31,467 Epoch[44] Batch [70]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.087344,	
2017-07-29 02:52:40,880 Epoch[44] Batch [80]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.085894,	
2017-07-29 02:52:56,334 Epoch[44] Batch [90]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.086385,	
2017-07-29 02:53:06,893 Epoch[44] Batch [100]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.086690,	
2017-07-29 02:53:18,491 Epoch[44] Batch [110]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.086240,	
2017-07-29 02:53:30,359 Epoch[44] Batch [120]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.086601,	
2017-07-29 02:53:43,070 Epoch[44] Batch [130]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.086868,	
2017-07-29 02:53:53,835 Epoch[44] Batch [140]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.086972,	
2017-07-29 02:54:04,499 Epoch[44] Batch [150]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.086795,	
2017-07-29 02:54:19,246 Epoch[44] Batch [160]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.086710,	
2017-07-29 02:54:36,108 Epoch[44] Batch [170]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.086955,	
2017-07-29 02:54:47,612 Epoch[44] Batch [180]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.086805,	
2017-07-29 02:55:00,259 Epoch[44] Batch [190]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.086989,	
2017-07-29 02:55:11,436 Epoch[44] Batch [200]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.087074,	
2017-07-29 02:55:22,266 Epoch[44] Batch [210]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.086761,	
2017-07-29 02:55:32,271 Epoch[44] Batch [220]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.087006,	
2017-07-29 02:55:43,234 Epoch[44] Batch [230]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.087224,	
2017-07-29 02:55:52,786 Epoch[44] Batch [240]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.087618,	
2017-07-29 02:56:04,827 Epoch[44] Batch [250]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.087677,	
2017-07-29 02:56:14,051 Epoch[44] Batch [260]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.087514,	
2017-07-29 02:56:22,990 Epoch[44] Batch [270]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.087794,	
2017-07-29 02:56:33,117 Epoch[44] Batch [280]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.087810,	
2017-07-29 02:56:42,642 Epoch[44] Batch [290]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.087627,	
2017-07-29 02:56:50,839 Epoch[44] Batch [300]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.087799,	
2017-07-29 02:57:01,665 Epoch[44] Batch [310]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.087489,	
2017-07-29 02:57:12,203 Epoch[44] Batch [320]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.087677,	
2017-07-29 02:57:21,681 Epoch[44] Batch [330]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.087648,	
2017-07-29 02:57:32,137 Epoch[44] Batch [340]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.087436,	
2017-07-29 02:57:41,922 Epoch[44] Batch [350]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.087805,	
2017-07-29 02:57:53,969 Epoch[44] Batch [360]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.087823,	
2017-07-29 02:58:04,531 Epoch[44] Batch [370]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.087846,	
2017-07-29 02:58:13,861 Epoch[44] Batch [380]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.087820,	
2017-07-29 02:58:28,666 Epoch[44] Batch [390]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.087898,	
2017-07-29 02:58:39,966 Epoch[44] Batch [400]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.088053,	
2017-07-29 02:58:51,017 Epoch[44] Batch [410]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.088169,	
2017-07-29 02:59:01,846 Epoch[44] Batch [420]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.088164,	
2017-07-29 02:59:14,155 Epoch[44] Batch [430]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.088248,	
2017-07-29 02:59:24,849 Epoch[44] Batch [440]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.088311,	
2017-07-29 02:59:34,600 Epoch[44] Batch [450]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.088079,	
2017-07-29 02:59:42,667 Epoch[44] Batch [460]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.088243,	
2017-07-29 02:59:50,620 Epoch[44] Batch [470]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.088408,	
2017-07-29 02:59:59,528 Epoch[44] Batch [480]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.088515,	
2017-07-29 03:00:09,110 Epoch[44] Batch [490]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.088504,	
2017-07-29 03:00:17,746 Epoch[44] Batch [500]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.088436,	
2017-07-29 03:00:25,367 Epoch[44] Batch [510]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.088452,	
2017-07-29 03:00:34,590 Epoch[44] Batch [520]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.088246,	
2017-07-29 03:00:42,572 Epoch[44] Batch [530]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088182,	
2017-07-29 03:00:51,896 Epoch[44] Batch [540]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.088122,	
2017-07-29 03:01:00,074 Epoch[44] Batch [550]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.087977,	
2017-07-29 03:01:11,845 Epoch[44] Batch [560]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.088051,	
2017-07-29 03:01:24,763 Epoch[44] Batch [570]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.088041,	
2017-07-29 03:01:40,000 Epoch[44] Batch [580]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.087900,	
2017-07-29 03:01:51,024 Epoch[44] Batch [590]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.087912,	
2017-07-29 03:02:00,281 Epoch[44] Batch [600]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.088010,	
2017-07-29 03:02:10,188 Epoch[44] Batch [610]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.087962,	
2017-07-29 03:02:21,233 Epoch[44] Batch [620]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.088048,	
2017-07-29 03:02:33,582 Epoch[44] Batch [630]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.087998,	
2017-07-29 03:02:46,253 Epoch[44] Batch [640]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.088144,	
2017-07-29 03:02:56,636 Epoch[44] Batch [650]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.088205,	
2017-07-29 03:03:09,588 Epoch[44] Batch [660]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.088343,	
2017-07-29 03:03:18,074 Epoch[44] Batch [670]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.088349,	
2017-07-29 03:03:27,590 Epoch[44] Batch [680]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.088343,	
2017-07-29 03:03:39,676 Epoch[44] Batch [690]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.088329,	
2017-07-29 03:03:49,958 Epoch[44] Batch [700]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.088387,	
2017-07-29 03:03:57,966 Epoch[44] Batch [710]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.088393,	
2017-07-29 03:04:06,644 Epoch[44] Batch [720]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.088395,	
2017-07-29 03:04:14,379 Epoch[44] Batch [730]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.088265,	
2017-07-29 03:04:22,603 Epoch[44] Batch [740]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.088264,	
2017-07-29 03:04:32,254 Epoch[44] Batch [750]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.088172,	
2017-07-29 03:04:42,748 Epoch[44] Batch [760]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.088322,	
2017-07-29 03:04:51,513 Epoch[44] Batch [770]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.088369,	
2017-07-29 03:05:00,209 Epoch[44] Batch [780]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.088465,	
2017-07-29 03:05:08,053 Epoch[44] Batch [790]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.088584,	
2017-07-29 03:05:16,165 Epoch[44] Batch [800]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.088474,	
2017-07-29 03:05:24,698 Epoch[44] Batch [810]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.088387,	
2017-07-29 03:05:35,206 Epoch[44] Batch [820]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.088370,	
2017-07-29 03:05:46,759 Epoch[44] Batch [830]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.088300,	
2017-07-29 03:05:57,868 Epoch[44] Batch [840]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.088280,	
2017-07-29 03:06:09,129 Epoch[44] Batch [850]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.088266,	
2017-07-29 03:06:18,554 Epoch[44] Batch [860]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.088260,	
2017-07-29 03:06:30,070 Epoch[44] Batch [870]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.088357,	
2017-07-29 03:06:40,196 Epoch[44] Batch [880]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.088495,	
2017-07-29 03:06:50,844 Epoch[44] Batch [890]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.088441,	
2017-07-29 03:07:01,737 Epoch[44] Batch [900]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.088393,	
2017-07-29 03:07:11,452 Epoch[44] Batch [910]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.088289,	
2017-07-29 03:07:22,771 Epoch[44] Batch [920]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.088197,	
2017-07-29 03:07:33,854 Epoch[44] Batch [930]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.088166,	
2017-07-29 03:07:43,055 Epoch[44] Batch [940]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.088137,	
2017-07-29 03:07:52,903 Epoch[44] Batch [950]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.088120,	
2017-07-29 03:08:03,293 Epoch[44] Batch [960]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.088361,	
2017-07-29 03:08:11,987 Epoch[44] Batch [970]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.088369,	
2017-07-29 03:08:19,781 Epoch[44] Batch [980]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.088425,	
2017-07-29 03:08:27,960 Epoch[44] Batch [990]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.088352,	
2017-07-29 03:08:37,137 Epoch[44] Batch [1000]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.088325,	
2017-07-29 03:08:45,611 Epoch[44] Batch [1010]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.088297,	
2017-07-29 03:08:56,594 Epoch[44] Batch [1020]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.088242,	
2017-07-29 03:09:04,788 Epoch[44] Batch [1030]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.088275,	
2017-07-29 03:09:14,366 Epoch[44] Batch [1040]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.088434,	
2017-07-29 03:09:24,603 Epoch[44] Batch [1050]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.088433,	
2017-07-29 03:09:33,191 Epoch[44] Batch [1060]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.088507,	
2017-07-29 03:09:41,514 Epoch[44] Batch [1070]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.088561,	
2017-07-29 03:09:51,215 Epoch[44] Batch [1080]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.088631,	
2017-07-29 03:10:04,790 Epoch[44] Batch [1090]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.088610,	
2017-07-29 03:10:15,276 Epoch[44] Batch [1100]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.088654,	
2017-07-29 03:10:25,351 Epoch[44] Batch [1110]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.088624,	
2017-07-29 03:10:38,698 Epoch[44] Batch [1120]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.088652,	
2017-07-29 03:10:49,917 Epoch[44] Batch [1130]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.088650,	
2017-07-29 03:11:02,517 Epoch[44] Batch [1140]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.088561,	
2017-07-29 03:11:13,936 Epoch[44] Batch [1150]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.088524,	
2017-07-29 03:11:25,460 Epoch[44] Batch [1160]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.088541,	
2017-07-29 03:11:35,895 Epoch[44] Batch [1170]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.088507,	
2017-07-29 03:11:48,595 Epoch[44] Batch [1180]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.088539,	
2017-07-29 03:11:59,065 Epoch[44] Batch [1190]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.088526,	
2017-07-29 03:12:11,267 Epoch[44] Batch [1200]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.088405,	
2017-07-29 03:12:20,686 Epoch[44] Batch [1210]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.088425,	
2017-07-29 03:12:29,995 Epoch[44] Batch [1220]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.088444,	
2017-07-29 03:12:39,140 Epoch[44] Batch [1230]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.088428,	
2017-07-29 03:12:48,418 Epoch[44] Batch [1240]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.088429,	
2017-07-29 03:12:57,563 Epoch[44] Batch [1250]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.088374,	
2017-07-29 03:13:06,634 Epoch[44] Batch [1260]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.088329,	
2017-07-29 03:13:14,616 Epoch[44] Batch [1270]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.088433,	
2017-07-29 03:13:24,185 Epoch[44] Batch [1280]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.088349,	
2017-07-29 03:13:32,382 Epoch[44] Batch [1290]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.088308,	
2017-07-29 03:13:41,407 Epoch[44] Batch [1300]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.088306,	
2017-07-29 03:13:53,144 Epoch[44] Batch [1310]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.088225,	
2017-07-29 03:14:04,079 Epoch[44] Batch [1320]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.088229,	
2017-07-29 03:14:15,386 Epoch[44] Batch [1330]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.088190,	
2017-07-29 03:14:27,181 Epoch[44] Batch [1340]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.088124,	
2017-07-29 03:14:37,760 Epoch[44] Batch [1350]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.088133,	
2017-07-29 03:14:50,353 Epoch[44] Batch [1360]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.088140,	
2017-07-29 03:15:02,809 Epoch[44] Batch [1370]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.088249,	
2017-07-29 03:15:12,874 Epoch[44] Batch [1380]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.088226,	
2017-07-29 03:15:27,518 Epoch[44] Batch [1390]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.088155,	
2017-07-29 03:15:40,189 Epoch[44] Batch [1400]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.088204,	
2017-07-29 03:15:51,836 Epoch[44] Batch [1410]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.088215,	
2017-07-29 03:16:02,262 Epoch[44] Batch [1420]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.088208,	
2017-07-29 03:16:13,519 Epoch[44] Batch [1430]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.088168,	
2017-07-29 03:16:25,049 Epoch[44] Batch [1440]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.088109,	
2017-07-29 03:16:36,774 Epoch[44] Batch [1450]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.088105,	
2017-07-29 03:16:45,793 Epoch[44] Batch [1460]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.088126,	
2017-07-29 03:16:56,633 Epoch[44] Batch [1470]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.088118,	
2017-07-29 03:17:05,666 Epoch[44] Batch [1480]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.088100,	
2017-07-29 03:17:11,221 Epoch[44] Train-FCNLogLoss=0.088059
2017-07-29 03:17:11,221 Epoch[44] Time cost=1539.973
2017-07-29 03:17:12,461 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0045.params"
2017-07-29 03:17:16,181 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0045.states"
2017-07-29 03:17:26,359 Epoch[45] Batch [10]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.087836,	
2017-07-29 03:17:36,268 Epoch[45] Batch [20]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.092656,	
2017-07-29 03:17:46,502 Epoch[45] Batch [30]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.091413,	
2017-07-29 03:17:55,684 Epoch[45] Batch [40]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.089750,	
2017-07-29 03:18:04,873 Epoch[45] Batch [50]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.089723,	
2017-07-29 03:18:15,757 Epoch[45] Batch [60]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.088760,	
2017-07-29 03:18:27,389 Epoch[45] Batch [70]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.088403,	
2017-07-29 03:18:39,103 Epoch[45] Batch [80]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.087755,	
2017-07-29 03:18:48,373 Epoch[45] Batch [90]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.088634,	
2017-07-29 03:19:00,678 Epoch[45] Batch [100]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.088005,	
2017-07-29 03:19:11,464 Epoch[45] Batch [110]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.087398,	
2017-07-29 03:19:19,715 Epoch[45] Batch [120]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.087276,	
2017-07-29 03:19:28,534 Epoch[45] Batch [130]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.087554,	
2017-07-29 03:19:40,528 Epoch[45] Batch [140]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.087805,	
2017-07-29 03:19:51,078 Epoch[45] Batch [150]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.087702,	
2017-07-29 03:20:02,345 Epoch[45] Batch [160]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.087388,	
2017-07-29 03:20:14,109 Epoch[45] Batch [170]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.087823,	
2017-07-29 03:20:24,384 Epoch[45] Batch [180]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.088086,	
2017-07-29 03:20:35,551 Epoch[45] Batch [190]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.087849,	
2017-07-29 03:20:48,124 Epoch[45] Batch [200]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.088001,	
2017-07-29 03:20:57,490 Epoch[45] Batch [210]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.088143,	
2017-07-29 03:21:06,211 Epoch[45] Batch [220]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.088188,	
2017-07-29 03:21:16,725 Epoch[45] Batch [230]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.087871,	
2017-07-29 03:21:25,039 Epoch[45] Batch [240]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.088136,	
2017-07-29 03:21:35,570 Epoch[45] Batch [250]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.088136,	
2017-07-29 03:21:45,788 Epoch[45] Batch [260]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.088290,	
2017-07-29 03:21:54,893 Epoch[45] Batch [270]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.088184,	
2017-07-29 03:22:03,169 Epoch[45] Batch [280]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.088153,	
2017-07-29 03:22:11,901 Epoch[45] Batch [290]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.087852,	
2017-07-29 03:22:19,923 Epoch[45] Batch [300]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087568,	
2017-07-29 03:22:28,032 Epoch[45] Batch [310]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.087650,	
2017-07-29 03:22:42,903 Epoch[45] Batch [320]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.087659,	
2017-07-29 03:22:52,723 Epoch[45] Batch [330]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.087722,	
2017-07-29 03:23:03,780 Epoch[45] Batch [340]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.087449,	
2017-07-29 03:23:13,114 Epoch[45] Batch [350]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.087703,	
2017-07-29 03:23:23,600 Epoch[45] Batch [360]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.087770,	
2017-07-29 03:23:35,675 Epoch[45] Batch [370]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.087750,	
2017-07-29 03:23:47,305 Epoch[45] Batch [380]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.087919,	
2017-07-29 03:23:59,413 Epoch[45] Batch [390]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.087890,	
2017-07-29 03:24:12,493 Epoch[45] Batch [400]	Speed: 3.06 samples/sec	Train-FCNLogLoss=0.087784,	
2017-07-29 03:24:22,383 Epoch[45] Batch [410]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.087808,	
2017-07-29 03:24:32,661 Epoch[45] Batch [420]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.087699,	
2017-07-29 03:24:41,826 Epoch[45] Batch [430]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.087848,	
2017-07-29 03:24:53,018 Epoch[45] Batch [440]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.087618,	
2017-07-29 03:25:04,041 Epoch[45] Batch [450]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.087686,	
2017-07-29 03:25:13,902 Epoch[45] Batch [460]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.087599,	
2017-07-29 03:25:21,986 Epoch[45] Batch [470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.087727,	
2017-07-29 03:25:30,259 Epoch[45] Batch [480]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.087807,	
2017-07-29 03:25:38,932 Epoch[45] Batch [490]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.087969,	
2017-07-29 03:25:47,444 Epoch[45] Batch [500]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.087960,	
2017-07-29 03:25:55,538 Epoch[45] Batch [510]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.087986,	
2017-07-29 03:26:04,083 Epoch[45] Batch [520]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.088035,	
2017-07-29 03:26:13,233 Epoch[45] Batch [530]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.087982,	
2017-07-29 03:26:22,152 Epoch[45] Batch [540]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.087790,	
2017-07-29 03:26:32,388 Epoch[45] Batch [550]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.087998,	
2017-07-29 03:26:42,495 Epoch[45] Batch [560]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.088000,	
2017-07-29 03:26:47,779 Epoch[45] Batch [570]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087956,	
2017-07-29 03:26:53,454 Epoch[45] Batch [580]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087852,	
2017-07-29 03:26:59,188 Epoch[45] Batch [590]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087767,	
2017-07-29 03:27:04,983 Epoch[45] Batch [600]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087612,	
2017-07-29 03:27:10,704 Epoch[45] Batch [610]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087604,	
2017-07-29 03:27:16,459 Epoch[45] Batch [620]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088004,	
2017-07-29 03:27:22,240 Epoch[45] Batch [630]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088227,	
2017-07-29 03:27:28,000 Epoch[45] Batch [640]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088568,	
2017-07-29 03:27:33,799 Epoch[45] Batch [650]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.088661,	
2017-07-29 03:27:39,565 Epoch[45] Batch [660]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.088668,	
2017-07-29 03:27:45,386 Epoch[45] Batch [670]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088617,	
2017-07-29 03:27:51,187 Epoch[45] Batch [680]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.088650,	
2017-07-29 03:27:56,985 Epoch[45] Batch [690]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.088621,	
2017-07-29 03:28:02,783 Epoch[45] Batch [700]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.088911,	
2017-07-29 03:28:08,604 Epoch[45] Batch [710]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088884,	
2017-07-29 03:28:14,381 Epoch[45] Batch [720]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088823,	
2017-07-29 03:28:20,187 Epoch[45] Batch [730]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088786,	
2017-07-29 03:28:25,990 Epoch[45] Batch [740]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088774,	
2017-07-29 03:28:31,778 Epoch[45] Batch [750]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088679,	
2017-07-29 03:28:37,608 Epoch[45] Batch [760]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.088628,	
2017-07-29 03:28:43,396 Epoch[45] Batch [770]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088760,	
2017-07-29 03:28:49,198 Epoch[45] Batch [780]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088758,	
2017-07-29 03:28:55,023 Epoch[45] Batch [790]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088872,	
2017-07-29 03:29:00,798 Epoch[45] Batch [800]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088817,	
2017-07-29 03:29:06,627 Epoch[45] Batch [810]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.088943,	
2017-07-29 03:29:12,417 Epoch[45] Batch [820]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.089081,	
2017-07-29 03:29:18,182 Epoch[45] Batch [830]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.089225,	
2017-07-29 03:29:24,033 Epoch[45] Batch [840]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.089338,	
2017-07-29 03:29:29,813 Epoch[45] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.089271,	
2017-07-29 03:29:35,605 Epoch[45] Batch [860]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.089237,	
2017-07-29 03:29:41,406 Epoch[45] Batch [870]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.089194,	
2017-07-29 03:29:47,176 Epoch[45] Batch [880]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.089109,	
2017-07-29 03:29:53,003 Epoch[45] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.089067,	
2017-07-29 03:29:58,793 Epoch[45] Batch [900]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088961,	
2017-07-29 03:30:04,573 Epoch[45] Batch [910]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088903,	
2017-07-29 03:30:10,393 Epoch[45] Batch [920]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088765,	
2017-07-29 03:30:16,202 Epoch[45] Batch [930]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088787,	
2017-07-29 03:30:21,517 Epoch[45] Batch [940]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088730,	
2017-07-29 03:30:26,729 Epoch[45] Batch [950]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088643,	
2017-07-29 03:30:32,054 Epoch[45] Batch [960]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088718,	
2017-07-29 03:30:37,828 Epoch[45] Batch [970]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088650,	
2017-07-29 03:30:42,930 Epoch[45] Batch [980]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088666,	
2017-07-29 03:30:48,120 Epoch[45] Batch [990]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088654,	
2017-07-29 03:30:53,188 Epoch[45] Batch [1000]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088604,	
2017-07-29 03:30:58,239 Epoch[45] Batch [1010]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088642,	
2017-07-29 03:31:03,803 Epoch[45] Batch [1020]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088665,	
2017-07-29 03:31:09,507 Epoch[45] Batch [1030]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088658,	
2017-07-29 03:31:15,259 Epoch[45] Batch [1040]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088642,	
2017-07-29 03:31:20,647 Epoch[45] Batch [1050]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088601,	
2017-07-29 03:31:26,127 Epoch[45] Batch [1060]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088534,	
2017-07-29 03:31:31,682 Epoch[45] Batch [1070]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088567,	
2017-07-29 03:31:37,233 Epoch[45] Batch [1080]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.088630,	
2017-07-29 03:31:42,577 Epoch[45] Batch [1090]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088516,	
2017-07-29 03:31:48,026 Epoch[45] Batch [1100]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.088491,	
2017-07-29 03:31:53,055 Epoch[45] Batch [1110]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088437,	
2017-07-29 03:31:58,338 Epoch[45] Batch [1120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088404,	
2017-07-29 03:32:04,092 Epoch[45] Batch [1130]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088425,	
2017-07-29 03:32:09,371 Epoch[45] Batch [1140]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088353,	
2017-07-29 03:32:14,695 Epoch[45] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088348,	
2017-07-29 03:32:20,203 Epoch[45] Batch [1160]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088377,	
2017-07-29 03:32:25,333 Epoch[45] Batch [1170]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088316,	
2017-07-29 03:32:30,708 Epoch[45] Batch [1180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088328,	
2017-07-29 03:32:36,115 Epoch[45] Batch [1190]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088317,	
2017-07-29 03:32:41,186 Epoch[45] Batch [1200]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088329,	
2017-07-29 03:32:46,351 Epoch[45] Batch [1210]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.088332,	
2017-07-29 03:32:51,580 Epoch[45] Batch [1220]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088282,	
2017-07-29 03:32:56,855 Epoch[45] Batch [1230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088259,	
2017-07-29 03:33:01,747 Epoch[45] Batch [1240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088213,	
2017-07-29 03:33:06,991 Epoch[45] Batch [1250]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088188,	
2017-07-29 03:33:12,257 Epoch[45] Batch [1260]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088290,	
2017-07-29 03:33:17,087 Epoch[45] Batch [1270]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088256,	
2017-07-29 03:33:22,357 Epoch[45] Batch [1280]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088270,	
2017-07-29 03:33:27,353 Epoch[45] Batch [1290]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088219,	
2017-07-29 03:33:32,481 Epoch[45] Batch [1300]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088194,	
2017-07-29 03:33:38,229 Epoch[45] Batch [1310]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088442,	
2017-07-29 03:33:43,873 Epoch[45] Batch [1320]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.088416,	
2017-07-29 03:33:49,027 Epoch[45] Batch [1330]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088404,	
2017-07-29 03:33:54,581 Epoch[45] Batch [1340]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088420,	
2017-07-29 03:33:59,885 Epoch[45] Batch [1350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088457,	
2017-07-29 03:34:05,460 Epoch[45] Batch [1360]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088433,	
2017-07-29 03:34:11,122 Epoch[45] Batch [1370]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088327,	
2017-07-29 03:34:16,753 Epoch[45] Batch [1380]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.088321,	
2017-07-29 03:34:22,306 Epoch[45] Batch [1390]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088289,	
2017-07-29 03:34:27,710 Epoch[45] Batch [1400]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088254,	
2017-07-29 03:34:33,455 Epoch[45] Batch [1410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088283,	
2017-07-29 03:34:39,274 Epoch[45] Batch [1420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088320,	
2017-07-29 03:34:44,699 Epoch[45] Batch [1430]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088359,	
2017-07-29 03:34:50,068 Epoch[45] Batch [1440]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088373,	
2017-07-29 03:34:55,380 Epoch[45] Batch [1450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088346,	
2017-07-29 03:35:00,855 Epoch[45] Batch [1460]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088401,	
2017-07-29 03:35:06,177 Epoch[45] Batch [1470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088385,	
2017-07-29 03:35:11,542 Epoch[45] Batch [1480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088360,	
2017-07-29 03:35:14,485 Epoch[45] Train-FCNLogLoss=0.088357
2017-07-29 03:35:14,485 Epoch[45] Time cost=1078.304
2017-07-29 03:35:15,316 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0046.params"
2017-07-29 03:35:16,987 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0046.states"
2017-07-29 03:35:22,754 Epoch[46] Batch [10]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.079359,	
2017-07-29 03:35:28,215 Epoch[46] Batch [20]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.084472,	
2017-07-29 03:35:33,879 Epoch[46] Batch [30]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086972,	
2017-07-29 03:35:39,418 Epoch[46] Batch [40]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.090408,	
2017-07-29 03:35:44,993 Epoch[46] Batch [50]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.090990,	
2017-07-29 03:35:50,460 Epoch[46] Batch [60]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.091566,	
2017-07-29 03:35:55,544 Epoch[46] Batch [70]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.090350,	
2017-07-29 03:36:00,622 Epoch[46] Batch [80]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.090039,	
2017-07-29 03:36:05,912 Epoch[46] Batch [90]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090052,	
2017-07-29 03:36:11,142 Epoch[46] Batch [100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.089635,	
2017-07-29 03:36:16,229 Epoch[46] Batch [110]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088739,	
2017-07-29 03:36:21,424 Epoch[46] Batch [120]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088025,	
2017-07-29 03:36:26,484 Epoch[46] Batch [130]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088670,	
2017-07-29 03:36:31,030 Epoch[46] Batch [140]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088263,	
2017-07-29 03:36:35,474 Epoch[46] Batch [150]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087834,	
2017-07-29 03:36:40,852 Epoch[46] Batch [160]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088742,	
2017-07-29 03:36:46,230 Epoch[46] Batch [170]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088108,	
2017-07-29 03:36:51,604 Epoch[46] Batch [180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088330,	
2017-07-29 03:36:56,930 Epoch[46] Batch [190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088479,	
2017-07-29 03:37:02,253 Epoch[46] Batch [200]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088483,	
2017-07-29 03:37:08,005 Epoch[46] Batch [210]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088483,	
2017-07-29 03:37:13,807 Epoch[46] Batch [220]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.089046,	
2017-07-29 03:37:19,353 Epoch[46] Batch [230]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.088806,	
2017-07-29 03:37:25,114 Epoch[46] Batch [240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.088599,	
2017-07-29 03:37:30,642 Epoch[46] Batch [250]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088587,	
2017-07-29 03:37:36,131 Epoch[46] Batch [260]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.088521,	
2017-07-29 03:37:41,713 Epoch[46] Batch [270]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088433,	
2017-07-29 03:37:47,494 Epoch[46] Batch [280]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088142,	
2017-07-29 03:37:53,304 Epoch[46] Batch [290]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.087789,	
2017-07-29 03:37:59,080 Epoch[46] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087545,	
2017-07-29 03:38:04,344 Epoch[46] Batch [310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087488,	
2017-07-29 03:38:09,415 Epoch[46] Batch [320]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087439,	
2017-07-29 03:38:14,335 Epoch[46] Batch [330]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.087221,	
2017-07-29 03:38:19,453 Epoch[46] Batch [340]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087149,	
2017-07-29 03:38:24,667 Epoch[46] Batch [350]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087013,	
2017-07-29 03:38:30,222 Epoch[46] Batch [360]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.086940,	
2017-07-29 03:38:35,324 Epoch[46] Batch [370]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086880,	
2017-07-29 03:38:40,796 Epoch[46] Batch [380]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086774,	
2017-07-29 03:38:45,938 Epoch[46] Batch [390]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 03:38:51,404 Epoch[46] Batch [400]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.086466,	
2017-07-29 03:38:56,583 Epoch[46] Batch [410]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.086594,	
2017-07-29 03:39:01,648 Epoch[46] Batch [420]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086579,	
2017-07-29 03:39:06,794 Epoch[46] Batch [430]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086487,	
2017-07-29 03:39:11,765 Epoch[46] Batch [440]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086702,	
2017-07-29 03:39:16,600 Epoch[46] Batch [450]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.086897,	
2017-07-29 03:39:21,823 Epoch[46] Batch [460]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086822,	
2017-07-29 03:39:26,920 Epoch[46] Batch [470]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086865,	
2017-07-29 03:39:32,060 Epoch[46] Batch [480]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.087123,	
2017-07-29 03:39:37,256 Epoch[46] Batch [490]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087274,	
2017-07-29 03:39:42,592 Epoch[46] Batch [500]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087426,	
2017-07-29 03:39:47,576 Epoch[46] Batch [510]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087286,	
2017-07-29 03:39:52,629 Epoch[46] Batch [520]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087253,	
2017-07-29 03:39:57,634 Epoch[46] Batch [530]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087323,	
2017-07-29 03:40:02,689 Epoch[46] Batch [540]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087275,	
2017-07-29 03:40:08,208 Epoch[46] Batch [550]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087263,	
2017-07-29 03:40:13,243 Epoch[46] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087235,	
2017-07-29 03:40:18,547 Epoch[46] Batch [570]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087286,	
2017-07-29 03:40:24,045 Epoch[46] Batch [580]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087228,	
2017-07-29 03:40:29,081 Epoch[46] Batch [590]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087137,	
2017-07-29 03:40:34,306 Epoch[46] Batch [600]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087076,	
2017-07-29 03:40:39,416 Epoch[46] Batch [610]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087063,	
2017-07-29 03:40:44,645 Epoch[46] Batch [620]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087097,	
2017-07-29 03:40:49,631 Epoch[46] Batch [630]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087150,	
2017-07-29 03:40:54,737 Epoch[46] Batch [640]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087115,	
2017-07-29 03:41:00,053 Epoch[46] Batch [650]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087018,	
2017-07-29 03:41:05,160 Epoch[46] Batch [660]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086992,	
2017-07-29 03:41:10,806 Epoch[46] Batch [670]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.087082,	
2017-07-29 03:41:15,911 Epoch[46] Batch [680]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087115,	
2017-07-29 03:41:20,730 Epoch[46] Batch [690]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087186,	
2017-07-29 03:41:25,740 Epoch[46] Batch [700]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087208,	
2017-07-29 03:41:30,785 Epoch[46] Batch [710]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087186,	
2017-07-29 03:41:35,840 Epoch[46] Batch [720]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087126,	
2017-07-29 03:41:41,133 Epoch[46] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087232,	
2017-07-29 03:41:46,589 Epoch[46] Batch [740]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.087270,	
2017-07-29 03:41:51,449 Epoch[46] Batch [750]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087286,	
2017-07-29 03:41:56,418 Epoch[46] Batch [760]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087188,	
2017-07-29 03:42:01,211 Epoch[46] Batch [770]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087131,	
2017-07-29 03:42:06,162 Epoch[46] Batch [780]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087248,	
2017-07-29 03:42:11,227 Epoch[46] Batch [790]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087283,	
2017-07-29 03:42:16,290 Epoch[46] Batch [800]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087335,	
2017-07-29 03:42:21,330 Epoch[46] Batch [810]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087232,	
2017-07-29 03:42:26,369 Epoch[46] Batch [820]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087265,	
2017-07-29 03:42:31,604 Epoch[46] Batch [830]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087238,	
2017-07-29 03:42:36,660 Epoch[46] Batch [840]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087124,	
2017-07-29 03:42:41,908 Epoch[46] Batch [850]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087142,	
2017-07-29 03:42:46,934 Epoch[46] Batch [860]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087196,	
2017-07-29 03:42:51,555 Epoch[46] Batch [870]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087280,	
2017-07-29 03:42:56,672 Epoch[46] Batch [880]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087288,	
2017-07-29 03:43:01,745 Epoch[46] Batch [890]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087348,	
2017-07-29 03:43:06,739 Epoch[46] Batch [900]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087421,	
2017-07-29 03:43:11,838 Epoch[46] Batch [910]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087359,	
2017-07-29 03:43:16,911 Epoch[46] Batch [920]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087371,	
2017-07-29 03:43:22,003 Epoch[46] Batch [930]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087387,	
2017-07-29 03:43:27,731 Epoch[46] Batch [940]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087409,	
2017-07-29 03:43:32,944 Epoch[46] Batch [950]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087356,	
2017-07-29 03:43:38,345 Epoch[46] Batch [960]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087336,	
2017-07-29 03:43:43,560 Epoch[46] Batch [970]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087256,	
2017-07-29 03:43:48,799 Epoch[46] Batch [980]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087243,	
2017-07-29 03:43:53,870 Epoch[46] Batch [990]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087161,	
2017-07-29 03:43:58,885 Epoch[46] Batch [1000]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087173,	
2017-07-29 03:44:03,893 Epoch[46] Batch [1010]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087157,	
2017-07-29 03:44:09,141 Epoch[46] Batch [1020]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087154,	
2017-07-29 03:44:14,249 Epoch[46] Batch [1030]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087175,	
2017-07-29 03:44:19,568 Epoch[46] Batch [1040]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087153,	
2017-07-29 03:44:24,614 Epoch[46] Batch [1050]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087167,	
2017-07-29 03:44:29,582 Epoch[46] Batch [1060]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087183,	
2017-07-29 03:44:34,671 Epoch[46] Batch [1070]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087223,	
2017-07-29 03:44:39,453 Epoch[46] Batch [1080]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087232,	
2017-07-29 03:44:44,435 Epoch[46] Batch [1090]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087315,	
2017-07-29 03:44:49,634 Epoch[46] Batch [1100]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087299,	
2017-07-29 03:44:54,782 Epoch[46] Batch [1110]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087324,	
2017-07-29 03:44:59,806 Epoch[46] Batch [1120]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087366,	
2017-07-29 03:45:04,851 Epoch[46] Batch [1130]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087379,	
2017-07-29 03:45:09,842 Epoch[46] Batch [1140]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087478,	
2017-07-29 03:45:15,193 Epoch[46] Batch [1150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087388,	
2017-07-29 03:45:20,484 Epoch[46] Batch [1160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087366,	
2017-07-29 03:45:25,818 Epoch[46] Batch [1170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087373,	
2017-07-29 03:45:30,808 Epoch[46] Batch [1180]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087386,	
2017-07-29 03:45:35,837 Epoch[46] Batch [1190]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087313,	
2017-07-29 03:45:40,867 Epoch[46] Batch [1200]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087323,	
2017-07-29 03:45:45,890 Epoch[46] Batch [1210]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087583,	
2017-07-29 03:45:50,697 Epoch[46] Batch [1220]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.087564,	
2017-07-29 03:45:56,217 Epoch[46] Batch [1230]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087580,	
2017-07-29 03:46:01,519 Epoch[46] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087602,	
2017-07-29 03:46:06,337 Epoch[46] Batch [1250]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087550,	
2017-07-29 03:46:11,268 Epoch[46] Batch [1260]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087640,	
2017-07-29 03:46:16,546 Epoch[46] Batch [1270]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087666,	
2017-07-29 03:46:21,795 Epoch[46] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087603,	
2017-07-29 03:46:26,891 Epoch[46] Batch [1290]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087625,	
2017-07-29 03:46:31,994 Epoch[46] Batch [1300]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087546,	
2017-07-29 03:46:36,911 Epoch[46] Batch [1310]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.087482,	
2017-07-29 03:46:41,819 Epoch[46] Batch [1320]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.087459,	
2017-07-29 03:46:46,651 Epoch[46] Batch [1330]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.087467,	
2017-07-29 03:46:51,593 Epoch[46] Batch [1340]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.087461,	
2017-07-29 03:46:56,483 Epoch[46] Batch [1350]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.087432,	
2017-07-29 03:47:01,343 Epoch[46] Batch [1360]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087384,	
2017-07-29 03:47:06,122 Epoch[46] Batch [1370]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087415,	
2017-07-29 03:47:11,308 Epoch[46] Batch [1380]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.087360,	
2017-07-29 03:47:16,559 Epoch[46] Batch [1390]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087420,	
2017-07-29 03:47:21,523 Epoch[46] Batch [1400]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.087427,	
2017-07-29 03:47:26,499 Epoch[46] Batch [1410]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087383,	
2017-07-29 03:47:31,292 Epoch[46] Batch [1420]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087394,	
2017-07-29 03:47:36,079 Epoch[46] Batch [1430]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087390,	
2017-07-29 03:47:40,877 Epoch[46] Batch [1440]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.087383,	
2017-07-29 03:47:45,920 Epoch[46] Batch [1450]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087398,	
2017-07-29 03:47:50,822 Epoch[46] Batch [1460]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.087394,	
2017-07-29 03:47:55,628 Epoch[46] Batch [1470]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.087368,	
2017-07-29 03:48:00,392 Epoch[46] Batch [1480]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087336,	
2017-07-29 03:48:03,395 Epoch[46] Train-FCNLogLoss=0.087350
2017-07-29 03:48:03,396 Epoch[46] Time cost=766.408
2017-07-29 03:48:04,284 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0047.params"
2017-07-29 03:48:06,038 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0047.states"
2017-07-29 03:48:11,664 Epoch[47] Batch [10]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087533,	
2017-07-29 03:48:16,381 Epoch[47] Batch [20]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089015,	
2017-07-29 03:48:21,039 Epoch[47] Batch [30]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089794,	
2017-07-29 03:48:26,547 Epoch[47] Batch [40]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088688,	
2017-07-29 03:48:31,330 Epoch[47] Batch [50]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086410,	
2017-07-29 03:48:35,908 Epoch[47] Batch [60]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.086308,	
2017-07-29 03:48:41,213 Epoch[47] Batch [70]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087001,	
2017-07-29 03:48:46,284 Epoch[47] Batch [80]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088057,	
2017-07-29 03:48:51,301 Epoch[47] Batch [90]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088173,	
2017-07-29 03:48:56,381 Epoch[47] Batch [100]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088162,	
2017-07-29 03:49:01,385 Epoch[47] Batch [110]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088645,	
2017-07-29 03:49:06,480 Epoch[47] Batch [120]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088756,	
2017-07-29 03:49:11,666 Epoch[47] Batch [130]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088164,	
2017-07-29 03:49:16,700 Epoch[47] Batch [140]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087991,	
2017-07-29 03:49:21,719 Epoch[47] Batch [150]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087722,	
2017-07-29 03:49:26,543 Epoch[47] Batch [160]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087464,	
2017-07-29 03:49:31,805 Epoch[47] Batch [170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087026,	
2017-07-29 03:49:36,856 Epoch[47] Batch [180]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087145,	
2017-07-29 03:49:41,888 Epoch[47] Batch [190]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087319,	
2017-07-29 03:49:46,869 Epoch[47] Batch [200]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087258,	
2017-07-29 03:49:52,156 Epoch[47] Batch [210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087800,	
2017-07-29 03:49:57,210 Epoch[47] Batch [220]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087701,	
2017-07-29 03:50:02,802 Epoch[47] Batch [230]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087915,	
2017-07-29 03:50:08,058 Epoch[47] Batch [240]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088504,	
2017-07-29 03:50:12,918 Epoch[47] Batch [250]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088428,	
2017-07-29 03:50:18,335 Epoch[47] Batch [260]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088403,	
2017-07-29 03:50:23,424 Epoch[47] Batch [270]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088484,	
2017-07-29 03:50:28,487 Epoch[47] Batch [280]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.088561,	
2017-07-29 03:50:33,923 Epoch[47] Batch [290]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088388,	
2017-07-29 03:50:39,014 Epoch[47] Batch [300]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088152,	
2017-07-29 03:50:44,020 Epoch[47] Batch [310]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087994,	
2017-07-29 03:50:48,970 Epoch[47] Batch [320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088135,	
2017-07-29 03:50:53,812 Epoch[47] Batch [330]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.087885,	
2017-07-29 03:50:58,795 Epoch[47] Batch [340]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087846,	
2017-07-29 03:51:03,786 Epoch[47] Batch [350]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087733,	
2017-07-29 03:51:08,733 Epoch[47] Batch [360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087717,	
2017-07-29 03:51:13,950 Epoch[47] Batch [370]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087895,	
2017-07-29 03:51:18,784 Epoch[47] Batch [380]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088025,	
2017-07-29 03:51:23,726 Epoch[47] Batch [390]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087746,	
2017-07-29 03:51:28,584 Epoch[47] Batch [400]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.087647,	
2017-07-29 03:51:33,705 Epoch[47] Batch [410]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087807,	
2017-07-29 03:51:38,805 Epoch[47] Batch [420]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087723,	
2017-07-29 03:51:43,680 Epoch[47] Batch [430]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.087666,	
2017-07-29 03:51:48,694 Epoch[47] Batch [440]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087568,	
2017-07-29 03:51:53,679 Epoch[47] Batch [450]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087816,	
2017-07-29 03:51:58,532 Epoch[47] Batch [460]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.087780,	
2017-07-29 03:52:03,563 Epoch[47] Batch [470]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087513,	
2017-07-29 03:52:08,855 Epoch[47] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087544,	
2017-07-29 03:52:14,641 Epoch[47] Batch [490]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087562,	
2017-07-29 03:52:19,861 Epoch[47] Batch [500]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087395,	
2017-07-29 03:52:24,723 Epoch[47] Batch [510]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087138,	
2017-07-29 03:52:29,756 Epoch[47] Batch [520]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087155,	
2017-07-29 03:52:34,805 Epoch[47] Batch [530]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087211,	
2017-07-29 03:52:39,838 Epoch[47] Batch [540]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087340,	
2017-07-29 03:52:45,031 Epoch[47] Batch [550]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087542,	
2017-07-29 03:52:49,985 Epoch[47] Batch [560]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.087477,	
2017-07-29 03:52:54,993 Epoch[47] Batch [570]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087618,	
2017-07-29 03:52:59,988 Epoch[47] Batch [580]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087513,	
2017-07-29 03:53:05,046 Epoch[47] Batch [590]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087498,	
2017-07-29 03:53:10,015 Epoch[47] Batch [600]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087603,	
2017-07-29 03:53:15,127 Epoch[47] Batch [610]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087745,	
2017-07-29 03:53:20,147 Epoch[47] Batch [620]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087869,	
2017-07-29 03:53:25,192 Epoch[47] Batch [630]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087759,	
2017-07-29 03:53:30,054 Epoch[47] Batch [640]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087647,	
2017-07-29 03:53:34,955 Epoch[47] Batch [650]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.087616,	
2017-07-29 03:53:39,794 Epoch[47] Batch [660]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087620,	
2017-07-29 03:53:44,788 Epoch[47] Batch [670]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087674,	
2017-07-29 03:53:49,862 Epoch[47] Batch [680]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087588,	
2017-07-29 03:53:54,492 Epoch[47] Batch [690]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087645,	
2017-07-29 03:53:58,731 Epoch[47] Batch [700]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087533,	
2017-07-29 03:54:03,633 Epoch[47] Batch [710]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.087590,	
2017-07-29 03:54:08,636 Epoch[47] Batch [720]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087490,	
2017-07-29 03:54:13,525 Epoch[47] Batch [730]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.087458,	
2017-07-29 03:54:18,507 Epoch[47] Batch [740]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087404,	
2017-07-29 03:54:23,198 Epoch[47] Batch [750]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087434,	
2017-07-29 03:54:28,523 Epoch[47] Batch [760]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087599,	
2017-07-29 03:54:33,386 Epoch[47] Batch [770]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087659,	
2017-07-29 03:54:38,423 Epoch[47] Batch [780]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087751,	
2017-07-29 03:54:43,445 Epoch[47] Batch [790]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087707,	
2017-07-29 03:54:48,483 Epoch[47] Batch [800]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087650,	
2017-07-29 03:54:53,559 Epoch[47] Batch [810]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087640,	
2017-07-29 03:54:58,585 Epoch[47] Batch [820]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087652,	
2017-07-29 03:55:03,588 Epoch[47] Batch [830]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087650,	
2017-07-29 03:55:08,711 Epoch[47] Batch [840]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087746,	
2017-07-29 03:55:13,858 Epoch[47] Batch [850]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087755,	
2017-07-29 03:55:19,005 Epoch[47] Batch [860]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087783,	
2017-07-29 03:55:23,976 Epoch[47] Batch [870]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087691,	
2017-07-29 03:55:28,726 Epoch[47] Batch [880]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087534,	
2017-07-29 03:55:34,036 Epoch[47] Batch [890]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087504,	
2017-07-29 03:55:39,064 Epoch[47] Batch [900]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087413,	
2017-07-29 03:55:44,101 Epoch[47] Batch [910]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087445,	
2017-07-29 03:55:49,111 Epoch[47] Batch [920]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087473,	
2017-07-29 03:55:54,144 Epoch[47] Batch [930]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087469,	
2017-07-29 03:55:59,159 Epoch[47] Batch [940]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087394,	
2017-07-29 03:56:04,165 Epoch[47] Batch [950]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087361,	
2017-07-29 03:56:09,185 Epoch[47] Batch [960]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087363,	
2017-07-29 03:56:14,252 Epoch[47] Batch [970]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087431,	
2017-07-29 03:56:19,271 Epoch[47] Batch [980]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087391,	
2017-07-29 03:56:24,320 Epoch[47] Batch [990]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087522,	
2017-07-29 03:56:29,092 Epoch[47] Batch [1000]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087650,	
2017-07-29 03:56:34,383 Epoch[47] Batch [1010]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087579,	
2017-07-29 03:56:39,652 Epoch[47] Batch [1020]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087614,	
2017-07-29 03:56:44,472 Epoch[47] Batch [1030]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087702,	
2017-07-29 03:56:49,428 Epoch[47] Batch [1040]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.087771,	
2017-07-29 03:56:54,396 Epoch[47] Batch [1050]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087720,	
2017-07-29 03:56:59,245 Epoch[47] Batch [1060]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087742,	
2017-07-29 03:57:04,501 Epoch[47] Batch [1070]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087734,	
2017-07-29 03:57:09,558 Epoch[47] Batch [1080]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087722,	
2017-07-29 03:57:14,594 Epoch[47] Batch [1090]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087723,	
2017-07-29 03:57:19,788 Epoch[47] Batch [1100]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087724,	
2017-07-29 03:57:24,815 Epoch[47] Batch [1110]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087646,	
2017-07-29 03:57:29,858 Epoch[47] Batch [1120]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087679,	
2017-07-29 03:57:34,893 Epoch[47] Batch [1130]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087657,	
2017-07-29 03:57:39,921 Epoch[47] Batch [1140]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087658,	
2017-07-29 03:57:45,144 Epoch[47] Batch [1150]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087683,	
2017-07-29 03:57:50,034 Epoch[47] Batch [1160]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.087723,	
2017-07-29 03:57:55,247 Epoch[47] Batch [1170]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087670,	
2017-07-29 03:58:00,307 Epoch[47] Batch [1180]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087649,	
2017-07-29 03:58:05,315 Epoch[47] Batch [1190]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087671,	
2017-07-29 03:58:10,375 Epoch[47] Batch [1200]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087649,	
2017-07-29 03:58:15,415 Epoch[47] Batch [1210]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087649,	
2017-07-29 03:58:20,449 Epoch[47] Batch [1220]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087732,	
2017-07-29 03:58:25,677 Epoch[47] Batch [1230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087734,	
2017-07-29 03:58:31,223 Epoch[47] Batch [1240]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087794,	
2017-07-29 03:58:36,004 Epoch[47] Batch [1250]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087814,	
2017-07-29 03:58:41,080 Epoch[47] Batch [1260]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087751,	
2017-07-29 03:58:46,056 Epoch[47] Batch [1270]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087808,	
2017-07-29 03:58:51,381 Epoch[47] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087858,	
2017-07-29 03:58:56,439 Epoch[47] Batch [1290]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087919,	
2017-07-29 03:59:01,327 Epoch[47] Batch [1300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.087879,	
2017-07-29 03:59:06,397 Epoch[47] Batch [1310]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087902,	
2017-07-29 03:59:11,344 Epoch[47] Batch [1320]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087870,	
2017-07-29 03:59:16,948 Epoch[47] Batch [1330]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.087849,	
2017-07-29 03:59:22,261 Epoch[47] Batch [1340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087835,	
2017-07-29 03:59:27,274 Epoch[47] Batch [1350]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087892,	
2017-07-29 03:59:32,498 Epoch[47] Batch [1360]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087937,	
2017-07-29 03:59:37,635 Epoch[47] Batch [1370]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087863,	
2017-07-29 03:59:42,623 Epoch[47] Batch [1380]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087845,	
2017-07-29 03:59:47,837 Epoch[47] Batch [1390]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087798,	
2017-07-29 03:59:52,948 Epoch[47] Batch [1400]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087801,	
2017-07-29 03:59:58,230 Epoch[47] Batch [1410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087798,	
2017-07-29 04:00:04,015 Epoch[47] Batch [1420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087798,	
2017-07-29 04:00:09,689 Epoch[47] Batch [1430]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087754,	
2017-07-29 04:00:15,279 Epoch[47] Batch [1440]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.087726,	
2017-07-29 04:00:20,729 Epoch[47] Batch [1450]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.087721,	
2017-07-29 04:00:26,379 Epoch[47] Batch [1460]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.087801,	
2017-07-29 04:00:31,514 Epoch[47] Batch [1470]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087807,	
2017-07-29 04:00:36,642 Epoch[47] Batch [1480]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.087882,	
2017-07-29 04:00:39,666 Epoch[47] Train-FCNLogLoss=0.087899
2017-07-29 04:00:39,667 Epoch[47] Time cost=753.628
2017-07-29 04:00:40,508 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0048.params"
2017-07-29 04:00:42,206 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0048.states"
2017-07-29 04:00:48,285 Epoch[48] Batch [10]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088255,	
2017-07-29 04:00:53,206 Epoch[48] Batch [20]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.085064,	
2017-07-29 04:00:58,199 Epoch[48] Batch [30]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.084143,	
2017-07-29 04:01:03,347 Epoch[48] Batch [40]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.083854,	
2017-07-29 04:01:08,407 Epoch[48] Batch [50]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.084162,	
2017-07-29 04:01:13,426 Epoch[48] Batch [60]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.085171,	
2017-07-29 04:01:18,480 Epoch[48] Batch [70]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.085199,	
2017-07-29 04:01:23,915 Epoch[48] Batch [80]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085533,	
2017-07-29 04:01:29,268 Epoch[48] Batch [90]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.085052,	
2017-07-29 04:01:34,370 Epoch[48] Batch [100]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.084815,	
2017-07-29 04:01:39,415 Epoch[48] Batch [110]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.085203,	
2017-07-29 04:01:44,683 Epoch[48] Batch [120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.085735,	
2017-07-29 04:01:49,881 Epoch[48] Batch [130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.085808,	
2017-07-29 04:01:55,191 Epoch[48] Batch [140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086248,	
2017-07-29 04:02:00,251 Epoch[48] Batch [150]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086557,	
2017-07-29 04:02:05,664 Epoch[48] Batch [160]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.087177,	
2017-07-29 04:02:10,786 Epoch[48] Batch [170]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087026,	
2017-07-29 04:02:16,002 Epoch[48] Batch [180]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086887,	
2017-07-29 04:02:21,131 Epoch[48] Batch [190]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086650,	
2017-07-29 04:02:26,144 Epoch[48] Batch [200]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.086821,	
2017-07-29 04:02:31,423 Epoch[48] Batch [210]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086983,	
2017-07-29 04:02:36,216 Epoch[48] Batch [220]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.086770,	
2017-07-29 04:02:41,387 Epoch[48] Batch [230]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086981,	
2017-07-29 04:02:46,417 Epoch[48] Batch [240]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086997,	
2017-07-29 04:02:51,612 Epoch[48] Batch [250]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.086911,	
2017-07-29 04:02:56,866 Epoch[48] Batch [260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087345,	
2017-07-29 04:03:02,177 Epoch[48] Batch [270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087062,	
2017-07-29 04:03:07,617 Epoch[48] Batch [280]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087432,	
2017-07-29 04:03:12,996 Epoch[48] Batch [290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087372,	
2017-07-29 04:03:18,774 Epoch[48] Batch [300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087709,	
2017-07-29 04:03:24,074 Epoch[48] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087354,	
2017-07-29 04:03:29,350 Epoch[48] Batch [320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087640,	
2017-07-29 04:03:34,890 Epoch[48] Batch [330]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.087612,	
2017-07-29 04:03:40,297 Epoch[48] Batch [340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.087724,	
2017-07-29 04:03:45,691 Epoch[48] Batch [350]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087659,	
2017-07-29 04:03:50,781 Epoch[48] Batch [360]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087788,	
2017-07-29 04:03:56,063 Epoch[48] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087815,	
2017-07-29 04:04:01,170 Epoch[48] Batch [380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087720,	
2017-07-29 04:04:06,333 Epoch[48] Batch [390]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087549,	
2017-07-29 04:04:11,748 Epoch[48] Batch [400]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.087533,	
2017-07-29 04:04:17,263 Epoch[48] Batch [410]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087487,	
2017-07-29 04:04:22,469 Epoch[48] Batch [420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087634,	
2017-07-29 04:04:27,600 Epoch[48] Batch [430]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.087529,	
2017-07-29 04:04:32,779 Epoch[48] Batch [440]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.087552,	
2017-07-29 04:04:37,875 Epoch[48] Batch [450]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087752,	
2017-07-29 04:04:43,170 Epoch[48] Batch [460]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087696,	
2017-07-29 04:04:48,989 Epoch[48] Batch [470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.087730,	
2017-07-29 04:04:54,234 Epoch[48] Batch [480]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.087533,	
2017-07-29 04:04:59,284 Epoch[48] Batch [490]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087619,	
2017-07-29 04:05:04,714 Epoch[48] Batch [500]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.087607,	
2017-07-29 04:05:09,849 Epoch[48] Batch [510]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087769,	
2017-07-29 04:05:15,018 Epoch[48] Batch [520]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.087771,	
2017-07-29 04:05:20,378 Epoch[48] Batch [530]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087896,	
2017-07-29 04:05:25,473 Epoch[48] Batch [540]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087643,	
2017-07-29 04:05:30,503 Epoch[48] Batch [550]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087828,	
2017-07-29 04:05:35,515 Epoch[48] Batch [560]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087809,	
2017-07-29 04:05:40,753 Epoch[48] Batch [570]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087829,	
2017-07-29 04:05:46,046 Epoch[48] Batch [580]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087920,	
2017-07-29 04:05:51,350 Epoch[48] Batch [590]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087901,	
2017-07-29 04:05:56,619 Epoch[48] Batch [600]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087869,	
2017-07-29 04:06:01,634 Epoch[48] Batch [610]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087765,	
2017-07-29 04:06:06,704 Epoch[48] Batch [620]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087821,	
2017-07-29 04:06:11,694 Epoch[48] Batch [630]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087864,	
2017-07-29 04:06:16,792 Epoch[48] Batch [640]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087724,	
2017-07-29 04:06:22,323 Epoch[48] Batch [650]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.087665,	
2017-07-29 04:06:27,705 Epoch[48] Batch [660]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087675,	
2017-07-29 04:06:33,384 Epoch[48] Batch [670]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.087781,	
2017-07-29 04:06:38,714 Epoch[48] Batch [680]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087766,	
2017-07-29 04:06:44,026 Epoch[48] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087803,	
2017-07-29 04:06:49,055 Epoch[48] Batch [700]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087810,	
2017-07-29 04:06:54,257 Epoch[48] Batch [710]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087835,	
2017-07-29 04:06:59,528 Epoch[48] Batch [720]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087818,	
2017-07-29 04:07:04,612 Epoch[48] Batch [730]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087795,	
2017-07-29 04:07:09,686 Epoch[48] Batch [740]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087694,	
2017-07-29 04:07:14,768 Epoch[48] Batch [750]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087664,	
2017-07-29 04:07:20,146 Epoch[48] Batch [760]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087808,	
2017-07-29 04:07:25,507 Epoch[48] Batch [770]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087704,	
2017-07-29 04:07:31,284 Epoch[48] Batch [780]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087631,	
2017-07-29 04:07:36,564 Epoch[48] Batch [790]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087704,	
2017-07-29 04:07:41,582 Epoch[48] Batch [800]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087752,	
2017-07-29 04:07:46,613 Epoch[48] Batch [810]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087558,	
2017-07-29 04:07:51,646 Epoch[48] Batch [820]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087565,	
2017-07-29 04:07:56,895 Epoch[48] Batch [830]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087599,	
2017-07-29 04:08:02,006 Epoch[48] Batch [840]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.087588,	
2017-07-29 04:08:07,084 Epoch[48] Batch [850]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087547,	
2017-07-29 04:08:12,023 Epoch[48] Batch [860]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.087612,	
2017-07-29 04:08:17,048 Epoch[48] Batch [870]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087572,	
2017-07-29 04:08:22,031 Epoch[48] Batch [880]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087539,	
2017-07-29 04:08:27,257 Epoch[48] Batch [890]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087586,	
2017-07-29 04:08:32,287 Epoch[48] Batch [900]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087569,	
2017-07-29 04:08:37,671 Epoch[48] Batch [910]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087696,	
2017-07-29 04:08:43,342 Epoch[48] Batch [920]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087773,	
2017-07-29 04:08:48,920 Epoch[48] Batch [930]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.087746,	
2017-07-29 04:08:54,504 Epoch[48] Batch [940]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.087673,	
2017-07-29 04:09:00,022 Epoch[48] Batch [950]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087719,	
2017-07-29 04:09:05,108 Epoch[48] Batch [960]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087829,	
2017-07-29 04:09:10,384 Epoch[48] Batch [970]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087830,	
2017-07-29 04:09:15,440 Epoch[48] Batch [980]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.087796,	
2017-07-29 04:09:20,611 Epoch[48] Batch [990]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.087690,	
2017-07-29 04:09:25,709 Epoch[48] Batch [1000]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087613,	
2017-07-29 04:09:30,834 Epoch[48] Batch [1010]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087542,	
2017-07-29 04:09:35,997 Epoch[48] Batch [1020]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087598,	
2017-07-29 04:09:41,159 Epoch[48] Batch [1030]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087560,	
2017-07-29 04:09:46,199 Epoch[48] Batch [1040]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087660,	
2017-07-29 04:09:51,326 Epoch[48] Batch [1050]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.087652,	
2017-07-29 04:09:56,577 Epoch[48] Batch [1060]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087616,	
2017-07-29 04:10:01,616 Epoch[48] Batch [1070]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087635,	
2017-07-29 04:10:06,808 Epoch[48] Batch [1080]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087536,	
2017-07-29 04:10:11,963 Epoch[48] Batch [1090]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.087514,	
2017-07-29 04:10:17,479 Epoch[48] Batch [1100]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087525,	
2017-07-29 04:10:22,549 Epoch[48] Batch [1110]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087531,	
2017-07-29 04:10:28,087 Epoch[48] Batch [1120]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.087535,	
2017-07-29 04:10:33,230 Epoch[48] Batch [1130]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.087469,	
2017-07-29 04:10:38,215 Epoch[48] Batch [1140]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087404,	
2017-07-29 04:10:43,473 Epoch[48] Batch [1150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087338,	
2017-07-29 04:10:48,559 Epoch[48] Batch [1160]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087342,	
2017-07-29 04:10:53,838 Epoch[48] Batch [1170]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087332,	
2017-07-29 04:10:58,135 Epoch[48] Batch [1180]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087305,	
2017-07-29 04:11:02,898 Epoch[48] Batch [1190]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087312,	
2017-07-29 04:11:08,075 Epoch[48] Batch [1200]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087231,	
2017-07-29 04:11:13,356 Epoch[48] Batch [1210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087446,	
2017-07-29 04:11:18,861 Epoch[48] Batch [1220]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.087424,	
2017-07-29 04:11:23,966 Epoch[48] Batch [1230]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087460,	
2017-07-29 04:11:29,097 Epoch[48] Batch [1240]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.087487,	
2017-07-29 04:11:34,272 Epoch[48] Batch [1250]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087415,	
2017-07-29 04:11:40,076 Epoch[48] Batch [1260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.087410,	
2017-07-29 04:11:45,525 Epoch[48] Batch [1270]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.087422,	
2017-07-29 04:11:50,700 Epoch[48] Batch [1280]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087475,	
2017-07-29 04:11:55,954 Epoch[48] Batch [1290]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087445,	
2017-07-29 04:12:01,285 Epoch[48] Batch [1300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087459,	
2017-07-29 04:12:06,831 Epoch[48] Batch [1310]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087411,	
2017-07-29 04:12:12,062 Epoch[48] Batch [1320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087437,	
2017-07-29 04:12:17,653 Epoch[48] Batch [1330]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087494,	
2017-07-29 04:12:22,731 Epoch[48] Batch [1340]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087449,	
2017-07-29 04:12:27,659 Epoch[48] Batch [1350]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.087482,	
2017-07-29 04:12:32,532 Epoch[48] Batch [1360]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.087503,	
2017-07-29 04:12:38,028 Epoch[48] Batch [1370]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087446,	
2017-07-29 04:12:43,243 Epoch[48] Batch [1380]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087494,	
2017-07-29 04:12:48,307 Epoch[48] Batch [1390]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087466,	
2017-07-29 04:12:53,778 Epoch[48] Batch [1400]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.087471,	
2017-07-29 04:12:58,673 Epoch[48] Batch [1410]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087473,	
2017-07-29 04:13:03,688 Epoch[48] Batch [1420]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087421,	
2017-07-29 04:13:08,738 Epoch[48] Batch [1430]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087467,	
2017-07-29 04:13:14,033 Epoch[48] Batch [1440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087494,	
2017-07-29 04:13:19,301 Epoch[48] Batch [1450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087521,	
2017-07-29 04:13:24,468 Epoch[48] Batch [1460]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.087478,	
2017-07-29 04:13:29,674 Epoch[48] Batch [1470]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087418,	
2017-07-29 04:13:34,962 Epoch[48] Batch [1480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087433,	
2017-07-29 04:13:38,135 Epoch[48] Train-FCNLogLoss=0.087429
2017-07-29 04:13:38,135 Epoch[48] Time cost=775.929
2017-07-29 04:13:38,984 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0049.params"
2017-07-29 04:13:40,662 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0049.states"
2017-07-29 04:13:46,692 Epoch[49] Batch [10]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.084313,	
2017-07-29 04:13:51,791 Epoch[49] Batch [20]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.082836,	
2017-07-29 04:13:56,763 Epoch[49] Batch [30]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086059,	
2017-07-29 04:14:02,037 Epoch[49] Batch [40]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086841,	
2017-07-29 04:14:07,051 Epoch[49] Batch [50]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.085117,	
2017-07-29 04:14:12,044 Epoch[49] Batch [60]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.083937,	
2017-07-29 04:14:17,022 Epoch[49] Batch [70]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.083188,	
2017-07-29 04:14:21,910 Epoch[49] Batch [80]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.083620,	
2017-07-29 04:14:26,746 Epoch[49] Batch [90]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.085103,	
2017-07-29 04:14:31,718 Epoch[49] Batch [100]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.085687,	
2017-07-29 04:14:36,808 Epoch[49] Batch [110]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.085862,	
2017-07-29 04:14:42,052 Epoch[49] Batch [120]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.085916,	
2017-07-29 04:14:47,098 Epoch[49] Batch [130]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.085853,	
2017-07-29 04:14:52,285 Epoch[49] Batch [140]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.085998,	
2017-07-29 04:14:57,432 Epoch[49] Batch [150]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086730,	
2017-07-29 04:15:02,888 Epoch[49] Batch [160]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.086186,	
2017-07-29 04:15:08,266 Epoch[49] Batch [170]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.086644,	
2017-07-29 04:15:13,735 Epoch[49] Batch [180]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086627,	
2017-07-29 04:15:18,782 Epoch[49] Batch [190]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086599,	
2017-07-29 04:15:24,051 Epoch[49] Batch [200]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086470,	
2017-07-29 04:15:29,088 Epoch[49] Batch [210]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.086647,	
2017-07-29 04:15:34,297 Epoch[49] Batch [220]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086756,	
2017-07-29 04:15:39,464 Epoch[49] Batch [230]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086277,	
2017-07-29 04:15:44,531 Epoch[49] Batch [240]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086045,	
2017-07-29 04:15:49,888 Epoch[49] Batch [250]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.086331,	
2017-07-29 04:15:55,065 Epoch[49] Batch [260]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086529,	
2017-07-29 04:16:00,291 Epoch[49] Batch [270]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086309,	
2017-07-29 04:16:05,549 Epoch[49] Batch [280]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086059,	
2017-07-29 04:16:10,640 Epoch[49] Batch [290]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086152,	
2017-07-29 04:16:15,845 Epoch[49] Batch [300]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.086104,	
2017-07-29 04:16:20,964 Epoch[49] Batch [310]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086175,	
2017-07-29 04:16:26,038 Epoch[49] Batch [320]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086382,	
2017-07-29 04:16:31,086 Epoch[49] Batch [330]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.086429,	
2017-07-29 04:16:36,091 Epoch[49] Batch [340]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.086494,	
2017-07-29 04:16:41,407 Epoch[49] Batch [350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086654,	
2017-07-29 04:16:46,335 Epoch[49] Batch [360]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086720,	
2017-07-29 04:16:51,306 Epoch[49] Batch [370]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086454,	
2017-07-29 04:16:56,426 Epoch[49] Batch [380]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 04:17:01,972 Epoch[49] Batch [390]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.086856,	
2017-07-29 04:17:07,239 Epoch[49] Batch [400]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087019,	
2017-07-29 04:17:12,585 Epoch[49] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087066,	
2017-07-29 04:17:17,786 Epoch[49] Batch [420]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087114,	
2017-07-29 04:17:22,791 Epoch[49] Batch [430]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.087000,	
2017-07-29 04:17:27,894 Epoch[49] Batch [440]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087190,	
2017-07-29 04:17:33,118 Epoch[49] Batch [450]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087156,	
2017-07-29 04:17:38,241 Epoch[49] Batch [460]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087240,	
2017-07-29 04:17:43,418 Epoch[49] Batch [470]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087026,	
2017-07-29 04:17:48,537 Epoch[49] Batch [480]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086990,	
2017-07-29 04:17:53,571 Epoch[49] Batch [490]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087133,	
2017-07-29 04:17:58,820 Epoch[49] Batch [500]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087056,	
2017-07-29 04:18:04,002 Epoch[49] Batch [510]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.087023,	
2017-07-29 04:18:09,162 Epoch[49] Batch [520]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087043,	
2017-07-29 04:18:14,230 Epoch[49] Batch [530]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087087,	
2017-07-29 04:18:19,493 Epoch[49] Batch [540]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087085,	
2017-07-29 04:18:24,594 Epoch[49] Batch [550]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.087122,	
2017-07-29 04:18:29,595 Epoch[49] Batch [560]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087047,	
2017-07-29 04:18:34,597 Epoch[49] Batch [570]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.087045,	
2017-07-29 04:18:39,642 Epoch[49] Batch [580]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086981,	
2017-07-29 04:18:44,556 Epoch[49] Batch [590]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.086890,	
2017-07-29 04:18:49,451 Epoch[49] Batch [600]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087043,	
2017-07-29 04:18:54,656 Epoch[49] Batch [610]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.086994,	
2017-07-29 04:18:59,680 Epoch[49] Batch [620]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.086983,	
2017-07-29 04:19:04,797 Epoch[49] Batch [630]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086798,	
2017-07-29 04:19:09,817 Epoch[49] Batch [640]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086776,	
2017-07-29 04:19:14,804 Epoch[49] Batch [650]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086785,	
2017-07-29 04:19:20,025 Epoch[49] Batch [660]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086777,	
2017-07-29 04:19:24,859 Epoch[49] Batch [670]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.086719,	
2017-07-29 04:19:29,913 Epoch[49] Batch [680]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086619,	
2017-07-29 04:19:35,137 Epoch[49] Batch [690]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086529,	
2017-07-29 04:19:40,199 Epoch[49] Batch [700]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086580,	
2017-07-29 04:19:45,460 Epoch[49] Batch [710]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086553,	
2017-07-29 04:19:50,934 Epoch[49] Batch [720]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086545,	
2017-07-29 04:19:56,019 Epoch[49] Batch [730]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086498,	
2017-07-29 04:20:01,492 Epoch[49] Batch [740]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086517,	
2017-07-29 04:20:06,583 Epoch[49] Batch [750]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086450,	
2017-07-29 04:20:12,133 Epoch[49] Batch [760]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.086490,	
2017-07-29 04:20:17,890 Epoch[49] Batch [770]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086579,	
2017-07-29 04:20:23,417 Epoch[49] Batch [780]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086654,	
2017-07-29 04:20:29,163 Epoch[49] Batch [790]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086585,	
2017-07-29 04:20:34,280 Epoch[49] Batch [800]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086623,	
2017-07-29 04:20:39,295 Epoch[49] Batch [810]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.086582,	
2017-07-29 04:20:44,027 Epoch[49] Batch [820]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.086661,	
2017-07-29 04:20:48,801 Epoch[49] Batch [830]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086654,	
2017-07-29 04:20:53,801 Epoch[49] Batch [840]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-29 04:20:58,622 Epoch[49] Batch [850]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086648,	
2017-07-29 04:21:03,372 Epoch[49] Batch [860]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.086709,	
2017-07-29 04:21:08,090 Epoch[49] Batch [870]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.086831,	
2017-07-29 04:21:12,738 Epoch[49] Batch [880]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.086796,	
2017-07-29 04:21:17,683 Epoch[49] Batch [890]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086818,	
2017-07-29 04:21:22,569 Epoch[49] Batch [900]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.086892,	
2017-07-29 04:21:27,802 Epoch[49] Batch [910]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086838,	
2017-07-29 04:21:32,602 Epoch[49] Batch [920]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086877,	
2017-07-29 04:21:37,684 Epoch[49] Batch [930]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086869,	
2017-07-29 04:21:42,715 Epoch[49] Batch [940]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086825,	
2017-07-29 04:21:48,103 Epoch[49] Batch [950]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.086764,	
2017-07-29 04:21:53,793 Epoch[49] Batch [960]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086722,	
2017-07-29 04:21:59,417 Epoch[49] Batch [970]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.086698,	
2017-07-29 04:22:05,022 Epoch[49] Batch [980]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.086786,	
2017-07-29 04:22:10,679 Epoch[49] Batch [990]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.086836,	
2017-07-29 04:22:16,155 Epoch[49] Batch [1000]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086851,	
2017-07-29 04:22:21,247 Epoch[49] Batch [1010]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086716,	
2017-07-29 04:22:26,400 Epoch[49] Batch [1020]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.086653,	
2017-07-29 04:22:31,588 Epoch[49] Batch [1030]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.086698,	
2017-07-29 04:22:37,068 Epoch[49] Batch [1040]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.086708,	
2017-07-29 04:22:42,516 Epoch[49] Batch [1050]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.086776,	
2017-07-29 04:22:47,392 Epoch[49] Batch [1060]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086725,	
2017-07-29 04:22:52,325 Epoch[49] Batch [1070]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.086681,	
2017-07-29 04:22:57,310 Epoch[49] Batch [1080]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086698,	
2017-07-29 04:23:02,449 Epoch[49] Batch [1090]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.086594,	
2017-07-29 04:23:07,280 Epoch[49] Batch [1100]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.086548,	
2017-07-29 04:23:12,296 Epoch[49] Batch [1110]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086493,	
2017-07-29 04:23:17,417 Epoch[49] Batch [1120]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086452,	
2017-07-29 04:23:22,317 Epoch[49] Batch [1130]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086476,	
2017-07-29 04:23:27,099 Epoch[49] Batch [1140]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086517,	
2017-07-29 04:23:32,038 Epoch[49] Batch [1150]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-29 04:23:36,907 Epoch[49] Batch [1160]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086417,	
2017-07-29 04:23:41,831 Epoch[49] Batch [1170]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086462,	
2017-07-29 04:23:46,779 Epoch[49] Batch [1180]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086433,	
2017-07-29 04:23:51,683 Epoch[49] Batch [1190]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086424,	
2017-07-29 04:23:56,928 Epoch[49] Batch [1200]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086389,	
2017-07-29 04:24:01,822 Epoch[49] Batch [1210]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086368,	
2017-07-29 04:24:07,251 Epoch[49] Batch [1220]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.086365,	
2017-07-29 04:24:12,209 Epoch[49] Batch [1230]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.086306,	
2017-07-29 04:24:17,343 Epoch[49] Batch [1240]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.086445,	
2017-07-29 04:24:22,316 Epoch[49] Batch [1250]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.086439,	
2017-07-29 04:24:27,238 Epoch[49] Batch [1260]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.086476,	
2017-07-29 04:24:32,225 Epoch[49] Batch [1270]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086472,	
2017-07-29 04:24:37,267 Epoch[49] Batch [1280]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-29 04:24:42,286 Epoch[49] Batch [1290]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.086405,	
2017-07-29 04:24:47,209 Epoch[49] Batch [1300]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.086428,	
2017-07-29 04:24:52,158 Epoch[49] Batch [1310]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-29 04:24:57,138 Epoch[49] Batch [1320]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086488,	
2017-07-29 04:25:02,043 Epoch[49] Batch [1330]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086514,	
2017-07-29 04:25:06,948 Epoch[49] Batch [1340]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086556,	
2017-07-29 04:25:11,880 Epoch[49] Batch [1350]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.086531,	
2017-07-29 04:25:16,788 Epoch[49] Batch [1360]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.086552,	
2017-07-29 04:25:21,781 Epoch[49] Batch [1370]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086536,	
2017-07-29 04:25:26,767 Epoch[49] Batch [1380]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086595,	
2017-07-29 04:25:31,551 Epoch[49] Batch [1390]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086575,	
2017-07-29 04:25:36,501 Epoch[49] Batch [1400]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.086592,	
2017-07-29 04:25:41,330 Epoch[49] Batch [1410]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.086588,	
2017-07-29 04:25:46,457 Epoch[49] Batch [1420]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086554,	
2017-07-29 04:25:52,168 Epoch[49] Batch [1430]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.086580,	
2017-07-29 04:25:57,859 Epoch[49] Batch [1440]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086518,	
2017-07-29 04:26:03,553 Epoch[49] Batch [1450]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086522,	
2017-07-29 04:26:09,253 Epoch[49] Batch [1460]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086620,	
2017-07-29 04:26:14,897 Epoch[49] Batch [1470]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086617,	
2017-07-29 04:26:20,602 Epoch[49] Batch [1480]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086585,	
2017-07-29 04:26:23,986 Epoch[49] Train-FCNLogLoss=0.086570
2017-07-29 04:26:23,986 Epoch[49] Time cost=763.324
2017-07-29 04:26:24,870 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0050.params"
2017-07-29 04:26:26,422 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0050.states"
2017-07-29 04:26:32,690 Epoch[50] Batch [10]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.087874,	
2017-07-29 04:26:38,156 Epoch[50] Batch [20]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.087761,	
2017-07-29 04:26:43,726 Epoch[50] Batch [30]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088445,	
2017-07-29 04:26:49,384 Epoch[50] Batch [40]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.087817,	
2017-07-29 04:26:55,052 Epoch[50] Batch [50]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.087171,	
2017-07-29 04:27:00,709 Epoch[50] Batch [60]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.086459,	
2017-07-29 04:27:06,238 Epoch[50] Batch [70]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.085752,	
2017-07-29 04:27:11,866 Epoch[50] Batch [80]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.085892,	
2017-07-29 04:27:16,779 Epoch[50] Batch [90]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.086377,	
2017-07-29 04:27:21,486 Epoch[50] Batch [100]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.085051,	
2017-07-29 04:27:26,339 Epoch[50] Batch [110]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.084403,	
2017-07-29 04:27:31,363 Epoch[50] Batch [120]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.084707,	
2017-07-29 04:27:36,699 Epoch[50] Batch [130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.084980,	
2017-07-29 04:27:41,540 Epoch[50] Batch [140]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.084962,	
2017-07-29 04:27:45,825 Epoch[50] Batch [150]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.084676,	
2017-07-29 04:27:50,144 Epoch[50] Batch [160]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.084562,	
2017-07-29 04:27:54,662 Epoch[50] Batch [170]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.084452,	
2017-07-29 04:27:59,214 Epoch[50] Batch [180]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.084919,	
2017-07-29 04:28:03,459 Epoch[50] Batch [190]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.085342,	
2017-07-29 04:28:07,673 Epoch[50] Batch [200]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.085252,	
2017-07-29 04:28:11,946 Epoch[50] Batch [210]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.085049,	
2017-07-29 04:28:16,279 Epoch[50] Batch [220]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.084970,	
2017-07-29 04:28:20,937 Epoch[50] Batch [230]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.084709,	
2017-07-29 04:28:25,126 Epoch[50] Batch [240]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.084816,	
2017-07-29 04:28:29,364 Epoch[50] Batch [250]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.084931,	
2017-07-29 04:28:33,814 Epoch[50] Batch [260]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.084773,	
2017-07-29 04:28:38,101 Epoch[50] Batch [270]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.084707,	
2017-07-29 04:28:42,969 Epoch[50] Batch [280]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.084814,	
2017-07-29 04:28:47,329 Epoch[50] Batch [290]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.084873,	
2017-07-29 04:28:51,696 Epoch[50] Batch [300]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.085339,	
2017-07-29 04:28:55,958 Epoch[50] Batch [310]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.085452,	
2017-07-29 04:29:00,057 Epoch[50] Batch [320]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.085316,	
2017-07-29 04:29:04,466 Epoch[50] Batch [330]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.085394,	
2017-07-29 04:29:08,944 Epoch[50] Batch [340]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.085267,	
2017-07-29 04:29:13,070 Epoch[50] Batch [350]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.085221,	
2017-07-29 04:29:17,257 Epoch[50] Batch [360]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.085231,	
2017-07-29 04:29:21,643 Epoch[50] Batch [370]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.085244,	
2017-07-29 04:29:25,838 Epoch[50] Batch [380]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.085396,	
2017-07-29 04:29:30,376 Epoch[50] Batch [390]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.085145,	
2017-07-29 04:29:34,903 Epoch[50] Batch [400]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.085120,	
2017-07-29 04:29:39,421 Epoch[50] Batch [410]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.085140,	
2017-07-29 04:29:43,623 Epoch[50] Batch [420]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085121,	
2017-07-29 04:29:47,860 Epoch[50] Batch [430]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.084908,	
2017-07-29 04:29:52,622 Epoch[50] Batch [440]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.084864,	
2017-07-29 04:29:56,832 Epoch[50] Batch [450]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.084811,	
2017-07-29 04:30:01,075 Epoch[50] Batch [460]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.084795,	
2017-07-29 04:30:05,366 Epoch[50] Batch [470]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.084839,	
2017-07-29 04:30:10,008 Epoch[50] Batch [480]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.084848,	
2017-07-29 04:30:14,192 Epoch[50] Batch [490]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.084754,	
2017-07-29 04:30:18,411 Epoch[50] Batch [500]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.084900,	
2017-07-29 04:30:22,816 Epoch[50] Batch [510]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.084828,	
2017-07-29 04:30:27,113 Epoch[50] Batch [520]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.084887,	
2017-07-29 04:30:32,157 Epoch[50] Batch [530]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.085192,	
2017-07-29 04:30:36,360 Epoch[50] Batch [540]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085232,	
2017-07-29 04:30:40,656 Epoch[50] Batch [550]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.085148,	
2017-07-29 04:30:45,116 Epoch[50] Batch [560]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.085174,	
2017-07-29 04:30:49,544 Epoch[50] Batch [570]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.085255,	
2017-07-29 04:30:53,631 Epoch[50] Batch [580]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.085302,	
2017-07-29 04:30:58,052 Epoch[50] Batch [590]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.085338,	
2017-07-29 04:31:02,179 Epoch[50] Batch [600]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.085440,	
2017-07-29 04:31:06,708 Epoch[50] Batch [610]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.085499,	
2017-07-29 04:31:11,161 Epoch[50] Batch [620]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.085544,	
2017-07-29 04:31:15,409 Epoch[50] Batch [630]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.085536,	
2017-07-29 04:31:19,738 Epoch[50] Batch [640]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.085554,	
2017-07-29 04:31:24,145 Epoch[50] Batch [650]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.085671,	
2017-07-29 04:31:28,473 Epoch[50] Batch [660]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.085679,	
2017-07-29 04:31:32,949 Epoch[50] Batch [670]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.085649,	
2017-07-29 04:31:37,292 Epoch[50] Batch [680]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.085623,	
2017-07-29 04:31:41,539 Epoch[50] Batch [690]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.085706,	
2017-07-29 04:31:45,649 Epoch[50] Batch [700]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.085600,	
2017-07-29 04:31:49,916 Epoch[50] Batch [710]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.085614,	
2017-07-29 04:31:54,409 Epoch[50] Batch [720]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.085446,	
2017-07-29 04:31:58,701 Epoch[50] Batch [730]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.085448,	
2017-07-29 04:32:03,074 Epoch[50] Batch [740]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.085401,	
2017-07-29 04:32:07,589 Epoch[50] Batch [750]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.085267,	
2017-07-29 04:32:11,995 Epoch[50] Batch [760]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.085540,	
2017-07-29 04:32:16,447 Epoch[50] Batch [770]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.085535,	
2017-07-29 04:32:20,957 Epoch[50] Batch [780]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.085493,	
2017-07-29 04:32:25,471 Epoch[50] Batch [790]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.085452,	
2017-07-29 04:32:30,021 Epoch[50] Batch [800]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.085581,	
2017-07-29 04:32:34,293 Epoch[50] Batch [810]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.085568,	
2017-07-29 04:32:38,486 Epoch[50] Batch [820]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.085420,	
2017-07-29 04:32:42,744 Epoch[50] Batch [830]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.085504,	
2017-07-29 04:32:47,154 Epoch[50] Batch [840]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.085453,	
2017-07-29 04:32:51,644 Epoch[50] Batch [850]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.085547,	
2017-07-29 04:32:56,128 Epoch[50] Batch [860]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.085555,	
2017-07-29 04:33:00,901 Epoch[50] Batch [870]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.085651,	
2017-07-29 04:33:05,484 Epoch[50] Batch [880]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.085831,	
2017-07-29 04:33:09,807 Epoch[50] Batch [890]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.085834,	
2017-07-29 04:33:14,161 Epoch[50] Batch [900]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.085835,	
2017-07-29 04:33:18,529 Epoch[50] Batch [910]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.085846,	
2017-07-29 04:33:22,797 Epoch[50] Batch [920]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.085883,	
2017-07-29 04:33:27,351 Epoch[50] Batch [930]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.085829,	
2017-07-29 04:33:31,684 Epoch[50] Batch [940]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.085887,	
2017-07-29 04:33:36,141 Epoch[50] Batch [950]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.085898,	
2017-07-29 04:33:40,603 Epoch[50] Batch [960]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.085900,	
2017-07-29 04:33:44,946 Epoch[50] Batch [970]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.086078,	
2017-07-29 04:33:49,137 Epoch[50] Batch [980]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086097,	
2017-07-29 04:33:53,691 Epoch[50] Batch [990]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086172,	
2017-07-29 04:33:58,059 Epoch[50] Batch [1000]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086112,	
2017-07-29 04:34:02,522 Epoch[50] Batch [1010]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.086146,	
2017-07-29 04:34:06,758 Epoch[50] Batch [1020]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.086285,	
2017-07-29 04:34:11,159 Epoch[50] Batch [1030]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.086287,	
2017-07-29 04:34:15,588 Epoch[50] Batch [1040]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.086178,	
2017-07-29 04:34:19,879 Epoch[50] Batch [1050]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.086218,	
2017-07-29 04:34:24,270 Epoch[50] Batch [1060]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.086263,	
2017-07-29 04:34:28,558 Epoch[50] Batch [1070]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-29 04:34:32,733 Epoch[50] Batch [1080]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086334,	
2017-07-29 04:34:36,998 Epoch[50] Batch [1090]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.086355,	
2017-07-29 04:34:41,409 Epoch[50] Batch [1100]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.086427,	
2017-07-29 04:34:45,812 Epoch[50] Batch [1110]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.086437,	
2017-07-29 04:34:50,230 Epoch[50] Batch [1120]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.086431,	
2017-07-29 04:34:54,423 Epoch[50] Batch [1130]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086397,	
2017-07-29 04:34:58,681 Epoch[50] Batch [1140]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086370,	
2017-07-29 04:35:03,002 Epoch[50] Batch [1150]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086424,	
2017-07-29 04:35:07,365 Epoch[50] Batch [1160]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.086423,	
2017-07-29 04:35:11,652 Epoch[50] Batch [1170]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.086443,	
2017-07-29 04:35:16,002 Epoch[50] Batch [1180]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.086451,	
2017-07-29 04:35:20,324 Epoch[50] Batch [1190]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086416,	
2017-07-29 04:35:24,557 Epoch[50] Batch [1200]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.086465,	
2017-07-29 04:35:28,874 Epoch[50] Batch [1210]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086437,	
2017-07-29 04:35:33,166 Epoch[50] Batch [1220]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.086514,	
2017-07-29 04:35:37,725 Epoch[50] Batch [1230]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086439,	
2017-07-29 04:35:42,098 Epoch[50] Batch [1240]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.086499,	
2017-07-29 04:35:46,457 Epoch[50] Batch [1250]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-29 04:35:50,681 Epoch[50] Batch [1260]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.086492,	
2017-07-29 04:35:55,154 Epoch[50] Batch [1270]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.086482,	
2017-07-29 04:35:59,472 Epoch[50] Batch [1280]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086518,	
2017-07-29 04:36:03,791 Epoch[50] Batch [1290]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086464,	
2017-07-29 04:36:08,304 Epoch[50] Batch [1300]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086456,	
2017-07-29 04:36:12,598 Epoch[50] Batch [1310]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.086446,	
2017-07-29 04:36:16,772 Epoch[50] Batch [1320]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086435,	
2017-07-29 04:36:21,074 Epoch[50] Batch [1330]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.086456,	
2017-07-29 04:36:25,427 Epoch[50] Batch [1340]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086388,	
2017-07-29 04:36:29,918 Epoch[50] Batch [1350]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.086349,	
2017-07-29 04:36:34,328 Epoch[50] Batch [1360]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.086346,	
2017-07-29 04:36:38,888 Epoch[50] Batch [1370]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086409,	
2017-07-29 04:36:43,196 Epoch[50] Batch [1380]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.086373,	
2017-07-29 04:36:47,492 Epoch[50] Batch [1390]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.086357,	
2017-07-29 04:36:51,766 Epoch[50] Batch [1400]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.086416,	
2017-07-29 04:36:55,868 Epoch[50] Batch [1410]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.086398,	
2017-07-29 04:37:00,122 Epoch[50] Batch [1420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.086420,	
2017-07-29 04:37:04,437 Epoch[50] Batch [1430]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086479,	
2017-07-29 04:37:08,807 Epoch[50] Batch [1440]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.086467,	
2017-07-29 04:37:13,126 Epoch[50] Batch [1450]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086491,	
2017-07-29 04:37:17,396 Epoch[50] Batch [1460]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.086463,	
2017-07-29 04:37:21,842 Epoch[50] Batch [1470]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.086429,	
2017-07-29 04:37:26,395 Epoch[50] Batch [1480]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086461,	
2017-07-29 04:37:28,885 Epoch[50] Train-FCNLogLoss=0.086418
2017-07-29 04:37:28,886 Epoch[50] Time cost=662.463
2017-07-29 04:37:29,769 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0051.params"
2017-07-29 04:37:31,445 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0051.states"
2017-07-29 04:37:36,589 Epoch[51] Batch [10]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.085372,	
2017-07-29 04:37:41,004 Epoch[51] Batch [20]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.090046,	
2017-07-29 04:37:45,443 Epoch[51] Batch [30]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.092526,	
2017-07-29 04:37:49,888 Epoch[51] Batch [40]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.093657,	
2017-07-29 04:37:54,194 Epoch[51] Batch [50]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.092802,	
2017-07-29 04:37:58,584 Epoch[51] Batch [60]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.092456,	
2017-07-29 04:38:02,946 Epoch[51] Batch [70]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.091391,	
2017-07-29 04:38:07,246 Epoch[51] Batch [80]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.090845,	
2017-07-29 04:38:11,317 Epoch[51] Batch [90]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.090519,	
2017-07-29 04:38:15,581 Epoch[51] Batch [100]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.089789,	
2017-07-29 04:38:19,857 Epoch[51] Batch [110]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.089056,	
2017-07-29 04:38:24,242 Epoch[51] Batch [120]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088799,	
2017-07-29 04:38:28,452 Epoch[51] Batch [130]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.088524,	
2017-07-29 04:38:32,805 Epoch[51] Batch [140]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087753,	
2017-07-29 04:38:37,091 Epoch[51] Batch [150]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087874,	
2017-07-29 04:38:41,426 Epoch[51] Batch [160]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087299,	
2017-07-29 04:38:45,645 Epoch[51] Batch [170]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.086772,	
2017-07-29 04:38:49,903 Epoch[51] Batch [180]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.086496,	
2017-07-29 04:38:53,972 Epoch[51] Batch [190]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.086610,	
2017-07-29 04:38:58,242 Epoch[51] Batch [200]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.086407,	
2017-07-29 04:39:02,474 Epoch[51] Batch [210]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.086493,	
2017-07-29 04:39:06,771 Epoch[51] Batch [220]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.086452,	
2017-07-29 04:39:10,987 Epoch[51] Batch [230]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.086346,	
2017-07-29 04:39:15,456 Epoch[51] Batch [240]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087010,	
2017-07-29 04:39:19,968 Epoch[51] Batch [250]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087572,	
2017-07-29 04:39:24,424 Epoch[51] Batch [260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087732,	
2017-07-29 04:39:28,934 Epoch[51] Batch [270]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087648,	
2017-07-29 04:39:33,327 Epoch[51] Batch [280]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087864,	
2017-07-29 04:39:37,718 Epoch[51] Batch [290]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087864,	
2017-07-29 04:39:42,051 Epoch[51] Batch [300]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087763,	
2017-07-29 04:39:46,451 Epoch[51] Batch [310]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087611,	
2017-07-29 04:39:50,703 Epoch[51] Batch [320]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087588,	
2017-07-29 04:39:54,908 Epoch[51] Batch [330]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.087434,	
2017-07-29 04:39:59,158 Epoch[51] Batch [340]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087539,	
2017-07-29 04:40:03,533 Epoch[51] Batch [350]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087605,	
2017-07-29 04:40:07,832 Epoch[51] Batch [360]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087765,	
2017-07-29 04:40:12,078 Epoch[51] Batch [370]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087854,	
2017-07-29 04:40:16,422 Epoch[51] Batch [380]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.087705,	
2017-07-29 04:40:20,819 Epoch[51] Batch [390]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087787,	
2017-07-29 04:40:25,251 Epoch[51] Batch [400]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088063,	
2017-07-29 04:40:29,535 Epoch[51] Batch [410]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.088131,	
2017-07-29 04:40:33,661 Epoch[51] Batch [420]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.088261,	
2017-07-29 04:40:38,002 Epoch[51] Batch [430]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088312,	
2017-07-29 04:40:42,464 Epoch[51] Batch [440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.088310,	
2017-07-29 04:40:46,777 Epoch[51] Batch [450]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088392,	
2017-07-29 04:40:51,294 Epoch[51] Batch [460]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088406,	
2017-07-29 04:40:55,639 Epoch[51] Batch [470]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088204,	
2017-07-29 04:40:59,862 Epoch[51] Batch [480]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.088343,	
2017-07-29 04:41:04,280 Epoch[51] Batch [490]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088255,	
2017-07-29 04:41:08,660 Epoch[51] Batch [500]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088234,	
2017-07-29 04:41:13,009 Epoch[51] Batch [510]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.088423,	
2017-07-29 04:41:17,437 Epoch[51] Batch [520]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088205,	
2017-07-29 04:41:21,787 Epoch[51] Batch [530]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.088281,	
2017-07-29 04:41:26,098 Epoch[51] Batch [540]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.088183,	
2017-07-29 04:41:30,274 Epoch[51] Batch [550]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.088264,	
2017-07-29 04:41:34,500 Epoch[51] Batch [560]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.088230,	
2017-07-29 04:41:38,927 Epoch[51] Batch [570]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088143,	
2017-07-29 04:41:43,146 Epoch[51] Batch [580]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.088153,	
2017-07-29 04:41:47,520 Epoch[51] Batch [590]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087998,	
2017-07-29 04:41:51,963 Epoch[51] Batch [600]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.088070,	
2017-07-29 04:41:56,472 Epoch[51] Batch [610]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088003,	
2017-07-29 04:42:00,804 Epoch[51] Batch [620]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087854,	
2017-07-29 04:42:05,107 Epoch[51] Batch [630]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.087814,	
2017-07-29 04:42:09,374 Epoch[51] Batch [640]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087953,	
2017-07-29 04:42:13,615 Epoch[51] Batch [650]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087913,	
2017-07-29 04:42:17,990 Epoch[51] Batch [660]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087840,	
2017-07-29 04:42:22,350 Epoch[51] Batch [670]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.087747,	
2017-07-29 04:42:26,775 Epoch[51] Batch [680]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087726,	
2017-07-29 04:42:31,212 Epoch[51] Batch [690]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087689,	
2017-07-29 04:42:35,562 Epoch[51] Batch [700]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087777,	
2017-07-29 04:42:39,797 Epoch[51] Batch [710]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.087763,	
2017-07-29 04:42:44,035 Epoch[51] Batch [720]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087785,	
2017-07-29 04:42:48,356 Epoch[51] Batch [730]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087747,	
2017-07-29 04:42:52,726 Epoch[51] Batch [740]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087763,	
2017-07-29 04:42:57,061 Epoch[51] Batch [750]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087743,	
2017-07-29 04:43:01,378 Epoch[51] Batch [760]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087787,	
2017-07-29 04:43:05,646 Epoch[51] Batch [770]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087824,	
2017-07-29 04:43:09,970 Epoch[51] Batch [780]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087843,	
2017-07-29 04:43:14,270 Epoch[51] Batch [790]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.087799,	
2017-07-29 04:43:18,714 Epoch[51] Batch [800]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087731,	
2017-07-29 04:43:22,994 Epoch[51] Batch [810]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.087722,	
2017-07-29 04:43:27,410 Epoch[51] Batch [820]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087771,	
2017-07-29 04:43:31,730 Epoch[51] Batch [830]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087893,	
2017-07-29 04:43:36,244 Epoch[51] Batch [840]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087791,	
2017-07-29 04:43:40,526 Epoch[51] Batch [850]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087802,	
2017-07-29 04:43:44,810 Epoch[51] Batch [860]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087647,	
2017-07-29 04:43:49,182 Epoch[51] Batch [870]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087680,	
2017-07-29 04:43:53,586 Epoch[51] Batch [880]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087698,	
2017-07-29 04:43:57,908 Epoch[51] Batch [890]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087631,	
2017-07-29 04:44:02,244 Epoch[51] Batch [900]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087645,	
2017-07-29 04:44:06,355 Epoch[51] Batch [910]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.087661,	
2017-07-29 04:44:10,551 Epoch[51] Batch [920]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.087648,	
2017-07-29 04:44:14,847 Epoch[51] Batch [930]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087488,	
2017-07-29 04:44:19,378 Epoch[51] Batch [940]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087604,	
2017-07-29 04:44:23,709 Epoch[51] Batch [950]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087572,	
2017-07-29 04:44:28,086 Epoch[51] Batch [960]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087551,	
2017-07-29 04:44:32,521 Epoch[51] Batch [970]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087653,	
2017-07-29 04:44:36,993 Epoch[51] Batch [980]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087583,	
2017-07-29 04:44:41,330 Epoch[51] Batch [990]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087537,	
2017-07-29 04:44:45,647 Epoch[51] Batch [1000]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087639,	
2017-07-29 04:44:49,948 Epoch[51] Batch [1010]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.087701,	
2017-07-29 04:44:54,281 Epoch[51] Batch [1020]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087675,	
2017-07-29 04:44:58,549 Epoch[51] Batch [1030]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087681,	
2017-07-29 04:45:02,859 Epoch[51] Batch [1040]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.087673,	
2017-07-29 04:45:07,162 Epoch[51] Batch [1050]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.087672,	
2017-07-29 04:45:11,437 Epoch[51] Batch [1060]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087640,	
2017-07-29 04:45:15,732 Epoch[51] Batch [1070]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087595,	
2017-07-29 04:45:20,099 Epoch[51] Batch [1080]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087656,	
2017-07-29 04:45:24,329 Epoch[51] Batch [1090]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087546,	
2017-07-29 04:45:28,673 Epoch[51] Batch [1100]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.087401,	
2017-07-29 04:45:33,044 Epoch[51] Batch [1110]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087459,	
2017-07-29 04:45:37,380 Epoch[51] Batch [1120]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087411,	
2017-07-29 04:45:41,796 Epoch[51] Batch [1130]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087396,	
2017-07-29 04:45:46,196 Epoch[51] Batch [1140]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087461,	
2017-07-29 04:45:50,669 Epoch[51] Batch [1150]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087519,	
2017-07-29 04:45:55,086 Epoch[51] Batch [1160]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087406,	
2017-07-29 04:45:59,322 Epoch[51] Batch [1170]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087361,	
2017-07-29 04:46:03,633 Epoch[51] Batch [1180]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.087367,	
2017-07-29 04:46:07,920 Epoch[51] Batch [1190]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087293,	
2017-07-29 04:46:12,323 Epoch[51] Batch [1200]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087268,	
2017-07-29 04:46:16,662 Epoch[51] Batch [1210]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087217,	
2017-07-29 04:46:21,191 Epoch[51] Batch [1220]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087155,	
2017-07-29 04:46:25,589 Epoch[51] Batch [1230]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087236,	
2017-07-29 04:46:29,871 Epoch[51] Batch [1240]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087242,	
2017-07-29 04:46:34,203 Epoch[51] Batch [1250]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087305,	
2017-07-29 04:46:38,514 Epoch[51] Batch [1260]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.087328,	
2017-07-29 04:46:42,830 Epoch[51] Batch [1270]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087305,	
2017-07-29 04:46:47,220 Epoch[51] Batch [1280]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087287,	
2017-07-29 04:46:51,684 Epoch[51] Batch [1290]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087256,	
2017-07-29 04:46:56,107 Epoch[51] Batch [1300]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087211,	
2017-07-29 04:47:00,421 Epoch[51] Batch [1310]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087185,	
2017-07-29 04:47:04,611 Epoch[51] Batch [1320]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.087092,	
2017-07-29 04:47:08,797 Epoch[51] Batch [1330]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.087095,	
2017-07-29 04:47:13,152 Epoch[51] Batch [1340]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087117,	
2017-07-29 04:47:17,442 Epoch[51] Batch [1350]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.087108,	
2017-07-29 04:47:21,687 Epoch[51] Batch [1360]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087045,	
2017-07-29 04:47:25,910 Epoch[51] Batch [1370]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.087064,	
2017-07-29 04:47:30,131 Epoch[51] Batch [1380]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087038,	
2017-07-29 04:47:34,392 Epoch[51] Batch [1390]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087034,	
2017-07-29 04:47:38,826 Epoch[51] Batch [1400]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087080,	
2017-07-29 04:47:43,281 Epoch[51] Batch [1410]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087155,	
2017-07-29 04:47:47,432 Epoch[51] Batch [1420]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.087139,	
2017-07-29 04:47:51,692 Epoch[51] Batch [1430]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087157,	
2017-07-29 04:47:56,079 Epoch[51] Batch [1440]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087072,	
2017-07-29 04:48:00,521 Epoch[51] Batch [1450]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087004,	
2017-07-29 04:48:04,734 Epoch[51] Batch [1460]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086999,	
2017-07-29 04:48:08,982 Epoch[51] Batch [1470]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.086984,	
2017-07-29 04:48:13,354 Epoch[51] Batch [1480]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.086975,	
2017-07-29 04:48:15,950 Epoch[51] Train-FCNLogLoss=0.086956
2017-07-29 04:48:15,950 Epoch[51] Time cost=644.504
2017-07-29 04:48:16,701 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0052.params"
2017-07-29 04:48:18,365 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0052.states"
2017-07-29 04:48:23,381 Epoch[52] Batch [10]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.080846,	
2017-07-29 04:48:27,796 Epoch[52] Batch [20]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.088356,	
2017-07-29 04:48:32,182 Epoch[52] Batch [30]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087056,	
2017-07-29 04:48:36,500 Epoch[52] Batch [40]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088762,	
2017-07-29 04:48:41,003 Epoch[52] Batch [50]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087429,	
2017-07-29 04:48:45,134 Epoch[52] Batch [60]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.088118,	
2017-07-29 04:48:49,565 Epoch[52] Batch [70]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.087524,	
2017-07-29 04:48:53,805 Epoch[52] Batch [80]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.088290,	
2017-07-29 04:48:58,089 Epoch[52] Batch [90]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.088301,	
2017-07-29 04:49:02,628 Epoch[52] Batch [100]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088748,	
2017-07-29 04:49:07,051 Epoch[52] Batch [110]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088961,	
2017-07-29 04:49:11,215 Epoch[52] Batch [120]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.088683,	
2017-07-29 04:49:15,601 Epoch[52] Batch [130]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088560,	
2017-07-29 04:49:19,863 Epoch[52] Batch [140]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088648,	
2017-07-29 04:49:24,196 Epoch[52] Batch [150]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.088328,	
2017-07-29 04:49:28,579 Epoch[52] Batch [160]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088360,	
2017-07-29 04:49:33,130 Epoch[52] Batch [170]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088542,	
2017-07-29 04:49:37,341 Epoch[52] Batch [180]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.088110,	
2017-07-29 04:49:41,517 Epoch[52] Batch [190]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.088042,	
2017-07-29 04:49:45,724 Epoch[52] Batch [200]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.087783,	
2017-07-29 04:49:50,127 Epoch[52] Batch [210]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087879,	
2017-07-29 04:49:54,418 Epoch[52] Batch [220]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.087848,	
2017-07-29 04:49:58,806 Epoch[52] Batch [230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087640,	
2017-07-29 04:50:03,100 Epoch[52] Batch [240]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088161,	
2017-07-29 04:50:07,499 Epoch[52] Batch [250]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087900,	
2017-07-29 04:50:11,799 Epoch[52] Batch [260]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.087608,	
2017-07-29 04:50:16,113 Epoch[52] Batch [270]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087430,	
2017-07-29 04:50:20,307 Epoch[52] Batch [280]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.087309,	
2017-07-29 04:50:24,622 Epoch[52] Batch [290]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087129,	
2017-07-29 04:50:29,029 Epoch[52] Batch [300]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087211,	
2017-07-29 04:50:33,431 Epoch[52] Batch [310]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087377,	
2017-07-29 04:50:37,879 Epoch[52] Batch [320]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087563,	
2017-07-29 04:50:42,120 Epoch[52] Batch [330]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087448,	
2017-07-29 04:50:46,443 Epoch[52] Batch [340]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087377,	
2017-07-29 04:50:50,782 Epoch[52] Batch [350]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087580,	
2017-07-29 04:50:55,261 Epoch[52] Batch [360]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087403,	
2017-07-29 04:50:59,514 Epoch[52] Batch [370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087399,	
2017-07-29 04:51:03,840 Epoch[52] Batch [380]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087448,	
2017-07-29 04:51:08,150 Epoch[52] Batch [390]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.087467,	
2017-07-29 04:51:12,259 Epoch[52] Batch [400]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.087354,	
2017-07-29 04:51:16,642 Epoch[52] Batch [410]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.087357,	
2017-07-29 04:51:20,898 Epoch[52] Batch [420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.087184,	
2017-07-29 04:51:25,203 Epoch[52] Batch [430]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087193,	
2017-07-29 04:51:29,292 Epoch[52] Batch [440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.087348,	
2017-07-29 04:51:33,438 Epoch[52] Batch [450]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.087086,	
2017-07-29 04:51:37,472 Epoch[52] Batch [460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.087207,	
2017-07-29 04:51:41,712 Epoch[52] Batch [470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087325,	
2017-07-29 04:51:46,107 Epoch[52] Batch [480]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087202,	
2017-07-29 04:51:50,335 Epoch[52] Batch [490]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087145,	
2017-07-29 04:51:54,577 Epoch[52] Batch [500]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087051,	
2017-07-29 04:51:58,769 Epoch[52] Batch [510]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086980,	
2017-07-29 04:52:02,852 Epoch[52] Batch [520]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.087068,	
2017-07-29 04:52:07,251 Epoch[52] Batch [530]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087103,	
2017-07-29 04:52:11,624 Epoch[52] Batch [540]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087204,	
2017-07-29 04:52:15,922 Epoch[52] Batch [550]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087185,	
2017-07-29 04:52:20,323 Epoch[52] Batch [560]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087154,	
2017-07-29 04:52:24,526 Epoch[52] Batch [570]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087238,	
2017-07-29 04:52:28,811 Epoch[52] Batch [580]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087237,	
2017-07-29 04:52:33,075 Epoch[52] Batch [590]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.087386,	
2017-07-29 04:52:37,459 Epoch[52] Batch [600]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087292,	
2017-07-29 04:52:41,761 Epoch[52] Batch [610]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.087220,	
2017-07-29 04:52:46,160 Epoch[52] Batch [620]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087169,	
2017-07-29 04:52:50,511 Epoch[52] Batch [630]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087147,	
2017-07-29 04:52:54,784 Epoch[52] Batch [640]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087132,	
2017-07-29 04:52:59,075 Epoch[52] Batch [650]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.087071,	
2017-07-29 04:53:03,432 Epoch[52] Batch [660]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086986,	
2017-07-29 04:53:07,532 Epoch[52] Batch [670]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.086854,	
2017-07-29 04:53:11,748 Epoch[52] Batch [680]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.086799,	
2017-07-29 04:53:15,912 Epoch[52] Batch [690]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.087005,	
2017-07-29 04:53:20,106 Epoch[52] Batch [700]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086983,	
2017-07-29 04:53:24,219 Epoch[52] Batch [710]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.086940,	
2017-07-29 04:53:28,438 Epoch[52] Batch [720]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.086808,	
2017-07-29 04:53:32,688 Epoch[52] Batch [730]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.086757,	
2017-07-29 04:53:36,916 Epoch[52] Batch [740]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.086815,	
2017-07-29 04:53:41,371 Epoch[52] Batch [750]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.086756,	
2017-07-29 04:53:45,601 Epoch[52] Batch [760]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.086607,	
2017-07-29 04:53:49,775 Epoch[52] Batch [770]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.086694,	
2017-07-29 04:53:54,033 Epoch[52] Batch [780]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.086706,	
2017-07-29 04:53:58,384 Epoch[52] Batch [790]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086682,	
2017-07-29 04:54:02,517 Epoch[52] Batch [800]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-29 04:54:06,864 Epoch[52] Batch [810]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.086691,	
2017-07-29 04:54:11,076 Epoch[52] Batch [820]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086672,	
2017-07-29 04:54:15,324 Epoch[52] Batch [830]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.086630,	
2017-07-29 04:54:19,524 Epoch[52] Batch [840]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.086647,	
2017-07-29 04:54:23,610 Epoch[52] Batch [850]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.086712,	
2017-07-29 04:54:27,787 Epoch[52] Batch [860]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086739,	
2017-07-29 04:54:32,020 Epoch[52] Batch [870]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.086848,	
2017-07-29 04:54:36,314 Epoch[52] Batch [880]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.086794,	
2017-07-29 04:54:40,429 Epoch[52] Batch [890]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.086764,	
2017-07-29 04:54:44,703 Epoch[52] Batch [900]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.086699,	
2017-07-29 04:54:49,031 Epoch[52] Batch [910]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.086628,	
2017-07-29 04:54:53,281 Epoch[52] Batch [920]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.086536,	
2017-07-29 04:54:57,599 Epoch[52] Batch [930]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086563,	
2017-07-29 04:55:02,068 Epoch[52] Batch [940]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086538,	
2017-07-29 04:55:06,427 Epoch[52] Batch [950]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086558,	
2017-07-29 04:55:10,865 Epoch[52] Batch [960]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.086539,	
2017-07-29 04:55:15,208 Epoch[52] Batch [970]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.086564,	
2017-07-29 04:55:19,484 Epoch[52] Batch [980]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086615,	
2017-07-29 04:55:23,753 Epoch[52] Batch [990]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.086634,	
2017-07-29 04:55:28,151 Epoch[52] Batch [1000]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.086597,	
2017-07-29 04:55:32,476 Epoch[52] Batch [1010]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086531,	
2017-07-29 04:55:36,761 Epoch[52] Batch [1020]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.086581,	
2017-07-29 04:55:41,114 Epoch[52] Batch [1030]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 04:55:45,466 Epoch[52] Batch [1040]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086728,	
2017-07-29 04:55:49,801 Epoch[52] Batch [1050]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086857,	
2017-07-29 04:55:54,143 Epoch[52] Batch [1060]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.086922,	
2017-07-29 04:55:58,592 Epoch[52] Batch [1070]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.086953,	
2017-07-29 04:56:02,835 Epoch[52] Batch [1080]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.086966,	
2017-07-29 04:56:06,966 Epoch[52] Batch [1090]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087013,	
2017-07-29 04:56:11,111 Epoch[52] Batch [1100]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.086926,	
2017-07-29 04:56:15,491 Epoch[52] Batch [1110]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.086982,	
2017-07-29 04:56:19,738 Epoch[52] Batch [1120]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.086903,	
2017-07-29 04:56:24,137 Epoch[52] Batch [1130]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.086828,	
2017-07-29 04:56:28,536 Epoch[52] Batch [1140]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.086825,	
2017-07-29 04:56:32,899 Epoch[52] Batch [1150]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.086810,	
2017-07-29 04:56:37,188 Epoch[52] Batch [1160]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.086815,	
2017-07-29 04:56:41,528 Epoch[52] Batch [1170]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.086822,	
2017-07-29 04:56:45,769 Epoch[52] Batch [1180]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.086740,	
2017-07-29 04:56:50,271 Epoch[52] Batch [1190]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.086750,	
2017-07-29 04:56:54,641 Epoch[52] Batch [1200]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.086717,	
2017-07-29 04:56:58,975 Epoch[52] Batch [1210]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086675,	
2017-07-29 04:57:03,291 Epoch[52] Batch [1220]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-29 04:57:07,532 Epoch[52] Batch [1230]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.086696,	
2017-07-29 04:57:11,888 Epoch[52] Batch [1240]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086615,	
2017-07-29 04:57:16,206 Epoch[52] Batch [1250]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086693,	
2017-07-29 04:57:20,413 Epoch[52] Batch [1260]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.086726,	
2017-07-29 04:57:24,639 Epoch[52] Batch [1270]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.086693,	
2017-07-29 04:57:29,037 Epoch[52] Batch [1280]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.086647,	
2017-07-29 04:57:33,435 Epoch[52] Batch [1290]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.086654,	
2017-07-29 04:57:37,747 Epoch[52] Batch [1300]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.086649,	
2017-07-29 04:57:42,095 Epoch[52] Batch [1310]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.086612,	
2017-07-29 04:57:46,327 Epoch[52] Batch [1320]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.086649,	
2017-07-29 04:57:50,811 Epoch[52] Batch [1330]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086680,	
2017-07-29 04:57:55,273 Epoch[52] Batch [1340]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.086754,	
2017-07-29 04:57:59,597 Epoch[52] Batch [1350]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086679,	
2017-07-29 04:58:03,875 Epoch[52] Batch [1360]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.086649,	
2017-07-29 04:58:08,089 Epoch[52] Batch [1370]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.086649,	
2017-07-29 04:58:12,506 Epoch[52] Batch [1380]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.086665,	
2017-07-29 04:58:16,816 Epoch[52] Batch [1390]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.086668,	
2017-07-29 04:58:21,077 Epoch[52] Batch [1400]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 04:58:25,412 Epoch[52] Batch [1410]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086676,	
2017-07-29 04:58:29,663 Epoch[52] Batch [1420]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.086646,	
2017-07-29 04:58:33,951 Epoch[52] Batch [1430]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.086670,	
2017-07-29 04:58:38,369 Epoch[52] Batch [1440]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.086637,	
2017-07-29 04:58:42,707 Epoch[52] Batch [1450]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.086549,	
2017-07-29 04:58:46,979 Epoch[52] Batch [1460]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.086534,	
2017-07-29 04:58:51,421 Epoch[52] Batch [1470]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.086464,	
2017-07-29 04:58:55,808 Epoch[52] Batch [1480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086445,	
2017-07-29 04:58:58,459 Epoch[52] Train-FCNLogLoss=0.086444
2017-07-29 04:58:58,459 Epoch[52] Time cost=640.094
2017-07-29 04:58:59,195 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0053.params"
2017-07-29 04:59:00,612 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a-0053.states"
2017-07-29 04:59:00,643 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn_res5a',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn_res5a'}

2017-07-29 04:59:11,403 testing 4/500 data 0.6881s net 0.3104s post 0.0074s
2017-07-29 04:59:11,942 testing 8/500 data 0.4709s net 0.2932s post 0.0082s
2017-07-29 04:59:12,495 testing 12/500 data 0.4047s net 0.2866s post 0.0080s
2017-07-29 04:59:13,143 testing 16/500 data 0.3940s net 0.2837s post 0.0088s
2017-07-29 04:59:13,767 testing 20/500 data 0.3832s net 0.2824s post 0.0085s
2017-07-29 04:59:14,403 testing 24/500 data 0.3776s net 0.2814s post 0.0088s
2017-07-29 04:59:15,083 testing 28/500 data 0.3800s net 0.2806s post 0.0089s
2017-07-29 04:59:15,821 testing 32/500 data 0.3890s net 0.2799s post 0.0092s
2017-07-29 04:59:16,471 testing 36/500 data 0.3859s net 0.2796s post 0.0094s
2017-07-29 04:59:17,092 testing 40/500 data 0.3805s net 0.2794s post 0.0096s
2017-07-29 04:59:17,784 testing 44/500 data 0.3827s net 0.2792s post 0.0096s
2017-07-29 04:59:18,366 testing 48/500 data 0.3756s net 0.2787s post 0.0098s
2017-07-29 04:59:18,930 testing 52/500 data 0.3678s net 0.2787s post 0.0099s
2017-07-29 04:59:19,616 testing 56/500 data 0.3700s net 0.2785s post 0.0100s
2017-07-29 04:59:20,314 testing 60/500 data 0.3724s net 0.2786s post 0.0101s
2017-07-29 04:59:20,872 testing 64/500 data 0.3662s net 0.2783s post 0.0102s
2017-07-29 04:59:21,501 testing 68/500 data 0.3649s net 0.2781s post 0.0102s
2017-07-29 04:59:22,181 testing 72/500 data 0.3666s net 0.2779s post 0.0102s
2017-07-29 04:59:22,733 testing 76/500 data 0.3617s net 0.2776s post 0.0100s
2017-07-29 04:59:23,295 testing 80/500 data 0.3575s net 0.2774s post 0.0100s
2017-07-29 04:59:23,858 testing 84/500 data 0.3535s net 0.2774s post 0.0101s
2017-07-29 04:59:24,409 testing 88/500 data 0.3495s net 0.2773s post 0.0101s
2017-07-29 04:59:24,961 testing 92/500 data 0.3459s net 0.2772s post 0.0102s
2017-07-29 04:59:25,510 testing 96/500 data 0.3424s net 0.2771s post 0.0102s
2017-07-29 04:59:26,225 testing 100/500 data 0.3461s net 0.2770s post 0.0101s
2017-07-29 04:59:26,941 testing 104/500 data 0.3492s net 0.2769s post 0.0102s
2017-07-29 04:59:27,631 testing 108/500 data 0.3514s net 0.2769s post 0.0100s
2017-07-29 04:59:28,326 testing 112/500 data 0.3533s net 0.2769s post 0.0101s
2017-07-29 04:59:28,908 testing 116/500 data 0.3514s net 0.2768s post 0.0102s
2017-07-29 04:59:29,622 testing 120/500 data 0.3539s net 0.2767s post 0.0102s
2017-07-29 04:59:30,331 testing 124/500 data 0.3561s net 0.2768s post 0.0102s
2017-07-29 04:59:31,008 testing 128/500 data 0.3572s net 0.2767s post 0.0102s
2017-07-29 04:59:31,713 testing 132/500 data 0.3589s net 0.2767s post 0.0103s
2017-07-29 04:59:32,386 testing 136/500 data 0.3597s net 0.2767s post 0.0103s
2017-07-29 04:59:32,953 testing 140/500 data 0.3575s net 0.2767s post 0.0103s
2017-07-29 04:59:33,594 testing 144/500 data 0.3576s net 0.2765s post 0.0102s
2017-07-29 04:59:34,290 testing 148/500 data 0.3591s net 0.2764s post 0.0103s
2017-07-29 04:59:34,851 testing 152/500 data 0.3569s net 0.2764s post 0.0102s
2017-07-29 04:59:35,416 testing 156/500 data 0.3549s net 0.2764s post 0.0102s
2017-07-29 04:59:35,965 testing 160/500 data 0.3527s net 0.2764s post 0.0101s
2017-07-29 04:59:36,539 testing 164/500 data 0.3510s net 0.2764s post 0.0102s
2017-07-29 04:59:37,087 testing 168/500 data 0.3490s net 0.2764s post 0.0101s
2017-07-29 04:59:37,648 testing 172/500 data 0.3472s net 0.2764s post 0.0101s
2017-07-29 04:59:38,200 testing 176/500 data 0.3455s net 0.2764s post 0.0101s
2017-07-29 04:59:38,764 testing 180/500 data 0.3439s net 0.2764s post 0.0101s
2017-07-29 04:59:39,311 testing 184/500 data 0.3422s net 0.2764s post 0.0100s
2017-07-29 04:59:39,869 testing 188/500 data 0.3407s net 0.2763s post 0.0100s
2017-07-29 04:59:40,420 testing 192/500 data 0.3393s net 0.2763s post 0.0100s
2017-07-29 04:59:41,087 testing 196/500 data 0.3401s net 0.2763s post 0.0100s
2017-07-29 04:59:41,645 testing 200/500 data 0.3388s net 0.2762s post 0.0099s
2017-07-29 04:59:42,236 testing 204/500 data 0.3381s net 0.2762s post 0.0099s
2017-07-29 04:59:42,887 testing 208/500 data 0.3387s net 0.2763s post 0.0099s
2017-07-29 04:59:43,602 testing 212/500 data 0.3403s net 0.2763s post 0.0099s
2017-07-29 04:59:44,268 testing 216/500 data 0.3411s net 0.2763s post 0.0098s
2017-07-29 04:59:44,850 testing 220/500 data 0.3402s net 0.2763s post 0.0099s
2017-07-29 04:59:45,407 testing 224/500 data 0.3390s net 0.2763s post 0.0099s
2017-07-29 04:59:45,964 testing 228/500 data 0.3379s net 0.2762s post 0.0098s
2017-07-29 04:59:46,644 testing 232/500 data 0.3389s net 0.2762s post 0.0098s
2017-07-29 04:59:47,240 testing 236/500 data 0.3384s net 0.2762s post 0.0098s
2017-07-29 04:59:47,884 testing 240/500 data 0.3387s net 0.2763s post 0.0098s
2017-07-29 04:59:48,562 testing 244/500 data 0.3396s net 0.2763s post 0.0097s
2017-07-29 04:59:49,247 testing 248/500 data 0.3405s net 0.2763s post 0.0098s
2017-07-29 04:59:49,929 testing 252/500 data 0.3414s net 0.2763s post 0.0098s
2017-07-29 04:59:50,510 testing 256/500 data 0.3407s net 0.2763s post 0.0098s
2017-07-29 04:59:51,188 testing 260/500 data 0.3415s net 0.2762s post 0.0099s
2017-07-29 04:59:51,861 testing 264/500 data 0.3423s net 0.2761s post 0.0098s
2017-07-29 04:59:52,558 testing 268/500 data 0.3433s net 0.2761s post 0.0098s
2017-07-29 04:59:53,248 testing 272/500 data 0.3443s net 0.2761s post 0.0098s
2017-07-29 04:59:53,943 testing 276/500 data 0.3453s net 0.2760s post 0.0098s
2017-07-29 04:59:54,525 testing 280/500 data 0.3447s net 0.2760s post 0.0097s
2017-07-29 04:59:55,074 testing 284/500 data 0.3436s net 0.2760s post 0.0096s
2017-07-29 04:59:55,742 testing 288/500 data 0.3442s net 0.2759s post 0.0096s
2017-07-29 04:59:56,445 testing 292/500 data 0.3452s net 0.2759s post 0.0096s
2017-07-29 04:59:57,146 testing 296/500 data 0.3462s net 0.2758s post 0.0097s
2017-07-29 04:59:57,811 testing 300/500 data 0.3467s net 0.2758s post 0.0097s
2017-07-29 04:59:58,359 testing 304/500 data 0.3456s net 0.2757s post 0.0097s
2017-07-29 04:59:59,029 testing 308/500 data 0.3462s net 0.2757s post 0.0097s
2017-07-29 04:59:59,712 testing 312/500 data 0.3469s net 0.2756s post 0.0097s
2017-07-29 05:00:00,268 testing 316/500 data 0.3460s net 0.2756s post 0.0097s
2017-07-29 05:00:00,952 testing 320/500 data 0.3467s net 0.2755s post 0.0097s
2017-07-29 05:00:01,624 testing 324/500 data 0.3472s net 0.2755s post 0.0097s
2017-07-29 05:00:02,292 testing 328/500 data 0.3477s net 0.2755s post 0.0097s
2017-07-29 05:00:02,857 testing 332/500 data 0.3469s net 0.2755s post 0.0096s
2017-07-29 05:00:03,406 testing 336/500 data 0.3460s net 0.2754s post 0.0096s
2017-07-29 05:00:03,964 testing 340/500 data 0.3452s net 0.2754s post 0.0095s
2017-07-29 05:00:04,513 testing 344/500 data 0.3443s net 0.2754s post 0.0095s
2017-07-29 05:00:05,170 testing 348/500 data 0.3447s net 0.2754s post 0.0095s
2017-07-29 05:00:05,783 testing 352/500 data 0.3445s net 0.2753s post 0.0096s
2017-07-29 05:00:06,480 testing 356/500 data 0.3453s net 0.2753s post 0.0096s
2017-07-29 05:00:07,126 testing 360/500 data 0.3454s net 0.2753s post 0.0096s
2017-07-29 05:00:07,792 testing 364/500 data 0.3459s net 0.2753s post 0.0095s
2017-07-29 05:00:08,439 testing 368/500 data 0.3461s net 0.2752s post 0.0096s
2017-07-29 05:00:09,009 testing 372/500 data 0.3455s net 0.2752s post 0.0095s
2017-07-29 05:00:09,568 testing 376/500 data 0.3448s net 0.2752s post 0.0095s
2017-07-29 05:00:10,132 testing 380/500 data 0.3441s net 0.2752s post 0.0095s
2017-07-29 05:00:10,686 testing 384/500 data 0.3433s net 0.2752s post 0.0095s
2017-07-29 05:00:11,246 testing 388/500 data 0.3426s net 0.2752s post 0.0095s
2017-07-29 05:00:11,811 testing 392/500 data 0.3420s net 0.2751s post 0.0095s
2017-07-29 05:00:12,364 testing 396/500 data 0.3413s net 0.2751s post 0.0095s
2017-07-29 05:00:12,939 testing 400/500 data 0.3408s net 0.2751s post 0.0096s
2017-07-29 05:00:13,494 testing 404/500 data 0.3401s net 0.2751s post 0.0095s
2017-07-29 05:00:14,132 testing 408/500 data 0.3402s net 0.2751s post 0.0095s
2017-07-29 05:00:14,810 testing 412/500 data 0.3407s net 0.2751s post 0.0095s
2017-07-29 05:00:15,399 testing 416/500 data 0.3404s net 0.2751s post 0.0095s
2017-07-29 05:00:16,071 testing 420/500 data 0.3409s net 0.2751s post 0.0095s
2017-07-29 05:00:16,745 testing 424/500 data 0.3414s net 0.2750s post 0.0095s
2017-07-29 05:00:17,386 testing 428/500 data 0.3416s net 0.2750s post 0.0094s
2017-07-29 05:00:17,952 testing 432/500 data 0.3411s net 0.2750s post 0.0095s
2017-07-29 05:00:18,574 testing 436/500 data 0.3411s net 0.2749s post 0.0095s
2017-07-29 05:00:19,261 testing 440/500 data 0.3416s net 0.2749s post 0.0095s
2017-07-29 05:00:19,927 testing 444/500 data 0.3420s net 0.2749s post 0.0095s
2017-07-29 05:00:20,633 testing 448/500 data 0.3427s net 0.2749s post 0.0095s
2017-07-29 05:00:21,249 testing 452/500 data 0.3426s net 0.2749s post 0.0095s
2017-07-29 05:00:21,813 testing 456/500 data 0.3420s net 0.2749s post 0.0095s
2017-07-29 05:00:22,357 testing 460/500 data 0.3413s net 0.2749s post 0.0095s
2017-07-29 05:00:22,922 testing 464/500 data 0.3408s net 0.2749s post 0.0095s
2017-07-29 05:00:23,465 testing 468/500 data 0.3401s net 0.2748s post 0.0096s
2017-07-29 05:00:24,023 testing 472/500 data 0.3396s net 0.2748s post 0.0096s
2017-07-29 05:00:24,709 testing 476/500 data 0.3401s net 0.2748s post 0.0096s
2017-07-29 05:00:25,358 testing 480/500 data 0.3403s net 0.2748s post 0.0096s
2017-07-29 05:00:25,920 testing 484/500 data 0.3398s net 0.2748s post 0.0096s
2017-07-29 05:00:26,475 testing 488/500 data 0.3392s net 0.2747s post 0.0096s
2017-07-29 05:00:27,048 testing 492/500 data 0.3388s net 0.2747s post 0.0096s
2017-07-29 05:00:27,687 testing 496/500 data 0.3389s net 0.2747s post 0.0096s
2017-07-29 05:00:28,235 testing 500/500 data 0.3383s net 0.2747s post 0.0096s
2017-07-29 05:02:22,993 evaluate segmentation: 

2017-07-29 05:02:22,993 IU_array:

2017-07-29 05:02:22,993 0.97849
2017-07-29 05:02:22,993 0.83059
2017-07-29 05:02:22,993 0.91065
2017-07-29 05:02:22,993 0.47609
2017-07-29 05:02:22,993 0.52601
2017-07-29 05:02:22,994 0.53064
2017-07-29 05:02:22,994 0.64106
2017-07-29 05:02:22,994 0.73110
2017-07-29 05:02:22,994 0.91387
2017-07-29 05:02:22,994 0.60643
2017-07-29 05:02:22,994 0.93445
2017-07-29 05:02:22,994 0.77770
2017-07-29 05:02:22,994 0.57759
2017-07-29 05:02:22,994 0.93316
2017-07-29 05:02:22,994 0.57269
2017-07-29 05:02:22,994 0.76593
2017-07-29 05:02:22,994 0.62219
2017-07-29 05:02:22,994 0.60023
2017-07-29 05:02:22,994 0.74003
2017-07-29 05:02:22,994 meanIU:0.71941

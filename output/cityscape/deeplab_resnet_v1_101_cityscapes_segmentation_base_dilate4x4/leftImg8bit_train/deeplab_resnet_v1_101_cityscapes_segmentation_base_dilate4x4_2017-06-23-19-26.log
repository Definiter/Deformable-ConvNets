2017-06-23 19:26:11,852 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate4x4'}

2017-06-23 19:27:20,125 Epoch[0] Batch [10]	Speed: 7.75 samples/sec	Train-FCNLogLoss=2.868853,	
2017-06-23 19:27:25,525 Epoch[0] Batch [20]	Speed: 7.41 samples/sec	Train-FCNLogLoss=2.712305,	
2017-06-23 19:27:30,773 Epoch[0] Batch [30]	Speed: 7.62 samples/sec	Train-FCNLogLoss=2.474711,	
2017-06-23 19:27:36,075 Epoch[0] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=2.257390,	
2017-06-23 19:27:41,467 Epoch[0] Batch [50]	Speed: 7.42 samples/sec	Train-FCNLogLoss=2.028896,	
2017-06-23 19:27:46,777 Epoch[0] Batch [60]	Speed: 7.53 samples/sec	Train-FCNLogLoss=1.849133,	
2017-06-23 19:27:52,291 Epoch[0] Batch [70]	Speed: 7.26 samples/sec	Train-FCNLogLoss=1.709465,	
2017-06-23 19:27:57,733 Epoch[0] Batch [80]	Speed: 7.35 samples/sec	Train-FCNLogLoss=1.591468,	
2017-06-23 19:28:03,364 Epoch[0] Batch [90]	Speed: 7.10 samples/sec	Train-FCNLogLoss=1.494575,	
2017-06-23 19:28:08,814 Epoch[0] Batch [100]	Speed: 7.34 samples/sec	Train-FCNLogLoss=1.410453,	
2017-06-23 19:28:14,280 Epoch[0] Batch [110]	Speed: 7.32 samples/sec	Train-FCNLogLoss=1.352157,	
2017-06-23 19:28:19,789 Epoch[0] Batch [120]	Speed: 7.26 samples/sec	Train-FCNLogLoss=1.295028,	
2017-06-23 19:28:25,235 Epoch[0] Batch [130]	Speed: 7.35 samples/sec	Train-FCNLogLoss=1.245194,	
2017-06-23 19:28:30,542 Epoch[0] Batch [140]	Speed: 7.54 samples/sec	Train-FCNLogLoss=1.191138,	
2017-06-23 19:28:36,036 Epoch[0] Batch [150]	Speed: 7.28 samples/sec	Train-FCNLogLoss=1.149046,	
2017-06-23 19:28:41,651 Epoch[0] Batch [160]	Speed: 7.12 samples/sec	Train-FCNLogLoss=1.110325,	
2017-06-23 19:28:46,815 Epoch[0] Batch [170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=1.076952,	
2017-06-23 19:28:52,126 Epoch[0] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=1.047320,	
2017-06-23 19:28:57,553 Epoch[0] Batch [190]	Speed: 7.37 samples/sec	Train-FCNLogLoss=1.017272,	
2017-06-23 19:29:02,794 Epoch[0] Batch [200]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.987416,	
2017-06-23 19:29:08,322 Epoch[0] Batch [210]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.969175,	
2017-06-23 19:29:13,848 Epoch[0] Batch [220]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.947252,	
2017-06-23 19:29:19,093 Epoch[0] Batch [230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.925683,	
2017-06-23 19:29:24,576 Epoch[0] Batch [240]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.907238,	
2017-06-23 19:29:30,042 Epoch[0] Batch [250]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.893191,	
2017-06-23 19:29:35,599 Epoch[0] Batch [260]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.876098,	
2017-06-23 19:29:41,155 Epoch[0] Batch [270]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.862220,	
2017-06-23 19:29:46,559 Epoch[0] Batch [280]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.848288,	
2017-06-23 19:29:51,815 Epoch[0] Batch [290]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.834140,	
2017-06-23 19:29:58,581 Epoch[0] Batch [300]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.820554,	
2017-06-23 19:30:03,905 Epoch[0] Batch [310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.809074,	
2017-06-23 19:30:09,684 Epoch[0] Batch [320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.795652,	
2017-06-23 19:30:14,951 Epoch[0] Batch [330]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.785174,	
2017-06-23 19:30:20,166 Epoch[0] Batch [340]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.774756,	
2017-06-23 19:30:25,644 Epoch[0] Batch [350]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.763909,	
2017-06-23 19:30:30,951 Epoch[0] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.753721,	
2017-06-23 19:30:36,356 Epoch[0] Batch [370]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.744494,	
2017-06-23 19:30:41,692 Epoch[0] Batch [380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.735443,	
2017-06-23 19:30:47,128 Epoch[0] Batch [390]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.725579,	
2017-06-23 19:30:52,641 Epoch[0] Batch [400]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.717477,	
2017-06-23 19:30:57,939 Epoch[0] Batch [410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.709470,	
2017-06-23 19:31:03,191 Epoch[0] Batch [420]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.701865,	
2017-06-23 19:31:08,693 Epoch[0] Batch [430]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.695816,	
2017-06-23 19:31:14,048 Epoch[0] Batch [440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.689553,	
2017-06-23 19:31:19,496 Epoch[0] Batch [450]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.684322,	
2017-06-23 19:31:24,705 Epoch[0] Batch [460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.677284,	
2017-06-23 19:31:30,237 Epoch[0] Batch [470]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.674597,	
2017-06-23 19:31:35,480 Epoch[0] Batch [480]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.669594,	
2017-06-23 19:31:41,045 Epoch[0] Batch [490]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.662430,	
2017-06-23 19:31:46,457 Epoch[0] Batch [500]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.657587,	
2017-06-23 19:31:51,940 Epoch[0] Batch [510]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.651794,	
2017-06-23 19:31:57,435 Epoch[0] Batch [520]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.646534,	
2017-06-23 19:32:02,837 Epoch[0] Batch [530]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.641164,	
2017-06-23 19:32:08,212 Epoch[0] Batch [540]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.634935,	
2017-06-23 19:32:13,413 Epoch[0] Batch [550]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.629491,	
2017-06-23 19:32:18,652 Epoch[0] Batch [560]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.625695,	
2017-06-23 19:32:24,123 Epoch[0] Batch [570]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.621570,	
2017-06-23 19:32:29,305 Epoch[0] Batch [580]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.617622,	
2017-06-23 19:32:34,562 Epoch[0] Batch [590]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.612783,	
2017-06-23 19:32:40,119 Epoch[0] Batch [600]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.608905,	
2017-06-23 19:32:45,360 Epoch[0] Batch [610]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.605116,	
2017-06-23 19:32:50,787 Epoch[0] Batch [620]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.600879,	
2017-06-23 19:32:56,453 Epoch[0] Batch [630]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.596111,	
2017-06-23 19:33:01,862 Epoch[0] Batch [640]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.592395,	
2017-06-23 19:33:07,066 Epoch[0] Batch [650]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.588709,	
2017-06-23 19:33:12,638 Epoch[0] Batch [660]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.584578,	
2017-06-23 19:33:17,845 Epoch[0] Batch [670]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.581095,	
2017-06-23 19:33:23,367 Epoch[0] Batch [680]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.577654,	
2017-06-23 19:33:28,659 Epoch[0] Batch [690]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.573749,	
2017-06-23 19:33:34,307 Epoch[0] Batch [700]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.570576,	
2017-06-23 19:33:39,653 Epoch[0] Batch [710]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.567560,	
2017-06-23 19:33:45,415 Epoch[0] Batch [720]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.563512,	
2017-06-23 19:33:50,683 Epoch[0] Batch [730]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.560233,	
2017-06-23 19:33:56,218 Epoch[0] Batch [740]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.557143,	
2017-06-23 19:34:01,696 Epoch[0] Batch [750]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.554197,	
2017-06-23 19:34:07,193 Epoch[0] Batch [760]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.551276,	
2017-06-23 19:34:12,559 Epoch[0] Batch [770]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.548445,	
2017-06-23 19:34:18,032 Epoch[0] Batch [780]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.545364,	
2017-06-23 19:34:23,642 Epoch[0] Batch [790]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.542022,	
2017-06-23 19:34:29,122 Epoch[0] Batch [800]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.539748,	
2017-06-23 19:34:34,367 Epoch[0] Batch [810]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.536716,	
2017-06-23 19:34:39,593 Epoch[0] Batch [820]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.534089,	
2017-06-23 19:34:45,450 Epoch[0] Batch [830]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.532434,	
2017-06-23 19:34:50,769 Epoch[0] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.529964,	
2017-06-23 19:34:56,330 Epoch[0] Batch [850]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.527475,	
2017-06-23 19:35:01,847 Epoch[0] Batch [860]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.524729,	
2017-06-23 19:35:07,141 Epoch[0] Batch [870]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.522378,	
2017-06-23 19:35:12,498 Epoch[0] Batch [880]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.520527,	
2017-06-23 19:35:18,063 Epoch[0] Batch [890]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.518535,	
2017-06-23 19:35:23,534 Epoch[0] Batch [900]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.516550,	
2017-06-23 19:35:28,799 Epoch[0] Batch [910]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.514927,	
2017-06-23 19:35:34,080 Epoch[0] Batch [920]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.512286,	
2017-06-23 19:35:39,528 Epoch[0] Batch [930]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.509759,	
2017-06-23 19:35:44,760 Epoch[0] Batch [940]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.507118,	
2017-06-23 19:35:50,262 Epoch[0] Batch [950]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.504864,	
2017-06-23 19:35:55,470 Epoch[0] Batch [960]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.502976,	
2017-06-23 19:36:00,721 Epoch[0] Batch [970]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.501149,	
2017-06-23 19:36:06,178 Epoch[0] Batch [980]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.499077,	
2017-06-23 19:36:11,695 Epoch[0] Batch [990]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.496843,	
2017-06-23 19:36:17,059 Epoch[0] Batch [1000]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.494758,	
2017-06-23 19:36:22,514 Epoch[0] Batch [1010]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.494952,	
2017-06-23 19:36:28,029 Epoch[0] Batch [1020]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.494824,	
2017-06-23 19:36:33,318 Epoch[0] Batch [1030]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.495682,	
2017-06-23 19:36:38,662 Epoch[0] Batch [1040]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.494698,	
2017-06-23 19:36:43,994 Epoch[0] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.494227,	
2017-06-23 19:36:49,528 Epoch[0] Batch [1060]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.494267,	
2017-06-23 19:36:54,754 Epoch[0] Batch [1070]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.493917,	
2017-06-23 19:37:00,265 Epoch[0] Batch [1080]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.492832,	
2017-06-23 19:37:05,880 Epoch[0] Batch [1090]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.491773,	
2017-06-23 19:37:11,472 Epoch[0] Batch [1100]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.490902,	
2017-06-23 19:37:16,981 Epoch[0] Batch [1110]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.490942,	
2017-06-23 19:37:22,404 Epoch[0] Batch [1120]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.490769,	
2017-06-23 19:37:27,740 Epoch[0] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.496238,	
2017-06-23 19:37:32,995 Epoch[0] Batch [1140]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.497477,	
2017-06-23 19:37:38,534 Epoch[0] Batch [1150]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.496893,	
2017-06-23 19:37:43,996 Epoch[0] Batch [1160]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.497011,	
2017-06-23 19:37:49,200 Epoch[0] Batch [1170]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.496455,	
2017-06-23 19:37:54,718 Epoch[0] Batch [1180]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.497789,	
2017-06-23 19:37:59,998 Epoch[0] Batch [1190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.497535,	
2017-06-23 19:38:05,182 Epoch[0] Batch [1200]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.496739,	
2017-06-23 19:38:10,451 Epoch[0] Batch [1210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.495691,	
2017-06-23 19:38:15,733 Epoch[0] Batch [1220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.495224,	
2017-06-23 19:38:21,154 Epoch[0] Batch [1230]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.493833,	
2017-06-23 19:38:26,708 Epoch[0] Batch [1240]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.492527,	
2017-06-23 19:38:32,125 Epoch[0] Batch [1250]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.491509,	
2017-06-23 19:38:37,562 Epoch[0] Batch [1260]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.490240,	
2017-06-23 19:38:42,932 Epoch[0] Batch [1270]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.489107,	
2017-06-23 19:38:48,420 Epoch[0] Batch [1280]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.487696,	
2017-06-23 19:38:53,812 Epoch[0] Batch [1290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.486238,	
2017-06-23 19:38:59,263 Epoch[0] Batch [1300]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.485244,	
2017-06-23 19:39:04,727 Epoch[0] Batch [1310]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.483911,	
2017-06-23 19:39:10,256 Epoch[0] Batch [1320]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.482854,	
2017-06-23 19:39:15,742 Epoch[0] Batch [1330]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.481915,	
2017-06-23 19:39:20,971 Epoch[0] Batch [1340]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.480523,	
2017-06-23 19:39:26,505 Epoch[0] Batch [1350]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.479613,	
2017-06-23 19:39:31,888 Epoch[0] Batch [1360]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.478622,	
2017-06-23 19:39:37,505 Epoch[0] Batch [1370]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.477740,	
2017-06-23 19:39:42,744 Epoch[0] Batch [1380]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.476543,	
2017-06-23 19:39:48,160 Epoch[0] Batch [1390]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.475789,	
2017-06-23 19:39:53,444 Epoch[0] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.474608,	
2017-06-23 19:39:58,797 Epoch[0] Batch [1410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.473037,	
2017-06-23 19:40:04,200 Epoch[0] Batch [1420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.471567,	
2017-06-23 19:40:09,395 Epoch[0] Batch [1430]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.470381,	
2017-06-23 19:40:14,813 Epoch[0] Batch [1440]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.469324,	
2017-06-23 19:40:20,301 Epoch[0] Batch [1450]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.468143,	
2017-06-23 19:40:25,657 Epoch[0] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.467400,	
2017-06-23 19:40:31,221 Epoch[0] Batch [1470]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.466224,	
2017-06-23 19:40:36,653 Epoch[0] Batch [1480]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.465067,	
2017-06-23 19:40:39,877 Epoch[0] Train-FCNLogLoss=0.464218
2017-06-23 19:40:39,877 Epoch[0] Time cost=817.706
2017-06-23 19:40:40,790 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0001.params"
2017-06-23 19:40:42,447 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0001.states"
2017-06-23 19:40:48,318 Epoch[1] Batch [10]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.276554,	
2017-06-23 19:40:53,536 Epoch[1] Batch [20]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.262519,	
2017-06-23 19:40:58,704 Epoch[1] Batch [30]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.263084,	
2017-06-23 19:41:04,007 Epoch[1] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.255740,	
2017-06-23 19:41:09,240 Epoch[1] Batch [50]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.258295,	
2017-06-23 19:41:14,774 Epoch[1] Batch [60]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.263043,	
2017-06-23 19:41:19,939 Epoch[1] Batch [70]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.267929,	
2017-06-23 19:41:25,114 Epoch[1] Batch [80]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.273618,	
2017-06-23 19:41:30,331 Epoch[1] Batch [90]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.275116,	
2017-06-23 19:41:35,482 Epoch[1] Batch [100]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.273629,	
2017-06-23 19:41:40,703 Epoch[1] Batch [110]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.277469,	
2017-06-23 19:41:45,886 Epoch[1] Batch [120]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.276270,	
2017-06-23 19:41:51,105 Epoch[1] Batch [130]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.276121,	
2017-06-23 19:41:56,305 Epoch[1] Batch [140]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.275482,	
2017-06-23 19:42:01,523 Epoch[1] Batch [150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.271331,	
2017-06-23 19:42:06,678 Epoch[1] Batch [160]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.268195,	
2017-06-23 19:42:11,881 Epoch[1] Batch [170]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.265170,	
2017-06-23 19:42:17,103 Epoch[1] Batch [180]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.264323,	
2017-06-23 19:42:22,297 Epoch[1] Batch [190]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.263626,	
2017-06-23 19:42:27,475 Epoch[1] Batch [200]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.267270,	
2017-06-23 19:42:32,824 Epoch[1] Batch [210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.268537,	
2017-06-23 19:42:37,686 Epoch[1] Batch [220]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.270414,	
2017-06-23 19:42:43,541 Epoch[1] Batch [230]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.271801,	
2017-06-23 19:42:48,747 Epoch[1] Batch [240]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.269926,	
2017-06-23 19:42:53,969 Epoch[1] Batch [250]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.270186,	
2017-06-23 19:42:59,150 Epoch[1] Batch [260]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.270552,	
2017-06-23 19:43:04,396 Epoch[1] Batch [270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.271354,	
2017-06-23 19:43:09,644 Epoch[1] Batch [280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.272191,	
2017-06-23 19:43:14,837 Epoch[1] Batch [290]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.271244,	
2017-06-23 19:43:20,117 Epoch[1] Batch [300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.272950,	
2017-06-23 19:43:25,261 Epoch[1] Batch [310]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.272998,	
2017-06-23 19:43:30,463 Epoch[1] Batch [320]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.273474,	
2017-06-23 19:43:35,671 Epoch[1] Batch [330]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.272969,	
2017-06-23 19:43:40,821 Epoch[1] Batch [340]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.274187,	
2017-06-23 19:43:45,996 Epoch[1] Batch [350]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.273996,	
2017-06-23 19:43:51,200 Epoch[1] Batch [360]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.274889,	
2017-06-23 19:43:56,375 Epoch[1] Batch [370]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.274249,	
2017-06-23 19:44:01,592 Epoch[1] Batch [380]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.273997,	
2017-06-23 19:44:06,810 Epoch[1] Batch [390]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.273625,	
2017-06-23 19:44:12,013 Epoch[1] Batch [400]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.272190,	
2017-06-23 19:44:17,211 Epoch[1] Batch [410]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.271627,	
2017-06-23 19:44:22,402 Epoch[1] Batch [420]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.271273,	
2017-06-23 19:44:27,601 Epoch[1] Batch [430]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.270526,	
2017-06-23 19:44:32,793 Epoch[1] Batch [440]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.270157,	
2017-06-23 19:44:38,020 Epoch[1] Batch [450]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.269858,	
2017-06-23 19:44:43,218 Epoch[1] Batch [460]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.268610,	
2017-06-23 19:44:48,390 Epoch[1] Batch [470]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.268014,	
2017-06-23 19:44:53,596 Epoch[1] Batch [480]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.267490,	
2017-06-23 19:44:58,833 Epoch[1] Batch [490]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.267727,	
2017-06-23 19:45:03,984 Epoch[1] Batch [500]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.267536,	
2017-06-23 19:45:09,199 Epoch[1] Batch [510]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.267796,	
2017-06-23 19:45:14,358 Epoch[1] Batch [520]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.266840,	
2017-06-23 19:45:19,563 Epoch[1] Batch [530]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.266329,	
2017-06-23 19:45:24,766 Epoch[1] Batch [540]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.265341,	
2017-06-23 19:45:30,007 Epoch[1] Batch [550]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.264845,	
2017-06-23 19:45:35,189 Epoch[1] Batch [560]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.264490,	
2017-06-23 19:45:40,458 Epoch[1] Batch [570]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.263504,	
2017-06-23 19:45:45,638 Epoch[1] Batch [580]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.263517,	
2017-06-23 19:45:50,825 Epoch[1] Batch [590]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.263781,	
2017-06-23 19:45:55,981 Epoch[1] Batch [600]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.263404,	
2017-06-23 19:46:01,250 Epoch[1] Batch [610]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.262970,	
2017-06-23 19:46:06,568 Epoch[1] Batch [620]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.262695,	
2017-06-23 19:46:11,710 Epoch[1] Batch [630]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.262548,	
2017-06-23 19:46:16,941 Epoch[1] Batch [640]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.262679,	
2017-06-23 19:46:22,136 Epoch[1] Batch [650]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.262409,	
2017-06-23 19:46:27,361 Epoch[1] Batch [660]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.262273,	
2017-06-23 19:46:32,604 Epoch[1] Batch [670]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.262800,	
2017-06-23 19:46:37,788 Epoch[1] Batch [680]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.263505,	
2017-06-23 19:46:43,034 Epoch[1] Batch [690]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.263218,	
2017-06-23 19:46:48,194 Epoch[1] Batch [700]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.262963,	
2017-06-23 19:46:53,418 Epoch[1] Batch [710]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.262678,	
2017-06-23 19:46:58,604 Epoch[1] Batch [720]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.262327,	
2017-06-23 19:47:03,822 Epoch[1] Batch [730]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.262733,	
2017-06-23 19:47:09,039 Epoch[1] Batch [740]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.262313,	
2017-06-23 19:47:14,235 Epoch[1] Batch [750]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.261852,	
2017-06-23 19:47:19,471 Epoch[1] Batch [760]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.262347,	
2017-06-23 19:47:24,650 Epoch[1] Batch [770]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.261995,	
2017-06-23 19:47:29,862 Epoch[1] Batch [780]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.261523,	
2017-06-23 19:47:35,079 Epoch[1] Batch [790]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.260886,	
2017-06-23 19:47:40,272 Epoch[1] Batch [800]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.260323,	
2017-06-23 19:47:45,464 Epoch[1] Batch [810]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.260113,	
2017-06-23 19:47:50,697 Epoch[1] Batch [820]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.260173,	
2017-06-23 19:47:55,850 Epoch[1] Batch [830]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.259438,	
2017-06-23 19:48:01,059 Epoch[1] Batch [840]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.258897,	
2017-06-23 19:48:06,280 Epoch[1] Batch [850]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.258800,	
2017-06-23 19:48:11,457 Epoch[1] Batch [860]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.258329,	
2017-06-23 19:48:16,662 Epoch[1] Batch [870]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.258079,	
2017-06-23 19:48:21,887 Epoch[1] Batch [880]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.257878,	
2017-06-23 19:48:27,066 Epoch[1] Batch [890]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.257816,	
2017-06-23 19:48:32,336 Epoch[1] Batch [900]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.258194,	
2017-06-23 19:48:37,531 Epoch[1] Batch [910]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.258086,	
2017-06-23 19:48:42,701 Epoch[1] Batch [920]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.258136,	
2017-06-23 19:48:47,959 Epoch[1] Batch [930]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.258405,	
2017-06-23 19:48:53,121 Epoch[1] Batch [940]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.258917,	
2017-06-23 19:48:58,327 Epoch[1] Batch [950]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.258838,	
2017-06-23 19:49:03,543 Epoch[1] Batch [960]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.258332,	
2017-06-23 19:49:08,713 Epoch[1] Batch [970]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.258347,	
2017-06-23 19:49:13,943 Epoch[1] Batch [980]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.257937,	
2017-06-23 19:49:19,118 Epoch[1] Batch [990]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.257946,	
2017-06-23 19:49:24,315 Epoch[1] Batch [1000]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.257778,	
2017-06-23 19:49:29,581 Epoch[1] Batch [1010]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.257320,	
2017-06-23 19:49:34,782 Epoch[1] Batch [1020]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.256918,	
2017-06-23 19:49:40,003 Epoch[1] Batch [1030]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.256810,	
2017-06-23 19:49:45,169 Epoch[1] Batch [1040]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.256826,	
2017-06-23 19:49:50,362 Epoch[1] Batch [1050]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.256397,	
2017-06-23 19:49:55,555 Epoch[1] Batch [1060]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.255742,	
2017-06-23 19:50:00,763 Epoch[1] Batch [1070]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.255328,	
2017-06-23 19:50:06,003 Epoch[1] Batch [1080]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.254878,	
2017-06-23 19:50:11,213 Epoch[1] Batch [1090]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.254724,	
2017-06-23 19:50:16,441 Epoch[1] Batch [1100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.254166,	
2017-06-23 19:50:21,685 Epoch[1] Batch [1110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.253864,	
2017-06-23 19:50:26,919 Epoch[1] Batch [1120]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.253532,	
2017-06-23 19:50:32,131 Epoch[1] Batch [1130]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.252938,	
2017-06-23 19:50:37,399 Epoch[1] Batch [1140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.252251,	
2017-06-23 19:50:42,599 Epoch[1] Batch [1150]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.252039,	
2017-06-23 19:50:47,815 Epoch[1] Batch [1160]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.251763,	
2017-06-23 19:50:53,062 Epoch[1] Batch [1170]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.251752,	
2017-06-23 19:50:58,288 Epoch[1] Batch [1180]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.251312,	
2017-06-23 19:51:03,529 Epoch[1] Batch [1190]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.251355,	
2017-06-23 19:51:08,680 Epoch[1] Batch [1200]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.251372,	
2017-06-23 19:51:13,949 Epoch[1] Batch [1210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.251646,	
2017-06-23 19:51:19,119 Epoch[1] Batch [1220]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.251512,	
2017-06-23 19:51:24,347 Epoch[1] Batch [1230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.251262,	
2017-06-23 19:51:29,592 Epoch[1] Batch [1240]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.250914,	
2017-06-23 19:51:34,805 Epoch[1] Batch [1250]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.250502,	
2017-06-23 19:51:40,061 Epoch[1] Batch [1260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.250202,	
2017-06-23 19:51:45,305 Epoch[1] Batch [1270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.250087,	
2017-06-23 19:51:50,469 Epoch[1] Batch [1280]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.249945,	
2017-06-23 19:51:55,652 Epoch[1] Batch [1290]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.250294,	
2017-06-23 19:52:00,874 Epoch[1] Batch [1300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.249890,	
2017-06-23 19:52:06,074 Epoch[1] Batch [1310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.249597,	
2017-06-23 19:52:11,277 Epoch[1] Batch [1320]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.249862,	
2017-06-23 19:52:16,455 Epoch[1] Batch [1330]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.249822,	
2017-06-23 19:52:21,698 Epoch[1] Batch [1340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.249524,	
2017-06-23 19:52:26,841 Epoch[1] Batch [1350]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.249271,	
2017-06-23 19:52:32,059 Epoch[1] Batch [1360]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.249038,	
2017-06-23 19:52:37,321 Epoch[1] Batch [1370]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.248723,	
2017-06-23 19:52:42,791 Epoch[1] Batch [1380]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.248398,	
2017-06-23 19:52:48,479 Epoch[1] Batch [1390]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.248277,	
2017-06-23 19:52:53,915 Epoch[1] Batch [1400]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.247763,	
2017-06-23 19:52:59,283 Epoch[1] Batch [1410]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.247534,	
2017-06-23 19:53:04,612 Epoch[1] Batch [1420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.247495,	
2017-06-23 19:53:10,546 Epoch[1] Batch [1430]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.247747,	
2017-06-23 19:53:16,604 Epoch[1] Batch [1440]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.247516,	
2017-06-23 19:53:22,779 Epoch[1] Batch [1450]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.247499,	
2017-06-23 19:53:28,787 Epoch[1] Batch [1460]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.247354,	
2017-06-23 19:53:35,121 Epoch[1] Batch [1470]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.247252,	
2017-06-23 19:53:41,426 Epoch[1] Batch [1480]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.246894,	
2017-06-23 19:53:45,369 Epoch[1] Train-FCNLogLoss=0.246666
2017-06-23 19:53:45,369 Epoch[1] Time cost=782.921
2017-06-23 19:53:46,219 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0002.params"
2017-06-23 19:53:47,856 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0002.states"
2017-06-23 19:53:55,305 Epoch[2] Batch [10]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.231594,	
2017-06-23 19:54:02,625 Epoch[2] Batch [20]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.231760,	
2017-06-23 19:54:09,924 Epoch[2] Batch [30]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.223414,	
2017-06-23 19:54:16,190 Epoch[2] Batch [40]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.219947,	
2017-06-23 19:54:22,467 Epoch[2] Batch [50]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.221354,	
2017-06-23 19:54:28,128 Epoch[2] Batch [60]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.227375,	
2017-06-23 19:54:33,339 Epoch[2] Batch [70]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.228303,	
2017-06-23 19:54:38,553 Epoch[2] Batch [80]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.224573,	
2017-06-23 19:54:43,738 Epoch[2] Batch [90]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.223640,	
2017-06-23 19:54:48,988 Epoch[2] Batch [100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.221294,	
2017-06-23 19:54:54,136 Epoch[2] Batch [110]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.219103,	
2017-06-23 19:54:59,307 Epoch[2] Batch [120]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.216396,	
2017-06-23 19:55:04,501 Epoch[2] Batch [130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.216073,	
2017-06-23 19:55:09,748 Epoch[2] Batch [140]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.217665,	
2017-06-23 19:55:14,912 Epoch[2] Batch [150]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.217033,	
2017-06-23 19:55:20,136 Epoch[2] Batch [160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.213912,	
2017-06-23 19:55:25,290 Epoch[2] Batch [170]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.213069,	
2017-06-23 19:55:30,557 Epoch[2] Batch [180]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.212177,	
2017-06-23 19:55:35,737 Epoch[2] Batch [190]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.211023,	
2017-06-23 19:55:40,901 Epoch[2] Batch [200]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.209660,	
2017-06-23 19:55:46,143 Epoch[2] Batch [210]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.208714,	
2017-06-23 19:55:51,178 Epoch[2] Batch [220]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.210575,	
2017-06-23 19:55:57,021 Epoch[2] Batch [230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.211154,	
2017-06-23 19:56:02,213 Epoch[2] Batch [240]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.210546,	
2017-06-23 19:56:07,467 Epoch[2] Batch [250]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.209498,	
2017-06-23 19:56:12,685 Epoch[2] Batch [260]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.211505,	
2017-06-23 19:56:17,876 Epoch[2] Batch [270]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.210466,	
2017-06-23 19:56:23,081 Epoch[2] Batch [280]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.210963,	
2017-06-23 19:56:28,287 Epoch[2] Batch [290]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.210778,	
2017-06-23 19:56:33,509 Epoch[2] Batch [300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211241,	
2017-06-23 19:56:38,585 Epoch[2] Batch [310]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.209965,	
2017-06-23 19:56:43,791 Epoch[2] Batch [320]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.210468,	
2017-06-23 19:56:48,938 Epoch[2] Batch [330]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.210354,	
2017-06-23 19:56:54,111 Epoch[2] Batch [340]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.210021,	
2017-06-23 19:56:59,336 Epoch[2] Batch [350]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211158,	
2017-06-23 19:57:04,561 Epoch[2] Batch [360]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211385,	
2017-06-23 19:57:09,710 Epoch[2] Batch [370]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.211162,	
2017-06-23 19:57:14,937 Epoch[2] Batch [380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.210867,	
2017-06-23 19:57:20,110 Epoch[2] Batch [390]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.210513,	
2017-06-23 19:57:25,293 Epoch[2] Batch [400]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.210925,	
2017-06-23 19:57:30,521 Epoch[2] Batch [410]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.210648,	
2017-06-23 19:57:35,682 Epoch[2] Batch [420]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.210028,	
2017-06-23 19:57:40,876 Epoch[2] Batch [430]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.209466,	
2017-06-23 19:57:46,007 Epoch[2] Batch [440]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.209205,	
2017-06-23 19:57:51,232 Epoch[2] Batch [450]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.209153,	
2017-06-23 19:57:56,462 Epoch[2] Batch [460]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.209395,	
2017-06-23 19:58:01,612 Epoch[2] Batch [470]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.209811,	
2017-06-23 19:58:06,763 Epoch[2] Batch [480]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.209837,	
2017-06-23 19:58:12,017 Epoch[2] Batch [490]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.211596,	
2017-06-23 19:58:17,162 Epoch[2] Batch [500]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.211514,	
2017-06-23 19:58:22,390 Epoch[2] Batch [510]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.211740,	
2017-06-23 19:58:27,582 Epoch[2] Batch [520]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.212347,	
2017-06-23 19:58:32,765 Epoch[2] Batch [530]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.212300,	
2017-06-23 19:58:37,942 Epoch[2] Batch [540]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.212760,	
2017-06-23 19:58:43,154 Epoch[2] Batch [550]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.212289,	
2017-06-23 19:58:48,344 Epoch[2] Batch [560]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.211856,	
2017-06-23 19:58:53,565 Epoch[2] Batch [570]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211621,	
2017-06-23 19:58:58,696 Epoch[2] Batch [580]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.211886,	
2017-06-23 19:59:03,916 Epoch[2] Batch [590]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211719,	
2017-06-23 19:59:09,141 Epoch[2] Batch [600]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211434,	
2017-06-23 19:59:14,348 Epoch[2] Batch [610]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.211338,	
2017-06-23 19:59:19,519 Epoch[2] Batch [620]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.212059,	
2017-06-23 19:59:24,668 Epoch[2] Batch [630]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.212441,	
2017-06-23 19:59:29,885 Epoch[2] Batch [640]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.213169,	
2017-06-23 19:59:35,081 Epoch[2] Batch [650]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.213464,	
2017-06-23 19:59:40,282 Epoch[2] Batch [660]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.215011,	
2017-06-23 19:59:45,459 Epoch[2] Batch [670]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.215038,	
2017-06-23 19:59:50,683 Epoch[2] Batch [680]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.214927,	
2017-06-23 19:59:55,895 Epoch[2] Batch [690]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.214594,	
2017-06-23 20:00:01,051 Epoch[2] Batch [700]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.213986,	
2017-06-23 20:00:06,279 Epoch[2] Batch [710]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.214190,	
2017-06-23 20:00:11,459 Epoch[2] Batch [720]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.214632,	
2017-06-23 20:00:16,651 Epoch[2] Batch [730]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.214585,	
2017-06-23 20:00:21,793 Epoch[2] Batch [740]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.214024,	
2017-06-23 20:00:27,058 Epoch[2] Batch [750]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.213718,	
2017-06-23 20:00:32,223 Epoch[2] Batch [760]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.213390,	
2017-06-23 20:00:37,382 Epoch[2] Batch [770]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.213134,	
2017-06-23 20:00:42,612 Epoch[2] Batch [780]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.213007,	
2017-06-23 20:00:47,799 Epoch[2] Batch [790]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.212709,	
2017-06-23 20:00:53,013 Epoch[2] Batch [800]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.212318,	
2017-06-23 20:00:58,200 Epoch[2] Batch [810]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.212100,	
2017-06-23 20:01:03,427 Epoch[2] Batch [820]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.211967,	
2017-06-23 20:01:08,603 Epoch[2] Batch [830]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.211714,	
2017-06-23 20:01:13,854 Epoch[2] Batch [840]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.211354,	
2017-06-23 20:01:19,078 Epoch[2] Batch [850]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.211133,	
2017-06-23 20:01:24,270 Epoch[2] Batch [860]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.210834,	
2017-06-23 20:01:29,467 Epoch[2] Batch [870]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.210807,	
2017-06-23 20:01:34,681 Epoch[2] Batch [880]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.210549,	
2017-06-23 20:01:39,858 Epoch[2] Batch [890]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.210420,	
2017-06-23 20:01:45,078 Epoch[2] Batch [900]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.210797,	
2017-06-23 20:01:50,259 Epoch[2] Batch [910]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.210773,	
2017-06-23 20:01:55,539 Epoch[2] Batch [920]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.210311,	
2017-06-23 20:02:00,873 Epoch[2] Batch [930]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.210267,	
2017-06-23 20:02:06,100 Epoch[2] Batch [940]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.210635,	
2017-06-23 20:02:11,484 Epoch[2] Batch [950]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.210294,	
2017-06-23 20:02:16,879 Epoch[2] Batch [960]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.210075,	
2017-06-23 20:02:22,287 Epoch[2] Batch [970]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.209989,	
2017-06-23 20:02:27,536 Epoch[2] Batch [980]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.209891,	
2017-06-23 20:02:32,746 Epoch[2] Batch [990]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.209720,	
2017-06-23 20:02:37,951 Epoch[2] Batch [1000]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.209501,	
2017-06-23 20:02:43,240 Epoch[2] Batch [1010]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.209346,	
2017-06-23 20:02:48,477 Epoch[2] Batch [1020]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.209184,	
2017-06-23 20:02:53,732 Epoch[2] Batch [1030]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.208923,	
2017-06-23 20:02:58,903 Epoch[2] Batch [1040]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.208746,	
2017-06-23 20:03:04,152 Epoch[2] Batch [1050]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.208793,	
2017-06-23 20:03:09,339 Epoch[2] Batch [1060]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.208961,	
2017-06-23 20:03:14,600 Epoch[2] Batch [1070]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.208479,	
2017-06-23 20:03:20,614 Epoch[2] Batch [1080]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.208301,	
2017-06-23 20:03:26,575 Epoch[2] Batch [1090]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.208093,	
2017-06-23 20:03:32,598 Epoch[2] Batch [1100]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.207937,	
2017-06-23 20:03:38,727 Epoch[2] Batch [1110]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.207662,	
2017-06-23 20:03:44,903 Epoch[2] Batch [1120]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.207553,	
2017-06-23 20:03:50,966 Epoch[2] Batch [1130]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.207153,	
2017-06-23 20:03:56,955 Epoch[2] Batch [1140]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.206765,	
2017-06-23 20:04:02,835 Epoch[2] Batch [1150]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.206476,	
2017-06-23 20:04:09,165 Epoch[2] Batch [1160]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.206624,	
2017-06-23 20:04:15,654 Epoch[2] Batch [1170]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.206637,	
2017-06-23 20:04:21,496 Epoch[2] Batch [1180]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.206586,	
2017-06-23 20:04:28,031 Epoch[2] Batch [1190]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.206707,	
2017-06-23 20:04:34,898 Epoch[2] Batch [1200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.206633,	
2017-06-23 20:04:40,888 Epoch[2] Batch [1210]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.206629,	
2017-06-23 20:04:47,287 Epoch[2] Batch [1220]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.206765,	
2017-06-23 20:04:53,887 Epoch[2] Batch [1230]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.207046,	
2017-06-23 20:04:59,879 Epoch[2] Batch [1240]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.207131,	
2017-06-23 20:05:06,255 Epoch[2] Batch [1250]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.207155,	
2017-06-23 20:05:12,474 Epoch[2] Batch [1260]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.207178,	
2017-06-23 20:05:18,574 Epoch[2] Batch [1270]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.207313,	
2017-06-23 20:05:24,600 Epoch[2] Batch [1280]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.207053,	
2017-06-23 20:05:30,689 Epoch[2] Batch [1290]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.207013,	
2017-06-23 20:05:36,608 Epoch[2] Batch [1300]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.207511,	
2017-06-23 20:05:42,600 Epoch[2] Batch [1310]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.208036,	
2017-06-23 20:05:48,549 Epoch[2] Batch [1320]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.208092,	
2017-06-23 20:05:54,465 Epoch[2] Batch [1330]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.208440,	
2017-06-23 20:06:00,562 Epoch[2] Batch [1340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.208544,	
2017-06-23 20:06:06,577 Epoch[2] Batch [1350]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.208717,	
2017-06-23 20:06:12,753 Epoch[2] Batch [1360]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.208918,	
2017-06-23 20:06:18,738 Epoch[2] Batch [1370]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.208994,	
2017-06-23 20:06:24,963 Epoch[2] Batch [1380]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.208755,	
2017-06-23 20:06:30,895 Epoch[2] Batch [1390]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.208857,	
2017-06-23 20:06:36,820 Epoch[2] Batch [1400]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.208613,	
2017-06-23 20:06:42,018 Epoch[2] Batch [1410]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.208704,	
2017-06-23 20:06:48,645 Epoch[2] Batch [1420]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.208424,	
2017-06-23 20:06:54,678 Epoch[2] Batch [1430]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.208464,	
2017-06-23 20:07:00,750 Epoch[2] Batch [1440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.208837,	
2017-06-23 20:07:06,812 Epoch[2] Batch [1450]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.208782,	
2017-06-23 20:07:12,858 Epoch[2] Batch [1460]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.208706,	
2017-06-23 20:07:19,053 Epoch[2] Batch [1470]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.208653,	
2017-06-23 20:07:25,059 Epoch[2] Batch [1480]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.208635,	
2017-06-23 20:07:28,639 Epoch[2] Train-FCNLogLoss=0.208804
2017-06-23 20:07:28,640 Epoch[2] Time cost=820.784
2017-06-23 20:07:29,834 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0003.params"
2017-06-23 20:07:31,634 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0003.states"
2017-06-23 20:07:39,034 Epoch[3] Batch [10]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.190901,	
2017-06-23 20:07:45,749 Epoch[3] Batch [20]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.197335,	
2017-06-23 20:07:52,011 Epoch[3] Batch [30]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.191920,	
2017-06-23 20:07:58,680 Epoch[3] Batch [40]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.198191,	
2017-06-23 20:08:05,351 Epoch[3] Batch [50]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.194844,	
2017-06-23 20:08:12,175 Epoch[3] Batch [60]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.189481,	
2017-06-23 20:08:18,732 Epoch[3] Batch [70]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.187553,	
2017-06-23 20:08:25,322 Epoch[3] Batch [80]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.184212,	
2017-06-23 20:08:31,990 Epoch[3] Batch [90]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.187754,	
2017-06-23 20:08:38,499 Epoch[3] Batch [100]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.192556,	
2017-06-23 20:08:44,490 Epoch[3] Batch [110]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.201287,	
2017-06-23 20:08:51,195 Epoch[3] Batch [120]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.211143,	
2017-06-23 20:08:58,138 Epoch[3] Batch [130]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.212592,	
2017-06-23 20:09:04,773 Epoch[3] Batch [140]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.213383,	
2017-06-23 20:09:11,089 Epoch[3] Batch [150]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.215965,	
2017-06-23 20:09:17,128 Epoch[3] Batch [160]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.216062,	
2017-06-23 20:09:23,280 Epoch[3] Batch [170]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.216716,	
2017-06-23 20:09:29,290 Epoch[3] Batch [180]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.216665,	
2017-06-23 20:09:35,304 Epoch[3] Batch [190]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.215443,	
2017-06-23 20:09:41,300 Epoch[3] Batch [200]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.216000,	
2017-06-23 20:09:47,393 Epoch[3] Batch [210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.214359,	
2017-06-23 20:09:53,937 Epoch[3] Batch [220]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.212761,	
2017-06-23 20:10:00,442 Epoch[3] Batch [230]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.211631,	
2017-06-23 20:10:07,607 Epoch[3] Batch [240]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.211687,	
2017-06-23 20:10:13,925 Epoch[3] Batch [250]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.211111,	
2017-06-23 20:10:20,818 Epoch[3] Batch [260]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.210615,	
2017-06-23 20:10:28,364 Epoch[3] Batch [270]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.208987,	
2017-06-23 20:10:34,926 Epoch[3] Batch [280]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.208220,	
2017-06-23 20:10:41,328 Epoch[3] Batch [290]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.207556,	
2017-06-23 20:10:48,185 Epoch[3] Batch [300]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.206068,	
2017-06-23 20:10:55,531 Epoch[3] Batch [310]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.205444,	
2017-06-23 20:11:02,498 Epoch[3] Batch [320]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.204552,	
2017-06-23 20:11:09,107 Epoch[3] Batch [330]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.204098,	
2017-06-23 20:11:16,149 Epoch[3] Batch [340]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.203777,	
2017-06-23 20:11:23,214 Epoch[3] Batch [350]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.202619,	
2017-06-23 20:11:29,699 Epoch[3] Batch [360]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.202685,	
2017-06-23 20:11:36,687 Epoch[3] Batch [370]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.202434,	
2017-06-23 20:11:43,714 Epoch[3] Batch [380]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.203084,	
2017-06-23 20:11:50,611 Epoch[3] Batch [390]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.207138,	
2017-06-23 20:11:57,538 Epoch[3] Batch [400]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.207011,	
2017-06-23 20:12:04,399 Epoch[3] Batch [410]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.208071,	
2017-06-23 20:12:11,318 Epoch[3] Batch [420]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.208128,	
2017-06-23 20:12:17,899 Epoch[3] Batch [430]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.207688,	
2017-06-23 20:12:24,496 Epoch[3] Batch [440]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.207258,	
2017-06-23 20:12:30,826 Epoch[3] Batch [450]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.206600,	
2017-06-23 20:12:37,399 Epoch[3] Batch [460]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.205867,	
2017-06-23 20:12:44,407 Epoch[3] Batch [470]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.205629,	
2017-06-23 20:12:51,458 Epoch[3] Batch [480]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.205010,	
2017-06-23 20:12:58,479 Epoch[3] Batch [490]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.204537,	
2017-06-23 20:13:04,889 Epoch[3] Batch [500]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.204736,	
2017-06-23 20:13:11,453 Epoch[3] Batch [510]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.204933,	
2017-06-23 20:13:18,017 Epoch[3] Batch [520]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.204724,	
2017-06-23 20:13:24,401 Epoch[3] Batch [530]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.204191,	
2017-06-23 20:13:30,624 Epoch[3] Batch [540]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.203835,	
2017-06-23 20:13:37,779 Epoch[3] Batch [550]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.203366,	
2017-06-23 20:13:44,325 Epoch[3] Batch [560]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.202793,	
2017-06-23 20:13:50,427 Epoch[3] Batch [570]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.202703,	
2017-06-23 20:13:57,816 Epoch[3] Batch [580]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.202469,	
2017-06-23 20:14:04,549 Epoch[3] Batch [590]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.201801,	
2017-06-23 20:14:10,862 Epoch[3] Batch [600]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.201658,	
2017-06-23 20:14:17,404 Epoch[3] Batch [610]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.201199,	
2017-06-23 20:14:24,114 Epoch[3] Batch [620]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.200968,	
2017-06-23 20:14:31,532 Epoch[3] Batch [630]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.200706,	
2017-06-23 20:14:38,769 Epoch[3] Batch [640]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.200499,	
2017-06-23 20:14:45,547 Epoch[3] Batch [650]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.200393,	
2017-06-23 20:14:52,734 Epoch[3] Batch [660]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.200399,	
2017-06-23 20:14:59,373 Epoch[3] Batch [670]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.200005,	
2017-06-23 20:15:06,607 Epoch[3] Batch [680]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.200287,	
2017-06-23 20:15:13,970 Epoch[3] Batch [690]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.200638,	
2017-06-23 20:15:21,185 Epoch[3] Batch [700]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.200618,	
2017-06-23 20:15:28,358 Epoch[3] Batch [710]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.200385,	
2017-06-23 20:15:35,692 Epoch[3] Batch [720]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.200102,	
2017-06-23 20:15:43,132 Epoch[3] Batch [730]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.199656,	
2017-06-23 20:15:50,742 Epoch[3] Batch [740]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.199424,	
2017-06-23 20:15:58,042 Epoch[3] Batch [750]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.199040,	
2017-06-23 20:16:05,683 Epoch[3] Batch [760]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.199081,	
2017-06-23 20:16:12,916 Epoch[3] Batch [770]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.199469,	
2017-06-23 20:16:20,275 Epoch[3] Batch [780]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.199477,	
2017-06-23 20:16:27,570 Epoch[3] Batch [790]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.199490,	
2017-06-23 20:16:34,149 Epoch[3] Batch [800]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.199543,	
2017-06-23 20:16:40,389 Epoch[3] Batch [810]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.199469,	
2017-06-23 20:16:47,459 Epoch[3] Batch [820]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.199003,	
2017-06-23 20:16:54,086 Epoch[3] Batch [830]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.199246,	
2017-06-23 20:17:00,718 Epoch[3] Batch [840]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.199100,	
2017-06-23 20:17:06,614 Epoch[3] Batch [850]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.198915,	
2017-06-23 20:17:12,875 Epoch[3] Batch [860]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.199203,	
2017-06-23 20:17:19,303 Epoch[3] Batch [870]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.199262,	
2017-06-23 20:17:25,487 Epoch[3] Batch [880]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.199690,	
2017-06-23 20:17:31,662 Epoch[3] Batch [890]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.199498,	
2017-06-23 20:17:37,583 Epoch[3] Batch [900]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.199285,	
2017-06-23 20:17:43,530 Epoch[3] Batch [910]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.199090,	
2017-06-23 20:17:49,695 Epoch[3] Batch [920]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.198827,	
2017-06-23 20:17:55,683 Epoch[3] Batch [930]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.198700,	
2017-06-23 20:18:01,472 Epoch[3] Batch [940]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.198930,	
2017-06-23 20:18:07,525 Epoch[3] Batch [950]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.198871,	
2017-06-23 20:18:13,462 Epoch[3] Batch [960]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.198986,	
2017-06-23 20:18:19,452 Epoch[3] Batch [970]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.199032,	
2017-06-23 20:18:25,224 Epoch[3] Batch [980]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.198944,	
2017-06-23 20:18:31,363 Epoch[3] Batch [990]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.198676,	
2017-06-23 20:18:37,347 Epoch[3] Batch [1000]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.198269,	
2017-06-23 20:18:43,282 Epoch[3] Batch [1010]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.198356,	
2017-06-23 20:18:49,187 Epoch[3] Batch [1020]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.198294,	
2017-06-23 20:18:55,123 Epoch[3] Batch [1030]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.197920,	
2017-06-23 20:19:01,196 Epoch[3] Batch [1040]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.197620,	
2017-06-23 20:19:07,795 Epoch[3] Batch [1050]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.197698,	
2017-06-23 20:19:13,745 Epoch[3] Batch [1060]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.197561,	
2017-06-23 20:19:19,863 Epoch[3] Batch [1070]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.197386,	
2017-06-23 20:19:25,420 Epoch[3] Batch [1080]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.197216,	
2017-06-23 20:19:31,493 Epoch[3] Batch [1090]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.197117,	
2017-06-23 20:19:37,063 Epoch[3] Batch [1100]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.196858,	
2017-06-23 20:19:43,088 Epoch[3] Batch [1110]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.196720,	
2017-06-23 20:19:49,077 Epoch[3] Batch [1120]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.196574,	
2017-06-23 20:19:54,965 Epoch[3] Batch [1130]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.196595,	
2017-06-23 20:20:00,912 Epoch[3] Batch [1140]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.196501,	
2017-06-23 20:20:06,929 Epoch[3] Batch [1150]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.196227,	
2017-06-23 20:20:12,908 Epoch[3] Batch [1160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.196070,	
2017-06-23 20:20:18,841 Epoch[3] Batch [1170]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.196130,	
2017-06-23 20:20:24,823 Epoch[3] Batch [1180]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.195925,	
2017-06-23 20:20:30,744 Epoch[3] Batch [1190]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.195742,	
2017-06-23 20:20:36,759 Epoch[3] Batch [1200]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.195507,	
2017-06-23 20:20:42,637 Epoch[3] Batch [1210]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.195315,	
2017-06-23 20:20:48,604 Epoch[3] Batch [1220]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.195124,	
2017-06-23 20:20:54,688 Epoch[3] Batch [1230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.195165,	
2017-06-23 20:21:00,569 Epoch[3] Batch [1240]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.195077,	
2017-06-23 20:21:06,821 Epoch[3] Batch [1250]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.195134,	
2017-06-23 20:21:12,864 Epoch[3] Batch [1260]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.195074,	
2017-06-23 20:21:18,794 Epoch[3] Batch [1270]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.195045,	
2017-06-23 20:21:24,717 Epoch[3] Batch [1280]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.195113,	
2017-06-23 20:21:30,710 Epoch[3] Batch [1290]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.195173,	
2017-06-23 20:21:36,609 Epoch[3] Batch [1300]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.195223,	
2017-06-23 20:21:42,582 Epoch[3] Batch [1310]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.195107,	
2017-06-23 20:21:48,507 Epoch[3] Batch [1320]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.194822,	
2017-06-23 20:21:54,471 Epoch[3] Batch [1330]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.195076,	
2017-06-23 20:22:00,375 Epoch[3] Batch [1340]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.195321,	
2017-06-23 20:22:06,371 Epoch[3] Batch [1350]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.195310,	
2017-06-23 20:22:12,396 Epoch[3] Batch [1360]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.195642,	
2017-06-23 20:22:18,288 Epoch[3] Batch [1370]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.195673,	
2017-06-23 20:22:24,284 Epoch[3] Batch [1380]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.195383,	
2017-06-23 20:22:30,239 Epoch[3] Batch [1390]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.195240,	
2017-06-23 20:22:36,191 Epoch[3] Batch [1400]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.194982,	
2017-06-23 20:22:42,111 Epoch[3] Batch [1410]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.194782,	
2017-06-23 20:22:48,075 Epoch[3] Batch [1420]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.194669,	
2017-06-23 20:22:54,053 Epoch[3] Batch [1430]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.194414,	
2017-06-23 20:22:59,947 Epoch[3] Batch [1440]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.194307,	
2017-06-23 20:23:05,927 Epoch[3] Batch [1450]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.194206,	
2017-06-23 20:23:11,797 Epoch[3] Batch [1460]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.194265,	
2017-06-23 20:23:17,698 Epoch[3] Batch [1470]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.194176,	
2017-06-23 20:23:23,564 Epoch[3] Batch [1480]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.194208,	
2017-06-23 20:23:27,130 Epoch[3] Train-FCNLogLoss=0.194061
2017-06-23 20:23:27,131 Epoch[3] Time cost=955.497
2017-06-23 20:23:28,261 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0004.params"
2017-06-23 20:23:31,904 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0004.states"
2017-06-23 20:23:38,645 Epoch[4] Batch [10]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.163515,	
2017-06-23 20:23:44,587 Epoch[4] Batch [20]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.180530,	
2017-06-23 20:23:50,340 Epoch[4] Batch [30]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.176841,	
2017-06-23 20:23:56,194 Epoch[4] Batch [40]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.182056,	
2017-06-23 20:24:02,079 Epoch[4] Batch [50]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.183485,	
2017-06-23 20:24:07,776 Epoch[4] Batch [60]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.177191,	
2017-06-23 20:24:13,775 Epoch[4] Batch [70]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.177825,	
2017-06-23 20:24:19,702 Epoch[4] Batch [80]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.178001,	
2017-06-23 20:24:25,650 Epoch[4] Batch [90]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.177561,	
2017-06-23 20:24:31,383 Epoch[4] Batch [100]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.181645,	
2017-06-23 20:24:37,335 Epoch[4] Batch [110]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.182805,	
2017-06-23 20:24:43,091 Epoch[4] Batch [120]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.180818,	
2017-06-23 20:24:48,858 Epoch[4] Batch [130]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.180918,	
2017-06-23 20:24:54,908 Epoch[4] Batch [140]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.179226,	
2017-06-23 20:25:00,791 Epoch[4] Batch [150]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.179962,	
2017-06-23 20:25:06,692 Epoch[4] Batch [160]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.178446,	
2017-06-23 20:25:12,344 Epoch[4] Batch [170]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.182307,	
2017-06-23 20:25:18,069 Epoch[4] Batch [180]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.182360,	
2017-06-23 20:25:24,031 Epoch[4] Batch [190]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.181734,	
2017-06-23 20:25:29,802 Epoch[4] Batch [200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.182019,	
2017-06-23 20:25:35,716 Epoch[4] Batch [210]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.183807,	
2017-06-23 20:25:41,393 Epoch[4] Batch [220]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.184457,	
2017-06-23 20:25:47,314 Epoch[4] Batch [230]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.182811,	
2017-06-23 20:25:52,464 Epoch[4] Batch [240]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.181633,	
2017-06-23 20:25:58,255 Epoch[4] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.181188,	
2017-06-23 20:26:04,050 Epoch[4] Batch [260]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.180196,	
2017-06-23 20:26:09,779 Epoch[4] Batch [270]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.180347,	
2017-06-23 20:26:15,480 Epoch[4] Batch [280]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.180047,	
2017-06-23 20:26:21,270 Epoch[4] Batch [290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.179168,	
2017-06-23 20:26:27,006 Epoch[4] Batch [300]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.178083,	
2017-06-23 20:26:32,941 Epoch[4] Batch [310]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.177867,	
2017-06-23 20:26:38,881 Epoch[4] Batch [320]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.178151,	
2017-06-23 20:26:44,886 Epoch[4] Batch [330]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.177547,	
2017-06-23 20:26:50,696 Epoch[4] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.177030,	
2017-06-23 20:26:56,779 Epoch[4] Batch [350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.177156,	
2017-06-23 20:27:02,461 Epoch[4] Batch [360]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.176933,	
2017-06-23 20:27:08,413 Epoch[4] Batch [370]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.176853,	
2017-06-23 20:27:14,447 Epoch[4] Batch [380]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.176665,	
2017-06-23 20:27:20,333 Epoch[4] Batch [390]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.176152,	
2017-06-23 20:27:26,279 Epoch[4] Batch [400]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.176130,	
2017-06-23 20:27:32,198 Epoch[4] Batch [410]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.176072,	
2017-06-23 20:27:38,195 Epoch[4] Batch [420]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.176060,	
2017-06-23 20:27:44,188 Epoch[4] Batch [430]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.175916,	
2017-06-23 20:27:50,203 Epoch[4] Batch [440]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.175786,	
2017-06-23 20:27:56,174 Epoch[4] Batch [450]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.176300,	
2017-06-23 20:28:02,172 Epoch[4] Batch [460]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.176726,	
2017-06-23 20:28:08,143 Epoch[4] Batch [470]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.177563,	
2017-06-23 20:28:14,166 Epoch[4] Batch [480]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.177379,	
2017-06-23 20:28:20,090 Epoch[4] Batch [490]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.177213,	
2017-06-23 20:28:26,085 Epoch[4] Batch [500]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.176977,	
2017-06-23 20:28:31,942 Epoch[4] Batch [510]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.177644,	
2017-06-23 20:28:38,289 Epoch[4] Batch [520]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.177774,	
2017-06-23 20:28:44,592 Epoch[4] Batch [530]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.177573,	
2017-06-23 20:28:50,460 Epoch[4] Batch [540]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.177033,	
2017-06-23 20:28:56,447 Epoch[4] Batch [550]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.176355,	
2017-06-23 20:29:02,391 Epoch[4] Batch [560]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.176633,	
2017-06-23 20:29:08,356 Epoch[4] Batch [570]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.176690,	
2017-06-23 20:29:14,285 Epoch[4] Batch [580]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.176908,	
2017-06-23 20:29:20,261 Epoch[4] Batch [590]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.176492,	
2017-06-23 20:29:26,199 Epoch[4] Batch [600]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.176148,	
2017-06-23 20:29:32,149 Epoch[4] Batch [610]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.176245,	
2017-06-23 20:29:38,110 Epoch[4] Batch [620]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.176023,	
2017-06-23 20:29:44,074 Epoch[4] Batch [630]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.176382,	
2017-06-23 20:29:50,053 Epoch[4] Batch [640]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.176043,	
2017-06-23 20:29:56,023 Epoch[4] Batch [650]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.175911,	
2017-06-23 20:30:01,999 Epoch[4] Batch [660]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.176037,	
2017-06-23 20:30:07,932 Epoch[4] Batch [670]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.176184,	
2017-06-23 20:30:13,915 Epoch[4] Batch [680]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.176008,	
2017-06-23 20:30:19,863 Epoch[4] Batch [690]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.175795,	
2017-06-23 20:30:25,814 Epoch[4] Batch [700]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.175471,	
2017-06-23 20:30:31,741 Epoch[4] Batch [710]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.175140,	
2017-06-23 20:30:37,702 Epoch[4] Batch [720]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.175258,	
2017-06-23 20:30:43,648 Epoch[4] Batch [730]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.175024,	
2017-06-23 20:30:49,606 Epoch[4] Batch [740]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174843,	
2017-06-23 20:30:55,548 Epoch[4] Batch [750]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174602,	
2017-06-23 20:31:01,495 Epoch[4] Batch [760]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174572,	
2017-06-23 20:31:07,443 Epoch[4] Batch [770]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174416,	
2017-06-23 20:31:13,402 Epoch[4] Batch [780]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174648,	
2017-06-23 20:31:19,357 Epoch[4] Batch [790]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.174790,	
2017-06-23 20:31:25,316 Epoch[4] Batch [800]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.175070,	
2017-06-23 20:31:31,280 Epoch[4] Batch [810]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174713,	
2017-06-23 20:31:37,219 Epoch[4] Batch [820]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.174408,	
2017-06-23 20:31:43,136 Epoch[4] Batch [830]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.174219,	
2017-06-23 20:31:49,099 Epoch[4] Batch [840]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174303,	
2017-06-23 20:31:55,037 Epoch[4] Batch [850]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.174079,	
2017-06-23 20:32:01,002 Epoch[4] Batch [860]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174131,	
2017-06-23 20:32:06,925 Epoch[4] Batch [870]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.174240,	
2017-06-23 20:32:12,884 Epoch[4] Batch [880]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174251,	
2017-06-23 20:32:18,808 Epoch[4] Batch [890]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.174136,	
2017-06-23 20:32:24,763 Epoch[4] Batch [900]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.173808,	
2017-06-23 20:32:30,716 Epoch[4] Batch [910]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.173745,	
2017-06-23 20:32:36,610 Epoch[4] Batch [920]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.173619,	
2017-06-23 20:32:42,533 Epoch[4] Batch [930]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.173502,	
2017-06-23 20:32:48,579 Epoch[4] Batch [940]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.173591,	
2017-06-23 20:32:54,353 Epoch[4] Batch [950]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.173601,	
2017-06-23 20:33:00,288 Epoch[4] Batch [960]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.173453,	
2017-06-23 20:33:06,240 Epoch[4] Batch [970]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.173609,	
2017-06-23 20:33:12,157 Epoch[4] Batch [980]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.173384,	
2017-06-23 20:33:18,118 Epoch[4] Batch [990]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.173391,	
2017-06-23 20:33:24,054 Epoch[4] Batch [1000]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.173563,	
2017-06-23 20:33:30,006 Epoch[4] Batch [1010]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.173548,	
2017-06-23 20:33:35,933 Epoch[4] Batch [1020]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.173484,	
2017-06-23 20:33:41,929 Epoch[4] Batch [1030]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.173535,	
2017-06-23 20:33:47,849 Epoch[4] Batch [1040]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.174125,	
2017-06-23 20:33:53,801 Epoch[4] Batch [1050]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.174211,	
2017-06-23 20:33:59,792 Epoch[4] Batch [1060]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.174228,	
2017-06-23 20:34:05,670 Epoch[4] Batch [1070]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.174587,	
2017-06-23 20:34:11,601 Epoch[4] Batch [1080]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.174663,	
2017-06-23 20:34:17,577 Epoch[4] Batch [1090]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.174676,	
2017-06-23 20:34:23,525 Epoch[4] Batch [1100]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174959,	
2017-06-23 20:34:29,467 Epoch[4] Batch [1110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174874,	
2017-06-23 20:34:35,392 Epoch[4] Batch [1120]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.174785,	
2017-06-23 20:34:41,352 Epoch[4] Batch [1130]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174667,	
2017-06-23 20:34:47,282 Epoch[4] Batch [1140]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.174680,	
2017-06-23 20:34:53,248 Epoch[4] Batch [1150]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.174675,	
2017-06-23 20:34:59,212 Epoch[4] Batch [1160]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174473,	
2017-06-23 20:35:05,159 Epoch[4] Batch [1170]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174475,	
2017-06-23 20:35:11,094 Epoch[4] Batch [1180]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.174394,	
2017-06-23 20:35:17,028 Epoch[4] Batch [1190]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.174128,	
2017-06-23 20:35:22,966 Epoch[4] Batch [1200]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.174049,	
2017-06-23 20:35:28,911 Epoch[4] Batch [1210]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.173929,	
2017-06-23 20:35:34,885 Epoch[4] Batch [1220]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.173932,	
2017-06-23 20:35:40,873 Epoch[4] Batch [1230]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.173860,	
2017-06-23 20:35:46,723 Epoch[4] Batch [1240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.173834,	
2017-06-23 20:35:52,710 Epoch[4] Batch [1250]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.173848,	
2017-06-23 20:35:58,641 Epoch[4] Batch [1260]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.173606,	
2017-06-23 20:36:04,584 Epoch[4] Batch [1270]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.173693,	
2017-06-23 20:36:10,525 Epoch[4] Batch [1280]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.173492,	
2017-06-23 20:36:16,468 Epoch[4] Batch [1290]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.173531,	
2017-06-23 20:36:22,423 Epoch[4] Batch [1300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.173495,	
2017-06-23 20:36:28,439 Epoch[4] Batch [1310]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.173524,	
2017-06-23 20:36:34,374 Epoch[4] Batch [1320]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.173427,	
2017-06-23 20:36:40,153 Epoch[4] Batch [1330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.173299,	
2017-06-23 20:36:46,059 Epoch[4] Batch [1340]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.173835,	
2017-06-23 20:36:51,941 Epoch[4] Batch [1350]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.173810,	
2017-06-23 20:36:57,617 Epoch[4] Batch [1360]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.173834,	
2017-06-23 20:37:03,493 Epoch[4] Batch [1370]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.173774,	
2017-06-23 20:37:09,460 Epoch[4] Batch [1380]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.173804,	
2017-06-23 20:37:15,401 Epoch[4] Batch [1390]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.173827,	
2017-06-23 20:37:21,345 Epoch[4] Batch [1400]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.173866,	
2017-06-23 20:37:27,289 Epoch[4] Batch [1410]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174157,	
2017-06-23 20:37:33,239 Epoch[4] Batch [1420]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.174236,	
2017-06-23 20:37:39,177 Epoch[4] Batch [1430]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.174218,	
2017-06-23 20:37:45,141 Epoch[4] Batch [1440]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.174106,	
2017-06-23 20:37:51,086 Epoch[4] Batch [1450]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.174178,	
2017-06-23 20:37:57,057 Epoch[4] Batch [1460]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.174387,	
2017-06-23 20:38:02,933 Epoch[4] Batch [1470]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.174274,	
2017-06-23 20:38:08,864 Epoch[4] Batch [1480]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.174348,	
2017-06-23 20:38:12,422 Epoch[4] Train-FCNLogLoss=0.174350
2017-06-23 20:38:12,422 Epoch[4] Time cost=880.517
2017-06-23 20:38:13,901 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0005.params"
2017-06-23 20:38:17,603 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0005.states"
2017-06-23 20:38:24,425 Epoch[5] Batch [10]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.159634,	
2017-06-23 20:38:30,352 Epoch[5] Batch [20]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.163462,	
2017-06-23 20:38:36,356 Epoch[5] Batch [30]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.160445,	
2017-06-23 20:38:42,233 Epoch[5] Batch [40]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.161963,	
2017-06-23 20:38:48,205 Epoch[5] Batch [50]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.164176,	
2017-06-23 20:38:54,183 Epoch[5] Batch [60]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.163938,	
2017-06-23 20:39:00,182 Epoch[5] Batch [70]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.163904,	
2017-06-23 20:39:06,050 Epoch[5] Batch [80]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.162517,	
2017-06-23 20:39:12,036 Epoch[5] Batch [90]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.163855,	
2017-06-23 20:39:17,957 Epoch[5] Batch [100]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.161928,	
2017-06-23 20:39:23,959 Epoch[5] Batch [110]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.160620,	
2017-06-23 20:39:29,847 Epoch[5] Batch [120]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.162894,	
2017-06-23 20:39:35,866 Epoch[5] Batch [130]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.162103,	
2017-06-23 20:39:42,024 Epoch[5] Batch [140]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.163972,	
2017-06-23 20:39:47,906 Epoch[5] Batch [150]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.163571,	
2017-06-23 20:39:54,074 Epoch[5] Batch [160]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.163311,	
2017-06-23 20:39:59,983 Epoch[5] Batch [170]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.164625,	
2017-06-23 20:40:05,929 Epoch[5] Batch [180]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.164984,	
2017-06-23 20:40:11,850 Epoch[5] Batch [190]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.166265,	
2017-06-23 20:40:17,750 Epoch[5] Batch [200]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.166764,	
2017-06-23 20:40:23,591 Epoch[5] Batch [210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.165802,	
2017-06-23 20:40:29,512 Epoch[5] Batch [220]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.165115,	
2017-06-23 20:40:35,650 Epoch[5] Batch [230]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.165263,	
2017-06-23 20:40:42,007 Epoch[5] Batch [240]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.165543,	
2017-06-23 20:40:48,003 Epoch[5] Batch [250]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.164378,	
2017-06-23 20:40:53,986 Epoch[5] Batch [260]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.164450,	
2017-06-23 20:40:59,835 Epoch[5] Batch [270]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164522,	
2017-06-23 20:41:05,854 Epoch[5] Batch [280]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.164550,	
2017-06-23 20:41:11,819 Epoch[5] Batch [290]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.164555,	
2017-06-23 20:41:17,670 Epoch[5] Batch [300]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164190,	
2017-06-23 20:41:23,703 Epoch[5] Batch [310]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.163836,	
2017-06-23 20:41:29,635 Epoch[5] Batch [320]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.163697,	
2017-06-23 20:41:35,665 Epoch[5] Batch [330]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.163034,	
2017-06-23 20:41:41,660 Epoch[5] Batch [340]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.162682,	
2017-06-23 20:41:47,579 Epoch[5] Batch [350]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.161836,	
2017-06-23 20:41:53,521 Epoch[5] Batch [360]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.161416,	
2017-06-23 20:41:59,163 Epoch[5] Batch [370]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.161485,	
2017-06-23 20:42:05,115 Epoch[5] Batch [380]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.161310,	
2017-06-23 20:42:10,916 Epoch[5] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.161154,	
2017-06-23 20:42:16,759 Epoch[5] Batch [400]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.161087,	
2017-06-23 20:42:22,510 Epoch[5] Batch [410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.161094,	
2017-06-23 20:42:28,448 Epoch[5] Batch [420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.161483,	
2017-06-23 20:42:34,451 Epoch[5] Batch [430]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.161997,	
2017-06-23 20:42:40,470 Epoch[5] Batch [440]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.162063,	
2017-06-23 20:42:46,346 Epoch[5] Batch [450]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.162246,	
2017-06-23 20:42:52,276 Epoch[5] Batch [460]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.162951,	
2017-06-23 20:42:58,222 Epoch[5] Batch [470]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.162531,	
2017-06-23 20:43:04,151 Epoch[5] Batch [480]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.162504,	
2017-06-23 20:43:10,098 Epoch[5] Batch [490]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.162965,	
2017-06-23 20:43:16,046 Epoch[5] Batch [500]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.163629,	
2017-06-23 20:43:22,028 Epoch[5] Batch [510]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.163505,	
2017-06-23 20:43:27,926 Epoch[5] Batch [520]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.163311,	
2017-06-23 20:43:33,860 Epoch[5] Batch [530]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.163670,	
2017-06-23 20:43:39,814 Epoch[5] Batch [540]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.163572,	
2017-06-23 20:43:45,694 Epoch[5] Batch [550]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.163454,	
2017-06-23 20:43:51,628 Epoch[5] Batch [560]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.163378,	
2017-06-23 20:43:57,522 Epoch[5] Batch [570]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.163266,	
2017-06-23 20:44:03,489 Epoch[5] Batch [580]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.163251,	
2017-06-23 20:44:09,436 Epoch[5] Batch [590]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.162809,	
2017-06-23 20:44:15,380 Epoch[5] Batch [600]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.163069,	
2017-06-23 20:44:21,166 Epoch[5] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.162596,	
2017-06-23 20:44:27,333 Epoch[5] Batch [620]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.162771,	
2017-06-23 20:44:33,538 Epoch[5] Batch [630]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.162627,	
2017-06-23 20:44:39,394 Epoch[5] Batch [640]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.163212,	
2017-06-23 20:44:45,323 Epoch[5] Batch [650]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.163744,	
2017-06-23 20:44:51,318 Epoch[5] Batch [660]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.164115,	
2017-06-23 20:44:57,231 Epoch[5] Batch [670]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.163885,	
2017-06-23 20:45:03,174 Epoch[5] Batch [680]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.164049,	
2017-06-23 20:45:09,113 Epoch[5] Batch [690]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.163775,	
2017-06-23 20:45:15,023 Epoch[5] Batch [700]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.163787,	
2017-06-23 20:45:20,975 Epoch[5] Batch [710]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.163935,	
2017-06-23 20:45:26,936 Epoch[5] Batch [720]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.164447,	
2017-06-23 20:45:32,920 Epoch[5] Batch [730]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.164743,	
2017-06-23 20:45:38,833 Epoch[5] Batch [740]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.165300,	
2017-06-23 20:45:44,751 Epoch[5] Batch [750]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.165352,	
2017-06-23 20:45:50,713 Epoch[5] Batch [760]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.166055,	
2017-06-23 20:45:56,717 Epoch[5] Batch [770]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.166017,	
2017-06-23 20:46:02,691 Epoch[5] Batch [780]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.166154,	
2017-06-23 20:46:08,572 Epoch[5] Batch [790]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.165992,	
2017-06-23 20:46:14,527 Epoch[5] Batch [800]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.165901,	
2017-06-23 20:46:20,452 Epoch[5] Batch [810]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.165865,	
2017-06-23 20:46:26,385 Epoch[5] Batch [820]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.165930,	
2017-06-23 20:46:32,291 Epoch[5] Batch [830]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.165995,	
2017-06-23 20:46:38,234 Epoch[5] Batch [840]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.165761,	
2017-06-23 20:46:44,197 Epoch[5] Batch [850]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.165585,	
2017-06-23 20:46:50,113 Epoch[5] Batch [860]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.165559,	
2017-06-23 20:46:56,109 Epoch[5] Batch [870]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.165781,	
2017-06-23 20:47:02,012 Epoch[5] Batch [880]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.165823,	
2017-06-23 20:47:07,995 Epoch[5] Batch [890]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.165515,	
2017-06-23 20:47:13,921 Epoch[5] Batch [900]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.165381,	
2017-06-23 20:47:19,824 Epoch[5] Batch [910]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.165422,	
2017-06-23 20:47:25,771 Epoch[5] Batch [920]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.165532,	
2017-06-23 20:47:31,706 Epoch[5] Batch [930]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.165461,	
2017-06-23 20:47:37,611 Epoch[5] Batch [940]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.165450,	
2017-06-23 20:47:43,550 Epoch[5] Batch [950]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.165225,	
2017-06-23 20:47:49,493 Epoch[5] Batch [960]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.164912,	
2017-06-23 20:47:55,472 Epoch[5] Batch [970]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.164836,	
2017-06-23 20:48:01,386 Epoch[5] Batch [980]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.164807,	
2017-06-23 20:48:07,358 Epoch[5] Batch [990]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.165143,	
2017-06-23 20:48:13,310 Epoch[5] Batch [1000]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.165119,	
2017-06-23 20:48:19,302 Epoch[5] Batch [1010]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.165087,	
2017-06-23 20:48:24,979 Epoch[5] Batch [1020]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.164993,	
2017-06-23 20:48:30,897 Epoch[5] Batch [1030]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.164830,	
2017-06-23 20:48:36,577 Epoch[5] Batch [1040]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.164867,	
2017-06-23 20:48:42,445 Epoch[5] Batch [1050]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.164991,	
2017-06-23 20:48:48,159 Epoch[5] Batch [1060]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.165076,	
2017-06-23 20:48:54,117 Epoch[5] Batch [1070]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.164790,	
2017-06-23 20:49:00,066 Epoch[5] Batch [1080]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.164607,	
2017-06-23 20:49:06,038 Epoch[5] Batch [1090]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.164670,	
2017-06-23 20:49:11,977 Epoch[5] Batch [1100]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.164502,	
2017-06-23 20:49:17,933 Epoch[5] Batch [1110]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.164577,	
2017-06-23 20:49:23,913 Epoch[5] Batch [1120]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.164641,	
2017-06-23 20:49:29,795 Epoch[5] Batch [1130]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.164625,	
2017-06-23 20:49:35,788 Epoch[5] Batch [1140]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.164692,	
2017-06-23 20:49:41,846 Epoch[5] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.164550,	
2017-06-23 20:49:47,696 Epoch[5] Batch [1160]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164610,	
2017-06-23 20:49:53,633 Epoch[5] Batch [1170]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.164782,	
2017-06-23 20:49:59,666 Epoch[5] Batch [1180]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.164788,	
2017-06-23 20:50:05,505 Epoch[5] Batch [1190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.164582,	
2017-06-23 20:50:11,443 Epoch[5] Batch [1200]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.164947,	
2017-06-23 20:50:17,444 Epoch[5] Batch [1210]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.165029,	
2017-06-23 20:50:23,345 Epoch[5] Batch [1220]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.165077,	
2017-06-23 20:50:29,257 Epoch[5] Batch [1230]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.165114,	
2017-06-23 20:50:35,235 Epoch[5] Batch [1240]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.164978,	
2017-06-23 20:50:41,273 Epoch[5] Batch [1250]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.164639,	
2017-06-23 20:50:47,121 Epoch[5] Batch [1260]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.164737,	
2017-06-23 20:50:53,052 Epoch[5] Batch [1270]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.164820,	
2017-06-23 20:50:59,037 Epoch[5] Batch [1280]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.164764,	
2017-06-23 20:51:04,963 Epoch[5] Batch [1290]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.164677,	
2017-06-23 20:51:10,915 Epoch[5] Batch [1300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.164664,	
2017-06-23 20:51:16,913 Epoch[5] Batch [1310]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.164607,	
2017-06-23 20:51:23,062 Epoch[5] Batch [1320]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.164598,	
2017-06-23 20:51:29,059 Epoch[5] Batch [1330]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.164557,	
2017-06-23 20:51:35,282 Epoch[5] Batch [1340]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.164684,	
2017-06-23 20:51:41,366 Epoch[5] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.164544,	
2017-06-23 20:51:47,577 Epoch[5] Batch [1360]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.164542,	
2017-06-23 20:51:53,574 Epoch[5] Batch [1370]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.164565,	
2017-06-23 20:51:59,280 Epoch[5] Batch [1380]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.164667,	
2017-06-23 20:52:05,218 Epoch[5] Batch [1390]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.164549,	
2017-06-23 20:52:11,173 Epoch[5] Batch [1400]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.164458,	
2017-06-23 20:52:17,210 Epoch[5] Batch [1410]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.164446,	
2017-06-23 20:52:23,362 Epoch[5] Batch [1420]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.164175,	
2017-06-23 20:52:29,253 Epoch[5] Batch [1430]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.164044,	
2017-06-23 20:52:34,981 Epoch[5] Batch [1440]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.163966,	
2017-06-23 20:52:41,259 Epoch[5] Batch [1450]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.163838,	
2017-06-23 20:52:47,183 Epoch[5] Batch [1460]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.163722,	
2017-06-23 20:52:53,131 Epoch[5] Batch [1470]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.163665,	
2017-06-23 20:52:59,002 Epoch[5] Batch [1480]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.163659,	
2017-06-23 20:53:02,599 Epoch[5] Train-FCNLogLoss=0.163695
2017-06-23 20:53:02,599 Epoch[5] Time cost=884.996
2017-06-23 20:53:03,686 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0006.params"
2017-06-23 20:53:07,561 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0006.states"
2017-06-23 20:53:14,629 Epoch[6] Batch [10]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.146621,	
2017-06-23 20:53:20,644 Epoch[6] Batch [20]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.144780,	
2017-06-23 20:53:26,570 Epoch[6] Batch [30]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.146036,	
2017-06-23 20:53:32,485 Epoch[6] Batch [40]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.149504,	
2017-06-23 20:53:38,498 Epoch[6] Batch [50]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.148619,	
2017-06-23 20:53:44,410 Epoch[6] Batch [60]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.154091,	
2017-06-23 20:53:50,391 Epoch[6] Batch [70]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.151696,	
2017-06-23 20:53:56,357 Epoch[6] Batch [80]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.150931,	
2017-06-23 20:54:02,354 Epoch[6] Batch [90]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.154652,	
2017-06-23 20:54:08,373 Epoch[6] Batch [100]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.155530,	
2017-06-23 20:54:14,317 Epoch[6] Batch [110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.156022,	
2017-06-23 20:54:20,408 Epoch[6] Batch [120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.154791,	
2017-06-23 20:54:26,506 Epoch[6] Batch [130]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.154819,	
2017-06-23 20:54:32,972 Epoch[6] Batch [140]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.155897,	
2017-06-23 20:54:39,175 Epoch[6] Batch [150]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.156208,	
2017-06-23 20:54:45,478 Epoch[6] Batch [160]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.154785,	
2017-06-23 20:54:51,535 Epoch[6] Batch [170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.153394,	
2017-06-23 20:54:57,980 Epoch[6] Batch [180]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.154321,	
2017-06-23 20:55:04,029 Epoch[6] Batch [190]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.154571,	
2017-06-23 20:55:10,140 Epoch[6] Batch [200]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.153347,	
2017-06-23 20:55:16,112 Epoch[6] Batch [210]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.153474,	
2017-06-23 20:55:21,954 Epoch[6] Batch [220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.153409,	
2017-06-23 20:55:27,981 Epoch[6] Batch [230]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.152738,	
2017-06-23 20:55:33,695 Epoch[6] Batch [240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.152309,	
2017-06-23 20:55:39,529 Epoch[6] Batch [250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.152664,	
2017-06-23 20:55:45,313 Epoch[6] Batch [260]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.152350,	
2017-06-23 20:55:51,234 Epoch[6] Batch [270]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.152200,	
2017-06-23 20:55:57,210 Epoch[6] Batch [280]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.152038,	
2017-06-23 20:56:03,045 Epoch[6] Batch [290]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151790,	
2017-06-23 20:56:09,145 Epoch[6] Batch [300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.152387,	
2017-06-23 20:56:15,271 Epoch[6] Batch [310]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.152231,	
2017-06-23 20:56:21,104 Epoch[6] Batch [320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.151845,	
2017-06-23 20:56:27,099 Epoch[6] Batch [330]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.151875,	
2017-06-23 20:56:33,046 Epoch[6] Batch [340]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.152582,	
2017-06-23 20:56:39,064 Epoch[6] Batch [350]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.153201,	
2017-06-23 20:56:45,002 Epoch[6] Batch [360]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.153709,	
2017-06-23 20:56:50,935 Epoch[6] Batch [370]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.153560,	
2017-06-23 20:56:56,876 Epoch[6] Batch [380]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.153378,	
2017-06-23 20:57:02,805 Epoch[6] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153477,	
2017-06-23 20:57:08,757 Epoch[6] Batch [400]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.153651,	
2017-06-23 20:57:14,702 Epoch[6] Batch [410]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.153539,	
2017-06-23 20:57:20,671 Epoch[6] Batch [420]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.153618,	
2017-06-23 20:57:26,607 Epoch[6] Batch [430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153460,	
2017-06-23 20:57:32,543 Epoch[6] Batch [440]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.153413,	
2017-06-23 20:57:38,470 Epoch[6] Batch [450]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153042,	
2017-06-23 20:57:44,429 Epoch[6] Batch [460]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.152853,	
2017-06-23 20:57:50,352 Epoch[6] Batch [470]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153099,	
2017-06-23 20:57:56,336 Epoch[6] Batch [480]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.152977,	
2017-06-23 20:58:02,254 Epoch[6] Batch [490]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.152954,	
2017-06-23 20:58:08,185 Epoch[6] Batch [500]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153075,	
2017-06-23 20:58:14,174 Epoch[6] Batch [510]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.152895,	
2017-06-23 20:58:20,185 Epoch[6] Batch [520]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.152970,	
2017-06-23 20:58:26,053 Epoch[6] Batch [530]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.152947,	
2017-06-23 20:58:32,040 Epoch[6] Batch [540]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.152911,	
2017-06-23 20:58:38,091 Epoch[6] Batch [550]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.153173,	
2017-06-23 20:58:44,035 Epoch[6] Batch [560]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.153358,	
2017-06-23 20:58:49,865 Epoch[6] Batch [570]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.153182,	
2017-06-23 20:58:55,853 Epoch[6] Batch [580]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.153222,	
2017-06-23 20:59:01,774 Epoch[6] Batch [590]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.152913,	
2017-06-23 20:59:07,709 Epoch[6] Batch [600]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.152788,	
2017-06-23 20:59:13,671 Epoch[6] Batch [610]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.152953,	
2017-06-23 20:59:19,581 Epoch[6] Batch [620]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.153163,	
2017-06-23 20:59:25,575 Epoch[6] Batch [630]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.153071,	
2017-06-23 20:59:31,478 Epoch[6] Batch [640]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.153263,	
2017-06-23 20:59:37,407 Epoch[6] Batch [650]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153105,	
2017-06-23 20:59:43,364 Epoch[6] Batch [660]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.153567,	
2017-06-23 20:59:49,308 Epoch[6] Batch [670]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.153749,	
2017-06-23 20:59:55,265 Epoch[6] Batch [680]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.153650,	
2017-06-23 21:00:01,278 Epoch[6] Batch [690]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.153570,	
2017-06-23 21:00:06,961 Epoch[6] Batch [700]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.153337,	
2017-06-23 21:00:12,973 Epoch[6] Batch [710]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.153616,	
2017-06-23 21:00:18,958 Epoch[6] Batch [720]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.153467,	
2017-06-23 21:00:24,767 Epoch[6] Batch [730]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.153331,	
2017-06-23 21:00:30,692 Epoch[6] Batch [740]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153426,	
2017-06-23 21:00:36,621 Epoch[6] Batch [750]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153070,	
2017-06-23 21:00:42,553 Epoch[6] Batch [760]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.153179,	
2017-06-23 21:00:48,563 Epoch[6] Batch [770]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.153157,	
2017-06-23 21:00:54,430 Epoch[6] Batch [780]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.153254,	
2017-06-23 21:01:00,411 Epoch[6] Batch [790]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.153620,	
2017-06-23 21:01:06,311 Epoch[6] Batch [800]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.153519,	
2017-06-23 21:01:12,303 Epoch[6] Batch [810]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.153587,	
2017-06-23 21:01:18,242 Epoch[6] Batch [820]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.153558,	
2017-06-23 21:01:24,199 Epoch[6] Batch [830]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.153375,	
2017-06-23 21:01:30,125 Epoch[6] Batch [840]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153357,	
2017-06-23 21:01:36,064 Epoch[6] Batch [850]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.153424,	
2017-06-23 21:01:42,014 Epoch[6] Batch [860]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.153344,	
2017-06-23 21:01:47,968 Epoch[6] Batch [870]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.153267,	
2017-06-23 21:01:54,050 Epoch[6] Batch [880]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.153027,	
2017-06-23 21:01:59,969 Epoch[6] Batch [890]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.153045,	
2017-06-23 21:02:05,929 Epoch[6] Batch [900]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.153188,	
2017-06-23 21:02:11,839 Epoch[6] Batch [910]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.153325,	
2017-06-23 21:02:18,076 Epoch[6] Batch [920]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.153174,	
2017-06-23 21:02:24,678 Epoch[6] Batch [930]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.153211,	
2017-06-23 21:02:31,509 Epoch[6] Batch [940]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.153210,	
2017-06-23 21:02:37,938 Epoch[6] Batch [950]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.153296,	
2017-06-23 21:02:44,160 Epoch[6] Batch [960]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.153361,	
2017-06-23 21:02:50,094 Epoch[6] Batch [970]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.153420,	
2017-06-23 21:02:56,014 Epoch[6] Batch [980]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.153393,	
2017-06-23 21:03:01,980 Epoch[6] Batch [990]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.153227,	
2017-06-23 21:03:07,979 Epoch[6] Batch [1000]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.153153,	
2017-06-23 21:03:13,965 Epoch[6] Batch [1010]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.153287,	
2017-06-23 21:03:20,144 Epoch[6] Batch [1020]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.153090,	
2017-06-23 21:03:26,174 Epoch[6] Batch [1030]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.153311,	
2017-06-23 21:03:32,376 Epoch[6] Batch [1040]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.153215,	
2017-06-23 21:03:38,424 Epoch[6] Batch [1050]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.153424,	
2017-06-23 21:03:44,598 Epoch[6] Batch [1060]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.153394,	
2017-06-23 21:03:50,875 Epoch[6] Batch [1070]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.153519,	
2017-06-23 21:03:56,979 Epoch[6] Batch [1080]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.153467,	
2017-06-23 21:04:03,121 Epoch[6] Batch [1090]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.153340,	
2017-06-23 21:04:09,106 Epoch[6] Batch [1100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.153261,	
2017-06-23 21:04:15,061 Epoch[6] Batch [1110]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.153161,	
2017-06-23 21:04:21,034 Epoch[6] Batch [1120]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.153283,	
2017-06-23 21:04:27,051 Epoch[6] Batch [1130]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.153409,	
2017-06-23 21:04:32,940 Epoch[6] Batch [1140]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.153495,	
2017-06-23 21:04:38,961 Epoch[6] Batch [1150]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.153516,	
2017-06-23 21:04:44,818 Epoch[6] Batch [1160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.153470,	
2017-06-23 21:04:50,871 Epoch[6] Batch [1170]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.153634,	
2017-06-23 21:04:56,767 Epoch[6] Batch [1180]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.153640,	
2017-06-23 21:05:02,809 Epoch[6] Batch [1190]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.153593,	
2017-06-23 21:05:08,757 Epoch[6] Batch [1200]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.153673,	
2017-06-23 21:05:15,362 Epoch[6] Batch [1210]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.153788,	
2017-06-23 21:05:21,354 Epoch[6] Batch [1220]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.153638,	
2017-06-23 21:05:27,298 Epoch[6] Batch [1230]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.153520,	
2017-06-23 21:05:33,815 Epoch[6] Batch [1240]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.153594,	
2017-06-23 21:05:41,059 Epoch[6] Batch [1250]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.153509,	
2017-06-23 21:05:47,708 Epoch[6] Batch [1260]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.153339,	
2017-06-23 21:05:53,874 Epoch[6] Batch [1270]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.153466,	
2017-06-23 21:05:59,990 Epoch[6] Batch [1280]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.153447,	
2017-06-23 21:06:05,982 Epoch[6] Batch [1290]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.153537,	
2017-06-23 21:06:12,219 Epoch[6] Batch [1300]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.153333,	
2017-06-23 21:06:18,224 Epoch[6] Batch [1310]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.153255,	
2017-06-23 21:06:24,363 Epoch[6] Batch [1320]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.153189,	
2017-06-23 21:06:30,661 Epoch[6] Batch [1330]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.153105,	
2017-06-23 21:06:36,590 Epoch[6] Batch [1340]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.153240,	
2017-06-23 21:06:42,573 Epoch[6] Batch [1350]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.153290,	
2017-06-23 21:06:48,840 Epoch[6] Batch [1360]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.153232,	
2017-06-23 21:06:54,867 Epoch[6] Batch [1370]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.153453,	
2017-06-23 21:07:00,969 Epoch[6] Batch [1380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.153472,	
2017-06-23 21:07:07,120 Epoch[6] Batch [1390]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.153361,	
2017-06-23 21:07:13,374 Epoch[6] Batch [1400]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.153357,	
2017-06-23 21:07:19,856 Epoch[6] Batch [1410]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.153237,	
2017-06-23 21:07:26,218 Epoch[6] Batch [1420]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.153285,	
2017-06-23 21:07:32,390 Epoch[6] Batch [1430]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.153156,	
2017-06-23 21:07:38,154 Epoch[6] Batch [1440]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.153170,	
2017-06-23 21:07:43,981 Epoch[6] Batch [1450]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.153170,	
2017-06-23 21:07:49,487 Epoch[6] Batch [1460]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.153197,	
2017-06-23 21:07:55,347 Epoch[6] Batch [1470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.153345,	
2017-06-23 21:08:01,311 Epoch[6] Batch [1480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.153240,	
2017-06-23 21:08:04,877 Epoch[6] Train-FCNLogLoss=0.153156
2017-06-23 21:08:04,877 Epoch[6] Time cost=897.315
2017-06-23 21:08:06,098 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0007.params"
2017-06-23 21:08:09,853 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0007.states"
2017-06-23 21:08:16,740 Epoch[7] Batch [10]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.134979,	
2017-06-23 21:08:22,741 Epoch[7] Batch [20]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.132369,	
2017-06-23 21:08:28,631 Epoch[7] Batch [30]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.132375,	
2017-06-23 21:08:34,605 Epoch[7] Batch [40]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.131704,	
2017-06-23 21:08:40,550 Epoch[7] Batch [50]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.134655,	
2017-06-23 21:08:46,509 Epoch[7] Batch [60]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.136230,	
2017-06-23 21:08:52,432 Epoch[7] Batch [70]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.135776,	
2017-06-23 21:08:58,370 Epoch[7] Batch [80]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.140210,	
2017-06-23 21:09:04,526 Epoch[7] Batch [90]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.139524,	
2017-06-23 21:09:10,455 Epoch[7] Batch [100]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.139977,	
2017-06-23 21:09:16,421 Epoch[7] Batch [110]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.141390,	
2017-06-23 21:09:22,333 Epoch[7] Batch [120]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.143171,	
2017-06-23 21:09:28,328 Epoch[7] Batch [130]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.143294,	
2017-06-23 21:09:34,166 Epoch[7] Batch [140]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.141923,	
2017-06-23 21:09:40,117 Epoch[7] Batch [150]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.142629,	
2017-06-23 21:09:46,121 Epoch[7] Batch [160]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.141864,	
2017-06-23 21:09:52,115 Epoch[7] Batch [170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.141203,	
2017-06-23 21:09:58,015 Epoch[7] Batch [180]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.143081,	
2017-06-23 21:10:03,980 Epoch[7] Batch [190]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.142759,	
2017-06-23 21:10:09,936 Epoch[7] Batch [200]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.142706,	
2017-06-23 21:10:15,890 Epoch[7] Batch [210]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.142711,	
2017-06-23 21:10:21,783 Epoch[7] Batch [220]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.142996,	
2017-06-23 21:10:27,735 Epoch[7] Batch [230]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.143580,	
2017-06-23 21:10:33,500 Epoch[7] Batch [240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.143952,	
2017-06-23 21:10:39,687 Epoch[7] Batch [250]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.143460,	
2017-06-23 21:10:45,417 Epoch[7] Batch [260]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.143555,	
2017-06-23 21:10:51,408 Epoch[7] Batch [270]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.144335,	
2017-06-23 21:10:57,344 Epoch[7] Batch [280]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.144096,	
2017-06-23 21:11:03,355 Epoch[7] Batch [290]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.144735,	
2017-06-23 21:11:09,274 Epoch[7] Batch [300]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.145622,	
2017-06-23 21:11:15,490 Epoch[7] Batch [310]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.146339,	
2017-06-23 21:11:21,261 Epoch[7] Batch [320]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.147521,	
2017-06-23 21:11:27,161 Epoch[7] Batch [330]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.148119,	
2017-06-23 21:11:32,689 Epoch[7] Batch [340]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.147860,	
2017-06-23 21:11:38,631 Epoch[7] Batch [350]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.147569,	
2017-06-23 21:11:44,550 Epoch[7] Batch [360]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.147612,	
2017-06-23 21:11:50,527 Epoch[7] Batch [370]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.147712,	
2017-06-23 21:11:56,457 Epoch[7] Batch [380]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.147278,	
2017-06-23 21:12:02,372 Epoch[7] Batch [390]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.148338,	
2017-06-23 21:12:08,348 Epoch[7] Batch [400]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.148235,	
2017-06-23 21:12:14,312 Epoch[7] Batch [410]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.148131,	
2017-06-23 21:12:20,289 Epoch[7] Batch [420]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.148214,	
2017-06-23 21:12:26,283 Epoch[7] Batch [430]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.147948,	
2017-06-23 21:12:32,231 Epoch[7] Batch [440]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.147954,	
2017-06-23 21:12:38,189 Epoch[7] Batch [450]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.147876,	
2017-06-23 21:12:44,217 Epoch[7] Batch [460]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.147669,	
2017-06-23 21:12:50,095 Epoch[7] Batch [470]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.147915,	
2017-06-23 21:12:56,060 Epoch[7] Batch [480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.148115,	
2017-06-23 21:13:02,030 Epoch[7] Batch [490]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.147766,	
2017-06-23 21:13:08,023 Epoch[7] Batch [500]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.148132,	
2017-06-23 21:13:13,871 Epoch[7] Batch [510]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.148398,	
2017-06-23 21:13:19,796 Epoch[7] Batch [520]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.148500,	
2017-06-23 21:13:25,819 Epoch[7] Batch [530]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.148310,	
2017-06-23 21:13:31,703 Epoch[7] Batch [540]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.148588,	
2017-06-23 21:13:37,868 Epoch[7] Batch [550]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.148720,	
2017-06-23 21:13:44,510 Epoch[7] Batch [560]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.148855,	
2017-06-23 21:13:51,183 Epoch[7] Batch [570]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.148720,	
2017-06-23 21:13:57,459 Epoch[7] Batch [580]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.148660,	
2017-06-23 21:14:04,058 Epoch[7] Batch [590]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.148769,	
2017-06-23 21:14:10,425 Epoch[7] Batch [600]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.148935,	
2017-06-23 21:14:16,700 Epoch[7] Batch [610]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.148640,	
2017-06-23 21:14:22,848 Epoch[7] Batch [620]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.148479,	
2017-06-23 21:14:29,040 Epoch[7] Batch [630]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.148484,	
2017-06-23 21:14:35,080 Epoch[7] Batch [640]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.148623,	
2017-06-23 21:14:41,244 Epoch[7] Batch [650]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.149109,	
2017-06-23 21:14:47,350 Epoch[7] Batch [660]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.149084,	
2017-06-23 21:14:53,790 Epoch[7] Batch [670]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.149239,	
2017-06-23 21:15:00,150 Epoch[7] Batch [680]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.149197,	
2017-06-23 21:15:06,277 Epoch[7] Batch [690]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.149085,	
2017-06-23 21:15:12,722 Epoch[7] Batch [700]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.149021,	
2017-06-23 21:15:18,741 Epoch[7] Batch [710]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.149088,	
2017-06-23 21:15:24,655 Epoch[7] Batch [720]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.149515,	
2017-06-23 21:15:30,651 Epoch[7] Batch [730]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.149986,	
2017-06-23 21:15:36,579 Epoch[7] Batch [740]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.150096,	
2017-06-23 21:15:42,502 Epoch[7] Batch [750]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.150045,	
2017-06-23 21:15:48,533 Epoch[7] Batch [760]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.150200,	
2017-06-23 21:15:54,667 Epoch[7] Batch [770]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.150165,	
2017-06-23 21:16:00,567 Epoch[7] Batch [780]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.150042,	
2017-06-23 21:16:06,622 Epoch[7] Batch [790]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.149953,	
2017-06-23 21:16:12,902 Epoch[7] Batch [800]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.149743,	
2017-06-23 21:16:19,124 Epoch[7] Batch [810]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.149703,	
2017-06-23 21:16:24,989 Epoch[7] Batch [820]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.149715,	
2017-06-23 21:16:30,930 Epoch[7] Batch [830]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.149439,	
2017-06-23 21:16:36,963 Epoch[7] Batch [840]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.149416,	
2017-06-23 21:16:42,938 Epoch[7] Batch [850]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.149465,	
2017-06-23 21:16:49,113 Epoch[7] Batch [860]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.149461,	
2017-06-23 21:16:55,436 Epoch[7] Batch [870]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.149454,	
2017-06-23 21:17:02,170 Epoch[7] Batch [880]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.149323,	
2017-06-23 21:17:08,062 Epoch[7] Batch [890]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.149108,	
2017-06-23 21:17:14,389 Epoch[7] Batch [900]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.149124,	
2017-06-23 21:17:21,038 Epoch[7] Batch [910]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.149094,	
2017-06-23 21:17:27,017 Epoch[7] Batch [920]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.148935,	
2017-06-23 21:17:33,457 Epoch[7] Batch [930]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.148752,	
2017-06-23 21:17:39,941 Epoch[7] Batch [940]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.148504,	
2017-06-23 21:17:46,722 Epoch[7] Batch [950]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.148492,	
2017-06-23 21:17:53,266 Epoch[7] Batch [960]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.148544,	
2017-06-23 21:17:59,843 Epoch[7] Batch [970]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.148594,	
2017-06-23 21:18:06,650 Epoch[7] Batch [980]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.148489,	
2017-06-23 21:18:13,532 Epoch[7] Batch [990]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.148323,	
2017-06-23 21:18:19,785 Epoch[7] Batch [1000]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.148179,	
2017-06-23 21:18:26,579 Epoch[7] Batch [1010]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.148250,	
2017-06-23 21:18:32,896 Epoch[7] Batch [1020]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.148368,	
2017-06-23 21:18:39,017 Epoch[7] Batch [1030]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.148361,	
2017-06-23 21:18:44,980 Epoch[7] Batch [1040]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.148383,	
2017-06-23 21:18:51,730 Epoch[7] Batch [1050]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.148311,	
2017-06-23 21:18:58,259 Epoch[7] Batch [1060]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.148121,	
2017-06-23 21:19:04,695 Epoch[7] Batch [1070]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.148031,	
2017-06-23 21:19:11,389 Epoch[7] Batch [1080]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.148003,	
2017-06-23 21:19:18,104 Epoch[7] Batch [1090]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.148082,	
2017-06-23 21:19:24,969 Epoch[7] Batch [1100]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.148013,	
2017-06-23 21:19:31,459 Epoch[7] Batch [1110]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.148081,	
2017-06-23 21:19:38,136 Epoch[7] Batch [1120]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.148141,	
2017-06-23 21:19:44,880 Epoch[7] Batch [1130]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.147995,	
2017-06-23 21:19:51,818 Epoch[7] Batch [1140]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.148121,	
2017-06-23 21:19:58,559 Epoch[7] Batch [1150]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.148057,	
2017-06-23 21:20:04,895 Epoch[7] Batch [1160]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.148081,	
2017-06-23 21:20:11,483 Epoch[7] Batch [1170]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.147965,	
2017-06-23 21:20:17,927 Epoch[7] Batch [1180]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.147954,	
2017-06-23 21:20:24,216 Epoch[7] Batch [1190]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.147861,	
2017-06-23 21:20:30,638 Epoch[7] Batch [1200]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.147909,	
2017-06-23 21:20:37,133 Epoch[7] Batch [1210]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.147814,	
2017-06-23 21:20:43,553 Epoch[7] Batch [1220]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.147715,	
2017-06-23 21:20:50,312 Epoch[7] Batch [1230]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.147628,	
2017-06-23 21:20:56,930 Epoch[7] Batch [1240]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.147445,	
2017-06-23 21:21:03,442 Epoch[7] Batch [1250]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.147739,	
2017-06-23 21:21:09,787 Epoch[7] Batch [1260]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.147820,	
2017-06-23 21:21:16,351 Epoch[7] Batch [1270]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.147834,	
2017-06-23 21:21:22,637 Epoch[7] Batch [1280]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.147948,	
2017-06-23 21:21:28,628 Epoch[7] Batch [1290]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.148092,	
2017-06-23 21:21:34,678 Epoch[7] Batch [1300]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.148132,	
2017-06-23 21:21:40,849 Epoch[7] Batch [1310]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.148374,	
2017-06-23 21:21:46,743 Epoch[7] Batch [1320]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.148473,	
2017-06-23 21:21:52,671 Epoch[7] Batch [1330]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.148505,	
2017-06-23 21:21:58,684 Epoch[7] Batch [1340]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.148460,	
2017-06-23 21:22:05,246 Epoch[7] Batch [1350]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.148570,	
2017-06-23 21:22:11,305 Epoch[7] Batch [1360]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.148501,	
2017-06-23 21:22:17,333 Epoch[7] Batch [1370]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.148475,	
2017-06-23 21:22:23,261 Epoch[7] Batch [1380]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.148505,	
2017-06-23 21:22:29,294 Epoch[7] Batch [1390]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.148490,	
2017-06-23 21:22:35,112 Epoch[7] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.148482,	
2017-06-23 21:22:41,045 Epoch[7] Batch [1410]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.148391,	
2017-06-23 21:22:46,853 Epoch[7] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.148282,	
2017-06-23 21:22:52,833 Epoch[7] Batch [1430]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.148289,	
2017-06-23 21:22:59,016 Epoch[7] Batch [1440]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.148295,	
2017-06-23 21:23:05,063 Epoch[7] Batch [1450]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.148404,	
2017-06-23 21:23:11,024 Epoch[7] Batch [1460]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.148407,	
2017-06-23 21:23:16,955 Epoch[7] Batch [1470]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.148424,	
2017-06-23 21:23:22,989 Epoch[7] Batch [1480]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.148393,	
2017-06-23 21:23:26,539 Epoch[7] Train-FCNLogLoss=0.148563
2017-06-23 21:23:26,539 Epoch[7] Time cost=916.685
2017-06-23 21:23:27,515 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0008.params"
2017-06-23 21:23:31,407 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0008.states"
2017-06-23 21:23:38,551 Epoch[8] Batch [10]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.163388,	
2017-06-23 21:23:44,446 Epoch[8] Batch [20]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.149956,	
2017-06-23 21:23:50,473 Epoch[8] Batch [30]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.146924,	
2017-06-23 21:23:56,409 Epoch[8] Batch [40]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.143484,	
2017-06-23 21:24:02,324 Epoch[8] Batch [50]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.142957,	
2017-06-23 21:24:08,487 Epoch[8] Batch [60]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.139306,	
2017-06-23 21:24:14,441 Epoch[8] Batch [70]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.138090,	
2017-06-23 21:24:20,369 Epoch[8] Batch [80]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.138198,	
2017-06-23 21:24:26,375 Epoch[8] Batch [90]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.137233,	
2017-06-23 21:24:32,237 Epoch[8] Batch [100]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.136274,	
2017-06-23 21:24:38,152 Epoch[8] Batch [110]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.134308,	
2017-06-23 21:24:44,135 Epoch[8] Batch [120]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.134636,	
2017-06-23 21:24:50,022 Epoch[8] Batch [130]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.136401,	
2017-06-23 21:24:56,004 Epoch[8] Batch [140]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.135664,	
2017-06-23 21:25:01,862 Epoch[8] Batch [150]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.135626,	
2017-06-23 21:25:07,837 Epoch[8] Batch [160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.135897,	
2017-06-23 21:25:13,792 Epoch[8] Batch [170]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.136561,	
2017-06-23 21:25:19,563 Epoch[8] Batch [180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.136241,	
2017-06-23 21:25:25,684 Epoch[8] Batch [190]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.136480,	
2017-06-23 21:25:31,832 Epoch[8] Batch [200]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.136882,	
2017-06-23 21:25:37,693 Epoch[8] Batch [210]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.136551,	
2017-06-23 21:25:43,421 Epoch[8] Batch [220]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.136759,	
2017-06-23 21:25:48,723 Epoch[8] Batch [230]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.137722,	
2017-06-23 21:25:54,615 Epoch[8] Batch [240]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.137838,	
2017-06-23 21:26:00,569 Epoch[8] Batch [250]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.137527,	
2017-06-23 21:26:06,516 Epoch[8] Batch [260]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.137646,	
2017-06-23 21:26:12,498 Epoch[8] Batch [270]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.137683,	
2017-06-23 21:26:18,485 Epoch[8] Batch [280]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.137852,	
2017-06-23 21:26:24,317 Epoch[8] Batch [290]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.138413,	
2017-06-23 21:26:30,258 Epoch[8] Batch [300]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.139441,	
2017-06-23 21:26:36,219 Epoch[8] Batch [310]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.139900,	
2017-06-23 21:26:42,200 Epoch[8] Batch [320]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.139858,	
2017-06-23 21:26:48,144 Epoch[8] Batch [330]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.140558,	
2017-06-23 21:26:54,081 Epoch[8] Batch [340]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.141120,	
2017-06-23 21:27:00,150 Epoch[8] Batch [350]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.141620,	
2017-06-23 21:27:06,600 Epoch[8] Batch [360]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.142024,	
2017-06-23 21:27:12,710 Epoch[8] Batch [370]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.141969,	
2017-06-23 21:27:18,925 Epoch[8] Batch [380]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.141632,	
2017-06-23 21:27:25,191 Epoch[8] Batch [390]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.141634,	
2017-06-23 21:27:31,433 Epoch[8] Batch [400]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.142009,	
2017-06-23 21:27:38,150 Epoch[8] Batch [410]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.141855,	
2017-06-23 21:27:44,630 Epoch[8] Batch [420]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.143111,	
2017-06-23 21:27:50,923 Epoch[8] Batch [430]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.143355,	
2017-06-23 21:27:57,190 Epoch[8] Batch [440]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.143570,	
2017-06-23 21:28:03,589 Epoch[8] Batch [450]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.143804,	
2017-06-23 21:28:10,306 Epoch[8] Batch [460]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.143605,	
2017-06-23 21:28:16,914 Epoch[8] Batch [470]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.143350,	
2017-06-23 21:28:23,288 Epoch[8] Batch [480]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.143365,	
2017-06-23 21:28:29,865 Epoch[8] Batch [490]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.143159,	
2017-06-23 21:28:35,900 Epoch[8] Batch [500]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.143271,	
2017-06-23 21:28:41,907 Epoch[8] Batch [510]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.143685,	
2017-06-23 21:28:48,261 Epoch[8] Batch [520]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.143660,	
2017-06-23 21:28:54,270 Epoch[8] Batch [530]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.144249,	
2017-06-23 21:29:00,499 Epoch[8] Batch [540]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.144672,	
2017-06-23 21:29:06,740 Epoch[8] Batch [550]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.144703,	
2017-06-23 21:29:12,926 Epoch[8] Batch [560]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.144940,	
2017-06-23 21:29:19,348 Epoch[8] Batch [570]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.144888,	
2017-06-23 21:29:25,527 Epoch[8] Batch [580]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.145262,	
2017-06-23 21:29:32,168 Epoch[8] Batch [590]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.145356,	
2017-06-23 21:29:38,413 Epoch[8] Batch [600]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.145972,	
2017-06-23 21:29:45,282 Epoch[8] Batch [610]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.146016,	
2017-06-23 21:29:51,579 Epoch[8] Batch [620]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.145769,	
2017-06-23 21:29:58,150 Epoch[8] Batch [630]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.145589,	
2017-06-23 21:30:04,343 Epoch[8] Batch [640]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.145565,	
2017-06-23 21:30:10,763 Epoch[8] Batch [650]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.145662,	
2017-06-23 21:30:17,108 Epoch[8] Batch [660]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.146067,	
2017-06-23 21:30:23,701 Epoch[8] Batch [670]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.146106,	
2017-06-23 21:30:30,179 Epoch[8] Batch [680]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.145997,	
2017-06-23 21:30:36,859 Epoch[8] Batch [690]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.146150,	
2017-06-23 21:30:43,014 Epoch[8] Batch [700]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.146052,	
2017-06-23 21:30:49,048 Epoch[8] Batch [710]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.146197,	
2017-06-23 21:30:55,341 Epoch[8] Batch [720]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.146561,	
2017-06-23 21:31:01,448 Epoch[8] Batch [730]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.146381,	
2017-06-23 21:31:07,819 Epoch[8] Batch [740]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.146672,	
2017-06-23 21:31:14,370 Epoch[8] Batch [750]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.146288,	
2017-06-23 21:31:20,718 Epoch[8] Batch [760]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.146174,	
2017-06-23 21:31:26,897 Epoch[8] Batch [770]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.145851,	
2017-06-23 21:31:33,323 Epoch[8] Batch [780]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.145971,	
2017-06-23 21:31:39,130 Epoch[8] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.145875,	
2017-06-23 21:31:45,329 Epoch[8] Batch [800]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.145731,	
2017-06-23 21:31:51,272 Epoch[8] Batch [810]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.145759,	
2017-06-23 21:31:57,503 Epoch[8] Batch [820]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.145697,	
2017-06-23 21:32:03,751 Epoch[8] Batch [830]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.145918,	
2017-06-23 21:32:10,108 Epoch[8] Batch [840]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.145895,	
2017-06-23 21:32:16,242 Epoch[8] Batch [850]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.145635,	
2017-06-23 21:32:23,012 Epoch[8] Batch [860]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.145824,	
2017-06-23 21:32:29,426 Epoch[8] Batch [870]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.145771,	
2017-06-23 21:32:36,154 Epoch[8] Batch [880]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.145683,	
2017-06-23 21:32:42,339 Epoch[8] Batch [890]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.145710,	
2017-06-23 21:32:49,000 Epoch[8] Batch [900]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.145820,	
2017-06-23 21:32:56,183 Epoch[8] Batch [910]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.145767,	
2017-06-23 21:33:02,490 Epoch[8] Batch [920]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.145682,	
2017-06-23 21:33:09,531 Epoch[8] Batch [930]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.145857,	
2017-06-23 21:33:16,067 Epoch[8] Batch [940]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.145685,	
2017-06-23 21:33:22,517 Epoch[8] Batch [950]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.145541,	
2017-06-23 21:33:28,958 Epoch[8] Batch [960]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.145456,	
2017-06-23 21:33:35,190 Epoch[8] Batch [970]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.145602,	
2017-06-23 21:33:41,090 Epoch[8] Batch [980]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.145853,	
2017-06-23 21:33:47,426 Epoch[8] Batch [990]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.145834,	
2017-06-23 21:33:53,828 Epoch[8] Batch [1000]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.145796,	
2017-06-23 21:34:00,312 Epoch[8] Batch [1010]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.145828,	
2017-06-23 21:34:06,702 Epoch[8] Batch [1020]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.145813,	
2017-06-23 21:34:12,759 Epoch[8] Batch [1030]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.145629,	
2017-06-23 21:34:18,897 Epoch[8] Batch [1040]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.145829,	
2017-06-23 21:34:25,138 Epoch[8] Batch [1050]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.145712,	
2017-06-23 21:34:31,297 Epoch[8] Batch [1060]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.145605,	
2017-06-23 21:34:37,517 Epoch[8] Batch [1070]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.145558,	
2017-06-23 21:34:43,573 Epoch[8] Batch [1080]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.145486,	
2017-06-23 21:34:49,613 Epoch[8] Batch [1090]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.145405,	
2017-06-23 21:34:55,814 Epoch[8] Batch [1100]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.145329,	
2017-06-23 21:35:01,755 Epoch[8] Batch [1110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.145189,	
2017-06-23 21:35:07,735 Epoch[8] Batch [1120]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.145164,	
2017-06-23 21:35:13,637 Epoch[8] Batch [1130]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.145035,	
2017-06-23 21:35:19,511 Epoch[8] Batch [1140]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.144900,	
2017-06-23 21:35:25,469 Epoch[8] Batch [1150]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.144744,	
2017-06-23 21:35:31,375 Epoch[8] Batch [1160]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.144750,	
2017-06-23 21:35:37,323 Epoch[8] Batch [1170]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.144688,	
2017-06-23 21:35:43,314 Epoch[8] Batch [1180]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.144784,	
2017-06-23 21:35:49,205 Epoch[8] Batch [1190]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.144754,	
2017-06-23 21:35:55,145 Epoch[8] Batch [1200]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.144624,	
2017-06-23 21:36:01,083 Epoch[8] Batch [1210]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.144650,	
2017-06-23 21:36:07,032 Epoch[8] Batch [1220]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.144690,	
2017-06-23 21:36:12,931 Epoch[8] Batch [1230]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.145036,	
2017-06-23 21:36:18,872 Epoch[8] Batch [1240]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.145040,	
2017-06-23 21:36:24,794 Epoch[8] Batch [1250]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.144988,	
2017-06-23 21:36:30,694 Epoch[8] Batch [1260]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.145077,	
2017-06-23 21:36:36,633 Epoch[8] Batch [1270]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.144980,	
2017-06-23 21:36:42,588 Epoch[8] Batch [1280]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.144952,	
2017-06-23 21:36:48,503 Epoch[8] Batch [1290]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.144883,	
2017-06-23 21:36:54,462 Epoch[8] Batch [1300]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.144838,	
2017-06-23 21:37:00,280 Epoch[8] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.144696,	
2017-06-23 21:37:06,558 Epoch[8] Batch [1320]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.144601,	
2017-06-23 21:37:12,491 Epoch[8] Batch [1330]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.144718,	
2017-06-23 21:37:18,590 Epoch[8] Batch [1340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.144646,	
2017-06-23 21:37:24,634 Epoch[8] Batch [1350]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.144770,	
2017-06-23 21:37:30,672 Epoch[8] Batch [1360]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.144810,	
2017-06-23 21:37:36,936 Epoch[8] Batch [1370]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.144758,	
2017-06-23 21:37:42,762 Epoch[8] Batch [1380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.144737,	
2017-06-23 21:37:48,669 Epoch[8] Batch [1390]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.144549,	
2017-06-23 21:37:54,906 Epoch[8] Batch [1400]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.144446,	
2017-06-23 21:38:00,842 Epoch[8] Batch [1410]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.144404,	
2017-06-23 21:38:06,775 Epoch[8] Batch [1420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.144348,	
2017-06-23 21:38:12,701 Epoch[8] Batch [1430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.144329,	
2017-06-23 21:38:18,677 Epoch[8] Batch [1440]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.144249,	
2017-06-23 21:38:24,536 Epoch[8] Batch [1450]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.144350,	
2017-06-23 21:38:30,419 Epoch[8] Batch [1460]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.144358,	
2017-06-23 21:38:36,256 Epoch[8] Batch [1470]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.144450,	
2017-06-23 21:38:42,068 Epoch[8] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.144366,	
2017-06-23 21:38:45,521 Epoch[8] Train-FCNLogLoss=0.144239
2017-06-23 21:38:45,522 Epoch[8] Time cost=914.114
2017-06-23 21:38:46,524 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0009.params"
2017-06-23 21:38:50,725 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0009.states"
2017-06-23 21:38:59,291 Epoch[9] Batch [10]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.138060,	
2017-06-23 21:39:06,100 Epoch[9] Batch [20]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.139076,	
2017-06-23 21:39:12,182 Epoch[9] Batch [30]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.144247,	
2017-06-23 21:39:18,431 Epoch[9] Batch [40]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.139568,	
2017-06-23 21:39:24,655 Epoch[9] Batch [50]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.139648,	
2017-06-23 21:39:30,826 Epoch[9] Batch [60]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.139756,	
2017-06-23 21:39:36,751 Epoch[9] Batch [70]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.140390,	
2017-06-23 21:39:42,668 Epoch[9] Batch [80]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.138007,	
2017-06-23 21:39:48,650 Epoch[9] Batch [90]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.140714,	
2017-06-23 21:39:54,659 Epoch[9] Batch [100]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.139915,	
2017-06-23 21:40:00,553 Epoch[9] Batch [110]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.138496,	
2017-06-23 21:40:06,563 Epoch[9] Batch [120]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.138295,	
2017-06-23 21:40:12,463 Epoch[9] Batch [130]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.138371,	
2017-06-23 21:40:18,395 Epoch[9] Batch [140]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.138245,	
2017-06-23 21:40:24,405 Epoch[9] Batch [150]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.137145,	
2017-06-23 21:40:30,315 Epoch[9] Batch [160]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.138107,	
2017-06-23 21:40:36,342 Epoch[9] Batch [170]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.139909,	
2017-06-23 21:40:42,316 Epoch[9] Batch [180]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.140631,	
2017-06-23 21:40:48,519 Epoch[9] Batch [190]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.140194,	
2017-06-23 21:40:54,592 Epoch[9] Batch [200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.140800,	
2017-06-23 21:41:00,721 Epoch[9] Batch [210]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.141039,	
2017-06-23 21:41:06,591 Epoch[9] Batch [220]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.141463,	
2017-06-23 21:41:13,117 Epoch[9] Batch [230]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.141587,	
2017-06-23 21:41:20,082 Epoch[9] Batch [240]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.141185,	
2017-06-23 21:41:26,483 Epoch[9] Batch [250]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.141043,	
2017-06-23 21:41:33,261 Epoch[9] Batch [260]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.141099,	
2017-06-23 21:41:39,677 Epoch[9] Batch [270]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.141932,	
2017-06-23 21:41:46,144 Epoch[9] Batch [280]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.141765,	
2017-06-23 21:41:52,291 Epoch[9] Batch [290]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.140944,	
2017-06-23 21:41:58,665 Epoch[9] Batch [300]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.140874,	
2017-06-23 21:42:05,123 Epoch[9] Batch [310]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.140720,	
2017-06-23 21:42:11,330 Epoch[9] Batch [320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.140220,	
2017-06-23 21:42:18,105 Epoch[9] Batch [330]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.139927,	
2017-06-23 21:42:25,250 Epoch[9] Batch [340]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.139716,	
2017-06-23 21:42:31,904 Epoch[9] Batch [350]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.139654,	
2017-06-23 21:42:38,480 Epoch[9] Batch [360]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.139914,	
2017-06-23 21:42:45,209 Epoch[9] Batch [370]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.139883,	
2017-06-23 21:42:51,812 Epoch[9] Batch [380]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.139896,	
2017-06-23 21:42:58,530 Epoch[9] Batch [390]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.140198,	
2017-06-23 21:43:05,603 Epoch[9] Batch [400]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.140008,	
2017-06-23 21:43:12,944 Epoch[9] Batch [410]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.139850,	
2017-06-23 21:43:19,764 Epoch[9] Batch [420]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.139434,	
2017-06-23 21:43:26,381 Epoch[9] Batch [430]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.139222,	
2017-06-23 21:43:33,315 Epoch[9] Batch [440]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.139525,	
2017-06-23 21:43:40,197 Epoch[9] Batch [450]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.139627,	
2017-06-23 21:43:46,526 Epoch[9] Batch [460]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.139648,	
2017-06-23 21:43:52,706 Epoch[9] Batch [470]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.139497,	
2017-06-23 21:43:59,146 Epoch[9] Batch [480]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.139498,	
2017-06-23 21:44:05,358 Epoch[9] Batch [490]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.139408,	
2017-06-23 21:44:12,239 Epoch[9] Batch [500]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.139375,	
2017-06-23 21:44:18,940 Epoch[9] Batch [510]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.139263,	
2017-06-23 21:44:25,530 Epoch[9] Batch [520]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.138957,	
2017-06-23 21:44:32,204 Epoch[9] Batch [530]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.138654,	
2017-06-23 21:44:38,599 Epoch[9] Batch [540]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.138486,	
2017-06-23 21:44:45,308 Epoch[9] Batch [550]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.139144,	
2017-06-23 21:44:51,296 Epoch[9] Batch [560]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.139127,	
2017-06-23 21:44:57,488 Epoch[9] Batch [570]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.139223,	
2017-06-23 21:45:03,422 Epoch[9] Batch [580]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.139477,	
2017-06-23 21:45:09,634 Epoch[9] Batch [590]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.139416,	
2017-06-23 21:45:15,669 Epoch[9] Batch [600]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.139385,	
2017-06-23 21:45:21,760 Epoch[9] Batch [610]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.139241,	
2017-06-23 21:45:27,911 Epoch[9] Batch [620]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.139302,	
2017-06-23 21:45:33,861 Epoch[9] Batch [630]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.139022,	
2017-06-23 21:45:39,988 Epoch[9] Batch [640]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.138982,	
2017-06-23 21:45:46,120 Epoch[9] Batch [650]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.139088,	
2017-06-23 21:45:52,472 Epoch[9] Batch [660]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.139145,	
2017-06-23 21:45:59,006 Epoch[9] Batch [670]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.139057,	
2017-06-23 21:46:05,164 Epoch[9] Batch [680]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.139049,	
2017-06-23 21:46:11,228 Epoch[9] Batch [690]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.139142,	
2017-06-23 21:46:17,710 Epoch[9] Batch [700]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.139160,	
2017-06-23 21:46:23,748 Epoch[9] Batch [710]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.139064,	
2017-06-23 21:46:30,091 Epoch[9] Batch [720]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.138814,	
2017-06-23 21:46:36,598 Epoch[9] Batch [730]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.139007,	
2017-06-23 21:46:43,013 Epoch[9] Batch [740]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.139032,	
2017-06-23 21:46:49,455 Epoch[9] Batch [750]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.138782,	
2017-06-23 21:46:55,975 Epoch[9] Batch [760]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.139510,	
2017-06-23 21:47:02,553 Epoch[9] Batch [770]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.139532,	
2017-06-23 21:47:08,860 Epoch[9] Batch [780]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.139497,	
2017-06-23 21:47:15,073 Epoch[9] Batch [790]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.139665,	
2017-06-23 21:47:21,912 Epoch[9] Batch [800]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.139665,	
2017-06-23 21:47:28,340 Epoch[9] Batch [810]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.139879,	
2017-06-23 21:47:34,693 Epoch[9] Batch [820]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.140851,	
2017-06-23 21:47:41,332 Epoch[9] Batch [830]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.141266,	
2017-06-23 21:47:47,632 Epoch[9] Batch [840]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.141312,	
2017-06-23 21:47:54,134 Epoch[9] Batch [850]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.141396,	
2017-06-23 21:48:00,445 Epoch[9] Batch [860]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.141725,	
2017-06-23 21:48:06,594 Epoch[9] Batch [870]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.141874,	
2017-06-23 21:48:12,709 Epoch[9] Batch [880]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.141893,	
2017-06-23 21:48:18,907 Epoch[9] Batch [890]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.141813,	
2017-06-23 21:48:25,178 Epoch[9] Batch [900]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.141983,	
2017-06-23 21:48:31,245 Epoch[9] Batch [910]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.141779,	
2017-06-23 21:48:37,118 Epoch[9] Batch [920]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.142260,	
2017-06-23 21:48:43,328 Epoch[9] Batch [930]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.142547,	
2017-06-23 21:48:49,526 Epoch[9] Batch [940]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.142538,	
2017-06-23 21:48:56,066 Epoch[9] Batch [950]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.142579,	
2017-06-23 21:49:02,513 Epoch[9] Batch [960]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.142389,	
2017-06-23 21:49:08,578 Epoch[9] Batch [970]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.142383,	
2017-06-23 21:49:14,553 Epoch[9] Batch [980]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.142526,	
2017-06-23 21:49:20,444 Epoch[9] Batch [990]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.142506,	
2017-06-23 21:49:26,399 Epoch[9] Batch [1000]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.142635,	
2017-06-23 21:49:32,365 Epoch[9] Batch [1010]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.142743,	
2017-06-23 21:49:38,402 Epoch[9] Batch [1020]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.142757,	
2017-06-23 21:49:44,424 Epoch[9] Batch [1030]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.142677,	
2017-06-23 21:49:50,266 Epoch[9] Batch [1040]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.142589,	
2017-06-23 21:49:56,145 Epoch[9] Batch [1050]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.142648,	
2017-06-23 21:50:02,400 Epoch[9] Batch [1060]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.142578,	
2017-06-23 21:50:08,740 Epoch[9] Batch [1070]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.142569,	
2017-06-23 21:50:14,844 Epoch[9] Batch [1080]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.142603,	
2017-06-23 21:50:21,240 Epoch[9] Batch [1090]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.142485,	
2017-06-23 21:50:27,108 Epoch[9] Batch [1100]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.142270,	
2017-06-23 21:50:33,048 Epoch[9] Batch [1110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.142274,	
2017-06-23 21:50:38,976 Epoch[9] Batch [1120]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.142312,	
2017-06-23 21:50:44,921 Epoch[9] Batch [1130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.142377,	
2017-06-23 21:50:50,902 Epoch[9] Batch [1140]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.142342,	
2017-06-23 21:50:56,891 Epoch[9] Batch [1150]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.142542,	
2017-06-23 21:51:02,806 Epoch[9] Batch [1160]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.142480,	
2017-06-23 21:51:08,777 Epoch[9] Batch [1170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.142748,	
2017-06-23 21:51:14,973 Epoch[9] Batch [1180]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.142803,	
2017-06-23 21:51:21,278 Epoch[9] Batch [1190]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.142882,	
2017-06-23 21:51:27,519 Epoch[9] Batch [1200]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.142830,	
2017-06-23 21:51:33,894 Epoch[9] Batch [1210]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.142728,	
2017-06-23 21:51:39,522 Epoch[9] Batch [1220]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.142633,	
2017-06-23 21:51:45,810 Epoch[9] Batch [1230]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.142863,	
2017-06-23 21:51:51,591 Epoch[9] Batch [1240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.142953,	
2017-06-23 21:51:57,497 Epoch[9] Batch [1250]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.143030,	
2017-06-23 21:52:03,393 Epoch[9] Batch [1260]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.143003,	
2017-06-23 21:52:09,300 Epoch[9] Batch [1270]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.142907,	
2017-06-23 21:52:15,278 Epoch[9] Batch [1280]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.142931,	
2017-06-23 21:52:21,211 Epoch[9] Batch [1290]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.142864,	
2017-06-23 21:52:27,164 Epoch[9] Batch [1300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.142792,	
2017-06-23 21:52:33,120 Epoch[9] Batch [1310]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.142724,	
2017-06-23 21:52:39,117 Epoch[9] Batch [1320]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.142540,	
2017-06-23 21:52:44,985 Epoch[9] Batch [1330]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.142503,	
2017-06-23 21:52:50,914 Epoch[9] Batch [1340]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.142452,	
2017-06-23 21:52:56,870 Epoch[9] Batch [1350]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.142526,	
2017-06-23 21:53:02,825 Epoch[9] Batch [1360]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.142512,	
2017-06-23 21:53:08,819 Epoch[9] Batch [1370]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.142261,	
2017-06-23 21:53:14,846 Epoch[9] Batch [1380]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.142266,	
2017-06-23 21:53:20,724 Epoch[9] Batch [1390]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.142074,	
2017-06-23 21:53:26,643 Epoch[9] Batch [1400]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.142000,	
2017-06-23 21:53:32,762 Epoch[9] Batch [1410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.142236,	
2017-06-23 21:53:38,571 Epoch[9] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.142226,	
2017-06-23 21:53:44,494 Epoch[9] Batch [1430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.142041,	
2017-06-23 21:53:50,392 Epoch[9] Batch [1440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.142017,	
2017-06-23 21:53:56,533 Epoch[9] Batch [1450]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.141891,	
2017-06-23 21:54:02,969 Epoch[9] Batch [1460]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.141915,	
2017-06-23 21:54:09,010 Epoch[9] Batch [1470]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.141768,	
2017-06-23 21:54:15,306 Epoch[9] Batch [1480]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.141642,	
2017-06-23 21:54:18,841 Epoch[9] Train-FCNLogLoss=0.141634
2017-06-23 21:54:18,842 Epoch[9] Time cost=928.116
2017-06-23 21:54:19,845 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0010.params"
2017-06-23 21:54:23,742 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0010.states"
2017-06-23 21:54:31,331 Epoch[10] Batch [10]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.158230,	
2017-06-23 21:54:37,754 Epoch[10] Batch [20]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.139313,	
2017-06-23 21:54:44,326 Epoch[10] Batch [30]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.142537,	
2017-06-23 21:54:50,880 Epoch[10] Batch [40]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.137496,	
2017-06-23 21:54:57,243 Epoch[10] Batch [50]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.137009,	
2017-06-23 21:55:03,628 Epoch[10] Batch [60]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.135150,	
2017-06-23 21:55:10,030 Epoch[10] Batch [70]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.134121,	
2017-06-23 21:55:16,453 Epoch[10] Batch [80]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.134116,	
2017-06-23 21:55:23,220 Epoch[10] Batch [90]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.133348,	
2017-06-23 21:55:29,944 Epoch[10] Batch [100]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.133034,	
2017-06-23 21:55:36,061 Epoch[10] Batch [110]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.132872,	
2017-06-23 21:55:41,875 Epoch[10] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.134909,	
2017-06-23 21:55:47,830 Epoch[10] Batch [130]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.134896,	
2017-06-23 21:55:53,898 Epoch[10] Batch [140]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.136177,	
2017-06-23 21:55:59,808 Epoch[10] Batch [150]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.136043,	
2017-06-23 21:56:06,081 Epoch[10] Batch [160]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.136257,	
2017-06-23 21:56:12,274 Epoch[10] Batch [170]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.135279,	
2017-06-23 21:56:18,381 Epoch[10] Batch [180]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.134705,	
2017-06-23 21:56:24,814 Epoch[10] Batch [190]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.134520,	
2017-06-23 21:56:31,085 Epoch[10] Batch [200]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.134159,	
2017-06-23 21:56:37,699 Epoch[10] Batch [210]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.133472,	
2017-06-23 21:56:43,885 Epoch[10] Batch [220]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.132828,	
2017-06-23 21:56:50,604 Epoch[10] Batch [230]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.132576,	
2017-06-23 21:56:57,276 Epoch[10] Batch [240]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.132581,	
2017-06-23 21:57:03,685 Epoch[10] Batch [250]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.132730,	
2017-06-23 21:57:10,743 Epoch[10] Batch [260]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.132904,	
2017-06-23 21:57:17,544 Epoch[10] Batch [270]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.133103,	
2017-06-23 21:57:23,892 Epoch[10] Batch [280]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.132858,	
2017-06-23 21:57:30,342 Epoch[10] Batch [290]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.132933,	
2017-06-23 21:57:36,968 Epoch[10] Batch [300]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.132627,	
2017-06-23 21:57:43,344 Epoch[10] Batch [310]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.132572,	
2017-06-23 21:57:50,025 Epoch[10] Batch [320]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.131939,	
2017-06-23 21:57:56,741 Epoch[10] Batch [330]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.131888,	
2017-06-23 21:58:03,527 Epoch[10] Batch [340]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.132046,	
2017-06-23 21:58:10,255 Epoch[10] Batch [350]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.132837,	
2017-06-23 21:58:16,437 Epoch[10] Batch [360]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.133030,	
2017-06-23 21:58:22,706 Epoch[10] Batch [370]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.133221,	
2017-06-23 21:58:29,289 Epoch[10] Batch [380]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.132775,	
2017-06-23 21:58:35,154 Epoch[10] Batch [390]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.132846,	
2017-06-23 21:58:41,122 Epoch[10] Batch [400]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.133146,	
2017-06-23 21:58:46,931 Epoch[10] Batch [410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.132890,	
2017-06-23 21:58:52,669 Epoch[10] Batch [420]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.132915,	
2017-06-23 21:58:58,967 Epoch[10] Batch [430]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.132872,	
2017-06-23 21:59:04,918 Epoch[10] Batch [440]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.133322,	
2017-06-23 21:59:10,995 Epoch[10] Batch [450]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.133624,	
2017-06-23 21:59:17,045 Epoch[10] Batch [460]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.133773,	
2017-06-23 21:59:23,691 Epoch[10] Batch [470]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.133642,	
2017-06-23 21:59:29,796 Epoch[10] Batch [480]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.133151,	
2017-06-23 21:59:36,089 Epoch[10] Batch [490]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.132899,	
2017-06-23 21:59:42,845 Epoch[10] Batch [500]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.132877,	
2017-06-23 21:59:48,995 Epoch[10] Batch [510]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.132655,	
2017-06-23 21:59:55,490 Epoch[10] Batch [520]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.132823,	
2017-06-23 22:00:02,108 Epoch[10] Batch [530]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.132780,	
2017-06-23 22:00:08,902 Epoch[10] Batch [540]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.132963,	
2017-06-23 22:00:15,291 Epoch[10] Batch [550]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.132830,	
2017-06-23 22:00:22,004 Epoch[10] Batch [560]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.132977,	
2017-06-23 22:00:28,694 Epoch[10] Batch [570]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.132713,	
2017-06-23 22:00:35,578 Epoch[10] Batch [580]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.132402,	
2017-06-23 22:00:42,002 Epoch[10] Batch [590]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.132123,	
2017-06-23 22:00:48,468 Epoch[10] Batch [600]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.132396,	
2017-06-23 22:00:55,447 Epoch[10] Batch [610]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.132893,	
2017-06-23 22:01:02,050 Epoch[10] Batch [620]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.132950,	
2017-06-23 22:01:08,792 Epoch[10] Batch [630]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.133019,	
2017-06-23 22:01:15,676 Epoch[10] Batch [640]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.133154,	
2017-06-23 22:01:21,776 Epoch[10] Batch [650]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.133071,	
2017-06-23 22:01:28,170 Epoch[10] Batch [660]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.133036,	
2017-06-23 22:01:34,335 Epoch[10] Batch [670]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.133043,	
2017-06-23 22:01:40,423 Epoch[10] Batch [680]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.132927,	
2017-06-23 22:01:46,626 Epoch[10] Batch [690]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.132908,	
2017-06-23 22:01:52,559 Epoch[10] Batch [700]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.133243,	
2017-06-23 22:01:58,936 Epoch[10] Batch [710]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.133172,	
2017-06-23 22:02:04,921 Epoch[10] Batch [720]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.133084,	
2017-06-23 22:02:10,901 Epoch[10] Batch [730]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.133287,	
2017-06-23 22:02:16,805 Epoch[10] Batch [740]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.133177,	
2017-06-23 22:02:22,771 Epoch[10] Batch [750]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.133638,	
2017-06-23 22:02:28,779 Epoch[10] Batch [760]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.133513,	
2017-06-23 22:02:34,574 Epoch[10] Batch [770]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.133690,	
2017-06-23 22:02:40,455 Epoch[10] Batch [780]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.133819,	
2017-06-23 22:02:46,396 Epoch[10] Batch [790]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.133758,	
2017-06-23 22:02:52,280 Epoch[10] Batch [800]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.133873,	
2017-06-23 22:02:58,241 Epoch[10] Batch [810]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.133787,	
2017-06-23 22:03:04,214 Epoch[10] Batch [820]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.133710,	
2017-06-23 22:03:10,417 Epoch[10] Batch [830]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.133654,	
2017-06-23 22:03:16,558 Epoch[10] Batch [840]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.133441,	
2017-06-23 22:03:23,114 Epoch[10] Batch [850]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.133312,	
2017-06-23 22:03:29,447 Epoch[10] Batch [860]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.133520,	
2017-06-23 22:03:35,935 Epoch[10] Batch [870]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.133507,	
2017-06-23 22:03:42,653 Epoch[10] Batch [880]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.133489,	
2017-06-23 22:03:49,618 Epoch[10] Batch [890]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.133645,	
2017-06-23 22:03:56,256 Epoch[10] Batch [900]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.133666,	
2017-06-23 22:04:02,872 Epoch[10] Batch [910]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.133820,	
2017-06-23 22:04:09,340 Epoch[10] Batch [920]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.133986,	
2017-06-23 22:04:15,967 Epoch[10] Batch [930]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.133838,	
2017-06-23 22:04:22,509 Epoch[10] Batch [940]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.133833,	
2017-06-23 22:04:29,030 Epoch[10] Batch [950]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.133721,	
2017-06-23 22:04:35,615 Epoch[10] Batch [960]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.133757,	
2017-06-23 22:04:42,126 Epoch[10] Batch [970]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.133725,	
2017-06-23 22:04:48,495 Epoch[10] Batch [980]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.133744,	
2017-06-23 22:04:54,566 Epoch[10] Batch [990]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.133875,	
2017-06-23 22:05:00,660 Epoch[10] Batch [1000]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.133837,	
2017-06-23 22:05:06,561 Epoch[10] Batch [1010]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.133903,	
2017-06-23 22:05:12,553 Epoch[10] Batch [1020]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.133753,	
2017-06-23 22:05:18,467 Epoch[10] Batch [1030]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.134039,	
2017-06-23 22:05:24,426 Epoch[10] Batch [1040]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.133989,	
2017-06-23 22:05:30,333 Epoch[10] Batch [1050]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.133872,	
2017-06-23 22:05:36,278 Epoch[10] Batch [1060]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.133741,	
2017-06-23 22:05:42,231 Epoch[10] Batch [1070]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.133838,	
2017-06-23 22:05:48,196 Epoch[10] Batch [1080]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.133958,	
2017-06-23 22:05:54,088 Epoch[10] Batch [1090]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.133833,	
2017-06-23 22:06:00,008 Epoch[10] Batch [1100]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.133760,	
2017-06-23 22:06:05,972 Epoch[10] Batch [1110]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.133769,	
2017-06-23 22:06:11,917 Epoch[10] Batch [1120]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.133646,	
2017-06-23 22:06:17,884 Epoch[10] Batch [1130]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.133501,	
2017-06-23 22:06:23,882 Epoch[10] Batch [1140]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.133324,	
2017-06-23 22:06:29,838 Epoch[10] Batch [1150]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.133299,	
2017-06-23 22:06:35,745 Epoch[10] Batch [1160]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.133187,	
2017-06-23 22:06:41,773 Epoch[10] Batch [1170]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.133103,	
2017-06-23 22:06:48,064 Epoch[10] Batch [1180]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.133046,	
2017-06-23 22:06:54,840 Epoch[10] Batch [1190]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.133073,	
2017-06-23 22:07:01,201 Epoch[10] Batch [1200]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.133082,	
2017-06-23 22:07:07,415 Epoch[10] Batch [1210]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.133104,	
2017-06-23 22:07:13,885 Epoch[10] Batch [1220]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.132991,	
2017-06-23 22:07:20,665 Epoch[10] Batch [1230]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.133030,	
2017-06-23 22:07:27,551 Epoch[10] Batch [1240]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.132910,	
2017-06-23 22:07:33,765 Epoch[10] Batch [1250]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.132991,	
2017-06-23 22:07:40,115 Epoch[10] Batch [1260]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.132934,	
2017-06-23 22:07:47,027 Epoch[10] Batch [1270]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.133071,	
2017-06-23 22:07:53,371 Epoch[10] Batch [1280]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.133017,	
2017-06-23 22:07:59,536 Epoch[10] Batch [1290]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.133094,	
2017-06-23 22:08:06,048 Epoch[10] Batch [1300]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.133239,	
2017-06-23 22:08:12,144 Epoch[10] Batch [1310]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.133277,	
2017-06-23 22:08:18,529 Epoch[10] Batch [1320]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.133365,	
2017-06-23 22:08:24,442 Epoch[10] Batch [1330]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.133420,	
2017-06-23 22:08:30,348 Epoch[10] Batch [1340]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.133172,	
2017-06-23 22:08:36,262 Epoch[10] Batch [1350]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.133141,	
2017-06-23 22:08:42,616 Epoch[10] Batch [1360]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.133154,	
2017-06-23 22:08:48,890 Epoch[10] Batch [1370]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.133036,	
2017-06-23 22:08:54,635 Epoch[10] Batch [1380]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.133059,	
2017-06-23 22:09:00,662 Epoch[10] Batch [1390]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.132965,	
2017-06-23 22:09:06,722 Epoch[10] Batch [1400]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.132931,	
2017-06-23 22:09:13,051 Epoch[10] Batch [1410]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.132819,	
2017-06-23 22:09:19,328 Epoch[10] Batch [1420]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.132712,	
2017-06-23 22:09:25,339 Epoch[10] Batch [1430]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.132635,	
2017-06-23 22:09:31,482 Epoch[10] Batch [1440]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.132679,	
2017-06-23 22:09:37,708 Epoch[10] Batch [1450]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.132680,	
2017-06-23 22:09:43,988 Epoch[10] Batch [1460]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.132649,	
2017-06-23 22:09:50,089 Epoch[10] Batch [1470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.132617,	
2017-06-23 22:09:56,696 Epoch[10] Batch [1480]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.132675,	
2017-06-23 22:10:00,478 Epoch[10] Train-FCNLogLoss=0.132634
2017-06-23 22:10:00,479 Epoch[10] Time cost=936.737
2017-06-23 22:10:01,599 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0011.params"
2017-06-23 22:10:05,484 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0011.states"
2017-06-23 22:10:13,094 Epoch[11] Batch [10]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.124108,	
2017-06-23 22:10:19,558 Epoch[11] Batch [20]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.125052,	
2017-06-23 22:10:25,731 Epoch[11] Batch [30]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.126150,	
2017-06-23 22:10:32,629 Epoch[11] Batch [40]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.126770,	
2017-06-23 22:10:39,327 Epoch[11] Batch [50]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.128942,	
2017-06-23 22:10:46,018 Epoch[11] Batch [60]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.129350,	
2017-06-23 22:10:52,651 Epoch[11] Batch [70]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.128098,	
2017-06-23 22:10:59,585 Epoch[11] Batch [80]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.128207,	
2017-06-23 22:11:05,947 Epoch[11] Batch [90]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.126719,	
2017-06-23 22:11:12,249 Epoch[11] Batch [100]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.128681,	
2017-06-23 22:11:18,708 Epoch[11] Batch [110]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.132104,	
2017-06-23 22:11:25,042 Epoch[11] Batch [120]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.132302,	
2017-06-23 22:11:31,368 Epoch[11] Batch [130]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.132524,	
2017-06-23 22:11:37,444 Epoch[11] Batch [140]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.134052,	
2017-06-23 22:11:43,938 Epoch[11] Batch [150]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.135120,	
2017-06-23 22:11:49,941 Epoch[11] Batch [160]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.136757,	
2017-06-23 22:11:56,028 Epoch[11] Batch [170]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.136720,	
2017-06-23 22:12:01,839 Epoch[11] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.136306,	
2017-06-23 22:12:07,831 Epoch[11] Batch [190]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.136447,	
2017-06-23 22:12:13,820 Epoch[11] Batch [200]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.136134,	
2017-06-23 22:12:19,854 Epoch[11] Batch [210]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.135525,	
2017-06-23 22:12:25,935 Epoch[11] Batch [220]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.136720,	
2017-06-23 22:12:31,871 Epoch[11] Batch [230]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.137310,	
2017-06-23 22:12:37,537 Epoch[11] Batch [240]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.137461,	
2017-06-23 22:12:43,681 Epoch[11] Batch [250]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.137757,	
2017-06-23 22:12:50,274 Epoch[11] Batch [260]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.137562,	
2017-06-23 22:12:57,136 Epoch[11] Batch [270]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.137099,	
2017-06-23 22:13:03,798 Epoch[11] Batch [280]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.138777,	
2017-06-23 22:13:10,315 Epoch[11] Batch [290]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.139543,	
2017-06-23 22:13:16,578 Epoch[11] Batch [300]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.139044,	
2017-06-23 22:13:23,011 Epoch[11] Batch [310]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.139270,	
2017-06-23 22:13:29,220 Epoch[11] Batch [320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.139282,	
2017-06-23 22:13:35,810 Epoch[11] Batch [330]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.139104,	
2017-06-23 22:13:42,366 Epoch[11] Batch [340]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.138943,	
2017-06-23 22:13:49,008 Epoch[11] Batch [350]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.138737,	
2017-06-23 22:13:55,603 Epoch[11] Batch [360]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.138314,	
2017-06-23 22:14:01,838 Epoch[11] Batch [370]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.138141,	
2017-06-23 22:14:08,546 Epoch[11] Batch [380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.138214,	
2017-06-23 22:14:15,124 Epoch[11] Batch [390]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.138322,	
2017-06-23 22:14:21,514 Epoch[11] Batch [400]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.138311,	
2017-06-23 22:14:27,763 Epoch[11] Batch [410]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.137914,	
2017-06-23 22:14:33,913 Epoch[11] Batch [420]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.137741,	
2017-06-23 22:14:40,084 Epoch[11] Batch [430]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.138064,	
2017-06-23 22:14:46,194 Epoch[11] Batch [440]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.138138,	
2017-06-23 22:14:52,463 Epoch[11] Batch [450]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.137980,	
2017-06-23 22:14:58,414 Epoch[11] Batch [460]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.137685,	
2017-06-23 22:15:04,517 Epoch[11] Batch [470]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.138421,	
2017-06-23 22:15:10,716 Epoch[11] Batch [480]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.138703,	
2017-06-23 22:15:17,003 Epoch[11] Batch [490]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.138923,	
2017-06-23 22:15:23,442 Epoch[11] Batch [500]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.139244,	
2017-06-23 22:15:29,744 Epoch[11] Batch [510]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.139213,	
2017-06-23 22:15:36,005 Epoch[11] Batch [520]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.139215,	
2017-06-23 22:15:41,984 Epoch[11] Batch [530]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.138965,	
2017-06-23 22:15:47,904 Epoch[11] Batch [540]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.138849,	
2017-06-23 22:15:53,861 Epoch[11] Batch [550]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.138838,	
2017-06-23 22:15:59,838 Epoch[11] Batch [560]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.138475,	
2017-06-23 22:16:05,797 Epoch[11] Batch [570]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.138309,	
2017-06-23 22:16:11,843 Epoch[11] Batch [580]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.138591,	
2017-06-23 22:16:17,663 Epoch[11] Batch [590]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.138496,	
2017-06-23 22:16:23,623 Epoch[11] Batch [600]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.138172,	
2017-06-23 22:16:29,605 Epoch[11] Batch [610]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.137916,	
2017-06-23 22:16:35,487 Epoch[11] Batch [620]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.137715,	
2017-06-23 22:16:41,477 Epoch[11] Batch [630]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.137585,	
2017-06-23 22:16:47,355 Epoch[11] Batch [640]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.137380,	
2017-06-23 22:16:53,309 Epoch[11] Batch [650]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.137492,	
2017-06-23 22:16:59,561 Epoch[11] Batch [660]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.137592,	
2017-06-23 22:17:05,415 Epoch[11] Batch [670]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.137406,	
2017-06-23 22:17:11,348 Epoch[11] Batch [680]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.137502,	
2017-06-23 22:17:17,558 Epoch[11] Batch [690]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.137776,	
2017-06-23 22:17:23,513 Epoch[11] Batch [700]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.137600,	
2017-06-23 22:17:29,464 Epoch[11] Batch [710]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.137615,	
2017-06-23 22:17:35,402 Epoch[11] Batch [720]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.137456,	
2017-06-23 22:17:41,294 Epoch[11] Batch [730]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.137174,	
2017-06-23 22:17:47,211 Epoch[11] Batch [740]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.136903,	
2017-06-23 22:17:53,156 Epoch[11] Batch [750]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.136788,	
2017-06-23 22:17:59,098 Epoch[11] Batch [760]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.136567,	
2017-06-23 22:18:04,995 Epoch[11] Batch [770]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.136338,	
2017-06-23 22:18:10,905 Epoch[11] Batch [780]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.136237,	
2017-06-23 22:18:16,696 Epoch[11] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.136014,	
2017-06-23 22:18:22,529 Epoch[11] Batch [800]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.136394,	
2017-06-23 22:18:28,315 Epoch[11] Batch [810]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.136257,	
2017-06-23 22:18:34,300 Epoch[11] Batch [820]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.136316,	
2017-06-23 22:18:40,257 Epoch[11] Batch [830]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.136522,	
2017-06-23 22:18:46,213 Epoch[11] Batch [840]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.136605,	
2017-06-23 22:18:52,115 Epoch[11] Batch [850]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.136704,	
2017-06-23 22:18:58,046 Epoch[11] Batch [860]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.136713,	
2017-06-23 22:19:04,037 Epoch[11] Batch [870]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.136714,	
2017-06-23 22:19:09,947 Epoch[11] Batch [880]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.136766,	
2017-06-23 22:19:15,871 Epoch[11] Batch [890]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.136728,	
2017-06-23 22:19:21,861 Epoch[11] Batch [900]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.136789,	
2017-06-23 22:19:27,789 Epoch[11] Batch [910]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.136642,	
2017-06-23 22:19:33,708 Epoch[11] Batch [920]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.136411,	
2017-06-23 22:19:39,720 Epoch[11] Batch [930]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.136335,	
2017-06-23 22:19:45,728 Epoch[11] Batch [940]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.136370,	
2017-06-23 22:19:51,615 Epoch[11] Batch [950]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.136572,	
2017-06-23 22:19:57,506 Epoch[11] Batch [960]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.136625,	
2017-06-23 22:20:03,440 Epoch[11] Batch [970]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.136505,	
2017-06-23 22:20:09,407 Epoch[11] Batch [980]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.136430,	
2017-06-23 22:20:15,393 Epoch[11] Batch [990]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.136371,	
2017-06-23 22:20:21,905 Epoch[11] Batch [1000]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.136129,	
2017-06-23 22:20:28,055 Epoch[11] Batch [1010]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.136003,	
2017-06-23 22:20:34,063 Epoch[11] Batch [1020]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.135897,	
2017-06-23 22:20:40,003 Epoch[11] Batch [1030]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.135757,	
2017-06-23 22:20:46,298 Epoch[11] Batch [1040]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.135651,	
2017-06-23 22:20:52,501 Epoch[11] Batch [1050]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.135663,	
2017-06-23 22:20:58,785 Epoch[11] Batch [1060]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.135500,	
2017-06-23 22:21:05,034 Epoch[11] Batch [1070]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.135437,	
2017-06-23 22:21:11,165 Epoch[11] Batch [1080]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.135611,	
2017-06-23 22:21:17,174 Epoch[11] Batch [1090]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.135586,	
2017-06-23 22:21:23,329 Epoch[11] Batch [1100]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.135517,	
2017-06-23 22:21:29,034 Epoch[11] Batch [1110]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.135420,	
2017-06-23 22:21:35,183 Epoch[11] Batch [1120]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.135384,	
2017-06-23 22:21:41,306 Epoch[11] Batch [1130]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.135336,	
2017-06-23 22:21:47,318 Epoch[11] Batch [1140]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.135384,	
2017-06-23 22:21:54,225 Epoch[11] Batch [1150]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.135294,	
2017-06-23 22:21:59,965 Epoch[11] Batch [1160]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.135232,	
2017-06-23 22:22:05,965 Epoch[11] Batch [1170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.135228,	
2017-06-23 22:22:12,316 Epoch[11] Batch [1180]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.135043,	
2017-06-23 22:22:18,960 Epoch[11] Batch [1190]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.135003,	
2017-06-23 22:22:25,469 Epoch[11] Batch [1200]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.135128,	
2017-06-23 22:22:32,246 Epoch[11] Batch [1210]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.135292,	
2017-06-23 22:22:38,793 Epoch[11] Batch [1220]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.135373,	
2017-06-23 22:22:44,701 Epoch[11] Batch [1230]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.135311,	
2017-06-23 22:22:50,631 Epoch[11] Batch [1240]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.135418,	
2017-06-23 22:22:57,070 Epoch[11] Batch [1250]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.135374,	
2017-06-23 22:23:03,374 Epoch[11] Batch [1260]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.135352,	
2017-06-23 22:23:09,479 Epoch[11] Batch [1270]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135309,	
2017-06-23 22:23:15,696 Epoch[11] Batch [1280]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.135137,	
2017-06-23 22:23:21,885 Epoch[11] Batch [1290]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.135069,	
2017-06-23 22:23:28,447 Epoch[11] Batch [1300]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.135044,	
2017-06-23 22:23:34,946 Epoch[11] Batch [1310]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.134999,	
2017-06-23 22:23:41,236 Epoch[11] Batch [1320]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.134915,	
2017-06-23 22:23:47,507 Epoch[11] Batch [1330]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.134921,	
2017-06-23 22:23:53,786 Epoch[11] Batch [1340]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.134838,	
2017-06-23 22:24:00,352 Epoch[11] Batch [1350]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.134671,	
2017-06-23 22:24:06,727 Epoch[11] Batch [1360]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.134591,	
2017-06-23 22:24:13,465 Epoch[11] Batch [1370]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.134505,	
2017-06-23 22:24:19,962 Epoch[11] Batch [1380]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.134373,	
2017-06-23 22:24:26,493 Epoch[11] Batch [1390]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.134303,	
2017-06-23 22:24:32,819 Epoch[11] Batch [1400]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.134310,	
2017-06-23 22:24:39,246 Epoch[11] Batch [1410]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.134237,	
2017-06-23 22:24:45,639 Epoch[11] Batch [1420]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.134141,	
2017-06-23 22:24:51,891 Epoch[11] Batch [1430]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.134083,	
2017-06-23 22:24:58,240 Epoch[11] Batch [1440]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.134110,	
2017-06-23 22:25:05,011 Epoch[11] Batch [1450]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.134093,	
2017-06-23 22:25:11,472 Epoch[11] Batch [1460]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.134370,	
2017-06-23 22:25:17,704 Epoch[11] Batch [1470]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.134358,	
2017-06-23 22:25:23,837 Epoch[11] Batch [1480]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.134323,	
2017-06-23 22:25:27,447 Epoch[11] Train-FCNLogLoss=0.134268
2017-06-23 22:25:27,447 Epoch[11] Time cost=921.962
2017-06-23 22:25:28,585 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0012.params"
2017-06-23 22:25:32,638 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0012.states"
2017-06-23 22:25:39,787 Epoch[12] Batch [10]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.125154,	
2017-06-23 22:25:45,846 Epoch[12] Batch [20]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.122018,	
2017-06-23 22:25:51,669 Epoch[12] Batch [30]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.126301,	
2017-06-23 22:25:57,368 Epoch[12] Batch [40]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.127529,	
2017-06-23 22:26:03,322 Epoch[12] Batch [50]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.127544,	
2017-06-23 22:26:09,253 Epoch[12] Batch [60]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.127524,	
2017-06-23 22:26:15,319 Epoch[12] Batch [70]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.128391,	
2017-06-23 22:26:21,225 Epoch[12] Batch [80]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.129681,	
2017-06-23 22:26:27,287 Epoch[12] Batch [90]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.129070,	
2017-06-23 22:26:32,868 Epoch[12] Batch [100]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.127954,	
2017-06-23 22:26:38,795 Epoch[12] Batch [110]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.129394,	
2017-06-23 22:26:44,882 Epoch[12] Batch [120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.128381,	
2017-06-23 22:26:50,967 Epoch[12] Batch [130]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.128670,	
2017-06-23 22:26:57,329 Epoch[12] Batch [140]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.127004,	
2017-06-23 22:27:03,938 Epoch[12] Batch [150]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.127062,	
2017-06-23 22:27:10,310 Epoch[12] Batch [160]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.127366,	
2017-06-23 22:27:16,523 Epoch[12] Batch [170]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.127231,	
2017-06-23 22:27:22,736 Epoch[12] Batch [180]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.127767,	
2017-06-23 22:27:28,848 Epoch[12] Batch [190]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.127695,	
2017-06-23 22:27:35,088 Epoch[12] Batch [200]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.127771,	
2017-06-23 22:27:41,670 Epoch[12] Batch [210]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.127756,	
2017-06-23 22:27:48,385 Epoch[12] Batch [220]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.127531,	
2017-06-23 22:27:54,540 Epoch[12] Batch [230]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.127656,	
2017-06-23 22:28:01,176 Epoch[12] Batch [240]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.128258,	
2017-06-23 22:28:07,154 Epoch[12] Batch [250]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.128689,	
2017-06-23 22:28:13,832 Epoch[12] Batch [260]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.128550,	
2017-06-23 22:28:20,331 Epoch[12] Batch [270]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.128266,	
2017-06-23 22:28:26,620 Epoch[12] Batch [280]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.128465,	
2017-06-23 22:28:32,725 Epoch[12] Batch [290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.128697,	
2017-06-23 22:28:39,069 Epoch[12] Batch [300]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.128606,	
2017-06-23 22:28:45,447 Epoch[12] Batch [310]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.128841,	
2017-06-23 22:28:52,233 Epoch[12] Batch [320]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.128650,	
2017-06-23 22:28:58,554 Epoch[12] Batch [330]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.128900,	
2017-06-23 22:29:05,226 Epoch[12] Batch [340]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.128672,	
2017-06-23 22:29:11,547 Epoch[12] Batch [350]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.128500,	
2017-06-23 22:29:17,945 Epoch[12] Batch [360]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.128560,	
2017-06-23 22:29:24,607 Epoch[12] Batch [370]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.128144,	
2017-06-23 22:29:31,059 Epoch[12] Batch [380]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.127789,	
2017-06-23 22:29:37,099 Epoch[12] Batch [390]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.127347,	
2017-06-23 22:29:43,340 Epoch[12] Batch [400]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.127350,	
2017-06-23 22:29:49,183 Epoch[12] Batch [410]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.127845,	
2017-06-23 22:29:55,112 Epoch[12] Batch [420]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.128179,	
2017-06-23 22:30:01,070 Epoch[12] Batch [430]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.128277,	
2017-06-23 22:30:07,003 Epoch[12] Batch [440]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.128646,	
2017-06-23 22:30:12,941 Epoch[12] Batch [450]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.129230,	
2017-06-23 22:30:18,945 Epoch[12] Batch [460]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.129569,	
2017-06-23 22:30:24,959 Epoch[12] Batch [470]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.130173,	
2017-06-23 22:30:30,797 Epoch[12] Batch [480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.130089,	
2017-06-23 22:30:36,808 Epoch[12] Batch [490]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.129761,	
2017-06-23 22:30:42,707 Epoch[12] Batch [500]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.129527,	
2017-06-23 22:30:48,573 Epoch[12] Batch [510]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.129179,	
2017-06-23 22:30:54,557 Epoch[12] Batch [520]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.129209,	
2017-06-23 22:31:00,481 Epoch[12] Batch [530]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.129310,	
2017-06-23 22:31:06,434 Epoch[12] Batch [540]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.129155,	
2017-06-23 22:31:12,368 Epoch[12] Batch [550]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.129024,	
2017-06-23 22:31:18,287 Epoch[12] Batch [560]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.128969,	
2017-06-23 22:31:24,222 Epoch[12] Batch [570]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.128681,	
2017-06-23 22:31:30,163 Epoch[12] Batch [580]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.128651,	
2017-06-23 22:31:36,113 Epoch[12] Batch [590]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.128472,	
2017-06-23 22:31:42,029 Epoch[12] Batch [600]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.128376,	
2017-06-23 22:31:47,735 Epoch[12] Batch [610]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.128283,	
2017-06-23 22:31:53,723 Epoch[12] Batch [620]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.128233,	
2017-06-23 22:31:59,409 Epoch[12] Batch [630]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.128146,	
2017-06-23 22:32:05,399 Epoch[12] Batch [640]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.128113,	
2017-06-23 22:32:11,361 Epoch[12] Batch [650]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.128043,	
2017-06-23 22:32:17,336 Epoch[12] Batch [660]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.127939,	
2017-06-23 22:32:23,983 Epoch[12] Batch [670]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.127961,	
2017-06-23 22:32:29,876 Epoch[12] Batch [680]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.128026,	
2017-06-23 22:32:35,826 Epoch[12] Batch [690]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.128170,	
2017-06-23 22:32:41,939 Epoch[12] Batch [700]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.128248,	
2017-06-23 22:32:47,952 Epoch[12] Batch [710]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.127970,	
2017-06-23 22:32:54,058 Epoch[12] Batch [720]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.127771,	
2017-06-23 22:33:00,002 Epoch[12] Batch [730]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.127584,	
2017-06-23 22:33:06,374 Epoch[12] Batch [740]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.127511,	
2017-06-23 22:33:12,884 Epoch[12] Batch [750]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.127534,	
2017-06-23 22:33:18,786 Epoch[12] Batch [760]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.127685,	
2017-06-23 22:33:24,792 Epoch[12] Batch [770]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.127499,	
2017-06-23 22:33:30,722 Epoch[12] Batch [780]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.127406,	
2017-06-23 22:33:36,690 Epoch[12] Batch [790]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.127578,	
2017-06-23 22:33:42,772 Epoch[12] Batch [800]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.127763,	
2017-06-23 22:33:48,677 Epoch[12] Batch [810]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.127763,	
2017-06-23 22:33:54,580 Epoch[12] Batch [820]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.127710,	
2017-06-23 22:34:00,886 Epoch[12] Batch [830]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.127811,	
2017-06-23 22:34:06,800 Epoch[12] Batch [840]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.127949,	
2017-06-23 22:34:12,840 Epoch[12] Batch [850]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.127893,	
2017-06-23 22:34:18,786 Epoch[12] Batch [860]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.128015,	
2017-06-23 22:34:24,714 Epoch[12] Batch [870]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.127866,	
2017-06-23 22:34:30,489 Epoch[12] Batch [880]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.127820,	
2017-06-23 22:34:36,431 Epoch[12] Batch [890]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.127868,	
2017-06-23 22:34:42,485 Epoch[12] Batch [900]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.128079,	
2017-06-23 22:34:48,378 Epoch[12] Batch [910]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.128212,	
2017-06-23 22:34:54,347 Epoch[12] Batch [920]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.128158,	
2017-06-23 22:35:00,259 Epoch[12] Batch [930]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.128207,	
2017-06-23 22:35:06,232 Epoch[12] Batch [940]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.128187,	
2017-06-23 22:35:12,193 Epoch[12] Batch [950]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.128243,	
2017-06-23 22:35:18,126 Epoch[12] Batch [960]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.128071,	
2017-06-23 22:35:24,416 Epoch[12] Batch [970]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.128056,	
2017-06-23 22:35:30,572 Epoch[12] Batch [980]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.128161,	
2017-06-23 22:35:37,135 Epoch[12] Batch [990]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.128260,	
2017-06-23 22:35:43,292 Epoch[12] Batch [1000]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.128317,	
2017-06-23 22:35:49,761 Epoch[12] Batch [1010]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.128281,	
2017-06-23 22:35:55,957 Epoch[12] Batch [1020]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.128356,	
2017-06-23 22:36:02,463 Epoch[12] Batch [1030]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.128319,	
2017-06-23 22:36:08,780 Epoch[12] Batch [1040]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.128268,	
2017-06-23 22:36:14,984 Epoch[12] Batch [1050]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.128123,	
2017-06-23 22:36:21,012 Epoch[12] Batch [1060]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.128054,	
2017-06-23 22:36:27,207 Epoch[12] Batch [1070]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.127937,	
2017-06-23 22:36:33,255 Epoch[12] Batch [1080]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.128066,	
2017-06-23 22:36:39,218 Epoch[12] Batch [1090]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.128084,	
2017-06-23 22:36:45,036 Epoch[12] Batch [1100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.128014,	
2017-06-23 22:36:50,905 Epoch[12] Batch [1110]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.127972,	
2017-06-23 22:36:56,948 Epoch[12] Batch [1120]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.127872,	
2017-06-23 22:37:02,885 Epoch[12] Batch [1130]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.127938,	
2017-06-23 22:37:08,673 Epoch[12] Batch [1140]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.128177,	
2017-06-23 22:37:14,722 Epoch[12] Batch [1150]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.128223,	
2017-06-23 22:37:20,807 Epoch[12] Batch [1160]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.128365,	
2017-06-23 22:37:27,083 Epoch[12] Batch [1170]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.128476,	
2017-06-23 22:37:33,401 Epoch[12] Batch [1180]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.128507,	
2017-06-23 22:37:39,779 Epoch[12] Batch [1190]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.128554,	
2017-06-23 22:37:46,442 Epoch[12] Batch [1200]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.128557,	
2017-06-23 22:37:53,246 Epoch[12] Batch [1210]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.128453,	
2017-06-23 22:37:59,639 Epoch[12] Batch [1220]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.128286,	
2017-06-23 22:38:06,318 Epoch[12] Batch [1230]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.128422,	
2017-06-23 22:38:12,833 Epoch[12] Batch [1240]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.128714,	
2017-06-23 22:38:19,050 Epoch[12] Batch [1250]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.129320,	
2017-06-23 22:38:25,678 Epoch[12] Batch [1260]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.129604,	
2017-06-23 22:38:32,709 Epoch[12] Batch [1270]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.129701,	
2017-06-23 22:38:39,388 Epoch[12] Batch [1280]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.129723,	
2017-06-23 22:38:45,965 Epoch[12] Batch [1290]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.129923,	
2017-06-23 22:38:52,690 Epoch[12] Batch [1300]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.129881,	
2017-06-23 22:38:58,740 Epoch[12] Batch [1310]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.129932,	
2017-06-23 22:39:05,152 Epoch[12] Batch [1320]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.130004,	
2017-06-23 22:39:11,622 Epoch[12] Batch [1330]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.129983,	
2017-06-23 22:39:17,991 Epoch[12] Batch [1340]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.129888,	
2017-06-23 22:39:24,376 Epoch[12] Batch [1350]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.129804,	
2017-06-23 22:39:30,493 Epoch[12] Batch [1360]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.129894,	
2017-06-23 22:39:36,599 Epoch[12] Batch [1370]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.129898,	
2017-06-23 22:39:42,712 Epoch[12] Batch [1380]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.129820,	
2017-06-23 22:39:49,069 Epoch[12] Batch [1390]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.129881,	
2017-06-23 22:39:54,915 Epoch[12] Batch [1400]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.129882,	
2017-06-23 22:40:01,269 Epoch[12] Batch [1410]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.129863,	
2017-06-23 22:40:07,499 Epoch[12] Batch [1420]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.129824,	
2017-06-23 22:40:14,076 Epoch[12] Batch [1430]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.129952,	
2017-06-23 22:40:20,318 Epoch[12] Batch [1440]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.130113,	
2017-06-23 22:40:26,596 Epoch[12] Batch [1450]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.130119,	
2017-06-23 22:40:33,052 Epoch[12] Batch [1460]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.130237,	
2017-06-23 22:40:39,306 Epoch[12] Batch [1470]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.130298,	
2017-06-23 22:40:46,208 Epoch[12] Batch [1480]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.130348,	
2017-06-23 22:40:50,231 Epoch[12] Train-FCNLogLoss=0.130305
2017-06-23 22:40:50,231 Epoch[12] Time cost=917.593
2017-06-23 22:40:51,310 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0013.params"
2017-06-23 22:40:55,187 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0013.states"
2017-06-23 22:41:02,963 Epoch[13] Batch [10]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.125343,	
2017-06-23 22:41:09,215 Epoch[13] Batch [20]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.125218,	
2017-06-23 22:41:15,820 Epoch[13] Batch [30]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.130776,	
2017-06-23 22:41:22,441 Epoch[13] Batch [40]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.129060,	
2017-06-23 22:41:28,778 Epoch[13] Batch [50]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.127797,	
2017-06-23 22:41:35,056 Epoch[13] Batch [60]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.127207,	
2017-06-23 22:41:41,628 Epoch[13] Batch [70]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.134048,	
2017-06-23 22:41:48,254 Epoch[13] Batch [80]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.134066,	
2017-06-23 22:41:54,540 Epoch[13] Batch [90]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.136801,	
2017-06-23 22:42:00,957 Epoch[13] Batch [100]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.137336,	
2017-06-23 22:42:07,146 Epoch[13] Batch [110]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.137773,	
2017-06-23 22:42:13,236 Epoch[13] Batch [120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.137163,	
2017-06-23 22:42:19,624 Epoch[13] Batch [130]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.136272,	
2017-06-23 22:42:25,696 Epoch[13] Batch [140]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.135927,	
2017-06-23 22:42:31,515 Epoch[13] Batch [150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136298,	
2017-06-23 22:42:37,459 Epoch[13] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.135590,	
2017-06-23 22:42:43,435 Epoch[13] Batch [170]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.134698,	
2017-06-23 22:42:49,546 Epoch[13] Batch [180]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.134668,	
2017-06-23 22:42:55,399 Epoch[13] Batch [190]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.134569,	
2017-06-23 22:43:01,356 Epoch[13] Batch [200]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.134105,	
2017-06-23 22:43:07,408 Epoch[13] Batch [210]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.133934,	
2017-06-23 22:43:13,293 Epoch[13] Batch [220]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.133438,	
2017-06-23 22:43:19,250 Epoch[13] Batch [230]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.134181,	
2017-06-23 22:43:25,261 Epoch[13] Batch [240]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.133682,	
2017-06-23 22:43:31,157 Epoch[13] Batch [250]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.133535,	
2017-06-23 22:43:37,186 Epoch[13] Batch [260]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.133893,	
2017-06-23 22:43:42,958 Epoch[13] Batch [270]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.133795,	
2017-06-23 22:43:49,253 Epoch[13] Batch [280]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.133278,	
2017-06-23 22:43:55,545 Epoch[13] Batch [290]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.132572,	
2017-06-23 22:44:01,970 Epoch[13] Batch [300]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.132469,	
2017-06-23 22:44:08,052 Epoch[13] Batch [310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.131862,	
2017-06-23 22:44:14,356 Epoch[13] Batch [320]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.131420,	
2017-06-23 22:44:20,420 Epoch[13] Batch [330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.131439,	
2017-06-23 22:44:26,936 Epoch[13] Batch [340]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.131399,	
2017-06-23 22:44:33,137 Epoch[13] Batch [350]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.131637,	
2017-06-23 22:44:39,670 Epoch[13] Batch [360]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.131066,	
2017-06-23 22:44:46,113 Epoch[13] Batch [370]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.130800,	
2017-06-23 22:44:52,318 Epoch[13] Batch [380]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.130600,	
2017-06-23 22:44:58,861 Epoch[13] Batch [390]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.130524,	
2017-06-23 22:45:05,242 Epoch[13] Batch [400]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.130788,	
2017-06-23 22:45:11,229 Epoch[13] Batch [410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.130986,	
2017-06-23 22:45:17,142 Epoch[13] Batch [420]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.131101,	
2017-06-23 22:45:23,307 Epoch[13] Batch [430]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.130844,	
2017-06-23 22:45:29,151 Epoch[13] Batch [440]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.130713,	
2017-06-23 22:45:35,080 Epoch[13] Batch [450]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.130788,	
2017-06-23 22:45:40,907 Epoch[13] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.130909,	
2017-06-23 22:45:46,916 Epoch[13] Batch [470]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.130831,	
2017-06-23 22:45:52,748 Epoch[13] Batch [480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.130468,	
2017-06-23 22:45:58,779 Epoch[13] Batch [490]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.130846,	
2017-06-23 22:46:04,954 Epoch[13] Batch [500]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.130839,	
2017-06-23 22:46:10,983 Epoch[13] Batch [510]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.130642,	
2017-06-23 22:46:16,978 Epoch[13] Batch [520]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.130597,	
2017-06-23 22:46:23,002 Epoch[13] Batch [530]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.130617,	
2017-06-23 22:46:28,917 Epoch[13] Batch [540]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.130289,	
2017-06-23 22:46:34,862 Epoch[13] Batch [550]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.130049,	
2017-06-23 22:46:40,877 Epoch[13] Batch [560]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.129945,	
2017-06-23 22:46:46,827 Epoch[13] Batch [570]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.130004,	
2017-06-23 22:46:52,763 Epoch[13] Batch [580]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.130135,	
2017-06-23 22:46:58,637 Epoch[13] Batch [590]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.129863,	
2017-06-23 22:47:04,590 Epoch[13] Batch [600]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.129839,	
2017-06-23 22:47:10,560 Epoch[13] Batch [610]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.129589,	
2017-06-23 22:47:16,636 Epoch[13] Batch [620]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.129453,	
2017-06-23 22:47:22,987 Epoch[13] Batch [630]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.129377,	
2017-06-23 22:47:29,756 Epoch[13] Batch [640]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.129277,	
2017-06-23 22:47:35,773 Epoch[13] Batch [650]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.129045,	
2017-06-23 22:47:42,264 Epoch[13] Batch [660]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.128987,	
2017-06-23 22:47:48,342 Epoch[13] Batch [670]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.128852,	
2017-06-23 22:47:54,472 Epoch[13] Batch [680]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.128785,	
2017-06-23 22:48:00,904 Epoch[13] Batch [690]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.128633,	
2017-06-23 22:48:07,415 Epoch[13] Batch [700]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.128615,	
2017-06-23 22:48:13,345 Epoch[13] Batch [710]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.128301,	
2017-06-23 22:48:19,229 Epoch[13] Batch [720]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.128229,	
2017-06-23 22:48:25,633 Epoch[13] Batch [730]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.128133,	
2017-06-23 22:48:32,334 Epoch[13] Batch [740]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.128065,	
2017-06-23 22:48:38,847 Epoch[13] Batch [750]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.127809,	
2017-06-23 22:48:45,213 Epoch[13] Batch [760]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.127712,	
2017-06-23 22:48:51,285 Epoch[13] Batch [770]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.127695,	
2017-06-23 22:48:57,291 Epoch[13] Batch [780]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.127530,	
2017-06-23 22:49:03,772 Epoch[13] Batch [790]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.127380,	
2017-06-23 22:49:09,739 Epoch[13] Batch [800]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.127183,	
2017-06-23 22:49:15,711 Epoch[13] Batch [810]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.127134,	
2017-06-23 22:49:21,771 Epoch[13] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.127153,	
2017-06-23 22:49:27,762 Epoch[13] Batch [830]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.126993,	
2017-06-23 22:49:33,664 Epoch[13] Batch [840]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.126992,	
2017-06-23 22:49:39,713 Epoch[13] Batch [850]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.126916,	
2017-06-23 22:49:45,786 Epoch[13] Batch [860]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.126783,	
2017-06-23 22:49:51,648 Epoch[13] Batch [870]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.126721,	
2017-06-23 22:49:57,523 Epoch[13] Batch [880]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.126612,	
2017-06-23 22:50:03,481 Epoch[13] Batch [890]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.126694,	
2017-06-23 22:50:09,448 Epoch[13] Batch [900]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.126678,	
2017-06-23 22:50:15,412 Epoch[13] Batch [910]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.126817,	
2017-06-23 22:50:21,427 Epoch[13] Batch [920]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.126707,	
2017-06-23 22:50:27,610 Epoch[13] Batch [930]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.126786,	
2017-06-23 22:50:33,830 Epoch[13] Batch [940]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.126724,	
2017-06-23 22:50:39,709 Epoch[13] Batch [950]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.126807,	
2017-06-23 22:50:45,988 Epoch[13] Batch [960]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.126767,	
2017-06-23 22:50:53,218 Epoch[13] Batch [970]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.126770,	
2017-06-23 22:50:59,565 Epoch[13] Batch [980]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.126678,	
2017-06-23 22:51:05,837 Epoch[13] Batch [990]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.126630,	
2017-06-23 22:51:12,141 Epoch[13] Batch [1000]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.126757,	
2017-06-23 22:51:18,853 Epoch[13] Batch [1010]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.126746,	
2017-06-23 22:51:25,828 Epoch[13] Batch [1020]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.126596,	
2017-06-23 22:51:32,317 Epoch[13] Batch [1030]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.126563,	
2017-06-23 22:51:38,730 Epoch[13] Batch [1040]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.126724,	
2017-06-23 22:51:45,120 Epoch[13] Batch [1050]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.126888,	
2017-06-23 22:51:52,179 Epoch[13] Batch [1060]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.126872,	
2017-06-23 22:51:59,006 Epoch[13] Batch [1070]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.127029,	
2017-06-23 22:52:05,641 Epoch[13] Batch [1080]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.126996,	
2017-06-23 22:52:11,839 Epoch[13] Batch [1090]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.126944,	
2017-06-23 22:52:18,094 Epoch[13] Batch [1100]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.126834,	
2017-06-23 22:52:24,026 Epoch[13] Batch [1110]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.126773,	
2017-06-23 22:52:30,114 Epoch[13] Batch [1120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.126754,	
2017-06-23 22:52:35,963 Epoch[13] Batch [1130]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.126742,	
2017-06-23 22:52:41,769 Epoch[13] Batch [1140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.126850,	
2017-06-23 22:52:47,622 Epoch[13] Batch [1150]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.126782,	
2017-06-23 22:52:53,675 Epoch[13] Batch [1160]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.126821,	
2017-06-23 22:52:59,850 Epoch[13] Batch [1170]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.126746,	
2017-06-23 22:53:05,955 Epoch[13] Batch [1180]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.126576,	
2017-06-23 22:53:12,163 Epoch[13] Batch [1190]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.126477,	
2017-06-23 22:53:18,355 Epoch[13] Batch [1200]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.126389,	
2017-06-23 22:53:24,477 Epoch[13] Batch [1210]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.126354,	
2017-06-23 22:53:30,798 Epoch[13] Batch [1220]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.126343,	
2017-06-23 22:53:37,288 Epoch[13] Batch [1230]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.126344,	
2017-06-23 22:53:43,818 Epoch[13] Batch [1240]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.126257,	
2017-06-23 22:53:50,194 Epoch[13] Batch [1250]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.126165,	
2017-06-23 22:53:56,937 Epoch[13] Batch [1260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.126190,	
2017-06-23 22:54:03,591 Epoch[13] Batch [1270]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.126109,	
2017-06-23 22:54:10,176 Epoch[13] Batch [1280]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.126030,	
2017-06-23 22:54:16,652 Epoch[13] Batch [1290]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.126137,	
2017-06-23 22:54:22,729 Epoch[13] Batch [1300]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.126066,	
2017-06-23 22:54:29,054 Epoch[13] Batch [1310]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.125989,	
2017-06-23 22:54:35,684 Epoch[13] Batch [1320]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.125939,	
2017-06-23 22:54:42,162 Epoch[13] Batch [1330]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.125919,	
2017-06-23 22:54:49,272 Epoch[13] Batch [1340]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.125972,	
2017-06-23 22:54:55,940 Epoch[13] Batch [1350]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.125922,	
2017-06-23 22:55:02,627 Epoch[13] Batch [1360]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.125859,	
2017-06-23 22:55:09,462 Epoch[13] Batch [1370]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.126000,	
2017-06-23 22:55:16,040 Epoch[13] Batch [1380]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.126037,	
2017-06-23 22:55:22,642 Epoch[13] Batch [1390]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.126033,	
2017-06-23 22:55:29,234 Epoch[13] Batch [1400]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.125909,	
2017-06-23 22:55:34,621 Epoch[13] Batch [1410]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.126014,	
2017-06-23 22:55:40,373 Epoch[13] Batch [1420]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.125931,	
2017-06-23 22:55:45,532 Epoch[13] Batch [1430]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.125991,	
2017-06-23 22:55:50,687 Epoch[13] Batch [1440]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.126079,	
2017-06-23 22:55:55,885 Epoch[13] Batch [1450]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.126137,	
2017-06-23 22:56:01,172 Epoch[13] Batch [1460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.126135,	
2017-06-23 22:56:06,636 Epoch[13] Batch [1470]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.126172,	
2017-06-23 22:56:11,811 Epoch[13] Batch [1480]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.126156,	
2017-06-23 22:56:14,883 Epoch[13] Train-FCNLogLoss=0.126146
2017-06-23 22:56:14,883 Epoch[13] Time cost=919.695
2017-06-23 22:56:15,839 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0014.params"
2017-06-23 22:56:19,718 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0014.states"
2017-06-23 22:56:26,041 Epoch[14] Batch [10]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.124954,	
2017-06-23 22:56:31,255 Epoch[14] Batch [20]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.125912,	
2017-06-23 22:56:36,452 Epoch[14] Batch [30]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.123181,	
2017-06-23 22:56:41,649 Epoch[14] Batch [40]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.123062,	
2017-06-23 22:56:46,867 Epoch[14] Batch [50]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.120006,	
2017-06-23 22:56:52,043 Epoch[14] Batch [60]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.119025,	
2017-06-23 22:56:57,233 Epoch[14] Batch [70]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.117337,	
2017-06-23 22:57:02,481 Epoch[14] Batch [80]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.119254,	
2017-06-23 22:57:07,708 Epoch[14] Batch [90]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.120166,	
2017-06-23 22:57:12,901 Epoch[14] Batch [100]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.117984,	
2017-06-23 22:57:18,100 Epoch[14] Batch [110]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.119413,	
2017-06-23 22:57:23,312 Epoch[14] Batch [120]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.118835,	
2017-06-23 22:57:28,483 Epoch[14] Batch [130]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.119091,	
2017-06-23 22:57:33,672 Epoch[14] Batch [140]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.119801,	
2017-06-23 22:57:38,903 Epoch[14] Batch [150]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.118828,	
2017-06-23 22:57:44,127 Epoch[14] Batch [160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.119293,	
2017-06-23 22:57:49,315 Epoch[14] Batch [170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.118864,	
2017-06-23 22:57:54,509 Epoch[14] Batch [180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.118244,	
2017-06-23 22:57:59,709 Epoch[14] Batch [190]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.119561,	
2017-06-23 22:58:04,934 Epoch[14] Batch [200]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.120293,	
2017-06-23 22:58:10,175 Epoch[14] Batch [210]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120054,	
2017-06-23 22:58:15,349 Epoch[14] Batch [220]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.119736,	
2017-06-23 22:58:20,593 Epoch[14] Batch [230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.119666,	
2017-06-23 22:58:25,848 Epoch[14] Batch [240]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.120029,	
2017-06-23 22:58:31,000 Epoch[14] Batch [250]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.120012,	
2017-06-23 22:58:36,232 Epoch[14] Batch [260]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.119906,	
2017-06-23 22:58:41,419 Epoch[14] Batch [270]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.120786,	
2017-06-23 22:58:46,218 Epoch[14] Batch [280]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.121473,	
2017-06-23 22:58:51,670 Epoch[14] Batch [290]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.121002,	
2017-06-23 22:58:56,845 Epoch[14] Batch [300]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.121028,	
2017-06-23 22:59:02,046 Epoch[14] Batch [310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.120743,	
2017-06-23 22:59:07,289 Epoch[14] Batch [320]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120498,	
2017-06-23 22:59:12,468 Epoch[14] Batch [330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120576,	
2017-06-23 22:59:17,749 Epoch[14] Batch [340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.120394,	
2017-06-23 22:59:22,958 Epoch[14] Batch [350]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.120176,	
2017-06-23 22:59:28,197 Epoch[14] Batch [360]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120279,	
2017-06-23 22:59:33,429 Epoch[14] Batch [370]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.120101,	
2017-06-23 22:59:38,610 Epoch[14] Batch [380]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120026,	
2017-06-23 22:59:43,851 Epoch[14] Batch [390]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120160,	
2017-06-23 22:59:49,039 Epoch[14] Batch [400]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.120197,	
2017-06-23 22:59:54,240 Epoch[14] Batch [410]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.120134,	
2017-06-23 22:59:59,463 Epoch[14] Batch [420]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.120031,	
2017-06-23 23:00:04,735 Epoch[14] Batch [430]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.120387,	
2017-06-23 23:00:09,921 Epoch[14] Batch [440]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.123409,	
2017-06-23 23:00:15,229 Epoch[14] Batch [450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125429,	
2017-06-23 23:00:20,388 Epoch[14] Batch [460]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.126052,	
2017-06-23 23:00:25,569 Epoch[14] Batch [470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.126600,	
2017-06-23 23:00:30,786 Epoch[14] Batch [480]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.126865,	
2017-06-23 23:00:36,000 Epoch[14] Batch [490]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127397,	
2017-06-23 23:00:41,215 Epoch[14] Batch [500]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127867,	
2017-06-23 23:00:46,462 Epoch[14] Batch [510]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.127912,	
2017-06-23 23:00:51,663 Epoch[14] Batch [520]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127886,	
2017-06-23 23:00:56,904 Epoch[14] Batch [530]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.128297,	
2017-06-23 23:01:02,098 Epoch[14] Batch [540]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.128310,	
2017-06-23 23:01:07,369 Epoch[14] Batch [550]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.128174,	
2017-06-23 23:01:12,587 Epoch[14] Batch [560]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127938,	
2017-06-23 23:01:17,854 Epoch[14] Batch [570]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.127959,	
2017-06-23 23:01:23,091 Epoch[14] Batch [580]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.127854,	
2017-06-23 23:01:28,307 Epoch[14] Batch [590]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127735,	
2017-06-23 23:01:33,527 Epoch[14] Batch [600]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.127642,	
2017-06-23 23:01:38,770 Epoch[14] Batch [610]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.127652,	
2017-06-23 23:01:44,003 Epoch[14] Batch [620]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.127698,	
2017-06-23 23:01:49,202 Epoch[14] Batch [630]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.127574,	
2017-06-23 23:01:54,448 Epoch[14] Batch [640]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.127612,	
2017-06-23 23:01:59,640 Epoch[14] Batch [650]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.127348,	
2017-06-23 23:02:04,840 Epoch[14] Batch [660]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127451,	
2017-06-23 23:02:10,079 Epoch[14] Batch [670]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.127196,	
2017-06-23 23:02:15,362 Epoch[14] Batch [680]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.127064,	
2017-06-23 23:02:20,578 Epoch[14] Batch [690]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.126939,	
2017-06-23 23:02:25,883 Epoch[14] Batch [700]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.126854,	
2017-06-23 23:02:31,044 Epoch[14] Batch [710]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.126896,	
2017-06-23 23:02:36,227 Epoch[14] Batch [720]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.126975,	
2017-06-23 23:02:41,407 Epoch[14] Batch [730]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.126897,	
2017-06-23 23:02:46,653 Epoch[14] Batch [740]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.126877,	
2017-06-23 23:02:51,847 Epoch[14] Batch [750]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.126744,	
2017-06-23 23:02:57,073 Epoch[14] Batch [760]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.126737,	
2017-06-23 23:03:02,302 Epoch[14] Batch [770]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.126613,	
2017-06-23 23:03:07,598 Epoch[14] Batch [780]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.126635,	
2017-06-23 23:03:12,804 Epoch[14] Batch [790]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126636,	
2017-06-23 23:03:17,920 Epoch[14] Batch [800]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.126776,	
2017-06-23 23:03:23,194 Epoch[14] Batch [810]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.126673,	
2017-06-23 23:03:28,349 Epoch[14] Batch [820]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.126791,	
2017-06-23 23:03:33,553 Epoch[14] Batch [830]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126855,	
2017-06-23 23:03:38,795 Epoch[14] Batch [840]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.126874,	
2017-06-23 23:03:44,026 Epoch[14] Batch [850]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.126892,	
2017-06-23 23:03:49,225 Epoch[14] Batch [860]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127075,	
2017-06-23 23:03:54,432 Epoch[14] Batch [870]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.127141,	
2017-06-23 23:03:59,664 Epoch[14] Batch [880]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.126935,	
2017-06-23 23:04:04,874 Epoch[14] Batch [890]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.126913,	
2017-06-23 23:04:10,119 Epoch[14] Batch [900]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.127101,	
2017-06-23 23:04:15,403 Epoch[14] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.127073,	
2017-06-23 23:04:20,571 Epoch[14] Batch [920]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.126954,	
2017-06-23 23:04:25,662 Epoch[14] Batch [930]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.126887,	
2017-06-23 23:04:30,866 Epoch[14] Batch [940]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126882,	
2017-06-23 23:04:36,087 Epoch[14] Batch [950]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.126991,	
2017-06-23 23:04:41,326 Epoch[14] Batch [960]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.127208,	
2017-06-23 23:04:46,529 Epoch[14] Batch [970]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127589,	
2017-06-23 23:04:51,743 Epoch[14] Batch [980]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127647,	
2017-06-23 23:04:56,826 Epoch[14] Batch [990]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.127582,	
2017-06-23 23:05:02,007 Epoch[14] Batch [1000]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.127461,	
2017-06-23 23:05:07,229 Epoch[14] Batch [1010]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.127559,	
2017-06-23 23:05:12,415 Epoch[14] Batch [1020]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.127947,	
2017-06-23 23:05:17,201 Epoch[14] Batch [1030]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.127950,	
2017-06-23 23:05:22,121 Epoch[14] Batch [1040]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.127938,	
2017-06-23 23:05:27,156 Epoch[14] Batch [1050]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.127983,	
2017-06-23 23:05:32,295 Epoch[14] Batch [1060]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.128021,	
2017-06-23 23:05:37,520 Epoch[14] Batch [1070]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.127944,	
2017-06-23 23:05:42,777 Epoch[14] Batch [1080]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.127830,	
2017-06-23 23:05:47,991 Epoch[14] Batch [1090]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127889,	
2017-06-23 23:05:53,230 Epoch[14] Batch [1100]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.127827,	
2017-06-23 23:05:58,394 Epoch[14] Batch [1110]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.127749,	
2017-06-23 23:06:03,667 Epoch[14] Batch [1120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.127773,	
2017-06-23 23:06:08,794 Epoch[14] Batch [1130]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.127822,	
2017-06-23 23:06:14,005 Epoch[14] Batch [1140]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.127656,	
2017-06-23 23:06:19,215 Epoch[14] Batch [1150]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.127559,	
2017-06-23 23:06:24,419 Epoch[14] Batch [1160]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127647,	
2017-06-23 23:06:29,592 Epoch[14] Batch [1170]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.127713,	
2017-06-23 23:06:34,836 Epoch[14] Batch [1180]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.127514,	
2017-06-23 23:06:40,066 Epoch[14] Batch [1190]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.127430,	
2017-06-23 23:06:45,261 Epoch[14] Batch [1200]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.127509,	
2017-06-23 23:06:50,308 Epoch[14] Batch [1210]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.127594,	
2017-06-23 23:06:55,397 Epoch[14] Batch [1220]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.127512,	
2017-06-23 23:07:00,609 Epoch[14] Batch [1230]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127483,	
2017-06-23 23:07:05,840 Epoch[14] Batch [1240]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.127372,	
2017-06-23 23:07:11,003 Epoch[14] Batch [1250]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.127240,	
2017-06-23 23:07:16,301 Epoch[14] Batch [1260]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.127354,	
2017-06-23 23:07:21,457 Epoch[14] Batch [1270]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.127296,	
2017-06-23 23:07:26,674 Epoch[14] Batch [1280]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.127217,	
2017-06-23 23:07:31,882 Epoch[14] Batch [1290]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.127211,	
2017-06-23 23:07:37,083 Epoch[14] Batch [1300]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127227,	
2017-06-23 23:07:42,214 Epoch[14] Batch [1310]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.127144,	
2017-06-23 23:07:47,441 Epoch[14] Batch [1320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.127238,	
2017-06-23 23:07:52,622 Epoch[14] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.127277,	
2017-06-23 23:07:57,851 Epoch[14] Batch [1340]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.127335,	
2017-06-23 23:08:03,171 Epoch[14] Batch [1350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.127196,	
2017-06-23 23:08:08,221 Epoch[14] Batch [1360]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.127124,	
2017-06-23 23:08:13,457 Epoch[14] Batch [1370]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.127127,	
2017-06-23 23:08:18,711 Epoch[14] Batch [1380]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.127022,	
2017-06-23 23:08:23,872 Epoch[14] Batch [1390]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.126933,	
2017-06-23 23:08:29,070 Epoch[14] Batch [1400]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.127041,	
2017-06-23 23:08:34,309 Epoch[14] Batch [1410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.127061,	
2017-06-23 23:08:39,468 Epoch[14] Batch [1420]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.127054,	
2017-06-23 23:08:44,706 Epoch[14] Batch [1430]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126930,	
2017-06-23 23:08:49,978 Epoch[14] Batch [1440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.126981,	
2017-06-23 23:08:55,135 Epoch[14] Batch [1450]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.126965,	
2017-06-23 23:09:00,340 Epoch[14] Batch [1460]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126909,	
2017-06-23 23:09:05,520 Epoch[14] Batch [1470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.126867,	
2017-06-23 23:09:10,756 Epoch[14] Batch [1480]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126921,	
2017-06-23 23:09:13,881 Epoch[14] Train-FCNLogLoss=0.126870
2017-06-23 23:09:13,882 Epoch[14] Time cost=774.163
2017-06-23 23:09:15,049 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0015.params"
2017-06-23 23:09:18,816 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0015.states"
2017-06-23 23:09:24,905 Epoch[15] Batch [10]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.118519,	
2017-06-23 23:09:30,099 Epoch[15] Batch [20]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.123471,	
2017-06-23 23:09:35,254 Epoch[15] Batch [30]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.124256,	
2017-06-23 23:09:40,471 Epoch[15] Batch [40]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.121959,	
2017-06-23 23:09:45,704 Epoch[15] Batch [50]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122442,	
2017-06-23 23:09:50,953 Epoch[15] Batch [60]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.120737,	
2017-06-23 23:09:56,171 Epoch[15] Batch [70]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.120270,	
2017-06-23 23:10:01,395 Epoch[15] Batch [80]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.120556,	
2017-06-23 23:10:06,623 Epoch[15] Batch [90]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.120734,	
2017-06-23 23:10:11,858 Epoch[15] Batch [100]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126481,	
2017-06-23 23:10:17,066 Epoch[15] Batch [110]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.127512,	
2017-06-23 23:10:22,280 Epoch[15] Batch [120]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.126690,	
2017-06-23 23:10:27,594 Epoch[15] Batch [130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.126356,	
2017-06-23 23:10:32,762 Epoch[15] Batch [140]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.127299,	
2017-06-23 23:10:37,983 Epoch[15] Batch [150]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.126669,	
2017-06-23 23:10:43,193 Epoch[15] Batch [160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.127014,	
2017-06-23 23:10:48,396 Epoch[15] Batch [170]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126280,	
2017-06-23 23:10:53,737 Epoch[15] Batch [180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.126437,	
2017-06-23 23:10:58,868 Epoch[15] Batch [190]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.126715,	
2017-06-23 23:11:04,126 Epoch[15] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.127189,	
2017-06-23 23:11:09,359 Epoch[15] Batch [210]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126841,	
2017-06-23 23:11:14,501 Epoch[15] Batch [220]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.127001,	
2017-06-23 23:11:19,742 Epoch[15] Batch [230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.126968,	
2017-06-23 23:11:24,951 Epoch[15] Batch [240]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.126765,	
2017-06-23 23:11:30,196 Epoch[15] Batch [250]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.126198,	
2017-06-23 23:11:35,368 Epoch[15] Batch [260]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.126131,	
2017-06-23 23:11:40,627 Epoch[15] Batch [270]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125907,	
2017-06-23 23:11:45,846 Epoch[15] Batch [280]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.125979,	
2017-06-23 23:11:50,385 Epoch[15] Batch [290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.125821,	
2017-06-23 23:11:55,334 Epoch[15] Batch [300]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.125684,	
2017-06-23 23:12:00,531 Epoch[15] Batch [310]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.125385,	
2017-06-23 23:12:05,747 Epoch[15] Batch [320]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.124956,	
2017-06-23 23:12:10,905 Epoch[15] Batch [330]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.125520,	
2017-06-23 23:12:16,151 Epoch[15] Batch [340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.124614,	
2017-06-23 23:12:21,401 Epoch[15] Batch [350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.124417,	
2017-06-23 23:12:26,578 Epoch[15] Batch [360]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.124731,	
2017-06-23 23:12:31,813 Epoch[15] Batch [370]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.124215,	
2017-06-23 23:12:36,949 Epoch[15] Batch [380]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.124078,	
2017-06-23 23:12:41,984 Epoch[15] Batch [390]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.124208,	
2017-06-23 23:12:47,136 Epoch[15] Batch [400]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.124198,	
2017-06-23 23:12:52,408 Epoch[15] Batch [410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.124170,	
2017-06-23 23:12:57,578 Epoch[15] Batch [420]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.124136,	
2017-06-23 23:13:02,790 Epoch[15] Batch [430]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.124053,	
2017-06-23 23:13:08,086 Epoch[15] Batch [440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.123596,	
2017-06-23 23:13:13,239 Epoch[15] Batch [450]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.123338,	
2017-06-23 23:13:18,440 Epoch[15] Batch [460]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.123141,	
2017-06-23 23:13:23,688 Epoch[15] Batch [470]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123083,	
2017-06-23 23:13:28,854 Epoch[15] Batch [480]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.123298,	
2017-06-23 23:13:34,120 Epoch[15] Batch [490]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.123120,	
2017-06-23 23:13:39,380 Epoch[15] Batch [500]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.123075,	
2017-06-23 23:13:44,540 Epoch[15] Batch [510]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.123186,	
2017-06-23 23:13:49,722 Epoch[15] Batch [520]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.122897,	
2017-06-23 23:13:54,901 Epoch[15] Batch [530]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.122799,	
2017-06-23 23:14:00,121 Epoch[15] Batch [540]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.123198,	
2017-06-23 23:14:05,415 Epoch[15] Batch [550]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122865,	
2017-06-23 23:14:10,521 Epoch[15] Batch [560]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.122785,	
2017-06-23 23:14:15,723 Epoch[15] Batch [570]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.122855,	
2017-06-23 23:14:20,914 Epoch[15] Batch [580]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122914,	
2017-06-23 23:14:26,118 Epoch[15] Batch [590]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.122851,	
2017-06-23 23:14:31,307 Epoch[15] Batch [600]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122963,	
2017-06-23 23:14:36,520 Epoch[15] Batch [610]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.122908,	
2017-06-23 23:14:41,821 Epoch[15] Batch [620]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.122774,	
2017-06-23 23:14:47,029 Epoch[15] Batch [630]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.122629,	
2017-06-23 23:14:52,201 Epoch[15] Batch [640]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.122898,	
2017-06-23 23:14:57,329 Epoch[15] Batch [650]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.122977,	
2017-06-23 23:15:02,489 Epoch[15] Batch [660]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.123097,	
2017-06-23 23:15:07,662 Epoch[15] Batch [670]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.123433,	
2017-06-23 23:15:12,910 Epoch[15] Batch [680]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123503,	
2017-06-23 23:15:18,128 Epoch[15] Batch [690]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.123534,	
2017-06-23 23:15:23,384 Epoch[15] Batch [700]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123533,	
2017-06-23 23:15:28,318 Epoch[15] Batch [710]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.123502,	
2017-06-23 23:15:33,480 Epoch[15] Batch [720]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.123589,	
2017-06-23 23:15:38,491 Epoch[15] Batch [730]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.123491,	
2017-06-23 23:15:43,430 Epoch[15] Batch [740]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.123418,	
2017-06-23 23:15:48,592 Epoch[15] Batch [750]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.123365,	
2017-06-23 23:15:53,593 Epoch[15] Batch [760]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.123317,	
2017-06-23 23:15:58,700 Epoch[15] Batch [770]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.123265,	
2017-06-23 23:16:03,408 Epoch[15] Batch [780]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.123192,	
2017-06-23 23:16:08,213 Epoch[15] Batch [790]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.123355,	
2017-06-23 23:16:13,297 Epoch[15] Batch [800]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.123483,	
2017-06-23 23:16:18,225 Epoch[15] Batch [810]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.123453,	
2017-06-23 23:16:23,132 Epoch[15] Batch [820]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.123215,	
2017-06-23 23:16:28,352 Epoch[15] Batch [830]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.123101,	
2017-06-23 23:16:33,582 Epoch[15] Batch [840]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.122897,	
2017-06-23 23:16:38,436 Epoch[15] Batch [850]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.123141,	
2017-06-23 23:16:43,697 Epoch[15] Batch [860]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.123246,	
2017-06-23 23:16:48,774 Epoch[15] Batch [870]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.123336,	
2017-06-23 23:16:53,857 Epoch[15] Batch [880]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.123329,	
2017-06-23 23:16:59,100 Epoch[15] Batch [890]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.123266,	
2017-06-23 23:17:04,424 Epoch[15] Batch [900]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.123412,	
2017-06-23 23:17:09,563 Epoch[15] Batch [910]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.123533,	
2017-06-23 23:17:14,644 Epoch[15] Batch [920]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.123411,	
2017-06-23 23:17:19,915 Epoch[15] Batch [930]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.123342,	
2017-06-23 23:17:24,976 Epoch[15] Batch [940]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.123336,	
2017-06-23 23:17:29,878 Epoch[15] Batch [950]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.123136,	
2017-06-23 23:17:35,281 Epoch[15] Batch [960]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.123116,	
2017-06-23 23:17:40,384 Epoch[15] Batch [970]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.123139,	
2017-06-23 23:17:45,455 Epoch[15] Batch [980]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.123324,	
2017-06-23 23:17:50,729 Epoch[15] Batch [990]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.123306,	
2017-06-23 23:17:55,934 Epoch[15] Batch [1000]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.123230,	
2017-06-23 23:18:01,075 Epoch[15] Batch [1010]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.123124,	
2017-06-23 23:18:06,377 Epoch[15] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.122977,	
2017-06-23 23:18:11,591 Epoch[15] Batch [1030]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.122962,	
2017-06-23 23:18:16,796 Epoch[15] Batch [1040]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.122812,	
2017-06-23 23:18:21,963 Epoch[15] Batch [1050]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.122761,	
2017-06-23 23:18:26,896 Epoch[15] Batch [1060]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.122775,	
2017-06-23 23:18:31,709 Epoch[15] Batch [1070]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.122755,	
2017-06-23 23:18:36,970 Epoch[15] Batch [1080]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.122651,	
2017-06-23 23:18:41,938 Epoch[15] Batch [1090]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.122801,	
2017-06-23 23:18:47,124 Epoch[15] Batch [1100]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122819,	
2017-06-23 23:18:52,011 Epoch[15] Batch [1110]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.122951,	
2017-06-23 23:18:56,954 Epoch[15] Batch [1120]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.122991,	
2017-06-23 23:19:02,007 Epoch[15] Batch [1130]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.123043,	
2017-06-23 23:19:06,953 Epoch[15] Batch [1140]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.123134,	
2017-06-23 23:19:12,117 Epoch[15] Batch [1150]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.123189,	
2017-06-23 23:19:17,274 Epoch[15] Batch [1160]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.123239,	
2017-06-23 23:19:22,483 Epoch[15] Batch [1170]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.123398,	
2017-06-23 23:19:27,788 Epoch[15] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.123421,	
2017-06-23 23:19:32,918 Epoch[15] Batch [1190]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.123340,	
2017-06-23 23:19:38,061 Epoch[15] Batch [1200]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.123364,	
2017-06-23 23:19:43,279 Epoch[15] Batch [1210]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.123430,	
2017-06-23 23:19:48,444 Epoch[15] Batch [1220]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.123662,	
2017-06-23 23:19:53,641 Epoch[15] Batch [1230]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.123566,	
2017-06-23 23:19:58,848 Epoch[15] Batch [1240]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.123544,	
2017-06-23 23:20:03,945 Epoch[15] Batch [1250]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.123570,	
2017-06-23 23:20:09,093 Epoch[15] Batch [1260]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.123539,	
2017-06-23 23:20:14,236 Epoch[15] Batch [1270]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.123445,	
2017-06-23 23:20:19,421 Epoch[15] Batch [1280]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.123479,	
2017-06-23 23:20:24,632 Epoch[15] Batch [1290]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.123466,	
2017-06-23 23:20:29,867 Epoch[15] Batch [1300]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.123403,	
2017-06-23 23:20:35,044 Epoch[15] Batch [1310]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.123296,	
2017-06-23 23:20:40,181 Epoch[15] Batch [1320]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.123199,	
2017-06-23 23:20:45,354 Epoch[15] Batch [1330]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.123096,	
2017-06-23 23:20:50,502 Epoch[15] Batch [1340]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.123078,	
2017-06-23 23:20:55,726 Epoch[15] Batch [1350]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.123009,	
2017-06-23 23:21:00,992 Epoch[15] Batch [1360]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.122927,	
2017-06-23 23:21:06,106 Epoch[15] Batch [1370]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.122933,	
2017-06-23 23:21:11,315 Epoch[15] Batch [1380]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.122914,	
2017-06-23 23:21:16,500 Epoch[15] Batch [1390]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122796,	
2017-06-23 23:21:21,701 Epoch[15] Batch [1400]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.122736,	
2017-06-23 23:21:26,934 Epoch[15] Batch [1410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122679,	
2017-06-23 23:21:32,155 Epoch[15] Batch [1420]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.122656,	
2017-06-23 23:21:37,296 Epoch[15] Batch [1430]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.122717,	
2017-06-23 23:21:42,345 Epoch[15] Batch [1440]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.122730,	
2017-06-23 23:21:47,528 Epoch[15] Batch [1450]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.122718,	
2017-06-23 23:21:52,752 Epoch[15] Batch [1460]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.122700,	
2017-06-23 23:21:57,982 Epoch[15] Batch [1470]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.122663,	
2017-06-23 23:22:03,110 Epoch[15] Batch [1480]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.122549,	
2017-06-23 23:22:06,141 Epoch[15] Train-FCNLogLoss=0.122459
2017-06-23 23:22:06,141 Epoch[15] Time cost=767.325
2017-06-23 23:22:07,225 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0016.params"
2017-06-23 23:22:09,106 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0016.states"
2017-06-23 23:22:14,971 Epoch[16] Batch [10]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.114361,	
2017-06-23 23:22:20,225 Epoch[16] Batch [20]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112283,	
2017-06-23 23:22:25,410 Epoch[16] Batch [30]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.115796,	
2017-06-23 23:22:30,614 Epoch[16] Batch [40]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.116703,	
2017-06-23 23:22:35,853 Epoch[16] Batch [50]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.115416,	
2017-06-23 23:22:41,015 Epoch[16] Batch [60]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.114864,	
2017-06-23 23:22:46,220 Epoch[16] Batch [70]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.114045,	
2017-06-23 23:22:51,415 Epoch[16] Batch [80]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.113782,	
2017-06-23 23:22:56,569 Epoch[16] Batch [90]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112852,	
2017-06-23 23:23:01,750 Epoch[16] Batch [100]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.114490,	
2017-06-23 23:23:06,911 Epoch[16] Batch [110]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.114757,	
2017-06-23 23:23:12,100 Epoch[16] Batch [120]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.115306,	
2017-06-23 23:23:17,294 Epoch[16] Batch [130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.114589,	
2017-06-23 23:23:22,494 Epoch[16] Batch [140]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.115643,	
2017-06-23 23:23:27,690 Epoch[16] Batch [150]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.115299,	
2017-06-23 23:23:32,898 Epoch[16] Batch [160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.115821,	
2017-06-23 23:23:38,067 Epoch[16] Batch [170]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.115528,	
2017-06-23 23:23:43,250 Epoch[16] Batch [180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.115407,	
2017-06-23 23:23:48,412 Epoch[16] Batch [190]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.115470,	
2017-06-23 23:23:53,624 Epoch[16] Batch [200]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.115043,	
2017-06-23 23:23:58,840 Epoch[16] Batch [210]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.115442,	
2017-06-23 23:24:04,026 Epoch[16] Batch [220]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.115493,	
2017-06-23 23:24:09,185 Epoch[16] Batch [230]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.115559,	
2017-06-23 23:24:14,394 Epoch[16] Batch [240]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.116824,	
2017-06-23 23:24:19,582 Epoch[16] Batch [250]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.117533,	
2017-06-23 23:24:24,811 Epoch[16] Batch [260]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.117713,	
2017-06-23 23:24:30,056 Epoch[16] Batch [270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.117575,	
2017-06-23 23:24:35,215 Epoch[16] Batch [280]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.117975,	
2017-06-23 23:24:40,407 Epoch[16] Batch [290]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.117835,	
2017-06-23 23:24:45,559 Epoch[16] Batch [300]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.117959,	
2017-06-23 23:24:50,377 Epoch[16] Batch [310]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.117575,	
2017-06-23 23:24:55,254 Epoch[16] Batch [320]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.117871,	
2017-06-23 23:25:00,792 Epoch[16] Batch [330]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.117973,	
2017-06-23 23:25:05,915 Epoch[16] Batch [340]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.117821,	
2017-06-23 23:25:10,975 Epoch[16] Batch [350]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.117911,	
2017-06-23 23:25:16,103 Epoch[16] Batch [360]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.117767,	
2017-06-23 23:25:21,363 Epoch[16] Batch [370]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.117986,	
2017-06-23 23:25:26,315 Epoch[16] Batch [380]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.118255,	
2017-06-23 23:25:31,530 Epoch[16] Batch [390]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.118082,	
2017-06-23 23:25:36,485 Epoch[16] Batch [400]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.118000,	
2017-06-23 23:25:41,460 Epoch[16] Batch [410]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.117697,	
2017-06-23 23:25:46,628 Epoch[16] Batch [420]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.117953,	
2017-06-23 23:25:51,711 Epoch[16] Batch [430]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.117891,	
2017-06-23 23:25:56,570 Epoch[16] Batch [440]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.117765,	
2017-06-23 23:26:01,715 Epoch[16] Batch [450]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.118396,	
2017-06-23 23:26:06,970 Epoch[16] Batch [460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118355,	
2017-06-23 23:26:12,031 Epoch[16] Batch [470]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.118463,	
2017-06-23 23:26:18,035 Epoch[16] Batch [480]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.119067,	
2017-06-23 23:26:23,838 Epoch[16] Batch [490]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.119339,	
2017-06-23 23:26:28,827 Epoch[16] Batch [500]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.119287,	
2017-06-23 23:26:33,833 Epoch[16] Batch [510]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.119179,	
2017-06-23 23:26:38,661 Epoch[16] Batch [520]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.119370,	
2017-06-23 23:26:43,848 Epoch[16] Batch [530]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.119688,	
2017-06-23 23:26:49,066 Epoch[16] Batch [540]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.120038,	
2017-06-23 23:26:53,804 Epoch[16] Batch [550]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.120101,	
2017-06-23 23:26:59,064 Epoch[16] Batch [560]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.120139,	
2017-06-23 23:27:04,193 Epoch[16] Batch [570]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.120329,	
2017-06-23 23:27:09,391 Epoch[16] Batch [580]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.120486,	
2017-06-23 23:27:14,393 Epoch[16] Batch [590]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.120726,	
2017-06-23 23:27:19,575 Epoch[16] Batch [600]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120839,	
2017-06-23 23:27:24,764 Epoch[16] Batch [610]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.120754,	
2017-06-23 23:27:29,968 Epoch[16] Batch [620]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.120723,	
2017-06-23 23:27:35,168 Epoch[16] Batch [630]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.120566,	
2017-06-23 23:27:40,404 Epoch[16] Batch [640]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.120357,	
2017-06-23 23:27:45,432 Epoch[16] Batch [650]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.120273,	
2017-06-23 23:27:50,387 Epoch[16] Batch [660]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.120317,	
2017-06-23 23:27:55,306 Epoch[16] Batch [670]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.120313,	
2017-06-23 23:28:00,432 Epoch[16] Batch [680]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.120443,	
2017-06-23 23:28:05,421 Epoch[16] Batch [690]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.120377,	
2017-06-23 23:28:10,480 Epoch[16] Batch [700]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.120528,	
2017-06-23 23:28:15,469 Epoch[16] Batch [710]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.120493,	
2017-06-23 23:28:20,410 Epoch[16] Batch [720]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.120569,	
2017-06-23 23:28:25,501 Epoch[16] Batch [730]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.120473,	
2017-06-23 23:28:30,474 Epoch[16] Batch [740]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.120499,	
2017-06-23 23:28:35,072 Epoch[16] Batch [750]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.120585,	
2017-06-23 23:28:40,256 Epoch[16] Batch [760]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120497,	
2017-06-23 23:28:45,265 Epoch[16] Batch [770]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.120740,	
2017-06-23 23:28:50,156 Epoch[16] Batch [780]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.120706,	
2017-06-23 23:28:55,315 Epoch[16] Batch [790]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.120838,	
2017-06-23 23:29:00,272 Epoch[16] Batch [800]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.120873,	
2017-06-23 23:29:05,338 Epoch[16] Batch [810]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.120689,	
2017-06-23 23:29:10,282 Epoch[16] Batch [820]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.120697,	
2017-06-23 23:29:15,340 Epoch[16] Batch [830]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.120956,	
2017-06-23 23:29:20,294 Epoch[16] Batch [840]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.121042,	
2017-06-23 23:29:25,231 Epoch[16] Batch [850]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.120948,	
2017-06-23 23:29:30,302 Epoch[16] Batch [860]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.120982,	
2017-06-23 23:29:35,154 Epoch[16] Batch [870]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.120972,	
2017-06-23 23:29:40,654 Epoch[16] Batch [880]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.120981,	
2017-06-23 23:29:45,453 Epoch[16] Batch [890]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.121013,	
2017-06-23 23:29:50,362 Epoch[16] Batch [900]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.121083,	
2017-06-23 23:29:55,327 Epoch[16] Batch [910]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.121157,	
2017-06-23 23:30:00,146 Epoch[16] Batch [920]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.121157,	
2017-06-23 23:30:05,276 Epoch[16] Batch [930]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.121054,	
2017-06-23 23:30:10,423 Epoch[16] Batch [940]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.121026,	
2017-06-23 23:30:15,603 Epoch[16] Batch [950]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120988,	
2017-06-23 23:30:20,841 Epoch[16] Batch [960]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.121134,	
2017-06-23 23:30:26,057 Epoch[16] Batch [970]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.121078,	
2017-06-23 23:30:31,221 Epoch[16] Batch [980]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.121021,	
2017-06-23 23:30:36,403 Epoch[16] Batch [990]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.121103,	
2017-06-23 23:30:41,475 Epoch[16] Batch [1000]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.121017,	
2017-06-23 23:30:46,648 Epoch[16] Batch [1010]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.121096,	
2017-06-23 23:30:51,846 Epoch[16] Batch [1020]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.121022,	
2017-06-23 23:30:57,066 Epoch[16] Batch [1030]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.121040,	
2017-06-23 23:31:02,279 Epoch[16] Batch [1040]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.121042,	
2017-06-23 23:31:07,496 Epoch[16] Batch [1050]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.120922,	
2017-06-23 23:31:12,703 Epoch[16] Batch [1060]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.121030,	
2017-06-23 23:31:17,890 Epoch[16] Batch [1070]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.121147,	
2017-06-23 23:31:23,039 Epoch[16] Batch [1080]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.121136,	
2017-06-23 23:31:28,166 Epoch[16] Batch [1090]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.121065,	
2017-06-23 23:31:33,446 Epoch[16] Batch [1100]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121132,	
2017-06-23 23:31:38,640 Epoch[16] Batch [1110]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.121208,	
2017-06-23 23:31:43,767 Epoch[16] Batch [1120]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.121146,	
2017-06-23 23:31:48,984 Epoch[16] Batch [1130]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.121040,	
2017-06-23 23:31:54,055 Epoch[16] Batch [1140]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.120977,	
2017-06-23 23:31:59,109 Epoch[16] Batch [1150]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.120935,	
2017-06-23 23:32:04,317 Epoch[16] Batch [1160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.120878,	
2017-06-23 23:32:09,522 Epoch[16] Batch [1170]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.121016,	
2017-06-23 23:32:14,712 Epoch[16] Batch [1180]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.121045,	
2017-06-23 23:32:19,876 Epoch[16] Batch [1190]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.121324,	
2017-06-23 23:32:25,056 Epoch[16] Batch [1200]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.121471,	
2017-06-23 23:32:30,227 Epoch[16] Batch [1210]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.121437,	
2017-06-23 23:32:35,425 Epoch[16] Batch [1220]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.121425,	
2017-06-23 23:32:40,668 Epoch[16] Batch [1230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.121282,	
2017-06-23 23:32:45,785 Epoch[16] Batch [1240]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.121285,	
2017-06-23 23:32:50,977 Epoch[16] Batch [1250]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.121253,	
2017-06-23 23:32:56,212 Epoch[16] Batch [1260]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.121202,	
2017-06-23 23:33:00,993 Epoch[16] Batch [1270]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.121163,	
2017-06-23 23:33:05,701 Epoch[16] Batch [1280]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121220,	
2017-06-23 23:33:10,896 Epoch[16] Batch [1290]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.121137,	
2017-06-23 23:33:15,943 Epoch[16] Batch [1300]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.121229,	
2017-06-23 23:33:20,626 Epoch[16] Batch [1310]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121146,	
2017-06-23 23:33:25,719 Epoch[16] Batch [1320]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.121138,	
2017-06-23 23:33:30,646 Epoch[16] Batch [1330]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.121219,	
2017-06-23 23:33:35,892 Epoch[16] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121167,	
2017-06-23 23:33:41,092 Epoch[16] Batch [1350]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.121180,	
2017-06-23 23:33:45,882 Epoch[16] Batch [1360]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.121070,	
2017-06-23 23:33:50,761 Epoch[16] Batch [1370]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.121066,	
2017-06-23 23:33:56,014 Epoch[16] Batch [1380]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121102,	
2017-06-23 23:34:00,749 Epoch[16] Batch [1390]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.121071,	
2017-06-23 23:34:05,934 Epoch[16] Batch [1400]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.121106,	
2017-06-23 23:34:11,064 Epoch[16] Batch [1410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.121122,	
2017-06-23 23:34:16,270 Epoch[16] Batch [1420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.121021,	
2017-06-23 23:34:21,511 Epoch[16] Batch [1430]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120973,	
2017-06-23 23:34:26,660 Epoch[16] Batch [1440]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.120980,	
2017-06-23 23:34:31,851 Epoch[16] Batch [1450]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.120921,	
2017-06-23 23:34:36,663 Epoch[16] Batch [1460]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.120824,	
2017-06-23 23:34:41,653 Epoch[16] Batch [1470]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.120779,	
2017-06-23 23:34:46,591 Epoch[16] Batch [1480]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.120773,	
2017-06-23 23:34:49,544 Epoch[16] Train-FCNLogLoss=0.120722
2017-06-23 23:34:49,544 Epoch[16] Time cost=760.437
2017-06-23 23:34:50,612 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0017.params"
2017-06-23 23:34:52,334 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0017.states"
2017-06-23 23:34:58,345 Epoch[17] Batch [10]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.130670,	
2017-06-23 23:35:03,499 Epoch[17] Batch [20]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.154523,	
2017-06-23 23:35:08,721 Epoch[17] Batch [30]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.144872,	
2017-06-23 23:35:13,885 Epoch[17] Batch [40]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.142432,	
2017-06-23 23:35:19,051 Epoch[17] Batch [50]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.135556,	
2017-06-23 23:35:24,272 Epoch[17] Batch [60]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.134789,	
2017-06-23 23:35:29,443 Epoch[17] Batch [70]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.135323,	
2017-06-23 23:35:34,630 Epoch[17] Batch [80]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.132798,	
2017-06-23 23:35:39,862 Epoch[17] Batch [90]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.132689,	
2017-06-23 23:35:45,029 Epoch[17] Batch [100]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.132878,	
2017-06-23 23:35:50,228 Epoch[17] Batch [110]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.131446,	
2017-06-23 23:35:55,442 Epoch[17] Batch [120]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.131291,	
2017-06-23 23:36:00,599 Epoch[17] Batch [130]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.130662,	
2017-06-23 23:36:05,848 Epoch[17] Batch [140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.129641,	
2017-06-23 23:36:11,004 Epoch[17] Batch [150]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.128157,	
2017-06-23 23:36:16,234 Epoch[17] Batch [160]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.127576,	
2017-06-23 23:36:21,439 Epoch[17] Batch [170]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.127080,	
2017-06-23 23:36:26,641 Epoch[17] Batch [180]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126222,	
2017-06-23 23:36:32,019 Epoch[17] Batch [190]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.126186,	
2017-06-23 23:36:37,096 Epoch[17] Batch [200]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.126275,	
2017-06-23 23:36:42,300 Epoch[17] Batch [210]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.125768,	
2017-06-23 23:36:47,419 Epoch[17] Batch [220]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.124941,	
2017-06-23 23:36:52,646 Epoch[17] Batch [230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.124516,	
2017-06-23 23:36:57,892 Epoch[17] Batch [240]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.123651,	
2017-06-23 23:37:03,071 Epoch[17] Batch [250]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.123250,	
2017-06-23 23:37:08,418 Epoch[17] Batch [260]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.123781,	
2017-06-23 23:37:13,545 Epoch[17] Batch [270]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.123547,	
2017-06-23 23:37:18,798 Epoch[17] Batch [280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123697,	
2017-06-23 23:37:23,986 Epoch[17] Batch [290]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.123688,	
2017-06-23 23:37:29,233 Epoch[17] Batch [300]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123993,	
2017-06-23 23:37:34,474 Epoch[17] Batch [310]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.124013,	
2017-06-23 23:37:39,713 Epoch[17] Batch [320]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.123767,	
2017-06-23 23:37:44,868 Epoch[17] Batch [330]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.123773,	
2017-06-23 23:37:50,151 Epoch[17] Batch [340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.123464,	
2017-06-23 23:37:55,266 Epoch[17] Batch [350]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.123077,	
2017-06-23 23:38:00,458 Epoch[17] Batch [360]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122911,	
2017-06-23 23:38:05,698 Epoch[17] Batch [370]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.123149,	
2017-06-23 23:38:10,888 Epoch[17] Batch [380]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122898,	
2017-06-23 23:38:15,996 Epoch[17] Batch [390]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.122683,	
2017-06-23 23:38:21,424 Epoch[17] Batch [400]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.122484,	
2017-06-23 23:38:26,613 Epoch[17] Batch [410]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122558,	
2017-06-23 23:38:31,853 Epoch[17] Batch [420]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122591,	
2017-06-23 23:38:36,834 Epoch[17] Batch [430]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.122567,	
2017-06-23 23:38:42,025 Epoch[17] Batch [440]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122145,	
2017-06-23 23:38:46,969 Epoch[17] Batch [450]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.121726,	
2017-06-23 23:38:52,128 Epoch[17] Batch [460]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.121448,	
2017-06-23 23:38:57,298 Epoch[17] Batch [470]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.121445,	
2017-06-23 23:39:02,579 Epoch[17] Batch [480]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121436,	
2017-06-23 23:39:07,781 Epoch[17] Batch [490]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.121612,	
2017-06-23 23:39:12,968 Epoch[17] Batch [500]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.121704,	
2017-06-23 23:39:18,199 Epoch[17] Batch [510]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121583,	
2017-06-23 23:39:23,370 Epoch[17] Batch [520]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.121290,	
2017-06-23 23:39:28,711 Epoch[17] Batch [530]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121243,	
2017-06-23 23:39:33,796 Epoch[17] Batch [540]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.121243,	
2017-06-23 23:39:39,052 Epoch[17] Batch [550]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121153,	
2017-06-23 23:39:44,234 Epoch[17] Batch [560]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.121149,	
2017-06-23 23:39:49,463 Epoch[17] Batch [570]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.120898,	
2017-06-23 23:39:54,598 Epoch[17] Batch [580]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.120656,	
2017-06-23 23:39:59,973 Epoch[17] Batch [590]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.120545,	
2017-06-23 23:40:05,083 Epoch[17] Batch [600]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.120367,	
2017-06-23 23:40:10,322 Epoch[17] Batch [610]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.120476,	
2017-06-23 23:40:15,462 Epoch[17] Batch [620]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.120508,	
2017-06-23 23:40:20,763 Epoch[17] Batch [630]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.120286,	
2017-06-23 23:40:25,943 Epoch[17] Batch [640]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120172,	
2017-06-23 23:40:31,062 Epoch[17] Batch [650]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.120246,	
2017-06-23 23:40:36,245 Epoch[17] Batch [660]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120303,	
2017-06-23 23:40:41,168 Epoch[17] Batch [670]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.120295,	
2017-06-23 23:40:45,963 Epoch[17] Batch [680]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.120344,	
2017-06-23 23:40:51,316 Epoch[17] Batch [690]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.120218,	
2017-06-23 23:40:56,505 Epoch[17] Batch [700]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.120249,	
2017-06-23 23:41:01,759 Epoch[17] Batch [710]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.120113,	
2017-06-23 23:41:06,953 Epoch[17] Batch [720]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.120095,	
2017-06-23 23:41:12,217 Epoch[17] Batch [730]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.120100,	
2017-06-23 23:41:17,319 Epoch[17] Batch [740]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.120175,	
2017-06-23 23:41:22,339 Epoch[17] Batch [750]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.120010,	
2017-06-23 23:41:27,470 Epoch[17] Batch [760]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.119789,	
2017-06-23 23:41:32,705 Epoch[17] Batch [770]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.119866,	
2017-06-23 23:41:37,839 Epoch[17] Batch [780]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.119878,	
2017-06-23 23:41:43,041 Epoch[17] Batch [790]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.119869,	
2017-06-23 23:41:48,236 Epoch[17] Batch [800]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.119795,	
2017-06-23 23:41:53,455 Epoch[17] Batch [810]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.119803,	
2017-06-23 23:41:58,675 Epoch[17] Batch [820]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.119677,	
2017-06-23 23:42:03,798 Epoch[17] Batch [830]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.119652,	
2017-06-23 23:42:08,993 Epoch[17] Batch [840]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.119747,	
2017-06-23 23:42:14,228 Epoch[17] Batch [850]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.119796,	
2017-06-23 23:42:19,339 Epoch[17] Batch [860]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.119780,	
2017-06-23 23:42:24,579 Epoch[17] Batch [870]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.119824,	
2017-06-23 23:42:29,806 Epoch[17] Batch [880]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.119956,	
2017-06-23 23:42:34,965 Epoch[17] Batch [890]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.119964,	
2017-06-23 23:42:40,172 Epoch[17] Batch [900]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119952,	
2017-06-23 23:42:45,366 Epoch[17] Batch [910]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.119785,	
2017-06-23 23:42:50,540 Epoch[17] Batch [920]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.119750,	
2017-06-23 23:42:55,738 Epoch[17] Batch [930]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.119708,	
2017-06-23 23:43:00,967 Epoch[17] Batch [940]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.119687,	
2017-06-23 23:43:06,147 Epoch[17] Batch [950]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.119740,	
2017-06-23 23:43:11,309 Epoch[17] Batch [960]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.119613,	
2017-06-23 23:43:16,534 Epoch[17] Batch [970]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.119635,	
2017-06-23 23:43:21,683 Epoch[17] Batch [980]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.119682,	
2017-06-23 23:43:26,890 Epoch[17] Batch [990]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119621,	
2017-06-23 23:43:32,066 Epoch[17] Batch [1000]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.119675,	
2017-06-23 23:43:37,253 Epoch[17] Batch [1010]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.119618,	
2017-06-23 23:43:42,430 Epoch[17] Batch [1020]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.119577,	
2017-06-23 23:43:47,614 Epoch[17] Batch [1030]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.119587,	
2017-06-23 23:43:52,838 Epoch[17] Batch [1040]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.119622,	
2017-06-23 23:43:58,099 Epoch[17] Batch [1050]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.119593,	
2017-06-23 23:44:03,211 Epoch[17] Batch [1060]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.119417,	
2017-06-23 23:44:08,362 Epoch[17] Batch [1070]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.119258,	
2017-06-23 23:44:13,553 Epoch[17] Batch [1080]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.119297,	
2017-06-23 23:44:18,765 Epoch[17] Batch [1090]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.119178,	
2017-06-23 23:44:23,988 Epoch[17] Batch [1100]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.119036,	
2017-06-23 23:44:29,208 Epoch[17] Batch [1110]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.119144,	
2017-06-23 23:44:34,344 Epoch[17] Batch [1120]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.119291,	
2017-06-23 23:44:39,515 Epoch[17] Batch [1130]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.119140,	
2017-06-23 23:44:44,710 Epoch[17] Batch [1140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.119119,	
2017-06-23 23:44:50,027 Epoch[17] Batch [1150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.119071,	
2017-06-23 23:44:55,131 Epoch[17] Batch [1160]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.119021,	
2017-06-23 23:45:00,283 Epoch[17] Batch [1170]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.119049,	
2017-06-23 23:45:05,526 Epoch[17] Batch [1180]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.118966,	
2017-06-23 23:45:10,687 Epoch[17] Batch [1190]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.118998,	
2017-06-23 23:45:15,899 Epoch[17] Batch [1200]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.118937,	
2017-06-23 23:45:20,887 Epoch[17] Batch [1210]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.118973,	
2017-06-23 23:45:26,042 Epoch[17] Batch [1220]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.118849,	
2017-06-23 23:45:31,199 Epoch[17] Batch [1230]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.119001,	
2017-06-23 23:45:36,249 Epoch[17] Batch [1240]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.118903,	
2017-06-23 23:45:41,334 Epoch[17] Batch [1250]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.118916,	
2017-06-23 23:45:46,525 Epoch[17] Batch [1260]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.118840,	
2017-06-23 23:45:51,733 Epoch[17] Batch [1270]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.118820,	
2017-06-23 23:45:56,929 Epoch[17] Batch [1280]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.118734,	
2017-06-23 23:46:02,117 Epoch[17] Batch [1290]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.118635,	
2017-06-23 23:46:07,372 Epoch[17] Batch [1300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118553,	
2017-06-23 23:46:12,541 Epoch[17] Batch [1310]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.118484,	
2017-06-23 23:46:17,712 Epoch[17] Batch [1320]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.118406,	
2017-06-23 23:46:22,797 Epoch[17] Batch [1330]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.118664,	
2017-06-23 23:46:27,880 Epoch[17] Batch [1340]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.118747,	
2017-06-23 23:46:32,912 Epoch[17] Batch [1350]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.118747,	
2017-06-23 23:46:37,403 Epoch[17] Batch [1360]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.118732,	
2017-06-23 23:46:42,015 Epoch[17] Batch [1370]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.118668,	
2017-06-23 23:46:46,716 Epoch[17] Batch [1380]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.118585,	
2017-06-23 23:46:51,453 Epoch[17] Batch [1390]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.118531,	
2017-06-23 23:46:56,336 Epoch[17] Batch [1400]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.118522,	
2017-06-23 23:47:01,540 Epoch[17] Batch [1410]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.118405,	
2017-06-23 23:47:06,433 Epoch[17] Batch [1420]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.118399,	
2017-06-23 23:47:11,580 Epoch[17] Batch [1430]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.118318,	
2017-06-23 23:47:16,366 Epoch[17] Batch [1440]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.118268,	
2017-06-23 23:47:21,201 Epoch[17] Batch [1450]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.118267,	
2017-06-23 23:47:26,155 Epoch[17] Batch [1460]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.118462,	
2017-06-23 23:47:31,121 Epoch[17] Batch [1470]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.118523,	
2017-06-23 23:47:35,926 Epoch[17] Batch [1480]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.118517,	
2017-06-23 23:47:38,932 Epoch[17] Train-FCNLogLoss=0.118530
2017-06-23 23:47:38,933 Epoch[17] Time cost=766.598
2017-06-23 23:47:39,738 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0018.params"
2017-06-23 23:47:41,369 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0018.states"
2017-06-23 23:47:47,077 Epoch[18] Batch [10]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.103484,	
2017-06-23 23:47:52,319 Epoch[18] Batch [20]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.108214,	
2017-06-23 23:47:57,530 Epoch[18] Batch [30]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.110063,	
2017-06-23 23:48:02,881 Epoch[18] Batch [40]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.112241,	
2017-06-23 23:48:08,425 Epoch[18] Batch [50]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.112967,	
2017-06-23 23:48:13,695 Epoch[18] Batch [60]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113114,	
2017-06-23 23:48:18,968 Epoch[18] Batch [70]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113858,	
2017-06-23 23:48:23,997 Epoch[18] Batch [80]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.115419,	
2017-06-23 23:48:29,450 Epoch[18] Batch [90]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.116999,	
2017-06-23 23:48:34,345 Epoch[18] Batch [100]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.115710,	
2017-06-23 23:48:39,201 Epoch[18] Batch [110]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.115156,	
2017-06-23 23:48:44,201 Epoch[18] Batch [120]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.114553,	
2017-06-23 23:48:49,173 Epoch[18] Batch [130]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.114495,	
2017-06-23 23:48:53,838 Epoch[18] Batch [140]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.113916,	
2017-06-23 23:48:58,847 Epoch[18] Batch [150]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.114566,	
2017-06-23 23:49:03,618 Epoch[18] Batch [160]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.115230,	
2017-06-23 23:49:08,715 Epoch[18] Batch [170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.115285,	
2017-06-23 23:49:13,775 Epoch[18] Batch [180]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.114453,	
2017-06-23 23:49:18,560 Epoch[18] Batch [190]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.114501,	
2017-06-23 23:49:23,312 Epoch[18] Batch [200]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.114365,	
2017-06-23 23:49:28,284 Epoch[18] Batch [210]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.114422,	
2017-06-23 23:49:33,000 Epoch[18] Batch [220]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.114404,	
2017-06-23 23:49:38,274 Epoch[18] Batch [230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.114169,	
2017-06-23 23:49:43,206 Epoch[18] Batch [240]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.114090,	
2017-06-23 23:49:48,060 Epoch[18] Batch [250]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.113923,	
2017-06-23 23:49:52,975 Epoch[18] Batch [260]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.113625,	
2017-06-23 23:49:57,936 Epoch[18] Batch [270]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.113853,	
2017-06-23 23:50:02,645 Epoch[18] Batch [280]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.113999,	
2017-06-23 23:50:07,671 Epoch[18] Batch [290]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.114272,	
2017-06-23 23:50:12,852 Epoch[18] Batch [300]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.114112,	
2017-06-23 23:50:18,182 Epoch[18] Batch [310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.114001,	
2017-06-23 23:50:23,171 Epoch[18] Batch [320]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.113392,	
2017-06-23 23:50:28,320 Epoch[18] Batch [330]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.113314,	
2017-06-23 23:50:33,239 Epoch[18] Batch [340]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.113333,	
2017-06-23 23:50:38,645 Epoch[18] Batch [350]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.113090,	
2017-06-23 23:50:43,836 Epoch[18] Batch [360]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.113036,	
2017-06-23 23:50:48,869 Epoch[18] Batch [370]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.113122,	
2017-06-23 23:50:54,056 Epoch[18] Batch [380]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.113181,	
2017-06-23 23:50:59,194 Epoch[18] Batch [390]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.113198,	
2017-06-23 23:51:04,195 Epoch[18] Batch [400]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.113242,	
2017-06-23 23:51:09,403 Epoch[18] Batch [410]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.113354,	
2017-06-23 23:51:14,285 Epoch[18] Batch [420]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.113357,	
2017-06-23 23:51:19,531 Epoch[18] Batch [430]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.113440,	
2017-06-23 23:51:24,275 Epoch[18] Batch [440]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.113349,	
2017-06-23 23:51:29,204 Epoch[18] Batch [450]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.112964,	
2017-06-23 23:51:34,417 Epoch[18] Batch [460]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112915,	
2017-06-23 23:51:39,309 Epoch[18] Batch [470]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.113021,	
2017-06-23 23:51:44,208 Epoch[18] Batch [480]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.113052,	
2017-06-23 23:51:49,220 Epoch[18] Batch [490]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.113225,	
2017-06-23 23:51:54,393 Epoch[18] Batch [500]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.113293,	
2017-06-23 23:51:59,549 Epoch[18] Batch [510]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.113023,	
2017-06-23 23:52:04,632 Epoch[18] Batch [520]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.113012,	
2017-06-23 23:52:09,679 Epoch[18] Batch [530]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.112837,	
2017-06-23 23:52:14,766 Epoch[18] Batch [540]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.112888,	
2017-06-23 23:52:19,827 Epoch[18] Batch [550]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.112724,	
2017-06-23 23:52:24,877 Epoch[18] Batch [560]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.112508,	
2017-06-23 23:52:30,013 Epoch[18] Batch [570]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.112281,	
2017-06-23 23:52:34,961 Epoch[18] Batch [580]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.112281,	
2017-06-23 23:52:40,067 Epoch[18] Batch [590]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.112131,	
2017-06-23 23:52:45,196 Epoch[18] Batch [600]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.112060,	
2017-06-23 23:52:50,408 Epoch[18] Batch [610]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.112049,	
2017-06-23 23:52:55,567 Epoch[18] Batch [620]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.112050,	
2017-06-23 23:53:00,756 Epoch[18] Batch [630]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112305,	
2017-06-23 23:53:05,947 Epoch[18] Batch [640]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112224,	
2017-06-23 23:53:10,927 Epoch[18] Batch [650]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.112245,	
2017-06-23 23:53:15,851 Epoch[18] Batch [660]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.112101,	
2017-06-23 23:53:21,027 Epoch[18] Batch [670]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.112186,	
2017-06-23 23:53:26,214 Epoch[18] Batch [680]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112150,	
2017-06-23 23:53:31,433 Epoch[18] Batch [690]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112172,	
2017-06-23 23:53:36,635 Epoch[18] Batch [700]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112148,	
2017-06-23 23:53:41,786 Epoch[18] Batch [710]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.112244,	
2017-06-23 23:53:46,759 Epoch[18] Batch [720]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.112305,	
2017-06-23 23:53:51,726 Epoch[18] Batch [730]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.112295,	
2017-06-23 23:53:56,882 Epoch[18] Batch [740]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.112033,	
2017-06-23 23:54:01,837 Epoch[18] Batch [750]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.111945,	
2017-06-23 23:54:06,897 Epoch[18] Batch [760]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.111857,	
2017-06-23 23:54:12,030 Epoch[18] Batch [770]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.111911,	
2017-06-23 23:54:16,797 Epoch[18] Batch [780]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.111978,	
2017-06-23 23:54:21,938 Epoch[18] Batch [790]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.112161,	
2017-06-23 23:54:27,193 Epoch[18] Batch [800]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112276,	
2017-06-23 23:54:32,107 Epoch[18] Batch [810]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.112275,	
2017-06-23 23:54:37,215 Epoch[18] Batch [820]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.112387,	
2017-06-23 23:54:42,174 Epoch[18] Batch [830]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.112435,	
2017-06-23 23:54:47,370 Epoch[18] Batch [840]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112411,	
2017-06-23 23:54:52,507 Epoch[18] Batch [850]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.112339,	
2017-06-23 23:54:57,770 Epoch[18] Batch [860]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112378,	
2017-06-23 23:55:02,993 Epoch[18] Batch [870]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112436,	
2017-06-23 23:55:07,762 Epoch[18] Batch [880]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.112382,	
2017-06-23 23:55:12,459 Epoch[18] Batch [890]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.112273,	
2017-06-23 23:55:17,574 Epoch[18] Batch [900]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.112291,	
2017-06-23 23:55:22,792 Epoch[18] Batch [910]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112271,	
2017-06-23 23:55:27,960 Epoch[18] Batch [920]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.112267,	
2017-06-23 23:55:33,150 Epoch[18] Batch [930]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112265,	
2017-06-23 23:55:38,419 Epoch[18] Batch [940]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112265,	
2017-06-23 23:55:43,642 Epoch[18] Batch [950]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112404,	
2017-06-23 23:55:48,396 Epoch[18] Batch [960]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.112266,	
2017-06-23 23:55:53,335 Epoch[18] Batch [970]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.112222,	
2017-06-23 23:55:58,550 Epoch[18] Batch [980]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112436,	
2017-06-23 23:56:03,816 Epoch[18] Batch [990]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112392,	
2017-06-23 23:56:08,663 Epoch[18] Batch [1000]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.112374,	
2017-06-23 23:56:13,875 Epoch[18] Batch [1010]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112334,	
2017-06-23 23:56:18,974 Epoch[18] Batch [1020]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.112323,	
2017-06-23 23:56:24,224 Epoch[18] Batch [1030]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112227,	
2017-06-23 23:56:29,412 Epoch[18] Batch [1040]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112257,	
2017-06-23 23:56:34,426 Epoch[18] Batch [1050]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.112163,	
2017-06-23 23:56:39,113 Epoch[18] Batch [1060]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.112124,	
2017-06-23 23:56:44,100 Epoch[18] Batch [1070]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.112184,	
2017-06-23 23:56:49,325 Epoch[18] Batch [1080]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112270,	
2017-06-23 23:56:54,482 Epoch[18] Batch [1090]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112355,	
2017-06-23 23:56:59,459 Epoch[18] Batch [1100]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.112434,	
2017-06-23 23:57:04,649 Epoch[18] Batch [1110]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112344,	
2017-06-23 23:57:09,876 Epoch[18] Batch [1120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112329,	
2017-06-23 23:57:15,130 Epoch[18] Batch [1130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112425,	
2017-06-23 23:57:20,022 Epoch[18] Batch [1140]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.112356,	
2017-06-23 23:57:24,646 Epoch[18] Batch [1150]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112289,	
2017-06-23 23:57:29,338 Epoch[18] Batch [1160]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.112280,	
2017-06-23 23:57:34,475 Epoch[18] Batch [1170]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.112200,	
2017-06-23 23:57:39,675 Epoch[18] Batch [1180]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112403,	
2017-06-23 23:57:44,841 Epoch[18] Batch [1190]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.112453,	
2017-06-23 23:57:50,045 Epoch[18] Batch [1200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112525,	
2017-06-23 23:57:55,301 Epoch[18] Batch [1210]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112423,	
2017-06-23 23:58:00,300 Epoch[18] Batch [1220]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.112377,	
2017-06-23 23:58:05,284 Epoch[18] Batch [1230]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.112407,	
2017-06-23 23:58:10,190 Epoch[18] Batch [1240]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.112524,	
2017-06-23 23:58:15,335 Epoch[18] Batch [1250]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.112467,	
2017-06-23 23:58:20,337 Epoch[18] Batch [1260]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.112451,	
2017-06-23 23:58:25,535 Epoch[18] Batch [1270]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112452,	
2017-06-23 23:58:30,267 Epoch[18] Batch [1280]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.112437,	
2017-06-23 23:58:35,334 Epoch[18] Batch [1290]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.112437,	
2017-06-23 23:58:40,073 Epoch[18] Batch [1300]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.112411,	
2017-06-23 23:58:45,094 Epoch[18] Batch [1310]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.112309,	
2017-06-23 23:58:49,768 Epoch[18] Batch [1320]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.112281,	
2017-06-23 23:58:54,474 Epoch[18] Batch [1330]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.112264,	
2017-06-23 23:58:59,570 Epoch[18] Batch [1340]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.112312,	
2017-06-23 23:59:04,512 Epoch[18] Batch [1350]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.112353,	
2017-06-23 23:59:09,668 Epoch[18] Batch [1360]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112397,	
2017-06-23 23:59:14,783 Epoch[18] Batch [1370]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.112626,	
2017-06-23 23:59:19,852 Epoch[18] Batch [1380]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.112673,	
2017-06-23 23:59:24,864 Epoch[18] Batch [1390]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.112718,	
2017-06-23 23:59:30,041 Epoch[18] Batch [1400]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.112849,	
2017-06-23 23:59:35,058 Epoch[18] Batch [1410]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.112912,	
2017-06-23 23:59:40,226 Epoch[18] Batch [1420]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.113014,	
2017-06-23 23:59:45,223 Epoch[18] Batch [1430]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.113126,	
2017-06-23 23:59:50,406 Epoch[18] Batch [1440]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.113137,	
2017-06-23 23:59:55,608 Epoch[18] Batch [1450]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.113407,	
2017-06-24 00:00:00,754 Epoch[18] Batch [1460]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.113446,	
2017-06-24 00:00:06,046 Epoch[18] Batch [1470]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.113455,	
2017-06-24 00:00:11,091 Epoch[18] Batch [1480]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.113542,	
2017-06-24 00:00:13,985 Epoch[18] Train-FCNLogLoss=0.113545
2017-06-24 00:00:13,985 Epoch[18] Time cost=752.616
2017-06-24 00:00:14,821 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0019.params"
2017-06-24 00:00:16,527 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0019.states"
2017-06-24 00:00:22,445 Epoch[19] Batch [10]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.099976,	
2017-06-24 00:00:27,479 Epoch[19] Batch [20]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.099710,	
2017-06-24 00:00:32,756 Epoch[19] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.102068,	
2017-06-24 00:00:37,853 Epoch[19] Batch [40]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.101467,	
2017-06-24 00:00:43,249 Epoch[19] Batch [50]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.106022,	
2017-06-24 00:00:48,490 Epoch[19] Batch [60]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.107986,	
2017-06-24 00:00:53,680 Epoch[19] Batch [70]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.111534,	
2017-06-24 00:00:58,729 Epoch[19] Batch [80]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.110673,	
2017-06-24 00:01:03,918 Epoch[19] Batch [90]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.110378,	
2017-06-24 00:01:09,136 Epoch[19] Batch [100]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.109246,	
2017-06-24 00:01:14,265 Epoch[19] Batch [110]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.109805,	
2017-06-24 00:01:19,569 Epoch[19] Batch [120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.109298,	
2017-06-24 00:01:24,767 Epoch[19] Batch [130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.109083,	
2017-06-24 00:01:29,927 Epoch[19] Batch [140]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.108590,	
2017-06-24 00:01:35,132 Epoch[19] Batch [150]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108689,	
2017-06-24 00:01:40,388 Epoch[19] Batch [160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.108899,	
2017-06-24 00:01:45,391 Epoch[19] Batch [170]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.109168,	
2017-06-24 00:01:50,589 Epoch[19] Batch [180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.109066,	
2017-06-24 00:01:55,745 Epoch[19] Batch [190]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.108752,	
2017-06-24 00:02:00,986 Epoch[19] Batch [200]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.110220,	
2017-06-24 00:02:06,171 Epoch[19] Batch [210]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.110562,	
2017-06-24 00:02:11,302 Epoch[19] Batch [220]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.110984,	
2017-06-24 00:02:16,577 Epoch[19] Batch [230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111379,	
2017-06-24 00:02:21,681 Epoch[19] Batch [240]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.111248,	
2017-06-24 00:02:26,947 Epoch[19] Batch [250]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111290,	
2017-06-24 00:02:32,142 Epoch[19] Batch [260]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.111541,	
2017-06-24 00:02:37,195 Epoch[19] Batch [270]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.111673,	
2017-06-24 00:02:42,192 Epoch[19] Batch [280]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.111375,	
2017-06-24 00:02:46,995 Epoch[19] Batch [290]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.111624,	
2017-06-24 00:02:52,192 Epoch[19] Batch [300]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.111755,	
2017-06-24 00:02:57,275 Epoch[19] Batch [310]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.111844,	
2017-06-24 00:03:02,557 Epoch[19] Batch [320]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111529,	
2017-06-24 00:03:07,741 Epoch[19] Batch [330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111496,	
2017-06-24 00:03:12,867 Epoch[19] Batch [340]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.111507,	
2017-06-24 00:03:18,043 Epoch[19] Batch [350]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.111477,	
2017-06-24 00:03:23,252 Epoch[19] Batch [360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111500,	
2017-06-24 00:03:28,458 Epoch[19] Batch [370]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111414,	
2017-06-24 00:03:33,688 Epoch[19] Batch [380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111538,	
2017-06-24 00:03:38,757 Epoch[19] Batch [390]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.111693,	
2017-06-24 00:03:43,584 Epoch[19] Batch [400]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.112017,	
2017-06-24 00:03:48,607 Epoch[19] Batch [410]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.111882,	
2017-06-24 00:03:53,689 Epoch[19] Batch [420]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.111999,	
2017-06-24 00:03:58,906 Epoch[19] Batch [430]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111626,	
2017-06-24 00:04:04,150 Epoch[19] Batch [440]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111914,	
2017-06-24 00:04:09,358 Epoch[19] Batch [450]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111931,	
2017-06-24 00:04:14,506 Epoch[19] Batch [460]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.111822,	
2017-06-24 00:04:19,756 Epoch[19] Batch [470]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111888,	
2017-06-24 00:04:24,948 Epoch[19] Batch [480]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.111866,	
2017-06-24 00:04:30,129 Epoch[19] Batch [490]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111656,	
2017-06-24 00:04:35,348 Epoch[19] Batch [500]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111731,	
2017-06-24 00:04:40,541 Epoch[19] Batch [510]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.111698,	
2017-06-24 00:04:45,580 Epoch[19] Batch [520]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.111673,	
2017-06-24 00:04:50,675 Epoch[19] Batch [530]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.111666,	
2017-06-24 00:04:55,902 Epoch[19] Batch [540]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111678,	
2017-06-24 00:05:01,085 Epoch[19] Batch [550]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111830,	
2017-06-24 00:05:05,880 Epoch[19] Batch [560]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.111815,	
2017-06-24 00:05:11,220 Epoch[19] Batch [570]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.111972,	
2017-06-24 00:05:15,870 Epoch[19] Batch [580]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.112059,	
2017-06-24 00:05:21,057 Epoch[19] Batch [590]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112031,	
2017-06-24 00:05:26,303 Epoch[19] Batch [600]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111769,	
2017-06-24 00:05:31,483 Epoch[19] Batch [610]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111514,	
2017-06-24 00:05:36,652 Epoch[19] Batch [620]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.111522,	
2017-06-24 00:05:41,850 Epoch[19] Batch [630]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.111425,	
2017-06-24 00:05:47,066 Epoch[19] Batch [640]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111707,	
2017-06-24 00:05:52,325 Epoch[19] Batch [650]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111874,	
2017-06-24 00:05:57,459 Epoch[19] Batch [660]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.111876,	
2017-06-24 00:06:02,662 Epoch[19] Batch [670]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.111867,	
2017-06-24 00:06:07,870 Epoch[19] Batch [680]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.112015,	
2017-06-24 00:06:13,074 Epoch[19] Batch [690]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112227,	
2017-06-24 00:06:18,229 Epoch[19] Batch [700]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112195,	
2017-06-24 00:06:23,031 Epoch[19] Batch [710]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.112414,	
2017-06-24 00:06:28,178 Epoch[19] Batch [720]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.112393,	
2017-06-24 00:06:33,376 Epoch[19] Batch [730]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112526,	
2017-06-24 00:06:38,534 Epoch[19] Batch [740]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112413,	
2017-06-24 00:06:43,365 Epoch[19] Batch [750]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.112341,	
2017-06-24 00:06:48,548 Epoch[19] Batch [760]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.112354,	
2017-06-24 00:06:53,639 Epoch[19] Batch [770]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.112251,	
2017-06-24 00:06:58,413 Epoch[19] Batch [780]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.112405,	
2017-06-24 00:07:03,539 Epoch[19] Batch [790]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.112393,	
2017-06-24 00:07:08,731 Epoch[19] Batch [800]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112342,	
2017-06-24 00:07:13,948 Epoch[19] Batch [810]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112473,	
2017-06-24 00:07:19,136 Epoch[19] Batch [820]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112444,	
2017-06-24 00:07:24,291 Epoch[19] Batch [830]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112478,	
2017-06-24 00:07:29,525 Epoch[19] Batch [840]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112429,	
2017-06-24 00:07:34,732 Epoch[19] Batch [850]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.112479,	
2017-06-24 00:07:39,905 Epoch[19] Batch [860]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.112597,	
2017-06-24 00:07:45,131 Epoch[19] Batch [870]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112641,	
2017-06-24 00:07:50,345 Epoch[19] Batch [880]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112582,	
2017-06-24 00:07:55,507 Epoch[19] Batch [890]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.112484,	
2017-06-24 00:08:00,734 Epoch[19] Batch [900]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112404,	
2017-06-24 00:08:05,994 Epoch[19] Batch [910]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112412,	
2017-06-24 00:08:11,213 Epoch[19] Batch [920]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112370,	
2017-06-24 00:08:16,381 Epoch[19] Batch [930]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.112413,	
2017-06-24 00:08:21,572 Epoch[19] Batch [940]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112465,	
2017-06-24 00:08:26,562 Epoch[19] Batch [950]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.112540,	
2017-06-24 00:08:31,720 Epoch[19] Batch [960]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.112517,	
2017-06-24 00:08:36,919 Epoch[19] Batch [970]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112597,	
2017-06-24 00:08:42,053 Epoch[19] Batch [980]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.112542,	
2017-06-24 00:08:47,288 Epoch[19] Batch [990]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112393,	
2017-06-24 00:08:52,492 Epoch[19] Batch [1000]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112453,	
2017-06-24 00:08:57,698 Epoch[19] Batch [1010]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.112283,	
2017-06-24 00:09:02,844 Epoch[19] Batch [1020]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.112259,	
2017-06-24 00:09:07,838 Epoch[19] Batch [1030]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.112161,	
2017-06-24 00:09:12,957 Epoch[19] Batch [1040]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.112242,	
2017-06-24 00:09:17,691 Epoch[19] Batch [1050]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.112214,	
2017-06-24 00:09:22,667 Epoch[19] Batch [1060]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.112151,	
2017-06-24 00:09:28,200 Epoch[19] Batch [1070]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.112238,	
2017-06-24 00:09:33,624 Epoch[19] Batch [1080]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.112224,	
2017-06-24 00:09:38,694 Epoch[19] Batch [1090]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.112157,	
2017-06-24 00:09:43,888 Epoch[19] Batch [1100]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112179,	
2017-06-24 00:09:49,057 Epoch[19] Batch [1110]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.112204,	
2017-06-24 00:09:53,972 Epoch[19] Batch [1120]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.112191,	
2017-06-24 00:09:58,964 Epoch[19] Batch [1130]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.112138,	
2017-06-24 00:10:04,383 Epoch[19] Batch [1140]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.112082,	
2017-06-24 00:10:09,567 Epoch[19] Batch [1150]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111946,	
2017-06-24 00:10:15,501 Epoch[19] Batch [1160]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.111884,	
2017-06-24 00:10:20,356 Epoch[19] Batch [1170]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.111831,	
2017-06-24 00:10:26,009 Epoch[19] Batch [1180]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.111899,	
2017-06-24 00:10:31,042 Epoch[19] Batch [1190]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.111932,	
2017-06-24 00:10:35,999 Epoch[19] Batch [1200]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.111959,	
2017-06-24 00:10:40,899 Epoch[19] Batch [1210]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.111946,	
2017-06-24 00:10:46,127 Epoch[19] Batch [1220]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111979,	
2017-06-24 00:10:51,296 Epoch[19] Batch [1230]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.112026,	
2017-06-24 00:10:56,312 Epoch[19] Batch [1240]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.112057,	
2017-06-24 00:11:01,358 Epoch[19] Batch [1250]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.112087,	
2017-06-24 00:11:06,877 Epoch[19] Batch [1260]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.112036,	
2017-06-24 00:11:11,799 Epoch[19] Batch [1270]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.111976,	
2017-06-24 00:11:17,129 Epoch[19] Batch [1280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.111840,	
2017-06-24 00:11:21,989 Epoch[19] Batch [1290]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.111891,	
2017-06-24 00:11:27,778 Epoch[19] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111847,	
2017-06-24 00:11:32,833 Epoch[19] Batch [1310]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.111870,	
2017-06-24 00:11:37,663 Epoch[19] Batch [1320]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.111937,	
2017-06-24 00:11:43,033 Epoch[19] Batch [1330]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.112044,	
2017-06-24 00:11:47,803 Epoch[19] Batch [1340]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.112050,	
2017-06-24 00:11:52,940 Epoch[19] Batch [1350]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.112078,	
2017-06-24 00:11:58,110 Epoch[19] Batch [1360]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.111996,	
2017-06-24 00:12:03,210 Epoch[19] Batch [1370]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.112025,	
2017-06-24 00:12:08,405 Epoch[19] Batch [1380]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112067,	
2017-06-24 00:12:13,737 Epoch[19] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.112121,	
2017-06-24 00:12:18,792 Epoch[19] Batch [1400]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.112145,	
2017-06-24 00:12:23,768 Epoch[19] Batch [1410]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.112239,	
2017-06-24 00:12:28,839 Epoch[19] Batch [1420]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.112328,	
2017-06-24 00:12:33,836 Epoch[19] Batch [1430]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.112323,	
2017-06-24 00:12:38,889 Epoch[19] Batch [1440]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.112267,	
2017-06-24 00:12:43,951 Epoch[19] Batch [1450]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.112330,	
2017-06-24 00:12:48,869 Epoch[19] Batch [1460]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.112313,	
2017-06-24 00:12:53,727 Epoch[19] Batch [1470]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.112404,	
2017-06-24 00:12:58,916 Epoch[19] Batch [1480]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112417,	
2017-06-24 00:13:02,103 Epoch[19] Train-FCNLogLoss=0.112484
2017-06-24 00:13:02,103 Epoch[19] Time cost=765.575
2017-06-24 00:13:03,120 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0020.params"
2017-06-24 00:13:04,681 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0020.states"
2017-06-24 00:13:10,796 Epoch[20] Batch [10]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142444,	
2017-06-24 00:13:16,258 Epoch[20] Batch [20]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.129053,	
2017-06-24 00:13:21,017 Epoch[20] Batch [30]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.121384,	
2017-06-24 00:13:26,407 Epoch[20] Batch [40]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.116448,	
2017-06-24 00:13:31,152 Epoch[20] Batch [50]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.114356,	
2017-06-24 00:13:36,104 Epoch[20] Batch [60]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.115359,	
2017-06-24 00:13:41,233 Epoch[20] Batch [70]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.114551,	
2017-06-24 00:13:46,106 Epoch[20] Batch [80]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.115956,	
2017-06-24 00:13:51,255 Epoch[20] Batch [90]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.126223,	
2017-06-24 00:13:56,517 Epoch[20] Batch [100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.136661,	
2017-06-24 00:14:01,702 Epoch[20] Batch [110]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.148347,	
2017-06-24 00:14:06,677 Epoch[20] Batch [120]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.154550,	
2017-06-24 00:14:11,607 Epoch[20] Batch [130]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.156868,	
2017-06-24 00:14:16,645 Epoch[20] Batch [140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.155646,	
2017-06-24 00:14:21,567 Epoch[20] Batch [150]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.152910,	
2017-06-24 00:14:26,729 Epoch[20] Batch [160]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.151641,	
2017-06-24 00:14:31,967 Epoch[20] Batch [170]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.149847,	
2017-06-24 00:14:36,914 Epoch[20] Batch [180]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.148172,	
2017-06-24 00:14:41,927 Epoch[20] Batch [190]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.146919,	
2017-06-24 00:14:46,924 Epoch[20] Batch [200]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.147340,	
2017-06-24 00:14:51,920 Epoch[20] Batch [210]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.147451,	
2017-06-24 00:14:57,245 Epoch[20] Batch [220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.145724,	
2017-06-24 00:15:02,209 Epoch[20] Batch [230]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.145149,	
2017-06-24 00:15:07,102 Epoch[20] Batch [240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.144000,	
2017-06-24 00:15:12,193 Epoch[20] Batch [250]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.143626,	
2017-06-24 00:15:17,260 Epoch[20] Batch [260]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.142523,	
2017-06-24 00:15:22,392 Epoch[20] Batch [270]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.142206,	
2017-06-24 00:15:27,516 Epoch[20] Batch [280]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.141389,	
2017-06-24 00:15:32,772 Epoch[20] Batch [290]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.140246,	
2017-06-24 00:15:37,909 Epoch[20] Batch [300]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.140053,	
2017-06-24 00:15:43,120 Epoch[20] Batch [310]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.139255,	
2017-06-24 00:15:48,324 Epoch[20] Batch [320]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.138232,	
2017-06-24 00:15:53,375 Epoch[20] Batch [330]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.137574,	
2017-06-24 00:15:58,266 Epoch[20] Batch [340]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.136660,	
2017-06-24 00:16:03,442 Epoch[20] Batch [350]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.136516,	
2017-06-24 00:16:08,398 Epoch[20] Batch [360]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.136355,	
2017-06-24 00:16:13,555 Epoch[20] Batch [370]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.136605,	
2017-06-24 00:16:18,448 Epoch[20] Batch [380]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.136413,	
2017-06-24 00:16:23,169 Epoch[20] Batch [390]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.135768,	
2017-06-24 00:16:28,032 Epoch[20] Batch [400]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.135258,	
2017-06-24 00:16:33,079 Epoch[20] Batch [410]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.134911,	
2017-06-24 00:16:38,024 Epoch[20] Batch [420]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.134583,	
2017-06-24 00:16:42,989 Epoch[20] Batch [430]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.134386,	
2017-06-24 00:16:47,892 Epoch[20] Batch [440]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.134045,	
2017-06-24 00:16:53,116 Epoch[20] Batch [450]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.133645,	
2017-06-24 00:16:58,265 Epoch[20] Batch [460]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.133282,	
2017-06-24 00:17:03,469 Epoch[20] Batch [470]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.132714,	
2017-06-24 00:17:08,204 Epoch[20] Batch [480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.132243,	
2017-06-24 00:17:12,679 Epoch[20] Batch [490]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.131751,	
2017-06-24 00:17:17,608 Epoch[20] Batch [500]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.132451,	
2017-06-24 00:17:22,770 Epoch[20] Batch [510]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.132779,	
2017-06-24 00:17:28,013 Epoch[20] Batch [520]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.133542,	
2017-06-24 00:17:32,754 Epoch[20] Batch [530]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.133794,	
2017-06-24 00:17:37,665 Epoch[20] Batch [540]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.133590,	
2017-06-24 00:17:42,875 Epoch[20] Batch [550]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.133481,	
2017-06-24 00:17:47,924 Epoch[20] Batch [560]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.133226,	
2017-06-24 00:17:53,050 Epoch[20] Batch [570]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.133030,	
2017-06-24 00:17:58,222 Epoch[20] Batch [580]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.132947,	
2017-06-24 00:18:03,259 Epoch[20] Batch [590]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.132603,	
2017-06-24 00:18:08,478 Epoch[20] Batch [600]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.132510,	
2017-06-24 00:18:13,611 Epoch[20] Batch [610]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.132390,	
2017-06-24 00:18:18,861 Epoch[20] Batch [620]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.132234,	
2017-06-24 00:18:23,916 Epoch[20] Batch [630]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.131819,	
2017-06-24 00:18:29,105 Epoch[20] Batch [640]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.131778,	
2017-06-24 00:18:34,333 Epoch[20] Batch [650]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.131334,	
2017-06-24 00:18:39,349 Epoch[20] Batch [660]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.131079,	
2017-06-24 00:18:44,301 Epoch[20] Batch [670]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.130964,	
2017-06-24 00:18:49,761 Epoch[20] Batch [680]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.130695,	
2017-06-24 00:18:54,502 Epoch[20] Batch [690]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.130585,	
2017-06-24 00:18:59,619 Epoch[20] Batch [700]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.130502,	
2017-06-24 00:19:04,813 Epoch[20] Batch [710]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.130515,	
2017-06-24 00:19:10,018 Epoch[20] Batch [720]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.130215,	
2017-06-24 00:19:14,911 Epoch[20] Batch [730]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.130074,	
2017-06-24 00:19:19,394 Epoch[20] Batch [740]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.129943,	
2017-06-24 00:19:24,223 Epoch[20] Batch [750]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.129857,	
2017-06-24 00:19:28,738 Epoch[20] Batch [760]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.129771,	
2017-06-24 00:19:33,726 Epoch[20] Batch [770]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.129660,	
2017-06-24 00:19:38,713 Epoch[20] Batch [780]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.129677,	
2017-06-24 00:19:43,573 Epoch[20] Batch [790]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.129544,	
2017-06-24 00:19:48,403 Epoch[20] Batch [800]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.129529,	
2017-06-24 00:19:53,257 Epoch[20] Batch [810]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.129352,	
2017-06-24 00:19:58,121 Epoch[20] Batch [820]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.129610,	
2017-06-24 00:20:03,240 Epoch[20] Batch [830]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.130223,	
2017-06-24 00:20:07,995 Epoch[20] Batch [840]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.130342,	
2017-06-24 00:20:12,943 Epoch[20] Batch [850]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.130411,	
2017-06-24 00:20:17,995 Epoch[20] Batch [860]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.130452,	
2017-06-24 00:20:22,829 Epoch[20] Batch [870]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.130406,	
2017-06-24 00:20:27,383 Epoch[20] Batch [880]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.130176,	
2017-06-24 00:20:32,116 Epoch[20] Batch [890]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.130005,	
2017-06-24 00:20:36,905 Epoch[20] Batch [900]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.129659,	
2017-06-24 00:20:41,499 Epoch[20] Batch [910]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.129594,	
2017-06-24 00:20:46,234 Epoch[20] Batch [920]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.129529,	
2017-06-24 00:20:51,276 Epoch[20] Batch [930]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.129311,	
2017-06-24 00:20:56,653 Epoch[20] Batch [940]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.129098,	
2017-06-24 00:21:01,956 Epoch[20] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.128987,	
2017-06-24 00:21:06,782 Epoch[20] Batch [960]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.128844,	
2017-06-24 00:21:12,081 Epoch[20] Batch [970]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.128697,	
2017-06-24 00:21:17,522 Epoch[20] Batch [980]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.128562,	
2017-06-24 00:21:23,183 Epoch[20] Batch [990]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.128646,	
2017-06-24 00:21:27,961 Epoch[20] Batch [1000]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.128734,	
2017-06-24 00:21:33,483 Epoch[20] Batch [1010]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128778,	
2017-06-24 00:21:38,777 Epoch[20] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.128629,	
2017-06-24 00:21:43,782 Epoch[20] Batch [1030]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.128608,	
2017-06-24 00:21:49,176 Epoch[20] Batch [1040]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.128465,	
2017-06-24 00:21:54,423 Epoch[20] Batch [1050]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.128491,	
2017-06-24 00:21:59,530 Epoch[20] Batch [1060]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.128464,	
2017-06-24 00:22:05,532 Epoch[20] Batch [1070]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.128349,	
2017-06-24 00:22:10,856 Epoch[20] Batch [1080]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.128281,	
2017-06-24 00:22:15,627 Epoch[20] Batch [1090]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.128100,	
2017-06-24 00:22:21,211 Epoch[20] Batch [1100]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.127954,	
2017-06-24 00:22:26,352 Epoch[20] Batch [1110]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.127940,	
2017-06-24 00:22:31,656 Epoch[20] Batch [1120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.127725,	
2017-06-24 00:22:36,851 Epoch[20] Batch [1130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.127650,	
2017-06-24 00:22:41,727 Epoch[20] Batch [1140]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.127529,	
2017-06-24 00:22:47,002 Epoch[20] Batch [1150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.127276,	
2017-06-24 00:22:51,746 Epoch[20] Batch [1160]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.127133,	
2017-06-24 00:22:56,544 Epoch[20] Batch [1170]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.127003,	
2017-06-24 00:23:01,661 Epoch[20] Batch [1180]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.126869,	
2017-06-24 00:23:07,024 Epoch[20] Batch [1190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.126897,	
2017-06-24 00:23:12,101 Epoch[20] Batch [1200]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.126782,	
2017-06-24 00:23:17,468 Epoch[20] Batch [1210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126728,	
2017-06-24 00:23:22,717 Epoch[20] Batch [1220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.126665,	
2017-06-24 00:23:28,070 Epoch[20] Batch [1230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.126595,	
2017-06-24 00:23:33,114 Epoch[20] Batch [1240]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.126606,	
2017-06-24 00:23:38,163 Epoch[20] Batch [1250]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.126414,	
2017-06-24 00:23:43,320 Epoch[20] Batch [1260]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.126377,	
2017-06-24 00:23:48,404 Epoch[20] Batch [1270]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.126274,	
2017-06-24 00:23:53,481 Epoch[20] Batch [1280]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.126130,	
2017-06-24 00:23:58,489 Epoch[20] Batch [1290]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.125998,	
2017-06-24 00:24:03,766 Epoch[20] Batch [1300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125993,	
2017-06-24 00:24:08,607 Epoch[20] Batch [1310]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.125999,	
2017-06-24 00:24:13,782 Epoch[20] Batch [1320]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.125965,	
2017-06-24 00:24:19,175 Epoch[20] Batch [1330]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125937,	
2017-06-24 00:24:23,991 Epoch[20] Batch [1340]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.125897,	
2017-06-24 00:24:28,873 Epoch[20] Batch [1350]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.125801,	
2017-06-24 00:24:34,106 Epoch[20] Batch [1360]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125682,	
2017-06-24 00:24:39,339 Epoch[20] Batch [1370]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125623,	
2017-06-24 00:24:44,377 Epoch[20] Batch [1380]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.125503,	
2017-06-24 00:24:49,550 Epoch[20] Batch [1390]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.125452,	
2017-06-24 00:24:54,554 Epoch[20] Batch [1400]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.125485,	
2017-06-24 00:24:59,558 Epoch[20] Batch [1410]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.125418,	
2017-06-24 00:25:04,794 Epoch[20] Batch [1420]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125358,	
2017-06-24 00:25:10,235 Epoch[20] Batch [1430]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.125350,	
2017-06-24 00:25:15,800 Epoch[20] Batch [1440]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.125305,	
2017-06-24 00:25:20,866 Epoch[20] Batch [1450]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.125105,	
2017-06-24 00:25:26,171 Epoch[20] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125009,	
2017-06-24 00:25:31,204 Epoch[20] Batch [1470]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.124878,	
2017-06-24 00:25:36,029 Epoch[20] Batch [1480]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.124823,	
2017-06-24 00:25:39,063 Epoch[20] Train-FCNLogLoss=0.124761
2017-06-24 00:25:39,063 Epoch[20] Time cost=754.381
2017-06-24 00:25:39,847 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0021.params"
2017-06-24 00:25:41,530 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0021.states"
2017-06-24 00:25:47,355 Epoch[21] Batch [10]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.115574,	
2017-06-24 00:25:52,527 Epoch[21] Batch [20]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.108430,	
2017-06-24 00:25:57,904 Epoch[21] Batch [30]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.108316,	
2017-06-24 00:26:03,100 Epoch[21] Batch [40]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.107267,	
2017-06-24 00:26:07,726 Epoch[21] Batch [50]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.108618,	
2017-06-24 00:26:12,505 Epoch[21] Batch [60]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.109489,	
2017-06-24 00:26:17,321 Epoch[21] Batch [70]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.108405,	
2017-06-24 00:26:22,475 Epoch[21] Batch [80]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.109094,	
2017-06-24 00:26:27,390 Epoch[21] Batch [90]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.107766,	
2017-06-24 00:26:32,497 Epoch[21] Batch [100]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.108164,	
2017-06-24 00:26:37,529 Epoch[21] Batch [110]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.108656,	
2017-06-24 00:26:42,378 Epoch[21] Batch [120]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.108371,	
2017-06-24 00:26:47,619 Epoch[21] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.108472,	
2017-06-24 00:26:52,431 Epoch[21] Batch [140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.107801,	
2017-06-24 00:26:57,232 Epoch[21] Batch [150]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.108218,	
2017-06-24 00:27:02,037 Epoch[21] Batch [160]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.108936,	
2017-06-24 00:27:06,887 Epoch[21] Batch [170]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.109547,	
2017-06-24 00:27:11,783 Epoch[21] Batch [180]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.109818,	
2017-06-24 00:27:16,804 Epoch[21] Batch [190]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.110134,	
2017-06-24 00:27:21,524 Epoch[21] Batch [200]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.110145,	
2017-06-24 00:27:26,104 Epoch[21] Batch [210]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.110690,	
2017-06-24 00:27:30,903 Epoch[21] Batch [220]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.110086,	
2017-06-24 00:27:35,827 Epoch[21] Batch [230]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.110035,	
2017-06-24 00:27:40,742 Epoch[21] Batch [240]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.110484,	
2017-06-24 00:27:45,968 Epoch[21] Batch [250]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.110827,	
2017-06-24 00:27:51,333 Epoch[21] Batch [260]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.111051,	
2017-06-24 00:27:56,325 Epoch[21] Batch [270]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.111029,	
2017-06-24 00:28:01,310 Epoch[21] Batch [280]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.111462,	
2017-06-24 00:28:06,227 Epoch[21] Batch [290]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.110898,	
2017-06-24 00:28:10,971 Epoch[21] Batch [300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.110620,	
2017-06-24 00:28:16,245 Epoch[21] Batch [310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.110458,	
2017-06-24 00:28:20,976 Epoch[21] Batch [320]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.110067,	
2017-06-24 00:28:25,748 Epoch[21] Batch [330]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.110059,	
2017-06-24 00:28:30,700 Epoch[21] Batch [340]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.109914,	
2017-06-24 00:28:35,554 Epoch[21] Batch [350]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.109908,	
2017-06-24 00:28:40,416 Epoch[21] Batch [360]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.109792,	
2017-06-24 00:28:45,537 Epoch[21] Batch [370]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.109888,	
2017-06-24 00:28:50,526 Epoch[21] Batch [380]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.109910,	
2017-06-24 00:28:55,759 Epoch[21] Batch [390]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.109978,	
2017-06-24 00:29:00,915 Epoch[21] Batch [400]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.110138,	
2017-06-24 00:29:06,066 Epoch[21] Batch [410]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.110398,	
2017-06-24 00:29:10,886 Epoch[21] Batch [420]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.110799,	
2017-06-24 00:29:15,715 Epoch[21] Batch [430]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.111629,	
2017-06-24 00:29:20,818 Epoch[21] Batch [440]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.112185,	
2017-06-24 00:29:25,660 Epoch[21] Batch [450]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.112409,	
2017-06-24 00:29:30,453 Epoch[21] Batch [460]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.112632,	
2017-06-24 00:29:35,259 Epoch[21] Batch [470]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.112811,	
2017-06-24 00:29:40,011 Epoch[21] Batch [480]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.112803,	
2017-06-24 00:29:45,038 Epoch[21] Batch [490]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.112539,	
2017-06-24 00:29:50,034 Epoch[21] Batch [500]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.112588,	
2017-06-24 00:29:54,974 Epoch[21] Batch [510]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.112852,	
2017-06-24 00:30:00,027 Epoch[21] Batch [520]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.112850,	
2017-06-24 00:30:05,237 Epoch[21] Batch [530]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.112868,	
2017-06-24 00:30:10,013 Epoch[21] Batch [540]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.112957,	
2017-06-24 00:30:15,363 Epoch[21] Batch [550]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.112987,	
2017-06-24 00:30:20,228 Epoch[21] Batch [560]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.112944,	
2017-06-24 00:30:24,975 Epoch[21] Batch [570]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.112761,	
2017-06-24 00:30:29,964 Epoch[21] Batch [580]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.112723,	
2017-06-24 00:30:35,255 Epoch[21] Batch [590]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.112876,	
2017-06-24 00:30:40,293 Epoch[21] Batch [600]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.113028,	
2017-06-24 00:30:45,310 Epoch[21] Batch [610]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.113057,	
2017-06-24 00:30:50,240 Epoch[21] Batch [620]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.112991,	
2017-06-24 00:30:54,959 Epoch[21] Batch [630]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.112957,	
2017-06-24 00:30:59,643 Epoch[21] Batch [640]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.112645,	
2017-06-24 00:31:04,548 Epoch[21] Batch [650]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.112734,	
2017-06-24 00:31:09,239 Epoch[21] Batch [660]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.112706,	
2017-06-24 00:31:14,306 Epoch[21] Batch [670]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.112649,	
2017-06-24 00:31:19,308 Epoch[21] Batch [680]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.112776,	
2017-06-24 00:31:24,030 Epoch[21] Batch [690]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.112776,	
2017-06-24 00:31:29,740 Epoch[21] Batch [700]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.112762,	
2017-06-24 00:31:35,139 Epoch[21] Batch [710]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.112711,	
2017-06-24 00:31:40,010 Epoch[21] Batch [720]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.112658,	
2017-06-24 00:31:45,564 Epoch[21] Batch [730]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.112695,	
2017-06-24 00:31:50,582 Epoch[21] Batch [740]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.112646,	
2017-06-24 00:31:55,585 Epoch[21] Batch [750]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.112681,	
2017-06-24 00:32:00,569 Epoch[21] Batch [760]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.112741,	
2017-06-24 00:32:05,619 Epoch[21] Batch [770]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.112616,	
2017-06-24 00:32:10,600 Epoch[21] Batch [780]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.112698,	
2017-06-24 00:32:15,710 Epoch[21] Batch [790]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.112700,	
2017-06-24 00:32:20,882 Epoch[21] Batch [800]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.112710,	
2017-06-24 00:32:26,503 Epoch[21] Batch [810]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.112621,	
2017-06-24 00:32:31,439 Epoch[21] Batch [820]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.112639,	
2017-06-24 00:32:36,312 Epoch[21] Batch [830]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.112635,	
2017-06-24 00:32:41,321 Epoch[21] Batch [840]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.112446,	
2017-06-24 00:32:46,992 Epoch[21] Batch [850]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.112241,	
2017-06-24 00:32:53,182 Epoch[21] Batch [860]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.112226,	
2017-06-24 00:32:58,168 Epoch[21] Batch [870]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.112243,	
2017-06-24 00:33:03,458 Epoch[21] Batch [880]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.112054,	
2017-06-24 00:33:09,062 Epoch[21] Batch [890]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.112121,	
2017-06-24 00:33:14,564 Epoch[21] Batch [900]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.112110,	
2017-06-24 00:33:19,920 Epoch[21] Batch [910]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.112220,	
2017-06-24 00:33:25,229 Epoch[21] Batch [920]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.112271,	
2017-06-24 00:33:30,217 Epoch[21] Batch [930]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.112270,	
2017-06-24 00:33:35,341 Epoch[21] Batch [940]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.112335,	
2017-06-24 00:33:40,161 Epoch[21] Batch [950]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.112290,	
2017-06-24 00:33:45,313 Epoch[21] Batch [960]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.112294,	
2017-06-24 00:33:50,261 Epoch[21] Batch [970]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.112095,	
2017-06-24 00:33:55,780 Epoch[21] Batch [980]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.111927,	
2017-06-24 00:34:00,991 Epoch[21] Batch [990]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111973,	
2017-06-24 00:34:06,240 Epoch[21] Batch [1000]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111997,	
2017-06-24 00:34:10,841 Epoch[21] Batch [1010]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.112050,	
2017-06-24 00:34:15,842 Epoch[21] Batch [1020]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.111893,	
2017-06-24 00:34:21,185 Epoch[21] Batch [1030]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.111937,	
2017-06-24 00:34:26,228 Epoch[21] Batch [1040]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.111915,	
2017-06-24 00:34:31,157 Epoch[21] Batch [1050]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.111768,	
2017-06-24 00:34:36,148 Epoch[21] Batch [1060]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.111800,	
2017-06-24 00:34:41,120 Epoch[21] Batch [1070]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.111781,	
2017-06-24 00:34:46,018 Epoch[21] Batch [1080]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.111721,	
2017-06-24 00:34:51,053 Epoch[21] Batch [1090]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.111706,	
2017-06-24 00:34:56,099 Epoch[21] Batch [1100]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.111628,	
2017-06-24 00:35:01,550 Epoch[21] Batch [1110]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.111580,	
2017-06-24 00:35:07,408 Epoch[21] Batch [1120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.111537,	
2017-06-24 00:35:12,834 Epoch[21] Batch [1130]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.111510,	
2017-06-24 00:35:17,682 Epoch[21] Batch [1140]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.111367,	
2017-06-24 00:35:22,905 Epoch[21] Batch [1150]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111383,	
2017-06-24 00:35:28,369 Epoch[21] Batch [1160]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.111393,	
2017-06-24 00:35:33,800 Epoch[21] Batch [1170]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.111400,	
2017-06-24 00:35:38,825 Epoch[21] Batch [1180]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.111536,	
2017-06-24 00:35:43,724 Epoch[21] Batch [1190]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.111533,	
2017-06-24 00:35:48,855 Epoch[21] Batch [1200]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.111518,	
2017-06-24 00:35:53,680 Epoch[21] Batch [1210]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.111518,	
2017-06-24 00:35:58,682 Epoch[21] Batch [1220]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.111410,	
2017-06-24 00:36:05,025 Epoch[21] Batch [1230]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.111436,	
2017-06-24 00:36:10,298 Epoch[21] Batch [1240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.111275,	
2017-06-24 00:36:15,086 Epoch[21] Batch [1250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.111314,	
2017-06-24 00:36:20,588 Epoch[21] Batch [1260]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.111287,	
2017-06-24 00:36:25,785 Epoch[21] Batch [1270]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.111244,	
2017-06-24 00:36:30,655 Epoch[21] Batch [1280]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.111223,	
2017-06-24 00:36:35,574 Epoch[21] Batch [1290]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.111179,	
2017-06-24 00:36:41,347 Epoch[21] Batch [1300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.111174,	
2017-06-24 00:36:46,384 Epoch[21] Batch [1310]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.111142,	
2017-06-24 00:36:51,832 Epoch[21] Batch [1320]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.111146,	
2017-06-24 00:36:57,504 Epoch[21] Batch [1330]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.111094,	
2017-06-24 00:37:02,778 Epoch[21] Batch [1340]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.110999,	
2017-06-24 00:37:07,925 Epoch[21] Batch [1350]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.111034,	
2017-06-24 00:37:13,323 Epoch[21] Batch [1360]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.111032,	
2017-06-24 00:37:18,437 Epoch[21] Batch [1370]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.110989,	
2017-06-24 00:37:23,600 Epoch[21] Batch [1380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.110999,	
2017-06-24 00:37:28,609 Epoch[21] Batch [1390]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.110966,	
2017-06-24 00:37:33,333 Epoch[21] Batch [1400]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.110994,	
2017-06-24 00:37:38,230 Epoch[21] Batch [1410]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.110909,	
2017-06-24 00:37:43,041 Epoch[21] Batch [1420]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.110835,	
2017-06-24 00:37:48,082 Epoch[21] Batch [1430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.110775,	
2017-06-24 00:37:52,897 Epoch[21] Batch [1440]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.110785,	
2017-06-24 00:37:58,091 Epoch[21] Batch [1450]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.110763,	
2017-06-24 00:38:03,090 Epoch[21] Batch [1460]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.110672,	
2017-06-24 00:38:07,980 Epoch[21] Batch [1470]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.110733,	
2017-06-24 00:38:12,909 Epoch[21] Batch [1480]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.110732,	
2017-06-24 00:38:15,823 Epoch[21] Train-FCNLogLoss=0.110762
2017-06-24 00:38:15,823 Epoch[21] Time cost=754.293
2017-06-24 00:38:16,626 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0022.params"
2017-06-24 00:38:18,318 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0022.states"
2017-06-24 00:38:23,910 Epoch[22] Batch [10]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.110725,	
2017-06-24 00:38:28,953 Epoch[22] Batch [20]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.124120,	
2017-06-24 00:38:34,101 Epoch[22] Batch [30]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.123759,	
2017-06-24 00:38:39,212 Epoch[22] Batch [40]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.118150,	
2017-06-24 00:38:43,913 Epoch[22] Batch [50]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.118004,	
2017-06-24 00:38:48,732 Epoch[22] Batch [60]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.117661,	
2017-06-24 00:38:53,541 Epoch[22] Batch [70]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.116402,	
2017-06-24 00:38:58,468 Epoch[22] Batch [80]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.114649,	
2017-06-24 00:39:03,647 Epoch[22] Batch [90]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.114669,	
2017-06-24 00:39:08,406 Epoch[22] Batch [100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.114362,	
2017-06-24 00:39:13,204 Epoch[22] Batch [110]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.113939,	
2017-06-24 00:39:18,364 Epoch[22] Batch [120]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.113497,	
2017-06-24 00:39:23,063 Epoch[22] Batch [130]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.112309,	
2017-06-24 00:39:28,398 Epoch[22] Batch [140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.112224,	
2017-06-24 00:39:33,143 Epoch[22] Batch [150]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.112433,	
2017-06-24 00:39:38,255 Epoch[22] Batch [160]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.112322,	
2017-06-24 00:39:43,327 Epoch[22] Batch [170]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.112352,	
2017-06-24 00:39:48,383 Epoch[22] Batch [180]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.112394,	
2017-06-24 00:39:53,655 Epoch[22] Batch [190]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.112161,	
2017-06-24 00:39:58,661 Epoch[22] Batch [200]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.111805,	
2017-06-24 00:40:03,432 Epoch[22] Batch [210]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.111566,	
2017-06-24 00:40:08,211 Epoch[22] Batch [220]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.111593,	
2017-06-24 00:40:13,302 Epoch[22] Batch [230]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.111430,	
2017-06-24 00:40:18,435 Epoch[22] Batch [240]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.111609,	
2017-06-24 00:40:23,370 Epoch[22] Batch [250]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.111409,	
2017-06-24 00:40:28,184 Epoch[22] Batch [260]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.111649,	
2017-06-24 00:40:32,867 Epoch[22] Batch [270]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.111463,	
2017-06-24 00:40:37,628 Epoch[22] Batch [280]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.111861,	
2017-06-24 00:40:42,849 Epoch[22] Batch [290]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111930,	
2017-06-24 00:40:48,014 Epoch[22] Batch [300]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.111435,	
2017-06-24 00:40:53,123 Epoch[22] Batch [310]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.111428,	
2017-06-24 00:40:58,213 Epoch[22] Batch [320]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.110892,	
2017-06-24 00:41:03,331 Epoch[22] Batch [330]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.111027,	
2017-06-24 00:41:08,377 Epoch[22] Batch [340]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.111391,	
2017-06-24 00:41:13,566 Epoch[22] Batch [350]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.111249,	
2017-06-24 00:41:19,015 Epoch[22] Batch [360]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.111431,	
2017-06-24 00:41:24,146 Epoch[22] Batch [370]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.111245,	
2017-06-24 00:41:29,312 Epoch[22] Batch [380]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.111321,	
2017-06-24 00:41:34,428 Epoch[22] Batch [390]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.111179,	
2017-06-24 00:41:39,541 Epoch[22] Batch [400]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.111344,	
2017-06-24 00:41:44,656 Epoch[22] Batch [410]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.111148,	
2017-06-24 00:41:49,740 Epoch[22] Batch [420]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.110773,	
2017-06-24 00:41:54,729 Epoch[22] Batch [430]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.110929,	
2017-06-24 00:41:59,718 Epoch[22] Batch [440]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.110834,	
2017-06-24 00:42:04,623 Epoch[22] Batch [450]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.110875,	
2017-06-24 00:42:09,947 Epoch[22] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.110773,	
2017-06-24 00:42:15,187 Epoch[22] Batch [470]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.111125,	
2017-06-24 00:42:20,704 Epoch[22] Batch [480]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.111255,	
2017-06-24 00:42:25,963 Epoch[22] Batch [490]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111122,	
2017-06-24 00:42:31,653 Epoch[22] Batch [500]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.111091,	
2017-06-24 00:42:36,964 Epoch[22] Batch [510]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.111039,	
2017-06-24 00:42:41,939 Epoch[22] Batch [520]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.111103,	
2017-06-24 00:42:46,796 Epoch[22] Batch [530]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.110979,	
2017-06-24 00:42:51,783 Epoch[22] Batch [540]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.110667,	
2017-06-24 00:42:57,353 Epoch[22] Batch [550]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.110547,	
2017-06-24 00:43:02,368 Epoch[22] Batch [560]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.110406,	
2017-06-24 00:43:07,944 Epoch[22] Batch [570]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.110381,	
2017-06-24 00:43:13,365 Epoch[22] Batch [580]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.110377,	
2017-06-24 00:43:18,436 Epoch[22] Batch [590]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.110274,	
2017-06-24 00:43:23,433 Epoch[22] Batch [600]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.110566,	
2017-06-24 00:43:29,153 Epoch[22] Batch [610]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.110548,	
2017-06-24 00:43:34,669 Epoch[22] Batch [620]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.110536,	
2017-06-24 00:43:40,641 Epoch[22] Batch [630]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.110670,	
2017-06-24 00:43:45,733 Epoch[22] Batch [640]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.110356,	
2017-06-24 00:43:50,991 Epoch[22] Batch [650]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.110507,	
2017-06-24 00:43:56,169 Epoch[22] Batch [660]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.110617,	
2017-06-24 00:44:01,834 Epoch[22] Batch [670]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.110591,	
2017-06-24 00:44:07,382 Epoch[22] Batch [680]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.110544,	
2017-06-24 00:44:12,309 Epoch[22] Batch [690]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.110519,	
2017-06-24 00:44:17,330 Epoch[22] Batch [700]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.110569,	
2017-06-24 00:44:22,139 Epoch[22] Batch [710]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.110591,	
2017-06-24 00:44:27,009 Epoch[22] Batch [720]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.110540,	
2017-06-24 00:44:32,138 Epoch[22] Batch [730]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.110467,	
2017-06-24 00:44:37,542 Epoch[22] Batch [740]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.110304,	
2017-06-24 00:44:42,546 Epoch[22] Batch [750]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.110324,	
2017-06-24 00:44:47,629 Epoch[22] Batch [760]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.110328,	
2017-06-24 00:44:52,618 Epoch[22] Batch [770]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.110207,	
2017-06-24 00:44:57,719 Epoch[22] Batch [780]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.110212,	
2017-06-24 00:45:02,783 Epoch[22] Batch [790]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.110361,	
2017-06-24 00:45:08,408 Epoch[22] Batch [800]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.110180,	
2017-06-24 00:45:13,809 Epoch[22] Batch [810]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.110181,	
2017-06-24 00:45:18,917 Epoch[22] Batch [820]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.110477,	
2017-06-24 00:45:24,044 Epoch[22] Batch [830]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.110532,	
2017-06-24 00:45:29,870 Epoch[22] Batch [840]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110570,	
2017-06-24 00:45:35,013 Epoch[22] Batch [850]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.110677,	
2017-06-24 00:45:40,215 Epoch[22] Batch [860]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.110784,	
2017-06-24 00:45:44,959 Epoch[22] Batch [870]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.110732,	
2017-06-24 00:45:50,158 Epoch[22] Batch [880]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.110645,	
2017-06-24 00:45:55,173 Epoch[22] Batch [890]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.110632,	
2017-06-24 00:46:00,189 Epoch[22] Batch [900]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.110679,	
2017-06-24 00:46:05,333 Epoch[22] Batch [910]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.110626,	
2017-06-24 00:46:10,445 Epoch[22] Batch [920]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.110533,	
2017-06-24 00:46:15,864 Epoch[22] Batch [930]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.110511,	
2017-06-24 00:46:20,805 Epoch[22] Batch [940]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.110523,	
2017-06-24 00:46:25,906 Epoch[22] Batch [950]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.110621,	
2017-06-24 00:46:30,703 Epoch[22] Batch [960]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.110591,	
2017-06-24 00:46:35,805 Epoch[22] Batch [970]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.110534,	
2017-06-24 00:46:42,489 Epoch[22] Batch [980]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.110508,	
2017-06-24 00:46:48,930 Epoch[22] Batch [990]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.110404,	
2017-06-24 00:46:54,618 Epoch[22] Batch [1000]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.110306,	
2017-06-24 00:47:00,191 Epoch[22] Batch [1010]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.110341,	
2017-06-24 00:47:05,319 Epoch[22] Batch [1020]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.110393,	
2017-06-24 00:47:10,643 Epoch[22] Batch [1030]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.110389,	
2017-06-24 00:47:15,801 Epoch[22] Batch [1040]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.110391,	
2017-06-24 00:47:21,052 Epoch[22] Batch [1050]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.110416,	
2017-06-24 00:47:26,114 Epoch[22] Batch [1060]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.110436,	
2017-06-24 00:47:31,507 Epoch[22] Batch [1070]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.110529,	
2017-06-24 00:47:37,096 Epoch[22] Batch [1080]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.110590,	
2017-06-24 00:47:43,050 Epoch[22] Batch [1090]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.110608,	
2017-06-24 00:47:48,490 Epoch[22] Batch [1100]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.110537,	
2017-06-24 00:47:53,299 Epoch[22] Batch [1110]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.110494,	
2017-06-24 00:47:57,908 Epoch[22] Batch [1120]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110574,	
2017-06-24 00:48:02,706 Epoch[22] Batch [1130]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.110607,	
2017-06-24 00:48:07,641 Epoch[22] Batch [1140]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.110503,	
2017-06-24 00:48:12,549 Epoch[22] Batch [1150]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.110559,	
2017-06-24 00:48:17,408 Epoch[22] Batch [1160]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.110566,	
2017-06-24 00:48:22,178 Epoch[22] Batch [1170]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.110604,	
2017-06-24 00:48:27,458 Epoch[22] Batch [1180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.110674,	
2017-06-24 00:48:32,571 Epoch[22] Batch [1190]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.110567,	
2017-06-24 00:48:37,085 Epoch[22] Batch [1200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110529,	
2017-06-24 00:48:41,855 Epoch[22] Batch [1210]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.110520,	
2017-06-24 00:48:47,244 Epoch[22] Batch [1220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.110546,	
2017-06-24 00:48:52,042 Epoch[22] Batch [1230]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.110974,	
2017-06-24 00:48:56,773 Epoch[22] Batch [1240]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.111183,	
2017-06-24 00:49:01,863 Epoch[22] Batch [1250]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.111301,	
2017-06-24 00:49:06,715 Epoch[22] Batch [1260]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.111223,	
2017-06-24 00:49:11,694 Epoch[22] Batch [1270]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.111207,	
2017-06-24 00:49:16,822 Epoch[22] Batch [1280]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.111176,	
2017-06-24 00:49:21,624 Epoch[22] Batch [1290]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.111071,	
2017-06-24 00:49:26,524 Epoch[22] Batch [1300]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.111073,	
2017-06-24 00:49:31,658 Epoch[22] Batch [1310]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.111028,	
2017-06-24 00:49:36,611 Epoch[22] Batch [1320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.110973,	
2017-06-24 00:49:41,345 Epoch[22] Batch [1330]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.110974,	
2017-06-24 00:49:46,488 Epoch[22] Batch [1340]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.110872,	
2017-06-24 00:49:51,506 Epoch[22] Batch [1350]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.110951,	
2017-06-24 00:49:56,336 Epoch[22] Batch [1360]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.110887,	
2017-06-24 00:50:01,697 Epoch[22] Batch [1370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.110855,	
2017-06-24 00:50:06,776 Epoch[22] Batch [1380]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.110862,	
2017-06-24 00:50:11,734 Epoch[22] Batch [1390]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.111114,	
2017-06-24 00:50:16,818 Epoch[22] Batch [1400]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.111117,	
2017-06-24 00:50:22,071 Epoch[22] Batch [1410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111174,	
2017-06-24 00:50:26,838 Epoch[22] Batch [1420]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.111188,	
2017-06-24 00:50:32,098 Epoch[22] Batch [1430]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111240,	
2017-06-24 00:50:37,087 Epoch[22] Batch [1440]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.111320,	
2017-06-24 00:50:42,367 Epoch[22] Batch [1450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111366,	
2017-06-24 00:50:47,034 Epoch[22] Batch [1460]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.111375,	
2017-06-24 00:50:52,534 Epoch[22] Batch [1470]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.111270,	
2017-06-24 00:50:57,738 Epoch[22] Batch [1480]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.111236,	
2017-06-24 00:51:00,966 Epoch[22] Train-FCNLogLoss=0.111298
2017-06-24 00:51:00,966 Epoch[22] Time cost=762.648
2017-06-24 00:51:01,725 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0023.params"
2017-06-24 00:51:03,348 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0023.states"
2017-06-24 00:51:09,232 Epoch[23] Batch [10]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.141955,	
2017-06-24 00:51:14,092 Epoch[23] Batch [20]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.153144,	
2017-06-24 00:51:19,113 Epoch[23] Batch [30]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.149019,	
2017-06-24 00:51:23,847 Epoch[23] Batch [40]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.139484,	
2017-06-24 00:51:28,301 Epoch[23] Batch [50]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.136892,	
2017-06-24 00:51:33,376 Epoch[23] Batch [60]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.137270,	
2017-06-24 00:51:38,667 Epoch[23] Batch [70]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.137425,	
2017-06-24 00:51:43,311 Epoch[23] Batch [80]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.135965,	
2017-06-24 00:51:48,302 Epoch[23] Batch [90]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.133170,	
2017-06-24 00:51:53,316 Epoch[23] Batch [100]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.131318,	
2017-06-24 00:51:57,976 Epoch[23] Batch [110]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.129390,	
2017-06-24 00:52:02,749 Epoch[23] Batch [120]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.127911,	
2017-06-24 00:52:07,789 Epoch[23] Batch [130]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.125214,	
2017-06-24 00:52:13,030 Epoch[23] Batch [140]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.123885,	
2017-06-24 00:52:18,242 Epoch[23] Batch [150]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.123444,	
2017-06-24 00:52:23,296 Epoch[23] Batch [160]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.123212,	
2017-06-24 00:52:28,303 Epoch[23] Batch [170]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.122637,	
2017-06-24 00:52:33,091 Epoch[23] Batch [180]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.121990,	
2017-06-24 00:52:38,428 Epoch[23] Batch [190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121529,	
2017-06-24 00:52:43,704 Epoch[23] Batch [200]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.120717,	
2017-06-24 00:52:48,798 Epoch[23] Batch [210]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.120045,	
2017-06-24 00:52:54,479 Epoch[23] Batch [220]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.120008,	
2017-06-24 00:52:59,070 Epoch[23] Batch [230]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.119236,	
2017-06-24 00:53:04,346 Epoch[23] Batch [240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119174,	
2017-06-24 00:53:09,846 Epoch[23] Batch [250]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.120152,	
2017-06-24 00:53:15,312 Epoch[23] Batch [260]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.120299,	
2017-06-24 00:53:20,450 Epoch[23] Batch [270]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.120070,	
2017-06-24 00:53:25,657 Epoch[23] Batch [280]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119576,	
2017-06-24 00:53:30,896 Epoch[23] Batch [290]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.119674,	
2017-06-24 00:53:36,114 Epoch[23] Batch [300]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.119537,	
2017-06-24 00:53:41,642 Epoch[23] Batch [310]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.119392,	
2017-06-24 00:53:46,445 Epoch[23] Batch [320]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.118899,	
2017-06-24 00:53:51,757 Epoch[23] Batch [330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118623,	
2017-06-24 00:53:58,134 Epoch[23] Batch [340]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.118048,	
2017-06-24 00:54:04,197 Epoch[23] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.117806,	
2017-06-24 00:54:09,213 Epoch[23] Batch [360]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.117584,	
2017-06-24 00:54:14,476 Epoch[23] Batch [370]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.117466,	
2017-06-24 00:54:19,820 Epoch[23] Batch [380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117780,	
2017-06-24 00:54:24,694 Epoch[23] Batch [390]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.117807,	
2017-06-24 00:54:29,586 Epoch[23] Batch [400]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.117747,	
2017-06-24 00:54:34,851 Epoch[23] Batch [410]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.117953,	
2017-06-24 00:54:39,604 Epoch[23] Batch [420]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.118465,	
2017-06-24 00:54:44,899 Epoch[23] Batch [430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118755,	
2017-06-24 00:54:49,755 Epoch[23] Batch [440]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.118846,	
2017-06-24 00:54:54,913 Epoch[23] Batch [450]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.118694,	
2017-06-24 00:54:59,961 Epoch[23] Batch [460]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.118388,	
2017-06-24 00:55:05,306 Epoch[23] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118264,	
2017-06-24 00:55:10,663 Epoch[23] Batch [480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118432,	
2017-06-24 00:55:16,855 Epoch[23] Batch [490]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.118232,	
2017-06-24 00:55:22,220 Epoch[23] Batch [500]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118096,	
2017-06-24 00:55:27,924 Epoch[23] Batch [510]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.118040,	
2017-06-24 00:55:33,209 Epoch[23] Batch [520]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.118060,	
2017-06-24 00:55:38,866 Epoch[23] Batch [530]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.117836,	
2017-06-24 00:55:44,530 Epoch[23] Batch [540]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.117714,	
2017-06-24 00:55:50,886 Epoch[23] Batch [550]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.117685,	
2017-06-24 00:55:55,952 Epoch[23] Batch [560]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.117640,	
2017-06-24 00:56:01,753 Epoch[23] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.117599,	
2017-06-24 00:56:07,352 Epoch[23] Batch [580]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.117331,	
2017-06-24 00:56:12,334 Epoch[23] Batch [590]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.116999,	
2017-06-24 00:56:17,332 Epoch[23] Batch [600]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.116936,	
2017-06-24 00:56:22,513 Epoch[23] Batch [610]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.116770,	
2017-06-24 00:56:28,054 Epoch[23] Batch [620]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.116721,	
2017-06-24 00:56:33,125 Epoch[23] Batch [630]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.116768,	
2017-06-24 00:56:37,897 Epoch[23] Batch [640]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.116615,	
2017-06-24 00:56:43,005 Epoch[23] Batch [650]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.116514,	
2017-06-24 00:56:48,573 Epoch[23] Batch [660]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.116322,	
2017-06-24 00:56:53,731 Epoch[23] Batch [670]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.116389,	
2017-06-24 00:56:58,639 Epoch[23] Batch [680]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.116192,	
2017-06-24 00:57:03,567 Epoch[23] Batch [690]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.116110,	
2017-06-24 00:57:08,726 Epoch[23] Batch [700]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.116163,	
2017-06-24 00:57:13,542 Epoch[23] Batch [710]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.116227,	
2017-06-24 00:57:18,313 Epoch[23] Batch [720]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.116054,	
2017-06-24 00:57:23,222 Epoch[23] Batch [730]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.115912,	
2017-06-24 00:57:28,719 Epoch[23] Batch [740]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.115915,	
2017-06-24 00:57:34,175 Epoch[23] Batch [750]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.116228,	
2017-06-24 00:57:39,775 Epoch[23] Batch [760]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.116085,	
2017-06-24 00:57:44,842 Epoch[23] Batch [770]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.115960,	
2017-06-24 00:57:50,191 Epoch[23] Batch [780]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.115972,	
2017-06-24 00:57:55,211 Epoch[23] Batch [790]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.115928,	
2017-06-24 00:58:00,410 Epoch[23] Batch [800]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.115871,	
2017-06-24 00:58:05,826 Epoch[23] Batch [810]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.115764,	
2017-06-24 00:58:10,797 Epoch[23] Batch [820]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.115799,	
2017-06-24 00:58:15,921 Epoch[23] Batch [830]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.115718,	
2017-06-24 00:58:21,333 Epoch[23] Batch [840]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.115701,	
2017-06-24 00:58:26,467 Epoch[23] Batch [850]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.115589,	
2017-06-24 00:58:32,206 Epoch[23] Batch [860]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.115551,	
2017-06-24 00:58:37,247 Epoch[23] Batch [870]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.115404,	
2017-06-24 00:58:42,615 Epoch[23] Batch [880]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.115285,	
2017-06-24 00:58:47,536 Epoch[23] Batch [890]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.115278,	
2017-06-24 00:58:52,118 Epoch[23] Batch [900]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.115183,	
2017-06-24 00:58:57,041 Epoch[23] Batch [910]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.115203,	
2017-06-24 00:59:01,762 Epoch[23] Batch [920]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.115030,	
2017-06-24 00:59:06,413 Epoch[23] Batch [930]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.114918,	
2017-06-24 00:59:11,187 Epoch[23] Batch [940]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.114753,	
2017-06-24 00:59:15,768 Epoch[23] Batch [950]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.114614,	
2017-06-24 00:59:21,100 Epoch[23] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.114524,	
2017-06-24 00:59:25,940 Epoch[23] Batch [970]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.114500,	
2017-06-24 00:59:30,679 Epoch[23] Batch [980]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.114379,	
2017-06-24 00:59:35,348 Epoch[23] Batch [990]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.114250,	
2017-06-24 00:59:40,096 Epoch[23] Batch [1000]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.114250,	
2017-06-24 00:59:44,742 Epoch[23] Batch [1010]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.114191,	
2017-06-24 00:59:49,444 Epoch[23] Batch [1020]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.114106,	
2017-06-24 00:59:53,932 Epoch[23] Batch [1030]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.113913,	
2017-06-24 00:59:59,098 Epoch[23] Batch [1040]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.113848,	
2017-06-24 01:00:04,020 Epoch[23] Batch [1050]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.113885,	
2017-06-24 01:00:09,355 Epoch[23] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113848,	
2017-06-24 01:00:14,469 Epoch[23] Batch [1070]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.113785,	
2017-06-24 01:00:19,257 Epoch[23] Batch [1080]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.113679,	
2017-06-24 01:00:24,099 Epoch[23] Batch [1090]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.113557,	
2017-06-24 01:00:29,150 Epoch[23] Batch [1100]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.113528,	
2017-06-24 01:00:33,908 Epoch[23] Batch [1110]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.113478,	
2017-06-24 01:00:39,126 Epoch[23] Batch [1120]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.113357,	
2017-06-24 01:00:44,287 Epoch[23] Batch [1130]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.113278,	
2017-06-24 01:00:49,374 Epoch[23] Batch [1140]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.113277,	
2017-06-24 01:00:54,250 Epoch[23] Batch [1150]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.113298,	
2017-06-24 01:00:59,809 Epoch[23] Batch [1160]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.113264,	
2017-06-24 01:01:04,903 Epoch[23] Batch [1170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.113214,	
2017-06-24 01:01:10,624 Epoch[23] Batch [1180]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.113083,	
2017-06-24 01:01:15,611 Epoch[23] Batch [1190]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.112988,	
2017-06-24 01:01:20,469 Epoch[23] Batch [1200]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.112852,	
2017-06-24 01:01:25,215 Epoch[23] Batch [1210]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.112712,	
2017-06-24 01:01:30,223 Epoch[23] Batch [1220]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.112561,	
2017-06-24 01:01:35,485 Epoch[23] Batch [1230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112461,	
2017-06-24 01:01:40,365 Epoch[23] Batch [1240]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.112436,	
2017-06-24 01:01:45,545 Epoch[23] Batch [1250]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.112469,	
2017-06-24 01:01:50,578 Epoch[23] Batch [1260]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.112453,	
2017-06-24 01:01:55,771 Epoch[23] Batch [1270]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112343,	
2017-06-24 01:02:01,257 Epoch[23] Batch [1280]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.112228,	
2017-06-24 01:02:06,205 Epoch[23] Batch [1290]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.112094,	
2017-06-24 01:02:11,464 Epoch[23] Batch [1300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111953,	
2017-06-24 01:02:16,672 Epoch[23] Batch [1310]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111954,	
2017-06-24 01:02:21,739 Epoch[23] Batch [1320]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.111975,	
2017-06-24 01:02:26,892 Epoch[23] Batch [1330]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.111912,	
2017-06-24 01:02:31,659 Epoch[23] Batch [1340]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.111887,	
2017-06-24 01:02:36,584 Epoch[23] Batch [1350]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.111765,	
2017-06-24 01:02:41,501 Epoch[23] Batch [1360]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.111656,	
2017-06-24 01:02:46,662 Epoch[23] Batch [1370]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.111520,	
2017-06-24 01:02:51,615 Epoch[23] Batch [1380]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.111506,	
2017-06-24 01:02:56,790 Epoch[23] Batch [1390]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.111476,	
2017-06-24 01:03:01,601 Epoch[23] Batch [1400]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.111454,	
2017-06-24 01:03:06,709 Epoch[23] Batch [1410]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.111394,	
2017-06-24 01:03:11,592 Epoch[23] Batch [1420]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.111297,	
2017-06-24 01:03:16,756 Epoch[23] Batch [1430]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.111266,	
2017-06-24 01:03:21,967 Epoch[23] Batch [1440]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111254,	
2017-06-24 01:03:26,744 Epoch[23] Batch [1450]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.111318,	
2017-06-24 01:03:31,520 Epoch[23] Batch [1460]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.111297,	
2017-06-24 01:03:36,513 Epoch[23] Batch [1470]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.111281,	
2017-06-24 01:03:41,524 Epoch[23] Batch [1480]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.111287,	
2017-06-24 01:03:44,521 Epoch[23] Train-FCNLogLoss=0.111361
2017-06-24 01:03:44,521 Epoch[23] Time cost=761.173
2017-06-24 01:03:45,295 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0024.params"
2017-06-24 01:03:46,850 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0024.states"
2017-06-24 01:03:52,386 Epoch[24] Batch [10]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.110880,	
2017-06-24 01:03:57,237 Epoch[24] Batch [20]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.112560,	
2017-06-24 01:04:02,339 Epoch[24] Batch [30]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.111360,	
2017-06-24 01:04:07,747 Epoch[24] Batch [40]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.112769,	
2017-06-24 01:04:13,035 Epoch[24] Batch [50]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.113272,	
2017-06-24 01:04:18,305 Epoch[24] Batch [60]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.110165,	
2017-06-24 01:04:24,043 Epoch[24] Batch [70]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.111133,	
2017-06-24 01:04:29,187 Epoch[24] Batch [80]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.110010,	
2017-06-24 01:04:34,037 Epoch[24] Batch [90]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.109831,	
2017-06-24 01:04:39,646 Epoch[24] Batch [100]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.109355,	
2017-06-24 01:04:44,890 Epoch[24] Batch [110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.109034,	
2017-06-24 01:04:49,922 Epoch[24] Batch [120]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.107717,	
2017-06-24 01:04:54,946 Epoch[24] Batch [130]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.107871,	
2017-06-24 01:05:00,117 Epoch[24] Batch [140]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.107107,	
2017-06-24 01:05:05,164 Epoch[24] Batch [150]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.107134,	
2017-06-24 01:05:10,483 Epoch[24] Batch [160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.106678,	
2017-06-24 01:05:15,778 Epoch[24] Batch [170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.106742,	
2017-06-24 01:05:20,770 Epoch[24] Batch [180]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.106737,	
2017-06-24 01:05:26,091 Epoch[24] Batch [190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.106414,	
2017-06-24 01:05:31,128 Epoch[24] Batch [200]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.106596,	
2017-06-24 01:05:36,093 Epoch[24] Batch [210]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.106590,	
2017-06-24 01:05:41,553 Epoch[24] Batch [220]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.106297,	
2017-06-24 01:05:47,455 Epoch[24] Batch [230]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106337,	
2017-06-24 01:05:52,897 Epoch[24] Batch [240]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.106084,	
2017-06-24 01:05:58,186 Epoch[24] Batch [250]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.106142,	
2017-06-24 01:06:03,764 Epoch[24] Batch [260]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.106350,	
2017-06-24 01:06:09,233 Epoch[24] Batch [270]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.106258,	
2017-06-24 01:06:13,986 Epoch[24] Batch [280]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.105898,	
2017-06-24 01:06:19,009 Epoch[24] Batch [290]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.105739,	
2017-06-24 01:06:24,128 Epoch[24] Batch [300]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.105876,	
2017-06-24 01:06:29,172 Epoch[24] Batch [310]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.105965,	
2017-06-24 01:06:34,041 Epoch[24] Batch [320]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.105838,	
2017-06-24 01:06:39,005 Epoch[24] Batch [330]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.106031,	
2017-06-24 01:06:44,021 Epoch[24] Batch [340]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.105752,	
2017-06-24 01:06:48,971 Epoch[24] Batch [350]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.106030,	
2017-06-24 01:06:53,643 Epoch[24] Batch [360]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106067,	
2017-06-24 01:06:58,830 Epoch[24] Batch [370]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105866,	
2017-06-24 01:07:04,349 Epoch[24] Batch [380]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.105852,	
2017-06-24 01:07:09,521 Epoch[24] Batch [390]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.106043,	
2017-06-24 01:07:14,734 Epoch[24] Batch [400]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.105695,	
2017-06-24 01:07:19,749 Epoch[24] Batch [410]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.105399,	
2017-06-24 01:07:25,530 Epoch[24] Batch [420]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.105593,	
2017-06-24 01:07:31,087 Epoch[24] Batch [430]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.105516,	
2017-06-24 01:07:35,916 Epoch[24] Batch [440]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.105671,	
2017-06-24 01:07:41,238 Epoch[24] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105789,	
2017-06-24 01:07:46,398 Epoch[24] Batch [460]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.105571,	
2017-06-24 01:07:51,395 Epoch[24] Batch [470]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.105485,	
2017-06-24 01:07:56,564 Epoch[24] Batch [480]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.105347,	
2017-06-24 01:08:01,465 Epoch[24] Batch [490]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.105302,	
2017-06-24 01:08:07,347 Epoch[24] Batch [500]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.105393,	
2017-06-24 01:08:13,270 Epoch[24] Batch [510]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105391,	
2017-06-24 01:08:18,790 Epoch[24] Batch [520]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.105480,	
2017-06-24 01:08:25,740 Epoch[24] Batch [530]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.105426,	
2017-06-24 01:08:31,414 Epoch[24] Batch [540]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.105327,	
2017-06-24 01:08:36,491 Epoch[24] Batch [550]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.105341,	
2017-06-24 01:08:41,753 Epoch[24] Batch [560]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.105225,	
2017-06-24 01:08:47,624 Epoch[24] Batch [570]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.105405,	
2017-06-24 01:08:52,904 Epoch[24] Batch [580]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.105399,	
2017-06-24 01:08:58,404 Epoch[24] Batch [590]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.105393,	
2017-06-24 01:09:03,559 Epoch[24] Batch [600]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.105250,	
2017-06-24 01:09:08,627 Epoch[24] Batch [610]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.105327,	
2017-06-24 01:09:14,286 Epoch[24] Batch [620]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.105481,	
2017-06-24 01:09:19,851 Epoch[24] Batch [630]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.105644,	
2017-06-24 01:09:25,022 Epoch[24] Batch [640]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.105516,	
2017-06-24 01:09:30,144 Epoch[24] Batch [650]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.105468,	
2017-06-24 01:09:35,242 Epoch[24] Batch [660]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.105181,	
2017-06-24 01:09:40,229 Epoch[24] Batch [670]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.105324,	
2017-06-24 01:09:45,200 Epoch[24] Batch [680]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.105361,	
2017-06-24 01:09:50,331 Epoch[24] Batch [690]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.105389,	
2017-06-24 01:09:55,437 Epoch[24] Batch [700]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.105396,	
2017-06-24 01:10:00,362 Epoch[24] Batch [710]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.105359,	
2017-06-24 01:10:05,371 Epoch[24] Batch [720]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.105431,	
2017-06-24 01:10:10,080 Epoch[24] Batch [730]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.105453,	
2017-06-24 01:10:14,829 Epoch[24] Batch [740]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.105290,	
2017-06-24 01:10:20,139 Epoch[24] Batch [750]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.105322,	
2017-06-24 01:10:25,328 Epoch[24] Batch [760]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105593,	
2017-06-24 01:10:30,849 Epoch[24] Batch [770]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.105627,	
2017-06-24 01:10:35,951 Epoch[24] Batch [780]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.105631,	
2017-06-24 01:10:41,501 Epoch[24] Batch [790]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.105613,	
2017-06-24 01:10:46,614 Epoch[24] Batch [800]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.105681,	
2017-06-24 01:10:51,764 Epoch[24] Batch [810]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.105767,	
2017-06-24 01:10:57,139 Epoch[24] Batch [820]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.105785,	
2017-06-24 01:11:01,966 Epoch[24] Batch [830]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.105837,	
2017-06-24 01:11:07,198 Epoch[24] Batch [840]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.105728,	
2017-06-24 01:11:12,419 Epoch[24] Batch [850]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105718,	
2017-06-24 01:11:17,627 Epoch[24] Batch [860]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105808,	
2017-06-24 01:11:22,866 Epoch[24] Batch [870]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.105769,	
2017-06-24 01:11:27,977 Epoch[24] Batch [880]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.105676,	
2017-06-24 01:11:33,170 Epoch[24] Batch [890]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.105694,	
2017-06-24 01:11:38,382 Epoch[24] Batch [900]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105858,	
2017-06-24 01:11:43,680 Epoch[24] Batch [910]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.105824,	
2017-06-24 01:11:48,797 Epoch[24] Batch [920]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.105788,	
2017-06-24 01:11:54,006 Epoch[24] Batch [930]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105904,	
2017-06-24 01:11:59,179 Epoch[24] Batch [940]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.106004,	
2017-06-24 01:12:04,399 Epoch[24] Batch [950]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105949,	
2017-06-24 01:12:09,582 Epoch[24] Batch [960]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105927,	
2017-06-24 01:12:14,823 Epoch[24] Batch [970]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.105851,	
2017-06-24 01:12:20,055 Epoch[24] Batch [980]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.105868,	
2017-06-24 01:12:25,201 Epoch[24] Batch [990]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.105839,	
2017-06-24 01:12:30,430 Epoch[24] Batch [1000]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.105774,	
2017-06-24 01:12:35,632 Epoch[24] Batch [1010]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.105796,	
2017-06-24 01:12:40,821 Epoch[24] Batch [1020]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105705,	
2017-06-24 01:12:46,056 Epoch[24] Batch [1030]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.105600,	
2017-06-24 01:12:51,295 Epoch[24] Batch [1040]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.105559,	
2017-06-24 01:12:56,428 Epoch[24] Batch [1050]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.105556,	
2017-06-24 01:13:01,562 Epoch[24] Batch [1060]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.105584,	
2017-06-24 01:13:06,744 Epoch[24] Batch [1070]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.106043,	
2017-06-24 01:13:11,966 Epoch[24] Batch [1080]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.106181,	
2017-06-24 01:13:17,182 Epoch[24] Batch [1090]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.106201,	
2017-06-24 01:13:22,443 Epoch[24] Batch [1100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.106203,	
2017-06-24 01:13:27,527 Epoch[24] Batch [1110]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.106137,	
2017-06-24 01:13:32,715 Epoch[24] Batch [1120]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.106110,	
2017-06-24 01:13:37,796 Epoch[24] Batch [1130]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.106128,	
2017-06-24 01:13:42,868 Epoch[24] Batch [1140]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.106135,	
2017-06-24 01:13:48,019 Epoch[24] Batch [1150]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.106117,	
2017-06-24 01:13:53,261 Epoch[24] Batch [1160]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.106136,	
2017-06-24 01:13:58,452 Epoch[24] Batch [1170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.106162,	
2017-06-24 01:14:03,645 Epoch[24] Batch [1180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.106229,	
2017-06-24 01:14:08,863 Epoch[24] Batch [1190]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.106228,	
2017-06-24 01:14:14,064 Epoch[24] Batch [1200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.106311,	
2017-06-24 01:14:19,275 Epoch[24] Batch [1210]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.106570,	
2017-06-24 01:14:24,474 Epoch[24] Batch [1220]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.106692,	
2017-06-24 01:14:29,524 Epoch[24] Batch [1230]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.106781,	
2017-06-24 01:14:34,400 Epoch[24] Batch [1240]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.106810,	
2017-06-24 01:14:38,962 Epoch[24] Batch [1250]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.106912,	
2017-06-24 01:14:43,883 Epoch[24] Batch [1260]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.106841,	
2017-06-24 01:14:48,648 Epoch[24] Batch [1270]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.106766,	
2017-06-24 01:14:53,471 Epoch[24] Batch [1280]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.106715,	
2017-06-24 01:14:58,505 Epoch[24] Batch [1290]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.106724,	
2017-06-24 01:15:03,418 Epoch[24] Batch [1300]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.106767,	
2017-06-24 01:15:08,398 Epoch[24] Batch [1310]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.106745,	
2017-06-24 01:15:13,436 Epoch[24] Batch [1320]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.106803,	
2017-06-24 01:15:18,633 Epoch[24] Batch [1330]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.106772,	
2017-06-24 01:15:23,708 Epoch[24] Batch [1340]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.106768,	
2017-06-24 01:15:28,440 Epoch[24] Batch [1350]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.106709,	
2017-06-24 01:15:33,510 Epoch[24] Batch [1360]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.106630,	
2017-06-24 01:15:38,361 Epoch[24] Batch [1370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.106573,	
2017-06-24 01:15:43,758 Epoch[24] Batch [1380]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.106564,	
2017-06-24 01:15:48,484 Epoch[24] Batch [1390]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.106618,	
2017-06-24 01:15:53,422 Epoch[24] Batch [1400]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.106611,	
2017-06-24 01:15:58,930 Epoch[24] Batch [1410]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.106738,	
2017-06-24 01:16:03,822 Epoch[24] Batch [1420]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.106771,	
2017-06-24 01:16:09,122 Epoch[24] Batch [1430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.106751,	
2017-06-24 01:16:14,538 Epoch[24] Batch [1440]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.106762,	
2017-06-24 01:16:20,219 Epoch[24] Batch [1450]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.106703,	
2017-06-24 01:16:25,642 Epoch[24] Batch [1460]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.106688,	
2017-06-24 01:16:30,383 Epoch[24] Batch [1470]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.106587,	
2017-06-24 01:16:35,806 Epoch[24] Batch [1480]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.106615,	
2017-06-24 01:16:39,079 Epoch[24] Train-FCNLogLoss=0.106620
2017-06-24 01:16:39,079 Epoch[24] Time cost=772.228
2017-06-24 01:16:39,831 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0025.params"
2017-06-24 01:16:41,514 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0025.states"
2017-06-24 01:16:47,640 Epoch[25] Batch [10]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.116155,	
2017-06-24 01:16:52,758 Epoch[25] Batch [20]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.110208,	
2017-06-24 01:16:58,037 Epoch[25] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.107792,	
2017-06-24 01:17:03,249 Epoch[25] Batch [40]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.107092,	
2017-06-24 01:17:08,754 Epoch[25] Batch [50]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.106471,	
2017-06-24 01:17:14,140 Epoch[25] Batch [60]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.105008,	
2017-06-24 01:17:19,433 Epoch[25] Batch [70]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.105639,	
2017-06-24 01:17:25,054 Epoch[25] Batch [80]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.106349,	
2017-06-24 01:17:30,183 Epoch[25] Batch [90]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.105602,	
2017-06-24 01:17:36,645 Epoch[25] Batch [100]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.105137,	
2017-06-24 01:17:42,301 Epoch[25] Batch [110]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.105430,	
2017-06-24 01:17:48,184 Epoch[25] Batch [120]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.104969,	
2017-06-24 01:17:53,182 Epoch[25] Batch [130]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.105035,	
2017-06-24 01:17:58,435 Epoch[25] Batch [140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.103794,	
2017-06-24 01:18:04,096 Epoch[25] Batch [150]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.103195,	
2017-06-24 01:18:09,237 Epoch[25] Batch [160]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.103721,	
2017-06-24 01:18:14,425 Epoch[25] Batch [170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.103811,	
2017-06-24 01:18:20,268 Epoch[25] Batch [180]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103598,	
2017-06-24 01:18:25,132 Epoch[25] Batch [190]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.104025,	
2017-06-24 01:18:30,461 Epoch[25] Batch [200]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104391,	
2017-06-24 01:18:35,617 Epoch[25] Batch [210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.104314,	
2017-06-24 01:18:41,214 Epoch[25] Batch [220]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.104445,	
2017-06-24 01:18:46,855 Epoch[25] Batch [230]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.104198,	
2017-06-24 01:18:52,493 Epoch[25] Batch [240]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.103918,	
2017-06-24 01:18:57,706 Epoch[25] Batch [250]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.103802,	
2017-06-24 01:19:03,011 Epoch[25] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.103743,	
2017-06-24 01:19:08,009 Epoch[25] Batch [270]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.103508,	
2017-06-24 01:19:13,659 Epoch[25] Batch [280]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.103367,	
2017-06-24 01:19:19,425 Epoch[25] Batch [290]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103934,	
2017-06-24 01:19:24,705 Epoch[25] Batch [300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.103610,	
2017-06-24 01:19:29,874 Epoch[25] Batch [310]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.103579,	
2017-06-24 01:19:35,714 Epoch[25] Batch [320]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103808,	
2017-06-24 01:19:41,832 Epoch[25] Batch [330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103916,	
2017-06-24 01:19:46,858 Epoch[25] Batch [340]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.103649,	
2017-06-24 01:19:52,344 Epoch[25] Batch [350]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.103455,	
2017-06-24 01:19:57,895 Epoch[25] Batch [360]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.103468,	
2017-06-24 01:20:03,077 Epoch[25] Batch [370]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.103461,	
2017-06-24 01:20:08,512 Epoch[25] Batch [380]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.103472,	
2017-06-24 01:20:14,436 Epoch[25] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103910,	
2017-06-24 01:20:20,070 Epoch[25] Batch [400]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.104043,	
2017-06-24 01:20:25,575 Epoch[25] Batch [410]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.104000,	
2017-06-24 01:20:31,669 Epoch[25] Batch [420]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103827,	
2017-06-24 01:20:37,747 Epoch[25] Batch [430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103793,	
2017-06-24 01:20:43,253 Epoch[25] Batch [440]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.103610,	
2017-06-24 01:20:48,546 Epoch[25] Batch [450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.103746,	
2017-06-24 01:20:53,416 Epoch[25] Batch [460]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.103978,	
2017-06-24 01:20:58,183 Epoch[25] Batch [470]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.104063,	
2017-06-24 01:21:03,255 Epoch[25] Batch [480]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.104211,	
2017-06-24 01:21:08,042 Epoch[25] Batch [490]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.104201,	
2017-06-24 01:21:12,751 Epoch[25] Batch [500]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104280,	
2017-06-24 01:21:17,719 Epoch[25] Batch [510]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.104124,	
2017-06-24 01:21:22,890 Epoch[25] Batch [520]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.104012,	
2017-06-24 01:21:28,256 Epoch[25] Batch [530]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.103886,	
2017-06-24 01:21:32,898 Epoch[25] Batch [540]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.103817,	
2017-06-24 01:21:37,885 Epoch[25] Batch [550]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.103732,	
2017-06-24 01:21:42,864 Epoch[25] Batch [560]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.103739,	
2017-06-24 01:21:47,360 Epoch[25] Batch [570]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103715,	
2017-06-24 01:21:52,689 Epoch[25] Batch [580]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.103788,	
2017-06-24 01:21:58,086 Epoch[25] Batch [590]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.103651,	
2017-06-24 01:22:03,113 Epoch[25] Batch [600]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.103673,	
2017-06-24 01:22:07,746 Epoch[25] Batch [610]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.103760,	
2017-06-24 01:22:12,644 Epoch[25] Batch [620]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.103770,	
2017-06-24 01:22:17,526 Epoch[25] Batch [630]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.103822,	
2017-06-24 01:22:22,245 Epoch[25] Batch [640]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.103945,	
2017-06-24 01:22:27,116 Epoch[25] Batch [650]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.103794,	
2017-06-24 01:22:31,853 Epoch[25] Batch [660]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.103892,	
2017-06-24 01:22:36,816 Epoch[25] Batch [670]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.103967,	
2017-06-24 01:22:41,632 Epoch[25] Batch [680]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.104011,	
2017-06-24 01:22:46,586 Epoch[25] Batch [690]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.103958,	
2017-06-24 01:22:52,274 Epoch[25] Batch [700]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.103908,	
2017-06-24 01:22:57,817 Epoch[25] Batch [710]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.103841,	
2017-06-24 01:23:03,239 Epoch[25] Batch [720]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.104226,	
2017-06-24 01:23:08,415 Epoch[25] Batch [730]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.104373,	
2017-06-24 01:23:13,268 Epoch[25] Batch [740]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.104492,	
2017-06-24 01:23:18,222 Epoch[25] Batch [750]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.104448,	
2017-06-24 01:23:23,152 Epoch[25] Batch [760]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.104753,	
2017-06-24 01:23:27,930 Epoch[25] Batch [770]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.104834,	
2017-06-24 01:23:32,694 Epoch[25] Batch [780]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.104782,	
2017-06-24 01:23:37,510 Epoch[25] Batch [790]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.104903,	
2017-06-24 01:23:42,237 Epoch[25] Batch [800]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.104926,	
2017-06-24 01:23:47,267 Epoch[25] Batch [810]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.104957,	
2017-06-24 01:23:52,306 Epoch[25] Batch [820]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.104928,	
2017-06-24 01:23:57,074 Epoch[25] Batch [830]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.104877,	
2017-06-24 01:24:02,203 Epoch[25] Batch [840]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.104809,	
2017-06-24 01:24:07,335 Epoch[25] Batch [850]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.104837,	
2017-06-24 01:24:12,395 Epoch[25] Batch [860]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.104887,	
2017-06-24 01:24:17,536 Epoch[25] Batch [870]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.104933,	
2017-06-24 01:24:22,197 Epoch[25] Batch [880]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105061,	
2017-06-24 01:24:27,373 Epoch[25] Batch [890]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.105185,	
2017-06-24 01:24:32,097 Epoch[25] Batch [900]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.105084,	
2017-06-24 01:24:36,856 Epoch[25] Batch [910]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.105253,	
2017-06-24 01:24:42,008 Epoch[25] Batch [920]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.105292,	
2017-06-24 01:24:46,798 Epoch[25] Batch [930]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.105244,	
2017-06-24 01:24:51,684 Epoch[25] Batch [940]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.105257,	
2017-06-24 01:24:57,051 Epoch[25] Batch [950]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.105383,	
2017-06-24 01:25:02,125 Epoch[25] Batch [960]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.105483,	
2017-06-24 01:25:07,073 Epoch[25] Batch [970]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.105358,	
2017-06-24 01:25:11,839 Epoch[25] Batch [980]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.105390,	
2017-06-24 01:25:16,707 Epoch[25] Batch [990]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.105505,	
2017-06-24 01:25:21,644 Epoch[25] Batch [1000]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.105608,	
2017-06-24 01:25:26,631 Epoch[25] Batch [1010]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.105587,	
2017-06-24 01:25:31,659 Epoch[25] Batch [1020]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.105660,	
2017-06-24 01:25:36,664 Epoch[25] Batch [1030]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.105640,	
2017-06-24 01:25:41,588 Epoch[25] Batch [1040]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.105503,	
2017-06-24 01:25:46,459 Epoch[25] Batch [1050]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.105473,	
2017-06-24 01:25:51,427 Epoch[25] Batch [1060]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.105503,	
2017-06-24 01:25:56,552 Epoch[25] Batch [1070]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.105674,	
2017-06-24 01:26:01,509 Epoch[25] Batch [1080]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.105725,	
2017-06-24 01:26:06,441 Epoch[25] Batch [1090]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.105631,	
2017-06-24 01:26:11,457 Epoch[25] Batch [1100]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.105622,	
2017-06-24 01:26:16,638 Epoch[25] Batch [1110]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105733,	
2017-06-24 01:26:22,188 Epoch[25] Batch [1120]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.105919,	
2017-06-24 01:26:28,389 Epoch[25] Batch [1130]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.106300,	
2017-06-24 01:26:34,040 Epoch[25] Batch [1140]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.106412,	
2017-06-24 01:26:38,994 Epoch[25] Batch [1150]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.106709,	
2017-06-24 01:26:44,166 Epoch[25] Batch [1160]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.106999,	
2017-06-24 01:26:49,674 Epoch[25] Batch [1170]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.107407,	
2017-06-24 01:26:55,140 Epoch[25] Batch [1180]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.107624,	
2017-06-24 01:27:00,467 Epoch[25] Batch [1190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107694,	
2017-06-24 01:27:05,625 Epoch[25] Batch [1200]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.107698,	
2017-06-24 01:27:11,234 Epoch[25] Batch [1210]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.107772,	
2017-06-24 01:27:16,552 Epoch[25] Batch [1220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.107854,	
2017-06-24 01:27:21,504 Epoch[25] Batch [1230]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.107972,	
2017-06-24 01:27:26,627 Epoch[25] Batch [1240]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.107946,	
2017-06-24 01:27:31,649 Epoch[25] Batch [1250]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.107935,	
2017-06-24 01:27:36,516 Epoch[25] Batch [1260]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.107913,	
2017-06-24 01:27:42,216 Epoch[25] Batch [1270]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107960,	
2017-06-24 01:27:47,509 Epoch[25] Batch [1280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.107987,	
2017-06-24 01:27:52,894 Epoch[25] Batch [1290]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.108068,	
2017-06-24 01:27:58,326 Epoch[25] Batch [1300]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.107967,	
2017-06-24 01:28:03,172 Epoch[25] Batch [1310]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.107908,	
2017-06-24 01:28:08,692 Epoch[25] Batch [1320]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.107915,	
2017-06-24 01:28:13,677 Epoch[25] Batch [1330]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.107859,	
2017-06-24 01:28:19,066 Epoch[25] Batch [1340]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.107919,	
2017-06-24 01:28:24,258 Epoch[25] Batch [1350]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.107855,	
2017-06-24 01:28:29,893 Epoch[25] Batch [1360]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.107812,	
2017-06-24 01:28:34,743 Epoch[25] Batch [1370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.107798,	
2017-06-24 01:28:40,053 Epoch[25] Batch [1380]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.107794,	
2017-06-24 01:28:45,368 Epoch[25] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.107677,	
2017-06-24 01:28:50,653 Epoch[25] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.107627,	
2017-06-24 01:28:56,374 Epoch[25] Batch [1410]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107549,	
2017-06-24 01:29:02,114 Epoch[25] Batch [1420]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.107501,	
2017-06-24 01:29:07,857 Epoch[25] Batch [1430]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.107490,	
2017-06-24 01:29:13,404 Epoch[25] Batch [1440]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.107396,	
2017-06-24 01:29:18,832 Epoch[25] Batch [1450]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.107368,	
2017-06-24 01:29:24,410 Epoch[25] Batch [1460]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.107394,	
2017-06-24 01:29:29,889 Epoch[25] Batch [1470]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.107431,	
2017-06-24 01:29:35,133 Epoch[25] Batch [1480]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.107441,	
2017-06-24 01:29:38,278 Epoch[25] Train-FCNLogLoss=0.107430
2017-06-24 01:29:38,278 Epoch[25] Time cost=776.764
2017-06-24 01:29:39,080 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0026.params"
2017-06-24 01:29:40,784 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0026.states"
2017-06-24 01:29:46,698 Epoch[26] Batch [10]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089565,	
2017-06-24 01:29:51,690 Epoch[26] Batch [20]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.092457,	
2017-06-24 01:29:57,051 Epoch[26] Batch [30]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094580,	
2017-06-24 01:30:01,833 Epoch[26] Batch [40]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.098813,	
2017-06-24 01:30:06,872 Epoch[26] Batch [50]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.100747,	
2017-06-24 01:30:12,376 Epoch[26] Batch [60]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.101795,	
2017-06-24 01:30:18,128 Epoch[26] Batch [70]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101444,	
2017-06-24 01:30:23,112 Epoch[26] Batch [80]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.100299,	
2017-06-24 01:30:28,442 Epoch[26] Batch [90]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101052,	
2017-06-24 01:30:33,780 Epoch[26] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100941,	
2017-06-24 01:30:39,052 Epoch[26] Batch [110]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100379,	
2017-06-24 01:30:44,002 Epoch[26] Batch [120]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.100411,	
2017-06-24 01:30:49,057 Epoch[26] Batch [130]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.101583,	
2017-06-24 01:30:54,225 Epoch[26] Batch [140]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.101430,	
2017-06-24 01:30:59,348 Epoch[26] Batch [150]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.101645,	
2017-06-24 01:31:04,535 Epoch[26] Batch [160]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.101434,	
2017-06-24 01:31:10,153 Epoch[26] Batch [170]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101770,	
2017-06-24 01:31:15,486 Epoch[26] Batch [180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101808,	
2017-06-24 01:31:20,544 Epoch[26] Batch [190]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.101536,	
2017-06-24 01:31:25,589 Epoch[26] Batch [200]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.100948,	
2017-06-24 01:31:31,708 Epoch[26] Batch [210]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101167,	
2017-06-24 01:31:36,439 Epoch[26] Batch [220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.101103,	
2017-06-24 01:31:42,020 Epoch[26] Batch [230]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.101064,	
2017-06-24 01:31:46,703 Epoch[26] Batch [240]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.100765,	
2017-06-24 01:31:51,803 Epoch[26] Batch [250]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.100959,	
2017-06-24 01:31:56,872 Epoch[26] Batch [260]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.100723,	
2017-06-24 01:32:01,597 Epoch[26] Batch [270]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.100700,	
2017-06-24 01:32:06,207 Epoch[26] Batch [280]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.100968,	
2017-06-24 01:32:11,011 Epoch[26] Batch [290]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.101043,	
2017-06-24 01:32:15,887 Epoch[26] Batch [300]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.100984,	
2017-06-24 01:32:20,643 Epoch[26] Batch [310]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.101207,	
2017-06-24 01:32:25,859 Epoch[26] Batch [320]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.101424,	
2017-06-24 01:32:31,121 Epoch[26] Batch [330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.101606,	
2017-06-24 01:32:35,944 Epoch[26] Batch [340]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.101514,	
2017-06-24 01:32:40,971 Epoch[26] Batch [350]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.101676,	
2017-06-24 01:32:46,009 Epoch[26] Batch [360]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.101824,	
2017-06-24 01:32:50,962 Epoch[26] Batch [370]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.102071,	
2017-06-24 01:32:55,818 Epoch[26] Batch [380]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.101981,	
2017-06-24 01:33:00,810 Epoch[26] Batch [390]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.102196,	
2017-06-24 01:33:05,485 Epoch[26] Batch [400]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.102339,	
2017-06-24 01:33:10,610 Epoch[26] Batch [410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.102411,	
2017-06-24 01:33:15,735 Epoch[26] Batch [420]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.102256,	
2017-06-24 01:33:20,317 Epoch[26] Batch [430]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.102080,	
2017-06-24 01:33:25,488 Epoch[26] Batch [440]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.102030,	
2017-06-24 01:33:30,177 Epoch[26] Batch [450]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.102079,	
2017-06-24 01:33:34,921 Epoch[26] Batch [460]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.101899,	
2017-06-24 01:33:39,682 Epoch[26] Batch [470]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.101624,	
2017-06-24 01:33:44,804 Epoch[26] Batch [480]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.101725,	
2017-06-24 01:33:49,587 Epoch[26] Batch [490]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.102479,	
2017-06-24 01:33:54,399 Epoch[26] Batch [500]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.102638,	
2017-06-24 01:33:59,141 Epoch[26] Batch [510]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.102695,	
2017-06-24 01:34:04,023 Epoch[26] Batch [520]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.102813,	
2017-06-24 01:34:08,496 Epoch[26] Batch [530]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102889,	
2017-06-24 01:34:13,297 Epoch[26] Batch [540]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.102927,	
2017-06-24 01:34:18,314 Epoch[26] Batch [550]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.103027,	
2017-06-24 01:34:23,304 Epoch[26] Batch [560]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.103133,	
2017-06-24 01:34:28,190 Epoch[26] Batch [570]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.103091,	
2017-06-24 01:34:33,238 Epoch[26] Batch [580]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.103066,	
2017-06-24 01:34:38,025 Epoch[26] Batch [590]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.103022,	
2017-06-24 01:34:43,425 Epoch[26] Batch [600]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.103116,	
2017-06-24 01:34:48,486 Epoch[26] Batch [610]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.103046,	
2017-06-24 01:34:53,778 Epoch[26] Batch [620]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.103054,	
2017-06-24 01:34:58,840 Epoch[26] Batch [630]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.102883,	
2017-06-24 01:35:03,555 Epoch[26] Batch [640]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.103010,	
2017-06-24 01:35:08,378 Epoch[26] Batch [650]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.103040,	
2017-06-24 01:35:13,156 Epoch[26] Batch [660]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.103065,	
2017-06-24 01:35:18,402 Epoch[26] Batch [670]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.102965,	
2017-06-24 01:35:23,303 Epoch[26] Batch [680]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.102993,	
2017-06-24 01:35:28,206 Epoch[26] Batch [690]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.103072,	
2017-06-24 01:35:33,244 Epoch[26] Batch [700]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.103087,	
2017-06-24 01:35:38,098 Epoch[26] Batch [710]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.103089,	
2017-06-24 01:35:43,071 Epoch[26] Batch [720]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.103098,	
2017-06-24 01:35:47,765 Epoch[26] Batch [730]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.103278,	
2017-06-24 01:35:52,617 Epoch[26] Batch [740]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.103314,	
2017-06-24 01:35:57,430 Epoch[26] Batch [750]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.103345,	
2017-06-24 01:36:02,729 Epoch[26] Batch [760]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.103345,	
2017-06-24 01:36:07,634 Epoch[26] Batch [770]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.103461,	
2017-06-24 01:36:12,595 Epoch[26] Batch [780]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.103639,	
2017-06-24 01:36:17,470 Epoch[26] Batch [790]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.103497,	
2017-06-24 01:36:22,115 Epoch[26] Batch [800]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.103533,	
2017-06-24 01:36:26,781 Epoch[26] Batch [810]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.103416,	
2017-06-24 01:36:31,972 Epoch[26] Batch [820]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.103417,	
2017-06-24 01:36:36,759 Epoch[26] Batch [830]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.103420,	
2017-06-24 01:36:42,305 Epoch[26] Batch [840]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.103516,	
2017-06-24 01:36:47,454 Epoch[26] Batch [850]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.103575,	
2017-06-24 01:36:52,542 Epoch[26] Batch [860]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.103552,	
2017-06-24 01:36:57,551 Epoch[26] Batch [870]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.103661,	
2017-06-24 01:37:02,471 Epoch[26] Batch [880]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.103777,	
2017-06-24 01:37:07,377 Epoch[26] Batch [890]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.103826,	
2017-06-24 01:37:12,782 Epoch[26] Batch [900]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.103852,	
2017-06-24 01:37:18,181 Epoch[26] Batch [910]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.103751,	
2017-06-24 01:37:23,531 Epoch[26] Batch [920]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103819,	
2017-06-24 01:37:28,931 Epoch[26] Batch [930]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.103880,	
2017-06-24 01:37:34,183 Epoch[26] Batch [940]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.104209,	
2017-06-24 01:37:39,499 Epoch[26] Batch [950]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104300,	
2017-06-24 01:37:44,560 Epoch[26] Batch [960]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.104378,	
2017-06-24 01:37:49,812 Epoch[26] Batch [970]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.104952,	
2017-06-24 01:37:55,117 Epoch[26] Batch [980]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.105029,	
2017-06-24 01:38:00,409 Epoch[26] Batch [990]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.105032,	
2017-06-24 01:38:05,375 Epoch[26] Batch [1000]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.105084,	
2017-06-24 01:38:10,610 Epoch[26] Batch [1010]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.105106,	
2017-06-24 01:38:15,642 Epoch[26] Batch [1020]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.105060,	
2017-06-24 01:38:20,685 Epoch[26] Batch [1030]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.105024,	
2017-06-24 01:38:26,064 Epoch[26] Batch [1040]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.105202,	
2017-06-24 01:38:31,174 Epoch[26] Batch [1050]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.105214,	
2017-06-24 01:38:36,212 Epoch[26] Batch [1060]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.105226,	
2017-06-24 01:38:41,266 Epoch[26] Batch [1070]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.105133,	
2017-06-24 01:38:46,136 Epoch[26] Batch [1080]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.105202,	
2017-06-24 01:38:51,996 Epoch[26] Batch [1090]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.105132,	
2017-06-24 01:38:57,885 Epoch[26] Batch [1100]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.105181,	
2017-06-24 01:39:03,827 Epoch[26] Batch [1110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105104,	
2017-06-24 01:39:09,068 Epoch[26] Batch [1120]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.105028,	
2017-06-24 01:39:14,309 Epoch[26] Batch [1130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.105019,	
2017-06-24 01:39:19,410 Epoch[26] Batch [1140]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.105001,	
2017-06-24 01:39:25,093 Epoch[26] Batch [1150]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.104987,	
2017-06-24 01:39:30,343 Epoch[26] Batch [1160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.104936,	
2017-06-24 01:39:35,578 Epoch[26] Batch [1170]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.104868,	
2017-06-24 01:39:40,478 Epoch[26] Batch [1180]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.104808,	
2017-06-24 01:39:45,947 Epoch[26] Batch [1190]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.104800,	
2017-06-24 01:39:50,820 Epoch[26] Batch [1200]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.104691,	
2017-06-24 01:39:56,025 Epoch[26] Batch [1210]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.104580,	
2017-06-24 01:40:01,136 Epoch[26] Batch [1220]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.104543,	
2017-06-24 01:40:06,397 Epoch[26] Batch [1230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.104603,	
2017-06-24 01:40:11,596 Epoch[26] Batch [1240]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.104544,	
2017-06-24 01:40:16,611 Epoch[26] Batch [1250]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.104409,	
2017-06-24 01:40:21,947 Epoch[26] Batch [1260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.104535,	
2017-06-24 01:40:27,374 Epoch[26] Batch [1270]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.104572,	
2017-06-24 01:40:32,542 Epoch[26] Batch [1280]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.104655,	
2017-06-24 01:40:37,647 Epoch[26] Batch [1290]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.104715,	
2017-06-24 01:40:42,814 Epoch[26] Batch [1300]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.104738,	
2017-06-24 01:40:48,374 Epoch[26] Batch [1310]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.104689,	
2017-06-24 01:40:53,216 Epoch[26] Batch [1320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.104673,	
2017-06-24 01:40:58,337 Epoch[26] Batch [1330]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.104642,	
2017-06-24 01:41:03,261 Epoch[26] Batch [1340]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.104739,	
2017-06-24 01:41:08,967 Epoch[26] Batch [1350]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.104743,	
2017-06-24 01:41:14,643 Epoch[26] Batch [1360]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.104789,	
2017-06-24 01:41:19,967 Epoch[26] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104781,	
2017-06-24 01:41:25,123 Epoch[26] Batch [1380]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.104763,	
2017-06-24 01:41:30,457 Epoch[26] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.104834,	
2017-06-24 01:41:35,201 Epoch[26] Batch [1400]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.104866,	
2017-06-24 01:41:40,306 Epoch[26] Batch [1410]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.104876,	
2017-06-24 01:41:45,842 Epoch[26] Batch [1420]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.104968,	
2017-06-24 01:41:51,237 Epoch[26] Batch [1430]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.104935,	
2017-06-24 01:41:57,103 Epoch[26] Batch [1440]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.104919,	
2017-06-24 01:42:02,723 Epoch[26] Batch [1450]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.104880,	
2017-06-24 01:42:07,930 Epoch[26] Batch [1460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.104868,	
2017-06-24 01:42:12,911 Epoch[26] Batch [1470]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.104871,	
2017-06-24 01:42:18,426 Epoch[26] Batch [1480]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.104935,	
2017-06-24 01:42:21,685 Epoch[26] Train-FCNLogLoss=0.104963
2017-06-24 01:42:21,685 Epoch[26] Time cost=760.900
2017-06-24 01:42:22,618 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0027.params"
2017-06-24 01:42:24,171 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0027.states"
2017-06-24 01:42:30,021 Epoch[27] Batch [10]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.119859,	
2017-06-24 01:42:35,222 Epoch[27] Batch [20]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.113506,	
2017-06-24 01:42:40,564 Epoch[27] Batch [30]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.112279,	
2017-06-24 01:42:45,826 Epoch[27] Batch [40]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112672,	
2017-06-24 01:42:50,678 Epoch[27] Batch [50]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.109024,	
2017-06-24 01:42:55,787 Epoch[27] Batch [60]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.108984,	
2017-06-24 01:43:01,020 Epoch[27] Batch [70]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.106760,	
2017-06-24 01:43:06,236 Epoch[27] Batch [80]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.107430,	
2017-06-24 01:43:11,231 Epoch[27] Batch [90]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.106611,	
2017-06-24 01:43:16,066 Epoch[27] Batch [100]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.106039,	
2017-06-24 01:43:20,880 Epoch[27] Batch [110]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.105987,	
2017-06-24 01:43:25,844 Epoch[27] Batch [120]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.105582,	
2017-06-24 01:43:30,605 Epoch[27] Batch [130]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.105814,	
2017-06-24 01:43:35,192 Epoch[27] Batch [140]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.105512,	
2017-06-24 01:43:40,297 Epoch[27] Batch [150]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.105601,	
2017-06-24 01:43:45,145 Epoch[27] Batch [160]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.105652,	
2017-06-24 01:43:50,101 Epoch[27] Batch [170]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.105537,	
2017-06-24 01:43:55,262 Epoch[27] Batch [180]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.105708,	
2017-06-24 01:44:00,206 Epoch[27] Batch [190]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.105503,	
2017-06-24 01:44:05,063 Epoch[27] Batch [200]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.105022,	
2017-06-24 01:44:09,845 Epoch[27] Batch [210]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.105092,	
2017-06-24 01:44:14,775 Epoch[27] Batch [220]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.105221,	
2017-06-24 01:44:19,811 Epoch[27] Batch [230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.104907,	
2017-06-24 01:44:24,897 Epoch[27] Batch [240]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.104655,	
2017-06-24 01:44:29,593 Epoch[27] Batch [250]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.104635,	
2017-06-24 01:44:34,535 Epoch[27] Batch [260]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.104448,	
2017-06-24 01:44:39,232 Epoch[27] Batch [270]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.104682,	
2017-06-24 01:44:44,535 Epoch[27] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.104717,	
2017-06-24 01:44:49,654 Epoch[27] Batch [290]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.104923,	
2017-06-24 01:44:54,661 Epoch[27] Batch [300]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.104932,	
2017-06-24 01:44:59,301 Epoch[27] Batch [310]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.104708,	
2017-06-24 01:45:04,108 Epoch[27] Batch [320]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.104550,	
2017-06-24 01:45:08,904 Epoch[27] Batch [330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.104429,	
2017-06-24 01:45:13,984 Epoch[27] Batch [340]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.104402,	
2017-06-24 01:45:18,766 Epoch[27] Batch [350]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.104606,	
2017-06-24 01:45:23,659 Epoch[27] Batch [360]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.104534,	
2017-06-24 01:45:28,461 Epoch[27] Batch [370]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.104560,	
2017-06-24 01:45:32,988 Epoch[27] Batch [380]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104369,	
2017-06-24 01:45:37,939 Epoch[27] Batch [390]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.104262,	
2017-06-24 01:45:42,799 Epoch[27] Batch [400]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.104209,	
2017-06-24 01:45:47,863 Epoch[27] Batch [410]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.103871,	
2017-06-24 01:45:52,596 Epoch[27] Batch [420]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.104020,	
2017-06-24 01:45:57,538 Epoch[27] Batch [430]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.103919,	
2017-06-24 01:46:02,345 Epoch[27] Batch [440]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.103874,	
2017-06-24 01:46:07,161 Epoch[27] Batch [450]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.103763,	
2017-06-24 01:46:12,121 Epoch[27] Batch [460]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.103876,	
2017-06-24 01:46:16,873 Epoch[27] Batch [470]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.103743,	
2017-06-24 01:46:21,630 Epoch[27] Batch [480]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.103367,	
2017-06-24 01:46:26,695 Epoch[27] Batch [490]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.103618,	
2017-06-24 01:46:31,189 Epoch[27] Batch [500]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103583,	
2017-06-24 01:46:35,850 Epoch[27] Batch [510]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.103976,	
2017-06-24 01:46:40,958 Epoch[27] Batch [520]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.103875,	
2017-06-24 01:46:45,951 Epoch[27] Batch [530]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.103773,	
2017-06-24 01:46:50,677 Epoch[27] Batch [540]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.103639,	
2017-06-24 01:46:56,043 Epoch[27] Batch [550]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.103565,	
2017-06-24 01:47:00,574 Epoch[27] Batch [560]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.103537,	
2017-06-24 01:47:05,765 Epoch[27] Batch [570]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.103615,	
2017-06-24 01:47:10,502 Epoch[27] Batch [580]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.103648,	
2017-06-24 01:47:15,746 Epoch[27] Batch [590]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.103831,	
2017-06-24 01:47:20,832 Epoch[27] Batch [600]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.103738,	
2017-06-24 01:47:26,347 Epoch[27] Batch [610]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.103781,	
2017-06-24 01:47:31,441 Epoch[27] Batch [620]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.103781,	
2017-06-24 01:47:37,476 Epoch[27] Batch [630]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103773,	
2017-06-24 01:47:42,526 Epoch[27] Batch [640]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.103714,	
2017-06-24 01:47:47,888 Epoch[27] Batch [650]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.103698,	
2017-06-24 01:47:53,076 Epoch[27] Batch [660]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.103683,	
2017-06-24 01:47:57,819 Epoch[27] Batch [670]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.104053,	
2017-06-24 01:48:02,554 Epoch[27] Batch [680]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.104041,	
2017-06-24 01:48:07,271 Epoch[27] Batch [690]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.104095,	
2017-06-24 01:48:12,420 Epoch[27] Batch [700]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.104009,	
2017-06-24 01:48:17,351 Epoch[27] Batch [710]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.104009,	
2017-06-24 01:48:22,407 Epoch[27] Batch [720]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.104055,	
2017-06-24 01:48:28,437 Epoch[27] Batch [730]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103975,	
2017-06-24 01:48:33,400 Epoch[27] Batch [740]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.103992,	
2017-06-24 01:48:39,562 Epoch[27] Batch [750]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103944,	
2017-06-24 01:48:44,980 Epoch[27] Batch [760]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.103988,	
2017-06-24 01:48:50,105 Epoch[27] Batch [770]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.103867,	
2017-06-24 01:48:55,507 Epoch[27] Batch [780]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.104095,	
2017-06-24 01:49:01,373 Epoch[27] Batch [790]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.104129,	
2017-06-24 01:49:06,090 Epoch[27] Batch [800]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.104335,	
2017-06-24 01:49:11,547 Epoch[27] Batch [810]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.104410,	
2017-06-24 01:49:16,742 Epoch[27] Batch [820]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.104497,	
2017-06-24 01:49:21,818 Epoch[27] Batch [830]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.104457,	
2017-06-24 01:49:26,923 Epoch[27] Batch [840]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.104375,	
2017-06-24 01:49:33,244 Epoch[27] Batch [850]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.104440,	
2017-06-24 01:49:38,848 Epoch[27] Batch [860]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.104303,	
2017-06-24 01:49:44,733 Epoch[27] Batch [870]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.104189,	
2017-06-24 01:49:49,751 Epoch[27] Batch [880]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.104225,	
2017-06-24 01:49:55,117 Epoch[27] Batch [890]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.104237,	
2017-06-24 01:50:00,568 Epoch[27] Batch [900]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.104230,	
2017-06-24 01:50:05,672 Epoch[27] Batch [910]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.104156,	
2017-06-24 01:50:11,156 Epoch[27] Batch [920]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.104266,	
2017-06-24 01:50:16,148 Epoch[27] Batch [930]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.104244,	
2017-06-24 01:50:21,311 Epoch[27] Batch [940]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.104407,	
2017-06-24 01:50:26,197 Epoch[27] Batch [950]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.104338,	
2017-06-24 01:50:31,236 Epoch[27] Batch [960]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.104431,	
2017-06-24 01:50:36,166 Epoch[27] Batch [970]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.104475,	
2017-06-24 01:50:41,845 Epoch[27] Batch [980]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.104346,	
2017-06-24 01:50:47,581 Epoch[27] Batch [990]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.104327,	
2017-06-24 01:50:52,892 Epoch[27] Batch [1000]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.104179,	
2017-06-24 01:50:58,473 Epoch[27] Batch [1010]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.104197,	
2017-06-24 01:51:03,606 Epoch[27] Batch [1020]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.104211,	
2017-06-24 01:51:08,686 Epoch[27] Batch [1030]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.104141,	
2017-06-24 01:51:13,451 Epoch[27] Batch [1040]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.104108,	
2017-06-24 01:51:18,343 Epoch[27] Batch [1050]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.104136,	
2017-06-24 01:51:23,802 Epoch[27] Batch [1060]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.104252,	
2017-06-24 01:51:28,920 Epoch[27] Batch [1070]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.104269,	
2017-06-24 01:51:34,144 Epoch[27] Batch [1080]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.104310,	
2017-06-24 01:51:39,603 Epoch[27] Batch [1090]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.104261,	
2017-06-24 01:51:45,558 Epoch[27] Batch [1100]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104202,	
2017-06-24 01:51:51,331 Epoch[27] Batch [1110]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.104202,	
2017-06-24 01:51:56,648 Epoch[27] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104365,	
2017-06-24 01:52:01,671 Epoch[27] Batch [1130]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.104356,	
2017-06-24 01:52:07,076 Epoch[27] Batch [1140]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.104380,	
2017-06-24 01:52:11,707 Epoch[27] Batch [1150]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.104203,	
2017-06-24 01:52:16,792 Epoch[27] Batch [1160]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.104145,	
2017-06-24 01:52:22,516 Epoch[27] Batch [1170]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.104337,	
2017-06-24 01:52:28,034 Epoch[27] Batch [1180]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.104320,	
2017-06-24 01:52:33,390 Epoch[27] Batch [1190]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.104249,	
2017-06-24 01:52:38,582 Epoch[27] Batch [1200]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.104234,	
2017-06-24 01:52:43,823 Epoch[27] Batch [1210]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.104136,	
2017-06-24 01:52:49,074 Epoch[27] Batch [1220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.104134,	
2017-06-24 01:52:54,081 Epoch[27] Batch [1230]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.104086,	
2017-06-24 01:52:58,974 Epoch[27] Batch [1240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.104053,	
2017-06-24 01:53:03,921 Epoch[27] Batch [1250]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.103960,	
2017-06-24 01:53:09,214 Epoch[27] Batch [1260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.103878,	
2017-06-24 01:53:14,412 Epoch[27] Batch [1270]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.103860,	
2017-06-24 01:53:19,450 Epoch[27] Batch [1280]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.103815,	
2017-06-24 01:53:24,596 Epoch[27] Batch [1290]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.103830,	
2017-06-24 01:53:29,898 Epoch[27] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.103747,	
2017-06-24 01:53:35,184 Epoch[27] Batch [1310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.103785,	
2017-06-24 01:53:40,337 Epoch[27] Batch [1320]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.103788,	
2017-06-24 01:53:46,109 Epoch[27] Batch [1330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103774,	
2017-06-24 01:53:51,771 Epoch[27] Batch [1340]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.103807,	
2017-06-24 01:53:56,822 Epoch[27] Batch [1350]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.103787,	
2017-06-24 01:54:02,028 Epoch[27] Batch [1360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.103742,	
2017-06-24 01:54:07,537 Epoch[27] Batch [1370]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.103755,	
2017-06-24 01:54:12,163 Epoch[27] Batch [1380]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.103742,	
2017-06-24 01:54:17,305 Epoch[27] Batch [1390]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.103650,	
2017-06-24 01:54:22,105 Epoch[27] Batch [1400]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.103579,	
2017-06-24 01:54:27,074 Epoch[27] Batch [1410]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.103602,	
2017-06-24 01:54:32,099 Epoch[27] Batch [1420]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.103594,	
2017-06-24 01:54:37,026 Epoch[27] Batch [1430]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.103554,	
2017-06-24 01:54:42,123 Epoch[27] Batch [1440]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.103494,	
2017-06-24 01:54:47,333 Epoch[27] Batch [1450]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.103415,	
2017-06-24 01:54:52,603 Epoch[27] Batch [1460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.103429,	
2017-06-24 01:54:57,404 Epoch[27] Batch [1470]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.103368,	
2017-06-24 01:55:02,320 Epoch[27] Batch [1480]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.103333,	
2017-06-24 01:55:05,249 Epoch[27] Train-FCNLogLoss=0.103283
2017-06-24 01:55:05,249 Epoch[27] Time cost=761.077
2017-06-24 01:55:06,022 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0028.params"
2017-06-24 01:55:07,728 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0028.states"
2017-06-24 01:55:13,551 Epoch[28] Batch [10]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.092101,	
2017-06-24 01:55:18,474 Epoch[28] Batch [20]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.099815,	
2017-06-24 01:55:23,466 Epoch[28] Batch [30]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.099943,	
2017-06-24 01:55:28,496 Epoch[28] Batch [40]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.104053,	
2017-06-24 01:55:33,182 Epoch[28] Batch [50]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.103140,	
2017-06-24 01:55:38,139 Epoch[28] Batch [60]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.104259,	
2017-06-24 01:55:43,053 Epoch[28] Batch [70]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.105060,	
2017-06-24 01:55:48,067 Epoch[28] Batch [80]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.106222,	
2017-06-24 01:55:53,003 Epoch[28] Batch [90]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.105374,	
2017-06-24 01:55:58,120 Epoch[28] Batch [100]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.106142,	
2017-06-24 01:56:02,815 Epoch[28] Batch [110]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.104854,	
2017-06-24 01:56:08,195 Epoch[28] Batch [120]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.104473,	
2017-06-24 01:56:13,219 Epoch[28] Batch [130]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.104719,	
2017-06-24 01:56:18,785 Epoch[28] Batch [140]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.105258,	
2017-06-24 01:56:24,255 Epoch[28] Batch [150]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.104371,	
2017-06-24 01:56:29,543 Epoch[28] Batch [160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.104097,	
2017-06-24 01:56:34,624 Epoch[28] Batch [170]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.103623,	
2017-06-24 01:56:39,642 Epoch[28] Batch [180]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.103056,	
2017-06-24 01:56:44,703 Epoch[28] Batch [190]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.103302,	
2017-06-24 01:56:49,895 Epoch[28] Batch [200]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.103116,	
2017-06-24 01:56:54,469 Epoch[28] Batch [210]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.102936,	
2017-06-24 01:56:59,555 Epoch[28] Batch [220]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.102928,	
2017-06-24 01:57:04,548 Epoch[28] Batch [230]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.102729,	
2017-06-24 01:57:09,316 Epoch[28] Batch [240]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.102374,	
2017-06-24 01:57:14,359 Epoch[28] Batch [250]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.102092,	
2017-06-24 01:57:19,294 Epoch[28] Batch [260]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.101766,	
2017-06-24 01:57:24,367 Epoch[28] Batch [270]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.101555,	
2017-06-24 01:57:29,048 Epoch[28] Batch [280]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.101439,	
2017-06-24 01:57:33,970 Epoch[28] Batch [290]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.101484,	
2017-06-24 01:57:39,137 Epoch[28] Batch [300]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.101189,	
2017-06-24 01:57:44,323 Epoch[28] Batch [310]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.100960,	
2017-06-24 01:57:49,358 Epoch[28] Batch [320]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.100641,	
2017-06-24 01:57:54,261 Epoch[28] Batch [330]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.100604,	
2017-06-24 01:57:59,126 Epoch[28] Batch [340]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.100817,	
2017-06-24 01:58:03,884 Epoch[28] Batch [350]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.100954,	
2017-06-24 01:58:08,596 Epoch[28] Batch [360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.100850,	
2017-06-24 01:58:13,614 Epoch[28] Batch [370]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.100930,	
2017-06-24 01:58:18,690 Epoch[28] Batch [380]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.100838,	
2017-06-24 01:58:23,740 Epoch[28] Batch [390]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.100869,	
2017-06-24 01:58:28,451 Epoch[28] Batch [400]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.100684,	
2017-06-24 01:58:33,946 Epoch[28] Batch [410]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.100873,	
2017-06-24 01:58:38,710 Epoch[28] Batch [420]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.101046,	
2017-06-24 01:58:43,463 Epoch[28] Batch [430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.101261,	
2017-06-24 01:58:48,880 Epoch[28] Batch [440]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.101330,	
2017-06-24 01:58:54,673 Epoch[28] Batch [450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101306,	
2017-06-24 01:58:59,950 Epoch[28] Batch [460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-24 01:59:04,874 Epoch[28] Batch [470]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.101365,	
2017-06-24 01:59:10,297 Epoch[28] Batch [480]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.101228,	
2017-06-24 01:59:15,825 Epoch[28] Batch [490]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.101220,	
2017-06-24 01:59:21,066 Epoch[28] Batch [500]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.101184,	
2017-06-24 01:59:26,293 Epoch[28] Batch [510]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.101377,	
2017-06-24 01:59:31,316 Epoch[28] Batch [520]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.101405,	
2017-06-24 01:59:36,433 Epoch[28] Batch [530]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.101694,	
2017-06-24 01:59:41,810 Epoch[28] Batch [540]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.101671,	
2017-06-24 01:59:47,026 Epoch[28] Batch [550]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.101388,	
2017-06-24 01:59:52,487 Epoch[28] Batch [560]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.101513,	
2017-06-24 01:59:57,643 Epoch[28] Batch [570]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.101456,	
2017-06-24 02:00:02,683 Epoch[28] Batch [580]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.101710,	
2017-06-24 02:00:08,576 Epoch[28] Batch [590]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.101573,	
2017-06-24 02:00:13,525 Epoch[28] Batch [600]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.101517,	
2017-06-24 02:00:19,162 Epoch[28] Batch [610]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.101430,	
2017-06-24 02:00:24,501 Epoch[28] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101446,	
2017-06-24 02:00:29,410 Epoch[28] Batch [630]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.101447,	
2017-06-24 02:00:34,469 Epoch[28] Batch [640]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.101289,	
2017-06-24 02:00:39,856 Epoch[28] Batch [650]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101515,	
2017-06-24 02:00:44,760 Epoch[28] Batch [660]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.101559,	
2017-06-24 02:00:49,984 Epoch[28] Batch [670]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.101525,	
2017-06-24 02:00:55,101 Epoch[28] Batch [680]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.101497,	
2017-06-24 02:01:00,431 Epoch[28] Batch [690]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101571,	
2017-06-24 02:01:05,737 Epoch[28] Batch [700]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101377,	
2017-06-24 02:01:10,649 Epoch[28] Batch [710]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.101471,	
2017-06-24 02:01:16,030 Epoch[28] Batch [720]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101453,	
2017-06-24 02:01:22,073 Epoch[28] Batch [730]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101294,	
2017-06-24 02:01:28,449 Epoch[28] Batch [740]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.101748,	
2017-06-24 02:01:33,987 Epoch[28] Batch [750]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.101760,	
2017-06-24 02:01:38,891 Epoch[28] Batch [760]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.101697,	
2017-06-24 02:01:44,009 Epoch[28] Batch [770]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.101716,	
2017-06-24 02:01:48,673 Epoch[28] Batch [780]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.101706,	
2017-06-24 02:01:53,708 Epoch[28] Batch [790]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.101738,	
2017-06-24 02:01:58,639 Epoch[28] Batch [800]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.101764,	
2017-06-24 02:02:03,548 Epoch[28] Batch [810]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.101782,	
2017-06-24 02:02:08,559 Epoch[28] Batch [820]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.101782,	
2017-06-24 02:02:13,789 Epoch[28] Batch [830]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.101818,	
2017-06-24 02:02:18,784 Epoch[28] Batch [840]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.101776,	
2017-06-24 02:02:24,020 Epoch[28] Batch [850]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.101762,	
2017-06-24 02:02:29,025 Epoch[28] Batch [860]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.101865,	
2017-06-24 02:02:33,786 Epoch[28] Batch [870]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.101734,	
2017-06-24 02:02:38,937 Epoch[28] Batch [880]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.101545,	
2017-06-24 02:02:44,099 Epoch[28] Batch [890]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.101683,	
2017-06-24 02:02:49,092 Epoch[28] Batch [900]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.101853,	
2017-06-24 02:02:53,931 Epoch[28] Batch [910]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.101881,	
2017-06-24 02:02:58,945 Epoch[28] Batch [920]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.101748,	
2017-06-24 02:03:03,909 Epoch[28] Batch [930]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.101645,	
2017-06-24 02:03:08,971 Epoch[28] Batch [940]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.101865,	
2017-06-24 02:03:14,117 Epoch[28] Batch [950]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.101777,	
2017-06-24 02:03:19,066 Epoch[28] Batch [960]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.101773,	
2017-06-24 02:03:23,990 Epoch[28] Batch [970]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.101890,	
2017-06-24 02:03:29,017 Epoch[28] Batch [980]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.101821,	
2017-06-24 02:03:34,072 Epoch[28] Batch [990]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.101758,	
2017-06-24 02:03:39,385 Epoch[28] Batch [1000]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.101672,	
2017-06-24 02:03:44,742 Epoch[28] Batch [1010]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101568,	
2017-06-24 02:03:49,433 Epoch[28] Batch [1020]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.101603,	
2017-06-24 02:03:54,678 Epoch[28] Batch [1030]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.101600,	
2017-06-24 02:03:59,536 Epoch[28] Batch [1040]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.101543,	
2017-06-24 02:04:04,869 Epoch[28] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101509,	
2017-06-24 02:04:10,046 Epoch[28] Batch [1060]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.101591,	
2017-06-24 02:04:16,282 Epoch[28] Batch [1070]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.101524,	
2017-06-24 02:04:22,483 Epoch[28] Batch [1080]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.101436,	
2017-06-24 02:04:27,417 Epoch[28] Batch [1090]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.101456,	
2017-06-24 02:04:33,000 Epoch[28] Batch [1100]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.101569,	
2017-06-24 02:04:37,837 Epoch[28] Batch [1110]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.101529,	
2017-06-24 02:04:43,559 Epoch[28] Batch [1120]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.101480,	
2017-06-24 02:04:48,454 Epoch[28] Batch [1130]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.101451,	
2017-06-24 02:04:53,496 Epoch[28] Batch [1140]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.101400,	
2017-06-24 02:04:58,322 Epoch[28] Batch [1150]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.101386,	
2017-06-24 02:05:03,422 Epoch[28] Batch [1160]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.101352,	
2017-06-24 02:05:08,380 Epoch[28] Batch [1170]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.101327,	
2017-06-24 02:05:13,644 Epoch[28] Batch [1180]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.101378,	
2017-06-24 02:05:19,264 Epoch[28] Batch [1190]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101421,	
2017-06-24 02:05:24,075 Epoch[28] Batch [1200]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.101417,	
2017-06-24 02:05:29,283 Epoch[28] Batch [1210]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.101363,	
2017-06-24 02:05:34,254 Epoch[28] Batch [1220]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.101381,	
2017-06-24 02:05:39,483 Epoch[28] Batch [1230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.101397,	
2017-06-24 02:05:44,728 Epoch[28] Batch [1240]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.101395,	
2017-06-24 02:05:49,520 Epoch[28] Batch [1250]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.101391,	
2017-06-24 02:05:54,562 Epoch[28] Batch [1260]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.101394,	
2017-06-24 02:05:59,349 Epoch[28] Batch [1270]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.101433,	
2017-06-24 02:06:04,676 Epoch[28] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101424,	
2017-06-24 02:06:09,483 Epoch[28] Batch [1290]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.101426,	
2017-06-24 02:06:14,231 Epoch[28] Batch [1300]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.101440,	
2017-06-24 02:06:19,040 Epoch[28] Batch [1310]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.101437,	
2017-06-24 02:06:23,841 Epoch[28] Batch [1320]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.101414,	
2017-06-24 02:06:28,637 Epoch[28] Batch [1330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.101447,	
2017-06-24 02:06:33,676 Epoch[28] Batch [1340]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.101446,	
2017-06-24 02:06:38,384 Epoch[28] Batch [1350]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.101421,	
2017-06-24 02:06:43,415 Epoch[28] Batch [1360]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.101421,	
2017-06-24 02:06:48,844 Epoch[28] Batch [1370]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.101396,	
2017-06-24 02:06:53,714 Epoch[28] Batch [1380]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.101361,	
2017-06-24 02:06:58,518 Epoch[28] Batch [1390]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.101371,	
2017-06-24 02:07:03,257 Epoch[28] Batch [1400]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.101391,	
2017-06-24 02:07:08,021 Epoch[28] Batch [1410]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.101343,	
2017-06-24 02:07:12,977 Epoch[28] Batch [1420]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.101252,	
2017-06-24 02:07:17,680 Epoch[28] Batch [1430]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.101256,	
2017-06-24 02:07:22,330 Epoch[28] Batch [1440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.101278,	
2017-06-24 02:07:27,151 Epoch[28] Batch [1450]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.101258,	
2017-06-24 02:07:32,337 Epoch[28] Batch [1460]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.101192,	
2017-06-24 02:07:37,197 Epoch[28] Batch [1470]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.101224,	
2017-06-24 02:07:41,841 Epoch[28] Batch [1480]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.101208,	
2017-06-24 02:07:44,672 Epoch[28] Train-FCNLogLoss=0.101183
2017-06-24 02:07:44,672 Epoch[28] Time cost=756.943
2017-06-24 02:07:45,446 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0029.params"
2017-06-24 02:07:47,287 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0029.states"
2017-06-24 02:07:53,236 Epoch[29] Batch [10]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.096080,	
2017-06-24 02:07:57,739 Epoch[29] Batch [20]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.100074,	
2017-06-24 02:08:02,612 Epoch[29] Batch [30]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.098874,	
2017-06-24 02:08:07,536 Epoch[29] Batch [40]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.098252,	
2017-06-24 02:08:12,990 Epoch[29] Batch [50]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.098521,	
2017-06-24 02:08:18,079 Epoch[29] Batch [60]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.098340,	
2017-06-24 02:08:23,048 Epoch[29] Batch [70]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.098075,	
2017-06-24 02:08:28,061 Epoch[29] Batch [80]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.098052,	
2017-06-24 02:08:32,727 Epoch[29] Batch [90]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.097843,	
2017-06-24 02:08:37,590 Epoch[29] Batch [100]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.099468,	
2017-06-24 02:08:42,538 Epoch[29] Batch [110]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.099567,	
2017-06-24 02:08:47,542 Epoch[29] Batch [120]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.099271,	
2017-06-24 02:08:52,789 Epoch[29] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.099422,	
2017-06-24 02:08:57,642 Epoch[29] Batch [140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.099265,	
2017-06-24 02:09:02,404 Epoch[29] Batch [150]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.099069,	
2017-06-24 02:09:07,191 Epoch[29] Batch [160]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.099074,	
2017-06-24 02:09:12,083 Epoch[29] Batch [170]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.098993,	
2017-06-24 02:09:16,869 Epoch[29] Batch [180]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.098744,	
2017-06-24 02:09:21,871 Epoch[29] Batch [190]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098472,	
2017-06-24 02:09:26,877 Epoch[29] Batch [200]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.099247,	
2017-06-24 02:09:31,416 Epoch[29] Batch [210]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.099511,	
2017-06-24 02:09:36,156 Epoch[29] Batch [220]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.098713,	
2017-06-24 02:09:40,967 Epoch[29] Batch [230]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.098982,	
2017-06-24 02:09:45,667 Epoch[29] Batch [240]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.098712,	
2017-06-24 02:09:50,357 Epoch[29] Batch [250]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.098719,	
2017-06-24 02:09:55,850 Epoch[29] Batch [260]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098871,	
2017-06-24 02:10:02,751 Epoch[29] Batch [270]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.098777,	
2017-06-24 02:10:08,951 Epoch[29] Batch [280]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.098622,	
2017-06-24 02:10:14,531 Epoch[29] Batch [290]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.099108,	
2017-06-24 02:10:20,006 Epoch[29] Batch [300]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.099369,	
2017-06-24 02:10:25,328 Epoch[29] Batch [310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099884,	
2017-06-24 02:10:31,026 Epoch[29] Batch [320]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.099787,	
2017-06-24 02:10:36,882 Epoch[29] Batch [330]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099833,	
2017-06-24 02:10:42,584 Epoch[29] Batch [340]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.099668,	
2017-06-24 02:10:48,042 Epoch[29] Batch [350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.099797,	
2017-06-24 02:10:53,185 Epoch[29] Batch [360]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.099874,	
2017-06-24 02:10:58,586 Epoch[29] Batch [370]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.100065,	
2017-06-24 02:11:04,024 Epoch[29] Batch [380]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.099870,	
2017-06-24 02:11:09,006 Epoch[29] Batch [390]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.099663,	
2017-06-24 02:11:14,127 Epoch[29] Batch [400]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.099597,	
2017-06-24 02:11:19,381 Epoch[29] Batch [410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099890,	
2017-06-24 02:11:25,287 Epoch[29] Batch [420]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099891,	
2017-06-24 02:11:30,672 Epoch[29] Batch [430]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.099888,	
2017-06-24 02:11:36,081 Epoch[29] Batch [440]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.099588,	
2017-06-24 02:11:41,095 Epoch[29] Batch [450]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.099500,	
2017-06-24 02:11:45,975 Epoch[29] Batch [460]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.099620,	
2017-06-24 02:11:51,363 Epoch[29] Batch [470]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.099613,	
2017-06-24 02:11:56,425 Epoch[29] Batch [480]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.099622,	
2017-06-24 02:12:01,800 Epoch[29] Batch [490]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099655,	
2017-06-24 02:12:07,043 Epoch[29] Batch [500]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.099650,	
2017-06-24 02:12:12,431 Epoch[29] Batch [510]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.099601,	
2017-06-24 02:12:17,646 Epoch[29] Batch [520]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099689,	
2017-06-24 02:12:22,809 Epoch[29] Batch [530]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.099605,	
2017-06-24 02:12:27,977 Epoch[29] Batch [540]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.099479,	
2017-06-24 02:12:33,082 Epoch[29] Batch [550]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099449,	
2017-06-24 02:12:38,795 Epoch[29] Batch [560]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.099285,	
2017-06-24 02:12:44,595 Epoch[29] Batch [570]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099364,	
2017-06-24 02:12:50,670 Epoch[29] Batch [580]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-24 02:12:56,977 Epoch[29] Batch [590]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.099280,	
2017-06-24 02:13:02,523 Epoch[29] Batch [600]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.099421,	
2017-06-24 02:13:08,080 Epoch[29] Batch [610]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.099374,	
2017-06-24 02:13:13,447 Epoch[29] Batch [620]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.099494,	
2017-06-24 02:13:18,882 Epoch[29] Batch [630]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.099461,	
2017-06-24 02:13:24,544 Epoch[29] Batch [640]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.099369,	
2017-06-24 02:13:29,739 Epoch[29] Batch [650]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099414,	
2017-06-24 02:13:35,705 Epoch[29] Batch [660]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099568,	
2017-06-24 02:13:41,518 Epoch[29] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099731,	
2017-06-24 02:13:46,597 Epoch[29] Batch [680]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.099852,	
2017-06-24 02:13:51,817 Epoch[29] Batch [690]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099938,	
2017-06-24 02:13:56,786 Epoch[29] Batch [700]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.099951,	
2017-06-24 02:14:02,513 Epoch[29] Batch [710]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099918,	
2017-06-24 02:14:07,758 Epoch[29] Batch [720]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.099898,	
2017-06-24 02:14:12,766 Epoch[29] Batch [730]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.099880,	
2017-06-24 02:14:17,909 Epoch[29] Batch [740]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.099899,	
2017-06-24 02:14:23,288 Epoch[29] Batch [750]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.100104,	
2017-06-24 02:14:28,496 Epoch[29] Batch [760]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.100094,	
2017-06-24 02:14:34,125 Epoch[29] Batch [770]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.099991,	
2017-06-24 02:14:39,345 Epoch[29] Batch [780]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099876,	
2017-06-24 02:14:44,546 Epoch[29] Batch [790]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099890,	
2017-06-24 02:14:50,006 Epoch[29] Batch [800]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.099814,	
2017-06-24 02:14:55,228 Epoch[29] Batch [810]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099828,	
2017-06-24 02:15:00,496 Epoch[29] Batch [820]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099824,	
2017-06-24 02:15:06,175 Epoch[29] Batch [830]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.099657,	
2017-06-24 02:15:11,217 Epoch[29] Batch [840]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.099722,	
2017-06-24 02:15:16,592 Epoch[29] Batch [850]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099713,	
2017-06-24 02:15:22,276 Epoch[29] Batch [860]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.099749,	
2017-06-24 02:15:27,426 Epoch[29] Batch [870]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.099720,	
2017-06-24 02:15:32,566 Epoch[29] Batch [880]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.099739,	
2017-06-24 02:15:38,124 Epoch[29] Batch [890]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.099660,	
2017-06-24 02:15:43,531 Epoch[29] Batch [900]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.099576,	
2017-06-24 02:15:48,485 Epoch[29] Batch [910]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.099586,	
2017-06-24 02:15:53,463 Epoch[29] Batch [920]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.099576,	
2017-06-24 02:15:58,475 Epoch[29] Batch [930]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.099693,	
2017-06-24 02:16:03,479 Epoch[29] Batch [940]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.099824,	
2017-06-24 02:16:08,126 Epoch[29] Batch [950]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.099668,	
2017-06-24 02:16:12,752 Epoch[29] Batch [960]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.099664,	
2017-06-24 02:16:17,738 Epoch[29] Batch [970]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.099461,	
2017-06-24 02:16:23,128 Epoch[29] Batch [980]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.099541,	
2017-06-24 02:16:28,301 Epoch[29] Batch [990]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099410,	
2017-06-24 02:16:33,187 Epoch[29] Batch [1000]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.099326,	
2017-06-24 02:16:37,832 Epoch[29] Batch [1010]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.099333,	
2017-06-24 02:16:43,278 Epoch[29] Batch [1020]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.099417,	
2017-06-24 02:16:48,025 Epoch[29] Batch [1030]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099449,	
2017-06-24 02:16:52,754 Epoch[29] Batch [1040]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.099408,	
2017-06-24 02:16:57,756 Epoch[29] Batch [1050]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.099432,	
2017-06-24 02:17:02,445 Epoch[29] Batch [1060]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.099442,	
2017-06-24 02:17:07,677 Epoch[29] Batch [1070]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.099462,	
2017-06-24 02:17:12,463 Epoch[29] Batch [1080]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.099413,	
2017-06-24 02:17:17,260 Epoch[29] Batch [1090]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.099366,	
2017-06-24 02:17:22,066 Epoch[29] Batch [1100]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.099292,	
2017-06-24 02:17:28,123 Epoch[29] Batch [1110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099318,	
2017-06-24 02:17:33,228 Epoch[29] Batch [1120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099258,	
2017-06-24 02:17:38,763 Epoch[29] Batch [1130]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.099145,	
2017-06-24 02:17:43,998 Epoch[29] Batch [1140]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099207,	
2017-06-24 02:17:48,846 Epoch[29] Batch [1150]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.099138,	
2017-06-24 02:17:54,125 Epoch[29] Batch [1160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099103,	
2017-06-24 02:17:59,264 Epoch[29] Batch [1170]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.099240,	
2017-06-24 02:18:04,459 Epoch[29] Batch [1180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099282,	
2017-06-24 02:18:09,637 Epoch[29] Batch [1190]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099266,	
2017-06-24 02:18:15,309 Epoch[29] Batch [1200]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.099158,	
2017-06-24 02:18:20,129 Epoch[29] Batch [1210]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.099224,	
2017-06-24 02:18:25,513 Epoch[29] Batch [1220]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-24 02:18:30,747 Epoch[29] Batch [1230]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099291,	
2017-06-24 02:18:35,535 Epoch[29] Batch [1240]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.099214,	
2017-06-24 02:18:40,584 Epoch[29] Batch [1250]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.099258,	
2017-06-24 02:18:45,596 Epoch[29] Batch [1260]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.099201,	
2017-06-24 02:18:50,440 Epoch[29] Batch [1270]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.099200,	
2017-06-24 02:18:55,457 Epoch[29] Batch [1280]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.099226,	
2017-06-24 02:19:00,452 Epoch[29] Batch [1290]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.099281,	
2017-06-24 02:19:05,347 Epoch[29] Batch [1300]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.099236,	
2017-06-24 02:19:10,585 Epoch[29] Batch [1310]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099219,	
2017-06-24 02:19:15,410 Epoch[29] Batch [1320]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.099276,	
2017-06-24 02:19:20,264 Epoch[29] Batch [1330]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.099319,	
2017-06-24 02:19:25,107 Epoch[29] Batch [1340]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.099307,	
2017-06-24 02:19:29,925 Epoch[29] Batch [1350]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.099326,	
2017-06-24 02:19:34,652 Epoch[29] Batch [1360]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.099285,	
2017-06-24 02:19:39,579 Epoch[29] Batch [1370]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.099230,	
2017-06-24 02:19:44,587 Epoch[29] Batch [1380]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.099341,	
2017-06-24 02:19:49,392 Epoch[29] Batch [1390]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.099377,	
2017-06-24 02:19:53,999 Epoch[29] Batch [1400]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.099324,	
2017-06-24 02:19:59,243 Epoch[29] Batch [1410]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.099347,	
2017-06-24 02:20:04,182 Epoch[29] Batch [1420]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.099421,	
2017-06-24 02:20:09,134 Epoch[29] Batch [1430]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.099439,	
2017-06-24 02:20:13,953 Epoch[29] Batch [1440]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.099449,	
2017-06-24 02:20:18,574 Epoch[29] Batch [1450]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.099560,	
2017-06-24 02:20:23,625 Epoch[29] Batch [1460]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.099554,	
2017-06-24 02:20:28,373 Epoch[29] Batch [1470]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099551,	
2017-06-24 02:20:33,282 Epoch[29] Batch [1480]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.099507,	
2017-06-24 02:20:36,361 Epoch[29] Train-FCNLogLoss=0.099533
2017-06-24 02:20:36,361 Epoch[29] Time cost=769.073
2017-06-24 02:20:37,164 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0030.params"
2017-06-24 02:20:38,769 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0030.states"
2017-06-24 02:20:44,552 Epoch[30] Batch [10]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.104485,	
2017-06-24 02:20:49,994 Epoch[30] Batch [20]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.098234,	
2017-06-24 02:20:55,513 Epoch[30] Batch [30]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.100659,	
2017-06-24 02:21:01,090 Epoch[30] Batch [40]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098569,	
2017-06-24 02:21:06,025 Epoch[30] Batch [50]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.099462,	
2017-06-24 02:21:11,483 Epoch[30] Batch [60]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.099955,	
2017-06-24 02:21:16,588 Epoch[30] Batch [70]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.097826,	
2017-06-24 02:21:22,125 Epoch[30] Batch [80]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098083,	
2017-06-24 02:21:27,124 Epoch[30] Batch [90]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098012,	
2017-06-24 02:21:32,076 Epoch[30] Batch [100]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.098819,	
2017-06-24 02:21:37,492 Epoch[30] Batch [110]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.098864,	
2017-06-24 02:21:42,972 Epoch[30] Batch [120]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.098863,	
2017-06-24 02:21:48,770 Epoch[30] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098770,	
2017-06-24 02:21:53,826 Epoch[30] Batch [140]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.098173,	
2017-06-24 02:21:59,247 Epoch[30] Batch [150]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.097394,	
2017-06-24 02:22:04,300 Epoch[30] Batch [160]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.096859,	
2017-06-24 02:22:09,895 Epoch[30] Batch [170]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.096093,	
2017-06-24 02:22:15,571 Epoch[30] Batch [180]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.096192,	
2017-06-24 02:22:20,701 Epoch[30] Batch [190]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.095878,	
2017-06-24 02:22:25,525 Epoch[30] Batch [200]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.096353,	
2017-06-24 02:22:30,738 Epoch[30] Batch [210]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096644,	
2017-06-24 02:22:35,989 Epoch[30] Batch [220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096747,	
2017-06-24 02:22:41,559 Epoch[30] Batch [230]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.097174,	
2017-06-24 02:22:46,662 Epoch[30] Batch [240]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.097436,	
2017-06-24 02:22:52,400 Epoch[30] Batch [250]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.097944,	
2017-06-24 02:22:57,777 Epoch[30] Batch [260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097599,	
2017-06-24 02:23:03,384 Epoch[30] Batch [270]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.097658,	
2017-06-24 02:23:08,776 Epoch[30] Batch [280]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097458,	
2017-06-24 02:23:13,823 Epoch[30] Batch [290]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.097526,	
2017-06-24 02:23:19,224 Epoch[30] Batch [300]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097729,	
2017-06-24 02:23:25,171 Epoch[30] Batch [310]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.097659,	
2017-06-24 02:23:30,370 Epoch[30] Batch [320]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-24 02:23:35,235 Epoch[30] Batch [330]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.097762,	
2017-06-24 02:23:40,475 Epoch[30] Batch [340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097771,	
2017-06-24 02:23:45,443 Epoch[30] Batch [350]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.097664,	
2017-06-24 02:23:50,480 Epoch[30] Batch [360]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.097741,	
2017-06-24 02:23:55,550 Epoch[30] Batch [370]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.097699,	
2017-06-24 02:24:00,583 Epoch[30] Batch [380]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.097479,	
2017-06-24 02:24:05,757 Epoch[30] Batch [390]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.097224,	
2017-06-24 02:24:10,978 Epoch[30] Batch [400]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.097657,	
2017-06-24 02:24:16,161 Epoch[30] Batch [410]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097903,	
2017-06-24 02:24:21,391 Epoch[30] Batch [420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098050,	
2017-06-24 02:24:27,326 Epoch[30] Batch [430]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.098292,	
2017-06-24 02:24:32,946 Epoch[30] Batch [440]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.098221,	
2017-06-24 02:24:38,180 Epoch[30] Batch [450]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.098088,	
2017-06-24 02:24:43,565 Epoch[30] Batch [460]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098247,	
2017-06-24 02:24:48,866 Epoch[30] Batch [470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098020,	
2017-06-24 02:24:54,471 Epoch[30] Batch [480]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098053,	
2017-06-24 02:24:59,717 Epoch[30] Batch [490]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098245,	
2017-06-24 02:25:05,995 Epoch[30] Batch [500]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.098514,	
2017-06-24 02:25:11,266 Epoch[30] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.098501,	
2017-06-24 02:25:16,508 Epoch[30] Batch [520]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.098509,	
2017-06-24 02:25:22,367 Epoch[30] Batch [530]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098535,	
2017-06-24 02:25:27,964 Epoch[30] Batch [540]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098671,	
2017-06-24 02:25:33,157 Epoch[30] Batch [550]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098649,	
2017-06-24 02:25:39,064 Epoch[30] Batch [560]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.098605,	
2017-06-24 02:25:44,848 Epoch[30] Batch [570]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098545,	
2017-06-24 02:25:49,838 Epoch[30] Batch [580]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.098502,	
2017-06-24 02:25:55,006 Epoch[30] Batch [590]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.098504,	
2017-06-24 02:26:00,121 Epoch[30] Batch [600]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.098635,	
2017-06-24 02:26:05,466 Epoch[30] Batch [610]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098617,	
2017-06-24 02:26:10,657 Epoch[30] Batch [620]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098626,	
2017-06-24 02:26:16,161 Epoch[30] Batch [630]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.098719,	
2017-06-24 02:26:21,044 Epoch[30] Batch [640]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.098807,	
2017-06-24 02:26:26,102 Epoch[30] Batch [650]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.098736,	
2017-06-24 02:26:30,927 Epoch[30] Batch [660]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.098718,	
2017-06-24 02:26:35,917 Epoch[30] Batch [670]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.098618,	
2017-06-24 02:26:40,718 Epoch[30] Batch [680]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.098640,	
2017-06-24 02:26:45,584 Epoch[30] Batch [690]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.098678,	
2017-06-24 02:26:50,495 Epoch[30] Batch [700]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.098596,	
2017-06-24 02:26:55,407 Epoch[30] Batch [710]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.098650,	
2017-06-24 02:27:00,236 Epoch[30] Batch [720]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.098576,	
2017-06-24 02:27:05,350 Epoch[30] Batch [730]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.098741,	
2017-06-24 02:27:10,349 Epoch[30] Batch [740]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098847,	
2017-06-24 02:27:15,326 Epoch[30] Batch [750]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.098871,	
2017-06-24 02:27:20,043 Epoch[30] Batch [760]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.098926,	
2017-06-24 02:27:24,920 Epoch[30] Batch [770]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.098841,	
2017-06-24 02:27:29,696 Epoch[30] Batch [780]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.098890,	
2017-06-24 02:27:34,750 Epoch[30] Batch [790]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.098714,	
2017-06-24 02:27:39,419 Epoch[30] Batch [800]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.098862,	
2017-06-24 02:27:44,458 Epoch[30] Batch [810]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.098969,	
2017-06-24 02:27:49,552 Epoch[30] Batch [820]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.099058,	
2017-06-24 02:27:54,563 Epoch[30] Batch [830]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.099087,	
2017-06-24 02:27:59,607 Epoch[30] Batch [840]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.099160,	
2017-06-24 02:28:04,476 Epoch[30] Batch [850]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.099112,	
2017-06-24 02:28:09,365 Epoch[30] Batch [860]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-24 02:28:14,167 Epoch[30] Batch [870]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.099149,	
2017-06-24 02:28:19,494 Epoch[30] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099180,	
2017-06-24 02:28:24,423 Epoch[30] Batch [890]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.099338,	
2017-06-24 02:28:29,416 Epoch[30] Batch [900]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.099360,	
2017-06-24 02:28:34,482 Epoch[30] Batch [910]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.099382,	
2017-06-24 02:28:39,271 Epoch[30] Batch [920]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.099259,	
2017-06-24 02:28:44,236 Epoch[30] Batch [930]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.099234,	
2017-06-24 02:28:49,194 Epoch[30] Batch [940]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.099157,	
2017-06-24 02:28:53,808 Epoch[30] Batch [950]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.099197,	
2017-06-24 02:28:58,636 Epoch[30] Batch [960]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.099215,	
2017-06-24 02:29:04,186 Epoch[30] Batch [970]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.098994,	
2017-06-24 02:29:09,122 Epoch[30] Batch [980]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.099004,	
2017-06-24 02:29:14,118 Epoch[30] Batch [990]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.098973,	
2017-06-24 02:29:19,073 Epoch[30] Batch [1000]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.098966,	
2017-06-24 02:29:23,870 Epoch[30] Batch [1010]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.098903,	
2017-06-24 02:29:28,877 Epoch[30] Batch [1020]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.098844,	
2017-06-24 02:29:33,689 Epoch[30] Batch [1030]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.098890,	
2017-06-24 02:29:38,857 Epoch[30] Batch [1040]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.098858,	
2017-06-24 02:29:43,658 Epoch[30] Batch [1050]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.098871,	
2017-06-24 02:29:48,298 Epoch[30] Batch [1060]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.098936,	
2017-06-24 02:29:53,057 Epoch[30] Batch [1070]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098888,	
2017-06-24 02:29:58,007 Epoch[30] Batch [1080]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.098897,	
2017-06-24 02:30:03,332 Epoch[30] Batch [1090]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098906,	
2017-06-24 02:30:09,059 Epoch[30] Batch [1100]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.098801,	
2017-06-24 02:30:13,842 Epoch[30] Batch [1110]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.098692,	
2017-06-24 02:30:18,958 Epoch[30] Batch [1120]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.098749,	
2017-06-24 02:30:24,502 Epoch[30] Batch [1130]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.098722,	
2017-06-24 02:30:29,694 Epoch[30] Batch [1140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098715,	
2017-06-24 02:30:34,370 Epoch[30] Batch [1150]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.098743,	
2017-06-24 02:30:39,778 Epoch[30] Batch [1160]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.098621,	
2017-06-24 02:30:45,163 Epoch[30] Batch [1170]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098596,	
2017-06-24 02:30:50,112 Epoch[30] Batch [1180]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.098543,	
2017-06-24 02:30:55,917 Epoch[30] Batch [1190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098440,	
2017-06-24 02:31:00,752 Epoch[30] Batch [1200]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.098436,	
2017-06-24 02:31:05,502 Epoch[30] Batch [1210]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.098476,	
2017-06-24 02:31:10,420 Epoch[30] Batch [1220]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.098474,	
2017-06-24 02:31:15,603 Epoch[30] Batch [1230]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098533,	
2017-06-24 02:31:21,398 Epoch[30] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098633,	
2017-06-24 02:31:26,530 Epoch[30] Batch [1250]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.098632,	
2017-06-24 02:31:32,160 Epoch[30] Batch [1260]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.098547,	
2017-06-24 02:31:37,417 Epoch[30] Batch [1270]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.098598,	
2017-06-24 02:31:42,740 Epoch[30] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098652,	
2017-06-24 02:31:48,505 Epoch[30] Batch [1290]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098683,	
2017-06-24 02:31:53,479 Epoch[30] Batch [1300]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.098576,	
2017-06-24 02:31:59,181 Epoch[30] Batch [1310]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.098536,	
2017-06-24 02:32:04,061 Epoch[30] Batch [1320]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.098548,	
2017-06-24 02:32:09,053 Epoch[30] Batch [1330]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.098631,	
2017-06-24 02:32:14,636 Epoch[30] Batch [1340]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098629,	
2017-06-24 02:32:19,920 Epoch[30] Batch [1350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098613,	
2017-06-24 02:32:25,412 Epoch[30] Batch [1360]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098607,	
2017-06-24 02:32:31,403 Epoch[30] Batch [1370]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.098605,	
2017-06-24 02:32:36,718 Epoch[30] Batch [1380]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098578,	
2017-06-24 02:32:41,683 Epoch[30] Batch [1390]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.098561,	
2017-06-24 02:32:47,436 Epoch[30] Batch [1400]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098462,	
2017-06-24 02:32:53,020 Epoch[30] Batch [1410]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.098426,	
2017-06-24 02:32:58,100 Epoch[30] Batch [1420]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.098329,	
2017-06-24 02:33:03,401 Epoch[30] Batch [1430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098393,	
2017-06-24 02:33:08,430 Epoch[30] Batch [1440]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.098479,	
2017-06-24 02:33:13,568 Epoch[30] Batch [1450]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.098533,	
2017-06-24 02:33:19,436 Epoch[30] Batch [1460]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.098557,	
2017-06-24 02:33:24,484 Epoch[30] Batch [1470]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.098538,	
2017-06-24 02:33:30,300 Epoch[30] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098558,	
2017-06-24 02:33:33,298 Epoch[30] Train-FCNLogLoss=0.098550
2017-06-24 02:33:33,298 Epoch[30] Time cost=774.528
2017-06-24 02:33:34,066 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0031.params"
2017-06-24 02:33:35,692 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0031.states"
2017-06-24 02:33:41,434 Epoch[31] Batch [10]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.096166,	
2017-06-24 02:33:46,624 Epoch[31] Batch [20]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094869,	
2017-06-24 02:33:51,962 Epoch[31] Batch [30]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095279,	
2017-06-24 02:33:56,780 Epoch[31] Batch [40]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.095538,	
2017-06-24 02:34:01,773 Epoch[31] Batch [50]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.096943,	
2017-06-24 02:34:06,914 Epoch[31] Batch [60]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.097301,	
2017-06-24 02:34:12,283 Epoch[31] Batch [70]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097854,	
2017-06-24 02:34:17,635 Epoch[31] Batch [80]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096931,	
2017-06-24 02:34:22,884 Epoch[31] Batch [90]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096154,	
2017-06-24 02:34:28,139 Epoch[31] Batch [100]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096356,	
2017-06-24 02:34:33,219 Epoch[31] Batch [110]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.095544,	
2017-06-24 02:34:38,361 Epoch[31] Batch [120]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.096423,	
2017-06-24 02:34:43,922 Epoch[31] Batch [130]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.096261,	
2017-06-24 02:34:49,249 Epoch[31] Batch [140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096310,	
2017-06-24 02:34:54,658 Epoch[31] Batch [150]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.095899,	
2017-06-24 02:34:59,993 Epoch[31] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096088,	
2017-06-24 02:35:05,391 Epoch[31] Batch [170]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.096236,	
2017-06-24 02:35:11,112 Epoch[31] Batch [180]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.095779,	
2017-06-24 02:35:17,438 Epoch[31] Batch [190]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.095718,	
2017-06-24 02:35:22,892 Epoch[31] Batch [200]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.095883,	
2017-06-24 02:35:28,311 Epoch[31] Batch [210]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.095685,	
2017-06-24 02:35:34,300 Epoch[31] Batch [220]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.095596,	
2017-06-24 02:35:39,664 Epoch[31] Batch [230]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095478,	
2017-06-24 02:35:44,783 Epoch[31] Batch [240]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.095903,	
2017-06-24 02:35:49,992 Epoch[31] Batch [250]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096176,	
2017-06-24 02:35:55,516 Epoch[31] Batch [260]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.096149,	
2017-06-24 02:36:00,906 Epoch[31] Batch [270]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095812,	
2017-06-24 02:36:06,704 Epoch[31] Batch [280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.095839,	
2017-06-24 02:36:13,311 Epoch[31] Batch [290]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.095909,	
2017-06-24 02:36:18,107 Epoch[31] Batch [300]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.095958,	
2017-06-24 02:36:23,675 Epoch[31] Batch [310]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.095593,	
2017-06-24 02:36:29,032 Epoch[31] Batch [320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095646,	
2017-06-24 02:36:34,928 Epoch[31] Batch [330]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.095702,	
2017-06-24 02:36:40,106 Epoch[31] Batch [340]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095810,	
2017-06-24 02:36:45,045 Epoch[31] Batch [350]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.095872,	
2017-06-24 02:36:50,223 Epoch[31] Batch [360]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095774,	
2017-06-24 02:36:55,871 Epoch[31] Batch [370]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.095711,	
2017-06-24 02:37:01,217 Epoch[31] Batch [380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095598,	
2017-06-24 02:37:06,552 Epoch[31] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095780,	
2017-06-24 02:37:11,795 Epoch[31] Batch [400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095882,	
2017-06-24 02:37:16,970 Epoch[31] Batch [410]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096173,	
2017-06-24 02:37:21,956 Epoch[31] Batch [420]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.096347,	
2017-06-24 02:37:27,169 Epoch[31] Batch [430]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096328,	
2017-06-24 02:37:32,154 Epoch[31] Batch [440]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.096361,	
2017-06-24 02:37:37,170 Epoch[31] Batch [450]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.096372,	
2017-06-24 02:37:42,138 Epoch[31] Batch [460]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.096251,	
2017-06-24 02:37:46,824 Epoch[31] Batch [470]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.096562,	
2017-06-24 02:37:52,015 Epoch[31] Batch [480]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.096546,	
2017-06-24 02:37:56,693 Epoch[31] Batch [490]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.096665,	
2017-06-24 02:38:01,670 Epoch[31] Batch [500]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.096632,	
2017-06-24 02:38:06,368 Epoch[31] Batch [510]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.096875,	
2017-06-24 02:38:11,439 Epoch[31] Batch [520]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.096979,	
2017-06-24 02:38:16,104 Epoch[31] Batch [530]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.097051,	
2017-06-24 02:38:21,396 Epoch[31] Batch [540]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097267,	
2017-06-24 02:38:26,366 Epoch[31] Batch [550]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.097379,	
2017-06-24 02:38:30,964 Epoch[31] Batch [560]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097400,	
2017-06-24 02:38:35,661 Epoch[31] Batch [570]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.097366,	
2017-06-24 02:38:40,182 Epoch[31] Batch [580]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097452,	
2017-06-24 02:38:45,118 Epoch[31] Batch [590]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.097377,	
2017-06-24 02:38:50,064 Epoch[31] Batch [600]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.097172,	
2017-06-24 02:38:55,128 Epoch[31] Batch [610]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.097375,	
2017-06-24 02:38:59,973 Epoch[31] Batch [620]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.097490,	
2017-06-24 02:39:05,024 Epoch[31] Batch [630]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.097317,	
2017-06-24 02:39:09,783 Epoch[31] Batch [640]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.097240,	
2017-06-24 02:39:14,732 Epoch[31] Batch [650]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.097233,	
2017-06-24 02:39:19,465 Epoch[31] Batch [660]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.097353,	
2017-06-24 02:39:24,267 Epoch[31] Batch [670]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.097268,	
2017-06-24 02:39:29,105 Epoch[31] Batch [680]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.097175,	
2017-06-24 02:39:33,876 Epoch[31] Batch [690]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.097182,	
2017-06-24 02:39:38,774 Epoch[31] Batch [700]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.097108,	
2017-06-24 02:39:43,671 Epoch[31] Batch [710]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.097112,	
2017-06-24 02:39:48,181 Epoch[31] Batch [720]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.097034,	
2017-06-24 02:39:53,064 Epoch[31] Batch [730]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.097038,	
2017-06-24 02:39:57,851 Epoch[31] Batch [740]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.097247,	
2017-06-24 02:40:02,710 Epoch[31] Batch [750]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.097271,	
2017-06-24 02:40:07,728 Epoch[31] Batch [760]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.097395,	
2017-06-24 02:40:12,744 Epoch[31] Batch [770]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.097323,	
2017-06-24 02:40:17,933 Epoch[31] Batch [780]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.097398,	
2017-06-24 02:40:22,930 Epoch[31] Batch [790]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.097455,	
2017-06-24 02:40:27,617 Epoch[31] Batch [800]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.097593,	
2017-06-24 02:40:32,797 Epoch[31] Batch [810]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097582,	
2017-06-24 02:40:37,956 Epoch[31] Batch [820]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097524,	
2017-06-24 02:40:43,299 Epoch[31] Batch [830]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097556,	
2017-06-24 02:40:48,259 Epoch[31] Batch [840]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.097601,	
2017-06-24 02:40:52,863 Epoch[31] Batch [850]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.097646,	
2017-06-24 02:40:58,409 Epoch[31] Batch [860]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.097693,	
2017-06-24 02:41:03,126 Epoch[31] Batch [870]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.097789,	
2017-06-24 02:41:07,726 Epoch[31] Batch [880]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097834,	
2017-06-24 02:41:12,888 Epoch[31] Batch [890]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097852,	
2017-06-24 02:41:17,976 Epoch[31] Batch [900]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.097853,	
2017-06-24 02:41:22,889 Epoch[31] Batch [910]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.097907,	
2017-06-24 02:41:27,719 Epoch[31] Batch [920]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.097876,	
2017-06-24 02:41:32,513 Epoch[31] Batch [930]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.097932,	
2017-06-24 02:41:37,846 Epoch[31] Batch [940]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097970,	
2017-06-24 02:41:43,012 Epoch[31] Batch [950]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.097962,	
2017-06-24 02:41:48,166 Epoch[31] Batch [960]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.097950,	
2017-06-24 02:41:53,759 Epoch[31] Batch [970]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.097964,	
2017-06-24 02:41:59,215 Epoch[31] Batch [980]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.098033,	
2017-06-24 02:42:05,770 Epoch[31] Batch [990]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.098030,	
2017-06-24 02:42:11,622 Epoch[31] Batch [1000]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098078,	
2017-06-24 02:42:17,412 Epoch[31] Batch [1010]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.098139,	
2017-06-24 02:42:22,501 Epoch[31] Batch [1020]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.098311,	
2017-06-24 02:42:28,240 Epoch[31] Batch [1030]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.098463,	
2017-06-24 02:42:33,951 Epoch[31] Batch [1040]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.098569,	
2017-06-24 02:42:40,054 Epoch[31] Batch [1050]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098568,	
2017-06-24 02:42:45,704 Epoch[31] Batch [1060]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.098579,	
2017-06-24 02:42:51,265 Epoch[31] Batch [1070]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.098655,	
2017-06-24 02:42:56,936 Epoch[31] Batch [1080]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.098650,	
2017-06-24 02:43:02,306 Epoch[31] Batch [1090]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098678,	
2017-06-24 02:43:07,678 Epoch[31] Batch [1100]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098699,	
2017-06-24 02:43:13,212 Epoch[31] Batch [1110]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098659,	
2017-06-24 02:43:18,243 Epoch[31] Batch [1120]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.098684,	
2017-06-24 02:43:23,145 Epoch[31] Batch [1130]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.098700,	
2017-06-24 02:43:28,185 Epoch[31] Batch [1140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.098778,	
2017-06-24 02:43:33,479 Epoch[31] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098859,	
2017-06-24 02:43:39,548 Epoch[31] Batch [1160]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098895,	
2017-06-24 02:43:44,550 Epoch[31] Batch [1170]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098865,	
2017-06-24 02:43:49,922 Epoch[31] Batch [1180]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098831,	
2017-06-24 02:43:55,135 Epoch[31] Batch [1190]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.098890,	
2017-06-24 02:44:00,954 Epoch[31] Batch [1200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098919,	
2017-06-24 02:44:06,451 Epoch[31] Batch [1210]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098956,	
2017-06-24 02:44:11,693 Epoch[31] Batch [1220]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.098858,	
2017-06-24 02:44:16,993 Epoch[31] Batch [1230]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098804,	
2017-06-24 02:44:22,574 Epoch[31] Batch [1240]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098820,	
2017-06-24 02:44:27,714 Epoch[31] Batch [1250]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.098803,	
2017-06-24 02:44:33,208 Epoch[31] Batch [1260]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098776,	
2017-06-24 02:44:38,435 Epoch[31] Batch [1270]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098752,	
2017-06-24 02:44:43,848 Epoch[31] Batch [1280]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.098823,	
2017-06-24 02:44:48,762 Epoch[31] Batch [1290]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.098835,	
2017-06-24 02:44:54,331 Epoch[31] Batch [1300]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.098848,	
2017-06-24 02:44:59,704 Epoch[31] Batch [1310]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098845,	
2017-06-24 02:45:04,861 Epoch[31] Batch [1320]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.098919,	
2017-06-24 02:45:09,955 Epoch[31] Batch [1330]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.098895,	
2017-06-24 02:45:15,148 Epoch[31] Batch [1340]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098943,	
2017-06-24 02:45:20,065 Epoch[31] Batch [1350]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.098890,	
2017-06-24 02:45:25,343 Epoch[31] Batch [1360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098876,	
2017-06-24 02:45:30,181 Epoch[31] Batch [1370]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.098974,	
2017-06-24 02:45:35,592 Epoch[31] Batch [1380]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.098973,	
2017-06-24 02:45:40,788 Epoch[31] Batch [1390]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098982,	
2017-06-24 02:45:45,968 Epoch[31] Batch [1400]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098957,	
2017-06-24 02:45:50,942 Epoch[31] Batch [1410]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.098974,	
2017-06-24 02:45:56,322 Epoch[31] Batch [1420]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098954,	
2017-06-24 02:46:01,282 Epoch[31] Batch [1430]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.098892,	
2017-06-24 02:46:07,403 Epoch[31] Batch [1440]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098914,	
2017-06-24 02:46:13,138 Epoch[31] Batch [1450]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.098896,	
2017-06-24 02:46:18,327 Epoch[31] Batch [1460]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098879,	
2017-06-24 02:46:23,647 Epoch[31] Batch [1470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098886,	
2017-06-24 02:46:28,821 Epoch[31] Batch [1480]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.098937,	
2017-06-24 02:46:31,963 Epoch[31] Train-FCNLogLoss=0.098961
2017-06-24 02:46:31,963 Epoch[31] Time cost=776.271
2017-06-24 02:46:32,698 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0032.params"
2017-06-24 02:46:34,456 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0032.states"
2017-06-24 02:46:40,501 Epoch[32] Batch [10]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.099351,	
2017-06-24 02:46:46,378 Epoch[32] Batch [20]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.101506,	
2017-06-24 02:46:51,744 Epoch[32] Batch [30]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.100700,	
2017-06-24 02:46:56,731 Epoch[32] Batch [40]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.102850,	
2017-06-24 02:47:02,147 Epoch[32] Batch [50]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.104340,	
2017-06-24 02:47:07,350 Epoch[32] Batch [60]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.103527,	
2017-06-24 02:47:12,363 Epoch[32] Batch [70]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.103362,	
2017-06-24 02:47:18,127 Epoch[32] Batch [80]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102379,	
2017-06-24 02:47:23,400 Epoch[32] Batch [90]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.102011,	
2017-06-24 02:47:28,614 Epoch[32] Batch [100]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.101104,	
2017-06-24 02:47:34,246 Epoch[32] Batch [110]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.099806,	
2017-06-24 02:47:39,740 Epoch[32] Batch [120]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.100168,	
2017-06-24 02:47:45,336 Epoch[32] Batch [130]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099046,	
2017-06-24 02:47:51,278 Epoch[32] Batch [140]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.098302,	
2017-06-24 02:47:56,233 Epoch[32] Batch [150]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.097750,	
2017-06-24 02:48:01,508 Epoch[32] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097581,	
2017-06-24 02:48:06,461 Epoch[32] Batch [170]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.097948,	
2017-06-24 02:48:11,531 Epoch[32] Batch [180]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.098109,	
2017-06-24 02:48:16,706 Epoch[32] Batch [190]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.098450,	
2017-06-24 02:48:21,753 Epoch[32] Batch [200]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.098675,	
2017-06-24 02:48:26,593 Epoch[32] Batch [210]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.098482,	
2017-06-24 02:48:31,925 Epoch[32] Batch [220]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098126,	
2017-06-24 02:48:36,997 Epoch[32] Batch [230]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.098332,	
2017-06-24 02:48:41,691 Epoch[32] Batch [240]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.098052,	
2017-06-24 02:48:46,803 Epoch[32] Batch [250]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.097816,	
2017-06-24 02:48:51,898 Epoch[32] Batch [260]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.097743,	
2017-06-24 02:48:56,885 Epoch[32] Batch [270]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.097375,	
2017-06-24 02:49:01,616 Epoch[32] Batch [280]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.097255,	
2017-06-24 02:49:06,460 Epoch[32] Batch [290]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.097181,	
2017-06-24 02:49:11,370 Epoch[32] Batch [300]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.097326,	
2017-06-24 02:49:16,497 Epoch[32] Batch [310]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.097174,	
2017-06-24 02:49:21,537 Epoch[32] Batch [320]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.096860,	
2017-06-24 02:49:26,581 Epoch[32] Batch [330]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.097068,	
2017-06-24 02:49:31,547 Epoch[32] Batch [340]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.096982,	
2017-06-24 02:49:36,670 Epoch[32] Batch [350]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.097078,	
2017-06-24 02:49:41,880 Epoch[32] Batch [360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096922,	
2017-06-24 02:49:46,535 Epoch[32] Batch [370]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.096840,	
2017-06-24 02:49:51,075 Epoch[32] Batch [380]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.096843,	
2017-06-24 02:49:55,722 Epoch[32] Batch [390]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.096598,	
2017-06-24 02:50:00,632 Epoch[32] Batch [400]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.096592,	
2017-06-24 02:50:05,422 Epoch[32] Batch [410]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.096581,	
2017-06-24 02:50:10,248 Epoch[32] Batch [420]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.096655,	
2017-06-24 02:50:15,169 Epoch[32] Batch [430]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.096745,	
2017-06-24 02:50:20,348 Epoch[32] Batch [440]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096768,	
2017-06-24 02:50:25,194 Epoch[32] Batch [450]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.096947,	
2017-06-24 02:50:30,079 Epoch[32] Batch [460]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.096715,	
2017-06-24 02:50:34,869 Epoch[32] Batch [470]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.096634,	
2017-06-24 02:50:39,775 Epoch[32] Batch [480]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.096742,	
2017-06-24 02:50:44,621 Epoch[32] Batch [490]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.096831,	
2017-06-24 02:50:49,370 Epoch[32] Batch [500]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.096820,	
2017-06-24 02:50:54,199 Epoch[32] Batch [510]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.096880,	
2017-06-24 02:50:59,080 Epoch[32] Batch [520]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.096988,	
2017-06-24 02:51:03,734 Epoch[32] Batch [530]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.096974,	
2017-06-24 02:51:08,766 Epoch[32] Batch [540]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.096975,	
2017-06-24 02:51:13,614 Epoch[32] Batch [550]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.097146,	
2017-06-24 02:51:18,589 Epoch[32] Batch [560]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.097347,	
2017-06-24 02:51:23,309 Epoch[32] Batch [570]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.097399,	
2017-06-24 02:51:28,291 Epoch[32] Batch [580]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.097277,	
2017-06-24 02:51:33,471 Epoch[32] Batch [590]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097139,	
2017-06-24 02:51:38,329 Epoch[32] Batch [600]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.097038,	
2017-06-24 02:51:43,253 Epoch[32] Batch [610]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.097111,	
2017-06-24 02:51:48,055 Epoch[32] Batch [620]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.096931,	
2017-06-24 02:51:53,150 Epoch[32] Batch [630]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.096939,	
2017-06-24 02:51:58,113 Epoch[32] Batch [640]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.096977,	
2017-06-24 02:52:03,096 Epoch[32] Batch [650]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.097109,	
2017-06-24 02:52:08,033 Epoch[32] Batch [660]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.097253,	
2017-06-24 02:52:12,495 Epoch[32] Batch [670]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.097135,	
2017-06-24 02:52:17,651 Epoch[32] Batch [680]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.097310,	
2017-06-24 02:52:22,349 Epoch[32] Batch [690]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.097267,	
2017-06-24 02:52:26,935 Epoch[32] Batch [700]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.097375,	
2017-06-24 02:52:31,674 Epoch[32] Batch [710]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.097296,	
2017-06-24 02:52:36,769 Epoch[32] Batch [720]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.097559,	
2017-06-24 02:52:41,710 Epoch[32] Batch [730]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.097604,	
2017-06-24 02:52:46,464 Epoch[32] Batch [740]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.097526,	
2017-06-24 02:52:51,214 Epoch[32] Batch [750]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.097472,	
2017-06-24 02:52:55,937 Epoch[32] Batch [760]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.097341,	
2017-06-24 02:53:01,243 Epoch[32] Batch [770]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097481,	
2017-06-24 02:53:06,164 Epoch[32] Batch [780]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.097334,	
2017-06-24 02:53:11,032 Epoch[32] Batch [790]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.097251,	
2017-06-24 02:53:16,984 Epoch[32] Batch [800]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.097224,	
2017-06-24 02:53:22,033 Epoch[32] Batch [810]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.097136,	
2017-06-24 02:53:26,887 Epoch[32] Batch [820]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.097089,	
2017-06-24 02:53:32,279 Epoch[32] Batch [830]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097015,	
2017-06-24 02:53:38,376 Epoch[32] Batch [840]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097282,	
2017-06-24 02:53:43,826 Epoch[32] Batch [850]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.097347,	
2017-06-24 02:53:48,903 Epoch[32] Batch [860]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.097428,	
2017-06-24 02:53:53,964 Epoch[32] Batch [870]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.097422,	
2017-06-24 02:53:58,965 Epoch[32] Batch [880]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.097331,	
2017-06-24 02:54:04,438 Epoch[32] Batch [890]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.097290,	
2017-06-24 02:54:09,656 Epoch[32] Batch [900]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097368,	
2017-06-24 02:54:14,765 Epoch[32] Batch [910]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.097418,	
2017-06-24 02:54:19,787 Epoch[32] Batch [920]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.097458,	
2017-06-24 02:54:24,866 Epoch[32] Batch [930]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.097501,	
2017-06-24 02:54:30,028 Epoch[32] Batch [940]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097531,	
2017-06-24 02:54:34,899 Epoch[32] Batch [950]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.097614,	
2017-06-24 02:54:39,949 Epoch[32] Batch [960]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.097656,	
2017-06-24 02:54:44,915 Epoch[32] Batch [970]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.097683,	
2017-06-24 02:54:49,781 Epoch[32] Batch [980]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.097630,	
2017-06-24 02:54:54,626 Epoch[32] Batch [990]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.097676,	
2017-06-24 02:54:59,814 Epoch[32] Batch [1000]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.097711,	
2017-06-24 02:55:04,820 Epoch[32] Batch [1010]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.097802,	
2017-06-24 02:55:10,054 Epoch[32] Batch [1020]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097823,	
2017-06-24 02:55:15,417 Epoch[32] Batch [1030]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097980,	
2017-06-24 02:55:20,645 Epoch[32] Batch [1040]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098082,	
2017-06-24 02:55:25,868 Epoch[32] Batch [1050]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.098071,	
2017-06-24 02:55:30,646 Epoch[32] Batch [1060]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.098055,	
2017-06-24 02:55:35,615 Epoch[32] Batch [1070]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.098108,	
2017-06-24 02:55:40,754 Epoch[32] Batch [1080]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.098146,	
2017-06-24 02:55:45,403 Epoch[32] Batch [1090]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.098178,	
2017-06-24 02:55:50,853 Epoch[32] Batch [1100]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098183,	
2017-06-24 02:55:55,923 Epoch[32] Batch [1110]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.098139,	
2017-06-24 02:56:00,985 Epoch[32] Batch [1120]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.098141,	
2017-06-24 02:56:05,828 Epoch[32] Batch [1130]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.098071,	
2017-06-24 02:56:10,781 Epoch[32] Batch [1140]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.098048,	
2017-06-24 02:56:15,746 Epoch[32] Batch [1150]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.097997,	
2017-06-24 02:56:20,658 Epoch[32] Batch [1160]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.097941,	
2017-06-24 02:56:25,459 Epoch[32] Batch [1170]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.097965,	
2017-06-24 02:56:30,389 Epoch[32] Batch [1180]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.097952,	
2017-06-24 02:56:35,548 Epoch[32] Batch [1190]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097994,	
2017-06-24 02:56:40,307 Epoch[32] Batch [1200]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098113,	
2017-06-24 02:56:45,402 Epoch[32] Batch [1210]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.098166,	
2017-06-24 02:56:50,527 Epoch[32] Batch [1220]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.098188,	
2017-06-24 02:56:55,902 Epoch[32] Batch [1230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098220,	
2017-06-24 02:57:01,121 Epoch[32] Batch [1240]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.098243,	
2017-06-24 02:57:06,048 Epoch[32] Batch [1250]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.098301,	
2017-06-24 02:57:11,427 Epoch[32] Batch [1260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098281,	
2017-06-24 02:57:16,309 Epoch[32] Batch [1270]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.098308,	
2017-06-24 02:57:22,012 Epoch[32] Batch [1280]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.098277,	
2017-06-24 02:57:27,189 Epoch[32] Batch [1290]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.098221,	
2017-06-24 02:57:32,081 Epoch[32] Batch [1300]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.098250,	
2017-06-24 02:57:37,499 Epoch[32] Batch [1310]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098235,	
2017-06-24 02:57:42,841 Epoch[32] Batch [1320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098159,	
2017-06-24 02:57:48,024 Epoch[32] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098213,	
2017-06-24 02:57:53,156 Epoch[32] Batch [1340]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.098183,	
2017-06-24 02:57:58,159 Epoch[32] Batch [1350]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098172,	
2017-06-24 02:58:03,189 Epoch[32] Batch [1360]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.098190,	
2017-06-24 02:58:08,039 Epoch[32] Batch [1370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.098287,	
2017-06-24 02:58:13,461 Epoch[32] Batch [1380]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098233,	
2017-06-24 02:58:18,531 Epoch[32] Batch [1390]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.098318,	
2017-06-24 02:58:24,499 Epoch[32] Batch [1400]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.098315,	
2017-06-24 02:58:30,258 Epoch[32] Batch [1410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098285,	
2017-06-24 02:58:35,487 Epoch[32] Batch [1420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098304,	
2017-06-24 02:58:40,508 Epoch[32] Batch [1430]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.098349,	
2017-06-24 02:58:45,239 Epoch[32] Batch [1440]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.098369,	
2017-06-24 02:58:50,171 Epoch[32] Batch [1450]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.098291,	
2017-06-24 02:58:55,153 Epoch[32] Batch [1460]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.098306,	
2017-06-24 02:59:00,038 Epoch[32] Batch [1470]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.098390,	
2017-06-24 02:59:05,121 Epoch[32] Batch [1480]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.098401,	
2017-06-24 02:59:08,507 Epoch[32] Train-FCNLogLoss=0.098442
2017-06-24 02:59:08,507 Epoch[32] Time cost=754.051
2017-06-24 02:59:09,319 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0033.params"
2017-06-24 02:59:10,938 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0033.states"
2017-06-24 02:59:16,864 Epoch[33] Batch [10]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.095529,	
2017-06-24 02:59:21,768 Epoch[33] Batch [20]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092220,	
2017-06-24 02:59:26,848 Epoch[33] Batch [30]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.091332,	
2017-06-24 02:59:31,590 Epoch[33] Batch [40]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090202,	
2017-06-24 02:59:36,566 Epoch[33] Batch [50]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.093064,	
2017-06-24 02:59:42,112 Epoch[33] Batch [60]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.095937,	
2017-06-24 02:59:47,574 Epoch[33] Batch [70]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.096102,	
2017-06-24 02:59:53,047 Epoch[33] Batch [80]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.096785,	
2017-06-24 02:59:58,232 Epoch[33] Batch [90]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.096150,	
2017-06-24 03:00:03,389 Epoch[33] Batch [100]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.096058,	
2017-06-24 03:00:08,501 Epoch[33] Batch [110]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.095980,	
2017-06-24 03:00:13,562 Epoch[33] Batch [120]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.096169,	
2017-06-24 03:00:18,288 Epoch[33] Batch [130]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.096102,	
2017-06-24 03:00:23,303 Epoch[33] Batch [140]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.095876,	
2017-06-24 03:00:28,323 Epoch[33] Batch [150]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.095794,	
2017-06-24 03:00:33,412 Epoch[33] Batch [160]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.095993,	
2017-06-24 03:00:37,995 Epoch[33] Batch [170]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.096735,	
2017-06-24 03:00:42,764 Epoch[33] Batch [180]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.097005,	
2017-06-24 03:00:47,783 Epoch[33] Batch [190]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.096366,	
2017-06-24 03:00:53,102 Epoch[33] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096458,	
2017-06-24 03:00:57,828 Epoch[33] Batch [210]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.096614,	
2017-06-24 03:01:02,851 Epoch[33] Batch [220]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.096675,	
2017-06-24 03:01:08,015 Epoch[33] Batch [230]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.096794,	
2017-06-24 03:01:12,887 Epoch[33] Batch [240]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.096781,	
2017-06-24 03:01:18,007 Epoch[33] Batch [250]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.096544,	
2017-06-24 03:01:23,380 Epoch[33] Batch [260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096404,	
2017-06-24 03:01:30,093 Epoch[33] Batch [270]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.096090,	
2017-06-24 03:01:35,229 Epoch[33] Batch [280]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.096002,	
2017-06-24 03:01:40,141 Epoch[33] Batch [290]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.095873,	
2017-06-24 03:01:45,009 Epoch[33] Batch [300]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.095728,	
2017-06-24 03:01:49,996 Epoch[33] Batch [310]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.096169,	
2017-06-24 03:01:54,728 Epoch[33] Batch [320]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.096401,	
2017-06-24 03:02:00,447 Epoch[33] Batch [330]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.096567,	
2017-06-24 03:02:05,684 Epoch[33] Batch [340]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.096704,	
2017-06-24 03:02:11,072 Epoch[33] Batch [350]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096767,	
2017-06-24 03:02:16,363 Epoch[33] Batch [360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096698,	
2017-06-24 03:02:21,712 Epoch[33] Batch [370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096569,	
2017-06-24 03:02:26,994 Epoch[33] Batch [380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096327,	
2017-06-24 03:02:32,387 Epoch[33] Batch [390]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.096281,	
2017-06-24 03:02:37,366 Epoch[33] Batch [400]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.096408,	
2017-06-24 03:02:42,116 Epoch[33] Batch [410]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.096294,	
2017-06-24 03:02:47,204 Epoch[33] Batch [420]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.096285,	
2017-06-24 03:02:52,885 Epoch[33] Batch [430]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.096287,	
2017-06-24 03:02:57,674 Epoch[33] Batch [440]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.096364,	
2017-06-24 03:03:02,696 Epoch[33] Batch [450]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.096365,	
2017-06-24 03:03:07,544 Epoch[33] Batch [460]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.096308,	
2017-06-24 03:03:12,613 Epoch[33] Batch [470]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.096441,	
2017-06-24 03:03:17,460 Epoch[33] Batch [480]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.096561,	
2017-06-24 03:03:22,218 Epoch[33] Batch [490]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.096422,	
2017-06-24 03:03:27,294 Epoch[33] Batch [500]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.096160,	
2017-06-24 03:03:32,336 Epoch[33] Batch [510]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.096065,	
2017-06-24 03:03:37,281 Epoch[33] Batch [520]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.095993,	
2017-06-24 03:03:42,206 Epoch[33] Batch [530]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.096020,	
2017-06-24 03:03:47,442 Epoch[33] Batch [540]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.096218,	
2017-06-24 03:03:52,277 Epoch[33] Batch [550]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.096347,	
2017-06-24 03:03:57,957 Epoch[33] Batch [560]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.096314,	
2017-06-24 03:04:03,099 Epoch[33] Batch [570]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.096445,	
2017-06-24 03:04:08,364 Epoch[33] Batch [580]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096527,	
2017-06-24 03:04:14,982 Epoch[33] Batch [590]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.096446,	
2017-06-24 03:04:21,161 Epoch[33] Batch [600]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.096531,	
2017-06-24 03:04:27,193 Epoch[33] Batch [610]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.096615,	
2017-06-24 03:04:32,513 Epoch[33] Batch [620]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096758,	
2017-06-24 03:04:38,053 Epoch[33] Batch [630]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.096701,	
2017-06-24 03:04:43,832 Epoch[33] Batch [640]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097027,	
2017-06-24 03:04:49,433 Epoch[33] Batch [650]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.097045,	
2017-06-24 03:04:55,367 Epoch[33] Batch [660]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.096997,	
2017-06-24 03:05:00,753 Epoch[33] Batch [670]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096972,	
2017-06-24 03:05:06,653 Epoch[33] Batch [680]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.096851,	
2017-06-24 03:05:12,107 Epoch[33] Batch [690]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.096858,	
2017-06-24 03:05:17,381 Epoch[33] Batch [700]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096928,	
2017-06-24 03:05:23,648 Epoch[33] Batch [710]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.097053,	
2017-06-24 03:05:29,089 Epoch[33] Batch [720]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.097117,	
2017-06-24 03:05:34,570 Epoch[33] Batch [730]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.097163,	
2017-06-24 03:05:39,719 Epoch[33] Batch [740]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.097217,	
2017-06-24 03:05:44,911 Epoch[33] Batch [750]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.097053,	
2017-06-24 03:05:50,012 Epoch[33] Batch [760]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.097022,	
2017-06-24 03:05:55,365 Epoch[33] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097155,	
2017-06-24 03:06:00,549 Epoch[33] Batch [780]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097248,	
2017-06-24 03:06:05,517 Epoch[33] Batch [790]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.097221,	
2017-06-24 03:06:10,915 Epoch[33] Batch [800]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097272,	
2017-06-24 03:06:16,132 Epoch[33] Batch [810]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097264,	
2017-06-24 03:06:21,228 Epoch[33] Batch [820]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.097270,	
2017-06-24 03:06:26,339 Epoch[33] Batch [830]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.097240,	
2017-06-24 03:06:31,291 Epoch[33] Batch [840]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.097313,	
2017-06-24 03:06:36,395 Epoch[33] Batch [850]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.097216,	
2017-06-24 03:06:41,583 Epoch[33] Batch [860]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.097200,	
2017-06-24 03:06:46,980 Epoch[33] Batch [870]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097050,	
2017-06-24 03:06:52,151 Epoch[33] Batch [880]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.097032,	
2017-06-24 03:06:57,170 Epoch[33] Batch [890]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.096979,	
2017-06-24 03:07:02,594 Epoch[33] Batch [900]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.096857,	
2017-06-24 03:07:07,795 Epoch[33] Batch [910]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.096931,	
2017-06-24 03:07:13,779 Epoch[33] Batch [920]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.096828,	
2017-06-24 03:07:19,241 Epoch[33] Batch [930]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.096679,	
2017-06-24 03:07:24,501 Epoch[33] Batch [940]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096629,	
2017-06-24 03:07:29,684 Epoch[33] Batch [950]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.096617,	
2017-06-24 03:07:34,902 Epoch[33] Batch [960]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096624,	
2017-06-24 03:07:39,878 Epoch[33] Batch [970]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.096704,	
2017-06-24 03:07:44,815 Epoch[33] Batch [980]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.096734,	
2017-06-24 03:07:49,906 Epoch[33] Batch [990]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.096725,	
2017-06-24 03:07:54,966 Epoch[33] Batch [1000]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.096647,	
2017-06-24 03:08:00,276 Epoch[33] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096732,	
2017-06-24 03:08:05,079 Epoch[33] Batch [1020]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.096744,	
2017-06-24 03:08:09,842 Epoch[33] Batch [1030]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.096820,	
2017-06-24 03:08:14,930 Epoch[33] Batch [1040]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.096786,	
2017-06-24 03:08:20,301 Epoch[33] Batch [1050]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096761,	
2017-06-24 03:08:25,437 Epoch[33] Batch [1060]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.097039,	
2017-06-24 03:08:30,914 Epoch[33] Batch [1070]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.097004,	
2017-06-24 03:08:36,525 Epoch[33] Batch [1080]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.097042,	
2017-06-24 03:08:41,501 Epoch[33] Batch [1090]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.096988,	
2017-06-24 03:08:46,697 Epoch[33] Batch [1100]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.096907,	
2017-06-24 03:08:51,714 Epoch[33] Batch [1110]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.097004,	
2017-06-24 03:08:57,154 Epoch[33] Batch [1120]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.097000,	
2017-06-24 03:09:02,247 Epoch[33] Batch [1130]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.097024,	
2017-06-24 03:09:07,189 Epoch[33] Batch [1140]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.097035,	
2017-06-24 03:09:12,122 Epoch[33] Batch [1150]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.097006,	
2017-06-24 03:09:17,383 Epoch[33] Batch [1160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097004,	
2017-06-24 03:09:22,482 Epoch[33] Batch [1170]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.096918,	
2017-06-24 03:09:27,863 Epoch[33] Batch [1180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096958,	
2017-06-24 03:09:33,192 Epoch[33] Batch [1190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096921,	
2017-06-24 03:09:38,167 Epoch[33] Batch [1200]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.096993,	
2017-06-24 03:09:43,608 Epoch[33] Batch [1210]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.096905,	
2017-06-24 03:09:48,539 Epoch[33] Batch [1220]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.096885,	
2017-06-24 03:09:53,665 Epoch[33] Batch [1230]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.096932,	
2017-06-24 03:09:58,687 Epoch[33] Batch [1240]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.096891,	
2017-06-24 03:10:03,548 Epoch[33] Batch [1250]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.096900,	
2017-06-24 03:10:08,806 Epoch[33] Batch [1260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096842,	
2017-06-24 03:10:13,757 Epoch[33] Batch [1270]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.096885,	
2017-06-24 03:10:18,777 Epoch[33] Batch [1280]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.096872,	
2017-06-24 03:10:23,819 Epoch[33] Batch [1290]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.096776,	
2017-06-24 03:10:28,790 Epoch[33] Batch [1300]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.096782,	
2017-06-24 03:10:33,992 Epoch[33] Batch [1310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.096710,	
2017-06-24 03:10:38,914 Epoch[33] Batch [1320]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.096767,	
2017-06-24 03:10:43,697 Epoch[33] Batch [1330]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.096826,	
2017-06-24 03:10:48,716 Epoch[33] Batch [1340]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.096876,	
2017-06-24 03:10:53,836 Epoch[33] Batch [1350]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.096966,	
2017-06-24 03:10:58,901 Epoch[33] Batch [1360]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.097059,	
2017-06-24 03:11:03,750 Epoch[33] Batch [1370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.097057,	
2017-06-24 03:11:08,425 Epoch[33] Batch [1380]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.097009,	
2017-06-24 03:11:13,850 Epoch[33] Batch [1390]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.097001,	
2017-06-24 03:11:18,625 Epoch[33] Batch [1400]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.097055,	
2017-06-24 03:11:23,804 Epoch[33] Batch [1410]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097037,	
2017-06-24 03:11:28,652 Epoch[33] Batch [1420]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.097012,	
2017-06-24 03:11:33,325 Epoch[33] Batch [1430]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.097041,	
2017-06-24 03:11:38,299 Epoch[33] Batch [1440]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.097020,	
2017-06-24 03:11:43,045 Epoch[33] Batch [1450]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.097107,	
2017-06-24 03:11:47,645 Epoch[33] Batch [1460]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097157,	
2017-06-24 03:11:52,470 Epoch[33] Batch [1470]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.097204,	
2017-06-24 03:11:57,285 Epoch[33] Batch [1480]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.097156,	
2017-06-24 03:12:00,284 Epoch[33] Train-FCNLogLoss=0.097126
2017-06-24 03:12:00,284 Epoch[33] Time cost=769.346
2017-06-24 03:12:01,059 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0034.params"
2017-06-24 03:12:02,627 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0034.states"
2017-06-24 03:12:08,486 Epoch[34] Batch [10]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.103712,	
2017-06-24 03:12:13,387 Epoch[34] Batch [20]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.100656,	
2017-06-24 03:12:18,659 Epoch[34] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095647,	
2017-06-24 03:12:23,611 Epoch[34] Batch [40]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.093286,	
2017-06-24 03:12:28,089 Epoch[34] Batch [50]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.094905,	
2017-06-24 03:12:33,213 Epoch[34] Batch [60]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094450,	
2017-06-24 03:12:38,238 Epoch[34] Batch [70]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.093470,	
2017-06-24 03:12:42,985 Epoch[34] Batch [80]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.095916,	
2017-06-24 03:12:48,196 Epoch[34] Batch [90]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096182,	
2017-06-24 03:12:53,109 Epoch[34] Batch [100]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.095864,	
2017-06-24 03:12:58,044 Epoch[34] Batch [110]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.095987,	
2017-06-24 03:13:03,220 Epoch[34] Batch [120]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095087,	
2017-06-24 03:13:08,179 Epoch[34] Batch [130]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.095229,	
2017-06-24 03:13:13,120 Epoch[34] Batch [140]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.094969,	
2017-06-24 03:13:18,000 Epoch[34] Batch [150]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.094277,	
2017-06-24 03:13:23,285 Epoch[34] Batch [160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093350,	
2017-06-24 03:13:28,465 Epoch[34] Batch [170]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093586,	
2017-06-24 03:13:33,525 Epoch[34] Batch [180]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.093552,	
2017-06-24 03:13:38,814 Epoch[34] Batch [190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094254,	
2017-06-24 03:13:43,832 Epoch[34] Batch [200]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.094477,	
2017-06-24 03:13:48,823 Epoch[34] Batch [210]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.096901,	
2017-06-24 03:13:53,792 Epoch[34] Batch [220]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.097202,	
2017-06-24 03:13:58,490 Epoch[34] Batch [230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.097383,	
2017-06-24 03:14:03,470 Epoch[34] Batch [240]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.097405,	
2017-06-24 03:14:08,337 Epoch[34] Batch [250]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.097198,	
2017-06-24 03:14:13,286 Epoch[34] Batch [260]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.097002,	
2017-06-24 03:14:18,430 Epoch[34] Batch [270]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.096895,	
2017-06-24 03:14:23,368 Epoch[34] Batch [280]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.096681,	
2017-06-24 03:14:28,336 Epoch[34] Batch [290]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.096627,	
2017-06-24 03:14:33,515 Epoch[34] Batch [300]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.096597,	
2017-06-24 03:14:38,424 Epoch[34] Batch [310]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.096567,	
2017-06-24 03:14:43,408 Epoch[34] Batch [320]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.096476,	
2017-06-24 03:14:48,779 Epoch[34] Batch [330]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096320,	
2017-06-24 03:14:53,955 Epoch[34] Batch [340]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096463,	
2017-06-24 03:14:59,143 Epoch[34] Batch [350]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.096261,	
2017-06-24 03:15:04,785 Epoch[34] Batch [360]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.096357,	
2017-06-24 03:15:09,795 Epoch[34] Batch [370]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.096654,	
2017-06-24 03:15:14,778 Epoch[34] Batch [380]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.096923,	
2017-06-24 03:15:19,777 Epoch[34] Batch [390]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.096721,	
2017-06-24 03:15:24,525 Epoch[34] Batch [400]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.096650,	
2017-06-24 03:15:29,435 Epoch[34] Batch [410]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.096408,	
2017-06-24 03:15:34,922 Epoch[34] Batch [420]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.096498,	
2017-06-24 03:15:40,016 Epoch[34] Batch [430]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.096383,	
2017-06-24 03:15:45,248 Epoch[34] Batch [440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.096559,	
2017-06-24 03:15:50,544 Epoch[34] Batch [450]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096934,	
2017-06-24 03:15:55,924 Epoch[34] Batch [460]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097846,	
2017-06-24 03:16:01,074 Epoch[34] Batch [470]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.098746,	
2017-06-24 03:16:06,683 Epoch[34] Batch [480]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.099384,	
2017-06-24 03:16:11,798 Epoch[34] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.099835,	
2017-06-24 03:16:16,908 Epoch[34] Batch [500]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.100333,	
2017-06-24 03:16:22,287 Epoch[34] Batch [510]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.100702,	
2017-06-24 03:16:27,476 Epoch[34] Batch [520]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.100816,	
2017-06-24 03:16:33,147 Epoch[34] Batch [530]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-24 03:16:38,765 Epoch[34] Batch [540]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101426,	
2017-06-24 03:16:44,903 Epoch[34] Batch [550]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101522,	
2017-06-24 03:16:50,299 Epoch[34] Batch [560]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.101601,	
2017-06-24 03:16:56,488 Epoch[34] Batch [570]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.101834,	
2017-06-24 03:17:02,186 Epoch[34] Batch [580]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.101795,	
2017-06-24 03:17:08,532 Epoch[34] Batch [590]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.101754,	
2017-06-24 03:17:14,353 Epoch[34] Batch [600]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101611,	
2017-06-24 03:17:19,582 Epoch[34] Batch [610]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.101691,	
2017-06-24 03:17:24,838 Epoch[34] Batch [620]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.101693,	
2017-06-24 03:17:29,946 Epoch[34] Batch [630]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.101564,	
2017-06-24 03:17:35,639 Epoch[34] Batch [640]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.101786,	
2017-06-24 03:17:40,901 Epoch[34] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.101626,	
2017-06-24 03:17:47,378 Epoch[34] Batch [660]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.101524,	
2017-06-24 03:17:52,930 Epoch[34] Batch [670]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.101468,	
2017-06-24 03:17:58,583 Epoch[34] Batch [680]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.101456,	
2017-06-24 03:18:04,516 Epoch[34] Batch [690]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101357,	
2017-06-24 03:18:10,115 Epoch[34] Batch [700]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.101316,	
2017-06-24 03:18:16,665 Epoch[34] Batch [710]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.101293,	
2017-06-24 03:18:22,889 Epoch[34] Batch [720]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.101119,	
2017-06-24 03:18:28,687 Epoch[34] Batch [730]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.101005,	
2017-06-24 03:18:33,803 Epoch[34] Batch [740]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.101003,	
2017-06-24 03:18:38,632 Epoch[34] Batch [750]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.100914,	
2017-06-24 03:18:43,748 Epoch[34] Batch [760]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.100888,	
2017-06-24 03:18:49,011 Epoch[34] Batch [770]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.100853,	
2017-06-24 03:18:53,666 Epoch[34] Batch [780]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.100867,	
2017-06-24 03:18:58,783 Epoch[34] Batch [790]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.100749,	
2017-06-24 03:19:04,282 Epoch[34] Batch [800]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.100867,	
2017-06-24 03:19:09,911 Epoch[34] Batch [810]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.100840,	
2017-06-24 03:19:15,446 Epoch[34] Batch [820]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.100875,	
2017-06-24 03:19:20,457 Epoch[34] Batch [830]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.100834,	
2017-06-24 03:19:26,412 Epoch[34] Batch [840]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.101044,	
2017-06-24 03:19:32,132 Epoch[34] Batch [850]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.100979,	
2017-06-24 03:19:38,757 Epoch[34] Batch [860]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.100990,	
2017-06-24 03:19:44,031 Epoch[34] Batch [870]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100851,	
2017-06-24 03:19:49,023 Epoch[34] Batch [880]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.100655,	
2017-06-24 03:19:54,446 Epoch[34] Batch [890]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.100656,	
2017-06-24 03:20:01,302 Epoch[34] Batch [900]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.100539,	
2017-06-24 03:20:08,160 Epoch[34] Batch [910]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.100484,	
2017-06-24 03:20:15,432 Epoch[34] Batch [920]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.100326,	
2017-06-24 03:20:21,832 Epoch[34] Batch [930]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.100209,	
2017-06-24 03:20:28,137 Epoch[34] Batch [940]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.100126,	
2017-06-24 03:20:33,422 Epoch[34] Batch [950]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.100131,	
2017-06-24 03:20:38,647 Epoch[34] Batch [960]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.100044,	
2017-06-24 03:20:43,755 Epoch[34] Batch [970]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.099918,	
2017-06-24 03:20:48,757 Epoch[34] Batch [980]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.099810,	
2017-06-24 03:20:53,995 Epoch[34] Batch [990]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099756,	
2017-06-24 03:20:58,682 Epoch[34] Batch [1000]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.099772,	
2017-06-24 03:21:03,535 Epoch[34] Batch [1010]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.099740,	
2017-06-24 03:21:08,082 Epoch[34] Batch [1020]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.099701,	
2017-06-24 03:21:12,623 Epoch[34] Batch [1030]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.099646,	
2017-06-24 03:21:17,155 Epoch[34] Batch [1040]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.099559,	
2017-06-24 03:21:21,789 Epoch[34] Batch [1050]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.099610,	
2017-06-24 03:21:26,314 Epoch[34] Batch [1060]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.099608,	
2017-06-24 03:21:30,718 Epoch[34] Batch [1070]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099622,	
2017-06-24 03:21:35,334 Epoch[34] Batch [1080]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.099723,	
2017-06-24 03:21:39,722 Epoch[34] Batch [1090]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.099715,	
2017-06-24 03:21:44,154 Epoch[34] Batch [1100]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.099820,	
2017-06-24 03:21:48,536 Epoch[34] Batch [1110]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.099845,	
2017-06-24 03:21:52,932 Epoch[34] Batch [1120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.099792,	
2017-06-24 03:21:57,379 Epoch[34] Batch [1130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.099637,	
2017-06-24 03:22:01,723 Epoch[34] Batch [1140]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.099442,	
2017-06-24 03:22:06,036 Epoch[34] Batch [1150]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.099333,	
2017-06-24 03:22:10,590 Epoch[34] Batch [1160]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.099355,	
2017-06-24 03:22:14,996 Epoch[34] Batch [1170]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099219,	
2017-06-24 03:22:19,372 Epoch[34] Batch [1180]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.099189,	
2017-06-24 03:22:23,794 Epoch[34] Batch [1190]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.099251,	
2017-06-24 03:22:28,277 Epoch[34] Batch [1200]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.099232,	
2017-06-24 03:22:32,691 Epoch[34] Batch [1210]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.099278,	
2017-06-24 03:22:37,157 Epoch[34] Batch [1220]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.099286,	
2017-06-24 03:22:41,600 Epoch[34] Batch [1230]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.099297,	
2017-06-24 03:22:46,054 Epoch[34] Batch [1240]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.099227,	
2017-06-24 03:22:50,503 Epoch[34] Batch [1250]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.099209,	
2017-06-24 03:22:54,967 Epoch[34] Batch [1260]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.099130,	
2017-06-24 03:22:59,538 Epoch[34] Batch [1270]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.099039,	
2017-06-24 03:23:03,928 Epoch[34] Batch [1280]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.099060,	
2017-06-24 03:23:08,549 Epoch[34] Batch [1290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.099061,	
2017-06-24 03:23:12,920 Epoch[34] Batch [1300]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.099207,	
2017-06-24 03:23:17,367 Epoch[34] Batch [1310]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.099242,	
2017-06-24 03:23:21,853 Epoch[34] Batch [1320]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.099156,	
2017-06-24 03:23:26,350 Epoch[34] Batch [1330]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.099210,	
2017-06-24 03:23:30,767 Epoch[34] Batch [1340]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.099240,	
2017-06-24 03:23:35,321 Epoch[34] Batch [1350]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.099254,	
2017-06-24 03:23:39,570 Epoch[34] Batch [1360]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.099245,	
2017-06-24 03:23:44,000 Epoch[34] Batch [1370]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.099238,	
2017-06-24 03:23:48,407 Epoch[34] Batch [1380]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099177,	
2017-06-24 03:23:52,841 Epoch[34] Batch [1390]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.099128,	
2017-06-24 03:23:57,280 Epoch[34] Batch [1400]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.099040,	
2017-06-24 03:24:01,482 Epoch[34] Batch [1410]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.099035,	
2017-06-24 03:24:05,811 Epoch[34] Batch [1420]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.098978,	
2017-06-24 03:24:10,175 Epoch[34] Batch [1430]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.098962,	
2017-06-24 03:24:14,460 Epoch[34] Batch [1440]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.098966,	
2017-06-24 03:24:18,843 Epoch[34] Batch [1450]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.098862,	
2017-06-24 03:24:23,176 Epoch[34] Batch [1460]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.098864,	
2017-06-24 03:24:27,386 Epoch[34] Batch [1470]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.098886,	
2017-06-24 03:24:31,666 Epoch[34] Batch [1480]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.098927,	
2017-06-24 03:24:34,258 Epoch[34] Train-FCNLogLoss=0.098983
2017-06-24 03:24:34,258 Epoch[34] Time cost=751.631
2017-06-24 03:24:35,116 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0035.params"
2017-06-24 03:24:36,864 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0035.states"
2017-06-24 03:24:41,907 Epoch[35] Batch [10]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.091973,	
2017-06-24 03:24:46,057 Epoch[35] Batch [20]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093013,	
2017-06-24 03:24:50,566 Epoch[35] Batch [30]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091122,	
2017-06-24 03:24:55,021 Epoch[35] Batch [40]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090082,	
2017-06-24 03:24:59,377 Epoch[35] Batch [50]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.090360,	
2017-06-24 03:25:03,705 Epoch[35] Batch [60]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.089379,	
2017-06-24 03:25:08,108 Epoch[35] Batch [70]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088913,	
2017-06-24 03:25:12,480 Epoch[35] Batch [80]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.089521,	
2017-06-24 03:25:16,806 Epoch[35] Batch [90]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.090030,	
2017-06-24 03:25:21,002 Epoch[35] Batch [100]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.089648,	
2017-06-24 03:25:25,309 Epoch[35] Batch [110]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.089361,	
2017-06-24 03:25:29,578 Epoch[35] Batch [120]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.089881,	
2017-06-24 03:25:33,817 Epoch[35] Batch [130]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.089756,	
2017-06-24 03:25:38,026 Epoch[35] Batch [140]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.090313,	
2017-06-24 03:25:42,233 Epoch[35] Batch [150]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.090845,	
2017-06-24 03:25:46,523 Epoch[35] Batch [160]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.091739,	
2017-06-24 03:25:50,665 Epoch[35] Batch [170]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.092086,	
2017-06-24 03:25:54,742 Epoch[35] Batch [180]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092253,	
2017-06-24 03:25:58,803 Epoch[35] Batch [190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.092514,	
2017-06-24 03:26:03,009 Epoch[35] Batch [200]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.092382,	
2017-06-24 03:26:07,111 Epoch[35] Batch [210]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091896,	
2017-06-24 03:26:11,336 Epoch[35] Batch [220]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.092412,	
2017-06-24 03:26:15,447 Epoch[35] Batch [230]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.092594,	
2017-06-24 03:26:19,719 Epoch[35] Batch [240]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.092304,	
2017-06-24 03:26:23,918 Epoch[35] Batch [250]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.092213,	
2017-06-24 03:26:28,119 Epoch[35] Batch [260]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.092048,	
2017-06-24 03:26:32,355 Epoch[35] Batch [270]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.092221,	
2017-06-24 03:26:36,371 Epoch[35] Batch [280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.092471,	
2017-06-24 03:26:40,462 Epoch[35] Batch [290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.092392,	
2017-06-24 03:26:44,585 Epoch[35] Batch [300]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092629,	
2017-06-24 03:26:48,772 Epoch[35] Batch [310]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.092827,	
2017-06-24 03:26:52,921 Epoch[35] Batch [320]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093019,	
2017-06-24 03:26:57,158 Epoch[35] Batch [330]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.093259,	
2017-06-24 03:27:01,287 Epoch[35] Batch [340]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093381,	
2017-06-24 03:27:05,388 Epoch[35] Batch [350]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.093480,	
2017-06-24 03:27:09,579 Epoch[35] Batch [360]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.093465,	
2017-06-24 03:27:13,882 Epoch[35] Batch [370]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.093686,	
2017-06-24 03:27:18,191 Epoch[35] Batch [380]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.094078,	
2017-06-24 03:27:22,275 Epoch[35] Batch [390]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.094158,	
2017-06-24 03:27:26,530 Epoch[35] Batch [400]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.094234,	
2017-06-24 03:27:30,761 Epoch[35] Batch [410]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.094584,	
2017-06-24 03:27:34,751 Epoch[35] Batch [420]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094844,	
2017-06-24 03:27:38,967 Epoch[35] Batch [430]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094740,	
2017-06-24 03:27:42,944 Epoch[35] Batch [440]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094765,	
2017-06-24 03:27:46,949 Epoch[35] Batch [450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094835,	
2017-06-24 03:27:50,980 Epoch[35] Batch [460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094844,	
2017-06-24 03:27:55,132 Epoch[35] Batch [470]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095147,	
2017-06-24 03:27:59,337 Epoch[35] Batch [480]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095228,	
2017-06-24 03:28:03,505 Epoch[35] Batch [490]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095404,	
2017-06-24 03:28:07,690 Epoch[35] Batch [500]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095491,	
2017-06-24 03:28:11,874 Epoch[35] Batch [510]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095450,	
2017-06-24 03:28:16,044 Epoch[35] Batch [520]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095401,	
2017-06-24 03:28:20,227 Epoch[35] Batch [530]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095456,	
2017-06-24 03:28:24,313 Epoch[35] Batch [540]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095555,	
2017-06-24 03:28:28,467 Epoch[35] Batch [550]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095445,	
2017-06-24 03:28:32,672 Epoch[35] Batch [560]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095538,	
2017-06-24 03:28:36,870 Epoch[35] Batch [570]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095393,	
2017-06-24 03:28:41,139 Epoch[35] Batch [580]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095375,	
2017-06-24 03:28:45,230 Epoch[35] Batch [590]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095404,	
2017-06-24 03:28:49,520 Epoch[35] Batch [600]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.095536,	
2017-06-24 03:28:53,668 Epoch[35] Batch [610]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095770,	
2017-06-24 03:28:57,848 Epoch[35] Batch [620]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095818,	
2017-06-24 03:29:02,062 Epoch[35] Batch [630]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.095910,	
2017-06-24 03:29:06,182 Epoch[35] Batch [640]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095871,	
2017-06-24 03:29:10,387 Epoch[35] Batch [650]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095840,	
2017-06-24 03:29:14,582 Epoch[35] Batch [660]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095953,	
2017-06-24 03:29:18,855 Epoch[35] Batch [670]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.095911,	
2017-06-24 03:29:23,026 Epoch[35] Batch [680]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095808,	
2017-06-24 03:29:27,237 Epoch[35] Batch [690]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.095760,	
2017-06-24 03:29:31,432 Epoch[35] Batch [700]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095709,	
2017-06-24 03:29:35,653 Epoch[35] Batch [710]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095727,	
2017-06-24 03:29:39,977 Epoch[35] Batch [720]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095724,	
2017-06-24 03:29:44,224 Epoch[35] Batch [730]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095918,	
2017-06-24 03:29:48,269 Epoch[35] Batch [740]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095976,	
2017-06-24 03:29:52,457 Epoch[35] Batch [750]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095937,	
2017-06-24 03:29:56,568 Epoch[35] Batch [760]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096007,	
2017-06-24 03:30:00,738 Epoch[35] Batch [770]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.096062,	
2017-06-24 03:30:04,829 Epoch[35] Batch [780]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.096149,	
2017-06-24 03:30:08,866 Epoch[35] Batch [790]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096080,	
2017-06-24 03:30:13,080 Epoch[35] Batch [800]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.096020,	
2017-06-24 03:30:17,222 Epoch[35] Batch [810]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095992,	
2017-06-24 03:30:21,537 Epoch[35] Batch [820]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.095892,	
2017-06-24 03:30:25,701 Epoch[35] Batch [830]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095826,	
2017-06-24 03:30:29,864 Epoch[35] Batch [840]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095851,	
2017-06-24 03:30:34,075 Epoch[35] Batch [850]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.095742,	
2017-06-24 03:30:38,272 Epoch[35] Batch [860]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095644,	
2017-06-24 03:30:42,655 Epoch[35] Batch [870]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095643,	
2017-06-24 03:30:46,834 Epoch[35] Batch [880]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095539,	
2017-06-24 03:30:50,979 Epoch[35] Batch [890]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095477,	
2017-06-24 03:30:55,170 Epoch[35] Batch [900]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095543,	
2017-06-24 03:30:59,313 Epoch[35] Batch [910]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095549,	
2017-06-24 03:31:03,526 Epoch[35] Batch [920]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.095486,	
2017-06-24 03:31:07,733 Epoch[35] Batch [930]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095481,	
2017-06-24 03:31:12,068 Epoch[35] Batch [940]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.095584,	
2017-06-24 03:31:16,173 Epoch[35] Batch [950]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095576,	
2017-06-24 03:31:20,424 Epoch[35] Batch [960]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095543,	
2017-06-24 03:31:24,765 Epoch[35] Batch [970]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.095711,	
2017-06-24 03:31:29,195 Epoch[35] Batch [980]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.095723,	
2017-06-24 03:31:33,390 Epoch[35] Batch [990]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095666,	
2017-06-24 03:31:37,575 Epoch[35] Batch [1000]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095658,	
2017-06-24 03:31:41,946 Epoch[35] Batch [1010]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095680,	
2017-06-24 03:31:46,389 Epoch[35] Batch [1020]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.095690,	
2017-06-24 03:31:50,862 Epoch[35] Batch [1030]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.095676,	
2017-06-24 03:31:55,343 Epoch[35] Batch [1040]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.095595,	
2017-06-24 03:31:59,759 Epoch[35] Batch [1050]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.095454,	
2017-06-24 03:32:04,081 Epoch[35] Batch [1060]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095493,	
2017-06-24 03:32:08,432 Epoch[35] Batch [1070]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095570,	
2017-06-24 03:32:12,821 Epoch[35] Batch [1080]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.095484,	
2017-06-24 03:32:17,140 Epoch[35] Batch [1090]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.095510,	
2017-06-24 03:32:21,540 Epoch[35] Batch [1100]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.095472,	
2017-06-24 03:32:26,022 Epoch[35] Batch [1110]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.095519,	
2017-06-24 03:32:30,369 Epoch[35] Batch [1120]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095461,	
2017-06-24 03:32:34,691 Epoch[35] Batch [1130]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.095473,	
2017-06-24 03:32:38,954 Epoch[35] Batch [1140]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095410,	
2017-06-24 03:32:43,179 Epoch[35] Batch [1150]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.095327,	
2017-06-24 03:32:47,449 Epoch[35] Batch [1160]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095379,	
2017-06-24 03:32:51,730 Epoch[35] Batch [1170]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.095448,	
2017-06-24 03:32:56,110 Epoch[35] Batch [1180]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095426,	
2017-06-24 03:33:00,281 Epoch[35] Batch [1190]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095505,	
2017-06-24 03:33:04,606 Epoch[35] Batch [1200]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095526,	
2017-06-24 03:33:08,783 Epoch[35] Batch [1210]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.095500,	
2017-06-24 03:33:12,995 Epoch[35] Batch [1220]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.095497,	
2017-06-24 03:33:17,242 Epoch[35] Batch [1230]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095457,	
2017-06-24 03:33:21,603 Epoch[35] Batch [1240]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095491,	
2017-06-24 03:33:25,810 Epoch[35] Batch [1250]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095459,	
2017-06-24 03:33:29,999 Epoch[35] Batch [1260]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095499,	
2017-06-24 03:33:34,360 Epoch[35] Batch [1270]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095445,	
2017-06-24 03:33:38,743 Epoch[35] Batch [1280]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095452,	
2017-06-24 03:33:43,011 Epoch[35] Batch [1290]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095444,	
2017-06-24 03:33:47,364 Epoch[35] Batch [1300]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.095418,	
2017-06-24 03:33:51,685 Epoch[35] Batch [1310]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.095431,	
2017-06-24 03:33:56,103 Epoch[35] Batch [1320]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.095512,	
2017-06-24 03:34:00,368 Epoch[35] Batch [1330]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095597,	
2017-06-24 03:34:04,673 Epoch[35] Batch [1340]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.095591,	
2017-06-24 03:34:09,014 Epoch[35] Batch [1350]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.095553,	
2017-06-24 03:34:13,423 Epoch[35] Batch [1360]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095583,	
2017-06-24 03:34:17,846 Epoch[35] Batch [1370]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.095708,	
2017-06-24 03:34:22,193 Epoch[35] Batch [1380]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095741,	
2017-06-24 03:34:26,503 Epoch[35] Batch [1390]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.095702,	
2017-06-24 03:34:30,898 Epoch[35] Batch [1400]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095745,	
2017-06-24 03:34:35,194 Epoch[35] Batch [1410]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.095709,	
2017-06-24 03:34:39,430 Epoch[35] Batch [1420]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095702,	
2017-06-24 03:34:43,817 Epoch[35] Batch [1430]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095679,	
2017-06-24 03:34:48,231 Epoch[35] Batch [1440]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.095757,	
2017-06-24 03:34:52,595 Epoch[35] Batch [1450]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095813,	
2017-06-24 03:34:56,901 Epoch[35] Batch [1460]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.095875,	
2017-06-24 03:35:01,093 Epoch[35] Batch [1470]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095950,	
2017-06-24 03:35:05,354 Epoch[35] Batch [1480]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.095908,	
2017-06-24 03:35:07,977 Epoch[35] Train-FCNLogLoss=0.095890
2017-06-24 03:35:07,977 Epoch[35] Time cost=631.113
2017-06-24 03:35:08,914 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0036.params"
2017-06-24 03:35:11,418 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0036.states"
2017-06-24 03:35:16,162 Epoch[36] Batch [10]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095795,	
2017-06-24 03:35:20,534 Epoch[36] Batch [20]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.097121,	
2017-06-24 03:35:25,012 Epoch[36] Batch [30]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.097075,	
2017-06-24 03:35:29,441 Epoch[36] Batch [40]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.096873,	
2017-06-24 03:35:33,828 Epoch[36] Batch [50]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.098330,	
2017-06-24 03:35:38,003 Epoch[36] Batch [60]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.098280,	
2017-06-24 03:35:42,468 Epoch[36] Batch [70]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097273,	
2017-06-24 03:35:46,844 Epoch[36] Batch [80]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.097216,	
2017-06-24 03:35:51,046 Epoch[36] Batch [90]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.096483,	
2017-06-24 03:35:55,363 Epoch[36] Batch [100]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096322,	
2017-06-24 03:35:59,639 Epoch[36] Batch [110]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.096444,	
2017-06-24 03:36:03,951 Epoch[36] Batch [120]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.096179,	
2017-06-24 03:36:08,320 Epoch[36] Batch [130]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095706,	
2017-06-24 03:36:12,817 Epoch[36] Batch [140]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.095729,	
2017-06-24 03:36:17,036 Epoch[36] Batch [150]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095857,	
2017-06-24 03:36:21,394 Epoch[36] Batch [160]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096414,	
2017-06-24 03:36:25,582 Epoch[36] Batch [170]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.096106,	
2017-06-24 03:36:29,746 Epoch[36] Batch [180]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095560,	
2017-06-24 03:36:33,912 Epoch[36] Batch [190]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096105,	
2017-06-24 03:36:38,127 Epoch[36] Batch [200]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.096008,	
2017-06-24 03:36:42,256 Epoch[36] Batch [210]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095840,	
2017-06-24 03:36:46,461 Epoch[36] Batch [220]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095904,	
2017-06-24 03:36:50,626 Epoch[36] Batch [230]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095877,	
2017-06-24 03:36:54,770 Epoch[36] Batch [240]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095836,	
2017-06-24 03:36:58,922 Epoch[36] Batch [250]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095124,	
2017-06-24 03:37:03,099 Epoch[36] Batch [260]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094941,	
2017-06-24 03:37:07,223 Epoch[36] Batch [270]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094681,	
2017-06-24 03:37:11,362 Epoch[36] Batch [280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094342,	
2017-06-24 03:37:15,513 Epoch[36] Batch [290]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094517,	
2017-06-24 03:37:19,748 Epoch[36] Batch [300]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.094429,	
2017-06-24 03:37:23,925 Epoch[36] Batch [310]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094383,	
2017-06-24 03:37:28,048 Epoch[36] Batch [320]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094281,	
2017-06-24 03:37:32,302 Epoch[36] Batch [330]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.094399,	
2017-06-24 03:37:36,405 Epoch[36] Batch [340]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094027,	
2017-06-24 03:37:40,437 Epoch[36] Batch [350]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094039,	
2017-06-24 03:37:44,559 Epoch[36] Batch [360]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.093826,	
2017-06-24 03:37:48,925 Epoch[36] Batch [370]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.093863,	
2017-06-24 03:37:53,081 Epoch[36] Batch [380]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.093338,	
2017-06-24 03:37:57,162 Epoch[36] Batch [390]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093278,	
2017-06-24 03:38:01,391 Epoch[36] Batch [400]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.093550,	
2017-06-24 03:38:05,556 Epoch[36] Batch [410]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.093751,	
2017-06-24 03:38:09,684 Epoch[36] Batch [420]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093733,	
2017-06-24 03:38:14,060 Epoch[36] Batch [430]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.093598,	
2017-06-24 03:38:18,299 Epoch[36] Batch [440]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.093880,	
2017-06-24 03:38:22,522 Epoch[36] Batch [450]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.093837,	
2017-06-24 03:38:26,649 Epoch[36] Batch [460]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093883,	
2017-06-24 03:38:31,063 Epoch[36] Batch [470]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.093892,	
2017-06-24 03:38:35,341 Epoch[36] Batch [480]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.093932,	
2017-06-24 03:38:39,549 Epoch[36] Batch [490]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.093997,	
2017-06-24 03:38:43,845 Epoch[36] Batch [500]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.094126,	
2017-06-24 03:38:48,002 Epoch[36] Batch [510]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.094153,	
2017-06-24 03:38:52,118 Epoch[36] Batch [520]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.094171,	
2017-06-24 03:38:56,314 Epoch[36] Batch [530]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094243,	
2017-06-24 03:39:00,454 Epoch[36] Batch [540]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094310,	
2017-06-24 03:39:04,546 Epoch[36] Batch [550]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094273,	
2017-06-24 03:39:08,792 Epoch[36] Batch [560]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.094489,	
2017-06-24 03:39:12,943 Epoch[36] Batch [570]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094230,	
2017-06-24 03:39:17,074 Epoch[36] Batch [580]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094337,	
2017-06-24 03:39:21,137 Epoch[36] Batch [590]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094343,	
2017-06-24 03:39:25,439 Epoch[36] Batch [600]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094377,	
2017-06-24 03:39:29,664 Epoch[36] Batch [610]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094315,	
2017-06-24 03:39:33,790 Epoch[36] Batch [620]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094212,	
2017-06-24 03:39:37,882 Epoch[36] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094046,	
2017-06-24 03:39:41,954 Epoch[36] Batch [640]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094240,	
2017-06-24 03:39:46,090 Epoch[36] Batch [650]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094371,	
2017-06-24 03:39:50,334 Epoch[36] Batch [660]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.094422,	
2017-06-24 03:39:54,562 Epoch[36] Batch [670]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094427,	
2017-06-24 03:39:58,640 Epoch[36] Batch [680]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094482,	
2017-06-24 03:40:03,016 Epoch[36] Batch [690]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.094560,	
2017-06-24 03:40:07,061 Epoch[36] Batch [700]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094555,	
2017-06-24 03:40:11,368 Epoch[36] Batch [710]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094463,	
2017-06-24 03:40:15,758 Epoch[36] Batch [720]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.094430,	
2017-06-24 03:40:20,050 Epoch[36] Batch [730]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094357,	
2017-06-24 03:40:24,533 Epoch[36] Batch [740]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.094478,	
2017-06-24 03:40:29,046 Epoch[36] Batch [750]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.094476,	
2017-06-24 03:40:33,575 Epoch[36] Batch [760]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.094405,	
2017-06-24 03:40:37,770 Epoch[36] Batch [770]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094369,	
2017-06-24 03:40:42,095 Epoch[36] Batch [780]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.094386,	
2017-06-24 03:40:46,269 Epoch[36] Batch [790]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094421,	
2017-06-24 03:40:50,815 Epoch[36] Batch [800]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.094464,	
2017-06-24 03:40:55,324 Epoch[36] Batch [810]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.094395,	
2017-06-24 03:40:59,675 Epoch[36] Batch [820]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.094352,	
2017-06-24 03:41:04,003 Epoch[36] Batch [830]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.094400,	
2017-06-24 03:41:08,796 Epoch[36] Batch [840]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.094413,	
2017-06-24 03:41:13,116 Epoch[36] Batch [850]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094465,	
2017-06-24 03:41:17,635 Epoch[36] Batch [860]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.094483,	
2017-06-24 03:41:22,226 Epoch[36] Batch [870]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.094494,	
2017-06-24 03:41:26,604 Epoch[36] Batch [880]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.094483,	
2017-06-24 03:41:31,039 Epoch[36] Batch [890]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.094498,	
2017-06-24 03:41:35,456 Epoch[36] Batch [900]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.094455,	
2017-06-24 03:41:40,012 Epoch[36] Batch [910]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.094415,	
2017-06-24 03:41:44,648 Epoch[36] Batch [920]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.094326,	
2017-06-24 03:41:49,229 Epoch[36] Batch [930]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.094428,	
2017-06-24 03:41:53,799 Epoch[36] Batch [940]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.094502,	
2017-06-24 03:41:58,261 Epoch[36] Batch [950]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.094471,	
2017-06-24 03:42:03,325 Epoch[36] Batch [960]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.094543,	
2017-06-24 03:42:08,172 Epoch[36] Batch [970]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.094442,	
2017-06-24 03:42:12,554 Epoch[36] Batch [980]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.094314,	
2017-06-24 03:42:17,193 Epoch[36] Batch [990]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.094258,	
2017-06-24 03:42:22,285 Epoch[36] Batch [1000]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.094203,	
2017-06-24 03:42:27,155 Epoch[36] Batch [1010]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.094096,	
2017-06-24 03:42:32,478 Epoch[36] Batch [1020]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094082,	
2017-06-24 03:42:37,198 Epoch[36] Batch [1030]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.094093,	
2017-06-24 03:42:42,239 Epoch[36] Batch [1040]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094024,	
2017-06-24 03:42:47,278 Epoch[36] Batch [1050]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094056,	
2017-06-24 03:42:51,920 Epoch[36] Batch [1060]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.094009,	
2017-06-24 03:42:57,124 Epoch[36] Batch [1070]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093978,	
2017-06-24 03:43:02,081 Epoch[36] Batch [1080]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093967,	
2017-06-24 03:43:07,120 Epoch[36] Batch [1090]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093986,	
2017-06-24 03:43:12,146 Epoch[36] Batch [1100]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.093987,	
2017-06-24 03:43:17,458 Epoch[36] Batch [1110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093905,	
2017-06-24 03:43:22,127 Epoch[36] Batch [1120]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.094022,	
2017-06-24 03:43:26,553 Epoch[36] Batch [1130]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.094034,	
2017-06-24 03:43:31,413 Epoch[36] Batch [1140]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.094038,	
2017-06-24 03:43:36,092 Epoch[36] Batch [1150]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.093922,	
2017-06-24 03:43:41,101 Epoch[36] Batch [1160]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.093907,	
2017-06-24 03:43:46,100 Epoch[36] Batch [1170]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.093941,	
2017-06-24 03:43:51,172 Epoch[36] Batch [1180]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093955,	
2017-06-24 03:43:56,136 Epoch[36] Batch [1190]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.093967,	
2017-06-24 03:44:01,458 Epoch[36] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094022,	
2017-06-24 03:44:06,178 Epoch[36] Batch [1210]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.093987,	
2017-06-24 03:44:11,893 Epoch[36] Batch [1220]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.093960,	
2017-06-24 03:44:17,415 Epoch[36] Batch [1230]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.093902,	
2017-06-24 03:44:22,560 Epoch[36] Batch [1240]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093910,	
2017-06-24 03:44:27,458 Epoch[36] Batch [1250]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.093885,	
2017-06-24 03:44:32,494 Epoch[36] Batch [1260]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093879,	
2017-06-24 03:44:38,287 Epoch[36] Batch [1270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093876,	
2017-06-24 03:44:43,161 Epoch[36] Batch [1280]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.093884,	
2017-06-24 03:44:48,073 Epoch[36] Batch [1290]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093942,	
2017-06-24 03:44:53,892 Epoch[36] Batch [1300]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.094024,	
2017-06-24 03:44:59,444 Epoch[36] Batch [1310]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.094019,	
2017-06-24 03:45:04,752 Epoch[36] Batch [1320]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094029,	
2017-06-24 03:45:10,247 Epoch[36] Batch [1330]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.094075,	
2017-06-24 03:45:16,056 Epoch[36] Batch [1340]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.094183,	
2017-06-24 03:45:21,602 Epoch[36] Batch [1350]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.094179,	
2017-06-24 03:45:27,446 Epoch[36] Batch [1360]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.094259,	
2017-06-24 03:45:33,725 Epoch[36] Batch [1370]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.094276,	
2017-06-24 03:45:39,414 Epoch[36] Batch [1380]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.094379,	
2017-06-24 03:45:45,596 Epoch[36] Batch [1390]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.094438,	
2017-06-24 03:45:51,248 Epoch[36] Batch [1400]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.094414,	
2017-06-24 03:45:56,596 Epoch[36] Batch [1410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094435,	
2017-06-24 03:46:02,115 Epoch[36] Batch [1420]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094525,	
2017-06-24 03:46:07,778 Epoch[36] Batch [1430]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.094490,	
2017-06-24 03:46:13,407 Epoch[36] Batch [1440]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.094508,	
2017-06-24 03:46:18,872 Epoch[36] Batch [1450]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.094476,	
2017-06-24 03:46:25,201 Epoch[36] Batch [1460]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094489,	
2017-06-24 03:46:30,960 Epoch[36] Batch [1470]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.094549,	
2017-06-24 03:46:36,814 Epoch[36] Batch [1480]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.094579,	
2017-06-24 03:46:40,178 Epoch[36] Train-FCNLogLoss=0.094605
2017-06-24 03:46:40,178 Epoch[36] Time cost=688.760
2017-06-24 03:46:41,017 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0037.params"
2017-06-24 03:46:44,439 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0037.states"
2017-06-24 03:46:52,143 Epoch[37] Batch [10]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.104725,	
2017-06-24 03:46:58,889 Epoch[37] Batch [20]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.098610,	
2017-06-24 03:47:05,739 Epoch[37] Batch [30]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.098454,	
2017-06-24 03:47:13,375 Epoch[37] Batch [40]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.096166,	
2017-06-24 03:47:20,601 Epoch[37] Batch [50]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.095080,	
2017-06-24 03:47:27,786 Epoch[37] Batch [60]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.095212,	
2017-06-24 03:47:35,567 Epoch[37] Batch [70]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.093315,	
2017-06-24 03:47:42,416 Epoch[37] Batch [80]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.092827,	
2017-06-24 03:47:49,803 Epoch[37] Batch [90]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.092457,	
2017-06-24 03:47:56,903 Epoch[37] Batch [100]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.092616,	
2017-06-24 03:48:04,138 Epoch[37] Batch [110]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.092756,	
2017-06-24 03:48:11,341 Epoch[37] Batch [120]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.092576,	
2017-06-24 03:48:18,331 Epoch[37] Batch [130]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.092931,	
2017-06-24 03:48:25,428 Epoch[37] Batch [140]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.093802,	
2017-06-24 03:48:32,970 Epoch[37] Batch [150]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.093498,	
2017-06-24 03:48:40,169 Epoch[37] Batch [160]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.093098,	
2017-06-24 03:48:47,213 Epoch[37] Batch [170]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.092802,	
2017-06-24 03:48:54,569 Epoch[37] Batch [180]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.093099,	
2017-06-24 03:49:01,757 Epoch[37] Batch [190]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.093025,	
2017-06-24 03:49:08,844 Epoch[37] Batch [200]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.092685,	
2017-06-24 03:49:16,315 Epoch[37] Batch [210]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.093319,	
2017-06-24 03:49:23,295 Epoch[37] Batch [220]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.093183,	
2017-06-24 03:49:30,939 Epoch[37] Batch [230]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.093425,	
2017-06-24 03:49:38,319 Epoch[37] Batch [240]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.093347,	
2017-06-24 03:49:45,203 Epoch[37] Batch [250]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.093482,	
2017-06-24 03:49:52,305 Epoch[37] Batch [260]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.093593,	
2017-06-24 03:49:59,355 Epoch[37] Batch [270]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.093270,	
2017-06-24 03:50:06,632 Epoch[37] Batch [280]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.093143,	
2017-06-24 03:50:14,366 Epoch[37] Batch [290]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.093092,	
2017-06-24 03:50:21,181 Epoch[37] Batch [300]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.093169,	
2017-06-24 03:50:28,234 Epoch[37] Batch [310]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.093310,	
2017-06-24 03:50:35,104 Epoch[37] Batch [320]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.093303,	
2017-06-24 03:50:42,281 Epoch[37] Batch [330]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.093079,	
2017-06-24 03:50:49,317 Epoch[37] Batch [340]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.093044,	
2017-06-24 03:50:56,487 Epoch[37] Batch [350]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.092979,	
2017-06-24 03:51:03,706 Epoch[37] Batch [360]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.092950,	
2017-06-24 03:51:11,122 Epoch[37] Batch [370]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.092699,	
2017-06-24 03:51:17,851 Epoch[37] Batch [380]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.092698,	
2017-06-24 03:51:24,016 Epoch[37] Batch [390]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.092885,	
2017-06-24 03:51:30,277 Epoch[37] Batch [400]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.092935,	
2017-06-24 03:51:36,936 Epoch[37] Batch [410]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.093173,	
2017-06-24 03:51:43,476 Epoch[37] Batch [420]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.093337,	
2017-06-24 03:51:50,886 Epoch[37] Batch [430]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.093584,	
2017-06-24 03:51:58,093 Epoch[37] Batch [440]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.093600,	
2017-06-24 03:52:05,072 Epoch[37] Batch [450]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.093718,	
2017-06-24 03:52:12,154 Epoch[37] Batch [460]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.093979,	
2017-06-24 03:52:19,574 Epoch[37] Batch [470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.094092,	
2017-06-24 03:52:26,782 Epoch[37] Batch [480]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.094150,	
2017-06-24 03:52:33,783 Epoch[37] Batch [490]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.094379,	
2017-06-24 03:52:40,580 Epoch[37] Batch [500]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.094297,	
2017-06-24 03:52:47,903 Epoch[37] Batch [510]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.094262,	
2017-06-24 03:52:54,862 Epoch[37] Batch [520]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.094313,	
2017-06-24 03:53:01,835 Epoch[37] Batch [530]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.094332,	
2017-06-24 03:53:08,939 Epoch[37] Batch [540]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094478,	
2017-06-24 03:53:16,080 Epoch[37] Batch [550]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.094431,	
2017-06-24 03:53:23,260 Epoch[37] Batch [560]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.094472,	
2017-06-24 03:53:29,902 Epoch[37] Batch [570]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.094666,	
2017-06-24 03:53:36,397 Epoch[37] Batch [580]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.094403,	
2017-06-24 03:53:43,688 Epoch[37] Batch [590]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.094514,	
2017-06-24 03:53:50,491 Epoch[37] Batch [600]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.094478,	
2017-06-24 03:53:57,228 Epoch[37] Batch [610]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.094753,	
2017-06-24 03:54:04,237 Epoch[37] Batch [620]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.094904,	
2017-06-24 03:54:11,105 Epoch[37] Batch [630]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.095073,	
2017-06-24 03:54:18,510 Epoch[37] Batch [640]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.095072,	
2017-06-24 03:54:25,559 Epoch[37] Batch [650]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.095324,	
2017-06-24 03:54:32,823 Epoch[37] Batch [660]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.095274,	
2017-06-24 03:54:40,274 Epoch[37] Batch [670]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.095530,	
2017-06-24 03:54:47,677 Epoch[37] Batch [680]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.095773,	
2017-06-24 03:54:54,498 Epoch[37] Batch [690]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.095740,	
2017-06-24 03:55:01,250 Epoch[37] Batch [700]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.096046,	
2017-06-24 03:55:08,188 Epoch[37] Batch [710]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.096390,	
2017-06-24 03:55:15,443 Epoch[37] Batch [720]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.096650,	
2017-06-24 03:55:22,770 Epoch[37] Batch [730]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.097002,	
2017-06-24 03:55:29,625 Epoch[37] Batch [740]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.097339,	
2017-06-24 03:55:36,668 Epoch[37] Batch [750]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.097590,	
2017-06-24 03:55:43,681 Epoch[37] Batch [760]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.097836,	
2017-06-24 03:55:50,848 Epoch[37] Batch [770]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.097855,	
2017-06-24 03:55:58,070 Epoch[37] Batch [780]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.097847,	
2017-06-24 03:56:04,963 Epoch[37] Batch [790]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.097937,	
2017-06-24 03:56:12,025 Epoch[37] Batch [800]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.097954,	
2017-06-24 03:56:18,852 Epoch[37] Batch [810]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.097905,	
2017-06-24 03:56:26,146 Epoch[37] Batch [820]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097902,	
2017-06-24 03:56:33,530 Epoch[37] Batch [830]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.097946,	
2017-06-24 03:56:40,415 Epoch[37] Batch [840]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.097908,	
2017-06-24 03:56:47,717 Epoch[37] Batch [850]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097924,	
2017-06-24 03:56:54,587 Epoch[37] Batch [860]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.097945,	
2017-06-24 03:57:01,624 Epoch[37] Batch [870]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.097986,	
2017-06-24 03:57:08,373 Epoch[37] Batch [880]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.097930,	
2017-06-24 03:57:15,270 Epoch[37] Batch [890]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.097879,	
2017-06-24 03:57:22,568 Epoch[37] Batch [900]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097824,	
2017-06-24 03:57:29,453 Epoch[37] Batch [910]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.097815,	
2017-06-24 03:57:36,551 Epoch[37] Batch [920]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.097815,	
2017-06-24 03:57:43,580 Epoch[37] Batch [930]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.097721,	
2017-06-24 03:57:50,488 Epoch[37] Batch [940]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.097840,	
2017-06-24 03:57:57,761 Epoch[37] Batch [950]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.097812,	
2017-06-24 03:58:05,086 Epoch[37] Batch [960]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.097833,	
2017-06-24 03:58:12,564 Epoch[37] Batch [970]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.097811,	
2017-06-24 03:58:20,168 Epoch[37] Batch [980]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.097741,	
2017-06-24 03:58:27,426 Epoch[37] Batch [990]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.097892,	
2017-06-24 03:58:34,821 Epoch[37] Batch [1000]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.097934,	
2017-06-24 03:58:41,971 Epoch[37] Batch [1010]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.097982,	
2017-06-24 03:58:49,056 Epoch[37] Batch [1020]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.097895,	
2017-06-24 03:58:56,485 Epoch[37] Batch [1030]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.097753,	
2017-06-24 03:59:03,591 Epoch[37] Batch [1040]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.097745,	
2017-06-24 03:59:10,363 Epoch[37] Batch [1050]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.097745,	
2017-06-24 03:59:17,502 Epoch[37] Batch [1060]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.097652,	
2017-06-24 03:59:24,650 Epoch[37] Batch [1070]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.097545,	
2017-06-24 03:59:31,757 Epoch[37] Batch [1080]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.097422,	
2017-06-24 03:59:38,777 Epoch[37] Batch [1090]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.097278,	
2017-06-24 03:59:46,136 Epoch[37] Batch [1100]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.097285,	
2017-06-24 03:59:53,174 Epoch[37] Batch [1110]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.097196,	
2017-06-24 04:00:00,369 Epoch[37] Batch [1120]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.097143,	
2017-06-24 04:00:07,465 Epoch[37] Batch [1130]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.097193,	
2017-06-24 04:00:14,416 Epoch[37] Batch [1140]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.097225,	
2017-06-24 04:00:21,610 Epoch[37] Batch [1150]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.097168,	
2017-06-24 04:00:28,689 Epoch[37] Batch [1160]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.097177,	
2017-06-24 04:00:36,126 Epoch[37] Batch [1170]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.097213,	
2017-06-24 04:00:43,734 Epoch[37] Batch [1180]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.097156,	
2017-06-24 04:00:51,296 Epoch[37] Batch [1190]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.097151,	
2017-06-24 04:00:58,738 Epoch[37] Batch [1200]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.097074,	
2017-06-24 04:01:05,448 Epoch[37] Batch [1210]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.097085,	
2017-06-24 04:01:12,472 Epoch[37] Batch [1220]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.097015,	
2017-06-24 04:01:19,405 Epoch[37] Batch [1230]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.097020,	
2017-06-24 04:01:26,731 Epoch[37] Batch [1240]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.096990,	
2017-06-24 04:01:34,296 Epoch[37] Batch [1250]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096975,	
2017-06-24 04:01:41,493 Epoch[37] Batch [1260]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.097002,	
2017-06-24 04:01:48,973 Epoch[37] Batch [1270]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096966,	
2017-06-24 04:01:56,196 Epoch[37] Batch [1280]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.096986,	
2017-06-24 04:02:03,150 Epoch[37] Batch [1290]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.097294,	
2017-06-24 04:02:10,411 Epoch[37] Batch [1300]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.097851,	
2017-06-24 04:02:17,647 Epoch[37] Batch [1310]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.098418,	
2017-06-24 04:02:25,068 Epoch[37] Batch [1320]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098766,	
2017-06-24 04:02:32,634 Epoch[37] Batch [1330]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098962,	
2017-06-24 04:02:40,052 Epoch[37] Batch [1340]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.099172,	
2017-06-24 04:02:47,558 Epoch[37] Batch [1350]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099286,	
2017-06-24 04:02:54,659 Epoch[37] Batch [1360]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.099316,	
2017-06-24 04:03:01,635 Epoch[37] Batch [1370]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.099343,	
2017-06-24 04:03:08,716 Epoch[37] Batch [1380]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.099379,	
2017-06-24 04:03:16,024 Epoch[37] Batch [1390]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.099406,	
2017-06-24 04:03:23,499 Epoch[37] Batch [1400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.099440,	
2017-06-24 04:03:30,882 Epoch[37] Batch [1410]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.099389,	
2017-06-24 04:03:38,246 Epoch[37] Batch [1420]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.099325,	
2017-06-24 04:03:45,514 Epoch[37] Batch [1430]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.099349,	
2017-06-24 04:03:53,114 Epoch[37] Batch [1440]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.099338,	
2017-06-24 04:03:59,892 Epoch[37] Batch [1450]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.099375,	
2017-06-24 04:04:07,130 Epoch[37] Batch [1460]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.099374,	
2017-06-24 04:04:14,073 Epoch[37] Batch [1470]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.099325,	
2017-06-24 04:04:21,331 Epoch[37] Batch [1480]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.099331,	
2017-06-24 04:04:25,714 Epoch[37] Train-FCNLogLoss=0.099282
2017-06-24 04:04:25,714 Epoch[37] Time cost=1061.275
2017-06-24 04:04:26,551 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0038.params"
2017-06-24 04:04:30,176 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0038.states"
2017-06-24 04:04:38,337 Epoch[38] Batch [10]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.097004,	
2017-06-24 04:04:45,613 Epoch[38] Batch [20]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.096992,	
2017-06-24 04:04:52,206 Epoch[38] Batch [30]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.102541,	
2017-06-24 04:04:59,065 Epoch[38] Batch [40]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.099396,	
2017-06-24 04:05:06,239 Epoch[38] Batch [50]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.097475,	
2017-06-24 04:05:13,583 Epoch[38] Batch [60]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097690,	
2017-06-24 04:05:21,095 Epoch[38] Batch [70]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099834,	
2017-06-24 04:05:27,762 Epoch[38] Batch [80]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109941,	
2017-06-24 04:05:35,292 Epoch[38] Batch [90]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.114650,	
2017-06-24 04:05:42,225 Epoch[38] Batch [100]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.120471,	
2017-06-24 04:05:49,129 Epoch[38] Batch [110]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.120023,	
2017-06-24 04:05:56,150 Epoch[38] Batch [120]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.122128,	
2017-06-24 04:06:03,541 Epoch[38] Batch [130]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.121525,	
2017-06-24 04:06:10,943 Epoch[38] Batch [140]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.122680,	
2017-06-24 04:06:17,996 Epoch[38] Batch [150]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.123789,	
2017-06-24 04:06:25,199 Epoch[38] Batch [160]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.124003,	
2017-06-24 04:06:32,686 Epoch[38] Batch [170]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.124012,	
2017-06-24 04:06:39,859 Epoch[38] Batch [180]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.123417,	
2017-06-24 04:06:47,140 Epoch[38] Batch [190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.123146,	
2017-06-24 04:06:54,528 Epoch[38] Batch [200]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.122425,	
2017-06-24 04:07:01,401 Epoch[38] Batch [210]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.122546,	
2017-06-24 04:07:08,790 Epoch[38] Batch [220]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.121762,	
2017-06-24 04:07:16,153 Epoch[38] Batch [230]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.121225,	
2017-06-24 04:07:22,914 Epoch[38] Batch [240]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.120791,	
2017-06-24 04:07:30,161 Epoch[38] Batch [250]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.119802,	
2017-06-24 04:07:37,981 Epoch[38] Batch [260]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.119295,	
2017-06-24 04:07:44,943 Epoch[38] Batch [270]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.118459,	
2017-06-24 04:07:52,350 Epoch[38] Batch [280]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.117945,	
2017-06-24 04:07:59,814 Epoch[38] Batch [290]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.117723,	
2017-06-24 04:08:07,186 Epoch[38] Batch [300]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.116859,	
2017-06-24 04:08:14,410 Epoch[38] Batch [310]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.116021,	
2017-06-24 04:08:21,443 Epoch[38] Batch [320]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.115175,	
2017-06-24 04:08:28,421 Epoch[38] Batch [330]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.114740,	
2017-06-24 04:08:35,523 Epoch[38] Batch [340]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.114206,	
2017-06-24 04:08:42,881 Epoch[38] Batch [350]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.113606,	
2017-06-24 04:08:50,859 Epoch[38] Batch [360]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.113081,	
2017-06-24 04:08:58,415 Epoch[38] Batch [370]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.112674,	
2017-06-24 04:09:05,805 Epoch[38] Batch [380]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.112292,	
2017-06-24 04:09:13,194 Epoch[38] Batch [390]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.112087,	
2017-06-24 04:09:20,343 Epoch[38] Batch [400]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.111799,	
2017-06-24 04:09:27,785 Epoch[38] Batch [410]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.111327,	
2017-06-24 04:09:35,619 Epoch[38] Batch [420]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.111007,	
2017-06-24 04:09:42,807 Epoch[38] Batch [430]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.110816,	
2017-06-24 04:09:49,965 Epoch[38] Batch [440]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.110587,	
2017-06-24 04:09:57,180 Epoch[38] Batch [450]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.110245,	
2017-06-24 04:10:04,325 Epoch[38] Batch [460]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.109947,	
2017-06-24 04:10:11,434 Epoch[38] Batch [470]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109653,	
2017-06-24 04:10:18,799 Epoch[38] Batch [480]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.109251,	
2017-06-24 04:10:26,193 Epoch[38] Batch [490]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.108989,	
2017-06-24 04:10:33,638 Epoch[38] Batch [500]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.108806,	
2017-06-24 04:10:40,956 Epoch[38] Batch [510]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.108468,	
2017-06-24 04:10:48,329 Epoch[38] Batch [520]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.108295,	
2017-06-24 04:10:55,648 Epoch[38] Batch [530]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.107923,	
2017-06-24 04:11:02,947 Epoch[38] Batch [540]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.107621,	
2017-06-24 04:11:10,830 Epoch[38] Batch [550]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.107314,	
2017-06-24 04:11:18,478 Epoch[38] Batch [560]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.107308,	
2017-06-24 04:11:25,842 Epoch[38] Batch [570]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.107302,	
2017-06-24 04:11:32,965 Epoch[38] Batch [580]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.107407,	
2017-06-24 04:11:40,749 Epoch[38] Batch [590]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.108332,	
2017-06-24 04:11:48,272 Epoch[38] Batch [600]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.108964,	
2017-06-24 04:11:55,277 Epoch[38] Batch [610]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.109423,	
2017-06-24 04:12:02,068 Epoch[38] Batch [620]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.109468,	
2017-06-24 04:12:09,229 Epoch[38] Batch [630]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.109249,	
2017-06-24 04:12:16,658 Epoch[38] Batch [640]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.109146,	
2017-06-24 04:12:23,931 Epoch[38] Batch [650]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.109146,	
2017-06-24 04:12:31,302 Epoch[38] Batch [660]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.108935,	
2017-06-24 04:12:38,656 Epoch[38] Batch [670]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.108868,	
2017-06-24 04:12:45,546 Epoch[38] Batch [680]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.108956,	
2017-06-24 04:12:53,158 Epoch[38] Batch [690]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.108926,	
2017-06-24 04:13:00,176 Epoch[38] Batch [700]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.108922,	
2017-06-24 04:13:07,283 Epoch[38] Batch [710]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.108895,	
2017-06-24 04:13:15,049 Epoch[38] Batch [720]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.108772,	
2017-06-24 04:13:22,887 Epoch[38] Batch [730]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.108625,	
2017-06-24 04:13:30,092 Epoch[38] Batch [740]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.108502,	
2017-06-24 04:13:37,394 Epoch[38] Batch [750]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.108434,	
2017-06-24 04:13:44,588 Epoch[38] Batch [760]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.108258,	
2017-06-24 04:13:51,999 Epoch[38] Batch [770]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.108209,	
2017-06-24 04:13:59,340 Epoch[38] Batch [780]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.108084,	
2017-06-24 04:14:06,345 Epoch[38] Batch [790]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.107990,	
2017-06-24 04:14:13,485 Epoch[38] Batch [800]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.107996,	
2017-06-24 04:14:20,851 Epoch[38] Batch [810]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.107985,	
2017-06-24 04:14:27,898 Epoch[38] Batch [820]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.107997,	
2017-06-24 04:14:34,620 Epoch[38] Batch [830]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.107934,	
2017-06-24 04:14:41,212 Epoch[38] Batch [840]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.107751,	
2017-06-24 04:14:48,083 Epoch[38] Batch [850]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.107589,	
2017-06-24 04:14:55,156 Epoch[38] Batch [860]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.107426,	
2017-06-24 04:15:02,371 Epoch[38] Batch [870]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.107342,	
2017-06-24 04:15:09,338 Epoch[38] Batch [880]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.107229,	
2017-06-24 04:15:16,441 Epoch[38] Batch [890]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.107152,	
2017-06-24 04:15:23,258 Epoch[38] Batch [900]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.107239,	
2017-06-24 04:15:30,605 Epoch[38] Batch [910]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.107186,	
2017-06-24 04:15:37,761 Epoch[38] Batch [920]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.107354,	
2017-06-24 04:15:44,724 Epoch[38] Batch [930]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.107218,	
2017-06-24 04:15:51,951 Epoch[38] Batch [940]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.107290,	
2017-06-24 04:15:59,324 Epoch[38] Batch [950]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.107206,	
2017-06-24 04:16:06,433 Epoch[38] Batch [960]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.107478,	
2017-06-24 04:16:13,312 Epoch[38] Batch [970]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.107359,	
2017-06-24 04:16:20,553 Epoch[38] Batch [980]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.107320,	
2017-06-24 04:16:27,861 Epoch[38] Batch [990]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.107198,	
2017-06-24 04:16:34,561 Epoch[38] Batch [1000]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.107098,	
2017-06-24 04:16:41,669 Epoch[38] Batch [1010]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.106976,	
2017-06-24 04:16:48,647 Epoch[38] Batch [1020]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.106900,	
2017-06-24 04:16:55,508 Epoch[38] Batch [1030]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.106834,	
2017-06-24 04:17:02,237 Epoch[38] Batch [1040]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.106718,	
2017-06-24 04:17:09,163 Epoch[38] Batch [1050]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.106533,	
2017-06-24 04:17:16,212 Epoch[38] Batch [1060]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.106470,	
2017-06-24 04:17:23,118 Epoch[38] Batch [1070]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.106488,	
2017-06-24 04:17:30,030 Epoch[38] Batch [1080]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.106487,	
2017-06-24 04:17:37,305 Epoch[38] Batch [1090]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.106472,	
2017-06-24 04:17:44,106 Epoch[38] Batch [1100]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.106415,	
2017-06-24 04:17:51,332 Epoch[38] Batch [1110]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.106355,	
2017-06-24 04:17:58,481 Epoch[38] Batch [1120]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.106327,	
2017-06-24 04:18:06,057 Epoch[38] Batch [1130]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.106275,	
2017-06-24 04:18:13,363 Epoch[38] Batch [1140]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.106157,	
2017-06-24 04:18:20,517 Epoch[38] Batch [1150]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.106112,	
2017-06-24 04:18:27,681 Epoch[38] Batch [1160]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.105955,	
2017-06-24 04:18:35,018 Epoch[38] Batch [1170]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.105838,	
2017-06-24 04:18:42,172 Epoch[38] Batch [1180]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.105882,	
2017-06-24 04:18:48,983 Epoch[38] Batch [1190]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.105846,	
2017-06-24 04:18:56,556 Epoch[38] Batch [1200]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.105969,	
2017-06-24 04:19:04,103 Epoch[38] Batch [1210]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.106002,	
2017-06-24 04:19:11,252 Epoch[38] Batch [1220]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.106111,	
2017-06-24 04:19:18,327 Epoch[38] Batch [1230]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.106447,	
2017-06-24 04:19:25,509 Epoch[38] Batch [1240]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.106500,	
2017-06-24 04:19:32,244 Epoch[38] Batch [1250]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.106480,	
2017-06-24 04:19:39,379 Epoch[38] Batch [1260]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.106471,	
2017-06-24 04:19:46,911 Epoch[38] Batch [1270]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.106415,	
2017-06-24 04:19:54,183 Epoch[38] Batch [1280]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.106339,	
2017-06-24 04:20:01,254 Epoch[38] Batch [1290]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.106425,	
2017-06-24 04:20:08,135 Epoch[38] Batch [1300]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106582,	
2017-06-24 04:20:15,880 Epoch[38] Batch [1310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.106647,	
2017-06-24 04:20:22,848 Epoch[38] Batch [1320]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.106621,	
2017-06-24 04:20:30,298 Epoch[38] Batch [1330]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.106794,	
2017-06-24 04:20:37,450 Epoch[38] Batch [1340]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.106775,	
2017-06-24 04:20:44,681 Epoch[38] Batch [1350]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.106790,	
2017-06-24 04:20:52,147 Epoch[38] Batch [1360]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.106745,	
2017-06-24 04:20:59,468 Epoch[38] Batch [1370]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.106727,	
2017-06-24 04:21:06,851 Epoch[38] Batch [1380]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.106631,	
2017-06-24 04:21:14,653 Epoch[38] Batch [1390]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.106521,	
2017-06-24 04:21:21,940 Epoch[38] Batch [1400]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.106464,	
2017-06-24 04:21:29,555 Epoch[38] Batch [1410]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.106457,	
2017-06-24 04:21:36,958 Epoch[38] Batch [1420]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.106526,	
2017-06-24 04:21:44,311 Epoch[38] Batch [1430]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.106441,	
2017-06-24 04:21:51,231 Epoch[38] Batch [1440]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.106450,	
2017-06-24 04:21:58,536 Epoch[38] Batch [1450]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.106378,	
2017-06-24 04:22:05,969 Epoch[38] Batch [1460]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.106277,	
2017-06-24 04:22:13,076 Epoch[38] Batch [1470]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.106162,	
2017-06-24 04:22:21,162 Epoch[38] Batch [1480]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.106129,	
2017-06-24 04:22:25,570 Epoch[38] Train-FCNLogLoss=0.106140
2017-06-24 04:22:25,570 Epoch[38] Time cost=1075.393
2017-06-24 04:22:26,668 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0039.params"
2017-06-24 04:22:30,235 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0039.states"
2017-06-24 04:22:38,405 Epoch[39] Batch [10]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.094261,	
2017-06-24 04:22:45,883 Epoch[39] Batch [20]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.091950,	
2017-06-24 04:22:53,419 Epoch[39] Batch [30]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095357,	
2017-06-24 04:23:00,573 Epoch[39] Batch [40]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.096288,	
2017-06-24 04:23:08,143 Epoch[39] Batch [50]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098152,	
2017-06-24 04:23:15,189 Epoch[39] Batch [60]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.098636,	
2017-06-24 04:23:22,487 Epoch[39] Batch [70]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.098665,	
2017-06-24 04:23:30,099 Epoch[39] Batch [80]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.097465,	
2017-06-24 04:23:37,282 Epoch[39] Batch [90]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.096831,	
2017-06-24 04:23:44,659 Epoch[39] Batch [100]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.096027,	
2017-06-24 04:23:52,085 Epoch[39] Batch [110]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.096519,	
2017-06-24 04:23:59,653 Epoch[39] Batch [120]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096742,	
2017-06-24 04:24:07,274 Epoch[39] Batch [130]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.096203,	
2017-06-24 04:24:14,534 Epoch[39] Batch [140]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.095899,	
2017-06-24 04:24:21,886 Epoch[39] Batch [150]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.095576,	
2017-06-24 04:24:29,264 Epoch[39] Batch [160]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.095057,	
2017-06-24 04:24:36,612 Epoch[39] Batch [170]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.094839,	
2017-06-24 04:24:43,598 Epoch[39] Batch [180]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.094886,	
2017-06-24 04:24:50,696 Epoch[39] Batch [190]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.094439,	
2017-06-24 04:24:57,607 Epoch[39] Batch [200]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.094540,	
2017-06-24 04:25:04,787 Epoch[39] Batch [210]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.094086,	
2017-06-24 04:25:11,909 Epoch[39] Batch [220]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.093664,	
2017-06-24 04:25:19,257 Epoch[39] Batch [230]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.093948,	
2017-06-24 04:25:26,316 Epoch[39] Batch [240]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.093728,	
2017-06-24 04:25:33,022 Epoch[39] Batch [250]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.093406,	
2017-06-24 04:25:39,979 Epoch[39] Batch [260]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.093460,	
2017-06-24 04:25:46,480 Epoch[39] Batch [270]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.093451,	
2017-06-24 04:25:53,561 Epoch[39] Batch [280]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.093604,	
2017-06-24 04:26:00,624 Epoch[39] Batch [290]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.093769,	
2017-06-24 04:26:07,331 Epoch[39] Batch [300]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.094117,	
2017-06-24 04:26:14,346 Epoch[39] Batch [310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.094216,	
2017-06-24 04:26:21,626 Epoch[39] Batch [320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.094772,	
2017-06-24 04:26:28,473 Epoch[39] Batch [330]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.094850,	
2017-06-24 04:26:35,511 Epoch[39] Batch [340]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.094712,	
2017-06-24 04:26:42,685 Epoch[39] Batch [350]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.094885,	
2017-06-24 04:26:49,786 Epoch[39] Batch [360]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094696,	
2017-06-24 04:26:57,221 Epoch[39] Batch [370]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.094723,	
2017-06-24 04:27:03,982 Epoch[39] Batch [380]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.094778,	
2017-06-24 04:27:10,687 Epoch[39] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.094960,	
2017-06-24 04:27:17,550 Epoch[39] Batch [400]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.094853,	
2017-06-24 04:27:24,647 Epoch[39] Batch [410]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.094778,	
2017-06-24 04:27:31,478 Epoch[39] Batch [420]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.095000,	
2017-06-24 04:27:38,692 Epoch[39] Batch [430]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.095238,	
2017-06-24 04:27:45,844 Epoch[39] Batch [440]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.095249,	
2017-06-24 04:27:53,031 Epoch[39] Batch [450]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.095647,	
2017-06-24 04:28:00,462 Epoch[39] Batch [460]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095753,	
2017-06-24 04:28:07,319 Epoch[39] Batch [470]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.095989,	
2017-06-24 04:28:14,772 Epoch[39] Batch [480]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.095968,	
2017-06-24 04:28:21,161 Epoch[39] Batch [490]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.095849,	
2017-06-24 04:28:27,885 Epoch[39] Batch [500]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.095659,	
2017-06-24 04:28:34,824 Epoch[39] Batch [510]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.095545,	
2017-06-24 04:28:42,144 Epoch[39] Batch [520]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.095341,	
2017-06-24 04:28:49,479 Epoch[39] Batch [530]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.095358,	
2017-06-24 04:28:56,689 Epoch[39] Batch [540]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.095293,	
2017-06-24 04:29:03,717 Epoch[39] Batch [550]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.095329,	
2017-06-24 04:29:10,730 Epoch[39] Batch [560]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.095381,	
2017-06-24 04:29:18,094 Epoch[39] Batch [570]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.095407,	
2017-06-24 04:29:25,233 Epoch[39] Batch [580]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.095416,	
2017-06-24 04:29:32,433 Epoch[39] Batch [590]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.095600,	
2017-06-24 04:29:39,605 Epoch[39] Batch [600]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.095616,	
2017-06-24 04:29:46,870 Epoch[39] Batch [610]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.095622,	
2017-06-24 04:29:54,219 Epoch[39] Batch [620]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.095525,	
2017-06-24 04:30:01,451 Epoch[39] Batch [630]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.095486,	
2017-06-24 04:30:09,373 Epoch[39] Batch [640]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.095433,	
2017-06-24 04:30:16,687 Epoch[39] Batch [650]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.095395,	
2017-06-24 04:30:23,796 Epoch[39] Batch [660]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.095392,	
2017-06-24 04:30:31,041 Epoch[39] Batch [670]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.095462,	
2017-06-24 04:30:38,240 Epoch[39] Batch [680]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.095676,	
2017-06-24 04:30:46,037 Epoch[39] Batch [690]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095590,	
2017-06-24 04:30:53,500 Epoch[39] Batch [700]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.095484,	
2017-06-24 04:31:00,756 Epoch[39] Batch [710]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.095492,	
2017-06-24 04:31:08,083 Epoch[39] Batch [720]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.095524,	
2017-06-24 04:31:15,009 Epoch[39] Batch [730]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.095328,	
2017-06-24 04:31:21,876 Epoch[39] Batch [740]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.095253,	
2017-06-24 04:31:29,028 Epoch[39] Batch [750]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.095286,	
2017-06-24 04:31:36,672 Epoch[39] Batch [760]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.095152,	
2017-06-24 04:31:44,271 Epoch[39] Batch [770]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.095178,	
2017-06-24 04:31:51,409 Epoch[39] Batch [780]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.095085,	
2017-06-24 04:31:58,909 Epoch[39] Batch [790]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.095081,	
2017-06-24 04:32:06,012 Epoch[39] Batch [800]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.095073,	
2017-06-24 04:32:13,836 Epoch[39] Batch [810]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.095167,	
2017-06-24 04:32:21,239 Epoch[39] Batch [820]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.095035,	
2017-06-24 04:32:28,345 Epoch[39] Batch [830]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094929,	
2017-06-24 04:32:35,588 Epoch[39] Batch [840]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.094923,	
2017-06-24 04:32:42,921 Epoch[39] Batch [850]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.094892,	
2017-06-24 04:32:50,541 Epoch[39] Batch [860]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095060,	
2017-06-24 04:32:58,157 Epoch[39] Batch [870]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095101,	
2017-06-24 04:33:05,547 Epoch[39] Batch [880]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.095121,	
2017-06-24 04:33:12,599 Epoch[39] Batch [890]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.095112,	
2017-06-24 04:33:19,825 Epoch[39] Batch [900]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.095147,	
2017-06-24 04:33:27,016 Epoch[39] Batch [910]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.095118,	
2017-06-24 04:33:34,045 Epoch[39] Batch [920]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.095109,	
2017-06-24 04:33:41,075 Epoch[39] Batch [930]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.095086,	
2017-06-24 04:33:48,433 Epoch[39] Batch [940]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.095076,	
2017-06-24 04:33:55,438 Epoch[39] Batch [950]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.095172,	
2017-06-24 04:34:02,886 Epoch[39] Batch [960]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.095208,	
2017-06-24 04:34:10,016 Epoch[39] Batch [970]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.095170,	
2017-06-24 04:34:17,138 Epoch[39] Batch [980]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.095241,	
2017-06-24 04:34:24,297 Epoch[39] Batch [990]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.095210,	
2017-06-24 04:34:31,788 Epoch[39] Batch [1000]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.095153,	
2017-06-24 04:34:39,392 Epoch[39] Batch [1010]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.095223,	
2017-06-24 04:34:46,921 Epoch[39] Batch [1020]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095153,	
2017-06-24 04:34:54,243 Epoch[39] Batch [1030]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.095201,	
2017-06-24 04:35:01,478 Epoch[39] Batch [1040]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.095194,	
2017-06-24 04:35:09,497 Epoch[39] Batch [1050]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.095117,	
2017-06-24 04:35:16,701 Epoch[39] Batch [1060]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.095013,	
2017-06-24 04:35:24,169 Epoch[39] Batch [1070]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.095024,	
2017-06-24 04:35:31,549 Epoch[39] Batch [1080]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.094917,	
2017-06-24 04:35:39,002 Epoch[39] Batch [1090]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094857,	
2017-06-24 04:35:46,376 Epoch[39] Batch [1100]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.094797,	
2017-06-24 04:35:53,225 Epoch[39] Batch [1110]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.094796,	
2017-06-24 04:36:00,263 Epoch[39] Batch [1120]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.094757,	
2017-06-24 04:36:07,414 Epoch[39] Batch [1130]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.094818,	
2017-06-24 04:36:14,369 Epoch[39] Batch [1140]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.094767,	
2017-06-24 04:36:21,054 Epoch[39] Batch [1150]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.094819,	
2017-06-24 04:36:28,225 Epoch[39] Batch [1160]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.094760,	
2017-06-24 04:36:35,585 Epoch[39] Batch [1170]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.094669,	
2017-06-24 04:36:42,743 Epoch[39] Batch [1180]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.094594,	
2017-06-24 04:36:50,275 Epoch[39] Batch [1190]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.094627,	
2017-06-24 04:36:57,358 Epoch[39] Batch [1200]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.094668,	
2017-06-24 04:37:04,235 Epoch[39] Batch [1210]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.094749,	
2017-06-24 04:37:11,277 Epoch[39] Batch [1220]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.094688,	
2017-06-24 04:37:18,196 Epoch[39] Batch [1230]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.094676,	
2017-06-24 04:37:25,363 Epoch[39] Batch [1240]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.094791,	
2017-06-24 04:37:32,137 Epoch[39] Batch [1250]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.094811,	
2017-06-24 04:37:39,278 Epoch[39] Batch [1260]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.094712,	
2017-06-24 04:37:46,635 Epoch[39] Batch [1270]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.094670,	
2017-06-24 04:37:54,082 Epoch[39] Batch [1280]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094649,	
2017-06-24 04:38:01,193 Epoch[39] Batch [1290]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.094675,	
2017-06-24 04:38:08,755 Epoch[39] Batch [1300]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.094698,	
2017-06-24 04:38:16,024 Epoch[39] Batch [1310]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.094703,	
2017-06-24 04:38:23,179 Epoch[39] Batch [1320]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.094756,	
2017-06-24 04:38:30,522 Epoch[39] Batch [1330]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.094747,	
2017-06-24 04:38:37,936 Epoch[39] Batch [1340]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.094743,	
2017-06-24 04:38:45,322 Epoch[39] Batch [1350]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.094707,	
2017-06-24 04:38:52,451 Epoch[39] Batch [1360]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.094718,	
2017-06-24 04:38:59,678 Epoch[39] Batch [1370]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.094720,	
2017-06-24 04:39:06,670 Epoch[39] Batch [1380]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.094697,	
2017-06-24 04:39:14,162 Epoch[39] Batch [1390]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.094728,	
2017-06-24 04:39:21,607 Epoch[39] Batch [1400]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094688,	
2017-06-24 04:39:28,584 Epoch[39] Batch [1410]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.094687,	
2017-06-24 04:39:35,482 Epoch[39] Batch [1420]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.094699,	
2017-06-24 04:39:42,718 Epoch[39] Batch [1430]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.094732,	
2017-06-24 04:39:49,439 Epoch[39] Batch [1440]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.094703,	
2017-06-24 04:39:56,635 Epoch[39] Batch [1450]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.094745,	
2017-06-24 04:40:03,968 Epoch[39] Batch [1460]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.094789,	
2017-06-24 04:40:10,804 Epoch[39] Batch [1470]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.094897,	
2017-06-24 04:40:17,948 Epoch[39] Batch [1480]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.095011,	
2017-06-24 04:40:22,224 Epoch[39] Train-FCNLogLoss=0.095051
2017-06-24 04:40:22,224 Epoch[39] Time cost=1071.988
2017-06-24 04:40:23,313 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0040.params"
2017-06-24 04:40:26,946 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0040.states"
2017-06-24 04:40:35,013 Epoch[40] Batch [10]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.114976,	
2017-06-24 04:40:41,970 Epoch[40] Batch [20]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.110906,	
2017-06-24 04:40:49,183 Epoch[40] Batch [30]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.104866,	
2017-06-24 04:40:56,566 Epoch[40] Batch [40]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.104319,	
2017-06-24 04:41:03,644 Epoch[40] Batch [50]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.105555,	
2017-06-24 04:41:10,352 Epoch[40] Batch [60]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.104125,	
2017-06-24 04:41:17,336 Epoch[40] Batch [70]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.103012,	
2017-06-24 04:41:24,380 Epoch[40] Batch [80]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.102741,	
2017-06-24 04:41:31,573 Epoch[40] Batch [90]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.101859,	
2017-06-24 04:41:38,481 Epoch[40] Batch [100]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.101731,	
2017-06-24 04:41:46,185 Epoch[40] Batch [110]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.100090,	
2017-06-24 04:41:53,462 Epoch[40] Batch [120]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.099681,	
2017-06-24 04:42:00,564 Epoch[40] Batch [130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.099522,	
2017-06-24 04:42:08,540 Epoch[40] Batch [140]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.098692,	
2017-06-24 04:42:15,912 Epoch[40] Batch [150]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.099624,	
2017-06-24 04:42:23,159 Epoch[40] Batch [160]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.099221,	
2017-06-24 04:42:30,245 Epoch[40] Batch [170]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.098766,	
2017-06-24 04:42:37,388 Epoch[40] Batch [180]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.098449,	
2017-06-24 04:42:44,684 Epoch[40] Batch [190]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.098464,	
2017-06-24 04:42:52,395 Epoch[40] Batch [200]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.098062,	
2017-06-24 04:42:59,888 Epoch[40] Batch [210]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098092,	
2017-06-24 04:43:07,143 Epoch[40] Batch [220]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.098534,	
2017-06-24 04:43:14,255 Epoch[40] Batch [230]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.098310,	
2017-06-24 04:43:21,907 Epoch[40] Batch [240]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.097891,	
2017-06-24 04:43:29,249 Epoch[40] Batch [250]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097619,	
2017-06-24 04:43:37,118 Epoch[40] Batch [260]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.097723,	
2017-06-24 04:43:44,112 Epoch[40] Batch [270]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.097197,	
2017-06-24 04:43:51,407 Epoch[40] Batch [280]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.096852,	
2017-06-24 04:43:58,978 Epoch[40] Batch [290]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.096733,	
2017-06-24 04:44:06,727 Epoch[40] Batch [300]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.096633,	
2017-06-24 04:44:14,167 Epoch[40] Batch [310]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.096267,	
2017-06-24 04:44:21,780 Epoch[40] Batch [320]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.096412,	
2017-06-24 04:44:29,135 Epoch[40] Batch [330]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.096187,	
2017-06-24 04:44:36,732 Epoch[40] Batch [340]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096187,	
2017-06-24 04:44:44,509 Epoch[40] Batch [350]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.096138,	
2017-06-24 04:44:51,648 Epoch[40] Batch [360]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.095888,	
2017-06-24 04:44:58,687 Epoch[40] Batch [370]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.095987,	
2017-06-24 04:45:05,787 Epoch[40] Batch [380]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.095748,	
2017-06-24 04:45:12,926 Epoch[40] Batch [390]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.095678,	
2017-06-24 04:45:20,192 Epoch[40] Batch [400]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.095476,	
2017-06-24 04:45:26,730 Epoch[40] Batch [410]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.095210,	
2017-06-24 04:45:33,672 Epoch[40] Batch [420]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.094865,	
2017-06-24 04:45:40,957 Epoch[40] Batch [430]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.094967,	
2017-06-24 04:45:47,758 Epoch[40] Batch [440]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.094778,	
2017-06-24 04:45:55,000 Epoch[40] Batch [450]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.094540,	
2017-06-24 04:46:01,945 Epoch[40] Batch [460]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.094345,	
2017-06-24 04:46:09,353 Epoch[40] Batch [470]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.094834,	
2017-06-24 04:46:16,560 Epoch[40] Batch [480]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.094704,	
2017-06-24 04:46:23,970 Epoch[40] Batch [490]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.094708,	
2017-06-24 04:46:31,357 Epoch[40] Batch [500]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.095029,	
2017-06-24 04:46:38,329 Epoch[40] Batch [510]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.095399,	
2017-06-24 04:46:44,652 Update[60000]: Change learning rate to 5.00000e-05
2017-06-24 04:46:45,570 Epoch[40] Batch [520]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.095373,	
2017-06-24 04:46:52,447 Epoch[40] Batch [530]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.095244,	
2017-06-24 04:46:59,388 Epoch[40] Batch [540]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.095255,	
2017-06-24 04:47:06,248 Epoch[40] Batch [550]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.095416,	
2017-06-24 04:47:13,791 Epoch[40] Batch [560]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095284,	
2017-06-24 04:47:20,868 Epoch[40] Batch [570]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.095281,	
2017-06-24 04:47:28,389 Epoch[40] Batch [580]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095172,	
2017-06-24 04:47:35,749 Epoch[40] Batch [590]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.095308,	
2017-06-24 04:47:42,216 Epoch[40] Batch [600]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.095124,	
2017-06-24 04:47:49,800 Epoch[40] Batch [610]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.094917,	
2017-06-24 04:47:56,684 Epoch[40] Batch [620]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.096002,	
2017-06-24 04:48:04,220 Epoch[40] Batch [630]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095914,	
2017-06-24 04:48:11,509 Epoch[40] Batch [640]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.095719,	
2017-06-24 04:48:18,426 Epoch[40] Batch [650]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.095793,	
2017-06-24 04:48:25,905 Epoch[40] Batch [660]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095959,	
2017-06-24 04:48:33,053 Epoch[40] Batch [670]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.095878,	
2017-06-24 04:48:39,966 Epoch[40] Batch [680]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.095815,	
2017-06-24 04:48:47,171 Epoch[40] Batch [690]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.095737,	
2017-06-24 04:48:54,522 Epoch[40] Batch [700]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.095746,	
2017-06-24 04:49:01,528 Epoch[40] Batch [710]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.095751,	
2017-06-24 04:49:08,580 Epoch[40] Batch [720]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.095716,	
2017-06-24 04:49:16,009 Epoch[40] Batch [730]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095698,	
2017-06-24 04:49:23,287 Epoch[40] Batch [740]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.095611,	
2017-06-24 04:49:30,571 Epoch[40] Batch [750]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.095428,	
2017-06-24 04:49:37,846 Epoch[40] Batch [760]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.095287,	
2017-06-24 04:49:45,017 Epoch[40] Batch [770]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.095246,	
2017-06-24 04:49:52,543 Epoch[40] Batch [780]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095142,	
2017-06-24 04:49:59,376 Epoch[40] Batch [790]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.095165,	
2017-06-24 04:50:06,230 Epoch[40] Batch [800]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.095133,	
2017-06-24 04:50:13,516 Epoch[40] Batch [810]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.095079,	
2017-06-24 04:50:20,970 Epoch[40] Batch [820]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.094913,	
2017-06-24 04:50:27,739 Epoch[40] Batch [830]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.094717,	
2017-06-24 04:50:34,889 Epoch[40] Batch [840]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.094732,	
2017-06-24 04:50:41,567 Epoch[40] Batch [850]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094768,	
2017-06-24 04:50:48,004 Epoch[40] Batch [860]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094719,	
2017-06-24 04:50:54,527 Epoch[40] Batch [870]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.094684,	
2017-06-24 04:51:01,132 Epoch[40] Batch [880]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.094628,	
2017-06-24 04:51:08,086 Epoch[40] Batch [890]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.094594,	
2017-06-24 04:51:14,891 Epoch[40] Batch [900]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.094556,	
2017-06-24 04:51:21,036 Epoch[40] Batch [910]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.094538,	
2017-06-24 04:51:27,581 Epoch[40] Batch [920]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.094462,	
2017-06-24 04:51:34,697 Epoch[40] Batch [930]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.094465,	
2017-06-24 04:51:41,687 Epoch[40] Batch [940]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.094329,	
2017-06-24 04:51:48,179 Epoch[40] Batch [950]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.094360,	
2017-06-24 04:51:54,451 Epoch[40] Batch [960]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.094383,	
2017-06-24 04:52:00,894 Epoch[40] Batch [970]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094357,	
2017-06-24 04:52:06,949 Epoch[40] Batch [980]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.094341,	
2017-06-24 04:52:13,068 Epoch[40] Batch [990]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.094325,	
2017-06-24 04:52:19,089 Epoch[40] Batch [1000]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.094309,	
2017-06-24 04:52:25,864 Epoch[40] Batch [1010]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.094231,	
2017-06-24 04:52:31,796 Epoch[40] Batch [1020]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.094127,	
2017-06-24 04:52:37,530 Epoch[40] Batch [1030]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.094113,	
2017-06-24 04:52:43,998 Epoch[40] Batch [1040]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.094184,	
2017-06-24 04:52:50,375 Epoch[40] Batch [1050]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.094195,	
2017-06-24 04:52:57,125 Epoch[40] Batch [1060]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.094223,	
2017-06-24 04:53:03,382 Epoch[40] Batch [1070]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.094171,	
2017-06-24 04:53:10,005 Epoch[40] Batch [1080]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.094104,	
2017-06-24 04:53:16,452 Epoch[40] Batch [1090]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094032,	
2017-06-24 04:53:22,944 Epoch[40] Batch [1100]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.094028,	
2017-06-24 04:53:29,570 Epoch[40] Batch [1110]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.093964,	
2017-06-24 04:53:36,058 Epoch[40] Batch [1120]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.093930,	
2017-06-24 04:53:42,516 Epoch[40] Batch [1130]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.093972,	
2017-06-24 04:53:48,698 Epoch[40] Batch [1140]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.094010,	
2017-06-24 04:53:55,087 Epoch[40] Batch [1150]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.093956,	
2017-06-24 04:54:01,400 Epoch[40] Batch [1160]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093951,	
2017-06-24 04:54:07,621 Epoch[40] Batch [1170]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.093953,	
2017-06-24 04:54:14,160 Epoch[40] Batch [1180]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.093956,	
2017-06-24 04:54:21,017 Epoch[40] Batch [1190]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.093877,	
2017-06-24 04:54:27,510 Epoch[40] Batch [1200]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.093818,	
2017-06-24 04:54:33,819 Epoch[40] Batch [1210]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093809,	
2017-06-24 04:54:40,258 Epoch[40] Batch [1220]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.093682,	
2017-06-24 04:54:46,511 Epoch[40] Batch [1230]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.093881,	
2017-06-24 04:54:53,332 Epoch[40] Batch [1240]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.093972,	
2017-06-24 04:55:00,689 Epoch[40] Batch [1250]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.093947,	
2017-06-24 04:55:06,855 Epoch[40] Batch [1260]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.093922,	
2017-06-24 04:55:12,807 Epoch[40] Batch [1270]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.093982,	
2017-06-24 04:55:18,995 Epoch[40] Batch [1280]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.093974,	
2017-06-24 04:55:25,636 Epoch[40] Batch [1290]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.093978,	
2017-06-24 04:55:31,953 Epoch[40] Batch [1300]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.093996,	
2017-06-24 04:55:38,374 Epoch[40] Batch [1310]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.093968,	
2017-06-24 04:55:44,611 Epoch[40] Batch [1320]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093909,	
2017-06-24 04:55:51,041 Epoch[40] Batch [1330]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093998,	
2017-06-24 04:55:57,008 Epoch[40] Batch [1340]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.094022,	
2017-06-24 04:56:03,394 Epoch[40] Batch [1350]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.093935,	
2017-06-24 04:56:09,778 Epoch[40] Batch [1360]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.093886,	
2017-06-24 04:56:15,938 Epoch[40] Batch [1370]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.093830,	
2017-06-24 04:56:22,351 Epoch[40] Batch [1380]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093813,	
2017-06-24 04:56:28,492 Epoch[40] Batch [1390]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.093726,	
2017-06-24 04:56:34,618 Epoch[40] Batch [1400]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093742,	
2017-06-24 04:56:40,923 Epoch[40] Batch [1410]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093767,	
2017-06-24 04:56:46,736 Epoch[40] Batch [1420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.093704,	
2017-06-24 04:56:53,116 Epoch[40] Batch [1430]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.093659,	
2017-06-24 04:56:59,378 Epoch[40] Batch [1440]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.093631,	
2017-06-24 04:57:05,650 Epoch[40] Batch [1450]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.093647,	
2017-06-24 04:57:12,897 Epoch[40] Batch [1460]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.093634,	
2017-06-24 04:57:19,399 Epoch[40] Batch [1470]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.093766,	
2017-06-24 04:57:27,549 Epoch[40] Batch [1480]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.093777,	
2017-06-24 04:57:31,882 Epoch[40] Train-FCNLogLoss=0.093773
2017-06-24 04:57:31,882 Epoch[40] Time cost=1024.935
2017-06-24 04:57:32,812 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0041.params"
2017-06-24 04:57:36,281 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0041.states"
2017-06-24 04:57:43,639 Epoch[41] Batch [10]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.099028,	
2017-06-24 04:57:49,754 Epoch[41] Batch [20]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.096279,	
2017-06-24 04:57:55,835 Epoch[41] Batch [30]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.094901,	
2017-06-24 04:58:01,948 Epoch[41] Batch [40]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100977,	
2017-06-24 04:58:08,290 Epoch[41] Batch [50]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.100145,	
2017-06-24 04:58:14,464 Epoch[41] Batch [60]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.099330,	
2017-06-24 04:58:20,603 Epoch[41] Batch [70]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.097231,	
2017-06-24 04:58:26,835 Epoch[41] Batch [80]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.096025,	
2017-06-24 04:58:33,281 Epoch[41] Batch [90]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.096261,	
2017-06-24 04:58:39,489 Epoch[41] Batch [100]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.096189,	
2017-06-24 04:58:45,867 Epoch[41] Batch [110]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.094972,	
2017-06-24 04:58:51,989 Epoch[41] Batch [120]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.095042,	
2017-06-24 04:58:58,209 Epoch[41] Batch [130]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.094103,	
2017-06-24 04:59:04,621 Epoch[41] Batch [140]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093507,	
2017-06-24 04:59:10,684 Epoch[41] Batch [150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.093498,	
2017-06-24 04:59:17,062 Epoch[41] Batch [160]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.093122,	
2017-06-24 04:59:22,597 Epoch[41] Batch [170]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.092614,	
2017-06-24 04:59:28,412 Epoch[41] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.092199,	
2017-06-24 04:59:34,841 Epoch[41] Batch [190]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.092181,	
2017-06-24 04:59:40,928 Epoch[41] Batch [200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.092107,	
2017-06-24 04:59:47,580 Epoch[41] Batch [210]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.092305,	
2017-06-24 04:59:53,970 Epoch[41] Batch [220]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.092827,	
2017-06-24 05:00:00,289 Epoch[41] Batch [230]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.093035,	
2017-06-24 05:00:06,507 Epoch[41] Batch [240]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.092680,	
2017-06-24 05:00:12,636 Epoch[41] Batch [250]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.092440,	
2017-06-24 05:00:18,990 Epoch[41] Batch [260]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.092374,	
2017-06-24 05:00:25,586 Epoch[41] Batch [270]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.092115,	
2017-06-24 05:00:32,184 Epoch[41] Batch [280]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.092755,	
2017-06-24 05:00:38,813 Epoch[41] Batch [290]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.092490,	
2017-06-24 05:00:45,186 Epoch[41] Batch [300]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.092572,	
2017-06-24 05:00:52,224 Epoch[41] Batch [310]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.092568,	
2017-06-24 05:00:58,343 Epoch[41] Batch [320]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.092707,	
2017-06-24 05:01:04,452 Epoch[41] Batch [330]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.092760,	
2017-06-24 05:01:10,560 Epoch[41] Batch [340]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.092875,	
2017-06-24 05:01:16,620 Epoch[41] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.092707,	
2017-06-24 05:01:22,883 Epoch[41] Batch [360]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.092835,	
2017-06-24 05:01:29,309 Epoch[41] Batch [370]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093050,	
2017-06-24 05:01:35,616 Epoch[41] Batch [380]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093035,	
2017-06-24 05:01:42,053 Epoch[41] Batch [390]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.092665,	
2017-06-24 05:01:48,189 Epoch[41] Batch [400]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.092440,	
2017-06-24 05:01:55,048 Epoch[41] Batch [410]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.092383,	
2017-06-24 05:02:02,278 Epoch[41] Batch [420]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.092270,	
2017-06-24 05:02:08,630 Epoch[41] Batch [430]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.092073,	
2017-06-24 05:02:14,631 Epoch[41] Batch [440]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.092129,	
2017-06-24 05:02:20,844 Epoch[41] Batch [450]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.091983,	
2017-06-24 05:02:26,782 Epoch[41] Batch [460]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.091681,	
2017-06-24 05:02:32,894 Epoch[41] Batch [470]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.091656,	
2017-06-24 05:02:38,780 Epoch[41] Batch [480]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.091698,	
2017-06-24 05:02:45,227 Epoch[41] Batch [490]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091593,	
2017-06-24 05:02:51,226 Epoch[41] Batch [500]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.091763,	
2017-06-24 05:02:57,894 Epoch[41] Batch [510]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.091739,	
2017-06-24 05:03:04,912 Epoch[41] Batch [520]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.091761,	
2017-06-24 05:03:11,403 Epoch[41] Batch [530]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091842,	
2017-06-24 05:03:17,688 Epoch[41] Batch [540]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.091817,	
2017-06-24 05:03:24,553 Epoch[41] Batch [550]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.091692,	
2017-06-24 05:03:31,999 Epoch[41] Batch [560]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.091695,	
2017-06-24 05:03:38,232 Epoch[41] Batch [570]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.091779,	
2017-06-24 05:03:44,525 Epoch[41] Batch [580]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.091760,	
2017-06-24 05:03:51,298 Epoch[41] Batch [590]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.091805,	
2017-06-24 05:03:58,669 Epoch[41] Batch [600]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.091821,	
2017-06-24 05:04:05,043 Epoch[41] Batch [610]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.092012,	
2017-06-24 05:04:11,526 Epoch[41] Batch [620]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.092097,	
2017-06-24 05:04:17,910 Epoch[41] Batch [630]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.092046,	
2017-06-24 05:04:24,160 Epoch[41] Batch [640]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.091922,	
2017-06-24 05:04:30,246 Epoch[41] Batch [650]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.091753,	
2017-06-24 05:04:37,407 Epoch[41] Batch [660]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.091833,	
2017-06-24 05:04:44,415 Epoch[41] Batch [670]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.091702,	
2017-06-24 05:04:50,410 Epoch[41] Batch [680]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.091809,	
2017-06-24 05:04:56,848 Epoch[41] Batch [690]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.091740,	
2017-06-24 05:05:04,221 Epoch[41] Batch [700]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.091701,	
2017-06-24 05:05:10,793 Epoch[41] Batch [710]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.091760,	
2017-06-24 05:05:17,529 Epoch[41] Batch [720]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.091752,	
2017-06-24 05:05:24,307 Epoch[41] Batch [730]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.091773,	
2017-06-24 05:05:30,456 Epoch[41] Batch [740]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.091723,	
2017-06-24 05:05:37,059 Epoch[41] Batch [750]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.091686,	
2017-06-24 05:05:43,261 Epoch[41] Batch [760]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.091542,	
2017-06-24 05:05:49,859 Epoch[41] Batch [770]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.091584,	
2017-06-24 05:05:56,569 Epoch[41] Batch [780]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.091578,	
2017-06-24 05:06:03,209 Epoch[41] Batch [790]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.091415,	
2017-06-24 05:06:10,119 Epoch[41] Batch [800]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.091424,	
2017-06-24 05:06:16,457 Epoch[41] Batch [810]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.091361,	
2017-06-24 05:06:23,347 Epoch[41] Batch [820]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.091425,	
2017-06-24 05:06:29,814 Epoch[41] Batch [830]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.091357,	
2017-06-24 05:06:36,839 Epoch[41] Batch [840]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.091314,	
2017-06-24 05:06:43,391 Epoch[41] Batch [850]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.091272,	
2017-06-24 05:06:50,316 Epoch[41] Batch [860]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.091195,	
2017-06-24 05:06:57,463 Epoch[41] Batch [870]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.091185,	
2017-06-24 05:07:03,760 Epoch[41] Batch [880]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.091078,	
2017-06-24 05:07:10,088 Epoch[41] Batch [890]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.091079,	
2017-06-24 05:07:17,131 Epoch[41] Batch [900]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.091101,	
2017-06-24 05:07:23,519 Epoch[41] Batch [910]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.091122,	
2017-06-24 05:07:29,961 Epoch[41] Batch [920]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.091173,	
2017-06-24 05:07:36,574 Epoch[41] Batch [930]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.091142,	
2017-06-24 05:07:43,068 Epoch[41] Batch [940]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091179,	
2017-06-24 05:07:49,024 Epoch[41] Batch [950]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.091114,	
2017-06-24 05:07:55,748 Epoch[41] Batch [960]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.091067,	
2017-06-24 05:08:02,087 Epoch[41] Batch [970]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.091091,	
2017-06-24 05:08:08,495 Epoch[41] Batch [980]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.091033,	
2017-06-24 05:08:14,855 Epoch[41] Batch [990]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.090974,	
2017-06-24 05:08:21,001 Epoch[41] Batch [1000]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.090938,	
2017-06-24 05:08:27,108 Epoch[41] Batch [1010]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.090867,	
2017-06-24 05:08:33,566 Epoch[41] Batch [1020]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.090889,	
2017-06-24 05:08:39,811 Epoch[41] Batch [1030]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.090811,	
2017-06-24 05:08:46,109 Epoch[41] Batch [1040]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.090880,	
2017-06-24 05:08:52,564 Epoch[41] Batch [1050]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.090774,	
2017-06-24 05:08:58,771 Epoch[41] Batch [1060]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.090769,	
2017-06-24 05:09:05,311 Epoch[41] Batch [1070]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.090778,	
2017-06-24 05:09:11,644 Epoch[41] Batch [1080]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.090932,	
2017-06-24 05:09:18,371 Epoch[41] Batch [1090]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.090825,	
2017-06-24 05:09:25,030 Epoch[41] Batch [1100]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.090747,	
2017-06-24 05:09:31,244 Epoch[41] Batch [1110]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.090749,	
2017-06-24 05:09:37,512 Epoch[41] Batch [1120]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.090709,	
2017-06-24 05:09:44,018 Epoch[41] Batch [1130]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.090658,	
2017-06-24 05:09:50,596 Epoch[41] Batch [1140]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.090657,	
2017-06-24 05:09:56,960 Epoch[41] Batch [1150]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.090644,	
2017-06-24 05:10:03,406 Epoch[41] Batch [1160]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.090678,	
2017-06-24 05:10:09,462 Epoch[41] Batch [1170]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.090736,	
2017-06-24 05:10:15,679 Epoch[41] Batch [1180]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.090707,	
2017-06-24 05:10:21,847 Epoch[41] Batch [1190]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.090692,	
2017-06-24 05:10:28,071 Epoch[41] Batch [1200]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.090652,	
2017-06-24 05:10:34,670 Epoch[41] Batch [1210]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.090615,	
2017-06-24 05:10:40,245 Epoch[41] Batch [1220]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.090654,	
2017-06-24 05:10:46,046 Epoch[41] Batch [1230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.090587,	
2017-06-24 05:10:52,099 Epoch[41] Batch [1240]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.090580,	
2017-06-24 05:10:58,121 Epoch[41] Batch [1250]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.090539,	
2017-06-24 05:11:03,963 Epoch[41] Batch [1260]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.090600,	
2017-06-24 05:11:10,171 Epoch[41] Batch [1270]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.090596,	
2017-06-24 05:11:16,547 Epoch[41] Batch [1280]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.090555,	
2017-06-24 05:11:22,946 Epoch[41] Batch [1290]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.090567,	
2017-06-24 05:11:29,781 Epoch[41] Batch [1300]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.090622,	
2017-06-24 05:11:36,221 Epoch[41] Batch [1310]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.090643,	
2017-06-24 05:11:42,755 Epoch[41] Batch [1320]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.090671,	
2017-06-24 05:11:48,918 Epoch[41] Batch [1330]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.090670,	
2017-06-24 05:11:55,376 Epoch[41] Batch [1340]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.090611,	
2017-06-24 05:12:01,733 Epoch[41] Batch [1350]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.090611,	
2017-06-24 05:12:08,282 Epoch[41] Batch [1360]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.090644,	
2017-06-24 05:12:15,290 Epoch[41] Batch [1370]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.090562,	
2017-06-24 05:12:21,837 Epoch[41] Batch [1380]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.090576,	
2017-06-24 05:12:28,070 Epoch[41] Batch [1390]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.090539,	
2017-06-24 05:12:34,458 Epoch[41] Batch [1400]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.090528,	
2017-06-24 05:12:40,532 Epoch[41] Batch [1410]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.090490,	
2017-06-24 05:12:46,671 Epoch[41] Batch [1420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.090399,	
2017-06-24 05:12:53,539 Epoch[41] Batch [1430]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.090348,	
2017-06-24 05:12:59,932 Epoch[41] Batch [1440]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.090332,	
2017-06-24 05:13:06,338 Epoch[41] Batch [1450]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.090324,	
2017-06-24 05:13:12,624 Epoch[41] Batch [1460]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.090320,	
2017-06-24 05:13:18,723 Epoch[41] Batch [1470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.090268,	
2017-06-24 05:13:24,976 Epoch[41] Batch [1480]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.090335,	
2017-06-24 05:13:28,662 Epoch[41] Train-FCNLogLoss=0.090315
2017-06-24 05:13:28,662 Epoch[41] Time cost=952.381
2017-06-24 05:13:29,957 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0042.params"
2017-06-24 05:13:33,591 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0042.states"
2017-06-24 05:13:40,931 Epoch[42] Batch [10]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088132,	
2017-06-24 05:13:47,353 Epoch[42] Batch [20]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.091538,	
2017-06-24 05:13:53,660 Epoch[42] Batch [30]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.091638,	
2017-06-24 05:14:00,039 Epoch[42] Batch [40]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.093036,	
2017-06-24 05:14:06,690 Epoch[42] Batch [50]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.090718,	
2017-06-24 05:14:13,309 Epoch[42] Batch [60]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.089368,	
2017-06-24 05:14:19,286 Epoch[42] Batch [70]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.089208,	
2017-06-24 05:14:26,528 Epoch[42] Batch [80]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.088664,	
2017-06-24 05:14:32,791 Epoch[42] Batch [90]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087769,	
2017-06-24 05:14:39,125 Epoch[42] Batch [100]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087416,	
2017-06-24 05:14:45,359 Epoch[42] Batch [110]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087037,	
2017-06-24 05:14:51,652 Epoch[42] Batch [120]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.086881,	
2017-06-24 05:14:58,001 Epoch[42] Batch [130]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.087056,	
2017-06-24 05:15:05,024 Epoch[42] Batch [140]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087325,	
2017-06-24 05:15:12,108 Epoch[42] Batch [150]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087843,	
2017-06-24 05:15:18,491 Epoch[42] Batch [160]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.087931,	
2017-06-24 05:15:24,725 Epoch[42] Batch [170]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087679,	
2017-06-24 05:15:31,260 Epoch[42] Batch [180]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087689,	
2017-06-24 05:15:37,523 Epoch[42] Batch [190]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087844,	
2017-06-24 05:15:43,730 Epoch[42] Batch [200]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.087783,	
2017-06-24 05:15:50,431 Epoch[42] Batch [210]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088361,	
2017-06-24 05:15:56,858 Epoch[42] Batch [220]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-24 05:16:03,295 Epoch[42] Batch [230]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-24 05:16:10,178 Epoch[42] Batch [240]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.087936,	
2017-06-24 05:16:16,311 Epoch[42] Batch [250]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-24 05:16:23,066 Epoch[42] Batch [260]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.087938,	
2017-06-24 05:16:29,359 Epoch[42] Batch [270]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.088017,	
2017-06-24 05:16:35,377 Epoch[42] Batch [280]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088212,	
2017-06-24 05:16:41,976 Epoch[42] Batch [290]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088075,	
2017-06-24 05:16:48,621 Epoch[42] Batch [300]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088260,	
2017-06-24 05:16:54,893 Epoch[42] Batch [310]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088143,	
2017-06-24 05:17:01,664 Epoch[42] Batch [320]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088284,	
2017-06-24 05:17:07,970 Epoch[42] Batch [330]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-24 05:17:14,271 Epoch[42] Batch [340]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088456,	
2017-06-24 05:17:20,458 Epoch[42] Batch [350]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088675,	
2017-06-24 05:17:26,405 Epoch[42] Batch [360]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.088637,	
2017-06-24 05:17:32,783 Epoch[42] Batch [370]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088605,	
2017-06-24 05:17:38,823 Epoch[42] Batch [380]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-24 05:17:44,803 Epoch[42] Batch [390]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-24 05:17:51,191 Epoch[42] Batch [400]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088569,	
2017-06-24 05:17:57,677 Epoch[42] Batch [410]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088655,	
2017-06-24 05:18:04,165 Epoch[42] Batch [420]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088699,	
2017-06-24 05:18:11,535 Epoch[42] Batch [430]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088671,	
2017-06-24 05:18:18,555 Epoch[42] Batch [440]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088501,	
2017-06-24 05:18:25,032 Epoch[42] Batch [450]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-24 05:18:31,664 Epoch[42] Batch [460]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.088583,	
2017-06-24 05:18:37,700 Epoch[42] Batch [470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088533,	
2017-06-24 05:18:44,347 Epoch[42] Batch [480]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088528,	
2017-06-24 05:18:51,251 Epoch[42] Batch [490]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-24 05:18:57,666 Epoch[42] Batch [500]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088689,	
2017-06-24 05:19:03,856 Epoch[42] Batch [510]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088502,	
2017-06-24 05:19:10,805 Epoch[42] Batch [520]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.088548,	
2017-06-24 05:19:17,416 Epoch[42] Batch [530]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088594,	
2017-06-24 05:19:23,909 Epoch[42] Batch [540]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088721,	
2017-06-24 05:19:29,874 Epoch[42] Batch [550]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-24 05:19:36,153 Epoch[42] Batch [560]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.088671,	
2017-06-24 05:19:42,017 Epoch[42] Batch [570]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.088848,	
2017-06-24 05:19:48,164 Epoch[42] Batch [580]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.088736,	
2017-06-24 05:19:54,426 Epoch[42] Batch [590]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088751,	
2017-06-24 05:20:00,764 Epoch[42] Batch [600]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088909,	
2017-06-24 05:20:06,954 Epoch[42] Batch [610]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088942,	
2017-06-24 05:20:13,287 Epoch[42] Batch [620]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-24 05:20:19,476 Epoch[42] Batch [630]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088803,	
2017-06-24 05:20:26,333 Epoch[42] Batch [640]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088875,	
2017-06-24 05:20:32,241 Epoch[42] Batch [650]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.088676,	
2017-06-24 05:20:38,059 Epoch[42] Batch [660]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088769,	
2017-06-24 05:20:43,988 Epoch[42] Batch [670]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.088758,	
2017-06-24 05:20:50,150 Epoch[42] Batch [680]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.088714,	
2017-06-24 05:20:56,447 Epoch[42] Batch [690]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088672,	
2017-06-24 05:21:03,035 Epoch[42] Batch [700]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.088583,	
2017-06-24 05:21:09,153 Epoch[42] Batch [710]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-24 05:21:15,258 Epoch[42] Batch [720]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-24 05:21:21,276 Epoch[42] Batch [730]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088608,	
2017-06-24 05:21:27,498 Epoch[42] Batch [740]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.088633,	
2017-06-24 05:21:33,842 Epoch[42] Batch [750]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088747,	
2017-06-24 05:21:40,262 Epoch[42] Batch [760]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088877,	
2017-06-24 05:21:47,462 Epoch[42] Batch [770]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088858,	
2017-06-24 05:21:53,671 Epoch[42] Batch [780]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088933,	
2017-06-24 05:22:00,040 Epoch[42] Batch [790]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088845,	
2017-06-24 05:22:06,346 Epoch[42] Batch [800]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088732,	
2017-06-24 05:22:12,659 Epoch[42] Batch [810]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088579,	
2017-06-24 05:22:19,143 Epoch[42] Batch [820]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088711,	
2017-06-24 05:22:25,505 Epoch[42] Batch [830]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.088848,	
2017-06-24 05:22:31,571 Epoch[42] Batch [840]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.088703,	
2017-06-24 05:22:37,940 Epoch[42] Batch [850]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088697,	
2017-06-24 05:22:44,278 Epoch[42] Batch [860]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088709,	
2017-06-24 05:22:50,463 Epoch[42] Batch [870]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088772,	
2017-06-24 05:22:56,738 Epoch[42] Batch [880]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-24 05:23:03,164 Epoch[42] Batch [890]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088876,	
2017-06-24 05:23:09,515 Epoch[42] Batch [900]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.088811,	
2017-06-24 05:23:16,076 Epoch[42] Batch [910]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.088849,	
2017-06-24 05:23:22,261 Epoch[42] Batch [920]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-24 05:23:28,357 Epoch[42] Batch [930]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.088821,	
2017-06-24 05:23:34,685 Epoch[42] Batch [940]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088723,	
2017-06-24 05:23:40,604 Epoch[42] Batch [950]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.088678,	
2017-06-24 05:23:47,024 Epoch[42] Batch [960]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088601,	
2017-06-24 05:23:53,331 Epoch[42] Batch [970]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-24 05:23:59,456 Epoch[42] Batch [980]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.088541,	
2017-06-24 05:24:06,070 Epoch[42] Batch [990]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088428,	
2017-06-24 05:24:12,690 Epoch[42] Batch [1000]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088454,	
2017-06-24 05:24:19,371 Epoch[42] Batch [1010]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.088500,	
2017-06-24 05:24:25,925 Epoch[42] Batch [1020]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.088535,	
2017-06-24 05:24:32,156 Epoch[42] Batch [1030]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.088507,	
2017-06-24 05:24:38,220 Epoch[42] Batch [1040]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.088422,	
2017-06-24 05:24:45,330 Epoch[42] Batch [1050]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.088402,	
2017-06-24 05:24:51,733 Epoch[42] Batch [1060]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.088337,	
2017-06-24 05:24:58,041 Epoch[42] Batch [1070]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088257,	
2017-06-24 05:25:04,894 Epoch[42] Batch [1080]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.088315,	
2017-06-24 05:25:11,281 Epoch[42] Batch [1090]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088374,	
2017-06-24 05:25:17,629 Epoch[42] Batch [1100]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.088388,	
2017-06-24 05:25:24,380 Epoch[42] Batch [1110]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.088463,	
2017-06-24 05:25:30,862 Epoch[42] Batch [1120]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088370,	
2017-06-24 05:25:37,753 Epoch[42] Batch [1130]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.088404,	
2017-06-24 05:25:44,642 Epoch[42] Batch [1140]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.088352,	
2017-06-24 05:25:51,359 Epoch[42] Batch [1150]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-24 05:25:58,182 Epoch[42] Batch [1160]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.088387,	
2017-06-24 05:26:05,273 Epoch[42] Batch [1170]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-24 05:26:12,075 Epoch[42] Batch [1180]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-24 05:26:19,047 Epoch[42] Batch [1190]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.088437,	
2017-06-24 05:26:26,326 Epoch[42] Batch [1200]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-24 05:26:33,355 Epoch[42] Batch [1210]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088509,	
2017-06-24 05:26:39,412 Epoch[42] Batch [1220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-24 05:26:45,712 Epoch[42] Batch [1230]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088608,	
2017-06-24 05:26:52,178 Epoch[42] Batch [1240]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088540,	
2017-06-24 05:26:58,674 Epoch[42] Batch [1250]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-24 05:27:05,731 Epoch[42] Batch [1260]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.088615,	
2017-06-24 05:27:12,288 Epoch[42] Batch [1270]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-24 05:27:18,756 Epoch[42] Batch [1280]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-24 05:27:24,931 Epoch[42] Batch [1290]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088662,	
2017-06-24 05:27:31,201 Epoch[42] Batch [1300]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088595,	
2017-06-24 05:27:37,283 Epoch[42] Batch [1310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-24 05:27:43,266 Epoch[42] Batch [1320]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.088766,	
2017-06-24 05:27:49,731 Epoch[42] Batch [1330]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-24 05:27:56,856 Epoch[42] Batch [1340]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-24 05:28:03,336 Epoch[42] Batch [1350]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088850,	
2017-06-24 05:28:09,812 Epoch[42] Batch [1360]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088841,	
2017-06-24 05:28:16,070 Epoch[42] Batch [1370]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088859,	
2017-06-24 05:28:23,280 Epoch[42] Batch [1380]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.088883,	
2017-06-24 05:28:30,699 Epoch[42] Batch [1390]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.088882,	
2017-06-24 05:28:37,214 Epoch[42] Batch [1400]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.088903,	
2017-06-24 05:28:43,459 Epoch[42] Batch [1410]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.088958,	
2017-06-24 05:28:49,794 Epoch[42] Batch [1420]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088978,	
2017-06-24 05:28:56,031 Epoch[42] Batch [1430]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.089025,	
2017-06-24 05:29:02,399 Epoch[42] Batch [1440]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.089016,	
2017-06-24 05:29:09,095 Epoch[42] Batch [1450]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088965,	
2017-06-24 05:29:15,584 Epoch[42] Batch [1460]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088984,	
2017-06-24 05:29:22,156 Epoch[42] Batch [1470]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.089031,	
2017-06-24 05:29:29,352 Epoch[42] Batch [1480]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088944,	
2017-06-24 05:29:33,371 Epoch[42] Train-FCNLogLoss=0.088953
2017-06-24 05:29:33,371 Epoch[42] Time cost=959.780
2017-06-24 05:29:34,206 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0043.params"
2017-06-24 05:29:37,904 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0043.states"
2017-06-24 05:29:45,145 Epoch[43] Batch [10]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.094956,	
2017-06-24 05:29:52,238 Epoch[43] Batch [20]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.090741,	
2017-06-24 05:29:58,599 Epoch[43] Batch [30]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.091536,	
2017-06-24 05:30:05,353 Epoch[43] Batch [40]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.091737,	
2017-06-24 05:30:12,246 Epoch[43] Batch [50]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.095269,	
2017-06-24 05:30:18,300 Epoch[43] Batch [60]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.094246,	
2017-06-24 05:30:24,632 Epoch[43] Batch [70]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094682,	
2017-06-24 05:30:30,895 Epoch[43] Batch [80]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.093488,	
2017-06-24 05:30:36,980 Epoch[43] Batch [90]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.092918,	
2017-06-24 05:30:43,402 Epoch[43] Batch [100]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.092268,	
2017-06-24 05:30:50,048 Epoch[43] Batch [110]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.092054,	
2017-06-24 05:30:56,773 Epoch[43] Batch [120]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.091711,	
2017-06-24 05:31:03,359 Epoch[43] Batch [130]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.091482,	
2017-06-24 05:31:09,500 Epoch[43] Batch [140]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.089995,	
2017-06-24 05:31:15,664 Epoch[43] Batch [150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.090409,	
2017-06-24 05:31:22,239 Epoch[43] Batch [160]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.090631,	
2017-06-24 05:31:28,665 Epoch[43] Batch [170]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.089980,	
2017-06-24 05:31:35,223 Epoch[43] Batch [180]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.089493,	
2017-06-24 05:31:41,666 Epoch[43] Batch [190]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088926,	
2017-06-24 05:31:47,624 Epoch[43] Batch [200]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.089036,	
2017-06-24 05:31:53,652 Epoch[43] Batch [210]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.088949,	
2017-06-24 05:32:00,358 Epoch[43] Batch [220]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.089054,	
2017-06-24 05:32:06,535 Epoch[43] Batch [230]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.089117,	
2017-06-24 05:32:12,739 Epoch[43] Batch [240]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.088938,	
2017-06-24 05:32:19,089 Epoch[43] Batch [250]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.089156,	
2017-06-24 05:32:25,838 Epoch[43] Batch [260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.088830,	
2017-06-24 05:32:32,060 Epoch[43] Batch [270]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.089185,	
2017-06-24 05:32:38,354 Epoch[43] Batch [280]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.089512,	
2017-06-24 05:32:44,726 Epoch[43] Batch [290]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.089432,	
2017-06-24 05:32:50,892 Epoch[43] Batch [300]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.089379,	
2017-06-24 05:32:56,904 Epoch[43] Batch [310]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.089205,	
2017-06-24 05:33:03,241 Epoch[43] Batch [320]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088862,	
2017-06-24 05:33:09,426 Epoch[43] Batch [330]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088843,	
2017-06-24 05:33:16,291 Epoch[43] Batch [340]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088671,	
2017-06-24 05:33:22,891 Epoch[43] Batch [350]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088754,	
2017-06-24 05:33:29,643 Epoch[43] Batch [360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.088577,	
2017-06-24 05:33:36,029 Epoch[43] Batch [370]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088519,	
2017-06-24 05:33:42,705 Epoch[43] Batch [380]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.088377,	
2017-06-24 05:33:49,252 Epoch[43] Batch [390]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088308,	
2017-06-24 05:33:55,703 Epoch[43] Batch [400]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-24 05:34:02,617 Epoch[43] Batch [410]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088453,	
2017-06-24 05:34:09,047 Epoch[43] Batch [420]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-24 05:34:15,191 Epoch[43] Batch [430]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.088494,	
2017-06-24 05:34:21,607 Epoch[43] Batch [440]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088332,	
2017-06-24 05:34:28,204 Epoch[43] Batch [450]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088526,	
2017-06-24 05:34:35,416 Epoch[43] Batch [460]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.088426,	
2017-06-24 05:34:42,432 Epoch[43] Batch [470]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-24 05:34:48,926 Epoch[43] Batch [480]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088399,	
2017-06-24 05:34:55,140 Epoch[43] Batch [490]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088491,	
2017-06-24 05:35:01,574 Epoch[43] Batch [500]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-24 05:35:07,717 Epoch[43] Batch [510]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.088387,	
2017-06-24 05:35:13,915 Epoch[43] Batch [520]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.088545,	
2017-06-24 05:35:20,299 Epoch[43] Batch [530]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088714,	
2017-06-24 05:35:26,628 Epoch[43] Batch [540]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088865,	
2017-06-24 05:35:34,144 Epoch[43] Batch [550]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.088841,	
2017-06-24 05:35:40,651 Epoch[43] Batch [560]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.088858,	
2017-06-24 05:35:47,423 Epoch[43] Batch [570]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088981,	
2017-06-24 05:35:54,689 Epoch[43] Batch [580]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.088925,	
2017-06-24 05:36:01,225 Epoch[43] Batch [590]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088850,	
2017-06-24 05:36:07,987 Epoch[43] Batch [600]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.088830,	
2017-06-24 05:36:14,124 Epoch[43] Batch [610]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088934,	
2017-06-24 05:36:21,041 Epoch[43] Batch [620]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.089037,	
2017-06-24 05:36:27,690 Epoch[43] Batch [630]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088998,	
2017-06-24 05:36:34,107 Epoch[43] Batch [640]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088964,	
2017-06-24 05:36:41,488 Epoch[43] Batch [650]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.089043,	
2017-06-24 05:36:48,306 Epoch[43] Batch [660]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.088982,	
2017-06-24 05:36:54,591 Epoch[43] Batch [670]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.089015,	
2017-06-24 05:37:01,068 Epoch[43] Batch [680]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.089088,	
2017-06-24 05:37:07,595 Epoch[43] Batch [690]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.088937,	
2017-06-24 05:37:14,158 Epoch[43] Batch [700]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.088953,	
2017-06-24 05:37:21,074 Epoch[43] Batch [710]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088897,	
2017-06-24 05:37:27,460 Epoch[43] Batch [720]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088930,	
2017-06-24 05:37:34,164 Epoch[43] Batch [730]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088928,	
2017-06-24 05:37:41,079 Epoch[43] Batch [740]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088952,	
2017-06-24 05:37:47,935 Epoch[43] Batch [750]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088930,	
2017-06-24 05:37:54,469 Epoch[43] Batch [760]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088835,	
2017-06-24 05:38:01,086 Epoch[43] Batch [770]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088853,	
2017-06-24 05:38:07,613 Epoch[43] Batch [780]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.088678,	
2017-06-24 05:38:14,186 Epoch[43] Batch [790]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.088633,	
2017-06-24 05:38:20,248 Epoch[43] Batch [800]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.088650,	
2017-06-24 05:38:27,082 Epoch[43] Batch [810]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-24 05:38:33,347 Epoch[43] Batch [820]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-24 05:38:40,536 Epoch[43] Batch [830]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088658,	
2017-06-24 05:38:46,699 Epoch[43] Batch [840]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.088592,	
2017-06-24 05:38:53,234 Epoch[43] Batch [850]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088528,	
2017-06-24 05:38:59,967 Epoch[43] Batch [860]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.088430,	
2017-06-24 05:39:07,033 Epoch[43] Batch [870]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088343,	
2017-06-24 05:39:13,401 Epoch[43] Batch [880]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088423,	
2017-06-24 05:39:20,108 Epoch[43] Batch [890]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.088279,	
2017-06-24 05:39:26,217 Epoch[43] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.088199,	
2017-06-24 05:39:30,462 Epoch[43] Batch [910]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.088204,	
2017-06-24 05:39:34,763 Epoch[43] Batch [920]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.088207,	
2017-06-24 05:39:38,981 Epoch[43] Batch [930]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.088170,	
2017-06-24 05:39:43,301 Epoch[43] Batch [940]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.088233,	
2017-06-24 05:39:47,574 Epoch[43] Batch [950]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.088201,	
2017-06-24 05:39:51,928 Epoch[43] Batch [960]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088149,	
2017-06-24 05:39:56,144 Epoch[43] Batch [970]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.088257,	
2017-06-24 05:40:00,249 Epoch[43] Batch [980]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.088218,	
2017-06-24 05:40:04,456 Epoch[43] Batch [990]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.088287,	
2017-06-24 05:40:08,765 Epoch[43] Batch [1000]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.088385,	
2017-06-24 05:40:13,017 Epoch[43] Batch [1010]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.088466,	
2017-06-24 05:40:17,368 Epoch[43] Batch [1020]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088521,	
2017-06-24 05:40:21,727 Epoch[43] Batch [1030]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.088536,	
2017-06-24 05:40:26,111 Epoch[43] Batch [1040]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-24 05:40:30,358 Epoch[43] Batch [1050]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.088526,	
2017-06-24 05:40:34,389 Epoch[43] Batch [1060]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.088446,	
2017-06-24 05:40:38,685 Epoch[43] Batch [1070]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.088468,	
2017-06-24 05:40:43,017 Epoch[43] Batch [1080]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-24 05:40:47,107 Epoch[43] Batch [1090]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.088434,	
2017-06-24 05:40:51,462 Epoch[43] Batch [1100]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088445,	
2017-06-24 05:40:55,558 Epoch[43] Batch [1110]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.088340,	
2017-06-24 05:40:59,832 Epoch[43] Batch [1120]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.088333,	
2017-06-24 05:41:04,233 Epoch[43] Batch [1130]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088314,	
2017-06-24 05:41:08,828 Epoch[43] Batch [1140]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088513,	
2017-06-24 05:41:13,325 Epoch[43] Batch [1150]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088486,	
2017-06-24 05:41:17,832 Epoch[43] Batch [1160]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-24 05:41:21,974 Epoch[43] Batch [1170]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.088538,	
2017-06-24 05:41:26,407 Epoch[43] Batch [1180]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-24 05:41:30,903 Epoch[43] Batch [1190]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-24 05:41:35,460 Epoch[43] Batch [1200]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088491,	
2017-06-24 05:41:39,861 Epoch[43] Batch [1210]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-24 05:41:44,358 Epoch[43] Batch [1220]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088555,	
2017-06-24 05:41:48,902 Epoch[43] Batch [1230]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-24 05:41:53,373 Epoch[43] Batch [1240]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088587,	
2017-06-24 05:41:57,876 Epoch[43] Batch [1250]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.088558,	
2017-06-24 05:42:02,285 Epoch[43] Batch [1260]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-24 05:42:06,763 Epoch[43] Batch [1270]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088543,	
2017-06-24 05:42:11,271 Epoch[43] Batch [1280]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088589,	
2017-06-24 05:42:15,506 Epoch[43] Batch [1290]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-24 05:42:19,740 Epoch[43] Batch [1300]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-24 05:42:24,123 Epoch[43] Batch [1310]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088620,	
2017-06-24 05:42:28,485 Epoch[43] Batch [1320]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-24 05:42:32,828 Epoch[43] Batch [1330]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-24 05:42:37,093 Epoch[43] Batch [1340]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.088542,	
2017-06-24 05:42:41,571 Epoch[43] Batch [1350]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-24 05:42:46,189 Epoch[43] Batch [1360]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088672,	
2017-06-24 05:42:50,487 Epoch[43] Batch [1370]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.088725,	
2017-06-24 05:42:54,839 Epoch[43] Batch [1380]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088740,	
2017-06-24 05:42:59,153 Epoch[43] Batch [1390]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088819,	
2017-06-24 05:43:03,509 Epoch[43] Batch [1400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.088788,	
2017-06-24 05:43:07,787 Epoch[43] Batch [1410]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.088812,	
2017-06-24 05:43:12,223 Epoch[43] Batch [1420]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088839,	
2017-06-24 05:43:16,479 Epoch[43] Batch [1430]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-24 05:43:20,789 Epoch[43] Batch [1440]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.088674,	
2017-06-24 05:43:25,149 Epoch[43] Batch [1450]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.088642,	
2017-06-24 05:43:29,375 Epoch[43] Batch [1460]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.088531,	
2017-06-24 05:43:33,719 Epoch[43] Batch [1470]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088542,	
2017-06-24 05:43:38,193 Epoch[43] Batch [1480]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-24 05:43:40,846 Epoch[43] Train-FCNLogLoss=0.088592
2017-06-24 05:43:40,846 Epoch[43] Time cost=842.942
2017-06-24 05:43:41,546 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0044.params"
2017-06-24 05:43:45,177 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0044.states"
2017-06-24 05:43:50,131 Epoch[44] Batch [10]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.096516,	
2017-06-24 05:43:54,572 Epoch[44] Batch [20]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.095403,	
2017-06-24 05:43:58,899 Epoch[44] Batch [30]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092084,	
2017-06-24 05:44:03,236 Epoch[44] Batch [40]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.090900,	
2017-06-24 05:44:07,496 Epoch[44] Batch [50]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.091548,	
2017-06-24 05:44:11,913 Epoch[44] Batch [60]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.092062,	
2017-06-24 05:44:16,303 Epoch[44] Batch [70]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.091767,	
2017-06-24 05:44:20,723 Epoch[44] Batch [80]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091405,	
2017-06-24 05:44:25,052 Epoch[44] Batch [90]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.090856,	
2017-06-24 05:44:29,397 Epoch[44] Batch [100]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.089507,	
2017-06-24 05:44:33,900 Epoch[44] Batch [110]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.088624,	
2017-06-24 05:44:38,105 Epoch[44] Batch [120]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.089390,	
2017-06-24 05:44:42,592 Epoch[44] Batch [130]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089045,	
2017-06-24 05:44:47,074 Epoch[44] Batch [140]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-24 05:44:51,604 Epoch[44] Batch [150]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088094,	
2017-06-24 05:44:55,880 Epoch[44] Batch [160]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.087587,	
2017-06-24 05:45:00,227 Epoch[44] Batch [170]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087356,	
2017-06-24 05:45:04,729 Epoch[44] Batch [180]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087300,	
2017-06-24 05:45:08,999 Epoch[44] Batch [190]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-24 05:45:13,431 Epoch[44] Batch [200]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087851,	
2017-06-24 05:45:17,872 Epoch[44] Batch [210]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088170,	
2017-06-24 05:45:22,247 Epoch[44] Batch [220]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.088618,	
2017-06-24 05:45:26,734 Epoch[44] Batch [230]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088665,	
2017-06-24 05:45:31,052 Epoch[44] Batch [240]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.088676,	
2017-06-24 05:45:35,482 Epoch[44] Batch [250]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-24 05:45:39,870 Epoch[44] Batch [260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.088683,	
2017-06-24 05:45:44,228 Epoch[44] Batch [270]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.088825,	
2017-06-24 05:45:48,505 Epoch[44] Batch [280]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089287,	
2017-06-24 05:45:53,033 Epoch[44] Batch [290]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089754,	
2017-06-24 05:45:57,626 Epoch[44] Batch [300]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089580,	
2017-06-24 05:46:02,031 Epoch[44] Batch [310]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.089271,	
2017-06-24 05:46:06,621 Epoch[44] Batch [320]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.089356,	
2017-06-24 05:46:11,245 Epoch[44] Batch [330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089227,	
2017-06-24 05:46:15,607 Epoch[44] Batch [340]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.089430,	
2017-06-24 05:46:20,132 Epoch[44] Batch [350]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089474,	
2017-06-24 05:46:24,734 Epoch[44] Batch [360]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089341,	
2017-06-24 05:46:29,310 Epoch[44] Batch [370]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089368,	
2017-06-24 05:46:33,950 Epoch[44] Batch [380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089406,	
2017-06-24 05:46:38,767 Epoch[44] Batch [390]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.089603,	
2017-06-24 05:46:44,057 Epoch[44] Batch [400]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089626,	
2017-06-24 05:46:48,454 Epoch[44] Batch [410]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089537,	
2017-06-24 05:46:53,143 Epoch[44] Batch [420]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089518,	
2017-06-24 05:46:57,657 Epoch[44] Batch [430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089282,	
2017-06-24 05:47:02,017 Epoch[44] Batch [440]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089212,	
2017-06-24 05:47:07,094 Epoch[44] Batch [450]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089018,	
2017-06-24 05:47:12,438 Epoch[44] Batch [460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088992,	
2017-06-24 05:47:16,997 Epoch[44] Batch [470]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089204,	
2017-06-24 05:47:21,628 Epoch[44] Batch [480]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089177,	
2017-06-24 05:47:26,235 Epoch[44] Batch [490]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088975,	
2017-06-24 05:47:31,057 Epoch[44] Batch [500]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088757,	
2017-06-24 05:47:35,943 Epoch[44] Batch [510]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088919,	
2017-06-24 05:47:40,318 Epoch[44] Batch [520]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.088899,	
2017-06-24 05:47:45,143 Epoch[44] Batch [530]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089008,	
2017-06-24 05:47:49,684 Epoch[44] Batch [540]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088986,	
2017-06-24 05:47:54,547 Epoch[44] Batch [550]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089181,	
2017-06-24 05:47:59,460 Epoch[44] Batch [560]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089110,	
2017-06-24 05:48:04,109 Epoch[44] Batch [570]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089233,	
2017-06-24 05:48:09,381 Epoch[44] Batch [580]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089355,	
2017-06-24 05:48:14,574 Epoch[44] Batch [590]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089449,	
2017-06-24 05:48:20,026 Epoch[44] Batch [600]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.089509,	
2017-06-24 05:48:25,126 Epoch[44] Batch [610]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.089375,	
2017-06-24 05:48:29,861 Epoch[44] Batch [620]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089649,	
2017-06-24 05:48:34,787 Epoch[44] Batch [630]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089652,	
2017-06-24 05:48:39,610 Epoch[44] Batch [640]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089666,	
2017-06-24 05:48:44,395 Epoch[44] Batch [650]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089713,	
2017-06-24 05:48:49,064 Epoch[44] Batch [660]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089780,	
2017-06-24 05:48:54,417 Epoch[44] Batch [670]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089752,	
2017-06-24 05:48:59,278 Epoch[44] Batch [680]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089731,	
2017-06-24 05:49:04,212 Epoch[44] Batch [690]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.089537,	
2017-06-24 05:49:09,223 Epoch[44] Batch [700]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089507,	
2017-06-24 05:49:14,534 Epoch[44] Batch [710]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089450,	
2017-06-24 05:49:20,079 Epoch[44] Batch [720]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.089446,	
2017-06-24 05:49:25,615 Epoch[44] Batch [730]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.089413,	
2017-06-24 05:49:30,944 Epoch[44] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089442,	
2017-06-24 05:49:36,459 Epoch[44] Batch [750]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.089459,	
2017-06-24 05:49:42,285 Epoch[44] Batch [760]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.089403,	
2017-06-24 05:49:48,295 Epoch[44] Batch [770]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.089231,	
2017-06-24 05:49:53,893 Epoch[44] Batch [780]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.089214,	
2017-06-24 05:49:59,211 Epoch[44] Batch [790]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089139,	
2017-06-24 05:50:04,662 Epoch[44] Batch [800]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.089146,	
2017-06-24 05:50:10,665 Epoch[44] Batch [810]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.089195,	
2017-06-24 05:50:16,600 Epoch[44] Batch [820]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.089285,	
2017-06-24 05:50:22,428 Epoch[44] Batch [830]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.089418,	
2017-06-24 05:50:28,214 Epoch[44] Batch [840]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.089406,	
2017-06-24 05:50:33,510 Epoch[44] Batch [850]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089409,	
2017-06-24 05:50:38,925 Epoch[44] Batch [860]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.089276,	
2017-06-24 05:50:44,915 Epoch[44] Batch [870]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.089248,	
2017-06-24 05:50:51,535 Epoch[44] Batch [880]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.089266,	
2017-06-24 05:50:57,034 Epoch[44] Batch [890]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.089263,	
2017-06-24 05:51:02,570 Epoch[44] Batch [900]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.089222,	
2017-06-24 05:51:07,743 Epoch[44] Batch [910]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089255,	
2017-06-24 05:51:13,462 Epoch[44] Batch [920]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-24 05:51:19,165 Epoch[44] Batch [930]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.089233,	
2017-06-24 05:51:25,163 Epoch[44] Batch [940]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.089279,	
2017-06-24 05:51:30,999 Epoch[44] Batch [950]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.089256,	
2017-06-24 05:51:36,366 Epoch[44] Batch [960]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089353,	
2017-06-24 05:51:42,306 Epoch[44] Batch [970]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.089210,	
2017-06-24 05:51:48,318 Epoch[44] Batch [980]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.089190,	
2017-06-24 05:51:54,057 Epoch[44] Batch [990]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.089193,	
2017-06-24 05:51:59,756 Epoch[44] Batch [1000]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.089189,	
2017-06-24 05:52:05,071 Epoch[44] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089221,	
2017-06-24 05:52:10,953 Epoch[44] Batch [1020]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.089271,	
2017-06-24 05:52:15,672 Epoch[44] Batch [1030]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089227,	
2017-06-24 05:52:20,547 Epoch[44] Batch [1040]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.089258,	
2017-06-24 05:52:25,883 Epoch[44] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089181,	
2017-06-24 05:52:31,589 Epoch[44] Batch [1060]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.089147,	
2017-06-24 05:52:36,420 Epoch[44] Batch [1070]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089084,	
2017-06-24 05:52:42,133 Epoch[44] Batch [1080]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.089056,	
2017-06-24 05:52:46,826 Epoch[44] Batch [1090]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089031,	
2017-06-24 05:52:51,933 Epoch[44] Batch [1100]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089000,	
2017-06-24 05:52:57,174 Epoch[44] Batch [1110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088876,	
2017-06-24 05:53:03,047 Epoch[44] Batch [1120]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088768,	
2017-06-24 05:53:08,609 Epoch[44] Batch [1130]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-24 05:53:14,008 Epoch[44] Batch [1140]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-24 05:53:19,383 Epoch[44] Batch [1150]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088663,	
2017-06-24 05:53:24,912 Epoch[44] Batch [1160]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088707,	
2017-06-24 05:53:29,672 Epoch[44] Batch [1170]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088698,	
2017-06-24 05:53:34,463 Epoch[44] Batch [1180]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-24 05:53:39,268 Epoch[44] Batch [1190]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-24 05:53:44,170 Epoch[44] Batch [1200]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088650,	
2017-06-24 05:53:49,338 Epoch[44] Batch [1210]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-24 05:53:54,298 Epoch[44] Batch [1220]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088728,	
2017-06-24 05:53:59,068 Epoch[44] Batch [1230]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088721,	
2017-06-24 05:54:04,229 Epoch[44] Batch [1240]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088778,	
2017-06-24 05:54:09,191 Epoch[44] Batch [1250]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088814,	
2017-06-24 05:54:14,335 Epoch[44] Batch [1260]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088785,	
2017-06-24 05:54:19,635 Epoch[44] Batch [1270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088782,	
2017-06-24 05:54:24,869 Epoch[44] Batch [1280]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088821,	
2017-06-24 05:54:30,065 Epoch[44] Batch [1290]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088810,	
2017-06-24 05:54:35,625 Epoch[44] Batch [1300]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088753,	
2017-06-24 05:54:41,241 Epoch[44] Batch [1310]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.088748,	
2017-06-24 05:54:46,346 Epoch[44] Batch [1320]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088761,	
2017-06-24 05:54:51,726 Epoch[44] Batch [1330]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088790,	
2017-06-24 05:54:57,022 Epoch[44] Batch [1340]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088810,	
2017-06-24 05:55:02,014 Epoch[44] Batch [1350]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088857,	
2017-06-24 05:55:07,583 Epoch[44] Batch [1360]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088848,	
2017-06-24 05:55:12,789 Epoch[44] Batch [1370]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088826,	
2017-06-24 05:55:18,091 Epoch[44] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088797,	
2017-06-24 05:55:23,710 Epoch[44] Batch [1390]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.088819,	
2017-06-24 05:55:29,841 Epoch[44] Batch [1400]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088785,	
2017-06-24 05:55:35,171 Epoch[44] Batch [1410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088862,	
2017-06-24 05:55:40,487 Epoch[44] Batch [1420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088913,	
2017-06-24 05:55:46,614 Epoch[44] Batch [1430]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.088891,	
2017-06-24 05:55:52,706 Epoch[44] Batch [1440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.088851,	
2017-06-24 05:55:58,514 Epoch[44] Batch [1450]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-24 05:56:04,613 Epoch[44] Batch [1460]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.088788,	
2017-06-24 05:56:10,982 Epoch[44] Batch [1470]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088788,	
2017-06-24 05:56:17,034 Epoch[44] Batch [1480]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.088790,	
2017-06-24 05:56:20,115 Epoch[44] Train-FCNLogLoss=0.088788
2017-06-24 05:56:20,116 Epoch[44] Time cost=754.938
2017-06-24 05:56:20,892 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0045.params"
2017-06-24 05:56:24,306 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0045.states"
2017-06-24 05:56:31,009 Epoch[45] Batch [10]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088852,	
2017-06-24 05:56:36,855 Epoch[45] Batch [20]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.087888,	
2017-06-24 05:56:42,767 Epoch[45] Batch [30]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085734,	
2017-06-24 05:56:48,620 Epoch[45] Batch [40]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.085932,	
2017-06-24 05:56:54,428 Epoch[45] Batch [50]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.090032,	
2017-06-24 05:57:00,856 Epoch[45] Batch [60]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.089304,	
2017-06-24 05:57:07,404 Epoch[45] Batch [70]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-24 05:57:13,478 Epoch[45] Batch [80]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087825,	
2017-06-24 05:57:19,699 Epoch[45] Batch [90]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087909,	
2017-06-24 05:57:25,809 Epoch[45] Batch [100]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-24 05:57:32,523 Epoch[45] Batch [110]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087504,	
2017-06-24 05:57:39,870 Epoch[45] Batch [120]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.087331,	
2017-06-24 05:57:46,057 Epoch[45] Batch [130]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088073,	
2017-06-24 05:57:52,319 Epoch[45] Batch [140]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088348,	
2017-06-24 05:57:58,630 Epoch[45] Batch [150]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088098,	
2017-06-24 05:58:05,176 Epoch[45] Batch [160]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088082,	
2017-06-24 05:58:11,234 Epoch[45] Batch [170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.088363,	
2017-06-24 05:58:17,608 Epoch[45] Batch [180]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088169,	
2017-06-24 05:58:23,745 Epoch[45] Batch [190]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-24 05:58:30,441 Epoch[45] Batch [200]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088846,	
2017-06-24 05:58:37,386 Epoch[45] Batch [210]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.088292,	
2017-06-24 05:58:43,830 Epoch[45] Batch [220]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088703,	
2017-06-24 05:58:50,280 Epoch[45] Batch [230]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088254,	
2017-06-24 05:58:56,524 Epoch[45] Batch [240]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.088048,	
2017-06-24 05:59:02,641 Epoch[45] Batch [250]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087792,	
2017-06-24 05:59:08,740 Epoch[45] Batch [260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.088176,	
2017-06-24 05:59:15,128 Epoch[45] Batch [270]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088022,	
2017-06-24 05:59:20,920 Epoch[45] Batch [280]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088194,	
2017-06-24 05:59:27,407 Epoch[45] Batch [290]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.087898,	
2017-06-24 05:59:33,618 Epoch[45] Batch [300]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.087889,	
2017-06-24 05:59:40,036 Epoch[45] Batch [310]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087940,	
2017-06-24 05:59:46,262 Epoch[45] Batch [320]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087977,	
2017-06-24 05:59:52,782 Epoch[45] Batch [330]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.087737,	
2017-06-24 05:59:59,356 Epoch[45] Batch [340]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087675,	
2017-06-24 06:00:05,612 Epoch[45] Batch [350]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087696,	
2017-06-24 06:00:11,708 Epoch[45] Batch [360]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.087915,	
2017-06-24 06:00:18,820 Epoch[45] Batch [370]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087880,	
2017-06-24 06:00:25,462 Epoch[45] Batch [380]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087833,	
2017-06-24 06:00:31,207 Epoch[45] Batch [390]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088117,	
2017-06-24 06:00:37,244 Epoch[45] Batch [400]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088354,	
2017-06-24 06:00:43,603 Epoch[45] Batch [410]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.088287,	
2017-06-24 06:00:49,441 Epoch[45] Batch [420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088214,	
2017-06-24 06:00:56,020 Epoch[45] Batch [430]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088397,	
2017-06-24 06:01:01,675 Epoch[45] Batch [440]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088604,	
2017-06-24 06:01:07,519 Epoch[45] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088414,	
2017-06-24 06:01:14,084 Epoch[45] Batch [460]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.088331,	
2017-06-24 06:01:20,408 Epoch[45] Batch [470]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.088414,	
2017-06-24 06:01:26,482 Epoch[45] Batch [480]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.088482,	
2017-06-24 06:01:32,867 Epoch[45] Batch [490]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-24 06:01:39,305 Epoch[45] Batch [500]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088482,	
2017-06-24 06:01:45,345 Epoch[45] Batch [510]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.088666,	
2017-06-24 06:01:51,546 Epoch[45] Batch [520]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.088862,	
2017-06-24 06:01:57,738 Epoch[45] Batch [530]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088977,	
2017-06-24 06:02:04,075 Epoch[45] Batch [540]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.089022,	
2017-06-24 06:02:10,504 Epoch[45] Batch [550]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088853,	
2017-06-24 06:02:16,719 Epoch[45] Batch [560]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088699,	
2017-06-24 06:02:22,422 Epoch[45] Batch [570]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-24 06:02:28,348 Epoch[45] Batch [580]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-24 06:02:34,893 Epoch[45] Batch [590]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088650,	
2017-06-24 06:02:41,038 Epoch[45] Batch [600]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.088517,	
2017-06-24 06:02:46,756 Epoch[45] Batch [610]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-24 06:02:53,079 Epoch[45] Batch [620]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.088418,	
2017-06-24 06:02:58,825 Epoch[45] Batch [630]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-24 06:03:04,592 Epoch[45] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.088271,	
2017-06-24 06:03:10,078 Epoch[45] Batch [650]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.088462,	
2017-06-24 06:03:15,585 Epoch[45] Batch [660]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088600,	
2017-06-24 06:03:20,839 Epoch[45] Batch [670]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088597,	
2017-06-24 06:03:26,405 Epoch[45] Batch [680]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088564,	
2017-06-24 06:03:32,144 Epoch[45] Batch [690]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.088492,	
2017-06-24 06:03:37,954 Epoch[45] Batch [700]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088481,	
2017-06-24 06:03:43,484 Epoch[45] Batch [710]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088478,	
2017-06-24 06:03:49,383 Epoch[45] Batch [720]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.088566,	
2017-06-24 06:03:55,242 Epoch[45] Batch [730]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.088605,	
2017-06-24 06:04:00,808 Epoch[45] Batch [740]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-24 06:04:07,030 Epoch[45] Batch [750]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.088530,	
2017-06-24 06:04:12,652 Epoch[45] Batch [760]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.088422,	
2017-06-24 06:04:17,667 Epoch[45] Batch [770]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088273,	
2017-06-24 06:04:23,068 Epoch[45] Batch [780]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088260,	
2017-06-24 06:04:28,637 Epoch[45] Batch [790]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088178,	
2017-06-24 06:04:34,556 Epoch[45] Batch [800]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.088307,	
2017-06-24 06:04:39,716 Epoch[45] Batch [810]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088438,	
2017-06-24 06:04:45,228 Epoch[45] Batch [820]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-24 06:04:50,447 Epoch[45] Batch [830]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088405,	
2017-06-24 06:04:55,625 Epoch[45] Batch [840]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088351,	
2017-06-24 06:05:01,039 Epoch[45] Batch [850]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088270,	
2017-06-24 06:05:06,446 Epoch[45] Batch [860]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088323,	
2017-06-24 06:05:11,531 Epoch[45] Batch [870]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088322,	
2017-06-24 06:05:16,956 Epoch[45] Batch [880]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088277,	
2017-06-24 06:05:22,692 Epoch[45] Batch [890]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.088244,	
2017-06-24 06:05:28,610 Epoch[45] Batch [900]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-24 06:05:34,868 Epoch[45] Batch [910]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088260,	
2017-06-24 06:05:40,721 Epoch[45] Batch [920]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.088264,	
2017-06-24 06:05:47,113 Epoch[45] Batch [930]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088254,	
2017-06-24 06:05:53,799 Epoch[45] Batch [940]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088257,	
2017-06-24 06:05:59,428 Epoch[45] Batch [950]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.088254,	
2017-06-24 06:06:04,733 Epoch[45] Batch [960]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088201,	
2017-06-24 06:06:10,082 Epoch[45] Batch [970]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088156,	
2017-06-24 06:06:15,406 Epoch[45] Batch [980]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088206,	
2017-06-24 06:06:20,495 Epoch[45] Batch [990]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088239,	
2017-06-24 06:06:25,889 Epoch[45] Batch [1000]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088283,	
2017-06-24 06:06:30,980 Epoch[45] Batch [1010]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088296,	
2017-06-24 06:06:35,981 Epoch[45] Batch [1020]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088399,	
2017-06-24 06:06:40,750 Epoch[45] Batch [1030]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088374,	
2017-06-24 06:06:46,135 Epoch[45] Batch [1040]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088425,	
2017-06-24 06:06:51,512 Epoch[45] Batch [1050]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088422,	
2017-06-24 06:06:56,734 Epoch[45] Batch [1060]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088372,	
2017-06-24 06:07:02,367 Epoch[45] Batch [1070]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.088411,	
2017-06-24 06:07:08,206 Epoch[45] Batch [1080]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088401,	
2017-06-24 06:07:12,994 Epoch[45] Batch [1090]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088457,	
2017-06-24 06:07:18,158 Epoch[45] Batch [1100]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088434,	
2017-06-24 06:07:23,623 Epoch[45] Batch [1110]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088449,	
2017-06-24 06:07:28,624 Epoch[45] Batch [1120]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088387,	
2017-06-24 06:07:33,706 Epoch[45] Batch [1130]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088344,	
2017-06-24 06:07:39,358 Epoch[45] Batch [1140]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.088331,	
2017-06-24 06:07:44,890 Epoch[45] Batch [1150]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088329,	
2017-06-24 06:07:50,928 Epoch[45] Batch [1160]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088394,	
2017-06-24 06:07:56,190 Epoch[45] Batch [1170]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-24 06:08:01,573 Epoch[45] Batch [1180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088345,	
2017-06-24 06:08:07,414 Epoch[45] Batch [1190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-24 06:08:13,493 Epoch[45] Batch [1200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.088390,	
2017-06-24 06:08:18,973 Epoch[45] Batch [1210]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088351,	
2017-06-24 06:08:24,751 Epoch[45] Batch [1220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088354,	
2017-06-24 06:08:30,732 Epoch[45] Batch [1230]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.088356,	
2017-06-24 06:08:36,568 Epoch[45] Batch [1240]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-24 06:08:42,055 Epoch[45] Batch [1250]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.088413,	
2017-06-24 06:08:47,471 Epoch[45] Batch [1260]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-24 06:08:53,262 Epoch[45] Batch [1270]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-24 06:08:59,019 Epoch[45] Batch [1280]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088387,	
2017-06-24 06:09:04,494 Epoch[45] Batch [1290]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088348,	
2017-06-24 06:09:09,733 Epoch[45] Batch [1300]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088357,	
2017-06-24 06:09:15,335 Epoch[45] Batch [1310]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.088361,	
2017-06-24 06:09:21,262 Epoch[45] Batch [1320]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.088317,	
2017-06-24 06:09:27,712 Epoch[45] Batch [1330]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088243,	
2017-06-24 06:09:33,902 Epoch[45] Batch [1340]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088220,	
2017-06-24 06:09:40,447 Epoch[45] Batch [1350]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088251,	
2017-06-24 06:09:48,219 Epoch[45] Batch [1360]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.088322,	
2017-06-24 06:09:55,008 Epoch[45] Batch [1370]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.088413,	
2017-06-24 06:10:01,143 Epoch[45] Batch [1380]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088346,	
2017-06-24 06:10:07,085 Epoch[45] Batch [1390]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.088373,	
2017-06-24 06:10:13,043 Epoch[45] Batch [1400]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088308,	
2017-06-24 06:10:19,293 Epoch[45] Batch [1410]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.088317,	
2017-06-24 06:10:25,445 Epoch[45] Batch [1420]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.088315,	
2017-06-24 06:10:31,871 Epoch[45] Batch [1430]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088281,	
2017-06-24 06:10:37,885 Epoch[45] Batch [1440]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088208,	
2017-06-24 06:10:43,796 Epoch[45] Batch [1450]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-24 06:10:50,015 Epoch[45] Batch [1460]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.088134,	
2017-06-24 06:10:56,333 Epoch[45] Batch [1470]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.088129,	
2017-06-24 06:11:02,611 Epoch[45] Batch [1480]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.088081,	
2017-06-24 06:11:06,490 Epoch[45] Train-FCNLogLoss=0.088065
2017-06-24 06:11:06,490 Epoch[45] Time cost=882.183

2017-06-24 11:30:07,632 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3,4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate4x4'}

2017-06-24 11:31:40,894 Epoch[0] Batch [10]	Speed: 8.22 samples/sec	Train-FCNLogLoss=2.799689,	
2017-06-24 11:31:49,257 Epoch[0] Batch [20]	Speed: 9.57 samples/sec	Train-FCNLogLoss=2.456801,	
2017-06-24 11:31:58,614 Epoch[0] Batch [30]	Speed: 8.55 samples/sec	Train-FCNLogLoss=2.108990,	
2017-06-24 11:32:08,071 Epoch[0] Batch [40]	Speed: 8.46 samples/sec	Train-FCNLogLoss=1.849049,	
2017-06-24 11:32:17,910 Epoch[0] Batch [50]	Speed: 8.13 samples/sec	Train-FCNLogLoss=1.654073,	
2017-06-24 11:32:27,614 Epoch[0] Batch [60]	Speed: 8.24 samples/sec	Train-FCNLogLoss=1.501510,	
2017-06-24 11:32:37,751 Epoch[0] Batch [70]	Speed: 7.89 samples/sec	Train-FCNLogLoss=1.380095,	
2017-06-24 11:32:47,093 Epoch[0] Batch [80]	Speed: 8.56 samples/sec	Train-FCNLogLoss=1.284252,	
2017-06-24 11:32:57,065 Epoch[0] Batch [90]	Speed: 8.02 samples/sec	Train-FCNLogLoss=1.199259,	
2017-06-24 11:33:07,743 Epoch[0] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=1.137337,	
2017-06-24 11:33:18,434 Epoch[0] Batch [110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=1.087070,	
2017-06-24 11:33:28,224 Epoch[0] Batch [120]	Speed: 8.17 samples/sec	Train-FCNLogLoss=1.038576,	
2017-06-24 11:33:37,479 Epoch[0] Batch [130]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.996094,	
2017-06-24 11:33:47,863 Epoch[0] Batch [140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.961357,	
2017-06-24 11:33:57,851 Epoch[0] Batch [150]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.927900,	
2017-06-24 11:34:08,064 Epoch[0] Batch [160]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.900050,	
2017-06-24 11:34:18,627 Epoch[0] Batch [170]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.875880,	
2017-06-24 11:34:29,019 Epoch[0] Batch [180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.852583,	
2017-06-24 11:34:38,768 Epoch[0] Batch [190]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.832977,	
2017-06-24 11:34:49,967 Epoch[0] Batch [200]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.812464,	
2017-06-24 11:35:00,405 Epoch[0] Batch [210]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.794408,	
2017-06-24 11:35:11,187 Epoch[0] Batch [220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.776191,	
2017-06-24 11:35:21,848 Epoch[0] Batch [230]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.758259,	
2017-06-24 11:35:32,709 Epoch[0] Batch [240]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.740905,	
2017-06-24 11:35:43,968 Epoch[0] Batch [250]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.725427,	
2017-06-24 11:35:54,798 Epoch[0] Batch [260]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.713576,	
2017-06-24 11:36:05,134 Epoch[0] Batch [270]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.699720,	
2017-06-24 11:36:15,297 Epoch[0] Batch [280]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.687991,	
2017-06-24 11:36:25,818 Epoch[0] Batch [290]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.678348,	
2017-06-24 11:36:35,657 Epoch[0] Batch [300]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.667545,	
2017-06-24 11:36:45,909 Epoch[0] Batch [310]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.656805,	
2017-06-24 11:36:56,342 Epoch[0] Batch [320]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.647602,	
2017-06-24 11:37:06,490 Epoch[0] Batch [330]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.638303,	
2017-06-24 11:37:17,361 Epoch[0] Batch [340]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.629518,	
2017-06-24 11:37:27,956 Epoch[0] Batch [350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.621713,	
2017-06-24 11:37:38,910 Epoch[0] Batch [360]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.614151,	
2017-06-24 11:37:49,541 Epoch[0] Batch [370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.606681,	
2017-06-24 11:37:59,761 Epoch[0] Batch [380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.599549,	
2017-06-24 11:38:11,157 Epoch[0] Batch [390]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.593912,	
2017-06-24 11:38:22,044 Epoch[0] Batch [400]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.588022,	
2017-06-24 11:38:32,764 Epoch[0] Batch [410]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.580801,	
2017-06-24 11:38:43,681 Epoch[0] Batch [420]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.575405,	
2017-06-24 11:38:55,258 Epoch[0] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.569969,	
2017-06-24 11:39:05,791 Epoch[0] Batch [440]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.565197,	
2017-06-24 11:39:16,981 Epoch[0] Batch [450]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.560479,	
2017-06-24 11:39:28,955 Epoch[0] Batch [460]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.555823,	
2017-06-24 11:39:39,764 Epoch[0] Batch [470]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.550065,	
2017-06-24 11:39:51,182 Epoch[0] Batch [480]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.545787,	
2017-06-24 11:40:01,417 Epoch[0] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.541367,	
2017-06-24 11:40:11,850 Epoch[0] Batch [500]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.537152,	
2017-06-24 11:40:22,537 Epoch[0] Batch [510]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.532682,	
2017-06-24 11:40:32,994 Epoch[0] Batch [520]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.528873,	
2017-06-24 11:40:43,312 Epoch[0] Batch [530]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.524889,	
2017-06-24 11:40:54,331 Epoch[0] Batch [540]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.521478,	
2017-06-24 11:41:05,402 Epoch[0] Batch [550]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.518242,	
2017-06-24 11:41:16,375 Epoch[0] Batch [560]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.514206,	
2017-06-24 11:41:27,202 Epoch[0] Batch [570]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.511055,	
2017-06-24 11:41:37,878 Epoch[0] Batch [580]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.507357,	
2017-06-24 11:41:48,550 Epoch[0] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.503616,	
2017-06-24 11:41:59,020 Epoch[0] Batch [600]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.500320,	
2017-06-24 11:42:09,440 Epoch[0] Batch [610]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.496866,	
2017-06-24 11:42:20,210 Epoch[0] Batch [620]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.493959,	
2017-06-24 11:42:30,192 Epoch[0] Batch [630]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.490863,	
2017-06-24 11:42:40,699 Epoch[0] Batch [640]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.487829,	
2017-06-24 11:42:50,933 Epoch[0] Batch [650]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.484514,	
2017-06-24 11:43:01,319 Epoch[0] Batch [660]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.481529,	
2017-06-24 11:43:11,381 Epoch[0] Batch [670]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.478519,	
2017-06-24 11:43:22,479 Epoch[0] Batch [680]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.475817,	
2017-06-24 11:43:33,421 Epoch[0] Batch [690]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.473046,	
2017-06-24 11:43:43,640 Epoch[0] Batch [700]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.470489,	
2017-06-24 11:43:55,556 Epoch[0] Batch [710]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.467840,	
2017-06-24 11:44:06,799 Epoch[0] Batch [720]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.464775,	
2017-06-24 11:44:18,687 Epoch[0] Batch [730]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.462398,	
2017-06-24 11:44:30,103 Epoch[0] Batch [740]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.459738,	
2017-06-24 11:44:31,840 Epoch[0] Train-FCNLogLoss=0.459391
2017-06-24 11:44:31,840 Epoch[0] Time cost=794.324
2017-06-24 11:44:33,754 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0001.params"
2017-06-24 11:44:35,909 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0001.states"
2017-06-24 11:44:47,394 Epoch[1] Batch [10]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.314495,	
2017-06-24 11:44:57,390 Epoch[1] Batch [20]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.294626,	
2017-06-24 11:45:06,827 Epoch[1] Batch [30]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.298690,	
2017-06-24 11:45:16,495 Epoch[1] Batch [40]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.307562,	
2017-06-24 11:45:26,263 Epoch[1] Batch [50]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.304123,	
2017-06-24 11:45:36,246 Epoch[1] Batch [60]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.303036,	
2017-06-24 11:45:46,187 Epoch[1] Batch [70]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.300340,	
2017-06-24 11:45:55,458 Epoch[1] Batch [80]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.297357,	
2017-06-24 11:46:04,941 Epoch[1] Batch [90]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.295011,	
2017-06-24 11:46:15,434 Epoch[1] Batch [100]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.293604,	
2017-06-24 11:46:25,392 Epoch[1] Batch [110]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.290727,	
2017-06-24 11:46:35,760 Epoch[1] Batch [120]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.291236,	
2017-06-24 11:46:46,602 Epoch[1] Batch [130]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.289924,	
2017-06-24 11:46:56,067 Epoch[1] Batch [140]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.292696,	
2017-06-24 11:47:06,531 Epoch[1] Batch [150]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.292639,	
2017-06-24 11:47:16,412 Epoch[1] Batch [160]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.289964,	
2017-06-24 11:47:25,879 Epoch[1] Batch [170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.288783,	
2017-06-24 11:47:35,624 Epoch[1] Batch [180]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.287636,	
2017-06-24 11:47:45,781 Epoch[1] Batch [190]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.286047,	
2017-06-24 11:47:56,299 Epoch[1] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.286152,	
2017-06-24 11:48:06,787 Epoch[1] Batch [210]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.285548,	
2017-06-24 11:48:16,099 Epoch[1] Batch [220]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.284774,	
2017-06-24 11:48:25,700 Epoch[1] Batch [230]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.283546,	
2017-06-24 11:48:36,168 Epoch[1] Batch [240]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.282958,	
2017-06-24 11:48:46,204 Epoch[1] Batch [250]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.282900,	
2017-06-24 11:48:56,218 Epoch[1] Batch [260]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.282257,	
2017-06-24 11:49:05,628 Epoch[1] Batch [270]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.287446,	
2017-06-24 11:49:15,099 Epoch[1] Batch [280]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.311524,	
2017-06-24 11:49:25,159 Epoch[1] Batch [290]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.320113,	
2017-06-24 11:49:35,231 Epoch[1] Batch [300]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.324302,	
2017-06-24 11:49:44,743 Epoch[1] Batch [310]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.329803,	
2017-06-24 11:49:54,420 Epoch[1] Batch [320]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.333016,	
2017-06-24 11:50:04,054 Epoch[1] Batch [330]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.335564,	
2017-06-24 11:50:13,948 Epoch[1] Batch [340]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.336372,	
2017-06-24 11:50:24,252 Epoch[1] Batch [350]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.337202,	
2017-06-24 11:50:33,926 Epoch[1] Batch [360]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.337863,	
2017-06-24 11:50:43,336 Epoch[1] Batch [370]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.337045,	
2017-06-24 11:50:52,370 Epoch[1] Batch [380]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.336651,	
2017-06-24 11:51:02,763 Epoch[1] Batch [390]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.336444,	
2017-06-24 11:51:13,013 Epoch[1] Batch [400]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.335312,	
2017-06-24 11:51:23,080 Epoch[1] Batch [410]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.334847,	
2017-06-24 11:51:33,425 Epoch[1] Batch [420]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.334537,	
2017-06-24 11:51:43,768 Epoch[1] Batch [430]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.334402,	
2017-06-24 11:51:54,263 Epoch[1] Batch [440]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.333171,	
2017-06-24 11:52:04,139 Epoch[1] Batch [450]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.331984,	
2017-06-24 11:52:15,198 Epoch[1] Batch [460]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.333008,	
2017-06-24 11:52:26,045 Epoch[1] Batch [470]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.333911,	
2017-06-24 11:52:37,273 Epoch[1] Batch [480]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.333002,	
2017-06-24 11:52:48,165 Epoch[1] Batch [490]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.331980,	
2017-06-24 11:52:58,775 Epoch[1] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.331063,	
2017-06-24 11:53:08,636 Epoch[1] Batch [510]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.331503,	
2017-06-24 11:53:18,902 Epoch[1] Batch [520]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.332051,	
2017-06-24 11:53:30,139 Epoch[1] Batch [530]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.331827,	
2017-06-24 11:53:41,086 Epoch[1] Batch [540]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.331190,	
2017-06-24 11:53:52,955 Epoch[1] Batch [550]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.330014,	
2017-06-24 11:54:02,776 Epoch[1] Batch [560]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.329144,	
2017-06-24 11:54:11,931 Epoch[1] Batch [570]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.329142,	
2017-06-24 11:54:21,080 Epoch[1] Batch [580]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.328477,	
2017-06-24 11:54:30,878 Epoch[1] Batch [590]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.327907,	
2017-06-24 11:54:41,171 Epoch[1] Batch [600]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.327745,	
2017-06-24 11:54:52,540 Epoch[1] Batch [610]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.326890,	
2017-06-24 11:55:03,140 Epoch[1] Batch [620]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.326319,	
2017-06-24 11:55:14,039 Epoch[1] Batch [630]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.325277,	
2017-06-24 11:55:24,745 Epoch[1] Batch [640]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.324176,	
2017-06-24 11:55:35,747 Epoch[1] Batch [650]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.322801,	
2017-06-24 11:55:46,935 Epoch[1] Batch [660]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.321938,	
2017-06-24 11:55:57,269 Epoch[1] Batch [670]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.321166,	
2017-06-24 11:56:08,063 Epoch[1] Batch [680]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.319606,	
2017-06-24 11:56:18,763 Epoch[1] Batch [690]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.318739,	
2017-06-24 11:56:29,808 Epoch[1] Batch [700]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.317880,	
2017-06-24 11:56:40,713 Epoch[1] Batch [710]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.317680,	
2017-06-24 11:56:51,061 Epoch[1] Batch [720]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.317233,	
2017-06-24 11:57:01,226 Epoch[1] Batch [730]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.316498,	
2017-06-24 11:57:10,679 Epoch[1] Batch [740]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.315657,	
2017-06-24 11:57:12,380 Epoch[1] Train-FCNLogLoss=0.315456
2017-06-24 11:57:12,380 Epoch[1] Time cost=756.471
2017-06-24 11:57:14,540 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0002.params"
2017-06-24 11:57:17,157 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0002.states"
2017-06-24 11:57:28,059 Epoch[2] Batch [10]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.230513,	
2017-06-24 11:57:37,591 Epoch[2] Batch [20]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.228869,	
2017-06-24 11:57:47,660 Epoch[2] Batch [30]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.239828,	
2017-06-24 11:57:58,229 Epoch[2] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.243874,	
2017-06-24 11:58:09,498 Epoch[2] Batch [50]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.243314,	
2017-06-24 11:58:20,023 Epoch[2] Batch [60]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.241384,	
2017-06-24 11:58:30,097 Epoch[2] Batch [70]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.241901,	
2017-06-24 11:58:40,019 Epoch[2] Batch [80]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.244172,	
2017-06-24 11:58:50,134 Epoch[2] Batch [90]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.245420,	
2017-06-24 11:59:00,215 Epoch[2] Batch [100]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.247477,	
2017-06-24 11:59:11,007 Epoch[2] Batch [110]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.245677,	
2017-06-24 11:59:22,163 Epoch[2] Batch [120]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.246813,	
2017-06-24 11:59:32,643 Epoch[2] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.245906,	
2017-06-24 11:59:42,582 Epoch[2] Batch [140]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.245132,	
2017-06-24 11:59:52,330 Epoch[2] Batch [150]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.245193,	
2017-06-24 12:00:02,661 Epoch[2] Batch [160]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.242926,	
2017-06-24 12:00:12,012 Epoch[2] Batch [170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.242931,	
2017-06-24 12:00:21,386 Epoch[2] Batch [180]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.243506,	
2017-06-24 12:00:31,206 Epoch[2] Batch [190]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.242758,	
2017-06-24 12:00:41,004 Epoch[2] Batch [200]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.241755,	
2017-06-24 12:00:51,194 Epoch[2] Batch [210]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.242346,	
2017-06-24 12:01:01,609 Epoch[2] Batch [220]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.243160,	
2017-06-24 12:01:11,798 Epoch[2] Batch [230]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.243619,	
2017-06-24 12:01:22,390 Epoch[2] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.243671,	
2017-06-24 12:01:32,892 Epoch[2] Batch [250]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.242623,	
2017-06-24 12:01:43,008 Epoch[2] Batch [260]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.241835,	
2017-06-24 12:01:53,473 Epoch[2] Batch [270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.240900,	
2017-06-24 12:02:04,069 Epoch[2] Batch [280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.240851,	
2017-06-24 12:02:14,702 Epoch[2] Batch [290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.240626,	
2017-06-24 12:02:25,989 Epoch[2] Batch [300]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.241039,	
2017-06-24 12:02:35,724 Epoch[2] Batch [310]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.239814,	
2017-06-24 12:02:46,297 Epoch[2] Batch [320]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.240775,	
2017-06-24 12:02:56,730 Epoch[2] Batch [330]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.240756,	
2017-06-24 12:03:07,184 Epoch[2] Batch [340]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.241504,	
2017-06-24 12:03:17,291 Epoch[2] Batch [350]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.240734,	
2017-06-24 12:03:27,005 Epoch[2] Batch [360]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.240219,	
2017-06-24 12:03:36,706 Epoch[2] Batch [370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.241695,	
2017-06-24 12:03:46,654 Epoch[2] Batch [380]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.241508,	
2017-06-24 12:03:56,993 Epoch[2] Batch [390]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.242010,	
2017-06-24 12:04:07,969 Epoch[2] Batch [400]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.241099,	
2017-06-24 12:04:18,223 Epoch[2] Batch [410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.240205,	
2017-06-24 12:04:29,113 Epoch[2] Batch [420]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.239945,	
2017-06-24 12:04:40,464 Epoch[2] Batch [430]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.239601,	
2017-06-24 12:04:51,105 Epoch[2] Batch [440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.238876,	
2017-06-24 12:05:02,323 Epoch[2] Batch [450]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.238109,	
2017-06-24 12:05:13,168 Epoch[2] Batch [460]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.238229,	
2017-06-24 12:05:23,473 Epoch[2] Batch [470]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.238094,	
2017-06-24 12:05:34,151 Epoch[2] Batch [480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.238833,	
2017-06-24 12:05:44,976 Epoch[2] Batch [490]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.238354,	
2017-06-24 12:05:55,827 Epoch[2] Batch [500]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.238711,	
2017-06-24 12:06:06,374 Epoch[2] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.238411,	
2017-06-24 12:06:16,888 Epoch[2] Batch [520]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.237743,	
2017-06-24 12:06:25,512 Epoch[2] Batch [530]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.236690,	
2017-06-24 12:06:33,094 Epoch[2] Batch [540]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.236100,	
2017-06-24 12:06:40,571 Epoch[2] Batch [550]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.235577,	
2017-06-24 12:06:47,962 Epoch[2] Batch [560]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.235830,	
2017-06-24 12:06:55,315 Epoch[2] Batch [570]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.235534,	
2017-06-24 12:07:02,870 Epoch[2] Batch [580]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.235540,	
2017-06-24 12:07:10,121 Epoch[2] Batch [590]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.235489,	
2017-06-24 12:07:17,320 Epoch[2] Batch [600]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.235708,	
2017-06-24 12:07:24,760 Epoch[2] Batch [610]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.235903,	
2017-06-24 12:07:32,239 Epoch[2] Batch [620]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.235480,	
2017-06-24 12:07:39,286 Epoch[2] Batch [630]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.234973,	
2017-06-24 12:07:46,647 Epoch[2] Batch [640]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.234438,	
2017-06-24 12:07:53,925 Epoch[2] Batch [650]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.234162,	
2017-06-24 12:08:01,049 Epoch[2] Batch [660]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.234190,	
2017-06-24 12:08:08,459 Epoch[2] Batch [670]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.233853,	
2017-06-24 12:08:15,851 Epoch[2] Batch [680]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.233534,	
2017-06-24 12:08:23,136 Epoch[2] Batch [690]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.233187,	
2017-06-24 12:08:30,364 Epoch[2] Batch [700]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.233114,	
2017-06-24 12:08:37,898 Epoch[2] Batch [710]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.232557,	
2017-06-24 12:08:48,423 Epoch[2] Batch [720]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.232442,	
2017-06-24 12:08:58,143 Epoch[2] Batch [730]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.232086,	
2017-06-24 12:09:05,819 Epoch[2] Batch [740]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.231975,	
2017-06-24 12:09:07,140 Epoch[2] Train-FCNLogLoss=0.231858
2017-06-24 12:09:07,141 Epoch[2] Time cost=709.983
2017-06-24 12:09:08,988 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0003.params"
2017-06-24 12:09:11,103 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0003.states"
2017-06-24 12:09:20,368 Epoch[3] Batch [10]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.217775,	
2017-06-24 12:09:28,012 Epoch[3] Batch [20]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.220180,	
2017-06-24 12:09:35,332 Epoch[3] Batch [30]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.220885,	
2017-06-24 12:09:43,231 Epoch[3] Batch [40]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.214764,	
2017-06-24 12:09:50,909 Epoch[3] Batch [50]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.214085,	
2017-06-24 12:09:58,374 Epoch[3] Batch [60]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.212782,	
2017-06-24 12:10:05,845 Epoch[3] Batch [70]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.211792,	
2017-06-24 12:10:13,133 Epoch[3] Batch [80]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.215096,	
2017-06-24 12:10:20,674 Epoch[3] Batch [90]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.218602,	
2017-06-24 12:10:28,397 Epoch[3] Batch [100]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.215376,	
2017-06-24 12:10:36,060 Epoch[3] Batch [110]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.214077,	
2017-06-24 12:10:43,632 Epoch[3] Batch [120]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.212645,	
2017-06-24 12:10:51,255 Epoch[3] Batch [130]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.210518,	
2017-06-24 12:10:58,894 Epoch[3] Batch [140]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.210417,	
2017-06-24 12:11:06,868 Epoch[3] Batch [150]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.209955,	
2017-06-24 12:11:14,736 Epoch[3] Batch [160]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.209035,	
2017-06-24 12:11:22,223 Epoch[3] Batch [170]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.209294,	
2017-06-24 12:11:29,535 Epoch[3] Batch [180]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.210219,	
2017-06-24 12:11:37,182 Epoch[3] Batch [190]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.211246,	
2017-06-24 12:11:44,697 Epoch[3] Batch [200]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.210440,	
2017-06-24 12:11:52,496 Epoch[3] Batch [210]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.210559,	
2017-06-24 12:12:00,079 Epoch[3] Batch [220]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.210314,	
2017-06-24 12:12:07,813 Epoch[3] Batch [230]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.211563,	
2017-06-24 12:12:15,136 Epoch[3] Batch [240]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.212464,	
2017-06-24 12:12:22,284 Epoch[3] Batch [250]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.213999,	
2017-06-24 12:12:29,592 Epoch[3] Batch [260]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.213195,	
2017-06-24 12:12:37,228 Epoch[3] Batch [270]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.212285,	
2017-06-24 12:12:44,415 Epoch[3] Batch [280]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.212299,	
2017-06-24 12:12:51,697 Epoch[3] Batch [290]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.212015,	
2017-06-24 12:12:59,418 Epoch[3] Batch [300]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.211064,	
2017-06-24 12:13:07,008 Epoch[3] Batch [310]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.210342,	
2017-06-24 12:13:14,529 Epoch[3] Batch [320]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.209171,	
2017-06-24 12:13:22,200 Epoch[3] Batch [330]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.208237,	
2017-06-24 12:13:29,763 Epoch[3] Batch [340]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.207493,	
2017-06-24 12:13:36,920 Epoch[3] Batch [350]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.206870,	
2017-06-24 12:13:45,456 Epoch[3] Batch [360]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.206994,	
2017-06-24 12:13:53,000 Epoch[3] Batch [370]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.207417,	
2017-06-24 12:14:00,332 Epoch[3] Batch [380]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.207290,	
2017-06-24 12:14:07,877 Epoch[3] Batch [390]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.206920,	
2017-06-24 12:14:15,387 Epoch[3] Batch [400]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.206604,	
2017-06-24 12:14:22,998 Epoch[3] Batch [410]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.206009,	
2017-06-24 12:14:30,258 Epoch[3] Batch [420]	Speed: 11.02 samples/sec	Train-FCNLogLoss=0.205474,	
2017-06-24 12:14:37,314 Epoch[3] Batch [430]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.205667,	
2017-06-24 12:14:44,796 Epoch[3] Batch [440]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.205248,	
2017-06-24 12:14:52,093 Epoch[3] Batch [450]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.205077,	
2017-06-24 12:14:59,447 Epoch[3] Batch [460]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.205039,	
2017-06-24 12:15:06,531 Epoch[3] Batch [470]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.205220,	
2017-06-24 12:15:13,828 Epoch[3] Batch [480]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.204645,	
2017-06-24 12:15:21,459 Epoch[3] Batch [490]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.204490,	
2017-06-24 12:15:28,628 Epoch[3] Batch [500]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.203977,	
2017-06-24 12:15:35,785 Epoch[3] Batch [510]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.203636,	
2017-06-24 12:15:43,102 Epoch[3] Batch [520]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.203271,	
2017-06-24 12:15:50,474 Epoch[3] Batch [530]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.202797,	
2017-06-24 12:15:57,656 Epoch[3] Batch [540]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.202578,	
2017-06-24 12:16:04,804 Epoch[3] Batch [550]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.202592,	
2017-06-24 12:16:12,446 Epoch[3] Batch [560]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.202496,	
2017-06-24 12:16:20,061 Epoch[3] Batch [570]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.202362,	
2017-06-24 12:16:27,531 Epoch[3] Batch [580]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.202110,	
2017-06-24 12:16:35,066 Epoch[3] Batch [590]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.201705,	
2017-06-24 12:16:42,344 Epoch[3] Batch [600]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.201624,	
2017-06-24 12:16:49,173 Epoch[3] Batch [610]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.201494,	
2017-06-24 12:16:56,506 Epoch[3] Batch [620]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.201149,	
2017-06-24 12:17:03,917 Epoch[3] Batch [630]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.200920,	
2017-06-24 12:17:11,316 Epoch[3] Batch [640]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.200915,	
2017-06-24 12:17:18,706 Epoch[3] Batch [650]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.200884,	
2017-06-24 12:17:25,942 Epoch[3] Batch [660]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.200843,	
2017-06-24 12:17:33,027 Epoch[3] Batch [670]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.200355,	
2017-06-24 12:17:40,475 Epoch[3] Batch [680]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.200703,	
2017-06-24 12:17:49,832 Epoch[3] Batch [690]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.200165,	
2017-06-24 12:18:00,531 Epoch[3] Batch [700]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.199997,	
2017-06-24 12:18:09,247 Epoch[3] Batch [710]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.199968,	
2017-06-24 12:18:17,166 Epoch[3] Batch [720]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.199499,	
2017-06-24 12:18:24,463 Epoch[3] Batch [730]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.199092,	
2017-06-24 12:18:31,728 Epoch[3] Batch [740]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.198730,	
2017-06-24 12:18:33,162 Epoch[3] Train-FCNLogLoss=0.198681
2017-06-24 12:18:33,162 Epoch[3] Time cost=562.057
2017-06-24 12:18:34,771 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0004.params"
2017-06-24 12:18:36,921 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0004.states"
2017-06-24 12:18:45,811 Epoch[4] Batch [10]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.195001,	
2017-06-24 12:18:52,885 Epoch[4] Batch [20]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.187781,	
2017-06-24 12:19:00,125 Epoch[4] Batch [30]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.186247,	
2017-06-24 12:19:07,772 Epoch[4] Batch [40]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.188577,	
2017-06-24 12:19:15,349 Epoch[4] Batch [50]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.188797,	
2017-06-24 12:19:22,801 Epoch[4] Batch [60]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.189655,	
2017-06-24 12:19:30,364 Epoch[4] Batch [70]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.188911,	
2017-06-24 12:19:38,086 Epoch[4] Batch [80]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.187640,	
2017-06-24 12:19:45,401 Epoch[4] Batch [90]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.190954,	
2017-06-24 12:19:52,645 Epoch[4] Batch [100]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.192455,	
2017-06-24 12:19:59,955 Epoch[4] Batch [110]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.192633,	
2017-06-24 12:20:07,275 Epoch[4] Batch [120]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.193315,	
2017-06-24 12:20:14,522 Epoch[4] Batch [130]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.192552,	
2017-06-24 12:20:21,602 Epoch[4] Batch [140]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.192263,	
2017-06-24 12:20:28,906 Epoch[4] Batch [150]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.192995,	
2017-06-24 12:20:36,559 Epoch[4] Batch [160]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.193173,	
2017-06-24 12:20:44,182 Epoch[4] Batch [170]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.192336,	
2017-06-24 12:20:51,619 Epoch[4] Batch [180]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.191756,	
2017-06-24 12:20:58,985 Epoch[4] Batch [190]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.191943,	
2017-06-24 12:21:06,083 Epoch[4] Batch [200]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.194120,	
2017-06-24 12:21:13,671 Epoch[4] Batch [210]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.193154,	
2017-06-24 12:21:20,949 Epoch[4] Batch [220]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.192619,	
2017-06-24 12:21:28,159 Epoch[4] Batch [230]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.191590,	
2017-06-24 12:21:35,292 Epoch[4] Batch [240]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.191132,	
2017-06-24 12:21:42,577 Epoch[4] Batch [250]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.190166,	
2017-06-24 12:21:49,621 Epoch[4] Batch [260]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.189578,	
2017-06-24 12:21:56,891 Epoch[4] Batch [270]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.189886,	
2017-06-24 12:22:04,352 Epoch[4] Batch [280]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.189299,	
2017-06-24 12:22:11,408 Epoch[4] Batch [290]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.188540,	
2017-06-24 12:22:18,783 Epoch[4] Batch [300]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.188127,	
2017-06-24 12:22:26,151 Epoch[4] Batch [310]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.187405,	
2017-06-24 12:22:33,058 Epoch[4] Batch [320]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.187815,	
2017-06-24 12:22:40,365 Epoch[4] Batch [330]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.187647,	
2017-06-24 12:22:49,462 Epoch[4] Batch [340]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.187484,	
2017-06-24 12:22:56,797 Epoch[4] Batch [350]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.186865,	
2017-06-24 12:23:04,112 Epoch[4] Batch [360]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.187331,	
2017-06-24 12:23:11,011 Epoch[4] Batch [370]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.186834,	
2017-06-24 12:23:18,662 Epoch[4] Batch [380]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.186631,	
2017-06-24 12:23:26,202 Epoch[4] Batch [390]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.186349,	
2017-06-24 12:23:34,113 Epoch[4] Batch [400]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.186325,	
2017-06-24 12:23:41,448 Epoch[4] Batch [410]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.185875,	
2017-06-24 12:23:48,848 Epoch[4] Batch [420]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.185671,	
2017-06-24 12:23:56,127 Epoch[4] Batch [430]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.185590,	
2017-06-24 12:24:03,469 Epoch[4] Batch [440]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.184944,	
2017-06-24 12:24:10,676 Epoch[4] Batch [450]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.185062,	
2017-06-24 12:24:17,902 Epoch[4] Batch [460]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.184928,	
2017-06-24 12:24:25,180 Epoch[4] Batch [470]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.184747,	
2017-06-24 12:24:32,696 Epoch[4] Batch [480]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.184681,	
2017-06-24 12:24:40,162 Epoch[4] Batch [490]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.184207,	
2017-06-24 12:24:47,879 Epoch[4] Batch [500]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.183749,	
2017-06-24 12:24:55,286 Epoch[4] Batch [510]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.183476,	
2017-06-24 12:25:02,505 Epoch[4] Batch [520]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.183367,	
2017-06-24 12:25:09,576 Epoch[4] Batch [530]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.183121,	
2017-06-24 12:25:16,980 Epoch[4] Batch [540]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.183359,	
2017-06-24 12:25:24,358 Epoch[4] Batch [550]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.184111,	
2017-06-24 12:25:32,023 Epoch[4] Batch [560]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.184112,	
2017-06-24 12:25:38,970 Epoch[4] Batch [570]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.184707,	
2017-06-24 12:25:46,377 Epoch[4] Batch [580]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.185072,	
2017-06-24 12:25:53,738 Epoch[4] Batch [590]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.184883,	
2017-06-24 12:26:00,837 Epoch[4] Batch [600]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.184787,	
2017-06-24 12:26:07,922 Epoch[4] Batch [610]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.184356,	
2017-06-24 12:26:15,058 Epoch[4] Batch [620]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.183930,	
2017-06-24 12:26:22,536 Epoch[4] Batch [630]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.184255,	
2017-06-24 12:26:30,127 Epoch[4] Batch [640]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.184267,	
2017-06-24 12:26:37,103 Epoch[4] Batch [650]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.185076,	
2017-06-24 12:26:44,339 Epoch[4] Batch [660]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.185167,	
2017-06-24 12:26:51,572 Epoch[4] Batch [670]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.185219,	
2017-06-24 12:26:58,640 Epoch[4] Batch [680]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.184966,	
2017-06-24 12:27:05,853 Epoch[4] Batch [690]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.184838,	
2017-06-24 12:27:16,280 Epoch[4] Batch [700]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.184936,	
2017-06-24 12:27:26,002 Epoch[4] Batch [710]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.184853,	
2017-06-24 12:27:33,199 Epoch[4] Batch [720]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.184369,	
2017-06-24 12:27:40,706 Epoch[4] Batch [730]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.184107,	
2017-06-24 12:27:47,793 Epoch[4] Batch [740]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.183965,	
2017-06-24 12:27:49,119 Epoch[4] Train-FCNLogLoss=0.183900
2017-06-24 12:27:49,119 Epoch[4] Time cost=552.198
2017-06-24 12:27:51,203 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0005.params"
2017-06-24 12:27:53,184 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0005.states"
2017-06-24 12:28:02,144 Epoch[5] Batch [10]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.182275,	
2017-06-24 12:28:09,926 Epoch[5] Batch [20]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.178491,	
2017-06-24 12:28:17,470 Epoch[5] Batch [30]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.175666,	
2017-06-24 12:28:24,960 Epoch[5] Batch [40]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.171075,	
2017-06-24 12:28:32,484 Epoch[5] Batch [50]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.170510,	
2017-06-24 12:28:39,859 Epoch[5] Batch [60]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.169022,	
2017-06-24 12:28:47,162 Epoch[5] Batch [70]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.167951,	
2017-06-24 12:28:54,701 Epoch[5] Batch [80]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.168360,	
2017-06-24 12:29:02,018 Epoch[5] Batch [90]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.166756,	
2017-06-24 12:29:09,182 Epoch[5] Batch [100]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.165593,	
2017-06-24 12:29:16,477 Epoch[5] Batch [110]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.164723,	
2017-06-24 12:29:24,027 Epoch[5] Batch [120]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.165347,	
2017-06-24 12:29:31,729 Epoch[5] Batch [130]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.165265,	
2017-06-24 12:29:39,215 Epoch[5] Batch [140]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.165475,	
2017-06-24 12:29:46,233 Epoch[5] Batch [150]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.168658,	
2017-06-24 12:29:53,760 Epoch[5] Batch [160]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.170261,	
2017-06-24 12:30:01,263 Epoch[5] Batch [170]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.170684,	
2017-06-24 12:30:08,700 Epoch[5] Batch [180]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.170794,	
2017-06-24 12:30:16,187 Epoch[5] Batch [190]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.169525,	
2017-06-24 12:30:23,851 Epoch[5] Batch [200]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.169848,	
2017-06-24 12:30:31,421 Epoch[5] Batch [210]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.169360,	
2017-06-24 12:30:38,656 Epoch[5] Batch [220]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.168796,	
2017-06-24 12:30:45,804 Epoch[5] Batch [230]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.168433,	
2017-06-24 12:30:53,257 Epoch[5] Batch [240]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.168968,	
2017-06-24 12:31:00,387 Epoch[5] Batch [250]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.168382,	
2017-06-24 12:31:07,704 Epoch[5] Batch [260]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.168483,	
2017-06-24 12:31:15,029 Epoch[5] Batch [270]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.169372,	
2017-06-24 12:31:22,198 Epoch[5] Batch [280]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.169201,	
2017-06-24 12:31:29,450 Epoch[5] Batch [290]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.170000,	
2017-06-24 12:31:37,013 Epoch[5] Batch [300]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.170357,	
2017-06-24 12:31:44,467 Epoch[5] Batch [310]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.169986,	
2017-06-24 12:31:52,380 Epoch[5] Batch [320]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.170062,	
2017-06-24 12:32:00,632 Epoch[5] Batch [330]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.169769,	
2017-06-24 12:32:07,673 Epoch[5] Batch [340]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.169715,	
2017-06-24 12:32:14,734 Epoch[5] Batch [350]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.169626,	
2017-06-24 12:32:21,359 Epoch[5] Batch [360]	Speed: 12.08 samples/sec	Train-FCNLogLoss=0.169669,	
2017-06-24 12:32:28,291 Epoch[5] Batch [370]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.169953,	
2017-06-24 12:32:34,992 Epoch[5] Batch [380]	Speed: 11.94 samples/sec	Train-FCNLogLoss=0.170147,	
2017-06-24 12:32:42,006 Epoch[5] Batch [390]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.170256,	
2017-06-24 12:32:48,746 Epoch[5] Batch [400]	Speed: 11.87 samples/sec	Train-FCNLogLoss=0.170602,	
2017-06-24 12:32:55,764 Epoch[5] Batch [410]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.170750,	
2017-06-24 12:33:02,533 Epoch[5] Batch [420]	Speed: 11.82 samples/sec	Train-FCNLogLoss=0.170927,	
2017-06-24 12:33:09,616 Epoch[5] Batch [430]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.171310,	
2017-06-24 12:33:16,646 Epoch[5] Batch [440]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.171624,	
2017-06-24 12:33:23,651 Epoch[5] Batch [450]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.172134,	
2017-06-24 12:33:30,738 Epoch[5] Batch [460]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.172397,	
2017-06-24 12:33:37,812 Epoch[5] Batch [470]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.172638,	
2017-06-24 12:33:44,476 Epoch[5] Batch [480]	Speed: 12.01 samples/sec	Train-FCNLogLoss=0.172932,	
2017-06-24 12:33:51,760 Epoch[5] Batch [490]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.172827,	
2017-06-24 12:33:58,399 Epoch[5] Batch [500]	Speed: 12.05 samples/sec	Train-FCNLogLoss=0.172441,	
2017-06-24 12:34:05,274 Epoch[5] Batch [510]	Speed: 11.64 samples/sec	Train-FCNLogLoss=0.172192,	
2017-06-24 12:34:12,258 Epoch[5] Batch [520]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.172635,	
2017-06-24 12:34:19,041 Epoch[5] Batch [530]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.172778,	
2017-06-24 12:34:26,178 Epoch[5] Batch [540]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.172372,	
2017-06-24 12:34:33,041 Epoch[5] Batch [550]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.172303,	
2017-06-24 12:34:39,873 Epoch[5] Batch [560]	Speed: 11.71 samples/sec	Train-FCNLogLoss=0.172157,	
2017-06-24 12:34:47,165 Epoch[5] Batch [570]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.171980,	
2017-06-24 12:34:54,188 Epoch[5] Batch [580]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.171622,	
2017-06-24 12:35:01,191 Epoch[5] Batch [590]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.171429,	
2017-06-24 12:35:07,845 Epoch[5] Batch [600]	Speed: 12.02 samples/sec	Train-FCNLogLoss=0.171291,	
2017-06-24 12:35:15,015 Epoch[5] Batch [610]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.171215,	
2017-06-24 12:35:21,736 Epoch[5] Batch [620]	Speed: 11.90 samples/sec	Train-FCNLogLoss=0.171083,	
2017-06-24 12:35:28,557 Epoch[5] Batch [630]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.170846,	
2017-06-24 12:35:35,434 Epoch[5] Batch [640]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.170895,	
2017-06-24 12:35:42,202 Epoch[5] Batch [650]	Speed: 11.82 samples/sec	Train-FCNLogLoss=0.170526,	
2017-06-24 12:35:49,096 Epoch[5] Batch [660]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.170274,	
2017-06-24 12:35:56,087 Epoch[5] Batch [670]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.170025,	
2017-06-24 12:36:02,834 Epoch[5] Batch [680]	Speed: 11.86 samples/sec	Train-FCNLogLoss=0.170053,	
2017-06-24 12:36:09,798 Epoch[5] Batch [690]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.169961,	
2017-06-24 12:36:16,841 Epoch[5] Batch [700]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.169843,	
2017-06-24 12:36:23,606 Epoch[5] Batch [710]	Speed: 11.83 samples/sec	Train-FCNLogLoss=0.169598,	
2017-06-24 12:36:30,662 Epoch[5] Batch [720]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.169544,	
2017-06-24 12:36:37,627 Epoch[5] Batch [730]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.169524,	
2017-06-24 12:36:44,509 Epoch[5] Batch [740]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.169392,	
2017-06-24 12:36:45,745 Epoch[5] Train-FCNLogLoss=0.169470
2017-06-24 12:36:45,745 Epoch[5] Time cost=532.561
2017-06-24 12:36:47,348 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0006.params"
2017-06-24 12:36:49,441 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0006.states"
2017-06-24 12:37:02,704 Epoch[6] Batch [10]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.173824,	
2017-06-24 12:37:10,632 Epoch[6] Batch [20]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.161737,	
2017-06-24 12:37:17,778 Epoch[6] Batch [30]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.160401,	
2017-06-24 12:37:24,885 Epoch[6] Batch [40]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.159128,	
2017-06-24 12:37:31,917 Epoch[6] Batch [50]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.159966,	
2017-06-24 12:37:38,765 Epoch[6] Batch [60]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.160602,	
2017-06-24 12:37:45,632 Epoch[6] Batch [70]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.158362,	
2017-06-24 12:37:52,426 Epoch[6] Batch [80]	Speed: 11.78 samples/sec	Train-FCNLogLoss=0.159464,	
2017-06-24 12:37:59,464 Epoch[6] Batch [90]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.159302,	
2017-06-24 12:38:06,376 Epoch[6] Batch [100]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.159075,	
2017-06-24 12:38:13,312 Epoch[6] Batch [110]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.159787,	
2017-06-24 12:38:20,276 Epoch[6] Batch [120]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.160220,	
2017-06-24 12:38:27,404 Epoch[6] Batch [130]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.160360,	
2017-06-24 12:38:34,750 Epoch[6] Batch [140]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.159691,	
2017-06-24 12:38:41,372 Epoch[6] Batch [150]	Speed: 12.08 samples/sec	Train-FCNLogLoss=0.159357,	
2017-06-24 12:38:48,711 Epoch[6] Batch [160]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.160581,	
2017-06-24 12:38:55,816 Epoch[6] Batch [170]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.160364,	
2017-06-24 12:39:02,961 Epoch[6] Batch [180]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.160805,	
2017-06-24 12:39:10,173 Epoch[6] Batch [190]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.160774,	
2017-06-24 12:39:16,968 Epoch[6] Batch [200]	Speed: 11.77 samples/sec	Train-FCNLogLoss=0.160407,	
2017-06-24 12:39:23,751 Epoch[6] Batch [210]	Speed: 11.79 samples/sec	Train-FCNLogLoss=0.160224,	
2017-06-24 12:39:30,721 Epoch[6] Batch [220]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.160692,	
2017-06-24 12:39:37,741 Epoch[6] Batch [230]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.160639,	
2017-06-24 12:39:44,637 Epoch[6] Batch [240]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.161099,	
2017-06-24 12:39:51,522 Epoch[6] Batch [250]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.160834,	
2017-06-24 12:39:58,445 Epoch[6] Batch [260]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.161271,	
2017-06-24 12:40:05,439 Epoch[6] Batch [270]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.161369,	
2017-06-24 12:40:12,767 Epoch[6] Batch [280]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.161136,	
2017-06-24 12:40:19,832 Epoch[6] Batch [290]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.161486,	
2017-06-24 12:40:26,802 Epoch[6] Batch [300]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.161691,	
2017-06-24 12:40:33,578 Epoch[6] Batch [310]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.161824,	
2017-06-24 12:40:40,678 Epoch[6] Batch [320]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.161545,	
2017-06-24 12:40:47,448 Epoch[6] Batch [330]	Speed: 11.82 samples/sec	Train-FCNLogLoss=0.161618,	
2017-06-24 12:40:54,381 Epoch[6] Batch [340]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.161619,	
2017-06-24 12:41:01,710 Epoch[6] Batch [350]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.161372,	
2017-06-24 12:41:08,381 Epoch[6] Batch [360]	Speed: 11.99 samples/sec	Train-FCNLogLoss=0.161383,	
2017-06-24 12:41:15,237 Epoch[6] Batch [370]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.161058,	
2017-06-24 12:41:22,329 Epoch[6] Batch [380]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.160851,	
2017-06-24 12:41:29,028 Epoch[6] Batch [390]	Speed: 11.94 samples/sec	Train-FCNLogLoss=0.160376,	
2017-06-24 12:41:36,005 Epoch[6] Batch [400]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.160049,	
2017-06-24 12:41:42,832 Epoch[6] Batch [410]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.160507,	
2017-06-24 12:41:49,814 Epoch[6] Batch [420]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.160436,	
2017-06-24 12:41:56,661 Epoch[6] Batch [430]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.160312,	
2017-06-24 12:42:03,648 Epoch[6] Batch [440]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.160350,	
2017-06-24 12:42:10,883 Epoch[6] Batch [450]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.160590,	
2017-06-24 12:42:17,697 Epoch[6] Batch [460]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.160456,	
2017-06-24 12:42:24,533 Epoch[6] Batch [470]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.160127,	
2017-06-24 12:42:31,575 Epoch[6] Batch [480]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.159897,	
2017-06-24 12:42:38,635 Epoch[6] Batch [490]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.159440,	
2017-06-24 12:42:45,412 Epoch[6] Batch [500]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.159125,	
2017-06-24 12:42:52,311 Epoch[6] Batch [510]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.158866,	
2017-06-24 12:42:59,455 Epoch[6] Batch [520]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.158854,	
2017-06-24 12:43:06,644 Epoch[6] Batch [530]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.158848,	
2017-06-24 12:43:13,511 Epoch[6] Batch [540]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.158795,	
2017-06-24 12:43:20,418 Epoch[6] Batch [550]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.159020,	
2017-06-24 12:43:27,631 Epoch[6] Batch [560]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.159380,	
2017-06-24 12:43:34,680 Epoch[6] Batch [570]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.159775,	
2017-06-24 12:43:41,588 Epoch[6] Batch [580]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.160062,	
2017-06-24 12:43:48,820 Epoch[6] Batch [590]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.160247,	
2017-06-24 12:43:55,887 Epoch[6] Batch [600]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.160284,	
2017-06-24 12:44:02,754 Epoch[6] Batch [610]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.160085,	
2017-06-24 12:44:09,709 Epoch[6] Batch [620]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.160090,	
2017-06-24 12:44:16,629 Epoch[6] Batch [630]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.160202,	
2017-06-24 12:44:23,473 Epoch[6] Batch [640]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.160080,	
2017-06-24 12:44:30,260 Epoch[6] Batch [650]	Speed: 11.79 samples/sec	Train-FCNLogLoss=0.159853,	
2017-06-24 12:44:37,272 Epoch[6] Batch [660]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.159642,	
2017-06-24 12:44:43,945 Epoch[6] Batch [670]	Speed: 11.99 samples/sec	Train-FCNLogLoss=0.159476,	
2017-06-24 12:44:51,070 Epoch[6] Batch [680]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.159528,	
2017-06-24 12:44:58,229 Epoch[6] Batch [690]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.159439,	
2017-06-24 12:45:05,002 Epoch[6] Batch [700]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.159240,	
2017-06-24 12:45:12,004 Epoch[6] Batch [710]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.159178,	
2017-06-24 12:45:19,106 Epoch[6] Batch [720]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.159373,	
2017-06-24 12:45:26,219 Epoch[6] Batch [730]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.159604,	
2017-06-24 12:45:33,043 Epoch[6] Batch [740]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.159810,	
2017-06-24 12:45:34,293 Epoch[6] Train-FCNLogLoss=0.159859
2017-06-24 12:45:34,293 Epoch[6] Time cost=524.852
2017-06-24 12:45:35,796 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0007.params"
2017-06-24 12:45:37,640 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0007.states"
2017-06-24 12:45:45,790 Epoch[7] Batch [10]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.167832,	
2017-06-24 12:45:52,754 Epoch[7] Batch [20]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.159686,	
2017-06-24 12:45:59,847 Epoch[7] Batch [30]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.156816,	
2017-06-24 12:46:06,737 Epoch[7] Batch [40]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.156503,	
2017-06-24 12:46:13,648 Epoch[7] Batch [50]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.156469,	
2017-06-24 12:46:20,585 Epoch[7] Batch [60]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.156090,	
2017-06-24 12:46:27,327 Epoch[7] Batch [70]	Speed: 11.87 samples/sec	Train-FCNLogLoss=0.156091,	
2017-06-24 12:46:34,228 Epoch[7] Batch [80]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.155504,	
2017-06-24 12:46:40,961 Epoch[7] Batch [90]	Speed: 11.88 samples/sec	Train-FCNLogLoss=0.155655,	
2017-06-24 12:46:47,825 Epoch[7] Batch [100]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.158561,	
2017-06-24 12:46:54,661 Epoch[7] Batch [110]	Speed: 11.71 samples/sec	Train-FCNLogLoss=0.157813,	
2017-06-24 12:47:01,705 Epoch[7] Batch [120]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.158322,	
2017-06-24 12:47:11,949 Epoch[7] Batch [130]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.157290,	
2017-06-24 12:47:21,623 Epoch[7] Batch [140]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.157868,	
2017-06-24 12:47:28,624 Epoch[7] Batch [150]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.156955,	
2017-06-24 12:47:35,526 Epoch[7] Batch [160]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.155357,	
2017-06-24 12:47:42,504 Epoch[7] Batch [170]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.154592,	
2017-06-24 12:47:49,866 Epoch[7] Batch [180]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.154820,	
2017-06-24 12:47:56,924 Epoch[7] Batch [190]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.155120,	
2017-06-24 12:48:03,759 Epoch[7] Batch [200]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.154672,	
2017-06-24 12:48:10,925 Epoch[7] Batch [210]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.154746,	
2017-06-24 12:48:17,868 Epoch[7] Batch [220]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.154937,	
2017-06-24 12:48:24,790 Epoch[7] Batch [230]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.155242,	
2017-06-24 12:48:31,957 Epoch[7] Batch [240]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.155011,	
2017-06-24 12:48:39,010 Epoch[7] Batch [250]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.154831,	
2017-06-24 12:48:45,875 Epoch[7] Batch [260]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.154588,	
2017-06-24 12:48:52,848 Epoch[7] Batch [270]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.154126,	
2017-06-24 12:48:59,807 Epoch[7] Batch [280]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.153395,	
2017-06-24 12:49:06,826 Epoch[7] Batch [290]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.153425,	
2017-06-24 12:49:13,874 Epoch[7] Batch [300]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.153627,	
2017-06-24 12:49:20,992 Epoch[7] Batch [310]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.154044,	
2017-06-24 12:49:27,883 Epoch[7] Batch [320]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.154209,	
2017-06-24 12:49:34,843 Epoch[7] Batch [330]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.153909,	
2017-06-24 12:49:41,667 Epoch[7] Batch [340]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.154422,	
2017-06-24 12:49:48,478 Epoch[7] Batch [350]	Speed: 11.75 samples/sec	Train-FCNLogLoss=0.154756,	
2017-06-24 12:49:55,724 Epoch[7] Batch [360]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.154730,	
2017-06-24 12:50:02,378 Epoch[7] Batch [370]	Speed: 12.02 samples/sec	Train-FCNLogLoss=0.154843,	
2017-06-24 12:50:09,324 Epoch[7] Batch [380]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.155054,	
2017-06-24 12:50:16,129 Epoch[7] Batch [390]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.154908,	
2017-06-24 12:50:23,196 Epoch[7] Batch [400]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.154714,	
2017-06-24 12:50:29,938 Epoch[7] Batch [410]	Speed: 11.87 samples/sec	Train-FCNLogLoss=0.155048,	
2017-06-24 12:50:36,933 Epoch[7] Batch [420]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.155343,	
2017-06-24 12:50:43,797 Epoch[7] Batch [430]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.155946,	
2017-06-24 12:50:50,938 Epoch[7] Batch [440]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.156682,	
2017-06-24 12:50:57,863 Epoch[7] Batch [450]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.157047,	
2017-06-24 12:51:04,687 Epoch[7] Batch [460]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.157121,	
2017-06-24 12:51:11,528 Epoch[7] Batch [470]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.156745,	
2017-06-24 12:51:18,494 Epoch[7] Batch [480]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.156845,	
2017-06-24 12:51:25,330 Epoch[7] Batch [490]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.156885,	
2017-06-24 12:51:32,518 Epoch[7] Batch [500]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.156767,	
2017-06-24 12:51:39,413 Epoch[7] Batch [510]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.156469,	
2017-06-24 12:51:46,518 Epoch[7] Batch [520]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.156222,	
2017-06-24 12:51:53,480 Epoch[7] Batch [530]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.156042,	
2017-06-24 12:52:00,282 Epoch[7] Batch [540]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.155575,	
2017-06-24 12:52:07,359 Epoch[7] Batch [550]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.155454,	
2017-06-24 12:52:14,164 Epoch[7] Batch [560]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.155310,	
2017-06-24 12:52:21,122 Epoch[7] Batch [570]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.155225,	
2017-06-24 12:52:28,057 Epoch[7] Batch [580]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.155124,	
2017-06-24 12:52:34,889 Epoch[7] Batch [590]	Speed: 11.71 samples/sec	Train-FCNLogLoss=0.155046,	
2017-06-24 12:52:41,884 Epoch[7] Batch [600]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.155427,	
2017-06-24 12:52:48,887 Epoch[7] Batch [610]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.155581,	
2017-06-24 12:52:55,689 Epoch[7] Batch [620]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.156058,	
2017-06-24 12:53:02,449 Epoch[7] Batch [630]	Speed: 11.83 samples/sec	Train-FCNLogLoss=0.156165,	
2017-06-24 12:53:09,436 Epoch[7] Batch [640]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.156374,	
2017-06-24 12:53:16,383 Epoch[7] Batch [650]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.156697,	
2017-06-24 12:53:23,319 Epoch[7] Batch [660]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.156629,	
2017-06-24 12:53:30,073 Epoch[7] Batch [670]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.156643,	
2017-06-24 12:53:37,205 Epoch[7] Batch [680]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.156747,	
2017-06-24 12:53:44,085 Epoch[7] Batch [690]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.156902,	
2017-06-24 12:53:50,959 Epoch[7] Batch [700]	Speed: 11.64 samples/sec	Train-FCNLogLoss=0.156699,	
2017-06-24 12:53:58,213 Epoch[7] Batch [710]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.156676,	
2017-06-24 12:54:05,442 Epoch[7] Batch [720]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.156568,	
2017-06-24 12:54:12,352 Epoch[7] Batch [730]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.156503,	
2017-06-24 12:54:19,420 Epoch[7] Batch [740]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.156476,	
2017-06-24 12:54:20,746 Epoch[7] Train-FCNLogLoss=0.156455
2017-06-24 12:54:20,746 Epoch[7] Time cost=523.105
2017-06-24 12:54:22,231 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0008.params"
2017-06-24 12:54:24,042 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0008.states"
2017-06-24 12:54:32,307 Epoch[8] Batch [10]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.160843,	
2017-06-24 12:54:39,113 Epoch[8] Batch [20]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.153348,	
2017-06-24 12:54:46,352 Epoch[8] Batch [30]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.153435,	
2017-06-24 12:54:53,231 Epoch[8] Batch [40]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.154867,	
2017-06-24 12:55:00,025 Epoch[8] Batch [50]	Speed: 11.78 samples/sec	Train-FCNLogLoss=0.154995,	
2017-06-24 12:55:07,060 Epoch[8] Batch [60]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.155318,	
2017-06-24 12:55:14,105 Epoch[8] Batch [70]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.153351,	
2017-06-24 12:55:21,062 Epoch[8] Batch [80]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.152119,	
2017-06-24 12:55:28,439 Epoch[8] Batch [90]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.151582,	
2017-06-24 12:55:35,162 Epoch[8] Batch [100]	Speed: 11.90 samples/sec	Train-FCNLogLoss=0.151074,	
2017-06-24 12:55:42,284 Epoch[8] Batch [110]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.150416,	
2017-06-24 12:55:49,140 Epoch[8] Batch [120]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.148990,	
2017-06-24 12:55:56,118 Epoch[8] Batch [130]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.149882,	
2017-06-24 12:56:03,063 Epoch[8] Batch [140]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.150353,	
2017-06-24 12:56:09,996 Epoch[8] Batch [150]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.150444,	
2017-06-24 12:56:17,012 Epoch[8] Batch [160]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.150100,	
2017-06-24 12:56:23,878 Epoch[8] Batch [170]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.149623,	
2017-06-24 12:56:31,085 Epoch[8] Batch [180]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.149631,	
2017-06-24 12:56:38,007 Epoch[8] Batch [190]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.149635,	
2017-06-24 12:56:44,899 Epoch[8] Batch [200]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.149970,	
2017-06-24 12:56:51,914 Epoch[8] Batch [210]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.150032,	
2017-06-24 12:56:58,634 Epoch[8] Batch [220]	Speed: 11.91 samples/sec	Train-FCNLogLoss=0.150136,	
2017-06-24 12:57:05,662 Epoch[8] Batch [230]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.149757,	
2017-06-24 12:57:12,391 Epoch[8] Batch [240]	Speed: 11.89 samples/sec	Train-FCNLogLoss=0.149988,	
2017-06-24 12:57:19,343 Epoch[8] Batch [250]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.149571,	
2017-06-24 12:57:28,186 Epoch[8] Batch [260]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.149938,	
2017-06-24 12:57:39,476 Epoch[8] Batch [270]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.150216,	
2017-06-24 12:57:46,008 Epoch[8] Batch [280]	Speed: 12.25 samples/sec	Train-FCNLogLoss=0.150000,	
2017-06-24 12:57:53,119 Epoch[8] Batch [290]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.150876,	
2017-06-24 12:58:00,009 Epoch[8] Batch [300]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.150964,	
2017-06-24 12:58:06,861 Epoch[8] Batch [310]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.150802,	
2017-06-24 12:58:13,798 Epoch[8] Batch [320]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.150581,	
2017-06-24 12:58:20,925 Epoch[8] Batch [330]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.150617,	
2017-06-24 12:58:28,143 Epoch[8] Batch [340]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.150564,	
2017-06-24 12:58:35,198 Epoch[8] Batch [350]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.150356,	
2017-06-24 12:58:42,384 Epoch[8] Batch [360]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.150231,	
2017-06-24 12:58:49,274 Epoch[8] Batch [370]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.149868,	
2017-06-24 12:58:56,321 Epoch[8] Batch [380]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.149673,	
2017-06-24 12:59:03,161 Epoch[8] Batch [390]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.149523,	
2017-06-24 12:59:10,095 Epoch[8] Batch [400]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.150034,	
2017-06-24 12:59:17,130 Epoch[8] Batch [410]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.149810,	
2017-06-24 12:59:24,531 Epoch[8] Batch [420]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.149613,	
2017-06-24 12:59:31,392 Epoch[8] Batch [430]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.149475,	
2017-06-24 12:59:38,292 Epoch[8] Batch [440]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.149840,	
2017-06-24 12:59:44,995 Epoch[8] Batch [450]	Speed: 11.94 samples/sec	Train-FCNLogLoss=0.149982,	
2017-06-24 12:59:51,855 Epoch[8] Batch [460]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.149582,	
2017-06-24 12:59:58,894 Epoch[8] Batch [470]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.149495,	
2017-06-24 13:00:05,882 Epoch[8] Batch [480]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.149418,	
2017-06-24 13:00:13,142 Epoch[8] Batch [490]	Speed: 11.02 samples/sec	Train-FCNLogLoss=0.149329,	
2017-06-24 13:00:20,276 Epoch[8] Batch [500]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.149817,	
2017-06-24 13:00:27,322 Epoch[8] Batch [510]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.149812,	
2017-06-24 13:00:34,125 Epoch[8] Batch [520]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.149690,	
2017-06-24 13:00:41,376 Epoch[8] Batch [530]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.149770,	
2017-06-24 13:00:48,260 Epoch[8] Batch [540]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.149497,	
2017-06-24 13:00:55,173 Epoch[8] Batch [550]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.149281,	
2017-06-24 13:01:02,371 Epoch[8] Batch [560]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.149160,	
2017-06-24 13:01:09,373 Epoch[8] Batch [570]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.149309,	
2017-06-24 13:01:16,091 Epoch[8] Batch [580]	Speed: 11.91 samples/sec	Train-FCNLogLoss=0.149207,	
2017-06-24 13:01:23,184 Epoch[8] Batch [590]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.149267,	
2017-06-24 13:01:30,019 Epoch[8] Batch [600]	Speed: 11.71 samples/sec	Train-FCNLogLoss=0.149375,	
2017-06-24 13:01:36,983 Epoch[8] Batch [610]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.149444,	
2017-06-24 13:01:44,049 Epoch[8] Batch [620]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.149112,	
2017-06-24 13:01:51,122 Epoch[8] Batch [630]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.148954,	
2017-06-24 13:01:58,110 Epoch[8] Batch [640]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.148830,	
2017-06-24 13:02:05,204 Epoch[8] Batch [650]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.148768,	
2017-06-24 13:02:12,181 Epoch[8] Batch [660]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.148816,	
2017-06-24 13:02:19,063 Epoch[8] Batch [670]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.149029,	
2017-06-24 13:02:26,228 Epoch[8] Batch [680]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.148905,	
2017-06-24 13:02:33,175 Epoch[8] Batch [690]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.148647,	
2017-06-24 13:02:40,092 Epoch[8] Batch [700]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.148621,	
2017-06-24 13:02:47,115 Epoch[8] Batch [710]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.148563,	
2017-06-24 13:02:53,798 Epoch[8] Batch [720]	Speed: 11.97 samples/sec	Train-FCNLogLoss=0.148261,	
2017-06-24 13:03:01,009 Epoch[8] Batch [730]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.148169,	
2017-06-24 13:03:07,981 Epoch[8] Batch [740]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.148006,	
2017-06-24 13:03:09,293 Epoch[8] Train-FCNLogLoss=0.147966
2017-06-24 13:03:09,293 Epoch[8] Time cost=525.250
2017-06-24 13:03:10,811 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0009.params"
2017-06-24 13:03:12,641 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0009.states"
2017-06-24 13:03:20,863 Epoch[9] Batch [10]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.139993,	
2017-06-24 13:03:27,957 Epoch[9] Batch [20]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.146468,	
2017-06-24 13:03:34,921 Epoch[9] Batch [30]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.147719,	
2017-06-24 13:03:41,831 Epoch[9] Batch [40]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.145682,	
2017-06-24 13:03:48,726 Epoch[9] Batch [50]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.142455,	
2017-06-24 13:03:55,915 Epoch[9] Batch [60]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.145106,	
2017-06-24 13:04:02,991 Epoch[9] Batch [70]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.146106,	
2017-06-24 13:04:10,170 Epoch[9] Batch [80]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.148198,	
2017-06-24 13:04:16,985 Epoch[9] Batch [90]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.147155,	
2017-06-24 13:04:24,038 Epoch[9] Batch [100]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.145984,	
2017-06-24 13:04:31,039 Epoch[9] Batch [110]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.145769,	
2017-06-24 13:04:37,960 Epoch[9] Batch [120]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.146028,	
2017-06-24 13:04:44,777 Epoch[9] Batch [130]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.145024,	
2017-06-24 13:04:51,781 Epoch[9] Batch [140]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.144940,	
2017-06-24 13:04:58,498 Epoch[9] Batch [150]	Speed: 11.91 samples/sec	Train-FCNLogLoss=0.143956,	
2017-06-24 13:05:05,646 Epoch[9] Batch [160]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.144170,	
2017-06-24 13:05:12,713 Epoch[9] Batch [170]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.144120,	
2017-06-24 13:05:19,791 Epoch[9] Batch [180]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.143912,	
2017-06-24 13:05:26,515 Epoch[9] Batch [190]	Speed: 11.90 samples/sec	Train-FCNLogLoss=0.144295,	
2017-06-24 13:05:33,465 Epoch[9] Batch [200]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.144082,	
2017-06-24 13:05:40,554 Epoch[9] Batch [210]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.143794,	
2017-06-24 13:05:47,302 Epoch[9] Batch [220]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.144286,	
2017-06-24 13:05:54,373 Epoch[9] Batch [230]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.143891,	
2017-06-24 13:06:01,240 Epoch[9] Batch [240]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.143239,	
2017-06-24 13:06:08,235 Epoch[9] Batch [250]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.143265,	
2017-06-24 13:06:15,279 Epoch[9] Batch [260]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.143048,	
2017-06-24 13:06:22,094 Epoch[9] Batch [270]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.143408,	
2017-06-24 13:06:29,050 Epoch[9] Batch [280]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.143252,	
2017-06-24 13:06:36,146 Epoch[9] Batch [290]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.143169,	
2017-06-24 13:06:43,420 Epoch[9] Batch [300]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.142928,	
2017-06-24 13:06:50,785 Epoch[9] Batch [310]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.143003,	
2017-06-24 13:06:57,824 Epoch[9] Batch [320]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.143136,	
2017-06-24 13:07:04,899 Epoch[9] Batch [330]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.143321,	
2017-06-24 13:07:11,841 Epoch[9] Batch [340]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.143431,	
2017-06-24 13:07:18,840 Epoch[9] Batch [350]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.143272,	
2017-06-24 13:07:25,874 Epoch[9] Batch [360]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.143249,	
2017-06-24 13:07:34,568 Epoch[9] Batch [370]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.143692,	
2017-06-24 13:07:46,045 Epoch[9] Batch [380]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.143569,	
2017-06-24 13:07:53,030 Epoch[9] Batch [390]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.144045,	
2017-06-24 13:08:00,021 Epoch[9] Batch [400]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.143819,	
2017-06-24 13:08:06,942 Epoch[9] Batch [410]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.143537,	
2017-06-24 13:08:13,983 Epoch[9] Batch [420]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.143345,	
2017-06-24 13:08:21,056 Epoch[9] Batch [430]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.143304,	
2017-06-24 13:08:27,898 Epoch[9] Batch [440]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.144104,	
2017-06-24 13:08:34,910 Epoch[9] Batch [450]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.144914,	
2017-06-24 13:08:41,691 Epoch[9] Batch [460]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.145119,	
2017-06-24 13:08:48,468 Epoch[9] Batch [470]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.145319,	
2017-06-24 13:08:55,290 Epoch[9] Batch [480]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.145319,	
2017-06-24 13:09:02,127 Epoch[9] Batch [490]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.145226,	
2017-06-24 13:09:09,035 Epoch[9] Batch [500]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.145219,	
2017-06-24 13:09:15,985 Epoch[9] Batch [510]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.145133,	
2017-06-24 13:09:23,020 Epoch[9] Batch [520]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.145036,	
2017-06-24 13:09:30,220 Epoch[9] Batch [530]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.144913,	
2017-06-24 13:09:37,046 Epoch[9] Batch [540]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.145114,	
2017-06-24 13:09:44,000 Epoch[9] Batch [550]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.144888,	
2017-06-24 13:09:51,015 Epoch[9] Batch [560]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.144732,	
2017-06-24 13:09:57,777 Epoch[9] Batch [570]	Speed: 11.83 samples/sec	Train-FCNLogLoss=0.144629,	
2017-06-24 13:10:04,625 Epoch[9] Batch [580]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.144355,	
2017-06-24 13:10:11,800 Epoch[9] Batch [590]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.144267,	
2017-06-24 13:10:18,585 Epoch[9] Batch [600]	Speed: 11.79 samples/sec	Train-FCNLogLoss=0.144409,	
2017-06-24 13:10:25,471 Epoch[9] Batch [610]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.144271,	
2017-06-24 13:10:32,570 Epoch[9] Batch [620]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.144530,	
2017-06-24 13:10:39,569 Epoch[9] Batch [630]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.144957,	
2017-06-24 13:10:46,330 Epoch[9] Batch [640]	Speed: 11.83 samples/sec	Train-FCNLogLoss=0.145008,	
2017-06-24 13:10:53,267 Epoch[9] Batch [650]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.144903,	
2017-06-24 13:11:00,407 Epoch[9] Batch [660]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.144870,	
2017-06-24 13:11:07,364 Epoch[9] Batch [670]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.144854,	
2017-06-24 13:11:14,272 Epoch[9] Batch [680]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.144955,	
2017-06-24 13:11:20,958 Epoch[9] Batch [690]	Speed: 11.97 samples/sec	Train-FCNLogLoss=0.144766,	
2017-06-24 13:11:27,909 Epoch[9] Batch [700]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.144688,	
2017-06-24 13:11:34,788 Epoch[9] Batch [710]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.144631,	
2017-06-24 13:11:41,598 Epoch[9] Batch [720]	Speed: 11.75 samples/sec	Train-FCNLogLoss=0.144597,	
2017-06-24 13:11:48,673 Epoch[9] Batch [730]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.144561,	
2017-06-24 13:11:55,659 Epoch[9] Batch [740]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.144583,	
2017-06-24 13:11:57,045 Epoch[9] Train-FCNLogLoss=0.144574
2017-06-24 13:11:57,045 Epoch[9] Time cost=524.403
2017-06-24 13:11:58,678 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0010.params"
2017-06-24 13:12:00,449 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0010.states"
2017-06-24 13:12:08,525 Epoch[10] Batch [10]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.138464,	
2017-06-24 13:12:15,448 Epoch[10] Batch [20]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.145885,	
2017-06-24 13:12:22,562 Epoch[10] Batch [30]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.143518,	
2017-06-24 13:12:29,865 Epoch[10] Batch [40]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.141083,	
2017-06-24 13:12:37,119 Epoch[10] Batch [50]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.140019,	
2017-06-24 13:12:44,012 Epoch[10] Batch [60]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.139377,	
2017-06-24 13:12:50,915 Epoch[10] Batch [70]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.138404,	
2017-06-24 13:12:58,089 Epoch[10] Batch [80]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.137597,	
2017-06-24 13:13:05,045 Epoch[10] Batch [90]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.137422,	
2017-06-24 13:13:11,782 Epoch[10] Batch [100]	Speed: 11.88 samples/sec	Train-FCNLogLoss=0.137365,	
2017-06-24 13:13:18,934 Epoch[10] Batch [110]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.136710,	
2017-06-24 13:13:26,021 Epoch[10] Batch [120]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.136628,	
2017-06-24 13:13:32,784 Epoch[10] Batch [130]	Speed: 11.83 samples/sec	Train-FCNLogLoss=0.137376,	
2017-06-24 13:13:39,771 Epoch[10] Batch [140]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.138170,	
2017-06-24 13:13:46,723 Epoch[10] Batch [150]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.139010,	
2017-06-24 13:13:53,451 Epoch[10] Batch [160]	Speed: 11.89 samples/sec	Train-FCNLogLoss=0.138536,	
2017-06-24 13:14:00,310 Epoch[10] Batch [170]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.138519,	
2017-06-24 13:14:07,383 Epoch[10] Batch [180]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.139049,	
2017-06-24 13:14:14,381 Epoch[10] Batch [190]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.138884,	
2017-06-24 13:14:21,511 Epoch[10] Batch [200]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.138675,	
2017-06-24 13:14:28,457 Epoch[10] Batch [210]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.138839,	
2017-06-24 13:14:35,457 Epoch[10] Batch [220]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.138862,	
2017-06-24 13:14:42,422 Epoch[10] Batch [230]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.139259,	
2017-06-24 13:14:49,509 Epoch[10] Batch [240]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.138991,	
2017-06-24 13:14:56,490 Epoch[10] Batch [250]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.138693,	
2017-06-24 13:15:03,269 Epoch[10] Batch [260]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.138649,	
2017-06-24 13:15:10,121 Epoch[10] Batch [270]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.138511,	
2017-06-24 13:15:16,977 Epoch[10] Batch [280]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.138362,	
2017-06-24 13:15:23,775 Epoch[10] Batch [290]	Speed: 11.77 samples/sec	Train-FCNLogLoss=0.137921,	
2017-06-24 13:15:30,779 Epoch[10] Batch [300]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.138125,	
2017-06-24 13:15:37,956 Epoch[10] Batch [310]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.137824,	
2017-06-24 13:15:44,996 Epoch[10] Batch [320]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.137475,	
2017-06-24 13:15:51,799 Epoch[10] Batch [330]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.137559,	
2017-06-24 13:15:58,819 Epoch[10] Batch [340]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.137478,	
2017-06-24 13:16:05,570 Epoch[10] Batch [350]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.137428,	
2017-06-24 13:16:12,484 Epoch[10] Batch [360]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.137305,	
2017-06-24 13:16:19,373 Epoch[10] Batch [370]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.137773,	
2017-06-24 13:16:26,412 Epoch[10] Batch [380]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.138490,	
2017-06-24 13:16:33,461 Epoch[10] Batch [390]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.139609,	
2017-06-24 13:16:40,230 Epoch[10] Batch [400]	Speed: 11.82 samples/sec	Train-FCNLogLoss=0.140595,	
2017-06-24 13:16:47,261 Epoch[10] Batch [410]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.141323,	
2017-06-24 13:16:54,397 Epoch[10] Batch [420]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.141576,	
2017-06-24 13:17:01,159 Epoch[10] Batch [430]	Speed: 11.83 samples/sec	Train-FCNLogLoss=0.141280,	
2017-06-24 13:17:08,145 Epoch[10] Batch [440]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.141099,	
2017-06-24 13:17:15,137 Epoch[10] Batch [450]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.141186,	
2017-06-24 13:17:22,049 Epoch[10] Batch [460]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.141033,	
2017-06-24 13:17:28,845 Epoch[10] Batch [470]	Speed: 11.77 samples/sec	Train-FCNLogLoss=0.140929,	
2017-06-24 13:17:35,840 Epoch[10] Batch [480]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.140734,	
2017-06-24 13:17:42,726 Epoch[10] Batch [490]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.140540,	
2017-06-24 13:17:50,361 Epoch[10] Batch [500]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.140560,	
2017-06-24 13:18:01,756 Epoch[10] Batch [510]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.140268,	
2017-06-24 13:18:09,938 Epoch[10] Batch [520]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.140087,	
2017-06-24 13:18:16,633 Epoch[10] Batch [530]	Speed: 11.95 samples/sec	Train-FCNLogLoss=0.140187,	
2017-06-24 13:18:23,416 Epoch[10] Batch [540]	Speed: 11.79 samples/sec	Train-FCNLogLoss=0.140035,	
2017-06-24 13:18:30,479 Epoch[10] Batch [550]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.140253,	
2017-06-24 13:18:37,809 Epoch[10] Batch [560]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.140120,	
2017-06-24 13:18:44,586 Epoch[10] Batch [570]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.139920,	
2017-06-24 13:18:51,407 Epoch[10] Batch [580]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.139820,	
2017-06-24 13:18:58,379 Epoch[10] Batch [590]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.139554,	
2017-06-24 13:19:05,549 Epoch[10] Batch [600]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.139472,	
2017-06-24 13:19:12,683 Epoch[10] Batch [610]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.139251,	
2017-06-24 13:19:19,627 Epoch[10] Batch [620]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.139249,	
2017-06-24 13:19:26,538 Epoch[10] Batch [630]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.139467,	
2017-06-24 13:19:33,789 Epoch[10] Batch [640]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.139427,	
2017-06-24 13:19:40,694 Epoch[10] Batch [650]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.139608,	
2017-06-24 13:19:47,609 Epoch[10] Batch [660]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.139605,	
2017-06-24 13:19:54,430 Epoch[10] Batch [670]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.139694,	
2017-06-24 13:20:01,550 Epoch[10] Batch [680]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.139638,	
2017-06-24 13:20:08,541 Epoch[10] Batch [690]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.139488,	
2017-06-24 13:20:15,370 Epoch[10] Batch [700]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.139269,	
2017-06-24 13:20:22,396 Epoch[10] Batch [710]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.139185,	
2017-06-24 13:20:29,244 Epoch[10] Batch [720]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.139072,	
2017-06-24 13:20:36,376 Epoch[10] Batch [730]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.138844,	
2017-06-24 13:20:43,503 Epoch[10] Batch [740]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.138825,	
2017-06-24 13:20:44,840 Epoch[10] Train-FCNLogLoss=0.138747
2017-06-24 13:20:44,841 Epoch[10] Time cost=524.392
2017-06-24 13:20:46,276 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0011.params"
2017-06-24 13:20:48,084 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0011.states"
2017-06-24 13:20:56,549 Epoch[11] Batch [10]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.150485,	
2017-06-24 13:21:03,606 Epoch[11] Batch [20]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.146581,	
2017-06-24 13:21:10,727 Epoch[11] Batch [30]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.142233,	
2017-06-24 13:21:17,546 Epoch[11] Batch [40]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.141408,	
2017-06-24 13:21:24,386 Epoch[11] Batch [50]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.139936,	
2017-06-24 13:21:31,334 Epoch[11] Batch [60]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.139825,	
2017-06-24 13:21:38,423 Epoch[11] Batch [70]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.141680,	
2017-06-24 13:21:45,592 Epoch[11] Batch [80]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.140249,	
2017-06-24 13:21:52,460 Epoch[11] Batch [90]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.139140,	
2017-06-24 13:21:59,288 Epoch[11] Batch [100]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.138778,	
2017-06-24 13:22:06,543 Epoch[11] Batch [110]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.138295,	
2017-06-24 13:22:13,427 Epoch[11] Batch [120]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.137031,	
2017-06-24 13:22:20,415 Epoch[11] Batch [130]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.135806,	
2017-06-24 13:22:27,501 Epoch[11] Batch [140]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.135505,	
2017-06-24 13:22:34,648 Epoch[11] Batch [150]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.134717,	
2017-06-24 13:22:41,929 Epoch[11] Batch [160]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.134668,	
2017-06-24 13:22:49,146 Epoch[11] Batch [170]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.135065,	
2017-06-24 13:22:56,261 Epoch[11] Batch [180]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.134459,	
2017-06-24 13:23:03,101 Epoch[11] Batch [190]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.134465,	
2017-06-24 13:23:10,058 Epoch[11] Batch [200]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.134298,	
2017-06-24 13:23:17,299 Epoch[11] Batch [210]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.134120,	
2017-06-24 13:23:24,593 Epoch[11] Batch [220]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.134748,	
2017-06-24 13:23:31,750 Epoch[11] Batch [230]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.134540,	
2017-06-24 13:23:38,480 Epoch[11] Batch [240]	Speed: 11.89 samples/sec	Train-FCNLogLoss=0.134204,	
2017-06-24 13:23:45,601 Epoch[11] Batch [250]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.133954,	
2017-06-24 13:23:52,422 Epoch[11] Batch [260]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.133427,	
2017-06-24 13:23:59,338 Epoch[11] Batch [270]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.132904,	
2017-06-24 13:24:06,330 Epoch[11] Batch [280]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.132881,	
2017-06-24 13:24:13,237 Epoch[11] Batch [290]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.132877,	
2017-06-24 13:24:20,283 Epoch[11] Batch [300]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.132794,	
2017-06-24 13:24:27,601 Epoch[11] Batch [310]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.132916,	
2017-06-24 13:24:34,731 Epoch[11] Batch [320]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.133276,	
2017-06-24 13:24:41,738 Epoch[11] Batch [330]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.133277,	
2017-06-24 13:24:48,598 Epoch[11] Batch [340]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.133013,	
2017-06-24 13:24:55,443 Epoch[11] Batch [350]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.132918,	
2017-06-24 13:25:02,342 Epoch[11] Batch [360]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.133017,	
2017-06-24 13:25:09,286 Epoch[11] Batch [370]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.133228,	
2017-06-24 13:25:16,374 Epoch[11] Batch [380]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.133259,	
2017-06-24 13:25:23,717 Epoch[11] Batch [390]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.133757,	
2017-06-24 13:25:30,957 Epoch[11] Batch [400]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.133747,	
2017-06-24 13:25:37,771 Epoch[11] Batch [410]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.133760,	
2017-06-24 13:25:44,726 Epoch[11] Batch [420]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.133637,	
2017-06-24 13:25:51,891 Epoch[11] Batch [430]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.133629,	
2017-06-24 13:25:58,871 Epoch[11] Batch [440]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.133919,	
2017-06-24 13:26:06,148 Epoch[11] Batch [450]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.133858,	
2017-06-24 13:26:13,605 Epoch[11] Batch [460]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.133734,	
2017-06-24 13:26:21,325 Epoch[11] Batch [470]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.133656,	
2017-06-24 13:26:28,730 Epoch[11] Batch [480]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.133734,	
2017-06-24 13:26:35,713 Epoch[11] Batch [490]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.133674,	
2017-06-24 13:26:42,712 Epoch[11] Batch [500]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.133715,	
2017-06-24 13:26:49,938 Epoch[11] Batch [510]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.133655,	
2017-06-24 13:26:57,798 Epoch[11] Batch [520]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.133652,	
2017-06-24 13:27:05,118 Epoch[11] Batch [530]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.133869,	
2017-06-24 13:27:12,540 Epoch[11] Batch [540]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.133702,	
2017-06-24 13:27:19,311 Epoch[11] Batch [550]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.133966,	
2017-06-24 13:27:26,525 Epoch[11] Batch [560]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.134204,	
2017-06-24 13:27:33,941 Epoch[11] Batch [570]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.134154,	
2017-06-24 13:27:41,151 Epoch[11] Batch [580]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.134110,	
2017-06-24 13:27:50,246 Epoch[11] Batch [590]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.134043,	
2017-06-24 13:28:01,416 Epoch[11] Batch [600]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.133847,	
2017-06-24 13:28:08,232 Epoch[11] Batch [610]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.133759,	
2017-06-24 13:28:15,965 Epoch[11] Batch [620]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.133668,	
2017-06-24 13:28:23,362 Epoch[11] Batch [630]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.133881,	
2017-06-24 13:28:30,170 Epoch[11] Batch [640]	Speed: 11.75 samples/sec	Train-FCNLogLoss=0.133816,	
2017-06-24 13:28:37,296 Epoch[11] Batch [650]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.133814,	
2017-06-24 13:28:44,672 Epoch[11] Batch [660]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.133922,	
2017-06-24 13:28:52,020 Epoch[11] Batch [670]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.134014,	
2017-06-24 13:28:59,207 Epoch[11] Batch [680]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.133989,	
2017-06-24 13:29:06,332 Epoch[11] Batch [690]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.134007,	
2017-06-24 13:29:13,652 Epoch[11] Batch [700]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.133880,	
2017-06-24 13:29:20,704 Epoch[11] Batch [710]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.133678,	
2017-06-24 13:29:27,877 Epoch[11] Batch [720]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.133491,	
2017-06-24 13:29:34,694 Epoch[11] Batch [730]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.133319,	
2017-06-24 13:29:41,762 Epoch[11] Batch [740]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.133207,	
2017-06-24 13:29:43,088 Epoch[11] Train-FCNLogLoss=0.133182
2017-06-24 13:29:43,088 Epoch[11] Time cost=535.004
2017-06-24 13:29:44,575 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0012.params"
2017-06-24 13:29:46,394 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0012.states"
2017-06-24 13:29:54,606 Epoch[12] Batch [10]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.130557,	
2017-06-24 13:30:01,671 Epoch[12] Batch [20]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.131784,	
2017-06-24 13:30:08,898 Epoch[12] Batch [30]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.130116,	
2017-06-24 13:30:16,476 Epoch[12] Batch [40]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.127160,	
2017-06-24 13:30:23,708 Epoch[12] Batch [50]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.125879,	
2017-06-24 13:30:31,209 Epoch[12] Batch [60]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.127754,	
2017-06-24 13:30:38,522 Epoch[12] Batch [70]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.128459,	
2017-06-24 13:30:45,611 Epoch[12] Batch [80]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.129817,	
2017-06-24 13:30:52,725 Epoch[12] Batch [90]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.130146,	
2017-06-24 13:30:59,991 Epoch[12] Batch [100]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.129990,	
2017-06-24 13:31:07,117 Epoch[12] Batch [110]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.130353,	
2017-06-24 13:31:14,174 Epoch[12] Batch [120]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.130261,	
2017-06-24 13:31:21,668 Epoch[12] Batch [130]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.129991,	
2017-06-24 13:31:28,857 Epoch[12] Batch [140]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.129385,	
2017-06-24 13:31:36,182 Epoch[12] Batch [150]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.129489,	
2017-06-24 13:31:43,284 Epoch[12] Batch [160]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.129952,	
2017-06-24 13:31:50,444 Epoch[12] Batch [170]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.129530,	
2017-06-24 13:31:57,939 Epoch[12] Batch [180]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.129498,	
2017-06-24 13:32:05,463 Epoch[12] Batch [190]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.130574,	
2017-06-24 13:32:12,706 Epoch[12] Batch [200]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.130366,	
2017-06-24 13:32:20,299 Epoch[12] Batch [210]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.129899,	
2017-06-24 13:32:27,386 Epoch[12] Batch [220]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.130254,	
2017-06-24 13:32:34,518 Epoch[12] Batch [230]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.130326,	
2017-06-24 13:32:41,824 Epoch[12] Batch [240]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.130285,	
2017-06-24 13:32:49,051 Epoch[12] Batch [250]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.130778,	
2017-06-24 13:32:56,404 Epoch[12] Batch [260]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.130489,	
2017-06-24 13:33:03,612 Epoch[12] Batch [270]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.130651,	
2017-06-24 13:33:11,033 Epoch[12] Batch [280]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.130778,	
2017-06-24 13:33:18,125 Epoch[12] Batch [290]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.130880,	
2017-06-24 13:33:25,330 Epoch[12] Batch [300]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.130933,	
2017-06-24 13:33:32,689 Epoch[12] Batch [310]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.130849,	
2017-06-24 13:33:40,026 Epoch[12] Batch [320]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.130793,	
2017-06-24 13:33:47,109 Epoch[12] Batch [330]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.130692,	
2017-06-24 13:33:54,046 Epoch[12] Batch [340]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.130391,	
2017-06-24 13:34:01,231 Epoch[12] Batch [350]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.130337,	
2017-06-24 13:34:08,857 Epoch[12] Batch [360]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.130269,	
2017-06-24 13:34:16,329 Epoch[12] Batch [370]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.130520,	
2017-06-24 13:34:23,641 Epoch[12] Batch [380]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.130352,	
2017-06-24 13:34:30,968 Epoch[12] Batch [390]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.130170,	
2017-06-24 13:34:38,125 Epoch[12] Batch [400]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.130063,	
2017-06-24 13:34:45,374 Epoch[12] Batch [410]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.129775,	
2017-06-24 13:34:52,789 Epoch[12] Batch [420]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.129830,	
2017-06-24 13:35:00,046 Epoch[12] Batch [430]	Speed: 11.02 samples/sec	Train-FCNLogLoss=0.129751,	
2017-06-24 13:35:07,155 Epoch[12] Batch [440]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.129657,	
2017-06-24 13:35:14,209 Epoch[12] Batch [450]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.129819,	
2017-06-24 13:35:21,442 Epoch[12] Batch [460]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.129923,	
2017-06-24 13:35:28,952 Epoch[12] Batch [470]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.130104,	
2017-06-24 13:35:36,025 Epoch[12] Batch [480]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.130153,	
2017-06-24 13:35:43,238 Epoch[12] Batch [490]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.129971,	
2017-06-24 13:35:50,704 Epoch[12] Batch [500]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.129927,	
2017-06-24 13:35:57,743 Epoch[12] Batch [510]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.129664,	
2017-06-24 13:36:05,285 Epoch[12] Batch [520]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.129610,	
2017-06-24 13:36:13,059 Epoch[12] Batch [530]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.129576,	
2017-06-24 13:36:20,101 Epoch[12] Batch [540]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.129703,	
2017-06-24 13:36:27,372 Epoch[12] Batch [550]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.129846,	
2017-06-24 13:36:34,715 Epoch[12] Batch [560]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.129891,	
2017-06-24 13:36:42,401 Epoch[12] Batch [570]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.129811,	
2017-06-24 13:36:49,943 Epoch[12] Batch [580]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.129455,	
2017-06-24 13:36:57,305 Epoch[12] Batch [590]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.129511,	
2017-06-24 13:37:04,735 Epoch[12] Batch [600]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.129415,	
2017-06-24 13:37:11,969 Epoch[12] Batch [610]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.129411,	
2017-06-24 13:37:20,393 Epoch[12] Batch [620]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.129418,	
2017-06-24 13:37:31,967 Epoch[12] Batch [630]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.129490,	
2017-06-24 13:37:39,038 Epoch[12] Batch [640]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.129420,	
2017-06-24 13:37:46,303 Epoch[12] Batch [650]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.129459,	
2017-06-24 13:37:53,954 Epoch[12] Batch [660]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.129456,	
2017-06-24 13:38:01,359 Epoch[12] Batch [670]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.129584,	
2017-06-24 13:38:08,893 Epoch[12] Batch [680]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.129747,	
2017-06-24 13:38:16,199 Epoch[12] Batch [690]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.129787,	
2017-06-24 13:38:23,821 Epoch[12] Batch [700]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.129703,	
2017-06-24 13:38:31,157 Epoch[12] Batch [710]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.129772,	
2017-06-24 13:38:38,597 Epoch[12] Batch [720]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.129903,	
2017-06-24 13:38:46,650 Epoch[12] Batch [730]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.129873,	
2017-06-24 13:38:54,341 Epoch[12] Batch [740]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.130096,	
2017-06-24 13:38:55,833 Epoch[12] Train-FCNLogLoss=0.130120
2017-06-24 13:38:55,833 Epoch[12] Time cost=549.438
2017-06-24 13:38:57,478 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0013.params"
2017-06-24 13:38:59,311 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0013.states"
2017-06-24 13:39:08,332 Epoch[13] Batch [10]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.127672,	
2017-06-24 13:39:16,066 Epoch[13] Batch [20]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.125680,	
2017-06-24 13:39:23,368 Epoch[13] Batch [30]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.127631,	
2017-06-24 13:39:31,029 Epoch[13] Batch [40]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.128760,	
2017-06-24 13:39:38,605 Epoch[13] Batch [50]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.129226,	
2017-06-24 13:39:46,247 Epoch[13] Batch [60]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.128669,	
2017-06-24 13:39:53,777 Epoch[13] Batch [70]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.131612,	
2017-06-24 13:40:01,287 Epoch[13] Batch [80]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.136365,	
2017-06-24 13:40:08,876 Epoch[13] Batch [90]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.138834,	
2017-06-24 13:40:16,721 Epoch[13] Batch [100]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.140781,	
2017-06-24 13:40:23,992 Epoch[13] Batch [110]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.140996,	
2017-06-24 13:40:31,577 Epoch[13] Batch [120]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.141767,	
2017-06-24 13:40:39,057 Epoch[13] Batch [130]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.141718,	
2017-06-24 13:40:46,158 Epoch[13] Batch [140]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.141195,	
2017-06-24 13:40:53,532 Epoch[13] Batch [150]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.140106,	
2017-06-24 13:41:01,226 Epoch[13] Batch [160]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.139252,	
2017-06-24 13:41:08,745 Epoch[13] Batch [170]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.138113,	
2017-06-24 13:41:16,359 Epoch[13] Batch [180]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.137007,	
2017-06-24 13:41:23,533 Epoch[13] Batch [190]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.136058,	
2017-06-24 13:41:31,148 Epoch[13] Batch [200]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.135652,	
2017-06-24 13:41:38,534 Epoch[13] Batch [210]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.134587,	
2017-06-24 13:41:46,693 Epoch[13] Batch [220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.134369,	
2017-06-24 13:41:54,236 Epoch[13] Batch [230]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.133969,	
2017-06-24 13:42:01,469 Epoch[13] Batch [240]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.133537,	
2017-06-24 13:42:08,872 Epoch[13] Batch [250]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.133146,	
2017-06-24 13:42:16,077 Epoch[13] Batch [260]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.133169,	
2017-06-24 13:42:23,360 Epoch[13] Batch [270]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.132963,	
2017-06-24 13:42:30,857 Epoch[13] Batch [280]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.133115,	
2017-06-24 13:42:38,873 Epoch[13] Batch [290]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.133564,	
2017-06-24 13:42:46,491 Epoch[13] Batch [300]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.133622,	
2017-06-24 13:42:53,871 Epoch[13] Batch [310]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.133661,	
2017-06-24 13:43:01,598 Epoch[13] Batch [320]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.133248,	
2017-06-24 13:43:09,344 Epoch[13] Batch [330]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.133541,	
2017-06-24 13:43:17,566 Epoch[13] Batch [340]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.133570,	
2017-06-24 13:43:27,849 Epoch[13] Batch [350]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.133729,	
2017-06-24 13:43:34,968 Epoch[13] Batch [360]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.133646,	
2017-06-24 13:43:42,250 Epoch[13] Batch [370]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.133232,	
2017-06-24 13:43:49,403 Epoch[13] Batch [380]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.132802,	
2017-06-24 13:43:56,771 Epoch[13] Batch [390]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.132733,	
2017-06-24 13:44:04,300 Epoch[13] Batch [400]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.132441,	
2017-06-24 13:44:13,220 Epoch[13] Batch [410]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.132046,	
2017-06-24 13:44:22,946 Epoch[13] Batch [420]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.131526,	
2017-06-24 13:44:32,057 Epoch[13] Batch [430]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.131524,	
2017-06-24 13:44:41,351 Epoch[13] Batch [440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.131146,	
2017-06-24 13:44:49,455 Epoch[13] Batch [450]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.130904,	
2017-06-24 13:44:59,172 Epoch[13] Batch [460]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.130897,	
2017-06-24 13:45:09,593 Epoch[13] Batch [470]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.130760,	
2017-06-24 13:45:19,372 Epoch[13] Batch [480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.130341,	
2017-06-24 13:45:31,147 Epoch[13] Batch [490]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.130368,	
2017-06-24 13:45:40,119 Epoch[13] Batch [500]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.130153,	
2017-06-24 13:45:48,138 Epoch[13] Batch [510]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.129971,	
2017-06-24 13:45:58,353 Epoch[13] Batch [520]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.129929,	
2017-06-24 13:46:09,505 Epoch[13] Batch [530]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.129756,	
2017-06-24 13:46:20,278 Epoch[13] Batch [540]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129824,	
2017-06-24 13:46:30,502 Epoch[13] Batch [550]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.129855,	
2017-06-24 13:46:41,546 Epoch[13] Batch [560]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.129753,	
2017-06-24 13:46:51,922 Epoch[13] Batch [570]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.129785,	
2017-06-24 13:47:03,242 Epoch[13] Batch [580]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.129744,	
2017-06-24 13:47:15,118 Epoch[13] Batch [590]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.129499,	
2017-06-24 13:47:25,793 Epoch[13] Batch [600]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129438,	
2017-06-24 13:47:36,971 Epoch[13] Batch [610]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.129565,	
2017-06-24 13:47:47,474 Epoch[13] Batch [620]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.129720,	
2017-06-24 13:47:58,532 Epoch[13] Batch [630]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.129605,	
2017-06-24 13:48:08,975 Epoch[13] Batch [640]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.129536,	
2017-06-24 13:48:15,889 Epoch[13] Batch [650]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.129624,	
2017-06-24 13:48:22,804 Epoch[13] Batch [660]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.129684,	
2017-06-24 13:48:29,687 Epoch[13] Batch [670]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.129642,	
2017-06-24 13:48:36,985 Epoch[13] Batch [680]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.129576,	
2017-06-24 13:48:44,804 Epoch[13] Batch [690]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.129546,	
2017-06-24 13:48:52,300 Epoch[13] Batch [700]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.129371,	
2017-06-24 13:49:00,700 Epoch[13] Batch [710]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.129427,	
2017-06-24 13:49:09,453 Epoch[13] Batch [720]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.129192,	
2017-06-24 13:49:17,277 Epoch[13] Batch [730]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.129149,	
2017-06-24 13:49:26,019 Epoch[13] Batch [740]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.129149,	
2017-06-24 13:49:28,246 Epoch[13] Train-FCNLogLoss=0.129147
2017-06-24 13:49:28,246 Epoch[13] Time cost=628.934
2017-06-24 13:49:30,115 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0014.params"
2017-06-24 13:49:31,874 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0014.states"
2017-06-24 13:49:43,548 Epoch[14] Batch [10]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.121110,	
2017-06-24 13:49:54,062 Epoch[14] Batch [20]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123443,	
2017-06-24 13:50:04,922 Epoch[14] Batch [30]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.123136,	
2017-06-24 13:50:15,415 Epoch[14] Batch [40]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125616,	
2017-06-24 13:50:24,824 Epoch[14] Batch [50]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.127561,	
2017-06-24 13:50:34,541 Epoch[14] Batch [60]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.126426,	
2017-06-24 13:50:44,888 Epoch[14] Batch [70]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.126246,	
2017-06-24 13:50:56,268 Epoch[14] Batch [80]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.125813,	
2017-06-24 13:51:06,793 Epoch[14] Batch [90]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125845,	
2017-06-24 13:51:18,659 Epoch[14] Batch [100]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.125570,	
2017-06-24 13:51:29,481 Epoch[14] Batch [110]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.125267,	
2017-06-24 13:51:40,544 Epoch[14] Batch [120]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.124605,	
2017-06-24 13:51:51,130 Epoch[14] Batch [130]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.124790,	
2017-06-24 13:52:01,777 Epoch[14] Batch [140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124339,	
2017-06-24 13:52:11,970 Epoch[14] Batch [150]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.124319,	
2017-06-24 13:52:23,243 Epoch[14] Batch [160]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.124329,	
2017-06-24 13:52:34,505 Epoch[14] Batch [170]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.124311,	
2017-06-24 13:52:45,361 Epoch[14] Batch [180]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.123908,	
2017-06-24 13:52:55,035 Epoch[14] Batch [190]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.123590,	
2017-06-24 13:53:02,155 Epoch[14] Batch [200]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.123866,	
2017-06-24 13:53:09,244 Epoch[14] Batch [210]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.124059,	
2017-06-24 13:53:16,460 Epoch[14] Batch [220]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.124113,	
2017-06-24 13:53:23,656 Epoch[14] Batch [230]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.123828,	
2017-06-24 13:53:30,772 Epoch[14] Batch [240]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.124172,	
2017-06-24 13:53:38,001 Epoch[14] Batch [250]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.124267,	
2017-06-24 13:53:45,323 Epoch[14] Batch [260]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.124410,	
2017-06-24 13:53:52,509 Epoch[14] Batch [270]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.124079,	
2017-06-24 13:53:59,912 Epoch[14] Batch [280]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.123551,	
2017-06-24 13:54:07,187 Epoch[14] Batch [290]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.123441,	
2017-06-24 13:54:14,872 Epoch[14] Batch [300]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.123851,	
2017-06-24 13:54:22,434 Epoch[14] Batch [310]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.123499,	
2017-06-24 13:54:29,851 Epoch[14] Batch [320]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.123913,	
2017-06-24 13:54:37,001 Epoch[14] Batch [330]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.124020,	
2017-06-24 13:54:44,398 Epoch[14] Batch [340]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.124310,	
2017-06-24 13:54:52,020 Epoch[14] Batch [350]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.124014,	
2017-06-24 13:55:00,188 Epoch[14] Batch [360]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.123790,	
2017-06-24 13:55:07,371 Epoch[14] Batch [370]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.123698,	
2017-06-24 13:55:14,855 Epoch[14] Batch [380]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123743,	
2017-06-24 13:55:21,994 Epoch[14] Batch [390]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.123739,	
2017-06-24 13:55:29,291 Epoch[14] Batch [400]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.123557,	
2017-06-24 13:55:36,674 Epoch[14] Batch [410]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.123552,	
2017-06-24 13:55:43,990 Epoch[14] Batch [420]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.123334,	
2017-06-24 13:55:51,217 Epoch[14] Batch [430]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.123359,	
2017-06-24 13:55:58,385 Epoch[14] Batch [440]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.123090,	
2017-06-24 13:56:05,955 Epoch[14] Batch [450]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.123166,	
2017-06-24 13:56:13,480 Epoch[14] Batch [460]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.123367,	
2017-06-24 13:56:20,993 Epoch[14] Batch [470]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123234,	
2017-06-24 13:56:28,973 Epoch[14] Batch [480]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.123300,	
2017-06-24 13:56:36,564 Epoch[14] Batch [490]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123203,	
2017-06-24 13:56:44,062 Epoch[14] Batch [500]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.123132,	
2017-06-24 13:56:52,483 Epoch[14] Batch [510]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.123205,	
2017-06-24 13:57:00,390 Epoch[14] Batch [520]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.123377,	
2017-06-24 13:57:08,201 Epoch[14] Batch [530]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.123363,	
2017-06-24 13:57:16,081 Epoch[14] Batch [540]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.123387,	
2017-06-24 13:57:24,245 Epoch[14] Batch [550]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.123316,	
2017-06-24 13:57:32,411 Epoch[14] Batch [560]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.123365,	
2017-06-24 13:57:41,603 Epoch[14] Batch [570]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.123670,	
2017-06-24 13:57:49,603 Epoch[14] Batch [580]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.123830,	
2017-06-24 13:57:57,769 Epoch[14] Batch [590]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.123812,	
2017-06-24 13:58:06,900 Epoch[14] Batch [600]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.123747,	
2017-06-24 13:58:18,481 Epoch[14] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.123644,	
2017-06-24 13:58:27,758 Epoch[14] Batch [620]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.123831,	
2017-06-24 13:58:37,298 Epoch[14] Batch [630]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.123712,	
2017-06-24 13:58:47,315 Epoch[14] Batch [640]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.123790,	
2017-06-24 13:58:56,905 Epoch[14] Batch [650]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.123641,	
2017-06-24 13:59:07,409 Epoch[14] Batch [660]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.123634,	
2017-06-24 13:59:18,249 Epoch[14] Batch [670]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.123627,	
2017-06-24 13:59:28,607 Epoch[14] Batch [680]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.123618,	
2017-06-24 13:59:37,309 Epoch[14] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.123798,	
2017-06-24 13:59:46,952 Epoch[14] Batch [700]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.123775,	
2017-06-24 13:59:55,984 Epoch[14] Batch [710]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.123884,	
2017-06-24 14:00:04,971 Epoch[14] Batch [720]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.123922,	
2017-06-24 14:00:14,120 Epoch[14] Batch [730]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.123876,	
2017-06-24 14:00:22,109 Epoch[14] Batch [740]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.123848,	
2017-06-24 14:00:23,734 Epoch[14] Train-FCNLogLoss=0.123762
2017-06-24 14:00:23,734 Epoch[14] Time cost=651.859
2017-06-24 14:00:25,333 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0015.params"
2017-06-24 14:00:28,097 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0015.states"
2017-06-24 14:00:38,385 Epoch[15] Batch [10]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.118816,	
2017-06-24 14:00:47,568 Epoch[15] Batch [20]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.115809,	
2017-06-24 14:00:57,143 Epoch[15] Batch [30]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.118439,	
2017-06-24 14:01:07,633 Epoch[15] Batch [40]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.118095,	
2017-06-24 14:01:17,510 Epoch[15] Batch [50]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.119167,	
2017-06-24 14:01:27,425 Epoch[15] Batch [60]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.121456,	
2017-06-24 14:01:36,515 Epoch[15] Batch [70]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.123150,	
2017-06-24 14:01:46,019 Epoch[15] Batch [80]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.122983,	
2017-06-24 14:01:55,196 Epoch[15] Batch [90]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.124229,	
2017-06-24 14:02:03,934 Epoch[15] Batch [100]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.125056,	
2017-06-24 14:02:12,438 Epoch[15] Batch [110]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.125274,	
2017-06-24 14:02:21,301 Epoch[15] Batch [120]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.125536,	
2017-06-24 14:02:30,195 Epoch[15] Batch [130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.124892,	
2017-06-24 14:02:39,584 Epoch[15] Batch [140]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.124980,	
2017-06-24 14:02:48,958 Epoch[15] Batch [150]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.124445,	
2017-06-24 14:02:59,595 Epoch[15] Batch [160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.123681,	
2017-06-24 14:03:10,793 Epoch[15] Batch [170]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.124111,	
2017-06-24 14:03:20,491 Epoch[15] Batch [180]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.124812,	
2017-06-24 14:03:30,145 Epoch[15] Batch [190]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.124780,	
2017-06-24 14:03:38,796 Epoch[15] Batch [200]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.124482,	
2017-06-24 14:03:47,678 Epoch[15] Batch [210]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.124931,	
2017-06-24 14:03:55,877 Epoch[15] Batch [220]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.125065,	
2017-06-24 14:04:07,415 Epoch[15] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.125332,	
2017-06-24 14:04:17,102 Epoch[15] Batch [240]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.125622,	
2017-06-24 14:04:25,824 Epoch[15] Batch [250]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.125593,	
2017-06-24 14:04:35,541 Epoch[15] Batch [260]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.125740,	
2017-06-24 14:04:45,885 Epoch[15] Batch [270]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.125972,	
2017-06-24 14:04:56,477 Epoch[15] Batch [280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125917,	
2017-06-24 14:05:07,542 Epoch[15] Batch [290]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.125790,	
2017-06-24 14:05:17,715 Epoch[15] Batch [300]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.125422,	
2017-06-24 14:05:27,060 Epoch[15] Batch [310]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124969,	
2017-06-24 14:05:35,604 Epoch[15] Batch [320]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.125230,	
2017-06-24 14:05:43,983 Epoch[15] Batch [330]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.125692,	
2017-06-24 14:05:52,843 Epoch[15] Batch [340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.125504,	
2017-06-24 14:06:01,336 Epoch[15] Batch [350]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.125557,	
2017-06-24 14:06:10,678 Epoch[15] Batch [360]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.125676,	
2017-06-24 14:06:18,910 Epoch[15] Batch [370]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126087,	
2017-06-24 14:06:28,088 Epoch[15] Batch [380]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.125915,	
2017-06-24 14:06:36,837 Epoch[15] Batch [390]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.126484,	
2017-06-24 14:06:45,916 Epoch[15] Batch [400]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.126661,	
2017-06-24 14:06:55,962 Epoch[15] Batch [410]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.126923,	
2017-06-24 14:07:06,966 Epoch[15] Batch [420]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.127374,	
2017-06-24 14:07:16,198 Epoch[15] Batch [430]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.127490,	
2017-06-24 14:07:25,445 Epoch[15] Batch [440]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.127507,	
2017-06-24 14:07:33,591 Epoch[15] Batch [450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.127195,	
2017-06-24 14:07:41,986 Epoch[15] Batch [460]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.126819,	
2017-06-24 14:07:50,927 Epoch[15] Batch [470]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.126662,	
2017-06-24 14:07:59,054 Epoch[15] Batch [480]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.126695,	
2017-06-24 14:08:07,256 Epoch[15] Batch [490]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.126664,	
2017-06-24 14:08:15,375 Epoch[15] Batch [500]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.126540,	
2017-06-24 14:08:24,261 Epoch[15] Batch [510]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.126664,	
2017-06-24 14:08:33,688 Epoch[15] Batch [520]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.126632,	
2017-06-24 14:08:42,454 Epoch[15] Batch [530]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.126621,	
2017-06-24 14:08:51,396 Epoch[15] Batch [540]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.126664,	
2017-06-24 14:09:01,030 Epoch[15] Batch [550]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.126589,	
2017-06-24 14:09:11,462 Epoch[15] Batch [560]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.126330,	
2017-06-24 14:09:20,472 Epoch[15] Batch [570]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.126115,	
2017-06-24 14:09:29,546 Epoch[15] Batch [580]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.125988,	
2017-06-24 14:09:38,310 Epoch[15] Batch [590]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.125991,	
2017-06-24 14:09:46,742 Epoch[15] Batch [600]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.125949,	
2017-06-24 14:09:55,999 Epoch[15] Batch [610]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.126002,	
2017-06-24 14:10:05,964 Epoch[15] Batch [620]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.125949,	
2017-06-24 14:10:17,515 Epoch[15] Batch [630]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.125756,	
2017-06-24 14:10:26,562 Epoch[15] Batch [640]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.125592,	
2017-06-24 14:10:35,826 Epoch[15] Batch [650]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.125534,	
2017-06-24 14:10:45,673 Epoch[15] Batch [660]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.125702,	
2017-06-24 14:10:55,836 Epoch[15] Batch [670]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.125802,	
2017-06-24 14:11:05,779 Epoch[15] Batch [680]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.125975,	
2017-06-24 14:11:15,113 Epoch[15] Batch [690]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.125996,	
2017-06-24 14:11:25,783 Epoch[15] Batch [700]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126016,	
2017-06-24 14:11:35,927 Epoch[15] Batch [710]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.126024,	
2017-06-24 14:11:46,902 Epoch[15] Batch [720]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.125908,	
2017-06-24 14:11:56,659 Epoch[15] Batch [730]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.125975,	
2017-06-24 14:12:05,799 Epoch[15] Batch [740]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.125859,	
2017-06-24 14:12:07,764 Epoch[15] Train-FCNLogLoss=0.125854
2017-06-24 14:12:07,764 Epoch[15] Time cost=699.667
2017-06-24 14:12:10,066 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0016.params"
2017-06-24 14:12:12,131 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0016.states"
2017-06-24 14:12:22,132 Epoch[16] Batch [10]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.124396,	
2017-06-24 14:12:32,159 Epoch[16] Batch [20]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.132787,	
2017-06-24 14:12:41,984 Epoch[16] Batch [30]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.131697,	
2017-06-24 14:12:51,431 Epoch[16] Batch [40]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.132218,	
2017-06-24 14:13:01,030 Epoch[16] Batch [50]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.130107,	
2017-06-24 14:13:11,005 Epoch[16] Batch [60]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.130422,	
2017-06-24 14:13:21,482 Epoch[16] Batch [70]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.128746,	
2017-06-24 14:13:30,963 Epoch[16] Batch [80]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.127906,	
2017-06-24 14:13:40,055 Epoch[16] Batch [90]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128146,	
2017-06-24 14:13:49,156 Epoch[16] Batch [100]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.127820,	
2017-06-24 14:13:57,521 Epoch[16] Batch [110]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.127349,	
2017-06-24 14:14:06,453 Epoch[16] Batch [120]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.126001,	
2017-06-24 14:14:16,139 Epoch[16] Batch [130]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.126058,	
2017-06-24 14:14:25,396 Epoch[16] Batch [140]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.126679,	
2017-06-24 14:14:35,007 Epoch[16] Batch [150]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.126462,	
2017-06-24 14:14:44,244 Epoch[16] Batch [160]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.126347,	
2017-06-24 14:14:54,437 Epoch[16] Batch [170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.126258,	
2017-06-24 14:15:03,444 Epoch[16] Batch [180]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.126329,	
2017-06-24 14:15:12,917 Epoch[16] Batch [190]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.125975,	
2017-06-24 14:15:22,808 Epoch[16] Batch [200]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.125635,	
2017-06-24 14:15:31,483 Epoch[16] Batch [210]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.125563,	
2017-06-24 14:15:40,089 Epoch[16] Batch [220]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.126316,	
2017-06-24 14:15:48,266 Epoch[16] Batch [230]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.125845,	
2017-06-24 14:15:57,696 Epoch[16] Batch [240]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.125559,	
2017-06-24 14:16:09,172 Epoch[16] Batch [250]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.125176,	
2017-06-24 14:16:18,527 Epoch[16] Batch [260]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.124632,	
2017-06-24 14:16:28,088 Epoch[16] Batch [270]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.124630,	
2017-06-24 14:16:37,011 Epoch[16] Batch [280]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.124323,	
2017-06-24 14:16:45,999 Epoch[16] Batch [290]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.123887,	
2017-06-24 14:16:55,195 Epoch[16] Batch [300]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.123649,	
2017-06-24 14:17:05,405 Epoch[16] Batch [310]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.123481,	
2017-06-24 14:17:14,665 Epoch[16] Batch [320]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.123350,	
2017-06-24 14:17:24,665 Epoch[16] Batch [330]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.123457,	
2017-06-24 14:17:34,664 Epoch[16] Batch [340]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.123214,	
2017-06-24 14:17:43,745 Epoch[16] Batch [350]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.122908,	
2017-06-24 14:17:51,850 Epoch[16] Batch [360]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.122661,	
2017-06-24 14:18:00,198 Epoch[16] Batch [370]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.122537,	
2017-06-24 14:18:09,591 Epoch[16] Batch [380]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.122509,	
2017-06-24 14:18:17,908 Epoch[16] Batch [390]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.122191,	
2017-06-24 14:18:26,464 Epoch[16] Batch [400]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.122191,	
2017-06-24 14:18:35,575 Epoch[16] Batch [410]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.122038,	
2017-06-24 14:18:44,159 Epoch[16] Batch [420]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.121982,	
2017-06-24 14:18:53,220 Epoch[16] Batch [430]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.121750,	
2017-06-24 14:19:03,202 Epoch[16] Batch [440]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.121644,	
2017-06-24 14:19:12,531 Epoch[16] Batch [450]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.121501,	
2017-06-24 14:19:21,473 Epoch[16] Batch [460]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121352,	
2017-06-24 14:19:30,351 Epoch[16] Batch [470]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.121227,	
2017-06-24 14:19:38,602 Epoch[16] Batch [480]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.121231,	
2017-06-24 14:19:46,868 Epoch[16] Batch [490]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.121269,	
2017-06-24 14:19:55,417 Epoch[16] Batch [500]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.121482,	
2017-06-24 14:20:04,175 Epoch[16] Batch [510]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.121497,	
2017-06-24 14:20:13,453 Epoch[16] Batch [520]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.121369,	
2017-06-24 14:20:22,413 Epoch[16] Batch [530]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.121449,	
2017-06-24 14:20:31,270 Epoch[16] Batch [540]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.121386,	
2017-06-24 14:20:40,271 Epoch[16] Batch [550]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.121488,	
2017-06-24 14:20:49,234 Epoch[16] Batch [560]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.121589,	
2017-06-24 14:20:59,057 Epoch[16] Batch [570]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.121612,	
2017-06-24 14:21:08,658 Epoch[16] Batch [580]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.121536,	
2017-06-24 14:21:17,715 Epoch[16] Batch [590]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.121335,	
2017-06-24 14:21:26,465 Epoch[16] Batch [600]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.121350,	
2017-06-24 14:21:34,943 Epoch[16] Batch [610]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.121188,	
2017-06-24 14:21:44,584 Epoch[16] Batch [620]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.121415,	
2017-06-24 14:21:52,243 Epoch[16] Batch [630]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.121373,	
2017-06-24 14:22:01,242 Epoch[16] Batch [640]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.121394,	
2017-06-24 14:22:10,198 Epoch[16] Batch [650]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.121454,	
2017-06-24 14:22:21,688 Epoch[16] Batch [660]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.121433,	
2017-06-24 14:22:30,782 Epoch[16] Batch [670]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.121520,	
2017-06-24 14:22:39,764 Epoch[16] Batch [680]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.121369,	
2017-06-24 14:22:50,272 Epoch[16] Batch [690]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121473,	
2017-06-24 14:23:00,866 Epoch[16] Batch [700]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121469,	
2017-06-24 14:23:10,239 Epoch[16] Batch [710]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121480,	
2017-06-24 14:23:19,329 Epoch[16] Batch [720]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.121413,	
2017-06-24 14:23:28,536 Epoch[16] Batch [730]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121436,	
2017-06-24 14:23:37,536 Epoch[16] Batch [740]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.121413,	
2017-06-24 14:23:39,243 Epoch[16] Train-FCNLogLoss=0.121318
2017-06-24 14:23:39,244 Epoch[16] Time cost=687.112
2017-06-24 14:23:40,855 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0017.params"
2017-06-24 14:23:42,771 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0017.states"
2017-06-24 14:23:52,025 Epoch[17] Batch [10]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.120933,	
2017-06-24 14:24:00,255 Epoch[17] Batch [20]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.121037,	
2017-06-24 14:24:08,976 Epoch[17] Batch [30]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.121868,	
2017-06-24 14:24:18,256 Epoch[17] Batch [40]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.119830,	
2017-06-24 14:24:28,045 Epoch[17] Batch [50]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.121274,	
2017-06-24 14:24:37,933 Epoch[17] Batch [60]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.123824,	
2017-06-24 14:24:48,755 Epoch[17] Batch [70]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.122353,	
2017-06-24 14:24:59,650 Epoch[17] Batch [80]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.120782,	
2017-06-24 14:25:09,115 Epoch[17] Batch [90]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.119970,	
2017-06-24 14:25:18,447 Epoch[17] Batch [100]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.119566,	
2017-06-24 14:25:27,434 Epoch[17] Batch [110]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.118628,	
2017-06-24 14:25:36,949 Epoch[17] Batch [120]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.118570,	
2017-06-24 14:25:45,050 Epoch[17] Batch [130]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117938,	
2017-06-24 14:25:53,444 Epoch[17] Batch [140]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.117555,	
2017-06-24 14:26:02,982 Epoch[17] Batch [150]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.117173,	
2017-06-24 14:26:12,186 Epoch[17] Batch [160]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.116701,	
2017-06-24 14:26:20,855 Epoch[17] Batch [170]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.116495,	
2017-06-24 14:26:30,837 Epoch[17] Batch [180]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.116489,	
2017-06-24 14:26:40,981 Epoch[17] Batch [190]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.116465,	
2017-06-24 14:26:50,639 Epoch[17] Batch [200]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.116386,	
2017-06-24 14:27:00,123 Epoch[17] Batch [210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.116179,	
2017-06-24 14:27:08,637 Epoch[17] Batch [220]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.116551,	
2017-06-24 14:27:17,406 Epoch[17] Batch [230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.116988,	
2017-06-24 14:27:25,629 Epoch[17] Batch [240]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116784,	
2017-06-24 14:27:34,279 Epoch[17] Batch [250]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.117013,	
2017-06-24 14:27:42,243 Epoch[17] Batch [260]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.116793,	
2017-06-24 14:27:50,690 Epoch[17] Batch [270]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.116852,	
2017-06-24 14:27:59,289 Epoch[17] Batch [280]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.116929,	
2017-06-24 14:28:07,992 Epoch[17] Batch [290]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.117282,	
2017-06-24 14:28:17,518 Epoch[17] Batch [300]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.117298,	
2017-06-24 14:28:28,967 Epoch[17] Batch [310]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.117181,	
2017-06-24 14:28:39,475 Epoch[17] Batch [320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.117692,	
2017-06-24 14:28:49,984 Epoch[17] Batch [330]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.118494,	
2017-06-24 14:28:59,573 Epoch[17] Batch [340]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.119124,	
2017-06-24 14:29:08,471 Epoch[17] Batch [350]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.119216,	
2017-06-24 14:29:17,163 Epoch[17] Batch [360]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.119634,	
2017-06-24 14:29:25,820 Epoch[17] Batch [370]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.119464,	
2017-06-24 14:29:34,285 Epoch[17] Batch [380]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.119420,	
2017-06-24 14:29:42,571 Epoch[17] Batch [390]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.119420,	
2017-06-24 14:29:50,598 Epoch[17] Batch [400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.119331,	
2017-06-24 14:29:59,361 Epoch[17] Batch [410]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.119461,	
2017-06-24 14:30:07,708 Epoch[17] Batch [420]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.119476,	
2017-06-24 14:30:16,692 Epoch[17] Batch [430]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.119429,	
2017-06-24 14:30:25,672 Epoch[17] Batch [440]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.119489,	
2017-06-24 14:30:35,215 Epoch[17] Batch [450]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.119583,	
2017-06-24 14:30:45,202 Epoch[17] Batch [460]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.119494,	
2017-06-24 14:30:54,269 Epoch[17] Batch [470]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.119449,	
2017-06-24 14:31:03,129 Epoch[17] Batch [480]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.119669,	
2017-06-24 14:31:12,668 Epoch[17] Batch [490]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.119540,	
2017-06-24 14:31:21,558 Epoch[17] Batch [500]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.119400,	
2017-06-24 14:31:30,392 Epoch[17] Batch [510]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.119472,	
2017-06-24 14:31:39,429 Epoch[17] Batch [520]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.119465,	
2017-06-24 14:31:47,861 Epoch[17] Batch [530]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.119417,	
2017-06-24 14:31:56,364 Epoch[17] Batch [540]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.119470,	
2017-06-24 14:32:04,812 Epoch[17] Batch [550]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.119309,	
2017-06-24 14:32:13,714 Epoch[17] Batch [560]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.119280,	
2017-06-24 14:32:22,571 Epoch[17] Batch [570]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.119160,	
2017-06-24 14:32:32,403 Epoch[17] Batch [580]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.119226,	
2017-06-24 14:32:42,037 Epoch[17] Batch [590]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.119129,	
2017-06-24 14:32:52,450 Epoch[17] Batch [600]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119069,	
2017-06-24 14:33:02,422 Epoch[17] Batch [610]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.118960,	
2017-06-24 14:33:11,277 Epoch[17] Batch [620]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.119009,	
2017-06-24 14:33:20,867 Epoch[17] Batch [630]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.119083,	
2017-06-24 14:33:29,727 Epoch[17] Batch [640]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.118925,	
2017-06-24 14:33:38,725 Epoch[17] Batch [650]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.118840,	
2017-06-24 14:33:48,081 Epoch[17] Batch [660]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.118704,	
2017-06-24 14:33:56,700 Epoch[17] Batch [670]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.118608,	
2017-06-24 14:34:05,839 Epoch[17] Batch [680]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.118589,	
2017-06-24 14:34:16,173 Epoch[17] Batch [690]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.118583,	
2017-06-24 14:34:26,398 Epoch[17] Batch [700]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.118743,	
2017-06-24 14:34:36,913 Epoch[17] Batch [710]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.119094,	
2017-06-24 14:34:47,307 Epoch[17] Batch [720]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.119150,	
2017-06-24 14:34:56,360 Epoch[17] Batch [730]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.119133,	
2017-06-24 14:35:06,141 Epoch[17] Batch [740]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.119212,	
2017-06-24 14:35:08,109 Epoch[17] Train-FCNLogLoss=0.119197
2017-06-24 14:35:08,109 Epoch[17] Time cost=685.338
2017-06-24 14:35:09,716 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0018.params"
2017-06-24 14:35:12,503 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0018.states"
2017-06-24 14:35:23,776 Epoch[18] Batch [10]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.118046,	
2017-06-24 14:35:32,546 Epoch[18] Batch [20]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.116286,	
2017-06-24 14:35:40,399 Epoch[18] Batch [30]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.115830,	
2017-06-24 14:35:48,207 Epoch[18] Batch [40]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.119914,	
2017-06-24 14:35:57,066 Epoch[18] Batch [50]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.120751,	
2017-06-24 14:36:05,868 Epoch[18] Batch [60]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.122462,	
2017-06-24 14:36:14,890 Epoch[18] Batch [70]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.121506,	
2017-06-24 14:36:23,506 Epoch[18] Batch [80]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.122719,	
2017-06-24 14:36:32,103 Epoch[18] Batch [90]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.121913,	
2017-06-24 14:36:40,864 Epoch[18] Batch [100]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.121336,	
2017-06-24 14:36:49,882 Epoch[18] Batch [110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.121026,	
2017-06-24 14:36:59,071 Epoch[18] Batch [120]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.120502,	
2017-06-24 14:37:08,369 Epoch[18] Batch [130]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.119771,	
2017-06-24 14:37:17,295 Epoch[18] Batch [140]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.119261,	
2017-06-24 14:37:26,068 Epoch[18] Batch [150]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.118782,	
2017-06-24 14:37:35,119 Epoch[18] Batch [160]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.118638,	
2017-06-24 14:37:43,855 Epoch[18] Batch [170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.118425,	
2017-06-24 14:37:53,740 Epoch[18] Batch [180]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.118323,	
2017-06-24 14:38:03,369 Epoch[18] Batch [190]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.118081,	
2017-06-24 14:38:12,429 Epoch[18] Batch [200]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.118074,	
2017-06-24 14:38:21,631 Epoch[18] Batch [210]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.118063,	
2017-06-24 14:38:30,542 Epoch[18] Batch [220]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.117818,	
2017-06-24 14:38:39,500 Epoch[18] Batch [230]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.117077,	
2017-06-24 14:38:48,421 Epoch[18] Batch [240]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.116866,	
2017-06-24 14:38:57,938 Epoch[18] Batch [250]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.116492,	
2017-06-24 14:39:07,023 Epoch[18] Batch [260]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.116527,	
2017-06-24 14:39:16,973 Epoch[18] Batch [270]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.116680,	
2017-06-24 14:39:27,225 Epoch[18] Batch [280]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.116699,	
2017-06-24 14:39:37,228 Epoch[18] Batch [290]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.116482,	
2017-06-24 14:39:46,852 Epoch[18] Batch [300]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.116198,	
2017-06-24 14:39:55,809 Epoch[18] Batch [310]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.116307,	
2017-06-24 14:40:04,822 Epoch[18] Batch [320]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.116486,	
2017-06-24 14:40:14,147 Epoch[18] Batch [330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.116476,	
2017-06-24 14:40:23,307 Epoch[18] Batch [340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.118091,	
2017-06-24 14:40:33,080 Epoch[18] Batch [350]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.118561,	
2017-06-24 14:40:44,574 Epoch[18] Batch [360]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.118907,	
2017-06-24 14:40:52,808 Epoch[18] Batch [370]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.119085,	
2017-06-24 14:41:01,988 Epoch[18] Batch [380]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.119093,	
2017-06-24 14:41:10,615 Epoch[18] Batch [390]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.119349,	
2017-06-24 14:41:19,018 Epoch[18] Batch [400]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.119295,	
2017-06-24 14:41:28,446 Epoch[18] Batch [410]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.119226,	
2017-06-24 14:41:36,894 Epoch[18] Batch [420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.118943,	
2017-06-24 14:41:45,573 Epoch[18] Batch [430]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.118676,	
2017-06-24 14:41:55,014 Epoch[18] Batch [440]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.118626,	
2017-06-24 14:42:04,308 Epoch[18] Batch [450]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.118738,	
2017-06-24 14:42:13,432 Epoch[18] Batch [460]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.118704,	
2017-06-24 14:42:22,275 Epoch[18] Batch [470]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.118721,	
2017-06-24 14:42:30,720 Epoch[18] Batch [480]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.118887,	
2017-06-24 14:42:40,956 Epoch[18] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.119084,	
2017-06-24 14:42:49,980 Epoch[18] Batch [500]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.119065,	
2017-06-24 14:42:59,000 Epoch[18] Batch [510]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.119233,	
2017-06-24 14:43:08,585 Epoch[18] Batch [520]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.119301,	
2017-06-24 14:43:17,595 Epoch[18] Batch [530]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.119296,	
2017-06-24 14:43:26,808 Epoch[18] Batch [540]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.119553,	
2017-06-24 14:43:36,829 Epoch[18] Batch [550]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.119616,	
2017-06-24 14:43:45,966 Epoch[18] Batch [560]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.119669,	
2017-06-24 14:43:55,109 Epoch[18] Batch [570]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.119644,	
2017-06-24 14:44:04,932 Epoch[18] Batch [580]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.119522,	
2017-06-24 14:44:13,777 Epoch[18] Batch [590]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.119473,	
2017-06-24 14:44:23,059 Epoch[18] Batch [600]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.119324,	
2017-06-24 14:44:32,259 Epoch[18] Batch [610]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.119146,	
2017-06-24 14:44:41,978 Epoch[18] Batch [620]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.119179,	
2017-06-24 14:44:51,621 Epoch[18] Batch [630]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.119168,	
2017-06-24 14:45:00,557 Epoch[18] Batch [640]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.119056,	
2017-06-24 14:45:09,349 Epoch[18] Batch [650]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.118859,	
2017-06-24 14:45:18,281 Epoch[18] Batch [660]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.118833,	
2017-06-24 14:45:27,088 Epoch[18] Batch [670]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.118936,	
2017-06-24 14:45:35,380 Epoch[18] Batch [680]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.119024,	
2017-06-24 14:45:44,678 Epoch[18] Batch [690]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.118952,	
2017-06-24 14:45:53,650 Epoch[18] Batch [700]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.118947,	
2017-06-24 14:46:02,475 Epoch[18] Batch [710]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.118939,	
2017-06-24 14:46:10,943 Epoch[18] Batch [720]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.118821,	
2017-06-24 14:46:19,344 Epoch[18] Batch [730]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.118868,	
2017-06-24 14:46:28,926 Epoch[18] Batch [740]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.118946,	
2017-06-24 14:46:31,001 Epoch[18] Train-FCNLogLoss=0.118889
2017-06-24 14:46:31,002 Epoch[18] Time cost=678.498
2017-06-24 14:46:32,582 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0019.params"
2017-06-24 14:46:34,471 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0019.states"
2017-06-24 14:46:47,533 Epoch[19] Batch [10]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.115776,	
2017-06-24 14:46:56,900 Epoch[19] Batch [20]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.120215,	
2017-06-24 14:47:04,705 Epoch[19] Batch [30]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.115185,	
2017-06-24 14:47:12,332 Epoch[19] Batch [40]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.114440,	
2017-06-24 14:47:20,567 Epoch[19] Batch [50]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.115176,	
2017-06-24 14:47:28,785 Epoch[19] Batch [60]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.114525,	
2017-06-24 14:47:36,335 Epoch[19] Batch [70]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.112868,	
2017-06-24 14:47:43,530 Epoch[19] Batch [80]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.113490,	
2017-06-24 14:47:50,845 Epoch[19] Batch [90]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.113323,	
2017-06-24 14:47:58,541 Epoch[19] Batch [100]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.112758,	
2017-06-24 14:48:06,688 Epoch[19] Batch [110]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112653,	
2017-06-24 14:48:14,835 Epoch[19] Batch [120]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112413,	
2017-06-24 14:48:23,422 Epoch[19] Batch [130]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.112502,	
2017-06-24 14:48:31,255 Epoch[19] Batch [140]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112554,	
2017-06-24 14:48:39,541 Epoch[19] Batch [150]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113166,	
2017-06-24 14:48:47,842 Epoch[19] Batch [160]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.113235,	
2017-06-24 14:48:56,577 Epoch[19] Batch [170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.113511,	
2017-06-24 14:49:05,352 Epoch[19] Batch [180]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.113972,	
2017-06-24 14:49:13,505 Epoch[19] Batch [190]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113938,	
2017-06-24 14:49:21,978 Epoch[19] Batch [200]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.114040,	
2017-06-24 14:49:30,570 Epoch[19] Batch [210]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.114192,	
2017-06-24 14:49:39,198 Epoch[19] Batch [220]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.114396,	
2017-06-24 14:49:47,440 Epoch[19] Batch [230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.114457,	
2017-06-24 14:49:54,821 Epoch[19] Batch [240]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.114344,	
2017-06-24 14:50:02,817 Epoch[19] Batch [250]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114322,	
2017-06-24 14:50:10,762 Epoch[19] Batch [260]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.114318,	
2017-06-24 14:50:19,043 Epoch[19] Batch [270]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.114575,	
2017-06-24 14:50:27,463 Epoch[19] Batch [280]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.114715,	
2017-06-24 14:50:36,183 Epoch[19] Batch [290]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.114544,	
2017-06-24 14:50:44,242 Epoch[19] Batch [300]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.114754,	
2017-06-24 14:50:52,948 Epoch[19] Batch [310]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.115016,	
2017-06-24 14:51:00,936 Epoch[19] Batch [320]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114775,	
2017-06-24 14:51:09,454 Epoch[19] Batch [330]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.114344,	
2017-06-24 14:51:18,308 Epoch[19] Batch [340]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.114452,	
2017-06-24 14:51:26,636 Epoch[19] Batch [350]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.114509,	
2017-06-24 14:51:34,477 Epoch[19] Batch [360]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.114568,	
2017-06-24 14:51:42,828 Epoch[19] Batch [370]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114352,	
2017-06-24 14:51:50,912 Epoch[19] Batch [380]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114275,	
2017-06-24 14:51:58,686 Epoch[19] Batch [390]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.114227,	
2017-06-24 14:52:06,668 Epoch[19] Batch [400]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.114163,	
2017-06-24 14:52:15,016 Epoch[19] Batch [410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114476,	
2017-06-24 14:52:22,715 Epoch[19] Batch [420]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.114242,	
2017-06-24 14:52:31,002 Epoch[19] Batch [430]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.114370,	
2017-06-24 14:52:39,262 Epoch[19] Batch [440]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.114417,	
2017-06-24 14:52:47,437 Epoch[19] Batch [450]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114252,	
2017-06-24 14:52:55,164 Epoch[19] Batch [460]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.114113,	
2017-06-24 14:53:03,393 Epoch[19] Batch [470]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.114173,	
2017-06-24 14:53:11,884 Epoch[19] Batch [480]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.114243,	
2017-06-24 14:53:20,851 Epoch[19] Batch [490]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.114492,	
2017-06-24 14:53:29,615 Epoch[19] Batch [500]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.114643,	
2017-06-24 14:53:38,457 Epoch[19] Batch [510]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.114506,	
2017-06-24 14:53:47,438 Epoch[19] Batch [520]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.114498,	
2017-06-24 14:53:55,611 Epoch[19] Batch [530]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114371,	
2017-06-24 14:54:03,498 Epoch[19] Batch [540]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.114231,	
2017-06-24 14:54:11,339 Epoch[19] Batch [550]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.114002,	
2017-06-24 14:54:19,083 Epoch[19] Batch [560]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.113865,	
2017-06-24 14:54:26,855 Epoch[19] Batch [570]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.113805,	
2017-06-24 14:54:35,007 Epoch[19] Batch [580]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113757,	
2017-06-24 14:54:43,421 Epoch[19] Batch [590]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.113778,	
2017-06-24 14:54:51,591 Epoch[19] Batch [600]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113745,	
2017-06-24 14:55:00,333 Epoch[19] Batch [610]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.113920,	
2017-06-24 14:55:08,573 Epoch[19] Batch [620]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113971,	
2017-06-24 14:55:16,754 Epoch[19] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114030,	
2017-06-24 14:55:25,840 Epoch[19] Batch [640]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.114014,	
2017-06-24 14:55:34,399 Epoch[19] Batch [650]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.114110,	
2017-06-24 14:55:42,899 Epoch[19] Batch [660]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.113955,	
2017-06-24 14:55:51,375 Epoch[19] Batch [670]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.113937,	
2017-06-24 14:55:59,480 Epoch[19] Batch [680]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113809,	
2017-06-24 14:56:07,858 Epoch[19] Batch [690]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.113686,	
2017-06-24 14:56:16,347 Epoch[19] Batch [700]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.113748,	
2017-06-24 14:56:24,235 Epoch[19] Batch [710]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.113761,	
2017-06-24 14:56:31,742 Epoch[19] Batch [720]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.113693,	
2017-06-24 14:56:39,678 Epoch[19] Batch [730]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113644,	
2017-06-24 14:56:48,256 Epoch[19] Batch [740]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.113599,	
2017-06-24 14:56:49,870 Epoch[19] Train-FCNLogLoss=0.113542
2017-06-24 14:56:49,871 Epoch[19] Time cost=615.399
2017-06-24 14:56:51,565 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0020.params"
2017-06-24 14:56:53,727 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0020.states"
2017-06-24 14:57:03,800 Epoch[20] Batch [10]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.108320,	
2017-06-24 14:57:13,455 Epoch[20] Batch [20]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.109302,	
2017-06-24 14:57:22,977 Epoch[20] Batch [30]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.110860,	
2017-06-24 14:57:32,736 Epoch[20] Batch [40]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.111406,	
2017-06-24 14:57:42,432 Epoch[20] Batch [50]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.110363,	
2017-06-24 14:57:51,556 Epoch[20] Batch [60]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109700,	
2017-06-24 14:58:00,230 Epoch[20] Batch [70]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110028,	
2017-06-24 14:58:11,630 Epoch[20] Batch [80]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.110255,	
2017-06-24 14:58:21,051 Epoch[20] Batch [90]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.111265,	
2017-06-24 14:58:29,408 Epoch[20] Batch [100]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.111942,	
2017-06-24 14:58:39,918 Epoch[20] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112705,	
2017-06-24 14:58:51,539 Epoch[20] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.112783,	
2017-06-24 14:59:03,702 Epoch[20] Batch [130]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.112882,	
2017-06-24 14:59:15,526 Epoch[20] Batch [140]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.112325,	
2017-06-24 14:59:27,857 Epoch[20] Batch [150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.112153,	
2017-06-24 14:59:39,270 Epoch[20] Batch [160]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.111370,	
2017-06-24 14:59:49,898 Epoch[20] Batch [170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.111279,	
2017-06-24 15:00:00,021 Epoch[20] Batch [180]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.110984,	
2017-06-24 15:00:10,213 Epoch[20] Batch [190]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.110833,	
2017-06-24 15:00:19,542 Epoch[20] Batch [200]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.111182,	
2017-06-24 15:00:30,773 Epoch[20] Batch [210]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.110912,	
2017-06-24 15:00:43,651 Epoch[20] Batch [220]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.110868,	
2017-06-24 15:00:56,104 Epoch[20] Batch [230]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.111400,	
2017-06-24 15:01:07,689 Epoch[20] Batch [240]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.111249,	
2017-06-24 15:01:19,631 Epoch[20] Batch [250]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.111153,	
2017-06-24 15:01:31,356 Epoch[20] Batch [260]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.111125,	
2017-06-24 15:01:42,902 Epoch[20] Batch [270]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.110882,	
2017-06-24 15:01:53,892 Epoch[20] Batch [280]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.111113,	
2017-06-24 15:02:05,126 Epoch[20] Batch [290]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.111103,	
2017-06-24 15:02:16,631 Epoch[20] Batch [300]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.111223,	
2017-06-24 15:02:28,406 Epoch[20] Batch [310]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.111306,	
2017-06-24 15:02:39,448 Epoch[20] Batch [320]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.111581,	
2017-06-24 15:02:48,388 Epoch[20] Batch [330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.111961,	
2017-06-24 15:02:57,049 Epoch[20] Batch [340]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111954,	
2017-06-24 15:03:05,962 Epoch[20] Batch [350]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.112082,	
2017-06-24 15:03:15,244 Epoch[20] Batch [360]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.112322,	
2017-06-24 15:03:24,511 Epoch[20] Batch [370]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.112324,	
2017-06-24 15:03:32,911 Epoch[20] Batch [380]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.112525,	
2017-06-24 15:03:41,032 Epoch[20] Batch [390]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112283,	
2017-06-24 15:03:49,930 Epoch[20] Batch [400]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.112456,	
2017-06-24 15:03:57,934 Epoch[20] Batch [410]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112501,	
2017-06-24 15:04:05,772 Epoch[20] Batch [420]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112356,	
2017-06-24 15:04:14,077 Epoch[20] Batch [430]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112296,	
2017-06-24 15:04:23,168 Epoch[20] Batch [440]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.112032,	
2017-06-24 15:04:32,181 Epoch[20] Batch [450]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.111857,	
2017-06-24 15:04:41,429 Epoch[20] Batch [460]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.111636,	
2017-06-24 15:04:50,584 Epoch[20] Batch [470]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.111772,	
2017-06-24 15:04:58,898 Epoch[20] Batch [480]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.111691,	
2017-06-24 15:05:07,387 Epoch[20] Batch [490]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.111570,	
2017-06-24 15:05:16,114 Epoch[20] Batch [500]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.111388,	
2017-06-24 15:05:24,698 Epoch[20] Batch [510]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111461,	
2017-06-24 15:05:32,757 Epoch[20] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111718,	
2017-06-24 15:05:40,805 Epoch[20] Batch [530]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111689,	
2017-06-24 15:05:49,287 Epoch[20] Batch [540]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.111814,	
2017-06-24 15:05:57,521 Epoch[20] Batch [550]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112018,	
2017-06-24 15:06:05,182 Epoch[20] Batch [560]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.112300,	
2017-06-24 15:06:12,956 Epoch[20] Batch [570]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.112703,	
2017-06-24 15:06:21,080 Epoch[20] Batch [580]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112958,	
2017-06-24 15:06:29,978 Epoch[20] Batch [590]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.113130,	
2017-06-24 15:06:39,163 Epoch[20] Batch [600]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.113469,	
2017-06-24 15:06:47,490 Epoch[20] Batch [610]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.113703,	
2017-06-24 15:06:56,650 Epoch[20] Batch [620]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.113797,	
2017-06-24 15:07:05,939 Epoch[20] Batch [630]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.113987,	
2017-06-24 15:07:14,659 Epoch[20] Batch [640]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.114065,	
2017-06-24 15:07:23,492 Epoch[20] Batch [650]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.114080,	
2017-06-24 15:07:31,896 Epoch[20] Batch [660]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.114167,	
2017-06-24 15:07:40,303 Epoch[20] Batch [670]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.114136,	
2017-06-24 15:07:48,577 Epoch[20] Batch [680]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.114140,	
2017-06-24 15:07:56,848 Epoch[20] Batch [690]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113990,	
2017-06-24 15:08:04,884 Epoch[20] Batch [700]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113928,	
2017-06-24 15:08:12,664 Epoch[20] Batch [710]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.113811,	
2017-06-24 15:08:20,270 Epoch[20] Batch [720]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.113901,	
2017-06-24 15:08:27,907 Epoch[20] Batch [730]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.113769,	
2017-06-24 15:08:35,666 Epoch[20] Batch [740]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.113746,	
2017-06-24 15:08:37,190 Epoch[20] Train-FCNLogLoss=0.113710
2017-06-24 15:08:37,190 Epoch[20] Time cost=703.462
2017-06-24 15:08:38,962 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0021.params"
2017-06-24 15:08:40,813 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0021.states"
2017-06-24 15:08:49,883 Epoch[21] Batch [10]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.115354,	
2017-06-24 15:08:57,870 Epoch[21] Batch [20]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112242,	
2017-06-24 15:09:06,253 Epoch[21] Batch [30]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.116220,	
2017-06-24 15:09:15,938 Epoch[21] Batch [40]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.118455,	
2017-06-24 15:09:25,319 Epoch[21] Batch [50]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.117870,	
2017-06-24 15:09:34,312 Epoch[21] Batch [60]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.117489,	
2017-06-24 15:09:43,043 Epoch[21] Batch [70]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.117959,	
2017-06-24 15:09:50,945 Epoch[21] Batch [80]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.117484,	
2017-06-24 15:09:58,938 Epoch[21] Batch [90]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.115641,	
2017-06-24 15:10:06,745 Epoch[21] Batch [100]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.116292,	
2017-06-24 15:10:14,445 Epoch[21] Batch [110]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.117410,	
2017-06-24 15:10:22,191 Epoch[21] Batch [120]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.118880,	
2017-06-24 15:10:29,989 Epoch[21] Batch [130]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.119381,	
2017-06-24 15:10:38,721 Epoch[21] Batch [140]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.118969,	
2017-06-24 15:10:46,594 Epoch[21] Batch [150]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.118949,	
2017-06-24 15:10:54,741 Epoch[21] Batch [160]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.118775,	
2017-06-24 15:11:03,182 Epoch[21] Batch [170]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.118518,	
2017-06-24 15:11:12,702 Epoch[21] Batch [180]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.117976,	
2017-06-24 15:11:22,445 Epoch[21] Batch [190]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.118371,	
2017-06-24 15:11:31,277 Epoch[21] Batch [200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.118572,	
2017-06-24 15:11:40,164 Epoch[21] Batch [210]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.118054,	
2017-06-24 15:11:48,950 Epoch[21] Batch [220]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.117955,	
2017-06-24 15:11:57,587 Epoch[21] Batch [230]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.117713,	
2017-06-24 15:12:06,501 Epoch[21] Batch [240]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.117494,	
2017-06-24 15:12:14,957 Epoch[21] Batch [250]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117627,	
2017-06-24 15:12:23,003 Epoch[21] Batch [260]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117485,	
2017-06-24 15:12:30,940 Epoch[21] Batch [270]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118084,	
2017-06-24 15:12:38,921 Epoch[21] Batch [280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118226,	
2017-06-24 15:12:46,955 Epoch[21] Batch [290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.118334,	
2017-06-24 15:12:55,336 Epoch[21] Batch [300]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.118175,	
2017-06-24 15:13:04,113 Epoch[21] Batch [310]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.118249,	
2017-06-24 15:13:12,373 Epoch[21] Batch [320]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117862,	
2017-06-24 15:13:21,269 Epoch[21] Batch [330]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.117731,	
2017-06-24 15:13:31,245 Epoch[21] Batch [340]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.117355,	
2017-06-24 15:13:41,136 Epoch[21] Batch [350]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.117166,	
2017-06-24 15:13:50,516 Epoch[21] Batch [360]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.116878,	
2017-06-24 15:13:59,387 Epoch[21] Batch [370]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.116793,	
2017-06-24 15:14:08,137 Epoch[21] Batch [380]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.116776,	
2017-06-24 15:14:16,254 Epoch[21] Batch [390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116577,	
2017-06-24 15:14:24,159 Epoch[21] Batch [400]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.116302,	
2017-06-24 15:14:32,216 Epoch[21] Batch [410]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116180,	
2017-06-24 15:14:40,203 Epoch[21] Batch [420]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.115873,	
2017-06-24 15:14:48,463 Epoch[21] Batch [430]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.115627,	
2017-06-24 15:14:57,282 Epoch[21] Batch [440]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.115513,	
2017-06-24 15:15:07,039 Epoch[21] Batch [450]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.115366,	
2017-06-24 15:15:17,075 Epoch[21] Batch [460]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.115082,	
2017-06-24 15:15:27,536 Epoch[21] Batch [470]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.115199,	
2017-06-24 15:15:37,414 Epoch[21] Batch [480]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.115083,	
2017-06-24 15:15:46,910 Epoch[21] Batch [490]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.115062,	
2017-06-24 15:15:55,398 Epoch[21] Batch [500]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.114894,	
2017-06-24 15:16:03,739 Epoch[21] Batch [510]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.114849,	
2017-06-24 15:16:12,053 Epoch[21] Batch [520]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.114609,	
2017-06-24 15:16:20,197 Epoch[21] Batch [530]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114581,	
2017-06-24 15:16:28,552 Epoch[21] Batch [540]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114564,	
2017-06-24 15:16:36,725 Epoch[21] Batch [550]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114852,	
2017-06-24 15:16:45,626 Epoch[21] Batch [560]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.115268,	
2017-06-24 15:16:54,812 Epoch[21] Batch [570]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.115388,	
2017-06-24 15:17:03,741 Epoch[21] Batch [580]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.115465,	
2017-06-24 15:17:13,115 Epoch[21] Batch [590]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.115595,	
2017-06-24 15:17:22,847 Epoch[21] Batch [600]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.115589,	
2017-06-24 15:17:33,776 Epoch[21] Batch [610]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.115640,	
2017-06-24 15:17:43,546 Epoch[21] Batch [620]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.115633,	
2017-06-24 15:17:53,443 Epoch[21] Batch [630]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.115440,	
2017-06-24 15:18:02,669 Epoch[21] Batch [640]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.115173,	
2017-06-24 15:18:11,826 Epoch[21] Batch [650]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.115139,	
2017-06-24 15:18:20,345 Epoch[21] Batch [660]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.115049,	
2017-06-24 15:18:28,862 Epoch[21] Batch [670]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.115094,	
2017-06-24 15:18:37,608 Epoch[21] Batch [680]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.115013,	
2017-06-24 15:18:47,253 Epoch[21] Batch [690]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.114985,	
2017-06-24 15:18:56,890 Epoch[21] Batch [700]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.114888,	
2017-06-24 15:19:06,098 Epoch[21] Batch [710]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.114753,	
2017-06-24 15:19:16,165 Epoch[21] Batch [720]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.114554,	
2017-06-24 15:19:26,237 Epoch[21] Batch [730]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.114490,	
2017-06-24 15:19:36,008 Epoch[21] Batch [740]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.114228,	
2017-06-24 15:19:38,030 Epoch[21] Train-FCNLogLoss=0.114192
2017-06-24 15:19:38,030 Epoch[21] Time cost=657.217
2017-06-24 15:19:39,655 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0022.params"
2017-06-24 15:19:41,607 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0022.states"
2017-06-24 15:19:52,412 Epoch[22] Batch [10]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.098350,	
2017-06-24 15:20:00,330 Epoch[22] Batch [20]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.099304,	
2017-06-24 15:20:08,735 Epoch[22] Batch [30]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.101357,	
2017-06-24 15:20:16,646 Epoch[22] Batch [40]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.102970,	
2017-06-24 15:20:24,654 Epoch[22] Batch [50]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104284,	
2017-06-24 15:20:33,499 Epoch[22] Batch [60]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.105819,	
2017-06-24 15:20:42,345 Epoch[22] Batch [70]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.105057,	
2017-06-24 15:20:50,597 Epoch[22] Batch [80]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.105564,	
2017-06-24 15:21:00,643 Epoch[22] Batch [90]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.105437,	
2017-06-24 15:21:09,937 Epoch[22] Batch [100]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.106863,	
2017-06-24 15:21:19,414 Epoch[22] Batch [110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.107715,	
2017-06-24 15:21:29,308 Epoch[22] Batch [120]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.108232,	
2017-06-24 15:21:38,250 Epoch[22] Batch [130]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.108314,	
2017-06-24 15:21:46,704 Epoch[22] Batch [140]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.108258,	
2017-06-24 15:21:55,573 Epoch[22] Batch [150]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.108866,	
2017-06-24 15:22:04,482 Epoch[22] Batch [160]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.108456,	
2017-06-24 15:22:13,134 Epoch[22] Batch [170]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.108671,	
2017-06-24 15:22:21,487 Epoch[22] Batch [180]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.108536,	
2017-06-24 15:22:30,361 Epoch[22] Batch [190]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.108059,	
2017-06-24 15:22:39,281 Epoch[22] Batch [200]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108318,	
2017-06-24 15:22:48,720 Epoch[22] Batch [210]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.108329,	
2017-06-24 15:22:57,813 Epoch[22] Batch [220]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108752,	
2017-06-24 15:23:06,220 Epoch[22] Batch [230]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.108886,	
2017-06-24 15:23:14,809 Epoch[22] Batch [240]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.109025,	
2017-06-24 15:23:24,230 Epoch[22] Batch [250]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.109036,	
2017-06-24 15:23:32,516 Epoch[22] Batch [260]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.108742,	
2017-06-24 15:23:40,687 Epoch[22] Batch [270]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109000,	
2017-06-24 15:23:49,381 Epoch[22] Batch [280]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.108904,	
2017-06-24 15:23:57,621 Epoch[22] Batch [290]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.108993,	
2017-06-24 15:24:06,224 Epoch[22] Batch [300]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.109275,	
2017-06-24 15:24:14,807 Epoch[22] Batch [310]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.109455,	
2017-06-24 15:24:23,179 Epoch[22] Batch [320]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.109316,	
2017-06-24 15:24:31,372 Epoch[22] Batch [330]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.109429,	
2017-06-24 15:24:40,306 Epoch[22] Batch [340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.109403,	
2017-06-24 15:24:50,099 Epoch[22] Batch [350]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.109269,	
2017-06-24 15:24:58,758 Epoch[22] Batch [360]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.109201,	
2017-06-24 15:25:07,235 Epoch[22] Batch [370]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109186,	
2017-06-24 15:25:16,040 Epoch[22] Batch [380]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.109399,	
2017-06-24 15:25:24,940 Epoch[22] Batch [390]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.109163,	
2017-06-24 15:25:33,855 Epoch[22] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.109122,	
2017-06-24 15:25:42,107 Epoch[22] Batch [410]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.108995,	
2017-06-24 15:25:50,822 Epoch[22] Batch [420]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108822,	
2017-06-24 15:25:59,393 Epoch[22] Batch [430]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.108916,	
2017-06-24 15:26:08,291 Epoch[22] Batch [440]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.109067,	
2017-06-24 15:26:17,094 Epoch[22] Batch [450]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108916,	
2017-06-24 15:26:25,035 Epoch[22] Batch [460]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.108939,	
2017-06-24 15:26:33,159 Epoch[22] Batch [470]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.108783,	
2017-06-24 15:26:41,842 Epoch[22] Batch [480]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108716,	
2017-06-24 15:26:50,066 Epoch[22] Batch [490]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.108868,	
2017-06-24 15:26:58,630 Epoch[22] Batch [500]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.108807,	
2017-06-24 15:27:07,802 Epoch[22] Batch [510]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.108847,	
2017-06-24 15:27:17,491 Epoch[22] Batch [520]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.108789,	
2017-06-24 15:27:28,746 Epoch[22] Batch [530]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.108737,	
2017-06-24 15:27:39,379 Epoch[22] Batch [540]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.108809,	
2017-06-24 15:27:49,600 Epoch[22] Batch [550]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.108734,	
2017-06-24 15:27:58,910 Epoch[22] Batch [560]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.108749,	
2017-06-24 15:28:08,152 Epoch[22] Batch [570]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.108870,	
2017-06-24 15:28:16,527 Epoch[22] Batch [580]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108897,	
2017-06-24 15:28:24,833 Epoch[22] Batch [590]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.108940,	
2017-06-24 15:28:33,247 Epoch[22] Batch [600]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.109042,	
2017-06-24 15:28:42,098 Epoch[22] Batch [610]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.109066,	
2017-06-24 15:28:50,967 Epoch[22] Batch [620]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.109026,	
2017-06-24 15:28:59,818 Epoch[22] Batch [630]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.109040,	
2017-06-24 15:29:08,145 Epoch[22] Batch [640]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.108873,	
2017-06-24 15:29:16,529 Epoch[22] Batch [650]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.108864,	
2017-06-24 15:29:25,425 Epoch[22] Batch [660]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.108828,	
2017-06-24 15:29:35,283 Epoch[22] Batch [670]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.108850,	
2017-06-24 15:29:44,176 Epoch[22] Batch [680]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.108816,	
2017-06-24 15:29:52,883 Epoch[22] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.109230,	
2017-06-24 15:30:01,552 Epoch[22] Batch [700]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.109358,	
2017-06-24 15:30:10,305 Epoch[22] Batch [710]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.109429,	
2017-06-24 15:30:19,219 Epoch[22] Batch [720]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.109743,	
2017-06-24 15:30:27,708 Epoch[22] Batch [730]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.109911,	
2017-06-24 15:30:36,297 Epoch[22] Batch [740]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.110185,	
2017-06-24 15:30:37,930 Epoch[22] Train-FCNLogLoss=0.110260
2017-06-24 15:30:37,930 Epoch[22] Time cost=656.323
2017-06-24 15:30:39,526 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0023.params"
2017-06-24 15:30:41,524 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0023.states"
2017-06-24 15:30:52,350 Epoch[23] Batch [10]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.131376,	
2017-06-24 15:31:00,959 Epoch[23] Batch [20]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.123054,	
2017-06-24 15:31:10,019 Epoch[23] Batch [30]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.121891,	
2017-06-24 15:31:19,109 Epoch[23] Batch [40]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.118798,	
2017-06-24 15:31:28,143 Epoch[23] Batch [50]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.116599,	
2017-06-24 15:31:37,968 Epoch[23] Batch [60]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.115855,	
2017-06-24 15:31:46,654 Epoch[23] Batch [70]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.114800,	
2017-06-24 15:31:55,657 Epoch[23] Batch [80]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.114029,	
2017-06-24 15:32:04,418 Epoch[23] Batch [90]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.114193,	
2017-06-24 15:32:13,200 Epoch[23] Batch [100]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.113360,	
2017-06-24 15:32:21,878 Epoch[23] Batch [110]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.113380,	
2017-06-24 15:32:30,474 Epoch[23] Batch [120]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.113550,	
2017-06-24 15:32:39,468 Epoch[23] Batch [130]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.113811,	
2017-06-24 15:32:48,412 Epoch[23] Batch [140]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.113810,	
2017-06-24 15:32:57,537 Epoch[23] Batch [150]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.113658,	
2017-06-24 15:33:06,040 Epoch[23] Batch [160]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112784,	
2017-06-24 15:33:14,714 Epoch[23] Batch [170]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.112571,	
2017-06-24 15:33:23,744 Epoch[23] Batch [180]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.112251,	
2017-06-24 15:33:32,488 Epoch[23] Batch [190]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.112427,	
2017-06-24 15:33:41,091 Epoch[23] Batch [200]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.112239,	
2017-06-24 15:33:50,172 Epoch[23] Batch [210]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112053,	
2017-06-24 15:33:59,188 Epoch[23] Batch [220]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.112092,	
2017-06-24 15:34:08,355 Epoch[23] Batch [230]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.112112,	
2017-06-24 15:34:16,692 Epoch[23] Batch [240]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.112176,	
2017-06-24 15:34:25,792 Epoch[23] Batch [250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.112114,	
2017-06-24 15:34:34,961 Epoch[23] Batch [260]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.111620,	
2017-06-24 15:34:43,705 Epoch[23] Batch [270]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.111446,	
2017-06-24 15:34:52,421 Epoch[23] Batch [280]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.111606,	
2017-06-24 15:35:01,569 Epoch[23] Batch [290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.111795,	
2017-06-24 15:35:10,499 Epoch[23] Batch [300]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.111728,	
2017-06-24 15:35:19,936 Epoch[23] Batch [310]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.111817,	
2017-06-24 15:35:30,253 Epoch[23] Batch [320]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.111559,	
2017-06-24 15:35:39,597 Epoch[23] Batch [330]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.111524,	
2017-06-24 15:35:49,277 Epoch[23] Batch [340]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.111341,	
2017-06-24 15:35:58,892 Epoch[23] Batch [350]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.111274,	
2017-06-24 15:36:07,179 Epoch[23] Batch [360]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.111504,	
2017-06-24 15:36:15,801 Epoch[23] Batch [370]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.111426,	
2017-06-24 15:36:25,035 Epoch[23] Batch [380]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.111164,	
2017-06-24 15:36:35,973 Epoch[23] Batch [390]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.110814,	
2017-06-24 15:36:45,895 Epoch[23] Batch [400]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.110802,	
2017-06-24 15:36:56,528 Epoch[23] Batch [410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.110749,	
2017-06-24 15:37:08,266 Epoch[23] Batch [420]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.110769,	
2017-06-24 15:37:18,643 Epoch[23] Batch [430]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.110703,	
2017-06-24 15:37:28,281 Epoch[23] Batch [440]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.110637,	
2017-06-24 15:37:37,795 Epoch[23] Batch [450]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.110690,	
2017-06-24 15:37:47,843 Epoch[23] Batch [460]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.110526,	
2017-06-24 15:37:56,408 Epoch[23] Batch [470]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.110317,	
2017-06-24 15:38:05,273 Epoch[23] Batch [480]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.110305,	
2017-06-24 15:38:13,365 Epoch[23] Batch [490]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110171,	
2017-06-24 15:38:21,414 Epoch[23] Batch [500]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.109984,	
2017-06-24 15:38:29,194 Epoch[23] Batch [510]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.109747,	
2017-06-24 15:38:36,722 Epoch[23] Batch [520]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.109813,	
2017-06-24 15:38:44,215 Epoch[23] Batch [530]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.109931,	
2017-06-24 15:38:52,241 Epoch[23] Batch [540]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.110073,	
2017-06-24 15:39:00,017 Epoch[23] Batch [550]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.110093,	
2017-06-24 15:39:08,150 Epoch[23] Batch [560]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.110045,	
2017-06-24 15:39:16,563 Epoch[23] Batch [570]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110005,	
2017-06-24 15:39:24,598 Epoch[23] Batch [580]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.109878,	
2017-06-24 15:39:32,014 Epoch[23] Batch [590]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.109932,	
2017-06-24 15:39:39,668 Epoch[23] Batch [600]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.109896,	
2017-06-24 15:39:47,266 Epoch[23] Batch [610]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.109747,	
2017-06-24 15:39:54,907 Epoch[23] Batch [620]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.109709,	
2017-06-24 15:40:02,041 Epoch[23] Batch [630]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.109677,	
2017-06-24 15:40:09,153 Epoch[23] Batch [640]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.109649,	
2017-06-24 15:40:16,684 Epoch[23] Batch [650]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.109654,	
2017-06-24 15:40:24,728 Epoch[23] Batch [660]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.109530,	
2017-06-24 15:40:32,139 Epoch[23] Batch [670]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.109418,	
2017-06-24 15:40:40,217 Epoch[23] Batch [680]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109353,	
2017-06-24 15:40:47,818 Epoch[23] Batch [690]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.109214,	
2017-06-24 15:40:55,585 Epoch[23] Batch [700]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.109129,	
2017-06-24 15:41:03,430 Epoch[23] Batch [710]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.109149,	
2017-06-24 15:41:12,140 Epoch[23] Batch [720]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.109101,	
2017-06-24 15:41:20,434 Epoch[23] Batch [730]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.109056,	
2017-06-24 15:41:28,595 Epoch[23] Batch [740]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108989,	
2017-06-24 15:41:30,099 Epoch[23] Train-FCNLogLoss=0.108936
2017-06-24 15:41:30,099 Epoch[23] Time cost=648.574
2017-06-24 15:41:31,842 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0024.params"
2017-06-24 15:41:33,858 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0024.states"
2017-06-24 15:41:42,822 Epoch[24] Batch [10]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.104662,	
2017-06-24 15:41:51,449 Epoch[24] Batch [20]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.105508,	
2017-06-24 15:41:59,389 Epoch[24] Batch [30]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.105781,	
2017-06-24 15:42:07,033 Epoch[24] Batch [40]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.105041,	
2017-06-24 15:42:15,242 Epoch[24] Batch [50]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105060,	
2017-06-24 15:42:23,791 Epoch[24] Batch [60]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.107559,	
2017-06-24 15:42:32,968 Epoch[24] Batch [70]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.107354,	
2017-06-24 15:42:41,365 Epoch[24] Batch [80]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.107917,	
2017-06-24 15:42:48,794 Epoch[24] Batch [90]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.107574,	
2017-06-24 15:42:56,746 Epoch[24] Batch [100]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.108061,	
2017-06-24 15:43:04,707 Epoch[24] Batch [110]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.108213,	
2017-06-24 15:43:12,855 Epoch[24] Batch [120]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.107796,	
2017-06-24 15:43:21,122 Epoch[24] Batch [130]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108411,	
2017-06-24 15:43:29,026 Epoch[24] Batch [140]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.108412,	
2017-06-24 15:43:36,782 Epoch[24] Batch [150]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.108799,	
2017-06-24 15:43:44,468 Epoch[24] Batch [160]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.109121,	
2017-06-24 15:43:52,962 Epoch[24] Batch [170]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.108816,	
2017-06-24 15:44:00,927 Epoch[24] Batch [180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.108820,	
2017-06-24 15:44:09,818 Epoch[24] Batch [190]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.108089,	
2017-06-24 15:44:17,879 Epoch[24] Batch [200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107884,	
2017-06-24 15:44:26,237 Epoch[24] Batch [210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.107423,	
2017-06-24 15:44:34,089 Epoch[24] Batch [220]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.106974,	
2017-06-24 15:44:42,167 Epoch[24] Batch [230]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.106977,	
2017-06-24 15:44:50,125 Epoch[24] Batch [240]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.106810,	
2017-06-24 15:44:57,990 Epoch[24] Batch [250]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.106755,	
2017-06-24 15:45:05,870 Epoch[24] Batch [260]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.106521,	
2017-06-24 15:45:13,444 Epoch[24] Batch [270]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.106836,	
2017-06-24 15:45:21,432 Epoch[24] Batch [280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106840,	
2017-06-24 15:45:29,186 Epoch[24] Batch [290]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.107150,	
2017-06-24 15:45:37,105 Epoch[24] Batch [300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.107279,	
2017-06-24 15:45:45,576 Epoch[24] Batch [310]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.107045,	
2017-06-24 15:45:54,075 Epoch[24] Batch [320]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.106869,	
2017-06-24 15:46:02,932 Epoch[24] Batch [330]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.106858,	
2017-06-24 15:46:11,686 Epoch[24] Batch [340]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.107048,	
2017-06-24 15:46:19,678 Epoch[24] Batch [350]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107033,	
2017-06-24 15:46:27,175 Epoch[24] Batch [360]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.106953,	
2017-06-24 15:46:35,162 Epoch[24] Batch [370]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106911,	
2017-06-24 15:46:42,736 Epoch[24] Batch [380]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.107029,	
2017-06-24 15:46:50,651 Epoch[24] Batch [390]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107504,	
2017-06-24 15:46:59,311 Epoch[24] Batch [400]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.107515,	
2017-06-24 15:47:07,890 Epoch[24] Batch [410]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.107624,	
2017-06-24 15:47:16,389 Epoch[24] Batch [420]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.107582,	
2017-06-24 15:47:25,771 Epoch[24] Batch [430]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107556,	
2017-06-24 15:47:34,002 Epoch[24] Batch [440]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.107595,	
2017-06-24 15:47:42,573 Epoch[24] Batch [450]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.107582,	
2017-06-24 15:47:51,239 Epoch[24] Batch [460]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.107679,	
2017-06-24 15:47:59,893 Epoch[24] Batch [470]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.107694,	
2017-06-24 15:48:08,740 Epoch[24] Batch [480]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.107532,	
2017-06-24 15:48:17,612 Epoch[24] Batch [490]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.107605,	
2017-06-24 15:48:25,863 Epoch[24] Batch [500]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.107797,	
2017-06-24 15:48:35,116 Epoch[24] Batch [510]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.107827,	
2017-06-24 15:48:44,530 Epoch[24] Batch [520]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.107910,	
2017-06-24 15:48:52,762 Epoch[24] Batch [530]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.108039,	
2017-06-24 15:49:01,136 Epoch[24] Batch [540]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108061,	
2017-06-24 15:49:08,931 Epoch[24] Batch [550]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.108087,	
2017-06-24 15:49:16,835 Epoch[24] Batch [560]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.108079,	
2017-06-24 15:49:25,529 Epoch[24] Batch [570]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.107987,	
2017-06-24 15:49:33,235 Epoch[24] Batch [580]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.108024,	
2017-06-24 15:49:42,096 Epoch[24] Batch [590]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.107830,	
2017-06-24 15:49:50,645 Epoch[24] Batch [600]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.107749,	
2017-06-24 15:49:58,173 Epoch[24] Batch [610]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.107794,	
2017-06-24 15:50:05,964 Epoch[24] Batch [620]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.107885,	
2017-06-24 15:50:13,920 Epoch[24] Batch [630]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.107845,	
2017-06-24 15:50:22,245 Epoch[24] Batch [640]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.107779,	
2017-06-24 15:50:30,161 Epoch[24] Batch [650]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107784,	
2017-06-24 15:50:38,704 Epoch[24] Batch [660]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.107848,	
2017-06-24 15:50:47,795 Epoch[24] Batch [670]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107821,	
2017-06-24 15:50:56,505 Epoch[24] Batch [680]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.107776,	
2017-06-24 15:51:05,016 Epoch[24] Batch [690]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.107798,	
2017-06-24 15:51:13,465 Epoch[24] Batch [700]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.107866,	
2017-06-24 15:51:21,703 Epoch[24] Batch [710]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.107912,	
2017-06-24 15:51:29,502 Epoch[24] Batch [720]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.107798,	
2017-06-24 15:51:37,137 Epoch[24] Batch [730]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.107636,	
2017-06-24 15:51:45,264 Epoch[24] Batch [740]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.107661,	
2017-06-24 15:51:47,286 Epoch[24] Train-FCNLogLoss=0.107631
2017-06-24 15:51:47,286 Epoch[24] Time cost=613.427
2017-06-24 15:51:48,857 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0025.params"
2017-06-24 15:51:50,706 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0025.states"
2017-06-24 15:52:00,161 Epoch[25] Batch [10]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.099446,	
2017-06-24 15:52:07,667 Epoch[25] Batch [20]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.104650,	
2017-06-24 15:52:15,566 Epoch[25] Batch [30]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.106495,	
2017-06-24 15:52:23,788 Epoch[25] Batch [40]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.107510,	
2017-06-24 15:52:32,139 Epoch[25] Batch [50]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.107659,	
2017-06-24 15:52:39,892 Epoch[25] Batch [60]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.107059,	
2017-06-24 15:52:48,098 Epoch[25] Batch [70]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.106531,	
2017-06-24 15:52:56,487 Epoch[25] Batch [80]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.105435,	
2017-06-24 15:53:04,775 Epoch[25] Batch [90]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105442,	
2017-06-24 15:53:12,820 Epoch[25] Batch [100]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105409,	
2017-06-24 15:53:20,918 Epoch[25] Batch [110]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104697,	
2017-06-24 15:53:29,428 Epoch[25] Batch [120]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.105097,	
2017-06-24 15:53:38,368 Epoch[25] Batch [130]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.105210,	
2017-06-24 15:53:46,681 Epoch[25] Batch [140]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.105271,	
2017-06-24 15:53:54,788 Epoch[25] Batch [150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105422,	
2017-06-24 15:54:03,503 Epoch[25] Batch [160]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.105468,	
2017-06-24 15:54:12,001 Epoch[25] Batch [170]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.104797,	
2017-06-24 15:54:20,300 Epoch[25] Batch [180]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.104838,	
2017-06-24 15:54:28,825 Epoch[25] Batch [190]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.105026,	
2017-06-24 15:54:36,440 Epoch[25] Batch [200]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.105259,	
2017-06-24 15:54:45,037 Epoch[25] Batch [210]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105043,	
2017-06-24 15:54:53,492 Epoch[25] Batch [220]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.105207,	
2017-06-24 15:55:03,003 Epoch[25] Batch [230]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.105183,	
2017-06-24 15:55:11,726 Epoch[25] Batch [240]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.105035,	
2017-06-24 15:55:20,098 Epoch[25] Batch [250]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.105266,	
2017-06-24 15:55:28,576 Epoch[25] Batch [260]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.105296,	
2017-06-24 15:55:36,743 Epoch[25] Batch [270]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105449,	
2017-06-24 15:55:45,329 Epoch[25] Batch [280]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.105152,	
2017-06-24 15:55:53,597 Epoch[25] Batch [290]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105094,	
2017-06-24 15:56:02,229 Epoch[25] Batch [300]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.104950,	
2017-06-24 15:56:11,141 Epoch[25] Batch [310]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.105134,	
2017-06-24 15:56:19,492 Epoch[25] Batch [320]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.104954,	
2017-06-24 15:56:28,154 Epoch[25] Batch [330]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.105020,	
2017-06-24 15:56:36,793 Epoch[25] Batch [340]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.105296,	
2017-06-24 15:56:45,384 Epoch[25] Batch [350]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105443,	
2017-06-24 15:56:53,980 Epoch[25] Batch [360]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105641,	
2017-06-24 15:57:01,976 Epoch[25] Batch [370]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105737,	
2017-06-24 15:57:10,470 Epoch[25] Batch [380]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.105585,	
2017-06-24 15:57:20,139 Epoch[25] Batch [390]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.105704,	
2017-06-24 15:57:29,058 Epoch[25] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.105824,	
2017-06-24 15:57:37,173 Epoch[25] Batch [410]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105794,	
2017-06-24 15:57:44,967 Epoch[25] Batch [420]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.105678,	
2017-06-24 15:57:53,504 Epoch[25] Batch [430]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.105515,	
2017-06-24 15:58:01,734 Epoch[25] Batch [440]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.105482,	
2017-06-24 15:58:09,700 Epoch[25] Batch [450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.105631,	
2017-06-24 15:58:17,702 Epoch[25] Batch [460]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105556,	
2017-06-24 15:58:25,709 Epoch[25] Batch [470]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.105335,	
2017-06-24 15:58:33,583 Epoch[25] Batch [480]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.105204,	
2017-06-24 15:58:42,152 Epoch[25] Batch [490]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.105143,	
2017-06-24 15:58:50,602 Epoch[25] Batch [500]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105329,	
2017-06-24 15:59:00,290 Epoch[25] Batch [510]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.105313,	
2017-06-24 15:59:10,045 Epoch[25] Batch [520]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.105337,	
2017-06-24 15:59:19,761 Epoch[25] Batch [530]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.105281,	
2017-06-24 15:59:29,141 Epoch[25] Batch [540]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.105184,	
2017-06-24 15:59:38,697 Epoch[25] Batch [550]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.105271,	
2017-06-24 15:59:48,536 Epoch[25] Batch [560]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.105310,	
2017-06-24 15:59:56,543 Epoch[25] Batch [570]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.105276,	
2017-06-24 16:00:04,959 Epoch[25] Batch [580]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.105339,	
2017-06-24 16:00:13,235 Epoch[25] Batch [590]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105294,	
2017-06-24 16:00:21,877 Epoch[25] Batch [600]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.105230,	
2017-06-24 16:00:31,203 Epoch[25] Batch [610]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105308,	
2017-06-24 16:00:40,296 Epoch[25] Batch [620]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.105294,	
2017-06-24 16:00:48,864 Epoch[25] Batch [630]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.105206,	
2017-06-24 16:00:57,700 Epoch[25] Batch [640]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.105198,	
2017-06-24 16:01:07,269 Epoch[25] Batch [650]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.105287,	
2017-06-24 16:01:15,931 Epoch[25] Batch [660]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.105123,	
2017-06-24 16:01:24,764 Epoch[25] Batch [670]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.105073,	
2017-06-24 16:01:34,260 Epoch[25] Batch [680]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.105037,	
2017-06-24 16:01:43,224 Epoch[25] Batch [690]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.105016,	
2017-06-24 16:01:52,327 Epoch[25] Batch [700]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104952,	
2017-06-24 16:02:00,975 Epoch[25] Batch [710]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.104927,	
2017-06-24 16:02:10,301 Epoch[25] Batch [720]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.104942,	
2017-06-24 16:02:19,784 Epoch[25] Batch [730]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.104926,	
2017-06-24 16:02:29,114 Epoch[25] Batch [740]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.104944,	
2017-06-24 16:02:30,943 Epoch[25] Train-FCNLogLoss=0.104905
2017-06-24 16:02:30,943 Epoch[25] Time cost=640.236
2017-06-24 16:02:32,455 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0026.params"
2017-06-24 16:02:34,342 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0026.states"
2017-06-24 16:02:44,396 Epoch[26] Batch [10]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.104040,	
2017-06-24 16:02:53,602 Epoch[26] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.106495,	
2017-06-24 16:03:02,710 Epoch[26] Batch [30]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.106535,	
2017-06-24 16:03:12,640 Epoch[26] Batch [40]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.106501,	
2017-06-24 16:03:22,422 Epoch[26] Batch [50]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.104130,	
2017-06-24 16:03:31,962 Epoch[26] Batch [60]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.104276,	
2017-06-24 16:03:41,395 Epoch[26] Batch [70]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.102928,	
2017-06-24 16:03:50,637 Epoch[26] Batch [80]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.102928,	
2017-06-24 16:04:00,380 Epoch[26] Batch [90]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.102667,	
2017-06-24 16:04:10,285 Epoch[26] Batch [100]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.102654,	
2017-06-24 16:04:20,000 Epoch[26] Batch [110]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.102943,	
2017-06-24 16:04:30,387 Epoch[26] Batch [120]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.103547,	
2017-06-24 16:04:39,902 Epoch[26] Batch [130]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.103049,	
2017-06-24 16:04:49,287 Epoch[26] Batch [140]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.102742,	
2017-06-24 16:04:58,482 Epoch[26] Batch [150]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.102688,	
2017-06-24 16:05:08,055 Epoch[26] Batch [160]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.103031,	
2017-06-24 16:05:17,787 Epoch[26] Batch [170]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.103469,	
2017-06-24 16:05:26,886 Epoch[26] Batch [180]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.103419,	
2017-06-24 16:05:36,336 Epoch[26] Batch [190]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.103248,	
2017-06-24 16:05:46,390 Epoch[26] Batch [200]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.103658,	
2017-06-24 16:05:56,237 Epoch[26] Batch [210]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.104102,	
2017-06-24 16:06:05,686 Epoch[26] Batch [220]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.104552,	
2017-06-24 16:06:16,088 Epoch[26] Batch [230]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.104865,	
2017-06-24 16:06:26,707 Epoch[26] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.104894,	
2017-06-24 16:06:36,745 Epoch[26] Batch [250]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.104952,	
2017-06-24 16:06:46,179 Epoch[26] Batch [260]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.104675,	
2017-06-24 16:06:55,607 Epoch[26] Batch [270]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104571,	
2017-06-24 16:07:05,004 Epoch[26] Batch [280]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.104562,	
2017-06-24 16:07:13,653 Epoch[26] Batch [290]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.104897,	
2017-06-24 16:07:22,179 Epoch[26] Batch [300]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.104454,	
2017-06-24 16:07:31,414 Epoch[26] Batch [310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.104505,	
2017-06-24 16:07:40,642 Epoch[26] Batch [320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.104416,	
2017-06-24 16:07:49,862 Epoch[26] Batch [330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.104482,	
2017-06-24 16:07:59,602 Epoch[26] Batch [340]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.104274,	
2017-06-24 16:08:09,998 Epoch[26] Batch [350]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.104279,	
2017-06-24 16:08:19,898 Epoch[26] Batch [360]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.104218,	
2017-06-24 16:08:28,871 Epoch[26] Batch [370]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.104232,	
2017-06-24 16:08:37,601 Epoch[26] Batch [380]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.104105,	
2017-06-24 16:08:46,299 Epoch[26] Batch [390]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.104299,	
2017-06-24 16:08:56,036 Epoch[26] Batch [400]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.104292,	
2017-06-24 16:09:05,872 Epoch[26] Batch [410]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.104391,	
2017-06-24 16:09:15,024 Epoch[26] Batch [420]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.104390,	
2017-06-24 16:09:24,078 Epoch[26] Batch [430]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.105112,	
2017-06-24 16:09:33,442 Epoch[26] Batch [440]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.105137,	
2017-06-24 16:09:42,474 Epoch[26] Batch [450]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.105424,	
2017-06-24 16:09:51,119 Epoch[26] Batch [460]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.105358,	
2017-06-24 16:10:00,502 Epoch[26] Batch [470]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.105407,	
2017-06-24 16:10:09,828 Epoch[26] Batch [480]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105274,	
2017-06-24 16:10:19,597 Epoch[26] Batch [490]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.105080,	
2017-06-24 16:10:29,354 Epoch[26] Batch [500]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.105027,	
2017-06-24 16:10:39,717 Epoch[26] Batch [510]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105051,	
2017-06-24 16:10:49,972 Epoch[26] Batch [520]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.105185,	
2017-06-24 16:10:59,939 Epoch[26] Batch [530]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.105044,	
2017-06-24 16:11:10,172 Epoch[26] Batch [540]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.105021,	
2017-06-24 16:11:20,389 Epoch[26] Batch [550]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.104970,	
2017-06-24 16:11:30,669 Epoch[26] Batch [560]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.105045,	
2017-06-24 16:11:40,160 Epoch[26] Batch [570]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.105040,	
2017-06-24 16:11:49,593 Epoch[26] Batch [580]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.104938,	
2017-06-24 16:11:58,697 Epoch[26] Batch [590]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104939,	
2017-06-24 16:12:07,951 Epoch[26] Batch [600]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.104900,	
2017-06-24 16:12:17,632 Epoch[26] Batch [610]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.104947,	
2017-06-24 16:12:27,149 Epoch[26] Batch [620]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.104862,	
2017-06-24 16:12:36,664 Epoch[26] Batch [630]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.104738,	
2017-06-24 16:12:45,751 Epoch[26] Batch [640]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.104725,	
2017-06-24 16:12:54,640 Epoch[26] Batch [650]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.104682,	
2017-06-24 16:13:03,618 Epoch[26] Batch [660]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104653,	
2017-06-24 16:13:12,410 Epoch[26] Batch [670]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.104637,	
2017-06-24 16:13:21,037 Epoch[26] Batch [680]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.104665,	
2017-06-24 16:13:30,387 Epoch[26] Batch [690]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.104609,	
2017-06-24 16:13:39,661 Epoch[26] Batch [700]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.104498,	
2017-06-24 16:13:49,077 Epoch[26] Batch [710]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.104523,	
2017-06-24 16:13:59,169 Epoch[26] Batch [720]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.104477,	
2017-06-24 16:14:09,157 Epoch[26] Batch [730]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.104581,	
2017-06-24 16:14:18,630 Epoch[26] Batch [740]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.104574,	
2017-06-24 16:14:20,217 Epoch[26] Train-FCNLogLoss=0.104548
2017-06-24 16:14:20,217 Epoch[26] Time cost=705.875
2017-06-24 16:14:21,582 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0027.params"
2017-06-24 16:14:23,418 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0027.states"
2017-06-24 16:14:34,322 Epoch[27] Batch [10]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.096408,	
2017-06-24 16:14:44,029 Epoch[27] Batch [20]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.096092,	
2017-06-24 16:14:53,850 Epoch[27] Batch [30]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-24 16:15:04,017 Epoch[27] Batch [40]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.099608,	
2017-06-24 16:15:14,345 Epoch[27] Batch [50]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.102840,	
2017-06-24 16:15:23,659 Epoch[27] Batch [60]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.102461,	
2017-06-24 16:15:32,917 Epoch[27] Batch [70]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.101605,	
2017-06-24 16:15:42,143 Epoch[27] Batch [80]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.102914,	
2017-06-24 16:15:51,328 Epoch[27] Batch [90]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.102722,	
2017-06-24 16:16:00,337 Epoch[27] Batch [100]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.102482,	
2017-06-24 16:16:10,442 Epoch[27] Batch [110]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.101967,	
2017-06-24 16:16:21,478 Epoch[27] Batch [120]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.102011,	
2017-06-24 16:16:31,153 Epoch[27] Batch [130]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.101909,	
2017-06-24 16:16:40,935 Epoch[27] Batch [140]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.101663,	
2017-06-24 16:16:50,385 Epoch[27] Batch [150]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.101590,	
2017-06-24 16:16:59,739 Epoch[27] Batch [160]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.101903,	
2017-06-24 16:17:09,082 Epoch[27] Batch [170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.101919,	
2017-06-24 16:17:18,040 Epoch[27] Batch [180]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.101574,	
2017-06-24 16:17:27,657 Epoch[27] Batch [190]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.102038,	
2017-06-24 16:17:37,599 Epoch[27] Batch [200]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.102254,	
2017-06-24 16:17:47,161 Epoch[27] Batch [210]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.101913,	
2017-06-24 16:17:56,534 Epoch[27] Batch [220]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.101769,	
2017-06-24 16:18:06,619 Epoch[27] Batch [230]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.101430,	
2017-06-24 16:18:16,039 Epoch[27] Batch [240]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.101516,	
2017-06-24 16:18:26,405 Epoch[27] Batch [250]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.101453,	
2017-06-24 16:18:37,057 Epoch[27] Batch [260]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101713,	
2017-06-24 16:18:46,976 Epoch[27] Batch [270]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.101790,	
2017-06-24 16:18:57,283 Epoch[27] Batch [280]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.102114,	
2017-06-24 16:19:07,575 Epoch[27] Batch [290]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.101966,	
2017-06-24 16:19:18,261 Epoch[27] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101943,	
2017-06-24 16:19:28,779 Epoch[27] Batch [310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.101726,	
2017-06-24 16:19:38,920 Epoch[27] Batch [320]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.101830,	
2017-06-24 16:19:49,407 Epoch[27] Batch [330]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.102234,	
2017-06-24 16:19:59,815 Epoch[27] Batch [340]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.102355,	
2017-06-24 16:20:09,826 Epoch[27] Batch [350]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.102326,	
2017-06-24 16:20:19,742 Epoch[27] Batch [360]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.102037,	
2017-06-24 16:20:29,907 Epoch[27] Batch [370]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.102265,	
2017-06-24 16:20:41,526 Epoch[27] Batch [380]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102321,	
2017-06-24 16:20:51,911 Epoch[27] Batch [390]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.102393,	
2017-06-24 16:21:02,480 Epoch[27] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.102610,	
2017-06-24 16:21:13,990 Epoch[27] Batch [410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.102683,	
2017-06-24 16:21:25,222 Epoch[27] Batch [420]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.102636,	
2017-06-24 16:21:36,969 Epoch[27] Batch [430]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.102530,	
2017-06-24 16:21:47,827 Epoch[27] Batch [440]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.102560,	
2017-06-24 16:21:58,866 Epoch[27] Batch [450]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.102572,	
2017-06-24 16:22:10,362 Epoch[27] Batch [460]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.102627,	
2017-06-24 16:22:21,729 Epoch[27] Batch [470]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.102511,	
2017-06-24 16:22:33,323 Epoch[27] Batch [480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102796,	
2017-06-24 16:22:43,833 Epoch[27] Batch [490]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.102641,	
2017-06-24 16:22:54,507 Epoch[27] Batch [500]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102599,	
2017-06-24 16:23:06,091 Epoch[27] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102699,	
2017-06-24 16:23:18,464 Epoch[27] Batch [520]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.102830,	
2017-06-24 16:23:30,079 Epoch[27] Batch [530]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102742,	
2017-06-24 16:23:41,735 Epoch[27] Batch [540]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102734,	
2017-06-24 16:23:52,798 Epoch[27] Batch [550]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.102675,	
2017-06-24 16:24:04,124 Epoch[27] Batch [560]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.102750,	
2017-06-24 16:24:15,536 Epoch[27] Batch [570]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.102674,	
2017-06-24 16:24:26,612 Epoch[27] Batch [580]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.102657,	
2017-06-24 16:24:37,923 Epoch[27] Batch [590]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.102559,	
2017-06-24 16:24:48,622 Epoch[27] Batch [600]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102459,	
2017-06-24 16:24:59,705 Epoch[27] Batch [610]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.102503,	
2017-06-24 16:25:09,597 Epoch[27] Batch [620]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.102538,	
2017-06-24 16:25:20,490 Epoch[27] Batch [630]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.102606,	
2017-06-24 16:25:30,965 Epoch[27] Batch [640]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.102645,	
2017-06-24 16:25:41,465 Epoch[27] Batch [650]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.102625,	
2017-06-24 16:25:51,350 Epoch[27] Batch [660]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.102649,	
2017-06-24 16:26:01,336 Epoch[27] Batch [670]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.102577,	
2017-06-24 16:26:11,653 Epoch[27] Batch [680]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.102497,	
2017-06-24 16:26:21,384 Epoch[27] Batch [690]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.102499,	
2017-06-24 16:26:30,880 Epoch[27] Batch [700]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.102469,	
2017-06-24 16:26:41,009 Epoch[27] Batch [710]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.102383,	
2017-06-24 16:26:51,640 Epoch[27] Batch [720]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.102384,	
2017-06-24 16:27:01,357 Epoch[27] Batch [730]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.102328,	
2017-06-24 16:27:12,196 Epoch[27] Batch [740]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.102321,	
2017-06-24 16:27:13,869 Epoch[27] Train-FCNLogLoss=0.102300
2017-06-24 16:27:13,869 Epoch[27] Time cost=770.450
2017-06-24 16:27:15,285 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0028.params"
2017-06-24 16:27:17,128 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0028.states"
2017-06-24 16:27:29,260 Epoch[28] Batch [10]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.099354,	
2017-06-24 16:27:38,725 Epoch[28] Batch [20]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.099589,	
2017-06-24 16:27:49,316 Epoch[28] Batch [30]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098813,	
2017-06-24 16:27:59,203 Epoch[28] Batch [40]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.097825,	
2017-06-24 16:28:08,642 Epoch[28] Batch [50]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.098036,	
2017-06-24 16:28:18,714 Epoch[28] Batch [60]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.098175,	
2017-06-24 16:28:29,515 Epoch[28] Batch [70]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098270,	
2017-06-24 16:28:40,331 Epoch[28] Batch [80]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.098190,	
2017-06-24 16:28:51,402 Epoch[28] Batch [90]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.097777,	
2017-06-24 16:29:01,996 Epoch[28] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098139,	
2017-06-24 16:29:13,222 Epoch[28] Batch [110]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098285,	
2017-06-24 16:29:24,499 Epoch[28] Batch [120]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.099310,	
2017-06-24 16:29:35,929 Epoch[28] Batch [130]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.099213,	
2017-06-24 16:29:47,940 Epoch[28] Batch [140]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.099327,	
2017-06-24 16:30:00,328 Epoch[28] Batch [150]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.099260,	
2017-06-24 16:30:12,900 Epoch[28] Batch [160]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.099298,	
2017-06-24 16:30:24,472 Epoch[28] Batch [170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099506,	
2017-06-24 16:30:36,512 Epoch[28] Batch [180]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099598,	
2017-06-24 16:30:47,954 Epoch[28] Batch [190]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.099755,	
2017-06-24 16:30:59,424 Epoch[28] Batch [200]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099968,	
2017-06-24 16:31:11,979 Epoch[28] Batch [210]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.100021,	
2017-06-24 16:31:24,822 Epoch[28] Batch [220]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.100248,	
2017-06-24 16:31:36,391 Epoch[28] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100375,	
2017-06-24 16:31:48,084 Epoch[28] Batch [240]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100193,	
2017-06-24 16:32:00,146 Epoch[28] Batch [250]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100027,	
2017-06-24 16:32:11,202 Epoch[28] Batch [260]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.100048,	
2017-06-24 16:32:22,529 Epoch[28] Batch [270]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.100571,	
2017-06-24 16:32:33,908 Epoch[28] Batch [280]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.100797,	
2017-06-24 16:32:46,970 Epoch[28] Batch [290]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.100720,	
2017-06-24 16:32:58,824 Epoch[28] Batch [300]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.101035,	
2017-06-24 16:33:11,570 Epoch[28] Batch [310]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.101095,	
2017-06-24 16:33:24,032 Epoch[28] Batch [320]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.100913,	
2017-06-24 16:33:35,904 Epoch[28] Batch [330]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.100751,	
2017-06-24 16:33:47,606 Epoch[28] Batch [340]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.101011,	
2017-06-24 16:33:58,286 Epoch[28] Batch [350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101011,	
2017-06-24 16:34:09,391 Epoch[28] Batch [360]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.100987,	
2017-06-24 16:34:22,517 Epoch[28] Batch [370]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.101077,	
2017-06-24 16:34:35,111 Epoch[28] Batch [380]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.101564,	
2017-06-24 16:34:48,172 Epoch[28] Batch [390]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.101436,	
2017-06-24 16:35:00,511 Epoch[28] Batch [400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101496,	
2017-06-24 16:35:11,872 Epoch[28] Batch [410]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.101366,	
2017-06-24 16:35:23,951 Epoch[28] Batch [420]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101351,	
2017-06-24 16:35:36,078 Epoch[28] Batch [430]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101395,	
2017-06-24 16:35:47,947 Epoch[28] Batch [440]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101723,	
2017-06-24 16:36:00,488 Epoch[28] Batch [450]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.101932,	
2017-06-24 16:36:12,330 Epoch[28] Batch [460]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101959,	
2017-06-24 16:36:24,472 Epoch[28] Batch [470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102072,	
2017-06-24 16:36:36,855 Epoch[28] Batch [480]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.102067,	
2017-06-24 16:36:48,650 Epoch[28] Batch [490]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.102104,	
2017-06-24 16:37:00,264 Epoch[28] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102062,	
2017-06-24 16:37:12,115 Epoch[28] Batch [510]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.101893,	
2017-06-24 16:37:23,846 Epoch[28] Batch [520]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.101875,	
2017-06-24 16:37:36,079 Epoch[28] Batch [530]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101878,	
2017-06-24 16:37:48,015 Epoch[28] Batch [540]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101870,	
2017-06-24 16:38:00,709 Epoch[28] Batch [550]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.101860,	
2017-06-24 16:38:13,585 Epoch[28] Batch [560]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.101883,	
2017-06-24 16:38:25,604 Epoch[28] Batch [570]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101909,	
2017-06-24 16:38:37,552 Epoch[28] Batch [580]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101897,	
2017-06-24 16:38:49,226 Epoch[28] Batch [590]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101925,	
2017-06-24 16:39:01,329 Epoch[28] Batch [600]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101927,	
2017-06-24 16:39:13,361 Epoch[28] Batch [610]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101870,	
2017-06-24 16:39:26,717 Epoch[28] Batch [620]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.101851,	
2017-06-24 16:39:39,044 Epoch[28] Batch [630]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101728,	
2017-06-24 16:39:51,432 Epoch[28] Batch [640]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.101661,	
2017-06-24 16:40:03,568 Epoch[28] Batch [650]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101627,	
2017-06-24 16:40:15,915 Epoch[28] Batch [660]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101507,	
2017-06-24 16:40:27,100 Epoch[28] Batch [670]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.101525,	
2017-06-24 16:40:39,430 Epoch[28] Batch [680]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101523,	
2017-06-24 16:40:51,564 Epoch[28] Batch [690]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101525,	
2017-06-24 16:41:04,088 Epoch[28] Batch [700]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.101460,	
2017-06-24 16:41:16,435 Epoch[28] Batch [710]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101483,	
2017-06-24 16:41:28,106 Epoch[28] Batch [720]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101551,	
2017-06-24 16:41:40,123 Epoch[28] Batch [730]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101520,	
2017-06-24 16:41:52,317 Epoch[28] Batch [740]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101514,	
2017-06-24 16:41:54,855 Epoch[28] Train-FCNLogLoss=0.101473
2017-06-24 16:41:54,855 Epoch[28] Time cost=877.727
2017-06-24 16:41:56,498 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0029.params"
2017-06-24 16:41:58,476 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0029.states"
2017-06-24 16:42:12,402 Epoch[29] Batch [10]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.100331,	
2017-06-24 16:42:24,613 Epoch[29] Batch [20]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102177,	
2017-06-24 16:42:36,927 Epoch[29] Batch [30]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.103747,	
2017-06-24 16:42:48,305 Epoch[29] Batch [40]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.100965,	
2017-06-24 16:43:00,169 Epoch[29] Batch [50]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.100931,	
2017-06-24 16:43:12,011 Epoch[29] Batch [60]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101510,	
2017-06-24 16:43:23,800 Epoch[29] Batch [70]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.101490,	
2017-06-24 16:43:35,339 Epoch[29] Batch [80]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101549,	
2017-06-24 16:43:47,856 Epoch[29] Batch [90]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.101165,	
2017-06-24 16:43:59,603 Epoch[29] Batch [100]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.100901,	
2017-06-24 16:44:12,301 Epoch[29] Batch [110]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.100914,	
2017-06-24 16:44:24,755 Epoch[29] Batch [120]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.100758,	
2017-06-24 16:44:36,955 Epoch[29] Batch [130]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101034,	
2017-06-24 16:44:48,710 Epoch[29] Batch [140]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.101045,	
2017-06-24 16:45:00,481 Epoch[29] Batch [150]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.100540,	
2017-06-24 16:45:12,363 Epoch[29] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.100448,	
2017-06-24 16:45:25,853 Epoch[29] Batch [170]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.100196,	
2017-06-24 16:45:37,941 Epoch[29] Batch [180]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100097,	
2017-06-24 16:45:50,394 Epoch[29] Batch [190]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.099942,	
2017-06-24 16:46:03,054 Epoch[29] Batch [200]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.100120,	
2017-06-24 16:46:15,264 Epoch[29] Batch [210]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100999,	
2017-06-24 16:46:27,168 Epoch[29] Batch [220]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.100841,	
2017-06-24 16:46:38,721 Epoch[29] Batch [230]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.100813,	
2017-06-24 16:46:50,143 Epoch[29] Batch [240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101067,	
2017-06-24 16:47:01,627 Epoch[29] Batch [250]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100981,	
2017-06-24 16:47:13,131 Epoch[29] Batch [260]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101030,	
2017-06-24 16:47:26,002 Epoch[29] Batch [270]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.100942,	
2017-06-24 16:47:37,747 Epoch[29] Batch [280]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.100743,	
2017-06-24 16:47:49,397 Epoch[29] Batch [290]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100662,	
2017-06-24 16:48:00,947 Epoch[29] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100547,	
2017-06-24 16:48:13,136 Epoch[29] Batch [310]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100940,	
2017-06-24 16:48:24,377 Epoch[29] Batch [320]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.100810,	
2017-06-24 16:48:36,461 Epoch[29] Batch [330]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100667,	
2017-06-24 16:48:48,938 Epoch[29] Batch [340]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.100624,	
2017-06-24 16:49:00,898 Epoch[29] Batch [350]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.100476,	
2017-06-24 16:49:13,496 Epoch[29] Batch [360]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100571,	
2017-06-24 16:49:26,016 Epoch[29] Batch [370]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.100565,	
2017-06-24 16:49:38,182 Epoch[29] Batch [380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100597,	
2017-06-24 16:49:49,587 Epoch[29] Batch [390]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100499,	
2017-06-24 16:50:01,526 Epoch[29] Batch [400]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.100548,	
2017-06-24 16:50:14,234 Epoch[29] Batch [410]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.100350,	
2017-06-24 16:50:26,785 Epoch[29] Batch [420]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.100418,	
2017-06-24 16:50:39,221 Epoch[29] Batch [430]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.100318,	
2017-06-24 16:50:50,803 Epoch[29] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100400,	
2017-06-24 16:51:02,544 Epoch[29] Batch [450]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.100771,	
2017-06-24 16:51:14,845 Epoch[29] Batch [460]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.100968,	
2017-06-24 16:51:26,074 Epoch[29] Batch [470]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101691,	
2017-06-24 16:51:38,707 Epoch[29] Batch [480]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.101926,	
2017-06-24 16:51:51,431 Epoch[29] Batch [490]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.102057,	
2017-06-24 16:52:04,000 Epoch[29] Batch [500]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.102106,	
2017-06-24 16:52:16,733 Epoch[29] Batch [510]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.102468,	
2017-06-24 16:52:28,351 Epoch[29] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102765,	
2017-06-24 16:52:40,377 Epoch[29] Batch [530]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102887,	
2017-06-24 16:52:52,392 Epoch[29] Batch [540]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102961,	
2017-06-24 16:53:03,926 Epoch[29] Batch [550]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.102844,	
2017-06-24 16:53:16,462 Epoch[29] Batch [560]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.102733,	
2017-06-24 16:53:28,726 Epoch[29] Batch [570]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102822,	
2017-06-24 16:53:41,545 Epoch[29] Batch [580]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.102754,	
2017-06-24 16:53:53,628 Epoch[29] Batch [590]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102721,	
2017-06-24 16:54:06,340 Epoch[29] Batch [600]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.102676,	
2017-06-24 16:54:17,523 Epoch[29] Batch [610]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102656,	
2017-06-24 16:54:29,256 Epoch[29] Batch [620]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.102673,	
2017-06-24 16:54:40,302 Epoch[29] Batch [630]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.102609,	
2017-06-24 16:54:52,437 Epoch[29] Batch [640]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102525,	
2017-06-24 16:55:04,738 Epoch[29] Batch [650]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.102514,	
2017-06-24 16:55:17,304 Epoch[29] Batch [660]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.102403,	
2017-06-24 16:55:29,788 Epoch[29] Batch [670]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.102407,	
2017-06-24 16:55:42,012 Epoch[29] Batch [680]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102269,	
2017-06-24 16:55:54,339 Epoch[29] Batch [690]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.102212,	
2017-06-24 16:56:05,903 Epoch[29] Batch [700]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102224,	
2017-06-24 16:56:17,550 Epoch[29] Batch [710]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102255,	
2017-06-24 16:56:29,484 Epoch[29] Batch [720]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102294,	
2017-06-24 16:56:41,900 Epoch[29] Batch [730]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.102231,	
2017-06-24 16:56:53,954 Epoch[29] Batch [740]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102133,	
2017-06-24 16:56:56,442 Epoch[29] Train-FCNLogLoss=0.102110
2017-06-24 16:56:56,442 Epoch[29] Time cost=897.965
2017-06-24 16:56:58,175 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0030.params"
2017-06-24 16:57:00,126 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0030.states"
2017-06-24 16:57:13,578 Epoch[30] Batch [10]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105021,	
2017-06-24 16:57:24,766 Epoch[30] Batch [20]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102804,	
2017-06-24 16:57:36,880 Epoch[30] Batch [30]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102581,	
2017-06-24 16:57:48,564 Epoch[30] Batch [40]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.101115,	
2017-06-24 16:58:01,396 Epoch[30] Batch [50]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.099949,	
2017-06-24 16:58:13,621 Epoch[30] Batch [60]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100998,	
2017-06-24 16:58:25,769 Epoch[30] Batch [70]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100061,	
2017-06-24 16:58:38,479 Epoch[30] Batch [80]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.099450,	
2017-06-24 16:58:50,442 Epoch[30] Batch [90]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.099487,	
2017-06-24 16:59:02,621 Epoch[30] Batch [100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099134,	
2017-06-24 16:59:14,493 Epoch[30] Batch [110]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099713,	
2017-06-24 16:59:25,943 Epoch[30] Batch [120]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.099242,	
2017-06-24 16:59:38,202 Epoch[30] Batch [130]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.099416,	
2017-06-24 16:59:49,607 Epoch[30] Batch [140]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.099320,	
2017-06-24 17:00:01,716 Epoch[30] Batch [150]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099222,	
2017-06-24 17:00:13,857 Epoch[30] Batch [160]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098804,	
2017-06-24 17:00:25,438 Epoch[30] Batch [170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099084,	
2017-06-24 17:00:37,108 Epoch[30] Batch [180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.099030,	
2017-06-24 17:00:49,127 Epoch[30] Batch [190]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.098871,	
2017-06-24 17:01:00,607 Epoch[30] Batch [200]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.098512,	
2017-06-24 17:01:12,423 Epoch[30] Batch [210]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.098716,	
2017-06-24 17:01:24,654 Epoch[30] Batch [220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.099026,	
2017-06-24 17:01:37,373 Epoch[30] Batch [230]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.099142,	
2017-06-24 17:01:49,962 Epoch[30] Batch [240]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.099308,	
2017-06-24 17:02:02,266 Epoch[30] Batch [250]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.099438,	
2017-06-24 17:02:14,570 Epoch[30] Batch [260]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.099474,	
2017-06-24 17:02:26,560 Epoch[30] Batch [270]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.099466,	
2017-06-24 17:02:37,397 Epoch[30] Batch [280]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.099458,	
2017-06-24 17:02:48,608 Epoch[30] Batch [290]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.099453,	
2017-06-24 17:03:00,288 Epoch[30] Batch [300]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099393,	
2017-06-24 17:03:12,221 Epoch[30] Batch [310]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.099255,	
2017-06-24 17:03:23,860 Epoch[30] Batch [320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099258,	
2017-06-24 17:03:35,135 Epoch[30] Batch [330]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.099171,	
2017-06-24 17:03:46,248 Epoch[30] Batch [340]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.099166,	
2017-06-24 17:03:57,463 Epoch[30] Batch [350]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.099003,	
2017-06-24 17:04:09,607 Epoch[30] Batch [360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098968,	
2017-06-24 17:04:21,102 Epoch[30] Batch [370]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099057,	
2017-06-24 17:04:33,665 Epoch[30] Batch [380]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.099102,	
2017-06-24 17:04:45,366 Epoch[30] Batch [390]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.099089,	
2017-06-24 17:04:58,436 Epoch[30] Batch [400]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.099167,	
2017-06-24 17:05:11,192 Epoch[30] Batch [410]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-24 17:05:23,918 Epoch[30] Batch [420]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.099111,	
2017-06-24 17:05:36,457 Epoch[30] Batch [430]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.099118,	
2017-06-24 17:05:48,752 Epoch[30] Batch [440]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.099214,	
2017-06-24 17:06:01,099 Epoch[30] Batch [450]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.099164,	
2017-06-24 17:06:13,610 Epoch[30] Batch [460]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.099197,	
2017-06-24 17:06:26,425 Epoch[30] Batch [470]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.099259,	
2017-06-24 17:06:38,729 Epoch[30] Batch [480]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-24 17:06:50,771 Epoch[30] Batch [490]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099234,	
2017-06-24 17:07:02,957 Epoch[30] Batch [500]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099310,	
2017-06-24 17:07:15,250 Epoch[30] Batch [510]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.099289,	
2017-06-24 17:07:27,716 Epoch[30] Batch [520]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.099242,	
2017-06-24 17:07:39,877 Epoch[30] Batch [530]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099166,	
2017-06-24 17:07:52,773 Epoch[30] Batch [540]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.099025,	
2017-06-24 17:08:05,636 Epoch[30] Batch [550]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.099009,	
2017-06-24 17:08:17,743 Epoch[30] Batch [560]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099035,	
2017-06-24 17:08:29,659 Epoch[30] Batch [570]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099004,	
2017-06-24 17:08:42,665 Epoch[30] Batch [580]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.098889,	
2017-06-24 17:08:54,605 Epoch[30] Batch [590]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.098723,	
2017-06-24 17:09:06,482 Epoch[30] Batch [600]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.098638,	
2017-06-24 17:09:18,408 Epoch[30] Batch [610]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.098499,	
2017-06-24 17:09:30,124 Epoch[30] Batch [620]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098383,	
2017-06-24 17:09:41,459 Epoch[30] Batch [630]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.098252,	
2017-06-24 17:09:54,020 Epoch[30] Batch [640]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.098118,	
2017-06-24 17:10:06,742 Epoch[30] Batch [650]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.098088,	
2017-06-24 17:10:19,127 Epoch[30] Batch [660]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.098041,	
2017-06-24 17:10:31,470 Epoch[30] Batch [670]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.098017,	
2017-06-24 17:10:42,826 Epoch[30] Batch [680]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.097995,	
2017-06-24 17:10:55,742 Epoch[30] Batch [690]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.097933,	
2017-06-24 17:11:07,643 Epoch[30] Batch [700]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.098009,	
2017-06-24 17:11:20,047 Epoch[30] Batch [710]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.097934,	
2017-06-24 17:11:32,153 Epoch[30] Batch [720]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097960,	
2017-06-24 17:11:44,838 Epoch[30] Batch [730]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.097832,	
2017-06-24 17:11:57,042 Epoch[30] Batch [740]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097907,	
2017-06-24 17:11:59,472 Epoch[30] Train-FCNLogLoss=0.097903
2017-06-24 17:11:59,472 Epoch[30] Time cost=899.345
2017-06-24 17:12:01,162 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0031.params"
2017-06-24 17:12:03,111 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0031.states"
2017-06-24 17:12:16,027 Epoch[31] Batch [10]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098505,	
2017-06-24 17:12:28,847 Epoch[31] Batch [20]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.094902,	
2017-06-24 17:12:41,090 Epoch[31] Batch [30]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.096484,	
2017-06-24 17:12:52,723 Epoch[31] Batch [40]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095166,	
2017-06-24 17:13:05,045 Epoch[31] Batch [50]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.095707,	
2017-06-24 17:13:17,160 Epoch[31] Batch [60]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.095819,	
2017-06-24 17:13:29,451 Epoch[31] Batch [70]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.095298,	
2017-06-24 17:13:41,719 Epoch[31] Batch [80]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.096346,	
2017-06-24 17:13:53,245 Epoch[31] Batch [90]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.096544,	
2017-06-24 17:14:05,434 Epoch[31] Batch [100]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097287,	
2017-06-24 17:14:17,522 Epoch[31] Batch [110]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097351,	
2017-06-24 17:14:29,147 Epoch[31] Batch [120]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098133,	
2017-06-24 17:14:41,487 Epoch[31] Batch [130]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.098195,	
2017-06-24 17:14:53,595 Epoch[31] Batch [140]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098014,	
2017-06-24 17:15:05,826 Epoch[31] Batch [150]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098170,	
2017-06-24 17:15:18,026 Epoch[31] Batch [160]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097766,	
2017-06-24 17:15:29,089 Epoch[31] Batch [170]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098054,	
2017-06-24 17:15:40,905 Epoch[31] Batch [180]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.098419,	
2017-06-24 17:15:52,600 Epoch[31] Batch [190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098645,	
2017-06-24 17:16:04,772 Epoch[31] Batch [200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098535,	
2017-06-24 17:16:17,540 Epoch[31] Batch [210]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.098769,	
2017-06-24 17:16:29,809 Epoch[31] Batch [220]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.098839,	
2017-06-24 17:16:41,869 Epoch[31] Batch [230]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098729,	
2017-06-24 17:16:53,674 Epoch[31] Batch [240]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.098564,	
2017-06-24 17:17:04,999 Epoch[31] Batch [250]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.098774,	
2017-06-24 17:17:16,848 Epoch[31] Batch [260]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.098743,	
2017-06-24 17:17:29,092 Epoch[31] Batch [270]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098470,	
2017-06-24 17:17:41,185 Epoch[31] Batch [280]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098455,	
2017-06-24 17:17:52,916 Epoch[31] Batch [290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.098460,	
2017-06-24 17:18:04,864 Epoch[31] Batch [300]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.098411,	
2017-06-24 17:18:16,572 Epoch[31] Batch [310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098478,	
2017-06-24 17:18:28,993 Epoch[31] Batch [320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.098431,	
2017-06-24 17:18:41,092 Epoch[31] Batch [330]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098222,	
2017-06-24 17:18:53,402 Epoch[31] Batch [340]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.098324,	
2017-06-24 17:19:06,020 Epoch[31] Batch [350]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.098207,	
2017-06-24 17:19:17,863 Epoch[31] Batch [360]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.098087,	
2017-06-24 17:19:29,903 Epoch[31] Batch [370]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097910,	
2017-06-24 17:19:41,608 Epoch[31] Batch [380]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.097718,	
2017-06-24 17:19:54,008 Epoch[31] Batch [390]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.097873,	
2017-06-24 17:20:05,742 Epoch[31] Batch [400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.097946,	
2017-06-24 17:20:17,228 Epoch[31] Batch [410]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.098116,	
2017-06-24 17:20:29,121 Epoch[31] Batch [420]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.098161,	
2017-06-24 17:20:40,963 Epoch[31] Batch [430]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.098152,	
2017-06-24 17:20:53,466 Epoch[31] Batch [440]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.098210,	
2017-06-24 17:21:05,936 Epoch[31] Batch [450]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.098228,	
2017-06-24 17:21:17,688 Epoch[31] Batch [460]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.098147,	
2017-06-24 17:21:29,899 Epoch[31] Batch [470]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098080,	
2017-06-24 17:21:42,103 Epoch[31] Batch [480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098046,	
2017-06-24 17:21:53,517 Epoch[31] Batch [490]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.098028,	
2017-06-24 17:22:04,831 Epoch[31] Batch [500]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.098089,	
2017-06-24 17:22:16,716 Epoch[31] Batch [510]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.098032,	
2017-06-24 17:22:29,074 Epoch[31] Batch [520]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.098069,	
2017-06-24 17:22:41,764 Epoch[31] Batch [530]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.098069,	
2017-06-24 17:22:54,243 Epoch[31] Batch [540]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.098183,	
2017-06-24 17:23:05,976 Epoch[31] Batch [550]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.098077,	
2017-06-24 17:23:17,437 Epoch[31] Batch [560]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.098186,	
2017-06-24 17:23:30,117 Epoch[31] Batch [570]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.098157,	
2017-06-24 17:23:42,737 Epoch[31] Batch [580]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.098343,	
2017-06-24 17:23:55,184 Epoch[31] Batch [590]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.098421,	
2017-06-24 17:24:07,793 Epoch[31] Batch [600]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.098355,	
2017-06-24 17:24:20,010 Epoch[31] Batch [610]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098475,	
2017-06-24 17:24:32,270 Epoch[31] Batch [620]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098483,	
2017-06-24 17:24:44,113 Epoch[31] Batch [630]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.098387,	
2017-06-24 17:24:55,804 Epoch[31] Batch [640]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.098427,	
2017-06-24 17:25:07,133 Epoch[31] Batch [650]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.098683,	
2017-06-24 17:25:19,666 Epoch[31] Batch [660]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.098802,	
2017-06-24 17:25:31,674 Epoch[31] Batch [670]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.098827,	
2017-06-24 17:25:42,676 Epoch[31] Batch [680]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.098898,	
2017-06-24 17:25:54,237 Epoch[31] Batch [690]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099024,	
2017-06-24 17:26:05,574 Epoch[31] Batch [700]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.098994,	
2017-06-24 17:26:17,948 Epoch[31] Batch [710]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.098953,	
2017-06-24 17:26:30,388 Epoch[31] Batch [720]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.098922,	
2017-06-24 17:26:41,625 Epoch[31] Batch [730]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.098944,	
2017-06-24 17:26:54,038 Epoch[31] Batch [740]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.098980,	
2017-06-24 17:26:56,616 Epoch[31] Train-FCNLogLoss=0.098971
2017-06-24 17:26:56,616 Epoch[31] Time cost=893.505
2017-06-24 17:26:58,599 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0032.params"
2017-06-24 17:27:01,098 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0032.states"
2017-06-24 17:27:14,993 Epoch[32] Batch [10]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103849,	
2017-06-24 17:27:27,082 Epoch[32] Batch [20]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101608,	
2017-06-24 17:27:39,520 Epoch[32] Batch [30]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.103755,	
2017-06-24 17:27:51,841 Epoch[32] Batch [40]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.104123,	
2017-06-24 17:28:04,102 Epoch[32] Batch [50]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.113297,	
2017-06-24 17:28:15,751 Epoch[32] Batch [60]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.122823,	
2017-06-24 17:28:28,229 Epoch[32] Batch [70]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.123785,	
2017-06-24 17:28:40,798 Epoch[32] Batch [80]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.124321,	
2017-06-24 17:28:52,601 Epoch[32] Batch [90]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.122162,	
2017-06-24 17:29:04,269 Epoch[32] Batch [100]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.120601,	
2017-06-24 17:29:16,292 Epoch[32] Batch [110]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.119327,	
2017-06-24 17:29:27,975 Epoch[32] Batch [120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.118694,	
2017-06-24 17:29:40,219 Epoch[32] Batch [130]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.117372,	
2017-06-24 17:29:51,831 Epoch[32] Batch [140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116178,	
2017-06-24 17:30:03,917 Epoch[32] Batch [150]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.115594,	
2017-06-24 17:30:16,808 Epoch[32] Batch [160]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.115603,	
2017-06-24 17:30:28,935 Epoch[32] Batch [170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.115121,	
2017-06-24 17:30:41,339 Epoch[32] Batch [180]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.114721,	
2017-06-24 17:30:52,599 Epoch[32] Batch [190]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.114397,	
2017-06-24 17:31:04,206 Epoch[32] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114705,	
2017-06-24 17:31:15,525 Epoch[32] Batch [210]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.114588,	
2017-06-24 17:31:26,865 Epoch[32] Batch [220]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.114069,	
2017-06-24 17:31:38,007 Epoch[32] Batch [230]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.113644,	
2017-06-24 17:31:49,979 Epoch[32] Batch [240]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.112779,	
2017-06-24 17:32:01,314 Epoch[32] Batch [250]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.111942,	
2017-06-24 17:32:13,352 Epoch[32] Batch [260]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.111648,	
2017-06-24 17:32:25,679 Epoch[32] Batch [270]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.111360,	
2017-06-24 17:32:38,109 Epoch[32] Batch [280]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.110972,	
2017-06-24 17:32:49,744 Epoch[32] Batch [290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.110588,	
2017-06-24 17:33:01,367 Epoch[32] Batch [300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.110307,	
2017-06-24 17:33:13,041 Epoch[32] Batch [310]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110051,	
2017-06-24 17:33:25,298 Epoch[32] Batch [320]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.109706,	
2017-06-24 17:33:37,284 Epoch[32] Batch [330]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.109501,	
2017-06-24 17:33:49,378 Epoch[32] Batch [340]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109361,	
2017-06-24 17:34:01,207 Epoch[32] Batch [350]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.109011,	
2017-06-24 17:34:13,077 Epoch[32] Batch [360]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108803,	
2017-06-24 17:34:25,012 Epoch[32] Batch [370]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.108512,	
2017-06-24 17:34:36,814 Epoch[32] Batch [380]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108298,	
2017-06-24 17:34:48,789 Epoch[32] Batch [390]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.107871,	
2017-06-24 17:35:01,165 Epoch[32] Batch [400]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.107716,	
2017-06-24 17:35:13,630 Epoch[32] Batch [410]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.107344,	
2017-06-24 17:35:25,506 Epoch[32] Batch [420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107175,	
2017-06-24 17:35:37,386 Epoch[32] Batch [430]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106828,	
2017-06-24 17:35:49,261 Epoch[32] Batch [440]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106572,	
2017-06-24 17:36:01,147 Epoch[32] Batch [450]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106377,	
2017-06-24 17:36:12,536 Epoch[32] Batch [460]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.106320,	
2017-06-24 17:36:24,114 Epoch[32] Batch [470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.106147,	
2017-06-24 17:36:36,361 Epoch[32] Batch [480]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106090,	
2017-06-24 17:36:48,031 Epoch[32] Batch [490]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.106210,	
2017-06-24 17:36:59,752 Epoch[32] Batch [500]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106038,	
2017-06-24 17:37:12,083 Epoch[32] Batch [510]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.105794,	
2017-06-24 17:37:24,039 Epoch[32] Batch [520]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105673,	
2017-06-24 17:37:36,224 Epoch[32] Batch [530]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.105626,	
2017-06-24 17:37:47,202 Epoch[32] Batch [540]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.105409,	
2017-06-24 17:37:58,818 Epoch[32] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.105274,	
2017-06-24 17:38:10,698 Epoch[32] Batch [560]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105220,	
2017-06-24 17:38:22,837 Epoch[32] Batch [570]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.104971,	
2017-06-24 17:38:35,401 Epoch[32] Batch [580]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.105044,	
2017-06-24 17:38:47,066 Epoch[32] Batch [590]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.104885,	
2017-06-24 17:38:58,925 Epoch[32] Batch [600]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.104743,	
2017-06-24 17:39:10,918 Epoch[32] Batch [610]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.104643,	
2017-06-24 17:39:22,308 Epoch[32] Batch [620]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.104597,	
2017-06-24 17:39:33,761 Epoch[32] Batch [630]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.104584,	
2017-06-24 17:39:45,570 Epoch[32] Batch [640]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104423,	
2017-06-24 17:39:57,713 Epoch[32] Batch [650]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.104327,	
2017-06-24 17:40:10,184 Epoch[32] Batch [660]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.104120,	
2017-06-24 17:40:22,229 Epoch[32] Batch [670]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103971,	
2017-06-24 17:40:34,100 Epoch[32] Batch [680]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103843,	
2017-06-24 17:40:46,128 Epoch[32] Batch [690]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.103648,	
2017-06-24 17:40:57,561 Epoch[32] Batch [700]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.103562,	
2017-06-24 17:41:08,982 Epoch[32] Batch [710]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.103461,	
2017-06-24 17:41:21,481 Epoch[32] Batch [720]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.103354,	
2017-06-24 17:41:33,550 Epoch[32] Batch [730]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103235,	
2017-06-24 17:41:45,351 Epoch[32] Batch [740]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.103192,	
2017-06-24 17:41:47,539 Epoch[32] Train-FCNLogLoss=0.103151
2017-06-24 17:41:47,540 Epoch[32] Time cost=886.441
2017-06-24 17:41:49,631 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0033.params"
2017-06-24 17:41:52,341 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0033.states"
2017-06-24 17:42:05,649 Epoch[33] Batch [10]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.095944,	
2017-06-24 17:42:17,214 Epoch[33] Batch [20]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.097460,	
2017-06-24 17:42:27,905 Epoch[33] Batch [30]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095833,	
2017-06-24 17:42:38,908 Epoch[33] Batch [40]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.095208,	
2017-06-24 17:42:50,162 Epoch[33] Batch [50]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.095444,	
2017-06-24 17:43:02,220 Epoch[33] Batch [60]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.095221,	
2017-06-24 17:43:14,248 Epoch[33] Batch [70]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.095984,	
2017-06-24 17:43:25,958 Epoch[33] Batch [80]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.096242,	
2017-06-24 17:43:37,177 Epoch[33] Batch [90]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.095778,	
2017-06-24 17:43:48,986 Epoch[33] Batch [100]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.095483,	
2017-06-24 17:44:00,473 Epoch[33] Batch [110]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.096199,	
2017-06-24 17:44:12,249 Epoch[33] Batch [120]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.096013,	
2017-06-24 17:44:23,365 Epoch[33] Batch [130]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.096184,	
2017-06-24 17:44:35,981 Epoch[33] Batch [140]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.096120,	
2017-06-24 17:44:46,872 Epoch[33] Batch [150]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.096257,	
2017-06-24 17:44:58,484 Epoch[33] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096215,	
2017-06-24 17:45:09,097 Epoch[33] Batch [170]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096170,	
2017-06-24 17:45:19,853 Epoch[33] Batch [180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096519,	
2017-06-24 17:45:31,138 Epoch[33] Batch [190]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.096638,	
2017-06-24 17:45:43,040 Epoch[33] Batch [200]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.096838,	
2017-06-24 17:45:54,725 Epoch[33] Batch [210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.096505,	
2017-06-24 17:46:06,859 Epoch[33] Batch [220]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.096681,	
2017-06-24 17:46:18,402 Epoch[33] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096281,	
2017-06-24 17:46:31,447 Epoch[33] Batch [240]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.096389,	
2017-06-24 17:46:43,025 Epoch[33] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096355,	
2017-06-24 17:46:54,651 Epoch[33] Batch [260]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096435,	
2017-06-24 17:47:06,243 Epoch[33] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096429,	
2017-06-24 17:47:17,906 Epoch[33] Batch [280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.096316,	
2017-06-24 17:47:29,794 Epoch[33] Batch [290]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.096349,	
2017-06-24 17:47:41,905 Epoch[33] Batch [300]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.096328,	
2017-06-24 17:47:53,374 Epoch[33] Batch [310]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.096342,	
2017-06-24 17:48:06,072 Epoch[33] Batch [320]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.096423,	
2017-06-24 17:48:18,106 Epoch[33] Batch [330]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.096527,	
2017-06-24 17:48:29,757 Epoch[33] Batch [340]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.096525,	
2017-06-24 17:48:41,752 Epoch[33] Batch [350]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.096356,	
2017-06-24 17:48:53,135 Epoch[33] Batch [360]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.096400,	
2017-06-24 17:49:04,882 Epoch[33] Batch [370]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.096424,	
2017-06-24 17:49:15,591 Epoch[33] Batch [380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096375,	
2017-06-24 17:49:26,234 Epoch[33] Batch [390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096418,	
2017-06-24 17:49:37,146 Epoch[33] Batch [400]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.096239,	
2017-06-24 17:49:48,396 Epoch[33] Batch [410]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.096134,	
2017-06-24 17:49:59,880 Epoch[33] Batch [420]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.096139,	
2017-06-24 17:50:10,157 Epoch[33] Batch [430]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.096167,	
2017-06-24 17:50:20,919 Epoch[33] Batch [440]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096236,	
2017-06-24 17:50:32,696 Epoch[33] Batch [450]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.096252,	
2017-06-24 17:50:43,647 Epoch[33] Batch [460]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.096338,	
2017-06-24 17:50:54,965 Epoch[33] Batch [470]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.096340,	
2017-06-24 17:51:05,864 Epoch[33] Batch [480]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.096383,	
2017-06-24 17:51:16,750 Epoch[33] Batch [490]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.096380,	
2017-06-24 17:51:26,982 Epoch[33] Batch [500]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.096524,	
2017-06-24 17:51:38,039 Epoch[33] Batch [510]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.096543,	
2017-06-24 17:51:48,756 Epoch[33] Batch [520]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096597,	
2017-06-24 17:51:59,310 Epoch[33] Batch [530]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096784,	
2017-06-24 17:52:10,317 Epoch[33] Batch [540]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.096791,	
2017-06-24 17:52:21,502 Epoch[33] Batch [550]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.096812,	
2017-06-24 17:52:32,522 Epoch[33] Batch [560]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.096851,	
2017-06-24 17:52:44,141 Epoch[33] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.096776,	
2017-06-24 17:52:55,724 Epoch[33] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096844,	
2017-06-24 17:53:06,599 Epoch[33] Batch [590]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.096855,	
2017-06-24 17:53:17,556 Epoch[33] Batch [600]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.096968,	
2017-06-24 17:53:28,918 Epoch[33] Batch [610]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.097044,	
2017-06-24 17:53:39,660 Epoch[33] Batch [620]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097167,	
2017-06-24 17:53:50,622 Epoch[33] Batch [630]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.097274,	
2017-06-24 17:54:00,948 Epoch[33] Batch [640]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097156,	
2017-06-24 17:54:12,028 Epoch[33] Batch [650]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.097156,	
2017-06-24 17:54:22,260 Epoch[33] Batch [660]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.097065,	
2017-06-24 17:54:32,907 Epoch[33] Batch [670]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096958,	
2017-06-24 17:54:43,052 Epoch[33] Batch [680]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.097011,	
2017-06-24 17:54:53,522 Epoch[33] Batch [690]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097038,	
2017-06-24 17:55:03,986 Epoch[33] Batch [700]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.096985,	
2017-06-24 17:55:14,473 Epoch[33] Batch [710]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.096974,	
2017-06-24 17:55:25,158 Epoch[33] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096949,	
2017-06-24 17:55:35,494 Epoch[33] Batch [730]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.096914,	
2017-06-24 17:55:46,109 Epoch[33] Batch [740]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096808,	
2017-06-24 17:55:48,396 Epoch[33] Train-FCNLogLoss=0.096803
2017-06-24 17:55:48,396 Epoch[33] Time cost=836.054
2017-06-24 17:55:50,005 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0034.params"
2017-06-24 17:55:52,405 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0034.states"
2017-06-24 17:56:04,911 Epoch[34] Batch [10]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.090271,	
2017-06-24 17:56:15,241 Epoch[34] Batch [20]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093188,	
2017-06-24 17:56:25,981 Epoch[34] Batch [30]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094800,	
2017-06-24 17:56:36,648 Epoch[34] Batch [40]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097192,	
2017-06-24 17:56:46,608 Epoch[34] Batch [50]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.098250,	
2017-06-24 17:56:57,711 Epoch[34] Batch [60]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.100013,	
2017-06-24 17:57:07,916 Epoch[34] Batch [70]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099946,	
2017-06-24 17:57:17,836 Epoch[34] Batch [80]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.099489,	
2017-06-24 17:57:27,883 Epoch[34] Batch [90]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.100199,	
2017-06-24 17:57:37,419 Epoch[34] Batch [100]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.100442,	
2017-06-24 17:57:47,853 Epoch[34] Batch [110]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099538,	
2017-06-24 17:57:58,324 Epoch[34] Batch [120]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099635,	
2017-06-24 17:58:08,760 Epoch[34] Batch [130]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099424,	
2017-06-24 17:58:18,679 Epoch[34] Batch [140]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.099868,	
2017-06-24 17:58:28,400 Epoch[34] Batch [150]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.100469,	
2017-06-24 17:58:38,436 Epoch[34] Batch [160]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.100665,	
2017-06-24 17:58:48,325 Epoch[34] Batch [170]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.100315,	
2017-06-24 17:58:57,629 Epoch[34] Batch [180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.100449,	
2017-06-24 17:59:07,597 Epoch[34] Batch [190]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.100574,	
2017-06-24 17:59:17,608 Epoch[34] Batch [200]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.100039,	
2017-06-24 17:59:27,965 Epoch[34] Batch [210]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.100064,	
2017-06-24 17:59:38,797 Epoch[34] Batch [220]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.099920,	
2017-06-24 17:59:49,405 Epoch[34] Batch [230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.100023,	
2017-06-24 18:00:00,382 Epoch[34] Batch [240]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.099855,	
2017-06-24 18:00:10,045 Epoch[34] Batch [250]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.099716,	
2017-06-24 18:00:19,443 Epoch[34] Batch [260]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.099527,	
2017-06-24 18:00:29,775 Epoch[34] Batch [270]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.099577,	
2017-06-24 18:00:40,553 Epoch[34] Batch [280]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.099378,	
2017-06-24 18:00:51,407 Epoch[34] Batch [290]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.099011,	
2017-06-24 18:01:02,609 Epoch[34] Batch [300]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098787,	
2017-06-24 18:01:13,854 Epoch[34] Batch [310]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.098658,	
2017-06-24 18:01:24,946 Epoch[34] Batch [320]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.098705,	
2017-06-24 18:01:35,772 Epoch[34] Batch [330]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.098745,	
2017-06-24 18:01:46,880 Epoch[34] Batch [340]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.098574,	
2017-06-24 18:01:58,288 Epoch[34] Batch [350]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.098751,	
2017-06-24 18:02:08,847 Epoch[34] Batch [360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098650,	
2017-06-24 18:02:19,047 Epoch[34] Batch [370]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.098445,	
2017-06-24 18:02:29,741 Epoch[34] Batch [380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098539,	
2017-06-24 18:02:40,416 Epoch[34] Batch [390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098511,	
2017-06-24 18:02:50,808 Epoch[34] Batch [400]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098481,	
2017-06-24 18:03:01,108 Epoch[34] Batch [410]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.098474,	
2017-06-24 18:03:11,664 Epoch[34] Batch [420]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.098261,	
2017-06-24 18:03:22,335 Epoch[34] Batch [430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098138,	
2017-06-24 18:03:33,732 Epoch[34] Batch [440]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.097995,	
2017-06-24 18:03:45,118 Epoch[34] Batch [450]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.097804,	
2017-06-24 18:03:55,554 Epoch[34] Batch [460]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097698,	
2017-06-24 18:04:07,601 Epoch[34] Batch [470]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097599,	
2017-06-24 18:04:18,868 Epoch[34] Batch [480]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.097542,	
2017-06-24 18:04:29,975 Epoch[34] Batch [490]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097615,	
2017-06-24 18:04:40,653 Epoch[34] Batch [500]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098097,	
2017-06-24 18:04:51,732 Epoch[34] Batch [510]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.098145,	
2017-06-24 18:05:02,548 Epoch[34] Batch [520]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.098075,	
2017-06-24 18:05:12,682 Epoch[34] Batch [530]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.098129,	
2017-06-24 18:05:23,801 Epoch[34] Batch [540]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.098367,	
2017-06-24 18:05:34,819 Epoch[34] Batch [550]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.098320,	
2017-06-24 18:05:45,898 Epoch[34] Batch [560]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.098265,	
2017-06-24 18:05:56,617 Epoch[34] Batch [570]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098304,	
2017-06-24 18:06:07,735 Epoch[34] Batch [580]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.098365,	
2017-06-24 18:06:18,233 Epoch[34] Batch [590]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098461,	
2017-06-24 18:06:28,885 Epoch[34] Batch [600]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098351,	
2017-06-24 18:06:39,572 Epoch[34] Batch [610]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098305,	
2017-06-24 18:06:50,591 Epoch[34] Batch [620]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.098392,	
2017-06-24 18:07:01,743 Epoch[34] Batch [630]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098312,	
2017-06-24 18:07:12,503 Epoch[34] Batch [640]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098238,	
2017-06-24 18:07:22,597 Epoch[34] Batch [650]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.098217,	
2017-06-24 18:07:33,331 Epoch[34] Batch [660]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098158,	
2017-06-24 18:07:43,983 Epoch[34] Batch [670]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097957,	
2017-06-24 18:07:55,109 Epoch[34] Batch [680]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.097942,	
2017-06-24 18:08:05,732 Epoch[34] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097981,	
2017-06-24 18:08:17,487 Epoch[34] Batch [700]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.098000,	
2017-06-24 18:08:28,462 Epoch[34] Batch [710]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.098041,	
2017-06-24 18:08:39,150 Epoch[34] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097971,	
2017-06-24 18:08:49,944 Epoch[34] Batch [730]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097982,	
2017-06-24 18:09:00,136 Epoch[34] Batch [740]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.098022,	
2017-06-24 18:09:02,241 Epoch[34] Train-FCNLogLoss=0.098000
2017-06-24 18:09:02,241 Epoch[34] Time cost=789.836
2017-06-24 18:09:03,808 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0035.params"
2017-06-24 18:09:05,762 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0035.states"
2017-06-24 18:09:18,348 Epoch[35] Batch [10]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.090661,	
2017-06-24 18:09:29,672 Epoch[35] Batch [20]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.090895,	
2017-06-24 18:09:41,073 Epoch[35] Batch [30]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.090086,	
2017-06-24 18:09:52,329 Epoch[35] Batch [40]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093546,	
2017-06-24 18:10:03,210 Epoch[35] Batch [50]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093250,	
2017-06-24 18:10:13,912 Epoch[35] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092637,	
2017-06-24 18:10:24,858 Epoch[35] Batch [70]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.093572,	
2017-06-24 18:10:35,708 Epoch[35] Batch [80]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.093790,	
2017-06-24 18:10:46,690 Epoch[35] Batch [90]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.094014,	
2017-06-24 18:10:57,645 Epoch[35] Batch [100]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094847,	
2017-06-24 18:11:08,621 Epoch[35] Batch [110]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.095230,	
2017-06-24 18:11:20,268 Epoch[35] Batch [120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.094701,	
2017-06-24 18:11:31,389 Epoch[35] Batch [130]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.094751,	
2017-06-24 18:11:42,004 Epoch[35] Batch [140]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094464,	
2017-06-24 18:11:52,885 Epoch[35] Batch [150]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093987,	
2017-06-24 18:12:03,400 Epoch[35] Batch [160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094058,	
2017-06-24 18:12:14,696 Epoch[35] Batch [170]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.094029,	
2017-06-24 18:12:25,246 Epoch[35] Batch [180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094215,	
2017-06-24 18:12:35,613 Epoch[35] Batch [190]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094342,	
2017-06-24 18:12:46,642 Epoch[35] Batch [200]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094604,	
2017-06-24 18:12:57,588 Epoch[35] Batch [210]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.094547,	
2017-06-24 18:13:07,629 Epoch[35] Batch [220]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.094596,	
2017-06-24 18:13:18,070 Epoch[35] Batch [230]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094940,	
2017-06-24 18:13:28,915 Epoch[35] Batch [240]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.095032,	
2017-06-24 18:13:39,583 Epoch[35] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095182,	
2017-06-24 18:13:50,567 Epoch[35] Batch [260]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.095071,	
2017-06-24 18:14:00,905 Epoch[35] Batch [270]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.095131,	
2017-06-24 18:14:11,556 Epoch[35] Batch [280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095031,	
2017-06-24 18:14:22,203 Epoch[35] Batch [290]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094913,	
2017-06-24 18:14:33,429 Epoch[35] Batch [300]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.094677,	
2017-06-24 18:14:44,977 Epoch[35] Batch [310]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094758,	
2017-06-24 18:14:55,830 Epoch[35] Batch [320]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094739,	
2017-06-24 18:15:06,915 Epoch[35] Batch [330]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.094585,	
2017-06-24 18:15:18,287 Epoch[35] Batch [340]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.094414,	
2017-06-24 18:15:29,426 Epoch[35] Batch [350]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.094853,	
2017-06-24 18:15:40,384 Epoch[35] Batch [360]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094966,	
2017-06-24 18:15:51,470 Epoch[35] Batch [370]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.095142,	
2017-06-24 18:16:02,331 Epoch[35] Batch [380]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.095358,	
2017-06-24 18:16:12,919 Epoch[35] Batch [390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095685,	
2017-06-24 18:16:24,863 Epoch[35] Batch [400]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.095708,	
2017-06-24 18:16:35,096 Epoch[35] Batch [410]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.095822,	
2017-06-24 18:16:45,885 Epoch[35] Batch [420]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095973,	
2017-06-24 18:16:57,000 Epoch[35] Batch [430]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.095880,	
2017-06-24 18:17:08,576 Epoch[35] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.095868,	
2017-06-24 18:17:19,597 Epoch[35] Batch [450]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.095893,	
2017-06-24 18:17:31,408 Epoch[35] Batch [460]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.095820,	
2017-06-24 18:17:42,535 Epoch[35] Batch [470]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.095883,	
2017-06-24 18:17:53,857 Epoch[35] Batch [480]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.095825,	
2017-06-24 18:18:04,836 Epoch[35] Batch [490]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.095903,	
2017-06-24 18:18:15,591 Epoch[35] Batch [500]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095924,	
2017-06-24 18:18:26,981 Epoch[35] Batch [510]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.095715,	
2017-06-24 18:18:38,098 Epoch[35] Batch [520]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.095666,	
2017-06-24 18:18:49,184 Epoch[35] Batch [530]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.095522,	
2017-06-24 18:19:00,235 Epoch[35] Batch [540]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.095430,	
2017-06-24 18:19:11,422 Epoch[35] Batch [550]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.095266,	
2017-06-24 18:19:22,199 Epoch[35] Batch [560]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095321,	
2017-06-24 18:19:33,036 Epoch[35] Batch [570]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.095351,	
2017-06-24 18:19:44,434 Epoch[35] Batch [580]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.095245,	
2017-06-24 18:19:55,712 Epoch[35] Batch [590]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.095196,	
2017-06-24 18:20:06,670 Epoch[35] Batch [600]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.095314,	
2017-06-24 18:20:17,744 Epoch[35] Batch [610]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.095287,	
2017-06-24 18:20:28,530 Epoch[35] Batch [620]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095222,	
2017-06-24 18:20:39,527 Epoch[35] Batch [630]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.095304,	
2017-06-24 18:20:50,778 Epoch[35] Batch [640]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.095253,	
2017-06-24 18:21:01,514 Epoch[35] Batch [650]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095341,	
2017-06-24 18:21:12,098 Epoch[35] Batch [660]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095351,	
2017-06-24 18:21:23,168 Epoch[35] Batch [670]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.095451,	
2017-06-24 18:21:34,075 Epoch[35] Batch [680]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.095508,	
2017-06-24 18:21:45,347 Epoch[35] Batch [690]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.095631,	
2017-06-24 18:21:55,719 Epoch[35] Batch [700]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095694,	
2017-06-24 18:22:06,051 Epoch[35] Batch [710]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.095849,	
2017-06-24 18:22:17,064 Epoch[35] Batch [720]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.095831,	
2017-06-24 18:22:27,878 Epoch[35] Batch [730]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.095856,	
2017-06-24 18:22:38,708 Epoch[35] Batch [740]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.095939,	
2017-06-24 18:22:40,821 Epoch[35] Train-FCNLogLoss=0.095902
2017-06-24 18:22:40,822 Epoch[35] Time cost=815.058
2017-06-24 18:22:42,208 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0036.params"
2017-06-24 18:22:44,107 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0036.states"
2017-06-24 18:22:56,080 Epoch[36] Batch [10]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109529,	
2017-06-24 18:23:05,970 Epoch[36] Batch [20]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.121968,	
2017-06-24 18:23:16,514 Epoch[36] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.120558,	
2017-06-24 18:23:27,258 Epoch[36] Batch [40]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117445,	
2017-06-24 18:23:38,159 Epoch[36] Batch [50]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.113618,	
2017-06-24 18:23:49,138 Epoch[36] Batch [60]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.110990,	
2017-06-24 18:24:00,429 Epoch[36] Batch [70]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.108415,	
2017-06-24 18:24:11,161 Epoch[36] Batch [80]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.107184,	
2017-06-24 18:24:22,408 Epoch[36] Batch [90]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.106026,	
2017-06-24 18:24:32,791 Epoch[36] Batch [100]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.104955,	
2017-06-24 18:24:44,048 Epoch[36] Batch [110]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.104362,	
2017-06-24 18:24:54,961 Epoch[36] Batch [120]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.103970,	
2017-06-24 18:25:06,853 Epoch[36] Batch [130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102958,	
2017-06-24 18:25:17,800 Epoch[36] Batch [140]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.102205,	
2017-06-24 18:25:29,449 Epoch[36] Batch [150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102500,	
2017-06-24 18:25:40,504 Epoch[36] Batch [160]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.101846,	
2017-06-24 18:25:51,627 Epoch[36] Batch [170]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.101200,	
2017-06-24 18:26:03,120 Epoch[36] Batch [180]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.100825,	
2017-06-24 18:26:14,973 Epoch[36] Batch [190]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.100077,	
2017-06-24 18:26:26,348 Epoch[36] Batch [200]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.100099,	
2017-06-24 18:26:37,175 Epoch[36] Batch [210]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.099930,	
2017-06-24 18:26:48,923 Epoch[36] Batch [220]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.099428,	
2017-06-24 18:26:59,624 Epoch[36] Batch [230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099264,	
2017-06-24 18:27:10,813 Epoch[36] Batch [240]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098923,	
2017-06-24 18:27:21,486 Epoch[36] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098861,	
2017-06-24 18:27:32,588 Epoch[36] Batch [260]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.098735,	
2017-06-24 18:27:43,771 Epoch[36] Batch [270]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098784,	
2017-06-24 18:27:54,564 Epoch[36] Batch [280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098734,	
2017-06-24 18:28:05,630 Epoch[36] Batch [290]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.098656,	
2017-06-24 18:28:16,849 Epoch[36] Batch [300]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098614,	
2017-06-24 18:28:28,105 Epoch[36] Batch [310]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.098583,	
2017-06-24 18:28:39,009 Epoch[36] Batch [320]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098148,	
2017-06-24 18:28:49,958 Epoch[36] Batch [330]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.098058,	
2017-06-24 18:29:01,388 Epoch[36] Batch [340]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.097942,	
2017-06-24 18:29:12,311 Epoch[36] Batch [350]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.097896,	
2017-06-24 18:29:23,571 Epoch[36] Batch [360]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.097789,	
2017-06-24 18:29:34,287 Epoch[36] Batch [370]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097785,	
2017-06-24 18:29:45,345 Epoch[36] Batch [380]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.097633,	
2017-06-24 18:29:55,983 Epoch[36] Batch [390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097765,	
2017-06-24 18:30:06,974 Epoch[36] Batch [400]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.097646,	
2017-06-24 18:30:17,948 Epoch[36] Batch [410]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.097708,	
2017-06-24 18:30:28,453 Epoch[36] Batch [420]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097781,	
2017-06-24 18:30:39,849 Epoch[36] Batch [430]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.097861,	
2017-06-24 18:30:50,775 Epoch[36] Batch [440]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.097913,	
2017-06-24 18:31:02,266 Epoch[36] Batch [450]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-24 18:31:13,928 Epoch[36] Batch [460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097953,	
2017-06-24 18:31:24,939 Epoch[36] Batch [470]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.097850,	
2017-06-24 18:31:35,748 Epoch[36] Batch [480]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.097661,	
2017-06-24 18:31:46,583 Epoch[36] Batch [490]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.097537,	
2017-06-24 18:31:57,415 Epoch[36] Batch [500]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.097404,	
2017-06-24 18:32:08,046 Epoch[36] Batch [510]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097252,	
2017-06-24 18:32:19,595 Epoch[36] Batch [520]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.097220,	
2017-06-24 18:32:30,581 Epoch[36] Batch [530]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.097205,	
2017-06-24 18:32:41,079 Epoch[36] Batch [540]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097253,	
2017-06-24 18:32:50,909 Epoch[36] Batch [550]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.097110,	
2017-06-24 18:33:02,201 Epoch[36] Batch [560]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.097182,	
2017-06-24 18:33:12,911 Epoch[36] Batch [570]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097117,	
2017-06-24 18:33:24,821 Epoch[36] Batch [580]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.097002,	
2017-06-24 18:33:36,497 Epoch[36] Batch [590]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.096890,	
2017-06-24 18:33:47,790 Epoch[36] Batch [600]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.096855,	
2017-06-24 18:33:58,991 Epoch[36] Batch [610]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.096975,	
2017-06-24 18:34:09,912 Epoch[36] Batch [620]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.096910,	
2017-06-24 18:34:21,147 Epoch[36] Batch [630]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.096833,	
2017-06-24 18:34:32,366 Epoch[36] Batch [640]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.096933,	
2017-06-24 18:34:43,611 Epoch[36] Batch [650]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.097005,	
2017-06-24 18:34:54,112 Epoch[36] Batch [660]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097016,	
2017-06-24 18:35:05,859 Epoch[36] Batch [670]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.096983,	
2017-06-24 18:35:17,221 Epoch[36] Batch [680]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.096847,	
2017-06-24 18:35:28,447 Epoch[36] Batch [690]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.096763,	
2017-06-24 18:35:39,908 Epoch[36] Batch [700]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.096759,	
2017-06-24 18:35:49,828 Epoch[36] Batch [710]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.096720,	
2017-06-24 18:36:00,254 Epoch[36] Batch [720]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096664,	
2017-06-24 18:36:11,084 Epoch[36] Batch [730]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.096671,	
2017-06-24 18:36:22,307 Epoch[36] Batch [740]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.096674,	
2017-06-24 18:36:24,302 Epoch[36] Train-FCNLogLoss=0.096663
2017-06-24 18:36:24,302 Epoch[36] Time cost=820.194
2017-06-24 18:36:25,777 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0037.params"
2017-06-24 18:36:27,690 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0037.states"
2017-06-24 18:36:40,020 Epoch[37] Batch [10]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087779,	
2017-06-24 18:36:51,304 Epoch[37] Batch [20]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.089700,	
2017-06-24 18:37:02,019 Epoch[37] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088487,	
2017-06-24 18:37:12,390 Epoch[37] Batch [40]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089275,	
2017-06-24 18:37:23,275 Epoch[37] Batch [50]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.089541,	
2017-06-24 18:37:34,536 Epoch[37] Batch [60]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.089668,	
2017-06-24 18:37:45,404 Epoch[37] Batch [70]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090129,	
2017-06-24 18:37:56,464 Epoch[37] Batch [80]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.090769,	
2017-06-24 18:38:07,140 Epoch[37] Batch [90]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.091199,	
2017-06-24 18:38:18,069 Epoch[37] Batch [100]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.092036,	
2017-06-24 18:38:28,938 Epoch[37] Batch [110]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.092793,	
2017-06-24 18:38:39,951 Epoch[37] Batch [120]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.092773,	
2017-06-24 18:38:50,650 Epoch[37] Batch [130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092664,	
2017-06-24 18:39:00,580 Epoch[37] Batch [140]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.092533,	
2017-06-24 18:39:10,524 Epoch[37] Batch [150]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.092523,	
2017-06-24 18:39:21,290 Epoch[37] Batch [160]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092575,	
2017-06-24 18:39:30,955 Epoch[37] Batch [170]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092960,	
2017-06-24 18:39:40,972 Epoch[37] Batch [180]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.093211,	
2017-06-24 18:39:51,017 Epoch[37] Batch [190]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092893,	
2017-06-24 18:40:02,013 Epoch[37] Batch [200]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.092682,	
2017-06-24 18:40:12,632 Epoch[37] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092412,	
2017-06-24 18:40:23,238 Epoch[37] Batch [220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092420,	
2017-06-24 18:40:33,095 Epoch[37] Batch [230]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092443,	
2017-06-24 18:40:43,209 Epoch[37] Batch [240]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092512,	
2017-06-24 18:40:53,255 Epoch[37] Batch [250]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.092336,	
2017-06-24 18:41:03,460 Epoch[37] Batch [260]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.092251,	
2017-06-24 18:41:13,685 Epoch[37] Batch [270]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.092337,	
2017-06-24 18:41:23,940 Epoch[37] Batch [280]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.092408,	
2017-06-24 18:41:34,280 Epoch[37] Batch [290]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092388,	
2017-06-24 18:41:44,950 Epoch[37] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092639,	
2017-06-24 18:41:55,630 Epoch[37] Batch [310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092498,	
2017-06-24 18:42:06,508 Epoch[37] Batch [320]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.092363,	
2017-06-24 18:42:17,292 Epoch[37] Batch [330]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092438,	
2017-06-24 18:42:27,872 Epoch[37] Batch [340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092233,	
2017-06-24 18:42:38,634 Epoch[37] Batch [350]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092523,	
2017-06-24 18:42:49,875 Epoch[37] Batch [360]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.092441,	
2017-06-24 18:43:01,255 Epoch[37] Batch [370]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.092381,	
2017-06-24 18:43:12,841 Epoch[37] Batch [380]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.092533,	
2017-06-24 18:43:24,029 Epoch[37] Batch [390]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092567,	
2017-06-24 18:43:34,910 Epoch[37] Batch [400]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.092455,	
2017-06-24 18:43:46,236 Epoch[37] Batch [410]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.092513,	
2017-06-24 18:43:57,214 Epoch[37] Batch [420]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092432,	
2017-06-24 18:44:08,915 Epoch[37] Batch [430]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.092312,	
2017-06-24 18:44:19,772 Epoch[37] Batch [440]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.092332,	
2017-06-24 18:44:30,614 Epoch[37] Batch [450]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.092469,	
2017-06-24 18:44:42,034 Epoch[37] Batch [460]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.092341,	
2017-06-24 18:44:54,271 Epoch[37] Batch [470]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.092497,	
2017-06-24 18:45:06,726 Epoch[37] Batch [480]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.092652,	
2017-06-24 18:45:18,896 Epoch[37] Batch [490]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.092855,	
2017-06-24 18:45:30,840 Epoch[37] Batch [500]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.093038,	
2017-06-24 18:45:42,920 Epoch[37] Batch [510]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093048,	
2017-06-24 18:45:54,076 Epoch[37] Batch [520]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.093220,	
2017-06-24 18:46:05,642 Epoch[37] Batch [530]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093320,	
2017-06-24 18:46:18,027 Epoch[37] Batch [540]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.093629,	
2017-06-24 18:46:31,412 Epoch[37] Batch [550]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.093626,	
2017-06-24 18:46:45,118 Epoch[37] Batch [560]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.093685,	
2017-06-24 18:46:58,228 Epoch[37] Batch [570]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.093560,	
2017-06-24 18:47:11,508 Epoch[37] Batch [580]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.093532,	
2017-06-24 18:47:24,437 Epoch[37] Batch [590]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.093502,	
2017-06-24 18:47:37,428 Epoch[37] Batch [600]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.093524,	
2017-06-24 18:47:49,400 Epoch[37] Batch [610]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.093572,	
2017-06-24 18:48:01,059 Epoch[37] Batch [620]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.093819,	
2017-06-24 18:48:14,127 Epoch[37] Batch [630]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.094051,	
2017-06-24 18:48:27,588 Epoch[37] Batch [640]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.094267,	
2017-06-24 18:48:40,429 Epoch[37] Batch [650]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.094443,	
2017-06-24 18:48:53,579 Epoch[37] Batch [660]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.094507,	
2017-06-24 18:49:06,239 Epoch[37] Batch [670]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094548,	
2017-06-24 18:49:18,981 Epoch[37] Batch [680]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.094598,	
2017-06-24 18:49:31,045 Epoch[37] Batch [690]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.094725,	
2017-06-24 18:49:43,282 Epoch[37] Batch [700]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.094674,	
2017-06-24 18:49:55,758 Epoch[37] Batch [710]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.094663,	
2017-06-24 18:50:08,773 Epoch[37] Batch [720]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.094604,	
2017-06-24 18:50:22,399 Epoch[37] Batch [730]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.094532,	
2017-06-24 18:50:34,238 Epoch[37] Batch [740]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.094556,	
2017-06-24 18:50:36,829 Epoch[37] Train-FCNLogLoss=0.094545
2017-06-24 18:50:36,829 Epoch[37] Time cost=849.139
2017-06-24 18:50:38,802 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0038.params"
2017-06-24 18:50:41,759 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0038.states"
2017-06-24 18:50:55,450 Epoch[38] Batch [10]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.091708,	
2017-06-24 18:51:08,443 Epoch[38] Batch [20]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.093872,	
2017-06-24 18:51:19,829 Epoch[38] Batch [30]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.092632,	
2017-06-24 18:51:31,726 Epoch[38] Batch [40]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093176,	
2017-06-24 18:51:43,663 Epoch[38] Batch [50]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.092744,	
2017-06-24 18:51:56,177 Epoch[38] Batch [60]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.093392,	
2017-06-24 18:52:09,912 Epoch[38] Batch [70]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.093861,	
2017-06-24 18:52:23,836 Epoch[38] Batch [80]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.093434,	
2017-06-24 18:52:37,522 Epoch[38] Batch [90]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.093612,	
2017-06-24 18:52:50,539 Epoch[38] Batch [100]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.093859,	
2017-06-24 18:53:02,793 Epoch[38] Batch [110]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093417,	
2017-06-24 18:53:14,775 Epoch[38] Batch [120]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094371,	
2017-06-24 18:53:26,293 Epoch[38] Batch [130]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.093885,	
2017-06-24 18:53:38,847 Epoch[38] Batch [140]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.093639,	
2017-06-24 18:53:52,539 Epoch[38] Batch [150]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.093882,	
2017-06-24 18:54:06,670 Epoch[38] Batch [160]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.093474,	
2017-06-24 18:54:19,957 Epoch[38] Batch [170]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.093667,	
2017-06-24 18:54:32,434 Epoch[38] Batch [180]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093646,	
2017-06-24 18:54:45,546 Epoch[38] Batch [190]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.093819,	
2017-06-24 18:54:58,408 Epoch[38] Batch [200]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093878,	
2017-06-24 18:55:09,801 Epoch[38] Batch [210]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.093869,	
2017-06-24 18:55:21,382 Epoch[38] Batch [220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.093898,	
2017-06-24 18:55:33,114 Epoch[38] Batch [230]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.093880,	
2017-06-24 18:55:46,618 Epoch[38] Batch [240]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.093799,	
2017-06-24 18:55:59,665 Epoch[38] Batch [250]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.093842,	
2017-06-24 18:56:12,534 Epoch[38] Batch [260]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093669,	
2017-06-24 18:56:25,865 Epoch[38] Batch [270]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.093551,	
2017-06-24 18:56:39,531 Epoch[38] Batch [280]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.093698,	
2017-06-24 18:56:52,459 Epoch[38] Batch [290]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.093525,	
2017-06-24 18:57:04,745 Epoch[38] Batch [300]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.093342,	
2017-06-24 18:57:16,998 Epoch[38] Batch [310]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093373,	
2017-06-24 18:57:29,652 Epoch[38] Batch [320]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.093387,	
2017-06-24 18:57:42,805 Epoch[38] Batch [330]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.093208,	
2017-06-24 18:57:56,541 Epoch[38] Batch [340]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.093307,	
2017-06-24 18:58:09,826 Epoch[38] Batch [350]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.093201,	
2017-06-24 18:58:23,186 Epoch[38] Batch [360]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.093181,	
2017-06-24 18:58:36,335 Epoch[38] Batch [370]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.093108,	
2017-06-24 18:58:49,382 Epoch[38] Batch [380]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.092996,	
2017-06-24 18:59:00,960 Epoch[38] Batch [390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.092856,	
2017-06-24 18:59:13,789 Epoch[38] Batch [400]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.092899,	
2017-06-24 18:59:27,613 Epoch[38] Batch [410]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.093037,	
2017-06-24 18:59:41,108 Epoch[38] Batch [420]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.093108,	
2017-06-24 18:59:53,941 Epoch[38] Batch [430]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093092,	
2017-06-24 19:00:07,486 Epoch[38] Batch [440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.092935,	
2017-06-24 19:00:20,669 Epoch[38] Batch [450]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.093038,	
2017-06-24 19:00:33,324 Epoch[38] Batch [460]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.093113,	
2017-06-24 19:00:45,028 Epoch[38] Batch [470]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093074,	
2017-06-24 19:00:57,414 Epoch[38] Batch [480]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.093054,	
2017-06-24 19:01:11,436 Epoch[38] Batch [490]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.092894,	
2017-06-24 19:01:25,697 Epoch[38] Batch [500]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.092779,	
2017-06-24 19:01:39,227 Epoch[38] Batch [510]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.092800,	
2017-06-24 19:01:52,693 Epoch[38] Batch [520]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.092768,	
2017-06-24 19:02:05,173 Epoch[38] Batch [530]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.092889,	
2017-06-24 19:02:17,997 Epoch[38] Batch [540]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.092953,	
2017-06-24 19:02:30,811 Epoch[38] Batch [550]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.092910,	
2017-06-24 19:02:42,971 Epoch[38] Batch [560]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.092880,	
2017-06-24 19:02:55,553 Epoch[38] Batch [570]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.092843,	
2017-06-24 19:03:08,518 Epoch[38] Batch [580]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.092850,	
2017-06-24 19:03:21,191 Epoch[38] Batch [590]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.092860,	
2017-06-24 19:03:34,141 Epoch[38] Batch [600]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.092930,	
2017-06-24 19:03:46,054 Epoch[38] Batch [610]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.092897,	
2017-06-24 19:03:58,805 Epoch[38] Batch [620]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.092873,	
2017-06-24 19:04:11,075 Epoch[38] Batch [630]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.092780,	
2017-06-24 19:04:22,969 Epoch[38] Batch [640]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.092731,	
2017-06-24 19:04:34,526 Epoch[38] Batch [650]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.092598,	
2017-06-24 19:04:47,407 Epoch[38] Batch [660]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.092515,	
2017-06-24 19:04:59,979 Epoch[38] Batch [670]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.092485,	
2017-06-24 19:05:12,370 Epoch[38] Batch [680]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.092421,	
2017-06-24 19:05:24,639 Epoch[38] Batch [690]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.092358,	
2017-06-24 19:05:37,032 Epoch[38] Batch [700]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.092316,	
2017-06-24 19:05:50,127 Epoch[38] Batch [710]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.092342,	
2017-06-24 19:06:02,521 Epoch[38] Batch [720]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.092301,	
2017-06-24 19:06:15,031 Epoch[38] Batch [730]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.092345,	
2017-06-24 19:06:27,339 Epoch[38] Batch [740]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.092295,	
2017-06-24 19:06:29,844 Epoch[38] Train-FCNLogLoss=0.092334
2017-06-24 19:06:29,844 Epoch[38] Time cost=948.085
2017-06-24 19:06:31,756 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0039.params"
2017-06-24 19:06:34,026 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0039.states"
2017-06-24 19:06:48,627 Epoch[39] Batch [10]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.096769,	
2017-06-24 19:07:01,918 Epoch[39] Batch [20]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.093229,	
2017-06-24 19:07:15,363 Epoch[39] Batch [30]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.093213,	
2017-06-24 19:07:28,586 Epoch[39] Batch [40]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.092120,	
2017-06-24 19:07:40,435 Epoch[39] Batch [50]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.090265,	
2017-06-24 19:07:52,643 Epoch[39] Batch [60]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.090685,	
2017-06-24 19:08:04,400 Epoch[39] Batch [70]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-24 19:08:16,014 Epoch[39] Batch [80]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.090128,	
2017-06-24 19:08:28,462 Epoch[39] Batch [90]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.090760,	
2017-06-24 19:08:41,260 Epoch[39] Batch [100]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.091318,	
2017-06-24 19:08:54,220 Epoch[39] Batch [110]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.091570,	
2017-06-24 19:09:07,715 Epoch[39] Batch [120]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.091566,	
2017-06-24 19:09:21,001 Epoch[39] Batch [130]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.091309,	
2017-06-24 19:09:33,897 Epoch[39] Batch [140]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091450,	
2017-06-24 19:09:47,008 Epoch[39] Batch [150]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.091244,	
2017-06-24 19:10:00,415 Epoch[39] Batch [160]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.091669,	
2017-06-24 19:10:12,897 Epoch[39] Batch [170]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.091159,	
2017-06-24 19:10:26,581 Epoch[39] Batch [180]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.091137,	
2017-06-24 19:10:40,650 Epoch[39] Batch [190]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.091073,	
2017-06-24 19:10:52,998 Epoch[39] Batch [200]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.090988,	
2017-06-24 19:11:05,120 Epoch[39] Batch [210]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.091378,	
2017-06-24 19:11:18,486 Epoch[39] Batch [220]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.091429,	
2017-06-24 19:11:30,683 Epoch[39] Batch [230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.091414,	
2017-06-24 19:11:42,795 Epoch[39] Batch [240]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.091277,	
2017-06-24 19:11:54,732 Epoch[39] Batch [250]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.091226,	
2017-06-24 19:12:07,646 Epoch[39] Batch [260]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091272,	
2017-06-24 19:12:21,407 Epoch[39] Batch [270]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.091360,	
2017-06-24 19:12:34,864 Epoch[39] Batch [280]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.091326,	
2017-06-24 19:12:48,550 Epoch[39] Batch [290]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.091367,	
2017-06-24 19:13:01,042 Epoch[39] Batch [300]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.091286,	
2017-06-24 19:13:14,132 Epoch[39] Batch [310]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.091093,	
2017-06-24 19:13:26,448 Epoch[39] Batch [320]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.091061,	
2017-06-24 19:13:38,685 Epoch[39] Batch [330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.090840,	
2017-06-24 19:13:50,177 Epoch[39] Batch [340]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.091163,	
2017-06-24 19:14:02,011 Epoch[39] Batch [350]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.091374,	
2017-06-24 19:14:15,403 Epoch[39] Batch [360]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.091421,	
2017-06-24 19:14:28,883 Epoch[39] Batch [370]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.091549,	
2017-06-24 19:14:42,314 Epoch[39] Batch [380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.091527,	
2017-06-24 19:14:55,721 Epoch[39] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.091468,	
2017-06-24 19:15:08,535 Epoch[39] Batch [400]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.091322,	
2017-06-24 19:15:20,947 Epoch[39] Batch [410]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.091259,	
2017-06-24 19:15:33,044 Epoch[39] Batch [420]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.091349,	
2017-06-24 19:15:44,244 Epoch[39] Batch [430]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.091185,	
2017-06-24 19:15:57,398 Epoch[39] Batch [440]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.091207,	
2017-06-24 19:16:11,069 Epoch[39] Batch [450]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.091166,	
2017-06-24 19:16:24,951 Epoch[39] Batch [460]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.091237,	
2017-06-24 19:16:38,739 Epoch[39] Batch [470]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.091259,	
2017-06-24 19:16:50,034 Epoch[39] Batch [480]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.091240,	
2017-06-24 19:17:02,623 Epoch[39] Batch [490]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.091259,	
2017-06-24 19:17:14,198 Epoch[39] Batch [500]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.091332,	
2017-06-24 19:17:26,560 Epoch[39] Batch [510]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.091263,	
2017-06-24 19:17:39,704 Epoch[39] Batch [520]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.091383,	
2017-06-24 19:17:52,688 Epoch[39] Batch [530]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091363,	
2017-06-24 19:18:06,246 Epoch[39] Batch [540]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.091362,	
2017-06-24 19:18:18,983 Epoch[39] Batch [550]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.091276,	
2017-06-24 19:18:31,589 Epoch[39] Batch [560]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.091224,	
2017-06-24 19:18:43,986 Epoch[39] Batch [570]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.091244,	
2017-06-24 19:18:56,560 Epoch[39] Batch [580]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.091172,	
2017-06-24 19:19:08,953 Epoch[39] Batch [590]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.091277,	
2017-06-24 19:19:21,191 Epoch[39] Batch [600]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.091320,	
2017-06-24 19:19:34,486 Epoch[39] Batch [610]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.091358,	
2017-06-24 19:19:48,705 Epoch[39] Batch [620]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.091223,	
2017-06-24 19:20:03,228 Epoch[39] Batch [630]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.091259,	
2017-06-24 19:20:15,949 Epoch[39] Batch [640]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.091220,	
2017-06-24 19:20:29,196 Epoch[39] Batch [650]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.091197,	
2017-06-24 19:20:41,709 Epoch[39] Batch [660]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.091286,	
2017-06-24 19:20:53,254 Epoch[39] Batch [670]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.091287,	
2017-06-24 19:21:04,964 Epoch[39] Batch [680]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.091301,	
2017-06-24 19:21:16,721 Epoch[39] Batch [690]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.091410,	
2017-06-24 19:21:30,245 Epoch[39] Batch [700]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.091322,	
2017-06-24 19:21:42,732 Epoch[39] Batch [710]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.091370,	
2017-06-24 19:21:55,391 Epoch[39] Batch [720]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.091407,	
2017-06-24 19:22:09,106 Epoch[39] Batch [730]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.091275,	
2017-06-24 19:22:22,746 Epoch[39] Batch [740]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.091250,	
2017-06-24 19:22:25,268 Epoch[39] Train-FCNLogLoss=0.091286
2017-06-24 19:22:25,268 Epoch[39] Time cost=951.242
2017-06-24 19:22:27,111 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0040.params"
2017-06-24 19:22:29,513 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0040.states"
2017-06-24 19:22:43,693 Epoch[40] Batch [10]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.094333,	
2017-06-24 19:22:56,112 Epoch[40] Batch [20]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093939,	
2017-06-24 19:23:07,240 Epoch[40] Batch [30]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.094005,	
2017-06-24 19:23:20,109 Epoch[40] Batch [40]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.092049,	
2017-06-24 19:23:33,345 Epoch[40] Batch [50]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.092284,	
2017-06-24 19:23:46,193 Epoch[40] Batch [60]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.092866,	
2017-06-24 19:23:58,597 Epoch[40] Batch [70]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.092662,	
2017-06-24 19:24:11,203 Epoch[40] Batch [80]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.091945,	
2017-06-24 19:24:23,272 Epoch[40] Batch [90]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.091707,	
2017-06-24 19:24:34,681 Epoch[40] Batch [100]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.092063,	
2017-06-24 19:24:46,865 Epoch[40] Batch [110]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.091575,	
2017-06-24 19:25:00,282 Epoch[40] Batch [120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.091730,	
2017-06-24 19:25:14,219 Epoch[40] Batch [130]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.091803,	
2017-06-24 19:25:28,076 Epoch[40] Batch [140]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.092789,	
2017-06-24 19:25:41,988 Epoch[40] Batch [150]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.093412,	
2017-06-24 19:25:54,592 Epoch[40] Batch [160]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.093652,	
2017-06-24 19:26:07,077 Epoch[40] Batch [170]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093613,	
2017-06-24 19:26:18,479 Epoch[40] Batch [180]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.093331,	
2017-06-24 19:26:31,086 Epoch[40] Batch [190]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.093043,	
2017-06-24 19:26:42,963 Epoch[40] Batch [200]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093106,	
2017-06-24 19:26:56,583 Epoch[40] Batch [210]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.092750,	
2017-06-24 19:27:09,332 Epoch[40] Batch [220]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.092800,	
2017-06-24 19:27:22,737 Epoch[40] Batch [230]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.092950,	
2017-06-24 19:27:36,805 Epoch[40] Batch [240]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.092773,	
2017-06-24 19:27:50,565 Epoch[40] Batch [250]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.092960,	
2017-06-24 19:28:04,278 Epoch[40] Batch [260]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.092920,	
2017-06-24 19:28:17,013 Epoch[40] Batch [270]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.092977,	
2017-06-24 19:28:28,033 Update[30000]: Change learning rate to 5.00000e-05
2017-06-24 19:28:29,670 Epoch[40] Batch [280]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.093072,	
2017-06-24 19:28:43,040 Epoch[40] Batch [290]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.093164,	
2017-06-24 19:28:56,455 Epoch[40] Batch [300]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.093025,	
2017-06-24 19:29:09,652 Epoch[40] Batch [310]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.092846,	
2017-06-24 19:29:22,032 Epoch[40] Batch [320]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.092943,	
2017-06-24 19:29:34,725 Epoch[40] Batch [330]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.092835,	
2017-06-24 19:29:47,989 Epoch[40] Batch [340]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.092851,	
2017-06-24 19:30:00,025 Epoch[40] Batch [350]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.092805,	
2017-06-24 19:30:11,273 Epoch[40] Batch [360]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.092683,	
2017-06-24 19:30:23,128 Epoch[40] Batch [370]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.092384,	
2017-06-24 19:30:35,780 Epoch[40] Batch [380]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.092083,	
2017-06-24 19:30:48,327 Epoch[40] Batch [390]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.092021,	
2017-06-24 19:31:07,228 Epoch[40] Batch [400]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.091871,	
2017-06-24 19:31:26,371 Epoch[40] Batch [410]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.091846,	
2017-06-24 19:31:45,593 Epoch[40] Batch [420]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.091989,	
2017-06-24 19:31:58,161 Epoch[40] Batch [430]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.091744,	
2017-06-24 19:32:09,937 Epoch[40] Batch [440]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.091713,	
2017-06-24 19:32:22,758 Epoch[40] Batch [450]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.091628,	
2017-06-24 19:32:35,523 Epoch[40] Batch [460]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.091712,	
2017-06-24 19:32:49,040 Epoch[40] Batch [470]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.091567,	
2017-06-24 19:33:02,443 Epoch[40] Batch [480]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.091449,	
2017-06-24 19:33:15,680 Epoch[40] Batch [490]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.091251,	
2017-06-24 19:33:28,299 Epoch[40] Batch [500]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.091145,	
2017-06-24 19:33:41,241 Epoch[40] Batch [510]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.090914,	
2017-06-24 19:33:53,687 Epoch[40] Batch [520]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.090772,	
2017-06-24 19:34:06,385 Epoch[40] Batch [530]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.090844,	
2017-06-24 19:34:20,699 Epoch[40] Batch [540]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.090765,	
2017-06-24 19:34:34,124 Epoch[40] Batch [550]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.090759,	
2017-06-24 19:34:47,254 Epoch[40] Batch [560]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.090844,	
2017-06-24 19:34:59,932 Epoch[40] Batch [570]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.090831,	
2017-06-24 19:35:12,304 Epoch[40] Batch [580]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090768,	
2017-06-24 19:35:24,253 Epoch[40] Batch [590]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.090893,	
2017-06-24 19:35:36,675 Epoch[40] Batch [600]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.090938,	
2017-06-24 19:35:49,254 Epoch[40] Batch [610]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.090906,	
2017-06-24 19:36:02,441 Epoch[40] Batch [620]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.090895,	
2017-06-24 19:36:15,670 Epoch[40] Batch [630]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.090920,	
2017-06-24 19:36:29,682 Epoch[40] Batch [640]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.090937,	
2017-06-24 19:36:43,064 Epoch[40] Batch [650]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.090944,	
2017-06-24 19:36:55,857 Epoch[40] Batch [660]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.090960,	
2017-06-24 19:37:08,003 Epoch[40] Batch [670]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.090918,	
2017-06-24 19:37:20,381 Epoch[40] Batch [680]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.090870,	
2017-06-24 19:37:32,648 Epoch[40] Batch [690]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.090880,	
2017-06-24 19:37:44,978 Epoch[40] Batch [700]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.090874,	
2017-06-24 19:37:57,928 Epoch[40] Batch [710]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.090758,	
2017-06-24 19:38:11,506 Epoch[40] Batch [720]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.090798,	
2017-06-24 19:38:24,315 Epoch[40] Batch [730]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.090732,	
2017-06-24 19:38:36,668 Epoch[40] Batch [740]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.090684,	
2017-06-24 19:38:39,092 Epoch[40] Train-FCNLogLoss=0.090661
2017-06-24 19:38:39,093 Epoch[40] Time cost=969.579
2017-06-24 19:38:40,551 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0041.params"
2017-06-24 19:38:42,527 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0041.states"
2017-06-24 19:38:56,803 Epoch[41] Batch [10]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.089381,	
2017-06-24 19:39:09,294 Epoch[41] Batch [20]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.085976,	
2017-06-24 19:39:22,351 Epoch[41] Batch [30]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.084398,	
2017-06-24 19:39:34,475 Epoch[41] Batch [40]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.086033,	
2017-06-24 19:39:47,971 Epoch[41] Batch [50]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-24 19:40:01,712 Epoch[41] Batch [60]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.087482,	
2017-06-24 19:40:15,082 Epoch[41] Batch [70]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087063,	
2017-06-24 19:40:27,703 Epoch[41] Batch [80]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086340,	
2017-06-24 19:40:41,355 Epoch[41] Batch [90]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.086873,	
2017-06-24 19:40:54,215 Epoch[41] Batch [100]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.086465,	
2017-06-24 19:41:07,970 Epoch[41] Batch [110]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.087158,	
2017-06-24 19:41:21,049 Epoch[41] Batch [120]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087940,	
2017-06-24 19:41:33,183 Epoch[41] Batch [130]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.088074,	
2017-06-24 19:41:46,853 Epoch[41] Batch [140]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.087500,	
2017-06-24 19:42:00,892 Epoch[41] Batch [150]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.087713,	
2017-06-24 19:42:14,753 Epoch[41] Batch [160]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.087526,	
2017-06-24 19:42:27,621 Epoch[41] Batch [170]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087783,	
2017-06-24 19:42:40,386 Epoch[41] Batch [180]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.087765,	
2017-06-24 19:42:53,239 Epoch[41] Batch [190]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087923,	
2017-06-24 19:43:06,445 Epoch[41] Batch [200]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087840,	
2017-06-24 19:43:18,106 Epoch[41] Batch [210]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087991,	
2017-06-24 19:43:30,433 Epoch[41] Batch [220]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.088048,	
2017-06-24 19:43:43,334 Epoch[41] Batch [230]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088017,	
2017-06-24 19:43:56,626 Epoch[41] Batch [240]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087931,	
2017-06-24 19:44:09,207 Epoch[41] Batch [250]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087518,	
2017-06-24 19:44:21,600 Epoch[41] Batch [260]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.087419,	
2017-06-24 19:44:34,791 Epoch[41] Batch [270]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087414,	
2017-06-24 19:44:47,913 Epoch[41] Batch [280]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087399,	
2017-06-24 19:45:00,440 Epoch[41] Batch [290]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087476,	
2017-06-24 19:45:12,622 Epoch[41] Batch [300]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087436,	
2017-06-24 19:45:25,596 Epoch[41] Batch [310]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.087555,	
2017-06-24 19:45:39,267 Epoch[41] Batch [320]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.087515,	
2017-06-24 19:45:52,872 Epoch[41] Batch [330]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087408,	
2017-06-24 19:46:05,466 Epoch[41] Batch [340]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087280,	
2017-06-24 19:46:19,029 Epoch[41] Batch [350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087364,	
2017-06-24 19:46:32,654 Epoch[41] Batch [360]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087530,	
2017-06-24 19:46:46,159 Epoch[41] Batch [370]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.087508,	
2017-06-24 19:46:58,072 Epoch[41] Batch [380]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087263,	
2017-06-24 19:47:10,175 Epoch[41] Batch [390]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-24 19:47:22,179 Epoch[41] Batch [400]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.087347,	
2017-06-24 19:47:35,567 Epoch[41] Batch [410]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-24 19:47:48,135 Epoch[41] Batch [420]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.087250,	
2017-06-24 19:48:01,524 Epoch[41] Batch [430]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087084,	
2017-06-24 19:48:14,587 Epoch[41] Batch [440]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087239,	
2017-06-24 19:48:26,931 Epoch[41] Batch [450]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087099,	
2017-06-24 19:48:39,272 Epoch[41] Batch [460]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087035,	
2017-06-24 19:48:51,473 Epoch[41] Batch [470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.087162,	
2017-06-24 19:49:03,712 Epoch[41] Batch [480]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087111,	
2017-06-24 19:49:16,347 Epoch[41] Batch [490]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087118,	
2017-06-24 19:49:29,199 Epoch[41] Batch [500]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087056,	
2017-06-24 19:49:42,559 Epoch[41] Batch [510]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086992,	
2017-06-24 19:49:56,373 Epoch[41] Batch [520]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.086919,	
2017-06-24 19:50:09,286 Epoch[41] Batch [530]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.086884,	
2017-06-24 19:50:22,984 Epoch[41] Batch [540]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.086890,	
2017-06-24 19:50:35,570 Epoch[41] Batch [550]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087052,	
2017-06-24 19:50:49,106 Epoch[41] Batch [560]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.086966,	
2017-06-24 19:51:01,551 Epoch[41] Batch [570]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086983,	
2017-06-24 19:51:14,765 Epoch[41] Batch [580]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.086984,	
2017-06-24 19:51:28,195 Epoch[41] Batch [590]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087064,	
2017-06-24 19:51:42,080 Epoch[41] Batch [600]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.087216,	
2017-06-24 19:51:55,925 Epoch[41] Batch [610]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.087349,	
2017-06-24 19:52:09,386 Epoch[41] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-24 19:52:21,730 Epoch[41] Batch [630]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087388,	
2017-06-24 19:52:34,532 Epoch[41] Batch [640]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087362,	
2017-06-24 19:52:46,749 Epoch[41] Batch [650]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087289,	
2017-06-24 19:52:58,259 Epoch[41] Batch [660]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087312,	
2017-06-24 19:53:10,209 Epoch[41] Batch [670]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087304,	
2017-06-24 19:53:22,501 Epoch[41] Batch [680]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.087316,	
2017-06-24 19:53:35,873 Epoch[41] Batch [690]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087430,	
2017-06-24 19:53:49,328 Epoch[41] Batch [700]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.087436,	
2017-06-24 19:54:02,610 Epoch[41] Batch [710]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087454,	
2017-06-24 19:54:16,272 Epoch[41] Batch [720]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.087483,	
2017-06-24 19:54:29,087 Epoch[41] Batch [730]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.087500,	
2017-06-24 19:54:40,563 Epoch[41] Batch [740]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087545,	
2017-06-24 19:54:43,047 Epoch[41] Train-FCNLogLoss=0.087567
2017-06-24 19:54:43,047 Epoch[41] Time cost=960.519
2017-06-24 19:54:45,617 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0042.params"
2017-06-24 19:54:47,715 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0042.states"
2017-06-24 19:55:01,304 Epoch[42] Batch [10]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.082097,	
2017-06-24 19:55:14,189 Epoch[42] Batch [20]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087276,	
2017-06-24 19:55:28,259 Epoch[42] Batch [30]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-24 19:55:42,280 Epoch[42] Batch [40]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.089306,	
2017-06-24 19:55:55,114 Epoch[42] Batch [50]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087717,	
2017-06-24 19:56:07,951 Epoch[42] Batch [60]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087001,	
2017-06-24 19:56:20,294 Epoch[42] Batch [70]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.086367,	
2017-06-24 19:56:32,821 Epoch[42] Batch [80]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.086524,	
2017-06-24 19:56:45,487 Epoch[42] Batch [90]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087009,	
2017-06-24 19:56:58,219 Epoch[42] Batch [100]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087204,	
2017-06-24 19:57:11,854 Epoch[42] Batch [110]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087309,	
2017-06-24 19:57:25,576 Epoch[42] Batch [120]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087412,	
2017-06-24 19:57:37,533 Epoch[42] Batch [130]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-24 19:57:50,127 Epoch[42] Batch [140]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087362,	
2017-06-24 19:58:02,760 Epoch[42] Batch [150]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087549,	
2017-06-24 19:58:15,123 Epoch[42] Batch [160]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.087314,	
2017-06-24 19:58:27,976 Epoch[42] Batch [170]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087413,	
2017-06-24 19:58:39,499 Epoch[42] Batch [180]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087176,	
2017-06-24 19:58:53,232 Epoch[42] Batch [190]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086936,	
2017-06-24 19:59:05,808 Epoch[42] Batch [200]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.086908,	
2017-06-24 19:59:18,735 Epoch[42] Batch [210]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.086688,	
2017-06-24 19:59:31,609 Epoch[42] Batch [220]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086823,	
2017-06-24 19:59:43,785 Epoch[42] Batch [230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.086693,	
2017-06-24 19:59:56,243 Epoch[42] Batch [240]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.086834,	
2017-06-24 20:00:08,946 Epoch[42] Batch [250]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086915,	
2017-06-24 20:00:21,502 Epoch[42] Batch [260]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.086857,	
2017-06-24 20:00:34,515 Epoch[42] Batch [270]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.087132,	
2017-06-24 20:00:48,675 Epoch[42] Batch [280]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087093,	
2017-06-24 20:01:02,141 Epoch[42] Batch [290]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087032,	
2017-06-24 20:01:14,612 Epoch[42] Batch [300]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087098,	
2017-06-24 20:01:27,880 Epoch[42] Batch [310]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.087152,	
2017-06-24 20:01:40,761 Epoch[42] Batch [320]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087260,	
2017-06-24 20:01:54,243 Epoch[42] Batch [330]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087441,	
2017-06-24 20:02:07,598 Epoch[42] Batch [340]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.087569,	
2017-06-24 20:02:19,766 Epoch[42] Batch [350]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087604,	
2017-06-24 20:02:34,766 Epoch[42] Batch [360]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.087575,	
2017-06-24 20:02:49,251 Epoch[42] Batch [370]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087738,	
2017-06-24 20:03:03,892 Epoch[42] Batch [380]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087582,	
2017-06-24 20:03:17,868 Epoch[42] Batch [390]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087502,	
2017-06-24 20:03:30,500 Epoch[42] Batch [400]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087459,	
2017-06-24 20:03:43,163 Epoch[42] Batch [410]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087526,	
2017-06-24 20:03:54,692 Epoch[42] Batch [420]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087699,	
2017-06-24 20:04:07,336 Epoch[42] Batch [430]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087553,	
2017-06-24 20:04:20,192 Epoch[42] Batch [440]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087630,	
2017-06-24 20:04:34,101 Epoch[42] Batch [450]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087708,	
2017-06-24 20:04:49,437 Epoch[42] Batch [460]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.087661,	
2017-06-24 20:05:02,464 Epoch[42] Batch [470]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-24 20:05:14,622 Epoch[42] Batch [480]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087367,	
2017-06-24 20:05:28,228 Epoch[42] Batch [490]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087279,	
2017-06-24 20:05:40,423 Epoch[42] Batch [500]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.087377,	
2017-06-24 20:05:53,187 Epoch[42] Batch [510]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-24 20:06:06,555 Epoch[42] Batch [520]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087209,	
2017-06-24 20:06:20,025 Epoch[42] Batch [530]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.087181,	
2017-06-24 20:06:33,351 Epoch[42] Batch [540]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.087288,	
2017-06-24 20:06:46,521 Epoch[42] Batch [550]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.087370,	
2017-06-24 20:06:59,726 Epoch[42] Batch [560]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-24 20:07:12,438 Epoch[42] Batch [570]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-24 20:07:24,309 Epoch[42] Batch [580]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087436,	
2017-06-24 20:07:37,548 Epoch[42] Batch [590]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087491,	
2017-06-24 20:07:50,254 Epoch[42] Batch [600]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.087456,	
2017-06-24 20:08:02,851 Epoch[42] Batch [610]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087450,	
2017-06-24 20:08:16,416 Epoch[42] Batch [620]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087506,	
2017-06-24 20:08:28,935 Epoch[42] Batch [630]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087513,	
2017-06-24 20:08:41,289 Epoch[42] Batch [640]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087434,	
2017-06-24 20:08:54,021 Epoch[42] Batch [650]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087436,	
2017-06-24 20:09:06,854 Epoch[42] Batch [660]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-24 20:09:18,419 Epoch[42] Batch [670]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-24 20:09:31,125 Epoch[42] Batch [680]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.087517,	
2017-06-24 20:09:43,412 Epoch[42] Batch [690]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.087530,	
2017-06-24 20:09:55,020 Epoch[42] Batch [700]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.087461,	
2017-06-24 20:10:07,171 Epoch[42] Batch [710]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087455,	
2017-06-24 20:10:20,887 Epoch[42] Batch [720]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-24 20:10:34,466 Epoch[42] Batch [730]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.087370,	
2017-06-24 20:10:46,942 Epoch[42] Batch [740]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.087419,	
2017-06-24 20:10:49,618 Epoch[42] Train-FCNLogLoss=0.087423
2017-06-24 20:10:49,618 Epoch[42] Time cost=961.902
2017-06-24 20:10:51,189 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0043.params"
2017-06-24 20:10:53,176 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0043.states"
2017-06-24 20:11:06,398 Epoch[43] Batch [10]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.085373,	
2017-06-24 20:11:19,164 Epoch[43] Batch [20]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088250,	
2017-06-24 20:11:32,184 Epoch[43] Batch [30]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.088919,	
2017-06-24 20:11:43,983 Epoch[43] Batch [40]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.088683,	
2017-06-24 20:11:56,596 Epoch[43] Batch [50]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088943,	
2017-06-24 20:12:09,090 Epoch[43] Batch [60]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.089581,	
2017-06-24 20:12:21,567 Epoch[43] Batch [70]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.089245,	
2017-06-24 20:12:34,890 Epoch[43] Batch [80]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.089022,	
2017-06-24 20:12:47,389 Epoch[43] Batch [90]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.089017,	
2017-06-24 20:12:59,276 Epoch[43] Batch [100]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.089216,	
2017-06-24 20:13:09,368 Epoch[43] Batch [110]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089107,	
2017-06-24 20:13:19,156 Epoch[43] Batch [120]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089149,	
2017-06-24 20:13:28,107 Epoch[43] Batch [130]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.089009,	
2017-06-24 20:13:37,991 Epoch[43] Batch [140]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088685,	
2017-06-24 20:13:48,863 Epoch[43] Batch [150]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088663,	
2017-06-24 20:14:00,577 Epoch[43] Batch [160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.089049,	
2017-06-24 20:14:11,393 Epoch[43] Batch [170]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089186,	
2017-06-24 20:14:22,347 Epoch[43] Batch [180]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088873,	
2017-06-24 20:14:33,110 Epoch[43] Batch [190]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088337,	
2017-06-24 20:14:45,003 Epoch[43] Batch [200]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.088063,	
2017-06-24 20:14:56,572 Epoch[43] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088028,	
2017-06-24 20:15:08,215 Epoch[43] Batch [220]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.087860,	
2017-06-24 20:15:19,202 Epoch[43] Batch [230]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087693,	
2017-06-24 20:15:30,094 Epoch[43] Batch [240]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087952,	
2017-06-24 20:15:42,503 Epoch[43] Batch [250]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.087849,	
2017-06-24 20:15:53,176 Epoch[43] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087832,	
2017-06-24 20:16:04,232 Epoch[43] Batch [270]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.087848,	
2017-06-24 20:16:14,557 Epoch[43] Batch [280]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087867,	
2017-06-24 20:16:25,342 Epoch[43] Batch [290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087838,	
2017-06-24 20:16:35,757 Epoch[43] Batch [300]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087746,	
2017-06-24 20:16:45,797 Epoch[43] Batch [310]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-24 20:16:55,834 Epoch[43] Batch [320]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.087669,	
2017-06-24 20:17:05,625 Epoch[43] Batch [330]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-24 20:17:16,404 Epoch[43] Batch [340]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087633,	
2017-06-24 20:17:27,308 Epoch[43] Batch [350]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.087592,	
2017-06-24 20:17:38,511 Epoch[43] Batch [360]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.087466,	
2017-06-24 20:17:50,783 Epoch[43] Batch [370]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087424,	
2017-06-24 20:18:02,294 Epoch[43] Batch [380]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087434,	
2017-06-24 20:18:13,791 Epoch[43] Batch [390]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-24 20:18:25,356 Epoch[43] Batch [400]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087610,	
2017-06-24 20:18:37,094 Epoch[43] Batch [410]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.087634,	
2017-06-24 20:18:47,552 Epoch[43] Batch [420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087673,	
2017-06-24 20:18:57,942 Epoch[43] Batch [430]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087666,	
2017-06-24 20:19:08,168 Epoch[43] Batch [440]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087584,	
2017-06-24 20:19:18,273 Epoch[43] Batch [450]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087701,	
2017-06-24 20:19:28,104 Epoch[43] Batch [460]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.087811,	
2017-06-24 20:19:36,903 Epoch[43] Batch [470]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-24 20:19:45,604 Epoch[43] Batch [480]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087832,	
2017-06-24 20:19:54,197 Epoch[43] Batch [490]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087898,	
2017-06-24 20:20:03,337 Epoch[43] Batch [500]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-24 20:20:12,533 Epoch[43] Batch [510]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-24 20:20:23,312 Epoch[43] Batch [520]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087796,	
2017-06-24 20:20:34,530 Epoch[43] Batch [530]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.087768,	
2017-06-24 20:20:44,427 Epoch[43] Batch [540]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087804,	
2017-06-24 20:20:54,713 Epoch[43] Batch [550]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.087757,	
2017-06-24 20:21:05,173 Epoch[43] Batch [560]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.087793,	
2017-06-24 20:21:15,814 Epoch[43] Batch [570]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087817,	
2017-06-24 20:21:25,702 Epoch[43] Batch [580]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-24 20:21:35,592 Epoch[43] Batch [590]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087827,	
2017-06-24 20:21:45,139 Epoch[43] Batch [600]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087750,	
2017-06-24 20:21:54,879 Epoch[43] Batch [610]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.087732,	
2017-06-24 20:22:04,436 Epoch[43] Batch [620]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087656,	
2017-06-24 20:22:13,897 Epoch[43] Batch [630]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087628,	
2017-06-24 20:22:24,083 Epoch[43] Batch [640]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-24 20:22:33,873 Epoch[43] Batch [650]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087509,	
2017-06-24 20:22:44,258 Epoch[43] Batch [660]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-24 20:22:54,554 Epoch[43] Batch [670]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087422,	
2017-06-24 20:23:05,898 Epoch[43] Batch [680]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-24 20:23:15,469 Epoch[43] Batch [690]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087437,	
2017-06-24 20:23:25,177 Epoch[43] Batch [700]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.087451,	
2017-06-24 20:23:35,533 Epoch[43] Batch [710]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087457,	
2017-06-24 20:23:46,316 Epoch[43] Batch [720]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087429,	
2017-06-24 20:23:56,067 Epoch[43] Batch [730]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.087393,	
2017-06-24 20:24:06,316 Epoch[43] Batch [740]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087414,	
2017-06-24 20:24:07,878 Epoch[43] Train-FCNLogLoss=0.087420
2017-06-24 20:24:07,878 Epoch[43] Time cost=794.701
2017-06-24 20:24:09,452 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0044.params"
2017-06-24 20:24:11,564 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0044.states"
2017-06-24 20:24:21,871 Epoch[44] Batch [10]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.090215,	
2017-06-24 20:24:30,909 Epoch[44] Batch [20]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.092209,	
2017-06-24 20:24:40,210 Epoch[44] Batch [30]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090949,	
2017-06-24 20:24:48,422 Epoch[44] Batch [40]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.089669,	
2017-06-24 20:24:56,245 Epoch[44] Batch [50]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.088455,	
2017-06-24 20:25:05,502 Epoch[44] Batch [60]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-24 20:25:14,755 Epoch[44] Batch [70]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089023,	
2017-06-24 20:25:24,462 Epoch[44] Batch [80]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088736,	
2017-06-24 20:25:34,267 Epoch[44] Batch [90]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.087995,	
2017-06-24 20:25:43,778 Epoch[44] Batch [100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088330,	
2017-06-24 20:25:53,293 Epoch[44] Batch [110]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087825,	
2017-06-24 20:26:02,893 Epoch[44] Batch [120]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086903,	
2017-06-24 20:26:12,745 Epoch[44] Batch [130]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086724,	
2017-06-24 20:26:21,400 Epoch[44] Batch [140]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.086612,	
2017-06-24 20:26:30,232 Epoch[44] Batch [150]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087030,	
2017-06-24 20:26:39,823 Epoch[44] Batch [160]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086912,	
2017-06-24 20:26:49,459 Epoch[44] Batch [170]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086970,	
2017-06-24 20:26:58,373 Epoch[44] Batch [180]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087287,	
2017-06-24 20:27:07,258 Epoch[44] Batch [190]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087162,	
2017-06-24 20:27:17,477 Epoch[44] Batch [200]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086955,	
2017-06-24 20:27:26,708 Epoch[44] Batch [210]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086972,	
2017-06-24 20:27:35,313 Epoch[44] Batch [220]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.086856,	
2017-06-24 20:27:43,736 Epoch[44] Batch [230]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086920,	
2017-06-24 20:27:51,691 Epoch[44] Batch [240]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.086908,	
2017-06-24 20:28:01,416 Epoch[44] Batch [250]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087149,	
2017-06-24 20:28:11,813 Epoch[44] Batch [260]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087090,	
2017-06-24 20:28:21,455 Epoch[44] Batch [270]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087036,	
2017-06-24 20:28:30,596 Epoch[44] Batch [280]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.086984,	
2017-06-24 20:28:39,625 Epoch[44] Batch [290]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086974,	
2017-06-24 20:28:48,934 Epoch[44] Batch [300]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.086812,	
2017-06-24 20:28:59,024 Epoch[44] Batch [310]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086973,	
2017-06-24 20:29:07,811 Epoch[44] Batch [320]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.086837,	
2017-06-24 20:29:17,366 Epoch[44] Batch [330]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086874,	
2017-06-24 20:29:25,378 Epoch[44] Batch [340]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.086934,	
2017-06-24 20:29:35,269 Epoch[44] Batch [350]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086762,	
2017-06-24 20:29:44,487 Epoch[44] Batch [360]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.086640,	
2017-06-24 20:29:53,960 Epoch[44] Batch [370]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.086510,	
2017-06-24 20:30:03,717 Epoch[44] Batch [380]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086508,	
2017-06-24 20:30:12,121 Epoch[44] Batch [390]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.086455,	
2017-06-24 20:30:20,711 Epoch[44] Batch [400]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.086397,	
2017-06-24 20:30:28,393 Epoch[44] Batch [410]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.086344,	
2017-06-24 20:30:36,323 Epoch[44] Batch [420]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.086473,	
2017-06-24 20:30:45,008 Epoch[44] Batch [430]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.086541,	
2017-06-24 20:30:53,925 Epoch[44] Batch [440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.086381,	
2017-06-24 20:31:01,938 Epoch[44] Batch [450]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.086285,	
2017-06-24 20:31:10,041 Epoch[44] Batch [460]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.086156,	
2017-06-24 20:31:19,465 Epoch[44] Batch [470]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.086162,	
2017-06-24 20:31:30,353 Epoch[44] Batch [480]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.086398,	
2017-06-24 20:31:40,438 Epoch[44] Batch [490]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.086235,	
2017-06-24 20:31:49,410 Epoch[44] Batch [500]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086214,	
2017-06-24 20:31:58,532 Epoch[44] Batch [510]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086321,	
2017-06-24 20:32:07,348 Epoch[44] Batch [520]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.086251,	
2017-06-24 20:32:15,893 Epoch[44] Batch [530]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.086179,	
2017-06-24 20:32:25,676 Epoch[44] Batch [540]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086337,	
2017-06-24 20:32:34,297 Epoch[44] Batch [550]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.086385,	
2017-06-24 20:32:42,116 Epoch[44] Batch [560]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.086273,	
2017-06-24 20:32:51,158 Epoch[44] Batch [570]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086248,	
2017-06-24 20:33:00,217 Epoch[44] Batch [580]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.086235,	
2017-06-24 20:33:10,573 Epoch[44] Batch [590]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086304,	
2017-06-24 20:33:20,359 Epoch[44] Batch [600]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086369,	
2017-06-24 20:33:30,781 Epoch[44] Batch [610]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086421,	
2017-06-24 20:33:40,435 Epoch[44] Batch [620]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086513,	
2017-06-24 20:33:49,706 Epoch[44] Batch [630]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086613,	
2017-06-24 20:33:59,139 Epoch[44] Batch [640]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.086626,	
2017-06-24 20:34:08,185 Epoch[44] Batch [650]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086677,	
2017-06-24 20:34:17,798 Epoch[44] Batch [660]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086682,	
2017-06-24 20:34:27,028 Epoch[44] Batch [670]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086740,	
2017-06-24 20:34:36,727 Epoch[44] Batch [680]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086766,	
2017-06-24 20:34:46,367 Epoch[44] Batch [690]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086834,	
2017-06-24 20:34:56,080 Epoch[44] Batch [700]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086863,	
2017-06-24 20:35:06,707 Epoch[44] Batch [710]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086853,	
2017-06-24 20:35:16,563 Epoch[44] Batch [720]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086781,	
2017-06-24 20:35:27,049 Epoch[44] Batch [730]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086726,	
2017-06-24 20:35:36,760 Epoch[44] Batch [740]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086701,	
2017-06-24 20:35:38,581 Epoch[44] Train-FCNLogLoss=0.086710
2017-06-24 20:35:38,581 Epoch[44] Time cost=687.016
2017-06-24 20:35:40,292 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0045.params"
2017-06-24 20:35:42,086 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0045.states"
2017-06-24 20:35:53,785 Epoch[45] Batch [10]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086160,	
2017-06-24 20:36:03,739 Epoch[45] Batch [20]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087826,	
2017-06-24 20:36:13,639 Epoch[45] Batch [30]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.084605,	
2017-06-24 20:36:23,149 Epoch[45] Batch [40]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.085344,	
2017-06-24 20:36:32,342 Epoch[45] Batch [50]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.086240,	
2017-06-24 20:36:42,094 Epoch[45] Batch [60]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.085083,	
2017-06-24 20:36:51,501 Epoch[45] Batch [70]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.085408,	
2017-06-24 20:37:01,233 Epoch[45] Batch [80]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.085208,	
2017-06-24 20:37:11,264 Epoch[45] Batch [90]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.085544,	
2017-06-24 20:37:21,856 Epoch[45] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.085761,	
2017-06-24 20:37:32,264 Epoch[45] Batch [110]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.085854,	
2017-06-24 20:37:42,034 Epoch[45] Batch [120]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.085596,	
2017-06-24 20:37:52,523 Epoch[45] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.085535,	
2017-06-24 20:38:02,782 Epoch[45] Batch [140]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.085865,	
2017-06-24 20:38:12,735 Epoch[45] Batch [150]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.085776,	
2017-06-24 20:38:22,465 Epoch[45] Batch [160]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.085813,	
2017-06-24 20:38:31,986 Epoch[45] Batch [170]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086065,	
2017-06-24 20:38:42,040 Epoch[45] Batch [180]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.086243,	
2017-06-24 20:38:51,982 Epoch[45] Batch [190]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086107,	
2017-06-24 20:39:01,268 Epoch[45] Batch [200]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086222,	
2017-06-24 20:39:10,672 Epoch[45] Batch [210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.086529,	
2017-06-24 20:39:21,191 Epoch[45] Batch [220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086777,	
2017-06-24 20:39:30,901 Epoch[45] Batch [230]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086564,	
2017-06-24 20:39:40,870 Epoch[45] Batch [240]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086639,	
2017-06-24 20:39:51,247 Epoch[45] Batch [250]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.086708,	
2017-06-24 20:40:01,725 Epoch[45] Batch [260]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086514,	
2017-06-24 20:40:12,088 Epoch[45] Batch [270]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.086556,	
2017-06-24 20:40:21,188 Epoch[45] Batch [280]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086542,	
2017-06-24 20:40:31,124 Epoch[45] Batch [290]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086429,	
2017-06-24 20:40:41,115 Epoch[45] Batch [300]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086442,	
2017-06-24 20:40:50,918 Epoch[45] Batch [310]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086256,	
2017-06-24 20:41:00,654 Epoch[45] Batch [320]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086285,	
2017-06-24 20:41:10,179 Epoch[45] Batch [330]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086278,	
2017-06-24 20:41:19,584 Epoch[45] Batch [340]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.086387,	
2017-06-24 20:41:29,551 Epoch[45] Batch [350]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086290,	
2017-06-24 20:41:39,425 Epoch[45] Batch [360]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086536,	
2017-06-24 20:41:48,163 Epoch[45] Batch [370]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086535,	
2017-06-24 20:41:56,880 Epoch[45] Batch [380]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086489,	
2017-06-24 20:42:05,388 Epoch[45] Batch [390]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.086411,	
2017-06-24 20:42:14,113 Epoch[45] Batch [400]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.086459,	
2017-06-24 20:42:22,733 Epoch[45] Batch [410]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.086488,	
2017-06-24 20:42:31,481 Epoch[45] Batch [420]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.086327,	
2017-06-24 20:42:39,648 Epoch[45] Batch [430]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.086660,	
2017-06-24 20:42:48,190 Epoch[45] Batch [440]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.086691,	
2017-06-24 20:42:56,822 Epoch[45] Batch [450]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086577,	
2017-06-24 20:43:06,674 Epoch[45] Batch [460]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086522,	
2017-06-24 20:43:15,505 Epoch[45] Batch [470]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.086575,	
2017-06-24 20:43:24,983 Epoch[45] Batch [480]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.086631,	
2017-06-24 20:43:34,722 Epoch[45] Batch [490]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086648,	
2017-06-24 20:43:44,071 Epoch[45] Batch [500]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.086562,	
2017-06-24 20:43:53,713 Epoch[45] Batch [510]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086540,	
2017-06-24 20:44:03,688 Epoch[45] Batch [520]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086473,	
2017-06-24 20:44:13,430 Epoch[45] Batch [530]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086365,	
2017-06-24 20:44:23,434 Epoch[45] Batch [540]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.086290,	
2017-06-24 20:44:32,979 Epoch[45] Batch [550]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086312,	
2017-06-24 20:44:42,969 Epoch[45] Batch [560]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086297,	
2017-06-24 20:44:53,546 Epoch[45] Batch [570]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086293,	
2017-06-24 20:45:03,961 Epoch[45] Batch [580]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086351,	
2017-06-24 20:45:13,381 Epoch[45] Batch [590]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.086286,	
2017-06-24 20:45:22,807 Epoch[45] Batch [600]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.086364,	
2017-06-24 20:45:32,580 Epoch[45] Batch [610]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.086428,	
2017-06-24 20:45:41,691 Epoch[45] Batch [620]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086515,	
2017-06-24 20:45:51,656 Epoch[45] Batch [630]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086497,	
2017-06-24 20:46:01,990 Epoch[45] Batch [640]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086486,	
2017-06-24 20:46:12,118 Epoch[45] Batch [650]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086402,	
2017-06-24 20:46:22,603 Epoch[45] Batch [660]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086365,	
2017-06-24 20:46:32,389 Epoch[45] Batch [670]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086448,	
2017-06-24 20:46:42,916 Epoch[45] Batch [680]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086446,	
2017-06-24 20:46:53,112 Epoch[45] Batch [690]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086535,	
2017-06-24 20:47:02,603 Epoch[45] Batch [700]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.086514,	
2017-06-24 20:47:11,892 Epoch[45] Batch [710]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.086460,	
2017-06-24 20:47:22,478 Epoch[45] Batch [720]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086516,	
2017-06-24 20:47:32,314 Epoch[45] Batch [730]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.086482,	
2017-06-24 20:47:42,653 Epoch[45] Batch [740]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086364,	
2017-06-24 20:47:44,989 Epoch[45] Train-FCNLogLoss=0.086405
2017-06-24 20:47:44,989 Epoch[45] Time cost=722.899
2017-06-24 20:47:46,683 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0046.params"
2017-06-24 20:47:48,552 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0046.states"
2017-06-24 20:48:00,450 Epoch[46] Batch [10]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.087578,	
2017-06-24 20:48:10,453 Epoch[46] Batch [20]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-24 20:48:20,407 Epoch[46] Batch [30]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088247,	
2017-06-24 20:48:29,737 Epoch[46] Batch [40]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087326,	
2017-06-24 20:48:39,719 Epoch[46] Batch [50]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086023,	
2017-06-24 20:48:49,177 Epoch[46] Batch [60]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.086929,	
2017-06-24 20:48:58,530 Epoch[46] Batch [70]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087574,	
2017-06-24 20:49:08,305 Epoch[46] Batch [80]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.087275,	
2017-06-24 20:49:17,719 Epoch[46] Batch [90]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.086504,	
2017-06-24 20:49:26,838 Epoch[46] Batch [100]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.086727,	
2017-06-24 20:49:35,849 Epoch[46] Batch [110]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086987,	
2017-06-24 20:49:44,702 Epoch[46] Batch [120]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086546,	
2017-06-24 20:49:53,742 Epoch[46] Batch [130]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086967,	
2017-06-24 20:50:03,770 Epoch[46] Batch [140]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087024,	
2017-06-24 20:50:13,746 Epoch[46] Batch [150]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087062,	
2017-06-24 20:50:24,343 Epoch[46] Batch [160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086713,	
2017-06-24 20:50:33,459 Epoch[46] Batch [170]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086353,	
2017-06-24 20:50:43,082 Epoch[46] Batch [180]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.086411,	
2017-06-24 20:50:53,271 Epoch[46] Batch [190]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086676,	
2017-06-24 20:51:03,163 Epoch[46] Batch [200]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086918,	
2017-06-24 20:51:12,614 Epoch[46] Batch [210]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.086939,	
2017-06-24 20:51:22,071 Epoch[46] Batch [220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.086968,	
2017-06-24 20:51:32,149 Epoch[46] Batch [230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087055,	
2017-06-24 20:51:42,305 Epoch[46] Batch [240]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087048,	
2017-06-24 20:51:52,265 Epoch[46] Batch [250]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087021,	
2017-06-24 20:52:01,729 Epoch[46] Batch [260]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087267,	
2017-06-24 20:52:10,990 Epoch[46] Batch [270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087004,	
2017-06-24 20:52:19,941 Epoch[46] Batch [280]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.086840,	
2017-06-24 20:52:29,166 Epoch[46] Batch [290]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086808,	
2017-06-24 20:52:37,917 Epoch[46] Batch [300]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.086834,	
2017-06-24 20:52:47,207 Epoch[46] Batch [310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087061,	
2017-06-24 20:52:56,099 Epoch[46] Batch [320]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.086950,	
2017-06-24 20:53:05,780 Epoch[46] Batch [330]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.087078,	
2017-06-24 20:53:16,086 Epoch[46] Batch [340]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.086969,	
2017-06-24 20:53:25,871 Epoch[46] Batch [350]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086964,	
2017-06-24 20:53:35,464 Epoch[46] Batch [360]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086992,	
2017-06-24 20:53:45,392 Epoch[46] Batch [370]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086996,	
2017-06-24 20:53:54,984 Epoch[46] Batch [380]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086841,	
2017-06-24 20:54:03,750 Epoch[46] Batch [390]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.086910,	
2017-06-24 20:54:12,909 Epoch[46] Batch [400]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.086965,	
2017-06-24 20:54:21,479 Epoch[46] Batch [410]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.086937,	
2017-06-24 20:54:30,868 Epoch[46] Batch [420]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086807,	
2017-06-24 20:54:39,737 Epoch[46] Batch [430]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.086854,	
2017-06-24 20:54:49,316 Epoch[46] Batch [440]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.086896,	
2017-06-24 20:54:58,655 Epoch[46] Batch [450]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.086997,	
2017-06-24 20:55:08,298 Epoch[46] Batch [460]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086906,	
2017-06-24 20:55:17,781 Epoch[46] Batch [470]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.086889,	
2017-06-24 20:55:27,567 Epoch[46] Batch [480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086780,	
2017-06-24 20:55:36,743 Epoch[46] Batch [490]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.086817,	
2017-06-24 20:55:46,913 Epoch[46] Batch [500]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086861,	
2017-06-24 20:55:56,962 Epoch[46] Batch [510]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.086726,	
2017-06-24 20:56:06,845 Epoch[46] Batch [520]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086646,	
2017-06-24 20:56:17,411 Epoch[46] Batch [530]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086522,	
2017-06-24 20:56:28,407 Epoch[46] Batch [540]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.086608,	
2017-06-24 20:56:39,078 Epoch[46] Batch [550]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086664,	
2017-06-24 20:56:49,537 Epoch[46] Batch [560]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086759,	
2017-06-24 20:56:59,727 Epoch[46] Batch [570]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086721,	
2017-06-24 20:57:09,230 Epoch[46] Batch [580]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.086591,	
2017-06-24 20:57:19,534 Epoch[46] Batch [590]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.086478,	
2017-06-24 20:57:28,176 Epoch[46] Batch [600]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.086589,	
2017-06-24 20:57:38,637 Epoch[46] Batch [610]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086598,	
2017-06-24 20:57:48,775 Epoch[46] Batch [620]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086612,	
2017-06-24 20:57:59,304 Epoch[46] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086560,	
2017-06-24 20:58:09,229 Epoch[46] Batch [640]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086480,	
2017-06-24 20:58:19,171 Epoch[46] Batch [650]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086403,	
2017-06-24 20:58:28,804 Epoch[46] Batch [660]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.086370,	
2017-06-24 20:58:38,680 Epoch[46] Batch [670]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086348,	
2017-06-24 20:58:48,648 Epoch[46] Batch [680]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086343,	
2017-06-24 20:58:58,486 Epoch[46] Batch [690]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.086436,	
2017-06-24 20:59:08,227 Epoch[46] Batch [700]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086374,	
2017-06-24 20:59:18,234 Epoch[46] Batch [710]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.086336,	
2017-06-24 20:59:31,202 Epoch[46] Batch [720]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086380,	
2017-06-24 20:59:52,540 Epoch[46] Batch [730]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.086410,	
2017-06-24 21:00:11,889 Epoch[46] Batch [740]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.086370,	
2017-06-24 21:00:15,507 Epoch[46] Train-FCNLogLoss=0.086449
2017-06-24 21:00:15,507 Epoch[46] Time cost=746.955
2017-06-24 21:00:17,929 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0047.params"
2017-06-24 21:00:20,891 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0047.states"
2017-06-24 21:00:40,021 Epoch[47] Batch [10]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.082821,	
2017-06-24 21:00:56,660 Epoch[47] Batch [20]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.085433,	
2017-06-24 21:01:15,555 Epoch[47] Batch [30]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.086605,	
2017-06-24 21:01:35,214 Epoch[47] Batch [40]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.086611,	
2017-06-24 21:01:54,987 Epoch[47] Batch [50]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.086825,	
2017-06-24 21:02:14,396 Epoch[47] Batch [60]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.086079,	
2017-06-24 21:02:30,299 Epoch[47] Batch [70]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.086101,	
2017-06-24 21:02:43,643 Epoch[47] Batch [80]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086980,	
2017-06-24 21:02:55,064 Epoch[47] Batch [90]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.087204,	
2017-06-24 21:03:07,037 Epoch[47] Batch [100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-24 21:03:18,698 Epoch[47] Batch [110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087123,	
2017-06-24 21:03:29,990 Epoch[47] Batch [120]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.087223,	
2017-06-24 21:03:41,240 Epoch[47] Batch [130]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.087026,	
2017-06-24 21:03:51,687 Epoch[47] Batch [140]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086856,	
2017-06-24 21:04:03,031 Epoch[47] Batch [150]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.086962,	
2017-06-24 21:04:13,431 Epoch[47] Batch [160]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.086584,	
2017-06-24 21:04:23,755 Epoch[47] Batch [170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.085863,	
2017-06-24 21:04:34,611 Epoch[47] Batch [180]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.085856,	
2017-06-24 21:04:45,398 Epoch[47] Batch [190]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.085769,	
2017-06-24 21:04:55,953 Epoch[47] Batch [200]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086214,	
2017-06-24 21:05:06,648 Epoch[47] Batch [210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.086567,	
2017-06-24 21:05:16,724 Epoch[47] Batch [220]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.086558,	
2017-06-24 21:05:27,306 Epoch[47] Batch [230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086688,	
2017-06-24 21:05:37,734 Epoch[47] Batch [240]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086626,	
2017-06-24 21:05:48,129 Epoch[47] Batch [250]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.086662,	
2017-06-24 21:05:58,453 Epoch[47] Batch [260]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.086520,	
2017-06-24 21:06:08,633 Epoch[47] Batch [270]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086313,	
2017-06-24 21:06:18,993 Epoch[47] Batch [280]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.086124,	
2017-06-24 21:06:29,796 Epoch[47] Batch [290]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.086249,	
2017-06-24 21:06:40,475 Epoch[47] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086293,	
2017-06-24 21:06:50,659 Epoch[47] Batch [310]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086191,	
2017-06-24 21:07:01,565 Epoch[47] Batch [320]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.086105,	
2017-06-24 21:07:12,009 Epoch[47] Batch [330]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086463,	
2017-06-24 21:07:22,459 Epoch[47] Batch [340]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086517,	
2017-06-24 21:07:33,061 Epoch[47] Batch [350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086282,	
2017-06-24 21:07:43,824 Epoch[47] Batch [360]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.086220,	
2017-06-24 21:07:53,985 Epoch[47] Batch [370]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086393,	
2017-06-24 21:08:05,037 Epoch[47] Batch [380]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086543,	
2017-06-24 21:08:16,444 Epoch[47] Batch [390]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086572,	
2017-06-24 21:08:26,873 Epoch[47] Batch [400]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086650,	
2017-06-24 21:08:37,681 Epoch[47] Batch [410]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.086590,	
2017-06-24 21:08:48,315 Epoch[47] Batch [420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086580,	
2017-06-24 21:08:58,651 Epoch[47] Batch [430]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086465,	
2017-06-24 21:09:09,329 Epoch[47] Batch [440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086477,	
2017-06-24 21:09:20,383 Epoch[47] Batch [450]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086600,	
2017-06-24 21:09:30,958 Epoch[47] Batch [460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086646,	
2017-06-24 21:09:41,315 Epoch[47] Batch [470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.086525,	
2017-06-24 21:09:51,874 Epoch[47] Batch [480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086715,	
2017-06-24 21:10:01,569 Epoch[47] Batch [490]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086616,	
2017-06-24 21:10:11,556 Epoch[47] Batch [500]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086610,	
2017-06-24 21:10:21,455 Epoch[47] Batch [510]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.086552,	
2017-06-24 21:10:31,764 Epoch[47] Batch [520]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.086649,	
2017-06-24 21:10:41,776 Epoch[47] Batch [530]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.086630,	
2017-06-24 21:10:51,380 Epoch[47] Batch [540]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086727,	
2017-06-24 21:11:01,580 Epoch[47] Batch [550]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086626,	
2017-06-24 21:11:11,650 Epoch[47] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.086550,	
2017-06-24 21:11:22,004 Epoch[47] Batch [570]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086566,	
2017-06-24 21:11:32,337 Epoch[47] Batch [580]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086534,	
2017-06-24 21:11:42,398 Epoch[47] Batch [590]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086479,	
2017-06-24 21:11:52,869 Epoch[47] Batch [600]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086459,	
2017-06-24 21:12:03,726 Epoch[47] Batch [610]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.086448,	
2017-06-24 21:12:14,320 Epoch[47] Batch [620]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086494,	
2017-06-24 21:12:25,024 Epoch[47] Batch [630]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.086490,	
2017-06-24 21:12:35,245 Epoch[47] Batch [640]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086518,	
2017-06-24 21:12:45,900 Epoch[47] Batch [650]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086460,	
2017-06-24 21:12:56,546 Epoch[47] Batch [660]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086482,	
2017-06-24 21:13:07,226 Epoch[47] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086494,	
2017-06-24 21:13:18,007 Epoch[47] Batch [680]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.086551,	
2017-06-24 21:13:29,116 Epoch[47] Batch [690]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.086556,	
2017-06-24 21:13:40,267 Epoch[47] Batch [700]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.086605,	
2017-06-24 21:13:52,097 Epoch[47] Batch [710]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086639,	
2017-06-24 21:14:03,402 Epoch[47] Batch [720]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086625,	
2017-06-24 21:14:14,049 Epoch[47] Batch [730]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086623,	
2017-06-24 21:14:24,888 Epoch[47] Batch [740]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.086677,	
2017-06-24 21:14:26,762 Epoch[47] Train-FCNLogLoss=0.086675
2017-06-24 21:14:26,762 Epoch[47] Time cost=845.870
2017-06-24 21:14:28,042 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0048.params"
2017-06-24 21:14:29,795 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0048.states"
2017-06-24 21:14:41,955 Epoch[48] Batch [10]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.084342,	
2017-06-24 21:14:52,836 Epoch[48] Batch [20]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.086856,	
2017-06-24 21:15:04,672 Epoch[48] Batch [30]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.087847,	
2017-06-24 21:15:15,278 Epoch[48] Batch [40]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-24 21:15:26,087 Epoch[48] Batch [50]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088049,	
2017-06-24 21:15:36,482 Epoch[48] Batch [60]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088570,	
2017-06-24 21:15:46,761 Epoch[48] Batch [70]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088996,	
2017-06-24 21:15:58,035 Epoch[48] Batch [80]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.088488,	
2017-06-24 21:16:08,815 Epoch[48] Batch [90]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088204,	
2017-06-24 21:16:20,198 Epoch[48] Batch [100]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088120,	
2017-06-24 21:16:30,146 Epoch[48] Batch [110]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087527,	
2017-06-24 21:16:40,598 Epoch[48] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.087338,	
2017-06-24 21:16:51,671 Epoch[48] Batch [130]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.086906,	
2017-06-24 21:17:02,114 Epoch[48] Batch [140]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086779,	
2017-06-24 21:17:12,334 Epoch[48] Batch [150]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086820,	
2017-06-24 21:17:22,772 Epoch[48] Batch [160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086693,	
2017-06-24 21:17:32,966 Epoch[48] Batch [170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086503,	
2017-06-24 21:17:43,501 Epoch[48] Batch [180]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086456,	
2017-06-24 21:17:54,649 Epoch[48] Batch [190]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.086694,	
2017-06-24 21:18:05,366 Epoch[48] Batch [200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.086584,	
2017-06-24 21:18:15,674 Epoch[48] Batch [210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.086586,	
2017-06-24 21:18:25,968 Epoch[48] Batch [220]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086470,	
2017-06-24 21:18:37,258 Epoch[48] Batch [230]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086625,	
2017-06-24 21:18:47,595 Epoch[48] Batch [240]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086414,	
2017-06-24 21:18:58,786 Epoch[48] Batch [250]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.086471,	
2017-06-24 21:19:09,820 Epoch[48] Batch [260]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.086576,	
2017-06-24 21:19:20,457 Epoch[48] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086733,	
2017-06-24 21:19:30,954 Epoch[48] Batch [280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086622,	
2017-06-24 21:19:40,868 Epoch[48] Batch [290]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.086430,	
2017-06-24 21:19:51,416 Epoch[48] Batch [300]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086418,	
2017-06-24 21:20:02,652 Epoch[48] Batch [310]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.086264,	
2017-06-24 21:20:14,015 Epoch[48] Batch [320]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086355,	
2017-06-24 21:20:24,662 Epoch[48] Batch [330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086403,	
2017-06-24 21:20:35,547 Epoch[48] Batch [340]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.086398,	
2017-06-24 21:20:45,625 Epoch[48] Batch [350]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.086423,	
2017-06-24 21:20:56,035 Epoch[48] Batch [360]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.086319,	
2017-06-24 21:21:06,167 Epoch[48] Batch [370]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086299,	
2017-06-24 21:21:16,496 Epoch[48] Batch [380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.086272,	
2017-06-24 21:21:27,115 Epoch[48] Batch [390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086272,	
2017-06-24 21:21:37,444 Epoch[48] Batch [400]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.086155,	
2017-06-24 21:21:47,702 Epoch[48] Batch [410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086188,	
2017-06-24 21:21:58,508 Epoch[48] Batch [420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.086179,	
2017-06-24 21:22:08,761 Epoch[48] Batch [430]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086115,	
2017-06-24 21:22:18,880 Epoch[48] Batch [440]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086113,	
2017-06-24 21:22:29,097 Epoch[48] Batch [450]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086094,	
2017-06-24 21:22:39,112 Epoch[48] Batch [460]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.086078,	
2017-06-24 21:22:49,258 Epoch[48] Batch [470]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086226,	
2017-06-24 21:22:58,940 Epoch[48] Batch [480]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086309,	
2017-06-24 21:23:08,831 Epoch[48] Batch [490]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086427,	
2017-06-24 21:23:19,417 Epoch[48] Batch [500]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086528,	
2017-06-24 21:23:29,679 Epoch[48] Batch [510]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086499,	
2017-06-24 21:23:39,831 Epoch[48] Batch [520]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086434,	
2017-06-24 21:23:50,729 Epoch[48] Batch [530]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.086353,	
2017-06-24 21:24:01,601 Epoch[48] Batch [540]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086396,	
2017-06-24 21:24:11,901 Epoch[48] Batch [550]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086317,	
2017-06-24 21:24:22,330 Epoch[48] Batch [560]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086287,	
2017-06-24 21:24:33,198 Epoch[48] Batch [570]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086271,	
2017-06-24 21:24:43,657 Epoch[48] Batch [580]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086237,	
2017-06-24 21:24:53,551 Epoch[48] Batch [590]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086259,	
2017-06-24 21:25:04,312 Epoch[48] Batch [600]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.086195,	
2017-06-24 21:25:15,089 Epoch[48] Batch [610]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.086073,	
2017-06-24 21:25:25,617 Epoch[48] Batch [620]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.085929,	
2017-06-24 21:25:36,628 Epoch[48] Batch [630]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.086001,	
2017-06-24 21:25:47,616 Epoch[48] Batch [640]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.085973,	
2017-06-24 21:25:58,521 Epoch[48] Batch [650]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.085886,	
2017-06-24 21:26:09,461 Epoch[48] Batch [660]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.085929,	
2017-06-24 21:26:19,972 Epoch[48] Batch [670]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.085840,	
2017-06-24 21:26:31,018 Epoch[48] Batch [680]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.085884,	
2017-06-24 21:26:41,703 Epoch[48] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.085918,	
2017-06-24 21:26:52,734 Epoch[48] Batch [700]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.085948,	
2017-06-24 21:27:03,801 Epoch[48] Batch [710]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.085923,	
2017-06-24 21:27:14,316 Epoch[48] Batch [720]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.085987,	
2017-06-24 21:27:24,810 Epoch[48] Batch [730]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086078,	
2017-06-24 21:27:35,721 Epoch[48] Batch [740]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.086080,	
2017-06-24 21:27:37,757 Epoch[48] Train-FCNLogLoss=0.086047
2017-06-24 21:27:37,757 Epoch[48] Time cost=787.962
2017-06-24 21:27:39,066 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0049.params"
2017-06-24 21:27:40,808 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0049.states"
2017-06-24 21:27:53,016 Epoch[49] Batch [10]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092799,	
2017-06-24 21:28:03,751 Epoch[49] Batch [20]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091729,	
2017-06-24 21:28:14,574 Epoch[49] Batch [30]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-24 21:28:25,008 Epoch[49] Batch [40]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.088777,	
2017-06-24 21:28:34,986 Epoch[49] Batch [50]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086382,	
2017-06-24 21:28:45,688 Epoch[49] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.085817,	
2017-06-24 21:28:57,043 Epoch[49] Batch [70]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.085308,	
2017-06-24 21:29:07,268 Epoch[49] Batch [80]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.084802,	
2017-06-24 21:29:17,558 Epoch[49] Batch [90]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.085110,	
2017-06-24 21:29:28,791 Epoch[49] Batch [100]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.085456,	
2017-06-24 21:29:39,973 Epoch[49] Batch [110]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.086011,	
2017-06-24 21:29:50,768 Epoch[49] Batch [120]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.086299,	
2017-06-24 21:30:01,862 Epoch[49] Batch [130]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.086754,	
2017-06-24 21:30:12,420 Epoch[49] Batch [140]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086648,	
2017-06-24 21:30:22,305 Epoch[49] Batch [150]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086863,	
2017-06-24 21:30:32,799 Epoch[49] Batch [160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087045,	
2017-06-24 21:30:43,602 Epoch[49] Batch [170]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.086840,	
2017-06-24 21:30:53,719 Epoch[49] Batch [180]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086684,	
2017-06-24 21:31:03,513 Epoch[49] Batch [190]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086674,	
2017-06-24 21:31:14,147 Epoch[49] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086972,	
2017-06-24 21:31:24,902 Epoch[49] Batch [210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087177,	
2017-06-24 21:31:35,233 Epoch[49] Batch [220]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.087034,	
2017-06-24 21:31:45,430 Epoch[49] Batch [230]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.087160,	
2017-06-24 21:31:56,246 Epoch[49] Batch [240]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.087080,	
2017-06-24 21:32:07,049 Epoch[49] Batch [250]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087020,	
2017-06-24 21:32:17,562 Epoch[49] Batch [260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086939,	
2017-06-24 21:32:27,795 Epoch[49] Batch [270]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086953,	
2017-06-24 21:32:39,037 Epoch[49] Batch [280]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.086918,	
2017-06-24 21:32:50,487 Epoch[49] Batch [290]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087107,	
2017-06-24 21:33:01,779 Epoch[49] Batch [300]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.087092,	
2017-06-24 21:33:13,061 Epoch[49] Batch [310]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.087078,	
2017-06-24 21:33:24,329 Epoch[49] Batch [320]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.086827,	
2017-06-24 21:33:35,380 Epoch[49] Batch [330]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086894,	
2017-06-24 21:33:45,760 Epoch[49] Batch [340]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.086812,	
2017-06-24 21:33:56,527 Epoch[49] Batch [350]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.086842,	
2017-06-24 21:34:07,403 Epoch[49] Batch [360]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086914,	
2017-06-24 21:34:17,689 Epoch[49] Batch [370]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.086956,	
2017-06-24 21:34:28,489 Epoch[49] Batch [380]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087050,	
2017-06-24 21:34:39,033 Epoch[49] Batch [390]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087161,	
2017-06-24 21:34:48,297 Epoch[49] Batch [400]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087188,	
2017-06-24 21:34:55,823 Epoch[49] Batch [410]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.087097,	
2017-06-24 21:35:02,822 Epoch[49] Batch [420]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.087098,	
2017-06-24 21:35:09,697 Epoch[49] Batch [430]	Speed: 11.64 samples/sec	Train-FCNLogLoss=0.087294,	
2017-06-24 21:35:16,536 Epoch[49] Batch [440]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.087156,	
2017-06-24 21:35:23,252 Epoch[49] Batch [450]	Speed: 11.91 samples/sec	Train-FCNLogLoss=0.087058,	
2017-06-24 21:35:30,089 Epoch[49] Batch [460]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.086958,	
2017-06-24 21:35:37,090 Epoch[49] Batch [470]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.086891,	
2017-06-24 21:35:44,021 Epoch[49] Batch [480]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.086942,	
2017-06-24 21:35:50,869 Epoch[49] Batch [490]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.086921,	
2017-06-24 21:35:57,521 Epoch[49] Batch [500]	Speed: 12.03 samples/sec	Train-FCNLogLoss=0.086934,	
2017-06-24 21:36:04,445 Epoch[49] Batch [510]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.086886,	
2017-06-24 21:36:11,182 Epoch[49] Batch [520]	Speed: 11.88 samples/sec	Train-FCNLogLoss=0.086823,	
2017-06-24 21:36:18,110 Epoch[49] Batch [530]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086746,	
2017-06-24 21:36:25,028 Epoch[49] Batch [540]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.086790,	
2017-06-24 21:36:31,738 Epoch[49] Batch [550]	Speed: 11.92 samples/sec	Train-FCNLogLoss=0.086835,	
2017-06-24 21:36:38,592 Epoch[49] Batch [560]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.086820,	
2017-06-24 21:36:45,434 Epoch[49] Batch [570]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.086773,	
2017-06-24 21:36:52,201 Epoch[49] Batch [580]	Speed: 11.82 samples/sec	Train-FCNLogLoss=0.086743,	
2017-06-24 21:36:58,998 Epoch[49] Batch [590]	Speed: 11.77 samples/sec	Train-FCNLogLoss=0.086740,	
2017-06-24 21:37:06,077 Epoch[49] Batch [600]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.086566,	
2017-06-24 21:37:12,978 Epoch[49] Batch [610]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.086473,	
2017-06-24 21:37:19,821 Epoch[49] Batch [620]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.086572,	
2017-06-24 21:37:26,535 Epoch[49] Batch [630]	Speed: 11.92 samples/sec	Train-FCNLogLoss=0.086565,	
2017-06-24 21:37:33,412 Epoch[49] Batch [640]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.086512,	
2017-06-24 21:37:40,132 Epoch[49] Batch [650]	Speed: 11.91 samples/sec	Train-FCNLogLoss=0.086524,	
2017-06-24 21:37:47,061 Epoch[49] Batch [660]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086421,	
2017-06-24 21:37:53,984 Epoch[49] Batch [670]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.086427,	
2017-06-24 21:38:00,836 Epoch[49] Batch [680]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.086450,	
2017-06-24 21:38:07,789 Epoch[49] Batch [690]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.086389,	
2017-06-24 21:38:14,434 Epoch[49] Batch [700]	Speed: 12.04 samples/sec	Train-FCNLogLoss=0.086405,	
2017-06-24 21:38:21,335 Epoch[49] Batch [710]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.086386,	
2017-06-24 21:38:28,356 Epoch[49] Batch [720]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.086421,	
2017-06-24 21:38:35,243 Epoch[49] Batch [730]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.086442,	
2017-06-24 21:38:42,140 Epoch[49] Batch [740]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.086460,	
2017-06-24 21:38:43,497 Epoch[49] Train-FCNLogLoss=0.086475
2017-06-24 21:38:43,497 Epoch[49] Time cost=662.689
2017-06-24 21:38:44,816 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0050.params"
2017-06-24 21:38:46,450 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0050.states"
2017-06-24 21:38:54,563 Epoch[50] Batch [10]	Speed: 11.79 samples/sec	Train-FCNLogLoss=0.082158,	
2017-06-24 21:39:01,699 Epoch[50] Batch [20]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.082387,	
2017-06-24 21:39:08,433 Epoch[50] Batch [30]	Speed: 11.88 samples/sec	Train-FCNLogLoss=0.082390,	
2017-06-24 21:39:15,335 Epoch[50] Batch [40]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.085567,	
2017-06-24 21:39:22,277 Epoch[50] Batch [50]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.086848,	
2017-06-24 21:39:28,820 Epoch[50] Batch [60]	Speed: 12.23 samples/sec	Train-FCNLogLoss=0.086856,	
2017-06-24 21:39:35,510 Epoch[50] Batch [70]	Speed: 11.96 samples/sec	Train-FCNLogLoss=0.086313,	
2017-06-24 21:39:42,261 Epoch[50] Batch [80]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.085662,	
2017-06-24 21:39:49,190 Epoch[50] Batch [90]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086124,	
2017-06-24 21:39:56,277 Epoch[50] Batch [100]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.085560,	
2017-06-24 21:40:03,170 Epoch[50] Batch [110]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.085731,	
2017-06-24 21:40:10,161 Epoch[50] Batch [120]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.085839,	
2017-06-24 21:40:17,129 Epoch[50] Batch [130]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.085401,	
2017-06-24 21:40:24,013 Epoch[50] Batch [140]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.085168,	
2017-06-24 21:40:31,071 Epoch[50] Batch [150]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.085196,	
2017-06-24 21:40:37,997 Epoch[50] Batch [160]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.085318,	
2017-06-24 21:40:44,909 Epoch[50] Batch [170]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.085152,	
2017-06-24 21:40:51,805 Epoch[50] Batch [180]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.085580,	
2017-06-24 21:40:58,651 Epoch[50] Batch [190]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.085763,	
2017-06-24 21:41:05,626 Epoch[50] Batch [200]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.085857,	
2017-06-24 21:41:12,623 Epoch[50] Batch [210]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.085804,	
2017-06-24 21:41:19,531 Epoch[50] Batch [220]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.085936,	
2017-06-24 21:41:26,219 Epoch[50] Batch [230]	Speed: 11.96 samples/sec	Train-FCNLogLoss=0.085845,	
2017-06-24 21:41:32,998 Epoch[50] Batch [240]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.085713,	
2017-06-24 21:41:39,920 Epoch[50] Batch [250]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.085884,	
2017-06-24 21:41:46,745 Epoch[50] Batch [260]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.085905,	
2017-06-24 21:41:53,495 Epoch[50] Batch [270]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.086004,	
2017-06-24 21:42:00,318 Epoch[50] Batch [280]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.085984,	
2017-06-24 21:42:07,258 Epoch[50] Batch [290]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.085891,	
2017-06-24 21:42:14,203 Epoch[50] Batch [300]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.086071,	
2017-06-24 21:42:20,788 Epoch[50] Batch [310]	Speed: 12.15 samples/sec	Train-FCNLogLoss=0.085954,	
2017-06-24 21:42:27,652 Epoch[50] Batch [320]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.086234,	
2017-06-24 21:42:34,266 Epoch[50] Batch [330]	Speed: 12.10 samples/sec	Train-FCNLogLoss=0.086174,	
2017-06-24 21:42:41,062 Epoch[50] Batch [340]	Speed: 11.77 samples/sec	Train-FCNLogLoss=0.086297,	
2017-06-24 21:42:47,843 Epoch[50] Batch [350]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.086477,	
2017-06-24 21:42:54,566 Epoch[50] Batch [360]	Speed: 11.90 samples/sec	Train-FCNLogLoss=0.086426,	
2017-06-24 21:43:01,494 Epoch[50] Batch [370]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086427,	
2017-06-24 21:43:08,319 Epoch[50] Batch [380]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.086402,	
2017-06-24 21:43:15,294 Epoch[50] Batch [390]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.086321,	
2017-06-24 21:43:22,218 Epoch[50] Batch [400]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086200,	
2017-06-24 21:43:28,996 Epoch[50] Batch [410]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.086261,	
2017-06-24 21:43:35,766 Epoch[50] Batch [420]	Speed: 11.82 samples/sec	Train-FCNLogLoss=0.086167,	
2017-06-24 21:43:42,712 Epoch[50] Batch [430]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.086248,	
2017-06-24 21:43:49,757 Epoch[50] Batch [440]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.086226,	
2017-06-24 21:43:56,513 Epoch[50] Batch [450]	Speed: 11.84 samples/sec	Train-FCNLogLoss=0.086277,	
2017-06-24 21:44:03,378 Epoch[50] Batch [460]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.086180,	
2017-06-24 21:44:09,962 Epoch[50] Batch [470]	Speed: 12.15 samples/sec	Train-FCNLogLoss=0.086178,	
2017-06-24 21:44:16,958 Epoch[50] Batch [480]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.086176,	
2017-06-24 21:44:23,750 Epoch[50] Batch [490]	Speed: 11.78 samples/sec	Train-FCNLogLoss=0.086211,	
2017-06-24 21:44:30,456 Epoch[50] Batch [500]	Speed: 11.93 samples/sec	Train-FCNLogLoss=0.086379,	
2017-06-24 21:44:37,365 Epoch[50] Batch [510]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.086243,	
2017-06-24 21:44:44,051 Epoch[50] Batch [520]	Speed: 11.97 samples/sec	Train-FCNLogLoss=0.086200,	
2017-06-24 21:44:50,770 Epoch[50] Batch [530]	Speed: 11.91 samples/sec	Train-FCNLogLoss=0.086175,	
2017-06-24 21:44:57,597 Epoch[50] Batch [540]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.086146,	
2017-06-24 21:45:04,523 Epoch[50] Batch [550]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086037,	
2017-06-24 21:45:11,283 Epoch[50] Batch [560]	Speed: 11.84 samples/sec	Train-FCNLogLoss=0.086018,	
2017-06-24 21:45:18,126 Epoch[50] Batch [570]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.086052,	
2017-06-24 21:45:25,102 Epoch[50] Batch [580]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.085892,	
2017-06-24 21:45:32,050 Epoch[50] Batch [590]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.085799,	
2017-06-24 21:45:39,176 Epoch[50] Batch [600]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.085775,	
2017-06-24 21:45:46,045 Epoch[50] Batch [610]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.085739,	
2017-06-24 21:45:52,826 Epoch[50] Batch [620]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.085690,	
2017-06-24 21:45:59,870 Epoch[50] Batch [630]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.085647,	
2017-06-24 21:46:06,663 Epoch[50] Batch [640]	Speed: 11.78 samples/sec	Train-FCNLogLoss=0.085634,	
2017-06-24 21:46:13,644 Epoch[50] Batch [650]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.085672,	
2017-06-24 21:46:20,627 Epoch[50] Batch [660]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.085518,	
2017-06-24 21:46:27,384 Epoch[50] Batch [670]	Speed: 11.84 samples/sec	Train-FCNLogLoss=0.085655,	
2017-06-24 21:46:34,462 Epoch[50] Batch [680]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.085641,	
2017-06-24 21:46:41,034 Epoch[50] Batch [690]	Speed: 12.17 samples/sec	Train-FCNLogLoss=0.085708,	
2017-06-24 21:46:48,073 Epoch[50] Batch [700]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.085742,	
2017-06-24 21:46:54,943 Epoch[50] Batch [710]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.085745,	
2017-06-24 21:47:01,573 Epoch[50] Batch [720]	Speed: 12.07 samples/sec	Train-FCNLogLoss=0.085750,	
2017-06-24 21:47:08,417 Epoch[50] Batch [730]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.085809,	
2017-06-24 21:47:15,133 Epoch[50] Batch [740]	Speed: 11.91 samples/sec	Train-FCNLogLoss=0.085841,	
2017-06-24 21:47:16,509 Epoch[50] Train-FCNLogLoss=0.085867
2017-06-24 21:47:16,510 Epoch[50] Time cost=510.059
2017-06-24 21:47:17,704 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0051.params"
2017-06-24 21:47:19,600 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0051.states"
2017-06-24 21:47:27,660 Epoch[51] Batch [10]	Speed: 11.96 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-24 21:47:34,578 Epoch[51] Batch [20]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.088711,	
2017-06-24 21:47:41,533 Epoch[51] Batch [30]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.087533,	
2017-06-24 21:47:48,460 Epoch[51] Batch [40]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086795,	
2017-06-24 21:47:55,389 Epoch[51] Batch [50]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.084822,	
2017-06-24 21:48:02,301 Epoch[51] Batch [60]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.085127,	
2017-06-24 21:48:09,110 Epoch[51] Batch [70]	Speed: 11.75 samples/sec	Train-FCNLogLoss=0.084754,	
2017-06-24 21:48:15,912 Epoch[51] Batch [80]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.084595,	
2017-06-24 21:48:22,798 Epoch[51] Batch [90]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.084497,	
2017-06-24 21:48:29,546 Epoch[51] Batch [100]	Speed: 11.86 samples/sec	Train-FCNLogLoss=0.084803,	
2017-06-24 21:48:36,557 Epoch[51] Batch [110]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.085202,	
2017-06-24 21:48:43,512 Epoch[51] Batch [120]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.085219,	
2017-06-24 21:48:50,264 Epoch[51] Batch [130]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.084938,	
2017-06-24 21:48:57,082 Epoch[51] Batch [140]	Speed: 11.73 samples/sec	Train-FCNLogLoss=0.085136,	
2017-06-24 21:49:03,977 Epoch[51] Batch [150]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.085447,	
2017-06-24 21:49:10,939 Epoch[51] Batch [160]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085803,	
2017-06-24 21:49:17,942 Epoch[51] Batch [170]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.085947,	
2017-06-24 21:49:24,767 Epoch[51] Batch [180]	Speed: 11.72 samples/sec	Train-FCNLogLoss=0.085974,	
2017-06-24 21:49:31,732 Epoch[51] Batch [190]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085837,	
2017-06-24 21:49:38,701 Epoch[51] Batch [200]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.085988,	
2017-06-24 21:49:45,626 Epoch[51] Batch [210]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.086061,	
2017-06-24 21:49:52,475 Epoch[51] Batch [220]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.086540,	
2017-06-24 21:49:59,313 Epoch[51] Batch [230]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.086413,	
2017-06-24 21:50:06,282 Epoch[51] Batch [240]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.086092,	
2017-06-24 21:50:13,072 Epoch[51] Batch [250]	Speed: 11.78 samples/sec	Train-FCNLogLoss=0.086217,	
2017-06-24 21:50:20,080 Epoch[51] Batch [260]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.085870,	
2017-06-24 21:50:27,042 Epoch[51] Batch [270]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085976,	
2017-06-24 21:50:33,946 Epoch[51] Batch [280]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.086080,	
2017-06-24 21:50:40,835 Epoch[51] Batch [290]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.085875,	
2017-06-24 21:50:47,675 Epoch[51] Batch [300]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.085803,	
2017-06-24 21:50:54,526 Epoch[51] Batch [310]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.085767,	
2017-06-24 21:51:01,488 Epoch[51] Batch [320]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085824,	
2017-06-24 21:51:08,499 Epoch[51] Batch [330]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.085796,	
2017-06-24 21:51:15,519 Epoch[51] Batch [340]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.085854,	
2017-06-24 21:51:22,326 Epoch[51] Batch [350]	Speed: 11.75 samples/sec	Train-FCNLogLoss=0.085903,	
2017-06-24 21:51:29,184 Epoch[51] Batch [360]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.085755,	
2017-06-24 21:51:36,125 Epoch[51] Batch [370]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.085724,	
2017-06-24 21:51:42,901 Epoch[51] Batch [380]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.085648,	
2017-06-24 21:51:49,906 Epoch[51] Batch [390]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.085617,	
2017-06-24 21:51:56,788 Epoch[51] Batch [400]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.085407,	
2017-06-24 21:52:03,533 Epoch[51] Batch [410]	Speed: 11.86 samples/sec	Train-FCNLogLoss=0.085405,	
2017-06-24 21:52:10,343 Epoch[51] Batch [420]	Speed: 11.75 samples/sec	Train-FCNLogLoss=0.085658,	
2017-06-24 21:52:17,281 Epoch[51] Batch [430]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.085671,	
2017-06-24 21:52:24,358 Epoch[51] Batch [440]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.085887,	
2017-06-24 21:52:31,104 Epoch[51] Batch [450]	Speed: 11.86 samples/sec	Train-FCNLogLoss=0.085910,	
2017-06-24 21:52:38,099 Epoch[51] Batch [460]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.085724,	
2017-06-24 21:52:45,000 Epoch[51] Batch [470]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.085630,	
2017-06-24 21:52:51,989 Epoch[51] Batch [480]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.085663,	
2017-06-24 21:52:58,974 Epoch[51] Batch [490]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.085507,	
2017-06-24 21:53:05,890 Epoch[51] Batch [500]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.085505,	
2017-06-24 21:53:13,023 Epoch[51] Batch [510]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.085552,	
2017-06-24 21:53:19,732 Epoch[51] Batch [520]	Speed: 11.92 samples/sec	Train-FCNLogLoss=0.085610,	
2017-06-24 21:53:26,644 Epoch[51] Batch [530]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.085528,	
2017-06-24 21:53:33,668 Epoch[51] Batch [540]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.085656,	
2017-06-24 21:53:40,527 Epoch[51] Batch [550]	Speed: 11.66 samples/sec	Train-FCNLogLoss=0.085647,	
2017-06-24 21:53:47,527 Epoch[51] Batch [560]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.085716,	
2017-06-24 21:53:54,328 Epoch[51] Batch [570]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.085701,	
2017-06-24 21:54:01,232 Epoch[51] Batch [580]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.085677,	
2017-06-24 21:54:08,354 Epoch[51] Batch [590]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.085685,	
2017-06-24 21:54:15,096 Epoch[51] Batch [600]	Speed: 11.87 samples/sec	Train-FCNLogLoss=0.085704,	
2017-06-24 21:54:22,028 Epoch[51] Batch [610]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.085656,	
2017-06-24 21:54:28,845 Epoch[51] Batch [620]	Speed: 11.74 samples/sec	Train-FCNLogLoss=0.085689,	
2017-06-24 21:54:35,758 Epoch[51] Batch [630]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.085684,	
2017-06-24 21:54:42,771 Epoch[51] Batch [640]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.085610,	
2017-06-24 21:54:49,760 Epoch[51] Batch [650]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.085602,	
2017-06-24 21:54:56,540 Epoch[51] Batch [660]	Speed: 11.80 samples/sec	Train-FCNLogLoss=0.085705,	
2017-06-24 21:55:03,577 Epoch[51] Batch [670]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.085717,	
2017-06-24 21:55:10,661 Epoch[51] Batch [680]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.085829,	
2017-06-24 21:55:17,529 Epoch[51] Batch [690]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.085844,	
2017-06-24 21:55:24,484 Epoch[51] Batch [700]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.085869,	
2017-06-24 21:55:31,587 Epoch[51] Batch [710]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.085861,	
2017-06-24 21:55:38,676 Epoch[51] Batch [720]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.085834,	
2017-06-24 21:55:45,541 Epoch[51] Batch [730]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.085824,	
2017-06-24 21:55:52,504 Epoch[51] Batch [740]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085872,	
2017-06-24 21:55:53,822 Epoch[51] Train-FCNLogLoss=0.085838
2017-06-24 21:55:53,822 Epoch[51] Time cost=514.222
2017-06-24 21:55:54,873 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0052.params"
2017-06-24 21:55:56,670 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0052.states"
2017-06-24 21:56:05,005 Epoch[52] Batch [10]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.087631,	
2017-06-24 21:56:11,936 Epoch[52] Batch [20]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.086704,	
2017-06-24 21:56:18,627 Epoch[52] Batch [30]	Speed: 11.96 samples/sec	Train-FCNLogLoss=0.085579,	
2017-06-24 21:56:25,560 Epoch[52] Batch [40]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.086003,	
2017-06-24 21:56:32,311 Epoch[52] Batch [50]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.086287,	
2017-06-24 21:56:39,245 Epoch[52] Batch [60]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.085923,	
2017-06-24 21:56:46,256 Epoch[52] Batch [70]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.085683,	
2017-06-24 21:56:53,259 Epoch[52] Batch [80]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.085357,	
2017-06-24 21:57:00,204 Epoch[52] Batch [90]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.084580,	
2017-06-24 21:57:07,145 Epoch[52] Batch [100]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.084860,	
2017-06-24 21:57:13,982 Epoch[52] Batch [110]	Speed: 11.70 samples/sec	Train-FCNLogLoss=0.085041,	
2017-06-24 21:57:20,787 Epoch[52] Batch [120]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.084933,	
2017-06-24 21:57:27,673 Epoch[52] Batch [130]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.084591,	
2017-06-24 21:57:34,662 Epoch[52] Batch [140]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.084840,	
2017-06-24 21:57:41,420 Epoch[52] Batch [150]	Speed: 11.84 samples/sec	Train-FCNLogLoss=0.084922,	
2017-06-24 21:57:48,083 Epoch[52] Batch [160]	Speed: 12.01 samples/sec	Train-FCNLogLoss=0.085141,	
2017-06-24 21:57:54,951 Epoch[52] Batch [170]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.085386,	
2017-06-24 21:58:01,725 Epoch[52] Batch [180]	Speed: 11.81 samples/sec	Train-FCNLogLoss=0.085642,	
2017-06-24 21:58:08,434 Epoch[52] Batch [190]	Speed: 11.92 samples/sec	Train-FCNLogLoss=0.085600,	
2017-06-24 21:58:15,309 Epoch[52] Batch [200]	Speed: 11.64 samples/sec	Train-FCNLogLoss=0.085593,	
2017-06-24 21:58:22,205 Epoch[52] Batch [210]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.085797,	
2017-06-24 21:58:29,056 Epoch[52] Batch [220]	Speed: 11.68 samples/sec	Train-FCNLogLoss=0.085502,	
2017-06-24 21:58:35,972 Epoch[52] Batch [230]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.085342,	
2017-06-24 21:58:42,989 Epoch[52] Batch [240]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.085237,	
2017-06-24 21:58:49,920 Epoch[52] Batch [250]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.085296,	
2017-06-24 21:58:56,722 Epoch[52] Batch [260]	Speed: 11.76 samples/sec	Train-FCNLogLoss=0.085292,	
2017-06-24 21:59:03,781 Epoch[52] Batch [270]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.085370,	
2017-06-24 21:59:11,004 Epoch[52] Batch [280]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.085289,	
2017-06-24 21:59:18,005 Epoch[52] Batch [290]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.085556,	
2017-06-24 21:59:24,970 Epoch[52] Batch [300]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085615,	
2017-06-24 21:59:31,777 Epoch[52] Batch [310]	Speed: 11.75 samples/sec	Train-FCNLogLoss=0.085807,	
2017-06-24 21:59:38,644 Epoch[52] Batch [320]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.085770,	
2017-06-24 21:59:45,355 Epoch[52] Batch [330]	Speed: 11.92 samples/sec	Train-FCNLogLoss=0.085590,	
2017-06-24 21:59:52,313 Epoch[52] Batch [340]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.085742,	
2017-06-24 21:59:59,319 Epoch[52] Batch [350]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.085833,	
2017-06-24 22:00:06,230 Epoch[52] Batch [360]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.085884,	
2017-06-24 22:00:13,389 Epoch[52] Batch [370]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.085858,	
2017-06-24 22:00:20,301 Epoch[52] Batch [380]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.085803,	
2017-06-24 22:00:27,189 Epoch[52] Batch [390]	Speed: 11.62 samples/sec	Train-FCNLogLoss=0.085758,	
2017-06-24 22:00:34,112 Epoch[52] Batch [400]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.085695,	
2017-06-24 22:00:41,046 Epoch[52] Batch [410]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.085563,	
2017-06-24 22:00:48,011 Epoch[52] Batch [420]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085598,	
2017-06-24 22:00:55,070 Epoch[52] Batch [430]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.085562,	
2017-06-24 22:01:02,088 Epoch[52] Batch [440]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.085643,	
2017-06-24 22:01:08,840 Epoch[52] Batch [450]	Speed: 11.85 samples/sec	Train-FCNLogLoss=0.085622,	
2017-06-24 22:01:15,896 Epoch[52] Batch [460]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.085598,	
2017-06-24 22:01:22,814 Epoch[52] Batch [470]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.085639,	
2017-06-24 22:01:29,719 Epoch[52] Batch [480]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.085720,	
2017-06-24 22:01:36,766 Epoch[52] Batch [490]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.085754,	
2017-06-24 22:01:43,710 Epoch[52] Batch [500]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.085724,	
2017-06-24 22:01:50,784 Epoch[52] Batch [510]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.085696,	
2017-06-24 22:01:57,991 Epoch[52] Batch [520]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.085724,	
2017-06-24 22:02:05,002 Epoch[52] Batch [530]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.085696,	
2017-06-24 22:02:11,975 Epoch[52] Batch [540]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.085675,	
2017-06-24 22:02:18,820 Epoch[52] Batch [550]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.085615,	
2017-06-24 22:02:25,785 Epoch[52] Batch [560]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085433,	
2017-06-24 22:02:32,807 Epoch[52] Batch [570]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.085439,	
2017-06-24 22:02:39,815 Epoch[52] Batch [580]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.085517,	
2017-06-24 22:02:46,847 Epoch[52] Batch [590]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.085556,	
2017-06-24 22:02:53,694 Epoch[52] Batch [600]	Speed: 11.69 samples/sec	Train-FCNLogLoss=0.085665,	
2017-06-24 22:03:00,602 Epoch[52] Batch [610]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.085635,	
2017-06-24 22:03:07,592 Epoch[52] Batch [620]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.085669,	
2017-06-24 22:03:14,601 Epoch[52] Batch [630]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.085688,	
2017-06-24 22:03:21,586 Epoch[52] Batch [640]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.085707,	
2017-06-24 22:03:28,592 Epoch[52] Batch [650]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.085710,	
2017-06-24 22:03:35,602 Epoch[52] Batch [660]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.085809,	
2017-06-24 22:03:42,567 Epoch[52] Batch [670]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.085817,	
2017-06-24 22:03:49,612 Epoch[52] Batch [680]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.085882,	
2017-06-24 22:03:56,566 Epoch[52] Batch [690]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.085854,	
2017-06-24 22:04:03,304 Epoch[52] Batch [700]	Speed: 11.87 samples/sec	Train-FCNLogLoss=0.085877,	
2017-06-24 22:04:10,193 Epoch[52] Batch [710]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.085913,	
2017-06-24 22:04:17,171 Epoch[52] Batch [720]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.085961,	
2017-06-24 22:04:24,219 Epoch[52] Batch [730]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.085969,	
2017-06-24 22:04:31,288 Epoch[52] Batch [740]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.085933,	
2017-06-24 22:04:32,580 Epoch[52] Train-FCNLogLoss=0.085941
2017-06-24 22:04:32,580 Epoch[52] Time cost=515.910
2017-06-24 22:04:33,885 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0053.params"
2017-06-24 22:04:35,740 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4-0053.states"
2017-06-24 22:04:35,750 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate4x4',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3,4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate4x4'}

2017-06-24 22:04:46,250 testing 8/500 data 1.3679s net 0.3136s post 0.0196s
2017-06-24 22:04:47,676 testing 16/500 data 1.2619s net 0.2846s post 0.0167s
2017-06-24 22:04:49,000 testing 24/500 data 1.1939s net 0.2738s post 0.0158s
2017-06-24 22:04:50,491 testing 32/500 data 1.1982s net 0.2692s post 0.0180s
2017-06-24 22:04:51,676 testing 40/500 data 1.1397s net 0.2664s post 0.0192s
2017-06-24 22:04:52,826 testing 48/500 data 1.0951s net 0.2643s post 0.0201s
2017-06-24 22:04:54,115 testing 56/500 data 1.0832s net 0.2632s post 0.0201s
2017-06-24 22:04:55,373 testing 64/500 data 1.0694s net 0.2628s post 0.0207s
2017-06-24 22:04:57,035 testing 72/500 data 1.1046s net 0.2619s post 0.0208s
2017-06-24 22:04:58,394 testing 80/500 data 1.1037s net 0.2608s post 0.0200s
2017-06-24 22:04:59,788 testing 88/500 data 1.1062s net 0.2598s post 0.0194s
2017-06-24 22:05:00,874 testing 96/500 data 1.0823s net 0.2593s post 0.0189s
2017-06-24 22:05:01,989 testing 104/500 data 1.0642s net 0.2587s post 0.0186s
2017-06-24 22:05:03,197 testing 112/500 data 1.0548s net 0.2583s post 0.0188s
2017-06-24 22:05:04,498 testing 120/500 data 1.0527s net 0.2580s post 0.0191s
2017-06-24 22:05:05,861 testing 128/500 data 1.0544s net 0.2582s post 0.0194s
2017-06-24 22:05:07,221 testing 136/500 data 1.0554s net 0.2586s post 0.0196s
2017-06-24 22:05:08,616 testing 144/500 data 1.0587s net 0.2589s post 0.0193s
2017-06-24 22:05:09,897 testing 152/500 data 1.0556s net 0.2589s post 0.0195s
2017-06-24 22:05:11,260 testing 160/500 data 1.0574s net 0.2587s post 0.0194s
2017-06-24 22:05:12,433 testing 168/500 data 1.0499s net 0.2585s post 0.0194s
2017-06-24 22:05:13,621 testing 176/500 data 1.0436s net 0.2583s post 0.0196s
2017-06-24 22:05:14,864 testing 184/500 data 1.0408s net 0.2579s post 0.0193s
2017-06-24 22:05:16,139 testing 192/500 data 1.0395s net 0.2576s post 0.0192s
2017-06-24 22:05:17,296 testing 200/500 data 1.0335s net 0.2574s post 0.0190s
2017-06-24 22:05:18,480 testing 208/500 data 1.0292s net 0.2571s post 0.0187s
2017-06-24 22:05:19,728 testing 216/500 data 1.0274s net 0.2568s post 0.0187s
2017-06-24 22:05:20,934 testing 224/500 data 1.0244s net 0.2566s post 0.0185s
2017-06-24 22:05:22,238 testing 232/500 data 1.0250s net 0.2564s post 0.0182s
2017-06-24 22:05:23,491 testing 240/500 data 1.0237s net 0.2562s post 0.0182s
2017-06-24 22:05:24,651 testing 248/500 data 1.0196s net 0.2560s post 0.0180s
2017-06-24 22:05:25,828 testing 256/500 data 1.0162s net 0.2559s post 0.0178s
2017-06-24 22:05:27,042 testing 264/500 data 1.0141s net 0.2557s post 0.0178s
2017-06-24 22:05:28,397 testing 272/500 data 1.0163s net 0.2556s post 0.0178s
2017-06-24 22:05:29,714 testing 280/500 data 1.0174s net 0.2555s post 0.0176s
2017-06-24 22:05:30,937 testing 288/500 data 1.0157s net 0.2554s post 0.0174s
2017-06-24 22:05:32,115 testing 296/500 data 1.0131s net 0.2552s post 0.0173s
2017-06-24 22:05:33,299 testing 304/500 data 1.0106s net 0.2551s post 0.0172s
2017-06-24 22:05:34,500 testing 312/500 data 1.0084s net 0.2551s post 0.0173s
2017-06-24 22:05:35,657 testing 320/500 data 1.0052s net 0.2551s post 0.0174s
2017-06-24 22:05:36,808 testing 328/500 data 1.0020s net 0.2550s post 0.0175s
2017-06-24 22:05:37,941 testing 336/500 data 0.9988s net 0.2550s post 0.0174s
2017-06-24 22:05:39,323 testing 344/500 data 1.0015s net 0.2550s post 0.0174s
2017-06-24 22:05:40,693 testing 352/500 data 1.0035s net 0.2551s post 0.0175s
2017-06-24 22:05:41,869 testing 360/500 data 1.0014s net 0.2550s post 0.0174s
2017-06-24 22:05:43,155 testing 368/500 data 1.0018s net 0.2549s post 0.0173s
2017-06-24 22:05:44,303 testing 376/500 data 0.9993s net 0.2548s post 0.0172s
2017-06-24 22:05:45,641 testing 384/500 data 1.0009s net 0.2547s post 0.0171s
2017-06-24 22:05:47,019 testing 392/500 data 1.0031s net 0.2547s post 0.0170s
2017-06-24 22:05:48,175 testing 400/500 data 1.0009s net 0.2546s post 0.0170s
2017-06-24 22:05:49,492 testing 408/500 data 1.0018s net 0.2546s post 0.0170s
2017-06-24 22:05:50,737 testing 416/500 data 1.0012s net 0.2545s post 0.0171s
2017-06-24 22:05:51,959 testing 424/500 data 1.0004s net 0.2544s post 0.0170s
2017-06-24 22:05:53,148 testing 432/500 data 0.9991s net 0.2543s post 0.0170s
2017-06-24 22:05:54,352 testing 440/500 data 0.9980s net 0.2542s post 0.0169s
2017-06-24 22:05:55,666 testing 448/500 data 0.9989s net 0.2542s post 0.0168s
2017-06-24 22:05:56,979 testing 456/500 data 0.9996s net 0.2542s post 0.0169s
2017-06-24 22:05:58,292 testing 464/500 data 1.0003s net 0.2543s post 0.0169s
2017-06-24 22:05:59,512 testing 472/500 data 0.9995s net 0.2543s post 0.0168s
2017-06-24 22:06:00,716 testing 480/500 data 0.9983s net 0.2542s post 0.0169s
2017-06-24 22:06:02,049 testing 488/500 data 0.9995s net 0.2541s post 0.0169s
2017-06-24 22:06:03,359 testing 496/500 data 1.0001s net 0.2541s post 0.0169s
2017-06-24 22:06:04,110 testing 504/500 data 0.9893s net 0.2568s post 0.0168s
2017-06-24 22:07:58,310 evaluate segmentation: 

2017-06-24 22:07:58,310 IU_array:

2017-06-24 22:07:58,310 0.97813
2017-06-24 22:07:58,310 0.82965
2017-06-24 22:07:58,310 0.91010
2017-06-24 22:07:58,310 0.46880
2017-06-24 22:07:58,311 0.51740
2017-06-24 22:07:58,311 0.53309
2017-06-24 22:07:58,311 0.63809
2017-06-24 22:07:58,311 0.72773
2017-06-24 22:07:58,311 0.91173
2017-06-24 22:07:58,311 0.60755
2017-06-24 22:07:58,311 0.93615
2017-06-24 22:07:58,311 0.77611
2017-06-24 22:07:58,311 0.56079
2017-06-24 22:07:58,311 0.93513
2017-06-24 22:07:58,311 0.58746
2017-06-24 22:07:58,311 0.77782
2017-06-24 22:07:58,311 0.57697
2017-06-24 22:07:58,311 0.60350
2017-06-24 22:07:58,312 0.73974
2017-06-24 22:07:58,312 meanIU:0.71663

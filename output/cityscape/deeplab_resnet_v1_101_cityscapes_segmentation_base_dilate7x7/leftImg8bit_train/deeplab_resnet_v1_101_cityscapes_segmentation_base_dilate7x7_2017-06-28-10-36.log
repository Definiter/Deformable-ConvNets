2017-06-28 10:36:31,021 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate7x7'}

2017-06-28 10:37:45,165 Epoch[0] Batch [10]	Speed: 9.16 samples/sec	Train-FCNLogLoss=2.891018,	
2017-06-28 10:37:49,522 Epoch[0] Batch [20]	Speed: 9.18 samples/sec	Train-FCNLogLoss=2.736222,	
2017-06-28 10:37:54,255 Epoch[0] Batch [30]	Speed: 8.45 samples/sec	Train-FCNLogLoss=2.480888,	
2017-06-28 10:37:58,854 Epoch[0] Batch [40]	Speed: 8.70 samples/sec	Train-FCNLogLoss=2.233853,	
2017-06-28 10:38:03,124 Epoch[0] Batch [50]	Speed: 9.37 samples/sec	Train-FCNLogLoss=2.014795,	
2017-06-28 10:38:07,309 Epoch[0] Batch [60]	Speed: 9.56 samples/sec	Train-FCNLogLoss=1.839754,	
2017-06-28 10:38:11,460 Epoch[0] Batch [70]	Speed: 9.64 samples/sec	Train-FCNLogLoss=1.703907,	
2017-06-28 10:38:15,746 Epoch[0] Batch [80]	Speed: 9.33 samples/sec	Train-FCNLogLoss=1.608946,	
2017-06-28 10:38:20,274 Epoch[0] Batch [90]	Speed: 8.83 samples/sec	Train-FCNLogLoss=1.522713,	
2017-06-28 10:38:24,692 Epoch[0] Batch [100]	Speed: 9.05 samples/sec	Train-FCNLogLoss=1.435554,	
2017-06-28 10:38:28,837 Epoch[0] Batch [110]	Speed: 9.65 samples/sec	Train-FCNLogLoss=1.358599,	
2017-06-28 10:38:33,299 Epoch[0] Batch [120]	Speed: 8.96 samples/sec	Train-FCNLogLoss=1.297900,	
2017-06-28 10:38:37,641 Epoch[0] Batch [130]	Speed: 9.21 samples/sec	Train-FCNLogLoss=1.245244,	
2017-06-28 10:38:42,062 Epoch[0] Batch [140]	Speed: 9.05 samples/sec	Train-FCNLogLoss=1.197635,	
2017-06-28 10:38:46,789 Epoch[0] Batch [150]	Speed: 8.46 samples/sec	Train-FCNLogLoss=1.154392,	
2017-06-28 10:38:51,132 Epoch[0] Batch [160]	Speed: 9.21 samples/sec	Train-FCNLogLoss=1.115842,	
2017-06-28 10:38:55,931 Epoch[0] Batch [170]	Speed: 8.33 samples/sec	Train-FCNLogLoss=1.080770,	
2017-06-28 10:39:00,597 Epoch[0] Batch [180]	Speed: 8.57 samples/sec	Train-FCNLogLoss=1.055122,	
2017-06-28 10:39:05,180 Epoch[0] Batch [190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=1.029333,	
2017-06-28 10:39:09,613 Epoch[0] Batch [200]	Speed: 9.02 samples/sec	Train-FCNLogLoss=1.003680,	
2017-06-28 10:39:14,147 Epoch[0] Batch [210]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.978532,	
2017-06-28 10:39:18,293 Epoch[0] Batch [220]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.961784,	
2017-06-28 10:39:23,055 Epoch[0] Batch [230]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.943789,	
2017-06-28 10:39:27,488 Epoch[0] Batch [240]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.924704,	
2017-06-28 10:39:31,824 Epoch[0] Batch [250]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.907097,	
2017-06-28 10:39:35,974 Epoch[0] Batch [260]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.888580,	
2017-06-28 10:39:40,449 Epoch[0] Batch [270]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.872228,	
2017-06-28 10:39:44,804 Epoch[0] Batch [280]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.857038,	
2017-06-28 10:39:49,273 Epoch[0] Batch [290]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.842218,	
2017-06-28 10:39:53,927 Epoch[0] Batch [300]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.829728,	
2017-06-28 10:39:58,644 Epoch[0] Batch [310]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.817166,	
2017-06-28 10:40:03,445 Epoch[0] Batch [320]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.804565,	
2017-06-28 10:40:07,979 Epoch[0] Batch [330]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.794430,	
2017-06-28 10:40:12,087 Epoch[0] Batch [340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.784206,	
2017-06-28 10:40:16,574 Epoch[0] Batch [350]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.773643,	
2017-06-28 10:40:20,960 Epoch[0] Batch [360]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.764056,	
2017-06-28 10:40:25,228 Epoch[0] Batch [370]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.754310,	
2017-06-28 10:40:29,378 Epoch[0] Batch [380]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.745252,	
2017-06-28 10:40:33,790 Epoch[0] Batch [390]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.736399,	
2017-06-28 10:40:38,265 Epoch[0] Batch [400]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.730068,	
2017-06-28 10:40:42,540 Epoch[0] Batch [410]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.723176,	
2017-06-28 10:40:46,950 Epoch[0] Batch [420]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.716110,	
2017-06-28 10:40:51,185 Epoch[0] Batch [430]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.708631,	
2017-06-28 10:40:55,888 Epoch[0] Batch [440]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.701679,	
2017-06-28 10:41:00,159 Epoch[0] Batch [450]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.694518,	
2017-06-28 10:41:04,697 Epoch[0] Batch [460]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.687175,	
2017-06-28 10:41:09,396 Epoch[0] Batch [470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.681707,	
2017-06-28 10:41:14,114 Epoch[0] Batch [480]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.675209,	
2017-06-28 10:41:18,692 Epoch[0] Batch [490]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.667872,	
2017-06-28 10:41:22,726 Epoch[0] Batch [500]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.661906,	
2017-06-28 10:41:27,107 Epoch[0] Batch [510]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.655900,	
2017-06-28 10:41:31,449 Epoch[0] Batch [520]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.651210,	
2017-06-28 10:41:36,294 Epoch[0] Batch [530]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.645751,	
2017-06-28 10:41:40,770 Epoch[0] Batch [540]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.640763,	
2017-06-28 10:41:45,436 Epoch[0] Batch [550]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.636781,	
2017-06-28 10:41:50,085 Epoch[0] Batch [560]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.632571,	
2017-06-28 10:41:54,562 Epoch[0] Batch [570]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.629353,	
2017-06-28 10:41:59,175 Epoch[0] Batch [580]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.624897,	
2017-06-28 10:42:03,603 Epoch[0] Batch [590]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.619961,	
2017-06-28 10:42:08,219 Epoch[0] Batch [600]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.615713,	
2017-06-28 10:42:12,404 Epoch[0] Batch [610]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.610868,	
2017-06-28 10:42:16,932 Epoch[0] Batch [620]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.606663,	
2017-06-28 10:42:21,271 Epoch[0] Batch [630]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.602508,	
2017-06-28 10:42:25,894 Epoch[0] Batch [640]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.600558,	
2017-06-28 10:42:30,274 Epoch[0] Batch [650]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.596971,	
2017-06-28 10:42:34,359 Epoch[0] Batch [660]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.593581,	
2017-06-28 10:42:38,525 Epoch[0] Batch [670]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.589615,	
2017-06-28 10:42:43,067 Epoch[0] Batch [680]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.585339,	
2017-06-28 10:42:47,680 Epoch[0] Batch [690]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.582308,	
2017-06-28 10:42:52,532 Epoch[0] Batch [700]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.579430,	
2017-06-28 10:42:56,708 Epoch[0] Batch [710]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.576923,	
2017-06-28 10:43:01,266 Epoch[0] Batch [720]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.573600,	
2017-06-28 10:43:05,929 Epoch[0] Batch [730]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.570465,	
2017-06-28 10:43:10,625 Epoch[0] Batch [740]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.566593,	
2017-06-28 10:43:15,251 Epoch[0] Batch [750]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.563117,	
2017-06-28 10:43:19,684 Epoch[0] Batch [760]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.560648,	
2017-06-28 10:43:24,172 Epoch[0] Batch [770]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.558169,	
2017-06-28 10:43:28,681 Epoch[0] Batch [780]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.556221,	
2017-06-28 10:43:33,237 Epoch[0] Batch [790]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.553654,	
2017-06-28 10:43:37,558 Epoch[0] Batch [800]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.551373,	
2017-06-28 10:43:41,929 Epoch[0] Batch [810]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.548556,	
2017-06-28 10:43:46,281 Epoch[0] Batch [820]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.545891,	
2017-06-28 10:43:50,830 Epoch[0] Batch [830]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.542870,	
2017-06-28 10:43:55,263 Epoch[0] Batch [840]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.540880,	
2017-06-28 10:43:59,337 Epoch[0] Batch [850]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.538464,	
2017-06-28 10:44:03,689 Epoch[0] Batch [860]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.535602,	
2017-06-28 10:44:08,363 Epoch[0] Batch [870]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.533409,	
2017-06-28 10:44:13,048 Epoch[0] Batch [880]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.531055,	
2017-06-28 10:44:17,478 Epoch[0] Batch [890]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.528405,	
2017-06-28 10:44:21,769 Epoch[0] Batch [900]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.525963,	
2017-06-28 10:44:25,901 Epoch[0] Batch [910]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.523790,	
2017-06-28 10:44:30,351 Epoch[0] Batch [920]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.521192,	
2017-06-28 10:44:34,541 Epoch[0] Batch [930]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.519348,	
2017-06-28 10:44:39,248 Epoch[0] Batch [940]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.517292,	
2017-06-28 10:44:43,603 Epoch[0] Batch [950]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.515377,	
2017-06-28 10:44:47,975 Epoch[0] Batch [960]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.513196,	
2017-06-28 10:44:52,648 Epoch[0] Batch [970]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.510828,	
2017-06-28 10:44:57,012 Epoch[0] Batch [980]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.509639,	
2017-06-28 10:45:01,421 Epoch[0] Batch [990]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.508590,	
2017-06-28 10:45:05,950 Epoch[0] Batch [1000]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.506530,	
2017-06-28 10:45:10,267 Epoch[0] Batch [1010]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.505611,	
2017-06-28 10:45:14,648 Epoch[0] Batch [1020]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.506832,	
2017-06-28 10:45:19,133 Epoch[0] Batch [1030]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.507095,	
2017-06-28 10:45:23,601 Epoch[0] Batch [1040]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.508108,	
2017-06-28 10:45:27,894 Epoch[0] Batch [1050]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.509346,	
2017-06-28 10:45:32,269 Epoch[0] Batch [1060]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.509081,	
2017-06-28 10:45:36,740 Epoch[0] Batch [1070]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.507963,	
2017-06-28 10:45:41,037 Epoch[0] Batch [1080]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.507665,	
2017-06-28 10:45:45,222 Epoch[0] Batch [1090]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.506606,	
2017-06-28 10:45:49,704 Epoch[0] Batch [1100]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.505045,	
2017-06-28 10:45:53,893 Epoch[0] Batch [1110]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.504244,	
2017-06-28 10:45:58,590 Epoch[0] Batch [1120]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.503151,	
2017-06-28 10:46:03,086 Epoch[0] Batch [1130]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.501953,	
2017-06-28 10:46:07,467 Epoch[0] Batch [1140]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.502368,	
2017-06-28 10:46:11,668 Epoch[0] Batch [1150]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.501426,	
2017-06-28 10:46:16,289 Epoch[0] Batch [1160]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.500232,	
2017-06-28 10:46:20,988 Epoch[0] Batch [1170]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.498985,	
2017-06-28 10:46:25,675 Epoch[0] Batch [1180]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.497826,	
2017-06-28 10:46:30,434 Epoch[0] Batch [1190]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.497608,	
2017-06-28 10:46:34,856 Epoch[0] Batch [1200]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.499102,	
2017-06-28 10:46:39,267 Epoch[0] Batch [1210]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.498292,	
2017-06-28 10:46:44,257 Epoch[0] Batch [1220]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.497050,	
2017-06-28 10:46:48,784 Epoch[0] Batch [1230]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.496892,	
2017-06-28 10:46:53,154 Epoch[0] Batch [1240]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.495510,	
2017-06-28 10:46:57,422 Epoch[0] Batch [1250]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.494621,	
2017-06-28 10:47:01,834 Epoch[0] Batch [1260]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.493777,	
2017-06-28 10:47:06,263 Epoch[0] Batch [1270]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.492783,	
2017-06-28 10:47:10,421 Epoch[0] Batch [1280]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.491784,	
2017-06-28 10:47:14,937 Epoch[0] Batch [1290]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.490285,	
2017-06-28 10:47:19,296 Epoch[0] Batch [1300]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.488693,	
2017-06-28 10:47:23,652 Epoch[0] Batch [1310]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.487115,	
2017-06-28 10:47:27,877 Epoch[0] Batch [1320]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.485525,	
2017-06-28 10:47:32,504 Epoch[0] Batch [1330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.484507,	
2017-06-28 10:47:37,180 Epoch[0] Batch [1340]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.484191,	
2017-06-28 10:47:41,635 Epoch[0] Batch [1350]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.483626,	
2017-06-28 10:47:46,419 Epoch[0] Batch [1360]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.482640,	
2017-06-28 10:47:50,630 Epoch[0] Batch [1370]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.481030,	
2017-06-28 10:47:55,426 Epoch[0] Batch [1380]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.479842,	
2017-06-28 10:47:59,930 Epoch[0] Batch [1390]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.479040,	
2017-06-28 10:48:04,451 Epoch[0] Batch [1400]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.477989,	
2017-06-28 10:48:08,736 Epoch[0] Batch [1410]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.476584,	
2017-06-28 10:48:13,098 Epoch[0] Batch [1420]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.475561,	
2017-06-28 10:48:18,033 Epoch[0] Batch [1430]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.474367,	
2017-06-28 10:48:22,469 Epoch[0] Batch [1440]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.472950,	
2017-06-28 10:48:26,827 Epoch[0] Batch [1450]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.471929,	
2017-06-28 10:48:31,398 Epoch[0] Batch [1460]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.470679,	
2017-06-28 10:48:35,708 Epoch[0] Batch [1470]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.469358,	
2017-06-28 10:48:40,022 Epoch[0] Batch [1480]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.467730,	
2017-06-28 10:48:42,964 Epoch[0] Train-FCNLogLoss=0.466879
2017-06-28 10:48:42,964 Epoch[0] Time cost=670.996
2017-06-28 10:48:44,049 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0001.params"
2017-06-28 10:48:45,636 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0001.states"
2017-06-28 10:48:50,636 Epoch[1] Batch [10]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.288163,	
2017-06-28 10:48:55,472 Epoch[1] Batch [20]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.305057,	
2017-06-28 10:48:59,769 Epoch[1] Batch [30]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.309688,	
2017-06-28 10:49:04,347 Epoch[1] Batch [40]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.304953,	
2017-06-28 10:49:09,309 Epoch[1] Batch [50]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.301186,	
2017-06-28 10:49:13,671 Epoch[1] Batch [60]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.303385,	
2017-06-28 10:49:18,162 Epoch[1] Batch [70]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.298436,	
2017-06-28 10:49:22,745 Epoch[1] Batch [80]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.296129,	
2017-06-28 10:49:27,261 Epoch[1] Batch [90]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.293857,	
2017-06-28 10:49:31,662 Epoch[1] Batch [100]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.296125,	
2017-06-28 10:49:35,744 Epoch[1] Batch [110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.294646,	
2017-06-28 10:49:40,356 Epoch[1] Batch [120]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.291457,	
2017-06-28 10:49:44,587 Epoch[1] Batch [130]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.286805,	
2017-06-28 10:49:49,275 Epoch[1] Batch [140]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.284995,	
2017-06-28 10:49:54,215 Epoch[1] Batch [150]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.284774,	
2017-06-28 10:49:58,739 Epoch[1] Batch [160]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.285316,	
2017-06-28 10:50:03,140 Epoch[1] Batch [170]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.288445,	
2017-06-28 10:50:07,453 Epoch[1] Batch [180]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.286841,	
2017-06-28 10:50:12,179 Epoch[1] Batch [190]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.285593,	
2017-06-28 10:50:17,177 Epoch[1] Batch [200]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.283687,	
2017-06-28 10:50:21,700 Epoch[1] Batch [210]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.281128,	
2017-06-28 10:50:25,990 Epoch[1] Batch [220]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.281865,	
2017-06-28 10:50:30,258 Epoch[1] Batch [230]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.282239,	
2017-06-28 10:50:34,840 Epoch[1] Batch [240]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.282480,	
2017-06-28 10:50:39,592 Epoch[1] Batch [250]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.280835,	
2017-06-28 10:50:43,946 Epoch[1] Batch [260]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.279820,	
2017-06-28 10:50:48,472 Epoch[1] Batch [270]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.277238,	
2017-06-28 10:50:52,887 Epoch[1] Batch [280]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.275777,	
2017-06-28 10:50:57,533 Epoch[1] Batch [290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.275417,	
2017-06-28 10:51:01,945 Epoch[1] Batch [300]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.274655,	
2017-06-28 10:51:06,332 Epoch[1] Batch [310]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.275170,	
2017-06-28 10:51:10,510 Epoch[1] Batch [320]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.273766,	
2017-06-28 10:51:14,641 Epoch[1] Batch [330]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.272765,	
2017-06-28 10:51:19,093 Epoch[1] Batch [340]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.272661,	
2017-06-28 10:51:23,790 Epoch[1] Batch [350]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.273990,	
2017-06-28 10:51:28,190 Epoch[1] Batch [360]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.272809,	
2017-06-28 10:51:32,911 Epoch[1] Batch [370]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.271193,	
2017-06-28 10:51:37,520 Epoch[1] Batch [380]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.270608,	
2017-06-28 10:51:41,944 Epoch[1] Batch [390]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.269843,	
2017-06-28 10:51:46,597 Epoch[1] Batch [400]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.269439,	
2017-06-28 10:51:51,235 Epoch[1] Batch [410]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.269399,	
2017-06-28 10:51:55,625 Epoch[1] Batch [420]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.268574,	
2017-06-28 10:52:00,320 Epoch[1] Batch [430]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.268440,	
2017-06-28 10:52:05,086 Epoch[1] Batch [440]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.269457,	
2017-06-28 10:52:09,564 Epoch[1] Batch [450]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.269670,	
2017-06-28 10:52:14,250 Epoch[1] Batch [460]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.270013,	
2017-06-28 10:52:18,361 Epoch[1] Batch [470]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.269907,	
2017-06-28 10:52:22,794 Epoch[1] Batch [480]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.269841,	
2017-06-28 10:52:27,422 Epoch[1] Batch [490]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.269423,	
2017-06-28 10:52:31,919 Epoch[1] Batch [500]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.268830,	
2017-06-28 10:52:36,399 Epoch[1] Batch [510]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.269449,	
2017-06-28 10:52:41,482 Epoch[1] Batch [520]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.269380,	
2017-06-28 10:52:46,035 Epoch[1] Batch [530]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.269403,	
2017-06-28 10:52:50,466 Epoch[1] Batch [540]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.270081,	
2017-06-28 10:52:55,046 Epoch[1] Batch [550]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.269742,	
2017-06-28 10:52:59,546 Epoch[1] Batch [560]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.269249,	
2017-06-28 10:53:04,500 Epoch[1] Batch [570]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.268745,	
2017-06-28 10:53:09,376 Epoch[1] Batch [580]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.268136,	
2017-06-28 10:53:14,191 Epoch[1] Batch [590]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.268061,	
2017-06-28 10:53:18,874 Epoch[1] Batch [600]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.267446,	
2017-06-28 10:53:23,418 Epoch[1] Batch [610]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.267042,	
2017-06-28 10:53:27,998 Epoch[1] Batch [620]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.266678,	
2017-06-28 10:53:32,596 Epoch[1] Batch [630]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.266121,	
2017-06-28 10:53:37,135 Epoch[1] Batch [640]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.265828,	
2017-06-28 10:53:41,622 Epoch[1] Batch [650]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.265031,	
2017-06-28 10:53:46,171 Epoch[1] Batch [660]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.264128,	
2017-06-28 10:53:50,618 Epoch[1] Batch [670]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.263339,	
2017-06-28 10:53:55,198 Epoch[1] Batch [680]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.262457,	
2017-06-28 10:54:00,036 Epoch[1] Batch [690]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.262023,	
2017-06-28 10:54:04,475 Epoch[1] Batch [700]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.261284,	
2017-06-28 10:54:09,083 Epoch[1] Batch [710]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.261713,	
2017-06-28 10:54:13,721 Epoch[1] Batch [720]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.262048,	
2017-06-28 10:54:17,976 Epoch[1] Batch [730]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.262138,	
2017-06-28 10:54:22,671 Epoch[1] Batch [740]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.262042,	
2017-06-28 10:54:26,850 Epoch[1] Batch [750]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.262007,	
2017-06-28 10:54:31,355 Epoch[1] Batch [760]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.261692,	
2017-06-28 10:54:36,051 Epoch[1] Batch [770]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.261587,	
2017-06-28 10:54:40,635 Epoch[1] Batch [780]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.261239,	
2017-06-28 10:54:44,957 Epoch[1] Batch [790]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.261005,	
2017-06-28 10:54:49,807 Epoch[1] Batch [800]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.260827,	
2017-06-28 10:54:54,501 Epoch[1] Batch [810]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.261390,	
2017-06-28 10:54:59,014 Epoch[1] Batch [820]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.261785,	
2017-06-28 10:55:03,645 Epoch[1] Batch [830]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.261608,	
2017-06-28 10:55:07,837 Epoch[1] Batch [840]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.261218,	
2017-06-28 10:55:12,366 Epoch[1] Batch [850]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.261260,	
2017-06-28 10:55:17,255 Epoch[1] Batch [860]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.261310,	
2017-06-28 10:55:21,577 Epoch[1] Batch [870]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.261641,	
2017-06-28 10:55:26,367 Epoch[1] Batch [880]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.261740,	
2017-06-28 10:55:30,915 Epoch[1] Batch [890]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.261134,	
2017-06-28 10:55:35,202 Epoch[1] Batch [900]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.260744,	
2017-06-28 10:55:39,644 Epoch[1] Batch [910]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.261000,	
2017-06-28 10:55:43,994 Epoch[1] Batch [920]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.260643,	
2017-06-28 10:55:48,447 Epoch[1] Batch [930]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.260449,	
2017-06-28 10:55:52,778 Epoch[1] Batch [940]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.259796,	
2017-06-28 10:55:57,534 Epoch[1] Batch [950]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.260043,	
2017-06-28 10:56:02,198 Epoch[1] Batch [960]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.259692,	
2017-06-28 10:56:06,971 Epoch[1] Batch [970]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.259572,	
2017-06-28 10:56:11,670 Epoch[1] Batch [980]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.259486,	
2017-06-28 10:56:16,339 Epoch[1] Batch [990]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.259087,	
2017-06-28 10:56:21,057 Epoch[1] Batch [1000]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.258587,	
2017-06-28 10:56:25,307 Epoch[1] Batch [1010]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.258084,	
2017-06-28 10:56:29,516 Epoch[1] Batch [1020]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.257558,	
2017-06-28 10:56:33,862 Epoch[1] Batch [1030]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.256983,	
2017-06-28 10:56:38,442 Epoch[1] Batch [1040]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.256513,	
2017-06-28 10:56:42,783 Epoch[1] Batch [1050]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.256613,	
2017-06-28 10:56:47,122 Epoch[1] Batch [1060]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.256567,	
2017-06-28 10:56:51,700 Epoch[1] Batch [1070]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.256251,	
2017-06-28 10:56:56,033 Epoch[1] Batch [1080]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.255719,	
2017-06-28 10:57:00,113 Epoch[1] Batch [1090]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.255308,	
2017-06-28 10:57:04,815 Epoch[1] Batch [1100]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.254957,	
2017-06-28 10:57:09,222 Epoch[1] Batch [1110]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.254585,	
2017-06-28 10:57:13,781 Epoch[1] Batch [1120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.254495,	
2017-06-28 10:57:18,173 Epoch[1] Batch [1130]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.254779,	
2017-06-28 10:57:22,246 Epoch[1] Batch [1140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.254681,	
2017-06-28 10:57:26,412 Epoch[1] Batch [1150]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.254482,	
2017-06-28 10:57:30,670 Epoch[1] Batch [1160]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.254056,	
2017-06-28 10:57:35,178 Epoch[1] Batch [1170]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.253556,	
2017-06-28 10:57:39,698 Epoch[1] Batch [1180]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.253280,	
2017-06-28 10:57:44,610 Epoch[1] Batch [1190]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.252985,	
2017-06-28 10:57:48,971 Epoch[1] Batch [1200]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.252705,	
2017-06-28 10:57:53,911 Epoch[1] Batch [1210]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.252950,	
2017-06-28 10:57:58,554 Epoch[1] Batch [1220]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.252761,	
2017-06-28 10:58:03,111 Epoch[1] Batch [1230]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.252293,	
2017-06-28 10:58:07,295 Epoch[1] Batch [1240]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.252204,	
2017-06-28 10:58:11,411 Epoch[1] Batch [1250]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.251907,	
2017-06-28 10:58:15,848 Epoch[1] Batch [1260]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.251559,	
2017-06-28 10:58:19,938 Epoch[1] Batch [1270]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.251361,	
2017-06-28 10:58:24,143 Epoch[1] Batch [1280]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.251040,	
2017-06-28 10:58:28,305 Epoch[1] Batch [1290]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.250604,	
2017-06-28 10:58:32,635 Epoch[1] Batch [1300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.250404,	
2017-06-28 10:58:36,818 Epoch[1] Batch [1310]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.249897,	
2017-06-28 10:58:41,385 Epoch[1] Batch [1320]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.249612,	
2017-06-28 10:58:45,859 Epoch[1] Batch [1330]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.249281,	
2017-06-28 10:58:50,221 Epoch[1] Batch [1340]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.248932,	
2017-06-28 10:58:54,884 Epoch[1] Batch [1350]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.248250,	
2017-06-28 10:58:59,383 Epoch[1] Batch [1360]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.247858,	
2017-06-28 10:59:03,584 Epoch[1] Batch [1370]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.247505,	
2017-06-28 10:59:08,151 Epoch[1] Batch [1380]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.247150,	
2017-06-28 10:59:12,994 Epoch[1] Batch [1390]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.246851,	
2017-06-28 10:59:18,018 Epoch[1] Batch [1400]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.246587,	
2017-06-28 10:59:22,976 Epoch[1] Batch [1410]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.246465,	
2017-06-28 10:59:27,465 Epoch[1] Batch [1420]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.246339,	
2017-06-28 10:59:32,139 Epoch[1] Batch [1430]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.246130,	
2017-06-28 10:59:36,631 Epoch[1] Batch [1440]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.245876,	
2017-06-28 10:59:41,310 Epoch[1] Batch [1450]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.245796,	
2017-06-28 10:59:46,114 Epoch[1] Batch [1460]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.245572,	
2017-06-28 10:59:50,466 Epoch[1] Batch [1470]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.245277,	
2017-06-28 10:59:54,791 Epoch[1] Batch [1480]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.245120,	
2017-06-28 10:59:57,360 Epoch[1] Train-FCNLogLoss=0.245129
2017-06-28 10:59:57,361 Epoch[1] Time cost=671.724
2017-06-28 10:59:58,295 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0002.params"
2017-06-28 10:59:59,966 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0002.states"
2017-06-28 11:00:04,959 Epoch[2] Batch [10]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.249696,	
2017-06-28 11:00:09,803 Epoch[2] Batch [20]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.223391,	
2017-06-28 11:00:14,175 Epoch[2] Batch [30]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.230282,	
2017-06-28 11:00:18,324 Epoch[2] Batch [40]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.219655,	
2017-06-28 11:00:22,643 Epoch[2] Batch [50]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.219700,	
2017-06-28 11:00:27,282 Epoch[2] Batch [60]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.213162,	
2017-06-28 11:00:31,680 Epoch[2] Batch [70]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.214171,	
2017-06-28 11:00:35,767 Epoch[2] Batch [80]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.217654,	
2017-06-28 11:00:40,240 Epoch[2] Batch [90]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.216788,	
2017-06-28 11:00:44,774 Epoch[2] Batch [100]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.217704,	
2017-06-28 11:00:49,408 Epoch[2] Batch [110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.218158,	
2017-06-28 11:00:53,776 Epoch[2] Batch [120]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.216321,	
2017-06-28 11:00:58,643 Epoch[2] Batch [130]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.218139,	
2017-06-28 11:01:03,170 Epoch[2] Batch [140]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.215913,	
2017-06-28 11:01:07,561 Epoch[2] Batch [150]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.215538,	
2017-06-28 11:01:11,876 Epoch[2] Batch [160]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.214972,	
2017-06-28 11:01:16,450 Epoch[2] Batch [170]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.216728,	
2017-06-28 11:01:20,890 Epoch[2] Batch [180]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.219123,	
2017-06-28 11:01:25,714 Epoch[2] Batch [190]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.219939,	
2017-06-28 11:01:30,146 Epoch[2] Batch [200]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.221076,	
2017-06-28 11:01:34,881 Epoch[2] Batch [210]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.220954,	
2017-06-28 11:01:39,303 Epoch[2] Batch [220]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.221376,	
2017-06-28 11:01:43,575 Epoch[2] Batch [230]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.221505,	
2017-06-28 11:01:47,960 Epoch[2] Batch [240]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.221355,	
2017-06-28 11:01:52,583 Epoch[2] Batch [250]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.222877,	
2017-06-28 11:01:57,072 Epoch[2] Batch [260]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.223205,	
2017-06-28 11:02:01,491 Epoch[2] Batch [270]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.221611,	
2017-06-28 11:02:06,097 Epoch[2] Batch [280]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.222336,	
2017-06-28 11:02:10,645 Epoch[2] Batch [290]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.221777,	
2017-06-28 11:02:14,974 Epoch[2] Batch [300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.221649,	
2017-06-28 11:02:19,937 Epoch[2] Batch [310]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.221876,	
2017-06-28 11:02:24,204 Epoch[2] Batch [320]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.221946,	
2017-06-28 11:02:28,795 Epoch[2] Batch [330]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.221311,	
2017-06-28 11:02:33,291 Epoch[2] Batch [340]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.220756,	
2017-06-28 11:02:38,004 Epoch[2] Batch [350]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.220516,	
2017-06-28 11:02:42,272 Epoch[2] Batch [360]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.220128,	
2017-06-28 11:02:46,854 Epoch[2] Batch [370]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.219857,	
2017-06-28 11:02:51,417 Epoch[2] Batch [380]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.218833,	
2017-06-28 11:02:55,929 Epoch[2] Batch [390]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.218126,	
2017-06-28 11:03:00,688 Epoch[2] Batch [400]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.217432,	
2017-06-28 11:03:05,363 Epoch[2] Batch [410]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.216194,	
2017-06-28 11:03:09,787 Epoch[2] Batch [420]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.215332,	
2017-06-28 11:03:14,139 Epoch[2] Batch [430]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.214935,	
2017-06-28 11:03:18,617 Epoch[2] Batch [440]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.214726,	
2017-06-28 11:03:23,025 Epoch[2] Batch [450]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.214124,	
2017-06-28 11:03:27,527 Epoch[2] Batch [460]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.213270,	
2017-06-28 11:03:31,915 Epoch[2] Batch [470]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.212762,	
2017-06-28 11:03:36,416 Epoch[2] Batch [480]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.213045,	
2017-06-28 11:03:40,960 Epoch[2] Batch [490]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.212707,	
2017-06-28 11:03:45,230 Epoch[2] Batch [500]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.212536,	
2017-06-28 11:03:49,255 Epoch[2] Batch [510]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.213218,	
2017-06-28 11:03:53,324 Epoch[2] Batch [520]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.212798,	
2017-06-28 11:03:57,780 Epoch[2] Batch [530]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.212790,	
2017-06-28 11:04:02,153 Epoch[2] Batch [540]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.212733,	
2017-06-28 11:04:06,456 Epoch[2] Batch [550]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.212815,	
2017-06-28 11:04:10,777 Epoch[2] Batch [560]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.213116,	
2017-06-28 11:04:15,053 Epoch[2] Batch [570]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.212856,	
2017-06-28 11:04:19,487 Epoch[2] Batch [580]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.213294,	
2017-06-28 11:04:24,143 Epoch[2] Batch [590]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.213331,	
2017-06-28 11:04:28,550 Epoch[2] Batch [600]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.213785,	
2017-06-28 11:04:32,982 Epoch[2] Batch [610]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.213431,	
2017-06-28 11:04:37,347 Epoch[2] Batch [620]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.213081,	
2017-06-28 11:04:41,560 Epoch[2] Batch [630]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.212569,	
2017-06-28 11:04:45,923 Epoch[2] Batch [640]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.212645,	
2017-06-28 11:04:50,742 Epoch[2] Batch [650]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.212246,	
2017-06-28 11:04:54,967 Epoch[2] Batch [660]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.212144,	
2017-06-28 11:04:59,665 Epoch[2] Batch [670]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.211910,	
2017-06-28 11:05:04,279 Epoch[2] Batch [680]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.212238,	
2017-06-28 11:05:08,848 Epoch[2] Batch [690]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.211871,	
2017-06-28 11:05:13,037 Epoch[2] Batch [700]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.211850,	
2017-06-28 11:05:17,298 Epoch[2] Batch [710]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.212053,	
2017-06-28 11:05:21,340 Epoch[2] Batch [720]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.211998,	
2017-06-28 11:05:25,706 Epoch[2] Batch [730]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.211658,	
2017-06-28 11:05:30,357 Epoch[2] Batch [740]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.211453,	
2017-06-28 11:05:34,491 Epoch[2] Batch [750]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.211467,	
2017-06-28 11:05:39,080 Epoch[2] Batch [760]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.211723,	
2017-06-28 11:05:43,608 Epoch[2] Batch [770]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.211853,	
2017-06-28 11:05:47,742 Epoch[2] Batch [780]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.211617,	
2017-06-28 11:05:51,983 Epoch[2] Batch [790]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.211098,	
2017-06-28 11:05:56,455 Epoch[2] Batch [800]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.210863,	
2017-06-28 11:06:00,842 Epoch[2] Batch [810]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.210508,	
2017-06-28 11:06:05,234 Epoch[2] Batch [820]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.210022,	
2017-06-28 11:06:09,669 Epoch[2] Batch [830]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.209982,	
2017-06-28 11:06:13,816 Epoch[2] Batch [840]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.210719,	
2017-06-28 11:06:18,137 Epoch[2] Batch [850]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.210686,	
2017-06-28 11:06:22,187 Epoch[2] Batch [860]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.210977,	
2017-06-28 11:06:26,914 Epoch[2] Batch [870]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.210751,	
2017-06-28 11:06:31,326 Epoch[2] Batch [880]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.210986,	
2017-06-28 11:06:35,595 Epoch[2] Batch [890]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.210901,	
2017-06-28 11:06:40,077 Epoch[2] Batch [900]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.210674,	
2017-06-28 11:06:44,641 Epoch[2] Batch [910]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.210632,	
2017-06-28 11:06:48,864 Epoch[2] Batch [920]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.210677,	
2017-06-28 11:06:52,948 Epoch[2] Batch [930]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.210497,	
2017-06-28 11:06:57,525 Epoch[2] Batch [940]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.210552,	
2017-06-28 11:07:02,162 Epoch[2] Batch [950]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.210729,	
2017-06-28 11:07:06,225 Epoch[2] Batch [960]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.210827,	
2017-06-28 11:07:10,606 Epoch[2] Batch [970]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.210614,	
2017-06-28 11:07:14,981 Epoch[2] Batch [980]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.210293,	
2017-06-28 11:07:19,780 Epoch[2] Batch [990]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.210630,	
2017-06-28 11:07:24,104 Epoch[2] Batch [1000]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.210486,	
2017-06-28 11:07:28,436 Epoch[2] Batch [1010]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.210387,	
2017-06-28 11:07:32,928 Epoch[2] Batch [1020]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.210009,	
2017-06-28 11:07:37,214 Epoch[2] Batch [1030]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.209691,	
2017-06-28 11:07:41,763 Epoch[2] Batch [1040]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.209559,	
2017-06-28 11:07:46,269 Epoch[2] Batch [1050]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.209439,	
2017-06-28 11:07:50,802 Epoch[2] Batch [1060]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.209296,	
2017-06-28 11:07:55,334 Epoch[2] Batch [1070]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.209199,	
2017-06-28 11:07:59,609 Epoch[2] Batch [1080]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.208917,	
2017-06-28 11:08:04,165 Epoch[2] Batch [1090]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.209069,	
2017-06-28 11:08:08,396 Epoch[2] Batch [1100]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.208973,	
2017-06-28 11:08:12,809 Epoch[2] Batch [1110]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.208616,	
2017-06-28 11:08:17,349 Epoch[2] Batch [1120]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.208607,	
2017-06-28 11:08:22,005 Epoch[2] Batch [1130]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.208250,	
2017-06-28 11:08:26,771 Epoch[2] Batch [1140]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.207993,	
2017-06-28 11:08:31,070 Epoch[2] Batch [1150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.207795,	
2017-06-28 11:08:35,678 Epoch[2] Batch [1160]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.207369,	
2017-06-28 11:08:39,860 Epoch[2] Batch [1170]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.207124,	
2017-06-28 11:08:44,240 Epoch[2] Batch [1180]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.206864,	
2017-06-28 11:08:48,557 Epoch[2] Batch [1190]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.206742,	
2017-06-28 11:08:52,915 Epoch[2] Batch [1200]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.206539,	
2017-06-28 11:08:57,653 Epoch[2] Batch [1210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.206441,	
2017-06-28 11:09:01,968 Epoch[2] Batch [1220]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.206274,	
2017-06-28 11:09:06,352 Epoch[2] Batch [1230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.206146,	
2017-06-28 11:09:11,061 Epoch[2] Batch [1240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.205907,	
2017-06-28 11:09:15,502 Epoch[2] Batch [1250]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.206034,	
2017-06-28 11:09:20,372 Epoch[2] Batch [1260]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.205949,	
2017-06-28 11:09:24,905 Epoch[2] Batch [1270]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.205631,	
2017-06-28 11:09:29,393 Epoch[2] Batch [1280]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.205511,	
2017-06-28 11:09:33,999 Epoch[2] Batch [1290]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.205535,	
2017-06-28 11:09:38,601 Epoch[2] Batch [1300]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.205502,	
2017-06-28 11:09:43,006 Epoch[2] Batch [1310]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.205636,	
2017-06-28 11:09:47,363 Epoch[2] Batch [1320]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.205781,	
2017-06-28 11:09:52,018 Epoch[2] Batch [1330]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.205723,	
2017-06-28 11:09:56,744 Epoch[2] Batch [1340]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.205710,	
2017-06-28 11:10:00,881 Epoch[2] Batch [1350]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.205561,	
2017-06-28 11:10:05,183 Epoch[2] Batch [1360]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.205557,	
2017-06-28 11:10:09,836 Epoch[2] Batch [1370]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.205346,	
2017-06-28 11:10:14,350 Epoch[2] Batch [1380]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.205064,	
2017-06-28 11:10:18,767 Epoch[2] Batch [1390]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.204690,	
2017-06-28 11:10:23,244 Epoch[2] Batch [1400]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.204551,	
2017-06-28 11:10:27,590 Epoch[2] Batch [1410]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.204546,	
2017-06-28 11:10:32,136 Epoch[2] Batch [1420]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.204681,	
2017-06-28 11:10:36,707 Epoch[2] Batch [1430]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.204540,	
2017-06-28 11:10:41,274 Epoch[2] Batch [1440]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.204482,	
2017-06-28 11:10:45,589 Epoch[2] Batch [1450]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.204266,	
2017-06-28 11:10:49,887 Epoch[2] Batch [1460]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.204366,	
2017-06-28 11:10:54,560 Epoch[2] Batch [1470]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.204418,	
2017-06-28 11:10:59,098 Epoch[2] Batch [1480]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.204485,	
2017-06-28 11:11:01,661 Epoch[2] Train-FCNLogLoss=0.204342
2017-06-28 11:11:01,661 Epoch[2] Time cost=661.695
2017-06-28 11:11:02,406 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0003.params"
2017-06-28 11:11:04,210 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0003.states"
2017-06-28 11:11:09,807 Epoch[3] Batch [10]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.186143,	
2017-06-28 11:11:14,624 Epoch[3] Batch [20]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.192866,	
2017-06-28 11:11:19,493 Epoch[3] Batch [30]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.187703,	
2017-06-28 11:11:23,947 Epoch[3] Batch [40]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.185945,	
2017-06-28 11:11:28,755 Epoch[3] Batch [50]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.186120,	
2017-06-28 11:11:33,588 Epoch[3] Batch [60]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.184675,	
2017-06-28 11:11:38,273 Epoch[3] Batch [70]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.185992,	
2017-06-28 11:11:42,716 Epoch[3] Batch [80]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.186783,	
2017-06-28 11:11:46,984 Epoch[3] Batch [90]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.185306,	
2017-06-28 11:11:51,763 Epoch[3] Batch [100]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.187352,	
2017-06-28 11:11:56,261 Epoch[3] Batch [110]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.189174,	
2017-06-28 11:12:00,923 Epoch[3] Batch [120]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.188549,	
2017-06-28 11:12:05,421 Epoch[3] Batch [130]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.186584,	
2017-06-28 11:12:10,301 Epoch[3] Batch [140]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.185678,	
2017-06-28 11:12:14,714 Epoch[3] Batch [150]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.183588,	
2017-06-28 11:12:19,230 Epoch[3] Batch [160]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.183636,	
2017-06-28 11:12:23,679 Epoch[3] Batch [170]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.183120,	
2017-06-28 11:12:28,273 Epoch[3] Batch [180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.182423,	
2017-06-28 11:12:32,637 Epoch[3] Batch [190]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.182586,	
2017-06-28 11:12:36,987 Epoch[3] Batch [200]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.183411,	
2017-06-28 11:12:41,134 Epoch[3] Batch [210]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.184453,	
2017-06-28 11:12:45,783 Epoch[3] Batch [220]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.186319,	
2017-06-28 11:12:50,014 Epoch[3] Batch [230]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.188226,	
2017-06-28 11:12:54,803 Epoch[3] Batch [240]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.189127,	
2017-06-28 11:12:59,542 Epoch[3] Batch [250]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.188859,	
2017-06-28 11:13:03,966 Epoch[3] Batch [260]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.189425,	
2017-06-28 11:13:08,338 Epoch[3] Batch [270]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.189266,	
2017-06-28 11:13:12,722 Epoch[3] Batch [280]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.189395,	
2017-06-28 11:13:17,191 Epoch[3] Batch [290]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.189343,	
2017-06-28 11:13:21,552 Epoch[3] Batch [300]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.189471,	
2017-06-28 11:13:26,203 Epoch[3] Batch [310]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.188976,	
2017-06-28 11:13:30,667 Epoch[3] Batch [320]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.188770,	
2017-06-28 11:13:35,483 Epoch[3] Batch [330]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.189085,	
2017-06-28 11:13:40,065 Epoch[3] Batch [340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.188455,	
2017-06-28 11:13:44,689 Epoch[3] Batch [350]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.188624,	
2017-06-28 11:13:49,291 Epoch[3] Batch [360]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.187587,	
2017-06-28 11:13:53,953 Epoch[3] Batch [370]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.186985,	
2017-06-28 11:13:58,266 Epoch[3] Batch [380]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.186297,	
2017-06-28 11:14:02,692 Epoch[3] Batch [390]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.186931,	
2017-06-28 11:14:07,224 Epoch[3] Batch [400]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.187473,	
2017-06-28 11:14:11,422 Epoch[3] Batch [410]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.187355,	
2017-06-28 11:14:16,080 Epoch[3] Batch [420]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.186918,	
2017-06-28 11:14:20,778 Epoch[3] Batch [430]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.187314,	
2017-06-28 11:14:25,480 Epoch[3] Batch [440]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.187964,	
2017-06-28 11:14:30,427 Epoch[3] Batch [450]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.187802,	
2017-06-28 11:14:34,866 Epoch[3] Batch [460]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.187918,	
2017-06-28 11:14:39,568 Epoch[3] Batch [470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.187393,	
2017-06-28 11:14:44,394 Epoch[3] Batch [480]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.187464,	
2017-06-28 11:14:48,503 Epoch[3] Batch [490]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.187144,	
2017-06-28 11:14:52,856 Epoch[3] Batch [500]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.187277,	
2017-06-28 11:14:57,405 Epoch[3] Batch [510]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.187316,	
2017-06-28 11:15:02,006 Epoch[3] Batch [520]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.187140,	
2017-06-28 11:15:06,263 Epoch[3] Batch [530]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.187387,	
2017-06-28 11:15:10,524 Epoch[3] Batch [540]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.187284,	
2017-06-28 11:15:14,789 Epoch[3] Batch [550]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.187317,	
2017-06-28 11:15:19,243 Epoch[3] Batch [560]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.187616,	
2017-06-28 11:15:23,877 Epoch[3] Batch [570]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.187292,	
2017-06-28 11:15:28,717 Epoch[3] Batch [580]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.186915,	
2017-06-28 11:15:33,301 Epoch[3] Batch [590]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.187389,	
2017-06-28 11:15:37,525 Epoch[3] Batch [600]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.187463,	
2017-06-28 11:15:42,248 Epoch[3] Batch [610]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.187117,	
2017-06-28 11:15:46,674 Epoch[3] Batch [620]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.186690,	
2017-06-28 11:15:51,223 Epoch[3] Batch [630]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.187285,	
2017-06-28 11:15:55,591 Epoch[3] Batch [640]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.187343,	
2017-06-28 11:16:00,158 Epoch[3] Batch [650]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.187280,	
2017-06-28 11:16:04,762 Epoch[3] Batch [660]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.187323,	
2017-06-28 11:16:09,317 Epoch[3] Batch [670]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.187545,	
2017-06-28 11:16:13,678 Epoch[3] Batch [680]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.187491,	
2017-06-28 11:16:18,116 Epoch[3] Batch [690]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.187351,	
2017-06-28 11:16:22,756 Epoch[3] Batch [700]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.187321,	
2017-06-28 11:16:26,962 Epoch[3] Batch [710]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.186884,	
2017-06-28 11:16:31,496 Epoch[3] Batch [720]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.186521,	
2017-06-28 11:16:35,737 Epoch[3] Batch [730]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.186081,	
2017-06-28 11:16:40,001 Epoch[3] Batch [740]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.185856,	
2017-06-28 11:16:43,935 Epoch[3] Batch [750]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.185681,	
2017-06-28 11:16:48,137 Epoch[3] Batch [760]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.185726,	
2017-06-28 11:16:52,674 Epoch[3] Batch [770]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.185948,	
2017-06-28 11:16:56,886 Epoch[3] Batch [780]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.186226,	
2017-06-28 11:17:01,116 Epoch[3] Batch [790]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.186023,	
2017-06-28 11:17:05,243 Epoch[3] Batch [800]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.185740,	
2017-06-28 11:17:09,324 Epoch[3] Batch [810]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.185419,	
2017-06-28 11:17:13,631 Epoch[3] Batch [820]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.185330,	
2017-06-28 11:17:18,006 Epoch[3] Batch [830]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.185145,	
2017-06-28 11:17:22,383 Epoch[3] Batch [840]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.185237,	
2017-06-28 11:17:26,884 Epoch[3] Batch [850]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.185288,	
2017-06-28 11:17:31,158 Epoch[3] Batch [860]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.186959,	
2017-06-28 11:17:35,443 Epoch[3] Batch [870]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.187029,	
2017-06-28 11:17:39,754 Epoch[3] Batch [880]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.187280,	
2017-06-28 11:17:43,987 Epoch[3] Batch [890]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.187341,	
2017-06-28 11:17:48,555 Epoch[3] Batch [900]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.188549,	
2017-06-28 11:17:52,860 Epoch[3] Batch [910]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.189661,	
2017-06-28 11:17:57,137 Epoch[3] Batch [920]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.189911,	
2017-06-28 11:18:01,868 Epoch[3] Batch [930]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.189972,	
2017-06-28 11:18:06,309 Epoch[3] Batch [940]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.189999,	
2017-06-28 11:18:10,736 Epoch[3] Batch [950]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.190139,	
2017-06-28 11:18:15,161 Epoch[3] Batch [960]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.189994,	
2017-06-28 11:18:19,566 Epoch[3] Batch [970]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.190229,	
2017-06-28 11:18:23,914 Epoch[3] Batch [980]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.190071,	
2017-06-28 11:18:28,006 Epoch[3] Batch [990]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.190226,	
2017-06-28 11:18:32,535 Epoch[3] Batch [1000]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.190202,	
2017-06-28 11:18:36,874 Epoch[3] Batch [1010]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.190138,	
2017-06-28 11:18:41,369 Epoch[3] Batch [1020]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.190159,	
2017-06-28 11:18:45,797 Epoch[3] Batch [1030]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.190102,	
2017-06-28 11:18:50,082 Epoch[3] Batch [1040]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.190029,	
2017-06-28 11:18:54,144 Epoch[3] Batch [1050]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.190483,	
2017-06-28 11:18:58,413 Epoch[3] Batch [1060]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.190740,	
2017-06-28 11:19:02,696 Epoch[3] Batch [1070]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.191120,	
2017-06-28 11:19:06,929 Epoch[3] Batch [1080]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.191386,	
2017-06-28 11:19:11,284 Epoch[3] Batch [1090]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.191808,	
2017-06-28 11:19:15,946 Epoch[3] Batch [1100]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.191702,	
2017-06-28 11:19:20,818 Epoch[3] Batch [1110]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.191787,	
2017-06-28 11:19:24,995 Epoch[3] Batch [1120]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.191873,	
2017-06-28 11:19:29,211 Epoch[3] Batch [1130]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.191708,	
2017-06-28 11:19:33,711 Epoch[3] Batch [1140]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.191509,	
2017-06-28 11:19:38,069 Epoch[3] Batch [1150]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.191348,	
2017-06-28 11:19:42,476 Epoch[3] Batch [1160]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.191238,	
2017-06-28 11:19:47,003 Epoch[3] Batch [1170]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.191154,	
2017-06-28 11:19:51,887 Epoch[3] Batch [1180]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.190994,	
2017-06-28 11:19:56,435 Epoch[3] Batch [1190]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.190820,	
2017-06-28 11:20:00,675 Epoch[3] Batch [1200]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.190866,	
2017-06-28 11:20:04,960 Epoch[3] Batch [1210]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.190770,	
2017-06-28 11:20:09,458 Epoch[3] Batch [1220]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.190679,	
2017-06-28 11:20:14,060 Epoch[3] Batch [1230]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.190687,	
2017-06-28 11:20:18,732 Epoch[3] Batch [1240]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.190556,	
2017-06-28 11:20:22,962 Epoch[3] Batch [1250]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.190569,	
2017-06-28 11:20:27,232 Epoch[3] Batch [1260]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.190409,	
2017-06-28 11:20:31,608 Epoch[3] Batch [1270]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.190337,	
2017-06-28 11:20:36,143 Epoch[3] Batch [1280]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.190062,	
2017-06-28 11:20:40,945 Epoch[3] Batch [1290]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.189840,	
2017-06-28 11:20:45,582 Epoch[3] Batch [1300]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.190029,	
2017-06-28 11:20:50,419 Epoch[3] Batch [1310]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.189846,	
2017-06-28 11:20:54,792 Epoch[3] Batch [1320]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.189781,	
2017-06-28 11:20:59,300 Epoch[3] Batch [1330]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.189708,	
2017-06-28 11:21:03,983 Epoch[3] Batch [1340]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.189572,	
2017-06-28 11:21:08,350 Epoch[3] Batch [1350]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.189639,	
2017-06-28 11:21:13,001 Epoch[3] Batch [1360]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.189686,	
2017-06-28 11:21:17,350 Epoch[3] Batch [1370]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.189608,	
2017-06-28 11:21:22,110 Epoch[3] Batch [1380]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.189456,	
2017-06-28 11:21:26,672 Epoch[3] Batch [1390]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.189426,	
2017-06-28 11:21:31,023 Epoch[3] Batch [1400]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.189291,	
2017-06-28 11:21:35,378 Epoch[3] Batch [1410]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.189300,	
2017-06-28 11:21:39,740 Epoch[3] Batch [1420]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.189302,	
2017-06-28 11:21:44,176 Epoch[3] Batch [1430]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.189163,	
2017-06-28 11:21:48,806 Epoch[3] Batch [1440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.188942,	
2017-06-28 11:21:53,426 Epoch[3] Batch [1450]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.188918,	
2017-06-28 11:21:58,332 Epoch[3] Batch [1460]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.188531,	
2017-06-28 11:22:02,790 Epoch[3] Batch [1470]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.188397,	
2017-06-28 11:22:07,638 Epoch[3] Batch [1480]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.188214,	
2017-06-28 11:22:10,367 Epoch[3] Train-FCNLogLoss=0.188104
2017-06-28 11:22:10,368 Epoch[3] Time cost=666.157
2017-06-28 11:22:11,046 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0004.params"
2017-06-28 11:22:12,579 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0004.states"
2017-06-28 11:22:17,744 Epoch[4] Batch [10]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.160258,	
2017-06-28 11:22:22,239 Epoch[4] Batch [20]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.177363,	
2017-06-28 11:22:26,681 Epoch[4] Batch [30]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.173571,	
2017-06-28 11:22:31,146 Epoch[4] Batch [40]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.176009,	
2017-06-28 11:22:35,430 Epoch[4] Batch [50]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.174621,	
2017-06-28 11:22:39,871 Epoch[4] Batch [60]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.173645,	
2017-06-28 11:22:44,104 Epoch[4] Batch [70]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.177451,	
2017-06-28 11:22:48,349 Epoch[4] Batch [80]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.178793,	
2017-06-28 11:22:52,364 Epoch[4] Batch [90]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.177056,	
2017-06-28 11:22:56,593 Epoch[4] Batch [100]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.176992,	
2017-06-28 11:23:00,964 Epoch[4] Batch [110]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.177818,	
2017-06-28 11:23:05,380 Epoch[4] Batch [120]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.180529,	
2017-06-28 11:23:09,602 Epoch[4] Batch [130]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.180652,	
2017-06-28 11:23:13,602 Epoch[4] Batch [140]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.180565,	
2017-06-28 11:23:17,752 Epoch[4] Batch [150]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.180895,	
2017-06-28 11:23:21,862 Epoch[4] Batch [160]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.180111,	
2017-06-28 11:23:26,361 Epoch[4] Batch [170]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.178769,	
2017-06-28 11:23:30,544 Epoch[4] Batch [180]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.177862,	
2017-06-28 11:23:34,550 Epoch[4] Batch [190]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.177545,	
2017-06-28 11:23:38,667 Epoch[4] Batch [200]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.177526,	
2017-06-28 11:23:42,933 Epoch[4] Batch [210]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.177258,	
2017-06-28 11:23:47,390 Epoch[4] Batch [220]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.177999,	
2017-06-28 11:23:51,791 Epoch[4] Batch [230]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.177047,	
2017-06-28 11:23:56,067 Epoch[4] Batch [240]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.176835,	
2017-06-28 11:24:00,434 Epoch[4] Batch [250]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.176501,	
2017-06-28 11:24:04,624 Epoch[4] Batch [260]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.175867,	
2017-06-28 11:24:08,869 Epoch[4] Batch [270]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.176243,	
2017-06-28 11:24:13,016 Epoch[4] Batch [280]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.176956,	
2017-06-28 11:24:17,447 Epoch[4] Batch [290]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.177030,	
2017-06-28 11:24:21,668 Epoch[4] Batch [300]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.177118,	
2017-06-28 11:24:25,632 Epoch[4] Batch [310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.177088,	
2017-06-28 11:24:29,782 Epoch[4] Batch [320]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.177014,	
2017-06-28 11:24:33,802 Epoch[4] Batch [330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.176793,	
2017-06-28 11:24:38,091 Epoch[4] Batch [340]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.176656,	
2017-06-28 11:24:42,302 Epoch[4] Batch [350]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.176046,	
2017-06-28 11:24:46,551 Epoch[4] Batch [360]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.175234,	
2017-06-28 11:24:50,993 Epoch[4] Batch [370]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.176109,	
2017-06-28 11:24:55,167 Epoch[4] Batch [380]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.177453,	
2017-06-28 11:24:59,578 Epoch[4] Batch [390]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.178194,	
2017-06-28 11:25:04,105 Epoch[4] Batch [400]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.179219,	
2017-06-28 11:25:08,564 Epoch[4] Batch [410]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.179417,	
2017-06-28 11:25:12,723 Epoch[4] Batch [420]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.179501,	
2017-06-28 11:25:16,753 Epoch[4] Batch [430]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.179459,	
2017-06-28 11:25:20,936 Epoch[4] Batch [440]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.179315,	
2017-06-28 11:25:25,173 Epoch[4] Batch [450]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.179383,	
2017-06-28 11:25:29,368 Epoch[4] Batch [460]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.180389,	
2017-06-28 11:25:33,699 Epoch[4] Batch [470]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.180517,	
2017-06-28 11:25:37,952 Epoch[4] Batch [480]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.180606,	
2017-06-28 11:25:42,235 Epoch[4] Batch [490]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.180065,	
2017-06-28 11:25:46,476 Epoch[4] Batch [500]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.180017,	
2017-06-28 11:25:50,875 Epoch[4] Batch [510]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.179784,	
2017-06-28 11:25:54,940 Epoch[4] Batch [520]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.179652,	
2017-06-28 11:25:59,132 Epoch[4] Batch [530]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.179394,	
2017-06-28 11:26:03,194 Epoch[4] Batch [540]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.179409,	
2017-06-28 11:26:07,494 Epoch[4] Batch [550]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.179508,	
2017-06-28 11:26:11,865 Epoch[4] Batch [560]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.179484,	
2017-06-28 11:26:15,962 Epoch[4] Batch [570]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.179656,	
2017-06-28 11:26:19,935 Epoch[4] Batch [580]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.179766,	
2017-06-28 11:26:24,007 Epoch[4] Batch [590]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.180060,	
2017-06-28 11:26:28,013 Epoch[4] Batch [600]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.179717,	
2017-06-28 11:26:32,296 Epoch[4] Batch [610]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.179917,	
2017-06-28 11:26:36,436 Epoch[4] Batch [620]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.181336,	
2017-06-28 11:26:40,579 Epoch[4] Batch [630]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.181465,	
2017-06-28 11:26:44,694 Epoch[4] Batch [640]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.181350,	
2017-06-28 11:26:49,050 Epoch[4] Batch [650]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.181205,	
2017-06-28 11:26:53,342 Epoch[4] Batch [660]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.180923,	
2017-06-28 11:26:57,727 Epoch[4] Batch [670]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.180549,	
2017-06-28 11:27:01,905 Epoch[4] Batch [680]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.180469,	
2017-06-28 11:27:06,180 Epoch[4] Batch [690]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.180536,	
2017-06-28 11:27:10,648 Epoch[4] Batch [700]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.180429,	
2017-06-28 11:27:14,823 Epoch[4] Batch [710]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.180152,	
2017-06-28 11:27:19,137 Epoch[4] Batch [720]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.180123,	
2017-06-28 11:27:23,202 Epoch[4] Batch [730]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.180205,	
2017-06-28 11:27:27,464 Epoch[4] Batch [740]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.180063,	
2017-06-28 11:27:31,544 Epoch[4] Batch [750]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.179895,	
2017-06-28 11:27:35,947 Epoch[4] Batch [760]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.179889,	
2017-06-28 11:27:40,217 Epoch[4] Batch [770]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.179512,	
2017-06-28 11:27:44,517 Epoch[4] Batch [780]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.179592,	
2017-06-28 11:27:48,799 Epoch[4] Batch [790]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.179052,	
2017-06-28 11:27:53,118 Epoch[4] Batch [800]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.179069,	
2017-06-28 11:27:57,184 Epoch[4] Batch [810]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.179450,	
2017-06-28 11:28:01,301 Epoch[4] Batch [820]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.179593,	
2017-06-28 11:28:05,423 Epoch[4] Batch [830]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.179646,	
2017-06-28 11:28:09,440 Epoch[4] Batch [840]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.179807,	
2017-06-28 11:28:13,503 Epoch[4] Batch [850]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.180505,	
2017-06-28 11:28:17,746 Epoch[4] Batch [860]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.180875,	
2017-06-28 11:28:21,838 Epoch[4] Batch [870]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.180838,	
2017-06-28 11:28:26,058 Epoch[4] Batch [880]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.180924,	
2017-06-28 11:28:30,143 Epoch[4] Batch [890]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.180921,	
2017-06-28 11:28:34,362 Epoch[4] Batch [900]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.180723,	
2017-06-28 11:28:38,711 Epoch[4] Batch [910]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.180575,	
2017-06-28 11:28:42,898 Epoch[4] Batch [920]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.180278,	
2017-06-28 11:28:47,086 Epoch[4] Batch [930]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.179802,	
2017-06-28 11:28:51,402 Epoch[4] Batch [940]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.179424,	
2017-06-28 11:28:56,285 Epoch[4] Batch [950]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.179583,	
2017-06-28 11:29:00,662 Epoch[4] Batch [960]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.180047,	
2017-06-28 11:29:04,937 Epoch[4] Batch [970]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.180034,	
2017-06-28 11:29:09,448 Epoch[4] Batch [980]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.179982,	
2017-06-28 11:29:13,509 Epoch[4] Batch [990]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.180298,	
2017-06-28 11:29:18,263 Epoch[4] Batch [1000]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.180414,	
2017-06-28 11:29:22,755 Epoch[4] Batch [1010]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.180529,	
2017-06-28 11:29:27,373 Epoch[4] Batch [1020]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.180419,	
2017-06-28 11:29:32,120 Epoch[4] Batch [1030]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.180137,	
2017-06-28 11:29:36,345 Epoch[4] Batch [1040]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.179947,	
2017-06-28 11:29:40,566 Epoch[4] Batch [1050]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.179789,	
2017-06-28 11:29:45,003 Epoch[4] Batch [1060]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.179731,	
2017-06-28 11:29:49,291 Epoch[4] Batch [1070]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.179418,	
2017-06-28 11:29:53,840 Epoch[4] Batch [1080]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.179356,	
2017-06-28 11:29:58,564 Epoch[4] Batch [1090]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.179269,	
2017-06-28 11:30:03,101 Epoch[4] Batch [1100]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.179350,	
2017-06-28 11:30:07,323 Epoch[4] Batch [1110]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.179242,	
2017-06-28 11:30:11,766 Epoch[4] Batch [1120]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.179171,	
2017-06-28 11:30:16,529 Epoch[4] Batch [1130]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.179061,	
2017-06-28 11:30:20,885 Epoch[4] Batch [1140]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.179257,	
2017-06-28 11:30:25,400 Epoch[4] Batch [1150]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.179515,	
2017-06-28 11:30:29,825 Epoch[4] Batch [1160]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.179318,	
2017-06-28 11:30:34,137 Epoch[4] Batch [1170]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.179238,	
2017-06-28 11:30:38,511 Epoch[4] Batch [1180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.179204,	
2017-06-28 11:30:42,829 Epoch[4] Batch [1190]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.179271,	
2017-06-28 11:30:47,261 Epoch[4] Batch [1200]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.179530,	
2017-06-28 11:30:51,328 Epoch[4] Batch [1210]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.179217,	
2017-06-28 11:30:55,567 Epoch[4] Batch [1220]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.179151,	
2017-06-28 11:30:59,832 Epoch[4] Batch [1230]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.179003,	
2017-06-28 11:31:04,649 Epoch[4] Batch [1240]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.178921,	
2017-06-28 11:31:09,413 Epoch[4] Batch [1250]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.179105,	
2017-06-28 11:31:13,901 Epoch[4] Batch [1260]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.178879,	
2017-06-28 11:31:18,445 Epoch[4] Batch [1270]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.178951,	
2017-06-28 11:31:22,760 Epoch[4] Batch [1280]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.178800,	
2017-06-28 11:31:27,134 Epoch[4] Batch [1290]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.178700,	
2017-06-28 11:31:31,566 Epoch[4] Batch [1300]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.178513,	
2017-06-28 11:31:36,081 Epoch[4] Batch [1310]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.178462,	
2017-06-28 11:31:40,570 Epoch[4] Batch [1320]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.178475,	
2017-06-28 11:31:45,022 Epoch[4] Batch [1330]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.178652,	
2017-06-28 11:31:49,447 Epoch[4] Batch [1340]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.178594,	
2017-06-28 11:31:53,766 Epoch[4] Batch [1350]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.178759,	
2017-06-28 11:31:57,981 Epoch[4] Batch [1360]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.178547,	
2017-06-28 11:32:02,072 Epoch[4] Batch [1370]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.178532,	
2017-06-28 11:32:06,547 Epoch[4] Batch [1380]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.178530,	
2017-06-28 11:32:10,790 Epoch[4] Batch [1390]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.178465,	
2017-06-28 11:32:15,111 Epoch[4] Batch [1400]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.178339,	
2017-06-28 11:32:19,495 Epoch[4] Batch [1410]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.178264,	
2017-06-28 11:32:23,742 Epoch[4] Batch [1420]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.178337,	
2017-06-28 11:32:27,929 Epoch[4] Batch [1430]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.178521,	
2017-06-28 11:32:32,262 Epoch[4] Batch [1440]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.178464,	
2017-06-28 11:32:36,617 Epoch[4] Batch [1450]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.178318,	
2017-06-28 11:32:40,778 Epoch[4] Batch [1460]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.178348,	
2017-06-28 11:32:45,162 Epoch[4] Batch [1470]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.178548,	
2017-06-28 11:32:49,223 Epoch[4] Batch [1480]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.178541,	
2017-06-28 11:32:51,632 Epoch[4] Train-FCNLogLoss=0.178469
2017-06-28 11:32:51,632 Epoch[4] Time cost=639.053
2017-06-28 11:32:52,332 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0005.params"
2017-06-28 11:32:53,953 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0005.states"
2017-06-28 11:32:58,789 Epoch[5] Batch [10]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.167643,	
2017-06-28 11:33:02,937 Epoch[5] Batch [20]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.168685,	
2017-06-28 11:33:06,991 Epoch[5] Batch [30]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.169780,	
2017-06-28 11:33:11,282 Epoch[5] Batch [40]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.168803,	
2017-06-28 11:33:15,571 Epoch[5] Batch [50]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.168773,	
2017-06-28 11:33:19,658 Epoch[5] Batch [60]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.167179,	
2017-06-28 11:33:24,230 Epoch[5] Batch [70]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.167914,	
2017-06-28 11:33:28,468 Epoch[5] Batch [80]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.167818,	
2017-06-28 11:33:32,859 Epoch[5] Batch [90]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.167607,	
2017-06-28 11:33:37,093 Epoch[5] Batch [100]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.169513,	
2017-06-28 11:33:41,311 Epoch[5] Batch [110]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.168898,	
2017-06-28 11:33:45,732 Epoch[5] Batch [120]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.167050,	
2017-06-28 11:33:50,268 Epoch[5] Batch [130]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.165575,	
2017-06-28 11:33:54,531 Epoch[5] Batch [140]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.165741,	
2017-06-28 11:33:58,692 Epoch[5] Batch [150]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.164177,	
2017-06-28 11:34:03,173 Epoch[5] Batch [160]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.163299,	
2017-06-28 11:34:07,286 Epoch[5] Batch [170]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.164293,	
2017-06-28 11:34:11,373 Epoch[5] Batch [180]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.163639,	
2017-06-28 11:34:15,460 Epoch[5] Batch [190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.164007,	
2017-06-28 11:34:19,521 Epoch[5] Batch [200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.163868,	
2017-06-28 11:34:23,610 Epoch[5] Batch [210]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.164087,	
2017-06-28 11:34:27,670 Epoch[5] Batch [220]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.164124,	
2017-06-28 11:34:31,767 Epoch[5] Batch [230]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.164166,	
2017-06-28 11:34:36,162 Epoch[5] Batch [240]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.163702,	
2017-06-28 11:34:40,271 Epoch[5] Batch [250]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.163576,	
2017-06-28 11:34:44,710 Epoch[5] Batch [260]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.163671,	
2017-06-28 11:34:49,000 Epoch[5] Batch [270]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.163669,	
2017-06-28 11:34:53,335 Epoch[5] Batch [280]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.163337,	
2017-06-28 11:34:57,683 Epoch[5] Batch [290]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.163202,	
2017-06-28 11:35:02,162 Epoch[5] Batch [300]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.162482,	
2017-06-28 11:35:06,982 Epoch[5] Batch [310]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.161714,	
2017-06-28 11:35:11,832 Epoch[5] Batch [320]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.161565,	
2017-06-28 11:35:16,903 Epoch[5] Batch [330]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.161481,	
2017-06-28 11:35:21,566 Epoch[5] Batch [340]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.161019,	
2017-06-28 11:35:25,750 Epoch[5] Batch [350]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.160845,	
2017-06-28 11:35:30,437 Epoch[5] Batch [360]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.160367,	
2017-06-28 11:35:35,010 Epoch[5] Batch [370]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.160502,	
2017-06-28 11:35:39,592 Epoch[5] Batch [380]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.160691,	
2017-06-28 11:35:43,965 Epoch[5] Batch [390]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.161286,	
2017-06-28 11:35:48,433 Epoch[5] Batch [400]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.161184,	
2017-06-28 11:35:52,678 Epoch[5] Batch [410]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.160608,	
2017-06-28 11:35:57,628 Epoch[5] Batch [420]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.160680,	
2017-06-28 11:36:02,337 Epoch[5] Batch [430]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.160949,	
2017-06-28 11:36:06,638 Epoch[5] Batch [440]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.160475,	
2017-06-28 11:36:11,226 Epoch[5] Batch [450]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.160206,	
2017-06-28 11:36:15,525 Epoch[5] Batch [460]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.159804,	
2017-06-28 11:36:20,284 Epoch[5] Batch [470]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.159453,	
2017-06-28 11:36:24,628 Epoch[5] Batch [480]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.159246,	
2017-06-28 11:36:29,157 Epoch[5] Batch [490]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.159704,	
2017-06-28 11:36:33,483 Epoch[5] Batch [500]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.159870,	
2017-06-28 11:36:37,835 Epoch[5] Batch [510]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.159677,	
2017-06-28 11:36:42,121 Epoch[5] Batch [520]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.159973,	
2017-06-28 11:36:46,454 Epoch[5] Batch [530]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.160256,	
2017-06-28 11:36:50,735 Epoch[5] Batch [540]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.159829,	
2017-06-28 11:36:55,373 Epoch[5] Batch [550]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.159740,	
2017-06-28 11:36:59,862 Epoch[5] Batch [560]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.159829,	
2017-06-28 11:37:04,241 Epoch[5] Batch [570]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.159715,	
2017-06-28 11:37:08,632 Epoch[5] Batch [580]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.159869,	
2017-06-28 11:37:12,806 Epoch[5] Batch [590]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.161283,	
2017-06-28 11:37:17,332 Epoch[5] Batch [600]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.163078,	
2017-06-28 11:37:21,777 Epoch[5] Batch [610]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.163333,	
2017-06-28 11:37:26,006 Epoch[5] Batch [620]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.163472,	
2017-06-28 11:37:30,261 Epoch[5] Batch [630]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.163762,	
2017-06-28 11:37:34,581 Epoch[5] Batch [640]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.164428,	
2017-06-28 11:37:38,908 Epoch[5] Batch [650]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.164603,	
2017-06-28 11:37:43,290 Epoch[5] Batch [660]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.164817,	
2017-06-28 11:37:47,710 Epoch[5] Batch [670]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.164584,	
2017-06-28 11:37:52,058 Epoch[5] Batch [680]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.164449,	
2017-06-28 11:37:56,619 Epoch[5] Batch [690]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.164376,	
2017-06-28 11:38:00,973 Epoch[5] Batch [700]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.163915,	
2017-06-28 11:38:05,448 Epoch[5] Batch [710]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.163918,	
2017-06-28 11:38:09,749 Epoch[5] Batch [720]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.163786,	
2017-06-28 11:38:14,272 Epoch[5] Batch [730]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.163735,	
2017-06-28 11:38:18,615 Epoch[5] Batch [740]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.164383,	
2017-06-28 11:38:23,334 Epoch[5] Batch [750]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.164459,	
2017-06-28 11:38:27,953 Epoch[5] Batch [760]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.164598,	
2017-06-28 11:38:32,551 Epoch[5] Batch [770]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.165065,	
2017-06-28 11:38:37,372 Epoch[5] Batch [780]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.164846,	
2017-06-28 11:38:41,946 Epoch[5] Batch [790]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.164768,	
2017-06-28 11:38:46,382 Epoch[5] Batch [800]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.164841,	
2017-06-28 11:38:50,683 Epoch[5] Batch [810]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.164654,	
2017-06-28 11:38:54,834 Epoch[5] Batch [820]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.164554,	
2017-06-28 11:38:59,344 Epoch[5] Batch [830]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.164745,	
2017-06-28 11:39:03,733 Epoch[5] Batch [840]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.165024,	
2017-06-28 11:39:08,327 Epoch[5] Batch [850]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.165128,	
2017-06-28 11:39:12,820 Epoch[5] Batch [860]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.165325,	
2017-06-28 11:39:17,519 Epoch[5] Batch [870]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.165424,	
2017-06-28 11:39:22,075 Epoch[5] Batch [880]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.165046,	
2017-06-28 11:39:26,538 Epoch[5] Batch [890]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.164736,	
2017-06-28 11:39:30,596 Epoch[5] Batch [900]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.164466,	
2017-06-28 11:39:34,909 Epoch[5] Batch [910]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.164260,	
2017-06-28 11:39:39,006 Epoch[5] Batch [920]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.164395,	
2017-06-28 11:39:43,411 Epoch[5] Batch [930]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.164226,	
2017-06-28 11:39:47,716 Epoch[5] Batch [940]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.164210,	
2017-06-28 11:39:52,233 Epoch[5] Batch [950]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.164166,	
2017-06-28 11:39:56,775 Epoch[5] Batch [960]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.164164,	
2017-06-28 11:40:01,342 Epoch[5] Batch [970]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.163948,	
2017-06-28 11:40:05,986 Epoch[5] Batch [980]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.164132,	
2017-06-28 11:40:10,502 Epoch[5] Batch [990]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.163954,	
2017-06-28 11:40:15,320 Epoch[5] Batch [1000]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.163801,	
2017-06-28 11:40:20,481 Epoch[5] Batch [1010]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.164345,	
2017-06-28 11:40:25,318 Epoch[5] Batch [1020]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.164269,	
2017-06-28 11:40:29,751 Epoch[5] Batch [1030]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.164221,	
2017-06-28 11:40:34,537 Epoch[5] Batch [1040]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.164011,	
2017-06-28 11:40:39,021 Epoch[5] Batch [1050]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.164289,	
2017-06-28 11:40:43,958 Epoch[5] Batch [1060]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.164613,	
2017-06-28 11:40:48,809 Epoch[5] Batch [1070]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.164750,	
2017-06-28 11:40:53,219 Epoch[5] Batch [1080]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.164636,	
2017-06-28 11:40:57,442 Epoch[5] Batch [1090]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.164608,	
2017-06-28 11:41:01,822 Epoch[5] Batch [1100]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.164649,	
2017-06-28 11:41:05,934 Epoch[5] Batch [1110]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.164635,	
2017-06-28 11:41:10,300 Epoch[5] Batch [1120]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.164553,	
2017-06-28 11:41:14,987 Epoch[5] Batch [1130]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.164718,	
2017-06-28 11:41:19,442 Epoch[5] Batch [1140]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.164462,	
2017-06-28 11:41:23,998 Epoch[5] Batch [1150]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.164351,	
2017-06-28 11:41:28,348 Epoch[5] Batch [1160]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.164379,	
2017-06-28 11:41:32,948 Epoch[5] Batch [1170]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.164392,	
2017-06-28 11:41:37,371 Epoch[5] Batch [1180]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.164368,	
2017-06-28 11:41:41,687 Epoch[5] Batch [1190]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.164290,	
2017-06-28 11:41:46,411 Epoch[5] Batch [1200]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.164280,	
2017-06-28 11:41:50,766 Epoch[5] Batch [1210]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.164281,	
2017-06-28 11:41:55,002 Epoch[5] Batch [1220]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.164225,	
2017-06-28 11:41:59,335 Epoch[5] Batch [1230]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.164114,	
2017-06-28 11:42:03,945 Epoch[5] Batch [1240]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.164020,	
2017-06-28 11:42:08,529 Epoch[5] Batch [1250]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.164041,	
2017-06-28 11:42:12,949 Epoch[5] Batch [1260]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.164037,	
2017-06-28 11:42:17,115 Epoch[5] Batch [1270]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.163849,	
2017-06-28 11:42:21,691 Epoch[5] Batch [1280]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.163884,	
2017-06-28 11:42:26,280 Epoch[5] Batch [1290]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.163766,	
2017-06-28 11:42:30,629 Epoch[5] Batch [1300]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.164120,	
2017-06-28 11:42:35,292 Epoch[5] Batch [1310]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.164217,	
2017-06-28 11:42:39,712 Epoch[5] Batch [1320]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.164341,	
2017-06-28 11:42:43,987 Epoch[5] Batch [1330]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.164425,	
2017-06-28 11:42:48,478 Epoch[5] Batch [1340]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.164407,	
2017-06-28 11:42:53,139 Epoch[5] Batch [1350]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.164390,	
2017-06-28 11:42:57,783 Epoch[5] Batch [1360]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.164759,	
2017-06-28 11:43:02,330 Epoch[5] Batch [1370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.164658,	
2017-06-28 11:43:06,738 Epoch[5] Batch [1380]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.164632,	
2017-06-28 11:43:11,224 Epoch[5] Batch [1390]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.164640,	
2017-06-28 11:43:15,683 Epoch[5] Batch [1400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.164620,	
2017-06-28 11:43:20,336 Epoch[5] Batch [1410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.164515,	
2017-06-28 11:43:25,052 Epoch[5] Batch [1420]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.164516,	
2017-06-28 11:43:29,935 Epoch[5] Batch [1430]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.164374,	
2017-06-28 11:43:34,214 Epoch[5] Batch [1440]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.164342,	
2017-06-28 11:43:38,571 Epoch[5] Batch [1450]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.164382,	
2017-06-28 11:43:43,326 Epoch[5] Batch [1460]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.164496,	
2017-06-28 11:43:47,517 Epoch[5] Batch [1470]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.164420,	
2017-06-28 11:43:51,771 Epoch[5] Batch [1480]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.164395,	
2017-06-28 11:43:54,252 Epoch[5] Train-FCNLogLoss=0.164554
2017-06-28 11:43:54,252 Epoch[5] Time cost=660.299
2017-06-28 11:43:55,045 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0006.params"
2017-06-28 11:43:56,722 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0006.states"
2017-06-28 11:44:01,904 Epoch[6] Batch [10]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.157171,	
2017-06-28 11:44:06,040 Epoch[6] Batch [20]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.167013,	
2017-06-28 11:44:10,378 Epoch[6] Batch [30]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.174205,	
2017-06-28 11:44:14,861 Epoch[6] Batch [40]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.169048,	
2017-06-28 11:44:19,350 Epoch[6] Batch [50]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.167747,	
2017-06-28 11:44:23,750 Epoch[6] Batch [60]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.167811,	
2017-06-28 11:44:28,477 Epoch[6] Batch [70]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.166521,	
2017-06-28 11:44:33,056 Epoch[6] Batch [80]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.166766,	
2017-06-28 11:44:37,355 Epoch[6] Batch [90]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.164435,	
2017-06-28 11:44:41,963 Epoch[6] Batch [100]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.161009,	
2017-06-28 11:44:46,316 Epoch[6] Batch [110]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.161214,	
2017-06-28 11:44:50,752 Epoch[6] Batch [120]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.160608,	
2017-06-28 11:44:55,122 Epoch[6] Batch [130]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.161588,	
2017-06-28 11:44:59,533 Epoch[6] Batch [140]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.160503,	
2017-06-28 11:45:03,777 Epoch[6] Batch [150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.160868,	
2017-06-28 11:45:08,178 Epoch[6] Batch [160]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.162170,	
2017-06-28 11:45:12,923 Epoch[6] Batch [170]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.163089,	
2017-06-28 11:45:17,209 Epoch[6] Batch [180]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.163466,	
2017-06-28 11:45:21,888 Epoch[6] Batch [190]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.164261,	
2017-06-28 11:45:26,216 Epoch[6] Batch [200]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.163159,	
2017-06-28 11:45:30,725 Epoch[6] Batch [210]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.164776,	
2017-06-28 11:45:35,543 Epoch[6] Batch [220]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.164838,	
2017-06-28 11:45:40,490 Epoch[6] Batch [230]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.164565,	
2017-06-28 11:45:45,337 Epoch[6] Batch [240]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.164463,	
2017-06-28 11:45:49,853 Epoch[6] Batch [250]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.164189,	
2017-06-28 11:45:54,265 Epoch[6] Batch [260]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.163760,	
2017-06-28 11:45:58,888 Epoch[6] Batch [270]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.162979,	
2017-06-28 11:46:03,506 Epoch[6] Batch [280]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.162616,	
2017-06-28 11:46:08,018 Epoch[6] Batch [290]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.162324,	
2017-06-28 11:46:12,170 Epoch[6] Batch [300]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.161158,	
2017-06-28 11:46:16,332 Epoch[6] Batch [310]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.161018,	
2017-06-28 11:46:21,232 Epoch[6] Batch [320]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.160369,	
2017-06-28 11:46:25,811 Epoch[6] Batch [330]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.161001,	
2017-06-28 11:46:30,220 Epoch[6] Batch [340]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.160835,	
2017-06-28 11:46:34,687 Epoch[6] Batch [350]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.160499,	
2017-06-28 11:46:39,137 Epoch[6] Batch [360]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.161026,	
2017-06-28 11:46:43,916 Epoch[6] Batch [370]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.160428,	
2017-06-28 11:46:48,754 Epoch[6] Batch [380]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.160453,	
2017-06-28 11:46:53,273 Epoch[6] Batch [390]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.160839,	
2017-06-28 11:46:57,588 Epoch[6] Batch [400]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.162440,	
2017-06-28 11:47:01,887 Epoch[6] Batch [410]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.162594,	
2017-06-28 11:47:06,389 Epoch[6] Batch [420]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.162514,	
2017-06-28 11:47:10,792 Epoch[6] Batch [430]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.162489,	
2017-06-28 11:47:15,212 Epoch[6] Batch [440]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.162221,	
2017-06-28 11:47:19,420 Epoch[6] Batch [450]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.161629,	
2017-06-28 11:47:23,612 Epoch[6] Batch [460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.161349,	
2017-06-28 11:47:27,800 Epoch[6] Batch [470]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.161431,	
2017-06-28 11:47:32,245 Epoch[6] Batch [480]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.161611,	
2017-06-28 11:47:36,418 Epoch[6] Batch [490]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.161262,	
2017-06-28 11:47:40,799 Epoch[6] Batch [500]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.161111,	
2017-06-28 11:47:45,090 Epoch[6] Batch [510]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.160948,	
2017-06-28 11:47:49,719 Epoch[6] Batch [520]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.160777,	
2017-06-28 11:47:54,724 Epoch[6] Batch [530]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.160602,	
2017-06-28 11:47:59,211 Epoch[6] Batch [540]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.160168,	
2017-06-28 11:48:03,702 Epoch[6] Batch [550]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.160360,	
2017-06-28 11:48:08,213 Epoch[6] Batch [560]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.160140,	
2017-06-28 11:48:12,479 Epoch[6] Batch [570]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.160485,	
2017-06-28 11:48:16,990 Epoch[6] Batch [580]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.160556,	
2017-06-28 11:48:21,192 Epoch[6] Batch [590]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.160898,	
2017-06-28 11:48:25,581 Epoch[6] Batch [600]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.161519,	
2017-06-28 11:48:30,075 Epoch[6] Batch [610]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.161509,	
2017-06-28 11:48:34,478 Epoch[6] Batch [620]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.161582,	
2017-06-28 11:48:38,705 Epoch[6] Batch [630]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.161760,	
2017-06-28 11:48:43,027 Epoch[6] Batch [640]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.161945,	
2017-06-28 11:48:47,232 Epoch[6] Batch [650]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.161987,	
2017-06-28 11:48:51,670 Epoch[6] Batch [660]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.162130,	
2017-06-28 11:48:56,392 Epoch[6] Batch [670]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.162062,	
2017-06-28 11:49:00,927 Epoch[6] Batch [680]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.162150,	
2017-06-28 11:49:05,854 Epoch[6] Batch [690]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.161996,	
2017-06-28 11:49:10,307 Epoch[6] Batch [700]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.161982,	
2017-06-28 11:49:14,622 Epoch[6] Batch [710]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.162033,	
2017-06-28 11:49:19,397 Epoch[6] Batch [720]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.161919,	
2017-06-28 11:49:23,860 Epoch[6] Batch [730]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.161781,	
2017-06-28 11:49:28,751 Epoch[6] Batch [740]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.161744,	
2017-06-28 11:49:33,318 Epoch[6] Batch [750]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.161958,	
2017-06-28 11:49:37,561 Epoch[6] Batch [760]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.162003,	
2017-06-28 11:49:41,945 Epoch[6] Batch [770]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.162160,	
2017-06-28 11:49:46,440 Epoch[6] Batch [780]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.162370,	
2017-06-28 11:49:50,766 Epoch[6] Batch [790]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.162267,	
2017-06-28 11:49:55,365 Epoch[6] Batch [800]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.161960,	
2017-06-28 11:50:00,160 Epoch[6] Batch [810]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.162198,	
2017-06-28 11:50:04,394 Epoch[6] Batch [820]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.162225,	
2017-06-28 11:50:08,711 Epoch[6] Batch [830]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.161931,	
2017-06-28 11:50:13,177 Epoch[6] Batch [840]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.161918,	
2017-06-28 11:50:17,548 Epoch[6] Batch [850]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.161758,	
2017-06-28 11:50:22,003 Epoch[6] Batch [860]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.161880,	
2017-06-28 11:50:26,463 Epoch[6] Batch [870]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.161711,	
2017-06-28 11:50:30,917 Epoch[6] Batch [880]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.161723,	
2017-06-28 11:50:35,307 Epoch[6] Batch [890]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.161544,	
2017-06-28 11:50:39,972 Epoch[6] Batch [900]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.161678,	
2017-06-28 11:50:44,086 Epoch[6] Batch [910]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.161638,	
2017-06-28 11:50:48,930 Epoch[6] Batch [920]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.161935,	
2017-06-28 11:50:53,461 Epoch[6] Batch [930]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.161999,	
2017-06-28 11:50:57,754 Epoch[6] Batch [940]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.161780,	
2017-06-28 11:51:02,110 Epoch[6] Batch [950]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.161887,	
2017-06-28 11:51:06,316 Epoch[6] Batch [960]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.161770,	
2017-06-28 11:51:10,815 Epoch[6] Batch [970]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.161543,	
2017-06-28 11:51:15,351 Epoch[6] Batch [980]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.161242,	
2017-06-28 11:51:19,613 Epoch[6] Batch [990]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.161067,	
2017-06-28 11:51:24,274 Epoch[6] Batch [1000]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.161055,	
2017-06-28 11:51:28,787 Epoch[6] Batch [1010]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.160884,	
2017-06-28 11:51:33,220 Epoch[6] Batch [1020]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.160996,	
2017-06-28 11:51:37,899 Epoch[6] Batch [1030]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.161002,	
2017-06-28 11:51:42,377 Epoch[6] Batch [1040]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.160744,	
2017-06-28 11:51:46,876 Epoch[6] Batch [1050]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.160580,	
2017-06-28 11:51:51,474 Epoch[6] Batch [1060]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.160701,	
2017-06-28 11:51:55,981 Epoch[6] Batch [1070]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.160578,	
2017-06-28 11:52:00,428 Epoch[6] Batch [1080]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.160330,	
2017-06-28 11:52:04,859 Epoch[6] Batch [1090]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.160249,	
2017-06-28 11:52:09,744 Epoch[6] Batch [1100]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.160109,	
2017-06-28 11:52:14,770 Epoch[6] Batch [1110]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.159986,	
2017-06-28 11:52:19,088 Epoch[6] Batch [1120]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.159752,	
2017-06-28 11:52:23,323 Epoch[6] Batch [1130]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.159605,	
2017-06-28 11:52:27,773 Epoch[6] Batch [1140]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.159588,	
2017-06-28 11:52:32,505 Epoch[6] Batch [1150]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.159446,	
2017-06-28 11:52:36,909 Epoch[6] Batch [1160]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.159473,	
2017-06-28 11:52:41,241 Epoch[6] Batch [1170]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.159406,	
2017-06-28 11:52:45,690 Epoch[6] Batch [1180]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.159388,	
2017-06-28 11:52:50,454 Epoch[6] Batch [1190]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.159508,	
2017-06-28 11:52:54,582 Epoch[6] Batch [1200]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.159592,	
2017-06-28 11:52:58,945 Epoch[6] Batch [1210]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.159526,	
2017-06-28 11:53:03,633 Epoch[6] Batch [1220]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.159392,	
2017-06-28 11:53:08,317 Epoch[6] Batch [1230]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.159188,	
2017-06-28 11:53:12,669 Epoch[6] Batch [1240]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.159015,	
2017-06-28 11:53:17,302 Epoch[6] Batch [1250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.158897,	
2017-06-28 11:53:21,807 Epoch[6] Batch [1260]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.158872,	
2017-06-28 11:53:26,252 Epoch[6] Batch [1270]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.158720,	
2017-06-28 11:53:30,759 Epoch[6] Batch [1280]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.158500,	
2017-06-28 11:53:35,180 Epoch[6] Batch [1290]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.158390,	
2017-06-28 11:53:39,715 Epoch[6] Batch [1300]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.158392,	
2017-06-28 11:53:44,360 Epoch[6] Batch [1310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.158427,	
2017-06-28 11:53:49,168 Epoch[6] Batch [1320]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.158386,	
2017-06-28 11:53:53,375 Epoch[6] Batch [1330]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.158292,	
2017-06-28 11:53:57,651 Epoch[6] Batch [1340]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.158233,	
2017-06-28 11:54:01,850 Epoch[6] Batch [1350]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.158083,	
2017-06-28 11:54:06,255 Epoch[6] Batch [1360]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.158100,	
2017-06-28 11:54:10,406 Epoch[6] Batch [1370]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.157974,	
2017-06-28 11:54:15,044 Epoch[6] Batch [1380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.157902,	
2017-06-28 11:54:19,515 Epoch[6] Batch [1390]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.157903,	
2017-06-28 11:54:24,200 Epoch[6] Batch [1400]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.157873,	
2017-06-28 11:54:28,773 Epoch[6] Batch [1410]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.158024,	
2017-06-28 11:54:33,587 Epoch[6] Batch [1420]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.158127,	
2017-06-28 11:54:37,891 Epoch[6] Batch [1430]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.157993,	
2017-06-28 11:54:42,167 Epoch[6] Batch [1440]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.157983,	
2017-06-28 11:54:46,642 Epoch[6] Batch [1450]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.157919,	
2017-06-28 11:54:50,871 Epoch[6] Batch [1460]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.158272,	
2017-06-28 11:54:55,344 Epoch[6] Batch [1470]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.158187,	
2017-06-28 11:54:59,489 Epoch[6] Batch [1480]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.158120,	
2017-06-28 11:55:01,966 Epoch[6] Train-FCNLogLoss=0.158071
2017-06-28 11:55:01,966 Epoch[6] Time cost=665.244
2017-06-28 11:55:02,667 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0007.params"
2017-06-28 11:55:04,415 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0007.states"
2017-06-28 11:55:09,585 Epoch[7] Batch [10]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.143006,	
2017-06-28 11:55:13,844 Epoch[7] Batch [20]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.145128,	
2017-06-28 11:55:18,387 Epoch[7] Batch [30]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.144715,	
2017-06-28 11:55:22,743 Epoch[7] Batch [40]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.147765,	
2017-06-28 11:55:26,988 Epoch[7] Batch [50]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.148538,	
2017-06-28 11:55:31,141 Epoch[7] Batch [60]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.151409,	
2017-06-28 11:55:35,618 Epoch[7] Batch [70]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.147165,	
2017-06-28 11:55:39,871 Epoch[7] Batch [80]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.147485,	
2017-06-28 11:55:44,365 Epoch[7] Batch [90]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.146927,	
2017-06-28 11:55:49,009 Epoch[7] Batch [100]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.147431,	
2017-06-28 11:55:53,292 Epoch[7] Batch [110]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.149465,	
2017-06-28 11:55:57,835 Epoch[7] Batch [120]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.148884,	
2017-06-28 11:56:02,338 Epoch[7] Batch [130]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.150376,	
2017-06-28 11:56:06,859 Epoch[7] Batch [140]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.149117,	
2017-06-28 11:56:11,052 Epoch[7] Batch [150]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.149675,	
2017-06-28 11:56:15,684 Epoch[7] Batch [160]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.150552,	
2017-06-28 11:56:20,134 Epoch[7] Batch [170]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.151185,	
2017-06-28 11:56:24,412 Epoch[7] Batch [180]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.151449,	
2017-06-28 11:56:28,758 Epoch[7] Batch [190]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.150941,	
2017-06-28 11:56:33,493 Epoch[7] Batch [200]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.150081,	
2017-06-28 11:56:38,134 Epoch[7] Batch [210]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.149856,	
2017-06-28 11:56:42,226 Epoch[7] Batch [220]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.150920,	
2017-06-28 11:56:46,559 Epoch[7] Batch [230]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.152087,	
2017-06-28 11:56:51,003 Epoch[7] Batch [240]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.152679,	
2017-06-28 11:56:55,245 Epoch[7] Batch [250]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.152516,	
2017-06-28 11:56:59,521 Epoch[7] Batch [260]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.152389,	
2017-06-28 11:57:03,825 Epoch[7] Batch [270]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.151846,	
2017-06-28 11:57:08,690 Epoch[7] Batch [280]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.151466,	
2017-06-28 11:57:13,377 Epoch[7] Batch [290]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.151607,	
2017-06-28 11:57:17,702 Epoch[7] Batch [300]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.151684,	
2017-06-28 11:57:21,851 Epoch[7] Batch [310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.151463,	
2017-06-28 11:57:25,989 Epoch[7] Batch [320]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.151865,	
2017-06-28 11:57:30,241 Epoch[7] Batch [330]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.150738,	
2017-06-28 11:57:34,460 Epoch[7] Batch [340]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.151115,	
2017-06-28 11:57:39,159 Epoch[7] Batch [350]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.151609,	
2017-06-28 11:57:43,757 Epoch[7] Batch [360]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.151737,	
2017-06-28 11:57:48,205 Epoch[7] Batch [370]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.151632,	
2017-06-28 11:57:52,728 Epoch[7] Batch [380]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.151520,	
2017-06-28 11:57:57,127 Epoch[7] Batch [390]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.151463,	
2017-06-28 11:58:01,783 Epoch[7] Batch [400]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.151628,	
2017-06-28 11:58:06,461 Epoch[7] Batch [410]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.151801,	
2017-06-28 11:58:10,779 Epoch[7] Batch [420]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.151632,	
2017-06-28 11:58:15,268 Epoch[7] Batch [430]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.151942,	
2017-06-28 11:58:19,756 Epoch[7] Batch [440]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.151643,	
2017-06-28 11:58:24,265 Epoch[7] Batch [450]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.151254,	
2017-06-28 11:58:28,459 Epoch[7] Batch [460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.151034,	
2017-06-28 11:58:32,490 Epoch[7] Batch [470]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.150978,	
2017-06-28 11:58:36,707 Epoch[7] Batch [480]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.151324,	
2017-06-28 11:58:41,114 Epoch[7] Batch [490]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.151291,	
2017-06-28 11:58:45,653 Epoch[7] Batch [500]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.150734,	
2017-06-28 11:58:50,190 Epoch[7] Batch [510]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.150760,	
2017-06-28 11:58:55,018 Epoch[7] Batch [520]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.150620,	
2017-06-28 11:58:59,784 Epoch[7] Batch [530]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.150385,	
2017-06-28 11:59:04,227 Epoch[7] Batch [540]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.149926,	
2017-06-28 11:59:08,960 Epoch[7] Batch [550]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.149707,	
2017-06-28 11:59:13,457 Epoch[7] Batch [560]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.149795,	
2017-06-28 11:59:18,024 Epoch[7] Batch [570]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.149966,	
2017-06-28 11:59:22,597 Epoch[7] Batch [580]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.149608,	
2017-06-28 11:59:27,010 Epoch[7] Batch [590]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.149566,	
2017-06-28 11:59:31,323 Epoch[7] Batch [600]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.149237,	
2017-06-28 11:59:35,853 Epoch[7] Batch [610]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.149225,	
2017-06-28 11:59:40,556 Epoch[7] Batch [620]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.149104,	
2017-06-28 11:59:45,246 Epoch[7] Batch [630]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.148806,	
2017-06-28 11:59:49,685 Epoch[7] Batch [640]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.148701,	
2017-06-28 11:59:54,138 Epoch[7] Batch [650]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.148942,	
2017-06-28 11:59:58,340 Epoch[7] Batch [660]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.148880,	
2017-06-28 12:00:02,697 Epoch[7] Batch [670]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.149142,	
2017-06-28 12:00:07,455 Epoch[7] Batch [680]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.149187,	
2017-06-28 12:00:11,769 Epoch[7] Batch [690]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.149460,	
2017-06-28 12:00:16,388 Epoch[7] Batch [700]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.149701,	
2017-06-28 12:00:21,125 Epoch[7] Batch [710]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.149678,	
2017-06-28 12:00:25,422 Epoch[7] Batch [720]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.149597,	
2017-06-28 12:00:29,848 Epoch[7] Batch [730]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.149609,	
2017-06-28 12:00:34,143 Epoch[7] Batch [740]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.149566,	
2017-06-28 12:00:38,302 Epoch[7] Batch [750]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.149693,	
2017-06-28 12:00:42,960 Epoch[7] Batch [760]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.149764,	
2017-06-28 12:00:47,653 Epoch[7] Batch [770]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.149996,	
2017-06-28 12:00:51,807 Epoch[7] Batch [780]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.150266,	
2017-06-28 12:00:56,282 Epoch[7] Batch [790]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.150289,	
2017-06-28 12:01:00,657 Epoch[7] Batch [800]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.150384,	
2017-06-28 12:01:05,337 Epoch[7] Batch [810]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.150394,	
2017-06-28 12:01:09,703 Epoch[7] Batch [820]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.150260,	
2017-06-28 12:01:14,071 Epoch[7] Batch [830]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.149992,	
2017-06-28 12:01:18,359 Epoch[7] Batch [840]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.150097,	
2017-06-28 12:01:22,704 Epoch[7] Batch [850]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.149803,	
2017-06-28 12:01:26,831 Epoch[7] Batch [860]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.149814,	
2017-06-28 12:01:31,202 Epoch[7] Batch [870]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.149594,	
2017-06-28 12:01:35,662 Epoch[7] Batch [880]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.149452,	
2017-06-28 12:01:40,014 Epoch[7] Batch [890]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.149558,	
2017-06-28 12:01:44,140 Epoch[7] Batch [900]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.150027,	
2017-06-28 12:01:48,491 Epoch[7] Batch [910]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.150138,	
2017-06-28 12:01:52,773 Epoch[7] Batch [920]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.150360,	
2017-06-28 12:01:56,921 Epoch[7] Batch [930]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.150358,	
2017-06-28 12:02:01,278 Epoch[7] Batch [940]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.150445,	
2017-06-28 12:02:05,608 Epoch[7] Batch [950]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.150245,	
2017-06-28 12:02:09,904 Epoch[7] Batch [960]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.150295,	
2017-06-28 12:02:14,463 Epoch[7] Batch [970]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.150143,	
2017-06-28 12:02:19,000 Epoch[7] Batch [980]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.150046,	
2017-06-28 12:02:23,480 Epoch[7] Batch [990]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.150142,	
2017-06-28 12:02:28,225 Epoch[7] Batch [1000]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.150085,	
2017-06-28 12:02:32,955 Epoch[7] Batch [1010]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.150011,	
2017-06-28 12:02:37,617 Epoch[7] Batch [1020]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.150056,	
2017-06-28 12:02:42,335 Epoch[7] Batch [1030]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.149859,	
2017-06-28 12:02:46,833 Epoch[7] Batch [1040]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.150393,	
2017-06-28 12:02:51,373 Epoch[7] Batch [1050]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.150597,	
2017-06-28 12:02:56,213 Epoch[7] Batch [1060]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.150821,	
2017-06-28 12:03:00,767 Epoch[7] Batch [1070]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.150739,	
2017-06-28 12:03:05,362 Epoch[7] Batch [1080]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.150869,	
2017-06-28 12:03:09,936 Epoch[7] Batch [1090]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.150894,	
2017-06-28 12:03:14,295 Epoch[7] Batch [1100]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.151048,	
2017-06-28 12:03:18,704 Epoch[7] Batch [1110]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.151231,	
2017-06-28 12:03:23,049 Epoch[7] Batch [1120]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.151107,	
2017-06-28 12:03:27,235 Epoch[7] Batch [1130]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.151048,	
2017-06-28 12:03:31,518 Epoch[7] Batch [1140]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.151107,	
2017-06-28 12:03:35,830 Epoch[7] Batch [1150]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.151081,	
2017-06-28 12:03:39,949 Epoch[7] Batch [1160]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.150972,	
2017-06-28 12:03:44,296 Epoch[7] Batch [1170]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.151055,	
2017-06-28 12:03:48,577 Epoch[7] Batch [1180]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.150924,	
2017-06-28 12:03:52,999 Epoch[7] Batch [1190]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.151134,	
2017-06-28 12:03:57,448 Epoch[7] Batch [1200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.151074,	
2017-06-28 12:04:02,204 Epoch[7] Batch [1210]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.151127,	
2017-06-28 12:04:06,472 Epoch[7] Batch [1220]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.151108,	
2017-06-28 12:04:11,032 Epoch[7] Batch [1230]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.151064,	
2017-06-28 12:04:15,482 Epoch[7] Batch [1240]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.151042,	
2017-06-28 12:04:19,839 Epoch[7] Batch [1250]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.150963,	
2017-06-28 12:04:24,076 Epoch[7] Batch [1260]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.151092,	
2017-06-28 12:04:28,514 Epoch[7] Batch [1270]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.151117,	
2017-06-28 12:04:32,708 Epoch[7] Batch [1280]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.151097,	
2017-06-28 12:04:37,161 Epoch[7] Batch [1290]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.151111,	
2017-06-28 12:04:41,998 Epoch[7] Batch [1300]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.150993,	
2017-06-28 12:04:46,486 Epoch[7] Batch [1310]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.150845,	
2017-06-28 12:04:50,839 Epoch[7] Batch [1320]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.150842,	
2017-06-28 12:04:55,529 Epoch[7] Batch [1330]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.150834,	
2017-06-28 12:05:00,219 Epoch[7] Batch [1340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.150684,	
2017-06-28 12:05:05,026 Epoch[7] Batch [1350]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.150597,	
2017-06-28 12:05:09,357 Epoch[7] Batch [1360]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.150434,	
2017-06-28 12:05:13,821 Epoch[7] Batch [1370]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.150328,	
2017-06-28 12:05:17,999 Epoch[7] Batch [1380]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.150360,	
2017-06-28 12:05:22,846 Epoch[7] Batch [1390]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.150240,	
2017-06-28 12:05:27,326 Epoch[7] Batch [1400]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.150200,	
2017-06-28 12:05:32,270 Epoch[7] Batch [1410]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.150102,	
2017-06-28 12:05:36,812 Epoch[7] Batch [1420]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.150114,	
2017-06-28 12:05:41,542 Epoch[7] Batch [1430]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.150085,	
2017-06-28 12:05:46,126 Epoch[7] Batch [1440]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.150141,	
2017-06-28 12:05:50,599 Epoch[7] Batch [1450]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.150162,	
2017-06-28 12:05:55,042 Epoch[7] Batch [1460]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.150178,	
2017-06-28 12:05:59,790 Epoch[7] Batch [1470]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.150166,	
2017-06-28 12:06:04,475 Epoch[7] Batch [1480]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.150036,	
2017-06-28 12:06:07,286 Epoch[7] Train-FCNLogLoss=0.150100
2017-06-28 12:06:07,286 Epoch[7] Time cost=662.871
2017-06-28 12:06:07,979 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0008.params"
2017-06-28 12:06:09,488 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0008.states"
2017-06-28 12:06:14,466 Epoch[8] Batch [10]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.149491,	
2017-06-28 12:06:18,738 Epoch[8] Batch [20]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.154756,	
2017-06-28 12:06:23,232 Epoch[8] Batch [30]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.150062,	
2017-06-28 12:06:27,930 Epoch[8] Batch [40]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.150998,	
2017-06-28 12:06:32,350 Epoch[8] Batch [50]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.149401,	
2017-06-28 12:06:36,781 Epoch[8] Batch [60]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.149003,	
2017-06-28 12:06:41,390 Epoch[8] Batch [70]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.148532,	
2017-06-28 12:06:45,929 Epoch[8] Batch [80]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.147697,	
2017-06-28 12:06:50,118 Epoch[8] Batch [90]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.147109,	
2017-06-28 12:06:54,684 Epoch[8] Batch [100]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.146760,	
2017-06-28 12:06:59,209 Epoch[8] Batch [110]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.147222,	
2017-06-28 12:07:03,778 Epoch[8] Batch [120]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.146127,	
2017-06-28 12:07:08,170 Epoch[8] Batch [130]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.147070,	
2017-06-28 12:07:12,663 Epoch[8] Batch [140]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.147030,	
2017-06-28 12:07:16,992 Epoch[8] Batch [150]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.146881,	
2017-06-28 12:07:21,280 Epoch[8] Batch [160]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.146714,	
2017-06-28 12:07:25,691 Epoch[8] Batch [170]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.146323,	
2017-06-28 12:07:29,935 Epoch[8] Batch [180]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.145960,	
2017-06-28 12:07:34,049 Epoch[8] Batch [190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.144964,	
2017-06-28 12:07:38,401 Epoch[8] Batch [200]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.145791,	
2017-06-28 12:07:42,870 Epoch[8] Batch [210]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.145148,	
2017-06-28 12:07:47,074 Epoch[8] Batch [220]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.144718,	
2017-06-28 12:07:51,552 Epoch[8] Batch [230]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.143707,	
2017-06-28 12:07:55,905 Epoch[8] Batch [240]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.143943,	
2017-06-28 12:08:00,174 Epoch[8] Batch [250]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.143917,	
2017-06-28 12:08:04,643 Epoch[8] Batch [260]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.143680,	
2017-06-28 12:08:08,794 Epoch[8] Batch [270]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.143237,	
2017-06-28 12:08:12,936 Epoch[8] Batch [280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.143599,	
2017-06-28 12:08:17,665 Epoch[8] Batch [290]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.143384,	
2017-06-28 12:08:22,145 Epoch[8] Batch [300]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.142930,	
2017-06-28 12:08:26,610 Epoch[8] Batch [310]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.143253,	
2017-06-28 12:08:31,137 Epoch[8] Batch [320]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.143277,	
2017-06-28 12:08:35,931 Epoch[8] Batch [330]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.143408,	
2017-06-28 12:08:40,641 Epoch[8] Batch [340]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.143610,	
2017-06-28 12:08:45,271 Epoch[8] Batch [350]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.143758,	
2017-06-28 12:08:49,481 Epoch[8] Batch [360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.144754,	
2017-06-28 12:08:54,260 Epoch[8] Batch [370]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.144830,	
2017-06-28 12:08:58,534 Epoch[8] Batch [380]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.146058,	
2017-06-28 12:09:02,766 Epoch[8] Batch [390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.146510,	
2017-06-28 12:09:07,168 Epoch[8] Batch [400]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.146473,	
2017-06-28 12:09:11,440 Epoch[8] Batch [410]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.147020,	
2017-06-28 12:09:16,176 Epoch[8] Batch [420]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.147230,	
2017-06-28 12:09:21,019 Epoch[8] Batch [430]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.147330,	
2017-06-28 12:09:25,512 Epoch[8] Batch [440]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.147359,	
2017-06-28 12:09:30,513 Epoch[8] Batch [450]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.146969,	
2017-06-28 12:09:35,082 Epoch[8] Batch [460]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.146898,	
2017-06-28 12:09:39,497 Epoch[8] Batch [470]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.146794,	
2017-06-28 12:09:43,855 Epoch[8] Batch [480]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.146294,	
2017-06-28 12:09:48,391 Epoch[8] Batch [490]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.145720,	
2017-06-28 12:09:53,163 Epoch[8] Batch [500]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.145451,	
2017-06-28 12:09:57,484 Epoch[8] Batch [510]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.145183,	
2017-06-28 12:10:01,887 Epoch[8] Batch [520]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.145713,	
2017-06-28 12:10:06,376 Epoch[8] Batch [530]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.145708,	
2017-06-28 12:10:10,923 Epoch[8] Batch [540]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.145553,	
2017-06-28 12:10:15,369 Epoch[8] Batch [550]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.145080,	
2017-06-28 12:10:19,805 Epoch[8] Batch [560]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.145229,	
2017-06-28 12:10:24,244 Epoch[8] Batch [570]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.145310,	
2017-06-28 12:10:28,340 Epoch[8] Batch [580]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.145672,	
2017-06-28 12:10:33,015 Epoch[8] Batch [590]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.145665,	
2017-06-28 12:10:37,102 Epoch[8] Batch [600]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.145521,	
2017-06-28 12:10:41,257 Epoch[8] Batch [610]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.145533,	
2017-06-28 12:10:45,470 Epoch[8] Batch [620]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.145334,	
2017-06-28 12:10:49,730 Epoch[8] Batch [630]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.145286,	
2017-06-28 12:10:54,094 Epoch[8] Batch [640]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.145104,	
2017-06-28 12:10:58,430 Epoch[8] Batch [650]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.144964,	
2017-06-28 12:11:02,711 Epoch[8] Batch [660]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.144826,	
2017-06-28 12:11:07,230 Epoch[8] Batch [670]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.144709,	
2017-06-28 12:11:11,873 Epoch[8] Batch [680]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.144792,	
2017-06-28 12:11:16,452 Epoch[8] Batch [690]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.144556,	
2017-06-28 12:11:21,034 Epoch[8] Batch [700]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.144540,	
2017-06-28 12:11:25,501 Epoch[8] Batch [710]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.144650,	
2017-06-28 12:11:29,834 Epoch[8] Batch [720]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.144428,	
2017-06-28 12:11:34,534 Epoch[8] Batch [730]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.144173,	
2017-06-28 12:11:39,385 Epoch[8] Batch [740]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.144058,	
2017-06-28 12:11:43,705 Epoch[8] Batch [750]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.144026,	
2017-06-28 12:11:47,774 Epoch[8] Batch [760]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.144095,	
2017-06-28 12:11:51,898 Epoch[8] Batch [770]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.144100,	
2017-06-28 12:11:56,653 Epoch[8] Batch [780]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.143976,	
2017-06-28 12:12:01,060 Epoch[8] Batch [790]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.143876,	
2017-06-28 12:12:05,346 Epoch[8] Batch [800]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.143822,	
2017-06-28 12:12:09,606 Epoch[8] Batch [810]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.143962,	
2017-06-28 12:12:13,762 Epoch[8] Batch [820]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.144069,	
2017-06-28 12:12:18,340 Epoch[8] Batch [830]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.144185,	
2017-06-28 12:12:22,863 Epoch[8] Batch [840]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.144263,	
2017-06-28 12:12:27,488 Epoch[8] Batch [850]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.144385,	
2017-06-28 12:12:32,175 Epoch[8] Batch [860]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.144336,	
2017-06-28 12:12:36,432 Epoch[8] Batch [870]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.144256,	
2017-06-28 12:12:40,666 Epoch[8] Batch [880]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.144252,	
2017-06-28 12:12:45,028 Epoch[8] Batch [890]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.144457,	
2017-06-28 12:12:49,410 Epoch[8] Batch [900]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.144744,	
2017-06-28 12:12:54,410 Epoch[8] Batch [910]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.144911,	
2017-06-28 12:12:59,280 Epoch[8] Batch [920]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.144920,	
2017-06-28 12:13:03,542 Epoch[8] Batch [930]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.144912,	
2017-06-28 12:13:07,657 Epoch[8] Batch [940]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.144932,	
2017-06-28 12:13:12,044 Epoch[8] Batch [950]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.144874,	
2017-06-28 12:13:16,833 Epoch[8] Batch [960]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.144796,	
2017-06-28 12:13:21,413 Epoch[8] Batch [970]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.144922,	
2017-06-28 12:13:25,702 Epoch[8] Batch [980]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.145059,	
2017-06-28 12:13:30,237 Epoch[8] Batch [990]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.145176,	
2017-06-28 12:13:34,598 Epoch[8] Batch [1000]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.145255,	
2017-06-28 12:13:38,921 Epoch[8] Batch [1010]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.145240,	
2017-06-28 12:13:43,433 Epoch[8] Batch [1020]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.145170,	
2017-06-28 12:13:47,644 Epoch[8] Batch [1030]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.145157,	
2017-06-28 12:13:51,767 Epoch[8] Batch [1040]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.145259,	
2017-06-28 12:13:56,132 Epoch[8] Batch [1050]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.145089,	
2017-06-28 12:14:00,547 Epoch[8] Batch [1060]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.145124,	
2017-06-28 12:14:04,720 Epoch[8] Batch [1070]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.145054,	
2017-06-28 12:14:09,249 Epoch[8] Batch [1080]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.145060,	
2017-06-28 12:14:14,106 Epoch[8] Batch [1090]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.144927,	
2017-06-28 12:14:18,546 Epoch[8] Batch [1100]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.144951,	
2017-06-28 12:14:23,209 Epoch[8] Batch [1110]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.144882,	
2017-06-28 12:14:27,698 Epoch[8] Batch [1120]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.144898,	
2017-06-28 12:14:32,350 Epoch[8] Batch [1130]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.144718,	
2017-06-28 12:14:36,951 Epoch[8] Batch [1140]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.144649,	
2017-06-28 12:14:41,869 Epoch[8] Batch [1150]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.144559,	
2017-06-28 12:14:46,487 Epoch[8] Batch [1160]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.144534,	
2017-06-28 12:14:51,119 Epoch[8] Batch [1170]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.144707,	
2017-06-28 12:14:55,591 Epoch[8] Batch [1180]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.144527,	
2017-06-28 12:14:59,857 Epoch[8] Batch [1190]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.144541,	
2017-06-28 12:15:04,333 Epoch[8] Batch [1200]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.144519,	
2017-06-28 12:15:08,821 Epoch[8] Batch [1210]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.144495,	
2017-06-28 12:15:13,294 Epoch[8] Batch [1220]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.144695,	
2017-06-28 12:15:17,711 Epoch[8] Batch [1230]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.144713,	
2017-06-28 12:15:22,342 Epoch[8] Batch [1240]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.144470,	
2017-06-28 12:15:26,798 Epoch[8] Batch [1250]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.144471,	
2017-06-28 12:15:30,948 Epoch[8] Batch [1260]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.144336,	
2017-06-28 12:15:35,494 Epoch[8] Batch [1270]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.144296,	
2017-06-28 12:15:39,948 Epoch[8] Batch [1280]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.144152,	
2017-06-28 12:15:44,466 Epoch[8] Batch [1290]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.144048,	
2017-06-28 12:15:48,848 Epoch[8] Batch [1300]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.144060,	
2017-06-28 12:15:53,491 Epoch[8] Batch [1310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.144000,	
2017-06-28 12:15:57,892 Epoch[8] Batch [1320]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.144001,	
2017-06-28 12:16:02,454 Epoch[8] Batch [1330]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.143992,	
2017-06-28 12:16:06,663 Epoch[8] Batch [1340]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.144276,	
2017-06-28 12:16:11,416 Epoch[8] Batch [1350]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.144471,	
2017-06-28 12:16:15,912 Epoch[8] Batch [1360]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.144566,	
2017-06-28 12:16:20,067 Epoch[8] Batch [1370]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.144571,	
2017-06-28 12:16:24,636 Epoch[8] Batch [1380]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.144645,	
2017-06-28 12:16:29,282 Epoch[8] Batch [1390]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.144649,	
2017-06-28 12:16:33,882 Epoch[8] Batch [1400]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.144581,	
2017-06-28 12:16:38,664 Epoch[8] Batch [1410]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.144594,	
2017-06-28 12:16:43,046 Epoch[8] Batch [1420]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.144703,	
2017-06-28 12:16:47,737 Epoch[8] Batch [1430]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.144790,	
2017-06-28 12:16:52,151 Epoch[8] Batch [1440]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.144887,	
2017-06-28 12:16:56,531 Epoch[8] Batch [1450]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.144907,	
2017-06-28 12:17:01,484 Epoch[8] Batch [1460]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.145088,	
2017-06-28 12:17:06,419 Epoch[8] Batch [1470]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.145220,	
2017-06-28 12:17:11,249 Epoch[8] Batch [1480]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.145227,	
2017-06-28 12:17:14,015 Epoch[8] Train-FCNLogLoss=0.145148
2017-06-28 12:17:14,015 Epoch[8] Time cost=664.527
2017-06-28 12:17:14,744 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0009.params"
2017-06-28 12:17:16,511 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0009.states"
2017-06-28 12:17:22,376 Epoch[9] Batch [10]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.161363,	
2017-06-28 12:17:26,979 Epoch[9] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.167204,	
2017-06-28 12:17:31,552 Epoch[9] Batch [30]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.168389,	
2017-06-28 12:17:36,198 Epoch[9] Batch [40]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.161351,	
2017-06-28 12:17:40,729 Epoch[9] Batch [50]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.156915,	
2017-06-28 12:17:45,253 Epoch[9] Batch [60]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.155466,	
2017-06-28 12:17:49,476 Epoch[9] Batch [70]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.153546,	
2017-06-28 12:17:53,750 Epoch[9] Batch [80]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.151390,	
2017-06-28 12:17:58,035 Epoch[9] Batch [90]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.148952,	
2017-06-28 12:18:02,111 Epoch[9] Batch [100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.147873,	
2017-06-28 12:18:06,369 Epoch[9] Batch [110]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.149434,	
2017-06-28 12:18:10,875 Epoch[9] Batch [120]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.151639,	
2017-06-28 12:18:15,352 Epoch[9] Batch [130]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.151594,	
2017-06-28 12:18:19,796 Epoch[9] Batch [140]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.154517,	
2017-06-28 12:18:24,457 Epoch[9] Batch [150]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.155565,	
2017-06-28 12:18:29,023 Epoch[9] Batch [160]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.154480,	
2017-06-28 12:18:33,291 Epoch[9] Batch [170]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.153505,	
2017-06-28 12:18:37,660 Epoch[9] Batch [180]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.153040,	
2017-06-28 12:18:42,376 Epoch[9] Batch [190]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.152928,	
2017-06-28 12:18:47,243 Epoch[9] Batch [200]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.152757,	
2017-06-28 12:18:51,457 Epoch[9] Batch [210]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.153008,	
2017-06-28 12:18:56,050 Epoch[9] Batch [220]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.151856,	
2017-06-28 12:19:00,944 Epoch[9] Batch [230]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.152533,	
2017-06-28 12:19:05,474 Epoch[9] Batch [240]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.151763,	
2017-06-28 12:19:10,226 Epoch[9] Batch [250]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.151441,	
2017-06-28 12:19:15,064 Epoch[9] Batch [260]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.151168,	
2017-06-28 12:19:19,745 Epoch[9] Batch [270]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.151127,	
2017-06-28 12:19:24,071 Epoch[9] Batch [280]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.151284,	
2017-06-28 12:19:28,270 Epoch[9] Batch [290]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.151706,	
2017-06-28 12:19:32,905 Epoch[9] Batch [300]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.151710,	
2017-06-28 12:19:37,574 Epoch[9] Batch [310]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.151314,	
2017-06-28 12:19:41,859 Epoch[9] Batch [320]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.151682,	
2017-06-28 12:19:46,233 Epoch[9] Batch [330]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.152153,	
2017-06-28 12:19:50,665 Epoch[9] Batch [340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.151607,	
2017-06-28 12:19:55,339 Epoch[9] Batch [350]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.151410,	
2017-06-28 12:19:59,845 Epoch[9] Batch [360]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.151463,	
2017-06-28 12:20:04,360 Epoch[9] Batch [370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.150754,	
2017-06-28 12:20:08,992 Epoch[9] Batch [380]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.150669,	
2017-06-28 12:20:13,504 Epoch[9] Batch [390]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.150312,	
2017-06-28 12:20:18,041 Epoch[9] Batch [400]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.149944,	
2017-06-28 12:20:22,642 Epoch[9] Batch [410]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.149622,	
2017-06-28 12:20:26,916 Epoch[9] Batch [420]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.149527,	
2017-06-28 12:20:31,590 Epoch[9] Batch [430]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.149626,	
2017-06-28 12:20:36,304 Epoch[9] Batch [440]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.150186,	
2017-06-28 12:20:40,584 Epoch[9] Batch [450]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.150250,	
2017-06-28 12:20:45,047 Epoch[9] Batch [460]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.150108,	
2017-06-28 12:20:49,620 Epoch[9] Batch [470]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.150120,	
2017-06-28 12:20:54,236 Epoch[9] Batch [480]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.150036,	
2017-06-28 12:20:58,522 Epoch[9] Batch [490]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.150263,	
2017-06-28 12:21:03,175 Epoch[9] Batch [500]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.150580,	
2017-06-28 12:21:07,578 Epoch[9] Batch [510]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.149955,	
2017-06-28 12:21:11,938 Epoch[9] Batch [520]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.149386,	
2017-06-28 12:21:16,336 Epoch[9] Batch [530]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.149117,	
2017-06-28 12:21:20,469 Epoch[9] Batch [540]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.148516,	
2017-06-28 12:21:24,726 Epoch[9] Batch [550]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.148319,	
2017-06-28 12:21:29,054 Epoch[9] Batch [560]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.148426,	
2017-06-28 12:21:33,522 Epoch[9] Batch [570]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.148428,	
2017-06-28 12:21:37,939 Epoch[9] Batch [580]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.148248,	
2017-06-28 12:21:42,084 Epoch[9] Batch [590]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.148388,	
2017-06-28 12:21:46,263 Epoch[9] Batch [600]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.148416,	
2017-06-28 12:21:50,672 Epoch[9] Batch [610]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.148264,	
2017-06-28 12:21:55,216 Epoch[9] Batch [620]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.148162,	
2017-06-28 12:21:59,794 Epoch[9] Batch [630]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.147907,	
2017-06-28 12:22:04,338 Epoch[9] Batch [640]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.147694,	
2017-06-28 12:22:08,658 Epoch[9] Batch [650]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.147494,	
2017-06-28 12:22:12,787 Epoch[9] Batch [660]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.147507,	
2017-06-28 12:22:17,297 Epoch[9] Batch [670]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.147340,	
2017-06-28 12:22:22,082 Epoch[9] Batch [680]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.147208,	
2017-06-28 12:22:26,559 Epoch[9] Batch [690]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.147008,	
2017-06-28 12:22:31,081 Epoch[9] Batch [700]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.146886,	
2017-06-28 12:22:35,629 Epoch[9] Batch [710]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.147104,	
2017-06-28 12:22:40,004 Epoch[9] Batch [720]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.146841,	
2017-06-28 12:22:44,269 Epoch[9] Batch [730]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.146503,	
2017-06-28 12:22:48,396 Epoch[9] Batch [740]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.146486,	
2017-06-28 12:22:53,027 Epoch[9] Batch [750]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.146405,	
2017-06-28 12:22:57,605 Epoch[9] Batch [760]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.146274,	
2017-06-28 12:23:02,136 Epoch[9] Batch [770]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.146035,	
2017-06-28 12:23:06,690 Epoch[9] Batch [780]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.145922,	
2017-06-28 12:23:11,331 Epoch[9] Batch [790]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.145773,	
2017-06-28 12:23:15,780 Epoch[9] Batch [800]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.145742,	
2017-06-28 12:23:20,451 Epoch[9] Batch [810]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.145473,	
2017-06-28 12:23:24,819 Epoch[9] Batch [820]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.145412,	
2017-06-28 12:23:29,256 Epoch[9] Batch [830]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.145421,	
2017-06-28 12:23:33,564 Epoch[9] Batch [840]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.145238,	
2017-06-28 12:23:37,819 Epoch[9] Batch [850]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.145269,	
2017-06-28 12:23:42,096 Epoch[9] Batch [860]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.145116,	
2017-06-28 12:23:46,208 Epoch[9] Batch [870]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.144937,	
2017-06-28 12:23:50,516 Epoch[9] Batch [880]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.144873,	
2017-06-28 12:23:54,751 Epoch[9] Batch [890]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.144721,	
2017-06-28 12:23:59,184 Epoch[9] Batch [900]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.144544,	
2017-06-28 12:24:03,586 Epoch[9] Batch [910]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.144521,	
2017-06-28 12:24:08,063 Epoch[9] Batch [920]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.144301,	
2017-06-28 12:24:12,106 Epoch[9] Batch [930]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.144155,	
2017-06-28 12:24:16,161 Epoch[9] Batch [940]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.144265,	
2017-06-28 12:24:20,231 Epoch[9] Batch [950]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.144182,	
2017-06-28 12:24:24,423 Epoch[9] Batch [960]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.144122,	
2017-06-28 12:24:28,711 Epoch[9] Batch [970]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.144086,	
2017-06-28 12:24:33,042 Epoch[9] Batch [980]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.144060,	
2017-06-28 12:24:37,874 Epoch[9] Batch [990]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.144179,	
2017-06-28 12:24:41,950 Epoch[9] Batch [1000]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.144031,	
2017-06-28 12:24:46,061 Epoch[9] Batch [1010]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.143951,	
2017-06-28 12:24:50,359 Epoch[9] Batch [1020]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.143804,	
2017-06-28 12:24:54,952 Epoch[9] Batch [1030]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.143886,	
2017-06-28 12:24:59,644 Epoch[9] Batch [1040]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.143924,	
2017-06-28 12:25:04,176 Epoch[9] Batch [1050]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.144078,	
2017-06-28 12:25:08,784 Epoch[9] Batch [1060]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.144069,	
2017-06-28 12:25:13,139 Epoch[9] Batch [1070]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.144185,	
2017-06-28 12:25:17,338 Epoch[9] Batch [1080]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.144196,	
2017-06-28 12:25:21,735 Epoch[9] Batch [1090]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.144227,	
2017-06-28 12:25:26,182 Epoch[9] Batch [1100]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.144150,	
2017-06-28 12:25:30,685 Epoch[9] Batch [1110]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.143908,	
2017-06-28 12:25:35,264 Epoch[9] Batch [1120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.144016,	
2017-06-28 12:25:39,640 Epoch[9] Batch [1130]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.143899,	
2017-06-28 12:25:44,335 Epoch[9] Batch [1140]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.143768,	
2017-06-28 12:25:49,081 Epoch[9] Batch [1150]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.143692,	
2017-06-28 12:25:53,350 Epoch[9] Batch [1160]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.143492,	
2017-06-28 12:25:57,714 Epoch[9] Batch [1170]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.143648,	
2017-06-28 12:26:02,378 Epoch[9] Batch [1180]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.143588,	
2017-06-28 12:26:06,814 Epoch[9] Batch [1190]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.143716,	
2017-06-28 12:26:11,084 Epoch[9] Batch [1200]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.143734,	
2017-06-28 12:26:15,622 Epoch[9] Batch [1210]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.143598,	
2017-06-28 12:26:20,221 Epoch[9] Batch [1220]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.143475,	
2017-06-28 12:26:25,071 Epoch[9] Batch [1230]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.143458,	
2017-06-28 12:26:29,840 Epoch[9] Batch [1240]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.143609,	
2017-06-28 12:26:34,180 Epoch[9] Batch [1250]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.143580,	
2017-06-28 12:26:38,541 Epoch[9] Batch [1260]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.143621,	
2017-06-28 12:26:42,942 Epoch[9] Batch [1270]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.143531,	
2017-06-28 12:26:47,566 Epoch[9] Batch [1280]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.143552,	
2017-06-28 12:26:51,778 Epoch[9] Batch [1290]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.143534,	
2017-06-28 12:26:56,268 Epoch[9] Batch [1300]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.143449,	
2017-06-28 12:27:01,022 Epoch[9] Batch [1310]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.143288,	
2017-06-28 12:27:05,454 Epoch[9] Batch [1320]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.143286,	
2017-06-28 12:27:09,574 Epoch[9] Batch [1330]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.143284,	
2017-06-28 12:27:14,101 Epoch[9] Batch [1340]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.143346,	
2017-06-28 12:27:18,267 Epoch[9] Batch [1350]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.143341,	
2017-06-28 12:27:22,741 Epoch[9] Batch [1360]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.143265,	
2017-06-28 12:27:27,029 Epoch[9] Batch [1370]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.143278,	
2017-06-28 12:27:31,527 Epoch[9] Batch [1380]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.143254,	
2017-06-28 12:27:35,729 Epoch[9] Batch [1390]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.143120,	
2017-06-28 12:27:40,528 Epoch[9] Batch [1400]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.143014,	
2017-06-28 12:27:44,702 Epoch[9] Batch [1410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.142874,	
2017-06-28 12:27:48,780 Epoch[9] Batch [1420]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.142808,	
2017-06-28 12:27:53,208 Epoch[9] Batch [1430]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.142895,	
2017-06-28 12:27:57,860 Epoch[9] Batch [1440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.142738,	
2017-06-28 12:28:02,287 Epoch[9] Batch [1450]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.142828,	
2017-06-28 12:28:06,792 Epoch[9] Batch [1460]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.142909,	
2017-06-28 12:28:11,548 Epoch[9] Batch [1470]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.142889,	
2017-06-28 12:28:16,185 Epoch[9] Batch [1480]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.142962,	
2017-06-28 12:28:18,872 Epoch[9] Train-FCNLogLoss=0.142968
2017-06-28 12:28:18,872 Epoch[9] Time cost=662.360
2017-06-28 12:28:19,616 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0010.params"
2017-06-28 12:28:21,267 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0010.states"
2017-06-28 12:28:26,802 Epoch[10] Batch [10]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.161662,	
2017-06-28 12:28:31,674 Epoch[10] Batch [20]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.149413,	
2017-06-28 12:28:36,118 Epoch[10] Batch [30]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.145880,	
2017-06-28 12:28:40,441 Epoch[10] Batch [40]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.141098,	
2017-06-28 12:28:44,776 Epoch[10] Batch [50]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.138306,	
2017-06-28 12:28:49,038 Epoch[10] Batch [60]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.138322,	
2017-06-28 12:28:53,337 Epoch[10] Batch [70]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.137637,	
2017-06-28 12:28:57,908 Epoch[10] Batch [80]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.138554,	
2017-06-28 12:29:02,408 Epoch[10] Batch [90]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.138009,	
2017-06-28 12:29:06,984 Epoch[10] Batch [100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.138300,	
2017-06-28 12:29:11,393 Epoch[10] Batch [110]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.139038,	
2017-06-28 12:29:15,789 Epoch[10] Batch [120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.139534,	
2017-06-28 12:29:19,925 Epoch[10] Batch [130]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.138087,	
2017-06-28 12:29:24,409 Epoch[10] Batch [140]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.138753,	
2017-06-28 12:29:29,120 Epoch[10] Batch [150]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.138563,	
2017-06-28 12:29:33,538 Epoch[10] Batch [160]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.137321,	
2017-06-28 12:29:37,802 Epoch[10] Batch [170]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.137115,	
2017-06-28 12:29:42,163 Epoch[10] Batch [180]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.136028,	
2017-06-28 12:29:46,808 Epoch[10] Batch [190]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.136725,	
2017-06-28 12:29:51,535 Epoch[10] Batch [200]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.135784,	
2017-06-28 12:29:56,315 Epoch[10] Batch [210]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.135777,	
2017-06-28 12:30:00,654 Epoch[10] Batch [220]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.135959,	
2017-06-28 12:30:04,846 Epoch[10] Batch [230]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.136729,	
2017-06-28 12:30:09,297 Epoch[10] Batch [240]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.136221,	
2017-06-28 12:30:13,986 Epoch[10] Batch [250]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.135451,	
2017-06-28 12:30:18,335 Epoch[10] Batch [260]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.134948,	
2017-06-28 12:30:22,818 Epoch[10] Batch [270]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.134909,	
2017-06-28 12:30:27,714 Epoch[10] Batch [280]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.134489,	
2017-06-28 12:30:32,163 Epoch[10] Batch [290]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.134338,	
2017-06-28 12:30:36,918 Epoch[10] Batch [300]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.133987,	
2017-06-28 12:30:41,584 Epoch[10] Batch [310]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.133644,	
2017-06-28 12:30:46,068 Epoch[10] Batch [320]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.133335,	
2017-06-28 12:30:50,481 Epoch[10] Batch [330]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.133452,	
2017-06-28 12:30:55,043 Epoch[10] Batch [340]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.133806,	
2017-06-28 12:30:59,476 Epoch[10] Batch [350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.133851,	
2017-06-28 12:31:03,834 Epoch[10] Batch [360]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.133836,	
2017-06-28 12:31:08,127 Epoch[10] Batch [370]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.134158,	
2017-06-28 12:31:12,285 Epoch[10] Batch [380]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.133800,	
2017-06-28 12:31:16,396 Epoch[10] Batch [390]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.133931,	
2017-06-28 12:31:20,688 Epoch[10] Batch [400]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.134281,	
2017-06-28 12:31:25,300 Epoch[10] Batch [410]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.134090,	
2017-06-28 12:31:29,763 Epoch[10] Batch [420]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.133895,	
2017-06-28 12:31:34,012 Epoch[10] Batch [430]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.134063,	
2017-06-28 12:31:38,102 Epoch[10] Batch [440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.133946,	
2017-06-28 12:31:42,565 Epoch[10] Batch [450]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.133972,	
2017-06-28 12:31:47,146 Epoch[10] Batch [460]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.134398,	
2017-06-28 12:31:51,619 Epoch[10] Batch [470]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.134953,	
2017-06-28 12:31:56,085 Epoch[10] Batch [480]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.135251,	
2017-06-28 12:32:00,215 Epoch[10] Batch [490]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.135701,	
2017-06-28 12:32:04,270 Epoch[10] Batch [500]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.136265,	
2017-06-28 12:32:08,545 Epoch[10] Batch [510]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.136439,	
2017-06-28 12:32:13,036 Epoch[10] Batch [520]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.137065,	
2017-06-28 12:32:17,549 Epoch[10] Batch [530]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.137311,	
2017-06-28 12:32:22,194 Epoch[10] Batch [540]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.137358,	
2017-06-28 12:32:26,601 Epoch[10] Batch [550]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.137165,	
2017-06-28 12:32:31,184 Epoch[10] Batch [560]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.137444,	
2017-06-28 12:32:35,667 Epoch[10] Batch [570]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.137502,	
2017-06-28 12:32:39,925 Epoch[10] Batch [580]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.137862,	
2017-06-28 12:32:43,952 Epoch[10] Batch [590]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.137941,	
2017-06-28 12:32:48,607 Epoch[10] Batch [600]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.137807,	
2017-06-28 12:32:52,898 Epoch[10] Batch [610]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.137708,	
2017-06-28 12:32:57,513 Epoch[10] Batch [620]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.137716,	
2017-06-28 12:33:01,712 Epoch[10] Batch [630]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.137642,	
2017-06-28 12:33:06,081 Epoch[10] Batch [640]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.137559,	
2017-06-28 12:33:10,627 Epoch[10] Batch [650]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.137660,	
2017-06-28 12:33:14,862 Epoch[10] Batch [660]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.137685,	
2017-06-28 12:33:19,222 Epoch[10] Batch [670]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.137616,	
2017-06-28 12:33:23,992 Epoch[10] Batch [680]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.137449,	
2017-06-28 12:33:28,832 Epoch[10] Batch [690]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.137399,	
2017-06-28 12:33:33,012 Epoch[10] Batch [700]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.137326,	
2017-06-28 12:33:37,208 Epoch[10] Batch [710]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.137152,	
2017-06-28 12:33:41,781 Epoch[10] Batch [720]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.136848,	
2017-06-28 12:33:46,164 Epoch[10] Batch [730]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.136852,	
2017-06-28 12:33:50,620 Epoch[10] Batch [740]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.136888,	
2017-06-28 12:33:54,943 Epoch[10] Batch [750]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.136926,	
2017-06-28 12:33:59,836 Epoch[10] Batch [760]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.136937,	
2017-06-28 12:34:04,270 Epoch[10] Batch [770]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.136895,	
2017-06-28 12:34:08,906 Epoch[10] Batch [780]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.137018,	
2017-06-28 12:34:13,720 Epoch[10] Batch [790]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.136951,	
2017-06-28 12:34:18,455 Epoch[10] Batch [800]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.136880,	
2017-06-28 12:34:23,282 Epoch[10] Batch [810]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.137208,	
2017-06-28 12:34:27,671 Epoch[10] Batch [820]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.137352,	
2017-06-28 12:34:31,829 Epoch[10] Batch [830]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.137416,	
2017-06-28 12:34:36,012 Epoch[10] Batch [840]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.137449,	
2017-06-28 12:34:40,151 Epoch[10] Batch [850]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.137345,	
2017-06-28 12:34:44,406 Epoch[10] Batch [860]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.137264,	
2017-06-28 12:34:48,544 Epoch[10] Batch [870]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.137326,	
2017-06-28 12:34:52,793 Epoch[10] Batch [880]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.137434,	
2017-06-28 12:34:56,873 Epoch[10] Batch [890]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.137357,	
2017-06-28 12:35:01,320 Epoch[10] Batch [900]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.137448,	
2017-06-28 12:35:05,892 Epoch[10] Batch [910]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.137496,	
2017-06-28 12:35:10,444 Epoch[10] Batch [920]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.137389,	
2017-06-28 12:35:14,954 Epoch[10] Batch [930]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.137493,	
2017-06-28 12:35:19,529 Epoch[10] Batch [940]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.137473,	
2017-06-28 12:35:23,926 Epoch[10] Batch [950]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.137346,	
2017-06-28 12:35:28,245 Epoch[10] Batch [960]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.137333,	
2017-06-28 12:35:32,499 Epoch[10] Batch [970]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.137298,	
2017-06-28 12:35:37,036 Epoch[10] Batch [980]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.137117,	
2017-06-28 12:35:41,599 Epoch[10] Batch [990]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.136925,	
2017-06-28 12:35:46,259 Epoch[10] Batch [1000]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.137136,	
2017-06-28 12:35:50,745 Epoch[10] Batch [1010]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.137201,	
2017-06-28 12:35:54,927 Epoch[10] Batch [1020]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.137153,	
2017-06-28 12:35:59,107 Epoch[10] Batch [1030]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.136958,	
2017-06-28 12:36:03,158 Epoch[10] Batch [1040]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.136991,	
2017-06-28 12:36:07,402 Epoch[10] Batch [1050]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.136973,	
2017-06-28 12:36:12,379 Epoch[10] Batch [1060]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.136692,	
2017-06-28 12:36:16,784 Epoch[10] Batch [1070]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.136674,	
2017-06-28 12:36:21,089 Epoch[10] Batch [1080]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.136625,	
2017-06-28 12:36:25,459 Epoch[10] Batch [1090]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.136697,	
2017-06-28 12:36:30,416 Epoch[10] Batch [1100]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.136753,	
2017-06-28 12:36:34,898 Epoch[10] Batch [1110]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.136718,	
2017-06-28 12:36:38,983 Epoch[10] Batch [1120]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.136655,	
2017-06-28 12:36:43,205 Epoch[10] Batch [1130]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.136636,	
2017-06-28 12:36:47,619 Epoch[10] Batch [1140]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.136715,	
2017-06-28 12:36:52,230 Epoch[10] Batch [1150]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.136743,	
2017-06-28 12:36:56,663 Epoch[10] Batch [1160]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.136588,	
2017-06-28 12:37:00,875 Epoch[10] Batch [1170]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.136785,	
2017-06-28 12:37:05,262 Epoch[10] Batch [1180]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.136804,	
2017-06-28 12:37:09,999 Epoch[10] Batch [1190]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.136816,	
2017-06-28 12:37:14,350 Epoch[10] Batch [1200]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.136797,	
2017-06-28 12:37:19,232 Epoch[10] Batch [1210]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.136645,	
2017-06-28 12:37:23,910 Epoch[10] Batch [1220]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.136713,	
2017-06-28 12:37:28,390 Epoch[10] Batch [1230]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.136630,	
2017-06-28 12:37:32,474 Epoch[10] Batch [1240]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.136599,	
2017-06-28 12:37:36,877 Epoch[10] Batch [1250]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.136536,	
2017-06-28 12:37:40,857 Epoch[10] Batch [1260]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.136870,	
2017-06-28 12:37:45,106 Epoch[10] Batch [1270]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.137016,	
2017-06-28 12:37:49,630 Epoch[10] Batch [1280]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.137011,	
2017-06-28 12:37:54,134 Epoch[10] Batch [1290]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.137050,	
2017-06-28 12:37:58,632 Epoch[10] Batch [1300]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.137036,	
2017-06-28 12:38:02,891 Epoch[10] Batch [1310]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.136923,	
2017-06-28 12:38:07,634 Epoch[10] Batch [1320]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.136833,	
2017-06-28 12:38:12,448 Epoch[10] Batch [1330]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.136785,	
2017-06-28 12:38:17,127 Epoch[10] Batch [1340]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.136918,	
2017-06-28 12:38:21,454 Epoch[10] Batch [1350]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.136826,	
2017-06-28 12:38:25,712 Epoch[10] Batch [1360]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.136857,	
2017-06-28 12:38:29,847 Epoch[10] Batch [1370]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136718,	
2017-06-28 12:38:34,198 Epoch[10] Batch [1380]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.136716,	
2017-06-28 12:38:38,633 Epoch[10] Batch [1390]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.136845,	
2017-06-28 12:38:43,210 Epoch[10] Batch [1400]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.136765,	
2017-06-28 12:38:47,664 Epoch[10] Batch [1410]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.136732,	
2017-06-28 12:38:52,368 Epoch[10] Batch [1420]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.136711,	
2017-06-28 12:38:56,792 Epoch[10] Batch [1430]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.136629,	
2017-06-28 12:39:01,002 Epoch[10] Batch [1440]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.136457,	
2017-06-28 12:39:05,508 Epoch[10] Batch [1450]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.136512,	
2017-06-28 12:39:09,723 Epoch[10] Batch [1460]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.136463,	
2017-06-28 12:39:14,414 Epoch[10] Batch [1470]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.136309,	
2017-06-28 12:39:18,855 Epoch[10] Batch [1480]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.136331,	
2017-06-28 12:39:21,595 Epoch[10] Train-FCNLogLoss=0.136268
2017-06-28 12:39:21,595 Epoch[10] Time cost=660.328
2017-06-28 12:39:22,314 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0011.params"
2017-06-28 12:39:23,952 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0011.states"
2017-06-28 12:39:29,152 Epoch[11] Batch [10]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.131459,	
2017-06-28 12:39:33,809 Epoch[11] Batch [20]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.119474,	
2017-06-28 12:39:38,477 Epoch[11] Batch [30]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.120513,	
2017-06-28 12:39:43,002 Epoch[11] Batch [40]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.126623,	
2017-06-28 12:39:47,542 Epoch[11] Batch [50]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.126893,	
2017-06-28 12:39:51,792 Epoch[11] Batch [60]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.128241,	
2017-06-28 12:39:56,205 Epoch[11] Batch [70]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.132154,	
2017-06-28 12:40:00,852 Epoch[11] Batch [80]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.133574,	
2017-06-28 12:40:05,456 Epoch[11] Batch [90]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.133194,	
2017-06-28 12:40:10,118 Epoch[11] Batch [100]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.134106,	
2017-06-28 12:40:14,653 Epoch[11] Batch [110]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.134746,	
2017-06-28 12:40:19,253 Epoch[11] Batch [120]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.134717,	
2017-06-28 12:40:23,958 Epoch[11] Batch [130]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.133448,	
2017-06-28 12:40:28,305 Epoch[11] Batch [140]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.133570,	
2017-06-28 12:40:33,320 Epoch[11] Batch [150]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.134989,	
2017-06-28 12:40:38,110 Epoch[11] Batch [160]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.133921,	
2017-06-28 12:40:42,474 Epoch[11] Batch [170]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.133420,	
2017-06-28 12:40:47,358 Epoch[11] Batch [180]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.132595,	
2017-06-28 12:40:51,676 Epoch[11] Batch [190]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.132868,	
2017-06-28 12:40:56,402 Epoch[11] Batch [200]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.133090,	
2017-06-28 12:41:01,099 Epoch[11] Batch [210]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.133078,	
2017-06-28 12:41:05,454 Epoch[11] Batch [220]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.132251,	
2017-06-28 12:41:10,104 Epoch[11] Batch [230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.132129,	
2017-06-28 12:41:14,611 Epoch[11] Batch [240]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.131760,	
2017-06-28 12:41:19,112 Epoch[11] Batch [250]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.131090,	
2017-06-28 12:41:23,369 Epoch[11] Batch [260]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.131132,	
2017-06-28 12:41:27,635 Epoch[11] Batch [270]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.130741,	
2017-06-28 12:41:32,167 Epoch[11] Batch [280]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.131194,	
2017-06-28 12:41:36,515 Epoch[11] Batch [290]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.131298,	
2017-06-28 12:41:40,803 Epoch[11] Batch [300]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.131593,	
2017-06-28 12:41:45,062 Epoch[11] Batch [310]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.131673,	
2017-06-28 12:41:49,291 Epoch[11] Batch [320]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.131689,	
2017-06-28 12:41:54,194 Epoch[11] Batch [330]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.131538,	
2017-06-28 12:41:58,484 Epoch[11] Batch [340]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.131639,	
2017-06-28 12:42:02,892 Epoch[11] Batch [350]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.131669,	
2017-06-28 12:42:07,344 Epoch[11] Batch [360]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.131508,	
2017-06-28 12:42:12,318 Epoch[11] Batch [370]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.131684,	
2017-06-28 12:42:17,215 Epoch[11] Batch [380]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.132329,	
2017-06-28 12:42:21,880 Epoch[11] Batch [390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.132879,	
2017-06-28 12:42:26,038 Epoch[11] Batch [400]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.133833,	
2017-06-28 12:42:30,732 Epoch[11] Batch [410]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.134296,	
2017-06-28 12:42:35,333 Epoch[11] Batch [420]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.134155,	
2017-06-28 12:42:39,759 Epoch[11] Batch [430]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.133965,	
2017-06-28 12:42:44,233 Epoch[11] Batch [440]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.134171,	
2017-06-28 12:42:48,561 Epoch[11] Batch [450]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.134379,	
2017-06-28 12:42:53,175 Epoch[11] Batch [460]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.134652,	
2017-06-28 12:42:57,405 Epoch[11] Batch [470]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.134665,	
2017-06-28 12:43:02,094 Epoch[11] Batch [480]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.134699,	
2017-06-28 12:43:06,557 Epoch[11] Batch [490]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.134869,	
2017-06-28 12:43:10,746 Epoch[11] Batch [500]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.134525,	
2017-06-28 12:43:15,103 Epoch[11] Batch [510]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.134727,	
2017-06-28 12:43:19,665 Epoch[11] Batch [520]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.134662,	
2017-06-28 12:43:24,446 Epoch[11] Batch [530]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.134344,	
2017-06-28 12:43:28,827 Epoch[11] Batch [540]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.134101,	
2017-06-28 12:43:33,253 Epoch[11] Batch [550]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.133868,	
2017-06-28 12:43:37,812 Epoch[11] Batch [560]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.133974,	
2017-06-28 12:43:42,151 Epoch[11] Batch [570]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.134080,	
2017-06-28 12:43:46,724 Epoch[11] Batch [580]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.133773,	
2017-06-28 12:43:51,341 Epoch[11] Batch [590]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.133634,	
2017-06-28 12:43:55,856 Epoch[11] Batch [600]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.133519,	
2017-06-28 12:44:00,370 Epoch[11] Batch [610]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.133549,	
2017-06-28 12:44:04,927 Epoch[11] Batch [620]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.133531,	
2017-06-28 12:44:09,926 Epoch[11] Batch [630]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.133279,	
2017-06-28 12:44:14,658 Epoch[11] Batch [640]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.133440,	
2017-06-28 12:44:19,288 Epoch[11] Batch [650]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.133178,	
2017-06-28 12:44:23,942 Epoch[11] Batch [660]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.132992,	
2017-06-28 12:44:28,522 Epoch[11] Batch [670]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.132793,	
2017-06-28 12:44:32,760 Epoch[11] Batch [680]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.132855,	
2017-06-28 12:44:37,382 Epoch[11] Batch [690]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.132942,	
2017-06-28 12:44:41,807 Epoch[11] Batch [700]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.132745,	
2017-06-28 12:44:46,372 Epoch[11] Batch [710]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.132711,	
2017-06-28 12:44:51,088 Epoch[11] Batch [720]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.132613,	
2017-06-28 12:44:55,524 Epoch[11] Batch [730]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.132680,	
2017-06-28 12:45:00,310 Epoch[11] Batch [740]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.132655,	
2017-06-28 12:45:04,943 Epoch[11] Batch [750]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132941,	
2017-06-28 12:45:09,339 Epoch[11] Batch [760]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.132983,	
2017-06-28 12:45:13,744 Epoch[11] Batch [770]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.133132,	
2017-06-28 12:45:17,816 Epoch[11] Batch [780]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.133031,	
2017-06-28 12:45:22,240 Epoch[11] Batch [790]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.133145,	
2017-06-28 12:45:26,617 Epoch[11] Batch [800]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.133018,	
2017-06-28 12:45:31,278 Epoch[11] Batch [810]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.133181,	
2017-06-28 12:45:35,865 Epoch[11] Batch [820]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.133209,	
2017-06-28 12:45:40,595 Epoch[11] Batch [830]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.133165,	
2017-06-28 12:45:44,920 Epoch[11] Batch [840]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.133211,	
2017-06-28 12:45:49,239 Epoch[11] Batch [850]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.133283,	
2017-06-28 12:45:53,358 Epoch[11] Batch [860]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.133080,	
2017-06-28 12:45:57,791 Epoch[11] Batch [870]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.133147,	
2017-06-28 12:46:02,417 Epoch[11] Batch [880]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.133129,	
2017-06-28 12:46:06,848 Epoch[11] Batch [890]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.133099,	
2017-06-28 12:46:11,275 Epoch[11] Batch [900]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.133040,	
2017-06-28 12:46:15,673 Epoch[11] Batch [910]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.132905,	
2017-06-28 12:46:20,005 Epoch[11] Batch [920]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.132751,	
2017-06-28 12:46:24,225 Epoch[11] Batch [930]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.132674,	
2017-06-28 12:46:28,593 Epoch[11] Batch [940]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.132522,	
2017-06-28 12:46:32,754 Epoch[11] Batch [950]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.132727,	
2017-06-28 12:46:37,020 Epoch[11] Batch [960]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.132617,	
2017-06-28 12:46:41,245 Epoch[11] Batch [970]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.132700,	
2017-06-28 12:46:45,681 Epoch[11] Batch [980]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.132513,	
2017-06-28 12:46:50,387 Epoch[11] Batch [990]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.132306,	
2017-06-28 12:46:54,888 Epoch[11] Batch [1000]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.132572,	
2017-06-28 12:46:59,308 Epoch[11] Batch [1010]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.132557,	
2017-06-28 12:47:03,940 Epoch[11] Batch [1020]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.132772,	
2017-06-28 12:47:08,547 Epoch[11] Batch [1030]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.132880,	
2017-06-28 12:47:12,813 Epoch[11] Batch [1040]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.132870,	
2017-06-28 12:47:16,919 Epoch[11] Batch [1050]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.132807,	
2017-06-28 12:47:20,898 Epoch[11] Batch [1060]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.132828,	
2017-06-28 12:47:25,287 Epoch[11] Batch [1070]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.132827,	
2017-06-28 12:47:29,601 Epoch[11] Batch [1080]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.132764,	
2017-06-28 12:47:33,929 Epoch[11] Batch [1090]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.132914,	
2017-06-28 12:47:38,573 Epoch[11] Batch [1100]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.133037,	
2017-06-28 12:47:42,933 Epoch[11] Batch [1110]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.133117,	
2017-06-28 12:47:47,552 Epoch[11] Batch [1120]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.133034,	
2017-06-28 12:47:52,205 Epoch[11] Batch [1130]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.132995,	
2017-06-28 12:47:56,864 Epoch[11] Batch [1140]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.132935,	
2017-06-28 12:48:01,372 Epoch[11] Batch [1150]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.132861,	
2017-06-28 12:48:05,764 Epoch[11] Batch [1160]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.132852,	
2017-06-28 12:48:10,050 Epoch[11] Batch [1170]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.132910,	
2017-06-28 12:48:14,815 Epoch[11] Batch [1180]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.132884,	
2017-06-28 12:48:19,114 Epoch[11] Batch [1190]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.132838,	
2017-06-28 12:48:23,797 Epoch[11] Batch [1200]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.132858,	
2017-06-28 12:48:28,201 Epoch[11] Batch [1210]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.132794,	
2017-06-28 12:48:32,460 Epoch[11] Batch [1220]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.132897,	
2017-06-28 12:48:36,532 Epoch[11] Batch [1230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.132866,	
2017-06-28 12:48:41,423 Epoch[11] Batch [1240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.132868,	
2017-06-28 12:48:46,152 Epoch[11] Batch [1250]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.132882,	
2017-06-28 12:48:50,398 Epoch[11] Batch [1260]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.132830,	
2017-06-28 12:48:54,636 Epoch[11] Batch [1270]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.132878,	
2017-06-28 12:48:58,672 Epoch[11] Batch [1280]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.132772,	
2017-06-28 12:49:02,958 Epoch[11] Batch [1290]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.132694,	
2017-06-28 12:49:07,516 Epoch[11] Batch [1300]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.132701,	
2017-06-28 12:49:11,915 Epoch[11] Batch [1310]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.132648,	
2017-06-28 12:49:15,996 Epoch[11] Batch [1320]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.132519,	
2017-06-28 12:49:20,388 Epoch[11] Batch [1330]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.132418,	
2017-06-28 12:49:24,787 Epoch[11] Batch [1340]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.132299,	
2017-06-28 12:49:29,233 Epoch[11] Batch [1350]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.132263,	
2017-06-28 12:49:33,442 Epoch[11] Batch [1360]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.132194,	
2017-06-28 12:49:37,582 Epoch[11] Batch [1370]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.132160,	
2017-06-28 12:49:41,668 Epoch[11] Batch [1380]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.132279,	
2017-06-28 12:49:46,126 Epoch[11] Batch [1390]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.132315,	
2017-06-28 12:49:50,386 Epoch[11] Batch [1400]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.132285,	
2017-06-28 12:49:54,467 Epoch[11] Batch [1410]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.132221,	
2017-06-28 12:49:58,678 Epoch[11] Batch [1420]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.132142,	
2017-06-28 12:50:03,435 Epoch[11] Batch [1430]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.132126,	
2017-06-28 12:50:07,775 Epoch[11] Batch [1440]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.132062,	
2017-06-28 12:50:12,509 Epoch[11] Batch [1450]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.132197,	
2017-06-28 12:50:17,268 Epoch[11] Batch [1460]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.132141,	
2017-06-28 12:50:22,029 Epoch[11] Batch [1470]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.132108,	
2017-06-28 12:50:26,777 Epoch[11] Batch [1480]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.132276,	
2017-06-28 12:50:29,272 Epoch[11] Train-FCNLogLoss=0.132310
2017-06-28 12:50:29,272 Epoch[11] Time cost=665.320
2017-06-28 12:50:29,962 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0012.params"
2017-06-28 12:50:31,614 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0012.states"
2017-06-28 12:50:36,780 Epoch[12] Batch [10]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.129148,	
2017-06-28 12:50:40,985 Epoch[12] Batch [20]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.127570,	
2017-06-28 12:50:45,139 Epoch[12] Batch [30]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.129528,	
2017-06-28 12:50:49,352 Epoch[12] Batch [40]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.127897,	
2017-06-28 12:50:53,958 Epoch[12] Batch [50]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.130833,	
2017-06-28 12:50:58,679 Epoch[12] Batch [60]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.127519,	
2017-06-28 12:51:03,284 Epoch[12] Batch [70]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.127367,	
2017-06-28 12:51:07,898 Epoch[12] Batch [80]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.127028,	
2017-06-28 12:51:12,766 Epoch[12] Batch [90]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.128545,	
2017-06-28 12:51:17,159 Epoch[12] Batch [100]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.126748,	
2017-06-28 12:51:21,906 Epoch[12] Batch [110]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.126505,	
2017-06-28 12:51:26,322 Epoch[12] Batch [120]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.126588,	
2017-06-28 12:51:30,826 Epoch[12] Batch [130]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.125376,	
2017-06-28 12:51:35,026 Epoch[12] Batch [140]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.124702,	
2017-06-28 12:51:39,389 Epoch[12] Batch [150]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.124316,	
2017-06-28 12:51:44,186 Epoch[12] Batch [160]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.124788,	
2017-06-28 12:51:48,799 Epoch[12] Batch [170]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.124473,	
2017-06-28 12:51:53,377 Epoch[12] Batch [180]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.124378,	
2017-06-28 12:51:57,767 Epoch[12] Batch [190]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.124097,	
2017-06-28 12:52:02,501 Epoch[12] Batch [200]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.124529,	
2017-06-28 12:52:06,903 Epoch[12] Batch [210]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.125465,	
2017-06-28 12:52:11,402 Epoch[12] Batch [220]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.125487,	
2017-06-28 12:52:15,859 Epoch[12] Batch [230]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.125042,	
2017-06-28 12:52:20,291 Epoch[12] Batch [240]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.125206,	
2017-06-28 12:52:25,031 Epoch[12] Batch [250]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.125537,	
2017-06-28 12:52:29,359 Epoch[12] Batch [260]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.125916,	
2017-06-28 12:52:33,762 Epoch[12] Batch [270]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.125747,	
2017-06-28 12:52:38,114 Epoch[12] Batch [280]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.126257,	
2017-06-28 12:52:42,881 Epoch[12] Batch [290]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.126338,	
2017-06-28 12:52:47,431 Epoch[12] Batch [300]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.126527,	
2017-06-28 12:52:51,771 Epoch[12] Batch [310]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.126971,	
2017-06-28 12:52:56,172 Epoch[12] Batch [320]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.126911,	
2017-06-28 12:53:00,637 Epoch[12] Batch [330]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.127474,	
2017-06-28 12:53:04,994 Epoch[12] Batch [340]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.128328,	
2017-06-28 12:53:09,368 Epoch[12] Batch [350]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.128325,	
2017-06-28 12:53:13,553 Epoch[12] Batch [360]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.129233,	
2017-06-28 12:53:17,744 Epoch[12] Batch [370]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.129234,	
2017-06-28 12:53:22,029 Epoch[12] Batch [380]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.129531,	
2017-06-28 12:53:26,469 Epoch[12] Batch [390]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.129336,	
2017-06-28 12:53:31,055 Epoch[12] Batch [400]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.129426,	
2017-06-28 12:53:35,781 Epoch[12] Batch [410]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.129341,	
2017-06-28 12:53:40,548 Epoch[12] Batch [420]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.128990,	
2017-06-28 12:53:45,109 Epoch[12] Batch [430]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.128757,	
2017-06-28 12:53:49,489 Epoch[12] Batch [440]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.128959,	
2017-06-28 12:53:53,790 Epoch[12] Batch [450]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.128837,	
2017-06-28 12:53:58,253 Epoch[12] Batch [460]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.128716,	
2017-06-28 12:54:02,342 Epoch[12] Batch [470]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.128630,	
2017-06-28 12:54:06,582 Epoch[12] Batch [480]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.128873,	
2017-06-28 12:54:10,752 Epoch[12] Batch [490]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.128794,	
2017-06-28 12:54:15,570 Epoch[12] Batch [500]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.128966,	
2017-06-28 12:54:19,980 Epoch[12] Batch [510]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.129257,	
2017-06-28 12:54:24,278 Epoch[12] Batch [520]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.129131,	
2017-06-28 12:54:28,478 Epoch[12] Batch [530]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.129061,	
2017-06-28 12:54:32,438 Epoch[12] Batch [540]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129581,	
2017-06-28 12:54:36,412 Epoch[12] Batch [550]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.129293,	
2017-06-28 12:54:40,683 Epoch[12] Batch [560]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.129220,	
2017-06-28 12:54:45,017 Epoch[12] Batch [570]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.129395,	
2017-06-28 12:54:49,394 Epoch[12] Batch [580]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.129601,	
2017-06-28 12:54:54,082 Epoch[12] Batch [590]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.129447,	
2017-06-28 12:54:58,675 Epoch[12] Batch [600]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.129296,	
2017-06-28 12:55:02,804 Epoch[12] Batch [610]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.129109,	
2017-06-28 12:55:07,475 Epoch[12] Batch [620]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.128946,	
2017-06-28 12:55:12,054 Epoch[12] Batch [630]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.129289,	
2017-06-28 12:55:16,342 Epoch[12] Batch [640]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.129358,	
2017-06-28 12:55:20,817 Epoch[12] Batch [650]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.129206,	
2017-06-28 12:55:25,128 Epoch[12] Batch [660]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.129143,	
2017-06-28 12:55:29,149 Epoch[12] Batch [670]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.129301,	
2017-06-28 12:55:33,532 Epoch[12] Batch [680]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.129127,	
2017-06-28 12:55:38,227 Epoch[12] Batch [690]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.129164,	
2017-06-28 12:55:42,363 Epoch[12] Batch [700]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.129097,	
2017-06-28 12:55:46,961 Epoch[12] Batch [710]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.129129,	
2017-06-28 12:55:51,164 Epoch[12] Batch [720]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.128905,	
2017-06-28 12:55:55,573 Epoch[12] Batch [730]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.128829,	
2017-06-28 12:55:59,975 Epoch[12] Batch [740]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.128897,	
2017-06-28 12:56:04,316 Epoch[12] Batch [750]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.128958,	
2017-06-28 12:56:08,604 Epoch[12] Batch [760]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.129169,	
2017-06-28 12:56:12,929 Epoch[12] Batch [770]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.129312,	
2017-06-28 12:56:17,161 Epoch[12] Batch [780]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.129280,	
2017-06-28 12:56:21,912 Epoch[12] Batch [790]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.129560,	
2017-06-28 12:56:26,789 Epoch[12] Batch [800]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.129545,	
2017-06-28 12:56:31,411 Epoch[12] Batch [810]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.129571,	
2017-06-28 12:56:36,443 Epoch[12] Batch [820]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.129674,	
2017-06-28 12:56:40,808 Epoch[12] Batch [830]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.129624,	
2017-06-28 12:56:45,330 Epoch[12] Batch [840]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.129515,	
2017-06-28 12:56:49,795 Epoch[12] Batch [850]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.129543,	
2017-06-28 12:56:54,322 Epoch[12] Batch [860]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.129973,	
2017-06-28 12:56:58,942 Epoch[12] Batch [870]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.129993,	
2017-06-28 12:57:03,400 Epoch[12] Batch [880]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.129890,	
2017-06-28 12:57:07,800 Epoch[12] Batch [890]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.129827,	
2017-06-28 12:57:12,270 Epoch[12] Batch [900]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.129941,	
2017-06-28 12:57:16,603 Epoch[12] Batch [910]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.130108,	
2017-06-28 12:57:20,809 Epoch[12] Batch [920]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.130239,	
2017-06-28 12:57:25,088 Epoch[12] Batch [930]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.130157,	
2017-06-28 12:57:29,655 Epoch[12] Batch [940]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.130122,	
2017-06-28 12:57:34,058 Epoch[12] Batch [950]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.130082,	
2017-06-28 12:57:38,304 Epoch[12] Batch [960]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.129972,	
2017-06-28 12:57:42,502 Epoch[12] Batch [970]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.129993,	
2017-06-28 12:57:46,927 Epoch[12] Batch [980]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.130141,	
2017-06-28 12:57:51,442 Epoch[12] Batch [990]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.130371,	
2017-06-28 12:57:56,097 Epoch[12] Batch [1000]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.130388,	
2017-06-28 12:58:00,990 Epoch[12] Batch [1010]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.130369,	
2017-06-28 12:58:05,460 Epoch[12] Batch [1020]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.130463,	
2017-06-28 12:58:09,858 Epoch[12] Batch [1030]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.130592,	
2017-06-28 12:58:14,424 Epoch[12] Batch [1040]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.130676,	
2017-06-28 12:58:19,036 Epoch[12] Batch [1050]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.130518,	
2017-06-28 12:58:23,335 Epoch[12] Batch [1060]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.130541,	
2017-06-28 12:58:27,871 Epoch[12] Batch [1070]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.130571,	
2017-06-28 12:58:31,956 Epoch[12] Batch [1080]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.130428,	
2017-06-28 12:58:36,168 Epoch[12] Batch [1090]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.130363,	
2017-06-28 12:58:40,696 Epoch[12] Batch [1100]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.130256,	
2017-06-28 12:58:45,053 Epoch[12] Batch [1110]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.130314,	
2017-06-28 12:58:49,358 Epoch[12] Batch [1120]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.130242,	
2017-06-28 12:58:53,499 Epoch[12] Batch [1130]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.130279,	
2017-06-28 12:58:57,902 Epoch[12] Batch [1140]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.130265,	
2017-06-28 12:59:02,481 Epoch[12] Batch [1150]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.130358,	
2017-06-28 12:59:07,207 Epoch[12] Batch [1160]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.130268,	
2017-06-28 12:59:11,732 Epoch[12] Batch [1170]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.130201,	
2017-06-28 12:59:16,011 Epoch[12] Batch [1180]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.129994,	
2017-06-28 12:59:20,336 Epoch[12] Batch [1190]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.129873,	
2017-06-28 12:59:24,967 Epoch[12] Batch [1200]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.129701,	
2017-06-28 12:59:29,448 Epoch[12] Batch [1210]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.129842,	
2017-06-28 12:59:33,937 Epoch[12] Batch [1220]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.129905,	
2017-06-28 12:59:38,179 Epoch[12] Batch [1230]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.130000,	
2017-06-28 12:59:42,601 Epoch[12] Batch [1240]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.130063,	
2017-06-28 12:59:46,863 Epoch[12] Batch [1250]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.130018,	
2017-06-28 12:59:50,988 Epoch[12] Batch [1260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.129967,	
2017-06-28 12:59:55,722 Epoch[12] Batch [1270]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.129930,	
2017-06-28 13:00:00,203 Epoch[12] Batch [1280]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.129938,	
2017-06-28 13:00:04,776 Epoch[12] Batch [1290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.129901,	
2017-06-28 13:00:09,218 Epoch[12] Batch [1300]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.129916,	
2017-06-28 13:00:13,859 Epoch[12] Batch [1310]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.129927,	
2017-06-28 13:00:18,285 Epoch[12] Batch [1320]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.129886,	
2017-06-28 13:00:22,648 Epoch[12] Batch [1330]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.129925,	
2017-06-28 13:00:26,862 Epoch[12] Batch [1340]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.129909,	
2017-06-28 13:00:31,298 Epoch[12] Batch [1350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.129924,	
2017-06-28 13:00:35,487 Epoch[12] Batch [1360]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.129953,	
2017-06-28 13:00:40,256 Epoch[12] Batch [1370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.129947,	
2017-06-28 13:00:44,869 Epoch[12] Batch [1380]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.130083,	
2017-06-28 13:00:49,169 Epoch[12] Batch [1390]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.130029,	
2017-06-28 13:00:53,751 Epoch[12] Batch [1400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.130089,	
2017-06-28 13:00:58,086 Epoch[12] Batch [1410]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.130039,	
2017-06-28 13:01:02,955 Epoch[12] Batch [1420]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.130008,	
2017-06-28 13:01:07,311 Epoch[12] Batch [1430]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.129906,	
2017-06-28 13:01:11,909 Epoch[12] Batch [1440]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.129895,	
2017-06-28 13:01:16,702 Epoch[12] Batch [1450]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.129859,	
2017-06-28 13:01:21,036 Epoch[12] Batch [1460]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.129682,	
2017-06-28 13:01:25,883 Epoch[12] Batch [1470]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.129576,	
2017-06-28 13:01:30,406 Epoch[12] Batch [1480]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.129488,	
2017-06-28 13:01:32,917 Epoch[12] Train-FCNLogLoss=0.129460
2017-06-28 13:01:32,917 Epoch[12] Time cost=661.303
2017-06-28 13:01:33,688 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0013.params"
2017-06-28 13:01:35,294 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0013.states"
2017-06-28 13:01:40,395 Epoch[13] Batch [10]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.121707,	
2017-06-28 13:01:44,783 Epoch[13] Batch [20]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.119223,	
2017-06-28 13:01:49,486 Epoch[13] Batch [30]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.117699,	
2017-06-28 13:01:54,207 Epoch[13] Batch [40]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.121549,	
2017-06-28 13:01:58,616 Epoch[13] Batch [50]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.123576,	
2017-06-28 13:02:03,024 Epoch[13] Batch [60]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.127248,	
2017-06-28 13:02:07,733 Epoch[13] Batch [70]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.127342,	
2017-06-28 13:02:12,350 Epoch[13] Batch [80]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.127656,	
2017-06-28 13:02:17,072 Epoch[13] Batch [90]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.128839,	
2017-06-28 13:02:21,647 Epoch[13] Batch [100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.129172,	
2017-06-28 13:02:26,315 Epoch[13] Batch [110]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.129891,	
2017-06-28 13:02:30,809 Epoch[13] Batch [120]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.129625,	
2017-06-28 13:02:35,319 Epoch[13] Batch [130]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.130509,	
2017-06-28 13:02:39,546 Epoch[13] Batch [140]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.129338,	
2017-06-28 13:02:43,807 Epoch[13] Batch [150]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.128653,	
2017-06-28 13:02:48,493 Epoch[13] Batch [160]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.128262,	
2017-06-28 13:02:52,921 Epoch[13] Batch [170]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.129284,	
2017-06-28 13:02:57,078 Epoch[13] Batch [180]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.128629,	
2017-06-28 13:03:01,692 Epoch[13] Batch [190]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.127625,	
2017-06-28 13:03:06,040 Epoch[13] Batch [200]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.126904,	
2017-06-28 13:03:10,744 Epoch[13] Batch [210]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.125655,	
2017-06-28 13:03:15,473 Epoch[13] Batch [220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.125450,	
2017-06-28 13:03:19,955 Epoch[13] Batch [230]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.125664,	
2017-06-28 13:03:24,632 Epoch[13] Batch [240]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.125622,	
2017-06-28 13:03:29,331 Epoch[13] Batch [250]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.125468,	
2017-06-28 13:03:33,703 Epoch[13] Batch [260]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.125094,	
2017-06-28 13:03:38,415 Epoch[13] Batch [270]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.125194,	
2017-06-28 13:03:42,870 Epoch[13] Batch [280]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.125026,	
2017-06-28 13:03:47,326 Epoch[13] Batch [290]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.124452,	
2017-06-28 13:03:51,537 Epoch[13] Batch [300]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.124588,	
2017-06-28 13:03:55,817 Epoch[13] Batch [310]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.124748,	
2017-06-28 13:04:00,187 Epoch[13] Batch [320]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.124703,	
2017-06-28 13:04:04,981 Epoch[13] Batch [330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.124701,	
2017-06-28 13:04:09,654 Epoch[13] Batch [340]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124891,	
2017-06-28 13:04:13,723 Epoch[13] Batch [350]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.124863,	
2017-06-28 13:04:17,662 Epoch[13] Batch [360]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.124960,	
2017-06-28 13:04:22,042 Epoch[13] Batch [370]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.125106,	
2017-06-28 13:04:26,805 Epoch[13] Batch [380]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.125027,	
2017-06-28 13:04:31,350 Epoch[13] Batch [390]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.125237,	
2017-06-28 13:04:35,682 Epoch[13] Batch [400]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.125317,	
2017-06-28 13:04:40,532 Epoch[13] Batch [410]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.125102,	
2017-06-28 13:04:44,652 Epoch[13] Batch [420]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.125476,	
2017-06-28 13:04:48,924 Epoch[13] Batch [430]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.125667,	
2017-06-28 13:04:53,455 Epoch[13] Batch [440]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.125716,	
2017-06-28 13:04:57,768 Epoch[13] Batch [450]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.125649,	
2017-06-28 13:05:02,226 Epoch[13] Batch [460]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.126008,	
2017-06-28 13:05:06,701 Epoch[13] Batch [470]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.126143,	
2017-06-28 13:05:11,068 Epoch[13] Batch [480]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.127799,	
2017-06-28 13:05:15,471 Epoch[13] Batch [490]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.127961,	
2017-06-28 13:05:19,715 Epoch[13] Batch [500]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.127894,	
2017-06-28 13:05:24,121 Epoch[13] Batch [510]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.127766,	
2017-06-28 13:05:28,519 Epoch[13] Batch [520]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.127566,	
2017-06-28 13:05:32,992 Epoch[13] Batch [530]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.127448,	
2017-06-28 13:05:37,326 Epoch[13] Batch [540]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.127419,	
2017-06-28 13:05:41,634 Epoch[13] Batch [550]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.127377,	
2017-06-28 13:05:46,026 Epoch[13] Batch [560]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.127316,	
2017-06-28 13:05:50,378 Epoch[13] Batch [570]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.127262,	
2017-06-28 13:05:54,792 Epoch[13] Batch [580]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.127424,	
2017-06-28 13:05:59,206 Epoch[13] Batch [590]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.127507,	
2017-06-28 13:06:03,577 Epoch[13] Batch [600]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.127498,	
2017-06-28 13:06:08,097 Epoch[13] Batch [610]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.127391,	
2017-06-28 13:06:12,460 Epoch[13] Batch [620]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.127037,	
2017-06-28 13:06:16,969 Epoch[13] Batch [630]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.127080,	
2017-06-28 13:06:21,579 Epoch[13] Batch [640]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.127108,	
2017-06-28 13:06:25,609 Epoch[13] Batch [650]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.127048,	
2017-06-28 13:06:30,138 Epoch[13] Batch [660]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.127024,	
2017-06-28 13:06:34,863 Epoch[13] Batch [670]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.127145,	
2017-06-28 13:06:39,258 Epoch[13] Batch [680]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.128033,	
2017-06-28 13:06:43,954 Epoch[13] Batch [690]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.129166,	
2017-06-28 13:06:48,734 Epoch[13] Batch [700]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.129668,	
2017-06-28 13:06:53,457 Epoch[13] Batch [710]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.129788,	
2017-06-28 13:06:58,262 Epoch[13] Batch [720]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.129745,	
2017-06-28 13:07:02,955 Epoch[13] Batch [730]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.129533,	
2017-06-28 13:07:07,817 Epoch[13] Batch [740]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.129505,	
2017-06-28 13:07:12,325 Epoch[13] Batch [750]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.129444,	
2017-06-28 13:07:16,581 Epoch[13] Batch [760]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.129335,	
2017-06-28 13:07:21,323 Epoch[13] Batch [770]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.129325,	
2017-06-28 13:07:25,886 Epoch[13] Batch [780]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.129450,	
2017-06-28 13:07:30,691 Epoch[13] Batch [790]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.129528,	
2017-06-28 13:07:35,133 Epoch[13] Batch [800]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.129526,	
2017-06-28 13:07:39,373 Epoch[13] Batch [810]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.129449,	
2017-06-28 13:07:43,480 Epoch[13] Batch [820]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129611,	
2017-06-28 13:07:47,919 Epoch[13] Batch [830]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.129556,	
2017-06-28 13:07:52,380 Epoch[13] Batch [840]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.129380,	
2017-06-28 13:07:56,884 Epoch[13] Batch [850]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.129300,	
2017-06-28 13:08:01,877 Epoch[13] Batch [860]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.129298,	
2017-06-28 13:08:06,425 Epoch[13] Batch [870]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.129257,	
2017-06-28 13:08:10,953 Epoch[13] Batch [880]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.129254,	
2017-06-28 13:08:15,477 Epoch[13] Batch [890]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.129471,	
2017-06-28 13:08:19,868 Epoch[13] Batch [900]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.129441,	
2017-06-28 13:08:24,470 Epoch[13] Batch [910]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.129466,	
2017-06-28 13:08:28,802 Epoch[13] Batch [920]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.129526,	
2017-06-28 13:08:33,082 Epoch[13] Batch [930]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.129673,	
2017-06-28 13:08:37,660 Epoch[13] Batch [940]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.129840,	
2017-06-28 13:08:42,265 Epoch[13] Batch [950]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.129787,	
2017-06-28 13:08:46,745 Epoch[13] Batch [960]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.129769,	
2017-06-28 13:08:51,785 Epoch[13] Batch [970]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.129826,	
2017-06-28 13:08:56,611 Epoch[13] Batch [980]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.129898,	
2017-06-28 13:09:01,123 Epoch[13] Batch [990]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.129821,	
2017-06-28 13:09:05,632 Epoch[13] Batch [1000]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.129731,	
2017-06-28 13:09:10,422 Epoch[13] Batch [1010]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.129693,	
2017-06-28 13:09:15,319 Epoch[13] Batch [1020]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.129757,	
2017-06-28 13:09:20,017 Epoch[13] Batch [1030]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.129764,	
2017-06-28 13:09:24,543 Epoch[13] Batch [1040]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.129575,	
2017-06-28 13:09:28,902 Epoch[13] Batch [1050]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.129422,	
2017-06-28 13:09:32,858 Epoch[13] Batch [1060]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.129456,	
2017-06-28 13:09:37,418 Epoch[13] Batch [1070]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.129540,	
2017-06-28 13:09:42,046 Epoch[13] Batch [1080]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.129460,	
2017-06-28 13:09:46,374 Epoch[13] Batch [1090]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.129310,	
2017-06-28 13:09:50,936 Epoch[13] Batch [1100]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.129139,	
2017-06-28 13:09:55,389 Epoch[13] Batch [1110]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.129121,	
2017-06-28 13:09:59,993 Epoch[13] Batch [1120]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.129157,	
2017-06-28 13:10:04,539 Epoch[13] Batch [1130]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.129048,	
2017-06-28 13:10:09,023 Epoch[13] Batch [1140]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.129123,	
2017-06-28 13:10:13,272 Epoch[13] Batch [1150]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.129168,	
2017-06-28 13:10:18,081 Epoch[13] Batch [1160]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.129053,	
2017-06-28 13:10:22,844 Epoch[13] Batch [1170]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.129085,	
2017-06-28 13:10:27,217 Epoch[13] Batch [1180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.129045,	
2017-06-28 13:10:31,613 Epoch[13] Batch [1190]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.129025,	
2017-06-28 13:10:35,688 Epoch[13] Batch [1200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.128917,	
2017-06-28 13:10:39,925 Epoch[13] Batch [1210]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.128841,	
2017-06-28 13:10:44,176 Epoch[13] Batch [1220]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.128907,	
2017-06-28 13:10:48,473 Epoch[13] Batch [1230]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.128965,	
2017-06-28 13:10:52,901 Epoch[13] Batch [1240]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.129071,	
2017-06-28 13:10:57,778 Epoch[13] Batch [1250]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.129077,	
2017-06-28 13:11:02,152 Epoch[13] Batch [1260]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.129049,	
2017-06-28 13:11:06,628 Epoch[13] Batch [1270]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.129173,	
2017-06-28 13:11:10,835 Epoch[13] Batch [1280]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.129045,	
2017-06-28 13:11:15,427 Epoch[13] Batch [1290]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.129087,	
2017-06-28 13:11:19,789 Epoch[13] Batch [1300]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.129043,	
2017-06-28 13:11:24,165 Epoch[13] Batch [1310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.128954,	
2017-06-28 13:11:28,573 Epoch[13] Batch [1320]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.128866,	
2017-06-28 13:11:32,753 Epoch[13] Batch [1330]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.128681,	
2017-06-28 13:11:37,061 Epoch[13] Batch [1340]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.128699,	
2017-06-28 13:11:41,529 Epoch[13] Batch [1350]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.128648,	
2017-06-28 13:11:46,331 Epoch[13] Batch [1360]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.128530,	
2017-06-28 13:11:51,064 Epoch[13] Batch [1370]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.128436,	
2017-06-28 13:11:55,704 Epoch[13] Batch [1380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.128397,	
2017-06-28 13:12:00,479 Epoch[13] Batch [1390]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.128359,	
2017-06-28 13:12:04,767 Epoch[13] Batch [1400]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.128328,	
2017-06-28 13:12:08,900 Epoch[13] Batch [1410]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.128399,	
2017-06-28 13:12:13,418 Epoch[13] Batch [1420]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.128309,	
2017-06-28 13:12:17,858 Epoch[13] Batch [1430]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.128309,	
2017-06-28 13:12:22,169 Epoch[13] Batch [1440]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.128404,	
2017-06-28 13:12:26,715 Epoch[13] Batch [1450]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128330,	
2017-06-28 13:12:31,395 Epoch[13] Batch [1460]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.128292,	
2017-06-28 13:12:35,771 Epoch[13] Batch [1470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.128268,	
2017-06-28 13:12:40,653 Epoch[13] Batch [1480]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.128170,	
2017-06-28 13:12:43,460 Epoch[13] Train-FCNLogLoss=0.128169
2017-06-28 13:12:43,460 Epoch[13] Time cost=668.165
2017-06-28 13:12:44,174 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0014.params"
2017-06-28 13:12:45,695 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0014.states"
2017-06-28 13:12:50,890 Epoch[14] Batch [10]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.144311,	
2017-06-28 13:12:55,343 Epoch[14] Batch [20]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.134205,	
2017-06-28 13:13:00,194 Epoch[14] Batch [30]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.125771,	
2017-06-28 13:13:04,745 Epoch[14] Batch [40]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.122181,	
2017-06-28 13:13:09,251 Epoch[14] Batch [50]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.120870,	
2017-06-28 13:13:13,567 Epoch[14] Batch [60]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.121175,	
2017-06-28 13:13:18,090 Epoch[14] Batch [70]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.121686,	
2017-06-28 13:13:22,320 Epoch[14] Batch [80]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.121186,	
2017-06-28 13:13:26,724 Epoch[14] Batch [90]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.123227,	
2017-06-28 13:13:31,412 Epoch[14] Batch [100]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.123089,	
2017-06-28 13:13:35,597 Epoch[14] Batch [110]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.122712,	
2017-06-28 13:13:39,600 Epoch[14] Batch [120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.123321,	
2017-06-28 13:13:44,005 Epoch[14] Batch [130]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.124376,	
2017-06-28 13:13:48,530 Epoch[14] Batch [140]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.124897,	
2017-06-28 13:13:53,043 Epoch[14] Batch [150]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.126571,	
2017-06-28 13:13:57,518 Epoch[14] Batch [160]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.126465,	
2017-06-28 13:14:01,838 Epoch[14] Batch [170]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.126862,	
2017-06-28 13:14:06,252 Epoch[14] Batch [180]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.126949,	
2017-06-28 13:14:10,759 Epoch[14] Batch [190]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.127435,	
2017-06-28 13:14:15,110 Epoch[14] Batch [200]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.127225,	
2017-06-28 13:14:19,729 Epoch[14] Batch [210]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.127109,	
2017-06-28 13:14:23,905 Epoch[14] Batch [220]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.127226,	
2017-06-28 13:14:28,544 Epoch[14] Batch [230]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.127717,	
2017-06-28 13:14:33,196 Epoch[14] Batch [240]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.127620,	
2017-06-28 13:14:37,889 Epoch[14] Batch [250]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.127713,	
2017-06-28 13:14:42,367 Epoch[14] Batch [260]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.127429,	
2017-06-28 13:14:46,782 Epoch[14] Batch [270]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.128187,	
2017-06-28 13:14:51,309 Epoch[14] Batch [280]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.128928,	
2017-06-28 13:14:55,558 Epoch[14] Batch [290]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.129442,	
2017-06-28 13:15:00,296 Epoch[14] Batch [300]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.129504,	
2017-06-28 13:15:05,046 Epoch[14] Batch [310]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.129232,	
2017-06-28 13:15:09,712 Epoch[14] Batch [320]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.128717,	
2017-06-28 13:15:14,411 Epoch[14] Batch [330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.128451,	
2017-06-28 13:15:18,800 Epoch[14] Batch [340]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.128828,	
2017-06-28 13:15:23,336 Epoch[14] Batch [350]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.128027,	
2017-06-28 13:15:27,909 Epoch[14] Batch [360]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.127982,	
2017-06-28 13:15:32,332 Epoch[14] Batch [370]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.128221,	
2017-06-28 13:15:36,662 Epoch[14] Batch [380]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.128277,	
2017-06-28 13:15:41,416 Epoch[14] Batch [390]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.128089,	
2017-06-28 13:15:45,817 Epoch[14] Batch [400]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.128061,	
2017-06-28 13:15:50,410 Epoch[14] Batch [410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.127949,	
2017-06-28 13:15:54,880 Epoch[14] Batch [420]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.127966,	
2017-06-28 13:15:59,074 Epoch[14] Batch [430]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.127673,	
2017-06-28 13:16:03,716 Epoch[14] Batch [440]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.127614,	
2017-06-28 13:16:08,387 Epoch[14] Batch [450]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.127467,	
2017-06-28 13:16:12,869 Epoch[14] Batch [460]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.127130,	
2017-06-28 13:16:17,413 Epoch[14] Batch [470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.127037,	
2017-06-28 13:16:21,924 Epoch[14] Batch [480]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.126775,	
2017-06-28 13:16:26,418 Epoch[14] Batch [490]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.126932,	
2017-06-28 13:16:31,295 Epoch[14] Batch [500]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.126907,	
2017-06-28 13:16:35,886 Epoch[14] Batch [510]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.126854,	
2017-06-28 13:16:40,318 Epoch[14] Batch [520]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.126828,	
2017-06-28 13:16:44,850 Epoch[14] Batch [530]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.126669,	
2017-06-28 13:16:49,551 Epoch[14] Batch [540]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.126806,	
2017-06-28 13:16:54,011 Epoch[14] Batch [550]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.126755,	
2017-06-28 13:16:58,815 Epoch[14] Batch [560]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.126613,	
2017-06-28 13:17:03,363 Epoch[14] Batch [570]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.126514,	
2017-06-28 13:17:07,724 Epoch[14] Batch [580]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.126680,	
2017-06-28 13:17:12,088 Epoch[14] Batch [590]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.126502,	
2017-06-28 13:17:16,965 Epoch[14] Batch [600]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.126199,	
2017-06-28 13:17:21,587 Epoch[14] Batch [610]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.126091,	
2017-06-28 13:17:25,968 Epoch[14] Batch [620]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.125905,	
2017-06-28 13:17:30,564 Epoch[14] Batch [630]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.125929,	
2017-06-28 13:17:35,159 Epoch[14] Batch [640]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.126023,	
2017-06-28 13:17:39,687 Epoch[14] Batch [650]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.125972,	
2017-06-28 13:17:43,779 Epoch[14] Batch [660]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.125941,	
2017-06-28 13:17:48,184 Epoch[14] Batch [670]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.125766,	
2017-06-28 13:17:52,272 Epoch[14] Batch [680]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.125663,	
2017-06-28 13:17:56,747 Epoch[14] Batch [690]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.125645,	
2017-06-28 13:18:01,028 Epoch[14] Batch [700]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.125447,	
2017-06-28 13:18:05,581 Epoch[14] Batch [710]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.125215,	
2017-06-28 13:18:09,865 Epoch[14] Batch [720]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.125210,	
2017-06-28 13:18:14,445 Epoch[14] Batch [730]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.125193,	
2017-06-28 13:18:18,882 Epoch[14] Batch [740]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.125214,	
2017-06-28 13:18:23,768 Epoch[14] Batch [750]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.125050,	
2017-06-28 13:18:28,349 Epoch[14] Batch [760]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.124939,	
2017-06-28 13:18:32,801 Epoch[14] Batch [770]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.125071,	
2017-06-28 13:18:37,321 Epoch[14] Batch [780]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.124901,	
2017-06-28 13:18:42,109 Epoch[14] Batch [790]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.124976,	
2017-06-28 13:18:46,462 Epoch[14] Batch [800]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.124973,	
2017-06-28 13:18:50,828 Epoch[14] Batch [810]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.124870,	
2017-06-28 13:18:55,325 Epoch[14] Batch [820]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.124926,	
2017-06-28 13:18:59,899 Epoch[14] Batch [830]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.124838,	
2017-06-28 13:19:04,416 Epoch[14] Batch [840]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.124887,	
2017-06-28 13:19:09,101 Epoch[14] Batch [850]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.124793,	
2017-06-28 13:19:13,846 Epoch[14] Batch [860]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.124598,	
2017-06-28 13:19:18,494 Epoch[14] Batch [870]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.124613,	
2017-06-28 13:19:23,053 Epoch[14] Batch [880]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.124557,	
2017-06-28 13:19:27,537 Epoch[14] Batch [890]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.124587,	
2017-06-28 13:19:32,243 Epoch[14] Batch [900]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.124614,	
2017-06-28 13:19:37,148 Epoch[14] Batch [910]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.124960,	
2017-06-28 13:19:42,029 Epoch[14] Batch [920]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.125124,	
2017-06-28 13:19:46,472 Epoch[14] Batch [930]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.125187,	
2017-06-28 13:19:51,113 Epoch[14] Batch [940]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.125312,	
2017-06-28 13:19:55,731 Epoch[14] Batch [950]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.125340,	
2017-06-28 13:20:00,083 Epoch[14] Batch [960]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.125641,	
2017-06-28 13:20:04,388 Epoch[14] Batch [970]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.125628,	
2017-06-28 13:20:08,994 Epoch[14] Batch [980]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.125961,	
2017-06-28 13:20:13,755 Epoch[14] Batch [990]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.126246,	
2017-06-28 13:20:18,009 Epoch[14] Batch [1000]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.126560,	
2017-06-28 13:20:22,229 Epoch[14] Batch [1010]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.126886,	
2017-06-28 13:20:26,868 Epoch[14] Batch [1020]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.127143,	
2017-06-28 13:20:31,383 Epoch[14] Batch [1030]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.127527,	
2017-06-28 13:20:35,984 Epoch[14] Batch [1040]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.127611,	
2017-06-28 13:20:40,484 Epoch[14] Batch [1050]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.127587,	
2017-06-28 13:20:44,970 Epoch[14] Batch [1060]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.127695,	
2017-06-28 13:20:49,427 Epoch[14] Batch [1070]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.127780,	
2017-06-28 13:20:53,824 Epoch[14] Batch [1080]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.127778,	
2017-06-28 13:20:58,502 Epoch[14] Batch [1090]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.127788,	
2017-06-28 13:21:02,953 Epoch[14] Batch [1100]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.127939,	
2017-06-28 13:21:07,812 Epoch[14] Batch [1110]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.128214,	
2017-06-28 13:21:12,135 Epoch[14] Batch [1120]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.128226,	
2017-06-28 13:21:16,996 Epoch[14] Batch [1130]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.128327,	
2017-06-28 13:21:21,965 Epoch[14] Batch [1140]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.128321,	
2017-06-28 13:21:26,643 Epoch[14] Batch [1150]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.128203,	
2017-06-28 13:21:31,188 Epoch[14] Batch [1160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128239,	
2017-06-28 13:21:35,518 Epoch[14] Batch [1170]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.128329,	
2017-06-28 13:21:39,982 Epoch[14] Batch [1180]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.128460,	
2017-06-28 13:21:44,493 Epoch[14] Batch [1190]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.128473,	
2017-06-28 13:21:49,129 Epoch[14] Batch [1200]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.128542,	
2017-06-28 13:21:53,559 Epoch[14] Batch [1210]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.128542,	
2017-06-28 13:21:57,768 Epoch[14] Batch [1220]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.128524,	
2017-06-28 13:22:02,140 Epoch[14] Batch [1230]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.128487,	
2017-06-28 13:22:06,480 Epoch[14] Batch [1240]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.128460,	
2017-06-28 13:22:11,060 Epoch[14] Batch [1250]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.128461,	
2017-06-28 13:22:15,699 Epoch[14] Batch [1260]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.128524,	
2017-06-28 13:22:19,911 Epoch[14] Batch [1270]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.128360,	
2017-06-28 13:22:23,995 Epoch[14] Batch [1280]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.128297,	
2017-06-28 13:22:28,420 Epoch[14] Batch [1290]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.128377,	
2017-06-28 13:22:32,700 Epoch[14] Batch [1300]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.128548,	
2017-06-28 13:22:37,312 Epoch[14] Batch [1310]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.128521,	
2017-06-28 13:22:42,052 Epoch[14] Batch [1320]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.128450,	
2017-06-28 13:22:46,526 Epoch[14] Batch [1330]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.128372,	
2017-06-28 13:22:51,294 Epoch[14] Batch [1340]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.128353,	
2017-06-28 13:22:55,967 Epoch[14] Batch [1350]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128233,	
2017-06-28 13:23:00,237 Epoch[14] Batch [1360]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.128193,	
2017-06-28 13:23:05,005 Epoch[14] Batch [1370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.128116,	
2017-06-28 13:23:09,460 Epoch[14] Batch [1380]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.128300,	
2017-06-28 13:23:14,179 Epoch[14] Batch [1390]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.128248,	
2017-06-28 13:23:19,039 Epoch[14] Batch [1400]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.128115,	
2017-06-28 13:23:23,745 Epoch[14] Batch [1410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.128136,	
2017-06-28 13:23:27,995 Epoch[14] Batch [1420]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.128147,	
2017-06-28 13:23:32,300 Epoch[14] Batch [1430]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.128120,	
2017-06-28 13:23:36,647 Epoch[14] Batch [1440]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.128281,	
2017-06-28 13:23:41,516 Epoch[14] Batch [1450]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.128184,	
2017-06-28 13:23:45,932 Epoch[14] Batch [1460]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.128341,	
2017-06-28 13:23:50,096 Epoch[14] Batch [1470]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.128420,	
2017-06-28 13:23:54,522 Epoch[14] Batch [1480]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.128496,	
2017-06-28 13:23:57,322 Epoch[14] Train-FCNLogLoss=0.128446
2017-06-28 13:23:57,323 Epoch[14] Time cost=671.627
2017-06-28 13:23:58,074 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0015.params"
2017-06-28 13:23:59,697 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0015.states"
2017-06-28 13:24:05,154 Epoch[15] Batch [10]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.122600,	
2017-06-28 13:24:09,668 Epoch[15] Batch [20]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.127884,	
2017-06-28 13:24:14,054 Epoch[15] Batch [30]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.123477,	
2017-06-28 13:24:18,450 Epoch[15] Batch [40]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.123562,	
2017-06-28 13:24:23,011 Epoch[15] Batch [50]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.123346,	
2017-06-28 13:24:27,369 Epoch[15] Batch [60]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.122852,	
2017-06-28 13:24:31,702 Epoch[15] Batch [70]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.123176,	
2017-06-28 13:24:35,898 Epoch[15] Batch [80]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.125422,	
2017-06-28 13:24:40,057 Epoch[15] Batch [90]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.123301,	
2017-06-28 13:24:44,537 Epoch[15] Batch [100]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.121043,	
2017-06-28 13:24:49,290 Epoch[15] Batch [110]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.121844,	
2017-06-28 13:24:53,843 Epoch[15] Batch [120]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121660,	
2017-06-28 13:24:58,354 Epoch[15] Batch [130]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.120758,	
2017-06-28 13:25:02,843 Epoch[15] Batch [140]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.121162,	
2017-06-28 13:25:07,578 Epoch[15] Batch [150]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.120952,	
2017-06-28 13:25:11,961 Epoch[15] Batch [160]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.121409,	
2017-06-28 13:25:16,393 Epoch[15] Batch [170]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.120793,	
2017-06-28 13:25:20,509 Epoch[15] Batch [180]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.120587,	
2017-06-28 13:25:24,675 Epoch[15] Batch [190]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.120533,	
2017-06-28 13:25:29,246 Epoch[15] Batch [200]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.120902,	
2017-06-28 13:25:33,649 Epoch[15] Batch [210]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.122039,	
2017-06-28 13:25:38,111 Epoch[15] Batch [220]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.122595,	
2017-06-28 13:25:42,325 Epoch[15] Batch [230]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.122505,	
2017-06-28 13:25:47,051 Epoch[15] Batch [240]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.122954,	
2017-06-28 13:25:51,583 Epoch[15] Batch [250]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.123298,	
2017-06-28 13:25:56,090 Epoch[15] Batch [260]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.123413,	
2017-06-28 13:26:00,692 Epoch[15] Batch [270]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.124037,	
2017-06-28 13:26:05,423 Epoch[15] Batch [280]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.124206,	
2017-06-28 13:26:10,168 Epoch[15] Batch [290]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.124239,	
2017-06-28 13:26:14,400 Epoch[15] Batch [300]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.124191,	
2017-06-28 13:26:19,032 Epoch[15] Batch [310]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.123835,	
2017-06-28 13:26:23,974 Epoch[15] Batch [320]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.123553,	
2017-06-28 13:26:28,367 Epoch[15] Batch [330]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.123486,	
2017-06-28 13:26:32,727 Epoch[15] Batch [340]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.123164,	
2017-06-28 13:26:37,020 Epoch[15] Batch [350]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.123439,	
2017-06-28 13:26:41,738 Epoch[15] Batch [360]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.123473,	
2017-06-28 13:26:46,047 Epoch[15] Batch [370]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.124036,	
2017-06-28 13:26:50,170 Epoch[15] Batch [380]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.124367,	
2017-06-28 13:26:54,683 Epoch[15] Batch [390]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.124464,	
2017-06-28 13:26:59,302 Epoch[15] Batch [400]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.124635,	
2017-06-28 13:27:03,582 Epoch[15] Batch [410]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.124397,	
2017-06-28 13:27:08,220 Epoch[15] Batch [420]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.124643,	
2017-06-28 13:27:12,705 Epoch[15] Batch [430]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.124773,	
2017-06-28 13:27:17,017 Epoch[15] Batch [440]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.124392,	
2017-06-28 13:27:21,630 Epoch[15] Batch [450]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.124339,	
2017-06-28 13:27:26,340 Epoch[15] Batch [460]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.124445,	
2017-06-28 13:27:30,894 Epoch[15] Batch [470]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.124203,	
2017-06-28 13:27:35,241 Epoch[15] Batch [480]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.124180,	
2017-06-28 13:27:39,737 Epoch[15] Batch [490]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.123981,	
2017-06-28 13:27:43,912 Epoch[15] Batch [500]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.123852,	
2017-06-28 13:27:48,217 Epoch[15] Batch [510]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.123639,	
2017-06-28 13:27:52,587 Epoch[15] Batch [520]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.123439,	
2017-06-28 13:27:57,383 Epoch[15] Batch [530]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.123305,	
2017-06-28 13:28:02,121 Epoch[15] Batch [540]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.123259,	
2017-06-28 13:28:06,628 Epoch[15] Batch [550]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.123124,	
2017-06-28 13:28:11,359 Epoch[15] Batch [560]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.123219,	
2017-06-28 13:28:15,887 Epoch[15] Batch [570]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.123189,	
2017-06-28 13:28:20,686 Epoch[15] Batch [580]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.123089,	
2017-06-28 13:28:25,030 Epoch[15] Batch [590]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.123151,	
2017-06-28 13:28:29,320 Epoch[15] Batch [600]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.123329,	
2017-06-28 13:28:33,600 Epoch[15] Batch [610]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.123384,	
2017-06-28 13:28:38,165 Epoch[15] Batch [620]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.123391,	
2017-06-28 13:28:42,717 Epoch[15] Batch [630]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.123498,	
2017-06-28 13:28:47,357 Epoch[15] Batch [640]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.123468,	
2017-06-28 13:28:51,987 Epoch[15] Batch [650]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.123650,	
2017-06-28 13:28:56,478 Epoch[15] Batch [660]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.123521,	
2017-06-28 13:29:00,748 Epoch[15] Batch [670]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.123391,	
2017-06-28 13:29:05,015 Epoch[15] Batch [680]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.123509,	
2017-06-28 13:29:09,589 Epoch[15] Batch [690]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.123464,	
2017-06-28 13:29:14,222 Epoch[15] Batch [700]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.123309,	
2017-06-28 13:29:18,932 Epoch[15] Batch [710]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.123251,	
2017-06-28 13:29:23,273 Epoch[15] Batch [720]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.123100,	
2017-06-28 13:29:27,537 Epoch[15] Batch [730]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.123040,	
2017-06-28 13:29:32,051 Epoch[15] Batch [740]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.122810,	
2017-06-28 13:29:36,341 Epoch[15] Batch [750]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.122681,	
2017-06-28 13:29:40,980 Epoch[15] Batch [760]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.122516,	
2017-06-28 13:29:45,312 Epoch[15] Batch [770]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.122486,	
2017-06-28 13:29:49,456 Epoch[15] Batch [780]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.122273,	
2017-06-28 13:29:53,835 Epoch[15] Batch [790]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.122168,	
2017-06-28 13:29:58,313 Epoch[15] Batch [800]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.122150,	
2017-06-28 13:30:02,872 Epoch[15] Batch [810]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.122155,	
2017-06-28 13:30:07,028 Epoch[15] Batch [820]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.122010,	
2017-06-28 13:30:11,049 Epoch[15] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121983,	
2017-06-28 13:30:15,797 Epoch[15] Batch [840]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.121921,	
2017-06-28 13:30:20,282 Epoch[15] Batch [850]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.121764,	
2017-06-28 13:30:24,879 Epoch[15] Batch [860]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.121737,	
2017-06-28 13:30:29,722 Epoch[15] Batch [870]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.121579,	
2017-06-28 13:30:34,190 Epoch[15] Batch [880]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121727,	
2017-06-28 13:30:38,751 Epoch[15] Batch [890]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.121732,	
2017-06-28 13:30:43,303 Epoch[15] Batch [900]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121865,	
2017-06-28 13:30:48,086 Epoch[15] Batch [910]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.122032,	
2017-06-28 13:30:52,735 Epoch[15] Batch [920]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.121890,	
2017-06-28 13:30:57,253 Epoch[15] Batch [930]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.121749,	
2017-06-28 13:31:02,183 Epoch[15] Batch [940]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.121729,	
2017-06-28 13:31:06,760 Epoch[15] Batch [950]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.121683,	
2017-06-28 13:31:11,363 Epoch[15] Batch [960]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121691,	
2017-06-28 13:31:15,814 Epoch[15] Batch [970]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.121658,	
2017-06-28 13:31:20,379 Epoch[15] Batch [980]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.121676,	
2017-06-28 13:31:25,048 Epoch[15] Batch [990]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.121570,	
2017-06-28 13:31:29,503 Epoch[15] Batch [1000]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.121584,	
2017-06-28 13:31:34,231 Epoch[15] Batch [1010]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121531,	
2017-06-28 13:31:38,771 Epoch[15] Batch [1020]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.121496,	
2017-06-28 13:31:42,866 Epoch[15] Batch [1030]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.121458,	
2017-06-28 13:31:47,335 Epoch[15] Batch [1040]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121310,	
2017-06-28 13:31:52,055 Epoch[15] Batch [1050]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.121327,	
2017-06-28 13:31:56,423 Epoch[15] Batch [1060]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.121443,	
2017-06-28 13:32:00,924 Epoch[15] Batch [1070]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.121501,	
2017-06-28 13:32:05,241 Epoch[15] Batch [1080]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.121531,	
2017-06-28 13:32:09,756 Epoch[15] Batch [1090]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.121547,	
2017-06-28 13:32:14,305 Epoch[15] Batch [1100]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121695,	
2017-06-28 13:32:18,700 Epoch[15] Batch [1110]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.121784,	
2017-06-28 13:32:23,150 Epoch[15] Batch [1120]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.121692,	
2017-06-28 13:32:27,505 Epoch[15] Batch [1130]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.121630,	
2017-06-28 13:32:31,871 Epoch[15] Batch [1140]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.121628,	
2017-06-28 13:32:36,844 Epoch[15] Batch [1150]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.121686,	
2017-06-28 13:32:41,551 Epoch[15] Batch [1160]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121552,	
2017-06-28 13:32:45,964 Epoch[15] Batch [1170]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.121501,	
2017-06-28 13:32:50,568 Epoch[15] Batch [1180]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121399,	
2017-06-28 13:32:55,296 Epoch[15] Batch [1190]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121447,	
2017-06-28 13:33:00,025 Epoch[15] Batch [1200]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121408,	
2017-06-28 13:33:04,674 Epoch[15] Batch [1210]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.121357,	
2017-06-28 13:33:08,951 Epoch[15] Batch [1220]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.121643,	
2017-06-28 13:33:13,568 Epoch[15] Batch [1230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121654,	
2017-06-28 13:33:17,802 Epoch[15] Batch [1240]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.121588,	
2017-06-28 13:33:22,270 Epoch[15] Batch [1250]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121664,	
2017-06-28 13:33:26,512 Epoch[15] Batch [1260]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.121713,	
2017-06-28 13:33:30,714 Epoch[15] Batch [1270]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.121786,	
2017-06-28 13:33:35,169 Epoch[15] Batch [1280]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.121864,	
2017-06-28 13:33:40,139 Epoch[15] Batch [1290]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.121736,	
2017-06-28 13:33:44,827 Epoch[15] Batch [1300]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.121748,	
2017-06-28 13:33:49,625 Epoch[15] Batch [1310]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.121627,	
2017-06-28 13:33:54,524 Epoch[15] Batch [1320]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.121698,	
2017-06-28 13:33:59,397 Epoch[15] Batch [1330]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.121860,	
2017-06-28 13:34:04,349 Epoch[15] Batch [1340]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.121898,	
2017-06-28 13:34:08,660 Epoch[15] Batch [1350]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.121941,	
2017-06-28 13:34:13,236 Epoch[15] Batch [1360]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.121869,	
2017-06-28 13:34:17,894 Epoch[15] Batch [1370]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.121885,	
2017-06-28 13:34:22,471 Epoch[15] Batch [1380]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.122038,	
2017-06-28 13:34:26,823 Epoch[15] Batch [1390]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.122117,	
2017-06-28 13:34:31,388 Epoch[15] Batch [1400]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.122278,	
2017-06-28 13:34:35,646 Epoch[15] Batch [1410]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.122356,	
2017-06-28 13:34:40,221 Epoch[15] Batch [1420]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.122401,	
2017-06-28 13:34:44,581 Epoch[15] Batch [1430]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.122443,	
2017-06-28 13:34:49,046 Epoch[15] Batch [1440]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.122502,	
2017-06-28 13:34:53,983 Epoch[15] Batch [1450]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.122532,	
2017-06-28 13:34:58,978 Epoch[15] Batch [1460]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.122510,	
2017-06-28 13:35:03,784 Epoch[15] Batch [1470]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.122504,	
2017-06-28 13:35:08,510 Epoch[15] Batch [1480]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.122518,	
2017-06-28 13:35:11,071 Epoch[15] Train-FCNLogLoss=0.122496
2017-06-28 13:35:11,071 Epoch[15] Time cost=671.374
2017-06-28 13:35:11,833 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0016.params"
2017-06-28 13:35:13,480 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0016.states"
2017-06-28 13:35:18,753 Epoch[16] Batch [10]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.122385,	
2017-06-28 13:35:23,667 Epoch[16] Batch [20]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.120552,	
2017-06-28 13:35:28,593 Epoch[16] Batch [30]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.123371,	
2017-06-28 13:35:32,869 Epoch[16] Batch [40]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.126619,	
2017-06-28 13:35:37,290 Epoch[16] Batch [50]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.127122,	
2017-06-28 13:35:41,792 Epoch[16] Batch [60]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.132157,	
2017-06-28 13:35:46,123 Epoch[16] Batch [70]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.132068,	
2017-06-28 13:35:51,053 Epoch[16] Batch [80]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.130697,	
2017-06-28 13:35:55,458 Epoch[16] Batch [90]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.130025,	
2017-06-28 13:35:59,569 Epoch[16] Batch [100]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.128913,	
2017-06-28 13:36:03,823 Epoch[16] Batch [110]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.128649,	
2017-06-28 13:36:08,423 Epoch[16] Batch [120]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.129154,	
2017-06-28 13:36:13,025 Epoch[16] Batch [130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.128691,	
2017-06-28 13:36:17,919 Epoch[16] Batch [140]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.128111,	
2017-06-28 13:36:22,687 Epoch[16] Batch [150]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.127610,	
2017-06-28 13:36:27,185 Epoch[16] Batch [160]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.127697,	
2017-06-28 13:36:31,632 Epoch[16] Batch [170]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.126958,	
2017-06-28 13:36:36,085 Epoch[16] Batch [180]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.126674,	
2017-06-28 13:36:40,954 Epoch[16] Batch [190]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.126520,	
2017-06-28 13:36:45,930 Epoch[16] Batch [200]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.126030,	
2017-06-28 13:36:50,421 Epoch[16] Batch [210]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.125781,	
2017-06-28 13:36:55,013 Epoch[16] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.125892,	
2017-06-28 13:36:59,430 Epoch[16] Batch [230]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.125508,	
2017-06-28 13:37:03,922 Epoch[16] Batch [240]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.125337,	
2017-06-28 13:37:08,512 Epoch[16] Batch [250]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.125206,	
2017-06-28 13:37:13,248 Epoch[16] Batch [260]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.124996,	
2017-06-28 13:37:17,809 Epoch[16] Batch [270]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.124942,	
2017-06-28 13:37:22,094 Epoch[16] Batch [280]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.124620,	
2017-06-28 13:37:26,724 Epoch[16] Batch [290]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.124607,	
2017-06-28 13:37:31,241 Epoch[16] Batch [300]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.124762,	
2017-06-28 13:37:35,867 Epoch[16] Batch [310]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.124010,	
2017-06-28 13:37:40,521 Epoch[16] Batch [320]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.123925,	
2017-06-28 13:37:45,191 Epoch[16] Batch [330]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.123735,	
2017-06-28 13:37:49,778 Epoch[16] Batch [340]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.123721,	
2017-06-28 13:37:53,807 Epoch[16] Batch [350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.123518,	
2017-06-28 13:37:57,927 Epoch[16] Batch [360]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.123798,	
2017-06-28 13:38:02,325 Epoch[16] Batch [370]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.123824,	
2017-06-28 13:38:06,680 Epoch[16] Batch [380]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.124233,	
2017-06-28 13:38:11,296 Epoch[16] Batch [390]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.123946,	
2017-06-28 13:38:15,762 Epoch[16] Batch [400]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.123876,	
2017-06-28 13:38:20,043 Epoch[16] Batch [410]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.123839,	
2017-06-28 13:38:24,637 Epoch[16] Batch [420]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.124090,	
2017-06-28 13:38:28,872 Epoch[16] Batch [430]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.123967,	
2017-06-28 13:38:33,408 Epoch[16] Batch [440]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.123896,	
2017-06-28 13:38:38,118 Epoch[16] Batch [450]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.123468,	
2017-06-28 13:38:42,255 Epoch[16] Batch [460]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.123278,	
2017-06-28 13:38:46,534 Epoch[16] Batch [470]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.123292,	
2017-06-28 13:38:50,713 Epoch[16] Batch [480]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.122924,	
2017-06-28 13:38:55,384 Epoch[16] Batch [490]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.122808,	
2017-06-28 13:38:59,752 Epoch[16] Batch [500]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.122578,	
2017-06-28 13:39:03,791 Epoch[16] Batch [510]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.122489,	
2017-06-28 13:39:07,975 Epoch[16] Batch [520]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.122151,	
2017-06-28 13:39:12,335 Epoch[16] Batch [530]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.121918,	
2017-06-28 13:39:16,663 Epoch[16] Batch [540]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.121822,	
2017-06-28 13:39:21,343 Epoch[16] Batch [550]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.121709,	
2017-06-28 13:39:25,756 Epoch[16] Batch [560]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.121754,	
2017-06-28 13:39:30,164 Epoch[16] Batch [570]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.121779,	
2017-06-28 13:39:34,537 Epoch[16] Batch [580]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.121919,	
2017-06-28 13:39:38,737 Epoch[16] Batch [590]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.122111,	
2017-06-28 13:39:42,907 Epoch[16] Batch [600]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122085,	
2017-06-28 13:39:47,267 Epoch[16] Batch [610]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.122102,	
2017-06-28 13:39:51,465 Epoch[16] Batch [620]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.121810,	
2017-06-28 13:39:55,699 Epoch[16] Batch [630]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.121931,	
2017-06-28 13:40:00,312 Epoch[16] Batch [640]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.121871,	
2017-06-28 13:40:05,273 Epoch[16] Batch [650]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.121748,	
2017-06-28 13:40:10,052 Epoch[16] Batch [660]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.121805,	
2017-06-28 13:40:14,592 Epoch[16] Batch [670]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.121820,	
2017-06-28 13:40:19,192 Epoch[16] Batch [680]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.122001,	
2017-06-28 13:40:23,532 Epoch[16] Batch [690]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.122007,	
2017-06-28 13:40:27,702 Epoch[16] Batch [700]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122203,	
2017-06-28 13:40:32,312 Epoch[16] Batch [710]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.122201,	
2017-06-28 13:40:36,692 Epoch[16] Batch [720]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.122201,	
2017-06-28 13:40:41,222 Epoch[16] Batch [730]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.122110,	
2017-06-28 13:40:45,913 Epoch[16] Batch [740]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.122221,	
2017-06-28 13:40:50,355 Epoch[16] Batch [750]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.122195,	
2017-06-28 13:40:54,788 Epoch[16] Batch [760]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.122261,	
2017-06-28 13:40:59,147 Epoch[16] Batch [770]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.121952,	
2017-06-28 13:41:03,492 Epoch[16] Batch [780]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.122064,	
2017-06-28 13:41:08,166 Epoch[16] Batch [790]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121986,	
2017-06-28 13:41:12,911 Epoch[16] Batch [800]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.122045,	
2017-06-28 13:41:17,473 Epoch[16] Batch [810]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.121891,	
2017-06-28 13:41:22,135 Epoch[16] Batch [820]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.121728,	
2017-06-28 13:41:26,737 Epoch[16] Batch [830]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.121837,	
2017-06-28 13:41:31,085 Epoch[16] Batch [840]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.121861,	
2017-06-28 13:41:35,758 Epoch[16] Batch [850]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121821,	
2017-06-28 13:41:40,173 Epoch[16] Batch [860]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.121748,	
2017-06-28 13:41:44,558 Epoch[16] Batch [870]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.121680,	
2017-06-28 13:41:49,018 Epoch[16] Batch [880]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.121640,	
2017-06-28 13:41:53,679 Epoch[16] Batch [890]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.121633,	
2017-06-28 13:41:58,108 Epoch[16] Batch [900]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.121776,	
2017-06-28 13:42:02,461 Epoch[16] Batch [910]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.122034,	
2017-06-28 13:42:07,189 Epoch[16] Batch [920]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121850,	
2017-06-28 13:42:11,427 Epoch[16] Batch [930]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.121901,	
2017-06-28 13:42:15,655 Epoch[16] Batch [940]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.121750,	
2017-06-28 13:42:19,652 Epoch[16] Batch [950]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.121775,	
2017-06-28 13:42:23,988 Epoch[16] Batch [960]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.121866,	
2017-06-28 13:42:28,775 Epoch[16] Batch [970]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.121819,	
2017-06-28 13:42:33,393 Epoch[16] Batch [980]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121744,	
2017-06-28 13:42:38,226 Epoch[16] Batch [990]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.121744,	
2017-06-28 13:42:42,767 Epoch[16] Batch [1000]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.121651,	
2017-06-28 13:42:47,476 Epoch[16] Batch [1010]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121559,	
2017-06-28 13:42:51,938 Epoch[16] Batch [1020]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.121482,	
2017-06-28 13:42:56,304 Epoch[16] Batch [1030]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.121247,	
2017-06-28 13:43:00,738 Epoch[16] Batch [1040]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.121141,	
2017-06-28 13:43:05,195 Epoch[16] Batch [1050]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.121184,	
2017-06-28 13:43:09,407 Epoch[16] Batch [1060]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.121099,	
2017-06-28 13:43:13,568 Epoch[16] Batch [1070]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.121112,	
2017-06-28 13:43:18,016 Epoch[16] Batch [1080]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.121089,	
2017-06-28 13:43:22,239 Epoch[16] Batch [1090]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.121099,	
2017-06-28 13:43:26,260 Epoch[16] Batch [1100]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121094,	
2017-06-28 13:43:30,221 Epoch[16] Batch [1110]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.121030,	
2017-06-28 13:43:34,662 Epoch[16] Batch [1120]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.121022,	
2017-06-28 13:43:39,033 Epoch[16] Batch [1130]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.121027,	
2017-06-28 13:43:43,443 Epoch[16] Batch [1140]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.121055,	
2017-06-28 13:43:47,922 Epoch[16] Batch [1150]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.121090,	
2017-06-28 13:43:51,898 Epoch[16] Batch [1160]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121125,	
2017-06-28 13:43:56,337 Epoch[16] Batch [1170]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.121145,	
2017-06-28 13:44:00,991 Epoch[16] Batch [1180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.121054,	
2017-06-28 13:44:05,625 Epoch[16] Batch [1190]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121104,	
2017-06-28 13:44:10,348 Epoch[16] Batch [1200]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.121101,	
2017-06-28 13:44:14,781 Epoch[16] Batch [1210]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.121099,	
2017-06-28 13:44:19,621 Epoch[16] Batch [1220]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.121056,	
2017-06-28 13:44:24,418 Epoch[16] Batch [1230]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.121030,	
2017-06-28 13:44:29,048 Epoch[16] Batch [1240]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.121009,	
2017-06-28 13:44:33,870 Epoch[16] Batch [1250]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.120917,	
2017-06-28 13:44:38,326 Epoch[16] Batch [1260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.120877,	
2017-06-28 13:44:42,788 Epoch[16] Batch [1270]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.120933,	
2017-06-28 13:44:47,050 Epoch[16] Batch [1280]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.120899,	
2017-06-28 13:44:51,703 Epoch[16] Batch [1290]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.120830,	
2017-06-28 13:44:56,386 Epoch[16] Batch [1300]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.120744,	
2017-06-28 13:45:00,931 Epoch[16] Batch [1310]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120684,	
2017-06-28 13:45:05,525 Epoch[16] Batch [1320]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.120646,	
2017-06-28 13:45:10,390 Epoch[16] Batch [1330]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.120802,	
2017-06-28 13:45:15,268 Epoch[16] Batch [1340]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.120768,	
2017-06-28 13:45:19,824 Epoch[16] Batch [1350]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.120766,	
2017-06-28 13:45:24,652 Epoch[16] Batch [1360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.120701,	
2017-06-28 13:45:29,188 Epoch[16] Batch [1370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.120586,	
2017-06-28 13:45:33,659 Epoch[16] Batch [1380]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.120423,	
2017-06-28 13:45:38,298 Epoch[16] Batch [1390]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.120330,	
2017-06-28 13:45:42,773 Epoch[16] Batch [1400]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.120338,	
2017-06-28 13:45:47,376 Epoch[16] Batch [1410]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.120200,	
2017-06-28 13:45:52,104 Epoch[16] Batch [1420]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.120163,	
2017-06-28 13:45:56,740 Epoch[16] Batch [1430]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.120197,	
2017-06-28 13:46:01,162 Epoch[16] Batch [1440]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.120192,	
2017-06-28 13:46:05,725 Epoch[16] Batch [1450]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.120212,	
2017-06-28 13:46:10,213 Epoch[16] Batch [1460]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.120249,	
2017-06-28 13:46:14,731 Epoch[16] Batch [1470]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.120295,	
2017-06-28 13:46:19,145 Epoch[16] Batch [1480]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.120210,	
2017-06-28 13:46:21,677 Epoch[16] Train-FCNLogLoss=0.120233
2017-06-28 13:46:21,677 Epoch[16] Time cost=668.196
2017-06-28 13:46:22,466 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0017.params"
2017-06-28 13:46:24,309 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0017.states"
2017-06-28 13:46:29,445 Epoch[17] Batch [10]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.109437,	
2017-06-28 13:46:33,697 Epoch[17] Batch [20]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.111058,	
2017-06-28 13:46:38,358 Epoch[17] Batch [30]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112907,	
2017-06-28 13:46:43,391 Epoch[17] Batch [40]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.113327,	
2017-06-28 13:46:47,727 Epoch[17] Batch [50]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.113441,	
2017-06-28 13:46:52,178 Epoch[17] Batch [60]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.113376,	
2017-06-28 13:46:56,908 Epoch[17] Batch [70]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.113086,	
2017-06-28 13:47:01,551 Epoch[17] Batch [80]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.114386,	
2017-06-28 13:47:05,972 Epoch[17] Batch [90]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.114716,	
2017-06-28 13:47:10,460 Epoch[17] Batch [100]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.116715,	
2017-06-28 13:47:14,853 Epoch[17] Batch [110]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.115327,	
2017-06-28 13:47:19,485 Epoch[17] Batch [120]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.114955,	
2017-06-28 13:47:23,891 Epoch[17] Batch [130]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.114662,	
2017-06-28 13:47:28,441 Epoch[17] Batch [140]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.114632,	
2017-06-28 13:47:32,902 Epoch[17] Batch [150]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.113805,	
2017-06-28 13:47:37,085 Epoch[17] Batch [160]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.114543,	
2017-06-28 13:47:41,403 Epoch[17] Batch [170]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.115241,	
2017-06-28 13:47:45,787 Epoch[17] Batch [180]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.114983,	
2017-06-28 13:47:50,088 Epoch[17] Batch [190]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.114571,	
2017-06-28 13:47:54,699 Epoch[17] Batch [200]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.114645,	
2017-06-28 13:47:58,880 Epoch[17] Batch [210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.114235,	
2017-06-28 13:48:03,260 Epoch[17] Batch [220]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.114410,	
2017-06-28 13:48:07,616 Epoch[17] Batch [230]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.114828,	
2017-06-28 13:48:11,934 Epoch[17] Batch [240]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.114774,	
2017-06-28 13:48:16,598 Epoch[17] Batch [250]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.114818,	
2017-06-28 13:48:20,852 Epoch[17] Batch [260]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.114870,	
2017-06-28 13:48:25,152 Epoch[17] Batch [270]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.115284,	
2017-06-28 13:48:29,494 Epoch[17] Batch [280]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.115340,	
2017-06-28 13:48:33,935 Epoch[17] Batch [290]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.115489,	
2017-06-28 13:48:38,034 Epoch[17] Batch [300]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.115272,	
2017-06-28 13:48:42,174 Epoch[17] Batch [310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115546,	
2017-06-28 13:48:46,610 Epoch[17] Batch [320]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.115427,	
2017-06-28 13:48:51,219 Epoch[17] Batch [330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115354,	
2017-06-28 13:48:55,513 Epoch[17] Batch [340]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.115199,	
2017-06-28 13:48:59,981 Epoch[17] Batch [350]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.114903,	
2017-06-28 13:49:04,875 Epoch[17] Batch [360]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.115265,	
2017-06-28 13:49:09,654 Epoch[17] Batch [370]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.115147,	
2017-06-28 13:49:14,249 Epoch[17] Batch [380]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.115806,	
2017-06-28 13:49:19,159 Epoch[17] Batch [390]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.116361,	
2017-06-28 13:49:23,515 Epoch[17] Batch [400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.116663,	
2017-06-28 13:49:28,107 Epoch[17] Batch [410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.116425,	
2017-06-28 13:49:32,604 Epoch[17] Batch [420]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116392,	
2017-06-28 13:49:37,348 Epoch[17] Batch [430]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.116615,	
2017-06-28 13:49:41,498 Epoch[17] Batch [440]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.116732,	
2017-06-28 13:49:45,838 Epoch[17] Batch [450]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.116615,	
2017-06-28 13:49:50,556 Epoch[17] Batch [460]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.116447,	
2017-06-28 13:49:54,858 Epoch[17] Batch [470]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.116452,	
2017-06-28 13:49:59,401 Epoch[17] Batch [480]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.116855,	
2017-06-28 13:50:03,921 Epoch[17] Batch [490]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.116931,	
2017-06-28 13:50:08,739 Epoch[17] Batch [500]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.118030,	
2017-06-28 13:50:13,481 Epoch[17] Batch [510]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.118289,	
2017-06-28 13:50:18,154 Epoch[17] Batch [520]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.118406,	
2017-06-28 13:50:22,611 Epoch[17] Batch [530]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.118310,	
2017-06-28 13:50:27,068 Epoch[17] Batch [540]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.118073,	
2017-06-28 13:50:31,381 Epoch[17] Batch [550]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.117882,	
2017-06-28 13:50:36,104 Epoch[17] Batch [560]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.117769,	
2017-06-28 13:50:40,503 Epoch[17] Batch [570]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.117684,	
2017-06-28 13:50:44,869 Epoch[17] Batch [580]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.117657,	
2017-06-28 13:50:49,352 Epoch[17] Batch [590]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.117706,	
2017-06-28 13:50:54,044 Epoch[17] Batch [600]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.117630,	
2017-06-28 13:50:58,685 Epoch[17] Batch [610]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.117744,	
2017-06-28 13:51:03,220 Epoch[17] Batch [620]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117908,	
2017-06-28 13:51:07,523 Epoch[17] Batch [630]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.117961,	
2017-06-28 13:51:11,949 Epoch[17] Batch [640]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.117802,	
2017-06-28 13:51:16,737 Epoch[17] Batch [650]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.117528,	
2017-06-28 13:51:21,074 Epoch[17] Batch [660]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.117429,	
2017-06-28 13:51:25,082 Epoch[17] Batch [670]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.117526,	
2017-06-28 13:51:29,384 Epoch[17] Batch [680]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.117447,	
2017-06-28 13:51:33,459 Epoch[17] Batch [690]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117535,	
2017-06-28 13:51:37,634 Epoch[17] Batch [700]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117655,	
2017-06-28 13:51:42,280 Epoch[17] Batch [710]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.117535,	
2017-06-28 13:51:47,082 Epoch[17] Batch [720]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.117509,	
2017-06-28 13:51:51,272 Epoch[17] Batch [730]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.117507,	
2017-06-28 13:51:55,482 Epoch[17] Batch [740]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.117547,	
2017-06-28 13:51:59,425 Epoch[17] Batch [750]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.117613,	
2017-06-28 13:52:03,750 Epoch[17] Batch [760]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.117547,	
2017-06-28 13:52:08,089 Epoch[17] Batch [770]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.117591,	
2017-06-28 13:52:12,183 Epoch[17] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117819,	
2017-06-28 13:52:16,676 Epoch[17] Batch [790]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.117942,	
2017-06-28 13:52:21,254 Epoch[17] Batch [800]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.117972,	
2017-06-28 13:52:25,734 Epoch[17] Batch [810]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.118150,	
2017-06-28 13:52:30,006 Epoch[17] Batch [820]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.118188,	
2017-06-28 13:52:34,339 Epoch[17] Batch [830]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.118227,	
2017-06-28 13:52:38,988 Epoch[17] Batch [840]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.118430,	
2017-06-28 13:52:44,010 Epoch[17] Batch [850]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.118495,	
2017-06-28 13:52:48,585 Epoch[17] Batch [860]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.118525,	
2017-06-28 13:52:52,731 Epoch[17] Batch [870]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.118607,	
2017-06-28 13:52:57,279 Epoch[17] Batch [880]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.118572,	
2017-06-28 13:53:01,713 Epoch[17] Batch [890]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.118609,	
2017-06-28 13:53:06,053 Epoch[17] Batch [900]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.118508,	
2017-06-28 13:53:10,430 Epoch[17] Batch [910]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.118490,	
2017-06-28 13:53:14,896 Epoch[17] Batch [920]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.118490,	
2017-06-28 13:53:19,492 Epoch[17] Batch [930]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.118513,	
2017-06-28 13:53:24,154 Epoch[17] Batch [940]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.118741,	
2017-06-28 13:53:28,755 Epoch[17] Batch [950]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.118931,	
2017-06-28 13:53:33,127 Epoch[17] Batch [960]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.118929,	
2017-06-28 13:53:37,479 Epoch[17] Batch [970]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.118984,	
2017-06-28 13:53:41,914 Epoch[17] Batch [980]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.119103,	
2017-06-28 13:53:46,395 Epoch[17] Batch [990]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.119038,	
2017-06-28 13:53:50,902 Epoch[17] Batch [1000]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.119010,	
2017-06-28 13:53:55,166 Epoch[17] Batch [1010]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.118987,	
2017-06-28 13:53:59,938 Epoch[17] Batch [1020]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.119035,	
2017-06-28 13:54:04,222 Epoch[17] Batch [1030]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.119053,	
2017-06-28 13:54:08,735 Epoch[17] Batch [1040]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.118896,	
2017-06-28 13:54:13,186 Epoch[17] Batch [1050]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.118869,	
2017-06-28 13:54:17,774 Epoch[17] Batch [1060]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.118822,	
2017-06-28 13:54:22,151 Epoch[17] Batch [1070]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.118986,	
2017-06-28 13:54:26,587 Epoch[17] Batch [1080]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.118778,	
2017-06-28 13:54:31,519 Epoch[17] Batch [1090]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.118555,	
2017-06-28 13:54:36,308 Epoch[17] Batch [1100]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.118624,	
2017-06-28 13:54:40,795 Epoch[17] Batch [1110]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.118626,	
2017-06-28 13:54:45,451 Epoch[17] Batch [1120]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.118671,	
2017-06-28 13:54:50,102 Epoch[17] Batch [1130]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.118855,	
2017-06-28 13:54:54,956 Epoch[17] Batch [1140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.118905,	
2017-06-28 13:54:59,145 Epoch[17] Batch [1150]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.118825,	
2017-06-28 13:55:03,362 Epoch[17] Batch [1160]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.118786,	
2017-06-28 13:55:07,479 Epoch[17] Batch [1170]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.118766,	
2017-06-28 13:55:11,557 Epoch[17] Batch [1180]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118721,	
2017-06-28 13:55:15,920 Epoch[17] Batch [1190]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.118766,	
2017-06-28 13:55:20,372 Epoch[17] Batch [1200]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.118719,	
2017-06-28 13:55:24,734 Epoch[17] Batch [1210]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.118723,	
2017-06-28 13:55:29,282 Epoch[17] Batch [1220]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.118716,	
2017-06-28 13:55:33,705 Epoch[17] Batch [1230]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.118815,	
2017-06-28 13:55:38,016 Epoch[17] Batch [1240]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.118849,	
2017-06-28 13:55:42,261 Epoch[17] Batch [1250]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.118933,	
2017-06-28 13:55:46,977 Epoch[17] Batch [1260]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.118938,	
2017-06-28 13:55:51,298 Epoch[17] Batch [1270]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.119100,	
2017-06-28 13:55:55,468 Epoch[17] Batch [1280]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.119151,	
2017-06-28 13:56:00,118 Epoch[17] Batch [1290]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.119307,	
2017-06-28 13:56:04,818 Epoch[17] Batch [1300]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.119286,	
2017-06-28 13:56:09,225 Epoch[17] Batch [1310]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.119271,	
2017-06-28 13:56:13,463 Epoch[17] Batch [1320]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.119208,	
2017-06-28 13:56:17,804 Epoch[17] Batch [1330]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.119243,	
2017-06-28 13:56:22,367 Epoch[17] Batch [1340]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.119312,	
2017-06-28 13:56:26,949 Epoch[17] Batch [1350]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.119302,	
2017-06-28 13:56:31,768 Epoch[17] Batch [1360]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.119281,	
2017-06-28 13:56:35,895 Epoch[17] Batch [1370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.119215,	
2017-06-28 13:56:40,436 Epoch[17] Batch [1380]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.119116,	
2017-06-28 13:56:45,276 Epoch[17] Batch [1390]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.119037,	
2017-06-28 13:56:49,799 Epoch[17] Batch [1400]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.118984,	
2017-06-28 13:56:54,147 Epoch[17] Batch [1410]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.118849,	
2017-06-28 13:56:58,804 Epoch[17] Batch [1420]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.118808,	
2017-06-28 13:57:03,049 Epoch[17] Batch [1430]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.118713,	
2017-06-28 13:57:07,307 Epoch[17] Batch [1440]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.118759,	
2017-06-28 13:57:11,714 Epoch[17] Batch [1450]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.118653,	
2017-06-28 13:57:16,374 Epoch[17] Batch [1460]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.118673,	
2017-06-28 13:57:20,805 Epoch[17] Batch [1470]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.118590,	
2017-06-28 13:57:25,538 Epoch[17] Batch [1480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.118497,	
2017-06-28 13:57:28,406 Epoch[17] Train-FCNLogLoss=0.118495
2017-06-28 13:57:28,406 Epoch[17] Time cost=664.097
2017-06-28 13:57:29,175 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0018.params"
2017-06-28 13:57:30,991 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0018.states"
2017-06-28 13:57:36,238 Epoch[18] Batch [10]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.113064,	
2017-06-28 13:57:40,628 Epoch[18] Batch [20]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.117222,	
2017-06-28 13:57:45,268 Epoch[18] Batch [30]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.114810,	
2017-06-28 13:57:50,042 Epoch[18] Batch [40]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.116592,	
2017-06-28 13:57:54,626 Epoch[18] Batch [50]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.122772,	
2017-06-28 13:57:59,427 Epoch[18] Batch [60]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.122504,	
2017-06-28 13:58:03,855 Epoch[18] Batch [70]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.122920,	
2017-06-28 13:58:07,991 Epoch[18] Batch [80]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.126462,	
2017-06-28 13:58:12,383 Epoch[18] Batch [90]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.130525,	
2017-06-28 13:58:16,684 Epoch[18] Batch [100]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.134824,	
2017-06-28 13:58:21,323 Epoch[18] Batch [110]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.135094,	
2017-06-28 13:58:25,766 Epoch[18] Batch [120]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.135745,	
2017-06-28 13:58:30,230 Epoch[18] Batch [130]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.136017,	
2017-06-28 13:58:34,312 Epoch[18] Batch [140]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.136433,	
2017-06-28 13:58:38,445 Epoch[18] Batch [150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.135815,	
2017-06-28 13:58:42,953 Epoch[18] Batch [160]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.134430,	
2017-06-28 13:58:47,799 Epoch[18] Batch [170]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.134721,	
2017-06-28 13:58:52,435 Epoch[18] Batch [180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.133864,	
2017-06-28 13:58:56,913 Epoch[18] Batch [190]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.133410,	
2017-06-28 13:59:01,378 Epoch[18] Batch [200]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.133177,	
2017-06-28 13:59:05,946 Epoch[18] Batch [210]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.132504,	
2017-06-28 13:59:10,572 Epoch[18] Batch [220]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.131910,	
2017-06-28 13:59:14,672 Epoch[18] Batch [230]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.130893,	
2017-06-28 13:59:19,021 Epoch[18] Batch [240]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.130074,	
2017-06-28 13:59:23,269 Epoch[18] Batch [250]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.129348,	
2017-06-28 13:59:27,575 Epoch[18] Batch [260]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.128821,	
2017-06-28 13:59:31,712 Epoch[18] Batch [270]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.128080,	
2017-06-28 13:59:36,117 Epoch[18] Batch [280]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.127580,	
2017-06-28 13:59:40,804 Epoch[18] Batch [290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.127589,	
2017-06-28 13:59:45,291 Epoch[18] Batch [300]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.126982,	
2017-06-28 13:59:49,551 Epoch[18] Batch [310]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.126729,	
2017-06-28 13:59:53,908 Epoch[18] Batch [320]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.126208,	
2017-06-28 13:59:58,420 Epoch[18] Batch [330]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.125871,	
2017-06-28 14:00:02,529 Epoch[18] Batch [340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.126615,	
2017-06-28 14:00:06,740 Epoch[18] Batch [350]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.126784,	
2017-06-28 14:00:11,372 Epoch[18] Batch [360]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.127291,	
2017-06-28 14:00:15,957 Epoch[18] Batch [370]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.126924,	
2017-06-28 14:00:20,598 Epoch[18] Batch [380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.127110,	
2017-06-28 14:00:24,817 Epoch[18] Batch [390]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.126905,	
2017-06-28 14:00:29,217 Epoch[18] Batch [400]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.126897,	
2017-06-28 14:00:33,445 Epoch[18] Batch [410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.127267,	
2017-06-28 14:00:37,695 Epoch[18] Batch [420]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.127235,	
2017-06-28 14:00:41,829 Epoch[18] Batch [430]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.126948,	
2017-06-28 14:00:46,187 Epoch[18] Batch [440]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.126843,	
2017-06-28 14:00:50,566 Epoch[18] Batch [450]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.126549,	
2017-06-28 14:00:54,782 Epoch[18] Batch [460]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.126312,	
2017-06-28 14:00:59,282 Epoch[18] Batch [470]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.126051,	
2017-06-28 14:01:03,966 Epoch[18] Batch [480]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.125565,	
2017-06-28 14:01:08,325 Epoch[18] Batch [490]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.125312,	
2017-06-28 14:01:12,861 Epoch[18] Batch [500]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.125110,	
2017-06-28 14:01:17,514 Epoch[18] Batch [510]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.124885,	
2017-06-28 14:01:22,075 Epoch[18] Batch [520]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.124657,	
2017-06-28 14:01:26,461 Epoch[18] Batch [530]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.124672,	
2017-06-28 14:01:30,708 Epoch[18] Batch [540]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.124411,	
2017-06-28 14:01:35,347 Epoch[18] Batch [550]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.124309,	
2017-06-28 14:01:39,722 Epoch[18] Batch [560]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.124056,	
2017-06-28 14:01:44,029 Epoch[18] Batch [570]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.124010,	
2017-06-28 14:01:48,319 Epoch[18] Batch [580]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.125880,	
2017-06-28 14:01:52,900 Epoch[18] Batch [590]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.127074,	
2017-06-28 14:01:57,548 Epoch[18] Batch [600]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.128966,	
2017-06-28 14:02:01,919 Epoch[18] Batch [610]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.130355,	
2017-06-28 14:02:06,285 Epoch[18] Batch [620]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.130904,	
2017-06-28 14:02:10,842 Epoch[18] Batch [630]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.131061,	
2017-06-28 14:02:15,464 Epoch[18] Batch [640]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.131630,	
2017-06-28 14:02:19,888 Epoch[18] Batch [650]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.132337,	
2017-06-28 14:02:24,452 Epoch[18] Batch [660]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.133023,	
2017-06-28 14:02:29,081 Epoch[18] Batch [670]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.133710,	
2017-06-28 14:02:33,786 Epoch[18] Batch [680]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.133845,	
2017-06-28 14:02:38,107 Epoch[18] Batch [690]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.133880,	
2017-06-28 14:02:42,602 Epoch[18] Batch [700]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.133702,	
2017-06-28 14:02:47,149 Epoch[18] Batch [710]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.133584,	
2017-06-28 14:02:51,294 Epoch[18] Batch [720]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.133514,	
2017-06-28 14:02:55,726 Epoch[18] Batch [730]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.133295,	
2017-06-28 14:03:00,187 Epoch[18] Batch [740]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.133287,	
2017-06-28 14:03:04,744 Epoch[18] Batch [750]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.133231,	
2017-06-28 14:03:09,180 Epoch[18] Batch [760]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.133069,	
2017-06-28 14:03:13,895 Epoch[18] Batch [770]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.132890,	
2017-06-28 14:03:18,420 Epoch[18] Batch [780]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.132960,	
2017-06-28 14:03:22,848 Epoch[18] Batch [790]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.132970,	
2017-06-28 14:03:27,235 Epoch[18] Batch [800]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.132812,	
2017-06-28 14:03:31,367 Epoch[18] Batch [810]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.132779,	
2017-06-28 14:03:35,747 Epoch[18] Batch [820]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.132572,	
2017-06-28 14:03:40,080 Epoch[18] Batch [830]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.132434,	
2017-06-28 14:03:45,016 Epoch[18] Batch [840]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.132514,	
2017-06-28 14:03:49,990 Epoch[18] Batch [850]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.132698,	
2017-06-28 14:03:54,599 Epoch[18] Batch [860]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.132540,	
2017-06-28 14:03:59,122 Epoch[18] Batch [870]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.132626,	
2017-06-28 14:04:03,591 Epoch[18] Batch [880]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.132538,	
2017-06-28 14:04:07,735 Epoch[18] Batch [890]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.132744,	
2017-06-28 14:04:11,999 Epoch[18] Batch [900]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.132848,	
2017-06-28 14:04:16,746 Epoch[18] Batch [910]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.132939,	
2017-06-28 14:04:21,459 Epoch[18] Batch [920]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.133000,	
2017-06-28 14:04:26,012 Epoch[18] Batch [930]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.133076,	
2017-06-28 14:04:30,236 Epoch[18] Batch [940]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.132980,	
2017-06-28 14:04:34,813 Epoch[18] Batch [950]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.132828,	
2017-06-28 14:04:39,302 Epoch[18] Batch [960]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.132970,	
2017-06-28 14:04:43,598 Epoch[18] Batch [970]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.132809,	
2017-06-28 14:04:47,936 Epoch[18] Batch [980]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.132700,	
2017-06-28 14:04:52,234 Epoch[18] Batch [990]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.132686,	
2017-06-28 14:04:56,326 Epoch[18] Batch [1000]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.132700,	
2017-06-28 14:05:01,113 Epoch[18] Batch [1010]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.132626,	
2017-06-28 14:05:05,867 Epoch[18] Batch [1020]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.132573,	
2017-06-28 14:05:10,568 Epoch[18] Batch [1030]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.132624,	
2017-06-28 14:05:15,050 Epoch[18] Batch [1040]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.132719,	
2017-06-28 14:05:19,318 Epoch[18] Batch [1050]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.132707,	
2017-06-28 14:05:23,563 Epoch[18] Batch [1060]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.133022,	
2017-06-28 14:05:27,903 Epoch[18] Batch [1070]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.133211,	
2017-06-28 14:05:32,369 Epoch[18] Batch [1080]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.133321,	
2017-06-28 14:05:36,767 Epoch[18] Batch [1090]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.133413,	
2017-06-28 14:05:40,964 Epoch[18] Batch [1100]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.133737,	
2017-06-28 14:05:45,476 Epoch[18] Batch [1110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.133757,	
2017-06-28 14:05:49,870 Epoch[18] Batch [1120]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.133832,	
2017-06-28 14:05:54,609 Epoch[18] Batch [1130]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.133582,	
2017-06-28 14:05:59,290 Epoch[18] Batch [1140]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.133502,	
2017-06-28 14:06:03,940 Epoch[18] Batch [1150]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.133665,	
2017-06-28 14:06:08,388 Epoch[18] Batch [1160]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.133693,	
2017-06-28 14:06:12,543 Epoch[18] Batch [1170]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.133654,	
2017-06-28 14:06:17,320 Epoch[18] Batch [1180]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.133532,	
2017-06-28 14:06:22,151 Epoch[18] Batch [1190]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.133721,	
2017-06-28 14:06:26,731 Epoch[18] Batch [1200]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.133822,	
2017-06-28 14:06:31,162 Epoch[18] Batch [1210]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.133825,	
2017-06-28 14:06:35,643 Epoch[18] Batch [1220]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.133631,	
2017-06-28 14:06:39,911 Epoch[18] Batch [1230]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.133629,	
2017-06-28 14:06:44,070 Epoch[18] Batch [1240]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.133519,	
2017-06-28 14:06:48,610 Epoch[18] Batch [1250]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.133478,	
2017-06-28 14:06:53,292 Epoch[18] Batch [1260]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.133437,	
2017-06-28 14:06:57,615 Epoch[18] Batch [1270]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.133426,	
2017-06-28 14:07:01,830 Epoch[18] Batch [1280]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.133425,	
2017-06-28 14:07:06,633 Epoch[18] Batch [1290]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.133388,	
2017-06-28 14:07:11,289 Epoch[18] Batch [1300]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.133290,	
2017-06-28 14:07:15,739 Epoch[18] Batch [1310]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.133201,	
2017-06-28 14:07:20,600 Epoch[18] Batch [1320]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.133285,	
2017-06-28 14:07:25,242 Epoch[18] Batch [1330]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.133239,	
2017-06-28 14:07:29,516 Epoch[18] Batch [1340]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.133293,	
2017-06-28 14:07:33,699 Epoch[18] Batch [1350]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.133393,	
2017-06-28 14:07:38,220 Epoch[18] Batch [1360]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.133634,	
2017-06-28 14:07:42,735 Epoch[18] Batch [1370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.133645,	
2017-06-28 14:07:47,022 Epoch[18] Batch [1380]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.133570,	
2017-06-28 14:07:51,385 Epoch[18] Batch [1390]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.133414,	
2017-06-28 14:07:55,742 Epoch[18] Batch [1400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.133402,	
2017-06-28 14:08:00,411 Epoch[18] Batch [1410]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.133303,	
2017-06-28 14:08:04,836 Epoch[18] Batch [1420]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.133231,	
2017-06-28 14:08:08,883 Epoch[18] Batch [1430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.133136,	
2017-06-28 14:08:13,126 Epoch[18] Batch [1440]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.133078,	
2017-06-28 14:08:17,741 Epoch[18] Batch [1450]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.132929,	
2017-06-28 14:08:22,378 Epoch[18] Batch [1460]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132936,	
2017-06-28 14:08:26,630 Epoch[18] Batch [1470]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.132851,	
2017-06-28 14:08:31,290 Epoch[18] Batch [1480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.132655,	
2017-06-28 14:08:34,108 Epoch[18] Train-FCNLogLoss=0.132621
2017-06-28 14:08:34,108 Epoch[18] Time cost=663.117
2017-06-28 14:08:34,834 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0019.params"
2017-06-28 14:08:36,479 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0019.states"
2017-06-28 14:08:41,596 Epoch[19] Batch [10]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.119641,	
2017-06-28 14:08:45,843 Epoch[19] Batch [20]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.121602,	
2017-06-28 14:08:50,783 Epoch[19] Batch [30]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.120679,	
2017-06-28 14:08:55,127 Epoch[19] Batch [40]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.118239,	
2017-06-28 14:08:59,412 Epoch[19] Batch [50]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.118117,	
2017-06-28 14:09:03,743 Epoch[19] Batch [60]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.116220,	
2017-06-28 14:09:08,349 Epoch[19] Batch [70]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115672,	
2017-06-28 14:09:12,880 Epoch[19] Batch [80]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.116018,	
2017-06-28 14:09:17,546 Epoch[19] Batch [90]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.116589,	
2017-06-28 14:09:21,949 Epoch[19] Batch [100]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.116526,	
2017-06-28 14:09:26,145 Epoch[19] Batch [110]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.115573,	
2017-06-28 14:09:30,608 Epoch[19] Batch [120]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.115911,	
2017-06-28 14:09:35,014 Epoch[19] Batch [130]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.115701,	
2017-06-28 14:09:39,717 Epoch[19] Batch [140]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.115871,	
2017-06-28 14:09:44,227 Epoch[19] Batch [150]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.116444,	
2017-06-28 14:09:48,932 Epoch[19] Batch [160]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.116196,	
2017-06-28 14:09:53,603 Epoch[19] Batch [170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.115880,	
2017-06-28 14:09:58,322 Epoch[19] Batch [180]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.116214,	
2017-06-28 14:10:02,897 Epoch[19] Batch [190]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.115911,	
2017-06-28 14:10:07,313 Epoch[19] Batch [200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.115879,	
2017-06-28 14:10:11,708 Epoch[19] Batch [210]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.116015,	
2017-06-28 14:10:16,178 Epoch[19] Batch [220]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.115729,	
2017-06-28 14:10:20,557 Epoch[19] Batch [230]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.115285,	
2017-06-28 14:10:25,184 Epoch[19] Batch [240]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.114840,	
2017-06-28 14:10:29,562 Epoch[19] Batch [250]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.115271,	
2017-06-28 14:10:34,421 Epoch[19] Batch [260]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.114976,	
2017-06-28 14:10:39,229 Epoch[19] Batch [270]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.115066,	
2017-06-28 14:10:43,574 Epoch[19] Batch [280]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.115371,	
2017-06-28 14:10:47,932 Epoch[19] Batch [290]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.115810,	
2017-06-28 14:10:52,034 Epoch[19] Batch [300]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.115670,	
2017-06-28 14:10:56,774 Epoch[19] Batch [310]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.115758,	
2017-06-28 14:11:01,576 Epoch[19] Batch [320]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.115595,	
2017-06-28 14:11:06,066 Epoch[19] Batch [330]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.115562,	
2017-06-28 14:11:10,735 Epoch[19] Batch [340]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.115505,	
2017-06-28 14:11:15,346 Epoch[19] Batch [350]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115305,	
2017-06-28 14:11:20,023 Epoch[19] Batch [360]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.115364,	
2017-06-28 14:11:24,623 Epoch[19] Batch [370]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.115128,	
2017-06-28 14:11:28,787 Epoch[19] Batch [380]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.115070,	
2017-06-28 14:11:33,647 Epoch[19] Batch [390]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.114759,	
2017-06-28 14:11:38,349 Epoch[19] Batch [400]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.114845,	
2017-06-28 14:11:42,576 Epoch[19] Batch [410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.114668,	
2017-06-28 14:11:46,951 Epoch[19] Batch [420]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.114942,	
2017-06-28 14:11:51,110 Epoch[19] Batch [430]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.115144,	
2017-06-28 14:11:55,350 Epoch[19] Batch [440]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.114993,	
2017-06-28 14:12:00,022 Epoch[19] Batch [450]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.114755,	
2017-06-28 14:12:04,739 Epoch[19] Batch [460]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.114924,	
2017-06-28 14:12:09,310 Epoch[19] Batch [470]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.114978,	
2017-06-28 14:12:13,579 Epoch[19] Batch [480]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.114789,	
2017-06-28 14:12:18,294 Epoch[19] Batch [490]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.114908,	
2017-06-28 14:12:22,769 Epoch[19] Batch [500]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.114719,	
2017-06-28 14:12:27,006 Epoch[19] Batch [510]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.114737,	
2017-06-28 14:12:31,690 Epoch[19] Batch [520]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.114784,	
2017-06-28 14:12:36,220 Epoch[19] Batch [530]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.114803,	
2017-06-28 14:12:40,591 Epoch[19] Batch [540]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.115109,	
2017-06-28 14:12:45,015 Epoch[19] Batch [550]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.115041,	
2017-06-28 14:12:49,293 Epoch[19] Batch [560]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.115029,	
2017-06-28 14:12:53,485 Epoch[19] Batch [570]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.115028,	
2017-06-28 14:12:57,815 Epoch[19] Batch [580]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.115139,	
2017-06-28 14:13:02,369 Epoch[19] Batch [590]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.115318,	
2017-06-28 14:13:06,995 Epoch[19] Batch [600]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.115246,	
2017-06-28 14:13:11,460 Epoch[19] Batch [610]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.115493,	
2017-06-28 14:13:16,136 Epoch[19] Batch [620]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.115646,	
2017-06-28 14:13:20,752 Epoch[19] Batch [630]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.115746,	
2017-06-28 14:13:25,237 Epoch[19] Batch [640]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.115738,	
2017-06-28 14:13:29,771 Epoch[19] Batch [650]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.116116,	
2017-06-28 14:13:34,393 Epoch[19] Batch [660]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.115944,	
2017-06-28 14:13:38,823 Epoch[19] Batch [670]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.115994,	
2017-06-28 14:13:43,409 Epoch[19] Batch [680]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.116025,	
2017-06-28 14:13:47,994 Epoch[19] Batch [690]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.116182,	
2017-06-28 14:13:52,299 Epoch[19] Batch [700]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.116347,	
2017-06-28 14:13:56,625 Epoch[19] Batch [710]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.116369,	
2017-06-28 14:14:01,460 Epoch[19] Batch [720]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.116442,	
2017-06-28 14:14:06,108 Epoch[19] Batch [730]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.116427,	
2017-06-28 14:14:10,361 Epoch[19] Batch [740]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.116421,	
2017-06-28 14:14:14,691 Epoch[19] Batch [750]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.116486,	
2017-06-28 14:14:19,313 Epoch[19] Batch [760]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.116522,	
2017-06-28 14:14:23,897 Epoch[19] Batch [770]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.116562,	
2017-06-28 14:14:28,303 Epoch[19] Batch [780]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.116447,	
2017-06-28 14:14:32,734 Epoch[19] Batch [790]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.116533,	
2017-06-28 14:14:36,945 Epoch[19] Batch [800]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.116673,	
2017-06-28 14:14:41,469 Epoch[19] Batch [810]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.116506,	
2017-06-28 14:14:45,833 Epoch[19] Batch [820]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.116465,	
2017-06-28 14:14:50,362 Epoch[19] Batch [830]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.116476,	
2017-06-28 14:14:54,982 Epoch[19] Batch [840]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.116510,	
2017-06-28 14:14:59,735 Epoch[19] Batch [850]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.116428,	
2017-06-28 14:15:04,385 Epoch[19] Batch [860]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.116522,	
2017-06-28 14:15:08,908 Epoch[19] Batch [870]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.116471,	
2017-06-28 14:15:13,180 Epoch[19] Batch [880]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.116396,	
2017-06-28 14:15:17,434 Epoch[19] Batch [890]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.116394,	
2017-06-28 14:15:21,894 Epoch[19] Batch [900]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.116505,	
2017-06-28 14:15:25,980 Epoch[19] Batch [910]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116499,	
2017-06-28 14:15:30,546 Epoch[19] Batch [920]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.116424,	
2017-06-28 14:15:35,066 Epoch[19] Batch [930]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.116495,	
2017-06-28 14:15:39,583 Epoch[19] Batch [940]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.116631,	
2017-06-28 14:15:44,006 Epoch[19] Batch [950]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.116529,	
2017-06-28 14:15:48,711 Epoch[19] Batch [960]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.116758,	
2017-06-28 14:15:53,350 Epoch[19] Batch [970]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.116854,	
2017-06-28 14:15:57,789 Epoch[19] Batch [980]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.116973,	
2017-06-28 14:16:02,191 Epoch[19] Batch [990]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.116869,	
2017-06-28 14:16:06,735 Epoch[19] Batch [1000]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.116847,	
2017-06-28 14:16:11,158 Epoch[19] Batch [1010]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.116837,	
2017-06-28 14:16:15,722 Epoch[19] Batch [1020]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.116821,	
2017-06-28 14:16:20,361 Epoch[19] Batch [1030]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.116978,	
2017-06-28 14:16:24,863 Epoch[19] Batch [1040]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.117202,	
2017-06-28 14:16:29,556 Epoch[19] Batch [1050]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.117311,	
2017-06-28 14:16:34,240 Epoch[19] Batch [1060]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.117412,	
2017-06-28 14:16:38,896 Epoch[19] Batch [1070]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.117507,	
2017-06-28 14:16:43,477 Epoch[19] Batch [1080]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117461,	
2017-06-28 14:16:47,862 Epoch[19] Batch [1090]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.117399,	
2017-06-28 14:16:52,571 Epoch[19] Batch [1100]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.117387,	
2017-06-28 14:16:57,062 Epoch[19] Batch [1110]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.117375,	
2017-06-28 14:17:01,531 Epoch[19] Batch [1120]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.117346,	
2017-06-28 14:17:05,971 Epoch[19] Batch [1130]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.117278,	
2017-06-28 14:17:10,814 Epoch[19] Batch [1140]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.117159,	
2017-06-28 14:17:15,282 Epoch[19] Batch [1150]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.117249,	
2017-06-28 14:17:20,030 Epoch[19] Batch [1160]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.117080,	
2017-06-28 14:17:24,714 Epoch[19] Batch [1170]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.117227,	
2017-06-28 14:17:29,002 Epoch[19] Batch [1180]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.117172,	
2017-06-28 14:17:33,794 Epoch[19] Batch [1190]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.117168,	
2017-06-28 14:17:38,311 Epoch[19] Batch [1200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.117179,	
2017-06-28 14:17:42,887 Epoch[19] Batch [1210]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.117133,	
2017-06-28 14:17:47,575 Epoch[19] Batch [1220]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.117075,	
2017-06-28 14:17:52,026 Epoch[19] Batch [1230]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.117018,	
2017-06-28 14:17:56,275 Epoch[19] Batch [1240]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.117058,	
2017-06-28 14:18:00,869 Epoch[19] Batch [1250]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.117070,	
2017-06-28 14:18:05,815 Epoch[19] Batch [1260]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.116967,	
2017-06-28 14:18:10,194 Epoch[19] Batch [1270]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.117011,	
2017-06-28 14:18:14,276 Epoch[19] Batch [1280]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116928,	
2017-06-28 14:18:18,389 Epoch[19] Batch [1290]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116886,	
2017-06-28 14:18:22,886 Epoch[19] Batch [1300]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116863,	
2017-06-28 14:18:27,413 Epoch[19] Batch [1310]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.116884,	
2017-06-28 14:18:32,128 Epoch[19] Batch [1320]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.116987,	
2017-06-28 14:18:36,394 Epoch[19] Batch [1330]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.116961,	
2017-06-28 14:18:40,838 Epoch[19] Batch [1340]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.116897,	
2017-06-28 14:18:45,353 Epoch[19] Batch [1350]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.116822,	
2017-06-28 14:18:49,832 Epoch[19] Batch [1360]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.116874,	
2017-06-28 14:18:54,119 Epoch[19] Batch [1370]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.116846,	
2017-06-28 14:18:58,722 Epoch[19] Batch [1380]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.116826,	
2017-06-28 14:19:03,451 Epoch[19] Batch [1390]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.116859,	
2017-06-28 14:19:08,439 Epoch[19] Batch [1400]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.116829,	
2017-06-28 14:19:12,725 Epoch[19] Batch [1410]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.116841,	
2017-06-28 14:19:16,786 Epoch[19] Batch [1420]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116815,	
2017-06-28 14:19:21,344 Epoch[19] Batch [1430]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.116746,	
2017-06-28 14:19:25,838 Epoch[19] Batch [1440]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116889,	
2017-06-28 14:19:30,510 Epoch[19] Batch [1450]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.116863,	
2017-06-28 14:19:35,062 Epoch[19] Batch [1460]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.116927,	
2017-06-28 14:19:39,247 Epoch[19] Batch [1470]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.116826,	
2017-06-28 14:19:43,790 Epoch[19] Batch [1480]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.116807,	
2017-06-28 14:19:46,158 Epoch[19] Train-FCNLogLoss=0.116838
2017-06-28 14:19:46,158 Epoch[19] Time cost=669.679
2017-06-28 14:19:46,893 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0020.params"
2017-06-28 14:19:48,954 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0020.states"
2017-06-28 14:19:54,413 Epoch[20] Batch [10]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.118089,	
2017-06-28 14:19:59,015 Epoch[20] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.117360,	
2017-06-28 14:20:03,302 Epoch[20] Batch [30]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.117698,	
2017-06-28 14:20:07,698 Epoch[20] Batch [40]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.113887,	
2017-06-28 14:20:12,007 Epoch[20] Batch [50]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.111760,	
2017-06-28 14:20:16,421 Epoch[20] Batch [60]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.111055,	
2017-06-28 14:20:20,931 Epoch[20] Batch [70]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111691,	
2017-06-28 14:20:25,081 Epoch[20] Batch [80]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.110795,	
2017-06-28 14:20:29,773 Epoch[20] Batch [90]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.109650,	
2017-06-28 14:20:33,950 Epoch[20] Batch [100]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109999,	
2017-06-28 14:20:38,238 Epoch[20] Batch [110]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.110181,	
2017-06-28 14:20:42,404 Epoch[20] Batch [120]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.109837,	
2017-06-28 14:20:47,014 Epoch[20] Batch [130]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109343,	
2017-06-28 14:20:51,387 Epoch[20] Batch [140]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.111236,	
2017-06-28 14:20:55,647 Epoch[20] Batch [150]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.110102,	
2017-06-28 14:20:59,947 Epoch[20] Batch [160]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.109837,	
2017-06-28 14:21:04,429 Epoch[20] Batch [170]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.109910,	
2017-06-28 14:21:08,769 Epoch[20] Batch [180]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110042,	
2017-06-28 14:21:13,060 Epoch[20] Batch [190]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.110538,	
2017-06-28 14:21:17,038 Epoch[20] Batch [200]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110030,	
2017-06-28 14:21:21,117 Epoch[20] Batch [210]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.110639,	
2017-06-28 14:21:25,546 Epoch[20] Batch [220]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.110579,	
2017-06-28 14:21:30,383 Epoch[20] Batch [230]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.110617,	
2017-06-28 14:21:34,971 Epoch[20] Batch [240]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.110508,	
2017-06-28 14:21:39,393 Epoch[20] Batch [250]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.110595,	
2017-06-28 14:21:43,962 Epoch[20] Batch [260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.110451,	
2017-06-28 14:21:48,617 Epoch[20] Batch [270]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.110518,	
2017-06-28 14:21:52,904 Epoch[20] Batch [280]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.110251,	
2017-06-28 14:21:57,322 Epoch[20] Batch [290]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.110508,	
2017-06-28 14:22:01,715 Epoch[20] Batch [300]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.110345,	
2017-06-28 14:22:06,285 Epoch[20] Batch [310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.110294,	
2017-06-28 14:22:10,471 Epoch[20] Batch [320]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.109960,	
2017-06-28 14:22:15,048 Epoch[20] Batch [330]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.110170,	
2017-06-28 14:22:19,342 Epoch[20] Batch [340]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.110580,	
2017-06-28 14:22:24,045 Epoch[20] Batch [350]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.110635,	
2017-06-28 14:22:28,411 Epoch[20] Batch [360]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.110552,	
2017-06-28 14:22:33,028 Epoch[20] Batch [370]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.110616,	
2017-06-28 14:22:37,497 Epoch[20] Batch [380]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.110543,	
2017-06-28 14:22:41,797 Epoch[20] Batch [390]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.110256,	
2017-06-28 14:22:46,213 Epoch[20] Batch [400]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.110345,	
2017-06-28 14:22:50,491 Epoch[20] Batch [410]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.110570,	
2017-06-28 14:22:54,781 Epoch[20] Batch [420]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.110545,	
2017-06-28 14:22:59,352 Epoch[20] Batch [430]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.110394,	
2017-06-28 14:23:03,960 Epoch[20] Batch [440]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110463,	
2017-06-28 14:23:08,369 Epoch[20] Batch [450]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.110960,	
2017-06-28 14:23:13,010 Epoch[20] Batch [460]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.110934,	
2017-06-28 14:23:17,557 Epoch[20] Batch [470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.110918,	
2017-06-28 14:23:22,359 Epoch[20] Batch [480]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.110849,	
2017-06-28 14:23:26,971 Epoch[20] Batch [490]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110784,	
2017-06-28 14:23:31,400 Epoch[20] Batch [500]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.111050,	
2017-06-28 14:23:35,913 Epoch[20] Batch [510]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110830,	
2017-06-28 14:23:40,391 Epoch[20] Batch [520]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.110710,	
2017-06-28 14:23:44,978 Epoch[20] Batch [530]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.110771,	
2017-06-28 14:23:49,379 Epoch[20] Batch [540]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.110544,	
2017-06-28 14:23:53,555 Epoch[20] Batch [550]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110462,	
2017-06-28 14:23:58,092 Epoch[20] Batch [560]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.110533,	
2017-06-28 14:24:02,414 Epoch[20] Batch [570]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110383,	
2017-06-28 14:24:06,735 Epoch[20] Batch [580]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110534,	
2017-06-28 14:24:11,169 Epoch[20] Batch [590]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.110749,	
2017-06-28 14:24:15,716 Epoch[20] Batch [600]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.110719,	
2017-06-28 14:24:20,297 Epoch[20] Batch [610]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.110878,	
2017-06-28 14:24:24,662 Epoch[20] Batch [620]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.110954,	
2017-06-28 14:24:28,981 Epoch[20] Batch [630]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110856,	
2017-06-28 14:24:33,256 Epoch[20] Batch [640]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.110952,	
2017-06-28 14:24:37,505 Epoch[20] Batch [650]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.110899,	
2017-06-28 14:24:41,813 Epoch[20] Batch [660]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.111086,	
2017-06-28 14:24:46,276 Epoch[20] Batch [670]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.111034,	
2017-06-28 14:24:50,705 Epoch[20] Batch [680]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.111148,	
2017-06-28 14:24:55,004 Epoch[20] Batch [690]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.111037,	
2017-06-28 14:24:59,534 Epoch[20] Batch [700]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.110982,	
2017-06-28 14:25:03,973 Epoch[20] Batch [710]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.110955,	
2017-06-28 14:25:08,406 Epoch[20] Batch [720]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111242,	
2017-06-28 14:25:12,927 Epoch[20] Batch [730]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.111451,	
2017-06-28 14:25:17,585 Epoch[20] Batch [740]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.111395,	
2017-06-28 14:25:22,270 Epoch[20] Batch [750]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.111432,	
2017-06-28 14:25:26,530 Epoch[20] Batch [760]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.111534,	
2017-06-28 14:25:30,870 Epoch[20] Batch [770]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.111594,	
2017-06-28 14:25:35,356 Epoch[20] Batch [780]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.111650,	
2017-06-28 14:25:39,846 Epoch[20] Batch [790]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.111771,	
2017-06-28 14:25:44,131 Epoch[20] Batch [800]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.111911,	
2017-06-28 14:25:48,641 Epoch[20] Batch [810]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111856,	
2017-06-28 14:25:53,101 Epoch[20] Batch [820]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111961,	
2017-06-28 14:25:57,677 Epoch[20] Batch [830]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.111935,	
2017-06-28 14:26:02,061 Epoch[20] Batch [840]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.111779,	
2017-06-28 14:26:06,944 Epoch[20] Batch [850]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.111654,	
2017-06-28 14:26:11,745 Epoch[20] Batch [860]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.111796,	
2017-06-28 14:26:16,148 Epoch[20] Batch [870]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.111773,	
2017-06-28 14:26:20,656 Epoch[20] Batch [880]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111874,	
2017-06-28 14:26:25,080 Epoch[20] Batch [890]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.111969,	
2017-06-28 14:26:29,577 Epoch[20] Batch [900]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.111965,	
2017-06-28 14:26:34,037 Epoch[20] Batch [910]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111934,	
2017-06-28 14:26:38,170 Epoch[20] Batch [920]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112097,	
2017-06-28 14:26:42,624 Epoch[20] Batch [930]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.112059,	
2017-06-28 14:26:46,790 Epoch[20] Batch [940]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.112107,	
2017-06-28 14:26:51,274 Epoch[20] Batch [950]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.112209,	
2017-06-28 14:26:55,829 Epoch[20] Batch [960]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.112285,	
2017-06-28 14:27:00,324 Epoch[20] Batch [970]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.112281,	
2017-06-28 14:27:04,888 Epoch[20] Batch [980]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.112283,	
2017-06-28 14:27:09,412 Epoch[20] Batch [990]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112299,	
2017-06-28 14:27:13,558 Epoch[20] Batch [1000]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112548,	
2017-06-28 14:27:18,119 Epoch[20] Batch [1010]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112956,	
2017-06-28 14:27:22,435 Epoch[20] Batch [1020]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.113001,	
2017-06-28 14:27:26,914 Epoch[20] Batch [1030]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.113185,	
2017-06-28 14:27:31,187 Epoch[20] Batch [1040]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.113386,	
2017-06-28 14:27:35,542 Epoch[20] Batch [1050]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.113306,	
2017-06-28 14:27:40,223 Epoch[20] Batch [1060]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.113459,	
2017-06-28 14:27:44,675 Epoch[20] Batch [1070]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.113395,	
2017-06-28 14:27:48,942 Epoch[20] Batch [1080]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.113379,	
2017-06-28 14:27:53,503 Epoch[20] Batch [1090]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.113408,	
2017-06-28 14:27:58,093 Epoch[20] Batch [1100]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.113294,	
2017-06-28 14:28:02,534 Epoch[20] Batch [1110]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.113297,	
2017-06-28 14:28:06,724 Epoch[20] Batch [1120]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.113790,	
2017-06-28 14:28:11,016 Epoch[20] Batch [1130]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.113909,	
2017-06-28 14:28:15,493 Epoch[20] Batch [1140]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.113872,	
2017-06-28 14:28:19,955 Epoch[20] Batch [1150]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.113891,	
2017-06-28 14:28:24,591 Epoch[20] Batch [1160]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.113867,	
2017-06-28 14:28:28,972 Epoch[20] Batch [1170]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.113883,	
2017-06-28 14:28:33,306 Epoch[20] Batch [1180]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.113856,	
2017-06-28 14:28:38,063 Epoch[20] Batch [1190]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.113929,	
2017-06-28 14:28:42,765 Epoch[20] Batch [1200]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.113860,	
2017-06-28 14:28:47,466 Epoch[20] Batch [1210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.113994,	
2017-06-28 14:28:51,762 Epoch[20] Batch [1220]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.113895,	
2017-06-28 14:28:56,273 Epoch[20] Batch [1230]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.113966,	
2017-06-28 14:29:00,869 Epoch[20] Batch [1240]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.113830,	
2017-06-28 14:29:05,384 Epoch[20] Batch [1250]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.113821,	
2017-06-28 14:29:09,894 Epoch[20] Batch [1260]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.113835,	
2017-06-28 14:29:14,546 Epoch[20] Batch [1270]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.113848,	
2017-06-28 14:29:18,782 Epoch[20] Batch [1280]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.113911,	
2017-06-28 14:29:23,323 Epoch[20] Batch [1290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.113810,	
2017-06-28 14:29:27,896 Epoch[20] Batch [1300]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.113744,	
2017-06-28 14:29:32,466 Epoch[20] Batch [1310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.113706,	
2017-06-28 14:29:37,135 Epoch[20] Batch [1320]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.113948,	
2017-06-28 14:29:41,501 Epoch[20] Batch [1330]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.113910,	
2017-06-28 14:29:45,965 Epoch[20] Batch [1340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.113900,	
2017-06-28 14:29:50,402 Epoch[20] Batch [1350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.113875,	
2017-06-28 14:29:54,904 Epoch[20] Batch [1360]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.113810,	
2017-06-28 14:29:59,448 Epoch[20] Batch [1370]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.113822,	
2017-06-28 14:30:04,111 Epoch[20] Batch [1380]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.113777,	
2017-06-28 14:30:08,788 Epoch[20] Batch [1390]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.113806,	
2017-06-28 14:30:13,353 Epoch[20] Batch [1400]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.113781,	
2017-06-28 14:30:17,634 Epoch[20] Batch [1410]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.113633,	
2017-06-28 14:30:21,709 Epoch[20] Batch [1420]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113649,	
2017-06-28 14:30:25,744 Epoch[20] Batch [1430]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113584,	
2017-06-28 14:30:30,147 Epoch[20] Batch [1440]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.113640,	
2017-06-28 14:30:34,873 Epoch[20] Batch [1450]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.113691,	
2017-06-28 14:30:39,269 Epoch[20] Batch [1460]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.113647,	
2017-06-28 14:30:43,642 Epoch[20] Batch [1470]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.113628,	
2017-06-28 14:30:48,040 Epoch[20] Batch [1480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.113690,	
2017-06-28 14:30:50,721 Epoch[20] Train-FCNLogLoss=0.113754
2017-06-28 14:30:50,721 Epoch[20] Time cost=661.767
2017-06-28 14:30:51,490 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0021.params"
2017-06-28 14:30:52,993 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0021.states"
2017-06-28 14:30:58,745 Epoch[21] Batch [10]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.110062,	
2017-06-28 14:31:03,762 Epoch[21] Batch [20]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.109578,	
2017-06-28 14:31:08,020 Epoch[21] Batch [30]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.107903,	
2017-06-28 14:31:12,393 Epoch[21] Batch [40]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.108211,	
2017-06-28 14:31:16,610 Epoch[21] Batch [50]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.108886,	
2017-06-28 14:31:21,214 Epoch[21] Batch [60]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108924,	
2017-06-28 14:31:25,482 Epoch[21] Batch [70]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.107938,	
2017-06-28 14:31:29,740 Epoch[21] Batch [80]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.109637,	
2017-06-28 14:31:33,962 Epoch[21] Batch [90]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.110392,	
2017-06-28 14:31:38,542 Epoch[21] Batch [100]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.110405,	
2017-06-28 14:31:42,928 Epoch[21] Batch [110]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.109799,	
2017-06-28 14:31:47,609 Epoch[21] Batch [120]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.110274,	
2017-06-28 14:31:51,865 Epoch[21] Batch [130]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.109872,	
2017-06-28 14:31:56,778 Epoch[21] Batch [140]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.109478,	
2017-06-28 14:32:01,229 Epoch[21] Batch [150]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.108832,	
2017-06-28 14:32:05,915 Epoch[21] Batch [160]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109300,	
2017-06-28 14:32:10,006 Epoch[21] Batch [170]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109182,	
2017-06-28 14:32:14,283 Epoch[21] Batch [180]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.109255,	
2017-06-28 14:32:18,661 Epoch[21] Batch [190]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.108867,	
2017-06-28 14:32:22,773 Epoch[21] Batch [200]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109882,	
2017-06-28 14:32:26,986 Epoch[21] Batch [210]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109462,	
2017-06-28 14:32:31,403 Epoch[21] Batch [220]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109763,	
2017-06-28 14:32:35,683 Epoch[21] Batch [230]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.109658,	
2017-06-28 14:32:40,167 Epoch[21] Batch [240]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109970,	
2017-06-28 14:32:44,854 Epoch[21] Batch [250]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.109565,	
2017-06-28 14:32:49,668 Epoch[21] Batch [260]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.109873,	
2017-06-28 14:32:54,162 Epoch[21] Batch [270]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.109801,	
2017-06-28 14:32:58,727 Epoch[21] Batch [280]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109859,	
2017-06-28 14:33:03,144 Epoch[21] Batch [290]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109808,	
2017-06-28 14:33:07,387 Epoch[21] Batch [300]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.109865,	
2017-06-28 14:33:12,341 Epoch[21] Batch [310]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.109906,	
2017-06-28 14:33:17,017 Epoch[21] Batch [320]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.110081,	
2017-06-28 14:33:21,336 Epoch[21] Batch [330]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110212,	
2017-06-28 14:33:25,761 Epoch[21] Batch [340]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.110196,	
2017-06-28 14:33:30,325 Epoch[21] Batch [350]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.110243,	
2017-06-28 14:33:34,787 Epoch[21] Batch [360]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.110254,	
2017-06-28 14:33:39,046 Epoch[21] Batch [370]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.110219,	
2017-06-28 14:33:43,415 Epoch[21] Batch [380]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.110239,	
2017-06-28 14:33:47,981 Epoch[21] Batch [390]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.110274,	
2017-06-28 14:33:52,648 Epoch[21] Batch [400]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.110166,	
2017-06-28 14:33:56,849 Epoch[21] Batch [410]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.110000,	
2017-06-28 14:34:00,924 Epoch[21] Batch [420]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.110225,	
2017-06-28 14:34:05,612 Epoch[21] Batch [430]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.110431,	
2017-06-28 14:34:10,215 Epoch[21] Batch [440]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.110348,	
2017-06-28 14:34:14,712 Epoch[21] Batch [450]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.110208,	
2017-06-28 14:34:18,913 Epoch[21] Batch [460]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.110959,	
2017-06-28 14:34:23,551 Epoch[21] Batch [470]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.111041,	
2017-06-28 14:34:27,877 Epoch[21] Batch [480]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111060,	
2017-06-28 14:34:32,158 Epoch[21] Batch [490]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.111011,	
2017-06-28 14:34:36,362 Epoch[21] Batch [500]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.111021,	
2017-06-28 14:34:40,883 Epoch[21] Batch [510]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.110849,	
2017-06-28 14:34:45,749 Epoch[21] Batch [520]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.110760,	
2017-06-28 14:34:49,943 Epoch[21] Batch [530]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110775,	
2017-06-28 14:34:54,602 Epoch[21] Batch [540]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.110868,	
2017-06-28 14:34:59,239 Epoch[21] Batch [550]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.110958,	
2017-06-28 14:35:04,110 Epoch[21] Batch [560]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.111073,	
2017-06-28 14:35:08,617 Epoch[21] Batch [570]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.111195,	
2017-06-28 14:35:12,947 Epoch[21] Batch [580]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111468,	
2017-06-28 14:35:17,422 Epoch[21] Batch [590]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.111517,	
2017-06-28 14:35:21,781 Epoch[21] Batch [600]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.111561,	
2017-06-28 14:35:25,915 Epoch[21] Batch [610]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111607,	
2017-06-28 14:35:30,225 Epoch[21] Batch [620]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.111631,	
2017-06-28 14:35:34,357 Epoch[21] Batch [630]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111717,	
2017-06-28 14:35:38,455 Epoch[21] Batch [640]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.111729,	
2017-06-28 14:35:42,678 Epoch[21] Batch [650]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.111837,	
2017-06-28 14:35:47,135 Epoch[21] Batch [660]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.111981,	
2017-06-28 14:35:51,418 Epoch[21] Batch [670]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.111960,	
2017-06-28 14:35:55,938 Epoch[21] Batch [680]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.112043,	
2017-06-28 14:36:00,573 Epoch[21] Batch [690]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.112255,	
2017-06-28 14:36:05,099 Epoch[21] Batch [700]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112240,	
2017-06-28 14:36:09,542 Epoch[21] Batch [710]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.112170,	
2017-06-28 14:36:13,819 Epoch[21] Batch [720]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112098,	
2017-06-28 14:36:18,099 Epoch[21] Batch [730]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112193,	
2017-06-28 14:36:22,918 Epoch[21] Batch [740]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.112166,	
2017-06-28 14:36:27,479 Epoch[21] Batch [750]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112236,	
2017-06-28 14:36:32,318 Epoch[21] Batch [760]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.112457,	
2017-06-28 14:36:36,796 Epoch[21] Batch [770]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.112346,	
2017-06-28 14:36:41,529 Epoch[21] Batch [780]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.112270,	
2017-06-28 14:36:46,001 Epoch[21] Batch [790]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.112339,	
2017-06-28 14:36:50,531 Epoch[21] Batch [800]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.112209,	
2017-06-28 14:36:54,769 Epoch[21] Batch [810]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.112015,	
2017-06-28 14:36:59,443 Epoch[21] Batch [820]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.111983,	
2017-06-28 14:37:03,698 Epoch[21] Batch [830]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111975,	
2017-06-28 14:37:08,133 Epoch[21] Batch [840]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111848,	
2017-06-28 14:37:12,849 Epoch[21] Batch [850]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.111799,	
2017-06-28 14:37:17,554 Epoch[21] Batch [860]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.111710,	
2017-06-28 14:37:22,158 Epoch[21] Batch [870]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.111610,	
2017-06-28 14:37:26,889 Epoch[21] Batch [880]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.111651,	
2017-06-28 14:37:31,616 Epoch[21] Batch [890]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.111472,	
2017-06-28 14:37:35,916 Epoch[21] Batch [900]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.111266,	
2017-06-28 14:37:40,020 Epoch[21] Batch [910]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111342,	
2017-06-28 14:37:44,434 Epoch[21] Batch [920]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.111267,	
2017-06-28 14:37:49,135 Epoch[21] Batch [930]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.111301,	
2017-06-28 14:37:53,634 Epoch[21] Batch [940]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.111232,	
2017-06-28 14:37:58,111 Epoch[21] Batch [950]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.111176,	
2017-06-28 14:38:02,515 Epoch[21] Batch [960]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.111345,	
2017-06-28 14:38:07,192 Epoch[21] Batch [970]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.111421,	
2017-06-28 14:38:11,635 Epoch[21] Batch [980]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.111578,	
2017-06-28 14:38:16,163 Epoch[21] Batch [990]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.111413,	
2017-06-28 14:38:20,658 Epoch[21] Batch [1000]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.111461,	
2017-06-28 14:38:25,023 Epoch[21] Batch [1010]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.111516,	
2017-06-28 14:38:29,561 Epoch[21] Batch [1020]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.111542,	
2017-06-28 14:38:33,835 Epoch[21] Batch [1030]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.111412,	
2017-06-28 14:38:38,292 Epoch[21] Batch [1040]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.111416,	
2017-06-28 14:38:42,622 Epoch[21] Batch [1050]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111424,	
2017-06-28 14:38:47,208 Epoch[21] Batch [1060]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.111338,	
2017-06-28 14:38:51,933 Epoch[21] Batch [1070]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.111245,	
2017-06-28 14:38:56,325 Epoch[21] Batch [1080]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.111413,	
2017-06-28 14:39:00,992 Epoch[21] Batch [1090]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.111436,	
2017-06-28 14:39:05,896 Epoch[21] Batch [1100]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.111500,	
2017-06-28 14:39:10,815 Epoch[21] Batch [1110]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.111496,	
2017-06-28 14:39:15,363 Epoch[21] Batch [1120]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.111519,	
2017-06-28 14:39:19,766 Epoch[21] Batch [1130]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.111496,	
2017-06-28 14:39:24,262 Epoch[21] Batch [1140]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.111491,	
2017-06-28 14:39:28,923 Epoch[21] Batch [1150]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.111410,	
2017-06-28 14:39:33,511 Epoch[21] Batch [1160]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.111573,	
2017-06-28 14:39:38,111 Epoch[21] Batch [1170]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.111546,	
2017-06-28 14:39:42,507 Epoch[21] Batch [1180]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.111541,	
2017-06-28 14:39:46,916 Epoch[21] Batch [1190]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.111501,	
2017-06-28 14:39:51,529 Epoch[21] Batch [1200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.111589,	
2017-06-28 14:39:56,210 Epoch[21] Batch [1210]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.111568,	
2017-06-28 14:40:00,580 Epoch[21] Batch [1220]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.111490,	
2017-06-28 14:40:04,899 Epoch[21] Batch [1230]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.111393,	
2017-06-28 14:40:09,392 Epoch[21] Batch [1240]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.111315,	
2017-06-28 14:40:14,253 Epoch[21] Batch [1250]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.111418,	
2017-06-28 14:40:18,773 Epoch[21] Batch [1260]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.111351,	
2017-06-28 14:40:23,475 Epoch[21] Batch [1270]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.111338,	
2017-06-28 14:40:27,931 Epoch[21] Batch [1280]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.111382,	
2017-06-28 14:40:32,603 Epoch[21] Batch [1290]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.111324,	
2017-06-28 14:40:37,347 Epoch[21] Batch [1300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.111443,	
2017-06-28 14:40:41,531 Epoch[21] Batch [1310]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.111528,	
2017-06-28 14:40:46,304 Epoch[21] Batch [1320]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.111627,	
2017-06-28 14:40:50,757 Epoch[21] Batch [1330]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.111503,	
2017-06-28 14:40:55,268 Epoch[21] Batch [1340]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111474,	
2017-06-28 14:40:59,684 Epoch[21] Batch [1350]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.111520,	
2017-06-28 14:41:04,583 Epoch[21] Batch [1360]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.111454,	
2017-06-28 14:41:09,255 Epoch[21] Batch [1370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.111563,	
2017-06-28 14:41:13,619 Epoch[21] Batch [1380]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.111670,	
2017-06-28 14:41:18,543 Epoch[21] Batch [1390]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.111691,	
2017-06-28 14:41:23,248 Epoch[21] Batch [1400]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.111685,	
2017-06-28 14:41:27,626 Epoch[21] Batch [1410]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.111755,	
2017-06-28 14:41:31,898 Epoch[21] Batch [1420]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.111918,	
2017-06-28 14:41:36,243 Epoch[21] Batch [1430]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.111967,	
2017-06-28 14:41:41,119 Epoch[21] Batch [1440]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.111882,	
2017-06-28 14:41:46,171 Epoch[21] Batch [1450]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.111934,	
2017-06-28 14:41:51,162 Epoch[21] Batch [1460]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.111941,	
2017-06-28 14:41:55,338 Epoch[21] Batch [1470]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.111927,	
2017-06-28 14:42:00,050 Epoch[21] Batch [1480]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.111847,	
2017-06-28 14:42:02,953 Epoch[21] Train-FCNLogLoss=0.111875
2017-06-28 14:42:02,953 Epoch[21] Time cost=669.960
2017-06-28 14:42:03,571 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0022.params"
2017-06-28 14:42:05,019 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0022.states"
2017-06-28 14:42:10,800 Epoch[22] Batch [10]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.102708,	
2017-06-28 14:42:15,303 Epoch[22] Batch [20]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.109012,	
2017-06-28 14:42:19,919 Epoch[22] Batch [30]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.106456,	
2017-06-28 14:42:24,433 Epoch[22] Batch [40]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.105001,	
2017-06-28 14:42:29,037 Epoch[22] Batch [50]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107534,	
2017-06-28 14:42:33,637 Epoch[22] Batch [60]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108943,	
2017-06-28 14:42:38,364 Epoch[22] Batch [70]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.108624,	
2017-06-28 14:42:42,734 Epoch[22] Batch [80]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.107793,	
2017-06-28 14:42:47,437 Epoch[22] Batch [90]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.105955,	
2017-06-28 14:42:52,139 Epoch[22] Batch [100]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.105010,	
2017-06-28 14:42:56,801 Epoch[22] Batch [110]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105324,	
2017-06-28 14:43:01,142 Epoch[22] Batch [120]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.105834,	
2017-06-28 14:43:05,836 Epoch[22] Batch [130]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.105994,	
2017-06-28 14:43:10,615 Epoch[22] Batch [140]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.106812,	
2017-06-28 14:43:15,141 Epoch[22] Batch [150]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107283,	
2017-06-28 14:43:19,842 Epoch[22] Batch [160]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.106494,	
2017-06-28 14:43:24,583 Epoch[22] Batch [170]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.106437,	
2017-06-28 14:43:29,139 Epoch[22] Batch [180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105629,	
2017-06-28 14:43:33,804 Epoch[22] Batch [190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.105973,	
2017-06-28 14:43:38,303 Epoch[22] Batch [200]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.105956,	
2017-06-28 14:43:42,992 Epoch[22] Batch [210]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.105752,	
2017-06-28 14:43:47,650 Epoch[22] Batch [220]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.105890,	
2017-06-28 14:43:52,212 Epoch[22] Batch [230]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.106110,	
2017-06-28 14:43:56,543 Epoch[22] Batch [240]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.106033,	
2017-06-28 14:44:01,023 Epoch[22] Batch [250]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106710,	
2017-06-28 14:44:05,717 Epoch[22] Batch [260]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.106736,	
2017-06-28 14:44:10,198 Epoch[22] Batch [270]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.107513,	
2017-06-28 14:44:14,478 Epoch[22] Batch [280]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.107648,	
2017-06-28 14:44:19,294 Epoch[22] Batch [290]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.107605,	
2017-06-28 14:44:23,803 Epoch[22] Batch [300]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.107314,	
2017-06-28 14:44:28,349 Epoch[22] Batch [310]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107198,	
2017-06-28 14:44:33,015 Epoch[22] Batch [320]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.107359,	
2017-06-28 14:44:37,292 Epoch[22] Batch [330]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.107122,	
2017-06-28 14:44:41,736 Epoch[22] Batch [340]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.107204,	
2017-06-28 14:44:46,120 Epoch[22] Batch [350]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.107389,	
2017-06-28 14:44:50,405 Epoch[22] Batch [360]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.107252,	
2017-06-28 14:44:54,716 Epoch[22] Batch [370]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.107306,	
2017-06-28 14:44:59,357 Epoch[22] Batch [380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107179,	
2017-06-28 14:45:03,856 Epoch[22] Batch [390]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.106971,	
2017-06-28 14:45:08,418 Epoch[22] Batch [400]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.106937,	
2017-06-28 14:45:12,907 Epoch[22] Batch [410]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.106994,	
2017-06-28 14:45:17,389 Epoch[22] Batch [420]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.107045,	
2017-06-28 14:45:21,978 Epoch[22] Batch [430]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.107178,	
2017-06-28 14:45:26,721 Epoch[22] Batch [440]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.107328,	
2017-06-28 14:45:31,290 Epoch[22] Batch [450]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.107329,	
2017-06-28 14:45:36,200 Epoch[22] Batch [460]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.107622,	
2017-06-28 14:45:41,019 Epoch[22] Batch [470]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.107604,	
2017-06-28 14:45:46,043 Epoch[22] Batch [480]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.107831,	
2017-06-28 14:45:50,702 Epoch[22] Batch [490]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.108126,	
2017-06-28 14:45:55,031 Epoch[22] Batch [500]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.108085,	
2017-06-28 14:45:59,634 Epoch[22] Batch [510]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108265,	
2017-06-28 14:46:04,075 Epoch[22] Batch [520]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108287,	
2017-06-28 14:46:08,667 Epoch[22] Batch [530]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.108324,	
2017-06-28 14:46:13,008 Epoch[22] Batch [540]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108681,	
2017-06-28 14:46:17,967 Epoch[22] Batch [550]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.108693,	
2017-06-28 14:46:22,407 Epoch[22] Batch [560]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108683,	
2017-06-28 14:46:26,865 Epoch[22] Batch [570]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108593,	
2017-06-28 14:46:31,595 Epoch[22] Batch [580]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.108586,	
2017-06-28 14:46:36,510 Epoch[22] Batch [590]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.108399,	
2017-06-28 14:46:41,078 Epoch[22] Batch [600]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108486,	
2017-06-28 14:46:45,787 Epoch[22] Batch [610]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.108485,	
2017-06-28 14:46:50,316 Epoch[22] Batch [620]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.108686,	
2017-06-28 14:46:54,871 Epoch[22] Batch [630]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.108601,	
2017-06-28 14:46:59,043 Epoch[22] Batch [640]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.108370,	
2017-06-28 14:47:03,341 Epoch[22] Batch [650]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.108310,	
2017-06-28 14:47:08,210 Epoch[22] Batch [660]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.108387,	
2017-06-28 14:47:12,674 Epoch[22] Batch [670]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.108422,	
2017-06-28 14:47:16,875 Epoch[22] Batch [680]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.108372,	
2017-06-28 14:47:21,724 Epoch[22] Batch [690]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.108407,	
2017-06-28 14:47:27,021 Epoch[22] Batch [700]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.108635,	
2017-06-28 14:47:31,684 Epoch[22] Batch [710]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.108625,	
2017-06-28 14:47:36,123 Epoch[22] Batch [720]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108525,	
2017-06-28 14:47:40,351 Epoch[22] Batch [730]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.108614,	
2017-06-28 14:47:44,621 Epoch[22] Batch [740]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.108712,	
2017-06-28 14:47:48,999 Epoch[22] Batch [750]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.108759,	
2017-06-28 14:47:53,463 Epoch[22] Batch [760]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.108785,	
2017-06-28 14:47:57,968 Epoch[22] Batch [770]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108741,	
2017-06-28 14:48:02,548 Epoch[22] Batch [780]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.108728,	
2017-06-28 14:48:06,761 Epoch[22] Batch [790]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.108631,	
2017-06-28 14:48:11,261 Epoch[22] Batch [800]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.108597,	
2017-06-28 14:48:15,753 Epoch[22] Batch [810]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.108607,	
2017-06-28 14:48:20,040 Epoch[22] Batch [820]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.108539,	
2017-06-28 14:48:24,871 Epoch[22] Batch [830]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.108502,	
2017-06-28 14:48:29,446 Epoch[22] Batch [840]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.108457,	
2017-06-28 14:48:33,948 Epoch[22] Batch [850]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.108527,	
2017-06-28 14:48:38,290 Epoch[22] Batch [860]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108584,	
2017-06-28 14:48:42,849 Epoch[22] Batch [870]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108641,	
2017-06-28 14:48:47,157 Epoch[22] Batch [880]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.108432,	
2017-06-28 14:48:51,716 Epoch[22] Batch [890]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108369,	
2017-06-28 14:48:56,188 Epoch[22] Batch [900]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.108249,	
2017-06-28 14:49:00,801 Epoch[22] Batch [910]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108209,	
2017-06-28 14:49:05,264 Epoch[22] Batch [920]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.108238,	
2017-06-28 14:49:09,560 Epoch[22] Batch [930]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.108028,	
2017-06-28 14:49:14,225 Epoch[22] Batch [940]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.107965,	
2017-06-28 14:49:18,665 Epoch[22] Batch [950]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108022,	
2017-06-28 14:49:23,095 Epoch[22] Batch [960]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.108175,	
2017-06-28 14:49:27,622 Epoch[22] Batch [970]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108297,	
2017-06-28 14:49:32,005 Epoch[22] Batch [980]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.108455,	
2017-06-28 14:49:36,283 Epoch[22] Batch [990]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.108789,	
2017-06-28 14:49:40,535 Epoch[22] Batch [1000]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.108965,	
2017-06-28 14:49:44,795 Epoch[22] Batch [1010]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.109033,	
2017-06-28 14:49:49,593 Epoch[22] Batch [1020]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.109216,	
2017-06-28 14:49:53,901 Epoch[22] Batch [1030]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.109237,	
2017-06-28 14:49:58,374 Epoch[22] Batch [1040]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.109437,	
2017-06-28 14:50:02,768 Epoch[22] Batch [1050]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.109453,	
2017-06-28 14:50:07,270 Epoch[22] Batch [1060]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.109389,	
2017-06-28 14:50:11,831 Epoch[22] Batch [1070]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109391,	
2017-06-28 14:50:16,857 Epoch[22] Batch [1080]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.109502,	
2017-06-28 14:50:21,838 Epoch[22] Batch [1090]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.109496,	
2017-06-28 14:50:26,274 Epoch[22] Batch [1100]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.109474,	
2017-06-28 14:50:30,402 Epoch[22] Batch [1110]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.109514,	
2017-06-28 14:50:35,357 Epoch[22] Batch [1120]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.109615,	
2017-06-28 14:50:40,236 Epoch[22] Batch [1130]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.109592,	
2017-06-28 14:50:44,898 Epoch[22] Batch [1140]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.109564,	
2017-06-28 14:50:49,261 Epoch[22] Batch [1150]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.109643,	
2017-06-28 14:50:53,610 Epoch[22] Batch [1160]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.109656,	
2017-06-28 14:50:58,027 Epoch[22] Batch [1170]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109636,	
2017-06-28 14:51:02,300 Epoch[22] Batch [1180]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109652,	
2017-06-28 14:51:06,632 Epoch[22] Batch [1190]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.109720,	
2017-06-28 14:51:10,954 Epoch[22] Batch [1200]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.109706,	
2017-06-28 14:51:15,487 Epoch[22] Batch [1210]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.109639,	
2017-06-28 14:51:20,366 Epoch[22] Batch [1220]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.109668,	
2017-06-28 14:51:24,752 Epoch[22] Batch [1230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.109586,	
2017-06-28 14:51:29,265 Epoch[22] Batch [1240]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.109511,	
2017-06-28 14:51:34,000 Epoch[22] Batch [1250]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109444,	
2017-06-28 14:51:38,641 Epoch[22] Batch [1260]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.109420,	
2017-06-28 14:51:43,049 Epoch[22] Batch [1270]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.109468,	
2017-06-28 14:51:47,630 Epoch[22] Batch [1280]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.109579,	
2017-06-28 14:51:52,192 Epoch[22] Batch [1290]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109498,	
2017-06-28 14:51:56,501 Epoch[22] Batch [1300]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.109549,	
2017-06-28 14:52:00,997 Epoch[22] Batch [1310]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.109494,	
2017-06-28 14:52:05,379 Epoch[22] Batch [1320]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.109541,	
2017-06-28 14:52:10,095 Epoch[22] Batch [1330]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.109650,	
2017-06-28 14:52:15,104 Epoch[22] Batch [1340]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.109680,	
2017-06-28 14:52:19,769 Epoch[22] Batch [1350]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.109635,	
2017-06-28 14:52:24,381 Epoch[22] Batch [1360]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.109528,	
2017-06-28 14:52:29,010 Epoch[22] Batch [1370]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109452,	
2017-06-28 14:52:33,336 Epoch[22] Batch [1380]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109583,	
2017-06-28 14:52:37,848 Epoch[22] Batch [1390]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.109554,	
2017-06-28 14:52:42,387 Epoch[22] Batch [1400]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109565,	
2017-06-28 14:52:46,900 Epoch[22] Batch [1410]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.109572,	
2017-06-28 14:52:51,966 Epoch[22] Batch [1420]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.109642,	
2017-06-28 14:52:56,434 Epoch[22] Batch [1430]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.109711,	
2017-06-28 14:53:00,719 Epoch[22] Batch [1440]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.109805,	
2017-06-28 14:53:05,162 Epoch[22] Batch [1450]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.109827,	
2017-06-28 14:53:09,680 Epoch[22] Batch [1460]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109826,	
2017-06-28 14:53:14,056 Epoch[22] Batch [1470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.109814,	
2017-06-28 14:53:18,582 Epoch[22] Batch [1480]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.109834,	
2017-06-28 14:53:21,331 Epoch[22] Train-FCNLogLoss=0.109780
2017-06-28 14:53:21,332 Epoch[22] Time cost=676.312
2017-06-28 14:53:22,072 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0023.params"
2017-06-28 14:53:23,457 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0023.states"
2017-06-28 14:53:28,776 Epoch[23] Batch [10]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107512,	
2017-06-28 14:53:32,991 Epoch[23] Batch [20]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.104863,	
2017-06-28 14:53:37,640 Epoch[23] Batch [30]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.103289,	
2017-06-28 14:53:42,269 Epoch[23] Batch [40]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.105647,	
2017-06-28 14:53:46,798 Epoch[23] Batch [50]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.107872,	
2017-06-28 14:53:51,498 Epoch[23] Batch [60]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.106387,	
2017-06-28 14:53:55,879 Epoch[23] Batch [70]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.105247,	
2017-06-28 14:54:00,078 Epoch[23] Batch [80]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.105959,	
2017-06-28 14:54:04,510 Epoch[23] Batch [90]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.106902,	
2017-06-28 14:54:09,340 Epoch[23] Batch [100]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.105960,	
2017-06-28 14:54:13,909 Epoch[23] Batch [110]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.105850,	
2017-06-28 14:54:18,839 Epoch[23] Batch [120]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.105157,	
2017-06-28 14:54:23,407 Epoch[23] Batch [130]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.105863,	
2017-06-28 14:54:27,948 Epoch[23] Batch [140]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.107063,	
2017-06-28 14:54:32,385 Epoch[23] Batch [150]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.106872,	
2017-06-28 14:54:37,470 Epoch[23] Batch [160]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.106836,	
2017-06-28 14:54:42,005 Epoch[23] Batch [170]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.106369,	
2017-06-28 14:54:46,483 Epoch[23] Batch [180]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.106152,	
2017-06-28 14:54:50,835 Epoch[23] Batch [190]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.105900,	
2017-06-28 14:54:55,477 Epoch[23] Batch [200]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.105866,	
2017-06-28 14:54:59,764 Epoch[23] Batch [210]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.106546,	
2017-06-28 14:55:03,926 Epoch[23] Batch [220]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.106503,	
2017-06-28 14:55:07,903 Epoch[23] Batch [230]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.106169,	
2017-06-28 14:55:12,598 Epoch[23] Batch [240]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.106015,	
2017-06-28 14:55:17,053 Epoch[23] Batch [250]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.106303,	
2017-06-28 14:55:21,514 Epoch[23] Batch [260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.106256,	
2017-06-28 14:55:25,755 Epoch[23] Batch [270]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106050,	
2017-06-28 14:55:30,231 Epoch[23] Batch [280]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.105985,	
2017-06-28 14:55:34,544 Epoch[23] Batch [290]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.105657,	
2017-06-28 14:55:38,862 Epoch[23] Batch [300]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.105427,	
2017-06-28 14:55:43,159 Epoch[23] Batch [310]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105270,	
2017-06-28 14:55:47,755 Epoch[23] Batch [320]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.105688,	
2017-06-28 14:55:52,313 Epoch[23] Batch [330]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105515,	
2017-06-28 14:55:57,023 Epoch[23] Batch [340]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.105289,	
2017-06-28 14:56:01,625 Epoch[23] Batch [350]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.105361,	
2017-06-28 14:56:05,923 Epoch[23] Batch [360]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105413,	
2017-06-28 14:56:10,293 Epoch[23] Batch [370]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.105204,	
2017-06-28 14:56:14,673 Epoch[23] Batch [380]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.105234,	
2017-06-28 14:56:19,223 Epoch[23] Batch [390]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.105197,	
2017-06-28 14:56:23,985 Epoch[23] Batch [400]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.105307,	
2017-06-28 14:56:28,977 Epoch[23] Batch [410]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.105510,	
2017-06-28 14:56:33,757 Epoch[23] Batch [420]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.105487,	
2017-06-28 14:56:38,347 Epoch[23] Batch [430]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.105414,	
2017-06-28 14:56:42,635 Epoch[23] Batch [440]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.105475,	
2017-06-28 14:56:46,957 Epoch[23] Batch [450]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.105407,	
2017-06-28 14:56:51,356 Epoch[23] Batch [460]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.105471,	
2017-06-28 14:56:55,827 Epoch[23] Batch [470]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.105443,	
2017-06-28 14:57:00,357 Epoch[23] Batch [480]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.105331,	
2017-06-28 14:57:05,413 Epoch[23] Batch [490]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.105653,	
2017-06-28 14:57:10,200 Epoch[23] Batch [500]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.105770,	
2017-06-28 14:57:14,535 Epoch[23] Batch [510]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.105849,	
2017-06-28 14:57:18,678 Epoch[23] Batch [520]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.105977,	
2017-06-28 14:57:23,182 Epoch[23] Batch [530]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.106123,	
2017-06-28 14:57:27,515 Epoch[23] Batch [540]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.106213,	
2017-06-28 14:57:32,092 Epoch[23] Batch [550]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.106480,	
2017-06-28 14:57:36,751 Epoch[23] Batch [560]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.106405,	
2017-06-28 14:57:41,102 Epoch[23] Batch [570]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.106373,	
2017-06-28 14:57:45,842 Epoch[23] Batch [580]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.106524,	
2017-06-28 14:57:50,172 Epoch[23] Batch [590]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.106522,	
2017-06-28 14:57:54,521 Epoch[23] Batch [600]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.106487,	
2017-06-28 14:57:58,831 Epoch[23] Batch [610]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.106667,	
2017-06-28 14:58:03,122 Epoch[23] Batch [620]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.106816,	
2017-06-28 14:58:07,673 Epoch[23] Batch [630]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.106678,	
2017-06-28 14:58:12,439 Epoch[23] Batch [640]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.106651,	
2017-06-28 14:58:16,878 Epoch[23] Batch [650]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.106835,	
2017-06-28 14:58:21,587 Epoch[23] Batch [660]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.106838,	
2017-06-28 14:58:26,030 Epoch[23] Batch [670]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.106739,	
2017-06-28 14:58:30,690 Epoch[23] Batch [680]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.106722,	
2017-06-28 14:58:34,943 Epoch[23] Batch [690]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.106672,	
2017-06-28 14:58:39,208 Epoch[23] Batch [700]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.106632,	
2017-06-28 14:58:44,025 Epoch[23] Batch [710]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.106611,	
2017-06-28 14:58:48,410 Epoch[23] Batch [720]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106751,	
2017-06-28 14:58:53,057 Epoch[23] Batch [730]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.106807,	
2017-06-28 14:58:57,896 Epoch[23] Batch [740]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.106854,	
2017-06-28 14:59:02,434 Epoch[23] Batch [750]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.106932,	
2017-06-28 14:59:06,974 Epoch[23] Batch [760]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.106968,	
2017-06-28 14:59:11,341 Epoch[23] Batch [770]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.107033,	
2017-06-28 14:59:16,104 Epoch[23] Batch [780]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.106921,	
2017-06-28 14:59:21,012 Epoch[23] Batch [790]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.106924,	
2017-06-28 14:59:25,657 Epoch[23] Batch [800]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.106915,	
2017-06-28 14:59:30,268 Epoch[23] Batch [810]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.106938,	
2017-06-28 14:59:34,733 Epoch[23] Batch [820]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.107055,	
2017-06-28 14:59:38,867 Epoch[23] Batch [830]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.106954,	
2017-06-28 14:59:43,576 Epoch[23] Batch [840]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.107028,	
2017-06-28 14:59:48,302 Epoch[23] Batch [850]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.106907,	
2017-06-28 14:59:52,878 Epoch[23] Batch [860]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.106975,	
2017-06-28 14:59:57,474 Epoch[23] Batch [870]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107119,	
2017-06-28 15:00:02,108 Epoch[23] Batch [880]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107086,	
2017-06-28 15:00:06,880 Epoch[23] Batch [890]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.107241,	
2017-06-28 15:00:11,663 Epoch[23] Batch [900]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.107310,	
2017-06-28 15:00:16,393 Epoch[23] Batch [910]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.107271,	
2017-06-28 15:00:20,976 Epoch[23] Batch [920]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.107290,	
2017-06-28 15:00:25,643 Epoch[23] Batch [930]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.107229,	
2017-06-28 15:00:30,356 Epoch[23] Batch [940]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.107295,	
2017-06-28 15:00:34,885 Epoch[23] Batch [950]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.107438,	
2017-06-28 15:00:39,438 Epoch[23] Batch [960]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.107502,	
2017-06-28 15:00:44,168 Epoch[23] Batch [970]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.107577,	
2017-06-28 15:00:48,934 Epoch[23] Batch [980]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.107520,	
2017-06-28 15:00:53,324 Epoch[23] Batch [990]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.107643,	
2017-06-28 15:00:57,783 Epoch[23] Batch [1000]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107730,	
2017-06-28 15:01:02,529 Epoch[23] Batch [1010]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.107647,	
2017-06-28 15:01:07,300 Epoch[23] Batch [1020]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.107632,	
2017-06-28 15:01:11,460 Epoch[23] Batch [1030]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.107648,	
2017-06-28 15:01:15,469 Epoch[23] Batch [1040]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.107604,	
2017-06-28 15:01:20,230 Epoch[23] Batch [1050]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.107563,	
2017-06-28 15:01:24,923 Epoch[23] Batch [1060]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.107612,	
2017-06-28 15:01:29,896 Epoch[23] Batch [1070]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.107565,	
2017-06-28 15:01:34,362 Epoch[23] Batch [1080]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.107461,	
2017-06-28 15:01:38,696 Epoch[23] Batch [1090]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.107482,	
2017-06-28 15:01:42,909 Epoch[23] Batch [1100]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.107503,	
2017-06-28 15:01:47,080 Epoch[23] Batch [1110]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.107498,	
2017-06-28 15:01:51,714 Epoch[23] Batch [1120]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107510,	
2017-06-28 15:01:56,303 Epoch[23] Batch [1130]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.107610,	
2017-06-28 15:02:01,206 Epoch[23] Batch [1140]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.107696,	
2017-06-28 15:02:05,838 Epoch[23] Batch [1150]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.107721,	
2017-06-28 15:02:10,543 Epoch[23] Batch [1160]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.107832,	
2017-06-28 15:02:14,804 Epoch[23] Batch [1170]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.107744,	
2017-06-28 15:02:19,466 Epoch[23] Batch [1180]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.107743,	
2017-06-28 15:02:24,360 Epoch[23] Batch [1190]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.107754,	
2017-06-28 15:02:28,939 Epoch[23] Batch [1200]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.107901,	
2017-06-28 15:02:33,716 Epoch[23] Batch [1210]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.108106,	
2017-06-28 15:02:38,043 Epoch[23] Batch [1220]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.108109,	
2017-06-28 15:02:42,561 Epoch[23] Batch [1230]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.108193,	
2017-06-28 15:02:46,816 Epoch[23] Batch [1240]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.108091,	
2017-06-28 15:02:51,130 Epoch[23] Batch [1250]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.108041,	
2017-06-28 15:02:55,744 Epoch[23] Batch [1260]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108108,	
2017-06-28 15:03:00,468 Epoch[23] Batch [1270]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.108195,	
2017-06-28 15:03:04,870 Epoch[23] Batch [1280]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108324,	
2017-06-28 15:03:09,409 Epoch[23] Batch [1290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.108311,	
2017-06-28 15:03:13,792 Epoch[23] Batch [1300]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.108279,	
2017-06-28 15:03:18,280 Epoch[23] Batch [1310]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.108262,	
2017-06-28 15:03:22,436 Epoch[23] Batch [1320]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.108278,	
2017-06-28 15:03:26,839 Epoch[23] Batch [1330]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.108295,	
2017-06-28 15:03:30,988 Epoch[23] Batch [1340]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.108412,	
2017-06-28 15:03:35,415 Epoch[23] Batch [1350]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.108595,	
2017-06-28 15:03:40,067 Epoch[23] Batch [1360]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108682,	
2017-06-28 15:03:44,571 Epoch[23] Batch [1370]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108771,	
2017-06-28 15:03:49,259 Epoch[23] Batch [1380]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.108787,	
2017-06-28 15:03:54,401 Epoch[23] Batch [1390]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.108720,	
2017-06-28 15:03:58,870 Epoch[23] Batch [1400]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.108780,	
2017-06-28 15:04:03,459 Epoch[23] Batch [1410]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.108779,	
2017-06-28 15:04:08,286 Epoch[23] Batch [1420]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.108787,	
2017-06-28 15:04:12,941 Epoch[23] Batch [1430]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.108744,	
2017-06-28 15:04:17,980 Epoch[23] Batch [1440]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.108772,	
2017-06-28 15:04:22,527 Epoch[23] Batch [1450]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.108776,	
2017-06-28 15:04:27,034 Epoch[23] Batch [1460]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108850,	
2017-06-28 15:04:31,741 Epoch[23] Batch [1470]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.108822,	
2017-06-28 15:04:36,187 Epoch[23] Batch [1480]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.108822,	
2017-06-28 15:04:38,758 Epoch[23] Train-FCNLogLoss=0.108879
2017-06-28 15:04:38,758 Epoch[23] Time cost=675.300
2017-06-28 15:04:39,433 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0024.params"
2017-06-28 15:04:40,956 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0024.states"
2017-06-28 15:04:46,049 Epoch[24] Batch [10]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.109071,	
2017-06-28 15:04:50,756 Epoch[24] Batch [20]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.106244,	
2017-06-28 15:04:55,172 Epoch[24] Batch [30]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.105770,	
2017-06-28 15:04:59,738 Epoch[24] Batch [40]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.105562,	
2017-06-28 15:05:04,362 Epoch[24] Batch [50]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.107583,	
2017-06-28 15:05:09,102 Epoch[24] Batch [60]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.106920,	
2017-06-28 15:05:13,953 Epoch[24] Batch [70]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.106274,	
2017-06-28 15:05:18,398 Epoch[24] Batch [80]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.111001,	
2017-06-28 15:05:23,133 Epoch[24] Batch [90]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.111633,	
2017-06-28 15:05:27,658 Epoch[24] Batch [100]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112020,	
2017-06-28 15:05:31,958 Epoch[24] Batch [110]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.112270,	
2017-06-28 15:05:36,597 Epoch[24] Batch [120]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.113305,	
2017-06-28 15:05:40,961 Epoch[24] Batch [130]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.113902,	
2017-06-28 15:05:45,324 Epoch[24] Batch [140]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.112924,	
2017-06-28 15:05:49,725 Epoch[24] Batch [150]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.112726,	
2017-06-28 15:05:54,049 Epoch[24] Batch [160]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.113068,	
2017-06-28 15:05:58,410 Epoch[24] Batch [170]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.112694,	
2017-06-28 15:06:03,080 Epoch[24] Batch [180]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.111851,	
2017-06-28 15:06:07,724 Epoch[24] Batch [190]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.111913,	
2017-06-28 15:06:12,183 Epoch[24] Batch [200]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111811,	
2017-06-28 15:06:16,698 Epoch[24] Batch [210]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.112019,	
2017-06-28 15:06:21,473 Epoch[24] Batch [220]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.111387,	
2017-06-28 15:06:26,095 Epoch[24] Batch [230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.111312,	
2017-06-28 15:06:30,801 Epoch[24] Batch [240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.111283,	
2017-06-28 15:06:35,309 Epoch[24] Batch [250]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.110804,	
2017-06-28 15:06:40,111 Epoch[24] Batch [260]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.110220,	
2017-06-28 15:06:44,812 Epoch[24] Batch [270]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.110031,	
2017-06-28 15:06:49,424 Epoch[24] Batch [280]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.109659,	
2017-06-28 15:06:54,221 Epoch[24] Batch [290]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.109870,	
2017-06-28 15:06:58,842 Epoch[24] Batch [300]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.109294,	
2017-06-28 15:07:03,289 Epoch[24] Batch [310]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.108769,	
2017-06-28 15:07:07,831 Epoch[24] Batch [320]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.108657,	
2017-06-28 15:07:12,200 Epoch[24] Batch [330]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.108477,	
2017-06-28 15:07:16,957 Epoch[24] Batch [340]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108510,	
2017-06-28 15:07:21,490 Epoch[24] Batch [350]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108284,	
2017-06-28 15:07:25,959 Epoch[24] Batch [360]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.108411,	
2017-06-28 15:07:30,294 Epoch[24] Batch [370]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.108161,	
2017-06-28 15:07:34,598 Epoch[24] Batch [380]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.108142,	
2017-06-28 15:07:39,046 Epoch[24] Batch [390]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.108407,	
2017-06-28 15:07:43,964 Epoch[24] Batch [400]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.108349,	
2017-06-28 15:07:48,787 Epoch[24] Batch [410]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.108247,	
2017-06-28 15:07:53,271 Epoch[24] Batch [420]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.108237,	
2017-06-28 15:07:57,861 Epoch[24] Batch [430]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.108349,	
2017-06-28 15:08:02,360 Epoch[24] Batch [440]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.108100,	
2017-06-28 15:08:06,714 Epoch[24] Batch [450]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.107933,	
2017-06-28 15:08:11,115 Epoch[24] Batch [460]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108165,	
2017-06-28 15:08:15,480 Epoch[24] Batch [470]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.108378,	
2017-06-28 15:08:19,879 Epoch[24] Batch [480]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.108404,	
2017-06-28 15:08:24,399 Epoch[24] Batch [490]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.108569,	
2017-06-28 15:08:29,077 Epoch[24] Batch [500]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108363,	
2017-06-28 15:08:34,002 Epoch[24] Batch [510]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.108401,	
2017-06-28 15:08:38,265 Epoch[24] Batch [520]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.108302,	
2017-06-28 15:08:42,805 Epoch[24] Batch [530]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.108428,	
2017-06-28 15:08:47,355 Epoch[24] Batch [540]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.108424,	
2017-06-28 15:08:52,285 Epoch[24] Batch [550]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.108321,	
2017-06-28 15:08:56,780 Epoch[24] Batch [560]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.108236,	
2017-06-28 15:09:01,363 Epoch[24] Batch [570]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.108167,	
2017-06-28 15:09:05,685 Epoch[24] Batch [580]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.108532,	
2017-06-28 15:09:10,181 Epoch[24] Batch [590]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.108353,	
2017-06-28 15:09:14,704 Epoch[24] Batch [600]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108184,	
2017-06-28 15:09:19,368 Epoch[24] Batch [610]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.108465,	
2017-06-28 15:09:23,963 Epoch[24] Batch [620]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108345,	
2017-06-28 15:09:28,469 Epoch[24] Batch [630]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108371,	
2017-06-28 15:09:32,890 Epoch[24] Batch [640]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.108373,	
2017-06-28 15:09:37,478 Epoch[24] Batch [650]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.108303,	
2017-06-28 15:09:42,075 Epoch[24] Batch [660]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108587,	
2017-06-28 15:09:46,830 Epoch[24] Batch [670]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108493,	
2017-06-28 15:09:51,366 Epoch[24] Batch [680]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108569,	
2017-06-28 15:09:55,849 Epoch[24] Batch [690]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.108931,	
2017-06-28 15:10:00,279 Epoch[24] Batch [700]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.108967,	
2017-06-28 15:10:05,038 Epoch[24] Batch [710]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108928,	
2017-06-28 15:10:09,520 Epoch[24] Batch [720]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.108992,	
2017-06-28 15:10:13,997 Epoch[24] Batch [730]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.108946,	
2017-06-28 15:10:18,680 Epoch[24] Batch [740]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.108803,	
2017-06-28 15:10:23,266 Epoch[24] Batch [750]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.108709,	
2017-06-28 15:10:27,362 Epoch[24] Batch [760]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108642,	
2017-06-28 15:10:32,076 Epoch[24] Batch [770]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.108343,	
2017-06-28 15:10:36,836 Epoch[24] Batch [780]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.108421,	
2017-06-28 15:10:41,346 Epoch[24] Batch [790]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.108356,	
2017-06-28 15:10:45,879 Epoch[24] Batch [800]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108336,	
2017-06-28 15:10:50,442 Epoch[24] Batch [810]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108334,	
2017-06-28 15:10:54,627 Epoch[24] Batch [820]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.108251,	
2017-06-28 15:10:59,048 Epoch[24] Batch [830]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.108259,	
2017-06-28 15:11:03,884 Epoch[24] Batch [840]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.108271,	
2017-06-28 15:11:08,612 Epoch[24] Batch [850]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.108107,	
2017-06-28 15:11:13,318 Epoch[24] Batch [860]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.108171,	
2017-06-28 15:11:17,506 Epoch[24] Batch [870]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108091,	
2017-06-28 15:11:21,638 Epoch[24] Batch [880]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108106,	
2017-06-28 15:11:26,106 Epoch[24] Batch [890]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.108077,	
2017-06-28 15:11:30,624 Epoch[24] Batch [900]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.108081,	
2017-06-28 15:11:35,196 Epoch[24] Batch [910]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108184,	
2017-06-28 15:11:40,077 Epoch[24] Batch [920]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.108184,	
2017-06-28 15:11:44,795 Epoch[24] Batch [930]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.108168,	
2017-06-28 15:11:49,027 Epoch[24] Batch [940]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.108145,	
2017-06-28 15:11:53,846 Epoch[24] Batch [950]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.108070,	
2017-06-28 15:11:58,309 Epoch[24] Batch [960]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.107932,	
2017-06-28 15:12:02,958 Epoch[24] Batch [970]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.107782,	
2017-06-28 15:12:07,221 Epoch[24] Batch [980]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.107716,	
2017-06-28 15:12:11,745 Epoch[24] Batch [990]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107574,	
2017-06-28 15:12:15,848 Epoch[24] Batch [1000]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.107585,	
2017-06-28 15:12:20,384 Epoch[24] Batch [1010]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.107423,	
2017-06-28 15:12:24,774 Epoch[24] Batch [1020]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.107294,	
2017-06-28 15:12:28,756 Epoch[24] Batch [1030]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.107242,	
2017-06-28 15:12:32,968 Epoch[24] Batch [1040]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.107208,	
2017-06-28 15:12:37,488 Epoch[24] Batch [1050]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.107391,	
2017-06-28 15:12:41,888 Epoch[24] Batch [1060]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.107427,	
2017-06-28 15:12:46,584 Epoch[24] Batch [1070]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.107457,	
2017-06-28 15:12:51,136 Epoch[24] Batch [1080]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.107491,	
2017-06-28 15:12:55,562 Epoch[24] Batch [1090]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.107505,	
2017-06-28 15:12:59,958 Epoch[24] Batch [1100]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.107477,	
2017-06-28 15:13:03,991 Epoch[24] Batch [1110]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.107463,	
2017-06-28 15:13:08,678 Epoch[24] Batch [1120]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107502,	
2017-06-28 15:13:13,328 Epoch[24] Batch [1130]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.107453,	
2017-06-28 15:13:17,930 Epoch[24] Batch [1140]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107369,	
2017-06-28 15:13:22,741 Epoch[24] Batch [1150]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.107368,	
2017-06-28 15:13:27,382 Epoch[24] Batch [1160]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107407,	
2017-06-28 15:13:32,068 Epoch[24] Batch [1170]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.107382,	
2017-06-28 15:13:37,019 Epoch[24] Batch [1180]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.107369,	
2017-06-28 15:13:41,807 Epoch[24] Batch [1190]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.107445,	
2017-06-28 15:13:46,829 Epoch[24] Batch [1200]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.107347,	
2017-06-28 15:13:51,440 Epoch[24] Batch [1210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.107367,	
2017-06-28 15:13:56,294 Epoch[24] Batch [1220]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.107340,	
2017-06-28 15:14:01,019 Epoch[24] Batch [1230]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.107403,	
2017-06-28 15:14:05,486 Epoch[24] Batch [1240]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.107386,	
2017-06-28 15:14:09,787 Epoch[24] Batch [1250]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.107388,	
2017-06-28 15:14:14,129 Epoch[24] Batch [1260]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.107428,	
2017-06-28 15:14:18,597 Epoch[24] Batch [1270]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.107418,	
2017-06-28 15:14:23,285 Epoch[24] Batch [1280]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107392,	
2017-06-28 15:14:27,850 Epoch[24] Batch [1290]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.107346,	
2017-06-28 15:14:32,317 Epoch[24] Batch [1300]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.107348,	
2017-06-28 15:14:36,841 Epoch[24] Batch [1310]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107600,	
2017-06-28 15:14:41,262 Epoch[24] Batch [1320]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.107544,	
2017-06-28 15:14:45,755 Epoch[24] Batch [1330]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.107562,	
2017-06-28 15:14:50,250 Epoch[24] Batch [1340]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.107498,	
2017-06-28 15:14:54,756 Epoch[24] Batch [1350]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.107446,	
2017-06-28 15:14:59,511 Epoch[24] Batch [1360]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.107440,	
2017-06-28 15:15:03,973 Epoch[24] Batch [1370]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107436,	
2017-06-28 15:15:08,268 Epoch[24] Batch [1380]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.107400,	
2017-06-28 15:15:12,535 Epoch[24] Batch [1390]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.107446,	
2017-06-28 15:15:17,135 Epoch[24] Batch [1400]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107420,	
2017-06-28 15:15:21,426 Epoch[24] Batch [1410]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.107384,	
2017-06-28 15:15:25,996 Epoch[24] Batch [1420]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.107331,	
2017-06-28 15:15:30,252 Epoch[24] Batch [1430]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.107355,	
2017-06-28 15:15:34,937 Epoch[24] Batch [1440]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.107302,	
2017-06-28 15:15:39,796 Epoch[24] Batch [1450]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.107265,	
2017-06-28 15:15:44,449 Epoch[24] Batch [1460]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.107307,	
2017-06-28 15:15:48,883 Epoch[24] Batch [1470]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.107290,	
2017-06-28 15:15:53,555 Epoch[24] Batch [1480]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.107394,	
2017-06-28 15:15:56,356 Epoch[24] Train-FCNLogLoss=0.107377
2017-06-28 15:15:56,356 Epoch[24] Time cost=675.399
2017-06-28 15:15:57,121 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0025.params"
2017-06-28 15:15:58,832 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0025.states"
2017-06-28 15:16:03,961 Epoch[25] Batch [10]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.122130,	
2017-06-28 15:16:08,777 Epoch[25] Batch [20]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.122136,	
2017-06-28 15:16:13,388 Epoch[25] Batch [30]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.118757,	
2017-06-28 15:16:18,037 Epoch[25] Batch [40]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.117069,	
2017-06-28 15:16:22,459 Epoch[25] Batch [50]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.116205,	
2017-06-28 15:16:27,252 Epoch[25] Batch [60]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.115514,	
2017-06-28 15:16:31,807 Epoch[25] Batch [70]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.116523,	
2017-06-28 15:16:36,359 Epoch[25] Batch [80]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.116630,	
2017-06-28 15:16:40,723 Epoch[25] Batch [90]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.114227,	
2017-06-28 15:16:45,250 Epoch[25] Batch [100]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.113039,	
2017-06-28 15:16:49,734 Epoch[25] Batch [110]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.112803,	
2017-06-28 15:16:54,293 Epoch[25] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112543,	
2017-06-28 15:16:58,740 Epoch[25] Batch [130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.111753,	
2017-06-28 15:17:02,944 Epoch[25] Batch [140]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110876,	
2017-06-28 15:17:07,790 Epoch[25] Batch [150]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.110887,	
2017-06-28 15:17:12,274 Epoch[25] Batch [160]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.111198,	
2017-06-28 15:17:16,761 Epoch[25] Batch [170]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.112366,	
2017-06-28 15:17:21,447 Epoch[25] Batch [180]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.112977,	
2017-06-28 15:17:25,786 Epoch[25] Batch [190]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.112151,	
2017-06-28 15:17:30,257 Epoch[25] Batch [200]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.111376,	
2017-06-28 15:17:34,585 Epoch[25] Batch [210]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.110799,	
2017-06-28 15:17:39,210 Epoch[25] Batch [220]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.110581,	
2017-06-28 15:17:43,979 Epoch[25] Batch [230]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.110465,	
2017-06-28 15:17:48,257 Epoch[25] Batch [240]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.110091,	
2017-06-28 15:17:52,737 Epoch[25] Batch [250]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.110185,	
2017-06-28 15:17:57,190 Epoch[25] Batch [260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.110096,	
2017-06-28 15:18:01,694 Epoch[25] Batch [270]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.109592,	
2017-06-28 15:18:06,144 Epoch[25] Batch [280]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.109307,	
2017-06-28 15:18:10,332 Epoch[25] Batch [290]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.109787,	
2017-06-28 15:18:14,778 Epoch[25] Batch [300]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.109686,	
2017-06-28 15:18:19,457 Epoch[25] Batch [310]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.109508,	
2017-06-28 15:18:24,211 Epoch[25] Batch [320]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.109312,	
2017-06-28 15:18:28,685 Epoch[25] Batch [330]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.108917,	
2017-06-28 15:18:33,453 Epoch[25] Batch [340]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.109035,	
2017-06-28 15:18:37,811 Epoch[25] Batch [350]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.109039,	
2017-06-28 15:18:42,357 Epoch[25] Batch [360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.108987,	
2017-06-28 15:18:46,834 Epoch[25] Batch [370]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.108740,	
2017-06-28 15:18:51,196 Epoch[25] Batch [380]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.109096,	
2017-06-28 15:18:55,600 Epoch[25] Batch [390]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.109277,	
2017-06-28 15:19:00,103 Epoch[25] Batch [400]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.109193,	
2017-06-28 15:19:04,424 Epoch[25] Batch [410]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.108907,	
2017-06-28 15:19:09,027 Epoch[25] Batch [420]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108762,	
2017-06-28 15:19:13,451 Epoch[25] Batch [430]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.108634,	
2017-06-28 15:19:17,897 Epoch[25] Batch [440]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.108646,	
2017-06-28 15:19:22,574 Epoch[25] Batch [450]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108418,	
2017-06-28 15:19:27,106 Epoch[25] Batch [460]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.108620,	
2017-06-28 15:19:31,439 Epoch[25] Batch [470]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.108513,	
2017-06-28 15:19:35,947 Epoch[25] Batch [480]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108404,	
2017-06-28 15:19:40,135 Epoch[25] Batch [490]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108388,	
2017-06-28 15:19:44,464 Epoch[25] Batch [500]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.108605,	
2017-06-28 15:19:49,110 Epoch[25] Batch [510]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.108988,	
2017-06-28 15:19:53,700 Epoch[25] Batch [520]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.109458,	
2017-06-28 15:19:58,146 Epoch[25] Batch [530]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.109464,	
2017-06-28 15:20:02,360 Epoch[25] Batch [540]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109656,	
2017-06-28 15:20:06,710 Epoch[25] Batch [550]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.110098,	
2017-06-28 15:20:11,224 Epoch[25] Batch [560]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.109956,	
2017-06-28 15:20:15,663 Epoch[25] Batch [570]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.109772,	
2017-06-28 15:20:20,067 Epoch[25] Batch [580]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.109649,	
2017-06-28 15:20:25,024 Epoch[25] Batch [590]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.109511,	
2017-06-28 15:20:29,756 Epoch[25] Batch [600]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109428,	
2017-06-28 15:20:34,325 Epoch[25] Batch [610]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109383,	
2017-06-28 15:20:39,062 Epoch[25] Batch [620]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109416,	
2017-06-28 15:20:43,763 Epoch[25] Batch [630]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.109904,	
2017-06-28 15:20:48,785 Epoch[25] Batch [640]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.109991,	
2017-06-28 15:20:53,364 Epoch[25] Batch [650]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.110241,	
2017-06-28 15:20:57,790 Epoch[25] Batch [660]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.110153,	
2017-06-28 15:21:02,601 Epoch[25] Batch [670]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.110059,	
2017-06-28 15:21:07,159 Epoch[25] Batch [680]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.110074,	
2017-06-28 15:21:11,674 Epoch[25] Batch [690]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110364,	
2017-06-28 15:21:16,454 Epoch[25] Batch [700]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.110626,	
2017-06-28 15:21:21,441 Epoch[25] Batch [710]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.110629,	
2017-06-28 15:21:26,323 Epoch[25] Batch [720]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.110620,	
2017-06-28 15:21:30,672 Epoch[25] Batch [730]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.110686,	
2017-06-28 15:21:35,049 Epoch[25] Batch [740]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.110550,	
2017-06-28 15:21:39,562 Epoch[25] Batch [750]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110558,	
2017-06-28 15:21:44,610 Epoch[25] Batch [760]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.110324,	
2017-06-28 15:21:48,918 Epoch[25] Batch [770]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.110159,	
2017-06-28 15:21:53,586 Epoch[25] Batch [780]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.110012,	
2017-06-28 15:21:58,100 Epoch[25] Batch [790]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110038,	
2017-06-28 15:22:02,620 Epoch[25] Batch [800]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109884,	
2017-06-28 15:22:07,167 Epoch[25] Batch [810]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109810,	
2017-06-28 15:22:11,686 Epoch[25] Batch [820]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109783,	
2017-06-28 15:22:16,067 Epoch[25] Batch [830]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.109701,	
2017-06-28 15:22:20,610 Epoch[25] Batch [840]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109631,	
2017-06-28 15:22:25,031 Epoch[25] Batch [850]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.109628,	
2017-06-28 15:22:29,357 Epoch[25] Batch [860]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109707,	
2017-06-28 15:22:34,171 Epoch[25] Batch [870]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.109697,	
2017-06-28 15:22:38,818 Epoch[25] Batch [880]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.109791,	
2017-06-28 15:22:43,536 Epoch[25] Batch [890]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.109665,	
2017-06-28 15:22:48,369 Epoch[25] Batch [900]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.109522,	
2017-06-28 15:22:52,954 Epoch[25] Batch [910]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.109256,	
2017-06-28 15:22:57,450 Epoch[25] Batch [920]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.109154,	
2017-06-28 15:23:02,262 Epoch[25] Batch [930]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.109122,	
2017-06-28 15:23:06,818 Epoch[25] Batch [940]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109062,	
2017-06-28 15:23:11,537 Epoch[25] Batch [950]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.109089,	
2017-06-28 15:23:16,279 Epoch[25] Batch [960]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.108958,	
2017-06-28 15:23:21,017 Epoch[25] Batch [970]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.108908,	
2017-06-28 15:23:25,929 Epoch[25] Batch [980]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.108926,	
2017-06-28 15:23:30,351 Epoch[25] Batch [990]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.108911,	
2017-06-28 15:23:34,810 Epoch[25] Batch [1000]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108928,	
2017-06-28 15:23:39,181 Epoch[25] Batch [1010]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.108861,	
2017-06-28 15:23:43,716 Epoch[25] Batch [1020]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108867,	
2017-06-28 15:23:48,008 Epoch[25] Batch [1030]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.108799,	
2017-06-28 15:23:52,343 Epoch[25] Batch [1040]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.108740,	
2017-06-28 15:23:56,735 Epoch[25] Batch [1050]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.108659,	
2017-06-28 15:24:01,196 Epoch[25] Batch [1060]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108624,	
2017-06-28 15:24:05,723 Epoch[25] Batch [1070]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108679,	
2017-06-28 15:24:10,376 Epoch[25] Batch [1080]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108697,	
2017-06-28 15:24:14,896 Epoch[25] Batch [1090]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.108642,	
2017-06-28 15:24:19,745 Epoch[25] Batch [1100]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.108563,	
2017-06-28 15:24:24,518 Epoch[25] Batch [1110]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.108559,	
2017-06-28 15:24:29,050 Epoch[25] Batch [1120]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.108546,	
2017-06-28 15:24:33,435 Epoch[25] Batch [1130]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.108445,	
2017-06-28 15:24:37,980 Epoch[25] Batch [1140]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.108429,	
2017-06-28 15:24:42,296 Epoch[25] Batch [1150]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.108358,	
2017-06-28 15:24:47,063 Epoch[25] Batch [1160]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.108194,	
2017-06-28 15:24:51,734 Epoch[25] Batch [1170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.108182,	
2017-06-28 15:24:56,715 Epoch[25] Batch [1180]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.108165,	
2017-06-28 15:25:01,384 Epoch[25] Batch [1190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.108123,	
2017-06-28 15:25:06,033 Epoch[25] Batch [1200]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108155,	
2017-06-28 15:25:10,333 Epoch[25] Batch [1210]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.108184,	
2017-06-28 15:25:14,838 Epoch[25] Batch [1220]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108091,	
2017-06-28 15:25:19,066 Epoch[25] Batch [1230]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.108090,	
2017-06-28 15:25:23,580 Epoch[25] Batch [1240]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.108122,	
2017-06-28 15:25:27,862 Epoch[25] Batch [1250]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.108197,	
2017-06-28 15:25:32,458 Epoch[25] Batch [1260]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108218,	
2017-06-28 15:25:37,128 Epoch[25] Batch [1270]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.108249,	
2017-06-28 15:25:41,771 Epoch[25] Batch [1280]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.108250,	
2017-06-28 15:25:46,033 Epoch[25] Batch [1290]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.108176,	
2017-06-28 15:25:50,414 Epoch[25] Batch [1300]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.108222,	
2017-06-28 15:25:54,816 Epoch[25] Batch [1310]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108191,	
2017-06-28 15:25:59,283 Epoch[25] Batch [1320]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.108255,	
2017-06-28 15:26:03,945 Epoch[25] Batch [1330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.108273,	
2017-06-28 15:26:08,731 Epoch[25] Batch [1340]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.108300,	
2017-06-28 15:26:12,922 Epoch[25] Batch [1350]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.108319,	
2017-06-28 15:26:17,256 Epoch[25] Batch [1360]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.108248,	
2017-06-28 15:26:21,598 Epoch[25] Batch [1370]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108245,	
2017-06-28 15:26:26,144 Epoch[25] Batch [1380]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.108204,	
2017-06-28 15:26:30,999 Epoch[25] Batch [1390]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.108216,	
2017-06-28 15:26:35,681 Epoch[25] Batch [1400]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.108214,	
2017-06-28 15:26:39,736 Epoch[25] Batch [1410]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108125,	
2017-06-28 15:26:43,943 Epoch[25] Batch [1420]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.108145,	
2017-06-28 15:26:48,697 Epoch[25] Batch [1430]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108226,	
2017-06-28 15:26:53,317 Epoch[25] Batch [1440]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.108261,	
2017-06-28 15:26:57,563 Epoch[25] Batch [1450]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.108261,	
2017-06-28 15:27:02,005 Epoch[25] Batch [1460]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108284,	
2017-06-28 15:27:06,434 Epoch[25] Batch [1470]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.108158,	
2017-06-28 15:27:10,858 Epoch[25] Batch [1480]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.108138,	
2017-06-28 15:27:13,594 Epoch[25] Train-FCNLogLoss=0.108142
2017-06-28 15:27:13,594 Epoch[25] Time cost=674.761
2017-06-28 15:27:14,338 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0026.params"
2017-06-28 15:27:15,731 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0026.states"
2017-06-28 15:27:21,133 Epoch[26] Batch [10]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.110745,	
2017-06-28 15:27:25,210 Epoch[26] Batch [20]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.107829,	
2017-06-28 15:27:29,481 Epoch[26] Batch [30]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.107444,	
2017-06-28 15:27:34,041 Epoch[26] Batch [40]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108177,	
2017-06-28 15:27:38,801 Epoch[26] Batch [50]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.107762,	
2017-06-28 15:27:43,200 Epoch[26] Batch [60]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108088,	
2017-06-28 15:27:47,894 Epoch[26] Batch [70]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.109023,	
2017-06-28 15:27:52,297 Epoch[26] Batch [80]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.110421,	
2017-06-28 15:27:56,832 Epoch[26] Batch [90]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.110268,	
2017-06-28 15:28:01,043 Epoch[26] Batch [100]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.110934,	
2017-06-28 15:28:05,388 Epoch[26] Batch [110]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.110139,	
2017-06-28 15:28:09,382 Epoch[26] Batch [120]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.109016,	
2017-06-28 15:28:13,433 Epoch[26] Batch [130]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.107632,	
2017-06-28 15:28:17,666 Epoch[26] Batch [140]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.107411,	
2017-06-28 15:28:22,307 Epoch[26] Batch [150]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.106681,	
2017-06-28 15:28:26,812 Epoch[26] Batch [160]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.105895,	
2017-06-28 15:28:31,498 Epoch[26] Batch [170]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.105816,	
2017-06-28 15:28:36,407 Epoch[26] Batch [180]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.105458,	
2017-06-28 15:28:41,016 Epoch[26] Batch [190]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.105588,	
2017-06-28 15:28:45,192 Epoch[26] Batch [200]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.104994,	
2017-06-28 15:28:49,912 Epoch[26] Batch [210]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.104951,	
2017-06-28 15:28:54,508 Epoch[26] Batch [220]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.104716,	
2017-06-28 15:28:59,213 Epoch[26] Batch [230]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.104916,	
2017-06-28 15:29:03,604 Epoch[26] Batch [240]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.104988,	
2017-06-28 15:29:08,052 Epoch[26] Batch [250]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.105062,	
2017-06-28 15:29:12,695 Epoch[26] Batch [260]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.104962,	
2017-06-28 15:29:17,235 Epoch[26] Batch [270]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.104626,	
2017-06-28 15:29:21,768 Epoch[26] Batch [280]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.104374,	
2017-06-28 15:29:26,482 Epoch[26] Batch [290]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104732,	
2017-06-28 15:29:31,341 Epoch[26] Batch [300]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.104955,	
2017-06-28 15:29:35,926 Epoch[26] Batch [310]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.105171,	
2017-06-28 15:29:40,048 Epoch[26] Batch [320]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105193,	
2017-06-28 15:29:44,540 Epoch[26] Batch [330]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104860,	
2017-06-28 15:29:49,306 Epoch[26] Batch [340]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.104692,	
2017-06-28 15:29:53,804 Epoch[26] Batch [350]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.104789,	
2017-06-28 15:29:58,746 Epoch[26] Batch [360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.104805,	
2017-06-28 15:30:03,470 Epoch[26] Batch [370]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.105109,	
2017-06-28 15:30:07,861 Epoch[26] Batch [380]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.105459,	
2017-06-28 15:30:12,209 Epoch[26] Batch [390]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.105575,	
2017-06-28 15:30:16,339 Epoch[26] Batch [400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.105778,	
2017-06-28 15:30:20,680 Epoch[26] Batch [410]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.105337,	
2017-06-28 15:30:24,928 Epoch[26] Batch [420]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.105513,	
2017-06-28 15:30:29,480 Epoch[26] Batch [430]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.105438,	
2017-06-28 15:30:34,054 Epoch[26] Batch [440]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.105253,	
2017-06-28 15:30:38,670 Epoch[26] Batch [450]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.105346,	
2017-06-28 15:30:43,097 Epoch[26] Batch [460]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.105286,	
2017-06-28 15:30:47,876 Epoch[26] Batch [470]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.105123,	
2017-06-28 15:30:52,618 Epoch[26] Batch [480]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.105170,	
2017-06-28 15:30:57,344 Epoch[26] Batch [490]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.105329,	
2017-06-28 15:31:01,648 Epoch[26] Batch [500]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.105321,	
2017-06-28 15:31:06,206 Epoch[26] Batch [510]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105007,	
2017-06-28 15:31:10,456 Epoch[26] Batch [520]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.104925,	
2017-06-28 15:31:15,006 Epoch[26] Batch [530]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104879,	
2017-06-28 15:31:19,405 Epoch[26] Batch [540]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.104725,	
2017-06-28 15:31:23,929 Epoch[26] Batch [550]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104648,	
2017-06-28 15:31:28,532 Epoch[26] Batch [560]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.104531,	
2017-06-28 15:31:33,243 Epoch[26] Batch [570]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104620,	
2017-06-28 15:31:38,064 Epoch[26] Batch [580]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.104578,	
2017-06-28 15:31:42,677 Epoch[26] Batch [590]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.104634,	
2017-06-28 15:31:47,686 Epoch[26] Batch [600]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.104821,	
2017-06-28 15:31:52,408 Epoch[26] Batch [610]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.105067,	
2017-06-28 15:31:57,172 Epoch[26] Batch [620]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.105232,	
2017-06-28 15:32:01,932 Epoch[26] Batch [630]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.105446,	
2017-06-28 15:32:06,669 Epoch[26] Batch [640]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.105535,	
2017-06-28 15:32:11,078 Epoch[26] Batch [650]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.105820,	
2017-06-28 15:32:15,593 Epoch[26] Batch [660]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.105624,	
2017-06-28 15:32:20,156 Epoch[26] Batch [670]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.105752,	
2017-06-28 15:32:24,949 Epoch[26] Batch [680]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.105903,	
2017-06-28 15:32:29,450 Epoch[26] Batch [690]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.105917,	
2017-06-28 15:32:33,846 Epoch[26] Batch [700]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.105921,	
2017-06-28 15:32:38,472 Epoch[26] Batch [710]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.105962,	
2017-06-28 15:32:43,004 Epoch[26] Batch [720]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.105972,	
2017-06-28 15:32:47,757 Epoch[26] Batch [730]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.106090,	
2017-06-28 15:32:52,271 Epoch[26] Batch [740]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106197,	
2017-06-28 15:32:56,511 Epoch[26] Batch [750]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106355,	
2017-06-28 15:33:01,117 Epoch[26] Batch [760]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.106312,	
2017-06-28 15:33:05,589 Epoch[26] Batch [770]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.106358,	
2017-06-28 15:33:09,891 Epoch[26] Batch [780]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106381,	
2017-06-28 15:33:14,401 Epoch[26] Batch [790]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.106474,	
2017-06-28 15:33:19,001 Epoch[26] Batch [800]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.106300,	
2017-06-28 15:33:23,353 Epoch[26] Batch [810]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.106326,	
2017-06-28 15:33:28,399 Epoch[26] Batch [820]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.106481,	
2017-06-28 15:33:32,959 Epoch[26] Batch [830]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.106480,	
2017-06-28 15:33:37,559 Epoch[26] Batch [840]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.106531,	
2017-06-28 15:33:41,900 Epoch[26] Batch [850]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.106623,	
2017-06-28 15:33:46,540 Epoch[26] Batch [860]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.106643,	
2017-06-28 15:33:51,203 Epoch[26] Batch [870]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.106660,	
2017-06-28 15:33:55,373 Epoch[26] Batch [880]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106692,	
2017-06-28 15:33:59,762 Epoch[26] Batch [890]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.106774,	
2017-06-28 15:34:04,437 Epoch[26] Batch [900]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106590,	
2017-06-28 15:34:09,154 Epoch[26] Batch [910]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.106542,	
2017-06-28 15:34:13,653 Epoch[26] Batch [920]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.106609,	
2017-06-28 15:34:17,954 Epoch[26] Batch [930]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106665,	
2017-06-28 15:34:22,489 Epoch[26] Batch [940]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.106579,	
2017-06-28 15:34:27,156 Epoch[26] Batch [950]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.106651,	
2017-06-28 15:34:31,645 Epoch[26] Batch [960]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.106569,	
2017-06-28 15:34:35,887 Epoch[26] Batch [970]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106503,	
2017-06-28 15:34:40,210 Epoch[26] Batch [980]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.106451,	
2017-06-28 15:34:44,855 Epoch[26] Batch [990]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.106432,	
2017-06-28 15:34:49,333 Epoch[26] Batch [1000]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106520,	
2017-06-28 15:34:53,381 Epoch[26] Batch [1010]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106709,	
2017-06-28 15:34:57,863 Epoch[26] Batch [1020]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106679,	
2017-06-28 15:35:02,201 Epoch[26] Batch [1030]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.106885,	
2017-06-28 15:35:06,458 Epoch[26] Batch [1040]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.106827,	
2017-06-28 15:35:10,813 Epoch[26] Batch [1050]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.106744,	
2017-06-28 15:35:15,305 Epoch[26] Batch [1060]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.106654,	
2017-06-28 15:35:19,881 Epoch[26] Batch [1070]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.106667,	
2017-06-28 15:35:24,692 Epoch[26] Batch [1080]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.106669,	
2017-06-28 15:35:29,091 Epoch[26] Batch [1090]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.106636,	
2017-06-28 15:35:33,424 Epoch[26] Batch [1100]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.106587,	
2017-06-28 15:35:37,393 Epoch[26] Batch [1110]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.106511,	
2017-06-28 15:35:41,535 Epoch[26] Batch [1120]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.106518,	
2017-06-28 15:35:45,756 Epoch[26] Batch [1130]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.106355,	
2017-06-28 15:35:50,142 Epoch[26] Batch [1140]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106299,	
2017-06-28 15:35:54,483 Epoch[26] Batch [1150]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.106414,	
2017-06-28 15:35:58,737 Epoch[26] Batch [1160]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.106646,	
2017-06-28 15:36:03,017 Epoch[26] Batch [1170]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.106945,	
2017-06-28 15:36:07,812 Epoch[26] Batch [1180]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.107028,	
2017-06-28 15:36:12,488 Epoch[26] Batch [1190]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.107063,	
2017-06-28 15:36:17,450 Epoch[26] Batch [1200]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.107108,	
2017-06-28 15:36:21,978 Epoch[26] Batch [1210]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107098,	
2017-06-28 15:36:26,844 Epoch[26] Batch [1220]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.107235,	
2017-06-28 15:36:31,517 Epoch[26] Batch [1230]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.107228,	
2017-06-28 15:36:36,224 Epoch[26] Batch [1240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.107299,	
2017-06-28 15:36:40,644 Epoch[26] Batch [1250]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.107282,	
2017-06-28 15:36:45,075 Epoch[26] Batch [1260]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.107266,	
2017-06-28 15:36:49,875 Epoch[26] Batch [1270]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.107259,	
2017-06-28 15:36:54,235 Epoch[26] Batch [1280]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.107210,	
2017-06-28 15:36:58,975 Epoch[26] Batch [1290]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.107149,	
2017-06-28 15:37:03,434 Epoch[26] Batch [1300]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107095,	
2017-06-28 15:37:07,873 Epoch[26] Batch [1310]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.107093,	
2017-06-28 15:37:12,310 Epoch[26] Batch [1320]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.107085,	
2017-06-28 15:37:17,169 Epoch[26] Batch [1330]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.107053,	
2017-06-28 15:37:21,845 Epoch[26] Batch [1340]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.107031,	
2017-06-28 15:37:26,717 Epoch[26] Batch [1350]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.107041,	
2017-06-28 15:37:31,661 Epoch[26] Batch [1360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.107038,	
2017-06-28 15:37:36,281 Epoch[26] Batch [1370]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.106976,	
2017-06-28 15:37:40,761 Epoch[26] Batch [1380]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106980,	
2017-06-28 15:37:45,266 Epoch[26] Batch [1390]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.106926,	
2017-06-28 15:37:49,727 Epoch[26] Batch [1400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.106904,	
2017-06-28 15:37:54,102 Epoch[26] Batch [1410]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.106911,	
2017-06-28 15:37:58,332 Epoch[26] Batch [1420]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.106911,	
2017-06-28 15:38:02,591 Epoch[26] Batch [1430]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.106972,	
2017-06-28 15:38:07,147 Epoch[26] Batch [1440]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.107041,	
2017-06-28 15:38:11,617 Epoch[26] Batch [1450]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.107087,	
2017-06-28 15:38:16,059 Epoch[26] Batch [1460]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.107102,	
2017-06-28 15:38:20,427 Epoch[26] Batch [1470]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.107082,	
2017-06-28 15:38:25,318 Epoch[26] Batch [1480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.107002,	
2017-06-28 15:38:28,161 Epoch[26] Train-FCNLogLoss=0.106931
2017-06-28 15:38:28,161 Epoch[26] Time cost=672.429
2017-06-28 15:38:28,958 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0027.params"
2017-06-28 15:38:30,645 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0027.states"
2017-06-28 15:38:35,978 Epoch[27] Batch [10]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.112955,	
2017-06-28 15:38:40,525 Epoch[27] Batch [20]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.110342,	
2017-06-28 15:38:45,088 Epoch[27] Batch [30]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.107702,	
2017-06-28 15:38:49,331 Epoch[27] Batch [40]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.107178,	
2017-06-28 15:38:53,873 Epoch[27] Batch [50]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.106281,	
2017-06-28 15:38:58,463 Epoch[27] Batch [60]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.106780,	
2017-06-28 15:39:02,600 Epoch[27] Batch [70]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.107447,	
2017-06-28 15:39:06,933 Epoch[27] Batch [80]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.106439,	
2017-06-28 15:39:11,364 Epoch[27] Batch [90]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.107209,	
2017-06-28 15:39:15,765 Epoch[27] Batch [100]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.106549,	
2017-06-28 15:39:19,910 Epoch[27] Batch [110]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105527,	
2017-06-28 15:39:24,338 Epoch[27] Batch [120]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.104839,	
2017-06-28 15:39:28,966 Epoch[27] Batch [130]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.107172,	
2017-06-28 15:39:33,492 Epoch[27] Batch [140]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107456,	
2017-06-28 15:39:37,866 Epoch[27] Batch [150]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.106913,	
2017-06-28 15:39:42,401 Epoch[27] Batch [160]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.107246,	
2017-06-28 15:39:46,964 Epoch[27] Batch [170]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.106974,	
2017-06-28 15:39:51,600 Epoch[27] Batch [180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107088,	
2017-06-28 15:39:55,855 Epoch[27] Batch [190]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.107062,	
2017-06-28 15:40:00,263 Epoch[27] Batch [200]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107326,	
2017-06-28 15:40:05,109 Epoch[27] Batch [210]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.107552,	
2017-06-28 15:40:09,497 Epoch[27] Batch [220]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.107114,	
2017-06-28 15:40:14,117 Epoch[27] Batch [230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.107462,	
2017-06-28 15:40:18,823 Epoch[27] Batch [240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.107214,	
2017-06-28 15:40:23,589 Epoch[27] Batch [250]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.107090,	
2017-06-28 15:40:28,165 Epoch[27] Batch [260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.107022,	
2017-06-28 15:40:32,664 Epoch[27] Batch [270]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.106801,	
2017-06-28 15:40:37,499 Epoch[27] Batch [280]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.106878,	
2017-06-28 15:40:42,175 Epoch[27] Batch [290]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.106909,	
2017-06-28 15:40:46,769 Epoch[27] Batch [300]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.106995,	
2017-06-28 15:40:51,286 Epoch[27] Batch [310]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106809,	
2017-06-28 15:40:55,801 Epoch[27] Batch [320]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.107023,	
2017-06-28 15:41:00,334 Epoch[27] Batch [330]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.107168,	
2017-06-28 15:41:04,795 Epoch[27] Batch [340]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.106765,	
2017-06-28 15:41:09,482 Epoch[27] Batch [350]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107080,	
2017-06-28 15:41:14,020 Epoch[27] Batch [360]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.106891,	
2017-06-28 15:41:18,260 Epoch[27] Batch [370]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106573,	
2017-06-28 15:41:22,617 Epoch[27] Batch [380]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.106279,	
2017-06-28 15:41:27,172 Epoch[27] Batch [390]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105898,	
2017-06-28 15:41:31,730 Epoch[27] Batch [400]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105804,	
2017-06-28 15:41:36,405 Epoch[27] Batch [410]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.105980,	
2017-06-28 15:41:40,794 Epoch[27] Batch [420]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.105739,	
2017-06-28 15:41:45,381 Epoch[27] Batch [430]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.105624,	
2017-06-28 15:41:50,477 Epoch[27] Batch [440]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.105355,	
2017-06-28 15:41:55,282 Epoch[27] Batch [450]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.105132,	
2017-06-28 15:42:00,082 Epoch[27] Batch [460]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.105084,	
2017-06-28 15:42:04,583 Epoch[27] Batch [470]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.105058,	
2017-06-28 15:42:09,067 Epoch[27] Batch [480]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.104936,	
2017-06-28 15:42:13,702 Epoch[27] Batch [490]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.104865,	
2017-06-28 15:42:18,115 Epoch[27] Batch [500]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.105275,	
2017-06-28 15:42:22,421 Epoch[27] Batch [510]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.105366,	
2017-06-28 15:42:26,621 Epoch[27] Batch [520]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.105425,	
2017-06-28 15:42:30,810 Epoch[27] Batch [530]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.105761,	
2017-06-28 15:42:35,513 Epoch[27] Batch [540]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.105973,	
2017-06-28 15:42:39,785 Epoch[27] Batch [550]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.105963,	
2017-06-28 15:42:44,314 Epoch[27] Batch [560]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.105792,	
2017-06-28 15:42:48,816 Epoch[27] Batch [570]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.105860,	
2017-06-28 15:42:53,466 Epoch[27] Batch [580]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.105833,	
2017-06-28 15:42:57,739 Epoch[27] Batch [590]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.105903,	
2017-06-28 15:43:02,289 Epoch[27] Batch [600]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.106004,	
2017-06-28 15:43:06,854 Epoch[27] Batch [610]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.106172,	
2017-06-28 15:43:11,378 Epoch[27] Batch [620]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.106130,	
2017-06-28 15:43:16,101 Epoch[27] Batch [630]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.106053,	
2017-06-28 15:43:20,789 Epoch[27] Batch [640]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.106072,	
2017-06-28 15:43:25,187 Epoch[27] Batch [650]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.106153,	
2017-06-28 15:43:29,860 Epoch[27] Batch [660]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106041,	
2017-06-28 15:43:34,518 Epoch[27] Batch [670]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.105999,	
2017-06-28 15:43:39,349 Epoch[27] Batch [680]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.106008,	
2017-06-28 15:43:43,702 Epoch[27] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.106081,	
2017-06-28 15:43:48,268 Epoch[27] Batch [700]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.105949,	
2017-06-28 15:43:52,672 Epoch[27] Batch [710]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.106151,	
2017-06-28 15:43:57,229 Epoch[27] Batch [720]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.106179,	
2017-06-28 15:44:01,907 Epoch[27] Batch [730]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.106105,	
2017-06-28 15:44:06,313 Epoch[27] Batch [740]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.106175,	
2017-06-28 15:44:10,971 Epoch[27] Batch [750]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.106124,	
2017-06-28 15:44:15,694 Epoch[27] Batch [760]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.105998,	
2017-06-28 15:44:20,127 Epoch[27] Batch [770]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.105976,	
2017-06-28 15:44:24,767 Epoch[27] Batch [780]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.105967,	
2017-06-28 15:44:29,413 Epoch[27] Batch [790]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.106002,	
2017-06-28 15:44:33,786 Epoch[27] Batch [800]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.105993,	
2017-06-28 15:44:38,063 Epoch[27] Batch [810]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.106029,	
2017-06-28 15:44:42,250 Epoch[27] Batch [820]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.105984,	
2017-06-28 15:44:46,496 Epoch[27] Batch [830]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.105940,	
2017-06-28 15:44:51,316 Epoch[27] Batch [840]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.105866,	
2017-06-28 15:44:55,897 Epoch[27] Batch [850]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.105883,	
2017-06-28 15:45:00,520 Epoch[27] Batch [860]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.105705,	
2017-06-28 15:45:04,981 Epoch[27] Batch [870]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.105626,	
2017-06-28 15:45:09,972 Epoch[27] Batch [880]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.105550,	
2017-06-28 15:45:14,196 Epoch[27] Batch [890]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105499,	
2017-06-28 15:45:18,480 Epoch[27] Batch [900]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.105396,	
2017-06-28 15:45:22,828 Epoch[27] Batch [910]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.105429,	
2017-06-28 15:45:26,838 Epoch[27] Batch [920]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.105443,	
2017-06-28 15:45:31,151 Epoch[27] Batch [930]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.105427,	
2017-06-28 15:45:35,945 Epoch[27] Batch [940]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.105359,	
2017-06-28 15:45:40,359 Epoch[27] Batch [950]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.105422,	
2017-06-28 15:45:45,348 Epoch[27] Batch [960]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.105532,	
2017-06-28 15:45:50,166 Epoch[27] Batch [970]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.105585,	
2017-06-28 15:45:55,003 Epoch[27] Batch [980]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.105505,	
2017-06-28 15:45:59,492 Epoch[27] Batch [990]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105548,	
2017-06-28 15:46:03,933 Epoch[27] Batch [1000]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.105719,	
2017-06-28 15:46:08,490 Epoch[27] Batch [1010]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105686,	
2017-06-28 15:46:12,964 Epoch[27] Batch [1020]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.105588,	
2017-06-28 15:46:17,563 Epoch[27] Batch [1030]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.105527,	
2017-06-28 15:46:22,319 Epoch[27] Batch [1040]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.105522,	
2017-06-28 15:46:26,838 Epoch[27] Batch [1050]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.105608,	
2017-06-28 15:46:31,595 Epoch[27] Batch [1060]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.105638,	
2017-06-28 15:46:36,324 Epoch[27] Batch [1070]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.105654,	
2017-06-28 15:46:41,154 Epoch[27] Batch [1080]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.105589,	
2017-06-28 15:46:45,796 Epoch[27] Batch [1090]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.105605,	
2017-06-28 15:46:50,604 Epoch[27] Batch [1100]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.105632,	
2017-06-28 15:46:55,299 Epoch[27] Batch [1110]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.105590,	
2017-06-28 15:46:59,603 Epoch[27] Batch [1120]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.105622,	
2017-06-28 15:47:03,943 Epoch[27] Batch [1130]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.105696,	
2017-06-28 15:47:08,325 Epoch[27] Batch [1140]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.105712,	
2017-06-28 15:47:12,629 Epoch[27] Batch [1150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.105712,	
2017-06-28 15:47:16,868 Epoch[27] Batch [1160]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.105818,	
2017-06-28 15:47:21,247 Epoch[27] Batch [1170]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.105788,	
2017-06-28 15:47:25,619 Epoch[27] Batch [1180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.105749,	
2017-06-28 15:47:30,093 Epoch[27] Batch [1190]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.105771,	
2017-06-28 15:47:34,619 Epoch[27] Batch [1200]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.105718,	
2017-06-28 15:47:39,194 Epoch[27] Batch [1210]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.105659,	
2017-06-28 15:47:43,934 Epoch[27] Batch [1220]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.105652,	
2017-06-28 15:47:48,416 Epoch[27] Batch [1230]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.105641,	
2017-06-28 15:47:52,851 Epoch[27] Batch [1240]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.105730,	
2017-06-28 15:47:57,535 Epoch[27] Batch [1250]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.105708,	
2017-06-28 15:48:01,790 Epoch[27] Batch [1260]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.105700,	
2017-06-28 15:48:06,048 Epoch[27] Batch [1270]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.105647,	
2017-06-28 15:48:10,224 Epoch[27] Batch [1280]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.105630,	
2017-06-28 15:48:14,882 Epoch[27] Batch [1290]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.105576,	
2017-06-28 15:48:19,436 Epoch[27] Batch [1300]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.105490,	
2017-06-28 15:48:23,850 Epoch[27] Batch [1310]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.105477,	
2017-06-28 15:48:28,323 Epoch[27] Batch [1320]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.105498,	
2017-06-28 15:48:33,168 Epoch[27] Batch [1330]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.105507,	
2017-06-28 15:48:37,633 Epoch[27] Batch [1340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.105564,	
2017-06-28 15:48:41,898 Epoch[27] Batch [1350]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.105591,	
2017-06-28 15:48:46,644 Epoch[27] Batch [1360]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.105626,	
2017-06-28 15:48:51,117 Epoch[27] Batch [1370]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.105630,	
2017-06-28 15:48:55,573 Epoch[27] Batch [1380]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.105618,	
2017-06-28 15:49:00,026 Epoch[27] Batch [1390]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.105543,	
2017-06-28 15:49:04,355 Epoch[27] Batch [1400]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.105657,	
2017-06-28 15:49:09,068 Epoch[27] Batch [1410]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.105607,	
2017-06-28 15:49:13,284 Epoch[27] Batch [1420]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.105608,	
2017-06-28 15:49:17,946 Epoch[27] Batch [1430]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105681,	
2017-06-28 15:49:22,574 Epoch[27] Batch [1440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.105665,	
2017-06-28 15:49:27,373 Epoch[27] Batch [1450]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.105614,	
2017-06-28 15:49:31,805 Epoch[27] Batch [1460]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.105531,	
2017-06-28 15:49:36,433 Epoch[27] Batch [1470]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.105512,	
2017-06-28 15:49:40,588 Epoch[27] Batch [1480]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105476,	
2017-06-28 15:49:43,605 Epoch[27] Train-FCNLogLoss=0.105529
2017-06-28 15:49:43,606 Epoch[27] Time cost=672.960
2017-06-28 15:49:44,309 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0028.params"
2017-06-28 15:49:46,003 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0028.states"
2017-06-28 15:49:51,337 Epoch[28] Batch [10]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.105905,	
2017-06-28 15:49:55,912 Epoch[28] Batch [20]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.103040,	
2017-06-28 15:50:00,213 Epoch[28] Batch [30]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.101831,	
2017-06-28 15:50:04,586 Epoch[28] Batch [40]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.101171,	
2017-06-28 15:50:08,829 Epoch[28] Batch [50]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100723,	
2017-06-28 15:50:13,445 Epoch[28] Batch [60]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.101422,	
2017-06-28 15:50:18,099 Epoch[28] Batch [70]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.103002,	
2017-06-28 15:50:22,477 Epoch[28] Batch [80]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.103240,	
2017-06-28 15:50:26,696 Epoch[28] Batch [90]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.102791,	
2017-06-28 15:50:30,968 Epoch[28] Batch [100]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.102919,	
2017-06-28 15:50:35,206 Epoch[28] Batch [110]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.103909,	
2017-06-28 15:50:39,599 Epoch[28] Batch [120]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.104221,	
2017-06-28 15:50:44,009 Epoch[28] Batch [130]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104672,	
2017-06-28 15:50:48,362 Epoch[28] Batch [140]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.106109,	
2017-06-28 15:50:52,766 Epoch[28] Batch [150]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.107458,	
2017-06-28 15:50:57,176 Epoch[28] Batch [160]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107892,	
2017-06-28 15:51:01,427 Epoch[28] Batch [170]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.107523,	
2017-06-28 15:51:05,938 Epoch[28] Batch [180]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.107814,	
2017-06-28 15:51:10,557 Epoch[28] Batch [190]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109129,	
2017-06-28 15:51:14,755 Epoch[28] Batch [200]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.109494,	
2017-06-28 15:51:19,044 Epoch[28] Batch [210]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.109392,	
2017-06-28 15:51:23,318 Epoch[28] Batch [220]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109077,	
2017-06-28 15:51:27,808 Epoch[28] Batch [230]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.109158,	
2017-06-28 15:51:32,163 Epoch[28] Batch [240]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.109071,	
2017-06-28 15:51:36,755 Epoch[28] Batch [250]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.108786,	
2017-06-28 15:51:40,966 Epoch[28] Batch [260]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.108243,	
2017-06-28 15:51:45,426 Epoch[28] Batch [270]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108524,	
2017-06-28 15:51:49,773 Epoch[28] Batch [280]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.108215,	
2017-06-28 15:51:54,098 Epoch[28] Batch [290]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.108321,	
2017-06-28 15:51:58,374 Epoch[28] Batch [300]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.107779,	
2017-06-28 15:52:02,700 Epoch[28] Batch [310]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.107642,	
2017-06-28 15:52:06,840 Epoch[28] Batch [320]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.107480,	
2017-06-28 15:52:11,261 Epoch[28] Batch [330]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.107201,	
2017-06-28 15:52:15,605 Epoch[28] Batch [340]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.107116,	
2017-06-28 15:52:19,862 Epoch[28] Batch [350]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.106855,	
2017-06-28 15:52:24,457 Epoch[28] Batch [360]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.106657,	
2017-06-28 15:52:28,870 Epoch[28] Batch [370]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.106474,	
2017-06-28 15:52:33,353 Epoch[28] Batch [380]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106254,	
2017-06-28 15:52:37,748 Epoch[28] Batch [390]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.106137,	
2017-06-28 15:52:42,106 Epoch[28] Batch [400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.105797,	
2017-06-28 15:52:46,560 Epoch[28] Batch [410]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.105963,	
2017-06-28 15:52:51,091 Epoch[28] Batch [420]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.105726,	
2017-06-28 15:52:55,580 Epoch[28] Batch [430]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105844,	
2017-06-28 15:53:00,028 Epoch[28] Batch [440]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.105947,	
2017-06-28 15:53:04,358 Epoch[28] Batch [450]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.105733,	
2017-06-28 15:53:08,856 Epoch[28] Batch [460]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.105542,	
2017-06-28 15:53:13,234 Epoch[28] Batch [470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.105706,	
2017-06-28 15:53:17,582 Epoch[28] Batch [480]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.105648,	
2017-06-28 15:53:21,969 Epoch[28] Batch [490]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.105540,	
2017-06-28 15:53:26,384 Epoch[28] Batch [500]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.105584,	
2017-06-28 15:53:30,628 Epoch[28] Batch [510]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.105671,	
2017-06-28 15:53:35,156 Epoch[28] Batch [520]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.105562,	
2017-06-28 15:53:39,263 Epoch[28] Batch [530]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105379,	
2017-06-28 15:53:43,584 Epoch[28] Batch [540]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.105330,	
2017-06-28 15:53:47,914 Epoch[28] Batch [550]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.105073,	
2017-06-28 15:53:52,372 Epoch[28] Batch [560]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.105026,	
2017-06-28 15:53:56,753 Epoch[28] Batch [570]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.104881,	
2017-06-28 15:54:01,176 Epoch[28] Batch [580]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.104629,	
2017-06-28 15:54:05,703 Epoch[28] Batch [590]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104865,	
2017-06-28 15:54:10,000 Epoch[28] Batch [600]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.104687,	
2017-06-28 15:54:14,423 Epoch[28] Batch [610]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.104839,	
2017-06-28 15:54:18,811 Epoch[28] Batch [620]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104821,	
2017-06-28 15:54:23,247 Epoch[28] Batch [630]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104718,	
2017-06-28 15:54:27,536 Epoch[28] Batch [640]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.104829,	
2017-06-28 15:54:31,965 Epoch[28] Batch [650]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.105227,	
2017-06-28 15:54:36,325 Epoch[28] Batch [660]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.105358,	
2017-06-28 15:54:40,811 Epoch[28] Batch [670]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.105435,	
2017-06-28 15:54:45,126 Epoch[28] Batch [680]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.105348,	
2017-06-28 15:54:49,518 Epoch[28] Batch [690]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.105392,	
2017-06-28 15:54:53,908 Epoch[28] Batch [700]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.105484,	
2017-06-28 15:54:58,397 Epoch[28] Batch [710]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105493,	
2017-06-28 15:55:02,712 Epoch[28] Batch [720]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.105604,	
2017-06-28 15:55:07,036 Epoch[28] Batch [730]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.105524,	
2017-06-28 15:55:11,388 Epoch[28] Batch [740]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.105521,	
2017-06-28 15:55:15,664 Epoch[28] Batch [750]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.105476,	
2017-06-28 15:55:20,038 Epoch[28] Batch [760]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.105607,	
2017-06-28 15:55:24,405 Epoch[28] Batch [770]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.105670,	
2017-06-28 15:55:28,815 Epoch[28] Batch [780]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.105842,	
2017-06-28 15:55:33,109 Epoch[28] Batch [790]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.105746,	
2017-06-28 15:55:37,587 Epoch[28] Batch [800]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.105524,	
2017-06-28 15:55:41,860 Epoch[28] Batch [810]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.105470,	
2017-06-28 15:55:46,294 Epoch[28] Batch [820]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.105402,	
2017-06-28 15:55:50,621 Epoch[28] Batch [830]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.105385,	
2017-06-28 15:55:54,986 Epoch[28] Batch [840]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.105252,	
2017-06-28 15:55:59,193 Epoch[28] Batch [850]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.105176,	
2017-06-28 15:56:03,568 Epoch[28] Batch [860]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.105272,	
2017-06-28 15:56:07,986 Epoch[28] Batch [870]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.105366,	
2017-06-28 15:56:12,357 Epoch[28] Batch [880]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.105362,	
2017-06-28 15:56:16,709 Epoch[28] Batch [890]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.105271,	
2017-06-28 15:56:21,073 Epoch[28] Batch [900]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.105247,	
2017-06-28 15:56:25,507 Epoch[28] Batch [910]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.105260,	
2017-06-28 15:56:29,795 Epoch[28] Batch [920]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.105281,	
2017-06-28 15:56:34,186 Epoch[28] Batch [930]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.105224,	
2017-06-28 15:56:38,254 Epoch[28] Batch [940]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105124,	
2017-06-28 15:56:42,692 Epoch[28] Batch [950]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.105125,	
2017-06-28 15:56:47,198 Epoch[28] Batch [960]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.105128,	
2017-06-28 15:56:51,489 Epoch[28] Batch [970]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.104965,	
2017-06-28 15:56:55,871 Epoch[28] Batch [980]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.104828,	
2017-06-28 15:57:00,283 Epoch[28] Batch [990]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104899,	
2017-06-28 15:57:04,866 Epoch[28] Batch [1000]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.104879,	
2017-06-28 15:57:09,425 Epoch[28] Batch [1010]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.104817,	
2017-06-28 15:57:13,779 Epoch[28] Batch [1020]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.104882,	
2017-06-28 15:57:18,102 Epoch[28] Batch [1030]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.104839,	
2017-06-28 15:57:22,487 Epoch[28] Batch [1040]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104789,	
2017-06-28 15:57:26,767 Epoch[28] Batch [1050]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.104719,	
2017-06-28 15:57:31,115 Epoch[28] Batch [1060]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.104764,	
2017-06-28 15:57:35,460 Epoch[28] Batch [1070]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.104785,	
2017-06-28 15:57:39,977 Epoch[28] Batch [1080]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104826,	
2017-06-28 15:57:44,389 Epoch[28] Batch [1090]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104766,	
2017-06-28 15:57:48,738 Epoch[28] Batch [1100]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.104839,	
2017-06-28 15:57:53,065 Epoch[28] Batch [1110]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.104824,	
2017-06-28 15:57:57,596 Epoch[28] Batch [1120]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.104838,	
2017-06-28 15:58:01,973 Epoch[28] Batch [1130]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.104815,	
2017-06-28 15:58:06,098 Epoch[28] Batch [1140]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.104799,	
2017-06-28 15:58:10,341 Epoch[28] Batch [1150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.104813,	
2017-06-28 15:58:14,494 Epoch[28] Batch [1160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104705,	
2017-06-28 15:58:18,785 Epoch[28] Batch [1170]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.104629,	
2017-06-28 15:58:23,150 Epoch[28] Batch [1180]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.104651,	
2017-06-28 15:58:27,700 Epoch[28] Batch [1190]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104609,	
2017-06-28 15:58:31,863 Epoch[28] Batch [1200]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.104665,	
2017-06-28 15:58:36,386 Epoch[28] Batch [1210]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104683,	
2017-06-28 15:58:40,757 Epoch[28] Batch [1220]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.104787,	
2017-06-28 15:58:45,065 Epoch[28] Batch [1230]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.104840,	
2017-06-28 15:58:49,507 Epoch[28] Batch [1240]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.104956,	
2017-06-28 15:58:53,922 Epoch[28] Batch [1250]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.104948,	
2017-06-28 15:58:58,094 Epoch[28] Batch [1260]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.104843,	
2017-06-28 15:59:02,498 Epoch[28] Batch [1270]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.104812,	
2017-06-28 15:59:06,879 Epoch[28] Batch [1280]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.104741,	
2017-06-28 15:59:11,056 Epoch[28] Batch [1290]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.104811,	
2017-06-28 15:59:15,409 Epoch[28] Batch [1300]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.104851,	
2017-06-28 15:59:19,780 Epoch[28] Batch [1310]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.104819,	
2017-06-28 15:59:24,303 Epoch[28] Batch [1320]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104820,	
2017-06-28 15:59:28,556 Epoch[28] Batch [1330]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.104797,	
2017-06-28 15:59:32,749 Epoch[28] Batch [1340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.104743,	
2017-06-28 15:59:37,183 Epoch[28] Batch [1350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104681,	
2017-06-28 15:59:41,580 Epoch[28] Batch [1360]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.104636,	
2017-06-28 15:59:45,875 Epoch[28] Batch [1370]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.104582,	
2017-06-28 15:59:50,303 Epoch[28] Batch [1380]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.104562,	
2017-06-28 15:59:54,448 Epoch[28] Batch [1390]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104427,	
2017-06-28 15:59:58,870 Epoch[28] Batch [1400]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.104357,	
2017-06-28 16:00:03,126 Epoch[28] Batch [1410]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.104252,	
2017-06-28 16:00:07,485 Epoch[28] Batch [1420]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104342,	
2017-06-28 16:00:11,655 Epoch[28] Batch [1430]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.104351,	
2017-06-28 16:00:15,983 Epoch[28] Batch [1440]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.104369,	
2017-06-28 16:00:20,217 Epoch[28] Batch [1450]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.104278,	
2017-06-28 16:00:24,619 Epoch[28] Batch [1460]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.104299,	
2017-06-28 16:00:29,012 Epoch[28] Batch [1470]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.104276,	
2017-06-28 16:00:33,317 Epoch[28] Batch [1480]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.104201,	
2017-06-28 16:00:35,870 Epoch[28] Train-FCNLogLoss=0.104115
2017-06-28 16:00:35,870 Epoch[28] Time cost=649.867
2017-06-28 16:00:36,503 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0029.params"
2017-06-28 16:00:38,020 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0029.states"
2017-06-28 16:00:42,948 Epoch[29] Batch [10]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.093784,	
2017-06-28 16:00:47,190 Epoch[29] Batch [20]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100440,	
2017-06-28 16:00:51,273 Epoch[29] Batch [30]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108948,	
2017-06-28 16:00:55,554 Epoch[29] Batch [40]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.112813,	
2017-06-28 16:01:00,019 Epoch[29] Batch [50]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.111651,	
2017-06-28 16:01:04,349 Epoch[29] Batch [60]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.110431,	
2017-06-28 16:01:08,769 Epoch[29] Batch [70]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.110299,	
2017-06-28 16:01:13,117 Epoch[29] Batch [80]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.109037,	
2017-06-28 16:01:17,622 Epoch[29] Batch [90]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108688,	
2017-06-28 16:01:21,961 Epoch[29] Batch [100]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.109579,	
2017-06-28 16:01:26,169 Epoch[29] Batch [110]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.108838,	
2017-06-28 16:01:30,581 Epoch[29] Batch [120]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107528,	
2017-06-28 16:01:35,063 Epoch[29] Batch [130]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106910,	
2017-06-28 16:01:39,501 Epoch[29] Batch [140]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.105995,	
2017-06-28 16:01:43,959 Epoch[29] Batch [150]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.105388,	
2017-06-28 16:01:48,266 Epoch[29] Batch [160]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.104952,	
2017-06-28 16:01:52,558 Epoch[29] Batch [170]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.105128,	
2017-06-28 16:01:56,884 Epoch[29] Batch [180]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.105039,	
2017-06-28 16:02:01,295 Epoch[29] Batch [190]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104168,	
2017-06-28 16:02:05,379 Epoch[29] Batch [200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104395,	
2017-06-28 16:02:09,735 Epoch[29] Batch [210]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104166,	
2017-06-28 16:02:14,007 Epoch[29] Batch [220]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.103797,	
2017-06-28 16:02:18,450 Epoch[29] Batch [230]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.103345,	
2017-06-28 16:02:22,779 Epoch[29] Batch [240]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.103328,	
2017-06-28 16:02:27,111 Epoch[29] Batch [250]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.102937,	
2017-06-28 16:02:31,519 Epoch[29] Batch [260]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.102546,	
2017-06-28 16:02:35,775 Epoch[29] Batch [270]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.102489,	
2017-06-28 16:02:39,951 Epoch[29] Batch [280]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.102473,	
2017-06-28 16:02:44,350 Epoch[29] Batch [290]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.102601,	
2017-06-28 16:02:48,685 Epoch[29] Batch [300]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.102620,	
2017-06-28 16:02:53,160 Epoch[29] Batch [310]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102429,	
2017-06-28 16:02:57,622 Epoch[29] Batch [320]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.102361,	
2017-06-28 16:03:01,776 Epoch[29] Batch [330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.102697,	
2017-06-28 16:03:06,172 Epoch[29] Batch [340]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.102726,	
2017-06-28 16:03:10,553 Epoch[29] Batch [350]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.102810,	
2017-06-28 16:03:14,858 Epoch[29] Batch [360]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.103000,	
2017-06-28 16:03:19,036 Epoch[29] Batch [370]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.102655,	
2017-06-28 16:03:23,332 Epoch[29] Batch [380]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.102939,	
2017-06-28 16:03:27,561 Epoch[29] Batch [390]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.103196,	
2017-06-28 16:03:32,031 Epoch[29] Batch [400]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.102933,	
2017-06-28 16:03:36,460 Epoch[29] Batch [410]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.102804,	
2017-06-28 16:03:41,029 Epoch[29] Batch [420]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.102639,	
2017-06-28 16:03:45,429 Epoch[29] Batch [430]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.102899,	
2017-06-28 16:03:50,108 Epoch[29] Batch [440]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.102970,	
2017-06-28 16:03:54,573 Epoch[29] Batch [450]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.102643,	
2017-06-28 16:03:59,611 Epoch[29] Batch [460]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.102661,	
2017-06-28 16:04:04,688 Epoch[29] Batch [470]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.102655,	
2017-06-28 16:04:10,049 Epoch[29] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.102430,	
2017-06-28 16:04:15,558 Epoch[29] Batch [490]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.102466,	
2017-06-28 16:04:21,202 Epoch[29] Batch [500]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.102445,	
2017-06-28 16:04:27,252 Epoch[29] Batch [510]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102543,	
2017-06-28 16:04:33,032 Epoch[29] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102458,	
2017-06-28 16:04:39,360 Epoch[29] Batch [530]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.102630,	
2017-06-28 16:04:45,225 Epoch[29] Batch [540]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.102644,	
2017-06-28 16:04:51,735 Epoch[29] Batch [550]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.102485,	
2017-06-28 16:04:57,567 Epoch[29] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102383,	
2017-06-28 16:05:02,876 Epoch[29] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.102343,	
2017-06-28 16:05:08,862 Epoch[29] Batch [580]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.102414,	
2017-06-28 16:05:15,610 Epoch[29] Batch [590]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.102250,	
2017-06-28 16:05:22,150 Epoch[29] Batch [600]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.102238,	
2017-06-28 16:05:27,969 Epoch[29] Batch [610]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.102246,	
2017-06-28 16:05:34,430 Epoch[29] Batch [620]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.102379,	
2017-06-28 16:05:40,639 Epoch[29] Batch [630]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.102381,	
2017-06-28 16:05:46,906 Epoch[29] Batch [640]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.102272,	
2017-06-28 16:05:53,099 Epoch[29] Batch [650]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.102430,	
2017-06-28 16:05:59,407 Epoch[29] Batch [660]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.102605,	
2017-06-28 16:06:05,516 Epoch[29] Batch [670]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102846,	
2017-06-28 16:06:11,656 Epoch[29] Batch [680]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102970,	
2017-06-28 16:06:17,975 Epoch[29] Batch [690]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.103043,	
2017-06-28 16:06:24,366 Epoch[29] Batch [700]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103173,	
2017-06-28 16:06:30,634 Epoch[29] Batch [710]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.103034,	
2017-06-28 16:06:36,910 Epoch[29] Batch [720]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.103067,	
2017-06-28 16:06:42,855 Epoch[29] Batch [730]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.103112,	
2017-06-28 16:06:48,898 Epoch[29] Batch [740]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103106,	
2017-06-28 16:06:54,858 Epoch[29] Batch [750]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103180,	
2017-06-28 16:07:00,761 Epoch[29] Batch [760]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.103095,	
2017-06-28 16:07:07,172 Epoch[29] Batch [770]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.102907,	
2017-06-28 16:07:13,595 Epoch[29] Batch [780]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.103067,	
2017-06-28 16:07:19,871 Epoch[29] Batch [790]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.103050,	
2017-06-28 16:07:25,647 Epoch[29] Batch [800]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103027,	
2017-06-28 16:07:31,836 Epoch[29] Batch [810]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.102984,	
2017-06-28 16:07:37,909 Epoch[29] Batch [820]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103048,	
2017-06-28 16:07:43,503 Epoch[29] Batch [830]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102986,	
2017-06-28 16:07:49,610 Epoch[29] Batch [840]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103526,	
2017-06-28 16:07:55,760 Epoch[29] Batch [850]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.104518,	
2017-06-28 16:08:01,774 Epoch[29] Batch [860]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.104832,	
2017-06-28 16:08:07,372 Epoch[29] Batch [870]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.105252,	
2017-06-28 16:08:13,512 Epoch[29] Batch [880]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.105506,	
2017-06-28 16:08:19,300 Epoch[29] Batch [890]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105578,	
2017-06-28 16:08:25,393 Epoch[29] Batch [900]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.105626,	
2017-06-28 16:08:31,693 Epoch[29] Batch [910]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.105646,	
2017-06-28 16:08:38,045 Epoch[29] Batch [920]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.105706,	
2017-06-28 16:08:44,371 Epoch[29] Batch [930]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.105739,	
2017-06-28 16:08:50,799 Epoch[29] Batch [940]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106045,	
2017-06-28 16:08:56,961 Epoch[29] Batch [950]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.106430,	
2017-06-28 16:09:02,856 Epoch[29] Batch [960]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.107035,	
2017-06-28 16:09:09,222 Epoch[29] Batch [970]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.107366,	
2017-06-28 16:09:15,513 Epoch[29] Batch [980]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.107608,	
2017-06-28 16:09:22,145 Epoch[29] Batch [990]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.107777,	
2017-06-28 16:09:28,190 Epoch[29] Batch [1000]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.107720,	
2017-06-28 16:09:34,516 Epoch[29] Batch [1010]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.107758,	
2017-06-28 16:09:40,475 Epoch[29] Batch [1020]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.107863,	
2017-06-28 16:09:46,760 Epoch[29] Batch [1030]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.108196,	
2017-06-28 16:09:53,281 Epoch[29] Batch [1040]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.108458,	
2017-06-28 16:10:00,190 Epoch[29] Batch [1050]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.108808,	
2017-06-28 16:10:06,361 Epoch[29] Batch [1060]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.109366,	
2017-06-28 16:10:12,651 Epoch[29] Batch [1070]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.109452,	
2017-06-28 16:10:18,715 Epoch[29] Batch [1080]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.109523,	
2017-06-28 16:10:24,643 Epoch[29] Batch [1090]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.109672,	
2017-06-28 16:10:30,856 Epoch[29] Batch [1100]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.109849,	
2017-06-28 16:10:37,036 Epoch[29] Batch [1110]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.110060,	
2017-06-28 16:10:42,927 Epoch[29] Batch [1120]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.110231,	
2017-06-28 16:10:48,872 Epoch[29] Batch [1130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.110951,	
2017-06-28 16:10:55,290 Epoch[29] Batch [1140]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.111447,	
2017-06-28 16:11:01,355 Epoch[29] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.111605,	
2017-06-28 16:11:07,501 Epoch[29] Batch [1160]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.111873,	
2017-06-28 16:11:13,713 Epoch[29] Batch [1170]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.111875,	
2017-06-28 16:11:19,938 Epoch[29] Batch [1180]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.111956,	
2017-06-28 16:11:26,586 Epoch[29] Batch [1190]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.112171,	
2017-06-28 16:11:33,029 Epoch[29] Batch [1200]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.112302,	
2017-06-28 16:11:39,653 Epoch[29] Batch [1210]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.112286,	
2017-06-28 16:11:45,433 Epoch[29] Batch [1220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112151,	
2017-06-28 16:11:51,498 Epoch[29] Batch [1230]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.112237,	
2017-06-28 16:11:57,828 Epoch[29] Batch [1240]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.112257,	
2017-06-28 16:12:03,699 Epoch[29] Batch [1250]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.112247,	
2017-06-28 16:12:10,196 Epoch[29] Batch [1260]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.112140,	
2017-06-28 16:12:16,466 Epoch[29] Batch [1270]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.112103,	
2017-06-28 16:12:22,387 Epoch[29] Batch [1280]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.112163,	
2017-06-28 16:12:28,053 Epoch[29] Batch [1290]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.112111,	
2017-06-28 16:12:33,715 Epoch[29] Batch [1300]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.111988,	
2017-06-28 16:12:39,842 Epoch[29] Batch [1310]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111868,	
2017-06-28 16:12:45,823 Epoch[29] Batch [1320]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.111783,	
2017-06-28 16:12:52,293 Epoch[29] Batch [1330]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.111769,	
2017-06-28 16:12:58,215 Epoch[29] Batch [1340]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.111770,	
2017-06-28 16:13:04,314 Epoch[29] Batch [1350]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.111743,	
2017-06-28 16:13:10,385 Epoch[29] Batch [1360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.111701,	
2017-06-28 16:13:16,511 Epoch[29] Batch [1370]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111674,	
2017-06-28 16:13:22,695 Epoch[29] Batch [1380]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.111686,	
2017-06-28 16:13:29,304 Epoch[29] Batch [1390]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.111604,	
2017-06-28 16:13:35,117 Epoch[29] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.111511,	
2017-06-28 16:13:41,411 Epoch[29] Batch [1410]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.111402,	
2017-06-28 16:13:48,013 Epoch[29] Batch [1420]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.111350,	
2017-06-28 16:13:54,068 Epoch[29] Batch [1430]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.111241,	
2017-06-28 16:14:00,137 Epoch[29] Batch [1440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.111149,	
2017-06-28 16:14:06,584 Epoch[29] Batch [1450]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.111077,	
2017-06-28 16:14:13,123 Epoch[29] Batch [1460]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.110935,	
2017-06-28 16:14:19,082 Epoch[29] Batch [1470]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.110862,	
2017-06-28 16:14:24,809 Epoch[29] Batch [1480]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.110841,	
2017-06-28 16:14:28,112 Epoch[29] Train-FCNLogLoss=0.110812
2017-06-28 16:14:28,113 Epoch[29] Time cost=830.092
2017-06-28 16:14:28,758 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0030.params"
2017-06-28 16:14:30,365 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0030.states"
2017-06-28 16:14:36,817 Epoch[30] Batch [10]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.098442,	
2017-06-28 16:14:43,318 Epoch[30] Batch [20]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.101817,	
2017-06-28 16:14:49,384 Epoch[30] Batch [30]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103125,	
2017-06-28 16:14:55,319 Epoch[30] Batch [40]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101799,	
2017-06-28 16:15:01,215 Epoch[30] Batch [50]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.102837,	
2017-06-28 16:15:06,687 Epoch[30] Batch [60]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.101700,	
2017-06-28 16:15:11,918 Epoch[30] Batch [70]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.101802,	
2017-06-28 16:15:16,968 Epoch[30] Batch [80]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.101946,	
2017-06-28 16:15:22,291 Epoch[30] Batch [90]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.102283,	
2017-06-28 16:15:27,649 Epoch[30] Batch [100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.102351,	
2017-06-28 16:15:33,798 Epoch[30] Batch [110]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.103357,	
2017-06-28 16:15:40,098 Epoch[30] Batch [120]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.104633,	
2017-06-28 16:15:46,625 Epoch[30] Batch [130]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.105399,	
2017-06-28 16:15:52,880 Epoch[30] Batch [140]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.105798,	
2017-06-28 16:15:59,314 Epoch[30] Batch [150]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.105318,	
2017-06-28 16:16:06,258 Epoch[30] Batch [160]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.105114,	
2017-06-28 16:16:12,663 Epoch[30] Batch [170]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.105192,	
2017-06-28 16:16:18,827 Epoch[30] Batch [180]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.105012,	
2017-06-28 16:16:24,748 Epoch[30] Batch [190]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105710,	
2017-06-28 16:16:30,818 Epoch[30] Batch [200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.105573,	
2017-06-28 16:16:37,166 Epoch[30] Batch [210]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.105802,	
2017-06-28 16:16:42,913 Epoch[30] Batch [220]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.105809,	
2017-06-28 16:16:49,084 Epoch[30] Batch [230]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.105882,	
2017-06-28 16:16:55,391 Epoch[30] Batch [240]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.105741,	
2017-06-28 16:17:01,622 Epoch[30] Batch [250]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.105365,	
2017-06-28 16:17:07,415 Epoch[30] Batch [260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104573,	
2017-06-28 16:17:14,018 Epoch[30] Batch [270]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.104989,	
2017-06-28 16:17:19,980 Epoch[30] Batch [280]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105041,	
2017-06-28 16:17:25,420 Epoch[30] Batch [290]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.105352,	
2017-06-28 16:17:31,758 Epoch[30] Batch [300]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.105199,	
2017-06-28 16:17:37,695 Epoch[30] Batch [310]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105147,	
2017-06-28 16:17:43,013 Epoch[30] Batch [320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105346,	
2017-06-28 16:17:48,828 Epoch[30] Batch [330]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.105375,	
2017-06-28 16:17:55,025 Epoch[30] Batch [340]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.105435,	
2017-06-28 16:18:00,986 Epoch[30] Batch [350]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105402,	
2017-06-28 16:18:07,213 Epoch[30] Batch [360]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.104763,	
2017-06-28 16:18:12,906 Epoch[30] Batch [370]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.104560,	
2017-06-28 16:18:18,966 Epoch[30] Batch [380]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104581,	
2017-06-28 16:18:25,289 Epoch[30] Batch [390]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.104441,	
2017-06-28 16:18:31,271 Epoch[30] Batch [400]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104362,	
2017-06-28 16:18:37,165 Epoch[30] Batch [410]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.104546,	
2017-06-28 16:18:43,309 Epoch[30] Batch [420]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.104233,	
2017-06-28 16:18:49,280 Epoch[30] Batch [430]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.104133,	
2017-06-28 16:18:55,150 Epoch[30] Batch [440]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104021,	
2017-06-28 16:19:00,574 Epoch[30] Batch [450]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.103983,	
2017-06-28 16:19:07,046 Epoch[30] Batch [460]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.103777,	
2017-06-28 16:19:13,751 Epoch[30] Batch [470]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.103818,	
2017-06-28 16:19:19,704 Epoch[30] Batch [480]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.103749,	
2017-06-28 16:19:25,538 Epoch[30] Batch [490]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103779,	
2017-06-28 16:19:32,295 Epoch[30] Batch [500]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.104033,	
2017-06-28 16:19:39,393 Epoch[30] Batch [510]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.104332,	
2017-06-28 16:19:45,620 Epoch[30] Batch [520]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.104074,	
2017-06-28 16:19:52,346 Epoch[30] Batch [530]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.104203,	
2017-06-28 16:19:58,615 Epoch[30] Batch [540]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.104130,	
2017-06-28 16:20:05,035 Epoch[30] Batch [550]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.104053,	
2017-06-28 16:20:11,481 Epoch[30] Batch [560]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.104098,	
2017-06-28 16:20:18,190 Epoch[30] Batch [570]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.104472,	
2017-06-28 16:20:24,451 Epoch[30] Batch [580]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.104345,	
2017-06-28 16:20:31,145 Epoch[30] Batch [590]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.104235,	
2017-06-28 16:20:37,376 Epoch[30] Batch [600]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.104447,	
2017-06-28 16:20:44,654 Epoch[30] Batch [610]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.104385,	
2017-06-28 16:20:51,899 Epoch[30] Batch [620]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.104256,	
2017-06-28 16:20:58,376 Epoch[30] Batch [630]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.104129,	
2017-06-28 16:21:04,893 Epoch[30] Batch [640]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.104083,	
2017-06-28 16:21:11,658 Epoch[30] Batch [650]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.104032,	
2017-06-28 16:21:18,775 Epoch[30] Batch [660]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.103933,	
2017-06-28 16:21:25,401 Epoch[30] Batch [670]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.103977,	
2017-06-28 16:21:31,751 Epoch[30] Batch [680]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.104120,	
2017-06-28 16:21:38,927 Epoch[30] Batch [690]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.104098,	
2017-06-28 16:21:45,055 Epoch[30] Batch [700]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.104066,	
2017-06-28 16:21:51,686 Epoch[30] Batch [710]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.103982,	
2017-06-28 16:21:57,826 Epoch[30] Batch [720]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103937,	
2017-06-28 16:22:04,918 Epoch[30] Batch [730]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.104004,	
2017-06-28 16:22:10,619 Epoch[30] Batch [740]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.103975,	
2017-06-28 16:22:16,405 Epoch[30] Batch [750]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.103962,	
2017-06-28 16:22:22,057 Epoch[30] Batch [760]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.103874,	
2017-06-28 16:22:27,873 Epoch[30] Batch [770]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.104042,	
2017-06-28 16:22:33,234 Epoch[30] Batch [780]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104066,	
2017-06-28 16:22:38,497 Epoch[30] Batch [790]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.103981,	
2017-06-28 16:22:44,410 Epoch[30] Batch [800]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103920,	
2017-06-28 16:22:49,795 Epoch[30] Batch [810]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.103835,	
2017-06-28 16:22:55,809 Epoch[30] Batch [820]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.103798,	
2017-06-28 16:23:01,539 Epoch[30] Batch [830]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.103833,	
2017-06-28 16:23:07,437 Epoch[30] Batch [840]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.103896,	
2017-06-28 16:23:13,467 Epoch[30] Batch [850]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103836,	
2017-06-28 16:23:19,057 Epoch[30] Batch [860]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.103775,	
2017-06-28 16:23:24,706 Epoch[30] Batch [870]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.103596,	
2017-06-28 16:23:30,777 Epoch[30] Batch [880]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103511,	
2017-06-28 16:23:36,704 Epoch[30] Batch [890]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103480,	
2017-06-28 16:23:42,909 Epoch[30] Batch [900]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.103658,	
2017-06-28 16:23:48,542 Epoch[30] Batch [910]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.103659,	
2017-06-28 16:23:54,313 Epoch[30] Batch [920]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103756,	
2017-06-28 16:23:59,836 Epoch[30] Batch [930]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.103720,	
2017-06-28 16:24:05,775 Epoch[30] Batch [940]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103697,	
2017-06-28 16:24:11,984 Epoch[30] Batch [950]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.103698,	
2017-06-28 16:24:18,397 Epoch[30] Batch [960]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.103731,	
2017-06-28 16:24:24,364 Epoch[30] Batch [970]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103689,	
2017-06-28 16:24:29,925 Epoch[30] Batch [980]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.103681,	
2017-06-28 16:24:36,316 Epoch[30] Batch [990]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103679,	
2017-06-28 16:24:41,662 Epoch[30] Batch [1000]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103685,	
2017-06-28 16:24:47,533 Epoch[30] Batch [1010]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.103772,	
2017-06-28 16:24:53,589 Epoch[30] Batch [1020]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.103816,	
2017-06-28 16:24:59,785 Epoch[30] Batch [1030]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.103772,	
2017-06-28 16:25:05,536 Epoch[30] Batch [1040]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.103823,	
2017-06-28 16:25:11,163 Epoch[30] Batch [1050]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.103889,	
2017-06-28 16:25:17,352 Epoch[30] Batch [1060]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.103855,	
2017-06-28 16:25:23,542 Epoch[30] Batch [1070]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.103859,	
2017-06-28 16:25:29,052 Epoch[30] Batch [1080]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.103885,	
2017-06-28 16:25:34,939 Epoch[30] Batch [1090]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.103829,	
2017-06-28 16:25:40,674 Epoch[30] Batch [1100]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.103930,	
2017-06-28 16:25:47,018 Epoch[30] Batch [1110]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.103897,	
2017-06-28 16:25:52,517 Epoch[30] Batch [1120]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.103895,	
2017-06-28 16:25:58,597 Epoch[30] Batch [1130]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103894,	
2017-06-28 16:26:04,185 Epoch[30] Batch [1140]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.103788,	
2017-06-28 16:26:09,206 Epoch[30] Batch [1150]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.103724,	
2017-06-28 16:26:15,002 Epoch[30] Batch [1160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103709,	
2017-06-28 16:26:20,171 Epoch[30] Batch [1170]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.103630,	
2017-06-28 16:26:25,612 Epoch[30] Batch [1180]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.103620,	
2017-06-28 16:26:31,077 Epoch[30] Batch [1190]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.103707,	
2017-06-28 16:26:37,467 Epoch[30] Batch [1200]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103635,	
2017-06-28 16:26:43,137 Epoch[30] Batch [1210]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.103609,	
2017-06-28 16:26:48,830 Epoch[30] Batch [1220]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.103644,	
2017-06-28 16:26:54,532 Epoch[30] Batch [1230]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.103668,	
2017-06-28 16:26:59,798 Epoch[30] Batch [1240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.103673,	
2017-06-28 16:27:05,484 Epoch[30] Batch [1250]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.103704,	
2017-06-28 16:27:10,592 Epoch[30] Batch [1260]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.103781,	
2017-06-28 16:27:15,959 Epoch[30] Batch [1270]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.103727,	
2017-06-28 16:27:21,065 Epoch[30] Batch [1280]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.103717,	
2017-06-28 16:27:26,116 Epoch[30] Batch [1290]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.103778,	
2017-06-28 16:27:31,696 Epoch[30] Batch [1300]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.103696,	
2017-06-28 16:27:37,065 Epoch[30] Batch [1310]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.103733,	
2017-06-28 16:27:42,636 Epoch[30] Batch [1320]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.103658,	
2017-06-28 16:27:48,032 Epoch[30] Batch [1330]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.103660,	
2017-06-28 16:27:53,602 Epoch[30] Batch [1340]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.103659,	
2017-06-28 16:27:58,772 Epoch[30] Batch [1350]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.103615,	
2017-06-28 16:28:03,722 Epoch[30] Batch [1360]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.103688,	
2017-06-28 16:28:08,888 Epoch[30] Batch [1370]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.103674,	
2017-06-28 16:28:13,807 Epoch[30] Batch [1380]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.103792,	
2017-06-28 16:28:19,566 Epoch[30] Batch [1390]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103916,	
2017-06-28 16:28:24,850 Epoch[30] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.103854,	
2017-06-28 16:28:29,982 Epoch[30] Batch [1410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.103853,	
2017-06-28 16:28:36,325 Epoch[30] Batch [1420]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.103800,	
2017-06-28 16:28:42,201 Epoch[30] Batch [1430]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.103781,	
2017-06-28 16:28:48,589 Epoch[30] Batch [1440]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103787,	
2017-06-28 16:28:54,529 Epoch[30] Batch [1450]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.103816,	
2017-06-28 16:29:00,149 Epoch[30] Batch [1460]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.103846,	
2017-06-28 16:29:05,642 Epoch[30] Batch [1470]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.103865,	
2017-06-28 16:29:11,390 Epoch[30] Batch [1480]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.103878,	
2017-06-28 16:29:14,733 Epoch[30] Train-FCNLogLoss=0.103847
2017-06-28 16:29:14,734 Epoch[30] Time cost=884.368
2017-06-28 16:29:15,352 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0031.params"
2017-06-28 16:29:16,854 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0031.states"
2017-06-28 16:29:22,776 Epoch[31] Batch [10]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.097912,	
2017-06-28 16:29:28,016 Epoch[31] Batch [20]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094517,	
2017-06-28 16:29:33,775 Epoch[31] Batch [30]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.094179,	
2017-06-28 16:29:39,659 Epoch[31] Batch [40]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.097344,	
2017-06-28 16:29:45,252 Epoch[31] Batch [50]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.097177,	
2017-06-28 16:29:50,988 Epoch[31] Batch [60]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.096674,	
2017-06-28 16:29:56,575 Epoch[31] Batch [70]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.097159,	
2017-06-28 16:30:01,951 Epoch[31] Batch [80]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098554,	
2017-06-28 16:30:07,026 Epoch[31] Batch [90]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.099478,	
2017-06-28 16:30:12,258 Epoch[31] Batch [100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.099363,	
2017-06-28 16:30:17,729 Epoch[31] Batch [110]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.100534,	
2017-06-28 16:30:23,390 Epoch[31] Batch [120]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.100668,	
2017-06-28 16:30:29,688 Epoch[31] Batch [130]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100702,	
2017-06-28 16:30:35,445 Epoch[31] Batch [140]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.100787,	
2017-06-28 16:30:41,165 Epoch[31] Batch [150]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.100786,	
2017-06-28 16:30:46,645 Epoch[31] Batch [160]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.100492,	
2017-06-28 16:30:53,042 Epoch[31] Batch [170]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.101308,	
2017-06-28 16:30:58,987 Epoch[31] Batch [180]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.101076,	
2017-06-28 16:31:05,299 Epoch[31] Batch [190]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.101215,	
2017-06-28 16:31:11,069 Epoch[31] Batch [200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100868,	
2017-06-28 16:31:17,114 Epoch[31] Batch [210]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100771,	
2017-06-28 16:31:22,871 Epoch[31] Batch [220]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101091,	
2017-06-28 16:31:28,599 Epoch[31] Batch [230]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.101084,	
2017-06-28 16:31:34,562 Epoch[31] Batch [240]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.100908,	
2017-06-28 16:31:40,719 Epoch[31] Batch [250]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.100768,	
2017-06-28 16:31:46,036 Epoch[31] Batch [260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100870,	
2017-06-28 16:31:51,420 Epoch[31] Batch [270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.100921,	
2017-06-28 16:31:57,648 Epoch[31] Batch [280]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.100942,	
2017-06-28 16:32:03,358 Epoch[31] Batch [290]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.101189,	
2017-06-28 16:32:08,950 Epoch[31] Batch [300]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.101248,	
2017-06-28 16:32:14,211 Epoch[31] Batch [310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.101322,	
2017-06-28 16:32:20,208 Epoch[31] Batch [320]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.101042,	
2017-06-28 16:32:25,667 Epoch[31] Batch [330]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.100740,	
2017-06-28 16:32:31,271 Epoch[31] Batch [340]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.100559,	
2017-06-28 16:32:36,936 Epoch[31] Batch [350]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.100948,	
2017-06-28 16:32:42,635 Epoch[31] Batch [360]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.100698,	
2017-06-28 16:32:48,286 Epoch[31] Batch [370]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.100710,	
2017-06-28 16:32:53,750 Epoch[31] Batch [380]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.100901,	
2017-06-28 16:32:59,917 Epoch[31] Batch [390]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101245,	
2017-06-28 16:33:05,498 Epoch[31] Batch [400]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.101050,	
2017-06-28 16:33:11,238 Epoch[31] Batch [410]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.100967,	
2017-06-28 16:33:16,551 Epoch[31] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100843,	
2017-06-28 16:33:22,672 Epoch[31] Batch [430]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100937,	
2017-06-28 16:33:28,619 Epoch[31] Batch [440]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.100863,	
2017-06-28 16:33:34,982 Epoch[31] Batch [450]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.100884,	
2017-06-28 16:33:40,918 Epoch[31] Batch [460]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.100872,	
2017-06-28 16:33:46,050 Epoch[31] Batch [470]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.100825,	
2017-06-28 16:33:51,170 Epoch[31] Batch [480]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.100841,	
2017-06-28 16:33:56,300 Epoch[31] Batch [490]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.100618,	
2017-06-28 16:34:02,592 Epoch[31] Batch [500]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.100781,	
2017-06-28 16:34:08,296 Epoch[31] Batch [510]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100507,	
2017-06-28 16:34:14,724 Epoch[31] Batch [520]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.100323,	
2017-06-28 16:34:20,381 Epoch[31] Batch [530]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.100478,	
2017-06-28 16:34:26,386 Epoch[31] Batch [540]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100515,	
2017-06-28 16:34:32,423 Epoch[31] Batch [550]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100604,	
2017-06-28 16:34:38,468 Epoch[31] Batch [560]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100585,	
2017-06-28 16:34:43,907 Epoch[31] Batch [570]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.100606,	
2017-06-28 16:34:50,746 Epoch[31] Batch [580]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.100419,	
2017-06-28 16:34:56,180 Epoch[31] Batch [590]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.100498,	
2017-06-28 16:35:02,125 Epoch[31] Batch [600]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.100445,	
2017-06-28 16:35:07,400 Epoch[31] Batch [610]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.100344,	
2017-06-28 16:35:12,560 Epoch[31] Batch [620]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.100390,	
2017-06-28 16:35:18,402 Epoch[31] Batch [630]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100426,	
2017-06-28 16:35:23,523 Epoch[31] Batch [640]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.100560,	
2017-06-28 16:35:29,074 Epoch[31] Batch [650]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.100526,	
2017-06-28 16:35:35,352 Epoch[31] Batch [660]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.100561,	
2017-06-28 16:35:41,571 Epoch[31] Batch [670]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.100857,	
2017-06-28 16:35:47,275 Epoch[31] Batch [680]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.100957,	
2017-06-28 16:35:53,189 Epoch[31] Batch [690]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101102,	
2017-06-28 16:35:59,128 Epoch[31] Batch [700]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.100944,	
2017-06-28 16:36:04,439 Epoch[31] Batch [710]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.101022,	
2017-06-28 16:36:09,814 Epoch[31] Batch [720]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.101004,	
2017-06-28 16:36:15,356 Epoch[31] Batch [730]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.101130,	
2017-06-28 16:36:20,952 Epoch[31] Batch [740]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.101131,	
2017-06-28 16:36:26,736 Epoch[31] Batch [750]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101156,	
2017-06-28 16:36:32,277 Epoch[31] Batch [760]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.100982,	
2017-06-28 16:36:38,581 Epoch[31] Batch [770]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100991,	
2017-06-28 16:36:44,270 Epoch[31] Batch [780]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.101024,	
2017-06-28 16:36:50,587 Epoch[31] Batch [790]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.101035,	
2017-06-28 16:36:55,677 Epoch[31] Batch [800]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.100961,	
2017-06-28 16:37:00,875 Epoch[31] Batch [810]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.101085,	
2017-06-28 16:37:06,603 Epoch[31] Batch [820]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.101137,	
2017-06-28 16:37:12,351 Epoch[31] Batch [830]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.101065,	
2017-06-28 16:37:17,684 Epoch[31] Batch [840]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100962,	
2017-06-28 16:37:22,819 Epoch[31] Batch [850]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.100918,	
2017-06-28 16:37:28,373 Epoch[31] Batch [860]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.100857,	
2017-06-28 16:37:34,025 Epoch[31] Batch [870]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.100855,	
2017-06-28 16:37:39,503 Epoch[31] Batch [880]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.100825,	
2017-06-28 16:37:45,096 Epoch[31] Batch [890]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.100814,	
2017-06-28 16:37:50,591 Epoch[31] Batch [900]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.100908,	
2017-06-28 16:37:55,964 Epoch[31] Batch [910]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100936,	
2017-06-28 16:38:01,922 Epoch[31] Batch [920]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.100924,	
2017-06-28 16:38:07,772 Epoch[31] Batch [930]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100956,	
2017-06-28 16:38:13,847 Epoch[31] Batch [940]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101041,	
2017-06-28 16:38:19,541 Epoch[31] Batch [950]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.101120,	
2017-06-28 16:38:25,499 Epoch[31] Batch [960]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.101069,	
2017-06-28 16:38:31,313 Epoch[31] Batch [970]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101134,	
2017-06-28 16:38:36,993 Epoch[31] Batch [980]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.101195,	
2017-06-28 16:38:43,069 Epoch[31] Batch [990]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101114,	
2017-06-28 16:38:48,932 Epoch[31] Batch [1000]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.101082,	
2017-06-28 16:38:54,675 Epoch[31] Batch [1010]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.101141,	
2017-06-28 16:39:00,103 Epoch[31] Batch [1020]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.101126,	
2017-06-28 16:39:05,819 Epoch[31] Batch [1030]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101063,	
2017-06-28 16:39:11,002 Epoch[31] Batch [1040]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.100946,	
2017-06-28 16:39:15,804 Epoch[31] Batch [1050]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.100921,	
2017-06-28 16:39:21,377 Epoch[31] Batch [1060]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.100948,	
2017-06-28 16:39:27,153 Epoch[31] Batch [1070]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101050,	
2017-06-28 16:39:32,958 Epoch[31] Batch [1080]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101106,	
2017-06-28 16:39:38,659 Epoch[31] Batch [1090]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.101186,	
2017-06-28 16:39:44,808 Epoch[31] Batch [1100]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.101299,	
2017-06-28 16:39:50,453 Epoch[31] Batch [1110]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.101245,	
2017-06-28 16:39:56,504 Epoch[31] Batch [1120]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101144,	
2017-06-28 16:40:02,700 Epoch[31] Batch [1130]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.101239,	
2017-06-28 16:40:07,739 Epoch[31] Batch [1140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.101209,	
2017-06-28 16:40:13,160 Epoch[31] Batch [1150]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.101181,	
2017-06-28 16:40:18,414 Epoch[31] Batch [1160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.101176,	
2017-06-28 16:40:24,435 Epoch[31] Batch [1170]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101113,	
2017-06-28 16:40:30,310 Epoch[31] Batch [1180]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.101083,	
2017-06-28 16:40:36,739 Epoch[31] Batch [1190]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.101039,	
2017-06-28 16:40:42,553 Epoch[31] Batch [1200]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101129,	
2017-06-28 16:40:48,702 Epoch[31] Batch [1210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.101164,	
2017-06-28 16:40:54,330 Epoch[31] Batch [1220]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.101135,	
2017-06-28 16:41:00,489 Epoch[31] Batch [1230]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101199,	
2017-06-28 16:41:06,195 Epoch[31] Batch [1240]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.101266,	
2017-06-28 16:41:11,499 Epoch[31] Batch [1250]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101149,	
2017-06-28 16:41:16,992 Epoch[31] Batch [1260]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.101271,	
2017-06-28 16:41:22,410 Epoch[31] Batch [1270]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.101158,	
2017-06-28 16:41:28,818 Epoch[31] Batch [1280]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.101094,	
2017-06-28 16:41:34,521 Epoch[31] Batch [1290]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.101187,	
2017-06-28 16:41:40,579 Epoch[31] Batch [1300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101182,	
2017-06-28 16:41:46,505 Epoch[31] Batch [1310]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.101188,	
2017-06-28 16:41:52,863 Epoch[31] Batch [1320]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.101144,	
2017-06-28 16:41:58,263 Epoch[31] Batch [1330]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.101050,	
2017-06-28 16:42:03,660 Epoch[31] Batch [1340]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.100976,	
2017-06-28 16:42:08,906 Epoch[31] Batch [1350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.101009,	
2017-06-28 16:42:13,851 Epoch[31] Batch [1360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.100968,	
2017-06-28 16:42:18,872 Epoch[31] Batch [1370]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.100976,	
2017-06-28 16:42:23,921 Epoch[31] Batch [1380]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.100912,	
2017-06-28 16:42:29,238 Epoch[31] Batch [1390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100862,	
2017-06-28 16:42:34,314 Epoch[31] Batch [1400]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.100841,	
2017-06-28 16:42:39,543 Epoch[31] Batch [1410]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.100858,	
2017-06-28 16:42:44,999 Epoch[31] Batch [1420]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.100840,	
2017-06-28 16:42:50,635 Epoch[31] Batch [1430]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.100767,	
2017-06-28 16:42:55,868 Epoch[31] Batch [1440]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.100726,	
2017-06-28 16:43:01,016 Epoch[31] Batch [1450]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.100747,	
2017-06-28 16:43:06,322 Epoch[31] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.100735,	
2017-06-28 16:43:11,329 Epoch[31] Batch [1470]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.100800,	
2017-06-28 16:43:16,203 Epoch[31] Batch [1480]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.100850,	
2017-06-28 16:43:19,285 Epoch[31] Train-FCNLogLoss=0.100792
2017-06-28 16:43:19,285 Epoch[31] Time cost=842.430
2017-06-28 16:43:19,923 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0032.params"
2017-06-28 16:43:21,400 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0032.states"
2017-06-28 16:43:27,527 Epoch[32] Batch [10]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.107497,	
2017-06-28 16:43:32,982 Epoch[32] Batch [20]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.104323,	
2017-06-28 16:43:38,312 Epoch[32] Batch [30]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.102991,	
2017-06-28 16:43:43,936 Epoch[32] Batch [40]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.101661,	
2017-06-28 16:43:49,618 Epoch[32] Batch [50]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.103595,	
2017-06-28 16:43:54,971 Epoch[32] Batch [60]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.103349,	
2017-06-28 16:44:00,377 Epoch[32] Batch [70]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.104032,	
2017-06-28 16:44:05,609 Epoch[32] Batch [80]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.103307,	
2017-06-28 16:44:11,148 Epoch[32] Batch [90]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.103595,	
2017-06-28 16:44:16,559 Epoch[32] Batch [100]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.103807,	
2017-06-28 16:44:21,404 Epoch[32] Batch [110]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.102808,	
2017-06-28 16:44:26,845 Epoch[32] Batch [120]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.102220,	
2017-06-28 16:44:32,677 Epoch[32] Batch [130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101992,	
2017-06-28 16:44:38,357 Epoch[32] Batch [140]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.102477,	
2017-06-28 16:44:43,795 Epoch[32] Batch [150]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.102217,	
2017-06-28 16:44:49,143 Epoch[32] Batch [160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102022,	
2017-06-28 16:44:54,502 Epoch[32] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.101760,	
2017-06-28 16:44:59,928 Epoch[32] Batch [180]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.101181,	
2017-06-28 16:45:05,441 Epoch[32] Batch [190]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.100613,	
2017-06-28 16:45:10,550 Epoch[32] Batch [200]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.100610,	
2017-06-28 16:45:15,514 Epoch[32] Batch [210]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.100624,	
2017-06-28 16:45:21,397 Epoch[32] Batch [220]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.101408,	
2017-06-28 16:45:26,912 Epoch[32] Batch [230]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.101631,	
2017-06-28 16:45:32,440 Epoch[32] Batch [240]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.101938,	
2017-06-28 16:45:38,411 Epoch[32] Batch [250]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101928,	
2017-06-28 16:45:44,089 Epoch[32] Batch [260]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.101740,	
2017-06-28 16:45:50,277 Epoch[32] Batch [270]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.101809,	
2017-06-28 16:45:55,862 Epoch[32] Batch [280]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.101556,	
2017-06-28 16:46:01,247 Epoch[32] Batch [290]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101412,	
2017-06-28 16:46:06,384 Epoch[32] Batch [300]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.101399,	
2017-06-28 16:46:11,438 Epoch[32] Batch [310]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.100978,	
2017-06-28 16:46:16,338 Epoch[32] Batch [320]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.100873,	
2017-06-28 16:46:21,602 Epoch[32] Batch [330]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.100357,	
2017-06-28 16:46:26,865 Epoch[32] Batch [340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.100248,	
2017-06-28 16:46:32,801 Epoch[32] Batch [350]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.100177,	
2017-06-28 16:46:38,603 Epoch[32] Batch [360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100126,	
2017-06-28 16:46:44,767 Epoch[32] Batch [370]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.100139,	
2017-06-28 16:46:50,374 Epoch[32] Batch [380]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.100237,	
2017-06-28 16:46:55,873 Epoch[32] Batch [390]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.100288,	
2017-06-28 16:47:01,727 Epoch[32] Batch [400]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.100064,	
2017-06-28 16:47:07,636 Epoch[32] Batch [410]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099988,	
2017-06-28 16:47:13,155 Epoch[32] Batch [420]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.099888,	
2017-06-28 16:47:18,560 Epoch[32] Batch [430]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.099871,	
2017-06-28 16:47:24,017 Epoch[32] Batch [440]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.100014,	
2017-06-28 16:47:29,338 Epoch[32] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100354,	
2017-06-28 16:47:35,064 Epoch[32] Batch [460]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.100110,	
2017-06-28 16:47:40,620 Epoch[32] Batch [470]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.099979,	
2017-06-28 16:47:46,572 Epoch[32] Batch [480]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.099740,	
2017-06-28 16:47:52,095 Epoch[32] Batch [490]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.099819,	
2017-06-28 16:47:57,859 Epoch[32] Batch [500]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099754,	
2017-06-28 16:48:03,655 Epoch[32] Batch [510]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.099599,	
2017-06-28 16:48:09,155 Epoch[32] Batch [520]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.099783,	
2017-06-28 16:48:15,166 Epoch[32] Batch [530]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100034,	
2017-06-28 16:48:20,447 Epoch[32] Batch [540]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.100478,	
2017-06-28 16:48:25,937 Epoch[32] Batch [550]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.100524,	
2017-06-28 16:48:31,106 Epoch[32] Batch [560]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.100636,	
2017-06-28 16:48:36,333 Epoch[32] Batch [570]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.100767,	
2017-06-28 16:48:41,802 Epoch[32] Batch [580]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.100814,	
2017-06-28 16:48:47,180 Epoch[32] Batch [590]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.101104,	
2017-06-28 16:48:52,855 Epoch[32] Batch [600]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.101256,	
2017-06-28 16:48:58,868 Epoch[32] Batch [610]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101311,	
2017-06-28 16:49:04,500 Epoch[32] Batch [620]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.101547,	
2017-06-28 16:49:09,581 Epoch[32] Batch [630]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.101421,	
2017-06-28 16:49:14,883 Epoch[32] Batch [640]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101271,	
2017-06-28 16:49:20,216 Epoch[32] Batch [650]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101219,	
2017-06-28 16:49:25,898 Epoch[32] Batch [660]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.101201,	
2017-06-28 16:49:31,916 Epoch[32] Batch [670]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101210,	
2017-06-28 16:49:37,706 Epoch[32] Batch [680]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101246,	
2017-06-28 16:49:43,039 Epoch[32] Batch [690]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101275,	
2017-06-28 16:49:48,544 Epoch[32] Batch [700]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.101241,	
2017-06-28 16:49:54,336 Epoch[32] Batch [710]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101257,	
2017-06-28 16:49:59,944 Epoch[32] Batch [720]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.101169,	
2017-06-28 16:50:05,661 Epoch[32] Batch [730]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101164,	
2017-06-28 16:50:11,417 Epoch[32] Batch [740]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101166,	
2017-06-28 16:50:16,500 Epoch[32] Batch [750]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.101146,	
2017-06-28 16:50:21,815 Epoch[32] Batch [760]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.101067,	
2017-06-28 16:50:27,677 Epoch[32] Batch [770]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.101048,	
2017-06-28 16:50:32,733 Epoch[32] Batch [780]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.101016,	
2017-06-28 16:50:37,843 Epoch[32] Batch [790]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.100904,	
2017-06-28 16:50:43,187 Epoch[32] Batch [800]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100954,	
2017-06-28 16:50:48,554 Epoch[32] Batch [810]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.100982,	
2017-06-28 16:50:54,326 Epoch[32] Batch [820]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.100917,	
2017-06-28 16:50:59,800 Epoch[32] Batch [830]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.100941,	
2017-06-28 16:51:05,349 Epoch[32] Batch [840]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.100996,	
2017-06-28 16:51:10,482 Epoch[32] Batch [850]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.100987,	
2017-06-28 16:51:15,957 Epoch[32] Batch [860]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.100974,	
2017-06-28 16:51:21,480 Epoch[32] Batch [870]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.101055,	
2017-06-28 16:51:27,012 Epoch[32] Batch [880]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.101069,	
2017-06-28 16:51:32,798 Epoch[32] Batch [890]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.100994,	
2017-06-28 16:51:38,184 Epoch[32] Batch [900]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.100967,	
2017-06-28 16:51:43,605 Epoch[32] Batch [910]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.101041,	
2017-06-28 16:51:48,895 Epoch[32] Batch [920]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.101237,	
2017-06-28 16:51:54,494 Epoch[32] Batch [930]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.101269,	
2017-06-28 16:51:59,514 Epoch[32] Batch [940]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.101226,	
2017-06-28 16:52:05,069 Epoch[32] Batch [950]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.101338,	
2017-06-28 16:52:10,299 Epoch[32] Batch [960]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.101324,	
2017-06-28 16:52:15,181 Epoch[32] Batch [970]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.101244,	
2017-06-28 16:52:20,450 Epoch[32] Batch [980]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.101193,	
2017-06-28 16:52:26,222 Epoch[32] Batch [990]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101213,	
2017-06-28 16:52:32,044 Epoch[32] Batch [1000]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.101212,	
2017-06-28 16:52:37,763 Epoch[32] Batch [1010]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.101167,	
2017-06-28 16:52:43,841 Epoch[32] Batch [1020]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101051,	
2017-06-28 16:52:49,228 Epoch[32] Batch [1030]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.101016,	
2017-06-28 16:52:54,526 Epoch[32] Batch [1040]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100960,	
2017-06-28 16:53:00,597 Epoch[32] Batch [1050]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101033,	
2017-06-28 16:53:06,425 Epoch[32] Batch [1060]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101094,	
2017-06-28 16:53:11,838 Epoch[32] Batch [1070]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.101173,	
2017-06-28 16:53:17,227 Epoch[32] Batch [1080]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.101334,	
2017-06-28 16:53:22,272 Epoch[32] Batch [1090]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.101251,	
2017-06-28 16:53:27,986 Epoch[32] Batch [1100]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101257,	
2017-06-28 16:53:33,261 Epoch[32] Batch [1110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.101207,	
2017-06-28 16:53:38,820 Epoch[32] Batch [1120]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.101172,	
2017-06-28 16:53:44,234 Epoch[32] Batch [1130]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.101149,	
2017-06-28 16:53:49,354 Epoch[32] Batch [1140]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.101112,	
2017-06-28 16:53:54,933 Epoch[32] Batch [1150]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.101033,	
2017-06-28 16:53:59,885 Epoch[32] Batch [1160]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.101057,	
2017-06-28 16:54:05,132 Epoch[32] Batch [1170]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.101038,	
2017-06-28 16:54:10,596 Epoch[32] Batch [1180]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.101074,	
2017-06-28 16:54:15,748 Epoch[32] Batch [1190]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.101077,	
2017-06-28 16:54:21,455 Epoch[32] Batch [1200]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.101036,	
2017-06-28 16:54:26,954 Epoch[32] Batch [1210]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.100961,	
2017-06-28 16:54:32,548 Epoch[32] Batch [1220]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.100931,	
2017-06-28 16:54:38,369 Epoch[32] Batch [1230]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100847,	
2017-06-28 16:54:43,866 Epoch[32] Batch [1240]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.100760,	
2017-06-28 16:54:49,631 Epoch[32] Batch [1250]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100628,	
2017-06-28 16:54:55,088 Epoch[32] Batch [1260]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.100580,	
2017-06-28 16:55:00,823 Epoch[32] Batch [1270]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.100596,	
2017-06-28 16:55:06,791 Epoch[32] Batch [1280]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.100535,	
2017-06-28 16:55:13,437 Epoch[32] Batch [1290]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.100636,	
2017-06-28 16:55:19,286 Epoch[32] Batch [1300]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100714,	
2017-06-28 16:55:25,336 Epoch[32] Batch [1310]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100776,	
2017-06-28 16:55:31,163 Epoch[32] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100742,	
2017-06-28 16:55:37,295 Epoch[32] Batch [1330]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.100724,	
2017-06-28 16:55:42,912 Epoch[32] Batch [1340]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.100727,	
2017-06-28 16:55:49,001 Epoch[32] Batch [1350]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100829,	
2017-06-28 16:55:54,302 Epoch[32] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100816,	
2017-06-28 16:56:00,152 Epoch[32] Batch [1370]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.100781,	
2017-06-28 16:56:05,478 Epoch[32] Batch [1380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100778,	
2017-06-28 16:56:11,421 Epoch[32] Batch [1390]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.100717,	
2017-06-28 16:56:17,688 Epoch[32] Batch [1400]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.100807,	
2017-06-28 16:56:23,520 Epoch[32] Batch [1410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.100770,	
2017-06-28 16:56:29,703 Epoch[32] Batch [1420]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.100757,	
2017-06-28 16:56:35,831 Epoch[32] Batch [1430]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.100695,	
2017-06-28 16:56:41,732 Epoch[32] Batch [1440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.100685,	
2017-06-28 16:56:47,139 Epoch[32] Batch [1450]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.100665,	
2017-06-28 16:56:52,953 Epoch[32] Batch [1460]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.100687,	
2017-06-28 16:56:58,755 Epoch[32] Batch [1470]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.100730,	
2017-06-28 16:57:04,975 Epoch[32] Batch [1480]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.100740,	
2017-06-28 16:57:08,457 Epoch[32] Train-FCNLogLoss=0.100762
2017-06-28 16:57:08,458 Epoch[32] Time cost=827.057
2017-06-28 16:57:09,109 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0033.params"
2017-06-28 16:57:10,765 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0033.states"
2017-06-28 16:57:17,917 Epoch[33] Batch [10]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.095127,	
2017-06-28 16:57:23,780 Epoch[33] Batch [20]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.089151,	
2017-06-28 16:57:29,973 Epoch[33] Batch [30]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.089928,	
2017-06-28 16:57:35,849 Epoch[33] Batch [40]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.090555,	
2017-06-28 16:57:42,472 Epoch[33] Batch [50]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.091237,	
2017-06-28 16:57:48,501 Epoch[33] Batch [60]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.092335,	
2017-06-28 16:57:54,081 Epoch[33] Batch [70]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.093279,	
2017-06-28 16:57:59,984 Epoch[33] Batch [80]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093262,	
2017-06-28 16:58:05,941 Epoch[33] Batch [90]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.093332,	
2017-06-28 16:58:11,865 Epoch[33] Batch [100]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.094137,	
2017-06-28 16:58:17,628 Epoch[33] Batch [110]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.094465,	
2017-06-28 16:58:23,634 Epoch[33] Batch [120]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.094232,	
2017-06-28 16:58:28,920 Epoch[33] Batch [130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094967,	
2017-06-28 16:58:34,601 Epoch[33] Batch [140]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.095636,	
2017-06-28 16:58:39,983 Epoch[33] Batch [150]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095445,	
2017-06-28 16:58:45,631 Epoch[33] Batch [160]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.095586,	
2017-06-28 16:58:51,241 Epoch[33] Batch [170]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.096025,	
2017-06-28 16:58:56,550 Epoch[33] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095675,	
2017-06-28 16:59:02,224 Epoch[33] Batch [190]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.095575,	
2017-06-28 16:59:07,130 Epoch[33] Batch [200]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.095445,	
2017-06-28 16:59:13,409 Epoch[33] Batch [210]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.095789,	
2017-06-28 16:59:19,652 Epoch[33] Batch [220]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.095724,	
2017-06-28 16:59:25,783 Epoch[33] Batch [230]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.095915,	
2017-06-28 16:59:31,661 Epoch[33] Batch [240]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.095638,	
2017-06-28 16:59:37,789 Epoch[33] Batch [250]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.096040,	
2017-06-28 16:59:43,542 Epoch[33] Batch [260]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.096448,	
2017-06-28 16:59:49,041 Epoch[33] Batch [270]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.096469,	
2017-06-28 16:59:54,421 Epoch[33] Batch [280]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096559,	
2017-06-28 16:59:59,640 Epoch[33] Batch [290]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096473,	
2017-06-28 17:00:05,435 Epoch[33] Batch [300]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096400,	
2017-06-28 17:00:10,940 Epoch[33] Batch [310]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.096931,	
2017-06-28 17:00:15,741 Epoch[33] Batch [320]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.097138,	
2017-06-28 17:00:21,163 Epoch[33] Batch [330]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.097224,	
2017-06-28 17:00:26,142 Epoch[33] Batch [340]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.096995,	
2017-06-28 17:00:32,332 Epoch[33] Batch [350]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.097445,	
2017-06-28 17:00:37,721 Epoch[33] Batch [360]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097285,	
2017-06-28 17:00:43,751 Epoch[33] Batch [370]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.096933,	
2017-06-28 17:00:50,353 Epoch[33] Batch [380]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.097154,	
2017-06-28 17:00:56,045 Epoch[33] Batch [390]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.097469,	
2017-06-28 17:01:01,403 Epoch[33] Batch [400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097367,	
2017-06-28 17:01:06,735 Epoch[33] Batch [410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097448,	
2017-06-28 17:01:12,277 Epoch[33] Batch [420]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.097310,	
2017-06-28 17:01:18,365 Epoch[33] Batch [430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097465,	
2017-06-28 17:01:23,875 Epoch[33] Batch [440]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.097622,	
2017-06-28 17:01:30,127 Epoch[33] Batch [450]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.097461,	
2017-06-28 17:01:35,987 Epoch[33] Batch [460]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.097600,	
2017-06-28 17:01:41,861 Epoch[33] Batch [470]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.097636,	
2017-06-28 17:01:47,255 Epoch[33] Batch [480]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.097639,	
2017-06-28 17:01:53,251 Epoch[33] Batch [490]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.097776,	
2017-06-28 17:01:59,079 Epoch[33] Batch [500]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097819,	
2017-06-28 17:02:04,503 Epoch[33] Batch [510]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.097610,	
2017-06-28 17:02:09,782 Epoch[33] Batch [520]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097637,	
2017-06-28 17:02:15,422 Epoch[33] Batch [530]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.097696,	
2017-06-28 17:02:21,255 Epoch[33] Batch [540]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.097792,	
2017-06-28 17:02:26,934 Epoch[33] Batch [550]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.097778,	
2017-06-28 17:02:33,226 Epoch[33] Batch [560]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.097540,	
2017-06-28 17:02:39,326 Epoch[33] Batch [570]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097622,	
2017-06-28 17:02:45,367 Epoch[33] Batch [580]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097652,	
2017-06-28 17:02:51,352 Epoch[33] Batch [590]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.097845,	
2017-06-28 17:02:57,815 Epoch[33] Batch [600]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.097822,	
2017-06-28 17:03:04,168 Epoch[33] Batch [610]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.097877,	
2017-06-28 17:03:10,588 Epoch[33] Batch [620]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.098017,	
2017-06-28 17:03:16,261 Epoch[33] Batch [630]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.098066,	
2017-06-28 17:03:22,027 Epoch[33] Batch [640]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098166,	
2017-06-28 17:03:27,533 Epoch[33] Batch [650]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.098177,	
2017-06-28 17:03:34,005 Epoch[33] Batch [660]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.098175,	
2017-06-28 17:03:40,205 Epoch[33] Batch [670]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.098202,	
2017-06-28 17:03:46,430 Epoch[33] Batch [680]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.098097,	
2017-06-28 17:03:52,685 Epoch[33] Batch [690]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.098178,	
2017-06-28 17:03:58,107 Epoch[33] Batch [700]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.098153,	
2017-06-28 17:04:03,966 Epoch[33] Batch [710]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098223,	
2017-06-28 17:04:09,795 Epoch[33] Batch [720]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098198,	
2017-06-28 17:04:15,910 Epoch[33] Batch [730]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098090,	
2017-06-28 17:04:21,147 Epoch[33] Batch [740]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.098059,	
2017-06-28 17:04:27,344 Epoch[33] Batch [750]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.097937,	
2017-06-28 17:04:33,173 Epoch[33] Batch [760]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.098235,	
2017-06-28 17:04:39,128 Epoch[33] Batch [770]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.098248,	
2017-06-28 17:04:44,933 Epoch[33] Batch [780]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098136,	
2017-06-28 17:04:50,499 Epoch[33] Batch [790]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.098105,	
2017-06-28 17:04:56,716 Epoch[33] Batch [800]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.098021,	
2017-06-28 17:05:02,056 Epoch[33] Batch [810]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098044,	
2017-06-28 17:05:07,582 Epoch[33] Batch [820]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.098067,	
2017-06-28 17:05:13,506 Epoch[33] Batch [830]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.098080,	
2017-06-28 17:05:18,863 Epoch[33] Batch [840]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.098177,	
2017-06-28 17:05:24,846 Epoch[33] Batch [850]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.098191,	
2017-06-28 17:05:30,353 Epoch[33] Batch [860]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.098185,	
2017-06-28 17:05:36,952 Epoch[33] Batch [870]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.098219,	
2017-06-28 17:05:43,035 Epoch[33] Batch [880]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098468,	
2017-06-28 17:05:49,453 Epoch[33] Batch [890]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.098725,	
2017-06-28 17:05:55,297 Epoch[33] Batch [900]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.099061,	
2017-06-28 17:06:01,272 Epoch[33] Batch [910]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.099054,	
2017-06-28 17:06:07,022 Epoch[33] Batch [920]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099015,	
2017-06-28 17:06:12,611 Epoch[33] Batch [930]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.099307,	
2017-06-28 17:06:18,847 Epoch[33] Batch [940]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.099330,	
2017-06-28 17:06:24,784 Epoch[33] Batch [950]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099523,	
2017-06-28 17:06:30,437 Epoch[33] Batch [960]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.099654,	
2017-06-28 17:06:35,286 Epoch[33] Batch [970]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.099774,	
2017-06-28 17:06:40,554 Epoch[33] Batch [980]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.100000,	
2017-06-28 17:06:46,590 Epoch[33] Batch [990]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100039,	
2017-06-28 17:06:52,495 Epoch[33] Batch [1000]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099942,	
2017-06-28 17:06:58,374 Epoch[33] Batch [1010]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.100106,	
2017-06-28 17:07:03,949 Epoch[33] Batch [1020]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.100027,	
2017-06-28 17:07:09,758 Epoch[33] Batch [1030]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100048,	
2017-06-28 17:07:15,232 Epoch[33] Batch [1040]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.100115,	
2017-06-28 17:07:21,042 Epoch[33] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.100195,	
2017-06-28 17:07:26,943 Epoch[33] Batch [1060]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.100188,	
2017-06-28 17:07:32,437 Epoch[33] Batch [1070]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.100037,	
2017-06-28 17:07:38,118 Epoch[33] Batch [1080]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.100058,	
2017-06-28 17:07:43,168 Epoch[33] Batch [1090]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.100046,	
2017-06-28 17:07:49,342 Epoch[33] Batch [1100]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.100029,	
2017-06-28 17:07:54,765 Epoch[33] Batch [1110]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.100041,	
2017-06-28 17:08:01,400 Epoch[33] Batch [1120]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.099978,	
2017-06-28 17:08:07,460 Epoch[33] Batch [1130]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099862,	
2017-06-28 17:08:13,188 Epoch[33] Batch [1140]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.099848,	
2017-06-28 17:08:19,292 Epoch[33] Batch [1150]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099864,	
2017-06-28 17:08:24,932 Epoch[33] Batch [1160]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.099836,	
2017-06-28 17:08:31,009 Epoch[33] Batch [1170]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100090,	
2017-06-28 17:08:37,107 Epoch[33] Batch [1180]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100046,	
2017-06-28 17:08:42,840 Epoch[33] Batch [1190]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.100048,	
2017-06-28 17:08:48,158 Epoch[33] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.100022,	
2017-06-28 17:08:54,503 Epoch[33] Batch [1210]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.100001,	
2017-06-28 17:09:00,529 Epoch[33] Batch [1220]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099957,	
2017-06-28 17:09:06,816 Epoch[33] Batch [1230]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.099995,	
2017-06-28 17:09:12,899 Epoch[33] Batch [1240]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099953,	
2017-06-28 17:09:18,892 Epoch[33] Batch [1250]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.099979,	
2017-06-28 17:09:24,996 Epoch[33] Batch [1260]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099984,	
2017-06-28 17:09:30,901 Epoch[33] Batch [1270]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-28 17:09:37,051 Epoch[33] Batch [1280]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.099836,	
2017-06-28 17:09:43,138 Epoch[33] Batch [1290]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099887,	
2017-06-28 17:09:49,200 Epoch[33] Batch [1300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099925,	
2017-06-28 17:09:55,231 Epoch[33] Batch [1310]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099986,	
2017-06-28 17:10:01,336 Epoch[33] Batch [1320]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099994,	
2017-06-28 17:10:06,912 Epoch[33] Batch [1330]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.099917,	
2017-06-28 17:10:12,678 Epoch[33] Batch [1340]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.099935,	
2017-06-28 17:10:18,462 Epoch[33] Batch [1350]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099922,	
2017-06-28 17:10:24,119 Epoch[33] Batch [1360]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.099837,	
2017-06-28 17:10:30,626 Epoch[33] Batch [1370]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.099819,	
2017-06-28 17:10:36,544 Epoch[33] Batch [1380]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.099805,	
2017-06-28 17:10:42,975 Epoch[33] Batch [1390]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.099736,	
2017-06-28 17:10:48,675 Epoch[33] Batch [1400]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.099739,	
2017-06-28 17:10:54,590 Epoch[33] Batch [1410]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.099670,	
2017-06-28 17:11:00,338 Epoch[33] Batch [1420]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099646,	
2017-06-28 17:11:06,097 Epoch[33] Batch [1430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099572,	
2017-06-28 17:11:11,880 Epoch[33] Batch [1440]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.099512,	
2017-06-28 17:11:16,676 Epoch[33] Batch [1450]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.099483,	
2017-06-28 17:11:21,776 Epoch[33] Batch [1460]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099481,	
2017-06-28 17:11:26,944 Epoch[33] Batch [1470]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.099536,	
2017-06-28 17:11:32,471 Epoch[33] Batch [1480]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.099500,	
2017-06-28 17:11:35,670 Epoch[33] Train-FCNLogLoss=0.099501
2017-06-28 17:11:35,670 Epoch[33] Time cost=864.905
2017-06-28 17:11:36,318 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0034.params"
2017-06-28 17:11:37,723 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0034.states"
2017-06-28 17:11:43,934 Epoch[34] Batch [10]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101126,	
2017-06-28 17:11:49,157 Epoch[34] Batch [20]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099229,	
2017-06-28 17:11:54,658 Epoch[34] Batch [30]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.100854,	
2017-06-28 17:12:00,619 Epoch[34] Batch [40]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.098499,	
2017-06-28 17:12:06,330 Epoch[34] Batch [50]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.101028,	
2017-06-28 17:12:11,948 Epoch[34] Batch [60]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101151,	
2017-06-28 17:12:17,881 Epoch[34] Batch [70]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101868,	
2017-06-28 17:12:22,826 Epoch[34] Batch [80]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.103547,	
2017-06-28 17:12:27,705 Epoch[34] Batch [90]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.102641,	
2017-06-28 17:12:33,391 Epoch[34] Batch [100]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.102417,	
2017-06-28 17:12:38,967 Epoch[34] Batch [110]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.102193,	
2017-06-28 17:12:44,702 Epoch[34] Batch [120]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.101282,	
2017-06-28 17:12:50,008 Epoch[34] Batch [130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101368,	
2017-06-28 17:12:55,901 Epoch[34] Batch [140]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.100552,	
2017-06-28 17:13:01,189 Epoch[34] Batch [150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.100262,	
2017-06-28 17:13:07,229 Epoch[34] Batch [160]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102210,	
2017-06-28 17:13:13,070 Epoch[34] Batch [170]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.102739,	
2017-06-28 17:13:18,755 Epoch[34] Batch [180]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.103016,	
2017-06-28 17:13:24,832 Epoch[34] Batch [190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102978,	
2017-06-28 17:13:30,169 Epoch[34] Batch [200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102859,	
2017-06-28 17:13:36,465 Epoch[34] Batch [210]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.102424,	
2017-06-28 17:13:42,363 Epoch[34] Batch [220]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.102337,	
2017-06-28 17:13:48,496 Epoch[34] Batch [230]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102055,	
2017-06-28 17:13:53,985 Epoch[34] Batch [240]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.101512,	
2017-06-28 17:13:59,786 Epoch[34] Batch [250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.102103,	
2017-06-28 17:14:05,232 Epoch[34] Batch [260]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.101757,	
2017-06-28 17:14:11,474 Epoch[34] Batch [270]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.101869,	
2017-06-28 17:14:18,123 Epoch[34] Batch [280]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.101662,	
2017-06-28 17:14:23,738 Epoch[34] Batch [290]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101461,	
2017-06-28 17:14:28,936 Epoch[34] Batch [300]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.101164,	
2017-06-28 17:14:33,991 Epoch[34] Batch [310]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.101488,	
2017-06-28 17:14:39,549 Epoch[34] Batch [320]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.101166,	
2017-06-28 17:14:44,722 Epoch[34] Batch [330]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.100972,	
2017-06-28 17:14:50,889 Epoch[34] Batch [340]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.100837,	
2017-06-28 17:14:56,187 Epoch[34] Batch [350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100536,	
2017-06-28 17:15:01,439 Epoch[34] Batch [360]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.100487,	
2017-06-28 17:15:06,432 Epoch[34] Batch [370]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.100394,	
2017-06-28 17:15:10,880 Epoch[34] Batch [380]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.100170,	
2017-06-28 17:15:15,800 Epoch[34] Batch [390]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.099775,	
2017-06-28 17:15:20,594 Epoch[34] Batch [400]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.099452,	
2017-06-28 17:15:25,255 Epoch[34] Batch [410]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.099427,	
2017-06-28 17:15:30,088 Epoch[34] Batch [420]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.099293,	
2017-06-28 17:15:35,116 Epoch[34] Batch [430]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.099226,	
2017-06-28 17:15:40,680 Epoch[34] Batch [440]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.099385,	
2017-06-28 17:15:45,861 Epoch[34] Batch [450]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.099292,	
2017-06-28 17:15:51,305 Epoch[34] Batch [460]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.099043,	
2017-06-28 17:15:56,732 Epoch[34] Batch [470]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.099030,	
2017-06-28 17:16:01,904 Epoch[34] Batch [480]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099016,	
2017-06-28 17:16:07,395 Epoch[34] Batch [490]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.099047,	
2017-06-28 17:16:13,137 Epoch[34] Batch [500]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.099029,	
2017-06-28 17:16:18,434 Epoch[34] Batch [510]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098973,	
2017-06-28 17:16:23,849 Epoch[34] Batch [520]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.099084,	
2017-06-28 17:16:28,718 Epoch[34] Batch [530]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.099141,	
2017-06-28 17:16:34,396 Epoch[34] Batch [540]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.099076,	
2017-06-28 17:16:39,646 Epoch[34] Batch [550]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098977,	
2017-06-28 17:16:44,789 Epoch[34] Batch [560]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.098994,	
2017-06-28 17:16:50,022 Epoch[34] Batch [570]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.098870,	
2017-06-28 17:16:55,339 Epoch[34] Batch [580]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098862,	
2017-06-28 17:17:01,155 Epoch[34] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098957,	
2017-06-28 17:17:06,302 Epoch[34] Batch [600]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.099035,	
2017-06-28 17:17:11,219 Epoch[34] Batch [610]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.099269,	
2017-06-28 17:17:16,424 Epoch[34] Batch [620]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.099099,	
2017-06-28 17:17:21,654 Epoch[34] Batch [630]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.099049,	
2017-06-28 17:17:27,392 Epoch[34] Batch [640]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.099031,	
2017-06-28 17:17:32,712 Epoch[34] Batch [650]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099049,	
2017-06-28 17:17:38,235 Epoch[34] Batch [660]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.098921,	
2017-06-28 17:17:43,462 Epoch[34] Batch [670]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098927,	
2017-06-28 17:17:48,807 Epoch[34] Batch [680]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098831,	
2017-06-28 17:17:53,598 Epoch[34] Batch [690]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.098779,	
2017-06-28 17:17:59,240 Epoch[34] Batch [700]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.098677,	
2017-06-28 17:18:05,017 Epoch[34] Batch [710]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.098715,	
2017-06-28 17:18:10,188 Epoch[34] Batch [720]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.098808,	
2017-06-28 17:18:15,616 Epoch[34] Batch [730]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098806,	
2017-06-28 17:18:20,561 Epoch[34] Batch [740]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.098819,	
2017-06-28 17:18:25,654 Epoch[34] Batch [750]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.098912,	
2017-06-28 17:18:30,834 Epoch[34] Batch [760]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098950,	
2017-06-28 17:18:36,039 Epoch[34] Batch [770]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099070,	
2017-06-28 17:18:41,057 Epoch[34] Batch [780]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.099039,	
2017-06-28 17:18:46,187 Epoch[34] Batch [790]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.098958,	
2017-06-28 17:18:51,546 Epoch[34] Batch [800]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099028,	
2017-06-28 17:18:56,981 Epoch[34] Batch [810]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.098942,	
2017-06-28 17:19:02,190 Epoch[34] Batch [820]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.099017,	
2017-06-28 17:19:07,685 Epoch[34] Batch [830]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.099085,	
2017-06-28 17:19:13,165 Epoch[34] Batch [840]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.099082,	
2017-06-28 17:19:18,328 Epoch[34] Batch [850]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.099075,	
2017-06-28 17:19:23,164 Epoch[34] Batch [860]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.098967,	
2017-06-28 17:19:28,399 Epoch[34] Batch [870]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.098940,	
2017-06-28 17:19:33,996 Epoch[34] Batch [880]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098962,	
2017-06-28 17:19:39,261 Epoch[34] Batch [890]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.098934,	
2017-06-28 17:19:44,443 Epoch[34] Batch [900]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098877,	
2017-06-28 17:19:49,414 Epoch[34] Batch [910]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.098960,	
2017-06-28 17:19:54,165 Epoch[34] Batch [920]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.098881,	
2017-06-28 17:19:59,069 Epoch[34] Batch [930]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.098982,	
2017-06-28 17:20:03,682 Epoch[34] Batch [940]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.098928,	
2017-06-28 17:20:08,359 Epoch[34] Batch [950]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.098926,	
2017-06-28 17:20:13,119 Epoch[34] Batch [960]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098961,	
2017-06-28 17:20:17,700 Epoch[34] Batch [970]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.098921,	
2017-06-28 17:20:22,530 Epoch[34] Batch [980]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.099010,	
2017-06-28 17:20:27,571 Epoch[34] Batch [990]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.098910,	
2017-06-28 17:20:32,763 Epoch[34] Batch [1000]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098808,	
2017-06-28 17:20:38,048 Epoch[34] Batch [1010]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098737,	
2017-06-28 17:20:43,336 Epoch[34] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098545,	
2017-06-28 17:20:48,485 Epoch[34] Batch [1030]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.098484,	
2017-06-28 17:20:53,867 Epoch[34] Batch [1040]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098542,	
2017-06-28 17:20:59,151 Epoch[34] Batch [1050]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098637,	
2017-06-28 17:21:04,482 Epoch[34] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098594,	
2017-06-28 17:21:09,439 Epoch[34] Batch [1070]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.098856,	
2017-06-28 17:21:14,847 Epoch[34] Batch [1080]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.098805,	
2017-06-28 17:21:19,868 Epoch[34] Batch [1090]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.098766,	
2017-06-28 17:21:24,862 Epoch[34] Batch [1100]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.098758,	
2017-06-28 17:21:30,132 Epoch[34] Batch [1110]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.098843,	
2017-06-28 17:21:35,307 Epoch[34] Batch [1120]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.098978,	
2017-06-28 17:21:40,380 Epoch[34] Batch [1130]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.099412,	
2017-06-28 17:21:45,849 Epoch[34] Batch [1140]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.099829,	
2017-06-28 17:21:51,578 Epoch[34] Batch [1150]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.100180,	
2017-06-28 17:21:56,551 Epoch[34] Batch [1160]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.100398,	
2017-06-28 17:22:01,694 Epoch[34] Batch [1170]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.100543,	
2017-06-28 17:22:07,097 Epoch[34] Batch [1180]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.100679,	
2017-06-28 17:22:12,500 Epoch[34] Batch [1190]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.100828,	
2017-06-28 17:22:18,068 Epoch[34] Batch [1200]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.101159,	
2017-06-28 17:22:23,391 Epoch[34] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101674,	
2017-06-28 17:22:28,571 Epoch[34] Batch [1220]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.101939,	
2017-06-28 17:22:33,609 Epoch[34] Batch [1230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.102218,	
2017-06-28 17:22:39,026 Epoch[34] Batch [1240]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.102385,	
2017-06-28 17:22:44,513 Epoch[34] Batch [1250]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.102442,	
2017-06-28 17:22:49,816 Epoch[34] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.102494,	
2017-06-28 17:22:55,059 Epoch[34] Batch [1270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.102572,	
2017-06-28 17:22:59,971 Epoch[34] Batch [1280]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.102586,	
2017-06-28 17:23:04,580 Epoch[34] Batch [1290]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.102603,	
2017-06-28 17:23:09,605 Epoch[34] Batch [1300]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.102570,	
2017-06-28 17:23:14,434 Epoch[34] Batch [1310]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.102539,	
2017-06-28 17:23:19,187 Epoch[34] Batch [1320]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.102546,	
2017-06-28 17:23:24,267 Epoch[34] Batch [1330]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.102649,	
2017-06-28 17:23:28,991 Epoch[34] Batch [1340]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.102611,	
2017-06-28 17:23:33,736 Epoch[34] Batch [1350]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.102682,	
2017-06-28 17:23:38,793 Epoch[34] Batch [1360]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.102668,	
2017-06-28 17:23:44,256 Epoch[34] Batch [1370]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.102632,	
2017-06-28 17:23:49,212 Epoch[34] Batch [1380]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.102722,	
2017-06-28 17:23:54,027 Epoch[34] Batch [1390]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.102755,	
2017-06-28 17:23:58,820 Epoch[34] Batch [1400]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.102745,	
2017-06-28 17:24:03,868 Epoch[34] Batch [1410]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.102743,	
2017-06-28 17:24:09,139 Epoch[34] Batch [1420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.102742,	
2017-06-28 17:24:14,167 Epoch[34] Batch [1430]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.102680,	
2017-06-28 17:24:19,379 Epoch[34] Batch [1440]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.102766,	
2017-06-28 17:24:24,441 Epoch[34] Batch [1450]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.102804,	
2017-06-28 17:24:29,241 Epoch[34] Batch [1460]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.102737,	
2017-06-28 17:24:33,871 Epoch[34] Batch [1470]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.102728,	
2017-06-28 17:24:38,606 Epoch[34] Batch [1480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.102791,	
2017-06-28 17:24:41,359 Epoch[34] Train-FCNLogLoss=0.102852
2017-06-28 17:24:41,360 Epoch[34] Time cost=783.636
2017-06-28 17:24:41,981 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0035.params"
2017-06-28 17:24:43,400 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0035.states"
2017-06-28 17:24:48,920 Epoch[35] Batch [10]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.101290,	
2017-06-28 17:24:53,675 Epoch[35] Batch [20]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.109496,	
2017-06-28 17:24:58,255 Epoch[35] Batch [30]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.105433,	
2017-06-28 17:25:03,276 Epoch[35] Batch [40]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.103364,	
2017-06-28 17:25:08,033 Epoch[35] Batch [50]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.101357,	
2017-06-28 17:25:13,406 Epoch[35] Batch [60]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.102169,	
2017-06-28 17:25:19,225 Epoch[35] Batch [70]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.100859,	
2017-06-28 17:25:25,127 Epoch[35] Batch [80]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.101317,	
2017-06-28 17:25:30,460 Epoch[35] Batch [90]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.100683,	
2017-06-28 17:25:35,611 Epoch[35] Batch [100]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.099891,	
2017-06-28 17:25:40,665 Epoch[35] Batch [110]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.099388,	
2017-06-28 17:25:45,840 Epoch[35] Batch [120]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099204,	
2017-06-28 17:25:50,822 Epoch[35] Batch [130]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.098798,	
2017-06-28 17:25:55,830 Epoch[35] Batch [140]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.098967,	
2017-06-28 17:26:00,897 Epoch[35] Batch [150]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.098898,	
2017-06-28 17:26:06,106 Epoch[35] Batch [160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.098343,	
2017-06-28 17:26:11,465 Epoch[35] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.098113,	
2017-06-28 17:26:16,526 Epoch[35] Batch [180]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.098418,	
2017-06-28 17:26:22,240 Epoch[35] Batch [190]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.098590,	
2017-06-28 17:26:27,617 Epoch[35] Batch [200]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098858,	
2017-06-28 17:26:33,130 Epoch[35] Batch [210]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.098689,	
2017-06-28 17:26:37,983 Epoch[35] Batch [220]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.098903,	
2017-06-28 17:26:43,238 Epoch[35] Batch [230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.098710,	
2017-06-28 17:26:48,896 Epoch[35] Batch [240]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.098748,	
2017-06-28 17:26:54,414 Epoch[35] Batch [250]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.098963,	
2017-06-28 17:26:59,811 Epoch[35] Batch [260]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098459,	
2017-06-28 17:27:05,392 Epoch[35] Batch [270]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098189,	
2017-06-28 17:27:10,522 Epoch[35] Batch [280]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.098414,	
2017-06-28 17:27:15,613 Epoch[35] Batch [290]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.098264,	
2017-06-28 17:27:21,284 Epoch[35] Batch [300]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.097907,	
2017-06-28 17:27:26,463 Epoch[35] Batch [310]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097807,	
2017-06-28 17:27:31,585 Epoch[35] Batch [320]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.098015,	
2017-06-28 17:27:36,764 Epoch[35] Batch [330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098431,	
2017-06-28 17:27:42,230 Epoch[35] Batch [340]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.098196,	
2017-06-28 17:27:47,657 Epoch[35] Batch [350]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098218,	
2017-06-28 17:27:53,089 Epoch[35] Batch [360]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.098649,	
2017-06-28 17:27:58,116 Epoch[35] Batch [370]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.098839,	
2017-06-28 17:28:03,582 Epoch[35] Batch [380]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.098766,	
2017-06-28 17:28:08,928 Epoch[35] Batch [390]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098770,	
2017-06-28 17:28:14,331 Epoch[35] Batch [400]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.099089,	
2017-06-28 17:28:19,581 Epoch[35] Batch [410]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.099067,	
2017-06-28 17:28:24,777 Epoch[35] Batch [420]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098832,	
2017-06-28 17:28:29,790 Epoch[35] Batch [430]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.098725,	
2017-06-28 17:28:34,845 Epoch[35] Batch [440]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.098445,	
2017-06-28 17:28:39,920 Epoch[35] Batch [450]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.098560,	
2017-06-28 17:28:45,394 Epoch[35] Batch [460]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.098529,	
2017-06-28 17:28:50,612 Epoch[35] Batch [470]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.098719,	
2017-06-28 17:28:55,999 Epoch[35] Batch [480]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098655,	
2017-06-28 17:29:01,214 Epoch[35] Batch [490]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099080,	
2017-06-28 17:29:06,824 Epoch[35] Batch [500]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098769,	
2017-06-28 17:29:12,015 Epoch[35] Batch [510]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098760,	
2017-06-28 17:29:17,473 Epoch[35] Batch [520]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.098818,	
2017-06-28 17:29:22,774 Epoch[35] Batch [530]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098702,	
2017-06-28 17:29:28,122 Epoch[35] Batch [540]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098838,	
2017-06-28 17:29:33,689 Epoch[35] Batch [550]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.098739,	
2017-06-28 17:29:39,458 Epoch[35] Batch [560]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098705,	
2017-06-28 17:29:45,109 Epoch[35] Batch [570]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.098809,	
2017-06-28 17:29:50,411 Epoch[35] Batch [580]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.098836,	
2017-06-28 17:29:55,931 Epoch[35] Batch [590]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.098851,	
2017-06-28 17:30:01,324 Epoch[35] Batch [600]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098741,	
2017-06-28 17:30:06,171 Epoch[35] Batch [610]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.098767,	
2017-06-28 17:30:10,820 Epoch[35] Batch [620]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.098624,	
2017-06-28 17:30:15,886 Epoch[35] Batch [630]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.098655,	
2017-06-28 17:30:21,372 Epoch[35] Batch [640]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.098525,	
2017-06-28 17:30:26,868 Epoch[35] Batch [650]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.098544,	
2017-06-28 17:30:32,296 Epoch[35] Batch [660]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.098429,	
2017-06-28 17:30:38,330 Epoch[35] Batch [670]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098567,	
2017-06-28 17:30:43,831 Epoch[35] Batch [680]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.098448,	
2017-06-28 17:30:48,869 Epoch[35] Batch [690]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.098335,	
2017-06-28 17:30:53,839 Epoch[35] Batch [700]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.098356,	
2017-06-28 17:30:58,687 Epoch[35] Batch [710]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.098449,	
2017-06-28 17:31:03,580 Epoch[35] Batch [720]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.098474,	
2017-06-28 17:31:08,378 Epoch[35] Batch [730]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.098347,	
2017-06-28 17:31:13,695 Epoch[35] Batch [740]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098317,	
2017-06-28 17:31:18,429 Epoch[35] Batch [750]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.098164,	
2017-06-28 17:31:23,455 Epoch[35] Batch [760]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.098193,	
2017-06-28 17:31:29,022 Epoch[35] Batch [770]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.098244,	
2017-06-28 17:31:34,462 Epoch[35] Batch [780]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.098142,	
2017-06-28 17:31:39,941 Epoch[35] Batch [790]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.098135,	
2017-06-28 17:31:45,392 Epoch[35] Batch [800]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098111,	
2017-06-28 17:31:50,556 Epoch[35] Batch [810]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.098140,	
2017-06-28 17:31:55,615 Epoch[35] Batch [820]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.098121,	
2017-06-28 17:32:00,592 Epoch[35] Batch [830]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.098069,	
2017-06-28 17:32:05,782 Epoch[35] Batch [840]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098051,	
2017-06-28 17:32:10,672 Epoch[35] Batch [850]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.098111,	
2017-06-28 17:32:15,732 Epoch[35] Batch [860]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.098149,	
2017-06-28 17:32:20,461 Epoch[35] Batch [870]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.098159,	
2017-06-28 17:32:25,830 Epoch[35] Batch [880]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098200,	
2017-06-28 17:32:31,479 Epoch[35] Batch [890]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.098100,	
2017-06-28 17:32:37,105 Epoch[35] Batch [900]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.098104,	
2017-06-28 17:32:42,730 Epoch[35] Batch [910]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.098006,	
2017-06-28 17:32:48,056 Epoch[35] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097828,	
2017-06-28 17:32:53,247 Epoch[35] Batch [930]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.097713,	
2017-06-28 17:32:58,471 Epoch[35] Batch [940]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.097657,	
2017-06-28 17:33:03,466 Epoch[35] Batch [950]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.097562,	
2017-06-28 17:33:08,887 Epoch[35] Batch [960]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.097507,	
2017-06-28 17:33:13,879 Epoch[35] Batch [970]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.097472,	
2017-06-28 17:33:18,932 Epoch[35] Batch [980]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.097508,	
2017-06-28 17:33:24,204 Epoch[35] Batch [990]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097539,	
2017-06-28 17:33:29,376 Epoch[35] Batch [1000]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.097460,	
2017-06-28 17:33:34,481 Epoch[35] Batch [1010]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.097464,	
2017-06-28 17:33:40,077 Epoch[35] Batch [1020]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.097538,	
2017-06-28 17:33:45,964 Epoch[35] Batch [1030]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.097546,	
2017-06-28 17:33:51,448 Epoch[35] Batch [1040]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.097579,	
2017-06-28 17:33:56,515 Epoch[35] Batch [1050]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.097536,	
2017-06-28 17:34:01,684 Epoch[35] Batch [1060]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.097640,	
2017-06-28 17:34:06,987 Epoch[35] Batch [1070]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097623,	
2017-06-28 17:34:11,799 Epoch[35] Batch [1080]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.097695,	
2017-06-28 17:34:17,158 Epoch[35] Batch [1090]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097776,	
2017-06-28 17:34:21,926 Epoch[35] Batch [1100]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.097743,	
2017-06-28 17:34:26,946 Epoch[35] Batch [1110]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.097741,	
2017-06-28 17:34:33,123 Epoch[35] Batch [1120]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.097855,	
2017-06-28 17:34:38,883 Epoch[35] Batch [1130]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.097824,	
2017-06-28 17:34:44,562 Epoch[35] Batch [1140]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.097831,	
2017-06-28 17:34:50,118 Epoch[35] Batch [1150]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097915,	
2017-06-28 17:34:55,447 Epoch[35] Batch [1160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-28 17:35:00,971 Epoch[35] Batch [1170]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.097925,	
2017-06-28 17:35:06,001 Epoch[35] Batch [1180]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.097969,	
2017-06-28 17:35:10,714 Epoch[35] Batch [1190]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.097865,	
2017-06-28 17:35:15,492 Epoch[35] Batch [1200]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.097866,	
2017-06-28 17:35:20,230 Epoch[35] Batch [1210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.097816,	
2017-06-28 17:35:24,748 Epoch[35] Batch [1220]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097808,	
2017-06-28 17:35:29,638 Epoch[35] Batch [1230]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.097851,	
2017-06-28 17:35:34,798 Epoch[35] Batch [1240]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097893,	
2017-06-28 17:35:39,781 Epoch[35] Batch [1250]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.097779,	
2017-06-28 17:35:45,010 Epoch[35] Batch [1260]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097835,	
2017-06-28 17:35:50,193 Epoch[35] Batch [1270]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097888,	
2017-06-28 17:35:55,394 Epoch[35] Batch [1280]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.097875,	
2017-06-28 17:36:00,826 Epoch[35] Batch [1290]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.097916,	
2017-06-28 17:36:06,231 Epoch[35] Batch [1300]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.097924,	
2017-06-28 17:36:11,969 Epoch[35] Batch [1310]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.097999,	
2017-06-28 17:36:17,072 Epoch[35] Batch [1320]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.097953,	
2017-06-28 17:36:22,947 Epoch[35] Batch [1330]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.097969,	
2017-06-28 17:36:28,326 Epoch[35] Batch [1340]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-28 17:36:33,850 Epoch[35] Batch [1350]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.097978,	
2017-06-28 17:36:39,595 Epoch[35] Batch [1360]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.098016,	
2017-06-28 17:36:45,328 Epoch[35] Batch [1370]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.098046,	
2017-06-28 17:36:50,956 Epoch[35] Batch [1380]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.098122,	
2017-06-28 17:36:56,591 Epoch[35] Batch [1390]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.098108,	
2017-06-28 17:37:02,052 Epoch[35] Batch [1400]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.098117,	
2017-06-28 17:37:07,453 Epoch[35] Batch [1410]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098166,	
2017-06-28 17:37:12,451 Epoch[35] Batch [1420]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.098242,	
2017-06-28 17:37:17,499 Epoch[35] Batch [1430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.098173,	
2017-06-28 17:37:22,848 Epoch[35] Batch [1440]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098136,	
2017-06-28 17:37:27,787 Epoch[35] Batch [1450]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.098095,	
2017-06-28 17:37:33,118 Epoch[35] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098147,	
2017-06-28 17:37:39,110 Epoch[35] Batch [1470]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.098063,	
2017-06-28 17:37:44,511 Epoch[35] Batch [1480]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.098064,	
2017-06-28 17:37:47,643 Epoch[35] Train-FCNLogLoss=0.098136
2017-06-28 17:37:47,643 Epoch[35] Time cost=784.243
2017-06-28 17:37:48,311 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0036.params"
2017-06-28 17:37:49,898 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0036.states"
2017-06-28 17:37:55,902 Epoch[36] Batch [10]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.106032,	
2017-06-28 17:38:00,898 Epoch[36] Batch [20]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.099077,	
2017-06-28 17:38:07,076 Epoch[36] Batch [30]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.096399,	
2017-06-28 17:38:12,438 Epoch[36] Batch [40]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097265,	
2017-06-28 17:38:17,040 Epoch[36] Batch [50]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.096253,	
2017-06-28 17:38:22,316 Epoch[36] Batch [60]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094703,	
2017-06-28 17:38:26,936 Epoch[36] Batch [70]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.095063,	
2017-06-28 17:38:31,934 Epoch[36] Batch [80]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.095421,	
2017-06-28 17:38:37,519 Epoch[36] Batch [90]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.094806,	
2017-06-28 17:38:43,297 Epoch[36] Batch [100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.095184,	
2017-06-28 17:38:48,631 Epoch[36] Batch [110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094568,	
2017-06-28 17:38:54,288 Epoch[36] Batch [120]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.095012,	
2017-06-28 17:38:59,905 Epoch[36] Batch [130]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.095675,	
2017-06-28 17:39:05,489 Epoch[36] Batch [140]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.094677,	
2017-06-28 17:39:11,004 Epoch[36] Batch [150]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094836,	
2017-06-28 17:39:16,039 Epoch[36] Batch [160]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.095077,	
2017-06-28 17:39:20,849 Epoch[36] Batch [170]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.095383,	
2017-06-28 17:39:26,487 Epoch[36] Batch [180]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.095174,	
2017-06-28 17:39:31,829 Epoch[36] Batch [190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095359,	
2017-06-28 17:39:37,402 Epoch[36] Batch [200]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.095434,	
2017-06-28 17:39:43,296 Epoch[36] Batch [210]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.095552,	
2017-06-28 17:39:48,078 Epoch[36] Batch [220]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.095797,	
2017-06-28 17:39:52,573 Epoch[36] Batch [230]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.095645,	
2017-06-28 17:39:56,767 Epoch[36] Batch [240]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095277,	
2017-06-28 17:40:00,992 Epoch[36] Batch [250]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094964,	
2017-06-28 17:40:05,382 Epoch[36] Batch [260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.095149,	
2017-06-28 17:40:09,602 Epoch[36] Batch [270]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095065,	
2017-06-28 17:40:13,862 Epoch[36] Batch [280]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.095472,	
2017-06-28 17:40:18,119 Epoch[36] Batch [290]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.095482,	
2017-06-28 17:40:22,309 Epoch[36] Batch [300]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095060,	
2017-06-28 17:40:26,466 Epoch[36] Batch [310]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.095010,	
2017-06-28 17:40:30,623 Epoch[36] Batch [320]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.095034,	
2017-06-28 17:40:34,946 Epoch[36] Batch [330]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095117,	
2017-06-28 17:40:39,212 Epoch[36] Batch [340]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095334,	
2017-06-28 17:40:43,515 Epoch[36] Batch [350]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.095668,	
2017-06-28 17:40:47,448 Epoch[36] Batch [360]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.095830,	
2017-06-28 17:40:51,690 Epoch[36] Batch [370]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.096049,	
2017-06-28 17:40:55,926 Epoch[36] Batch [380]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095899,	
2017-06-28 17:41:00,167 Epoch[36] Batch [390]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.095761,	
2017-06-28 17:41:04,543 Epoch[36] Batch [400]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095384,	
2017-06-28 17:41:08,747 Epoch[36] Batch [410]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095526,	
2017-06-28 17:41:12,944 Epoch[36] Batch [420]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095484,	
2017-06-28 17:41:17,196 Epoch[36] Batch [430]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095501,	
2017-06-28 17:41:21,395 Epoch[36] Batch [440]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095619,	
2017-06-28 17:41:25,852 Epoch[36] Batch [450]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.095472,	
2017-06-28 17:41:30,118 Epoch[36] Batch [460]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095638,	
2017-06-28 17:41:34,354 Epoch[36] Batch [470]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095589,	
2017-06-28 17:41:38,696 Epoch[36] Batch [480]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.095635,	
2017-06-28 17:41:42,979 Epoch[36] Batch [490]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.095747,	
2017-06-28 17:41:47,179 Epoch[36] Batch [500]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095848,	
2017-06-28 17:41:51,544 Epoch[36] Batch [510]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095936,	
2017-06-28 17:41:55,803 Epoch[36] Batch [520]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.095967,	
2017-06-28 17:42:00,136 Epoch[36] Batch [530]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.095817,	
2017-06-28 17:42:04,324 Epoch[36] Batch [540]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095662,	
2017-06-28 17:42:08,451 Epoch[36] Batch [550]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095481,	
2017-06-28 17:42:12,885 Epoch[36] Batch [560]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.095649,	
2017-06-28 17:42:17,417 Epoch[36] Batch [570]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.095735,	
2017-06-28 17:42:21,542 Epoch[36] Batch [580]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095723,	
2017-06-28 17:42:25,907 Epoch[36] Batch [590]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095739,	
2017-06-28 17:42:30,267 Epoch[36] Batch [600]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.095721,	
2017-06-28 17:42:34,308 Epoch[36] Batch [610]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.095711,	
2017-06-28 17:42:38,619 Epoch[36] Batch [620]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.095612,	
2017-06-28 17:42:42,886 Epoch[36] Batch [630]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095670,	
2017-06-28 17:42:47,085 Epoch[36] Batch [640]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095681,	
2017-06-28 17:42:51,472 Epoch[36] Batch [650]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095573,	
2017-06-28 17:42:55,706 Epoch[36] Batch [660]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095688,	
2017-06-28 17:42:59,902 Epoch[36] Batch [670]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095530,	
2017-06-28 17:43:03,921 Epoch[36] Batch [680]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095396,	
2017-06-28 17:43:08,024 Epoch[36] Batch [690]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095436,	
2017-06-28 17:43:12,512 Epoch[36] Batch [700]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.095421,	
2017-06-28 17:43:16,764 Epoch[36] Batch [710]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095528,	
2017-06-28 17:43:21,071 Epoch[36] Batch [720]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.095572,	
2017-06-28 17:43:25,474 Epoch[36] Batch [730]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.095633,	
2017-06-28 17:43:29,705 Epoch[36] Batch [740]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095744,	
2017-06-28 17:43:33,954 Epoch[36] Batch [750]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095663,	
2017-06-28 17:43:38,216 Epoch[36] Batch [760]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095667,	
2017-06-28 17:43:42,377 Epoch[36] Batch [770]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095638,	
2017-06-28 17:43:46,744 Epoch[36] Batch [780]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095639,	
2017-06-28 17:43:50,748 Epoch[36] Batch [790]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095652,	
2017-06-28 17:43:55,093 Epoch[36] Batch [800]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.095606,	
2017-06-28 17:43:59,260 Epoch[36] Batch [810]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095628,	
2017-06-28 17:44:03,381 Epoch[36] Batch [820]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095633,	
2017-06-28 17:44:07,561 Epoch[36] Batch [830]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095743,	
2017-06-28 17:44:11,706 Epoch[36] Batch [840]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095768,	
2017-06-28 17:44:15,965 Epoch[36] Batch [850]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.095765,	
2017-06-28 17:44:20,365 Epoch[36] Batch [860]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.095600,	
2017-06-28 17:44:24,493 Epoch[36] Batch [870]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095703,	
2017-06-28 17:44:28,881 Epoch[36] Batch [880]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095775,	
2017-06-28 17:44:33,133 Epoch[36] Batch [890]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095801,	
2017-06-28 17:44:37,503 Epoch[36] Batch [900]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095754,	
2017-06-28 17:44:41,892 Epoch[36] Batch [910]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.095741,	
2017-06-28 17:44:46,072 Epoch[36] Batch [920]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095712,	
2017-06-28 17:44:50,343 Epoch[36] Batch [930]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095693,	
2017-06-28 17:44:54,525 Epoch[36] Batch [940]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095654,	
2017-06-28 17:44:58,669 Epoch[36] Batch [950]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095754,	
2017-06-28 17:45:02,844 Epoch[36] Batch [960]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.095731,	
2017-06-28 17:45:06,973 Epoch[36] Batch [970]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095632,	
2017-06-28 17:45:11,143 Epoch[36] Batch [980]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095552,	
2017-06-28 17:45:15,540 Epoch[36] Batch [990]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095484,	
2017-06-28 17:45:19,929 Epoch[36] Batch [1000]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.095446,	
2017-06-28 17:45:24,117 Epoch[36] Batch [1010]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095538,	
2017-06-28 17:45:28,395 Epoch[36] Batch [1020]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095680,	
2017-06-28 17:45:32,764 Epoch[36] Batch [1030]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095854,	
2017-06-28 17:45:37,118 Epoch[36] Batch [1040]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.095918,	
2017-06-28 17:45:41,668 Epoch[36] Batch [1050]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095853,	
2017-06-28 17:45:45,897 Epoch[36] Batch [1060]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.095845,	
2017-06-28 17:45:50,197 Epoch[36] Batch [1070]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.095926,	
2017-06-28 17:45:54,598 Epoch[36] Batch [1080]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.095964,	
2017-06-28 17:45:58,808 Epoch[36] Batch [1090]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.096004,	
2017-06-28 17:46:03,135 Epoch[36] Batch [1100]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.095939,	
2017-06-28 17:46:07,257 Epoch[36] Batch [1110]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095940,	
2017-06-28 17:46:11,524 Epoch[36] Batch [1120]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.096103,	
2017-06-28 17:46:15,862 Epoch[36] Batch [1130]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.096163,	
2017-06-28 17:46:20,376 Epoch[36] Batch [1140]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.096222,	
2017-06-28 17:46:24,574 Epoch[36] Batch [1150]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096248,	
2017-06-28 17:46:28,772 Epoch[36] Batch [1160]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096389,	
2017-06-28 17:46:33,210 Epoch[36] Batch [1170]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.096397,	
2017-06-28 17:46:37,625 Epoch[36] Batch [1180]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.096453,	
2017-06-28 17:46:41,807 Epoch[36] Batch [1190]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.096428,	
2017-06-28 17:46:46,292 Epoch[36] Batch [1200]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.096364,	
2017-06-28 17:46:50,579 Epoch[36] Batch [1210]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.096316,	
2017-06-28 17:46:54,916 Epoch[36] Batch [1220]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.096335,	
2017-06-28 17:46:59,072 Epoch[36] Batch [1230]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.096410,	
2017-06-28 17:47:03,397 Epoch[36] Batch [1240]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.096434,	
2017-06-28 17:47:07,528 Epoch[36] Batch [1250]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096474,	
2017-06-28 17:47:11,693 Epoch[36] Batch [1260]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096427,	
2017-06-28 17:47:16,001 Epoch[36] Batch [1270]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.096318,	
2017-06-28 17:47:20,357 Epoch[36] Batch [1280]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096264,	
2017-06-28 17:47:24,665 Epoch[36] Batch [1290]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.096252,	
2017-06-28 17:47:28,951 Epoch[36] Batch [1300]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.096308,	
2017-06-28 17:47:33,278 Epoch[36] Batch [1310]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.096236,	
2017-06-28 17:47:37,649 Epoch[36] Batch [1320]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096301,	
2017-06-28 17:47:41,963 Epoch[36] Batch [1330]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.096312,	
2017-06-28 17:47:46,296 Epoch[36] Batch [1340]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096328,	
2017-06-28 17:47:50,672 Epoch[36] Batch [1350]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.096278,	
2017-06-28 17:47:54,884 Epoch[36] Batch [1360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.096289,	
2017-06-28 17:47:59,086 Epoch[36] Batch [1370]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.096266,	
2017-06-28 17:48:03,166 Epoch[36] Batch [1380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.096343,	
2017-06-28 17:48:07,440 Epoch[36] Batch [1390]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.096304,	
2017-06-28 17:48:11,685 Epoch[36] Batch [1400]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.096281,	
2017-06-28 17:48:16,008 Epoch[36] Batch [1410]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.096218,	
2017-06-28 17:48:20,053 Epoch[36] Batch [1420]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.096303,	
2017-06-28 17:48:24,086 Epoch[36] Batch [1430]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.096305,	
2017-06-28 17:48:28,381 Epoch[36] Batch [1440]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.096248,	
2017-06-28 17:48:32,667 Epoch[36] Batch [1450]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.096204,	
2017-06-28 17:48:36,911 Epoch[36] Batch [1460]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.096232,	
2017-06-28 17:48:41,244 Epoch[36] Batch [1470]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.096207,	
2017-06-28 17:48:45,121 Epoch[36] Batch [1480]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.096192,	
2017-06-28 17:48:47,677 Epoch[36] Train-FCNLogLoss=0.096190
2017-06-28 17:48:47,677 Epoch[36] Time cost=657.778
2017-06-28 17:48:48,338 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0037.params"
2017-06-28 17:48:50,012 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0037.states"
2017-06-28 17:48:54,969 Epoch[37] Batch [10]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.097106,	
2017-06-28 17:48:59,292 Epoch[37] Batch [20]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095297,	
2017-06-28 17:49:03,641 Epoch[37] Batch [30]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.096036,	
2017-06-28 17:49:07,891 Epoch[37] Batch [40]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.096085,	
2017-06-28 17:49:12,342 Epoch[37] Batch [50]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.094128,	
2017-06-28 17:49:16,712 Epoch[37] Batch [60]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.094539,	
2017-06-28 17:49:21,212 Epoch[37] Batch [70]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093186,	
2017-06-28 17:49:25,644 Epoch[37] Batch [80]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.096132,	
2017-06-28 17:49:29,603 Epoch[37] Batch [90]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.095494,	
2017-06-28 17:49:33,731 Epoch[37] Batch [100]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094957,	
2017-06-28 17:49:38,116 Epoch[37] Batch [110]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095040,	
2017-06-28 17:49:42,331 Epoch[37] Batch [120]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.095760,	
2017-06-28 17:49:46,643 Epoch[37] Batch [130]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.095770,	
2017-06-28 17:49:50,829 Epoch[37] Batch [140]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095536,	
2017-06-28 17:49:55,049 Epoch[37] Batch [150]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.096018,	
2017-06-28 17:49:59,505 Epoch[37] Batch [160]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.095813,	
2017-06-28 17:50:03,910 Epoch[37] Batch [170]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.095251,	
2017-06-28 17:50:08,163 Epoch[37] Batch [180]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095408,	
2017-06-28 17:50:12,405 Epoch[37] Batch [190]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.095794,	
2017-06-28 17:50:16,549 Epoch[37] Batch [200]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095409,	
2017-06-28 17:50:20,769 Epoch[37] Batch [210]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095071,	
2017-06-28 17:50:25,044 Epoch[37] Batch [220]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.094651,	
2017-06-28 17:50:29,426 Epoch[37] Batch [230]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.094618,	
2017-06-28 17:50:33,823 Epoch[37] Batch [240]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.094178,	
2017-06-28 17:50:38,109 Epoch[37] Batch [250]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.094400,	
2017-06-28 17:50:42,350 Epoch[37] Batch [260]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.094546,	
2017-06-28 17:50:46,483 Epoch[37] Batch [270]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094595,	
2017-06-28 17:50:50,654 Epoch[37] Batch [280]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.094389,	
2017-06-28 17:50:54,903 Epoch[37] Batch [290]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.094768,	
2017-06-28 17:50:59,337 Epoch[37] Batch [300]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.094809,	
2017-06-28 17:51:03,550 Epoch[37] Batch [310]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094978,	
2017-06-28 17:51:07,925 Epoch[37] Batch [320]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095147,	
2017-06-28 17:51:12,267 Epoch[37] Batch [330]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.095120,	
2017-06-28 17:51:16,625 Epoch[37] Batch [340]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.095186,	
2017-06-28 17:51:20,792 Epoch[37] Batch [350]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095379,	
2017-06-28 17:51:25,126 Epoch[37] Batch [360]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.095287,	
2017-06-28 17:51:29,402 Epoch[37] Batch [370]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095476,	
2017-06-28 17:51:33,750 Epoch[37] Batch [380]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095521,	
2017-06-28 17:51:38,014 Epoch[37] Batch [390]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095141,	
2017-06-28 17:51:42,116 Epoch[37] Batch [400]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095152,	
2017-06-28 17:51:46,547 Epoch[37] Batch [410]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.095155,	
2017-06-28 17:51:50,949 Epoch[37] Batch [420]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.095223,	
2017-06-28 17:51:55,198 Epoch[37] Batch [430]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095179,	
2017-06-28 17:51:59,627 Epoch[37] Batch [440]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.095115,	
2017-06-28 17:52:04,017 Epoch[37] Batch [450]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.094969,	
2017-06-28 17:52:08,441 Epoch[37] Batch [460]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095015,	
2017-06-28 17:52:12,639 Epoch[37] Batch [470]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094914,	
2017-06-28 17:52:16,855 Epoch[37] Batch [480]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094600,	
2017-06-28 17:52:21,078 Epoch[37] Batch [490]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094467,	
2017-06-28 17:52:25,270 Epoch[37] Batch [500]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094446,	
2017-06-28 17:52:29,530 Epoch[37] Batch [510]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094216,	
2017-06-28 17:52:33,565 Epoch[37] Batch [520]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094155,	
2017-06-28 17:52:37,748 Epoch[37] Batch [530]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094246,	
2017-06-28 17:52:42,065 Epoch[37] Batch [540]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.094411,	
2017-06-28 17:52:46,374 Epoch[37] Batch [550]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.094631,	
2017-06-28 17:52:50,710 Epoch[37] Batch [560]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.094510,	
2017-06-28 17:52:55,424 Epoch[37] Batch [570]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.094445,	
2017-06-28 17:53:00,163 Epoch[37] Batch [580]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.094428,	
2017-06-28 17:53:04,700 Epoch[37] Batch [590]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.094406,	
2017-06-28 17:53:09,256 Epoch[37] Batch [600]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.094548,	
2017-06-28 17:53:13,848 Epoch[37] Batch [610]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.094652,	
2017-06-28 17:53:18,042 Epoch[37] Batch [620]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094814,	
2017-06-28 17:53:22,541 Epoch[37] Batch [630]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094980,	
2017-06-28 17:53:27,258 Epoch[37] Batch [640]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.095134,	
2017-06-28 17:53:31,856 Epoch[37] Batch [650]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.095155,	
2017-06-28 17:53:36,489 Epoch[37] Batch [660]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.095235,	
2017-06-28 17:53:41,146 Epoch[37] Batch [670]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.095359,	
2017-06-28 17:53:45,689 Epoch[37] Batch [680]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.095515,	
2017-06-28 17:53:50,281 Epoch[37] Batch [690]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.095591,	
2017-06-28 17:53:54,693 Epoch[37] Batch [700]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095628,	
2017-06-28 17:53:59,255 Epoch[37] Batch [710]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.095558,	
2017-06-28 17:54:03,538 Epoch[37] Batch [720]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.095510,	
2017-06-28 17:54:08,070 Epoch[37] Batch [730]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.095606,	
2017-06-28 17:54:12,588 Epoch[37] Batch [740]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095554,	
2017-06-28 17:54:16,981 Epoch[37] Batch [750]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095394,	
2017-06-28 17:54:21,355 Epoch[37] Batch [760]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095319,	
2017-06-28 17:54:25,705 Epoch[37] Batch [770]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095295,	
2017-06-28 17:54:29,947 Epoch[37] Batch [780]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.095345,	
2017-06-28 17:54:34,481 Epoch[37] Batch [790]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.095324,	
2017-06-28 17:54:39,054 Epoch[37] Batch [800]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.095468,	
2017-06-28 17:54:43,307 Epoch[37] Batch [810]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095486,	
2017-06-28 17:54:47,898 Epoch[37] Batch [820]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.095700,	
2017-06-28 17:54:52,464 Epoch[37] Batch [830]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.096313,	
2017-06-28 17:54:56,973 Epoch[37] Batch [840]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.096492,	
2017-06-28 17:55:01,302 Epoch[37] Batch [850]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.096597,	
2017-06-28 17:55:05,659 Epoch[37] Batch [860]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096832,	
2017-06-28 17:55:10,053 Epoch[37] Batch [870]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.097028,	
2017-06-28 17:55:14,432 Epoch[37] Batch [880]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.097007,	
2017-06-28 17:55:18,712 Epoch[37] Batch [890]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097085,	
2017-06-28 17:55:23,309 Epoch[37] Batch [900]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097751,	
2017-06-28 17:55:27,548 Epoch[37] Batch [910]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.098157,	
2017-06-28 17:55:32,020 Epoch[37] Batch [920]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.098510,	
2017-06-28 17:55:36,468 Epoch[37] Batch [930]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.098567,	
2017-06-28 17:55:40,786 Epoch[37] Batch [940]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.098767,	
2017-06-28 17:55:45,194 Epoch[37] Batch [950]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.098835,	
2017-06-28 17:55:49,764 Epoch[37] Batch [960]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.098928,	
2017-06-28 17:55:54,444 Epoch[37] Batch [970]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.099091,	
2017-06-28 17:55:58,822 Epoch[37] Batch [980]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.099099,	
2017-06-28 17:56:03,504 Epoch[37] Batch [990]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.099109,	
2017-06-28 17:56:08,329 Epoch[37] Batch [1000]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.099240,	
2017-06-28 17:56:13,042 Epoch[37] Batch [1010]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.099237,	
2017-06-28 17:56:17,788 Epoch[37] Batch [1020]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099291,	
2017-06-28 17:56:22,612 Epoch[37] Batch [1030]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.099303,	
2017-06-28 17:56:27,284 Epoch[37] Batch [1040]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.099321,	
2017-06-28 17:56:31,656 Epoch[37] Batch [1050]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.099325,	
2017-06-28 17:56:36,459 Epoch[37] Batch [1060]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.099355,	
2017-06-28 17:56:41,029 Epoch[37] Batch [1070]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.099332,	
2017-06-28 17:56:45,293 Epoch[37] Batch [1080]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.099318,	
2017-06-28 17:56:50,041 Epoch[37] Batch [1090]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099354,	
2017-06-28 17:56:54,692 Epoch[37] Batch [1100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.099332,	
2017-06-28 17:56:59,481 Epoch[37] Batch [1110]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.099300,	
2017-06-28 17:57:03,847 Epoch[37] Batch [1120]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.099259,	
2017-06-28 17:57:08,396 Epoch[37] Batch [1130]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.099219,	
2017-06-28 17:57:13,165 Epoch[37] Batch [1140]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.099101,	
2017-06-28 17:57:17,571 Epoch[37] Batch [1150]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099020,	
2017-06-28 17:57:22,283 Epoch[37] Batch [1160]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.099042,	
2017-06-28 17:57:26,839 Epoch[37] Batch [1170]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.099087,	
2017-06-28 17:57:31,425 Epoch[37] Batch [1180]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.099238,	
2017-06-28 17:57:35,893 Epoch[37] Batch [1190]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.099306,	
2017-06-28 17:57:40,295 Epoch[37] Batch [1200]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.099376,	
2017-06-28 17:57:44,597 Epoch[37] Batch [1210]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.099306,	
2017-06-28 17:57:49,106 Epoch[37] Batch [1220]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.099387,	
2017-06-28 17:57:53,582 Epoch[37] Batch [1230]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.099391,	
2017-06-28 17:57:58,039 Epoch[37] Batch [1240]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.099401,	
2017-06-28 17:58:02,511 Epoch[37] Batch [1250]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.099493,	
2017-06-28 17:58:07,179 Epoch[37] Batch [1260]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.099407,	
2017-06-28 17:58:11,694 Epoch[37] Batch [1270]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.099414,	
2017-06-28 17:58:16,021 Epoch[37] Batch [1280]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.099482,	
2017-06-28 17:58:20,811 Epoch[37] Batch [1290]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.099457,	
2017-06-28 17:58:25,288 Epoch[37] Batch [1300]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.099450,	
2017-06-28 17:58:29,659 Epoch[37] Batch [1310]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.099482,	
2017-06-28 17:58:34,236 Epoch[37] Batch [1320]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.099489,	
2017-06-28 17:58:39,173 Epoch[37] Batch [1330]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.099496,	
2017-06-28 17:58:43,797 Epoch[37] Batch [1340]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.099440,	
2017-06-28 17:58:48,312 Epoch[37] Batch [1350]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.099412,	
2017-06-28 17:58:52,929 Epoch[37] Batch [1360]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.099363,	
2017-06-28 17:58:57,376 Epoch[37] Batch [1370]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-28 17:59:01,963 Epoch[37] Batch [1380]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.099188,	
2017-06-28 17:59:06,845 Epoch[37] Batch [1390]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.099139,	
2017-06-28 17:59:11,520 Epoch[37] Batch [1400]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.099085,	
2017-06-28 17:59:16,118 Epoch[37] Batch [1410]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.099046,	
2017-06-28 17:59:20,746 Epoch[37] Batch [1420]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.099041,	
2017-06-28 17:59:25,493 Epoch[37] Batch [1430]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.098958,	
2017-06-28 17:59:30,198 Epoch[37] Batch [1440]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.099015,	
2017-06-28 17:59:34,972 Epoch[37] Batch [1450]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.098952,	
2017-06-28 17:59:39,241 Epoch[37] Batch [1460]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.098944,	
2017-06-28 17:59:43,849 Epoch[37] Batch [1470]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.098946,	
2017-06-28 17:59:48,217 Epoch[37] Batch [1480]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.098945,	
2017-06-28 17:59:50,942 Epoch[37] Train-FCNLogLoss=0.099030
2017-06-28 17:59:50,942 Epoch[37] Time cost=660.930
2017-06-28 17:59:51,544 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0038.params"
2017-06-28 17:59:52,995 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0038.states"
2017-06-28 17:59:58,233 Epoch[38] Batch [10]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107520,	
2017-06-28 18:00:02,665 Epoch[38] Batch [20]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.107200,	
2017-06-28 18:00:06,980 Epoch[38] Batch [30]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.101993,	
2017-06-28 18:00:11,421 Epoch[38] Batch [40]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.098676,	
2017-06-28 18:00:16,057 Epoch[38] Batch [50]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.098778,	
2017-06-28 18:00:20,720 Epoch[38] Batch [60]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.097390,	
2017-06-28 18:00:25,583 Epoch[38] Batch [70]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.096460,	
2017-06-28 18:00:30,158 Epoch[38] Batch [80]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.095814,	
2017-06-28 18:00:34,787 Epoch[38] Batch [90]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.096587,	
2017-06-28 18:00:39,444 Epoch[38] Batch [100]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.096210,	
2017-06-28 18:00:44,223 Epoch[38] Batch [110]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.095527,	
2017-06-28 18:00:48,767 Epoch[38] Batch [120]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.094993,	
2017-06-28 18:00:53,369 Epoch[38] Batch [130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.095699,	
2017-06-28 18:00:58,022 Epoch[38] Batch [140]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.095660,	
2017-06-28 18:01:02,517 Epoch[38] Batch [150]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.095399,	
2017-06-28 18:01:06,864 Epoch[38] Batch [160]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095690,	
2017-06-28 18:01:11,523 Epoch[38] Batch [170]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.095516,	
2017-06-28 18:01:16,038 Epoch[38] Batch [180]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095088,	
2017-06-28 18:01:20,637 Epoch[38] Batch [190]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.094819,	
2017-06-28 18:01:25,222 Epoch[38] Batch [200]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.094777,	
2017-06-28 18:01:29,999 Epoch[38] Batch [210]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.095020,	
2017-06-28 18:01:34,341 Epoch[38] Batch [220]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.095345,	
2017-06-28 18:01:38,924 Epoch[38] Batch [230]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.095355,	
2017-06-28 18:01:43,189 Epoch[38] Batch [240]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095146,	
2017-06-28 18:01:47,613 Epoch[38] Batch [250]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095292,	
2017-06-28 18:01:52,362 Epoch[38] Batch [260]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.095592,	
2017-06-28 18:01:56,727 Epoch[38] Batch [270]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095659,	
2017-06-28 18:02:01,573 Epoch[38] Batch [280]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.095688,	
2017-06-28 18:02:06,408 Epoch[38] Batch [290]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.095716,	
2017-06-28 18:02:10,913 Epoch[38] Batch [300]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095507,	
2017-06-28 18:02:15,485 Epoch[38] Batch [310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.095521,	
2017-06-28 18:02:20,195 Epoch[38] Batch [320]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.095253,	
2017-06-28 18:02:24,920 Epoch[38] Batch [330]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.095466,	
2017-06-28 18:02:29,282 Epoch[38] Batch [340]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095520,	
2017-06-28 18:02:33,936 Epoch[38] Batch [350]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.095701,	
2017-06-28 18:02:38,803 Epoch[38] Batch [360]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.095715,	
2017-06-28 18:02:43,556 Epoch[38] Batch [370]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.095731,	
2017-06-28 18:02:48,108 Epoch[38] Batch [380]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095770,	
2017-06-28 18:02:52,736 Epoch[38] Batch [390]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095713,	
2017-06-28 18:02:57,533 Epoch[38] Batch [400]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.095787,	
2017-06-28 18:03:02,396 Epoch[38] Batch [410]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.095738,	
2017-06-28 18:03:06,838 Epoch[38] Batch [420]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.095673,	
2017-06-28 18:03:11,560 Epoch[38] Batch [430]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.095622,	
2017-06-28 18:03:16,130 Epoch[38] Batch [440]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.095523,	
2017-06-28 18:03:20,793 Epoch[38] Batch [450]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095711,	
2017-06-28 18:03:25,070 Epoch[38] Batch [460]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095898,	
2017-06-28 18:03:29,618 Epoch[38] Batch [470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.095876,	
2017-06-28 18:03:33,967 Epoch[38] Batch [480]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095745,	
2017-06-28 18:03:38,711 Epoch[38] Batch [490]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.095595,	
2017-06-28 18:03:43,623 Epoch[38] Batch [500]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.095643,	
2017-06-28 18:03:48,259 Epoch[38] Batch [510]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.095618,	
2017-06-28 18:03:52,900 Epoch[38] Batch [520]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.095578,	
2017-06-28 18:03:57,488 Epoch[38] Batch [530]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.095557,	
2017-06-28 18:04:01,975 Epoch[38] Batch [540]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.095482,	
2017-06-28 18:04:06,771 Epoch[38] Batch [550]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.095559,	
2017-06-28 18:04:11,355 Epoch[38] Batch [560]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.095507,	
2017-06-28 18:04:16,148 Epoch[38] Batch [570]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.095653,	
2017-06-28 18:04:20,643 Epoch[38] Batch [580]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.095605,	
2017-06-28 18:04:25,191 Epoch[38] Batch [590]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.095785,	
2017-06-28 18:04:29,924 Epoch[38] Batch [600]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.095868,	
2017-06-28 18:04:34,978 Epoch[38] Batch [610]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.095817,	
2017-06-28 18:04:39,817 Epoch[38] Batch [620]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.095821,	
2017-06-28 18:04:44,372 Epoch[38] Batch [630]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.095808,	
2017-06-28 18:04:49,430 Epoch[38] Batch [640]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.095813,	
2017-06-28 18:04:54,157 Epoch[38] Batch [650]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.095572,	
2017-06-28 18:04:58,842 Epoch[38] Batch [660]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.095614,	
2017-06-28 18:05:03,484 Epoch[38] Batch [670]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.095626,	
2017-06-28 18:05:08,000 Epoch[38] Batch [680]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095668,	
2017-06-28 18:05:12,442 Epoch[38] Batch [690]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.095519,	
2017-06-28 18:05:17,000 Epoch[38] Batch [700]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.095493,	
2017-06-28 18:05:21,426 Epoch[38] Batch [710]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095489,	
2017-06-28 18:05:25,977 Epoch[38] Batch [720]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095609,	
2017-06-28 18:05:30,287 Epoch[38] Batch [730]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.095526,	
2017-06-28 18:05:34,502 Epoch[38] Batch [740]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.095692,	
2017-06-28 18:05:38,733 Epoch[38] Batch [750]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095516,	
2017-06-28 18:05:42,930 Epoch[38] Batch [760]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095450,	
2017-06-28 18:05:47,196 Epoch[38] Batch [770]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095414,	
2017-06-28 18:05:51,350 Epoch[38] Batch [780]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095474,	
2017-06-28 18:05:55,696 Epoch[38] Batch [790]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095465,	
2017-06-28 18:05:59,938 Epoch[38] Batch [800]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.095361,	
2017-06-28 18:06:04,253 Epoch[38] Batch [810]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.095419,	
2017-06-28 18:06:08,606 Epoch[38] Batch [820]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.095322,	
2017-06-28 18:06:12,846 Epoch[38] Batch [830]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095328,	
2017-06-28 18:06:17,267 Epoch[38] Batch [840]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.095251,	
2017-06-28 18:06:21,676 Epoch[38] Batch [850]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095327,	
2017-06-28 18:06:25,903 Epoch[38] Batch [860]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.095284,	
2017-06-28 18:06:30,060 Epoch[38] Batch [870]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.095286,	
2017-06-28 18:06:34,324 Epoch[38] Batch [880]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095172,	
2017-06-28 18:06:38,691 Epoch[38] Batch [890]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095069,	
2017-06-28 18:06:42,880 Epoch[38] Batch [900]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095177,	
2017-06-28 18:06:47,224 Epoch[38] Batch [910]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.095068,	
2017-06-28 18:06:51,445 Epoch[38] Batch [920]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095054,	
2017-06-28 18:06:55,842 Epoch[38] Batch [930]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095145,	
2017-06-28 18:07:00,059 Epoch[38] Batch [940]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095103,	
2017-06-28 18:07:04,305 Epoch[38] Batch [950]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095184,	
2017-06-28 18:07:08,846 Epoch[38] Batch [960]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.095277,	
2017-06-28 18:07:13,219 Epoch[38] Batch [970]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095418,	
2017-06-28 18:07:17,503 Epoch[38] Batch [980]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.095738,	
2017-06-28 18:07:21,885 Epoch[38] Batch [990]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095937,	
2017-06-28 18:07:26,105 Epoch[38] Batch [1000]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.096211,	
2017-06-28 18:07:30,563 Epoch[38] Batch [1010]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.096322,	
2017-06-28 18:07:35,028 Epoch[38] Batch [1020]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.096341,	
2017-06-28 18:07:39,220 Epoch[38] Batch [1030]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096249,	
2017-06-28 18:07:43,476 Epoch[38] Batch [1040]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.096303,	
2017-06-28 18:07:48,001 Epoch[38] Batch [1050]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.096431,	
2017-06-28 18:07:52,303 Epoch[38] Batch [1060]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.096453,	
2017-06-28 18:07:56,590 Epoch[38] Batch [1070]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.096539,	
2017-06-28 18:08:00,749 Epoch[38] Batch [1080]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.096593,	
2017-06-28 18:08:05,121 Epoch[38] Batch [1090]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096669,	
2017-06-28 18:08:09,304 Epoch[38] Batch [1100]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.096735,	
2017-06-28 18:08:13,554 Epoch[38] Batch [1110]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.096766,	
2017-06-28 18:08:17,876 Epoch[38] Batch [1120]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096807,	
2017-06-28 18:08:22,247 Epoch[38] Batch [1130]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096816,	
2017-06-28 18:08:26,632 Epoch[38] Batch [1140]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096863,	
2017-06-28 18:08:31,171 Epoch[38] Batch [1150]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.096804,	
2017-06-28 18:08:35,381 Epoch[38] Batch [1160]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.096811,	
2017-06-28 18:08:39,724 Epoch[38] Batch [1170]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.096696,	
2017-06-28 18:08:44,210 Epoch[38] Batch [1180]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.096729,	
2017-06-28 18:08:48,228 Epoch[38] Batch [1190]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.096706,	
2017-06-28 18:08:52,600 Epoch[38] Batch [1200]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096644,	
2017-06-28 18:08:57,033 Epoch[38] Batch [1210]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.096674,	
2017-06-28 18:09:01,396 Epoch[38] Batch [1220]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.096664,	
2017-06-28 18:09:05,618 Epoch[38] Batch [1230]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.096647,	
2017-06-28 18:09:10,161 Epoch[38] Batch [1240]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.096623,	
2017-06-28 18:09:14,632 Epoch[38] Batch [1250]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.096617,	
2017-06-28 18:09:18,923 Epoch[38] Batch [1260]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.096572,	
2017-06-28 18:09:23,263 Epoch[38] Batch [1270]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.096640,	
2017-06-28 18:09:27,525 Epoch[38] Batch [1280]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.096639,	
2017-06-28 18:09:31,879 Epoch[38] Batch [1290]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.096619,	
2017-06-28 18:09:36,134 Epoch[38] Batch [1300]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.096606,	
2017-06-28 18:09:40,475 Epoch[38] Batch [1310]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.096648,	
2017-06-28 18:09:44,624 Epoch[38] Batch [1320]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096635,	
2017-06-28 18:09:49,023 Epoch[38] Batch [1330]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.096661,	
2017-06-28 18:09:53,394 Epoch[38] Batch [1340]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096631,	
2017-06-28 18:09:57,696 Epoch[38] Batch [1350]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.096589,	
2017-06-28 18:10:01,891 Epoch[38] Batch [1360]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096561,	
2017-06-28 18:10:06,094 Epoch[38] Batch [1370]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.096647,	
2017-06-28 18:10:10,604 Epoch[38] Batch [1380]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.096638,	
2017-06-28 18:10:15,006 Epoch[38] Batch [1390]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.096603,	
2017-06-28 18:10:19,133 Epoch[38] Batch [1400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096654,	
2017-06-28 18:10:23,715 Epoch[38] Batch [1410]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.096671,	
2017-06-28 18:10:28,071 Epoch[38] Batch [1420]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096659,	
2017-06-28 18:10:32,474 Epoch[38] Batch [1430]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.096653,	
2017-06-28 18:10:36,853 Epoch[38] Batch [1440]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.096723,	
2017-06-28 18:10:40,982 Epoch[38] Batch [1450]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096775,	
2017-06-28 18:10:45,301 Epoch[38] Batch [1460]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096751,	
2017-06-28 18:10:49,381 Epoch[38] Batch [1470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.096790,	
2017-06-28 18:10:53,790 Epoch[38] Batch [1480]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.096754,	
2017-06-28 18:10:56,309 Epoch[38] Train-FCNLogLoss=0.096718
2017-06-28 18:10:56,309 Epoch[38] Time cost=663.314
2017-06-28 18:10:56,927 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0039.params"
2017-06-28 18:10:58,340 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0039.states"
2017-06-28 18:11:03,203 Epoch[39] Batch [10]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.097934,	
2017-06-28 18:11:07,530 Epoch[39] Batch [20]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.095887,	
2017-06-28 18:11:11,879 Epoch[39] Batch [30]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.094261,	
2017-06-28 18:11:16,212 Epoch[39] Batch [40]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.091548,	
2017-06-28 18:11:20,511 Epoch[39] Batch [50]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.092118,	
2017-06-28 18:11:24,981 Epoch[39] Batch [60]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091660,	
2017-06-28 18:11:29,301 Epoch[39] Batch [70]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.091663,	
2017-06-28 18:11:33,755 Epoch[39] Batch [80]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090899,	
2017-06-28 18:11:37,888 Epoch[39] Batch [90]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.092360,	
2017-06-28 18:11:42,121 Epoch[39] Batch [100]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.093040,	
2017-06-28 18:11:46,274 Epoch[39] Batch [110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.093298,	
2017-06-28 18:11:50,558 Epoch[39] Batch [120]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.093342,	
2017-06-28 18:11:54,875 Epoch[39] Batch [130]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.093523,	
2017-06-28 18:11:59,311 Epoch[39] Batch [140]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.094235,	
2017-06-28 18:12:03,491 Epoch[39] Batch [150]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.093795,	
2017-06-28 18:12:07,904 Epoch[39] Batch [160]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.094561,	
2017-06-28 18:12:12,682 Epoch[39] Batch [170]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.094051,	
2017-06-28 18:12:17,560 Epoch[39] Batch [180]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.094263,	
2017-06-28 18:12:22,450 Epoch[39] Batch [190]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093988,	
2017-06-28 18:12:27,164 Epoch[39] Batch [200]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.094176,	
2017-06-28 18:12:31,719 Epoch[39] Batch [210]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.093682,	
2017-06-28 18:12:36,621 Epoch[39] Batch [220]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.093101,	
2017-06-28 18:12:41,303 Epoch[39] Batch [230]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.093672,	
2017-06-28 18:12:45,898 Epoch[39] Batch [240]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.093924,	
2017-06-28 18:12:50,628 Epoch[39] Batch [250]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.093827,	
2017-06-28 18:12:55,177 Epoch[39] Batch [260]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.093721,	
2017-06-28 18:13:00,303 Epoch[39] Batch [270]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.093865,	
2017-06-28 18:13:05,424 Epoch[39] Batch [280]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093695,	
2017-06-28 18:13:10,731 Epoch[39] Batch [290]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093777,	
2017-06-28 18:13:15,815 Epoch[39] Batch [300]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.093640,	
2017-06-28 18:13:20,924 Epoch[39] Batch [310]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.093539,	
2017-06-28 18:13:25,960 Epoch[39] Batch [320]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093302,	
2017-06-28 18:13:30,797 Epoch[39] Batch [330]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092924,	
2017-06-28 18:13:35,260 Epoch[39] Batch [340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.093034,	
2017-06-28 18:13:39,440 Epoch[39] Batch [350]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092786,	
2017-06-28 18:13:44,111 Epoch[39] Batch [360]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.093814,	
2017-06-28 18:13:48,500 Epoch[39] Batch [370]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.096039,	
2017-06-28 18:13:52,954 Epoch[39] Batch [380]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.096530,	
2017-06-28 18:13:57,410 Epoch[39] Batch [390]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.097319,	
2017-06-28 18:14:02,500 Epoch[39] Batch [400]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.097681,	
2017-06-28 18:14:07,502 Epoch[39] Batch [410]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.097960,	
2017-06-28 18:14:12,263 Epoch[39] Batch [420]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.098423,	
2017-06-28 18:14:17,147 Epoch[39] Batch [430]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.098553,	
2017-06-28 18:14:22,025 Epoch[39] Batch [440]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.099198,	
2017-06-28 18:14:26,941 Epoch[39] Batch [450]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.101488,	
2017-06-28 18:14:32,071 Epoch[39] Batch [460]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.102035,	
2017-06-28 18:14:36,889 Epoch[39] Batch [470]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.103063,	
2017-06-28 18:14:41,549 Epoch[39] Batch [480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.103643,	
2017-06-28 18:14:46,326 Epoch[39] Batch [490]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.103952,	
2017-06-28 18:14:50,983 Epoch[39] Batch [500]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.104060,	
2017-06-28 18:14:55,659 Epoch[39] Batch [510]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.104208,	
2017-06-28 18:15:00,626 Epoch[39] Batch [520]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.104406,	
2017-06-28 18:15:05,611 Epoch[39] Batch [530]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.104768,	
2017-06-28 18:15:10,509 Epoch[39] Batch [540]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.105196,	
2017-06-28 18:15:15,422 Epoch[39] Batch [550]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.105497,	
2017-06-28 18:15:20,366 Epoch[39] Batch [560]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.105643,	
2017-06-28 18:15:25,245 Epoch[39] Batch [570]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.105535,	
2017-06-28 18:15:29,919 Epoch[39] Batch [580]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.105567,	
2017-06-28 18:15:34,710 Epoch[39] Batch [590]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.105417,	
2017-06-28 18:15:39,188 Epoch[39] Batch [600]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.105401,	
2017-06-28 18:15:43,753 Epoch[39] Batch [610]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.105665,	
2017-06-28 18:15:48,766 Epoch[39] Batch [620]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.105814,	
2017-06-28 18:15:53,598 Epoch[39] Batch [630]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.105925,	
2017-06-28 18:15:58,674 Epoch[39] Batch [640]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.106336,	
2017-06-28 18:16:03,365 Epoch[39] Batch [650]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.106230,	
2017-06-28 18:16:07,847 Epoch[39] Batch [660]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106052,	
2017-06-28 18:16:12,599 Epoch[39] Batch [670]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.106007,	
2017-06-28 18:16:17,579 Epoch[39] Batch [680]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.105852,	
2017-06-28 18:16:22,559 Epoch[39] Batch [690]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.105758,	
2017-06-28 18:16:27,375 Epoch[39] Batch [700]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.105607,	
2017-06-28 18:16:32,232 Epoch[39] Batch [710]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.105459,	
2017-06-28 18:16:37,165 Epoch[39] Batch [720]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.105444,	
2017-06-28 18:16:42,014 Epoch[39] Batch [730]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.105355,	
2017-06-28 18:16:46,884 Epoch[39] Batch [740]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.105354,	
2017-06-28 18:16:51,754 Epoch[39] Batch [750]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.105145,	
2017-06-28 18:16:56,738 Epoch[39] Batch [760]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.105046,	
2017-06-28 18:17:01,736 Epoch[39] Batch [770]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.105223,	
2017-06-28 18:17:06,567 Epoch[39] Batch [780]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.105078,	
2017-06-28 18:17:11,553 Epoch[39] Batch [790]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.105127,	
2017-06-28 18:17:16,773 Epoch[39] Batch [800]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105233,	
2017-06-28 18:17:21,920 Epoch[39] Batch [810]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.105265,	
2017-06-28 18:17:26,747 Epoch[39] Batch [820]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.105071,	
2017-06-28 18:17:31,461 Epoch[39] Batch [830]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104958,	
2017-06-28 18:17:36,342 Epoch[39] Batch [840]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.104800,	
2017-06-28 18:17:41,177 Epoch[39] Batch [850]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.104711,	
2017-06-28 18:17:45,766 Epoch[39] Batch [860]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.104846,	
2017-06-28 18:17:50,618 Epoch[39] Batch [870]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.104899,	
2017-06-28 18:17:55,427 Epoch[39] Batch [880]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.104897,	
2017-06-28 18:18:00,222 Epoch[39] Batch [890]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.104922,	
2017-06-28 18:18:05,127 Epoch[39] Batch [900]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.104919,	
2017-06-28 18:18:09,716 Epoch[39] Batch [910]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.104886,	
2017-06-28 18:18:14,428 Epoch[39] Batch [920]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104855,	
2017-06-28 18:18:19,675 Epoch[39] Batch [930]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.104934,	
2017-06-28 18:18:24,412 Epoch[39] Batch [940]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.105095,	
2017-06-28 18:18:29,148 Epoch[39] Batch [950]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.105138,	
2017-06-28 18:18:33,968 Epoch[39] Batch [960]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.104972,	
2017-06-28 18:18:38,215 Epoch[39] Batch [970]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.104959,	
2017-06-28 18:18:42,962 Epoch[39] Batch [980]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.104968,	
2017-06-28 18:18:47,861 Epoch[39] Batch [990]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.104991,	
2017-06-28 18:18:52,797 Epoch[39] Batch [1000]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.105002,	
2017-06-28 18:18:58,009 Epoch[39] Batch [1010]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105079,	
2017-06-28 18:19:03,335 Epoch[39] Batch [1020]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.105023,	
2017-06-28 18:19:08,309 Epoch[39] Batch [1030]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.105012,	
2017-06-28 18:19:13,249 Epoch[39] Batch [1040]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.104958,	
2017-06-28 18:19:18,108 Epoch[39] Batch [1050]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.104920,	
2017-06-28 18:19:23,005 Epoch[39] Batch [1060]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.104857,	
2017-06-28 18:19:28,323 Epoch[39] Batch [1070]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104772,	
2017-06-28 18:19:33,489 Epoch[39] Batch [1080]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.104749,	
2017-06-28 18:19:38,309 Epoch[39] Batch [1090]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.104641,	
2017-06-28 18:19:43,304 Epoch[39] Batch [1100]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.104636,	
2017-06-28 18:19:47,831 Epoch[39] Batch [1110]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104571,	
2017-06-28 18:19:52,662 Epoch[39] Batch [1120]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.104617,	
2017-06-28 18:19:57,457 Epoch[39] Batch [1130]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.104622,	
2017-06-28 18:20:02,065 Epoch[39] Batch [1140]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.104602,	
2017-06-28 18:20:06,596 Epoch[39] Batch [1150]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.104619,	
2017-06-28 18:20:11,427 Epoch[39] Batch [1160]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.104627,	
2017-06-28 18:20:16,276 Epoch[39] Batch [1170]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.104667,	
2017-06-28 18:20:20,871 Epoch[39] Batch [1180]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.104688,	
2017-06-28 18:20:25,466 Epoch[39] Batch [1190]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.104696,	
2017-06-28 18:20:30,189 Epoch[39] Batch [1200]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.104588,	
2017-06-28 18:20:35,076 Epoch[39] Batch [1210]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.104536,	
2017-06-28 18:20:39,907 Epoch[39] Batch [1220]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.104727,	
2017-06-28 18:20:44,922 Epoch[39] Batch [1230]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.104967,	
2017-06-28 18:20:49,854 Epoch[39] Batch [1240]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.105133,	
2017-06-28 18:20:54,753 Epoch[39] Batch [1250]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.105159,	
2017-06-28 18:20:59,902 Epoch[39] Batch [1260]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.105248,	
2017-06-28 18:21:04,873 Epoch[39] Batch [1270]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.105201,	
2017-06-28 18:21:09,564 Epoch[39] Batch [1280]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.105242,	
2017-06-28 18:21:14,486 Epoch[39] Batch [1290]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.105148,	
2017-06-28 18:21:19,197 Epoch[39] Batch [1300]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.105038,	
2017-06-28 18:21:23,900 Epoch[39] Batch [1310]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.104972,	
2017-06-28 18:21:28,610 Epoch[39] Batch [1320]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104865,	
2017-06-28 18:21:33,944 Epoch[39] Batch [1330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.104798,	
2017-06-28 18:21:39,170 Epoch[39] Batch [1340]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.104824,	
2017-06-28 18:21:44,317 Epoch[39] Batch [1350]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.104690,	
2017-06-28 18:21:49,037 Epoch[39] Batch [1360]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.104602,	
2017-06-28 18:21:53,761 Epoch[39] Batch [1370]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.104503,	
2017-06-28 18:21:58,814 Epoch[39] Batch [1380]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.104541,	
2017-06-28 18:22:03,480 Epoch[39] Batch [1390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.104566,	
2017-06-28 18:22:08,290 Epoch[39] Batch [1400]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.104491,	
2017-06-28 18:22:13,102 Epoch[39] Batch [1410]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.104476,	
2017-06-28 18:22:17,947 Epoch[39] Batch [1420]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.104517,	
2017-06-28 18:22:22,755 Epoch[39] Batch [1430]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.104460,	
2017-06-28 18:22:27,706 Epoch[39] Batch [1440]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.104381,	
2017-06-28 18:22:32,608 Epoch[39] Batch [1450]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.104385,	
2017-06-28 18:22:37,632 Epoch[39] Batch [1460]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.104387,	
2017-06-28 18:22:42,503 Epoch[39] Batch [1470]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.104309,	
2017-06-28 18:22:47,693 Epoch[39] Batch [1480]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.104290,	
2017-06-28 18:22:50,485 Epoch[39] Train-FCNLogLoss=0.104302
2017-06-28 18:22:50,485 Epoch[39] Time cost=712.145
2017-06-28 18:22:51,187 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0040.params"
2017-06-28 18:22:52,640 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0040.states"
2017-06-28 18:22:58,168 Epoch[40] Batch [10]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.091316,	
2017-06-28 18:23:02,857 Epoch[40] Batch [20]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.094442,	
2017-06-28 18:23:07,882 Epoch[40] Batch [30]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.095803,	
2017-06-28 18:23:12,827 Epoch[40] Batch [40]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.095192,	
2017-06-28 18:23:17,914 Epoch[40] Batch [50]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.094438,	
2017-06-28 18:23:23,007 Epoch[40] Batch [60]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.093681,	
2017-06-28 18:23:27,767 Epoch[40] Batch [70]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.094227,	
2017-06-28 18:23:32,657 Epoch[40] Batch [80]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093542,	
2017-06-28 18:23:37,671 Epoch[40] Batch [90]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.093247,	
2017-06-28 18:23:42,723 Epoch[40] Batch [100]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.093501,	
2017-06-28 18:23:47,997 Epoch[40] Batch [110]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.092701,	
2017-06-28 18:23:53,098 Epoch[40] Batch [120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.093242,	
2017-06-28 18:23:57,736 Epoch[40] Batch [130]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.093878,	
2017-06-28 18:24:02,694 Epoch[40] Batch [140]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.093592,	
2017-06-28 18:24:07,451 Epoch[40] Batch [150]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.093897,	
2017-06-28 18:24:12,262 Epoch[40] Batch [160]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.094013,	
2017-06-28 18:24:17,464 Epoch[40] Batch [170]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093947,	
2017-06-28 18:24:22,450 Epoch[40] Batch [180]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.094180,	
2017-06-28 18:24:27,553 Epoch[40] Batch [190]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.094277,	
2017-06-28 18:24:32,699 Epoch[40] Batch [200]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094715,	
2017-06-28 18:24:37,718 Epoch[40] Batch [210]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.094896,	
2017-06-28 18:24:42,180 Epoch[40] Batch [220]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.094880,	
2017-06-28 18:24:46,846 Epoch[40] Batch [230]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.094767,	
2017-06-28 18:24:51,479 Epoch[40] Batch [240]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095059,	
2017-06-28 18:24:56,315 Epoch[40] Batch [250]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.094631,	
2017-06-28 18:25:00,972 Epoch[40] Batch [260]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.094741,	
2017-06-28 18:25:05,740 Epoch[40] Batch [270]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094757,	
2017-06-28 18:25:10,497 Epoch[40] Batch [280]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-28 18:25:15,595 Epoch[40] Batch [290]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094335,	
2017-06-28 18:25:20,308 Epoch[40] Batch [300]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.094397,	
2017-06-28 18:25:25,004 Epoch[40] Batch [310]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.094347,	
2017-06-28 18:25:29,659 Epoch[40] Batch [320]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.094264,	
2017-06-28 18:25:34,357 Epoch[40] Batch [330]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.094143,	
2017-06-28 18:25:39,029 Epoch[40] Batch [340]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.094154,	
2017-06-28 18:25:43,746 Epoch[40] Batch [350]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.094299,	
2017-06-28 18:25:48,861 Epoch[40] Batch [360]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.094300,	
2017-06-28 18:25:54,228 Epoch[40] Batch [370]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094264,	
2017-06-28 18:25:59,020 Epoch[40] Batch [380]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.094371,	
2017-06-28 18:26:04,126 Epoch[40] Batch [390]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.094449,	
2017-06-28 18:26:09,224 Epoch[40] Batch [400]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094406,	
2017-06-28 18:26:14,347 Epoch[40] Batch [410]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094940,	
2017-06-28 18:26:19,219 Epoch[40] Batch [420]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.094843,	
2017-06-28 18:26:24,351 Epoch[40] Batch [430]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.094996,	
2017-06-28 18:26:29,243 Epoch[40] Batch [440]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.094904,	
2017-06-28 18:26:34,181 Epoch[40] Batch [450]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.094873,	
2017-06-28 18:26:39,103 Epoch[40] Batch [460]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.094957,	
2017-06-28 18:26:44,094 Epoch[40] Batch [470]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.094942,	
2017-06-28 18:26:48,715 Epoch[40] Batch [480]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.094785,	
2017-06-28 18:26:53,378 Epoch[40] Batch [490]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095085,	
2017-06-28 18:26:58,314 Epoch[40] Batch [500]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.095115,	
2017-06-28 18:27:03,070 Epoch[40] Batch [510]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.095081,	
2017-06-28 18:27:07,654 Update[60000]: Change learning rate to 5.00000e-05
2017-06-28 18:27:08,347 Epoch[40] Batch [520]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095296,	
2017-06-28 18:27:13,214 Epoch[40] Batch [530]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.095385,	
2017-06-28 18:27:18,187 Epoch[40] Batch [540]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.095489,	
2017-06-28 18:27:23,259 Epoch[40] Batch [550]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.095593,	
2017-06-28 18:27:28,155 Epoch[40] Batch [560]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.095584,	
2017-06-28 18:27:32,884 Epoch[40] Batch [570]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.095682,	
2017-06-28 18:27:37,188 Epoch[40] Batch [580]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.095975,	
2017-06-28 18:27:41,710 Epoch[40] Batch [590]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.095797,	
2017-06-28 18:27:46,465 Epoch[40] Batch [600]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.095726,	
2017-06-28 18:27:50,857 Epoch[40] Batch [610]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.095596,	
2017-06-28 18:27:55,123 Epoch[40] Batch [620]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095594,	
2017-06-28 18:27:59,355 Epoch[40] Batch [630]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095704,	
2017-06-28 18:28:03,740 Epoch[40] Batch [640]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095792,	
2017-06-28 18:28:08,109 Epoch[40] Batch [650]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095848,	
2017-06-28 18:28:12,469 Epoch[40] Batch [660]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.095889,	
2017-06-28 18:28:16,670 Epoch[40] Batch [670]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095863,	
2017-06-28 18:28:20,954 Epoch[40] Batch [680]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.095868,	
2017-06-28 18:28:25,300 Epoch[40] Batch [690]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095868,	
2017-06-28 18:28:29,892 Epoch[40] Batch [700]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.095711,	
2017-06-28 18:28:34,063 Epoch[40] Batch [710]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095574,	
2017-06-28 18:28:38,443 Epoch[40] Batch [720]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095539,	
2017-06-28 18:28:42,859 Epoch[40] Batch [730]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.095666,	
2017-06-28 18:28:47,255 Epoch[40] Batch [740]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095605,	
2017-06-28 18:28:51,536 Epoch[40] Batch [750]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095562,	
2017-06-28 18:28:56,244 Epoch[40] Batch [760]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.095417,	
2017-06-28 18:29:00,796 Epoch[40] Batch [770]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095406,	
2017-06-28 18:29:05,269 Epoch[40] Batch [780]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.095310,	
2017-06-28 18:29:09,732 Epoch[40] Batch [790]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.095333,	
2017-06-28 18:29:14,100 Epoch[40] Batch [800]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095376,	
2017-06-28 18:29:18,599 Epoch[40] Batch [810]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.095350,	
2017-06-28 18:29:23,367 Epoch[40] Batch [820]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.095303,	
2017-06-28 18:29:28,047 Epoch[40] Batch [830]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.095319,	
2017-06-28 18:29:32,509 Epoch[40] Batch [840]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.095425,	
2017-06-28 18:29:37,009 Epoch[40] Batch [850]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.095422,	
2017-06-28 18:29:41,590 Epoch[40] Batch [860]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.095453,	
2017-06-28 18:29:46,026 Epoch[40] Batch [870]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.095289,	
2017-06-28 18:29:50,384 Epoch[40] Batch [880]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.095285,	
2017-06-28 18:29:54,722 Epoch[40] Batch [890]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.095285,	
2017-06-28 18:29:59,379 Epoch[40] Batch [900]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.095216,	
2017-06-28 18:30:03,746 Epoch[40] Batch [910]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095089,	
2017-06-28 18:30:08,152 Epoch[40] Batch [920]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.095070,	
2017-06-28 18:30:12,758 Epoch[40] Batch [930]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.095132,	
2017-06-28 18:30:17,169 Epoch[40] Batch [940]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095158,	
2017-06-28 18:30:21,554 Epoch[40] Batch [950]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095150,	
2017-06-28 18:30:26,107 Epoch[40] Batch [960]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095210,	
2017-06-28 18:30:30,794 Epoch[40] Batch [970]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.095115,	
2017-06-28 18:30:35,284 Epoch[40] Batch [980]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.095114,	
2017-06-28 18:30:39,621 Epoch[40] Batch [990]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.095088,	
2017-06-28 18:30:44,013 Epoch[40] Batch [1000]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.095062,	
2017-06-28 18:30:48,551 Epoch[40] Batch [1010]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.094925,	
2017-06-28 18:30:53,246 Epoch[40] Batch [1020]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.094866,	
2017-06-28 18:30:57,952 Epoch[40] Batch [1030]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.095041,	
2017-06-28 18:31:02,615 Epoch[40] Batch [1040]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.094980,	
2017-06-28 18:31:07,099 Epoch[40] Batch [1050]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.094832,	
2017-06-28 18:31:11,840 Epoch[40] Batch [1060]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.094899,	
2017-06-28 18:31:16,390 Epoch[40] Batch [1070]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.094856,	
2017-06-28 18:31:20,811 Epoch[40] Batch [1080]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.094826,	
2017-06-28 18:31:25,311 Epoch[40] Batch [1090]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094872,	
2017-06-28 18:31:30,006 Epoch[40] Batch [1100]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.094883,	
2017-06-28 18:31:34,574 Epoch[40] Batch [1110]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.094852,	
2017-06-28 18:31:39,041 Epoch[40] Batch [1120]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.094800,	
2017-06-28 18:31:43,536 Epoch[40] Batch [1130]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094726,	
2017-06-28 18:31:47,985 Epoch[40] Batch [1140]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.094710,	
2017-06-28 18:31:52,342 Epoch[40] Batch [1150]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094595,	
2017-06-28 18:31:56,968 Epoch[40] Batch [1160]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.094561,	
2017-06-28 18:32:01,499 Epoch[40] Batch [1170]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.094661,	
2017-06-28 18:32:05,855 Epoch[40] Batch [1180]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094636,	
2017-06-28 18:32:10,352 Epoch[40] Batch [1190]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094538,	
2017-06-28 18:32:14,815 Epoch[40] Batch [1200]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.094513,	
2017-06-28 18:32:19,272 Epoch[40] Batch [1210]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.094491,	
2017-06-28 18:32:23,422 Epoch[40] Batch [1220]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094485,	
2017-06-28 18:32:27,892 Epoch[40] Batch [1230]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-28 18:32:32,392 Epoch[40] Batch [1240]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094541,	
2017-06-28 18:32:36,858 Epoch[40] Batch [1250]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.094528,	
2017-06-28 18:32:41,193 Epoch[40] Batch [1260]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.094575,	
2017-06-28 18:32:45,574 Epoch[40] Batch [1270]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.094573,	
2017-06-28 18:32:50,003 Epoch[40] Batch [1280]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.094510,	
2017-06-28 18:32:54,462 Epoch[40] Batch [1290]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.094477,	
2017-06-28 18:32:58,895 Epoch[40] Batch [1300]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.094425,	
2017-06-28 18:33:03,253 Epoch[40] Batch [1310]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094348,	
2017-06-28 18:33:07,624 Epoch[40] Batch [1320]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.094335,	
2017-06-28 18:33:11,844 Epoch[40] Batch [1330]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094255,	
2017-06-28 18:33:16,298 Epoch[40] Batch [1340]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.094327,	
2017-06-28 18:33:20,711 Epoch[40] Batch [1350]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.094256,	
2017-06-28 18:33:25,450 Epoch[40] Batch [1360]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.094197,	
2017-06-28 18:33:29,785 Epoch[40] Batch [1370]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.094187,	
2017-06-28 18:33:34,240 Epoch[40] Batch [1380]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.094192,	
2017-06-28 18:33:38,686 Epoch[40] Batch [1390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.094182,	
2017-06-28 18:33:43,218 Epoch[40] Batch [1400]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.094162,	
2017-06-28 18:33:47,639 Epoch[40] Batch [1410]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.094205,	
2017-06-28 18:33:51,875 Epoch[40] Batch [1420]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.094195,	
2017-06-28 18:33:56,082 Epoch[40] Batch [1430]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.094194,	
2017-06-28 18:34:00,374 Epoch[40] Batch [1440]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094151,	
2017-06-28 18:34:04,872 Epoch[40] Batch [1450]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094134,	
2017-06-28 18:34:09,173 Epoch[40] Batch [1460]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094107,	
2017-06-28 18:34:13,554 Epoch[40] Batch [1470]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.094107,	
2017-06-28 18:34:18,111 Epoch[40] Batch [1480]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.094146,	
2017-06-28 18:34:20,831 Epoch[40] Train-FCNLogLoss=0.094127
2017-06-28 18:34:20,831 Epoch[40] Time cost=688.190
2017-06-28 18:34:21,437 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0041.params"
2017-06-28 18:34:22,832 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0041.states"
2017-06-28 18:34:28,118 Epoch[41] Batch [10]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.094384,	
2017-06-28 18:34:32,586 Epoch[41] Batch [20]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.089899,	
2017-06-28 18:34:36,922 Epoch[41] Batch [30]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.091219,	
2017-06-28 18:34:41,496 Epoch[41] Batch [40]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092433,	
2017-06-28 18:34:45,903 Epoch[41] Batch [50]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090568,	
2017-06-28 18:34:50,230 Epoch[41] Batch [60]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.090238,	
2017-06-28 18:34:54,632 Epoch[41] Batch [70]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089843,	
2017-06-28 18:34:59,234 Epoch[41] Batch [80]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090188,	
2017-06-28 18:35:03,973 Epoch[41] Batch [90]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090108,	
2017-06-28 18:35:08,814 Epoch[41] Batch [100]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091407,	
2017-06-28 18:35:13,673 Epoch[41] Batch [110]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.091500,	
2017-06-28 18:35:18,582 Epoch[41] Batch [120]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.091309,	
2017-06-28 18:35:23,407 Epoch[41] Batch [130]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090632,	
2017-06-28 18:35:28,258 Epoch[41] Batch [140]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090715,	
2017-06-28 18:35:33,191 Epoch[41] Batch [150]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.091033,	
2017-06-28 18:35:37,946 Epoch[41] Batch [160]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090797,	
2017-06-28 18:35:43,479 Epoch[41] Batch [170]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.091310,	
2017-06-28 18:35:48,489 Epoch[41] Batch [180]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.091157,	
2017-06-28 18:35:53,453 Epoch[41] Batch [190]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.091452,	
2017-06-28 18:35:58,596 Epoch[41] Batch [200]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.091071,	
2017-06-28 18:36:04,114 Epoch[41] Batch [210]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.091151,	
2017-06-28 18:36:08,998 Epoch[41] Batch [220]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091350,	
2017-06-28 18:36:13,931 Epoch[41] Batch [230]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090952,	
2017-06-28 18:36:19,247 Epoch[41] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090412,	
2017-06-28 18:36:24,381 Epoch[41] Batch [250]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090762,	
2017-06-28 18:36:29,046 Epoch[41] Batch [260]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.090746,	
2017-06-28 18:36:34,090 Epoch[41] Batch [270]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.090954,	
2017-06-28 18:36:38,913 Epoch[41] Batch [280]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090701,	
2017-06-28 18:36:43,738 Epoch[41] Batch [290]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090714,	
2017-06-28 18:36:49,210 Epoch[41] Batch [300]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.090646,	
2017-06-28 18:36:54,144 Epoch[41] Batch [310]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090599,	
2017-06-28 18:36:58,884 Epoch[41] Batch [320]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090623,	
2017-06-28 18:37:03,748 Epoch[41] Batch [330]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090815,	
2017-06-28 18:37:08,075 Epoch[41] Batch [340]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.090563,	
2017-06-28 18:37:12,433 Epoch[41] Batch [350]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.090667,	
2017-06-28 18:37:16,890 Epoch[41] Batch [360]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090484,	
2017-06-28 18:37:21,700 Epoch[41] Batch [370]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090171,	
2017-06-28 18:37:26,938 Epoch[41] Batch [380]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.090185,	
2017-06-28 18:37:31,934 Epoch[41] Batch [390]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.090103,	
2017-06-28 18:37:36,802 Epoch[41] Batch [400]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090195,	
2017-06-28 18:37:41,971 Epoch[41] Batch [410]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090352,	
2017-06-28 18:37:47,374 Epoch[41] Batch [420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090473,	
2017-06-28 18:37:52,692 Epoch[41] Batch [430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090548,	
2017-06-28 18:37:57,793 Epoch[41] Batch [440]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.090492,	
2017-06-28 18:38:03,160 Epoch[41] Batch [450]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090501,	
2017-06-28 18:38:08,528 Epoch[41] Batch [460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090551,	
2017-06-28 18:38:13,771 Epoch[41] Batch [470]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090681,	
2017-06-28 18:38:18,633 Epoch[41] Batch [480]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.090905,	
2017-06-28 18:38:23,785 Epoch[41] Batch [490]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.091178,	
2017-06-28 18:38:29,166 Epoch[41] Batch [500]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.091156,	
2017-06-28 18:38:34,070 Epoch[41] Batch [510]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.091233,	
2017-06-28 18:38:39,018 Epoch[41] Batch [520]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.091303,	
2017-06-28 18:38:43,682 Epoch[41] Batch [530]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091221,	
2017-06-28 18:38:48,546 Epoch[41] Batch [540]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.091272,	
2017-06-28 18:38:53,508 Epoch[41] Batch [550]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.091401,	
2017-06-28 18:38:58,201 Epoch[41] Batch [560]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091265,	
2017-06-28 18:39:03,002 Epoch[41] Batch [570]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.091308,	
2017-06-28 18:39:07,938 Epoch[41] Batch [580]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.091410,	
2017-06-28 18:39:12,704 Epoch[41] Batch [590]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091501,	
2017-06-28 18:39:17,469 Epoch[41] Batch [600]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.091503,	
2017-06-28 18:39:22,279 Epoch[41] Batch [610]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091521,	
2017-06-28 18:39:27,285 Epoch[41] Batch [620]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.091555,	
2017-06-28 18:39:32,235 Epoch[41] Batch [630]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.091621,	
2017-06-28 18:39:37,060 Epoch[41] Batch [640]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091735,	
2017-06-28 18:39:41,829 Epoch[41] Batch [650]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091846,	
2017-06-28 18:39:46,380 Epoch[41] Batch [660]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091853,	
2017-06-28 18:39:51,232 Epoch[41] Batch [670]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.091822,	
2017-06-28 18:39:56,272 Epoch[41] Batch [680]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.091764,	
2017-06-28 18:40:01,313 Epoch[41] Batch [690]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.091752,	
2017-06-28 18:40:06,082 Epoch[41] Batch [700]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091777,	
2017-06-28 18:40:11,027 Epoch[41] Batch [710]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.091519,	
2017-06-28 18:40:15,719 Epoch[41] Batch [720]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091515,	
2017-06-28 18:40:21,039 Epoch[41] Batch [730]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091467,	
2017-06-28 18:40:25,954 Epoch[41] Batch [740]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.091439,	
2017-06-28 18:40:31,013 Epoch[41] Batch [750]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.091423,	
2017-06-28 18:40:35,765 Epoch[41] Batch [760]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.091442,	
2017-06-28 18:40:40,763 Epoch[41] Batch [770]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.091383,	
2017-06-28 18:40:45,876 Epoch[41] Batch [780]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.091442,	
2017-06-28 18:40:50,606 Epoch[41] Batch [790]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091453,	
2017-06-28 18:40:55,256 Epoch[41] Batch [800]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091367,	
2017-06-28 18:40:59,598 Epoch[41] Batch [810]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-28 18:41:04,339 Epoch[41] Batch [820]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091092,	
2017-06-28 18:41:09,348 Epoch[41] Batch [830]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.091076,	
2017-06-28 18:41:14,393 Epoch[41] Batch [840]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.091063,	
2017-06-28 18:41:19,175 Epoch[41] Batch [850]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.091027,	
2017-06-28 18:41:24,349 Epoch[41] Batch [860]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.091102,	
2017-06-28 18:41:29,108 Epoch[41] Batch [870]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091022,	
2017-06-28 18:41:34,001 Epoch[41] Batch [880]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.091123,	
2017-06-28 18:41:38,812 Epoch[41] Batch [890]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091201,	
2017-06-28 18:41:44,146 Epoch[41] Batch [900]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091199,	
2017-06-28 18:41:49,141 Epoch[41] Batch [910]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.091137,	
2017-06-28 18:41:54,143 Epoch[41] Batch [920]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-28 18:41:58,987 Epoch[41] Batch [930]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091204,	
2017-06-28 18:42:03,925 Epoch[41] Batch [940]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.091116,	
2017-06-28 18:42:09,034 Epoch[41] Batch [950]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.091133,	
2017-06-28 18:42:13,934 Epoch[41] Batch [960]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.091090,	
2017-06-28 18:42:18,439 Epoch[41] Batch [970]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091186,	
2017-06-28 18:42:22,799 Epoch[41] Batch [980]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.091155,	
2017-06-28 18:42:27,624 Epoch[41] Batch [990]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091079,	
2017-06-28 18:42:32,472 Epoch[41] Batch [1000]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091135,	
2017-06-28 18:42:37,801 Epoch[41] Batch [1010]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091116,	
2017-06-28 18:42:42,931 Epoch[41] Batch [1020]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.091033,	
2017-06-28 18:42:48,093 Epoch[41] Batch [1030]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.091046,	
2017-06-28 18:42:53,158 Epoch[41] Batch [1040]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090996,	
2017-06-28 18:42:58,288 Epoch[41] Batch [1050]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.091034,	
2017-06-28 18:43:02,799 Epoch[41] Batch [1060]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.090942,	
2017-06-28 18:43:07,960 Epoch[41] Batch [1070]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090875,	
2017-06-28 18:43:13,149 Epoch[41] Batch [1080]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090935,	
2017-06-28 18:43:18,523 Epoch[41] Batch [1090]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090876,	
2017-06-28 18:43:23,204 Epoch[41] Batch [1100]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090865,	
2017-06-28 18:43:28,470 Epoch[41] Batch [1110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090909,	
2017-06-28 18:43:32,925 Epoch[41] Batch [1120]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090949,	
2017-06-28 18:43:37,404 Epoch[41] Batch [1130]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.090983,	
2017-06-28 18:43:42,131 Epoch[41] Batch [1140]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090954,	
2017-06-28 18:43:46,881 Epoch[41] Batch [1150]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090952,	
2017-06-28 18:43:51,844 Epoch[41] Batch [1160]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.090956,	
2017-06-28 18:43:56,689 Epoch[41] Batch [1170]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091025,	
2017-06-28 18:44:01,314 Epoch[41] Batch [1180]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091059,	
2017-06-28 18:44:05,993 Epoch[41] Batch [1190]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090990,	
2017-06-28 18:44:10,582 Epoch[41] Batch [1200]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091039,	
2017-06-28 18:44:15,679 Epoch[41] Batch [1210]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.091066,	
2017-06-28 18:44:20,339 Epoch[41] Batch [1220]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091087,	
2017-06-28 18:44:25,286 Epoch[41] Batch [1230]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.091081,	
2017-06-28 18:44:29,991 Epoch[41] Batch [1240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091037,	
2017-06-28 18:44:35,112 Epoch[41] Batch [1250]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.091073,	
2017-06-28 18:44:39,856 Epoch[41] Batch [1260]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.091059,	
2017-06-28 18:44:45,001 Epoch[41] Batch [1270]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.091135,	
2017-06-28 18:44:49,972 Epoch[41] Batch [1280]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.091096,	
2017-06-28 18:44:54,753 Epoch[41] Batch [1290]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.091119,	
2017-06-28 18:44:59,820 Epoch[41] Batch [1300]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.091193,	
2017-06-28 18:45:04,773 Epoch[41] Batch [1310]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.091194,	
2017-06-28 18:45:09,900 Epoch[41] Batch [1320]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.091140,	
2017-06-28 18:45:15,002 Epoch[41] Batch [1330]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.091106,	
2017-06-28 18:45:20,401 Epoch[41] Batch [1340]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091094,	
2017-06-28 18:45:25,287 Epoch[41] Batch [1350]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091043,	
2017-06-28 18:45:30,586 Epoch[41] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091026,	
2017-06-28 18:45:35,512 Epoch[41] Batch [1370]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.090987,	
2017-06-28 18:45:40,447 Epoch[41] Batch [1380]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090953,	
2017-06-28 18:45:45,091 Epoch[41] Batch [1390]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090986,	
2017-06-28 18:45:49,985 Epoch[41] Batch [1400]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.090979,	
2017-06-28 18:45:54,753 Epoch[41] Batch [1410]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090929,	
2017-06-28 18:45:59,537 Epoch[41] Batch [1420]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090903,	
2017-06-28 18:46:04,209 Epoch[41] Batch [1430]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090943,	
2017-06-28 18:46:09,350 Epoch[41] Batch [1440]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090989,	
2017-06-28 18:46:14,188 Epoch[41] Batch [1450]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.091003,	
2017-06-28 18:46:19,254 Epoch[41] Batch [1460]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090922,	
2017-06-28 18:46:23,964 Epoch[41] Batch [1470]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090915,	
2017-06-28 18:46:28,934 Epoch[41] Batch [1480]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.090862,	
2017-06-28 18:46:31,879 Epoch[41] Train-FCNLogLoss=0.090820
2017-06-28 18:46:31,879 Epoch[41] Time cost=729.046
2017-06-28 18:46:32,520 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0042.params"
2017-06-28 18:46:34,102 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0042.states"
2017-06-28 18:46:39,986 Epoch[42] Batch [10]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.085278,	
2017-06-28 18:46:44,875 Epoch[42] Batch [20]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086363,	
2017-06-28 18:46:50,255 Epoch[42] Batch [30]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.085581,	
2017-06-28 18:46:55,233 Epoch[42] Batch [40]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.086047,	
2017-06-28 18:47:00,506 Epoch[42] Batch [50]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087813,	
2017-06-28 18:47:05,403 Epoch[42] Batch [60]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088558,	
2017-06-28 18:47:10,518 Epoch[42] Batch [70]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089441,	
2017-06-28 18:47:15,606 Epoch[42] Batch [80]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089046,	
2017-06-28 18:47:20,908 Epoch[42] Batch [90]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090148,	
2017-06-28 18:47:26,226 Epoch[42] Batch [100]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091032,	
2017-06-28 18:47:31,672 Epoch[42] Batch [110]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091144,	
2017-06-28 18:47:36,707 Epoch[42] Batch [120]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090718,	
2017-06-28 18:47:41,963 Epoch[42] Batch [130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.091518,	
2017-06-28 18:47:46,986 Epoch[42] Batch [140]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.091995,	
2017-06-28 18:47:51,819 Epoch[42] Batch [150]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.091238,	
2017-06-28 18:47:56,651 Epoch[42] Batch [160]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.091754,	
2017-06-28 18:48:01,279 Epoch[42] Batch [170]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.092105,	
2017-06-28 18:48:05,707 Epoch[42] Batch [180]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.091804,	
2017-06-28 18:48:10,226 Epoch[42] Batch [190]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.091780,	
2017-06-28 18:48:14,783 Epoch[42] Batch [200]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092015,	
2017-06-28 18:48:19,387 Epoch[42] Batch [210]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092037,	
2017-06-28 18:48:24,219 Epoch[42] Batch [220]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092295,	
2017-06-28 18:48:29,105 Epoch[42] Batch [230]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091851,	
2017-06-28 18:48:34,186 Epoch[42] Batch [240]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.091676,	
2017-06-28 18:48:39,327 Epoch[42] Batch [250]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.092088,	
2017-06-28 18:48:44,076 Epoch[42] Batch [260]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092202,	
2017-06-28 18:48:48,734 Epoch[42] Batch [270]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091804,	
2017-06-28 18:48:54,028 Epoch[42] Batch [280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.091774,	
2017-06-28 18:48:59,364 Epoch[42] Batch [290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091660,	
2017-06-28 18:49:04,755 Epoch[42] Batch [300]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092019,	
2017-06-28 18:49:09,976 Epoch[42] Batch [310]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.091870,	
2017-06-28 18:49:14,816 Epoch[42] Batch [320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091744,	
2017-06-28 18:49:19,471 Epoch[42] Batch [330]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091895,	
2017-06-28 18:49:24,737 Epoch[42] Batch [340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091992,	
2017-06-28 18:49:29,877 Epoch[42] Batch [350]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.092188,	
2017-06-28 18:49:35,273 Epoch[42] Batch [360]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091931,	
2017-06-28 18:49:39,930 Epoch[42] Batch [370]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091828,	
2017-06-28 18:49:44,729 Epoch[42] Batch [380]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092072,	
2017-06-28 18:49:49,279 Epoch[42] Batch [390]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091986,	
2017-06-28 18:49:54,581 Epoch[42] Batch [400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091667,	
2017-06-28 18:49:59,591 Epoch[42] Batch [410]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.091536,	
2017-06-28 18:50:04,528 Epoch[42] Batch [420]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.091347,	
2017-06-28 18:50:09,905 Epoch[42] Batch [430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091310,	
2017-06-28 18:50:15,217 Epoch[42] Batch [440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091215,	
2017-06-28 18:50:20,695 Epoch[42] Batch [450]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.091176,	
2017-06-28 18:50:25,528 Epoch[42] Batch [460]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.091165,	
2017-06-28 18:50:30,672 Epoch[42] Batch [470]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090840,	
2017-06-28 18:50:35,963 Epoch[42] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090690,	
2017-06-28 18:50:41,275 Epoch[42] Batch [490]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090543,	
2017-06-28 18:50:46,198 Epoch[42] Batch [500]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090359,	
2017-06-28 18:50:51,110 Epoch[42] Batch [510]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.090231,	
2017-06-28 18:50:55,872 Epoch[42] Batch [520]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090259,	
2017-06-28 18:51:00,700 Epoch[42] Batch [530]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.090167,	
2017-06-28 18:51:05,760 Epoch[42] Batch [540]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090315,	
2017-06-28 18:51:10,991 Epoch[42] Batch [550]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090358,	
2017-06-28 18:51:16,105 Epoch[42] Batch [560]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.090458,	
2017-06-28 18:51:20,996 Epoch[42] Batch [570]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.090535,	
2017-06-28 18:51:26,687 Epoch[42] Batch [580]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.090449,	
2017-06-28 18:51:31,728 Epoch[42] Batch [590]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090434,	
2017-06-28 18:51:36,796 Epoch[42] Batch [600]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.090478,	
2017-06-28 18:51:41,628 Epoch[42] Batch [610]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.090519,	
2017-06-28 18:51:46,390 Epoch[42] Batch [620]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090632,	
2017-06-28 18:51:51,106 Epoch[42] Batch [630]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090559,	
2017-06-28 18:51:55,917 Epoch[42] Batch [640]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090496,	
2017-06-28 18:52:00,755 Epoch[42] Batch [650]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.090471,	
2017-06-28 18:52:05,962 Epoch[42] Batch [660]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090412,	
2017-06-28 18:52:11,111 Epoch[42] Batch [670]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.090352,	
2017-06-28 18:52:16,208 Epoch[42] Batch [680]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090312,	
2017-06-28 18:52:21,571 Epoch[42] Batch [690]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090304,	
2017-06-28 18:52:26,599 Epoch[42] Batch [700]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.090425,	
2017-06-28 18:52:31,508 Epoch[42] Batch [710]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.090384,	
2017-06-28 18:52:36,308 Epoch[42] Batch [720]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.090432,	
2017-06-28 18:52:41,304 Epoch[42] Batch [730]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.090551,	
2017-06-28 18:52:46,305 Epoch[42] Batch [740]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.090584,	
2017-06-28 18:52:51,335 Epoch[42] Batch [750]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.090420,	
2017-06-28 18:52:56,315 Epoch[42] Batch [760]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.090415,	
2017-06-28 18:53:01,083 Epoch[42] Batch [770]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090428,	
2017-06-28 18:53:06,007 Epoch[42] Batch [780]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.090426,	
2017-06-28 18:53:10,747 Epoch[42] Batch [790]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090301,	
2017-06-28 18:53:15,090 Epoch[42] Batch [800]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.090169,	
2017-06-28 18:53:19,956 Epoch[42] Batch [810]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090120,	
2017-06-28 18:53:24,485 Epoch[42] Batch [820]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090211,	
2017-06-28 18:53:29,063 Epoch[42] Batch [830]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090094,	
2017-06-28 18:53:33,577 Epoch[42] Batch [840]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090008,	
2017-06-28 18:53:38,654 Epoch[42] Batch [850]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.090025,	
2017-06-28 18:53:43,348 Epoch[42] Batch [860]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089981,	
2017-06-28 18:53:48,116 Epoch[42] Batch [870]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089974,	
2017-06-28 18:53:52,767 Epoch[42] Batch [880]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089853,	
2017-06-28 18:53:57,449 Epoch[42] Batch [890]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089766,	
2017-06-28 18:54:02,015 Epoch[42] Batch [900]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089797,	
2017-06-28 18:54:06,443 Epoch[42] Batch [910]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.089781,	
2017-06-28 18:54:10,782 Epoch[42] Batch [920]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.089715,	
2017-06-28 18:54:15,158 Epoch[42] Batch [930]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.089831,	
2017-06-28 18:54:19,683 Epoch[42] Batch [940]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089924,	
2017-06-28 18:54:24,423 Epoch[42] Batch [950]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090000,	
2017-06-28 18:54:29,057 Epoch[42] Batch [960]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089959,	
2017-06-28 18:54:33,727 Epoch[42] Batch [970]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090090,	
2017-06-28 18:54:38,609 Epoch[42] Batch [980]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.090066,	
2017-06-28 18:54:43,060 Epoch[42] Batch [990]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.090056,	
2017-06-28 18:54:48,000 Epoch[42] Batch [1000]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089980,	
2017-06-28 18:54:52,755 Epoch[42] Batch [1010]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090056,	
2017-06-28 18:54:57,375 Epoch[42] Batch [1020]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090080,	
2017-06-28 18:55:02,158 Epoch[42] Batch [1030]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090011,	
2017-06-28 18:55:06,567 Epoch[42] Batch [1040]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090058,	
2017-06-28 18:55:10,884 Epoch[42] Batch [1050]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.090034,	
2017-06-28 18:55:15,303 Epoch[42] Batch [1060]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.090053,	
2017-06-28 18:55:19,906 Epoch[42] Batch [1070]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089978,	
2017-06-28 18:55:24,260 Epoch[42] Batch [1080]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.089959,	
2017-06-28 18:55:28,639 Epoch[42] Batch [1090]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.089958,	
2017-06-28 18:55:33,037 Epoch[42] Batch [1100]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090021,	
2017-06-28 18:55:37,511 Epoch[42] Batch [1110]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090087,	
2017-06-28 18:55:41,686 Epoch[42] Batch [1120]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.090030,	
2017-06-28 18:55:46,101 Epoch[42] Batch [1130]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.090095,	
2017-06-28 18:55:50,576 Epoch[42] Batch [1140]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090152,	
2017-06-28 18:55:54,983 Epoch[42] Batch [1150]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090137,	
2017-06-28 18:55:59,372 Epoch[42] Batch [1160]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090112,	
2017-06-28 18:56:03,635 Epoch[42] Batch [1170]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.090104,	
2017-06-28 18:56:07,970 Epoch[42] Batch [1180]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.090035,	
2017-06-28 18:56:12,782 Epoch[42] Batch [1190]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.090072,	
2017-06-28 18:56:17,409 Epoch[42] Batch [1200]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.090055,	
2017-06-28 18:56:21,855 Epoch[42] Batch [1210]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090038,	
2017-06-28 18:56:26,518 Epoch[42] Batch [1220]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089997,	
2017-06-28 18:56:30,972 Epoch[42] Batch [1230]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089926,	
2017-06-28 18:56:35,700 Epoch[42] Batch [1240]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089967,	
2017-06-28 18:56:40,201 Epoch[42] Batch [1250]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089885,	
2017-06-28 18:56:44,780 Epoch[42] Batch [1260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089816,	
2017-06-28 18:56:49,076 Epoch[42] Batch [1270]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.089829,	
2017-06-28 18:56:53,361 Epoch[42] Batch [1280]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.089875,	
2017-06-28 18:56:58,001 Epoch[42] Batch [1290]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089849,	
2017-06-28 18:57:02,628 Epoch[42] Batch [1300]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089894,	
2017-06-28 18:57:07,345 Epoch[42] Batch [1310]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089967,	
2017-06-28 18:57:11,916 Epoch[42] Batch [1320]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090019,	
2017-06-28 18:57:16,363 Epoch[42] Batch [1330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090102,	
2017-06-28 18:57:21,104 Epoch[42] Batch [1340]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090117,	
2017-06-28 18:57:25,589 Epoch[42] Batch [1350]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.090160,	
2017-06-28 18:57:30,396 Epoch[42] Batch [1360]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090174,	
2017-06-28 18:57:35,110 Epoch[42] Batch [1370]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090243,	
2017-06-28 18:57:39,682 Epoch[42] Batch [1380]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090251,	
2017-06-28 18:57:44,443 Epoch[42] Batch [1390]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090259,	
2017-06-28 18:57:49,195 Epoch[42] Batch [1400]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090270,	
2017-06-28 18:57:53,798 Epoch[42] Batch [1410]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090295,	
2017-06-28 18:57:58,503 Epoch[42] Batch [1420]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090246,	
2017-06-28 18:58:02,939 Epoch[42] Batch [1430]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090228,	
2017-06-28 18:58:07,901 Epoch[42] Batch [1440]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.090242,	
2017-06-28 18:58:12,831 Epoch[42] Batch [1450]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090207,	
2017-06-28 18:58:17,436 Epoch[42] Batch [1460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090276,	
2017-06-28 18:58:22,044 Epoch[42] Batch [1470]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090283,	
2017-06-28 18:58:26,630 Epoch[42] Batch [1480]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.090300,	
2017-06-28 18:58:29,269 Epoch[42] Train-FCNLogLoss=0.090339
2017-06-28 18:58:29,270 Epoch[42] Time cost=715.168
2017-06-28 18:58:30,004 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0043.params"
2017-06-28 18:58:31,582 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0043.states"
2017-06-28 18:58:36,993 Epoch[43] Batch [10]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088977,	
2017-06-28 18:58:41,638 Epoch[43] Batch [20]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088955,	
2017-06-28 18:58:46,425 Epoch[43] Batch [30]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088061,	
2017-06-28 18:58:51,134 Epoch[43] Batch [40]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.086834,	
2017-06-28 18:58:55,586 Epoch[43] Batch [50]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087804,	
2017-06-28 18:59:00,022 Epoch[43] Batch [60]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088904,	
2017-06-28 18:59:04,793 Epoch[43] Batch [70]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088944,	
2017-06-28 18:59:09,412 Epoch[43] Batch [80]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088526,	
2017-06-28 18:59:13,751 Epoch[43] Batch [90]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-28 18:59:18,326 Epoch[43] Batch [100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088638,	
2017-06-28 18:59:22,758 Epoch[43] Batch [110]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088719,	
2017-06-28 18:59:27,411 Epoch[43] Batch [120]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089163,	
2017-06-28 18:59:32,258 Epoch[43] Batch [130]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089701,	
2017-06-28 18:59:37,081 Epoch[43] Batch [140]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090318,	
2017-06-28 18:59:42,268 Epoch[43] Batch [150]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090965,	
2017-06-28 18:59:46,920 Epoch[43] Batch [160]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090556,	
2017-06-28 18:59:51,805 Epoch[43] Batch [170]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.090241,	
2017-06-28 18:59:56,439 Epoch[43] Batch [180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090265,	
2017-06-28 19:00:00,654 Epoch[43] Batch [190]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.090077,	
2017-06-28 19:00:05,088 Epoch[43] Batch [200]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090568,	
2017-06-28 19:00:09,665 Epoch[43] Batch [210]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090397,	
2017-06-28 19:00:14,340 Epoch[43] Batch [220]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090100,	
2017-06-28 19:00:18,936 Epoch[43] Batch [230]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090002,	
2017-06-28 19:00:23,833 Epoch[43] Batch [240]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089933,	
2017-06-28 19:00:28,769 Epoch[43] Batch [250]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089891,	
2017-06-28 19:00:33,232 Epoch[43] Batch [260]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.089768,	
2017-06-28 19:00:37,859 Epoch[43] Batch [270]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089830,	
2017-06-28 19:00:42,732 Epoch[43] Batch [280]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089868,	
2017-06-28 19:00:47,192 Epoch[43] Batch [290]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.090005,	
2017-06-28 19:00:52,205 Epoch[43] Batch [300]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.090132,	
2017-06-28 19:00:56,757 Epoch[43] Batch [310]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090169,	
2017-06-28 19:01:01,439 Epoch[43] Batch [320]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090099,	
2017-06-28 19:01:06,130 Epoch[43] Batch [330]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090229,	
2017-06-28 19:01:10,483 Epoch[43] Batch [340]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.090078,	
2017-06-28 19:01:15,035 Epoch[43] Batch [350]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090040,	
2017-06-28 19:01:19,801 Epoch[43] Batch [360]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090066,	
2017-06-28 19:01:24,653 Epoch[43] Batch [370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090174,	
2017-06-28 19:01:29,440 Epoch[43] Batch [380]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090380,	
2017-06-28 19:01:34,706 Epoch[43] Batch [390]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090357,	
2017-06-28 19:01:39,986 Epoch[43] Batch [400]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090399,	
2017-06-28 19:01:45,135 Epoch[43] Batch [410]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.090419,	
2017-06-28 19:01:50,867 Epoch[43] Batch [420]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.090310,	
2017-06-28 19:01:55,799 Epoch[43] Batch [430]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090090,	
2017-06-28 19:02:01,165 Epoch[43] Batch [440]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090127,	
2017-06-28 19:02:06,766 Epoch[43] Batch [450]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.090392,	
2017-06-28 19:02:12,165 Epoch[43] Batch [460]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-28 19:02:17,660 Epoch[43] Batch [470]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090574,	
2017-06-28 19:02:22,867 Epoch[43] Batch [480]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090625,	
2017-06-28 19:02:27,980 Epoch[43] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.090651,	
2017-06-28 19:02:33,037 Epoch[43] Batch [500]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090513,	
2017-06-28 19:02:38,501 Epoch[43] Batch [510]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.090434,	
2017-06-28 19:02:43,856 Epoch[43] Batch [520]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090396,	
2017-06-28 19:02:48,920 Epoch[43] Batch [530]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090384,	
2017-06-28 19:02:53,766 Epoch[43] Batch [540]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090628,	
2017-06-28 19:02:58,932 Epoch[43] Batch [550]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090561,	
2017-06-28 19:03:03,708 Epoch[43] Batch [560]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.090583,	
2017-06-28 19:03:08,932 Epoch[43] Batch [570]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.090734,	
2017-06-28 19:03:13,836 Epoch[43] Batch [580]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.090682,	
2017-06-28 19:03:19,081 Epoch[43] Batch [590]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090727,	
2017-06-28 19:03:24,476 Epoch[43] Batch [600]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090707,	
2017-06-28 19:03:29,693 Epoch[43] Batch [610]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.090664,	
2017-06-28 19:03:35,200 Epoch[43] Batch [620]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.090621,	
2017-06-28 19:03:40,263 Epoch[43] Batch [630]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090509,	
2017-06-28 19:03:45,285 Epoch[43] Batch [640]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.090599,	
2017-06-28 19:03:50,470 Epoch[43] Batch [650]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090574,	
2017-06-28 19:03:55,814 Epoch[43] Batch [660]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090709,	
2017-06-28 19:04:01,064 Epoch[43] Batch [670]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090704,	
2017-06-28 19:04:06,245 Epoch[43] Batch [680]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.090669,	
2017-06-28 19:04:11,513 Epoch[43] Batch [690]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090624,	
2017-06-28 19:04:16,859 Epoch[43] Batch [700]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090679,	
2017-06-28 19:04:21,910 Epoch[43] Batch [710]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.090679,	
2017-06-28 19:04:27,386 Epoch[43] Batch [720]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.090810,	
2017-06-28 19:04:32,846 Epoch[43] Batch [730]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.090778,	
2017-06-28 19:04:38,105 Epoch[43] Batch [740]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090761,	
2017-06-28 19:04:43,081 Epoch[43] Batch [750]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.090839,	
2017-06-28 19:04:48,536 Epoch[43] Batch [760]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.090860,	
2017-06-28 19:04:53,296 Epoch[43] Batch [770]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090810,	
2017-06-28 19:04:58,456 Epoch[43] Batch [780]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090654,	
2017-06-28 19:05:03,501 Epoch[43] Batch [790]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.090625,	
2017-06-28 19:05:08,303 Epoch[43] Batch [800]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.090560,	
2017-06-28 19:05:13,339 Epoch[43] Batch [810]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090532,	
2017-06-28 19:05:18,291 Epoch[43] Batch [820]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.090432,	
2017-06-28 19:05:23,144 Epoch[43] Batch [830]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090283,	
2017-06-28 19:05:28,011 Epoch[43] Batch [840]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090221,	
2017-06-28 19:05:33,272 Epoch[43] Batch [850]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090183,	
2017-06-28 19:05:38,263 Epoch[43] Batch [860]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.090249,	
2017-06-28 19:05:43,510 Epoch[43] Batch [870]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090252,	
2017-06-28 19:05:48,237 Epoch[43] Batch [880]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090194,	
2017-06-28 19:05:53,474 Epoch[43] Batch [890]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.090102,	
2017-06-28 19:05:58,540 Epoch[43] Batch [900]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089949,	
2017-06-28 19:06:04,018 Epoch[43] Batch [910]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.090024,	
2017-06-28 19:06:09,299 Epoch[43] Batch [920]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090072,	
2017-06-28 19:06:14,885 Epoch[43] Batch [930]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.090098,	
2017-06-28 19:06:19,837 Epoch[43] Batch [940]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.090081,	
2017-06-28 19:06:25,082 Epoch[43] Batch [950]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089952,	
2017-06-28 19:06:29,939 Epoch[43] Batch [960]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090145,	
2017-06-28 19:06:34,500 Epoch[43] Batch [970]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090216,	
2017-06-28 19:06:39,622 Epoch[43] Batch [980]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090246,	
2017-06-28 19:06:44,163 Epoch[43] Batch [990]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090203,	
2017-06-28 19:06:49,467 Epoch[43] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090193,	
2017-06-28 19:06:54,492 Epoch[43] Batch [1010]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.090180,	
2017-06-28 19:06:59,879 Epoch[43] Batch [1020]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090231,	
2017-06-28 19:07:05,137 Epoch[43] Batch [1030]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090205,	
2017-06-28 19:07:10,706 Epoch[43] Batch [1040]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.090295,	
2017-06-28 19:07:15,925 Epoch[43] Batch [1050]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.090298,	
2017-06-28 19:07:20,935 Epoch[43] Batch [1060]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.090277,	
2017-06-28 19:07:25,824 Epoch[43] Batch [1070]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.090198,	
2017-06-28 19:07:30,860 Epoch[43] Batch [1080]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090180,	
2017-06-28 19:07:36,226 Epoch[43] Batch [1090]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090214,	
2017-06-28 19:07:41,324 Epoch[43] Batch [1100]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090235,	
2017-06-28 19:07:46,719 Epoch[43] Batch [1110]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090215,	
2017-06-28 19:07:52,132 Epoch[43] Batch [1120]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090267,	
2017-06-28 19:07:57,313 Epoch[43] Batch [1130]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090339,	
2017-06-28 19:08:02,326 Epoch[43] Batch [1140]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.090287,	
2017-06-28 19:08:07,991 Epoch[43] Batch [1150]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.090261,	
2017-06-28 19:08:13,211 Epoch[43] Batch [1160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.090308,	
2017-06-28 19:08:18,642 Epoch[43] Batch [1170]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090367,	
2017-06-28 19:08:24,107 Epoch[43] Batch [1180]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.090373,	
2017-06-28 19:08:29,142 Epoch[43] Batch [1190]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090429,	
2017-06-28 19:08:34,171 Epoch[43] Batch [1200]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.090399,	
2017-06-28 19:08:39,730 Epoch[43] Batch [1210]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.090435,	
2017-06-28 19:08:45,285 Epoch[43] Batch [1220]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.090426,	
2017-06-28 19:08:50,539 Epoch[43] Batch [1230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090410,	
2017-06-28 19:08:55,561 Epoch[43] Batch [1240]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.090463,	
2017-06-28 19:09:00,858 Epoch[43] Batch [1250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090442,	
2017-06-28 19:09:05,813 Epoch[43] Batch [1260]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.090468,	
2017-06-28 19:09:11,703 Epoch[43] Batch [1270]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.090456,	
2017-06-28 19:09:16,626 Epoch[43] Batch [1280]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090462,	
2017-06-28 19:09:22,564 Epoch[43] Batch [1290]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.090385,	
2017-06-28 19:09:27,697 Epoch[43] Batch [1300]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090407,	
2017-06-28 19:09:33,181 Epoch[43] Batch [1310]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.090438,	
2017-06-28 19:09:38,239 Epoch[43] Batch [1320]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090473,	
2017-06-28 19:09:43,267 Epoch[43] Batch [1330]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.090490,	
2017-06-28 19:09:48,509 Epoch[43] Batch [1340]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090510,	
2017-06-28 19:09:53,780 Epoch[43] Batch [1350]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090562,	
2017-06-28 19:09:59,089 Epoch[43] Batch [1360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090557,	
2017-06-28 19:10:04,628 Epoch[43] Batch [1370]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.090537,	
2017-06-28 19:10:10,054 Epoch[43] Batch [1380]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090566,	
2017-06-28 19:10:15,061 Epoch[43] Batch [1390]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.090566,	
2017-06-28 19:10:20,314 Epoch[43] Batch [1400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090570,	
2017-06-28 19:10:25,241 Epoch[43] Batch [1410]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.090600,	
2017-06-28 19:10:30,557 Epoch[43] Batch [1420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090588,	
2017-06-28 19:10:35,437 Epoch[43] Batch [1430]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090600,	
2017-06-28 19:10:40,978 Epoch[43] Batch [1440]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.090662,	
2017-06-28 19:10:46,175 Epoch[43] Batch [1450]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.090619,	
2017-06-28 19:10:51,386 Epoch[43] Batch [1460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090558,	
2017-06-28 19:10:56,320 Epoch[43] Batch [1470]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090592,	
2017-06-28 19:11:01,020 Epoch[43] Batch [1480]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090593,	
2017-06-28 19:11:03,921 Epoch[43] Train-FCNLogLoss=0.090615
2017-06-28 19:11:03,922 Epoch[43] Time cost=752.339
2017-06-28 19:11:04,545 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0044.params"
2017-06-28 19:11:06,045 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0044.states"
2017-06-28 19:11:11,621 Epoch[44] Batch [10]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093820,	
2017-06-28 19:11:16,458 Epoch[44] Batch [20]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.090007,	
2017-06-28 19:11:21,749 Epoch[44] Batch [30]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.085408,	
2017-06-28 19:11:27,215 Epoch[44] Batch [40]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.085469,	
2017-06-28 19:11:32,269 Epoch[44] Batch [50]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.085231,	
2017-06-28 19:11:37,219 Epoch[44] Batch [60]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087855,	
2017-06-28 19:11:42,385 Epoch[44] Batch [70]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086680,	
2017-06-28 19:11:47,723 Epoch[44] Batch [80]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086593,	
2017-06-28 19:11:52,686 Epoch[44] Batch [90]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086984,	
2017-06-28 19:11:57,981 Epoch[44] Batch [100]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-28 19:12:02,874 Epoch[44] Batch [110]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088127,	
2017-06-28 19:12:08,180 Epoch[44] Batch [120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088471,	
2017-06-28 19:12:13,331 Epoch[44] Batch [130]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-28 19:12:18,672 Epoch[44] Batch [140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088255,	
2017-06-28 19:12:24,100 Epoch[44] Batch [150]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.087988,	
2017-06-28 19:12:29,320 Epoch[44] Batch [160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088521,	
2017-06-28 19:12:34,437 Epoch[44] Batch [170]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088414,	
2017-06-28 19:12:39,332 Epoch[44] Batch [180]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-28 19:12:44,782 Epoch[44] Batch [190]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.089283,	
2017-06-28 19:12:49,896 Epoch[44] Batch [200]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089007,	
2017-06-28 19:12:54,922 Epoch[44] Batch [210]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089145,	
2017-06-28 19:12:59,990 Epoch[44] Batch [220]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.089369,	
2017-06-28 19:13:04,796 Epoch[44] Batch [230]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089418,	
2017-06-28 19:13:09,777 Epoch[44] Batch [240]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.089378,	
2017-06-28 19:13:14,802 Epoch[44] Batch [250]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089343,	
2017-06-28 19:13:19,637 Epoch[44] Batch [260]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089310,	
2017-06-28 19:13:24,841 Epoch[44] Batch [270]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089042,	
2017-06-28 19:13:30,083 Epoch[44] Batch [280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089072,	
2017-06-28 19:13:35,482 Epoch[44] Batch [290]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089219,	
2017-06-28 19:13:40,538 Epoch[44] Batch [300]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088816,	
2017-06-28 19:13:45,740 Epoch[44] Batch [310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-28 19:13:50,653 Epoch[44] Batch [320]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088922,	
2017-06-28 19:13:55,591 Epoch[44] Batch [330]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.088937,	
2017-06-28 19:14:01,009 Epoch[44] Batch [340]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.089254,	
2017-06-28 19:14:06,468 Epoch[44] Batch [350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089067,	
2017-06-28 19:14:11,805 Epoch[44] Batch [360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089368,	
2017-06-28 19:14:17,264 Epoch[44] Batch [370]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089208,	
2017-06-28 19:14:22,510 Epoch[44] Batch [380]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089025,	
2017-06-28 19:14:27,743 Epoch[44] Batch [390]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089187,	
2017-06-28 19:14:32,927 Epoch[44] Batch [400]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089164,	
2017-06-28 19:14:37,917 Epoch[44] Batch [410]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.089201,	
2017-06-28 19:14:42,356 Epoch[44] Batch [420]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.089231,	
2017-06-28 19:14:46,963 Epoch[44] Batch [430]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089296,	
2017-06-28 19:14:52,116 Epoch[44] Batch [440]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.089215,	
2017-06-28 19:14:57,119 Epoch[44] Batch [450]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089231,	
2017-06-28 19:15:02,156 Epoch[44] Batch [460]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.089388,	
2017-06-28 19:15:07,200 Epoch[44] Batch [470]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089449,	
2017-06-28 19:15:12,164 Epoch[44] Batch [480]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089278,	
2017-06-28 19:15:17,026 Epoch[44] Batch [490]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089279,	
2017-06-28 19:15:21,722 Epoch[44] Batch [500]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089172,	
2017-06-28 19:15:26,833 Epoch[44] Batch [510]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089180,	
2017-06-28 19:15:31,790 Epoch[44] Batch [520]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.089469,	
2017-06-28 19:15:36,870 Epoch[44] Batch [530]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089323,	
2017-06-28 19:15:41,756 Epoch[44] Batch [540]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.089261,	
2017-06-28 19:15:46,935 Epoch[44] Batch [550]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089195,	
2017-06-28 19:15:51,801 Epoch[44] Batch [560]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089130,	
2017-06-28 19:15:56,368 Epoch[44] Batch [570]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089065,	
2017-06-28 19:16:01,527 Epoch[44] Batch [580]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088966,	
2017-06-28 19:16:06,503 Epoch[44] Batch [590]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089082,	
2017-06-28 19:16:11,782 Epoch[44] Batch [600]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089099,	
2017-06-28 19:16:16,986 Epoch[44] Batch [610]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088998,	
2017-06-28 19:16:22,186 Epoch[44] Batch [620]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089129,	
2017-06-28 19:16:27,260 Epoch[44] Batch [630]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089124,	
2017-06-28 19:16:32,732 Epoch[44] Batch [640]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.089211,	
2017-06-28 19:16:37,862 Epoch[44] Batch [650]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.089273,	
2017-06-28 19:16:42,788 Epoch[44] Batch [660]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089245,	
2017-06-28 19:16:47,703 Epoch[44] Batch [670]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089395,	
2017-06-28 19:16:53,017 Epoch[44] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089326,	
2017-06-28 19:16:57,980 Epoch[44] Batch [690]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089291,	
2017-06-28 19:17:02,634 Epoch[44] Batch [700]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089267,	
2017-06-28 19:17:07,643 Epoch[44] Batch [710]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089253,	
2017-06-28 19:17:12,431 Epoch[44] Batch [720]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089332,	
2017-06-28 19:17:17,510 Epoch[44] Batch [730]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089342,	
2017-06-28 19:17:22,328 Epoch[44] Batch [740]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.089297,	
2017-06-28 19:17:27,522 Epoch[44] Batch [750]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089162,	
2017-06-28 19:17:32,492 Epoch[44] Batch [760]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089040,	
2017-06-28 19:17:38,190 Epoch[44] Batch [770]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.089129,	
2017-06-28 19:17:43,341 Epoch[44] Batch [780]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089274,	
2017-06-28 19:17:48,514 Epoch[44] Batch [790]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089238,	
2017-06-28 19:17:53,749 Epoch[44] Batch [800]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089212,	
2017-06-28 19:17:59,339 Epoch[44] Batch [810]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.089180,	
2017-06-28 19:18:04,464 Epoch[44] Batch [820]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.089219,	
2017-06-28 19:18:09,399 Epoch[44] Batch [830]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.089079,	
2017-06-28 19:18:14,961 Epoch[44] Batch [840]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.089019,	
2017-06-28 19:18:20,017 Epoch[44] Batch [850]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089002,	
2017-06-28 19:18:25,612 Epoch[44] Batch [860]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.088967,	
2017-06-28 19:18:30,758 Epoch[44] Batch [870]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089173,	
2017-06-28 19:18:35,570 Epoch[44] Batch [880]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.089283,	
2017-06-28 19:18:40,721 Epoch[44] Batch [890]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089228,	
2017-06-28 19:18:45,786 Epoch[44] Batch [900]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089190,	
2017-06-28 19:18:50,633 Epoch[44] Batch [910]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089112,	
2017-06-28 19:18:55,468 Epoch[44] Batch [920]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089011,	
2017-06-28 19:18:59,905 Epoch[44] Batch [930]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088934,	
2017-06-28 19:19:04,556 Epoch[44] Batch [940]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088879,	
2017-06-28 19:19:08,892 Epoch[44] Batch [950]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.088825,	
2017-06-28 19:19:13,995 Epoch[44] Batch [960]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088738,	
2017-06-28 19:19:19,171 Epoch[44] Batch [970]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088723,	
2017-06-28 19:19:23,956 Epoch[44] Batch [980]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-28 19:19:29,326 Epoch[44] Batch [990]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088633,	
2017-06-28 19:19:34,507 Epoch[44] Batch [1000]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088626,	
2017-06-28 19:19:39,519 Epoch[44] Batch [1010]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088686,	
2017-06-28 19:19:44,862 Epoch[44] Batch [1020]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088732,	
2017-06-28 19:19:49,736 Epoch[44] Batch [1030]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088706,	
2017-06-28 19:19:54,567 Epoch[44] Batch [1040]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088659,	
2017-06-28 19:19:59,708 Epoch[44] Batch [1050]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088712,	
2017-06-28 19:20:04,999 Epoch[44] Batch [1060]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-28 19:20:10,170 Epoch[44] Batch [1070]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.088681,	
2017-06-28 19:20:15,539 Epoch[44] Batch [1080]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088629,	
2017-06-28 19:20:20,895 Epoch[44] Batch [1090]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-28 19:20:26,124 Epoch[44] Batch [1100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-28 19:20:30,854 Epoch[44] Batch [1110]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088656,	
2017-06-28 19:20:35,926 Epoch[44] Batch [1120]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088641,	
2017-06-28 19:20:40,956 Epoch[44] Batch [1130]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-28 19:20:46,035 Epoch[44] Batch [1140]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088644,	
2017-06-28 19:20:51,359 Epoch[44] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088654,	
2017-06-28 19:20:56,736 Epoch[44] Batch [1160]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088679,	
2017-06-28 19:21:01,969 Epoch[44] Batch [1170]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-28 19:21:07,404 Epoch[44] Batch [1180]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-28 19:21:12,049 Epoch[44] Batch [1190]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088684,	
2017-06-28 19:21:16,714 Epoch[44] Batch [1200]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088663,	
2017-06-28 19:21:21,255 Epoch[44] Batch [1210]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088625,	
2017-06-28 19:21:25,797 Epoch[44] Batch [1220]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088623,	
2017-06-28 19:21:30,344 Epoch[44] Batch [1230]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088670,	
2017-06-28 19:21:35,027 Epoch[44] Batch [1240]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-28 19:21:39,452 Epoch[44] Batch [1250]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088735,	
2017-06-28 19:21:44,083 Epoch[44] Batch [1260]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-28 19:21:48,487 Epoch[44] Batch [1270]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.088742,	
2017-06-28 19:21:53,057 Epoch[44] Batch [1280]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-28 19:21:57,887 Epoch[44] Batch [1290]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-28 19:22:02,647 Epoch[44] Batch [1300]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088784,	
2017-06-28 19:22:07,720 Epoch[44] Batch [1310]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088690,	
2017-06-28 19:22:12,550 Epoch[44] Batch [1320]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-28 19:22:17,301 Epoch[44] Batch [1330]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088685,	
2017-06-28 19:22:22,301 Epoch[44] Batch [1340]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088719,	
2017-06-28 19:22:27,117 Epoch[44] Batch [1350]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088733,	
2017-06-28 19:22:31,995 Epoch[44] Batch [1360]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088735,	
2017-06-28 19:22:36,900 Epoch[44] Batch [1370]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088709,	
2017-06-28 19:22:41,585 Epoch[44] Batch [1380]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088778,	
2017-06-28 19:22:46,297 Epoch[44] Batch [1390]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088826,	
2017-06-28 19:22:51,033 Epoch[44] Batch [1400]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088842,	
2017-06-28 19:22:56,127 Epoch[44] Batch [1410]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088917,	
2017-06-28 19:23:00,788 Epoch[44] Batch [1420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088928,	
2017-06-28 19:23:05,640 Epoch[44] Batch [1430]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088876,	
2017-06-28 19:23:10,398 Epoch[44] Batch [1440]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088866,	
2017-06-28 19:23:15,109 Epoch[44] Batch [1450]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088874,	
2017-06-28 19:23:19,814 Epoch[44] Batch [1460]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088931,	
2017-06-28 19:23:24,380 Epoch[44] Batch [1470]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.088890,	
2017-06-28 19:23:29,268 Epoch[44] Batch [1480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088841,	
2017-06-28 19:23:32,155 Epoch[44] Train-FCNLogLoss=0.088882
2017-06-28 19:23:32,155 Epoch[44] Time cost=746.109
2017-06-28 19:23:32,829 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0045.params"
2017-06-28 19:23:34,446 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0045.states"
2017-06-28 19:23:39,990 Epoch[45] Batch [10]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.096090,	
2017-06-28 19:23:44,717 Epoch[45] Batch [20]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087896,	
2017-06-28 19:23:49,706 Epoch[45] Batch [30]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087003,	
2017-06-28 19:23:54,446 Epoch[45] Batch [40]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087721,	
2017-06-28 19:23:59,224 Epoch[45] Batch [50]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086160,	
2017-06-28 19:24:03,979 Epoch[45] Batch [60]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087097,	
2017-06-28 19:24:08,708 Epoch[45] Batch [70]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088025,	
2017-06-28 19:24:13,149 Epoch[45] Batch [80]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088299,	
2017-06-28 19:24:17,603 Epoch[45] Batch [90]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.088932,	
2017-06-28 19:24:22,153 Epoch[45] Batch [100]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088448,	
2017-06-28 19:24:27,186 Epoch[45] Batch [110]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087544,	
2017-06-28 19:24:31,873 Epoch[45] Batch [120]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.086837,	
2017-06-28 19:24:37,147 Epoch[45] Batch [130]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087712,	
2017-06-28 19:24:42,091 Epoch[45] Batch [140]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088397,	
2017-06-28 19:24:46,862 Epoch[45] Batch [150]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-28 19:24:51,402 Epoch[45] Batch [160]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088744,	
2017-06-28 19:24:56,134 Epoch[45] Batch [170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088819,	
2017-06-28 19:25:00,629 Epoch[45] Batch [180]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088739,	
2017-06-28 19:25:04,858 Epoch[45] Batch [190]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.089165,	
2017-06-28 19:25:09,191 Epoch[45] Batch [200]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.089619,	
2017-06-28 19:25:13,612 Epoch[45] Batch [210]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.089852,	
2017-06-28 19:25:18,134 Epoch[45] Batch [220]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.089436,	
2017-06-28 19:25:22,622 Epoch[45] Batch [230]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089581,	
2017-06-28 19:25:27,364 Epoch[45] Batch [240]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089761,	
2017-06-28 19:25:32,328 Epoch[45] Batch [250]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089767,	
2017-06-28 19:25:37,081 Epoch[45] Batch [260]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089889,	
2017-06-28 19:25:42,067 Epoch[45] Batch [270]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089625,	
2017-06-28 19:25:47,082 Epoch[45] Batch [280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089354,	
2017-06-28 19:25:51,922 Epoch[45] Batch [290]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089585,	
2017-06-28 19:25:56,643 Epoch[45] Batch [300]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089684,	
2017-06-28 19:26:01,451 Epoch[45] Batch [310]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089513,	
2017-06-28 19:26:06,013 Epoch[45] Batch [320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089305,	
2017-06-28 19:26:10,623 Epoch[45] Batch [330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089409,	
2017-06-28 19:26:15,518 Epoch[45] Batch [340]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089340,	
2017-06-28 19:26:20,019 Epoch[45] Batch [350]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089146,	
2017-06-28 19:26:25,108 Epoch[45] Batch [360]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089409,	
2017-06-28 19:26:30,034 Epoch[45] Batch [370]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089317,	
2017-06-28 19:26:34,871 Epoch[45] Batch [380]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089696,	
2017-06-28 19:26:39,434 Epoch[45] Batch [390]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089646,	
2017-06-28 19:26:44,117 Epoch[45] Batch [400]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089600,	
2017-06-28 19:26:48,707 Epoch[45] Batch [410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089547,	
2017-06-28 19:26:53,414 Epoch[45] Batch [420]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089514,	
2017-06-28 19:26:58,411 Epoch[45] Batch [430]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089585,	
2017-06-28 19:27:03,134 Epoch[45] Batch [440]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089664,	
2017-06-28 19:27:07,927 Epoch[45] Batch [450]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089817,	
2017-06-28 19:27:12,858 Epoch[45] Batch [460]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.089737,	
2017-06-28 19:27:17,673 Epoch[45] Batch [470]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.089699,	
2017-06-28 19:27:22,507 Epoch[45] Batch [480]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089719,	
2017-06-28 19:27:27,645 Epoch[45] Batch [490]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089589,	
2017-06-28 19:27:32,349 Epoch[45] Batch [500]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089502,	
2017-06-28 19:27:37,268 Epoch[45] Batch [510]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.089417,	
2017-06-28 19:27:42,444 Epoch[45] Batch [520]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089278,	
2017-06-28 19:27:47,641 Epoch[45] Batch [530]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089382,	
2017-06-28 19:27:52,284 Epoch[45] Batch [540]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-28 19:27:57,151 Epoch[45] Batch [550]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089370,	
2017-06-28 19:28:02,292 Epoch[45] Batch [560]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.089289,	
2017-06-28 19:28:07,015 Epoch[45] Batch [570]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089471,	
2017-06-28 19:28:11,842 Epoch[45] Batch [580]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089328,	
2017-06-28 19:28:16,783 Epoch[45] Batch [590]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089219,	
2017-06-28 19:28:21,760 Epoch[45] Batch [600]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089338,	
2017-06-28 19:28:26,709 Epoch[45] Batch [610]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089450,	
2017-06-28 19:28:31,257 Epoch[45] Batch [620]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089398,	
2017-06-28 19:28:36,001 Epoch[45] Batch [630]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089358,	
2017-06-28 19:28:40,407 Epoch[45] Batch [640]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.089312,	
2017-06-28 19:28:45,238 Epoch[45] Batch [650]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089366,	
2017-06-28 19:28:50,238 Epoch[45] Batch [660]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089388,	
2017-06-28 19:28:55,206 Epoch[45] Batch [670]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089351,	
2017-06-28 19:28:59,890 Epoch[45] Batch [680]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089301,	
2017-06-28 19:29:04,694 Epoch[45] Batch [690]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089249,	
2017-06-28 19:29:09,690 Epoch[45] Batch [700]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089328,	
2017-06-28 19:29:14,355 Epoch[45] Batch [710]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089360,	
2017-06-28 19:29:18,976 Epoch[45] Batch [720]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089436,	
2017-06-28 19:29:23,808 Epoch[45] Batch [730]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089422,	
2017-06-28 19:29:28,586 Epoch[45] Batch [740]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089407,	
2017-06-28 19:29:33,524 Epoch[45] Batch [750]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089464,	
2017-06-28 19:29:38,452 Epoch[45] Batch [760]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089355,	
2017-06-28 19:29:43,160 Epoch[45] Batch [770]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089264,	
2017-06-28 19:29:47,481 Epoch[45] Batch [780]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.089111,	
2017-06-28 19:29:51,878 Epoch[45] Batch [790]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089042,	
2017-06-28 19:29:56,485 Epoch[45] Batch [800]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089050,	
2017-06-28 19:30:00,920 Epoch[45] Batch [810]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088986,	
2017-06-28 19:30:05,521 Epoch[45] Batch [820]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089017,	
2017-06-28 19:30:09,991 Epoch[45] Batch [830]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.089028,	
2017-06-28 19:30:14,566 Epoch[45] Batch [840]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089053,	
2017-06-28 19:30:19,208 Epoch[45] Batch [850]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089023,	
2017-06-28 19:30:23,904 Epoch[45] Batch [860]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089117,	
2017-06-28 19:30:29,124 Epoch[45] Batch [870]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.089100,	
2017-06-28 19:30:33,993 Epoch[45] Batch [880]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089040,	
2017-06-28 19:30:38,903 Epoch[45] Batch [890]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089118,	
2017-06-28 19:30:43,795 Epoch[45] Batch [900]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.089117,	
2017-06-28 19:30:48,819 Epoch[45] Batch [910]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089084,	
2017-06-28 19:30:53,221 Epoch[45] Batch [920]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089145,	
2017-06-28 19:30:58,295 Epoch[45] Batch [930]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089259,	
2017-06-28 19:31:03,172 Epoch[45] Batch [940]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089354,	
2017-06-28 19:31:08,117 Epoch[45] Batch [950]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.089396,	
2017-06-28 19:31:12,998 Epoch[45] Batch [960]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.089458,	
2017-06-28 19:31:18,185 Epoch[45] Batch [970]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089392,	
2017-06-28 19:31:22,702 Epoch[45] Batch [980]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089380,	
2017-06-28 19:31:27,215 Epoch[45] Batch [990]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089484,	
2017-06-28 19:31:31,858 Epoch[45] Batch [1000]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089500,	
2017-06-28 19:31:36,443 Epoch[45] Batch [1010]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.089474,	
2017-06-28 19:31:41,293 Epoch[45] Batch [1020]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089433,	
2017-06-28 19:31:45,963 Epoch[45] Batch [1030]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089424,	
2017-06-28 19:31:50,881 Epoch[45] Batch [1040]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.089414,	
2017-06-28 19:31:56,394 Epoch[45] Batch [1050]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.089352,	
2017-06-28 19:32:01,641 Epoch[45] Batch [1060]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089348,	
2017-06-28 19:32:06,973 Epoch[45] Batch [1070]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-28 19:32:11,844 Epoch[45] Batch [1080]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.089316,	
2017-06-28 19:32:16,689 Epoch[45] Batch [1090]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.089335,	
2017-06-28 19:32:21,751 Epoch[45] Batch [1100]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089359,	
2017-06-28 19:32:26,518 Epoch[45] Batch [1110]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089400,	
2017-06-28 19:32:31,115 Epoch[45] Batch [1120]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089342,	
2017-06-28 19:32:35,853 Epoch[45] Batch [1130]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089410,	
2017-06-28 19:32:40,607 Epoch[45] Batch [1140]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089386,	
2017-06-28 19:32:46,107 Epoch[45] Batch [1150]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.089423,	
2017-06-28 19:32:51,013 Epoch[45] Batch [1160]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089394,	
2017-06-28 19:32:56,403 Epoch[45] Batch [1170]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089437,	
2017-06-28 19:33:01,461 Epoch[45] Batch [1180]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089406,	
2017-06-28 19:33:07,231 Epoch[45] Batch [1190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.089444,	
2017-06-28 19:33:12,495 Epoch[45] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089487,	
2017-06-28 19:33:17,791 Epoch[45] Batch [1210]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089511,	
2017-06-28 19:33:22,970 Epoch[45] Batch [1220]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089538,	
2017-06-28 19:33:28,292 Epoch[45] Batch [1230]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089549,	
2017-06-28 19:33:33,216 Epoch[45] Batch [1240]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089546,	
2017-06-28 19:33:38,295 Epoch[45] Batch [1250]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089518,	
2017-06-28 19:33:43,478 Epoch[45] Batch [1260]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089507,	
2017-06-28 19:33:48,120 Epoch[45] Batch [1270]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089554,	
2017-06-28 19:33:53,279 Epoch[45] Batch [1280]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089546,	
2017-06-28 19:33:58,194 Epoch[45] Batch [1290]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089533,	
2017-06-28 19:34:03,373 Epoch[45] Batch [1300]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089601,	
2017-06-28 19:34:08,118 Epoch[45] Batch [1310]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089623,	
2017-06-28 19:34:13,643 Epoch[45] Batch [1320]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.089628,	
2017-06-28 19:34:18,114 Epoch[45] Batch [1330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.089553,	
2017-06-28 19:34:22,881 Epoch[45] Batch [1340]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089568,	
2017-06-28 19:34:27,872 Epoch[45] Batch [1350]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089531,	
2017-06-28 19:34:32,831 Epoch[45] Batch [1360]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.089579,	
2017-06-28 19:34:37,838 Epoch[45] Batch [1370]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089613,	
2017-06-28 19:34:43,009 Epoch[45] Batch [1380]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.089638,	
2017-06-28 19:34:47,962 Epoch[45] Batch [1390]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089581,	
2017-06-28 19:34:52,935 Epoch[45] Batch [1400]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089600,	
2017-06-28 19:34:57,897 Epoch[45] Batch [1410]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089596,	
2017-06-28 19:35:02,873 Epoch[45] Batch [1420]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089600,	
2017-06-28 19:35:07,528 Epoch[45] Batch [1430]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089564,	
2017-06-28 19:35:12,430 Epoch[45] Batch [1440]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089522,	
2017-06-28 19:35:17,333 Epoch[45] Batch [1450]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089509,	
2017-06-28 19:35:21,990 Epoch[45] Batch [1460]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089533,	
2017-06-28 19:35:27,677 Epoch[45] Batch [1470]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.089556,	
2017-06-28 19:35:33,168 Epoch[45] Batch [1480]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.089545,	
2017-06-28 19:35:36,723 Epoch[45] Train-FCNLogLoss=0.089595
2017-06-28 19:35:36,724 Epoch[45] Time cost=722.277
2017-06-28 19:35:37,373 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0046.params"
2017-06-28 19:35:38,817 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0046.states"
2017-06-28 19:35:44,499 Epoch[46] Batch [10]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.092040,	
2017-06-28 19:35:49,784 Epoch[46] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.091479,	
2017-06-28 19:35:54,787 Epoch[46] Batch [30]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.090442,	
2017-06-28 19:36:00,639 Epoch[46] Batch [40]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.091152,	
2017-06-28 19:36:06,066 Epoch[46] Batch [50]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090790,	
2017-06-28 19:36:11,417 Epoch[46] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092881,	
2017-06-28 19:36:16,864 Epoch[46] Batch [70]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092082,	
2017-06-28 19:36:21,863 Epoch[46] Batch [80]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.091664,	
2017-06-28 19:36:26,974 Epoch[46] Batch [90]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089498,	
2017-06-28 19:36:31,734 Epoch[46] Batch [100]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089372,	
2017-06-28 19:36:36,506 Epoch[46] Batch [110]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089127,	
2017-06-28 19:36:41,594 Epoch[46] Batch [120]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089723,	
2017-06-28 19:36:46,633 Epoch[46] Batch [130]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088973,	
2017-06-28 19:36:51,957 Epoch[46] Batch [140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090120,	
2017-06-28 19:36:56,849 Epoch[46] Batch [150]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.090324,	
2017-06-28 19:37:01,989 Epoch[46] Batch [160]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090352,	
2017-06-28 19:37:07,243 Epoch[46] Batch [170]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090253,	
2017-06-28 19:37:12,798 Epoch[46] Batch [180]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.090068,	
2017-06-28 19:37:17,666 Epoch[46] Batch [190]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-28 19:37:23,316 Epoch[46] Batch [200]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.089699,	
2017-06-28 19:37:28,621 Epoch[46] Batch [210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089493,	
2017-06-28 19:37:33,764 Epoch[46] Batch [220]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.089290,	
2017-06-28 19:37:39,251 Epoch[46] Batch [230]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.089085,	
2017-06-28 19:37:44,394 Epoch[46] Batch [240]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.089416,	
2017-06-28 19:37:49,630 Epoch[46] Batch [250]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089499,	
2017-06-28 19:37:54,837 Epoch[46] Batch [260]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.089399,	
2017-06-28 19:38:00,350 Epoch[46] Batch [270]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.089438,	
2017-06-28 19:38:05,554 Epoch[46] Batch [280]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.090013,	
2017-06-28 19:38:11,014 Epoch[46] Batch [290]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.090147,	
2017-06-28 19:38:16,350 Epoch[46] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090065,	
2017-06-28 19:38:21,325 Epoch[46] Batch [310]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.090115,	
2017-06-28 19:38:26,822 Epoch[46] Batch [320]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090085,	
2017-06-28 19:38:31,778 Epoch[46] Batch [330]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.090337,	
2017-06-28 19:38:36,990 Epoch[46] Batch [340]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.090217,	
2017-06-28 19:38:41,970 Epoch[46] Batch [350]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.090091,	
2017-06-28 19:38:47,635 Epoch[46] Batch [360]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.090075,	
2017-06-28 19:38:52,672 Epoch[46] Batch [370]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090158,	
2017-06-28 19:38:58,271 Epoch[46] Batch [380]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.090145,	
2017-06-28 19:39:03,669 Epoch[46] Batch [390]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090086,	
2017-06-28 19:39:09,049 Epoch[46] Batch [400]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090146,	
2017-06-28 19:39:14,526 Epoch[46] Batch [410]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.090236,	
2017-06-28 19:39:19,406 Epoch[46] Batch [420]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090044,	
2017-06-28 19:39:24,336 Epoch[46] Batch [430]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.089816,	
2017-06-28 19:39:28,743 Epoch[46] Batch [440]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090070,	
2017-06-28 19:39:33,499 Epoch[46] Batch [450]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089972,	
2017-06-28 19:39:38,257 Epoch[46] Batch [460]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089946,	
2017-06-28 19:39:43,094 Epoch[46] Batch [470]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089949,	
2017-06-28 19:39:47,969 Epoch[46] Batch [480]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089731,	
2017-06-28 19:39:52,803 Epoch[46] Batch [490]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089700,	
2017-06-28 19:39:57,889 Epoch[46] Batch [500]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089676,	
2017-06-28 19:40:02,882 Epoch[46] Batch [510]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089675,	
2017-06-28 19:40:08,220 Epoch[46] Batch [520]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089713,	
2017-06-28 19:40:13,551 Epoch[46] Batch [530]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089655,	
2017-06-28 19:40:19,032 Epoch[46] Batch [540]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089742,	
2017-06-28 19:40:24,659 Epoch[46] Batch [550]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.089849,	
2017-06-28 19:40:29,680 Epoch[46] Batch [560]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089768,	
2017-06-28 19:40:35,384 Epoch[46] Batch [570]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.089728,	
2017-06-28 19:40:40,656 Epoch[46] Batch [580]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089755,	
2017-06-28 19:40:45,981 Epoch[46] Batch [590]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089787,	
2017-06-28 19:40:51,143 Epoch[46] Batch [600]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089707,	
2017-06-28 19:40:56,666 Epoch[46] Batch [610]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.089565,	
2017-06-28 19:41:01,578 Epoch[46] Batch [620]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089568,	
2017-06-28 19:41:06,696 Epoch[46] Batch [630]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089520,	
2017-06-28 19:41:11,603 Epoch[46] Batch [640]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089390,	
2017-06-28 19:41:16,410 Epoch[46] Batch [650]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089426,	
2017-06-28 19:41:21,006 Epoch[46] Batch [660]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089433,	
2017-06-28 19:41:25,965 Epoch[46] Batch [670]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.089421,	
2017-06-28 19:41:30,750 Epoch[46] Batch [680]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-28 19:41:36,025 Epoch[46] Batch [690]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089261,	
2017-06-28 19:41:40,926 Epoch[46] Batch [700]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089238,	
2017-06-28 19:41:46,425 Epoch[46] Batch [710]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.089162,	
2017-06-28 19:41:51,481 Epoch[46] Batch [720]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089256,	
2017-06-28 19:41:57,145 Epoch[46] Batch [730]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089294,	
2017-06-28 19:42:02,230 Epoch[46] Batch [740]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089287,	
2017-06-28 19:42:08,122 Epoch[46] Batch [750]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.089391,	
2017-06-28 19:42:13,107 Epoch[46] Batch [760]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089558,	
2017-06-28 19:42:18,592 Epoch[46] Batch [770]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.089656,	
2017-06-28 19:42:23,653 Epoch[46] Batch [780]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089694,	
2017-06-28 19:42:27,740 Epoch[46] Batch [790]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.089679,	
2017-06-28 19:42:31,970 Epoch[46] Batch [800]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.089797,	
2017-06-28 19:42:36,711 Epoch[46] Batch [810]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089738,	
2017-06-28 19:42:41,883 Epoch[46] Batch [820]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089738,	
2017-06-28 19:42:47,215 Epoch[46] Batch [830]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089735,	
2017-06-28 19:42:52,911 Epoch[46] Batch [840]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.089829,	
2017-06-28 19:42:58,427 Epoch[46] Batch [850]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.089824,	
2017-06-28 19:43:03,480 Epoch[46] Batch [860]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089777,	
2017-06-28 19:43:08,565 Epoch[46] Batch [870]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089673,	
2017-06-28 19:43:13,530 Epoch[46] Batch [880]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089780,	
2017-06-28 19:43:18,480 Epoch[46] Batch [890]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089699,	
2017-06-28 19:43:23,541 Epoch[46] Batch [900]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089715,	
2017-06-28 19:43:28,607 Epoch[46] Batch [910]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089711,	
2017-06-28 19:43:33,713 Epoch[46] Batch [920]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089697,	
2017-06-28 19:43:38,430 Epoch[46] Batch [930]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089605,	
2017-06-28 19:43:43,848 Epoch[46] Batch [940]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.089620,	
2017-06-28 19:43:48,742 Epoch[46] Batch [950]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089594,	
2017-06-28 19:43:53,892 Epoch[46] Batch [960]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089623,	
2017-06-28 19:43:59,174 Epoch[46] Batch [970]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089586,	
2017-06-28 19:44:04,471 Epoch[46] Batch [980]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089622,	
2017-06-28 19:44:09,821 Epoch[46] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089624,	
2017-06-28 19:44:15,483 Epoch[46] Batch [1000]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089582,	
2017-06-28 19:44:20,382 Epoch[46] Batch [1010]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089579,	
2017-06-28 19:44:25,650 Epoch[46] Batch [1020]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089581,	
2017-06-28 19:44:30,948 Epoch[46] Batch [1030]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089547,	
2017-06-28 19:44:36,265 Epoch[46] Batch [1040]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089554,	
2017-06-28 19:44:41,941 Epoch[46] Batch [1050]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.089543,	
2017-06-28 19:44:47,395 Epoch[46] Batch [1060]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089618,	
2017-06-28 19:44:52,619 Epoch[46] Batch [1070]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.089617,	
2017-06-28 19:44:58,020 Epoch[46] Batch [1080]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089635,	
2017-06-28 19:45:03,498 Epoch[46] Batch [1090]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089639,	
2017-06-28 19:45:08,483 Epoch[46] Batch [1100]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089660,	
2017-06-28 19:45:14,123 Epoch[46] Batch [1110]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.089717,	
2017-06-28 19:45:19,151 Epoch[46] Batch [1120]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089735,	
2017-06-28 19:45:24,406 Epoch[46] Batch [1130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089767,	
2017-06-28 19:45:29,648 Epoch[46] Batch [1140]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089771,	
2017-06-28 19:45:35,119 Epoch[46] Batch [1150]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.089775,	
2017-06-28 19:45:40,572 Epoch[46] Batch [1160]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089676,	
2017-06-28 19:45:45,776 Epoch[46] Batch [1170]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089622,	
2017-06-28 19:45:51,061 Epoch[46] Batch [1180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089578,	
2017-06-28 19:45:56,011 Epoch[46] Batch [1190]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089581,	
2017-06-28 19:46:01,262 Epoch[46] Batch [1200]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089553,	
2017-06-28 19:46:06,485 Epoch[46] Batch [1210]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.089610,	
2017-06-28 19:46:12,015 Epoch[46] Batch [1220]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.089560,	
2017-06-28 19:46:17,589 Epoch[46] Batch [1230]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.089493,	
2017-06-28 19:46:23,306 Epoch[46] Batch [1240]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.089482,	
2017-06-28 19:46:28,322 Epoch[46] Batch [1250]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-28 19:46:33,497 Epoch[46] Batch [1260]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089434,	
2017-06-28 19:46:38,464 Epoch[46] Batch [1270]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089457,	
2017-06-28 19:46:43,886 Epoch[46] Batch [1280]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.089545,	
2017-06-28 19:46:49,261 Epoch[46] Batch [1290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089593,	
2017-06-28 19:46:54,380 Epoch[46] Batch [1300]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089542,	
2017-06-28 19:46:59,917 Epoch[46] Batch [1310]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.089578,	
2017-06-28 19:47:05,276 Epoch[46] Batch [1320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089445,	
2017-06-28 19:47:10,780 Epoch[46] Batch [1330]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.089486,	
2017-06-28 19:47:16,111 Epoch[46] Batch [1340]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089376,	
2017-06-28 19:47:21,488 Epoch[46] Batch [1350]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089331,	
2017-06-28 19:47:26,937 Epoch[46] Batch [1360]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.089420,	
2017-06-28 19:47:32,363 Epoch[46] Batch [1370]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089448,	
2017-06-28 19:47:37,693 Epoch[46] Batch [1380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089465,	
2017-06-28 19:47:42,861 Epoch[46] Batch [1390]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.089429,	
2017-06-28 19:47:48,526 Epoch[46] Batch [1400]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089385,	
2017-06-28 19:47:54,094 Epoch[46] Batch [1410]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.089365,	
2017-06-28 19:47:59,658 Epoch[46] Batch [1420]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.089343,	
2017-06-28 19:48:04,985 Epoch[46] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089392,	
2017-06-28 19:48:10,558 Epoch[46] Batch [1440]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.089326,	
2017-06-28 19:48:15,933 Epoch[46] Batch [1450]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089338,	
2017-06-28 19:48:21,020 Epoch[46] Batch [1460]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089339,	
2017-06-28 19:48:26,321 Epoch[46] Batch [1470]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089342,	
2017-06-28 19:48:31,335 Epoch[46] Batch [1480]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089351,	
2017-06-28 19:48:34,207 Epoch[46] Train-FCNLogLoss=0.089325
2017-06-28 19:48:34,207 Epoch[46] Time cost=775.390
2017-06-28 19:48:34,895 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0047.params"
2017-06-28 19:48:36,375 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0047.states"
2017-06-28 19:48:42,421 Epoch[47] Batch [10]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086631,	
2017-06-28 19:48:47,629 Epoch[47] Batch [20]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.091493,	
2017-06-28 19:48:52,919 Epoch[47] Batch [30]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090666,	
2017-06-28 19:48:58,303 Epoch[47] Batch [40]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090568,	
2017-06-28 19:49:03,426 Epoch[47] Batch [50]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090688,	
2017-06-28 19:49:08,200 Epoch[47] Batch [60]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.090278,	
2017-06-28 19:49:12,946 Epoch[47] Batch [70]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090195,	
2017-06-28 19:49:17,408 Epoch[47] Batch [80]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.088810,	
2017-06-28 19:49:22,260 Epoch[47] Batch [90]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-28 19:49:26,864 Epoch[47] Batch [100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089688,	
2017-06-28 19:49:31,726 Epoch[47] Batch [110]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089401,	
2017-06-28 19:49:36,626 Epoch[47] Batch [120]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089791,	
2017-06-28 19:49:41,536 Epoch[47] Batch [130]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089290,	
2017-06-28 19:49:46,827 Epoch[47] Batch [140]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090060,	
2017-06-28 19:49:51,884 Epoch[47] Batch [150]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-28 19:49:56,926 Epoch[47] Batch [160]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.090273,	
2017-06-28 19:50:01,937 Epoch[47] Batch [170]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089816,	
2017-06-28 19:50:06,928 Epoch[47] Batch [180]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089884,	
2017-06-28 19:50:11,658 Epoch[47] Batch [190]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089429,	
2017-06-28 19:50:16,384 Epoch[47] Batch [200]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088749,	
2017-06-28 19:50:20,910 Epoch[47] Batch [210]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088508,	
2017-06-28 19:50:25,659 Epoch[47] Batch [220]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088874,	
2017-06-28 19:50:30,229 Epoch[47] Batch [230]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088848,	
2017-06-28 19:50:35,338 Epoch[47] Batch [240]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088837,	
2017-06-28 19:50:40,344 Epoch[47] Batch [250]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088803,	
2017-06-28 19:50:45,458 Epoch[47] Batch [260]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088836,	
2017-06-28 19:50:50,384 Epoch[47] Batch [270]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089095,	
2017-06-28 19:50:55,380 Epoch[47] Batch [280]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088970,	
2017-06-28 19:51:00,643 Epoch[47] Batch [290]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089011,	
2017-06-28 19:51:05,750 Epoch[47] Batch [300]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089191,	
2017-06-28 19:51:10,953 Epoch[47] Batch [310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089145,	
2017-06-28 19:51:15,721 Epoch[47] Batch [320]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089068,	
2017-06-28 19:51:21,043 Epoch[47] Batch [330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088997,	
2017-06-28 19:51:26,260 Epoch[47] Batch [340]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.089339,	
2017-06-28 19:51:31,245 Epoch[47] Batch [350]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089318,	
2017-06-28 19:51:36,640 Epoch[47] Batch [360]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089229,	
2017-06-28 19:51:41,778 Epoch[47] Batch [370]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089259,	
2017-06-28 19:51:46,948 Epoch[47] Batch [380]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.089327,	
2017-06-28 19:51:51,971 Epoch[47] Batch [390]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089249,	
2017-06-28 19:51:57,281 Epoch[47] Batch [400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089239,	
2017-06-28 19:52:02,303 Epoch[47] Batch [410]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089116,	
2017-06-28 19:52:07,200 Epoch[47] Batch [420]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089035,	
2017-06-28 19:52:12,103 Epoch[47] Batch [430]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088887,	
2017-06-28 19:52:16,746 Epoch[47] Batch [440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089024,	
2017-06-28 19:52:21,818 Epoch[47] Batch [450]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.089049,	
2017-06-28 19:52:26,203 Epoch[47] Batch [460]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.089158,	
2017-06-28 19:52:30,781 Epoch[47] Batch [470]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089074,	
2017-06-28 19:52:35,497 Epoch[47] Batch [480]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089068,	
2017-06-28 19:52:40,307 Epoch[47] Batch [490]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089286,	
2017-06-28 19:52:44,950 Epoch[47] Batch [500]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089424,	
2017-06-28 19:52:49,991 Epoch[47] Batch [510]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.089361,	
2017-06-28 19:52:55,257 Epoch[47] Batch [520]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089210,	
2017-06-28 19:53:00,197 Epoch[47] Batch [530]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089015,	
2017-06-28 19:53:05,627 Epoch[47] Batch [540]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089092,	
2017-06-28 19:53:10,662 Epoch[47] Batch [550]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.089087,	
2017-06-28 19:53:15,639 Epoch[47] Batch [560]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088923,	
2017-06-28 19:53:20,460 Epoch[47] Batch [570]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088915,	
2017-06-28 19:53:25,260 Epoch[47] Batch [580]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088792,	
2017-06-28 19:53:30,202 Epoch[47] Batch [590]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.089041,	
2017-06-28 19:53:35,195 Epoch[47] Batch [600]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089121,	
2017-06-28 19:53:40,166 Epoch[47] Batch [610]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089024,	
2017-06-28 19:53:44,928 Epoch[47] Batch [620]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088983,	
2017-06-28 19:53:49,708 Epoch[47] Batch [630]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089073,	
2017-06-28 19:53:54,733 Epoch[47] Batch [640]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089104,	
2017-06-28 19:53:59,707 Epoch[47] Batch [650]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089046,	
2017-06-28 19:54:04,615 Epoch[47] Batch [660]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089092,	
2017-06-28 19:54:09,604 Epoch[47] Batch [670]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089142,	
2017-06-28 19:54:14,706 Epoch[47] Batch [680]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.089166,	
2017-06-28 19:54:19,940 Epoch[47] Batch [690]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089215,	
2017-06-28 19:54:24,786 Epoch[47] Batch [700]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.089216,	
2017-06-28 19:54:29,913 Epoch[47] Batch [710]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.089159,	
2017-06-28 19:54:35,307 Epoch[47] Batch [720]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089105,	
2017-06-28 19:54:40,084 Epoch[47] Batch [730]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089126,	
2017-06-28 19:54:44,887 Epoch[47] Batch [740]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089227,	
2017-06-28 19:54:49,798 Epoch[47] Batch [750]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089318,	
2017-06-28 19:54:54,812 Epoch[47] Batch [760]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089337,	
2017-06-28 19:54:59,688 Epoch[47] Batch [770]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089391,	
2017-06-28 19:55:04,483 Epoch[47] Batch [780]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089327,	
2017-06-28 19:55:08,929 Epoch[47] Batch [790]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.089297,	
2017-06-28 19:55:13,835 Epoch[47] Batch [800]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089192,	
2017-06-28 19:55:19,038 Epoch[47] Batch [810]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089161,	
2017-06-28 19:55:24,032 Epoch[47] Batch [820]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.089202,	
2017-06-28 19:55:29,191 Epoch[47] Batch [830]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089140,	
2017-06-28 19:55:34,059 Epoch[47] Batch [840]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089208,	
2017-06-28 19:55:39,387 Epoch[47] Batch [850]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-28 19:55:44,472 Epoch[47] Batch [860]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089164,	
2017-06-28 19:55:49,310 Epoch[47] Batch [870]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089146,	
2017-06-28 19:55:54,713 Epoch[47] Batch [880]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089145,	
2017-06-28 19:55:59,735 Epoch[47] Batch [890]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089186,	
2017-06-28 19:56:04,929 Epoch[47] Batch [900]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089170,	
2017-06-28 19:56:09,747 Epoch[47] Batch [910]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.089086,	
2017-06-28 19:56:14,873 Epoch[47] Batch [920]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.089209,	
2017-06-28 19:56:20,045 Epoch[47] Batch [930]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089162,	
2017-06-28 19:56:25,279 Epoch[47] Batch [940]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089177,	
2017-06-28 19:56:30,396 Epoch[47] Batch [950]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089164,	
2017-06-28 19:56:35,653 Epoch[47] Batch [960]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089103,	
2017-06-28 19:56:40,606 Epoch[47] Batch [970]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089072,	
2017-06-28 19:56:44,982 Epoch[47] Batch [980]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.089070,	
2017-06-28 19:56:49,673 Epoch[47] Batch [990]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089033,	
2017-06-28 19:56:54,638 Epoch[47] Batch [1000]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089028,	
2017-06-28 19:56:59,539 Epoch[47] Batch [1010]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089036,	
2017-06-28 19:57:04,174 Epoch[47] Batch [1020]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089059,	
2017-06-28 19:57:08,767 Epoch[47] Batch [1030]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089058,	
2017-06-28 19:57:13,497 Epoch[47] Batch [1040]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089150,	
2017-06-28 19:57:17,855 Epoch[47] Batch [1050]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089080,	
2017-06-28 19:57:22,656 Epoch[47] Batch [1060]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089013,	
2017-06-28 19:57:27,650 Epoch[47] Batch [1070]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089073,	
2017-06-28 19:57:32,432 Epoch[47] Batch [1080]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089034,	
2017-06-28 19:57:37,015 Epoch[47] Batch [1090]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.088952,	
2017-06-28 19:57:41,748 Epoch[47] Batch [1100]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088918,	
2017-06-28 19:57:46,878 Epoch[47] Batch [1110]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088965,	
2017-06-28 19:57:51,827 Epoch[47] Batch [1120]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088982,	
2017-06-28 19:57:56,802 Epoch[47] Batch [1130]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088981,	
2017-06-28 19:58:01,987 Epoch[47] Batch [1140]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088994,	
2017-06-28 19:58:07,503 Epoch[47] Batch [1150]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.089060,	
2017-06-28 19:58:12,566 Epoch[47] Batch [1160]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089079,	
2017-06-28 19:58:17,321 Epoch[47] Batch [1170]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089038,	
2017-06-28 19:58:22,342 Epoch[47] Batch [1180]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088970,	
2017-06-28 19:58:27,310 Epoch[47] Batch [1190]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088895,	
2017-06-28 19:58:31,860 Epoch[47] Batch [1200]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088939,	
2017-06-28 19:58:36,679 Epoch[47] Batch [1210]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088897,	
2017-06-28 19:58:41,716 Epoch[47] Batch [1220]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088869,	
2017-06-28 19:58:46,448 Epoch[47] Batch [1230]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-28 19:58:51,436 Epoch[47] Batch [1240]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088736,	
2017-06-28 19:58:56,083 Epoch[47] Batch [1250]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088618,	
2017-06-28 19:59:00,902 Epoch[47] Batch [1260]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088592,	
2017-06-28 19:59:05,695 Epoch[47] Batch [1270]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088610,	
2017-06-28 19:59:10,724 Epoch[47] Batch [1280]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088567,	
2017-06-28 19:59:15,748 Epoch[47] Batch [1290]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088575,	
2017-06-28 19:59:21,005 Epoch[47] Batch [1300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-28 19:59:26,064 Epoch[47] Batch [1310]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088559,	
2017-06-28 19:59:31,112 Epoch[47] Batch [1320]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-28 19:59:35,880 Epoch[47] Batch [1330]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088540,	
2017-06-28 19:59:40,744 Epoch[47] Batch [1340]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088535,	
2017-06-28 19:59:45,709 Epoch[47] Batch [1350]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-28 19:59:50,527 Epoch[47] Batch [1360]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088564,	
2017-06-28 19:59:55,553 Epoch[47] Batch [1370]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088593,	
2017-06-28 20:00:00,612 Epoch[47] Batch [1380]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088473,	
2017-06-28 20:00:05,649 Epoch[47] Batch [1390]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-28 20:00:10,501 Epoch[47] Batch [1400]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-28 20:00:15,393 Epoch[47] Batch [1410]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088492,	
2017-06-28 20:00:20,161 Epoch[47] Batch [1420]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088457,	
2017-06-28 20:00:25,529 Epoch[47] Batch [1430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-28 20:00:30,823 Epoch[47] Batch [1440]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-28 20:00:36,229 Epoch[47] Batch [1450]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088461,	
2017-06-28 20:00:41,207 Epoch[47] Batch [1460]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088438,	
2017-06-28 20:00:46,236 Epoch[47] Batch [1470]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088429,	
2017-06-28 20:00:51,236 Epoch[47] Batch [1480]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-28 20:00:54,358 Epoch[47] Train-FCNLogLoss=0.088447
2017-06-28 20:00:54,358 Epoch[47] Time cost=737.983
2017-06-28 20:00:55,023 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0048.params"
2017-06-28 20:00:56,659 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0048.states"
2017-06-28 20:01:02,263 Epoch[48] Batch [10]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-28 20:01:06,991 Epoch[48] Batch [20]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087914,	
2017-06-28 20:01:11,980 Epoch[48] Batch [30]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089095,	
2017-06-28 20:01:17,280 Epoch[48] Batch [40]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088869,	
2017-06-28 20:01:22,417 Epoch[48] Batch [50]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089051,	
2017-06-28 20:01:27,482 Epoch[48] Batch [60]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089914,	
2017-06-28 20:01:32,389 Epoch[48] Batch [70]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089870,	
2017-06-28 20:01:37,211 Epoch[48] Batch [80]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.090120,	
2017-06-28 20:01:42,262 Epoch[48] Batch [90]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.090334,	
2017-06-28 20:01:47,532 Epoch[48] Batch [100]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089492,	
2017-06-28 20:01:52,452 Epoch[48] Batch [110]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090018,	
2017-06-28 20:01:57,358 Epoch[48] Batch [120]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089053,	
2017-06-28 20:02:02,269 Epoch[48] Batch [130]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089208,	
2017-06-28 20:02:07,067 Epoch[48] Batch [140]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089427,	
2017-06-28 20:02:11,897 Epoch[48] Batch [150]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089027,	
2017-06-28 20:02:16,474 Epoch[48] Batch [160]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088845,	
2017-06-28 20:02:21,427 Epoch[48] Batch [170]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089290,	
2017-06-28 20:02:26,333 Epoch[48] Batch [180]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089740,	
2017-06-28 20:02:31,211 Epoch[48] Batch [190]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089484,	
2017-06-28 20:02:35,710 Epoch[48] Batch [200]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089462,	
2017-06-28 20:02:40,638 Epoch[48] Batch [210]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089211,	
2017-06-28 20:02:45,281 Epoch[48] Batch [220]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089086,	
2017-06-28 20:02:49,801 Epoch[48] Batch [230]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.089093,	
2017-06-28 20:02:54,652 Epoch[48] Batch [240]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089091,	
2017-06-28 20:02:59,390 Epoch[48] Batch [250]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089072,	
2017-06-28 20:03:04,240 Epoch[48] Batch [260]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-28 20:03:09,391 Epoch[48] Batch [270]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089028,	
2017-06-28 20:03:14,172 Epoch[48] Batch [280]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088784,	
2017-06-28 20:03:18,820 Epoch[48] Batch [290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088790,	
2017-06-28 20:03:23,517 Epoch[48] Batch [300]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-28 20:03:28,461 Epoch[48] Batch [310]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088976,	
2017-06-28 20:03:33,465 Epoch[48] Batch [320]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089154,	
2017-06-28 20:03:39,021 Epoch[48] Batch [330]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088925,	
2017-06-28 20:03:44,387 Epoch[48] Batch [340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-28 20:03:49,776 Epoch[48] Batch [350]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-28 20:03:54,829 Epoch[48] Batch [360]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088862,	
2017-06-28 20:04:00,119 Epoch[48] Batch [370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088623,	
2017-06-28 20:04:06,235 Epoch[48] Batch [380]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088902,	
2017-06-28 20:04:11,435 Epoch[48] Batch [390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088851,	
2017-06-28 20:04:16,437 Epoch[48] Batch [400]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088922,	
2017-06-28 20:04:21,388 Epoch[48] Batch [410]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088713,	
2017-06-28 20:04:26,795 Epoch[48] Batch [420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088777,	
2017-06-28 20:04:32,166 Epoch[48] Batch [430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088659,	
2017-06-28 20:04:37,406 Epoch[48] Batch [440]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088739,	
2017-06-28 20:04:42,384 Epoch[48] Batch [450]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088718,	
2017-06-28 20:04:46,865 Epoch[48] Batch [460]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088816,	
2017-06-28 20:04:51,725 Epoch[48] Batch [470]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-28 20:04:56,871 Epoch[48] Batch [480]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088788,	
2017-06-28 20:05:01,976 Epoch[48] Batch [490]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088711,	
2017-06-28 20:05:07,166 Epoch[48] Batch [500]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088740,	
2017-06-28 20:05:12,422 Epoch[48] Batch [510]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088743,	
2017-06-28 20:05:17,627 Epoch[48] Batch [520]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088674,	
2017-06-28 20:05:22,813 Epoch[48] Batch [530]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-28 20:05:27,892 Epoch[48] Batch [540]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-28 20:05:33,402 Epoch[48] Batch [550]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088749,	
2017-06-28 20:05:38,675 Epoch[48] Batch [560]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088768,	
2017-06-28 20:05:44,218 Epoch[48] Batch [570]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088855,	
2017-06-28 20:05:48,974 Epoch[48] Batch [580]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088759,	
2017-06-28 20:05:53,988 Epoch[48] Batch [590]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088809,	
2017-06-28 20:05:58,810 Epoch[48] Batch [600]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088766,	
2017-06-28 20:06:03,829 Epoch[48] Batch [610]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088783,	
2017-06-28 20:06:08,814 Epoch[48] Batch [620]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088789,	
2017-06-28 20:06:13,491 Epoch[48] Batch [630]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088826,	
2017-06-28 20:06:18,788 Epoch[48] Batch [640]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088856,	
2017-06-28 20:06:23,962 Epoch[48] Batch [650]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088748,	
2017-06-28 20:06:28,956 Epoch[48] Batch [660]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088660,	
2017-06-28 20:06:34,421 Epoch[48] Batch [670]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088566,	
2017-06-28 20:06:39,546 Epoch[48] Batch [680]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088631,	
2017-06-28 20:06:44,844 Epoch[48] Batch [690]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088651,	
2017-06-28 20:06:50,216 Epoch[48] Batch [700]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088691,	
2017-06-28 20:06:55,692 Epoch[48] Batch [710]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088742,	
2017-06-28 20:07:01,061 Epoch[48] Batch [720]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088750,	
2017-06-28 20:07:06,336 Epoch[48] Batch [730]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-28 20:07:11,599 Epoch[48] Batch [740]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088820,	
2017-06-28 20:07:16,569 Epoch[48] Batch [750]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088709,	
2017-06-28 20:07:22,042 Epoch[48] Batch [760]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088743,	
2017-06-28 20:07:27,221 Epoch[48] Batch [770]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088815,	
2017-06-28 20:07:32,647 Epoch[48] Batch [780]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088885,	
2017-06-28 20:07:37,965 Epoch[48] Batch [790]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-28 20:07:42,861 Epoch[48] Batch [800]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088814,	
2017-06-28 20:07:47,961 Epoch[48] Batch [810]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088823,	
2017-06-28 20:07:52,688 Epoch[48] Batch [820]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088806,	
2017-06-28 20:07:57,817 Epoch[48] Batch [830]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088754,	
2017-06-28 20:08:02,385 Epoch[48] Batch [840]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.088644,	
2017-06-28 20:08:07,200 Epoch[48] Batch [850]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-28 20:08:12,256 Epoch[48] Batch [860]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088631,	
2017-06-28 20:08:17,260 Epoch[48] Batch [870]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-28 20:08:22,221 Epoch[48] Batch [880]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088638,	
2017-06-28 20:08:27,547 Epoch[48] Batch [890]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088606,	
2017-06-28 20:08:32,974 Epoch[48] Batch [900]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088528,	
2017-06-28 20:08:38,347 Epoch[48] Batch [910]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-28 20:08:43,471 Epoch[48] Batch [920]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088712,	
2017-06-28 20:08:48,870 Epoch[48] Batch [930]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088730,	
2017-06-28 20:08:53,808 Epoch[48] Batch [940]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.088691,	
2017-06-28 20:08:59,337 Epoch[48] Batch [950]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088725,	
2017-06-28 20:09:04,286 Epoch[48] Batch [960]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088729,	
2017-06-28 20:09:09,508 Epoch[48] Batch [970]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088731,	
2017-06-28 20:09:15,283 Epoch[48] Batch [980]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-28 20:09:20,530 Epoch[48] Batch [990]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088847,	
2017-06-28 20:09:25,545 Epoch[48] Batch [1000]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088753,	
2017-06-28 20:09:30,738 Epoch[48] Batch [1010]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088815,	
2017-06-28 20:09:35,510 Epoch[48] Batch [1020]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088863,	
2017-06-28 20:09:41,073 Epoch[48] Batch [1030]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088939,	
2017-06-28 20:09:46,357 Epoch[48] Batch [1040]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088902,	
2017-06-28 20:09:51,954 Epoch[48] Batch [1050]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.088822,	
2017-06-28 20:09:57,125 Epoch[48] Batch [1060]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088835,	
2017-06-28 20:10:02,645 Epoch[48] Batch [1070]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088865,	
2017-06-28 20:10:07,670 Epoch[48] Batch [1080]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088837,	
2017-06-28 20:10:12,462 Epoch[48] Batch [1090]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-28 20:10:17,418 Epoch[48] Batch [1100]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088690,	
2017-06-28 20:10:22,148 Epoch[48] Batch [1110]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088673,	
2017-06-28 20:10:27,241 Epoch[48] Batch [1120]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088705,	
2017-06-28 20:10:31,956 Epoch[48] Batch [1130]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088743,	
2017-06-28 20:10:36,898 Epoch[48] Batch [1140]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-28 20:10:42,327 Epoch[48] Batch [1150]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088750,	
2017-06-28 20:10:47,274 Epoch[48] Batch [1160]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088746,	
2017-06-28 20:10:52,768 Epoch[48] Batch [1170]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.088823,	
2017-06-28 20:10:58,457 Epoch[48] Batch [1180]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088778,	
2017-06-28 20:11:03,755 Epoch[48] Batch [1190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088751,	
2017-06-28 20:11:09,453 Epoch[48] Batch [1200]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.088795,	
2017-06-28 20:11:15,027 Epoch[48] Batch [1210]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088873,	
2017-06-28 20:11:20,152 Epoch[48] Batch [1220]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088846,	
2017-06-28 20:11:25,491 Epoch[48] Batch [1230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088900,	
2017-06-28 20:11:31,131 Epoch[48] Batch [1240]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.088813,	
2017-06-28 20:11:36,354 Epoch[48] Batch [1250]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-28 20:11:41,076 Epoch[48] Batch [1260]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088851,	
2017-06-28 20:11:45,841 Epoch[48] Batch [1270]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088872,	
2017-06-28 20:11:50,548 Epoch[48] Batch [1280]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088865,	
2017-06-28 20:11:55,368 Epoch[48] Batch [1290]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088842,	
2017-06-28 20:12:00,600 Epoch[48] Batch [1300]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088828,	
2017-06-28 20:12:05,704 Epoch[48] Batch [1310]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088835,	
2017-06-28 20:12:11,617 Epoch[48] Batch [1320]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.088895,	
2017-06-28 20:12:16,902 Epoch[48] Batch [1330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088934,	
2017-06-28 20:12:22,162 Epoch[48] Batch [1340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088936,	
2017-06-28 20:12:27,515 Epoch[48] Batch [1350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088883,	
2017-06-28 20:12:33,045 Epoch[48] Batch [1360]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088867,	
2017-06-28 20:12:38,256 Epoch[48] Batch [1370]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088883,	
2017-06-28 20:12:43,726 Epoch[48] Batch [1380]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088936,	
2017-06-28 20:12:49,072 Epoch[48] Batch [1390]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088918,	
2017-06-28 20:12:54,018 Epoch[48] Batch [1400]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088950,	
2017-06-28 20:12:59,772 Epoch[48] Batch [1410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088982,	
2017-06-28 20:13:05,376 Epoch[48] Batch [1420]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.088947,	
2017-06-28 20:13:10,953 Epoch[48] Batch [1430]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088878,	
2017-06-28 20:13:16,436 Epoch[48] Batch [1440]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088941,	
2017-06-28 20:13:21,516 Epoch[48] Batch [1450]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088956,	
2017-06-28 20:13:27,206 Epoch[48] Batch [1460]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088957,	
2017-06-28 20:13:32,444 Epoch[48] Batch [1470]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088980,	
2017-06-28 20:13:37,948 Epoch[48] Batch [1480]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.089013,	
2017-06-28 20:13:41,226 Epoch[48] Train-FCNLogLoss=0.088996
2017-06-28 20:13:41,226 Epoch[48] Time cost=764.567
2017-06-28 20:13:41,894 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0049.params"
2017-06-28 20:13:43,475 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0049.states"
2017-06-28 20:13:50,109 Epoch[49] Batch [10]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086586,	
2017-06-28 20:13:54,947 Epoch[49] Batch [20]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.083297,	
2017-06-28 20:13:59,940 Epoch[49] Batch [30]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.085232,	
2017-06-28 20:14:04,772 Epoch[49] Batch [40]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.086305,	
2017-06-28 20:14:09,827 Epoch[49] Batch [50]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086657,	
2017-06-28 20:14:14,864 Epoch[49] Batch [60]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.087923,	
2017-06-28 20:14:19,713 Epoch[49] Batch [70]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087388,	
2017-06-28 20:14:24,218 Epoch[49] Batch [80]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087034,	
2017-06-28 20:14:28,848 Epoch[49] Batch [90]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087228,	
2017-06-28 20:14:33,589 Epoch[49] Batch [100]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087675,	
2017-06-28 20:14:38,902 Epoch[49] Batch [110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087878,	
2017-06-28 20:14:43,943 Epoch[49] Batch [120]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088498,	
2017-06-28 20:14:48,950 Epoch[49] Batch [130]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089219,	
2017-06-28 20:14:54,126 Epoch[49] Batch [140]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089347,	
2017-06-28 20:14:58,676 Epoch[49] Batch [150]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089961,	
2017-06-28 20:15:03,955 Epoch[49] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090103,	
2017-06-28 20:15:09,128 Epoch[49] Batch [170]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089786,	
2017-06-28 20:15:14,057 Epoch[49] Batch [180]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.090133,	
2017-06-28 20:15:19,368 Epoch[49] Batch [190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090407,	
2017-06-28 20:15:24,602 Epoch[49] Batch [200]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.090423,	
2017-06-28 20:15:30,049 Epoch[49] Batch [210]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.090062,	
2017-06-28 20:15:35,829 Epoch[49] Batch [220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.089947,	
2017-06-28 20:15:41,751 Epoch[49] Batch [230]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.089929,	
2017-06-28 20:15:46,648 Epoch[49] Batch [240]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.090353,	
2017-06-28 20:15:52,081 Epoch[49] Batch [250]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090375,	
2017-06-28 20:15:57,292 Epoch[49] Batch [260]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090427,	
2017-06-28 20:16:01,925 Epoch[49] Batch [270]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090543,	
2017-06-28 20:16:07,120 Epoch[49] Batch [280]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.090393,	
2017-06-28 20:16:12,351 Epoch[49] Batch [290]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090447,	
2017-06-28 20:16:17,417 Epoch[49] Batch [300]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090466,	
2017-06-28 20:16:22,954 Epoch[49] Batch [310]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.090136,	
2017-06-28 20:16:28,383 Epoch[49] Batch [320]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089946,	
2017-06-28 20:16:34,303 Epoch[49] Batch [330]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.090139,	
2017-06-28 20:16:39,728 Epoch[49] Batch [340]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090065,	
2017-06-28 20:16:45,531 Epoch[49] Batch [350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.089909,	
2017-06-28 20:16:50,579 Epoch[49] Batch [360]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089909,	
2017-06-28 20:16:56,138 Epoch[49] Batch [370]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.089500,	
2017-06-28 20:17:01,200 Epoch[49] Batch [380]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089251,	
2017-06-28 20:17:05,794 Epoch[49] Batch [390]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089149,	
2017-06-28 20:17:10,658 Epoch[49] Batch [400]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089176,	
2017-06-28 20:17:15,447 Epoch[49] Batch [410]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088985,	
2017-06-28 20:17:20,322 Epoch[49] Batch [420]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088891,	
2017-06-28 20:17:26,049 Epoch[49] Batch [430]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.089001,	
2017-06-28 20:17:31,375 Epoch[49] Batch [440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088849,	
2017-06-28 20:17:37,153 Epoch[49] Batch [450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088993,	
2017-06-28 20:17:42,432 Epoch[49] Batch [460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089111,	
2017-06-28 20:17:47,678 Epoch[49] Batch [470]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089197,	
2017-06-28 20:17:52,989 Epoch[49] Batch [480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089188,	
2017-06-28 20:17:58,607 Epoch[49] Batch [490]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.089178,	
2017-06-28 20:18:03,758 Epoch[49] Batch [500]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089128,	
2017-06-28 20:18:08,619 Epoch[49] Batch [510]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089136,	
2017-06-28 20:18:13,992 Epoch[49] Batch [520]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089226,	
2017-06-28 20:18:18,961 Epoch[49] Batch [530]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089158,	
2017-06-28 20:18:24,799 Epoch[49] Batch [540]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.089008,	
2017-06-28 20:18:29,758 Epoch[49] Batch [550]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088860,	
2017-06-28 20:18:35,518 Epoch[49] Batch [560]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088779,	
2017-06-28 20:18:40,676 Epoch[49] Batch [570]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088803,	
2017-06-28 20:18:45,498 Epoch[49] Batch [580]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088864,	
2017-06-28 20:18:50,901 Epoch[49] Batch [590]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-28 20:18:55,971 Epoch[49] Batch [600]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088746,	
2017-06-28 20:19:01,075 Epoch[49] Batch [610]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-28 20:19:06,178 Epoch[49] Batch [620]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088608,	
2017-06-28 20:19:10,890 Epoch[49] Batch [630]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088653,	
2017-06-28 20:19:15,708 Epoch[49] Batch [640]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088600,	
2017-06-28 20:19:20,357 Epoch[49] Batch [650]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088732,	
2017-06-28 20:19:25,884 Epoch[49] Batch [660]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088813,	
2017-06-28 20:19:31,439 Epoch[49] Batch [670]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088901,	
2017-06-28 20:19:36,490 Epoch[49] Batch [680]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088924,	
2017-06-28 20:19:41,787 Epoch[49] Batch [690]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088897,	
2017-06-28 20:19:46,518 Epoch[49] Batch [700]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089008,	
2017-06-28 20:19:51,615 Epoch[49] Batch [710]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.089007,	
2017-06-28 20:19:57,224 Epoch[49] Batch [720]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.089013,	
2017-06-28 20:20:02,462 Epoch[49] Batch [730]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088890,	
2017-06-28 20:20:08,329 Epoch[49] Batch [740]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.088937,	
2017-06-28 20:20:13,367 Epoch[49] Batch [750]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088995,	
2017-06-28 20:20:18,669 Epoch[49] Batch [760]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088989,	
2017-06-28 20:20:23,592 Epoch[49] Batch [770]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088878,	
2017-06-28 20:20:28,553 Epoch[49] Batch [780]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088921,	
2017-06-28 20:20:33,450 Epoch[49] Batch [790]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089034,	
2017-06-28 20:20:38,614 Epoch[49] Batch [800]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088979,	
2017-06-28 20:20:44,028 Epoch[49] Batch [810]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.089033,	
2017-06-28 20:20:48,630 Epoch[49] Batch [820]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089064,	
2017-06-28 20:20:53,937 Epoch[49] Batch [830]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088975,	
2017-06-28 20:20:59,575 Epoch[49] Batch [840]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.088998,	
2017-06-28 20:21:05,016 Epoch[49] Batch [850]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.089036,	
2017-06-28 20:21:10,451 Epoch[49] Batch [860]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.089121,	
2017-06-28 20:21:15,318 Epoch[49] Batch [870]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089045,	
2017-06-28 20:21:20,449 Epoch[49] Batch [880]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.089030,	
2017-06-28 20:21:25,778 Epoch[49] Batch [890]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-28 20:21:31,157 Epoch[49] Batch [900]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088915,	
2017-06-28 20:21:36,401 Epoch[49] Batch [910]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088885,	
2017-06-28 20:21:41,345 Epoch[49] Batch [920]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088882,	
2017-06-28 20:21:46,276 Epoch[49] Batch [930]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.088849,	
2017-06-28 20:21:50,639 Epoch[49] Batch [940]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.088897,	
2017-06-28 20:21:55,252 Epoch[49] Batch [950]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088884,	
2017-06-28 20:22:00,456 Epoch[49] Batch [960]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088837,	
2017-06-28 20:22:05,638 Epoch[49] Batch [970]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088840,	
2017-06-28 20:22:10,831 Epoch[49] Batch [980]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-28 20:22:15,653 Epoch[49] Batch [990]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088850,	
2017-06-28 20:22:20,642 Epoch[49] Batch [1000]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088863,	
2017-06-28 20:22:25,797 Epoch[49] Batch [1010]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088838,	
2017-06-28 20:22:30,789 Epoch[49] Batch [1020]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-28 20:22:36,255 Epoch[49] Batch [1030]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088833,	
2017-06-28 20:22:41,622 Epoch[49] Batch [1040]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088770,	
2017-06-28 20:22:46,809 Epoch[49] Batch [1050]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088755,	
2017-06-28 20:22:51,771 Epoch[49] Batch [1060]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088725,	
2017-06-28 20:22:56,657 Epoch[49] Batch [1070]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088813,	
2017-06-28 20:23:01,525 Epoch[49] Batch [1080]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-28 20:23:06,777 Epoch[49] Batch [1090]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088811,	
2017-06-28 20:23:12,005 Epoch[49] Batch [1100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088924,	
2017-06-28 20:23:17,111 Epoch[49] Batch [1110]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088878,	
2017-06-28 20:23:22,212 Epoch[49] Batch [1120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088948,	
2017-06-28 20:23:27,519 Epoch[49] Batch [1130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088948,	
2017-06-28 20:23:32,918 Epoch[49] Batch [1140]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088914,	
2017-06-28 20:23:38,223 Epoch[49] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088977,	
2017-06-28 20:23:43,533 Epoch[49] Batch [1160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088919,	
2017-06-28 20:23:48,591 Epoch[49] Batch [1170]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088910,	
2017-06-28 20:23:53,941 Epoch[49] Batch [1180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088991,	
2017-06-28 20:23:59,081 Epoch[49] Batch [1190]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088954,	
2017-06-28 20:24:04,706 Epoch[49] Batch [1200]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.088968,	
2017-06-28 20:24:10,008 Epoch[49] Batch [1210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088967,	
2017-06-28 20:24:15,694 Epoch[49] Batch [1220]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088991,	
2017-06-28 20:24:21,360 Epoch[49] Batch [1230]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089104,	
2017-06-28 20:24:26,538 Epoch[49] Batch [1240]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089083,	
2017-06-28 20:24:32,124 Epoch[49] Batch [1250]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.089097,	
2017-06-28 20:24:37,439 Epoch[49] Batch [1260]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089048,	
2017-06-28 20:24:43,167 Epoch[49] Batch [1270]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.089018,	
2017-06-28 20:24:48,824 Epoch[49] Batch [1280]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088985,	
2017-06-28 20:24:54,191 Epoch[49] Batch [1290]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089005,	
2017-06-28 20:24:59,628 Epoch[49] Batch [1300]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.089034,	
2017-06-28 20:25:04,622 Epoch[49] Batch [1310]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089027,	
2017-06-28 20:25:09,726 Epoch[49] Batch [1320]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.089001,	
2017-06-28 20:25:15,034 Epoch[49] Batch [1330]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088982,	
2017-06-28 20:25:20,620 Epoch[49] Batch [1340]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.088996,	
2017-06-28 20:25:25,852 Epoch[49] Batch [1350]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.089000,	
2017-06-28 20:25:30,881 Epoch[49] Batch [1360]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088968,	
2017-06-28 20:25:35,823 Epoch[49] Batch [1370]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.088920,	
2017-06-28 20:25:40,822 Epoch[49] Batch [1380]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088978,	
2017-06-28 20:25:46,104 Epoch[49] Batch [1390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089015,	
2017-06-28 20:25:51,120 Epoch[49] Batch [1400]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088985,	
2017-06-28 20:25:55,894 Epoch[49] Batch [1410]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088965,	
2017-06-28 20:26:01,230 Epoch[49] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088960,	
2017-06-28 20:26:06,551 Epoch[49] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088942,	
2017-06-28 20:26:11,454 Epoch[49] Batch [1440]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089013,	
2017-06-28 20:26:16,343 Epoch[49] Batch [1450]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.089096,	
2017-06-28 20:26:21,185 Epoch[49] Batch [1460]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.089116,	
2017-06-28 20:26:26,334 Epoch[49] Batch [1470]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089107,	
2017-06-28 20:26:31,180 Epoch[49] Batch [1480]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089163,	
2017-06-28 20:26:34,072 Epoch[49] Train-FCNLogLoss=0.089122
2017-06-28 20:26:34,073 Epoch[49] Time cost=770.597
2017-06-28 20:26:34,730 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0050.params"
2017-06-28 20:26:36,252 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0050.states"
2017-06-28 20:26:42,105 Epoch[50] Batch [10]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088452,	
2017-06-28 20:26:47,391 Epoch[50] Batch [20]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090483,	
2017-06-28 20:26:52,093 Epoch[50] Batch [30]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091110,	
2017-06-28 20:26:56,723 Epoch[50] Batch [40]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089103,	
2017-06-28 20:27:01,412 Epoch[50] Batch [50]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087774,	
2017-06-28 20:27:06,302 Epoch[50] Batch [60]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.087687,	
2017-06-28 20:27:11,757 Epoch[50] Batch [70]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.087721,	
2017-06-28 20:27:16,311 Epoch[50] Batch [80]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088152,	
2017-06-28 20:27:21,590 Epoch[50] Batch [90]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-28 20:27:26,581 Epoch[50] Batch [100]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088385,	
2017-06-28 20:27:31,822 Epoch[50] Batch [110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088427,	
2017-06-28 20:27:37,048 Epoch[50] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088533,	
2017-06-28 20:27:42,260 Epoch[50] Batch [130]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087976,	
2017-06-28 20:27:47,306 Epoch[50] Batch [140]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087784,	
2017-06-28 20:27:52,297 Epoch[50] Batch [150]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088251,	
2017-06-28 20:27:57,571 Epoch[50] Batch [160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088442,	
2017-06-28 20:28:02,658 Epoch[50] Batch [170]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087709,	
2017-06-28 20:28:07,480 Epoch[50] Batch [180]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087790,	
2017-06-28 20:28:12,173 Epoch[50] Batch [190]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087477,	
2017-06-28 20:28:16,686 Epoch[50] Batch [200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087401,	
2017-06-28 20:28:21,439 Epoch[50] Batch [210]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087244,	
2017-06-28 20:28:26,216 Epoch[50] Batch [220]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087285,	
2017-06-28 20:28:31,418 Epoch[50] Batch [230]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087490,	
2017-06-28 20:28:36,403 Epoch[50] Batch [240]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087135,	
2017-06-28 20:28:41,060 Epoch[50] Batch [250]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.087338,	
2017-06-28 20:28:45,902 Epoch[50] Batch [260]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-28 20:28:50,835 Epoch[50] Batch [270]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088206,	
2017-06-28 20:28:55,954 Epoch[50] Batch [280]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088393,	
2017-06-28 20:29:00,794 Epoch[50] Batch [290]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088588,	
2017-06-28 20:29:06,138 Epoch[50] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088480,	
2017-06-28 20:29:11,028 Epoch[50] Batch [310]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088397,	
2017-06-28 20:29:16,257 Epoch[50] Batch [320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088472,	
2017-06-28 20:29:20,675 Epoch[50] Batch [330]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088985,	
2017-06-28 20:29:25,206 Epoch[50] Batch [340]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-28 20:29:30,129 Epoch[50] Batch [350]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088590,	
2017-06-28 20:29:34,665 Epoch[50] Batch [360]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088643,	
2017-06-28 20:29:39,472 Epoch[50] Batch [370]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088582,	
2017-06-28 20:29:43,881 Epoch[50] Batch [380]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088482,	
2017-06-28 20:29:48,575 Epoch[50] Batch [390]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088570,	
2017-06-28 20:29:53,698 Epoch[50] Batch [400]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088435,	
2017-06-28 20:29:58,710 Epoch[50] Batch [410]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088169,	
2017-06-28 20:30:03,219 Epoch[50] Batch [420]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088145,	
2017-06-28 20:30:08,233 Epoch[50] Batch [430]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088212,	
2017-06-28 20:30:12,888 Epoch[50] Batch [440]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088223,	
2017-06-28 20:30:17,747 Epoch[50] Batch [450]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088164,	
2017-06-28 20:30:22,871 Epoch[50] Batch [460]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088142,	
2017-06-28 20:30:28,407 Epoch[50] Batch [470]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088167,	
2017-06-28 20:30:33,410 Epoch[50] Batch [480]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.088212,	
2017-06-28 20:30:38,160 Epoch[50] Batch [490]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088304,	
2017-06-28 20:30:43,286 Epoch[50] Batch [500]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088194,	
2017-06-28 20:30:48,521 Epoch[50] Batch [510]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088460,	
2017-06-28 20:30:53,652 Epoch[50] Batch [520]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088512,	
2017-06-28 20:30:59,161 Epoch[50] Batch [530]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088596,	
2017-06-28 20:31:04,240 Epoch[50] Batch [540]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088631,	
2017-06-28 20:31:09,450 Epoch[50] Batch [550]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088524,	
2017-06-28 20:31:14,258 Epoch[50] Batch [560]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088574,	
2017-06-28 20:31:18,961 Epoch[50] Batch [570]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088554,	
2017-06-28 20:31:23,876 Epoch[50] Batch [580]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088469,	
2017-06-28 20:31:28,872 Epoch[50] Batch [590]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088530,	
2017-06-28 20:31:34,102 Epoch[50] Batch [600]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088509,	
2017-06-28 20:31:39,335 Epoch[50] Batch [610]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088426,	
2017-06-28 20:31:44,524 Epoch[50] Batch [620]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088347,	
2017-06-28 20:31:49,649 Epoch[50] Batch [630]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088275,	
2017-06-28 20:31:54,802 Epoch[50] Batch [640]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088317,	
2017-06-28 20:31:59,795 Epoch[50] Batch [650]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088466,	
2017-06-28 20:32:04,257 Epoch[50] Batch [660]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088381,	
2017-06-28 20:32:08,865 Epoch[50] Batch [670]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088280,	
2017-06-28 20:32:13,615 Epoch[50] Batch [680]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088306,	
2017-06-28 20:32:18,281 Epoch[50] Batch [690]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088272,	
2017-06-28 20:32:23,140 Epoch[50] Batch [700]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088339,	
2017-06-28 20:32:28,322 Epoch[50] Batch [710]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088409,	
2017-06-28 20:32:33,457 Epoch[50] Batch [720]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088402,	
2017-06-28 20:32:38,558 Epoch[50] Batch [730]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-28 20:32:43,267 Epoch[50] Batch [740]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088618,	
2017-06-28 20:32:47,961 Epoch[50] Batch [750]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-28 20:32:52,714 Epoch[50] Batch [760]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088552,	
2017-06-28 20:32:57,618 Epoch[50] Batch [770]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-28 20:33:02,357 Epoch[50] Batch [780]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088480,	
2017-06-28 20:33:07,096 Epoch[50] Batch [790]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088476,	
2017-06-28 20:33:12,030 Epoch[50] Batch [800]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.088566,	
2017-06-28 20:33:16,741 Epoch[50] Batch [810]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-28 20:33:21,535 Epoch[50] Batch [820]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088388,	
2017-06-28 20:33:26,317 Epoch[50] Batch [830]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088421,	
2017-06-28 20:33:31,515 Epoch[50] Batch [840]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088435,	
2017-06-28 20:33:36,801 Epoch[50] Batch [850]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088452,	
2017-06-28 20:33:41,974 Epoch[50] Batch [860]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088407,	
2017-06-28 20:33:46,822 Epoch[50] Batch [870]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088354,	
2017-06-28 20:33:52,007 Epoch[50] Batch [880]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088299,	
2017-06-28 20:33:56,663 Epoch[50] Batch [890]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088293,	
2017-06-28 20:34:01,416 Epoch[50] Batch [900]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088283,	
2017-06-28 20:34:06,342 Epoch[50] Batch [910]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088248,	
2017-06-28 20:34:11,360 Epoch[50] Batch [920]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088270,	
2017-06-28 20:34:16,215 Epoch[50] Batch [930]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088431,	
2017-06-28 20:34:21,129 Epoch[50] Batch [940]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088486,	
2017-06-28 20:34:26,008 Epoch[50] Batch [950]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088437,	
2017-06-28 20:34:30,888 Epoch[50] Batch [960]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088431,	
2017-06-28 20:34:35,758 Epoch[50] Batch [970]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088407,	
2017-06-28 20:34:40,653 Epoch[50] Batch [980]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-28 20:34:45,639 Epoch[50] Batch [990]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088491,	
2017-06-28 20:34:50,588 Epoch[50] Batch [1000]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088489,	
2017-06-28 20:34:55,394 Epoch[50] Batch [1010]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088524,	
2017-06-28 20:35:00,189 Epoch[50] Batch [1020]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088542,	
2017-06-28 20:35:04,961 Epoch[50] Batch [1030]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088491,	
2017-06-28 20:35:10,062 Epoch[50] Batch [1040]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088518,	
2017-06-28 20:35:14,844 Epoch[50] Batch [1050]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088527,	
2017-06-28 20:35:20,086 Epoch[50] Batch [1060]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088523,	
2017-06-28 20:35:25,057 Epoch[50] Batch [1070]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088525,	
2017-06-28 20:35:29,828 Epoch[50] Batch [1080]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-28 20:35:34,570 Epoch[50] Batch [1090]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088521,	
2017-06-28 20:35:39,517 Epoch[50] Batch [1100]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088527,	
2017-06-28 20:35:44,318 Epoch[50] Batch [1110]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088500,	
2017-06-28 20:35:49,547 Epoch[50] Batch [1120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088481,	
2017-06-28 20:35:55,070 Epoch[50] Batch [1130]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088513,	
2017-06-28 20:36:00,625 Epoch[50] Batch [1140]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088534,	
2017-06-28 20:36:05,533 Epoch[50] Batch [1150]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.088470,	
2017-06-28 20:36:10,407 Epoch[50] Batch [1160]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088523,	
2017-06-28 20:36:15,660 Epoch[50] Batch [1170]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088547,	
2017-06-28 20:36:20,850 Epoch[50] Batch [1180]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088526,	
2017-06-28 20:36:25,791 Epoch[50] Batch [1190]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-28 20:36:30,598 Epoch[50] Batch [1200]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088482,	
2017-06-28 20:36:35,350 Epoch[50] Batch [1210]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088525,	
2017-06-28 20:36:40,108 Epoch[50] Batch [1220]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-28 20:36:44,789 Epoch[50] Batch [1230]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088567,	
2017-06-28 20:36:49,585 Epoch[50] Batch [1240]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088556,	
2017-06-28 20:36:54,874 Epoch[50] Batch [1250]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088657,	
2017-06-28 20:37:00,065 Epoch[50] Batch [1260]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-28 20:37:05,378 Epoch[50] Batch [1270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088613,	
2017-06-28 20:37:10,555 Epoch[50] Batch [1280]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088646,	
2017-06-28 20:37:15,832 Epoch[50] Batch [1290]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088715,	
2017-06-28 20:37:21,204 Epoch[50] Batch [1300]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-28 20:37:26,461 Epoch[50] Batch [1310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088527,	
2017-06-28 20:37:31,551 Epoch[50] Batch [1320]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088552,	
2017-06-28 20:37:36,726 Epoch[50] Batch [1330]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088527,	
2017-06-28 20:37:41,799 Epoch[50] Batch [1340]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088478,	
2017-06-28 20:37:47,083 Epoch[50] Batch [1350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088539,	
2017-06-28 20:37:51,597 Epoch[50] Batch [1360]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088620,	
2017-06-28 20:37:56,934 Epoch[50] Batch [1370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088579,	
2017-06-28 20:38:02,037 Epoch[50] Batch [1380]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088522,	
2017-06-28 20:38:07,141 Epoch[50] Batch [1390]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088505,	
2017-06-28 20:38:11,526 Epoch[50] Batch [1400]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088488,	
2017-06-28 20:38:16,220 Epoch[50] Batch [1410]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088512,	
2017-06-28 20:38:20,794 Epoch[50] Batch [1420]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088508,	
2017-06-28 20:38:25,753 Epoch[50] Batch [1430]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088512,	
2017-06-28 20:38:30,957 Epoch[50] Batch [1440]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088479,	
2017-06-28 20:38:36,618 Epoch[50] Batch [1450]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088492,	
2017-06-28 20:38:41,947 Epoch[50] Batch [1460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088483,	
2017-06-28 20:38:47,153 Epoch[50] Batch [1470]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088509,	
2017-06-28 20:38:52,186 Epoch[50] Batch [1480]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088508,	
2017-06-28 20:38:55,487 Epoch[50] Train-FCNLogLoss=0.088479
2017-06-28 20:38:55,487 Epoch[50] Time cost=739.235
2017-06-28 20:38:56,140 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0051.params"
2017-06-28 20:38:57,584 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0051.states"
2017-06-28 20:39:04,274 Epoch[51] Batch [10]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087284,	
2017-06-28 20:39:09,827 Epoch[51] Batch [20]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.089743,	
2017-06-28 20:39:15,465 Epoch[51] Batch [30]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.085331,	
2017-06-28 20:39:21,030 Epoch[51] Batch [40]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.086821,	
2017-06-28 20:39:26,707 Epoch[51] Batch [50]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087159,	
2017-06-28 20:39:32,316 Epoch[51] Batch [60]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.086988,	
2017-06-28 20:39:37,888 Epoch[51] Batch [70]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-28 20:39:43,718 Epoch[51] Batch [80]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087827,	
2017-06-28 20:39:49,048 Epoch[51] Batch [90]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-28 20:39:54,406 Epoch[51] Batch [100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089235,	
2017-06-28 20:39:59,538 Epoch[51] Batch [110]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088747,	
2017-06-28 20:40:04,625 Epoch[51] Batch [120]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089913,	
2017-06-28 20:40:09,793 Epoch[51] Batch [130]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090159,	
2017-06-28 20:40:14,960 Epoch[51] Batch [140]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090145,	
2017-06-28 20:40:20,055 Epoch[51] Batch [150]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.089691,	
2017-06-28 20:40:24,738 Epoch[51] Batch [160]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089868,	
2017-06-28 20:40:30,219 Epoch[51] Batch [170]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.090198,	
2017-06-28 20:40:35,987 Epoch[51] Batch [180]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.090191,	
2017-06-28 20:40:41,528 Epoch[51] Batch [190]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.090020,	
2017-06-28 20:40:47,186 Epoch[51] Batch [200]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.089637,	
2017-06-28 20:40:52,798 Epoch[51] Batch [210]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.090291,	
2017-06-28 20:40:58,192 Epoch[51] Batch [220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090565,	
2017-06-28 20:41:03,484 Epoch[51] Batch [230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090351,	
2017-06-28 20:41:08,620 Epoch[51] Batch [240]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090475,	
2017-06-28 20:41:13,736 Epoch[51] Batch [250]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.090478,	
2017-06-28 20:41:18,561 Epoch[51] Batch [260]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090448,	
2017-06-28 20:41:23,682 Epoch[51] Batch [270]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090356,	
2017-06-28 20:41:28,601 Epoch[51] Batch [280]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090184,	
2017-06-28 20:41:34,105 Epoch[51] Batch [290]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.090188,	
2017-06-28 20:41:39,774 Epoch[51] Batch [300]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.090027,	
2017-06-28 20:41:45,156 Epoch[51] Batch [310]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090048,	
2017-06-28 20:41:50,313 Epoch[51] Batch [320]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.090289,	
2017-06-28 20:41:55,404 Epoch[51] Batch [330]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.090312,	
2017-06-28 20:42:00,400 Epoch[51] Batch [340]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.090185,	
2017-06-28 20:42:05,849 Epoch[51] Batch [350]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.090039,	
2017-06-28 20:42:10,912 Epoch[51] Batch [360]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.090187,	
2017-06-28 20:42:16,395 Epoch[51] Batch [370]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089929,	
2017-06-28 20:42:21,506 Epoch[51] Batch [380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089734,	
2017-06-28 20:42:26,685 Epoch[51] Batch [390]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089568,	
2017-06-28 20:42:32,050 Epoch[51] Batch [400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089697,	
2017-06-28 20:42:36,977 Epoch[51] Batch [410]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089541,	
2017-06-28 20:42:42,380 Epoch[51] Batch [420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089515,	
2017-06-28 20:42:47,424 Epoch[51] Batch [430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089488,	
2017-06-28 20:42:52,818 Epoch[51] Batch [440]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089295,	
2017-06-28 20:42:57,987 Epoch[51] Batch [450]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.089118,	
2017-06-28 20:43:03,197 Epoch[51] Batch [460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.089045,	
2017-06-28 20:43:08,265 Epoch[51] Batch [470]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088895,	
2017-06-28 20:43:12,877 Epoch[51] Batch [480]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088774,	
2017-06-28 20:43:17,485 Epoch[51] Batch [490]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088782,	
2017-06-28 20:43:22,218 Epoch[51] Batch [500]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088753,	
2017-06-28 20:43:26,859 Epoch[51] Batch [510]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088886,	
2017-06-28 20:43:31,960 Epoch[51] Batch [520]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088783,	
2017-06-28 20:43:37,180 Epoch[51] Batch [530]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088697,	
2017-06-28 20:43:42,173 Epoch[51] Batch [540]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088742,	
2017-06-28 20:43:47,373 Epoch[51] Batch [550]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088622,	
2017-06-28 20:43:52,354 Epoch[51] Batch [560]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.088618,	
2017-06-28 20:43:57,493 Epoch[51] Batch [570]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088589,	
2017-06-28 20:44:02,742 Epoch[51] Batch [580]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088679,	
2017-06-28 20:44:08,323 Epoch[51] Batch [590]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088723,	
2017-06-28 20:44:14,015 Epoch[51] Batch [600]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-28 20:44:18,862 Epoch[51] Batch [610]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088607,	
2017-06-28 20:44:23,913 Epoch[51] Batch [620]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088558,	
2017-06-28 20:44:29,177 Epoch[51] Batch [630]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088527,	
2017-06-28 20:44:34,228 Epoch[51] Batch [640]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088516,	
2017-06-28 20:44:39,616 Epoch[51] Batch [650]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088521,	
2017-06-28 20:44:44,298 Epoch[51] Batch [660]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-28 20:44:48,778 Epoch[51] Batch [670]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-28 20:44:53,505 Epoch[51] Batch [680]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-28 20:44:58,002 Epoch[51] Batch [690]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088551,	
2017-06-28 20:45:03,020 Epoch[51] Batch [700]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088541,	
2017-06-28 20:45:08,057 Epoch[51] Batch [710]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-28 20:45:13,240 Epoch[51] Batch [720]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-28 20:45:19,196 Epoch[51] Batch [730]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088613,	
2017-06-28 20:45:24,522 Epoch[51] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088738,	
2017-06-28 20:45:30,137 Epoch[51] Batch [750]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-28 20:45:35,389 Epoch[51] Batch [760]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088753,	
2017-06-28 20:45:40,490 Epoch[51] Batch [770]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088697,	
2017-06-28 20:45:45,676 Epoch[51] Batch [780]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-28 20:45:50,300 Epoch[51] Batch [790]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.088811,	
2017-06-28 20:45:55,739 Epoch[51] Batch [800]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088789,	
2017-06-28 20:46:00,711 Epoch[51] Batch [810]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088803,	
2017-06-28 20:46:05,897 Epoch[51] Batch [820]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088841,	
2017-06-28 20:46:11,353 Epoch[51] Batch [830]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-28 20:46:16,640 Epoch[51] Batch [840]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-28 20:46:22,345 Epoch[51] Batch [850]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-28 20:46:27,364 Epoch[51] Batch [860]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.088664,	
2017-06-28 20:46:33,477 Epoch[51] Batch [870]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088677,	
2017-06-28 20:46:38,607 Epoch[51] Batch [880]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088763,	
2017-06-28 20:46:43,644 Epoch[51] Batch [890]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088885,	
2017-06-28 20:46:49,221 Epoch[51] Batch [900]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088911,	
2017-06-28 20:46:54,116 Epoch[51] Batch [910]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088923,	
2017-06-28 20:46:58,697 Epoch[51] Batch [920]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.088948,	
2017-06-28 20:47:03,228 Epoch[51] Batch [930]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088992,	
2017-06-28 20:47:07,759 Epoch[51] Batch [940]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-28 20:47:13,110 Epoch[51] Batch [950]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088872,	
2017-06-28 20:47:18,197 Epoch[51] Batch [960]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088938,	
2017-06-28 20:47:23,099 Epoch[51] Batch [970]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-28 20:47:28,443 Epoch[51] Batch [980]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088952,	
2017-06-28 20:47:33,439 Epoch[51] Batch [990]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088942,	
2017-06-28 20:47:38,418 Epoch[51] Batch [1000]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.088861,	
2017-06-28 20:47:44,087 Epoch[51] Batch [1010]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-28 20:47:49,760 Epoch[51] Batch [1020]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.088766,	
2017-06-28 20:47:54,810 Epoch[51] Batch [1030]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088790,	
2017-06-28 20:47:59,659 Epoch[51] Batch [1040]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088721,	
2017-06-28 20:48:04,698 Epoch[51] Batch [1050]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088691,	
2017-06-28 20:48:09,158 Epoch[51] Batch [1060]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.088706,	
2017-06-28 20:48:14,181 Epoch[51] Batch [1070]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088670,	
2017-06-28 20:48:19,703 Epoch[51] Batch [1080]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-28 20:48:25,043 Epoch[51] Batch [1090]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088796,	
2017-06-28 20:48:31,164 Epoch[51] Batch [1100]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088736,	
2017-06-28 20:48:36,314 Epoch[51] Batch [1110]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088731,	
2017-06-28 20:48:41,584 Epoch[51] Batch [1120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088690,	
2017-06-28 20:48:46,845 Epoch[51] Batch [1130]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-28 20:48:51,764 Epoch[51] Batch [1140]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088717,	
2017-06-28 20:48:56,355 Epoch[51] Batch [1150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088648,	
2017-06-28 20:49:01,063 Epoch[51] Batch [1160]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088690,	
2017-06-28 20:49:05,902 Epoch[51] Batch [1170]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-28 20:49:10,743 Epoch[51] Batch [1180]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088554,	
2017-06-28 20:49:15,748 Epoch[51] Batch [1190]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-28 20:49:21,521 Epoch[51] Batch [1200]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088548,	
2017-06-28 20:49:27,045 Epoch[51] Batch [1210]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088613,	
2017-06-28 20:49:32,316 Epoch[51] Batch [1220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-28 20:49:37,429 Epoch[51] Batch [1230]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088600,	
2017-06-28 20:49:42,403 Epoch[51] Batch [1240]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088595,	
2017-06-28 20:49:47,786 Epoch[51] Batch [1250]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088691,	
2017-06-28 20:49:52,950 Epoch[51] Batch [1260]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088642,	
2017-06-28 20:49:58,587 Epoch[51] Batch [1270]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-28 20:50:04,152 Epoch[51] Batch [1280]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088615,	
2017-06-28 20:50:09,062 Epoch[51] Batch [1290]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.088581,	
2017-06-28 20:50:13,936 Epoch[51] Batch [1300]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-28 20:50:18,990 Epoch[51] Batch [1310]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088684,	
2017-06-28 20:50:24,147 Epoch[51] Batch [1320]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088703,	
2017-06-28 20:50:29,630 Epoch[51] Batch [1330]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-28 20:50:34,753 Epoch[51] Batch [1340]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-28 20:50:39,928 Epoch[51] Batch [1350]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.088588,	
2017-06-28 20:50:45,115 Epoch[51] Batch [1360]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088575,	
2017-06-28 20:50:50,434 Epoch[51] Batch [1370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-28 20:50:55,689 Epoch[51] Batch [1380]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088670,	
2017-06-28 20:51:01,061 Epoch[51] Batch [1390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088596,	
2017-06-28 20:51:06,243 Epoch[51] Batch [1400]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088640,	
2017-06-28 20:51:11,479 Epoch[51] Batch [1410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088643,	
2017-06-28 20:51:15,988 Epoch[51] Batch [1420]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088643,	
2017-06-28 20:51:21,094 Epoch[51] Batch [1430]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-28 20:51:26,222 Epoch[51] Batch [1440]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088602,	
2017-06-28 20:51:31,217 Epoch[51] Batch [1450]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088663,	
2017-06-28 20:51:36,417 Epoch[51] Batch [1460]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088689,	
2017-06-28 20:51:41,055 Epoch[51] Batch [1470]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088709,	
2017-06-28 20:51:45,882 Epoch[51] Batch [1480]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088683,	
2017-06-28 20:51:48,771 Epoch[51] Train-FCNLogLoss=0.088694
2017-06-28 20:51:48,771 Epoch[51] Time cost=771.187
2017-06-28 20:51:49,441 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0052.params"
2017-06-28 20:51:51,011 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0052.states"
2017-06-28 20:51:56,872 Epoch[52] Batch [10]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.085847,	
2017-06-28 20:52:02,555 Epoch[52] Batch [20]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-28 20:52:07,408 Epoch[52] Batch [30]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.089763,	
2017-06-28 20:52:12,186 Epoch[52] Batch [40]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088579,	
2017-06-28 20:52:16,766 Epoch[52] Batch [50]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089950,	
2017-06-28 20:52:21,759 Epoch[52] Batch [60]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089323,	
2017-06-28 20:52:27,124 Epoch[52] Batch [70]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088665,	
2017-06-28 20:52:32,634 Epoch[52] Batch [80]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.089826,	
2017-06-28 20:52:38,329 Epoch[52] Batch [90]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.090183,	
2017-06-28 20:52:43,688 Epoch[52] Batch [100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089354,	
2017-06-28 20:52:49,049 Epoch[52] Batch [110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089225,	
2017-06-28 20:52:53,930 Epoch[52] Batch [120]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088378,	
2017-06-28 20:52:59,007 Epoch[52] Batch [130]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088314,	
2017-06-28 20:53:04,631 Epoch[52] Batch [140]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.087817,	
2017-06-28 20:53:09,835 Epoch[52] Batch [150]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087810,	
2017-06-28 20:53:14,901 Epoch[52] Batch [160]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087547,	
2017-06-28 20:53:20,062 Epoch[52] Batch [170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087599,	
2017-06-28 20:53:24,707 Epoch[52] Batch [180]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087681,	
2017-06-28 20:53:29,731 Epoch[52] Batch [190]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087702,	
2017-06-28 20:53:34,985 Epoch[52] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088019,	
2017-06-28 20:53:39,859 Epoch[52] Batch [210]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.087925,	
2017-06-28 20:53:44,661 Epoch[52] Batch [220]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087910,	
2017-06-28 20:53:49,290 Epoch[52] Batch [230]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088492,	
2017-06-28 20:53:54,257 Epoch[52] Batch [240]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088502,	
2017-06-28 20:53:58,944 Epoch[52] Batch [250]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088484,	
2017-06-28 20:54:03,948 Epoch[52] Batch [260]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088523,	
2017-06-28 20:54:08,973 Epoch[52] Batch [270]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088198,	
2017-06-28 20:54:13,787 Epoch[52] Batch [280]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088261,	
2017-06-28 20:54:18,533 Epoch[52] Batch [290]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088259,	
2017-06-28 20:54:23,221 Epoch[52] Batch [300]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087884,	
2017-06-28 20:54:27,891 Epoch[52] Batch [310]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088170,	
2017-06-28 20:54:33,152 Epoch[52] Batch [320]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087885,	
2017-06-28 20:54:38,399 Epoch[52] Batch [330]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087924,	
2017-06-28 20:54:43,278 Epoch[52] Batch [340]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.087998,	
2017-06-28 20:54:48,677 Epoch[52] Batch [350]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087994,	
2017-06-28 20:54:53,791 Epoch[52] Batch [360]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088012,	
2017-06-28 20:54:58,775 Epoch[52] Batch [370]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.088079,	
2017-06-28 20:55:03,833 Epoch[52] Batch [380]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088049,	
2017-06-28 20:55:08,627 Epoch[52] Batch [390]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088116,	
2017-06-28 20:55:13,325 Epoch[52] Batch [400]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088108,	
2017-06-28 20:55:18,023 Epoch[52] Batch [410]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088134,	
2017-06-28 20:55:22,735 Epoch[52] Batch [420]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088164,	
2017-06-28 20:55:27,673 Epoch[52] Batch [430]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.088137,	
2017-06-28 20:55:32,950 Epoch[52] Batch [440]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087985,	
2017-06-28 20:55:38,188 Epoch[52] Batch [450]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087962,	
2017-06-28 20:55:43,472 Epoch[52] Batch [460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087867,	
2017-06-28 20:55:48,542 Epoch[52] Batch [470]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087908,	
2017-06-28 20:55:53,922 Epoch[52] Batch [480]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-28 20:55:58,701 Epoch[52] Batch [490]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088355,	
2017-06-28 20:56:03,967 Epoch[52] Batch [500]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088499,	
2017-06-28 20:56:09,060 Epoch[52] Batch [510]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088521,	
2017-06-28 20:56:13,544 Epoch[52] Batch [520]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-28 20:56:18,626 Epoch[52] Batch [530]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088578,	
2017-06-28 20:56:23,487 Epoch[52] Batch [540]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088640,	
2017-06-28 20:56:28,003 Epoch[52] Batch [550]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088735,	
2017-06-28 20:56:32,753 Epoch[52] Batch [560]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088659,	
2017-06-28 20:56:37,549 Epoch[52] Batch [570]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088645,	
2017-06-28 20:56:42,365 Epoch[52] Batch [580]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088735,	
2017-06-28 20:56:47,217 Epoch[52] Batch [590]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088779,	
2017-06-28 20:56:52,108 Epoch[52] Batch [600]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088766,	
2017-06-28 20:56:57,040 Epoch[52] Batch [610]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-28 20:57:02,190 Epoch[52] Batch [620]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088828,	
2017-06-28 20:57:07,000 Epoch[52] Batch [630]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-28 20:57:11,556 Epoch[52] Batch [640]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088702,	
2017-06-28 20:57:16,098 Epoch[52] Batch [650]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088592,	
2017-06-28 20:57:20,889 Epoch[52] Batch [660]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088585,	
2017-06-28 20:57:25,515 Epoch[52] Batch [670]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.088487,	
2017-06-28 20:57:29,811 Epoch[52] Batch [680]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-28 20:57:34,724 Epoch[52] Batch [690]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088433,	
2017-06-28 20:57:39,466 Epoch[52] Batch [700]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088390,	
2017-06-28 20:57:44,342 Epoch[52] Batch [710]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088336,	
2017-06-28 20:57:49,534 Epoch[52] Batch [720]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088408,	
2017-06-28 20:57:55,336 Epoch[52] Batch [730]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-28 20:58:00,480 Epoch[52] Batch [740]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.088511,	
2017-06-28 20:58:06,172 Epoch[52] Batch [750]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088537,	
2017-06-28 20:58:11,216 Epoch[52] Batch [760]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088626,	
2017-06-28 20:58:16,898 Epoch[52] Batch [770]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088533,	
2017-06-28 20:58:22,232 Epoch[52] Batch [780]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088544,	
2017-06-28 20:58:27,675 Epoch[52] Batch [790]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.088488,	
2017-06-28 20:58:32,544 Epoch[52] Batch [800]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088644,	
2017-06-28 20:58:37,570 Epoch[52] Batch [810]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-28 20:58:42,491 Epoch[52] Batch [820]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088644,	
2017-06-28 20:58:47,325 Epoch[52] Batch [830]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088666,	
2017-06-28 20:58:52,427 Epoch[52] Batch [840]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088647,	
2017-06-28 20:58:57,987 Epoch[52] Batch [850]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088691,	
2017-06-28 20:59:03,242 Epoch[52] Batch [860]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088618,	
2017-06-28 20:59:08,609 Epoch[52] Batch [870]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-28 20:59:13,700 Epoch[52] Batch [880]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-28 20:59:18,762 Epoch[52] Batch [890]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.088565,	
2017-06-28 20:59:23,752 Epoch[52] Batch [900]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088596,	
2017-06-28 20:59:28,726 Epoch[52] Batch [910]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088697,	
2017-06-28 20:59:34,023 Epoch[52] Batch [920]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088781,	
2017-06-28 20:59:39,566 Epoch[52] Batch [930]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088748,	
2017-06-28 20:59:44,718 Epoch[52] Batch [940]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088698,	
2017-06-28 20:59:49,797 Epoch[52] Batch [950]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-28 20:59:55,145 Epoch[52] Batch [960]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088745,	
2017-06-28 21:00:00,792 Epoch[52] Batch [970]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.088707,	
2017-06-28 21:00:05,928 Epoch[52] Batch [980]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088613,	
2017-06-28 21:00:10,744 Epoch[52] Batch [990]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088610,	
2017-06-28 21:00:15,350 Epoch[52] Batch [1000]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-28 21:00:20,188 Epoch[52] Batch [1010]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088645,	
2017-06-28 21:00:24,858 Epoch[52] Batch [1020]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088670,	
2017-06-28 21:00:29,449 Epoch[52] Batch [1030]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088637,	
2017-06-28 21:00:34,149 Epoch[52] Batch [1040]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088602,	
2017-06-28 21:00:39,041 Epoch[52] Batch [1050]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-28 21:00:44,577 Epoch[52] Batch [1060]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-28 21:00:49,793 Epoch[52] Batch [1070]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.088514,	
2017-06-28 21:00:55,476 Epoch[52] Batch [1080]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-28 21:01:00,360 Epoch[52] Batch [1090]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-28 21:01:05,123 Epoch[52] Batch [1100]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088548,	
2017-06-28 21:01:10,817 Epoch[52] Batch [1110]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088516,	
2017-06-28 21:01:16,005 Epoch[52] Batch [1120]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088522,	
2017-06-28 21:01:20,629 Epoch[52] Batch [1130]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-28 21:01:25,460 Epoch[52] Batch [1140]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088528,	
2017-06-28 21:01:30,457 Epoch[52] Batch [1150]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088537,	
2017-06-28 21:01:35,353 Epoch[52] Batch [1160]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088521,	
2017-06-28 21:01:40,376 Epoch[52] Batch [1170]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088482,	
2017-06-28 21:01:45,617 Epoch[52] Batch [1180]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088531,	
2017-06-28 21:01:50,991 Epoch[52] Batch [1190]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088447,	
2017-06-28 21:01:55,985 Epoch[52] Batch [1200]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.088489,	
2017-06-28 21:02:01,141 Epoch[52] Batch [1210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088528,	
2017-06-28 21:02:05,715 Epoch[52] Batch [1220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088451,	
2017-06-28 21:02:10,517 Epoch[52] Batch [1230]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088394,	
2017-06-28 21:02:15,152 Epoch[52] Batch [1240]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088415,	
2017-06-28 21:02:19,788 Epoch[52] Batch [1250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088363,	
2017-06-28 21:02:24,577 Epoch[52] Batch [1260]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088316,	
2017-06-28 21:02:29,534 Epoch[52] Batch [1270]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088315,	
2017-06-28 21:02:34,766 Epoch[52] Batch [1280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088272,	
2017-06-28 21:02:39,630 Epoch[52] Batch [1290]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088286,	
2017-06-28 21:02:44,190 Epoch[52] Batch [1300]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088307,	
2017-06-28 21:02:49,108 Epoch[52] Batch [1310]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088289,	
2017-06-28 21:02:53,752 Epoch[52] Batch [1320]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088273,	
2017-06-28 21:02:58,405 Epoch[52] Batch [1330]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088214,	
2017-06-28 21:03:03,255 Epoch[52] Batch [1340]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088235,	
2017-06-28 21:03:08,384 Epoch[52] Batch [1350]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088233,	
2017-06-28 21:03:13,493 Epoch[52] Batch [1360]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088225,	
2017-06-28 21:03:18,544 Epoch[52] Batch [1370]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088236,	
2017-06-28 21:03:23,705 Epoch[52] Batch [1380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088241,	
2017-06-28 21:03:28,760 Epoch[52] Batch [1390]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088208,	
2017-06-28 21:03:34,012 Epoch[52] Batch [1400]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088227,	
2017-06-28 21:03:38,609 Epoch[52] Batch [1410]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088252,	
2017-06-28 21:03:43,582 Epoch[52] Batch [1420]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088314,	
2017-06-28 21:03:49,154 Epoch[52] Batch [1430]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088315,	
2017-06-28 21:03:53,849 Epoch[52] Batch [1440]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088345,	
2017-06-28 21:03:58,529 Epoch[52] Batch [1450]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088293,	
2017-06-28 21:04:03,241 Epoch[52] Batch [1460]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088272,	
2017-06-28 21:04:08,357 Epoch[52] Batch [1470]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-28 21:04:13,156 Epoch[52] Batch [1480]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088232,	
2017-06-28 21:04:16,094 Epoch[52] Train-FCNLogLoss=0.088151
2017-06-28 21:04:16,094 Epoch[52] Time cost=745.083
2017-06-28 21:04:16,718 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0053.params"
2017-06-28 21:04:18,358 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7-0053.states"
2017-06-28 21:04:18,374 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate7x7',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate7x7'}

2017-06-28 21:04:25,945 testing 4/500 data 0.5888s net 0.3139s post 0.0094s
2017-06-28 21:04:26,428 testing 8/500 data 0.4091s net 0.2800s post 0.0088s
2017-06-28 21:04:27,331 testing 12/500 data 0.4903s net 0.2676s post 0.0083s
2017-06-28 21:04:27,924 testing 16/500 data 0.4530s net 0.2620s post 0.0080s
2017-06-28 21:04:28,745 testing 20/500 data 0.4750s net 0.2588s post 0.0087s
2017-06-28 21:04:29,420 testing 24/500 data 0.4657s net 0.2564s post 0.0090s
2017-06-28 21:04:30,031 testing 28/500 data 0.4502s net 0.2548s post 0.0091s
2017-06-28 21:04:30,895 testing 32/500 data 0.4706s net 0.2534s post 0.0088s
2017-06-28 21:04:31,856 testing 36/500 data 0.4973s net 0.2523s post 0.0086s
2017-06-28 21:04:32,657 testing 40/500 data 0.5021s net 0.2515s post 0.0088s
2017-06-28 21:04:33,367 testing 44/500 data 0.4982s net 0.2508s post 0.0086s
2017-06-28 21:04:34,025 testing 48/500 data 0.4907s net 0.2502s post 0.0085s
2017-06-28 21:04:34,945 testing 52/500 data 0.5044s net 0.2497s post 0.0084s
2017-06-28 21:04:35,626 testing 56/500 data 0.4987s net 0.2494s post 0.0086s
2017-06-28 21:04:36,605 testing 60/500 data 0.5138s net 0.2491s post 0.0085s
2017-06-28 21:04:37,276 testing 64/500 data 0.5077s net 0.2488s post 0.0087s
2017-06-28 21:04:37,842 testing 68/500 data 0.4964s net 0.2485s post 0.0086s
2017-06-28 21:04:38,416 testing 72/500 data 0.4867s net 0.2483s post 0.0085s
2017-06-28 21:04:38,973 testing 76/500 data 0.4772s net 0.2481s post 0.0084s
2017-06-28 21:04:39,548 testing 80/500 data 0.4695s net 0.2480s post 0.0083s
2017-06-28 21:04:40,123 testing 84/500 data 0.4624s net 0.2478s post 0.0084s
2017-06-28 21:04:40,978 testing 88/500 data 0.4689s net 0.2476s post 0.0083s
2017-06-28 21:04:41,612 testing 92/500 data 0.4651s net 0.2474s post 0.0083s
2017-06-28 21:04:42,496 testing 96/500 data 0.4720s net 0.2473s post 0.0084s
2017-06-28 21:04:43,191 testing 100/500 data 0.4707s net 0.2472s post 0.0085s
2017-06-28 21:04:43,769 testing 104/500 data 0.4650s net 0.2471s post 0.0086s
2017-06-28 21:04:44,335 testing 108/500 data 0.4592s net 0.2470s post 0.0087s
2017-06-28 21:04:45,158 testing 112/500 data 0.4631s net 0.2469s post 0.0088s
2017-06-28 21:04:46,164 testing 116/500 data 0.4731s net 0.2468s post 0.0087s
2017-06-28 21:04:46,844 testing 120/500 data 0.4714s net 0.2468s post 0.0088s
2017-06-28 21:04:47,414 testing 124/500 data 0.4665s net 0.2467s post 0.0088s
2017-06-28 21:04:47,987 testing 128/500 data 0.4618s net 0.2467s post 0.0088s
2017-06-28 21:04:48,550 testing 132/500 data 0.4571s net 0.2466s post 0.0089s
2017-06-28 21:04:49,335 testing 136/500 data 0.4594s net 0.2465s post 0.0089s
2017-06-28 21:04:50,006 testing 140/500 data 0.4581s net 0.2464s post 0.0090s
2017-06-28 21:04:50,577 testing 144/500 data 0.4543s net 0.2464s post 0.0089s
2017-06-28 21:04:51,157 testing 148/500 data 0.4507s net 0.2464s post 0.0090s
2017-06-28 21:04:52,276 testing 152/500 data 0.4616s net 0.2463s post 0.0090s
2017-06-28 21:04:52,913 testing 156/500 data 0.4596s net 0.2462s post 0.0090s
2017-06-28 21:04:53,477 testing 160/500 data 0.4558s net 0.2462s post 0.0090s
2017-06-28 21:04:54,039 testing 164/500 data 0.4523s net 0.2462s post 0.0090s
2017-06-28 21:04:54,723 testing 168/500 data 0.4517s net 0.2462s post 0.0090s
2017-06-28 21:04:55,347 testing 172/500 data 0.4499s net 0.2461s post 0.0090s
2017-06-28 21:04:55,920 testing 176/500 data 0.4469s net 0.2461s post 0.0090s
2017-06-28 21:04:56,497 testing 180/500 data 0.4440s net 0.2461s post 0.0091s
2017-06-28 21:04:57,048 testing 184/500 data 0.4409s net 0.2461s post 0.0090s
2017-06-28 21:04:57,738 testing 188/500 data 0.4408s net 0.2460s post 0.0091s
2017-06-28 21:04:58,383 testing 192/500 data 0.4398s net 0.2460s post 0.0090s
2017-06-28 21:04:58,997 testing 196/500 data 0.4381s net 0.2460s post 0.0091s
2017-06-28 21:05:00,026 testing 200/500 data 0.4448s net 0.2459s post 0.0091s
2017-06-28 21:05:00,690 testing 204/500 data 0.4441s net 0.2459s post 0.0092s
2017-06-28 21:05:01,366 testing 208/500 data 0.4437s net 0.2459s post 0.0091s
2017-06-28 21:05:02,223 testing 212/500 data 0.4467s net 0.2459s post 0.0091s
2017-06-28 21:05:02,897 testing 216/500 data 0.4462s net 0.2458s post 0.0092s
2017-06-28 21:05:03,567 testing 220/500 data 0.4456s net 0.2458s post 0.0092s
2017-06-28 21:05:04,504 testing 224/500 data 0.4499s net 0.2457s post 0.0092s
2017-06-28 21:05:05,161 testing 228/500 data 0.4490s net 0.2457s post 0.0093s
2017-06-28 21:05:05,729 testing 232/500 data 0.4466s net 0.2457s post 0.0093s
2017-06-28 21:05:06,295 testing 236/500 data 0.4444s net 0.2456s post 0.0093s
2017-06-28 21:05:07,042 testing 240/500 data 0.4452s net 0.2456s post 0.0094s
2017-06-28 21:05:07,614 testing 244/500 data 0.4431s net 0.2456s post 0.0093s
2017-06-28 21:05:08,334 testing 248/500 data 0.4435s net 0.2456s post 0.0093s
2017-06-28 21:05:08,916 testing 252/500 data 0.4417s net 0.2455s post 0.0093s
2017-06-28 21:05:09,479 testing 256/500 data 0.4397s net 0.2455s post 0.0093s
2017-06-28 21:05:10,053 testing 260/500 data 0.4378s net 0.2455s post 0.0093s
2017-06-28 21:05:10,618 testing 264/500 data 0.4359s net 0.2455s post 0.0093s
2017-06-28 21:05:11,181 testing 268/500 data 0.4341s net 0.2455s post 0.0093s
2017-06-28 21:05:11,870 testing 272/500 data 0.4341s net 0.2455s post 0.0092s
2017-06-28 21:05:12,785 testing 276/500 data 0.4373s net 0.2455s post 0.0092s
2017-06-28 21:05:13,409 testing 280/500 data 0.4364s net 0.2454s post 0.0093s
2017-06-28 21:05:13,966 testing 284/500 data 0.4345s net 0.2454s post 0.0093s
2017-06-28 21:05:14,534 testing 288/500 data 0.4328s net 0.2454s post 0.0093s
2017-06-28 21:05:15,091 testing 292/500 data 0.4311s net 0.2454s post 0.0093s
2017-06-28 21:05:16,031 testing 296/500 data 0.4345s net 0.2454s post 0.0093s
2017-06-28 21:05:16,715 testing 300/500 data 0.4344s net 0.2454s post 0.0093s
2017-06-28 21:05:17,266 testing 304/500 data 0.4327s net 0.2454s post 0.0092s
2017-06-28 21:05:17,918 testing 308/500 data 0.4323s net 0.2453s post 0.0092s
2017-06-28 21:05:18,490 testing 312/500 data 0.4308s net 0.2453s post 0.0092s
2017-06-28 21:05:19,271 testing 316/500 data 0.4320s net 0.2453s post 0.0092s
2017-06-28 21:05:19,965 testing 320/500 data 0.4321s net 0.2453s post 0.0092s
2017-06-28 21:05:20,545 testing 324/500 data 0.4308s net 0.2453s post 0.0092s
2017-06-28 21:05:21,109 testing 328/500 data 0.4294s net 0.2453s post 0.0092s
2017-06-28 21:05:21,811 testing 332/500 data 0.4296s net 0.2453s post 0.0092s
2017-06-28 21:05:22,468 testing 336/500 data 0.4293s net 0.2452s post 0.0092s
2017-06-28 21:05:23,051 testing 340/500 data 0.4282s net 0.2452s post 0.0092s
2017-06-28 21:05:23,898 testing 344/500 data 0.4301s net 0.2452s post 0.0092s
2017-06-28 21:05:24,550 testing 348/500 data 0.4297s net 0.2452s post 0.0092s
2017-06-28 21:05:25,131 testing 352/500 data 0.4285s net 0.2452s post 0.0092s
2017-06-28 21:05:25,699 testing 356/500 data 0.4272s net 0.2452s post 0.0092s
2017-06-28 21:05:26,279 testing 360/500 data 0.4261s net 0.2452s post 0.0092s
2017-06-28 21:05:26,857 testing 364/500 data 0.4250s net 0.2451s post 0.0092s
2017-06-28 21:05:27,413 testing 368/500 data 0.4237s net 0.2451s post 0.0093s
2017-06-28 21:05:27,974 testing 372/500 data 0.4224s net 0.2451s post 0.0093s
2017-06-28 21:05:28,643 testing 376/500 data 0.4223s net 0.2451s post 0.0093s
2017-06-28 21:05:29,208 testing 380/500 data 0.4211s net 0.2451s post 0.0093s
2017-06-28 21:05:29,778 testing 384/500 data 0.4200s net 0.2451s post 0.0093s
2017-06-28 21:05:30,904 testing 388/500 data 0.4246s net 0.2451s post 0.0094s
2017-06-28 21:05:31,598 testing 392/500 data 0.4248s net 0.2451s post 0.0093s
2017-06-28 21:05:32,505 testing 396/500 data 0.4271s net 0.2451s post 0.0094s
2017-06-28 21:05:33,208 testing 400/500 data 0.4274s net 0.2450s post 0.0093s
2017-06-28 21:05:33,785 testing 404/500 data 0.4263s net 0.2450s post 0.0094s
2017-06-28 21:05:34,486 testing 408/500 data 0.4265s net 0.2450s post 0.0094s
2017-06-28 21:05:35,065 testing 412/500 data 0.4255s net 0.2450s post 0.0094s
2017-06-28 21:05:35,854 testing 416/500 data 0.4266s net 0.2450s post 0.0094s
2017-06-28 21:05:36,469 testing 420/500 data 0.4260s net 0.2450s post 0.0093s
2017-06-28 21:05:37,032 testing 424/500 data 0.4249s net 0.2450s post 0.0093s
2017-06-28 21:05:37,866 testing 428/500 data 0.4264s net 0.2450s post 0.0093s
2017-06-28 21:05:38,543 testing 432/500 data 0.4264s net 0.2449s post 0.0093s
2017-06-28 21:05:39,128 testing 436/500 data 0.4256s net 0.2449s post 0.0093s
2017-06-28 21:05:39,708 testing 440/500 data 0.4247s net 0.2449s post 0.0093s
2017-06-28 21:05:40,272 testing 444/500 data 0.4237s net 0.2449s post 0.0092s
2017-06-28 21:05:40,844 testing 448/500 data 0.4227s net 0.2449s post 0.0092s
2017-06-28 21:05:41,414 testing 452/500 data 0.4218s net 0.2449s post 0.0092s
2017-06-28 21:05:41,978 testing 456/500 data 0.4209s net 0.2449s post 0.0092s
2017-06-28 21:05:42,535 testing 460/500 data 0.4199s net 0.2449s post 0.0092s
2017-06-28 21:05:43,341 testing 464/500 data 0.4211s net 0.2449s post 0.0091s
2017-06-28 21:05:43,958 testing 468/500 data 0.4206s net 0.2449s post 0.0091s
2017-06-28 21:05:44,544 testing 472/500 data 0.4198s net 0.2449s post 0.0091s
2017-06-28 21:05:45,244 testing 476/500 data 0.4200s net 0.2449s post 0.0091s
2017-06-28 21:05:45,871 testing 480/500 data 0.4197s net 0.2449s post 0.0091s
2017-06-28 21:05:46,587 testing 484/500 data 0.4201s net 0.2448s post 0.0091s
2017-06-28 21:05:47,273 testing 488/500 data 0.4202s net 0.2448s post 0.0091s
2017-06-28 21:05:48,071 testing 492/500 data 0.4212s net 0.2448s post 0.0091s
2017-06-28 21:05:48,686 testing 496/500 data 0.4208s net 0.2448s post 0.0090s
2017-06-28 21:05:49,664 testing 500/500 data 0.4232s net 0.2448s post 0.0090s
2017-06-28 21:07:33,692 evaluate segmentation: 

2017-06-28 21:07:33,692 IU_array:

2017-06-28 21:07:33,692 0.97885
2017-06-28 21:07:33,692 0.83006
2017-06-28 21:07:33,692 0.91273
2017-06-28 21:07:33,692 0.52436
2017-06-28 21:07:33,692 0.54431
2017-06-28 21:07:33,692 0.53904
2017-06-28 21:07:33,692 0.63497
2017-06-28 21:07:33,692 0.72400
2017-06-28 21:07:33,692 0.91342
2017-06-28 21:07:33,693 0.61915
2017-06-28 21:07:33,693 0.93620
2017-06-28 21:07:33,693 0.77608
2017-06-28 21:07:33,693 0.57070
2017-06-28 21:07:33,693 0.93624
2017-06-28 21:07:33,693 0.63823
2017-06-28 21:07:33,693 0.79979
2017-06-28 21:07:33,693 0.60600
2017-06-28 21:07:33,693 0.59103
2017-06-28 21:07:33,693 0.73752
2017-06-28 21:07:33,693 meanIU:0.72698

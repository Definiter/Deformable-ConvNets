2017-06-19 14:14:32,970 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data01/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data01/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn_dilatedoffset3x3'}

2017-06-19 14:15:18,384 Epoch[0] Batch [10]	Speed: 2.55 samples/sec	Train-FCNLogLoss=2.909321,	
2017-06-19 14:15:28,708 Epoch[0] Batch [20]	Speed: 2.91 samples/sec	Train-FCNLogLoss=2.826580,	
2017-06-19 14:15:39,842 Epoch[0] Batch [30]	Speed: 2.69 samples/sec	Train-FCNLogLoss=2.675320,	
2017-06-19 14:15:47,930 Epoch[0] Batch [40]	Speed: 3.71 samples/sec	Train-FCNLogLoss=2.467806,	
2017-06-19 14:15:54,314 Epoch[0] Batch [50]	Speed: 4.70 samples/sec	Train-FCNLogLoss=2.263200,	
2017-06-19 14:16:00,268 Epoch[0] Batch [60]	Speed: 5.04 samples/sec	Train-FCNLogLoss=2.072826,	
2017-06-19 14:16:05,896 Epoch[0] Batch [70]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.938711,	
2017-06-19 14:16:11,762 Epoch[0] Batch [80]	Speed: 5.11 samples/sec	Train-FCNLogLoss=1.834791,	
2017-06-19 14:16:17,391 Epoch[0] Batch [90]	Speed: 5.33 samples/sec	Train-FCNLogLoss=1.739863,	
2017-06-19 14:16:23,297 Epoch[0] Batch [100]	Speed: 5.08 samples/sec	Train-FCNLogLoss=1.646052,	
2017-06-19 14:16:29,411 Epoch[0] Batch [110]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.562228,	
2017-06-19 14:16:35,547 Epoch[0] Batch [120]	Speed: 4.89 samples/sec	Train-FCNLogLoss=1.501428,	
2017-06-19 14:16:41,879 Epoch[0] Batch [130]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.436946,	
2017-06-19 14:16:48,275 Epoch[0] Batch [140]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.383178,	
2017-06-19 14:16:54,019 Epoch[0] Batch [150]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.344747,	
2017-06-19 14:16:59,679 Epoch[0] Batch [160]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.303639,	
2017-06-19 14:17:05,377 Epoch[0] Batch [170]	Speed: 5.26 samples/sec	Train-FCNLogLoss=1.263122,	
2017-06-19 14:17:11,716 Epoch[0] Batch [180]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.220037,	
2017-06-19 14:17:18,513 Epoch[0] Batch [190]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.188601,	
2017-06-19 14:17:24,747 Epoch[0] Batch [200]	Speed: 4.81 samples/sec	Train-FCNLogLoss=1.155385,	
2017-06-19 14:17:31,094 Epoch[0] Batch [210]	Speed: 4.73 samples/sec	Train-FCNLogLoss=1.122786,	
2017-06-19 14:17:37,623 Epoch[0] Batch [220]	Speed: 4.59 samples/sec	Train-FCNLogLoss=1.095043,	
2017-06-19 14:17:43,286 Epoch[0] Batch [230]	Speed: 5.30 samples/sec	Train-FCNLogLoss=1.072600,	
2017-06-19 14:17:49,019 Epoch[0] Batch [240]	Speed: 5.23 samples/sec	Train-FCNLogLoss=1.050309,	
2017-06-19 14:17:54,554 Epoch[0] Batch [250]	Speed: 5.42 samples/sec	Train-FCNLogLoss=1.027313,	
2017-06-19 14:18:00,124 Epoch[0] Batch [260]	Speed: 5.39 samples/sec	Train-FCNLogLoss=1.005242,	
2017-06-19 14:18:05,431 Epoch[0] Batch [270]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.986463,	
2017-06-19 14:18:10,616 Epoch[0] Batch [280]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.967607,	
2017-06-19 14:18:16,043 Epoch[0] Batch [290]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.950593,	
2017-06-19 14:18:21,433 Epoch[0] Batch [300]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.933164,	
2017-06-19 14:18:26,966 Epoch[0] Batch [310]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.919700,	
2017-06-19 14:18:32,755 Epoch[0] Batch [320]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.905236,	
2017-06-19 14:18:38,568 Epoch[0] Batch [330]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.890743,	
2017-06-19 14:18:43,778 Epoch[0] Batch [340]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.880347,	
2017-06-19 14:18:49,128 Epoch[0] Batch [350]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.869468,	
2017-06-19 14:18:54,882 Epoch[0] Batch [360]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.859953,	
2017-06-19 14:19:00,769 Epoch[0] Batch [370]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.849001,	
2017-06-19 14:19:06,397 Epoch[0] Batch [380]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.841243,	
2017-06-19 14:19:12,316 Epoch[0] Batch [390]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.831084,	
2017-06-19 14:19:18,105 Epoch[0] Batch [400]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.825402,	
2017-06-19 14:19:24,339 Epoch[0] Batch [410]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.815073,	
2017-06-19 14:19:30,638 Epoch[0] Batch [420]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.804952,	
2017-06-19 14:19:36,886 Epoch[0] Batch [430]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.798608,	
2017-06-19 14:19:42,628 Epoch[0] Batch [440]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.790091,	
2017-06-19 14:19:48,280 Epoch[0] Batch [450]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.780893,	
2017-06-19 14:19:54,161 Epoch[0] Batch [460]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.770837,	
2017-06-19 14:19:59,888 Epoch[0] Batch [470]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.762882,	
2017-06-19 14:20:05,339 Epoch[0] Batch [480]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.755133,	
2017-06-19 14:20:11,143 Epoch[0] Batch [490]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.746620,	
2017-06-19 14:20:17,094 Epoch[0] Batch [500]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.739688,	
2017-06-19 14:20:22,535 Epoch[0] Batch [510]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.733416,	
2017-06-19 14:20:28,101 Epoch[0] Batch [520]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.725875,	
2017-06-19 14:20:34,170 Epoch[0] Batch [530]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.719956,	
2017-06-19 14:20:39,901 Epoch[0] Batch [540]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.716334,	
2017-06-19 14:20:45,738 Epoch[0] Batch [550]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.709411,	
2017-06-19 14:20:51,435 Epoch[0] Batch [560]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.706342,	
2017-06-19 14:20:57,376 Epoch[0] Batch [570]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.701199,	
2017-06-19 14:21:03,103 Epoch[0] Batch [580]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.695268,	
2017-06-19 14:21:08,890 Epoch[0] Batch [590]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.689810,	
2017-06-19 14:21:14,428 Epoch[0] Batch [600]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.684780,	
2017-06-19 14:21:20,205 Epoch[0] Batch [610]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.680379,	
2017-06-19 14:21:26,182 Epoch[0] Batch [620]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.676082,	
2017-06-19 14:21:32,007 Epoch[0] Batch [630]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.672449,	
2017-06-19 14:21:38,045 Epoch[0] Batch [640]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.667583,	
2017-06-19 14:21:43,959 Epoch[0] Batch [650]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.662089,	
2017-06-19 14:21:49,668 Epoch[0] Batch [660]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.658950,	
2017-06-19 14:21:55,481 Epoch[0] Batch [670]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.655840,	
2017-06-19 14:22:01,851 Epoch[0] Batch [680]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.651406,	
2017-06-19 14:22:08,417 Epoch[0] Batch [690]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.647546,	
2017-06-19 14:22:14,228 Epoch[0] Batch [700]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.643864,	
2017-06-19 14:22:20,250 Epoch[0] Batch [710]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.640497,	
2017-06-19 14:22:26,407 Epoch[0] Batch [720]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.636866,	
2017-06-19 14:22:32,236 Epoch[0] Batch [730]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.633182,	
2017-06-19 14:22:38,733 Epoch[0] Batch [740]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.630168,	
2017-06-19 14:22:44,836 Epoch[0] Batch [750]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.626576,	
2017-06-19 14:22:50,466 Epoch[0] Batch [760]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.622567,	
2017-06-19 14:22:56,427 Epoch[0] Batch [770]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.619008,	
2017-06-19 14:23:02,493 Epoch[0] Batch [780]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.615664,	
2017-06-19 14:23:08,421 Epoch[0] Batch [790]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.612181,	
2017-06-19 14:23:14,317 Epoch[0] Batch [800]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.608897,	
2017-06-19 14:23:19,793 Epoch[0] Batch [810]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.605875,	
2017-06-19 14:23:28,372 Epoch[0] Batch [820]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.601583,	
2017-06-19 14:23:36,647 Epoch[0] Batch [830]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.598256,	
2017-06-19 14:23:46,666 Epoch[0] Batch [840]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.595329,	
2017-06-19 14:23:56,712 Epoch[0] Batch [850]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.592813,	
2017-06-19 14:24:05,906 Epoch[0] Batch [860]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.590766,	
2017-06-19 14:24:13,532 Epoch[0] Batch [870]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.587587,	
2017-06-19 14:24:23,265 Epoch[0] Batch [880]	Speed: 3.08 samples/sec	Train-FCNLogLoss=0.584773,	
2017-06-19 14:24:32,688 Epoch[0] Batch [890]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.582574,	
2017-06-19 14:24:42,288 Epoch[0] Batch [900]	Speed: 3.13 samples/sec	Train-FCNLogLoss=0.579747,	
2017-06-19 14:24:52,149 Epoch[0] Batch [910]	Speed: 3.04 samples/sec	Train-FCNLogLoss=0.577839,	
2017-06-19 14:25:03,548 Epoch[0] Batch [920]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.575092,	
2017-06-19 14:25:15,293 Epoch[0] Batch [930]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.571847,	
2017-06-19 14:25:26,605 Epoch[0] Batch [940]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.570186,	
2017-06-19 14:25:37,183 Epoch[0] Batch [950]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.568413,	
2017-06-19 14:25:48,647 Epoch[0] Batch [960]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.565957,	
2017-06-19 14:25:58,359 Epoch[0] Batch [970]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.564125,	
2017-06-19 14:26:09,473 Epoch[0] Batch [980]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.561860,	
2017-06-19 14:26:21,710 Epoch[0] Batch [990]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.559307,	
2017-06-19 14:26:35,172 Epoch[0] Batch [1000]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.558298,	
2017-06-19 14:26:48,399 Epoch[0] Batch [1010]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.559564,	
2017-06-19 14:27:00,363 Epoch[0] Batch [1020]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.561039,	
2017-06-19 14:27:14,473 Epoch[0] Batch [1030]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.561788,	
2017-06-19 14:27:27,626 Epoch[0] Batch [1040]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.562103,	
2017-06-19 14:27:40,613 Epoch[0] Batch [1050]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.561755,	
2017-06-19 14:27:52,227 Epoch[0] Batch [1060]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.561965,	
2017-06-19 14:28:03,826 Epoch[0] Batch [1070]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.560466,	
2017-06-19 14:28:16,198 Epoch[0] Batch [1080]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.559417,	
2017-06-19 14:28:28,101 Epoch[0] Batch [1090]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.557775,	
2017-06-19 14:28:39,036 Epoch[0] Batch [1100]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.557444,	
2017-06-19 14:28:50,374 Epoch[0] Batch [1110]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.558395,	
2017-06-19 14:29:01,437 Epoch[0] Batch [1120]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.557183,	
2017-06-19 14:29:12,757 Epoch[0] Batch [1130]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.556591,	
2017-06-19 14:29:23,834 Epoch[0] Batch [1140]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.554938,	
2017-06-19 14:29:37,076 Epoch[0] Batch [1150]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.555056,	
2017-06-19 14:29:48,335 Epoch[0] Batch [1160]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.555437,	
2017-06-19 14:29:59,104 Epoch[0] Batch [1170]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.555019,	
2017-06-19 14:30:10,052 Epoch[0] Batch [1180]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.553824,	
2017-06-19 14:30:21,965 Epoch[0] Batch [1190]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.552502,	
2017-06-19 14:30:34,255 Epoch[0] Batch [1200]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.551611,	
2017-06-19 14:30:46,713 Epoch[0] Batch [1210]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.550162,	
2017-06-19 14:30:57,606 Epoch[0] Batch [1220]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.548963,	
2017-06-19 14:31:09,086 Epoch[0] Batch [1230]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.546995,	
2017-06-19 14:31:24,051 Epoch[0] Batch [1240]	Speed: 2.00 samples/sec	Train-FCNLogLoss=0.544935,	
2017-06-19 14:31:37,326 Epoch[0] Batch [1250]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.542839,	
2017-06-19 14:31:48,663 Epoch[0] Batch [1260]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.541318,	
2017-06-19 14:32:00,791 Epoch[0] Batch [1270]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.539896,	
2017-06-19 14:32:12,664 Epoch[0] Batch [1280]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.538039,	
2017-06-19 14:32:24,737 Epoch[0] Batch [1290]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.536357,	
2017-06-19 14:32:38,841 Epoch[0] Batch [1300]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.534553,	
2017-06-19 14:32:51,931 Epoch[0] Batch [1310]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.533848,	
2017-06-19 14:33:05,271 Epoch[0] Batch [1320]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.532829,	
2017-06-19 14:33:18,999 Epoch[0] Batch [1330]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.531121,	
2017-06-19 14:33:31,854 Epoch[0] Batch [1340]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.529346,	
2017-06-19 14:33:44,696 Epoch[0] Batch [1350]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.528031,	
2017-06-19 14:33:57,793 Epoch[0] Batch [1360]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.526222,	
2017-06-19 14:34:12,747 Epoch[0] Batch [1370]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.525099,	
2017-06-19 14:34:25,293 Epoch[0] Batch [1380]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.523756,	
2017-06-19 14:34:38,926 Epoch[0] Batch [1390]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.522389,	
2017-06-19 14:34:52,018 Epoch[0] Batch [1400]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.520477,	
2017-06-19 14:35:03,526 Epoch[0] Batch [1410]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.519716,	
2017-06-19 14:35:14,269 Epoch[0] Batch [1420]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.517983,	
2017-06-19 14:35:27,715 Epoch[0] Batch [1430]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.516439,	
2017-06-19 14:35:34,242 Epoch[0] Batch [1440]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.514980,	
2017-06-19 14:35:40,825 Epoch[0] Batch [1450]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.513817,	
2017-06-19 14:35:47,840 Epoch[0] Batch [1460]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.512232,	
2017-06-19 14:35:54,380 Epoch[0] Batch [1470]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.510527,	
2017-06-19 14:36:00,928 Epoch[0] Batch [1480]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.509035,	
2017-06-19 14:36:08,112 Epoch[0] Batch [1490]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.508000,	
2017-06-19 14:36:14,881 Epoch[0] Batch [1500]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.506270,	
2017-06-19 14:36:21,363 Epoch[0] Batch [1510]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.504402,	
2017-06-19 14:36:27,666 Epoch[0] Batch [1520]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.502531,	
2017-06-19 14:36:33,968 Epoch[0] Batch [1530]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.500632,	
2017-06-19 14:36:40,837 Epoch[0] Batch [1540]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.499302,	
2017-06-19 14:36:47,428 Epoch[0] Batch [1550]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.497891,	
2017-06-19 14:36:54,303 Epoch[0] Batch [1560]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.496730,	
2017-06-19 14:37:01,194 Epoch[0] Batch [1570]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.495900,	
2017-06-19 14:37:07,955 Epoch[0] Batch [1580]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.494539,	
2017-06-19 14:37:15,913 Epoch[0] Batch [1590]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.494054,	
2017-06-19 14:37:24,561 Epoch[0] Batch [1600]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.492772,	
2017-06-19 14:37:34,198 Epoch[0] Batch [1610]	Speed: 3.11 samples/sec	Train-FCNLogLoss=0.491409,	
2017-06-19 14:37:45,273 Epoch[0] Batch [1620]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.490162,	
2017-06-19 14:37:55,300 Epoch[0] Batch [1630]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.488820,	
2017-06-19 14:38:07,824 Epoch[0] Batch [1640]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.487644,	
2017-06-19 14:38:19,733 Epoch[0] Batch [1650]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.486580,	
2017-06-19 14:38:31,985 Epoch[0] Batch [1660]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.485481,	
2017-06-19 14:38:44,591 Epoch[0] Batch [1670]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.483992,	
2017-06-19 14:38:57,525 Epoch[0] Batch [1680]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.482632,	
2017-06-19 14:39:08,386 Epoch[0] Batch [1690]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.482308,	
2017-06-19 14:39:19,375 Epoch[0] Batch [1700]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.481574,	
2017-06-19 14:39:26,096 Epoch[0] Batch [1710]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.480979,	
2017-06-19 14:39:32,476 Epoch[0] Batch [1720]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.479884,	
2017-06-19 14:39:38,874 Epoch[0] Batch [1730]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.478914,	
2017-06-19 14:39:45,371 Epoch[0] Batch [1740]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.477682,	
2017-06-19 14:39:51,357 Epoch[0] Batch [1750]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.476488,	
2017-06-19 14:39:57,129 Epoch[0] Batch [1760]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.475521,	
2017-06-19 14:40:03,221 Epoch[0] Batch [1770]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.474206,	
2017-06-19 14:40:09,643 Epoch[0] Batch [1780]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.473199,	
2017-06-19 14:40:16,355 Epoch[0] Batch [1790]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.472218,	
2017-06-19 14:40:22,800 Epoch[0] Batch [1800]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.471216,	
2017-06-19 14:40:29,415 Epoch[0] Batch [1810]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.469958,	
2017-06-19 14:40:35,568 Epoch[0] Batch [1820]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.468971,	
2017-06-19 14:40:41,667 Epoch[0] Batch [1830]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.467897,	
2017-06-19 14:40:47,810 Epoch[0] Batch [1840]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.466896,	
2017-06-19 14:40:53,668 Epoch[0] Batch [1850]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.465948,	
2017-06-19 14:41:00,260 Epoch[0] Batch [1860]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.464814,	
2017-06-19 14:41:07,179 Epoch[0] Batch [1870]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.463729,	
2017-06-19 14:41:13,576 Epoch[0] Batch [1880]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.462394,	
2017-06-19 14:41:19,734 Epoch[0] Batch [1890]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.461258,	
2017-06-19 14:41:25,913 Epoch[0] Batch [1900]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.460497,	
2017-06-19 14:41:32,494 Epoch[0] Batch [1910]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.459691,	
2017-06-19 14:41:39,066 Epoch[0] Batch [1920]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.459431,	
2017-06-19 14:41:45,392 Epoch[0] Batch [1930]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.458436,	
2017-06-19 14:41:51,374 Epoch[0] Batch [1940]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.457885,	
2017-06-19 14:41:57,867 Epoch[0] Batch [1950]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.457177,	
2017-06-19 14:42:04,120 Epoch[0] Batch [1960]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.456135,	
2017-06-19 14:42:10,715 Epoch[0] Batch [1970]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.455260,	
2017-06-19 14:42:17,331 Epoch[0] Batch [1980]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.454353,	
2017-06-19 14:42:18,680 Epoch[0] Train-FCNLogLoss=0.454139
2017-06-19 14:42:18,681 Epoch[0] Time cost=1638.549
2017-06-19 14:42:20,408 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.params"
2017-06-19 14:42:22,406 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.states"
2017-06-19 14:42:29,630 Epoch[1] Batch [10]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.281657,	
2017-06-19 14:42:35,474 Epoch[1] Batch [20]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.305639,	
2017-06-19 14:42:40,882 Epoch[1] Batch [30]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.292618,	
2017-06-19 14:42:46,690 Epoch[1] Batch [40]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.285874,	
2017-06-19 14:42:52,683 Epoch[1] Batch [50]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.289065,	
2017-06-19 14:42:58,291 Epoch[1] Batch [60]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.282235,	
2017-06-19 14:43:03,645 Epoch[1] Batch [70]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.274827,	
2017-06-19 14:43:09,296 Epoch[1] Batch [80]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.274332,	
2017-06-19 14:43:15,407 Epoch[1] Batch [90]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.274759,	
2017-06-19 14:43:21,030 Epoch[1] Batch [100]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.274196,	
2017-06-19 14:43:27,173 Epoch[1] Batch [110]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.272406,	
2017-06-19 14:43:32,773 Epoch[1] Batch [120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.270298,	
2017-06-19 14:43:38,691 Epoch[1] Batch [130]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.267939,	
2017-06-19 14:43:44,403 Epoch[1] Batch [140]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.266102,	
2017-06-19 14:43:49,869 Epoch[1] Batch [150]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.264822,	
2017-06-19 14:43:55,466 Epoch[1] Batch [160]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.261879,	
2017-06-19 14:44:01,345 Epoch[1] Batch [170]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.266232,	
2017-06-19 14:44:07,381 Epoch[1] Batch [180]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.265779,	
2017-06-19 14:44:13,108 Epoch[1] Batch [190]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.263890,	
2017-06-19 14:44:18,693 Epoch[1] Batch [200]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.265097,	
2017-06-19 14:44:24,675 Epoch[1] Batch [210]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.264147,	
2017-06-19 14:44:30,321 Epoch[1] Batch [220]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.262944,	
2017-06-19 14:44:36,070 Epoch[1] Batch [230]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.263081,	
2017-06-19 14:44:41,401 Epoch[1] Batch [240]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.261325,	
2017-06-19 14:44:47,124 Epoch[1] Batch [250]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.261463,	
2017-06-19 14:44:52,694 Epoch[1] Batch [260]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.259008,	
2017-06-19 14:44:58,562 Epoch[1] Batch [270]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.258057,	
2017-06-19 14:45:04,347 Epoch[1] Batch [280]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.255838,	
2017-06-19 14:45:10,010 Epoch[1] Batch [290]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.253608,	
2017-06-19 14:45:15,992 Epoch[1] Batch [300]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.253219,	
2017-06-19 14:45:22,607 Epoch[1] Batch [310]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.252850,	
2017-06-19 14:45:28,487 Epoch[1] Batch [320]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.253041,	
2017-06-19 14:45:34,093 Epoch[1] Batch [330]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.253206,	
2017-06-19 14:45:39,583 Epoch[1] Batch [340]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.252221,	
2017-06-19 14:45:45,772 Epoch[1] Batch [350]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.252674,	
2017-06-19 14:45:51,466 Epoch[1] Batch [360]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.252437,	
2017-06-19 14:45:57,093 Epoch[1] Batch [370]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.252010,	
2017-06-19 14:46:02,631 Epoch[1] Batch [380]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.250568,	
2017-06-19 14:46:08,601 Epoch[1] Batch [390]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.250746,	
2017-06-19 14:46:14,300 Epoch[1] Batch [400]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.250026,	
2017-06-19 14:46:20,011 Epoch[1] Batch [410]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.248448,	
2017-06-19 14:46:25,298 Epoch[1] Batch [420]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.247084,	
2017-06-19 14:46:31,144 Epoch[1] Batch [430]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.247383,	
2017-06-19 14:46:36,550 Epoch[1] Batch [440]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.247241,	
2017-06-19 14:46:41,683 Epoch[1] Batch [450]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.246688,	
2017-06-19 14:46:47,037 Epoch[1] Batch [460]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.246464,	
2017-06-19 14:46:52,492 Epoch[1] Batch [470]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.247192,	
2017-06-19 14:46:58,003 Epoch[1] Batch [480]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.248136,	
2017-06-19 14:47:03,665 Epoch[1] Batch [490]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.249275,	
2017-06-19 14:47:09,717 Epoch[1] Batch [500]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.249804,	
2017-06-19 14:47:15,556 Epoch[1] Batch [510]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.248844,	
2017-06-19 14:47:22,505 Epoch[1] Batch [520]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.248153,	
2017-06-19 14:47:28,395 Epoch[1] Batch [530]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.247897,	
2017-06-19 14:47:34,106 Epoch[1] Batch [540]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.247547,	
2017-06-19 14:47:39,612 Epoch[1] Batch [550]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.249540,	
2017-06-19 14:47:45,734 Epoch[1] Batch [560]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.250573,	
2017-06-19 14:47:51,782 Epoch[1] Batch [570]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.250457,	
2017-06-19 14:47:57,989 Epoch[1] Batch [580]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.251405,	
2017-06-19 14:48:03,765 Epoch[1] Batch [590]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.251375,	
2017-06-19 14:48:09,354 Epoch[1] Batch [600]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.251929,	
2017-06-19 14:48:15,194 Epoch[1] Batch [610]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.251664,	
2017-06-19 14:48:21,062 Epoch[1] Batch [620]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.251915,	
2017-06-19 14:48:28,244 Epoch[1] Batch [630]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.251824,	
2017-06-19 14:48:36,281 Epoch[1] Batch [640]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.251000,	
2017-06-19 14:48:45,738 Epoch[1] Batch [650]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.250369,	
2017-06-19 14:48:57,926 Epoch[1] Batch [660]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.250215,	
2017-06-19 14:49:10,160 Epoch[1] Batch [670]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.250363,	
2017-06-19 14:49:21,629 Epoch[1] Batch [680]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.250497,	
2017-06-19 14:49:32,495 Epoch[1] Batch [690]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.251246,	
2017-06-19 14:49:43,863 Epoch[1] Batch [700]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.250926,	
2017-06-19 14:49:55,439 Epoch[1] Batch [710]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.250985,	
2017-06-19 14:50:06,821 Epoch[1] Batch [720]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.250499,	
2017-06-19 14:50:18,981 Epoch[1] Batch [730]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.250061,	
2017-06-19 14:50:32,768 Epoch[1] Batch [740]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.249220,	
2017-06-19 14:50:44,241 Epoch[1] Batch [750]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.248442,	
2017-06-19 14:50:56,080 Epoch[1] Batch [760]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.247678,	
2017-06-19 14:51:07,901 Epoch[1] Batch [770]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.246882,	
2017-06-19 14:51:19,304 Epoch[1] Batch [780]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.246535,	
2017-06-19 14:51:31,798 Epoch[1] Batch [790]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.247294,	
2017-06-19 14:51:43,758 Epoch[1] Batch [800]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.247525,	
2017-06-19 14:51:55,473 Epoch[1] Batch [810]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.247796,	
2017-06-19 14:52:06,499 Epoch[1] Batch [820]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.247381,	
2017-06-19 14:52:19,439 Epoch[1] Batch [830]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.247280,	
2017-06-19 14:52:31,966 Epoch[1] Batch [840]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.247130,	
2017-06-19 14:52:43,640 Epoch[1] Batch [850]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.246959,	
2017-06-19 14:52:56,342 Epoch[1] Batch [860]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.246919,	
2017-06-19 14:53:07,760 Epoch[1] Batch [870]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.247259,	
2017-06-19 14:53:19,329 Epoch[1] Batch [880]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.246866,	
2017-06-19 14:53:31,546 Epoch[1] Batch [890]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.246516,	
2017-06-19 14:53:42,624 Epoch[1] Batch [900]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.246321,	
2017-06-19 14:53:53,943 Epoch[1] Batch [910]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.245831,	
2017-06-19 14:54:05,682 Epoch[1] Batch [920]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.245468,	
2017-06-19 14:54:17,705 Epoch[1] Batch [930]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.245088,	
2017-06-19 14:54:28,904 Epoch[1] Batch [940]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.245154,	
2017-06-19 14:54:39,860 Epoch[1] Batch [950]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.245592,	
2017-06-19 14:54:51,817 Epoch[1] Batch [960]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.245868,	
2017-06-19 14:55:05,219 Epoch[1] Batch [970]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.246926,	
2017-06-19 14:55:17,106 Epoch[1] Batch [980]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.247015,	
2017-06-19 14:55:29,223 Epoch[1] Batch [990]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.246696,	
2017-06-19 14:55:40,934 Epoch[1] Batch [1000]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.246802,	
2017-06-19 14:55:51,937 Epoch[1] Batch [1010]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.247705,	
2017-06-19 14:56:03,875 Epoch[1] Batch [1020]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.247802,	
2017-06-19 14:56:15,140 Epoch[1] Batch [1030]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.248093,	
2017-06-19 14:56:26,367 Epoch[1] Batch [1040]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.248395,	
2017-06-19 14:56:39,571 Epoch[1] Batch [1050]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.248440,	
2017-06-19 14:56:50,971 Epoch[1] Batch [1060]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.248132,	
2017-06-19 14:57:03,076 Epoch[1] Batch [1070]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.247731,	
2017-06-19 14:57:14,714 Epoch[1] Batch [1080]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.248278,	
2017-06-19 14:57:26,802 Epoch[1] Batch [1090]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.248154,	
2017-06-19 14:57:38,524 Epoch[1] Batch [1100]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.247685,	
2017-06-19 14:57:50,249 Epoch[1] Batch [1110]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.247264,	
2017-06-19 14:58:01,028 Epoch[1] Batch [1120]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.247152,	
2017-06-19 14:58:12,164 Epoch[1] Batch [1130]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.247150,	
2017-06-19 14:58:23,057 Epoch[1] Batch [1140]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.246982,	
2017-06-19 14:58:34,256 Epoch[1] Batch [1150]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.246449,	
2017-06-19 14:58:44,299 Epoch[1] Batch [1160]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.246035,	
2017-06-19 14:58:55,243 Epoch[1] Batch [1170]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.245604,	
2017-06-19 14:59:06,551 Epoch[1] Batch [1180]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.245397,	
2017-06-19 14:59:17,391 Epoch[1] Batch [1190]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.244960,	
2017-06-19 14:59:28,655 Epoch[1] Batch [1200]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.244737,	
2017-06-19 14:59:39,511 Epoch[1] Batch [1210]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.244407,	
2017-06-19 14:59:50,925 Epoch[1] Batch [1220]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.244252,	
2017-06-19 15:00:01,537 Epoch[1] Batch [1230]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.244295,	
2017-06-19 15:00:13,404 Epoch[1] Batch [1240]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.244210,	
2017-06-19 15:00:25,144 Epoch[1] Batch [1250]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.243848,	
2017-06-19 15:00:36,128 Epoch[1] Batch [1260]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.243581,	
2017-06-19 15:00:47,433 Epoch[1] Batch [1270]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.243291,	
2017-06-19 15:00:58,958 Epoch[1] Batch [1280]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.243069,	
2017-06-19 15:01:09,479 Epoch[1] Batch [1290]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.242808,	
2017-06-19 15:01:20,792 Epoch[1] Batch [1300]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.242951,	
2017-06-19 15:01:32,625 Epoch[1] Batch [1310]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.242932,	
2017-06-19 15:01:43,454 Epoch[1] Batch [1320]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.242880,	
2017-06-19 15:01:54,283 Epoch[1] Batch [1330]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.243073,	
2017-06-19 15:02:05,924 Epoch[1] Batch [1340]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.242778,	
2017-06-19 15:02:16,642 Epoch[1] Batch [1350]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.242637,	
2017-06-19 15:02:26,994 Epoch[1] Batch [1360]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.242238,	
2017-06-19 15:02:37,151 Epoch[1] Batch [1370]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.242324,	
2017-06-19 15:02:48,356 Epoch[1] Batch [1380]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.242393,	
2017-06-19 15:02:59,171 Epoch[1] Batch [1390]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.242449,	
2017-06-19 15:03:10,213 Epoch[1] Batch [1400]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.242212,	
2017-06-19 15:03:20,649 Epoch[1] Batch [1410]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.241891,	
2017-06-19 15:03:31,170 Epoch[1] Batch [1420]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.241527,	
2017-06-19 15:03:42,541 Epoch[1] Batch [1430]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.241311,	
2017-06-19 15:03:52,905 Epoch[1] Batch [1440]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.242191,	
2017-06-19 15:03:59,814 Epoch[1] Batch [1450]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.242668,	
2017-06-19 15:04:05,251 Epoch[1] Batch [1460]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.242516,	
2017-06-19 15:04:10,962 Epoch[1] Batch [1470]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.242395,	
2017-06-19 15:04:16,605 Epoch[1] Batch [1480]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.242632,	
2017-06-19 15:04:22,252 Epoch[1] Batch [1490]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.242535,	
2017-06-19 15:04:27,911 Epoch[1] Batch [1500]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.242801,	
2017-06-19 15:04:33,774 Epoch[1] Batch [1510]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.242577,	
2017-06-19 15:04:39,532 Epoch[1] Batch [1520]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.242239,	
2017-06-19 15:04:44,828 Epoch[1] Batch [1530]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.242089,	
2017-06-19 15:04:50,381 Epoch[1] Batch [1540]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.242005,	
2017-06-19 15:04:55,867 Epoch[1] Batch [1550]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.241830,	
2017-06-19 15:05:01,348 Epoch[1] Batch [1560]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.241631,	
2017-06-19 15:05:06,523 Epoch[1] Batch [1570]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.241331,	
2017-06-19 15:05:11,870 Epoch[1] Batch [1580]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.241071,	
2017-06-19 15:05:17,873 Epoch[1] Batch [1590]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.241193,	
2017-06-19 15:05:23,723 Epoch[1] Batch [1600]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.241160,	
2017-06-19 15:05:29,288 Epoch[1] Batch [1610]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.240905,	
2017-06-19 15:05:35,231 Epoch[1] Batch [1620]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.240734,	
2017-06-19 15:05:41,104 Epoch[1] Batch [1630]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.240620,	
2017-06-19 15:05:46,835 Epoch[1] Batch [1640]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.240765,	
2017-06-19 15:05:52,404 Epoch[1] Batch [1650]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.240725,	
2017-06-19 15:05:58,255 Epoch[1] Batch [1660]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.240450,	
2017-06-19 15:06:03,825 Epoch[1] Batch [1670]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.240276,	
2017-06-19 15:06:09,656 Epoch[1] Batch [1680]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.240036,	
2017-06-19 15:06:15,382 Epoch[1] Batch [1690]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.239695,	
2017-06-19 15:06:20,959 Epoch[1] Batch [1700]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.239307,	
2017-06-19 15:06:26,604 Epoch[1] Batch [1710]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.239269,	
2017-06-19 15:06:32,054 Epoch[1] Batch [1720]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.238916,	
2017-06-19 15:06:37,574 Epoch[1] Batch [1730]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.238906,	
2017-06-19 15:06:43,258 Epoch[1] Batch [1740]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.238811,	
2017-06-19 15:06:49,287 Epoch[1] Batch [1750]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.239128,	
2017-06-19 15:06:54,966 Epoch[1] Batch [1760]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.239087,	
2017-06-19 15:07:00,578 Epoch[1] Batch [1770]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.238830,	
2017-06-19 15:07:06,203 Epoch[1] Batch [1780]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.238498,	
2017-06-19 15:07:11,721 Epoch[1] Batch [1790]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.238265,	
2017-06-19 15:07:17,224 Epoch[1] Batch [1800]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.238100,	
2017-06-19 15:07:23,013 Epoch[1] Batch [1810]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.237885,	
2017-06-19 15:07:28,920 Epoch[1] Batch [1820]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.237622,	
2017-06-19 15:07:34,617 Epoch[1] Batch [1830]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.237499,	
2017-06-19 15:07:40,193 Epoch[1] Batch [1840]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.237419,	
2017-06-19 15:07:46,190 Epoch[1] Batch [1850]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.237453,	
2017-06-19 15:07:51,642 Epoch[1] Batch [1860]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.237275,	
2017-06-19 15:07:57,319 Epoch[1] Batch [1870]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.237361,	
2017-06-19 15:08:03,160 Epoch[1] Batch [1880]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.237149,	
2017-06-19 15:08:08,690 Epoch[1] Batch [1890]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.237257,	
2017-06-19 15:08:14,063 Epoch[1] Batch [1900]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.237004,	
2017-06-19 15:08:19,749 Epoch[1] Batch [1910]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.236988,	
2017-06-19 15:08:25,903 Epoch[1] Batch [1920]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.236974,	
2017-06-19 15:08:31,922 Epoch[1] Batch [1930]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.236835,	
2017-06-19 15:08:37,598 Epoch[1] Batch [1940]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.237031,	
2017-06-19 15:08:42,720 Epoch[1] Batch [1950]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.236820,	
2017-06-19 15:08:47,952 Epoch[1] Batch [1960]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.236732,	
2017-06-19 15:08:53,257 Epoch[1] Batch [1970]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.236561,	
2017-06-19 15:08:58,940 Epoch[1] Batch [1980]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.236593,	
2017-06-19 15:08:59,912 Epoch[1] Train-FCNLogLoss=0.236507
2017-06-19 15:08:59,913 Epoch[1] Time cost=1597.462
2017-06-19 15:09:00,843 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0002.params"
2017-06-19 15:09:02,842 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0002.states"
2017-06-19 15:09:09,096 Epoch[2] Batch [10]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.225761,	
2017-06-19 15:09:15,138 Epoch[2] Batch [20]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.227002,	
2017-06-19 15:09:21,186 Epoch[2] Batch [30]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.225955,	
2017-06-19 15:09:26,965 Epoch[2] Batch [40]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.214002,	
2017-06-19 15:09:32,449 Epoch[2] Batch [50]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.216354,	
2017-06-19 15:09:38,081 Epoch[2] Batch [60]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.216826,	
2017-06-19 15:09:43,645 Epoch[2] Batch [70]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.217857,	
2017-06-19 15:09:49,669 Epoch[2] Batch [80]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.217492,	
2017-06-19 15:09:55,468 Epoch[2] Batch [90]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.214991,	
2017-06-19 15:10:01,224 Epoch[2] Batch [100]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.210717,	
2017-06-19 15:10:07,155 Epoch[2] Batch [110]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.212808,	
2017-06-19 15:10:12,740 Epoch[2] Batch [120]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.214911,	
2017-06-19 15:10:18,317 Epoch[2] Batch [130]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.212395,	
2017-06-19 15:10:23,759 Epoch[2] Batch [140]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.212855,	
2017-06-19 15:10:29,387 Epoch[2] Batch [150]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.213187,	
2017-06-19 15:10:34,969 Epoch[2] Batch [160]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.213448,	
2017-06-19 15:10:40,437 Epoch[2] Batch [170]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.210425,	
2017-06-19 15:10:46,244 Epoch[2] Batch [180]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.207525,	
2017-06-19 15:10:51,752 Epoch[2] Batch [190]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.206716,	
2017-06-19 15:10:57,412 Epoch[2] Batch [200]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.204746,	
2017-06-19 15:11:02,975 Epoch[2] Batch [210]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.205272,	
2017-06-19 15:11:08,390 Epoch[2] Batch [220]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.206005,	
2017-06-19 15:11:14,132 Epoch[2] Batch [230]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.205699,	
2017-06-19 15:11:19,490 Epoch[2] Batch [240]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.205029,	
2017-06-19 15:11:24,929 Epoch[2] Batch [250]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.205599,	
2017-06-19 15:11:30,733 Epoch[2] Batch [260]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.205096,	
2017-06-19 15:11:36,221 Epoch[2] Batch [270]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.204614,	
2017-06-19 15:11:41,614 Epoch[2] Batch [280]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.203932,	
2017-06-19 15:11:47,461 Epoch[2] Batch [290]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.203767,	
2017-06-19 15:11:53,351 Epoch[2] Batch [300]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.205469,	
2017-06-19 15:11:59,139 Epoch[2] Batch [310]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.205456,	
2017-06-19 15:12:04,556 Epoch[2] Batch [320]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.204438,	
2017-06-19 15:12:10,292 Epoch[2] Batch [330]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.203347,	
2017-06-19 15:12:15,780 Epoch[2] Batch [340]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.202538,	
2017-06-19 15:12:21,507 Epoch[2] Batch [350]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.201965,	
2017-06-19 15:12:27,077 Epoch[2] Batch [360]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.202859,	
2017-06-19 15:12:32,760 Epoch[2] Batch [370]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.202548,	
2017-06-19 15:12:38,345 Epoch[2] Batch [380]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.202553,	
2017-06-19 15:12:43,947 Epoch[2] Batch [390]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.202330,	
2017-06-19 15:12:49,471 Epoch[2] Batch [400]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.202229,	
2017-06-19 15:12:55,241 Epoch[2] Batch [410]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.202768,	
2017-06-19 15:13:00,844 Epoch[2] Batch [420]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.201648,	
2017-06-19 15:13:06,970 Epoch[2] Batch [430]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.200932,	
2017-06-19 15:13:12,450 Epoch[2] Batch [440]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.200397,	
2017-06-19 15:13:18,138 Epoch[2] Batch [450]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.199834,	
2017-06-19 15:13:24,201 Epoch[2] Batch [460]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.199586,	
2017-06-19 15:13:29,947 Epoch[2] Batch [470]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.200176,	
2017-06-19 15:13:35,697 Epoch[2] Batch [480]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.199257,	
2017-06-19 15:13:41,460 Epoch[2] Batch [490]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.198594,	
2017-06-19 15:13:47,123 Epoch[2] Batch [500]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.198546,	
2017-06-19 15:13:52,842 Epoch[2] Batch [510]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.198548,	
2017-06-19 15:13:58,404 Epoch[2] Batch [520]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.198568,	
2017-06-19 15:14:04,067 Epoch[2] Batch [530]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.198254,	
2017-06-19 15:14:09,590 Epoch[2] Batch [540]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.198047,	
2017-06-19 15:14:14,877 Epoch[2] Batch [550]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.197607,	
2017-06-19 15:14:20,743 Epoch[2] Batch [560]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.197906,	
2017-06-19 15:14:26,392 Epoch[2] Batch [570]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.197431,	
2017-06-19 15:14:31,956 Epoch[2] Batch [580]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.196681,	
2017-06-19 15:14:37,453 Epoch[2] Batch [590]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.196753,	
2017-06-19 15:14:43,344 Epoch[2] Batch [600]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.196848,	
2017-06-19 15:14:49,124 Epoch[2] Batch [610]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.196608,	
2017-06-19 15:14:54,922 Epoch[2] Batch [620]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.196341,	
2017-06-19 15:15:00,960 Epoch[2] Batch [630]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.196154,	
2017-06-19 15:15:07,059 Epoch[2] Batch [640]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.196270,	
2017-06-19 15:15:13,038 Epoch[2] Batch [650]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.196372,	
2017-06-19 15:15:19,055 Epoch[2] Batch [660]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.196445,	
2017-06-19 15:15:24,989 Epoch[2] Batch [670]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.196369,	
2017-06-19 15:15:31,145 Epoch[2] Batch [680]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.196251,	
2017-06-19 15:15:37,014 Epoch[2] Batch [690]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.196735,	
2017-06-19 15:15:42,898 Epoch[2] Batch [700]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.196430,	
2017-06-19 15:15:48,798 Epoch[2] Batch [710]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.196839,	
2017-06-19 15:15:55,025 Epoch[2] Batch [720]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.196873,	
2017-06-19 15:16:01,173 Epoch[2] Batch [730]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.198439,	
2017-06-19 15:16:06,887 Epoch[2] Batch [740]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.198849,	
2017-06-19 15:16:12,883 Epoch[2] Batch [750]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.199257,	
2017-06-19 15:16:18,866 Epoch[2] Batch [760]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.199407,	
2017-06-19 15:16:24,808 Epoch[2] Batch [770]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.199332,	
2017-06-19 15:16:30,728 Epoch[2] Batch [780]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.199351,	
2017-06-19 15:16:36,535 Epoch[2] Batch [790]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.199277,	
2017-06-19 15:16:42,284 Epoch[2] Batch [800]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.199463,	
2017-06-19 15:16:47,952 Epoch[2] Batch [810]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.198863,	
2017-06-19 15:16:53,784 Epoch[2] Batch [820]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.198827,	
2017-06-19 15:16:59,970 Epoch[2] Batch [830]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.199602,	
2017-06-19 15:17:05,705 Epoch[2] Batch [840]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.199947,	
2017-06-19 15:17:11,454 Epoch[2] Batch [850]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.200763,	
2017-06-19 15:17:17,184 Epoch[2] Batch [860]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.200940,	
2017-06-19 15:17:22,674 Epoch[2] Batch [870]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.200911,	
2017-06-19 15:17:28,224 Epoch[2] Batch [880]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.200893,	
2017-06-19 15:17:34,540 Epoch[2] Batch [890]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.200993,	
2017-06-19 15:17:40,199 Epoch[2] Batch [900]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.200855,	
2017-06-19 15:17:46,083 Epoch[2] Batch [910]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.201143,	
2017-06-19 15:17:52,542 Epoch[2] Batch [920]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.200945,	
2017-06-19 15:17:58,079 Epoch[2] Batch [930]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.200739,	
2017-06-19 15:18:04,370 Epoch[2] Batch [940]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.200689,	
2017-06-19 15:18:10,246 Epoch[2] Batch [950]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.200528,	
2017-06-19 15:18:16,087 Epoch[2] Batch [960]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.200154,	
2017-06-19 15:18:21,926 Epoch[2] Batch [970]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.200119,	
2017-06-19 15:18:27,955 Epoch[2] Batch [980]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.200325,	
2017-06-19 15:18:33,461 Epoch[2] Batch [990]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.200538,	
2017-06-19 15:18:39,194 Epoch[2] Batch [1000]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.200980,	
2017-06-19 15:18:45,103 Epoch[2] Batch [1010]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.201012,	
2017-06-19 15:18:51,186 Epoch[2] Batch [1020]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.200899,	
2017-06-19 15:18:56,997 Epoch[2] Batch [1030]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.200718,	
2017-06-19 15:19:02,668 Epoch[2] Batch [1040]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.200555,	
2017-06-19 15:19:08,211 Epoch[2] Batch [1050]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.200572,	
2017-06-19 15:19:14,354 Epoch[2] Batch [1060]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.200194,	
2017-06-19 15:19:19,997 Epoch[2] Batch [1070]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.200200,	
2017-06-19 15:19:25,642 Epoch[2] Batch [1080]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.200023,	
2017-06-19 15:19:31,718 Epoch[2] Batch [1090]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.200089,	
2017-06-19 15:19:37,327 Epoch[2] Batch [1100]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.200118,	
2017-06-19 15:19:43,241 Epoch[2] Batch [1110]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.200088,	
2017-06-19 15:19:48,785 Epoch[2] Batch [1120]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.200195,	
2017-06-19 15:19:54,452 Epoch[2] Batch [1130]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.200113,	
2017-06-19 15:20:00,002 Epoch[2] Batch [1140]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.200057,	
2017-06-19 15:20:05,852 Epoch[2] Batch [1150]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.200267,	
2017-06-19 15:20:11,283 Epoch[2] Batch [1160]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.200188,	
2017-06-19 15:20:16,855 Epoch[2] Batch [1170]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.200468,	
2017-06-19 15:20:22,739 Epoch[2] Batch [1180]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.200300,	
2017-06-19 15:20:28,447 Epoch[2] Batch [1190]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.200400,	
2017-06-19 15:20:34,185 Epoch[2] Batch [1200]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.200254,	
2017-06-19 15:20:39,637 Epoch[2] Batch [1210]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.200184,	
2017-06-19 15:20:45,470 Epoch[2] Batch [1220]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.200072,	
2017-06-19 15:20:51,297 Epoch[2] Batch [1230]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.200015,	
2017-06-19 15:20:57,588 Epoch[2] Batch [1240]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.199847,	
2017-06-19 15:21:03,499 Epoch[2] Batch [1250]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.199729,	
2017-06-19 15:21:09,340 Epoch[2] Batch [1260]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.199903,	
2017-06-19 15:21:15,492 Epoch[2] Batch [1270]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.200228,	
2017-06-19 15:21:21,453 Epoch[2] Batch [1280]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.200371,	
2017-06-19 15:21:27,392 Epoch[2] Batch [1290]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.200243,	
2017-06-19 15:21:33,530 Epoch[2] Batch [1300]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.200222,	
2017-06-19 15:21:39,548 Epoch[2] Batch [1310]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.200140,	
2017-06-19 15:21:44,920 Epoch[2] Batch [1320]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.200061,	
2017-06-19 15:21:50,757 Epoch[2] Batch [1330]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.199892,	
2017-06-19 15:21:56,269 Epoch[2] Batch [1340]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.199831,	
2017-06-19 15:22:02,161 Epoch[2] Batch [1350]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.199534,	
2017-06-19 15:22:08,334 Epoch[2] Batch [1360]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.199417,	
2017-06-19 15:22:14,477 Epoch[2] Batch [1370]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.199428,	
2017-06-19 15:22:20,406 Epoch[2] Batch [1380]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.199090,	
2017-06-19 15:22:26,158 Epoch[2] Batch [1390]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.199126,	
2017-06-19 15:22:32,287 Epoch[2] Batch [1400]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.198817,	
2017-06-19 15:22:38,509 Epoch[2] Batch [1410]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.198632,	
2017-06-19 15:22:44,284 Epoch[2] Batch [1420]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.198461,	
2017-06-19 15:22:50,433 Epoch[2] Batch [1430]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.198248,	
2017-06-19 15:22:55,863 Epoch[2] Batch [1440]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.198281,	
2017-06-19 15:23:01,491 Epoch[2] Batch [1450]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.198279,	

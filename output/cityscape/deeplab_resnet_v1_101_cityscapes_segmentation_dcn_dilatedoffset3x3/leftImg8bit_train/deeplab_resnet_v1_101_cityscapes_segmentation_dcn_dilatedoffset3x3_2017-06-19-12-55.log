2017-06-19 12:55:21,548 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data01/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data01/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn_dilatedoffset3x3'}

2017-06-19 12:56:31,287 Epoch[0] Batch [10]	Speed: 2.15 samples/sec	Train-FCNLogLoss=2.895081,	
2017-06-19 12:56:42,015 Epoch[0] Batch [20]	Speed: 1.86 samples/sec	Train-FCNLogLoss=2.849865,	
2017-06-19 12:56:51,579 Epoch[0] Batch [30]	Speed: 2.09 samples/sec	Train-FCNLogLoss=2.748427,	
2017-06-19 12:57:02,448 Epoch[0] Batch [40]	Speed: 1.84 samples/sec	Train-FCNLogLoss=2.642630,	
2017-06-19 12:57:12,218 Epoch[0] Batch [50]	Speed: 2.05 samples/sec	Train-FCNLogLoss=2.488190,	
2017-06-19 12:57:22,316 Epoch[0] Batch [60]	Speed: 1.98 samples/sec	Train-FCNLogLoss=2.330497,	
2017-06-19 12:57:31,827 Epoch[0] Batch [70]	Speed: 2.10 samples/sec	Train-FCNLogLoss=2.214588,	
2017-06-19 12:57:41,292 Epoch[0] Batch [80]	Speed: 2.11 samples/sec	Train-FCNLogLoss=2.079400,	
2017-06-19 12:57:50,068 Epoch[0] Batch [90]	Speed: 2.28 samples/sec	Train-FCNLogLoss=1.974711,	
2017-06-19 12:57:59,080 Epoch[0] Batch [100]	Speed: 2.22 samples/sec	Train-FCNLogLoss=1.874810,	
2017-06-19 12:58:08,430 Epoch[0] Batch [110]	Speed: 2.14 samples/sec	Train-FCNLogLoss=1.786428,	
2017-06-19 12:58:17,903 Epoch[0] Batch [120]	Speed: 2.11 samples/sec	Train-FCNLogLoss=1.710583,	
2017-06-19 12:58:27,246 Epoch[0] Batch [130]	Speed: 2.14 samples/sec	Train-FCNLogLoss=1.627377,	
2017-06-19 12:58:36,235 Epoch[0] Batch [140]	Speed: 2.22 samples/sec	Train-FCNLogLoss=1.568356,	
2017-06-19 12:58:46,421 Epoch[0] Batch [150]	Speed: 1.96 samples/sec	Train-FCNLogLoss=1.525535,	
2017-06-19 12:58:56,884 Epoch[0] Batch [160]	Speed: 1.91 samples/sec	Train-FCNLogLoss=1.471771,	
2017-06-19 12:59:05,983 Epoch[0] Batch [170]	Speed: 2.20 samples/sec	Train-FCNLogLoss=1.418353,	
2017-06-19 12:59:15,305 Epoch[0] Batch [180]	Speed: 2.15 samples/sec	Train-FCNLogLoss=1.373649,	
2017-06-19 12:59:24,166 Epoch[0] Batch [190]	Speed: 2.26 samples/sec	Train-FCNLogLoss=1.332139,	
2017-06-19 12:59:33,427 Epoch[0] Batch [200]	Speed: 2.16 samples/sec	Train-FCNLogLoss=1.298237,	
2017-06-19 12:59:43,999 Epoch[0] Batch [210]	Speed: 1.89 samples/sec	Train-FCNLogLoss=1.273186,	
2017-06-19 12:59:52,883 Epoch[0] Batch [220]	Speed: 2.25 samples/sec	Train-FCNLogLoss=1.246094,	
2017-06-19 13:00:00,868 Epoch[0] Batch [230]	Speed: 2.50 samples/sec	Train-FCNLogLoss=1.217792,	
2017-06-19 13:00:08,735 Epoch[0] Batch [240]	Speed: 2.54 samples/sec	Train-FCNLogLoss=1.193752,	
2017-06-19 13:00:17,579 Epoch[0] Batch [250]	Speed: 2.26 samples/sec	Train-FCNLogLoss=1.164261,	
2017-06-19 13:00:26,076 Epoch[0] Batch [260]	Speed: 2.35 samples/sec	Train-FCNLogLoss=1.138067,	
2017-06-19 13:00:34,331 Epoch[0] Batch [270]	Speed: 2.42 samples/sec	Train-FCNLogLoss=1.115438,	
2017-06-19 13:00:44,358 Epoch[0] Batch [280]	Speed: 1.99 samples/sec	Train-FCNLogLoss=1.097363,	
2017-06-19 13:00:52,926 Epoch[0] Batch [290]	Speed: 2.33 samples/sec	Train-FCNLogLoss=1.074170,	
2017-06-19 13:01:01,151 Epoch[0] Batch [300]	Speed: 2.43 samples/sec	Train-FCNLogLoss=1.053717,	
2017-06-19 13:01:09,974 Epoch[0] Batch [310]	Speed: 2.27 samples/sec	Train-FCNLogLoss=1.036488,	
2017-06-19 13:01:17,496 Epoch[0] Batch [320]	Speed: 2.66 samples/sec	Train-FCNLogLoss=1.017191,	
2017-06-19 13:01:27,193 Epoch[0] Batch [330]	Speed: 2.06 samples/sec	Train-FCNLogLoss=1.001823,	
2017-06-19 13:01:35,338 Epoch[0] Batch [340]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.994287,	
2017-06-19 13:01:44,095 Epoch[0] Batch [350]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.985293,	
2017-06-19 13:01:52,177 Epoch[0] Batch [360]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.973418,	
2017-06-19 13:02:00,303 Epoch[0] Batch [370]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.962992,	
2017-06-19 13:02:08,001 Epoch[0] Batch [380]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.947851,	
2017-06-19 13:02:15,969 Epoch[0] Batch [390]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.937521,	
2017-06-19 13:02:24,953 Epoch[0] Batch [400]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.923525,	
2017-06-19 13:02:32,894 Epoch[0] Batch [410]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.911168,	
2017-06-19 13:02:42,383 Epoch[0] Batch [420]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.901435,	
2017-06-19 13:02:50,377 Epoch[0] Batch [430]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.893205,	
2017-06-19 13:02:59,110 Epoch[0] Batch [440]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.884323,	
2017-06-19 13:03:07,595 Epoch[0] Batch [450]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.873191,	
2017-06-19 13:03:15,811 Epoch[0] Batch [460]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.864258,	
2017-06-19 13:03:23,154 Epoch[0] Batch [470]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.854685,	
2017-06-19 13:03:31,992 Epoch[0] Batch [480]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.847084,	
2017-06-19 13:03:41,629 Epoch[0] Batch [490]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.839857,	
2017-06-19 13:03:51,547 Epoch[0] Batch [500]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.835517,	
2017-06-19 13:04:00,763 Epoch[0] Batch [510]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.826270,	
2017-06-19 13:04:08,883 Epoch[0] Batch [520]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.820760,	
2017-06-19 13:04:17,507 Epoch[0] Batch [530]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.813724,	
2017-06-19 13:04:26,182 Epoch[0] Batch [540]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.806114,	
2017-06-19 13:04:34,188 Epoch[0] Batch [550]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.799295,	
2017-06-19 13:04:42,395 Epoch[0] Batch [560]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.792588,	
2017-06-19 13:04:50,962 Epoch[0] Batch [570]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.789774,	
2017-06-19 13:04:59,792 Epoch[0] Batch [580]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.784061,	
2017-06-19 13:05:08,625 Epoch[0] Batch [590]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.778451,	
2017-06-19 13:05:17,335 Epoch[0] Batch [600]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.772396,	
2017-06-19 13:05:26,484 Epoch[0] Batch [610]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.767765,	
2017-06-19 13:05:35,040 Epoch[0] Batch [620]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.761960,	
2017-06-19 13:05:43,672 Epoch[0] Batch [630]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.756587,	
2017-06-19 13:05:51,474 Epoch[0] Batch [640]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.751344,	
2017-06-19 13:06:01,484 Epoch[0] Batch [650]	Speed: 2.00 samples/sec	Train-FCNLogLoss=0.745908,	
2017-06-19 13:06:09,333 Epoch[0] Batch [660]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.741013,	
2017-06-19 13:06:17,702 Epoch[0] Batch [670]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.736592,	
2017-06-19 13:06:25,379 Epoch[0] Batch [680]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.731863,	
2017-06-19 13:06:33,232 Epoch[0] Batch [690]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.726473,	
2017-06-19 13:06:42,247 Epoch[0] Batch [700]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.722642,	
2017-06-19 13:06:50,503 Epoch[0] Batch [710]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.717598,	
2017-06-19 13:06:58,913 Epoch[0] Batch [720]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.715201,	
2017-06-19 13:07:07,696 Epoch[0] Batch [730]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.710036,	
2017-06-19 13:07:15,369 Epoch[0] Batch [740]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.705417,	
2017-06-19 13:07:24,620 Epoch[0] Batch [750]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.701227,	
2017-06-19 13:07:31,935 Epoch[0] Batch [760]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.698508,	
2017-06-19 13:07:40,140 Epoch[0] Batch [770]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.695205,	
2017-06-19 13:07:48,198 Epoch[0] Batch [780]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.691392,	
2017-06-19 13:07:56,256 Epoch[0] Batch [790]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.688605,	
2017-06-19 13:08:04,198 Epoch[0] Batch [800]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.687412,	
2017-06-19 13:08:12,900 Epoch[0] Batch [810]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.683763,	
2017-06-19 13:08:20,991 Epoch[0] Batch [820]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.679860,	
2017-06-19 13:08:29,821 Epoch[0] Batch [830]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.675948,	
2017-06-19 13:08:39,076 Epoch[0] Batch [840]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.672776,	
2017-06-19 13:08:46,842 Epoch[0] Batch [850]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.669585,	
2017-06-19 13:08:55,445 Epoch[0] Batch [860]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.667895,	
2017-06-19 13:09:03,417 Epoch[0] Batch [870]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.663635,	
2017-06-19 13:09:11,268 Epoch[0] Batch [880]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.661082,	
2017-06-19 13:09:17,686 Epoch[0] Batch [890]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.658118,	
2017-06-19 13:09:25,963 Epoch[0] Batch [900]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.654161,	
2017-06-19 13:09:33,433 Epoch[0] Batch [910]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.651531,	
2017-06-19 13:09:41,867 Epoch[0] Batch [920]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.648861,	
2017-06-19 13:09:49,847 Epoch[0] Batch [930]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.646202,	
2017-06-19 13:09:57,924 Epoch[0] Batch [940]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.644154,	
2017-06-19 13:10:08,267 Epoch[0] Batch [950]	Speed: 1.93 samples/sec	Train-FCNLogLoss=0.641487,	
2017-06-19 13:10:17,506 Epoch[0] Batch [960]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.638906,	
2017-06-19 13:10:25,617 Epoch[0] Batch [970]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.636200,	
2017-06-19 13:10:32,970 Epoch[0] Batch [980]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.634085,	
2017-06-19 13:10:40,827 Epoch[0] Batch [990]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.630914,	
2017-06-19 13:10:49,263 Epoch[0] Batch [1000]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.628496,	
2017-06-19 13:10:57,789 Epoch[0] Batch [1010]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.627079,	
2017-06-19 13:11:05,900 Epoch[0] Batch [1020]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.624639,	
2017-06-19 13:11:14,156 Epoch[0] Batch [1030]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.622091,	
2017-06-19 13:11:21,984 Epoch[0] Batch [1040]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.620280,	
2017-06-19 13:11:29,610 Epoch[0] Batch [1050]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.620426,	
2017-06-19 13:11:37,104 Epoch[0] Batch [1060]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.620326,	
2017-06-19 13:11:44,828 Epoch[0] Batch [1070]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.621022,	
2017-06-19 13:11:52,807 Epoch[0] Batch [1080]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.621096,	
2017-06-19 13:12:00,827 Epoch[0] Batch [1090]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.620464,	
2017-06-19 13:12:09,157 Epoch[0] Batch [1100]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.620876,	
2017-06-19 13:12:16,654 Epoch[0] Batch [1110]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.619517,	
2017-06-19 13:12:23,918 Epoch[0] Batch [1120]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.617645,	
2017-06-19 13:12:32,560 Epoch[0] Batch [1130]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.617996,	
2017-06-19 13:12:40,949 Epoch[0] Batch [1140]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.616291,	
2017-06-19 13:12:50,532 Epoch[0] Batch [1150]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.615026,	
2017-06-19 13:12:59,485 Epoch[0] Batch [1160]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.613115,	
2017-06-19 13:13:07,666 Epoch[0] Batch [1170]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.611907,	
2017-06-19 13:13:16,028 Epoch[0] Batch [1180]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.610471,	
2017-06-19 13:13:23,530 Epoch[0] Batch [1190]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.608362,	
2017-06-19 13:13:31,679 Epoch[0] Batch [1200]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.607275,	
2017-06-19 13:13:39,417 Epoch[0] Batch [1210]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.607691,	
2017-06-19 13:13:47,875 Epoch[0] Batch [1220]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.605696,	
2017-06-19 13:13:56,079 Epoch[0] Batch [1230]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.603860,	
2017-06-19 13:14:03,012 Epoch[0] Batch [1240]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.601991,	
2017-06-19 13:14:11,891 Epoch[0] Batch [1250]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.600614,	
2017-06-19 13:14:20,091 Epoch[0] Batch [1260]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.600157,	
2017-06-19 13:14:27,911 Epoch[0] Batch [1270]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.599146,	
2017-06-19 13:14:36,109 Epoch[0] Batch [1280]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.596859,	
2017-06-19 13:14:43,682 Epoch[0] Batch [1290]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.595675,	
2017-06-19 13:14:51,816 Epoch[0] Batch [1300]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.594159,	
2017-06-19 13:15:00,430 Epoch[0] Batch [1310]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.592281,	
2017-06-19 13:15:09,202 Epoch[0] Batch [1320]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.590580,	
2017-06-19 13:15:17,338 Epoch[0] Batch [1330]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.589257,	
2017-06-19 13:15:25,466 Epoch[0] Batch [1340]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.588421,	
2017-06-19 13:15:34,681 Epoch[0] Batch [1350]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.588273,	
2017-06-19 13:15:43,197 Epoch[0] Batch [1360]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.587132,	
2017-06-19 13:15:51,653 Epoch[0] Batch [1370]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.585870,	
2017-06-19 13:15:59,616 Epoch[0] Batch [1380]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.584236,	
2017-06-19 13:16:07,213 Epoch[0] Batch [1390]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.583084,	
2017-06-19 13:16:14,961 Epoch[0] Batch [1400]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.582813,	
2017-06-19 13:16:22,721 Epoch[0] Batch [1410]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.581277,	
2017-06-19 13:16:29,926 Epoch[0] Batch [1420]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.579593,	
2017-06-19 13:16:37,146 Epoch[0] Batch [1430]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.577959,	
2017-06-19 13:16:44,034 Epoch[0] Batch [1440]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.576346,	
2017-06-19 13:16:52,313 Epoch[0] Batch [1450]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.574239,	
2017-06-19 13:17:00,609 Epoch[0] Batch [1460]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.572509,	
2017-06-19 13:17:08,868 Epoch[0] Batch [1470]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.570611,	
2017-06-19 13:17:17,348 Epoch[0] Batch [1480]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.568624,	
2017-06-19 13:17:26,079 Epoch[0] Batch [1490]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.566720,	
2017-06-19 13:17:33,235 Epoch[0] Batch [1500]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.565381,	
2017-06-19 13:17:41,112 Epoch[0] Batch [1510]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.563502,	
2017-06-19 13:17:50,544 Epoch[0] Batch [1520]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.561592,	
2017-06-19 13:18:00,072 Epoch[0] Batch [1530]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.559814,	
2017-06-19 13:18:08,209 Epoch[0] Batch [1540]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.557764,	
2017-06-19 13:18:16,267 Epoch[0] Batch [1550]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.556039,	
2017-06-19 13:18:23,583 Epoch[0] Batch [1560]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.553992,	
2017-06-19 13:18:32,209 Epoch[0] Batch [1570]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.552010,	
2017-06-19 13:18:39,619 Epoch[0] Batch [1580]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.550887,	
2017-06-19 13:18:48,608 Epoch[0] Batch [1590]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.549592,	
2017-06-19 13:18:57,498 Epoch[0] Batch [1600]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.548132,	
2017-06-19 13:19:05,609 Epoch[0] Batch [1610]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.546421,	
2017-06-19 13:19:13,801 Epoch[0] Batch [1620]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.545134,	
2017-06-19 13:19:22,058 Epoch[0] Batch [1630]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.544363,	
2017-06-19 13:19:29,786 Epoch[0] Batch [1640]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.543031,	
2017-06-19 13:19:37,949 Epoch[0] Batch [1650]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.541954,	
2017-06-19 13:19:47,146 Epoch[0] Batch [1660]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.540298,	
2017-06-19 13:19:54,195 Epoch[0] Batch [1670]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.538813,	
2017-06-19 13:20:03,187 Epoch[0] Batch [1680]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.537268,	
2017-06-19 13:20:12,314 Epoch[0] Batch [1690]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.536302,	
2017-06-19 13:20:21,624 Epoch[0] Batch [1700]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.534755,	
2017-06-19 13:20:29,554 Epoch[0] Batch [1710]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.533402,	
2017-06-19 13:20:36,933 Epoch[0] Batch [1720]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.531799,	
2017-06-19 13:20:45,295 Epoch[0] Batch [1730]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.530408,	
2017-06-19 13:20:53,175 Epoch[0] Batch [1740]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.529371,	
2017-06-19 13:21:01,330 Epoch[0] Batch [1750]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.528495,	
2017-06-19 13:21:09,125 Epoch[0] Batch [1760]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.527693,	
2017-06-19 13:21:17,822 Epoch[0] Batch [1770]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.526555,	
2017-06-19 13:21:26,695 Epoch[0] Batch [1780]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.525451,	
2017-06-19 13:21:33,360 Epoch[0] Batch [1790]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.523882,	
2017-06-19 13:21:41,043 Epoch[0] Batch [1800]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.522813,	
2017-06-19 13:21:48,502 Epoch[0] Batch [1810]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.521532,	
2017-06-19 13:21:56,419 Epoch[0] Batch [1820]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.520515,	
2017-06-19 13:22:05,541 Epoch[0] Batch [1830]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.519003,	
2017-06-19 13:22:13,653 Epoch[0] Batch [1840]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.517486,	
2017-06-19 13:22:23,392 Epoch[0] Batch [1850]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.516015,	
2017-06-19 13:22:32,441 Epoch[0] Batch [1860]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.514546,	
2017-06-19 13:22:42,602 Epoch[0] Batch [1870]	Speed: 1.97 samples/sec	Train-FCNLogLoss=0.513481,	
2017-06-19 13:22:50,760 Epoch[0] Batch [1880]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.512350,	
2017-06-19 13:22:58,241 Epoch[0] Batch [1890]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.511049,	
2017-06-19 13:23:07,550 Epoch[0] Batch [1900]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.509860,	
2017-06-19 13:23:16,242 Epoch[0] Batch [1910]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.508416,	
2017-06-19 13:23:24,540 Epoch[0] Batch [1920]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.507071,	
2017-06-19 13:23:33,572 Epoch[0] Batch [1930]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.506219,	
2017-06-19 13:23:41,687 Epoch[0] Batch [1940]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.505040,	
2017-06-19 13:23:50,485 Epoch[0] Batch [1950]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.503710,	
2017-06-19 13:23:59,212 Epoch[0] Batch [1960]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.504505,	
2017-06-19 13:24:07,014 Epoch[0] Batch [1970]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.503615,	
2017-06-19 13:24:15,372 Epoch[0] Batch [1980]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.502966,	
2017-06-19 13:24:22,871 Epoch[0] Batch [1990]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.503180,	
2017-06-19 13:24:31,583 Epoch[0] Batch [2000]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.502597,	
2017-06-19 13:24:39,359 Epoch[0] Batch [2010]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.502011,	
2017-06-19 13:24:47,076 Epoch[0] Batch [2020]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.501152,	
2017-06-19 13:24:53,860 Epoch[0] Batch [2030]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.500081,	
2017-06-19 13:25:01,560 Epoch[0] Batch [2040]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.499101,	
2017-06-19 13:25:09,748 Epoch[0] Batch [2050]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.497939,	
2017-06-19 13:25:17,387 Epoch[0] Batch [2060]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.497372,	
2017-06-19 13:25:25,955 Epoch[0] Batch [2070]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.496492,	
2017-06-19 13:25:33,953 Epoch[0] Batch [2080]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.495669,	
2017-06-19 13:25:41,195 Epoch[0] Batch [2090]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.494410,	
2017-06-19 13:25:49,870 Epoch[0] Batch [2100]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.493189,	
2017-06-19 13:25:57,054 Epoch[0] Batch [2110]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.492711,	
2017-06-19 13:26:04,592 Epoch[0] Batch [2120]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.491761,	
2017-06-19 13:26:12,791 Epoch[0] Batch [2130]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.490778,	
2017-06-19 13:26:21,566 Epoch[0] Batch [2140]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.489836,	
2017-06-19 13:26:30,729 Epoch[0] Batch [2150]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.488763,	
2017-06-19 13:26:44,198 Epoch[0] Batch [2160]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.487679,	
2017-06-19 13:26:53,831 Epoch[0] Batch [2170]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.486571,	
2017-06-19 13:27:02,449 Epoch[0] Batch [2180]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.485555,	
2017-06-19 13:27:08,925 Epoch[0] Batch [2190]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.484761,	
2017-06-19 13:27:17,447 Epoch[0] Batch [2200]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.483903,	
2017-06-19 13:27:26,956 Epoch[0] Batch [2210]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.483319,	
2017-06-19 13:27:34,459 Epoch[0] Batch [2220]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.482427,	
2017-06-19 13:27:42,922 Epoch[0] Batch [2230]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.481516,	
2017-06-19 13:27:51,107 Epoch[0] Batch [2240]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.480501,	
2017-06-19 13:27:58,745 Epoch[0] Batch [2250]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.479854,	
2017-06-19 13:28:07,091 Epoch[0] Batch [2260]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.478705,	
2017-06-19 13:28:16,135 Epoch[0] Batch [2270]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.477994,	
2017-06-19 13:28:24,167 Epoch[0] Batch [2280]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.477000,	
2017-06-19 13:28:32,755 Epoch[0] Batch [2290]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.476063,	
2017-06-19 13:28:41,227 Epoch[0] Batch [2300]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.474926,	
2017-06-19 13:28:50,176 Epoch[0] Batch [2310]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.474683,	
2017-06-19 13:28:57,802 Epoch[0] Batch [2320]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.473852,	
2017-06-19 13:29:07,695 Epoch[0] Batch [2330]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.472818,	
2017-06-19 13:29:16,519 Epoch[0] Batch [2340]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.471910,	
2017-06-19 13:29:25,979 Epoch[0] Batch [2350]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.470988,	
2017-06-19 13:29:33,378 Epoch[0] Batch [2360]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.470068,	
2017-06-19 13:29:41,667 Epoch[0] Batch [2370]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.469267,	
2017-06-19 13:29:49,160 Epoch[0] Batch [2380]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.468446,	
2017-06-19 13:29:57,502 Epoch[0] Batch [2390]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.467593,	
2017-06-19 13:30:07,343 Epoch[0] Batch [2400]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.466957,	
2017-06-19 13:30:15,941 Epoch[0] Batch [2410]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.466000,	
2017-06-19 13:30:25,085 Epoch[0] Batch [2420]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.464995,	
2017-06-19 13:30:34,032 Epoch[0] Batch [2430]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.464160,	
2017-06-19 13:30:43,343 Epoch[0] Batch [2440]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.463163,	
2017-06-19 13:30:52,920 Epoch[0] Batch [2450]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.462499,	
2017-06-19 13:31:00,945 Epoch[0] Batch [2460]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.461478,	
2017-06-19 13:31:09,771 Epoch[0] Batch [2470]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.460689,	
2017-06-19 13:31:17,947 Epoch[0] Batch [2480]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.459786,	
2017-06-19 13:31:25,879 Epoch[0] Batch [2490]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.458890,	
2017-06-19 13:31:35,805 Epoch[0] Batch [2500]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.458175,	
2017-06-19 13:31:45,057 Epoch[0] Batch [2510]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.457528,	
2017-06-19 13:31:53,578 Epoch[0] Batch [2520]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.456782,	
2017-06-19 13:32:02,638 Epoch[0] Batch [2530]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.455888,	
2017-06-19 13:32:13,222 Epoch[0] Batch [2540]	Speed: 1.89 samples/sec	Train-FCNLogLoss=0.454999,	
2017-06-19 13:32:22,257 Epoch[0] Batch [2550]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.454443,	
2017-06-19 13:32:32,446 Epoch[0] Batch [2560]	Speed: 1.96 samples/sec	Train-FCNLogLoss=0.453724,	
2017-06-19 13:32:41,781 Epoch[0] Batch [2570]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.452768,	
2017-06-19 13:32:50,604 Epoch[0] Batch [2580]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.452120,	
2017-06-19 13:33:00,761 Epoch[0] Batch [2590]	Speed: 1.97 samples/sec	Train-FCNLogLoss=0.451447,	
2017-06-19 13:33:10,823 Epoch[0] Batch [2600]	Speed: 1.99 samples/sec	Train-FCNLogLoss=0.451241,	
2017-06-19 13:33:20,223 Epoch[0] Batch [2610]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.450447,	
2017-06-19 13:33:29,824 Epoch[0] Batch [2620]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.449542,	
2017-06-19 13:33:40,763 Epoch[0] Batch [2630]	Speed: 1.83 samples/sec	Train-FCNLogLoss=0.449308,	
2017-06-19 13:33:52,275 Epoch[0] Batch [2640]	Speed: 1.74 samples/sec	Train-FCNLogLoss=0.448907,	
2017-06-19 13:34:01,096 Epoch[0] Batch [2650]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.449120,	
2017-06-19 13:34:09,383 Epoch[0] Batch [2660]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.448569,	
2017-06-19 13:34:17,610 Epoch[0] Batch [2670]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.447866,	
2017-06-19 13:34:26,955 Epoch[0] Batch [2680]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.447220,	
2017-06-19 13:34:35,385 Epoch[0] Batch [2690]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.446634,	
2017-06-19 13:34:46,647 Epoch[0] Batch [2700]	Speed: 1.78 samples/sec	Train-FCNLogLoss=0.446542,	
2017-06-19 13:34:56,956 Epoch[0] Batch [2710]	Speed: 1.94 samples/sec	Train-FCNLogLoss=0.445993,	
2017-06-19 13:35:06,437 Epoch[0] Batch [2720]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.445597,	
2017-06-19 13:35:17,416 Epoch[0] Batch [2730]	Speed: 1.82 samples/sec	Train-FCNLogLoss=0.445010,	
2017-06-19 13:35:27,375 Epoch[0] Batch [2740]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.444916,	
2017-06-19 13:35:37,446 Epoch[0] Batch [2750]	Speed: 1.99 samples/sec	Train-FCNLogLoss=0.444385,	
2017-06-19 13:35:48,223 Epoch[0] Batch [2760]	Speed: 1.86 samples/sec	Train-FCNLogLoss=0.443765,	
2017-06-19 13:35:57,937 Epoch[0] Batch [2770]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.442901,	
2017-06-19 13:36:07,835 Epoch[0] Batch [2780]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.442277,	
2017-06-19 13:36:17,056 Epoch[0] Batch [2790]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.441469,	
2017-06-19 13:36:27,463 Epoch[0] Batch [2800]	Speed: 1.92 samples/sec	Train-FCNLogLoss=0.440797,	
2017-06-19 13:36:37,914 Epoch[0] Batch [2810]	Speed: 1.91 samples/sec	Train-FCNLogLoss=0.440826,	
2017-06-19 13:36:47,363 Epoch[0] Batch [2820]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.440795,	
2017-06-19 13:36:56,103 Epoch[0] Batch [2830]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.440390,	
2017-06-19 13:37:05,638 Epoch[0] Batch [2840]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.439717,	
2017-06-19 13:37:15,182 Epoch[0] Batch [2850]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.439526,	
2017-06-19 13:37:26,049 Epoch[0] Batch [2860]	Speed: 1.84 samples/sec	Train-FCNLogLoss=0.439338,	
2017-06-19 13:37:37,230 Epoch[0] Batch [2870]	Speed: 1.79 samples/sec	Train-FCNLogLoss=0.438800,	
2017-06-19 13:37:47,006 Epoch[0] Batch [2880]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.438044,	
2017-06-19 13:37:56,201 Epoch[0] Batch [2890]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.437485,	
2017-06-19 13:38:05,853 Epoch[0] Batch [2900]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.436667,	
2017-06-19 13:38:16,531 Epoch[0] Batch [2910]	Speed: 1.87 samples/sec	Train-FCNLogLoss=0.435951,	
2017-06-19 13:38:26,002 Epoch[0] Batch [2920]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.435178,	
2017-06-19 13:38:36,470 Epoch[0] Batch [2930]	Speed: 1.91 samples/sec	Train-FCNLogLoss=0.434545,	
2017-06-19 13:38:45,560 Epoch[0] Batch [2940]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.434388,	
2017-06-19 13:38:55,169 Epoch[0] Batch [2950]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.433868,	
2017-06-19 13:39:03,932 Epoch[0] Batch [2960]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.433812,	
2017-06-19 13:39:15,088 Epoch[0] Batch [2970]	Speed: 1.79 samples/sec	Train-FCNLogLoss=0.433327,	
2017-06-19 13:39:19,185 Epoch[0] Train-FCNLogLoss=0.433161
2017-06-19 13:39:19,186 Epoch[0] Time cost=2585.797
2017-06-19 13:39:20,925 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.params"
2017-06-19 13:39:26,020 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.states"
2017-06-19 13:39:34,930 Epoch[1] Batch [10]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.243110,	
2017-06-19 13:39:42,694 Epoch[1] Batch [20]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.225972,	
2017-06-19 13:39:51,964 Epoch[1] Batch [30]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.224962,	
2017-06-19 13:39:59,563 Epoch[1] Batch [40]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.241322,	
2017-06-19 13:40:08,611 Epoch[1] Batch [50]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.258298,	
2017-06-19 13:40:17,569 Epoch[1] Batch [60]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.281404,	
2017-06-19 13:40:25,873 Epoch[1] Batch [70]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.277871,	
2017-06-19 13:40:34,815 Epoch[1] Batch [80]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.275610,	
2017-06-19 13:40:43,903 Epoch[1] Batch [90]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.268767,	
2017-06-19 13:40:51,780 Epoch[1] Batch [100]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.263876,	
2017-06-19 13:40:59,549 Epoch[1] Batch [110]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.259256,	
2017-06-19 13:41:07,960 Epoch[1] Batch [120]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.260845,	
2017-06-19 13:41:16,091 Epoch[1] Batch [130]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.263563,	
2017-06-19 13:41:24,024 Epoch[1] Batch [140]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.260555,	
2017-06-19 13:41:32,571 Epoch[1] Batch [150]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.258059,	
2017-06-19 13:41:40,743 Epoch[1] Batch [160]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.259353,	
2017-06-19 13:41:49,238 Epoch[1] Batch [170]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.257085,	
2017-06-19 13:41:56,481 Epoch[1] Batch [180]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.255061,	
2017-06-19 13:42:04,184 Epoch[1] Batch [190]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.254325,	
2017-06-19 13:42:13,152 Epoch[1] Batch [200]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.256662,	
2017-06-19 13:42:20,495 Epoch[1] Batch [210]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.255649,	
2017-06-19 13:42:30,298 Epoch[1] Batch [220]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.255136,	
2017-06-19 13:42:40,156 Epoch[1] Batch [230]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.255123,	
2017-06-19 13:42:47,932 Epoch[1] Batch [240]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.253698,	
2017-06-19 13:42:55,980 Epoch[1] Batch [250]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.253113,	
2017-06-19 13:43:04,194 Epoch[1] Batch [260]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.253585,	
2017-06-19 13:43:13,778 Epoch[1] Batch [270]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.253630,	
2017-06-19 13:43:23,467 Epoch[1] Batch [280]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.251473,	
2017-06-19 13:43:32,315 Epoch[1] Batch [290]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.251123,	
2017-06-19 13:43:39,723 Epoch[1] Batch [300]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.250692,	
2017-06-19 13:43:48,504 Epoch[1] Batch [310]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.249385,	
2017-06-19 13:43:56,855 Epoch[1] Batch [320]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.248434,	
2017-06-19 13:44:05,011 Epoch[1] Batch [330]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.247690,	
2017-06-19 13:44:14,126 Epoch[1] Batch [340]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.246977,	
2017-06-19 13:44:21,655 Epoch[1] Batch [350]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.246457,	
2017-06-19 13:44:30,035 Epoch[1] Batch [360]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.245776,	
2017-06-19 13:44:39,009 Epoch[1] Batch [370]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.246326,	
2017-06-19 13:44:46,265 Epoch[1] Batch [380]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.245378,	
2017-06-19 13:44:54,761 Epoch[1] Batch [390]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.245361,	
2017-06-19 13:45:02,316 Epoch[1] Batch [400]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.244650,	
2017-06-19 13:45:11,979 Epoch[1] Batch [410]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.245158,	
2017-06-19 13:45:21,076 Epoch[1] Batch [420]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.246435,	
2017-06-19 13:45:29,156 Epoch[1] Batch [430]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.246923,	
2017-06-19 13:45:37,728 Epoch[1] Batch [440]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.246138,	
2017-06-19 13:45:47,552 Epoch[1] Batch [450]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.245232,	
2017-06-19 13:45:57,064 Epoch[1] Batch [460]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.244678,	
2017-06-19 13:46:04,409 Epoch[1] Batch [470]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.245081,	
2017-06-19 13:46:12,747 Epoch[1] Batch [480]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.244918,	
2017-06-19 13:46:20,411 Epoch[1] Batch [490]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.244384,	
2017-06-19 13:46:28,988 Epoch[1] Batch [500]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.243780,	
2017-06-19 13:46:37,972 Epoch[1] Batch [510]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.244051,	
2017-06-19 13:46:46,180 Epoch[1] Batch [520]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.244236,	
2017-06-19 13:46:55,062 Epoch[1] Batch [530]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.245028,	
2017-06-19 13:47:03,123 Epoch[1] Batch [540]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.244870,	
2017-06-19 13:47:10,274 Epoch[1] Batch [550]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.244515,	
2017-06-19 13:47:17,872 Epoch[1] Batch [560]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.244057,	
2017-06-19 13:47:26,459 Epoch[1] Batch [570]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.244087,	
2017-06-19 13:47:34,903 Epoch[1] Batch [580]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.243544,	
2017-06-19 13:47:43,483 Epoch[1] Batch [590]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.242718,	
2017-06-19 13:47:51,204 Epoch[1] Batch [600]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.242563,	
2017-06-19 13:47:59,043 Epoch[1] Batch [610]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.241658,	
2017-06-19 13:48:07,852 Epoch[1] Batch [620]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.241590,	
2017-06-19 13:48:15,955 Epoch[1] Batch [630]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.241691,	
2017-06-19 13:48:25,209 Epoch[1] Batch [640]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.241028,	
2017-06-19 13:48:33,204 Epoch[1] Batch [650]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.241129,	
2017-06-19 13:48:41,213 Epoch[1] Batch [660]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.240425,	
2017-06-19 13:48:49,415 Epoch[1] Batch [670]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.241276,	
2017-06-19 13:48:58,166 Epoch[1] Batch [680]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.242004,	
2017-06-19 13:49:05,241 Epoch[1] Batch [690]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.243062,	
2017-06-19 13:49:13,011 Epoch[1] Batch [700]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.243230,	
2017-06-19 13:49:21,860 Epoch[1] Batch [710]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.243226,	
2017-06-19 13:49:29,549 Epoch[1] Batch [720]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.243172,	
2017-06-19 13:49:37,029 Epoch[1] Batch [730]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.242575,	
2017-06-19 13:49:46,974 Epoch[1] Batch [740]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.242433,	
2017-06-19 13:49:55,051 Epoch[1] Batch [750]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.242991,	
2017-06-19 13:50:03,471 Epoch[1] Batch [760]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.243102,	
2017-06-19 13:50:11,010 Epoch[1] Batch [770]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.243389,	
2017-06-19 13:50:17,660 Epoch[1] Batch [780]	Speed: 3.01 samples/sec	Train-FCNLogLoss=0.243401,	
2017-06-19 13:50:24,587 Epoch[1] Batch [790]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.242895,	
2017-06-19 13:50:32,293 Epoch[1] Batch [800]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.242356,	
2017-06-19 13:50:41,119 Epoch[1] Batch [810]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.241470,	
2017-06-19 13:50:49,018 Epoch[1] Batch [820]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.240825,	
2017-06-19 13:50:57,231 Epoch[1] Batch [830]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.240392,	
2017-06-19 13:51:04,722 Epoch[1] Batch [840]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.240047,	
2017-06-19 13:51:13,842 Epoch[1] Batch [850]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.239742,	
2017-06-19 13:51:22,031 Epoch[1] Batch [860]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.239492,	
2017-06-19 13:51:29,900 Epoch[1] Batch [870]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.238701,	
2017-06-19 13:51:37,864 Epoch[1] Batch [880]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.238663,	
2017-06-19 13:51:46,621 Epoch[1] Batch [890]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.238946,	
2017-06-19 13:51:53,408 Epoch[1] Batch [900]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.238294,	
2017-06-19 13:52:00,595 Epoch[1] Batch [910]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.238069,	
2017-06-19 13:52:08,210 Epoch[1] Batch [920]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.237959,	
2017-06-19 13:52:15,771 Epoch[1] Batch [930]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.237822,	
2017-06-19 13:52:22,746 Epoch[1] Batch [940]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.237653,	
2017-06-19 13:52:29,384 Epoch[1] Batch [950]	Speed: 3.01 samples/sec	Train-FCNLogLoss=0.237504,	
2017-06-19 13:52:36,847 Epoch[1] Batch [960]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.237573,	
2017-06-19 13:52:44,082 Epoch[1] Batch [970]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.237377,	
2017-06-19 13:52:53,427 Epoch[1] Batch [980]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.236892,	
2017-06-19 13:53:01,338 Epoch[1] Batch [990]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.236651,	
2017-06-19 13:53:09,436 Epoch[1] Batch [1000]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.236438,	
2017-06-19 13:53:16,727 Epoch[1] Batch [1010]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.236019,	
2017-06-19 13:53:24,254 Epoch[1] Batch [1020]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.236099,	
2017-06-19 13:53:33,174 Epoch[1] Batch [1030]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.236236,	
2017-06-19 13:53:40,263 Epoch[1] Batch [1040]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.236899,	
2017-06-19 13:53:48,900 Epoch[1] Batch [1050]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.236757,	
2017-06-19 13:53:56,398 Epoch[1] Batch [1060]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.236482,	
2017-06-19 13:54:03,014 Epoch[1] Batch [1070]	Speed: 3.02 samples/sec	Train-FCNLogLoss=0.236209,	
2017-06-19 13:54:10,751 Epoch[1] Batch [1080]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.236063,	
2017-06-19 13:54:18,157 Epoch[1] Batch [1090]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.235629,	
2017-06-19 13:54:27,133 Epoch[1] Batch [1100]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.235356,	
2017-06-19 13:54:35,150 Epoch[1] Batch [1110]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.235211,	
2017-06-19 13:54:43,675 Epoch[1] Batch [1120]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.234827,	
2017-06-19 13:54:51,447 Epoch[1] Batch [1130]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.234521,	
2017-06-19 13:54:58,840 Epoch[1] Batch [1140]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.234324,	
2017-06-19 13:55:06,675 Epoch[1] Batch [1150]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.234171,	
2017-06-19 13:55:16,230 Epoch[1] Batch [1160]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.234026,	
2017-06-19 13:55:24,695 Epoch[1] Batch [1170]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.233802,	
2017-06-19 13:55:33,000 Epoch[1] Batch [1180]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.233813,	
2017-06-19 13:55:41,952 Epoch[1] Batch [1190]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.233854,	
2017-06-19 13:55:50,246 Epoch[1] Batch [1200]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.233802,	
2017-06-19 13:55:58,186 Epoch[1] Batch [1210]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.233446,	
2017-06-19 13:56:07,143 Epoch[1] Batch [1220]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.233306,	
2017-06-19 13:56:14,315 Epoch[1] Batch [1230]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.233590,	
2017-06-19 13:56:22,073 Epoch[1] Batch [1240]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.233739,	
2017-06-19 13:56:30,846 Epoch[1] Batch [1250]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.233582,	
2017-06-19 13:56:39,339 Epoch[1] Batch [1260]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.233337,	
2017-06-19 13:56:46,838 Epoch[1] Batch [1270]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.233722,	
2017-06-19 13:56:55,921 Epoch[1] Batch [1280]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.233832,	
2017-06-19 13:57:03,146 Epoch[1] Batch [1290]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.233885,	
2017-06-19 13:57:10,792 Epoch[1] Batch [1300]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.234671,	
2017-06-19 13:57:18,650 Epoch[1] Batch [1310]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.234726,	
2017-06-19 13:57:25,561 Epoch[1] Batch [1320]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.234396,	
2017-06-19 13:57:33,176 Epoch[1] Batch [1330]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.234227,	
2017-06-19 13:57:39,425 Epoch[1] Batch [1340]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.234314,	
2017-06-19 13:57:44,338 Epoch[1] Batch [1350]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.234439,	
2017-06-19 13:57:49,591 Epoch[1] Batch [1360]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.234473,	
2017-06-19 13:57:54,618 Epoch[1] Batch [1370]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.234420,	
2017-06-19 13:57:59,580 Epoch[1] Batch [1380]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.234189,	
2017-06-19 13:58:04,592 Epoch[1] Batch [1390]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.233936,	
2017-06-19 13:58:09,282 Epoch[1] Batch [1400]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.233635,	
2017-06-19 13:58:14,314 Epoch[1] Batch [1410]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.233618,	
2017-06-19 13:58:19,153 Epoch[1] Batch [1420]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.233541,	
2017-06-19 13:58:23,961 Epoch[1] Batch [1430]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.233668,	
2017-06-19 13:58:28,796 Epoch[1] Batch [1440]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.233833,	
2017-06-19 13:58:33,815 Epoch[1] Batch [1450]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.233845,	
2017-06-19 13:58:39,024 Epoch[1] Batch [1460]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.233752,	
2017-06-19 13:58:43,949 Epoch[1] Batch [1470]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.234140,	
2017-06-19 13:58:48,881 Epoch[1] Batch [1480]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.233998,	
2017-06-19 13:58:53,840 Epoch[1] Batch [1490]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.234045,	
2017-06-19 13:58:58,566 Epoch[1] Batch [1500]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.233766,	
2017-06-19 13:59:03,801 Epoch[1] Batch [1510]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.233454,	
2017-06-19 13:59:08,572 Epoch[1] Batch [1520]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.233425,	
2017-06-19 13:59:13,490 Epoch[1] Batch [1530]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.233927,	
2017-06-19 13:59:18,260 Epoch[1] Batch [1540]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.233751,	
2017-06-19 13:59:23,152 Epoch[1] Batch [1550]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.233540,	
2017-06-19 13:59:28,117 Epoch[1] Batch [1560]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.233854,	
2017-06-19 13:59:32,904 Epoch[1] Batch [1570]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.233917,	
2017-06-19 13:59:37,895 Epoch[1] Batch [1580]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.233586,	
2017-06-19 13:59:42,781 Epoch[1] Batch [1590]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.233550,	
2017-06-19 13:59:47,651 Epoch[1] Batch [1600]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.233680,	
2017-06-19 13:59:52,826 Epoch[1] Batch [1610]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.233571,	
2017-06-19 13:59:58,250 Epoch[1] Batch [1620]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.233462,	
2017-06-19 14:00:03,110 Epoch[1] Batch [1630]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.233329,	
2017-06-19 14:00:08,266 Epoch[1] Batch [1640]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.233180,	
2017-06-19 14:00:14,095 Epoch[1] Batch [1650]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.233550,	
2017-06-19 14:00:18,837 Epoch[1] Batch [1660]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.233378,	
2017-06-19 14:00:23,836 Epoch[1] Batch [1670]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.233371,	
2017-06-19 14:00:28,697 Epoch[1] Batch [1680]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.233071,	
2017-06-19 14:00:33,580 Epoch[1] Batch [1690]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.233273,	
2017-06-19 14:00:38,517 Epoch[1] Batch [1700]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.233095,	
2017-06-19 14:00:43,627 Epoch[1] Batch [1710]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.232802,	
2017-06-19 14:00:48,498 Epoch[1] Batch [1720]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.232608,	
2017-06-19 14:00:53,361 Epoch[1] Batch [1730]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.232319,	
2017-06-19 14:00:57,927 Epoch[1] Batch [1740]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.232261,	
2017-06-19 14:01:03,226 Epoch[1] Batch [1750]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.232319,	
2017-06-19 14:01:08,099 Epoch[1] Batch [1760]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.232236,	
2017-06-19 14:01:13,253 Epoch[1] Batch [1770]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.231958,	
2017-06-19 14:01:18,214 Epoch[1] Batch [1780]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.232095,	
2017-06-19 14:01:23,055 Epoch[1] Batch [1790]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.232019,	
2017-06-19 14:01:27,976 Epoch[1] Batch [1800]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.232023,	
2017-06-19 14:01:33,074 Epoch[1] Batch [1810]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.232036,	
2017-06-19 14:01:38,283 Epoch[1] Batch [1820]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.232346,	
2017-06-19 14:01:43,695 Epoch[1] Batch [1830]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.232309,	
2017-06-19 14:01:48,913 Epoch[1] Batch [1840]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.232168,	
2017-06-19 14:01:54,696 Epoch[1] Batch [1850]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.231916,	
2017-06-19 14:01:59,864 Epoch[1] Batch [1860]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.232037,	
2017-06-19 14:02:05,293 Epoch[1] Batch [1870]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.231767,	
2017-06-19 14:02:10,699 Epoch[1] Batch [1880]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.231621,	
2017-06-19 14:02:16,243 Epoch[1] Batch [1890]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.231634,	
2017-06-19 14:02:22,087 Epoch[1] Batch [1900]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.231329,	
2017-06-19 14:02:27,845 Epoch[1] Batch [1910]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.231039,	
2017-06-19 14:02:33,698 Epoch[1] Batch [1920]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.230742,	
2017-06-19 14:02:38,791 Epoch[1] Batch [1930]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.230651,	
2017-06-19 14:02:44,753 Epoch[1] Batch [1940]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.230650,	
2017-06-19 14:02:51,090 Epoch[1] Batch [1950]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.230830,	
2017-06-19 14:02:57,252 Epoch[1] Batch [1960]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.230696,	
2017-06-19 14:03:02,653 Epoch[1] Batch [1970]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.230649,	
2017-06-19 14:03:08,606 Epoch[1] Batch [1980]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.230255,	
2017-06-19 14:03:13,813 Epoch[1] Batch [1990]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.230170,	
2017-06-19 14:03:20,638 Epoch[1] Batch [2000]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.229905,	
2017-06-19 14:03:27,332 Epoch[1] Batch [2010]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.229972,	
2017-06-19 14:03:33,924 Epoch[1] Batch [2020]	Speed: 3.03 samples/sec	Train-FCNLogLoss=0.230094,	
2017-06-19 14:03:39,855 Epoch[1] Batch [2030]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.229913,	
2017-06-19 14:03:45,806 Epoch[1] Batch [2040]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.230020,	
2017-06-19 14:03:52,018 Epoch[1] Batch [2050]	Speed: 3.22 samples/sec	Train-FCNLogLoss=0.230142,	
2017-06-19 14:03:58,190 Epoch[1] Batch [2060]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.230017,	
2017-06-19 14:04:05,166 Epoch[1] Batch [2070]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.229829,	
2017-06-19 14:04:11,639 Epoch[1] Batch [2080]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.229841,	
2017-06-19 14:04:18,294 Epoch[1] Batch [2090]	Speed: 3.01 samples/sec	Train-FCNLogLoss=0.229711,	
2017-06-19 14:04:24,505 Epoch[1] Batch [2100]	Speed: 3.22 samples/sec	Train-FCNLogLoss=0.229799,	
2017-06-19 14:04:30,879 Epoch[1] Batch [2110]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.229624,	
2017-06-19 14:04:37,181 Epoch[1] Batch [2120]	Speed: 3.17 samples/sec	Train-FCNLogLoss=0.229587,	
2017-06-19 14:04:43,475 Epoch[1] Batch [2130]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.229386,	
2017-06-19 14:04:49,878 Epoch[1] Batch [2140]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.229189,	
2017-06-19 14:04:56,027 Epoch[1] Batch [2150]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.229026,	
2017-06-19 14:05:02,766 Epoch[1] Batch [2160]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.228728,	
2017-06-19 14:05:10,661 Epoch[1] Batch [2170]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.228755,	
2017-06-19 14:05:17,389 Epoch[1] Batch [2180]	Speed: 2.97 samples/sec	Train-FCNLogLoss=0.228484,	
2017-06-19 14:05:24,282 Epoch[1] Batch [2190]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.228322,	
2017-06-19 14:05:31,181 Epoch[1] Batch [2200]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.228301,	
2017-06-19 14:05:38,951 Epoch[1] Batch [2210]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.228159,	
2017-06-19 14:05:45,242 Epoch[1] Batch [2220]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.228091,	
2017-06-19 14:05:52,387 Epoch[1] Batch [2230]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.228200,	
2017-06-19 14:05:59,260 Epoch[1] Batch [2240]	Speed: 2.91 samples/sec	Train-FCNLogLoss=0.228014,	
2017-06-19 14:06:06,264 Epoch[1] Batch [2250]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.227909,	
2017-06-19 14:06:12,931 Epoch[1] Batch [2260]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.227763,	
2017-06-19 14:06:19,972 Epoch[1] Batch [2270]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.227650,	
2017-06-19 14:06:27,155 Epoch[1] Batch [2280]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.227623,	
2017-06-19 14:06:34,118 Epoch[1] Batch [2290]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.227551,	
2017-06-19 14:06:41,198 Epoch[1] Batch [2300]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.227335,	
2017-06-19 14:06:47,612 Epoch[1] Batch [2310]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.227028,	
2017-06-19 14:06:54,549 Epoch[1] Batch [2320]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.226925,	
2017-06-19 14:07:01,859 Epoch[1] Batch [2330]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.226785,	
2017-06-19 14:07:09,415 Epoch[1] Batch [2340]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.226663,	
2017-06-19 14:07:16,318 Epoch[1] Batch [2350]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.226487,	
2017-06-19 14:07:23,339 Epoch[1] Batch [2360]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.226356,	
2017-06-19 14:07:31,335 Epoch[1] Batch [2370]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.226530,	
2017-06-19 14:07:37,444 Epoch[1] Batch [2380]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.226234,	
2017-06-19 14:07:44,999 Epoch[1] Batch [2390]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.226182,	
2017-06-19 14:07:51,620 Epoch[1] Batch [2400]	Speed: 3.02 samples/sec	Train-FCNLogLoss=0.226070,	
2017-06-19 14:07:57,751 Epoch[1] Batch [2410]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.226117,	
2017-06-19 14:08:04,940 Epoch[1] Batch [2420]	Speed: 2.78 samples/sec	Train-FCNLogLoss=0.225906,	
2017-06-19 14:08:11,050 Epoch[1] Batch [2430]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.225774,	
2017-06-19 14:08:17,860 Epoch[1] Batch [2440]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.225665,	
2017-06-19 14:08:24,568 Epoch[1] Batch [2450]	Speed: 2.98 samples/sec	Train-FCNLogLoss=0.225527,	
2017-06-19 14:08:31,937 Epoch[1] Batch [2460]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.225434,	
2017-06-19 14:08:38,996 Epoch[1] Batch [2470]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.225221,	
2017-06-19 14:08:46,352 Epoch[1] Batch [2480]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.225091,	
2017-06-19 14:08:53,123 Epoch[1] Batch [2490]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.224835,	
2017-06-19 14:09:00,122 Epoch[1] Batch [2500]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.224636,	
2017-06-19 14:09:06,370 Epoch[1] Batch [2510]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.224798,	
2017-06-19 14:09:13,037 Epoch[1] Batch [2520]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.224579,	
2017-06-19 14:09:20,075 Epoch[1] Batch [2530]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.224317,	
2017-06-19 14:09:26,973 Epoch[1] Batch [2540]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.224082,	
2017-06-19 14:09:33,962 Epoch[1] Batch [2550]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.223946,	
2017-06-19 14:09:41,464 Epoch[1] Batch [2560]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.224079,	
2017-06-19 14:09:47,849 Epoch[1] Batch [2570]	Speed: 3.13 samples/sec	Train-FCNLogLoss=0.224013,	
2017-06-19 14:09:54,960 Epoch[1] Batch [2580]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.223984,	
2017-06-19 14:10:01,957 Epoch[1] Batch [2590]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.223917,	
2017-06-19 14:10:09,406 Epoch[1] Batch [2600]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.223938,	
2017-06-19 14:10:17,701 Epoch[1] Batch [2610]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.223924,	
2017-06-19 14:10:24,950 Epoch[1] Batch [2620]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.223874,	
2017-06-19 14:10:32,197 Epoch[1] Batch [2630]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.223903,	
2017-06-19 14:10:39,157 Epoch[1] Batch [2640]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.223812,	
2017-06-19 14:10:46,552 Epoch[1] Batch [2650]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.223576,	
2017-06-19 14:10:53,503 Epoch[1] Batch [2660]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.223509,	
2017-06-19 14:11:01,935 Epoch[1] Batch [2670]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.223432,	
2017-06-19 14:11:09,200 Epoch[1] Batch [2680]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.223436,	
2017-06-19 14:11:16,150 Epoch[1] Batch [2690]	Speed: 2.88 samples/sec	Train-FCNLogLoss=0.223285,	
2017-06-19 14:11:23,589 Epoch[1] Batch [2700]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.223109,	
2017-06-19 14:11:31,247 Epoch[1] Batch [2710]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.223281,	
2017-06-19 14:11:37,262 Epoch[1] Batch [2720]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.223318,	
2017-06-19 14:11:43,546 Epoch[1] Batch [2730]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.223445,	
2017-06-19 14:11:53,502 Epoch[1] Batch [2740]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.223294,	
2017-06-19 14:12:01,575 Epoch[1] Batch [2750]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.223222,	
2017-06-19 14:12:08,724 Epoch[1] Batch [2760]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.223246,	
2017-06-19 14:12:15,098 Epoch[1] Batch [2770]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.223145,	
2017-06-19 14:12:21,569 Epoch[1] Batch [2780]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.223106,	
2017-06-19 14:12:28,809 Epoch[1] Batch [2790]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.223095,	
2017-06-19 14:12:35,481 Epoch[1] Batch [2800]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.223060,	
2017-06-19 14:12:43,297 Epoch[1] Batch [2810]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.222986,	
2017-06-19 14:12:49,470 Epoch[1] Batch [2820]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.222768,	
2017-06-19 14:12:57,089 Epoch[1] Batch [2830]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.222520,	
2017-06-19 14:13:04,850 Epoch[1] Batch [2840]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.222383,	
2017-06-19 14:13:11,814 Epoch[1] Batch [2850]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.222081,	
2017-06-19 14:13:20,092 Epoch[1] Batch [2860]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.222010,	
2017-06-19 14:13:27,563 Epoch[1] Batch [2870]	Speed: 2.68 samples/sec	Train-FCNLogLoss=0.221951,	
2017-06-19 14:13:35,878 Epoch[1] Batch [2880]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.221746,	
2017-06-19 14:13:42,592 Epoch[1] Batch [2890]	Speed: 2.98 samples/sec	Train-FCNLogLoss=0.221602,	
2017-06-19 14:13:49,565 Epoch[1] Batch [2900]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.221473,	
2017-06-19 14:13:56,583 Epoch[1] Batch [2910]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.221511,	
2017-06-19 14:14:03,791 Epoch[1] Batch [2920]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.221584,	
2017-06-19 14:14:09,831 Epoch[1] Batch [2930]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.221558,	

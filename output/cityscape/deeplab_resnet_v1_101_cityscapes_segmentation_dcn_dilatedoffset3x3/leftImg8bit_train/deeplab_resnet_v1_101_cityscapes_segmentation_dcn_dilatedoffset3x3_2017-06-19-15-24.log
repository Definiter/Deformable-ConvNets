2017-06-19 15:24:02,916 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data01/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data01/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn_dilatedoffset3x3'}

2017-06-19 15:24:41,030 Epoch[0] Batch [10]	Speed: 5.10 samples/sec	Train-FCNLogLoss=2.870169,	
2017-06-19 15:24:48,939 Epoch[0] Batch [20]	Speed: 5.06 samples/sec	Train-FCNLogLoss=2.719368,	
2017-06-19 15:24:56,778 Epoch[0] Batch [30]	Speed: 5.10 samples/sec	Train-FCNLogLoss=2.466591,	
2017-06-19 15:25:04,615 Epoch[0] Batch [40]	Speed: 5.10 samples/sec	Train-FCNLogLoss=2.253644,	
2017-06-19 15:25:12,477 Epoch[0] Batch [50]	Speed: 5.09 samples/sec	Train-FCNLogLoss=2.060391,	
2017-06-19 15:25:20,398 Epoch[0] Batch [60]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.924452,	
2017-06-19 15:25:28,127 Epoch[0] Batch [70]	Speed: 5.18 samples/sec	Train-FCNLogLoss=1.777421,	
2017-06-19 15:25:35,838 Epoch[0] Batch [80]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.667817,	
2017-06-19 15:25:43,697 Epoch[0] Batch [90]	Speed: 5.09 samples/sec	Train-FCNLogLoss=1.583615,	
2017-06-19 15:25:51,840 Epoch[0] Batch [100]	Speed: 4.91 samples/sec	Train-FCNLogLoss=1.500808,	
2017-06-19 15:25:59,935 Epoch[0] Batch [110]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.427480,	
2017-06-19 15:26:08,218 Epoch[0] Batch [120]	Speed: 4.83 samples/sec	Train-FCNLogLoss=1.361318,	
2017-06-19 15:26:16,120 Epoch[0] Batch [130]	Speed: 5.06 samples/sec	Train-FCNLogLoss=1.303643,	
2017-06-19 15:26:24,235 Epoch[0] Batch [140]	Speed: 4.93 samples/sec	Train-FCNLogLoss=1.252060,	
2017-06-19 15:26:31,832 Epoch[0] Batch [150]	Speed: 5.27 samples/sec	Train-FCNLogLoss=1.202003,	
2017-06-19 15:26:39,927 Epoch[0] Batch [160]	Speed: 4.94 samples/sec	Train-FCNLogLoss=1.157208,	
2017-06-19 15:26:47,846 Epoch[0] Batch [170]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.125169,	
2017-06-19 15:26:56,237 Epoch[0] Batch [180]	Speed: 4.77 samples/sec	Train-FCNLogLoss=1.092664,	
2017-06-19 15:27:04,010 Epoch[0] Batch [190]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.062163,	
2017-06-19 15:27:12,547 Epoch[0] Batch [200]	Speed: 4.69 samples/sec	Train-FCNLogLoss=1.036241,	
2017-06-19 15:27:20,516 Epoch[0] Batch [210]	Speed: 5.02 samples/sec	Train-FCNLogLoss=1.009720,	
2017-06-19 15:27:28,653 Epoch[0] Batch [220]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.986087,	
2017-06-19 15:27:36,213 Epoch[0] Batch [230]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.967769,	
2017-06-19 15:27:44,043 Epoch[0] Batch [240]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.947950,	
2017-06-19 15:27:51,522 Epoch[0] Batch [250]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.927344,	
2017-06-19 15:27:59,225 Epoch[0] Batch [260]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.909416,	
2017-06-19 15:28:06,948 Epoch[0] Batch [270]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.895711,	
2017-06-19 15:28:15,168 Epoch[0] Batch [280]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.879942,	
2017-06-19 15:28:22,762 Epoch[0] Batch [290]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.867292,	
2017-06-19 15:28:30,793 Epoch[0] Batch [300]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.852704,	
2017-06-19 15:28:38,660 Epoch[0] Batch [310]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.840043,	
2017-06-19 15:28:46,992 Epoch[0] Batch [320]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.827250,	
2017-06-19 15:28:54,660 Epoch[0] Batch [330]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.816042,	
2017-06-19 15:29:02,606 Epoch[0] Batch [340]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.803884,	
2017-06-19 15:29:10,578 Epoch[0] Batch [350]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.793492,	
2017-06-19 15:29:18,527 Epoch[0] Batch [360]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.783592,	
2017-06-19 15:29:26,303 Epoch[0] Batch [370]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.774221,	
2017-06-19 15:29:34,388 Epoch[0] Batch [380]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.764422,	
2017-06-19 15:29:42,591 Epoch[0] Batch [390]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.757164,	
2017-06-19 15:29:50,634 Epoch[0] Batch [400]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.747536,	
2017-06-19 15:29:59,774 Epoch[0] Batch [410]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.737977,	
2017-06-19 15:30:07,882 Epoch[0] Batch [420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.730758,	
2017-06-19 15:30:16,494 Epoch[0] Batch [430]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.723151,	
2017-06-19 15:30:30,023 Epoch[0] Batch [440]	Speed: 2.96 samples/sec	Train-FCNLogLoss=0.714569,	
2017-06-19 15:30:44,552 Epoch[0] Batch [450]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.706145,	
2017-06-19 15:31:00,358 Epoch[0] Batch [460]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.698576,	
2017-06-19 15:31:17,132 Epoch[0] Batch [470]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.692935,	
2017-06-19 15:31:35,791 Epoch[0] Batch [480]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.689231,	
2017-06-19 15:31:55,550 Epoch[0] Batch [490]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.684680,	
2017-06-19 15:32:13,111 Epoch[0] Batch [500]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.678188,	
2017-06-19 15:32:32,071 Epoch[0] Batch [510]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.673857,	
2017-06-19 15:32:49,957 Epoch[0] Batch [520]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.668112,	
2017-06-19 15:33:10,678 Epoch[0] Batch [530]	Speed: 1.93 samples/sec	Train-FCNLogLoss=0.662431,	
2017-06-19 15:33:28,607 Epoch[0] Batch [540]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.657397,	
2017-06-19 15:33:45,606 Epoch[0] Batch [550]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.652254,	
2017-06-19 15:34:04,194 Epoch[0] Batch [560]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.647267,	
2017-06-19 15:34:22,253 Epoch[0] Batch [570]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.642273,	
2017-06-19 15:34:41,984 Epoch[0] Batch [580]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.636953,	
2017-06-19 15:34:59,894 Epoch[0] Batch [590]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.632359,	
2017-06-19 15:35:18,695 Epoch[0] Batch [600]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.627109,	
2017-06-19 15:35:37,179 Epoch[0] Batch [610]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.623486,	
2017-06-19 15:35:55,372 Epoch[0] Batch [620]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.618810,	
2017-06-19 15:36:15,348 Epoch[0] Batch [630]	Speed: 2.00 samples/sec	Train-FCNLogLoss=0.614767,	
2017-06-19 15:36:34,970 Epoch[0] Batch [640]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.610476,	
2017-06-19 15:36:53,810 Epoch[0] Batch [650]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.606932,	
2017-06-19 15:37:13,145 Epoch[0] Batch [660]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.604099,	
2017-06-19 15:37:30,565 Epoch[0] Batch [670]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.600731,	
2017-06-19 15:37:49,940 Epoch[0] Batch [680]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.598364,	
2017-06-19 15:38:09,330 Epoch[0] Batch [690]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.594689,	
2017-06-19 15:38:27,668 Epoch[0] Batch [700]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.591489,	
2017-06-19 15:38:44,567 Epoch[0] Batch [710]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.587584,	
2017-06-19 15:39:02,831 Epoch[0] Batch [720]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.583953,	
2017-06-19 15:39:21,312 Epoch[0] Batch [730]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.580826,	
2017-06-19 15:39:39,814 Epoch[0] Batch [740]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.577171,	
2017-06-19 15:39:58,666 Epoch[0] Batch [750]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.573421,	
2017-06-19 15:40:19,098 Epoch[0] Batch [760]	Speed: 1.96 samples/sec	Train-FCNLogLoss=0.570954,	
2017-06-19 15:40:38,019 Epoch[0] Batch [770]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.567952,	
2017-06-19 15:40:56,637 Epoch[0] Batch [780]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.565636,	
2017-06-19 15:41:14,417 Epoch[0] Batch [790]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.562986,	
2017-06-19 15:41:32,040 Epoch[0] Batch [800]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.560363,	
2017-06-19 15:41:50,598 Epoch[0] Batch [810]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.558410,	
2017-06-19 15:42:08,467 Epoch[0] Batch [820]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.555896,	
2017-06-19 15:42:28,308 Epoch[0] Batch [830]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.553348,	
2017-06-19 15:42:47,014 Epoch[0] Batch [840]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.550937,	
2017-06-19 15:43:05,188 Epoch[0] Batch [850]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.547982,	
2017-06-19 15:43:24,201 Epoch[0] Batch [860]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.545659,	
2017-06-19 15:43:42,507 Epoch[0] Batch [870]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.543459,	
2017-06-19 15:43:59,180 Epoch[0] Batch [880]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.541497,	
2017-06-19 15:44:14,261 Epoch[0] Batch [890]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.539254,	
2017-06-19 15:44:30,787 Epoch[0] Batch [900]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.537378,	
2017-06-19 15:44:48,535 Epoch[0] Batch [910]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.534414,	
2017-06-19 15:45:04,835 Epoch[0] Batch [920]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.532104,	
2017-06-19 15:45:19,974 Epoch[0] Batch [930]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.530643,	
2017-06-19 15:45:38,657 Epoch[0] Batch [940]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.528961,	
2017-06-19 15:45:55,959 Epoch[0] Batch [950]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.526896,	
2017-06-19 15:46:13,775 Epoch[0] Batch [960]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.524383,	
2017-06-19 15:46:30,128 Epoch[0] Batch [970]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.522462,	
2017-06-19 15:46:47,317 Epoch[0] Batch [980]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.520945,	
2017-06-19 15:47:04,617 Epoch[0] Batch [990]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.518923,	
2017-06-19 15:47:21,650 Epoch[0] Batch [1000]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.517195,	
2017-06-19 15:47:38,979 Epoch[0] Batch [1010]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.515276,	
2017-06-19 15:47:55,051 Epoch[0] Batch [1020]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.516502,	
2017-06-19 15:48:09,081 Epoch[0] Batch [1030]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.518718,	
2017-06-19 15:48:22,482 Epoch[0] Batch [1040]	Speed: 2.98 samples/sec	Train-FCNLogLoss=0.518274,	
2017-06-19 15:48:36,413 Epoch[0] Batch [1050]	Speed: 2.87 samples/sec	Train-FCNLogLoss=0.517643,	
2017-06-19 15:48:51,467 Epoch[0] Batch [1060]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.517969,	
2017-06-19 15:49:06,226 Epoch[0] Batch [1070]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.517727,	
2017-06-19 15:49:21,636 Epoch[0] Batch [1080]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.516898,	
2017-06-19 15:49:36,484 Epoch[0] Batch [1090]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.515926,	
2017-06-19 15:49:51,896 Epoch[0] Batch [1100]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.514389,	
2017-06-19 15:50:07,227 Epoch[0] Batch [1110]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.513164,	
2017-06-19 15:50:25,076 Epoch[0] Batch [1120]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.511771,	
2017-06-19 15:50:40,370 Epoch[0] Batch [1130]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.511399,	
2017-06-19 15:50:55,759 Epoch[0] Batch [1140]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.510317,	
2017-06-19 15:51:13,036 Epoch[0] Batch [1150]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.509362,	
2017-06-19 15:51:30,394 Epoch[0] Batch [1160]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.507832,	
2017-06-19 15:51:45,222 Epoch[0] Batch [1170]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.506071,	
2017-06-19 15:52:00,524 Epoch[0] Batch [1180]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.504348,	
2017-06-19 15:52:16,723 Epoch[0] Batch [1190]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.502789,	
2017-06-19 15:52:30,953 Epoch[0] Batch [1200]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.501645,	
2017-06-19 15:52:46,542 Epoch[0] Batch [1210]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.499947,	
2017-06-19 15:53:02,522 Epoch[0] Batch [1220]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.498733,	
2017-06-19 15:53:19,899 Epoch[0] Batch [1230]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.496965,	
2017-06-19 15:53:35,906 Epoch[0] Batch [1240]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.495930,	
2017-06-19 15:53:52,732 Epoch[0] Batch [1250]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.494782,	
2017-06-19 15:54:08,466 Epoch[0] Batch [1260]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.493185,	
2017-06-19 15:54:25,065 Epoch[0] Batch [1270]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.492508,	
2017-06-19 15:54:42,550 Epoch[0] Batch [1280]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.491218,	
2017-06-19 15:55:00,959 Epoch[0] Batch [1290]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.490130,	
2017-06-19 15:55:17,687 Epoch[0] Batch [1300]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.488802,	
2017-06-19 15:55:35,435 Epoch[0] Batch [1310]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.488460,	
2017-06-19 15:55:53,292 Epoch[0] Batch [1320]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.487704,	
2017-06-19 15:56:09,793 Epoch[0] Batch [1330]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.486497,	
2017-06-19 15:56:26,463 Epoch[0] Batch [1340]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.485414,	
2017-06-19 15:56:42,951 Epoch[0] Batch [1350]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.483830,	
2017-06-19 15:56:59,180 Epoch[0] Batch [1360]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.482650,	
2017-06-19 15:57:15,533 Epoch[0] Batch [1370]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.481454,	
2017-06-19 15:57:32,319 Epoch[0] Batch [1380]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.479792,	
2017-06-19 15:57:49,380 Epoch[0] Batch [1390]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.478222,	
2017-06-19 15:58:06,011 Epoch[0] Batch [1400]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.476874,	
2017-06-19 15:58:24,417 Epoch[0] Batch [1410]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.475122,	
2017-06-19 15:58:42,552 Epoch[0] Batch [1420]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.473826,	
2017-06-19 15:59:01,206 Epoch[0] Batch [1430]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.472893,	
2017-06-19 15:59:19,543 Epoch[0] Batch [1440]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.471292,	
2017-06-19 15:59:36,128 Epoch[0] Batch [1450]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.470123,	
2017-06-19 15:59:54,877 Epoch[0] Batch [1460]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.468628,	
2017-06-19 16:00:12,395 Epoch[0] Batch [1470]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.467347,	
2017-06-19 16:00:28,962 Epoch[0] Batch [1480]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.466132,	
2017-06-19 16:00:40,222 Epoch[0] Train-FCNLogLoss=0.465234
2017-06-19 16:00:40,222 Epoch[0] Time cost=2172.129
2017-06-19 16:00:41,904 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.params"
2017-06-19 16:00:46,460 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.states"
2017-06-19 16:00:59,796 Epoch[1] Batch [10]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.298143,	
2017-06-19 16:01:11,464 Epoch[1] Batch [20]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.304625,	
2017-06-19 16:01:22,929 Epoch[1] Batch [30]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.287448,	
2017-06-19 16:01:35,177 Epoch[1] Batch [40]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.285535,	
2017-06-19 16:01:46,880 Epoch[1] Batch [50]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.277533,	
2017-06-19 16:01:58,540 Epoch[1] Batch [60]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.276318,	
2017-06-19 16:02:10,821 Epoch[1] Batch [70]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.288721,	
2017-06-19 16:02:21,895 Epoch[1] Batch [80]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.301004,	
2017-06-19 16:02:33,338 Epoch[1] Batch [90]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.332289,	
2017-06-19 16:02:45,178 Epoch[1] Batch [100]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.333042,	
2017-06-19 16:02:57,073 Epoch[1] Batch [110]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.332473,	
2017-06-19 16:03:08,884 Epoch[1] Batch [120]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.330559,	
2017-06-19 16:03:20,553 Epoch[1] Batch [130]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.333014,	
2017-06-19 16:03:32,415 Epoch[1] Batch [140]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.333884,	
2017-06-19 16:03:44,561 Epoch[1] Batch [150]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.338256,	
2017-06-19 16:03:56,447 Epoch[1] Batch [160]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.341220,	
2017-06-19 16:04:08,123 Epoch[1] Batch [170]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.343083,	
2017-06-19 16:04:19,667 Epoch[1] Batch [180]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.342948,	
2017-06-19 16:04:31,877 Epoch[1] Batch [190]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.343141,	
2017-06-19 16:04:43,594 Epoch[1] Batch [200]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.339254,	
2017-06-19 16:04:55,489 Epoch[1] Batch [210]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.336352,	
2017-06-19 16:05:07,386 Epoch[1] Batch [220]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.334456,	
2017-06-19 16:05:19,016 Epoch[1] Batch [230]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.332425,	
2017-06-19 16:05:31,258 Epoch[1] Batch [240]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.329220,	
2017-06-19 16:05:42,689 Epoch[1] Batch [250]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.332289,	
2017-06-19 16:05:54,479 Epoch[1] Batch [260]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.330080,	
2017-06-19 16:06:06,355 Epoch[1] Batch [270]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.330185,	
2017-06-19 16:06:18,773 Epoch[1] Batch [280]	Speed: 3.22 samples/sec	Train-FCNLogLoss=0.327716,	
2017-06-19 16:06:30,607 Epoch[1] Batch [290]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.324814,	
2017-06-19 16:06:41,596 Epoch[1] Batch [300]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.323114,	
2017-06-19 16:06:53,186 Epoch[1] Batch [310]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.321124,	
2017-06-19 16:07:05,117 Epoch[1] Batch [320]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.320305,	
2017-06-19 16:07:16,932 Epoch[1] Batch [330]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.318582,	
2017-06-19 16:07:28,621 Epoch[1] Batch [340]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.317729,	
2017-06-19 16:07:39,673 Epoch[1] Batch [350]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.316503,	
2017-06-19 16:07:51,662 Epoch[1] Batch [360]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.314916,	
2017-06-19 16:08:03,608 Epoch[1] Batch [370]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.313735,	
2017-06-19 16:08:15,342 Epoch[1] Batch [380]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.312938,	
2017-06-19 16:08:27,201 Epoch[1] Batch [390]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.312084,	
2017-06-19 16:08:39,410 Epoch[1] Batch [400]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.310655,	
2017-06-19 16:08:50,379 Epoch[1] Batch [410]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.309323,	
2017-06-19 16:09:02,004 Epoch[1] Batch [420]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.307952,	
2017-06-19 16:09:13,957 Epoch[1] Batch [430]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.307099,	
2017-06-19 16:09:25,884 Epoch[1] Batch [440]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.305229,	
2017-06-19 16:09:37,549 Epoch[1] Batch [450]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.303787,	
2017-06-19 16:09:49,190 Epoch[1] Batch [460]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.302244,	
2017-06-19 16:10:01,576 Epoch[1] Batch [470]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.300932,	
2017-06-19 16:10:13,426 Epoch[1] Batch [480]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.300297,	
2017-06-19 16:10:25,335 Epoch[1] Batch [490]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.299774,	
2017-06-19 16:10:37,453 Epoch[1] Batch [500]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.298979,	
2017-06-19 16:10:49,232 Epoch[1] Batch [510]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.298224,	
2017-06-19 16:11:01,170 Epoch[1] Batch [520]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.298031,	
2017-06-19 16:11:12,907 Epoch[1] Batch [530]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.297280,	
2017-06-19 16:11:24,747 Epoch[1] Batch [540]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.296446,	
2017-06-19 16:11:36,685 Epoch[1] Batch [550]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.295696,	
2017-06-19 16:11:48,294 Epoch[1] Batch [560]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.296083,	
2017-06-19 16:12:00,006 Epoch[1] Batch [570]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.295356,	
2017-06-19 16:12:12,241 Epoch[1] Batch [580]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.294128,	
2017-06-19 16:12:24,596 Epoch[1] Batch [590]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.294054,	
2017-06-19 16:12:36,219 Epoch[1] Batch [600]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.293379,	
2017-06-19 16:12:48,023 Epoch[1] Batch [610]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.292542,	
2017-06-19 16:12:59,269 Epoch[1] Batch [620]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.292079,	
2017-06-19 16:13:11,668 Epoch[1] Batch [630]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.291616,	
2017-06-19 16:13:23,560 Epoch[1] Batch [640]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.291611,	
2017-06-19 16:13:35,870 Epoch[1] Batch [650]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.290789,	
2017-06-19 16:13:47,506 Epoch[1] Batch [660]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.289991,	
2017-06-19 16:14:00,878 Epoch[1] Batch [670]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.289213,	
2017-06-19 16:14:16,139 Epoch[1] Batch [680]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.288455,	
2017-06-19 16:14:31,424 Epoch[1] Batch [690]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.287699,	
2017-06-19 16:14:47,429 Epoch[1] Batch [700]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.286778,	
2017-06-19 16:15:00,669 Epoch[1] Batch [710]	Speed: 3.02 samples/sec	Train-FCNLogLoss=0.286700,	
2017-06-19 16:15:14,296 Epoch[1] Batch [720]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.287277,	
2017-06-19 16:15:26,236 Epoch[1] Batch [730]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.286725,	
2017-06-19 16:15:38,234 Epoch[1] Batch [740]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.285606,	
